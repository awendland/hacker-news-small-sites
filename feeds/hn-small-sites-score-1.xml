<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 04 Oct 2020 01:07:49 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sun, 04 Oct 2020 01:07:49 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[A Fistful of States: More State Machine Patterns in Rust]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24661395">thread link</a>) | @lukastyrychtr
<br/>
October 2, 2020 | https://deislabs.io/posts/a-fistful-of-states/ | <a href="https://web.archive.org/web/*/https://deislabs.io/posts/a-fistful-of-states/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

<p>Earlier this year, DeisLabs released Krustlet, a project to implement Kubelet
in Rust. <sup id="fnref:Fisher"><a href="#fn:Fisher">1</a></sup> <sup id="fnref:Squillace"><a href="#fn:Squillace">2</a></sup> Kubelet is the component of Kubernetes that
runs on each node which is assigned Pods by the control plane and runs them on
its node. Krustlet defines a flexible API in the <code>kubelet</code> crate, which allows
developers to build Kubelets to run new types of workloads. The project
includes two such examples, which can run Web Assembly workloads on WASI or
waSCC runtimes. <sup id="fnref:wasmtime"><a href="#fn:wasmtime">3</a></sup> <sup id="fnref:waSCC"><a href="#fn:waSCC">4</a></sup> Beyond this, I have been working to
develop a Rust Kubelet for traditional Linux containers using the Container
Runtime Interface (CRI). <sup id="fnref:krustlet-cri"><a href="#fn:krustlet-cri">5</a></sup> <sup id="fnref:CRI"><a href="#fn:CRI">6</a></sup></p>

<p>Over the last few releases, Krustlet has focused on expanding the functionality
of these Web Assembly Kubelets, such as adding support for init containers,
fixing small bugs, and log streaming. This, in turn, has built quite a bit of
interest in alternative workloads and node architectures on Kubernetes, as well
as demonstrated the many strengths of Rust for development of these types of
applications.</p>

<p>For the <code>v0.5.0</code> release, we turned our attention to the internal architecture
of Krustlet, in particular how Pods move through their lifecycle, how
developers write this logic, and how updates to the Kubernetes control plane
are handled. <sup id="fnref:Pod-Lifecycle"><a href="#fn:Pod-Lifecycle">7</a></sup> We settled upon a state machine implementation
which should result in fewer bugs and greater fault tolerance. This refactoring
resulted in substantial changes for consumers of our API; however we believe
this will result in code that is much easier to reason about and maintain. For
an excellent summary of these changes, and description of how you can migrate
code that depends on the <code>kubelet</code> crate, please see Taylor Thomas’ excellent
<a href="https://github.com/deislabs/krustlet/releases/tag/v0.5.0">Release Notes</a>.
In this post I will share a deep dive into our new architecture and the
development journey which led to it.</p>

<h2 id="the-trailhead">The Trailhead</h2>

<p>Before <code>v0.5.0</code>, developers wishing to implement a Kubelet using Krustlet
primarily needed to implement the <code>Provider</code> trait, which allowed them to write
methods for handling events like <code>add</code>, <code>delete</code>, and <code>logs</code> for Pods scheduled
to that node. This offered a lot of flexibility, but was a very low-level API.
We identified a number of issues with this architecture:</p>

<ul>
<li>The entire lifecycle of a Pod was defined in 1 or 2 monolithic methods of the
<code>Provider</code> trait. This resulted in messy code and a very poor understanding
of error handling in the many phases of a Pod’s lifecycle.</li>
<li>Pod and Container status patches to the Kubernetes control plane were
scattered throughout the codebase, both in the <code>kubelet</code> crate and the
<code>Provider</code> implementations. This made it very difficult to reason about what
was actually reported back to the user and when, and involved lot of repeated
code.</li>
<li>Unlike the Go Kubelet, if Krustlet encountered an error it would report the
error back to Kubernetes and then (most of the time) end execution of the
Pod. There was no built-in notion of the reconciliation loop that one expects
from Kubernetes.</li>
<li>We recognized that a lot of these issues were left to each developer to
solve, but were things that any Kubelet would need to handle. We wanted to
move this kind of logic into the <code>kubelet</code> crate, so that each provider did
not have to reinvent things.</li>
</ul>

<h2 id="our-mission">Our Mission</h2>

<p>At its core, Kubernetes relies on declarative (mostly immutable) manifests, and
controllers which run reconciliation loops to drive cluster state to match this
configuration. Kubelet is no exception to this, with its focus being
indivisible units of work, or Pods. Kubelet simply monitors for changes to Pods
that have been assigned to it by <code>kube-scheduler</code>, and runs a loop to attempt
to run this work on its node. In fact, I would describe Kubelet as no different
from any other Kubernetes controller, except that it has the additional
first-class capability for streaming logs and exec sessions. However these
capabilities, as they are implemented in Krustlet, are orthogonal to this
discussion.</p>

<p>Our goal with this rewrite was to ensure that Krustlet would mirror the official
Kubelet’s behavior as closely as possible. We found that many details about
this behavior are undocumented, and spent considerable time running the
application to infer its behavior and inspecting the Go source code. Our
understanding is as follows:</p>

<ul>
<li>The Kubelet watches for Events on Pods that have been scheduled to it by
<code>kube-scheduler</code>.</li>
<li>When a Pod is added, the Kubelet enters a control loop to attempt to run the
Pod which only exits when the Pod is <code>Completed</code> (all containers
exit successfully) or <code>Terminated</code> (Pod is marked for deletion via the
control plane and execution is interrupted).</li>
<li>Within the control loop, there are various steps such as <code>Image Pull</code>,
<code>Starting</code>, etc., as well as back-off steps which wait some time before
retrying the Pod. At each of these steps, the Kubelet updates the control
plane.</li>
</ul>

<p>We recognized this pretty quickly as a finite-state machine design pattern,
which consists of infallible state handlers and valid state transitions. This
allows us to address the issues mentioned above:</p>

<ul>
<li>Break up the <code>Provider</code> trait methods for running the Pod into short,
single-focus state handler methods.</li>
<li>Consolidate status patch code to where a Pod enters a given state.</li>
<li>Include error and back-off states in the state graph, and only stop
attempting to execute a Pod on <code>Terminated</code> or <code>Complete</code>.</li>
<li>Move as much of this logic into <code>kubelet</code> as possible so that providers need
only focus on implementing the state handlers.
<br></li>
</ul>

<p>With this architecture it becomes very easy to understand the behavior of the
application, and strengthens our confidence that the application will not enter
undefined behavior. In addition, we felt that Rust would allow us to achieve
our goals while presenting an elegant API to developers, and with full
compile-time enforcement of our state machine rules.</p>

<h2 id="our-animal-guide">Our Animal Guide</h2>

<p>When first discussing the requirements of our state machine, and the daunting
task of integrating it with the existing Krustlet codebase, we recalled an
excellent blog post,
<a href="https://hoverbear.org/blog/rust-state-machine-pattern/">Pretty State Machine Patterns in Rust</a>,
by Ana Hobden (hoverbear), which I think has inspired a lot of Rust developers.
The post explores patterns in Rust for implementing state machines which
satisfy a number of constraints and leverage Rust’s type system. I encourage
you to read the original post, but for the sake of this discussion I will
paraphrase the final design pattern here:</p>

<pre><code>struct StateMachine&lt;S&gt; {
    state: S,
}

struct StateA;

impl StateMachine&lt;StateA&gt; {
    fn new() -&gt; Self {
        StateMachine {
            state: StateA
        }
    }
}

struct StateB;

impl From&lt;StateMachine&lt;StateA&gt;&gt; for StateMachine&lt;StateB&gt; {
    fn from(val: StateMachine&lt;StateA&gt;) -&gt; StateMachine&lt;StateB&gt; {
        StateMachine {
            state: StateB 
        }
    }
}

struct StateC;

impl From&lt;StateMachine&lt;StateB&gt;&gt; for StateMachine&lt;StateC&gt; {
    fn from(val: StateMachine&lt;StateB&gt;) -&gt; StateMachine&lt;StateC&gt; {
        StateMachine {
            state: StateC 
        }
    }
}

fn main() {
    let in_state_a = StateMachine::new();

    // Does not compile because `StateC` is not `From&lt;StateMachine&lt;StateB&gt;&gt;`.
    // let in_state_c = StateMachine::&lt;StateC&gt;::from(in_state_a);

    let in_state_b = StateMachine::&lt;StateB&gt;::from(in_state_a);

    // Does not compile because `in_state_a` was moved in the line above.
    // let in_state_b_again = StateMachine::&lt;StateB&gt;::from(in_state_a);

    let in_state_c = StateMachine::&lt;StateC&gt;::from(in_state_b);
}
</code></pre>

<p>Ana introduces a number of requirements for a good state machine
implementation, and achieves them with concise and easily interpretable code.
In particular, these requirements (some based on the definition of a state
machine, and some on ergonomics) were a high priority for us:</p>

<ul>
<li>One state at a time.</li>
<li>Capability for shared state.</li>
<li>Only explicitly defined transitions should be permitted.</li>
<li>Any error messages should be easy to understand.</li>
<li>As many errors as possible should be identified at <strong>compile-time</strong>.</li>
</ul>

<p>In the next section I will discuss some additional requirements that we
introduced and how these impacted the solution. In particular, we relaxed some
of Ana’s goals in exchange for greater flexibility, while satisfying those
listed above.</p>

<h2 id="tribulation">Tribulation</h2>

<p>We were off to a great start, but it was time to consider how we want
downstream developers to interact with our new state machine API. In
particular, while the Kubelets we are familiar with all follow roughly the same
Pod lifecycle, we wanted developers to be able to implement arbitrary state
machines for their Kubelet. For example, some workloads or architectures may
need to have additional provisioning states for infrastructure or data, or
to introduce post-run states for proper garbage collection of resources.
Additionally, it felt like an anti-pattern to have a parent method (<code>main</code> in
the example above) which defines the logic for progressing through the states,
as this felt like having two sources of truth and was not something we could
implement on behalf of our downstream developers for arbitrary state machines.
Ana had discussed how to hold the state machine in a parent structure using an
<code>enum</code>, but it felt clunky to introduce large match statements which could
introduce runtime errors.</p>

<p>We knew that to allow arbitrary state machines we would need a <code>State</code> trait to
mark types as valid states. We felt that it would be possible for this trait to
have a <code>next()</code> method which runs the state and then returns the next <code>State</code>
to transition to, and we wanted our code to be able to simply call <code>next()</code>
repeatedly to drive the machine to completion. This pattern, we soon found,
introduced a number of challenges.</p>

<pre><code>/// Rough pseudocode of our plan.

trait State {
    /// Do work for this state and return next state.
    async fn next(self) -&gt; impl State;
}

fn drive_state_machine(mut state: impl State) {
    loop {
        state = state.next().await;
    }
}
</code></pre>

<h3 id="what-does-next-return">What does <code>next()</code> return?</h3>

<p>Within our loop, we are repeatedly overwriting a local variable with
<em>different</em> types that all implement <code>State</code>. …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://deislabs.io/posts/a-fistful-of-states/">https://deislabs.io/posts/a-fistful-of-states/</a></em></p>]]>
            </description>
            <link>https://deislabs.io/posts/a-fistful-of-states/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24661395</guid>
            <pubDate>Fri, 02 Oct 2020 11:16:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Digital Euro [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24661368">thread link</a>) | @user1241320
<br/>
October 2, 2020 | https://www.ecb.europa.eu/pub/pdf/other/Report_on_a_digital_euro~4d7268b458.en.pdf | <a href="https://web.archive.org/web/*/https://www.ecb.europa.eu/pub/pdf/other/Report_on_a_digital_euro~4d7268b458.en.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.ecb.europa.eu/pub/pdf/other/Report_on_a_digital_euro~4d7268b458.en.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24661368</guid>
            <pubDate>Fri, 02 Oct 2020 11:13:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Privacy Is the Most Important Concept of Our Time]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24661271">thread link</a>) | @umilegenio
<br/>
October 2, 2020 | https://inre.me/why-privacy-is-the-most-important-concept-of-our-time/ | <a href="https://web.archive.org/web/*/https://inre.me/why-privacy-is-the-most-important-concept-of-our-time/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-25770" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">

	
	
<div>

	
	<!-- .entry-header -->

	
	<div itemprop="text">

		
		
<p>I have always believed in the importance of privacy, but I felt that common definitions (e.g., <em>the right to be left alone</em>) were lacking. In fact, I think that the whole conceptualization of privacy as simply a right of an individual as partial and limiting. It could be because privacy, as <a href="https://en.wikipedia.org/wiki/Privacy">it is intended nowadays, originated from the Anglo-American world (that is what Wikipedia says</a>). </p>



<p>You might say that then, maybe, I am not really thinking about privacy, but rather something else. That might be true, so let’s not talk about privacy, instead let’s talk about <a href="https://en.wikipedia.org/wiki/Definitions_of_fascism#Umberto_Eco">Ur-Privacy</a>, the properties of any version of the concept of privacy you might have. Take this as the opinion of a random guy that cares about the issue.</p>



<div><h2>What is Ur-Privacy</h2><p><em>A few principles for privacy</em></p></div>







<p><strong>Privacy is about boundaries.</strong> <strong>It is not about hiding something from someone but allowing to create a space with rules</strong> <strong>decided by its members</strong>. I like to compare it to borders. Some people say that borders are a restriction, something that limit freedom of movement and we do not need in the contemporary world. As if they were arbitrary obstacles put there by the ancient petty Greek gods. It almost makes sense if you do not think about them, after all you are actually stopped at a border.</p>



<p>However, that is not true, that is not why they exist. Borders delimit the area that a certain state control, an area where a specific set of rules and laws applies. There was a time before borders, in fact most of human history did not have clear borders. It was not a time of freedom, but anarchy, where bands of barbarians could roam into your home and pillage everything.</p>



<p>In this context is also important to remember that before the <a href="https://en.wikipedia.org/wiki/Peace_of_Westphalia">Peace of Westphalia</a> modern European states were plagued by continual wars. The short version is that this was due to the combination of two facts:</p>



<ul><li>modernity begets differences, different kings choose different religions<sup><a id="link_1" href="#note_1" data-type="internal" data-id="#note_1">1</a></sup> and separated societies</li><li>however, the legitimacy of kings was still based on shared medieval ideals, like the concept of divine rule</li></ul>



<p>In short, the issue was not that leaders wanted to make war all the time, they needed to do so because the legitimacy of their power depended, at least on some level, to what the rest of the European world was doing. If you claim to be a divine king there better be agreement on what the divine is, otherwise a guy that picks a different religion can also rightly pick a different king. To change the situation this peace treaty established the principle that the internal affairs of a state are the exclusive interest of said state.</p>



<p>The connection with privacy is that without clear rules on what is private and what is public, nobody knows which stuff belongs to whom and this means that all belong to the strongest. <strong>Somebody might say that what you do in private, it is not private at all but political, it concerns the society at large. Therefore it must be regulated according to their rules</strong>.</p>



<p><strong>Privacy is about control</strong>. <strong>Without privacy we cannot decide for ourselves how to live our lives.</strong> If there is no privacy all become public. Whoever has more power and an interest can affect your life according to their own rules. Then, I have to care about what other people think, otherwise they will control how I can behave. As before the peace of Westphalia, the issue is not that other people are bad, <em>they have to do it</em>. When everything is subject to public scrutiny, you either control the rules and judge others or you are judged and controlled by others.</p>



<p>Think about this way: we say a lot of things in our private lives that are not meant to be taken literally. In private we say something and then we add: <em>you know what I mean</em>. And that is actually true. We can do that because the people we talk to in private know us; they understand the context in which our words must be understood. When I was a child I would sometimes say and think that I wanted to kill my brother. I did not meant literally and everybody knew it. If I said the same thing now, in public, to somebody that does not know me, the phrase would be different. It would be a <a href="https://en.wikipedia.org/wiki/Threat">threat</a>.</p>



<p>Why is that? They are the exact same words. You know why, of course. I am different and the context is different. The real meaning of something, whether an action or a word, is not absolute, in most cases is relative. When we speak in public, we share a different context, therefore our words have a different meaning.</p>



<p>So even I say something as an hyperbole or as an potentially implicit threat (e.g., <em>they must be stopped at all costs</em>!), they might protest. You might say that they are overreacting, that it was just a joke, but <em>how can they be sure of it</em>? <strong>They do not know me.</strong> <strong>And it is true that acts of violence are prepared by violent words</strong>. Even if you are unsure if something is really violent, you have to take a stand. You have to make clear that any attack against you is not permissible. Otherwise, <a href="https://en.wikipedia.org/wiki/Christchurch_mosque_shootings" data-type="URL" data-id="https://en.wikipedia.org/wiki/Christchurch_mosque_shootings">somebody, maybe a crazy guy, might think that it is permissible and the right course of action</a>. Somebody might feel legitimate to take your land and kingdom.</p>



<p>A clear example of the loss of privacy is the <em>rise of violent rhetoric</em>. Everybody swears and everybody threaten. However, for the most part they do not mean it. We know that because the actual rate of violence has not risen. We simply talk in public as we talk in private, because our private lives have become more public. I mean, some bosses want even to look at your Facebook profile<sup><a href="#note_2">2</a></sup><a id="link_2" href="https://inre.me/why-privacy-is-the-most-important-concept-of-our-time/note_2">.</a></p>



<div><h2>Privacy Affects Everything</h2><p><em>Defending privacy would require all-around changes</em></p></div>







<p><strong>Privacy is the most important concept of our time, because it allows to define everything else. Without privacy we do not know what rules applies. Our lives will be judged according to the rules, even the whims, of somebody else.</strong></p>



<p>People lost jobs and had their lives ruined, because the mob judged something they said in private in a different way from what they expected. And they paid a price. You might say: that was fair. We might judge ourselves by our intentions, but others by their actions, which are real and objective.</p>







<p>I, for once, disagree with XKCD and this view. There are a couple of different issues here:</p>



<ul><li>how we should react to speech we disagree with</li><li>what was meant to be shared among friends was taken out of context and made public</li></ul>



<p>This complicates the whole matter. At a first glance the first issue should not matter here, because we are talking about privacy. However, this is a bit more complicated. Violations of privacy can affect other rights and freedom. Freedom of speech is a right regarding the public sphere. You have always been able to say everything in private, for the simple fact that people cannot control that. If now the private becomes public, then either we get absolute freedom of speech (a sort of <em>speech anarchy</em>, if you will) or we lose freedom of speech.</p>



<p>Okay, then we demand to not violate privacy even in the case of bad speech. If you said something bad in private then I cannot demand your boss to fire you. I cannot do that even by maintaining privacy: <em>trust me on this, they say something really bad</em>,<em> you should fire them</em>. This is a practical example of how privacy might affect everything.</p>



<p>This is crucial, but we have to understand that simply enforcing privacy in the traditional way is not enough anymore. To protect privacy we need to re-interpret some rights we have. For instance, traditionally there have been exceptions to privacy for public interest. If you heard somebody famous saying something controversial in private you could go public about. The issue is that few people (i.e., the press) had that power. Now we all have it. <strong>So, to defend privacy we need to accept shared norms of behavior</strong>. We cannot expect consequences outside the context that caused them.</p>



<p>This is hard to do, because people have different idea of public interest. It is not true that we judge other by their actions. We judge others by <em>our intentions</em>. So, we must be strict about the norm that the answer to some speech should be only some other form speech. In other words, if somebody offended you with some method, you should respond with the same method. If somebody said something bad, you cannot shove them. <strong>Actions by a mob in order to punish an alleged transgressor, punish a convicted transgressor, or intimidate them is not an answer to a bad argument, it is a<a href="https://en.wikipedia.org/wiki/Lynching"> lynching</a></strong>.</p>



<p>There is a difference between killing somebody and just ruining their lives. However, it is still bad. It is still lynching, something we do to one to control one hundred. Making somebody lose their livelihood because of something said in private it is not fair, because they said in a different context. They were not prepared to be judged by their worst enemies. And they should not have. </p>



<p>The philosopher Jeremy Bentham described the perfect prison as the <a href="https://en.wikipedia.org/wiki/Panopticon">Panopticon</a>. A prison where in every cell there was a one-way mirror. This way the guards could watch the inmates without being seen. Therefore the inmates would have to behave as if they were always watched. That kind of sounds like the world right now. And I am ready to lose the power to punish bad people in order to protect me from people that think I am a bad guy.</p>



<p><em>Given the discussion on Hacker News, I think that I was a bit unclear here. The connection between privacy and freedom of speech is just an example. My point is that privacy affects how we enjoy other rights, too. Even though that might not seem obvious at first.  </em></p>



<div><h2>What Should We Do?</h2><p>A modest proposal</p></div>







<p>So what has to be done to defend privacy? <strong>There should be clear boundaries about private, social and public spaces</strong>:</p>



<ul><li>a private space regards only you or your family</li><li>a social space is something involving a community, either a virtual one like a forum or a real one like a city</li><li>a public space is a space for all actors of society</li></ul>



<p>By clear boundaries I mean that we should create rules, …</p></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://inre.me/why-privacy-is-the-most-important-concept-of-our-time/">https://inre.me/why-privacy-is-the-most-important-concept-of-our-time/</a></em></p>]]>
            </description>
            <link>https://inre.me/why-privacy-is-the-most-important-concept-of-our-time/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24661271</guid>
            <pubDate>Fri, 02 Oct 2020 10:55:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Flatpak: A security nightmare – two years later]]>
            </title>
            <description>
<![CDATA[
Score 69 | Comments 13 (<a href="https://news.ycombinator.com/item?id=24661126">thread link</a>) | @krimeo
<br/>
October 2, 2020 | https://www.flatkill.org/2020/ | <a href="https://web.archive.org/web/*/https://www.flatkill.org/2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<p>Two years ago I <a href="https://flatkill.org/">wrote</a> about then heavily-pushed Flatpak, self-proclaimed "Future of Apps on Linux". The article criticized the following three major flows in Flatpak:</p><ul>
<li>Most of the apps have full access to the host system but users are misled to believe the apps are sandboxed
</li><li>The flatpak runtimes and apps do not get security updates
</li><li>Flatpak breaks many aspects of desktop integration
</li></ul>

<!-- <p>A lot has changed in the 2 years (the company behind Flatpak is now just another IBM's brand for one thing) so let's see how Flatpak developers addressed these fundamental issues.</p> -->
<p>So let's see how Flatpak developers addressed these fundamental issues.</p>

<h2>The sandbox is STILL a lie</h2>

<p>Almost all popular apps on Flathub still come with <span>filesystem=host</span> or <span>filesystem=home</span> permissions, in other words, <b>write access to the user home directory</b> (and more) so all it takes to escape the sandbox is trivial <span>echo download_and_execute_evil &gt;&gt; ~/.bashrc</span>. That's it.</p>


<p>The most popular applications on Flathub still suffer from this - Gimp, VSCodium, PyCharm, Octave, Inkscape, Audacity, VLC are still not sandboxed.</p>

<p>And, indeed, users are still mislead by the reassuring blue "sandboxed" icon. Two years is not enough to add a warning that an application is <b>not</b> sandboxed if it comes with dangerous permissions (like full access to your home directory)? Seriously?</p>

<img src="https://www.flatkill.org/2020/sandboxlie.png" alt="sandboxlie">

<h2>Flatpak apps and runtimes STILL contain long known security holes</h2>
<p>It took me about 20 minutes to find the first vulnerability in a Flathub application with full host access and I didn't even bother to use a vulnerability scanner.</p>

A perfect example is <a href="https://www.cvedetails.com/cve/CVE-2019-17498">CVE-2019-17498</a> with public exploit <a href="https://github.com/github/securitylab/tree/main/SecurityExploits/libssh2/out_of_bounds_read_disconnect_CVE-2019-17498">available</a> for some 8 months. The first app on Flathub I find to use libssh2 library is Gitg and, indeed, it does ship with unpatched libssh2.

<p>But is it just this one application? Let's look at the <b>official runtimes</b> at the heart of Flatpak (org.freedesktop.Platform and org.gnome.Platform <b>3.36</b> - as of time of writing used by most of the applications on Flathub). The first unpatched vulnerable dependency I found in the offical runtime is ffmpeg in version 4.2.1 with no security patches backported, <a href="https://www.cvedetails.com/cve/CVE-2020-12284">CVE-2020-12284</a>.</p><p>Recently I stumbled upon an article from 2011 which started what is today known as flatpak, <a href="https://people.gnome.org/~alexl/glick2">in the words of the project founder:</a></p>

<p><a href="https://people.gnome.org/~alexl/glick2"><b><i>"Another problem is with security (or bugfix) updates in bundled libraries. With bundled libraries its much harder to upgrade a single library, as you need to find and upgrade each app that uses it. Better tooling and upgrader support can lessen the impact of this, but not completely eliminate it."</i></b></a></p>

<p>After reading that it comes as no surprise flatpak still suffers from the same security issues as 2 years ago because flatpak developers knew about these problems from the beginning.</p>

<h2>Local root exploits are NOT considered a minor issue anymore!</h2>
<p>Great! Two years ago I wrote about a trivial local root exploit using flatpak to install suid binaries (<a href="https://www.cvedetails.com/cve/CVE-2017-9780/">CVE-2017-9780</a>) and how it was downplayed by Flatpak developers as a minor security issue <a href="https://github.com/flatpak/flatpak/releases/tag/0.8.7">here</a>. I am happy to see at least the attitude to local root exploits has changed and today <a href="https://github.com/containers/bubblewrap/security/advisories/GHSA-j2qp-rvxj-43vj">local root exploits</a> are considered high severity.

</p><h2>Desktop integration</h2>
<p>System and user fonts are now available to flatpak applications and basic font rendering settings are respected as well, however do not expect your changes in /etc/fonts, typically setting a proper fallback font for CJK characters, to work with flatpak.  KDE applications in flatpak are still ignoring themes, fonts and icon settings (tested with Qt5ct). Applications installed from the distribution sources do not have these problems, of course. <a href="https://www.flatkill.org/2020/desktopbrokenation.mp4">A quick screen capture to demonstrate</a>.</p>

<p>More importantly, fcitx, <i>the</i> IME for Chinese is still broken - it has been 2 years. Here is the <a href="https://github.com/flatpak/flatpak/issues/2031">issue</a> I linked 2 years ago - especially of interest is <a href="https://github.com/flatpak/flatpak/issues/2031#issuecomment-655134889">the following comment</a> directly from fcitx developer:

</p><p><i>"Because fcitx im module in flatpak is from 4.2.97 and using a different dbus object path. <b>It need to be the same version of fcitx on your host</b>."</i></p>

So I need to run multiple fcitx daemons on my desktop and switch between them as I switch flatpak apps depending on which fcitx libraries are bundled with that app or maybe in the future of linux apps it's not possible to type chinese anymore and it's fine?

<p>While the "bundle everything" approach has proven very useful on servers it clearly does not work for desktop applications, let's keep linking system libraries in desktop applications (and use the bundled libraries as a fallback only) to avoid introducing all these problems to Linux desktop.</p>



</div>]]>
            </description>
            <link>https://www.flatkill.org/2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24661126</guid>
            <pubDate>Fri, 02 Oct 2020 10:35:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Coding Graphical UIs with React and SVG Part 2]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24661031">thread link</a>) | @moonpool
<br/>
October 2, 2020 | https://datalanguage.com/blog/graphical-uis-with-svg-and-react-part-2-arcs-angles-and-transformations | <a href="https://web.archive.org/web/*/https://datalanguage.com/blog/graphical-uis-with-svg-and-react-part-2-arcs-angles-and-transformations">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In this mini-series we’re looking at rendering interactive graphical UI’s using components built with React and SVG.</p><p>In <a href="https://datalanguage.com/blog/graphical-uis-with-svg-and-react-part-1-declarative-graphics" rel="noopener">part 1</a>, Declarative Graphics, we used React to compose simple graphical components from declarative SVG primitives, and covered the basics of the viewBox and the viewport.</p><p>Throughout the series we’ll be putting together an interactive floor-plan. In this, part 2, we’re going to add security cameras to the plan and show their field of view, giving us the opportunity to explore arcs, angles, and transformations, along with a useful little digression into alternative coordinate systems.</p><p>Let’s start by creating a simple <code>Camera</code> component that we can place inside any <code>Room</code> at a position and orientation we specify. The basic camera will look like this:</p><figure><img src="https://images.datalanguage.com/2020/10/Screenshot-2020-07-24-16.31.52.png" alt="" srcset="https://images.datalanguage.com/size/w600/2020/10/Screenshot-2020-07-24-16.31.52.png 600w, https://images.datalanguage.com/2020/10/Screenshot-2020-07-24-16.31.52.png 1000w" sizes="(min-width: 720px) 720px"><figcaption>How we'd like our camera component to look (zoomed in for clarity)</figcaption></figure><p>Our camera shape is straight-forward, and can be composed as a path with 8 straight-line segments joining up 8 coordinates. SVG <code>path</code> elements are powerful tools that create shapes from lines, curves, and arcs and can be stroked and filled just like <code>circle</code> and <code>rect</code>.</p><p>Our initial use of path is relatively simple and consists of simple straight line segments using the <code>L</code> command to join up the 8 coordinates of our camera, marked below with black circles.</p><figure><img src="https://images.datalanguage.com/2020/10/Screenshot-2020-07-24-17.36.52.png" alt="" srcset="https://images.datalanguage.com/size/w600/2020/10/Screenshot-2020-07-24-17.36.52.png 600w, https://images.datalanguage.com/2020/10/Screenshot-2020-07-24-17.36.52.png 800w" sizes="(min-width: 720px) 720px"></figure><p>We’ll make it easy on ourselves by using single digits of a 4x4 square, so our path is easy to create. The path element takes its path data in a <code>d</code> attribute <code>&lt;path d={``}/&gt;</code>.</p><p>We begin by telling it to “move” to the coordinate of the first black circle at (0,0), then proceed to draw lines to each of the other absolute coordinates. The final segment is drawn automatically when we “close” the path with <code>Z</code>.</p><pre><code>&lt;path 
  d={`M0,0 L4,0 L3,1 L4,1 L4,4 L0,4 L0,1 L1,1 Z`}
  fill="black"
/&gt;</code></pre><h3 id="relatively-simple">Relatively Simple</h3><p>Path commands such as <code>L</code> can be absolute or relative, designated by upper or lower case respectively, so an alternative way to write the same camera path is to use relative coordinates, like so:</p><pre><code>&lt;path
  d={`M0,0 l4,0 l-1,1 l1,0 l0,3 l-4,0 l0,-3 l1,0 Z`}
  fill="black"
/&gt;</code></pre><p>Alternatively, a convenient shortcut when drawing lines which are perfectly vertical or horizontal is to use <code>V</code> or <code>H</code> with absolute coords, or <code>v</code> and <code>h</code> with relative coords, yielding yet another alternative way of drawing the same path:</p><pre><code>&lt;path
  d={`M0,0 h4 l-1,1 h1 v3 h-4 v-3 h1 Z`}
  fill="black"
/&gt;</code></pre><h2 id="everything-in-its-place">Everything in its place</h2><p>That’s great, we have a nice camera shape, but there’s a problem: we’ve drawn it with the top corner of the camera at the origin of our user-space. How can we place it at a specific location in our user-space? And what if we want to draw more than one Camera at different locations?</p><p>One simple option might be to use string interpolation to set the initial position <code>Mx,y</code> to something other than <code>0,0</code>.</p><pre><code>const Camera = ({x, y}) =&gt; (
  &lt;path
    d={`M${x},${y} h4 l-1,1 h1 v3 h-4 v-3 h1 Z`}
    fill="black"
  /&gt;
);</code></pre><p>OK, that works, but the camera is not positioned <em>quite</em> where we want it — we probably meant that x,y is the centre of the camera, so we need to offset it by -50% on each axis. We know that the camera is 4 user-space units wide and 4 units high, so the maths is easy:</p><pre><code>const Camera = ({x, y}) =&gt; (
  &lt;path
    d={`M${x-2},${y-2} h4 l-1,1 h1 v3 h-4 v-3 h1 Z`}
    fill="black"
  /&gt;
);</code></pre><p>This is reasonably straight-forward, and because we used relative coords to define the path we only had to do any math for the initial move <code>M</code> operation. However, there’s an alternative way of positioning things without tinkering with the path, which also opens up some exciting new opportunities…</p><h3 id="simply-transformational">Simply Transformational</h3><p>Shifting the camera to centre it on the given coordinates involved a reasonably simple change to the path, but things would rapidly get out of hand if we want to, say, rotate the camera by 45 degrees using this approach.</p><p>Instead, what if we could design our camera for the simple case of being drawn at the origin and pointing straight upwards, and then apply transformations to position and rotate it as required, avoiding any complicated maths?</p><p>In fact we can do just that using the <code>transform</code> attribute, which takes a list of transformation operations and applies them in order. Valid transform operations are:</p><ul><li><code>translate</code> — move horizontally and vertically</li><li><code>rotate</code></li><li><code>scale</code></li><li>skew (<code>skewX</code> and <code>skewY</code>)</li><li><code>matrix</code> (a mathematical expression that consolidates all of the above)</li></ul><p>We can specify a list of these operations in a single transform string like this:</p><pre><code>transform="translate(20,30) rotate(45) scale(10)"</code></pre><p>Recall from part 1 that the initial “user-space” specified by the viewBox is the coordinate system in which our SVG primitives are drawn.</p><p>By providing a transform attribute with a transform list we are creating a <em>new, nested user-space</em> — a new coordinate system in which the attributed element is drawn.</p><p>When applied to a simple element such as a <code>circle</code>, <code>rect</code>, <code>path</code>, etc., the new user-space only applies to that element. However, we can also set a transform on a group <code>&lt;g&gt;</code> element, in which case all elements nested within that group are also drawn in the user-space of the transformed <code>g</code> element.</p><p>With this in mind, we can now declare our Camera component such that it can be easily positioned and rotated:</p><pre><code>const Camera = ({ x, y, angle }) =&gt; (
  &lt;g transform={`translate(${x}, ${y}) rotate(${angle})`}&gt;
    &lt;path
      transform="translate(-2, -2)"
      d="M0,0 h4 l-1,1 h1 v3 h-4 v-3 h1 Z"
      fill="#000"
    /&gt;
  &lt;/g&gt;
);</code></pre><p>This is great — the code that describes the camera’s shape is now entirely static and distinct from the code that positions and orients the camera. We can make this more explicit by extracting a component for drawing the camera body:</p><pre><code>const CameraBody = () =&gt; (  
  &lt;path
    transform="translate(-2, -2)"
    d="M0,0 h4 l-1,1 h1 v3 h-4 v-3 h1 Z"
    fill="#000"
  /&gt;
);

const Camera = ({ x, y, angle }) =&gt; (
  &lt;g transform={`translate(${x}, ${y}) rotate(${angle})`}&gt;
    &lt;CameraBody /&gt;
  &lt;/g&gt;
);</code></pre><h3 id="adding-contrast">Adding Contrast</h3><p>The camera is quite a dark shape against the dark blue background of our floor-plan, so to increase contrast lets give it a semi-transparent circular “enclosure” that lightens the background.</p><p>Because this enclosure is nested inside our camera’s group <code>&lt;g&gt;</code> element it exists within the camera’s user-space, which means we can simply draw it at the origin and it will move and rotate with the camera — result!</p><p>Note that we draw the enclosure first, before drawing the camera body, so that the camera body appears on top of the enclosure (on the z axis) and does not get lightened by it.</p><pre><code>const CameraEnclosure = () =&gt; (
  &lt;circle
    cx="0"
    cy="0"
    r="3.5"
    fill="rgba(255,255,255,0.25)"
    stroke="#fff"
    strokeWidth={0.25}
  /&gt;
);

const Camera = ({ x, y, angle }) =&gt; (
  &lt;g transform={`translate(${x}, ${y}) rotate(${angle})`}&gt;      
    &lt;CameraEnclosure /&gt;
    &lt;CameraBody /&gt;
  &lt;/g&gt;
);</code></pre><p>And now we can render multiple cameras in different positions and orientations and see them clearly on our blueprint backdrop:</p><pre><code>{  
  Array.from({ length: 6 }).map((_, i) =&gt; (    
    &lt;Camera
      key={`camera_${i}`}
      x={Math.round(Math.random() * 5000)}
      y={Math.round(Math.random() * 3000)}
      angle={Math.random() * 360}
    /&gt;  
  ))
}</code></pre><figure><img src="https://images.datalanguage.com/2020/10/multiple-cameras.png" alt="" srcset="https://images.datalanguage.com/size/w600/2020/10/multiple-cameras.png 600w, https://images.datalanguage.com/size/w1000/2020/10/multiple-cameras.png 1000w, https://images.datalanguage.com/2020/10/multiple-cameras.png 1286w" sizes="(min-width: 1200px) 1200px"><figcaption>Many instances of Camera rotated to different angles</figcaption></figure><h3 id="field-of-view">Field of View</h3><p>Before we add the cameras to our floor plan, let’s look at showing the camera’s field of view as a segment of a circle centred at the camera origin, looking like this:</p><figure><img src="https://images.datalanguage.com/2020/10/Screenshot-from-2020-09-17-16-00-04.png" alt="" srcset="https://images.datalanguage.com/size/w600/2020/10/Screenshot-from-2020-09-17-16-00-04.png 600w, https://images.datalanguage.com/size/w1000/2020/10/Screenshot-from-2020-09-17-16-00-04.png 1000w, https://images.datalanguage.com/size/w1600/2020/10/Screenshot-from-2020-09-17-16-00-04.png 1600w, https://images.datalanguage.com/2020/10/Screenshot-from-2020-09-17-16-00-04.png 1625w" sizes="(min-width: 1200px) 1200px"><figcaption>Camera with 40 degree Field-of-View</figcaption></figure><p>We’re not really trying to model the real world here, just keeping things reasonably simple by defining the field of view as an angle describing the arc, and a distance or range that describes how far the camera can “see”. The API for the <code>FieldOfView</code> component could then just be:</p><pre><code>&lt;FieldOfView angle={40} range={500} /&gt;</code></pre><p>Note that we don’t need to specify a position for <code>FieldOfView</code> because it will be nested inside the <code>Camera</code>’s group <code>g</code> element, and therefore drawn in the user-space of the <code>Camera</code>.</p><p>We can get a feel for how the props relate to the rendered field of view from the diagram below. Remember that the camera is drawn pointing upwards, so the mid-point of the field of view needs to be directly &nbsp;up the y-axis from the origin.</p><figure><img src="https://images.datalanguage.com/2020/10/Screenshot-from-2020-09-30-12-25-41.png" alt="" srcset="https://images.datalanguage.com/size/w600/2020/10/Screenshot-from-2020-09-30-12-25-41.png 600w, https://images.datalanguage.com/2020/10/Screenshot-from-2020-09-30-12-25-41.png 793w"><figcaption>How the range and angle props relate to the rendered field of view</figcaption></figure><p>A quick and dirty approximation of the field of view would be a triangle connecting the dots A, B, and C along the dashed lines in the above diagram. We already know the position of A (the origin of our <code>Camera</code>’s user-space), so we just need to work out the positions of B and C, then this approximated path is super-easy to write.</p><p>To do that we need to put our math hats on again for some basic trigonometry, but I want to take a little diversion (<em>or a tangent, ahahaha</em>) and talk a little bit about coordinate systems.</p><p>If — unlike me — you are a bit of a math whiz, you might already be familiar with Euclidean spaces and coordinate systems, in which case feel free to skim the next section. If not, follow me down the rabbit-hole, <em>I promise its worth it!</em></p><h3 id="euclidean-coordinate-systems">Euclidean Coordinate Systems</h3><p>So far we’ve been working with the familiar <a href="https://en.wikipedia.org/wiki/Cartesian_coordinate_system" rel="noopener"><em>Cartesian</em></a> coordinate system for representing points in a Euclidean space, where <code>[x,y]</code> represents a distance from the origin along the x and y axes. But this isn’t the only way to represent the same point in Euclidean space!</p><p>When working with radial UI’s (think clocks, compasses, dials, and just about anything that has symmetry around a centre), there’s an alternative coordinate representation that makes everything <em>waaay</em> simpler to visualise intuitively: a <a href="https://en.wikipedia.org/wiki/Polar_coordinate_system" rel="noopener">polar coordinate system</a>.</p><p>Using polar coordinates, the Cartesian point <code>[x, y]</code> can be expressed instead as a <em>distance</em> from the origin or “pole” and an <em>angle</em> offset from a reference angle, i.e. instead of <code>[x,y]</code> we have <code>[distance, angle]</code>.</p><figure><img src="https://images.datalanguage.com/2020/10/Screenshot-from-2020-09-30-11-55-13.png" alt="" srcset="https://images.datalanguage.com/size/w600/2020/10/Screenshot-from-2020-09-30-11-55-13.png 600w, https://images.datalanguage.com/size/w1000/2020/10/Screenshot-from-2020-09-30-11-55-13.png 1000w, https://images.datalanguage.com/2020/10/Screenshot-from-2020-09-30-11-55-13.png 1515w" sizes="(min-width: 1200px) 1200px"><figcaption>The same point represented in Cartesian and polar coordinates</figcaption></figure><p>In polar coordinates, the positions of points B and C in our field-of-view are intuitively easy to read from the diagram:</p><figure><img src="https://images.datalanguage.com/2020/10/Screenshot-from-2020-09-30-12-25-41-2.png" alt="" srcset="https://images.datalanguage.com/size/w600/2020/10/Screenshot-from-2020-09-30-12-25-41-2.png 600w, https://images.datalanguage.com/2020/10/Screenshot-from-2020-09-30-12-25-41-2.png 793w" sizes="(min-width: 720px) 720px"><figcaption>Polar coordinates are intuitive in radial UI’s</figcaption></figure><p>Both are at a distance <code>range</code> …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://datalanguage.com/blog/graphical-uis-with-svg-and-react-part-2-arcs-angles-and-transformations">https://datalanguage.com/blog/graphical-uis-with-svg-and-react-part-2-arcs-angles-and-transformations</a></em></p>]]>
            </description>
            <link>https://datalanguage.com/blog/graphical-uis-with-svg-and-react-part-2-arcs-angles-and-transformations</link>
            <guid isPermaLink="false">hacker-news-small-sites-24661031</guid>
            <pubDate>Fri, 02 Oct 2020 10:20:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using GNU stow to manage dotfiles]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24660912">thread link</a>) | @mathieuh
<br/>
October 2, 2020 | http://mathieuhendey.com/posts/stowing-dotfiles/ | <a href="https://web.archive.org/web/*/http://mathieuhendey.com/posts/stowing-dotfiles/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      <p>I recently found about a piece of GNU software called Stow<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>.</p>
<p>It lets you manage your dotfiles in a really simple way, meaning you can put them in git and have them easily transferable between machines.</p>
<p>What it will do is let you move all your dotfiles into a directory, and then symlink them back into your home directory with a simple command.</p>
<p>From the man page<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>:</p>
<blockquote>
<p>Stow is a symlink farm manager which takes distinct sets of software and/or data located in separate
directories on the filesystem, and makes them all appear to be installed in a single directory tree.</p>
</blockquote>
<h2 id="set-up">Set up</h2>
<p>First you’ll need to install <code>Stow</code> using your package manager of choice. I use a Mac so it’s just:</p>
<p>Then you’ll need to create a directory in which to store your dotfiles, and directories within it to keep them separate.</p>
<div><pre><code data-lang="sh">mkdir ~/dotfiles;
mkdir ~/dotfiles/git;
mkdir ~/dotfiles/zsh;
</code></pre></div><p>Move your dotfiles into the relevant directories:</p>
<div><pre><code data-lang="sh">mv ~/.gitconfig ~/dotfiles/git;
mv ~/.zshrc ~/dotfiles/zsh;
mv ~/.zshenv ~/dotfiles/zsh;
</code></pre></div><h2 id="the-magic-part">The magic part</h2>
<p>Now here’s where <code>stow</code> comes in. Stow will, given a source directory and a destination directory, create symlinks in the destination directory to all the files in the source directory.</p>
<p>From within <code>~/dotfiles</code></p>
<p>Here’s an explanation of what that command is doing:</p>
<ol>
<li>
<p><code>-R</code> means “restow”. This will overwrite your symlinks, say if you’ve updated your dotfiles on another machine and want to sync them to your current machine From the manpage:</p>
<blockquote>
<p>Restow packages (first unstow, then stow again). This is useful for pruning obsolete symlinks
from the target tree after updating the software in a package.</p>
</blockquote>
</li>
<li>
<p><code>-t ~</code> is the target directory. This is where the symlinks will be created.</p>
</li>
<li>
<p>The final argument is the directory containing the files to be symlinked to.</p>
</li>
</ol>
<p>Putting it all together, running <code>stow -R -t ~ git</code> will create a symlink in your home directory to <code>~/dotfiles/git/.gitconfig</code>.</p>
<p>And it’s that simple.</p>
<p>Now you can <code>git init</code> inside your <code>~/dotfiles</code> directory, push them up to your remote and have them immediately available on all your machines.</p>
<p>Here’s a simple bit of bash that will stow all the dotfiles in your home directory from your <code>~/dotfiles</code> repo:</p>
<div><pre><code data-lang="sh"><span>for</span> d in */ ; <span>do</span>
    stow -R -t ~ <span>"</span>$d<span>"</span>
<span>done</span>
</code></pre></div><p>For reference, <a href="https://github.com/mathieuhendey/dotfiles">here are my dotfiles on GitHub</a>.</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p><a href="https://www.gnu.org/software/stow/">https://www.gnu.org/software/stow/</a> <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p><a href="https://linux.die.net/man/8/stow">https://linux.die.net/man/8/stow</a> <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>

    </div></div>]]>
            </description>
            <link>http://mathieuhendey.com/posts/stowing-dotfiles/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660912</guid>
            <pubDate>Fri, 02 Oct 2020 10:03:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Porting EBU R128 audio loudness analysis from C to Rust – Porting Details]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24660868">thread link</a>) | @lukastyrychtr
<br/>
October 2, 2020 | https://coaxion.net/blog/2020/09/porting-ebu-r128-audio-loudness-analysis-from-c-to-rust-porting-details/ | <a href="https://web.archive.org/web/*/https://coaxion.net/blog/2020/09/porting-ebu-r128-audio-loudness-analysis-from-c-to-rust-porting-details/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-833">
	
	<!-- .entry-header -->

	<div>
		<p>This blog post is part two of a four part series</p>
<ol>
<li><a href="https://coaxion.net/blog/2020/09/porting-ebu-r128-audio-loudness-analysis-from-c-to-rust/">Overview, summary and motivation</a></li>
<li><strong>Porting approach with various details, examples and problems I ran into along the way</strong></li>
<li>Performance optimizations</li>
<li>Building Rust code into a C library as drop-in replacement</li>
</ol>
<p>In this part I’ll go through the actual porting process of the <a href="https://github.com/jiixyj/libebur128">libebur128</a> C code to <a href="https://www.rust-lang.org/">Rust</a>, the approach I’ve chosen with various examples and a few problems I was running into.</p>
<p>It will be rather technical. I won’t explain details about how the C code works but will only focus on the aspects that are relevant for porting to Rust, otherwise this blog post would become even longer than it already is.</p>


<h2>Porting</h2>
<p>With the warnings out of the way, let’s get started. As a reminder, the code can be found on <a href="https://github.com/sdroege/ebur128/">GitHub</a> and you can also follow along the actual chronological porting process by going through the git history there. It’s not very different to what will follow here but just in case you prefer looking at diffs instead.</p>
<h3><span id="Approach">Approach</span></h3>
<p>The approach I’ve taken is basically the same that <a href="https://people.gnome.org/~federico/blog/librsvg-posts.html">Federico</a> took for <a href="https://gitlab.gnome.org/GNOME/librsvg">librsvg</a> or <a href="https://jneem.github.io/nnnoiseless/">Joe Neeman’s</a> took for <code>nnnoiseless</code>:</p>
<ol>
<li>Start with the C code and safe Rust bindings around the C API</li>
<li>Look for a function or component very low in the call graph without dependencies on (too much) other C code</li>
<li>Rewrite that code in Rust and add an internal C API for it</li>
<li>Call the new internal C API for that new Rust code from the C code and get rid of the C implementation of the component</li>
<li>Make sure the tests are still passing</li>
<li>Go to 2. and repeat</li>
</ol>
<p>Compared to what I did when <a href="https://coaxion.net/blog/2020/07/live-loudness-normalization-in-gstreamer-experiences-with-porting-a-c-audio-filter-to-rust/">porting</a> the FFmpeg loudness normalization filter this has the advantage that at every step there is a working version of the code and you don’t only notice at the very end that somewhere along the way you made a mistake. At each step you can validate that what you did was correct and the amount of code to debug if something went wrong is limited.</p>
<p>Thanks to Rust having a good <a href="https://doc.rust-lang.org/nomicon/ffi.html">FFI</a> story for interoperability with C in either direction, writing the parts of the code that are called from C or calling into C is not that much of a headache and not worse than actually writing C.</p>
<h3><span id="Rust_Bindings_around_C_Library">Rust Bindings around C Library</span></h3>
<p>This step could’ve been skipped if all I cared about was having a C API for the ported code later, or if I wanted to work with the tests of the C library for validation and worry about calling it from Rust at a later point. In this case I had already done safe Rust bindings around the C library before, and having a Rust API made it much easier to write tests that could be used during the porting and that could be automatically run at each step.</p>
<h4><span id="EJS28"> <code data-enlighter-language="raw">bindgen</code><br>
</span></h4>
<p>As a first step for creating the Rust bindings there needs to be a way to actually call into the C code. In C there are the header files with the type definitions and function declarations, but Rust can’t directly work from those. The solution to this was in this case <a href="https://github.com/rust-lang/rust-bindgen"><code>bindgen</code></a>, which basically converts the C header files into something that Rust can understand. The resulting API is completely unsafe still but can be used in a next step to write safe Rust bindings around it.</p>
<p>I would recommend using <code data-enlighter-language="raw">bindgen</code> for any non-trivial C API for which there is no better translation tool available, or for which there is no machine-readable description of the API that could be used instead by another tool. Parsing C headers is no fun and there is very little information available in C for generating safe bindings. For example for <a href="https://en.wikipedia.org/wiki/GObject"><code>GObject</code></a>-based libraries, using <a href="https://github.com/gtk-rs/gir/"><code>gir</code></a> would be a better idea as it works from a rich XML description of the API that contains information about e.g. ownership transfer and allows to autogenerate safe Rust bindings in many cases.</p>
<p>Also the dependency on <a href="https://clang.llvm.org/"><code>clang</code></a> makes it hard to run <code data-enlighter-language="raw">bindgen</code> as part of every build, so instead I’ve made sure that the code generated by <code data-enlighter-language="raw">bindgen</code> is platform independent and included it inside the repository. If you use <code>bindgen</code>, please try to do the same. Requiring <code data-enlighter-language="raw">clang</code> for building your crate makes everything more complicated for your users, especially if they’re unfortunate enough to use Windows.</p>
<p>But back to the topic. What <code data-enlighter-language="raw">bindgen</code> <a href="https://github.com/sdroege/ebur128/blob/0.1.1/src/ffi.rs">generates</a> is basically a translation of the C header into Rust: type definitions and function declarations. This looks for example as follows</p>
<pre data-enlighter-language="rust">\#[repr(C)]
\#[derive(Debug, Copy, Clone)]
pub struct ebur128_state {
    pub mode: ::std::os::raw::c_int,
    pub channels: ::std::os::raw::c_uint,
    pub samplerate: ::std::os::raw::c_ulong,
    pub d: *mut ebur128_state_internal,
}

extern "C" {
    pub fn ebur128_init(
        channels: ::std::os::raw::c_uint,
        samplerate: ::std::os::raw::c_ulong,
        mode: ::std::os::raw::c_int,
    ) -&gt; *mut ebur128_state;

    pub fn ebur128_destroy(st: *mut *mut ebur128_state);

    pub fn ebur128_add_frames_int(
        st: *mut ebur128_state,
        src: *const ::std::os::raw::c_int,
        frames: usize,
    ) -&gt; ::std::os::raw::c_int;
}
</pre>
<p>Based on this it is possible to call the C functions directly from <code data-enlighter-language="raw">unsafe</code> Rust code and access the members of all the structs. It requires working with raw pointers and ensuring that everything is done correctly at any point to not cause memory corruption or worse. It’s just like using the API from C with a slightly different syntax.</p>
<h4><span id="Build_System">Build System</span></h4>
<p>To be able to call into the C API its implementation somehow has to be linked into your crate. As the C code later also has to be modified to call into the already ported Rust functions instead of the original C code, it makes most sense to build it as part of the crate instead of linking to an external version of it.</p>
<p>This can be done with the <a href="https://crates.io/crates/cc"><code>cc</code></a> crate. It is called into from <code>cargo</code>‘s <code data-enlighter-language="raw">build.rs</code> for configuring it, for example for configuring which C files to compile and how. Once done it is possible to call any exported C function from the Rust code. The <a href="https://github.com/sdroege/ebur128/blob/0.1.1/build.rs"><code>build.rs</code></a> is not really complicated in this case</p>
<pre data-enlighter-language="rust">fn main() {
    cc::Build::new()
        .file("src/c/ebur128.c")
        .compile("ebur128");
}
</pre>
<h4><span id="Safe_Rust_API">Safe Rust API</span></h4>
<p>With all that in place a safe Rust API around the unsafe C functions can be written now. How this looks in practice differs from API to API and might require some more thought in case of a more complex API to ensure everything is still safe and sound from a Rust point of view. In this case it was fortunately rather simple.</p>
<p>For example the struct definition, the constructor and the destructor (<code>Drop</code> impl) <a href="https://github.com/sdroege/ebur128/blob/0.1.1/src/ebur128.rs">looks as follows</a> based on what <code data-enlighter-language="raw">bindgen</code> generated above</p>
<pre data-enlighter-language="rust">pub struct EbuR128(ptr::NonNull&lt;ffi::ebur128_state&gt;);
</pre>
<p>The struct is a simple wrapper around <a href="https://doc.rust-lang.org/std/ptr/struct.NonNull.html"><code>std::ptr::NonNull</code></a>, which itself is a zero-cost wrapper around raw pointers that additionally ensures that the stored pointer is never <code data-enlighter-language="raw">NULL</code> and allows additional optimizations to take place based on that.</p>
<p>In other words: the Rust struct is just a raw pointer but with additional safety guarantees.</p>
<pre data-enlighter-language="rust">impl EbuR128 {
    pub fn new(channels: u32, samplerate: u32, mode: Mode) -&gt; Result&lt;Self, Error&gt; {
        static ONCE: std::sync::Once = std::sync::Once::new();

        ONCE.call_once(|| unsafe { ffi::ebur128_libinit() });

        unsafe {
            let ptr = ffi::ebur128_init(channels, samplerate as _, mode.bits() as i32);
            let ptr = ptr::NonNull::new(ptr).ok_or(Error::NoMem)?;
            Ok(EbuR128(ptr))
        }
    }
}
</pre>
<p>The constructor is slightly more complicated as it also has to ensure that the one-time initialization function is called, once. This requires using <a href="https://doc.rust-lang.org/std/sync/struct.Once.html"><code>std::sync::Once</code></a> as above.</p>
<p>After that it calls the C constructor with the given parameters. This can return <code data-enlighter-language="raw">NULL</code> in various cases when not enough memory could be allocated as described in the documentation of the C library. This needs to be handled gracefully here and instead of panicking an error is returned to the caller. <code data-enlighter-language="raw">ptr::NonNull::new()</code> is returning an <a href="https://doc.rust-lang.org/std/option/enum.Option.html"><code>Option</code></a> and if <code data-enlighter-language="raw">NULL</code> is passed it would return <code>None</code>. If this happens it is transformed into an error together with an early return via the <code data-enlighter-language="raw">?</code> operator.</p>
<p>In the end the pointer then only has to be wrapped in the struct and be returned.</p>
<pre data-enlighter-language="rust">impl Drop for EbuR128 {
    fn drop(&amp;mut self) {
        unsafe {
            let mut state = self.0.as_ptr();
            ffi::ebur128_destroy(&amp;mut state);
        }
    }
}
</pre>
<p>The <a href="https://doc.rust-lang.org/std/ops/trait.Drop.html"><code>Drop</code></a> trait is used for defining what should happen if a value of the struct goes out of scope and what should be done to clean up after it. In this case this means calling the destroy function of the C library. It takes a pointer to a pointer to its state, which is then set to <code>NULL</code>. As such it is necessary to store the raw pointer in a local variable and pass a mutable reference to it. Otherwise the <code data-enlighter-language="raw">ptr::NonNull</code> would end up with a <code data-enlighter-language="raw">NULL</code> pointer inside it, which would result in undefined behaviour.</p>
<p>The last function that I want to mention here is the one that takes a slice of audio samples for processing</p>
<pre data-enlighter-language="rust">    pub fn add_frames_i32(&amp;mut self, frames: &amp;[i32]) -&gt; Result&lt;(), Error&gt; {
        unsafe {
            if frames.len() % self.0.as_ref().channels != 0 {
                return Err(Error::NoMem);
            }

            let res = ffi::ebur128_add_frames_int(
                self.0.as_ptr(),
                frames.as_ptr(),
                frames.len() / self.0.as_ref().channels,
            );
            Error::from_ffi(res as ffi::error, || ())
        }
    }
</pre>
<p>Apart from calling the C function it is again necessary to check various pre-conditions before doing so. The C function will cause out of bounds reads if passed a slice that doesn’t contain a sample for each channel, so this must be checked beforehand or otherwise the caller (safe Rust code!) could cause out of bounds memory accesses.</p>
<p>In the end after calling the function its return value is converted into a <code>Result</code>, converting any errors into the crate’s own <code data-enlighter-language="raw">Error</code> enum.</p>
<p>As can be seen here, writing safe Rust bindings around the C API requires reading of the documentation of the C code and keeping all the safety guarantees of Rust in mind to ensure that it is impossible to violate those safety guarantees, no matter what the …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://coaxion.net/blog/2020/09/porting-ebu-r128-audio-loudness-analysis-from-c-to-rust-porting-details/">https://coaxion.net/blog/2020/09/porting-ebu-r128-audio-loudness-analysis-from-c-to-rust-porting-details/</a></em></p>]]>
            </description>
            <link>https://coaxion.net/blog/2020/09/porting-ebu-r128-audio-loudness-analysis-from-c-to-rust-porting-details/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660868</guid>
            <pubDate>Fri, 02 Oct 2020 09:57:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Node.js malware caught posting IPs, username, and device info on GitHub]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24660810">thread link</a>) | @axsharma
<br/>
October 2, 2020 | https://securityreport.com/nodejs-malware-caught-exfiltrating-ips-username-and-device-information-on-github/ | <a href="https://web.archive.org/web/*/https://securityreport.com/nodejs-malware-caught-exfiltrating-ips-username-and-device-information-on-github/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                                    <!-- .entry-header -->

                
                        <div>
                                    <p><img width="1024" height="683" src="https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-1024x683.jpg" alt="red and blue hearts illustration" loading="lazy" srcset="https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-1024x683.jpg 1024w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-300x200.jpg 300w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-768x512.jpg 768w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-1536x1024.jpg 1536w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-2048x1365.jpg 2048w" sizes="(max-width: 1024px) 100vw, 1024px" data-srcset="https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-1024x683.jpg 1024w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-300x200.jpg 300w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-768x512.jpg 768w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-1536x1024.jpg 1536w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-2048x1365.jpg 2048w" data-src="https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-1024x683.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">                </p>
            
                                            </div>

            

        <!-- end slider-section -->
                                    

    <div>
        <div>
            




<p>Multiple NodeJS packages laden with malicious code have been spotted on npm registry.</p>



<p>These “typosquatting” packages served no purpose other than collecting data from the user’s device and broadcasting it on public GitHub pages.</p>



<p>The findings were spotted by Sonatype’s <a href="https://blog.sonatype.com/sonatype-spots-malicious-npm-packages" target="_blank" rel="noreferrer noopener">automated malware detection systems</a> and further investigated by the company’s Security Research team which includes me. </p>



<p>The packages previously present on the open source npm registry included:</p>



<ol><li><a rel="noreferrer noopener" href="https://www.npmjs.com/package/electorn" target="_blank">electorn</a> (intentional misspelling of a legitimate package “electron”)</li><li><a rel="noreferrer noopener" href="https://www.npmjs.com/package/loadyaml" target="_blank">loadyaml</a> </li><li>loadyml</li><li>lodashs (intentional misspelling of a legitimate package “lodash”)</li></ol>



<p>All four packages were published by the same user “simplelive12” and have now been removed, with the first two having been taken down by npm as of October 1, 2020. The previous two packages were unpublished by the author themselves.</p>



<p>Once installed, <code>electorn</code> ran a script in the background <strong>every</strong> <strong>hour</strong> which collected the logged-in user’s IP, geolocation data, username, path to home directory, and CPU model information.</p>



<figure><img loading="lazy" width="1024" height="356" src="https://securityreport.com/wp-content/uploads/2020/10/image-1-1024x356.png" alt="" srcset="https://securityreport.com/wp-content/uploads/2020/10/image-1-1024x356.png 1024w, https://securityreport.com/wp-content/uploads/2020/10/image-1-300x104.png 300w, https://securityreport.com/wp-content/uploads/2020/10/image-1-768x267.png 768w, https://securityreport.com/wp-content/uploads/2020/10/image-1-1536x534.png 1536w, https://securityreport.com/wp-content/uploads/2020/10/image-1-2048x712.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px" data-srcset="https://securityreport.com/wp-content/uploads/2020/10/image-1-1024x356.png 1024w, https://securityreport.com/wp-content/uploads/2020/10/image-1-300x104.png 300w, https://securityreport.com/wp-content/uploads/2020/10/image-1-768x267.png 768w, https://securityreport.com/wp-content/uploads/2020/10/image-1-1536x534.png 1536w, https://securityreport.com/wp-content/uploads/2020/10/image-1-2048x712.png 2048w" data-src="https://securityreport.com/wp-content/uploads/2020/10/image-1-1024x356.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption>The malicious code within <code>electorn</code> and 3 other identical packages which exfiltrated user information</figcaption></figure>



<p>This information, part of which constitutes the device “fingerprint” was uploaded and published on <a rel="noreferrer noopener" href="http://web.archive.org/web/20201001065601/https://github.com/h4ppyl1ve/collect/issues/4" target="_blank">GitHub</a> in real-time.</p>



<p>Some of the information being published is base64-encoded but this can be trivially decoded by anyone who has access to it:</p>



<figure><img loading="lazy" width="1024" height="488" src="https://securityreport.com/wp-content/uploads/2020/10/image-1024x488.png" alt="" srcset="https://securityreport.com/wp-content/uploads/2020/10/image-1024x488.png 1024w, https://securityreport.com/wp-content/uploads/2020/10/image-300x143.png 300w, https://securityreport.com/wp-content/uploads/2020/10/image-768x366.png 768w, https://securityreport.com/wp-content/uploads/2020/10/image-1536x732.png 1536w, https://securityreport.com/wp-content/uploads/2020/10/image.png 1632w" sizes="(max-width: 1024px) 100vw, 1024px" data-srcset="https://securityreport.com/wp-content/uploads/2020/10/image-1024x488.png 1024w, https://securityreport.com/wp-content/uploads/2020/10/image-300x143.png 300w, https://securityreport.com/wp-content/uploads/2020/10/image-768x366.png 768w, https://securityreport.com/wp-content/uploads/2020/10/image-1536x732.png 1536w, https://securityreport.com/wp-content/uploads/2020/10/image.png 1632w" data-src="https://securityreport.com/wp-content/uploads/2020/10/image-1024x488.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure>



<p>Sonatype’s Security Research team has accounted for these malicious packages into their products, and had notified both npm and GitHub teams of the malicious activity stemming from the components. This led to the takedown of these malicious packages. </p>



<p>To this date, all 4 packages have scored a little over <strong>400</strong> total downloads.</p>



<p>It is not exactly clear what was the purpose of collecting this data and why was it being published on the web for the world to see, however, incidents like these highlight the potential of typosquatting attacks on the open-source ecosystem.</p>



<p>We can only imagine what the next possible version of these packages could have been capable of – possibly carrying out even more sinister activities. </p>



<p>By tricking an unsuspecting developer into mistakenly installing a misspelled package, attackers can push their malicious code “downstream” into any other open-source projects that use the misspelled malicious component as a transitive dependency.</p>



<p>Adopting DevSecOps best practices and building security early on into your software development lifecycle can prevent “counterfeit components” such as electorn and loadyaml from entering, and thriving in your software supply chains.</p>



<p>The complete research findings are available on the <a href="https://blog.sonatype.com/sonatype-spots-malicious-npm-packages" target="_blank" rel="noreferrer noopener">Sonatype blog</a>.</p>
                <div>
                    <h3>About the author</h3>
                                        
        <div>

                <p><a href="https://securityreport.com/author/ax-sharma/"><img alt="" src="https://secure.gravatar.com/avatar/d0d95768ca47b1764f5fb964cf860afa?s=150&amp;d=retro&amp;r=pg" srcset="https://secure.gravatar.com/avatar/d0d95768ca47b1764f5fb964cf860afa?s=300&amp;d=retro&amp;r=pg 2x" height="150" width="150" loading="lazy" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></a>
                </p>
                <div>
                    <h4>
                        <a href="https://securityreport.com/author/ax-sharma/">Ax Sharma</a>
                    </h4>

                    
                    
                                            <p>
                        <a href="https://axsharma.com/" target="_blank">https://axsharma.com/</a>
                        </p>
                                        <div>
                        <p>Ax Sharma is a Security Researcher, Engineer, and Tech Columnist. His works and expert analyses have frequently been featured by leading media outlets like Fortune, The Register, TechRepublic, CIO, etc.</p>
<p>Ax’s expertise lies in vulnerability research, reverse engineering, software development, and web app security. He’s an active community member of the OWASP Foundation and the British Association of Journalists (BAJ).</p>
<p>Send any tips via email or Twitter DM.</p>
                    </div>
                    
                                    </div>
        </div>

                                            </div>
                                            
                        
	<nav role="navigation" aria-label="Continue Reading">
		<h2>Continue Reading</h2>
		
	</nav>                    </div><!-- .entry-content -->
    </div>
                        </div></div>]]>
            </description>
            <link>https://securityreport.com/nodejs-malware-caught-exfiltrating-ips-username-and-device-information-on-github/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660810</guid>
            <pubDate>Fri, 02 Oct 2020 09:47:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bloom Filter Calculator]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24660716">thread link</a>) | @nreece
<br/>
October 2, 2020 | https://hur.st/bloomfilter/ | <a href="https://web.archive.org/web/*/https://hur.st/bloomfilter/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="CalculatorForm" method="get" action="/bloomfilter/">
				<fieldset><legend></legend>
					<section>
						<p><a href="http://en.wikipedia.org/wiki/Bloom_filter">Bloom filters</a> are
						space-efficient probablistic data structures used to test whether an element
						is a member of a set.</p>

						<p>They're surprisingly simple: take an array of <strong>m</strong>
						bits, and for up to <strong>n</strong> different elements, either test or set
						<strong>k</strong> bits using positions chosen using hash functions. If all
						bits are set, the element <em>probably</em> already exists, with a false positive
						rate of <strong>p</strong>; if any of the bits are not set, the element
						<em>certainly</em> does not exist.</p>

						<p>Bloom filters find a wide range of uses, including tracking which
						<a href="https://blog.medium.com/what-are-bloom-filters-1ec2a50c68ff">articles you've read</a>,
						<a href="https://bitcoin.org/en/developer-guide#application-of-bloom-filters">speeding up Bitcoin clients</a>,
						<a href="http://blog.alexyakunin.com/2010/03/nice-bloom-filter-application.html">detecting malicious web sites</a>,
						and <a href="https://en.wikipedia.org/wiki/Bloom_filter#Cache_filtering">improving the performance of caches</a>.</p>

						<p>This page will help you choose an optimal size for your filter, or explore
						how the different parameters interact.</p>
					</section>

					<hr>

					<dl>
						<dt>n</dt>
						<dd><label><strong>N</strong>umber of items in the filter (optionally with <a href="https://en.wikipedia.org/wiki/Metric_prefix#List_of_SI_prefixes">SI units</a>: k, M, G, T, P, E, Z, Y)<br>
							</label>
						</dd>
						<dt>p</dt>
						<dd><label><strong>P</strong>robability of false positives, fraction between 0 and 1 or a number indicating 1-in-p<br>
							</label>
						</dd>
						<dt>m</dt>
						<dd><label>Nu<strong>m</strong>ber of bits in the filter (or a size with KB, KiB, MB, Mb, GiB, etc)<br>
							</label>
						</dd>
						<dt>k</dt>
						<dd><label>Number of hash fun<strong title="close enough">c</strong>tions<br>
							</label>
							
							<em id="WarningText"></em>
						</dd>
					</dl>

					<p id="ResultText">
						<code>n = </code>4,<wbr>000<br>
<strong><code>p = </code>1.0E-7 (1 in 9,<wbr>994,<wbr>297)</strong><br>
<strong><code>m = </code>134,<wbr>191 (16.38KiB)</strong><br>
<strong><code>k = </code>23</strong>					</p>

					
				</fieldset>
			</div></div>]]>
            </description>
            <link>https://hur.st/bloomfilter/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660716</guid>
            <pubDate>Fri, 02 Oct 2020 09:28:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Please Stop Imposing American Views about Race on Us]]>
            </title>
            <description>
<![CDATA[
Score 297 | Comments 214 (<a href="https://news.ycombinator.com/item?id=24660682">thread link</a>) | @dgellow
<br/>
October 2, 2020 | https://www.persuasion.community/p/please-stop-imposing-american-views | <a href="https://web.archive.org/web/*/https://www.persuasion.community/p/please-stop-imposing-american-views">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3a4a8fb-963e-4611-8bc2-448a875dfb14_5184x3456.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3a4a8fb-963e-4611-8bc2-448a875dfb14_5184x3456.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/e3a4a8fb-963e-4611-8bc2-448a875dfb14_5184x3456.jpeg&quot;,&quot;height&quot;:971,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:18107111,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></p><p><em>Construction workers reopen Winston Churchill statue in Parliament Square after it was covered with metal panels to protect it against defacement by protestors.</em></p><p>Over the past couple of months, many Britons have imported American discourse on race wholesale. When asked to analyze the experiences of black people in the United Kingdom, we now talk with an American accent.</p><p>Take a look, for instance, at a meme that has been circulating among some of my white friends on Facebook and Instagram:</p><blockquote><p>I have privilege as a White person because I can do all of these things without thinking twice about it … I can go jogging (#AmaudArbery). I can relax in the comfort of my own home (#BothemSean and #AtatianaJefferson). I can ask for help after being in a car crash (#Jonathan Ferrell and #RenishaMcBride). I can have a cellphone (#StephonClark). I can leave a party to get to safety (#JordanEdwards). I can play loud music (#JordanDavis). I can sell CDs (#AltonSterling). I can sleep (#AiyanaJones). I can walk from the corner store (#MikeBrown).</p></blockquote><p>The post goes on and on, like an interminable spoken-word poem. All the individuals listed are American, but most of the people who have shared this on my timeline are British. In trying to express their solidarity with black Britons, they are affirming a supposedly transcendental truth: to be black is to live in perpetual terror of being murdered by the state. </p><p>But Britain is not America. And importing American race discourse into the United Kingdom not only prevents us from recognizing the specific ways in which racial injustice manifests in this country—it cloaks the reality of black British lives behind an abstraction that flattens our humanity. </p><p>Britain has a long and painful history of anti-black racism. In the twentieth century alone, the growing black presence led to a long catalogue of abuses: the 1919 race riots in Liverpool, Cardiff and London; the 1958 race riots in Nottingham and Notting Hill; the 1969 police murder of David Oluwale, a Nigerian immigrant who was tortured, pissed on and finally drowned in a river in Leeds. I could list other examples. It is not hard to see why the horrific killing of George Floyd has evoked such strong feelings in this country as well.</p><p>But for all of the country’s flaws, Britain is not America. Trying to understand its racial dynamics through the lens of another country’s does more to obscure than to illuminate the situation that black Britons like myself actually face.</p><p>The average black American in the United States can trace his ancestry further back than the average white American. Most black Americans are descended from enslaved Africans. Their forebears suffered through the segregation and racial terror of the Jim Crow era. The majority of black people in the United Kingdom, by contrast, are immigrants or the children of immigrants. Though many of them have certainly had harrowing experiences with injustice or discrimination, they do not have the same history of racist disadvantage.</p><p>To understand the experience of black Britons, it is not only necessary to grasp how different their history is from that of black Americans: we need to understand the diversity captured by the label “black British.” For example, around two out of every three students with Congolese or Somali origins get free school meals, a standard indicator that their parents are poor. Among students with Nigerian or Ghanaian origins, only one in five do. It is also noteworthy that black Caribbean students are twice as likely to be excluded from school as black African students. </p><p>The discrepancy in educational attainment is just as stark. On average, 58% of black African students graduate from middle school at grade level (defined as achieving A* to C grades at GCSE)—about the same number as white students. But black Caribbean students are significantly less likely to do so—while those whose parents hail from Nigeria actually outperform their white peers by a considerable margin. </p><p>None of this is to disavow the label “black British.” But we need to invest it with the nuance consonant with its reality—and to cast doubt on the idea that every discrepancy in representation must be explained by structural injustice or white supremacy.</p><p>There has, for example, been a lot of concern about the underrepresentation of black Britons in professions like the arts and publishing. But why would you choose to go into theater or journalism—rather than law, medicine or finance—if you are a talented child of ambitious but not well off immigrants? </p><p>This is not a flippant question. While representation can be important, anybody who actually wants to improve the condition of black Britons should at least be a little curious about why they are overrepresented in some prestigious professions and underrepresented in others. In a country in which black people make up only three percent of the population, for example, six percent of junior doctors are black. Would the country—or the black community—really benefit if more black Britons chose to ditch medicine for the theater? The debate is worth having. But in the place of that debate, there have only been pious paeans to diversity.</p><p>The stereotype of the West African parent who wants their child to study law or medicine bears some relation to reality; but the widespread view of black people as perennial victims devoid of agency is a defamatory abstraction. The black person in Britain, like Ralph Ellison’s iconic protagonist, is “invisible because no one wants to see him.”</p><p>So much of the British reaction to the death of George Floyd has constituted a failure of nerve. Desperately seeking to assuage their feelings of guilt, to do <em>something</em>, many Britons have sacrificed their critical faculties to a narrative that does not actually help black people—a narrative that, by reducing us to passive abstractions, only makes us more invisible.</p><p>Racists assume that black people are all the same. Ironically, anti-racists sometimes do so too. But anybody who is truly committed to racial equality needs to recognize that this kind of simplification neither serves justice nor reflects the truth.</p><p><strong>Tomiwa Owolade is a writer who lives in London.</strong></p></div></div>]]>
            </description>
            <link>https://www.persuasion.community/p/please-stop-imposing-american-views</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660682</guid>
            <pubDate>Fri, 02 Oct 2020 09:20:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quick Test to Figure Out Why You Feel Down Lately]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24660666">thread link</a>) | @azarai
<br/>
October 2, 2020 | https://mindfuldevmag.com/issues/issue-8-readers-questions/felling-down-figure-out-why-test | <a href="https://web.archive.org/web/*/https://mindfuldevmag.com/issues/issue-8-readers-questions/felling-down-figure-out-why-test">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                            <div>
                                                                            
                                                                         <p>Feeling down lately?</p>
<p>But you don’t know why?</p>
<p>This quick test helps you to figure it out and gives you tips on getting up again.</p>
<h2>Quick Test</h2>
<blockquote>
<p>Did you sleep 7-8 hours a night for most of the last 7 days?</p>
</blockquote>
<p>Sleep is essential, and we should not skip on that. While we sleep, our brain processes the day and also cleans itself of toxic waste (<a href="https://www.scientificamerican.com/article/deep-sleep-gives-your-brain-a-deep-clean1/#:~:text=Why%20sleep%20has%20restorative%E2%80%94or,is%20hugely%20improved%20during%20sleep.">see</a>)</p>
<blockquote>
<p>Did you drink less than 10 drinks of alcohol in the last 7 days?</p>
</blockquote>
<p>There is nothing to say against a drink or two. But if you take it too far, you start to feel down, groggy and more. Moreover, alcohol can be addictive, and you don’t want to become an alcoholic.</p>
<blockquote>
<p>Did you drink too much caffeine in the last 7 days? (Coffee, black tea, energy drinks, etc.)</p>
</blockquote>
<p>Caffeine is a short energy booster, but it comes with downsides too. It blocks the body’s desire to rest for a short time, but then your body is twice as tired, wanting to rest.</p>
<p>Now, if you drink caffeine again, you start a vicious cycle. You’ll only feel productive when you got your dose of caffeine. Otherwise, you feel tired again.</p>
<p>Over time you need to consume more and more caffeine to even get the effect.</p>
<p>Rest. Your body needs rest, and you should give it.</p>
<blockquote>
<p>Do you think you’re eating healthy in the last 7 days?</p>
</blockquote>
<p>Your body needs proper nutrition to function.</p>
<p>A diet of chips, chocolate bars, ice cream, or fast food is not the right thing to fuel your body the energy it needs.</p>
<p>Once in a while, it is fine but don’t thrive on it.</p>
<blockquote>
<p>Have you gone outside in the last 7 days?</p>
</blockquote>
<p>Pandemic here, pandemic there. But even without it, many of us don’t go outside enough—especially people working from home.</p>
<p>But we need movement and fresh air. So, enjoy a long walk in nature, or a park or forest near you. Or just stroll through your city.</p>
<blockquote>
<p>Have you exercised in the last 7 days?</p>
</blockquote>
<p>Move your ass. Doesn’t matter what kind of exercise you like, do it. Movement is king.</p>
<p>Not only will it lift your mood. It will also help you to think fresh and clear again.</p>
<blockquote>
<p>Have you meditated in the last 7 days? Or journaled, etc.</p>
</blockquote>
<p>Meditation is a great tool to clear your thoughts and calming down. But you don’t need to sit still.</p>
<p>You can do <a href="https://mindfuldevmag.com/issues/issue-3-mindfulness-for-skeptics/walking-meditation">walking meditations</a> or journaling or other kinds of activities that help you to focus and clear your mind.</p>
<blockquote>
<p>Have you done anything to actively relax?</p>
</blockquote>
<p>This can be taking massages, doing yoga, taking a hot bath, sauna, or anything else that helps you relax.</p>
<p>Take your time and do it on purpose.</p>
<p>Btw watching tv might feel like relaxation, but it mostly is not. Our brain’s on alert mode.</p>
<p>Can’t decide on one?</p>
<p>Go for a walk in the next park.</p>
<blockquote>
<p>Have you talked to other people or met with your friends? Preferably IRL</p>
</blockquote>
<p>Even the most introverted of us love to talk to somebody. Sure, I can go without days of talking to somebody except my family. But even that has its limit.</p>
<p>Talk or, better yet, meet your friends, and have a great time. None handy at the moment? Talk to your neighbor, cashiers, or anybody else you can have interactions with.</p>
<blockquote>
<p>If you’re in a relationship, are you with the right person?</p>
</blockquote>
<p>If your relationship sucks, your mood will drop too. But if it is a loveable and stable one, it can lift you up and help through darker times.</p>
<blockquote>
<p>Have you helped someone in the last days with something you’re good at?</p>
</blockquote>
<p>Believe it or not. It’s humans to help others and feel good about it at the same time. It’s totally refreshing and re-energizing.</p>
<blockquote>
<p>Have you made any new experiences in the last month?</p>
</blockquote>
<p>Doing the same old from day to day, week to week, and month to month can drag you down. It feels like a rut. Being stuck.</p>
<p>Energize your life and go for new experiences. Go for a hike, visit a new city, test a new restaurant. Whatever it is, pick something new.</p>
<blockquote>
<p>Are you working on stuff that’s meaningful to you?</p>
</blockquote>
<p>Does your job or the things you work on in your spare time give you enough meaning? Or does it feel like working for the devil?</p>
<p>Does it fulfill you?</p>
<blockquote>
<p>Does your current situation allow you to do what you really want to do in life?</p>
</blockquote>
<p>If not, think about what you could start to change? What are thing top 3 things holding you back?</p>
<p>How could you remove them?</p>
<blockquote>
<p>Did you create anything in the last week?</p>
</blockquote>
<p>Does not matter what it is. Maybe you draw comics or paint art, make music, build websites, or whatever.</p>
<p>Let your creativity go wild, and your mood will go up.</p>
<blockquote>
<p>Are your working on too many things at the same time?</p>
</blockquote>
<p>Pursuing multiple things at the same time makes you feel like nothing moves forward. Often paired with getting frustrated and then feeling down.</p>
<p>Set your focus on one thing for now and work on that. The down feelings will fade.</p>
<blockquote>
<p>Do you have the feeling that you accomplished something?</p>
</blockquote>
<p>Sometimes we hustle and hustle but have the feeling we got nowhere. Just being tired and running towards a burnout.</p>
<p>Think about what small things you could add that make you feel to have accomplished something? Must not be work-related. It could also be private things you pushed for years in front of you.</p>
<h2>All Positive But Still Feeling Down?</h2>
<p>If you answered all questions positively and are still feeling down, it might be time to visit a therapist. There is no shame in that. We all need help sometimes.</p>
<p>Find someone near you or use an online service like <a href="https://www.talkspace.com/">talkspace</a>.</p>
                                     
                                     <hr>
                                     
                                                                          
                                     
                                       
                                       
                            </div>

                    </div></div>]]>
            </description>
            <link>https://mindfuldevmag.com/issues/issue-8-readers-questions/felling-down-figure-out-why-test</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660666</guid>
            <pubDate>Fri, 02 Oct 2020 09:17:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I built a lay-down desk]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24660610">thread link</a>) | @polote
<br/>
October 2, 2020 | https://blog.luap.info/i-built-a-lay-down-desk.html | <a href="https://web.archive.org/web/*/https://blog.luap.info/i-built-a-lay-down-desk.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		  <div role="main">
	<article>

		


		<p>After spending part of the last 12 months <a href="https://blog.luap.info/travelling-with-24-monitors.html">travelling in Europe</a> I'm now settling down around Paris and I need to adapt my multi-screens setup.</p>
<p>You probably have seen an ads for <a href="https://altwork.com/">the altwork desk</a> <em>a $7000 desk that let you work laying down</em>. Spending a big part of my day in front of a computer I want to have the most comfortable position as possible, but well $7000 + $1000 for the delivery seems so expensive. There is also <a href="http://www.ergoquest.com/">this company</a> but this is still about $4000 all included. Let's be creative and build it myself.</p>
<p>Here is the result</p>
<p><img alt="complete desk" src="https://blog.luap.info/static/desk/complete.jpg"> </p>
<p>The things I have to take into account are:</p>
<ul>
<li>
<p>I have three monitors</p>
</li>
<li>
<p>I have no diy tools</p>
</li>
<li>
<p>I want a laying down position</p>
</li>
<li>
<p>This should be easy to use</p>
</li>
<li>
<p>This should be light and not take too much space</p>
</li>
<li>
<p>I have only a bike to move the parts</p>
</li>
<li>
<p>I haven't found anyone who has done something similar and so don't really have examples</p>
</li>
</ul>
<p>So instead of doing the waterfall way I decided to go the agile way and to not do any plans, I didn't know what to expect, so let's do it step by step and see how it goes</p>
<h2>Take care of the chair</h2>
<p>There are several options:</p>
<ol>
<li>
<p>Built a chair from scratch including the 'mattress' part</p>
</li>
<li>
<p>Use a reclined chair</p>
</li>
<li>
<p>Adapt a chair</p>
</li>
</ol>
<p>The issue with the first option is that I will not be sure of the result, is it going to be comfortable ? How I'm going to wash the seat covers ? I have no idea of the things to take into account for building a comfortable chair.</p>
<p>Reclined chairs are great but they are very heavy (except the garden ones but not very comfortable) and expensive. So again let's be creative, I got inspired by <a href="https://www.ikeahackers.net/2017/04/poang-gravity-recliner.html">this</a> and <a href="https://www.ikeahackers.net/2020/04/remove-poang-arms.html">this</a> ikea hacks which use a IKEA POANG chair and transform it into a reclined chair.</p>
<p>Here is the result :</p>
<p><img alt="ikea poang adaptation" src="https://blog.luap.info/static/desk/chair.jpg"></p>
<p>The chair is 69 euro, I had to buy three cushion to extend it</p>
<p>The most complex part was to do 7km with the chair on a bike. I do not recommend doing the same, particularly because I have done it on a rainy day but well a bit of challenge in my life is always welcome!</p>
<p><img alt="ikea bike" src="https://blog.luap.info/static/desk/ikea_bike.jpg"></p>
<p>Great, the chair is comfortable, let's do something for the desk part.</p>
<h2>What structure for the desk</h2>
<p>The biggest issue you are going to have with the lay down position, is that the desk is going to be on your legs and you cant 'enter' or 'leave' the desk if you can't move the desk. So you need the 'desk' part to be dynamic from the 'chair' part.</p>
<p>I had two ideas for that, either the Altwork way, the structure goes above your head and can incline, or the the base is on the side and the desk can move somewhere (writing that, having the desk in front of me, I wonder if having the base where the foot are is not an even better solution ? Damn, too late). Having the base on the side seems better because it would be smaller and lighter and also you can balance the weight much better. But the structure also needs to be more rigid and I need to find a way to incline the desk, anyway I haven't found a way to do it :(, after a night of thinking I went the altwork way.</p>
<p>There are two parts to design:</p>
<ol>
<li>
<p>The base + the incline system</p>
</li>
<li>
<p>The desk + the screen supports</p>
</li>
</ol>
<h3>1. Base + incline system</h3>
<p>The base is pretty standard, you need something strong enough so that it can suppot the whole thing. At that point I still didn't know the weight of the complete platform so I didn't know how strong it should be. After a few failing choices, I ended up with a main pole of 7cm x 7cm.</p>
<p>Now the complex part, how to design the rotation part ? How heavy is going to be the rest of desk ? How much does the desk need to move so that I can 'enter' the desk ? So many questions I didnt have an answer for.</p>
<p>So let's try something and see how it goes, I bought an <a href="https://www.amazon.fr/gp/product/B00H8SZ87W">gaz actuator on Amazon</a> which can support 70kg with a range of 31cm, it is built for cars and pretty cheap, 19euro. Actually 70kg is a lot. So at least I have a some freedom on the weight of the structure.</p>
<p>I had two issues with the actuator:</p>
<ul>
<li>70kg IS A LOT, it is so much that when I was fixing it on the wood of the base, it was breaking the wood. The best would be to have an iron piece that I can fix to the wood but I didnt have the tools for that so I used stronger woods but this is still fragile. </li>
</ul>
<p><img alt="fixation verrin" src="https://blog.luap.info/static/desk/fixation_verrin.jpg"></p>
<ul>
<li>The desk follows a circular trajectory when you move it up and down. As a result the barycenter of the structure changes depending on the Y position of the 'desk part' and so there is more strength applied on the actuator when it is up than when it is down. So basically the desk will not stay by itself when in the up position.  I need to find a way to get the desk in the up position.</li>
</ul>
<p>I'm not really proud of the way I've done it, but it somewhat works. I've built a piece of wood that inserts itself in the area between the two poles where the actuator is. There is a counterweight which drags the piece into the zone when in up position, and when I want to release it, I just need to pull on the rope. (I think I will replace the actuator with a real electric actuator when the current system breaks so that I can control the movement, it is about 120euro)</p>
<p><img alt="system block" src="https://blog.luap.info/static/desk/blocking_system.jpg"></p>
<h3>2. Desk + screens support</h3>
<p>I bought a chipboard plate of 80cm x 120cm, and cut some space for my body</p>
<p><img alt="plaque bois" src="https://blog.luap.info/static/desk/agglo.jpg"> </p>
<p>This is pretty solid, so I can directly screw this plate to the pole and we have a desk surface</p>
<p><img alt="plaque bureau" src="https://blog.luap.info/static/desk/bureau_with_plaque.jpg"></p>
<p>For holding the monitors I did something pretty basic, I created a box for each screen. Then comes the position of the screen, how to know the position of each screen ? I didnt know how to know it beforehand, so I just created dynamic arms and adjusted them while in front of the screens</p>
<p><img alt="support monitor" src="https://blog.luap.info/static/desk/support_monitor.jpg"></p>
<h2>Next steps</h2>
<p>This is only a few days old so I can't really make a feedback but there are already a few things that I need to fix</p>
<ul>
<li>
<p>I can't use a mouse anymore, as the mouse would fall down, I'm probably going to replace it by a trackball</p>
</li>
<li>
<p>I need to invest in an ergonomic keyboard to get really comfortable, probably going to buy the kenesis advantage 2, but this is expensive !</p>
</li>
</ul>
<p>Here is a video of the complete desk:</p>
<video controls="">
  <source src="https://blog.luap.info/static/desk/video.mp4" type="video/mp4">
</video>

<h2>Conclusion</h2>
<p>When you want to build this kind of structure, I'm not sure you can plan everything beforehand, there are always things that will happen that you didn't expect, like when you code: if you want to modify the actuator when the 60kg setup is mounted how do you do ? (I have done it 6 times) When your base can't support the weight because it lacks one screw and you need to unmount everything what do you do ? ...</p>
<p>I'm really annoyed by the actuator part, I hope I will find something more reliable</p>
<p>Overall it cost me :</p>
<ul>
<li>
<p>45 euro for tools</p>
</li>
<li>
<p>130 euro for wood pieces, screws, joins, ...</p>
</li>
<li>
<p>110 euro for the IKEA chair + cushions</p>
</li>
</ul>
<p>and I spent 26 hours working, excluding the transport and the time shopping for pieces</p>
<p>Don't forget when you do woodworking to clean afterwards  :)</p>
<p><img alt="dirty" src="https://blog.luap.info/static/desk/dirty_floor.jpg"></p>
<p>If you have done something similar and know a few advice, please send me an email</p>
<p>PS: If you wonder whether you can do that or not, everyone can do it, basic woodworking is not complex, you need to know how to cut wood, how to join wood, how to screw and a little bit of imagination, you dont even need a car to transport parts, I transported everything: pole of 2m40, big plate ... on a bike</p>	

	</article>


		  </div>	

		  

	  </div></div>]]>
            </description>
            <link>https://blog.luap.info/i-built-a-lay-down-desk.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660610</guid>
            <pubDate>Fri, 02 Oct 2020 09:06:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[In Flancia there are no walled gardens]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24660583">thread link</a>) | @ColinWright
<br/>
October 2, 2020 | https://flancia.org/mine/flanbook/ | <a href="https://web.archive.org/web/*/https://flancia.org/mine/flanbook/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody text">
    <div>
<p>In Flancia the internet is truly open: they managed to get rid of <a href="https://en.wikipedia.org/wiki/Closed_platform">walled gardens</a>. How they did it is an interesting&nbsp;story.</p>
<h2>Status&nbsp;quo</h2>
<p>Let’s take just one example; it should suffice to represent the general approach they took. In Flancia they had a social network — well, they had many of course, same as we do, but one in particular had grown into dominance. People had sort of liked it at some point, then eventually didn’t anymore, but they were stuck with it by then; it had developed at just the right time in internet history, and it had done enough things right in the beginning to take over from contenders and really soar in&nbsp;usage. </p>
<p>As it often was the case in those days, this network was fully controlled by a single corporation, and although at the beginning there were some provisions in place that made it look like a relatively healthy platform eventually the company had chosen to consolidate their dominion; namely close down APIs and turn it into a walled garden. By then network effects had taken over and de facto locked people in, too: the company had gotten users to build up an expansive social graph for them and had succeeding in retaining control over it. They proceeded to use this virtual monopoly on many users’ social capital and attention to make billions selling ads — and gained the ability to significantly steer public opinion in the process, too. Many people recognized problems with this approach, but users at large mostly kept using it. It was that or being locked out of a significant portion of social activity online and&nbsp;offline. </p>
<h2>X marks the&nbsp;spot</h2>
<p>One of the obstacles that Flancians faced when trying to improve on this status quo was that there was no single clearly better platform of choice available; in areas where there were some alternatives there were often too many, so the competitive landscape was fragmented, and that played to the company’s advantage. The company also used their ad-fueled wealth to buy most promising contenders and offer them as relatively empty alternatives to their main network, while effectively gaining access to more social data and expanding their influence. After a while network effects and inertia were so strong that competitors all but stopped trying; social networks are known to be hard to decamp from, as most of their value is in the social graph that users build on them; and the oh-so-valuable graph was kept very deep within the company’s walled&nbsp;garden. </p>
<p>Flancians didn’t have much when facing this dire state of affairs, but they had one thing, and it was an important one: they had <a href="https://flancia.org/agora/">a machine for solving coordination problems</a>. So they used it. First they sketched out a declaration of intents flowing naturally from their publicly espoused&nbsp;values.</p>
<ul>
<li>Useful internet platforms should be&nbsp;open.</li>
<li><span>‘</span>Open’ means that no single monolithic entity can fully control them and that their inner workings are transparent to interested parties and appropriately&nbsp;malleable.</li>
<li><span>‘</span>Open’ is desirable because otherwise monolithic egotistical entities can gain control of the network and extort value out of its users, or mislead&nbsp;them.</li>
</ul>
<p>Then they proceeded to write a plan together. The first version was remarkably simple; a sketch to get the real discussion started. It said essentially as&nbsp;follows:</p>
<ul>
<li>For each useful internet platform X that is not&nbsp;open:</li>
<li>Let X’ be its open&nbsp;replica.</li>
<li>Write down a plan to reimplement its core functionality, F(X’) ≈&nbsp;F(X).</li>
<li>Write down a plan to reproduce its critical data set, D(X’) ≈&nbsp;D(X).</li>
<li>Add X’ to the <a href="https://anagora.org/wiki/Missing_Devices">Catalog of Missing Devices</a> in the Agora. This both marks it as a canonical replica of X and announces it as a priority for&nbsp;Flancians.</li>
</ul>
<p>Once this bootstrap process was complete, the standard Agora algorithms took over; Flancians would best-effort iterate, improving on plans and resource estimates and executing actions as available to them, until failure or&nbsp;convergence.</p>
<p>Social networks were useful internet platforms; the Agora, after all, was in many ways a social network (a focused, goal-oriented one). So Flancians set out to replicate the company’s social network. They named that particular X’ <em>Flanbook</em> — after <a href="https://en.wikipedia.org/wiki/The_Book_of_Sand">The Book of Sand</a>, of course. It was fitting because the task of replicating it seemed at that point in time infinite in&nbsp;scope.</p>
<h2>I(X’)</h2>
<p>Looking around, it turned out that Flancians were relatively lucky. Most of the tools and libraries needed to build an open replica of the social network were available off-the-shelf. From all its algorithms, its ranking algorithms were perhaps the most sophisticated; but Flancians intended to replace those anyways, thinking the community could do better, so that was not an issue. The road to I(X’) was not trivial by any means, but it wasn’t very interesting for the purpose of telling this particular&nbsp;story.</p>
<h2>D(X’)</h2>
<p>In the case of social networks, then, it followed that most of their value was in their data; and, from all their data, none was more valuable than their social graph. Here Flancians had an ideological advantage, albeit perhaps not strictly a legal one to begin with, as they were known to often burst into chant in unison in barely appropriate&nbsp;occasions:</p>
<p><em>This, which is our data,<br>
will always be our data.<br>
A Flancian and their data<br>
shall never come apart.</em><br></p>
<p>This somewhat awkward ritual came handy sometimes, though. Flancians strongly believed that any information they produced and maintained was theirs; they believed this almost as much as they believed in the Agora. To a Flancian, the idea of their part of the social graph (the piece they had contributed a node and edges to) being out of their reach, locked down somewhere deep in a walled garden, just didn’t make sense. They refused to take it. So they just agreed to take their data&nbsp;back.</p>
<p>To perform this kind of task in a scalable way, they built special devices called <em>syphons</em>. The simplest came in the form of browser extensions. Whenever a Flancian used a targeted service X, the syphon redirected relevant data in the background to the replica X’. This allowed building up D(X’) incrementally so it could eventually function as a drop-in replacement. Flancians agreed to use these devices any time they could in platforms being replicated, even when they were not otherwise directly involved in the replication&nbsp;project.</p>
<p>Now, Flancians are an altogether friendly group, and they have the added advantage of knowing how to use an Agora; but they still do sometimes come into disagreements. Here Flancians disagreed with each other in how to define <em>relevant</em> in the above paragraph. Some Flancians, believing closed platforms to be actively dangerous to society, took the position that <em>all</em> data could be considered relevant in the noble pursuit of replicating such platforms, and consequently took a relatively aggressive stance and built and used syphons that actively sought to crawl and extract the largest portion of D(X) possible as fast as possible, regardless of provenance of data. Other Flancians, mostly aligned with the Middle Way, built syphons that only extracted data that they could strongly claim to be <em>theirs</em> to begin with, according to a shared and public&nbsp;definition:</p>
<ul>
<li>If the user of the syphon added the node or edge, it is considered&nbsp;relevant.</li>
<li>If a non-Flancian added the node or edge, and they give explicit consent to extraction, it is&nbsp;relevant.</li>
<li>If a Flancian added the node or edge, it is relevant (Flancians consent by default to the rational constructive actions of other&nbsp;Flancians).</li>
</ul>
<p>The second approach introduced the additional problem of identifying users across platforms and tracking consent. The syphons offered cross-platform validation as a feature; otherwise it could be manually accomplished by cross-posting tokens and declarations of intent publicly in the relevant&nbsp;networks.</p>
<p>Once this system was in place, it would presumably make D(X’) converge into a usable&nbsp;dataset.</p>
<p>The company, of course, put up a battle. They correctly identified X’ as an existential risk, and sought to attack syphons and their users. This started an arms race. Both groups of Flancians were affected differently, with those subscribing to the Middle Way being on more solid legal footing. The fact that Flancians had enough resources and a platform to organize a united resistance (the Agora) helped them tremendously; also helpful was the fact that relatively small but dense parts of D(X’) were sufficient to bootstrap smaller social networks within the&nbsp;network.</p>
<p>It would be perhaps unwise of me to say at this point which group fared better in the end, and precisely when and how the first replication project was brought to effective completion. Suffice it to say that Flanbook was a success, at least for a while, and it remains somewhat popular among the more old school Flancians. I, myself, am more partial to&nbsp;Instaflan.</p>
</div>
    </div></div>]]>
            </description>
            <link>https://flancia.org/mine/flanbook/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660583</guid>
            <pubDate>Fri, 02 Oct 2020 08:59:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Chrome85 is stopping to send URL path as HTTP Referer field]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24660580">thread link</a>) | @yoshiokatsuneo
<br/>
October 2, 2020 | https://engineering.paiza.io/entry/referrer_policy | <a href="https://web.archive.org/web/*/https://engineering.paiza.io/entry/referrer_policy">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
        <div id="main-inner">
          


          
  
  <!-- google_ad_section_start -->
  <!-- rakuten_ad_target_begin -->
  
  
  

  

  
    
      
        <article id="entry-26006613635480643" data-keyword-campaign="" data-uuid="26006613635480643" data-publication-type="entry">
  <div>
    

    


    <div>
  
    <p><span itemscope="" itemtype="http://schema.org/Photograph"><img src="https://cdn-ak.f.st-hatena.com/images/fotolife/p/paiza/20201002/20201002144505.png" alt="f:id:paiza:20201002144505p:plain" title="f:id:paiza:20201002144505p:plain" itemprop="image"></span></p>

<div>
<p><small>(Japanese article is <a href="https://paiza.hatenablog.com/entry/2020/10/02/referrer_policy">here</a>)</small></p>
</div>


<p><span itemscope="" itemtype="http://schema.org/Photograph"><img src="https://cdn-ak.f.st-hatena.com/images/fotolife/p/paiza/20151217/20151217152725.jpg" alt="f:id:paiza:20151217152725j:plain" title="f:id:paiza:20151217152725j:plain" itemprop="image"></span>Hi, I'm Tsuneo([twitter:@yoshiokatsuneo]).</p>

<p>Now, the latest Chrome is stopping to send the URL path as HTTP Referer on cross-domain access.</p>

<p>If you analyze access to your web site, you can not know which article leads the user to your site.</p>

<h2>Beginning</h2>

<p>We have a blog as our own media to lead to our web service.
And, we are monitoring the reference URLs to our web service.</p>

<p>We happen to nice that the more and more reference is from the blog top page, and less and less reference from each article URLs.</p>

<h2>Chrome 85</h2>

<p>From our access logs, it looks like the change happens only on Chrome.</p>

<p>And, we noticed that the default "Referrer Policy" is changed from <strong>no-referrer-when-downgrade</strong> to <strong>strict-origin-when-cross-origin</strong> on Chrome85.</p>

<p>For example, the reference URL "<a href="https://paiza.hatenablog.com/entry/2020/10/01/140612">https://paiza.hatenablog.com/entry/2020/10/01/140612</a>" is stripped to "<a href="https://paiza.hatenablog.com/">https://paiza.hatenablog.com/</a>" .</p>

<p><cite><a href="https://www.chromestatus.com/feature/6251880185331712">www.chromestatus.com</a></cite></p>

<p>But, actually, when I test on Chrome85 my machine, the setting was  "no-referrer-when-downgrade", yet.
It looks that the setting is changing gradually.</p>

<h2>How to see the Referrer Policy</h2>

<p>We can see that what URL is sent as Referer on the cross-domain link.</p>

<p><a href="https://webdbg.com/test/refer/">https://webdbg.com/test/refer/</a></p>

<p>If the first green box has a URL with the path, your Chrome has "no-referrer-when-downgrade" as the Referrer Policy.</p>

<figure title="ãƒ‘ã‚¹å��ã�Œã�‚ã‚‹å&nbsp;´å�ˆ"><span itemscope="" itemtype="http://schema.org/Photograph"><img src="https://cdn-ak.f.st-hatena.com/images/fotolife/p/paiza/20201002/20201002143005.png" alt="f:id:paiza:20201002143005p:plain" title="f:id:paiza:20201002143005p:plain" itemprop="image"></span><figcaption>URL with path(no-referrer-when-downgrade)</figcaption></figure>

<p>If the first green box has a URL without the path like below, your Chrome has the new "strict-origin-when-cross-origin" settings like below.</p>

<figure title="ãƒ‘ã‚¹å��ã�Œã�ªã�„å&nbsp;´å�ˆ"><span itemscope="" itemtype="http://schema.org/Photograph"><img src="https://cdn-ak.f.st-hatena.com/images/fotolife/p/paiza/20201002/20201002142849.png" alt="f:id:paiza:20201002142849p:plain" title="f:id:paiza:20201002142849p:plain" itemprop="image"></span><figcaption>URL without path(strict-origin-when-cross-origin)</figcaption></figure>

<p>You can also see the Referrer-Policy on Chrome developer tool, network tab.</p>

<p><span itemscope="" itemtype="http://schema.org/Photograph"><img src="https://cdn-ak.f.st-hatena.com/images/fotolife/p/paiza/20201002/20201002143238.png" alt="f:id:paiza:20201002143238p:plain" title="f:id:paiza:20201002143238p:plain" itemprop="image"></span></p>

<h2>Why is the "Referrer Policy" changed ?</h2>

<p>The Referrer Policy is changed because of privacy and security concerns.</p>

<p>The Referer URL may contain search keywords, account ID, e-mail address, or other IDs, and the information may be sent to the linked site as "Referer".</p>

<p><cite><a href="https://web.dev/referrer-best-practices/">web.dev</a></cite></p>

<figure title="(https://web.dev/referrer-best-practices/ ã‚ˆã‚Š)"><span itemscope="" itemtype="http://schema.org/Photograph"><img src="https://cdn-ak.f.st-hatena.com/images/fotolife/p/paiza/20201002/20201002143341.png" alt="f:id:paiza:20201002143341p:plain" title="f:id:paiza:20201002143341p:plain" itemprop="image"></span><figcaption>(from <a href="https://web.dev/referrer-best-practices/)">https://web.dev/referrer-best-practices/)</a></figcaption></figure>

<p>Nowadays, security and privacy are getting more critical than before. So, other browsers may change the settings as Chrome does.</p>

<h2>Current Referrer Policy deployment status</h2>

<p>How many Chrome85 have new "strict-origin-when-cross-origin", at now ?</p>

<p>At first, I created a poll at Slack. It looks more than half have the new settings.</p>

<p><span itemscope="" itemtype="http://schema.org/Photograph"><img src="https://cdn-ak.f.st-hatena.com/images/fotolife/p/paiza/20201002/20201002143535.png" alt="f:id:paiza:20201002143535p:plain" title="f:id:paiza:20201002143535p:plain" itemprop="image"></span></p>

<p>Also, from the access logs to our web sites, the percentage of Referer from the top page is growing from less than 10% to around 20% on  8th/Sep, and more than 50% on 29th/Sep or later.</p>

<h2>Solution</h2>

<p>If you can change the HTTP header or the HTML meta tag, you can change the Policy Referrer settings.</p>

<h3>HTTP header(Policy-Referrer) settings</h3>

<p>You can change Policy-Referrer HTTP response header field.
On nginx, you can change the configuration file like below.</p>

<pre data-lang="" data-unlink="">add_header 'Referrer-Policy' 'no-referrer-when-downgrade';</pre>


<h3>meta tag(name=referer) settings</h3>

<p>You can also change using the HTML meta tag like below.</p>

<pre data-lang="html" data-unlink=""><span>&lt;</span><span>meta</span><span> </span><span>name</span><span>=</span><span>"referrer"</span><span> </span><span>content</span><span>=</span><span>"no-referrer-when-downgrade"</span><span>/&gt;</span>
</pre>


<h3>Chrome settings</h3>

<p>You can also change on Chrome settings by putting "chrome://flags/#reduced-referrer-granularity" on the URL bar for testing.
By enabling the settings, Chrome does not send pathname on the URL.
By disabling the settings, Chrome sends pathname on the URL.</p>

<p><span itemscope="" itemtype="http://schema.org/Photograph"><img src="https://cdn-ak.f.st-hatena.com/images/fotolife/p/paiza/20201002/20201002153758.png" alt="f:id:paiza:20201002153758p:plain" title="f:id:paiza:20201002153758p:plain" itemprop="image"></span></p>



<p>On Safari 13 introducing ITP2.3, the access from the domain classified as tracker does not contain the path on Referer.</p>

<p><cite><a href="https://webkit.org/blog/9521/intelligent-tracking-prevention-2-3/">webkit.org</a></cite></p>



<p>The new Chrome85 is gradually stopping to send a URL path on Referer on cross-domain link, and it can cause huge impact on your web marketing.
I recommend checking your settings on web sites, access logs, or analysis tools.</p>

<hr>


<p>Withã€Œ<a href="https://paiza.cloud/">PaizaCloud Cloud IDE</a>ã€�, you can flexibly and easily develop your Web application or server application, and publish it, just in your browser.
<a href="https://paiza.cloud/"><img src="https://cdn-ak.f.st-hatena.com/images/fotolife/p/paiza/20171214/20171214153422.png" alt="https://paiza.cloud"></a></p>

<hr>


    

  
</div>

    
  

  </div>
</article>

      
      
    
  

  
  <!-- rakuten_ad_target_end -->
  <!-- google_ad_section_end -->
  
  
  
  


  



        </div>
      </div></div>]]>
            </description>
            <link>https://engineering.paiza.io/entry/referrer_policy</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660580</guid>
            <pubDate>Fri, 02 Oct 2020 08:59:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[[ Is a Builtin, but [[ Is Part of the Shell Language (2016)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24660535">thread link</a>) | @chubot
<br/>
October 2, 2020 | http://www.oilshell.org/blog/2016/10/12.html | <a href="https://web.archive.org/web/*/http://www.oilshell.org/blog/2016/10/12.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  <!-- INSERT LATCH HTML -->
<p><a href="http://www.oilshell.org/blog/">blog</a> | <a href="http://www.oilshell.org/">oilshell.org</a></p>

<p>
  2016-10-12
</p>
<!--
Started:                  ~8:35pm
Done with second edit:     9:10pm
More edits and deployed:   9:16pm
Editing again:             11:29
Done again again:          11:45
X -->
<p>The current theme of this blog is to show how the oil parser works.  But let's
make sure we understand an important concept first: <strong>parse-time errors</strong> vs.
<strong>runtime errors</strong>.</p>
<p>The way I write conditions in shell is like this:</p>
<div><pre><span></span><span>if</span> <span>test</span> -d /tmp<span>;</span> <span>then</span>
  <span>echo</span> <span>"/tmp is a dir"</span>
<span>fi</span>
</pre></div>
<p>This is the same thing:</p>
<div><pre><span></span><span>if</span> <span>[</span> -d /tmp <span>]</span><span>;</span> <span>then</span>
  <span>echo</span> <span>"/tmp is a dir"</span>
<span>fi</span>
</pre></div>
<p>But yet another construct for conditional expressions is <code>[[</code>.  The <a href="http://www.oilshell.org/cross-ref.html#google-style-guide">Google
Shell Style Guide</a> recommends using it, reasoning that:</p>
<blockquote>
<p>[[ ... ]] reduces errors as no pathname expansion or word splitting takes
place between [[ and ]].</p>
</blockquote>
<blockquote>
<p>[[ ... ]] allows for regular expression matching where [ ... ] does not.</p>
</blockquote>
<p>That is, consider the following:</p>
<div><pre><span></span><span>x</span><span>=</span><span>'name with space.sh'</span>
<span>[</span> <span>$x</span> <span>==</span> *.sh <span>]</span>
<span>[[</span> <span>$x</span> <span>==</span> *.sh <span>]]</span>
</pre></div>
<p>On the <code>[</code> line, <code>$x</code> will be split into 3 arguments.  The glob <code>*.sh</code> is also
expanded into multiple arguments, depending on what's in the current directory.
Both of these things cause the wrong number of arguments to appear on each side
of <code>==</code>.  In contrast, the <code>[[</code> expression will have exactly one argument on
the left and right of <code>==</code>.  (It tests if <code>$x</code> matches the pattern <code>*.sh</code>,
which is true.)</p>
<p>What I didn't realize before implementing the oil parser is that this doesn't
quite capture the difference between <code>[[</code> and <code>[</code>.  The more important
difference is that <code>[[</code> is <strong>part of the shell language</strong>, while <code>[</code> is a
<strong>builtin</strong>.</p>
<p>This means that an expression inside <code>[[ ... ]]</code> is <strong>parsed up front</strong>, before
any code is executed.  In contrast, the arguments to <code>[</code> are parsed by the
builtin itself at <strong>runtime</strong>.</p>
<p>(In terms of parsing arguments, shell builtins behave like external commands.
The fact that they happen to live inside the <code>/bin/sh</code> binary doesn't change
anything.)</p>
<p>The bash help doesn't capture this difference either: see <code>help [</code> and <code>help [[</code>.  The parse-time vs. runtime distinction isn't mentioned.</p>
<p>Let's write some code to show this difference.  First we create syntax errors
by leaving off the right hand side of an equality test:</p>
<pre><span>$ <span></span><span>[</span> <span>a</span> <span>==</span> <span>]</span>
</span><span>/bin/bash: line 1: [: a: unary operator expected</span>
</pre>
<pre><span>$ <span></span><span>[[</span> <span>a</span> <span>==</span> <span>]]</span>
</span><span>/bin/bash: line 1: unexpected argument `]]' to conditional binary operator
/bin/bash: line 1: syntax error near `]]'
/bin/bash: line 1: `[[ a == ]]'</span>
</pre>
<p>On the face of it, these errors look similar.  Now let's use the general
technique of wrapping them in <code>if false</code>:</p>
<pre><span>$ <span></span><span>if</span> false<span>;</span> <span>then</span> <span>[</span> <span>a</span> <span>==</span> <span>]</span><span>;</span> <span>else</span> <span>echo</span> <span>'NOT PARSED'</span><span>;</span> <span>fi</span>
</span><span>NOT PARSED</span>
</pre>
<pre><span>$ <span></span><span>if</span> false<span>;</span> <span>then</span> <span>[[</span> <span>a</span> <span>==</span> <span>]]</span><span>;</span> <span>else</span> <span>echo</span> <span>'NOT PARSED'</span><span>;</span> <span>fi</span>
</span><span>/bin/bash: line 1: unexpected argument `]]' to conditional binary operator
/bin/bash: line 1: syntax error near `;'
/bin/bash: line 1: `if false; then [[ a == ]]; else echo 'NOT PARSED'; fi'</span>
</pre>
<p><code>bash</code> parsed the first statement without issue, and executed the <code>else</code>
clause.  The stuff inside <code>[</code> is just an opaque list of strings.  We never
executed it and never parsed it.</p>
<p>In contrast, it emitted a parse error for the second statement, and didn't
execute any code.  This is because <code>[[</code> is actually part of the language.</p>
<p>Tomorrow we will use the same <code>if false</code> technique to compare the oil parser
with popular shell parsers.  We will see which errors they can catch at parse
time, and which errors have to wait until runtime.</p>
<p>oil has the philosophy that catching errors earlier is better.  You don't want
run a 4 hour script and get a syntax error after 3 hours.</p>




</div>]]>
            </description>
            <link>http://www.oilshell.org/blog/2016/10/12.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660535</guid>
            <pubDate>Fri, 02 Oct 2020 08:51:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remote Teams and Good Time Management]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24660510">thread link</a>) | @lucyinkedup
<br/>
October 2, 2020 | https://caylent.com/remote-teams-and-good-time-management | <a href="https://web.archive.org/web/*/https://caylent.com/remote-teams-and-good-time-management">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	                    <section>
	                        <div>
	                            
<p>This year’s global pandemic has forced the fast adjustment for many organizations from in-office normality to a remote working setup at whiplash speed. The rapid adoption of remote working is not easy though—even without the pressure of COVID.&nbsp;</p>



<p>Challenges are abundant for both those with remote working experience and those without. Managers and team leaders are struggling to keep their teams motivated and efficient. Remote teams are often seen as more difficult to manage, but the tips discussed in this article can help you overcome these challenges.&nbsp;</p>



<h2>Empower Remote Team Members</h2>



<p>Before digging deeper into time and task management, there are actually several basic steps that you need to complete in order to make remote teams effective. The first thing you want to do is making sure that team members can communicate easily and effectively, and that means establishing a way of communicating that everyone is comfortable with.</p>



<p>Most teams turn to <a href="https://slack.com/" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">Slack</a>, but Slack is not always the best tool for the job. If your team puts emphasis on project management, for instance, using digital Kanban tools with built-in chat feature can be more effective and other communication tools such as Google Mail with Google Chat and Meet integrations are helpful. Microsoft has a similar suite of tools if you’re inclined to that choice of software.&nbsp;</p>



<p>To further empower team members, integrate a good task management platform. There is no way to keep track of everything when team members have to organize their tasks individually. The easier way to establish a baseline for remote working is by using a project or task management tool that turns tasks into blocks waiting to be managed such as <a href="https://trello.com/en" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">Trello,</a> <a href="https://asana.com/" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">Asana</a> or <a href="https://basecamp.com/" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">Basecamp</a>.</p>



<p>Lastly, encourage team members to create a productive environment that works for them. Some startups and corporations are starting to provide team members with aids to help them set up a more comfortable and functional home office. This is the kind of initiative that puts team members in the right mindset for effective remote working.</p>



<h2>Meetings and Discussions</h2>



<p>The next thing to tackle is how meetings are set up. Even when working in the office, meetings are very distracting when they are not planned properly. Too many meetings will prevent team members from completing their tasks. Too few meetings could result in the team not having clear⁠—and mutual⁠—directions and common objectives.</p>



<p>With remote working, however, limiting the number of ad-hoc, on-demand meetings is highly recommended. Meetings need to be scheduled beforehand and team members must utilize the provided communications channels⁠—such as groups in Google Chat⁠—to discuss other work-related matters.</p>



<p>Scheduling daily standups that are not too long at the beginning of every day is also a good idea. The daily standup doesn’t just function as an opportunity for everyone to stay up to date with what the rest of the team is doing, but also as an opportunity to provide moral support for each other. As mentioned before, working remotely is not easy for everyone.</p>



<p>Set aside one or two days during which team members can focus entirely on the tasks in hand. For instance, you can have Thursday and Friday free of meetings and other distractions. This will allow all team members to prepare for Thursday-Friday sprints of their own since they already know what tasks they need to finish and can plan for the two days better.</p>



<p>Speaking of planning, it is also recommended to have a predetermined timeframe for sprints. Anything shorter than six weeks⁠—but longer than two⁠—is usually ideal, but ask your team for feedback on how to compose it to determine the best way to organize sprints that work for you all. Don’t hesitate to collaborate on best practices for remote working with team members to facilitate a solution that works for everyone involved. It’s a great way to get buy in at every level.</p>



<h2>Boost Engagement</h2>



<p>That last part is important on its own. When working remotely, employee engagement becomes a crucial component. You cannot have the progress of the team hindered by one or two disengaged team members. This is where some adjustments to how you (and other members of the team) communicate become very important.</p>



<p>For starters, forget about tracking time. Switch to a result-oriented approach and let team members worry about managing their own time. At the same time, provide team members with resources that will help them manage their time better, such as the digital Kanban board mentioned earlier. Anything that helps organize tasks in a transparent way helps.</p>



<p>Next, throw micromanagement out the window. There is no way you can micro-manage team members when everyone is working remotely. Trying to do so will only disrupt the internal flow and reduce the effectiveness of the team. Instead, allow everyone to be more involved in the tasks that they are interested in the most.</p>



<p>Transparency of workloads will encourage team members to also be even more engaged. With tasks and workloads monitored closely, team members are more likely to offer help to others when their own tasks are finished. There will be a growing awareness of the mutual objectives that the team is trying to achieve.</p>



<h2>Manage Time</h2>



<p>Of course, remote working relies heavily on the ability of every team member to manage time, and there are several things you can do to encourage good time management. You can start by supporting team members to prioritize the tasks in hand accordingly. Motivation and acknowledgment are key components in the procesto.</p>



<p>More importantly, encourage team members to embrace a work-life balance. Working remotely doesn’t mean working all the time; and trying to push team members to do so will only reduce their productivity. By encouraging the team to have fun and focusing more on the results they deliver, you can facilitate time management improvement in a more positive way.</p>



<p>That’s it! Remote working is a challenge for some teams, but the tips we discussed in this article will help you transition into a remote-first organization in time.</p>



<hr>



<p><a href="http://www.caylent.com/" target="_blank" rel="noreferrer noopener">Caylent</a>&nbsp;provides a critical DevOps-as-a-Service function to high growth companies looking for expert support with Kubernetes, cloud security, cloud infrastructure, and CI/CD pipelines. Our managed and consulting services are a more cost-effective option than hiring in-house, and we scale as your team and company grow. Check out some of the use cases, learn how we work with clients, and read more about our<a href="https://caylent.com/devops-as-a-service/" target="_blank" rel="noreferrer noopener">&nbsp;DevOps-as-a-Service offering</a>.</p>
                     
	                        </div>
	                    </section>
	                </article></div>]]>
            </description>
            <link>https://caylent.com/remote-teams-and-good-time-management</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660510</guid>
            <pubDate>Fri, 02 Oct 2020 08:47:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I can't write a JavaScript for loop, and it does not matter]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24660465">thread link</a>) | @slorber
<br/>
October 2, 2020 | https://daily.sebastienlorber.com/i-cant-write-a-javascript-for-loop-and-it-does-not-matter-ckfrzpby8004iv6s19cxq04vj | <a href="https://web.archive.org/web/*/https://daily.sebastienlorber.com/i-cant-write-a-javascript-for-loop-and-it-does-not-matter-ckfrzpby8004iv6s19cxq04vj">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>I've been using JavaScript daily for 7 years, and I'm not able to remember the syntax of a JavaScript for loop.</p>
<p>Despite this fact, I'm a rather successful freelance developer. Recently I even had the awesome opportunity to work for Facebook, as the <a target="_blank" href="https://github.com/facebook/docusaurus/issues/2336">Docusaurus lead maintainer</a>, writing the code for the framework that powers the documentation sites of Babel, Prettier, Jest, ReactNative...</p>
<p>I'll explain why I'm not able to remember such syntax, and why it does not matter much.</p>
<hr>

<p><strong>TLDR</strong>: I'm a functional programmer</p>
<p>I've really started programming at the beginning of my engineer degree, around 2004 (before that, I was only able to hack some scripts for Counter-Strike console or IRC).</p>
<p>Most of our school teaching was based on Java, but we also saw a bit of C, C++, OCaml. </p>
<p>The first loop syntax I learned probably looked like this one:</p>
<pre><code>List&lt;Integer&gt; numbers = Lists.newArrayList(<span>1</span>, <span>2</span>, <span>3</span>);

<span>for</span> (<span>int</span> i = <span>0</span>; i &lt; numbers.length; i++) {
   System.out.println(numbers.get(i));
}
</code></pre>
<p>Before I came out of school, Java 6 brought some new, simpler syntax:</p>
<pre><code>List&lt;Integer&gt; numbers = Lists.newArrayList(<span>1</span>, <span>2</span>, <span>3</span>);

<span>for</span> (Integer number : numbers) {
   System.out.println(number);
}
</code></pre>
<p>At my first job, the <a target="_blank" href="https://github.com/google/guava">Google Guava</a> lib brought some new verbose functional syntax to Java, and I was able to do weird things with it 😅.</p>
<pre><code>List&lt;Integer&gt; numbers = Lists.newArrayList(<span>1</span>, <span>2</span>, <span>3</span>);

Lists.newArrayList(Collections2.transform(numbers, <span>new</span> Function&lt;Integer,Void&gt;() {
  <span>@Override</span>
  <span><span>public</span> Void <span>apply</span><span>(Integer number)</span> </span>{
    System.out.println(number);
    <span>return</span> <span>null</span>;
  }
}));
</code></pre>
<p>This Guava lib got me intrigued by functional programming, and lead me to become a Scala developer since 2012, and I was finally able to use functional programming concepts (loops, but not only) without the ugly Java/Guava syntax.</p>
<pre><code>val numbers = List(1, 2, 3)
numbers.foreach(println)
</code></pre>
<p>In 2013, <a target="_blank" href="https://reactjs.org/blog/2013/06/05/why-react.html">ReactJS came out</a>, and this totally changed my career path. At this time, I didn't like JavaScript much and was only able to hack some inline JQuery things in server-rendered pages. But as a startup CTO, I saw my team struggle with architecture, BackboneJS and RequireJS, and thought I had to become better at frontend to lead them.</p>
<p>AngularJS looked like the safer choice at this time, but a Scala developer colleague really pushed for React, which looked fancy and risky. All things made sense with the visionary post of David Nolen (<a target="_blank" href="https://swannodette.github.io/2013/12/17/the-future-of-javascript-mvcs/">The Future of JavaScript MVC Frameworks</a>), and we finally adopted React in January 2014, as it seemed we would be able to use our functional programming knowledge to the frontend app as well, and make the UI more predictable.</p>
<p>Fast forward, it wasn't easy to be a React early-adopter for our critical app. All companies were building their own state management solution, trying to figure things out, <a target="_blank" href="https://github.com/stample/atom-react">and so we did</a>, based on the ideas of David Nolen to hold a single immutable state in an atom (I was able to get a <a target="_blank" href="https://www.youtube.com/watch?v=zxN8FYYBcrI">hacky time-travel working</a> before Redux). </p>
<p>Since then both the JavaScript language and the ReactJS ecosystem have progressed a lot, and it's very common to use functional programming principles nowadays.</p>

<p>As a long-time functional programmer, <strong>I simply don't write for loops</strong> very often. </p>
<p>Like anything you don't use regularly, you end up forgetting the syntax.</p>
<p>Today, many of us use ES5+ syntax (or Lodash/Ramda...) and some functional constructs. Using <code>map</code>, <code>forEach</code>, <code>filter</code> are the most illustrated examples in the JS community.</p>
<pre><code><span>const</span> numbers = [<span>1</span>, <span>2</span>, <span>3</span>]
numbers.forEach(<span><span>number</span> =&gt;</span> <span>console</span>.log(number));
</code></pre>
<p>But we can go much further than that once we are more experienced with functional programming, and almost never write any for loops anymore. </p>
<p>Don't get me wrong, it's not necessarily a goal to not write for loops anymore, and I'm not telling you that you should remove all for loops of your production codebase.</p>
<p>Very often there's an alternative syntax possible for your loops that might be more expressive and easier to understand. After a while, you end up seeing a for loop as an implementation detail of a more elegant functional abstraction.</p>
<p>This more expressive syntax is not only for loops, and you can as well see a functional abstraction being an implementation detail of another higher-level abstraction.</p>
<p>Let's consider we want to increment the age of 2 brothers.</p>
<pre><code><span>const</span> brothers = {
  <span>id1</span>: {<span>name</span>: <span>"Sébastien"</span>, <span>age</span>: <span>34</span>},
  <span>id2</span>: {<span>name</span>: <span>"Antoine"</span>, <span>age</span>: <span>23</span>}
};
</code></pre>
<p>I very often see the <code>array.reduce()</code> operator used when a more expressive alternative was possible.</p>
<pre><code><span><span>function</span> <span>incrementBrothersAges</span>(<span></span>) </span>{
  <span>return</span> <span>Object</span>.entries(brothers)
    .reduce(<span>(<span>acc,[id,brother]</span>) =&gt;</span> {
      acc[id] = {...brother, <span>age</span>: brother.age + <span>1</span>};
      <span>return</span> acc;  
    },{})
}
</code></pre>
<p>You know what? <strong>I really struggled to write this code</strong>. </p>
<p>My first attempt was not working at all (TypeScript would have helped).</p>
<pre><code><span><span>function</span> <span>incrementBrothersAges</span>(<span></span>) </span>{
  <span>return</span> <span>Object</span>.entries(brothers)
      
      .reduce(<span>(<span>[id,brother],  acc</span>) =&gt;</span> {
        acc[id] = {...brother, <span>age</span>: brother.age + <span>1</span>};
        
      },{});
}
</code></pre>
<p>Yet, writing this kind of transform is idiomatic for me, using higher-level functional programming abstractions, such as <code>mapValues</code> (included in lodash).</p>
<pre><code><span><span>function</span> <span>incrementBrothersAges</span>(<span></span>) </span>{
  <span>return</span> mapValues(
    brothers, 
    <span><span>brother</span> =&gt;</span> ({...brother, <span>age</span>: brother.age + <span>1</span>})
  );
}
</code></pre>
<p>And I think nobody would argue that this is harder to read and maintain right? If junior developers are not familiar with functional programming, they'll catch up fast and get used to it. This might even be harder to learn <code>reduce</code>.</p>

<p>I don't write for loops (or <code>reduce</code>), but I know the concepts. I know that these loops exist in different syntaxes, that can be useful for different use cases, and how to make a choice with a good tradeoff (performance, readability...).</p>
<p>I'll illustrate this with a concrete example from my daily work that actually led me to write this article.</p>
<p>I had this async function that performs some long task for a given country.</p>
<pre><code><span>async</span> <span><span>function</span> <span>runCountryTask</span>(<span>country</span>) </span>{

  
  <span>const</span> taskDuration = <span>1000</span> + <span>Math</span>.random() * <span>4000</span>;
  <span>await</span> <span>new</span> <span>Promise</span>(<span><span>resolve</span> =&gt;</span> <span>setTimeout</span>(resolve, taskDuration));

  <span>console</span>.log(<span>`Task completed for <span>${country}</span>`</span>);
}
</code></pre>
<p>This task had to be run for many countries, but the tasks should be run sequentially, not in parallel.</p>
<p>As I know the concepts, and I knew that the following would not work, as <code>Promise.all</code> would run all tasks in parallel.</p>
<pre><code><span>async</span> <span><span>function</span> <span>runAllCountryTasks</span>(<span></span>) </span>{
  <span>const</span> countries = [<span>"FR"</span>, <span>"EN"</span>, <span>"US"</span>, <span>"DE"</span>, <span>"UK"</span>, <span>"IT"</span>];

  
  <span>await</span> <span>Promise</span>.all(countries.map(runCountryTask))
}
</code></pre>
<p>I also knew that there were multiple possible solutions to solve this problem:</p>
<ul>
<li>use a third-party dependency exposing the higher-level async primitive I need</li>
<li>use <code>Promise.then()</code> recursively</li>
<li>use async/await, using a for loop syntax to iterate over a fixed-size array</li>
</ul>
<p>I didn't want to introduce a new third party dependency just for a tiny utility function. </p>
<p>I also knew that using <code>Promise.then()</code> recursively could be harder to read, write, and maintain. There are many ways to write such a recursion, one of them could be:</p>
<pre><code><span>async</span> <span><span>function</span> <span>forEachAsyncSequential</span>(<span>array, asyncFn</span>) </span>{
  <span>await</span> array.reduce(<span>(<span>acc, item</span>) =&gt;</span> {
    <span>return</span> acc.then(<span>() =&gt;</span> asyncFn(item))
  }, <span>Promise</span>.resolve());
}
</code></pre>
<p>So I opted for a basic for loop, as it seemed the right tradeoff. </p>
<p>As I'm totally unable to remember the syntax (<code>in</code> vs <code>of</code>, can I actually use <code>const</code>?), I had to actually google it, and it didn't take me long to be able to write the TypeScript code that will be shipped in production.</p>
<pre><code><span>export</span> <span>async</span> <span><span>function</span> <span>forEachAsyncSequencial</span>&lt;<span>T</span>&gt;(<span>
  array: T[],
  asyncFn: (t: T) =&gt; <span>Promise</span>&lt;<span>void</span>&gt;,
</span>): <span>Promise</span>&lt;<span>void</span>&gt; </span>{
  <span>for</span> (<span>const</span> item <span>of</span> array) {
    <span>await</span> asyncFn(item);
  }
}
</code></pre>
<pre><code><span>async</span> <span><span>function</span> <span>runAllCountryTasks</span>(<span></span>) </span>{
  <span>const</span> countries = [<span>"FR"</span>, <span>"EN"</span>, <span>"US"</span>, <span>"DE"</span>, <span>"UK"</span>, <span>"IT"</span>];

  
  <span>await</span> forEachAsyncSequencial(countries, runCountryTask);
}
</code></pre>
<p>Believe me or not, but I think It's the only for loop I actually wrote in JavaScript this year. And once it's written, I won't need to write it ever again (at least for this project), as it's now part of my functional programming abstractions, that I can reuse anywhere I need.</p>
<p><a target="_blank" href="https://jsfiddle.net/y17c6et8/1/">JsFiddle playground</a></p>
<hr>

<p>It's not very important to remember every syntax details to be productive in your daily work, particularly when you don't use them often (on purpose), as you prefer to work with more expressive, higher-level abstractions. </p>
<p>I had to google many things to write this article:</p>
<ul>
<li>Syntax for declaring a Java list</li>
<li>Syntax for iterating a Java list</li>
<li>Does <code>System.out.println</code> accept an Integer?</li>
<li>Syntax for Scala string interpolation</li>
<li>Is there a <code>forEach</code> in Guava (actually found <a target="_blank" href="https://stackoverflow.com/questions/38251257/guava-iterators-for-nested-foreach">my own StackOverflow question</a>)</li>
<li>What are the possible syntaxes for iterating over a JavaScript array</li>
<li>Signature of <code>array.reduce()</code></li>
</ul>
<p>Not remembering all this does not matter much, as long as I know what to look for.</p>
<p>In the same way, I don't know much about many other JavaScript things:</p>
<ul>
<li>prototypes: I think I never hard to use them directly in my entire life, and I'm fine</li>
<li>classes: used them temporarily when I really had to in React</li>
<li>JavaScript quirks: I know some of them, but simply avoid the others by using ESLint, <code>===</code>, TypeScript... it's not worth knowing all of them</li>
<li>...</li>
</ul>
<p>The knowledge and concepts you learn are more easily transposable from one language to another. I was able to learn React and contribute to its ecosystem quickly, thanks to my functional programming background. </p>
<p>I would argue that knowing how to do a recursive algorithm is more important than knowing the syntax of a for loop of a particular language. You will likely write many recursive algorithms in your career: the concept of recursion is not going anywhere anytime soon. But it's way more likely that you switch from one language to another from time to time. </p>
<p>Hopefully, writing this post will help me remember the syntax for a while until I forget it again 🤪.</p>
<hr>
<p>🙏 If you like this post, please like it, share it or comment it 🙏: </p>
<ul>
<li><a target="_blank" href="https://twitter.com/sebastienlorber/status/1311948662843551744">Tweet</a></li>
<li><a target="_blank" href="https://daily.sebastienlorber.com/i-cant-write-a-javascript-for-loop-and-it-does-not-matter-ckfrzpby8004iv6s19cxq04vj">Hashnode</a></li>
<li><a target="_blank" href="https://dev.to/sebastienlorber/i-can-t-write-a-javascript-for-loop-and-it-does-not-matter-11jb">Dev</a></li>
<li><a target="_blank" href="https://www.reddit.com/r/javascript/comments/j3r08h/i_cant_write_a_javascript_for_loop_and_it_does/">Reddit</a></li>
<li><a target="_blank" href="https://news.ycombinator.com/item?id=24660465">HackerNews</a></li>
</ul>
<p>For more content like this, subscribe to <a target="_blank" href="https://mailchi.mp/4ea4df0b54f7/sebastienlorber">my mailing list</a> and follow me on <a target="_blank" href="https://twitter.com/sebastienlorber">Twitter</a>.</p>
</div></div>]]>
            </description>
            <link>https://daily.sebastienlorber.com/i-cant-write-a-javascript-for-loop-and-it-does-not-matter-ckfrzpby8004iv6s19cxq04vj</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660465</guid>
            <pubDate>Fri, 02 Oct 2020 08:41:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Flicker free fireworks (or how I accidentally rediscovered the regen buffer)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24660412">thread link</a>) | @lukastyrychtr
<br/>
October 2, 2020 | https://blog.darrien.dev/posts/flicker-free-fireworks/ | <a href="https://web.archive.org/web/*/https://blog.darrien.dev/posts/flicker-free-fireworks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
        <p>In <a href="https://blog.darrien.dev/posts/fireworks-for-your-terminal/">my last post</a> I talked about
how I made a enjoyable little display of
<a href="https://gitlab.com/darrieng/term-fireworks">fireworks</a> for the terminal. It was
fun to make and it’s fun to watch when meetings get boring (always).</p>
<p><a href="https://gitlab.com/DarrienG/term-fireworks">Fireworks can be found here.</a></p>
<p>However after running my fireworks for a while, I started noticing some funky
details. The fireworks could be a little flickery at times. And not in a good
way.</p>
<p>Well we couldn’t have that! So it was time to investigate.</p>
<h2 id="what-do-the-flickers-mean-mason">What do the flickers mean Mason?<a href="#what-do-the-flickers-mean-mason" arialabel="Anchor">⌗</a> </h2>
<p>The first thing I noticed was this wasn’t a problem on Linux, it only happened
on macOS.</p>
<p>I do most of my development on a beefy Linux machine with 6 real cores (12 total
threads) and figured perhaps this was just a specs thing, so I fired up my 7
year old ThinkPad running CentOS and still didn’t have flickering. Compared to
my 2019 work MacBook, it was smooth as butter. Could this be a Mac only bug?</p>
<p>On a whim I remembered how iTerm is not the fastest terminal in the world and
decided to try my fireworks on the slowest terminal I could think of. The WSL
terminal.</p>
<p>I broke out my old Windows machine and after a half an hour, got WSL and
fireworks up and running. The result:</p>
<p><img src="https://blog.darrien.dev/flicker-free-fireworks/flicker.webp" alt="flickering in action"></p>
<p>The Windows terminal running WSL exhibited the same behaviors as on macOS, but
much more frequently and much more consistently. This lead me to believe that
the problem was in drawing. I must not be doing it efficiently. Other terminal
applications can run flicker free in Windows terminal, so why not me too?</p>
<h2 id="the-old-firework-rendering-pipeline">The old firework rendering pipeline<a href="#the-old-firework-rendering-pipeline" arialabel="Anchor">⌗</a> </h2>
<p>The old rendering pipeline was very simple. It used two total threads, one for
input, and one for all rendering work. This is a simple approximation of it:</p>
<p><img src="https://blog.darrien.dev/flicker-free-fireworks/renderer-v1.png" alt="renderer-v1"></p>
<p>If you look at this for long enough, you’re going to see some low hanging fruit
to optimize away.</p>
<ul>
<li>we’re making fireworks on the same thread we draw points</li>
<li>we’re clearing way more points than we need to</li>
<li>we’re drawing way more points than we need to</li>
</ul>
<p>Let’s dig into each one individually.</p>
<h3 id="were-making-fireworks-on-the-same-thread-we-draw-points">we’re making fireworks on the same thread we draw points<a href="#were-making-fireworks-on-the-same-thread-we-draw-points" arialabel="Anchor">⌗</a> </h3>
<p>The <em>maybe generate new firework</em> and <em>advance fireworks one step</em> happens
before drawing every single time. In order to keep a consistent framerate, this
would have to be completed in a fraction of a fraction of a second. I’ve done my
best to optimize this as much as possible, but especially with the more exciting
fireworks I plan on adding later, this won’t be possible in the future.</p>
<p>Firework generation and advancing should happen on another thread.</p>
<h3 id="were-clearingdrawing-more-points-than-we-need-to">we’re [clearing|drawing] more points than we need to<a href="#were-clearingdrawing-more-points-than-we-need-to" arialabel="Anchor">⌗</a> </h3>
<p>The painting implementation is dumb as rocks, and simply:</p>
<ul>
<li>creates a list of every single point to be drawn</li>
<li>creates a list of every single point to be cleared</li>
</ul>
<p>This means on each loop, we draw points that were already on the screen, and
clear points just to have them repainted shortly after.</p>
<p>Drawing is easily the slowest part of the application, so that’s not good at
all.</p>
<h2 id="how-do-we-deal-with-this">How do we deal with this?<a href="#how-do-we-deal-with-this" arialabel="Anchor">⌗</a> </h2>
<p>Given our two problems, I felt it would make the most sense to move as much of
the actual firework building work to another thread. While overkill for how
we’re currently figuring out the points we need to draw fireworks, if we move
the work to another thread we’ll have time for all of the set logic required to
only draw and clear the points that have changed.</p>
<h2 id="the-new-architecture">The new architecture<a href="#the-new-architecture" arialabel="Anchor">⌗</a> </h2>
<p>The new architecture revamps a few things, but mostly just moves them around
with the addition of a new compositor component.</p>
<p><img src="https://blog.darrien.dev/flicker-free-fireworks/renderer-v2.png" alt="renderer-v2"></p>
<p>The compositor runs in a separate thread and sets up all the points required for
all of the fireworks ahead of time.</p>
<p>Originally when planning up this v2 architecture I was only going to prep one
frame of fireworks at a time, but then I figured, why do just one? Why not get
a few ready ahead of time?</p>
<p>Rust has
<a href="https://doc.rust-lang.org/std/sync/mpsc/fn.sync_channel.html">sync_channel</a>s
which easily lets you do this. Set the max buffer size and it won’t insert more
than that. For my Java folks out there, it’s conceptually similar to a
<a href="https://docs.oracle.com/javase/7/docs/api/java/util/concurrent/LinkedBlockingQueue.html">LinkedBlockingQueue</a>
for sharing data across threads.</p>
<h2 id="its-just-a-regen-buffer">It’s just a regen buffer<a href="#its-just-a-regen-buffer" arialabel="Anchor">⌗</a> </h2>
<p>At this point I was thinking myself very clever for coming up with such a new
innovative idea. Imagine what others will think when I tell them about this cool
new concept of async rendering!</p>
<p>I put my head down and tried to think of all of the other applications that
might find this technique useful, only to realize… a lot of other applications
already did something like this.</p>
<p>Distraught but still hopeful I had “really done something” I Google’d around
only for my hope to meet its demise on the <a href="https://en.wikipedia.org/wiki/Framebuffer">framebuffer wikipedia
page</a>.</p>
<blockquote>
<p>In computing, a screen buffer is a part of computer memory used by a computer
application for the representation of the content to be shown on the computer
display. The screen buffer may also be called the video buffer, the
regeneration buffer, or regen buffer for short. Screen buffers should be
distinguished from video memory. To this end, the term off-screen buffer is also
used.</p>
</blockquote>
<p>Well so much for that.</p>
<h2 id="implementation">Implementation<a href="#implementation" arialabel="Anchor">⌗</a> </h2>
<p>This post would be no fun without a bit of discussing how it was made. We can
spend all day in the ivory tower talking about architecture, but entering the
trenches and actually writing the code is a little different.</p>
<h3 id="channel-setup">Channel setup<a href="#channel-setup" arialabel="Anchor">⌗</a> </h3>
<p>If you look at the <a href="https://blog.darrien.dev/posts/flicker-free-fireworks/#the-new-architecture">v2 architecture diagram</a> you’ll
see there are 3 components now. I wanted to give them all a chance to shut down
completely, so the component accepting input now takes a list of senders it will
send <em>request to kill signals</em> to.</p>
<p>Likewise, we need to set up the buffer for which we can send fireworks to the
renderer. This is all done like so:</p>
<div><pre><code data-lang="rust"><span>fn</span> <span>main</span>() {
  <span>let</span> (input_sender_1, input_receiver_1): (Sender<span>&lt;</span><span>bool</span><span>&gt;</span>, Receiver<span>&lt;</span><span>bool</span><span>&gt;</span>) <span>=</span> mpsc::channel();
  <span>let</span> (input_sender_2, input_receiver_2): (Sender<span>&lt;</span><span>bool</span><span>&gt;</span>, Receiver<span>&lt;</span><span>bool</span><span>&gt;</span>) <span>=</span> mpsc::channel();

  <span>let</span> (regen_buffer_filler, regen_buffer): (SyncSender<span>&lt;</span>Drawables<span>&gt;</span>, Receiver<span>&lt;</span>Drawables<span>&gt;</span>) <span>=</span>
    mpsc::sync_channel(<span>5</span>);

  <span>let</span> <span>mut</span> stdout <span>=</span> stdout()
    .into_raw_mode()
    .expect(<span>"Unable to capture stdout. Exiting."</span>);

  <span>// all internal modules in fireworks
</span><span></span>  input::capture(vec<span>!</span>[input_sender_1, input_sender_2]);
  compositor::start(seed, regen_buffer_filler, input_receiver_2);
  renderer::start(<span>&amp;</span><span>mut</span> stdout, regen_buffer, input_receiver_1);
}
</code></pre></div><p>A design decision I made here was to not have the compositor be spawned by the
renderer. I didn’t want the renderer to know anything about the compositor, just
that it will receive <code>Drawables</code> from some magic buffer. Who knows what’s
filling it!</p>
<h3 id="input-capturer">Input capturer<a href="#input-capturer" arialabel="Anchor">⌗</a> </h3>
<p>This barely changes and isn’t really isn’t worth talking about. <a href="https://gitlab.com/DarrienG/term-fireworks/-/blob/168c80689612cee5442e92b4f30b2b5a5bfabe78/src/input.rs">It has now been
upgraded from an 18 line file to a 20 line
file.</a></p>
<p>Poor input capturer; perhaps you’ll get a longer section in the future.</p>
<h3 id="renderer">Renderer<a href="#renderer" arialabel="Anchor">⌗</a> </h3>
<p>The
<a href="https://gitlab.com/DarrienG/term-fireworks/-/blob/168c80689612cee5442e92b4f30b2b5a5bfabe78/src/renderer.rs">renderer</a>
changes in a few exciting ways, the most exciting in that it is gutted. No
longer does it spin up a firework state machine to get Drawables, now it just
waits at a channel, lonely and blocking until it gets some input.</p>
<div><pre><code data-lang="rust"><span>let</span> to_draw <span>=</span> regen_buffer.recv().expect(<span>"Compositor unexpectedly died!"</span>);
</code></pre></div><p>Otherwise the renderer is the same. The goal of the renderer is to be as dumb as
possible and it is certainly achieving that.</p>
<h3 id="compositor">Compositor<a href="#compositor" arialabel="Anchor">⌗</a> </h3>
<p>Finally the compositor, which is 30 or so lines that really come down to:
ticking the state machine and sending the points it made somewhere.</p>
<div><pre><code data-lang="rust"><span>pub</span> <span>fn</span> <span>compositor_loop</span>(
  seed: <span>u64</span>,
  regen_buffer_filler: <span>SyncSender</span><span>&lt;</span>Drawables<span>&gt;</span>,
  end_signal: <span>Receiver</span><span>&lt;</span><span>bool</span><span>&gt;</span>,
) {
  <span>let</span> <span>mut</span> state_machine <span>=</span> state_machine::StateMachine::new(seed, terminal_width());

  <span>loop</span> {
    <span>let</span> drawables <span>=</span> state_machine.tick(terminal_width());
    <span>if</span> regen_buffer_filler.send(drawables).is_err() {
      panic<span>!</span>(<span>"Renderer unexpectedly died!"</span>);
    }
    <span>if</span> <span>let</span> Ok(v) <span>=</span> end_signal.try_recv() {
      <span>if</span> v {
        <span>return</span>;
      }
    }
  }
}
</code></pre></div><p>And that’s it for the new architecture components!</p>
<h3 id="so-then-where-are-all-the-code-changes">So then where are all the code changes??<a href="#so-then-where-are-all-the-code-changes" arialabel="Anchor">⌗</a> </h3>
<p>There are only a few. Really, the bulk of the work was in architectural changes.</p>
<p>The final changes, the ones that affect drawing are in the firework itself. We
can do a whole lot more work now that we can work in a separate thread, and so
the Drawable trait we worked with in the previous post goes from:</p>
<div><pre><code data-lang="rust"><span>impl</span> Drawable <span>for</span> TailPoints {
  <span>fn</span> <span>draw</span>(<span>&amp;</span>self) -&gt; <span>&amp;</span>[Point] {
    <span>&amp;</span>self.tail
  }
  <span>fn</span> <span>clear</span>(<span>&amp;</span>self) -&gt; <span>&amp;</span>[Point] {
    <span>&amp;</span>self.old_tail
  }
}
</code></pre></div><p>to:</p>
<div><pre><code data-lang="rust"><span>impl</span> Drawable <span>for</span> TailPoints {
  <span>fn</span> <span>draw</span>(<span>&amp;</span>self) -&gt; Vec<span>&lt;</span>Point<span>&gt;</span> {
    difference(<span>&amp;</span>self.tail, <span>&amp;</span>self.old_tail)
  }
  <span>fn</span> <span>clear</span>(<span>&amp;</span>self) -&gt; Vec<span>&lt;</span>Point<span>&gt;</span> {
    difference(<span>&amp;</span>self.old_tail, <span>&amp;</span>self.tail)
  }
}


<span>fn</span> <span>difference</span>(points_1: <span>&amp;</span>[Point], points_2: <span>&amp;</span>[Point]) -&gt; Vec<span>&lt;</span>Point<span>&gt;</span> {
  <span>let</span> set_1 <span>=</span> points_1.iter().cloned().collect::<span>&lt;</span>HashSet<span>&lt;</span>Point<span>&gt;&gt;</span>();

  <span>let</span> set_2 <span>=</span> points_2.iter().cloned().collect::<span>&lt;</span>HashSet<span>&lt;</span>Point<span>&gt;&gt;</span>();
  set_1.difference(<span>&amp;</span>set_2).cloned().collect()
}
</code></pre></div><p>Looking at the two, you’ll see the first is infinitely faster and also does
infinitely fewer allocations. And that’s how it was meant to be! As Drawables
had to be ready in real time, the implementation had to be fast as lightning.
But now they can take a little longer and do a lot more work. With async
rendering, they can do (roughly) as much work as they like and still be real
time!</p>
<p>All this extra work affords us some really slick optimizations. Post work we:</p>
<ul>
<li>paint exactly what has changed and nothing else</li>
<li>clear exactly what needs to disappear and nothing else</li>
</ul>
<p>These two things optimizations vastly increase the speed of drawing fireworks.</p>
<h2 id="downsides">Downsides<a href="#downsides" arialabel="Anchor">⌗</a> </h2>
<p>Well there is one, and if a point is ever drawn over and then cleared, it will
never be redrawn, meaning there can occasionally be small holes in the
fireworks. Something like this happens when two fireworks collide.</p>
<p>Solving this wouldn’t be too hard, but the fireworks still look pretty nice and
I think the asymmetrical nature of ones with little holes gives them some
character.</p>
<h2 id="so-was-it-all-worth-it">So was it all worth it?<a href="#so-was-it-all-worth-it" arialabel="Anchor">⌗</a> </h2>
<p>Well I’ll let the results speak for themself.</p>
<p><img src="https://blog.darrien.dev/flicker-free-fireworks/results.webp" alt="results"></p>
<p>Thanks for reading! If you liked this post, feel free to check out my blog posts
about the silly CLIs I made using rust :)</p>
<p>Fireworks source and binaries can be found
<a href="https://gitlab.com/DarrienG/term-fireworks">here</a>.</p>

      </div></div></div>]]>
            </description>
            <link>https://blog.darrien.dev/posts/flicker-free-fireworks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660412</guid>
            <pubDate>Fri, 02 Oct 2020 08:33:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What (not so) recently happened in Miri]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24660216">thread link</a>) | @lukastyrychtr
<br/>
October 2, 2020 | https://www.ralfj.de/blog/2020/09/28/miri.html | <a href="https://web.archive.org/web/*/https://www.ralfj.de/blog/2020/09/28/miri.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="-content">
      <header>
    
    
</header>

<p>A lot has happened in Miri over the last year and a half, and I figured it would be a good idea to advertise all this progress a bit more widely, so here we go.
We also recently performed a breaking change that affects some CI configurations, so this post serves as an announcement for you to update your CI configuration if needed.</p>

<p>For the uninitiated, <a href="https://github.com/rust-lang/miri/">Miri</a> is an interpreter that runs your Rust code and checks if it triggers any <a href="https://doc.rust-lang.org/reference/behavior-considered-undefined.html">Undefined Behavior</a>.
You can think of it a as very thorough (and very slow) version of valgrind: Miri will detect when your program uses uninitialized memory incorrectly, performs out-of-bounds memory accesses or pointer arithmetic, violates key language invariants, does not ensure proper pointer alignment, or causes incorrect aliasing.
As such, it is most helpful when writing unsafe code, as it aids in ensuring that you follow all the rules required for unsafe code to be correct and safe.
Miri also detects memory leaks, i.e., it informs you at the end of program execution if there is any memory that was not deallocated properly.</p>

<!-- MORE -->

<p>However, being an interpreter, Miri is limited in the kinds of code it can execute – everything that would usually involve interacting with C libraries or the operating system needs to be specifically supported, as C code cannot be interpreted by Miri.
Miri also lacks support for some Rust features that are hard to interpret, but we are slowly closing these gaps.</p>

<h2 id="recent-and-past-progress-in-miri">Recent and past progress in Miri</h2>

<p>During the last 1.5 years, thanks to a series of excellent contributors, we made a lot of progress towards supporting more and more Rust code to run in Miri.
I am going to list some highlights below.</p>

<p>If you want to learn how to use Miri yourself, scroll down to the end of this post.
If you are using Miri already, maybe you are still passing flags like <code>--exclude-should-panic</code> or disabling tests that require concurrency; you should be able to update those flags now.
Also note the breaking change in how <code>cargo miri</code> interprets CLI arguments below!</p>

<h3 id="randomness-and-hashmap">Randomness and <code>HashMap</code></h3>

<p>The Rust <code>HashMap</code> picks a new random seed for each execution.
This seed in obtained from the operating system, an operation which Miri did not support until @Aaron1011 implemented <code>getrandom</code> (<a href="https://github.com/rust-lang/miri/pull/683">#683</a>).
To ensure the same programs behaves the same way each time it is run by Miri, Miri internally uses a deterministic RNG (seeded with <code>0</code>, but that can be changed via <code>-Zmiri-seed</code>) to implement getrandom.
This PR also enabled Miri to be used with projects that use the <code>rand</code> crate for randomness.</p>

<p>However, this also means randomness in Miri is actually not random, so <em>do not use Miri to perform any important cryptographic operations</em>.</p>

<h3 id="unwinding">Unwinding</h3>

<p>Miri used to just abort program execution in case of a panic.
To better match the behavior of real Rust programs, @Aaron1011 implement proper unwinding support in Miri (<a href="https://github.com/rust-lang/miri/pull/693">#693</a>).
He even implemented catching panics again, which required aligning quite a few pieces across rustc, the standard library, and Miri itself.
This means Miri can finally also execute <code>#[should_panic]</code> tests.
Since recently, this is supported even for Windows targets.</p>

<h3 id="pointer-integer-casts">Pointer-integer casts</h3>

<p>Thanks to @christianpoveda, Miri now properly supports casting arbitrary pointers to integers and back (<a href="https://github.com/rust-lang/miri/pull/779">#779</a>).</p>

<p>Recently, I also adjusted the alignment check to fully take this information into account, so that Miri can now run code that performs its own alignment logic (<a href="https://github.com/rust-lang/miri/pull/1513">#1513</a>).
Notice however that this can lead to code that just happens to work by pure chance; to properly test such code, the test should be run at least 10 times.</p>

<h3 id="file-system-access">File system access</h3>

<p>@christianpoveda went on to implement file system access (this series of PRs started with <a href="https://github.com/rust-lang/miri/pull/962">#962</a>).
Later, @divergentdave improved that support with directory listing and some related operations (starting with <a href="https://github.com/rust-lang/miri/pull/1152">#1152</a>).
This means programs running in Miri can now read from and write to files on the host computer.
This is the first form of communication that we support between the interpreted program and the outside world.
Communication needs to be explicitly requested via <code>-Zmiri-disable-isolation</code>; by default, Miri isolates the program to ensure that each execution is perfectly reproducible.</p>

<p>File system access is only supported on Linux and macOS targets, but due to cross-interpretation this is not a problem even for Windows users – see the next point.</p>

<h3 id="cross-interpretation">Cross-interpretation</h3>

<p>Based on earlier work by @Aaron1011 who made Miri use check-only builds both for the standard library and the interpreted crate itself (<a href="https://github.com/rust-lang/miri/pull/1136">#1136</a>),
I made Miri support “cross-interpretation” (<a href="https://github.com/rust-lang/miri/pull/1249">#1249</a>).
This means even when you are on a Windows host, you can pass <code>--target x86_64-unknown-linux-gnu</code> so Miri will interpret the program <em>as if</em> it was running on Linux, in particular using all the Linux parts of the standard library for the interaction with the operating system.
Sine Miri supports the Linux APIs for file system access, it can interpret these programs even when running on a Windows host.</p>

<p>This is particularly useful when testing target features that differ from the host platform: for example, even on a 64bit macOS host, you can run programs for the 32bit Linux target (<code>--target i686-unknown-linux-gnu</code>), making sure your logic works for different pointer sizes.
Miri also supports big-endian targets like <code>--target mips64-unknown-linux-gnuabi64</code>, so if your code is endianess-sensitive, you can test if it behaves correctly on big-endian systems.
And finally cross-interpretation was enormously helpful for developing Miri itself; for example, I relied on this when fixing up our panic and unwinding support for Windows targets.</p>

<h3 id="concurrency">Concurrency</h3>

<p>Earlier this year, @vakaras surprised me by suddenly showing up with a series of patches that equip Miri with support for concurrency (<a href="https://github.com/rust-lang/miri/pull/1284">#1284</a>).
This is work he did during an internship with Amazon, so also thank you to Amazon for sponsoring this work!
Now Miri programs can spawn threads and interact via locks or atomics.
There are some caveats though: Miri does not detect data races, so programs with incorrect synchronization can cause Undefined Behavior through data races without Miri noticing.
Also Miri’s scheduler is rather crude, so programs can be stuck in infinite loops under some circumstances.</p>

<h3 id="better-cargo-compatibility-breaking-change">Better <code>cargo</code> compatibility (breaking change!)</h3>

<p>Recently, I mostly re-wrote the main entry point for users to execute programs in Miri, <code>cargo miri</code> (<a href="https://github.com/rust-lang/miri/pull/1540">#1540</a>).
It is now more compatible with cargo itself: <code>cargo test</code> and <code>cargo miri test</code> support the exact same flags, and likewise for <code>cargo run</code> and <code>cargo miri run</code>.</p>

<p>However, this required a breaking change: previously, the way to pass flags to Miri itself and the program when executing the test suite was <code>cargo miri test -- &lt;miri flags&gt; -- &lt;test suite flags&gt;</code>.
Now flags are passed via <code>cargo miri test -- &lt;test suite flags&gt;</code> like they are with <code>cargo test</code>; if you need to pass flags to Miri, you can set the <code>MIRIFLAGS</code> variable which works like <code>RUSTFLAGS</code>.
I also removed support for <code>cargo miri</code> without further arguments, which used to be an alias for <code>cargo miri run</code>.
The reason is that (a) <code>cargo miri test</code> is actually used much more frequently and (b) disambiguating these options while also supporting arbitrary flags is tricky.</p>

<p>If you have set up your CI to run tests in Miri, please make sure to adjust your configuration to the new format.
For now, Miri still supports the old style (and emits an appropriate warning), but the intention is to remove that support code eventually.
If your project is hosted on GitHub and is affected by the change, you should have already received a notification from me, but I might have missed some projects and of course not everything is on GitHub.
While at it, you can also remove <code>cargo miri setup</code> from your CI script; that is no longer needed as thanks to @dtolnay Miri automatically detects when it runs on CI and goes into non-interactive mode.</p>

<h3 id="-and-more">… and more</h3>

<p>This list is by far not exhaustive.
Many small functions, from trigonometry to environment variable access to timekeeping, have been implemented over the last months, ever growing the range of programs that Miri can execute.
Thank you to @Aaron1011, @christianpoveda, @divergentdave, @JOE1994, and @samrat!
I hope I did not miss anyone…</p>

<h2 id="using-miri">Using Miri</h2>

<p>If this post made you curious and you want to give Miri a try, here’s how to do that.
Assuming you have a crate with some unsafe code, and you already have a test suite (you are testing your unsafe code, right?), you can just install Miri (<code>rustup +nightly component add miri</code>) and then run <code>cargo +nightly miri test</code> to execute all tests in Miri (except for doctests, which are not supported yet).
Note that this requires the nightly toolchain as Miri is still an experimental tool.</p>

<p>Miri is very slow, so it is likely that some tests will take way too long to be feasible.
You can adjust iteration counts in Miri without affecting non-Miri testing as follows:</p>

<figure><pre><code data-lang="rust"><span>let</span> <span>limit</span> <span>=</span> <span>if</span> <span>cfg!</span><span>(</span><span>miri</span><span>)</span> <span>{</span> <span>10</span> <span>}</span> <span>else</span> <span>{</span> <span>10_000</span> <span>};</span></code></pre></figure>

<p>If your test suite needs to access OS facilities such as timers or the file system, set <code>MIRIFLAGS=-Zmiri-disable-isolation</code> to enable those.
(Miri will tell you when that is necessary.)
If your test suite runs into an unsupported operation, please <a href="https://github.com/rust-lang/miri/issues">report an issue</a>.</p>

<p>If you want to add Miri to your CI to ensure your test suite keeps working in Miri, please consult our <a href="https://github.com/rust-lang/miri/#running-miri-on-ci">README</a>.
That document is also a great starting point for any other questions you might have.</p>

<p>Miri is also integrated into the <a href="https://play.rust-lang.org/">Rust Playground</a>: you can select Miri in the “Tools” menu to check the code for Undefined Behavior.</p>

<p>If Miri complains about your code and you do not understand why, I am happy to help!
The best places to ask probably are Zulip (the #general stream seems fine), and the Miri issue tracker.
Asking publicly is strongly encouraged so other people can help answer the question, and everyone can learn from the responses.
Questions are much easier to answer if you manage to reproduce the problem in a small self-contained bit of example …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ralfj.de/blog/2020/09/28/miri.html">https://www.ralfj.de/blog/2020/09/28/miri.html</a></em></p>]]>
            </description>
            <link>https://www.ralfj.de/blog/2020/09/28/miri.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660216</guid>
            <pubDate>Fri, 02 Oct 2020 07:58:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Progress report on rustc_codegen_cranelift (Sep 2020)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24660154">thread link</a>) | @lukastyrychtr
<br/>
October 2, 2020 | https://bjorn3.github.io/2020/09/28/progress-report-sep-2020.html | <a href="https://web.archive.org/web/*/https://bjorn3.github.io/2020/09/28/progress-report-sep-2020.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><a href="https://github.com/bjorn3/rustc_codegen_cranelift">Rustc_codegen_cranelift</a> (cg_clif) is an alternative backend for rustc that I have been working on for the past two years. It uses the Cranelift code generator. Unlike LLVM which is optimized for output quality at the cost of compilation speed even when optimizations are disabled, Cranelift is optimized for compilation speed while producing executables that are almost as fast as LLVM with optimizations disabled. This has the potential to reduce the compilation times of rustc in debug mode.</p>

<p>I recently looked back at the <a href="https://hackmd.io/VnVX5bEHR268SDH4R7izLw">notes</a> for the <a href="https://rust-lang.zulipchat.com/#narrow/stream/131828-t-compiler/topic/design.20meeting.202020-04-03.20compiler-team.23257/near/192806450">design meeting</a> (<a href="https://github.com/rust-lang/compiler-team/issues/257">meeting proposal</a>) about integrating cg_clif into rustc. I noticed that several of the challenges that needed to be solved have since been solved. Because of this I decided to give an overview of the achievements in the past six months and what the current challenges are.</p>



<h4 id="tada-building-rustc-tada">
<img title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"> Building rustc <img title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20">
</h4>

<p>Fixing an ABI incompatibility for proc-macros (see next section) combined with several small fixes to the 128bit support made it possible to compile rustc using cg_clif.</p>

<ul>
  <li>issue <a href="https://github.com/bjorn3/rustc_codegen_cranelift/issues/743">#743</a>: Compile rustc using cg_clif</li>
  <li>commit <a href="https://github.com/bjorn3/rustc_codegen_cranelift/commit/cd684e39e0d27513d21f15e7cc65273ec5883e1b">cd684e3</a>: Fix saturated_* intrinsics for 128bit ints</li>
  <li>commit <a href="https://github.com/bjorn3/rustc_codegen_cranelift/commit/ef4186a85b4c9bd94d258e3280cb239f26b8436e">ef4186a</a>: Use Cranelift legalization for icmp.i128</li>
  <li>commit <a href="https://github.com/bjorn3/rustc_codegen_cranelift/commit/8d639cd778bb11fed2c230d8071664e24d30a84f">8d639cd</a>: Test signed 128bit discriminants</li>
  <li>commit <a href="https://github.com/bjorn3/rustc_codegen_cranelift/commit/e87651c3f23e6ad63cc1ee359115ad72e50d3ba9">e87651c</a>: Add test for SwitchInt on 128bit integers</li>
</ul>

<h4 id="abi-compatibility">ABI compatibility</h4>

<p>Proc-macro support has been implemented by fixing an ABI incompatibility.</p>

<ul>
  <li>
<a href="https://github.com/bjorn3/rustc_codegen_cranelift/pull/1068">#1068</a>: Pass ByRef values at fixed stack offset for extern “C”</li>
  <li>
<a href="https://github.com/bytecodealliance/wasmtime/pull/1559">wasmtime#1559</a>: SystemV struct arguments</li>
</ul>

<h4 id="inline-assembly">Inline assembly</h4>

<p>The new style <code>asm!</code> inline assembly and <code>global_asm!</code> have been implemented on Linux by compiling a separate object file using an assembler and linking the main object file for the codegen unit and the assembly object file together. On macOS linking both object files together gives a linker error. Linking both object files together is necessary as rustc expects a single object file for each codegen unit.</p>

<ul>
  <li>
<a href="https://github.com/bjorn3/rustc_codegen_cranelift/pull/1062">#1062</a>: Implement global_asm! using an external assembler</li>
  <li>
<a href="https://github.com/bjorn3/rustc_codegen_cranelift/pull/1064">#1064</a>: Basic inline asm support</li>
</ul>

<h4 id="simd">SIMD</h4>

<p>The cpuid x86 instruction is now emulated using code that pretends the current CPU is an Intel cpu with SSE and SSE2 support. This fixes ppv-lite86 and by extension c2-chacha and rand. It is not yet possible to use the inline assembly support as corearch uses <code>llvm_asm!</code> for the cpuid invocation. I didn’t implement this as it is currently being replaced with <code>asm!</code>.</p>

<ul>
  <li>
<a href="https://github.com/bjorn3/rustc_codegen_cranelift/pull/1070">#1070</a>: Emulate cpuid</li>
</ul>

<p>Stdarch has been changed to use constify on all x86 intrinsics that use <code>rustc_args_required_const</code>. This was necessary to support <code>simd_insert</code> and <code>simd_extract</code> based intrinsics.</p>

<ul>
  <li>
<a href="https://github.com/rust-lang/stdarch/pull/876">stdarch#876</a>: Constify all x86 rustc_args_required_const intrinsics</li>
  <li>issue <a href="https://github.com/bjorn3/rustc_codegen_cranelift/issues/669">#669</a>: Support simd_insert platform intrinsic</li>
</ul>

<h4 id="fixing-linking-with-lld-and-sysroot-and-executable-size">Fixing linking with lld and sysroot and executable size</h4>

<p>I assumed the sysroot and executables are much bigger for cg_clif than cg_llvm because of missing optimizations. While fixing linking with lld I discovered that for executables most of this is caused by per function sections not being used by cg_clif. Using this does significantly reduce the size of executables at the cost of significantly slowing down the linker. For this reason I put it behind the <code>CG_CLIF_FUNCTION_SECTIONS</code> env var.</p>

<ul>
  <li>
<a href="https://github.com/bjorn3/rustc_codegen_cranelift/pull/1083">#1083</a>: Fix lld</li>
  <li>
<a href="https://github.com/bytecodealliance/wasmtime/pull/2212">wasmtime#2212</a>: Fix relocated readonly data in custom sections</li>
  <li>
<a href="https://github.com/bytecodealliance/wasmtime/pull/2218">wasmtime#2218</a>: cranelift-object: Support per function sections</li>
</ul>

<h4 id="unsized-locals">Unsized locals</h4>

<p>rust#77170 changed the MIR of <code>&lt;Box&lt;F&gt; as FnOnce&gt;::call_once</code> such that it doesn’t need an alloca anymore. 27a46ff removed the hack to workaround the missing alloca support for this.</p>

<ul>
  <li>commit <a href="https://github.com/bjorn3/rustc_codegen_cranelift/commit/27a46ff765c26eab7b1e1f7d419cec8f5051df00">27a46ff</a>: Rustup to rustc 1.44.0-nightly (45d050cde 2020-04-21)</li>
  <li>
<a href="https://github.com/rust-lang/rust/pull/71170">rust#71170</a>: Make <code>Box&lt;dyn FnOnce&gt;</code> respect self alignment</li>
</ul>

<h4 id="rust-test-suite">Rust test suite</h4>

<p>There has been significant improvements on the amount of passing rustc tests with the previously mentioned #1068 fixing 82 tests. Except for abi incompatibilities all miscompilations seem to be fixed. There are some unimplemented features, but those are not very important for most use cases.</p>

<ul>
  <li>issue <a href="https://github.com/bjorn3/rustc_codegen_cranelift/issues/381">#381</a>: Make rustc test suite pass</li>
</ul>



<h2 id="simd-1">SIMD</h2>

<p>Many intrinsics remain unimplemented.</p>

<ul>
  <li>issue <a href="https://github.com/bjorn3/rustc_codegen_cranelift/issues/171">#171</a>: std::arch SIMD intrinsics</li>
</ul>

<h4 id="abi-compatibility-1">ABI compatibility</h4>

<p>There are many remaining ABI incomptibilities. I will need to rework cg_clif to reuse <code>rustc_target::abi::call::FnAbi</code>.</p>

<ul>
  <li>
<a href="https://github.com/bjorn3/rustc_codegen_cranelift/issues/10">#10</a>: C abi compatability</li>
</ul>

<h4 id="cleanup-during-stack-unwinding-on-panics">Cleanup during stack unwinding on panics</h4>

<p>Cranelift currently doesn’t have support for cleanup during stack unwinding.</p>

<ul>
  <li>
<a href="https://github.com/bytecodealliance/wasmtime/issues/1677">wasmtime#1677</a>: Support cleanup during unwinding</li>
</ul>

<h4 id="atomics">Atomics</h4>

<p>Atomic instructions are currently emulated using a global lock. This is very inefficient and only works when pthreads is available. The new style backend for Cranelift support native atomic instructions. There are several missing features before I can switch cg_clif to use the new style backends.</p>

<ul>
  <li>
<a href="https://github.com/bytecodealliance/wasmtime/pull/2077">wasmtime#2077</a>: Implement Wasm Atomics for Cranelift/newBE/aarch64.</li>
  <li>
<a href="https://github.com/bytecodealliance/wasmtime/pull/2149">wasmtime#2149</a>: This patch fills in the missing pieces needed to support wasm atomics…</li>
</ul>

<h4 id="windows-support">Windows support</h4>

<p>Various issues</p>

<ul>
  <li>
<a href="https://github.com/bjorn3/rustc_codegen_cranelift/issues/977">#997</a>: Windows support</li>
  <li>branch <a href="https://github.com/bjorn3/rustc_codegen_cranelift/compare/wip_windows_support">wip_windows_support</a>
</li>
</ul>

<h4 id="git-subtree"><code>git subtree</code></h4>

<p>The plan for integration with rustc was to use <code>git subtree</code>. This git command currently has a bug for which a fix has not yet been upstreamed. It would be nice if for example <code>git submodule</code> could be used for the time being instead.</p>

<ul>
  <li>
<a href="https://github.com/rust-lang/rust-clippy/issues/5565">rust-clippy#5565</a>: git subtree crashes: can’t sync rustc clippy changes into rust-lang/rust-clippy</li>
  <li>
<a href="https://github.com/rust-lang/compiler-team/issues/270">compiler-team#270</a>: Integration of the Cranelift backend with rustc</li>
</ul>

<h4 id="maintenance">Maintenance</h4>

<p>While there have been several PR’s by other people like @osa1, @vi, @spastorino and @CohenArthur, I am the only person who has contributed more than a few changes to cg_clif.</p>

<ul>
  <li><a href="https://github.com/bjorn3/rustc_codegen_cranelift/pulls?q=is%3Apr+is%3Aclosed+-author%3Aapp%2Fdependabot-preview">https://github.com/bjorn3/rustc_codegen_cranelift/pulls?q=is%3Apr+is%3Aclosed+-author%3Aapp%2Fdependabot-preview</a></li>
</ul>



<p>The easiest way to help is by trying to compile and run any project and reporting any issues. You could also try to fix one of the above issues or any other issues in the issue tracker. They are not easy though. Contributing to Cranelift will also help with cg_clif.</p>



<p>I would like to thank each and every person that has supported me while working on cg_clif for the past 2 years. Whether by contributing, donating or simply mentioning cg_clif.</p>

<p>I would also like to thank @eddyb and @cfallin for reviewing a draft of this post.</p>

  </div>

</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://bjorn3.github.io/2020/09/28/progress-report-sep-2020.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660154</guid>
            <pubDate>Fri, 02 Oct 2020 07:49:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Google Collapsed]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24659499">thread link</a>) | @partingshots
<br/>
October 1, 2020 | https://dcj.dev/how-google-collapsed | <a href="https://web.archive.org/web/*/https://dcj.dev/how-google-collapsed">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://dcj.dev/how-google-collapsed</link>
            <guid isPermaLink="false">hacker-news-small-sites-24659499</guid>
            <pubDate>Fri, 02 Oct 2020 06:17:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust programming language exploit mitigations]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24659489">thread link</a>) | @lukastyrychtr
<br/>
October 1, 2020 | https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/ | <a href="https://web.archive.org/web/*/https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>By  on <time itemprop="datePublished" datetime="2020-09-16T00:00:00-07:00">September 16, 2020</time>. <a href="https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/#disqus_thread" data-disqus-identifier="/2020/09/16/rust-lang-exploit-mitigations/"></a></p><div itemprop="articleBody">
    <p>The Rust programming language provides memory[1] and thread[2] safety
guarantees via its ownership[3], references and borrowing[4], and slice
types[5] features. However, Unsafe Rust[6] introduces unsafe blocks, unsafe
functions and methods, unsafe traits, and new types that are not subject to
the borrowing rules.</p>

<p>Parts of the Rust standard library are implemented as safe abstractions over
unsafe code (and historically have been vulnerable to memory corruption[7]).
Furthermore, the Rust code and documentation encourage creating safe
abstractions over unsafe code. This can cause a false sense of security if
unsafe code is not properly reviewed and tested.</p>

<p>Unsafe Rust introduces features that do not provide the same memory and
thread safety guarantees. This causes programs or libraries to be
susceptible to memory corruption (CWE-119)[8] and concurrency issues
(CWE-557)[9]. Modern C and C++ compilers provide exploit mitigations to
increase the difficulty to exploit vulnerabilities resulting from these
issues. Therefore, the Rust compiler must also support these exploit
mitigations in order to mitigate vulnerabilities resulting from the use of
Unsafe Rust. This post is going to document these exploit mitigations and
how they apply to Rust.</p>

<h2 id="exploit-mitigations">Exploit mitigations</h2>

<p>This section documents the exploit mitigations applicable to the Rust
compiler when building programs for the Linux operating system on the AMD64
architecture and equivalent.<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> All examples in this section were
built using the Rust compiler version 1.40.0 (2019-12-19) on Debian testing
(Bullseye).</p>

<p>The Rust Programming Language currently has no specification. The Rust
compiler (i.e., rustc) is the language reference implementation. All
references to “the Rust compiler” in this post refer to the language
reference implementation.</p>

<p>Table I <br>
Summary of exploit mitigations supported by the Rust compiler when building
programs for the Linux operating system on the AMD64 architecture and
equivalent.</p>
<table>
  <tbody><tr>
   <td><strong>Exploit mitigation</strong>
   </td>
   <td><strong>Supported and enabled by default</strong>
   </td>
   <td><strong>Since</strong>
   </td>
  </tr>
  <tr>
   <td>Position-independent executable
   </td>
   <td>Yes
   </td>
   <td>0.12.0 (2014-10-09)
   </td>
  </tr>
  <tr>
   <td>Integer overflow checks
   </td>
   <td>Yes (enabled when debug assertions are enabled, and disabled when debug assertions are disabled)
   </td>
   <td>1.1.0 (2015-06-25)
   </td>
  </tr>
  <tr>
   <td>Non-executable memory regions
   </td>
   <td>Yes
   </td>
   <td>1.8.0 (2016-04-14)
   </td>
  </tr>
  <tr>
   <td>Stack clashing protection
   </td>
   <td>Yes
   </td>
   <td>1.20.0 (2017-08-31)
   </td>
  </tr>
  <tr>
   <td>Read-only relocations and immediate binding
   </td>
   <td>Yes
   </td>
   <td>1.21.0 (2017-10-12)
   </td>
  </tr>
  <tr>
   <td>Heap corruption protection
   </td>
   <td>Yes
   </td>
   <td>1.32.0 (2019-01-17) (via operating system default or specified allocator)
   </td>
  </tr>
  <tr>
   <td>Stack smashing protection
   </td>
   <td>No
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>Forward-edge control flow protection
   </td>
   <td>No
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>Backward-edge control flow protection (e.g., shadow and safe stack)
   </td>
   <td>No
   </td>
   <td>
   </td>
  </tr>
</tbody></table>

<p id="fn:1">1. See
<a href="https://github.com/rust-lang/rust/tree/master/compiler/rustc_target/src/spec">https://github.com/rust-lang/rust/tree/master/compiler/rustc_target/src/spec</a>
for a list of targets and their default options. <a href="#fnref:1" role="doc-backlink">↩</a></p>

<h3 id="position-independent-executable">Position-independent executable</h3>

<p>Position-independent executable increases the difficulty of the use of code
reuse exploitation techniques, such as return-oriented programming (ROP) and
variants, by generating position-independent code for the executable, and
instructing the dynamic linker to load it similarly to a shared object at a
random load address, thus also benefiting from address-space layout
randomization (ASLR). This is also referred to as “full ASLR”.</p>

<p>The Rust compiler supports position-independent executable, and enables it
by default since version 0.12.0 (2014-10-09)[10]–[13].</p>

<div><div><pre><code>$ readelf -h target/release/hello-rust | grep Type:
  Type:                              DYN (Shared object file)
</code></pre></div></div>
<p>Fig. 1. Checking if an executable is a position-independent executable.</p>

<p>An executable with an object type of <code>ET_DYN</code> (i.e., shared object) and not
<code>ET_EXEC</code> (i.e., executable) is a position-independent executable (see Fig.
1).</p>

<h3 id="integer-overflow-checks">Integer overflow checks</h3>

<p>Integer overflow checks protects programs from undefined and unintended
behavior (which may cause vulnerabilities) by checking for results of signed
and unsigned integer computations that cannot be represented in their type,
resulting in an overflow or wraparound.</p>

<p>The Rust compiler supports integer overflow checks, and enables it when
debug assertions are enabled since version 1.0.0 (2015-05-15)[14]–[17], but
support for it was not completed until version 1.1.0 (2015-06-25)[16]. An
option to control integer overflow checks was later stabilized in version
1.17.0 (2017-04-27)[18]–[20].</p>

<div><div><pre><code><span>fn</span> <span>main</span><span>()</span> <span>{</span>
    <span>let</span> <span>u</span><span>:</span> <span>u8</span> <span>=</span> <span>255</span><span>;</span>
    <span>println!</span><span>(</span><span>"u: {}"</span><span>,</span> <span>u</span> <span>+</span> <span>1</span><span>);</span>
<span>}</span>
</code></pre></div></div>
<p>Fig. 2. hello-rust-integer program.</p>

<div><div><pre><code>$ cargo run
   Compiling hello-rust-integer v0.1.0 (/home/rcvalle/hello-rust-integer)
    Finished dev [unoptimized + debuginfo] target(s) in 0.23s
     Running `target/debug/hello-rust-integer`
thread 'main' panicked at 'attempt to add with overflow', src/main.rs:3:23
note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace.
</code></pre></div></div>
<p>Fig. 3. Build and execution of hello-rust-integer with debug assertions
enabled.</p>

<div><div><pre><code>$ cargo run --release
   Compiling hello-rust-integer v0.1.0 (/home/rcvalle/hello-rust-integer)
    Finished release [optimized] target(s) in 0.23s
     Running `target/release/hello-rust-integer`
u: 0
</code></pre></div></div>
<p>Fig. 4. Build and execution of hello-rust-integer with debug assertions
disabled.</p>

<p>Integer overflow checks are enabled when debug assertions are enabled (see
Fig. 3), and disabled when debug assertions are disabled (see Fig. 4). To
enable integer overflow checks independently, use the option to control
integer overflow checks, scoped attributes, or explicit checking methods
such as <code>checked_add</code><sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>.</p>

<p>It is recommended that explicit wrapping methods such as <code>wrapping_add</code> be
used when wrapping semantics are intended, and that explicit checking and
wrapping methods always be used when using Unsafe Rust.</p>

<p id="fn:2">2. See <a href="https://doc.rust-lang.org/std/primitive.u32.html">https://doc.rust-lang.org/std/primitive.u32.html</a> for more
information on the checked, overflowing, saturating, and wrapping methods
(using u32 as an example). <a href="#fnref:2" role="doc-backlink">↩</a></p>

<h3 id="non-executable-memory-regions">Non-executable memory regions</h3>

<p>Non-executable memory regions increase the difficulty of exploitation by
limiting the memory regions that can be used to execute arbitrary code. Most
modern processors provide support for the operating system to mark memory
regions as non executable, but it was previously emulated by software, such
as in grsecurity/PaX’s
<a href="https://pax.grsecurity.net/docs/pageexec.txt">PAGEEXEC</a> and
<a href="https://pax.grsecurity.net/docs/segmexec.txt">SEGMEXEC</a>, on processors that
did not provide support for it. This is also known as “No Execute (NX) Bit”,
“Execute Disable (XD) Bit”, “Execute Never (XN) Bit”, and others.</p>

<p>The Rust compiler supports non-executable memory regions, and enables it by
default since its initial release, version 0.1 (2012-01-20)[21], [22], but
has regressed since then[23]–[25], and enforced by default since version
1.8.0 (2016-04-14)[25].</p>

<div><div><pre><code>$ readelf -l target/release/hello-rust | grep -A 1 GNU_STACK
  GNU_STACK      0x0000000000000000 0x0000000000000000 0x0000000000000000
                 0x0000000000000000 0x0000000000000000  RW     0x10
</code></pre></div></div>
<p>Fig. 5. Checking if non-executable memory regions are enabled for a given
binary.</p>

<p>The presence of an element of type <code>PT_GNU_STACK</code> in the program header
table with the <code>PF_X</code> (i.e., executable) flag unset indicates non-executable
memory regions<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup> are enabled for a given binary (see Fig. 5).
Conversely, the presence of an element of type <code>PT_GNU_STACK</code> in the program
header table with the <code>PF_X</code> flag set or the absence of an element of type
<code>PT_GNU_STACK</code> in the program header table indicates non-executable memory
regions are not enabled for a given binary.</p>

<p id="fn:3">3. See the Appendix section for more information on why it affects other
memory regions besides the stack. <a href="#fnref:3" role="doc-backlink">↩</a></p>

<h3 id="stack-clashing-protection">Stack clashing protection</h3>

<p>Stack clashing protection protects the stack from overlapping with another
memory region—allowing arbitrary data in both to be overwritten using each
other—by reading from the stack pages as the stack grows to cause a page
fault when attempting to read from the guard page/region. This is also
referred to as “stack probes” or “stack probing”.</p>

<p>The Rust compiler supports stack clashing protection via stack probing, and
enables it by default since version 1.20.0 (2017-08-31)[26]–[29].</p>

<p><img src="https://rcvalle.blog/assets/2020/09/16/rust-lang-exploit-mitigations/image1.png" alt="Screenshot listing cross references to __rust_probestack in hello-rust." title="Cross references to __rust_probestack in hello-rust.">
Fig. 6. Cross references to <code>__rust_probestack</code> in hello-rust.</p>

<div><div><pre><code><span>fn</span> <span>hello</span><span>()</span> <span>{</span>
    <span>println!</span><span>(</span><span>"Hello, world!"</span><span>);</span>
<span>}</span>

<span>fn</span> <span>main</span><span>()</span> <span>{</span>
    <span>let</span> <span>_</span><span>:</span> <span>[</span><span>u64</span><span>;</span> <span>1024</span><span>]</span> <span>=</span> <span>[</span><span>0</span><span>;</span> <span>1024</span><span>];</span>
    <span>hello</span><span>();</span>
<span>}</span>
</code></pre></div></div>
<p>Fig 7. Modified hello-rust.</p>

<p><img src="https://rcvalle.blog/assets/2020/09/16/rust-lang-exploit-mitigations/image2.png" alt="Screenshot listing cross references to __rust_probestack in modified hello-rust." title="Cross references to __rust_probestack in modified hello-rust.">
Fig. 8. Cross references to <code>__rust_probestack</code> in modified hello-rust.</p>

<p>To check if stack clashing protection is enabled for a given binary, search
for cross references to <code>__rust_probestack</code>. The <code>__rust_probestack</code> is
called in the prologue of functions whose stack size is larger than a page
size (see Fig. 6), and can be forced for illustration purposes by modifying
the hello-rust example as seen in Fig. 7 and Fig. 8.</p>

<h3 id="read-only-relocations-and-immediate-binding">Read-only relocations and immediate binding</h3>

<p><strong>Read-only relocations</strong> protect segments containing relocations and
relocation information (i.e., <code>.init_array</code>, <code>.fini_array</code>, <code>.dynamic</code>, and
<code>.got</code>) from being overwritten by marking these segments read only. This is
also referred to as “partial RELRO”.</p>

<p>The Rust compiler supports read-only relocations, and enables it by default
since version 1.21.0 (2017-10-12)[30], [31].</p>

<div><div><pre><code>$ readelf -l target/release/hello-rust | grep GNU_RELRO
  GNU_RELRO      0x000000000002ee00 0x000000000002fe00 0x000000000002fe00
</code></pre></div></div>
<p>Fig. 9. Checking if read-only relocations is enabled for a given binary.</p>

<p>The presence of an element of type <code>PT_GNU_RELRO</code> in the program header
table indicates read-only relocations are enabled for a given binary (see
Fig. 9). Conversely, the absence of an element of type <code>PT_GNU_RELRO</code> in the
program header table indicates read-only relocations are not enabled for a
given binary.</p>

<p><strong>Immediate binding</strong> protects additional segments containing relocations
(i.e., <code>.got.plt</code>) from being overwritten by instructing the dynamic linker
to perform all relocations before transferring control to the program during
startup, so all segments containing relocations can be marked …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/">https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/</a></em></p>]]>
            </description>
            <link>https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24659489</guid>
            <pubDate>Fri, 02 Oct 2020 06:16:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Free Software Foundation gives developers money for their first GNU contribution]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24659354">thread link</a>) | @protontypes
<br/>
October 1, 2020 | https://gnucode.me/make-money-contributing-to-gnu.html | <a href="https://web.archive.org/web/*/https://gnucode.me/make-money-contributing-to-gnu.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>So, the truth is that I and <a href="https://rednosehacker.com/">Jeremy Korwin</a> hate
having money.  It is really quite annoying.  We have decided to get rid of some
of it, and we hope you will help us.</p><p>If you have been wanting to contribute to a GNU project, but did not know how,
then here is your chance.  I will pay you $1 (and Jeremy will pay 1€) for any
single contribution to any GNU project.  The only requirement, is that it has to
be your first contribution to that project.  Examples include:</p><ul><li>Your first commit to a GNU software project</li><li>Your first commit to a GNU manual</li><li>You contribute artwork that is accepted into a GNU project.</li><li>You commit a new package or update an existing one to a <a href="https://www.gnu.org/distros/free-distros.html">GNU
distro</a>.</li><li>You help translate a GNU package or manual</li><li>Improve h-node.org <a href="https://www.gnu.org/help/help.html#hnode">h-node.org</a></li><li>Improve <a href="https://libreplanet.org/wiki/Main_Page">libreplanet.org</a></li><li>You successfully <a href="https://www.gnu.org/philosophy/selling.html">sell</a> free software for the first time.</li><li>Start a free software blog.  I can <a href="https://gnucode.me/services.html">help with this</a>.</li><li>Write for the free software bulletin. Email <a href="mailto:info@fsf.org">info@fsf.org</a>.</li><li>Post a video on <a href="https://audio-video.gnu.org/">audio-video.gnu.org</a>.  You'll
need to email <a href="https://gnucode.me/campaigns@fsf.org">info@fsf.org</a>.</li><li>Switch to a completely <a href="https://www.gnu.org/distros/free-distros.html">free operating system</a>.</li><li>Add your program as <a href="https://www.gnu.org/help/evaluation.html">a GNU package</a>.</li><li>Write a Firefox extension that will replace the nonfree Javascript code of
some useful web site (when that nonfree code is blocked by LibreJS). Either
pick a site yourself, or ask for suggestions.  I hang out in <code>#guix</code> on irc.</li><li>Convince your University to release <a href="https://www.gnu.org/philosophy/university.html">your program as free
software</a>.</li><li>Join the <a href="http://www.gnu.org/people/webmeisters.html">GNU webmasters team</a>.</li><li>Improve <a href="https://www.gnu.org/server/tasks.html">gnu.org</a>.</li><li>List your company in the <a href="https://www.fsf.org/resources/service">FSF service
directory</a>.</li></ul><p>Please keep in mind, that we will need to be able to verify that this is your
first contribution to a specific GNU project.  Ideally, you will commit some
change to a software project, and we can use <code>git-log</code> to verify this is your
first commit to that project.</p><p>We are setting aside $90 and 90€ for this "Helping GNU" campaign.  First come,
first serve.  Email me at
<a href="mailto:jbranso+helping-gnu@dismail.de">jbranso+helping-gnu@dismail.de</a> when
your submission is done.</p><p>Your email should look something like:</p><pre><code>Hey Joshua and Jeremy!

So I contributed my first change to this GNU &lt;software project&gt;.
As you can see my email address is &lt;your email address&gt;.  You can verify that
this is my first submission to the GNU &lt;software project&gt; via this &lt;method&gt;.
You can pay me via paypal.  My email address is: &lt;email address&gt;.

Thanks,

Live long and prosper,

&lt;Your Name&gt;
I'm a rock star!
</code></pre><p>Live long and prosper.</p><p>P.S.  If you know of a better payment method, please let me know.  Jeremy is in
the E.U., and I am based in the U.S.</p></div></div>]]>
            </description>
            <link>https://gnucode.me/make-money-contributing-to-gnu.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24659354</guid>
            <pubDate>Fri, 02 Oct 2020 05:54:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Eight Falsehoods Programmers Believe About Map Coordinates]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24659039">thread link</a>) | @boyter
<br/>
October 1, 2020 | https://engineering.kablamo.com.au/posts/2020/falsehoods-about-map-coordinates | <a href="https://web.archive.org/web/*/https://engineering.kablamo.com.au/posts/2020/falsehoods-about-map-coordinates">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span>
      <span></span>
  <img alt="Mercator projection SW" title="Mercator projection SW" src="https://engineering.kablamo.com.au/static/e780902de4e676c5b62d7e1a4a139f42/72e01/Mercator_projection_SW.jpg" srcset="https://engineering.kablamo.com.au/static/e780902de4e676c5b62d7e1a4a139f42/e4a55/Mercator_projection_SW.jpg 256w,https://engineering.kablamo.com.au/static/e780902de4e676c5b62d7e1a4a139f42/36dd4/Mercator_projection_SW.jpg 512w,https://engineering.kablamo.com.au/static/e780902de4e676c5b62d7e1a4a139f42/72e01/Mercator_projection_SW.jpg 1024w,https://engineering.kablamo.com.au/static/e780902de4e676c5b62d7e1a4a139f42/ac99c/Mercator_projection_SW.jpg 1536w,https://engineering.kablamo.com.au/static/e780902de4e676c5b62d7e1a4a139f42/e1596/Mercator_projection_SW.jpg 2048w,https://engineering.kablamo.com.au/static/e780902de4e676c5b62d7e1a4a139f42/1cd85/Mercator_projection_SW.jpg 2058w" sizes="(max-width: 1024px) 100vw, 1024px" loading="lazy">
    </span>
(Map image by Daniel R. Strebe, licensed under CC BY-SA 3.0)</p><h2>1. The only projection that is important is Web Mercator</h2><p>While <a href="https://en.wikipedia.org/wiki/Web_Mercator_projection">Web Mercator</a> is
probably the most popular projection that most people will run into, the
<a href="https://en.wikipedia.org/wiki/Albers_projection">Albers</a> and
<a href="https://en.wikipedia.org/wiki/Lambert_cylindrical_equal-area_projection">Lambert</a>
equal-area projections are fairly common for when the projection needs to maintain
the area rather than the navigational direction (which is one of the main features
of the Mercator projection).</p><h2>2. All coordinates are latitude/longitude pairs</h2><p>In addition to latitude/longitude coordinates, <a href="https://en.wikipedia.org/wiki/Universal_Transverse_Mercator_coordinate_system">Universal Transverse Mercator (UTM)
coordinates</a>
are also fairly common. UTM splits the Earth into 60 zones, and then
further specifies northings and eastings in metres (as opposed to degrees, minutes and seconds).</p><p>The UTM notably omits the polar areas - which are covered by the <a href="https://en.wikipedia.org/wiki/Universal_polar_stereographic_coordinate_system">Universal Polar Stereographic (UPS)
coordinate system</a>
instead.</p><h2>3. Latitude always comes before longitude in a coordinate pair</h2><p>While it is common to see items in (latitude,longitude) order, some formats
(e.g. <a href="https://en.wikipedia.org/wiki/GeoJSON">GeoJSON</a>) dictate that coordinates
follow (longitude,latitude) order instead. This matches the typical way coordinates
are specified in a Cartesian coordinate system: (x,y).</p><h2>4. A degree of latitude or longitude always represents the same distance</h2><p>In the Mercator projection, the Earth - which, in reality, is an
<a href="https://en.wikipedia.org/wiki/Spheroid#Oblate_spheroids">oblate spheroid</a> -
is projected as a simple cylinder. This means that "parallel" longitude lines
meet at the poles, so the distance between degrees of longitude are much shorter
as they get closer to the poles than they are at the equator (~111 km).</p><p>The variance in latitude is not as large - but it still varies by about 1km going
from the equator to the poles.</p><h2>5. The shortest path between two points is a straight line</h2><p>The Earth isn't flat - as such, although your map may be projected to be flat,
the distance between two points needs to follow the curvature of
the Earth and can usually be approximated by the
<a href="https://en.wikipedia.org/wiki/Haversine_formula">Haversine formula</a>.</p><h2>6. Coordinates for a given landmark are always fixed</h2><p><a href="https://en.wikipedia.org/wiki/Continental_drift">Movements of the Earth's tectonic plates</a>
mean that the land masses are moving slowly with the passage of time.
For example, Australia has shifted about 1.8 metres from where it
was in 1994 (about 7 centimetres per year). This also means that <a href="http://www.ga.gov.au/scientific-topics/positioning-navigation/geodesy/datums-projections/gda2020">geocentric
datums</a>
have to be updated to account for these changes every once in a while.</p><h2>7. Given a pair of coordinates, you can plot it on a map</h2><p>In addition to coordinates, we also need to know the datum, which is
the coordinate system and its specific set of reference points on the Earth.
While most coordinates often follow the
<a href="https://en.wikipedia.org/wiki/World_Geodetic_System">WGS84 datum</a>,
care should be taken to ensure that the map and the coordinates plotted
are using the same datum.</p><h2>8. There is one global ellipsoid to base coordinates on</h2><p>Most modern datums are based on the WGS84
<a href="https://en.wikipedia.org/wiki/Ellipsoid">ellipsoid</a>
as the surveys are often completed using GPS as a reference, but notably
Russia and China still base their local datums on different reference ellipsoids.</p><p>As a result, conversions to and from datums based on different
ellipsoids may result in inaccuracies and deviations and may be of concern
if you have to deal with GPS, GLONASS, and BeiDou data at the same time.</p></div></div>]]>
            </description>
            <link>https://engineering.kablamo.com.au/posts/2020/falsehoods-about-map-coordinates</link>
            <guid isPermaLink="false">hacker-news-small-sites-24659039</guid>
            <pubDate>Fri, 02 Oct 2020 04:59:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Interview with Transport Tycoon creator Chris Sawyer]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24658958">thread link</a>) | @wizardfeet
<br/>
October 1, 2020 | https://lifeandtimes.games/episodes/files/28 | <a href="https://web.archive.org/web/*/https://lifeandtimes.games/episodes/files/28">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a href="https://pdcn.co/e/traffic.megaphone.fm/ADL8847793182.mp3" target="_blank">Click/tap here to download this episode.</a></p><p><a href="https://ratethispodcast.com/ltvg" target="_blank"><img src="https://storage.googleapis.com/rtp-assets/buttons/lifetimevideogames.png" width="198" height="56" alt="Rate This Podcast"></a></p>
<p><img alt="A screenshot of the main menu from Transport Tycoon for DOS" src="https://lifeandtimes.games/episodes/files/transport-tycoon-dos-screenshot-main-menu.png" width="276" height="212"></p><p>On the rise and, um...<em>fade out(?)</em> of Chris Sawyer, the genius creator of bestselling, critically-acclaimed simulation games Transport Tycoon and RollerCoaster Tycoon — who made a career out of working at the cutting-edge, in bare metal assembly code that he wrote and optimised (and optimised again) on his own.</p><p>Until the cutting-edge left him behind.</p><p><strong>Hello Hacker News readers! As of this update, the post there erroneously labels this as an interview. It's not. Chris doesn't do interviews, except via an intermediary (which doesn't really work in an audio format), so the story is based entirely on my in-depth research and analysis. I hope you still enjoy it and learn something interesting. (I have stories on many other things that do involve interviews, though, like </strong><strong><a href="https://lifeandtimes.games/episodes/files/27" title="Episodes:27 - Links">1990 golf game Links</a></strong><strong>, Bungie's </strong><strong><a href="https://lifeandtimes.games/episodes/files/25" title="Episodes:25 - Pimps at Sea">fake game Pimps at Sea</a></strong><strong>, and </strong><strong><a href="https://lifeandtimes.games/episodes/files/22" title="Episodes:22 - Wololo">the "Wololo" sound effect</a></strong><strong> from Age of Empires.)</strong></p><p>Chris was only a design consultant on 2004 game RollerCoaster Tycoon 3, but its remastered "Complete" edition has just come out on Nintendo Switch and the PC version is free on the Epic Games Store right now (until October 2). The original two games are also still sold via the likes of Steam and GOG.</p><p>Transport Tycoon, meanwhile, lives on in open-source project <a href="https://www.openttd.org/" target="_blank">OpenTTD</a> and in a mobile port (<a href="https://play.google.com/store/apps/details?id=com.thirtyonex.TransportTycoon&amp;hl=en_US" target="_blank">Android</a>, <a href="https://apps.apple.com/us/app/transport-tycoon/id634013256" target="_blank">iOS</a>) of the original game by Chris's company 31X. You can see a snippet of his source code in the image below:</p><div><p><img alt="cstg_code1" src="https://lifeandtimes.games/episodes/files/cstg_code1.jpg" width="1262" height="1775"></p></div><div><p>Thanks as always to my supporters on Patreon — especially my $10+ backers Carey Clanton, Rob Eberhardt, Simon Moss, Vivek Mohan, Wade Tregaskis, and Seth Robinson. If you'd like to become a supporter, for as little as $1 a month, head to <a href="https://www.patreon.com/lifeandtimesofvideogames">my Patreon page</a> and sign up. Or for one-off donations you can use <a href="https://paypal.me/mossrc">paypal.me/mossrc</a>.</p><p>Please remember to tell other people about the show, and to leave a review by following the links at <a href="https://ratethispodcast.com/ltvg">ratethispodcast.com/ltvg</a>.</p><p>I'm currently writing a new book called Shareware Heroes: Independent Games at the Dawn of the Internet. You can learn more and/or pre-order your copy <a href="https://unbound.com/books/shareware-heroes/" target="_blank">from Unbound</a>.</p></div><hr>
<h3>(Partial) Transcript</h3>
<p><strong><em>[Most episode transcripts/scripts are reserved for my Patreon supporters (at least for the time being), but I like to give you at least a taster here — or in this case, the first half of the episode.]</em></strong></p><p><em>Welcome to the Life and Times of Video Games, an audio series about video games and the video game industry, as they were in the past and how they’ve come to be the way they are today. I'm Richard Moss, and this is episode 28, Transport Tycoon, or the tale of the great optimiser and his two greatest works.</em></p><p>We’ll get going in just a moment. </p><p>*pause for pre-roll ad/cross-promo slot*</p><p>***</p><p>You may have heard the expression that every overnight sensation is a decade in the making — a decade of hard work, toiling in obscurity…or <em>relative</em> obscurity, honing a talent, perfecting a craft, <em>optimising</em> a skill set and envisioning whatever it is that breaks through.</p><p>In reality the actual duration is rarely a decade — it’s five years or eight years or eighteen years, or however long it takes for the pieces to all fall into place: the talent, timing, and product. But the idea bears repeating: the greatest accolades, the greatest achievements, the greatest games are the product of hard work built atop years of invisible labour.</p><p>And such it was that Chris Sawyer, like John Romero, Carol Shaw, Gunpei Yokoi, and many others before and since — such it was that in 1994 Chris Sawyer suddenly shifted from a little-known (though well-respected) figure in the games industry, a programmer who converted Amiga games to the PC, to become an industry icon.</p><p>Nineteen-ninety-four was the year when his first original game was published, the year when big-name PC game publisher Microprose put his transportation-focused business simulation game Transport Tycoon, an incredible solo development effort, in a box and sold it in stores to widespread acclaim. </p><p><img alt="SCR1" src="https://lifeandtimes.games/episodes/files/scr1.jpg" width="866" height="362"><br><em>Transport Tycoon, the game that made Chris Sawyer into a games industry icon (</em><em><a href="https://www.tt-forums.net/viewtopic.php?f=47&amp;t=29058" target="_blank">image source</a></em><em>)</em><br></p><div><p>The game itself had taken Chris just a year to develop, but the journey to making it had begun much earlier.</p><p>Chris had started programming as a teenager in 1981, largely out of curiosity, through trying to make things appear on the screen on a range of different computers he’d encountered. There was the Commodore PET at his high school, the Sinclair ZX81 demonstration unit in a W H Smiths store, and the Texas Instruments TI99/4A one of his neighbours owned, as well as the Commodore VIC-20 a different neighbour had. And eventually, after diligently saving up his pocket money, he’d become engrossed in a machine of his own, a Camputers Lynx, a now-forgotten, obscure-even-then 8-bit computer with fancier graphics and more horsepower than the leading systems of its day (the leading systems at the time being the Apple II, ZX Spectrum, and Commodore 64).</p><p>Here, in 1983, is where the journey really starts — where Chris set off towards the lands where he’d make his name. And I find it fascinating how serendipitous this was — for, you see, Chris’s two great successes, Transport Tycoon and RollerCoaster Tycoon, were both made possible by his phenomenal systems knowledge; by his immense capacity to hand-code complex interactions of data at low levels of abstraction.</p><p>And here is where he began to learn those skills, to internalise them to the point of becoming natural talents. He later told Arcade Attack in an interview that he’d not had access to an assembler for that Lynx computer, so when he’d wanted to move beyond coding in BASIC he’d needed to write his programs byte-by-byte in machine code — the lowest-level programming language, the numerical instructions that computers themselves use. And with scant resources available to teach him these skills, he mostly figured it out on his own, just trying different things until he got his ideas to work. Always chasing the next exhilarating breakthrough.</p><p>Chris continued to dabble in machine code, though somewhat less than before, when he upgraded to a similarly-obscure machine called the Memotech MTX500, which actually did come with a built-in assembler, which enabled him to write programs in the abbreviation-heavy Z80 assembly language. Programs that, beginning in 1984, he very often had published commercially.</p></div><p><img alt="Memotech_MTX500-wide" src="https://lifeandtimes.games/episodes/files/memotech_mtx500-wide.jpg" width="1020" height="584"><br><em>The Memotech MTX500 (</em><em><a href="https://en.wikipedia.org/wiki/File:Memotech_MTX500.jpg" target="_blank">Image source</a></em><em>)</em><br></p><div><p>Chris had sent Memotech cassette tapes of some games he’d made through copying the designs of popular titles, like Missile Kommand, which was the 1980 Atari arcade game converted to the capabilities of the MTX500, using a mix of BASIC and machine code, with the name intentionally misspelled (a ‘k’ rather than a ‘c’) as though that somehow made his unapologetic, blatant clone of another’s work okay. </p><p>But this was the wild west of the computer games business, and Memotech weren’t much concerned. Or at least their games guy Jim Wills wasn’t much concerned, neither at this point nor a few months later when he left to start a company called Megastar Games. Jim liked Chris’s work enough to publish it, for meagre royalties but invaluable experience. And so Chris was commercially published with his unlicensed MTX500 versions of Missile Command, Q*bert, Manic Miner, and a few others.</p><p>After high school he enrolled in a computer science and microprocessor systems degree, where he studied the fundamentals of both software and hardware design in computers — an experience he found invaluable, as it taught him how to push computers further by learning how their hardware worked. And it taught him the theories behind the sorts of nitty-gritty software-systems things he’d already been practising at home: optimisation, sorting, algorithms, and even more varieties of machine code.</p></div><p><img alt="escape-from-zarcos-memotech-mtx500" src="https://lifeandtimes.games/episodes/files/escape-from-zarcos-memotech-mtx500.png" width="1044" height="788"><em><br>Escape from Zarcos, Chris Sawyer clone of Manic Miner for the Memotech MTX500</em><br></p><div><p>At home, meanwhile, he’d shifted over to the Amstrad CPC, which technologically-speaking wasn’t hugely different to the Memotech system he’d been on before — but it was a modest upgrade, and unlike his previous computers it was actually a popular system. And for Chris it was a gateway to the PC, because in the course of studying at university and making computer games on the side he wound up getting an Amstrad-made IBM-PC clone.</p><p>Chris had during this period been getting his games published through Ariolasoft, a German company with a UK subsidiary that promised him a job programming games for them once he graduated. Except some promises can’t be kept, especially in an industry that moves as fast as computer games publishing.</p><p>The home computer business was by that point deep into its transition from 8-bit to 16-bit hardware, and that transition came with adjustments to the standard of game graphics and design required, and to the way marketing and sales worked, and the cost of publishing, and so on, and Ariolasoft wasn’t doing too well at managing the transition. </p><p>So Chris didn’t have a job waiting for him after all, and he’d missed out on all the great electronics engineering jobs his classmates applied for. (Oops!) But not to worry — he’d made enough connections and enough headway as a programmer that he could get himself a business agent, and that agent in turn connected him to the booming Amiga-to-PC games porting industry.</p><p>He later said he’d thought it a “stop-gap” measure, just “a bit of fun” while he looked for more permanent employment in the electronics industry. But Chris took to his new conversions work like a duck to water. The kid who’d had to get creative and remain patient to make anything work on his Camputers Lynx machine now excelled in an environment where he had to contend with the vast gap in multimedia capabilities between the Amiga and the PC.</p><p>PCs of the day were pathetically inept as games machines, compared to a system like the Amiga. Whereas the PC had just a CPU, and maybe, in a minority of machines, a dedicated sound card like the SoundBlaster 16, every Amiga came with a custom chipset that contained audio and video co-processors that could take some strain off the …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lifeandtimes.games/episodes/files/28">https://lifeandtimes.games/episodes/files/28</a></em></p>]]>
            </description>
            <link>https://lifeandtimes.games/episodes/files/28</link>
            <guid isPermaLink="false">hacker-news-small-sites-24658958</guid>
            <pubDate>Fri, 02 Oct 2020 04:45:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Jargon File]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24658797">thread link</a>) | @purec
<br/>
October 1, 2020 | http://jargon-file.org/archive/jargon-4.4.7.dos.txt | <a href="https://web.archive.org/web/*/http://jargon-file.org/archive/jargon-4.4.7.dos.txt">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://jargon-file.org/archive/jargon-4.4.7.dos.txt</link>
            <guid isPermaLink="false">hacker-news-small-sites-24658797</guid>
            <pubDate>Fri, 02 Oct 2020 04:12:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[線香花火 WebGL Japanese Sparkler]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24658771">thread link</a>) | @lioeters
<br/>
October 1, 2020 | https://tompng.github.io/senkouhanabi_gl/ | <a href="https://web.archive.org/web/*/https://tompng.github.io/senkouhanabi_gl/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://tompng.github.io/senkouhanabi_gl/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24658771</guid>
            <pubDate>Fri, 02 Oct 2020 04:07:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: How to compute a factorial with λ calculus in a post card]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24658404">thread link</a>) | @martyalain
<br/>
October 1, 2020 | http://lambdaway.free.fr/lambdawalks/?view=lambdafact | <a href="https://web.archive.org/web/*/http://lambdaway.free.fr/lambdawalks/?view=lambdafact">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://lambdaway.free.fr/lambdawalks/?view=lambdafact</link>
            <guid isPermaLink="false">hacker-news-small-sites-24658404</guid>
            <pubDate>Fri, 02 Oct 2020 03:10:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The (Not Failing) New York Times - How the NYT pivoted into subscription]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24658206">thread link</a>) | @ReallyFantastic
<br/>
October 1, 2020 | https://minesafetydisclosures.com/blog/newyorktimes | <a href="https://web.archive.org/web/*/https://minesafetydisclosures.com/blog/newyorktimes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="pageWrapper" role="main">
        <!-- CATEGORY NAV -->
        
      <section id="page">

      <div data-content-field="main-content">
        <article id="article-5f70e3da36b37d25b6fe92ee" data-item-id="5f70e3da36b37d25b6fe92ee">

  <!--SPECIAL CONTENT-->

  

  
  <!--POST HEADER-->
    
  <header>
    
    <div>
      <p><span><a href="https://minesafetydisclosures.com/blog/newyorktimes" title="Permalink"><time datetime="2020-10-01">October 01, 2020</time></a></span>
       in <span><a href="https://minesafetydisclosures.com/blog/category/Companies" rel="tag">Companies</a></span>
    </p></div>
  </header>
  
  
  <!--POST BODY-->

  <div><div data-layout-label="Post Body" data-type="item" data-updated-on="1601234027667" id="item-5f70e3da36b37d25b6fe92ee"><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1601572339034_143602"><div><p><strong>CLICK TO EXPAND</strong> (<a href="https://www.dropbox.com/s/qy3nfaxjiplmtcf/The%20%28Not%20Failing%29%20New%20York%20Times.pdf?dl=0">or download the PDF</a>)</p></div></div><div data-block-json="{&quot;transparentBackground&quot;:false,&quot;existingGallery&quot;:null,&quot;hSize&quot;:null,&quot;newWindow&quot;:true,&quot;floatDir&quot;:null,&quot;methodOption&quot;:&quot;transient&quot;,&quot;aspect-ratio&quot;:&quot;four-three&quot;,&quot;aspectRatio&quot;:null,&quot;auto-crop&quot;:false,&quot;autoplay&quot;:false,&quot;blockAnimation&quot;:&quot;none&quot;,&quot;collectionId&quot;:&quot;5f75feeb15e1c70b3500b2af&quot;,&quot;controls&quot;:true,&quot;design&quot;:&quot;grid&quot;,&quot;lightbox&quot;:true,&quot;lightboxTheme&quot;:&quot;dark&quot;,&quot;meta-position&quot;:&quot;bottom&quot;,&quot;padding&quot;:4,&quot;show-meta&quot;:true,&quot;show-meta-basic&quot;:true,&quot;show-meta-only-title&quot;:false,&quot;show-meta-only-description&quot;:false,&quot;show-meta-on-hover&quot;:false,&quot;square-thumbs&quot;:false,&quot;thumbnail-strip-height&quot;:130,&quot;thumbnail-strip-margin&quot;:20,&quot;thumbnails&quot;:true,&quot;thumbnails-per-row&quot;:3,&quot;vSize&quot;:null,&quot;transientGalleryId&quot;:&quot;5f75feeb15e1c70b3500b2af&quot;}" data-block-type="8" id="block-yui_3_17_2_1_1601554581161_153023"><div>




  

  


<div>
  <div>
    
      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568491898-QSKD151WV1V66SWF76RX/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.001.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568491898-QSKD151WV1V66SWF76RX/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.001.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568491898-QSKD151WV1V66SWF76RX/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.001.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.001.jpeg" data-load="false" data-image-id="5f75feebcd2d631e090d8ecf" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568491898-QSKD151WV1V66SWF76RX/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.001.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568491687-BUFX9ZE5GUJAGSBOVDB9/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.002.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568491687-BUFX9ZE5GUJAGSBOVDB9/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.002.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568491687-BUFX9ZE5GUJAGSBOVDB9/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.002.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.002.jpeg" data-load="false" data-image-id="5f75feeb0df493541c6b0f58" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568491687-BUFX9ZE5GUJAGSBOVDB9/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.002.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568491980-NS9879K140O4DB5H89E9/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.003.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568491980-NS9879K140O4DB5H89E9/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.003.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568491980-NS9879K140O4DB5H89E9/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.003.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.003.jpeg" data-load="false" data-image-id="5f75feeb753f9f3986c12f5b" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568491980-NS9879K140O4DB5H89E9/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.003.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568492756-KSFTPTJFGSP526MW1UKF/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.004.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568492756-KSFTPTJFGSP526MW1UKF/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.004.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568492756-KSFTPTJFGSP526MW1UKF/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.004.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.004.jpeg" data-load="false" data-image-id="5f75feec2b2362390706eb55" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568492756-KSFTPTJFGSP526MW1UKF/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.004.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568493267-8B3VVVKJ56OBBNJ2G96W/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.005.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568493267-8B3VVVKJ56OBBNJ2G96W/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.005.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568493267-8B3VVVKJ56OBBNJ2G96W/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.005.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.005.jpeg" data-load="false" data-image-id="5f75feec753f9f3986c13128" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568493267-8B3VVVKJ56OBBNJ2G96W/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.005.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568493207-7YR1TD6N9L1PKMK2N6FQ/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.006.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568493207-7YR1TD6N9L1PKMK2N6FQ/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.006.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568493207-7YR1TD6N9L1PKMK2N6FQ/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.006.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.006.jpeg" data-load="false" data-image-id="5f75feed0dd0c87c41a98128" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568493207-7YR1TD6N9L1PKMK2N6FQ/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.006.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568493555-9EF3RMHI4MF4OTXSGG8W/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.007.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568493555-9EF3RMHI4MF4OTXSGG8W/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.007.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568493555-9EF3RMHI4MF4OTXSGG8W/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.007.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.007.jpeg" data-load="false" data-image-id="5f75feedd134f3794caf0000" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568493555-9EF3RMHI4MF4OTXSGG8W/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.007.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568494053-VPDXKBOQ1BUKTW0ZKQFC/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.008.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568494053-VPDXKBOQ1BUKTW0ZKQFC/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.008.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568494053-VPDXKBOQ1BUKTW0ZKQFC/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.008.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.008.jpeg" data-load="false" data-image-id="5f75feed8036587780b953a7" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568494053-VPDXKBOQ1BUKTW0ZKQFC/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.008.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568494716-UHDI7FEBGQOVNR8SHMKV/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.009.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568494716-UHDI7FEBGQOVNR8SHMKV/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.009.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568494716-UHDI7FEBGQOVNR8SHMKV/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.009.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.009.jpeg" data-load="false" data-image-id="5f75feee0373414277bdfd7c" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568494716-UHDI7FEBGQOVNR8SHMKV/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.009.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568495258-UTWT4HEEUYA5KZKX6IVW/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.010.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568495258-UTWT4HEEUYA5KZKX6IVW/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.010.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568495258-UTWT4HEEUYA5KZKX6IVW/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.010.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.010.jpeg" data-load="false" data-image-id="5f75feef7a7dba1ef4d84dcc" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568495258-UTWT4HEEUYA5KZKX6IVW/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.010.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568496734-P4HP47QWQ6IRPH5JT74Q/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.011.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568496734-P4HP47QWQ6IRPH5JT74Q/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.011.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568496734-P4HP47QWQ6IRPH5JT74Q/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.011.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.011.jpeg" data-load="false" data-image-id="5f75feef15e1c70b3500b4a9" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568496734-P4HP47QWQ6IRPH5JT74Q/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.011.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568496800-PE3LOP4L3ZSMZYGXOE9X/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.012.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568496800-PE3LOP4L3ZSMZYGXOE9X/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.012.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568496800-PE3LOP4L3ZSMZYGXOE9X/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.012.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.012.jpeg" data-load="false" data-image-id="5f75feefcd2d631e090d8f05" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568496800-PE3LOP4L3ZSMZYGXOE9X/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.012.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568497147-28FKSZORBFDD17JLLSLJ/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.013.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568497147-28FKSZORBFDD17JLLSLJ/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.013.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568497147-28FKSZORBFDD17JLLSLJ/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.013.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.013.jpeg" data-load="false" data-image-id="5f75fef096d0d45d87873ae4" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568497147-28FKSZORBFDD17JLLSLJ/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.013.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568497521-EWBNLMCM0ZDZTK3XPZ8E/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.014.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568497521-EWBNLMCM0ZDZTK3XPZ8E/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.014.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568497521-EWBNLMCM0ZDZTK3XPZ8E/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.014.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.014.jpeg" data-load="false" data-image-id="5f75fef196d0d45d87873ae5" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568497521-EWBNLMCM0ZDZTK3XPZ8E/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.014.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568498130-H8QT1RS246K919X5SQRX/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.015.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568498130-H8QT1RS246K919X5SQRX/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.015.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568498130-H8QT1RS246K919X5SQRX/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.015.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.015.jpeg" data-load="false" data-image-id="5f75fef178c626590ead63bd" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568498130-H8QT1RS246K919X5SQRX/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.015.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568498473-EIHAUFRT6BG08IVZURSV/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.016.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568498473-EIHAUFRT6BG08IVZURSV/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.016.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568498473-EIHAUFRT6BG08IVZURSV/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.016.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.016.jpeg" data-load="false" data-image-id="5f75fef1cd2d631e090d90d5" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568498473-EIHAUFRT6BG08IVZURSV/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.016.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568498729-B330234GGXYLVBDU6130/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.017.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568498729-B330234GGXYLVBDU6130/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.017.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568498729-B330234GGXYLVBDU6130/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.017.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.017.jpeg" data-load="false" data-image-id="5f75fef20cb6f82db9374309" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568498729-B330234GGXYLVBDU6130/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.017.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568499948-VLV4587BFNX0LDWHIW4H/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.018.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568499948-VLV4587BFNX0LDWHIW4H/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.018.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568499948-VLV4587BFNX0LDWHIW4H/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.018.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.018.jpeg" data-load="false" data-image-id="5f75fef2fcfe7968a6c406c0" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568499948-VLV4587BFNX0LDWHIW4H/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.018.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568500013-N4BX21PST785J6FK8YEK/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.019.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568500013-N4BX21PST785J6FK8YEK/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.019.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568500013-N4BX21PST785J6FK8YEK/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.019.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.019.jpeg" data-load="false" data-image-id="5f75fef31158a96d1adab031" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568500013-N4BX21PST785J6FK8YEK/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.019.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568500821-X2OXQN1L8KR8THJ3QV5N/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.020.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568500821-X2OXQN1L8KR8THJ3QV5N/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.020.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568500821-X2OXQN1L8KR8THJ3QV5N/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.020.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.020.jpeg" data-load="false" data-image-id="5f75fef4a1b4e25ba6ac297c" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568500821-X2OXQN1L8KR8THJ3QV5N/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.020.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568500697-BM3FM16OOZIYBBE9KYYP/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.021.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568500697-BM3FM16OOZIYBBE9KYYP/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.021.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568500697-BM3FM16OOZIYBBE9KYYP/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.021.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.021.jpeg" data-load="false" data-image-id="5f75fef4a1b4e25ba6ac297f" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568500697-BM3FM16OOZIYBBE9KYYP/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.021.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568501352-S7J64XCV0X2P97ZP2NES/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.022.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568501352-S7J64XCV0X2P97ZP2NES/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.022.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568501352-S7J64XCV0X2P97ZP2NES/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.022.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.022.jpeg" data-load="false" data-image-id="5f75fef5883c6055aa1defb2" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568501352-S7J64XCV0X2P97ZP2NES/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.022.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568501618-3E7W4Z1STCOJP5NOISTX/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.023.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568501618-3E7W4Z1STCOJP5NOISTX/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.023.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568501618-3E7W4Z1STCOJP5NOISTX/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.023.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.023.jpeg" data-load="false" data-image-id="5f75fef52b2362390706f660" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568501618-3E7W4Z1STCOJP5NOISTX/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.023.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568501743-XFRV55E2U72DOREBV745/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.024.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568501743-XFRV55E2U72DOREBV745/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.024.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568501743-XFRV55E2U72DOREBV745/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.024.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.024.jpeg" data-load="false" data-image-id="5f75fef59993bf06c4e0fd0b" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568501743-XFRV55E2U72DOREBV745/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.024.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568502651-A0BJQXLUEU8MH8TU1YEU/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.025.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568502651-A0BJQXLUEU8MH8TU1YEU/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.025.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568502651-A0BJQXLUEU8MH8TU1YEU/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.025.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.025.jpeg" data-load="false" data-image-id="5f75fef50dd0c87c41a983ae" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568502651-A0BJQXLUEU8MH8TU1YEU/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.025.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568502122-XIO1PMT8VIJMWAT5OZY4/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.026.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568502122-XIO1PMT8VIJMWAT5OZY4/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.026.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568502122-XIO1PMT8VIJMWAT5OZY4/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.026.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.026.jpeg" data-load="false" data-image-id="5f75fef51158a96d1adab04e" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568502122-XIO1PMT8VIJMWAT5OZY4/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.026.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568502736-FB2FXT4PKZSTQBBHLCTV/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.027.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568502736-FB2FXT4PKZSTQBBHLCTV/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.027.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568502736-FB2FXT4PKZSTQBBHLCTV/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.027.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.027.jpeg" data-load="false" data-image-id="5f75fef6df48bb24d6e115b8" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568502736-FB2FXT4PKZSTQBBHLCTV/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.027.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568504546-6QFZ8QWG6WZXQD37C25Y/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.028.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568504546-6QFZ8QWG6WZXQD37C25Y/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.028.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568504546-6QFZ8QWG6WZXQD37C25Y/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.028.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.028.jpeg" data-load="false" data-image-id="5f75fef6f5a59735fc9dad85" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568504546-6QFZ8QWG6WZXQD37C25Y/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.028.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568503675-K0JPRBENUV0OIBNRJVNA/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.029.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568503675-K0JPRBENUV0OIBNRJVNA/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.029.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568503675-K0JPRBENUV0OIBNRJVNA/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.029.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.029.jpeg" data-load="false" data-image-id="5f75fef705a7793966d1d02c" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568503675-K0JPRBENUV0OIBNRJVNA/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.029.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568504260-2ZJZ0N29T60PUYVO0PD2/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.030.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568504260-2ZJZ0N29T60PUYVO0PD2/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.030.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568504260-2ZJZ0N29T60PUYVO0PD2/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.030.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.030.jpeg" data-load="false" data-image-id="5f75fef70dd0c87c41a983cb" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568504260-2ZJZ0N29T60PUYVO0PD2/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.030.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568505505-SXMJKTI3GZ4KPP5T89H0/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.031.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568505505-SXMJKTI3GZ4KPP5T89H0/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.031.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568505505-SXMJKTI3GZ4KPP5T89H0/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.031.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.031.jpeg" data-load="false" data-image-id="5f75fef878c626590ead67cf" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568505505-SXMJKTI3GZ4KPP5T89H0/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.031.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568505726-IGC0IN2QUPBGN7UG35QZ/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.032.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568505726-IGC0IN2QUPBGN7UG35QZ/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.032.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568505726-IGC0IN2QUPBGN7UG35QZ/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.032.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.032.jpeg" data-load="false" data-image-id="5f75fef92fbf5a3363926728" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568505726-IGC0IN2QUPBGN7UG35QZ/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.032.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568506018-0D7AQ4VKMJZNXSXBUDRE/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.033.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568506018-0D7AQ4VKMJZNXSXBUDRE/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.033.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568506018-0D7AQ4VKMJZNXSXBUDRE/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.033.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.033.jpeg" data-load="false" data-image-id="5f75fef996d0d45d87873f25" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568506018-0D7AQ4VKMJZNXSXBUDRE/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.033.jpeg">
                </a>
                
              </p></div>
            </div></div></div></div></div></div></div></div></div></article></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://minesafetydisclosures.com/blog/newyorktimes">https://minesafetydisclosures.com/blog/newyorktimes</a></em></p>]]>
            </description>
            <link>https://minesafetydisclosures.com/blog/newyorktimes</link>
            <guid isPermaLink="false">hacker-news-small-sites-24658206</guid>
            <pubDate>Fri, 02 Oct 2020 02:34:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[London, Ont. study reveals science behind curling's 2015 'Frankenbroom' ban]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24658102">thread link</a>) | @lando2319
<br/>
October 1, 2020 | https://www.cbc.ca/news/canada/london/curling-frankenbrooms-directional-fabric-1.5744754 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/london/curling-frankenbrooms-directional-fabric-1.5744754">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.cbc.ca/news/canada/london/curling-frankenbrooms-directional-fabric-1.5744754</link>
            <guid isPermaLink="false">hacker-news-small-sites-24658102</guid>
            <pubDate>Fri, 02 Oct 2020 02:13:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Build Complex Entry Forms Using Only HTML and Vue Templating – Demo App]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24658012">thread link</a>) | @__app_dev__
<br/>
October 1, 2020 | https://www.dataformsjs.com/examples/entry-form-demo-vue.htm | <a href="https://web.archive.org/web/*/https://www.dataformsjs.com/examples/entry-form-demo-vue.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.dataformsjs.com/examples/entry-form-demo-vue.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-24658012</guid>
            <pubDate>Fri, 02 Oct 2020 01:56:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Big O, Little N]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 31 (<a href="https://news.ycombinator.com/item?id=24657747">thread link</a>) | @adamzerner
<br/>
October 1, 2020 | https://adamzerner.bearblog.dev/big-o-little-n/ | <a href="https://web.archive.org/web/*/https://adamzerner.bearblog.dev/big-o-little-n/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div><p>I remember when I was first learning about hash tables. I thought I stumbled across an ingenious optimization for dealing with hash collisions. Before explaining my optimization, let me first briefly explain how hash tables work and what hash collisions are. I also made a video if you're interested.</p>
<p><a href="http://www.youtube.com/watch?v=pM9zhZB2KkM" title="Hash Tables"><img alt="" src="http://img.youtube.com/vi/pM9zhZB2KkM/0.jpg"></a></p>
<p>Say that we have a hash that maps someone's name to their age. <code>"adam"</code> is <code>27</code>, so we want to enter that into our hash.</p>
<p><img alt="" src="https://i.ibb.co/qWdjbhM/Slice.png"></p>
<p>Here's what happens:</p>
<ul>
<li><code>"adam"</code> gets put through a hash function.</li>
<li>The hash function spits out <code>7</code>.</li>
<li><code>7</code> is the index of the array where we are going to store <code>"adam"</code>'s value.</li>
<li>So we store <code>27</code> into <code>array[7]</code>.</li>
</ul>
<p>If we run <code>hash.get("adam")</code> in the future and need to look up the value for <code>"adam"</code>, we:</p>
<ul>
<li>Run <code>"adam"</code> through the hash function.</li>
<li>Get <code>7</code> as the output.</li>
<li>This means we have to look at <code>array[7]</code> to get the value.</li>
<li>So we look at <code>array[7]</code> to get our value.</li>
</ul>
<p>Hopefully if we have a key of <code>"alice"</code> or <code>"bob"</code> it'll hash to a different index. But... what happens if it hashes to the same index? That's called a hash collision.</p>
<p><img alt="" src="https://i.ibb.co/sJbJKnD/Slice.png"></p>
<p>A common approach is that if there's a collision, you store the values in a linked list.</p>
<p><img alt="" src="https://i.ibb.co/VJsSW3T/Slice.png"></p>
<p>Fair enough. That makes sense.</p>
<p>But wait!!! It takes <code>O(n)</code> time to look up a value in a linked list. Can't we use a binary search tree to speed that up to <code>O(log n)</code>???</p>
<p><img alt="" src="https://i.ibb.co/R3Vrc10/Slice.png"></p>
<p>Or... can't we take it a step further and use a <em>hash inside of a hash</em> to get the lookup time all the way down to <code>O(1)</code>?!</p>
<p><img alt="" src="https://i.ibb.co/7CyYNWY/Slice.png"></p>
<p>I hate to say it, but however many years ago when I had these thoughts, there were a few moments where I thought I was a genius. Now when I look back at that former self, I facepalm.</p>
<p>It is true that going from a linked list to a BST to a hash takes you from <code>O(n)</code> to <code>O(logn)</code> to <code>O(1)</code> lookup time. However, since collisions are rare, <code>n</code> is going to be small. And when <code>n</code> is small, <code>O(n)</code> might be faster than <code>O(1)</code>.</p>
<p>To understand why that is, think back to what Big-O really means. I think it helps to think about it as a "math thing" instead of a "programming thing". Consider two functions:</p>
<pre><code>f(n) = 4n + 1000
g(n) = 2n^2 + 5
</code></pre>
<p>Big-O of <code>f</code> is <code>O(n)</code> and Big-O of <code>g</code> is <code>O(n^2)</code>. We just focus on the part that "really matters". When <code>n</code> gets really big, the fact that it's <code>4n</code> doesn't really matter. Nor does the <code>+ 1000</code>.</p>
<p>But what about when <code>n</code> is small? Well, let's look at happens when <code>n</code> is <code>5</code>:</p>
<pre><code>f(5) = 4(5) + 1000 = 20 + 1000 = 1020
g(5) = 2(5^2) + 5 = 2(25) + 5 = 50 + 5 = 55
</code></pre>
<p>Look at that! The <code>O(n^2)</code> function is almost 20 times faster than the <code>O(n)</code> function!</p>
<p>And <em>that</em> is basically why they use a linked list instead of a BST or hash to handle collisions. Since <code>n</code> is small, Big-O isn't the right question to ask.</p>
<hr>
<p>Here's another example. I just wrote the following code while prepping for an interview:</p>
<pre><code>const isVowel = (char) =&gt; ["a", "e", "i", "o", "u"].includes(char);
</code></pre>
<p>Normally I wouldn't think twice about it, but since interviewers care so much about time complexity, I stopped to think about whether it could be improved.</p>
<p>And it hit me that it's actually <code>O(n)</code>(<a href="https://news.ycombinator.com/item?id=24660824">caveat</a>), because we've got an array and have to iterate over every element to see if the element matches <code>char</code>. It's easy to overlook this because we're using <code>includes</code> and not writing the code ourselves.</p>
<p>So then I thought that maybe we could use a hash instead to get <code>O(1)</code> lookup. Something like this:</p>
<pre><code>const isVowel = (char) =&gt; {
  const vowels = {
    a: true,
    e: true,
    i: true,
    o: true,
    u: true,
  };

  return !!vowels[char];
};
</code></pre>
<p>But then I realized that this is the same mistake I made with the hash collision stuff however many years ago. <em><code>n</code> is small, so Big-O isn't the question we should be asking</em>. Here <code>n</code> is <code>5</code>.</p>
<p>I think that the array approach would actually be faster than the hash approach, even though it's <code>O(n)</code> instead of <code>O(1)</code>. The reason for this is called locality.</p>
<p>If you dive deep under the hood, when you look up an element in an array, the CPU actually grabs a bunch of adjacent elements as well as the one you wanted, and it stores the adjacent elements in a cache. So here when we look up <code>"a"</code> in the array, it'll probably grab <code>"a"</code>, <code>"e"</code>, <code>"i"</code>, <code>"o"</code>, and <code>"u"</code>. And so next time when we want to grab <code>"e"</code>, it can take it from the cache, which is a lot faster. This works because the elements in the array are close to each other in the physical memory. But with a hash, my understanding is that they wouldn't be so close, and thus we wouldn't benefit from this spatial locality effect.</p>
<p>I'm no low-level programming wiz so I'm not sure about any of this. That's ok, I think it's beside the point of this post. The real point of this post is that when you have a little <code>n</code>, Big-O doesn't matter.</p>
</div>
</div></div>]]>
            </description>
            <link>https://adamzerner.bearblog.dev/big-o-little-n/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24657747</guid>
            <pubDate>Fri, 02 Oct 2020 00:59:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Designer's Guide to JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24657624">thread link</a>) | @philipcdavis
<br/>
October 1, 2020 | https://react.design/javascript | <a href="https://web.archive.org/web/*/https://react.design/javascript">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>You can learn the basics of JavaScript quickly. You don't need a engineering degree, or a front end bootcamp.</p><p>Learning the basics of JavaScript is enough to get started with modern frameworks like React.js. Once you know the basics, you can do some truly amazing things.</p><p>You can quickly spin up interactive prototypes.<br>You can use live data sets.<br>You can create web, mobile, and desktop apps.<br>You can define interfaces in high fidelity.<br>You can write scripts to automate daily tasks.<br>You can make plugins for design tools like Sketch and Figma.<br>You can build with modern frameworks like React.js.</p><p>You can't learn JavaScript in a day, but you can learn it quickly. The best way to learn is to build. This guide is meant to give you enough information to start building. </p><h2>Editor</h2><p><img src="https://react.design/assets/javascript/theme.png">
</p><p>Before we write any code, it's a good idea to get comfortable with your text editor. I'd recommend using a text editor like <a href="https://code.visualstudio.com/">VSCode</a>, or <a href="https://atom.io/">Atom</a> as you write JavaScript. They're both free and support lots of plugins to make things easier. You can also find lots of nice themes. Here's a <a href="https://marketplace.visualstudio.com/items?itemName=Framer.framer-syntax">theme</a> for VSCode that I like.</p><p>Learning keyboard shortcuts, and customizing the look of your editor will make for a much more enjoyable coding experience.</p><h2>Setup</h2><p>JavaScript is a scripting language that for our intents and purposes, will be executed by the browser.</p><p>There are multiple ways to include javascript inside your webpage. The way we will use javascript will be by including <code>&lt;script&gt;</code> tags right before the closing <code>&lt;/body&gt;</code> tag. </p><pre><code><span>&lt;!</span><span>DOCTYPE</span><span> </span><span>html</span><span>&gt;</span><span>
</span><span></span><span>&lt;</span><span>html</span><span>&gt;</span><span>
</span><span>  </span><span>&lt;</span><span>head</span><span>&gt;</span><span>&lt;/</span><span>head</span><span>&gt;</span><span>
</span><span>  </span><span>&lt;</span><span>body</span><span>&gt;</span><span>
</span>    
<span>    </span><span>&lt;</span><span>script</span><span>&gt;</span><span>
</span><span>        </span><span>// Javascript will go here</span><span>
</span><span>        </span><span>console</span><span>.</span><span>log</span><span>(</span><span>"Hello friend!"</span><span>)</span><span>
</span><span>    </span><span>&lt;/</span><span>script</span><span>&gt;</span><span>
</span><span>  </span><span>&lt;/</span><span>body</span><span>&gt;</span><span>
</span><span></span><span>&lt;/</span><span>html</span><span>&gt;</span></code></pre><p>Weâ€™ll put our javascript inside here, but we could also reference an external file.
<code>console.log()</code> is a helpful tool for debugging. Here I'm writing "Hello Friend!" To the console. You an access the console in Chrome using the <code>CMD+Option+J</code> shortcut.</p><p><img src="https://react.design/assets/javascript/console.png">
</p><p>There are 5 core concepts in JavaScript that are important to understand.</p><p><strong>1. Variables</strong><br><strong>2. Data Structures</strong><br><strong>3. Loops</strong><br><strong>4. Conditionals</strong><br><strong>5. Functions</strong></p><h2>Variables</h2><p>Variables are containers that hold values. These values can take lots of different forms. If you wanted a variable to hold a number you could write it as <code>var num = 20;</code>. If I use <code>console.log(num)</code> it should show me the number twenty.</p><p>Variables can be referenced later. <code>var double = num * 2; // 40</code></p><p>Variables can hold lots of different data types. I want to discuss a few different common ways to hold data. There are primitive data types like numbers, which we used earlier, There are strings, which are just a way to store text, and booleans which are values that are either true or false.</p><pre><code><span>var</span><span> days </span><span>=</span><span> </span><span>40</span><span>;</span><span> </span><span>// Number</span><span>
</span><span></span><span>var</span><span> label </span><span>=</span><span> </span><span>"Hello"</span><span>;</span><span> </span><span>// String</span><span>
</span><span></span><span>var</span><span> hidden </span><span>=</span><span> </span><span>true</span><span>;</span><span> </span><span>// Boolean</span></code></pre><h2>Data Structures</h2><p>In addition to primitive data types there are others that have more complex structures. Two of these important types are objects (sometimes called object literals) and arrays. </p><p>Objects can be defined using curly braces. 
<code>var obj = {}</code></p><p>What goes inside the curly braces are a collection of key value pairs. The key goes first, followed by a colon, and then the value. </p><pre><code><span>var</span><span> obj </span><span>=</span><span> </span><span>{</span><span>
</span><span>  key</span><span>:</span><span> value
</span><span></span><span>}</span></code></pre><p>Keys are labels that help you find the data you want to store. Keys in a single object must be unique. Values can be any data type. Numbers, strings, arrays, and even other objects. 
Here's an example Object with multiple key value pairs in action:</p><pre><code><span>var</span><span> profile </span><span>=</span><span> </span><span>{</span><span>
</span><span>	name</span><span>:</span><span> </span><span>'Philip'</span><span>,</span><span> 
</span><span>	age</span><span>:</span><span> </span><span>25</span><span>,</span><span> 
</span><span>	contact</span><span>:</span><span> </span><span>{</span><span>
</span><span>		twitter</span><span>:</span><span> </span><span>'philipcdavis'</span><span>,</span><span> 
</span><span>		email</span><span>:</span><span> </span><span>'reactfordesigners@gmail.com'</span><span>
</span><span>	</span><span>}</span><span>
</span><span></span><span>}</span></code></pre><p>Name, age, contact, twitter, and email are all different keys in this object. The values are all different and many have different value types. Some are strings, some are numbers, and some are other objects.</p><p>This nested structure is common and you will see it a lot when working with data sets.</p><p>There are two ways to access a value inside an object. The first way is sometimes called dot notation: <code>profile.name</code>. The second way is by using brackets <code>profile['name']</code>. Bracket notion is useful when your key name is dynamic.</p><p>The other data type thatâ€™s important to know about is the Array. You define an array with square brackets. </p><p><code>var myArr = [];</code></p><p>You can store any type of data inside these arrays and they don't need to all be the same type (though they usually are). An example array might look like this: </p><pre><code><span>var</span><span> teams </span><span>=</span><span> </span><span>[</span><span>'lakers'</span><span>,</span><span> </span><span>'nuggets'</span><span>,</span><span> </span><span>'rockets'</span><span>]</span><span>;</span></code></pre><p>Instead of using keys, arrays use a built in index to keep track of location. The index of arrays starts at 0. If we wanted to access the second value of this array (nuggets) we could do so by typing <code>teams[1];</code></p><p>If your data was as simple as this, using objects and arrays might seem unnecessary. They start to shine when you have data sets that are larger. To work with more data, we'll probably want to use a loop</p><h2>Loops</h2><p>Loops enable you to run a block of code multiple times. You can use a loop with objects and arrays to execute a block of code on each item in the structure. </p><p>To loop through each value in an array you can use a for loop that executes a block. </p><pre><code><span>for</span><span> </span><span>(</span><span>var</span><span> i</span><span>=</span><span>0</span><span>;</span><span> i</span><span>&lt;</span><span>teams</span><span>.</span><span>length</span><span>;</span><span> i</span><span>++</span><span>)</span><span> </span><span>{</span><span>
</span><span>    </span><span>// Block to be executed</span><span>
</span><span></span><span>}</span></code></pre><p>What goes into the parenthesis determines how many times the block of code is executed. The first value is a counter variable. <code>i</code> is often used to refer to the fact that it's used as the index value of the array. We will start the counter at 0. </p><p>The next value is called the conditional. Once the conditional is false, the loop will end. We can set the value to be <code>i &lt; teams.length</code>. The <code>.length</code> is a helper value built into every array that will tell you how many items are in the array. Once the value of the counter is as great as the length of the array, we can stop looping. The last value <code>i++</code> is what we want to happen after our loop runs. We want our counter to increase in value by one every time the loop runs.</p><p>If we log a string, you can see that it will print out 4 times.
If we log the value i, you can see that it increments up. If you combine this incremented value i with our array, you can see how we can access each value in our array.</p><pre><code><span>for</span><span> </span><span>(</span><span>var</span><span> i</span><span>=</span><span>0</span><span>;</span><span>i</span><span>&lt;</span><span>teams</span><span>.</span><span>length</span><span>;</span><span>i</span><span>++</span><span>)</span><span> </span><span>{</span><span> 
</span><span>	</span><span>console</span><span>.</span><span>log</span><span>(</span><span>teams</span><span>[</span><span>i</span><span>]</span><span>)</span><span>
</span><span></span><span>}</span><span>;</span></code></pre><p>There are other types of loops but they all are doing something pretty similar, running a block of code multiple times. Thatâ€™s the essential work of a loop.</p><h2>Conditionals</h2><p>Next up on our list is conditionals. The most common type of conditional is the if/else statement. </p><pre><code><span>if</span><span> </span><span>(</span><span>conditional</span><span>)</span><span> </span><span>{</span><span>
</span><span>	</span><span>console</span><span>.</span><span>log</span><span>(</span><span>'the conditional evaluated to true'</span><span>)</span><span>;</span><span>
</span><span></span><span>}</span><span> </span><span>else</span><span> </span><span>{</span><span>
</span><span>  </span><span>console</span><span>.</span><span>log</span><span>(</span><span>'the conditional evaluated to false'</span><span>)</span><span>;</span><span>
</span><span></span><span>}</span></code></pre><p>If the <code>conditional</code> value in the parenthesis evaluates to true, the block inside the first set of curly brackets is run, otherwise the else block is run.</p><p>Letâ€™s use it in combination with our loop to log only the first two items in our array. Because we donâ€™t need the else here, we can remove it, and weâ€™ll get the same result.</p><pre><code><span>for</span><span> </span><span>(</span><span>var</span><span> i </span><span>=</span><span> </span><span>0</span><span>;</span><span> i</span><span>&lt;</span><span>teams</span><span>.</span><span>length</span><span>;</span><span> i</span><span>++</span><span>)</span><span> </span><span>{</span><span>
</span><span>	</span><span>if</span><span> </span><span>(</span><span>i </span><span>&lt;</span><span> </span><span>2</span><span>)</span><span> </span><span>{</span><span>
</span><span>	  </span><span>console</span><span>.</span><span>log</span><span>(</span><span>teams</span><span>[</span><span>i</span><span>]</span><span>)</span><span>;</span><span>
</span><span>	</span><span>}</span><span>
</span><span></span><span>}</span></code></pre><p>Youâ€™ll use these conditionals to to control what gets executed when.</p><h2>Functions</h2><p>Functions allow you to create reusable and modular code.</p><p>Another way to say it is that they are blocks of code than can be executed whenever they are needed. </p><p>Here's what one looks like</p><pre><code><span>function</span><span> </span><span>add</span><span> </span><span>(</span><span>a</span><span>,</span><span> b</span><span>)</span><span> </span><span>{</span><span>
</span><span>	</span><span>var</span><span> total </span><span>=</span><span> a </span><span>+</span><span> b</span><span>;</span><span>
</span><span>	</span><span>return</span><span> total</span><span>;</span><span>
</span><span></span><span>}</span><span> </span></code></pre><p>Here we have a simple function that takes two input values, adds them together, and then returns the total. Weâ€™ll use generic names for our input arguments. You can name these pretty much whatever you want, but they will be used within our block so if your function is complex, itâ€™s good to have descriptive names. Because this is a pretty simple function we're using <code>a</code> and <code>b</code>. </p><p>What we've created is a function declaration. In order to execute, or invoke our function we can call <code>add(2,50)</code>.
<code>console.log(add(2,50)) // 52</code></p><p><code>console.log</code> is itself a function. Functions can be stored in variables, objects, arrays, or even passed into other functions.</p><p>One other important thing to note about functions is how they affect variables inside them. If you define a variable within a function, the variable cannot be used outside the function. That's because javascript has a function based scope.</p><hr><p>Javascript is a really fun language to learn. If you feel comfortable with the material above you can do a lot! Most of JavaScript is just building on to these core concepts.</p><h2>Modern JavaScript</h2><p>In 2015 a set of new syntax and features were introduced that made writing JavaScript easier. Many of the following updates are meant to help you write code faster and cleaner. If you're using modern frameworks like React you'll often see them in examples.</p><h3>Const / Let</h3><p>This is just a new way to write variables. </p><pre><code><span>const</span><span> height </span><span>=</span><span> </span><span>30</span><span>;</span><span>
</span><span></span><span>let</span><span> height </span><span>=</span><span> </span><span>30</span><span>;</span></code></pre><p><code>const</code> values cannot be reassigned after the initial assignment. This is usually the default way of creating variables. </p><p><code>let</code> values can be reassigned but are scoped to conditionals, the same way all variables are scoped to functions. If you declare one inside an if/else statement it won't be available outside the statement.</p><h3>Arrow Functions</h3><p>This a shorthand for writing functions.
Instead of writing:</p><pre><code><span>const</span><span> </span><span>add</span><span> </span><span>=</span><span> </span><span>function</span><span>(</span><span>a</span><span>,</span><span>b</span><span>)</span><span>{</span><span> </span><span>return</span><span> a </span><span>+</span><span> b </span><span>}</span></code></pre><p>You can use an arrow function which looks like this:</p><pre><code><span>const</span><span> </span><span>add</span><span> </span><span>=</span><span> </span><span>(</span><span>a</span><span>,</span><span>b</span><span>)</span><span> </span><span>=&gt;</span><span> a </span><span>+</span><span> b</span></code></pre><p>If your function takes a single parameter you can omit the parenthesis.</p><pre><code><span>const</span><span> </span><span>getStyle</span><span> </span><span>=</span><span> </span><span>a</span><span> </span><span>=&gt;</span><span> a</span><span>.</span><span>style</span></code></pre><h3>Template Literals</h3><p>Previously is you wanted dynamic strings, you would insert values using the following syntax.</p><pre><code><span>const</span><span> dynamicString </span><span>=</span><span> </span><span>"Hello my name is"</span><span> </span><span>+</span><span> firstName </span><span>+</span><span> </span><span>". Welcome!"</span></code></pre><p>Using template literals, you can use the backtick for strings, and <code>${}</code> to insert variables.</p><pre><code><span>const</span><span> dynamicString </span><span>=</span><span> </span><span>`</span><span>Hello my name is </span><span>${</span><span>firstName</span><span>}</span><span>. Welcome!</span><span>`</span></code></pre><h3>Imports and Exports</h3><p>Instead of using large javascript files, you'll often want to break your code into smaller modules and export anything that other modules need to access.</p><pre><code><span>// Colors.js</span><span>
</span><span></span><span>export</span><span> </span><span>const</span><span> colors </span><span>=</span><span> </span><span>{</span><span>
</span><span>	blue</span><span>:</span><span> </span><span>"#EA3232"</span><span>,</span><span>
</span><span>	red</span><span>:</span><span> </span><span>"#4062F3"</span><span>,</span><span>
</span><span>	yellow</span><span>:</span><span> </span><span>"#FFAD05"</span><span>,</span><span>
</span><span></span><span>}</span></code></pre><p>In a different file you can import these colors using the following syntax.</p><pre><code><span>import</span><span> </span><span>{</span><span>colors</span><span>}</span><span> </span><span>from</span><span> </span><span>'./Color'</span></code></pre><p>You can also define default exports …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://react.design/javascript">https://react.design/javascript</a></em></p>]]>
            </description>
            <link>https://react.design/javascript</link>
            <guid isPermaLink="false">hacker-news-small-sites-24657624</guid>
            <pubDate>Fri, 02 Oct 2020 00:32:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Automatic-Differentiation-Worked-Examples]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24657571">thread link</a>) | @formalsystem
<br/>
October 1, 2020 | http://h2.jaguarpaw.co.uk/posts/automatic-differentiation-worked-examples/ | <a href="https://web.archive.org/web/*/http://h2.jaguarpaw.co.uk/posts/automatic-differentiation-worked-examples/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <h3>automatic-differentiation-worked-examples</h3>
  
<p>– forwards and reverse</p>
<h2 id="introduction">Introduction</h2>
<p>This article demonstrates how to perform source transformations on a program to generate forward mode and reverse mode derivative programs (automatic differentiation, or “AD”). My aim is to write the shortest possible article that communicates all the essential features of a source-to-source AD system with a particular focus on making the reverse mode transformation clear.</p>
<p>The goal of brevity means that a lot of possible commentary has been omitted. If you find this makes some part of the article hard to understand then please <a href="http://web.jaguarpaw.co.uk/~tom/contact">contact me</a> and I’ll do my best to clarify. In particular this article contains hardly any mathematical content at all. I hope that the reader who is familiar with multivariate calculus will be able to obtain an intuitive understanding of how AD relates to mathematical techniques he or she is already familiar with. A more in-depth description of the relationship will have to wait for another article.</p>
<h2 id="the-program">The program</h2>
<p>Let’s consider the following pseudocode program that performs some elementary arithmetic through a sequence of assignment statements.</p>
<pre><code>p = 7 * x
r = 1 / y
q = p * x * 5
v = 2 * p * q + 3 * r</code></pre>
<p><code>x</code> and <code>y</code> are not defined in the program so I’m going to informally consider them to be “inputs”; <code>v</code> is not used anywhere so I’m going to consider it to be the “output”. (I won’t burden the article by formalising these notions here.)</p>
<h2 id="preparation">Preparation</h2>
<p>We’ll do a small amount of preparation to our original program which will preserve its behaviour and get it into a form in which it is straightforward to apply the automatic differentiation (AD) algorithms. It is possible to apply AD algorithms without doing these transformations first but then the AD algorithms would have to do equivalent operations implicitly. Doing these transformations first is a kind of <a href="https://en.wikipedia.org/wiki/Separation_of_concerns">separation of concerns</a>.</p>
<h3 id="use-prefix-functions-with-exactly-one-argument">Use prefix functions with exactly one argument</h3>
<p>Let’s use prefix functions instead of <a href="https://en.wikipedia.org/wiki/Infix_notation">infix operators</a>. Infix operators are more familiar for arithmetic but the AD algorithms will be clearer to present if we use prefix functions. Additionally I want every function to have exactly one argument (although that argument may be a tuple). Single-argument style will make the reverse mode transformation much clearer (although it does not make any difference for forward mode). For example, <code>x1 + x2</code> would become <code>add (x1, x2)</code>. Our program becomes</p>
<pre><code>p = mul (7, x)
r = div (1, y)
q = mul (mul (p, x), 5)
v = add (mul (mul (2, p), q), mul (3, r))</code></pre>
<h3 id="no-nested-subexpressions">No nested subexpressions</h3>
<p>Next let’s convert to a form where every function is applied to (tuples of) variables and constants only, i.e.&nbsp;where there are no nested sub-expressions (besides potentially nested tuples). We assign each nested sub-expression to an intermediate variable. For example</p>
<pre><code>a = add (add (b, c), d)</code></pre>
<p>would become</p>
<pre><code>i = add (b, c)
a = add (i, d)</code></pre>
<p>The choice of <code>i</code> is arbitrary; it just has to be a variable that’s not used elsewhere in our program. This form without nested subexpressions is a lot like <a href="https://en.wikipedia.org/wiki/A-normal_form">ANF</a> from the field of functional compiler construction. It’s also a lot like the <a href="https://en.wikipedia.org/wiki/Static_single_assignment_form">SSA form</a> of assembly language. After removing nested subexpressions, our program becomes</p>
<pre><code>p = mul (7, x)
r = div (1, y)
i1 = mul (p, x)
q = mul (i1, 5)
i2 = mul (2, p)
i3 = mul (i2, q)
i4 = mul (3, r)
v = add (i3, i4)</code></pre>
<h2 id="differentiation-line-by-line">Differentiation line-by-line</h2>
<p>We have performed all the transformations needed to prepare our program and we are ready to proceed to differentiation. We will differentiate the program line-by-line, that is, both the forward mode and reverse mode differentiation algorithms will generate one line of derivative code for each line of input code. But what <em>is</em> the derivative of an assignment statement? For forward mode, the derivatives correspond quite closely to what you might be familiar with from a first multivariate calculus course..</p>
<h3 id="examples">Examples</h3>
<h4 id="addition">Addition</h4>
<p>If a line of our pseudocode program is</p>
<pre><code>y = add (x1, x2)</code></pre>
<p>then the derivative line is</p>
<pre><code>dy = add (dx1, dx2)</code></pre>
<h4 id="multiplication">Multiplication</h4>
<p>If a line of our pseudocode program is</p>
<pre><code>y = mul (x1, x2)</code></pre>
<p>then the derivative line is</p>
<pre><code>dy = add (mul (x2, dx1), mul (x1, dx2))</code></pre>
<h4 id="division">Division</h4>
<p>If a line of our pseudocode program is</p>
<pre><code>y = div (x1, x2)</code></pre>
<p>then the derivative line is</p>
<pre><code>dy = add (div (dx1, x2), negate (mul (div (x1, mul (x2, x2)), dx2)))</code></pre>
<h2 id="forward-mode">Forward mode</h2>
<p>The forward mode transformation applies the appropriate differentiation rule to each line in the input program (listed on the left) to obtain a derivative line (listed on the right). To each line we apply exactly one rule and the form of the rule does not depend on any of the other lines.</p>
<pre><code>p = mul (7, x)   | dp = mul (7, dx)
r = div (1, y)   | dr = negate (div (dy, mul (y, y)))
i1 = mul (p, x)  | di1 = add (mul (dp, x), mul (p, dx))
q = mul (i1, 5)  | dq = mul (di1, 5)
i2 = mul (2, p)  | di2 = mul (2, dp)
i3 = mul (i2, q) | di3 = add (mul (di2, q), mul (i2, dq))
i4 = mul (3, r)  | di4 = mul (3, dr)
v = add (i3, i4) | dv = add (di3, di4)</code></pre>
<p>If we form a new program consisting of the sequence of assignments on the left followed by the sequence of assignments on the right then we have a program that calculates the forward derivative! The “inputs” of this program are <code>x</code>, <code>y</code>, <code>dx</code> and <code>dy</code>. The “outputs” are <code>v</code> and <code>dv</code>.</p>
<p>(The derivatives of constants are zero and I’ve left terms that are zero out for simplicity.)</p>
<p>In fact we can be a little more clever. We can interleave the assignments, so an assignment from the left is immediately followed by its corresponding assignment from the right, that is</p>
<pre><code>p = mul (7, x)
dp = mul (7, dx)
r = div (1, y)
dr = negate (div (dy, mul (y, y)))
i1 = mul (p, x)
di1 = add (mul (dp, x), mul (p, dx))
q = mul (i1, 5)
dq = mul (di1, 5)
i2 = mul (2, p)
di2 = mul (2, dp)
i3 = mul (i2, q)
di3 = add (mul (di2, q), mul (i2, dq))
i4 = mul (3, r)
di4 = mul (3, dr)
v = add (i3, i4)
dv = add (di3, di4)</code></pre>
<p>This interleaving demonstrates an important property of the automatic derivative: that it uses space proportional to the space usage of the original program. Specifically, as soon as we no longer need a variable that was assigned in the original program we no longer need the corresponding <code>d</code> version either.</p>
<p>We can also see another important property of the forward derivative: it runs in time proportional to the run time of the original program (assuming that the derivative of every primitive runs in time proportional to the run time of the primitive itself).</p>
<h2 id="reverse-mode-requires-two-additional-ideas">Reverse mode requires two additional ideas</h2>
<p>Now that we’ve shown how to generate the forward mode derivative we can move on to the reverse mode derivative. Reverse mode requires two additional ideas:</p>
<ol type="1">
<li><p>We need to convert our original program to “explicit duplication” form: if a variable is used more than once then we make that explicit in the structure of the program. This is unusual but straightforward.</p></li>
<li><p>We need to use a form of the derivative that will be unfamiliar to most readers. It will appear quite bizarre when seeing it for the first time but it is crucial to implementing the reverse mode derivative.</p></li>
</ol>
<h2 id="explicit-duplication-form">Explicit duplication form</h2>
<p>Before applying the reverse mode AD transformation we will convert to “explicit duplication” form. Again, the transformation is not strictly required but if we omit it then the differentiation pass will have to do it implicitly. We take the ANF form of the program and insert explicit duplications (<code>dup</code>) for any variable that is used more that once. Recall that after removing nested subexpressions our program was</p>
<pre><code>p = mul (7, x)
r = div (1, y)
i1 = mul (p, x)
q = mul (i1, 5)
i2 = mul (2, p)
i3 = mul (i2, q)
i4 = mul (3, r)
v = add (i3, i4)</code></pre>
<p>We can see that <code>x</code> and <code>p</code> appear on the right hand side (i.e.&nbsp;are consumed) twice each. Therefore, they will need explicit duplication, so that each variable in the resulting program is used only once. With explicit duplication the program looks like</p>
<pre><code>(x1, x2) = dup x
p = mul (7, x1)
(p1, p2) = dup p
r = div (1, y)
i1 = mul (p1, x2)
q = mul (i1, 5)
i2 = mul (2, p2)
i3 = mul (i2, q)
i4 = mul (3, r)
v = add (i3, i4)</code></pre>
<p>(If a variable were used <span><em>n</em></span> times then we would have to insert <span><em>n</em> − 1</span> <code>dup</code>s for it. In our example no variable is used more than twice.)</p>
<p>Notice that now not only is every variable defined exactly once, but every variable is also <em>used</em> exactly once (except the inputs and outputs, <code>x</code>, <code>y</code> and <code>v</code> – I won’t say more here about how exactly these seemingly special cases fit into the story). This property is important for a reason which will be explained when we come to generate the reverse mode program.</p>
<h2 id="differentiation-line-by-line-1">Differentiation line-by-line</h2>
<p>The line-by-line differentiation rules for generating the reverse mode need another article to explain thoroughly, but in this article I will hope to provide some basic intuition via examples and the informal notion that the reverse mode program calculates how sensitive the output is to different variables. For example, if the variable <code>y</code> appears in the original program then the variable <code>d_dy</code> will appear in the reverse mode program and measures “how sensitive the output is to small changes in <code>y</code>”. (I’ll abbreviate this to “<code>d_dy</code> is the sensitivity to <code>y</code>”.)</p>
<h3 id="examples-1">Examples</h3>
<h4 id="addition-1">Addition</h4>
<p>If a line of our pseudocode program is</p>
<pre><code>y = add (x1, x2)</code></pre>
<p>then the derivatives are</p>
<pre><code>d_dx1 = d_dy
d_dx2 = d_dy</code></pre>
<p>because the sensitivity to <code>x1</code> is the same as the sensitivity to <code>y</code> (and likewise for <code>x2</code>). This is written on a single line as</p>
<pre><code>(d_dx1, d_dx2) = dup (d_dy)</code></pre>
<h4 id="multiplication-1">Multiplication</h4>
<p>If a line of our program was</p>
<pre><code>y = mul (x1, x2)</code></pre>
<p>then the derivative line is</p>
<pre><code>(d_dx1, d_dx2) = (mul (x2, d_dy), mul (x1, d_dy))</code></pre>
<p>because the sensitivity to <code>x1</code> is <code>x2</code> times the sensitivity to <code>y</code> (and similarly for <code>x2</code>).</p>
<h4 id="duplication">Duplication</h4>
<p>If a line of our program was</p>
<pre><code>(x1, x2) = dup (x)</code></pre>
<p>then the derivative line is</p>
<pre><code>d_dx = add (d_dx1, d_dx2)</code></pre>
<p>because the sensitivity to <code>x</code> is the sensitivity to <code>x1</code> plus the sensitivity to <code>x2</code>.</p>
<h2 id="generating-reverse-mode-code">Generating reverse mode code</h2>
<p>Like forward mode before it, the reverse mode transformation applies the appropriate differentiation rule to each line in the input program (listed on the left) to obtain a …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://h2.jaguarpaw.co.uk/posts/automatic-differentiation-worked-examples/">http://h2.jaguarpaw.co.uk/posts/automatic-differentiation-worked-examples/</a></em></p>]]>
            </description>
            <link>http://h2.jaguarpaw.co.uk/posts/automatic-differentiation-worked-examples/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24657571</guid>
            <pubDate>Fri, 02 Oct 2020 00:21:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How YouTube Originals Shifted Prioritization to Stricter Ad Optimized Content]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24657529">thread link</a>) | @godisai
<br/>
October 1, 2020 | https://look.law/how-youtube-originals-like-wayne-shifted-prioritization-to-stricter-ad-optimized-content/ | <a href="https://web.archive.org/web/*/https://look.law/how-youtube-originals-like-wayne-shifted-prioritization-to-stricter-ad-optimized-content/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					








<figure><p>
<iframe title="Wayne | Official Trailer | YouTube Originals" width="1100" height="619" src="https://www.youtube.com/embed/PFOtvHtyW8s?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>











<p>The Wayne YouTube Original was a Gen Z version of Bonnie and Clyde mixed with Deadpool’s rough humor. This golden egg was YouTube’s hope of breaking into the world of streaming originals. Long story short, their hopes died with the failure of this show. This failure marks a critical pivot in YouTube’s business model. They transitioned to a model that prioritizes an array of content that is not just ad-friendly, but ad optimized. Understanding this pivot helps creators align their business strategy with this new direction. To understand this new business model, we need to review YouTube’s history of growth and monetization.&nbsp;</p>







<h2><strong>A History of YouTube Monetization</strong></h2>







<p>Thirteen years ago, Neil Cicierega uploaded a 2-minute video called Harry Potter Puppet Pals to YouTube. Now that video has 192,913,827 views, and YouTube enthusiasts revere it as a culture-defining classic. This democratized unfiltered viral content was YouTube’s brand in the late 2000s. The exciting start-up revolutionized how people consumed digital content but lacked a robust monetization model. At the time, YouTube only approved a handful of creators for advertising through its partnership program.&nbsp;</p>







<p>YouTube changed this In <a href="https://www.bloomberg.com/news/articles/2009-08-24/one-off-viral-videos-now-can-make-money-on-youtube">2009</a> when it updated its partnership program to include the monetization of individual videos. This move opened the door for small creators to generate revenue by making viral videos. Content like Harry Potter Puppet Pals now had a way to make money from its views.&nbsp;&nbsp;</p>







<p>Then in <a href="https://www.theverge.com/2012/4/13/2945243/youtube-partner-program-monetization">2012</a>, YouTube adjusted its partnership program again by opening monetization up to everyone. This created a new incentive structure that resulted in a production value boom. Videos like <a href="https://www.youtube.com/watch?v=Yk7SLuNG5Nk">Gangnam Style</a> and <a href="https://www.youtube.com/watch?v=avaSdC0QOUM">I’m on a Boat</a> replaced the Harry Potter Puppet Pals ascetic as YouTube’s new brand.&nbsp;</p>







<h2><strong>Hours of video uploaded to YouTube every minute as of May 2019:</strong></h2>



<figure><img src="https://lh6.googleusercontent.com/BJSwNSU5tIWygW07foEEPP9CbtROjW9W-M94HEcImnHgSZik8KO5ITInRxgN1UMo7HWmoCoUHWsZwsFIkgVVgZAxx_9fNbGXYnAy2FAYKHbT_G5CQu1p84ZhvhTUVtTj5eZ2V2HM" alt=""></figure>







<p>This era of YouTube was a gold rush for creators. The platform prioritized user-generated content and approved volumes for monetization without any question. This pattern changed in <a href="https://www.independent.co.uk/news/business/news/google-adverts-latest-youtube-extremist-videos-companies-pull-adverts-marks-spencer-companies-ku-klux-klan-isis-rape-apologists-a7638991.html">2017</a> when advertisers in the UK noticed their ads on extremist content like ISIS and KKK videos. This news hurt Google’s bottom line and forced YouTube to enforce stricter guidelines for ad-friendly content.&nbsp;&nbsp;</p>







<p>Advertising wasn’t the only growth model YouTube was using, however. Their business model included an investment strategy in subscription-based streams of revenue. In 2010, they started a rental program, then in 2014, they created a subscription service for music called YouTube Red. YouTube was splitting their efforts between an SVOD (Subscription Video On Demand) and AVOD (Advertising Video On Demand) business model.&nbsp;</p>







<h2><strong>The Difference Between SVOD and AVOD.&nbsp;</strong></h2>







<p>An SVOD (Subscription Video On Demand) model is a video-on-demand service where users pay a flat rate each month to gain access to as much content as they wish. So with this model, content is created and funded with the primary purpose of attracting and retaining viewership. This objective saves SVOD’s time and hassle of curating and promoting ad-friendly content.&nbsp;</p>







<p>The AVOD (Advertising Video On Demand) model does not charge viewers for its content; it charges advertisers access to viewer’s data and attention. In this model, YouTube needs to attract and retain viewership while also curating and promoting ad-friendly content.&nbsp;</p>







<p>The AVOD model is more labor-intensive but less competitive. After addressing concerns over inappropriate content in 2017, YouTube also invested more in its SVOD model. They dropped their most controversial YouTuber, <a href="https://techcrunch.com/2017/02/14/pewdiepies-youtube-red-series-gets-cancelled-after-vlogger-posts-anti-semitic-content/">Pewdiepie</a>, from YouTube Red and started investing in scripted shows. In <a href="https://arstechnica.com/gadgets/2018/05/youtubes-revamped-music-subscription-service-launches-on-may-22/">2018</a> they updated their YouTube Red subscription service to YouTube Premium. So subscribers now had access to exclusive ad-free YouTube Originals like Wayne, and all of their favorite channels and music services.&nbsp;</p>







<h2><strong>Why YouTube Originals Failed</strong></h2>







<p>In 2016, YouTube had just over 1 billion total users, with only <a href="https://www.theverge.com/2016/11/2/13498470/youtube-red-subscribers-video-content-music">1.5 million</a> monthly subscribers in YouTube Red. In 2018, YouTube believed that they could compete with Netflix, Hulu, and Amazon by attracting their 1 billion users to YouTube Premium. So they released the pilots of shows like Wayne on their central platform in a significant promotional effort.&nbsp;</p>







<p>The show was a massive success with the critics. It received a <a href="https://deadline.com/2019/08/step-up-wayne-canceled-youtube-pilot-dark-cargo-its-a-mans-wold-dead-seek-new-homes-scripted-programming-pullback-programming-shift-1202669457/">100% fresh rating on rotten tomatoes and 27 million people viewed the pilot.</a> Despite its success, Youtube couldn’t convince enough viewers to purchase a subscription to keep watching. Viewers had two reasons not to buy.</p>







<h2>Brand Conditioning and Opportunity Cost </h2>







<figure><img src="https://215kdel576-flywheel.netdna-ssl.com/wp-content/uploads/2020/09/sahand-hoseini-VrJnsLH2nOY-unsplash-683x1024.jpg" alt="" srcset="https://215kdel576-flywheel.netdna-ssl.com/wp-content/uploads/2020/09/sahand-hoseini-VrJnsLH2nOY-unsplash-683x1024.jpg 683w, https://215kdel576-flywheel.netdna-ssl.com/wp-content/uploads/2020/09/sahand-hoseini-VrJnsLH2nOY-unsplash-200x300.jpg 200w, https://215kdel576-flywheel.netdna-ssl.com/wp-content/uploads/2020/09/sahand-hoseini-VrJnsLH2nOY-unsplash-768x1152.jpg 768w, https://215kdel576-flywheel.netdna-ssl.com/wp-content/uploads/2020/09/sahand-hoseini-VrJnsLH2nOY-unsplash-1024x1536.jpg 1024w, https://215kdel576-flywheel.netdna-ssl.com/wp-content/uploads/2020/09/sahand-hoseini-VrJnsLH2nOY-unsplash-1365x2048.jpg 1365w, https://215kdel576-flywheel.netdna-ssl.com/wp-content/uploads/2020/09/sahand-hoseini-VrJnsLH2nOY-unsplash-600x900.jpg 600w, https://215kdel576-flywheel.netdna-ssl.com/wp-content/uploads/2020/09/sahand-hoseini-VrJnsLH2nOY-unsplash-scaled.jpg 1707w" sizes="(max-width: 683px) 100vw, 683px"></figure>







<p>The first reason was that YouTube’s core brand was and still is user-generated content. It is in their name. Users are not likely to pay a subscription for content that isn’t associated with YouTube’s brand. So That subscription wasn’t a purchase of Wayne; it was an investment in future YouTube originals. This investment is hard to sell when it isn’t in the company’s brand.&nbsp;</p>







<p>YouTube conditions users to receive ads. The whole model facilitates the right ads and the right amount of ads while also retaining viewership. Since most viewers are already conditioned for this, they had minimal incentive to pay extra for zero ads.&nbsp;</p>







<p>Lastly, YouTube’s investment in scripted paywall content was an opportunity cost. YouTube’s ad-supported business generates billions of dollars in revenue a year. This cash cow couldn’t compete with the revenue from subscriptions. As a result, successful shows like Wayne were costing the company money by excluding them from the ads. &nbsp;</p>







<p>In <a href="https://deadline.com/2019/08/step-up-wayne-canceled-youtube-pilot-dark-cargo-its-a-mans-wold-dead-seek-new-homes-scripted-programming-pullback-programming-shift-1202669457/">2019</a>, YouTube publicly acknowledged that the SVOD model could no longer compete with the AVOD model. As a result, they dropped these scripted shows from the paywall and quietly stopped investing in scripted content. This decision provided more room for the two leading giants, Netflix and Amazon, to duke it out in the streaming wars. We may even see one of these streaming services purchase the rights to Originals like Wayne.&nbsp;</p>







<p>This change in strategy means that YouTube pivoted its growth model. Instead of moving into the SVOD space, they reinvested that time and money to grow their ad revenue. Most of their efforts have been in setting stricter enforcement of their ad policies and incentivizing more ad-optimized content.&nbsp;</p>







<h2><strong>The Difference Between Ad Friendly and Ad Optimized Content</strong></h2>







<p>Ad-friendly content is a list of topics that YouTube will not include in its monetization program. This policy extends to all parts of the content, including the video, thumbnail, metadata, description, and tags.&nbsp;</p>







<p>If the content on the platform includes any of the topics listed in the policy, it can potentially be demonetized. The only exception to this is informative or educational content.&nbsp;</p>







<p>The “<a href="https://www.theverge.com/2019/4/5/18287318/youtube-logan-paul-pewdiepie-demonetization-adpocalypse-premium-influencers-creators">adpocalypse</a>” is evidence of stricter enforcement of YouTube’s guidelines around ad-friendly content. Since the 2017 controversy, YouTube has been increasingly enforcing their policies through demonetizing creators who violate their guidelines. They have improved their algorithm’s ability to catch this kind of content, demonetize, and even suppress it. Now that their business strategy heavily invests in the AVOD model, this will only get better and stricter.&nbsp;</p>







<p>Suppressing content isn’t the only tool in their business strategy. YouTube’s algorithm can now prioritize content optimized for ads. They do this through a backdoor curation tool set by advertisers.&nbsp;</p>







<p>YouTube’s algorithm reviews every video to determine if any of these five categories apply:</p>







<ul><li>Tragedy and conflict</li><li>Sensitive social issues</li><li>Sexually suggestive content&nbsp;</li><li>Sensational and shocking</li><li>Profanity and rough language&nbsp;</li></ul>







<p>Now, advertisers can exclude any of these categories. This ability creates a tiered categorization of all content. As a result, YouTube is incentivized to prioritize high tiered content that makes more ad revenue.&nbsp;</p>







<p>This model is very different from the golden era of viral user-generated content. The algorithm isn’t just learning what viewers like; it is learning what advertisers want. This machine learning is why users see product review channels promoted right alongside music channels. The new incentive model is why videos like Harry Potter Puppet pals no longer appear on the front page of YouTube.&nbsp;</p>







<h2><strong>What this means for creators</strong></h2>







<p>YouTube’s prioritization has evolved from user-generated content to scripted shows to a mix of ad-optimized user and network-generated content. Creators shouldn’t see this as an obstacle. YouTube isn’t a gatekeeper; it is a business partner. Our <a href="https://look.law/how-strategic-alliances-increase-youtube-revenue-per-view/">last post </a>explains how creators could benefit from strategic business alliances with other channels. This alliance can increase YouTube revenue per view and provide leverage to smaller independent channels. The key to these alliances is in structuring a business strategy that benefits both parties. YouTubers in the partner program are already in a strategic partnership with YouTube, whether they realize it or not.&nbsp;&nbsp;</p>


<div id="ub_call_to_action_8cb30d77-8501-448a-b58e-b3966e1e083b">
                <p>Look.Law</p>
                <p>Understanding YouTube’s business strategy helps creators structure their business model around a successful partnership with YouTube. As a law firm specializing in creative entrepreneurship, we can help creators innovate and restructure their business strategy in light of these trends. Contact us for more consul on this or any of our service offerings.&nbsp;</p>
                </div>



					                </div></div>]]>
            </description>
            <link>https://look.law/how-youtube-originals-like-wayne-shifted-prioritization-to-stricter-ad-optimized-content/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24657529</guid>
            <pubDate>Fri, 02 Oct 2020 00:14:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Community Moderation]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24657148">thread link</a>) | @minimaxir
<br/>
October 1, 2020 | https://www.joinclubhouse.com/on-community-moderation | <a href="https://web.archive.org/web/*/https://www.joinclubhouse.com/on-community-moderation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>Oct 1, 2020</p>
      <p>Since <a href="https://www.joinclubhouse.com/check-1-2-3">our last blog post</a>, Clubhouse has gone from a small community of beta testers to a growing network of communities, made up of people with vastly different opinions, experiences, worldviews and perspectives. This past week, people on Clubhouse have hosted several intense conversations on topics of identity, ethnicity, gender, racism, and religion. These conversations led to a number of serious incident reports, and we received questions and concerns from our community about how we plan to scale safety and moderation on Clubhouse. In the wake of this, we wanted to share some thoughts regarding what we stand for as a company, what we will and will not tolerate, what we are doing to prevent abuse, and how we plan to empower conversation hosts with better moderation tools as we grow.</p>
      <p>First, we unequivocally condemn Anti-Blackness, Anti-Semitism, and all other forms of racism, hate speech and abuse on Clubhouse. Our <a href="http://community.joinclubhouse.com/">Community Guidelines</a> and <a href="http://tos.joinclubhouse.com/">Terms of Service</a> make this clear, and we have trust and safety procedures in place to address any violation of these rules. People who violate them are warned, suspended, or removed completely from the platform, depending on the severity of the offense. This is a critical area of investment for us as a company and we are working hard to continue building tools and policies that are robust and that account for the unique dynamics of real-time voice conversations and group discussions.</p>
      <p>Second, we celebrate the fact that Clubhouse is not one single community, but a network of interconnected and diverse communities. As these communities grow, we need to provide moderators and club leaders with better tools and infrastructure to bring people together. Our goal is to empower them to host important, and even difficult, conversations—because some of the most powerful moments on Clubhouse happen when you find yourself speaking with a room full of people whose backgrounds and experiences are completely different from your own. These conversations often go on for hours, spilling out into breakout rooms full of people connecting, debating, evolving their worldviews and recognizing their blindspots. Our hope for Clubhouse is that it can be a new type of network based on empathy, discussion and sensemaking, rather than polarization. We think social media needs more of this.</p>
      <p>PREVENTING ABUSE</p>
      <p>Our Terms of Service and Community Guidelines define what type of behavior is allowed on Clubhouse and we are committed to addressing behavior that violates these rules. Here is what we’re doing to help with that:</p>
      <ul>
          <li><u>We’re taking action on all incident reports.</u> Any time someone reports a violation of our Terms of Service or Community Guidelines, we immediately investigate it. We don’t discuss these investigations publicly for user privacy reasons, but they are happening, and when rules are violated, corrective action is taken. This week, we’re also shipping real-time systems to investigate incidents more quickly and empower moderators to restrict and end rooms.</li>
          <li><u>We’re continuing to scale our trust and safety operations</u>. This is an ongoing effort for us that spans people, policy and product. On the people side, we’re focused on:</li>
          <ul>
              <li><u>Adding advisors.</u> We are building a team of advisors with deep expertise in trust, safety, diversity and inclusion to provide ongoing advice and input.</li>
              <li><u>Engaging directly with the community.</u> Since the earliest days of Clubhouse we’ve been engaging deeply with a diverse cross-section of our community to understand their needs—through weekly Town Halls, New User Orientation sessions and deeper discussions, both on Clubhouse and off. We plan to continue the dialogue and see how these formats can be improved. We also use these discussions to continuously evolve our Terms of Service, Privacy Policy and Community Guidelines. These will be living documents.</li>
              <li><u>Growing our team.</u> Our trust and safety efforts are staffed to respond swiftly to incident reports, and we plan to proactively scale this operation as we grow. </li>
            </ul>
          
          <li><u>We’re shipping a wave of new safety features</u>. Over the past couple months we introduced blocking, muting, in-room reporting, and the ability for moderators to end a room. This week we are shipping a wave of new enhancements to make in-room reporting more real-time, specific and robust. We are also making the Community Guidelines accessible from every room and shipping new features to empower Clubhouse moderators.</li>
        </ul>
      
      <p>EMPOWERING MODERATORS AND CLUB LEADERS</p>
      <p>As we take these steps, we want to avoid conflating abuse with other things that can feel uncomfortable—like differences in opinion or conversational style. Abuse, racism, religious intolerance, sexism and hate speech are never okay. Targeted and coordinated harassment is never okay. But what about general rudeness? Or holding opposing political viewpoints? While these things might seem jarring, we don’t believe they should be banned. We want to make sure that when you use Clubhouse, you get to choose your communities, your rooms, and your style of conversation. Here’s what we’re working on to enable this:</p>
      <ul>
          <li><u>Allowing clubs to set their own norms.</u> With our next release, club founders will be able to write rules that are specific to their clubs—to share their community values, communicate their norms, and define the dos and don'ts for speaking. When people join the club they'll be asked to agree to the rules. And when the club hosts a public conversation, non-members will be asked to agree to the rules before speaking. We think this will help people create intentional gathering spaces that cater to many interests and styles. These rules will supplement the Community Guidelines, which still apply to everyone.</li>
          <li><u>Hosting formal moderator training sessions.</u> There is no single way to moderate, and each room can have its own style. To help with this, we’re going to start offering regular moderator training sessions on the app, to ensure that people who wish to host discussions are equipped with the tools and knowledge they need.</li>
          <li><u>Improving moderator tooling.</u> Great moderators create great conversations, and we need to empower them with the right tools. This week we are building infrastructure that will allow us to notify moderators when there is a safety concern related to their room. Moderators can also tap the “End Room” button anytime if they feel the conversation is getting out of hand.</li>
          <li><u>Adding moderator badges.</u> This is a small thing, but it’s easier to provide a speaker with feedback when you know who’s in charge of the room. These will be live in the next release.</li>
        </ul>
      
      <p>The world is not a monoculture, and we want Clubhouse to reflect that. Ideally the experience is more like a town square, where people with different backgrounds, religions, political affiliations, sexual orientations, genders, ethnicities, and ideas about the world come together to share their views, be heard and learn. Some of these communities come together to debate. Some come to relax and joke around. Others hold listening parties and fireside chats. We think many styles should be supported, and we’re working on tools to help everyone create their own space, deepen friendships, meet new people and have meaningful discussions—in the way that suits them best.</p>
      <p>Clubhouse is nothing without the community, and we are immensely grateful for all of your ideas, emails, tweets, support and critiques. We’ll continue working around the clock on all of this as we open it up to more of the world. Thank you! 🙏🏽</p>

    </div></div>]]>
            </description>
            <link>https://www.joinclubhouse.com/on-community-moderation</link>
            <guid isPermaLink="false">hacker-news-small-sites-24657148</guid>
            <pubDate>Thu, 01 Oct 2020 23:11:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[VMware Fusion 12 Metal Support]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24656836">thread link</a>) | @wila
<br/>
October 1, 2020 | https://www.vimalin.com/blog/fusion-12-0-metal-support/ | <a href="https://web.archive.org/web/*/https://www.vimalin.com/blog/fusion-12-0-metal-support/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>			<div>
				
				<article id="post-1344">	
			<figure>
		<img width="1136" height="918" src="https://www.vimalin.com/wp-content/uploads/2020/10/image.png?is-pending-load=1" alt="VMware Fusion 12 Metal Support" loading="lazy" data-lazy-srcset="https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?w=1136&amp;ssl=1 1136w, https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=300%2C242&amp;ssl=1 300w, https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=1024%2C827&amp;ssl=1 1024w, https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=768%2C621&amp;ssl=1 768w" data-lazy-sizes="(max-width: 1136px) 100vw, 1136px" data-lazy-src="https://www.vimalin.com/wp-content/uploads/2020/10/image.png?is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">		</figure>
			<div>
					
				
									<div>
				
<p>Ok.. I’m so ecstatic.. a quick blog post must be written…</p>



<p>On VMworld’s “What’s New with VMware Workstation and VMware Fusion”, Michael Roy dropped a bomb in his last “One more thing” note.</p>



<p>He showed off “Metal Support” in a macOS guest… Now we have been told for years that we cannot get 3D Acceleration in a macOS guest, so seeing that was already pretty great. Something to look forward to.<br>In that same presentation he also showed the .vmx settings in order to get that working. Once the feature lands… </p>



<p>So of course immediately after the presentation I _had_ to try, even while it is only supposed to be working in a future version of VMware Fusion 12.0.<br>I got a “Invalid configuration” error (or something along those lines). <br>OK.<br>Silly me did not look at the vmware.log file, so today I was poking Michael a bit on twitter and asking about how well Metal works on Big Sur beta 9 and that it is “so hard to wait” and he tells me “but you can try it yourself already”… 😮</p>



<figure><div>
<blockquote data-width="500" data-dnt="true"><div lang="en" dir="ltr"><p>You can totally use it today actually, but AutoFit doesn't work (needs new tools that haven't shipped yet… future versions won't require Tools at all)</p><p>svga.present="FALSE"<br>appleGPU0.present="TRUE"</p><p>appleGPU0.screenWidth=1680 appleGPU0.screenHeight=1050</p></div>— Michael Roy (@mikeroySoft) <a href="https://twitter.com/mikeroySoft/status/1311754703055675392?ref_src=twsrc%5Etfw">October 1, 2020</a></blockquote>
</div></figure>



<p>OMG.. that’s when I realized that I had missed a detail..</p>



<figure><div>
<blockquote data-width="500" data-dnt="true"><div lang="en" dir="ltr"><p>Ohh… I had not put the svga.present="FALSE" line and now I see what other precondition I missed (silly me)…</p><p>vmx| I005: AppleGPU: Apple GPU support is not available: requires macOS 11.</p><p>Looks like I will update that box to macOS 11 right now.</p></div>— Wil van Antwerpen (@wilva) <a href="https://twitter.com/wilva/status/1311759349572870144?ref_src=twsrc%5Etfw">October 1, 2020</a></blockquote>
</div></figure>



<p>Also my host wasn’t running Big Sur yet (I had only run it in a VM)<br>… so… next hour or so I was frantically busy installing Big Sur Beta 9 on my 2014 Mac Mini and YES… IT DOES WORK and it is SOOOO SMOOTH</p>



<figure><img loading="lazy" width="1024" height="827" src="https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=1024%2C827&amp;ssl=1" alt="" srcset="https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=1024%2C827&amp;ssl=1 1024w, https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=300%2C242&amp;ssl=1 300w, https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=768%2C621&amp;ssl=1 768w, https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?w=1136&amp;ssl=1 1136w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=1024%2C827&amp;ssl=1 1024w, https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=300%2C242&amp;ssl=1 300w, https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=768%2C621&amp;ssl=1 768w, https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?w=1136&amp;ssl=1 1136w" data-lazy-src="https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=1024%2C827&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>This is the best thing since sliced bread.</p>



<div><p>THANK YOU VMware Fusion team!</p><p>In summary:<br>This is not an officially released feature, treat it what it is: Experimental<br>Required: minimum of macOS Big Sur as host OS<br>Required: minimum VMware Fusion 12.0<br>Guest OS support: So far I have only gotten this to work with a macOS Big Sur guest (but I haven’t tried others beyond macOS Mojave)</p><p>You have to add the following lines to the .vmx file of your VM in order to test this:<br><code>svga.present="FALSE"<br>appleGPU0.present="TRUE"<br>appleGPU0.screen0.width = "1680"<br>appleGPU0.screen0.height = "1050"</code></p></div>



<p>To be honest I don’t even have the lines with width and height, but that’s how you can define that for now.<br>It will only get better from here on once it is officially supported.</p>
			</div>
					
			<hr>
			
					</div>
</article>						</div>	
			
		<!--/Blog Content-->
		         				</div></div>]]>
            </description>
            <link>https://www.vimalin.com/blog/fusion-12-0-metal-support/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24656836</guid>
            <pubDate>Thu, 01 Oct 2020 22:28:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using artificial intelligence to make publishing profitable]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24656437">thread link</a>) | @Sanksshep
<br/>
October 1, 2020 | https://www.aiplusinfo.com/blog/using-artificial-intelligence-to-make-publishing-profitable | <a href="https://web.archive.org/web/*/https://www.aiplusinfo.com/blog/using-artificial-intelligence-to-make-publishing-profitable">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-1fd98981423ebe5f9a2e"><p><h2>Artificial Intelligence has significant implications in making publishing profitable – from automation to improvements in advertising. Let’s dive into what AI is, as well as the potential applications within the publishing industry to make it profitable.</h2></p></div><div data-block-type="2" id="block-yui_3_17_2_1_1601450467819_4883"><div><h3><strong>What is AI?</strong></h3><p>Artificial intelligence, or AI, refers to the ability of tools or technology to perform tasks that would normally require human intelligence to complete.&nbsp;</p><p>Machine learning is a subset of AI in the computer science space – where the platform or model learns from an existing data set so that it can understand the underlying trends and patterns. This knowledge is then used by the machine learning models to make predictions or determine outcomes from the new data it encounters.</p><p>In other words, the computer model uses statistical techniques to learn how to get better at a task, whether that be categorizing data or predicting if a client is a good fit for a certain product. For the model to learn to do this without specific programming, it must analyze existing data that is already pre-labeled.</p><p>Deep learning is another subset of artificial intelligence that involves the creation of a neural network, which has layers and layers of data processing. This type of AI can make deep connections and gain valuable insights from a dataset since it processes information almost like the human brain does.</p><h3><strong>Goals of Artificial Intelligence in Publishing</strong></h3><p>The goals of artificial intelligence in publishing include automating story production and evaluating content automatically.&nbsp;</p><p>The Associated Press started using AI back in 2015 for story automation. They understood that machine learning could create content such as public company earnings report recaps since they need details and accuracy but do not require much creativity.&nbsp;</p><p>They took this further in 2016 when they developed an AI platform that could report on Minor League Baseball games – the machine learning model could incorporate statistics and highlights that, again, are strictly fact-based.&nbsp;</p><p>This is just the beginning for automatic story production, and as artificial intelligence platforms become more accessible there will be more publishers utilize it to create automated content.</p><p>Another goal of artificial intelligence in publishing is evaluating content. A machine learning model can help an editor when making decisions regarding moderation and editing.&nbsp;</p><p>AI can be used to automate complex tasks, such as comparing the characteristics of a manuscript to those of a bestseller to see where improvements can be made. This can help editors focus on the most marketable content and save time and effort narrowing them down.&nbsp;</p><p>Automated text analysis can optimize plagiarism detection as well as copyright enforcement! Artificial intelligence can eliminate some of the tedious work involved with researching copyrights and ensuring that the content being published is 100% authentic.&nbsp;</p><p>Comment moderation can be significantly improved as a result of artificial intelligence. Machine learning models can save publishers valuable time and resources by automatically detective inappropriate or abusive labels and comments – and removing them.&nbsp;</p><p>Reducing the workload of human moderators can allow publishers to open more content for commenting and facilitate a wider scope of articles. The New York Times has already implemented automation within the moderation space, and this has allowed them to open up more content for commenting – where previously they capped it at 10% of their articles.&nbsp;</p><h3><strong>Artificial Intelligence and Advertising</strong></h3><p>Artificial intelligence can also help publishing firms when it comes to advertising. It can improve everything from engagement to the structuring and design of content.&nbsp;</p><p>AI platforms allow publishers to personalize content for marketing campaigns since statistics have shown that personal advertisements have a higher level of engagement – and therefore, a better return on investment.</p><p>Machine learning models will analyze content and engagement to curate newsletters and articles that fit right in with your audience segment. Research performed by McKinsey found that this level of personalization is essential and can increase the efficiency of marketing budgets by up to 30%!</p><p>This type of personalization can also be used for the automation of recommendations. You can gain insights into what your readers like based on their browsing history, and then the machine learning model can identify trends and patterns.&nbsp;</p><p>With this information, you can give your readers personalized recommendations on other content they may enjoy. This will help your firm boost engagement as well as make your advertisements much more personalized.&nbsp;</p><h3><strong>Conclusion</strong></h3><p>These are just a few aspects in which artificial intelligence can impact publishing by reorganizing the workforce towards better things with the help of automation and improve revenue by personalizing content and experiences for a diverse set of users. Publishing companies can benefit a lot by using artificial intelligence in tough economic climates and weather the storm and keep the lights on. </p></div></div></div>]]>
            </description>
            <link>https://www.aiplusinfo.com/blog/using-artificial-intelligence-to-make-publishing-profitable</link>
            <guid isPermaLink="false">hacker-news-small-sites-24656437</guid>
            <pubDate>Thu, 01 Oct 2020 21:42:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[COVID19 Blues: My father, the immune system, & the philosophy of Thelonius Monk]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24656227">thread link</a>) | @jinnko
<br/>
October 1, 2020 | https://selfishactivist.com/covid19-blues-my-father-the-immune-system-and-the-philosophy-of-thelonius-monk/ | <a href="https://web.archive.org/web/*/https://selfishactivist.com/covid19-blues-my-father-the-immune-system-and-the-philosophy-of-thelonius-monk/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p><img width="1688" height="2250" src="https://selfishactivist.com/wp-content/uploads/2020/04/pexels-photo-3395507-1.jpeg" alt="" loading="lazy" srcset="https://selfishactivist.com/wp-content/uploads/2020/04/pexels-photo-3395507-1.jpeg 1688w, https://selfishactivist.com/wp-content/uploads/2020/04/pexels-photo-3395507-1-416x555.jpeg 416w, https://selfishactivist.com/wp-content/uploads/2020/04/pexels-photo-3395507-1-225x300.jpeg 225w, https://selfishactivist.com/wp-content/uploads/2020/04/pexels-photo-3395507-1-768x1024.jpeg 768w, https://selfishactivist.com/wp-content/uploads/2020/04/pexels-photo-3395507-1-1152x1536.jpeg 1152w, https://selfishactivist.com/wp-content/uploads/2020/04/pexels-photo-3395507-1-1536x2048.jpeg 1536w, https://selfishactivist.com/wp-content/uploads/2020/04/pexels-photo-3395507-1-660x880.jpeg 660w, https://selfishactivist.com/wp-content/uploads/2020/04/pexels-photo-3395507-1-450x600.jpeg 450w" sizes="(max-width: 1688px) 100vw, 1688px"></p><p>I am not a doctor.</p>



<p>But my father is.</p>



<p>In fact, he is an immunologist.</p>



<p>So what follows below is not medical advice but a story of reconciliation (with some possible medicinal effects).</p>



<p>You see, my father and I have been more or less estranged for the last few years – and even before that we only communicated once in a while, maybe once a year, since we have been living in different continents, me in Canada and my father in Japan, for more than two decades.</p>



<p>It is only really the last few months that we have had consistent amicable communication for the first time in decades.</p>



<p>As far as back as I can remember, there has been a distance in my relationship with my father, a stuckness in understanding each other’s way of seeing the world. He wanted me to follow in his footsteps and become a scientist.</p>



<p>I naturally went the opposite direction, studied comparative religions, then ditched that, went to art school, and finally, ended up as a therapist after what was basically a (still unfolding) mid-life crisis.</p>



<p>Part of me resisting his desire for me to do scientific research was undoubtedly related to his unfortunate position in our family. He has always been a kind of lone genius, whose work we understood to be incredibly impactful but had no idea what it actually meant. Like many archetypal, or maybe more appropriately, stereotypical, ‘gifted children’, he had little everyday life skills to maintain relationships – something that I have obviously inherited a bit of myself.</p>



<p>What I do remember of him fondly from my childhood is that he absolutely loved talking about pandemics. <a rel="noreferrer noopener" href="https://www.goodreads.com/book/show/7670.The_Andromeda_Strain" target="_blank">Andromeda Strain</a> was a favored book in our household.</p>



<hr>



<p>Fast forward to 2020 and there is a global pandemic phenomenon – and it has brought me back to understanding him and his work. We’re emailing back and forth.</p>



<p>It’s hard to describe the ironic humour I find in how I am spending hours obsessively trying to understand the so-called immune system and the functions of its many minions, T-cells, B-cells, lymphocytes, neutrophils, and so on – all these labels and terms that as a kid made my brain just turn off and my eyes roll into the back of my head at the dinner table.</p>



<p>But as fate has it, my foray into magick, animism, and neurobiology has ultimately led me back discover that we have been exploring the same world all along – just from different entrances – our neurological and immune systems are a part of a larger whole that modulates together.</p>



<hr>



<p>I want to switch gears here and officially welcome another character to this story: COVID19. This pandemic spirit who has caused much death and chaos has also been responsible for accelerating the timeline for my father and I’s reconciliation.</p>



<p>It’s only with the anxious fear of death that COVID19 inspired in me that I would have bothered to do the research to look up how it causes fatality, through which I learned about <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Cytokine_release_syndrome" target="_blank">cytokine storms</a> – a phenomenon that happens when a viral infection of other factor triggers a hyper-inflammatory response that can overwhelm the body. In the case of COVID19, cytokine storms can be triggered by pneumonia it brings on in some patients and can cause a fatal chain of failures in the lungs and other organs.</p>



<p>Hearing that COVID19 ultimately kills through an autoimmune response brought me a bit emotional relief, being able to anchor into something I already feel confident I know something about – even though I wasn’t nearly settled about it. I’ve been intrigued by chronic autoimmune conditions and their connection to nervous system dysregulation from complex trauma, including ancestral trauma, for quite a while.</p>



<p>I emailed my father about the connection between the vagus nerve and cytokine storms.</p>



<p>His reply back was excited, even elated, and a lot of garbly jargon. To his credit though, it did have some keywords that led me on to better google searches about <a rel="noreferrer noopener" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4082307/" target="_blank">the relationship between the inflammatory reflex and the vagus nerve</a>.</p>



<p>I have to say that it’s hilarious – even endearing – to read his emails about the vagus nerve and the way it regulates the immune response but remembering that he has had very little idea of how to do exactly that in his real daily life.</p>



<p>(Apparently though, he has purchased a <a rel="noreferrer noopener" href="https://www.goodreads.com/book/show/520624.Healing_Trauma" target="_blank">book by Peter Levine on somatic experiencing</a>, recommended by his therapist – who he has only been seeing for three months after being essentially reprimanded by me – and has also been doing loving kindness meditations, including thinking of me.)</p>



<hr>



<p>Further researching the neuroimmune modulation brought me to <a rel="noreferrer noopener" href="https://onlinelibrary.wiley.com/doi/abs/10.1046/j.1526-0968.2002.00452.x" target="_blank">the work of another prominent Japanese immunologist, Toru Abo</a>.</p>



<p>One of Abo’s major contributions of conceptualizing how the sympathetic and parasympathetic branches of the nervous system shift our immune response:</p>



<ul><li>The sympathetic nervous system, activated in states of excited play and exploration, or fight or flight when in a survival response, tend to shift the immune system to produce granulocytes, of which the common type are neutrophils. This is significant as neutrophils and other granulocytes are specialized in handling acute distress and involved in the body’s inflammatory response. </li><li>The parasympathetic nervous system, activated in states of rest-and-digest, or freeze when in a survival response, tends shift the immune system to produce lymphocytes, which are particularly effective in managing viral infections as well as preventing chronic issues such as development tumors.</li></ul>



<p>Abo attributes the existence of these two distinct immunomodulation styles to the body’s needs in wild vs. social environments. The activities of hunting and foraging, that engage sympathetic activation, requires the body to be protected from cuts and bacterial infections that may come in through those open wounds. Hence, the production of granulocytes. On the other hand, in relaxed social environments that engage parasympathetic activation, such as a village with livestock, the main threats are viral infections that spread human-to-human or animal-to-human. This is in alignment with the production of lymphocytes when we are in rested states. </p>



<p>This leads us to consider the connection between the relationship between chronic stress and the fatality of COVID19. It is apparent from Abo’s hypothesis that constant sympathetic activation means the body’s balance of granulocytes to lymphocytes becomes deeply thrown off. Indeed, a high neutrophil-to-lymphocyte ratio is said to be a key indicator of poor COVID19 outcomes as it is connected to an increased probability of cytokine storms.</p>



<hr>



<p>Relevant to this, I watched <a href="https://www.youtube.com/watch?v=oyijHfL-W7w" target="_blank" rel="noreferrer noopener">a talk with Bruce Lipton</a>, who broke down how the fear of COVID19 is likely to create a dynamic that exacerbates the fatality of it because of fear’s impact on the nervous system. There is likely a large part of the COVID19 phenomenon that is generated by the fear-dependent nature of our communication across various media platforms – it’s bad mass hypnosis.</p>



<p>I had to agree.</p>



<p>One of our great challenges in this pandemic, and life in general, is: how do we face destabilization in a reasonably regulated state, neither overly activated or passively dissociated by threat.</p>



<p>It seems like most governments are not capable of such a neurological feat. In some ways, I can’t blame them. I’ve had great personal difficulty managing dysregulation has been for me – and I’m someone who is constantly training their nervous system.</p>



<p>So how do we deal with this fear?</p>



<p>Something that I believe is a big part of this is how we conceive of our immune system itself.</p>



<hr>


         



<hr>



<p>Someone who follows my blog sent me a reference to a book by Ed Cohen called: “<a href="https://www.dukeupress.edu/a-body-worth-defending" target="_blank" rel="noreferrer noopener">A body worth defending</a>”. It was a bit of a heady read for me, based on critical theory, but it still had important nuggets.</p>



<p>The term immunity in fact comes from law and originates in the Roman Empire. It refers to being exempt from legal bounds. Immunity began to be used in biology in the 18th century to describe the paradigm of seeing the body as a territory that is owned by man, where there is a constant need for invaders to be warded off. This means our modern conception of the immune system has an ideological connection to imperialism in all of its forms, which of course is an entirely fear-based collective behavior.</p>



<p>What I found fascinating about this was that in the end, it seemed that the operation of our immune system came down to a highly philosophical question of distinguishing between self and non-self.</p>



<p>Truth be told, I spent a few hours trying to figure out <a rel="noreferrer noopener" href="https://www.khanacademy.org/science/high-school-biology/hs-human-body-systems/hs-the-immune-system/v/self-versus-non-self" target="_blank">how the immune system determines what is self and what is not</a> and ultimately found no satisfying answers. Our entire body functions on a metaphysical self-understanding that isn’t actually quantifiable and is quite arbitrary.</p>



<p>I believe this also means that our philosophical understanding of ourselves may change how our immune system operates. And in fact, I think this is what autoimmune illnesses teach us, including COVID19.</p>



<hr>



<p>The stakes of understanding how our self-perception impacts our nervous system, and how that in turn deeply changes how we interface with the world, isn’t just applicable to the functioning of our immune system.</p>



<p>It isn’t lost on me that the mechanism of cytokine storms echo <a rel="noreferrer noopener" href="https://selfishactivist.com/understanding-accountability-abuse/" target="_blank">the self-inflicted violence of call-out/outrage culture</a>. It is again, nervous systems overloading and protection systems going into a hyperdrive that causes internal collapse.</p>



<p>In my observation of <a rel="noreferrer noopener" href="https://selfishactivist.com/understanding-accountability-abuse/" target="_blank">accountability abuse</a> in social justice communities, time and time again, I’ve seen the cultural somatic ‘immune system’ kick in to mistakenly over target individuals because of the hyper-activated voice of a few, while failing to address deeper chronic failures, leaving dysfunctional organizations and community leaders unquestioned and intact.</p>



<p>Here too, there is a deeply philosophical problem of “who are we, who are we not”, behind our failings in collective wellbeing.</p>



<hr>



<div><p>With that diversion, …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://selfishactivist.com/covid19-blues-my-father-the-immune-system-and-the-philosophy-of-thelonius-monk/">https://selfishactivist.com/covid19-blues-my-father-the-immune-system-and-the-philosophy-of-thelonius-monk/</a></em></p>]]>
            </description>
            <link>https://selfishactivist.com/covid19-blues-my-father-the-immune-system-and-the-philosophy-of-thelonius-monk/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24656227</guid>
            <pubDate>Thu, 01 Oct 2020 21:17:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A primer on engineering delivery metrics]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24656191">thread link</a>) | @Anon84
<br/>
October 1, 2020 | https://leaddev.com/primer-engineering-delivery-metrics | <a href="https://web.archive.org/web/*/https://leaddev.com/primer-engineering-delivery-metrics">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<div> <p>Before joining&nbsp;<a data-gc-link="https://stripe.com/" href="https://stripe.com/">Stripe</a>, I had the opportunity to build, grow, and lead the&nbsp;<a data-gc-link="https://splice.com" href="https://splice.com/">Splice</a>&nbsp;engineering organization for almost four years (yes, still I mix up the names). The most challenging engineering problem I’ve had to tackle so far has been working on accelerating software delivery in an organization that grew from 5 to 55+ engineers in my first 18 months. As the Splice team expanded, our ability to deliver software ground to a halt. The processes that worked when the company was small couldn’t support the explosive growth, and we needed to find a way to get back on track. By focusing on delivery metrics, we were able to increase the rate of software delivery drastically, and you don’t have to take my word for it, let’s look at a graph of cycle time (or delivery lead time) from May 2018 to April 2019.</p>
<p><img alt="Chart showing delivery lead time" data-id="null" src="https://lh3.googleusercontent.com/p4BZUo4UtAzkdOV3uqK88jTx34Cy6e_p1OJRC3WeEHBTdY1mobwx17QYg8zZly7NPJ0DACLoAVeP6LIo6APVbnD0wCnAYypKng1eiqT6qkZI3sIWbNfh-RjIvMktsp4FeNZvfxT2" title=""></p>
<p>This graph shows how we stabilized&nbsp;<strong>delivery lead time</strong>&nbsp;over a year. This metric’s average also decreased from a few hundred hours to the lower tens, even reaching 20 hours on our best delivery weeks despite frequent organization change. We did this without working longer hours or even weekends, but rather by engineering our processes using metrics to observe and direct the desired change. Today, any team can take control of their ability to deliver production-ready software at an accelerating tempo by understanding and adopting a few simple metrics. Let’s dive in.&nbsp;</p>
<h2>What are engineering delivery metrics?</h2>
<p>Engineering delivery metrics are a method of measuring the software delivery phase in software development. We measure delivery, and not the entire development process because the design phase of software varies significantly. In the early stages of software, we don't know what we're looking to build, so to make our lives easier, we focus on the portion of the pipeline where we can have more control as engineers. To do this, we can assume that the delivery process begins when we commit code and ends when code is running in production.</p>
<p><img alt="Diagram showing coding timeline" data-id="null" src="https://lh5.googleusercontent.com/mwxLQLKwZjLRvwgi31jE-SaioQlO77r0LlyBYghPafBpuojTbBWl_Cz3eWPZZ7n0bquUD1gBKt0-KQyMczOgCRFdBpSNrfhSwB0UrjHs-JVHusrl45ZgrAskb_wII5KjoxpDamKJ" title=""></p>

<table data-wrap-id="table-id-faaet"><tbody><tr data-wrap-id="table-row-xfuvw"><td data-wrap-id="table-cell-ysmwy">
<p><strong>Product design &amp; development</strong></p>
</td>
<td data-wrap-id="table-cell-ilfzf">
<p><strong>Product delivery</strong></p>
</td>
</tr><tr data-wrap-id="table-row-bbmel"><td data-wrap-id="table-cell-fwtnn">
<p>Create new products and services that solve customer problems using hypothesis-driven delivery, modern UX, and design thinking.</p>
</td>
<td data-wrap-id="table-cell-ihcpi">
<p>Enable fast flow from development to production and reliable releases by standardizing work, and reducing variability and batch sizes.</p>
</td>
</tr><tr data-wrap-id="table-row-zjizq"><td data-wrap-id="table-cell-pjyaq">
<p>Feature design and implementation may require work that has never been performed before.</p>
</td>
<td data-wrap-id="table-cell-hqhxx">
<p>Integration, test, and deployment must be performed continuously as quickly as possible.</p>
</td>
</tr><tr data-wrap-id="table-row-erjbr"><td data-wrap-id="table-cell-fulwo">
<p>Estimates are highly uncertain.</p>
</td>
<td data-wrap-id="table-cell-nkval">
<p>Cycle times should be well-known and predictable.</p>
</td>
</tr><tr data-wrap-id="table-row-pbjpf"><td data-wrap-id="table-cell-maaty">
<p>Outcomes are highly variable.</p>
</td>
<td data-wrap-id="table-cell-nbqab">
<p>Outcomes should have low variability.</p>
</td>
</tr></tbody></table><p><sup><a href="#footnote1">[1]</a></sup></p>
<p>We can instrument several metrics across the entire delivery process, and their effectiveness depends on the outcomes we're seeking for our organization. Before we measure, we must ask, ‘what are we trying to achieve with these?’ Metrics are neither good nor bad. They can be useful or harmful, and the results depend on our context and ability to use them.</p>
<p>Some examples of metrics can be:</p>
<ul><li data-gc-list-depth="1" data-gc-list-style="bullet">Build time</li>
<li data-gc-list-depth="1" data-gc-list-style="bullet">Code volume</li>
<li data-gc-list-depth="1" data-gc-list-style="bullet">Code churn</li>
<li data-gc-list-depth="1" data-gc-list-style="bullet">Time to merge</li>
</ul><p>In the absence of any context, it's hard to tell if any of these metrics will produce the desired results. For example, would we&nbsp;<a data-gc-link="https://www.infoworld.com/article/2072312/lines-of-code-and-unintended-consequences.html" href="https://www.infoworld.com/article/2072312/lines-of-code-and-unintended-consequences.html">get any positive outcomes if we measured lines of code</a>? Deleting code can sometimes produce better results than adding more.</p>
<h2>Why use delivery metrics?</h2>
<p>Knowing why we measure can be more impactful than what we measure. Software delivery is an emergent property of a software engineering team and the processes it adopts. For example, heart rate is an emergent property of the heart and can give us valuable information about its health. In conjunction with useful metrics, well-defined outcomes offer us a window into how our organization delivers software. Metrics help us observe our process and evolve it.&nbsp;<br>
&nbsp;</p>
<p>At Splice, the desired results involved eliminating roadblocks that engineers had in shipping software because we wanted to learn fast.&nbsp; Product engineering teams in early-stage companies are learning with every line of code they get in front of users. If we wanted to achieve our mission of ‘enabling Splice to learn faster than the market by delivering production-ready software at an accelerating tempo’, we needed a way to see what was holding us back so that we could change it. If we were a company that supported enterprise customers, our emphasis might have increased our services’ reliability over our iteration speed.</p>
<p><img alt="Chart showing code pushes at Splice" data-id="null" src="https://lh4.googleusercontent.com/6Br30nuJ28xuwlhfxCPSZxaR124VxWkrmrT3HQbETVsnegiB5BYwEsE8nMFwhJFoHyrTnd12wCiJ34-t1jpcx7to5-hIHnxG0NFb2OPN8TgytiACBHtGbkjzsfblLNXGUEzdWOMv" title=""></p>
<p><em><small>One year of code pushes at Splice during our delivery improvement plan, showing how we improved our throughput without growing in size or working longer hours.</small></em></p>
<p>Before you pick what you want to measure, define why you want to measure it. A few examples of outcomes you might be looking for can be:</p>
<ul><li data-gc-list-depth="1" data-gc-list-style="bullet">Better reliability</li>
<li data-gc-list-depth="1" data-gc-list-style="bullet">Improved quality</li>
<li data-gc-list-depth="1" data-gc-list-style="bullet">Lower effort</li>
<li data-gc-list-depth="1" data-gc-list-style="bullet">Increased throughput</li>
<li data-gc-list-depth="1" data-gc-list-style="bullet">Cost-effectiveness</li>
<li data-gc-list-depth="1" data-gc-list-style="bullet">Staffing efficiency</li>
<li data-gc-list-depth="1" data-gc-list-style="bullet">Faster learning</li>
</ul><h2>Which delivery metrics are useful?</h2>
<p>When you search the web for "engineering delivery metrics", the results are abundant and not always useful or tailored to your outcomes. When we embarked on this journey, the most valuable resources I found were a series of reports compiled by different groups or companies we had to mix-and-match from to get actionable results. Fortunately for us, Dr. Nicole Forsgren and her team have done all the heavy lifting and summarized it in a book called&nbsp;<a data-gc-link="https://www.oreilly.com/library/view/accelerate/9781457191435/" href="https://www.oreilly.com/library/view/accelerate/9781457191435/"><em>Accelerate.</em></a>&nbsp;It sits on my desk, next to&nbsp;<a data-gc-link="https://www.amazon.com/Managers-Path-Leaders-Navigating-Growth-ebook/dp/B06XP3GJ7F" href="https://www.amazon.com/Managers-Path-Leaders-Navigating-Growth-ebook/dp/B06XP3GJ7F"><em>The Manager's Path</em></a>&nbsp;by Camille Fournier. These two books mark the beginning of a new era in engineering leadership, where learning how to be a great leader doesn't require oral tradition inside an established tech company.</p>
<p>In&nbsp;<em>Accelerate</em>, Dr. Forsgren and her team set the foundation of four metrics they found to be good indicators of software delivery performance across thousands of organizations. From there, they also proposed a capabilities framework that can allow software organizations to increase their performance and drive better business outcomes. A fascinating conclusion is how they were able to find a relationship between software delivery and organizational performance. It seems that if we're good at delivering software, then our company as a whole performs better.</p>
<p>If you've read&nbsp;<a data-gc-link="https://leaddev.com/debugging-engineering-velocity-and-leading-high-performing-teams" href="https://leaddev.com/debugging-engineering-velocity-and-leading-high-performing-teams">Smruti's article on debugging engineering velocity</a>, you've already encountered the four metrics outlined by Dr. Fosgren, and the ones we found to be the most useful as we drove change at Splice.</p>
<h4>Software Delivery Performance Metrics</h4>
<p>⌚️&nbsp;<strong>Delivery lead time</strong>. How long it takes code from commit to production.&nbsp;<br>
🚢&nbsp;<strong>Deployment frequency.</strong>&nbsp;How often we are deploying to production.&nbsp;<br>
🚒&nbsp;<strong>Mean time to restore.</strong>&nbsp;How long it takes us to restore service after an incident.&nbsp;<br>
🔨&nbsp;<strong>Change failure rate.</strong>&nbsp;The percentage of changes that degrade service or require remediation.</p>
<h3>What about story points and velocity?</h3>
<p><a data-gc-link="https://www.agilealliance.org/glossary/velocity" href="https://www.agilealliance.org/glossary/velocity">Velocity</a>&nbsp;is not a good measure of the software delivery process because it's designed to be a capacity planning tool. When we use velocity to measure productivity, our approach is flawed because:</p>
<p>‘<em>First, velocity is a relative and team-dependent measure, not an absolute one. Teams usually have significantly different contexts which render their velocities incommensurable. Second, when velocity is used as a productivity measure, teams inevitably work to game their velocity. They inflate their estimates and focus on completing as many stories as possible at the expense of collaboration with as many stories as possible at the expense of collaboration with other teams (which might decrease their velocity and increase the other team’s velocity, making them look bad). Not only does this destroy the utility of velocity for its intended purpose, it also inhibits collaboration between teams.’&nbsp;</em><sup><em><a href="#footnote2">[2]</a></em></sup></p>
<h2>How should you use delivery metrics?</h2>
<p>Without knowing the exact problem you or your team faces, it's challenging to make a recommendation that can be helpful. Instead, I&nbsp;<a data-gc-link="https://twitter.com/buritica/status/1277745668505972736" href="https://twitter.com/buritica/status/1277745668505972736">asked engineering leaders for their questions</a>&nbsp;and found some common patterns.&nbsp;</p>
<h3>How do I convince my team about using metrics?</h3>
<p>In the last few years, I’ve advised several companies in the adoption of delivery metrics, and the first hurdle any leader has to cross is to sell their team on the use of these metrics. In my experience, convincing a team to adopt metrics is highly dependent on how well they understand the purpose of measuring, and how much they trust you. Unfortunately, metrics have been used to judge individual performance in ways that have negatively impacted employees beyond their actual performance, such as using lines of code. These poor management practices have eroded the trust between management and collaborators, and it’s normal for engineers to approach metrics with skepticism.&nbsp;</p>
<p>To successfully convince your team to adopt delivery metrics, you must have an obvious purpose for the metrics and solid reasoning for the outcomes you seek. Some questions you should be able to answer to your team members about your intention of measuring the delivery process can be:</p>
<ul><li data-gc-list-depth="1" data-gc-list-style="bullet">Why do we need metrics?</li>
<li data-gc-list-depth="1" data-gc-list-style="bullet">What are we going to measure?</li>
<li data-gc-list-depth="1" data-gc-list-style="bullet">Who will have access to these metrics?</li>
<li data-gc-list-depth="1" data-gc-list-style="bullet">Why did we pick these metrics, and which others could we have chosen?</li>
<li data-gc-list-depth="1" data-gc-list-style="bullet">What is our plan to move these metrics forward?</li>
<li data-gc-list-depth="1" data-gc-list-style="bullet">How will these metrics impact individuals?</li>
</ul><p>Engineering managers should hold their problem-solving abilities and reasoning to the same standards for engineers in their organization. In my case, writing a proposal that outlined my thinking in the form of an RFC helped iron out the details that weren’t clear, and my team helped make it more robust through their questions. You can&nbsp;<a data-gc-link="https://github.com/buritica/mgt/blob/master/rfcs/up-tempo.md" href="https://github.com/buritica/mgt/blob/master/rfcs/up-tempo.md">read the original version of this document here</a>.</p>
<p>The primary lesson I took from deploying delivery metrics was the importance of trust. For metrics to be successful, I needed my team to trust my intentions and embrace the strategy presented to them, especially when I didn’t have too many answers on the actual results we’d get. Not only should you have answers for the questions outlined above, and possibly others depending on your needs, the answers need to give confidence to your team …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://leaddev.com/primer-engineering-delivery-metrics">https://leaddev.com/primer-engineering-delivery-metrics</a></em></p>]]>
            </description>
            <link>https://leaddev.com/primer-engineering-delivery-metrics</link>
            <guid isPermaLink="false">hacker-news-small-sites-24656191</guid>
            <pubDate>Thu, 01 Oct 2020 21:12:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Golden Wall Post-Mortem (StarCraft II)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24656063">thread link</a>) | @tosh
<br/>
October 1, 2020 | http://superouman.net/2020/08/golden-wall-post-mortem/ | <a href="https://web.archive.org/web/*/http://superouman.net/2020/08/golden-wall-post-mortem/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Golden Wall’s time in the ladder and tournaments map pools has come to an end. It has been a wild ride, my favourite kind of wild ride. I’d like to take some time to share in this post-mortem what I’ve learnt from Golden Wall.</p>



<p>Creation process</p>



<p>The first version of Golden Wall had a rotational symmetry and had only one path between the two halves of the map and additional paths could be opened by mining minerals. </p>



<figure><img loading="lazy" width="1024" height="765" src="http://superouman.net/wp-content/uploads/2019/01/Golden-Wall-60-1024x765.png" alt="" srcset="http://superouman.net/wp-content/uploads/2019/01/Golden-Wall-60-1024x765.png 1024w, http://superouman.net/wp-content/uploads/2019/01/Golden-Wall-60-300x224.png 300w, http://superouman.net/wp-content/uploads/2019/01/Golden-Wall-60-768x574.png 768w, http://superouman.net/wp-content/uploads/2019/01/Golden-Wall-60.png 1951w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>







<p>The Teamliquid Map Contest 12 judges didn’t like that the single path could be heavily abused and suggested that I turn the map into a mirror symmetry map. For some reason i only had in mind a diagonal mirror symmetry in mind at that time and I didn’t manage to fit the layout properly while keeping the golden wall landmark. When the next Teamliquid Map Contest started 6 months later, I realized that vertical symmetry was the way to go and I made the appropriate edits.<br></p>



<p>With this new layout, I was able to turn the map into an experimental map while letting players play in a totally standard way if they wish to. This is something I never thought about before and I took this opportunity to try it out. </p>







<p>Main map features</p>



<p>The backdoor in the starting base that is blocked by reduced mineral fields. Backdoors in the starting base blocked by destructible rocks are a notoriously hated map feature. The attacker can easily take them down even early in the game and deal deadly damage to the opponent. </p>



<p>In theory, reduced mineral fields fix that issue because the attacker has to bring many workers that may not be able to make a hole when the defender placed ranged units behind the mineral wall. And in practice, it worked! The defender has complete control whether the path is open or not. This is definitely a map feature I’ll use again.</p>



<figure><img loading="lazy" width="1024" height="493" src="http://superouman.net/wp-content/uploads/2020/08/Terrain-791-1024x493.jpg" alt="" srcset="http://superouman.net/wp-content/uploads/2020/08/Terrain-791-1024x493.jpg 1024w, http://superouman.net/wp-content/uploads/2020/08/Terrain-791-300x144.jpg 300w, http://superouman.net/wp-content/uploads/2020/08/Terrain-791-768x370.jpg 768w, http://superouman.net/wp-content/uploads/2020/08/Terrain-791-1536x739.jpg 1536w, http://superouman.net/wp-content/uploads/2020/08/Terrain-791.jpg 1899w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>







<p>There are reduced mineral fields in the middle. Controlling this area is important when the gold bases aren’t yet open. Players often made the effort to open that path by sending a few workers so this is a success.</p>



<figure><img loading="lazy" width="1024" height="493" src="http://superouman.net/wp-content/uploads/2020/08/Terrain-793-1024x493.jpg" alt="" srcset="http://superouman.net/wp-content/uploads/2020/08/Terrain-793-1024x493.jpg 1024w, http://superouman.net/wp-content/uploads/2020/08/Terrain-793-300x144.jpg 300w, http://superouman.net/wp-content/uploads/2020/08/Terrain-793-768x370.jpg 768w, http://superouman.net/wp-content/uploads/2020/08/Terrain-793-1536x739.jpg 1536w, http://superouman.net/wp-content/uploads/2020/08/Terrain-793.jpg 1899w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>







<p>The bottom half is initially completely inaccessible to ground units.  This is a mixed bag because at the same time it allows interesting expansion layouts with different playstyles but also some really dirty strategies with Nydus/Swarm Host and Marine/Tank elevator pushes. If the defender doesn’t preemptively open the reduced mineral fields, these can be a pain to deal with. I initially expected the elevator pushes to be weaker as they require highground vision.</p>



<p>I wanted to experiment with ground area inaccessible with ground units for some time, especially lowground cliffs near expansions. What I’ve seen on Golden Wall makes me more cautious when experimenting with similar island features in the future. </p>



<figure><img loading="lazy" width="1024" height="493" src="http://superouman.net/wp-content/uploads/2020/08/Terrain-794-1024x493.jpg" alt="" srcset="http://superouman.net/wp-content/uploads/2020/08/Terrain-794-1024x493.jpg 1024w, http://superouman.net/wp-content/uploads/2020/08/Terrain-794-300x144.jpg 300w, http://superouman.net/wp-content/uploads/2020/08/Terrain-794-768x370.jpg 768w, http://superouman.net/wp-content/uploads/2020/08/Terrain-794-1536x739.jpg 1536w, http://superouman.net/wp-content/uploads/2020/08/Terrain-794.jpg 1899w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>







<p>The gold bases near the natural bases are very vulnerable to attacks. The proximity of these bases to the natural make them very strong for the extra boost to the economy. I was able to make it balance it out because of how it can be attacked from behind. It is also the shortest path to the bottom half without opening a hole in the starting base. </p>



<p>Usually, placing gold bases near natural bases allows for very strong proxy hatcheries strategies. To prevent that, the natural base has a ramp leading to it and it worked, I barely saw any proxy hatcheries there. That base was a big success!</p>



<figure><img loading="lazy" width="1024" height="493" src="http://superouman.net/wp-content/uploads/2020/08/Terrain-795-1024x493.jpg" alt="" srcset="http://superouman.net/wp-content/uploads/2020/08/Terrain-795-1024x493.jpg 1024w, http://superouman.net/wp-content/uploads/2020/08/Terrain-795-300x144.jpg 300w, http://superouman.net/wp-content/uploads/2020/08/Terrain-795-768x370.jpg 768w, http://superouman.net/wp-content/uploads/2020/08/Terrain-795-1536x739.jpg 1536w, http://superouman.net/wp-content/uploads/2020/08/Terrain-795.jpg 1899w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>How the map played out</p>



<p>Because of these map features, the games were very diverse. To the point where each player has its own stylistic approach to the map. Most maps are figured out in a few weeks with their timings, attack/drop routes, proxy locations and so on. On Golden Wall however, the meta was evolving every month with seemingly overpowered strategies finding their counter.</p>



<p>These are the final Golden Wall matchup balance stats.</p>



<figure><img loading="lazy" width="841" height="98" src="http://superouman.net/wp-content/uploads/2020/10/golden_wall_stats.png" alt="Golden Wall balance statistics" srcset="http://superouman.net/wp-content/uploads/2020/10/golden_wall_stats.png 841w, http://superouman.net/wp-content/uploads/2020/10/golden_wall_stats-300x35.png 300w, http://superouman.net/wp-content/uploads/2020/10/golden_wall_stats-768x89.png 768w" sizes="(max-width: 841px) 100vw, 841px"></figure>



<p>Source: <a href="https://liquipedia.net/starcraft2/Golden_Wall_LE" target="_blank" rel="noreferrer noopener">https://liquipedia.net/starcraft2/Golden_Wall_LE</a></p>



<p>The map ended up very well balanced for the amount of unusual features it has. With this kind of maps, it’s often a shot in the dark with the balance even with educated guesses about how it would play out theorically.</p>



<p>Conclusion</p>



<p>In the end, Golden Wall is my favourite map i’ve made to this day. It has the highest diversity of opening and strategies and it was a treat to watch them. Some players play completely standard with the top part, some use only the bottom part and others have a mixed use of the two halves. What i love the most about this left versus right map is that some games end up with a top versus bottom layout. Some games even had their players swap their main bases! Crazy.</p>



<figure><div>
<p><iframe title="StarCraft 2: NEW MAP - THE GOLDEN WALL! (uThermal vs Reynor)" width="1150" height="647" src="https://www.youtube.com/embed/3rlNKYAnKfE?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
</div></figure>



<p>I am definetly going to reuse some of the features and lessons of Golden Wall in future maps so stay tuned!</p>
	</div></div>]]>
            </description>
            <link>http://superouman.net/2020/08/golden-wall-post-mortem/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24656063</guid>
            <pubDate>Thu, 01 Oct 2020 20:55:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Asynchronous Development for Hybrid Remote Dev Teams]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24656046">thread link</a>) | @davetwichell
<br/>
October 1, 2020 | https://linearb.io/blog/asynchronous-development/ | <a href="https://web.archive.org/web/*/https://linearb.io/blog/asynchronous-development/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="670d84f7" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
			
<p>Hope and optimism are default settings for my LinearB co-founder, Ori Keren. For Ori, one silver lining in this tumultuous year is that 2020 ushered in the age of the hybrid remote work model. </p>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM-1024x429.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM-300x126.png.webp 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM-768x322.png.webp 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM-1536x644.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM.png.webp 1908w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM-1024x429.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM-1024x429.png 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM-300x126.png 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM-768x322.png 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM-1536x644.png 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM.png 1908w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>



<figure><audio controls="" src="https://linearb.io/wp-content/uploads/2020/09/Asynch-2.mp3"></audio><figcaption><em>Click here to hear Ori</em></figcaption></figure>







<p>“Hybrid remote is how software development teams were always meant to work. It just took 20 years and a global pandemic for us to figure that out.” </p>



<p>Ori believes that, to be highly successful, developers need uninterrupted time to get into a deep state of focus on their task at hand. Getting in “the zone” is hard and when you get interrupted you can’t easily get your deep focus back. </p>



<p>Remote work has eliminated most dev interruptions, right? Not so fast. </p>



<p>Company culture is a powerful force. Like gravity, we don’t see or or think about most days but it effects everything we do. </p>



<div><p>According to Ori, culture is even more powerful than a global pandemic or a new trend like hybrid remote. </p><p>“Working remote was great for our dev team at first. Once we got over the initial disruption of getting equipment and finding a quiet place to work at home, team productivity soared. But then we started noticing our efficiency going down.” </p></div>



<div><p>What happened? Our in-the-office culture grabbed hold and brought us right back to where we were in March. </p><p>“All of the interruptions crept back in… scheduled meetings, impromptu Zoom status meetings…” </p><p>In other words, we were a hybrid remote company with an in-the-office mindset and process. </p><p>You can see the effects here in our Cycle Time trend chart. </p></div>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-1024x586.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-300x172.png.webp 300w, https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-768x440.png.webp 768w, https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-1536x879.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-2048x1172.png.webp 2048w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-1024x586.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-1024x586.png 1024w, https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-300x172.png 300w, https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-768x440.png 768w, https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-1536x879.png 1536w, https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-2048x1172.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>







<div><p>“Being a remote employee used to be a semi-unique experience that came with a certain level of trust, preparation and experience. Then the entire global dev community went remote at the same time, without preparation or understanding of what needs to change.”</p><p>Hybrid remote can be a business advantage for companies embracing it. But only if we adapt our culture and process to make it work. </p></div>



<p>This is how Asynchronous Development was born. </p>







<h2>What is Asynchronous Development?</h2>



<p>Async Dev is an approach to development grounded in asynchronous communication. It works for hybrid remote, full remote and any dev teams that wants to unlock the full creative power of their developers. </p>







<iframe width="560" height="465" src="https://www.youtube.com/embed/w0pw0dcFZ-w?rel=0" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>







<p>Async Dev builds on the foundation Agile put in place. Since the Agile Manifesto was published 20 years ago, software development has gone through some drastic changes. Many of those changes like asynchronous communication tools (e.g. Slack &amp; Teams) becoming the default form of communication and hiring remote developers were forced into the spotlight in 2020. </p>



<p>Ori  started wrote the Async Dev manifesto to help engineering and product leaders see how they can change the way they work to turn this new situation into an opportunity. </p>



<p><strong><em>Below Ori explains how Async Dev builds on the Agile and DevOps movements and talk through each of the five core tenets of Async Dev. Listen to the accompanying 60~ second audio clip from Ori in each section or just read the blog</em></strong>. </p>







<h2>The Async Dev Movement</h2>



<p>Hybrid remote development is not new, but 2020 accelerated the adoption of many of the practices already in place. As these hybrid remote methods are normalized globally, we also have to accept the way we work, the processes, and the ceremonies have changed as well. </p>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-1024x489.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-300x143.png.webp 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-768x367.png.webp 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-1536x734.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-2048x978.png.webp 2048w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-1024x489.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-1024x489.png 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-300x143.png 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-768x367.png 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-1536x734.png 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-2048x978.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>



<figure><audio controls="" src="https://linearb.io/wp-content/uploads/2020/10/history-1.mp3"></audio><figcaption><em>Click here to hear Ori</em></figcaption></figure>







<p>Asynchronous Development acknowledges the importance of movements like Agile and DevOps and offers a new way of looking at development that is a better fit for 2020.&nbsp;</p>











<h2>The 5 Tenets of Asynchronous Development</h2>



<p>There are 5 core tenets of Async Dev that we have adopted to transform the hybrid remote reality into an opportunity to strengthen the alignment between development and the business.</p>







<div><div>
<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-1024x521.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-300x153.png.webp 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-768x391.png.webp 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-1536x782.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-2048x1043.png.webp 2048w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-1024x521.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-1024x521.png 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-300x153.png 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-768x391.png 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-1536x782.png 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-2048x1043.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>
</div></div>







<ol><li>Asynchronous is the default form of communication</li><li>Git is the central element of your development process</li><li>Project Management tools are for planning, not status updates</li><li>Continuous improvement is a daily practice</li><li>Dev teams are the core of the business</li></ol>











<figure><blockquote><p>LinearB built a new kind of project board exclusively for hybrid remote dev teams.</p><p><span><a href="https://linearb.io/get-started-linearb/" target="_blank" rel="noreferrer noopener">Get our Devboard free</a></span></p></blockquote></figure>







<h2>Tenet 1 – Asynchronous is the default form of communication</h2>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM-1024x462.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM-300x135.png.webp 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM-768x347.png.webp 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM-1536x693.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM.png.webp 1950w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM-1024x462.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM-1024x462.png 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM-300x135.png 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM-768x347.png 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM-1536x693.png 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM.png 1950w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>



<figure><audio controls="" src="https://linearb.io/wp-content/uploads/2020/09/Tenet-1.mp3"></audio><figcaption>Click here to listen to Ori</figcaption></figure>







<p>Asynchronous communication means using collaboration tools and mentions by default. It helps reduce context switching, avoid unnecessary interruptions, and increases productivity. </p>



<p>After LinearB went full remote back in April of 2020, we analyzed our development team’s metrics to understand exactly how this change effected the productivity and efficiency of the team. </p>



<p>In true Asynchronous fashion, 92% of developers at LinearB were writing more code, while PR sizes and Cycle Times increased. This clearly tells us that fewer interruptions means greater individual productivity. It also clearly shows what we needed to adapt the way worked to the new circumstances if we were going to continue delivering at the same level as pre-wfh. </p>



<p>At LinearB we have started taking a closer look at the function of the daily stand-up and how to use that time to best suit our team. Now that we are a hybrid remote development team with up to the minute updates on issue statuses using LinearB, we use our stand-up time to connect on a personal level, and then just talk about blockers. It’s not perfect, but it’s been a nice adaptation to our new reality.</p>







<h2>Tenet 2 – Git is the central element of your development process</h2>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM-1024x580.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM-300x170.png.webp 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM-768x435.png.webp 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM-1536x869.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM.png.webp 1802w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM-1024x580.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM-1024x580.png 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM-300x170.png 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM-768x435.png 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM-1536x869.png 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM.png 1802w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>



<figure><audio controls="" src="https://linearb.io/wp-content/uploads/2020/09/Tenet-2_2-1.mp3"></audio><figcaption>Click here to hear Ori</figcaption></figure>







<p>Whether you use GitHub, GitLab, Bitbucket, Azure DevOps or other git flavor, most of the stages of the development cycle either start or involve your git system. How you choose to configure, deploy and utilize it has a great impact on your dev process. </p>



<p>In addition the most up to date status of work progress resides in the git system. Fortunately git was built with open source in mind so most of the phases (coding, review, merge) do not require mandatory synchronous communication and can be executed in different places and different times.</p>











<h2>Tenet 3 – Project Management tools are for planning, not status updates</h2>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM-1024x581.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM-300x170.png.webp 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM-768x436.png.webp 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM-1536x871.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM.png.webp 1714w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM-1024x581.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM-1024x581.png 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM-300x170.png 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM-768x436.png 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM-1536x871.png 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM.png 1714w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>



<figure><audio controls="" src="https://linearb.io/wp-content/uploads/2020/09/Tenet3_2.mp3"></audio><figcaption><em>Click here to hear Ori</em></figcaption></figure>







<p>Whether your team uses Jira, Trello or something else, project management tools are great for planning an iteration or the next week, but trying to use them to enrich dozens of micro decisions that dev teams are taking every day will slow down productivity. </p>



<p>Every update to the work status while in ‘building mode’ should be with dev first in mind, meaning it should automatically reflect the status based on actual git activity and it should mainly serve the people that build and ship the software.</p>







<figure><blockquote><p>Does your current project board</p><p>give you more questions than answers?</p><p><a href="https://linearb.io/get-started-linearb/" target="_blank" rel="noreferrer noopener">Try the LinearB Devboard free</a></p></blockquote></figure>







<h2>Tenet 4 – Continuous improvement is a daily practice</h2>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM-1024x596.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM-300x175.png.webp 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM-768x447.png.webp 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM-1536x895.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM.png.webp 1724w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM-1024x596.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM-1024x596.png 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM-300x175.png 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM-768x447.png 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM-1536x895.png 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM.png 1724w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>



<figure><audio controls="" src="https://linearb.io/wp-content/uploads/2020/10/tenet4new.mp3"></audio><figcaption><em>Click here to hear Ori</em></figcaption></figure>







<p>Data should always be accessible to everyone – no gate keepers, not just data engineers, and not just reviewed in meetings by management.</p>



<p>Your KPIs and how you decide to utilized them will define your culture. </p>



<p>Key Principles for Data Usage: </p>



<ul><li>Team-based data over developer stack ranking</li><li>Measure process over output</li><li>Measure empiric over subjective</li><li>Focus on leading indicators vs. lagging indicators</li><li>Establish baseline data points and trends</li><li>Make sure it’s actionable</li></ul>







<p>Data should be used in an ethical way and cannot replace good managers with good soft skills and human interaction.</p>







<figure><blockquote><p>High-risk code &amp; stuck PR Slack Alerts are pretty amazing.</p><p><a href="https://linearb.io/get-started-linearb/" target="_blank" rel="noreferrer noopener">Get them Free with LinearB</a></p></blockquote></figure>







<h2>Tenet 5 – Dev teams are the core of the business</h2>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM-1024x552.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM-300x162.png.webp 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM-768x414.png.webp 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM-1536x828.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM.png.webp 1988w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM-1024x552.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM-1024x552.png 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM-300x162.png 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM-768x414.png 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM-1536x828.png 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM.png 1988w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>



<figure><audio controls="" src="https://linearb.io/wp-content/uploads/2020/09/Tenet-5_1.mp3"></audio><figcaption><em>Click here to hear Ori</em></figcaption></figure>







<p>The best companies in the world evolved from developers that were highly aligned with business and market needs. Dev-led companies empower developers to make decisions on behalf of customers and the business by giving them context instead of instructions.&nbsp;</p>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-1024x460.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-300x135.png.webp 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-768x345.png.webp 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-1536x689.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-2048x919.png.webp 2048w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-1024x460.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-1024x460.png 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-300x135.png 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-768x345.png 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-1536x689.png 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-2048x919.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>







<p>We believe that ‘developers’ and ‘business’ are not disjoint sets and sometimes the most important business decisions are hiding in code lines. That is why the best businesses should focus on pushing context to dev teams, and dev teams should provide transparency into their decision making so both can enjoy a refinement cycle.</p>



<p>This is probably the hardest part of making Async Dev a reality because, as dev leaders, it is the element we have least control over. We need buy-in from throughout the business. </p>







<h3><strong>Here are 5 practical steps you can take today to start practicing Async Dev:</strong></h3>







<h4>1) Cut status updates from your daily stand-up</h4>



<p>Instead focus on what matters – who needs help and whether you’re going to ship on time. Async Dev means never spending valuable meeting time on status updates when everyone could take 5 minutes on their own before the meeting to see what happened yesterday and what’s happening today. <a href="https://linearb.io/blog/make-daily-better/" target="_blank" rel="noreferrer noopener">Click here to get 16 tips</a> for how to run a better daily stand-up. </p>







<h4>2) Decouple learning and improvement from your retro. </h4>



<p>We’re not saying to cancel your retro. Getting together every few weeks to discuss learnings is great. But if you un-gate your team metrics so everyone can see bottlenecks and suggestions for how to improve each day, then improvement can be led everyone on your team (not just managers) and become part of the fabric of your team culture. <a href="https://linearb.io/blog/data-driven-dev-team/" target="_blank" rel="noreferrer noopener">Click here to see how to use data in your day-to-day</a> practices without damaging culture. </p>







<h4>3) Combine quantitative signals &amp; qualitative assessments for team health</h4>



<p>Use multiple data points to identify signs of overload and burnout. Face to face conversation is not the only way to see if a teammate is struggling. Looking at your WIP balance across the team and consecutive days worked, in combination with 1:1 conversation, can tell you a lot about a person’s work health. <a href="https://linearb.io/blog/dev-team-health/" target="_blank" rel="noreferrer noopener">Click here to see which data points can help you …</a></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://linearb.io/blog/asynchronous-development/">https://linearb.io/blog/asynchronous-development/</a></em></p>]]>
            </description>
            <link>https://linearb.io/blog/asynchronous-development/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24656046</guid>
            <pubDate>Thu, 01 Oct 2020 20:53:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Build a video chat app in Phoenix LiveView]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24656017">thread link</a>) | @rahimnathwani
<br/>
October 1, 2020 | https://littlelines.com/blog/2020/07/06/building-a-video-chat-app-in-phoenix-liveview | <a href="https://web.archive.org/web/*/https://littlelines.com/blog/2020/07/06/building-a-video-chat-app-in-phoenix-liveview">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <section>
            <p>During this global pandemic, online video calls have become essential to the way we work. Millions of workers are now accustomed to hopping on calls with their colleagues to hash things out that they would previously have done in person. Zoom has shown itself to be a reliable partner for video conferencing. However, as a company, Zoom has given <a href="https://theintercept.com/2020/03/31/zoom-meeting-encryption/">plenty of</a> <a href="https://techcrunch.com/2019/07/10/apple-silent-update-zoom-app/">reasons to</a> <a href="https://www.theverge.com/2020/6/3/21279355/zoom-end-encryption-calls-fbi-police-free-users">avoid</a> <a href="https://www.npr.org/2020/06/12/876351501/zoom-acknowledges-it-suspended-activists-accounts-at-china-s-request">its software.</a></p>

<p>The world’s new reliance on video conferencing got me thinking: <em>How hard could it be to build a video conferencing web application?</em> Like most things worth doing, the answer was <em>difficult, but fun</em>.</p>

<p>When I first started researching for this project, I discovered that there isn’t much information out there about building a WebRTC-based application from start to finish. Mozilla’s WebRTC documentation is invaluable, but it lacked answers to some of the questions I had. And tutorials that exist generally only cover connecting two users in a fairly basic way. I wanted to do something more ambitious.</p>

<h2 id="what-were-going-to-build">What we’re going to build:</h2>

<p>In this article, we’re going to build a real-time video chat application with the following requirements:</p>

<ul>
  <li>The app will allow users to create video chat rooms with a unique slug, allowing any user to join.</li>
  <li>The app will keep track of which users are connected to the given room.</li>
  <li>The app will allow users to establish a group video call with eachother through WebRTC peer connections.</li>
</ul>

<p>Well, that sounds easy enough. Creating pages with central information on the fly in a web app is the bread and butter of any self-respecting web framework—and with Phoenix it’s a piece of cake. Tracking users seems a little tricky, but if you’ve heard of what LiveView and PubSub can do, you can probably guess that we’re still on the right track. WebRTC was designed for video calls, but group video calls? That might get complex. Plus, how would that even work if each of the connections is only peer-to-peer? We’ll get to that.</p>

<ul>
  <li><a href="https://littlechat.app/">We’ve wrapped up the finished product and deployed it at littlechat.app</a>. Try creating a room and hopping on it with a friend or two. That’s what we’re going to create.</li>
  <li><a href="https://github.com/littlelines/littlechat">You can also find the source code for this project here if you’re more of the self-guided type.</a></li>
</ul>

<h2 id="prerequisites">Prerequisites</h2>

<p>I’m going to assume that you are comfortable working with Elixir and Phoenix. I’ll assume that you might have toyed around with LiveView a few times before this article, but it doesn’t take much to get up to speed. Finally, I’ll assume you have no WebRTC experience beyond having heard about it a few times.</p>

<p>We will be using the latest versions of Elixir, Erlang, Phoenix, and Phoenix LiveView in this article, which are the following at the time of writing:</p>

<ul>
  <li>Elixir 1.10.3</li>
  <li>Erlang 23.0.2</li>
  <li>Phoenix 1.5.3</li>
  <li>Phoenix LiveView 0.13.3</li>
</ul>

<h2 id="the-tech">The Tech</h2>

<h3 id="webrtc">WebRTC</h3>

<p>Web Real Time Communication, or WebRTC for short, is a technology that allows real-time, peer-to-peer communication between users. It provides an API for handling user video, audio, and other data via peer-to-peer connections.</p>

<p>WebRTC has been around since 2011, but implementation by the various browsers has been uneven over the years. Nowadays, each browser has a more consistent WebRTC implementation, making browser support much better, but implementing it can still be a dance.</p>

<p>What makes WebRTC so flexible—and, at times, confounding—is that it has no standardized server-side implementation. WebRTC does not care how users in a video chat learn about each other and send their connection information, it only handles how to connect those users once their information has been sent. This originally confused me, as I was not sure where the server-side <em>signaling</em> (the WebRTC term for the process of telling two users about each other for a peer connection) ended and the <code>RTCPeerConnection</code> began. We’ll dig into this later.</p>

<h3 id="phoenix">Phoenix</h3>

<p>Elixir’s Phoenix framework allows us to build reliable and performant web applications built on Erlang’s rock-solid foundation. On any project, my first instinct these days is to reach for Phoenix. But the motivation goes deeper.</p>

<p>Elixir is built on Erlang’s VM, which was specifically developed for the challenges of the telecoms industry, where fault-tolerance and high-availability are essential. That sounds perfect for this project.</p>

<h3 id="liveview">LiveView</h3>

<p><a href="https://hexdocs.pm/phoenix_live_view/Phoenix.LiveView.html">LiveView</a> is one of my favorite components of Phoenix. It makes real-time user interaction between the client’s UI and the server seamless, without needing to write (much) JavaScript. LiveView makes real-time user interactions much easier to build and maintain, all while working within familiar concepts: Phoenix, Elixir, and OTP.</p>

<h2 id="getting-started">Getting Started</h2>

<p>Have you got all your tools ready? Let’s go!</p>

<p>First, we’re going to create a new Phoenix project with LiveView already configured. If you’re trying to add video chat to an existing app without LiveView already configured, <a href="https://hexdocs.pm/phoenix_live_view/installation.html#content">LiveView is pretty easy to set up from scratch too.</a> We’re going to call our project Littlechat, a portmenteau of Littlelines and chat.</p>

<div><pre><code><span>$ </span>mix phx.new littlechat --live</code></pre></div>

<p>Now let’s <code>cd littlechat</code> into our brand new app and install its dependencies.</p>

<div><pre><code><span>$ </span><span>cd </span>littlechat
<span>$ </span>mix deps.get
<span>$ </span>npm install --prefix assets</code></pre></div>

<p>Standard stuff. Let’s go a little deeper.</p>

<h2 id="creating-the-rooms">Creating the Rooms</h2>

<p>Users can’t connect to each other if they don’t have a place to meet, so let’s build them a room!</p>

<p>Let’s create a <em>context</em> called <code>Organizer</code> with a schema <code>Room</code>.</p>

<div><pre><code><span>$ </span>mix phx.gen.context Organizer Room rooms title:string slug:string</code></pre></div>

<p>That generated a few files for us, <code>lib/littlechat/organizer.ex</code>, <code>lib/littlechat/organizer/room.ex</code>, and a migration file ending in <code>XXXXX_create_rooms.exs</code> Let’s start with our Room schema.</p>

<p>Our rooms will only have two data to start, <code>slug</code> and <code>title</code>, both strings. <code>slug</code> will be the unique identifier for the room, so we’ll need to add a unique index to the database to prevent collisions. Let’s set up the database:</p>

<div><pre><code><span># priv/repo/migrations/XXXXX_create_rooms.exs</span>

<span>defmodule</span> <span>Littlechat.Repo.Migrations.CreateRooms</span> <span>do</span>
  <span>use</span> <span>Ecto.Migration</span>

  <span>def</span> <span>change</span> <span>do</span>
    <span>create</span> <span>table</span><span>(</span><span>"rooms"</span><span>)</span> <span>do</span>
      <span>add</span> <span>:slug</span><span>,</span> <span>:string</span>
      <span>add</span> <span>:title</span><span>,</span> <span>:string</span>

      <span>timestamps</span><span>()</span>
    <span>end</span>

    <span>create</span> <span>unique_index</span><span>(</span><span>:rooms</span><span>,</span> <span>:slug</span><span>)</span>
  <span>end</span>
<span>end</span></code></pre></div>

<p>For the schema, we’re going to create a basic changeset function with the added <code>unique_constraint</code> on slug. But we’re also going to add a private function, <code>format_slug/1</code> for the purpose of cleaning our slug input.</p>

<div><pre><code><span># lib/littlechat/room.ex</span>

<span>defmodule</span> <span>Littlechat.Room</span> <span>do</span>
  <span>@moduledoc</span> <span>"""</span>
<span>  Schema for creating video chat rooms.</span>
<span>  """</span>

  <span>use</span> <span>Ecto.Schema</span>
  <span>import</span> <span>Ecto.Changeset</span>

  <span>schema</span> <span>"rooms"</span> <span>do</span>
    <span>field</span> <span>:title</span><span>,</span> <span>:string</span>
    <span>field</span> <span>:slug</span><span>,</span> <span>:string</span>

    <span>timestamps</span><span>()</span>
  <span>end</span>

  <span>@fields</span> <span>[</span><span>:title</span><span>,</span> <span>:slug</span><span>]</span>

  <span>def</span> <span>changeset</span><span>(</span><span>room</span><span>,</span> <span>attrs</span><span>)</span> <span>do</span>
    <span>room</span>
    <span>|&gt;</span> <span>cast</span><span>(</span><span>attrs</span><span>,</span> <span>@fields</span><span>)</span>
    <span>|&gt;</span> <span>validate_required</span><span>([</span><span>:title</span><span>,</span> <span>:slug</span><span>])</span>
    <span>|&gt;</span> <span>format_slug</span><span>()</span>
    <span>|&gt;</span> <span>unique_constraint</span><span>(</span><span>:slug</span><span>)</span>
  <span>end</span>

  <span>defp</span> <span>format_slug</span><span>(%</span><span>Ecto.Changeset</span><span>{</span><span>changes</span><span>:</span> <span>%{</span><span>slug</span><span>:</span> <span>_</span><span>}}</span> <span>=</span> <span>changeset</span><span>)</span> <span>do</span>
    <span>changeset</span>
    <span>|&gt;</span> <span>update_change</span><span>(</span><span>:slug</span><span>,</span> <span>fn</span> <span>slug</span> <span>-&gt;</span>
      <span>slug</span>
      <span>|&gt;</span> <span>String</span><span>.</span><span>downcase</span><span>()</span>
      <span>|&gt;</span> <span>String</span><span>.</span><span>replace</span><span>(</span><span>" "</span><span>,</span> <span>"-"</span><span>)</span>
    <span>end</span><span>)</span>
  <span>end</span>
  <span>defp</span> <span>format_slug</span><span>(</span><span>changeset</span><span>),</span> <span>do</span><span>:</span> <span>changeset</span>
<span>end</span></code></pre></div>

<p>Great! Now we can create rooms in the database. What about getting one from the DB? Easy.</p>

<div><pre><code><span># lib/littlechat/organizer.ex</span>

<span>defmodule</span> <span>Littlechat.Organizer</span> <span>do</span>
  <span>alias</span> <span>Littlechat.Repo</span>
  <span>alias</span> <span>Littlechat.Room</span>

  <span>import</span> <span>Ecto.Query</span>

  <span>def</span> <span>get_room</span><span>(</span><span>slug</span><span>)</span> <span>when</span> <span>is_binary</span><span>(</span><span>slug</span><span>)</span> <span>do</span>
    <span>from</span><span>(</span><span>room</span> <span>in</span> <span>Room</span><span>,</span> <span>where</span><span>:</span> <span>room</span><span>.</span><span>slug</span> <span>==</span> <span>^</span><span>slug</span><span>)</span>
    <span>|&gt;</span> <span>Repo</span><span>.</span><span>one</span><span>()</span>
  <span>end</span>
<span>end</span></code></pre></div>

<p>Now let’s build LiveViews for creating and viewing rooms.</p>

<p>We’re going to create two LiveViews, <code>LittlechatWeb.Room.NewLive</code> and <code>LittlechatWeb.Room.ShowLive</code>, the former for creating and the latter for showing the rooms. Let’s start with <code>NewLive</code>:</p>

<div><pre><code><span># lib/littlechat_web/live/room/new_live.ex</span>

<span>defmodule</span> <span>LittlechatWeb.Room.NewLive</span> <span>do</span>
  <span>use</span> <span>LittlechatWeb</span><span>,</span> <span>:live_view</span>

  <span>alias</span> <span>Littlechat.Repo</span>
  <span>alias</span> <span>Littlechat.Room</span>

  <span>@impl</span> <span>true</span>
  <span>def</span> <span>render</span><span>(</span><span>assigns</span><span>)</span> <span>do</span>
    <span>~L</span><span>"""</span>
<span>    &lt;h1&gt;Create a New Room&lt;/h1&gt;</span>
<span>    &lt;div&gt;</span>
<span>      &lt;%= form_for @changeset, "#", [phx_change: "validate", phx_submit: "save"], fn f -&gt; %&gt;</span>
<span>        &lt;%= text_input f, :title, placeholder: "Title" %&gt;</span>
<span>        &lt;%= error_tag f, :title %&gt;</span>
<span>        &lt;%= text_input f, :slug, placeholder: "room-slug" %&gt;</span>
<span>        &lt;%= error_tag f, :slug %&gt;</span>
<span>        &lt;%= submit "Save" %&gt;</span>
<span>      &lt;% end %&gt;</span>
<span>    &lt;/div&gt;</span>
<span>    """</span>
  <span>end</span>

  <span>@impl</span> <span>true</span>
  <span>def</span> <span>mount</span><span>(</span><span>_params</span><span>,</span> <span>_session</span><span>,</span> <span>socket</span><span>)</span> <span>do</span>
    <span>{</span><span>:ok</span><span>,</span>
      <span>socket</span>
      <span>|&gt;</span> <span>put_changeset</span><span>()</span>
    <span>}</span>
  <span>end</span>

  <span>@impl</span> <span>true</span>
  <span>def</span> <span>handle_event</span><span>(</span><span>"validate"</span><span>,</span> <span>%{</span><span>"room"</span> <span>=&gt;</span> <span>room_params</span><span>},</span> <span>socket</span><span>)</span> <span>do</span>
    <span>{</span><span>:noreply</span><span>,</span>
      <span>socket</span>
      <span>|&gt;</span> <span>put_changeset</span><span>(</span><span>room_params</span><span>)</span>
    <span>}</span>
  <span>end</span>

  <span>def</span> <span>handle_event</span><span>(</span><span>"save"</span><span>,</span> <span>_</span><span>,</span> <span>%{</span><span>assigns</span><span>:</span> <span>%{</span><span>changeset</span><span>:</span> <span>changeset</span><span>}}</span> <span>=</span> <span>socket</span><span>)</span> <span>do</span>
    <span>case</span> <span>Repo</span><span>.</span><span>insert</span><span>(</span><span>changeset</span><span>)</span> <span>do</span>
      <span>{</span><span>:ok</span><span>,</span> <span>room</span><span>}</span> <span>-&gt;</span>
        <span>{</span><span>:noreply</span><span>,</span>
          <span>socket</span>
          <span>|&gt;</span> <span>push_redirect</span><span>(</span><span>to</span><span>:</span> <span>Routes</span><span>.</span><span>room_show_path</span><span>(</span><span>socket</span><span>,</span> <span>:show</span><span>,</span> <span>room</span><span>.</span><span>slug</span><span>))</span>
        <span>}</span>
      <span>{</span><span>:error</span><span>,</span> <span>changeset</span><span>}</span> <span>-&gt;</span>
        <span>{</span><span>:noreply</span><span>,</span>
          <span>socket</span>
          <span>|&gt;</span> <span>assign</span><span>(</span><span>:changeset</span><span>,</span> <span>changeset</span><span>)</span>
          <span>|&gt;</span> <span>put_flash</span><span>(</span><span>:error</span><span>,</span> <span>"Could not save the room."</span><span>)</span>
        <span>}</span>
    <span>end</span>
  <span>end</span>

  <span>defp</span> <span>put_changeset</span><span>(</span><span>socket</span><span>,</span> <span>params</span> <span>\\</span> <span>%{})</span> <span>do</span>
    <span>socket</span>
    <span>|&gt;</span> <span>assign</span><span>(</span><span>:changeset</span><span>,</span> <span>Room</span><span>.</span><span>changeset</span><span>(%</span><span>Room</span><span>{},</span> <span>params</span><span>))</span>
  <span>end</span>
<span>end</span></code></pre></div>

<p>Let’s break this down by function.</p>

<ul>
  <li><code>render/1</code> implements a LiveView callback with the given <code>assigns</code> (variables containing session data) and expects a <code>~L</code> sigil (Live EEx). I prefer my LEEx templates inline, but you’re welcome to create a file <code>lib/littlechat_web/live/room/new_live.html.leex</code> and get rid of this function if you prefer to keep your templates separate.</li>
  <li>Inside of this template, we create a basic form for creating a new Room. Note the reference to the <code>@changeset</code> assign.</li>
  <li>We then tell the form (via LiveView) to send the event <code>"validate"</code> to the server every time user input is added.</li>
  <li>Finally, we tell the form to send the event <code>"submit"</code>, along with the associated form data, to the server when the user makes a submit action (presses enter or clicks “Submit”).</li>
  <li><code>mount/3</code> is a key callback that makes the LiveView function. It contains three arguments, <code>par…</code></li></ul></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://littlelines.com/blog/2020/07/06/building-a-video-chat-app-in-phoenix-liveview">https://littlelines.com/blog/2020/07/06/building-a-video-chat-app-in-phoenix-liveview</a></em></p>]]>
            </description>
            <link>https://littlelines.com/blog/2020/07/06/building-a-video-chat-app-in-phoenix-liveview</link>
            <guid isPermaLink="false">hacker-news-small-sites-24656017</guid>
            <pubDate>Thu, 01 Oct 2020 20:49:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Authenticating with AWS Managed Microsoft Active Directory and LDAP]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24655887">thread link</a>) | @mooreds
<br/>
October 1, 2020 | https://fusionauth.io/blog/2020/10/01/active-directory-connector | <a href="https://web.archive.org/web/*/https://fusionauth.io/blog/2020/10/01/active-directory-connector">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
              <p>Microsoft’s Active Directory is a common enterprise user data store. If you are building apps for users authenticated by Active Directory, you might want to connect FusionAuth to it. Another common use case is to have some applications for internal users which should be authenticated against Active Directory and other applications for people outside your organization, with user data stored in FusionAuth. FusionAuth can act as a CIAM for your external users, but delegate authentication of internal accounts to Active Directory.</p>

<!--more-->

<p>If you do this, applications no longer have to understand LDAP or be able to connect to your Active Directory server. Any framework or application with OAuth/OIDC or SAML support talks to FusionAuth for auth information, while user data remains in Active Directory.</p>

<p>You can achieve this with the FusionAuth LDAP connector. This post will explain how to set up a connection between FusionAuth and Active Directory. For this post, <a href="https://aws.amazon.com/directoryservice/active-directory/">AWS Microsoft Managed AD</a> is used, but the configuration and concepts will work with any Microsoft Active Directory instance.</p>

<h2 id="setting-up-microsoft-active-directory">Setting up Microsoft Active Directory</h2>

<p>There are a few steps you need to take before you can dive into configuring the LDAP Connector.</p>

<p><em>Connectors are a feature of the paid editions. You can sign up for a free trial of the <a href="https://fusionauth.io/pricing">FusionAuth Developer Edition</a>.</em></p>

<p>To fully explore this scenario, you need to have an application users can sign into with their Active Directory credentials. In this post, you are going to use ASP.NET to run such an application, so make sure you have .NET Core version 3 installed if you want to follow along with the code. I found the <a href="https://dotnet.microsoft.com/download/dotnet-core/scripts">bash script here</a> worked best for installing on macOS.</p>

<p>Then, ensure you have FusionAuth installed and running. You can download and install FusionAuth <a href="https://fusionauth.io/docs/v1/tech/installation-guide/">using Docker, RPM, or in a number of other ways</a>. You’ll need at least version 1.18. Make sure you’ve <a href="https://fusionauth.io/docs/v1/tech/reactor">activated your instance</a> by providing a license key to enable the Connector feature.</p>

<p>Next, make sure you have Active Directory accessible to the server running FusionAuth, since they will need to communicate. In my case, since AWS Microsoft Managed AD doesn’t by <a href="https://forums.aws.amazon.com/thread.jspa?messageID=688592&amp;#688592">default expose an interface to the outside world</a>, I stood up a FusionAuth server on an EC2 instance in the same subnet. You could use a VPN, SSH tunnel or HTTP proxy in front of Active Directory as well.</p>

<p>Test that you can access the Active Directory instance from your FusionAuth server by installing <code>ldapsearch</code> and running a simple LDAP query. For an EC2 instance running Amazon Linux, I ran these commands to install and then query the Active Directory server:</p>

<div><div><pre><code><span>sudo </span>yum <span>install </span>openldap-clients
ldapsearch <span>-H</span> ldap://xx.xx.xx.xx
</code></pre></div></div>

<p>Note that <code>xx.xx.xx.xx</code> is the IP address of your Active Directory instance. If you are running Active Directory with LDAPS, you may need to change the scheme.</p>

<p>If you see this error message:</p>

<div><div><pre><code>ldap_sasl_interactive_bind_s: Can't contact LDAP server (-1)
</code></pre></div></div>

<p>That means the Active Directory server is not accessible. If, on the other hand, you see this error message, you’re on the right path:</p>

<div><div><pre><code>SASL/EXTERNAL authentication started
ldap_sasl_interactive_bind_s: Unknown authentication method (-6)
	additional info: SASL(-4): no mechanism available: 
</code></pre></div></div>

<p>The above message is Active Directory telling you:</p>

<ul>
  <li>“Hey bonehead, provide me some credentials” (in a polite way).</li>
  <li>You can connect from your FusionAuth server to Active Directory.</li>
</ul>

<h3 id="configuring-aws-microsoft-managed-ad">Configuring AWS Microsoft Managed AD</h3>

<p>This post isn’t about installing AWS Microsoft Managed AD or any other Active Directory server, so I’ll mostly leave you to the tender mercies of AWS’s documentation. If, however, you have a running Active Directory instance you can access with the above <code>ldapsearch</code> commands, you can skip this entire section.</p>

<p>Here’s a brief outline of what I did to set up the Active Directory server so that I could connect it with FusionAuth:</p>

<ul>
  <li>Create a VPC with two subnets.</li>
  <li><a href="https://docs.aws.amazon.com/directoryservice/latest/admin-guide/ms_ad_getting_started_create_directory.html">Create an AWS Microsoft Managed AD Directory.</a></li>
  <li>Stand up a Windows server instance in the Active Directory’s subnet.</li>
  <li><a href="https://apps.apple.com/app/microsoft-remote-desktop/id1295203466">Install the MacOS RDP client</a> and <a href="https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/troubleshoot-connect-windows-instance.html">connect to that instance</a>.</li>
  <li><a href="https://docs.aws.amazon.com/directoryservice/latest/admin-guide/join_windows_instance.html">Manually join the Windows EC2 instance to Active Directory.</a></li>
  <li><a href="https://docs.aws.amazon.com/directoryservice/latest/admin-guide/ms_ad_manage_users_groups.html">Install the AD tools and create a user.</a></li>
</ul>

<p>As mentioned, this post assumes there is an EC2 instance inside a private subnet with access to the Active Directory server, so the connection between FusionAuth and AWS Microsoft Managed AD won’t use TLS. If you are using this configuration in production, please ensure that the network connection between the two servers is secured, especially if the traffic is over the open internet.</p>

<h3 id="active-directory-users">Active Directory users</h3>

<p>You are going to want to create two users in Active Directory.</p>

<p>The first will be an administrative user who has at least read access to the section of the directory where the internal user accounts are stored. When I created the directory, there was an <code>Admin</code> account created as well, so I’ll use that.</p>

<p>The second user will log in to FusionAuth and be authenticated against Active Directory using the Connector. Below, I’m adding John Stafford.</p>

<p><img src="https://fusionauth.io/assets/img/blogs/active-directory-connector/active-directory-add-user.png" alt="Adding a user in Active Directory."></p>

<p>I ran into an issue where when creating the user I required their password to be changed. This blocked FusionAuth from authenticating them. If you run into such issues, you can check by attempting to sign in to the domain, perhaps using the EC2 instance which is set up to auth directly against Active Directory.</p>

<h2 id="setting-up-fusionauth">Setting up FusionAuth</h2>

<p>Next, you want to add an application in FusionAuth. An application is anything a user can sign into. We’re going to reuse an <a href="https://fusionauth.io/blog/2019/05/06/securing-asp-netcore-razor-pages-app-with-oauth">existing ASP.NET Razor Pages application</a>. While required, the application isn’t the focus of this blog post, so if you want to learn more, check out the linked article. But let’s pretend this application is an internal payroll application. Only users in Active Directory should be able to access it, but we want to leverage FusionAuth for all our application auth needs.</p>

<p>To set up this application in FusionAuth, navigate to “Settings” and then “Key Master” to set up an RSA keypair. You need to do this because the default signing algorithm for a JSON Web Token (JWT) in FusionAuth is HMAC, but the ASP.NET library used doesn’t support symmetric algorithms. Below I’m generating an RSA key pair, but you can import one you’ve previously created should you need to share the keys across systems:</p>

<p><img src="https://fusionauth.io/assets/img/blogs/active-directory-connector/fusionauth-add-rsa-key.png" alt="Adding an RSA key in Key Master."></p>

<p>Create an application called “Internal Payroll App”. This is what you are going to let John have access to. In the “OAuth” tab, add a redirect URL of “http://localhost:5000/signin-oidc”. Add a logout redirect of “http://localhost:5000/”.</p>

<p>Navigate to the “JWT” tab. Enable JWT application configuration and change the signing keys to the just created RSA key pair: “For Internal Payroll App”.</p>

<p><img src="https://fusionauth.io/assets/img/blogs/active-directory-connector/fusionauth-jwt-config.png" alt="Configuring the application's JWT settings to sign with the generated RSA keypair."></p>

<p>Save the application and then view it by clicking on the green magnifying glass. Scroll down to the “OAuth configuration” section, noting the <code>Client ID</code> and <code>Client Secret</code> values, which you’ll need when configuring the web application in a bit:</p>

<p><img src="https://fusionauth.io/assets/img/blogs/active-directory-connector/fusionauth-oauth-config.png" alt="Viewing the application's OAuth settings to record the Client ID and Client Secret values."></p>

<h2 id="configure-the-ldap-connector">Configure the LDAP connector</h2>

<p>To configure the LDAP connector, you need to do the following:</p>

<ul>
  <li>Create an LDAP reconcile lambda to map user’s directory attributes to FusionAuth user attributes.</li>
  <li>Configure the Connector with information such as the URL of the Active Directory server.</li>
  <li>Add the Connector policy to the tenant, which configures how the connector is invoked by FusionAuth.</li>
</ul>

<p>Seems pretty simple, right? Let’s take these one at a time.</p>

<h3 id="create-the-ldap-lambda">Create the LDAP lambda</h3>

<p>Because FusionAuth has no idea about the structure of your Active Directory or other LDAP database, you’ll need to create a <a href="https://fusionauth.io/docs/v1/tech/lambdas/ldap-connector-reconcile">reconciliation lambda</a> to map the attributes from LDAP to FusionAuth. At its most basic, this lambda looks like this:</p>

<div><div><pre><code><span>function</span> <span>reconcile</span><span>(</span><span>user</span><span>,</span> <span>userAttributes</span><span>)</span> <span>{</span>
  <span>// Lambda code goes here</span>
<span>}</span>
</code></pre></div></div>

<p>This code isn’t too helpful though, as no user attributes are copied. At a minimum, you must set <code>user.id</code> and either <code>user.username</code> or <code>user.email</code> values. You also probably want to configure the <code>registrations</code> collection, which is the set of FusionAuth applications for which this user is authorized. If you have multiple tenants, populate <code>user.tenantId</code> as well.</p>

<p>The lambda will receive a <code>userAttributes</code> variable from the Connector. This contains attributes requested from Active Directory. You’ll see how to request specific attributes below. From <code>userAttributes</code>, you’ll want to assemble a FusionAuth <code>user</code> object. All the normal <a href="https://fusionauth.io/docs/v1/tech/lambdas/#limitations">lambda limitations apply</a>. The attributes of the <code>user</code> object are thoroughly documented in the <a href="https://fusionauth.io/docs/v1/tech/apis/users#create-a-user">API docs</a>, but in general you’ll be copying values from <code>userAttributes</code> to <code>user</code>, or hardcoding values. Here’s a more full featured example lambda function, which copies some attributes, sets <code>active</code> to <code>true</code>, and registers the user for a given application:</p>

<div><div><pre><code><span>// Using the response from an LDAP connector, reconcile the User.</span>
<span>function</span> <span>reconcile</span><span>(</span><span>user</span><span>,</span> <span>userAttributes</span><span>)</span> <span>{</span>

  <span>user</span><span>.</span><span>email</span> <span>=</span> <span>userAttributes</span><span>.</span><span>userPrincipalName</span><span>;</span>
  <span>user</span><span>.</span><span>firstName</span> <span>=</span> <span>userAttributes</span><span>.</span><span>givenName</span><span>;</span>
  <span>user</span><span>.</span><span>lastName</span>  <span>=</span> <span>userAttributes</span><span>.</span><span>sn</span><span>;</span>
  <span>user</span><span>.</span><span>active</span>    <span>=</span> <span>true</span><span>;</span>
  
  <span>var</span> <span>reg</span> <span>=</span> <span>{};</span>
  <span>reg</span><span>.</span><span>applicationId</span> <span>=</span> <span>"</span><span>f81adc10-04f7-4546-8410-f9837ff248ab</span><span>"</span><span>;</span> <span>// the application we want the user registered for</span>
  <span>user</span><span>.</span><span>registrations</span> <span>=</span> <span>[</span><span>reg</span><span>];</span>
  
  <span>user</span><span>.</span><span>id</span> <span>=</span> <span>guidToString</span><span>(</span><span>userAttributes</span><span>[</span><span>'</span><span>objectGUID;binary</span><span>'</span><span>]);</span>
<span>}</span>

<span>function</span> <span>decodeBase64</span><span>(</span><span>string</span><span>)</span>
<span>{</span>
	<span>var</span> <span>b</span><span>=</span><span>0</span><span>,</span><span>l</span><span>=</span><span>0</span><span>,</span> <span>r</span><span>=</span><span>''</span><span>,</span>
  <span>m</span><span>=</span><span>'</span><span>ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/</span><span>'</span><span>;</span>
  <span>string</span><span>.</span><span>split</span><span>(</span><span>''</span><span>).</span><span>forEach</span><span>(</span><span>function</span> <span>(</span><span>v</span><span>)</span> <span>{</span>
    <span>b</span><span>=</span><span>(</span><span>b</span><span>&lt;&lt;</span><span>6</span><span>)</span><span>+</span><span>m</span><span>.</span><span>indexOf</span><span>(</span><span>v</span><span>);</span> <span>l</span><span>+=</span><span>6</span><span>;</span>
    <span>if</span> <span>(</span><span>l</span><span>&gt;=</span><span>8</span><span>)</span> <span>r</span><span>+=</span><span>String</span><span>.</span><span>fromCharCode</span><span>((</span><span>b</span><span>&gt;&gt;&gt;</span><span>(</span><span>l</span><span>-=</span><span>8</span><span>))</span><span>&amp;</span><span>0xff</span><span>);</span>
  <span>});</span>
  <span>return</span> <span>r</span><span>;</span>
<span>}</span>

<span>function</span> <span>guidToString</span><span>(</span><span>b64</span><span>)</span>
<span>{</span>
  <span>var</span> <span>x</span> <span>=</span> <span>decodeBase64</span><span>(</span><span>b64</span><span>);</span>
  
  <span>console</span><span>.</span><span>debug</span><span>(</span><span>"</span><span>Binary String: </span><span>"</span> <span>+</span> <span>x</span><span>.</span><span>length</span> <span>+</span> <span>"</span><span> length: </span><span>"</span> <span>+</span> <span>x</span><span>);</span>
  
  <span>var</span> <span>ret</span> <span>=</span> <span>""</span><span>;</span>
  
  <span>for</span> <span>(</span><span>i</span> <span>=</span> <span>3</span><span>;</span> <span>i</span> <span>&gt;=</span> <span>0</span><span>;</span> <span>i</span><span>--</span><span>)</span>
  <span>{</span>
    <span>ret</span> <span>+=</span> <span>(</span><span>'</span><span>00</span><span>'</span><span>+</span><span>x</span><span>.</span><span>charCodeAt</span><span>(</span><span>i</span><span>).</span><span>toString</span><span>(</span><span>16</span><span>)).</span><span>substr</span><span>(</span><span>-</span><span>2</span><span>,</span><span>2</span><span>);</span>
  <span>}</span>
  <span>ret</span> <span>+=</span> <span>"</span><span>-</span><span>"</span><span>;</span>
  <span>for</span> <span>(</span><span>i</span> <span>=</span> <span>5</span><span>;</span> <span>i</span> <span>&gt;=</span> <span>4</span><span>;</span> <span>i</span><span>--</span><span>)</span>
  <span>{</span>
    <span>//ret = ret + ('00' + (charCode &amp; 0xFF00) &gt;&gt; 8);</span>
    <span>ret</span> <span>+=</span> <span>(</span><span>'</span><span>00</span><span>'</span><span>+</span><span>x</span><span>.</span><span>charCodeAt</span><span>(</span><span>i</span><span>).</span><span>toString</span><span>(</span><span>16</span><span>)).</span><span>substr</span><span>(</span><span>-</span><span>2</span><span>,</span><span>2</span><span>);</span>
  <span>}</span>
  <span>ret</span> <span>+=</span> <span>"</span><span>-</span><span>"</span><span>;</span>
  <span>for</span> <span>(</span><span>i</span> <span>=</span> <span>7</span><span>;</span> <span>i</span> <span>&gt;=</span> <span>6</span><span>;</span> <span>i</span><span>--</span><span>)</span>
  <span>{</span>
    <span>//ret = ret + …</span></code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://fusionauth.io/blog/2020/10/01/active-directory-connector">https://fusionauth.io/blog/2020/10/01/active-directory-connector</a></em></p>]]>
            </description>
            <link>https://fusionauth.io/blog/2020/10/01/active-directory-connector</link>
            <guid isPermaLink="false">hacker-news-small-sites-24655887</guid>
            <pubDate>Thu, 01 Oct 2020 20:33:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Interviewing During Covid – Google/Apple/ByteDance/Databricks/Citadel/HRT/JS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24655799">thread link</a>) | @oneraynyday
<br/>
October 1, 2020 | https://oneraynyday.github.io/misc/2020/09/30/Interviewing-During-Covid/ | <a href="https://web.archive.org/web/*/https://oneraynyday.github.io/misc/2020/09/30/Interviewing-During-Covid/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p><strong>I interviewed for Googleâ€™s Tensorflow, Appleâ€™s MLPT (Machine Learning Platform &amp; Technology), Bytedanceâ€™s ad infrastructure, Databrickâ€™s ML team, Citadel Securities as a quantitative research analyst, Hudson River Trading(HRT) as an algorithm engineer, and Jane Streetâ€™s research desk as SWE. I received offers from all of the companies except for Jane Street. Hereâ€™s my experience interviewing during COVID.</strong></p>

<p><em>Disclaimer: I wonâ€™t be walking on the edge of leaking confidential information like an idiot(yes, I signed an NDA for all of these companies). Donâ€™t expect to get any hints for your interviews.</em></p>

<p>The structure of this blog is inspired by my friend <a href="https://medium.com/@XiaohanZeng/i-interviewed-at-five-top-companies-in-silicon-valley-in-five-days-and-luckily-got-five-job-offers-25178cf74e0f">Hanâ€™s medium blogpost.</a></p>

<p><img src="http://oneraynyday.github.io/assets/interviews.png" alt="interviews"></p>



<ul id="markdown-toc">
  <li><a href="#table-of-contents" id="markdown-toc-table-of-contents">Table of Contents</a></li>
  <li><a href="#preparation" id="markdown-toc-preparation">Preparation</a>    <ul>
      <li><a href="#algorithms" id="markdown-toc-algorithms">Algorithms</a></li>
      <li><a href="#systems-design" id="markdown-toc-systems-design">Systems Design</a></li>
      <li><a href="#math-questions" id="markdown-toc-math-questions">Math Questions</a></li>
    </ul>
  </li>
  <li><a href="#the-interview-process" id="markdown-toc-the-interview-process">The interview process</a>    <ul>
      <li><a href="#more-interview-rounds-during-covid" id="markdown-toc-more-interview-rounds-during-covid">More interview rounds during COVID</a></li>
      <li><a href="#dealing-with-time-zones" id="markdown-toc-dealing-with-time-zones">Dealing with time zones</a></li>
      <li><a href="#which-ones-were-the-hardest" id="markdown-toc-which-ones-were-the-hardest">Which ones were the hardest?</a></li>
    </ul>
  </li>
  <li><a href="#making-a-decision" id="markdown-toc-making-a-decision">Making a decision</a>    <ul>
      <li><a href="#the-culture-and-the-small-things-count" id="markdown-toc-the-culture-and-the-small-things-count">The culture and the â€œsmallâ€� things count</a></li>
    </ul>
  </li>
  <li><a href="#conclusion" id="markdown-toc-conclusion">Conclusion</a></li>
</ul>



<p><strong>Working on machine learning infrastructure is 99% systems engineering and 1% machine learning.</strong> My experience on machine learning infrastructure teams has taught me this, and preparing for systems engineering topics was the right way to go. I did the following to prepare:</p>

<h2 id="algorithms">Algorithms</h2>

<p><strong>~50 leetcode hard questions</strong>. Some of them are DP, some are graph based, some of them are just NP-hard problems that are a pain to code(which is the point), and some include devising some clever data structure that supports a very specific access pattern. I gave myself roughly 40 minutes to solve these problems. ~15%(7 questions) of the time I couldnâ€™t figure out the correct solution because time limit exceeded, memory limit exceeded, or I was just flat out wrong. I directly read the solutions and learned the tricks necessary to solve the type of problems moving forward. Donâ€™t bother with medium or easy questions since hard questions often contain medium/easy tasks as subroutines, and these companies probably wouldnâ€™t ask you easy leetcode questions anyways.</p>

<p>I wrote the solutions in either python and C++(sometimes both) and went back to polish my code for minor optimizations or readability improvements. For C++, I made sure I wasnâ€™t using raw pointers unless appropriate and I was using C++17 (<code>constexpr</code> functions, <code>std::array</code> instead of raw arrays, smart pointers, template type deduction with lambdas, etc) features. The reason I wasnâ€™t using C++20 was because the online coding platforms(like coderpad) likely use stable distributions of GCC and clang, which means some of the new features are in their experimental phase. <strong>I didnâ€™t want to encounter a bug with concepts or <code>std::ranges</code>  in the middle of the interview.</strong> (In fact, I found a <a href="https://stackoverflow.com/questions/62398252/why-likely-attribute-in-c20-raises-a-warning-here">bug with attributes</a> recently in a new version of gcc)</p>

<p>I also spent a few days on problems elsewhere:</p>

<ul>
  <li><a href="https://codingcompetitions.withgoogle.com/codejam/archive">Codejam problems</a>. Round 1 and 2 are feasible, but round 3 was very difficult. Iâ€™d suggest studying round 1â€™s if you only care about interviews.</li>
  <li><a href="https://codeforces.com/">Codeforce contests</a>. There are 3 tiers(or Divs, as they call it), and for interviews I suggest Div 3 and Div 2. Donâ€™t bother with the D+ questions in Div 2, and definitely donâ€™t bother with Div 1.</li>
</ul>

<h2 id="systems-design">Systems Design</h2>

<p>Working at Airbnb has made me pretty familiar with high level distributed systems design, but of course I worked only with a subset of them. I think Martin Kleppmanâ€™s book <a href="https://www.google.com/books/edition/Designing_Data_Intensive_Applications/p1heDgAAQBAJ?hl=en">Designing Data Intensive Applications</a> is a great read, but youâ€™ll have to pick and choose which sections you want to go over as itâ€™s a pretty dense book. If you donâ€™t have time, maybe just try understanding how Kubernetes works with Marko Luksaâ€™s <a href="https://www.manning.com/books/kubernetes-in-action">Kubernetes in Action</a>, which is a much easier read. You can then draw parallels with the distributed design for K8s against whatever systems design question the interviewer has for you.</p>

<p>Make sure you know some fundamental ideas about distributed systems like the <strong>map reduce paradigm</strong>, <strong>sharding</strong>, <strong>asynchronous and synchronous follower replicas</strong>, <strong>CAP theorem</strong>, etc. <em>What you donâ€™t want to do is read 3 sentences about each of the terms above and regurgitate it in your interviews. Interviewers have been doing this for a while, they know you donâ€™t actually understand the concepts.</em> Donâ€™t be that guy.</p>

<h2 id="math-questions">Math Questions</h2>

<p><strong>These are only asked in finance firms.</strong> Honestly, these are just all over the place. I read this green book called <a href="http://quantfinanceinterviews.com/">A Practical Guide to Quantitative Finance Interviews</a> by Xinfeng Zhou, but only doing a single problem in each section by myself. Hedge funds will quiz you on discrete math to probability theory to geometry to information theory to literally anything. My advice is if youâ€™re a software engineer interviewing for a hybrid of finance and tech places, timebox yourself in this category.</p>

<hr>

<p>I have not seen an interview question this cycle that was an exact question Iâ€™ve seen online or in books. Your mileage may vary.</p>



<p>Interviewing and talking with all of these companies was a great experience, even with COVID in place. Obviously, as shelter-in-place continues, these companies are conducting virtual on-site interviews and trying to make this process as smooth as possible. Without getting into the specifics, Iâ€™ll outline some common things Iâ€™ve noticed during the process in the COVID era.</p>

<ul>
  <li>Many companies use Zoom or Google Hangouts for their on-sites.</li>
  <li>They give you ~15 minute breaks in between interviews for water breaks.</li>
  <li>Some companies give you a longer lunch break (45 mins to an hour).</li>
  <li>If youâ€™re interviewing for a company in another time zone, prepare to wake up in the early AMâ€™s or interview in the late afternoon (sometimes after dinner).</li>
  <li>Conveying an idea takes slightly longer because youâ€™re not drawing on a whiteboard. Some companies have virtual whiteboard apps and others allow the use of Zoom whiteboards.</li>
  <li><strong>Some companies added more interview rounds for virtual on-sites.</strong> Apparently more people are getting into companies with subpar technical skills during COVID and theyâ€™re making the process more selective. I think this can also be due to the increase in competition due to unemployment rates increasing.</li>
  <li>Feedback and communications with recruiters is generally faster.</li>
</ul>

<h2 id="more-interview-rounds-during-covid">More interview rounds during COVID</h2>

<p>The bolded text might scare you as a potential candidate, but donâ€™t worry too much. The added questions arenâ€™t testing you if you know how to implement a bloom filter or a fibonacci heap or something niche. They usually test on the <em>coding abilities of the person and how well theyâ€™d actually ramp up in a novel, collaborative environment</em>. This can manifest itself in multiple ways - live debugging session with a new codebase, reading documentation to work with new technology, or a collaborative brainstorming sesion for a hard(er) problem. If youâ€™re a decent software engineer you shouldnâ€™t worry about these as much.</p>

<h2 id="dealing-with-time-zones">Dealing with time zones</h2>

<p><em>One of the biggest struggles I had during the interview process was adjusting my sleep schedule to wake up at 5-6AM to make sure Iâ€™m awake and on time for the interviews in New York/Chicago (Iâ€™m in California so this was a 3 hour gap)</em>. Usually, companies would fly you out the day-of or the day before the on-site. Iâ€™ve always felt tired after a plane flight and was able to get a good nightâ€™s rest before the interviews in the past. With COVID, everything is virtual and the companies expect you to interview at their hours.</p>

<p>Even with slowly adjusting my sleep schedule over a week or two I still had trouble with sleep. Personally, I get pretty nervous before an on-site and Iâ€™d need to feel adequately tired to get a good nightâ€™s rest instead of tossing and turning in bed. With the clock turned 3 hours back, I suddenly found myself not tired enough to sleep on time the night before the interview(even with a whole week of adjusting). This led to me consistently getting 6-7 hours of sleep instead of the 9 hours of sleep I usually get on game day, which really sucked.</p>

<p>Ultimately, I have no idea how much the sleep problem really affected my performance, but it was enough to shake my confidence going in.</p>

<p><em>NOTE: +1 to Citadel for proactively breaking my on-site over multiple days so I can have a sane sleep schedule for their interviews. This might depend on the specific team youâ€™re interviewing with.</em></p>

<h2 id="which-ones-were-the-hardest">Which ones were the hardest?</h2>

<p>This is subjective, and the question can be broken up into multiple components:</p>

<ul>
  <li><strong>Time pressure - Jane Street</strong>. This is probably why I failed their interviews, which were a bit longer than usual. I tend to explain my approach before coding anything to get a confirmation on the interviewerâ€™s side that Iâ€™m on the right track. I probably spent too much time explaining and didnâ€™t have enough time to finish the code for some interviews.</li>
  <li><strong>Math questions - Citadel</strong>. They asked me some <em>really</em> interesting math problems that arenâ€™t related to finance at all. I donâ€™t think they expect the interviewer to get 100% of the questions since whenever I solved one the interviewer was ready with another. HRT also asked some.</li>
  <li><strong>Systems design - HRT</strong>.</li>
  <li><strong>Outside-the-box problems - Databricks</strong>. They conduct one of the most unique interviews Iâ€™ve ever had.</li>
  <li><strong>Language specific questions - Citadel/HRT</strong>. Grilled me a lot on low level C++ stuff.</li>
  <li><strong>Length of interview - HRT</strong>. I started at 8AM PST (I requested to move it to 8AM from 7AM) and finished at ~2:30PM. <strong>That is a whopping 6 hours and 30 minutes.</strong> I also did a coding challenge and 2 phone screens before I moved to on-site, totalling almost 10 hours for interviews.</li>
  <li><strong>General algorithm questions - Jane Street/HRT</strong>. I think Jane Street was a bit harder given the time pressure. The flavor of algorithm questions are also different between these firms.</li>
</ul>

<p>Once again, this breakdown is <strong>subjective</strong>. I obviously have a lot of experience interviewing with Silicon Valley companies so the novelty of questions from the finance companies added to the difficulty.</p>



<p>This was the hardest part for me. I spent two weeks suffering from analysis paralysis. I would …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://oneraynyday.github.io/misc/2020/09/30/Interviewing-During-Covid/">https://oneraynyday.github.io/misc/2020/09/30/Interviewing-During-Covid/</a></em></p>]]>
            </description>
            <link>https://oneraynyday.github.io/misc/2020/09/30/Interviewing-During-Covid/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24655799</guid>
            <pubDate>Thu, 01 Oct 2020 20:24:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Asteroids: By the Numbers]]>
            </title>
            <description>
<![CDATA[
Score 43 | Comments 16 (<a href="https://news.ycombinator.com/item?id=24655752">thread link</a>) | @rbanffy
<br/>
October 1, 2020 | http://www.retrogamedeconstructionzone.com/2019/10/asteroids-by-numbers.html?m=1 | <a href="https://web.archive.org/web/*/http://www.retrogamedeconstructionzone.com/2019/10/asteroids-by-numbers.html?m=1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div id="post-body-3855344372715435262"><p>
By 1979, arcade games were rapidly becoming more complex and colorful, and a game like <i>Asteroids </i>might have seemed quaint by comparison to the likes of <i><a href="http://www.retrogamedeconstructionzone.com/2019/09/galaxian-aesthetics-of-simple-patterns.html">Galaxian</a>, <a href="http://www.retrogamedeconstructionzone.com/2019/09/star-fire-weirdness-of-pseudo-3d.html">Star Fire</a></i>, or <i>Radar Scope.&nbsp; </i>But beneath its simple exterior lies a challenging shooter with surprisingly complex physics.&nbsp; The image below shows a sample still from it, including the player's ship (the triangle on the left), three sizes of asteroids, and an alien ship.</p><p><a href="https://1.bp.blogspot.com/-XOyg91qwUV4/XZwhbHR4tnI/AAAAAAAAOXs/DJ89MzjAODU3mAoraZKUaq6vl9nKvdsSACLcBGAsYHQ/s1600/Asteroids_sample%2B%25282%2529.png"><img data-original-height="461" data-original-width="598" height="492" src="https://1.bp.blogspot.com/-XOyg91qwUV4/XZwhbHR4tnI/AAAAAAAAOXs/DJ89MzjAODU3mAoraZKUaq6vl9nKvdsSACLcBGAsYHQ/s640/Asteroids_sample%2B%25282%2529.png" width="640"></a></p>

<p>
The goal of the game is to maximize your score, destroying as many asteroids and aliens as possible before you run out of ships.&nbsp; When an asteroid is hit by something (usually the player's bullets), large asteroids turn into two medium ones and medium asteroids turn into two small ones, while small asteroids and aliens are destroyed when hit.</p><p><a href="https://1.bp.blogspot.com/-cEzHmkcz3bA/XaU1zGl7IBI/AAAAAAAAObY/2GDlGaxtEc0ytzWpyQRinUxnbioeVsTbQCLcBGAsYHQ/s1600/Asteroids%2BPlay.gif"><img data-original-height="357" data-original-width="600" height="237" src="https://1.bp.blogspot.com/-cEzHmkcz3bA/XaU1zGl7IBI/AAAAAAAAObY/2GDlGaxtEc0ytzWpyQRinUxnbioeVsTbQCLcBGAsYHQ/s400/Asteroids%2BPlay.gif" width="400"></a></p>
<p>
For the designers of the game, balancing the relative sizes of the objects would have been important in such a dense field, because it determines how often things run into one another other.&nbsp; The table below outlines the sizes of the objects in <i>Asteroids</i>, expressed relative to the length of the player's ship.</p><table>
<caption>The approximate horizontal lengths of objects in <i>Asteroids</i></caption>
    <tbody>
<tr>
    <th>Object</th>
    <th>Length (in player ship lengths)</th>
    </tr>
<tr>
    <td>Screen</td>
    <td>25 x 36</td>
    </tr>
<tr>
    <td>Large Asteroids</td>
    <td>2.4</td>
    </tr>
<tr>
    <td>Medium Asteroid</td>
    <td>1.2</td>
    </tr>
<tr>
    <td>Small Asteroid</td>
    <td>0.6</td>
    </tr>
<tr>
    <td>Alien Ship (large)</td>
    <td>1.5</td>
    </tr>
<tr>
    <td>Alien Ship (small)</td>
    <td>0.75</td>
    </tr>
</tbody>
    </table>
<p>
Notice how the medium asteroid is twice the size of the small one, and the large is twice the size of the medium.&nbsp; If you think about it, this doesn't actually make much physical sense -- you can break a two-dimensional object into four pieces half its size, not two.&nbsp; But the size ratios do make game sense, because what really matters to the player is not how much area an asteroid takes up, but how likely it is to hit them.</p><p><a href="https://1.bp.blogspot.com/-5wVPSIS6W_M/XZwmjsjcYII/AAAAAAAAOX4/a7MThKiGRH8vhydf83eCiOmmJuKUULHIwCLcBGAsYHQ/s1600/Asteroids_cross_section%2B%25282%2529.png"><img data-original-height="281" data-original-width="170" src="https://1.bp.blogspot.com/-5wVPSIS6W_M/XZwmjsjcYII/AAAAAAAAOX4/a7MThKiGRH8vhydf83eCiOmmJuKUULHIwCLcBGAsYHQ/s1600/Asteroids_cross_section%2B%25282%2529.png"></a></p>

<p>
In the picture above, you can see that while the four small asteroids take up less area on the screen than the big one, they present the same cross section to your ship.&nbsp; This means that breaking up the asteroids doesn't greatly increase the probability that the player will be struck by one.&nbsp; If the asteroids had been broken up into four half-sized pieces at each blow, each large asteroid would result in sixteen small ones (that's four times the cross section!) and the player would be quickly overwhelmed.&nbsp; Note that the small asteroids do move faster than the large ones, and speed increases the chance of getting hit, but I'll return to that in a moment.</p>

<p>
Another big reason that size matters in <i>Asteroids</i>&nbsp;is that it determines how close something has to be before you're likely to be able to hit it.&nbsp; In 1979, vector arcade cabinet screens had an effective resolution of 1024 x 768, and the player's ship was only connected graphically by about 20 points.&nbsp; This meant, in turn, that there were only a limited number of orientations that they could render for the ship, in this case intervals of 5 degrees.&nbsp; To see how this might affect gameplay, imagine your ship is located at the fixed position shown in the picture below.&nbsp; Anything located entirely between the two solid lines will not be accessible by your bullets because your ship can't turn to the appropriate angle to hit it.&nbsp; This restriction isn't a big deal for large asteroids, which are still accessible over most of the screen, but small asteroids can be out of reach of your guns at relatively close range, sometimes as close as 7 ship lengths away!&nbsp; So even if you aim as accurately as possible, chances are you won't be able to hit a small asteroid on the other side of the screen, at least not on your first shot.&nbsp; This is probably one of the reasons that <i>Asteroids</i>&nbsp;allows you to fire up to four bullets in succession: even if you can't hit an object right away, it will eventually move into your line of fire.</p>

<p><a href="https://1.bp.blogspot.com/-EX2V1tAwdnM/XZvKFmnQZoI/AAAAAAAAOXI/cd411AFReLcKkCQGooANzsmxVD7QV3ikgCLcBGAsYHQ/s1600/Asteroids_hittable%2B%25285%2529.png"><img data-original-height="397" data-original-width="1024" height="248" src="https://1.bp.blogspot.com/-EX2V1tAwdnM/XZvKFmnQZoI/AAAAAAAAOXI/cd411AFReLcKkCQGooANzsmxVD7QV3ikgCLcBGAsYHQ/s640/Asteroids_hittable%2B%25285%2529.png" width="640"></a></p>
<p>
And what about speed?&nbsp; There is some variability in the speeds of individual asteroids, but small asteroids can move as much as 63% faster than large ones (see the table below), meaning that even if four small asteroids present the same cross section for hitting your ship as a large one does, their higher speed means they're more likely to hit you.&nbsp; The reasoning for this is simple: the faster something moves, the longer the path it can traverse in a given amount of time, and the larger the likelihood that you'll be in that path.&nbsp; Fortunately, even the fastest asteroids are much slower than your ship, which can traverse the screen in about two seconds; so if you're skilled enough, you should be able to maneuver around the asteroid field without a problem.</p><table>
<caption>The approximate speeds of objects in <i>Asteroids</i></caption>
    <tbody>
<tr>
    <th>Object</th>
    <th>Speed (in ship lengths per second)</th>
    </tr>
<tr>
    <td>Your ship</td>
    <td>0 - 17</td>
    </tr>
<tr>
    <td>Asteroids</td>
    <td>4 - 6.5</td>
    </tr>
<tr>
    <td>Alien ships (both sizes)</td>
    <td>4 - 6.5 (depending on your score)</td>
    </tr>
<tr>
    <td>Bullets</td>
    <td>17 (ship at rest)&nbsp;</td></tr>
</tbody></table>
<p>
One other interesting thing about speed: notice in the table above that the speed of a bullet, when fired at rest, is the same as your ship's maximum speed.&nbsp; This means that when you're moving rapidly and fire a bullet in the opposite direction of your motion, the two speeds should cancel for a stationary observer and the bullet should appear roughly stationary.</p>

<p><a href="https://1.bp.blogspot.com/-pRIxsTPNfSY/XaD7O0foijI/AAAAAAAAOZQ/JWZGFR26JEY3UM43RiruPhhGfHOCW21DgCLcBGAsYHQ/s1600/Asteroids_bullet_stationary.gif"><img data-original-height="175" data-original-width="468" height="239" src="https://1.bp.blogspot.com/-pRIxsTPNfSY/XaD7O0foijI/AAAAAAAAOZQ/JWZGFR26JEY3UM43RiruPhhGfHOCW21DgCLcBGAsYHQ/s640/Asteroids_bullet_stationary.gif" width="640"></a></p>


<div><p>
Sure enough, when I fire a bullet while moving quickly in the opposite direction, it just floats near where I fired it, allowing me to place bullets like mines for the asteroids to run into.</p>
<p>
The developers of <i>Asteroids </i>wanted the game to simulate the real laws of physics (<a href="http://www.technologyuk.net/computing/computer-gaming/gaming-landmarks-1960-1985/asteroids.shtml">see here</a>), and I think in many respects they succeeded, at least compared to most other arcade games of the time.&nbsp; It's not entirely realistic, however.&nbsp; In my article on <a href="http://www.retrogamedeconstructionzone.com/2019/10/impossible-motion-in-video-games.html">motion in early arcade games</a>, I discussed how the acceleration of the ship in <i>Asteroids</i> is too rapid for a human-occupied vehicle.&nbsp; We might suppose that the vehicle is automated, but even then, engineering spacecraft to withstand 30+ g's of acceleration is a non-trivial challenge.</p><p><a href="https://1.bp.blogspot.com/-eBpcOCL_1a0/XaU-bXjLJjI/AAAAAAAAObk/N_FxduJSebIMaqzrq7BhDmNFufzmyBRfgCLcBGAsYHQ/s1600/Acceleration%2BAsteroids.gif"><img data-original-height="175" data-original-width="634" height="176" src="https://1.bp.blogspot.com/-eBpcOCL_1a0/XaU-bXjLJjI/AAAAAAAAObk/N_FxduJSebIMaqzrq7BhDmNFufzmyBRfgCLcBGAsYHQ/s640/Acceleration%2BAsteroids.gif" width="640"></a></p>
<p>
Another issue is the way the asteroids break up.&nbsp; In physics, there's a principle called the conservation of momentum that says that when objects interact with one another or break apart, the total mass times the velocity must remain the same after the interaction as it was before.&nbsp; In layman's terms, this means that things can't suddenly go from moving one direction to moving in another unless there is something else carry its previous momentum.&nbsp; In the example shown below, an asteroid does just that, and the only thing that could have absorbed its previous momentum is the bullet.&nbsp; But the bullet is so tiny that it's difficult to imagine how that would be possible.</p><p><a href="https://1.bp.blogspot.com/-vsDHHIPNXrQ/XaEAAKYXRII/AAAAAAAAOZc/-lhbXy0TSV4nEiLvOf-pe7zyt9sPGLcEACLcBGAsYHQ/s1600/Asteroids_momentum.gif"><img data-original-height="248" data-original-width="533" height="185" src="https://1.bp.blogspot.com/-vsDHHIPNXrQ/XaEAAKYXRII/AAAAAAAAOZc/-lhbXy0TSV4nEiLvOf-pe7zyt9sPGLcEACLcBGAsYHQ/s400/Asteroids_momentum.gif" width="400"></a></p>

<p>
These are mere quibbles, however, and shouldn't dissuade you from giving the game a try.&nbsp; <i>Asteroids </i>ended up being one of Atari's biggest arcade hits, selling over 70,000 cabinets, and remains one of their most recognizable games to this day.&nbsp; Many gamers who grew up in the '80s, myself included, are more familiar with the Atari 2600 version of the game.&nbsp; Unfortunately, the designers had to make a lot of sacrifices in game physics in order to make it work on a home console, so I think the arcade version is really the way to go.&nbsp; Outside of visiting a vintage arcade, your best bet is probably the <a href="https://www.mamedev.org/">Multiple Arcade Machine Emulator</a> (MAME).&nbsp; Happy hunting!</p></div><div><p><span>NOTE: &nbsp;A previous version of this article stated that the game has limited pixel resolution, but <i>Asteroids </i>uses a vector display that is not composed of pixels. &nbsp;The resolution of the <i>Asteroids </i>vector display is 1024 x 768.</span></p><p><a href="https://1.bp.blogspot.com/-7gLKzZ6gULM/XaDx0uT70-I/AAAAAAAAOYo/aLUcLQJkl9AY1k2OYsewuUHydaxbkT0gwCLcBGAsYHQ/s1600/Asteroids_loop_transparent.gif"><img data-original-height="151" data-original-width="600" height="160" src="https://1.bp.blogspot.com/-7gLKzZ6gULM/XaDx0uT70-I/AAAAAAAAOYo/aLUcLQJkl9AY1k2OYsewuUHydaxbkT0gwCLcBGAsYHQ/s640/Asteroids_loop_transparent.gif" width="640"></a></p>
<br></div>
</div>
</div></div>]]>
            </description>
            <link>http://www.retrogamedeconstructionzone.com/2019/10/asteroids-by-numbers.html?m=1</link>
            <guid isPermaLink="false">hacker-news-small-sites-24655752</guid>
            <pubDate>Thu, 01 Oct 2020 20:19:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Use the internet, not just companies (2018)]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24655745">thread link</a>) | @downshun
<br/>
October 1, 2020 | https://sive.rs/netskill | <a href="https://web.archive.org/web/*/https://sive.rs/netskill">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

<article>
<header>


<small>2018-02-12</small>
</header>

<p>
	I’ve been online since 1994, and seen so many companies come and go.
</p><p>
	In the year 2000, the place to be was mp3.com.
	Every musician would keep all of their music and fans there.
	A few years later, it was gone — shut down — all music and fan lists deleted.
</p><p>
	In 2005, it was MySpace.
	Again, musicians kept all of their music, photos, and fans there.
	A few years later, it was gone.
	Not shut down, but basically moot.
	There was no way to communicate with all of those people, because you didn’t have their direct contact info — you only had their MySpace inbox, which nobody checked anymore.
</p><p>
	As I’m writing this now in 2018, it’s Facebook, YouTube, and Spotify.
	Just like with mp3.com and MySpace, people act like these websites are everything, and keep all of their music, photos, and fans there.
	By the time you read this, they might be gone.
</p><p>
<strong>
	Don’t depend on a company.
	They come and go.
</strong>
	Think long-term.
	You’re going to be creating stuff, making fans, and building relationships for the rest of your life — much longer than these companies will last.
</p><p>
<strong>
	So have your own website.
</strong>
	Instead of sending your fans to some company’s site, send them to yours.
	Get everyone’s direct contact information so you don’t have to go through a company to reach them.
</p><p>
<strong>
	Your website should be the definitive place to get everything you create.
</strong>
	If you put your stuff on some company’s site, have it be secondary — a copy of the stuff that’s already on your site.
	That way you can use the popular networks without depending on them.
</p><p>
	Only rely on open standards that aren’t owned by any company — like email and the web.
</p>
<h3>
	Email skills:
</h3>
<p>
	Go into your email settings, and make sure you <strong>have a signature</strong>.
	You need this because you’re going to be emailing people who have no idea who or where you are!
	Give them some context.
	Your signature should say who, what, and where, with a URL or two.
	For example:
</p>
<pre>--
Maya Danubé, fragrant jazz bass clarinet, New York City
http://mayadanube.com  <a href="https://sive.rs/cdn-cgi/l/email-protection" data-cfemail="7e131b3e131f071f1a1f100b1c1b501d1113">[email&nbsp;protected]</a>  (917)611-5310
Watch &amp; listen: https://www.youtube.com/user/mayadanube
Friend me, baby: https://www.facebook.com/mayadanube
</pre>
<p>
	When you email people, write a <strong>descriptive subject</strong>.
	Never “hey” or “booking”.
	Try “Available June 6 for showcase?” or “introduction to photographer”.
	This is considerate.
	Now when your email is one of hundreds in an inbox, it will say exactly what is contained inside.
</p><p>
	Make it <strong>as short as possible</strong>.
	The shorter your email, the more likely it will get a response.
	Be direct.
	Five sentences is ideal.
	If your email is too long, they are likely to procrastinate, and never get back to it.
</p><p>
	Use short paragraphs.
	Leave plenty of space.
	Reading a screen is different from reading a book.
</p>
<h3>
	Web skills:
</h3>
<p>
<strong>
	Know how to update your website.
</strong>
	Don’t depend on someone else to do this for you.
	Know how to add new songs or videos, and how to make any changes.
</p><p>
<strong>
	Know your URLs.
</strong>
	Telling someone to go search for you is like telling them to look up your phone number.
	Instead, know your exact URLs (yoursite.com, twitter.com/something, facebook.com/whatever) so you can give it to people directly.
	If you don’t, they’ll probably never bother to go search for you.
</p><p>
<strong>
	Know how to make an MP3.
</strong>
	Give it a good filename like YOUR_NAME-Song_Title.mp3 (not mix7.mp3)
	Don’t use spaces in the filename.
	Edit the ID3 tags to put your full name and URL in the info, so whoever has this MP3 knows who it is and how to find you.
</p><p>
	Sorry if these sound too basic to you.
	But you’d be surprised by how many people don’t know these skills, and so are silently handicapped when interacting with the world.
</p>
<img alt="" src="https://sive.rs/images/internet-skills.gif">


</article>



</div></div>]]>
            </description>
            <link>https://sive.rs/netskill</link>
            <guid isPermaLink="false">hacker-news-small-sites-24655745</guid>
            <pubDate>Thu, 01 Oct 2020 20:18:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Shape of Belief Curves]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24655726">thread link</a>) | @avoidboringppl
<br/>
October 1, 2020 | https://www.leonlinsx.com/belief-curve-shape/ | <a href="https://web.archive.org/web/*/https://www.leonlinsx.com/belief-curve-shape/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="text">
        
        <h2 id="takeaway">Takeaway</h2>

<p>We draw our beliefs from others but are ultimately responsible for them ourselves.</p>





<h2 id="belief-curves">Belief curves</h2>

<p><strong>We aren’t born with our beliefs.</strong></p>

<p>We grow into them over time, influenced by our experiences.</p>

<p>It’s fun to debate <a href="https://www.simplypsychology.org/naturevsnurture.html" title="nature">nature vs nurture</a>, biology vs behaviourism, <a href="https://www.whatisepigenetics.com/what-is-epigenetics/" title="epigenetics">genes vs epigenetics</a>, but what we believe and <a href="https://www.amazon.com/dp/0143110918/ref=dp-kindle-redirect?_encoding=UTF8&amp;btkr=1" title="behave">how we behave</a> is unquestionably influenced by others.</p>

<p><strong>We aren’t sure what our beliefs are either.</strong></p>

<p>We have a small set of strong beliefs, and a large set of vague ones.</p>

<p>It’s worth trying to write down all your core beliefs, the issues you feel most strongly about, your raison d’etre. If you’re like me, <a href="https://www.leonlinsx.com/about-me/" title="me">your list likely doesn’t extend much beyond 20 items</a> [1]. Yet, based on that short list of ideals, we have to make decisions in reality.</p>

<p><strong>We aren’t making decisions on just our beliefs alone.</strong></p>

<p>We realise we don’t live in a simple single person scenario, but a complex society of people.</p>

<p>We both influence and are influenced by the actions of others, and over time define <a href="https://en.wikipedia.org/wiki/Zeitgeist" title="zeit">the cultural zeitgeist</a>. Since we’re playing a relative status game, we need to consider what others believe. We behave in ways that we think will enhance our status in others’ eyes.</p>

<p><strong>Most of our time is then figuring out what others believe.</strong></p>

<p>In investing, we try to figure out <a href="https://avoidboringpeople.substack.com/p/relatively-speaking-the-billionaire?r=1b9e6&amp;utm_campaign=post&amp;utm_medium=web&amp;utm_source=copy" title="cons">what market consensus is.</a> If you knew exactly where consensus was, you’d print money.</p>

<p>In tech, we try to figure out what customers desire. If you knew exactly what consumers would buy, you’d print money.</p>

<p>In life, we try to figure out what society demands. If you knew exactly what others wanted you to do, you’d print money.</p>

<p>“No way, I spend my time gathering as much information as possible, I adjust my <a href="https://en.wikipedia.org/wiki/Prior_probability" title="bayes">bayesian priors,</a> I’m a man of math”</p>

<p>If so, would evidence showing that <a href="https://scholarsbank.uoregon.edu/xmlui/bitstream/handle/1794/23607/928.pdf?sequence=3&amp;isAllowed=y" title="confidence">more information increases your confidence, but not your accuracy,</a> affect how strongly you hold your beliefs?</p>

<p><img src="https://www.leonlinsx.com/assets/images/confidence%20vs%20information.png" alt="post"></p>

<p>The graph above comes from a study in which bettors were given different amounts of information. The more information they got, the more confident they got in their decision, as see by the upward sloping confidence line. However, that had little to no impact on the accuracy of their bets. More isn’t better, when it’s hard to evaluate the quality of the information.</p>

<p>Most of us, myself included, like to think we’re well calibrated like the below:</p>

<p><img src="https://www.leonlinsx.com/assets/images/confidence%20belief%201.png" alt="post"></p>

<p>When we’re usually more like this instead:</p>

<p><img src="https://www.leonlinsx.com/assets/images/confidence%20belief%202.png" alt="post"></p>

<p>“No way, I’m an independent thinker, I don’t care what others think, I’m a man of science”</p>

<p>There’s less difference between you and someone who <a href="https://en.wikipedia.org/wiki/Reptilian_conspiracy_theory" title="lizards">believes in lizard people.</a> [2]</p>

<p>Let’s take something like the discovery of <a href="https://home.cern/science/physics/higgs-boson" title="Higgs">the Higgs Boson</a>, a elementary particle in physics. As a man of science, you celebrated when you read the news that it was discovered. Another advancement for the ages.</p>

<p>How can you be so sure though? It’s based on a news report, from conclusions of a paper, of a study in advanced physics that you’re unlikely to understand, let alone replicate. Try as you might, you’re not going to be able to build another Large Hadron Collider in your backyard [3]. You have to assume that what others believe is true.</p>

<p><img src="https://www.leonlinsx.com/assets/images/Lizard%20people%20vs%20Higgs.png" alt="post"></p>

<p>So that’s the bad news. You’re not much better than those of the lizard laity.</p>

<p>Here’s the good news. You still get to decide what you believe in, changing that as you learn more than before. You’re not fixed to any one opinion.</p>

<p>In those confidence vs evidence graphs above, it’s up to you to decide which type of graph you want to be. Whether that’s through <a href="https://www.theatlantic.com/politics/archive/2017/06/the-highest-form-of-disagreement/531597/" title="steelman">steelmanning the other side’s arguments</a>, doing an <a href="https://www.econlib.org/archives/2011/06/the_ideological.html" title="test">ideological turing test</a>, or just reading and talking to more people outside of your comfort zone. The choice is yours, whether to change or be constant.</p>

<p>And while that does mean that some people will be reluctant to update their harmful beliefs, it also means that there’s always hope that they can change. We can help make that happen, by being a voice of reason. When enough people express their beliefs, over time that influences others to slowly change their minds.</p>

<p><a href="https://www.youtube.com/watch?v=4QJIu15VjQg&amp;feature=youtu.be&amp;t=243" title="racist">Nobody’s born a racist;</a> everybody can change.</p>

<p>I want to believe.</p>



<ol>
  <li>For those unaware, I have a personal site as well in case substack goes away. There’s also other things I can post there like a list of websites I follow.</li>
  <li>The phrasing for polls like this <a href="https://slatestarcodex.com/2020/05/28/bush-did-north-dakota/" title="poll">can be bad</a>, but even if you haircut the numbers by 99% there is still &gt; 1 person who seriously believes in a lizard king.</li>
  <li>Well, if you somehow are able to build the next large particle accelerator in your backyard, I’d be happy to admit I’m wrong. You can even put my name down as the person who you had a bone to pick with and wanted to prove wrong.</li>
</ol>

<h2 id="paid-reader-survey-discussion">Paid reader survey discussion</h2>

<p>I did a survey on a small group of you paying subscribers; thank you to everyone who filled it out. The feedback was helpful in seeing what people have actually liked recently (the <a href="https://avoidboringpeople.substack.com/p/authentic-contrarians-vs-consensus" title="Josh">Josh Wolfe</a> and the <a href="https://avoidboringpeople.substack.com/p/picassos-new-painting-perspectives" title="Picasso">Picasso</a> profiles came up often) and also for knowing what people want more of (more finance, more tech, more random interesting things).</p>

<p>It’s also flattering and frustrating to realise that people found the recent talk summaries boring, and would rather hear my opinion instead of CEOs. Given the amount of time involved in transcribing, summarising, and cleaning those up, vs the value that people are getting out of them, it makes sense to reduce the frequency of such posts in the future.</p>

<p>Sometimes I don’t add much to something because I don’t have a strong opinion, or a high enough conviction level in the point I want to make. However, I understand the desire for more of my personal voice, and will adjust this moving forward too. This also implies that future posts will naturally be <a href="https://devonzuegel.com/post/epistemic-statuses-are-lazy-and-that-is-a-good-thing" title="status">things I’m less confident in, as I try to push the boundary of what I cover.</a></p>

<p>If there’s one thing I want to be known for, it’s that I listen to feedback seriously. I might not make all the changes that people want, but I will adjust to the extent possible so that this newsletter continues getting better. Many features of the current version were due to suggestions by readers like you, such as the takeaways up top or separate sections in the monthly. Keep the feedback coming, it’s much appreciated.</p>

<p><em>If you liked this, sign up for my <a href="https://avoidboringpeople.substack.com/" title="ABP">finance and tech newsletter:</a></em></p>



        
      </section></div>]]>
            </description>
            <link>https://www.leonlinsx.com/belief-curve-shape/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24655726</guid>
            <pubDate>Thu, 01 Oct 2020 20:16:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Solving Solved Problems]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24655637">thread link</a>) | @headalgorithm
<br/>
October 1, 2020 | https://ahmadnassri.com/blog/solving-solved-problems/ | <a href="https://web.archive.org/web/*/https://ahmadnassri.com/blog/solving-solved-problems/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  <h6 id="top"><a href="https://ahmadnassri.com/">Home</a> › <a href="https://ahmadnassri.com/blog">blog</a></h6>


  <header>
    
    <h2> — Lessons from my journey</h2>
  </header>

  <h5>How seemingly “solved problems” in technology keep repeating themselves, and how developers keep falling into the trap of reinventing the wheel
</h5>

  
    
  

  

  

  

  <p>When I started my professional journey, the technology landscape looked completely different, yet the patterns in which people operate within this ever-changing landscape keep repeating themselves.</p>

<p>It’s interesting and somewhat frustrating that the challenges I experienced leading small teams in small companies are the same challenges in  leading teams of hundreds in large enterprise businesses!</p>

<p>The interesting part is <strong>recognizing the patterns</strong> shared across all these experiences and creating solutions that scale up and down to accommodate the context. The frustrating part is how seemingly <strong>solved problems keep repeating themselves</strong>, and <strong>developers keep falling into the trap</strong> of reinventing the wheel.</p>

<p>No-one actually has a foolproof plan; people that claim they do are either faking it or miscommunicating their ability to identify patterns. This is especially true in software technology. Our industry‘s <a href="https://en.wikipedia.org/wiki/Half-life_of_knowledge">half-life of knowledge</a> is rapidly shrinking from a few years to a few months, as the rate of change and innovation keeps increasing. And while change is constant for us, so are the patterns!</p>

<p>Or as popularized by Mike Tyson’s quote: <em><strong>“Everybody has a plan until they get punched in the mouth.”</strong></em></p>

<p>In almost every team that I led, the following “solved problems” keep coming up: <em>user authentication/authorization, logging &amp; monitoring, data warehousing &amp; BI, data management &amp; security, infrastructure automation, etc …</em></p>

<p>These are but a small set of “solved problems” that kept on being reinvented, despite many products and service providers that exist solely to solve these problems for you! And I often found myself in the position of being “that guy” who has to pull the brakes and say, <em>“how about we don’t waste time reinventing the wheel here!”</em></p>

<p>One of the fundamental principles I try to instill in every team is <strong>“we should only build things that ONLY WE CAN build.”</strong> While that might seem obvious on the surface, it’s hard for many development teams to realize that they don’t have to reinvent the wheel and roll out custom <em>authentication systems, deployment tools, or monitoring solutions…</em></p>

<p>Our industry’s communities tend to believe that certain companies, which are seen as “leaders” or drivers of “innovation”, somehow have all the answers and know exactly what they are doing. I’m here to tell you that they don’t. Humans tend to put people and companies they admire on pedestals and then blindly copy or mimic them. This is dangerous, especially for technology teams.</p>

<h2 id="technical-debt-and-reinventing-the-wheel">Technical Debt and Reinventing the Wheel</h2>

<p>My first exposure to a wildly popular company and product was at <a href="https://www.itbusiness.ca/news/toronto-developers-viigo-top-download-on-blackberry-app-store/13369">Viigo</a>, a BlackBerry app that predates the iPhone and Android smartphone world. In this world, everybody had a BlackBerry in their pocket, and on that BlackBerry, they had Viigo installed. The app was so popular, it topped the BlackBerry App Store charts for years, even outranking Facebook in downloads and popularity!</p>

<p>I remember getting on subways and streetcars in Toronto, and seeing everybody on their phones using the app I worked on! The local tech community ended up putting the company and development team on a pedestal as if we were creating some groundbreaking technology</p>

<p>In reality, it was a glorified RSS reader with some additional functionality and hackery to get around the limitations of the BlackBerry OS. Most of the content was funnelled through some bat-shit-crazy XML/XSLT processing in PHP that I put together and threw on a couple of EC2 servers … there was no reason this janky XML/XSLT/PHP combo should have scaled to support tens of millions of users and a vast amount of rich media content and real-time sports events (we even covered the Olympics live with nothing but an XML feed and XSLT!). Still, it worked, and it served millions of users across the world! I led the Web Services team at the time, which consisted of myself and two developers mucking around with XSLT templates all day long!</p>

<p>Years later, I joined Mashape <em>(now known as Kong Inc.)</em> as VP of Engineering where we began with an <a href="https://konghq.com/blog/the-api-marketplace-joins-rapidapi/">API Marketplace</a> that grew from 50 users during our Alpha launch in 2010 to over 350,000 users, powering billions of real-time API calls! We later built out a standalone API Management Proxy called Kong, which took all the experience we gained to build and maintain the Marketplace into a standalone product meant for Enterprise-scale API management. The company has since shifted entirely to operating as <a href="https://konghq.com/">Kong Inc.</a> and focuses solely on the Enterprise API product space, with multiple products and services.</p>

<p>When we would go to conference events, we would have a line at our booths that sometimes stretched across the entire booth area, much to the dismay and irks of fellow booth exhibitors! People wanted our cute gorilla mascot t-shirts, and they wanted to chat with us about the “amazing” products we were producing that made their lives easier.</p>

<p>At the time, the engineering team was no more than ten developers that built and maintained four products with massive adoption and massive amounts of traffic—the secret technology behind it all: Nginx and Redis. There was nothing fancy or exceptional about the stack, and we barely managed to keep our heads above water as we proxied billions of business-critical API calls for our users through our systems.</p>

<p>My most recent role was as CTO of npm, Inc. With a massive worldwide community of users that looked to us to provide them with critical services that directly affect their productivity and daily work. Every web developer in the world used our products, with over 1.3 million open-source packages, and serving ~125 billion requests at a whopping six petabytes per month!</p>

<p>A small team of ~25 developers were responsible for this large-scale &amp; critical product, dealing with the same challenges and technical debt problems as any other startup or enterprise team. If it weren’t for a CDN partner taking care of the majority of the traffic at a HIGHLY discounted flat rate, there would have been no way a small team like that could maintain that level of scale!</p>

<p>All these teams were burnt-out. None of them were happy. But we were and still are proud of the large-scale work we accomplished with such small team sizes.</p>

<p>The other common thread in all these experiences was that they were all <em><strong>massively popular technology products mired with technical debt and reinventing-the-wheel syndrome</strong></em>. Some of that debt was created by me back when I didn’t know any better, the rest I inherited. This debt usually comes with a breakdown of technical culture and business growth challenges. While not simple nor easy, the remedy was always about focusing on <em>only building things that only the company can build</em>.</p>

<p>Viigo was <a href="https://www.theglobeandmail.com/globe-investor/rim-buying-toronto-firm-creator-of-popular-app/article4312875/">acquired by BlackBerry in 2010</a>, Kong <a href="https://konghq.com/blog/the-api-marketplace-joins-rapidapi/">sold the API Marketplace to RapidAPI in 2017</a>, and npm was just <a href="https://ahmadnassri.com/blog/so-long-and-thanks-for-all-the-packages/">recently acquired by GitHub</a>.</p>

<h2 id="enter-the-enterprise">Enter the Enterprise</h2>

<p>Before joining npm and soon after the Viigo acquisition, I went into the Enterprise world for a change of pace. In 2013 I joined the <a href="https://en.wikipedia.org/wiki/Canadian_Broadcasting_Corporation">CBC</a> as Development Manager, Digital Operations leading a team of 35, and in 2017 I was Chief Architect at <a href="https://en.wikipedia.org/wiki/Telus">TELUS</a> leading all technology practices and teams spanning over 450+ technologists. And while I’ve had many years of experience in servicing and selling technology products to Enterprise companies, my years inside the Enterprise were perhaps the most eye-opening to our industry’s patterns!</p>

<p>The main takeaway:</p>

<p><strong>There are no differences in technology operations and software development practices between Enterprises and Startups</strong>; the only differences that exist are in communications and processes, which are <em><strong>fundamentally human—not technological—problems</strong></em>.</p>

<p>Enterprise teams are also stuck solving the same “solved problems” and accumulating technical debt, rather than focusing on building the things only they can build. The difference, though, is while these were the same problems, they were distributed across departments and repeated across many teams, which <strong>ultimately adds up to hundreds of millions of dollars in waste</strong>.</p>

<p>Lacking centralized technical leadership and unified vision in the Enterprise world is the root cause for teams to fall into these traps and continue going deeper into the cycle of reinventing the wheel and creating technical debt.</p>

<picture>
  <img src="https://ahmadnassri.com/blog/solving-solved-problems/enterprise-innovation.png">
</picture>

<p>In both worlds, Enterprises and Startups require a centralized model of technical leadership. A clear and measured technical vision to avoid reinventing the wheel and minimizing technical debt can only be achieved by <strong>investing in people</strong> first, ensuring you have the right leaders, the right members, and the right tools to help them succeed. <strong>The responsibility to establish such leadership and vision lies in the hands of the CTO</strong>.</p>

<h2 id="are-there-any-answers">Are there any answers?</h2>

<p><em>Spoiler Alert!</em> there is no ONE answer to address these challenges, and that’s okay! If there was just one answer, then the entire industry will fold into itself, and we’d all be working for Microsoft!</p>

<p>And to pay respect to Mike Tyson’s wisdom again, I can’t suggest having a “plan” to address these challenges, as the next “punch” life delivers will throw any plan out the window!</p>

<p>There are, however, some <strong>key patterns that we share and pitfalls we know to avoid</strong>. My focus will be on building and sharing a body of knowledge in these areas so that CTOs, Founders and Engineering Leaders can benefit from and contribute to each other’s success!</p>

<p>I’m planning to use this space to start tackling some of those patterns one by one, and I’m looking for the community’s feedback &amp; contribution to surface our collective body of knowledge higher and higher!</p>

<h2 id="need-help-now">Need help now?</h2>

<p>While writing and sharing lessons are helpful, it takes time, and it may not be the thing you need RIGHT NOW. But don’t worry, I might still be able to help you!</p>

<p>I’ve started …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ahmadnassri.com/blog/solving-solved-problems/">https://ahmadnassri.com/blog/solving-solved-problems/</a></em></p>]]>
            </description>
            <link>https://ahmadnassri.com/blog/solving-solved-problems/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24655637</guid>
            <pubDate>Thu, 01 Oct 2020 20:09:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why plain text emails perform better than HTML designed ones]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24655493">thread link</a>) | @pau_alcala
<br/>
October 1, 2020 | https://blog.palabra.io/plain-text-engagement | <a href="https://web.archive.org/web/*/https://blog.palabra.io/plain-text-engagement">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p><em>By <a href="https://www.linkedin.com/in/naara-abril-taker/">Abril Taker</a> - Content Creator at <a href="https://www.palabra.io/?utm_medium=plain-text&amp;utm_source=blog">Palabra</a></em></p><p>Plain text sounds boring? Well, let me tell you that plain text is more important than you can imagine. At <a href="https://www.palabra.io/?utm_medium=plain-text&amp;utm_source=blog">Palabra</a> we love plain text to send every email, specially our onboarding sequences. And in this article we’ll share why we think you should start using it too.</p><h2>Isn’t plain text for grannies?👵🏼</h2><p>Plain text has been around since the beginnings of the Internet. So it is understandable that some people think it is obsolete. Maybe there was a time where HTML emails were on a boom, but plain text today is more functional than ever.</p><p>Before we continue we’d like all of us to be in the same page about what plain text is:</p><p>The term Plain text, when we talk about an email, refers to the composition that consists of the copy within the style. Which means that it does not include complex formatting or styled fonts. Although it can have images and links.</p><p>Even if plain text could sound boring at first compared with HTML emails, you will discover that their use can bring many benefits in general, and especially for onboarding sequences.</p><h2>Use plain text for onboarding sequences 🏆</h2><p>When you have a service or a product that depends, on a large portion, of having a constant flow of users, you might want to apply an onboarding sequence in order to avoid the churn rate and to connect with your community.</p><p>If you’re still in the early stage of your strategy, we recommend to read our article about <strong><a href="https://blog.palabra.io/questions-onboarding">5 questions to ask yourself before creating an onboarding email sequence</a></strong>, it will guide you in the process.</p><p>Over the years, new technologies have risen in the field of user experience. We now have many tools to call the attention of customers. This means people are getting a bunch of emails that now look like ads delivered right to your inbox.</p><p>Onboarding should look nothing like ads. That's when you start a close relationship with early users, you educate them about how to use your product better, and open communication channels.</p><h2>5 reasons why plain text is always a good idea</h2><h3>📩 It ensures deliverability</h3><p>The number one thing that you need to do to engage with someone is to get their attention. And for that, you need to get them to open your emails.</p><p>As we said before, HTML emails have images, links, GIFs, all sorts of things that attract the attention of email filters. So they’re more susceptible to being redirected to the spam folder if they have broken links or suspicious behaviours.</p><p>Since plain text emails don’t contain much more information than text, it’s much more likely that they will not alert spam filters.</p><p>Also, plain text emails seem more “real” to your email filters. And that's also handy for your readers!</p><h3>📜 It feels more personal</h3><p>Once your customers open your emails, you don’t want them to say “ugh, another stupid corporative email. DELETE”. That’s probably the worst case scenario.</p><p>Plain text has been proved to have higher click-through rates. Not just because they can pass spam filters, but also because they feel more personal. They look like something a real person sends, to offer information instead of driving sales.</p><p>Then, when you receive a plain text email, it is more associated with a regular person, someone who just wants to talk and know about you as an individual (and not as a target). Your users can perceive you more relatable, human and trust-worthy ✨.</p><h3>🗣️ Starts 1-1 conversations</h3><p>As you can see, there’s a progression. And with plain text you help your emails to be delivered and opened. Do you know what is even better? If your users answer the email!</p><p>We like plain text precisely because of this. Through this kind of emails, we’ve received feedback from our users that was very valuable for us to grow as a company and as a team. They respond because there's a real email address from a real person to answer to.</p><p>We send onboarding emails that appeal to conversation. Having a dialog is the fuel to power the relationship with the users. We try to build a space where the user can feel part of the process and can say something to improve the use of a tool that is so necessary in his life.</p><h3>👩🏼‍🦽 Is more accessible</h3><p>Now we want to highlight something that usually goes unnoticed. Plain text is readable for accessibility systems. This kind of emails has an ethical benefit, because they’re reachable for people with different needs.</p><p>When you send an HTML email, you’re making it more difficult for a blind person, for example, to understand your message.</p><p>At this point, it is good to ask ourselves if our emails can be accessed by a blind person using a screen reader.</p><h3>🔮 Adapts to new technology</h3><p>From the previous point it follows the fact that plain text is more readable. I personally was surprised to discover that you can read your emails in smartwatches and smart assisters,or that you can obtain a more comprehensible preview of the content.</p><p>I know, it is super obvious when you think about it. But we do not always have in mind that there are other kinds of displays where people read their emails or notifications. And that we have to be ahead of the new possibilities, because we don’t know what type of devices will be developed in the future.</p><p>In this case, keeping it simple will ensure you that people can read your messages.</p><p>So, now you know, don’t be shy and start sending those emails and talking to your users. You may be pleasantly surprised with what you discover.</p><hr><p>Hope you enjoyed this post! If you are curious about what you can do with Palabra or would just like to try it go ahead and <a href="https://www.palabra.io/?utm_medium=plain-text&amp;utm_source=blog">create an account here</a>.</p></section></div>]]>
            </description>
            <link>https://blog.palabra.io/plain-text-engagement</link>
            <guid isPermaLink="false">hacker-news-small-sites-24655493</guid>
            <pubDate>Thu, 01 Oct 2020 19:54:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Subsumptions of Regular Polytopes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24655303">thread link</a>) | @mathgenius
<br/>
October 1, 2020 | https://cp4space.hatsya.com/2020/10/01/subsumptions-of-regular-polytopes/ | <a href="https://web.archive.org/web/*/https://cp4space.hatsya.com/2020/10/01/subsumptions-of-regular-polytopes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<p>We say that a regular <em>n</em>-dimensional polytope P <em>subsumes</em> a regular <em>n</em>-dimensional polytope Q if the vertex-set of Q is geometrically similar to a subset of the vertex-set of P.</p>
<p>For instance, the dodecahedron subsumes a cube (the convex hull of the red and blue vertices below), which in turn subsumes a tetrahedron (the convex hull of the blue vertices alone):</p>
<p><img loading="lazy" src="https://cp4space.hatsya.com/wp-content/uploads/2020/10/subsumption.png" alt="" width="440" height="429" srcset="https://cp4space.hatsya.com/wp-content/uploads/2020/10/subsumption.png 440w, https://cp4space.hatsya.com/wp-content/uploads/2020/10/subsumption-300x293.png 300w" sizes="(max-width: 440px) 100vw, 440px"></p>
<p>Note that the centroid of a regular polytope is also the circumcentre — the unique point equidistant from all of the polytope’s vertices — which implies that if one polytope subsumes another, the two vertex-sets must share the same centre. Consequently, we assume without loss of generality that regular polytopes are always centred on the origin.</p>
<h3>Two and three dimensions</h3>
<p>The only regular polytopes in two dimensions are the regular polygons. Using the above reasoning, it is straightforward to see that an <em>m</em>-gon subsumes an <em>n</em>-gon if and only if <em>n</em> is a divisor of <em>m</em>.</p>
<p>In three dimensions, there are exactly five regular polytopes, the Platonic solids. We have already seen that the tetrahedron, cube, and dodecahedron form a chain of subsumptions. It can be shown that these are the only subsumptions between Platonic solids. In particular, if we normalise the solid P to be centred on the origin and have unit radius, we can calculate the set S(P) of pairwise inner products between the vertices of the polyhedron. If P subsumes Q, then S(Q) must necessarily be a subset of S(P).</p>
<h3>Four dimensions</h3>
<p>In four dimensions, there are six ‘Platonic solids’. Five of these form a subsumption chain:</p>
<ul>
<li>the orthoplex (generalised octahedron) is subsumed by</li>
<li>the hypercube, which is subsumed by</li>
<li>the 24-cell, which is subsumed by</li>
<li>the 600-cell, which is subsumed by</li>
<li>the 120-cell.</li>
</ul>
<p>There’s a really elegant way to see these inclusions in terms of quaternions. The group Q8 of eight quaternions {±1, ±i, ±j, ±k} form the vertices of an orthoplex.</p>
<p>This is an index-3 subgroup of the <em>binary tetrahedral group</em>, which contains these eight quaternions together with the 16 unit quaternions of the form:</p>
<p>½(±1 ± i ± j ± k)</p>
<p>These 16 quaternions manifestly form the vertices of a hypercube. Moreover, because we can partition the binary tetrahedral group into cosets with respect to the subgroup Q8, it follows that this hypercube is the union of two disjoint orthoplexes. Taken together, these 24 quaternions form the vertices of a 24-cell, a four-dimensional regular polytope which has no analogue in three dimensions.</p>
<p>Greg Egan’s animation below shows the three cosets in red, green, and blue. Each coset forms the vertices of an orthoplex; the union of any two cosets forms the vertices of a hypercube; the union of all three cosets forms the vertices of a 24-cell:</p>
<div id="attachment_6198"><p><img aria-describedby="caption-attachment-6198" loading="lazy" src="https://cp4space.hatsya.com/wp-content/uploads/2020/10/greg-egan-24-cell.gif" alt="" width="506" height="506"></p><p id="caption-attachment-6198">Animation by Greg Egan of a 24-cell undergoing a double rotation.</p></div>
<p>The 600-cell has 120 vertices which can be identified with the <a href="https://en.wikipedia.org/wiki/Icosian"><em>unit icosians</em></a>, a group of 120 unit quaternions which contains the binary tetrahedral group as an index-5 subgroup. It follows, therefore, that the 600-cell subsumes the 24-cell.</p>
<p>If you take the ring generated by the unit icosians, the 600 norm-2 elements form a scaled copy of the 120-cell, a four-dimensional analogue of a dodecahedron. We can identify norm-2 elements if one can be obtained from the other by right-multiplication by a unit icosian; this partitions these 600 vertices into five equivalence classes, each geometrically similar to the 120 vertices of a 600-cell.</p>
<p>The remaining four-dimensional regular polytope, the simplex, is not subsumed by any of these polytopes; again, this can be deduced from looking at the set S of inner products.</p>
<h3>Higher dimensions</h3>
<p>In higher dimensions, there are only three regular polytopes: the simplex, the orthoplex, and the hypercube.</p>
<p>S(simplex) is the set {1, −1/n}, and S(orthoplex) is the set {1, 0, −1}. It follows that neither of these can subsume each other. This leaves the question of whether the hypercube can subsume either of the other two regular polytopes. The answer is that it depends on <em>n</em>, and is an unsolved problem!</p>
<p>The orthoplex consists of n orthogonal pairs of opposite vertices. For this to be subsumed by a hypercube is equivalent to the existence of a matrix M consisting entirely of entries ±1 such that H := M / √d is a real orthogonal matrix. Such <em>Hadamard matrices</em> exist whenever <em>n</em> is a power of 2. If <em>n</em> ≥ 3, it is easy to show that <em>n</em> must be a multiple of 4, and the converse is conjectured to be true:</p>
<blockquote><p>Does a Hadamard matrix exist in dimension <em>n</em> whenever <em>n</em> is divisible by 4?</p></blockquote>
<p>The first unsolved case is <em>n</em> = 668.</p>
<p>When does the hypercube subsume a simplex? This is equivalent to having <em>n</em>+1 vectors with entries ±1 such that, for every pair of vectors, they disagree in sign in (<em>n</em>+1)/2 coordinates and agree in sign in the other (<em>n</em>−1)/2 coordinates. If we appended an (<em>n</em>+1)th coordinate which is identically 1 to every vector, they would all be orthogonal and therefore form a Hadamard matrix. The converse is also true: removing a column of a Hadamard matrix results in a set of rows which form the vertices of a regular simplex.</p>
<p>To conclude:</p>
<ul>
<li>The hypercube subsumes the simplex if and only if there is a Hadamard matrix of dimension n+1;</li>
<li>The hypercube subsumes the orthoplex if and only if there is a Hadamard matrix of dimension n.</li>
</ul>
											</div></div>]]>
            </description>
            <link>https://cp4space.hatsya.com/2020/10/01/subsumptions-of-regular-polytopes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24655303</guid>
            <pubDate>Thu, 01 Oct 2020 19:36:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MBA: Useless? Worth It?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24655248">thread link</a>) | @william_blount
<br/>
October 1, 2020 | https://www.adamtank.com/new-blog/2020/9/29/mba-useless-worth-it-how-to-decide-if-business-school-is-for-you | <a href="https://web.archive.org/web/*/https://www.adamtank.com/new-blog/2020/9/29/mba-useless-worth-it-how-to-decide-if-business-school-is-for-you">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site">
		<div id="canvas">

			<!-- / headerWrapper -->

			<div id="pageWrapper" role="main">
				<section id="page" data-content-field="main-content">
					<article id="article-5f739a1d700a470284ca17f2" data-item-id="5f739a1d700a470284ca17f2">

	<div>
  <!--SPECIAL CONTENT-->

    

    <div>

    <!--POST HEADER-->

			<header>
				
				
			</header>

    <!--POST BODY-->

      <div><div data-layout-label="Post Body" data-type="item" data-updated-on="1601418418482" id="item-5f739a1d700a470284ca17f2"><div><div><div data-block-type="2" id="block-03961952396bc7b16512"><div><div><p>I’ve been asked 27 times if getting an MBA is worth it. </p><p>I started counting after two close friends texted me essentially the same question:</p><p>‘Considering going back to school... do you think I should get an MBA?’</p><p>I love helping out. But there comes a point when answering the same question 27 times is a little absurd. This essay is my no-bullshit attempt to help people answer that question. </p><p><strong>Disclaimer: </strong>I have an MBA. It was worth it. I doubled my salary, made life-long friends, and learned a hell of a lot. <em>But it’s not worth it for most people.</em><strong>TL;DR - there are only two good reasons to get an MBA</strong>If you stumbled across this essay because you’re considering an MBA I want you to have a definitive answer by the time you’re finished reading. </p><p>Not some wishy-washy ‘well it depends on these 13 factors and if you have kids and if you can ace the GMAT and if you can get into a top school and if if if.’</p><p>Here’s your answer - there are only two GOOD reasons to get an MBA:</p><p>- You want to pivot your career, <em>fast.<br></em>- Your company requires an MBA for promotion - a.k.a. you need to ‘check the box.’</p><p>That’s it. All other reasons aren’t good enough. There’s the ‘TL;DR’ version of this essay.&nbsp; </p></div></div></div><div data-block-type="23" id="block-yui_3_17_2_1_1601418515090_27853"><p><h2 id="Table1">1. My personal MBA journey</h2></p></div><div data-block-type="2" id="block-yui_3_17_2_1_1601411557388_15111"><div><div><p>I started my career as a microbiologist and quality engineer for a large food manufacturing company. It didn’t take long to realize I hated my work.&nbsp;</p><p>About a year and a half into my first job a senior sales executive <a href="https://www.adamtank.com/new-blog/2020/6/27/slumdog-millionaire-how-i-found-new-purpose-getting-lost-in-rio-de-janeiro" target="_blank">opened my eyes to business</a>, and specifically, the importance of concepts like branding, value propositions, supply chain, and other terms I hadn’t ever heard of or thought about. </p><p>I knew I needed to make a career change and started to look for ways to switch roles inside of the company. I was especially interested in sales and marketing roles because when I interacted with those types of employees I felt my strengths, namely <a href="https://www.adamtank.com/new-blog/2020/3/31/most-presentations-suck-heres-what-you-can-do-about-it" target="_blank">public speaking and presentation</a> skills, were more closely aligned with what they did day-to-day.</p><p>After attempting to navigate the internal political structure I came to the realization I wouldn’t be able to switch roles (engineer -&gt; sales) without it taking multiple years and a ton of headaches. Big companies aren’t set up for employees to readily explore their career interests, much less make job function changes in a short amount of time.</p><p>I started looking externally for opportunities that would expose me to other functions and divisions of a business, in addition to the possibility of living and working abroad. I settled on a small food manufacturing company in Rio de Janeiro, Brazil with the goal of getting their processes up to international export certification standards.&nbsp;</p><p>After a year or so living and working in Rio (and also having to embarrassingly <a href="https://www.adamtank.com/new-blog/2020/3/2/the-fastest-way-to-learn-a-new-language-act-like-a-child" target="_blank">learn Portuguese</a>), I came back to the U.S. to help them sell their products. I loved sales and decided to solidify my interest in becoming a full-blown sales &amp; marketing person by getting an MBA. I felt, and still feel, that it was the quickest path to redefine myself in the eyes of future employers as a business person and not just a quality/manufacturing engineer.</p><p>I studied for and took the GMAT twice, researched potential schools, and applied to a half dozen. I settled on the University of Arizona because of their highly ranked entrepreneurship program and the affordability (free with my GMAT score of 690 - above average but nothing too spectacular).&nbsp;</p><p>My two year, full-time experience was definitely worth it. I doubled my salary, made life-long friends, and learned a hell of a lot.&nbsp;</p><p>But it’s not worth it for most people.</p></div></div></div><div data-block-type="23" id="block-yui_3_17_2_1_1601418515090_39092"><p><h2 id="Table2">2. The most commonly used BAD reasons to get an MBA</h2></p></div><div data-block-type="2" id="block-yui_3_17_2_1_1601418515090_40006"><div><div><p>This section lists the top five reasons I’ve heard from friends considering an MBA. The list is not complete and a <a href="https://www.postgrad.com/business-schools/mba-program/reasons-to-study-an-mba/" target="_blank">quick google search</a> will bring up dozens of others. But none of these are good enough to justify spending two years of your life and hundreds of thousands of dollars on a business degree.</p><p><strong>&nbsp;- <em>“I want the network”</em></strong>Although you can develop a great network in business school it should only be a consideration for what full-time school you choose (discussed below), but not a reason to go in the first place.<strong><em></em></strong>This was a good reason before the internet really took off. You can meet, interact, and network with <strong><em>anyone</em></strong> using the power of the internet and social media… specifically <a href="https://twitter.com/artank/status/1304116979985457155?s=20" target="_blank">Twitter.</a></p><p>Elite individuals including business professionals and entrepreneurs all congregate in like-minded groups around the internet. You have to do some digging to find them. But that digging will cost you far less in both time and money than an MBA.&nbsp;</p><p>Take, for instance, one of <a href="https://www.inc.com/bill-murphy-jr/ubers-original-ceo-resigns-the-guy-before-travis-k.html" target="_blank">Travis Kalanick’s first employees</a> at Uber who became CEO… all because he responded to one of Travis’ tweets.&nbsp;</p><p><em>I’ve built a broader AND deeper network</em> than I ever did in grad school by having an active <a href="https://twitter.com/artank" target="_blank">Twitter presence</a>, <a href="https://www.adamtank.com/new-blog/2020/4/30/the-cost-of-writing-well" target="_blank">taking online courses</a>, and a <a href="https://www.adamtank.com/contact" target="_blank">contact me</a> form on this blog.&nbsp;</p><p>If network is the primary reason you’re considering business school think about <em>who</em> you want to network with and <em>why</em>. Create ‘personas’ of those people you imagine surrounding yourself with and then go and find them on the internet. Engage. And see what happens.</p><p><strong>&nbsp;- “<em>I want to learn more about business”</em></strong>That’s what YouTube and Wikipedia are for. That’s also what colleagues in other departments of your workplace are for. You could also try a career in a small business or work for an entrepreneur as a ‘side hustle.’&nbsp;</p><p>There’s also the option of free or heavily discounted online courses through <a href="https://www.udemy.com/course/an-entire-mba-in-1-courseaward-winning-business-school-prof/" target="_blank">Udemy</a>, <a href="https://www.coursera.org/business/collections/mini-mba/" target="_blank">Coursera</a>, or something like <a href="https://altmba.com/" target="_blank">Seth Godin’s altMBA</a>. </p><p>If you really feel motivated try <a href="https://www.adamtank.com/new-blog/2020/4/12/my-failed-attempt-at-the-4-hour-workweek" target="_blank">starting your own company</a>. The best way to learn about business is to do it, not study it. <strong> <p>&nbsp;- “<em>I want to increase my salary”</em></p></strong>Getting an MBA doesn’t guarantee you anything, much less a salary increase, just like getting an undergrad degree doesn’t guarantee you a job.&nbsp;</p><p>MBA students who work hard, go to top schools, and enter highly-paid industries like consulting (despite what they <em>really</em> want out of life) typically see salary increases… but if getting an MBA guaranteed a salary increase there’d be a hell of a lot more people getting MBAs.</p><p><a href="https://bschool.pepperdine.edu/blog/posts/how-does-mba-impact-salary.htm" target="_blank">Pepperdine’s blog</a> sums it up well:</p></div></div></div><div data-block-type="31" id="block-yui_3_17_2_1_1601411557388_18755"><div>

<figure>
  <blockquote data-animation-role="quote">
    <span>“</span>A survey of over 100,000 respondents indicates the average MBA salary is $86,000. According to the U.S. News &amp; World Report article Find MBAs That Lead to Employment, High Salaries, among the 130 ranked full-time MBA programs that reported data, the highest average MBA salary and bonus paid to 2018 graduates was $102,495...<span>”</span>
  </blockquote>
  
</figure>
</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1601411557388_20396"><div><div><p>Keep in mind that the highest <em>AVERAGE</em> MBA salary and bonus in 2018 was $102k. So half of the graduates fell below that… and the upper half likely already had lucrative careers lined up with a former employer before they even started their graduate program.</p><p>Pepperdine then says, “<strong>While there is no guarantee your MBA salary will fall within or beyond this range</strong>, data does show that MBA graduates tend to make good money.”</p><p>What is ‘good money’ anyway? <a href="https://www.cnbc.com/2020/05/26/how-your-salary-and-the-way-you-spend-money-affect-your-happiness.html#:~:text=There%20is%20a%20sort%20of%20perfect%20'happiness'%20salary&amp;text=But%20more%20recently%2C%20a%202018,%2475%2C000%20for%20emotional%20well%2Dbeing." target="_blank">Studies have shown</a> that happiness levels start to fall off after an individual makes more than ~105k/yr. - or right about the highest average starting salary + bonus of an MBA graduate (how ironic…).</p><p>As Biggie says… mo’ money, mo’ problems.</p><p><strong>- <em>“It will help me figure out what to do with my life”</em></strong>If this is a top reason you’re likely a recent college grad, &lt;5 yrs into your career, or recently unemployed.</p><p>Using an MBA to switch careers is great (discussed below). Using an MBA to find a new career is not. Ask yourself if you’re truly using business school to explore an alternate career path (unlikely) or just using it to kill time until you find your next job (likely).&nbsp;</p><p><strong>Grad school will not help you figure out your path in life.&nbsp;</strong>Only you can do that.</p><p>And spending $100k and two years trying to do that is a waste of time and money.&nbsp; An MBA is a safe choice, not a life-changing choice. Don’t conflate the two.&nbsp;</p><p>As John Shedd says, “A ship in harbor is safe, but that is not what ships are built for.”</p><p><strong><em>&nbsp;- “An MBA will impress employers and people in my network”</em></strong>Publicly posting the ‘alphabet soup’ of credentials makes you look like an ass and nobody cares. Here’s a real example on a LinkedIn profile:</p><p>MBA, PMP®, CSM®, PMI-ACP®, ITIL®&nbsp;</p><p>If an employer requires those credentials that’s fine… but they belong on your resume, not as a publicly visible badge of honor.</p><p>As fellow MBA and <a href="https://www.adamtank.com/new-blog/2020/4/30/the-cost-of-writing-well" target="_blank">Write of Passage</a> friend <a href="http://camhouser.com/" target="_blank">Cam Houser</a> says, “MBA is particularly useless here. PhD actually (sometimes) carry weight. MBA on your list looks weak.”</p></div><div><p>The problem with MBA-types - myself included - is that we overanalyze decisions. Paralysis by analysis. I’m trying to help you avoid that. The intent of this section is to help you think critically about a big life decision and come to a definitive answer on what you should do.&nbsp;</p><p>The question you’re asking - should I get an MBA? - is the wrong question. Instead, you should be brutally honest with yourself and answer this question: <strong>What am I trying to accomplish by getting an MBA?</strong>Unlike medicine or law there’s not an MBA requirement (or any degree, for that matter) to have a career in business. You can be wildly successful without any credentials. </p><p>Want proof? If money is your measurement, 30% of billionaires in 2015 didn’t even have a <a href="https://fortune.com/2016/08/08/billionaires-no-degree/#:~:text=About%20three%20out%20of%2010,billionaire%20census%20by%20Wealth%2DX.&amp;text=The%20percent%20of%20billionaires%20with,of%20billionaires%20had%20no%20degree.">bachelor’s degree</a>.&nbsp;</p></div></div></div><div data-block-type="23" id="block-yui_3_17_2_1_1601418515090_47805"><p><h2 id="Table3">3. The only two GOOD reasons to get an MBA</h2></p></div><div data-block-type="2" id="block-yui_3_17_2_1_1601418515090_55018"><div><div><p>This leads me to the only two good reasons to get an MBA. </p><p><strong><em>&nbsp;- You want to pivot your career, fast </em></strong>What I mean by pivot is someone going from an <a href="https://www.punchlistzero.com/this-is-the-best-minor-to-supplement-your-engineering-degree/">engineer</a> to a finance professional, or a non-profit employee to a marketer. Without an MBA this process can take YEARS and come with a lot of headaches, salary reductions, and overall misery.</p><p>The beauty of an MBA is that the first day you set foot on campus you get to choose your ‘new persona.’ And it’s totally acceptable in the eyes of employers!&nbsp;</p><p>As an example, I was a quality and manufacturing engineer that <em>in the first week on campus</em> applied for sales and marketing internships. Many of my classmates were non-profit employees their entire …</p></div></div></div></div></div></div></div></div></div></article></section></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.adamtank.com/new-blog/2020/9/29/mba-useless-worth-it-how-to-decide-if-business-school-is-for-you">https://www.adamtank.com/new-blog/2020/9/29/mba-useless-worth-it-how-to-decide-if-business-school-is-for-you</a></em></p>]]>
            </description>
            <link>https://www.adamtank.com/new-blog/2020/9/29/mba-useless-worth-it-how-to-decide-if-business-school-is-for-you</link>
            <guid isPermaLink="false">hacker-news-small-sites-24655248</guid>
            <pubDate>Thu, 01 Oct 2020 19:31:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Next-Gen Rust Web Apps]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24654891">thread link</a>) | @yannikyeo
<br/>
October 1, 2020 | https://blog.shortepic.com/blog/first/ | <a href="https://web.archive.org/web/*/https://blog.shortepic.com/blog/first/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p>This is an homage to this absolute <a href="http://www.sheshbabu.com/posts/rust-wasm-yew-single-page-application/">work of art</a> by Shesh Babu.</p>

<p>Rust's strong typing and fearless concurrency means we can skip virtual DOM differencing. </p>
<p>In the JavaScript world, avoiding the vDOM is the bread and butter of <a href="https://svelte.dev/">Svelte</a> 
started by Rich Harris, which uses compile-time code generation to assist.</p>
<p>When I can't have static typing I love Clojure, and have spent some time reviewing and 
playing with the stupendous full-stack Clojure SPA framework <a href="http://book.fulcrologic.com/">Fulcro</a> 
by Tony Kay (and associated back-end enabler <a href="https://blog.wsscode.com/pathom/">Pathom</a> 
by Wilker Lucio). It does use vDOM, leveraging Clojure immutable/concurrent data structures 
for time travel superpowers.</p>
<p>For me, the major innovation (among many) in Fulcro is the use of a browser-side normalised database 
which is queried to populate properties for components. This means that updating (<em>mutating</em>) 
a uniquely-keyed item results in the update trivially propagating to any and all components 
referencing the data through that identifier. In Shesh Babu's language: all state is App state.</p>
<p>This article, or series of articles, is going to share my findings and thinking on the 
state of the nation in Rust front-end frameworks which are avoiding the vDOM strategy.</p>
<p>There are actually two Rust front-end frameworks with significant progress already, and they are 
awesome:</p>
<ul>
<li><a href="https://crates.io/crates/mogwai">mogwai</a> by Schell Scivally</li>
<li><a href="https://crates.io/crates/valerie">valerie</a> by Emmanuel Antony</li>
</ul>

<p>The official React site offers a <a href="https://reactjs.org/tutorial/tutorial.html">guided introduction</a> 
by progressively implementing a client-side tic-tac-toe game (also known as <em>noughts and crosses</em>). 
They don't explore a back-end, routing or forms, or many of the other SPA complexities. </p>
<p>For us, it is just enough to highlight the potential of the two Rust frameworks above and paint 
a picture of how those advanced extensions can be easily incorporated, and gives us a solid 
reference point from the old world.</p>

<p>This is the first in a series of articles showing how the two frameworks might attack the example 
application, and then show some code which extends the frameworks to incorporate Fulcro-like app 
state.</p>
<p>My code will concentrate on the ergonomics of the frameworks from the perspective of the SPA-writer.</p>
<p>Next up, I'll show an implementation of the game in Valerie.</p>
<p><a href="https://blog.shortepic.com/blog/second/">On to the first code sample</a>.</p>

  </article></div>]]>
            </description>
            <link>https://blog.shortepic.com/blog/first/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24654891</guid>
            <pubDate>Thu, 01 Oct 2020 19:02:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Incarceration in Real Numbers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24654820">thread link</a>) | @tmsh
<br/>
October 1, 2020 | https://mkorostoff.github.io/incarceration-in-real-numbers/ | <a href="https://web.archive.org/web/*/https://mkorostoff.github.io/incarceration-in-real-numbers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div id="prisoners">
    
    
    
    

    <div>
      <p>The United States holds more people in jails and prisons than any other country by far, both in absolute numbers and as a percentage of population.</p>
    </div>

    <div id="per-one-hundred">
      <div id="per-one-hundred-inner">
        <h2>Incarcerated per 100,000 residents <sup>[<a href="https://github.com/MKorostoff/incarceration-in-real-numbers/blob/master/SOURCES.md#incarceration-rates" target="_blank"></a>]</sup></h2>
        <p><span>USA (698)</span></p>
        <p><span>El Salvador (590)</span></p>
        <p><span>Turkmenistan (552)</span></p>
        <p><span>Thailand (531)</span></p>
        <p><span>Rwanda (511)</span></p>
        <p><span>Cuba (510)</span></p>
        <p><span>Panama (401)</span></p>
        <p><span>Costa Rica (374)</span></p>
        <p><span>Cayman Islands (365)</span></p>
        <p><span>Russia (363)</span></p>
        <p><span>Belize (356)</span></p>
        <p><span>Brazil (348)</span></p>
        <p><span>Belarus (343)</span></p>
        <p><span>Nicaragua (332)</span></p>
        <p><span>Turkey (324)</span></p>
        <p><span>Puerto Rico (313)</span></p>
        <p><span>Brunei Darussalam (307)</span></p>
        <p><span>Cape Verde (296)</span></p>
        <p><span>Uruguay (295)</span></p>
        <p><span>Namibia (295)</span></p>
        <p><span>Iran (294)</span></p>
        <p><span>Trinidad and Tobago (292)</span></p>
        <p><span>Guyana (284)</span></p>
        <p><span>Peru (278)</span></p>
        <p><span>South Africa (275)</span></p>
        <p><span>Georgia (262)</span></p>
        <p><span>Taiwan (258)</span></p>
        <p><span>Swaziland (258)</span></p>
        <p><span>Greenland (249)</span></p>
        <p><span>Colombia (246)</span></p>
        <p><span>French Guiana (243)</span></p>
        <p><span>Gabon (241)</span></p>
        <p><span>Morocco (237)</span></p>
        <p><span>Dominican Republic (237)</span></p>
        <p><span>CuraÃ§ao (236)</span></p>
        <p><span>Azerbaijan (235)</span></p>
        <p><span>Israel (234)</span></p>
        <p><span>Bahrain (234)</span></p>
        <p><span>Ecuador (233)</span></p>
        <p><span>Macau (233)</span></p>
        <p><span>Chile (232)</span></p>
        <p><span>Argentina (230)</span></p>
        <p><span>Malaysia (230)</span></p>
        <p><span>Honduras (229)</span></p>
        <p><span>Lithuania (221)</span></p>
        <p><span>Cambodia (220)</span></p>
        <p><span>Martinique (215)</span></p>
        <p><span>Fiji (210)</span></p>
        <p><span>Botswana (208)</span></p>
        <p><span>Mauritius (203)</span></p>
        <p><span>New Zealand (201)</span></p>
        <p><span>Paraguay (199)</span></p>
        <p><span>Singapore (199)</span></p>
        <p><span>Jordan (198)</span></p>
        <p><span>Saudi Arabia (197)</span></p>
        <p><span>Czech Republic (197)</span></p>
        <p><span>Poland (195)</span></p>
        <p><span>Tunisia (195)</span></p>
        <p><span>Slovakia (195)</span></p>
        <p><span>Moldova (194)</span></p>
        <p><span>New Caledonia (189)</span></p>
        <p><span>Estonia (187)</span></p>
        <p><span>Latvia (183)</span></p>
        <p><span>Montenegro (183)</span></p>
        <p><span>Suriname (183)</span></p>
        <p><span>Philippines (179)</span></p>
        <p><span>Venezuela (178)</span></p>
        <p><span>Albania (177)</span></p>
        <p><span>Hungary (173)</span></p>
        <p><span>Myanmar (171)</span></p>
        <p><span>Australia (170)</span></p>
        <p><span>Mexico (163)</span></p>
        <p><span>Kyrgyzstan (161)</span></p>
        <p><span>Bolivia (158)</span></p>
        <p><span>Kazakhstan (156)</span></p>
        <p><span>Serbia (156)</span></p>
        <p><span>Algeria (151)</span></p>
        <p><span>Uzbekistan (150)</span></p>
        <p><span>Scotland (149)</span></p>
        <p><span>Ukraine (148)</span></p>
        <p><span>Bhutan (145)</span></p>
        <p><span>Lebanon (144)</span></p>
        <p><span>Guatemala (143)</span></p>
        <p><span>England &amp; Wales (140)</span></p>
        <p><span>Nauru (140)</span></p>
        <p><span>Libya (139)</span></p>
        <p><span>Jamaica (138)</span></p>
        <p><span>Malta (131)</span></p>
        <p><span>Laos (130)</span></p>
        <p><span>Vietnam (128)</span></p>
        <p><span>Ethiopia (127)</span></p>
        <p><span>Micronesia (127)</span></p>
        <p><span>Guernsey (127)</span></p>
        <p><span>Iraq (126)</span></p>
        <p><span>Portugal (125)</span></p>
        <p><span>Bulgaria (125)</span></p>
        <p><span>Isle of Man (125)</span></p>
        <p><span>Spain (124)</span></p>
        <p><span>Uganda (124)</span></p>
        <p><span>Cameroon (124)</span></p>
        <p><span>Zambia (123)</span></p>
        <p><span>Tajikistan (121)</span></p>
        <p><span>China (120)</span></p>
        <p><span>Kuwait (117)</span></p>
        <p><span>Egypt (116)</span></p>
        <p><span>Zimbabwe (114)</span></p>
        <p><span>North Macedonia (112)</span></p>
        <p><span>Mongolia (110)</span></p>
        <p><span>Canada (107)</span></p>
        <p><span>Romania (107)</span></p>
        <p><span>Hong Kong (106)</span></p>
        <p><span>France (105)</span></p>
        <p><span>Sri Lanka (105)</span></p>
        <p><span>Luxembourg (105)</span></p>
        <p><span>UAE (104)</span></p>
        <p><span>Kenya (102)</span></p>
        <p><span>Italy (101)</span></p>
        <p><span>Indonesia (99)</span></p>
        <p><span>Austria (98)</span></p>
        <p><span>Belgium (95)</span></p>
        <p><span>Greece (95)</span></p>
        <p><span>Kosovo (95)</span></p>
        <p><span>Madagascar (93)</span></p>
        <p><span>Angola (93)</span></p>
        <p><span>Lesotho (92)</span></p>
        <p><span>Afghanistan (87)</span></p>
        <p><span>Cyprus (86)</span></p>
        <p><span>Burundi  (85)</span></p>
        <p><span>Monaco (83)</span></p>
        <p><span>Cote d'Ivoire  (82)</span></p>
        <p><span>Switzerland  (81)</span></p>
        <p><span>Haiti  (80)</span></p>
        <p><span>Croatia  (79)</span></p>
        <p><span>Ireland (79)</span></p>
        <p><span>Nepal  (79)</span></p>
        <p><span>Northern Ireland (78)</span></p>
        <p><span>Germany  (77)</span></p>
        <p><span>Armenia  (76)</span></p>
        <p><span>Malawi (76)</span></p>
        <p><span>Slovenia (69)</span></p>
        <p><span>Benin  (68)</span></p>
        <p><span>Senegal  (68)</span></p>
        <p><span>Djibouti (66)</span></p>
        <p><span>Togo (66)</span></p>
        <p><span>Andorra  (64)</span></p>
        <p><span>Denmark  (63)</span></p>
        <p><span>Equatorial Guinea  (63)</span></p>
        <p><span>Mozambique (63)</span></p>
        <p><span>Papua New Guinea (62)</span></p>
        <p><span>Sweden (61)</span></p>
        <p><span>Netherlands  (61)</span></p>
        <p><span>Norway (60)</span></p>
        <p><span>Sierra Leone (60)</span></p>
        <p><span>Syria  (60)</span></p>
        <p><span>Chad (59)</span></p>
        <p><span>Tanzania (59)</span></p>
        <p><span>Finland  (53)</span></p>
        <p><span>Mauritania (53)</span></p>
        <p><span>Qatar  (53)</span></p>
        <p><span>Yemen  (53)</span></p>
        <p><span>Bangladesh (52)</span></p>
        <p><span>Ghana  (52)</span></p>
        <p><span>Sudan  (52)</span></p>
        <p><span>Timor-Leste (52)</span></p>
        <p><span>Liberia  (50)</span></p>
        <p><span>South Sudan  (50)</span></p>
        <p><span>Niger  (44)</span></p>
        <p><span>Burkina Faso (39)</span></p>
        <p><span>Japan  (39)</span></p>
        <p><span>Pakistan (38)</span></p>
        <p><span>Iceland  (37)</span></p>
        <p><span>Nigeria  (36)</span></p>
        <p><span>Oman (36)</span></p>
        <p><span>India  (34)</span></p>
        <p><span>Mali (33)</span></p>
        <p><span>Gambia (31)</span></p>
        <p><span>Liechtenstein  (31)</span></p>
        <p><span>Democratic Republic of Congo (29)</span></p>
        <p><span>Guinea (28)</span></p>
        <p><span>Congo (27)</span></p>
        <p><span>Central African Republic (16)</span></p>
        <p><span>Guinea Bissau  (10)</span></p>
        <p><span>San Marino (6)</span></p>
      <p><a onclick="toggleExpand('per-one-hundred', 'per-one-hundred-inner')">Expand ▼</a>
      </p></div>
    </div>

    <div id="country-rank">
      <div id="country-rank-inner">
        <h2>Number of people incarcerated <sup>[<a href="https://github.com/MKorostoff/incarceration-in-real-numbers/blob/master/SOURCES.md#incarceration-rates" target="_blank"></a>]</sup></h2>
        <p>USA (2.3M)</p>
        <p><span>China (1.7M)</span></p>
        <p><span>Brazil (747K)</span></p>
        <p><span>Russian Federation (524K)</span></p>
        <p><span>India (466K)</span></p>
        <p><span>Thailand (368K)</span></p>
        <p><span>Indonesia (267K)</span></p>
        <p><span>Turkey (265K)</span></p>
        <p><span>Iran (240K)</span></p>
        <p><span>Philippines (215K)</span></p>
        <p><span>Mexico (203K)</span></p>
        <p><span>South Africa (163K)</span></p>
        <p><span>Vietnam (124K)</span></p>
        <p><span>Colombia (123K)</span></p>
        <p><span>Ethiopia (114K)</span></p>
        <p><span>Egypt (106K)</span></p>
        <p><span>Argentina (103K)</span></p>
        <p><span>Myanmar  (92K)</span></p>
        <p><span>Peru (91K)</span></p>
        <p><span>Bangladesh (88K)</span></p>
        <p><span>Morocco (86K)</span></p>
        <p><span>United Kingdom: England &amp; Wales (83K)</span></p>
        <p><span>Pakistan (77K)</span></p>
        <p><span>Poland (74K)</span></p>
        <p><span>Malaysia (74K)</span></p>
        <p><span>Nigeria (73K)</span></p>
        <p><span>France (71K)</span></p>
        <p><span>Rwanda (65K)</span></p>
        <p><span>Germany (64K)</span></p>
        <p><span>Algeria (63K)</span></p>
        <p><span>Saudi Arabia (61K)</span></p>
        <p><span>Taiwan (61K)</span></p>
        <p><span>Italy (61K)</span></p>
        <p><span>Spain (58K)</span></p>
        <p><span>Cuba (57K)</span></p>
        <p><span>Venezuela (57K)</span></p>
        <p><span>Uganda (55K)</span></p>
        <p><span>Republic of  (55K)</span></p>
        <p><span>Ukraine (53K)</span></p>
        <p><span>Kenya (51K)</span></p>
        <p><span>Japan (49K)</span></p>
        <p><span>Iraq (45K)</span></p>
        <p><span>Uzbekistan (44K)</span></p>
        <p><span>Australia (43K)</span></p>
        <p><span>Chile (43K)</span></p>
        <p><span>Ecuador (40K)</span></p>
        <p><span>Canada (40K)</span></p>
        <p><span>El Salvador (38K)</span></p>
        <p><span>Cambodia (37K)</span></p>
        <p><span>Tanzania (36K)</span></p>
        <p><span>Belarus (33K)</span></p>
        <p><span>Afghanistan (31K)</span></p>
        <p><span>Cameroon (31K)</span></p>
        <p><span>Turkmenistan (30K)</span></p>
        <p><span>Kazakhstan (29K)</span></p>
        <p><span>Dominican Republic (26K)</span></p>
        <p><span>Guatemala (25K)</span></p>
        <p><span>Madagascar (25K)</span></p>
        <p><span>Angola (24K)</span></p>
        <p><span>Nepal (24K)</span></p>
        <p><span>Sri Lanka (23K)</span></p>
        <p><span>Azerbaijan (23K)</span></p>
        <p><span>Zambia (23K)</span></p>
        <p><span>Tunisia (23K)</span></p>
        <p><span>Cote d'Ivoire (21K)</span></p>
        <p><span>Czech Republic (21K)</span></p>
        <p><span>Sudan (21K)</span></p>
        <p><span>Nicaragua (21K)</span></p>
        <p><span>Romania (21K)</span></p>
        <p><span>Democratic Republic of Congo (21K)</span></p>
        <p><span>Honduras (21K)</span></p>
        <p><span>Jordan (20K)</span></p>
        <p><span>Mozambique (20K)</span></p>
        <p><span>Zimbabwe (19K)</span></p>
        <p><span>Israel (19K)</span></p>
        <p><span>Costa Rica (19K)</span></p>
        <p><span>Bolivia (18K)</span></p>
        <p><span>Panama (17K)</span></p>
        <p><span>Hungary (17K)</span></p>
        <p><span>Ghana (15K)</span></p>
        <p><span>Malawi (15K)</span></p>
        <p><span>Yemen (14K)</span></p>
        <p><span>Paraguay (14K)</span></p>
        <p><span>Portugal (13K)</span></p>
        <p><span>Singapore (12K)</span></p>
        <p><span>Senegal (12K)</span></p>
        <p><span>Belgium (11K)</span></p>
        <p><span>Serbia (11K)</span></p>
        <p><span>Burundi (11K)</span></p>
        <p><span>Slovakia (11K)</span></p>
        <p><span>Syria (11K)</span></p>
        <p><span>Puerto Rico  (10K)</span></p>
        <p><span>Netherlands (10K)</span></p>
        <p><span>Uruguay (10K)</span></p>
        <p><span>Greece (10K)</span></p>
        <p><span>Kyrgyzstan (10K)</span></p>
        <p><span>New Zealand (10K)</span></p>
        <p><span>United Arab Emirates (10K)</span></p>
        <p><span>Georgia (10K)</span></p>
        <p><span>Niger (10K)</span></p>
        <p><span>Tajikistan (9K)</span></p>
        <p><span>Libya (9K)</span></p>
        <p><span>Bulgaria (9K)</span></p>
        <p><span>Laos (9K)</span></p>
        <p><span>Haiti (9K)</span></p>
        <p><span>Chad (9K)</span></p>
        <p><span>Austria (9K)</span></p>
        <p><span>United Kingdom: Scotland (8K)</span></p>
        <p><span>Hong Kong  (8K)</span></p>
        <p><span>Benin (8K)</span></p>
        <p><span>Burkina Faso (8K)</span></p>
        <p><span>Namibia (7K)</span></p>
        <p><span>South Sudan (7K)</span></p>
        <p><span>Lebanon (7K)</span></p>
        <p><span>Switzerland (7K)</span></p>
        <p><span>Moldova  (7K)</span></p>
        <p><span>Sweden (6K)</span></p>
        <p><span>Lithuania (6K)</span></p>
        <p><span>Mali (5K)</span></p>
        <p><span>Togo (5K)</span></p>
        <p><span>Papua New Guinea (5K)</span></p>
        <p><span>Albania (5K)</span></p>
        <p><span>Sierra Leone (5K)</span></p>
        <p><span>Kuwait (5K)</span></p>
        <p><span>Gabon (4K)</span></p>
        <p><span>Botswana (4K)</span></p>
        <p><span>Trinidad and Tobago (4K)</span></p>
        <p><span>Ireland, Republic of (4K)</span></p>
        <p><span>Jamaica (4K)</span></p>
        <p><span>Guinea  (4K)</span></p>
        <p><span>Denmark (4K)</span></p>
        <p><span>Latvia (4K)</span></p>
        <p><span>Bahrain (3K)</span></p>
        <p><span>Swaziland/eSwatini (3K)</span></p>
        <p><span>Mongolia (3K)</span></p>
        <p><span>Croatia (3K)</span></p>
        <p><span>Norway (3K)</span></p>
        <p><span>Finland (3K)</span></p>
        <p><span>Mauritius (3K)</span></p>
        <p><span>Estonia (2K)</span></p>
        <p><span>Liberia (2K)</span></p>
        <p><span>North Macedonia (2K)</span></p>
        <p><span>Mauritania (2K)</span></p>
        <p><span>Armenia (2K)</span></p>
        <p><span>Guyana (2K)</span></p>
        <p><span>Lesotho (2K)</span></p>
        <p><span>Fiji (2K)</span></p>
        <p><span>Maldives (2K)</span></p>
        <p><span>Bahamas (2K)</span></p>
        <p><span>Bosnia and Herzegovina: Federation (2K)</span></p>
        <p><span>Kosovo/Kosova (2K)</span></p>
        <p><span>Macau  (2K)</span></p>
        <p><span>Cape Verde  (2K)</span></p>
        <p><span>United Kingdom: Northern Ireland (1K)</span></p>
        <p><span>Slovenia (1K)</span></p>
        <p><span>Brunei Darussalam (1K)</span></p>
        <p><span>Oman (1K)</span></p>
        <p><span>Belize (1K)</span></p>
        <p><span>Congo  (1K)</span></p>
      <p><a onclick="toggleExpand('country-rank', 'country-rank-inner')">Expand ▼</a>
      </p></div>
    </div>

    <div>
      <p>There are more incarcerated people than members of almost any profession. There are more incarcerated people than military personnel. There are more incarcerated people than bus drivers, bar tenders, and hair dressers combined. [<a target="_blank" href="https://github.com/MKorostoff/incarceration-in-real-numbers/blob/master/SOURCES.md#incarceration-compared-to-professions"></a>]</p>
    </div>

    <div>
      <p>
        More Americans are incarcerated today than there have been Americans killed in all of the wars in all of history combined.
      </p>
    </div>

    <div id="casualties">
      <div>
        <h2>Incarceration compared to casualties of war <sup>[<a target="_blank" href="https://github.com/MKorostoff/incarceration-in-real-numbers/blob/master/SOURCES.md#american-war-dead"></a>]</sup></h2>
        <p>Americans currently incarcerated (2.3M)</p>
        <p>American war dead, all of history combined (1.3M)</p>
        <p>American war wounded, all of history combined (1.5M)</p>
      </div>
    </div>

    <div>
      <p>While the incarcerated population is unfathomably large, it is just the tip of the iceberg.</p>
    </div>

    <div id="correctional-population">
      <div>
        <h2>The total correctional population <sup>[<a href="https://github.com/MKorostoff/incarceration-in-real-numbers/blob/master/SOURCES.md#total-correctional-population" target="_blank"></a>]</sup></h2>
        <div>

          <div>
            <p>Currently incarcerated (2.3M)</p>
          </div>

          <div>
            <p>Will be incarcerated this year (4.9M)</p>
          </div>

          <div>
            <p>Alive currently, will go to prison ever (10.9M)</p>
          </div>

          <div>
            <p>Has a criminal record (77M)</p>
          </div>

          <div>
            <p>Ever had an immediate family member incarcerated (113M)</p>
          </div>

        </div>
      </div>
    </div>

    <div>
      <p>Almost no one gets a trial.</p>
    </div>

    <div>
      <p><img src="https://mkorostoff.github.io/incarceration-in-real-numbers/img/person/blue.svg">Notice that the background icons have changed. The blue icons are the portion of incarcerated people who got trials, around 2%.</p>
    </div>

    <div>
      <p>Almost all accused people are extorted into taking plea bargains under the threat of a longer sentence, the ruinous cost of mounting a defense, and the wildly under-resourced public defender system. [<a href="https://github.com/MKorostoff/incarceration-in-real-numbers/blob/master/SOURCES.md#plea-bargains" target="_blank"></a>]</p>
    </div>

    <div>
      <p>No other country on earth incarcerates so many people without trial. …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mkorostoff.github.io/incarceration-in-real-numbers/">https://mkorostoff.github.io/incarceration-in-real-numbers/</a></em></p>]]>
            </description>
            <link>https://mkorostoff.github.io/incarceration-in-real-numbers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24654820</guid>
            <pubDate>Thu, 01 Oct 2020 18:57:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reducing spam emails from 43% to 1% (after a spammer exploited our SaaS)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24654762">thread link</a>) | @kareemm
<br/>
October 1, 2020 | https://www.savio.io/blog/improving-email-deliverability-from-43-percent-spam-to-1-percent/ | <a href="https://web.archive.org/web/*/https://www.savio.io/blog/improving-email-deliverability-from-43-percent-spam-to-1-percent/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

      <p>Last month spammers found a hole in our app that let them send spam emails.   Our customers use Savio to track feature requests.  When those requests get deployed, our customers send a "<a href="https://www.savio.io/use-cases/close-the-loop/">close the loop</a>" email so requesters know the feature they wanted is now live.</p>
<p>Spammers exploited this feature to send about 20,000 unsolicited emails.  Fortunately there was a bit of friction if you're trying to use Savio to spam; it wasn't as easy as pasting in a list of email addresses and hitting send so the spammers weren't able to do major damage.  Plus, we noticed the problem within an hour or so and were able to close the exploit quickly.</p>
<p>Here's our daily email sent volume (the attack happened on August 27):</p>
<p><img alt="Sending volume went up significantly.  Thanks Spammers!" src="https://a.storyblok.com/f/84825/1902x1002/736c27b517/sending-volume.png"> </p>
<p>We only had 4 spam complaints. But we also had 3744 bounces:</p>
<p><img alt="Not too many bounces" src="https://a.storyblok.com/f/84825/2022x1042/bd71153076/bounces.png"> </p>
<p>Doesn't sound terrible, but it had some bad downstream implications for our email deliverability...</p>
<h2>Problem: Our Customers' "Close the Loop" Emails were being marked as spam</h2>
<p>We ran a few tests to see if email deliverability was impacted and didn't notice anything bad.  But we got an email from a customer who was seeing her "Close the Loop" emails end up in spam:</p>
<p><img alt="Img" src="https://a.storyblok.com/f/84825/1588x394/43eac609fe/going-to-spam.png">  </p>
<p>So it was time to dig in and see what was going on.</p>
<h2>Diagnosing our deliverability problem</h2>
<p>There were two things we did to understand what might be causing the deliverability problem:</p>
<ol>
<li>
<p>We verified we had legit SPF, DMARC, and DKIM DNS records</p>
</li>
<li>
<p>We used GlockApps to test deliverability (thanks to my pal <a href="https://twitter.com/CollinYVR">@Collin</a> for the tip)</p>
</li>
</ol>
<h3>1. Verifying DNS records</h3>
<p>We used <a href="https://www.mail-tester.com/spf-dkim-check">MailTester</a> to verify our SPF and DKIM records, and <a href="https://mxtoolbox.com/dmarc.aspx">MXToolbox's DMarc Tool</a> to verify we had properly added our deliverability-related DNS records. These records help email services like Gmail know whether emails sent from your domain are legit or not.  All came back good, so we didn't have to mess around with those.</p>
<h3>2. Run deliverability test with GlockApps</h3>
<p>I'd never heard of <a href="https://glockapps.com/">GlockApps</a> before Collin suggested trying them.  It's a fantastic service.  It works by:</p>
<ol>
<li>
<p>Giving you a bunch of email addresses at different providers to send your email to.  </p>
</li>
<li>
<p>Analyzing whether those emails end up in the inbox or spam folder</p>
</li>
<li>
<p>Showing you the results</p>
</li>
<li>
<p>Giving you steps to take to fix things</p>
</li>
</ol>
<p>On the first test we ran with Glock, we sent our "Close the Loop" email to 73 GlockApps-provided email addresses at Gmail, Yahoo, Hotmail, Fastmail, GSuite, AOL, and a few other providers.  </p>
<p>Here were the high-level results:</p>
<p><img alt="Img" src="https://a.storyblok.com/f/84825/2210x420/809475f09f/report1-annotated.png"></p>
<p>43.7% of our emails ended up in the spam folder - NOT good.</p>
<p>When we looked at the heuristics Glock ran, things didn't look <strong>too</strong> bad...</p>
<p><img alt="Img" src="https://a.storyblok.com/f/84825/2218x706/b76ad08837/report1-results.png"> </p>
<p>... but even so, all the emails we sent to AOL, Gmail, GSuite, and Yahoo addresses ended up in spam 😱</p>
<p>Yahoo:<br>
<img alt="Img" src="https://a.storyblok.com/f/84825/2138x584/0e7a9f0e82/yahoo-annotated.png"></p>
<p>Gmail and GSuite:<br>
<img alt="Img" src="https://a.storyblok.com/f/84825/2196x1144/3bccd33a21/gmail-annotated.png"></p>
<p>Aol:<br>
<img alt="Img" src="https://a.storyblok.com/f/84825/2158x478/8cdb38db63/aol-annotated.png"></p>
<p>Yikes.</p>
<h2>Fixing our deliverability problem</h2>
<p>Luckily Glock gives you some ideas about how to improve deliverability.  Specifically:</p>
<ul>
<li>
<p>They show you if you're on any email blacklists</p>
</li>
<li>
<p>They analyze your email's content and tell you if there are issues you can fix </p>
</li>
<li>
<p>They provide a list of action steps you can take to improve deliverability</p>
</li>
<li>
<p>They also provided two articles - one of which included advice that moved the dial most for us! </p>
</li>
</ul>
<h3>1. Getting off email Blacklists</h3>
<p><a href="https://www.leadfuze.com/email-blacklist/">Leadfuze says</a>:</p>
<blockquote>
<p>An email Blacklist is a real-time database that uses criteria to determine if an IP is sending email it considers to be SPAM. There are several blacklists… Each list [has] a unique way of accepting inbound mail and determining if email is considered SPAM. They can all impact deliverability for your emails.</p>
</blockquote>
<p>We had ended up on two blacklists: <a href="http://www.sorbs.net/">SORBS</a> and <a href="https://www.justspam.org/">JustSpam</a>.  It's not entirely clear whether our spammer put us on either list.  That's because:</p>
<ol>
<li>
<p>We are using a shared <a href="https://www.mailgun.com/">Mailgun</a> server to send email.  Others using the same box (and therefore same IP address) would impact our sending.  Being on the same box as a spammer would impact deliverability for everybody who sent email via that IP.</p>
</li>
<li>
<p>SORBS showed multiple spam incidents, none of which seemed to be ours (which occurred on August 27 2020):</p>
</li>
</ol>
<p><img alt="Img" src="https://a.storyblok.com/f/84825/1368x1026/4a1cdc6755/sorbs-annotated.png"></p>
<p>Getting off of the SORBS blacklist required us to sign up for an account and write up a ticket explaining what happened.  I got a response quickly:</p>
<p><img alt="Img" src="https://a.storyblok.com/f/84825/1600x864/56d66b5f4d/sorbs-response.png"></p>
<p>I was hard-pressed to come up with a good reply to that - the clear answer seemed that we should use a different IP address to send emails.</p>
<p>Getting off of JustSpam.org's list was a lot easier: one click and an hour later our server's IP was off:</p>
<p><img alt="Img" src="https://a.storyblok.com/f/84825/2508x904/13a8b46ebb/justspam-response.png"></p>
<p>Ultimately the solution to an IP address with reputation problems is moving servers.  Not hard to do but we didn't want to try that just yet. </p>
<h3>2. Fixing our content issues</h3>
<p>We had three quick fixes here:</p>
<ol>
<li>
<p>We didn't have a TITLE tag inside our HTML email's HEAD section.  That was a quick fix.</p>
</li>
<li>
<p>We weren't including a text version of our emails alongside the HTML version, so we added that.  Google apparently regards emails with no text version as spammier than those with both text and HTML.</p>
</li>
<li>
<p>We included a "Sent with Savio" link in the email footer. I removed that just to make the email as low-risk as possible.</p>
</li>
</ol>
<h3>3. Other action steps</h3>
<p>Glock provided a list of other action steps we could take:</p>
<p><img alt="Img" src="https://a.storyblok.com/f/84825/2262x1448/93fa1d6acb/more-action-steps.png"></p>
<p>Many seemed like they didn't apply (use fewer exclamation marks in your emails!), weren't helpful (Google Postmaster literally told us to come back later after we signed up), or would take days / weeks to test and didn't stand out as things that were likely to work.</p>
<h2>More resources (and the eventual fix!)</h2>
<p>Glock also pointed us to two other articles, one which ended up containing the secret to fixing our deliverability issue:</p>
<ol>
<li>
<p><a href="https://glockapps.com/blog/how-i-decreased-my-spam-rate/">How this guy decreased his spam rate from 35.2% to 2.8%</a>.  Spoiler: he sent emails from his spammy domain to friends, had those friends reply, and continued the conversation for a couple weeks.  Google weighs replies and engagement very highly when determining whether an email or sender is spammy.  In my work with <a href="https://www.predictablerevenue.com/">Predictable Revenue</a> I know that warming up email accounts like this is hugely important.  But since our account had already been operating for nearly two years, this didn't seem like low-hanging fruit.</p>
</li>
<li>
<p><a href="https://glockapps.com/tutorials/fix-email-deliverability/">How to Find and Fix Email Deliverability Issues</a>.  This article was gold.  It covered:</p>
<ul>
<li>email content (ours was good)</li>
<li>server config like DKIM, SPF, etc (also good)</li>
<li>IP address reputation (not great, but fixable by switching boxes)</li>
<li>and email and domain reputation (unexplored)</li>
</ul>
</li>
</ol>
<p>Seemed like it was worth exploring email and domain reputation in a little bit more depth.</p>
<h2>Testing email and Domain Reputation</h2>
<p>Glock described how to test whether email providers saw your email address as spammy:</p>
<blockquote>
<p>Use GlockApps to test different sender addresses on the same domain. Remember to keep other variables the same. If the same email (from the same IP and domain) is delivered to more Inboxes with a different sender email address, the problem could be in your old email address.  </p>
</blockquote>
<p>That seemed like a super easy experiment to run.  So we changed our sending email address from notifications@savio.io to email@savio.io.</p>
<p>Here were the results:</p>
<p><img alt="Img" src="https://a.storyblok.com/f/84825/2076x410/f5e3fb35ef/report2-annotated.png"></p>
<p><strong>Incredibly, the percentage of emails marked as spam had dropped from 43.7% to 1.4%!</strong></p>
<p>To be fair, this test also included the fixes I mentioned above:</p>
<ul>
<li>
<p>The HTML email included a TITLE tag</p>
</li>
<li>
<p>The email also included a text version</p>
</li>
<li>
<p>I removed the "Sent with Savio" link from the email footer</p>
</li>
</ul>
<p>But my guess is that changing the sending address is the major factor that solved the spam problem.</p>
<p>Compare the two tests side by side:</p>
<p><img alt="Img" src="https://a.storyblok.com/f/84825/2076x532/f258e9d5be/comparison-annotated.png"></p>
<h2>What next</h2>
<p>There are still a few steps we can take to ensure deliverability stays high.</p>
<ol>
<li>
<p>Think like an attacker when building features that customers can use to contact others.  Given previous businesses we worked on we really should have spotted this before it went to production.  We've now added an "Possible Exploits and Mitigation" section to our requirements document.  This is to prompt us to identify potential major exploits worth devoting dev resources to when building a new feature.</p>
</li>
<li>
<p>Move email sending to a dedicated IP address.  This would ensure we wouldn't be impacted by the spammy neighbour problem.</p>
</li>
<li>
<p>Isolate "Close the Loop" emails to a different sending subdomain.  We provide a template, but ultimately our customers write the emails that get sent on our domain.  Isolating these emails to their own subdomain would ensure that and reputation issues would not affect email sent from the rest of the app or from the email accounts we use to conduct business.     </p>
</li>
</ol>

      <p><i>Last Updated: October 1, 2020</i></p><div>
        <p><img src="https://www.savio.io/static/images/founder-headshot-kareem.png" alt="" height="150" width="150">
        </p>
        <div>
            <h4>Kareem Mayan</h4>
            <p>Kareem is a co-founder at <a href="https://www.savio.io/">Savio</a>. He's been prioritizing customer feedback professionally since 2001. He likes tea and tea snacks, and dislikes refraining from eating lots of tea snacks.</p>
        </div>
      </div>

      <form method="post" action="https://sendfox.com/form/1dze03/1y0wom" id="1y0wom" data-async="true">

      <h4>Want more articles like this?</h4>
      <p>Leaders from Slack, Zapier, and Appcues read our newsletter to delight customers, lower churn, and grow expansion revenue.</p>
      

      <!-- no botz please -->
      
      
      <p>Max 2 emails/month. Unsub anytime.</p>

      </form>
    </div></div>]]>
            </description>
            <link>https://www.savio.io/blog/improving-email-deliverability-from-43-percent-spam-to-1-percent/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24654762</guid>
            <pubDate>Thu, 01 Oct 2020 18:53:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[All you need to build a product is a mission]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24654576">thread link</a>) | @dvt
<br/>
October 1, 2020 | http://noemititarenco.com/2020/09/25/all-you-need-to-build-a-product-is-a-mission/ | <a href="https://web.archive.org/web/*/http://noemititarenco.com/2020/09/25/all-you-need-to-build-a-product-is-a-mission/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://noemititarenco.com/2020/09/25/all-you-need-to-build-a-product-is-a-mission/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24654576</guid>
            <pubDate>Thu, 01 Oct 2020 18:37:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hosting a blog on Azure for $2.5 per month]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24654536">thread link</a>) | @fleide
<br/>
October 1, 2020 | https://www.eiden.ca/azure-static-blog/ | <a href="https://web.archive.org/web/*/https://www.eiden.ca/azure-static-blog/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article role="main">
        <p>High level picture of hosting a static site (blog) on Azure with details on how to wire a custom domain (root and www) with HTTPS support. It’s actually easier that it sounds.</p>

<!--more-->

<p>Let’s start by noting that $2 out of the $2.5 mentioned in the title are for the custom domain name and associated SSL certificate (for HTTPS). Static content hosting, CDN (<a href="https://en.wikipedia.org/wiki/Content_delivery_network">content delivery network</a>) and networking in Azure cost less than 50 cents per month for this application. To be fair, this is not the most read blog of the Internet.</p>

<p>Also I’m using <a href="https://jekyllrb.com/">Jekyll</a> for this blog, and it’s been good to me so far.</p>

<h2 id="summary">Summary</h2>

<p>The main components used are:</p>

<ul>
  <li>From non-Microsoft providers
    <ul>
      <li>a <strong>custom domain name</strong> from a registrar of our choosing (I’m using <a href="https://www.gandi.net/en-CA">Gandi</a>) - here <code>eiden.ca</code></li>
      <li>a <strong>SSL certificate</strong> to enable HTTPS, I recommend Namecheap (<a href="https://www.namecheap.com/security/ssl-certificates/comodo/positivessl/">PositiveSSL</a>) to procure one. This certificate will need to be generated for the custom domain name we created above (we’ll see how). <strong>THIS IS IF</strong> you want HTTPS for the <strong>root</strong> of the custom domain (<a href="https://eiden.ca/">https://eiden.ca</a>), even if you just want it to redirect to <strong>www</strong>. This was a must have for me, and the reason for the existence of this very article. If you don’t care about the root, you can use the <a href="https://docs.microsoft.com/en-us/azure/cdn/cdn-custom-ssl?tabs=option-1-default-enable-https-with-a-cdn-managed-certificate">managed certificate included</a> in Azure CDN (which at the time of writing doesn’t support root).</li>
    </ul>
  </li>
  <li>In Azure
    <ul>
      <li>a <strong>Storage Account</strong> with <a href="https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-static-website">static web hosting</a> enabled. That feature allows to serve static content (html, css, javascript, images) directly from a container</li>
      <li>a <strong>Key Vault</strong> to help generate the certificate and store it once issued by the provider</li>
      <li>a <strong>CDN Profile</strong>, to cache the content and optimize performance and cost. The CDN profile loads our content from the storage account, distributes in its worldwide network, and serves to visitors in a scalable fashion automatically</li>
      <li>a <strong>DNS Zone</strong>, to manage the name resolution of our custom domain and point the traffic towards the CDN profile</li>
    </ul>
  </li>
</ul>

<p>On a picture:</p>

<p><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/overall_schema.png"><img src="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/overall_schema.png" alt="Schema of the solution, all details will be explained below in this post"></a></p>

<p><em><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/overall_schema.png">figure 1 : Schema of the solution</a></em></p>

<p>Let’s jump into it.</p>

<h2 id="step-1-and-2--starting-with-the-static-website-and-the-cdn-profile">Step 1 and 2 : Starting with the Static Website and the CDN Profile</h2>

<p>First we will follow the <strong>parts 1 and 2</strong> from this <a href="https://www.wrightfully.com/azure-static-website-custom-domain-https">awesome tutorial</a> from John M. Wright to get the storage account and CDN profile set up. <strong>Let’s not go further than part 2</strong>, we’ll switch to another guide for the following step.</p>

<p>In part 2, I’ve personally used the <code>Azure CDN from Microsoft</code> and it went great.</p>

<p>At this point, what we should have is this:</p>

<p><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step1.png"><img src="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step1.png" alt="Step 1 : a storage account with static hosting and a CDN endpoint"></a></p>

<p><em><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step1.png">figure 2 : a storage account with static hosting and a CDN endpoint</a></em></p>

<p>We can already see our content online at the following URLs:</p>

<ul>
  <li><code>https://&lt;sa&gt;.web.core.windows.net</code>, directly from the storage account</li>
  <li><code>https://&lt;cdn&gt;.azureedge.net</code>, from the CDN endpoint</li>
</ul>

<p>To be noted that to upload our content to the <code>$web</code> container of the storage account, the best option is to use the <a href="https://docs.microsoft.com/en-us/cli/azure/install-azure-cli">Azure CLI</a> or <a href="https://azure.microsoft.com/en-us/features/storage-explorer/">Azure Storage Explorer</a>. I tend to default on PowerShell but here <code>Set-AzStorageBlobContent</code> doesn’t manage the content-types of the files it uploads.</p>

<p>The syntax in the CLI is straightforward (in a PowerShell host, cmd or bash terminal) :</p>

<pre><code># Here the parameter syntax is PowerShell and I'm already logged in the CLI via az login
$contentLocalPath = "C:\..."
$storageAccountName = "mystorageaccount"
az storage blob upload-batch -s $contentLocalPath -d '$web' --account-name $storageAccountName
</code></pre>

<h2 id="step-3--adding-a-dns-zone">Step 3 : Adding a DNS Zone</h2>

<p>To add the DNS Zone, let’s switch to the <strong>part 3</strong> of this <a href="https://the.aamodt.family/rune/2020/01/08/tutorial-azure-website.html#step-3-set-up-dns-configuration">exhaustive guide</a> from Rune Aamodt.</p>

<p>Here we will <strong>not only</strong> create a record for the <strong>www subdomain</strong> (type <code>CNAME</code>, alias record set to the CDN endpoint) like in the guide, but also for the <strong>root (apex) domain</strong> (type <code>A</code>, alias record set to the same CDN endpoint).</p>

<p>This is how it should look now (<strong>bold</strong> being the ones we created above):</p>

<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>TTL</th>
      <th>Value</th>
      <th>Alias resource type</th>
      <th>Alias target</th>
      <th>Comment</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>@</strong></td>
      <td><strong>A</strong></td>
      <td>3600</td>
      <td>-</td>
      <td>Azure CDN</td>
      <td>eiden-ca</td>
      <td><strong>Root/apex domain record</strong></td>
    </tr>
    <tr>
      <td>@</td>
      <td>NS</td>
      <td>172800</td>
      <td>ns1-07.azure-dns.com…</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>Azure stuff</td>
    </tr>
    <tr>
      <td>@</td>
      <td>SOA</td>
      <td>3600</td>
      <td>Email:… Host: ns1-07.azure-dns.com…</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>Azure stuff</td>
    </tr>
    <tr>
      <td>@</td>
      <td>MX</td>
      <td>3600</td>
      <td>10 spool.mail.gandi.net.,50 fb.mail.gandi.net.</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>Gandi stuff, for the email addresses of the domain</td>
    </tr>
    <tr>
      <td>@</td>
      <td>TXT</td>
      <td>3600</td>
      <td>“v=spf1 include:_mailcust.gandi…</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>Gandi stuff, for the email addresses of the domain</td>
    </tr>
    <tr>
      <td>cdnverify</td>
      <td>CNAME</td>
      <td>3600</td>
      <td>cdnverify.eiden-ca.azure…</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>Verification record created automatically for alias record sets</td>
    </tr>
    <tr>
      <td>sa</td>
      <td>CNAME</td>
      <td>3600</td>
      <td>external.simpleanalytics.com.</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>Record required by the analytics provider I use here</td>
    </tr>
    <tr>
      <td><strong>www</strong></td>
      <td><strong>CNAME</strong></td>
      <td>3600</td>
      <td>-</td>
      <td>Azure CDN</td>
      <td>eiden-ca</td>
      <td><strong>www subdomain record</strong></td>
    </tr>
    <tr>
      <td>cdnverify.www</td>
      <td>CNAME</td>
      <td>3600</td>
      <td>cdnverify.eiden-ca.azure…</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>Verification record created automatically for alias record sets</td>
    </tr>
  </tbody>
</table>

<p>This is where we will have to log in to the admin portal of our Domain Registrar (Gandi for me) to switch our custom domain to use <strong>external nameservers</strong>. We will provide the 4 Azure ones listed in our DNS zone.</p>

<p>This can be a frustrating step since making changes to DNS records can take hours to take effect. Let’s try and be patient…</p>

<p>On <strong>Gandi</strong> it looks like this:</p>

<p><img src="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step3_gandi.jpg" alt="Step 3 : Screenshot of the admin portal in Gandi"></p>

<p><em><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step3_gandi.jpg">figure 3 : updating nameservers in Gandi</a></em></p>

<p>Now that we have the DNS Zone setup, the situation looks like that:</p>

<p><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step3.png"><img src="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step3.png" alt="Step 3 : A DNS Zone is added to the picture, but the CDN profile still needs to be updated"></a></p>

<p><em><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step3.png">figure 4 : A DNS Zone is added to the picture, but the CDN profile still needs to be updated</a></em></p>

<p>Now let’s head back to the CDN endpoint to add the custom domains we just created here.</p>

<h2 id="step-4--enabling-https-for-the-cdn-endpoint-custom-domains">Step 4 : Enabling HTTPS for the CDN Endpoint Custom Domains</h2>

<p>We will head back to the first tutorial, but <strong>before let’s quickly sum up the situation</strong>. As I mentioned in the summary, Azure CDN offers managed certificate for HTTPS, but at the time of writing they are not available for the root / apex domain.</p>

<p>This is why we need to bring our own certificate.</p>

<p>Before heading back into the tutorial, let’s review the 3 high level steps of that process:</p>

<ol>
  <li>In an Azure Key Vault, we will create a new certificate that will be issued by a <strong>non-integrated</strong> CA (Namecheap). <strong>Contrary</strong> to what’s in the guide, use <strong>PKCS#12</strong> (even if we don’t understand the details, it’s just easier)</li>
  <li>We will then download the CSR (<code>Certificate Signing Request</code>) from Azure Key Vault, upload it to our SSL certificate provider to get processed, get the PKCS#12 file generated there back into Azure Key Vault (<code>merge signed request</code>)</li>
  <li>Back in the CDN Endpoint, we will create the custom domains (root and www), with HTTPS, using our own certificate hosted in Key Vault</li>
</ol>

<p>So let’s head back to <a href="https://www.wrightfully.com/azure-static-website-custom-domain-https">the tutorial</a> from John for <strong>part 4 and 5</strong> (sorry there’s no direct links) that explains everything in details.</p>

<h2 id="step-5--adding-cdn-rules">Step 5 : Adding CDN rules</h2>

<p>Finally, we need to add some rules in the CDN Rules engine to sort traffic coming from the root and subdomain on both HTTP and HTTPS. I wanted everything to end on <code>https://www.eiden.ca</code>, but you can adapt the rules below for a different result:</p>

<ul>
  <li>Rule 1 : <code>http://</code> requests need to be redirect to <code>https://www...</code></li>
  <li>Rule 2 : root requests need to be redirected to <code>https://www...</code></li>
</ul>

<p>For that we can get inspiration from the <a href="https://the.aamodt.family/rune/2020/01/08/tutorial-azure-website.html#step-5-enforce-https">step 5</a> of the second guide to get something looking like that:</p>

<p><img src="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step5_rules.jpg" alt="Step 5 : Screenshot of the CDN endpoint rules engine configuration, details below"></p>

<p><em><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step5_rules.jpg">figure 5 : Rules to manage traffic across domains and protocols</a></em></p>

<p>The details of these rules:</p>

<ul>
  <li>Rule 1
    <ul>
      <li>Name : <strong>http2https</strong></li>
      <li>If Request <strong>protocol</strong>
        <ul>
          <li>Operator : <code>Equals</code></li>
          <li>Request URL : <code>HTTP</code></li>
        </ul>
      </li>
      <li>Then URL redirect
        <ul>
          <li>Type : <code>Moved (301)</code></li>
          <li>Protocol : <code>HTTPS</code></li>
          <li>Hostname : <code>www.eiden.ca</code></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Rule 2
    <ul>
      <li>Name : <strong>root2www</strong></li>
      <li>If Request <strong>URL</strong>
        <ul>
          <li>Operator : <code>Begins with</code></li>
          <li>Request URL : <code>https://eiden.ca</code></li>
          <li>Case transform : <code>To lowercase</code></li>
        </ul>
      </li>
      <li>Then URL redirect
        <ul>
          <li>Type : <code>Moved (301)</code></li>
          <li>Protocol : <code>HTTPS</code></li>
          <li>Hostname : <code>www.eiden.ca</code></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>The picture is now complete:</p>

<p><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/overall_schema.png"><img src="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/overall_schema.png" alt="Schema of the solution, everything has been explained above"></a></p>

<p><em><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/overall_schema.png">figure 6 : The whole thing wired up together</a></em></p>

<h2 id="step-6--flushing-the-cdn-profile">Step 6 : Flushing the CDN profile</h2>

<p>As discussed earlier, the CDN caches our files to serve them in an optimal fashion. Like any cache, it will need to be expired and reloaded when new content is uploaded to the storage account. This is not done automatically.</p>

<p>In the Azure CDN world, this operation is called a <strong>purge</strong>. It can be done in <a href="https://docs.microsoft.com/en-us/azure/cdn/cdn-purge-endpoint">the Azure portal</a> or via script.</p>

<p>In my case I’m using the <a href="https://docs.microsoft.com/en-us/powershell/azure/new-azureps-module-az?view=azps-4.7.0">PowerShell Az module</a> (not to be mistaken with the AzureRM module) to do that every time I publish a new article:</p>

<pre><code># Already logged via Connect-AzAccount

$cdnProfileName = "eiden-ca"

Get-AzCdnProfile `
  | Where-Object {$_.Name -eq $cdnProfileName} `
  | Get-AzCdnEndpoint `
  | Unpublish-AzCdnEndpointContent -PurgeContent "/*"

</code></pre>

<h2 id="closing">Closing</h2>

<p>So really, $2.5 per month?</p>

<ul>
  <li><a href="https://www.namecheap.com/security/ssl-certificates/comodo/positivessl/">Namecheap</a> SSL Certificate : $9 per year</li>
  <li><a href="https://www.gandi.net/en-CA">Gandi</a> custom domain (<code>.ca</code>) : $15 per year</li>
  <li>Everything <a href="https://azure.microsoft.com/en-us/free/">Azure</a> : $.5 per month</li>
</ul>

<p><strong>Total : $2.5 per month!</strong></p>

      </article></div>]]>
            </description>
            <link>https://www.eiden.ca/azure-static-blog/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24654536</guid>
            <pubDate>Thu, 01 Oct 2020 18:34:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to build an open source business]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24654427">thread link</a>) | @mattgreg
<br/>
October 1, 2020 | https://www.ockam.io/learn/blog/zero_ipo/ | <a href="https://web.archive.org/web/*/https://www.ockam.io/learn/blog/zero_ipo/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p font-family="body" font-weight="body" font-size="body" color="text">Ockam’s Zero-to-IPO map is a key strategy input to our tactical short, medium and long-term business planning. It focuses on the one-thing that <em>really</em> matters, at specific points in time. We live our values at Ockam, and as an open source company, we want to share our roadmap.</p><p font-family="body" font-weight="body" font-size="body" color="text">As outlined in the progression below, we’ve plotted a course from stoking awareness to operating an enterprise sales machine.</p><p font-family="body" font-weight="body" font-size="body" color="text"><span>
      <a href="https://www.ockam.io/static/6a42376b8825dbf0d0fb048487413853/dbe83/map.png">
    <span></span>
  </a><a href="https://www.ockam.io/static/6a42376b8825dbf0d0fb048487413853/e3189/map.png" rel="noopener noreferrer" target="_blank"><img src="https://www.ockam.io/static/6a42376b8825dbf0d0fb048487413853/e3189/map.png" alt="Zero to IPO map" title="Zero to IPO map" srcset="https://www.ockam.io/static/6a42376b8825dbf0d0fb048487413853/a2ead/map.png 259w,https://www.ockam.io/static/6a42376b8825dbf0d0fb048487413853/6b9fd/map.png 518w,https://www.ockam.io/static/6a42376b8825dbf0d0fb048487413853/e3189/map.png 1035w,https://www.ockam.io/static/6a42376b8825dbf0d0fb048487413853/44d59/map.png 1553w,https://www.ockam.io/static/6a42376b8825dbf0d0fb048487413853/a6d66/map.png 2070w,https://www.ockam.io/static/6a42376b8825dbf0d0fb048487413853/dbe83/map.png 3652w" sizes="(max-width: 1035px) 100vw, 1035px" loading="lazy"></a>
  
    </span></p><p font-family="body" font-weight="body" font-size="body" color="text">The time scale for our route to IPO is, as you’d expect, years long. Given that startups plan around funding cycles, let’s plot funding cycles as waypoints on our course. It can generally be assumed that there is 18-24 months between these waypoints.</p><p font-family="body" font-weight="body" font-size="body" color="text"><span>
      <a href="https://www.ockam.io/static/f9b1d634d67c6a0cf8c599df614453fa/4eef4/funding.png">
    <span></span>
  </a><a href="https://www.ockam.io/static/f9b1d634d67c6a0cf8c599df614453fa/e3189/funding.png" rel="noopener noreferrer" target="_blank"><img src="https://www.ockam.io/static/f9b1d634d67c6a0cf8c599df614453fa/e3189/funding.png" alt="Funding time scale" title="Funding time scale" srcset="https://www.ockam.io/static/f9b1d634d67c6a0cf8c599df614453fa/a2ead/funding.png 259w,https://www.ockam.io/static/f9b1d634d67c6a0cf8c599df614453fa/6b9fd/funding.png 518w,https://www.ockam.io/static/f9b1d634d67c6a0cf8c599df614453fa/e3189/funding.png 1035w,https://www.ockam.io/static/f9b1d634d67c6a0cf8c599df614453fa/44d59/funding.png 1553w,https://www.ockam.io/static/f9b1d634d67c6a0cf8c599df614453fa/a6d66/funding.png 2070w,https://www.ockam.io/static/f9b1d634d67c6a0cf8c599df614453fa/4eef4/funding.png 3660w" sizes="(max-width: 1035px) 100vw, 1035px" loading="lazy"></a>
  
    </span></p><p font-family="body" font-weight="body" font-size="body" color="text">The cloud, edge, and open source landscape continues to evolve - which means that we need to chart our own course into the future. However, Ockam’s route to IPO also considers the various ways that other companies have run the gauntlet from Zero-to-IPO. I’ve been fortunate to have been ‘in the rooms where it happened’. Over the past 10 years I’ve directly worked with well over 100 companies that were underpinned by open source software projects. I’ve seen spectacular successes, breathtaking failures, modest acquisitions, and some companies that simply fade into the darkness. I'll save those stories for another time, maybe over a beer.</p><p font-family="body" font-weight="body" font-size="body" color="text">In the image below are experiences that I’ve drawn from the previous decade in the open source, cloud, and developer tool space.</p><p font-family="body" font-weight="body" font-size="body" color="text"><span>
      <a href="https://www.ockam.io/static/61433a9b6094d6dc270ffe138701bb4c/8ddda/rooms.png">
    <span></span>
  </a><a href="https://www.ockam.io/static/61433a9b6094d6dc270ffe138701bb4c/e3189/rooms.png" rel="noopener noreferrer" target="_blank"><img src="https://www.ockam.io/static/61433a9b6094d6dc270ffe138701bb4c/e3189/rooms.png" alt="Rooms where it happened" title="Rooms where it happened" srcset="https://www.ockam.io/static/61433a9b6094d6dc270ffe138701bb4c/a2ead/rooms.png 259w,https://www.ockam.io/static/61433a9b6094d6dc270ffe138701bb4c/6b9fd/rooms.png 518w,https://www.ockam.io/static/61433a9b6094d6dc270ffe138701bb4c/e3189/rooms.png 1035w,https://www.ockam.io/static/61433a9b6094d6dc270ffe138701bb4c/44d59/rooms.png 1553w,https://www.ockam.io/static/61433a9b6094d6dc270ffe138701bb4c/a6d66/rooms.png 2070w,https://www.ockam.io/static/61433a9b6094d6dc270ffe138701bb4c/8ddda/rooms.png 3724w" sizes="(max-width: 1035px) 100vw, 1035px" loading="lazy"></a>
  
    </span></p><p font-family="body" font-weight="body" font-size="body" color="text">Let’s dive into each stage, in turn, to unpack what we are doing, when we are doing it, and how we are going to measure it.</p><h2 id="motion" color="heading" font-family="heading" font-weight="heading">Motion<a href="#motion"></a></h2><p font-family="body" font-weight="body" font-size="body" color="text">In order to recruit our team, or for a developer to consider using Ockam, first they have to know we exist. We create and distribute a tremendous amount of content at Ockam with one goal - driving developer awareness.</p><p font-family="body" font-weight="body" font-size="body" color="text">For example, The first product Ockam shipped was <a href="https://www.ockam.io/learn/guides/team/values_and_virtues_on_the_Ockam_Team/">a blog on our Values</a>. The second was a white paper that shared our vision. Even this post is an example!  We have a learning library that outlines our thesis on the open source ecosystem, teaches computer science fundamentals, gives insights into our team culture, and demonstrates our technology. We’ve sat down for dozens of podcasts and interviews over the past two years. Ockam’s content is based around teaching. Being an effective listener and a great teacher are core underpinnings when building an open source community.</p><h2 id="metrics" color="heading" font-family="heading" font-weight="heading">Metrics<a href="#metrics"></a></h2><p font-family="body" font-weight="body" font-size="body" color="text">To gauge awareness we track activity including page views on ockam.io, 'contact us' webform inquiries, GitHub stars, social media mentions, followers and, most importantly, applications to join our team.</p><h2 id="motion-1" color="heading" font-family="heading" font-weight="heading">Motion<a href="#motion-1"></a></h2><p font-family="body" font-weight="body" font-size="body" color="text">This is a critically important step in our progression to IPO. Building Ockam's community is a never-ending endeavor. It takes years of focus and unrelenting attention to get this step right. For example, Kafka spent it's first 5 years in this phase as an Apache project before Confluent was started.</p><p font-family="body" font-weight="body" font-size="body" color="text">We have three code interfaces to Ockam, which means that there are three different personas in our community:</p><p font-family="body" font-weight="body" font-size="body" color="text"><strong>Application layer developers</strong></p><p font-family="body" font-weight="body" font-size="body" color="text">Ockam’s users build systems and applications with our simple APIs, OckamD binary downloads, and hosted cloud services.</p><p font-family="body" font-weight="body" font-size="body" color="text">To simplify what’s going on at this stage, we create packages that any developer can grab in the middle of the night, on the other side of the world, and get a quick win for their demo day at work. You’ve got a job to be done, and we’ve got a simple solution for you. You can get it right now and we will measure your time to a technical-win in the scale of minutes.</p><p font-family="body" font-weight="body" font-size="body" color="text"><strong>Partners</strong></p><p font-family="body" font-weight="body" font-size="body" color="text">Community partners build add-ons, connectors, and plug-ins to connect Ockam to other codebases, cloud services and hardware components. Examples include InfluxData, Confluent - Kafka, Microchip, NXP, MacOS, and Microsoft Azure.</p><p font-family="body" font-weight="body" font-size="body" color="text"><strong>Open source developers</strong></p><p font-family="body" font-weight="body" font-size="body" color="text">Ockam’s open source builders are engaged in development of Ockam's core codebase. They attend our monthly community meetings, and are hands-on with our OSS codebase on GitHub. Their participation ranges from updating a typo in documentation, to building complex features.</p><h2 id="metrics-1" color="heading" font-family="heading" font-weight="heading">Metrics<a href="#metrics-1"></a></h2><p font-family="body" font-weight="body" font-size="body" color="text">We track Monthly Active Users across all three personas in our community:</p><p font-family="body" font-weight="body" font-size="body" color="text">Binary downloads, account signups, or SaaS service IOPS are all indicators of usage. As hinted above, time to ‘technical win’, for an individual developer is also paramount. We’ve defined time to ‘technical win’ as the time it takes to go from an individual developer’s initial discovery to a working prototype that includes Ockam features.</p><p font-family="body" font-weight="body" font-size="body" color="text">The easiest user growth to track is the number of partner integrations. Since partners engage with us 1:1 on an integration, we are highly selective and deliberate about the partnerships that we support. Eventually the development of our technical partnerships will become programmatic. Programmatic examples from my past include the partner program for Heroku Add-ons and the Azure Marketplace partner portal.</p><p font-family="body" font-weight="body" font-size="body" color="text">We also track the intersection of partnerships and usage. For example, the number of Ockam Daemons that run alongside Influx Telegraf, or the number of IOPS in Ockam Routers that securely move packets to a Kafka Connector.</p><p font-family="body" font-weight="body" font-size="body" color="text">Finally open source activity and engagement is transparent through the tools in GitHub. Check out <a href="https://github.com/ockam-network">how we are doing</a> with stars, forks and commits.</p><h2 id="motion-2" color="heading" font-family="heading" font-weight="heading">Motion<a href="#motion-2"></a></h2><p font-family="body" font-weight="body" font-size="body" color="text">This is a really fun stage for a product-and-pricing-nut like me. By this point in our journey we have users, but not customers. To satisfy investor expectations and to further fund product development, we start to feed our product development machine with revenue.</p><p font-family="body" font-weight="body" font-size="body" color="text">This stage is far simpler than it’s often made out to be. Here’s my basic formula;</p><ul><li>If you are an individual developer, then Ockam is free.</li><li>If you are a commercial enterprise, but have not yet had a ‘technical win’ with Ockam, then Ockam is free.</li><li>If you are a commercial enterprise, and have had a ‘technical win’ with Ockam, then you pay.</li></ul><p font-family="body" font-weight="body" font-size="body" color="text">From here things get a bit more complicated. Services need to be packaged and priced. This, in my opinion, is the most challenging, but also the most fun part of product development. The classic product marketing mix (aka the 4P’s) framework is durable and applies for Ockam’s planned product offerings. In this phase we are packaging <strong>P</strong>roducts (say S, M, L sizes), establishing a <strong>P</strong>rice for each product, <strong>P</strong>romoting the product through rigorous segmentation and targeting, and <strong>P</strong>lacing it into various channels and partner marketplaces for distribution.</p><p font-family="body" font-weight="body" font-size="body" color="text">Ockam’s SaaS products will have a freemium pricing and packaging structure. It’s worth calling out that freemium is not a pricing strategy. It’s a customer acquisition tactic that aligns with the formula above.</p><h2 id="metrics-2" color="heading" font-family="heading" font-weight="heading">Metrics<a href="#metrics-2"></a></h2><p font-family="body" font-weight="body" font-size="body" color="text">Monthly Recurring Revenue (MRR) is the top line / key metric during this phase.</p><p font-family="body" font-weight="body" font-size="body" color="text">The free-to-paid funnel is another key metric since it is a leading indicator and helps to forecast MRR. We will track both conversion and velocity of our freemium SaaS users.</p><p font-family="body" font-weight="body" font-size="body" color="text">The metrics we track in the Self-Serve SaaS phase allow us to A/B test in our demand generation funnel. A/B testing allows us to optimize month-over-month revenue growth.  The target is 10-15% MoM growth.</p><h2 id="motion-3" color="heading" font-family="heading" font-weight="heading">Motion<a href="#motion-3"></a></h2><p font-family="body" font-weight="body" font-size="body" color="text">Inside Sales is a channel strategy for specific types of large customers we already have. This is mainly a cultivate-and-grow tactic. Our bottoms-up, Self Serve SaaS product model feeds leads to our Inside Sales Team. This team is technical, includes sales engineers and provides world-class support.</p><p font-family="body" font-weight="body" font-size="body" color="text">There are two separate objectives during this phase.</p><ul><li>Increase MRR through an increase in our customer base, and in the average ticket size.</li><li>Learn about Customer Acquisition Costs (CAC) for specific segments, prior to launching the Enterprise Sales phase.</li></ul><p font-family="body" font-weight="body" font-size="body" color="text">Monthly recurring revenue is still our top priority during the Inside Sales phase.</p><p font-family="body" font-weight="body" font-size="body" color="text">What’s less obvious is the second objective. Understanding CAC prepares us for an all-in Enterprise Sales motion. Moving from here onto the Enterprise Sales waypoint is probably the most challenging. It’s fraught with peril. Many, many smart companies, with great products, and ‘developer love’ die right here.</p><p font-family="body" font-weight="body" font-size="body" color="text">How can that be? It’s because Inside Sales is bottoms-up and Enterprise Sales is tops-down. This means entirely new buyers, new product-marketing mix, and new internal talent. We must hold onto our developer roots, while we also learn to sell to the suits. While we are executing on Inside Sales we are doing the primary research that will help spawn a new company from our company.</p><p font-family="body" font-weight="body" font-size="body" color="text">This is fantastically difficult - mostly from a cultural standpoint. Fortunately there are a lot of people with a lot of scar tissue from the past 10 years - including myself - and we will push through. The key is patience. We need to use our inside sales motion to find specific beachheads to land our Enterprise Sales motion.</p><h2 id="metrics-3" color="heading" font-family="heading" font-weight="heading">Metrics<a href="#metrics-3"></a></h2><p font-family="body" font-weight="body" font-size="body" color="text">MRR carries over as our key metric from the Self Serve SaaS phase.</p><p font-family="body" font-weight="body" font-size="body" color="text">CAC analysis for multiple customer segments.</p><h2 id="anti-metrics" color="heading" font-family="heading" font-weight="heading">Anti-Metrics<a href="#anti-metrics"></a></h2><p font-family="body" font-weight="body" font-size="body" color="text">There will be noise in our Inside Sales data!</p><p font-family="body" font-weight="body" font-size="body" color="text">The noise is any sale that looks like it could be Enterprise Sales. Up to this point, non-recurring engineering (NRE) and enterprise-like sales don’t count as Enterprise Sales, as we define the term in the next section. Typically they are one-off deals because the motion to win these deals isn’t scalable. We will do large custom deals to gain access to smart teams that deploy interesting technology. I prefer to categorize this class of revenue as ‘business development’ or even R&amp;D.</p><p font-family="body" font-weight="body" font-size="body" color="text">Why is this an anti-metric? Because other Open Source startups typically stand up a couple one-off enterprises like sales as a way to puff themselves up and to convince themselves that they are ready to move to the next phase. I strongly caution my future self to parse the noise from the signal prior to launching Enterprise Sales.</p><p font-family="body" font-weight="body" font-size="body" color="text">Furthermore, there are other Open Source companies that entirely bypass the Self Serve SaaS phase in favor of the chunky revenue that comes with Enterprise Sales. Those companies tend not to be product companies. They become …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ockam.io/learn/blog/zero_ipo/">https://www.ockam.io/learn/blog/zero_ipo/</a></em></p>]]>
            </description>
            <link>https://www.ockam.io/learn/blog/zero_ipo/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24654427</guid>
            <pubDate>Thu, 01 Oct 2020 18:26:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Video encoded neck scarves of New York City neighborhoods]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24654352">thread link</a>) | @Sanksshep
<br/>
October 1, 2020 | https://thebrooklynblock.com/collections/all | <a href="https://web.archive.org/web/*/https://thebrooklynblock.com/collections/all">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

  
  

  

  <div>
    
      <ul>
        
          <li></li>
        
          <li></li>
        
          <li></li>
        
          <li></li>
        
          <li></li>
        
          <li></li>
        
          <li></li>
        
          <li></li>
        
          <li></li>
        
          <li></li>
        
          <li></li>
        
      </ul>
    

    
    <p role="contentinfo">Copyright © 
      2020
     The Brooklyn Block.</p>
  </div>

</div></div>]]>
            </description>
            <link>https://thebrooklynblock.com/collections/all</link>
            <guid isPermaLink="false">hacker-news-small-sites-24654352</guid>
            <pubDate>Thu, 01 Oct 2020 18:19:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Short-form podcasts are the future]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24654292">thread link</a>) | @dazzn
<br/>
October 1, 2020 | https://martinsthoughts.com/short-form-podcasts-are-the-future-just-not-mine/ | <a href="https://web.archive.org/web/*/https://martinsthoughts.com/short-form-podcasts-are-the-future-just-not-mine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://martinsthoughts.com/short-form-podcasts-are-the-future-just-not-mine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24654292</guid>
            <pubDate>Thu, 01 Oct 2020 18:15:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Biopharma Startup Funding Dashboard]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24654255">thread link</a>) | @aaavl2821
<br/>
October 1, 2020 | https://www.baybridgebio.com/startup_database.html | <a href="https://web.archive.org/web/*/https://www.baybridgebio.com/startup_database.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><header>
  <nav>
    

    
</nav></header>

 <section>
    <div>
      
      
      <p>This dashboard covers biopharma VC, IPO and M&amp;A trends.  Explore more of our data <a href="https://www.baybridgebio.com/biotech-screener.html">here</a>.</p>
      <br>
      <h2>Biopharma venture funding over time</h2>
        <p>
        <span id="startup-dashboard-loading"><h3>Loading...</h3></span></p>
      <br>
      <h2>2019 topline data</h2>
      <div>
          <div>
              <div>
                  <h3>VC funding, 2019</h3>
                  <p>
                      <h2>$<span id="vc-ytd">0.0</span>B</h2>
                  </p>
                  <p>Latest deal: <span id="vc-updated-date">March 2019</span></p>
              </div>
          </div>
          <div>
              <div>
                  <h3>IPO proceeds, 2019</h3>
                  <p>
                      <h2>$<span id="ipo-proceeds-ytd">0.0</span>B</h2>
                  </p>
                  <p>Latest deal: <span id="ipo-updated-date">March 2019</span></p>
              </div>
          </div>
          <div>
              <div>
                  <h3>M&amp;A total consideration, 2019</h3>
                  <p>
                      <h2>$<span id="ma-total-ytd">0.0</span>B</h2>
                  </p>
                  <p>Latest deal: <span id="ma-updated-date">March 2019</span></p>
              </div>
          </div>
      </div>
      <p>The database is updated several times per month.  We periodically publish deep dives on <a href="https://www.baybridgebio.com/blog/ipo_2018_q12019.html">startup valuation</a>, <a href="https://www.baybridgebio.com/blog/venture_returns_ipo.html">venture returns</a>, <a href="https://www.baybridgebio.com/blog/jan_2019_funding.html">funding trends</a> and more on our <a href="https://www.baybridgebio.com/blog.html">blog</a>.  Sign up for our newsletter to receive updates.</p>
      
      <div>
        <h2>2020 on pace to be biggest year ever for biopharma venture investing</h2>
        
      </div>
      <div>
        <h2>Venture round sizes increasing</h2>
        <div>
          <div>
            <p>Most Series A rounds are between $10-60M, but there is a long tail of "megarounds" of $100M or more.  Since 2018, Series A sizes have been increasing.  Thus far in 2020, 75% of Series A deals have been greater than $30M.</p>
            <p>Series B and C rounds have been increasing as well.  Series B and C megarounds of $100M or more are increasingly common.  31% of Series B rounds and 38% of Series C rounds in 2020 have been over $100M, compared to 10% for Series B and 26% for Series C in 2018.</p>
            <p>The average post-money valuation of Series A companies is $79M.  More info on venture-stage valuations <a href="https://www.baybridgebio.com/blog/ipo_2018_q12019.html">here</a>.</p>
          </div>
          
        </div>
        
        
      </div>
      <div>
          <div>
              <h3>Valuations of 250+ biopharma VC rounds</h3>
              <p>Access detailed financial profiles of 100+ biopharma startups that went public in 2018 through 1H 2020, including estimated private-round valuations.</p>
          </div>
          
      </div>
      <div>
        <h2>US-based biotech VCs and crossover investors dominate</h2>
        <div>
          <div>
            <p>US-based specialist biotech VCs dominate biotech venture, especially at the Series A stage.  Due to 2020's active IPO market, crossover investors (investors who participate in late-stage private rounds as well as IPOs) have become increasingly active.</p>
            <p>Generalist tech VCs have increased their investment levels to that of pharma corporate VCs, but they still make up a small amount of overall funding.</p>
            <p>In 2018, Chinese investors were the biggest leaders of Series B investments into US biopharma companies.  Due to recent trade tensions between the US and China, but in 2019 Chinese investors led nearly zero deals (although they did participate as non-lead investors).  More on that <a href="https://www.baybridgebio.com/blog/chinese_investment_down_1h2019.html">here</a>.</p>
          </div>
        </div>
        <div>
          <h3>Lead investors by type, all rounds</h3>
          
        </div>
        <div>
          <h3>Lead investors by type, Series A</h3>
          
        </div>
        <div>
          <h3>Lead investors by type, Series B</h3>
          
        </div>
        </div>
      <div>
        <h2>Few active lead investors</h2>
        <div>
          <div>
            <p>The most active VCs generally only lead a handful of deals per year.  Many of these Series A investors create many of the companies they fund in-house.</p>
            <p>These investors are generating outsized returns.  Series A investments in companies that IPO <b>return an average of 10.8x</b>, with on average 3.5 years from Series A to IPO.  More on returns <a href="https://www.baybridgebio.com/blog/venture_returns_ipo.html">here</a>.</p>
          </div>
        </div>
        <div>
          <h3>Most active lead investors, all stages</h3>
          
        </div>
        <div>
          <h3>Most active lead investors, Series A</h3>
          
        </div>
        <div>
          <h3>Most active lead investors, Series B</h3>
          
        </div>
      </div>
      <div>
        <h2>Oncology and rare disease declining, neuro and autoimmune rising</h2>
        <div>
          <div>
            <p>Oncology represents about a quarter of venture-funded programs from 2018-2019</p>
            <p>While rare disease has historically received the second-most funding after oncology, neuro + neurodegenerative programs now receive more Series A funding than rare disease</p>
            <p>These charts represent the therapeutic areas of all companies receiving funding.  Many companies have programs in multiple therapeutic areas</p>
          </div>
          
        </div>
        
        <div>
          <div>
            <p>Series A investment trends can inform what kinds of companies will get funded in future rounds</p>
            <p>Oncology makes up a lower percentage of Series A-funded programs than rare disease, autoimmune and neuro combined, though oncology is still the single most funded therapeutic area</p>
          </div>
          
        </div>
      </div>
      <div>
        <h2>2020 on pace to be record year for VC-backed biopharma IPOs</h2>
        <p>2020 is on pace to be a record year for VC-backed biopharma IPOs in terms of proceeds raised.</p>
        
        
      </div>
      <div>
        
        <p><a href="https://goo.gl/forms/kHRFwxfXidRVZsDf1">Sign up</a> for our newsletter for periodic updates and analyses on biopharma VC trends.</p>
        <p>Do you have questions about our data?  Are there other analyses you'd like to see?  <a href="https://baybridgebio-report.herokuapp.com/contact">Contact us</a>, or chat with us here if we're available (you'll see an icon on the bottom-right of the screen).</p>
        <p>Our database contains additional detailed data on startups, IPOs and M&amp;A activity.  Explore our database <a href="https://www.baybridgebio.com/biotech-screener.html">here</a>.</p>
      </div>
    </div>
  </section>
  
  <!--Start of Tawk.to Script-->
      
    <!--End of Tawk.to Script-->
    
    


</div>]]>
            </description>
            <link>https://www.baybridgebio.com/startup_database.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24654255</guid>
            <pubDate>Thu, 01 Oct 2020 18:11:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What is the difference between Docker and a Virtual Machine]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24654229">thread link</a>) | @championshuttle
<br/>
October 1, 2020 | https://itsopensource.com/what-is-the-difference-between-docker-and-a-virtual-machine/ | <a href="https://web.archive.org/web/*/https://itsopensource.com/what-is-the-difference-between-docker-and-a-virtual-machine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>While in principle they are very similar, it might be more common to know about Virtual Machines than Docker Containers. Virtual Machines are like Inception, but with computers; you’re running another computer inside your computer. A usual use-case for this setup that’s applicable even to people not working in tech, is for example, you have a Windows machine (your Host OS) and you want to somehow have Ubuntu (your Guest OS) just to test a software that only runs on Linux machines. You just want to quickly try it out, so you don’t want to go through the process of installing another OS in your system (dual booting).</p>
<p><span>
      <a href="https://itsopensource.com/static/44eafcd1b741ccc88a5bf2b7440aea18/f67cc/ubuntu-vm.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="Running an Ubuntu session using VirtualBox" title="Running an Ubuntu session using VirtualBox" src="https://itsopensource.com/static/44eafcd1b741ccc88a5bf2b7440aea18/88218/ubuntu-vm.jpg" srcset="https://itsopensource.com/static/44eafcd1b741ccc88a5bf2b7440aea18/7237a/ubuntu-vm.jpg 148w,
https://itsopensource.com/static/44eafcd1b741ccc88a5bf2b7440aea18/0cfdf/ubuntu-vm.jpg 295w,
https://itsopensource.com/static/44eafcd1b741ccc88a5bf2b7440aea18/88218/ubuntu-vm.jpg 590w,
https://itsopensource.com/static/44eafcd1b741ccc88a5bf2b7440aea18/f67cc/ubuntu-vm.jpg 800w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p>Now let’s discuss the underlying technology a bit. A virtual machine is a system which emulates a computer system. It has its own CPU, memory, hard disk, network and other hardware resources which are managed by a ‘virtualization layer’. This layer then translates these requests to the physical hardware (host computer).</p>
<p>If you have tried running a VM in your machine, you know how your machine started heating up. This whole process is resource-intensive, because hey, you’re practically running a full version of another machine! That’s definitely something you won’t do when you want to solve a bigger use-case that requires this setup.</p>
<p><span>
      <a href="https://itsopensource.com/static/a36cdb7beaa411e06c9fcb56decfd989/a8246/vm-architecture.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Virtual Machine Simple Architecture" title="Virtual Machine Simple Architecture" src="https://itsopensource.com/static/a36cdb7beaa411e06c9fcb56decfd989/a8246/vm-architecture.png" srcset="https://itsopensource.com/static/a36cdb7beaa411e06c9fcb56decfd989/00d96/vm-architecture.png 148w,
https://itsopensource.com/static/a36cdb7beaa411e06c9fcb56decfd989/0b23c/vm-architecture.png 295w,
https://itsopensource.com/static/a36cdb7beaa411e06c9fcb56decfd989/a8246/vm-architecture.png 400w" sizes="(max-width: 400px) 100vw, 400px" loading="lazy">
  </a>
    </span></p>
<p>What if my colleagues also want to try that software? Do they also have to install the same heavy thing on their system? What if their hardware can’t handle it?</p>
<p>That’s where Docker comes in. It’s like milk, but the leanest version with the least amount of fat that you can find (sort of).</p>
<p>With Docker, you can run applications on your host operating system (e.g. Windows), in what is called a Container. A container is almost similar to an operating system minus the graphical user interface (the stuff you can click). It technically functions just like running a session on a VM, but here’s the magic: unlike in a VM where you have to run a session of an entire OS to use an application, with Docker, you are able to run the application in light-weight containers AND control it from the host OS. The part where you see another OS running? The part where you turn on Ubuntu on your VM Manager that you installed on your Windows machine? That part has been scrapped, making the whole setup way lighter. Instead, you just write some commands on the command line and you go directly into running your application.</p>
<p><em>Whuuuut?</em></p>
<p>Let’s try to visualize that with this image, compared to our previous one.</p>
<p><span>
      <a href="https://itsopensource.com/static/8570b603ddc9ec9226dcfc0c3e0b0ceb/11d19/docker-vm.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Docker vs VM Visualized" title="Docker vs VM Visualized" src="https://itsopensource.com/static/8570b603ddc9ec9226dcfc0c3e0b0ceb/799d3/docker-vm.png" srcset="https://itsopensource.com/static/8570b603ddc9ec9226dcfc0c3e0b0ceb/00d96/docker-vm.png 148w,
https://itsopensource.com/static/8570b603ddc9ec9226dcfc0c3e0b0ceb/0b23c/docker-vm.png 295w,
https://itsopensource.com/static/8570b603ddc9ec9226dcfc0c3e0b0ceb/799d3/docker-vm.png 590w,
https://itsopensource.com/static/8570b603ddc9ec9226dcfc0c3e0b0ceb/11d19/docker-vm.png 800w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p>The game-changing advantage of Docker is that it allows you to package any software with all of its dependencies into a single standardized unit called image.</p>
<p>Virtual machines run on a host OS and make guest OS available inside each VM, each OS needs to be booted individually. On the other hand, Docker containers are hosted on a single docker engine on a host OS. All the containers share the docker instance. Sharing the engine between containers makes them light and decreases the boot time. While Docker Containers boot in a few seconds, VMs take a few minutes to boot. </p>
<p><span>
      <a href="https://itsopensource.com/static/632533cd83014f756c2c557efb650694/7217d/docker-architecture.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Docker Architecture" title="Docker Architecture" src="https://itsopensource.com/static/632533cd83014f756c2c557efb650694/7217d/docker-architecture.png" srcset="https://itsopensource.com/static/632533cd83014f756c2c557efb650694/00d96/docker-architecture.png 148w,
https://itsopensource.com/static/632533cd83014f756c2c557efb650694/0b23c/docker-architecture.png 295w,
https://itsopensource.com/static/632533cd83014f756c2c557efb650694/7217d/docker-architecture.png 500w" sizes="(max-width: 500px) 100vw, 500px" loading="lazy">
  </a>
    </span></p>
<p>Now that we have that background, let’s take a look at some real examples of how these can be applied:</p>
<p><strong>Virtual machine</strong></p>
<p>You have a Windows machine and want to try out GIMP on Ubuntu. Here’s how the process will look like:</p>
<ol>
<li>Install an Ubuntu VM on a Windows machine</li>
<li>Go inside the VM window and operate Ubuntu</li>
<li>Install GIMP there and use it.</li>
</ol>
<p>The host OS (Windows) is totally unaware of what is being done inside VM (Ubuntu).</p>
<p><strong>Docker</strong></p>
<p>You use Wordpress.com and discovered that there is an open source version of it that you can run yourself, so you want to test it out on your own computer first. Now, setting up a Wordpress site has dependencies, that is, your system needs to have Apache, MySQL database and PHP installed.</p>
<p>Using Docker, here’s how the process will look like.</p>
<ol>
<li>Create a container using a <a href="https://hub.docker.com/_/wordpress">Wordpress image</a>. We’re able to jump directly to this step because the Wordpress image has already been packaged by the Docker community. It contains all the dependencies needed to run Wordpress.</li>
<li>Run Wordpress on your browser!</li>
</ol>
<p>In a nutshell, Docker containers support OS virtualization, and VM supports hardware virtualization.</p></section></div>]]>
            </description>
            <link>https://itsopensource.com/what-is-the-difference-between-docker-and-a-virtual-machine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24654229</guid>
            <pubDate>Thu, 01 Oct 2020 18:09:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Startup Lessons I Needed to Learn First Hand (But Maybe You Don’t)]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24654192">thread link</a>) | @jlrubin
<br/>
October 1, 2020 | http://www.nancyhua.com/2020/10/01/startup-lessons-i-needed-to-learn-first-hand-but-maybe-you-dont/ | <a href="https://web.archive.org/web/*/http://www.nancyhua.com/2020/10/01/startup-lessons-i-needed-to-learn-first-hand-but-maybe-you-dont/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://www.nancyhua.com/2020/10/01/startup-lessons-i-needed-to-learn-first-hand-but-maybe-you-dont/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24654192</guid>
            <pubDate>Thu, 01 Oct 2020 18:06:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Programmers need to think like hackers]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 15 (<a href="https://news.ycombinator.com/item?id=24654136">thread link</a>) | @gexos
<br/>
October 1, 2020 | https://gexos.org/2020/10/01/Programmers-need-to-think-like-hackers!/ | <a href="https://web.archive.org/web/*/https://gexos.org/2020/10/01/Programmers-need-to-think-like-hackers!/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://gexos.org/2020/10/01/Programmers-need-to-think-like-hackers!/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24654136</guid>
            <pubDate>Thu, 01 Oct 2020 18:01:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Spaced Repetition, Anki and Execute Program]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24654071">thread link</a>) | @williamsmj
<br/>
October 1, 2020 | https://mike.place/2020/executeprogram/ | <a href="https://web.archive.org/web/*/https://mike.place/2020/executeprogram/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
            
            
            <p><span>2020-09-02</span></p><p>Here’s the tl;dr</p>
<ul>
<li>memorizing stuff is good</li>
<li>spaced repetition is a good way to memorize things</li>
<li><a href="https://www.executeprogram.com/">Execute Program</a> is a subscription
learning site that uses spaced repetition</li>
<li>Execute Program has good lessons (especially on regular expressions and
concurrency)</li>
<li>Ergo Execute Program is good</li>
<li>Also <a href="https://ankiweb.net/">Anki</a> is good</li>
</ul>
<p>QED.</p>
<h2 id="memorizing-stuff-is-useful">Memorizing stuff is useful</h2>
<p>It seems almost self-evident to me that this <a href="https://overcast.fm/+R7DUeyopY/2:03:38">John Siracusa
quote</a>
(<a href="https://twitter.com/garybernhardt/status/1287883217450614784">via</a>) is true:</p>
<blockquote>
<p>It’s good to reach the level of competence where you can write [programs] from
top to bottom and never have to look anything up.</p>
</blockquote>
<p>There are two steps to reaching this enlightened state. The first is learning
the facts in the first place. The second is <em>remembering</em> them. That second step
is crucial because, by storing this stuff in your head, rather than offloading
it to search engines and man pages, you make the connection between your brain
and the computer higher bandwidth. Programming then becomes more more fun in the
same way a conversation between two people who are fluent in the same language
is often more fun.</p>
<h2 id="spaced-repetition">Spaced repetition</h2>
<p>Most of us stop making time for memorization when we stop taking exams. That’s
probably because it’s insanely boring and time-consuming. But that is less true
if you use spaced repetition, a family of algorithms for memorizing things
efficiently.</p>
<p>Spaced repitition works like this: on day 0, you’re shown a question or prompt
and asked to recall the response. You’re shown it again on day 1. And then again
on (for example) day 3, day 8, day 20, etc. These growing intervals are chosen
such that, just when you’re on the verge of forgetting something, you’re asked
to dredge it up from the back of your mind. If you can’t do that then you go
back to the beginning of the sequence of intervals for that prompt. The growing
intervals mean that you’re using your time efficiently while minimizing (not
eliminating!) the boringness.</p>
<p>It’s a simple and very natural idea so it’s a little surprising just how well it
works. I used spaced repetition to learn German. I haven’t used German for
nearly ten years. I have a terrible memory. I <em>still</em> remember not only the
words, but the <em>layout</em> of specific flashcards I used to learn pretty obscure
bits of vocabulary.</p>
<h2 id="anki">Anki</h2>
<p>Natural language learning is probably the most common use case for spaced
repetition, but <a href="https://sive.rs/srs">lots</a> of
<a href="https://sasha.wtf/anki-post-1/">people</a> use it to memorize bits of things they
learn while programming. Anything that I have to look up more than a couple of
times goes in my list of prompts and responses. Some examples from my “deck” of
prompts and responses:</p>
<ul>
<li>
<p>curl switch to follow redirects (short and long versions)<br>
<code>-L --location</code></p>
</li>
<li>
<p>Makefile alias for current target<br>
<code>$@</code></p>
</li>
<li>
<p>Find and replace string <code>foo</code> in a bash <code>$variable</code><br>
<code>${variable//foo/bar}</code></p>
</li>
<li>
<p><a href="https://xkcd.com/1168/">Tar a directory</a><br>
<code>tar cf file.tar directory/</code></p>
</li>
</ul>
<p>I only add things I have to look up. I don’t add things my editor helps me with,
such as the calling signatures of functions. I might benefit from doing that,
but that’s where I draw the line.</p>
<p>To manage my “deck” of prompts and responses, and to review them at
appropriately spaced intervals I use <a href="https://apps.ankiweb.net/">Anki</a>.</p>
<p>Anki is a charmingly crusty bit of open-source cross-platform software. It uses
<a href="https://faqs.ankiweb.net/what-spaced-repetition-algorithm.html">its own spaced repetition
algorithm</a>. It’s
ugly. It’s confusing. The mobile versions are $25! But it’s extremely popular,
very flexible, and better than <a href="https://getpolarized.io/2020/02/03/anki-ripped-off.html">the scummy
rip-off</a>.</p>
<p>You can and should assemble your own deck. But that’s a lot of work (more work
than the remembering). So, if you want to give it a try first, download a small
public deck <a href="https://ankiweb.net/shared/decks/">from the shared library</a>. I
started with the <a href="https://ankiweb.net/shared/info/959976866">US state capitals</a>.</p>
<h2 id="execute-program-and-spaced-repetition">Execute Program and spaced repetition</h2>
<p><a href="https://www.executeprogram.com/">Execute Program</a> is a subscription learning
site by <a href="https://www.destroyallsoftware.com/">Gary Bernhardt</a>. You work your way
through courses on Javascript, TypeScript, SQL and Regex and then you get
pestered by a spaced repetition algorithm to review, i.e. regurgitate what you
learned by completing tiny programs.</p>
<p>Each course takes perhaps 20 minutes/day for a couple of weeks (you have to wait
for the reviews so you can’t do the whole course in a day). Once the lessons are
over, the reviews take about ten minutes/day at first, but that approaches zero
as the spaces between the repetitions grow.</p>
<p><img src="https://mike.place/post/executeprogram/executeprogram.png" alt="Execute Program"></p>
<p>The Execute Program review UI</p>
<p>The spaced repetition is a little crude relative to Anki. For example, I miss
being able to <a href="https://docs.ankiweb.net/#/background?id=spaced-repetition">say if something was easy or
hard</a>. After you get
something right for the fourth time, on day 64, even it doesn’t feel like it’s
stuck, you’re congratulated and told you’re never going to see it again. And
related reviews all come on the same day, which makes them artificially easy.</p>
<p>But you can’t argue with results. I can say with a straight face that I “know”
this stuff after spending four months as a subscriber, and doing the reviews.
So, very highly recommended!</p>
<h2 id="execute-programs-courses">Execute Program’s courses</h2>
<p>In what sense do you “know” these subjects after completing the Execute Program
course? Firstly, you have the syntax at your fingertips thanks to spaced
repetition. For example, I’m not an experienced TypeScript programmer. But I
know the syntax well, and that makes occasionally writing crappy little
TypeScript programs at work much less frustrating. Secondly, the courses
themselves are incredibly well done. They’re not a parade of facts. I
<em>understand</em> stuff I didn’t understand before I used the site.</p>
<p>I joined planning to learn concurrency but I ended up doing all of the other
courses: regular expressions, JavaScript arrays, Modern JavaScript, TypeScript,
and SQL.</p>
<p>They’re all really good! My only complaint (and the reason I’ve let my
subscription lapse) is that they’re not longer and there aren’t more of them.
The <a href="https://www.executeprogram.com/faq">FAQ</a> explains the teaching philosophy
better than I can, so I won’t repeat it here. But I will make some comments on
my two favorite courses.</p>
<h3 id="regular-expressions">Regular Expressions</h3>
<p>This topic is the perfect fit for spaced repetition because there is no way
around the fact that you just gotta learn a bunch of facts (the same goes for
the course on JavaScript Arrays). The course stops before named groups and
lookback/ahead, so I had to learn that stuff myself (from <a href="https://learning.oreilly.com/library/view/learning-regular-expressions/9780134757056/">the second half of
this perfect, short
book</a>).
But if you want to learn 90% of what you need to read and write regular
expressions in the absolute shortest amount of time, conditional on being able
to remember any of it, this course is the way to go.</p>
<h3 id="concurrency">Concurrency</h3>
<p>Concurrency is <em>not</em> the perfect fit for spaced repetition. It’s subtle. There
are often many different solutions to a problem. And the review “answers” tend
to be quite long in terms of number of characters. Nevertheless, this course is
probably my favorite.</p>
<p>I have been banging my head against a brick wall with concurrency for years. It
clicked for me this year in great part because of this course. (Shout out to
this talk about <a href="https://www.youtube.com/watch?v=8aGhZQkoFbQ&amp;feature=youtu.be">the JS event
loop</a> and some
Python async content too, especially <a href="https://www.youtube.com/watch?v=Xbl7XjFYsN4&amp;list=PLhNSoGM2ik6SIkVGXWBwerucXjgP1rHmB">Łukasz Langa’s
videos</a>
and <a href="https://realpython.com/async-io-python/">Brad Solomon’s Real Python
article</a>.)</p>
<p>Why is this course so good? Because it doesn’t start from the assumption that
you know or care what <a href="http://callbackhell.com/">callback hell</a> is, or even that
you’re a particularly experienced JavaScript programmer (I’m not). Assuming you
know and hate JavaScript is a widespread antipattern in JavaScript writing: “you
think this sucks” is the starting point. Well, I didn’t! But now you’re making
me nervous (and confused because you’re teaching me about a bunch of stuff that
I apparently should not do?!) In other words, <a href="https://mkremins.github.io/blog/doors-headaches-intellectual-need/">as Max Kreminski
says</a>:</p>
<blockquote>
<p>One of the worst things you can do is force people who don’t feel pain to take
your aspirin.</p>
</blockquote>
<p>The Execute Program Concurrency course just gets straight to the point:
timeouts, promises. I hope they add async/await.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Execute Program is good. It’s fun. The lessons are extremely thoughtfully put
together. I hope they add more!</p>
<p>And every time you have to search for something for the third time, add it to
an Anki deck.</p>

        </div>

        
    </div></div>]]>
            </description>
            <link>https://mike.place/2020/executeprogram/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24654071</guid>
            <pubDate>Thu, 01 Oct 2020 17:55:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a Faster CouchDB View Server in Rust]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24653369">thread link</a>) | @bryanrasmussen
<br/>
October 1, 2020 | https://www.garrensmith.com/blogs/fortuna-rs-couchdb-view-server | <a href="https://web.archive.org/web/*/https://www.garrensmith.com/blogs/fortuna-rs-couchdb-view-server">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.garrensmith.com/blogs/fortuna-rs-couchdb-view-server</link>
            <guid isPermaLink="false">hacker-news-small-sites-24653369</guid>
            <pubDate>Thu, 01 Oct 2020 17:01:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hub-and-Spoke vs. Point-to-Point Data Synchronization: There's One Clear Winner]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24653337">thread link</a>) | @knes
<br/>
October 1, 2020 | https://blog.getcensus.com/hub-and-spoke-vs-point-to-point-data-synchronization-theres-one-clear-winner/ | <a href="https://web.archive.org/web/*/https://blog.getcensus.com/hub-and-spoke-vs-point-to-point-data-synchronization-theres-one-clear-winner/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <section>
                <div>
                    <div><p>Consistent, accurate data is the foundation of your operational success as a business. For your marketing to make sense, you need a clear (and accurate) picture of your buyer personas. For your sales team to be successful, they need up-to-date records of which companies you’ve already spoken with, who is interested in what services, and who the point of contact is for each lead.</p><p>So how do you ensure that your data is accurate and accessible to everyone who needs it? You choose the best data synchronization architecture. In this article, we’re going to show you why the hub-and-spoke method will prevail over point-to-point data synchronization every time, with a five-round fight. </p><p>But first, let’s review what each method looks like. Point-to-point integration is an architectural system in which each individual point (in this case, app or software) is connected to every other point it needs to share information with.</p></div><figure><img src="https://blog.getcensus.com/content/images/2020/09/Hub-and-spoke-diagram-archicture-v2--1-.png" alt="" srcset="https://blog.getcensus.com/content/images/size/w600/2020/09/Hub-and-spoke-diagram-archicture-v2--1-.png 600w, https://blog.getcensus.com/content/images/size/w1000/2020/09/Hub-and-spoke-diagram-archicture-v2--1-.png 1000w, https://blog.getcensus.com/content/images/size/w1600/2020/09/Hub-and-spoke-diagram-archicture-v2--1-.png 1600w, https://blog.getcensus.com/content/images/2020/09/Hub-and-spoke-diagram-archicture-v2--1-.png 2300w" sizes="(min-width: 720px) 720px"><figcaption>Point to Point and Hub &amp; Spoke Infrastructures</figcaption></figure><p>The hub-and-spoke system, on the other hand, is laid out so that one central hub connects to all of the spokes. Now, let’s dive into how our two contenders match up:</p><h2 id="round-1-which-scales-more-easily">Round 1: Which Scales More Easily?</h2><div><p>Point-to-point data synchronization is messy, which makes scaling a serious challenge. When you add a new app to your business, you may initially need to connect it to only one other app. But as your business grows and your teams get larger, you’ll eventually want to connect your tech stack so that each team has access to as much information as possible, so they are empowered to make the best decisions for your business’s success.</p><p>But the point-to-point method requires exponentially more connections (or integrations) to achieve a fully connected data and tech stack. In fact, the number of connections grows by the square of the number of apps. So, if you have eight apps, you may need as many as 64 connections to achieve full data synchronicity—and a fully scalable business.</p><p>As <a href="https://www.christiernan.com/why-point-to-point-integrations-are-evil/">Chris Tiernan</a>, senior director of software engineering for IT business applications at Splunk, wrote:</p></div><blockquote>“Many organizations have learned the hard way, an infrastructure based on P2P integration quickly becomes unmanageable, brittle, and damaging to both the IT budget and the organization’s ability to meet current and changing business needs.”</blockquote><p>The hub-and-spoke system, on the other hand, requires only one connection (to the hub) for each app. So no matter how many apps your business needs as you grow, your integration and setup time won’t go through the roof. &nbsp;If we use the same example of a business with eight apps, the maximum number of connections required for a fully synchronized data and tech stack is only eight. That’s 56 fewer integrations to set up and maintain. </p><h2 id="round-2-which-synchronizes-more-accurately">Round 2: Which Synchronizes More Accurately?</h2><div><p>When it comes to data consistency, point-to-point synchronization falls short again. Disparate apps within a point-to-point system often wind up with conflicting data because there is no one central point, or hub, that determines which information is the most up-to-date or accurate. Once this happens, it’s a nightmare to figure out which data set is correct.</p><p>Data quality is a huge concern for businesses of all sizes. You don't want your teams making strategic decisions or developing business processes based on bad information. If Salesforce, for instance, shows 160 active clients but Marketo only shows 130, your marketing team could be tailoring ad campaigns based on a misrepresented user base. If your data transfer between Salesforce and SalesLoft is broken, you may wind up with two sales reps who waste time reaching out to the same company. Or, worse yet, one of your sales reps could cold call an existing client and unintentionally put that account at risk.</p><p>Point-to-point data synchronization also makes you more vulnerable to data stomping—where information submitted by one app is overwritten and completely deleted by another unintentionally. Say, for instance, you have two employees working on the same account. Each employee adds notes to your client’s file at the same time, one in your CRM tool and one in your sales engagement tool. If you’re using a point-to-point integration to share information across this software, you risk losing part or all of that data as the two apps struggle to sort out which information is the most current. One set of data may completely overwrite the other, or you may wind up with an unintelligible jumble of both sets of notes. And if you don’t catch that error right away, valuable client notes may be lost forever.</p><p>Luckily, our second contender solves this problem. It’s a lot easier to ensure data consistency across your company with the hub-and-spoke model since all apps have the same source of truth—your data warehouse or hub. </p><p>Think of the hub as the brain of your operation and the spokes as your five senses. If you smell smoke at the same time you see someone grilling burgers, your brain will know which information should supersede the other and determine that there is no immediate risk.</p></div><h2 id="round-3-which-is-easier-to-maintain">Round 3: Which Is Easier to Maintain?</h2><p>Spoiler alert: point-to-point is going to lose this round, too. The more API integrations you have, the harder your system is to maintain. In <a href="http://tray.io/">Tray.io</a>’s guide, <a href="https://tray.io/blog/what-is-an-api-integration-for-non-technical-people">What are APIs and API Integrations</a>, they explain that:</p><blockquote>“trying to get your data to sync up [using API integrations] usually requires error-prone manual work, jury-rigged workarounds, or filing a ticket for IT support.”</blockquote><p>The image below is an actual diagram of GitLab’s point-to-point data infrastructure in 2020.<br></p><figure><img src="https://blog.getcensus.com/content/images/2020/09/gitlab_data_infrastructure.png" alt="gitlab data infrastructure" srcset="https://blog.getcensus.com/content/images/size/w600/2020/09/gitlab_data_infrastructure.png 600w, https://blog.getcensus.com/content/images/size/w1000/2020/09/gitlab_data_infrastructure.png 1000w, https://blog.getcensus.com/content/images/2020/09/gitlab_data_infrastructure.png 1510w" sizes="(min-width: 720px) 720px"><figcaption>Gitlab Data Infrastructure (<a href="https://twitter.com/dwr/status/1260432470262059008">source</a>)</figcaption></figure><div><p>A web with this many lines, or API integrations and webhooks, requires <em>a lot</em> of maintenance. Whenever one of those apps or programs is updated, you run the risk of the connecting API integrations failing. So, for GitLab, based on this diagram, a Marketo update could mean eight different integrations will need to be fixed. If Salesforce updates, 26 integrations may need recoding or fixing.</p><p>Hub-and-spoke is—you guessed it—easier to maintain because each application your team requires only needs to be integrated with your hub instead of every other app in your tech stack. If one of those apps is updated to a new version, you don’t need to worry about recoding five or more connections to ensure it keeps syncing with all of your other apps. The same thing is true if you want to add a new app.</p><p>Hub-and-spoke also makes it easier to clean up or transform data and have those adjustments reflected everywhere that data appears. Say, for instance, that you want to add a customer persona to your target audience divisions. You only need to do this once for it to be reflected across your entire tech stack (in your marketing, sales, and other apps) rather than adding it to each app individually and then having to check the integrations to make sure all of your coding is compatible.</p></div><h2 id="round-4-which-is-more-secure"><strong>Round 4: Which Is More Secure?</strong></h2><div><p>The point-to-point model poses a serious security risk, whether you’re using it for data synchronization or even network architecting. Doug Guth, managing architect at <a href="https://corebts.com/">Core BTS</a>, explained that “when you go to a point to point [system]... security is next to impossible. Your visibility of who’s accessing what and where and how, what’s flowing where and how... it’s difficult at best, if not impossible to do.”</p><p>When it comes to data synchronization specifically, point-to-point systems require numerous API user accounts. And as <a href="https://www.christiernan.com/why-point-to-point-integrations-are-evil/">Tiernan</a> wrote</p></div><blockquote>“In general security terms, the more API user accounts available, the more exposure to risk the company has for security breaches.” </blockquote><div><p>In addition, if you’re synchronizing information with third-party vendors from app to app using various APIs, it’s very hard to protect confidentiality and maintain compliance. You can't create clear and consistent access control lists if your data is spread across 30 different apps. </p><p>Hub-and-spoke, on the other hand, provides a sort of vault, in the form of your hub, that allows you to protect and limit what information is shared, with which apps or vendors, and how that information is shared. Using the hub-and-spoke model, you can define permissions based on data and people, rather than apps, which ensures more reliable and trustworthy data.</p><p>Hub-and-spoke data synchronization seriously limits your exposure to data breaches. <a href="https://www.ellucian.com/insights/hubs-spokes-and-point-point-quick-guide-common-integration-terminology#:~:text=hub%2Dand%2Dspoke%20integration&amp;text=Point%2Dto%2Dpoint%20integration%20uses,data%2Dsharing%20between%20two%20systems.&amp;text=Hub%2Dand%2Dspoke%20integration%2C,to%20any%20other%20sharing%20system">Ben Morley</a>, director of product management at Ellucian, wrote, “The bottom line is that it’s [hub and spoke] a more secure approach because you're reducing the number of factors of attack.” </p></div><h2 id="round-5-which-is-more-affordable"><strong>Round 5: Which Is More Affordable?</strong></h2><div><p>Those of you rooting for the underdog, here’s where point-to-point throws a punch: on an individual project level, point-to-point data synchronization can be cheaper, which is why you’ll still find it in use. </p><p>But zoom out and you’ll quickly see that the total operational cost of managing a point-to-point infrastructure can quickly become cost-prohibitive, even for small businesses with only a few apps. Gartner Research recently <a href="https://www.gartner.com/en/documents/3986583/cost-optimization-is-crucial-for-modern-data-management-">published a report</a> on modern data management where they referred to point-to-point integrations as “haphazard reactive measures” that cause costs to “escalate uncontrollably.”</p><p>It’s a common misconception that hub-and-spoke data synchronization comes with a large upfront cost. Historically, there was truth to this belief, but this is no longer the case thanks to data warehouses like <a href="https://www.snowflake.com/">Snowflake</a> and <a href="https://cloud.google.com/bigquery">BigQuery</a> with flexible pricing structures. BigQuery’s <a href="https://cloud.google.com/bigquery#section-10">pay-as-you-go</a> subscription is just $5 per TB per month. Once you’ve got your <a href="https://blog.getcensus.com/graduating-to-the-modern-data-stack-for-startups/">data storage set up</a>, you can use synchronization tools such as <a href="https://fivetran.com/">Fivetran</a> and <a href="https://getcensus.com/">Census</a> to easily move information to and from all of your apps. And each of these software offers a free trial.</p></div><h2 id="the-modern-tech-stack-champion">The Modern Tech Stack Champion</h2><figure><img src="https://blog.getcensus.com/content/images/2020/09/point-to-point-vs-hub---spoke-competition-table-1.png" alt="" srcset="https://blog.getcensus.com/content/images/size/w600/2020/09/point-to-point-vs-hub---spoke-competition-table-1.png 600w, https://blog.getcensus.com/content/images/size/w1000/2020/09/point-to-point-vs-hub---spoke-competition-table-1.png 1000w, https://blog.getcensus.com/content/images/2020/09/point-to-point-vs-hub---spoke-competition-table-1.png 1040w" sizes="(min-width: 720px) 720px"><figcaption>Hub &amp; Spoke vs Point to Point Summary</figcaption></figure><p>The hub-and-spoke model is the clear champion of data synchronization. And we designed Census to make this winning system easily accessible for businesses of all sizes. Forget …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.getcensus.com/hub-and-spoke-vs-point-to-point-data-synchronization-theres-one-clear-winner/">https://blog.getcensus.com/hub-and-spoke-vs-point-to-point-data-synchronization-theres-one-clear-winner/</a></em></p>]]>
            </description>
            <link>https://blog.getcensus.com/hub-and-spoke-vs-point-to-point-data-synchronization-theres-one-clear-winner/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24653337</guid>
            <pubDate>Thu, 01 Oct 2020 16:59:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quick Tips to Build Your Blog from Scratch]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24653236">thread link</a>) | @gergelyke
<br/>
October 1, 2020 | https://nemethgergely.com/blog/building-your-blog-from-scratch | <a href="https://web.archive.org/web/*/https://nemethgergely.com/blog/building-your-blog-from-scratch">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-baseweb="block"><p data-baseweb="block">Modern web development came a long way. The blog that you are currently reading was built in about ten days, with not more than an hour spent on it on those days. Because of all the open-source libraries available, the site is fast and accessible, with little extra work required on my end.</p><p data-baseweb="block">This article contains a few quick tips that will help you build your blog from scratch, should you choose to go down on that path.</p><h2 data-baseweb="block" id="why-building-a-blog-from-scratch-in-2020">Why building a blog from scratch in 2020? <a href="#why-building-a-blog-from-scratch-in-2020"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2><p data-baseweb="block">First, let's address the elephant in the room! Why would anyone build their blog from scratch in 2020, when we have services like <a data-baseweb="link" rel="noopener" href="https://ghost.org/" target="_blank">Ghost</a> or <a data-baseweb="link" rel="noopener" href="https://wordpress.com/" target="_blank">Wordpress</a>?</p><p data-baseweb="block">Previously, I used a blog engine called <a data-baseweb="link" rel="noopener" href="https://hexo.io/" target="_blank">Hexo</a>. While it worked well for a few years, it became increasingly hard to maintain and update. It doesn't have a vibrant plugin ecosystem, so quite a few times, I ended up monkey-patching it's build pipeline to include support for web workers or webp images formats. So maintaining the old blog was not an option anymore.</p><p data-baseweb="block">Secondly, I wanted to have a small side project to learn and experiment with new technologies and language features. As I wrote in the article <a data-baseweb="link" href="https://nemethgergely.com/blog/coding-as-an-engineering-manager">Coding as an Engineering Manager</a>, as a manager, I usually work on bug fixes when it comes to coding. This website allows working on a project end-to-end and keeps my technical chops up-to-date.</p><p data-baseweb="block">Be aware, working on your blog can also result in endless procrastination <em>(let me quickly fix that one LAST thing)</em>. I have been there done that.</p><h2 data-baseweb="block" id="1-use-nextjs-with-a-component-library">1. Use Next.js With a Component Library <a href="#1-use-nextjs-with-a-component-library"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2><p data-baseweb="block"><a data-baseweb="link" rel="noopener" href="https://nextjs.org/" target="_blank">Next.js</a> is a web framework built for React. The reasons I picked it for my blog:</p><ul><li data-baseweb="block"><strong>Zero configuration</strong>: it comes batteries-included, so you don't have to deal with Webpack configurations if you don't want to.</li><li data-baseweb="block"><strong>Static site generation</strong>: there is barely anything dynamic on my blog, so I wanted to pick a tool that supports static site generation.</li><li data-baseweb="block"><strong>Code splitting</strong>: by using <a data-baseweb="link" rel="noopener" href="https://nextjs.org/docs/advanced-features/dynamic-import" target="_blank">dynamic imports</a>, one can reduce the main JavaScript's bundle size dramatically to improve page load times.</li></ul><p data-baseweb="block">I picked <a data-baseweb="link" rel="noopener" href="https://baseweb.design/" target="_blank">Base Web</a> as the component library for this site. While it doesn't matter which component library you choose from a stylistic point of view, do pay attention to the following technical details:</p><ul><li data-baseweb="block"><strong>Built-in accessibility</strong> to ensure that you don't have to invest a vast amount of time making your website accessible. The component library should do the heavy-lifting here.</li><li data-baseweb="block"><strong>Reasonable CSS/JS footprint</strong>, so your website loads quickly on slower networks too.</li><li data-baseweb="block"><strong>Extensibility/theme-ability</strong>, so you can easily create your visual language.</li></ul><h2 data-baseweb="block" id="2-leverage-the-mdx-file-format">2. Leverage the MDX File Format <a href="#2-leverage-the-mdx-file-format"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2><p data-baseweb="block">Once you start using Next.js or any React frameworks, I highly recommend starting using <a data-baseweb="link" rel="noopener" href="https://mdxjs.com/" target="_blank">MDX</a>. MDX is a format that lets you write JSX in your Markdown documents. So in practice, you can keep wiring markdown-based blog posts that Next.js/Gatsby can easily pick up.</p><p data-baseweb="block">Read more on it <a data-baseweb="link" rel="noopener" href="https://mdxjs.com/" target="_blank">here</a>.</p><h2 data-baseweb="block" id="3-reduce-the-amount-of-javascript-your-site-needs">3. Reduce the Amount of JavaScript Your Site Needs <a href="#3-reduce-the-amount-of-javascript-your-site-needs"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2><p data-baseweb="block">It may be tempting to utilize external libraries for things like share buttons that enable your readers to post content to Twitter, Facebook or LinkedIn. <strong>It doesn't just add a lot of external dependencies to your site and slows it down, but it also adds additional trackers to your site.</strong></p><p data-baseweb="block">Instead, you can rely on share URLs that most social networks provide:</p><ul><li data-baseweb="block">For LinkedIn, you can use <code>https://www.linkedin.com/shareArticle?url=</code>.</li><li data-baseweb="block">For Twitter, you can use <code>https://twitter.com/intent/tweet/?url=</code>.</li><li data-baseweb="block">For Facebook, you can use <code>https://www.facebook.com/sharer/sharer.php?u=</code>.</li></ul><p data-baseweb="block">Similarly, you can integrate most newsletter services, like Mailchimp, without any additional JavaScript dependencies. For example, check out the Mailchimp integration at the bottom of this page.</p><h2 data-baseweb="block" id="4-leverage-cloudflare-workers-for-redirects">4. Leverage Cloudflare Workers for Redirects <a href="#4-leverage-cloudflare-workers-for-redirects"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2><p data-baseweb="block">Originally, the blog posts I wrote lived under the root of the domain, without name namespace, like: <code>https://nemethgergely.com/coding-as-an-engineering-manager</code>. While initially it worked well, it became problematic as the number of blog posts increased.</p><p data-baseweb="block">Because of that, I've decided to move all blog posts under the namespace <code>/blog/</code>. So the previously mentioned article would be accessible from <code>https://nemethgergely.com/blog/coding-as-an-engineering-manager</code>. To ensure that I don't break any previous links to the site, I wanted to create redirects to the new locations.</p><p data-baseweb="block">This is where Cloudflare Workers become super handy - they provide extreme flexibility and are simple to write. This is the script that I use today to create the redirects:</p><div><div data-baseweb="block"><div><pre dir="ltr"><p><span>const</span><span> base </span><span>=</span><span> </span><span>"https://nemethgergely.com"</span><span></span></p><p><span></span><span>const</span><span> statusCode </span><span>=</span><span> </span><span>301</span><span>;</span><span></span></p><p><span></span><span>const</span><span> routes </span><span>=</span><span> </span><span>[</span><span></span></p><p><span>  </span><span>"engineering-productivity"</span><span>,</span><span></span></p><p><span>  </span><span>...</span><span></span></p><p><span></span><span>]</span><span>;</span><span></span></p><p><span></span><span>addEventListener</span><span>(</span><span>'fetch'</span><span>,</span><span> </span><span>event</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>  event</span><span>.</span><span>respondWith</span><span>(</span><span>handleRequest</span><span>(</span><span>event</span><span>.</span><span>request</span><span>)</span><span>)</span><span></span></p><p><span></span><span>}</span><span>)</span><span></span></p><p><span></span><span>async</span><span> </span><span>function</span><span> </span><span>handleRequest</span><span>(</span><span>request</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>const</span><span> url </span><span>=</span><span> </span><span>new</span><span> </span><span>URL</span><span>(</span><span>request</span><span>.</span><span>url</span><span>)</span><span></span></p><p><span>  </span><span>let</span><span> </span><span>{</span><span> pathname </span><span>}</span><span> </span><span>=</span><span> url</span></p><p><span>  </span><span>if</span><span> </span><span>(</span><span>routes</span><span>.</span><span>includes</span><span>(</span><span>pathname</span><span>)</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>    </span><span>return</span><span> Response</span><span>.</span><span>redirect</span><span>(</span><span>`</span><span>${</span><span>base</span><span>}</span><span>/blog/</span><span>${</span><span>pathname</span><span>}</span><span>`</span><span>,</span><span> statusCode</span><span>)</span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span>  </span><span>return</span><span> </span><span>fetch</span><span>(</span><span>request</span><span>)</span><span></span></p><p><span></span><span>}</span></p></pre></div></div></div><p data-baseweb="block">Twitter, Facebook or LinkedIn display an image in users' feed when you share one of your articles. These images are coming from <a data-baseweb="link" rel="noopener" href="https://ogp.me/" target="_blank">OpenGraph tags</a>, and you can set almost any image <em>(with some requirements)</em> to be displayed. However, creating these images whenever you write a new article can be taxing at times.</p><p data-baseweb="block">Because of this, and to ensure that these images are consistent, I implemented the following automation:</p><ol><li data-baseweb="block">Created a simple HTML page used as a template, screenshot below.</li><li data-baseweb="block">A small script goes through all the blog posts I have, replaces the <code>undefined</code> title in HTML, and creates screenshots.</li><li data-baseweb="block">Profit!</li></ol><p data-baseweb="block"><picture><source srcset="https://nemethgergely.com/webp/social-card-html-template.webp" type="image/webp"><source srcset="https://nemethgergely.com/social-card-html-template.png" type="image/png"><img src="https://nemethgergely.com/social-card-html-template.png" alt="social card html template"></picture></p><h2 data-baseweb="block" id="6-have-some-test-coverage">6. Have Some Test Coverage <a href="#6-have-some-test-coverage"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2><p data-baseweb="block">When I started building this blog, I broke it a few times (mostly the layout or links). That's when I realized that I should add some basic sanity tests. As of today, I have two checks:</p><ul><li data-baseweb="block">a <strong>broken link checker</strong>, built on top of <a data-baseweb="link" rel="noopener" href="https://pptr.dev/" target="_blank">puppeteer</a>,</li><li data-baseweb="block"><strong>screenshots</strong>, where a CI job takes a few screenshots of some of the pages, and display them as artifacts on Circle CI <em>(built on puppeteer too)</em></li></ul><h2 data-baseweb="block" id="takeaways">Takeaways <a href="#takeaways"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2><p data-baseweb="block">It always fun for me to build something. If you decide to create your blog too, keep these in mind:</p><ul><li data-baseweb="block">Procrastination is real. Focus on writing blog posts instead of always finding something you can improve on the technical side.</li><li data-baseweb="block">At the same time, try to automate as many of the repeated tasks of blog post writing, as possible, like social card generation or basic test coverage for sanity checks.</li></ul><div data-baseweb="block"><p data-baseweb="typo-paragraphsmall">October 1, 2020</p><div data-baseweb="block"><form action="https://nemethgergely.us2.list-manage.com/subscribe/post?u=f87b0ce29bc7e4718c40739f4&amp;id=ac4c709a2b" method="post" name="mc-embedded-subscribe-form" target="_blank" novalidate=""><p>Did you like this article? Subscribe to get notified about new ones on engineering management, open-source and the web!</p><label data-baseweb="form-control-label" for="email-address">Your email address</label></form></div></div></div></div>]]>
            </description>
            <link>https://nemethgergely.com/blog/building-your-blog-from-scratch</link>
            <guid isPermaLink="false">hacker-news-small-sites-24653236</guid>
            <pubDate>Thu, 01 Oct 2020 16:52:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AWS Is Not Your Ideal]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24653013">thread link</a>) | @amortize
<br/>
October 1, 2020 | https://sujithjay.com/not-aws | <a href="https://web.archive.org/web/*/https://sujithjay.com/not-aws">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
  
  <p><span> 01 Oct 2020  • <span>
  
    
    
    <a href="https://sujithjay.com/tag/product"><code><nobr>PRODUCT</nobr></code>&nbsp;</a>
  
    
    
    <a href="https://sujithjay.com/tag/management"><code><nobr>MANAGEMENT</nobr></code>&nbsp;</a>
  
</span></span></p><p>Let me start with an assertion. Every platform engineering team <sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> in every organisation aspires to be like AWS <sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>.</p>

<p>Every platform team wants to be like AWS, because like AWS, they provide infrastructure abstractions to users. AWS provides infrastructure via the abstractions of VMs and disks and write-capacity-units, while platform teams provide infrastructure using higher abstractions which solve service definitions, database or message queue provisioning, and service right-sizing <sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup>.</p>

<p>This similarity prompts leaders of platform engineering teams to model their teams as agnostic providers of universal, non-leaky (within SLO bounds), self-served abstractions for their engineering organisation. Platform teams structured as such detached units struggle to define cohesive roadmaps which provide increasing value to business. But how does your platform differ from AWS?</p>

<h2 id="your-platform-vs-the-platform">Your Platform vs. The Platform</h2>

<h3 id="1-the-middle-ground">1. The Middle Ground</h3>
<p>As an agnostic service provider, AWS can afford to cater to median use-cases. The reason platform engineering teams exist is to bridge the gap between PaaS abstractions which work for the median use-case to your business’ specific use-cases. AWS can afford to target the median (economy of scale etc.), but you cannot.</p>

<p><img src="https://sujithjay.com/public/notaws/Median.jpeg" alt="AWS can afford to stay within a single σ. You cannot."></p>
<p><span> AWS can afford to stay within a single σ. You cannot.</span>
</p>

<p>Agnostic platform engineering teams which emulate AWS try to get away from this responsibility by proposing abstractions which target the median use-case. A tell-tale sign of this is when the lack in wide usability of internal abstractions is compensated for by extensive onboarding &amp; repeated training. This is also a side-effect of the relative valuation of engineering time vs. the time of another function <sup id="fnref:4" role="doc-noteref"><a href="#fn:4">4</a></sup>.</p>

<h3 id="2-follow-the-money">2. Follow the Money</h3>
<p>The dictum ‘follow the money’ works beautifully for customer-front products. When faced with a choice between two competing features to prioritise, a common tactical play is to make something which leads to more (immediate &amp; long-term) revenue. The proxy for increased revenue could be increased acquisition conversion, better retention or improved user experience – metrics which ensure increased revenue for the company over time. In short, revenue growth is the north star <sup id="fnref:5" role="doc-noteref"><a href="#fn:5">5</a></sup>.</p>

<p>Not so much in platform engineering. There is no revenue since your customers are internal, captive ones. Captive audiences are forced to use a solution by the force of dictum and lack of choice. The metrics used in platform products are proxies for usability and user satisfaction – but there are no foolproof ways to measure it for captive audiences. For captive audiences, solutions can not compete and better solutions cannot win. Like a command economy, platform products are designed rather than evolved. Design takes priority over market economy. So why is design bad?</p>

<h2 id="bad-design">Bad Design</h2>
<p>For design to work, there has to be an objective function against which we can design. A specification is an objective function against which engineering teams design a solution. Since we do not have reliable metrics <sup id="fnref:6" role="doc-noteref"><a href="#fn:6">6</a></sup> to rely on for platform engineering, how do we come up with specifications? And without rigorous specifications, new features created by the platform run a high risk of not solving worthwhile problems for the users.The current accepted methodology among platform engineering leaders to solve this paucity of specifications is to rely on user-interviews. This is, as mentioned before, an unreliable source since captive users do not have the best view of the ideal state of tooling and abstractions that could be available to them.</p>

<p>The only way to flip this situation is to let go of command-economy-style designed abstractions, and to let your platform self-organise along the principle of markets. How does that look in practice?</p>

<h3 id="1-market-ftw">1. Market, FTW</h3>
<p>Camille Fournier mentions in <a href="https://medium.com/@skamille/product-for-internal-platforms-9205c3a08142">Product for Internal Platforms</a> how her team partners with customer teams to develop prototypes for specific problems. These specific solutions are later honed and iterated on to become general solutions provided by your team. I would go a step further on this route, where possible. Partner to prototype with multiple teams facing related problems to develop multiple specific solutions. These specific solutions can be seen as competing candidates to solve a general problem. Bring in user-interviews at this point to gauge pain-points, and iterate individually on these specific solutions. This switches the economy of your team to a self-organised market. Once considerable thought and iteration has gone into each solution, it is time to assimilate. Assimilate the best solution(s) while migrating the rest to the chosen solution. As emphasised in <a href="https://medium.com/@skamille/product-for-internal-platforms-9205c3a08142">Product for Internal Platforms</a>, an early investment of time into migration strategies is essential for such a scheme to sustain.</p>

<p>In platforms designed with experimentation, you will find that innovation continues to thrive at the edges of the platform’s domain while the stable core of the platform is subject to periodic rework or maintenance. The use-cases a platform supports grows in a controlled manner to address an ever-growing percent of the consumers, and does not stagnate after addressing just the median users.</p>

<h3 id="2-overloaded-use-cases">2. Overloaded Use-cases</h3>
<p>Although agnostic platform engineering teams might only be catering to very specific median use-cases, the customer teams with specific needs cannot afford to be blocked and they cannot stop delivering their deliverables. These teams sometimes create their own solutions, and in such cases the above strategy of assimilation works wonders. You get a prototype for free on which the team can iterate on. However, this scenario is rarer in cases where it requires specific skills to build such solutions, such as in data platforms. One common pattern in such knowledge-constricted situations is that users find ways to overload the existing solutions with minor tweaks to fit their use-case. Look out for such overloaded use-cases within your platform, for they are excellent guides to unmet needs of the users. You can leverage them to advocate for newer features to explicitly support those use-cases.</p>

<h3 id="3-listen-to-them-only-at-the-start">3. Listen To Them (Only At The Start!)</h3>
<p>As a parting note, I will take a jab at user-interviews again. The above tactics work when you are trying to scale your platform from 1 to N. When taking a platform from 0 to 1, the only solution to creating specifications is to listen to the users. Give them exactly what they want. Listen to their exact demands. A propensity of platform product managers is to rely on this excessively at a much later stage in the product’s lifecycle. User-interviews have their place in evolving products, but the over-reliance on the methodology is a bane to platform product management.</p>

<p><strong>P.S.</strong> As I read back the above essay, the heavy influence of <a href="https://medium.com/@skamille/product-for-internal-platforms-9205c3a08142">Product for Internal Platforms</a> is clear. I would like to say that was the intention: to reassert the ideas in it which resounded with me, while stating a few of my own.</p>

<h3 id="footnotes">Footnotes</h3>


  </div>









      </div></div>]]>
            </description>
            <link>https://sujithjay.com/not-aws</link>
            <guid isPermaLink="false">hacker-news-small-sites-24653013</guid>
            <pubDate>Thu, 01 Oct 2020 16:37:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Classic Paper: Go to Statement Considered Harmful]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24652958">thread link</a>) | @chsasank
<br/>
October 1, 2020 | https://chsasank.github.io/classic_papers/goto-statement-considered-harmful.html | <a href="https://web.archive.org/web/*/https://chsasank.github.io/classic_papers/goto-statement-considered-harmful.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

  

  <p><span>Edsger W. Dijkstra</span> |
    <time datetime="01 October 2020">01 October 2020</time>
  </p>

  <section>
    <blockquote>
  <p><strong>NOTE</strong>: This is <em>not</em> my article. This is a classic paper originally published in <em>Communications of the ACM</em>, 1968 by Edsger W. Dijkstra  and a mirror of <a href="https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.92.4846&amp;rep=rep1&amp;type=pdf">another mirror</a>. Blue highlights/annotations are my own.</p>
</blockquote>

<p>Editor,</p>

<p>For a number of years I have been familiar with the observation that the quality of programmers is a decreasing function of the density of <code>go to</code> statements in the programs they produce. More recently I discovered why the use of the <code>go to</code> statement has such disastrous effects, and I became convinced that the <code>go to</code> statement should be abolished from all “higher level” programming languages (i.e. everything except, perhaps, plain machine code). At that time I did not attach too much importance to this discovery; I now submit my considerations for publication because in very recent discussions in which the subject turned up, I have been urged to do so.</p>

<p>My first remark is that, although the programmer’s activity ends when he has constructed a correct program, the process taking place under control of his program is the true subject matter of his activity, for it is this process that has to accomplish the desired effect; it is this process that in its dynamic behavior has to satisfy the desired specifications. Yet, once the program has been made, the ‘making’ of the corresponding process is delegated to the machine.</p>

<p>My second remark is that our intellectual powers are rather geared to master static relations and that our powers to visualize processes evolving in time are relatively poorly developed. For that reason we should do (as wise programmers aware of our limitations) our utmost to shorten the conceptual gap between the static program and the dynamic process, to make the correspondence between the program (spread out in text space) and the process (spread out in time) as trivial as possible.</p>

<blockquote>
  <p>Our intellectual powers are rather geared to master static relations and that our powers to visualize processes evolving in time are relatively poorly developed.</p>
</blockquote>

<p>Let us now consider how we can characterize the progress of a process. (You may think about this question in a very concrete manner: suppose that a process, considered as a time succession of actions, is stopped after an arbitrary action, what data do we have to fix in order that we can redo the process until the very same point?) If the program text is a pure concatenation of, say, assignment statements (for the purpose of this discussion regarded as the descriptions of single actions) it is sufficient to point in the program text to a point between two successive action descriptions. (In the absence of <code>go to</code> statements I can permit myself the syntactic ambiguity in the last three words of the previous sentence: if we parse them as “successive (action descriptions)” we mean successive in text space; if we parse as “(successive action) descriptions” we mean successive in time.) Let us call such a pointer to a suitable place in the text a “textual index.”</p>

<p>When we include conditional clauses (<code>if B then A</code>), alternative clauses (<code>if B then A1 else A2</code>), choice clauses as introduced by C. A. R. Hoare (case[i] of (A1, A2,···, An)),or conditional expressions as introduced by J. McCarthy (B1 -&gt; E1, B2 -&gt; E2, ···, Bn -&gt; En), the fact remains that the progress of the process remains characterized by a single textual index.</p>

<p>As soon as we include in our language procedures we must admit that a single textual index is no longer sufficient. In the case that a textual index points to the interior of a procedure body the dynamic progress is only characterized when we also give to which call of the procedure we refer. With the inclusion of procedures we can characterize the progress of the process via a sequence of textual indices, the length of this sequence being equal to the dynamic depth of procedure calling.</p>

<p>Let us now consider repetition clauses (like, <code>while B repeat A</code> or <code>repeat A until B</code>). Logically speaking, such clauses are now superfluous, because we can express repetition with the aid of recursive procedures. For reasons of realism I don’t wish to exclude them: on the one hand, repetition clauses can be implemented quite comfortably with present day finite equipment; on the other hand, the reasoning pattern known as “induction” makes us well equipped to retain our intellectual grasp on the processes generated by repetition clauses. With the inclusion of the repetition clauses textual indices are no longer sufficient to describe the dynamic progress of the process. With each entry into a repetition clause, however, we can associate a so-called “dynamic index,” inexorably counting the ordinal number of the corresponding current repetition. As repetition clauses (just as procedure calls) may be applied nestedly, we find that now the progress of the process can always be uniquely characterized by a (mixed) sequence of textual and/or dynamic indices.</p>

<blockquote>
  <p>The reasoning pattern known as “induction” makes us well equipped to retain our intellectual grasp on the processes generated by repetition clauses.</p>
</blockquote>

<p>The main point is that the values of these indices are outside programmer’s control; they are generated (either by the write-up of his program or by the dynamic evolution of the process) whether he wishes or not. They provide independent coordinates in which to describe the progress of the process.</p>

<p>Why do we need such independent coordinates? The reason is - and this seems to be inherent to sequential processes - that we can interpret the value of a variable only with respect to the progress of the process. If we wish to count the number, <em>n</em> say, of people in an initially empty room, we can achieve this by increasing n by one whenever we see someone entering the room. In the in-between moment that we have observed someone entering the room but have not yet performed the subsequent increase of n, its value equals the number of people in the room minus one!</p>

<p>The unbridled use of the <code>go to</code> statement has an immediate consequence that it becomes terribly hard to find a meaningful set of coordinates in which to describe the process progress. Usually, people take into account as well the values of some well chosen variables, but this is out of the question because it is relative to the progress that the meaning of these values is to be understood! With the <code>go to</code> statement one can, of course, still describe the progress uniquely by a counter counting the number of actions performed since program start (viz. a kind of normalized clock). The difficulty is that such a coordinate, although unique, is utterly unhelpful. In such a coordinate system it becomes an extremely complicated affair to define all those points of progress where, say, <em>n</em> equals the number of persons in the room minus one!</p>

<blockquote>
  <p>The unbridled use of the go to statement has an immediate consequence that it becomes terribly hard to find a meaningful set of coordinates in which to describe the process progress.</p>
</blockquote>

<p>The <code>go to</code> statement as it stands is just too primitive; it is too much an invitation to make a mess of one’s program. One can regard and appreciate the clauses considered as bridling its use. I do not claim that the clauses mentioned are exhaustive in the sense that they will satisfy all needs, but whatever clauses are suggested (e.g. abortion clauses) they should satisfy the requirement that a programmer independent coordinate system can be maintained to describe the process in a helpful and manageable way.</p>

<p>It is hard to end this with a fair acknowledgment. Am I to judge by whom my thinking has been influenced? It is fairly obvious that I am not uninfluenced by Peter Landin and Christopher Strachey. Finally I should like to record (as I remember it quite distinctly) how Heinz Zemanek at the pre-ALGOL meeting in early 1959 in Copenhagen quite explicitly expressed his doubts whether the <code>go to</code> statement should be treated on equal syntactic footing with the assignment statement. To a modest extent I blame myself for not having then drawn the consequences of his remark.</p>

<p>The remark about the undesirability of the <code>go to</code> statement is far from new. I remember having read the explicit recommendation to restrict the use of the <code>go to</code> statement to alarm exits, but I have not been able to trace it; presumably, it has been made by C. A. R. Hoare. In [1, Sec. 3.2.1.] Wirth and Hoare together make a remark in the same direction in motivating the case construction: “Like the conditional, it mirrors the dynamic structure of a program more clearly than <code>go to</code> statements and switches, and it eliminates the need for introducing a large number of labels in the program.”</p>

<p>In [2] Guiseppe Jacopini seems to have proved the (logical) superfluousness of the <code>go to</code> statement. The exercise to translate an arbitrary flow diagram more or less mechanically into a jump-less one, however, is not to be recommended. Then the resulting flow diagram cannot be expected to be more transparent than the original one.</p>

<p>References:</p>

<ol>
  <li>Wirth, Niklaus, and Hoare C. A. R. A contribution to the development of ALGOL. Comm. ACM 9(June 1966), 413-432.</li>
  <li>BÖhm, Corrado, and Jacopini Guiseppe. Flow diagrams, Turing machines and languages with only two formation rules. Comm. ACM 9 (May 1966), 366-371.</li>
</ol>

<p>Edsger W. Dijkstra,<br>Technological University Eindhoven,<br>The Netherlands</p>

  </section>

    


  
</article></div>]]>
            </description>
            <link>https://chsasank.github.io/classic_papers/goto-statement-considered-harmful.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24652958</guid>
            <pubDate>Thu, 01 Oct 2020 16:33:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Compiling a Lisp to x86-64: Let expressions]]>
            </title>
            <description>
<![CDATA[
Score 127 | Comments 30 (<a href="https://news.ycombinator.com/item?id=24652842">thread link</a>) | @todsacerdoti
<br/>
October 1, 2020 | https://bernsteinbear.com/blog/compiling-a-lisp-7/ | <a href="https://web.archive.org/web/*/https://bernsteinbear.com/blog/compiling-a-lisp-7/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p><em><a href="https://bernsteinbear.com/blog/compiling-a-lisp-0/">first</a></em> – <em><a href="https://bernsteinbear.com/blog/compiling-a-lisp-6/">previous</a></em></p>

<p>Welcome back to the “Compiling a Lisp” series. Last time we added a reader
(also known as a parser) to our compiler. This time we’re going to compile a
new form: <em>let</em> expressions.</p>

<p>Let expressions are a way to bind variables to values in a particular scope.
For example:</p>

<div><div><pre><code><span>(</span><span>let</span> <span>((</span><span>a</span> <span>1</span><span>)</span> <span>(</span><span>b</span> <span>2</span><span>))</span>
  <span>(</span><span>+</span> <span>a</span> <span>b</span><span>))</span>
</code></pre></div></div>

<p>Binds <code>a</code> to <code>1</code> and <code>b</code> to <code>2</code>, but only for the body of the <code>let</code> — the
rest of the S-expression — and then executes the body.</p>

<p>This is similar in C to opening a new block:</p>

<div><div><pre><code><span>int</span> <span>result</span><span>;</span>
<span>{</span>
  <span>int</span> <span>a</span> <span>=</span> <span>1</span><span>;</span>
  <span>int</span> <span>b</span> <span>=</span> <span>2</span><span>;</span>
  <span>result</span> <span>=</span> <span>a</span> <span>+</span> <span>b</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>but it’s a little different because C has a divide between <em>statements</em> and
<em>expressions</em>, whereas Lisp does not.</p>

<p>It’s <em>also</em> different because let-expressions do not make previous binding
names available to expressions being bound. For example, the following program
should fail because it cannot find the name <code>a</code>:</p>



<p>There is a form that makes bindings available serially, but that is called
<code>let*</code> and we are not implementing that today.</p>

<p>For completeness’ sake, there is also <code>let rec</code>, which makes names available
serially and also within the same binding. This is useful for binding recursive
or mutually recursive functions. Again, we are not implementing that today.</p>

<h3 id="name-binding-implementation-strategy">Name binding implementation strategy</h3>

<p>You’ll notice two new things about let expressions:</p>

<ol>
  <li>They introduce ways to bind names to values, something we have to figure out
how to keep track of</li>
  <li>In order to use those names we have to figure out how to look up what the
name means</li>
</ol>

<p>In more technical terms, we have to add <em>environments</em> to our compiler. We can
then use those environments to map <em>names</em> to <em>stack locations</em>.</p>

<p>“Environment” is just a fancy word for “look-up table”. In order to implement
this table, we’re going to make an <em>association list</em>.</p>

<p>An <em>association list</em> is a list of <code>(key value)</code> pairs. Adding a pair means
tacking it on at the end (or beginning) of the list. Searching through the
table involves a linear scan, checking if keys match.</p>

<blockquote>
  <p>You may be wondering why we’re using this data structure to implement
environments. Didn’t I even take a data structures course in college?
Shouldn’t I know that <em>linear</em> equals <em>slow</em> and that I should <em>obviously</em>
use a hash table?</p>

  <p>Well, hash tables have costs too. They are hard to implement right; they have
high overhead despite being technically constant time; they incur higher
space cost per entry.</p>

  <p>For a compiler as small as this, a tuned hash table could easily be as long
as the rest of the compiler. Since we’re also compiling small <em>programs</em>,
we’ll worry about time complexity later. It is only an implementation detail.</p>
</blockquote>

<p>In order to do this, we’ll first draw up an association list. We’ll use a
linked list, just like cons cells:</p>

<div><div><pre><code><span>// Env</span>

<span>typedef</span> <span>struct</span> <span>Env</span> <span>{</span>
  <span>const</span> <span>char</span> <span>*</span><span>name</span><span>;</span>
  <span>word</span> <span>value</span><span>;</span>
  <span>struct</span> <span>Env</span> <span>*</span><span>prev</span><span>;</span>
<span>}</span> <span>Env</span><span>;</span>
</code></pre></div></div>

<p>I’ve done the usual thing and overloaded <code>Env</code> to mean both “a node in the
environment” and “a whole environment”. While one little <code>Env</code> struct only
holds a one name and one value, it also points to the rest of them, eventually
ending with <code>NULL</code>.</p>

<p>This <code>Env</code> will map names (symbols) to <em>stack offsets</em>. This is because we’re
going to continue our strategy of <em>not doing register allocation</em>.</p>

<p>To manipulate this data structure, we will also have two functions<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>:</p>

<div><div><pre><code><span>Env</span> <span>Env_bind</span><span>(</span><span>const</span> <span>char</span> <span>*</span><span>name</span><span>,</span> <span>word</span> <span>value</span><span>,</span> <span>Env</span> <span>*</span><span>prev</span><span>);</span>
<span>bool</span> <span>Env_find</span><span>(</span><span>Env</span> <span>*</span><span>env</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>key</span><span>,</span> <span>word</span> <span>*</span><span>result</span><span>);</span>
</code></pre></div></div>

<p><code>Env_bind</code> creates a new node from the given name and value, borrowing a
reference to the name, and prepends it to <code>prev</code>. Instead of returning an
<code>Env*</code>, it returns a whole struct. We’ll learn more about why later, but the
“TL;DR” is that I think it requires less manual cleanup.</p>

<p><code>Env_find</code> takes an <code>Env*</code> and searches through the linked list for a <code>name</code>
matching the given <code>key</code>. If it finds a match, it returns <code>true</code> and stores the
<code>value</code> in <code>*result</code>. Otherwise, it returns <code>false</code>.</p>

<p>We can stop at the first match because Lisp allows name <em>shadowing</em>. Shadowing
occurs when a binding at a inner scope has the same name as a binding at an
outer scope. The inner binding takes precedence:</p>

<div><div><pre><code><span>(</span><span>let</span> <span>((</span><span>a</span> <span>1</span><span>))</span>
  <span>(</span><span>let</span> <span>((</span><span>a</span> <span>2</span><span>))</span>
    <span>a</span><span>))</span>
<span>; =&gt; 2</span>
</code></pre></div></div>

<p>Let’s learn about how these functions are implemented.</p>

<h3 id="name-binding-implementation">Name binding implementation</h3>

<p><code>Env_bind</code> is a little silly looking, but it’s equivalent to prepending a
node onto a chain of linked-list nodes. It returns a struct <code>Env</code> containing
the parameters passed to the function. I opted <em>not</em> to return a heap pointer
(allocated with <code>malloc</code>, etc) so that this can be easily stored in a
stack-allocated variable.</p>

<div><div><pre><code><span>Env</span> <span>Env_bind</span><span>(</span><span>const</span> <span>char</span> <span>*</span><span>name</span><span>,</span> <span>word</span> <span>value</span><span>,</span> <span>Env</span> <span>*</span><span>prev</span><span>)</span> <span>{</span>
  <span>return</span> <span>(</span><span>Env</span><span>){.</span><span>name</span> <span>=</span> <span>name</span><span>,</span> <span>.</span><span>value</span> <span>=</span> <span>value</span><span>,</span> <span>.</span><span>prev</span> <span>=</span> <span>prev</span><span>};</span>
<span>}</span>
</code></pre></div></div>

<p><em>Note</em> that we’re <strong>pre</strong>pending, not <strong>ap</strong>pending, so that names we add deeper
in a let chain shadow names from outside.</p>

<p><code>Env_find</code> does a recursive linear search through the linked list nodes. It may
look familiar to you if you’ve already written such a function in your life.</p>

<div><div><pre><code><span>bool</span> <span>Env_find</span><span>(</span><span>Env</span> <span>*</span><span>env</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>key</span><span>,</span> <span>word</span> <span>*</span><span>result</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>env</span> <span>==</span> <span>NULL</span><span>)</span>
    <span>return</span> <span>false</span><span>;</span>
  <span>if</span> <span>(</span><span>strcmp</span><span>(</span><span>env</span><span>-&gt;</span><span>name</span><span>,</span> <span>key</span><span>)</span> <span>==</span> <span>0</span><span>)</span> <span>{</span>
    <span>*</span><span>result</span> <span>=</span> <span>env</span><span>-&gt;</span><span>value</span><span>;</span>
    <span>return</span> <span>true</span><span>;</span>
  <span>}</span>
  <span>return</span> <span>Env_find</span><span>(</span><span>env</span><span>-&gt;</span><span>prev</span><span>,</span> <span>key</span><span>,</span> <span>result</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>We search for the node with the string <code>key</code> and return the stack offset associated
with it.</p>

<p>Alright, now we’ve got names and data structures. Let’s implement some name
resolution and name binding.</p>

<h3 id="compiling-name-resolution">Compiling name resolution</h3>

<p>Up until now, <code>Compile_expr</code> could only compile integers, characters, booleans,
<code>nil</code>, and some primitive call expressions (via <code>Compile_call</code>). Now we’re
going to add a new case: symbols.</p>

<p>When a symbol is compiled, the compiler will look up its stack offset in the
current environment and emit a load. This opcode, <code>Emit_load_reg_indirect</code>, is
very similar to <code>Emit_add_reg_indirect</code> that we implemented for primitive
binary functions.</p>

<div><div><pre><code><span>int</span> <span>Compile_expr</span><span>(</span><span>Buffer</span> <span>*</span><span>buf</span><span>,</span> <span>ASTNode</span> <span>*</span><span>node</span><span>,</span> <span>word</span> <span>stack_index</span><span>,</span>
                 <span>Env</span> <span>*</span><span>varenv</span><span>)</span> <span>{</span>
  <span>// ...</span>
  <span>if</span> <span>(</span><span>AST_is_symbol</span><span>(</span><span>node</span><span>))</span> <span>{</span>
    <span>const</span> <span>char</span> <span>*</span><span>symbol</span> <span>=</span> <span>AST_symbol_cstr</span><span>(</span><span>node</span><span>);</span>
    <span>word</span> <span>value</span><span>;</span>
    <span>if</span> <span>(</span><span>Env_find</span><span>(</span><span>varenv</span><span>,</span> <span>symbol</span><span>,</span> <span>&amp;</span><span>value</span><span>))</span> <span>{</span>
      <span>Emit_load_reg_indirect</span><span>(</span><span>buf</span><span>,</span> <span>/*dst=*/</span><span>kRax</span><span>,</span> <span>/*src=*/</span><span>Ind</span><span>(</span><span>kRbp</span><span>,</span> <span>value</span><span>));</span>
      <span>return</span> <span>0</span><span>;</span>
    <span>}</span>
    <span>return</span> <span>-</span><span>1</span><span>;</span>
  <span>}</span>
  <span>assert</span><span>(</span><span>0</span> <span>&amp;&amp;</span> <span>"unexpected node type"</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>If the variable is not in the environment, this is a compiler error and we
return <code>-1</code> to signal that. This is not a tremendously helpful signal. Maybe
soon we will add more helpful error messages.</p>

<p>Ah, yes, <code>varenv</code>. You will, like I had to, go and add an <code>Env*</code> parameter to
all relevant <code>Compile_XYZ</code> functions and then plumb it through the recursive
calls. Have fun!</p>

<h3 id="compiling-let-finally">Compiling let, finally</h3>

<p>Now that we can resolve the names, let’s go ahead and compile the expressions
that bind them.</p>

<p>We’ll have to add a case in <code>Compile_expr</code>. We could add it in the body of
<code>Compile_expr</code> itself, but there is some helpful setup in <code>Compile_call</code>
already. It’s a bit of a misnomer, since it’s not a call, but oh well.</p>

<div><div><pre><code><span>int</span> <span>Compile_call</span><span>(</span><span>Buffer</span> <span>*</span><span>buf</span><span>,</span> <span>ASTNode</span> <span>*</span><span>callable</span><span>,</span> <span>ASTNode</span> <span>*</span><span>args</span><span>,</span>
                 <span>word</span> <span>stack_index</span><span>,</span> <span>Env</span> <span>*</span><span>varenv</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>AST_is_symbol</span><span>(</span><span>callable</span><span>))</span> <span>{</span>
    <span>// ...</span>
    <span>if</span> <span>(</span><span>AST_symbol_matches</span><span>(</span><span>callable</span><span>,</span> <span>"let"</span><span>))</span> <span>{</span>
      <span>return</span> <span>Compile_let</span><span>(</span><span>buf</span><span>,</span> <span>/*bindings=*/</span><span>operand1</span><span>(</span><span>args</span><span>),</span>
                         <span>/*body=*/</span><span>operand2</span><span>(</span><span>args</span><span>),</span> <span>stack_index</span><span>,</span>
                         <span>/*binding_env=*/</span><span>varenv</span><span>,</span>
                         <span>/*body_env=*/</span><span>varenv</span><span>);</span>
    <span>}</span>
  <span>}</span>
  <span>assert</span><span>(</span><span>0</span> <span>&amp;&amp;</span> <span>"unexpected call type"</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>We have two cases to handle: no bindings and some bindings. We’ll tackle these
recursively, with no bindings being the base case. For that reason, I added a
helper function <code>Compile_let</code>.</p>

<p>As with all of the other compiler functions, we pass it an machine code buffer,
a stack index, and an environment. Unlike other functions, we passed it two
expressions and two environments.</p>

<p>I split up the bindings and the body so we can more easily recurse on the
bindings as we go through them. When we get to the end (the base case), the
bindings will be <code>nil</code> and we can just compile the <code>body</code>.</p>

<p>We have two environments for the reason I mentioned above: when we’re
evaluating the expressions that we’re binding the names to, we can’t add
bindings iteratively. We have to evaluate them in the parent environment. It’ll
be come clearer in a moment how that works.</p>

<p>We’ll tackle the simple case first — no bindings:</p>

<div><div><pre><code><span>int</span> <span>Compile_let</span><span>(</span><span>Buffer</span> <span>*</span><span>buf</span><span>,</span> <span>ASTNode</span> <span>*</span><span>bindings</span><span>,</span> <span>ASTNode</span> <span>*</span><span>body</span><span>,</span>
                <span>word</span> <span>stack_index</span><span>,</span> <span>Env</span> <span>*</span><span>binding_env</span><span>,</span> <span>Env</span> <span>*</span><span>body_env</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>AST_is_nil</span><span>(</span><span>bindings</span><span>))</span> <span>{</span>
    <span>// Base case: no bindings. Compile the body</span>
    <span>_</span><span>(</span><span>Compile_expr</span><span>(</span><span>buf</span><span>,</span> <span>body</span><span>,</span> <span>stack_index</span><span>,</span> <span>body_env</span><span>));</span>
    <span>return</span> <span>0</span><span>;</span>
  <span>}</span>
  <span>// ...</span>
<span>}</span>
</code></pre></div></div>

<p>In that case, we compile the body using the <code>body_env</code> as the environment. This
is the environment that we will have added all of the bindings to.</p>

<p>In the case where we <em>do</em> have bindings, we can take the first one off and pull
it apart:</p>

<div><div><pre><code>  <span>// ...</span>
  <span>assert</span><span>(</span><span>AST_is_pair</span><span>(</span><span>bindings</span><span>));</span>
  <span>// Get the next binding</span>
  <span>ASTNode</span> <span>*</span><span>binding</span> <span>=</span> <span>AST_pair_car</span><span>(</span><span>bindings</span><span>);</span>
  <span>ASTNode</span> <span>*</span><span>name</span> <span>=</span> <span>AST_pair_car</span><span>(</span><span>binding</span><span>);</span>
  <span>assert</span><span>(</span><span>AST_is_symbol</span><span>(</span><span>name</span><span>));</span>
  <span>ASTNode</span> <span>*</span><span>binding_expr</span> <span>=</span> <span>AST_pair_car</span><span>(</span><span>AST_pair_cdr</span><span>(</span><span>binding</span><span>));</span>
  <span>// ...</span>
</code></pre></div></div>

<p>Once we have the <code>binding_expr</code>, we should compile it. The result will end up
in <code>rax</code>, per our internal compiler convention. We’ll then store it in the next
available stack location:</p>

<div><div><pre><code>  <span>// ...</span>
  <span>// Compile the binding expression</span>
  <span>_</span><span>(</span><span>Compile_expr</span><span>(</span><span>buf</span><span>,</span> <span>binding_expr</span><span>,</span> <span>stack_index</span><span>,</span> <span>binding_env</span><span>));</span>
  <span>Emit_store_reg_indirect</span><span>(</span><span>buf</span><span>,</span> <span>/*dst=*/</span><span>Ind</span><span>(</span><span>kRbp</span><span>,</span> <span>stack_index</span><span>),</span>
                          <span>/*src=*/</span><span>kRax</span><span>);</span>
  <span>// ...</span>
</code></pre></div></div>

<p>We’re compiling this binding expression in <code>binding_env</code>, the parent
environment, because we don’t want the previous bindings to be visible.</p>

<p>Once we’ve generated code to store it on the stack, we should register that
stack location with the binding name in the environment:</p>

<div><div><pre><code>  <span>// ...</span>
  <span>// Bind the name</span>
  <span>Env</span> <span>entry</span> <span>=</span> <span>Env_bind</span><span>(</span><span>AST_symbol_cstr</span><span>(</span><span>name</span><span>),</span> <span>stack_index</span><span>,</span> <span>body_env</span><span>);</span>
  <span>// ...</span>
</code></pre></div></div>

<p>Note that we’re binding it in the <code>body_env</code> because we want this to be
available to the body, but not the other bindings.</p>

<p>At this point we’ve done all the work required for …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bernsteinbear.com/blog/compiling-a-lisp-7/">https://bernsteinbear.com/blog/compiling-a-lisp-7/</a></em></p>]]>
            </description>
            <link>https://bernsteinbear.com/blog/compiling-a-lisp-7/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24652842</guid>
            <pubDate>Thu, 01 Oct 2020 16:26:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Data Science Pull Requests– Review and merge code, data and experiments]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24652832">thread link</a>) | @Dean-DAGsHub
<br/>
October 1, 2020 | https://dagshub.com/blog/data-science-pull-requests/ | <a href="https://web.archive.org/web/*/https://dagshub.com/blog/data-science-pull-requests/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
              <h3 id="a-step-forward-for-mlops-and-unlocking-open-source-data-science">A step forward for MLOps and unlocking Open Source Data Science</h3><p>Today, we're releasing Data Science Pull Requests (DS PRs), which are Pull Requests (PRs), re-imagined for the data science (DS) workflow. This new capability unlocks a standard review process for data science teams, enabling them to merge data across different branches and accept data contributions across forks. This provides a better collaborative experience for teams in data science organizations and enables truly Open Source Data Science (OSDS) projects. </p><p>For more details, read on...</p><h2 id="introduction">Introduction</h2><p>When we started DAGsHub, we were focused on making data science collaboration possible. Specifically, we deeply <em>care</em> and <em>rely on</em> Open Source Software (OSS), and we set out on a mission to make OSDS as accessible and prevalent as OSS is today.</p><p>This meant that we were concerned about <strong><em>discoverability </em></strong>of data science projects and experiments to work on, <strong><em>understandability</em></strong> of the context of an experiment, <strong><em>reproducibility</em> of </strong>its results, and finally, <strong><em>contributability</em></strong> of code-, data- and models- changed back to the original project.</p><p>When reviewing these processes and the existing solutions some things become clear:</p><ul><li><em><strong>Discoverability </strong></em>means being able to answer the question "<em>What should I do next?</em>" – finding a project to work on, and within that project finding what experiments might be interesting or important. <br>It is solved mainly by <strong>experiment tracking</strong> systems, many of them using proprietary or black box formats that are hard to understand and migrate to/from.<p>DAGsHub goes beyond this by creating an experiment tracking system that relies on simple open formats (<code>YAML</code> and <code>CSV</code>). This means you don't need to add obscure lines of code – everything works by automatically scanning and analyzing the git commits pushed into the platform.</p></li><li><em><strong>Understandability</strong></em> means being able to answer the question "<em>How should I do what I want to do?</em>" – this usually consists of reviewing why, how, and what was already done in a project or experiment. The solution for this step is mostly manual and relies on self-documenting one's work and discussions with collaborators.<p>DAGsHub improves on this by providing a convenient interface into projects' code, data, models, and pipelines which give users a window into their projects' components, and how they interact with each other.</p></li><li><em><strong>Reproducibility</strong></em> means setting up an exact copy of the experiment you want to work on. Many times this process is reduced to a Git commit and the experiment parameters (logged in the experiment tracking system). However, the true standard for reproducibility involves <em><strong>easily </strong></em>retrieving the same version of data, models, and other artifacts. It is best solved by using Git with some dedicated data versioning solution.<p>DAGsHub solves this by relying on open source tools such as Git and DVC to provide the standard discussed above – a complete copy of your project (code, data, models, parameters, and other artifacts) with one (or two) commands.</p></li><li><em><strong>Contributability</strong></em> means that you can take a new experiment or result, and incorporate them back into the project you started from so that you don't need to maintain your result separately. Today, this is entirely manual, full of friction, and fundamentally <strong>non-existent</strong>.</li></ul><p>We have many more things to build, but it was clear that one aspect needed to be covered first – a <strong><em>CONTRIBUTION </em></strong>mechanism.</p><h2 id="contributing-data-science-pull-requests">Contributing – Data Science Pull Requests</h2><p>The final step of the collaborative process is arguably the most important one. Without it, the workflow is one-sided, a monologue, which means collaboration isn't happening. Practically, <strong><em>Contributing</em></strong> can be broken down into two tasks - <strong>reviewing</strong> and <strong>merging </strong>contributions.</p><p>In software, both reviewing and merging are a part of the <strong>pull request</strong> process, but their focus was solely on code. </p><blockquote>Data Science Pull Requests let you <strong>review experiments<u>,</u></strong> <strong>code, data, models, </strong>and your<strong> pipelines</strong>, and <strong><u>merge changes to all of them automatically.</u></strong> </blockquote><h3 id="data-science-review">Data Science Review</h3><p>If you've ever worked on a data science project with other people or tried reviewing someone else's data science work, you know how hard it is to get the information you need to understand someone else's work, or explain your own, so that the review process is meaningful. The process is slow and manual because systems are not built for review.</p><p>An automatic review process means changes and updates can be discussed and integrated faster into your project.<strong> You need to quickly see what has changed, discuss it, in context, and decide how to move forward.</strong></p><p>What this means in practice:</p><ul><li>Commenting on experiments, in context – you can look at the new experiments that are being contributed as part of the DS PR, and compare them to the base experiment in the original project. See all the visualization and information, and add comments on these within the PR discussion with links to the relevant comparison/visualization.</li></ul><figure><img src="https://dagshub.com/blog/content/images/2020/09/exp-comment-long-hq.gif" alt="Commenting on experiments"><figcaption>Commenting on experiments in DS PRs</figcaption></figure><ul><li>See what data and models have changed (not just code) – view what data, model, and artifact files were added, removed, or modified. This means you can easily pinpoint changes and focus the discussion on what's important.</li></ul><figure><img src="https://dagshub.com/blog/content/images/2020/09/Screen-Shot-2020-09-25-at-18.51.25.png" alt="Viewing data changes in a DAGsHub project" srcset="https://dagshub.com/blog/content/images/size/w600/2020/09/Screen-Shot-2020-09-25-at-18.51.25.png 600w, https://dagshub.com/blog/content/images/size/w1000/2020/09/Screen-Shot-2020-09-25-at-18.51.25.png 1000w, https://dagshub.com/blog/content/images/2020/09/Screen-Shot-2020-09-25-at-18.51.25.png 1189w" sizes="(min-width: 720px) 720px"><figcaption>Data Comparison Example</figcaption></figure><ul><li>Compare and diff notebooks side-by-side – notebooks are an important part of many data science projects. However, for a very long time, they haven't received adequate treatment in the review process, relying on diffs to the raw <code>JSON</code> file, which were mostly unreadable. You can now review the changes in an intuitive UI as part of the DS PR. Another benefit of this is that if you require a special visualization, you can commit a notebook with that visualization, and view the changes conveniently.</li></ul><figure><img src="https://dagshub.com/blog/content/images/2020/09/Screen-Shot-2020-09-25-at-19.04.33.png" alt="Notebook comparison" srcset="https://dagshub.com/blog/content/images/size/w600/2020/09/Screen-Shot-2020-09-25-at-19.04.33.png 600w, https://dagshub.com/blog/content/images/size/w1000/2020/09/Screen-Shot-2020-09-25-at-19.04.33.png 1000w, https://dagshub.com/blog/content/images/size/w1600/2020/09/Screen-Shot-2020-09-25-at-19.04.33.png 1600w, https://dagshub.com/blog/content/images/2020/09/Screen-Shot-2020-09-25-at-19.04.33.png 2298w" sizes="(min-width: 720px) 720px"><figcaption>Notebook Diffing Example</figcaption></figure><p>After reviewing a collaborator's work, we need a way to incorporate those changes, automatically. That's why we built data science merging.</p><h3 id="data-science-merging">Data Science Merging</h3><p>Merging code is possible with Git, but as we already discussed, that is not the full picture for data science projects. With DS PRs, you can merge your data and other artifacts as well. </p><h4 id="data-merging">Data Merging</h4><p>Everyone knows about bugs in code, but you might also have data bugs that you're not aware of. Examples include data that is not up to date, biased, or mislabeled. Assuming you found out about such a bug and you wanted to fix it – that would usually mean you need to agree on and perform some manual operation to update or add new data. With data merging, once you accept a DS PR, the new data would automatically be copied into your project in an entirely automatic process.</p><h4 id="artifact-merging">Artifact Merging</h4><p>This doesn't end with just the <em>raw data – </em>data merging lets you merge models and any other artifact of your data pipeline (e.g. preprocessed data or 3d models). Take a case where one of the steps in a pipeline takes 2 weeks to run and results in some trained model or a processed dataset. If only raw data was merged, you'd have to run that excruciating 2-week process again. Artifact merging means that after a DS PR is merged, the resulting project is as reproducible as the original contribution.</p><p>After accepting a DS PR you are in the same state of your DS project, as you would after accepting a PR in a software project.</p><figure><img src="https://dagshub.com/blog/content/images/2020/09/Screen-Shot-2020-09-25-at-19.23.30.png" alt="Data Merging on DAGsHub" srcset="https://dagshub.com/blog/content/images/size/w600/2020/09/Screen-Shot-2020-09-25-at-19.23.30.png 600w, https://dagshub.com/blog/content/images/size/w1000/2020/09/Screen-Shot-2020-09-25-at-19.23.30.png 1000w, https://dagshub.com/blog/content/images/size/w1600/2020/09/Screen-Shot-2020-09-25-at-19.23.30.png 1600w, https://dagshub.com/blog/content/images/2020/09/Screen-Shot-2020-09-25-at-19.23.30.png 1846w" sizes="(min-width: 720px) 720px"><figcaption>Data Science Merging – Note that 171 MB of data will be copied on accepting this DS PR</figcaption></figure><p>Data merging means you can accept data and models from contributors with ease, without giving each one full access to your data storage. This can reduce friction and speed up team efforts.</p><p>This last capability is especially useful for OSDS.</p><h2 id="what-does-this-mean-for-osds">What does this mean for OSDS?</h2><p><a href="https://dagshub.com/blog/a-case-for-open-source-data-science/">Open Source Data Science (OSDS) has the potential to have a similar effect on the world</a>, as Open Source Software (OSS) had. It is DAGsHub's stated goal to promote OSDS and build the technology to make it as easy as possible. OSDS must come first, and industry workflows will mirror those in OSDS projects, as they have for OSS. </p><p>But let's face it – OSDS doesn't <em>really</em> exist yet. If you maintain some OSDS project and you want to accept contributions from people (like you would for OSS) – you have to do it entirely manually or <strong>resort to accepting only code changes</strong> (no way to accept data bug fixes – and we all know there are plenty).</p><p>From the individual contributor side, if you want to improve your ML portfolio by contributing to some OSDS project, you're also stuck. You have to either fork the project and not contribute your changes (which means their quality is never reviewed – you don't learn as much) or go through a painstaking manual effort<sup>[1]</sup>.</p><blockquote>DS PRs make OSDS possible by providing a standard interface and workflow to review and accept contributions from anyone, anywhere, and for any type of data science component.</blockquote><p><strong>We'd love to support open source data science projects that want to accept data science contributions from the community. Please reach out to us at <a href="mailto:osds@dagshub.com">osds@dagshub.com</a> if this is relevant for you.</strong></p><h2 id="thank-you-">Thank You!</h2><p>Thank you to all the people that gave us feedback before and while we were building DS PRs. We'd love to get your feedback as well on how DS PRs could be improved for the community – the best way to do this is to join our <a href="https://discord.com/invite/9gU36Y6">Discord channel</a>. Looking forward to hearing your thoughts and seeing what people build with open source data science.</p><hr><!--kg-card-begin: markdown--><p>
[1] Kaggle is worth a mention here – It is a common way to show some of your DS chops. However, it's competitive (as opposed to collaborative). Furthermore, data science projects in the wild rarely have one all-encompassing metric to optimize at the expense of everything else - 80% of the work is just gathering data and deciding what is even worth optimizing! 
Our goal with DAGsHub is to enable a collaborative way to showcase your capabilities while encouraging interoperability – i.e. working together rather than everyone doing their own thing and ending up with a ton of fragmentation.
</p><!--kg-card-end: markdown-->
                <section>
                  
                  <ul>
                      <li>
                        <a href="https://dagshub.com/blog/tag/data-science/" title="Data Science">Data Science</a>
                      </li>
                      <li>
                        <a href="https://dagshub.com/blog/tag/data-science-workflow/" title="Data Science Workflow">Data Science Workflow</a>
                      </li>
                      <li>
               …</li></ul></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dagshub.com/blog/data-science-pull-requests/">https://dagshub.com/blog/data-science-pull-requests/</a></em></p>]]>
            </description>
            <link>https://dagshub.com/blog/data-science-pull-requests/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24652832</guid>
            <pubDate>Thu, 01 Oct 2020 16:26:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A look at PostGIS vs. Geocoder in Rails]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24652608">thread link</a>) | @leighhalliday
<br/>
October 1, 2020 | https://pganalyze.com/blog/postgis-rails-geocoder | <a href="https://web.archive.org/web/*/https://pganalyze.com/blog/postgis-rails-geocoder">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>
This article sets out to compare PostGIS in Rails with Geocoder and to highlight a couple of the areas where you'll want to (or need to) reach for one over the other. I will also present some of the terminology and libraries that I found along the way of working on this project and article as I set out to understand PostGIS better and how it is integrated with Rails.</p>

<p><span>
      <span></span>
  <img alt="PostGIS vs. Geocoder in Rails" title="PostGIS vs. Geocoder in Rails" src="https://pganalyze.com/static/383f2659b144f300d98f78a94aefe750/29d31/postgis_rails_geocoder_pganalyze.jpg" srcset="https://pganalyze.com/static/383f2659b144f300d98f78a94aefe750/e52aa/postgis_rails_geocoder_pganalyze.jpg 175w, https://pganalyze.com/static/383f2659b144f300d98f78a94aefe750/70ebb/postgis_rails_geocoder_pganalyze.jpg 350w, https://pganalyze.com/static/383f2659b144f300d98f78a94aefe750/29d31/postgis_rails_geocoder_pganalyze.jpg 700w, https://pganalyze.com/static/383f2659b144f300d98f78a94aefe750/9ecec/postgis_rails_geocoder_pganalyze.jpg 1050w, https://pganalyze.com/static/383f2659b144f300d98f78a94aefe750/e5166/postgis_rails_geocoder_pganalyze.jpg 1200w" sizes="(max-width: 700px) 100vw, 700px" loading="lazy">
    </span>
Picture via <a href="https://unsplash.com/@anniespratt">Annie Spratt</a> on Unsplash</p>
<p>I have built a number of Rails applications over the years that show locations on a map, have nearby search functionality, and I had never used <a href="https://postgis.net/">PostGIS</a> before! How was this possible? The reason is that there is a Ruby gem named <a href="https://github.com/alexreisner/geocoder">Geocoder</a> which enables you to do these sorts of queries, and it's quite efficient! That said, there is a reason that PostGIS exists. For more complex geo queries I’d recommend reaching beyond Geocoder to PostGIS.</p>
<p>As an example, if you wanted to find homes which have a school within 1km of them, or if you wanted to draw an oddly shaped polygon on a map and search within it, this is the world where PostGIS shines and makes these complex geo queries possible.</p>
<p>In this article we will be covering:</p>
<ul>
<li>PostGIS in Rails setup</li>
<li>Finding nearby records (Geocoder + PostGIS)</li>
<li>Finding records within a bounding box (Geocoder + PostGIS)</li>
<li>Finding records within a polygon (PostGIS)</li>
<li>Finding nearby related records (PostGIS)</li>
</ul>
<p>The source code referenced in this article can be <a href="https://github.com/pganalyze-resources/rails-postgis-demo">found here</a>.</p>
<h2 id="installing-postgis"><a href="#installing-postgis" aria-label="installing postgis permalink"></a>Installing PostGIS</h2>
<p>Postgres comes with a number of built-in extensions that you can enable, but unfortunately PostGIS (Spatial and Geographic objects for Postgres) isn't one of them. In order to enable this extension, you will have to use a Postgres install with PostGIS support. I recommend using the <a href="https://registry.hub.docker.com/r/postgis/postgis">official postgis docker image</a>, but luckily many hosted Postgres solutions come with PostGIS already available. If you are not sure, you can query the available extensions with the following query:</p>
<div data-language="sql"><pre><code><span>select</span> <span>*</span>
<span>from</span> pg_available_extensions
<span>where</span> name <span>like</span> <span>'%postgis%'</span></code></pre></div>
<p>If you'd like to see if the extension is <em>already</em> enabled, you can run this query:</p>
<div data-language="sql"><pre><code><span>select</span> <span>*</span> <span>from</span> pg_extension</code></pre></div>
<p>And finally, to enable this extension, you can use the command <code>create extension postgis</code>, but since we're working within Rails, there is a Gem that will take care of this step for us as we'll see below.</p>
<h2 id="activerecord-postgis-adapter"><a href="#activerecord-postgis-adapter" aria-label="activerecord postgis adapter permalink"></a>ActiveRecord PostGIS Adapter</h2>
<p>If you have confirmed that your version of Postgres supports the <code>postgis</code> extension, you're ready to integrate it with your Rails application. This can be done by using the <a href="https://github.com/rgeo/activerecord-postgis-adapter">activerecord-postgis-adapter</a> gem. Two things need to be done to get up and running. The first is to update the <code>adapter</code> within <code>config/database.yml</code> to be set to <code>postgis</code>. Next, if this is a new application, you can run <code>rails db:create</code> as normal, but if it is an existing one, you'll have to run the command <code>rake db:gis:setup</code>. This command is enabling the postgis extension in your database.</p>
<h2 id="our-example-data"><a href="#our-example-data" aria-label="our example data permalink"></a>Our Example Data</h2>
<p>We'll be working with sample data for a realtor website that allows us to find homes in a variety of ways, including homes that are nearby a local school. There are two models: <code>homes</code> and <code>schools</code>. The Rails migration to create these tables is below:</p>
<div data-language="ruby"><pre><code><span>class</span> <span>CreateHomes</span> <span>&lt;</span> <span>ActiveRecord</span><span>:</span><span>:</span><span>Migration</span><span>[</span><span>6.0</span><span>]</span>
  <span>def</span> <span><span>change</span></span>
    create_table <span>:homes</span> <span>do</span> <span>|</span>t<span>|</span>
      t<span>.</span>string <span>:name</span><span>,</span> null<span>:</span> <span>false</span>
      t<span>.</span>string <span>:status</span><span>,</span> null<span>:</span> <span>false</span>
      t<span>.</span>bigint <span>:price</span><span>,</span> null<span>:</span> <span>false</span>
      t<span>.</span>integer <span>:beds</span><span>,</span> null<span>:</span> <span>false</span><span>,</span> default<span>:</span> <span>0</span>
      t<span>.</span>integer <span>:baths</span><span>,</span> null<span>:</span> <span>false</span><span>,</span> default<span>:</span> <span>0</span>
      t<span>.</span>st_point <span>:coords</span><span>,</span> null<span>:</span> <span>false</span><span>,</span> geographic<span>:</span> <span>true</span>
      t<span>.</span>float <span>:longitude</span><span>,</span> null<span>:</span> <span>false</span>
      t<span>.</span>float <span>:latitude</span><span>,</span> null<span>:</span> <span>false</span>
      t<span>.</span>timestamps

      t<span>.</span>index <span>:coords</span><span>,</span> using<span>:</span> <span>:gist</span>
      t<span>.</span>index <span>%i[latitude longitude]</span>
      t<span>.</span>index <span>:status</span>
      t<span>.</span>index <span>:price</span>
    <span>end</span>

    create_table <span>:schools</span> <span>do</span> <span>|</span>t<span>|</span>
      t<span>.</span>st_point <span>:coords</span><span>,</span> null<span>:</span> <span>false</span><span>,</span> geographic<span>:</span> <span>true</span>

      t<span>.</span>index <span>:coords</span><span>,</span> using<span>:</span> <span>:gist</span>
      t<span>.</span>timestamps
    <span>end</span>
  <span>end</span>
<span>end</span></code></pre></div>
<p>By using <code>activerecord-postgis-adapter</code> we are able to define PostGIS columns within our migration file. When working with PostGIS you can store a point (latitude + longitude) as a single column of type <code>ts_point</code>, whereas when working with <a href="https://github.com/alexreisner/geocoder">Geocoder</a> the latitude and longitude are stored as floats in separate columns. Because we are comparing the two approaches, we will store the data both ways, but typically you would choose one approach or the other.</p>
<p>PostGIS <strong>geographic</strong> columns can be indexed using <a href="https://www.postgresql.org/docs/current/gist-intro.html">GiST</a> style indexes. GiST indexes are required over B-Tree indexes when working with geographic data because coordinates cannot be easily sorted along a single axis (such as numbers, letters, dates, etc...) in a way that would allow the database to speed up common geographic operations.</p>
<p>The example project for this article contains a seeds file (run with <code>rake db:seed</code>) which will generate 100k homes and 100 schools in and around the Atlanta, Georgia area.</p>
<h2 id="building-a-geo-helper-class-with-postgis"><a href="#building-a-geo-helper-class-with-postgis" aria-label="building a geo helper class with postgis permalink"></a>Building a Geo Helper Class with PostGIS</h2>
<p>The Rails PostGIS adapter is based on a library named <a href="https://github.com/rgeo/rgeo">RGeo</a>, which while incredibly powerful, I found a little bit confusing due to a lack of documentation. I ended up building a small helper class to generate different geo objects for me. The first thing to point out is what <a href="https://en.wikipedia.org/wiki/Spatial_reference_system">SRID</a> is. Just like the imperial and metric systems are used to measure and weigh amounts using an agreed upon reference point, coordinates also need a coordinate reference system to ensure that the latitude and longitude that one uses means the same thing to different people when referring to a single place on earth. <a href="https://spatialreference.org/ref/epsg/wgs-84/">4326</a> is the spatial system used for GPS satellite navigation systems and the one we will be using within this article.</p>
<p>One last thing to define is what <a href="https://en.wikipedia.org/wiki/Well-known_text_representation_of_geometry">WKT</a> is. Well-known Text representation of geometry is a string representation of a point, line string, and polygon (among other things) that we will be using in our examples in this article. This is the format Postgres (PostGIS) receives and displays geographic data types in.</p>
<div data-language="ruby"><pre><code><span>class</span> <span>Geo</span>
  <span>SRID</span> <span>=</span> <span>4326</span>

  <span>def</span> <span><span>self</span><span>.</span><span>factory</span></span>
    <span>@@factory</span> <span>||</span><span>=</span> <span>RGeo</span><span>:</span><span>:</span><span>Geographic</span><span>.</span>spherical_factory<span>(</span>srid<span>:</span> <span>SRID</span><span>)</span>
  <span>end</span>

  <span>def</span> <span><span>self</span><span>.</span><span>pairs_to_points</span></span><span>(</span>pairs<span>)</span>
    pairs<span>.</span>map <span>{</span> <span>|</span>pair<span>|</span> point<span>(</span>pair<span>[</span><span>0</span><span>]</span><span>,</span> pair<span>[</span><span>1</span><span>]</span><span>)</span> <span>}</span>
  <span>end</span>

  <span>def</span> <span><span>self</span><span>.</span><span>point</span></span><span>(</span>longitude<span>,</span> latitude<span>)</span>
    factory<span>.</span>point<span>(</span>longitude<span>,</span> latitude<span>)</span>
  <span>end</span>

  <span>def</span> <span><span>self</span><span>.</span><span>line_string</span></span><span>(</span>points<span>)</span>
    factory<span>.</span>line_string<span>(</span>points<span>)</span>
  <span>end</span>

  <span>def</span> <span><span>self</span><span>.</span><span>polygon</span></span><span>(</span>points<span>)</span>
    line <span>=</span> line_string<span>(</span>points<span>)</span>
    factory<span>.</span>polygon<span>(</span>line<span>)</span>
  <span>end</span>

  <span>def</span> <span><span>self</span><span>.</span><span>to_wkt</span></span><span>(</span>feature<span>)</span>
    <span>"srid=<span><span>#{</span><span>SRID</span><span>}</span></span>;<span><span>#{</span>feature<span>}</span></span>"</span>
  <span>end</span>
<span>end</span></code></pre></div>
<h2 id="finding-nearby-records-with-postgis-and-geocoder"><a href="#finding-nearby-records-with-postgis-and-geocoder" aria-label="finding nearby records with postgis and geocoder permalink"></a>Finding Nearby Records with PostGIS and Geocoder</h2>
<p>One of the most common geo queries used in applications is to find all records within X distance from a known point (the user's location, an event, a search, etc...). Because we installed <code>Geocoder</code> and added <code>reverse_geocoded_by :latitude, :longitude</code> to our <code>Home</code> class, we can use the <code>nearby</code> method to find all homes within 5km of this latitude and longitude (which happens to be Atlanta, Georgia). Geocoder likes to have arrays with latitude and then longitude, as opposed to PostGIS which <strong>prefers the exact opposite</strong> order!</p>
<div data-language="ruby"><pre><code><span>Home</span><span>.</span>near<span>(</span><span>[</span><span>33.753746</span><span>,</span> <span>-</span><span>84.386330</span><span>]</span><span>,</span> <span>5</span><span>)</span><span>.</span>count<span>(</span><span>:all</span><span>)</span> </code></pre></div>
<p>This query ran in about 5ms on my computer (searching through 100k records)... pretty fast! The reason it is fast is because we added an index on the latitude and longitude fields, but also because Geocoder applies a bounding box filter which utilises the index. Remember the Spatial Reference System (SRID) that we mentioned above? Because our coordinates do not take place on a <a href="https://en.wikipedia.org/wiki/Cartesian_coordinate_system">Cartesian plane</a>, we can’t use a standard distance formula to calculate the <a href="https://www.mathsisfun.com/algebra/distance-2-points.html">distance between two points</a>. Although we won’t venture further into the math of this query below, it takes into consideration the Earth’s spherical nature when calculating the distance between two coordinates as specified by latitude and longitude. <a href="https://www.movable-type.co.uk/scripts/latlong.html">This article</a> dives into more detail on these calculations if you are interested.</p>
<div data-language="sql"><pre><code><span>SELECT</span> <span>COUNT</span><span>(</span><span>*</span><span>)</span> <span>FROM</span> <span>"homes"</span> <span>WHERE</span> <span>(</span>homes<span>.</span>latitude <span>BETWEEN</span> <span>33.708779919704064</span> <span>AND</span> <span>33.798712080295935</span> <span>AND</span> homes<span>.</span>longitude <span>BETWEEN</span> <span>-</span><span>84.44041260768655</span> <span>AND</span> <span>-</span><span>84.33224739231345</span> <span>AND</span> <span>(</span><span>6371.0</span> <span>*</span> <span>2</span> <span>*</span> ASIN<span>(</span>SQRT<span>(</span>POWER<span>(</span>SIN<span>(</span><span>(</span><span>33.753746</span> <span>-</span> homes<span>.</span>latitude<span>)</span> <span>*</span> PI<span>(</span><span>)</span> <span>/</span> <span>180</span> <span>/</span> <span>2</span><span>)</span><span>,</span> <span>2</span><span>)</span> <span>+</span> COS<span>(</span><span>33.753746</span> <span>*</span> PI<span>(</span><span>)</span> <span>/</span> <span>180</span><span>)</span> <span>*</span> COS<span>(</span>homes<span>.</span>latitude <span>*</span> PI<span>(</span><span>)</span> <span>/</span> <span>180</span><span>)</span> <span>*</span> POWER<span>(</span>SIN<span>(</span><span>(</span><span>-</span><span>84.38633</span> <span>-</span> homes<span>.</span>longitude<span>)</span> <span>*</span> PI<span>(</span><span>)</span> <span>/</span> <span>180</span> <span>/</span> <span>2</span><span>)</span><span>,</span> <span>2</span><span>)</span><span>)</span><span>)</span><span>)</span> <span>BETWEEN</span> <span>0.0</span> <span>AND</span> <span>5</span><span>)</span></code></pre></div>
<p>We'll have to build our own <code>near</code> query when working with PostGIS, but don't worry, it's pretty straight forward! The <code>g_near</code> method lives within the <code>Home</code> model, and takes advantage of the <a href="https://postgis.net/docs/ST_DWithin.html">ST_DWithin</a> function provided by PostGIS. Remember that we have to convert our point into the correct WKT format so that PostGIS understands the data we are passing it.</p>
<div data-language="ruby"><pre><code><span>def</span> <span><span>self</span><span>.</span><span>g_near</span></span><span>(</span>point<span>,</span> distance<span>)</span>
  where<span>(</span>
    <span>'ST_DWithin(coords, :point, :distance)'</span><span>,</span>
    <span>{</span> point<span>:</span> <span>Geo</span><span>.</span>to_wkt<span>(</span>point<span>)</span><span>,</span> distance<span>:</span> distance <span>*</span> <span>1000</span> <span>}</span> 
  <span>)</span>
<span>end</span>

<span>Home</span><span>.</span>g_near<span>(</span><span>Geo</span><span>.</span>point<span>(</span><span>-</span><span>84.386330</span><span>,</span> <span>33.753746</span><span>)</span><span>,</span> <span>5</span><span>)</span><span>.</span>count </code></pre></div>
<p>This query performs just about as fast as the Geocoder version (because of our GiST index on the <code>coords</code> column), but is definitely a little easier on the eyes to read.</p>
<div data-language="sql"><pre><code><span>SELECT</span> <span>COUNT</span><span>(</span><span>*</span><span>)</span> <span>FROM</span> <span>"homes"</span> <span>WHERE</span> <span>(</span>ST_DWithin<span>(</span>coords<span>,</span> <span>'srid=4326;POINT (-84.38633 33.753746)'</span><span>,</span> <span>5000</span><span>)</span><span>)</span></code></pre></div>
<h2 id="finding-records-within-a-bounding-box-with-postgis-and-geocoder"><a href="#finding-records-within-a-bounding-box-with-postgis-and-geocoder" aria-label="finding records within a bounding box with postgis and geocoder permalink"></a>Finding Records Within a Bounding Box with PostGIS and Geocoder</h2>
<p>Geocoder provides us a way to find all records within a bounding box (roughly a rectangle, ignoring projection onto a sphere), and we just have to pass it the bottom left (south west) and top right (north east) coordinates.</p>
<div data-language="ruby"><pre><code><span>Home</span><span>.</span>within_bounding_box<span>(</span>
  <span>[</span><span>33.7250057553</span><span>,</span> <span>-</span><span>84.4224209302</span><span>]</span><span>,</span>
  <span>[</span><span>33.774350796</span><span>,</span> <span>-</span><span>84.3570139222</span><span>]</span>
<span>)</span><span>.</span>count </code></pre></div>
<p>Because it can use the index on latitude and longitude, it is quite efficient.</p>
<div data-language="sql"><pre><code><span>SELECT</span> <span>COUNT</span><span>(</span><span>*</span><span>)</span> <span>FROM</span> <span>"homes"</span> <span>WHERE</span> <span>(</span>homes<span>.</span>latitude <span>BETWEEN</span> <span>33.7250057553</span> <span>AND</span> <span>33.774350796</span> <span>AND</span> homes<span>.</span>longitude <span>BETWEEN</span> <span>-</span><span>84.4224209302</span> <span>AND</span> <span>-</span><span>84.3570139222</span><span>)</span></code></pre></div>
<p>To perform a bounding box query using PostGis, we'll create a method named <code>g_within_box</code> inside of the <code>Home</code> model, and utilize a PostGIS function named <a href="https://postgis.net/docs/ST_MakeEnvelope.html">ST_MakeEnvelope</a> along with the <code>&amp;&amp;</code> operator.</p>
<div data-language="ruby"><pre><code><span>def</span> <span><span>self</span><span>.</span><span>g_within_box</span></span><span>(</span>sw_point<span>,</span> ne_point<span>)</span>
  where<span>(</span>
    <span>"coords &amp;&amp; ST_MakeEnvelope(:sw_lon, …</span></code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pganalyze.com/blog/postgis-rails-geocoder">https://pganalyze.com/blog/postgis-rails-geocoder</a></em></p>]]>
            </description>
            <link>https://pganalyze.com/blog/postgis-rails-geocoder</link>
            <guid isPermaLink="false">hacker-news-small-sites-24652608</guid>
            <pubDate>Thu, 01 Oct 2020 16:11:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building your own air pollution monitor with a Raspberry Pi]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24652488">thread link</a>) | @stevenhubertron
<br/>
October 1, 2020 | https://www.drkpxl.com/pollution-gas-and-noise-monitoring-with-raspberry-pi/ | <a href="https://web.archive.org/web/*/https://www.drkpxl.com/pollution-gas-and-noise-monitoring-with-raspberry-pi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
	<article>
		<div>

			<section>
				<p>With all the wildfires happening around the US this summer (2020) I finally got motivated enough to put together an air quality monitor home base station to see air quality in person, on the web and on my phone. &nbsp;If you has a Raspberry Pi plus a few other items you can set this up in an afternoon. I have it tuned to measure PM1.0, PM2.5, PM10, and Carbon Monoxide inside my house. </p><p>As an example, here is what I see in my Adafruit Dashboard</p><figure><img src="https://www.drkpxl.com/content/images/2020/09/Screen-Shot-2020-09-14-at-2.54.09-PM.png" alt="" srcset="https://www.drkpxl.com/content/images/size/w600/2020/09/Screen-Shot-2020-09-14-at-2.54.09-PM.png 600w, https://www.drkpxl.com/content/images/size/w1000/2020/09/Screen-Shot-2020-09-14-at-2.54.09-PM.png 1000w, https://www.drkpxl.com/content/images/size/w1600/2020/09/Screen-Shot-2020-09-14-at-2.54.09-PM.png 1600w, https://www.drkpxl.com/content/images/2020/09/Screen-Shot-2020-09-14-at-2.54.09-PM.png 2024w" sizes="(min-width: 720px) 720px"><figcaption>My Adafruit dashboard.&nbsp;</figcaption></figure><p>I already had most of the the supplies but here is a list of what you will need:</p><ul><li><a href="https://shop.pimoroni.com/products/raspberry-pi-zero-wh-with-pre-soldered-header">Raspberry Pi Zero WH</a></li><li><a href="https://shop.pimoroni.com/products/enviro?variant=31155658489939">Enviro+</a></li><li><a href="https://shop.pimoroni.com/products/pms5003-particulate-matter-sensor-with-cable">PMS50003</a> Particulate Matter Sensor with cable</li><li>A free <a href="https://io.adafruit.com/">Adafruit IO</a> account</li></ul><p>Once you get it all plugged into, the Enviro+ into the Pi, and the PMS5003 into the Enviropi you can get the OS setup with a standard install.</p><p>I'll assume you know how to get Raspberry setup on your PI as well as SSH into it. If not there are a great number of <a href="https://desertbot.io/blog/headless-raspberry-pi-4-ssh-wifi-setup">tutorials</a> <a href="https://www.tomshardware.com/reviews/raspberry-pi-headless-setup-how-to,6028.html">out</a> <a href="https://medium.com/@jay_proulx/headless-raspberry-pi-zero-w-setup-with-ssh-and-wi-fi-8ddd8c4d2742">there</a>.</p><p>Once you are SSHed in, you can follow along with the instructions on the Pimoroni site or just run this script after an <code>apt upgrade</code> and <code>apt update</code></p><pre><code>git clone https://github.com/pimoroni/enviroplus-python
cd enviroplus-python
sudo ./install.sh</code></pre><p>This will install all the various code and samples to get playing with the sensors. The Enviro+ has a bunch of different sensors and LCDs in one making it extremely easy.</p><p>My goals for the setup are:</p><figure><img src="https://www.drkpxl.com/content/images/2020/09/IMG_5163-1.jpg" alt="" srcset="https://www.drkpxl.com/content/images/size/w600/2020/09/IMG_5163-1.jpg 600w, https://www.drkpxl.com/content/images/size/w1000/2020/09/IMG_5163-1.jpg 1000w, https://www.drkpxl.com/content/images/2020/09/IMG_5163-1.jpg 1500w" sizes="(min-width: 720px) 720px"></figure><h3 id="lcd">LCD</h3><p>The LCD displays PM10, PM2.5 and PM1, temp, and noise level on the screen by default. If the pollution spikes, or the gas spikes the LCD will turn red and display a warning.</p><h3 id="adafruit-io">Adafruit IO</h3><p>All the LCD data <strong>plus</strong> Carbon Monoxide, CPU Temp, and CPU load so that I just have a view that everything is healthy on the Pi.</p><figure><img src="https://www.drkpxl.com/content/images/2020/09/IMG_5168.jpg" alt="" srcset="https://www.drkpxl.com/content/images/size/w600/2020/09/IMG_5168.jpg 600w, https://www.drkpxl.com/content/images/size/w1000/2020/09/IMG_5168.jpg 1000w, https://www.drkpxl.com/content/images/2020/09/IMG_5168.jpg 1123w" sizes="(min-width: 720px) 720px"></figure><h3 id="ifttt">IFTTT</h3><p>Push alerts to high pollution or gas to my phone so I can be notified immediately if something is at issue.</p><h2 id="key-code-snippets">Key Code Snippets</h2><h3 id="get-the-cpu-temp">Get the CPU Temp</h3><figure><pre><code>def cpu_report_func():
    # Get CPU Info
    cpu = CPUTemperature()
    aio.send('cpu-temp', round(cpu.temperature * 1.8 + 32))
    aio.send('cpu', psutil.cpu_percent())</code></pre><figcaption>Get CPU temp, convert to F and send both temp and usage to Adafruit</figcaption></figure><h3 id="get-noise">Get Noise</h3><figure><pre><code>def noise_func():
    # Get Noise
    global noise_amount, noise_display
    noise_amount = noise.get_amplitude_at_frequency_range(20, 8000)
    noise_display = str(int(round(noise_amount * 100))) + " db"
    aio.send('noise', int(round(noise_amount * 100)))</code></pre><figcaption>Get noise within a wide range, round it and send off to display and Adafruit</figcaption></figure><h3 id="get-ambient-temps-w-corrections">Get Ambient Temps w/ Corrections</h3><pre><code>def temp_func():
    # Read Temp, convert to F and adjust
    global tempf_display
    # Tuning factor for compensation. Decrease this number to adjust the
    # temperature down, and increase to adjust up
    factor = 0.6

    cpu_temp = CPUTemperature().temperature
    cpu_temps.append(cpu_temp)
    avg_cpu_temp = sum(cpu_temps) / float(len(cpu_temps))
    raw_temp = bme280.get_temperature()
    comp_temp = raw_temp - ((avg_cpu_temp - raw_temp) / factor)
    # Convert to America
    tempf = round(comp_temp * 1.8 + 32)
    
    tempf_display = "" + str(tempf) + " F"
    print(tempf_display)

    # Clean up Array so it doesn't overflow memory
    if (len(cpu_temps) &gt; 10):
        cpu_temps.pop(0)
        aio.send('temp', tempf)</code></pre><p>The thing you would think would be the easiest is actually the hardest due mainly to the fact the themometer is so close to the CPU that it's picking up ambient heat from it. What this does (and is heavily cribbed from the Pimoroni example) is use the CPU temp as a baseline measure that fills up an array, correct for it and convert it to F. Since this "app" is basically one big loop I want to clear the array out after 10 readings or 10 minutes. That should give me enough history to get a good average and the temps I see pass the gut check. </p><p>The <code>factor</code> float may need to be adjusted for your specfic needs. For example if you don't have the Pi in a Lego case, or have different airflow the factor you need to adjust it to may need to be different. </p><h3 id="get-gas-specfically-reducing-aka-carbon-monoxide">Get Gas, specfically Reducing AKA Carbon Monoxide </h3><figure><pre><code>def gas_func():
    global gas_reading, gas_average, gas_warning_amount
    # Get Gas
    gas_reading = gas.read_all()
    gas_array.append(gas_reading.reducing)
    # If the array is larger than 8 items dump the first one
    if (len(gas_array) &gt; 8):
        gas_array.pop(0)
        #print("Popped!")
        aio.send('gas', round(gas_reading.reducing))
    gas_average = (sum(gas_array) / len(gas_array))
    gas_warning_amount = str(round(gas_reading.reducing))
</code></pre><figcaption>Get an average gas reading, current reading and send to Adafruit</figcaption></figure><h3 id="get-air-pollution">Get Air Pollution</h3><figure><pre><code>def pollution_func():
    global pm25, pm10_display, pm25_display, pm1_display
    # Read Particulate Matter
    readings = pms5003.read()
    pm25 = readings.pm_ug_per_m3(2.5)
    pm10 = readings.pm_ug_per_m3(10)
    pm1 = readings.pm_ug_per_m3(1)
    # Send to Adafruit
    aio.send('pollution.pm25', pm25)
    aio.send('pollution.pm1', pm1)
    aio.send('pollution.pm10', pm10)
    # Draw on Screen
    pm10_display = "PM10: " + str(pm10) + " ug/m3"
    pm25_display = "PM25: " + str(pm25) + " ug/m3"
    pm1_display = "PM10: " + str(pm1) + " ug/m3"</code></pre><figcaption>Get the standard ug/m3 readings, send to Adafruit and display</figcaption></figure><h3 id="display-logic">Display Logic</h3><pre><code># Display output of sensors on display
        disp.set_backlight(1)
        if (gas_reading.reducing &gt; (gas_average * 1.05) and len(gas_array) == 8):
            print("High Pollution Warning")
            draw.rectangle((0, 0, 160, 80), (255, 0, 0))
            draw.text((10, 20), warning, font=font, fill=text_colour)
            draw.text((10, 40), gas_warning_amount, font=font, fill=text_colour)
        elif (pm25 &gt; 50):
            draw.rectangle((0, 0, 160, 80), (255, 0, 0))
            draw.text((10, 20), warning, font=font, fill=text_colour)
            draw.text((10, 40), pm25_display, font=font, fill=text_colour)
        else:
            draw.rectangle((0, 0, 160, 80), back_colour)
            draw.text((0, 0), pm10_display, font=font, fill=text_colour)
            draw.text((0, 20), pm25_display, font=font, fill=text_colour)
            draw.text((0, 40), pm1_display, font=font, fill=text_colour)
            draw.text((0, 60), tempf_display, font=font, fill=text_colour)
            draw.text((80, 60), noise_display, font=font, fill=text_colour)
        disp.display(img)
        time.sleep(60)</code></pre><p>This is a basic if else statement that has the following rules:</p><ul><li>If gas is higher than the average + 5% (indicating a spike) push an alarm to the Pi's display</li><li>If gas is ok, but PM2.5 pikes over 50 push an alarm to the Pi's display</li><li>Otherwise just show the PM numbers, Temp and Noise</li></ul><p>As you can see it's all pretty straightforward code in one big loop. If you just copy and paste the code following, add your Adafruit key, and do some additional setup in Adafruit IO you can have this up and running very quickly.</p><h2 id="the-complete-code">The Complete Code</h2><pre><code>import psutil
from gpiozero import CPUTemperature
import time
import datetime
from Adafruit_IO import Client
from bme280 import BME280
from enviroplus.noise import Noise
import colorsys
import sys
import ST7735
try:
    # Transitional fix for breaking change in LTR559
    from ltr559 import LTR559
    ltr559 = LTR559()
except ImportError:
    import ltr559

try:
    from smbus2 import SMBus
except ImportError:
    from smbus import SMBus


from pms5003 import PMS5003, ReadTimeoutError as pmsReadTimeoutError, SerialTimeoutError
from enviroplus import gas
from subprocess import PIPE, Popen
from PIL import Image
from PIL import ImageDraw
from PIL import ImageFont
from fonts.ttf import RobotoMedium as UserFont
from datetime import timedelta



# Initial Setup of sensors / API
bus = SMBus(1)
bme280 = BME280(i2c_dev=bus)
aio = Client('XXX', 'aio_XXX')
pms5003 = PMS5003()
noise = Noise()

# Create LCD class instance.
disp = ST7735.ST7735(
    port=0,
    cs=1,
    dc=9,
    backlight=12,
    rotation=270,
    spi_speed_hz=10000000
)

# Create array for averages
gas_array = []
cpu_temps = []

# Initialize display.
disp.begin()

# Width and height to calculate text position.
WIDTH = disp.width
HEIGHT = disp.height

# New canvas to draw on.
img = Image.new('RGB', (WIDTH, HEIGHT), color=(0, 0, 0))
draw = ImageDraw.Draw(img)

# Text settings.
font_size = 20
small_font_size = 12
font = ImageFont.truetype(UserFont, font_size)
small_font = ImageFont.truetype(UserFont, small_font_size)
text_colour = (255, 255, 255)
back_colour = (0, 0, 0)
#size_x, size_y = draw.textsize(message, font)
warning = "Warning!"

# Calculate text position
#x = (WIDTH - size_x) / 2
#y = (HEIGHT / 2) - (size_y / 2)
x = 0
y = 0


def warm_func():
    currentTime = datetime.datetime.now()
    draw.rectangle((0, 0, 160, 80), (30, 160, 30))
    draw.text((10, 20), "Warming Up", font=font, fill=text_colour)
    draw.text((0, 66), currentTime.strftime("%a, %b %d %I:%M:%S %p"), font=small_font, fill=text_colour)
    disp.display(img)
    print("Warming Up at " + currentTime.strftime("%a, %b %d %I:%M:%S %p"))

def cpu_report_func():
    # Get CPU Info
    cpu = CPUTemperature()
    aio.send('cpu-temp', round(cpu.temperature * 1.8 + 32))
    aio.send('cpu', psutil.cpu_percent())

def noise_func():
    # Get Noise
    global noise_amount, noise_display
    noise_amount = noise.get_amplitude_at_frequency_range(20, 8000)
    noise_display = str(int(round(noise_amount * 100))) + " db"
    aio.send('noise', int(round(noise_amount * 100)))

def temp_func():
    # Read Temp, convert to F and adjust
    global tempf_display
    # Tuning factor for compensation. Decrease this number to adjust the
    # temperature down, and increase to adjust up
    factor = 0.6

    cpu_temp = CPUTemperature().temperature
    #print("CPU Temp: " + str(cpu_temp))
    cpu_temps.append(cpu_temp)
    avg_cpu_temp = sum(cpu_temps) / float(len(cpu_temps))
    raw_temp = bme280.get_temperature()
    comp_temp = raw_temp - ((avg_cpu_temp - raw_temp) / factor)
    # Convert to America
    tempf = round(comp_temp * 1.8 + 32)
    
    tempf_display = "" + str(tempf) + " F"
    print(tempf_display)

    # Clean up Array …</code></pre></section></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.drkpxl.com/pollution-gas-and-noise-monitoring-with-raspberry-pi/">https://www.drkpxl.com/pollution-gas-and-noise-monitoring-with-raspberry-pi/</a></em></p>]]>
            </description>
            <link>https://www.drkpxl.com/pollution-gas-and-noise-monitoring-with-raspberry-pi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24652488</guid>
            <pubDate>Thu, 01 Oct 2020 16:03:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Streaming Netflix 4K on macOS Big Sur requires a Mac with a T2 security chip]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24652462">thread link</a>) | @bangonkeyboard
<br/>
October 1, 2020 | https://appleterm.com/2020/09/30/streaming-netflix-4k-on-macos-big-sur-requires-a-mac-with-a-t2-security-chip/ | <a href="https://web.archive.org/web/*/https://appleterm.com/2020/09/30/streaming-netflix-4k-on-macos-big-sur-requires-a-mac-with-a-t2-security-chip/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" itemscope="itemscope" itemtype="https://schema.org/CreativeWork">
<div id="primary" data-v-spacing="top:bottom">
<div data-sidebar="left">
<section>
<article id="post-17376" data-structure="default:boxed">
<section data-type="type-1">

</section>
<div>
<figure><img onload="Wpfcll.r(this,true);" src="https://appleterm.com/wp-content/plugins/wp-fastest-cache-premium/pro/images/blank.gif" loading="lazy" width="1024" height="576" data-wpfc-original-src="https://appleterm.com/wp-content/uploads/2020/09/netflix-4k-needing-a-t2-secuirty-chip-rect-1-1024x576.jpg" alt="netflix 4k needing a t2 secuirty chip rect 1" data-wpfc-original-srcset="https://appleterm.com/wp-content/uploads/2020/09/netflix-4k-needing-a-t2-secuirty-chip-rect-1-1024x576.jpg 1024w, https://appleterm.com/wp-content/uploads/2020/09/netflix-4k-needing-a-t2-secuirty-chip-rect-1-300x169.jpg 300w, https://appleterm.com/wp-content/uploads/2020/09/netflix-4k-needing-a-t2-secuirty-chip-rect-1-768x432.jpg 768w, https://appleterm.com/wp-content/uploads/2020/09/netflix-4k-needing-a-t2-secuirty-chip-rect-1.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px" title="Streaming Netflix 4K on macOS Big Sur requires a Mac with a T2 security chip 1"></figure>
<p>Safari on macOS Big Sur enables websites to stream content in 4K with supported Mac displays. Given macOS Big Sur is yet to be released, it’s difficult to come to a conclusion on which websites support it and don’t. One that is known to support the feature however is Netflix, with a catch.</p>
<p>Netflix <a href="https://www.macg.co/mac/2020/09/netflix-en-4k-sur-mac-uniquement-pour-les-machines-avec-puce-t2-116775?amp&amp;__twitter_impression=true" target="_blank" rel="noopener">explains</a> in a <a href="https://help.netflix.com/fr-ca/node/55764" target="_blank" rel="noopener">support page</a> that the feature will only be available to Macs with a T2 security chip. It seems unlogical at first, however one <a href="https://www.reddit.com/r/apple/comments/j2cik9/youll_need_a_mac_with_a_t2_chip_to_be_able_to/" target="_blank" rel="noopener">Reddit</a> users tries to make sense of it:</p>
<blockquote><p>This makes zero sense to me. The only Macs, that could really benefit from 4k streaming, without an external monitor, are the 4k and 5k iMacs yet only 2 models (the Pro and the new 2020 27″) will be able to stream it. Windows machines don’t have any kind of T2 alternative and are still able to stream 4k via Edge or via the native app, their only requirement is a 7th gen intel cpu or a dedicated graphics card. Does anyone know why that is?</p></blockquote>
<p>macOS Big Sur has yet to be released to the public, however a launch this month prior to an expected revamp of the Mac lineup, including the first Apple Silicon in November is likely. Here are the supported Macs for streaming 4K Netlfix on macOS Big Sur:</p>
<ul><li>iMac Pro (late 2017)</li><li>Mac mini (late 2018)</li><li>MacBook Air ( 2018 and up)</li><li>MacBook Pro (2018 and up)</li><li>Mac Pro (2019)</li><li>iMac (2020)</li></ul>
</div><nav>
<a href="https://appleterm.com/2020/09/30/apple-says-it-was-doing-anything-to-prevent-fortnite-users-from-using-sign-in-with-apple/">
<figure><img onload="Wpfcll.r(this,true);" src="https://appleterm.com/wp-content/plugins/wp-fastest-cache-premium/pro/images/blank.gif" width="300" height="300" data-wpfc-original-src="https://appleterm.com/wp-content/uploads/2020/09/apple-cleary-moving-to-dsibale-SIWA-squ-300x300.jpg" alt="blank" loading="lazy" data-wpfc-original-srcset="https://appleterm.com/wp-content/uploads/2020/09/apple-cleary-moving-to-dsibale-SIWA-squ-300x300.jpg 300w, https://appleterm.com/wp-content/uploads/2020/09/apple-cleary-moving-to-dsibale-SIWA-squ-1024x1024.jpg 1024w, https://appleterm.com/wp-content/uploads/2020/09/apple-cleary-moving-to-dsibale-SIWA-squ-150x150.jpg 150w, https://appleterm.com/wp-content/uploads/2020/09/apple-cleary-moving-to-dsibale-SIWA-squ-768x768.jpg 768w, https://appleterm.com/wp-content/uploads/2020/09/apple-cleary-moving-to-dsibale-SIWA-squ-912x912.jpg 912w, https://appleterm.com/wp-content/uploads/2020/09/apple-cleary-moving-to-dsibale-SIWA-squ-550x550.jpg 550w, https://appleterm.com/wp-content/uploads/2020/09/apple-cleary-moving-to-dsibale-SIWA-squ-470x470.jpg 470w, https://appleterm.com/wp-content/uploads/2020/09/apple-cleary-moving-to-dsibale-SIWA-squ.jpg 1080w" sizes="(max-width: 300px) 100vw, 300px" data-object-fit="~" itemprop="image"><svg width="20px" height="15px" viewBox="0 0 20 15"><polygon points="0,7.5 5.5,13 6.4,12.1 2.4,8.1 20,8.1 20,6.9 2.4,6.9 6.4,2.9 5.5,2 "></polygon></svg><span></span></figure>
<p><span> Previous <span>Post</span> </span> <span> Emails show Apple had clear intent to disable Sign in with Apple for Fortnite users, contradicting public statements </span></p></a>
<a href="https://appleterm.com/2020/10/01/iphone-12-series-to-include-5-models-not-4-according-to-a-new-report/">
<p><span> Next <span>Post</span> </span> <span> iPhone 12 series to include 5 models, not 4, according to a new report </span></p><figure><img onload="Wpfcll.r(this,true);" src="https://appleterm.com/wp-content/plugins/wp-fastest-cache-premium/pro/images/blank.gif" width="300" height="300" data-wpfc-original-src="https://appleterm.com/wp-content/uploads/2020/10/iphone-12-having-5-not-4-models-squ-300x300.jpg" alt="blank" loading="lazy" data-wpfc-original-srcset="https://appleterm.com/wp-content/uploads/2020/10/iphone-12-having-5-not-4-models-squ-300x300.jpg 300w, https://appleterm.com/wp-content/uploads/2020/10/iphone-12-having-5-not-4-models-squ-1024x1024.jpg 1024w, https://appleterm.com/wp-content/uploads/2020/10/iphone-12-having-5-not-4-models-squ-150x150.jpg 150w, https://appleterm.com/wp-content/uploads/2020/10/iphone-12-having-5-not-4-models-squ-768x768.jpg 768w, https://appleterm.com/wp-content/uploads/2020/10/iphone-12-having-5-not-4-models-squ-912x912.jpg 912w, https://appleterm.com/wp-content/uploads/2020/10/iphone-12-having-5-not-4-models-squ-550x550.jpg 550w, https://appleterm.com/wp-content/uploads/2020/10/iphone-12-having-5-not-4-models-squ-470x470.jpg 470w, https://appleterm.com/wp-content/uploads/2020/10/iphone-12-having-5-not-4-models-squ.jpg 1080w" sizes="(max-width: 300px) 100vw, 300px" data-object-fit="~" itemprop="image"><svg width="20px" height="15px" viewBox="0 0 20 15"><polygon points="14.5,2 13.6,2.9 17.6,6.9 0,6.9 0,8.1 17.6,8.1 13.6,12.1 14.5,13 20,7.5 "></polygon></svg><span></span></figure> </a>
</nav>
</article>
</section>
</div></div></div></div>]]>
            </description>
            <link>https://appleterm.com/2020/09/30/streaming-netflix-4k-on-macos-big-sur-requires-a-mac-with-a-t2-security-chip/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24652462</guid>
            <pubDate>Thu, 01 Oct 2020 16:01:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Compiling a JavaScript Neural Network in less than 500kb with NectarJS]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24652389">thread link</a>) | @seraum
<br/>
October 1, 2020 | https://nectarjs.com/compiling-a-javascript-neural-network-in-js-in-less-than-500kb/ | <a href="https://web.archive.org/web/*/https://nectarjs.com/compiling-a-javascript-neural-network-in-js-in-less-than-500kb/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-elementor-type="wp-post" data-elementor-id="527" data-elementor-settings="[]">
						<div>
							<div>
							<section data-id="4740b1" data-element_type="section">
						<div>
							<div>
					<div data-id="76f1811" data-element_type="column">
			<div>
							<div>
						<div data-id="7c2eb337" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img width="707" height="707" src="https://nectarjs.com/wp-content/uploads/2020/06/adrien.jpg" alt="" loading="lazy" srcset="https://nectarjs.com/wp-content/uploads/2020/06/adrien.jpg 707w, https://nectarjs.com/wp-content/uploads/2020/06/adrien-300x300.jpg 300w, https://nectarjs.com/wp-content/uploads/2020/06/adrien-150x150.jpg 150w, https://nectarjs.com/wp-content/uploads/2020/06/adrien-570x570.jpg 570w, https://nectarjs.com/wp-content/uploads/2020/06/adrien-510x510.jpg 510w" sizes="(max-width: 707px) 100vw, 707px">											</p>
				</div>
				</div>
				
				
				
				
						</div>
					</div>
		</div>
				<div data-id="13b89b9d" data-element_type="column">
			<div>
							<div>
						
				<div data-id="5b0756a1" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>Reaching a new milestone in the NectarJS journey,&nbsp;<span>an open source JavaScript native compiler (</span><a href="https://github.com/nectarjs/nectarjs" target="_blank" rel="noopener">Github repo</a><span>).</span></p>
				</div>
				</div>
				
				<div data-id="1d7f6c5" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><span>For the version 0.7, we started a big refactoring of the code, initiated by @saiv46 (on Discord). The objectives were:&nbsp;</span></p><p>– To reach a new level with the EcmaScript compliance</p><p>– To benefit of the new c++17 (and soon c++20) features.</p><p>We achieved a considerable success by covering a major part of ES3 specifications with a much simpler code base. To demonstrate what we can do with NectarJS we lately focus on compiling a Neural Network script written by @wesley1989 (thanks to him).</p></div>
				</div>
				</div>
				
				<div data-id="1c2b6be" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><span>The script we will compile is a Neural Network using classes, this, Math functions and more. The main algorithm of this script trains a XOR Neural Network.</span></p><p><span>Here is the code:</span></p></div>
				</div>
				</div>
				<div data-id="2eabc88" data-element_type="widget" data-widget_type="elementor-syntax-highlighter.default">
				<div>
			<pre><code>/*
	Neural Network example by @wesley1989
	v1.2
*/

function sigmoid(x) {
  return 1 / (1 + Math.exp(-x));
}

function derivativeOfSigmoid(y){  
  return y * (1 - y); 
}

  class Matrix {
    constructor(rows, cols) {  
      this.rows = rows;
      this.cols = cols;
      this.data = [];
      for (let i = 0; i &lt; this.rows; i++) {
          this.data[i] = [];
        for (let j = 0; j &lt; this.cols; j++) {
          this.data[i][j] = Number(((Math.random() * 2) - 1).toFixed(2)); 
        }
      }           
    }

    static transposeMatrix(matrix) {
      let result = new Matrix(matrix.cols, matrix.rows);
      for (let i = 0; i &lt; matrix.rows; i++) {
        for (let j = 0; j &lt; matrix.cols; j++) {
          result.data[j][i] = matrix.data[i][j];
        }
      }
      return result;
    }
  
    static dotProduct(matrix1, matrix2) {
      if (matrix1.cols !== matrix2.rows) {
        return 1;
      } 
      let result = new Matrix(matrix1.rows, matrix2.cols); 
      for (let i = 0; i &lt; result.rows; i++) {
        for (let j = 0; j &lt; result.cols; j++) {
          let sum = 0;
          for (let k = 0; k &lt; matrix1.cols; k++) {
            sum = sum + matrix1.data[i][k] * matrix2.data[k][j];
          }
            result.data[i][j] = sum;
            result.data[i][j] = Number((result.data[i][j]).toFixed(2))
        }
      }
       return result;
    }

    static fromArray(arr) {
      let m = new Matrix(arr.length, 1);
      for (let i = 0; i &lt; arr.length; i++) {
        m.data[i][0] = Number((arr[i]).toFixed(2));
      }
      return m;
    }
  
    static subtract(a, b) {
      let result = new Matrix(a.rows, a.cols);
      for (let i = 0; i &lt; result.rows; i++) {
        for (let j = 0; j &lt; result.cols; j++) {
          var sub = a.data[i][j] - b.data[i][j]
          result.data[i][j] = Number((sub).toFixed(2));
        }
      }
      return result;
    }
    
    static map(matrix, activation) {
      let result = new Matrix(matrix.rows, matrix.cols);
      for (let i = 0; i &lt; matrix.rows; i++) {
        for (let j = 0; j &lt; matrix.cols; j++) {
          result.data[i][j] = Number((activation(matrix.data[i][j])).toFixed(2));
        }
      }
      return result;
    }
  
    toArray() {
      let arr = [];
      for (let i = 0; i &lt; this.rows; i++) {
        for (let j = 0; j &lt; this.cols; j++) {
          arr.push(this.data[i][j]);
        }
      }
      return arr;
    }
    
    add(n) {
      if (n instanceof Matrix) {
        for (let i = 0; i &lt; this.rows; i++) {
          for (let j = 0; j &lt; this.cols; j++) {
            this.data[i][j] = this.data[i][j] + n.data[i][j];
            this.data[i][j] = Number((this.data[i][j]).toFixed(2))
          }
        }
      } else {
        for (let i = 0; i &lt; this.rows; i++) {
          for (let j = 0; j &lt; this.cols; j++) {
            this.data[i][j] =this.data[i][j] + n;
            this.data[i][j] = Number((this.data[i][j]).toFixed(2))
          }
        }
      }
    }
  
    multiply(n) {  
      if (n instanceof Matrix) {
        for (let i = 0; i &lt; this.rows; i++) {
          for (let j = 0; j &lt; this.cols; j++) {
            this.data[i][j] = this.data[i][j] * n.data[i][j];
            this.data[i][j] = Number((this.data[i][j]).toFixed(2))
          }
        }
      } else {
        for (let i = 0; i &lt; this.rows; i++) {
          for (let j = 0; j &lt;  this.cols; j++) {
            this.data[i][j] = this.data[i][j] * n;
            this.data[i][j] = Number((this.data[i][j]).toFixed(2))
          }
        }
      }
    }

    map(otherFunction) {
      for (let i = 0; i &lt; this.rows; i++) {
        for (let j = 0; j &lt; this.cols; j++) {
          this.data[i][j] = Number((otherFunction(this.data[i][j])).toFixed(2));
        }
      }
    }
  }

class NeuralNetwork {

  // length of input
  // length of output
  constructor(input_length, output_length) {
    // weights = (input length + output length) times 2 
    // for a better nn training
    this.weights_1 = new Matrix((input_length + output_length) * 2, input_length);
    this.weights_2 = new Matrix(output_length, (input_length + output_length) * 2); 
    this.bias_1 = new Matrix((input_length + output_length) * 2, 1);
    this.bias_2 = new Matrix(output_length, 1);
    this.learning_rate = 0.9;  
  }

  feed_forward(inputs) {
    let inputs_from = Matrix.fromArray(inputs);
    let hidden = Matrix.dotProduct(this.weights_1, inputs_from);
    hidden.add(this.bias_1);
    hidden.map(sigmoid);
    let output = Matrix.dotProduct(this.weights_2, hidden);
    output.add(this.bias_2);
    output.map(sigmoid);
    return output.toArray();
  }

  // feedforward with backpropagation
  train(input_array, target_array) {  
    let inputs = Matrix.fromArray(input_array);

    let hidden = Matrix.dotProduct(this.weights_1, inputs);  
    hidden.add(this.bias_1);
    hidden.map(sigmoid);
    
    let outputs = Matrix.dotProduct(this.weights_2, hidden);
    outputs.add(this.bias_2);
    outputs.map(sigmoid); 

    
    let targets = Matrix.fromArray(target_array);
    let output_errors = Matrix.subtract(targets, outputs);

    let gradients = Matrix.map(outputs,derivativeOfSigmoid);
    gradients.multiply(output_errors);
    gradients.multiply(this.learning_rate);

    let hidden_transposed = Matrix.transposeMatrix(hidden);
  
    let weights_2_deltas = Matrix.dotProduct(gradients, hidden_transposed);

    this.weights_2.add(weights_2_deltas);
    this.bias_2.add(gradients);
    let who_t = Matrix.transposeMatrix(this.weights_2);
    let hidden_errors = Matrix.dotProduct(who_t, output_errors);
    
    let hidden_gradient = Matrix.map(hidden,derivativeOfSigmoid);
    hidden_gradient.multiply(hidden_errors);
    hidden_gradient.multiply(this.learning_rate);

    let inputs_transposed = Matrix.transposeMatrix(inputs);
    let weights_1_deltas = Matrix.dotProduct(hidden_gradient, inputs_transposed);
    this.weights_1.add(weights_1_deltas);
    this.bias_1.add(hidden_gradient);
  }

}

function shuffle(a) {
  var j, x, i;
  for (i = a.length - 1; i &gt; 0; i--) {
      j = Math.floor(Math.random() * (i + 1));
      x = a[i];
      a[i] = a[j];
      a[j] = x;
  }
  return a;
  }

// XOR example
// NeuralNetwork takes as params 
// input and output length
// 2 inputs and 1 output

var NN = new NeuralNetwork(2, 1);

var defined_data = [
  {
  input:[0,0],
  output:[0]
  },
 {
  input:[0,1],
  output:[1]
},
{
  input:[1,0],
  output:[1]
},
{
  input:[1,1],
  output:[0]
},
]

for (let i = 0; i &lt; 1000; i++) {
    var shuffled = shuffle(defined_data)
    for (let j = 0; j &lt; shuffled.length; j++) {
      NN.train(shuffled[j].input,shuffled[j].output)
    }
} 

console.log("[0,1] =&gt;", NN.feed_forward([0,1]));
console.log("[0,0] =&gt;", NN.feed_forward([0,0]));
console.log("[1,0] =&gt;", NN.feed_forward([1,0]));
console.log("[1,1] =&gt;", NN.feed_forward([1,1])); </code></pre>		</div>
				</div>
				<div data-id="3ef05d2" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>And now, the compilation and execution process:</p>
				</div>
				</div>
				<div data-id="b334533" data-element_type="widget" data-widget_type="elementor-syntax-highlighter.default">
				<div>
			<pre><code>&gt; nectar neural_network.js --preset speed --run --verbose
[*] Generating source file
[*] Compiling with preset: speed

[*] Informations :

Size      : 412.16 ko
Main file : neural_network.js
Output    : C:\Users\NectarJS\Desktop\neural_network.exe
Preset    : speed

[*] Executing C:\Users\NectarJS\Desktop\neural_network.exe
[0,1] =&gt;  [ 0.95 ]
[0,0] =&gt;  [ 0.01 ]
[1,0] =&gt;  [ 0.93 ]
[1,1] =&gt;  [ 0.07 ] </code></pre>		</div>
				</div>
				<div data-id="f407729" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><strong>Hurray !</strong></p>
<p>We just compiled into a native binary a full (easy) neural network, written in JavaScript in less than 500Kb!</p>
<p>The next step is to be compliant with the ES3 specifications at more than 90% to be able to compile a big part of the JS ecosystem.</p>
<p>Stay tuned,</p>
<p>Adrien.</p>
</div>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
						</div>
						</div>
					</div></div>]]>
            </description>
            <link>https://nectarjs.com/compiling-a-javascript-neural-network-in-js-in-less-than-500kb/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24652389</guid>
            <pubDate>Thu, 01 Oct 2020 15:56:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Not to Get Fired as a CTO]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24651834">thread link</a>) | @abyx
<br/>
October 1, 2020 | https://avivbenyosef.com/how-not-to-get-fired-as-a-cto/ | <a href="https://web.archive.org/web/*/https://avivbenyosef.com/how-not-to-get-fired-as-a-cto/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1818">
	
	
	<!-- .entry-header -->

	
	<div>
		
<p>Over the past month or so, I’ve consulted several CEOs who have had trouble with their tech executives. Some are now with or searching for their third or fourth CTO/VP of Engineering. More often than not, these mismatches are not the fault of just one of the parties: both sides need to be better vetting and expectation setting as part of the hiring process. Some also need more coaching or mentoring after the tech executive has joined (for the CEO, for the tech exec, or both). If you’re a CEO hiring a tech executive or struggling with your current one, or an aspiring tech executive, here are some tips to reduce your risks of ending up in the wrong position.</p>



<h3>The Job-To-Be-Done of a Job</h3>



<p>Jobs-to-be-done (JTBD) is a framework pioneered by Clayton Christensen. If you’ve been involved in tech at all, you likely have already heard of it by now from your Product peers. In JTBD, you consider what job a product is hired to provide, be that product an app, SaaS service, a mattress, or a milkshake. Many CEOs grasp this concept when it comes to their product, but fail to do so when defining a <em>job</em>.</p>



<p>No matter if you are interviewing or being interviewed, you should clarify what job the tech executive position is intended to achieve. Failing to do so before accepting the job or making an offer will make things blow up at a later stage, which is a lot riskier and grossly more expensive to remedy.</p>



<p><em>Define Success:</em> What would be considered a success for the tech executive within the next 6, 12, and 24 months? It is near-impossible to hit a target if you don’t know how it looks like or where it is.</p>



<p><em>Define Responsibilities:</em> Tech executives are often in charge of People, Architecture, or Evangelism. <em>People</em> management is usually under a VP of Engineering, who is in charge of the delivery of software in the company, and the entire engineering team. <em>Architecture</em> has many forms, but most frequently means leading the tech capabilities of the organization or introducing technological innovation. Think Chief Architect roles, and sometimes a CTO. Lastly, <em>Evangelism</em> is used for companies that have a significant part of their product facing other technologists external to the company—platforms, SDKs, and APIs most often. A tech executive responsible for evangelism is likely to be speaking at conferences, creating partnerships, and so on. Knowing which of these responsibilities the CEO has in mind will help find the right person to fill the position.</p>



<p><em>Define Values:</em> It is vital for executives of the company to share its values and mission. However, this is not often given enough attention during interviews. Both parties should discuss their ideology, beliefs, and motivation. I’ve seen mismatches between executives and CEOs stemming from not agreeing on basic culture. Some people want to keep the scrappy, garage-like behavior for years and others prefer a more relaxed and “grown-up” way of doing things. Some people might want to work at a company that takes a political stand in areas not directly related to it, and others prefer to remain focused on what the company is working to solve. Ensure that you have an accord here.</p>



<p><em>Discuss the Path:</em> Every executive, being truly an executive and not a glorified manager, should have an idea about achieving and accomplishing the goals discussed. While not everything will be known beforehand, and some things are bound to change, candidates should have a sense of how to get these objectives done. Talking about the path forward provides both sides with more confidence: the CEO can see that there’s a plan that she can get behind, and the tech executive gains general agreement for her ideas.</p>



<h3>Sometimes It Takes Three to Tango</h3>



<p>When the tech executive is finally there and starts working, new issues will arise. It is just the way things are. However, there are situations where merely doing their best is not going to cut it. Sometimes, one of the sides needs to be coached (e.g., teaching the CEO to provide autonomy, or helping the tech executive speak business so the rest of the executive team can understand her). Other times, the relationship itself between them needs to be worked on.</p>



<p>I may be biased, as I do this for a living, but have another person involved in the first few months as a coach and advisor gets things up and running significantly faster. A typical example: CEOs often feel relieved when they hear it is perfectly natural, even for an experienced executive, to require a few months to grok the team’s situation and start showing improvement. This removes a lot of tension (the constant “did I make the right hire” question looping in their mind) and allows trust to be built.</p>



<p>If you find that you are struggling in the first few months, I highly recommend seeking support (even internally, e.g., another co-founder who’s not the CEO). </p>



<p>And, lastly, always remember that things always turn out to be different than how you first imagined them. It doesn’t necessarily mean that you made the wrong choice.</p>
 <div data-ck-version="6">   <div>   <div>     <h3>Get the Tech Executive Operating System</h3>     <p>Get the best newsletter for tech executives online. Tailored for your daily work. Weekly, short, and packed with exclusive insights.</p>            <!--  Form starts here  -->        </div>  </div>  </div>    			</div><!-- .entry-content -->

	<!-- .entry-footer -->

	
</article></div>]]>
            </description>
            <link>https://avivbenyosef.com/how-not-to-get-fired-as-a-cto/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24651834</guid>
            <pubDate>Thu, 01 Oct 2020 15:14:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Testing TikTok’s multi-billion dollar algorithm]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24651822">thread link</a>) | @ailon
<br/>
October 1, 2020 | https://blog.ailon.org/testing-tiktoks-multi-billion-dollar-algorithm-af38fdd8225?source=friends_link&sk=a736bbdd904768fa4d7bcfb536615573 | <a href="https://web.archive.org/web/*/https://blog.ailon.org/testing-tiktoks-multi-billion-dollar-algorithm-af38fdd8225?source=friends_link&sk=a736bbdd904768fa4d7bcfb536615573">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p id="aae4">Almost a month ago my wife wanted to register on TikTok and was experiencing some odd difficulties. As our family’s tech-support person I ended up registering myself in the process of helping her. After posting a random TikTok (again, to help with some issues) I realized that it’s a good opportunity to put TikTok’s mighty algorithm to the test.</p><p id="8ee7">Since I went deep(ish) into my music making hobby this year, I decided to make <a href="https://www.tiktok.com/@ailonid" rel="noopener">my TikTok</a> focused on that. Both as a content consumer and creator. To try to preserve the “purity” of the experiment I decided not to tell anyone about my TikTok for the duration of this experiment. Well, my wife knew, obviously, and “contaminated” the results a bit. But I don’t think that was a major factor. So, here’s what I find out…</p><h2 id="168f">TikTok’s Algorithm for Consumers</h2><p id="571d">In the onboarding process you get asked very little. You pick some very wide-ranging themes of interest like entertainment, sports, music, etc. And that’s about it. Not surprisingly the initial experience is quite random — you get a bunch of half-naked beautiful people, kitty-puppy videos, poor dad joke reenactments and alike.</p><p id="c9fc">I tried not to “like” any of the above and not to follow any celebrities. I went into search and tried to look up people posting TikToks about music production, music theory, audio engineering, music business and similar. After I followed a bunch of those not much changed in the first couple of days. But then my “For You” feed (TikTok’s algorithmic feed) improved dramatically and became quite on-point.</p><p id="8d99">Interestingly, I was traveling for a couple of days (yes, this still happens once in a while in our neck of the woods) and didn’t use TikTok for a day or two. When I launched it after the break I got quite an increase in “funny” videos again. I guess this is AI’s idea of how to best “reactivate” churning users. But after a day or two it got back to my regular programming.</p><p id="a2bb">So, from the consumer’s side the algorithm works quite well. On the other hand, so does the algorithm on YouTube or Instagram. As <a href="https://twitter.com/mattcutts" rel="noopener">Matt Cutts</a> (one of the early Googlers) <a href="https://youtu.be/kpmbptHDVJg?t=1335" rel="noopener">said on TWiT</a>:</p><blockquote><p id="8242">You can probably do a pretty good approximation [of TikTok’s algorithm] in like a thousand lines of code. You are looking for engagement, you are looking for growth, you are looking at the first derivative… it’s gonna be pretty simple…</p></blockquote><p id="4112">In any case, it does work fine but this wasn’t the most interesting part to me. I’d be more surprised if it didn’t work well for consumers.</p><p id="cde4">What I was more interested in is the constant stream of raving comments on how well it works for creators — “nobodies” can reach millions with a good video, they said. Let’s see how that works…</p><h2 id="3e43">TikTok’s Algorithm for Creators</h2><p id="1833">I tried to post TikToks regularly. Not exactly every day but so far I posted 17 videos in about 4 weeks.</p><p id="8bc1">Quite obviously TikTok’s “hook” is that they over-expose TikToks from newbies and make you feel really good in your first few days. (How do they deal with bots and trolls trying to abuse this is an interesting question but beside the point here.) My first 5 TikToks (the first one was just a random test) got between 500 and 700 views. Not bad for someone with 1 follower. But then the views started to go down.</p><p id="2433">Obviously, I didn’t produce any stunning content and I don’t think I deserve more views from the algorithm pushing me. But I’ve noticed something peculiar…</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2070/1*TlzZOu5ZTizu7xsCT9oaNQ.png" width="1035" height="483" srcset="https://miro.medium.com/max/552/1*TlzZOu5ZTizu7xsCT9oaNQ.png 276w, https://miro.medium.com/max/1104/1*TlzZOu5ZTizu7xsCT9oaNQ.png 552w, https://miro.medium.com/max/1280/1*TlzZOu5ZTizu7xsCT9oaNQ.png 640w, https://miro.medium.com/max/1400/1*TlzZOu5ZTizu7xsCT9oaNQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*TlzZOu5ZTizu7xsCT9oaNQ.png?q=20"></p></div></div></div><figcaption>Typical stats for most of my recent TikToks</figcaption></figure><p id="2de3">While all of my TikToks (except one) are in [mostly broken] English, and I added relevant hashtags and descriptions in English, they were primarily shown in my home country of Lithuania. That’s a very small niche. Add that TikToks were for a niche subject of “music-making” and you get close to zero of overlap.</p><p id="2d64">Interestingly, I got similar results on a couple of videos that I posted from Poland and Germany.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1012/1*A0bxyk6k9iMsg6XC5xs4kg.png" width="506" height="368" srcset="https://miro.medium.com/max/552/1*A0bxyk6k9iMsg6XC5xs4kg.png 276w, https://miro.medium.com/max/1012/1*A0bxyk6k9iMsg6XC5xs4kg.png 506w" sizes="506px" data-old-src="https://miro.medium.com/max/60/1*A0bxyk6k9iMsg6XC5xs4kg.png?q=20"></p></div></div><figcaption>Stats for TikTok posted from Germany</figcaption></figure><p id="d459">As you can see there’s Germany present here but the majority is still from Lithuania. The one from Poland had more Polish viewers but still fewer than Lithuanians. (FYI, the population of Poland is about 14x of Lithuania)</p><p id="569a">So the “almighty algorithm” somehow prioritizes your profile’s country over everything else. Not very smart, if you ask me. You may not notice this if you live in the US or some other big country, or if you create content for your local market. But, anecdotally, it feels like TikTok’s algorithm is quite discriminatory towards people from small countries trying to create global content.</p><p id="9aa2">To add insult to injury, I’m pretty sure TikTok never asked me for my country (I registered with email address, not phone or other account), and it doesn’t require location permissions (kudos for that). So basically they took my IP address at the time of registration and hard-coded my profile’s country to what they got from the IP lookup. Good thing I didn’t register at the office as many services think we are in Norway based on that IP. Or maybe that’s a bad thing given my goals.</p><blockquote><p id="e552"><strong>Untested pro-tip</strong>: create your account over VPN to US (or whatever location you care about) for better distribution.</p></blockquote><p id="5b0f">The bottom line is that TikTok’s algorithm still gave me more exposure than probably any other service would, considering I didn’t do anything to assist it (I didn’t tell anyone about my TikTok, remember?). Having said that, it handicapped me for no apparent reason purely based on my home country.</p><p id="2686">And that’s the main problem with all the algorithmic social media — you are at the mercy of a bunch of “if-then” statements with their bugs, quirks, and oddities.</p><p id="cef8">Now that you know <a href="https://www.tiktok.com/@ailonid" rel="noopener">I have TikTok</a>, we can proceed to the phase 2 of the experiment. If you are even remotely interested in music production and don’t live in Lithuania, please <a href="https://www.tiktok.com/@ailonid" rel="noopener">follow me on TikTok @ailonid</a> and in another month I will report if having followers outside of Lithuania had any impact on the algorithm.</p></div></div></div>]]>
            </description>
            <link>https://blog.ailon.org/testing-tiktoks-multi-billion-dollar-algorithm-af38fdd8225?source=friends_link&amp;sk=a736bbdd904768fa4d7bcfb536615573</link>
            <guid isPermaLink="false">hacker-news-small-sites-24651822</guid>
            <pubDate>Thu, 01 Oct 2020 15:13:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Julian Assange Acted Responsibly]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24651796">thread link</a>) | @DiogenesKynikos
<br/>
October 1, 2020 | https://www.republik.ch/2020/10/01/julian-assange-ist-verantwortungsvoll-mit-den-daten-umgegangen | <a href="https://web.archive.org/web/*/https://www.republik.ch/2020/10/01/julian-assange-ist-verantwortungsvoll-mit-den-daten-umgegangen">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div data-css-88vvl0=""><p data-pos="0-0" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Der Bieler Professor Christian Grothoff hat keine Ahnung, wer M.Â&nbsp;I.Â&nbsp;A. ist. Schade eigentlich. Schon allein wegen ihres spektakulÃ¤ren, verstÃ¶renden und kontrovers diskutierten Ausblicks auf das Trump-Zeitalter aus dem Jahr 2010, des zehnÂ­minÃ¼tigen Videos zu ihrer Single Â«Born FreeÂ». Darin werden in einer alternativen RealitÃ¤t Rothaarige als verfolgte ethnische Minderheit von paraÂ­militÃ¤rischen US-Truppen zu Tode gejagt.</p><figure data-pos="0-1" data-css-1esus25=""><a data-css-11au926=""><span data-css-mcluq8=""><svg width="26" height="36.01" viewBox="0 0 26 36"><path d="M25.956 18.188L.894 35.718V.66" fill="#fff"></path></svg></span><span data-css-fijd0m="">Dies ist ein Vimeo-Video. Wenn Sie das Video abspielen, kann Vimeo Sie tracken.</span><span data-css-1bqahl="" role="img" aria-label=""></span></a><figcaption data-css-s9b1dj="" data-css-qc9yqx="">M.I.A, Born Free</figcaption></figure><p data-pos="0-2" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">DafÃ¼r weiss M.Â&nbsp;I.Â&nbsp;A. aber, wer Christian Grothoff ist.</p><p data-pos="0-3" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">M.Â&nbsp;I.Â&nbsp;A.Â&nbsp;â€“ jene englische Rapperin, die 2012 von der NFL auf eine Million Dollar SchadenÂ­ersatz verklagt worden war, weil sie wÃ¤hrend ihres Super-Bowl-PausenÂ­auftritts mit Nicki Minaj und Madonna den MittelÂ­finger <a href="https://www.youtube.com/watch?v=qlEUz1IlN70&amp;ab_channel=ATownHR23" data-css-9r2oe9="" data-css-1exity3="">in die Kameras gehalten hatte</a>. Oder 2016: Verklagt vom FussballÂ­club Paris Saint-Germain, weil sie im Video zu ihrem Song Â«BordersÂ» ein T-Shirt des franzÃ¶sischen Vereins trug und dabei den SchriftÂ­zug des Sponsors Â«Fly EmiratesÂ» <a href="https://www.youtube.com/watch?v=r-Nw7HbaeWY&amp;ab_channel=MIAVEVO" data-css-9r2oe9="" data-css-1exity3="">in Â«Fly PiratesÂ» abgeÃ¤ndert hatte</a>. </p><p data-pos="0-4" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Die 45-jÃ¤hrige Musikerin und politische Aktivistin setzt sich derzeit mit zahlÂ­reichen KÃ¼nstlerinnen, darunter <a href="https://www.washingtonpost.com/entertainment/dissident-ai-weiwei-protests-possible-extradition-of-assange/2020/09/28/89e17c56-0183-11eb-b92e-029676f9ebec_story.html" data-css-9r2oe9="" data-css-1exity3="">Ai Weiwei oder Designerin Vivienne Westwood</a>, dafÃ¼r ein, dass Wikileaks-GrÃ¼nder Julian Assange nicht an die USA ausgeliefert wird. Seit dem 7.Â&nbsp;September lÃ¤uft an einem Londoner Gericht die zweite Runde des AuslieferungsÂ­verfahrens, das wegen Covid-19 im April unterbrochen worden war. Die USA beschuldigen Assange, mit der VerÃ¶ffentlichung von 250â€™000Â&nbsp;Depeschen aus US-Botschaften das Leben von Diplomaten und amerikanischen Helfern weltweit gefÃ¤hrdet zu haben.</p><h2 data-css-153qrt7="" data-css-qc9yqx=""><a data-css-1i4zy90="" id="der-zeuge-aus-der-schweiz"></a>Der Zeuge aus der Schweiz</h2><p data-pos="0-6" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">M.Â&nbsp;I.Â&nbsp;A. war es mÃ¶glich, das Verfahren per VideoÂ­stream live zu verfolgenÂ&nbsp;â€“ was alles andere als selbstÂ­verstÃ¤ndlich ist: Im Gericht waren fÃ¼r die neue AnhÃ¶rungsÂ­runde nur noch fÃ¼nf Journalistinnen und ein paar wenige GÃ¤ste zugelassen, diversen ProzessÂ­beobachtern wie Amnesty International wurde am ersten AnhÃ¶rungsÂ­tag kurzfristig der Zugang verweigert, zugesagte BeobachterÂ­plÃ¤tze wurden gestrichen, ihnen wurde zusammen mit vierzig anderen Organisationen oder akkreditierten Medien die MÃ¶glichkeit entzogen, <a href="https://www.amnesty.org/en/latest/news/2020/09/why-are-amnesty-international-monitors-not-able-to-observe-the-assange-hearing/" data-css-9r2oe9="" data-css-1exity3="">das Verfahren wenigstens per Stream verfolgen zu kÃ¶nnen</a>.</p><p data-pos="0-7" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Dieser Vorgang wurde laut Amnesty International <a href="https://www.amnesty.org/en/latest/news/2020/09/why-are-amnesty-international-monitors-not-able-to-observe-the-assange-hearing/" data-css-9r2oe9="" data-css-1exity3="">nicht weiter begrÃ¼ndet</a> und sei Â«sehr beunruhigendÂ». Â«Mit diesem Schritt missachtet das Gericht das GrundÂ­prinzip der Ã–ffentlichkeitÂ», schrieb die MenschenrechtsÂ­organisation: Â«Konkret, dass internationale ProzessÂ­beobachterinnen nachvollziehen kÃ¶nnen, ob nationales und internationales Recht eingehalten wird.Â» Und dies in einem Verfahren, in dem die RechtÂ­sprechung sowieso ziemlich eigenwillig interpretiert wird. Assange, dem der Zugang zu seinen eigenen AnwÃ¤lten in den letzten sechs Monaten verweigert worden war, sitzt mittlerweile seit 16Â&nbsp;Monaten ohne juristische Grundlage in IsolationsÂ­haft, wasÂ&nbsp;â€“ Grundlage hin oder herÂ&nbsp;â€“ als Folter gesehen werden muss. (Sein Vergehen, <a href="https://www.forbes.com/sites/thomasbrewster/2019/05/01/assange-given-50-weeks-in-prison-for-breaking-bail/#2af1cd5fa1d8" data-css-9r2oe9="" data-css-1exity3="">der Verstoss gegen Kautionsauflagen</a>, wird in Grossbritannien normalerÂ­weise nicht einmal mit einer kurzen GefÃ¤ngnisÂ­strafe geahndet.)</p><p data-pos="0-8" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">M.Â&nbsp;I.Â&nbsp;A. also war es mÃ¶glich, den Prozess live zu verfolgen.</p><p data-pos="0-9" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Und am Morgen des 21.Â&nbsp;September twitterte die Rapperin:</p><div data-css-wnj6iv="" data-pos="0-10"><p data-css-87w1y="" data-css-5rrfwp="">Â«Ich beobachtete diesen Zeugen. Ziemlich intensive Befragung, sogar die Richterin wurde wÃ¼tend wegen des schonungsÂ­losen KreuzÂ­verhÃ¶rs, das er zu erdulden hatte. Ich empfehle es allen: Studiert bei Professor Dr.Â&nbsp;Christian Grothoff. Grothoff ist Professor der Informatik in der Schweiz. Er war brillant.Â»</p><figcaption data-css-s9b1dj="" data-css-qc9yqx=""><a href="https://twitter.com/MIAuniverse/status/1308129185240580096" data-css-9r2oe9="" data-css-1exity3="">Tweet von @MIAuniverse</a></figcaption></div><p data-pos="0-11" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Am Tag darauf rief ich den InformatikÂ­professor an. </p><figure data-pos="0-12" data-css-j57vv8=""><figcaption data-css-s9b1dj="" data-css-qc9yqx="">Â«Mit dem nÃ¶tigen FachÂ­wissen lÃ¤sst sich alles Schritt fÃ¼r Schritt nachvollziehenÂ»: Christian Grothoff. <span data-css-puup3u="">Martin Gross/youtube/gnunet</span></figcaption></figure><p data-pos="0-13" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Â«KÃ¶nnen Sie mir sagen, was da los war?Â», fragte ich.</p><p data-pos="0-14" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Â«Ja, natÃ¼rlichÂ», sagt er. Â«Nach meinem Auftritt vor Gericht ist es mir jetzt erlaubt, meine Erkenntnisse mit der Presse zu teilen.Â»</p><p data-pos="0-15" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Â«Sie waren Zeuge im Assange-Prozess?Â»</p><p data-pos="0-16" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Â«JaÂ», sagte Professor Grothoff. Â«Ich habe meine Expertise dem Gericht zur VerfÃ¼gung gestellt, einen dicken Stapel Unterlagen.Â»</p><p data-pos="0-17" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Â«Was fÃ¼r eine Expertise?Â»</p><p data-pos="0-18" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Â«Ich sollte im Auftrag der Verteidigung nach bestem Wissen und Gewissen analysieren, wie es dazu kam, dass die DiplomatenÂ­depeschen, die Chelsea Manning Wikileaks Ã¼bergeben hatte, spÃ¤ter komplett ungeschwÃ¤rzt im Internet kursierten. Das ist ja eigentlich einer der zentralen AnklageÂ­punkte: Diese Publikation der gesamten Depeschen. Wer hat sie zuerst ins Netz gestellt? Wikileaks, wie es die USA behaupten?Â»</p><p data-pos="0-19" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Â«Haben Sie eine Antwort gefunden?Â»</p><p data-pos="0-20" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Â«Mit dem nÃ¶tigen FachÂ­wissen lÃ¤sst sich alles Schritt fÃ¼r Schritt nachvollziehen.Â»</p><p data-pos="0-21" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Wir trafen uns einen Tag spÃ¤ter zum AbendÂ­essen in einem chinesischen Imbiss in der Berner Altstadt.</p><h2 data-css-153qrt7="" data-css-qc9yqx=""><a data-css-1i4zy90="" id="die-hauptschuld-liegt-beim-guardian"></a>Â«Die Hauptschuld liegt beim â€¹Guardianâ€ºÂ»</h2><p data-pos="0-23" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Und die Geschichte, die der Bieler Professor Christian Grothoff an jenem Abend im September zu erzÃ¤hlen hat, ist hÃ¶chst erstaunlich.</p><figure data-pos="0-24" data-css-j57vv8=""><figcaption data-css-s9b1dj="" data-css-qc9yqx="">Assange-UnterstÃ¼tzerinnen: Chelsea Manning (Mitte) und Dame Vivienne Westwood, hier mit ihrem Mann Andreas Kronthaler. <span data-css-puup3u="">David M. Benett/Getty Images</span></figcaption></figure><p data-pos="0-25" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Zehn Jahre lang <a href="https://www.bbc.com/news/technology-37165230" data-css-9r2oe9="" data-css-1exity3="">behaupteten die US-BehÃ¶rden (ohne jemals einen einzigen Beweis dafÃ¼r zu erbringen</a>), dass Julian Assange MenschenÂ­leben gefÃ¤hrdet habe, weil er die ihm von Chelsea Manning anvertrauten diplomatischen Depeschen der US-Regierung komplett und einfach so ins Netz gestellt habe, und deswegen sei Assange kein Journalist.</p><p data-pos="0-26" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Die ErzÃ¤hlung von der GefÃ¤hrdung hat sich bis heute gehalten, obwohl Mitarbeitende des State Department bereits Ende 2010 gegenÃ¼ber dem US-Kongress hatten durchsickern lassen (wÃ¤hrend die Obama-Administration Ã¶ffentlich das Gegenteil behauptete), <a href="https://www.reuters.com/article/us-wikileaks-damage-idUSTRE70H6TO20110118" data-css-9r2oe9="" data-css-1exity3="">dass Wikileaks die USA zwar blossgestellt habe, dabei aber niemand zu Schaden gekommen sei</a>.</p><p data-pos="0-27" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Bei seiner Analyse fand Grothoff zudem heraus: Die BehauptungÂ&nbsp;â€“ ein zentraler AnklageÂ­punkt der US-JustizÂ&nbsp;â€“, Wikileaks habe als erste Quelle die Depeschen komplett und unbearbeitet ins Netz gestellt und sei deshalb unter dem Â«Espionage ActÂ» zu verfolgen, ist nachweislich falsch. Mit dem nÃ¶tigen FachÂ­wissen sei im Netz nachvollziehbar und unzweifelhaft belegbar, so Grothoff in seiner Expertise, dass Wikileaks erst im Nachgang die gesamten Depeschen publiziert habeÂ&nbsp;â€“ nachdem diese von anderen Quellen bereits online gestellt worden waren.</p><p data-pos="0-28" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Der Informatiker Christian Grothoff mit akademischen und beruflichen Stationen in Los Angeles, Denver, MÃ¼nchen und Rennes ist ein international angesehener Fachmann unter anderem fÃ¼r VerschlÃ¼sselungsÂ­techniken, aber auch in der Analyse von Peer-to-Peer-Netzwerken und der Ãœberlastung von Servern zum Beispiel durch sogenannte DDOS-Angriffe.</p><p data-pos="0-29" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Kurz: Grothoff vereint so ziemlich das ganze FachÂ­wissen, das in dieser Angelegenheit gefragt ist.</p><p data-pos="0-30" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Â«Es ist im Ãœbrigen so, dass Assange die diplomatischen Depeschen derart gut geschÃ¼tzt hatÂ», sagte Grothoff im GesprÃ¤ch mit der Republik und auch vor Gericht, Â«dass sie auch von der NSA nicht hÃ¤tten geknackt werden kÃ¶nnen.Â»</p><p data-pos="0-31" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Das Bild, das Grothoff stattdessen zeichnet, ist ein ArmutsÂ­zeugnis fÃ¼r den Journalismus: Die Journalisten des Â«GuardianÂ», mit denen sich Assange bald Ã¼berwarf, hefteten sich wie BlutÂ­sauger an den Wikileaks-GrÃ¼nder, um mit seiner Hilfe die grossen Geschichten fahren zu kÃ¶nnen. Der Â«GuardianÂ»-Journalist David Leigh Ã¼bte dabei massiven Druck auf Assange aus: Er solle ihm das Passwort fÃ¼r die verschlÃ¼sselten Depeschen nennen, fÃ¼r den Fall, dass Assange verhaftet werde und dann keine weiteren Geschichten mehr publiziert werden kÃ¶nnten.</p><p data-pos="0-32" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Die Quelle dafÃ¼r: das Buch Â«Wikileaks: Inside Julian Assangeâ€™s War on SecrecyÂ», das David Leigh im Februar 2011 selbst publiziert hatte. Dort steht auch, Assange habe schliesslich eingewilligt, Leigh das Passwort auszuhÃ¤ndigenÂ&nbsp;â€“ mit der eindringlichen Bitte, es niemals irgendwo als Ganzes aufzuschreiben.</p><p data-pos="0-33" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Â«Assange, das steht in meiner Expertise fÃ¼r das Gericht, ist verantwortungsÂ­voll mit den Daten umgegangenÂ», sagt Grothoff. Â«Das lÃ¤sst sich alles nachvollziehen und belegen.Â» Doch was nach der PasswortÂ­Ã¼bergabe passiert sei, kÃ¶nne er als Fachmann nur als Â«grob fahrlÃ¤ssigÂ» bezeichnen, und zwar nicht von Wikileaks, sondern vom Â«GuardianÂ»: Â«Der Journalist David Leigh schwatzt Julian Assange das Passwort abÂ&nbsp;â€“ und dann publiziert er es ein paar Monate spÃ¤ter als KapitelÂ­titel in seinem Buch â€¹Inside Wikileaksâ€º.Â»</p><p data-pos="0-34" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Ja, Sie haben richtig gelesen.</p><p data-pos="0-35" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Das Passwort, 58Â&nbsp;Buchstaben, Ziffern und SonderÂ­zeichen, als Ãœberschrift in einem Buch. Der Â«GuardianÂ»-Journalist habe spÃ¤ter behauptet, er sei davon ausgegangen, das Passwort sei veraltet gewesen. Als VerschlÃ¼sselungsÂ­experte, sagte Grothoff, mÃ¼sse er entgegnen, dass man in der Pflicht sei, sich zu informieren, mit welcher Technik man es zu tun habe, wenn man mit derartig sensiblen Daten operiere. </p><p data-pos="0-36" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Es dauerte nicht lange, da wurde in den Medien (namentlich im Â«FreitagÂ» und im Â«SpiegelÂ») ein ZusammenÂ­hang zwischen dem Passwort aus dem Buch des Â«GuardianÂ»-Journalisten und der Depeschen-Datei hergestellt, die nach massiven sogenannten DDOS-Angriffen auf den Wikileaks-Server (Angriffe, um den Server lahmzulegen) und Spiegelungen ebenjenes Servers durch Dritte irgendwo unkontrolliert als Kopie in den Weiten des Netzes umherschwirrte. Am 1.Â&nbsp;September 2011 sei diese dann unverschlÃ¼sselt auf einer Plattform namens Â«CryptomeÂ» aufgetaucht. </p><p data-pos="0-37" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">TatsÃ¤chlich sagte der Betreiber von Â«CryptomeÂ» nun vor dem Londoner Gericht aus, er habe als Erster die Depeschen vollumfÃ¤nglich, ungeschwÃ¤rzt und unverschlÃ¼sselt hochgeladenÂ&nbsp;â€“ <a href="https://www.fr24news.com/a/2020/09/us-never-asked-wikileaks-rival-to-remove-leaking-cables-court-says-julian-assange.html" data-css-9r2oe9="" data-css-1exity3="">und bis heute habe die US-Regierung bei ihm nichts von sich hÃ¶ren lassen</a>.</p><p data-pos="0-38" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Â«Die Depeschen finden sich immer noch dortÂ», sagt Grothoff. </p><p data-pos="0-39" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Es sei problemlos chronologisch aufzuzeigen, sagte InformatikÂ­professor Grothoff im Berner Imbiss, dass die HauptÂ­schuld fÃ¼r die Publikation der gesamten Depeschen beim Â«GuardianÂ» liege. Â«WÃ¤re man …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.republik.ch/2020/10/01/julian-assange-ist-verantwortungsvoll-mit-den-daten-umgegangen">https://www.republik.ch/2020/10/01/julian-assange-ist-verantwortungsvoll-mit-den-daten-umgegangen</a></em></p>]]>
            </description>
            <link>https://www.republik.ch/2020/10/01/julian-assange-ist-verantwortungsvoll-mit-den-daten-umgegangen</link>
            <guid isPermaLink="false">hacker-news-small-sites-24651796</guid>
            <pubDate>Thu, 01 Oct 2020 15:11:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on QA]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24651571">thread link</a>) | @tigranhakobian
<br/>
October 1, 2020 | https://blog.superannotate.com/how-to-detect-mislabeled-annotations | <a href="https://web.archive.org/web/*/https://blog.superannotate.com/how-to-detect-mislabeled-annotations">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p><em>Manual QA is a significant part of the annotation pipeline. Annotation companies report that 40 percent of the annotation time can be spent on manual QA. As a result, finding ways to reduce QA testing time can have a significant impact on annotation costs.&nbsp;</em></p>
<!--more--><p><em>At SuperAnnotate, we’ve developed a tool to accelerate the QA process. This article discusses SuperAnnotate’s features that speed up the quality assurance process substantially. It presents several automation tools within the platform listing specific use cases in which a major acceleration of the QA process can be obtained. We also explored various ML algorithms that can detect over 90 percent of mislabeled instances in data while accelerating the QA process up to 4 times.&nbsp;</em></p>
<h3><strong><span>Outline</span></strong></h3>
<ul>
<li><em>Problem with noisy annotation in data&nbsp;</em></li>
<li><em>Manual QA acceleration</em></li>
<li><em>QA automation</em></li>
<li><em>Conclusion</em></li>
</ul>
<h2><span>Problem with annotation noise in data</span></h2>
<p><strong><span>1.1. The importance of model accuracy and the impact of annotation noise&nbsp;&nbsp;</span></strong></p>
<p>In real-world applications, the performance of machine learning (ML) systems is of crucial importance. ML models heavily rely on the quality of annotated data, but obtaining high-quality annotations is costly and requires extensive manual labor.&nbsp;</p>
<p><span>In any annotation pipeline, regardless of the data collection method, i.e., human or machine, several factors inject annotation noise in data. As a result, even the most celebrated datasets contain mislabeled annotations.</span></p>

<p><img src="https://lh3.googleusercontent.com/mL1r0JU9VM5-WflEsLU04zQ7vhYhl8cKRux8LvOnUTYEKZvnIUD9Gv8HmkVTqPfgoDtEkb_5ApX3SjgJjdTAHNfG6I-5Q7_fag_cra8IhXTWp-uVdrvQCf7kzoqt03BwtgKlTb4i" width="720" alt="How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on Quality Assurance"><em>Figure: Ambiguous or Mislabeled annotations from ImageNet. Source (</em><a href="https://arxiv.org/abs/2001.10528"><em><span>Pleiss et al</span></em></a><em>.)</em></p>

<p><span>Recent studies show that both natural and malicious corruptions of annotations tend to radically degrade the performance of machine learning systems. Deep Neural Networks (DNNs) tend to memorize noisy labels in data, resulting in less generalizable features and poor model performance (<a href="https://arxiv.org/abs/1611.03530">Zhang et al.</a>)</span></p>
<p><span>Therefore, extensive quality control of annotated data is required to clean annotation noise and improve model performance.</span><em><br></em></p>

<p><img src="https://lh4.googleusercontent.com/7BKHH4Am8Z_PZebzMe7mkbGCA6J_UyNRZE-ClAMwP5qVo52ZEuybUx81EOWYSdKrz2Mz7P4zf2cHuoz9nlyl4Alg-D16cD58mSCLf1CAOUwwDEp2MUkIsaTi37D6y9aliNShqdUz" width="720" alt="How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on Quality Assurance"></p>
<p><em>Figure: Accuracy drop in multiple datasets when injecting label noise. Source (</em><a href="https://arxiv.org/abs/1611.03530"><em><span>Rolnick et al.</span></em></a><em>)</em></p>

<h2>Manual QA Acceleration</h2>
<p><strong><span>2.1 SuperAnnotate’s QA pipeline&nbsp;</span></strong></p>
<p><span>Quality Assurance of annotated data is time-consuming and requires particular attention. Annotation tools need to provide reliable and scalable QA pipelines to accelerate the QA process. <a href="https://annotate.online/login">SuperAnnotate</a> provides interlinked annotation and QA processes within the same platform. As a result, QA systems do not require additional management.</span></p>
<p><span>The design of SuperAnnotate’s QA system guarantees an efficient process and ensures a minimal probability of error.&nbsp;</span></p>
<p><strong><span>2.2 Pinning images to reduce common errors&nbsp;</span></strong></p>
<p><span>Sharing repetitive labeling mistakes across the annotation team is essential to reduce systematic errors throughout single or multiple annotation projects. </span>SuperAnnotate’s pin functionality is designed specifically for this cause.&nbsp;</p>
<p>Once the reviewer notices a recurring error, they can share this information through pinned annotations instead of extensive project instructions. Pinned annotations will appear first in the annotation editor to immediately grab the annotation team’s attention.&nbsp;</p>
<p>This functionality is highly efficient since it allows the project coordinator to instantly share common instructions, eliminating the spread of systematic errors.&nbsp;</p>

<p><img src="https://lh6.googleusercontent.com/g1sh6D7Xy1hLYBMczMWfFGdO1_1gktJn7dNF1Spx3lwUxeZd8isGaMHgYLB1GoT0lY8jJKTemdqvtExgPJIocgjNEFuzYGjbPQYeRo31873mdN3U4U10DMjW7DZOnr1eAh5_o-bc" width="720" alt="How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on Quality Assurance"></p>
<p><em>Figure: Pin functionality</em></p>

<p><strong><span>2.3 Approve/Disapprove functionality</span></strong></p>
<p>Apart from various image-level QA tools, SuperAnnotate also provides instance-level QA functionalities. The latter is designed to help the QA focus on a specific instance area. As a result, no error is overlooked, at the time a meticulous QA is time-efficient.</p>
<p>Additionally, the Approve/Disapprove functionality works on the level of individual instances<span>.</span> If a QA specialist disapproves of an annotation, they can send it back to the Annotator for correction. The QA specialist can send the annotation back to the Annotator as many times as needed until the annotation is corrected. Once approved, the annotations can be exported from the platform.</p>

<p><img src="https://lh4.googleusercontent.com/BpQPXRUuTMRYUP-YGJTSRJwFUtdLr6wsB5LVwn66wK6TqFJCTRW5LLwhTp4sRttqgzQaCngKzm7Z6ONZBpPhwzxifj1KlBRs5_FOl_Nk0cFpaC_jn7-l9CMn1WJX2FENx9f9NI24" width="720" alt="How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on Quality Assurance"></p>
<p>Figure: Approve/Disapprove functionality</p>

<p><span>The QA mode is another useful tool for manual instance inspection. When enabled, the annotations are visually isolated from the background. This allows the user to distinguish between instances and the underlying objects, making the instance inspection easier.</span></p>
<p><span>All listed features extensively accelerate the manual QA process. However, machine learning techniques that automatically detect annotation noise can provide an additional level of automation.</span></p>

<h2><span>QA Automation</span></h2>
<p><strong><span>3.1 ML for QA Automation</span></strong></p>
<p><span>QA of annotated data takes around 40 percent of the annotation time.</span></p>
<p><span>On average, only a small fraction of annotated data contains noise. Still, QA is applied to the entire dataset, and monitoring clean data costs the annotators extra time and resources. An automation method could substantially cut down the QA process of clean data by isolating a set of risky annotations. So, our goal is to determine ML techniques that identify noisy annotations in data with high precision and recall.</span></p>
<p><strong><span>3.2 Current research</span></strong></p>
<p><span>Learning on datasets that contain annotation noise has been an active research area in ML. Several methods use predictions from DNNs to detect label noise and modify training loss (Reed et al., 2015; Tanaka et al., 2018). These methods do not perform well under high noise ratio as the domination of noisy annotations in data causes overfitting of DNNs. Another approach is to treat small loss samples as clean annotations and allow only clean samples to contribute to the training loss (Jiang et al., 2017). Ultimately, this research area’s core challenge is to design a reliable criterion capable of identifying the annotation noise.</span></p>
<p><span>A significant amount of research in this area is focused on classification with noisy labels. The proposed methods range from detecting and correcting noisy samples to using noise-robust loss functions. Unsupervised and semi-supervised learning techniques are also relevant to this task since those require few or no labels. Mislabeled samples that are detected without label correction can be used as unlabeled data in a semi-supervised setting (Li et al. 2020).&nbsp;</span></p>
<p><span>Going beyond classification makes things far more challenging. In classification, the existence of an object per image is guaranteed. So, the noisiness criterion can be defined between predicted and annotated image labels. However, in more complex tasks such as object detection, the correspondence between predicted and annotated instances is less trivial. Even though research in this area is in its initial state, several methods suggest valid measures to indicate both localization and label noise in object detection (Pleiss et al 2020, Chadwick et al. 2019).</span></p>
<p><strong><span>3.3&nbsp; Proposed method</span></strong></p>
<p>Consider the task of object detection on a dataset that contains mislabeled annotations. Several techniques use DNN predictions to identify label noise in data. Based on this concept, we propose the following algorithm.</p>
<ul>
<li>For each bounding box annotation, we obtain the matching prediction that has the maximum IOU.&nbsp;</li>
<li><span>Compute <strong>L2 distance</strong> between one hot vector of an annotated class and Fast RCNN softmax logits of the matched prediction. </span>This distance serves as a mislabel metric for annotations. We treat this number as the probability of annotation being mislabeled. As we aim to achieve maximal recall and precision in mislabel detection, we select an optimal threshold to attain the desired objective. This defines the split of data between clean and mislabeled annotations by the given criterion.</li>
</ul>

<p><img src="https://lh6.googleusercontent.com/JJtyM51584r8uJCIbHuW0UKhdgxQIIMm4G23vuD8lxnn5yrYHONPRytIxl-9QjFodM51zy7d8pvswhiMYokXY8XOz-DxqTd4ua-_DHGemiuXULNKqCbq_ePQfzulkbsrNu_jyX0D" width="720" alt="How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on Quality Assurance"></p>
<p><em>Figure: L2 distance on gt one hot and prediction logits</em></p>

<p>Along with mislabeled detections, we also suggest considering the most confident predictions as missing annotations.&nbsp;</p>
<p><strong><span>3.4 Experiments and results</span></strong></p>
<p>To evaluate the performance of our method, we used PASCAL VOC as a toy dataset. When we manually injected asymmetric label noise in 20 percent of bbox annotations, the described mislabel criterion resulted in the precision-recall curve shown below.</p>
<p><img src="https://lh5.googleusercontent.com/OhgoPNrwmPWqR21Y1jnMY-1rbgKV8cxdFd8F0lZsVCZTcrN9C77EBX-0yqvZfVbYOVAFH_pxHNh88T7r26Gbp6hxWWdF5XqyLkN8SS5G46q512ZOHILlP1wmeR20aCo2QDWsOMms" width="400" alt="How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on Quality Assurance"></p>
<p><em>Figure: PR curve with optimal mismatch threshold selected</em></p>

<p>Here, recall determines the portion of annotation noise captured, and precision identifies the fraction of data validated as clean.</p>
<p><span>Based on the PR curve above, using optimal mislabel threshold results in over 93 percent recall. This proves the reliability of our method, as we capture the dominant fraction of annotation noise. Along with high recall, we obtained over 75 percent precision, which attributes to validating ¾ of annotations as clean. This cuts manual inspection time over the whole dataset by a margin of 4, resulting in extensive automation for the manual QA.&nbsp;</span></p>
<p>Note that detected risky annotations contain clean samples apart from correctly detected mislabeled instances. Those are the images that were hard to capture by the detection model and thus are misclassified as risky. Distinguishing between these two categories is a challenging problem for further research.&nbsp;</p>
<p>You can find the source code for the discussed experiments at our <a href="https://github.com/superannotateai/qa-automation"><span>GitHub repository</span></a>.</p>
<p>Also, consider our <a href="https://colab.research.google.com/drive/1Xbt3dxkmX4ozQhdY_vnHXAH67OUeg0Nj#scrollTo=7unkuuiqLdqd&amp;uniqifier=2"><span>Colab tutorial</span></a> as a step-by-step guide to reproduce the given results.&nbsp;</p>
<p><strong><span>3.5 Automate Approve/Disapprove functionality&nbsp;</span></strong></p>
<p>Once mislabeled annotations are captured by ML techniques, SuperAnnotate allows users to import the detected information to the platform through the <strong>error </strong>key of SA formatted annotations. Just set the <strong>error</strong> key in mislabeled annotations and import SA formatted JSONs to SuperAnnotate via Python SDK.&nbsp;</p>

<p><img src="https://lh3.googleusercontent.com/to5CwRUFKERkSeyPgA1Nzl84I0ijhR8bQCpsUHhIxi_zhsm7FnNGOxSJ-i0V8HXnJSzN4VOxDnVgj_JWo2QCwQF6ECSjO4CrLShBB9V3YPHp8SWxO9D2CEwC6UbfqClElWgxIOf3" width="654" height="183" alt="How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on Quality Assurance"></p>
<p><em>Figure: JSON Code Block</em></p>

<p><img src="https://lh3.googleusercontent.com/0SJ8E5OnOSxB50Fh_4d4_qjJNT0lygY1yHzFGuFlZ9fMDjIGyUGQDqxGsDDG9j2dMcfmf6PLOHvj3JRJ4F3UtaQup-muynR2TFd18W6vbjI1ANF8Ll99dK_b8v1GIzkBUbpwVaPn" width="654" height="121" alt="How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on Quality Assurance"></p>
<p><em>Figure: SDK Code Block</em></p>

<p><span>Discussed pipeline provides complete automation of Approve/Disapprove functional.</span></p>

<p><img src="https://lh5.googleusercontent.com/w9VXvs6INaP4WaEADW2pW6fEVj6s8sj5FZd44gN-10LcKplspRX3N7tt-aRuV1BUmNFzANwQTjKgq9rt-EbND0_SpY2z5Ikcpc3xo6wZHQMm2-TB3iY6ao5LboT86FK8qaw8ZwPu" width="720" alt="How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on Quality Assurance"></p>
<p><em>Figure: Before v.s After autoqa in SA platform&nbsp;</em></p>

<h3><span>Conclusion</span></h3>
<p><span>QA automation is of crucial importance as it constitutes a significant portion of annotation time. This article shows that using proper algorithms and associated tools can help us detect mislabeled annotations with high precision while spending 4x less time on QA.</span></p></span>
</p>


</div></div>]]>
            </description>
            <link>https://blog.superannotate.com/how-to-detect-mislabeled-annotations</link>
            <guid isPermaLink="false">hacker-news-small-sites-24651571</guid>
            <pubDate>Thu, 01 Oct 2020 14:57:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CodeShip Status – Critical Security Notification]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24651240">thread link</a>) | @jwilk
<br/>
October 1, 2020 | https://www.codeshipstatus.com/incidents/91bvlfw9xlm9 | <a href="https://web.archive.org/web/*/https://www.codeshipstatus.com/incidents/91bvlfw9xlm9">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
              Dear CodeShip users,</p><p>We are reaching out to inform you of additional information we have uncovered as a result of our continuing investigation of the recent GitHub breach. To provide maximum transparency, we are reporting on the results of our investigation, the impact on users, actions you must take to protect yourself/your organization, and actions we will take to strengthen our security processes going forward.</p><p>On Wednesday, September 16, 2020, CloudBees was notified by GitHub of suspicious activities targeting CodeShip business accounts connected to GitHub via the CodeShip GitHub app and now deprecated CodeShip OAuth tokens. CloudBees immediately initiated an investigation conducted by our security and engineering teams, and on September 27, we identified additional evidence of malicious activity against a failover CodeShip database. On September 29, we uncovered evidence to indicate that a malicious actor had access to this failover instance during the period of June 2019 to June 2020. At this time and to the best of our knowledge, we have no evidence of malicious activity or attempts within CodeShip systems since June 2020. </p><p>*What type of data was affected?*</p><p>The impacted accounts are those of CodeShip users. No other products or accounts were affected and CodeShip is in no way integrated with other CloudBees products or systems.</p><p>*For all CodeShip users:*</p><p>CodeShip users hashed account passwords, one-time password (OTP) recovery codes, and the OTP secret keys used to seed two-factor authentication all may have been exposed.</p><p>Business contact information for invoicing purposes such as company contact name, company name, VAT number, postal address, phone number also may have been exposed. No payment information, such as bank account numbers or credit card numbers, was exposed. No other CloudBees product other than CodeShip was impacted. Also, the logging system was not accessed for any customers.</p><p>*For CodeShip Basic users:*</p><p>Any information contained in CodeShip users’ pipelines may have been exposed. This includes scripts, environment variables, access tokens and other similar data.</p><p>*For CodeShip Pro users:*</p><p>AES encryption keys may have been exposed.</p><p>*Steps you should take*</p><p>Although at this time we have no evidence that the data potentially exfiltrated has been used, all CodeShip users may have been affected (including free, Basic and Pro accounts) and should take the following steps:</p><p>- Immediately rotate any keys or other secrets for cloud providers, third-party tools, or anything else that you used in your CodeShip pipelines.</p><p>- If using CodeShip Pro, rotate your AES key and re-encrypt your secrets.</p><p>- Immediately identify any other sensitive information that is stored in your pipelines and replace them within your pipelines and on any external systems.</p><p>- Determine whether any of your systems accessible from CodeShip have experienced unauthorized access, by contacting your provider or carefully review your access records.</p><p>- Verify that the source code held in repositories that are linked to your CodeShip account have retained their full integrity.</p><p>- Reset your CodeShip 2FA: <a target="_blank" href="https://documentation.codeship.com/general/about/2fa/">https://documentation.codeship.com/general/about/2fa/</a></p><p>At this time and to the best of our knowledge, we have no evidence of malicious activity or attempts within CodeShip systems since June 2020. We are continuing to monitor the situation.</p><p>*Steps we are taking*</p><p>As soon as we were notified by GitHub on September 16, we proceeded to rotate all our applications' internal secrets and rebuilt all our AWS AMIs. We are continuing to scrutinize our AWS security logs to monitor for suspicious activity, such as outbound connections to known malicious IPs. To date, we have not found any such activity.</p><p>We want you to be assured that we are taking steps to increase the security strength of the CodeShip product, including but not limited to:</p><p>- Validation that our product threat modeling and large-scope security reviews are systematically implemented.</p><p>- Validation that the application of production security standards to all operational processes and artifacts is systematically implemented.</p><p>- Enhancement of strict restrictions on access to production data and strict segregation of sensitive data.</p><p>- Improvement of existing SIRT processes to ensure faster and better forensic investigation.</p><p>*Who to contact *</p><p> We will update here with any new developments. </p><p>If you still have questions, please contact <a target="_blank" href="mailto:security@codeship.com">security@codeship.com</a>.</p><p>Last but not least, I’d like to apologize for the impact this is having on you. In the decade that CloudBees has been operating SaaS applications, we have always taken full responsibility for our products and we do so today. Please be assured that we will do everything we can to prevent this from happening again. </p><p>- Sacha Labourey, CEO, CloudBees
            </p></div></div>]]>
            </description>
            <link>https://www.codeshipstatus.com/incidents/91bvlfw9xlm9</link>
            <guid isPermaLink="false">hacker-news-small-sites-24651240</guid>
            <pubDate>Thu, 01 Oct 2020 14:32:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Web Scraping Newegg RTX Inventory with Python]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24651154">thread link</a>) | @antonb90
<br/>
October 1, 2020 | https://www.usetrove.io/blog/introduction-to-web-scraping-with-python/ | <a href="https://web.archive.org/web/*/https://www.usetrove.io/blog/introduction-to-web-scraping-with-python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><h2>Introduction</h2>
<p>In this post, we'll cover how to scrape <strong>Newegg</strong> using <strong>python, lxml</strong> and <strong>requests</strong>. Python is a great language that anyone can pick up quickly and I believe it's also one of the more readable languages, where you can quickly scan the code to determine what it is doing.</p>
<p>Just look at this <strong>loop</strong> with auto incrementing index:</p>
<pre><code><p><span>for</span> index, element <span>in</span> enumerate(href_elements):</p></code></pre>
<p>We'll scrape <strong>Newegg</strong> with the use case of monitoring prices and inventory, especially the RTX 3080 and RTX 3090.</p>
<h2>Setting up</h2>
<p>We're going to work in a <a href="https://virtualenv.pypa.io/en/stable/">virtual python environment</a> which helps us address dependencies and versions separately for each application / project. Let's create a virtual environment in our home directory and install the dependencies we need.</p>
<p>Make sure you are running at least python 3.6, <a href="https://www.python.org/downloads/">3.5 is end of support</a>.</p>
<pre><code><p>mkdir ~/intro-web-scraping</p><p><span>cd</span> ~/intro-web-scraping</p><p>virtualenv env</p><p>. env/bin/activate </p><p>pip install lxml requests</p></code></pre>
<p>Let's create the following folders and files.</p>
<pre><code><p>|-- env </p><p>|-- core</p><p>|   |-- crawler.py</p><p>|   |-- scraper.py</p><p>|   |-- utils.py</p><p>|-- newegg</p><p>|   |-- __main__.py</p></code></pre>
<p>We created a <code>__main__.py</code> file, this lets us run the <strong>Newegg</strong> scraper with the following command (nothing should happend right now):</p>
<pre><code><p>python -m newegg</p></code></pre>
<h2>Crawling the content</h2>
<p>We need to write code that can crawl the content, by crawl I mean fetch or download the HTML from the target website. Our first target is <strong>Newegg</strong>, this website doesn't seem to require javascript for the data we need. We'll get into rendering javascript in a future post that covers <strong>headless scraping</strong> using <strong>requests-html</strong> on <strong>Google Places</strong>.</p>
<p>Open <code>core/crawler.py</code> which we created earlier. Now, we'll begin by requesting the HTML content from Newegg's domain.</p>
<pre><code><p><span>import</span> requests</p><p>newegg = <span>"https://newegg.com"</span></p><p>response = requests.get(newegg)</p><p>print(response.status_code)</p></code></pre>
<p>In <code>newegg/__main__.py</code> we can import crawler and the code above will execute.</p>
<pre><code><p><span>from</span> core <span>import</span> crawler</p></code></pre>
<p>Remember you can execute and test your code with the previous python command in your terminal (must be run in the root folder <code>~/intro-web-scraping</code>).</p>
<pre><code><p>python -m newegg</p></code></pre>
<p>It looks like the request succeeded, the status code should of been printed to your terminal with a success of <code>200</code>.
Let's clean up the code to make it reusable and define a function for returning the response text.</p>
<p>In <code>core/crawler.py</code> we'll define a <code>crawl_html</code> function (we want to reuse it and this lets us redefine where the HTML comes from in the future).</p>
<pre><code><p><span>import</span> requests</p><p><span><span>def</span> <span>crawl_html</span>(<span>url</span>):</span></p><p>    response = requests.get(url)</p><p><span>return</span> response.content </p></code></pre>
<p>In <code>newegg/__main__.py</code> we'll use the function, you can run it and see the HTML being printed. We use an uppercased variable <code>NEWEGG_URL</code> to define a constant - something that shouldn't change.</p>
<pre><code><p><span>from</span> core <span>import</span> crawler</p><p>NEWEGG_URL = <span>"https://newegg.com"</span></p><p>html = crawler.crawl_html(NEWEGG_URL)</p><p>print(html)</p></code></pre>
<h2>Scraping the data we need</h2>
<p>Now that we have access to the HTML content from <strong>Newegg</strong>, we want a way to pull out stock information and price for the RTX 3080 and RTX 3090.
Let's find the page from <strong>Newegg</strong> that has that information first.</p>
<p>Navigate to <a href="https://www.newegg.com/p/pl?N=100007709%20601357282">https://www.newegg.com/p/pl?N=100007709%20601357282</a> in your browser and you'll see we have filters applied for RTX 30 series.</p>
<p><img src="https://www.usetrove.io/images/newegg-screenshot.png" alt="Newegg Category Page"></p>
<p>We'll take that path and append it to our <code>NEWEGG_URL</code>. We do this using <a href="https://docs.python.org/3/reference/lexical_analysis.html#f-strings">f-strings</a> in python, which is a way to interpolate variables in strings.</p>
<pre><code><p><span>from</span> core <span>import</span> crawler</p><p>NEWEGG_URL = <span>"https://newegg.com"</span></p><p>NEWEGG_RTX_PATH = <span>"/p/pl?N=100007709%20601357282"</span></p><p>crawl_url = <span>f"<span>{NEWEGG_URL}</span><span>{NEWEGG_RTX_PATH}</span>"</span></p><p>html = crawler.crawl_html(crawl_url)</p><p>print(html)</p></code></pre>
<p>From this URL we can start scraping the data we need. Let's start by creating a few useful functions in the file <code>core/scraping.py</code>. These functions wrap lxml and handle some of the type conversions to make it easier for us to work with.</p>
<pre><code><p><span>from</span> lxml <span>import</span> html</p><p><span><span>def</span> <span>get_tree</span>(<span>html_content</span>):</span></p><p><span>return</span> html.fromstring(html_content)</p><p><span><span>def</span> <span>get_text</span>(<span>tree, xpath_selector</span>):</span></p><p>    elements = tree.xpath(xpath_selector)</p><p><span>return</span> list(map(<span>lambda</span> element: element.text_content(), elements))</p><p><span><span>def</span> <span>get_attributes</span>(<span>tree, xpath_selector, attribute</span>):</span></p><p>    elements = tree.xpath(xpath_selector)</p><p><span>return</span> list(map(<span>lambda</span> element: element.get(attribute), elements))</p></code></pre>
<h3>Finding the data</h3>
<p>We'll first try to get the prices with XPath. I highly recommend you use XPath instead of CSS selectors which is much more declarative and more expressive, you can use this simple <a href="https://devhints.io/xpath">cheat sheet</a> for quickly finding out how to specify selectors. A more in-depth guide can be found from <a href="https://librarycarpentry.org/lc-webscraping/02-xpath/index.html">librarycarpentry</a>.</p>
<p>Open your chrome browser and visit the crawl url we defined earlier: <a href="https://www.newegg.com/p/pl?N=100007709%20601357282">https://www.newegg.com/p/pl?N=100007709%20601357282</a>.</p>
<p>Press F12 on your keyboard or open the developer console by right-clicking one of the prices on the page and selecting <code>inspect</code>.</p>
<p><img src="https://www.usetrove.io/images/newegg-inspect.png" alt="Newegg Inspect"></p>
<h3>Using XPath</h3>
<p>We'll use the inspector and practice our XPath to figure out how to get all prices on the page (there are <strong>29</strong> items listed). This selector: <code>//li[contains(@class, 'price-current')]</code> grabs all relevant prices.</p>
<p><img src="https://www.usetrove.io/images/newegg-inspector.png" alt="Newegg Inspector"></p>
<p>With the selector in hand, let's modify our <code>newegg/__main__.py</code> entry file by adding a new function to grab the prices.</p>
<pre><code><p><span>from</span> core <span>import</span> crawler, scraper</p><p>NEWEGG_URL = <span>"https://newegg.com"</span></p><p>NEWEGG_RTX_PATH = <span>"/p/pl?N=100007709%20601357282"</span></p><p><span><span>def</span> <span>get_rtx_prices</span>(<span>tree</span>):</span></p><p>    price_selector = <span>"//li[contains(@class, 'price-current')]"</span></p><p><span>return</span> scraper.get_text(tree, price_selector)</p><p>crawl_url = <span>f"<span>{NEWEGG_URL}</span><span>{NEWEGG_RTX_PATH}</span>"</span></p><p>html = crawler.crawl_html(crawl_url)</p><p>tree = scraper.get_tree(html)</p><p>prices = get_rtx_prices(tree)</p><p>print(prices)</p></code></pre>
<p>We should see output like the following.</p>
<pre><code><p>[<span>'$1,499.99\xa0–'</span>, <span>'$749.99\xa0–'</span>, <span>'$809.99\xa0–'</span>, <span>'$1,619.99\xa0–'</span>, <span>'$1,549.99\xa0–'</span>, <span>'$1,549.99\xa0–'</span>, <span>'$729.99\xa0–'</span>, <span>'$759.99\xa0–'</span>, <span>'$1,589.99\xa0–'</span>, <span>'$699.99\xa0–'</span>, <span>'$749.99\xa0–'</span>, <span>'$749.99\xa0–'</span>, <span>'$1,799.99\xa0–'</span>, <span>'$1,499.99\xa0–'</span>, <span>'$1,799.99\xa0–'</span>, <span>'$1,599.99\xa0–'</span>, <span>'COMING SOON'</span>, <span>'$739.99\xa0–'</span>, <span>'$699.99\xa0–'</span>, <span>'$1,579.99\xa0–'</span>, <span>'$1,499.99\xa0–'</span>, <span>'$699.99\xa0–'</span>, <span>'$699.99\xa0–'</span>, <span>'$729.99\xa0–'</span>, <span>'$1,499.99\xa0–'</span>, <span>'$1,729.99\xa0–'</span>, <span>'$789.99\xa0–'</span>, <span>'COMING SOON'</span>, <span>'$1,499.99\xa0–'</span>]</p></code></pre>
<p>Let's clean this extra HTML entity appearing at the end of our prices with a utility function. We'll make use of <code>re</code> for regex and <code>unescape</code> from html module to cleanup our data. We need to check if the input contains numbers in order to account for the <code>COMING SOON</code> labels. We'll keep this logic encapsulated in our <code>get_rtx_prices</code> by mapping over each item and then converting it back to a list (<code>map</code> returns an object iterator).</p>
<pre><code><p><span>from</span> core <span>import</span> crawler, scraper</p><p><span>from</span> html <span>import</span> unescape</p><p><span>import</span> re</p><p>NEWEGG_URL = <span>"https://newegg.com"</span></p><p>NEWEGG_RTX_PATH = <span>"/p/pl?N=100007709%20601357282"</span></p><p><span><span>def</span> <span>clean_price</span>(<span>price</span>):</span></p><p>    price_contains_numbers = bool(re.search(<span>r'[\d+,]+(\d+)'</span>, price))</p><p><span>if</span> price_contains_numbers:</p><p>        price = unescape(price).split()[<span>0</span>]</p><p><span>return</span> price</p><p><span><span>def</span> <span>get_rtx_prices</span>(<span>tree</span>):</span></p><p>    price_selector = <span>"//li[contains(@class, 'price-current')]"</span></p><p>    price_text = scraper.get_text(tree, price_selector)</p><p><span>return</span> list(map(<span>lambda</span> price: clean_price(price), price_text))</p><p>crawl_url = <span>f"<span>{NEWEGG_URL}</span><span>{NEWEGG_RTX_PATH}</span>"</span></p><p>html = crawler.crawl_html(crawl_url)</p><p>tree = scraper.get_tree(html)</p><p>prices = get_rtx_prices(tree)</p><p>print(prices)</p></code></pre>
<pre><code><p>[<span>'$1,499.99'</span>, <span>'$749.99'</span>, <span>'$809.99'</span>, <span>'$1,619.99'</span>, <span>'$1,549.99'</span>, <span>'$1,549.99'</span>, <span>'$729.99'</span>, <span>'$759.99'</span>, <span>'$1,589.99'</span>, <span>'$699.99'</span>, <span>'$749.99'</span>, <span>'$749.99'</span>, <span>'$1,799.99'</span>, <span>'$1,499.99'</span>, <span>'$1,799.99'</span>, <span>'$1,599.99'</span>, <span>'COMING SOON'</span>, <span>'$739.99'</span>, <span>'$699.99'</span>, <span>'$1,579.99'</span>, <span>'$1,499.99'</span>, <span>'$699.99'</span>, <span>'$699.99'</span>, <span>'$729.99'</span>, <span>'$1,499.99'</span>, <span>'$1,729.99'</span>, <span>'$789.99'</span>, <span>'COMING SOON'</span>, <span>'$1,499.99'</span>]</p></code></pre>
<p>Let's grab the item names.</p>
<pre><code><p><span><span>def</span> <span>get_rtx_names</span>(<span>tree</span>):</span></p><p>    name_selector = <span>"//div[@class='item-info']/a"</span></p><p><span>return</span> scraper.get_text(tree, name_selector)</p></code></pre>
<p>We also want the link to the item.</p>
<pre><code><p><span><span>def</span> <span>get_rtx_links</span>(<span>tree</span>):</span></p><p>    link_selector = <span>"//div[@class='item-info']/a"</span></p><p><span>return</span> scraper.get_attributes(tree, link_selector, <span>"href"</span>)</p></code></pre>
<h3>More complex XPath</h3>
<p>Next we want the stock information (out of stock or in stock). To do this we need to add another function called <code>get_children_text</code> to <code>core/scraper.py</code>. This will allow us to specify a parent selector and a child selector, which will return the first child that matches. If our parent selector has many matches it will try to find a matching child and if it does not find one it will return <code>None</code>. In our case we have many parent matches but some of them may not contain the <code>OUT OF STOCK</code> element.</p>
<p>In <code>core/scraper.py</code> add the new function.</p>
<pre><code><p><span><span>def</span> <span>get_children_text</span>(<span>tree, xpath_parent_selector, xpath_child_selector</span>):</span></p><p>    parent_elements = tree.xpath(xpath_parent_selector)</p><p>    children_texts = []</p><p><span>for</span> element <span>in</span> iter(parent_elements):</p><p>        child = element.xpath(xpath_child_selector)</p><p><span>if</span> child:</p><p>            children_texts.append(child[<span>0</span>].text_content())</p><p><span>else</span>:</p><p>            children_texts.append(<span>None</span>)</p><p><span>return</span> children_texts</p></code></pre>
<p>Back in <code>newegg/__main__.py</code> we can add the stock selector.</p>
<pre><code><p><span><span>def</span> <span>get_rtx_stock_information</span>(<span>tree</span>):</span></p><p>    item_selector = <span>"//div[@class='item-container']"</span></p><p>    child_selector = <span>"div[@class='item-info']/p[contains(., 'OUT OF STOCK')]"</span></p><p>    stock_details = scraper.get_children_text(tree, item_selector, child_selector)</p><p><span>return</span> list(map(<span>lambda</span> element: element <span>or</span> <span>"IN STOCK"</span>, stock_details))</p></code></pre>
<p>We also want the product id, having this can help us track changes to the product in the future. Here's how we can find the item id from the page.</p>
<p><img src="https://www.usetrove.io/images/newegg-item-id.png" alt="Item id selector"></p>
<p>If you notice on the highlighted lines below, you can see we added another function to our scraper. Because we are using the <code>text()</code> function of XPath, we are asking for the text node which ignores the other <code>strong</code> label node in the tree seen in the screenshot above.</p>
<pre><code><p><span><span>def</span> <span>get_rtx_ids</span>(<span>tree</span>):</span></p><p>    item_id_selector = <span>"//ul[@class='item-features']/li[contains(., 'Item #')]/text()"</span></p><p><span>return</span> scraper.get_nodes(tree, item_id_selector)</p></code></pre>
<p>Let's add <code>get_nodes</code> to our <code>core/scraper.py</code> module.</p>
<pre><code><p><span><span>def</span> <span>get_nodes</span>(<span>tree, xpath_selector</span>):</span></p><p><span>return</span> tree.xpath(xpath_selector)</p></code></pre>
<h3>Our final output structure</h3>
<p>Let's put it all together now to generate the final structure for our output which will contain basic <strong>stock</strong> information, <strong>price</strong>, <strong>product name</strong>, <strong>product id</strong> and <strong>product link</strong>.</p>
<pre><code><p><span><span>def</span> <span>get_rtx_items</span>(<span>tree</span>):</span></p><p>    prices = …</p></code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.usetrove.io/blog/introduction-to-web-scraping-with-python/">https://www.usetrove.io/blog/introduction-to-web-scraping-with-python/</a></em></p>]]>
            </description>
            <link>https://www.usetrove.io/blog/introduction-to-web-scraping-with-python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24651154</guid>
            <pubDate>Thu, 01 Oct 2020 14:25:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Book Recommendations for October 2020]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24651117">thread link</a>) | @bojanvidanovic
<br/>
October 1, 2020 | https://devandgear.com/posts/5-book-recommendations-for-october-2020/ | <a href="https://web.archive.org/web/*/https://devandgear.com/posts/5-book-recommendations-for-october-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>If you have noticed the cover image for this post, you might ask what it has to
do with books? Well, because I have included the autobiography of Edward
Snowden titled Permanent Record. After listening to his last interview on the
Joe Rogan Experience podcast, I decided to include it in the list books for
this October 2020. If you haven’t already listened to the podcast, go check it out on <a href="https://www.youtube.com/watch?v=_Rl82OQDoOc">YouTube</a>,
lots of eye-opening stuff.</p>
<p>Moving from the surveillance stuff, we have Continuous Delivery, lots of useful
techniques for those who want to deploy, and sleep tight. Then from code
deployment to mastering the editor for code creation which brings us to Visual
Studio Code, covering end-to-end editing, and debugging tools.</p>
<p>Outside the code, I added The 4-Hour Workweek, a book on productivity, which is
one with the highest ratings on Amazon. And Universal Principles of Design,
it’s a comprehensive, cross-disciplinary encyclopedia of design.</p>
<p>If you haven’t seen the book recommendations for the previous month, go check
it out <a href="https://devandgear.com/posts/books-recommendations-for-september-2020/">here</a>.</p>
<p>If you have already read any of these books, let us know in the comments your
opinion.</p>
<h2 id="1-permanent-record">1. Permanent Record</h2>
<article>
<p><a href="https://devandgear.com/books/edward-snowden-permanent-record/">
<img data-src="https://m.media-amazon.com/images/I/51z1ZaEn6sL.jpg" alt="Edward Snowden Permanent Record" src="https://m.media-amazon.com/images/I/51z1ZaEn6sL.jpg">
</a>
</p>

</article>
<h2 id="2-continuous-delivery">2. Continuous Delivery</h2>
<article>
<p><a href="https://devandgear.com/books/continuous-delivery/">
<img data-src="https://m.media-amazon.com/images/I/51NbiDn81NL.jpg" alt="Continuous Delivery" src="https://m.media-amazon.com/images/I/51NbiDn81NL.jpg">
</a>
</p>

</article>
<h2 id="3-visual-studio-code">3. Visual Studio Code</h2>
<article>
<p><a href="https://devandgear.com/books/visual-studio-code/">
<img data-src="https://m.media-amazon.com/images/I/51Je7J+HS2L.jpg" alt="Visual Studio Code" src="https://m.media-amazon.com/images/I/51Je7J+HS2L.jpg">
</a>
</p>

</article>
<h2 id="4-universal-principles-of-design">4. Universal Principles of Design</h2>
<article>
<p><a href="https://devandgear.com/books/universal-principles-of-design/">
<img data-src="https://m.media-amazon.com/images/I/41nQFR+FSCL.jpg" alt="Universal Principles of Design" src="https://m.media-amazon.com/images/I/41nQFR+FSCL.jpg">
</a>
</p>

</article>
<h2 id="5-the-4-hour-workweek">5. The 4-Hour Workweek</h2>
<article>
<p><a href="https://devandgear.com/books/the-4-hour-workweek/">
<img data-src="https://m.media-amazon.com/images/I/51I2EIRF44L.jpg" alt="The 4 Hour Workweek" src="https://m.media-amazon.com/images/I/51I2EIRF44L.jpg">
</a>
</p>

</article>

<section>
<h2>Author</h2>
<div>
<p><img data-src="https://res.cloudinary.com/dev-and-gear/image/upload/w_200,h_200,c_fill,r_max//v1601042336/EACDEB44-BC4A-4E1E-9C13-553D64E1A0C2_t6ayms.jpg" width="200" height="200" src="https://res.cloudinary.com/dev-and-gear/image/upload/w_200,h_200,c_fill,r_max//v1601042336/EACDEB44-BC4A-4E1E-9C13-553D64E1A0C2_t6ayms.jpg"></p><div>
<p>Bojan Vidanovic is a front-end web developer and tech geek. Love making internet products, blogging, learning, reading,
calisthenics and fitness enthusiast.<br>
More on <a href="https://bojanvidanovic.com/">www.bojanvidanovic.com</a>.</p>
<address>

</address>
</div>
</div>
</section>
</div></div>]]>
            </description>
            <link>https://devandgear.com/posts/5-book-recommendations-for-october-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24651117</guid>
            <pubDate>Thu, 01 Oct 2020 14:22:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Memgraph DB 1.1 Up to 50% Better Memory Usage and Higher Throughput]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24651091">thread link</a>) | @karimtr
<br/>
October 1, 2020 | https://memgraph.com/blog/memgraph-1-1-benchmarks | <a href="https://web.archive.org/web/*/https://memgraph.com/blog/memgraph-1-1-benchmarks">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>Introduction</h2>
<p>At Memgraph, we put great effort into delivering a high-performance in-memory graph storage and analytics engine. We do this by investing a lot of time optimizing and continuously improving various aspects of the Memgraph core engine. In this blog post, we will explore some of the improvements we have made on the storage layer and their impact on performance and memory usage.</p>
<p>The two most significant improvements we introduced in recent years are a new storage engine and a new way of storing properties on both nodes and edges.  Prior to version v0.50.0 Memgraph had an <a href="https://en.wikipedia.org/wiki/Multiversion_concurrency_control">MVCC</a> storage where copies of nodes and edges were used to version the data. <strong>Memgraph v0.50.0</strong> introduced a new way of managing graph data where each node or edge consists of the latest version of data, and associated changes of data required to reconstruct previous versions.</p>
<p><img src="https://i.imgur.com/bQbvvp6.png" alt=""></p>
<p><strong>Memgraph v1.1.0</strong> introduced a new way of storing properties. Each node or edge has a property store that takes at least 16B of memory. Memgraph tries to hold properties data in 16B on the stack, if possible. If the properties data exceeds 16B, the first 8B of the stack buffer indicates the total number of bytes required for the storage of properties, and the second 8B a pointer to the array on the heap that stores properties. This technique is called small buffer optimization.</p>
<p><img src="https://i.imgur.com/LWP2te8.png" alt=""></p>
<p>Additionally, there were various other smaller improvements of existing internal data structures, most notably the <a href="https://en.wikipedia.org/wiki/Skip_list">skip list</a> which is used as an indexing data structure. The combined result was a massive improvement in memory usage with a substantial reduction in memory fragmentation while ensuring equivalent or better performance. Before jumping into the analysis and explanations, let’s have a look at the benchmark setup.</p>
<h2>Setup</h2>
<h3>Target Systems</h3>
<p>The benchmark tests different Memgraph versions. The release dates and details of each version are the following:</p>
<ul>
<li><strong>v0.15.2</strong>, October 23, 2019, the last version of Memgraph that used an in-memory storage engine based on copies of nodes/edges.</li>
<li><strong>v0.50.0</strong>, December 11, 2019, introduced the new in-memory storage engine based on data changes and a C-based storage API.</li>
<li><strong>v1.0.0</strong>, April 6, 2020, introduced a Python-based storage API.</li>
<li><strong>v1.1.0</strong>, July 1, 2020, added encoding and compression to node and edge properties.</li>
</ul>
<p>The <a href="https://docs.memgraph.com/memgraph/changelog">Memgraph Changelog Docs</a> page contains more details about changes in each version.</p>
<h3>Hardware</h3>
<ul>
<li>Server: HP DL360 G6</li>
<li>CPU: 2x Intel Xeon X5650 6C12T @ 2.67GHz</li>
<li>RAM: 144GB</li>
<li>Disk: 120GB SSD</li>
<li>OS: Debian 9 Stretch</li>
</ul>
<h3>Workload</h3>
<p>The benchmark consists of several different queries that test the performance of the graph database. Typical graph database workloads consist of READ, CREATE, and ANALYZE queries.</p>
<p>Memgraph is particularly well suited for hybrid transactional-analytical workloads where it’s crucial to ingest data as fast as possible and simultaneously deliver analytics as quickly as possible. For this reason, we are mostly interested in traversal queries (1-Hop, 2-Hop, etc.) which represent the majority of analytical queries.</p>
<p>In the following table, you can find the exact queries we have used for benchmarking.</p>
<pre><code>|            Query Name             |                                                Query                                                        |  Query Type |
| --------------------------------- | ----------------------------------------------------------------------------------------------------------- | ----------- |
| Aggregation                       | `MATCH (n:User) RETURN n.age, COUNT(*);`                                                                    | ANALYZE     |
| 1-Hop Expand                      | `MATCH (s:User {id: $id})--&gt;(n:User) RETURN n.id;`                                                          | ANALYZE     |
| 2-Hop Expand                      | `MATCH (s:User {id: $id})--&gt;()--&gt;(n:User) RETURN DISTINCT n.id;`                                            | ANALYZE     |
| 3-Hop Expand                      | `MATCH (s:User {id: $id})--&gt;()--&gt;()--&gt;(n:User) RETURN DISTINCT n.id;`                                       | ANALYZE     |
| 4-Hop Expand                      | `MATCH (s:User {id: $id})--&gt;()--&gt;()--&gt;()--&gt;(n:User) RETURN DISTINCT n.id;`                                  | ANALYZE     |
| 2-Hop Variable Expand             | `MATCH (s:User {id: $id})-[*1..2]-&gt;(n:User) RETURN DISTINCT n.id;`                                          | ANALYZE     |
| 2-Hop Variable Expand with Result | `MATCH (s:User {id: $id})-[*1..2]-&gt;(n:User) RETURN DISTINCT n.id, n;`                                       | ANALYZE     |
| Shortest Path                     | `MATCH p=(n:User {id: $from})-[*bfs..15]-&gt;(m:User {id: $to}) RETURN extract(n in nodes(p) | n.id) AS path;` | ANALYZE     |
| Insert New Relationship           | `MATCH (n:User {id: $from}), (m:User {id: $to}) WITH n, m CREATE (n)-[e:Temp]-&gt;(m) RETURN e;`               | CREATE      |
| Find Node                         | `MATCH (n:User {id : $id}) RETURN n;`                                                                       | READ        |
| Insert a New Node                 | `CREATE (n:UserTemp {id : $id}) RETURN n;`                                                                  | CREATE      |
</code></pre>
<p>The benchmarking harness executed all queries against the <a href="https://snap.stanford.edu/data/soc-Pokec.html">Pokec dataset</a> which contains 1.6M nodes and 30.6M edges. Given that the goal of each benchmark is to saturate the target system to extract its peak characteristics, we took great care in carefully designing and polishing our setup. Some of the essential elements of the harness are:</p>
<ul>
<li>optimized C/C++ client to minimize client overhead.</li>
<li>fresh dataset load before each execution.</li>
<li>concurrent execution (up to 12 cores) to push Memgraph to its limits.</li>
</ul>
<h2>Data Import Analysis</h2>
<p>Before delving deep into the workload queries execution analysis, a couple of notes about the data import.</p>
<p>The harness imported data in a real-time manner, equivalent to normal query execution by running queries. The data was imported using 8 concurrent clients.  Throughput and peak memory usage were measured during the data import. A couple of interesting insights emerged. On the memory usage side, there is already a massive difference between Memgraph versions. <strong>Before v0.50.0</strong>, Memgraph stored all data modifications as whole copies of the modified objects. By removing the need to make whole copies of database objects, versions <strong>after v0.50.0</strong> provide a significantly less memory usage. The same benefits apply to the runtime environment since the import uses regular queries.</p>
<p><img src="https://i.imgur.com/VfDzuCw.png" alt=""></p>
<p>At this point, you might be wondering about the import speed. As the chart below shows, throughput on basic CREATE queries also improved. Since data copying is generally a fast operation, throughput improvement is not huge but is still significant. One important thing to notice is the difference between v1.0.0 and v1.1.0. <strong>v1.1.0</strong> has almost the same throughput as versions before even though more work is involved in property compression.</p>
<p><img src="https://i.imgur.com/hsh6uDj.png" alt=""></p>
<h2>Query Execution Analysis</h2>
<p>Let’s start analyzing the <strong>workload queries</strong>. The following radar chart shows peak memory usage during query execution across different Memgraph versions. Keep in mind that less is better.</p>
<p>As you can see, <strong>v1.1.0 uses ~50%</strong> less memory compared to v0.15.2. v0.50.0 and v1.0.0 fall in-between with almost no difference because not much from the storage perspective changed between these two versions. The most significant difference is between v0.15.2 and v0.50.0 (introduction of the new storage engine), and v1.0.0 and v1.1.0 (introduction of encoded and compressed properties).</p>
<p><img src="https://i.imgur.com/4ETpDXT.png" alt=""></p>
<p>On the other hand, while looking at memory, it’s also critical to observe what is happening with the throughput. Generally, there is a well-known trade-off between space and time. But, as you can see in the following chart, v1.1.0 has the best performance. Please note that in this case, more is better.</p>
<p><img src="https://i.imgur.com/c0nBqJS.png" alt=""></p>
<p>Of course, not all queries yield significant throughput improvements. E.g., the <code>Insert New Node</code> query performance stayed similar across different Memgraph versions. Nonetheless, the following chart illustrates well how Memgraph scales with the number of concurrent requests.</p>
<p><img src="https://i.imgur.com/vIy7rTM.png" alt=""></p>
<p>The new storage engine also introduced a feature where it is possible to disable storing properties on edges. Sometimes graph datasets don’t have any data attached to edges. Memgraph offers a configuration option to remove all associated data structures required to store data on edges. As you can see in the following chart, by not having properties on edges, memory usage goes down by almost 50% (in addition to the reductions mentioned above). v0.15.2 can’t disable the property storage on edges, so the chart shows nothing there. Using all the improvements in new versions of Memgraph you can store the same dataset in 3.36x less memory (comparing v0.15.2 with properties enabled and v1.1.0 with properties disabled).</p>
<p><img src="https://i.imgur.com/PtQviBf.png" alt=""></p>
<p>The rest of the charts show performance for each query with regards to linear scalability. Linear scalability is the ability of a system to handle more work by adding more resources linearly. E.g., by doubling the number of cores, the system is capable of executing twice as many queries. In practice, it’s impossible to reach perfect linear scalability due to various overheads.  The real question is how far Memgraph is from linear scalability? As you can see below, not by a lot.</p>
<p>The following chart shows throughput data for the simple read query (Find Node). The node lookup inside Memgraph has an O(logN) complexity.</p>
<p><img src="https://i.imgur.com/0z46Rg5.png" alt=""></p>
<p>In the next case, instead of reading, Memgraph creates an edge. The operation contains two node lookups and one edge write. Which means it’s very similar to the Find Node query. Instead of one lookup, the action has two lookups and one write. The chart looks very similar to the Find Node chart.</p>
<p><img src="https://i.imgur.com/ZWzeFc6.png" alt=""></p>
<p>By moving towards more complex queries, there is a more significant scalability difference between previous versions of Memgraph and the latest ones. v0.15.2 is far behind the latest versions.</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://memgraph.com/blog/memgraph-1-1-benchmarks">https://memgraph.com/blog/memgraph-1-1-benchmarks</a></em></p>]]>
            </description>
            <link>https://memgraph.com/blog/memgraph-1-1-benchmarks</link>
            <guid isPermaLink="false">hacker-news-small-sites-24651091</guid>
            <pubDate>Thu, 01 Oct 2020 14:19:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Slide deck presentations are the worst way to share knowledge remotely]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24650821">thread link</a>) | @mcrittenden
<br/>
October 1, 2020 | https://critter.blog/2020/10/01/slide-deck-presentations-are-the-worst-way-to-share-knowledge-remotely/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/10/01/slide-deck-presentations-are-the-worst-way-to-share-knowledge-remotely/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-1717">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>Nobody is paying attention to your remote slide deck presentation. In person? Sure. But not remote. They’re distracted. They’re multitasking. The internet is irresistible when there’s nobody watching over their shoulder.</p>



<p>They’re catching up on email or checking Slack or playing online poker or getting some actual work done. At best, they’re listening to you in the background.</p>



<p>Give it up. Stop spending hours putting together presentations that help no one. </p>



<p>Instead, write up a document and share it around ahead of time. Let people read it and understand it on their own. Or, <a href="https://www.cnbc.com/2019/10/14/jeff-bezos-this-is-the-smartest-thing-we-ever-did-at-amazon.html">do what Amazon does</a> and set aside reading time for it at the beginning of the meeting to remove all excuses. </p>



<p>Then the meeting itself can be a Q&amp;A or a discussion instead of a presentation. You can use your time together to be <em>together</em> and to dig into the topic as a group. It’ll be more valuable for everyone, including yourself. </p>



		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/10/01/slide-deck-presentations-are-the-worst-way-to-share-knowledge-remotely/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24650821</guid>
            <pubDate>Thu, 01 Oct 2020 13:56:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using His Bike as an Ambulance, Man Saves 5k Lives]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24650761">thread link</a>) | @stanrivers
<br/>
October 1, 2020 | https://www.myindiamyglory.com/2017/08/16/bike-ambulance-man-saved-5000-lives/ | <a href="https://web.archive.org/web/*/https://www.myindiamyglory.com/2017/08/16/bike-ambulance-man-saved-5000-lives/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="mh-wrapper">

<!-- Easy Plugin for AdSense V8.7 -->
<!-- [leadin: 0 urCount: 0 urMax: 0] -->

<!-- Easy Plugin for AdSense V8.7 -->
<p><strong>Using His Bike Ambulance, this Man Saved 5000 Lives from 20 Villages!</strong></p>
<p><img loading="lazy" src="https://www.myindiamyglory.com/wp-content/uploads/2017/08/bike-ambulance.jpg" alt="Karimul Haque and his bike ambulance" width="600" height="315"></p>
<p>Humanity does exist amid adversity. For a person to help a fellow being and the society at large, riches aren’t all that is required. And this happens only in India! This is best corroborated by the selfless service of a tea-garden worker who earns a monthly salary of just Rs. 5000. And he is happy running his family as well as serving people from his village and neighboring villages with this meager amount. He is Karimul Haque from Dhalabari in Jalpaiguri district of West Bengal.</p>

<p>50 year old Karimul Haque runs a bike ambulance for free. He is known in his region as the ‘Bike Ambulance <em>Dada</em>’. The tea garden area is a feast for the eyes, but lack of proper roads, basic amenities and medical facilities are the disadvantages. He ferries the sick to the nearest hospital for free. Till date, Karimul has ferried 5000 poor patients from 20 villages in Jalpaiguri to the hospital since the last 14 years. He is a ray of hope to the poor and needy in his village and neighboring villages.</p>

<p>Karimul says, “Many years ago, my mother suddenly fell ill in the middle of the night. She was in dire need of medical attention. But the hospital was located several kilometers away. I had no vehicle in my house then. Neither was there any ambulance facility nearby. I went from door to door for help, but in vain. And my mother breathed her last. I failed to save her.”</p>

<p>An inconsolable Karimul decided that night that thenceforth he would not let any sick person in his village die due to lack of ambulance facilities. He somehow managed to buy a bike. Some 14 years ago, a co-worker collapsed while on duty. There was no ambulance or four-wheeler to take him to the hospital. Hospital authorities, on knowing about the incident, sent an ambulance. But it would take time. Immediately, an idea struck his mind, as he could not afford his co-worker risk his life waiting for the ambulance. He tied the patient to his back, made him ride pillion and took him to the nearest hospital. His bike ambulance saved his co-worker’s life!</p>

<!-- Easy Plugin for AdSense V8.7 -->
<!-- [midtext: 1 urCount: 1 urMax: 0] -->

<!-- Easy Plugin for AdSense V8.7 -->

<p>And then there was no looking back. He made himself available for 24 hours to ferry any sick person from his village or nearby areas to the hospital for free. With the help of the local doctors, he also started organizing healthcare camps. He has even trained himself in medical first aid from the local doctor to control emergency situations.</p>

<p>“I told my wife that I get a salary of Rs. 5000 per month. When my mother was alive, I spent Rs. 1000 on her for her basic needs. She is no more. I can use that amount of 1000 to buy petrol for my bike ambulance so that I could ferry the sick to the hospital,” said Karimul. He continued after a pause, his eyes already turning moist, “My wife agreed. She had no objection.”</p>

<p>Recently Karimul was invited to the sets of Zee TV’s <em>Sare Ga Ma Pa Little Champs</em> where he was honored with a momento. The audience’s eyes turned moist listening to his story. Famous singer Neha Kakkar, a judge in the singing show, declared that she would donate Rs. 1 lakh to Karimul Haque so that he could use the money over time to buy petrol for his bike ambulance to ferry the sick to the hospital. It was then learnt that Karimul had bought the motorbike on loan. He felt happy to use part of the donated amount to pay his loan.</p>

<p>Karimul Haque’s dream is to make an advanced ambulance equipped with all necessary facilities, available at his village. He was rightly honored with the Padma Shri Award for his efforts.</p>

<p>Bike ambulance image courtesy: Hindustan Times.</p>
<div id="ts-fab-below"><p><span>The following two tabs change content below.</span></p><ul><li><a href="#ts-fab-bio-below">Bio</a></li><li><a href="#ts-fab-latest-posts-below">Latest Posts</a></li></ul><div>
	<div id="ts-fab-bio-below">
		<div><p><img src="https://www.myindiamyglory.com/wp-content/uploads/2016/11/me1-150x150.jpg" width="80" height="80" alt="manoshi sinha"></p>
		</div>
		
		<div>
			<!-- /.ts-fab-header -->
			<p>Manoshi Sinha is a writer, history researcher, avid heritage traveler; Author of 8 books including 'The Eighth Avatar', 'Blue Vanquisher', 'Saffron Swords'.</p>
		</div>
	</div>
	<div id="ts-fab-latest-posts-below">
		<div><p><img src="https://www.myindiamyglory.com/wp-content/uploads/2016/11/me1-150x150.jpg" width="80" height="80" alt="manoshi sinha"></p>
		</div>
		
	</div>
		</div>
	</div><!-- Facebook Comments Plugin for WordPress: http://peadig.com/wordpress-plugins/facebook-comments/ --><h3>Comments</h3>
</div></div>]]>
            </description>
            <link>https://www.myindiamyglory.com/2017/08/16/bike-ambulance-man-saved-5000-lives/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24650761</guid>
            <pubDate>Thu, 01 Oct 2020 13:48:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ElasticSearch Query Builder]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24650651">thread link</a>) | @piranha
<br/>
October 1, 2020 | https://solovyov.net/blog/2020/elasticsearch-query-builder/ | <a href="https://web.archive.org/web/*/https://solovyov.net/blog/2020/elasticsearch-query-builder/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><p>This post strives to be useful to anyone who uses ElasticSearch, but all examples are going to be in Clojure since it’s what we use.</p>
<p>ElasticSearch is a wildly useful database (if I may say so), but at times it feels like its query language evolved rather than was planned. This manifests in it being rather ad-hoc and non-orthogonal. Plus using JSON with its low expressiveness adds quite a bit of verbosity. All of this leads to code which builds ES queries being messy and unpleasant to use.</p>
<h2 id="jump-in">Jump in</h2>
<p>Certainly, this was our case a few years ago. Our code was a bunch of functions calling one another, which sounds like functional programming and should be fine, right? Well, as always, the devil is in the detail, and:</p>
<ul>
<li><code>if</code>/<code>case</code>/<code>cond</code> everywhere, various cases were piling on top of each other</li>
<li><a href="https://solovyov.net/blog/2020/higher-order-functions/">functions parametrized with functions</a> — it’s a good tool if you make some higher-order well-documented/understood function, but your business logic should be free of this stuff in general; makes logic hard to be understood</li>
<li>code factorization was quite a bit off: function boundaries felt a bit random</li>
<li>it was written at the start of the current codebase, grew with it and just happened, was never planned</li>
</ul>
<p>Our use case, by the way, is a product filtering API (facets and all that stuff) for an ecommerce site, <a href="https://kasta.ua/">Kasta</a>. Apply some filters and retrieve some aggregations, which is enough of a problem to need a proper solution.</p>
<h2 id="what-is-out-there">What is out there</h2>
<p>So where to go? I looked around and saw stuff like <a href="https://elasticsearch-dsl.readthedocs.io/en/latest/">elasticsearch-dsl</a>, which was just like ES data structures, but methods on mutable objects. Ugh. Also, <a href="https://elastic-builder.js.org/docs/">ElasticBuilder</a>, which is similar, but with different names, so you have to remember two layers of abstraction. Thanks, but no.</p>
<p>And there are a lot of articles on how to make a query to get what you need from ES, but nobody wrote an article on how to make an ES query builder! Well, except for me. :-)</p>
<h2 id="solution">Solution</h2>
<p>What I like in terms of API is <a href="https://github.com/seancorfield/honeysql">HoneySQL</a>, which is a compiler from maps/vectors to SQL queries. This got me thinking and it turns out that a good question is half of the answer.</p>
<p>What we need is a compiler from our API interface — GET request query string — to an ES query.</p>
<p>Rephrased like this it makes the task almost a walk in the park. A long-long walk, but much less “here be dragons” if-peppered abomination of the past. And the design cornerstones are:</p>
<ul>
<li>branchless pipeline</li>
<li><a href="https://clojuredocs.org/clojure.core/defmulti">multimethods</a></li>
<li>small dictionary of verbs on top of ES incantations</li>
</ul>
<h3 id="data-format">Data format</h3>
<p>Some time ago I stumbled upon a great article about working with ES, and one of its parts <a href="https://project-a.github.io/on-site-search-design-patterns-for-e-commerce/#generic-faceted-search">describes a data model</a> they have used. It proposes that instead of a map like <code>{:brand "wow" :color "red"}</code> you use a following structure:</p>
<pre><code>{:facets [{:name "brand"
           :value "wow"}
          {:name "color"
           :value "red"}]}
</code></pre>
<p>This allows you to query all those facets with a single definition, rather than sending a separate aggregation for every field. More than that, you don’t need to know which facets are available for filtering upfront, since you’ll receive all of them from ES.</p>
<p>In practice, two lists of facets are needed - regular ones and ranged facets. Regular facets are aggregated by <code>terms</code> aggregation, and ranged are aggregated by a combo of <code>ranges</code> and <code>percentiles</code>.</p>
<h3 id="verbs">Verbs</h3>
<p>So we have several functions like <code>not</code>, <code>and</code>, <code>or</code>, <code>term=</code>. They signal intent rather than what ES is doing inside and make reading aggregations and filters much easier. Or should I say <code>should</code> easier? Or <code>must</code> easier? :-) You can understand what’s it doing without opening ES docs. Some examples:</p>
<pre><code>(defn or* [&amp; clauses]
  (let [clauses (filterv identity clauses)]
    (cond
      (empty? clauses)
      {:bool {}}

      (= 1 (count clauses))
      (first clauses)

      :else
      {:bool {:should               clauses
              :minimum_should_match 1}})))


(defn facet= [k v]
  {:nested {:path  "facets"
            :query (and* (term= "facets.id" k)
                         (term= "facets.value" v))}})
</code></pre>
<p>What they accomplish is that most of our lower-level use cases are covered with “loaded” terminology rather than “neutral” (and often cryptic) ES maps.</p>
<h3 id="pipeline">Pipeline</h3>
<p>The pipeline is 4 steps:</p>
<ul>
<li><code>qs-&gt;query</code> parses query string, cookies, headers into a basic query data structure</li>
<li><code>make-aggs-q</code> loops through supplied filters and known aggregations, and builds an ES query</li>
<li>then a query is executed</li>
<li><code>aggs-&gt;response</code> converts ES response to what our API returns</li>
</ul>
<p>We represent a user query internally with a map like that:</p>
<pre><code>{:base    {"menu" "pants"}
 :filters {"1" #{"123" "456"}}
 :sort    :default
 :cursor  "ZXCVB"
 :limit   100}
</code></pre>
<p>This is easier to interact with than with just a raw query string.</p>
<h3 id="make-aggs-q">make-aggs-q</h3>
<p>This part is the most convoluted one. It builds the essence of an ES query for aggregations, and consists of:</p>
<ul>
<li>loop over known non-facet aggregations</li>
<li>loop over every facet which was used as a filter in a query</li>
<li>query for regular facets</li>
<li>query for ranged facets</li>
</ul>
<p>What is a facet aggregation is described in <a href="#data-format">data format</a> section. All other aggregations are non-facet and should be explicitly mentioned. Those are filters such as price, depot (whenever they are on stock in our warehouse rather than supplier’s one), supplier, etc. When I look there it feels like most of them need to be in facets. Historical reasons. :)</p>
<p>Every loop then delegates to <code>make-agg</code> multimethod, which builds its piece of the query. Here is an example of a filter for colors - it’s one of the simplest aggregations, just generates a list of colors available for selected products.</p>
<pre><code>(def NESTED-AGG :_nest)

(defn agg-filter [agg filter-data]
  {:filter filter-data
   :aggs   {NESTED-AGG agg}})

(defmethod make-agg :color [filter-name _ filters options]
  [filter-name
   (-&gt; {:terms {:field "color_group"
                :size  (:max-buckets options)}}
       (agg-filter (filters/make filters)))])

</code></pre>
<p><code>filters</code> are filters for the given query except for the one for the given aggregation, so that you’ll receive all possible values for the current aggregation in a given context. So we apply them with an <code>agg-filter</code> function.</p>
<p><code>-&gt;</code> could be confusing, but look at it as a pipeline operator: every function you give it is executed in order.</p>
<p>ElasticSearch aggregation rules are nested, read on to discover why we need <code>NESTED-AGG</code>.</p>
<h3 id="aggs-response">aggs-&gt;response</h3>
<p>This stage loops over response and converts data from ES into API response format. Fortunately most parts of the response are independent, so it’s pretty clean and simple: it’s a loop, which calls <code>extract-agg</code> on every aggregation:</p>
<pre><code>(defn agg-recur [{:keys [doc_count] :as agg}]
  (loop [agg agg]
    (if-let [nested (get agg NESTED-AGG)]
      (recur nested)
      (if-not (:doc_count agg)
        (assoc agg :doc_count doc_count)
        agg))))

(defn aggs-&gt;response [query es-response]
  (for [[k agg] (:aggregations es-response)
     (extract-agg k (agg-recur agg) query))
</code></pre>
<p><code>agg-recur</code> is a way to get to the real data: ES aggregations are very nested. To get through we use key <code>:_nest</code> (value of <code>NESTED-AGG</code>), and then use this <code>agg-recur</code> function.</p>
<p>Unfortunately, there is no good way to pass additional information from <code>make-agg</code> to <code>extract-agg</code>, so it’s stringly-typed, as is <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.x/returning-aggregation-type.html">recommended by ES</a>. Look at our <code>extract-agg</code> multimethod (<code>defmulti</code> defines dispatcher, this is a function which determines which method to call):</p>
<pre><code>(defmulti extract-agg
  (fn [filter-name data query]
    (condp #(str/starts-with? %2 %1) filter-name
      "facet_"      :facet
      "percentile_" :percentile
      "range_"      :range
      :else         filter-name)))
</code></pre>
<p><code>extract-agg</code> methods extract data, sort if necessary (so brands are alphabet-sorted rather than count of matches-sorted), fix up document count (in case of nested aggregations). Here’s an example processing <code>:depot</code>:</p>
<pre><code>(defmethod extract-agg :depot [filter-name agg query]
  (let [cnt (-&gt; agg :real_count :doc_count)]
    [{:id        filter-name
      :widget    :toggle
      :values    [{:key       "true"
                   :doc_count cnt}]
      :doc_count cnt}]))
</code></pre>
<p>That part is pretty simple since you just have to massage data into whatever you need for the API. :)</p>
<h2 id="divide-and-conquer">Divide and conquer</h2>
<p>There is nothing new under the sun. If only the right idea would appear right at the start. :-) Just factor your functions correctly and you’re golden.</p>
<p>In the end what we’ve got is a straightforward pipeline, no parametrization with functions, every chunk of a query is as simple as it gets, and extensibility is just great! It’s been in production for 1.5 years now with no significant changes to the logic, received some new features, and doesn’t feel like it was holding us back.</p>
<p>I hope this post can serve as an inspiration for your code. If you feel confused or have questions, please contact me by email — I would love to make this post more approachable.</p>
</div></div>]]>
            </description>
            <link>https://solovyov.net/blog/2020/elasticsearch-query-builder/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24650651</guid>
            <pubDate>Thu, 01 Oct 2020 13:38:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ontario police used Covid-19 database illegally, civil rights groups find]]>
            </title>
            <description>
<![CDATA[
Score 248 | Comments 70 (<a href="https://news.ycombinator.com/item?id=24650515">thread link</a>) | @seigando
<br/>
October 1, 2020 | https://www.cbc.ca/news/canada/toronto/covid-police-database-1.5745481 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/toronto/covid-police-database-1.5745481">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Police forces across&nbsp;Ontario&nbsp;engaged in broad, illegal searches&nbsp;of a now-defunct COVID-19 database, two civil rights groups alleged Wednesday, claiming the use of the portal violated individual privacy rights for months.</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5704129.1598642644!/cumulusImage/httpImage/image.jpg_gen/derivatives/16x9_780/shutterstock-medium-file-typing-on-laptop.jpg"></p></div><figcaption>The Canadian Civil Liberties Association and the Canadian&nbsp;Constitution Foundation say in separate reports that many services used the database to look at COVID-19 test results for wide geographic areas and sometimes pulled up personal information unrelated to active calls.<!-- --> <!-- -->(maradon 333 / Shutterstock)</figcaption></figure><p><span><p>Police forces across&nbsp;Ontario&nbsp;engaged in broad, illegal searches&nbsp;of a now-defunct COVID-19 database, two civil rights groups alleged Wednesday, claiming the use of the portal violated individual privacy rights for months.</p>  <p>The Canadian Civil Liberties Association (CCLA) and the Canadian&nbsp;Constitution Foundation (CCF) said in separate reports that many services used the database to look at COVID-19 test results for wide geographic areas and sometimes pulled up personal information unrelated to active calls.</p>  <p>"People weren't told that when they went for COVID tests that&nbsp;this information was being shared with police and they certainly weren't asked for their consent," said Abby Deshman, the criminal&nbsp;justice program director for the CCLA.&nbsp;</p>  <p>"That should be a decision every person makes about what they&nbsp;want to do with their own personal medical information."</p>  <p>In early April, the&nbsp;Ontario&nbsp;government passed an emergency order&nbsp;that allowed police to obtain the names, addresses and dates of birth of Ontarians who had tested positive for COVID-19. The portal was aimed at helping to protect first responders.</p>  <p>Police access to that database ended on Aug. 17, after a legal&nbsp;challenge was filed by a group of human rights&nbsp; organizations.</p>  <p>The group, which included the CCLA, argued that allowing police&nbsp;to access personal health records violated individuals'<br> constitutional rights to privacy and equality.</p>  <h2>Police conducted 95,000 searches of database</h2>  <p>Data released in the context of the legal action showed that&nbsp; Ontario&nbsp;police services conducted over 95,000 searches of the&nbsp;database while it was active.</p>  <p>The CCF filed a freedom of information act request to the&nbsp;province related to police use of the database.&nbsp;</p>    <blockquote><span><span><svg version="1.1" focusable="false" x="0px" y="0px" width="30px" height="25px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g><g><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g display="none"><g display="inline"> <path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg>Police were caught using the COVID-19 database to look up names&nbsp;unrelated to active calls, to do wholesale postal&nbsp; code searches for COVID-19 cases, and to even do broad based searches outside officers' own cities.<svg focusable="false" x="0px" y="0px" width="23px" height="22px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g display="none"><g display="inline"><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g><g><path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg></span><cite>- Christine Van Geyn, Canadian Constitution Foundation</cite></span></blockquote>    <p>On Wednesday, the CCF made public a June memo from the Solicitor&nbsp;General's office to chiefs of police that warned against using the&nbsp;database beyond the "express purpose" of the emergency order.</p>  <p>The CCF said the memo revealed a "shocking misuse" of personal&nbsp;health information by police.</p>  <p>"Police were caught using the COVID-19 database to look up names&nbsp;unrelated to active calls, to do wholesale postal&nbsp; code searches for COVID-19 cases, and to even do broad based searches outside officers' own cities," said CCF litigation director, Christine Van&nbsp;Geyn.&nbsp;<span><ul><li><a href="https://www.cbc.ca/news/canada/toronto/covid-ont-police-database-1.5690220" data-contentid="" flag="" text="Ontario ends police access to COVID-19 database after legal challenge"><span>Ontario ends police access to COVID-19 database after legal challenge</span></a></li></ul></span></p>  <p>The CCF said it has filed a complaint with&nbsp;Ontario's privacy&nbsp;commissioner over violations of the Personal Health Information Protection Act, and with the&nbsp;Ontario&nbsp;Independent Police Review Director for officer misconduct.</p>  <p>Meanwhile, the CCLA sent letters to 37 police forces, asking them&nbsp;for details of how the database was used and if any information was retained from it.</p>  <p>Twenty-three responded and Deshman said she expects more to do&nbsp;so.</p>  <h2>Thunder Bay, Durham police conducted more than 40% of searches</h2>  <p>Many forces found the database difficult to use and resorted to&nbsp;problematic broad searches in an attempt to find workarounds, the CCLA said.</p>  <p>The association notes that more than 40 per cent of the 95,000&nbsp;searches of the database were conducted by either the Thunder Bay police or Durham Region police.&nbsp;</p>    <p>In Durham Region, police continued to run unauthorized searches&nbsp;even after provincial audits called attention to the inappropriate&nbsp;searches taking place, the CCLA said. The force's access to the portal was cut off by the province as a result, the CCLA said.</p>  <p>"Durham is a particularly concerning example," said Deshman.&nbsp;"In those cases there needs to be disclosure (to citizens whose information was accessed) and accountability by following up with the individuals in the police service that looked up information inappropriately."</p>  <h2>Anyone concerned can contact police, privacy commissioner&nbsp;</h2>  <p>Holly Walbourne, the legal counsel for Thunder Bay police, said&nbsp;in a letter sent to the groups that filed the legal challenge that&nbsp;the force understood their concerns but that police had "lawful authority" to use the database to protect first responders.</p>    <p>Durham police Supt. Peter Cousins wrote a report to the force's&nbsp;police services board on the issue on Sept. 1 saying&nbsp; access to theportal and its information was treated "seriously and with due care."&nbsp;</p>  <p>Toronto police never used the database because of "issues with&nbsp;the accuracy and reliability of the information," the CCLA reported. York Region police said they asked the province to revoke access to the database after an internal review found the risks associated with accessing personal health information outweighed any benefits.</p>  <p>Deshman said anyone concerned about police access to the province's COVID-19 database should contact their local police force&nbsp;and the&nbsp;Ontario&nbsp;Privacy Commissioner.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/canada/toronto/covid-police-database-1.5745481</link>
            <guid isPermaLink="false">hacker-news-small-sites-24650515</guid>
            <pubDate>Thu, 01 Oct 2020 13:23:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Not PHP?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24650385">thread link</a>) | @muglug
<br/>
October 1, 2020 | https://mattbrown.dev/articles/why-not-php | <a href="https://web.archive.org/web/*/https://mattbrown.dev/articles/why-not-php">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <article>
                                
                <p>
                    October 1, 2020 - 
                                            4&nbsp;minute&nbsp;read
                                    </p>
                                <!--
	title: Why not PHP?
	date: 2020-10-01
    author: Matt Brown
    author_link: https://twitter.com/mattbrowndev
-->
<p>I was intrigued by <a href="https://matklad.github.io/2020/09/20/why-not-rust.html">Why Not Rust</a>, a list of compelling disadvantages written by someone who uses Rust a lot, and the author of <a href="https://github.com/rust-analyzer/rust-analyzer">a popular Rust static analysis tool</a>. I have a similar relationship to PHP – I use it every day (at <a href="https://vimeo.com/">Vimeo</a>), and I’m the author of <a href="https://psalm.dev/">a popular PHP static analysis tool</a>.</p>
<p>The similarities end there, though – Rust and PHP are very different languages, with very different reputations in the wider programming community. Rust has been getting a lot of hype in the last few years, while PHP has been getting the opposite. Indeed, a lot has been written about PHP from a place of contempt. Here’s my attempt to argue against PHP, but from a place of admiration:</p>
<h2 id="its-mainly-for-serving-simple-http-requests">It’s mainly for serving simple HTTP&nbsp;requests</h2>
<p>PHP was originally designed for the then-nascent world wide web, and its popularity has risen (and, lately, fallen) with the popularity of server-rendered HTML.</p>
<p>Its process model (no shared memory between requests) makes it ideal for serving HTML on a case-by-case basis. If that’s what you’re after, it’s incredibly easy to get started.</p>
<p>On the one hand that means the average PHP programmer never has to worry about memory-related race conditions within a single request, because they simply can’t happen.</p>
<p>But all of PHP’s optimisations for serving individual HTML requests will get in the way if you do, in fact, want to run your own service with shared memory between requests, or any other long-running process. While PHP <em>can</em> do that, its implementation won’t be half as pretty as it would be in a language like Go.</p>
<h2 id="its-relatively-old">It’s (relatively)&nbsp;old</h2>
<p>New programming languages are often a thoughtful combination of languages that came before them. Writing code in a recently-written language can expose you to new idioms, and helps you see the world of programming through a different lens.</p>
<p>PHP is not a new language – it’s 26 years old, and pretty thoroughly-cooked at this point.</p>
<h2 id="no-large-corporate-backers">No large corporate&nbsp;backers</h2>
<p>Some languages come directly from large profitable companies that devote considerable resources to their development (e.g. Go, TypeScript, C#, Swift, Java, Kotlin) while others are sort of adopted by companies (Python at Dropbox, OCaml at Jane St, JS interpreters at Google &amp; Mozilla).</p>
<p>PHP hasn’t had a large corporate backer for a while. As far as I know, only one PHP core engineer is <a href="https://blog.jetbrains.com/phpstorm/2019/01/nikita-popov-joins-phpstorm-team/">paid to work on the language full-time</a>.</p>
<p>Large corporate sponsors can be great for a language. Sponsorship sends a message to other companies that “we trust X to help run our billion-dollar business” and also “if you use X you’ll benefit from the work we’re putting into it”.</p>
<p>PHP’s community is pretty strong, though, and has produced some <a href="https://getcomposer.org/">great</a> <a href="https://phpunit.de/">pieces</a> of <a href="https://symfony.com/">software</a> that have moved the entire ecosystem forward.</p>
<h2 id="many-beginners-few-experts">Many beginners, few&nbsp;experts</h2>
<p>PHP is very easy to get into, and it’s easy to make things in PHP that other people find useful.</p>
<p>PHP’s community is also sort of like a high school, where other language communities (e.g. Rust) are like universities: the teachers in a high school can make you a productive member of society, but if you’re looking to surround yourself with professors who are specialists in things you find interesting, universities are a better bet.</p>
<p>This reputation problem isn’t unique to PHP – other popular interpreted languages like Ruby have it too – but it can deter people who want to feel smart when writing code.</p>
<p>JavaScript had this problem for years, but in the last decade several big internet companies have thrown tons of money at its language ecosystem, and JavaScript experts are now plentiful.</p>
<h2 id="it-has-many-minor-potholes">It has many minor&nbsp;potholes</h2>
<p>API inconsistency comes up repeatedly in peoples’ criticism of PHP. While it’s something the vast majority of PHP developers get used to quickly, there’s no getting around the clunkiness of some core library functions: <code>strpos($haystack, $needle)</code> vs <code>in_array($needle, $haystack)</code> and <code>array_map($callback, $array)</code> vs <code>array_filter($array, $callback)</code>.</p>
<hr>
<h2 id="where-do-we-go-from-here">Where do we go from&nbsp;here?</h2>
<p>People have been predicting its demise for a couple of decades, but PHP’s still a pretty popular option. Why? Despite everything written above, there’s never been a better time to start a new PHP project.</p>
<p>PHP now has a huge ecosystem of open-source packages, and its main download hub has been accessed <a href="https://packagist.org/statistics">over a billion times last month</a> by developers around the world. That’s up roughly 50% from the year before, and doubly impressive once you factor in all the things PHP can do natively.</p>
<p>There’s also good reason to be optimistic about PHP’s future. Ten years ago, things were looking much more dire, but the community has invested a lot of time and effort into improving things:</p>
<ul>
<li>
<strong>Package management</strong><br>
<a href="https://getcomposer.org/">Composer</a>, introduced in 2012, has made setting up a new project a breeze</li>
<li>
<strong>Static analysis</strong><br>
A bunch of great competing static analysis tools (including my own, <a href="https://psalm.dev/">Psalm</a>) have been released in the last five years</li>
<li>
<strong>Raw performance</strong><br>
At Vimeo time spent in PHP itself has roughly halved since we upgraded from PHP 5 to PHP 7. Each new version squeezes out a little more speed, and PHP handily outperforms similar interpreted languages like Ruby, Python and Node</li>
<li>
<strong>Standard ways to write modern PHP</strong><br>
<a href="https://www.php-fig.org/psr/">PSR</a> emerged from a primordial soup of spaghetti code, and now pretty much all modern PHP looks very similar</li>
</ul>
<hr>
<p><a href="https://www.reddit.com/r/PHP/comments/j37zih/why_not_php/">Discuss on /r/php</a></p>
            </article>
        </div></div>]]>
            </description>
            <link>https://mattbrown.dev/articles/why-not-php</link>
            <guid isPermaLink="false">hacker-news-small-sites-24650385</guid>
            <pubDate>Thu, 01 Oct 2020 13:07:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Russian Opposition Leader Navalny on His Poisoning: “Putin Was Behind the Crime”]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24650372">thread link</a>) | @rerx
<br/>
October 1, 2020 | https://www.spiegel.de/international/world/alexei-navalny-on-his-poisoning-i-assert-that-putin-was-behind-the-crime-a-ae5923d5-20f3-4117-80bd-39a99b5b86f4 | <a href="https://web.archive.org/web/*/https://www.spiegel.de/international/world/alexei-navalny-on-his-poisoning-i-assert-that-putin-was-behind-the-crime-a-ae5923d5-20f3-4117-80bd-39a99b5b86f4">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-article-el="body">
<section data-app-hidden="true">


</section>
<section>
<div>
<figure data-component="Image" data-settings="{&quot;id&quot;:&quot;54d78056-207d-4c6f-b894-b46c2774c039&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;63b9e7b9-489f-49dd-b36b-e4270e4aa806&quot;}">
<p><span>
<span data-image-el="aspect">
<span>
<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/54d78056-207d-4c6f-b894-b46c2774c039_w948_r1.77_fpx58_fpy45.jpg" srcset="https://cdn.prod.www.spiegel.de/images/54d78056-207d-4c6f-b894-b46c2774c039_w520_r1.77_fpx58_fpy45.jpg 520w, https://cdn.prod.www.spiegel.de/images/54d78056-207d-4c6f-b894-b46c2774c039_w948_r1.77_fpx58_fpy45.jpg 948w" width="948" height="536" sizes="948px">
</span>
</span>
</span>

</p>
<figcaption>
<span>
Foto: <p>Peter Rigaud / DER SPIEGEL</p>
</span>
</figcaption>
</figure>
</div><div>
<p>It's six o'clock in the morning on Wednesday when Alexei Navalny shows up at the Berlin editorial office of DER SPIEGEL for an interview. The office is located a few hundred meters from Charité University Hospital, where Navalny spent a month receiving treatment, hovering between life and death.</p>


<div>
<p>Navalny, who was poisoned with the nerve agent Novichok, was only released from the hospital last week.</p><p>Four agents from the State Office of Criminal Investigation (LKA) accompanied him during his visit. Navalny, who wasn't able to walk not long ago, took the stairs to the office rather than the elevator.</p><p>Alexei Navalny, 44, is Russia's most prominent opposition politician. Following the attempt on his life on August 20 in the Siberian city of Tomsk, however, he is now squarely in the international spotlight. German Chancellor Angela Merkel intervened for him to be allowed to leave Russia for treatment in Germany. Because he was poisoned with a substance that can essentially only come from state-run laboratories in Russia, the question of Russian President Vladimir Putin's personal responsibility is one that many around the world are asking. It's not the first time that a Russian opposition politician was to be killed, but it is the first time that the circumstances seem to so clearly point at the Kremlin.</p>
</div>

<div>
<p>The interview with DER SPIEGEL is the first that Navalny has given since the attack. He is alert at the meeting and he remembers many things - and yet the impact of the poisoning is still clear. Scars on his neck show where he was hooked up to a ventilator. When he pours water from the bottle into his glass, it is obvious that it requires effort and he has to use both hands. But he refuses assistance. "My physical therapist says I should try to do everything myself," he says</p><p>Navalny&nbsp;seems more nervous than he did at previous meetings. His face is gaunter and his figure more angular after losing 12 kilos. But his voice is the same as it has always been, as is his humor, his irony. Sitting next to him is his spokeswoman, Kira Yarmysh, who was with him on the plane on August 20 when he first began showing signs of having been poisoned.</p>
</div>

<p>Before the interview begins, he has something he wants to say.</p>
<figure>
<div data-component="Image" data-settings="{&quot;id&quot;:&quot;02a833ee-fba3-4850-98b7-7c4ed3654454&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;11d45842-a011-42f2-8a67-4ede5c57b0c8&quot;}">
<div>
<div>
<p><span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/02a833ee-fba3-4850-98b7-7c4ed3654454_w683_r1.3714859437751004_fpx36.46_fpy50.jpg" srcset="https://cdn.prod.www.spiegel.de/images/02a833ee-fba3-4850-98b7-7c4ed3654454_w488_r1.3714859437751004_fpx36.46_fpy50.jpg 488w, https://cdn.prod.www.spiegel.de/images/02a833ee-fba3-4850-98b7-7c4ed3654454_w616_r1.3714859437751004_fpx36.46_fpy50.jpg 616w, https://cdn.prod.www.spiegel.de/images/02a833ee-fba3-4850-98b7-7c4ed3654454_w683_r1.3714859437751004_fpx36.46_fpy50.jpg 718w," width="683" height="498" sizes="683px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/02a833ee-fba3-4850-98b7-7c4ed3654454_w488_r1.3714859437751004_fpx36.46_fpy50.jpg 488w, https://cdn.prod.www.spiegel.de/images/02a833ee-fba3-4850-98b7-7c4ed3654454_w616_r1.3714859437751004_fpx36.46_fpy50.jpg 616w, https://cdn.prod.www.spiegel.de/images/02a833ee-fba3-4850-98b7-7c4ed3654454_w683_r1.3714859437751004_fpx36.46_fpy50.jpg 718w," title="This photo was taken in Navalny's hotel room in Tomsk, where his team secured water bottles and other objects. One of the bottles contained traces of the poison." alt="This photo was taken in Navalny's hotel room in Tomsk, where his team secured water bottles and other objects. One of the bottles contained traces of the poison.">
</span>
</span>
</span>
</p><figcaption>
<p>This photo was taken in Navalny's hotel room in Tomsk, where his team secured water bottles and other objects. One of the bottles contained traces of the poison.</p>
<span>
Foto: AFP
</span>
</figcaption>
</div>
</div>
</div>
</figure><p><strong>Navalny:</strong> It is important to me that this interview appears in the German press. I have never been closely associated with Germany. I don't know anyone here. I didn't know a single politician. And yet it turned out - you see, my voice is trembling, I have become so emotional - that German politicians and Angela Merkel have taken an interest in my fate and saved my life. The doctors at Charité saved my life a second time and, more importantly, they gave me back my personality. So, the first thing I want to say is: I feel a tremendous gratitude to all Germans. I know it sounds a bit overblown, but Germany has become a special country for me. I had few connections here before and only visited Berlin for the first time three years ago! And then so much human compassion from so many people.</p>

<div>
<p><strong>DER SPIEGEL:</strong> Our readers will be happy to hear that. How are you doing Mr. Navalny?</p><p><strong>Navalny:</strong> Much better than three weeks ago, and it is getting better each day. Not long ago, I could only climb 10 steps, but now I can make it up to the 5th floor. The most important thing for me is that my mental abilities have returned. Well, maybe we will find the opposite to be true during this interview (<em>laughs</em>).</p><p><strong>DER SPIEGEL:</strong> You wrote on Instagram that you are no longer able to stand on one foot.</p><p><strong>Navalny:</strong> Now I can again. My next challenge is to stand on one leg and stretch the other leg forward, which I practice every day. These are actually exercises that ninety-year-olds do in the park.</p><p><strong>DER SPIEGEL:</strong> Are you able to sleep well?</p><p><strong>Navalny:</strong> That's my biggest problem. I used to laugh about people with sleep problems because I never had them myself. But then came the coma, the anesthesia, the weaning off of the sedatives, that long hovering state when I was neither asleep nor awake. I haven't been able to sleep without sleeping pills since.</p>
</div>
<figure>
<div data-component="Image" data-settings="{&quot;id&quot;:&quot;ae3d6308-8e23-4f16-b6a0-25e3b742c41c&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;2efc0b83-5af5-4dfb-9efe-9925a51cfd75&quot;}">
<div>
<div>
<p><span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/ae3d6308-8e23-4f16-b6a0-25e3b742c41c_w683_r1.3742454728370221_fpx62.38_fpy49.9.jpg" srcset="https://cdn.prod.www.spiegel.de/images/ae3d6308-8e23-4f16-b6a0-25e3b742c41c_w488_r1.3742454728370221_fpx62.38_fpy49.9.jpg 488w, https://cdn.prod.www.spiegel.de/images/ae3d6308-8e23-4f16-b6a0-25e3b742c41c_w616_r1.3742454728370221_fpx62.38_fpy49.9.jpg 616w, https://cdn.prod.www.spiegel.de/images/ae3d6308-8e23-4f16-b6a0-25e3b742c41c_w683_r1.3742454728370221_fpx62.38_fpy49.9.jpg 718w," width="683" height="497" sizes="683px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/ae3d6308-8e23-4f16-b6a0-25e3b742c41c_w488_r1.3742454728370221_fpx62.38_fpy49.9.jpg 488w, https://cdn.prod.www.spiegel.de/images/ae3d6308-8e23-4f16-b6a0-25e3b742c41c_w616_r1.3742454728370221_fpx62.38_fpy49.9.jpg 616w, https://cdn.prod.www.spiegel.de/images/ae3d6308-8e23-4f16-b6a0-25e3b742c41c_w683_r1.3742454728370221_fpx62.38_fpy49.9.jpg 718w," title="Navalny was flown from Omsk to Berlin on this chartered plane." alt="Navalny was flown from Omsk to Berlin on this chartered plane.">
</span>
</span>
</span>
</p><figcaption>
<p>Navalny was flown from Omsk to Berlin on this chartered plane.</p>
<span>
Foto: Kira Yarmysh / dpa
</span>
</figcaption>
</div>
</div>
</div>
</figure><div>
<p><strong>DER SPIEGEL:</strong> When you lost consciousness, you were a figure in Russian politics. When you woke from the coma, you were a global political figure. Chancellor Merkel even visited you at your bedside. What did you talk about?</p><p><strong>Navalny:</strong> That was last week. It was totally unexpected. The door opened, my doctor came in - and Merkel. It was a private meeting with my family - my wife Julia and my son Zahar were there. I can't tell you the details, but we didn't discuss anything secret or sensational. The visit was a gesture. I was impressed by how precisely she knows Russia and my case. She knows some of the details better than I do. She really has a deep understanding of what is going on in Russia. And when you talk to her, you understand why she has been at the top in Germany for so long. I thanked her for her efforts and she said: "I only did my duty."</p><p><strong>DER SPIEGEL:</strong> What has daily life been like for you since you left the hospital? Where are you living?</p><p><strong>Navalny:</strong> I live with my wife and my son here. My daughter has returned to Stanford University. We've rented an apartment. My everyday life is monotonous. I exercise daily - that's all I do. In the morning, I take a walk in the park - that's my job. Then I do the exercises with the doctor. In the evening, I go for another walk. During the day, I try to work on the computer. The doctors say I can be restored to 90 percent of my former self, maybe even 100 percent, but nobody really knows for sure. Basically, I'm a bit of a guinea pig. After all, there aren't many people you can observe who are still alive after being poisoned with a nerve agent. At some point, I will probably be written about in medical journals. And I am happy to share my experiences. Seriously: The Russian leadership has developed such a penchant for poisoning that it is not going to stop doing so anytime soon. My medical history will be instructive.</p><p><strong>DER SPIEGEL:</strong> Going by your posts on social media, it appears that you left your bed in the hospital often.</p><p><strong>Navalny:</strong> The doctors and nurses at Charité are the most tolerant people in the world. I was a difficult patient. I would get up at night in the intensive care unit, and one time I tore all the tubes out of my body and started bleeding. Later, when I was already conscious and could recognize and talk to the people around me, I had hysterical fits. I said I was healthy and wanted to go to a hotel. Weeks later, I understood that this strange behavior was a consequence of the poisoning.</p>
</div>
<figure>
<div data-component="Image" data-settings="{&quot;id&quot;:&quot;39d3599b-4262-4232-b6f7-b6016c2162e6&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;faa1abbd-7467-4067-b0c4-edd82e84f603&quot;}">
<div>
<div>
<p><span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/39d3599b-4262-4232-b6f7-b6016c2162e6_w718_r1.4145383104125737_fpx49.45_fpy50.jpg" srcset="https://cdn.prod.www.spiegel.de/images/39d3599b-4262-4232-b6f7-b6016c2162e6_w488_r1.4145383104125737_fpx49.45_fpy50.jpg 488w, https://cdn.prod.www.spiegel.de/images/39d3599b-4262-4232-b6f7-b6016c2162e6_w616_r1.4145383104125737_fpx49.45_fpy50.jpg 616w, https://cdn.prod.www.spiegel.de/images/39d3599b-4262-4232-b6f7-b6016c2162e6_w718_r1.4145383104125737_fpx49.45_fpy50.jpg 718w" width="718" height="508" sizes="718px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/39d3599b-4262-4232-b6f7-b6016c2162e6_w488_r1.4145383104125737_fpx49.45_fpy50.jpg 488w, https://cdn.prod.www.spiegel.de/images/39d3599b-4262-4232-b6f7-b6016c2162e6_w616_r1.4145383104125737_fpx49.45_fpy50.jpg 616w, https://cdn.prod.www.spiegel.de/images/39d3599b-4262-4232-b6f7-b6016c2162e6_w718_r1.4145383104125737_fpx49.45_fpy50.jpg 718w" title="A first sign of life: Navalny with his children Daria and Zahar and his wife Yulia in his room at Berlin's Charité University Hospital" alt="A first sign of life: Navalny with his children Daria and Zahar and his wife Yulia in his room at Berlin's Charité University Hospital">
</span>
</span>
</span>
</p><figcaption>
<p>A first sign of life: Navalny with his children Daria and Zahar and his wife Yulia in his room at Berlin's Charité University Hospital</p>
<span>
Foto: Alexei Navalny / ddp media
</span>
</figcaption>
</div>
</div>
</div>
</figure><div>
<p><strong>DER SPIEGEL:</strong> Let's go over what happened to you, and we'll start with your last memory before you lost consciousness. It's August 20, at eight o'clock in the morning. You're sitting in a plane from Tomsk to Moscow. You had spent a few days in Siberia. What was going through your head?</p><p><strong>Navalny:</strong> It was a wonderful day. I'm on my way home, with a strenuous and successful business trip behind me. We shot videos for the regional election campaign, and everything had gone according to plan. I'm sitting comfortably in my seat and I'm looking forward to a quiet flight during which I can watch a series. Once I get back to Moscow, I am looking forward to recording my weekly YouTube show and then spending the weekend with my family. I feel good, as I did at the airport. And then… it's hard to describe because there is nothing to compare it with. Organophosphorus compounds attack your nervous system like a DDos attack attacks the computer - it's an overload that breaks you. You can no longer concentrate. I can feel that something is&nbsp;wrong. I break out in a cold sweat. I ask Kira beside me for a tissue. Then I say to her: Speak to me. I need to hear a voice - something's wrong with me. She looks at me like I'm crazy and starts talking.</p><p><strong>DER SPIEGEL:</strong> What happened then?</p><p><strong>Navalny:</strong> I don't understand what is happening to me. The stewards come by with the trolley. I first want to ask them for water, but I then say: No, let me by, I'm going to the bathroom. I wash myself with cold water, sit down and wait and then wash myself again. And then I think: If I don't get out now, I'll never get out. The most important feeling was: You are feeling no pain, but you know you're dying. And I mean, right now, yet nothing hurts. I leave the toilet, turn to the steward - and instead of asking for help, I say, to my own surprise: "I've been poisoned. I'm dying." And then I lay down on the ground in front of him to die. He’s the last thing I see - a face that looks at me with slight astonishment and a light smile. He says: "Poisoned?" and by that he probably means I was served bad chicken.</p><p>And the last thing I hear, already on the floor is: Do you have heart problems? But my heart doesn't hurt. Nothing hurts. All I know is that I am dying. Then I hear voices growing ever quieter, and a woman calling: "Don't leave us! Don't leave us!" Then it's over. I know I'm dead. Only later would it turn out that I was wrong.</p><p><strong>DER SPIEGEL:</strong> There's a video shot by a passenger in which your screams can be heard on the plane. It sounds horrible, almost like the cries of an animal.</p><p><strong>Navalny:</strong> I've watched it - it's circulating on the internet under the title: "Navalny screaming in pain." But it wasn't pain. It was something else, worse. Pain makes you feel like you're alive. But in this case, you sense: This is the end.</p>
</div>
<figure>
<div data-component="Image" data-settings="{&quot;id&quot;:&quot;fe4efb86-8391-4038-9e36-19f7e61bb096&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;3f5b8bb3-847b-4c27-8c66-7e9559644f4e&quot;}">
<div>
<div>
<p><span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/fe4efb86-8391-4038-9e36-19f7e61bb096_w655_r0.8652575957727873_fpx44.89_fpy38.84.jpg" srcset="https://cdn.prod.www.spiegel.de/images/fe4efb86-8391-4038-9e36-19f7e61bb096_w488_r0.8652575957727873_fpx44.89_fpy38.84.jpg 488w, https://cdn.prod.www.spiegel.de/images/fe4efb86-8391-4038-9e36-19f7e61bb096_w616_r0.8652575957727873_fpx44.89_fpy38.84.jpg 616w, https://cdn.prod.www.spiegel.de/images/fe4efb86-8391-4038-9e36-19f7e61bb096_w655_r0.8652575957727873_fpx44.89_fpy38.84.jpg 718w," width="655" height="757" sizes="655px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/fe4efb86-8391-4038-9e36-19f7e61bb096_w488_r0.8652575957727873_fpx44.89_fpy38.84.jpg 488w, https://cdn.prod.www.spiegel.de/images/fe4efb86-8391-4038-9e36-19f7e61bb096_w616_r0.8652575957727873_fpx44.89_fpy38.84.jpg 616w, https://cdn.prod.www.spiegel.de/images/fe4efb86-8391-4038-9e36-19f7e61bb096_w655_r0.8652575957727873_fpx44.89_fpy38.84.jpg 718w," title="Navalny posted photos of himself on Instagram showing him on the balcony of his room." alt="Navalny posted photos of himself on Instagram showing him on the balcony of his room.">
</span>
</span>
</span>
</p><figcaption>
<p>Navalny posted photos of himself on Instagram showing him on the …</p></figcaption></div></div></div></figure></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.spiegel.de/international/world/alexei-navalny-on-his-poisoning-i-assert-that-putin-was-behind-the-crime-a-ae5923d5-20f3-4117-80bd-39a99b5b86f4">https://www.spiegel.de/international/world/alexei-navalny-on-his-poisoning-i-assert-that-putin-was-behind-the-crime-a-ae5923d5-20f3-4117-80bd-39a99b5b86f4</a></em></p>]]>
            </description>
            <link>https://www.spiegel.de/international/world/alexei-navalny-on-his-poisoning-i-assert-that-putin-was-behind-the-crime-a-ae5923d5-20f3-4117-80bd-39a99b5b86f4</link>
            <guid isPermaLink="false">hacker-news-small-sites-24650372</guid>
            <pubDate>Thu, 01 Oct 2020 13:06:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A free remote desktop client for macOS, Linux und Windows]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24650312">thread link</a>) | @aphelion_
<br/>
October 1, 2020 | https://thincast.com/en/products/client | <a href="https://web.archive.org/web/*/https://thincast.com/en/products/client">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div uk-grid="">
        <p><img width="96" height="96" src="https://thincast.com/images/client.png">
        </p>
        <p><img width="48" height="48" src="https://thincast.com/images/client.png">
        </p>
        
    </div>
                <h3>A free Remote Desktop Client for Linux, macOS and Windows.</h3>
        <p>A free Remote Desktop Client for Linux, macOS and Windows.</p>
        <p>Thincast Client turns your computer into a fully Remote Desktop Protocol (RDP) Client, making it easy to connect remotely to your company's infrastructure. Using the Remote Desktop (RD) WebAccess Client you gain easy access to and control of published virtual machines (with Thincast Workstation), desktop sessions and applications. Its built-in, hardware-accelerated Remote Desktop Client (RDC) delivers a rich user experience by saving valuable CPU power.</p>
           </div></div>]]>
            </description>
            <link>https://thincast.com/en/products/client</link>
            <guid isPermaLink="false">hacker-news-small-sites-24650312</guid>
            <pubDate>Thu, 01 Oct 2020 12:57:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[China forces international birding organization to eject Taiwan, gags employees]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24650128">thread link</a>) | @ilamont
<br/>
October 1, 2020 | https://www.cips-cepi.ca/2020/09/30/ruffled-feathers-why-chinese-interference-in-international-bird-conservation-is-a-threat-to-world-peace/ | <a href="https://web.archive.org/web/*/https://www.cips-cepi.ca/2020/09/30/ruffled-feathers-why-chinese-interference-in-international-bird-conservation-is-a-threat-to-world-peace/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
<hr>



<p><strong>The&nbsp;</strong><a href="https://www.theguardian.com/world/2020/sep/25/hawk-or-dove-birdwatching-worlds-feathers-ruffled-over-taiwan-independence"><strong>ejection</strong></a><strong>&nbsp;of Taiwan’s Chinese Wild Bird Federation (CWBF) from BirdLife International and the subsequent&nbsp;</strong><a href="https://www.reuters.com/article/us-taiwan-environment-politics/british-bird-group-issues-gag-order-over-taiwan-china-issue-idUSKBN2690BX"><strong>gag order</strong></a><strong>&nbsp;asking BirdLife employees to refrain from speaking to the press may appear at first glance to be the smallest of China’s many micro-aggressions, but is indicative of a serious security threat.&nbsp;</strong></p>



<hr>



<p>BirdLife notified the CWBF on September 7 that their 24-year-old partnership had ended. The reason? BirdLife asked the Taiwanese partner to change their official Chinese name and to sign a document promising to neither promote the independence of Taiwan from China nor to advocate the legitimacy of the Republic of China (Taiwan’s official name). It didn’t matter that the Federation had never taken a political stance on Taiwan’s status. It didn’t matter that they had already changed their English name three times at the behest of BirdLife, even twisting facts to alter the name from “Wild Bird Federation Taiwan” to “Chinese Wild Bird Federation” in 2007. BirdLife wouldn’t even give them time, as a democratically run NGO, to debate this at the Annual General Meeting. They simply kicked them out of the nest.&nbsp;</p>



<hr>



<p><strong>Recommended: </strong><a href="https://www.cips-cepi.ca/2020/09/29/mbss-admits-full-responsibility-for-the-khashoggi-murder-what-this-means-for-the-kingdoms-allies/"><strong>🏅2020 CIPS Blog Award Winner! MBS admits “full responsibility” for the Khashoggi murder: What this means for the Kingdom’s allies</strong></a></p>



<hr>



<p>Taiwan protested. The&nbsp;<a href="https://focustaiwan.tw/politics/202009150029">Ministry of Foreign Affairs</a>&nbsp;condemned China for interfering in international conservation NGOs and BirdLife for cooperating with China to coerce the CWBF into taking a political stance.&nbsp;On September 19, the General Assembly of the CWBF decided to finally revert to the more accurate name in English as the&nbsp;<a href="https://www.bird.org.tw/news/602?fbclid=IwAR1RgQoW9nXgZCHRBxlGgr7qamTs_nRhbUyffndt5WEbziqkX92HmKTIdDA">Taiwan Wild Bird Federation</a>.&nbsp;</p>



<p><strong>What is BirdLife?</strong></p>



<p>BirdLife, a global coalition of scientific and conservation NGOs, is active in Canada through Nature Canada and Birds Canada. It coordinates the IBA (Important Bird and Biodiversity Areas) program that identifies and manages important bird habitat sites. Because birds do not respect borders, collaboration between countries is central to BirdLife’s mandate. Since 2000, Taiwan’s Forestry Bureau has contributed to BirdLife conservation projects in Madagascar, Cambodia, and Sao Tome.&nbsp;</p>



<p>Taiwan is second only to Japan in Asia for bird conservation and scientific research. Taiwan hosts 682 bird species, 29 endemic species, and 43 endangered species. Taiwanese birders are active contributors to eBird, the world’s most comprehensive citizen science project in ornithology. The CWBF does important work to protect the Chinese Crested Tern and Black-faced Spoonbill. In 2020, the 4,864 Black-faced Spoonbills that wintered in Taiwan accounted for 57.3% of the population of that endangered species. Migratory birds along the East Asian-Australasian Flyway depend on Taiwan because of its strategic location on their pathways that stretch from Siberia to Australia. Taiwan’s expulsion from BirdLife will hinder cross-border cooperation on conservation, just because China prioritizes its political goals over even pragmatic scientific cooperation. China makes everything into a zero-sum game.&nbsp;</p>



<figure><p>
https://twitter.com/TaiwanBirding/status/1309409778393776128?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1309409778393776128%7Ctwgr%5Eshare_3&amp;ref_url=https%3A%2F%2Fpublish.twitter.com%2F%3Fquery%3Dhttps3A2F2Ftwitter.com2FTaiwanBirding2Fstatus2F1309409778393776128widget%3DTweet
</p></figure>



<p><strong>China Curtails Freedom of International Civil Society</strong></p>



<p>BirdLife is a dangerous precedent for other NGOs. Because China can pressure one leading NGO into cutting out Taiwan, they will feel emboldened to go after other NGOs – including in Canada. NGOs hoping to expand into China will hesitate to build partnerships with Taiwan. This is a shame because Taiwanese NGOs have strong expertise as well as the financial means to get things done. It is even more unfortunate because democratic Taiwan, like Canada, actually has real social movements run by civilians without government interference. China, on the other hand, strictly limits the freedoms of Chinese NGOs. Since 2017, when China changed its NGO regulations in line with broader security-related legislation, international NGOs have been required to register with the Ministry of Public Security and must have an approved local partner. This means the Chinese Communist Party can use NGOs to export their standards to the world.&nbsp;</p>



<p>Until now, China has not permitted BirdLife to enter China, which means the closest they get is collaboration with the Hong Kong Birdwatching Society. Maybe that is the point. Quite possibly, BirdLife is negotiating with China and took action against Taiwan as a precondition for collaboration. The cost is high. It means letting China dictate the norms of how international NGOs operate. BirdLife even imported Chinese norms on media freedom by issuing a gag order to their employees. And this is in Great Britain, which takes pride in the Magna Charta as one of the founding documents of democracy.&nbsp;</p>



<p>Because of China’s sheer size and long coastlines used by migratory birds, BirdLife is badly needed in China. International bird conservation would improve if China were to open up its own borders to free, unfettered cooperation between Chinese and international NGOs. Bird habitats along migration routes would be best protected if China were to set aside politics and collaborate with Taiwanese ornithologists and conservation scientists&nbsp;&nbsp;like Japan and Russia do in spite of long-standing territorial disputes that straddle bird habitats.&nbsp;&nbsp;</p>



<p><strong>The Bigger Picture</strong></p>



<p>China’s pressure on BirdLife is part of a new strategy. For decades, BirdLife’s Taiwanese partner could simply accept a compromise name of “Chinese Wild Bird Federation” internationally; and “Republic of China Wild Bird Federation” at home. BirdLife and the CWBF could collaborate as long as they remained silent about China-Taiwan relations. The most troubling sign is not the requested name change, but the fact that the CWBF was asked to commit themselves to a political stance. China is trying to shape a world in which even silence is not an option. China’s goal is to get the entire world to parrot its claims that Taiwan is part of the People’s Republic of China. This must be seen as part of a larger strategy in which the Chinese military during a global pandemic feels emboldened to practice invasion of Taiwan and to regularly send jets into Taiwanese airspace.&nbsp;</p>



<p>BirdLife should be reminding the world that coastal birds inhabiting wetlands along the Taiwan Straits would be the first victims if China were to ever invade Taiwan. Instead, their abandonment of the Taiwan Wild Bird Federation gives Beijing one more sign that the world does not oppose their strategy to annex Taiwan. Acquiescing to Chinese micro-management of international NGOs is not good for the birds and, in the long run, it is dangerous for the security of the entire region.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p>



<hr>



<p><strong>Recommended: </strong><a href="https://www.cips-cepi.ca/2020/09/27/twitter-conference-understanding-the-five-eyes/"><strong>Twitter Conference: Understanding the Five Eyes</strong></a></p>




</div></div></div>]]>
            </description>
            <link>https://www.cips-cepi.ca/2020/09/30/ruffled-feathers-why-chinese-interference-in-international-bird-conservation-is-a-threat-to-world-peace/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24650128</guid>
            <pubDate>Thu, 01 Oct 2020 12:31:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Segment Tree – Competitive Programming Algorithms]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24650084">thread link</a>) | @pmoriarty
<br/>
October 1, 2020 | https://cp-algorithms.com/data_structures/segment_tree.html | <a href="https://web.archive.org/web/*/https://cp-algorithms.com/data_structures/segment_tree.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="container">
    


<p>A Segment Tree is a data structure that allows answering range queries over an array effectively, while still being flexible enough to allow modifying the array. 
This includes finding the sum of consecutive array elements $a[l \dots r]$, or finding the minimum element in a such a range in $O(\log n)$ time. 
Between answering such queries the Segment Tree allows modifying the array by replacing one element, or even change the elements of a whole subsegment (e.g. assigning all elements $a[l \dots r]$ to any value, or adding a value to all element in the subsegment).</p>

<p>In general a Segment Tree is a very flexible data structure, and a huge number of problems can be solved with it. 
Additionally it is also possible to apply more complex operations and answer more complex queries (see <a href="https://cp-algorithms.com/data_structures/segment_tree.html#advanced-versions-of-segment-trees">Advanced versions of Segment Trees</a>).
In particular the Segment Tree can be easily generalized to larger dimensions. 
For instance with a two-dimensional Segment Tree you can answer sum or minimum queries over some subrectangle of a given matrix.
However only in $O(\log^2 n)$ time.</p>

<p>One important property of Segment Trees is, that they require only a linear amount of memory.
The standard Segment Tree requires $4n$ vertices for working on an array of size $n$.</p>

<h2>Simplest form of a Segment Tree</h2>

<p>To start easy, we consider the simplest form of a Segment Tree. 
We want to answer sum queries efficiently. 
The formal definition of our task is:
We have an array $a[0 \dots n-1]$, and the Segment Tree must be able to find the sum of elements between the indices $l$ and $r$ (i.e. computing the sum $\sum_{i=l}^r a[i]$), and also handle changing values of the elements in the array (i.e. perform assignments of the form $a[i] = x$). 
The Segment Tree should be able to process both queries in $O(\log n)$ time.</p>

<h3>Structure of the Segment Tree</h3>

<p>So, what is a Segment Tree?</p>

<p>We compute and store the sum of the elements of the whole array, i.e. the sum of the segment $a[0 \dots n-1]$. 
We then split the array into two halves $a[0 \dots n/2]$ and $a[n/2+1 \dots n-1]$ and compute the sum of each halve and store them. 
Each of these two halves in turn also split in half, their sums are computed and stored. 
And this process repeats until all segments reach size $1$. 
In other words we start with the segment $a[0 \dots n-1]$, split the current segment in half (if it has not yet become a segment containing a single element), and then calling the same procedure for both halves. 
For each such segment we store the sum of the numbers on it.</p>

<p>We can say, that these segments form a binary tree: 
the root of this tree is the segment $a[0 \dots n-1]$, and each vertex (except leaf vertices) has exactly two child vertices. 
This is why the data structure is called "Segment Tree", even though in most implementations the tree is not constructed explicitly (see <a href="https://cp-algorithms.com/data_structures/segment_tree.html#implementation">Implementation</a>).</p>

<p>Here is a visual representation of such a Segment Tree over the array $a = [1, 3, -2, 8, -7]$:</p>

<p><img src="https://raw.githubusercontent.com/e-maxx-eng/e-maxx-eng/master/img/sum-segment-tree.png" alt="&quot;Sum Segment Tree&quot;"></p>

<p>From this short description of the data structure, we can already conclude that a Segment Tree only requires a linear number of vertices. 
The first level of the tree contains a single node (the root), the second level will contain two vertices, in the third it will contain four vertices, until the number of vertices reaches $n$. 
Thus the number of vertices in the worst case can be estimated by the sum $1 + 2 + 4 + \dots + 2^{\lceil\log_2 n\rceil} = 2^{\lceil\log_2 n\rceil + 1} \lt 4n$.</p>

<p>It is worth noting that whenever $n$ is not a power of two, not all levels of the Segment Tree will be completely filled. 
We can see that behavior in the image.
For now we can forget about this fact, but it will become important later during the implementation.</p>

<p>The height of the Segment Tree is $O(\log n)$, because when going down from the root to the leaves the size of the segments decreases approximately by half.</p>

<h3>Construction</h3>

<p>Before constructing the segment tree, we need to decide:</p>

<ol>
<li>the <em>value</em> that gets stored at each node of the segment tree.
For example, in a sum segment tree, a node would store the sum of the elements in its range $[l, r]$.</li>
<li>the <em>merge</em> operation that merges two siblings in a segment tree.
For example, in a sum segment tree, the two nodes corresponding to the ranges $a[l_1 \dots r_1]$ and $a[l_2 \dots r_2]$ would be merged into a node corresponding to the range $a[l_1 \dots r_2]$ by adding the values of the two nodes.</li>
</ol>

<p>Note that a vertex is a "leaf vertex", if its corresponding segment covers only one value in the original array. It is present at the lowermost level of a segment tree. Its value would be equal to the (corresponding) element $a[i]$.</p>

<p>Now, for construction of the segment tree, we start at the bottom level (the leaf vertices) and assign them their respective values. On the basis of these values, we can compute the values of the previous level, using the <code>merge</code> function.
And on the basis of those, we can compute the values of the previous, and repeat the procedure until we reach the root vertex.</p>

<p>It is convenient to describe this operation recursively in the other direction, i.e., from the root vertex to the leaf vertices. The construction procedure, if called on a non-leaf vertex, does the following:</p>

<ol>
<li>recursively construct the values of the two child vertices</li>
<li>merge the computed values of these children.</li>
</ol>

<p>We start the construction at the root vertex, and hence, we are able to compute the entire segment tree.</p>

<p>The time complexity of this construction is $O(n)$, assuming that the merge operation is constant time (the merge operation gets called $n$ times, which is equal to the number of internal nodes in the segment tree).</p>

<h3>Sum queries</h3>

<p>For now we are going to answer sum queries. As an input we receive two integers $l$ and $r$, and we have to compute the sum of the segment $a[l \dots r]$ in $O(\log n)$ time.</p>

<p>To do this, we will traverse the Segment Tree and use the precomputed sums of the segments.
Let's assume that we are currently at the vertex that covers the segment $a[tl \dots tr]$.
There are three possible cases.</p>

<p>The easiest case is when the segment $a[l \dots r]$ is equal to the corresponding segment of the current vertex (i.e. $a[l \dots r] = a[tl \dots tr]$), then we are finished and can return the precomputed sum that is stored in the vertex.</p>

<p>Alternatively the segment of the query can fall completely into the domain of either the left or the right child.
Recall that the left child covers the segment $a[tl \dots tm]$ and the right vertex covers the segment $a[tm + 1 \dots tr]$ with $tm = (tl + tr) / 2$. 
In this case we can simply go to the child vertex, which corresponding segment covers the query segment, and execute the algorithm described here with that vertex.</p>

<p>And then there is the last case, the query segment intersects with both children. 
In this case we have no other option as to make two recursive calls, one for each child.
First we go to the left child, compute a partial answer for this vertex (i.e. the sum of values of the intersection between the segment of the query and the segment of the left child), then go to the right child, compute the partial answer using that vertex, and then combine the answers by adding them. 
In other words, since the left child represents the segment $a[tl \dots tm]$ and the right child the segment $a[tm+1 \dots tr]$, we compute the sum query $a[l \dots tm]$ using the left child, and the sum query $a[tm+1 \dots r]$ using the right child.</p>

<p>So processing a sum query is a function that recursively calls itself once with either the left or the right child (without changing the query boundaries), or twice, once for the left and once for the right child (by splitting the query into two subqueries). 
And the recursion ends, whenever the boundaries of the current query segment coincides with the boundaries of the segment of the current vertex. 
In that case the answer will be the precomputed value of the sum of this segment, which is stored in the tree.</p>

<p>In other words, the calculation of the query is a traversal of the tree, which spreads through all necessary branches of the tree, and uses the precomputed sum values of the segments in the tree.</p>

<p>Obviously we will start the traversal from the root vertex of the Segment Tree.</p>

<p>The procedure is illustrated in the following image.
Again the array $a = [1, 3, -2, 8, -7]$ is used, and here we want to compute the sum $\sum_{i=2}^4 a[i]$.
The colored vertices will be visited, and we will use the precomputed values of the green vertices.
This gives us the result $-2 + 1 = -1$.</p>

<p><img src="https://raw.githubusercontent.com/e-maxx-eng/e-maxx-eng/master/img/sum-segment-tree-query.png" alt="&quot;Sum Segment Tree Query&quot;"></p>

<p>Why is the complexity of this algorithm $O(\log n)$?
To show this complexity we look at each level of the tree. 
It turns out, that for each level we only visit not more than four vertices. 
And since the height of the tree is $O(\log n)$, we receive the desired running time.</p>

<p>We can show that this proposition (at most four vertices each level) is true by induction.
At the first level, we only visit one vertex, the root vertex, so here we visit less than four vertices. 
Now let's look at an arbitrary level.
By induction hypothesis, we visit at most four vertices. 
If we only visit at most two vertices, the next level has at most four vertices. That trivial, because each vertex can only cause at most two recursive calls. 
So let's assume that we visit three or four vertices in the current level. 
From those vertices, we will analyze the vertices in the middle more carefully. 
Since the sum query asks for the sum of a continuous subarray, we know that segments corresponding to the visited vertices in the middle will be completely covered by the segment of the sum query. 
Therefore these vertices will not make any recursive calls. 
So only the most left, and the most right vertex will have the potential to make recursive calls. 
And those will only create at most four recursive calls, so also the next level will satisfy the assertion.
We can say that one branch approaches the left boundary of the query, and the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cp-algorithms.com/data_structures/segment_tree.html">https://cp-algorithms.com/data_structures/segment_tree.html</a></em></p>]]>
            </description>
            <link>https://cp-algorithms.com/data_structures/segment_tree.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24650084</guid>
            <pubDate>Thu, 01 Oct 2020 12:25:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MIT new large tokamak to be the first in history to do self-sustaining reaction]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24650030">thread link</a>) | @vermontdevil
<br/>
October 1, 2020 | https://defector.com/if-scientists-are-to-create-and-harness-the-unfathomable-power-of-a-star-they-must-agree-to-hurl-me-into-it/ | <a href="https://web.archive.org/web/*/https://defector.com/if-scientists-are-to-create-and-harness-the-unfathomable-power-of-a-star-they-must-agree-to-hurl-me-into-it/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div id="pico">
<p>Scientists at the Massachusetts Institute of Technology <a href="https://www.nytimes.com/2020/09/29/climate/nuclear-fusion-reactor.html?smtyp=cur&amp;smid=tw-nytimes&amp;utm_source=Default+audience&amp;utm_campaign=88af7df3e9-EMAIL_CAMPAIGN_2020_09_29_06_13&amp;utm_medium=email&amp;utm_term=0_3cb9478f4c-88af7df3e9-193252502" target="_blank">are developing</a> a type of reactor, called a tokamak, which if it works as intended will generate conditions of sufficient intensity to fuse hydrogen isotopes and harness all the incredible energy released in the process. Their goal is super ambitious: There are other tokamaks, but the MIT scientists expect their large tokamak to be the first in history that is capable of a self-sustaining reaction, and the first that generates more energy than it uses. And they expect to pivot immediately from this historic engineering feat to commercial energy production, and to do all of this on a relatively modest budget, and on a timeline of just three to four years. They expect, in other words, to build the world’s first fully operational thermonuclear fusion reactor, pumping out infinitely sustainable energy right here in the U.S. of A.</p>



<p>I expect to walk up to this tokamak, engage the help of several brawny nuclear engineers, and to be hurled bodily into the inconceivable heat and indescribable beauty of the radiant plasma cloud magnetically suspended in its core, so that I am instantaneously vaporized and eradicated altogether from this plane of existence. The sooner the better.</p>



<p>Initially it seemed that the best choice for this job would be the International Thermonuclear Experimental Reactor, or ITER, in Provence, France. Whereas the <a href="https://www.psfc.mit.edu/sparc" target="_blank">SPARC tokamak</a> being developed by MIT will be the size of a tennis court, <a href="https://www.iter.org/mach" target="_blank">the ITER</a>, which has been in various phases of development and construction for something like 13 years, will eventually be the size of a soccer field. The specs on this thing <a href="https://www.newyorker.com/magazine/2014/03/03/a-star-in-a-bottle" target="_blank">are mind-boggling</a>:</p>



<blockquote><p>At its core, densely packed high-precision equipment will encase a cavernous vacuum chamber, in which a super-hot cloud of heavy hydrogen will rotate faster than the speed of sound, twisting like a strand of DNA as it circulates. The cloud will be scorched by electric current (a surge so forceful that it will make lightning seem like a tiny arc of static electricity), and bombarded by concentrated waves of radiation. Beams of uncharged particles—the energy in them so great it could vaporize a car in seconds—will pour into the chamber, adding tremendous heat. In this way, the circulating hydrogen will become ionized, and achieve temperatures exceeding two hundred million degrees Celsius—more than ten times as hot as the sun at its blazing core.</p><cite>&nbsp;Raffi Khatchadourian, <em><a href="https://www.newyorker.com/magazine/2014/03/03/a-star-in-a-bottle" target="_blank">The New Yorker</a></em></cite></blockquote>



<p>“Tremendous heat” is an understatement of brain-scrambling, laugh-out-loud proportions. This cloud of plasma will be so hot that no physical substance on Earth or known to humankind could contain it for even a fraction of a second: “Metals, plastics, ceramics, concrete, even pure diamond—all would be obliterated on contact.” The only way to keep the plasma cloud in place, and thus concentrated enough to trigger nuclear fusion, is to squeeze it into a pocket of space using the “titanic forces” of “the largest system of superconducting magnets in the world,” actively cooled to deep-space temperatures in order to survive the heat of an actual star.</p>



<p>So in an ultra-secure chamber in a pit in the countryside of Provence, a blob of the hottest substance in our entire solar system will hang in the air, consuming hydrogen isotopes and generating enough energy to turn diamonds into vapor on contact. There are those who would point out that it is probably a bad idea to let humanity just have the Sun, that inevitably some technician is going to want to pull a viral YouTube prank by aiming a beam of the God Cloud at his buddy’s balls and wind up boring a hole through the planet itself. Or that a janitor will absentmindedly unplug the supercooling systems that allow the mega-magnets to contain the reaction and accidentally atomize the Western Hemisphere. Those people are probably right. Humanity can’t be counted upon to safely handle livestock—putting it in charge of a star seems like something that should not be allowed, by the universe.</p>



<p>But since we are building these things anyway, all I ask is that I be lifted by the scruff of my shirt and the seat of my pants by two strong nuclear technicians and, on the count of three, heaved face-first into whichever of the two God Clouds is completed first. It’s nice to think of all my atoms instantly dispersing into the fabric of the universe, but mostly it will be extremely bitchin’ to be devoured by a star. If this cannot be arranged for whatever reason, I will accept having a beam of the star juice fired into my chest, so that I may utter “fuck yeah” before it is over.</p>
</div></div></div></div></div>]]>
            </description>
            <link>https://defector.com/if-scientists-are-to-create-and-harness-the-unfathomable-power-of-a-star-they-must-agree-to-hurl-me-into-it/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24650030</guid>
            <pubDate>Thu, 01 Oct 2020 12:19:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New white paper on open-source Edge Computing with OpenNebula]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24649831">thread link</a>) | @amarti
<br/>
October 1, 2020 | https://opennebula.io/get-edge-computing-whitepaper/ | <a href="https://web.archive.org/web/*/https://opennebula.io/get-edge-computing-whitepaper/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="full-width-page-wrapper-enterprise">
    <!-- .entry-header -->

	<div id="content">

		<div>

			<div id="primary">

				<main id="main" role="main">

					
						
<article class="page" id="post-27526">

	
	<div>

		
<p>Complete the form below to receive an email with the instructions to download our new white paper on <strong>Edge Computing with OpenNebula</strong> and to subscribe to receive communications like new releases, events, tutorials, workshops, webinars, and more. If you want to learn more about OpenNebula’s open source edge computing platform, please visit <a href="http://oneedge.io/" target="_blank" rel="noreferrer noopener">ONEedge.io</a></p>







<div><figure><img src="https://opennebula.io/wp-content/uploads/2020/09/EdgeWP.png" alt="" srcset="https://opennebula.io/wp-content/uploads/2020/09/EdgeWP.png 622w, https://opennebula.io/wp-content/uploads/2020/09/EdgeWP-300x216.png 300w" sizes="(max-width: 622px) 100vw, 622px"></figure></div>
















		
	</div><!-- .entry-content -->

</article><!-- #post-## -->

						
					
				</main><!-- #main -->

			</div><!-- #primary -->

		</div><!-- .row end -->

	</div><!-- #content -->

</div></div>]]>
            </description>
            <link>https://opennebula.io/get-edge-computing-whitepaper/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649831</guid>
            <pubDate>Thu, 01 Oct 2020 11:49:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Web Neural Network API]]>
            </title>
            <description>
<![CDATA[
Score 48 | Comments 20 (<a href="https://news.ycombinator.com/item?id=24649616">thread link</a>) | @rajveermalviya
<br/>
October 1, 2020 | https://webmachinelearning.github.io/webnn/ | <a href="https://web.archive.org/web/*/https://webmachinelearning.github.io/webnn/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
   <h2 data-level="1" id="intro"><span>1. </span><span>Introduction</span><a href="#intro"></a></h2>
   <p>We’re working on this section. Meanwhile, please take a look at the <a href="https://github.com/webmachinelearning/webnn/blob/master/explainer.md">explainer</a>.</p>
   <h2 data-level="2" id="usecases"><span>2. </span><span>Use cases</span><a href="#usecases"></a></h2>
   <h3 data-level="2.1" id="usecases-application"><span>2.1. </span><span>Application Use Cases</span><a href="#usecases-application"></a></h3>
   <p>This section illustrates application-level use cases for neural network
inference hardware acceleration. All applications in those use cases can be
built on top of pre-trained deep neural network (DNN) models.</p>
   <h4 data-level="2.1.1" id="usecase-person-detection"><span>2.1.1. </span><span>Person Detection</span><a href="#usecase-person-detection"></a></h4>
   <p>A user opens a web-based video conferencing application, but she temporarily
leaves from her room. The application is watching whether she is in front of her
PC by using object detection (for example, using object detection approaches
such as <a data-link-type="biblio" href="#biblio-ssd">[SSD]</a> or <a data-link-type="biblio" href="#biblio-yolo">[YOLO]</a> that use a single DNN) to detect regions in a camera
input frame that include persons.</p>
   <p>When she comes back, the application automatically detects her and notifies
other online users that she is active now.</p>
   <h4 data-level="2.1.2" id="usecase-segmentation"><span>2.1.2. </span><span>Semantic Segmentation</span><a href="#usecase-segmentation"></a></h4>
   <p>A user joins a teleconference via a web-based video conferencing application at
her desk since no meeting room in her office is available. During the
teleconference, she does not wish that her room and people in the background are
visible. To protect the privacy of the other people and the surroundings, the
application runs a machine learning model such as <a data-link-type="biblio" href="#biblio-deeplabv3">[DeepLabv3+]</a> or <a data-link-type="biblio" href="#biblio-maskr-cnn">[MaskR-CNN]</a> to semantically split an image into segments and replaces
segments that represent other people and background with another picture.</p>
   <h4 data-level="2.1.3" id="usecase-skeleton-detection"><span>2.1.3. </span><span>Skeleton Detection</span><a href="#usecase-skeleton-detection"></a></h4>
   <p>A web-based video conferencing application tracks a pose of user’s skeleton by
running a machine learning model, which allows for real-time human pose
estimation, such as <a data-link-type="biblio" href="#biblio-posenet">[PoseNet]</a> to recognize her gesture and body language. When
she raises her hand, her microphone is automatically unmuted and she can start
speaking on the teleconference.</p>
   <h4 data-level="2.1.4" id="usecase-face-recognition"><span>2.1.4. </span><span>Face Recognition</span><a href="#usecase-face-recognition"></a></h4>
   <p>There are multiple people in the conference room and they join an online meeting
using a web-based video conferencing application. The application detects faces
of participants by using object detection (for example, using object detection
approaches such as <a data-link-type="biblio" href="#biblio-ssd">[SSD]</a>) and checks whether each face was present at the
previous meeting or not by running a machine learning model such as <a data-link-type="biblio" href="#biblio-facenet">[FaceNet]</a>,
which verifies whether two faces would be identical or not.</p>
   <h4 data-level="2.1.5" id="usecase-facial-landmarks"><span>2.1.5. </span><span>Facial Landmark Detection</span><a href="#usecase-facial-landmarks"></a></h4>
   <p>A user wants to find new glasses that beautifully fits her on an online glasses
store. The online store offers web-based try-on simulator that runs a machine
learning model such as Face Alignment Network <a data-link-type="biblio" href="#biblio-fan">[FAN]</a> to detect facial landmarks
like eyes, nose, mouth, etc. When she chooses a pair of glasses, the simulator
properly render the selected glasses on the detected position of eyes on her
facial image.</p>
   <h4 data-level="2.1.6" id="usecase-style-transfer"><span>2.1.6. </span><span>Style Transfer</span><a href="#usecase-style-transfer"></a></h4>
   <p>A user is looking for cosmetics on an online store and wondering which color may
fit her face. The online store shows sample facial makeup images of cosmetics,
and offers makeup simulator that runs a machine learning model like <a data-link-type="biblio" href="#biblio-contextualloss">[ContextualLoss]</a> or <a data-link-type="biblio" href="#biblio-pairedcyclegan">[PairedCycleGAN]</a> to transfer the makeup style of the
sample makeup image to her facial image. She can check how the selected makeup
looks like on her face by the simulator.</p>
   <h4 data-level="2.1.7" id="usecase-super-resolution"><span>2.1.7. </span><span>Super Resolution</span><a href="#usecase-super-resolution"></a></h4>
   <p>A web-based video conferencing is receiving a video stream from its peer, but
the resolution of the video becomes lower due to network congestion. To prevent
degradation of the perceived video quality, the application runs a machine
learning model for super-resolution such as <a data-link-type="biblio" href="#biblio-srgan">[SRGAN]</a> to generate
higher-resolution video frames.</p>
   <h4 data-level="2.1.8" id="usecase-image-captioning"><span>2.1.8. </span><span>Image Captioning</span><a href="#usecase-image-captioning"></a></h4>
   <p>For better accessibility, a web-based presentation application provides
automatic image captioning by running a machine learning model such as <a data-link-type="biblio" href="#biblio-im2txt">[im2txt]</a> which predicts explanatory words of the presentation slides.</p>
   <h4 data-level="2.1.9" id="usecase-translation"><span>2.1.9. </span><span>Machine Translation</span><a href="#usecase-translation"></a></h4>
   <p>Multiple people from various countries are talking via a web-based real-time
text chat application. The application translates their conversation by using a
machine learning model such as <a data-link-type="biblio" href="#biblio-gnmt">[GNMT]</a> or <a data-link-type="biblio" href="#biblio-opennmt">[OpenNMT]</a>, which translates every
text into different language.</p>
   <h4 data-level="2.1.10" id="usecase-emotion-analysis"><span>2.1.10. </span><span>Emotion Analysis</span><a href="#usecase-emotion-analysis"></a></h4>
   <p>A user is talking to her friend via a web-based real-time text chat application,
and she is wondering how the friend feels because she cannot see the friend’s
face. The application analyses the friend’s emotion by using a machine learning
model such as <a data-link-type="biblio" href="#biblio-deepmoji">[DeepMoji]</a>, which infers emotion from input texts, and displays
an emoji that represents the estimated emotion.</p>
   <h4 data-level="2.1.11" id="usecase-video-summalization"><span>2.1.11. </span><span>Video Summarization</span><a href="#usecase-video-summalization"></a></h4>
   <p>A web-based video conferencing application records received video streams, and
it needs to reduce recorded video data to be stored. The application generates
the short version of the recorded video by using a machine learning model for
video summarization such as <a data-link-type="biblio" href="#biblio-video-summarization-with-lstm">[Video-Summarization-with-LSTM]</a>.</p>
   <h4 data-level="2.1.12" id="usecase-noise-suppression"><span>2.1.12. </span><span>Noise Suppression</span><a href="#usecase-noise-suppression"></a></h4>
   <p>A web-based video conferencing application records received audio streams, but
usually the background noise is everywhere. The application leverages real-time 
noise suppression using Recurrent Neural Network such as <a data-link-type="biblio" href="#biblio-rnnoise">[RNNoise]</a> for 
suppressing background dynamic noise like baby cry or dog barking to improve 
audio experiences in video conferences.</p>
   <h3 data-level="2.2" id="usecases-framework"><span>2.2. </span><span>Framework Use Cases</span><a href="#usecases-framework"></a></h3>
   <p>This section collects framework-level use cases for a dedicated low-level API
for neural network inference hardware acceleration. It is expected that Machine
Learning frameworks will be key consumers of the Web Neural Network API (WebNN
API) and the low-level details exposed through the WebNN API are abstracted out
from typical web developers. However, it is also expected that web developers
with specific interest and competence in Machine Learning will want to interface
with the WebNN API directly instead of a higher-level ML framework.</p>
   <h4 data-level="2.2.1" id="usecase-custom-layer"><span>2.2.1. </span><span>Custom Layer</span><a href="#usecase-custom-layer"></a></h4>
   <p>A web application developer wants to run a DNN model on the WebNN API. However,
she has found that some of activation functions like <a data-link-type="biblio" href="#biblio-leakyrelu">[LeakyReLU]</a>, <a data-link-type="biblio" href="#biblio-elu">[ELU]</a>,
etc. are not included in the WebNN API. To address this issue, she constructs
custom layers of the additional activation functions on top of the WebNN API.
Note that the scope of custom layers may include convolution, normalization,
etc. as well as activation.</p>
   <h4 data-level="2.2.2" id="usecase-network-concat"><span>2.2.2. </span><span>Network Concatenation</span><a href="#usecase-network-concat"></a></h4>
   <p>A web application uses a DNN model, and its model data of upper convolutional
layers and lower fully-connected layers are stored in separate files, since
model data of the fully-connected layers are periodically updated due to fine
tuning at the server side.</p>
   <p>Therefore, the application downloads both partial model files at first and
concatenates them into a single model. When the model is updated, the
application downloads fine-tuned part of the model and replace only the
fully-connected layers with it.</p>
   <h4 data-level="2.2.3" id="usecase-perf-adapt"><span>2.2.3. </span><span>Performance Adaptation</span><a href="#usecase-perf-adapt"></a></h4>
   <p>A web application developer has a concern about performance of her DNN model on
mobile devices. She has confirmed that it may run too slow on mobile devices
which do not have GPU acceleration. To address this issue, her web application
refers to the WebNN API to confirm whether acceleration is available or not, so
that the application can display the warning for devices without acceleration.</p>
   <p>After several weeks, she has developed a tiny DNN model that can even run on
CPU. In order to accommodate CPU execution, she modifies the application
so that the application loads the tiny model in the case of CPU-only devices.</p>
   <h2 data-level="3" id="api"><span>3. </span><span>API</span><a href="#api"></a></h2>
   <h3 data-level="3.1" id="api-navigator"><span>3.1. </span><span>Navigator</span><a href="#api-navigator"></a></h3>
<pre><c- b="">partial</c-> <c- b="">interface</c-> <a data-link-type="interface" href="https://html.spec.whatwg.org/multipage/system-state.html#navigator" id="ref-for-navigator"><c- g="">Navigator</c-></a> {
  <c- b="">readonly</c-> <c- b="">attribute</c-> <a data-link-type="idl-name" href="#ml" id="ref-for-ml"><c- n="">ML</c-></a> <dfn data-dfn-for="Navigator" data-dfn-type="attribute" data-export="" data-readonly="" data-type="ML" id="dom-navigator-ml"><code><c- g="">ml</c-></code><a href="#dom-navigator-ml"></a></dfn>;
};
</pre>
   <h3 data-level="3.2" id="api-ml"><span>3.2. </span><span>ML</span><a href="#api-ml"></a></h3>
<pre><c- b="">interface</c-> <dfn data-dfn-type="interface" data-export="" id="ml"><code><c- g="">ML</c-></code></dfn> {
  <a data-link-type="idl-name" href="#neuralnetworkcontext" id="ref-for-neuralnetworkcontext"><c- n="">NeuralNetworkContext</c-></a> <dfn data-dfn-for="ML" data-dfn-type="method" data-export="" data-lt="getNeuralNetworkContext()" id="dom-ml-getneuralnetworkcontext"><code><c- g="">getNeuralNetworkContext</c-></code><a href="#dom-ml-getneuralnetworkcontext"></a></dfn>();
};
</pre>
   <h3 data-level="3.3" id="api-operanddescriptor"><span>3.3. </span><span>OperandDescriptor</span><a href="#api-operanddescriptor"></a></h3>
<pre><c- b="">enum</c-> <dfn data-dfn-type="enum" data-export="" id="enumdef-operandlayout"><code><c- g="">OperandLayout</c-></code></dfn> {
  <dfn data-dfn-for="OperandLayout" data-dfn-type="enum-value" data-export="" id="dom-operandlayout-nchw"><code><c- s="">"nchw"</c-></code><a href="#dom-operandlayout-nchw"></a></dfn>,
  <dfn data-dfn-for="OperandLayout" data-dfn-type="enum-value" data-export="" id="dom-operandlayout-nhwc"><code><c- s="">"nhwc"</c-></code><a href="#dom-operandlayout-nhwc"></a></dfn>
};

<c- b="">enum</c-> <dfn data-dfn-type="enum" data-export="" id="enumdef-operandtype"><code><c- g="">OperandType</c-></code></dfn> {
  <dfn data-dfn-for="OperandType" data-dfn-type="enum-value" data-export="" id="dom-operandtype-float32"><code><c- s="">"float32"</c-></code><a href="#dom-operandtype-float32"></a></dfn>,
  <dfn data-dfn-for="OperandType" data-dfn-type="enum-value" data-export="" id="dom-operandtype-float16"><code><c- s="">"float16"</c-></code><a href="#dom-operandtype-float16"></a></dfn>,
  <dfn data-dfn-for="OperandType" data-dfn-type="enum-value" data-export="" id="dom-operandtype-int32"><code><c- s="">"int32"</c-></code><a href="#dom-operandtype-int32"></a></dfn>,
  <dfn data-dfn-for="OperandType" data-dfn-type="enum-value" data-export="" id="dom-operandtype-uint32"><code><c- s="">"uint32"</c-></code><a href="#dom-operandtype-uint32"></a></dfn>,
  <dfn data-dfn-for="OperandType" data-dfn-type="enum-value" data-export="" id="dom-operandtype-tensor-float32"><code><c- s="">"tensor-float32"</c-></code><a href="#dom-operandtype-tensor-float32"></a></dfn>,
  <dfn data-dfn-for="OperandType" data-dfn-type="enum-value" data-export="" id="dom-operandtype-tensor-float16"><code><c- s="">"tensor-float16"</c-></code><a href="#dom-operandtype-tensor-float16"></a></dfn>,
  <dfn data-dfn-for="OperandType" data-dfn-type="enum-value" data-export="" id="dom-operandtype-tensor-int32"><code><c- s="">"tensor-int32"</c-></code><a href="#dom-operandtype-tensor-int32"></a></dfn>,
  <dfn data-dfn-for="OperandType" data-dfn-type="enum-value" data-export="" id="dom-operandtype-tensor-quant8-asymm"><code><c- s="">"tensor-quant8-asymm"</c-></code><a href="#dom-operandtype-tensor-quant8-asymm"></a></dfn>
};

<c- b="">dictionary</c-> <dfn data-dfn-type="dictionary" data-export="" id="dictdef-operanddescriptor"><code><c- g="">OperandDescriptor</c-></code></dfn> {
  // The operand type.
  <c- b="">required</c-> <a data-link-type="idl-name" href="#enumdef-operandtype" id="ref-for-enumdef-operandtype"><c- n="">OperandType</c-></a> <dfn data-dfn-for="OperandDescriptor" data-dfn-type="dict-member" data-export="" data-type="OperandType " id="dom-operanddescriptor-type"><code><c- g="">type</c-></code><a href="#dom-operanddescriptor-type"></a></dfn>;

  // The dimensions field is only required for tensor operands.
  // The negative value means an unknown dimension.
  <c- b="">sequence</c->&lt;<a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long"><c- b="">long</c-></a>&gt; <dfn data-dfn-for="OperandDescriptor" data-dfn-type="dict-member" data-export="" data-type="sequence<long> " id="dom-operanddescriptor-dimensions"><code><c- g="">dimensions</c-></code><a href="#dom-operanddescriptor-dimensions"></a></dfn>;

  // The following two fields are only required for quantized operand.
  // scale: an non-negative floating point value
  // zeroPoint: an integer, in range [0, 255]
  // The real value is (value - zeroPoint) * scale
  <a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-float" id="ref-for-idl-float"><c- b="">float</c-></a> <dfn data-dfn-for="OperandDescriptor" data-dfn-type="dict-member" data-export="" data-type="float " id="dom-operanddescriptor-scale"><code><c- g="">scale</c-></code><a href="#dom-operanddescriptor-scale"></a></dfn>;
  <a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long①"><c- b="">long</c-></a> <dfn data-dfn-for="OperandDescriptor" data-dfn-type="dict-member" data-export="" data-type="long " id="dom-operanddescriptor-zeropoint"><code><c- g="">zeroPoint</c-></code><a href="#dom-operanddescriptor-zeropoint"></a></dfn>;
};
</pre>
   <h3 data-level="3.4" id="api-operand"><span>3.4. </span><span>Operand</span><a href="#api-operand"></a></h3>
<pre><c- b="">interface</c-> <dfn data-dfn-type="interface" data-export="" id="operand"><code><c- g="">Operand</c-></code></dfn> {};
</pre>
   <h3 data-level="3.5" id="api-neuralnetworkcontext"><span>3.5. </span><span>NeuralNetworkContext</span><a href="#api-neuralnetworkcontext"></a></h3>
   <p>The <code><a data-link-type="idl" href="#neuralnetworkcontext" id="ref-for-neuralnetworkcontext①">NeuralNetworkContext</a></code> defines a set of operations derived from the first-wave models <a data-link-type="biblio" href="#biblio-models">[Models]</a> that address identified <a href="#usecases">§ 2 Use cases</a>.</p>
<pre><c- b="">typedef</c-> <a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-double" id="ref-for-idl-double"><c- b="">double</c-></a> <dfn data-dfn-type="typedef" data-export="" id="typedefdef-number"><code><c- g="">number</c-></code></dfn>;

<c- b="">dictionary</c-> <dfn data-dfn-type="dictionary" data-export="" id="dictdef-namedoperand"><code><c- g="">NamedOperand</c-></code></dfn> {
  <c- b="">required</c-> <a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-DOMString" id="ref-for-idl-DOMString"><c- b="">DOMString</c-></a> <dfn data-dfn-for="NamedOperand" data-dfn-type="dict-member" data-export="" data-type="DOMString " id="dom-namedoperand-name"><code><c- g="">name</c-></code><a href="#dom-namedoperand-name"></a></dfn>;
  <c- b="">required</c-> <a data-link-type="idl-name" href="#operand" id="ref-for-operand"><c- n="">Operand</c-></a> <dfn data-dfn-for="NamedOperand" data-dfn-type="dict-member" data-export="" data-type="Operand " id="dom-namedoperand-operand"><code><c- g="">operand</c-></code><a href="#dom-namedoperand-operand"></a></dfn>;
};

<c- b="">interface</c-> <dfn data-dfn-type="interface" data-export="" id="neuralnetworkcontext"><code><c- g="">NeuralNetworkContext</c-></code></dfn> {
  // Create an Operand object that represents a model input.
  <a data-link-type="idl-name" href="#operand" id="ref-for-operand①"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export="" data-lt="input(name, desc)" id="dom-neuralnetworkcontext-input"><code><c- g="">input</c-></code><a href="#dom-neuralnetworkcontext-input"></a></dfn>(<a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-DOMString" id="ref-for-idl-DOMString①"><c- b="">DOMString</c-></a> <dfn data-dfn-for="NeuralNetworkContext/input(name, desc)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-input-name-desc-name"><code><c- g="">name</c-></code><a href="#dom-neuralnetworkcontext-input-name-desc-name"></a></dfn>, <a data-link-type="idl-name" href="#dictdef-operanddescriptor" id="ref-for-dictdef-operanddescriptor"><c- n="">OperandDescriptor</c-></a> <dfn data-dfn-for="NeuralNetworkContext/input(name, desc)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-input-name-desc-desc"><code><c- g="">desc</c-></code><a href="#dom-neuralnetworkcontext-input-name-desc-desc"></a></dfn>);

  // Create an Operand object that represents a model constant.
  <a data-link-type="idl-name" href="#operand" id="ref-for-operand②"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export="" data-lt="constant(desc, value)" id="dom-neuralnetworkcontext-constant"><code><c- g="">constant</c-></code><a href="#dom-neuralnetworkcontext-constant"></a></dfn>(<a data-link-type="idl-name" href="#dictdef-operanddescriptor" id="ref-for-dictdef-operanddescriptor①"><c- n="">OperandDescriptor</c-></a> <dfn data-dfn-for="NeuralNetworkContext/constant(desc, value)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-constant-desc-value-desc"><code><c- g="">desc</c-></code><a href="#dom-neuralnetworkcontext-constant-desc-value-desc"></a></dfn>, <a data-link-type="idl-name" href="https://heycam.github.io/webidl/#ArrayBufferView" id="ref-for-ArrayBufferView"><c- n="">ArrayBufferView</c-></a> <dfn data-dfn-for="NeuralNetworkContext/constant(desc, value)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-constant-desc-value-value"><code><c- g="">value</c-></code><a href="#dom-neuralnetworkcontext-constant-desc-value-value"></a></dfn>);

  // Create a single-value tensor from the specified number of the specified type.
  <a data-link-type="idl-name" href="#operand" id="ref-for-operand③"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export="" data-lt="constant(value, type)|constant(value)" id="dom-neuralnetworkcontext-constant-value-type"><code><c- g="">constant</c-></code><a href="#dom-neuralnetworkcontext-constant-value-type"></a></dfn>(<a data-link-type="idl-name" href="#typedefdef-number" id="ref-for-typedefdef-number"><c- n="">number</c-></a> <dfn data-dfn-for="NeuralNetworkContext/constant(value, type), NeuralNetworkContext/constant(value)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-constant-value-type-value"><code><c- g="">value</c-></code><a href="#dom-neuralnetworkcontext-constant-value-type-value"></a></dfn>, <c- b="">optional</c-> <a data-link-type="idl-name" href="#enumdef-operandtype" id="ref-for-enumdef-operandtype①"><c- n="">OperandType</c-></a> <dfn data-dfn-for="NeuralNetworkContext/constant(value, type), NeuralNetworkContext/constant(value)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-constant-value-type-type"><code><c- g="">type</c-></code><a href="#dom-neuralnetworkcontext-constant-value-type-type"></a></dfn> = "float32");

  // Create a Model object by identifying output operands.
  <c- b="">Promise</c->&lt;<a data-link-type="idl-name" href="#model" id="ref-for-model"><c- n="">Model</c-></a>&gt; <dfn data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export="" data-lt="createModel(outputs)" id="dom-neuralnetworkcontext-createmodel"><code><c- g="">createModel</c-></code><a href="#dom-neuralnetworkcontext-createmodel"></a></dfn>(<c- b="">sequence</c->&lt;<a data-link-type="idl-name" href="#dictdef-namedoperand" id="ref-for-dictdef-namedoperand"><c- n="">NamedOperand</c-></a>&gt; <dfn data-dfn-for="NeuralNetworkContext/createModel(outputs)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-createmodel-outputs-outputs"><code><c- g="">outputs</c-></code><a href="#dom-neuralnetworkcontext-createmodel-outputs-outputs"></a></dfn>);
};
</pre>
   <h4 data-level="3.5.1" id="api-neuralnetworkcontext-batchnorm"><span>3.5.1. </span><span>batchNormalization</span><a href="#api-neuralnetworkcontext-batchnorm"></a></h4>
    Normalize the tensor values across dimensions in a batch through a specialized <a data-link-type="biblio" href="#biblio-batchnorm">[BatchNorm]</a> <a href="https://en.wikipedia.org/wiki/Batch_normalization#Batch_Normalizing_Transform">transform</a>. The <em>mean</em> and <em>variance</em> tensors are previously calculated during model training pass. 
<pre><c- b="">partial</c-> <c- b="">interface</c-> <a data-link-type="interface" href="#neuralnetworkcontext" id="ref-for-neuralnetworkcontext②"><c- g="">NeuralNetworkContext</c-></a> {
  <a data-link-type="idl-name" href="#operand" id="ref-for-operand④"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export="" data-lt="batchNormalization(input, mean, variance, scale, bias, axis, epsilon)|batchNormalization(input, mean, variance, scale, bias, axis)|batchNormalization(input, mean, variance, scale, bias)|batchNormalization(input, mean, variance, scale)|batchNormalization(input, mean, variance)" id="dom-neuralnetworkcontext-batchnormalization"><code><c- g="">batchNormalization</c-></code><a href="#dom-neuralnetworkcontext-batchnormalization"></a></dfn>(<a data-link-type="idl-name" href="#operand" id="ref-for-operand⑤"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis, epsilon), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias), NeuralNetworkContext/batchNormalization(input, mean, variance, scale), NeuralNetworkContext/batchNormalization(input, mean, variance)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-input"><code><c- g="">input</c-></code><a href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-input"></a></dfn>, <a data-link-type="idl-name" href="#operand" id="ref-for-operand⑥"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis, epsilon), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias), NeuralNetworkContext/batchNormalization(input, mean, variance, scale), NeuralNetworkContext/batchNormalization(input, mean, variance)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-mean"><code><c- g="">mean</c-></code><a href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-mean"></a></dfn>, <a data-link-type="idl-name" href="#operand" id="ref-for-operand⑦"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis, epsilon), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias), NeuralNetworkContext/batchNormalization(input, mean, variance, scale), NeuralNetworkContext/batchNormalization(input, mean, variance)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-variance"><code><c- g="">variance</c-></code><a href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-variance"></a></dfn>, 
                             <c- b="">optional</c-> <a data-link-type="idl-name" href="#operand" id="ref-for-operand⑧"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis, epsilon), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias), NeuralNetworkContext/batchNormalization(input, mean, variance, scale), NeuralNetworkContext/batchNormalization(input, mean, variance)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-scale"><code><c- g="">scale</c-></code><a href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-scale"></a></dfn>, <c- b="">optional</c-> <a data-link-type="idl-name" href="#operand" id="ref-for-operand⑨"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis, epsilon), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias), NeuralNetworkContext/batchNormalization(input, mean, variance, scale), NeuralNetworkContext/batchNormalization(input, mean, variance)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-bias"><code><c- g="">bias</c-></code><a href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-bias"></a></dfn>, 
                             <c- b="">optional</c-> <a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long②"><c- b="">long</c-></a> <dfn data-dfn-for="NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis, epsilon), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias), NeuralNetworkContext/batchNormalization(input, mean, variance, scale), NeuralNetworkContext/batchNormalization(input, mean, variance)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-axis"><code><c- g="">axis</c-></code><a href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-axis"></a></dfn> = 1, <c- b="">optional</c-> <a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-float" id="ref-for-idl-float①"><c- b="">float</c-></a> <dfn data-dfn-for="NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis, epsilon), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias), NeuralNetworkContext/batchNormalization(input, mean, variance, scale), NeuralNetworkContext/batchNormalization(input, mean, variance)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-epsilon"><code><c- g="">epsilon</c-></code><a href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-epsilon"></a></dfn> = 1e-5);
};
</pre>
   <div data-algorithm="batchnorm">
     <p><strong>Arguments:</strong></p><ul>
     <li data-md="">
      <p><em>input</em>: an <code><a data-link-type="idl" href="#operand" id="ref-for-operand①⓪">Operand</a></code>. The input N-D tensor.</p>
     </li><li data-md="">
      <p><em>mean</em>: an <code><a data-link-type="idl" href="#operand" id="ref-for-operand①①">Operand</a></code>. The 1-D tensor of the batch mean values
whose length is equal to the size of the input dimension denoted by <em>axis</em>.</p>
     </li><li data-md="">
      <p><em>variance</em>: an <code><a data-link-type="idl" href="#operand" id="ref-for-operand①②">Operand</a></code>. The 1-D tensor of the batch variance values
whose length is equal to the size of the input …</p></li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://webmachinelearning.github.io/webnn/">https://webmachinelearning.github.io/webnn/</a></em></p>]]>
            </description>
            <link>https://webmachinelearning.github.io/webnn/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649616</guid>
            <pubDate>Thu, 01 Oct 2020 11:18:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Is Sortition?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24649577">thread link</a>) | @a_imho
<br/>
October 1, 2020 | https://equalitybylot.com/introduction-to-sortition-government-by-jury/ | <a href="https://web.archive.org/web/*/https://equalitybylot.com/introduction-to-sortition-government-by-jury/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

					<h2>Sortition – government by jury</h2>
<p>In our society elections and democracy are considered inseparable. In fact, this connection is far from clear. The ancient Greeks, for example, thought that elections are part and parcel of an oligarchy<sup><a href="#foot1">1</a></sup>. It was oligarchical Sparta, rather than democratic Athens, that elected its government.</p>
<p>The Athenians had a very different system: political offices were distributed using a lottery. The lottery method – known as Sortition – could be implemented here. If Congresspeople were drawn at random from the U.S. citizenry, Congress would not be an elite body made predominantly of rich, male, white, old lawyers<sup><a href="#foot2">2</a></sup>. Rather, it would look like a statistical sample of the people: it would contain 50% women, 28% hispanics and blacks, rich and poor, young and old, straight and gay, and very few lawyers.</p>
<p>More information on the sortition system can be found on Wikipedia at <a href="http://en.wikipedia.org/wiki/Sortition">http://en.wikipedia.org/wiki/Sortition</a>, and other online resources. One such resource is <em>A Citizen Legislature</em> by Ernest Callenbach and Michael Phillips – a book with a specific proposal for using sortition to select the U.S. House of Representatives. The book is available <a href="https://people.well.com/user/mp/citleg.html">here</a>.</p>
<p>This blog, <a href="https://equalitybylot.wordpress.com/">Equality-by-Lot</a>, is devoted to discussion of issues associated with sortition and with the promotion of sortition as a tool of democracy.</p>
<hr>
<p>Notes:<br>
[1]<a title="foot1" name="foot1"></a> “[T]he appointment of magistrates by lot is thought to be democratic, and the election of them oligarchical, democratic again when there is no property qualification, oligarchical when there is.” Aristotle, Politics, book IV, 9.</p>
<p>[2]<a title="foot2" name="foot2"></a> Of the 535 members of the 112th Congress there were 75 (14%) blacks and hispanics, 91 (17%) women, and 222 (41%) lawyers. The average age in Congress was 62, vs. 37 in the population. Sources: <a href="http://www.senate.gov/reference/resources/pdf/R41647.pdf">http://www.senate.gov/reference/resources/pdf/R41647.pdf</a>, 2009 population data – Statistical abstract of the U.S., 2011, Table 6.</p>
										

				</div></div>]]>
            </description>
            <link>https://equalitybylot.com/introduction-to-sortition-government-by-jury/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649577</guid>
            <pubDate>Thu, 01 Oct 2020 11:09:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Supporting a misbehaving NAND ECC engine in the Linux kernel]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24649565">thread link</a>) | @pabs3
<br/>
October 1, 2020 | https://bootlin.com/blog/supporting-a-misbehaving-nand-ecc-engine/ | <a href="https://web.archive.org/web/*/https://bootlin.com/blog/supporting-a-misbehaving-nand-ecc-engine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-13845">
	<!-- .entry-header -->

	
	
	<div>
		<p>Over the years, Bootlin has grown a significant expertise in U-Boot and Linux support for flash memory devices. Thanks to this expertise, we have recently been in charge of rewriting and upstreaming a driver for the <a href="https://www.arasan.com/products/nand-flash/">Arasan NAND controller</a>, which is used in a number of <a href="https://www.xilinx.com/products/silicon-devices/soc.html">Xilinx Zynq SoCs</a>. It turned out that supporting this NAND controller had some interesting challenges to handle its ECC engine peculiarities. In this blog post, we would like to give some background about ECC issues with NAND flash devices, and then dive into the specific issues that we encountered with the Arasan NAND controller, and how we solved them.</p>

<p>NAND flash memories are known to be intrinsically rather unstable: over time, external conditions or repetitive access to a NAND device may result in the data being corrupted. This is particularly true with newer chips, where the number of corruptions usually increases with density, requiring even stronger corrections. To mitigate this, Error Correcting Codes are typically used to detect and correct such corruptions, and since the calculations related to ECC detection and correction are quite intensive, NAND controllers often embed a dedicated engine, the ECC engine, to offload those operations from the CPU.</p>
<p>An ECC engine typically acts as a DMA master, moving, correcting data and calculating syndromes on the fly between the controller FIFO’s and the user buffer. The engine correction is characterized by two inputs: the size of the data chunks on which the correction applies and the strength of the correction. Old SLC (Single Level Cell) NAND chips typically require a strength of 1 symbol over 4096 (1 bit/512 bytes) while new ones may require much more: 8, 16 or even 24 symbols.</p>
<p>In the write path, the ECC engine reads a user buffer and computes a code for each chunk of data. NAND pages being longer than officially advertised, there is a persistent Out-Of-Band (OOB) area which may be used to store these codes. When reading data, the ECC engine gets fed by the data coming from the NAND bus, including the OOB area. Chunk by chunk, the engine will do some math and correct the data if needed, and then report the number of corrected symbols. If the number of error is higher than the chosen strength, the engine is not capable of any correction and returns an error.</p>

<p>As explained in our introduction, as part of our work on upstreaming the Arasan NAND controller driver, we discovered that this NAND controller IP has a specific behavior in terms of how it reports ECC results: the hardware ECC engine never reports errors. It means the data may be corrected or uncorrectable: the engine behaves the same. From a software point of view, this is a critical flaw and fully relying on such hardware was not an option.</p>
<p>To overcome this limitation, we investigated different solutions, which we detail in the sections below.</p>
<h2>Suppose there will never be any uncorrectable error</h2>
<p>Let’s be honest, this hypothesis is highly unreliable. Besides that anyway, it would imply that we do not differentiate between written/erased pages and users would receive unclean buffers (with bitflips), which would not work with upper layers such as UBI/UBIFS which expect clean data.</p>
<h2>Keep an history of bitflips of every page</h2>
<p>This way, during a read, it would be possible to compare the evolution of the number of bitflips. If it suddenly drops significantly, the engine is lying and we are facing an error. Unfortunately it is not a reliable solution either because we should either trigger a write operation every time a read happens (slowing down a lot the I/Os and wearing out very quickly the storage device) or loose the tracking after every power cycle which would make this solution very fragile.</p>
<h2>Add a CRC16</h2>
<p>This CRC16 could lay in the OOB area and help to manually verify the data integrity after the engine’s correction by checking it against the checksum. This could be acceptable, even if not perfect in term of collisions. However, it would not work with existing data while there are many downstreams users of the vendor driver already.</p>
<h2>Use a bitwise XOR between raw and corrected data</h2>
<p>By doing a bitwise XOR between raw and corrected datra, and compare with the number of bitflips reported by the engine, we could detect if the engine is lying on the number of corrected bitflips. This solution has actually been implemented and tested. It involves extra I/Os as the page must be read twice: first with correction and then again without correction. Hence, the NAND bus throughput becomes a limiting factor. In addition, when there are too many bitflips, the engine still tries to correct data and creates bitflips by itself. The result is that, with just a XOR, we cannot discriminate a working correction from a failure. The following figure shows the issue.</p>
<p><a href="https://bootlin.com/wp-content/uploads/2020/06/arasan-bitflips.png"><img loading="lazy" src="https://bootlin.com/wp-content/uploads/2020/06/arasan-bitflips-1024x460.png" alt="Show the engine issue when it creates bitflips when trying to correct uncorrectable data" width="840" height="377" srcset="https://bootlin.com/wp-content/uploads/2020/06/arasan-bitflips-1024x460.png 1024w, https://bootlin.com/wp-content/uploads/2020/06/arasan-bitflips-300x135.png 300w, https://bootlin.com/wp-content/uploads/2020/06/arasan-bitflips-768x345.png 768w, https://bootlin.com/wp-content/uploads/2020/06/arasan-bitflips-1200x539.png 1200w, https://bootlin.com/wp-content/uploads/2020/06/arasan-bitflips.png 1458w" sizes="(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px"></a></p>
<h2>Rely on the hardware only in the write path</h2>
<p>Using the hardware engine in the write path is fine (and possibly the quickest solution). Instead of trying to workaround the flaws of the read path, we can do the math by software to derive the syndrome in the read path and compare it with the one in the OOB section. If it does not match, it means we are facing an uncorrectable error. This is finally the solution that we have chosen. Of course, if we want to compare software and hardware calculated ECC bytes, we must find a way to reproduce the hardware calculations, and this is what we are going to explore in the next sections.</p>

<p>There is already a BCH library in the Linux kernel on which we could rely on to compute BCH codes. What needed to be identified though, were the BCH initial parameters. In particular:</p>
<ul>
<li>The BCH primary polynomial, from which is derived the generator polynomial. The latter is then used for the computation of BCH codes.</li>
<li>The range of data on which the derivation would apply.</li>
</ul>
<p>There are several thousands possible primary polynomials with a form like <code>x^3 + x^2 + 1</code>. In order to represent these polynomials more easily by software, we use integers or binary arrays. In both cases, each bit represents the coefficient for the order of magnitude corresponding to its position. The above example could be represented by <code>b1101</code> or <code>0xD</code>.</p>
<p>For a given desired BCH code (ie. the ECC chunk size and hence its corresponding Gallois Field order), there is a limited range of possible primary polynomials which can be used. Given <code>eccsize</code> being the amount of data to protect, the Gallois Field order is the smallest integer <code>m</code> so that: <code>2^m &gt; eccsize</code>. Knowing <code>m</code>, one can check <a href="https://www.partow.net/programming/polynomials/index.html">these tables</a> to see examples of polynomials which could match (non exhaustive). The Arasan ECC engine supporting two possible ECC chunk sizes of 512 and 1024 bytes, we had to look at the tables for <code>m = 13</code> and <code>m = 14</code>.</p>
<p>Given the required strength <code>t</code>, the number of needed parity bits <code>p</code> is: <code>p = t x m</code>.</p>
<p>The total amount of manipulated data (ECC chunk, parity bits, eventual padding) <code>n</code>, also called BCH codeword in papers, is: <code>n = 2^m - 1</code>.</p>
<p>Given the size of the codeword <code>n</code> and the number of parity bits <code>p</code>, it is then possible to derive the maximum message length <code>k</code> with: <code>k = n - p</code>.</p>
<p>The theory of BCH also shows that if <code>(n, k)</code> is a valid BCH code, then <code>(n - x, k - x)</code> will also be valid. In our situation this is very interesting. Indeed, we want to protect <code>eccsize</code> number of symbols, but we currently cover <code>k</code> within <code>n</code>. In other words we could use the translation factor <code>x</code> being: <code>x = k - eccsize</code>. If the ECC engine was also protecting some part of the OOB area, <code>x</code> should have been extended a little bit to match the extra range.</p>
<p>With all this theory in mind, we used GNU Octave to <a href="https://github.com/miquelraynal/find-bch-prim-poly/blob/master/find_bch_polynomial.m">brute force the BCH polynomials</a> used by the Arasan ECC engine with the following logic:</p>
<ul>
<li>Write a NAND page with a <code>eccsize</code>-long ECC step full of zeros, and another one full of ones: this is our known set of inputs.</li>
<li>Extract each BCH code of <code>p</code> bits produced by the hardware: this is our known set of outputs.</li>
</ul>
<p>For each possible primary polynomial with the Gallois Field order <code>m</code>, we derive a generator polynomial, use it to encode both input buffers thanks to a regular BCH derivation, and compare the output syndromes with the expected output buffers.</p>
<p>Because the GNU Octave program was not tricky to write, we first tried to match with the output of Linux software BCH engine. Linux using by default the primary polynomial which is the first in GNU Octave’s list for the desired field order, it was quite easy to verify the algorithm worked.</p>
<p>As unfortunate as it sounds, running this test with the hardware data did not gave any match. Looking more in depth, we realized that visually, there was something like a matching pattern between the output of the Arasan engine and the output of Linux software BCH engine. In fact, both syndromes where identical, the bits being swapped at byte level by the hardware. This observation was made possible because the input buffers have the same values no matter the bit ordering. By extension, we also figured that swapping the bits in the input buffer was also necessary.</p>
<p>The primary polynomial for an <code>eccsize</code> of 512 bytes being already found, we ran again the program with <code>eccsize</code> being 1024 bytes:</p>
<p><code>     eccsize =  1024<br>
     eccstrength =  24<br>
     m =  14<br>
     n =  16383<br>
     p =  336<br>
     k =  16047<br>
     x =  7855<br>
     Trying primary polynomial #1: 0x402b<br>
     Trying primary polynomial #2: 0x4039<br>
     Trying primary polynomial #3: 0x4053<br>
     Trying primary polynomial #4: 0x405f<br>
     Trying primary polynomial #5: 0x407b<br>
     [...]<br>
     Trying primary polynomial #44: 0x43c9<br>
     Trying primary polynomial #45: 0x43eb<br>
     Trying primary polynomial #46: 0x43ed<br>
     Trying primary polynomial #47: 0x440b<br>
     Trying primary polynomial #48: 0x4443<br>
     Primary polynomial found! 0x4443</code></p>

<p>With the two possible primary polynomials in hand, we could finish the support for this ECC engine.</p>
<p>At first, we tried a “mixed-mode” solution: read and correct the data with the hardware engine and then re-read the data in raw mode. Calculate the syndrome over the raw data, derive the number …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bootlin.com/blog/supporting-a-misbehaving-nand-ecc-engine/">https://bootlin.com/blog/supporting-a-misbehaving-nand-ecc-engine/</a></em></p>]]>
            </description>
            <link>https://bootlin.com/blog/supporting-a-misbehaving-nand-ecc-engine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649565</guid>
            <pubDate>Thu, 01 Oct 2020 11:08:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Deep Learning Toolchain]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24649488">thread link</a>) | @rosshemsley
<br/>
October 1, 2020 | https://rosshemsley.co.uk/posts/deep_learning_toolchain/ | <a href="https://web.archive.org/web/*/https://rosshemsley.co.uk/posts/deep_learning_toolchain/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
Successful model development can be surprisingly dependent on good engineering practices. Despite this, many model implementations scattered about Github are difficult to follow and hard to recreate locally.
</p>

<p>
But what should a <em>good model</em> look like? I would propose that the gold standard for a model implemented on Github could be:
</p>
<ol>
<li> The dependencies may be installed automatically, using a single command.</li>
<li> I can build the model in a sandbox without polluting with my dev. environment.</li>
<li> I can easily retrain (and retune!) the model the model exactly as the author did during their development.</li>
<li> I can easily test the inference pass.</li>
<li> I can easily import the model into my own workflow and use it as part of my own code.</li>
</ol>
<p>
It may be that I've never come across a model that met this standard in practical day-to-day development...! But I claim that achieving these things is surprisingly easy given the modern tools available to us.
</p>
<p>
Furthermore, many may simply respond "just ship everything in a Docker container". My response to this is that Docker is a great tool for
<em>deploying</em> a stable, reproducible environment, but Docker images provide a poor basis for sharing code and enabling collaboration.
In this post, we'll focus on designing models that can be <em>installed and imported with a single command, without Docker, on any OS, on any platform,
using the vanilla tools our language provides</em>.
</p>
<p>
So, let's dive in and look at the tools that I use to train models, and how they can be used to meet the gold standard I gave above.
</p>

<h2>Python 3 for model development</h2>
<p><img src="https://rosshemsley.co.uk/posts/deep_learning_toolchain_images/python_logo.png"></p><p>
It may not be controversial these days, but it's worth highlighting that Python 3 is an excellent choice for prototyping and releasing deep learning models. The key feature here is the library support, which is unmatched by other languages.
I tend to target <strong>Python 3.7.5</strong> or later, because I make heavy use of <em><a href="https://docs.python.org/3/library/dataclasses.html">dataclass</a></em>, and it's recent enough to support type annotations. Ubuntu Focal now includes Python 3.8 by default,
so many users will start being able to support this out of the box.
</p>
<h3>Bonus pionts: type annotations</h3>
<p>
If you use type annotations (correctly) in your model, you will get serious points from me.
It's very common that models use native lists, tensors, and numpy arrays almost interchangeably as function
arguments, and so using type hints can make the data flow in your model easier to follow and debug.
</p>
<div><pre><code data-lang="python"><span>from</span> dataclasses <span>import</span> dataclass
<span>from</span> typing <span>import</span> List, Optional

<span>import</span> numpy <span>as</span> np
<span>from</span> PIL <span>import</span> Image

<span>@dataclass</span>
<span>class</span> <span>DataSample</span>:
    img: Image
    bboxes: List[np<span>.</span>ndarray]
    scores: Optional[List[float]]

<span>...</span>

sample <span>=</span> DataSample(Image(), [np<span>.</span>array([<span>1</span>,<span>2</span>,<span>3</span>,<span>4</span>])], scores<span>=</span>None)</code></pre></div>
<p><em><strong>Above:</strong> an example of using modern Python features to write a clear and simple data container
for a training sample in a model. The dataclass decorator adds all of the utility functions we may want (including
a pretty string reprsentation so we can print the object), and the type annotations make it clear what the user 
should expect the fields to contain.</em></p><h2> Use <em>pyenv</em> to manage Python versions</h2>
<p>
For better or worse, many incompatible versions of Python now exist, and it's easy to get
in a tangle with different Python installs, especially when making system-wide changes.
</p>
<p>
My advice here is to do it properly, and do it once: learn to use <em>pyenv</em> to manage all of your Python
installs.
</p>
<p>
Pyenv is a tool that provides a shim around the <em>python</em> command which redirects it to the correct version 
of Python for the current context. For a given project, you can use <em>pyenv local 3.7.5</em> in a directory
to tell pyenv to use Python 3.7.5 from now on when calling Python in that directory.
</p>
<p>
If you don't have the version of Python installed that you need, you can use pyenv to install it.
If the universe is feeling good to you today, <em>pyenv install 3.7.5</em> should be sufficient to fetch and install Python 3.7.5
for you automatically on any platform.
</p>
<p>
<strong>In practice</strong>, things don't always go so smoothly with pyenv, however I really believe
it's really worth the hassle of spending the time and getting it working - most issues you might enouncter are well understood, and documented on stackoverflow.
</p>
<h3>A few common tips for common pyenv issues</h3>
<ul>
<li><strong>It's not working!</strong> - make sure you have activated it (google "pyenv activate"). Typically you need to add this to e.g. your .bashrc</li>
<li><strong><em>pyenv install</em> failed!</strong> - you may be missing system dependencies. Be patient, and trawl stackoverflow. It can be made to work!</li>
</ul>


<h2>Use <em>poetry</em> to manage your project and dependencies</h2> 
<p>
Keeping your Python project sandboxed is crucial aspect of remaining sane when using Python.
We typically use <em>virtualenvs</em>, or virtual environments, to achieve this. These are are essentially directories containing their own
Python install, and a local copy of all the packages your project needs. 
</p>
<p>
A separate but related problem is ensuring you actually <em>have</em> the dependencies your project needs
installed into that virtualenv. 
</p>
<p>
Once upon a time, you may have used `virtualenv` and `requirements.txt` or `anaconda` or `pipenv` to do these things.
</p>
<p>
Well, my advice is <strong>steer clear from all of them</strong> and move straight to <a href="https://python-poetry.org/">poetry</a>.
It's very much the new kid on the block, but from my perspective it's already miles ahead of the competition.
I have managed to deploy a number of complex Python applications in a professional capacity using
poetry, and I have found it both plays very well with other tools and is generally well designed.
</p>
<p>
Poetry uses the modern <a href="https://snarky.ca/what-the-heck-is-pyproject-toml/">pyproject.toml</a> way of defining a package, and this essentially replaces the old setup.py and friends.
It would be out of scope to explain why pyproject.toml is important and worth learning about, so I recommend some googling here!
</p>
<p>
Ok, so let's create a new project! ... don't forget to `pyenv local 3.7.5` first, to ensure you are using the correct version of Python (if you forgot, you can run it later, and then go
back and edit pyproject.toml to make sure it's set correctly.)
</p>

<p>
Yes, it's as easy as that. Go ahead and move in the directory poetry created for you, and you can now
</p>
<p>
and poetry will automatically create a managed virtualenv for you. Let's now install some of the tools of our trade,
</p><div><pre><code data-lang="bash">$ poetry add torch
$ poetry add numpy</code></pre></div>
<p>
Poetry will install them to the virtualenv and add them to the pyproject.toml. It will 
also <strong>pin</strong> the exact versions of the dependencies into a lock file so that <strong>other users installing your package
can reproduce precisely the same environment as you</strong>. This is perhaps the most important step here, and is worth underscoring:
this is how we are able to achieve <em>reproducibility</em>. 
</p>
<h3>The Best Bit About Poetry</h3>
<p>
Poetry was designed to be good at both developing packages and <em>building/sharing/publishing</em> them.
These latter features are sorely missing from other tools (such as pyenv), and they are really the killer
feature of poetry.
</p>
<p>
Let's suppose you pushed your <em>fancynet</em> package to github (don't forget to check in the lock file!).
Now, <strong>anyone using a recent version of pip can install your package with a single command</strong>,
</p><div><pre><code data-lang="bash">$ pip install git+https://github.com/myusername/fancynet</code></pre></div>
<p>
Pip will fetch the code from github, look into the pyproject.toml, see it uses poetry, and then just do
everything for you, including installing poetry, and fetching the correct versions of the pinned dependencies!
<strong>
This is totally magic and not enough people know this trick.</strong> Go forth and spread this knowledge!
</p>
<p>
If your package reaches a level of maturity where you'd like to publish it to a public package repository (e.g. pypi),
you can use poetry to manage this. To bump the version (you can also bump the minor and major versions this way), use
</p><p>
Then to build and publish to pypi, use
</p><div><pre><code data-lang="bash">$ poetry build
$ poetry publish</code></pre></div><p>
The defaults used by poetry are spookily well designed, and I have never had any problems publishing packages in this way.
</p>

<h2>Use <em>click</em> to manage your entrypoint</h2> 
<p>
An oft-overlooked step in building a good python package is organising the files and "entrypoints" (or "executables"). 
I believe it's worth imagining that someone else is going to use your code at somepoint, and so I try to create nicely named
subdirectories for each part of my model: "datasets", "models", "inference", but also <strong>"cli"</strong>.
In this "cli" directory, I usually have several subdirectories "train", "tune", "test". Each of these contains a single
"__main__.py", which contains the (small!) shim code needed to perform those actions.
</p>
<p>
Inside "__main__.py" I then use <a href="https://click.palletsprojects.com/en/7.x/">click</a> to manage arguments and the entrypoint.
I have found it much easier to use than argparse, and I do think it's worth the effort!
</p>
<div><pre><code data-lang="python"><span>import</span> click
<span>from</span> omegaconf <span>import</span> OmegaConf
<span>from</span> pytorch_lightning <span>import</span> Trainer

<span>from</span> mynet.models <span>import</span> MyNet

<span>@click.command</span>()
<span>@click.option</span>(<span>'--dataset-root-dir'</span>, help<span>=</span><span>'directory containing the dataset'</span>)
<span>@click.option</span>(<span>'--config-path'</span>, default<span>=</span><span>"config.yaml"</span>, help<span>=</span><span>'The config file to use.'</span>)
<span>def</span> <span>train</span>(dataset_root_dir: str, config_path: str):
    cfg <span>=</span> OmegaConf<span>.</span>load(config_path)

    model <span>=</span> MyNet(cfg)
    trainer <span>=</span> Trainer(gpus<span>=</span><span>1</span>, profiler<span>=</span>True)
    trainer<span>.</span>fit(model)

<span>if</span> __name__ <span>==</span> <span>'__main__'</span>:
    train()</code></pre></div>
<p>
Now, if we are developing locally, we can run this using
</p><div><pre><code data-lang="bash">$ poetry run python -m mynet.cli.train --dataset-root-dir /foo/bar/baz</code></pre></div><p>
Which is fine and good, but if we want to go 10X, we can also use a neat future of project.toml and add an entrypoint
</p><div><pre><code data-lang="toml">[<span>tool</span>.<span>poetry</span>.<span>scripts</span>]
<span>train</span> = <span>"mynet.cli.train.__main__:train"</span></code></pre></div><p>
Once we do this, users can run training using
</p><div><pre><code data-lang="bash">$ poetry run train --dataset-root-dir /foo/bar/baz</code></pre></div><p>
or if you "activate" the environment, simply
</p><div><pre><code data-lang="bash">$ train --dataset-root-dir /foo/bar/baz</code></pre></div>

<p>
It's possible to add multiple entrypoints to the pyproject.toml, so you can easily create one for training, tuning, testing.
This is helpful for users trying to discover how to train or evaluate your model from scratch!
</p>
<p>
Do note that if a user installs your package into a shared virtualenv, you may wish to choose a more meaningful name than train!
</p>

<h2>Use <em>pytorch</em> to develop your net</h2>
<p></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rosshemsley.co.uk/posts/deep_learning_toolchain/">https://rosshemsley.co.uk/posts/deep_learning_toolchain/</a></em></p>]]>
            </description>
            <link>https://rosshemsley.co.uk/posts/deep_learning_toolchain/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649488</guid>
            <pubDate>Thu, 01 Oct 2020 10:54:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PowerShell Universal v1.4]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24649270">thread link</a>) | @l33t_d0nut
<br/>
October 1, 2020 | https://blog.ironmansoftware.com/powershell-universal-1-4/ | <a href="https://web.archive.org/web/*/https://blog.ironmansoftware.com/powershell-universal-1-4/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content" role="main"><div><h2>PowerShell Universal v1.4</h2><h4>September 30, 2020</h4><p>I’m pleased to announce another feature-packed <a href="https://ironmansoftware.com/powershell-universal">PowerShell Universal</a> release! Today, we’re releasing version 1.4 of the ultimate platform for building web-based IT tools. This release contains an extensive list of features as well as bug fixes. This blog post will go over them but I encourage you to <a href="https://ironmansoftware.com/downloads">download or upgrade</a> to take full advantage of everything that has been added.</p><h2 id="release-notes">Release Notes</h2><p>Full release notes can be found <a href="https://docs.ironmansoftware.com/changelog">here</a>.</p><h2 id="downloads">Downloads</h2><ul><li><a href="https://imsreleases.blob.core.windows.net/universal/production/1.4.0/PowerShellUniversal.1.4.0.msi">Windows MSI</a></li><li><a href="https://imsreleases.blob.core.windows.net/universal/production/1.4.0/Universal.win-x64.1.4.0.zip">Windows ZIP</a></li><li><a href="https://imsreleases.blob.core.windows.net/universal/production/1.4.0/Universal.linux-x64.1.4.0.zip">Linux ZIP</a></li><li><a href="https://hub.docker.com/r/ironmansoftware/universal">Docker</a></li></ul><h2 id="platform">Platform</h2><h3 id="environments">Environments</h3><p>We’ve extended the concept of PowerShell Versions and replaced it with Environments. Environments allow you to specify the executable, arguments, modules and variables that are defined whenever you execute an API request, run a job or host a dashboard. The execution environment will automatically create a runspace pool with the assets you define so there is no need to import them every time.</p><p>We’ve standardized environments across all features and now you can select which environment is used in each place.</p><p><a href="https://docs.ironmansoftware.com/config/environments">Learn more about Environments</a></p><p><img src="https://blog.ironmansoftware.com/images/environments.png" alt=""></p><h3 id="windows-authentication-with-iis">Windows Authentication with IIS</h3><p>You can now configure Windows Authentication without IIS. IIS can complicate deployments and if it’s not something you need, you can now avoid it by simply installing Universal as a service and configuring Windows authentication.</p><p><a href="https://docs.ironmansoftware.com/config/security#windows-authentication-outside-of-iis">Learn more about Windows Authentication without IIS</a></p><h2 id="apis">APIs</h2><h3 id="rate-limiting">Rate Limiting</h3><p>We’ve added the ability to configure rate limiting for APIs. This is an important feature for anyone that may be exposing their API publicly or may call a sensitive resource that you do not want to overload. You can configure rate limits based on HTTP method, endpoint (or pattern), and the number of requests over a period of time.</p><p><a href="https://docs.ironmansoftware.com/api/rate-limiting">Learn more about Rate Limiting</a></p><p><img src="https://blog.ironmansoftware.com/images/ratelimit.png" alt=""></p><h3 id="connection-information">Connection Information</h3><p>You’ll have access to more connection information in your endpoints. Variables are now defined for Local IP Address, Remote IP Address, Local Port and Remote Port.</p><h3 id="updated-endpoint-page">Updated Endpoint Page</h3><p>We’ve enhanced the API page to provide a neat in-browser experience for developing your API. This includes the ability to test your APIs directly in the browser.</p><p><img src="https://blog.ironmansoftware.com/images/apis.png" alt=""></p><h2 id="automation">Automation</h2><h3 id="continuous-schedules">Continuous Schedules</h3><p>You can now define continuous schedules that will run a job over and over again with a configurable delay. It won’t start another job until the previous one has finished.</p><p><a href="https://docs.ironmansoftware.com/automation/schedules#continuous">Learn more about Scheduling</a></p><p><img src="https://blog.ironmansoftware.com/images/continuous-schedule.png" alt=""></p><h3 id="variables">Variables</h3><p>Variables are now global for the entire Universal platform. By default, your existing Environments will import all variables but you can define specific variables or patterns to use in an environment. This change shouldn’t affect your jobs but be aware that variables are no longer present only present in jobs but present in any one of the features using an Environment.</p><p><a href="https://docs.ironmansoftware.com/automation/variables">Learn more about Variables</a></p><h2 id="dashboard">Dashboard</h2><h3 id="role-based-access">Role-based Access</h3><p>We’ve added the ability to assign roles to dashboards and pages in the v3 framework. If you assign a role to a dashboard, only users of that role will have access to the entire dashboard. When you assign roles to a page in a dashboard, any authenticated user will be able to access the dashboard but only users in the specified role will have access to the pages.</p><p><a href="https://docs.ironmansoftware.com/dashboard/role-based-access">Learn more about Role-Based Access in Dashboards</a></p><h3 id="chartjs">ChartJS</h3><p>We’ve brought back ChartJS support. This was the primary chart library in UDv2. Many users preferred this library over our Nivo charts integration so we have decided to include it. We’ve also simplified the API to make it even easier to build charts.</p><p><a href="https://docs.ironmansoftware.com/dashboard/components/data-visualization/charts#chartjs">Learn more about ChartJS integration</a></p><p><img src="https://blog.ironmansoftware.com/images/chartjs.png" alt=""></p><h3 id="improved-navigation">Improved Navigation</h3><p>We’ve simplified and extended the built in navigation. You can now more easily define your navigation items for a page. We also support a persistent layout that does not require a click of a hamburger menu to open the navigation.</p><p><a href="https://docs.ironmansoftware.com/dashboard/components/pages#navigation">Learn more about Navigation</a></p><p><img src="https://blog.ironmansoftware.com/images/permanent-drawer.png" alt=""></p><h3 id="redesigned-dashboard-page">Redesigned Dashboard Page</h3><p>The dashboard page has been redesigned to make it easier to see an overview of the dashboards running in your environment.</p><p><img src="https://blog.ironmansoftware.com/images/new-dashboards.png" alt=""></p><h2 id="get-started-now">Get Started Now</h2><p>PowerShell Universal is free to try. <a href="https://ironmansoftware.com/downloads">Download now</a> and start building tools with your existing PowerShell scripts. Please feel free to join our <a href="https://forums.universaldashboard.io/">growing community</a>.</p></div></div></div>]]>
            </description>
            <link>https://blog.ironmansoftware.com/powershell-universal-1-4/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649270</guid>
            <pubDate>Thu, 01 Oct 2020 10:11:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You can drive more traffic and engagement with content amplification]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24649266">thread link</a>) | @JamesConverge
<br/>
October 1, 2020 | https://www.converge.today/engage-articles/drive-more-traffic-and-engagement-with-content-amplification | <a href="https://web.archive.org/web/*/https://www.converge.today/engage-articles/drive-more-traffic-and-engagement-with-content-amplification">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><strong>Content amplification is one of the most underused&nbsp;pieces of the&nbsp;content marketing puzzle.</strong></p>
<p><strong>Hands down.</strong></p>
<p><span>So many businesses create great content, but then they only publish that content on their own website, and maybe share it once or twice on social media.</span></p>
<p><span>Sorry to break it to you, but with millions of other businesses doing the same thing, that isn't going to help you cut through the noise.&nbsp;</span></p>
<p><span>At all.&nbsp;</span></p>
<p><span>And hoping that someone will just stumble across your content isn’t a good strategy, either.&nbsp;</span></p>
<p><span>In reality, you need to <strong>AMPLIFY YOUR CONTENT</strong></span><span>.</span></p>
<p><span>Without content amplification, your hard work and effort will remain essentially “on the shelf collecting dust".</span></p>
<p><span>Creating content is less than half the battle. If you don't have a distribution, or amplification strategy for your content, then you're missing out on more traffic, more awareness, more backlinks, better SEO and a more engaged audience.</span></p>
<p><span>And, of course, all of the above <em>usually</em> lead to additional commercial benefits such as more customers and more sales.</span></p>
<p><span>In this article, we’re going to break down content amplification, tell you what it is, how it works, and how you can get the most out of it so your content can start to work harder and more effectively for you.&nbsp;</span></p>
<p><span>We’re going to answer the most common questions we get that relate to content amplification, such as:</span></p>
<ul>
<li><span>What is content amplification?</span></li>
<li><span>Why is content amplification so important?</span></li>
<li><span>How can I build a content amplification strategy?</span></li>
</ul>
<p><span>But enough with the preamble. Let’s jump in and get right into the good stuff.&nbsp;</span></p>
<p><span><img src="https://www.converge.today/uploads/engage/Content%202019/Mark%20Masters.jpg" alt="" width="1600" height="150"></span></p>
<p><em>"The reason we shy away from content distribution or amplification is that it feels far better to be creative and produce, than it is to encourage people to watch/listen/read, as this side takes far more effort. Then again, the reason we are creating is to motivate people and get them to subscribe, enquire, interact and buy.</em></p>
<p><em>What is really important is to have something to say that can be amplified. Distribution channels work really well, once you have something to distribute. So, make sure that your message links to your values and that can strike a chord with others. This is how you find your allies, make sure your work is seen and people want to feel a part of it and prepared to stand with you."&nbsp;</em></p>
<p><strong><em>Mark Masters - <a href="https://www.wearethemedia.co.uk/">We Are The Media</a></em></strong></p>
<p>What is content amplification, and why is it so important?</p>
<p><span>Content amplification is the act of promoting and distributing your content across multiple channels (paid, owned and earned) so you can increase the reach and impact of both your content and your brand.</span></p>
<p><span>However, amplifying your content does more than simply provide your brand with additional exposure. It also allows you to position yourself as a thought leader, and build valuable backlinks, as well as build relationships, and increase both engagement and conversion rates with your target audience.&nbsp;</span></p>
<p><span>There are many different ways to amplify content. Paying to promote your content on Facebook or Twitter, leveraging influencers to promote your content, publishing your content on </span><a href="https://promos.converge.today/join-converge"><span>other platforms with an already captivated audience</span></a><span> - they’re all different ways to amplify your content, and we’ll get into them in a bit more detail later on.</span></p>
<p><span>Without amplification, it’ll be much more difficult for you to get the results you want from your content.&nbsp;</span></p>
<p><span>Every single day, there are</span><a href="https://www.worldometers.info/blogs/"><span> millions of new blogs published</span></a><span>. Yes, not all of them will be competing with what you’ve created, but that’s a lot of potential noise getting in the way of your message. And organic reach is getting lower and lower all the time.</span></p>
<p><span>Because organic reach across the board is down, way down, when it comes to creating content - and you may be producing the best stuff out there - the likelihood is that without amplifying your content, it’s not going to perform well.&nbsp;</span></p>
<p><span><img src="https://www.converge.today/uploads/engage/Content%202019/Cathy%20McPhillips.jpg" alt="" width="1600" height="150"></span></p>
<p><em>“You’ve written an amazing article – and now what? You can’t expect the results to happen without some distribution work on your end. This includes content amplification – a multi-channel approach to increase your brand’s reach. It’s taking your owned media, and combining it with paid and earned media. It’s really knowing the right places – and people – to help amplify your message to your audience.</em></p>
<p><em>Through content amplification, you’re able to extend your reach into new areas you couldn’t achieve on your own through organic methods. It’s getting out of your echo chamber of your current customers and brand loyalists and finding new and relevant customers who wouldn’t have necessarily heard of you otherwise. Amplification done right brings customers to you who didn’t yet know how much they needed you.</em></p>
<p><strong><em>Cathy McPhillips - <a href="http://contentmarketinginstitute.com/">Content Marketing Institute</a></em></strong></p>
<p>The problem with organic traffic</p>
<p><span>OK, that’s a little misleading. There is no problem with organic traffic.</span></p>
<p><span>The problem lies with the expectations people have when it comes to organic traffic. And, frankly, the delusion that generating it is both a) easily achievable and, b) that it is the only traffic source worth aiming for.&nbsp;</span></p>
<p><span>Nope.</span></p>
<p><span>Listen, organic traffic is great. It’s wonderful. If you’re getting huge organic traffic and your website and blogs are appearing right at the top of search results for your most relevant and valuable keywords and phrases, then brilliant! You’ve smashed it already.&nbsp;</span></p>
<p><span>Chances are, though, that’s not the case. Because, 1) only a handful of businesses across the entire planet can claim to have achieved the above. And it’s a constant battle for them to remain at the top. And, 2) organic reach is in decline </span><a href="https://blog.hootsuite.com/organic-reach-declining/"><span>across the board</span></a><span>.</span></p>
<p><span>We’re not saying achieving a first page ranking on Google for your content is impossible, but it may take both time and resources that you currently don’t have to get there. So, before you become a high-ranking Google superstar, you must find another way to get eyeballs on your content.</span></p>
<p><span>You need to amplify content so you can generate the consistent traffic and backlinks you need to get it the awareness and engagement it deserves, and to get it started on the long, arduous climb towards the first page of search results.&nbsp;</span></p>
<p><span><img src="https://www.converge.today/uploads/engage/Content%202019/Abby%20Sorensen.jpg" alt="" width="1600" height="150"></span></p>
<p><em>“Imagine this scenario at the most important trade show in your industry - Your sales team picks up their badges and heads for the show floor, eager to make connections and meet potential buyers. Your product/service is the exact right fit for these prospects, and your message has been carefully crafted to resonate with them. But your booth is set up at the empty convention center across town. Maybe you were trying to stretch your budget. Or maybe you thought your product/service was so exciting that buyers would go out of their way to find you. Your sales team heads back to the office empty-handed, a complete waste of time and energy spent setting up your booth where your buyers were not.</em></p>
<p><em>This is exactly what happens when you create content with no plan to distribute it.<strong> Only a select few companies can afford to buy their way to the top of Google’s search rankings.</strong> The only way to get the most out of your content is to distribute it where your buyers are likely to be. And while your website might be the most strategized, optimized, digitized, mobilized website in your market, your buyers simply are not likely to spend a great deal of time there (especially if you hit them with gates and form-fills).”</em></p>
<p><strong><em>Abby Sorensen - <a href="https://www.followyourbuyer.com/">Follow Your Buyer</a></em></strong></p>
<p>Creating content is less than half the battle</p>
<p><span>That’s right. All that time you spent researching, planning, creating and publishing content is less than half of what’s required to give your content the best chance of generating the return on investment you want from it.&nbsp;</span></p>
<p><span>Depending on who you talk to and the articles you read, you may have heard people saying content creation is anywhere from 20-40% of the job.</span></p>
<p><span>The rest of it? You guessed it; amplification/distribution/promotion - whatever you call it. Whatever it takes to get your content in front of everyone you want to read it.</span></p>
<p><span>But let’s not get bogged down in specific percentages. The only thing you need to know is that you need to spend more time promoting your hard work than you do creating it. Because the competition for attention is fierce, and you need to cut through the noise and make sure people are actually engaging with your content. Otherwise why spend the time creating it in the first place?&nbsp;</span></p>
<p><span><img src="https://www.converge.today/uploads/engage/Content%202019/Alexandra%20Cote.jpg" alt="" width="1600" height="150"></span></p>
<p><em>"Beyond simply creating a really good post, you'll also need really great content amplification methods in place. In fact, everything that happens AFTER you publish a piece of content is much more important than the post itself. This is because sharing content across appropriate channels and talking about your findings and products gets your brand in front of more people.</em></p>
<p><em>This being said, content amplification is the core driver behind reaching your business goals and hitting your KPIs. Whether you want to improve your brand awareness, get more qualified leads, gain new partnerships, or just position yourself as a thought leader in the industry, content amplification can help you hit those targets. Do remember to stay away from vanity metrics though. Just because a lot of people like a post of yours on LinkedIn doesn't mean they read your article and it's a far cry from them actually making a purchase.</em></p>
<p><em>The best advice I have to ensure you're seeing real results from your content amplification techniques is to choose the right networks and websites to promote your content. You'll first need a clear image of your buyer persona. By analyzing potential customers and their behavior, you'll see where they spend most of their time and, above all, what determines them to make a purchase decision. Then, all you have to do is craft the right messaging revolving around the benefits they're looking to get and stay consistent on a couple of networks of choice. Feel free to include the same terms and pain points they use and remember to be responsive so the conversation is bidirectional."</em></p>
<p><strong><em><a href="https://mktodyssey.wordpress.com/">Alexandra Cote</a>, B2B and SaaS Content Writer and SEO Strategist</em></strong></p>
<p>Building a content amplification strategy</p>
<p><span>Of course, it’s easy …</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.converge.today/engage-articles/drive-more-traffic-and-engagement-with-content-amplification">https://www.converge.today/engage-articles/drive-more-traffic-and-engagement-with-content-amplification</a></em></p>]]>
            </description>
            <link>https://www.converge.today/engage-articles/drive-more-traffic-and-engagement-with-content-amplification</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649266</guid>
            <pubDate>Thu, 01 Oct 2020 10:10:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New Proposed Standard to ensure secure time on the Internet]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24649121">thread link</a>) | @fogihujy
<br/>
October 1, 2020 | https://www.netnod.se/time-and-frequency/new-proposed-standard-to-ensure-secure-time-on-the-internet | <a href="https://web.archive.org/web/*/https://www.netnod.se/time-and-frequency/new-proposed-standard-to-ensure-secure-time-on-the-internet">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
                  
                
            <p>Stockholm, Sweden - 1 October 2020 - The Proposed Standard for Network Time Security (NTS) has today been published by the IETF as RFC8915. This comes at the end of a five year development process. As one of the leading figures in NTS, Netnod has worked on all stages of NTS development from the IETF standard to software and hardware implementations at client and server levels. The publication of the NTS Proposed Standard as an RFC marks an important milestone in the development of secure time on the Internet.&nbsp;</p>
      
        
            <div><p><span><span><span><span><span><span><span>The current standard for receiving time information over the internet, the Network Time Protocol (NTP), was created in 1985</span></span></span></span></span></span></span><span><span><span><span><span><span>. Over the last 35 years, a number of issues as well as some high-profile attacks have shown that NTP needs an increased level of security. The new Network Time Security (NTS) standard has been designed to fix that.</span></span></span></span></span></span></p>
<p><span><span><span><span><span><span>NTS uses modern cryptography to add an essential layer of security to NTP. It prevents a range of security vulnerabilities including amplification attacks, packet manipulation, and replay attacks. The protection against packet manipulation and replay attacks secures NTP against Man-in-the-Middle (MITM) attacks. MITM attacks are used by malicious actors to sit between the client and the NTP server, forge messages and lie about time. Since many processes are dependent on accurate time, the consequences here are very serious. </span></span></span></span></span></span><span><span><span><span><span><span><span>Everything from establishing encrypted sessions and using DNSSEC to time-stamping financial transactions and preventing online fraud depends on accurate and secure time.</span></span></span></span></span></span></span></p>
<p><span><span><span><span><span><span>In March 2015, the first Internet-Draft of the NTS standard was published by the NTP working group in the IETF. Over the next 5 years, the draft went through 28 further iterations until </span></span></span></span></span></span><a href="https://datatracker.ietf.org/doc/draft-ietf-ntp-using-nts-for-ntp/" target="_blank"><span><span><span><span><span><span><span><span>the Internet Draft ‘Network Time Security for the Network Time Protocol’ </span></span></span></span></span></span></span></span></a><span><span><span><span><span><span>was approved as a Proposed Standard in March 2020. Following some time in the RFC editor queue and final approval from the authors, </span></span></span></span></span></span><a href="https://www.rfc-editor.org/info/rfc8915" target="_blank"><span><span><span><span><span><span><span><span>the RFC proper </span></span></span></span></span></span></span></span></a><span><span><span><span><span><span>has today been published.</span></span></span></span></span></span></p>
<p><span><span><span><span><span><span>“The publication of </span></span></span></span></span></span><span><span><span><span><span><span><span>RFC8915 is an important moment both for the development of NTS</span></span></span></span></span></span></span><span><span><span><span><span><span> and for security on the Internet in general,” said Lars Michael Jogbäck, Netnod CEO. “Netnod is proud to have been at the forefront of developing the NTS standard and implementations. We will continue to focus on services such as NTS to make the Internet as secure and robust as possible for everyone.”</span></span></span></span></span></span></p>
<p><span><span><span><span><span><span>Netnod provides NTP, NTS and Precision Time Protocol (PTP) services offering a robust, reliable and highly accurate source for time and frequency traceable to official Swedish time UTC(SP). Netnod’s time service, funded by the Swedish Post and Telecom Authority (PTS), uses a distributed timescale on multiple, autonomous sites throughout Sweden to provide a time service available over IPv4 and IPv6. Each site has full redundancy: multiple servers, caesium clocks, and FPGA boards provide an extremely fast hardware implementation of NTP. The service is available to the general public worldwide for free on ntp.se, which resolves to anycast IPv4 and IPv6 addresses. The NTS-enabled service is available at: nts.ntp.se. More information about Netnod’s NTS service is available </span></span></span></span></span></span><a href="https://www.netnod.se/time-and-frequency/network-time-security"><span><span><span><span><span><span><span><span>here</span></span></span></span></span></span></span></span></a><span><span><span><span><span><span>. </span></span></span></span></span></span><span><span><span><span><span><span><span>&nbsp;</span></span></span></span></span></span></span></p>
<p><span><span><span><strong><span><span>About Netnod</span></span></strong></span></span></span></p>
<p><span><span><span><span><span><span>Netnod provides critical infrastructure support ranging from interconnection services and Internet Exchanges to DNS services, root server operations, and time and frequency services. With a worldwide reputation for its services and the expertise of its staff, Netnod ensures a stable and secure Internet for the Nordics and beyond.Established in 1996 as a neutral and independent Internet infrastructure organisation, Netnod is fully owned by the non-profit foundation TU-stiftelsen (Stiftelsen för Telematikens utveckling). More information is available at:</span></span></span></span></span></span><a href="http://www.netnod.se/"><span><span><span><span><span><span><span><span> www.netnod.se</span></span></span></span></span></span></span></span></a></p>
</div>
      
        

      </div></div>]]>
            </description>
            <link>https://www.netnod.se/time-and-frequency/new-proposed-standard-to-ensure-secure-time-on-the-internet</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649121</guid>
            <pubDate>Thu, 01 Oct 2020 09:43:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why are secrets in Git such a threat?]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24649034">thread link</a>) | @oodelally
<br/>
October 1, 2020 | https://www.gitguardian.com/secrets-detection/secret-sprawl | <a href="https://web.archive.org/web/*/https://www.gitguardian.com/secrets-detection/secret-sprawl">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>What are secrets in the software development world?</p><div><p>In the common language, a secret can be any sensitive data that we want to keep private. When discussing secrets in the context of software development, secrets generally refer to digital authentication credentials that grant access to systems or data. These are most commonly API keys, usernames and passwords, or security certificates.</p><p>Secrets exist in the context of applications that are no longer standalone monoliths. Applications nowadays rely on thousands of independent building blocks: cloud infrastructure, databases, SaaS components such as Stripe, Slack, HubSpot…&nbsp;</p><p>Secrets are what tie together these different building blocks of a single application by creating a secure connection between each component.</p></div><p>What is secret sprawl?</p><div><p>Secret sprawl is the unwanted distribution of secrets like API keys and credentials through multiple systems.&nbsp;</p><p>In modern software development, secrets are regularly used by developers and applications. As a result they often get shared through different services like Slack or email and can be stored in multiple locations including different machines, git repositories or inside company wikis. This is a phenomenon we call secret sprawl.</p></div><p>What are some of the best practices to securely manage secrets like API keys?</p><div><p>Storing and managing secrets like API keys and other credentials can be challenging. Even the most careful policies can sometimes be circumvented in exchange for convenience. We have put together a helpful <a href="https://blog.gitguardian.com/secrets-api-management/" target="_blank">cheat sheet</a> and article explaining the <a href="https://blog.gitguardian.com/secrets-api-management/" target="_blank">best practices for managing secrets</a>.</p><p>As a minimum here are some points you should consider:</p></div><div><p>Never store unencrypted secrets in git repositories</p></div><div><p>Avoid git add * commands on git</p></div><div><p>Add sensitive files in .gitignore</p></div><div><p>Don’t rely on code reviews to discover secrets</p></div><div><p>Use automated secrets scanning on repositories</p></div><div><p>Don’t share your secrets unencrypted in messaging systems like Slack</p></div><div><p>Store secrets safely (method to be used depends on every use case)</p></div><div><p>Default to minimal permission scope for APIs</p></div><div><p>Whitelist IP addresses where appropriate</p></div><p>What are the threats associated with secret sprawl?</p><div><p>When secrets are sprawled through multiple systems it increases what is referred to as the ‘attack surface’. This is the amount of points where an unauthorized user could gain access to your systems or data. In the case of secret sprawl, each time a secret enters another system it is another point where an attacker could gain access to your secrets.</p><p>Most internal systems are not an appropriate place to store sensitive information, even if those systems are private. No company wants credit card numbers in plaintext in databases, PII in application logs, bank account credentials in a Google Doc. Secrets benefit from the same kind of protective measures.</p><p>As a general security principle, where feasible, data should remain safe even if it leaves the devices, systems, infrastructure or networks that are under organizations’ control, or if they are compromised. This helps prevent credential stealing, which is a well-known adversary technique described in the MITRE ATT&amp;CK framework:</p></div><p>“ Adversaries may search local file systems and remote file shares for files containing passwords. These can be files created by users to store their own credentials, shared credential stores for a group of individuals, configuration files containing passwords for a system or service, or source code/ binary files containing embedded passwords. ”<br></p><p>Secrets accessed by malicious threat actors can lead to information leakage and allow lateral movement or privilege escalation, as secrets very often lead to other secrets. Furthermore, once an attacker has the credentials to operate like a valid user, it is extremely difficult to detect the abuse and the threat can become persistent.<br></p><p>What are some of the biggest challenges associated with secret sprawl?</p><div><p>Because secrets tie together each component of an application, developers and ops need access to these secrets to build, connect, test and deploy applications. The result is that secrets need to be both tightly wrapped and also widely distributed. </p><p>Enforcing good security practices at the organization level is hard. Developers today can have large turnovers inside companies, be spread through many different teams and geographies. They have a growing number of technologies they must master and are under hard pressure due to shortened release cycles. This makes secret management very complicated and an ever changing challenge. </p><p>This is further complicated when VCS like git are introduced because secrets can be buried deep inside the history. The actual version of source code might look clean, while the history might present credentials that were added than later removed. Any secret reaching the Version Control System must be considered compromised and the presence of valid secrets in the git history presents a threat!</p></div></div></div>]]>
            </description>
            <link>https://www.gitguardian.com/secrets-detection/secret-sprawl</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649034</guid>
            <pubDate>Thu, 01 Oct 2020 09:27:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why is it hard to detect API keys in source code?]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24649026">thread link</a>) | @oodelally
<br/>
October 1, 2020 | https://www.gitguardian.com/secrets-detection/how-to-detect-secrets-in-source-code | <a href="https://web.archive.org/web/*/https://www.gitguardian.com/secrets-detection/how-to-detect-secrets-in-source-code">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Why is it hard to detect secrets like API keys and other credentials?</p><div><p>Secrets detection is probabilistic—that is to say that it is not always possible to determine what is a true secret (or true positive). Because secrets share very few common, distinctive factors, decisions must be taken by aggregating weak signals to make strong predictions. </p><p>One of the most common factors is that almost all secrets are strings that look random. We call these strings high entropy strings. The issue is that this common factor is not very distinctive: 99% of strings that look random in source code aren’t secrets. They are for example database IDs or other types of false positives. </p><p>Of course, some secrets have fixed patterns: AWS keys often start with AKIA for example. But most secrets do not. The portions of code surrounding them are also very different, depending on what the secrets are used for and how they are used by the developers in the context of specific applications. Usernames and passwords can be used to authenticate in many different ways, and it is really hard to distinguish between real and fake credentials used as placeholders for example. </p><p>All this makes it extremely challenging to accurately capture all true secrets without also capturing false positives. At some point, a line in the sand needs to be drawn that considers the cost of a secret going undetected (a false negative) and compares it to the outcome that too many false positives would create. Different organizations with different people, cultures and workflows will draw different lines!</p></div><p>Why do code reviews fail at finding secrets in source code?</p><p>Code reviews are great overall for detecting logic flaws or maintaining certain good coding practices. But they are not adequate protection for detecting secrets, mostly for two reasons:<br></p><div><p>Reviews generally only consider the net difference between the current and proposed states. Not the entire history of changes. If a commit adds a secret and another one later deletes it, this has a zero net effect that is not of any interest to reviewers. But the vulnerability is there.</p></div><div><p>Reviewers prefer to focus on errors that cannot be automatically detected, like design flaws. As a general principle, security automation should be implemented wherever it can be, so that humans focus on where they bring the most value.</p></div><p>What is a "good" secrets detection algorithm?</p><div><p>Detecting secrets in source code is like finding needles in a haystack: there are a lot more sticks than there are needles, and you don’t know how many needles might be in the haystack. In the case of secrets detection, you don’t even know what all the needles look like!</p><p>Ideally, you want your detection system to achieve at the same time:</p></div><div><p>A low number of false alerts raised. We call this high precision. Precision answers the question: «What is the percentage of the secrets that you detect that are actual secrets?». This question is perfectly legitimate, especially in the context of security teams being overwhelmed with too many alerts.</p></div><div><p>A low number of secrets missed. This is what we call high recall. Considering that a single undetected credential can have a big impact for an organization, some organizations prefer to triage more false alerts but make sure they don’t miss a secret.</p></div><p>Balancing the equation to ensure that the algorithm captures as many secrets as possible without flagging too many false results is an intricate and extremely difficult challenge. Read more on evaluating <a href="https://blog.gitguardian.com/secrets-detection-accuracy-precision-recall-explained/" target="_blank">secrets detection algorithms</a>.<br></p><p>What is a false positive in secrets detection?</p><div><p>A false positive in secrets detection refers to when a secret candidate is wrongly marked as a true secret when it is in fact a non-sensitive string. </p><p>Typical examples of strings that can be mistaken for true secrets are:</p></div><div><p>UUIDs (Universally Unique Identifiers) that are used for example by databases as unique keys.</p></div><div><p>High entropy URLs or file paths. They often contain random strings that look like keys.</p></div><p>Examples of server-side hooks:<br></p><div><p>Test keys. Service Providers sometimes provide developers with a set of test credentials with a very restricted scope so developers can exercise parts of the API without charging their account</p></div><div><p>Public keys. As surprising as it is, a very small number of keys are really meant to be public (like Firebase keys, see this Stack Overflow <a href="https://stackoverflow.com/questions/37482366/is-it-safe-to-expose-firebase-apikey-to-the-public" target="_blank">conversation</a>).</p></div><p>Are secrets detection algorithms language-dependent?</p><p>Secrets detection is, for the most part, not language specific. Of course, there are some subtleties to take into account, like the way variables are assigned in any programming language. But there is no need to support all the different syntaxes in their greatest details. This means that the same algorithms can be applied to any project, in any programming language, without using things like Abstract Syntax Trees.<br></p></div></div>]]>
            </description>
            <link>https://www.gitguardian.com/secrets-detection/how-to-detect-secrets-in-source-code</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649026</guid>
            <pubDate>Thu, 01 Oct 2020 09:26:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why automate secrets scanning throughout your SDLC?]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24649022">thread link</a>) | @oodelally
<br/>
October 1, 2020 | https://www.gitguardian.com/secrets-detection/secrets-detection-application-security | <a href="https://web.archive.org/web/*/https://www.gitguardian.com/secrets-detection/secrets-detection-application-security">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>My source code is private, so why is hardcoding credentials in git considered a bad practice?</p><div><p>While private repositories offer some level of protection for your code they still do not have adequate protection to store information as sensitive as secrets. </p><p>Imagine if there was a plain text file with all your credit card numbers within it, you hopefully wouldn’t put this into the companies git repository. Secrets are just as sensitive.</p><p>A few things to consider when storing secrets in private repositories:</p></div><div><p>Source code is made to be duplicated and distributed, therefore lives in multiple places. Source code is a leaky asset and you never know where it is going to end up. It can be cloned to a compromised workstation or server, intentionally or accidentally published in whole or in part, uploaded to your website, released to a customer, pasted in Slack, or end up in your package manager or mobile application...</p></div><div><p>It would just take one compromised developer account to compromise all the secrets they have access to.</p></div><div><p>Hardcoded credentials make it impossible to know what secrets a developer accessed, and very difficult to rotate keys.</p></div><p>Why automate secrets scanning throughout the Software Development Life Cycle (SLDC)?</p><p>While DevOps, Continuous Integration and Continuous Delivery speed up software development, they can also significantly increase security risks.<br></p><p>“DevOps is rapid and requires lots of small, iterative changes. But this increases complexity and opens up a new set of security problems. With DevOps, existing security vulnerabilities can be magnified and manifest themselves in new ways. The speed of software creation can mean new vulnerabilities are created unseen by developers. The solution is to build security monitoring into the DevOps process from the start.”<br></p><p>Greg Day, RSA Conference Organizer (<a href="https://www.securityroundtable.org/the-biggest-cybersecurity-risks-in-2020/" target="_blank">source</a>)<br></p><p>Security now needs to be part of the SDLC from the start, and part of every incremental change. This concept is called Shifting Left, a development principle which states that security should move from the right (or end) of the SDLC to the left (the beginning). A great deal of automation is needed in order to be able to cope with running security checks at each incremental change. &nbsp;Automation helps streamline the detection, alerting and remediation processes and workflows.<br></p><p>How does secrets detection compare with Static Application Security Testing (SAST)?</p><div><p>Secrets detection is often confused with SAST because both scan through static source code. </p><p>SAST is mostly testing control structure, input validation, error handling, etc. Such vulnerabilities like SQL injection vulnerabilities only express themselves the moment the code is deployed. Exposed secrets are unlike these vulnerabilities, because any secret reaching version control system must be considered compromised and requires immediate attention. This is true even if the code is never deployed. </p><p>Implementing secrets detection is not only about scanning the most actual version of your master branch before deployment. It is also about scanning through every single commit of your git history, covering every branch, even development or test ones.</p><p>To conclude, SAST is concerned only with the current version of a project, the version that is going to be deployed, whereas secrets detection is concerned with the entire history of the project.</p></div><p>What are git hooks?</p><div><p>Git hooks are scripts that are triggered by certain actions in the software development process, like committing or pushing. By automatically pointing out issues in code, they allow reviewers not to waste time on mistakes that can be easily diagnosed by a machine. </p><p>There are client-side hooks, that execute locally on the developers’ workstation, and server-side hooks, that execute on the centralized version control system.</p><p>Examples of client-side hooks:</p></div><p>Examples of server-side hooks:<br></p><p>What is a pre-commit hook?</p><div><p>"The pre-commit hook is run first when committing, before you even type in a commit message. It’s used to inspect the snapshot that’s about to be committed, to see if you’ve forgotten something, to make sure tests run, or to examine whatever you need to inspect in the code. </p><p>Exiting non-zero from this hook aborts the commit, although you can bypass it with <span>git commit --no-verify</span>. You can do things like check for code style (run lint or something equivalent), check for trailing whitespace, or check for appropriate documentation on new methods."</p></div><p>Source: <a href="https://git-scm.com/book/en/v2/Customizing-Git-Git-Hooks" target="_blank">git-scm</a><br></p><p>What is a pre-receive hook?</p><div><p>A pre-receive hook is a script that runs on the server. It performs checks on the content of the push; if it exits non-zero, the push is rejected. You can use this hook to do things like prevent a PR author from merging their own changes, or require commit messages to follow some specific guidelines. </p><p>Be careful when using pre-receive hooks as they are blocking: if the checks don’t pass, the server is not updated.</p></div><p>What is a post-receive hook?</p><p>"The post-receive hook runs after the entire process of pushing code to the server is completed and can be used to update other services or notify users. Examples include emailing a list, notifying a continuous integration server, or updating a ticket-tracking system – you can even parse the commit messages to see if any tickets need to be opened, modified, or closed. This script can’t stop the push process, but the client doesn’t disconnect until it has completed, so be careful if you try to do anything that may take a long time."<br></p><p>Source: <a href="https://git-scm.com/book/en/v2/Customizing-Git-Git-Hooks" target="_blank">git-scm</a><br></p><p>Unlike the pre-receive hook, post-receive is non-blocking.<br></p><p>Where in the DevOps pipeline to implement automated secrets scanning? Client-side or server-side?</p><div><p>The earlier a security vulnerability is uncovered, the less costly it is to correct. Hardcoded secrets are no exceptions. If the secret is uncovered after the secret reaches centralized version control server-side, it must be considered compromised, which requires rotating (revoking and redistributing) the exposed credential. This operation can be complex and typically involves multiple stakeholders.</p><p>Client-side secrets detection early in the software development process is a nice-to-have as it will prevent secrets entering the VCS earlier. </p><p>Server-side secrets detection is a must have:</p></div><div><p>&nbsp;Server-side is where the ultimate threat lies. From the server, the code can uncontrollably spread in a lot of different places, with the hardcoded secrets in it.</p></div><div><p>Implementing client-side hooks on an organization level is hard. This is something we have heard many application security professionals claim they are not confident to do, due to the difficulty to deploy and update this on every developer’s workstation.</p></div><div><p>Client-side hooks can and must be easy to bypass (remember secret detection is probabilistic). Usage of client side hooks largely comes down to the individual developers’ responsibility. Hence the need to have visibility over the later stages.</p></div><p>Should secrets detection be blocking or non-blocking in the SDLC?</p><div><p>From our experience, when trying to impose rules that are too constraining, people will bend them, often in an effort to collaborate better and do their job. Security must not be a blocker. It should allow flexibility and enable information to flow, yet enable visibility and control. </p><p>On one hand, security measures will be bypassed, sometimes for the worst. But on the other hand, it is also good sometimes that the developer can take the responsibility to bypass them. </p><p>Because even the best algorithms can fail and need human judgement. Secrets detection is probabilistic: algorithms achieve a tradeoff between not raising false alerts and not missing keys.</p></div></div></div>]]>
            </description>
            <link>https://www.gitguardian.com/secrets-detection/secrets-detection-application-security</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649022</guid>
            <pubDate>Thu, 01 Oct 2020 09:25:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Paralyzed Dutch man can temporarily move and talk again thanks to sleeping pill]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24648831">thread link</a>) | @jacquesm
<br/>
October 1, 2020 | https://www.world-today-news.com/paralyzed-dutch-man-can-temporarily-move-and-talk-again-thanks-to-sleeping-pill-now/ | <a href="https://web.archive.org/web/*/https://www.world-today-news.com/paralyzed-dutch-man-can-temporarily-move-and-talk-again-thanks-to-sleeping-pill-now/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>A Dutch man who has been unable to move and speak for eight years due to brain damage, can temporarily do so after taking the sleeping drug Zolpidem.  Brain scans show that the sleeping pill removes an obstacle to these actions, scientists from Radboudumc and Amsterdam UMC report Thursday.</p>
<p>In men, the brain activity for moving and talking is drowned out by the brain activity for the transfer of information.</p>
<p>“You could compare the brain, as it were, to a large string orchestra”, explains fellow researcher Hisse Arnts.  “With Richard (the man, ed.) The first violins play so loud that they drown out the other members of the string orchestra and people can no longer hear each other. Zolpidem ensures that these first violins play more ‘pianissimo’, so that everyone back within time. “</p>
<p>The fact that the man does not go to sleep because of Zolpidem is probably due to the way his brain has become confused, Arnts thinks.  The problem, however, is that the man gets used to the sleeping aid, so that the effect becomes shorter and shorter.  Yet he still receives it regularly and the discovery is a promising starting point for further research.</p>
<p>The man is not the first to return to a normal situation briefly with such a means;  there are similar reports from Italy and South Africa.  But how that is possible has now been determined for the first time on the basis of scans, according to the medical centers.</p>

<p>The man, in his late twenties at the time, suffered a severe lack of oxygen eight years ago due to choking.  He ended up in a nursing home with the very rare diagnosis of akinetic mutism.  Because Richard’s situation seemed hopeless, it was decided to give him the remedy.</p>

</div><p>    .</p></div>]]>
            </description>
            <link>https://www.world-today-news.com/paralyzed-dutch-man-can-temporarily-move-and-talk-again-thanks-to-sleeping-pill-now/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24648831</guid>
            <pubDate>Thu, 01 Oct 2020 08:48:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Asteroids: By the Numbers]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24648639">thread link</a>) | @rbanffy
<br/>
October 1, 2020 | http://www.retrogamedeconstructionzone.com/2019/10/asteroids-by-numbers.html?m=1 | <a href="https://web.archive.org/web/*/http://www.retrogamedeconstructionzone.com/2019/10/asteroids-by-numbers.html?m=1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div id="post-body-3855344372715435262"><p>
By 1979, arcade games were rapidly becoming more complex and colorful, and a game like <i>Asteroids </i>might have seemed quaint by comparison to the likes of <i><a href="http://www.retrogamedeconstructionzone.com/2019/09/galaxian-aesthetics-of-simple-patterns.html">Galaxian</a>, <a href="http://www.retrogamedeconstructionzone.com/2019/09/star-fire-weirdness-of-pseudo-3d.html">Star Fire</a></i>, or <i>Radar Scope.&nbsp; </i>But beneath its simple exterior lies a challenging shooter with surprisingly complex physics.&nbsp; The image below shows a sample still from it, including the player's ship (the triangle on the left), three sizes of asteroids, and an alien ship.</p><p><a href="https://1.bp.blogspot.com/-XOyg91qwUV4/XZwhbHR4tnI/AAAAAAAAOXs/DJ89MzjAODU3mAoraZKUaq6vl9nKvdsSACLcBGAsYHQ/s1600/Asteroids_sample%2B%25282%2529.png"><img data-original-height="461" data-original-width="598" height="492" src="https://1.bp.blogspot.com/-XOyg91qwUV4/XZwhbHR4tnI/AAAAAAAAOXs/DJ89MzjAODU3mAoraZKUaq6vl9nKvdsSACLcBGAsYHQ/s640/Asteroids_sample%2B%25282%2529.png" width="640"></a></p>

<p>
The goal of the game is to maximize your score, destroying as many asteroids and aliens as possible before you run out of ships.&nbsp; When an asteroid is hit by something (usually the player's bullets), large asteroids turn into two medium ones and medium asteroids turn into two small ones, while small asteroids and aliens are destroyed when hit.</p><p><a href="https://1.bp.blogspot.com/-cEzHmkcz3bA/XaU1zGl7IBI/AAAAAAAAObY/2GDlGaxtEc0ytzWpyQRinUxnbioeVsTbQCLcBGAsYHQ/s1600/Asteroids%2BPlay.gif"><img data-original-height="357" data-original-width="600" height="237" src="https://1.bp.blogspot.com/-cEzHmkcz3bA/XaU1zGl7IBI/AAAAAAAAObY/2GDlGaxtEc0ytzWpyQRinUxnbioeVsTbQCLcBGAsYHQ/s400/Asteroids%2BPlay.gif" width="400"></a></p>
<p>
For the designers of the game, balancing the relative sizes of the objects would have been important in such a dense field, because it determines how often things run into one another other.&nbsp; The table below outlines the sizes of the objects in <i>Asteroids</i>, expressed relative to the length of the player's ship.</p><table>
<caption>The approximate horizontal lengths of objects in <i>Asteroids</i></caption>
    <tbody>
<tr>
    <th>Object</th>
    <th>Length (in player ship lengths)</th>
    </tr>
<tr>
    <td>Screen</td>
    <td>25 x 36</td>
    </tr>
<tr>
    <td>Large Asteroids</td>
    <td>2.4</td>
    </tr>
<tr>
    <td>Medium Asteroid</td>
    <td>1.2</td>
    </tr>
<tr>
    <td>Small Asteroid</td>
    <td>0.6</td>
    </tr>
<tr>
    <td>Alien Ship (large)</td>
    <td>1.5</td>
    </tr>
<tr>
    <td>Alien Ship (small)</td>
    <td>0.75</td>
    </tr>
</tbody>
    </table>
<p>
Notice how the medium asteroid is twice the size of the small one, and the large is twice the size of the medium.&nbsp; If you think about it, this doesn't actually make much physical sense -- you can break a two-dimensional object into four pieces half its size, not two.&nbsp; But the size ratios do make game sense, because what really matters to the player is not how much area an asteroid takes up, but how likely it is to hit them.</p><p><a href="https://1.bp.blogspot.com/-5wVPSIS6W_M/XZwmjsjcYII/AAAAAAAAOX4/a7MThKiGRH8vhydf83eCiOmmJuKUULHIwCLcBGAsYHQ/s1600/Asteroids_cross_section%2B%25282%2529.png"><img data-original-height="281" data-original-width="170" src="https://1.bp.blogspot.com/-5wVPSIS6W_M/XZwmjsjcYII/AAAAAAAAOX4/a7MThKiGRH8vhydf83eCiOmmJuKUULHIwCLcBGAsYHQ/s1600/Asteroids_cross_section%2B%25282%2529.png"></a></p>

<p>
In the picture above, you can see that while the four small asteroids take up less area on the screen than the big one, they present the same cross section to your ship.&nbsp; This means that breaking up the asteroids doesn't greatly increase the probability that the player will be struck by one.&nbsp; If the asteroids had been broken up into four half-sized pieces at each blow, each large asteroid would result in sixteen small ones (that's four times the cross section!) and the player would be quickly overwhelmed.&nbsp; Note that the small asteroids do move faster than the large ones, and speed increases the chance of getting hit, but I'll return to that in a moment.</p>

<p>
Another big reason that size matters in <i>Asteroids</i>&nbsp;is that it determines how close something has to be before you're likely to be able to hit it.&nbsp; In 1979, vector arcade cabinet screens had an effective resolution of 1024 x 768, and the player's ship was only connected graphically by about 20 points.&nbsp; This meant, in turn, that there were only a limited number of orientations that they could render for the ship, in this case intervals of 5 degrees.&nbsp; To see how this might affect gameplay, imagine your ship is located at the fixed position shown in the picture below.&nbsp; Anything located entirely between the two solid lines will not be accessible by your bullets because your ship can't turn to the appropriate angle to hit it.&nbsp; This restriction isn't a big deal for large asteroids, which are still accessible over most of the screen, but small asteroids can be out of reach of your guns at relatively close range, sometimes as close as 7 ship lengths away!&nbsp; So even if you aim as accurately as possible, chances are you won't be able to hit a small asteroid on the other side of the screen, at least not on your first shot.&nbsp; This is probably one of the reasons that <i>Asteroids</i>&nbsp;allows you to fire up to four bullets in succession: even if you can't hit an object right away, it will eventually move into your line of fire.</p>

<p><a href="https://1.bp.blogspot.com/-EX2V1tAwdnM/XZvKFmnQZoI/AAAAAAAAOXI/cd411AFReLcKkCQGooANzsmxVD7QV3ikgCLcBGAsYHQ/s1600/Asteroids_hittable%2B%25285%2529.png"><img data-original-height="397" data-original-width="1024" height="248" src="https://1.bp.blogspot.com/-EX2V1tAwdnM/XZvKFmnQZoI/AAAAAAAAOXI/cd411AFReLcKkCQGooANzsmxVD7QV3ikgCLcBGAsYHQ/s640/Asteroids_hittable%2B%25285%2529.png" width="640"></a></p>
<p>
And what about speed?&nbsp; There is some variability in the speeds of individual asteroids, but small asteroids can move as much as 63% faster than large ones (see the table below), meaning that even if four small asteroids present the same cross section for hitting your ship as a large one does, their higher speed means they're more likely to hit you.&nbsp; The reasoning for this is simple: the faster something moves, the longer the path it can traverse in a given amount of time, and the larger the likelihood that you'll be in that path.&nbsp; Fortunately, even the fastest asteroids are much slower than your ship, which can traverse the screen in about two seconds; so if you're skilled enough, you should be able to maneuver around the asteroid field without a problem.</p><table>
<caption>The approximate speeds of objects in <i>Asteroids</i></caption>
    <tbody>
<tr>
    <th>Object</th>
    <th>Speed (in ship lengths per second)</th>
    </tr>
<tr>
    <td>Your ship</td>
    <td>0 - 17</td>
    </tr>
<tr>
    <td>Asteroids</td>
    <td>4 - 6.5</td>
    </tr>
<tr>
    <td>Alien ships (both sizes)</td>
    <td>4 - 6.5 (depending on your score)</td>
    </tr>
<tr>
    <td>Bullets</td>
    <td>17 (ship at rest)&nbsp;</td></tr>
</tbody></table>
<p>
One other interesting thing about speed: notice in the table above that the speed of a bullet, when fired at rest, is the same as your ship's maximum speed.&nbsp; This means that when you're moving rapidly and fire a bullet in the opposite direction of your motion, the two speeds should cancel for a stationary observer and the bullet should appear roughly stationary.</p>

<p><a href="https://1.bp.blogspot.com/-pRIxsTPNfSY/XaD7O0foijI/AAAAAAAAOZQ/JWZGFR26JEY3UM43RiruPhhGfHOCW21DgCLcBGAsYHQ/s1600/Asteroids_bullet_stationary.gif"><img data-original-height="175" data-original-width="468" height="239" src="https://1.bp.blogspot.com/-pRIxsTPNfSY/XaD7O0foijI/AAAAAAAAOZQ/JWZGFR26JEY3UM43RiruPhhGfHOCW21DgCLcBGAsYHQ/s640/Asteroids_bullet_stationary.gif" width="640"></a></p>


<div><p>
Sure enough, when I fire a bullet while moving quickly in the opposite direction, it just floats near where I fired it, allowing me to place bullets like mines for the asteroids to run into.</p>
<p>
The developers of <i>Asteroids </i>wanted the game to simulate the real laws of physics (<a href="http://www.technologyuk.net/computing/computer-gaming/gaming-landmarks-1960-1985/asteroids.shtml">see here</a>), and I think in many respects they succeeded, at least compared to most other arcade games of the time.&nbsp; It's not entirely realistic, however.&nbsp; In my article on <a href="http://www.retrogamedeconstructionzone.com/2019/10/impossible-motion-in-video-games.html">motion in early arcade games</a>, I discussed how the acceleration of the ship in <i>Asteroids</i> is too rapid for a human-occupied vehicle.&nbsp; We might suppose that the vehicle is automated, but even then, engineering spacecraft to withstand 30+ g's of acceleration is a non-trivial challenge.</p><p><a href="https://1.bp.blogspot.com/-eBpcOCL_1a0/XaU-bXjLJjI/AAAAAAAAObk/N_FxduJSebIMaqzrq7BhDmNFufzmyBRfgCLcBGAsYHQ/s1600/Acceleration%2BAsteroids.gif"><img data-original-height="175" data-original-width="634" height="176" src="https://1.bp.blogspot.com/-eBpcOCL_1a0/XaU-bXjLJjI/AAAAAAAAObk/N_FxduJSebIMaqzrq7BhDmNFufzmyBRfgCLcBGAsYHQ/s640/Acceleration%2BAsteroids.gif" width="640"></a></p>
<p>
Another issue is the way the asteroids break up.&nbsp; In physics, there's a principle called the conservation of momentum that says that when objects interact with one another or break apart, the total mass times the velocity must remain the same after the interaction as it was before.&nbsp; In layman's terms, this means that things can't suddenly go from moving one direction to moving in another unless there is something else carry its previous momentum.&nbsp; In the example shown below, an asteroid does just that, and the only thing that could have absorbed its previous momentum is the bullet.&nbsp; But the bullet is so tiny that it's difficult to imagine how that would be possible.</p><p><a href="https://1.bp.blogspot.com/-vsDHHIPNXrQ/XaEAAKYXRII/AAAAAAAAOZc/-lhbXy0TSV4nEiLvOf-pe7zyt9sPGLcEACLcBGAsYHQ/s1600/Asteroids_momentum.gif"><img data-original-height="248" data-original-width="533" height="185" src="https://1.bp.blogspot.com/-vsDHHIPNXrQ/XaEAAKYXRII/AAAAAAAAOZc/-lhbXy0TSV4nEiLvOf-pe7zyt9sPGLcEACLcBGAsYHQ/s400/Asteroids_momentum.gif" width="400"></a></p>

<p>
These are mere quibbles, however, and shouldn't dissuade you from giving the game a try.&nbsp; <i>Asteroids </i>ended up being one of Atari's biggest arcade hits, selling over 70,000 cabinets, and remains one of their most recognizable games to this day.&nbsp; Many gamers who grew up in the '80s, myself included, are more familiar with the Atari 2600 version of the game.&nbsp; Unfortunately, the designers had to make a lot of sacrifices in game physics in order to make it work on a home console, so I think the arcade version is really the way to go.&nbsp; Outside of visiting a vintage arcade, your best bet is probably the <a href="https://www.mamedev.org/">Multiple Arcade Machine Emulator</a> (MAME).&nbsp; Happy hunting!</p></div><div><p><span>NOTE: &nbsp;A previous version of this article stated that the game has limited pixel resolution, but <i>Asteroids </i>uses a vector display that is not composed of pixels. &nbsp;The resolution of the <i>Asteroids </i>vector display is 1024 x 768.</span></p><p><a href="https://1.bp.blogspot.com/-7gLKzZ6gULM/XaDx0uT70-I/AAAAAAAAOYo/aLUcLQJkl9AY1k2OYsewuUHydaxbkT0gwCLcBGAsYHQ/s1600/Asteroids_loop_transparent.gif"><img data-original-height="151" data-original-width="600" height="160" src="https://1.bp.blogspot.com/-7gLKzZ6gULM/XaDx0uT70-I/AAAAAAAAOYo/aLUcLQJkl9AY1k2OYsewuUHydaxbkT0gwCLcBGAsYHQ/s640/Asteroids_loop_transparent.gif" width="640"></a></p>
<br></div>
</div>
</div></div>]]>
            </description>
            <link>http://www.retrogamedeconstructionzone.com/2019/10/asteroids-by-numbers.html?m=1</link>
            <guid isPermaLink="false">hacker-news-small-sites-24648639</guid>
            <pubDate>Thu, 01 Oct 2020 08:15:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Russian opposition leader Alexei Navalny describes his poisoning with Novichok]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24648502">thread link</a>) | @FrojoS
<br/>
October 1, 2020 | https://www.spiegel.de/international/world/alexei-navalny-thanks-germany-and-describes-his-poisoning-with-novichok-a-f1249540-76f7-43ce-aa14-358d71256684 | <a href="https://web.archive.org/web/*/https://www.spiegel.de/international/world/alexei-navalny-thanks-germany-and-describes-his-poisoning-with-novichok-a-f1249540-76f7-43ce-aa14-358d71256684">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-article-el="body">
<section data-app-hidden="true">


</section>
<section>
<div>
<figure data-component="Image" data-settings="{&quot;id&quot;:&quot;83eb2320-0da2-4c9c-971a-560530cea088&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;fdb20ad3-3dfd-4108-863b-4a4212f228e0&quot;}">
<p><span>
<span data-image-el="aspect">
<span>
<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/83eb2320-0da2-4c9c-971a-560530cea088_w948_r1.77_fpx28.11_fpy49.98.jpg" srcset="https://cdn.prod.www.spiegel.de/images/83eb2320-0da2-4c9c-971a-560530cea088_w520_r1.77_fpx28.11_fpy49.98.jpg 520w, https://cdn.prod.www.spiegel.de/images/83eb2320-0da2-4c9c-971a-560530cea088_w948_r1.77_fpx28.11_fpy49.98.jpg 948w" width="948" height="536" sizes="948px" title="Alexei Nawalny" alt="Alexei Nawalny">
</span>
</span>
</span>

</p>
<figcaption>
<p>Alexei Nawalny</p>
<span>
Foto: Peter Rigaud&nbsp;/ DER SPIEGEL
</span>
</figcaption>
</figure>
</div><div>
<p>In his first media interview following his poisoning, Russian opposition leader Alexei Navalny expresses his "tremendous gratitude to all Germans" in an interview with the newsmagazine DER SPIEGEL. In the interview, he says that although he never had close ties to Germany, it was German politicians and Chancellor Angela Merkel who saved his life. He says the doctors at Berlin's Charité University Hospital saved his life for a second time and nursed him back to health. "I know it sounds a bit over the top, but Germany has become a special country for me," Navalny says. Describing the personal visit paid to him by Merkel last week, he says: "I was impressed by the detail she knows about <a href="https://www.spiegel.de/thema/russia_en/" data-link-flag="english">Russia</a> and my case."</p>



<section data-area="contentbox">

</section>
<p>Navalny says he is doing "much better than three weeks ago, and things are getting better each day." The doctors say he could get back to 90 percent of his former self, perhaps even 100 percent, although no one knows for sure. "Basically, I’m a bit of a guinea pig," he says. "There aren’t many people you can observe who are still alive after being poisoned with a nerve agent." Describing the moment in the airplane when the poison started to take effect, Navalny says: "You feel no pain, but you know you’re dying. And I mean, right now. Even though nothing hurts you." You just think: This is the end. "Organophosphorus compounds attack your nervous system like a DDos attack attacks the computer - it's an overload that breaks you," he told DER SPIEGEL.</p>

<div>
<p>"I assert that <a href="https://www.spiegel.de/thema/vladimir_putin_en/" data-link-flag="english">Putin</a> was behind the crime, and I have no other explanation for what happened." Despite the attempt on his life, he says he wants to return to Russia. "And my job now is to remain the guy who isn’t afraid. And I’m not afraid! When my hands shake, it’s not from fear – it’s from this stuff. I would not give Putin the gift of not returning to Russia."</p><p>When asked whether he thinks Germany should stop the completion of the Nord Stream 2 Russian gas pipeline project, Navalny didn’t want to answer. "That’s Germany’s business. Decide for yourself!" Any strategy toward Russia must "take into account the level of insanity that Putin has reached."</p>
</div>

<div>
<p><em>The full interview with Navalny will be posted in English later today.</em></p>
<p><span><svg aria-labelledby="title-0c5f048c-ffa2-4be2-a45e-fd323d53e722" width="10" height="20" viewBox="0 0 10 20" fill="none" xmlns="http://www.w3.org/2000/svg" role="img"><title id="title-0c5f048c-ffa2-4be2-a45e-fd323d53e722">Icon: Der Spiegel</title><g id="l-s-flag-0c5f048c-ffa2-4be2-a45e-fd323d53e722"><path id="vector-0c5f048c-ffa2-4be2-a45e-fd323d53e722" d="M9.85 16.293v-8H3.212V4.667h3.533v2.24h3.212v-3.2C9.85 2.747 8.993 2 8.03 2H1.713C.749 2 0 2.747 0 3.707v7.253h6.638v4.373H3.105v-2.986H0v3.84c0 .96.75 1.706 1.713 1.706H8.03c.963.107 1.82-.64 1.82-1.6z" fill="#000"></path></g></svg>
</span>
</p></div>

</div>
</section>

</div></div>]]>
            </description>
            <link>https://www.spiegel.de/international/world/alexei-navalny-thanks-germany-and-describes-his-poisoning-with-novichok-a-f1249540-76f7-43ce-aa14-358d71256684</link>
            <guid isPermaLink="false">hacker-news-small-sites-24648502</guid>
            <pubDate>Thu, 01 Oct 2020 07:54:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Checking Out Quest DB]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24648455">thread link</a>) | @asafg6
<br/>
October 1, 2020 | https://www.turtle-techies.com/checking-out-quest-db/ | <a href="https://web.archive.org/web/*/https://www.turtle-techies.com/checking-out-quest-db/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
        
        <h4>We decided to check out Quest DB, an open-source Time Series database</h4>
                <h6>
                    By Suresh Regmi, Published 2020-08-31
                </h6>
    </p><div itemprop="articleBody"><h2 id="what-is-quest-db">What is Quest DB?</h2>
<p>QuestDB is an open-source Time Series database that uses a column-oriented storage approach and vectored execution for simple and extremely quick query execution.<br>
It was developed by QuestDB Limited in 2014.<br>
It is written in Java and supports Linux, macOS and Windows as the server operating system.<br>
The query language utilized for QuestDB is SQL (Structured Query Language) alongside its expansion for time series-analysis.<br>
QuestDB depends on the relational data model, normally found in some of the popular relational databases like PostgreSQL, MySQL, SQL Server, Oracle, and so forth which means that each time-series estimation is recorded in its row, with a time field followed by other fields.</p>
<h2 id="features">Features</h2>
<p>Some of the best features of QuestDB are as follows.</p>
<ul>
<li>Time series database with a relational data model.</li>
<li>SIMD optimized analytics</li>
<li>Uses column-oriented storage technologies with each column stored continuously in sequential blocks</li>
<li>It allows columns to be chosen as a designated timestamp to utilize it’s high-performance time series functions</li>
<li>Comes with a built-in SQL optimizer</li>
<li>InfluxDB line and Postgres wire protocol support</li>
<li>Supports time series and relational joins</li>
<li>It supports horizontal partitioning (by timestamps)</li>
<li>Supports ACID</li>
</ul>
<p>The setting up of QuestDB can be done easily by following the <a href="https://questdb.io/docs/introduction/" target="_blank">QuestDB documentation</a><a>.<br>
It runs on port 9000 (by default) and provides a web console to interact with the database. The web console has a schema/table browser, query tool and visualization window where the query results can be shown either in tabular form or using graphs.</a></p><a>
<p>Here is how the web console looks like:</p>
</a><p><a></a><a href="https://www.turtle-techies.com/checking-out-quest-db/image1.png" target="_blank"><img src="https://www.turtle-techies.com/checking-out-quest-db/image1.png" alt="QuestDB web console"></a></p>
<h2 id="how-to-setup-questdb">How to setup QuestDB</h2>
<p>If like me, you want to setup QuestDB for learning or for a development environment, I would recommend using Docker.
Here are the instructions I used:
<a href="https://questdb.io/docs/packages/docker/" target="_blank"> </a><a href="https://questdb.io/docs/packages/docker/">https://questdb.io/docs/packages/docker/</a> </p>
<p>Your other options are:</p>
<ol>
<li>
<p>Using binaries:
For setting up QuestDB using binaries, you can refer to QuestDB's documentation <a href="https://questdb.io/docs/packages/binaries/" target="_blank"> </a><a href="https://questdb.io/docs/packages/binaries/">https://questdb.io/docs/packages/binaries/</a> .</p>
</li>
<li>
<p>Homebrew:
For macOS users, QuestDB is available via Homebrew <a href="https://questdb.io/docs/packages/homebrew/"> </a><a href="https://questdb.io/docs/packages/homebrew/">https://questdb.io/docs/packages/homebrew/</a> .</p>
</li>
</ol>
<h2 id="why-should-you-choose-questdb">Why should you choose QuestDB?</h2>
<p>The one thing I like most about QuestDB is that despite the fact that its engineering is planned from the ground up to be close to the hardware.
It offers advanced execution and is additionally centered around making it simpler for designers to integrate and query.</p>
<p>Following are the reasons you should choose QuestDB</p>
<h3 id="easy-to-set-up-and-use">Easy to set up and use</h3>
<p>QuestDB is a lightweight open-source database and is anything but difficult to set up without any conditions.
It will take just a couple of minutes to download and you can begin playing with it.
Its official website provides detailed technical documentation which makes installation, configuration and running the database very simple.
Its web console enables us to perform real-time analytics with easy visualization using different types of charts like bar, line area etc.</p>
<h3 id="supports-sql">Supports SQL</h3>
<p>One reason for utilizing QuestDB is its SQL-like query language.
On the off chance that you know about SQL, utilizing QuestDB would be simpler as it depends on SQL with its very time-series alterations.</p>
<h3 id="performance">Performance</h3>
<p>Execution is one of the fundamental rules that ought to be thought of while picking the database.
QuestDB offers better execution while managing time-series data like data from IoT gadgets, stock value information and DevOps measurements.
For a database that is new in the TSDB field, it gives seemingly preferable execution over other entrenched time-series databases.</p>
<h2 id="why-questdb-is-not-a-good-choice">Why QuestDB is not a good choice?</h2>
<h3 id="new-to-the-tsdb-ecosystem">New to the TSDB ecosystem</h3>
<p>QuestDB is a less mature product than other time-series databases like TimescaleDB and InfluxDB, which implies that there are a ton of integrations and features that are yet to be worked from the developers’ side.
So if you are searching for a well established time-series database with an extraordinary help network and discussion, QuestDB isn't there yet.</p>
<h3 id="oltp-support">OLTP Support</h3>
<p>OLTP databases require frequent inserts, updates, and deletes with user-defined constraints to be kept up.
If you are intending to utilize a database that likewise supports Online Transaction Processing, QuestDB is not a solid match.</p>
<h2 id="how-does-it-compare-with-other-databases">How does it compare with other databases?</h2>
<h3 id="questdb-vs-sql-databases">QuestDB vs SQL Databases</h3>
<p>QuestDB is like a SQL database (MySQL, Oracle, PostgreSQL) however unique from multiple points of view.<br>
Other relational databases can also handle time-series data but they tend to offer worse performance while dealing with common time-series operations like real-time aggregations of data.</p>
<p>On the other hand, QuestDB is purpose-built for fast storage and processing of time series data.
The data model followed by QuestDB is a relational data model which means that data is stored in a table and each row in a table represents a collection of related values.
It also follows the ACID property and supports joins like relational databases but does not allow user-defined constraints and triggers.</p>
<h3 id="alternatives-to-questdb">Alternatives to QuestDB</h3>
<p>Some of the best alternatives to QuestDB are as follows</p>
<h4 id="influxdb">InfluxDB</h4>
<p>InfluxDB is an open-source time-series database designed for high-availability storage and retrieval of data.<br>
It is a part of the TICK (Telegraf, InfluxDB, Chronograf, Kapacitor) stack and has a non-relational, NoSQL data model. It has SQL-like query language to handle interactions with the data</p>
<h4 id="timescaledb">TimescaleDB</h4>
<p>Built on the top of the Postgres database, TImescaleDB is optimized for fast ingest and complex queries with full SQL support like traditional relational databases.</p>
<h5 id="kdb">KDB+</h5>
<p>KDB+ is also a high performance column-store relational time-series database with in-memory abilities.<br>
It is commonly used to store, analyze and process high-frequency financial time series data.</p>
<p>I hope you enjoyed, and of course as always, feel free to comment or share.<br>
Thank you for reading.</p>
</div></div>]]>
            </description>
            <link>https://www.turtle-techies.com/checking-out-quest-db/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24648455</guid>
            <pubDate>Thu, 01 Oct 2020 07:47:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Baremetal programming on the tinyAVR 0 micro-controllers]]>
            </title>
            <description>
<![CDATA[
Score 101 | Comments 94 (<a href="https://news.ycombinator.com/item?id=24648397">thread link</a>) | @unwind
<br/>
October 1, 2020 | https://www.omzlo.com/articles/baremetal-programming-on-the-tinyavr-0-micro-controllers | <a href="https://web.archive.org/web/*/https://www.omzlo.com/articles/baremetal-programming-on-the-tinyavr-0-micro-controllers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><section><div><h4>All you need is a text editor, a makefile and a USB-serial cable.</h4></div></section><section><div><p><img src="https://www.omzlo.com/uploads/std_attiny-406-macro.jpg" alt=""></p>

<h2 id="introduction">Introduction</h2>

<p>Are you an 8-bit or a 32-bit programmer? </p>

<p>At OMZLO, we have been mainly focussing our development efforts on newer 32-bit Arm-Cortex chips (STM32 and SAMD), which typically offer more RAM, more speed, more peripherals, at a similar or lower price-point than older 8-bit MCUs. But 8-bit MCUs are far from dead. Microchip has notably released a new series of chips, collectively branded as the "tinyAVR 0-series", which offer more modern peripherals than the older AVR chips at a very competitive price point. They seem like the perfect candidate for simple products that don't need all the features and fine-tuning capabilities of the newer 32-bit MCUs. 8-bit MCUs are also substantially simpler to program, which translates into faster development time. </p>

<p>Thanks to the success of the Arduino UNO, there are tons of tutorials online that explain how to program 8-bit Atmega328 microcontrollers and their cousins like the Attiny85 using direct register access, without the Arduino language or any vendor IDE such as Atmel Studio. Just google "atmega328 blinky". All you need is an AVR C-compiler, a text editor, <a href="https://www.nongnu.org/avrdude/">avrdude</a>, and an AVR programmer. Some <a href="https://www.instructables.com/id/Getting-Started-With-the-ATMega328P/">resources</a> even show how to also build the electronics needed to get a basic atmega328 running on a breadboard. However, it's hard to find the same information for these newer "tinyAVR 0" chips.</p>

<p>Of course, Microchip offers all the tools necessary to program these newer "TinyAVR" MCUs with their windows-only IDE. There are also "Arduino cores" for some of these newer "TinyAVR" MCUs that let you program them with the Arduino IDE. But again, if you like to write code for MCUs in "baremetal" style, with your favorite text editor, a makefile, and a c-compiler, there are few resources available online. </p>

<p>In this blog post, we will describe how to program a <a href="https://www.ladyada.net/learn/proj1/blinky.html">blinky</a> firmware on an <strong>Attiny406</strong>, from the ground up, using the simplest tools. Most of the things described here can be easily transposed to other TinyAVR MCUs. Our approach is generally guided toward macOS or Linux users, but should also be applicable in an MS-Windows environment with a few minor changes.</p>

<h2 id="hardware">Hardware</h2>

<p>We decided to play with the <a href="https://www.microchip.com/wwwproducts/en/ATTINY406">Attiny406</a>, with a view of using it in the future to replace the Attiny45 we currently use on the <a href="https://www.omzlo.com/articles/the-piwatcher">PiWatcher</a>, our Raspberry-Pi watchdog. The Attiny406 has 4K of flash space, 256 bytes of RAM, and can run at 20Mhz without an external clock source.</p>

<p>One of the most important differences between the new TinyAVR MCUs and the older classic AVR MCU like the Attiny85 is that the newer chips use a different programming protocol called UPDI, which requires only 3 pins, as opposed to the 6-pin ISP on the classic AVRs.</p>

<p>A little research shows that programming TinyAVRs with UPDI can be achieved with a simple USB-to-serial cable and a resistor, thanks to a python tool called <a href="https://github.com/mraardvark/pyupdi">pyupdi</a>, which suggests the following connection diagram for firmware upload:</p>
<pre>                        Vcc                     Vcc
                        +-+                     +-+
                         |                       |
 +---------------------+ |                       | +--------------------+
 | Serial port         +-+                       +-+  AVR device        |
 |                     |      +----------+         |                    |
 |                  TX +------+   4k7    +---------+ UPDI               |
 |                     |      +----------+    |    |                    |
 |                     |                      |    |                    |
 |                  RX +----------------------+    |                    |
 |                     |                           |                    |
 |                     +--+                     +--+                    |
 +---------------------+  |                     |  +--------------------+
                         +-+                   +-+
                         GND                   GND
</pre>
<h3 id="shematic">shematic</h3>

<p>We created a minimalistic breakout board for the Attiny406. The board can be powered by 5V through USB or a lower 3.3V through dedicated VCC/GND pins. An LED and a button were also fitted on the board. For testing purposes, we decided to embed the 4.7K resistor needed for the UPDI programming directly in the hardware (i.e. resistor <em>R2</em>). 
This gives us the following schematic:</p>

<p><img src="https://www.omzlo.com/uploads/attiny406-schematic.png" alt="schematic"></p>

<h3 id="board">Board</h3>

<p>The resulting breakout board is tiny and fits conveniently on a small breadboard. The design files are <a href="https://aisler.net/p/SIEGFIYL">shared on aisler.net</a>.</p>

<p><img src="https://www.omzlo.com/uploads/std_attiny-406-breadboard.jpg" alt=""></p>

<p>Programming the Attiny406 on the board with a USB-serial cable is done by connecting the headers on the board edge:</p>

<p><img src="https://www.omzlo.com/uploads/attiny406-prog.png" alt=""></p>

<h2 id="software">Software</h2>

<h3 id="pyudpi">pyudpi</h3>

<p>We installed <strong>pyupdi</strong> following the instructions provided on <a href="https://github.com/mraardvark/pyupdi">their webpage</a>. </p>

<p>We connected our USB-Serial cable to the board with the 4 dedicated UPDI pins available on the board. Our USB-Serial converter shows up as the file <code>/dev/tty.usbserial-FTF5HUAV</code> on a MacOS system.</p>

<p>To test that the programmer recognizes the Attiny406, you can issue a command similar to the following, adapting the path for the USB-serial converter to your setup:</p>
<pre>pyupdi -d tiny406 -c /dev/tty.usbserial-FTF5HUAV -i
</pre>
<p>This should result in the following output if all goes well:</p>
<pre>Device info: {'family': 'tinyAVR', 'nvm': 'P:0', 'ocd': 'D:0', 'osc': '3', 'device_id': '1E9225', 'device_rev': '0.1'}
</pre>
<h3 id="the-c-compiler">The C compiler</h3>

<p>The typical <strong>avr-gcc</strong> available on macOS with <a href="https://brew.sh/">homebrew</a> did not seem to recognize the Attiny406 as a compiler target, so we went off to install the avr-gcc compiler provided by Microchip, which is available <a href="https://www.microchip.com/mplab/avr-support/avr-and-arm-toolchains-c-compilers">here</a>. Downloading the compiler requires you to create an account on the Microchip website, which is a bit annoying. </p>

<p><img src="https://www.omzlo.com/uploads/avr-toolchain.png" alt="AVR toolchain link"></p>

<p>Once downloaded, we extracted the provided archive in a dedicated directory. The <code>bin</code> directory in the archive should be added to the <code>PATH</code> variable to make your life easier. Assuming the downloaded compiler is stored in the directory <code>$HOME/Src/avr8-gnu-toolchain-darwin_x86_64</code>, the PATH can be altered by adding the following line to your <code>.bash_profile</code> file:</p>
<pre>export PATH=$PATH:$HOME/Src/avr8-gnu-toolchain-darwin_x86_64/bin/
</pre>
<p>Newer Attiny MCUs are not supported out of the box by the Microchip <strong>avc-gcc</strong> compiler. You need to download a dedicated <em>Attiny Device Pack</em> from <a href="http://packs.download.atmel.com/">their website</a>, as shown below:</p>

<p><img src="https://www.omzlo.com/uploads/microchip-pack-repository.png" alt="AVR toolchain link"></p>

<p>The resulting downloaded <em>Device Pack</em> is named <code>Atmel.ATtiny_DFP.1.6.326.atpack</code> (or similar depending on versioning). Though the extension is <code>.atpack</code>, the file is actually a zip archive. We changed the extension to <code>.zip</code> and extracted the package in the directory <code>$HOME/Src/Atmel.ATtiny_DFP.1.6.326</code> next to the compiler files. </p>

<h3 id="c-program">C program</h3>

<p>We created the following program that blinks the LED on pin PB5 of our Attiny board at a frequency of 1Hz.</p>
<pre><span>#include &lt;avr/io.h&gt;
#include &lt;util/delay.h&gt;
</span>
<span>int</span> <span>main</span><span>()</span> <span>{</span>
    <span>_PROTECTED_WRITE</span><span>(</span><span>CLKCTRL</span><span>.</span><span>MCLKCTRLB</span><span>,</span> <span>0</span><span>);</span> <span>// set to 20Mhz (assuming fuse 0x02 is set to 2)</span>

    <span>PORTB</span><span>.</span><span>DIRSET</span> <span>=</span> <span>(</span><span>1</span><span>&lt;&lt;</span><span>5</span><span>);</span>
    <span>for</span> <span>(;;)</span> <span>{</span>
        <span>PORTB</span><span>.</span><span>OUTSET</span> <span>=</span> <span>(</span><span>1</span><span>&lt;&lt;</span><span>5</span><span>);</span>
        <span>_delay_ms</span><span>(</span><span>500</span><span>);</span>
        <span>PORTB</span><span>.</span><span>OUTCLR</span> <span>=</span> <span>(</span><span>1</span><span>&lt;&lt;</span><span>5</span><span>);</span>
        <span>_delay_ms</span><span>(</span><span>500</span><span>);</span>
    <span>}</span>
<span>}</span>
</pre>
<p>The code looks very similar to what you would see on a classic AVR "blinky" program. One visible change is the use of structures to access various registers of the MCU: e.g instead of setting bits in <code>PORTB</code>, you access <code>PORTB.DIRSET</code>.</p>

<p>The other visible change is the clock setup code <code>_PROTECTED_WRITE(CLKCTRL.MCLKCTRLB, 0)</code>. Out of the box, at reset, the Attiny406 runs at 3.33Mhz, which corresponds to a base frequency of 20Mhz with a 6x clock divider applied. To enable the full 20Mhz speed, the register <code>CLKCTRL.MCLKCTRLB</code> is cleared. Because this register needs to be protected against accidental changes, the Attiny406 requires a specific programming sequence to modify it. Fortunately, this is natively offered by the macro <code>_PROTECTED_WRITE</code>. More details are available in the <a href="http://ww1.microchip.com/downloads/en/DeviceDoc/ATtiny406-DataSheet-DS40001976B.pdf">Attiny406 datasheet</a>.</p>

<p>In comparison with an STM32 or a SAMD21, the code is blissfully simple. </p>

<h3 id="makefile">Makefile</h3>

<p>We assume the following directory structure where:</p>

<ul>
<li><code>Src/Atmel.ATtiny_DFP.1.6.326/</code> is the location of the Microchip <em>Device Pack</em></li>
<li><code>Src/attiny406-test/</code> is the directory where the code above is stored in a file called <code>main.c</code></li>
</ul>

<p>Compiling the code can be done by issuing the following command within <code>attiny406-test/</code> directory,:</p>
<pre>avr-gcc -mmcu=attiny406 -B ../Atmel.ATtiny_DFP.1.6.326/gcc/dev/attiny406/ -O3 -I ../Atmel.ATtiny_DFP.1.6.326/include/ -DF_CPU=20000000L -o attiny406-test.elf main.c
</pre>
<p>An <code>-O</code> optimization flag is required to make the <code>_delay_ms()</code> function calls work successfully, as well as defining the variable F_CPU to reflect the expected chip clock speed. The rest of the parameters provide the location of the Attiny406 device-specific files we previously extracted from the <em>Device Pack</em>.</p>

<p>Uploading the firmware to the MCU requires a conversion to the intel HEX format and a call to the <strong>pyupdi</strong> tool. To address all these steps, we created a simple Makefile.</p>
<pre><span>OBJS</span><span>=</span>main.o
<span>ELF</span><span>=</span><span>$(</span>notdir <span>$(</span>CURDIR<span>))</span>.elf  
<span>HEX</span><span>=</span><span>$(</span>notdir <span>$(</span>CURDIR<span>))</span>.hex
<span>F_CPU</span><span>=</span>20000000L


<span>CFLAGS</span><span>=</span><span>-mmcu</span><span>=</span>attiny406 <span>-B</span> ../Atmel.ATtiny_DFP.1.6.326/gcc/dev/attiny406/ <span>-O3</span>
CFLAGS+<span>=</span><span>-I</span> ../Atmel.ATtiny_DFP.1.6.326/include/ <span>-DF_CPU</span><span>=</span><span>$(</span>F_CPU<span>)</span>
<span>LDFLAGS</span><span>=</span><span>-mmcu</span><span>=</span>attiny406 <span>-B</span> ../Atmel.ATtiny_DFP.1.6.326/gcc/dev/attiny406/
<span>CC</span><span>=</span>avr-gcc
<span>LD</span><span>=</span>avr-gcc

all:    <span>$(</span>HEX<span>)</span>  

<span>$(</span>ELF<span>)</span>: <span>$(</span>OBJS<span>)</span>
                <span>$(</span>LD<span>)</span> <span>$(</span>LDFLAGS<span>)</span> <span>-o</span> <span>$@</span> <span>$(</span>OBJS<span>)</span> <span>$(</span>LDLIBS<span>)</span>

<span>$(</span>HEX<span>)</span>: <span>$(</span>ELF<span>)</span>
                avr-objcopy <span>-O</span> ihex <span>-R</span> .eeprom <span>$&lt;</span> <span>$@</span>

flash:  <span>$(</span>HEX<span>)</span>
                pyupdi <span>-d</span> tiny406 <span>-c</span> /dev/tty.usbserial-FTF5HUAV <span>-f</span> attiny406-test.hex

read-fuses:
                pyupdi <span>-d</span> tiny406 <span>-c</span> /dev/tty.usbserial-FTF5HUAV <span>-fr</span>

clean:
                <span>rm</span> <span>-rf</span> <span>$(</span>OBJS<span>)</span> <span>$(</span>ELF<span>)</span> <span>$(</span>HEX<span>)</span>
</pre>
<p>To compile the code, we simply type <code>make</code>. Uploading is done with <code>make flash</code>. This Makefile can be further enhanced as needed.</p>

<h2 id="conclusion">Conclusion</h2>

<p>With the right tools, baremetal programming on the new TinyAVR MCUs is as simple as on its older AVR cousins. </p>

<p>If you have programming tips for the AVRTiny, please share them with us on <a href="https://twitter.com/OmzloElec">on Twitter</a> or in the comments below.</p>
</div></section><section><div><h4>Comments</h4><div><div><p>Hi, </p>

<p>It's great that …</p></div></div></div></section></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.omzlo.com/articles/baremetal-programming-on-the-tinyavr-0-micro-controllers">https://www.omzlo.com/articles/baremetal-programming-on-the-tinyavr-0-micro-controllers</a></em></p>]]>
            </description>
            <link>https://www.omzlo.com/articles/baremetal-programming-on-the-tinyavr-0-micro-controllers</link>
            <guid isPermaLink="false">hacker-news-small-sites-24648397</guid>
            <pubDate>Thu, 01 Oct 2020 07:37:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Start your open-source venture with AsyncAPI at Hacktoberfest]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24648373">thread link</a>) | @derberg
<br/>
October 1, 2020 | https://www.asyncapi.com/blog/hacktoberfest-2020 | <a href="https://web.archive.org/web/*/https://www.asyncapi.com/blog/hacktoberfest-2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><img src="https://www.asyncapi.com/img/posts/hacktoberfest.webp" alt="Post cover image"><h2 id="what-is-asyncapi">What is AsyncAPI</h2><p>AsyncAPI is a specification for describing your <a href="https://www.asyncapi.com/docs/getting-started/event-driven-architectures/">event-driven architecture</a>. You are probably using already <a href="https://www.asyncapi.com/docs/getting-started/coming-from-openapi/">OpenAPI/Swagger specification</a> for describing your synchronous RESTful APIs. AsyncAPI is something that supplements OpenAPI. As an example, you should use AsyncAPI when your services do not talk to each other directly but through a message broker.</p><p>In contrast to the OpenAPI Initiative, AsyncAPI Initiative is focused not only on creating and evolving the AsyncAPI specification but also on its tooling. It is a vendor-neutral space for the community to work together on the spec and its tools. We work on tools like specification parsers or docs and code generators.</p><p><iframe src="https://www.youtube.com/embed/pU71J-F7pfI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></p><h2 id="what-is-hacktoberfest-and-why-asyncapi-initiative-joins-it">What Is Hacktoberfest And Why AsyncAPI Initiative Joins It</h2><p><a href="https://hacktoberfest.digitalocean.com/">Hacktoberfest</a> is a well-known event that promotes open source contributions. In short, you have the entire October to submit four pull requests to any project you want, and in exchange, you get a super cool t-shirt. Is that it? Is it just for a t-shirt? Nah, the t-shirt is nice but what you also get is easy access to open source world. Maintainers of many projects open up for contributions, and it is a great chance to make your first step to joining this fantastic world.</p><p>AsyncAPI Initiative joins the Hacktoberfest for two main reasons:</p><ul><li>Promote AsyncAPI Initiative as a place where we don't work on the specification only but also build a lot of great tools</li><li>Make it much easier for the community to make the first contribution to one of the AsyncAPI repositories</li></ul><p>In the past, we were also there where you are now, shy and uncertain if we can impact open source community. We want to give you an easy path to take the first baby steps in the world of open source in a welcoming and friendly environment.</p><blockquote><p>Don't forget to <a href="https://hacktoberfest.digitalocean.com/login">sign up</a> to the Hacktoberfest</p></blockquote><p><iframe src="https://www.youtube.com/embed/_1WRr3Ml9t4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></p><h2 id="how-can-you-help">How Can You Help</h2><p>There is always a lot of work waiting out there. For the sake of this special event, we prepared around 75 GitHub issues that you can pick up. They represent different areas (for example, JavaScript or HTML), different difficulty (for example, 50 issues are easy), and different repositories. No matter if they are trivial or demanding, all of them are important for us. Even with trivial ones where you, for example, need to remove a semicolon, we will still be super happy because this will improve the quality of the project (SonarCloud reports). In other words, every single issue from <a href="https://docs.google.com/spreadsheets/d/1vX4J395apexutfQ0OSqPNltFKDacmemHZwCmOXwHNLo/edit?usp=sharing">this</a> list is important.</p><h3 id="1-pick-the-right-issue">1. Pick The Right Issue</h3><p><a href="https://docs.google.com/spreadsheets/d/1vX4J395apexutfQ0OSqPNltFKDacmemHZwCmOXwHNLo/edit?usp=sharing">Here</a> you can find a list of all the issues that you can work on. Most of the issues are about code contribution, but not all of them. There are also issues about documentation or CI/CD configuration (we use GitHub Actions). Just pick the issues you want to work on, one at a time, and let us know in the comments section that you want to work on it.</p><p><iframe src="https://www.youtube.com/embed/Iqs_2BiNEEo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></p><h3 id="2-setup-your-environment-and-create-a-first-pull-request">2. Setup Your Environment And Create A First Pull Request</h3><p>Once you <a href="https://git-scm.com/book/en/v2/Getting-Started-Installing-Git">install Git</a> on your machine and get a <a href="https://github.com/join">GitHub account</a>, you need first to decide if you are here just for Hacktoberfest or longer, and make sure if your issue is easy and maybe you can complete it in the GitHub UI. </p><p>In case you are here just for the Hacktoberfest, and you picked easy issues that involve changes only to a single file, there is no need to install Git and complicate your life. GitHub UI enables you to <a href="https://docs.github.com/en/free-pro-team@latest/github/managing-files-in-a-repository/editing-files-in-your-repository">make changes to a single file online</a>.</p><p>In case you:</p><ul><li>want to stay with us longer,</li><li>you picked up an issue where you need to make changes to more than just one file,</li><li>you also need to run the project locally to check if it works</li></ul><p>Then follow <a href="https://github.com/asyncapi/.github/blob/master/git-workflow.md">this</a> short instruction on how to fork the repository and set it up locally.</p><p>Once you are ready with your changes, submit a pull request. Be nice and follow our <a href="https://github.com/asyncapi/.github/blob/master/CODE_OF_CONDUCT.md">code of conduct</a> and make sure your pull request is <a href="https://github.com/asyncapi/.github/blob/master/CONTRIBUTING.md#conventional-commits">described properly</a>.</p><p><iframe src="https://www.youtube.com/embed/BsC5tu4M1rw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></p><h2 id="office-hours">Office Hours</h2><p>Do you feel overwhelmed? No need. You can do it. Just take this blog post seriously. </p><p>Trust me when I write that every pull request is crucial for us.
Trust me when I write that we are a welcoming community.
Don't be afraid that you will waste our time. If we would think about it this way, we would not even join the Hacktoberfest.</p><p>Still not sure if you can make it? Don't worry. We want to host office hours throughout the event, 2x a week, 1h long, and different time zones. You can join whenever you want and ask us anything, or do pair programming with us. We start with the first meeting on <a href="https://calendar.google.com/calendar/u/0?cid=dGJyYmZxNGRlNWJjbmd0OG9rdmV2NGxzdGtAZ3JvdXAuY2FsZW5kYXIuZ29vZ2xlLmNvbQ">Tuesday 6th, 8AM UTC</a> and then on the following days:</p><ul><li>Tuesday 6th, 8AM UTC</li><li>Thursday 8th, 4PM UTC</li><li>Tuesday 13th, 8AM UTC</li><li>Thursday 15th, 4PM UTC</li><li>Tuesday 20th, 8AM UTC</li><li>Thursday 22nd, 4PM UTC</li><li>Tuesday 27th, 8AM UTC</li><li>Thursday 29th, 4PM UTC</li></ul><p>You can also join us in a more asynchronous discussion on <a href="https://www.asyncapi.com/slack-invite/">Slack</a>. For updates and latest news, the best is to follow our <a href="https://twitter.com/AsyncAPISpec">Twitter account</a>. </p><h2 id="blooper-reel">Blooper Reel</h2><p>Before you jump to your first contribution, have a look at the making of the videos. It was quite fun.</p><p><iframe src="https://www.youtube.com/embed/anjcF2l0lGs" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></p><p>Enjoy the Hacktoberfest!</p></article></div>]]>
            </description>
            <link>https://www.asyncapi.com/blog/hacktoberfest-2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-24648373</guid>
            <pubDate>Thu, 01 Oct 2020 07:34:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MobX 6]]>
            </title>
            <description>
<![CDATA[
Score 139 | Comments 59 (<a href="https://news.ycombinator.com/item?id=24648363">thread link</a>) | @nikivi
<br/>
October 1, 2020 | https://michel.codes/blogs/mobx6 | <a href="https://web.archive.org/web/*/https://michel.codes/blogs/mobx6">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="___gatsby"><div tabindex="-1" role="group"><div><section><center><br><small>September 24, 2020</small></center><div><h2>Five years of MobX</h2>
<p>Time flies, and it has been 5.5 years since the first commit to MobX was made to build <a href="https://www.mendix.com/">Mendix Studio</a>.
In those years MobX has been adopted by well-known Software companies like Microsoft (Outlook), Netflix, Amazon and, my personal favorite, it runs in the Battlefield games by EA.
<a href="https://www.amazon.co.uk/MobX-Quick-Start-Guide-Supercharge/dp/1789344832/ref=sr_1_1?crid=BRUIHPUQL64D&amp;dchild=1&amp;keywords=mobx&amp;qid=1600809874&amp;s=books&amp;sprefix=mobx%2Caps%2C138&amp;sr=1-1">Books</a> and video courses have been written, and so have implementations in other languages.</p>
<p><span>
    <span></span>
    <img alt="Battlefield &amp; MobX" title="" src="https://michel.codes/static/5e0cc6842fdf39e4a7bf69a61fa15151/128ae/dice.jpg" srcset="https://michel.codes/static/5e0cc6842fdf39e4a7bf69a61fa15151/08cbc/dice.jpg 160w,
https://michel.codes/static/5e0cc6842fdf39e4a7bf69a61fa15151/37ac5/dice.jpg 320w,
https://michel.codes/static/5e0cc6842fdf39e4a7bf69a61fa15151/128ae/dice.jpg 640w,
https://michel.codes/static/5e0cc6842fdf39e4a7bf69a61fa15151/52793/dice.jpg 800w" sizes="(max-width: 640px) 100vw, 640px">
  </span></p>
<p>Yet, since that first commit the philosophy of the MobX hasn't changed: <em>Anything that can be derived from the application state, should be derived. Automatically.</em>.
The API hasn't changed too much since those days either,
and you will find the original <a href="https://www.mendix.com/blog/making-react-reactive-pursuit-high-performing-easily-maintainable-react-apps/">introduction of MobX</a> still pretty recognizable.
If <code>React.createClass</code> still rings a bell that is.</p>
<p>In contrast, the JavaScript eco-system has changed significantly over the years.
TypeScript and Babel have become the de-facto standards.
React went from <code>createClass</code> to classes to hook-based function components.
Yet, relevant JavaScript proposals for observables, Object.observe and decorators have never materialized.</p>
<p>MobX 6 is a new major version that doesn't bring many new features, but is rather a consolidation of MobX on the current state of affairs in JavaScript.
That doesn't come without a few plot twists, so if you are an existing MobX user, please read till the end!</p>
<h2>Bye bye decorators</h2>
<p>Let's start with the bad news: Using decorators is no longer the norm in MobX.
This is good news to some of you, but others will hate it.
Rightfully so, because I concur that the declarative syntax of decorators is still the best that can be offered.
When MobX started, it was a TypeScript only project, so decorators were available.
Still experimental, but obviously they were going to be standardized soon.
That was my expectation at least (I did mostly Java and C# before).
However, that moment still hasn't come yet, and two decorators proposals have been cancelled in the mean time.
Although they still can be transpiled.</p>
<p>So why did we stop using decorators by default?</p>
<p>First of all, the current experimental decorator implementations are incompatible with the soon-to-be-standardized class-fields proposal.
The legacy (Babel) and experimental (TypeScript) decorator implementations will no longer be able to <a href="https://github.com/tc39/proposal-class-fields/issues/151">trap class fields initializations</a>.</p>
<p>Secondly, using decorators has always been a serious hurdle in adopting and advocating MobX.
In Babel, it is quite fragile to set up.
<code>create-react-app</code> doesn't support it out of the box, and many developers rightfully don't like to use non-standard features.
Even though decorators have always been optional in MobX, the fact that they were prominent in the docs left many confused.
Or as one MobX fan <a href="https://github.com/mobxjs/mobx/issues/2325#issuecomment-693130586">puts it</a>:</p>
<p><em>I am guessing this choice [to drop decorators] was probably a good call. Maybe now without decorators I am hopeful I will be able to convey to people how amazing Mobx is and at least I won't hear the decorators excuse anymore. I have never seen an "@" sign scare so many people.</em></p>
<p>So, what does MobX after decorators look like?
Simply put, instead of decorating class members during the class definition, instance members need to be annotated in the constructor instead, using the new <code>makeObservable</code> utility:</p>
<div data-language="typescript"><pre><code><span>import</span> <span>{</span>observable<span>,</span> computed<span>,</span> action<span>,</span> makeObservable<span>}</span> <span>from</span> <span>"mobx"</span>


<span>class</span> <span>TodoStore</span> <span>{</span>
    @observable
    todos<span>:</span> Todo<span>[</span><span>]</span> <span>=</span> <span>[</span><span>]</span>

    @computed
    <span>get</span> <span>unfinishedTodoCount</span><span>(</span><span>)</span> <span>{</span>
        <span>return</span> <span>this</span><span>.</span>todos<span>.</span><span>filter</span><span>(</span>todo <span>=&gt;</span> <span>!</span>todo<span>.</span>done<span>)</span><span>.</span>length
    <span>}</span>

    @action
    <span>addTodo</span><span>(</span>todo<span>:</span> Todo<span>)</span> <span>{</span>
        <span>this</span><span>.</span>todos<span>.</span><span>push</span><span>(</span>todo<span>)</span>
    <span>}</span>
<span>}</span>


<span>class</span> <span>TodoStore</span> <span>{</span>
    todos<span>:</span> Todo<span>[</span><span>]</span> <span>=</span> <span>[</span><span>]</span>

    <span>constructor</span><span>(</span><span>)</span> <span>{</span>
        <span>makeObservable</span><span>(</span><span>this</span><span>,</span> <span>{</span>
            todos<span>:</span> observable<span>,</span>
            unfinishedTodoCount<span>:</span> computed<span>,</span>
            addTodo<span>:</span> action
        <span>}</span><span>)</span>
    <span>}</span>

    <span>get</span> <span>unfinishedTodoCount</span><span>(</span><span>)</span> <span>{</span>
        <span>return</span> <span>this</span><span>.</span>todos<span>.</span><span>filter</span><span>(</span>todo <span>=&gt;</span> <span>!</span>todo<span>.</span>done<span>)</span><span>.</span>length
    <span>}</span>

    <span>addTodo</span><span>(</span>todo<span>:</span> Todo<span>)</span> <span>{</span>
        <span>this</span><span>.</span>todos<span>.</span><span>push</span><span>(</span>todo<span>)</span>
    <span>}</span>
<span>}</span></code></pre></div>
<p>Admittedly, this is a slightly worse DX than before, since member and annotation are no longer co-located.
But the good news is that using <code>makeObservable</code> doesn't require any fancy build setup.
It should work everywhere out of the box.</p>
<p>Migrating an entire code-base from decorators to <code>makeObservable</code> might be challenging, so that is why we released a <a href="https://www.npmjs.com/package/mobx-undecorate">code-mod</a> together with MobX 6 to do that automatically!
Just run the command <code>npx mobx-undecorate</code> inside the folder where your source files live, and after that all decorators should have been magically rewritten!
After that, make sure to <a href="https://mobx.js.org/migrating-from-4-or-5.html#getting-started">update your TypeScript / babel config</a>, and you should be good to go!</p>
<h2>Introducing <code>makeAutoObservable</code></h2>
<p>We realize it is easier to make mistakes now that the annotations are no longer adjacent to the fields they are decorating.
Hence a convenience utility has been introduced that automates the annotation process by picking sane defaults: <code>makeAutoObservable</code>.
It will automatically pick the best annotation for every member of a class, thereby simplifying the above listing to:</p>
<div data-language="typescript"><pre><code><span>class</span> <span>TodoStore</span> <span>{</span>
    todos<span>:</span> Todo<span>[</span><span>]</span> <span>=</span> <span>[</span><span>]</span>

    <span>constructor</span><span>(</span><span>)</span> <span>{</span>
        <span>makeAutoObservable</span><span>(</span><span>this</span><span>)</span>
    <span>}</span>

    <span>get</span> <span>unfinishedTodoCount</span><span>(</span><span>)</span> <span>{</span>
        <span>return</span> <span>this</span><span>.</span>todos<span>.</span><span>filter</span><span>(</span>todo <span>=&gt;</span> <span>!</span>todo<span>.</span>done<span>)</span><span>.</span>length
    <span>}</span>

    <span>addTodo</span><span>(</span>todo<span>:</span> Todo<span>)</span> <span>{</span>
        <span>this</span><span>.</span>todos<span>.</span><span>push</span><span>(</span>todo<span>)</span>
    <span>}</span>
<span>}</span></code></pre></div>
<p>Note that it is possible to pass a map of <em>overrides</em> as second argument, in case you want to use a modifier.
For example: <code>makeAutoObservable(this, { todos: observable.shallow })</code>.
Pass <code>member: false</code> to have MobX ignore that member entirely.
(Technical fineprint: class methods will not be decorated with <code>action</code>, but with the new <code>autoAction</code>, this annotation will make methods suitable to be used both as a state updating action, or as function that derives information from state).</p>
<p>What I personally like about <code>makeAutoObservable</code> is that it plays really nice with factory functions.
Which is great if you prefer to not use classes (factory functions make it is easy to hide members and prevent issues with <code>this</code> and <code>new</code>. And they compose more easily).
The same store expressed as factory function will look as follows. Pick the style that suits you:</p>
<div data-language="typescript"><pre><code><span>function</span> <span>createTodoStore</span><span>(</span><span>)</span> <span>{</span>
    <span>const</span> store <span>=</span> <span>makeAutoObservable</span><span>(</span><span>{</span>
        todos<span>:</span> <span>[</span><span>]</span> <span>as</span> Todo<span>[</span><span>]</span><span>,</span>
        <span>get</span> <span>unfinishedTodoCount</span><span>(</span><span>)</span> <span>{</span>
            <span>return</span> store<span>.</span>todos<span>.</span><span>filter</span><span>(</span>todo <span>=&gt;</span> <span>!</span>todo<span>.</span>done<span>)</span><span>.</span>length
        <span>}</span><span>,</span>
        <span>addTodo</span><span>(</span>todo<span>:</span> Todo<span>)</span> <span>{</span>
            store<span>.</span>todos<span>.</span><span>push</span><span>(</span>todo<span>)</span>
        <span>}</span>
    <span>}</span><span>)</span>
    <span>return</span> store
<span>}</span></code></pre></div>
<h2>Fresh docs!</h2>
<p>Since decorators are no longer the norm, <a href="https://twitter.com/faassen">Martijn Faassen</a>, <a href="https://twitter.com/zangornjak">Žan Gornjak</a> and yours truly went over all the documentation.
We updated all examples and significantly restructured the docs that have grown quite organically over the years.
We feel the current docs are shorter, have less repetition, and better discuss common scenarios.
Also, we marked all non-essential knowledge in the docs with a {🚀} rocket emoji, to make it clear which knowledge is optional.
Hopefully it is much quicker now to find your way around in MobX!</p>
<p>On a similar note, we've updated all <a href="https://mobx.js.org/react-integration.html">React related documentation</a> to use function components instead of class components. And added documentation on how to use MobX with hooks, context and effects.
This knowledge existed before (little has changed technically), but was scattered all over the place.
As a result, we now recommend <code>mobx-react-lite</code> over <code>mobx-react</code> for (greenfield) projects that don't use class components.
As a result the separate mobx-react.js.org/ website has been deprecated.
All credits go to <a href="https://twitter.com/danielk_cz">Daniel K</a> for maintaining those two projects!</p>
<p>And finally, there is now a <a href="https://gum.co/fSocU">one pager MobX 6 cheat sheet 👨‍🎓</a> covering all the import mobx / mobx-react(-lite) API's.
(It is a great way to one-time sponser the project in an invoicable way).</p>
<h2>Improved browser support</h2>
<p>A probably little surprising improvement in MobX 6 is that it supports <em>more</em> JavaScript engines than MobX 5.
MobX 5 required proxy support, making MobX unsuitable for Internet Explorer or React Native (depending on the engine).
For this reason MobX 4 was still actively maintained.
However, MobX 6 replaces both at once.</p>
<p>By default MobX 6 will still require Proxies, but it is possible to opt-out from Proxy usage in case you need to support older engines.
And, as a result, it is now possible for MobX 6 to warn in development mode when features that would require proxies are used.
See the documentation for more <a href="https://mobx.js.org/configuration.html#proxy-support">details</a>.</p>
<div data-language="typescript"><pre><code><span>import</span> <span>{</span> configure <span>}</span> <span>from</span> <span>"mobx"</span>

<span>configure</span><span>(</span><span>{</span>
    
    
    
    useProxies<span>:</span> <span>"never"</span>
<span>}</span><span>)</span></code></pre></div>
<h2>Decorators are back!</h2>
<p>Ok, time for the plot twist. MobX 6 stills supports decorators!
The decorator implementation in MobX 6 is entirely different from the one in earlier versions, but does work with the current implementations in TypeScript and Babel.
It basically provides an alternative way to construct the annotations map for <code>makeObservable</code>, and allows us to rewrite the first example as:</p>
<div data-language="typescript"><pre><code><span>class</span> <span>TodoStore</span> <span>{</span>
    @observable
    todos<span>:</span> Todo<span>[</span><span>]</span> <span>=</span> <span>[</span><span>]</span>

    <span>constructor</span><span>(</span><span>)</span> <span>{</span>
        <span>makeObservable</span><span>(</span><span>this</span><span>)</span>
    <span>}</span>

    @computed
    <span>get</span> <span>unfinishedTodoCount</span><span>(</span><span>)</span> <span>{</span>
        <span>return</span> <span>this</span><span>.</span>todos<span>.</span><span>filter</span><span>(</span>todo <span>=&gt;</span> <span>!</span>todo<span>.</span>done<span>)</span><span>.</span>length
    <span>}</span>

    @action
    <span>addTodo</span><span>(</span>todo<span>:</span> Todo<span>)</span> <span>{</span>
        <span>this</span><span>.</span>todos<span>.</span><span>push</span><span>(</span>todo<span>)</span>
    <span>}</span>
<span>}</span></code></pre></div>
<p>Note that we still need to add a constructor to the class, but this time we omit the second argument to <code>makeObservable</code>, so that it will rely on the decorators instead.
We don't recommend this set up for greenfield projects, after all decorators are still experimental, but this is a great compromise for
existing code bases.
Generating constructors without removing decorators is supported by <code>mobx-undecorate</code> as well, and can be achieved by running <code>npx mobx-undecorate --keepDecorators</code>.</p>
<p>And here is even more good news: There is a fresh <a href="https://github.com/tc39/proposal-decorators">decorators proposal</a> being championed by the tireless hero <a href="https://twitter.com/littledan">Daniel Ehrenberg</a>.
I've been a bit involved in it, and the MobX use case has inspired the proposal.
So the benefits of the fresh decorator implementation are that it a) solves the compatibility issue with the class fields spec discussed above, and
b) it also paves the way …</p></div></section></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://michel.codes/blogs/mobx6">https://michel.codes/blogs/mobx6</a></em></p>]]>
            </description>
            <link>https://michel.codes/blogs/mobx6</link>
            <guid isPermaLink="false">hacker-news-small-sites-24648363</guid>
            <pubDate>Thu, 01 Oct 2020 07:33:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Worst Decision of My Career]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 15 (<a href="https://news.ycombinator.com/item?id=24648256">thread link</a>) | @fribmendes
<br/>
October 1, 2020 | https://subvisual.com/blog/posts/the-worst-decision-of-my-career/ | <a href="https://web.archive.org/web/*/https://subvisual.com/blog/posts/the-worst-decision-of-my-career/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><article><section><div><div><div><div><div><div>
<p>This is a reflection on software development and complexity. Let's start with
some quotes to make me look smart:</p>
<blockquote>
<p>A complex system that works is invariably found to have evolved from a simple
system that worked. A complex system designed from scratch never works and
cannot be patched up to make it work. You have to start over with a working
simple system -- <em>Gall's law</em></p>
</blockquote>
<p>I only came across this quote recently, but I think that it summarizes what
I've learned these past seven years. Another idea that I've found in a few books
is that programming in isolation is problem-solving, but software engineering
is all about managing complexity. This distinction between programming and
software engineering makes sense to me, probably because of my mental models.
I'm sure we can all disagree on this, but that's not the topic of today.
Complexity is.</p>
<h2>Complexity</h2>
<p>Almost everyone I know in the software industry wants to build products that
solve real and challenging problems. Change the world! The last thing you want
is to build another CRUD application. They are fine, but it gets boring after
a while.</p>
<p>Most of us will get bored without novelty. That's why the software industry has
a recycling mechanism to keep things fresh and interesting for us: every once
in a while a new, or different, language/framework will rise and light the path
for a brighter future, overthrowing the existing standard, demanding that we
learn it to be on top of the game.</p>
<p>We change our tools, but we keep building the same things over and over. I've
been doing this long enough to see that we are just going in circles. Let's be
honest, most of us aren't building life-changing products that wouldn't have
been possible ten years ago, so let's not jump straight into another shiny
technology that just came out and is going to solve all of our problems.</p>
<h2>Solutions, solutions, solutions</h2>
<blockquote>
<p>For a while, the solution to every problem I encountered was a Rails app. --
<em>this one is mine</em></p>
</blockquote>
<p>Over the years, I've seen companies rewrite their products to change languages,
frameworks, or architectures because they were told that the change would make
their product better, run faster, and scale. By the way, you're only a true
Ruby developer after you've heard the question "but does it scale?" at least
one hundred times (kidding, but it'll happen).</p>
<p>Think about it, how many times were you sold a new programming language,
technology, or a concept like microservices, serverless, event sourcing, clean
architecture, micro frontends. There are many preachers in the software world.</p>
<p>At Subvisual, we started using Elixir a lot these past years, so I've learned
a bit about the history of Erlang. If you don't know, Erlang uses the Actor
Model, and the interesting part is that the designers of Erlang only learned
about the Actor Model after having designed Erlang. This is important because
the designers of Erlang didn't start with the intent of applying the Actor
Model; it came as a solution to fault-tolerant distributed programming.</p>
<blockquote>
<p>If all you have is a hammer, everything looks like a nail <em>Abraham Maslow</em></p>
</blockquote>
<p>The designers of Erlang picked the right tool for the job and most of us want
to do the same. Unfortunately, there's usually more than one "tool" that would
be "right," but to know which ones, you need to know what "job" you're solving.
All of us <strong>should</strong> know this, but I keep learning about teams that fail to do
it. There are so many companies, with a handful of experienced developers, that
don't know what they are building, don't have a clear business yet, but their
product is already built on complex architectures and technologies such as
microservices, Kubernetes or event-sourcing.</p>
<h2>Improving</h2>
<p>Every project we start from scratch is an opportunity to do it right. We'll
think to ourselves: <em>This time I won't fall into the same traps! I have learned
my lessons, I've studied the books, and I even met some of my gurus that wrote
them! This time I'll follow "industry standards"!</em></p>
<p><em>I am the "architect"; I will design the perfect system! Without me, none of
this will be possible. Those mindless programmers have no idea what they are
doing. I, and only I, am the true heir of Martin Fowler!</em></p>
<p>This was a bit dramatic, but I needed a break from all of that whining. I know
it's easy to fall into these traps. It's even easier when your company raised
money, and everyone is expecting you to deliver the absolute best product ever
because they are paying you for it! This is why your starting team is so
important; they have to withstand the pressure. They must know that to build
the grand vision, they have to go one step at a time.</p>
<h2>The decision</h2>
<p>I've made many bad decisions, and I've been fortunate enough to suffer the
consequences of those decisions. A lot of developers don't get to experience
consequences, so they never learn.</p>
<p>So what was the worst decision of my career? I don't know. But the title of
this blog post is inspired by something an old colleague said. At the time, we
were working for a product company that reached for event-driven architecture
and event-sourcing too soon. They knew little about their market, and the
choices the software team made were crippling their ability to change. Business
rules were almost set in stone. Migrating data was a pain and the source of
many bugs. And unfortunately, because the team didn't have experience with
event-sourcing, the event store, which kept the state of all services, was also
being used as an event-bus to communicate between services. Because of that, it
was possible to couple one service to the internal state of another, which
happened a lot. This almost invisible coupling made everything worse.</p>
<p>What did we do against such an unpredictable system? We took it apart: merging
services that were too coupled; defining clear boundaries between services;
moving some services away from the event-store into a traditional database;
making some communication channels synchronous; writing integration and
end-to-end tests.</p>
<p>When we were finished it was still an unnecessarily complex system, but it was
one that we could change with some confidence. After that, we defined
a long-term plan for the product's architecture and technology, but we didn't
implement it. We waited for the right moment when something was starting to
slow us down to make a small step in that direction. When the business goals
changed, we changed our long-term plan, and once again made small steps in that
direction when we felt the need for it.</p>
<p>Eventually, complexity found its way again into the codebase, but it was fine
because the codebase was evolving slowing, adding and removing complexity when
necessary.</p>
<h2>Making the right call</h2>
<p>Was that the worst decision of his career? I don't think so. The issue with him
going for event-sourcing and event-driven architecture was that it wasn't the
right moment, but my colleague didn't know that. He thought the goals for the
next years were well defined, but unfortunately, they never are.</p>
<p>Should you use microservices or event-sourcing? Maybe, it depends on the
context and the client. The decisions I make are the best that I can with the
information that I have. For instance, when I'm part of the team that's
starting a product, the technology we pick will depend on how we'll hire: if
you want to build an office in Portugal, we have to make sure we have
developers for that technology available. We have to think things through, and
some things you only learn from experience. This applies to the systems we
design as well. I've seen enough people design around what they believe the
product will become in two years to know that those designs always fail to
accommodate the changes that will come. So we design systems for small,
incremental changes. Do the smallest thing that will get us started and
doesn't compromise our ability to change once we know what the business needs.</p></div></div></div></div></div></div></section></article></div></div></div>]]>
            </description>
            <link>https://subvisual.com/blog/posts/the-worst-decision-of-my-career/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24648256</guid>
            <pubDate>Thu, 01 Oct 2020 07:18:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Minimum Elucidating Examples]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24648046">thread link</a>) | @Topolomancer
<br/>
September 30, 2020 | https://bastian.rieck.me/blog/posts/2020/elucidating_examples/ | <a href="https://web.archive.org/web/*/https://bastian.rieck.me/blog/posts/2020/elucidating_examples/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>I tend to learn new concepts best by seeing an <em>example</em> of them. This
dates back to when I first started studying mathematics: I felt that I
was able to actually <em>work</em> with a certain definition once I had at
least an intuitive grasp of what is meant. I quickly discovered that
there are at least three kinds of examples. The first kind is trivial,
leading to even more confusion, the second kind is too complex, and the
third kind is actually elucidating. It is the third kind of example that
I am primarily interested in here, so let’s quickly discuss the other
two and move on.</p>
<p>Examples of the first kind are trivial. Suppose you want to illustrate
the concept of addition and state that $1 + 0 = 1$. This is obviously
correct but does not teach you anything because it contains the idea
that $a + 0 = a$ as a <em>confounding property</em>. Likewise, mentioning the
empty set $\emptyset$ as an example of a certain kind of structure is
always good for some laughs,<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> but it does not really help you
understand what is going on.</p>
<p>Examples of the second kind are not more helpful. They are characterised
by a rapid increase in complexity that just bogs you down without really
helping you gain intuition or understanding. <a href="https://abstrusegoose.com/474">This Abstruse Goose comic</a>
provides a marvellous instance.<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> Other examples include, say, teaching
you about <a href="https://en.wikipedia.org/wiki/Determinant">determinants</a> by
letting you invert a $10 \times 10$ matrix, when a smaller dimension
would have been sufficient.</p>
<p>Examples of the third kind help you grow and understand. I call these
examples <em>minimum elucidating examples</em>: they have <em>just</em> the right
amount of complexity to not be wholly trivial, but they are simple
enough to be remembered and understood correctly. For instance, when
learning about group theory, some elucidating examples are the additive
group over the integers, $\mathbb{Z}/2\mathbb{Z}$&nbsp;(the group with
only two elements), or, to be a little bit more complex, the general
linear group of all real invertible matrices. The utility of such an
elucidating example depends heavily on the context—as a student,
I preferred learning about the ‘number groups’ first, but nowadays, my preferred
go-to example is the general linear group, because it is more
abstract and provides a better glimpse into the power of group theory.</p>
<p>Closely related to such elucidating examples are elucidating
<em>non-examples</em>&nbsp;(or counterexamples). In group theory, the natural
numbers $\mathbb{N}$ come to mind: lacking an additive
inverse for every element except $0$, every student can easily grasp
that the additional requirements raise the bar for something to be
called a group, while at the same time illustrating that a much richer
structure is exposed by demanding these properties.</p>
<p>Of particular pedagogical interest are examples that <em>defy</em> our
presuppositions. These are counterexamples to our misplaced intuitions!
For instance, the <a href="https://en.wikipedia.org/wiki/Cantor_set">Cantor set</a>
is a marvellous counterexample in measure theory:<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup> typically,
students only encounter sets with measure zero that are <em>countable</em>.
This can lead to the wrong impression that ‘measure zero’ and
‘countable’ are somewhat equivalent. The Cantor set destroys this
illusion, as it constitutes a set that is <em>uncountable</em> while having
measure zero! My mind was shattered when I first learned about this, and
since then, the Cantor set has been a cherished counterexample in my
toolbox.</p>
<p>Having switched academic fields for a while now, I sometimes wonder what
minimum elucidating examples <em>we</em> should develop for machine
learning&nbsp;(ML).  What is the smallest useful architecture and data set that demonstrates
issues such as <a href="https://en.wikipedia.org/wiki/Vanishing_gradient_problem">vanishing gradients</a>?
Is there a way to store and disseminate such counterexamples? Would the
aspiring ML researcher find them useful and digest them, or are we still
in the ‘pragmatic phase’ of our field and use whatever works, without
caring too much about the theoretical underpinnings? Time will
tell—and I for one hope to collect as many juicy minimum elucidating
(counter)examples as I possibly can.</p>
<p>Until next time, have fun being exemplary!</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>Full disclosure: as a cheeky undergraduate, I did this a few times
in oral exams. It is funny but probably less so for the professors who
have to endure that sort of humour all day long. <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>I disagree with the comic on one thing, though: maths textbooks
tend to follow this recipe more often than computer science textbooks,
in my experience. <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>Measure theory deals with <em>measuring</em> subsets of Euclidean space,
assigning them a number that describes their ‘size’; think of a generalisation of
the concepts of <em>area</em> or <em>volume</em>. Measure theory is often invoked
when dealing with problematic solutions or inputs to
functions—essentially, one tries to show that while such degenerate
inputs may exist, they are ‘too small’&nbsp;(in the sense of measure
theory) to worry about. <a href="#fnref:3" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>

      </div></div>]]>
            </description>
            <link>https://bastian.rieck.me/blog/posts/2020/elucidating_examples/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24648046</guid>
            <pubDate>Thu, 01 Oct 2020 06:43:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Before You Start Coding]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24647918">thread link</a>) | @dinomad
<br/>
September 30, 2020 | https://scorpil.com/post/before-you-start-coding/ | <a href="https://web.archive.org/web/*/https://scorpil.com/post/before-you-start-coding/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper"><div id="container"><div><article itemscope="" itemtype="http://schema.org/BlogPosting"><div itemprop="articleBody"><p>Full disclosure: things discussed in this post are, to be frank, quite obvious. My intent is not so much to teach a reader something new, as to remind him what might have been forgotten. After all, anyone who does a single kind of work daily for years inevitably develops habits and mental-shortcuts that are <em>usually</em> useful but can misfire from time to time. After all, software development is too complex and too technical to be guided by subconscious intuition.</p><p>Pilots use pre-flight checks to combat this kind of problem, so why not developers? Here’s a check-list of things I find important to consider <strong>before</strong> writing the first line of code.</p><h3 id="set-your-target-straight">Set your target straight</h3><p>Imagine yourself solving these tasks:</p><ul><li>generating a single-use report for an established company</li><li>writing a feature in proof-of-concept MVP for a startup</li><li>extending at enterprise product that has 20 years of codebase support guarantee in its SLAs</li></ul><p>Clearly, it wouldn’t be smart to blindly apply the same set of software development best-practices for all three cases. You probably don’t need a perfectly polished code for a single-use report. A startup that operates in the “rush to market before we run out of money" mode is much more worried about the feature working than about its performance. Long-support code needs to be first and foremost maintainable. Also, if you’re working on a pet-project for fun, you might gasp skip writing tests (unless you enjoy writing tests, in which case I envy you a little bit). Some developers take so much pride in their craft that they lose sight of the forest behind the trees. Following all best practices and writing state-of-the-art code <em>feels</em> right, but logically it’s not the only option. Sometimes you should consciously generate technical debt. Reality constraints are not something that can be ignored.</p><p>As self-evident as this advice is, we’ve all heard stories where things went wrong because of misaligned goals. “Premature optimization” is a common special case. Refactoring an old codebase that rarely changes, just so it’s pretty, is another one. And to not leave you with the thought that goal misalignment is always linked to perfectionism: writing an unsupportable code to meet a <em>fictional</em> deadline, either self-imposed or forced on to developers by impatient management, is the same kind of error.</p><p>You need to know where to go before you can start thinking about how to get there. Think of the most important criteria your solution needs to fulfill and align your decision-making with those.</p><h3 id="consider-alternatives">Consider alternatives</h3><p>You’ve got the task in front of you, requirements are pretty clear, and you vaguely remember how you did something similar a few years before. Or maybe you don’t know how to solve it at first, but after some googling, you get a general idea. Start coding?</p><p>There are always multiple ways to solve a problem. The first viable solution is unlikely to be an optimal one. By focusing on the first approach discovered you rob yourself of choice. Do a thorough research first, and after you have options in front of you, carefully consider the pros and cons of each. There is no magical number of solutions you need. I often set the minimum bound to three for myself.</p><p>Selecting the right tool for a job is an obvious example of a decision that benefits from upfront research, and even then, in a real-world scenario, a tool that’s familiar often gets selected over the tool that fits. Don’t think this advice only applies to „macro“ decisions, it can be applied just as well for your everyday code design choices.</p><h3 id="consult-the-docs-yes-upfront">Consult the docs. Yes, upfront</h3><p>It’s impossible to keep up with the pace modern tech is moving. Doesn’t matter how many years of experience you have under your belt, when you pick up the project on a modern stack there will be tools and libraries, released recently, that have slipped under your radar. So most developers are in a constant in-flight-learning mode: picking up knowledge as they search answers on immediate questions. It’s an efficient way to learn, but it creates a risk of missing an easy solution because of the inability to form the right question.</p><p>Skimming the docs upfront, without digging deep into any particular topic, doesn’t take much time, but it helps create mental anchors, which your brain will fetch when you encounter the problem. You will have a better starting point for finding the right answer quickly.</p><h3 id="design-your-apis">Design your APIs</h3><p>The hardest part of writing code is to imagine in the minutest details how to handle each workflow, each exceptional situation, and each edge case. Many developers first solve a problem, then write a „wrapper“ to expose their work to the outside world through some kind of API (i don’t mean just REST API, function signatures and interfaces are APIs as well). Often this bottom-up design leads to an API that’s too „technical“, i.e. leaking it’s abstractions to the consumer. It’s hard to make your brain switch from one level of abstraction to another.</p><p>Before starting the work on implementation, put yourself in the shoes of the API user first (even if that user is you). What would be the user’s most common usage pattern? What’s the absolute minimal required set of parameters the API needs to have? Which terminology makes sense for the user? What input format would be most convenient? What defaults to set? It’s up to you how thorough you want this process to be.</p><h3 id="split-up-the-work">Split up the work</h3><p>Each entity in a system exponentially increases the number of possible interactions. Code that’s easy to reason about forms a pyramid of abstraction layers, each one hiding its inner workings from the layer above. Each layer can be reasoned about independently, limiting the amount of „moving parts“ you need to keep track of in your brain. If you succeed in splitting the task into multiple loosely coupled entities upfront, you will simplify your code and work process.</p><p>If the task at hand is large enough, it might make sense to form a tree-like task structure, starting from the highest level of abstraction and moving down the layers until the tasks are small enough. The „small enough“ parameter depends on your particular codebase, mindset, and type of work you do, but after a bit of practice, you’ll find what granularity suits you the best.</p><p>Each task should be fairly self-sufficient and ideally shouldn’t stay in “kinda-finished” state for long (“finished but not deployed”, “finished but not reviewed”, “finished but not tested” or “finished but waiting for authorization from XYZ department”). Finished is when you don’t think about it anymore and it doesn’t drain your mental resources.</p><p><img src="https://scorpil.com/img/tree.png" alt="Example of a task tree"></p><p>Do you have your own tips and tricks for organizing developer’s work? Please share!</p></div></article></div></div></div></div>]]>
            </description>
            <link>https://scorpil.com/post/before-you-start-coding/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24647918</guid>
            <pubDate>Thu, 01 Oct 2020 06:20:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You're Allowed to Write Slow Rust Code]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 54 (<a href="https://news.ycombinator.com/item?id=24647910">thread link</a>) | @ingve
<br/>
September 30, 2020 | https://blog.jonstodle.com/youre-allowed-to-write-slow-rust-code/ | <a href="https://web.archive.org/web/*/https://blog.jonstodle.com/youre-allowed-to-write-slow-rust-code/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="blog-post">
    
    
    <article>
        <p>There's a thing that comes up from time to time in the Rust community: people wanting to optimize their code. Make the code run faster. Make it allocate less memory. These are worthy goals, but maybe not necessary for all projects. Just because your program is written in Rust, it doesn't have to be optimized to the moon and back to do it's job. In a lot of cases, you'll be fine using <code>.clone()</code>.</p>
<p>There's a fantastic quote from a discussion on the <a href="https://users.rust-lang.org/">Rust user forums</a> which I always think of when these discussions emerge:</p>
<blockquote>
<p>Just because Rust allows you to write super cool non-allocating zero-copy algorithms safely, doesn't mean every algorithm you write should be super cool, zero-copy and non-allocating.<br>
-- <a href="https://users.rust-lang.org/t/feeling-rust-is-so-difficult/29962/15">trentj on The Rust Programming Language Forum</a></p>
</blockquote>
<p>Of course there's a time and place for <em>super cool no-allocating zero-copy algorithms</em>, but very often it's not the time, nor the place. You can write fantastically effective code with Rust, but <strong>you don't have to</strong>! A lot of the time it's entirely fine to just write code that works with minimal effort. You don't have to spend 4 days trying to figure out how lifetimes work just to avoid calling <code>.clone()</code> a few times.</p>
<p>Don't spend time trying to make micro optimizations now. Take the easy route. You'll probably come back to that piece of code in a few months time, smile, and change that <code>.clone()</code> to something more efficient.</p>
<p>Happy coding!</p>
<p><small>NB: Watch this <a href="https://youtu.be/rAl-9HwD858">video by Jon Gjengset</a> if you want a good, pragmatic walk through of lifetimes in Rust.</small></p>

    </article>
</div></div>]]>
            </description>
            <link>https://blog.jonstodle.com/youre-allowed-to-write-slow-rust-code/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24647910</guid>
            <pubDate>Thu, 01 Oct 2020 06:19:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Designed IOS14 Icons to to fight the screen time, clutter and visual fatigue]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24647737">thread link</a>) | @hren
<br/>
September 30, 2020 | https://hren.io/products/iso14-home-screen-icons-set/ | <a href="https://web.archive.org/web/*/https://hren.io/products/iso14-home-screen-icons-set/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>As IOS14 allows the customization of the home screen with the Shortcuts app, this icon set tries to fight the screen time, clutter and fatigue by minimizing visuals.</p><p>The goal is to also lover the Screen Time by only limited to one screen.</p><p>More icons will be added. For icon requests DM on<!-- --> <a href="https://twitter.com/@darjanhren" target="_blank">Twitter</a>.</p><p><a href="https://gum.co/wIROw" target="_blank">Get Calm Icon Set</a></p></div></div></div>]]>
            </description>
            <link>https://hren.io/products/iso14-home-screen-icons-set/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24647737</guid>
            <pubDate>Thu, 01 Oct 2020 05:44:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Running GitHub Actions for Certain Commit Messages]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 29 (<a href="https://news.ycombinator.com/item?id=24647722">thread link</a>) | @kiyanwang
<br/>
September 30, 2020 | https://ryangjchandler.co.uk/articles/running-github-actions-for-certain-commit-messages | <a href="https://web.archive.org/web/*/https://ryangjchandler.co.uk/articles/running-github-actions-for-certain-commit-messages">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
            
                <section>
        
        <p>A quick look at how you can configure your GitHub Actions workflows to only run when a certain phrase is present in the commit message.</p>
                    <small>Published 4 days ago</small>
                            <span>|</span>
                <small>Updated 4 days ago</small>
                                                <p><span>
    Tooling
</span>
 
                                     <span>
    GitHub Actions
</span>
 
                            </p>
                        <article>
            <p>I'm going to be honest with you all for a second. I write a lot of <code>wip</code> commits. These commits are normally small changes that I want to push up to GitHub so that:</p>
<ol>
<li>I don't lose things if anything goes wrong and my backup hasn't picked it up.</li>
<li>If I can't describe the change I have just made.</li>
<li>If I'm demonstrating something to somebody on a pull-request.</li>
</ol>
<p>The problem is, my actions are setup to run on <code>push</code>, so every single <code>wip</code> commit gets run through the CI process, whether it be running tests, linting or formatting.</p>
<p>After doing some research, I found a way of preventing these from running on every single commit.</p>
<pre><code data-lang="yml"><span>jobs:</span>
  <span>format:</span>
    <span>runs-on:</span> <span>ubuntu-latest</span>
    <span>if:</span> <span>"! contains(github.event.head_commit.message, 'wip')"</span>
</code></pre>
<p>Now, whenever I push a <code>wip</code> commit or any commit that contains the word <code>wip</code>, it will be marked as skipped inside of GitHub actions.</p>
<p>You could also flip the logic and perhaps do something like:</p>
<pre><code data-lang="yml"><span>jobs:</span>
  <span>format:</span>
    <span>runs-on:</span> <span>ubuntu-latest</span>
    <span>if:</span> <span>"contains(github.event.head_commit.message, '[build]')"</span>
</code></pre>
<p>Any commit that contains <code>[build]</code> will now trigger these jobs, everything else will be skipped.</p>
<p>You can thank me later! 😉</p>

        </article>
    </section>
        </div>
    </div></div>]]>
            </description>
            <link>https://ryangjchandler.co.uk/articles/running-github-actions-for-certain-commit-messages</link>
            <guid isPermaLink="false">hacker-news-small-sites-24647722</guid>
            <pubDate>Thu, 01 Oct 2020 05:41:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Faster Literal String Matching in Go]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24647210">thread link</a>) | @boyter
<br/>
September 30, 2020 | https://boyter.org/posts/faster-literal-string-matching-in-go/ | <a href="https://web.archive.org/web/*/https://boyter.org/posts/faster-literal-string-matching-in-go/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><strong>TL/DR:</strong> I wrote a fast literal string matching library in Go get it here <a href="https://github.com/boyter/go-string/">https://github.com/boyter/go-string/</a></p>
<p>Recently I rebuilt <a href="https://searchcode.com/">searchcode</a> in Go, as <a href="https://boyter.org/posts/searchcode-rebuilt-with-go/">mentioned</a>.</p>
<p>While there was a variety of reasons for this one was that performance in the previous Python version was not great. Please note this was mostly due to my own shortcomings and not the language itself. However I have always used searchcode as a test bed for interesting problems, since it gets enough traffic to verify things at scale, and I wanted to get better at Go.</p>
<p>One of the main performance hotspots in searchcode has always been finding lines to display based on the search query and then highlighting them. While most search index tools can do this for you, I have always done this myself, because I want to control whats displayed as I find it an interesting problem to solve.</p>
<p>It sounds simple, for some search terms “sally sea shell” find all the locations of inside a string “Sally sells sea shells by the sea shore” and then wrap them in a tag. This seems to be a trivial, since all you need a <code>indexOf</code> in a loop and some string splitting and insertion.</p>
<p>I had previously written about some of the issues with the above when writing about <a href="https://boyter.org/posts/unicode-support-what-does-that-actually-mean/">unicode support</a> with the relevant portion below,</p>
<blockquote>
<p>At which point you go, fine i’ll just search for all case variants of Java and use that to work things out, and then realise adding case folding is a small addition to what you just wrote and working with just bytes to save time was a red-herring.</p>
</blockquote>
<p>The generally always correct answer to case insensitive matching is to use Regular Expressions. However there can be issues with it. Firstly the regular expression engine in Go is slower than you think, and for matching string literals its a very large hammer for a smallish nail.</p>
<p>So I wrote my own implementation which does the same thing but without touching the regular expression engine <a href="https://github.com/boyter/go-string/">https://github.com/boyter/go-string/</a> thus making it much faster than using FindAllIndex for the majority of cases.</p>
<p>Talk is cheap… show me the benchmarks. Included below is the output from a small application I wrote. A small program which you supply a search string and a filename. I have tested it against a 550MB file. First it runs case insensitive search using FindAllIndex in the regex package, then against IndexAllIgnoreCase my own implementation. The number on the end of each line is the number of matches found.</p>
<pre><code>$ ./csperf ſecret 550MB
File length 576683100

FindAllIndex (regex ignore case)
Scan took 25.403231773s 16680
Scan took 25.39742299s 16680
Scan took 25.227218738s 16680

IndexAllIgnoreCase (custom)
Scan took 2.04013314s 16680
Scan took 2.019360935s 16680
Scan took 1.996732171s 16680
</code></pre><p>Note using the long s, <code>ſ</code> in the search term so both solutions are unicode aware!</p>
<p>The results speak for themselves. The case insensitive search is considerably faster. For pure literal case insensitive searches based on wall clock time it can be 10 times faster. I also added an implementation of <code>IndexAll</code> for case sensitive matches saving you from having to do your own logic there or again falling back to regular expressions, although its speedup will depend on your needle and haystack.</p>
<p>If you are curious about I did this read on. Otherwise feel free to just suck down the library and use it. It’s published under either MIT or The Unlicense so be as liberated as I can make it. There is also some other useful functions in there such as the highlight function which I am not going to discuss here.</p>
<p><strong>So how does it work?</strong></p>
<p>The code itself is reasonably <a href="https://github.com/boyter/go-string/blob/master/index.go#L98">well commented</a> so you may want to just read the code.</p>
<p>In short it copies some techniques from tools like ripgrep.</p>
<p>When looking at string matching algorithms, you run into algorithms such as Boyer-Moore, Aho-Corasick and Rabin-Carp. It may then surprise you to learn that Go’s implementation of strings.Index does not use them, well at least not till the needle is over 64 characters when 64 bit compiled where it starts to use Rabin-Carp, presumably as a CPU cache line optimisation.</p>
<p>What strings.Index actually does a simple loop through each byte checking for a match, and then when one is found starts checking against the needle. This means it does not do any byte skipping which Boyer-Moore does! Naturally, I was appalled by this and looked for a Boyer-Moore implementation to swap it out for. Turns out there is one inside the Go codebase which made me very curious. Why was it not used? Well after trying a few implementations each turned out to be much slower than the simple one Go uses. As it turns out, that implementation compiles down to fancy vector instructions on modern CPU’s. It’s pretty hard to beat silicon with algorithms, unless you algorithm happens to be massively more efficient so there was no trivial gains to be made there with a fancy algorithm.</p>
<p>So what actually happens in the code is that it takes the needle, and uses the first 3 characters (if over 3 characters long) to create a string of every possible case. So <code>foo</code> would return the following strings <code>foo Foo fOo FOo foO FoO fOO FOO</code>. It then searches using each one of those cases and collecting all the resulting matching locations. For strings over 3 characters (note characters, not bytes so it is unicode aware for simple case fold rules), as mentioned the first 3 characters are used, and then when a possible match is found the rest of the characters are checked to see if there is actually a match before recording the location.</p>
<p>In theory Aho-Corasick would be faster than the above as you could use maybe the first 4 characters and use that for matching each byte, however I was not going for extreme performance, but something much faster than regular expressions. Also its reasonably simple to follow, while leveraging the Go SDK which is a massive win in my opinion.</p>
<p>The result is currently running in searchcode. This replaces what was the slowest portion of the code in the old version of searchcode and is much faster reducing the load on the servers considerably. Every string runs through the implementation and as such its fairly battle tested. It might not be perfect, but there has been no crashes to date with the v1.0.0 tag release so it should be reasonably safe to use, but of course there is no warranty. As mentioned a few times the code is open and on github, so feel free to bash against it <a href="https://github.com/boyter/go-string">https://github.com/boyter/go-string</a> and report bugs! If you do run into an interesting case where you use it let me know and ill add it to the README.</p>

</div></div>]]>
            </description>
            <link>https://boyter.org/posts/faster-literal-string-matching-in-go/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24647210</guid>
            <pubDate>Thu, 01 Oct 2020 03:59:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Prime and battery usage on Linux laptops: sometimes it's not what it seems to be]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24646504">thread link</a>) | @todsacerdoti
<br/>
September 30, 2020 | https://nwildner.com/posts/2020-10-01-nvidia-reverseprime/ | <a href="https://web.archive.org/web/*/https://nwildner.com/posts/2020-10-01-nvidia-reverseprime/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><a href="https://wiki.archlinux.org/index.php/PRIME">PRIME</a> is a technology used to manage hybrid graphics. It was meant to be a resource saver since you can configure it to use only the Integrated GPU, and render offload to the dedicated GPU whenever is needed. But that is not what happened in my real life situation.</p>

<p>I was not happy with the fact that my laptop was draining a lot of battery. Not only while using render offload by running software with <code>prime-run</code> and delegating gpu stuff to my dGPU(Nvidia MX150), but using the iGPU(i915 Intel) to daily stuff(terminal, browser) was also draining a lot of battery. Overheating was also a problem and then, i started to investigate.</p>
<p>Using <code>powertop -t 3</code> shown that Firefox was draining as much as <code>800 mW</code> per process(tab) on the <code>Power Est.</code> column. Meanwhile, <code>i915</code> module was using about <code>150 mW</code> alone. That got me thinking if, using the dedicated GPU to render stuff would get it better, but it didn’t. Launching Firefox with <code>prime-run</code> reduced a little the power usage per tab (opening the same websites), but the Intel module was still draining almost the same amount of power(<code>145 mW</code>) while the <code>nvidia</code> module was using <code>35mW</code>.</p>
<p>Other thing that bugged me was that my system always started with a lot of RAM already compromissed(<code>900MB</code>) on a simple <code>i3</code> setup. Could be the case where my iGPU was already allocating a lot of that resource to itself?</p>
<p>After that, i’ve decided to try some 3D, and <a href="https://veloren.net/">Veloren</a> was the game i’ve chosen. Those were the metrics captured with my status bar and <code>powertop</code>:</p>
<ul>
<li>
<p>Using <code>i915</code> driver:</p>
<ul>
<li>Driver drain reached <code>400mW</code>.</li>
<li><code>1,9 GB</code> Ram used</li>
<li>Battery expected duration after full charge was <code>1:28</code>.</li>
</ul>
</li>
<li>
<p>Using <code>nvidia</code> driver with <code>prime-run</code>.</p>
<ul>
<li><code>i915</code> driver was still draining <code>200 mW</code> approximately, spiking to <code>400</code> sometimes.</li>
<li><code>nvidia</code> driver was using about <code>50mW</code>, spiking to <code>80</code> once in a while.</li>
<li><code>1,7 GB</code> RAM used</li>
<li>About <code>140MB</code> of GDDR used</li>
<li>Battery expected duration after full charge was <code>1:12</code>.</li>
<li>nvidia temperature reached <code>73ºC</code>.</li>
</ul>
</li>
</ul>
<p>I know that this doesn’t seems to be a fair test, comparing a dGPU with an iGPU while executing a game. The point I was trying to prove was: Using the render offload didn’t really help on reducing resource consumption at all. On the oposite, it seems that it somehow helped me to have resources wasted by doubling energy consumption due to this binding created between modules with the <a href="https://wiki.archlinux.org/index.php/PRIME#PRIME_render_offload">render offload</a> feature.</p>

<p>I was decided to try a new approach and use <a href="https://wiki.archlinux.org/index.php/NVIDIA_Optimus#Use_NVIDIA_graphics_only">Nvidia graphics only</a>. Setup was pretty straightforward and after rebooting, I’ve launched Firefox with the same sites and <code>Power Est.</code> was about <code>570mW</code> per process. Good news, lets try Veloren again:</p>
<ul>
<li>Using <code>nvidia</code> driver only
<ul>
<li><code>nvidia</code> driver was using about <code>120mW</code>.</li>
<li>Battery expected duration after full charge was <code>1:47</code>.</li>
<li><code>1,3 GB</code> RAM used</li>
<li>About <code>140MB</code> of GDDR used</li>
<li>nvidia temperature reached <code>67ºC</code>.</li>
</ul>
</li>
</ul>
<p>That’s a lot better. I also noticed that my system was using only <code>500MB</code> RAM after a fresh start(a <code>400MB</code> difference).</p>
<p><strong>Lesson learned.</strong> Try things by yourself when it comes to power management.</p>

<p>Other things changed on my system after spending the weekend optimizing energy stuff:</p>
<ul>
<li>Not using <a href="https://github.com/tobi-wan-kenobi/bumblebee-status"><code>bumblebee-status</code></a> anymore. It’s a great bar, full of useful modules, but it was creating some weird spikes on power usage. Migrated to <a href="https://github.com/greshake/i3status-rust/"><code>i3status-rust</code></a> and now my bar isn’t even listed on the top 20 power usage agressors.
<ul>
<li>All previous tests were done using the same bar.</li>
</ul>
</li>
<li><code>telegram-desktop</code> is a mess on power and cpu usage and i’m seriously thinking on ditching this software and using it’s web version only. Firefox is a software I already use so, there’s nothing to lose.</li>
<li>Try to get used with some lightweight browser like <a href="https://qutebrowser.org/">qutebrowser</a> while on battery, and stop using my bookmark sync of choice. Have to test since not having video acceleration could be a caveat.</li>
<li>Find out why while using specific softwares <code>pulseaudio</code> gets crazy and it spikes with <code>4W</code> of Power Estimated usage.</li>
</ul>
  </div></div>]]>
            </description>
            <link>https://nwildner.com/posts/2020-10-01-nvidia-reverseprime/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24646504</guid>
            <pubDate>Thu, 01 Oct 2020 02:06:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mouth Dreams]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24646471">thread link</a>) | @bangonkeyboard
<br/>
September 30, 2020 | http://www.neilcic.com/mouthdreams/ | <a href="https://web.archive.org/web/*/http://www.neilcic.com/mouthdreams/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.neilcic.com/mouthdreams/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24646471</guid>
            <pubDate>Thu, 01 Oct 2020 02:01:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Our Voice Assistant Spoke to Google Duplex. Here’s What Happened]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24646421">thread link</a>) | @xingyzt
<br/>
September 30, 2020 | https://www.polyai.com/our-voice-assistant-spoke-to-google-duplex-heres-what-happened/ | <a href="https://web.archive.org/web/*/https://www.polyai.com/our-voice-assistant-spoke-to-google-duplex-heres-what-happened/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				
				<div>
				
													<p><img src="https://www.polyai.com/wp-content/uploads/2019/08/nikola-1-500x500.jpg"></p><div>
							<h6>Nikola Mrkšić</h6>
							<p><span>
								23 Sep 2020								- 5 minutes read							</span>
						</p></div>
						
										
				</div>
			</div><div>
									<p>This summer, Google has been deploying its AI voice assistant called Duplex to call bars and restaurants in order to update their opening hours on Google Maps listings.<br>
Here’s a call their system had with our virtual assistant for restaurants.</p>
<p><iframe src="https://player.vimeo.com/video/460586741" width="640" height="360" frameborder="0" allowfullscreen="allowfullscreen"><span data-mce-type="bookmark" style="display: inline-block; width: 0px; overflow: hidden; line-height: 0;" class="mce_SELRES_start">﻿</span><span data-mce-type="bookmark" style="display: inline-block; width: 0px; overflow: hidden; line-height: 0;" class="mce_SELRES_start">﻿</span></iframe></p>
<p>As far as we’re aware, this is the <strong>first naturally-occurring conversation between AI voice assistants in the wild</strong>. I have never seen anything like this before, and I’m incredibly proud that PolyAI is sharing this moment in computing history with our friends from Google.</p>
<p>After listening to the call, we’d say that it went pretty well! Google could have handled the two-part opening hours a bit better, but overall, the interaction was smooth. I want to share a few thoughts on what this means for the future of conversational technologies.</p>
<h3>Human language is a Universal API</h3>
<p>This interaction did not need to be a conversation in the way that we as humans think of it. The caller’s request was transactional and to the point. An API call or an HTTPS request between two web services would have done the job in 150ms, instead of two minutes of synthesized voice going back and forth across the telephone line. However, such APIs are not always available, or standardised. For instance, there are dozens of reservation APIs for restaurants used in the UK alone, and voice assistants will never integrate with every single one.</p>
<p>This kind of machine-to-machine conversational communication will become more commonplace as AI deployment accelerates. And while it may seem like an overkill from a technical standpoint, there are good reasons for these kinds of interactions to be conversational, rather than API calls.</p>
<p>Imagine you ask your virtual assistant — Siri or Alexa, for example — to book a hotel room. It can phone multiple hotels to check availability and book without having to integrate into each hotel’s individual booking API. And logs of the conversation can inform the user of alternative venues for their next trip.</p>
<h3>Welcome to the Uncanny Valley</h3>
<p>Google introduced <a href="https://ai.googleblog.com/2018/05/duplex-ai-system-for-natural-conversation.html">Duplex in May 2018</a> as an ‘AI system for accomplishing real-world tasks over the phone’. You may have seen this video of <a href="https://www.youtube.com/watch?v=D5VN56jQMWM">Sundar Pichai at Google I/O</a> using Duplex to make a restaurant reservation.</p>
<p>I’ll be the first to point out how incredible Google’s TTS (text-to-speech) is in the Duplex/PolyAI call. It sounds like a human, much more so than our assistant does.</p>
<p>According to the <a href="https://en.wikipedia.org/wiki/Uncanny_valley">Uncanny Valley theory</a>, the more human-like a robot is, the more likely people are to feel positive towards it. However, at a certain point of human-likeness, the robot becomes a bit creepy, and people are repulsed by it.</p>
<p><img src="https://www.polyai.com/wp-content/uploads/2020/09/uncanny-valley.png" alt="" width="588" height="387" srcset="https://www.polyai.com/wp-content/uploads/2020/09/uncanny-valley.png 588w, https://www.polyai.com/wp-content/uploads/2020/09/uncanny-valley-300x197.png 300w" sizes="(max-width: 588px) 100vw, 588px"></p>
<p>In the Google/PolyAI call, Duplex really does sound like a human – it does mention that it’s an automated service, but this is not enough. Why? Because crossing the Uncanny Valley means that a person on the call will treat the bot as though they are human.</p>
<p>Around the 1 minute mark, you’ll hear our voice assistant ask the caller when they’d like to come in, and Duplex speaks over it. In reality, these are machines – no-one’s getting offended. But when you listen to the call, the Duplex bot comes across as pretty rude. Because it sounds so human, it’s practically impossible to not attribute human qualities to the bot. And no one wants a rude voice assistant representing their company.</p>
<p><strong>Making customers think that your voice assistant is a real human is a sure-fire way to deliver frustrating customer experiences. At PolyAI, we work hard to make sure our voice assistants sit at the peak right before the Uncanny Valley – but without crossing it. Warm and friendly enough to put callers at ease, but not real enough to cause cognitive dissonance.</strong></p>
<h3>The Future of Voice</h3>
<p>Companies are wising up to the benefits of conversational AI in customer communications, and we’ll see a growing number of instances of machines communicating in human language. While this type of transactional communication may seem better suited to quick API calls, voice assistants can get the job done even when such APIs are not available.</p>
<p>We are super excited about the future of voice assistants. Two highly sophisticated voice assistants have now met in the wild, in a rerun of the legendary “Dr Livingstone, I presume” moment (though neither assistant realised they were speaking to one of their own). This is a sign of great things to come. Stay tuned – and get in touch with us if you want to build a great voice assistant for your brand.</p>
<p><strong>What do you think of the PolyAI vs Google Duplex call? Let us know on Twitter, <a href="https://twitter.com/poly_ai">@poly_ai</a>.</strong></p>
							</div></div>]]>
            </description>
            <link>https://www.polyai.com/our-voice-assistant-spoke-to-google-duplex-heres-what-happened/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24646421</guid>
            <pubDate>Thu, 01 Oct 2020 01:54:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Grand Design (2010)]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 41 (<a href="https://news.ycombinator.com/item?id=24646120">thread link</a>) | @got-any-grapes
<br/>
September 30, 2020 | https://blas.com/the-grand-design/ | <a href="https://web.archive.org/web/*/https://blas.com/the-grand-design/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
	<!-- #masthead -->

	<div id="main">

	<div id="primary">
		<div id="content" role="main">

			
				
	<article id="post-5144">
				<!-- .entry-header -->

				<div>
			
<p>Summary</p>



<ol><li>Traditionally these are questions for philosophy, but philosophy is dead. Philosophy has not kept up with modern developments in science, particularly physics. Scientists have become the bearers of the torch of discovery in our quest for knowledge. The purpose of this book is to give the answers that are suggested by recent discoveries and theoretical advances. They lead us to a new picture of the universe and our place in it that is very different from the traditional one, and different even from the picture we might have painted just a decade or two ago.</li></ol>



<p>Key Takeaways</p>



<ol><li>According to the traditional conception of the universe, objects move on well-defined paths and have definite histories. We can specify their precise position at each moment in time. Although that account is successful enough for everyday purposes, it was found in the 1920s that this “classical” picture could not account for the seemingly bizarre behavior observed on the atomic and subatomic scales of existence. Instead it was necessary to adopt a different framework, called quantum physics. Quantum theories have turned out to be remarkably accurate at predicting events on those scales, while also reproducing the predictions of the old classical theories when applied to the macroscopic world of daily life. But quantum and classical physics are based on very different conceptions of physical reality.</li><li><strong>We will explain Feynman’s approach in detail, and employ it to explore the idea that the universe itself has no single history, nor even an independent existence. That seems like a radical idea, even to many physicists. Indeed, like many notions in today’s science, it appears to violate common sense. But common sense is based upon everyday experience, not upon the universe as it is revealed through the marvels of technologies such as those that allow us to gaze deep into the atom or back to the early universe.</strong></li><li><strong>To deal with such paradoxes we shall adopt an approach that we call model-dependent realism. It is based on the idea that our brains interpret the input from our sensory organs by making a model of the world. When such a model is successful at explaining events, we tend to attribute to it, and to the elements and concepts that constitute it, the quality of reality or absolute truth. But there may be different ways in which one could model the same physical situation, with each employing different fundamental elements and concepts. If two such physical theories or models accurately predict the same events, one cannot be said to be more real than the other; rather, we are free to use whichever model is most convenient.</strong><ol><li><em>Model-dependent realism, mental models</em></li></ol></li><li><strong>M-theory is not a theory in the usual sense. It is a whole family of different theories, each of which is a good description of observations only in some range of physical situations. It is a bit like a map. As is well known, one cannot show the whole of the earth’s surface on a single map. The usual Mercator projection used for maps of the world makes areas appear larger and larger in the far north and south and doesn’t cover the North and South Poles. To faithfully map the entire earth, one has to use a collection of maps, each of which covers a limited region. The maps overlap each other, and where they do, they show the same landscape. M-theory is similar. The different theories in the M-theory family may look very different, but they can all be regarded as aspects of the same underlying theory. They are versions of the theory that are applicable only in limited ranges—for example, when certain quantities such as energy are small. Like the overlapping maps in a Mercator projection, where the ranges of different versions overlap, they predict the same phenomena. But just as there is no flat map that is a good representation of the earth’s entire surface, there is no single theory that is a good representation of observations in all situations.</strong><ol><li><em>The Mp is Not the Terrain</em></li></ol></li><li>Today most scientists would say a law of nature is a rule that is based upon an observed regularity and provides predictions that go beyond the immediate situations upon which it is based.<ol><li><em>General and broadly applicable</em></li></ol></li><li>Because it is so impractical to use the underlying physical laws to predict human behavior, we adopt what is called an effective theory. In physics, an effective theory is a framework created to model certain observed phenomena without describing in detail all of the underlying processes.</li><li>There is no picture- or theory-independent concept of reality. Instead we will adopt a view that we will call model-dependent realism: the idea that a physical theory or world picture is a model (generally of a mathematical nature) and a set of rules that connect the elements of the model to observations. This provides a framework with which to interpret modern science.</li><li><strong>We make models in science, but we also make them in everyday life. Model-dependent realism applies not only to scientific models but also to the conscious and subconscious mental models we all create in order to interpret and understand the everyday world. There is no way to remove the observer—us—from our perception of the world, which is created through our sensory processing and through the way we think and reason. Our perception—and hence the observations upon which our theories are based—is not direct, but rather is shaped by a kind of lens, the interpretive structure of our human brains.</strong><ol><li><em>Mental Models, Galilean Relativity</em></li></ol></li><li><strong>A model is a good model if it: Is elegant, Contains few arbitrary or adjustable elements, Agrees with and explains all existing observations, Makes detailed predictions about future observations that can disprove or falsify the model if they are not borne out.</strong></li><li>Another of the main tenets of quantum physics is the uncertainty principle, formulated by Werner Heisenberg in 1926. The uncertainty principle tells us that there are limits to our ability to simultaneously measure certain data, such as the position and velocity of a particle. According to the uncertainty principle, for example, if you multiply the uncertainty in the position of a particle by the uncertainty in its momentum (its mass times its velocity) the result can never be smaller than a certain fixed quantity, called Planck’s constant. That’s a tongue-twister, but its gist can be stated simply: The more precisely you measure speed, the less precisely you can measure position, and vice versa.</li><li><strong>In other words, nature does not dictate the outcome of any process or experiment, even in the simplest of situations. Rather, it allows a number of different eventualities, each with a certain likelihood of being realized.</strong></li><li>Given the state of a system at some time, the laws of nature determine the probabilities of various futures and pasts rather than determining the future and past with certainty.</li><li><strong>Quantum physics tells us that no matter how thorough our observation of the present, the (unobserved) past, like the future, is indefinite and exists only as a spectrum of possibilities. The universe, according to quantum physics, has no single past, or history. The fact that the past takes no definite form means that observations you make on a system in the present affect its past.</strong></li><li>Electric and magnetic forces are far stronger than gravity, but we don’t usually notice them in everyday life because a macroscopic body contains almost equal numbers of positive and negative electrical charges. This means that the electric and magnetic forces between two macroscopic bodies nearly cancel each other out, unlike the gravitational forces, which all add up.</li><li>Maxwell’s equations dictate that electromagnetic waves travel at a speed of about 300,000 kilometers a second, or about 670 million miles per hour. But to quote a speed means nothing unless you specify a frame of reference relative to which the speed is measured. That’s not something you usually need to think about in everyday life. When a speed limit sign reads 60 miles per hour, it is understood that your speed is measured relative to the road and not the black hole at the center of the Milky Way. But even in everyday life there are occasions in which you have to take into account reference frames. For example, if you carry a cup of tea up the aisle of a jet plane in flight, you might say your speed is 2 miles per hour. Someone on the ground, however, might say you were moving at 572 miles per hour. Lest you think that one or the other of those observers has a better claim to the truth, keep in mind that because the earth orbits the sun, someone watching you from the surface of that heavenly body would disagree with both and say you are moving at about 18 miles per second, not to mention envying your air-conditioning.<ol><li><em>Galilean Relativity</em></li></ol></li><li>Electromagnetic forces are responsible for all of chemistry and biology.</li><li>The histories that contribute to the Feynman sum don’t have an independent existence, but depend on what is being measured. We create history by our observation, rather than history creating us. The idea that the universe does not have a unique observer-independent history might seem to conflict with certain facts we know. There might be one history in which the moon is made of Roquefort cheese. But we have observed that the moon is not made of cheese, which is bad news for mice. Hence histories in which the moon is made of cheese do not contribute to the present state of our universe, though they might contribute to others. That might sound like science fiction, but it isn’t.</li><li>What makes this universe interesting is that although the fundamental “physics” of this universe is simple, the “chemistry” can be complicated. That is, composite objects exist on different scales. At the smallest scale, the fundamental physics tells us that there are just live and dead squares. On a larger scale, there are gliders, blinkers, and still-life blocks. At a still larger scale there are even more complex objects, such as …</li></ol></div></article></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blas.com/the-grand-design/">https://blas.com/the-grand-design/</a></em></p>]]>
            </description>
            <link>https://blas.com/the-grand-design/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24646120</guid>
            <pubDate>Thu, 01 Oct 2020 01:08:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Computer Dungeon Slash Postmortem]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24646063">thread link</a>) | @panic
<br/>
September 30, 2020 | https://museumofzzt.com/article/496/a-computer-dungeon-slash-postmortem | <a href="https://web.archive.org/web/*/https://museumofzzt.com/article/496/a-computer-dungeon-slash-postmortem">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article data-article_id="496">


    

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image2.png"></p>


        

    


<p>I consider <a href="https://museumofzzt.com/file/c/CDZ20MOZ.ZIP" target="_blank"><i>Computer Dungeon Slash: ZZT 2.0</i></a> my personal best for ZZT games. I've now released two versions, one in September of 2019 and then another with some updates and optimizations in May of 2020. Aside from a couple of smaller errors and special-thanks additions, there's not much more to fix, so this will probably be the final version with any major changes.</p>

<p>Like some of my previous ZZT games, it relies heavily on procedural generation, with apparently such complexity that Dr. Dos called it "basically sorcery" during their <a href="https://museumofzzt.com/article/479/livestream-computer-dungeon-slash-zzt-20">playthrough on Twitch</a>, which I took as a great compliment. He also mentioned that this game, its generators in particular, could use a write-up. So I wrote one!</p>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image24.png"></p>

<p>In case you're reading this and unfamiliar with this game, it concerns a player finding themselves in the town of Habeas Corpus, where almost everyone and everything has been swallowed by the dungeon.</p>

<p>The player's task is to brave the randomly-generated dungeon, rescuing the town and townspeople from its clutches.</p>

<p>There's not much more plot or lore than the above, since I focused mainly on characterization in my worldbuilding and most of the actual plot isn't revealed until the end.</p>

<p>So what about the workings of this game?</p>

<p>I'll start with "sorcery"--there's something to that, for sure. When I work with procedural generation it feels a bit like alchemy. Scientific, but also a little bit mysterious and magical. I hope this article helps you better understand the scientific side of that coin.</p>

<p>For readers not intimately familiar with ZZT, one reason a veteran ZZTer would call my level generation "sorcery"  is its limitations. ZZT is a 1991 DOS game-creation-system, after all, simple enough for 8-year-old me to use. So if you don't know anything about ZZT coming in, I hope this write-up helps you better understand the absurdity and appeal of working in it and pushing its limits.</p>

<p>Further, if you came into this wanting to know how this stuff works so that you can experiment with it or even improve on it, I want you to be empowered to do so.</p>

<h2>Goals</h2>

<p>With <i>Computer Dungeon Slash: ZZT</i> (called <i>CDZ</i> here for short) I had three goals for generation. I wanted levels to be interesting to look at, fun to play, and fair. What does fair mean?</p>

<p>Most previous ZZT releases with procedural generation would probably not soft-lock players (block them off from finishing the game). In the early 2000s when this fad hit, most ZZTers involved were in high school and "probably not" was enough. But that small chance of soft-locking players with my generators annoyed me even then.</p>

<p>With <i>CDZ</i>, I wanted some certainty that my algorithms absolutely would not soft-lock players.</p>

<p>With these goals in mind, let's look at the tools I had to accomplish them.</p>

<h2>Building Blocks for Procedural Level Generation in ZZT</h2>

<p>ZZT is tile-based, so making it create its own levels is kind of like generating dungeons for classic ASCII roguelikes, except with much more restrictive tools and limits than, for example, C++ or Python. There's no way to easily store level layout data outside of "in the level", and ZZT boasts precious few variables and only ten true-or-false flags. In addition, the entire game is made up of "boards" of only 60x25 tiles! Despite being such a limited system, ZZT lets us do a fair amount.</p>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image4.png">
<img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image7.gif"></p>

<p>Almost any element (terrain or other object) that takes up a space on a board is helpful, but a few basic ones are laid out in a reference image on the left. Fake walls prove pretty invaluable because they don't block objects but help the engine easily keep track of where another terrain type <i>will</i> later appear.</p>

<p>While <i>CDZ</i> uses sliders and boulders to some extent, the classic examples of ZZT level generators using sliders and boulders are probably WiL's <i>Run-On</i> and Benco's <i>Lost</i>.</p>

<p>And of course, one of the elements of play is actually <i>called</i> an object, and can run little scripts in ZZT-OOP, the engine's default "language." ZZT-OOP has a number of helpful commands for procedural generation.</p>

<p>The <code>#change</code> command can change almost any ZZT gameplay element into almost any other, which is invaluable both for structuring and theming levels. <code>#put THING DIRECTION</code> and <code>#become THING</code> allow for level builder objects to modify environments directly, and they have a more complex use we'll go into later.</p>

<p>Procedural level generation in <i>CDZ</i> is random. Appropriately, ZZT-OOP's random directions proved immensely useful in making it happen. A number of situations call for a "four-sided" dice-roll, and ZZT does have an <i>rnd</i> direction (randomly north, south, east, or west), but as the reader may know, <i>rnd</i> is twice as likely to give an east-west result as a north-south. So what to do?</p>

<p>Well, there are also <i>rndne</i> (north or east) and <i>rndp DIRECTION</i> (one of two directions perpendicular to <i>DIRECTION</i>). Because <i>rndne</i> is a valid direction in itself, you can use <i>rndp rndne</i> to get a random cardinal direction with equal probability of each. (I'm ashamed that I didn't realize that one until reading Anna Anthropy's <i>ZZT</i> a few years back.)</p>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image14.gif"></p>

<p>In ZZT, <code>#if blocked DIRECTION</code> tells an object whether it is blocked in a given direction. And <code>#send OBJECTNAME:LABEL</code> tells another object, <i>OBJECTNAME</i>, to immediately begin executing code starting with <i>:LABEL</i>.</p>

<p>Slime enemies move erratically and leave breakable walls behind, so you can change their color frequently to fill empty spaces with different colors of breakable walls.</p>

<p>One last limitation and one last "coding" trick deserves mention. ZZT has a limit of about 20 kilobytes per board (including code) before the board misbehaves or gets corrupted at runtime. Objects can use the command <code>#bind OBJECTNAME</code> to work from the same exact instance of the same code as the other object <i>OBJECTNAME</i>, saving valuable code space.</p>

<p>Nowadays, one can "pre-bind" objects with external editors, causing them to share identical labels and behaviors but eliminating the need for the 5+ bytes of space that a <code>#bind</code> command needs.</p>

<h2>Two Big Insights</h2>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image18.png">
<img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image20.png"></p>

<p>In addition to the more concrete "tools" above, two big conceptual insights greatly impacted this project. The first is about level connectedness, and it hit me after reading Rabbitboots's musings on house generation in <a href="https://museumofzzt.com/file/d/dood2018.zip" target="_blank"><i>Doodads 2018</i></a>.</p>

<p>Say I have a house with four rooms, and I block off only one doorway in the house, as on the left. Any room in the house can still visit any other.</p>

<p>Rabbitboots goes on to note that if we make a larger house out of smaller ones, the large house remains fully connected.</p>

<p>If House A connects to House B and B connects to House C, then A connects to C.</p>

<p>This was huge for me. It gave me hope that I could avoid soft-locks while also making more interesting, varied levels.</p>

<p>Shortly after the 2019 release, while looking at TriphEd's maze generation in <a href="https://museumofzzt.com/file/b/BACKTRAX.zip" target="_blank"><i>Backtrax</i></a>, I had another "Aha!" moment.</p>


<p>The algorithm is best explained step-by-step, and you can follow along with the following roughly equivalent method if you have a pencil and paper.</p>

<p>(1) Start with a grid of dots. Any size 3 x 3 or up will do.</p>

<p>(2) Connect all the outer dots along the edge so that they make a rectangle.</p>

<p>(3) For each "middle dot" within the square, draw <i>exactly one line</i> from that dot to any dot directly above, below, left, or right of it. Edge dots can receive lines.</p>

<p>If you used a 3 x 3 grid of dots, the end result will resemble the 2 x 2 house above.</p>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/backtrax-levels.gif"></p>

<p>Any edge tile can access any other edge tile in this algorithm. It can leave some squares inaccessible from the edges, but this is acceptable if nothing essential to player progress is placed in those tiles.</p>

<p>In ZZT, you can accomplish this by having objects use <code>#put rndp rndne ELEMENT</code> on a grid, and that's exactly what <i>Backtrax</i> is doing.</p>

<p>A <i>very</i> small set of soft-lock possibilities does exist in <i>Backtrax</i>. Because there's a blocking linewall diagonally southeast of the lower-right-hand wall generator object, the wrong combinations of walls <i>could</i> block the player, but it is <i>incredibly</i> unlikely and easily remedied.</p>

<p>This is the most elegant level generator in ZZT to date--and also, in case it wasn't already elegant enough, it weighs in at only 10.9 kilobytes and re-uses its "grid" after you reach the exit, using a separate trick (that I won't discuss in detail here) to teleport the player back to the start for a new level.</p>

<p>Recognize TriphEd's genius.</p>

<p>After the initial <i>CDZ</i> release, I experimented a lot with this algorithm. Several generators in version 2.0 benefited from its use. We can now move slowly but surely into the actual inner workings of this game.</p>

<h2>Primary Generators</h2>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image6.png"></p>

<p><i>Computer Dungeon Slash</i> level generators have a "primary generator" object that handles a lot of needed dice-rolls and uses <code>#send</code> to communicate its randomization to different groups of objects. It's usually set up as on the left, or similar.</p>

<p>This particular setup involves fake walls placed north, south, east, and west of the primary generator and water (a blocking terrain) in the four corners. To make a four-direction roll, it uses <code>#put rndp rndne gem</code> and then iterates over some variation of:</p>

<code>#if blocked n #send object:option1
#if blocked e #send object:option2
#if blocked s #send object:option3
#if blocked w #send object:option4</code>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image16.png"></p>

<p>The objects referred to in the <code>#send object:option</code> commands  are pre-bound objects with exactly the same code, and positioned so that only one of them will place a wall, generate an important key, etc. at the time they're called. In this example, the pre-bound group of objects has this code:</p><p>

<code>@object
#cycle 1
#end
:option1
#if blocked n become solid
#die
:option2
#if blocked e become solid
#die
:option3
#if blocked s become solid
#die
:option4
#if blocked w become solid
#die</code></p><p>There is a fake wall in the middle of the house, so that only one object becomes a wall, and the rest die. Then the primary generator turns the fake into a solid wall.</p>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image23.gif"></p>

<p>This method also extends to larger houses similar to those in the <i>Doodads 2018</i> example, and can …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://museumofzzt.com/article/496/a-computer-dungeon-slash-postmortem">https://museumofzzt.com/article/496/a-computer-dungeon-slash-postmortem</a></em></p>]]>
            </description>
            <link>https://museumofzzt.com/article/496/a-computer-dungeon-slash-postmortem</link>
            <guid isPermaLink="false">hacker-news-small-sites-24646063</guid>
            <pubDate>Thu, 01 Oct 2020 00:59:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ontario doctors sign letter to Premier advising against sweeping lockdowns]]>
            </title>
            <description>
<![CDATA[
Score 108 | Comments 175 (<a href="https://news.ycombinator.com/item?id=24645821">thread link</a>) | @mrfusion
<br/>
September 30, 2020 | https://beta.ctvnews.ca/local/ottawa/2020/9/30/1_5126193.html | <a href="https://web.archive.org/web/*/https://beta.ctvnews.ca/local/ottawa/2020/9/30/1_5126193.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>



<div>
    
        <p>Published Sept. 30, 2020 9:40 a.m. ET</p>
        <p>Updated  Sept. 30, 2020 7:26 p.m. ET</p>
    
</div>



  


    
        
        
    
    
    <amp-iframe resizable="" width="16" height="17" layout="responsive" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation" allowfullscreen="" frameborder="0" src="https://ampvideo.ctvnews.ca/content/ctvnews/en/local/ottawa/2020/9/30/1_5126193.vidi.root-responsivegrid-vidicomponent.html?preventDefault=true">
        
        <p>Click to Expand</p>
    </amp-iframe>





    <p>OTTAWA -- 	Twenty-one Ontario doctors have signed a joint letter to Premier Doug Ford, urging him not to issue a new lockdown this fall because of rising COVID-19 case numbers.</p><p>	Daily numbers of new cases have risen dramatically in recent days, with Ontario recording <a href="https://toronto.ctvnews.ca/new-covid-19-cases-in-ontario-reach-highest-mark-ever-1.5122863" target="_blank">700 new cases of COVID-19 on Monday</a> – the highest number of new cases recorded in a single day.</p><p>	However, the 21 doctors who signed the letter to the premier say another provincewide lockdown—similar to what was in place in the spring—would not be helpful.</p><ul>	<li>		<a href="#Full letter"><i>Read the full letter below</i></a></li></ul><p>	"We are writing this letter in support of the governments’ plan to use a tactical localized approach, rather than sweeping new lockdown measures, to deal with the increasing COVID case numbers in Ontario," the letter says.&nbsp;</p><p>	"Lockdowns have been shown not to eliminate the virus. While they slow the spread of the virus, this only lasts as long as the lockdown lasts. This creates a situation where there is no way to end the lockdown, and society cannot move forward in vitally important ways including in the health sector, the economy and other critically important instrumental goods including education, recreation, and healthy human social interactions."</p><p>	Speaking on Newstalk 580 CFRA's "The Morning Rush with Bill Carroll" in Ottawa, CTV's infectious disease specialist Dr. Neil Rau—a signatory of the letter—pointed to two data points to consider when looking at the spread of COVID-19.</p><p>	"We're reacting to increased aggregate case numbers, but the percentage positive is not really as bad as it used to be," he said. "We're testing more people, so we're finding more cases […] We're driving our numbers up, it's worse than it was in the summer, but it's not what it was last winter and life has to go on."</p><ul>	<li>		<a href="https://www.iheartradio.ca/580-cfra/podcasts/the-morning-rush-dr-neil-rau-interview-why-we-don-t-want-another-lockdown-1.13612912?mode=Article" target="_blank"><strong>LISTEN NOW: "The Morning Rush": Dr. Neil Rau - Why we don't want another lockdown</strong></a></li></ul><p>	Monday's 700 cases in Ontario came from 41,111 total tests, for a positive percentage rate of 1.7 per cent. On April 24, <a href="https://toronto.ctvnews.ca/highest-number-of-new-covid-19-cases-in-a-single-day-reported-by-ontario-health-officials-1.4910216" target="_blank">the previous watermark of 640 new cases in a single day</a>, the result came from 12,295 tests, for a positive percentage rate of 5.2 per cent.</p><p>	Testing capacity was lower in the spring than it is now, and testing criteria has changed over time; however, Dr. Rau and the other signatories of the letter said the increasing case numbers are not leading to unmanageable levels of hospitalizations.</p><p>	"In Ontario and other parts of the world, such as the European Union, increasing case loads are not necessarily translating into unmanageable levels of hospitalizations and ICU admissions," the letter says.</p><p>	The letter also points to other health impacts linked to the lockdown.</p><p>	"Hard data now exist showing the significant negative health effects shutting down society has caused. Overdoses have risen 40% in some jurisdictions. Extensive morbidity has been experienced by those whose surgery has been cancelled, and the ramifications for cancer patients whose diagnostic testing was delayed has yet to be determined," the letter states.</p><p>	"Economic harms are health harms," Dr. Rau told CFRA. "It sounds horrible to say, but it's true. Health is wealth. We all know this."</p><h2>	<strong>LETTER POINTS TO DISAGREEMENT AMONG HEALTH PROFESSIONALS</strong></h2><p>	Other Ontario health professionals have been arguing for increased restrictions as cases rise.</p><p>	Last week, the Ontario Hospital Association released a letter signed by 38 health professionals which <a href="https://ottawa.ctvnews.ca/ontario-hospital-association-calls-for-return-to-restrictions-on-non-essential-businesses-1.5119832" target="_blank">called for immediate restrictions to be re-imposed on non-essential businesses</a>, such as gyms, dine-in restaurants and bars, nightclubs, and theatres. It also calls on restrictions on other places where people can gather, such as places of worship.</p><p>	The letter from the OHA said regions where the speed of transmission was underestimated are “now facing the consequence of increased hospitalization rates, including a rise in intensive care unit (ICU) admissions and more deaths.”</p><p>	Hospitalizations in Ontario have been increasing, but have not yet reached the same level that was seen in the spring.</p><p>	According to <a href="https://covid-19.ontario.ca/data" target="_blank">data from the Ontario government</a>, there were 128 people in hospital in Ontario with COVID-19 complications on Monday—the day 700 new cases were recorded—up from 65 a week before; however, on April 24—when 640 new cases were recorded—government data shows that there were 910 people in hospital. The peak for hospitalizations in Ontario came in May, when there were days when more than 1,000 people were hospitalized. That number steadily decreased from May through the summer before it began going up again in September.</p><p>	Speaking on CTV Morning Live Ottawa, infectious disease specialist Dr. Abdu Sharkawy suggested t<a href="https://ottawa.ctvnews.ca/video?clipId=2045684" target="_blank">emporary restrictions on gathering would help curb the spread of COVID-19</a>.&nbsp;</p><p>	"We don't want to see our hospitals overwhelmed," he said. "We're still waiting for flu season and a whole bunch of other respiratory viruses to hit us and our capacity to be challenged. We don't want that to happen. We need everybody to try and simplify their lives and minimize anything that's non-essential."</p><p>	Dr. Sharkawy said regions where cases are rapidly rising may need to impose new restrictions to get the spread of the virus under control.</p><p>	"I think it's abundantly clear that, particularly in hot spots like Ottawa, Toronto and Peel region, the situation is not well controlled," he said. "Sometimes you need blunt instruments, even if they're temporary in nature, to make sure that you curtail the spread of this virus because it gets away from us a lot more quickly than many of us can anticipate sometimes."</p><p>	Dr. Sharkawy suggested hot spots follow the lead of Quebec, which imposed <a href="https://montreal.ctvnews.ca/life-in-the-red-zone-here-s-what-you-can-and-can-t-do-1.5125093" target="_blank">harsh restrictions on three areas in the province</a>, including Montreal and Quebec City, banning private gatherings and closing bars and restaurant dining rooms.</p><p>	"I think we should do it now," Dr. Sharkawy said of Ontario. "I think we all need to adopt an attitude and an approach that recognizes that we have to do what's absolutely necessary to keep everybody safe."</p><h2>	<strong>FULL LETTER FROM ONTARIO DOCTORS TO THE PREMIER</strong></h2><p>	Dear Premier Ford,</p><p>	We are writing this letter in support of the governments’ plan to use a tactical localized approach, rather than sweeping new lockdown measures, to deal with the increasing COVID case numbers in Ontario. Lockdowns have been shown not to eliminate the virus. While they slow the spread of the virus, this only lasts as long as the lockdown lasts. This creates a situation where there is no way to end the lockdown, and society cannot move forward in vitally important ways including in the health sector, the economy and other critically important instrumental goods including education, recreation, and healthy human social interactions.</p><p>	In Ontario the increase in cases at this time are in people under 60 years of age who are unlikely to become very ill. At the peak of the pandemic in Ontario in mid-April, 56% of cases were in ≥60 year olds, now in Sept only 14% of cases are in ≥60 year olds. In Ontario and other parts of the world, such as the European Union, increasing case loads are not necessarily translating into unmanageable levels of hospitalizations and ICU admissions. This is not a result of a lag in reporting of severe and fatal cases. While we understand the concerns that these cases could spill into vulnerable communities, we also need to balance the actual risk. As the virus circulates at manageable levels within the community, we need to continue the gains we have made in the protection of the vulnerable in long-term care and retirement institutions, and continue to educate other people about their individual risk, so that they can observe appropriate protective measures.</p><p>	Lockdowns have costs that have, to this point, not been included in the consideration of further measures. A full accounting of the implications on health and well-being must be included in the models, and be brought forward for public debate. Hard data now exist showing the significant negative health effects shutting down society has caused. Overdoses have risen 40% in some jurisdictions. Extensive morbidity has been experienced by those whose surgery has been cancelled, and the ramifications for cancer patients whose diagnostic testing was delayed has yet to be determined. A huge concern is the implication of closure of schools, and the ongoing reluctance we have seen in the large urban centers of sending children back to the classroom due to safety concerns. Global data clearly now show that children have an extremely low risk of serious illness, but they are disproportionately harmed by precautions. Children’s rights to societal care, mental health support and education must be protected. This cannot be achieved with ongoing or rotating lockdown.</p><p>	The invitation and involvement of other health experts to advise the government’s response beside individuals in Public Health and Infectious Diseases in addition to leaders in the business, securities and arts communities is essential. We also call for increased open debate, in the public forum, that hears voices from outside the medical and public health communities, in order to consider all points of view from society. This is a fundamental principle upon which democratic societies are built. All stakeholders should have an equal right to participation in public discourse when it comes to setting such fundamental and sweeping societal interventions.</p><p>	All have the right to feel their voices have been heard, and moreover to ensure factual credible data is openly debated, in contrast to the personal and political slants that have had apparent significant impacts on the management of the virus to date. Our society has borne enormous pain over the past 6 months. It’s time to do something different.</p><p>	Sincerely,</p><p>	Jane Batt MD, PhD, FRCPC. Respirologist, Associate Professor, Department of …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://beta.ctvnews.ca/local/ottawa/2020/9/30/1_5126193.html">https://beta.ctvnews.ca/local/ottawa/2020/9/30/1_5126193.html</a></em></p>]]>
            </description>
            <link>https://beta.ctvnews.ca/local/ottawa/2020/9/30/1_5126193.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24645821</guid>
            <pubDate>Thu, 01 Oct 2020 00:23:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A housing industry of endless one-offs is holding our society back]]>
            </title>
            <description>
<![CDATA[
Score 73 | Comments 156 (<a href="https://news.ycombinator.com/item?id=24645525">thread link</a>) | @jseliger
<br/>
September 30, 2020 | https://blokable.com/news/the-housing-market-is-building-snowflakes-an-endless-series-of-one-offs/ | <a href="https://web.archive.org/web/*/https://blokable.com/news/the-housing-market-is-building-snowflakes-an-endless-series-of-one-offs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2><strong>By Aaron Holm and Nelson Del Rio,<br>Co-CEOs, Blokable Inc.</strong></h2><h2>The following post breaks down the high cost of building housing as part of a series exploring the root causes of the U.S. housing crisis and how private and public sector collaboration can chart a different course.&nbsp;</h2><figure><img width="1200" height="800" src="data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjA0OCAxMzY0IiB3aWR0aD0iMjA0OCIgaGVpZ2h0PSIxMzY0IiBkYXRhLXU9IiUyRndwLWNvbnRlbnQlMkZ1cGxvYWRzJTJGMjAyMCUyRjA5JTJGQmxvZy0yLWltYWdlLTIwNDh4MTM2NC5qcGciIGRhdGEtdz0iMjA0OCIgZGF0YS1oPSIxMzY0IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPjwvc3ZnPg==" data-spai="1" alt="" sizes="(max-width: 1200px) 100vw, 1200px"></figure><p>In mid-2018 we met with Washington State Governor Jay Inslee to discuss the insatiable need for affordable housing in the Pacific Northwest. We gave him a tour of Blokable’s prototype factory in Vancouver, Wash., and shared our R&amp;D work to reimagine how housing is built. Afterward, we drove up to Seattle in a rented Nissan Maxima, wondering aloud what it would cost to build our rental car from scratch in a driveway — exactly how nearly all housing is built today.&nbsp;&nbsp;&nbsp;</p><p>We would have to design, engineer, and fabricate all of the car’s systems and components, specify and source the materials, identify the regulatory requirements and work with different agencies to test our systems and sign off on safety and environmental requirements, create a working set of engineering drawings to track the build, order the equipment necessary to complete the assembly, and hire at least a small team of people to put the car together. A car that retails for just under $35,000 would cost tens of millions of dollars to build, and there would be no guarantees of quality and reliability.&nbsp;</p><p>Every time a new residential real estate project appears on the landscape, it’s a bespoke process that can directly involve hundreds of people, including a developer and a general contractor, various architects and engineers, and the investors who are funding the project. For each participant in the process, the singular goal is to extract a profit from that specific patch of dirt, and their profits are circumscribed by the value of the land, the applicable building regulations, and the prevailing labor and capital costs.&nbsp;</p><p>The result of this one-off approach is soaring project costs that make housing simply unaffordable to most people in many parts of the U.S.. Conventional housing development is like building a snowflake every time. And if the glut of empty luxury condo towers in downtown San Francisco is any indication, many of these snowflake projects are indeed melting as soon as they touch the ground.&nbsp;</p><p>How did this one-off approach to development take shape? Everything from ovens to stereos were all once clunky prototypes built as one-offs in the same location as their eventual use. Over time with innovation, standardization, and market demand, they evolved into products. In the early days of the automobile and aviation industries, prototypes and projects were built at high cost and yielded low quality results that resembled the current market products in their most basic functionality: they could drive and fly. Early automobile and airplane prototypes were unsafe and expensive. But through investment in product design, engineering, prototyping, and manufacturing, these prototypes eventually evolved into products. Increasingly stable designs and specifications enabled greater standardization, repeatability, and mass production resulting in lower costs, higher quality, and broader distribution.&nbsp;</p><p>Coupled with clear market demand, this standardization led to the formation of entire industries to build roads and airports, manufacture tires, test safety under federal guidelines, and so on. If you visit the automotive and aviation manufacturing hubs around Detroit and Seattle you’ll find vibrant supply chains competing for business and investing in innovation to provide better products and services. Continuously improving engines, seats, windshields, and bathrooms. All of this activity creates ever-improving products and fierce competition for performance, quality, and price.&nbsp;&nbsp;</p><p>If we compare product manufacturing in the automotive and aviation industries to how we build housing — whether it is an Accessory Dwelling Unit (ADU), single family home, multi-family apartment building, or a high rise — the steps in the process are largely the same. To simplify the housing development process, let’s assume the land is entitled, there are no environmental mitigation issues, financing is secured, and development will not be opposed by regulatory agencies or local city council. What does it take to build a snowflake?</p><figure><img width="1200" height="800" src="data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjA0OCAxMzY0IiB3aWR0aD0iMjA0OCIgaGVpZ2h0PSIxMzY0IiBkYXRhLXU9IiUyRndwLWNvbnRlbnQlMkZ1cGxvYWRzJTJGMjAyMCUyRjA5JTJGQmxvZy0yLWJvZHktaW1hZ2UtMjA0OHgxMzY0LmpwZyIgZGF0YS13PSIyMDQ4IiBkYXRhLWg9IjEzNjQiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyI+PC9zdmc+" data-spai="1" alt="Housing creation is an endless series of one-offs" sizes="(max-width: 1200px) 100vw, 1200px"><figcaption><em>Conventional housing development is like building a snowflake every time.</em></figcaption></figure><p>Let’s look at the absolute bare minimum of steps in the process from the perspective of the developer. Broadly speaking, the developer identifies and ties up the site, conducts preliminary site review and discussions with impacted parties, manages entitlements, financing, and the project approval process for the site, oversees all building and owns the project along with any equity investors they have brought in to finance the deal. With respect to the building process itself, the developer will partner with an architect to work up a site massing and design that will satisfy the intended program — the mix of units, floorplans, common spaces, revenue generating and non-revenue generating space — as well as the code requirements for the building and the site. Once the basic architecture is in place, the project heads over to engineers, which are typically separate firms with separate contracts, costs, regulatory oversight, and liability, to specify structural engineering, MEP (mechanical, electrical, plumbing), and site and offsite engineering.&nbsp;</p><p>With the initial design and engineering complete, the developer sends a construction set of drawings to a general contractor (GC) for final pricing. The GC will take the specifications and build out a schedule and budget to determine how much work they intend to do themselves (self-perform) vs. how much work they will contract out to sub-contractors (subs). The GC will oversee all of the work necessary to build this custom-designed and engineered project on-site, including civil, foundation, pulling utilities, framing, rough-in and waterproofing, siding and cladding, roofing, windows and doors, MEP, paint and trim, fixtures and finishes, and ultimately certificate of occupancy.&nbsp; It is important to note that at this stage the GC’s quote is just an estimate. We haven’t built anything yet.</p><p>With approved drawings, financing, budget, and schedule in hand, the developer can start the snowflake build. Every step listed in the paragraph above must be completed by the corresponding specialists, and getting the work done on schedule is much more of an art than a science. Each contractor and subcontractor has their own contractual obligations, risks, and liability. Getting to the certificate of occupancy means the developer has navigated the process and can now bring in buyers or renters to start paying off the decades of debt that were secured to finance the build.&nbsp; When the developer moves on to the next project, all of the steps must be performed again, without exception. The finished project may be beautiful, energy efficient, or last 100 years, but it will still be a one-off.&nbsp;&nbsp;</p><p>All of this work is done for every project every time, regardless of size. A home or apartment is not more complicated than a car or plane, and while the unique attributes of individual sites and real estate do add challenges to repeatability, it is possible to decouple the building from the dirt.</p><p>We can’t be surprised that building costs for new housing continue to escalate. We can’t be surprised that it’s even more expensive to create affordable housing. Yet we continue to shrug our shoulders and say, “That’s just how it is.” We dig around the edges of the problem, foraging for scraps by looking for cost savings in commodities, underpaying labor, cutting corners on quality and performance, and building on cheaper land further and further from work and community.&nbsp;</p><p>Housing development is antiquated and the only group benefitting is the real estate development and building industry, who in fact have every incentive to restrict the supply. We’re making Version 1 of the oven, stereo, car, and plane over and over again, in a housing market that is chronically under-served. The failure to build adequate housing has generational effects on health, education, and opportunity.&nbsp;</p><p>There has to be a better way. We have to re-imagine the housing market and build better. More on that to come in our next post.</p></div></div></div>]]>
            </description>
            <link>https://blokable.com/news/the-housing-market-is-building-snowflakes-an-endless-series-of-one-offs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24645525</guid>
            <pubDate>Wed, 30 Sep 2020 23:48:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: CSS-to-Tailwind – Transform plain CSS into TailwindCSS]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24645087">thread link</a>) | @miklosme
<br/>
September 30, 2020 | https://transform.tools/css-to-tailwind | <a href="https://web.archive.org/web/*/https://transform.tools/css-to-tailwind">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://transform.tools/css-to-tailwind</link>
            <guid isPermaLink="false">hacker-news-small-sites-24645087</guid>
            <pubDate>Wed, 30 Sep 2020 23:01:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bay Area approve plan requiring employees to work from home 3 days a week]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24645083">thread link</a>) | @henryw
<br/>
September 30, 2020 | https://usatodaysun.com/bay-area-says-employees-will-be-required-to-work-from-home-three-days-a-week-after-the-pandemic-to-reduce-greenhouse-gas-emissions/ | <a href="https://web.archive.org/web/*/https://usatodaysun.com/bay-area-says-employees-will-be-required-to-work-from-home-three-days-a-week-after-the-pandemic-to-reduce-greenhouse-gas-emissions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://usatodaysun.com/bay-area-says-employees-will-be-required-to-work-from-home-three-days-a-week-after-the-pandemic-to-reduce-greenhouse-gas-emissions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24645083</guid>
            <pubDate>Wed, 30 Sep 2020 23:01:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Alpha Support for Envoy on Windows (Envoyproxy.io)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24645007">thread link</a>) | @slowstart
<br/>
September 30, 2020 | https://blog.envoyproxy.io/announcing-alpha-support-for-envoy-on-windows-d2c53c51de7b | <a href="https://web.archive.org/web/*/https://blog.envoyproxy.io/announcing-alpha-support-for-envoy-on-windows-d2c53c51de7b">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><div><div><div><p><a href="https://blog.envoyproxy.io/@sunjaybhatia?source=post_page-----d2c53c51de7b--------------------------------" rel="noopener"><img alt="Sunjay Bhatia" src="https://miro.medium.com/fit/c/96/96/1*fT4wp_OWPsif0-BAbBmd4g.jpeg" width="48" height="48"></a></p></div></div></div></div><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/8000/1*PhwQzf6DWMsCvXY3fYj3RQ.png" width="4000" height="2000" srcset="https://miro.medium.com/max/552/1*PhwQzf6DWMsCvXY3fYj3RQ.png 276w, https://miro.medium.com/max/1104/1*PhwQzf6DWMsCvXY3fYj3RQ.png 552w, https://miro.medium.com/max/1280/1*PhwQzf6DWMsCvXY3fYj3RQ.png 640w, https://miro.medium.com/max/1400/1*PhwQzf6DWMsCvXY3fYj3RQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*PhwQzf6DWMsCvXY3fYj3RQ.png?q=20"></p></div></div></div></figure><p id="bf23">Porting Envoy to the Windows platform has been a <a href="https://github.com/envoyproxy/envoy/issues/129" rel="noopener">goal of the project since 2016</a> and today we are excited to announce the Alpha release of Windows-native support for Envoy. The contributor community has been hard at work bringing Envoy’s rich feature set to Windows and this is another step in line with the project’s mission of making the network “transparent” to any application, regardless of language, architecture, or operating system.</p><p id="ddcf">Envoy is already in production use by a <a href="https://www.envoyproxy.io/#used-by" rel="noopener">wide range of companies</a> and Windows support should open up its usage to additional cloud-native services, legacy .NET applications, and a whole host of other application architectures. Particularly promising is the potential for users to deploy Envoy alongside Windows applications running in the datacenter or public cloud on Windows Server, in Windows-based containers, or even alongside desktop applications.</p><p id="29b7">The road to this Alpha announcement has been a long one but we hope we have done our part to improve the Envoy code base with cross platform code, new abstractions, and additional test coverage. If you are interested in a glimpse into the process of porting Envoy to Windows, take a look at this <a href="https://www.youtube.com/watch?v=FGBBeyZ-p1k&amp;ab_channel=CNCF%5BCloudNativeComputingFoundation%5D" rel="noopener">presentation from KubeCon 2019</a> and look out for the upcoming <a href="https://sched.co/ecca" rel="noopener">presentation at EnvoyCon 2020</a>. We would like to thank the Envoy maintainer team and especially Matt Klein and Lizan Zhou for enabling and supporting the Windows contributor group to reach this milestone.</p><p id="53b2">Alpha support for Envoy on Windows signifies the Envoy codebase has reached a stage where the contributor and maintainer community is confident it is stable enough on Windows for evaluation by the general public. General Availability (GA) release is also upcoming. We hope that by announcing this Alpha release, we can accelerate the process of collecting community feedback and contributions to push for a GA release.</p><p id="154a">As a result of getting to Alpha, Envoy compiles on Windows and tests are now required to pass in CI for every pull request and merged commit. In addition, there is a dedicated group of developers contributing to Windows, spending their time triaging reported issues and bugs, fixing CI failures and test flakes, and working with maintainers to ensure code quality and correctness (if you would like to get involved with this effort, see below!). The Alpha release does not signify that Envoy is suitable or supported for production workloads yet.</p><p id="1cf4">The project considers the master branch of the Envoy source repo to be release candidate quality at all times, and many organizations track and deploy master in production. As such, there is no “tagged” Alpha release commit, rather the master branch should be considered Alpha release quality on Windows until a GA release occurs. In general the Envoy codebase continues <a href="https://github.com/envoyproxy/envoy/graphs/code-frequency" rel="noopener">to move forward rapidly</a> so we recommend refreshing your source checkouts often to take advantage of the feedback and improvements from the contributor community.</p><h2 id="6167">Building From Source</h2><p id="b875">Currently Envoy Windows release binaries are not yet available and must be built from source. Documentation on setting up a build environment and compiling a statically linked Envoy executable from source on Windows with Bazel can be found <a href="https://github.com/envoyproxy/envoy/tree/master/bazel#building-envoy-with-bazel" rel="noopener">here</a>. We also provide a Windows Server 2019 Server Core based Docker container image with all required tools to build and statically link Envoy, see <a href="https://github.com/envoyproxy/envoy/blob/master/ci/README.md" rel="noopener">this document</a> for more details.</p><h2 id="77f9">Usage Example</h2><p id="5955">Once you have an Envoy binary and want to start getting familiar with using Envoy on Windows, a good place to start is <a rel="noopener" href="https://blog.envoyproxy.io/envoy-proxy-on-windows-containers-193dffa13050">this tutorial</a>. You will run through a modified version of the <a href="https://www.envoyproxy.io/docs/envoy/latest/start/start#sandboxes" rel="noopener">Front Proxy Sandbox</a> example that demonstrates the advantage of running Envoy collocated with your services: all requests are handled by the service Envoy, and efficiently routed to your services.</p><p id="16e4">Work on Windows support is still moving rapidly and as of this Alpha release most all core Envoy functionality should have parity with Linux. Service mesh support requires additional platform capabilities and we hope to enable this functionality with an upcoming release of Windows. <a href="https://www.envoyproxy.io/docs/envoy/latest/configuration/configuration" rel="noopener">Envoy configuration</a> and usage should not differ between platforms other than with common platform specific details like file paths, socket options, etc. That said, some existing features of Envoy were designed and implemented with Linux in mind first and as a result may be disabled on Windows or work in a limited capacity. You can find a list of Envoy APIs with <a href="https://github.com/envoyproxy/envoy/issues/13322" rel="noopener">degraded or disabled functionality on Windows here</a>.</p><p id="0382">We expect users and new contributors may run into known issues or new bugs others have reported. The <a href="https://github.com/envoyproxy/envoy/issues?q=is%3Aissue+label%3Aarea%2Fwindows+" rel="noopener">area/windows tag</a> in the Envoy issue tracker on GitHub and pulling the latest Envoy source from the master branch are great starting points if you encounter problems. Including “Windows:” in the title of any new issues and following the existing Envoy new issue templates will greatly help with triage. As always, PRs and issues are welcome to improve documentation in addition to Envoy source code.</p><p id="d78c">To get in touch with full-time contributors to Envoy on Windows about how to get more involved with the project, development details, and detailed user scenarios, visit the <a href="https://envoyslack.cncf.io/" rel="noopener">Envoy slack workspace</a> <em>#envoy-windows-dev</em> channel. We also hold a community meeting specifically for Windows contributors which you can find on the Envoy CNCF calendar <a href="https://goo.gl/PkDijT" rel="noopener">here</a>. In addition to Github issues, this weekly meeting is a good place to stay in the loop with and contribute to the Envoy roadmap on Windows. The <a href="https://groups.google.com/g/envoy-dev" rel="noopener">envoy-dev</a> and <a href="https://groups.google.com/g/envoy-announce" rel="noopener">envoy-announce</a> Google groups are two other avenues via which we may solicit feedback.</p><p id="ac23">We hope to lean on the community to get as much mileage as we can running Envoy on Windows and grow the community as we push forward to a GA release. Whether you would simply like to evaluate if Envoy suits your needs in a Windows environment or are interested in getting involved in active development on Windows, the project greatly appreciates detailed feedback. We look forward to collaborating with you and hearing how you use Envoy on Windows!</p></div></div></section></div></div>]]>
            </description>
            <link>https://blog.envoyproxy.io/announcing-alpha-support-for-envoy-on-windows-d2c53c51de7b</link>
            <guid isPermaLink="false">hacker-news-small-sites-24645007</guid>
            <pubDate>Wed, 30 Sep 2020 22:54:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Boost Debt Collection Using Machine Learning]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24644984">thread link</a>) | @umermirzapk
<br/>
September 30, 2020 | https://thinkml.ai/boost-collections-and-recoveries-using-machine-learning-p4/ | <a href="https://web.archive.org/web/*/https://thinkml.ai/boost-collections-and-recoveries-using-machine-learning-p4/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://thinkml.ai/content/images/size/w300/2020/09/ModelingDT.JPG 300w,
                            https://thinkml.ai/content/images/size/w600/2020/09/ModelingDT.JPG 600w,
                            https://thinkml.ai/content/images/size/w1000/2020/09/ModelingDT.JPG 1000w,
                            https://thinkml.ai/content/images/size/w2000/2020/09/ModelingDT.JPG 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 700px,
                            1400px" src="https://thinkml.ai/content/images/size/w2000/2020/09/ModelingDT.JPG" alt="Boost Debt Collection and Recovery using Machine Learning [part 4/5]">
            </figure>

            <section>
                <div>
                    <p>This is part-4 of the case study on Boost Debt Collections and Recoveries using Machine Learning (MLBR). A machine learning predictive model to enhance the current recovery system by creating focus groups for business to boost debt collection.</p><blockquote><em><em><em><em><u>Disclaimer:</u> This case study is solely an educational exercise and information contained in this case study is to be used only as a case study example for teaching purposes. This hypothetical case study is provided for illustrative purposes only and do not represent an actual client or an actual client’s experience. All of the data, contents and information presented here have been altered and edited to protect the confidentiality and privacy of the company.</em></em></em></em></blockquote><p>In <a href="https://thinkml.ai/boost-collections-and-recoveries-using-machine-learning-p1/">Part-1</a>, we looked at the background and the understanding of the debt collection and recovery process in credit lending companies. We looked at the entities/players involved in the traditional debt recovery process. We also defined the objective of our use case and highlights of the proposed machine learning solution.</p><p>In <a href="https://thinkml.ai/boost-collections-and-recoveries-using-machine-learning-p2/">Part-2</a>, we looked at the data elements and high level design. We also discussed the data collection process and design of the data pipeline. We also discussed the complex data variables created as result of feature engineering. We also discussed the importance of expert opinion in this complex case study. The value of expert opinion and how collection score turned out to be a significant key attribute in Modeling phase.</p><p>In <a href="https://thinkml.ai/boost-collections-and-recoveries-using-machine-learning-p3/">Part-3</a>, we discussed the modeling phase. We also explained the learning phase and the various data sets. How Training data set, Test data set and cross validation data set are prepared.</p><p>In this part, we will look at the comparison of various models results and the selection of the best model.</p><h3 id="4-6-1-3-selection-of-the-best-model-for-classification"><strong>4.6.1.3 &nbsp;</strong>Selection of the best model for Classification</h3><p>We trained three classification models, </p><ul><li>Support Vector Machine (SVM) </li><li>Decision Tree (DT) </li><li>Naïve Bayes (NB) </li></ul><p>“Training dataset” is used to train all three machine learning models. Once training is complete, we compared the statistics of all three models. </p><p><em>Recap on the data sets used:</em> </p><p>Multiple snapshots of LHD were created,</p><ol><li><strong><strong>Snapshot-0: </strong></strong>This is the historical snapshot of the database as of <strong><strong>31-Mar-2018</strong></strong>. It is further split into two datasetsa) &nbsp;<strong><strong>Training dataset:</strong></strong> 70% of the data from snapshot-0 is taken into training dataset at random. Purpose of this dataset is to train different models for prediction.b) &nbsp;<strong><strong>Testing dataset:</strong></strong> 30% of the data from snapshot-0 is taken into testing dataset at random. Purpose of this dataset is to test and compare all three models. This dataset is also used for first Cross Validation.</li><li><strong><strong>Snapshot-1:</strong></strong> This is the historical snapshot of the database as of <strong><strong>31-Mar-2019</strong></strong> (one year later).</li><li><strong><strong>Snapshot-2:</strong></strong> This is the historical snapshot of the database as of <strong><strong>31-Oct-2019</strong></strong> (almost one and half year later than snapshot-0).</li></ol><p>The data cutoff date for all snapshots are depicted below:</p><figure><img src="https://thinkml.ai/content/images/2020/09/image-11.png"><figcaption>Data cutoff for Training, Testing and Cross Validation Data sets</figcaption></figure><figure><img src="https://thinkml.ai/content/images/2020/09/image-9.png"><figcaption>Overall performance of all three models (after training)</figcaption></figure><figure><img src="https://thinkml.ai/content/images/2020/09/image-10.png"><figcaption>Performance Matrix for all three models (after training)</figcaption></figure><p>Decision tree model appears to have better overall accuracy on training dataset but Naïve Bayes turned out to be a better option on testing dataset. So, we choose Naïve Bayes for Cross Validation.</p><p>In next <a href="https://thinkml.ai/boost-collections-and-recoveries-using-machine-learning-p5/">part</a>, we will look at Cross Validation Result and Implementation.</p><p>Cheers :)</p>
                </div>
            </section>

            <section>
                <h3>Subscribe to ThinkML</h3>
                <p>Get the latest posts delivered right to your inbox</p>
                


            </section>

            

            

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://thinkml.ai/boost-collections-and-recoveries-using-machine-learning-p4/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24644984</guid>
            <pubDate>Wed, 30 Sep 2020 22:52:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My First Year as a Developer]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24644935">thread link</a>) | @josejorgexl
<br/>
September 30, 2020 | https://jj.hashnode.dev/my-first-year-as-a-developer | <a href="https://web.archive.org/web/*/https://jj.hashnode.dev/my-first-year-as-a-developer">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>It has been a year since I started to make money from building software. I don't call myself a developer, maybe one year making a living from programming is very similar to your definition of what a developer is, but I don't see the things in that way. However this could be the subject of another post. Here I will write about some of my first year experiences.</p>
<blockquote>
<p>I'll include some side notes like this one. I'll use these notes to briefly introduce some concepts and tools for those who are starting their programming journey right now.</p>
</blockquote>
<h2 id="rigidness-is-not-that-bad">Rigidness is not that bad</h2>
<p>When it comes to choosing a framework or a library there is often a lot of discussion. At some point in my evolution as a programmer I thought that flexibility is always good. After a bunch of lines of code I learned that rigidness is not that bad.</p>
<p>Frameworks, libraries, and tools in general are here because we are bad programmers by nature (among other causes). I really appreciate when a tool forces me to make things in a unique specific and very good way, so I can acomplish my goals by following that way.</p>
<p>In a smooth scenario, when definitions and requirements don't change abruptly during a week I always choose rigidness. I always choose the straight path.</p>
<h2 id="when-premises-dont-hold">When premises don't hold</h2>
<p>Then here I am, a guy that prefers the straight path in the middle of this jungle with no path at all. Definitions and requirements are changing every day in the most abrupt possible way and every week I am doing a very different project. I had to learn to embrace flexibility, in the hard way.</p>
<p>Now I am going to ilustrate that hard way through examples.</p>
<p>They decided to build a website using React. I learned React while doing the project so I started to consume a lot of tutorials. I decided to use <code>create-react-app</code> (CRA) to scafold the project since it is used in every single tutorial. So far, so good. I had a good workplace and was able to make the production build with a single command and so on.</p>
<blockquote>
<p>I highly recommend you to learn something while doing a project and, if possible, while getting paid for it. I think it is the best way to learn, at least when it comes to frameworks and tools in general.</p>
<p>CRA is a very useful way to get started with your React project. With just typing <code>npx create-react-app &lt;project-name&gt;</code> you get the whole project scafolding. I think every React developer can take advantage from this tool no matter if you are novice or senior. I won't complain about CRA, but I think some tutorials should warn us about the possible drawbacks resulting from using it.</p>
</blockquote>
<p>Then the boss learned what a Progressive Web App (PWA) is, and after a couple of weeks we were required to make the site progressive. This is not a big deal since CRA provides us with a service worker.</p>
<blockquote>
<p>PWA is a mechanism to make websites working offline and to behave like native apps in mobile devices, among other benefits. This is achieved with the colaboration of several components like the browser, a special script called service worker, a manifest file, and some code to install the service worker in the browser. As I said, CRA provides us with the required components in order we can make our React site progressive.</p>
</blockquote>
<p>Once you have a service worker in your site, you are able to receive push notifications from a server, and of course, after two weeks we were required to implement this too. But to make that possible you need to make some adjustments in the service worker and guess what, the CRA service worker is not customizable at all!</p>
<blockquote>
<p>Maybe you have encountered some sites that ask you whether you'd like to receive notifications. If you answer yes, they can send you the so called push notifications with the content they like. This notifications pop up in your device no matter that you have the browser closed. This is possible because the browser keeps the service worker script running in the background.</p>
</blockquote>
<p>Then I had to build a new service worker from scratch and the code to install it. That is not a big deal because I had have to do it no matter I had used CRA or not. So let's move to other issues.</p>
<p>After building the whole payment process, they decided that we needed to use some service that verifies your identity from some images of your face and of an identity document. So we needed to change a lot of things in the already built payment process. I made possible that the user could take a selfie, and take the picture of his ID document. But after that, we were required to use a specific SDK provided by the service in order to make the images to fulfill some features required for a reliable evaluation.</p>
<p>The SDK was a vanilla Javascript file that needed to be imported via HTML script tag. It is intended to be integrated in applications that use vanilla javascript. You know, the non-NodeJS one. So I needed to make the impossible to get everything working without making <code>eject</code>. After knowing about webpack, I'd like to go back in time and start my project from scratch, without using CRA or anything and taking care of my own webpack configuration. Belive me, this is just a single example because I don't want to make the story so long, I just want to make my point.</p>
<blockquote>
<p>Webpack is a tool that allows us to translate our NodeJS code into a vanilla javascript bundle that can be used in our production site. It's hard to master and that's why tools like CRA manage all the webpack related issues for you. But I haven't found a smooth enough way to make changes in the CRA webpack configurations, so I think that if you are facing the sort of complexities I am telling you about, you should consider using some more flexible tool (and then tell me what tool is that) or doing your own webpack configurations. CRA allows you to run <code>npm eject</code> and after that, you are by your own with webpack and everything, but I am not brave enough yet.</p>
</blockquote>
<p>My first task in this company, before the React website I have written about above, was to build a responsive website. After a lot of effort and passing through all sort of dificulties, the site have never been used. Yes, I got paid, but this post is not about making money, this post is about what I think is wrong.</p>
<h2 id="what-i-would-do">What I would do</h2>
<p>The problem here is not the changing. There are always unstable scenarios, businesses that are unstable by nature, or at least that become unstable due to new events. The problem is the rush in the decision making, the lack of connection between developers and the business men and the misconception by some of those business men that the cost of developing is negligible.</p>
<p>I think you just learn about good programming practices when you find yourself repeating the same code everywhere and fixing the same bug in diferent places. Well, with this experience I have learned the necessity of planning and writing. You need to define your problem and to write down that definition. You need to keep a record of your requirements, and even keep a record of the infrastructure you need in order to fulfill those requirements.  I don't like to overthink, but it's just a lack of common sense thinking that you can get something by just hitting the keys when the project is complex enough.</p>
<p>The problem is not the need to make big changes in the project per se. But if you can include those changes in the initial plan then they are not changes but initial requirements, and the developing process is faster, cleaner and no one do fruitless job. The sooner the change is predicted, the smaller and the easier the refactoring.</p>
<h2 id="conclusions">Conclusions</h2>
<p>Those have been some of my experiences in this firs year as a developer. I'll certainly write about some others, don't think everything have been that painful.</p>
<p>I hope you or your boss don't be suffering the WIPCA syndrome (Why Isn't Paul Coding Anything?!). So always try to write your problem definition, the requirements and everything you think is necessary, like the infrastructure. No matter if you are using Scrum, Waterfall or whatever. Just write a little bit and try to make changes, which will always be needed, less painful. Of course this only applies to complex enough projects, but don't underestimate projects, actually a way to assert whether a project is complex enough is defining the problem and the requirements.</p>
<p>If you liked this post hit the like button. Feel free to comment whatever you want. You can also follow me on Twitter for debates about Computer Science.</p>
</div></div>]]>
            </description>
            <link>https://jj.hashnode.dev/my-first-year-as-a-developer</link>
            <guid isPermaLink="false">hacker-news-small-sites-24644935</guid>
            <pubDate>Wed, 30 Sep 2020 22:46:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A wearable sensor for people with inflammatory bowel disease]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24644672">thread link</a>) | @finphil
<br/>
September 30, 2020 | https://nuadox.com/post/630721968777396224/wearable-sensor-ibd | <a href="https://web.archive.org/web/*/https://nuadox.com/post/630721968777396224/wearable-sensor-ibd">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 
                 
                    
                    <article id="630721968777396224">
                        <div>
                            <div>
                                <a href="https://nuadox.com/post/630721968777396224/wearable-sensor-ibd"><h2>A wearable sensor for people with inflammatory bowel disease</h2></a>
                                <figure data-orig-width="1440" data-orig-height="1080"><img src="https://64.media.tumblr.com/8437b22213729d2768464edb697ca740/317dd0b354885cc7-93/s1280x1920/ae1679bff7d4419d3646dd55cd062ce8c187ed01.jpg" alt="image" data-orig-width="1440" data-orig-height="1080" width="1280" height="960"></figure><p><b>- By <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.utdallas.edu%2Fnews%2Fmedia-contact%2Fkim-horner%2F&amp;t=YjAyYjExMDkwMjhkOThlM2RmY2FmM2JhYjdkOWZhOTA0ZWYzNjQ3MywxUEdHTm4yMA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F630721968777396224%2Fwearable-sensor-ibd&amp;m=0&amp;ts=1601773712">Kim Horner</a> ,&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.utdallas.edu%2F&amp;t=ODFiOGI3NDg1ZDhkZjM0MjU0N2E4ZTgwZDliYjhiYTlmYTczNTEwNSwxUEdHTm4yMA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F630721968777396224%2Fwearable-sensor-ibd&amp;m=0&amp;ts=1601773712">University of Texas at Dallas</a> -</b></p><p>University of Texas at Dallas researchers have designed a wearable device that monitors sweat for biomarkers that could signal flare-ups of inflammatory bowel disease (IBD).</p><p>A team of bioengineers demonstrated the wristwatch-like device in a proof-of-concept study funded by the Crohn’s &amp; Colitis Foundation and published online July 28 and in the October print edition of the foundation’s journal, <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Facademic.oup.com%2Fibdjournal%2Fadvance-article-abstract%2Fdoi%2F10.1093%2Fibd%2Fizaa191%2F5877396&amp;t=ZGU3MzNiODRkYzM3NDcxZThmZGY0ZWUwNjg0NTk5NWJhYTMzZTVmMywxUEdHTm4yMA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F630721968777396224%2Fwearable-sensor-ibd&amp;m=0&amp;ts=1601773712"><i>Inflammatory Bowel Diseases</i></a>.</p><p>A sensor in the device detects and quantifies the presence of two key biomarkers associated with inflammatory bowel disease: interleukin-1β and C-reactive protein (CRP). The study is the first to establish that CRP is present in human sweat and the first to show that the two biomarkers can be detected in sweat.</p><p><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Futdallas.edu%2Fchairs%2Fprofiles%2Fdr-shalini-prasad%2F&amp;t=YjgzZGFlZGU3MjE4YjcyOGU2NjViZjA0OWUwNzAwZGZkMTdlNGJmOSwxUEdHTm4yMA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F630721968777396224%2Fwearable-sensor-ibd&amp;m=0&amp;ts=1601773712">Dr. Shalini Prasad</a>, department head and professor of <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fbe.utdallas.edu%2F&amp;t=N2Q0ZTIyYmY5NDA4MWI0Y2M5NjkxYjgyYmIyYzQyMDJkMGVkOGNkYSwxUEdHTm4yMA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F630721968777396224%2Fwearable-sensor-ibd&amp;m=0&amp;ts=1601773712">bioengineering</a> in the <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fengineering.utdallas.edu%2F&amp;t=YzNlMzg3NDg2ZDc5MDYzNmUwYmM3ZDMwMTEyNDdiMDgzNTgxNDU4MSwxUEdHTm4yMA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F630721968777396224%2Fwearable-sensor-ibd&amp;m=0&amp;ts=1601773712">Erik Jonsson School of Engineering and Computer Science</a> and the study’s principal investigator, said the technology could provide a warning but not a diagnosis of inflammatory bowel disease. The ultimate goal of the work is to develop a device to help patients gain more control over IBD, which can be unpredictable.</p><p>“It’s like the check-engine light in a car,” said Prasad, the Cecil H. and Ida Green Professor in Systems Biology Science. “The warning signal doesn’t mean a patient is having a flare-up, but it could give the person the chance to intervene earlier, when the symptoms may be more responsive to treatment. The device also could help doctors understand sooner whether a treatment is working.”</p><p>The researchers monitored the levels of the two biomarkers in 20 healthy volunteers to show that the biomarkers could be tracked and to establish the levels of biomarkers in people without IBD.</p><p>The researchers used what is called passive sweat, which means that the wearer did not need to engage in physical activity or have their sweat glands expressed to generate a sample. The sweat is collected on a removable strip incorporated into the wrist device that must be changed daily. That the device collects passive sweat is important because people with IBD may be unable to exercise at levels needed to generate active sweat, Prasad said.</p><p>The prototype will be tested on patient volunteers in a second phase of the research, also funded by the foundation, and must undergo further testing before it can become available to patients.</p><p>The device has the potential to track other diseases and conditions marked by an inflammatory response. Prasad’s team is investigating whether it could alert people to increases in cytokines, which are proteins released by the immune system at the early stages of a viral infection, such as COVID-19.</p><p>Prasad’s team previously developed a <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.utdallas.edu%2Fnews%2Fscience-technology%2Fbioengineers-improve-diabetes-monitors-versatility%2F&amp;t=MTUwNDY0MzFkM2IwMDdjYjllNDM1Nzk4Y2YyYzg0ZDAwNTE1NGM1NCwxUEdHTm4yMA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F630721968777396224%2Fwearable-sensor-ibd&amp;m=0&amp;ts=1601773712">biosensor</a> that analyzes sweat to detect levels of certain chemicals, such as glucose and cortisol, that could indicate diabetes. In 2014 she co-founded a company called <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fenlisense.com%2F&amp;t=ZDUyYjMyMjM1Njg3OWJmYmM0ZjBlN2U3MDFkMTgwM2I0MTExZWZhYiwxUEdHTm4yMA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F630721968777396224%2Fwearable-sensor-ibd&amp;m=0&amp;ts=1601773712">EnLiSense</a> in Allen, Texas, to develop lifestyle-based sensors and devices. Based on Prasad’s successful work on the glucose tracker, the Crohn’s &amp; Colitis Foundation partnered with her to apply the concept to develop a noninvasive monitor for IBD, said Dr. Gerard Honig, associate director of research innovation for the foundation.</p><p>“We’ve seen extraordinary revolutions in a number of fields, such as bioengineering, and dramatic events relating to medical devices, and we have not necessarily seen those ideas applied to IBD,” Honig said.</p><p>IBD, which affects millions of people in the U.S., is characterized by chronic or recurring immune response wherein the cells lining the intestines are attacked when the body mistakes food, bacteria and other materials for foreign substances, causing inflammation. Symptoms include fatigue and abdominal pain, with diarrhea in patients with Crohn’s disease and stool urgency in those with ulcerative colitis.</p><p>Currently, doctors measure intestinal inflammation through endoscopy, which involves the insertion of a long, thin tube into the body to view internal organs or tissue. The procedure is too invasive to be feasible for frequent monitoring of the disease, which creates challenges in recruiting patients for clinical drug trials, Honig said.</p><p>“A wearable microsensor device would have the potential to empower patients to be actively engaged in monitoring their disease and managing it,” Honig said. “It would greatly facilitate clinical research and potentially could be used in the long term to facilitate proactive management, where you have a target biomarker level you’re trying to achieve over a certain period of time and you optimize care to get there.”</p><p>–</p><p><i>Header image:&nbsp;UT Dallas researchers designed a prototype of a wristwatch-like device that detects two key biomarkers associated with inflammatory bowel disease. Credit:&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.utdallas.edu%2Fnews%2Fscience-technology%2Fwearable-sensor-ibd-2020%2F&amp;t=NzI5N2E1NDQwMTkzODcxNmIzN2I3MWMxODlmYzUzNjRmNWJjMTY1OCwxUEdHTm4yMA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F630721968777396224%2Fwearable-sensor-ibd&amp;m=0&amp;ts=1601773712">University of Texas at Dallas</a>.</i></p><p><b>Source:&nbsp;

<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.utdallas.edu%2Fnews%2Fscience-technology%2Fwearable-sensor-ibd-2020%2F&amp;t=NzI5N2E1NDQwMTkzODcxNmIzN2I3MWMxODlmYzUzNjRmNWJjMTY1OCwxUEdHTm4yMA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F630721968777396224%2Fwearable-sensor-ibd&amp;m=0&amp;ts=1601773712">University of Texas at Dallas</a></b></p><p><b>Full study:</b>&nbsp;“A Sweat-based Wearable Enabling Technology for Real-time Monitoring of IL-1β and CRP as Potential Markers for Inflammatory Bowel Disease”,&nbsp;<i>Inflammatory Bowel Diseases</i>.</p><p><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fdoi.org%2F10.1093%2Fibd%2Fizaa191&amp;t=ZGY4ZTVmYWMyNjg0MDJlN2IyMDBkMWUwMDEzYjUxNmM0YTg5Y2JmNSwxUEdHTm4yMA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F630721968777396224%2Fwearable-sensor-ibd&amp;m=0&amp;ts=1601773712">https://doi.org/10.1093/ibd/izaa191</a><br></p><h2><b>Read Also</b></h2><p><a href="https://nuadox.com/post/178125297442/new-wearable-ultrasound-patch-ucsd">New wearable ultrasound patch non-invasively monitors blood pressure in arteries</a></p>
                    
                      
                    
                    
                    
                    
                    
                    
                    
                    
                                             
                                <p><span>
                                    <p>
                                    
                                        <a href="https://nuadox.com/tagged/smart-wristband">smart wristband</a>
                                    
                                        <a href="https://nuadox.com/tagged/inflammatory-bowel-disease">inflammatory bowel disease</a>
                                    
                                        <a href="https://nuadox.com/tagged/ibd">ibd</a>
                                    
                                        <a href="https://nuadox.com/tagged/wearables">wearables</a>
                                    
                                        <a href="https://nuadox.com/tagged/healthcare">healthcare</a>
                                    
                                        <a href="https://nuadox.com/tagged/health-tech">health tech</a>
                                    
                                        <a href="https://nuadox.com/tagged/health">health</a>
                                    
                                        <a href="https://nuadox.com/tagged/iot">iot</a>
                                    
                                        <a href="https://nuadox.com/tagged/internet-of-things">internet of things</a>
                                    
                                        <a href="https://nuadox.com/tagged/biosensor">biosensor</a>
                                    
                                        <a href="https://nuadox.com/tagged/biotech">biotech</a>
                                    
                                        <a href="https://nuadox.com/tagged/biotechnology">biotechnology</a>
                                    
                                        <a href="https://nuadox.com/tagged/gastroenterology">gastroenterology</a>
                                    
                                    </p>
                                </span></p>
                                
<ol><!-- START NOTES --><!-- END NOTES --></ol></div>
                        </div>
                    </article>
                 
                </div></div>]]>
            </description>
            <link>https://nuadox.com/post/630721968777396224/wearable-sensor-ibd</link>
            <guid isPermaLink="false">hacker-news-small-sites-24644672</guid>
            <pubDate>Wed, 30 Sep 2020 22:18:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Secrets detection learning center: complete handbook for dev, SEC, ops]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24644392">thread link</a>) | @mackenzie-gg
<br/>
September 30, 2020 | https://www.gitguardian.com/secrets-detection | <a href="https://web.archive.org/web/*/https://www.gitguardian.com/secrets-detection">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.gitguardian.com/secrets-detection</link>
            <guid isPermaLink="false">hacker-news-small-sites-24644392</guid>
            <pubDate>Wed, 30 Sep 2020 21:49:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dissecting Lemire’s nearly divisionless random]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24644370">thread link</a>) | @bbgm
<br/>
September 30, 2020 | https://veryseriousblog.com/posts/dissecting-lemire | <a href="https://web.archive.org/web/*/https://veryseriousblog.com/posts/dissecting-lemire">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-74174200445ef6e30546"><div><p>This blog post is very late. It’s well over a year since<a href="https://twitter.com/colmmacc/status/1153727018896244736"> I posted a coding challenge on twitter</a>. The idea was simple, I’ve always felt that code readability is undervalued so I figured I’d put cold hard cash up. I announced a $1,000 pot, divided into $500, $300, and $200 prizes for the most readable implementations of <a href="https://lemire.me/blog/2019/06/06/nearly-divisionless-random-integer-generation-on-various-systems/">Daniel Lemire’s nearly divisionless algorithm for selecting a random number from an interval.</a> I now have winners to announce and congratulate, and they’re in this blog post, but there’s more to this story.</p><p>I didn’t know it at the time but I’d end up reviewing the entries with colleagues to see if they could follow what was happening (spoiler: they couldn’t). When people got stuck, we’d whiteboard&nbsp;our way through so that we could better understand why and where people were getting stuck. Oh, to be able to whiteboard in person again!  </p><p>I learned a lot about how people think through problems, and that process led to me writing a seperate implementation of Lemire’s Algorithm, with a twenty-to-one comment to code ratio (that’s a lot of comments), and finding a sort-of security issue with the algorithm in the process. I say “sort of” because you really have a ridiculously enormous struggle to find a case where it’s going to be practical to exploit. But it still surprised me, and you probably can’t use Lemire’s algorithm in Vegas.</p><h4>Why Lemire’s Algorithm?</h4><p>I chose Lemire’s algorithm because it is brilliant. When I read Lemire’s code I get that kind of brain-tingling and gawk at the sheer “How on earth did someone think of this” of it all. Lemire has a mastery of code and how code is executed, and then pairs that with transcendent creativity and concision.  Lemire also writes well, and the papers that accompany his code and algorithms are easily some of the most cogent and approachable you’ll find in academia. They are short and clear and avoid the jargon and obtuseness that plagues the field, while containing just enough formalism to be rigorous.</p><p>Lemire’s algorithm is a solution to the problem “Give me a random number between 0 and N, not including N itself”. For simulating a dice, N would be 6 and you’d get back either 0, 1, 2, 3, 4, or 5 with equal probability. Computers like to start at zero. We can always add one to the result to get the familiar results you’d get on a real dice. I’ve worked on random number generators and written quite a few. In 20 years of doing that, I’d never come across a solution as cool as Lemire’s.</p><p>Before Lemire, the best-known solutions to this problem required one or two divisions per number generated. You probably learned long division when you were quite young. You may remember that it can be get pretty tedious and cumbersome. It’s the same for computers. Division is actually one of the slowest things we can ask a computer to do. Lemire avoids division by translating numbers into a much larger number “space” and using binary-friendly powers-of-two operations instead. His technique almost always avoids needing a division.</p><p>The second reason I chose Lemire’s algorithm is that it is impenetrable upon first reading. There are lucky few people who are so practiced and conversant in number manipulation that they can see inside of algorithms like Neo in the matrix, but I don’t mean them. To the average reader, myself included, it’s not clear what’s going on and why.</p><p>Lemire’s reference code is fourteen lines long, like a sonnet. Twelve of the lines are simple, and any proficient programmer could tell <em>what</em> they are doing. Two specific lines of the code are pretty hard to decipher.. But the real difficulty is how hard it is to understand <em>why</em> all 14 lines are doing what they are doing, and <em>why</em> it results in a fair and correct algorithm for choosing a random number.</p><div><p>As a case in point, if you read the comments to Lemire’s blog, you’ll find several misunderstandings of the code. That’s within an audience of primed Lemire fans and critics who are familiar with the field. <a href="https://arxiv.org/abs/1805.10941">Lemire’s accompanying paper</a> is great and very readable, but it still takes effort and concentration to follow everything. I work on cryptography and write cryptographic code for a living and I’m not ashamed to tell you it took me about 3 readings to really get it. The algorithm is based on an interaction between two modular spaces, one of which is sized 2 to power of 64, and the other is “N” sized, and if I just totally lost you there, I beg forgiveness and if you bear with me I promise there’s a link to my detailed dissection of how and why everything works. </p><p>All of this makes Lemire’s algorithm a really good challenge for creating a more readable version. Ideally something that an average coder can read in one pass, understand, and agree that it’s correct. </p></div><h4>Why does readability matter?</h4><p>Code readability is the most important pillar of code correctness and maintainability. When code is unreadable, it is harder to spot errors. That’s true when you’re doing a code review and it’s even more true when you’re adding more code to an existing code base. Great testing can compensate for some of the correctness challenges, but it doesn’t do as much for maintainability. </p><p>In s2n, one of our <a href="https://github.com/awslabs/s2n/blob/main/docs/DEVELOPMENT-GUIDE.md">development principles</a> is to write clear readable code with a light cognitive load. We’re serious about it, and I wasn’t going to try and use Lemire’s algorithm in s2n without a very readable implementation.</p><p>Working in software development I’ve heard the opinion more than once about how programmers and coders should be more familiar with the fundamental mathematics of logic and number theory that underpin their field, and that academic style papers and explanations should be sufficient. I happen to work with teams that are made up of both expert coders and expert mathematicians, and even there I don’t think this is a good idea.</p><p>Software engineering is engineering, which means translating science into solutions that work in the real world.  To wildly generalize, there are better dividends to be found in focusing on deepening ones understanding of the “real world” part of that, the users, the customers, the business models, usability, ergonomics, and so on, than on the “science” part of that. Some science is needed, but there’s a shallow limit. Just as a civil engineer doesn’t need too detailed an understanding of the chemistry of concrete. PHs and setting times, but not quantum numbers.</p><p>Code should be self-documenting. The average programmer, including someone straight out of college, should be able to understand and work on a well put-together codebase. This greatly improves the odds of finding problems, and that’s what matters. </p><h4>The contest</h4><p>One of the reasons I’ve been so tardy about this blog post is that the contest didn’t go as I’d expected. </p><p>Let’s start with the great thing that happened. I got several submissions, more than enough to pick winners from. Many of these submissions are good and do improve upon Lemire’s code. The most common improvement was to use more descriptive names for the variables. Lemire uses variable names such as “s”, “t”, “l” which seemingly don’t correspond to much. In such a short piece of code, this actually isn’t too big an offense. I kept these terms in my own implementation, because I want to be consistent with the paper, but it’s absolutely a valid improvement. Another great improvement is to write and include tests, which is really an essential part of software development. </p><p>The first place <a href="https://github.com/ziglang/zig/blob/98183e47436699f6e5eab200061c46eec342806e/std/rand.zig#L74-L118">winner</a> did both of these, and also cleared up some of the confusing lines of code by making an implicit truncation explicit. According to GitHub the winner had 5 contributors, but twitter user <a href="https://twitter.com/komu_wairagu/status/1161643573223317504">komu_wairagu</a> submitted it, so that’s who I’ll be contacting to Venmo $500.</p><p>The second place <a href="https://github.com/nimia/Lemire_RNG">winner</a> comes from <a href="https://twitter.com/NimrodAviram">Nimrod Aviram</a>, who I know professionally as the discoverer of the DROWN vulnerability and fun person to hang out with at RealWorldCrypto. Nimrod’s implementation includes some great testing too.</p><p>The third place winner wants to stay anonymous, and cheated their way to some bonus points by writing a great implementation in LISP. How can you not love that? If they change their minds about anonymity I’ll update this post with a link. The sha256 checksum of their implementation is ae008644b2f0b10eddbbce3a0508b103b19925e4e0c9354c569ff0816acb760c. </p><p>Now on to the not as great, and one of the reasons I’ve taken this long to write. It doesn’t feel right to criticize any of these efforts, made in spare time and as part of a fun challenge I put out there, but none of them actually explained Lemire’s algorithm or broke down how and why it worked. I asked several colleagues to look through these implementations and tell me if they understood what was going on, and the response was a uniform zero. Noone could fully understand even one of the implementations, or Lemire’s original.  When I asked people to also read the paper, things got a bit better, but everyone still seemed to trip on some issues.  These are smart people who absolutely know what they are doing. I’m sure given more time they could fully understand everything, but that wasn’t the goal. The goal was to have understanding after one or two, or at most just a few, readings.</p><h4>What did people find hard to follow?</h4><p>Talking through things with people I found some common problems. Some directly in the code, and others in the paper. The first line of code that threw people was:</p><pre><code>uint64_t l = ( uint64_t ) m;</code></pre><p>This line of code does an unusual operation called truncation. It takes a 128-bit value “m” and truncates that to its least significant 64-bits. All of this is implicit in the code, rather than explicit. Reading the code, you have to recall that m is 128-bits. Then there’s also the question of why are we doing this truncation? I’ll leave that for a minute. </p><p>The next problematic line of code was:</p><pre><code>uint64_t t = -s % s;</code></pre><p>This line of code is using an unusual combination of unary negation, on an unsigned int, and the modulus operator.  Nobody remembers what unary negation does to an unsigned int - and why should they …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://veryseriousblog.com/posts/dissecting-lemire">https://veryseriousblog.com/posts/dissecting-lemire</a></em></p>]]>
            </description>
            <link>https://veryseriousblog.com/posts/dissecting-lemire</link>
            <guid isPermaLink="false">hacker-news-small-sites-24644370</guid>
            <pubDate>Wed, 30 Sep 2020 21:48:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Netflix 4K UHD Streaming requires Apple's T2 chip]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24644228">thread link</a>) | @aunali1
<br/>
September 30, 2020 | https://www.iphoneincanada.ca/news/how-to-stream-netflix-in-4k-on-mac/ | <a href="https://web.archive.org/web/*/https://www.iphoneincanada.ca/news/how-to-stream-netflix-in-4k-on-mac/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>


<!-- .entry-social-links -->
<div>
	
	
	
		
		
	
<!-- .entry-social-links -->	
		
		
	<div>
	<p>Netflix has finally made its 4K Ultra HD content available to stream on Mac, albeit not everyone will be able to benefit from that. As mentioned on the&nbsp;<a href="https://help.netflix.com/fr-ca/node/55764">Netflix Ultra HD support page</a>, 4K streaming only works on&nbsp;select 2018 or later Mac computers with an Apple T2 Security chip (via <em><a href="https://www.macg.co/mac/2020/09/netflix-en-4k-sur-mac-uniquement-pour-les-machines-avec-puce-t2-116775">MacGeneration</a></em>).</p>
<p><img title="netflix log.png" src="https://cdn.iphoneincanada.ca/wp-content/uploads/2020/09/netflix-log.png" alt="Netflix log" width="640" height="272"></p>	
	
	
	
<p>In addition to a T2 chip Mac, you also need the latest version of Safari running on macOS Big Sur, a screen capable of displaying a 4K 60Hz image (compliant with the HDCP 2.2 standard in the case of an external screen), and a subscription plan that supports Ultra HD streaming.</p>
<p>Here’s an interesting take on the T2 chip requirement from a <a href="https://www.reddit.com/r/apple/comments/j2cik9/youll_need_a_mac_with_a_t2_chip_to_be_able_to/">Reddit</a> user:</p>
<blockquote>
<p><em>“This makes zero sense to me. The only Macs, that could really benefit from 4k streaming, without an external monitor, are the 4k and 5k iMacs yet only 2 models (the Pro and the new 2020 27″) will be able to stream it. Windows machines don’t have any kind of T2 alternative and are still able to stream 4k via Edge or via the native app, their only requirement is a 7th gen intel cpu or a dedicated graphics card.”</em></p>
</blockquote>
<p>Below is the&nbsp;list of Macs compatible with 4K Netflix streaming:</p>
<ul>
<li>iMac Pro (late 2017)</li>
<li>Mac mini (late 2018)</li>
<li>MacBook Air ( 2018 and up)</li>
<li>MacBook Pro (2018 and up)</li>
<li>Mac Pro (2019)</li>
<li>iMac (2020)</li>
</ul>
<p>What do you guys think of the T2 chip requirement for streaming Netflix in Ultra HD?</p>

	</div>

</div><!-- .entry-inner -->
</article></div>]]>
            </description>
            <link>https://www.iphoneincanada.ca/news/how-to-stream-netflix-in-4k-on-mac/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24644228</guid>
            <pubDate>Wed, 30 Sep 2020 21:36:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Is Good Retention]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24643994">thread link</a>) | @cwaffles
<br/>
September 30, 2020 | https://www.lennyrachitsky.com/p/what-is-good-retention-issue-29 | <a href="https://web.archive.org/web/*/https://www.lennyrachitsky.com/p/what-is-good-retention-issue-29">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>Hello, and welcome to the&nbsp;<strong>free monthly edition&nbsp;</strong>of my weekly newsletter. I’m&nbsp;<a href="https://twitter.com/lennysan">Lenny</a>, and each week I tackle reader questions about product, growth, working with humans, and anything else that’s stressing you out at the office.</em></p><p><em><strong>If you’re not a paid subscriber, here’s what you missed this month:</strong></em></p><ol><li><p><em><a href="https://www.lennyrachitsky.com/p/interviewing-users-for-product-market">How to find out if you have product-market fit</a></em></p></li><li><p><em><a href="https://www.lennyrachitsky.com/p/taking-responsibility-for-a-failed">How to communicate bad news to your boss</a></em></p></li><li><p><em><a href="https://www.lennyrachitsky.com/p/prioritizing-across-conversion-opportunities">Tips for prioritizing amongst conversion opportunities</a></em></p></li></ol><p>I’m very excited about this week’s post, so let’s get to it.</p><blockquote><p><em>"Great retention is THE scalable way to grow a product. It's the best indicator of product-market fit, it is the most important factor in a user’s lifetime value, and high retention drives all of the best acquisition strategies. It's growth's equivalent of the triple-word-score."</em></p><p>— <a href="https://twitter.com/onecaseman">Casey Winters</a></p></blockquote><p><strong>Although retention is widely considered to be the most important metric to get right when building (and investing in) a business, it’s also one of the least understood.</strong> Why? Because unless you’re a growth expert or an experienced investor, you’re often relying on anecdotes, dated blog posts, and misguided benchmarks. I ran into this problem myself many times when working with startups.</p><p>So when <a href="https://www.linkedin.com/in/caseywinters">Casey Winters</a> (former head of growth at Pinterest, GrubHub, and now CPO at Eventbrite) brought up this question in a conversation we were having, we decided to take the opportunity to do some new research. Together, we reached out to twenty of the most experienced growth practitioners we knew and asked them two simple questions:</p><ol><li><p><strong>What do you consider GOOD and GREAT user retention (at 6 months)</strong>?</p></li><li><p><strong>What do you consider GOOD and GREAT net revenue retention (at 12 months)</strong>?</p></li></ol><p>Taking these insights and combining them with available public data, <strong>we’ve come up with a set of concrete recommendations for GOOD and GREAT retention across most types of businesses</strong>. Below you’ll find a visual summary of these conclusions, along with detailed recommendations from each of the experts, and public comps from many of today’s biggest companies.</p><p>As a companion to this post, <a href="https://caseyaccidental.com/what-is-good-retention">Casey also published an essay</a> delving into ways to increase retention, amongst other topics, which you should definitely check out.</p><p>Without further ado, let’s dive in.</p><h2><strong>What is GOOD and GREAT retention?</strong></h2><h4><strong>GOOD and GREAT User Retention</strong></h4><ul><li><p><strong>Consumer Social:</strong> ~25% is GOOD, ~45% is GREAT</p></li><li><p><strong>Consumer Transactional</strong>:  ~30% is GOOD, ~50% is GREAT</p></li><li><p><strong>Consumer SaaS:</strong> ~40% is GOOD, ~70% is GREAT</p></li><li><p><strong>SMB / Mid-Market SaaS:</strong> ~60% is GOOD, ~80% is GREAT</p></li><li><p><strong>Enterprise SaaS:</strong> ~70% is GOOD, ~90% is GREAT</p></li></ul><h4><strong>GOOD and GREAT Net Revenue Retention</strong></h4><ul><li><p><strong>Consumer SaaS:</strong> ~55% is GOOD, ~80% is GREAT</p></li><li><p><strong>Bottom-Up SaaS:</strong> ~100% is GOOD, ~120% is GREAT</p></li><li><p><strong>Land and Expand VSB SaaS:</strong> ~80% is GOOD, ~100% is GREAT</p></li><li><p><strong>Land and Expand SMB / Mid-Market SaaS:</strong> ~90% is GOOD, ~110% is GREAT</p></li><li><p><strong>Enterprise SaaS:</strong> ~110% is GOOD, ~130% is GREAT</p></li></ul><p>Here’s a handy visual guide, which links to a high-res PDF:</p><p><a target="_blank" href="https://www.dropbox.com/s/h6p02vvmyxxonzy/What%20is%20good%20retention%20.pdf?dl=0"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F56c42120-3472-426c-bc68-6498d214944a_2550x2944.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/56c42120-3472-426c-bc68-6498d214944a_2550x2944.png&quot;,&quot;height&quot;:1681,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:617828,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:&quot;https://www.dropbox.com/s/h6p02vvmyxxonzy/What%20is%20good%20retention%20.pdf?dl=0&quot;}" alt=""></a></p><h2><strong>Big thank you to the experts</strong></h2><p><strong><a href="https://www.linkedin.com/in/adamjfishman/">Adam Fishman</a></strong> (Patreon, Imperfect Foods), <strong><a href="https://twitter.com/andrewchen">Andrew Chen</a></strong> (Uber, a16z), <strong><a href="https://www.linkedin.com/in/andrewjohns/">Andy Johns</a></strong> (Twitter, Facebook, Wealthfront), <strong><a href="https://brianbalfour.com/">Brian Balfour</a></strong> (Reforge), <strong><a href="https://brianrothenberg.com/)">Brian Rothenberg</a></strong> (Eventbrite, TaskRabbit), <strong><a href="https://www.linkedin.com/in/chenliw/">ChenLi Wang</a></strong> (Dropbox), <strong><a href="https://twitter.com/danhockenmaier">Dan Hockenmaier</a></strong> (Thumbtack), <strong><a href="https://www.linkedin.com/in/elenaverna/">Elena Verna</a></strong> (SurveyMonkey, Miro), <strong><a href="https://www.linkedin.com/in/fareed/">Fareed Mosavat</a></strong> (Slack), <strong><a href="https://twitter.com/jamiequint?lang=en">Jamie Quint</a></strong> (Notion, Reddit), <strong><a href="https://www.linkedin.com/in/jeff-chang-82467459/">Jeff Chang</a></strong> (Pinterest), <strong><a href="https://www.linkedin.com/in/julieyizhou/">Julie Zhou</a></strong> (Hipmunk, Yik Yak, AdRoll), <strong><a href="https://www.linkedin.com/in/kevinakwok/">Kevin Kwok</a></strong> (Greylock), <strong><a href="https://twitter.com/ljin18">Li Jin</a></strong> (a16z), <strong><a href="https://www.linkedin.com/in/merci/">Merci Grace</a></strong> (Slack), <strong><a href="https://twitter.com/mduboe">Mike Duboe</a></strong> (Stitch Fix, Greylock), <strong><a href="https://www.linkedin.com/in/naomipilosofionita/">Naomi Ionita</a></strong> (Evernote, Menlo Ventures), <strong><a href="https://www.linkedin.com/in/nicksoman/">Nick Soman</a></strong> (Gusto, Decent), <strong><a href="https://twitter.com/saranormous">Sarah Guo</a></strong> (Greylock), <strong><a href="https://www.linkedin.com/in/shaun-clowes-80795014">Shaun Clowes</a></strong> (Atlassian, MuleSoft), and <strong><a href="https://www.linkedin.com/in/yuriytimen/">Yuriy Timen</a></strong> (Grammarly). And of course, my incredible partner on this research, <strong><a href="https://www.linkedin.com/in/caseywinters">Casey Winters</a></strong>.</p><h3><strong>Disclaimer: Why it may be OK for your retention to be low</strong></h3><p>To some, these retention benchmarks will seem high. This is because the bar to build a massively successful business is high. Frankly, it’s why most startups fail. However, although<strong> retention is an important metric to get right, it doesn’t live in vacuum</strong>. There are cases where a lower retention rate is OK:</p><ol><li><p><strong>You’re just starting out:</strong> Don’t despair if you don’t see this level of retention immediately. Use these benchmarks a guide to prioritize between retention vs. acquisition, and <a href="https://caseyaccidental.com/what-is-good-retention">read Casey’s post</a> for three ways to approach increasing retention. But just know, startups rarely increase retention significantly.</p></li><li><p><strong>You have low CAC and marginal costs: </strong>Growth is a balancing act between CAC, retention, and unit economics. If you can acquire new users cheaply (e.g. SEO, WOM, or virality), you can afford to lose more users. <a href="https://twitter.com/danhockenmaier/status/1270376412642373633">This thread by Dan Hockenmaier</a> explains why low retention for businesses like Shopify and Twitter is OK. </p></li><li><p><strong>You’re not building a venture-scale business:</strong> These benchmarks are coming from people who helped build iconic, massively scalable, businesses. This level of retention is <em>not</em> required for product/market fit, or to build a sustainable business. Though the upside will be limited, a flat retention curve that drives a scalable acquisition strategy is enough to keep your business alive.</p></li></ol><blockquote><p><strong>Ultimately,  what matters is that your retention supports sustained growth. </strong></p><p>— <a href="https://www.linkedin.com/in/fareed/">Fareed Mosavat</a></p></blockquote><p>Now, let’s get into the details.</p><p>Let’s define <em>user retention</em> as the % of users who signed up and are still active (i.e. using the product, making a purchase, posting a photo) six months later.</p><h3>Consumer<strong> Social: ~25% is GOOD, ~45% is GREAT</strong></h3><p>This includes companies such as <strong>Snapchat, Twitter, and Instagram</strong> that are free to use and are generally supported by advertising. The denominator in this category are registered users.</p><p><strong>Expert recommendations</strong></p><ul><li><p><strong>Jeff Chang</strong>: Over 25% is GOOD, over 40% is GREAT</p></li><li><p><strong>Casey Winters</strong>: Over 25% is GOOD, over 45% is GREAT</p></li><li><p><strong>Brian Rothenberg</strong>: Over 25% is GOOD, over 50% is GREAT</p></li><li><p><strong>Jamie Quint: </strong>Over 30% is GOOD, over 40% is GREAT</p></li><li><p><strong>ChenLi Wang</strong>: Over 30% is GOOD, over 50% is GREAT</p></li><li><p><strong>Julie Zhou</strong>: Over 30% is GOOD, over 60% is GREAT</p></li><li><p><strong>Kevin Kwok</strong>: Over 30% is GOOD, over 60% is GREAT</p></li><li><p><strong>Andrew Chen</strong>: Over 50% is GOOD, over 75% is GREAT</p></li></ul><p><strong>Public comps</strong></p><ul><li><p><strong>Facebook</strong>: 60 - 70% 6-month user retention</p></li><li><p><strong>Instagram</strong>: 50 - 60% 6-month user retention</p></li><li><p><strong>Snapchat</strong>: 33% 3-month user retention, 30% 24-month (<a href="https://www.theinformation.com/articles/which-apps-retail-their-users-and-which-ones-dont">source</a>, <a href="https://www.statista.com/statistics/523845/highest-retention-social-android-apps/">source</a>)</p></li><li><p><strong>Twitter</strong>: 31% 3-month user retention, 22% 24-month (<a href="https://www.theinformation.com/articles/which-apps-retail-their-users-and-which-ones-dont">source</a>, <a href="https://www.statista.com/statistics/523845/highest-retention-social-android-apps/">source</a>)</p></li></ul><h3>Consumer<strong> Transactional: ~30% is GOOD, ~50% is GREAT</strong></h3><p>This includes companies such as <strong>Airbnb, Lyft, and TurboTax </strong>that are generally supported by one-off purchases. The denominator in this category are users who have made at least one transaction.</p><p><strong>Expert recommendations</strong></p><ul><li><p><strong>Casey Winters</strong>: Over 15% is GOOD, over 35% is GREAT</p></li><li><p><strong>Kevin Kwok</strong>: Over 30% is GOOD, over 50% is GREAT</p></li><li><p><strong>Dan Hockenmaier</strong>: Over 30% is GOOD, over 50% is GREAT</p></li><li><p><strong>Li Jin:</strong> Over 30% is GOOD, over 50% is GREAT</p></li><li><p><strong>Brian Rothenberg</strong>: Over 30% is GOOD, over 60% is GREAT</p></li><li><p><strong>ChenLi Wang</strong>: Over 30% is GOOD, over 70% is GREAT</p></li></ul><p><strong>Public comps</strong></p><ul><li><p><strong>TurboTax</strong>: 77% 12-month customer retention (<a href="https://www.hbs.edu/openforum/openforum.hbs.org/goto/challenge/understand-digital-transformation-of-business/intuit-s-turbotax-price-discrimination-is-effective.1.html">source</a>)</p></li><li><p><strong>Lyft</strong>: 22% 12-month customer retention (<a href="https://www.thetaequity.com/lyft-ipo">source</a>)</p></li></ul><h3>Consumer SaaS:<strong> ~40% is GOOD, ~70% is GREAT</strong></h3><p>This includes companies such as <strong>Netflix, Spotify, and Hulu</strong> that sell a monthly/yearly subscription to consumers. The denominator in this category are users who have started a paid subscription.</p><p><strong>Expert recommendations</strong></p><ul><li><p><strong>Dan Hockenmaier: </strong>Over 40% is GOOD, over 60% is GREAT</p></li><li><p><strong>Adam Fishman: </strong>Over 40% is GOOD, over 70% is GREAT</p></li><li><p><strong>Jeff Chang: </strong>Over 50% is GOOD, over 70% is GREAT</p></li><li><p><strong>Mike Duboe: </strong>Over 50% is GOOD, over 70% is GREAT</p></li><li><p><strong>Elena Verna</strong>: Over 70% is GOOD, over 80% is GREAT</p></li></ul><p><strong>Public comps</strong></p><ul><li><p><strong>Amazon Prime</strong>: 93% 12-month customer retention (<a href="https://www.twice.com/retailing/amazon-prime-subscribers-2019">source</a>)</p></li><li><p><strong>Dropbox:</strong> ~80% 12-month customer retention</p></li><li><p><strong>Spotify</strong>: 72% 6-month customer retention (<a href="https://blog.measurable.ai/2019/11/04/exceptional-purchase-retention-of-spotify-and-its-new-podcast-strategy/">source</a>, <a href="https://www.statista.com/statistics/241424/dau-and-mau-of-spotifys-facebook-app/">source</a>)</p></li><li><p><strong>Netflix</strong>: 66% 12-month customer retention (<a href="https://secondmeasure.com/datapoints/netflix-disney-plus-apple-customer-retention/">source</a>)</p></li><li><p><strong>Hulu</strong>: 53% 12-month customer retention (<a href="https://secondmeasure.com/datapoints/netflix-disney-plus-apple-customer-retention/">source</a>)</p></li></ul><h3><strong>SMB / Mid-Market SaaS: ~60% is GOOD, ~80% is GREAT</strong></h3><p>This includes companies such as <strong>Asana, Slack, and Atlassian</strong> that primarily sell a subscription product to companies roughly 100-1000 employees. The denominator in this category are companies who have started a paid subscription.</p><p><strong>Expert recommendations</strong></p><ul><li><p><strong>Yuriy Timen</strong>: Over 60% is GOOD, over 80% is GREAT</p></li><li><p><strong>Mike Duboe</strong>: Over 60% is GOOD, 80% is GREAT</p></li><li><p><strong>Sarah Guo</strong>: Over 70% is GOOD, over 80% is GREAT</p></li><li><p><strong>Fareed Mosavat: </strong>Over 70% is GOOD, over 85% is GREAT</p></li><li><p><strong>ChenLi Wang</strong>: Over 70% is GOOD, over 85% is GREAT</p></li><li><p><strong>Andy Johns</strong>: Over 70% is GOOD, 90% is GREAT</p></li><li><p><strong>Dan Hockenmaier</strong>: Over 70% is GOOD, over 90% is GREAT</p></li><li><p><strong>Merci Grace</strong>: Over 80% is GOOD, 90% is GREAT</p></li></ul><p><strong>Public companies</strong></p><ul><li><p><strong>Atlassian</strong>: 98% 12-month customer retention (<a href="https://seekingalpha.com/article/4289582-atlassian-is-repositioning-for-future">source</a>)</p></li><li><p><strong>Slack:</strong> 90-95% 12-month customer retention (<a href="https://www.rocketblocks.me/blog/slack-metrics.php">source</a>, <a href="https://www.thetaequity.com/slack-ipo">source</a>)</p></li><li><p><strong>QuickBooks</strong>: 79% 12-month customer retention (<a href="http://analysisreport.morningstar.com/stock/research/c-report?&amp;t=XNAS:INTU&amp;region=usa&amp;culture=zh-CN&amp;productcode=QS&amp;cur=&amp;urlCookie=8056723522&amp;e=eyJhbGciOiJSU0EtT0FFUCIsImVuYyI6IkExMjhHQ00ifQ.jRbbMI400Bb9ZooVDzRwlWTjZLVQK8Wuoe4MTNuK_HRhEGWQC7iTj6RNX_QkUhRaIakTpCwLhioYtggMawqPo_MQQU9oqP5dJxQh_4aQBR9MdISHGljBgRaItM-6xRSIfSxa5GgnDmcwLALZe1tkPz0YI5rXlvXPDOflJOXHEuY.yO-n-CczhDqdbPMI.MPLk1bS9rMP369DrL5Q-RcyIIBeMhHp5svZmp0VIsOjaG0J9Sjk53Uq9PrFqk883utblUw2UqRXSn0ORFuXLSfQcS7fD1y1Y9a7VlubYNWqVfoBlbRZNxjaGidgk62ToWSvSkVztsyLfwQMbaBp1_G3ITrQ-Ud0GTNbK7oCzTZ7IMHwcvonZRt5gnVFRcSpe1EFT7Z3oZt3GtfwoNrI-mq8faPGpqForBnxtrDo.1-3ri8thKyjDFOjF2CIn2Q">source</a>)</p></li></ul><h3><strong>Enterprise SaaS: ~75% is GOOD, ~90% is GREAT</strong></h3><p>This includes companies such as <strong>Salesforce, Workday, and ADP</strong> that primarily sell a subscription product to large enterprise companies (i.e. over 1000 employees).</p><p><strong>Expert recommendations</strong></p><ul><li><p><strong>Andy Johns</strong>: Over 70% is GOOD, over 90% is GREAT&nbsp;</p></li><li><p><strong>Brian Rothenberg</strong>: Over 75% is GOOD, over 90% is GREAT</p></li><li><p><strong>Jeff Chang</strong>: Over 80% is GOOD, over 90% is GREAT</p></li><li><p><strong>Sarah Guo</strong>: Over 85% is GOOD, over 95% is GREAT</p></li><li><p><strong>Nick Soman</strong>: Over 85% is GOOD, over 95% is GREAT</p></li><li><p><strong>Shaun Clowes:</strong> Over 85% is GOOD, over 95% is GREAT</p></li></ul><p><strong>Public comps</strong></p><ul><li><p><strong>Workday: </strong>95% 12-month customer retention (<a href="https://www.workday.com/content/dam/web/en-us/documents/investor/workday-financial-analyst-day-2018.pdf">source</a>)</p></li><li><p><strong>Salesforce: </strong>90% 12-month customer retention (<a href="https://seekingalpha.com/article/4308906-salesforce-buy">source</a>)</p></li><li><p><strong>ADP: </strong>90%+ 12-month customer retention (<a href="https://www.forbes.com/sites/greatspeculations/2019/02/01/key-takeaways-from-adps-q2/#549ea1ac4877">source</a>)</p></li></ul><p>Let’s define <em>Net Revenue Retention</em> as a company’s monthly recurring revenue (MRR) one year ago divided into the current month’s MRR <em>from that same group of customers</em>. Essentially, how much revenue are you driving from one cohort of customers over time?</p><p>You’ll notice this section has slightly different categories from previous section. This is because of the way the customers a business sells to impacts revenue retention (unlike user retention). For example, the network effects in Bottom-Up SaaS often drive up retention, while involuntary churn of Very Small business (VSB) is common because many go out of business, and Land and Expand models increases revenue&nbsp;per user in ways that can make up for high user churn.</p><p>Now, let’s look at what good and great net revenue retention looks like for each type of business.</p><h3><strong>Consumer SaaS: ~55% is GOOD, ~80% is GREAT</strong></h3><p>This includes companies such as <strong>Netflix, Spotify, and Hulu </strong> that sell a monthly/yearly …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.lennyrachitsky.com/p/what-is-good-retention-issue-29">https://www.lennyrachitsky.com/p/what-is-good-retention-issue-29</a></em></p>]]>
            </description>
            <link>https://www.lennyrachitsky.com/p/what-is-good-retention-issue-29</link>
            <guid isPermaLink="false">hacker-news-small-sites-24643994</guid>
            <pubDate>Wed, 30 Sep 2020 21:18:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ent by Facebook: Entity Framework for Go Now Supports GraphQL]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24643910">thread link</a>) | @ajeetdsouza
<br/>
September 30, 2020 | https://entgo.io/docs/graphql/ | <a href="https://web.archive.org/web/*/https://entgo.io/docs/graphql/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><p><span><p>The <code>ent</code> framework provides an integration with GraphQL through the <a href="https://github.com/99designs/gqlgen">99designs/gqlgen</a>
library using the <a href="https://entgo.io/docs/templates">external templates</a> option (i.e. it can be extended to support other libraries).</p>
<h2>Quick Introduction</h2>
<p>In order to enable the <a href="https://github.com/facebookincubator/ent-contrib/tree/master/entgql"><code>entgql</code></a> extension to your
project, you need to use the <code>entc</code> (ent codegen) package as described <a href="https://entgo.io/docs/code-gen#use-entc-as-a-package">here</a>.
Follow these 3 steps to enable it to your project:</p>
<p>1. Create a new Go file named <code>ent/entc.go</code>, and paste the following content:</p>
<pre><code>

<span>package</span> main

<span>import</span> (
    <span>"log"</span>

    <span>"github.com/facebook/ent/entc"</span>
    <span>"github.com/facebook/ent/entc/gen"</span>
    <span>"github.com/facebookincubator/ent-contrib/entgql"</span>
)

<span><span>func</span> <span>main</span><span>()</span></span> {
    err := entc.Generate(<span>"./schema"</span>, &amp;gen.Config{
        Templates: entgql.AllTemplates,
    })
    <span>if</span> err != <span>nil</span> {
        log.Fatalf(<span>"running ent codegen: %v"</span>, err)
    }
}
</code></pre>
<p>2. Edit the <code>ent/generate.go</code> file to execute the <code>ent/entc.go</code> file:</p>
<pre><code><span>package</span> ent


</code></pre>
<p>Note that <code>ent/entc.go</code> is ignored using a build tag, and it's executed by the <code>go generate</code> command
through the <code>generate.go</code> file. The full example can be found in the <a href="https://github.com/facebookincubator/ent-contrib/blob/master/entgql/internal/todo">ent-contrib repository</a>.</p>
<p>3. Run codegen for your ent project:</p>
<pre><code>go generate ./...
</code></pre>
<p>After running codegen, the following add-ons will be added to your project.</p>
<h2>Node API</h2>
<p>A new file named <code>ent/node.go</code> was created that implements the <a href="https://relay.dev/docs/en/graphql-server-specification.html#object-identification">Relay Node interface</a>.</p>
<p>In order to use the new generated <code>ent.Noder</code> interface in the <a href="https://gqlgen.com/reference/resolvers/">GraphQL resolver</a>,
add the <code>Node</code> method to the query resolver, and see the <a href="#gql-configuration">configuration</a> section to understand
how to use it.</p>
<pre><code><span><span>func</span> <span>(r *queryResolver)</span> <span>Node</span><span>(ctx context.Context, id <span>int</span>)</span> <span>(ent.Noder, error)</span></span> {
    <span>return</span> r.client.Noder(ctx, id)
}
</code></pre>
<p>Note that schema migration must be configured with the <a href="https://entgo.io/docs/migrate#universal-ids">Universal IDs</a> option if you want
ent to resolve the "type from id" for you.</p>
<h2>GQL Configuration</h2>
<p>Here's a configuration example for a todo app as exists in <a href="https://github.com/facebookincubator/ent-contrib/tree/master/entgql/internal/todo">ent-contrib/entgql/todo</a>.</p>
<pre><code><span>schema:</span>
  <span>-</span> <span>todo.graphql</span>

<span>resolver:</span>
  
  <span>layout:</span> <span>follow-schema</span>
  <span>dir:</span> <span>.</span>



<span>autobind:</span>
  <span>-</span> <span>github.com/facebookincubator/ent-contrib/entgql/internal/todo/ent</span>

<span>models:</span>
  <span>ID:</span>
    <span>model:</span>
      <span>-</span> <span>github.com/99designs/gqlgen/graphql.IntID</span>
  <span>Node:</span>
    <span>model:</span>
      
      <span>-</span> <span>github.com/facebookincubator/ent-contrib/entgql/internal/todo/ent.Noder</span>
</code></pre>
<h2>Pagination</h2>
<p>The pagination template adds a pagination support according to the <em>Relay Cursor Connections Spec</em>. More info
about the Relay Spec can be found in its <a href="https://relay.dev/graphql/connections.htm">website</a>.</p>
<h2>Connection Ordering</h2>
<p>The ordering option allows us to apply an ordering on the edges returned from a connection.</p>
<h3>Usage Notes</h3>
<ul>
<li>The generated types will be <code>autobind</code>ed to GraphQL types if a naming convention is preserved (see example below).</li>
<li>Ordering can only be defined on ent fields (no edges).</li>
<li>Ordering fields should normally be <a href="https://entgo.io/docs/schema-indexes">indexed</a> to avoid full table DB scan.</li>
<li>Pagination queries can be sorted by a single field (no order by ... then by ... semantics).</li>
</ul>
<h3>Example</h3>
<p>Let's go over the steps needed in order to add ordering to an existing GraphQL type.
The code example is based on a todo-app that can be found in <a href="https://github.com/facebookincubator/ent-contrib/tree/master/entgql/internal/todo">ent-contrib/entql/todo</a>.</p>
<h3>Defining order fields in ent/schema</h3>
<p>Ordering can be defined on any comparable field of ent by annotating it with <code>entgql.Annotation</code>.
Note that the given <code>OrderField</code> name must match its enum value in graphql schema.</p>
<pre><code><span><span>func</span> <span>(Todo)</span> <span>Fields</span><span>()</span> []<span>ent</span>.<span>Field</span></span> {
    <span>return</span> []ent.Field{
        field.Time(<span>"created_at"</span>).
            Default(time.Now).
            Immutable().
            Annotations(
                entgql.OrderField(<span>"CREATED_AT"</span>),
            ),
        field.Enum(<span>"status"</span>).
            NamedValues(
                <span>"InProgress"</span>, <span>"IN_PROGRESS"</span>,
                <span>"Completed"</span>, <span>"COMPLETED"</span>,
            ).
            Annotations(
                entgql.OrderField(<span>"STATUS"</span>),
            ),
        field.Int(<span>"priority"</span>).
            Default(<span>0</span>).
            Annotations(
                entgql.OrderField(<span>"PRIORITY"</span>),
            ),
        field.Text(<span>"text"</span>).
            NotEmpty().
            Annotations(
                entgql.OrderField(<span>"TEXT"</span>),
            ),
    }
}
</code></pre>
<p>That's all the schema changes required, make sure to run <code>go generate</code> to apply them.</p>
<h3>Define ordering types in GraphQL schema</h3>
<p>Next we need to define the ordering types in graphql schema:</p>
<pre><code><span><span>enum</span> <span>OrderDirection</span> {</span>
  ASC
  DESC
}

<span><span>enum</span> <span>TodoOrderField</span> {</span>
  CREATED_AT
  PRIORITY
  STATUS
  TEXT
}

input TodoOrder {
  <span>direction:</span> OrderDirection!
  <span>field:</span> TodoOrderField
}
</code></pre>
<p>Note that the naming must take the form of <code>&lt;T&gt;OrderField</code> / <code>&lt;T&gt;Order</code> for <code>autobind</code>ing to the generated ent types.
Alternatively <a href="https://gqlgen.com/config/#inline-config-with-directives">@goModel</a> directive can be used for manual type binding.</p>
<h3>Adding orderBy argument to the pagination query</h3>
<pre><code><span>type</span> <span>Query</span> {
  todos(
    after: <span>Cursor</span>
    first: <span>Int</span>
    before: <span>Cursor</span>
    last: <span>Int</span>
    orderBy: <span>TodoOrder</span>
  ): <span>TodoConnection</span>
}
</code></pre>
<p>That's all for the GraphQL schema changes, let's run <code>gqlgen</code> code generation.</p>
<h3>Update the underlying resolver</h3>
<p>Head over to the Todo resolver and update it to pass <code>orderBy</code> argument to <code>.Paginate()</code> call:</p>
<pre><code><span><span>func</span> <span>(r *queryResolver)</span> <span>Todos</span><span>(ctx context.Context, after *ent.Cursor, first *<span>int</span>, before *ent.Cursor, last *<span>int</span>, orderBy *ent.TodoOrder)</span> <span>(*ent.TodoConnection, error)</span></span> {
    <span>return</span> r.client.Todo.Query().
        Paginate(ctx, after, first, before, last,
            ent.WithTodoOrder(orderBy),
        )
}
</code></pre>
<h3>Use in GraphQL</h3>
<pre><code>query {
    todos(first: 3, orderBy: {direction: DESC, field: NAME}) {
        edges {
            node {
                name
            }
        }
    }
}
</code></pre>
<h2>Fields Collection</h2>
<p>The collection template adds support for automatic fields collection from GraphQL requests using eager-loading
the ent-edges. In order to configure this option to specific edges, use the <code>entgql.Annotation</code> as follows:</p>
<pre><code><span><span>func</span> <span>(Todo)</span> <span>Edges</span><span>()</span> []<span>ent</span>.<span>Edge</span></span> {
    <span>return</span> []ent.Edge{
        edge.To(<span>"children"</span>, Todo.Type).
            Annotations(entgql.Bind()).
            From(<span>"parent"</span>).
            
            
            Annotations(entgql.Bind()).
            Unique(),
        edge.From(<span>"owner"</span>, User.Type).
            Ref(<span>"tasks"</span>).
            
            Annotations(entgql.MapsTo(<span>"taskOwner"</span>)),
    }
}
</code></pre>
<p>Then, in the resolver, use it as follows:</p>
<pre><code><span><span>func</span> <span>(r *todoResolver)</span> <span>Parent</span><span>(ctx context.Context, t *ent.Todo)</span> <span>(*ent.Todo, error)</span></span> {
    parent, err := t.Edges.ParentOrErr()
    <span>return</span> parent, ent.MaskNotFound(err)
}

<span><span>func</span> <span>(r *todoResolver)</span> <span>Children</span><span>(ctx context.Context, obj *ent.Todo)</span> <span>([]*ent.Todo, error)</span></span> {
    <span>return</span> obj.Edges.ChildrenOrErr()
}
</code></pre>
<p>More info about fields-collection can be found in <a href="https://spec.graphql.org/June2018/#sec-Field-Collection">Relay website</a>.</p>
<h2>Enum Implementation</h2>
<p>The enum template implements the MarshalGQL/UnmarshalGQL methods for enums generated by ent.</p>
<h2>Transactional Mutations</h2>
<p>The <code>entgql.Transactioner</code> handler executes each GraphQL mutation in a transaction. The injected client for the resolver
is a <a href="https://entgo.io/docs/transactions#transactional-client">transactional <code>ent.Client</code></a>.
Hence, code that uses <code>ent.Client</code> won't need to be changed. In order to use it, follow these steps:</p>
<p>1. In the GraphQL server initialization, use the <code>entgql.Transactioner</code> handler as follows:</p>
<pre><code>srv := handler.NewDefaultServer(todo.NewSchema(client))
srv.Use(entgql.Transactioner{TxOpener: client})
</code></pre>
<p>2. And then, in the GraphQL mutations, use the client from context as follows:</p>
<pre><code><span><span>func</span> <span>(mutationResolver)</span> <span>CreateTodo</span><span>(ctx context.Context, todo TodoInput)</span> <span>(*ent.Todo, error)</span></span> {
    client := ent.FromContext(ctx)
    <span>return</span> client.Todo.
        Create().
        SetStatus(todo.Status).
        SetNillablePriority(todo.Priority).
        SetText(todo.Text).
        SetNillableParentID(todo.Parent).
        Save(ctx)
}
</code></pre>
<hr>
<p>Please note that this documentation is under development. All code parts reside in <a href="https://github.com/facebookincubator/ent-contrib/tree/master/entgql">ent-contrib/entgql</a>,
and an example of a todo-app can be found in <a href="https://github.com/facebookincubator/ent-contrib/tree/master/entgql/internal/todo">ent-contrib/entql/todo</a>.</p>
</span></p></article></div></div>]]>
            </description>
            <link>https://entgo.io/docs/graphql/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24643910</guid>
            <pubDate>Wed, 30 Sep 2020 21:11:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DigitalOcean's Hacktoberfest Is Hurting Open Source]]>
            </title>
            <description>
<![CDATA[
Score 790 | Comments 378 (<a href="https://news.ycombinator.com/item?id=24643894">thread link</a>) | @domenicd
<br/>
September 30, 2020 | https://blog.domenic.me/hacktoberfest/ | <a href="https://web.archive.org/web/*/https://blog.domenic.me/hacktoberfest/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>For the last couple of years, <a href="https://www.digitalocean.com/">DigitalOcean</a> has run
<a href="https://hacktoberfest.digitalocean.com/">Hacktoberfest</a>, which purports to “support open source” by giving free
t-shirts to people who send pull requests to open source repositories.</p>

<p>In reality, <strong>Hacktoberfest is a corporate-sponsored distributed denial of service attack against the open source
maintainer community</strong>.</p>

<p>So far today, on <a href="https://github.com/whatwg/html/pulls?q=is%3Apr+is%3Aclosed+label%3Aspam">a single repository</a>, myself
and fellow maintainers have closed 11 spam pull requests. Each of these generates notifications, often email, to the 485
watchers of the repository. And each of them requires maintainer time to visit the pull request page, evaluate its
spamminess, close it, tag it as spam, lock the thread to prevent further spam comments, and then report the spammer to
GitHub in the hopes of stopping their time-wasting rampage.</p>

<p>The rate of spam pull requests is, at this time, around four per hour. <em>And it’s not even October yet in my timezone.</em></p>

<p><img src="https://blog.domenic.me/images/hacktoberfest-spam-listing.png" alt="A screenshot showing a spam query for the whatwg/html repository, which is at this time up to 14 spam PRs"></p>

<p>Myself and other maintainers of the whatwg/html repository are not alone in suffering this deluge.
<a href="https://twitter.com/gravitystorm/status/1311386082982924289">My tweet</a> got commiseration from
<a href="https://mobile.twitter.com/gravitystorm/status/1311386082982924289">OpenStreetMap, phpMyAdmin</a>,
<a href="https://mobile.twitter.com/ulmerleben/status/1311378655231332355">PubCSS</a>,
<a href="https://mobile.twitter.com/JakeDChampion/status/1311389420638138370">GitHub, the Financial Times</a>,
<a href="https://twitter.com/slicknet/status/1311377444188770312">ESLint</a>, a
<a href="https://mobile.twitter.com/zekjur/status/1311411780162326531">computer club website</a>, and
<a href="https://mobile.twitter.com/juliusvolz/status/1311412919196844038">a conference website</a>, just within the first couple
of hours. Since then a dedicated account “<a href="https://twitter.com/shitoberfest">@shitoberfest</a>” has arisen to document the
barrage. Some <a href="https://github.com/search?q=is%3Apr+%22improve+docs%22+created%3A%3E2020-09-29&amp;type=Issues">cursory</a>
<a href="https://github.com/search?q=is%3Apr+label%3Ainvalid+created%3A%3E2020-09-29&amp;type=Issues">searches</a> show thousands of
spam pull requests, and rising.</p>

<p>DigitalOcean seems to be aware that they have a spam problem. Their solution, per their
<a href="https://hacktoberfest.digitalocean.com/faq">FAQ</a>, is to put the burden solely on the shoulders of maintainers. If we go
out of our way to tag a contribution as spam, then… we slightly decrease the chance of the spammer getting their free
t-shirt. In reality, the spammer will just keep going, submitting more pull requests to more repositories, until they
finally find a repository where the maintainer doesn’t bother to tag the PR as spam, or where the maintainer isn’t
available during the seven-day window DigitalOcean uses for spam-tracking.</p>

<p>To be clear, myself and my fellow maintainers did not ask for this. This is not an opt-in situation. If your open source
project is public on GitHub, DigitalOcean will incentivize people to spam you. There is no consent involved. Either we
contribute to DigitalOcean’s marketing project, or,
<a href="https://twitter.com/SudoFox/status/1311431141702819840">they suggest, we should quit open source</a>.</p>

<p>Hacktoberfest does not support open source. Instead, it drives open source maintainers even closer to
<a href="https://www.google.com/search?q=open+source+burnout">burnout</a>.</p>

<p><img src="https://blog.domenic.me/images/hacktoberfest-spam-pr.png" alt="A screenshot of a spam PR which adds the heading &quot;Great Work&quot; to the HTML Standard README"></p>

<h2 id="what-can-we-do">What can we do?</h2>

<p>My most fervent hope is that DigitalOcean will see the harm they are doing to the open source community, and put an end
to Hacktoberfest. I hope they can do it as soon as possible, before October becomes another lowpoint in the hell-year
that is 2020. In 2021, they could consider relaunching it as an opt-in project, where maintainers consent on a
per-repository basis to deal with such t-shirt–incentivized contributors.</p>

<p>To protect ourselves, maintainers have a few options. First, you can take the feeble step of ensuring that any spam
against your repositories doesn’t contribute to the spammer’s “t-shirt points”, by tagging pull requests with a “spam”
label, and <a href="https://twitter.com/MattIPv4/status/1311390498888781824">emailing hacktoberfest@digitalocean.com</a>.
DigitalOcean themselves, however, admit that
<a href="https://twitter.com/MattIPv4/status/1311390054334554113">this won’t stop the problem they’ve unleashed on us</a>. But
maybe it will contribute to the <a href="https://github.com/MattIPv4/hacktoberfest-data">metrics</a> they collect, which last year
showed that “only” 3,712 pull requests were labeled as spam by project maintainers.</p>

<p>If you’re comfortable cutting off genuine contributions from new users, you can try enabling GitHub’s
<a href="https://docs.github.com/en/free-pro-team@latest/github/building-a-strong-community/limiting-interactions-in-your-repository">interaction limits</a>.
However, <del>you have to do this every 24 hours, and</del> it has the drawback of also disabling issue creation and
comments. <ins>Update: GitHub has made the limit configurable, and has
<a href="https://twitter.com/github/status/1311772722234560517">a nice cheeky announcement tweet</a> zooming in on the “1 month”
option.</ins></p>

<p>Another promising route would be if GitHub would cut off DigitalOcean’s API access, as
<a href="https://twitter.com/__agwa/status/1311399074814472194">Andrew Ayer has suggested</a>. It’s not clear whether DigitalOcean
is committing a terms of service violation that would support such measures. But they’re certainly making GitHub a
less-pleasant place to be, and I hope GitHub can think seriously about how to discourage such corporate-sponsored
attacks on the open source community.</p>

<p>Finally, and most importantly, we can remember that this is how DigitalOcean treats the open source maintainer
community, and stay away from their products going forward. Although we’ve enjoyed using them for hosting the
<a href="https://whatwg.org/">WHATWG</a> standards organization, this kind of behavior is not something we want to support, so
we’re starting to investigate alternatives.</p>

  </div>

</article></div>]]>
            </description>
            <link>https://blog.domenic.me/hacktoberfest/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24643894</guid>
            <pubDate>Wed, 30 Sep 2020 21:10:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Create and watch any 100m race with AI based Fantasy100m]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24643622">thread link</a>) | @SeanWingad
<br/>
September 30, 2020 | https://www.joinfudge.com/fantasy100m | <a href="https://web.archive.org/web/*/https://www.joinfudge.com/fantasy100m">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.joinfudge.com/fantasy100m</link>
            <guid isPermaLink="false">hacker-news-small-sites-24643622</guid>
            <pubDate>Wed, 30 Sep 2020 20:46:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Creative Destruction: The Risks of Not Innovating]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24643617">thread link</a>) | @nicotesla
<br/>
September 30, 2020 | https://blog.codelitt.com/not-innovating/ | <a href="https://web.archive.org/web/*/https://blog.codelitt.com/not-innovating/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="Post__Main-Content">
        <div>
          <p>What makes an idea or product innovative? It depends on who you ask, but most answers can be boiled down to the process of <strong>creating purpose-driven value. </strong></p><p>For an organization, this process could be focusing on creating a new product for its customers or streamlining internal workflows to enable greater productivity. They could be <em>exciting</em>, like a tool for visualizing data in augmented reality, or just simply <em>necessary</em>, such as bringing a 100-year-old company’s internal systems up to modern-day standards. These two very different examples give insight into the spectrum of projects that Codelitt has been brought on as a partner to help solve. </p><p>A big point to be made here is that innovation is not just for startups. “Out with the old and in with the new” doesn’t mean that the established companies need to step aside! </p><p>Instead, it’s a call to action that they need to stay agile in the face of a rapidly changing world and take part in what Joseph Schumpeter referred to as “creative destruction” - incessantly destroying the old and creating the new <em>from</em> <em>within</em>. </p><p>Enter the infamous business consideration: risk! Risk is what keeps organizations and the leaders within them complacent in participating in this evolution. <a href="https://archive.fortune.com/magazines/fortune/fortune500_archive/full/1955/">With nearly 90% of the companies in the Fortune 500 in the 1950s</a><a href="https://fortune.com/fortune500/walmart/"> gone by the 2010s</a>, complacency has serious implications. </p><p>Furthermore, the <strong>longer you wait to act in these fast-moving times the higher the cost.</strong> 50 years ago the life expectancy for a company within the Fortune 500 was 75 years. Today, the average is 15 years.<br></p><figure><img src="https://res-3.cloudinary.com/hepw4b4yn/image/upload/q_auto/v1/ghost-blog-images/Creative-Destruction-Graph.png"></figure><p>There are two ways that we’ve found companies are taking on this risk: empowering employees to become intrapreneurs and <strong>outsourcing the burden of innovation to experienced partners. </strong></p><p>Codelitt believes that any employee can be innovative regardless of their position within an organization. <a href="https://www.codelitt.com/intrapreneur.html">We have written extensively about how employees can become “intrapreneurs”</a> - essentially internal entrepreneurs! </p><p>Some companies just encourage their employees to think outside of the box while others take a more active role through the creation of internal Innovation Centers of Excellence made up of people whose sole purpose is to ideate and innovate. </p><p>Regardless of where your particular company stands on this, it cannot be argued that <strong>establishing a structured process</strong> for how to approach innovation from within can help save you time and money.<br></p><figure><img src="https://res-5.cloudinary.com/hepw4b4yn/image/upload/q_auto/v1/ghost-blog-images/creative-2.jpg"></figure><p>When an organization can’t do it internally or feels it would benefit from an outside perspective, the decision is made to outsource to a 3rd party Innovation Partner. </p><p>Why? Simple! The leaders we speak with know they need to prioritize innovation, but the risks/costs of keeping it internal are too high.</p><p><strong>What are these risks?</strong></p><ul><li>Ideating in a vacuum can cause biases to form which makes refining or reframing of the innovative solutions challenging</li><li>Staying on time and within budget is difficult</li><li>Diverting resources to work on innovation is inefficient</li><li>The required specialized skills might not exist within the org. Having to find, hire, onboard, train, and pay salary/benefits is expensive</li></ul><p>Along with having these specialized skills, outsourced partners have processes in place for working with a wide variety of teams to help them quickly validate ideas. </p><p>For the decision makers we work with, Codelitt is extremely valuable as we shoulder the weight of having to deliver projects on time and within the established budget. Where internal Innovation Centers of Excellence exist, leaders have found value in collaborating with Codelitt to ensure they are being <strong>strategic with their innovation backlog.</strong> </p><p>We become the “expert pair of eyes” to ensure that they are thinking about their problems the right way and delivering results when the skills needed are beyond internal capabilities.<br></p><p><strong>How will you take on creative destruction within your own organization in 2020?</strong></p><p><a href="https://www.codelitt.com/contact.html">Get in touch with us!</a></p>
        </div>
      </section></div>]]>
            </description>
            <link>https://blog.codelitt.com/not-innovating/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24643617</guid>
            <pubDate>Wed, 30 Sep 2020 20:46:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ClickHouse, Redshift and 2.5B Rows of Time Series Data – Brandonharris.io]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24643541">thread link</a>) | @daniel_levine
<br/>
September 30, 2020 | http://brandonharris.io/redshift-clickhouse-time-series/ | <a href="https://web.archive.org/web/*/http://brandonharris.io/redshift-clickhouse-time-series/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

<p><img src="http://brandonharris.io/images/stochastic.jpg" alt=""></p>

<h3 id="overview">Overview</h3>
<blockquote>

  <p>Finding true time series data at billion row level scale is hard. It’s usually either generated from standard RNG’s which leave out the very important temporal dependencies through their use of Gaussian or Uniform distributions, or it’s too large to easily move around for testing purposes. In this post I show you how to synthesize billions of rows of true time series data with an autoregressive component, and then explore it with ClickHouse, a big data scale OLAP RDBMS, all on AWS. If you’re on a deadline, feel free to skip my thoughts and <a href="https://github.com/namebrandon/time-series-gen">get the code here</a>.</p>
</blockquote>

<h3 id="background-discussion">Background Discussion</h3>

<p>One of the areas that I continue to be impressed with is how quickly “standard SQL” solutions rebounded to start to handle very large datasets. These multi-billion row datasets were the domain of a few limited “Big Data” solutions only a few years ago. If you were working in this field in the early 2010’s, you’ll remember some crazy things when it came to manipulating very large data sets (raise your hand if you spent time googling how to create a bag in pig…).</p>

<p>Of course there have always been SQL or SQL-like offerings for big data work (and I won’t even talk about some of the crazy big data OLAP cube solutions) but in those early days if you wanted serious performance, you probably were going to be doing a lot more than just writing SQL. Even Spark SQL (which was a great option at the time, and still is for some use cases) required knowing a bit about RDD’s and lazy evaluation and even though you may have had some serious SQL chops, unless you knew Python or a bit of Scala, you were in for a tough ride.   </p>

<p><a href="https://prestodb.io/">Presto</a> went pretty far to solve this pain point, and in fact it was one of my early favorites in this space, as you can see from a post of mine <a href="http://brandonharris.io/redshift-clickhouse-time-series/(http://brandonharris.io/evaluating-big-data-performance-of-prestodb-and-parquet-on-s3-storage/)">way back in 2016</a>. Presto is still doing well (Amazon Athena anyone?) and has great support (check out the cool things <a href="https://www.starburstdata.com/">Starburst</a> is doing with enterprise Presto). <a href="https://spark.apache.org/sql/">SparkSQL</a> definitely has its place, and of course the proprietary solutions like Vertica, Aster and Greenplum are in use at alot of enterprises, but there are also some great offerings out there that are still not mainstream for some reason.</p>

<p>Back when I wrote that old <a href="http://brandonharris.io/evaluating-big-data-performance-of-prestodb-and-parquet-on-s3-storage/">Presto post</a>, <a href="https://tech.marksblogg.com/benchmarks.html">Mark</a> had jumped in and left some comments and I’d been following his Taxi Ride Adventures ever since. I started off this research really wanting to test out a GPU database and settled on <a href="https://www.brytlyt.com/">brytlytDB</a>, but something is up with them and they’ve pulled their AMI from AWS. I went looking elsewhere for something interesting to evaluate and I decided to give <a href="https://clickhouse.tech/">ClickHouse</a> a shot. Released in 2016 from the minds at Yandex (you should be familiar with them, but if not, think Google in Russia), <a href="https://clickhouse.tech/">ClickHouse</a>  is a columnar RDBMS implemented in C++ that offers distributed capabilities and has a syntax very close to ANSI SQL. </p>

<h3 id="about-clickhouse">About ClickHouse</h3>

<p>One of the areas that impressed me the most about ClickHouse was the numerous analytics related functions that are available right out to the box. These are just a few that I’m looking forward to playing with.</p>

<ul>
  <li>
    <p><a href="https://clickhouse.tech/docs/en/sql-reference/aggregate-functions/parametric-functions/#windowfunnel">windowFunnel()</a> – Searches for event chains in a sliding time window and calculates the maximum number of events that occurred from the chain.     </p>
  </li>
  <li>
    <p><a href="https://clickhouse.tech/docs/en/sql-reference/aggregate-functions/parametric-functions/#retention">retention()</a> - The function takes as arguments a set of conditions from 1 to 32 arguments of type UInt8 that indicate whether a certain condition was met for the event. Any condition can be specified as an argument (as in WHERE).    </p>
  </li>
  <li>
    <p><a href="https://clickhouse.tech/docs/en/sql-reference/aggregate-functions/parametric-functions/#function-sequencecount">sequenceCount()</a> - Counts the number of event chains that matched the pattern. The function searches event chains that don’t overlap. It starts to search for the next chain after the current chain is matched.</p>
  </li>
  <li>
    <p>Aggregate function combinations like <a href="https://clickhouse.tech/docs/en/sql-reference/aggregate-functions/combinators/#agg-functions-combinator-resample">resample()</a> - Lets you divide data into groups, and then separately aggregates the data in those groups. Groups are created by splitting the values from one column into intervals.</p>
  </li>
  <li>
    <p><a href="https://clickhouse.tech/docs/en/sql-reference/aggregate-functions/reference/grouparraymovingavg/">groupArrayMovingAvg </a>- Calculates the moving average of input values.</p>
  </li>
</ul>

<p>There is even an implementation for <a href="https://clickhouse.tech/docs/en/sql-reference/aggregate-functions/reference/stochasticlinearregression/">stochastic Linear and Logistic regression</a> with an option to use a variety of algorithms for updating weights (SGD of course, but also Adam, Nesterov and Momentum)! Not only is that just plain cool, but think of the overhead you can save not moving your data out of the database! </p>

<p>The analytics functions lead me to the next item.. I had been impressed with the work Mark and others had done to benchmark ClickHouse, but I wanted to focus a bit more on time series data rather than your traditional Taxi ride set many have used. I started looking for some large datasets and didn’t find what I wanted, so in a similar approach to the <a href="https://github.com/namebrandon/Sparkov_Data_Generation">Sparkov</a> project, I decided to generate my own. </p>

<p>I found a big boost from the team behind the Python <a href="https://github.com/TimeSynth/TimeSynth">TimeSynth</a> package, as with their help I was able to address the largest fault I’ve found with most synthetic “time series” data. Most synthetic data sets that purport to be time series are usually just generated with a random number generator based on a uniform or gaussian distribution, which means the data is independent. This is the case even with the wonderful <a href="https://github.com/timescale/tsbs">Time Series Benchmark Suites (TSBS)</a>. Part of the magic of time series data is the temporal dependency inherent in the values. With the availability of the TimeSynth package it became trivial to implement a solution that could generate billions of records that had an autoregressive component, as well as to add noise based in a Gaussian process (meaning the noise generated was i.i.d). </p>

<p>OK, enough exposition, let’s walk through creating an environment to generate 2.5 billion rows of true time series data, and then using ClickHouse to demonstrate some very impressive performance. While ClickHouse has a distributed capability, I was impressed enough with the SMP-style performance to run this on a single instance for now. Even though I used a hefty instance (r5ad.24xlarge, 96 cores, 200GB memory), this is still some fantastic performance. You’re not going to see these numbers on MySQL, even with equivalent hardware, I promise. In fact, I’ve included some RedShift comparisons at the end if you’re interested in the measurements.</p>

<h2 id="hands-on">Hands-On</h2>

<p>Here’s the high-level approach.     </p>

<p>•	Using a Python 3 environment with boto3 we’ll create an ec2 instance   <br>
•	Configure two NVME disks in RAID 0 to use for data generation as well as our ClickHouse storage. <br>
•	Clone <a href="https://github.com/namebrandon/time-series-gen">my repo</a> and use the parallelized Python code there to generate our data. <br>
•	Create the destination table in ClickHouse that’s well suited to our use case of time series data (column-oriented and using the MergeTree engine). <br>
•	Load the data into ClickHouse. <br>
•	Run some queries that demonstrate how we can perform aggregations and windowing functions across billions of rows very quickly.   </p>

<p>At this point I will assume you have an environment running Python 3 and that has the boto3 library installed. There is some more detail on this on my <a href="https://github.com/namebrandon/time-series-gen/blob/master/readme.md">GitHub readme</a> but Google will be your friend here to get to this state if you’re not already there.    </p>

<h3 id="data-generation">Data Generation</h3>

<p>The first thing we’ll need to do is the clone the repo from GitHub.</p>

<div><pre><code data-lang="bash">git clone https://github.com/namebrandon/time-series-gen.git</code></pre></div>

<p>You’ll end up more or less with a structure like this.</p>

<div><pre><code data-lang="text">---\
----\ create-db.sql - SQL DDL to create ClickHouse database and table
----\ gen.py - Python 3 script that is configurable. Data size and details are set here.
----\ launch-ec2.py - Python 3 script that uses AWS SDK to instantiate data generation and query environment
----\ load-data.sh - bash script to load data to ClickHouse
----\ requirements.txt - pip requirements
----\ secrets.txt - you create this. Two lines, account key on first, secret on second line.
----\ time-series.conf - ClickHouse conf.d override for storage - points to nvme raid 0 array</code></pre></div>

<p><code>launch-ec2.py</code> is the python script we’ll be using to create the infrastructure, and as mentioned, requires boto3. There is a requirements.txt for pip usage but that’s for the data generation component. Using it here will take care of the boto3 requirement, but it’s also overkill and you may want avoid those packages being installed in your current environment.</p>

<p>Assuming there are no issues with boto, you need to make sure you create a file called <code>secrets.txt</code> in the root of the directory where you cloned the repo. This should have your AWS IAM secret and key in the file and that’s how the <code>launch-ec2.py</code> obtains credentials for creating AWS resources. If you’ve got them in your environment variables you can re-write the code to use those, I believe <code>os.getenv</code> should help, but if you’re using virtualenv that may make things a bit more complicated.</p>

<p><strong>Please note that you should never store secrets or credentials in version control. My .gitignore will prevent the secrets.txt file from being shared but you should be cautious here and double-check before committing.</strong></p>

<div><pre><code data-lang="bash">touch secrets.txt
<span>echo </span>AADK1134123213 &gt;&gt; secrets.txt
<span>echo </span>asd090jkj12l3kj2l109a-0s9klk3aqa14 &gt;&gt;secrets.txt</code></pre></div>

<p>The final step before we execute the script is to modify any account or region specific items in the code so that they work for you. There is a section in the <code>launch-ec2.py</code> file labeled “Configure your relevant information here”. I’ll let you guess what that section might be for!</p>

<p><strong>One import item:</strong> Part of generating this data as well as optimizing most any database performance is ensuring our I/O subsystem is performing well. As a result, I’ve chosen either the r5ad or c5ad ec2 instance family. These come with a pair of NVME disks that we can put into RAID 0 for very fast I/O throughput. The userdata script that is part of the <code>launch-ec2.py</code> creates this array, and expects certain underlying storage devices. Unless you are comfortable picking up where this code will fail and creating your own array and manually following from this point, <strong>please stick with an r5ad or c5ad instance type (I suggest at minimum a 4xlarge).</strong></p>

<p>Once you’re comfortable with your changes to the <code>launch-ec2.py</code> file, let’s …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://brandonharris.io/redshift-clickhouse-time-series/">http://brandonharris.io/redshift-clickhouse-time-series/</a></em></p>]]>
            </description>
            <link>http://brandonharris.io/redshift-clickhouse-time-series/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24643541</guid>
            <pubDate>Wed, 30 Sep 2020 20:39:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Definition of News Has Been Legally Changed]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24643481">thread link</a>) | @recroad
<br/>
September 30, 2020 | https://zararsiddiqi.com/definition-of-news-legally-changed/ | <a href="https://web.archive.org/web/*/https://zararsiddiqi.com/definition-of-news-legally-changed/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>A tipping point has been reached in what is legally considered news. Critiquing a news source by  questioning the facts presented, the manner in which they were communicated, the source's validity, the broadcaster's motivations or any inherent biases that may exist, is no longer a fruitful activity.</p>
<p>That line of critique has been swept aside by legally muddying what news is. The presenter is no longer required to convey any truths and the onus of verification has entirely shifted from the news source to the audience.</p>
<p>There are two ways on how this has been achieved.</p>
<p><em>Burden of Verification</em>: A "reasonable" viewer is expected to "arrive with an appropriate amount of skepticism" based on the material presented by the news outlet. Any lies that the news broadcast may convey are not actionable because the viewer is expected to filter out lies from the truth. Even if the news source is spewing lies they're given a pass because the viewer should have known better to believe it in the first place to believe it. That is, any "reasonable" viewer. Adding this word into any court's ruling opens up the door to say anything.</p>
<p><em>False Presupposition</em>: The presenter can state an assumption which is very likely to be false (or known to be false) and then base future arguments on the suspect assumption. As long as what follows traces back to the false assumption, all is good and anything can be said. For example if a host says "We’re going to start by stipulating that everything Michael Cohen has told the feds is absolutely true", then the presenter has wide latitude on what conclusions they can draw, without ever worrying about whether Cohen was lying.</p>
<p>There are two compounding factors which make this especially harmful.</p>
<p><em>Inability for Skepticism</em>:  The constant bombarding of rhetoric in news shows overwhelms its audience and amplifies the echo in the chamber that the viewer already lives in. There is no pause (or desire to pause) to reflect on whether the information presented should be met with skepticism. The expectation that the consumer has the ability to be skeptical is wrong. The medium has become powerful enough that it overrides a human being's ability to be skeptical, especially one who <em>wants to believe</em> in the lie.</p>
<p><em>Repackaging</em>: Having talk shows disguise as news programs is a laughably easy way of repackaging lies without risking the penalty of being called out. Twenty-four hour news channels can have talk shows with millions of viewers who tune in to get some semblance of valid information. I provide the "some semblance" qualifier only because the audience have been conditioned enough and are polarized enough that they no longer can think on their own, and only tune in to reinforce whatever they already believe. As there is no material differentiation between talk shows and news programs for the audience, the convenient repackaging gives the broadcaster an out to say anything and hide behind the argument, "it's not news, it's a talk show".</p>
<p><img src="https://zararsiddiqi.com/images/news-court-ruling.png" alt="&quot;US District Court, Southern District of New York: Case 1:19-cv-11161-MKV   Document 39   Filed 09/24/20   Page 12 of 19&quot;">
US District Court, Southern District of New York: Case 1:19-cv-11161-MKV   Document 39   Filed 09/24/20  Page 12 of 19</p>
<p>--</p>
<ul>
<li><a href="https://law.justia.com/cases/federal/district-courts/new-york/nysdce/1:2019cv11161/527808/39/">https://law.justia.com/cases/federal/district-courts/new-york/nysdce/1:2019cv11161/527808/39/</a></li>
</ul></div></div>]]>
            </description>
            <link>https://zararsiddiqi.com/definition-of-news-legally-changed/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24643481</guid>
            <pubDate>Wed, 30 Sep 2020 20:34:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CloudBee's CodeShip Critical Security Notification]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24643253">thread link</a>) | @seneca
<br/>
September 30, 2020 | https://www.codeshipstatus.com/incidents/91bvlfw9xlm9 | <a href="https://web.archive.org/web/*/https://www.codeshipstatus.com/incidents/91bvlfw9xlm9">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
              Dear CodeShip users,</p><p>We are reaching out to inform you of additional information we have uncovered as a result of our continuing investigation of the recent GitHub breach. To provide maximum transparency, we are reporting on the results of our investigation, the impact on users, actions you must take to protect yourself/your organization, and actions we will take to strengthen our security processes going forward.</p><p>On Wednesday, September 16, 2020, CloudBees was notified by GitHub of suspicious activities targeting CodeShip business accounts connected to GitHub via the CodeShip GitHub app and now deprecated CodeShip OAuth tokens. CloudBees immediately initiated an investigation conducted by our security and engineering teams, and on September 27, we identified additional evidence of malicious activity against a failover CodeShip database. On September 29, we uncovered evidence to indicate that a malicious actor had access to this failover instance during the period of June 2019 to June 2020. At this time and to the best of our knowledge, we have no evidence of malicious activity or attempts within CodeShip systems since June 2020. </p><p>*What type of data was affected?*</p><p>The impacted accounts are those of CodeShip users. No other products or accounts were affected and CodeShip is in no way integrated with other CloudBees products or systems.</p><p>*For all CodeShip users:*</p><p>CodeShip users hashed account passwords, one-time password (OTP) recovery codes, and the OTP secret keys used to seed two-factor authentication all may have been exposed.</p><p>Business contact information for invoicing purposes such as company contact name, company name, VAT number, postal address, phone number also may have been exposed. No payment information, such as bank account numbers or credit card numbers, was exposed. No other CloudBees product other than CodeShip was impacted. Also, the logging system was not accessed for any customers.</p><p>*For CodeShip Basic users:*</p><p>Any information contained in CodeShip users’ pipelines may have been exposed. This includes scripts, environment variables, access tokens and other similar data.</p><p>*For CodeShip Pro users:*</p><p>AES encryption keys may have been exposed.</p><p>*Steps you should take*</p><p>Although at this time we have no evidence that the data potentially exfiltrated has been used, all CodeShip users may have been affected (including free, Basic and Pro accounts) and should take the following steps:</p><p>- Immediately rotate any keys or other secrets for cloud providers, third-party tools, or anything else that you used in your CodeShip pipelines.</p><p>- If using CodeShip Pro, rotate your AES key and re-encrypt your secrets.</p><p>- Immediately identify any other sensitive information that is stored in your pipelines and replace them within your pipelines and on any external systems.</p><p>- Determine whether any of your systems accessible from CodeShip have experienced unauthorized access, by contacting your provider or carefully review your access records.</p><p>- Verify that the source code held in repositories that are linked to your CodeShip account have retained their full integrity.</p><p>- Reset your CodeShip 2FA: <a target="_blank" href="https://documentation.codeship.com/general/about/2fa/">https://documentation.codeship.com/general/about/2fa/</a></p><p>At this time and to the best of our knowledge, we have no evidence of malicious activity or attempts within CodeShip systems since June 2020. We are continuing to monitor the situation.</p><p>*Steps we are taking*</p><p>As soon as we were notified by GitHub on September 16, we proceeded to rotate all our applications' internal secrets and rebuilt all our AWS AMIs. We are continuing to scrutinize our AWS security logs to monitor for suspicious activity, such as outbound connections to known malicious IPs. To date, we have not found any such activity.</p><p>We want you to be assured that we are taking steps to increase the security strength of the CodeShip product, including but not limited to:</p><p>- Validation that our product threat modeling and large-scope security reviews are systematically implemented.</p><p>- Validation that the application of production security standards to all operational processes and artifacts is systematically implemented.</p><p>- Enhancement of strict restrictions on access to production data and strict segregation of sensitive data.</p><p>- Improvement of existing SIRT processes to ensure faster and better forensic investigation.</p><p>*Who to contact *</p><p> We will update here with any new developments. </p><p>If you still have questions, please contact <a target="_blank" href="mailto:security@codeship.com">security@codeship.com</a>.</p><p>Last but not least, I’d like to apologize for the impact this is having on you. In the decade that CloudBees has been operating SaaS applications, we have always taken full responsibility for our products and we do so today. Please be assured that we will do everything we can to prevent this from happening again. </p><p>- Sacha Labourey, CEO, CloudBees
            </p></div></div>]]>
            </description>
            <link>https://www.codeshipstatus.com/incidents/91bvlfw9xlm9</link>
            <guid isPermaLink="false">hacker-news-small-sites-24643253</guid>
            <pubDate>Wed, 30 Sep 2020 20:12:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Defer Reference Implementation for C]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 59 (<a href="https://news.ycombinator.com/item?id=24643034">thread link</a>) | @cyber1
<br/>
September 30, 2020 | https://gustedt.gitlabpages.inria.fr/defer/ | <a href="https://web.archive.org/web/*/https://gustedt.gitlabpages.inria.fr/defer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="text-1-1">
<p>
In the following code snippet we
have one <i>guarded block</i> and three <i>deferred statements</i>.
</p>

<div>
<pre>guard {
  <span>void</span> * <span>const</span> <span>p</span> = malloc(25);
  <span>if</span> (<span>!</span>p) <span>break</span>;
  <span>defer</span> <span>free</span>(p);

  <span>void</span> * <span>const</span> <span>q</span> = malloc(25);
  <span>if</span> (<span>!</span>q) <span>break</span>;
  <span>defer</span> <span>free</span>(q);

  <span>if</span> (mtx_lock(&amp;mut)==thrd_error) <span>break</span>;
  <span>defer</span> <span>mtx_unlock</span>(&amp;mut);

  <span>// </span><span>all resources acquired</span>
}

</pre>
</div>

<p>
The idea is that we indicate with a <b><code>defer</code></b> keyword that the
statement, e.g a call to <b><code>free</code></b>, is only to be executed at the end of
the guarded block, and, that we want this action to happen
unconditionally in which way ever the guarded block is left.  For the
three deferred statements together it says that they should be
executed in the inverse order than they were encountered. So the
control flow for this code example can be visualized as follows:
</p>



<p><img src="https://gustedt.gitlabpages.inria.fr/defer/defer-image.png" alt="defer-image.png">
</p>

<p>
Here, the dashed lines represent circumstancial control flow that
might arise when some resources are not available or when the
execution is interrupted by a signal.
</p>

<p>
This new technique has at least two advantages to commonly used <code>C</code> or
<code>C++</code> techniques:
</p>

<dl>
<dt>proximity</dt><dd>The cleanup code (<code>free</code> or <code>mtx_unlock</code>) is coded
close to the place where its need arises.</dd>

<dt>visibility</dt><dd>The cleanup code is not hidden in some previously
defined function (such as for <code>atexit</code> handlers) or
constructor/destructor pairs (<code>C++</code>)</dd>
</dl>


<p>
For normal control flow (without intermediate <b><code>return</code></b>, <code>exit</code>, …)
code with similar properties can be coded with existing tools. The
above is equivalent to something like the following
</p>

<div>
<pre>{
   <span>void</span> * <span>const</span> <span>p</span> = malloc(25);
   <span>if</span> (<span>!</span>p) <span>goto</span> <span>DEFER0</span>;
   <span>if</span> (<span>false</span>) {
     <span>DEFER1</span>:
       free(p);
       <span>goto</span> <span>DEFER0</span>;
   }

   <span>void</span> * <span>const</span> <span>q</span> = malloc(25);
   <span>if</span> (<span>!</span>q) <span>goto</span> <span>DEFER1</span>;

   <span>if</span> (<span>false</span>) {
     <span>DEFER2</span>:
       free(q);
       <span>goto</span> <span>DEFER1</span>;
   }

   <span>if</span> (mtx_lock(&amp;mut)==thrd_error) <span>goto</span> <span>DEFER2</span>;

   <span>if</span> (<span>false</span>) {
     <span>DEFER3</span>:
       mtx_unlock(&amp;mut);
       <span>goto</span> <span>DEFER2</span>;
   }

   <span>// </span><span>all resources acquired</span>

   <span>goto</span> <span>DEFER3</span>;
   <span>DEFER0</span>:;
}

</pre>
</div>

<p>
Here, the <b><code>if(false)</code></b> clauses guarantee that the deferred statements
are jumped over when they are first met, and the labels and <b><code>goto</code></b>
statements implement the hops from back to front to execute the
deferred statements eventually.
</p>

<p>
Obviously, most <code>C</code> programmers would not code like this but they
would prefer to write down a <i>linearization</i> of the above, which is a
quite common idiom for cleanup handling in <code>C</code>:
</p>

<div>
<pre>{
   <span>void</span> * <span>const</span> <span>p</span> = malloc(25);
   <span>if</span> (<span>!</span>p) <span>goto</span> <span>DEFER0</span>;

   <span>void</span>*<span>const</span> <span>q</span> = malloc(25);
   <span>if</span> (<span>!</span>q) <span>goto</span> <span>DEFER1</span>;

   <span>if</span> (mtx_lock(&amp;mut)==thrd_error) <span>goto</span> <span>DEFER2</span>;

   <span>// </span><span>all resources acquired</span>

   mtx_unlock(&amp;mut);

 <span>DEFER2</span>:
   free(q);
 <span>DEFER1</span>:
   free(p);
 <span>DEFER0</span>:;
}

</pre>
</div>

<p>
This has the advantage of only making the circumstantial control flow
explicit (with three *=goto=) but it does that for the price of
proximity; the cleanup code is far from the place where its need
arises.
</p>

<p>
Nevertheless, even this linearization needs some form of naming
convention for the labels. For more complicated code the maintenance
of these jumps can be tricky and prone to errors.  This shows another
advantage of the <a href="#org63e5a5c"><code>defer</code></a> approach:
</p>

<dl>
<dt>maintainability</dt><dd>The cleanup specification is not dependent on
arbitrary naming such as labels (<code>C</code>) or RAII classes
(<code>C++</code>) and does not change when <a href="#org63e5a5c"><code>defer</code></a> or <b><code>break</code></b>
statements are added or removed.</dd>
</dl>

<p>
Another important property that is much more difficult to implement in
<code>C</code> (and that needs <b><code>try/catch</code></b> blocks in <code>C++</code>) is that <b>all</b> exits
from the guarded block are detected and acted upon: <b><code>break</code></b>, <b><code>return</code></b>,
<a href="#org18b8cc4"><code>thrd_exit</code></a>, <a href="#org9db677d"><code>exit</code></a>, <a href="#org7f6c106"><code>panic</code></a>, or
an interruption by a signal. That is, unless there are nasal deamons
flying around, we have a forth important property
</p>


<dl>
<dt>robustness</dt><dd>Any deferred statement is guaranteed to be executed
eventually.</dd>
</dl>

<p>
This is different from <code>C++</code>'s handling of destructors, which are only
guaranteed to be executed if there is a <b><code>try/catch</code></b> block underneath.
</p>

<p>
This principle of deferred execution extends to nested
guarded blocks in a natural way, even if they are stacked in
different function calls.
</p>
</div></div>]]>
            </description>
            <link>https://gustedt.gitlabpages.inria.fr/defer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24643034</guid>
            <pubDate>Wed, 30 Sep 2020 19:55:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Qiskit release comprehensive textbook for all to learn basic quantum computing]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24643006">thread link</a>) | @mindcrime
<br/>
September 30, 2020 | https://quantumzeitgeist.com/qiskit-releases-comprehensive-textbook-for-all-to-learn-basic-quantum-computing | <a href="https://web.archive.org/web/*/https://quantumzeitgeist.com/qiskit-releases-comprehensive-textbook-for-all-to-learn-basic-quantum-computing">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
								
<p>Qiskit hosted a course this past summer, which saw over 4000 students from more than 100 countries registering to attend the same quantum computing courses taught to IBM Quantum interns. Now, Qiskit is planning to offer the same course to anyone who wants to get their feet wet in the world of quantum computing and quantum hardware.</p>



<p>One of the core beliefs the Qiskit team holds to is that anyone trained right can program a quantum computer. Because of this belief, the team wrote an open-source textbook that teaches readers how to use Qiskit in quantum computing. The training is both effective and thorough. A survey revealed that 92 percent of QGSS participants felt that the Qiskit Global Summer School exceeded or was equivalent to other quantum computing courses available.</p>



<figure><img loading="lazy" width="1024" height="668" src="https://i2.wp.com/quantumzeitgeist.com/wp-content/uploads/1_Mnqa-aMTqT08pM2vokXM_g.png?resize=1024%2C668&amp;ssl=1" alt="" srcset="https://i2.wp.com/quantumzeitgeist.com/wp-content/uploads/1_Mnqa-aMTqT08pM2vokXM_g.png?resize=1024%2C668&amp;ssl=1 1024w, https://i2.wp.com/quantumzeitgeist.com/wp-content/uploads/1_Mnqa-aMTqT08pM2vokXM_g.png?resize=300%2C196&amp;ssl=1 300w, https://i2.wp.com/quantumzeitgeist.com/wp-content/uploads/1_Mnqa-aMTqT08pM2vokXM_g.png?resize=768%2C501&amp;ssl=1 768w, https://i2.wp.com/quantumzeitgeist.com/wp-content/uploads/1_Mnqa-aMTqT08pM2vokXM_g.png?resize=750%2C490&amp;ssl=1 750w, https://i2.wp.com/quantumzeitgeist.com/wp-content/uploads/1_Mnqa-aMTqT08pM2vokXM_g.png?w=1050&amp;ssl=1 1050w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/quantumzeitgeist.com/wp-content/uploads/1_Mnqa-aMTqT08pM2vokXM_g.png?resize=1024%2C668&amp;ssl=1 1024w, https://i2.wp.com/quantumzeitgeist.com/wp-content/uploads/1_Mnqa-aMTqT08pM2vokXM_g.png?resize=300%2C196&amp;ssl=1 300w, https://i2.wp.com/quantumzeitgeist.com/wp-content/uploads/1_Mnqa-aMTqT08pM2vokXM_g.png?resize=768%2C501&amp;ssl=1 768w, https://i2.wp.com/quantumzeitgeist.com/wp-content/uploads/1_Mnqa-aMTqT08pM2vokXM_g.png?resize=750%2C490&amp;ssl=1 750w, https://i2.wp.com/quantumzeitgeist.com/wp-content/uploads/1_Mnqa-aMTqT08pM2vokXM_g.png?w=1050&amp;ssl=1 1050w" data-lazy-src="https://i2.wp.com/quantumzeitgeist.com/wp-content/uploads/1_Mnqa-aMTqT08pM2vokXM_g.png?resize=1024%2C668&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>The various lectures that will be available for all</figcaption></figure>



<p>The team will be releasing 27 lectures with notes and labs, around a semester’s load of content. The lectures will teach students the basics of programming a quantum computer, introduce famous algorithms such as Shor’s and Grover’s algorithm, and give an overview of how they built quantum bits and use them to represent data. There will even be an introduction to quantum chemistry included. Two prerequisites are a basic understanding of the Python language and linear algebra.</p>



<p>Qiskit believes that quantum computing should be accessible by all, and access to this knowledge should not be limited. They hope that students can teach themselves how to code with quantum computers as well as help and teach others. By doing so, the largest and easiest quantum community will come to fruition.</p>



<p><strong>About<a href="https://qiskit.org/" data-wpel-link="external" rel="external noopener noreferrer"> Qiskit</a></strong></p>



<p>Qiskit is an open-source software development kit that is used to program quantum computers, work with quantum experiments, and write quantum applications. It can be installed by anyone with a working computer and is easily available. The Qiskit community is very tight-knit and often very helpful in sharing information and teaching.</p>
															</div></div>]]>
            </description>
            <link>https://quantumzeitgeist.com/qiskit-releases-comprehensive-textbook-for-all-to-learn-basic-quantum-computing</link>
            <guid isPermaLink="false">hacker-news-small-sites-24643006</guid>
            <pubDate>Wed, 30 Sep 2020 19:53:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Signals and Threads: Compiler Optimization, with Greta Yorsh]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24642987">thread link</a>) | @yminsky
<br/>
September 30, 2020 | https://signalsandthreads.com/compiler-optimization/ | <a href="https://web.archive.org/web/*/https://signalsandthreads.com/compiler-optimization/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<!--
## 0:00
# Name
Text with [link](url).  <br><br>New paragraph.
-->

<h2 id="000004">00:00:04</h2>

<p>Welcome to Signals &amp; Threads, in-depth conversations about every layer of the tech stack from Jane Street. I’m Ron Minsky. So, it’s my pleasure today to have a conversation with Greta Yorsh. Greta is a compiler engineer in our compilers team in the London office, and she also has a rich and interesting background in compilers and programming languages and program analysis and verification, and we’re going to talk about all that. She’s also had a lot of experience in both industry and academia, and since 2018, Great has worked with us working on the OCaml compiler. So, Greta, to start with, can you talk about how you got interested in compiler optimization?</p>

<h2 id="000044">00:00:44</h2>

<div><p>I studied in Israel. I did my undergraduate studies in computer science and economics. I found that I don’t cope well with uncertainty, so the interesting mathematical bits of economics were not the right choice for me. So, I decided to do a PhD in computer science in the area of software verification where a lot of the concerns are about ensuring things, so that fits well with my approach to certain things. And after my PhD, I worked for a few years at IBM Watson Research Center in New York working on program analysis and verification problems.
</p><p> After that, I moved to Cambridge in England, and I joined an amazing company, ARM, that makes processors, and I worked there in the compilers team working on the GCC compiler backend for ARM, and after that, I worked at Queen Mary University of London as an assistant professor, or lecturer it’s called in England, where I did research in teaching in the area of compilers, and then recently, a year and a half ago, I joined Jane Street. At Jane Street, I work on the compilers team on the OCaml compiler.</p></div>

<h2 id="000209">00:02:09</h2>

<p>Tell us a little bit more about how that fits into the arc of your research.</p>

<h2 id="000214">00:02:14</h2>

<div><p>I started my research working on the problem of software verification or certain aspects of this problem, proving that software satisfies certain good properties, correctness properties that users expect from it, and that research involved a lot of reasoning about the source code of the program rather than executing it and then using certain formal methods and logical reasoning techniques, decision procedures, in order to prove properties of the program.
</p><p> I worked on that for a while, and there’s this ultimate goal of proving that the software behaves just the way it should be so that real-world executions of their program don’t cause terrible failures, and I was very excited about it for a while, but it is an undecidable problem, a problem that is very hard to solve in general, and that becomes a bit frustrating after a while, and I was interested in what is it that real programmers and users of software want to prove about their programs, and how I can help them using the techniques that I know and the logic that I know.
</p><p> So I worked on that, and in the process of that, I’ve discovered that it’s really fun to work with real users and have people who care about certain things. I don’t know what they care about, but if I talk to them, maybe I’ll find out, and maybe one of the tools I have in my toolbox will help me to give users a tool, and I found it very exciting. I think the first time it happened, it was at IBM, and I was really excited about it, but what I also realized is that not everyone really cares about correctness, that sometimes it’s okay to have bugs in their programs.
</p><p> There are other important aspects of software, like performance. That made a big change to my understanding, because I could now put these very formal techniques together with something practical and try to combine the two. And then when I had the chance to work at ARM on the GCC compiler backend for ARM, I’ve discovered how important it is, the performance and how exciting it is to work on this micro-optimization, CPU-specific, machine-specific optimization, how much difference they make to the behavior of the program, to the performance behavior from these characteristics of the program, and at the same time, working on the compiler, you just can’t have bugs. An important property of the compiler is that so much else in our system is built on top of it. That was a tool that combines correctness and performance. It’s an optimization function that is very clear and measurable, as opposed to what properties do users want to have for their programs, and that’s how I came to work in compilers.</p></div>

<h2 id="000458">00:04:58</h2>

<div><p>Yeah, it’s interesting, you’re starting off by focusing on verification, because I think verification is this very shiny and attractive goal, because there’s this basic fact about programming, which is that we’re all terrible at it. Humans are bad at writing programs. Program languages are things that, at their best, do, infuriatingly, only the very specific things you ask them to do and not what you intended, and so trying to close that gap between the thing you tried to do and the terrible thing that you actually wrote down is an attractive goal.
</p><p> You were talking about one of the problems of verification, and just to be clear, by verification, formal methods (lots of terms here), we basically mean coming up with the moral equivalent of a proof that a program matches some specification. So you write in some precise, higher-level way what the program is supposed to do, and then there’s the actual program that you’ve written, and some kind of proof of the program does what it’s intended to do. You mentioned undecidability – an undecidable problem is one where you can show that there is no general technique that solves it all the time, and you mention that as a sign of how difficult the problem is. But, it’s a funny thing, in some sense almost everything that we do is undecidable, right? You can’t answer almost any interesting question about a program in full generality, the classic result being the halting program: You can’t even tell whether a given problem is going to ever finish executing in a general way. But that normally doesn’t stop us. The way we deal with this is we tend to provide people not with fully automated systems that solve all of their problems, but instead, tools that they can use while they write programs. They can maybe do some extra work along the side to help ensure the correctness of those programs, and those tools might be in the form of testing systems, and they might be in the forms of something that looks more like formal methods, things that, essentially, along with the program, develop some aspect of the proof of correctness of the program. So, I’m curious what you think about the kind of practicality and ergonomics of formal methods as a thing that can be layered into the programming process to make it easier for people to write programs that do the right thing.</p></div>

<h2 id="000702">00:07:02</h2>

<div><p>The kind of verification, proving properties of programs, that I think of when I say software verification (traditional methods) involve writing a program in one language and then providing specification of its behavior, telling what properties should hold about the program in a different language, in logic of some kind that describes it, and then proving that the specification and the implementation are conformed. That is very different from the type system approach that OCaml takes where the types are the specification of the program, and that is something I’m learning as I become better at programming in OCaml. But the kind of verification I’m talking about, the idea of specifying these properties on the side somewhere or even in the program, but in a different syntax, I think is a big problem for adopting this kind of technology. It’s possible to specify something about the library, but keeping it up to date as the code evolves is very hard. Same problem with documentation, but as you try to reason about it, and you have a tool that runs together with the specification and the code and checks them against each other as you do the development, there is some hope to keep the code and the spec aligned, but still, the programmer needs to write both of them. So, there is opportunity for automation to save some work for the programmer and keep the two aligned.
</p><p> I also wanted to mention, when you were talking about verification, so different people think of verification as different things. To me, it is what you said. It’s the more formal proof about the source code of the program and its properties, but for most of the development process, it is testing. It’s running the program on some inputs and checking that the outputs behave as we expect. So, after working a bit and trying to find the right logics that are expressive enough to describe the properties we want and at the same time, allow us to prove automatically that the program conforms to these properties, you find, “oh, this is very restrictive.” Then you look, but testing is so much better. “I’ve been working on this for two years, but I could’ve found this bug with a simple test.” So how do we find tests that are good tests, or do we have good tests? So, this problem has been worked on by many people, and what I find exciting is that taking the testing approach, finding test cases, and the formal proof approach, and combining them helps us build better tools. So, there are many ways in which each side can help the other, and I worked on exploring some of these ways, and I found it very interesting. And I think this shows up in the verification, but there are also similar combinations of static and dynamic information or execution time and compile time information that are useful for compilers during compilations.</p></div>

<h2 id="000949">00:09:49</h2>

<p>It’s interesting for you to say this thing about the way in which tests and formal proofs mix together. I feel like this is a thing that I’ve noticed informally on my own in programming, which is the OCaml type system, and in general type systems, are a kind of lightweight formal method. Types only capture some fairly limited properties of …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://signalsandthreads.com/compiler-optimization/">https://signalsandthreads.com/compiler-optimization/</a></em></p>]]>
            </description>
            <link>https://signalsandthreads.com/compiler-optimization/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24642987</guid>
            <pubDate>Wed, 30 Sep 2020 19:51:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why you should care about Robot Framework – Part I]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24642945">thread link</a>) | @kim_schiller
<br/>
September 30, 2020 | https://testautomation.dev/why-you-should-care-about-robot-framework-part-i/ | <a href="https://web.archive.org/web/*/https://testautomation.dev/why-you-should-care-about-robot-framework-part-i/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Have you ever heard of Robot Framework? If not, then this article will show you why you should care about Robot Framework and how it can be useful to you in your test automation work.</p>



<h2>What is Robot Framework?</h2>



<p>Robot Framework is a generic test automation framework. You use it primarily for functional acceptance testing and it is well suited for acceptence test driven development (ATDD) or similar approaches, but has also been extended to be used for robotic process automation (RPA). It is open source and implemented in Python.</p>



<p>While it is frequently used for testing web applications, it extends far beyond that. It can be used for testing REST API’s, databases, Java desktop applications, mobile applications and really it can be used on most types of systems. More on that later.</p>



<h2>Keyword-Driven</h2>



<p>One of the benefits of using Robot Framework is that you have an easy way to define and execute test cases, without the need to know technical details. This makes it a very useful for collaboration between test engineers, domain experts and developers. And using <strong>keywords</strong> makes this happen. </p>



<p>If you are not familiar with keyword-driven testing, here are the most important things you need to know.</p>



<ul><li>Keywords provide a layer of abstraction that hide implementation details away from the user.</li><li>Any action or step you define in your test case is considered a keyword.<ul><li>example: <code>Open login page</code></li></ul></li><li>You can add arguments to keywords<ul><li>example: <code>Open login page   user    password<mark id="annotation-text-8dd14e67-57d7-4a0d-b96c-ca4a857b4150"></mark></code></li></ul></li><li>You can reuse an already defined keyword in multiple test cases.</li><li>Keywords are well suited for automation</li></ul>



<h2>Architecture</h2>



<div><figure><img src="https://testautomation.dev/wp-content/uploads/2020/07/robot-framework-architecture-241x300.png" alt="Robot Framework architecture diagram" width="300" srcset="https://testautomation.dev/wp-content/uploads/2020/07/robot-framework-architecture-241x300.png 241w, https://testautomation.dev/wp-content/uploads/2020/07/robot-framework-architecture-823x1024.png 823w, https://testautomation.dev/wp-content/uploads/2020/07/robot-framework-architecture-768x955.png 768w, https://testautomation.dev/wp-content/uploads/2020/07/robot-framework-architecture.png 1010w" sizes="(max-width: 241px) 100vw, 241px"><figcaption>Figure 1: Robot Framework Architecture</figcaption></figure></div>



<p>Don’t skip this section! The modular architecture of Robot Framework is one of the main attractions, since this is what provides you with the great versatility this framework offers.</p>



<p>You pass test data into the framework, which in turn communicates with the system under test through the use of libraries, as you will see more of in the next chapter. </p>



<p>The libraries can use tools internally to provide functionality or contain the whole implementation themselves.</p>



<p>An example of using tools, is the AppiumLibrary for mobile testing, which internally uses the <a href="http://appium.io/">Appium Framework</a> to do all the heavy lifting. In this instance, the Robot Framework library acts as a wrapper of Appium functionality in keywords, ready to use.</p>



<p>By having this layered model, with the Library API at the core, Robot Framework makes it easy for you to:</p>



<ul><li>Test practically any type of system regardless of technology stack. (This is something most Record-Playback tools promise as well, but with Robot Framework, you don’t have to sell your soul to get it. 😉 )</li><li> Maintain stable test cases, even if the technology in the system under test changes.</li><li>Have full control over how test tests call the system under test, by adding your own library.</li></ul>







<h2>Libraries</h2>



<p>As mentioned earlier, Robot Framework can be used to test a wide range of systems. This is due to its well thought out architecture that you just saw, that allows external libraries to be plugged in to the framework.</p>



<p>External? Yes, well there are a number of libraries already included in the framework as <strong>standard libraries</strong>, for you to use. And you will use many of them for basic operations on files, strings, working with dates and lists and so on. </p>



<p>As for the <strong>external libraries</strong>, there are many external libraries developed by others, like:</p>



<ul><li><a href="https://github.com/jollychang/robotframework-appiumlibrary">AppiumLibrary</a></li><li><a href="http://franz-see.github.com/Robotframework-Database-Library/">Database Library</a></li><li><a href="https://github.com/kowalpy/Robot-Framework-FTP-Library">FTP Library</a></li><li><a href="https://github.com/eficode/JavaFXLibrary">JavaFXLibrary</a></li><li><a href="https://github.com/asyrjasalo/RESTinstance/">RESTinstance</a></li><li><a href="http://github.com/robotframework/SeleniumLibrary/">SeleniumLibrary</a></li></ul>



<div><figure><img loading="lazy" src="https://testautomation.dev/wp-content/uploads/2020/07/python-logo.png" alt="Python logo" width="292" height="99" srcset="https://testautomation.dev/wp-content/uploads/2020/07/python-logo.png 601w, https://testautomation.dev/wp-content/uploads/2020/07/python-logo-300x101.png 300w" sizes="(max-width: 292px) 100vw, 292px"></figure></div>



<p>You can also create your own library. The easiest option is to create it using Python. Robot Framework natively understands Python. </p>



<p>But if you run Robot Framework on the Java implementation Jython, you can write libraries in Java, and for .NET you can run IronPython and write libraries in supported .NET-languages.</p>



<p>In addition you can use the remote library feature, which opens up even more options. A remote library launches a remote server as a gateway to your library. There are remote servers available for Java, Ruby, .NET, Clojure, Perl, node.js and PHP. Check out the project: <a href="https://github.com/robotframework/RemoteInterface">https://github.com/robotframework/RemoteInterface</a></p>



<h2>Reporting</h2>



<p>Reporting is a very important feature in a test framework. Some frameworks come with only basic reporting functionality, that you normally can expand on yourself. But with Robot Framework you get a very comprehensive report and log out-of-the-box.</p>



<p>A test run produces three report artifacts. A <strong>report.html</strong> with an overview of the complete test execution. A <strong>log.html</strong> that contains details for each test, including output from each keyword executed. And finally an <strong>output.xml</strong> containing the raw data in XML format. Anyone interested in the test result, can read the HTML files, which are formatted to be human readable. External tools can use and process the XML file, eg. a test management system or continuous integration system.</p>



<p>The report looks like this:</p>



<div><figure><img loading="lazy" width="1024" height="690" src="https://testautomation.dev/wp-content/uploads/2020/07/robot-framework-test-report-1024x690.png" alt="Robot Framework Test Report" srcset="https://testautomation.dev/wp-content/uploads/2020/07/robot-framework-test-report-1024x690.png 1024w, https://testautomation.dev/wp-content/uploads/2020/07/robot-framework-test-report-300x202.png 300w, https://testautomation.dev/wp-content/uploads/2020/07/robot-framework-test-report-768x518.png 768w, https://testautomation.dev/wp-content/uploads/2020/07/robot-framework-test-report-1536x1035.png 1536w, https://testautomation.dev/wp-content/uploads/2020/07/robot-framework-test-report.png 1730w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Figure 2: Robot Framework Test Report</figcaption></figure></div>



<p>In case you are wondering, the background color is not always <span>green</span>. When one of your tests fail, it changes to <span>red</span>. This is a small feature, but it can actually be very valuable. <strong>Failed tests should make noise!</strong></p>



<h2>Community</h2>



<p>You are going to get stuck! And you will have questions. When this happens, you can join the Robot Framework online communities and get help. </p>



<div><figure><img loading="lazy" width="226" height="230" src="https://testautomation.dev/wp-content/uploads/2020/07/slack.png" alt="Slack logo"></figure></div>



<p>The most active place is probably Slack, where you will find several channels for specific topics.</p>



<p>Also you should visit the new <a href="https://forum.robotframework.org/">Robot Framework forum</a> and the still active mailing list on Google Groups.</p>



<p>The community is friendly and very helpful, both helping you solve problems you might run in to and in general discussing the use of the framework and the surrounding ecosystem.</p>



<h2>Development and maintenance</h2>



<p>Robot Framework was originally developed by <a href="https://twitter.com/pekkaklarck">Pekka Klärck</a> as his masters theses in 2005, and was further developed during his time at Nokia Networks and finally open sourced in 2008. Pekka is still active as lead developer on the framework.</p>



<p>Since then, the Robot Framework Foundation has been established as a non-profit organisation with the objective to sponsor the development of the framework and the ecosystem. They are also helping in organising local meetup groups as well as the annual <a href="https://robocon.io/">RoboCon</a> conference.</p>



<p>As of today there are more than 40 members of the foundation. This provides a strong backing for the framework.</p>



<h2>Conclusion</h2>



<p>Robot Framework is a keyword-driven generic test automation framework written in Python. It is a versatile framework that can be used to test most systems regardless of technology. </p>



<p>At the core of its architecture is a library API, that allows external libraries to be used to communicate with the system under test. Apart from the standard libraries being included, there is a growing number of libraires developed for both common and not so common technologies. A comprehensive test status report and log is built in, that has both an HTML version and XML version. </p>



<p>There is a very active community around Robot Framework, with a lot of discussions, which mostly takes place on Slack. And the creator of the framework, Pekka Klärck, is very active in the community and is lead developer on the framework. However, the development has been adopted by the Robot Framework Foundation, where over 40 members now sponsor the framework development.</p>



<p>Go check out <a href="https://robotframework.org/">Robot Framework</a> now. Or wait, because soon you can read the next part in this two-part series, <em>Why you should care about Robot Framework – Part II,</em> where you will be introduced to writing and executing test cases in Robot Framework. Coming soon…</p>



<hr>
<div heateor-sss-data-href="https://testautomation.dev/why-you-should-care-about-robot-framework-part-i/"><p>Share this post with your friends and followers:</p><ul></ul></div>	</div></div>]]>
            </description>
            <link>https://testautomation.dev/why-you-should-care-about-robot-framework-part-i/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24642945</guid>
            <pubDate>Wed, 30 Sep 2020 19:46:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How can Artificial Intelligence help with the Coronavirus vaccine search?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24642851">thread link</a>) | @Sanksshep
<br/>
September 30, 2020 | https://www.aiplusinfo.com/blog/aiandcovid19 | <a href="https://web.archive.org/web/*/https://www.aiplusinfo.com/blog/aiandcovid19">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" id="item-5f6660711674913350fd1601"><div><div><div data-block-type="2" id="block-5638530cbcac306ba30c"><p><h2>Artificial Intelligence can help accelerate the search for Coronavirus (COVID-19) vaccine. My thoughts, research, and approach to benefit &amp; accelerate the search for Coronavirus vaccine using artificial intelligence.</h2></p></div><div data-block-type="5" id="block-yui_3_17_2_1_1600544883185_4355"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f665deb78917549d33fe01d/1601252346673-38UEV8LFISCPL031AC0N/ke17ZwdGBToddI8pDm48kKC_hTD-rFzHwTnJxMBwHBZ7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UTNiI2uMwdQQKY2MK1cexINQOr1bn4yoydgWGauILAZDG6v6ULRah83RgHXAWD5lbQ/coronavirus-5590560_1920.png" data-image="https://images.squarespace-cdn.com/content/v1/5f665deb78917549d33fe01d/1601252346673-38UEV8LFISCPL031AC0N/ke17ZwdGBToddI8pDm48kKC_hTD-rFzHwTnJxMBwHBZ7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UTNiI2uMwdQQKY2MK1cexINQOr1bn4yoydgWGauILAZDG6v6ULRah83RgHXAWD5lbQ/coronavirus-5590560_1920.png" data-image-dimensions="1920x1358" data-image-focal-point="0.5,0.5" alt="source:&amp;nbsp; Alexandra_Koch , via&amp;nbsp; pixabay &amp;nbsp;(CC0)" data-load="false" data-image-id="5f712bfa4278c74ee0ed73b2" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f665deb78917549d33fe01d/1601252346673-38UEV8LFISCPL031AC0N/ke17ZwdGBToddI8pDm48kKC_hTD-rFzHwTnJxMBwHBZ7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UTNiI2uMwdQQKY2MK1cexINQOr1bn4yoydgWGauILAZDG6v6ULRah83RgHXAWD5lbQ/coronavirus-5590560_1920.png">
          </p>
        
          
        

        
          
          <figcaption>
            
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="44" id="block-yui_3_17_2_1_1600544883185_6098"><div><blockquote>
<p>Before I start I would like to take this opportunity to thank all the COVID warriors who are on the frontline. This is hard, folks on the frontlines are real heroes! We cannot thank them enough. Scientific research is not easy, there are a million edge cases that these scientists need to think of and apply, our body is very complex and different due to diversity and habits. They are not making 2-minute noodles. So please be patient and help them by staying home, wearing a mask and maintaining social distancing. Help them flatten the curve till we find a solution. 🙏</p>
</blockquote>
</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1600544883185_4645"><div><h2>Preface</h2><p>Artificial intelligence has had its share of debates where we have questioned how can it be used for good and bad. There is a lot of fear and hope as a result of these discussions and debates. What we need right now is a ray of hope in these dark times when we are fighting a pandemic. It is time that AI lives up to its hype and helps the scientific community in the search of a vaccine. I write this piece with a lot of responsibility and would like to share my research and thoughts on this topic through this article.</p><p>I am very fortunate to have an interest in AI and the opportunity to work with AI. I think AI is playing three strategic roles in this quest of helping scientist fight Coronavirus —</p><ul data-rte-list="default"><li><p><em>Running complex algorithms by parsing diverse datasets and identifying components of a vaccine by understanding the viral protein structure of COVID -19.</em></p></li><li><p><em>By helping medical researchers parse through tons of relevant research papers at an unprecedented pace.</em></p></li><li><p><em>Identifying compounds using AI and cloud computing to prevent the Spike protein from binding to the ACE2 receptor on human cells.</em></p></li></ul><p>A lot of companies/institutes have&nbsp;created&nbsp;AI tools, shared data sets, and research results, and shared them freely with the global scientific community.</p><p>According to the National Institute of Allergy and Infectious Diseases, There are three types of vaccines —</p><ul data-rte-list="default"><li><p>Whole-Pathogen Vaccines</p></li><li><p>Subunit Vaccines</p></li><li><p>Nucleic Acid Vaccines</p></li></ul><p>The types of vaccines the scientific community is interested in, are the subunit vaccine and nucleic acid vaccine type.&nbsp;These types of vaccines inject genetic material of the pathogen into human cells to stimulate an immune response.&nbsp;The latter is the type of vaccine targeting the virus, that began trials this week in the United States. AI is useful in accelerating the development of subunit and nucleic acid vaccines.</p><p>Proteins are an essential part of viruses and are made up of a sequence of amino acids that determine their unique 3D structure.&nbsp;Once we understand the structure of the protein, scientists can develop response based drugs that work with the protein’s unique structure.&nbsp;However, it would be impossible to examine all possible shapes of a protein before finding its unique 3D structure. AI can expedite this process by a million fold and helps us identify compounds that can vector in the unique protein structure.</p><p>There has been extensive work done on this using AI by a lot of organizations and institutions.&nbsp;In January, Google DeepMind introduced&nbsp;<a href="https://deepmind.com/blog/article/AlphaFold-Using-AI-for-scientific-discovery">AlphaFold</a>, a cutting-edge system that predicts the 3D structure of a protein-based on its genetic sequence.&nbsp;In early March, the system was put to the test on&nbsp;<a href="https://deepmind.com/research/open-source/computational-predictions-of-protein-structures-associated-with-COVID-19">COVID-19</a>. DeepMind released protein structure predictions of several under-studied proteins associated with SARS-CoV-2, the virus that causes COVID-19, to help the research community better understand the virus.</p><p>The University of Texas at Austin and the National Institutes of Health used a popular biology technique to create the&nbsp;<a href="https://news.utexas.edu/2020/02/19/breakthrough-in-coronavirus-research-results-in-new-map-to-support-vaccine-design/">first 3D atomic-scale map</a>&nbsp;of the part of the virus that attaches to and infects human cells — the spike protein.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1600544883185_6812"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f665deb78917549d33fe01d/1600545451047-JQYFQNL6P8BFX5J2IT50/ke17ZwdGBToddI8pDm48kFX2KuRl8d90069-zQ5z-Q1Zw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7UAwRg-drVjy0tH40Gqh4FNmfMO9L-gD9pMjeJ2_fJe7yhtyYWkC_zq_QBMOQI-dPg/Protien_Structure.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5f665deb78917549d33fe01d/1600545451047-JQYFQNL6P8BFX5J2IT50/ke17ZwdGBToddI8pDm48kFX2KuRl8d90069-zQ5z-Q1Zw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7UAwRg-drVjy0tH40Gqh4FNmfMO9L-gD9pMjeJ2_fJe7yhtyYWkC_zq_QBMOQI-dPg/Protien_Structure.jpg" data-image-dimensions="214x300" data-image-focal-point="0.5,0.5" alt="Protien_Structure.jpg" data-load="false" data-image-id="5f6662aa179c39639df86337" data-type="image" src="https://www.aiplusinfo.com/blog/Protien_Structure.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1600544883185_7101"><div><pre><code>This is a 3D atomic-scale map, or molecular structure, of the 2019-nCoV spike protein. The protein takes on two different shapes, called conformations — one before it infects a host cell, and another during infection. This structure represents the protein before it infects a cell, called the prefusion conformation. Credit: Jason McLellan/<a href="https://news.utexas.edu/2020/02/19/breakthrough-in-coronavirus-research-results-in-new-map-to-support-vaccine-design/">Univ. of Texas at Austin</a></code></pre><p><a href="https://www.ipd.uw.edu/">University of Washington’s Institute for Protein Design</a>&nbsp;also used computer models to develop&nbsp;<a href="https://www.ipd.uw.edu/2020/02/rosettas-role-in-fighting-coronavirus/">3D atomic-scale models of the SARS-CoV-2 spike</a>&nbsp;protein that closely match those discovered in the UT Austin lab.</p><p>It is crucial to be on top of the scientific research on COVID-19 but it requires a lot of effort to keep up with the results and collate them at one common platform. This can really help the scientific community by sharing critical pieces of information that will save them a lot of time and effort. Labs report their work via published articles and increasingly via preprint services like&nbsp;<a href="https://www.biorxiv.org/">bioRxiv</a>&nbsp;(<a href="https://connect.biorxiv.org/relate/content/181">COVID-19 Work</a>) and&nbsp;<a href="https://www.medrxiv.org/">medRxiv</a>&nbsp;(<a href="https://connect.medrxiv.org/relate/content/181">COVID-19 Work</a>).</p><p>As new research keeps getting published on a daily, sometimes hourly basis in this critical time. it becomes increasingly difficult for the scientists to be on top of the research, connect the dots, and uncover insights.</p><p>In this pursuit,&nbsp;<a href="https://allenai.org/">Allen Institute for AI</a>&nbsp;has partnered with several research organizations to produce the&nbsp;<a href="https://pages.semanticscholar.org/coronavirus-research">COVID-19 Open Research Dataset (CORD-19)</a>, a unique resource of over forty thousand plus scholarly articles about COVID-19, SARS-CoV-2, and related coronaviruses. It is updated daily as new research is published. This freely available data set is machine-readable, so researchers can create and apply natural-language processing algorithms, and hopefully accelerate the discovery of a vaccine.</p><p>AI has played a vital role in the COVID-19 outbreak apart from just research.</p><ol data-rte-list="default"><li><p><em> AI startup&nbsp;</em><a href="https://www.cnbc.com/2020/03/03/bluedot-used-artificial-intelligence-to-predict-coronavirus-spread.html"><em>Bluedot</em></a><em>&nbsp;detected a cluster of unusual pneumonia cases in Wuhan in late December and accurately predicted where the virus might spread.<br></em></p></li><li><p><em>&nbsp;</em><a href="https://www.cnbc.com/2020/03/18/how-china-is-using-robots-and-telemedicine-to-combat-the-coronavirus.html"><em>Robots</em></a><em>&nbsp;have been reducing human interaction by disinfecting hospital rooms, moving food and supplies, and delivering telehealth consultations. AI is being used to&nbsp;</em><a href="https://www.wsj.com/articles/online-map-tracks-coronavirus-outbreak-in-real-time-11583354911"><em>track and map the spread of infection</em></a><em>&nbsp;in real-time,&nbsp;</em><a href="https://www.radiologybusiness.com/topics/artificial-intelligence/artificial-intelligence-ct-images-coronavirus-diagnosis"><em>diagnose infections</em></a><em>,&nbsp;</em><a href="https://www.medrxiv.org/content/10.1101/2020.02.27.20028027v2"><em>predict mortality risk</em></a><em>, and more.<br></em></p></li><li><p><em>AI and FLIR enabled helmets have been used to monitor the temperature in large scale and regulate, isolate, and transfer patients who have shown symptoms of COVID-19.<br></em></p></li><li><p><em>AI enabled&nbsp;models that predict the rate of spread of this infection and help us flatten the curve with better targeting.<br></em></p></li><li><p><em>AI enabled models that predict the mutations of the virus that can help our scientists work with the vaccine to counter the mutations.<br></em></p></li><li><p><em>Robots that help healthcare workers with limiting the exposure to the patients.<br></em></p></li><li><p><em>Doctors using AI to triage COVID-19 patients (More info&nbsp;</em><a href="https://www.technologyreview.com/2020/04/23/1000410/ai-triage-covid-19-patients-health-care/"><em>here</em></a><em>).<br></em></p></li><li><p><em>AI is being used to fight misinformation about COVID-19.</em></p></li></ol><p>There is a slight problem though, modern AI methods require large amounts of labeled data to be effective, and that data isn’t currently available. Even when data is available, human judgment is essential to carefully analyze AI’s pattern recognition. This is something we need to keep in mind while using AI as a tool on such large scale unvetted data.</p><h2>My Approach</h2><p>Here is my humble attempt to accelerate the search for the COVID-19 vaccine using AI.</p><p>While we have some issues with the way we are collating data with regards to what is happening in real-time, we have some solid input based on the 3d structure of the protein that forms the outer layer of this virus. My approach to identifying a series of compounds used in drugs that are already available in the market.</p><p>My approach towards the problem from a technical standpoint encompasses the following steps.</p><ol data-rte-list="default"><li><p>Identify possibilities of the virus outer structure.</p></li><li><p>Identify vector possibilities from the diverse set of structures of the lipid spike protein.</p></li><li><p>Go through the list of available vaccines/medicines, parse them to identify chemical compounds.</p></li><li><p>Identify compounds that prevent the spike protein to bind with the ACE2 receptors of the human cells.</p></li></ol><h2>Algorithms</h2><p>The following algorithms have been used during the various stages of the research.</p><ul data-rte-list="default"><li><p>Cluster analysis</p></li><li><p>K-means clustering</p></li><li><p>Decision tree/forest</p></li><li><p>K-NN</p></li><li><p>Statistical classification</p></li></ul><p>My approach was to identify and use the rules of deduction so we can focus on the compounds that are probable. This would mean the positives will be limited and we can focus on them. The first step in this process was to do some cluster analysis on the compounds and identify positives. The next step was to build a strong decision tree / decision forest. Once the criteria was established, I ran the compounds through the decision forest. I was able to tweak the decision forest based on results which helped in streamlining compounds further. Once the positives were identified, I wanted to identify the nearest compounds to the positive compounds. This approach helped me identify&nbsp;34 compounds using AI that&nbsp;<strong><em>may</em></strong>&nbsp;prevent the spike protein from binding to the AEC2 receptors in the human&nbsp;body. Using these compounds&nbsp;<strong><em>may</em></strong>&nbsp;help stop the replication of the COVID-19 virus within the&nbsp;human body.</p><h2>Cluster Analysis</h2></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1600544883185_9444"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f665deb78917549d33fe01d/1600545774238-FGXXS3D2SUBX1ZSO5A8P/ke17ZwdGBToddI8pDm48kO3V6q6KF4Q0x4UdZodyGVNZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVEUyZMBYoKljUDZzBUjLz9HCyU9QRw0ahXsdyZm4nwj3jFvbuqF0GUInBxxtVhBOn4/ClusterAnalysis.gif" data-image="https://images.squarespace-cdn.com/content/v1/5f665deb78917549d33fe01d/1600545774238-FGXXS3D2SUBX1ZSO5A8P/ke17ZwdGBToddI8pDm48kO3V6q6KF4Q0x4UdZodyGVNZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVEUyZMBYoKljUDZzBUjLz9HCyU9QRw0ahXsdyZm4nwj3jFvbuqF0GUInBxxtVhBOn4/ClusterAnalysis.gif" data-image-dimensions="405x386" data-image-focal-point="0.5,0.5" alt="Data modeling of data compiled. GIF created via&amp;nbsp; imgflip" data-load="false" data-image-id="5f6663ee6909a42b50203e8f" data-type="image">
          </p>
        
          
        

        
          
          <figcaption>
            <p>Data modeling of data compiled. GIF created via&nbsp;<a href="http://imgflip.com/">imgflip</a></p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1600544883185_9733"><div><p>The objective of cluster analysis is to assign observations to groups “clusters” so that observations within each group are similar to one another with respect to variables or attributes of …</p></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.aiplusinfo.com/blog/aiandcovid19">https://www.aiplusinfo.com/blog/aiandcovid19</a></em></p>]]>
            </description>
            <link>https://www.aiplusinfo.com/blog/aiandcovid19</link>
            <guid isPermaLink="false">hacker-news-small-sites-24642851</guid>
            <pubDate>Wed, 30 Sep 2020 19:39:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using redo to manage data analysis workflow]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24642732">thread link</a>) | @kkoncevicius
<br/>
September 30, 2020 | http://karolis.koncevicius.lt/posts/using_redo_to_manage_r_data_analysis_workflow/ | <a href="https://web.archive.org/web/*/http://karolis.koncevicius.lt/posts/using_redo_to_manage_r_data_analysis_workflow/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">




<p>Real world data analysis projects are often complicated.
They can involve multi-gigabyte input files, complex data cleaning procedures, week-long computations, and elaborate reports.
Making changes and then tracking down the parts that need to be recomputed becomes close to impossible.
In this article I describe my approach for dealing with this problem, which is based on a lesser known build automation tool - redo<a href="#fn:1" id="fnref:1" title="see footnote"><sup>◦</sup></a>.</p>

<h2 id="redo">Redo</h2>

<p>Data science projects typically have complex pipelines involving input files, code, results, and reports.
Analyses can be computationally intensive and take hours if not days or weeks to complete.
Hence, data science practitioners need to be able to make changes without restarting the whole pipeline from scratch.
Workflow management becomes essential and many projects turn to build automation tools like Make<a href="#fn:2" id="fnref:2" title="see footnote"><sup>◦</sup></a>.
However Make has its warts, in particular when applied to data analysis, and so people end up designing their own variants, such as SCons<a href="#fn:3" id="fnref:3" title="see footnote"><sup>◦</sup></a>, Snakemake<a href="#fn:4" id="fnref:4" title="see footnote"><sup>◦</sup></a>, and Drake<a href="#fn:5" id="fnref:5" title="see footnote"><sup>◦</sup></a>, among others.</p>

<p>One lesser known alternative to the above mentioned tools goes by the name of “redo”.
Redo is a recursive build automation system that promises to be simpler and more powerful than Make.
Unlike Make or its derivatives redo is tiny, recursive, and has no special syntax of its own.
It allows declaring dependencies straight from within the code being executed, which enables writing scripts that “know” they will need to rerun themselves whenever their input data changes all without maintaining a separate dependency configuration file.
This demonstration will use the redo version by “apenwarr”<a href="#fn:6" id="fnref:6" title="see footnote"><sup>◦</sup></a> who rediscovered, documented, and popularized the idea and is the author and current maintainer of its most comprehensive implementation<a href="#fn:7" id="fnref:7" title="see footnote"><sup>◦</sup></a>.</p>

<h2 id="setup">Setup</h2>

<p>A typical data analysis workflow has four parts: 1) obtaining the data; 2) cleaning the data; 3) estimating a model; 4) producing a report.
Similarly our dummy project will consist of four steps:</p>

<ol>
<li>Obtain a dataset of chicken weights and their feed supplements.</li>
<li>Subset the data by only selecting one type of feed supplement.</li>
<li>Produce a “model” for the selected supplement using empirical density estimation.</li>
<li>Summarise the obtained results in a report.</li>
</ol>

<p>Each step will produce an output and save the results to a separate file.
To keep things simple all the scripts for the steps above will be written in R.
The overall goal is to construct a pipeline that can detect changes in our stored data files or our code and automatically reproduce the final report with all its dependencies.
This demonstration will start simple and add complexity along the way.</p>

<h2 id="doingandredoing">Doing and redoing</h2>

<p>Let’s start with the most basic redo command.
In the first step we have to obtain a dataset of chicken weights plus the type of supplements they were fed and store it in a file.
The dataset is freely available from within R so all we have to do is save it.
We enter the commands for this task to a file named <code>'rawdata.rds.do'</code>:</p>

<pre><code>1.  #!/usr/bin/env Rscript
2.
3.  outfile &lt;- commandArgs(trailingOnly = TRUE)[3]
4.
5.  saveRDS(chickwts, file = outfile)
</code></pre>

<p>Then to obtain the data file we go to a command line and call redo:</p>

<pre><code>$ redo rawdata.rds

redo:  rawdata.rds
</code></pre>

<p>Which creates the <code>'rds'</code> file named <code>'rawdata.rds'</code> containing the data and informs us about the result.</p>

<p>Some explanation is necessary.
The redo command simply takes an argument and tries to produce a file of the same name.
In this case the argument was <code>'rawdata.rds'</code> and, given the command, redo starts looking for instructions about how to produce it.
The rule for storing instructions is quite simple - they are stored in a separate file with a name constructed by adding a <code>'.do'</code> suffix to the original argument.
In other words - redo looks for instructions about producing <code>'rawdata.rds'</code> file in a file named <code>'rawdata.rds.do'</code>.</p>

<p>The file itself is treated as a shell script.
This is why it is started with a hash-bang<a href="#fn:8" id="fnref:8" title="see footnote"><sup>◦</sup></a> sequence followed by a path to a program that will be used to interpret the instructions.
We want to write our script in R so we specify Rscript.</p>

<p>Finally, when redo calls our script with <code>'redo rawdata.rds.do'</code> it passes three arguments to it:
1) The target name itself - <code>'rawdata.rds'</code>, 2) The basename of the target file - <code>'rawdata'</code>, 3) The temporary file to save the data in - <code>'rawdata.rds.redo.tmp'</code>.
After the execution finishes the file stored in the temp file (3rd argument) will be moved to the target (1st argument).
This mechanism makes sure that in the case of failed computation the existing target will not be corrupted.
And that is why we do not specify the output filename within the script ourselves but rather use the 3rd variable provided by redo.</p>

<p>The dataset is obtained and stored and so the first step of this project is now complete.</p>

<h2 id="dependencies">Dependencies</h2>

<p>What happens if we execute the previous redo command again? - nothing spectacular:</p>

<pre><code>$ redo rawdata.rds

redo  rawdata.rds
</code></pre>

<p>Redo executed the instruction file again and reproduced the output.
But there exists another command called <code>redo-ifchange</code> that behaves a bit differently:</p>

<pre><code>$ redo-ifchange rawdata.rds
</code></pre>

<p>After calling this command - nothing happens.
<code>redo-ifchange</code> differs from redo in an important way: it checks if any dependencies needed to reproduce the specified output have changed.
In our case redo knows only a single dependency for our <code>'rawdata.rds'</code> file - the ‘do’ instruction file itself.
It hasn’t changed so <code>redo-ifchange</code> halts and does not reproduce the target.</p>

<p>So let’s move on to the second step of the project and select a feed type.
To achieve this we produce a separate R file called <code>'subdata.rds.do'</code>:</p>

<pre><code>1.   #!/usr/bin/env Rscript
2.
3.   outfile &lt;- commandArgs(trailingOnly = TRUE)[3]
4.
5.   system("redo-ifchange rawdata.rds")
6.   rawdata &lt;- readRDS("rawdata.rds")
7.
8.   subdata &lt;- rawdata[rawdata$feed == "soybean", ]
9.
10.  saveRDS(subdata, file = outfile)
</code></pre>

<p>Take a closer look at the 5th line in the file above.
Here, before loading the data, we call the <code>redo-ifchange</code> command on it.
At this step the script temporarily halts and checks if our requested data file, <code>rawdata.rds</code>, needs to be recomputed.
If the target file is missing or some of its dependencies have changed it will be regenerated by calling the <code>'rawdata.rds.do'</code> script.
And if nothing changed the 5th line passes without redoing anything and the already existing data file is used.</p>

<p>Now, to obtain the output for the second step, we request the file with redo, just like before:</p>

<pre><code>$ redo subdata.rds

redo subdata.rds
</code></pre>

<p>All done, the result is stored in <code>'subdata.rds'</code>.
Currently we have the following files in our project:</p>

<pre><code>$ tree
.
├── rawdata.rds
├── rawdata.rds.do
├── subdata.rds
└── subdata.rds.do
</code></pre>

<p>Let’s remove all the <code>'rds'</code> data files and try reproducing the <code>'subdata.rds'</code> again:</p>

<pre><code>$ rm *.rds
$ redo subdata.rds

redo  subdata.rds
redo    rawdata.rds
</code></pre>

<p>Here we asked for <code>'subdata.rds'</code> but redo was smart enough to reproduce both of the data files.
What we did, in essence, is declared a dependency between two R scripts from within the script itself.</p>

<h2 id="defaultinstructions">Default instructions</h2>

<p>Before moving on we have to spend some time on a few redo implementation details.
By convention when we call <code>'redo a.b.rds'</code> command redo starts looking for an <code>'a.b.rds.do'</code> script.
But if the file doesn’t exist redo will search for a different file named <code>'default.b.rds.do'</code> which should store general instructions for producing any <code>'*.b.rds'</code> file.
As an example we rename our previous <code>'subdata.rds.do'</code> file to <code>'default.subdata.rds.do'</code>.
Now this do script will get executed whenever we use redo to request a file that ends with <code>'subdata.rds.do'</code>:</p>

<pre><code>$ mv subdata.rds.do default.subdata.rds.do
$ redo a.subdata.rds b.subdata.rds

redo a.subdata.rds
redo b.subdata.rds
</code></pre>

<p>Since both files generated above were produced by the same script <code>'default.subdata.rds.do'</code> they are identical - they both hold the data for soybean feed.
Those files will no longer be needed for our demonstration so we can get rid of them:</p>

<pre><code>$ rm *subdata.rds
$ tree
.
├── default.subdata.rds.do
├── rawdata.rds
└── rawdata.rds.do
</code></pre>

<h2 id="parameters">Parameters</h2>

<p>The default instructions introduced above can be exploited to implement parameters in our do scripts.
In the current stage we have a script - <code>'default.subdata.rds.do'</code> that is executed whenever we request an ‘rds’ file that ends with <code>'subdata.rds'</code>.
It always produces the data for the soybean feed but we can make it return different outputs based on the prefix of the target file.</p>

<p>Currently the feed types we are selecting are hard-coded in the code itself.
It would be nicer if we can specify them as parameters passed to the R script.
We rewrite <code>'default.subdata.rds.do'</code> file:</p>

<pre><code>1.   #!/usr/bin/env Rscript
2.
3.   outfile &lt;- commandArgs(trailingOnly = TRUE)[3]
4.   feed    &lt;- strsplit(outfile, "\\.")[[1]][1]
5.
6.   system("redo-ifchange rawdata.rds")
7.   rawdata &lt;- readRDS("rawdata.rds")
8.
9.   subdata &lt;- rawdata[rawdata$feed == feed, ]
10.
11.  saveRDS(subdata, file = outfile)
</code></pre>

<p>Two changes were made:
1) the 4th line uses the prefix of the output file in order to decide which feed type should be returned;
2) the 9th line then uses the selected feed type in order to subset the data.
This allows us to request various types of feed data:</p>

<pre><code>$ redo soybean.subdata.rds

redo soybean.subdata.rds

$ redo casein.subdata.rds

redo casein.subdata.rds
</code></pre>

<p>And now we have separate types in separate files.</p>

<h2 id="redoingwithparameters">Redoing with parameters</h2>

<p>In the third step we need a do script that, given subsetted feed data, estimates the density function and stores the result to a separate file.
Like the previous script, we want it to be general and work for any selected feed type.
For this to happen we have to know which input file to load based on the given output file.
If the script will be called by <code>'redo soybeen.density.rds'</code> command our target will be <code>'soybean.density.rds'</code>.
And from this we can deduce that the input file needed to obtain its density is <code>'soybean.subdata.rds'</code>.
So we make a file <code>'default.density.rds.do'</code> with …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://karolis.koncevicius.lt/posts/using_redo_to_manage_r_data_analysis_workflow/">http://karolis.koncevicius.lt/posts/using_redo_to_manage_r_data_analysis_workflow/</a></em></p>]]>
            </description>
            <link>http://karolis.koncevicius.lt/posts/using_redo_to_manage_r_data_analysis_workflow/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24642732</guid>
            <pubDate>Wed, 30 Sep 2020 19:30:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Artificial Intelligence in Health Care]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24642719">thread link</a>) | @Sanksshep
<br/>
September 30, 2020 | https://www.aiplusinfo.com/blog/ai-in-healthcare | <a href="https://web.archive.org/web/*/https://www.aiplusinfo.com/blog/ai-in-healthcare">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-3857ad1892c7d8adea01"><p><h2>Artificial intelligence has the potential to transform many aspects of patient care and administrative processes in healthcare. I think the role of artificial intelligence will be an asset to all healthcare professionals. The following article contains examples of artificial intelligence in healthcare and companies doing a great job at it.</h2></p></div><div data-block-type="2" id="block-yui_3_17_2_1_1600557578492_4166"><div><h3>Introduction</h3><p>Artificial intelligence (AI), Machine learning, NLP, Robotics, and Automation are increasingly prevalent in all aspects and are being applied to healthcare as well. These technologies have the potential to transform all aspects of health care from patient care to the development and production of new experimental drugs that can have a faster roll-out date than traditional methods.&nbsp;</p><p>There are numerous research studies suggesting that AI can outperform humans at key healthcare tasks, such as diagnosing ailments. Here is a great example, <a href="https://www.bbc.com/news/health-50857759#:~:text=Artificial%20intelligence%20is%20more%20accurate,images%20from%20nearly%2029%2C000%20women." target="_blank">AI ‘outperforms’ doctors diagnosing breast cancer¹.</a></p><p>Artificial intelligence is a collection of technologies that come together form artificial intelligence. AI’s diverse range of technologies impacts a wide spectrum of healthcare.&nbsp;</p><p>Tech firms and startups are also working assiduously on the same issues. Google, for example, is collaborating with health delivery networks to build prediction models from big data to warn clinicians of high-risk conditions, such as sepsis and heart failure. Google, Enlitic, and a variety of other startups are developing AI-derived image interpretation algorithms. Jvion offers a ‘clinical success machine’ that identifies the patients most at risk as well as those most likely to respond to treatment protocols. Each of these could provide decision support to clinicians seeking to find the best diagnosis and treatment for patients.</p><p>You will find below some technologies that improve a specific area in healthcare with examples sourced from the internet with citations.&nbsp;</p><h3>Machine learning</h3><p>Machine learning is an application of artificial intelligence (AI)<em> </em>that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. Machine learning focuses on the development of computer programs that can access data and use it to learn for themselves².</p><p>There are majorly three types of Machine learning — </p><ul data-rte-list="default"><li><p>Supervised Learning</p></li><li><p>Unsupervised Learning</p></li><li><p>Reinforcement Learning&nbsp;</p></li></ul><p>In healthcare, the most common application of machine learning is predictive medicine  —  predicting what treatment alternatives are likely to work best on a patient based on various patient traits, history, the treatment situation, and protocols. The supervised learning model for predictive medicine applications requires a training dataset, like all supervised learning models. the difference here is that there may be a lot of variables.&nbsp;</p><p>Using neural networks it is now possible to also predict whether a patient will acquire a particular ailment or not based on a set of variables and conditions that can be fed into algorithms in the form of data.</p><p>One common application of deep learning and neural networks is the ability to detect ailments/issues in the radiology images. I think deep learning should be increasingly applied wherever clinically possible. This will allow doctors and radiologists to just supervise results and focus on other important aspects of their job. This combination promises better accuracy of finding ailments with limited human intervention or supervision.&nbsp;</p><p>Here are some organizations that are doing groundbreaking work in this area.</p><blockquote><p><strong>Organization:</strong> <a href="https://www.pathai.com/">PathAI</a><br><strong>Location: </strong>Cambridge, Massachusetts<br><strong>How it’s using AI in healthcare:</strong> PathAI is developing machine learning technology to assist pathologists in making more accurate diagnoses. The company’s current goals include reducing errors in cancer diagnosis and developing methods for individualized medical treatment³.</p><p><strong>Organization:</strong> <a href="https://www.enlitic.com/">Enlitic</a><span><br></span><strong>Location: </strong>San Francisco, California<br><strong>How it’s using AI in healthcare: </strong>Enlitic develops deep learning medical tools to streamline radiology diagnoses. The company’s deep learning platform analyzes unstructured medical data (radiology images, blood tests, EKGs, genomics, patient medical history) to give doctors better insight into a patient’s real-time needs³.</p></blockquote><h3>Natural language processing</h3><p>In healthcare, most applications of NLP involve the creation, understanding, parsing, and classification of clinical documentation and published research. NLP can also be used to analyze clinical notes, prescriptions, help prepare reports, and possibly conversational AI. Few good examples of how NLP is currently being used.&nbsp;</p><ul data-rte-list="default"><li><p>Parsing data realtime from coronavirus research that is being published globally. You can find more information about this in my article <a href="https://medium.com/@sanksshep/how-can-ai-help-with-the-covid-19-vaccine-search-a68d40fc0cb0" target="_blank">here</a>.&nbsp;</p></li><li><p>Project Meena by Google. More information can be found <a href="https://ai.googleblog.com/2020/01/towards-conversational-agent-that-can.html" target="_blank">here</a>.</p></li></ul><h3>Decision Tree&nbsp;</h3><p>Decision trees require doctors and engineers to come up with an if-then-else decision flow chart that can help train machines to make decisions by building complex algorithms based on the finalized decision tree. This is critical and processes heavy software design, this enables the machines to take accurate decisions with human intervention. This will help save a ton of time for doctors and patients alike. This will enhance the capabilities of doctors to predict, analyze, and come up with a treatment plan for patient care.&nbsp;</p><p>This can also be used extensively in vaccine and treatment research provided the known variable is the ailment we are making the vaccine for and its pre-set conditions and protocols. This is an effective mechanism for pre-morbidity patients as well.&nbsp;</p><h3>Robotics</h3><p>Robots are becoming more intelligent, as other AI capabilities are being embedded in their OS. Other areas of improvements in AI have exponentially improved the capabilities of the robots and their ability to perform complex operations.</p><p>One such area of operation is robotic surgery. This enables surgeons to perform complex procedures with much greater precision and create precise, minimized, invasive incisions, and stitches. This is a game-changer in performing surgery, as long as human supervision exists. &nbsp;</p><p>Here are some examples of organizations using AI and Robotics&nbsp;</p><blockquote><p><strong>Organization: </strong><a href="https://www.vicarioussurgical.com/" target="_blank">Vicarious Surgical</a><br><strong>Location: </strong>Charlestown, Massachusetts<br><strong>How it’s using AI in healthcare: </strong>Vicarious Surgical combines virtual reality with AI-enabled robots so surgeons can perform minimally invasive operations. Using the company’s technology, surgeons can virtually shrink and explore the inside of a patient’s body in much more detail³.</p><p><strong>Organization:</strong> <a href="https://www.aurishealth.com/" target="_blank">Auris Health</a><br><strong>Location: </strong>Redwood City, California<br><strong>How it’s using AI in healthcare: </strong>Auris Health develops a variety of robots designed to improve endoscopies by employing the latest in micro-instrumentation, endoscope design, data science and AI. Consequently, doctors get a clearer view of a patient’s illness from both physical and data perspective³.</p><p><strong>Organization:</strong>  <a href="https://www.accuray.com/" target="_blank">Accuray</a>  <br><strong>Location: </strong>Sunnyvale, California<br><strong>How it’s using AI in healthcare: </strong>The Accuray CyberKnife System uses robotic arms to precisely treat cancerous tumors all over the body. Using the robot’s real-time tumor tracking capabilities, doctors and surgeons are able to treat only affected areas rather than the whole body. The Accuray CyberKnife robot uses 6D motion-sensing technology to aggressively track and attack cancerous tumors while saving healthy tissue³.</p><p><strong>Organization:</strong> <a href="https://www.intuitive.com/" target="_blank">Intuitive</a><br><strong>Location:</strong> San Francisco, California<br><strong>How it’s using AI in healthcare:</strong> Intuitive’s da Vinci platforms have pioneered the robotic surgery industry. Being the first robotic surgery assistant approved by the FDA over 18 years ago, the surgical machines feature cameras, robotic arms, and surgical tools to aide in minimally invasive procedures.<br>The da Vinci platform is constantly taking in information and providing analytics to surgeons to improve future surgeries. So far, da Vinci has assisted in over five million operations³.</p><p><strong>University: </strong><a href="https://www.cmu.edu/" target="_blank">Carnegie Mellon University</a> <br><strong>Location:</strong> Pittsburgh, Pennsylvania<br><strong>How it’s using AI in healthcare:</strong> The robotics department at Carnegie Mellon University developed Heartlander, a miniature mobile robot designed to facilitate therapy on the heart. Under a physician’s control, the tiny robot enters the chest through a small incision, navigates to certain locations of the heart by itself, adheres to the surface of the heart, and administers therapy³.</p><p><strong>Organization:</strong> <a href="http://microsure.nl/" target="_blank">MicroSure</a><br><strong>Location:</strong> Eindhoven, The Netherlands<br><strong>How it’s using AI in healthcare:</strong> MicroSure robots help surgeons overcome their human physical limitations. The company’s motion stabilizer system reportedly improves performance and precision during surgical procedures. Currently, eight of MicroSure’s micro-surgical operations are approved for lymphatic system procedures³.</p><p><strong>Organization:</strong> <a href="https://www.mazorrobotics.com/index.php/en-us/" target="_blank">Mazor Robotics</a><br><strong>Location:</strong> Caesarea, Israel<br><strong>How it’s using AI in healthcare:</strong> Surgeons use the Mazor Robotics’ 3D tools to visualize their surgical plans, read images with AI that recognizes anatomical features and perform a more stable and precise spinal operation³.</p></blockquote><h3>Robotic process automation</h3><p>Robotic process automation performs structured digital tasks for administrative purposes, ie those involving information systems, as if they were a human user following a script or rules. It relies on a combination of workflow, business rules, and ‘presentation layer’ integration with information systems to act like a semi-intelligent user of the systems. In healthcare, they are used for repetitive tasks like prior authorization, updating patient records, or billing. When combined with other technologies like image recognition, they can be used to extract data from, for example, faxed images in order to input it into transactional systems.</p><h3>Mass personalization</h3><p>Artificial Intelligence can help in mass personalization of patient care, treatments, procedures, vaccine research, and production. This along with human interaction can reduce costs and improve coverage across the board for healthcare.&nbsp;</p><p>AI can help with various aspects of patient care, like, charting the …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.aiplusinfo.com/blog/ai-in-healthcare">https://www.aiplusinfo.com/blog/ai-in-healthcare</a></em></p>]]>
            </description>
            <link>https://www.aiplusinfo.com/blog/ai-in-healthcare</link>
            <guid isPermaLink="false">hacker-news-small-sites-24642719</guid>
            <pubDate>Wed, 30 Sep 2020 19:29:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Systems Thinking: A Technical Overview]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24642695">thread link</a>) | @genghizkhan
<br/>
September 30, 2020 | https://hawkradius.com/systems-thinking-a-technical-overview/ | <a href="https://web.archive.org/web/*/https://hawkradius.com/systems-thinking-a-technical-overview/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://hawkradius.com/content/images/size/w300/2020/09/systems-thinking-header.jpg 300w,
                            https://hawkradius.com/content/images/size/w600/2020/09/systems-thinking-header.jpg 600w,
                            https://hawkradius.com/content/images/size/w1000/2020/09/systems-thinking-header.jpg 1000w,
                            https://hawkradius.com/content/images/size/w2000/2020/09/systems-thinking-header.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://hawkradius.com/content/images/size/w2000/2020/09/systems-thinking-header.jpg" alt="Systems Thinking: a Technical Overview">
            </figure>

            <section>
                <div>
                    <!--kg-card-begin: markdown--><p>I've had to to a bunch of reading about systems thinking with respect to healthcare recently, sparking an intense interest in the topic. You tend to find <a href="https://thesystemsthinker.com/systems-thinking-what-why-when-where-and-how/">a lot</a> <a href="https://learningforsustainability.net/systems-thinking">of literature</a> <a href="https://medium.com/disruptive-design/tools-for-systems-thinkers-the-6-fundamental-concepts-of-systems-thinking-379cdac3dc6a">online</a> talking about it. Systems thinking is described as an approach to problem solving in which one thinks about the whole system as being comprised of constituent parts and concentrates on parts and relationships both.</p>
<p>However, that doesn't really tell us much about what it is and how one goes about using this paradigm. If one wants to really get into what systems thinking is about, a more academic source might be handier. For the purposes of this article, I refer to a paper called "A Definition of Systems Thinking: A Systems Approach" by Arnold and Wade from 2015<sup><a href="#fn1" id="fnref1">[1]</a></sup> which goes about the process of definition in a very interesting way.</p>
<h2 id="sowhatreallyissystemsthinking">So what really is systems thinking?</h2>
<p>We can start by saying that systems thinking is, really, nothing more than a <em>system of thinking about systems</em>. If that sounds like a circular concept, buckle up. Systems tend to be the easiest to define using their function or their purpose; but that is, often, the hardest part of a system to tease out. In this case, fortunately, it is easy. The function of systems thinking is to think about systems!</p>
<p>To go deeper, we need to define what a system <em>is</em>. The Oxford Dictionary tells us that a system is "a set of things working together as parts of a mechanism or an interconnecting network; a complex whole." In other words, it is a set of things (let's call them elements) which are connected to each other, signifying relationships. So systems thinking is a framework which gives us the tools to understand how a system functions.</p>
<h3 id="whyisthisneeded">Why is this needed?</h3>
<p>Understanding systems turns out to be fundamental to nearly every task we manage because systems surround us. Nothing in this world is completely independent. Society, the government, electricity transmission, the shipping industry, the ecosystem of a pond, the climate are all examples of systems. Understanding each of them is an art in of itself: understanding their effects on each other and the surrounding world might be beyond the world's fastest supercomputer!</p>
<p>Hold on, you might say at this point. Don't we already understand these things? Aren't we already fluent in our understanding of electricity transmission systems? Didn't we <em>design</em> the government? Isn't the shipping industry the bedrock of all modern consumerism?</p>
<p>The answer is kind of, to all of those. Or rather, it depends on how we define these systems. Sure, we understand electricity transmission systems. But a huge element of these systems is the group of consumers who sit pretty at the other end, the ones who actually consume the electricity being generated and transmitted. Another big part happens to be the workers who maintain these lines. Another element of this system might be politicians (depending on your country) who may have a vested interest in making sure that the constituents of their choice get the generated electricity. Claiming that we understand all these actors and the relationships between them is more than can be said by most people. Similarly, it would be the height of folly for any man or woman to claim that they understand the inner workings of the government or the economic eddies that govern shipping.</p>
<p>The classical approach to problems such as this is called reductionism. Most wielders of the scientific method are intimately familiar with this school of thought. Break a complex problem into its constituent parts, understand each part, and lo behold! The complex, intractable problem is now reduced to several manageable issues.</p>
<p>This tends to be one part of systems thinking. Knowing how to define the elements of a system requires one to be educated in reductionism, but understanding their relationships tends to be a problem of exponentially increasing complexity as the number of elements of a system increase.</p>
<p>So let's start with the easier part of systems thinking. Reducing it to its elements.</p>
<h3 id="elementsofsystemsthinking">Elements of systems thinking</h3>
<p>Stave and Hopper (2007) give us a set of elements with which we may start understanding systems thinking<sup><a href="#fn2" id="fnref2">[2]</a></sup>:</p>
<ol>
<li>Recognizing Interconnections</li>
<li>Identifying Feedback</li>
<li>Understanding Dynamic Behavior</li>
<li>Differentiating types of flows and variables</li>
<li>Using Conceptual Models</li>
<li>Creating Simulation Models</li>
<li>Testing Policies</li>
</ol>
<p>Arnold and Wade (2015) add to and subtract from these elements to give us the following:</p>
<ol>
<li><strong>Recognizing Interconnections:</strong> This tends to be the most basic systems thinking still. One needs to be able to identify the key parts of a system and figure out the key relationships between them</li>
<li><strong>Identifying and Understanding Feedback:</strong> A bunch of these relationships form feedback loops, where two elements may feed into each other. These need to be understood and evaluated separately from the others</li>
<li><strong>Understanding System Structure:</strong> This is a step above the other two elements, in which one takes these key relationships and understands how the parts of a system fit together so as to describe the system as a whole</li>
<li><strong>Differentiating Types of Stocks, Flows, Variables:</strong> A stock is a pool of a given resource in a system. A flow would be the inflow or outflow of that resource. A variable would be something like flow-rate or the maximum quantity of a stock. Once the system structure is understood, stocks, flows and variables need to be quantified and described separately</li>
<li><strong>Identifying and Understanding Non-Linear Relationships:</strong> This has been separated out from the previous element by Arnold and Wade. In particular, this element is also about measuring stocks and flows, but it measures those which do not have linear relationships with each other</li>
<li><strong>Understanding Dynamic Behavior:</strong> All the elements and relationships which have been understood interact with each other and may behave unpredictably. Such behaviour is called dynamic behaviour. Understanding this is one of the core functions of systems thinking</li>
<li><strong>Reducing Complexity by Modeling Systems Conceptually:</strong> While complexity is part and parcel of most systems, understanding them often requires stripping away that complexity and observation from different angles. In other words, one needs to know how to model a system so as to be able to explain it well</li>
<li><strong>Understanding Systems at Different Scales:</strong> And finally, this skill is the ability to understand systems at different scales. Each element of a system may be a system itself, and the system being viewed is probably an element in a more complex system. Being aware of these details can lead to better insights</li>
</ol>
<h3 id="relationships">Relationships</h3>
<p>Now that we know all the elements, we can see what the relationships between them are like. The easiest way to understand it is to map it out (adapted from Arnold and Wade, 2015).</p>
<p><img src="https://hawkradius.com/content/images/2020/09/systems-thinking-relationships-5.png" alt="Relationships between the elements of systems thinking"></p>
<p>This is a slightly complicated map. In short, the thick arrows with solid borders represent strong relationships, and the thin arrows with dotted borders represent weak relationships. The strong relationships are as follows:</p>
<ol>
<li>Understanding system structure strongly enhances understanding of dynamic system behaviour</li>
<li>Understanding a system's structure leads to developing conceptual models properly</li>
<li>A conceptual understanding of the system may lead to insights about the system's role in as an element in bigger systems as well as the complexity of its constituent elements</li>
</ol>
<p>The weak relationships come out thus:</p>
<ol>
<li>Understanding dynamic behaviour of a system may prompt one to go back and take a second look at the elements and relationships already identified</li>
<li>It is often worth going back and re-identifying elements and relationships when making conceptual systems</li>
<li>Understanding a system conceptually makes it easier to identify and seek out dynamic behaviour</li>
<li>Once a person is able to start understanding systems at different scales, it can reveal additional elements and relationships one might not have picked up at the start of the exercise</li>
<li>Understanding dynamic behaviour can allow the incorporation of dynamic models when creating a conceptual system</li>
<li>Knowledge of the different scales at which a system operates can help in enhancing the accuracy of any conceptual models one might like to use</li>
</ol>
<p>All the four major elements in the diagramme strongly improve one's ability to identify systems, predict their behaviours, and devise modifications if and when needed.</p>
<h2 id="definitionofsystemsthinking">Definition of systems thinking</h2>
<p>So now that we <em>have</em> come this far, we can understand the definition of systems thinking:</p>
<blockquote>
<p>Systems thinking is a set of synergistic analytic skills used to improve the capability of identifying and understanding systems, predicting their behaviors, and devising modifications to them in order to produce desired effects. These skills work together as a system. - Arnold and Wade (2015)</p>
</blockquote>
<p>These analytical skills and their interconnections are easy enough to understand, and they make complete sense when seen from the lens of systems thinking itself.</p>
<p>In the next post in this series, we shall look at some systems thinking frameworks used in healthcare followed by an intervention strategy informed by the same.</p>
<hr>
<section>
<ol>
<li id="fn1"><p>Arnold, R.D. and Wade, J.P., 2015. A definition of systems thinking: A systems approach. Procedia computer science, 44(2015), pp.669-678. <a href="#fnref1">↩︎</a></p>
</li>
<li id="fn2"><p>Stave, K. and Hopper, M., 2007, July. What constitutes systems thinking? A proposed taxonomy. In 25th International Conference of the System Dynamics Society. <a href="#fnref2">↩︎</a></p>
</li>
</ol>
</section>
<!--kg-card-end: markdown-->
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://hawkradius.com/systems-thinking-a-technical-overview/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24642695</guid>
            <pubDate>Wed, 30 Sep 2020 19:27:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Buy vs. Building Software]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24642596">thread link</a>) | @neinasaservice
<br/>
September 30, 2020 | https://21-lessons.com/2020/09/30/buy-vs-build/ | <a href="https://web.archive.org/web/*/https://21-lessons.com/2020/09/30/buy-vs-build/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
	<p><a href="#content">Skip to content</a></p><div id="content">
		<div>

		

<header id="masthead" role="banner">
	<div>

		<p><a href="https://21-lessons.com/" rel="home" itemprop="url"><img width="400" height="400" src="https://i2.wp.com/21-lessons.com/wp-content/uploads/2020/06/original-scaled.png?fit=400%2C400&amp;ssl=1&amp;is-pending-load=1" alt="" loading="lazy" data-size="patch-site-logo" itemprop="logo" data-attachment-id="694" data-permalink="https://21-lessons.com/original-scaled/" data-orig-file="https://i2.wp.com/21-lessons.com/wp-content/uploads/2020/06/original-scaled.png?fit=400%2C400&amp;ssl=1" data-orig-size="400,400" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Original – Scaled" data-image-description="" data-medium-file="https://i2.wp.com/21-lessons.com/wp-content/uploads/2020/06/original-scaled.png?fit=300%2C300&amp;ssl=1" data-large-file="https://i2.wp.com/21-lessons.com/wp-content/uploads/2020/06/original-scaled.png?fit=400%2C400&amp;ssl=1" data-lazy-src="https://i2.wp.com/21-lessons.com/wp-content/uploads/2020/06/original-scaled.png?fit=400%2C400&amp;ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></p><div>
		<p><a href="https://21-lessons.com/" rel="home">
			21 Lessons		</a>

		</p></div>
			<p><span>Learn 21st Century Skills</span>
			</p>

		
	</div><!-- .site-branding -->

	<nav id="site-navigation" role="navigation">

		<ul id="menu-main-menu"><li id="menu-item-343"><a href="https://21lessonscom.wordpress.com/">Home</a></li>
<li id="menu-item-1094"><a title="About Jan" href="https://work-with-jan.com/">About</a></li>
</ul>
	</nav><!-- #site-navigation -->

</header><!-- #masthead -->


	<div id="primary">
		<main id="main" role="main">

			
<article id="post-1145">

    <div>

        
        <header>
            <div>

                <p><span><a href="https://21-lessons.com/category/business/" rel="category tag">Business</a>, <a href="https://21-lessons.com/category/programming/" rel="category tag">programming</a></span></p><div>

                    <p><span> by <span><a href="https://21-lessons.com/author/jan21lessonscom/">Jan</a></span></span><span><a href="https://21-lessons.com/2020/09/30/buy-vs-build/" rel="bookmark"><time datetime="2020-09-30T14:54:00-04:00">September 30, 2020<span>2:54 pm</span></time></a></span>
                </p></div>

            </div><!-- .entry-meta -->

            
        </header><!-- .entry-header -->

        
    </div>

	<div>

		
<figure><img data-attachment-id="1146" data-permalink="https://21-lessons.com/2020/09/30/buy-vs-build/buy_vs_build/" data-orig-file="https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?fit=2048%2C2048&amp;ssl=1" data-orig-size="2048,2048" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Buy_Vs_Build" data-image-description="" data-medium-file="https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?fit=300%2C300&amp;ssl=1" data-large-file="https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?fit=980%2C980&amp;ssl=1" loading="lazy" width="980" height="980" src="https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=980%2C980&amp;ssl=1" alt="Buy vs Build Sketchnote, explaining the cost of not using a paid tool for CI/CD" srcset="https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?w=2048&amp;ssl=1 2048w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=300%2C300&amp;ssl=1 300w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=1024%2C1024&amp;ssl=1 1024w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=150%2C150&amp;ssl=1 150w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=768%2C768&amp;ssl=1 768w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=1536%2C1536&amp;ssl=1 1536w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=1200%2C1200&amp;ssl=1 1200w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=800%2C800&amp;ssl=1 800w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=400%2C400&amp;ssl=1 400w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=200%2C200&amp;ssl=1 200w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=640%2C640&amp;ssl=1 640w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=500%2C500&amp;ssl=1 500w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=928%2C928&amp;ssl=1 928w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=600%2C600&amp;ssl=1 600w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=100%2C100&amp;ssl=1 100w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?w=1960&amp;ssl=1 1960w" sizes="(max-width: 980px) 100vw, 980px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?w=2048&amp;ssl=1 2048w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=300%2C300&amp;ssl=1 300w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=1024%2C1024&amp;ssl=1 1024w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=150%2C150&amp;ssl=1 150w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=768%2C768&amp;ssl=1 768w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=1536%2C1536&amp;ssl=1 1536w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=1200%2C1200&amp;ssl=1 1200w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=800%2C800&amp;ssl=1 800w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=400%2C400&amp;ssl=1 400w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=200%2C200&amp;ssl=1 200w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=640%2C640&amp;ssl=1 640w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=500%2C500&amp;ssl=1 500w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=928%2C928&amp;ssl=1 928w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=600%2C600&amp;ssl=1 600w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=100%2C100&amp;ssl=1 100w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?w=1960&amp;ssl=1 1960w" data-lazy-src="https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=980%2C980&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>

<p id="jp-relatedposts">
	<h3><em>Also checkout these posts</em></h3>
</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article><!-- #post-## -->



		</main><!-- #main -->
	</div><!-- #primary -->


<div id="secondary" role="complementary">

	
</div><!-- #secondary -->		</div><!-- .container -->
	</div><!-- #content -->

	<!-- #colophon -->
	<div>
		<div>
			<form role="search" method="get" action="https://21-lessons.com/">
				<label>
					<span>Search for:</span>
					
				</label>
				
			</form>			<p>Begin typing your search above and press return to search. Press Esc to cancel.</p>
		</div>
		</div>
</div></div>]]>
            </description>
            <link>https://21-lessons.com/2020/09/30/buy-vs-build/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24642596</guid>
            <pubDate>Wed, 30 Sep 2020 19:19:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Progress in Biology Is Slow – Here's How We Can Speed It Up]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 21 (<a href="https://news.ycombinator.com/item?id=24642489">thread link</a>) | @ashwal
<br/>
September 30, 2020 | https://adamashwal.com/irreducible | <a href="https://web.archive.org/web/*/https://adamashwal.com/irreducible">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

			<p>Living is great and I'd prefer to do more of it. Unfortunately, progress towards immortality has been rather slow — for all of our technological progress in the last century we've only picked up a few extra years of life. An incorrect framing of the problem has led to slow progress, but with a little bit of mind shift we can choose much better strategies for learning about and manipulating biology.</p>
<h3 id="what-s-the-status-quo-">What's the status quo?</h3>
<p>There's been a subset of humans over the last 100 years who also would like to live longer and healthier lives and have invested considerable time and energy into this problem. They've mostly failed as is evidence by the fact if you make it out of childhood, keep a good BMI, stop smoking, and exercise, you'll make it, at best, <a href="https://ourworldindata.org/life-expectancy">a decade longer than someone in the 1700s</a> (provided you escaped the trough of death that was childhood). In that same 100 years we took our first flight on Earth and then landed on the moon. In that same 100 years we went from 0 transistors per chip to 50,000,000,000. In that same 100 years we invented the Cool Ranch Dorito. So why did we succeed in so many other places but have failed in the most important? Why don't we live extremely long, healthy, and happy lives?</p>
<h3 id="why-has-this-approach-worked-in-other-areas-">Why has this approach worked in other areas?</h3>
<p>Some problems are, in retrospect, clearly easier than others. But if you had surveyed the leading minds in 1900 which would be easier: splitting the atom, sending a probe outside the solar system, or living to 90, it's hard to imagine it would be the last option they would have chosen. Yet here we are.</p>
<p>There are problems that on the face of it seem of similar difficulty to an outsider but are magnitudes (and magnitudes and magnitudes) harder to solve. What leads to this difference can be summarized as <em>computational reducibility</em>. As way of example, take the planet. Think of every atom on Earth- the rocks, the trees, that one ex who still drifts in and out of memory. If I want to know where this sphere will be in the universe tomorrow or 1,000 years from now and I don't have a notion of basic physics I may think this intractable. There's so much going on! How could one possibly think to describe how all these atoms would move through space and time? But it turns out to be fairly trivial - all those atoms can be reduced to a single point, a center of mass, and then calculations of momentum can be easily computed and trajectory projected forward. There are many systems that allow for these "shortcuts" where the dimensionality can be collapsed and the useful information is still present. A bridge builder doesn't need to think of each atom in a brick, or even really the brick; it's enough to think of the collection of bricks and how they are arranged.</p>
<h3 id="engineering-takes-place-in-reducible-places">Engineering takes place in reducible places</h3>
<p>Engineering, generally, is the practice of working on problems that are tractable. Given constraints on energy and time, only hard problems that have been sufficiently reduced are tractable and as such are the ones that are worked on. Oftentimes science leads us to new ways of reducing the complexity of problems (think Newton and his equations in the previous example). This isn't a law, just a result of how resources are allocated. </p>
<h3 id="is-biology-reducible-">Is Biology Reducible?</h3>
<p>We haven't seen progress in biology because it is stubborn to attempts to reduce it. Darwin was one of the last great reducers - able to collapse the high dimensional problem of evolution into a few axioms. But even with natural selection in hand, the resolution of claims is not particularly specific. Hypotheses are hard to prove or disprove given the near impossibility of running a counterfactual and it mostly serves as a post-hoc description (large proboscis <a href="https://en.wikipedia.org/wiki/Xanthopan">moths</a> notwithstanding). Perhaps if we were luckier we could  have lived in a universe that allowed us to use natural selection to know the structure of cells and animals without having to go look (this is a little true - something I'll explore in a future post), similar to knowing the position of the planets a millennia in advance.</p>
<p>What is it about biology that makes it irreducible but splitting the atom was something we accomplished 80 years ago? Spitting in the face of entropy is hard and the number of problems that need to be solved by a biological system are vast. The components of that system are not elegant fundamental laws of the universe but artisanal components created by random search through a loosely constrained fitness space. Even highly conserved pathways still exist in a unique context of the whole organism. </p>
<h3 id="biology-s-drunken-walk">Biology's Drunken Walk</h3>
<p>Biology is constantly transitioning from current state to a future state where some future branch of the evolutionary tree has higher fitness but the potential branch space is massive and the "choice" of which branch is picked is a random process. For example, in a scenario where the environment is slowly acidifying, any given bacteria has many solutions to survive. While aesthetically they could be vastly different (off the top of my head: changes to cell membranes, additional transmembrane proton pumps, neutralizing organelles, heat shock proteins, etc), which one ends up being dominant for a given bacteria is a random mutation. Given enough bacteria "searching" the solution space, you'll likely see many solutions.</p>
<p>Crucially, because in any scenario there is a one-to-many relationship between a problem and solutions, you can't extrapolate which solutions an organism possesses based on reasoning. You can’t postdict, you have to go look.</p>
<h3 id="so-what-do-we-do-">So, what do we do?</h3>
<p>So biology suffers from low reducibility - we aren’t able to summarize systems allowing us to make inferences cheaply. In the instance of disease this prevents both easy understanding of the disease state, i.e. what is going wrong, and prevents easy drug design, i.e. which node in the system do I push on in order to reverse the disease state. Right now, drug discovery is a lot of serendipity and a lot of pretending we know enough to pick targets. Unsurprisingly, this mostly fails.</p>
<p>There is another way. Currently, we brute force biology via Grad student search and it’s remarkably slow. A small number of underpowered, poorly done experiments makes up the bulk of what is produced. A model organism is chosen, an intervention is proposed, a measurement is done, and a paper is written: repeat ad nauseam. </p>
<p>But if an infinite number of monkeys can write Shakespeare, an infinite number of mice can allow us a way forward.</p>
<p>If we care about blood pressure, for example, why have we not given every drug, at every dosage, every regiment, and in every combination to a mouse and actually seen what happens?
We <em>do</em> have high throughput screening, mostly in individual cells or enzymes, but this is mostly garbage owing to the information decay from cell to whole organism (something I will expound on in a future post). Is my proposed solution expensive? Yes! Combinatorial explosions are the opposite of computational reducibility. But my point is that we can't just hope to have cheaper solutions in the future – that is the ostrich approach to progress. And we spent $288,100,000,000 to get to the moon.</p>
<p>The problem is also not as intractable as it may first seem. How do we test a large number of drugs on a large number of mice? Drive the cost down on any marginal mouse. Recent advances in machine learning allow automation of those pesky variable costs. Image recognition and classification are now good enough to track a mouse and its movements automatically - there is no need to babysit mice and manually classify behavior. With the state of every mouse known, simple robotics, e.g. food/medication administration and outcome measurements, become possible. The simplest experiments are possible today, and with a concerted effort, the realm of possible can grow. </p>
<p>There will always be innovations in new measurement techniques, new ways of peering into the system. Biologists generally fail in scaling these new techniques at a detriment to our ability to control biology. By adding scalability as an important aspect of innovation we can unlock so much more with what we already have today. </p>
<p>Importantly, this isn't just limited to a causal inference between a drug and a disease. We're getting very good at measuring the state of systems, just pick your favorite "–ome". It's not hard to squint and see that large numbers of interventions, on large numbers of model organisms, with large readouts of state will approach full 4D models of organic systems.  </p>
<p>There are not going to be any shortcuts with biology. The sooner we recognize this, the sooner we can start building systems that operate at the scale needed to bring useful inference, drug discovery, and network topology into the 21st century. </p>
<p>Thank you to Aubree for her feedback on commas, words, and ideas.</p>


			
			
		

			
			




		</div></div>]]>
            </description>
            <link>https://adamashwal.com/irreducible</link>
            <guid isPermaLink="false">hacker-news-small-sites-24642489</guid>
            <pubDate>Wed, 30 Sep 2020 19:10:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Trillium: Cancer Drug Bet Pays Off for Biotech CEO with 3,600% Stock Surge]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24642462">thread link</a>) | @finphil
<br/>
September 30, 2020 | https://www.bnnbloomberg.ca/cancer-drug-bet-pays-off-for-biotech-ceo-with-3-600-stock-surge-1.1501665 | <a href="https://web.archive.org/web/*/https://www.bnnbloomberg.ca/cancer-drug-bet-pays-off-for-biotech-ceo-with-3-600-stock-surge-1.1501665">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>(Bloomberg) -- When Jan Skvarka joined biotechnology firm Trillium Therapeutics Inc. as chief executive officer, he made a big bet to reshape the company and went all-in on a cancer treatment platform. Now, heâ€™s reaping the rewards.</p><p>It was the gamble of a lifetime for the 53-year-old CEO, who decided to shutter the drug developerâ€™s lead program on treating tumors directly and instead focus on cancer-fighting technology for patients with different blood cancers. Investors cheered, rewarding him with a 3,600% stock-surge since he joined the company a year ago.</p><p>Trillium is the No. 1 stock on Canadaâ€™s S&amp;P/TSX Composite Index this year, skyrocketing past tech behemoth Shopify Inc. by almost 10-fold. Itâ€™s U.S.-listed shares are the fourth best-performing company on the Nasdaq Composite Index.</p><p>Despite its epic stock-market rally, every analyst covering the company rates it a buy, signaling that further gains are on the horizon for investors that missed out on Trilliumâ€™s initial boom. Wall Street has an average 12-month share price target of $17.58, implying gains of about 30% over the coming year, data compiled by Bloomberg show. Trilliumâ€™s shares closed trading at $13.55 on Tuesday.</p><p>â€œWe need to walk before we run, but if you ask me what our ultimate aspirations are, itâ€™s to challenge chemotherapy,â€� Skvarka, a former partner of Bain &amp; Co. and Harvard Business School graduate, said by phone.</p><p>The rebirth of Cambridge, Massachusetts-based Trillium attracted a whoâ€™s who of health-focused hedge funds and snagged a $25 million investment from industry giant Pfizer Inc. For Skvarka, who celebrated the anniversary of his first year last weekend, the decision to restructure the company and focus on a newer cancer technology has transformed the drugmaker into a firm with a market cap of about $1.3 billion. Last Halloween, it had a value of a mere $7 million.</p><p>Some of the hedge funds that have invested in the company, like Millennium Management LLC and Avoro Capital Advisors, have cashed in on part of the yearâ€™s gains, while others including Ghost Tree Capital LLC have piled onto their positions.</p><p>Trillium, like many drug-developing peers that are focused on cancer therapies, is looking to improve on current treatment options and help patients live longer lives.</p><p>â€œItâ€™s a very exciting time,â€� Skvarka said. â€œWe are squarely out of the realm of preclinical data and in the realm of clinical data.â€�</p><p>M&amp;A Target?</p><p>Those aspirations are where the companyâ€™s cancer medicines, TTI-621 and TTI-622, come in. The pair of programs, which have shown promising results in early stage studies, are in an emerging class of cancer-fighting technologies that triggered Gilead Sciences Inc.â€™s $4.9 billion takeout of peer Forty Seven Inc. earlier this year. That deal has sparked speculation that Trillium could be among the next group of companies snatched up by bigger players amid the industryâ€™s rush of deals.</p><p>While Skvarka wouldnâ€™t comment on whether the company has been approached about a sale, he said that Trilliumâ€™s goal is to keep its options open for the time being.</p><p>â€œThe way we struck the Pfizer deal was very important for us as it kept our optionality openâ€� for the future, he said. â€œI am a big believer of optionality and having as many options as possible. The options for us are to continue alone or strike a global partnership potentially a way down the road.â€�</p><p>Â©2020 Bloomberg L.P.</p></div></div>]]>
            </description>
            <link>https://www.bnnbloomberg.ca/cancer-drug-bet-pays-off-for-biotech-ceo-with-3-600-stock-surge-1.1501665</link>
            <guid isPermaLink="false">hacker-news-small-sites-24642462</guid>
            <pubDate>Wed, 30 Sep 2020 19:08:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Startup Advisors]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24642383">thread link</a>) | @dmonn
<br/>
September 30, 2020 | https://mentorcruise.com/blog/startup-advisors-what-they-do-where-meet-them-and-/ | <a href="https://web.archive.org/web/*/https://mentorcruise.com/blog/startup-advisors-what-they-do-where-meet-them-and-/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Advisors are the bloodline of many modern startups. Not only do they often add fancy names to your team page, but they can <a href="https://mentorcruise.com/blog/how-get-business-mentor/">help your business</a> with their connections and network, help you work through issues, bring in their inputs and open doors with partners and investors that would usually be closed.</p>
<p>That doesn’t come from nothing, of course. Companies must prove their worth, show progress every week and the traction an advisor expects for them to stay on board. That often also means that the advisor is compensated or has a stake in the company.</p>
<h2 id="what-does-a-startup-advisor-do">What does a startup advisor do?</h2>
<p>Startup advisors are chosen and utilized on a varying range of topics. The most common startup advisors are professors, founders and serial founders themselves, with deep expertise of the niche that a company acts in.</p>
<p>Apart from that, they may be growth advisors, with deep expertise in marketing, sales and growing products from nothing to millions of users. Growth is often the number one priority at startups and bringing on independent and new ideas can work wonders.</p>
<p>There are also technical advisors, commonly seen in industries where deep technical expertise is needed or where founders need extra support to push through the challenges.</p>
<p>No matter the nature of the advisors, an advisory board is usually a formal group and often the first place that startup founders can go to talk through issues.</p>
<h2 id="how-do-i-compensate-a-startup-advisor">How do I compensate a startup advisor?</h2>
<p>Startup advisors don’t work for free. For the value they provide, they are looking for a return.</p>
<p>Most commonly, advisors have an equity stake in the company and are paid $1,000 upwards, plus expenses, for each meeting to reimburse their time.</p>
<p>Other advisors will not take a meeting fee and rely on a more generous equity package instead, while a monetary meeting and retainer fee may be preferred by others.</p>
<p>The compensation and service plan is usually tightly set in an advisory agreement, like this one by the <a href="https://fi.co/insight/the-founder-institute-s-standard-advisor-agreement-for-startups-fast">Founder Institute</a>.</p>
<h2 id="where-can-i-find-a-startup-advisor">Where can I find a startup advisor?</h2>
<p>So, you’re sold on the idea of getting an <a href="https://mentorcruise.com/blog/how-can-startup-mentor-can-help-your-business-succ/">advisor for your startup</a>, where can you get one? Good advisors aren’t sold on the street, so you need to go to the right places to find one.</p>
<h3 id="1-startup-networking-events">1. Startup networking events</h3>
<p>Be it meetups, demo days or startup groups. If you want to make the right connections, startup network events are usually where investors and advisors are looking to hear your ideas.</p>
<p>If you work in a specific industry and visit those events, you will also get the added benefit of finding people experienced and well-connected in those industries.</p>
<p>When it comes to signing up an advisor to your team, it’s always good to show others what you can do. Participate in presentations and demo days or directly pick out who you want to talk with and give it your best. </p>
<h3 id="2-partners">2. Partners</h3>
<p>It wouldn’t be the first time that someone signed a business partner, customer or supplier to come on board as an advisor or even an investor.</p>
<p>Exploring the business partners you are close with is a great way to get an introduction to advisors in your industry. Even better, there’s no need to make things formal right away. You can start by asking a few questions, meeting once in a while to get some advice, before moving on to the next stage.</p>
<p>This is an approach we value and exercise at <a href="https://mentorcruise.com/">MentorCruise</a> religiously. Just yesterday, I’ve signed up for another session with a <a href="https://mentorcruise.com/expert/marketing/">marketer</a>, right here on the platform. In the past, I’ve booked sessions to push through scalability issues and gain new ideas in marketing. Talk about scratching our itch!</p>
<h3 id="3-cold-emailing-startup-advisors">3. Cold emailing startup advisors</h3>
<p>A good cold email can open a ton of doors! <a href="https://woodpecker.co/blog/how-to-write-a-cold-email-that-actually-works-six-step-tutorial/">Writing a good cold email</a> is an art in itself, but if you master it, there’s no limit to what you can achieve and who you can reach.</p>
<p>The great thing about this is that you can pick <strong>anyone</strong> on the world and see whether they can help you. The not-so-great thing is that great advisors get a ton of cold emails and most of them land in spam right away. As someone receiving a fair share of cold emails myself, not many are getting the response you’d like.</p>
<p>Therefore, a few short tips to make your cold email feel a lot less cold.</p>
<ul>
<li>
<p>Do not, never, automate your cold emails. Keep things personal and human.</p>
</li>
<li>
<p>Don’t ask them to become an advisor or whether you will be able to send them a question – lead with your question and be direct</p>
</li>
<li>
<p>Offer something in return. Support a project or cause that they are passionate about or feedback to something they’ve written/built/talked about.</p>
</li>
</ul>
<p>In short: be human and natural, don’t ask for commitment or even a reply, just pay it forward and see whether it can lead to a relationship.</p>
<h3 id="4-online-communities">4. Online Communities</h3>
<p>Especially nowadays, startup events and networking increasingly happen online. There are online communities out there, where super-smart engineering students share the same space with 8-figure business owners. The possibilities are endless.</p>
<p>Even better – people in the right communities <strong>love</strong> to interact with others. Whereas with cold emailing your biggest challenge is to even get a reply, in communities you will find a lot of people with the same mindset as you.</p>
<p>In many cases, what you will find in these places is peer-to-peer advisors: Folks in the trenches together, trying to help each other out. That’s not something bad though! In many cases, you will find long-lasting and valuable contacts in communities like this.</p>
<p>Our top picks for this are <a href="https://indiehackers.com/">IndieHackers</a>, <a href="https://megamaker.co/">MegaMaker</a> and <a href="https://www.startupschool.org/">Startup School</a>, but there are many others!</p>
<h3 id="5-mentorship-platforms">5. Mentorship Platforms</h3>
<p>Mentorship platforms are popping up left and right and indeed, they are one of the easiest ways to connect with an expert for advice.</p>
<p>Besides ourselves offering sessions and longterm mentorships with experts all around the tech industry, there are plenty of <a href="https://mentorcruise.com/blog/best-mentor-programs-tech/">other players in the market</a> that can help you.</p>
<p>On one side, you have apps like <a href="https://growthmentor.com/">GrowthMentor</a>, helping you to connect casually to growth and marketing experts that can help you get unstuck in a few sessions you can book through the platform.</p>
<p><img alt="GrowthMentor" src="https://cdn.mentorcruise.com/pinax-images/image-set-122/50229a0f-14a9-43dd-8b09-bd4ce583660d.png"></p>
<p>Then, you have programs like <a href="https://mentorpass.co/">Mentorpass</a> that allow you to get access to a range of great advisors for as long as you need them, to push through issues and problems in a few calls as well.</p>
<p>While not the cheapest option, it’s probably the most comfortable and accessible way to get access to real experts in their topic and your industry.</p>
<h3 id="6-incubators-and-accelerators">6. Incubators and accelerators</h3>
<p>Finally, if you want to go the full way, you can get very close 1-to-1 mentorships and advisors if you join a renowned incubator program. For example, the well-known <a href="https://www.ycombinator.com/">YCombinator</a> and <a href="https://www.techstars.com/">Techstars</a> programs each give you a personal advisor when you join their program.</p>
<p>Of course, incubators and accelerators also come with the most baggage out of all of them. It’s not uncommon for these programs to have rigid investing rules, long presence programs and is usually bound to them taking a free equity stake, so make sure you know what you are getting into!</p>
</div></div>]]>
            </description>
            <link>https://mentorcruise.com/blog/startup-advisors-what-they-do-where-meet-them-and-/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24642383</guid>
            <pubDate>Wed, 30 Sep 2020 19:02:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Revisiting Apple Notes (5): Encrypted Notes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24642368">thread link</a>) | @ra7
<br/>
September 30, 2020 | https://ciofecaforensics.com/2020/07/31/apple-notes-revisited-encrypted-notes/ | <a href="https://web.archive.org/web/*/https://ciofecaforensics.com/2020/07/31/apple-notes-revisited-encrypted-notes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemprop="articleBody"> <p><strong>TL;DR</strong>: Apple Notes allows users to encrypt note contents at rest and the <a href="https://github.com/threeplanetssoftware/apple_cloud_notes_parser">Apple Cloud Notes Parser</a> now supports parsing of encrypted content.</p> <!--more--> <h2 id="background">Background</h2> <p>Apple Notes has allowed users to encrypt their note’s contents at rest in the NoteStore database since <a href="https://support.apple.com/en-us/HT208010#93">iOS 9.3</a>. While some commercial forensics tools can unlock notes, I am unaware of free, open source tools in the community which do so and adding this functionality was a challenge posed to me by <a href="https://smarterforensics.com/">Heather Mahalik</a> a few years ago during a <a href="https://www.sans.org/course/advanced-smartphone-mobile-device-forensics">SANS FOR585</a>. The foundations which Apple uses to carry out the encryption are well documented standards, but initial attempts at putting them together when the parser was written in Perl failed. The struggles with debugging are what led to completely rewriting the parser into an object-oriented language in late 2019 and early 2020. With the parser rewritten, each of the foundational blocks could be implemented discretely and built into the overall program, leading to decryption of encrypted notes in July of 2020.</p> <p>This article is a detailed look at what is encrypted, how it is encrypted, and how to decrypt it. If you are just looking at Apple notes for the first time, I would recommend starting with the other entries in the <a href="https://ciofecaforensics.com/categories/#Apple%20Notes">Apple Notes</a> category to understand how it works under normal circumstances before tackling encrypted notes. Throughout this article, I will mainly refer to the <code>ZICCLOUDSYNCINGOBJECT</code> table when I reference the NoteStore.sqlite database and hence will not be writing that table name every time. I will intentionally include a table name when referencing other tables, such as <code>ZICNOTEDATA.ZDATA</code>.</p> <p><img src="https://ciofecaforensics.com/assets/img/posts/2020/07/lockednote_sm.jpg" alt="Locked note"></p> <h2 id="password-recovery">Password Recovery</h2> <p>It must be said from the outset that the Apple Cloud Notes Parser is not intended to be a password cracker for Apple Notes. This software is to be used to backup or recover notes which you legally have the password to. With that said, Apple’s documentation says that “if you forgot your password, Apple can’t help you regain access to your locked notes.” While true, if you do not have the password for the encrypted note, but do still have the database, you could use a program like <a href="https://github.com/hashcat/hashcat">HashCat</a> or <a href="https://github.com/magnumripper/JohnTheRipper">John the Ripper</a> to potentially recover it. Both of those programs support password recovery on Apple Notes and Apple File System (APFS) encryption. The rest of this article assumes you either created the note and know the password for the note or have a legal reason for reading the note and have the password.</p> <p>Face ID and Touch ID can also be used to unlock notes, but these do not change the underlying password. All they do is unlock the password you set up in Settings-&gt;Notes-&gt;Password and enter it automatically, so the password is still able to be recovered from the database. .</p> <h2 id="decrypting-with-apple-cloud-notes-parser">Decrypting with Apple Cloud Notes Parser</h2> <p>While I hope the detailed explanations below allow many others to implement note decryption, Apple Cloud Notes Parser aims to make it easy. To tell the parser which passwords to try, a new argument has been added which expects a file path pointing to a file with one password on each line.</p> <div><div><pre><code>-w, --password-file FILE         File with plaintext passwords, one per line.
</code></pre></div></div> <p>For example:</p> <figure><pre><code data-lang="raw">notta@cuppa ~/apple_cloud_notes_parser $ cat passwords.txt
root
Summer!2018
password
password1

notta@cuppa ~/apple_cloud_notes_parser $ ruby notes_cloud_ripper.rb --itunes-dir ~/phone_rips/iphone/notes_2019_12_05/device_id --password-file passwords.txt

Starting Apple Notes Parser at Wed Jul 29 19:48:43 2020
Storing the results in ./output/2020_07_29-19_48_43

Created a new AppleBackup from iTunes backup: /home/notta/phone_rips/iphone/notes_2019_12_05/device_id/
Guessed Notes Version: 13
Guessed Notes Version: 8
Added 4 passwords to the AppleDecrypter from /home/notta/apple_could_notes_parser/passwords.txt
Updated AppleNoteStore object with 70 AppleNotes in 11 folders belonging to 2 accounts.
Updated AppleNoteStore object with 0 AppleNotes in 1 folders belonging to 1 accounts.
Adding the ZICNOTEDATA.ZPLAINTEXT and ZICNOTEDATA.ZDECOMPRESSEDDATA columns, this takes a few seconds

Successfully finished at Wed Jul 29 19:48:48 2020</code></pre></figure> <h2 id="what-is-encrypted">What is Encrypted?</h2> <p>When I say that users can encrypt their note’s contents, I need to be careful to be precise. For the most part, what is encrypted is what is found in the <code>ZICNOTEDATA.ZDATA</code> column in the NoteStore.sqlite database. This leaves most of the note metadata unencrypted, and even some of the content (specifically the <code>ZTITLE1</code> column) unencrypted. Aside from the <code>ZICNOTEDATA.ZDATA</code> column, contents of attached files end up encrypted and some of the metadata about objects ends up encypted in the <code>ZENCRYPTEDVALUESJSON</code> column, such as filenames and URLs. Notice in the below screenshot how, even though the notes are all locked, you can see the day they were created and the title.</p> <p><img src="https://ciofecaforensics.com/assets/img/posts/2020/07/all_locked_notes_sm.jpg" alt="Locked note"></p> <p>According to Apple<sup id="fnref:secure-notes-features" role="doc-noteref"><a href="#fn:secure-notes-features">1</a></sup>, users can encrypt notes containing “images, sketches, tables, maps, and websites.” Each of those functions slightly differently in how they encrypt, but the general rules I’ve seen are:</p> <ol> <li>If the normal version of the attachment writes to disk, such as an image or a thumbnail of a webpage, that file will contain encrypted data</li> <li>If the normal version of the attachment has a user-generated filename, such as an image, that filename will be encrypted and stored in the <code>ZENCRYPTEDVALUESJSON</code> column but the file will use the <code>ZIDENTIFER</code> column as its filename</li> <li>If the normal version of the attachment has a Notes-generated filename, such as a sketch, that filename will remain the same</li> <li>If the normal version of the attachment uses the <code>ZMERGEABLEDATA1</code> column, such as a table, that blob will be encrypted and stored in the <code>ZENCRYPTEDVALUESJSON</code> column</li> <li>Files are encrypted on disk using the <code>ZASSETCRYPTOTAG</code> and <code>ZASSETCRYPTOINITIALIZATIONVECTOR</code> columns</li> <li>Fallback images, such as for sketches, are encrypted on disk using the <code>ZFALLBACKIMAGECRYPTOTAG</code> and <code>ZFALLBACKIMAGECRYPTOINITIALIZATIONVECTOR</code> columns</li> </ol> <h2 id="how-is-it-encrypted">How is it Encrypted?</h2> <p>Like much of Apple’s products, specific details on the inner workings of Apple Notes are hard to come by and they use functionality that is not part of the larger libraries Apple makes available to most developers<sup id="fnref:aes-added" role="doc-noteref"><a href="#fn:aes-added">2</a></sup>. The bulk of what is officially known comes from a brief blurb that has been copied over a few different Apple pages over the years<sup id="fnref:secure-notes-features:1" role="doc-noteref"><a href="#fn:secure-notes-features">1</a></sup>. The blurb describes the underlying foundation of their encryption, but doesn’t get quite far enough for someone unfamiliar with the implementation of these foundations to implement it on their own. That is possibly why this feature shows up in commercial tools and not homegrown ones. Here is the most relevant section of the blurb:</p> <blockquote> <p>When a user secures a note, a 16-byte key is derived from the user’s passphrase using PBKDF2 and SHA256. The note and all of its attachments are encrypted using AES-GCM. New records are created in Core Data and CloudKit to store the encrypted note, attachments, tag, and initialization vector. After the new records are created, the original unencrypted data is deleted. Attachments that support encryption include images, sketches, tables, maps, and websites. Notes containing other types of attachments can’t be encrypted, and unsupported attachments can’t be added to secure notes.</p> </blockquote> <blockquote> <p>…</p> </blockquote> <blockquote> <p>To change the passphrase on a secure note, the user must enter the current passphrase, as Touch ID and Face ID aren’t available when changing the passphrase. After choosing a new passphrase, the Notes app rewraps the keys of all existing notes in the same account that are encrypted by the previous passphrase.</p> </blockquote> <h2 id="what-changes-during-encryption">What Changes During Encryption?</h2> <p>During testing of how to decrypt, we wanted to see what exactly happened when a user encrypted a note. I used a MacOS computer to create a note, copied the NoteStore.sqlite database off, then encrypted the note and copied it off again. This is the output of sqldiff’ing the files:</p> <figure><pre><code data-lang="sql"><span>notta</span><span>@</span><span>cuppa</span> <span>~/</span><span>notestores</span> <span>$</span> <span>sqldiff</span> <span>MacNoteStore_preencryption</span><span>.</span><span>sqlite</span> <span>MacNoteStore_postencryption</span><span>.</span><span>sqlite</span> <span>|</span> <span>grep</span> <span>-</span><span>e</span> <span>"ZICCLOUDSYNCINGOBJECT</span><span>\|</span><span>ZICNOTEDATA"</span>
<span>UPDATE</span> <span>ZICCLOUDSYNCINGOBJECT</span> <span>SET</span> <span>Z_OPT</span><span>=</span><span>8</span><span>,</span> <span>ZMARKEDFORDELETION</span><span>=</span><span>1</span><span>,</span> <span>ZSNIPPET</span><span>=</span><span>NULL</span><span>,</span> <span>ZTITLE1</span><span>=</span><span>NULL</span> <span>WHERE</span> <span>Z_PK</span><span>=</span><span>121</span><span>;</span>
<span>UPDATE</span> <span>ZICCLOUDSYNCINGOBJECT</span> <span>SET</span> <span>Z_OPT</span><span>=</span><span>4</span> <span>WHERE</span> <span>Z_PK</span><span>=</span><span>123</span><span>;</span>
<span>INSERT</span> <span>INTO</span> <span>ZICCLOUDSYNCINGOBJECT</span><span>(</span><span>Z_PK</span><span>,</span><span>Z_ENT</span><span>,</span><span>Z_OPT</span><span>,</span><span>ZCRYPTOITERATIONCOUNT</span><span>,</span><span>ZISPASSWORDPROTECTED</span><span>,</span><span>ZMARKEDFORDELETION</span><span>,</span><span>ZMINIMUMSUPPORTEDNOTESVERSION</span><span>,</span><span>ZNEEDSINITIALFETCHFROMCLOUD</span><span>,</span><span>ZNEEDSTOBEFETCHEDFROMCLOUD</span><span>,</span><span>ZNEEDSTOSAVEUSERSPECIFICRECORD</span><span>,</span><span>ZCLOUDSTATE</span><span>,</span><span>ZACCOUNT</span><span>,</span><span>ZCHECKEDFORLOCATION</span><span>,</span><span>ZFILESIZE</span><span>,</span><span>ZHANDWRITINGSUMMARYVERSION</span><span>,</span><span>ZHASMARKUPDATA</span><span>,</span><span>ZIMAGECLASSIFICATIONSUMMARYVERSION</span><span>,</span><span>ZIMAGEFILTERTYPE</span><span>,</span><span>ZOCRSUMMARYVERSION</span><span>,</span><span>ZORIENTATION</span><span>,</span><span>ZSECTION</span><span>,</span><span>ZLOCATION</span><span>,</span><span>ZMEDIA</span><span>,</span><span>ZNOTE</span><span>,</span><span>ZNOTEUSINGTITLEFORNOTETITLE</span><span>,</span><span>ZPARENTATTACHMENT</span><span>,</span><span>ZAPPEARANCETYPE</span><span>,</span><span>ZSCALEWHENDRAWING</span><span>,</span><span>ZVERSION</span><span>,</span><span>ZVERSIONOUTOFDATE</span><span>,</span><span>ZATTACHMENT</span><span>,</span><span>ZSTATE</span><span>,</span><span>ZACCOUNT1</span><span>,</span><span>ZTYPE</span><span>,</span><span>ZACCOUNT2</span><span>,</span><span>ZATTACHMENT1</span><span>,</span><span>ZATTACHMENTVIEWTYPE</span><span>,</span><span>ZISPINNED</span><span>,</span><span>ZLEGACYNOTEWASPLAINTEXT</span><span>,</span><span>ZNOTEHASCHANGES</span><span>,</span><span>ZPAPERSTYLETYPE</span><span>,</span><span>ZPREFERREDBACKGROUNDTYPE</span><span>,</span><span>ZACCOUNT3</span><span>,</span><span>ZFOLDER</span><span>,</span><span>ZNOTEDATA</span><span>,</span><span>ZTITLESOURCEATTACHMENT</span><span>,</span><span>ZISHIDDENNOTECONTAINER</span><span>,</span><span>ZSORTORDER</span><span>,</span><span>ZOWNER</span><span>,</span><span>ZACCOUNTTYPE</span><span>,</span><span>ZDIDCHOOSETOMIGRATE</span><span>,</span><span>ZDIDFINISHMIGRATION</span><span>,</span><span>ZDIDMIGRATEONMAC</span><span>,</span><span>ZSTOREDATASEPARATELY</span><span>,</span><span>ZACCOUNTDATA</span><span>,</span><span>ZCUSTOMNOTESORTTYPEVALUE</span><span>,</span><span>ZFOLDERTYPE</span><span>,</span><span>ZIMPORTEDFROMLEGACY</span><span>,</span><span>ZACCOUNT4</span><span>,</span><span>ZPARENT</span><span>,</span><span>ZCREATIONDATE</span><span>,</span><span>ZCROPPINGQUADBOTTOMLEFTX</span><span>,</span><span>ZCROPPINGQUADBOTTOMLEFTY</span><span>,</span><span>ZCROPPINGQUADBOTTOMRIGHTX</span><span>,</span><span>ZCROPPINGQUADBOTTOMRIGHTY</span><span>,</span><span>ZCROPPINGQUADTOPLEFTX</span><span>,</span><span>ZCROPPINGQUADTOPLEFTY</span><span>,</span><span>ZCROPPINGQUADTOPRIGHTX</span><span>,</span><span>ZCROPPINGQUADTOPRIGHTY</span><span>,</span><span>ZDURATION</span><span>,</span><span>ZMODIFICATIONDATE</span><span>,</span><span>ZORIGINX</span><span>,</span><span>ZORIGINY</span><span>,</span><span>ZPREVIEWUPDATEDATE</span><span>,</span><span>ZSIZEHEIGHT</span><span>,</span><span>ZSIZEWIDTH</span><span>,</span><span>ZHEIGHT</span><span>,</span><span>ZMODIFIEDDATE</span><span>,</span><span>ZSCALE</span><span>,</span><span>ZWIDTH</span><span>,</span><span>ZSTATEMODIFICATIONDATE</span><span>,</span><span>ZMODIFICATIONDATEATIMPORT</span><span>,</span><span>ZCREATIONDATE1</span><span>,</span><span>ZFOLDERMODIFICATIONDATE</span><span>,</span><span>ZLASTNOTIFIEDDATE</span><span>,</span><span>ZLASTVIEWEDMODIFICATIONDATE</span><span>,</span><span>ZLEGACYMODIFICATIONDATEATIMPORT</span><span>,</span><span>ZMODIFICATIONDATE1</span><span>,</span><span>ZCUSTOMNOTESORTTYPEMODIFICATIONDATE</span><span>,</span><span>ZDATEFORLASTTITLEMODIFICATION</span><span>,</span><span>ZPARENTMODIFICATIONDATE</span><span>,</span><span>ZIDENTIFIER</span><span>,</span><span>ZPASSWORDHINT</span><span>,</span><span>ZZONEOWNERNAME</span><span>,</span><span>ZADDITIONALINDEXABLETEXT</span><span>,</span><span>ZFALLBACKSUBTITLEIOS</span><span>,</span><span>ZFALLBACKSUBTITLEMAC</span><span>,</span><span>ZFALLBACKTITLE</span><span>,</span><span>ZHANDWRITINGSUMMARY</span><span>,</span><span>ZIMAGECLASSIFICATIONSUMMARY</span><span>,</span><span>ZOCRSUMMARY</span><span>,</span><span>ZREMOTEFILEURLSTRING</span><span>,</span><span>ZSUMMARY</span><span>,</span><span>ZTITLE</span><span>,</span><span>ZTYPEUTI</span><span>,</span><span>ZURLSTRING</span><span>,</span><span>ZUSERTITLE</span><span>,</span><span>ZDEVICEIDENTIFIER</span><span>,</span><span>ZCONTENTHASHATIMPORT</span>…</code></pre></figure></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ciofecaforensics.com/2020/07/31/apple-notes-revisited-encrypted-notes/">https://ciofecaforensics.com/2020/07/31/apple-notes-revisited-encrypted-notes/</a></em></p>]]>
            </description>
            <link>https://ciofecaforensics.com/2020/07/31/apple-notes-revisited-encrypted-notes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24642368</guid>
            <pubDate>Wed, 30 Sep 2020 19:01:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The story on how I discovered, fell in love and abandoned Event Sourcing]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24642262">thread link</a>) | @zeLaur
<br/>
September 30, 2020 | https://laurentiu.codes/2020/09/04/the-story-on-how-i-discovered-and-fell-in-love-with-event-sourcing/ | <a href="https://web.archive.org/web/*/https://laurentiu.codes/2020/09/04/the-story-on-how-i-discovered-and-fell-in-love-with-event-sourcing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-77">

    

	<div>

		
<p>Well, yeah … quite the title here, for quite the story. To be honest, I discovered and used Event sourcing way before it was called event sourcing, and way before it was cool, or at least at that time, I had no idea that this will become such a hot topic.</p>



<p>It all happened about 7 years ago, I was a quite happy camper, achieving my “mid software engineer” title and was a awaiting this awesome new project were, for the first time will have a say in the software design (green field and stuff). Everything was looking just fine and dandy, the client was a top client, the software stack was up to us to pick, so yeah I was super hyped, that is, until I got the requirements… </p>



<blockquote><p> I was super hyped, that is, until I got the requirements…</p></blockquote>



<p>Apart from the usual stuff, there was one thing that, thus far, I haven’t ever done on a web based application nor ever seen being implemented, this thing was the ability to <strong>audit everything</strong> (including data access) and <strong>undo </strong>any changes done on the domain objects.</p>



<p>At this point, I kind of understood why other people with more seniority didn’t want to work on this, this was looking to be quite a big undertaking to implement, keep in mind this was something about 2010 – 2012, nosql was a kind of an idea more than an actual product, and cloud wasn’t yet in the picture and we were still using .net 3.5 and 4 at that time and phones back than were upgrading from Android 1.6 to 2.1. </p>



<p>But I digress, back to the story. Now that we build a better temporal  awareness and a bit more context, let go into the more depth. As I said, I was a seen as a “promising” young engineer back than, and this was the first project with this new client a lot of eye were on me, and a lot of pressure, as you may or may not know, if you are working in a consulting / services context, the first project usually makes or brakes a partnership. So yeah, the stakes were high. </p>



<p>So how did we managed to pull this of ? Well, after endless discussion with my Team Lead / PM and a few other people around, who mostly had their experience in embedded C and low level UNIX development, and doing some research on how desktop applications do this (mostly playing around in excel trying to figure it out), I came with this crazy idea of writing our software stack. </p>



<p>We will be using MVC instead of WebForms ( first revolutionary thing, back than ), and instead of the regular way of storing data ( CRUD based ) we will be storing ALL of the interactions with the back-end that touch the Domain objects in Journal tables. In order to give the users the ability to read the data in a “normal view” we would hydrate the journal entries for that specific id by selecting them and applying all the changes one after the other, this way we would be able to know exactly who made what change, and also have versioned “domain objects” and we would be able to undo changes. </p>



<p>People seemed to like the idea, and gave me the green light, I was the only developer working on this full time with two other seniors who I could ask help from on very specific issues. </p>



<p>So off to the races, I started implement this to the best of my abilities back than, everything was going great until I realized than my great design had this small performance issue, on a very small and not very frequently used page, the List View … I’m not going to lie, this was baaaaddd… after letting the others know about this, they gave me a few days to fix this, or they would take the project away from me, and rebuild it with a different team using “industry standard” patterns. </p>



<blockquote><p>I’m not going to lie, this was baaaaddd…</p><cite>Me</cite></blockquote>



<p>As you could imagine, this scared the life out of me, but instead of despair I started thinking on how I could figure the perfect solution to this problem, because, I really liked the idea of this journaling the changes… So, as you might think right know this is obvious, back than, not so much, I wasn’t aware of Greg Young and his push of ES, so yeah, back to the story, so I came with this crazy <strong>“database memoization”</strong> idea. </p>



<p>How did this work ? Glad you asked. Well basically the way this worked was the following, on each “change” a user would make to a domain object, after we would save the “change” in the journal, we would call this memoization component ( I think we called it “[DomainType]MemoizationManager”, in those days most classes were managers :D) to run, this component would go through each of the events of a specific ID, and build the state for it, as before, but this time, instead of returning it it would save it in a “classic” database table, also, this entity also had two columns to keep track of the version and id of the last processed event so it would require to go through all of them on each change. Than, we set up MVC to display the list and detail view based on this table. Also, in order to minimize the chance that a user would see old data after a “change was made”, after the edit view was submitted, we would redirect them to a page that said that the “change was successful” and provided links to the detail view and list view ( I know, but UX wasn’t a thing back than).</p>



<p>Yep, this worked like a charm, the day was saved! (and I continued to work there for about 5 more years). But this was not all, this “db memorization” basically was like a gateway drug, and one of the best things since sliced bread, because it opened the way to building backing tables for highly specific reports that otherwise would take tons of ram and cpu to process.</p>



<p>Now, if you are even remotely familiar with “modern” event sourcing you will basically recognize that was I used was, CQRS ( acknowledging the changes via commands, having a different read model, although used the same DB), Event sourcing with Stream per type, since DBs don’t usually like to have dynamic tables, and projections ( DBMemoization ). Just for the record, we also used event snapshots after about 200 events ( at the end as an optimization), and cross domain object memoizations for the reports and the dashboard. </p>



<blockquote><p>Nobody in their right mind would build such a complex abomination.</p><cite>Enterprise Developers</cite></blockquote>



<p>The sad thing about this whole project was that, although it turned out to be success, both commercial and technically, the client was very impressed by the performance and machine requirements, every one I talked about this solution at that time and quite a lot after said that, this was crazy, nobody in their right mind would build such a complex abomination, and could have been build with nHibernate and some services and a lot of polymorphism. It didn’t matter that this solution was better in terms of performance and memory usage, it wasn’t the way .NET was developed. After hearing this a lot more times than I’d  like to admit, I kind of buried the idea more or less like a highly specific one time thing, and haven’t discussed about it again.</p>



<p>To be honest, I still used some things I learned from that project, for example building “report tables” with data updates triggered on domain events. But most of the time I had to be quite sneaky when presenting others the concept.</p>



<p>That was until, a couple of years ago a discovered ,by mistake, on YouTube, a talk from a guy called Greg Young who, for years was pushing this cool new idea, <strong>Event Sourcing</strong>. I remember watching the whole talk without event flinching, and at the very end I got this very nice and fuzzy feeling of knowing that I’m not crazy, or at least not as crazy as other people thought, or there were others that noticed this cool way of doing things. Now I had somewhere where I could send people if they thought I wasn’t making a lot of sense, and more importantly someone with more notoriety, so yeah thanks Greg.</p>



<h2>The takeaway</h2>



<p>Well, I think, if there is a takeaway from this story, that would be, if you are presented an idea by someone, even with far less seniority than you, give it thought, and remember that especially in software development there are endless ways of achieving something. And more important, if you are going to disagree or give feedback, give constructive feedback / criticism don’t just shut them down.</p>









	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://laurentiu.codes/2020/09/04/the-story-on-how-i-discovered-and-fell-in-love-with-event-sourcing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24642262</guid>
            <pubDate>Wed, 30 Sep 2020 18:53:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Beeminder?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24642136">thread link</a>) | @maxwelljoslyn
<br/>
September 30, 2020 | https://www.maxwelljoslyn.com/beeminder | <a href="https://web.archive.org/web/*/https://www.maxwelljoslyn.com/beeminder">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="article-body">
        <p><strong>I vigorously encourage you</strong> to <a href="https://beeminder.com/">use Beeminder</a> for tracking, maintaining, and modifying habits.</p>
<p>Several people have recently asked me to explain why I like this service so much. This page is my evolving answer.</p>
<p>So, <strong>why Beeminder?</strong></p>
<h2 id="design">Design</h2>
<p>The core feature of Beeminder is the “bee sting.” The service charges you money if you fail to meet a certain rate of progress toward a goal.</p>
<p>For instance, if I declare to Beeminder that I will meditate 5 minutes per day, and I fail to perform meditation at that rate, Beeminder will “derail” me, charge me a small amount of money, and – after a weeklong grace period – rearm the sting.</p>
<p><strong>Why Beeminder?</strong> It assigns meaningful consequences for not living up to your stated goals.</p>
<p>The good news about the bee sting is that Beeminder is totally self-driven. You<a href="#fn1" id="fnref1"><sup>1</sup></a> do the data reporting, you set the starting and maximum penalties for the bee sting, and you choose how fast you want to make progress on each goal. You are even responsible for confirming with the Beeminder team whether or not a derailment was legitimate.</p>
<p><strong>Why Beeminder?</strong> It trains you to build honesty with yourself (and the support team!) when you succeed or fail. This calibrates a better understanding of your strengths and weaknesses, while giving you the information you need to ramp up or ease off on a goal.</p>
<h2 id="philosophy">Philosophy</h2>
<p>A Beeminder user must break down his or her goals into atomic, numerically-measurable steps toward a large goal. Goals like “chinups performed,” being both numeric and precise, are a perfect fit for Beeminder. To perform 100 chinups, set your target rate to 1 chinup per hour/day/week; set your target number to 100; and do chinups whenever you can. That’s it: as long as you keep your average rate above 1 chinup per chosen time unit, Beeminder will never charge you, and you’ll be making steady progress.</p>
<p><strong>Why Beeminder?</strong> It trains you to reframe your life goals, especially ones that seem monumental, as nothing more than piles of little goals, steadily achieved.</p>
<p>While goals that are easily quantified are the best fit for Beeminder, even nebulous goals can be tracked and nudged in the system. One of my goals is called “selfserve”, and its target number is 100 – where “100” means “has ported 100% of this website to self-administered web servers and infrastructure.”</p>
<p>Few methods of calculating exact progress on this goal would be worth the time they took to administer. However, since I know the scope of the task and its subtasks, after completing each subtask I can add a few percent here and a few percent there into Beeminder’s tracker.</p>
<p><strong>Why Beeminder?</strong> Whether your goal is concrete or abstract, Beeminder puts you on a schedule which will achieve it.</p>
<p>What’s more, merely declaring “I will be 100% done with this hairy task by such-and-such date” was enough to spur me into action. My original target date was 100% completion by mid-December, but as of today, before even reaching October, my “selfserve” goal sits at 60%! I’m months ahead of my original pessimistic estimate, and <em>it never once felt difficult</em> to get there – but if I hadn’t <em>promised myself</em>, via Beeminder, that I would do so, I’d probably still be sitting around griping about my crappy old website infrastructure.</p>
<p><strong>Why Beeminder?</strong> It builds the self-confidence and self-trust that can only come from diligently working toward success.</p>
<p>Finally, I realized recently that Beeminder has <em>instilled in me a new and creative instinct</em>: the impulse to judge any new opportunity by determining how I might realize its potential in steps of Beemindable size.</p>
<p>It is one thing for the latest self-help book or productivity guru to tell you that anything is achievable in small steps. It is quite another for that mantra to develop into a deep-seated instinct which influences your worldview. Thus Beeminder is empowering in the truest sense of the word: it grants new abilities.</p>
<p><strong>Why Beeminder?</strong> Extended use installs the powerful meta-habit of noticing opportunities to achieve goals by “mere” effort – and as a Beeminder user, you’ll be ready to exploit such opportunities <em>because you’ve practiced doing so.</em></p>
<h2 id="proof-by-existence">Proof by Existence</h2>
<p>The Beeminder founders, Danny and Bethany, use Beeminder to supercharge the development of Beeminder itself. <a href="https://www.beeminder.com/meta">They’ve set up the Beeminder user “meta”</a> to publicly display business metrics, which they’ve committed to Beeminding just as you or I might Beemind pushups or calories.</p>
<p>The “meta” goals include typical metrics like revenue and monthly active users. That Beeminder openly publishes these figures makes them is noble, but I want to draw attention to a non-financial indicator: <a href="https://www.beeminder.com/meta/uvi">a very, very important number called “UVIs.”</a></p>
<p>UVI stands for “User-Visible Improvement,” and they are the gold-standard, AAA, totally-unfakeable indicator that Beeminder works. One point on the UVI goal means the Beeminder team has directly improved your experience using Beeminder, and at time of writing, the Beeminder team has added <em>one new UVI every day for ten years</em>.</p>
<p><strong>Why Beeminder?</strong> <em>Its own existence is a massive proof</em> of its ability to motivate you to fantastic heights – like, say, creating a program which has helped tens of thousands of people achieve their goals.</p>
<h2 id="conclusion">Conclusion</h2>
<p>I’ve said my piece, so don’t delay: <a href="https://beeminder.com/">go try Beeminder for yourself</a>. <strong>Set your goals to the minimum charge until you figure out what works for you</strong>, and if you want help getting started, email the ever-helpful support team, or check out the forums.</p>
<p>I’m just a happy customer with a blog, and Beeminder didn’t ask me to write this post. That said, Danny and other staff members encouraged me to write on this topic after I mentioned it over email.</p>
<p>If you liked this, leave a response! In a future post, I’ll investigate my own Beeminder successes and failures as case studies for others to learn from. Thanks for reading, and never ever hesitate to .</p>


        





        
    </div></div>]]>
            </description>
            <link>https://www.maxwelljoslyn.com/beeminder</link>
            <guid isPermaLink="false">hacker-news-small-sites-24642136</guid>
            <pubDate>Wed, 30 Sep 2020 18:43:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Energy Efficiency across Programming Languages [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 190 | Comments 153 (<a href="https://news.ycombinator.com/item?id=24642134">thread link</a>) | @Malfunction92
<br/>
September 30, 2020 | https://greenlab.di.uminho.pt/wp-content/uploads/2017/10/sleFinal.pdf | <a href="https://web.archive.org/web/*/https://greenlab.di.uminho.pt/wp-content/uploads/2017/10/sleFinal.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://greenlab.di.uminho.pt/wp-content/uploads/2017/10/sleFinal.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24642134</guid>
            <pubDate>Wed, 30 Sep 2020 18:43:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My path away from spinning hard drives on my home desktop]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24641719">thread link</a>) | @pcr910303
<br/>
September 30, 2020 | https://utcc.utoronto.ca/~cks/space/blog/tech/HomePCAllSolidStatePath | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/tech/HomePCAllSolidStatePath">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>My likely path away from spinning hard drives on my home desktop</h2>

	<p><small>September 28, 2020</small></p>
</div><div><p>One of my goals for <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/HomeMachine2018">my home desktop</a>
is to move entirely to solid state storage. Well, it's a goal for
both my home and <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/WorkMachine2017">work machine</a>, and I
originally expected to get there first at home, but then work had
spare money and suddenly my work machine has been all solid state
for some time (which is great except for the bit where I'm not at
work to enjoy it).</p>

<p>Moving to all solid state at work was relatively straightforward
because all of my old storage on my work machine was relatively
small; I had a mirrored pair of 250 GB SSDs, a mirrored pair of 1
TB HDs, and a third 500 GB HD for less important things, and none
of them were all too full. This was easily all replaced with a pair
of reasonable sized NVMe drives and a pair of 2 TB SSDs, which
weren't that expensive even in late 2019. Unfortunately my home
machine is better configured; I currently have a mirrored pair of
750 GB SSDs and a mirrored pair of '3 TB' HDs (one of them is a 4
TB HD, but since it's mirrored the extra TB is wasted). The HDs are
used for a <a href="https://en.wikipedia.org/wiki/Logical_Volume_Manager_(Linux)">LVM volume</a> that
has only about 1.4 TiB allocated, so in theory I could get away
with a pair of 2 TB SSDs as the replacement for these HDs. However,
that would leave me relatively short of extra space for things like
digital photography (those <a href="https://en.wikipedia.org/wiki/Raw_image_format">RAW</a> files add up fast).</p>

<p>The obvious replacement and supplement for my current 750 GB SSDs is
a pair of decent 1 TB NVMe drives, which seem to be not too expensive
these days. Unfortunately there is not as good a replacement for my
pair of 3 TB HDs. While 4 TB SSDs are available, they cost noticeably
more per GB than 2 TB SSDs do (as I write this, one large Canadian
online retailer lists WD Blue 2 TB SSDs for $304 and the 4 TB version
for $709). One option would be to shrug and pay the premium for future
proofing things; another would be to buy a pair of 2 TB SSDs and rely
on a combination of the extra space on the NVMe drives, reusing my
current 750 GB SSDs, and rationalizing space usage when I migrate
from my old LVM setup to ZFS on the new SSDs.</p>

<p>A complication is that now is not necessarily the right time to buy
new NVMe drives, especially relatively expensive ones. The NVMe
world is just starting to move from PCIe 3.0 to PCIe 4.0, which
offers various improvements once everything is working. My current
home motherboard has no PCIe 4.0 support, of course, but based on
past experience I'll be keeping any NVMe drives that I buy now for
at least half a decade, which means that they'll likely wind up in
a PCIe 4.0 capable system within their lifetime.</p>

<p>(On the one hand, PCIe 4.0 will probably not make a particularly
visible performance difference on my home machine on typical or
even somewhat atypical tasks, like compiling Firefox from source.
On the other hand, I don't like leaving potential performance on
the table.)</p>

<p>So despite all of what I've written, I'm probably going to do my
usual thing and sit on my hands for a while. Perhaps various end
of the year sale prices will get me to finally move forward.</p>

<p>(This is one of the entries that I write partly to try to motivate
myself.)</p>

<p>PS: I have a mixed pair of 3TB and 4TB HDs for the usual reason,
which is that I used to have a pair of 3 TB HDs and then one of
them died and I needed to replace it. My LVM array has migrated
up from smaller sizes of HDs over time this way.</p>

<p>(Waiting for a warranty replacement is never an option, because I
want my redundancy back much sooner than a replacement would get
to me.)</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/tech/HomePCAllSolidStatePath</link>
            <guid isPermaLink="false">hacker-news-small-sites-24641719</guid>
            <pubDate>Wed, 30 Sep 2020 18:11:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Towards an Infinite Laptop]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24641674">thread link</a>) | @thedataexchange
<br/>
September 30, 2020 | https://gradientflow.com/towards-an-infinite-laptop/ | <a href="https://web.archive.org/web/*/https://gradientflow.com/towards-an-infinite-laptop/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-7518">

	

	
	<div>
		<h3>The new Anyscale platform offers the ease of development on a laptop combined with the power of the cloud.</h3>
<p><span>During a series of short keynotes at the </span><a href="https://events.linuxfoundation.org/ray-summit/?utm_source=gradientflow&amp;utm_medium=postanyscalelaunch&amp;utm_campaign=raysummit#featuredspeakers"><span>Ray Summit</span></a><span> this morning, Anyscale</span><sup>1</sup><span>, the company formed by the creators of Ray, publicly shared their initial product offering. <a href="https://anyscale.com/?utm_source=gradientflow&amp;utm_medium=post&amp;utm_campaign=anyscale"><img data-attachment-id="7525" data-permalink="https://gradientflow.com/towards-an-infinite-laptop/attachment/anyscale-logo/" data-orig-file="https://i2.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-logo.jpg?fit=484%2C134&amp;ssl=1" data-orig-size="484,134" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="anyscale-logo" data-image-description="" data-medium-file="https://i2.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-logo.jpg?fit=300%2C83&amp;ssl=1" data-large-file="https://i2.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-logo.jpg?fit=484%2C134&amp;ssl=1" loading="lazy" src="https://i2.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-logo.jpg?resize=217%2C60&amp;ssl=1" alt="" width="217" height="60" srcset="https://i2.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-logo.jpg?resize=300%2C83&amp;ssl=1 300w, https://i2.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-logo.jpg?w=484&amp;ssl=1 484w" sizes="(max-width: 217px) 100vw, 217px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-logo.jpg?resize=300%2C83&amp;ssl=1 300w, https://i2.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-logo.jpg?w=484&amp;ssl=1 484w" data-lazy-src="https://i2.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-logo.jpg?resize=217%2C60&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a>Dubbed the “infinite laptop”,&nbsp; Anyscale’s platform allows developers to treat their laptop as an “infinite cluster”. Developers can use their preferred development tools (e.g., IDE, notebook, text editor, etc.) on Anyscale’s platform, and seamlessly burst into a cloud platform when needed.&nbsp;</span></p>
<p><span>The demo at the conference walked the audience through the process of a building an end-to-end application: training and deploying models for a recommendation engine. Consider a developer in the process of building and training a model for a machine learning application. The challenge with machine learning is that the model building phase requires multiple runs. You usually need to explore different models and model parameters before settling on a model. If model training takes too long, it limits the amount of ideas a developer can try. On the other hand, developers invest time setting up their laptops and they feel productive when their favorite IDE, libraries and software are in place.&nbsp;Ideally one can explore ideas on a laptop (say a simpler model, or a model that uses less training data) and burst out to a compute cluster when computations begin to overwhelm your laptop. The Anyscale platform delivers this exact solution!</span></p>
<p><span>The Anyscale platform gives developers the “development experience on their laptop combined with the power of the cloud”. This means that Anyscale syncs code on your laptop to the cloud. You can continue to edit your program using the development tools on your laptop and Anyscale will optionally execute your code on the cloud. Machine learning developers can use specialized processors (including TPUs or fast GPUs) and scale out to a cluster if they need to parallelize certain computations.&nbsp; It is cloud native and you can even use multiple clouds at the same time. You really have the best of both worlds: the tools and libraries that you feel most comfortable with, backed with the compute resources you need to be productive and effective. My immediate reaction after watching the demo was <em>“That’s exactly how I want to work and the platform I need!”</em></span></p>
<p><a href="https://anyscale.com/blog/?utm_source=gradientflow&amp;utm_medium=post&amp;utm_campaign=anyscale"><img data-attachment-id="7523" data-permalink="https://gradientflow.com/towards-an-infinite-laptop/attachment/anyscale-demo/" data-orig-file="https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-demo.jpg?fit=1946%2C1006&amp;ssl=1" data-orig-size="1946,1006" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="anyscale-demo" data-image-description="" data-medium-file="https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-demo.jpg?fit=300%2C155&amp;ssl=1" data-large-file="https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-demo.jpg?fit=750%2C387&amp;ssl=1" loading="lazy" src="https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-demo.jpg?resize=750%2C387&amp;ssl=1" alt="" width="750" height="387" srcset="https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-demo.jpg?resize=1024%2C529&amp;ssl=1 1024w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-demo.jpg?resize=300%2C155&amp;ssl=1 300w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-demo.jpg?resize=768%2C397&amp;ssl=1 768w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-demo.jpg?resize=1536%2C794&amp;ssl=1 1536w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-demo.jpg?resize=1200%2C620&amp;ssl=1 1200w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-demo.jpg?resize=1568%2C811&amp;ssl=1 1568w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-demo.jpg?w=1946&amp;ssl=1 1946w" sizes="(max-width: 750px) 100vw, 750px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-demo.jpg?resize=1024%2C529&amp;ssl=1 1024w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-demo.jpg?resize=300%2C155&amp;ssl=1 300w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-demo.jpg?resize=768%2C397&amp;ssl=1 768w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-demo.jpg?resize=1536%2C794&amp;ssl=1 1536w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-demo.jpg?resize=1200%2C620&amp;ssl=1 1200w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-demo.jpg?resize=1568%2C811&amp;ssl=1 1568w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-demo.jpg?w=1946&amp;ssl=1 1946w" data-lazy-src="https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/anyscale-demo.jpg?resize=750%2C387&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></p><center><small>Image: Edward Oakes, Anyscale Product Demo at the Ray Summit</small></center>
<p><span>Building efficient and performant distributed applications – the sort needed in modern AI – is challenging for most developers. A developer needs to be able to deal with failures (which are inevitable), control where computations take place, and efficiently handle multiple processes that handle data and communicate with each other. Fortunately, developers need not start from scratch. As Anyscale co-founder Robert Nishihara highlighted in his keynote, the open source project </span><a href="https://ray.io/"><span>Ray</span></a><span> is becoming the </span><a href="https://docs.ray.io/en/master/ray-libraries.html"><span>software platform for building distributed applications</span></a><span>.</span></p>
<p><img data-attachment-id="7646" data-permalink="https://gradientflow.com/towards-an-infinite-laptop/attachment/ray-library-ecosystem/" data-orig-file="https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-library-ecosystem.jpg?fit=2504%2C1310&amp;ssl=1" data-orig-size="2504,1310" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ray-library-ecosystem" data-image-description="" data-medium-file="https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-library-ecosystem.jpg?fit=300%2C157&amp;ssl=1" data-large-file="https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-library-ecosystem.jpg?fit=750%2C393&amp;ssl=1" loading="lazy" src="https://i1.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-library-ecosystem-1024x536.jpg?resize=750%2C393&amp;ssl=1" alt="" width="750" height="393" srcset="https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-library-ecosystem.jpg?resize=1024%2C536&amp;ssl=1 1024w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-library-ecosystem.jpg?resize=300%2C157&amp;ssl=1 300w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-library-ecosystem.jpg?resize=768%2C402&amp;ssl=1 768w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-library-ecosystem.jpg?resize=1536%2C804&amp;ssl=1 1536w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-library-ecosystem.jpg?resize=2048%2C1071&amp;ssl=1 2048w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-library-ecosystem.jpg?resize=1200%2C628&amp;ssl=1 1200w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-library-ecosystem.jpg?resize=1568%2C820&amp;ssl=1 1568w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-library-ecosystem.jpg?w=2250&amp;ssl=1 2250w" sizes="(max-width: 750px) 100vw, 750px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-library-ecosystem.jpg?resize=1024%2C536&amp;ssl=1 1024w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-library-ecosystem.jpg?resize=300%2C157&amp;ssl=1 300w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-library-ecosystem.jpg?resize=768%2C402&amp;ssl=1 768w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-library-ecosystem.jpg?resize=1536%2C804&amp;ssl=1 1536w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-library-ecosystem.jpg?resize=2048%2C1071&amp;ssl=1 2048w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-library-ecosystem.jpg?resize=1200%2C628&amp;ssl=1 1200w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-library-ecosystem.jpg?resize=1568%2C820&amp;ssl=1 1568w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-library-ecosystem.jpg?w=2250&amp;ssl=1 2250w" data-lazy-src="https://i1.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-library-ecosystem-1024x536.jpg?resize=750%2C393&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p><center><small>Image: Robert Nishihara at the Ray Summit (“The Future of Ray”)</small></center>
<p><span>Anyscale provides what co-founder Ion Stoica described as a “serverless experience without serverless limitations”. It abstracts away servers and DevOps so developers can focus on writing their applications.&nbsp; And since Anyscale uses Ray, the Actor model allows it to support stateful applications that are as fast as those built from scratch by experts in distributed programming.</span></p>
<p><img data-attachment-id="7640" data-permalink="https://gradientflow.com/towards-an-infinite-laptop/attachment/ray-serverless/" data-orig-file="https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-serverless.jpg?fit=2316%2C1354&amp;ssl=1" data-orig-size="2316,1354" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ray-serverless" data-image-description="" data-medium-file="https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-serverless.jpg?fit=300%2C175&amp;ssl=1" data-large-file="https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-serverless.jpg?fit=750%2C439&amp;ssl=1" loading="lazy" src="https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-serverless.jpg?resize=750%2C439&amp;ssl=1" alt="" width="750" height="439" srcset="https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-serverless.jpg?resize=1024%2C599&amp;ssl=1 1024w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-serverless.jpg?resize=300%2C175&amp;ssl=1 300w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-serverless.jpg?resize=768%2C449&amp;ssl=1 768w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-serverless.jpg?resize=1536%2C898&amp;ssl=1 1536w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-serverless.jpg?resize=2048%2C1197&amp;ssl=1 2048w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-serverless.jpg?resize=1200%2C702&amp;ssl=1 1200w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-serverless.jpg?resize=1568%2C917&amp;ssl=1 1568w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-serverless.jpg?w=2250&amp;ssl=1 2250w" sizes="(max-width: 750px) 100vw, 750px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-serverless.jpg?resize=1024%2C599&amp;ssl=1 1024w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-serverless.jpg?resize=300%2C175&amp;ssl=1 300w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-serverless.jpg?resize=768%2C449&amp;ssl=1 768w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-serverless.jpg?resize=1536%2C898&amp;ssl=1 1536w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-serverless.jpg?resize=2048%2C1197&amp;ssl=1 2048w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-serverless.jpg?resize=1200%2C702&amp;ssl=1 1200w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-serverless.jpg?resize=1568%2C917&amp;ssl=1 1568w, https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-serverless.jpg?w=2250&amp;ssl=1 2250w" data-lazy-src="https://i0.wp.com/gradientflow.com/wp-content/uploads/2020/09/ray-serverless.jpg?resize=750%2C439&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p><center><small>Image: Ion Stoica at the Ray Summit (“Programming the Cloud as Easily as your Laptop”)</small></center>
<p><span>Why is this exciting? Machine learning and AI are becoming central to many applications. But building machine learning applications can be extremely compute intensive. Even with the emergence of hardware accelerators, many machine learning workloads </span><a href="https://arxiv.org/pdf/2007.05558.pdf"><span>go beyond the capacity of a single server</span></a><span>. We need tools that enable regular developers to quickly build distributed applications. The Anyscale platform is a great step in this direction.</span></p>
<p><span>The company announced this morning that the Anyscale platform is currently <a href="https://anyscale.com/?utm_source=gradientflow&amp;utm_medium=post&amp;utm_campaign=anyscale">available as an invite-only Beta</a>. Learn more by watching the following demo from the Ray Summit:</span></p>
<p><span><iframe width="750" height="422" src="https://www.youtube.com/embed/8GTd8Y_JGTQ?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span></p><p>If you’re interested in Ray, read this new <a href="https://www.anyscale.com/blog/announcing-ray-1-0?utm_source=gradientflow&amp;utm_medium=post&amp;utm_campaign=anyscale">post describing the version 1.0 release</a>.</p>
<hr>
<p><small>[1] Full disclosure: the author is an advisor to Anyscale.</small></p><p><small><strong>Related Content:</strong> Download your free copy of the <a href="https://gradientflow.com/2020nlpsurvey/?utm_source=gradientflow&amp;utm_medium=blog&amp;utm_campaign=nlpsurvey">2020 NLP Industry Survey Results</a>.</small><br>
&nbsp;</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://gradientflow.com/towards-an-infinite-laptop/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24641674</guid>
            <pubDate>Wed, 30 Sep 2020 18:07:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Optimization: Making Rust Code Go Brrrr]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24641608">thread link</a>) | @ajeetdsouza
<br/>
September 30, 2020 | https://aspenuwu.me/posts/rust-optimization.html | <a href="https://web.archive.org/web/*/https://aspenuwu.me/posts/rust-optimization.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<p>Rust code can be fast. Very fast, in fact. If you look at the <a href="https://benchmarksgame-team.pages.debian.net/benchmarksgame/fastest/rust.html">Benchmarks Game</a>, it goes head-to-head with C and C++.</p>
<p>But performance isn't effortless, although Rust's LLVM backend makes it seem so. I'm going to go over the ways I improve performance in my Rust projects.</p>
<h2>Rayon isn't a magic bullet</h2>
<p>It's really not. Many people think just slapping <code>par_iter</code> on the smallest operation will magically fix their performance. It won't. With that mindset, <em>synchronization overhead will eat you alive</em>.</p>
<p>Rayon has more than just <code>par_iter</code>. For example, <a href="https://docs.rs/rayon/*/rayon/slice/trait.ParallelSlice.html#method.par_chunks"><code>par-chunks</code></a> is very useful - you can split your task into parallel <em>chunks</em>, each thread processing a portion of the entire dataset at a time. This greatly reduces synchronization overhead, especially for situations where you have a large amount of small tasks. However, <em><strong>it still may be better to use <em><strong><code>par_iter</code></strong></em> for large tasks that take a while per iteration</strong></em>.</p>
<pre><code>iter.par_chunks(4096).for_each(|x| {
	for y in x {
		y.do_small_thing();
	}
});
</code></pre>
<h2>Buffering matters!</h2>
<p>This is simple. I/O involves syscalls. Syscalls are bad for performance. Therefore, you want to minimize syscalls and optimize I/O.</p>
<p>You should always wrap I/O (whether it be a <a href="https://doc.rust-lang.org/std/fs/struct.File.html"><code>File</code></a>, <a href="https://doc.rust-lang.org/std/net/struct.TcpStream.html"><code>TcpStream</code></a>, et cetera) in an <a href="https://doc.rust-lang.org/std/io/struct.BufReader.html"><code>BufReader</code></a> or <a href="https://doc.rust-lang.org/std/io/struct.BufWriter.html"><code>BufWriter</code></a>. These quite simply buffer I/O operations, preferring to write things in a single large batch, over many small batches. This reduces your total syscalls, and overall increases performance.</p>
<p><strong>Remember!!:</strong> If you use a <a href="https://doc.rust-lang.org/std/io/struct.BufWriter.html"><code>BufWriter</code></a>, make sure to call <a href="https://doc.rust-lang.org/std/io/struct.BufWriter.html#method.flush"><code>flush</code></a> and/or <a href="https://doc.rust-lang.org/std/fs/struct.File.html#method.sync_all"><code>sync_all</code></a> before it's dropped! This will allow you to handle any errors.</p>
<pre><code>let fd = File::create("example.bin").expect("Failed to create file!");
let mut writer = BufWriter::new(fd);
std::io::copy(&amp;mut buffer, &amp;mut writer).expect("Failed to copy buffer!");
writer.flush().expect("Failed to write file!");
</code></pre>
<h2>std isn't always the best.</h2>
<p>The Rust standard library is great. I mean, it really is. But it doesn't always offer the best options. Some crates provide near-identical interfaces at greatly increased performance.</p>
<ul>
<li><a href="https://crates.io/crates/parking_lot"><code>parking_lot</code></a> - Offers better <a href="https://docs.rs/parking_lot/*/parking_lot/type.Mutex.html"><code>Mutex</code></a> and <a href="https://docs.rs/parking_lot/*/parking_lot/type.RwLock.html"><code>RwLock</code></a> implementations than Rust's standard library. In addition to performing better, they don't poison (so no need for an additional match/unwrap).</li>
<li><a href="https://crates.io/crates/crossbeam-channel"><code>crossbeam-channel</code></a> and <a href="https://crates.io/crates/flume"><code>flume</code></a> - These provide alternative <code>Sender</code>/<code>Receiver</code> implementations to the ones in <a href="https://doc.rust-lang.org/std/sync/mpsc/index.html"><code>std::sync::mpsc</code></a>. I personally prefer <a href="https://crates.io/crates/flume"><code>flume</code></a>, as it's implemented in 100% safe code.</li>
<li><a href="https://crates.io/crates/dashmap"><code>dashmap</code></a> is a better solution than throwing <code>Arc&lt;RwLock&lt;HashMap&lt;K, V&gt;&gt;&gt;</code> everywhere - as it's optimized with sharding, allows for concurrent access, highly performant, and easy to use/convert to.</li>
<li><a href="https://crates.io/crates/ryu"><code>ryu</code></a> and <a href="https://crates.io/crates/lexical"><code>lexical</code></a> - These are highly performant interfaces for converting to and from decimal strings. Quite simply, they turn <code>"1.2345"</code> to <code>1.2345_f32</code> and do so fast, and vice versa.
<ul>
<li>Just prefer to avoid text processing when possible, truth be told.</li>
</ul>
</li>
</ul>
<h2>Allocating the path to hell</h2>
<p>Many Rust developers take types such as <code>String</code> and <code>Vec</code> for granted, without understanding the downsides. These are <em>dynamically allocated</em> types. Allocations are not your friend when you're optimizing for performance. </p>
<ul>
<li>In types that will be serialized/deserialized from another format, prefer <a href="https://doc.rust-lang.org/std/borrow/enum.Cow.html"><code>Cow&lt;str&gt;</code></a>. This will allow you to borrow the string, and then convert it to an owned string if needed.</li>
<li>Look into crates such as <a href="https://crates.io/crates/tinyvec"><code>tinyvec</code></a> and <a href="https://crates.io/crates/smol_str"><code>smolstr</code></a>. These allow for you to have stack-optimized structures, with minimal effort.</li>
<li>Types that require an explicit <a href="https://doc.rust-lang.org/std/clone/trait.Clone.html"><code>clone</code></a> typically allocate! Prefer <a href="https://doc.rust-lang.org/std/marker/trait.Copy.html"><code>Copy</code></a> types where possible.</li>
</ul>
<p>In addition, look into alternative allocators which may yield better performance for your project, such as <a href="https://crates.io/crates/jemallocator">jemallocator</a> or <a href="https://crates.io/crates/mimalloc">mimalloc</a>.</p>
<h2>Advanced Magic Extensions</h2>
<p>Modern processor have tons of extremely useful extensions, such as <a href="https://en.wikipedia.org/wiki/Advanced_Vector_Extensions">AVX</a> and <a href="https://en.wikipedia.org/wiki/Streaming_SIMD_Extensions">SSE</a>. Even on non-x86 platforms, extensions with similar functionality are available, such as <a href="https://en.wikipedia.org/wiki/ARM_architecture#Advanced_SIMD_(NEON)">NEON</a> on ARM, and the <a href="https://en.wikipedia.org/wiki/RISC-V#Packed_SIMD">proposed P and V extensions for RISC-V</a>.</p>
<p>While Rust allows you to directly interface with these extensions, and there are many packages for higher-level interfacing, such as <a href="https://crates.io/crates/packed_simd">packed_simd</a> and <a href="https://crates.io/crates/generic-simd">generic-simd</a>, the LLVM optimizer is capable of automatically optimizing code to use these extensions.</p>
<p>You may need to pass <code>-C target-cpu=native</code> or <code>-C target-features=+avx</code> through <code>RUSTFLAGS</code> in order to take advantage of this (see <code>rustc --print target-features</code> for available features for your target, and use somethng like <code>lscpu</code> to see what your CPU supports).</p>
<ul>
<li>Doing things in groups of 4/8 is good for vectorization.
<ul>
<li>Do note, <strong>branching will heavily reduce the chances of vectorization.</strong></li>
</ul>
</li>
</ul>
<p>See this function. It converts four <code>f32</code>s into four <code>u8</code>s.</p>
<pre><code>#[inline]
pub unsafe fn f32_to_u8(f: f32) -&gt; u8 {
	if f &gt; f32::from(u8::MAX) {
		u8::MAX
	} else {
		f32::to_int_unchecked(f)
	}
}

/// Converts a slice of 4 [f32] s into a tuple of 4 [u8]s, rounding it in the process
#[must_use]
pub fn f32s4_to_u8(f: [f32; 4]) -&gt; (u8, u8, u8, u8) {
	let f = &amp;f[..4];
	unsafe {
		(
			f32_to_u8(f[0]),
			f32_to_u8(f[1]),
			f32_to_u8(f[2]),
			f32_to_u8(f[3]),
		)
	}
}
</code></pre>
<p>Now, we can throw this code into <a href="https://godbolt.org/">Compiler Explorer</a> to see what assembly it generates. Don't forget the compiler flags!</p>
<pre><code>example::f32s4_to_u8:
        vmovss  xmm0, dword ptr [rip + .LCPI0_0]
        vminss  xmm1, xmm0, dword ptr [rdi]
        vcvttss2si      eax, xmm1
        vminss  xmm0, xmm0, dword ptr [rdi + 4]
        vcvttss2si      ecx, xmm0
        vmovsd  xmm0, qword ptr [rdi + 8]
        vbroadcastss    xmm1, dword ptr [rip + .LCPI0_0]
        vcmpleps        xmm2, xmm1, xmm0
        vblendvps       xmm0, xmm0, xmm1, xmm2
        vcvttps2dq      xmm0, xmm0
        vpand   xmm0, xmm0, xmmword ptr [rip + .LCPI0_1]
        vpsllvd xmm0, xmm0, xmmword ptr [rip + .LCPI0_2]
        movzx   ecx, cl
        shl     ecx, 8
        movzx   eax, al
        or      eax, ecx
        vmovd   ecx, xmm0
        or      ecx, eax
        vpextrd eax, xmm0, 1
        or      eax, ecx
        ret
</code></pre>
<p>Success! It generates AVX instructions, such as <a href="https://www.felixcloutier.com/x86/vbroadcast"><code>VBROADCASTSS</code></a> and <a href="https://www.felixcloutier.com/x86/movss"><code>VMOVSS</code></a>!</p>
<h2>Making the compiler brrrr harder</h2>
<p>It is entirely possible to configure the compiler to optimize more aggressively! For example, in <code>Cargo.toml</code> (<strong>Do note this will increase compile times!!</strong>):</p>
<pre><code>[profile.release]
lto = 'thin'
panic = 'abort'
codegen-units = 1

[profile.bench]
lto = 'thin'
codegen-units = 1
</code></pre>
<p>Each option explained:</p>
<ul>
<li><code>lto = 'thin'</code> - Quite simply enables <a href="https://clang.llvm.org/docs/ThinLTO.html">Thin LTO</a>. You can also try <code>lto = 'fat'</code>, performance gains should be similar.</li>
<li><code>panic = 'abort'</code> - Abort instead of unwinding on panic. You'll get a smaller, more performant binary, but you won't be able to catch panics anymore. See <a href="https://doc.rust-lang.org/edition-guide/rust-2018/error-handling-and-panics/aborting-on-panic.html">the Rust Guide for more info</a>.</li>
<li><code>codegen-units = 1</code> - Ensures that the crate is compiled with only one <a href="https://doc.rust-lang.org/rustc/codegen-options/index.html#codegen-units">code generation unit</a>. This reduces the paralellization of the compilation, but will allow the LLVM to optimize it much better.</li>
</ul>
<h2>Edits</h2>
<ul>
<li><strong>9/30/2020, 3:40 PM EST</strong> - Re-phrased the Copy/Clone section, (thanks /u/SkiFire13) mentioned <code>sync_all</code> in the buffering section (thanks /u/Freeky), and also mentioned <code>lto = 'fat'</code> (thanks /u/po8)</li>
</ul>
<ul id="article_footer">
<li>tags: <a href="https://aspenuwu.me/tags/optimization.html">optimization<sup>1</sup></a><a href="https://aspenuwu.me/tags/rust.html">rust<sup>1</sup></a></li>
<li>date: 2020-09-29 21:46:19</li>
</ul>
</article></div>]]>
            </description>
            <link>https://aspenuwu.me/posts/rust-optimization.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24641608</guid>
            <pubDate>Wed, 30 Sep 2020 18:01:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why is Snowflake so Valuable?]]>
            </title>
            <description>
<![CDATA[
Score 240 | Comments 158 (<a href="https://news.ycombinator.com/item?id=24641481">thread link</a>) | @malisper
<br/>
September 30, 2020 | https://www.freshpaint.io/blog/why-is-snowflake-so-valuable | <a href="https://web.archive.org/web/*/https://www.freshpaint.io/blog/why-is-snowflake-so-valuable">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Two weeks ago, Snowflake had the largest IPO ever for a software company. On the first day of trading, the stock price doubled, giving Snowflake a market cap of over $60 billion. Snowflake became all that everyone was talking about. There was so much hype, my mom, who doesn't even know what Snowflake is, decided to invest in Snowflake.</p><p>At first glance, the valuation of $60 billion seems absurd. Not only is Snowflake not profitable, having a net loss of $349 million in 2019, but their revenue is also small relative to their valuation. Their revenue over the last 12 months was $403 million. Based on that, their market cap is around 150x their revenue. So why exactly is their market cap so high? Besides revenue and profitability, there are a number of other metrics that investors look at. Compared to similar software businesses, Snowflake has god-like metrics. In this post, I'm going to go through a number of metrics from Snowflake's S-1, explain what the metrics mean, and give context on just how exceptional Snowflake's metrics are.</p><p>The first metric that stands out is Snowflakes 121% year over year growth. To give you a sense of how fantastic it is, you can compare it to the growth rates of other companies at IPO. <a href="https://techcrunch.com/2013/08/24/how-fast-should-you-be-growing/">Institutional Venture Partners looked at how quickly Internet and software companies were growing at IPO</a>.</p><figure><p><img src="https://uploads-ssl.webflow.com/5dad2b1e508f04886d0245c3/5f74c44d240d4de932d463c4_growth1.jpeg" alt="growth1"></p></figure><p>Based on their numbers, only 25% of companies that are between $75M-$500M in annual revenue are growing at just over 60% year over year. Snowflake's growth rate is nearly twice that! Snowflake's revenue was also $403M for the last 12 months, which would put them at the high end of that range. Not only are they growing significantly faster than other companies, but they are already significantly larger!</p><p>For companies that sell software to businesses an important number to look at is their retention rate. For Snowflake, their net retention rate is 158%. You may be asking, how do they have a retention rate over 100%? That's because companies that use Snowflake pay more for Snowflake over time. For every $1 of revenue Snowflake received from their customers a year ago, that same pool of customers are now paying $1.58. That means Snowflake could acquire no new customers, and they would still be doubling revenue every 18 months.</p><p>To compare that to other companies, <a href="https://www.lennyrachitsky.com/p/what-is-good-retention-issue-29">Lenny Rachitsky surveyed a number of industry experts on what they thought good and great net retention would be</a>. On average, for enterprise subscription software, the category Snowflake would fall under, the experts surveyed said 110% net retention would be good and 130% net retention would be great. He also pulled the net retention rates for a number of public companies:</p><ul role="list"><li><strong>Alteryx</strong>: 135% (<a href="https://docs.google.com/spreadsheets/d/1ogELPtct2s6jj9wRBpOgqGUE5k4cO73XXcvqmEZE89M/edit#gid=0">source</a>)</li><li><strong>Fastly</strong>: 130% (<a href="https://www.saastr.com/5-interesting-learnings-from-fastly-as-it-gets-ready-to-ipo/">source</a>)</li><li><strong>Okta</strong>: 124% (<a href="https://docs.google.com/spreadsheets/d/1ogELPtct2s6jj9wRBpOgqGUE5k4cO73XXcvqmEZE89M/edit#gid=0">source</a>)</li><li><strong>Anaplan</strong>: 124% (<a href="https://www.key.com/kco/images/Public_SaaS_Company_Retention_Metrics_2019.pdf">source</a>)</li><li><strong>Workday</strong>: 100%+ (<a href="https://www.workday.com/content/dam/web/en-us/documents/investor/workday-financial-analyst-day-2018.pdf">source</a>)</li><li><strong>ServiceNow</strong>: 97% (<a href="https://www.publiccomps.com/tickers/NOW">source</a>)</li></ul><p>You will notice that Snowflake's net retention rate of 158% is significantly higher than all of these!</p><p>Net promoter score (NPS) is a way of measuring customer satisfaction. It's convenient because it's easy to calculate and boils down customer satisfaction to a single number, making it easy to compare NPS between different companies. To compute NPS, a company performs a survey of their customers. The company asks "On a scale of 0 to 10, how likely are you to recommend this company’s product or service to a friend or a colleague?". Anyone that answers 9 or 10 is deemed a "promoter" of the product, while anyone that answers 6 or less is considered to be a "detractor". To compute the NPS, you take the percentage of users that are promoters and subtract the percentage of users that are detractors. This results in a number between -100 and 100 which is the NPS.</p><p>To give some examples, an NPS of 0 means your company has just as many promoters as detractors, whereas an NPS of 100 means everyone loves your product. Here are the NPS's for a few well known companies according to <a href="https://www.satmetrix.com/infographic/2020-us-consumer-benchmarks/">satmetrix</a>:</p><ul role="list"><li>Apple - 62</li><li>AirBnB - 43</li><li>AT&amp;T - 20</li></ul><p>What is Snowflake's NPS score? It's 71. According to NPS, Snowflake's customers like Snowflake more than Apple's customers like Apple.</p><p>The average Snowflake customer pays Snowflake $165k a year. Average contract value (ACV) is a useful metric to look at because it gives you a rough sense of how efficient a sales team is. To elaborate, there's a similar amount of work needed for a sales person to sell a $50k deal as there is for a sales person to sell a $100k deal. This is because most of the work a sales person does such as giving a demo, dealing with the paper process, and negotiating, have to happen regardless of how much the contract actually winds up being. Closing a $100k deal brings in twice as much revenue as a $50k deal does, but it's not usually twice as much work.</p><p>For this reason, higher average contract values are usually better. According to <a href="https://dskok-wpengine.netdna-ssl.com/wp-content/uploads/2020/08/2020-KBCM-SaaS-Survey.pdf">KBCM Technology Group</a>, 29% of software businesses have an ACV between $50k-$250k, and only 9% have an ACV greater than $250k. That gives Snowflake a relatively healthy ACV.</p><p>Not only does Snowflake have a high ACV, but their high end contract values are also really high. Snowflake has 56 customers that pay them over $1M a year. They also have Capital One, their largest customer, account for 11% of their 2019 revenue with approximately $29M.</p><p>Snowflake's net loss of $349M during 2019 does not sound good, but it does not tell the full story. There are two issues with using profit as a metric when looking at a subscription software business:</p><ul role="list"><li>Due to the generally accepted accounting principles (GAAP), a customer can give Snowflake money, but Snowflake can't count that money as revenue until a later date, even though that money is in Snowflake's bank account.</li><li>A net loss doesn't tell you where the money is coming in and where the money is going to.</li></ul><p>Addressing each of these points:</p><h3>Revenue under GAAP</h3><p>Under GAAP, Snowflake doesn't count revenue when a customer pays them, but instead when a customer uses the Snowflake product. To be more specific when a company pays Snowflake, they are purchasing a number of "Snowflake credits". When you are using the Snowflake product you exchange your credits for Snowflake compute time.</p><p>As an example, let's say a customer purchases one year of Snowflake credits for $100k. That money winds up in Snowflake's bank account, but Snowflake cannot count that $100k as revenue until Snowflake delivers the service, which is when the customer uses their credits for compute time. If the customer uses a quarter of the Snowflake credits within three months after purchases them, under GAAP, Snowflake would count that as $25k in revenue over those three months.</p><p>You can see the impact this has by looking at the $688M Snowflake has in "remaining performance obligations". This $688M is money that Snowflake's customers have either already given to Snowflake or have contractually committed to giving to Snowflake, but it won't show up as revenue until the customers use the credits they purchased.</p><h3>Where's the money going?</h3><p>The other thing to look at is what they are spending the money on. Snowflake is making money on every sale. They have a gross profit of 62% so they have no problem running the product. The thing is they are spending A LOT on sales and marketing. Their total net loss for the last six months was $171M while during the same time period they spent $191M on sales and marketing. If they wanted to, they could stop investing in growth, lay off their entire sales and marketing team, and they would become profitable. In other words, Snowflake could be profitable if they wanted to, but they are intentionally choosing not to, and are instead focusing on growing the customer base.</p><p>Not that they should. If we assume the $191M they spent in sales and marketing over the last six months was responsible for the $81M increase in revenue in the last six months compared to the prior six months, every $1 Snowflake invests in sales and marketing results in $.42 of revenue. With Snowflake's 158% net retention rate, that customer will pay back the initial investment in sales and marketing after around two years and then return many times the investment in the years following that.</p><p>In practice, Snowflake probably sees a return on investment much sooner. A company pays for Snowflake well before Snowflake is able to count that money as revenue.</p><p>So does it make sense for Snowflake's market cap to be 150x their revenue. I definitely think it's high, but I it's certainly plausible. They're growing faster, have higher customer satisfaction, and just have phenomenal metrics across the board when compared to similar businesses.</p><p>‍</p></div></div>]]>
            </description>
            <link>https://www.freshpaint.io/blog/why-is-snowflake-so-valuable</link>
            <guid isPermaLink="false">hacker-news-small-sites-24641481</guid>
            <pubDate>Wed, 30 Sep 2020 17:50:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Save Millions with QSBS and Section 1045 Rollovers]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24641348">thread link</a>) | @ankit77
<br/>
September 30, 2020 | https://goyalpost.com/2020/09/29/how-to-save-millions-with-qsbs-and-section-1045-rollovers/ | <a href="https://web.archive.org/web/*/https://goyalpost.com/2020/09/29/how-to-save-millions-with-qsbs-and-section-1045-rollovers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Qualified Small Business Stock (QSBS) is some of the most tax-advantaged stock you can hold, yet few people know about it. If you’re a founder, early employee, or investor, you can potentially save millions of dollars by understanding the implications of QSBS.</p>



<p>In this article I will discuss the following:</p>



<ol><li>History of QSBS</li><li>QSBS Tax Savings</li><li>Requirements for QSBS</li><li>Section 1045 Rollover (applicable if you don’t meet the five year holding period, explained below)</li></ol>



<p>I recently sold shares in a company I co-founded and spoke to more than two dozen accountants in the process. I’m summarizing my findings and experiences in the article below. As such, the information in this article is not formal tax advice. I recommend you speak with your accountant prior to making any decisions.&nbsp;</p>



<h2>History of QSBS</h2>



<p>Section 1202 is the section of the tax code that outlines the QSBS tax exclusion. It was added to the tax code in 1993 to encourage individuals to invest in new ventures, far before the creation of Silicon Valley as we know it today. The act, however, failed to provide the intended incentive of spurring investments in new ventures.</p>



<p>Over the past three decades, a number of tailwinds have propelled QSBS back into the limelight. Congress reduced the tax on long-term capital gains in 1997, increased the tax savings of QSBS incrementally until 2010, and finally reduced corporate taxes from 35% to a flat 21% in 2017. These three forces have made QSBS far more relevant today than in the past.</p>



<h2>QSBS Tax Savings</h2>



<p><strong>Under Section 1202, your gains from selling QSBS may be eligible for up to 100% exclusion from federal and state taxes. This exclusion is limited to the </strong><strong><em>greater</em></strong><strong> of $10 million or 10 times your cost basis during a liquidity event.</strong></p>



<p>For instance, the excludable amount for a founder may be on $10 million of gain, while the exclusion for a VC may be much greater. If, for instance, a VC invests $20 million, the VC may obtain an exclusion for $200 million of gain. See the “Scenario Table” in the Appendix for more examples. Please also note that if you end up selling your shares in multiple tranches over multiple years, the excludable amount might vary. Reference<a href="https://www.thetaxadviser.com/issues/2018/nov/qualified-small-business-stock-more-attractive.html"> this</a> article for further details.</p>



<p><strong>If you qualify for a QSBS tax exclusion, you are 100% exempt from federal taxes. The current federal tax rate is 23.8% (20% federal + 3.8% medicare). This means you can save 23.8% in long-term capital gains that you would have been subject to otherwise. Depending on which state you live in (</strong><strong><em>not</em></strong><strong> which state the company is incorporated), you may qualify for state-level exclusion as well.</strong> States typically fall into one of four buckets:</p>



<ol><li>States with no individual income tax or no capital gains tax. These states are QSBS compliant by default.</li><li>States that follow the federal tax code and waive state taxes if an individual meets the federal-level QSBS requirements. These states are also QSBS compliant.&nbsp;</li><li>States that have their own QSBS exclusion statues.</li><li>States that do not recognize QSBS in any way, shape, or form (California notably falls in this bucket).&nbsp;</li></ol>



<p>I’ve provided a chart of applicable QSBS treatment in each of the 50 states and District of Columbia in the Appendix.</p>



<h2>Requirements for QSBS</h2>



<p><strong>For your stock to qualify as QSBS, you must meet certain requirements at the time of your stock issuance, and others during your entire holding period of the stock. If you sell QSBS, you must report the entire gain as a long-term gain on your Schedule D, and enter the allowable exclusion as a loss below the entry for the gain.</strong></p>



<h3>Requirements that must be met on the date of issuance:</h3>



<ul><li>Corporation issuing the stock must be a domestic C-Corp (and the stock must be issued after August 9, 1993)</li><li>You must acquire your stock directly from the company for money, property, or services. The only exception is if you acquire the stock by gift or inheritance. In this case, you are treated as having acquired the stock in the same manner as the original owner.<ul><li>Note: do not contribute the stock to a family LLC, limited partnership/trust, or to an LLC organized to manage the sale of your stock. This will disqualify the stock as QSBS.</li></ul></li><li><strong>Corporation must have assets of $50M or less at the time you receive your shares (or exercise your options).</strong><ul><li>Note: this is a continuous requirement and if at any point the assets of a corporation exceed $50M, the corporation can never again issue QSBS (even if the assets are below $50M on the date of the subsequent issuance).</li><li>Note: the assets of the corporation must not exceed $50M even after taking into account amounts the corporation received in the current issuance. If, for instance, a company has $40M in the bank and is raising a $20M Series B, none of the newly issued Series B stock will be QSBS.</li></ul></li><li>You must determine your stock issuance date. This is critical for three reasons:<ul><li><strong>Starts the clock for purposes of the five-year holding period requirement. In order to be eligible for the tax exemption outlined above, you must have held on to your stock for a minimum of five years.</strong> If you do not meet this minimum requirement, you can employ a Section 1045 rollover (described below) to extend your holding period.<ul><li><strong>Note: this requirement is yet another reason why you should early exercise your options and file an 83(b). Early exercise allows you to 1) start the one year holding period for long-term capital gains treatment, and 2) start the five year holding period for Section 1202. If you don’t file an 83(b) election, the clock on long-term capital gain only begins when your shares vest – so if there are multiple vesting dates, you will have multiple clocks to monitor for long-term capital gain – and, if eligible, QSBS. An unexercised option or warrant is not considered QSBS, even if the underlying stock would meet the definition of QSBS.</strong></li><li><strong>Note: for stock acquired through the exercise of an option, the company must pass the “$50M asset test” on the date of your exercise, not on the date of your grant.</strong> Similarly, for stock acquired through the vesting of RSUs, the company must pass the “$50M asset test” on vesting, and your five year holding period begins on vesting, not on grant.</li><li>Note: if the stock was received as a gift, inheritance, or as a distribution from a partnership, the acquisition date is the date on which the transferor acquired the stock.</li></ul></li><li>Determines whether gain from the sale of the QSB stock is eligible for a 50%, 75%, or 100% federal tax exclusion.<ul><li>50% federal tax exclusion for stock issued before February 18, 2009</li><li>75% federal tax exclusion for stock issued between February 18, 2009 and September 27, 2010</li><li>100% federal tax exclusion for stock issued after September 27, 2010</li></ul></li><li>Marks the date on which the company must have $50M or less in assets.&nbsp;</li></ul></li></ul>



<h3>Requirements that must be met during the shareholder’s holding period:</h3>



<ul><li>Corporation must be a C-corp for the entire holding period.</li><li><strong>The corporation must be an “active business” during the entire period you held your stock. This means that at least 80% (by value) of the assets in your corporation must be used to pursue business in industries </strong><strong><em>other</em></strong><strong> than the industries below. Note that if your business provides a service, then it most likely does not qualify as a qualified small business.&nbsp;</strong><ul><li>Health, law, non-software engineering (civil, electrical, etc), architecture, accounting, actuarial science, performing arts, consulting, athletics, financial services, or brokerage.</li><li>Banking, insurance, financing, leasing, investing, or similar business.</li><li>Farming.</li><li>Mining or natural resource production or extraction.</li><li>Operating a hotel, restaurant, or similar business.</li></ul></li><li>Cash held for burn requirements generally qualify under this “active business” requirement. However, after two years, technically no more than 50% of the corporation’s assets can qualify under this exemption. While startups usually satisfy this requirement, it isn’t always clear how to apply the rule, especially if the startup retains significant cash following an investment (in other words, overfunded startups sitting on cash). If you’re like most startups and you’re burning cash to fund business operations you will most likely pass this check.</li><li>If the corporation bought back 5% or more of its stock in the year before or after your stock issuance, your stock will not qualify as QSBS.&nbsp;</li></ul>



<h2>Section 1045 Rollover</h2>



<p><strong>In order to be eligible for preferential tax treatment under Section 1202, you must satisfy the requirements above and have held onto your stock for at least five years. If you have not met the five year minimum, however, you can employ a Section 1045 rollover to extend your holding period.</strong></p>



<p><strong>If you have held onto your QSBS for at least six months, you can sell your QSBS and roll the proceeds of the sale into another QSBS issuer without recognizing a gain under Section 1045.</strong> This is a similar concept to a Section 1031 exchange in real estate. <strong>Per Section 1045, you have 60 days from the date of the sale of your original QSBS to roll the sale proceeds into new QSBS.</strong> In general, you should roll all of the proceeds from your sale of original QSBS into the new QSBS. If you take any cash off the table after the initial sale, that amount would be subject to capital gains tax. <strong>The cost basis of the new QSBS is the same as the cost basis of the original QSBS, and the holding period from the original QSBS is counted towards the holding period of the new QSBS.</strong></p>



<p>Consider the following scenario: you acquire 5M shares of QSBS from “Company A” on January 1st, 2010 for $0.00001 per share. Your original cost basis is $50 (5M * $0.00001). Assume you then sell these shares in Company A for $4M on January 1st, 2012, and then reinvest this $4M to purchase 2,000 shares of QSBS in “Company B”. Your holding period will pick up from where it left off and the cost basis for your new shares in Company B will be the same as the original cost basis for your shares in Company A ($50). If you then sell your QSBS in Company B at any point after January 1, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://goyalpost.com/2020/09/29/how-to-save-millions-with-qsbs-and-section-1045-rollovers/">https://goyalpost.com/2020/09/29/how-to-save-millions-with-qsbs-and-section-1045-rollovers/</a></em></p>]]>
            </description>
            <link>https://goyalpost.com/2020/09/29/how-to-save-millions-with-qsbs-and-section-1045-rollovers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24641348</guid>
            <pubDate>Wed, 30 Sep 2020 17:39:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Temporal reaches version 1]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24641125">thread link</a>) | @Sevein
<br/>
September 30, 2020 | https://docs.temporal.io/blog/temporal-v1-announcement/ | <a href="https://web.archive.org/web/*/https://docs.temporal.io/blog/temporal-v1-announcement/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p><strong>Latest Release at Time of Writing:</strong>&nbsp;V1.0.0</p><p>Hey Temporal community, I hope you've got your socks on because this isn't a typical transparency report. I am extremely happy to announce that we have officially reached stability which means that Temporal V1 production release is now available.</p><p>This is a huge milestone for the project, community and Temporal as a business. Without our community, Temporal would have never existed. For all of you who have been waiting or blocked by this release, your patience is appreciated. This release served as a learning process for the Temporal team and we hope that it reflects in our future behavior.</p><img alt="V1 pipeline" src="https://docs.temporal.io/img/v1-pipeline.png"><h2>What does this mean?</h2><p>Temporal version 1 is available and ready for production consumption with the caveats covered in our last report (reiterated below). This also means that the system has entered a backwards compatibility era where there will be no more breaking API or schema changes for publicly facing APIs. Note that we will have a deprecation policy (which will be made public in the near future) so we can continue evolving and improving the product.</p><p>In this release we improved how shard IDs are hashed. This may cause an elevated rate of errors when upgrading cluster in-place from a previous release. To be 100% clear there is no potential for data loss and this should only happen once. The practical impact is slightly higher resource usage on your cluster until the upgrade is complete.</p><h3>What is not included in the release?</h3><p>When scoping out the V1 stabilization work, we triaged features based on criticality and usage. During our triage we collected a list of features that we felt could be stabilized after the release and would not block the majority of users. We want to stress that these features are in no way "broken" and many users are already relying on them without issue. That being said, these features have not gone through the rigorous set of checks and validations that we require before deeming something "production ready". Moving forward, we will be referring to features that fall into this bucket as "experimental".</p><p>With this context, here are the features we consider experimental in this release:</p><ul><li>Archival</li><li>Cross data center replication</li><li>Batch operations (signal, terminate, cancel)</li><li>Dynamic config</li><li>Addition, removal and creation of searchable attributes with ElasticSearch</li></ul><h2>What's next?</h2><p>V1 is just the start of the Temporal story. Moving forward expect to see things like support for new languages, databases and security capabilities. We also plan to ramp up our engagement with users and have regular meetups, conferences and design sessions. On the business side, we are working on a cloud offering which will provide Temporal as a service. Aside from being a reasonably good way to support the company, we strongly believe that the requirement to run Temporal is one of the biggest barriers of adoption today. Having a cloud solution will make it much easier for new users to get started with Temporal and therefore enable us to continue growing this already great community. We still plan to release regular transparency updates but they may not come on such a strict schedule.</p><h3>Versioning</h3><p>We recently made some changes to how our versioning will work moving forward.</p><ol><li>All validation logic is on the server. Client only sends headers. If header is missing assume that "client doesn't care" and no restriction is applied.</li><li>Client sends to server following headers:</li></ol><ul><li><code>client-name</code>: one of <code>temporal-go</code>, <code>temporal-java</code>, <code>temporal-cli</code>,</li><li><code>client-version</code>: <code>1.0.0</code>,</li><li><code>supported-server-versions</code>: <code>&gt;=1.0.0 &lt;2.0.0</code>.</li></ul><ol start="3"><li>Server has <code>GetClusterInfo</code> API which returns its version and supported version ranges for every supported client.</li><li>All old clients and servers are supported because they don't send these headers and fit into "I don't care" category. Moving forward we will be able to restrict old clients and old servers. (edited)</li></ol><p>As always, feel free to reach out with questions, comments or critical feedback via email, Slack or our community forum.</p><p>Email:&nbsp;<a href="mailto:ryland@temporal.io" target="_blank" rel="noopener noreferrer">ryland@temporal.io</a></p><p>Slack:&nbsp;<a href="http://temporalio.slack.com/" target="_blank" rel="noopener noreferrer">temporalio.slack.com</a></p><p>Forum:&nbsp;<a href="https://community.temporal.io/" target="_blank" rel="noopener noreferrer">https://community.temporal.io/</a></p></section></div>]]>
            </description>
            <link>https://docs.temporal.io/blog/temporal-v1-announcement/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24641125</guid>
            <pubDate>Wed, 30 Sep 2020 17:18:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Telegram bot to get new HN stories by keywords]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24640924">thread link</a>) | @solus_factor
<br/>
September 30, 2020 | https://solus.life/hnbuzz/ | <a href="https://web.archive.org/web/*/https://solus.life/hnbuzz/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://solus.life/hnbuzz/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24640924</guid>
            <pubDate>Wed, 30 Sep 2020 17:00:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ray 1.0]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24640775">thread link</a>) | @robertnishihara
<br/>
September 30, 2020 | https://www.anyscale.com/blog/announcing-ray-1-0 | <a href="https://web.archive.org/web/*/https://www.anyscale.com/blog/announcing-ray-1-0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h3>Announcing Ray&nbsp;1.0</h3><p>Today, we’re happy to announce the release of <a href="https://github.com/ray-project/ray">Ray 1.0</a>. Ray 1.0 brings a <a href="https://docs.ray.io/en/master/package-ref.html">stable API</a> and new <a href="https://ray2020.sched.com/event/dhCy/ray-a-general-purpose-serverless-substrate-eric-liang-anyscale">general purpose serverless</a> features, both important steps towards the goal of providing a universal API for distributed computing. This past release has seen 67 contributors and 458 commits, making it the among the <a href="https://github.com/ray-project/ray/releases">largest yet</a> for Ray. In addition, 1.0 brings many new community <a href="https://docs.ray.io/en/master/ray-libraries.html">library integrations</a> to the growing Ray ecosystem.</p><h3>New Features</h3><p>Ray 1.0 makes it easier than ever to build and compose highly scalable libraries, applications, and services. Here are the highlights:</p><p><b>Resources, Not Machines: </b>Building distributed applications that run portably across different machine types, clusters, and clouds is a challenging task. Ray 1.0 makes this easy with an <a href="https://docs.ray.io/en/master/cluster/autoscaling.html">autoscaler</a> that intelligently selects the best <a href="https://docs.ray.io/en/master/cluster/autoscaling.html#multiple-node-type-autoscaling">node types</a> for an application’s <a href="https://docs.ray.io/en/master/advanced.html#accelerator-types">resource requests</a>. In addition, Ray 1.0 introduces <a href="https://docs.ray.io/en/master/placement-group.html">a placement group API</a> for fine-grained control over scheduling.</p><p><b>Production Serving: </b>A general purpose serverless framework hosts both offline batch and online serving workloads. Ray 1.0 ships with <a href="https://docs.ray.io/en/master/serve/">Ray Serve</a>, a production microservice and ML serving library. For custom serving applications, Ray 1.0 also introduces <a href="https://docs.ray.io/en/master/actors.html?highlight=lifetime#actor-lifetimes">detached</a> actor lifetimes, <a href="https://docs.ray.io/en/master/async_api.html">AsyncIO</a> actors, and application-level metrics via <a href="https://docs.ray.io/en/master/ray-metrics.html?highlight=prometheus">Prometheus</a>. Ray serving applications can be deployed in various <a href="https://docs.ray.io/en/master/cluster/cloud.html">cloud providers</a> and on <a href="https://docs.ray.io/en/master/cluster/kubernetes.html">Kubernetes</a>.</p><p><b>Automatic Memory Management</b>: Users of Ray 1.0 can say goodbye to “object evicted” errors, thanks to fully automated <a href="https://docs.ray.io/en/master/memory-management.html">memory management</a>. Application performance and memory usage can be debugged in the <a href="https://docs.ray.io/en/master/ray-dashboard.html">Ray dashboard</a>. To learn more about how Ray implements distributed reference counting with high-performance, reliability, and fault tolerance, check out the new <a href="https://docs.ray.io/en/master/whitepaper.html">Ray 1.0 whitepaper</a>.</p><p><b>Java and Windows Support: </b>Ray 1.0 brings native support for the Java and Windows platforms. This means that you can now use Ray to build <a href="https://docs.ray.io/en/master/cross-language.html">cross-language</a> and <a href="https://medium.com/distributed-computing-with-ray/build-distributed-java-applications-with-ray-90b381eff564">distributed Java</a> applications, and <a href="https://docs.ray.io/en/master/installation.html#windows-support">install Ray on Windows</a>.</p><h3>Community Update</h3><p><b>Community Integrations</b>: There are a growing number of <a href="https://docs.ray.io/en/master/ray-libraries.html">community libraries</a> that integrate with Ray 1.0 for distributed execution: <a href="https://classyvision.ai/tutorials/ray_aws">ClassyVision</a>, <a href="https://docs.ray.io/en/master/dask-on-ray.html">Dask</a>, <a href="https://github.com/asappresearch/flambe">Flambe</a>, <a href="https://horovod.readthedocs.io/en/stable/ray_include.html">Horovod</a>, <a href="https://huggingface.co/transformers/master/main_classes/trainer.html#transformers.Trainer.hyperparameter_search">HuggingFace</a>, <a href="https://analytics-zoo.github.io/master/#ProgrammingGuide/rayonspark/">Intel Analytics Zoo</a>, <a href="https://docs.ray.io/en/master/mars-on-ray.html">MARS</a>, <a href="https://github.com/modin-project/modin">Modin</a>, <a href="https://github.com/Intel-bigdata/oap-raydp">RayDP</a>, <a href="https://github.com/SeldonIO/alibi">Seldon Alibi</a>, and <a href="https://pypi.org/project/spacy-ray/">SpaCy</a>. This means users of these libraries can now scale their applications with Ray, and Ray users can easily leverage these libraries in their distributed applications.</p><p><b>Open Source</b>: At Anyscale, we’re proud to develop Ray along with the open source community. Many key Ray contributions are driven by the community — for example, ongoing projects around high availability, multi-tenancy, and placement groups are led by <a href="https://www.antgroup.com/en">Ant Group</a>, and improved autoscaler support for different Clouds has come from <a href="https://aws.amazon.com/">Amazon</a> and <a href="https://azure.microsoft.com/en-us/">Microsoft</a>.</p><h3>More Information</h3><p>To learn more about Ray, join us at <a href="https://events.linuxfoundation.org/ray-summit/">Ray Summit</a>, which runs from September 30 to October 1. You can also find out more about Ray 1.0 through the <a href="https://forms.gle/9TSdDYUgxYs8SA9e8">Ray Slack</a> or the <a href="https://docs.ray.io/en/master/index.html">Documentation</a>.</p></div></div></div>]]>
            </description>
            <link>https://www.anyscale.com/blog/announcing-ray-1-0</link>
            <guid isPermaLink="false">hacker-news-small-sites-24640775</guid>
            <pubDate>Wed, 30 Sep 2020 16:49:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Easy Ubuntu Hardening for Web Developers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24640736">thread link</a>) | @mariuz
<br/>
September 30, 2020 | https://blog.openbloc.com/automated-hardening-for-ubuntu/ | <a href="https://web.archive.org/web/*/https://blog.openbloc.com/automated-hardening-for-ubuntu/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://cdn.openbloc.fr/2020/06/Capture-d--cran-de-2020-06-17-13-40-37.png 300w,
                            https://cdn.openbloc.fr/2020/06/Capture-d--cran-de-2020-06-17-13-40-37.png 600w,
                            https://cdn.openbloc.fr/2020/06/Capture-d--cran-de-2020-06-17-13-40-37.png 1000w,
                            https://cdn.openbloc.fr/2020/06/Capture-d--cran-de-2020-06-17-13-40-37.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://cdn.openbloc.fr/2020/06/Capture-d--cran-de-2020-06-17-13-40-37.png" alt="Easy Ubuntu Hardening for Web Developers">
            </figure>

            <section>
                <div>
                    <p>You may have good reasons to focus on developing your disrupting app. And you may well be a very talented developer. But like me, even after years of experience as a web engineer, comes a point where we have to admit we don't know that much about security.</p><p>Unless you only use fully managed solutions to host your web applications, your startup probably has a bunch of servers you have to monitor and maintain. And unless your company has the scale to pay for real DevOps, security engineers, audits or pentests, then quite frankly, we'll mainly focus on finishing the current sprint hoping to get some traction ;)</p><p>Today I got my first Ubuntu VPS from <a href="https://blog.openbloc.com/p/3f54a7d4-a161-4bf0-a9ee-8ea9c6daf259/www.ovh.com">OVH</a>, a fresh new image ready to host the next version of my website. And it's got me thinking: I do remember it's best practice to disable SSH login by password, what else should I do ? Do I need a firewall ? Surely I don't have time to fully audit this default Ubuntu image by myself...</p><p>In this article I'll show you how to harden a default Ubuntu Server 20.04 image using existing open-source tools:</p><ol><li><a href="https://www.inspec.io/">Inspec</a> to identify security issues and misconfiguration</li><li><a href="https://www.ansible.com/">Ansible</a> to automatically harden your server</li><li><a href="https://dev-sec.io/">The DevSec Hardening Framework</a> which provides:<br>- <a href="https://github.com/dev-sec/linux-baseline">An Inspec profile</a><br>- <a href="https://github.com/dev-sec">Ansible / Chef / Puppet recipes</a> to enforce above Inspec profile</li></ol><!--kg-card-begin: markdown--><h2 id="quicksshsetup">Quick SSH setup</h2>
<p>Make sure your server is defined in <code>~/.ssh/config</code></p>
<pre><code>Host servername
	HostName &lt;your server ip address&gt;
	User username
	Port 22
</code></pre>
<p>To ssh into the server with your ssh key without typing the password just run:</p>
<p><code>$ ssh-copy-id -i ~/.ssh/id_rsa.pub servername</code></p>
<h2 id="usinginspecwithlinuxbaselineprofile">Using Inspec with linux-baseline profile</h2>
<p>On the server:</p>
<pre><code># download and install Inspec
$ wget https://packages.chef.io/files/stable/inspec/4.20.2/ubuntu/20.04/inspec_4.20.2-1_amd64.deb
$ sudo dpkg -i inspec_4.20.2-1_amd64.deb

# clone the linux-baseline profile
$ git clone https://github.com/dev-sec/linux-baseline

# run the Inspec profile
$ inspec exec linux-baseline
</code></pre>
<p><a href="https://www.inspec.io/docs/reference/install/">Inspec installation instructions</a></p>
<p>You should see a similar output:<br>
<img src="https://cdn.openbloc.fr/2020/06/Capture-d--cran-de-2020-06-17-13-01-40.png" alt="Capture-d--cran-de-2020-06-17-13-01-40"></p>
<p>Next thing will be to automatically apply better OS settings using Ansible and the recipes provided by the DevSec framework.</p>
<h2 id="usingansibletohardentheserver">Using Ansible to harden the server</h2>
<p>On your local machine:</p>
<pre><code># install Ansible
$ sudo apt update
$ sudo apt install software-properties-common
$ sudo apt-add-repository --yes --update ppa:ansible/ansible
$ sudo apt install ansible

# install the os and ssh hardening roles
$ ansible-galaxy install dev-sec.os-hardening
$ ansible-galaxy install dev-sec.ssh-hardening
</code></pre>
<p><a href="https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html">Ansible installation instructions</a></p>
<p>We then need to write a playbook for each ansible role:</p>
<pre><code># ansible-os-hardening.yaml
- hosts: your-server
  become: true
  roles:
    - dev-sec.os-hardening
    
# ansible-ssh-hardening.yaml 
- hosts: your-server
  become: true
  roles:
    - dev-sec.ssh-hardening
</code></pre>
<p>Finally run these playbooks with the following commands:</p>
<pre><code>$ ansible-playbook -K ansible-os-hardening.yaml
$ ansible-playbook -K ansible-ssh-hardening.yaml
</code></pre>
<p>Then, re-running <code>inspec exec linux-baseline</code> on the server should give a similar output:<br>
<img src="https://cdn.openbloc.fr/2020/06/Capture-d--cran-de-2020-06-17-13-00-59.png" alt="Capture-d--cran-de-2020-06-17-13-00-59"></p>
<p>Which is much better!</p>
<h2 id="finalthoughts">Final thoughts</h2>
<p>Though I can't say I have audited the DevSec framework per-se, I hope you now have a better understanding on how you can automate your servers security to stay up-to-date whith industry best practices.</p>
<p>Depending on what you then run on your server, you may have to allow some ports on the Ubuntu firewall, <a href="https://help.ubuntu.com/community/UFW">ufw</a>. Personally while testing <a href="https://caprover.com/">CapRover</a> I just had to run:</p>
<p><code>$ ufw allow 80,443,3000,996,7946,4789,2377/tcp; ufw allow 7946,4789,2377/udp;</code></p>
<h3 id="thanksforreadingandtakecare">Thanks for reading and take care !</h3>
<!--kg-card-end: markdown-->
                </div>
            </section>

                <section>
    <h3>Subscribe to Openbloc</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.openbloc.com/automated-hardening-for-ubuntu/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24640736</guid>
            <pubDate>Wed, 30 Sep 2020 16:46:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introducting Guide: A GUI for your Deta Base]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24640669">thread link</a>) | @mxek
<br/>
September 30, 2020 | https://blog.deta.sh/posts/base_guide/ | <a href="https://web.archive.org/web/*/https://blog.deta.sh/posts/base_guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <header>
    
    <time datetime="2020-09-30T00:00:00Z">September 30, 2020</time>
  </header>
  

<h2 id="what-s-a-deta-base-guide">What’s a Deta Base Guide?</h2>

<p>Base Guide (beta) is a graphical user interface for Deta Base. Base Guide was inspired by the struggles of many developers in interacting with the data powering their apps, <em>outside the confines</em> <em>of the app  itself.</em></p>

<p>A video tour is available <a href="#tour">at the end of the post</a>.</p>

<h2 id="motivation"><strong>Motivation</strong></h2>

<p>Since shipping <a href="https://youtu.be/jHYFrS0LVY8?t=110">the earliest alpha of Deta &amp; Deta Base</a>, devs have resonated with the simplicity of spinning up a database using Deta. In it’s purest form, there is no marginal config step required, it’s just code.</p>

<p>This approach is great when you want to design state from the comforts of your text editor. While Base has provided a persistent state solution for some inspirational apps so far, we realized it was falling short on another dimension we didn’t initially expect.</p>

<p>The biggest shortcoming we’ve heard from users about Base is the lack of a UI. We often heard ‘<em>I want to be able to easily see and interact with the data my app generates</em>’.  We noticed some users would hack around this shortcoming, adding auxiliary logic to their application or a side script to quickly inspect or modify the records their main app generates.</p>

<p>But going through both a text editor and running a script to inspect and modify records is less than ideal. Two members of our community— turned summer fellows—both took it a step further, each hacking their own Base records viewers together (<a href="https://explorer.deta.dev/">first</a> w/ <a href="https://github.com/fillerInk/deta-base-explorer">source</a>; <a href="https://base-ui.jajoo.fun/">second</a> w/ <a href="https://github.com/jajoosam/base-ui">source</a>).</p>

<p>Suffice to say, we are extremely excited to address this need and launch Deta’s official Base GUI solution into beta, building off the work of the second solution. With Base Guide, you can rapidly inspect, add, delete, and modify the records contained in your Base.</p>

<h3 id="inspecting-records">Inspecting Records</h3>

<p>To view a Base’s records, all you need to do is open an individual Base from the Deta Project’s Sidebar. By default the Base’s records will load into Base Guide.</p>

<p><img src="https://dev-to-uploads.s3.amazonaws.com/i/ygo4vp291q1zz9g9bu6u.png" alt="Alt Text"></p>

<p>If you want to inspect a slice of the data within a Base, you can use <a href="https://docs.deta.sh/docs/base/sdk#queries">Base’s queries</a> to do so, i.e.:</p>

<pre><code>[{"cuisine": "Italian", "have_visited": false}]
</code></pre>

<p><img src="https://dev-to-uploads.s3.amazonaws.com/i/qv2mz4uniqjlv0fcu0ky.png" alt="Alt Text"></p>

<h3 id="adding-records">Adding Records</h3>

<p>To add records to a base, click the ‘<strong>+ Add</strong>’ button and a new row will appear at the top of your Base’s UI.</p>

<p><img src="https://dev-to-uploads.s3.amazonaws.com/i/n184adeun585uvpr9k27.png" alt="Alt Text"></p>

<p>The new row will be treated as a candidate edit, with a yellow background, which can be permanently saved by clicking the ‘<strong>Save</strong>’ button.</p>

<h3 id="modifying-records">Modifying Records</h3>

<p>For primitive types (strings, booleans, and numbers), you can modify any record directly from within a cell.</p>

<p>For advanced editing, i.e. to change the type of a given value, or edit arrays or objects, you can expand the cell and do so.</p>

<p><img src="https://dev-to-uploads.s3.amazonaws.com/i/pom71tzotlie0s865n7i.png" alt="Alt Text"></p>

<p>Once you are satisfied with your edits, simply click the ‘<strong>Save Edits</strong>’ button, as before, to modify these records in your Base. If you want to discard all your edits locally, click ‘<strong>Undo Changes</strong>’.</p>

<h3 id="deleting-records">Deleting Records</h3>

<p>For every record displayed in Base UI, there is a checkbox on the left side. By clicking the checkbox, the record will be highlighted in red as a delete candidate. To go forward with the deletion, simply click the ‘<strong>Delete</strong>’ item.</p>

<p><img src="https://dev-to-uploads.s3.amazonaws.com/i/sootikirv2s5cmz0xj3o.png" alt="Alt Text"></p>

<p>For candidate adds, edits, and deletes, the ‘<strong>Undo</strong>’ button will revert the Base Guide to the state that was last pulled.</p>

<h3 id="start-with-base-guide-today">Start with Base Guide Today</h3>

<p>To get started with Base Guide, simply <a href="https://web.deta.sh/">log-in / sign-up</a> with Deta, grab a project key, and create a <a href="https://docs.deta.sh/docs/base/sdk">Deta Base</a> in your Python or Node.js app. Deta Guide will be accessible for any Base you create.</p>

<h3 id="tour">Tour</h3>


<p>
  <iframe src="https://www.youtube.com/embed/y11dOkP8ZTI" allowfullscreen="" title="YouTube Video"></iframe>
</p>


<h3 id="thanks">Thanks</h3>

<p>We’d love to thank the Deta community for the incredible feedback that led to this initiative as well as Samarth Jajoo for the initial implementation which we built on top of!</p>

</article></div>]]>
            </description>
            <link>https://blog.deta.sh/posts/base_guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24640669</guid>
            <pubDate>Wed, 30 Sep 2020 16:41:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Love Is the Only Antidote to Fear: A Lecture by John O'Donohue]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24640573">thread link</a>) | @sbuccini
<br/>
September 30, 2020 | https://www.stevenbuccini.com/love-is-the-only-antidote-to-fear | <a href="https://web.archive.org/web/*/https://www.stevenbuccini.com/love-is-the-only-antidote-to-fear">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <blockquote>
  <p>“It’s an old-fashioned thing to say, but I think that occasions of fear are invitations for freedom and for courage.”<br>
<em>—John O’Donohue</em></p>
</blockquote>

<p>It was just before Thanksgiving in 2017 and I was scared. The enormity of the decision I had just made – to leave behind 5 years worth of memories, friendships, and professional networks on the opposite side of the country to move home and run for office – was finally hitting home. I was lonely and afraid. So I decided to drive down to Durham to meet up with a close high school friend I hadn’t seen in a long, long time. After a couple of beers, I confessed my anxiousness. She recommended <a href="https://drive.google.com/open?id=1RpKTUDIhXlfXdoZXqt3gBlY0Zvy4_EZY">a lecture by an Irish thinker named John O’Donohue, specifically “Love is the Only Antidote to Fear”</a>. The words hit me like a thunderbolt. Ever since then, whenever I am weighing the pros and cons of a big decision, I make sure to re-listen to this talk.</p>

<p>These are confusing, chaotic, and uncertain times. It is natural to be afraid. I hope this lecture provides some level of comfort to you, just as it has for me throughout the years.</p>

<p>NB: I highly, highly recommend <em>listening</em> to this talk. <a href="https://drive.google.com/open?id=1RpKTUDIhXlfXdoZXqt3gBlY0Zvy4_EZY">You can find the link here</a>. O’Donohue is a noted lecturer for a reason, and it’s clear when you hear his highly conversational style in a Celtic lilt that those skills were honed at a lecturn during his years as a parish priest. However, if you prefer to read the text, I have transcribed it below.</p>

<hr>



<p><em>This text has been lightly edited to improve the flow while reading. I fed the recording through Descript to generate the original transcript, and then attempted to manually clean it up as I best I could. Transcription errors may remain. If you have suggestions or corrections, please email me.</em></p>

<p>Something that everyone has in common is the experience of fear, and the power of the presence of fear. There is no one that could say that they’re not afraid of something. Fear is present in every heart, and science and cultural studies show us that we’re right to be afraid to a level of about 10% in our experience that that corresponds with what’s actually the situation, but that 90% of the fear that we have is unreal. And that’s the haunting loneliness and incredible wastage of what fear does to the human heart.</p>

<p>Fear is the greatest trickster of all. It makes what is real seem unreal and it makes the unreal, real. I always think from nature that the most telling image to correspond to fear is fog. If you’ve ever been out in the mountains and you’ve got caught in fog, you’ll know what I’m talking about. Several years ago, in the mountains at home in the west of Ireland that I know very well, I brought a friend from Manchester for a day on the mountains. And about two hours up in the mountains, the fog came down. I know these mountains really well and we kept going because I told her that I knew where I was going. And about four hours later, we found ourselves exactly back in the place where we were on the fog came down, not knowing where we were. Eventually we got down off the mountains because I was able to hear the ocean and we went in that direction. But that’s what fear does. And your normal experience is that it inflates things and makes something that’s fairly small very, very huge.</p>

<p>Some years ago, I was talking to a friend of mine who is into psychology and psychotherapy about fear. He said that something that he found very helpful when he was afraid was to hold on to one question and stick with it. And the question is to ask yourself, “What is it, exactly, that I’m afraid of?” If you hold to this question, gradually what seems huge and amorphous and beyond your control begins to shrink right down to one moment, one thing that you can actually deal with and handle.</p>

<p>Part of the reason that fear has such power over us is we are vulnerable, and fear draws great strength from time. If you wake up one Monday morning and you realize that on the next Friday that you have something horrible waiting for you, the chances are that your days on Monday, Tuesday, Wednesday, and Thursday will be totally shadowed by the threat of Friday, and you waste four lovely days because the fear of what’s waiting for you robs you of the beauty of the days that you have.
Something that I try to do myself when I’m afraid is to sit myself down, and on an empty chair opposite me I’d imagine the thing (or person or situation or whatever) that I was afraid of. Then I’d say to myself, “Let’s do it now. Instead of being miserable about it, let’s have a blast at it.” And then I would imagine, I’d say to myself, “What’s the worst thing that could happen in this situation?” And I’d think about it until I realize what the worst thing was and then I would force myself to imagine all the elements of the worst aspect of it. And then by the time the situation actually arrives, it isn’t too bad at all. You’ll be incredibly relieved cause it’s never as bad as you thought!</p>

<p>One of the questions that’s always haunted me is what is the origin of fear? Why are humans afraid? One of the reasons is that the place we live in the world is in this clay tent of the human body. And it’s a very vulnerable old tent. Because once you’re in a body, you’re always somewhere. You can never successfully hide and you can always be gotten to. You know, like in some of these mafia films, when they go off for a while but somebody always turns up nearly and gets to them? It’s the same thing, but in a human life.</p>

<p>The other thing is that the way that we interpret the world is an incredibly painful and broken and tender way through birth, which was separation. And I always think that humans are really able for anything after successfully coming through the trauma of being born. Because it was loss, separation, alienation. I mean, I often think that’s an image I often use for myself in relation to death. Maybe we have death all wrong because we always think of it as an ending, as closure. A quenching.
But say you turn it the other way around. Say you conducted an interview with the baby in the womb before it was born. And say was a real “with it” baby, the kind that wanted to know what’s going down and you said:</p>

<p>“Okay, baby, you asked for it. You’re going to get it. Here’s the story. In a half an hour you will be expelled from the shelter of the womb where you have emerged and been formed. Secondly, you will come out along a passage (and we all did this) where you will feel that every moment you’re being smothered. Thirdly, you will arrive out into a huge vacancy, probably with merciless light in it. Fourthly, the cord that connects you to the mother heart will be cut. Fifthly, regardless of how close you ever come to anyone in your life afterwards, you will always be on your own. Sixthly, you’re going on a journey for which there is no map. And seventhly, you can’t turn back and eighth, anything can happen to you on the journey.”
Now, if the baby was still breathing at that stage, it would have to conclude, “Jesus, things were really nice and good here and now it looks like I’m going to die,” when in actual fact what’s happening is that has been born. And my suspicion in relation to death is that we only see all the destructive side of it, and that possibly, (I’ll address this bit tomorrow and my talk on beauty), that what’s happening actually in death is that we’re being born again. This time, in a way that the loneliness of space and time no longer has a hold over us.</p>

<p>But I think that if you were to ask, “What is the root of all fear?” the root of all fear is in the fear of death. And I have an old suspicion that if you sort out your fear of death as the worst thing – not something that just might happen to you but that IS going to happen to you – then you remove the soil and the nutrient that nourishes your normal fears.</p>

<p>I used to be very afraid of dying for a long time in my life. And then I became a Roman Catholic priest. And in my years as a priest, one of the immense privileges was to help people to die. And early on in my priesthood there was this woman that I knew. She was a lovely woman, 27 years old. She was a traveler, one of the gypsy people, and she had two children and she was pregnant with a third child when she got leukemia. She was being treated for it though, and it seemed to be working. I was visiting her once a week, and one evening I went in to see her and I was going to give her a hug and she said, “Don’t hug me, I’m bleeding.” And it turned out that the treatment wasn’t working. About four nights later, in the middle of the night, there was a knock at the door of my house. Her family was there and they said, “We’ve got news from the hospital that she’s really bad and we need to go in.” So I talked to the father and mother, and then they all came with their vans and we all went into the hospital. And as soon as I came in the hospital door, I saw the young woman on all these machines and tubes and everything. And she looked up at me, the poor pet, and she said, “Am I going to die?” And I said, “I don’t know whether you’re going to die or not. But when I do, I will tell you.” She said, “Okay.” So then everybody arrived and all the rest of it, and about 4:15 in the morning, she said to me, “Will you open the window?” And something told me that she was going to die. So I went out and I met the house doctor who was on duty and I said, “What’s the story here?” He said, “At 7:30, we are going to bring our downstairs and try one more procedure. But, in actual fact, we expect her to be dead by 10.” So I went back into the room and I said that I wanted some time on my own with her. All the family left and I sat down. I took her hand.</p>

<p>“You’re going to die,” is one of the most awful sentences any human being can ever hear, no matter how sick you are. Sometimes we think when people are sick that they know what’s coming, but they don’t. Because language is an incredible presence. There are some words that are said that are like …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.stevenbuccini.com/love-is-the-only-antidote-to-fear">https://www.stevenbuccini.com/love-is-the-only-antidote-to-fear</a></em></p>]]>
            </description>
            <link>https://www.stevenbuccini.com/love-is-the-only-antidote-to-fear</link>
            <guid isPermaLink="false">hacker-news-small-sites-24640573</guid>
            <pubDate>Wed, 30 Sep 2020 16:33:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Eltrot, a web app to have structured debates with results]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24640470">thread link</a>) | @jandehaan
<br/>
September 30, 2020 | https://about.eltrot.com/en/ | <a href="https://web.archive.org/web/*/https://about.eltrot.com/en/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <h2>When might I use this?</h2>

            <p>When medium-sized groups (10 to 100 people) have to make decisions, it can be a lot of work to make
                sure that everyone gets the opportunity to voice their opinion. You could get everyone gathered in a
                room (not a good idea at the moment) to present arguments and then have a vote, but that is in most
                cases only feasible for a few issues that are deemed to be the most important.</p>

            <p>Asynchronous communication-tools such as instant-messaging groups lower the barrier to having a
                discussion,
                but their complete lack of structure makes it difficult for a decision to be reached, and
                participation
                is
                in most cases
                limited to a passionate few, leaving either the decision or, if a poll is conducted afterwards, the
                choices, without sufficient legitimacy.</p>

            <p>Eltrot is supposed to be the better choice in these situations.</p>
        </div><div>
            <h2>Why are votes not secret?</h2>

            <p>Preferential voting systems are not compatible with secret voting: You would only need 10 answers for
                there
                to be vastly more possible rankings than voters, enabling voters to identify themselves.</p>

            <p>Even when you ignore this problem, electronic voting is difficult or even impossible to get right. Making
                votes public ensures the system is not used when the stakes are too high. If the stakes are high enough
                to
                require secret voting, I recommend using paper ballots.</p>
            
        </div></div>]]>
            </description>
            <link>https://about.eltrot.com/en/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24640470</guid>
            <pubDate>Wed, 30 Sep 2020 16:25:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Brief History of Neural Nets and Deep Learning]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24640259">thread link</a>) | @andreyk
<br/>
September 30, 2020 | https://www.skynettoday.com/overviews/neural-net-history | <a href="https://web.archive.org/web/*/https://www.skynettoday.com/overviews/neural-net-history">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h2 id="prologue-the-deep-learning-tsunami">Prologue: The Deep Learning Tsunami</h2>

<blockquote>
  <p>“Deep Learning waves have lapped at the shores of computational linguistics for several years now, but 2015 seems like the year when the full force of the tsunami hit the major Natural Language Processing (NLP) conferences.” -<a href="http://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00239">Dr. Christopher D. Manning, Dec 2015</a> <sup id="fnref:part1_1" role="doc-noteref"><a href="#fn:part1_1">1</a></sup></p>
</blockquote>

<p>This may sound hyperbolic - to say the established methods of an entire field of research are quickly being superseded by a new discovery, as if hit by a research ‘tsunami’. But, this catastrophic language is appropriate for describing the meteoric rise of Deep Learning over the last several years - a rise characterized by drastic improvements over reigning approaches towards the hardest problems in AI, massive investments from industry giants such as Google, and exponential growth in research publications (and Machine Learning graduate students). Having taken several classes on Machine Learning, and even used it in undergraduate research, I could not help but wonder if this new ‘Deep Learning’ was anything fancy or just a scaled up version of the ‘artificial neural nets’ that were already developed by the late 80s. And let me tell you, the answer is quite a story - the story of not just neural nets, not just of a sequence of research breakthroughs that make Deep Learning somewhat more interesting than ‘big neural nets’  (that I will attempt to explain in a way that just about anyone can understand), but most of all of how several unyielding researchers made it through dark decades of banishment to finally redeem neural nets and achieve the dream of Deep Learning.</p>


<blockquote><p id="sources">
I am certainly not a foremost expert on this topic. In depth technical overviews with long lists of references written by those who actually made the field what it is include Yoshua Bengio's <a href="http://www.iro.umontreal.ca/~lisa/pointeurs/TR1312.pdf">"Learning Deep Architectures for AI"</a>, Jürgen Schmidhuber's <a href="http://arxiv.org/pdf/1404.7828v4.pdf">"Deep Learning in Neural Networks: An Overview"</a> and LeCun et al.s' <a href="http://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf">"Deep learning"</a>. In particular, this is mostly a history of research in the US/Canada AI community, and even there will not mention many researchers; a particularly in depth history of the field that covers these omissions is Jürgen Schmidhuber's <a href="http://people.idsia.ch/~juergen/deep-learning-overview.html">"Deep Learning in Neural Networks: An Overview"</a>. I am also most certainly not a professional writer, and will cop to there being shorter and much less technical overviews written by professional writers such as Paul Voosen's <a href="http://chronicle.com/article/The-Believers/190147">"The Believers"</a>, John Markoff's <a href="http://www.nytimes.com/2012/11/24/science/scientists-see-advances-in-deep-learning-a-part-of-artificial-intelligence.html">"Scientists See Promise in Deep-Learning Programs"</a> and Gary Marcus's <a href="http://www.newyorker.com/news/news-desk/is-deep-learning-a-revolution-in-artificial-intelligence">"Is “Deep Learning” a Revolution in Artificial Intelligence?"</a>. I also will stay away from getting too technical here, but there is a plethora of tutorials on the internet on all the major topics covered in brief by me.
<br>
Any corrections would be appreciated, though I will note some ommisions are intentional since I want to try and keep this 'brief' and a good mix of simple technical explanations and storytelling. 
<br>
This piece is an updated and expanded version of blog posts originally released in 2015 on www.andreykurenkov.com. 
</p></blockquote>

<ul id="markdown-toc">
  <li><a href="#prologue-the-deep-learning-tsunami" id="markdown-toc-prologue-the-deep-learning-tsunami">Prologue: The Deep Learning Tsunami</a></li>
  <li><a href="#part-1-the-beginnings-1950s-1980s" id="markdown-toc-part-1-the-beginnings-1950s-1980s">Part 1: The Beginnings (1950s-1980s)</a>    <ul>
      <li><a href="#the-centuries-old-machine-learning-algorithm" id="markdown-toc-the-centuries-old-machine-learning-algorithm">The Centuries Old Machine Learning Algorithm</a></li>
      <li><a href="#the-folly-of-false-promises" id="markdown-toc-the-folly-of-false-promises">The Folly of False Promises</a></li>
      <li><a href="#the-thaw-of-the-ai-winter" id="markdown-toc-the-thaw-of-the-ai-winter">The Thaw of the AI Winter</a></li>
    </ul>
  </li>
  <li><a href="#part-2-neural-nets-blossom-1980s-2000s" id="markdown-toc-part-2-neural-nets-blossom-1980s-2000s">Part 2: Neural Nets Blossom (1980s-2000s)</a>    <ul>
      <li><a href="#neural-nets-gain-vision" id="markdown-toc-neural-nets-gain-vision">Neural Nets Gain Vision</a></li>
      <li><a href="#neural-nets-go-unsupervised" id="markdown-toc-neural-nets-go-unsupervised">Neural Nets Go Unsupervised</a></li>
      <li><a href="#neural-nets-gain-beliefs" id="markdown-toc-neural-nets-gain-beliefs">Neural Nets Gain Beliefs</a></li>
      <li><a href="#neural-nets-make-decisions" id="markdown-toc-neural-nets-make-decisions">Neural Nets Make Decisions</a></li>
      <li><a href="#neural-nets-get-loopy" id="markdown-toc-neural-nets-get-loopy">Neural Nets Get Loopy</a></li>
      <li><a href="#neural-nets-start-to-speak" id="markdown-toc-neural-nets-start-to-speak">Neural Nets Start to Speak</a></li>
      <li><a href="#a-new-winter-dawns" id="markdown-toc-a-new-winter-dawns">A New Winter Dawns</a></li>
    </ul>
  </li>
  <li><a href="#part-3-deep-learning-2000s-2010s" id="markdown-toc-part-3-deep-learning-2000s-2010s">Part 3: Deep Learning (2000s-2010s)</a>    <ul>
      <li><a href="#the-funding-of-more-layers" id="markdown-toc-the-funding-of-more-layers">The Funding of More Layers</a></li>
      <li><a href="#the-development-of-big-data" id="markdown-toc-the-development-of-big-data">The Development of Big Data</a></li>
      <li><a href="#the-importance-of-brute-force" id="markdown-toc-the-importance-of-brute-force">The Importance of Brute Force</a></li>
      <li><a href="#the-deep-learning-equation" id="markdown-toc-the-deep-learning-equation">The Deep Learning Equation</a></li>
    </ul>
  </li>
  <li><a href="#epilogue-the-decade-of-deep-learning" id="markdown-toc-epilogue-the-decade-of-deep-learning">Epilogue: The Decade of Deep Learning</a></li>
</ul>


<p>The beginning of a story spanning half a century, about how we learned to make computers learn. In this part, we shall cover the birth of neural nets with the Perceptron in 1958, the AI Winter of the 70s, and neural nets’ return to popularity with backpropagation in 1986.</p>

<h2 id="the-centuries-old-machine-learning-algorithm">The Centuries Old Machine Learning Algorithm</h2>
<figure>
    <img src="https://www.skynettoday.com/assets/img/overviews/2020-09-27-a-brief-history-of-neural-nets-and-deep-learning/Linear_regression.svg" alt="Linear Regression">     
    <figcaption>Linear regression <a href="https://upload.wikimedia.org/wikipedia/commons/3/3a/Linear_regression.svg">(Source)</a></figcaption>
</figure>

<p>Let’s start with a brief primer on what Machine Learning is. Take some points on a 2D graph, and draw a line that fits them as well as possible. What you have just done is generalized from a few example of pairs of input values (x) and output values (y) to a general function that can map any input value to an output value. This is known as linear regression, and it is a wonderful little <a href="https://en.wikipedia.org/wiki/Linear_regression#cite_note-4">200 year old</a> technique for extrapolating a general function from some set of input-output pairs. And here’s why having such a technique is wonderful: there is an incalculable number of functions that are hard to develop equations for directly, but are easy to collect examples of input and output pairs for in the real world - for instance, the function mapping an input of recorded audio of a spoken word to an output of what that spoken word is.</p>

<p>Linear regression is a bit too wimpy a technique to solve the problem of speech recognition, but what it does is essentially what <strong>supervised Machine Learning</strong> is all about: ‘learning’ a function given a <strong>training set</strong> of <strong>examples</strong>, where each example is a pair of an input and output from the function (we shall touch on the unsupervised flavor in a little while). In particular, machine learning methods should derive a function that can generalize well to inputs not in the training set, since then we can actually apply it to inputs for which we do not have an output. For instance, Google’s current speech recognition technology is powered by Machine Learning with a massive training set, but not nearly as big a training set as all the possible speech inputs you might task your phone with understanding.</p>

<p>This generalization principle is so important that there is almost always a <strong>test set</strong> of data (more examples of inputs and outputs) that is not part of the training set. The separate set can be used to evaluate the effectiveness of the machine learning technique by seeing how many of the examples the method correctly computes outputs for given the inputs. The nemesis of generalization is <strong>overfitting</strong> - learning a function that works really well for the training set but badly on the test set. Since machine learning researchers needed means to compare the effectiveness of their methods, over time there appeared standard <strong>datasets</strong> of training and testing sets that could be used to evaluate machine learning algorithms.</p>

<p>Okay okay, enough definitions. Point is - our line drawing exercise is a very simple example of supervised machine learning: the points are the training set (X is input and Y is output), the line is the approximated function, and we can use the line to find Y values for X values that don’t match any of the points we started with. Don’t worry, the rest of this history will not be nearly so dry as all this. Here we go.</p>

<h2 id="the-folly-of-false-promises">The Folly of False Promises</h2>

<p>Why have all this prologue with linear regression, since the topic here is ostensibly neural nets? Well, in fact linear regression bears some resemblance to the first idea conceived specifically as a method to make machines learn: <a href="http://psycnet.apa.org/index.cfm?fa=buy.optionToBuy&amp;id=1959-09865-001">Frank Rosenblatt’s <strong>Perceptron</strong></a><sup id="fnref:part1_2" role="doc-noteref"><a href="#fn:part1_2">2</a></sup>.</p>
<figure>
    <img src="https://www.skynettoday.com/assets/img/overviews/2020-09-27-a-brief-history-of-neural-nets-and-deep-learning/34998.jpg" alt="Perceptron">
    <figcaption>A diagram showing how the Perceptron works. <a href="http://cse-wiki.unl.edu/wiki/images/0/0f/Perceptron.jpg">(Source)</a></figcaption>    
</figure>

<p>A psychologist, Rosenblatt conceived of the Percetron as a simplified mathematical model of how the neurons in our brains operate: it takes a set of binary inputs (nearby neurons), multiplies each input by a continuous valued weight (the synapse strength to each nearby neuron), and thresholds the sum of these weighted inputs to output a 1 if the sum is big enough and otherwise a 0 (in the same way neurons either fire or do not). Most of the inputs to a Perceptron are either some data or the output of another Perceptron, but an extra detail is that Perceptrons also have one special ‘bias’ input, which just has a value of 1 and basically ensures that more functions are computable with the same input by being able to offset the summed value. This model of the neuron built on the work of Warren McCulloch and Walter Pitts <a href="http://www.minicomplexity.org/pubs/1943-mcculloch-pitts-bmb.pdf">Mcculoch-Pitts</a><sup id="fnref:part1_3" role="doc-noteref"><a href="#fn:part1_3">3</a></sup>, who showed that a neuron model that sums binary inputs and outputs a 1 if the sum exceeds a certain threshold value, and otherwise outputs a 0, can model the basic OR/AND/NOT functions. This, in the early days of AI, was a big deal - the predominant thought at the time was that making computers able to perform formal logical reasoning would essentially solve AI.</p>

<figure>
    <img src="https://www.skynettoday.com/assets/img/overviews/2020-09-27-a-brief-history-of-neural-nets-and-deep-learning/34832.jpg" alt="Perceptron 2"> 
    <figcaption>Another diagram, showing the biological inspiration. The <b>activation function</b> is what people now call the non-linear function applied to the weighted input sum to produce the output of the artificial neuron - in the case of Rosenblatt's Perceptron, the function just a thresholding operation.  <a href="http://cs231n.github.io/neural-networks-1/">(Source)</a> </figcaption>    
</figure>

<p>However, the Mcculoch-Pitts model lacked a mechanism for learning, which was crucial for it to be usable for AI. This is where the Perceptron excelled - Rosenblatt came up with a way to make such artificial neurons learn, inspired by the <a href="http://onlinelibrary.wiley.com/doi/10.1002/cne.900930310/abstract">foundational work</a><sup id="fnref:part1_4" role="doc-noteref"><a href="#fn:part1_4">4</a></sup> of Donald Hebb. Hebb put forth the unexpected and hugely influential idea that knowledge and learning occurs in the brain primarily through the formation and change of synapses between neurons - concisely stated as Hebb’s Rule:</p>

<blockquote>
  <p>“When an axon of cell A is near enough to excite a cell B and repeatedly or persistently takes part in firing it, some growth process or metabolic change takes place in one or both cells such that A’s efficiency, as one of the cells firing B, is increased.”</p>
</blockquote>

<p>The Perceptron did not follow this idea exactly, but having weights on the inputs allowed for a very simple and intuitive learning scheme: given a <strong>training set</strong> of input-output examples the Perceptron should ‘learn’ a function from, for each example increase the weights if the Perceptron output for that example’s input is too low compared to the example, and otherwise decrease the weights if the output is too high. Stated ever so slightly more formally, the algorithm is as follows:</p>

<ol>
  <li>Start off with a Perceptron having random weights and a training set</li>
  <li>For the inputs of an example in the …</li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.skynettoday.com/overviews/neural-net-history">https://www.skynettoday.com/overviews/neural-net-history</a></em></p>]]>
            </description>
            <link>https://www.skynettoday.com/overviews/neural-net-history</link>
            <guid isPermaLink="false">hacker-news-small-sites-24640259</guid>
            <pubDate>Wed, 30 Sep 2020 16:07:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Watching Your iPhone Work to Protect You from Covid-19]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24640216">thread link</a>) | @josephby
<br/>
September 30, 2020 | https://joseph.by/2020/09/30/watching-your-iphone-work-to-protect-you-from-covid-19/ | <a href="https://web.archive.org/web/*/https://joseph.by/2020/09/30/watching-your-iphone-work-to-protect-you-from-covid-19/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
	<p><a href="#content">Skip to content</a></p><!-- #masthead -->

	
	<div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-636">

	

	
			<figure>
				<img width="1568" height="1153" src="https://josephby873743584.files.wordpress.com/2020/09/pexels-photo-699122.jpeg?w=1568" alt="" loading="lazy" srcset="https://josephby873743584.files.wordpress.com/2020/09/pexels-photo-699122.jpeg?w=1568 1568w, https://josephby873743584.files.wordpress.com/2020/09/pexels-photo-699122.jpeg?w=150 150w, https://josephby873743584.files.wordpress.com/2020/09/pexels-photo-699122.jpeg?w=300 300w, https://josephby873743584.files.wordpress.com/2020/09/pexels-photo-699122.jpeg?w=768 768w, https://josephby873743584.files.wordpress.com/2020/09/pexels-photo-699122.jpeg?w=1024 1024w, https://josephby873743584.files.wordpress.com/2020/09/pexels-photo-699122.jpeg 1768w" sizes="(max-width: 1568px) 100vw, 1568px" data-attachment-id="657" data-permalink="https://joseph.by/2020/09/30/watching-your-iphone-work-to-protect-you-from-covid-19/pexels-photo-699122/" data-orig-file="https://josephby873743584.files.wordpress.com/2020/09/pexels-photo-699122.jpeg" data-orig-size="1768,1300" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="pexels-photo-699122.jpeg" data-image-description="" data-medium-file="https://josephby873743584.files.wordpress.com/2020/09/pexels-photo-699122.jpeg?w=300" data-large-file="https://josephby873743584.files.wordpress.com/2020/09/pexels-photo-699122.jpeg?w=750">			</figure><!-- .post-thumbnail -->

		
	<div>
		
<p>Much has been written about the Apple + Google Covid-19 Exposure Notification framework. This is the software that is now part of Android and iOS (13.5+) and powers Covid-19 detection apps for Android and iPhone like COVID Alert (much of Canada), COVIDWISE (Virginia) and <a href="https://www.xda-developers.com/google-apple-covid-19-contact-tracing-exposure-notifications-api-app-list-countries/">dozens of other jurisdictions around the world</a> .</p>



<p>I’m in Ontario and use COVID Alert on my iPhone 8 Plus. The apps are fantastic pieces of work from the Canadian Digital Service and its private sector partners Shopify and BlackBerry. That said, I have always wished for more feedback from the app itself. Something that gives me a sense of it actually working. I’m the first to admit that this isn’t a rational need. When you open COVID Alert here is what you see:</p>



<figure><img loading="lazy" data-attachment-id="643" data-permalink="https://joseph.by/covid-alert-screen-shot-1/" data-orig-file="https://josephby873743584.files.wordpress.com/2020/09/covid-alert-screen-shot-1.jpg" data-orig-size="1242,2148" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="covid-alert-screen-shot-1" data-image-description="" data-medium-file="https://josephby873743584.files.wordpress.com/2020/09/covid-alert-screen-shot-1.jpg?w=173" data-large-file="https://josephby873743584.files.wordpress.com/2020/09/covid-alert-screen-shot-1.jpg?w=592" src="https://josephby873743584.files.wordpress.com/2020/09/covid-alert-screen-shot-1.jpg?w=592" alt="" width="296" height="512" srcset="https://josephby873743584.files.wordpress.com/2020/09/covid-alert-screen-shot-1.jpg?w=592 592w, https://josephby873743584.files.wordpress.com/2020/09/covid-alert-screen-shot-1.jpg?w=296 296w, https://josephby873743584.files.wordpress.com/2020/09/covid-alert-screen-shot-1.jpg?w=87 87w, https://josephby873743584.files.wordpress.com/2020/09/covid-alert-screen-shot-1.jpg?w=173 173w" sizes="(max-width: 296px) 100vw, 296px"><figcaption>Great! You’re active! But what does that mean?</figcaption></figure>



<p>I’m grateful that no exposure has been detected! But the app doesn’t <em>look</em> like it’s doing anything. I know that that’s not the case. I know that it is doing stuff but that’s because I’m a nerd and because the Canadian Digital Service maintains the source for both the Android and iPhone COVID Alert apps <a href="https://github.com/cds-snc/covid-alert-app.">on GitHub</a> .</p>



<h2>But how can I see it actually doing stuff?</h2>



<p>Well here’s one way. Both iPhone and Android allow you to see a log <a href="https://www.canada.ca/en/public-health/services/diseases/coronavirus-disease-covid-19/covid-alert/help.html#13">showing each time COVID Alert has downloaded a list of exposures</a> from the COVID Alert server.</p>



<p>On iPhone you can see the log in Settings -&gt; Exposure Notifications -&gt; Exposure Logging Status -&gt; Exposure Checks . </p>



<figure><ul data-carousel-extra="{&quot;blog_id&quot;:181459260,&quot;permalink&quot;:&quot;https:\/\/joseph.by\/2020\/09\/30\/watching-your-iphone-work-to-protect-you-from-covid-19\/&quot;}"><li><figure><img data-attachment-id="648" data-permalink="https://joseph.by/img_1696/" data-orig-file="https://josephby873743584.files.wordpress.com/2020/09/img_1696.jpg" data-orig-size="1242,2148" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_1696" data-image-description="" data-medium-file="https://josephby873743584.files.wordpress.com/2020/09/img_1696.jpg?w=173" data-large-file="https://josephby873743584.files.wordpress.com/2020/09/img_1696.jpg?w=592" src="https://josephby873743584.files.wordpress.com/2020/09/img_1696.jpg?w=592" alt="" data-id="648" data-link="https://joseph.by/img_1696/" srcset="https://josephby873743584.files.wordpress.com/2020/09/img_1696.jpg?w=592 592w, https://josephby873743584.files.wordpress.com/2020/09/img_1696.jpg?w=1184 1184w, https://josephby873743584.files.wordpress.com/2020/09/img_1696.jpg?w=87 87w, https://josephby873743584.files.wordpress.com/2020/09/img_1696.jpg?w=173 173w, https://josephby873743584.files.wordpress.com/2020/09/img_1696.jpg?w=768 768w" sizes="(max-width: 592px) 100vw, 592px"><figcaption>A log of every time COVID Alert downloaded new exposures</figcaption></figure></li><li><figure><img data-attachment-id="647" data-permalink="https://joseph.by/img_1697/" data-orig-file="https://josephby873743584.files.wordpress.com/2020/09/img_1697.jpg" data-orig-size="1242,2148" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_1697" data-image-description="" data-medium-file="https://josephby873743584.files.wordpress.com/2020/09/img_1697.jpg?w=173" data-large-file="https://josephby873743584.files.wordpress.com/2020/09/img_1697.jpg?w=592" src="https://josephby873743584.files.wordpress.com/2020/09/img_1697.jpg?w=592" alt="" data-id="647" data-link="https://joseph.by/img_1697/" srcset="https://josephby873743584.files.wordpress.com/2020/09/img_1697.jpg?w=592 592w, https://josephby873743584.files.wordpress.com/2020/09/img_1697.jpg?w=1184 1184w, https://josephby873743584.files.wordpress.com/2020/09/img_1697.jpg?w=87 87w, https://josephby873743584.files.wordpress.com/2020/09/img_1697.jpg?w=173 173w, https://josephby873743584.files.wordpress.com/2020/09/img_1697.jpg?w=768 768w" sizes="(max-width: 592px) 100vw, 592px"><figcaption>A single log entry</figcaption></figure></li><li><figure><img data-attachment-id="646" data-permalink="https://joseph.by/img_1698/" data-orig-file="https://josephby873743584.files.wordpress.com/2020/09/img_1698.jpg" data-orig-size="1227,2121" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_1698" data-image-description="" data-medium-file="https://josephby873743584.files.wordpress.com/2020/09/img_1698.jpg?w=174" data-large-file="https://josephby873743584.files.wordpress.com/2020/09/img_1698.jpg?w=592" src="https://josephby873743584.files.wordpress.com/2020/09/img_1698.jpg?w=592" alt="" data-id="646" data-link="https://joseph.by/img_1698/" srcset="https://josephby873743584.files.wordpress.com/2020/09/img_1698.jpg?w=592 592w, https://josephby873743584.files.wordpress.com/2020/09/img_1698.jpg?w=1184 1184w, https://josephby873743584.files.wordpress.com/2020/09/img_1698.jpg?w=87 87w, https://josephby873743584.files.wordpress.com/2020/09/img_1698.jpg?w=174 174w, https://josephby873743584.files.wordpress.com/2020/09/img_1698.jpg?w=768 768w" sizes="(max-width: 592px) 100vw, 592px"><figcaption>Details for that exposure download event; COVID Alert received 246 IDs representing devices associated with a positive test. </figcaption></figure></li></ul></figure>



<p>What I believe this means is that in that one Exposure Check done at 10:09am ET COVID Alert downloaded 246 Tracing Keys (“device IDs”) of devices that had had a positive Covid-19 test reported over the past 14 days. It also determined that my iPhone did not get close enough to any of those phones, for a long enough period of time, to warrant me getting a Covid-19 test. It’s pretty cool to see the app at work.</p>



<h2>What else could it do?</h2>



<p>I would also love the app to help me understand:</p>



<ol><li><strong>How risky is my current behaviour?</strong><br>How many devices did my phone see in the past 24 hours? How many rolling proximity identifiers (RPIDs) did my phone log? I know that you are not supposed to be able to derive a Tracing Key from an RPID, but could the system run a function over a set of RPIDs and estimate the number of unique Tracing Keys they represent?<br></li><li><strong>How effective is the app at warning people about potential exposure?</strong><br>We had 625 new cases of Covid-19 reported yesterday in Ontario. How does that compare to the 246 Tracing Keys my phone received? Do the time frames line up? Can I compare them? <strong>What’s the effective penetration of the app?</strong></li></ol>



<h2>Closing thoughts</h2>



<p>You can’t tech your way out of a policy or political problem. That said, I strongly agree with the what Apple, Google, and the Government of Canada have done here. If the policy decision is to continue to deploy these decentralized, anonymous exposure notification applications on a voluntary basis then we need to keep looking for ways to make them more effective and more compelling to download and use. Sharing more useful information with people could be a way to get more people to use the app and better inform public health authorities on what to do next.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div><!-- #content -->

		<!-- #colophon -->

</div></div>]]>
            </description>
            <link>https://joseph.by/2020/09/30/watching-your-iphone-work-to-protect-you-from-covid-19/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24640216</guid>
            <pubDate>Wed, 30 Sep 2020 16:05:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On the pervasive presence of military language elements in computer security]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24640198">thread link</a>) | @dijit
<br/>
September 30, 2020 | https://dustri.org/b/on-the-pervasive-presence-of-military-language-elements-in-computer-security.html | <a href="https://web.archive.org/web/*/https://dustri.org/b/on-the-pervasive-presence-of-military-language-elements-in-computer-security.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<section id="content">
  <article>
    <header>
      
    </header>

    <div>
      <p>As I was writing an article for the first edition of <a href="https://pagedout.institute/">Paged Out</a>,
I had an interesting (albeit too short) conversation regarding
its <a href="https://pagedout.institute/download/PagedOut_001_wallpaper_30.png">cover</a>
with <a href="https://gynvael.coldwind.pl/?id=50">Gynvael Coldwind</a>.
Drawn by <a href="https://www.deviantart.com/refiend">ReFiend</a>, it
features two people on the foreground, wielding what looks like guns.
This lead to a discussion on the omnipresence of military jargon, and thus violence,
in the world of computer security. I told him that I'll publish a blogpost 
to correctly articulate my thoughts on the topic, instead of the incoherent
rambling that I served him.</p>
<p>At every single security conference, there is someone with a direct quote of
the <a href="https://en.wikipedia.org/wiki/The_Art_of_War">Art of War</a> on their slide
deck, and there is a metric fuckton of assorted military-inspired bullshit
terms for almost everything: <a href="http://www.sans.org/reading-room/whitepapers/analyst/killing-advanced-threats-tracks-intelligent-approach-attack">cyber
kill-chain</a>/<a href="https://www.langner.com/2010/12/the-short-path-from-cyber-missiles-to-dirty-digital-bombs/">cyber
missiles</a>/<a href="https://www.techopedia.com/definition/29052/cyber-pearl-harbor">cyber
pearl
harbor</a>/<a href="https://www.arcyber.army.mil/">cyber
soldier</a>/<a href="https://www.langner.com/2010/12/the-short-path-from-cyber-missiles-to-dirty-digital-bombs/">cyber
strikes</a>/<a href="https://www.wired.com/2010/03/schmidt-cyberwar/">cyber</a>
<a href="https://www.theverge.com/2014/11/21/7259833/cyberwar-is-bullshit">war</a>/<a href="https://www.bloomberg.com/news/articles/2011-07-20/cyber-weapons-the-new-arms-race">cyber
weapons</a>/<a href="https://www.academic-conferences.org/conferences/iccws/">cyber</a>
<a href="https://en.wikipedia.org/wiki/cyberwarfare">warfare</a>/<a href="http://www.nsci-va.org/cyberreferencelib/2010-11-joint%20terminology%20for%20cyberspace%20operations.pdf">defensive counter
cyber</a>/<a href="https://nvd.nist.gov/800-53/rev4/control/sc-44">detonation
chamber capability</a>/<a href="https://www.cyberriskopportunities.com/notpetya-the-exploit-that-would-lead-to-many-attacks-part-3/">digital
munitions</a>/<a href="https://www.howtogeek.com/445096/what-does-military-grade-encryption-mean/">military-grade
encryption</a>/<a href="https://www.jstor.org/stable/26502756">next-generation
defensive cyber operations</a>/<a href="https://en.wikipedia.org/wiki/proactive_cyber_defence">proactive
cyber defence</a>/…</p>
<p>I understand that it's tempting to compare computer security to war: It takes our daily toil and
raises the stakes, makes us feel that victory is glorious; a battle of the
minds, that our work really matters and is important; and we are united against a common enemy.</p>
<p>But when you think about it, it's absurd: War is something terrible that should be avoided at
almost any cost, a <em>solution</em> of last resort. The worse outcome of
computer-related drama/problems probably doesn't imply entire populations
dying, being tortured, millions of refugees, camps, … Odds are that you won't
save actual lives by deploying a firewall: don't call it a "cyber bulletproof vest deployment".</p>
<p>War justifies terrible behaviours: who cares about you being screamed at when
you're <em>at war</em>? Who cares about your family life, your dinners plans, your hollidays, … when you're <em>at war</em>? What
are broken principles and despicable means, when you're <em>at war</em> ? …
which is a disastrous way to govern and organise a workspace.</p>
<p>Moreover, war maps poorly over computer security. What is a "<a href="https://en.wikipedia.org/wiki/Penetration_test">penetration
test</a>"
combat-wise? How do you map "<a href="https://en.wikipedia.org/wiki/Full_disclosure_">full disclosure</a>" to war? What is a
"prisoner's camp" or "<a href="https://en.wikipedia.org/wiki/Carpet_bombing">carpet bombing</a>" with a computer (apparently <a href="https://www.zdnet.com/article/proof-of-concept-carpet-bombing-exploit-released-in-the-wild/">zdnet</a> <a href="https://www.zdnet.com/article/carpet-bombing-ddos-attack-takes-down-south-african-isp-for-an-entire-day/">can</a> )? Rigidly mapping
one onto the other can and will create huge distortions.</p>
<p>Of course, nobody says that computer security stuff actually <em>is</em> war, but
as said in <a href="https://en.wikipedia.org/wiki/Metaphors_We_Live_By">Metaphors We Live By </a> by <a href="https://en.wikipedia.org/wiki/George_Lakoff">George Lakoff</a> and <a href="https://en.wikipedia.org/wiki/Mark_Johnson_(professor)">Mark
Johnson</a>, "Conceptual metaphors shape not just our communication, but also shape
the way we think and act.". Leading to nonsensical bullshit posts like <a href="https://twoscenarios.typepad.com/maneuver_marketing_commun/2005/05/military_metaph.html">this one</a>, <a href="https://www.forbes.com/sites/forbeslifestyle/2012/05/07/plea-for-a-cease-fire-in-business-as-warfare-advice/#f77cce37aa79">entire laughingly stupid books</a>,
and to despicable and hostile work climate.</p>
<p>An other perverse effect is that since military and violent imagery are traditionally, culturally and stereotypically associated with <a href="https://en.wikipedia.org/wiki/Toxic_masculinity">toxic masculinity</a>,
this doesn't help with increasing the <a href="https://www.isc2.org/research/women-in-cybersecurity">dramatically low</a> diversity in the computer security sector.</p>
<p>When we think about it, we have way better metaphors:</p>
<ul>
<li>Computer security as gardening: defending against bugs, growing programs,
     harvesting money, …</li>
<li>Computer security as building a house: everyone wants cosy stuff, yet you
    still need a solid door, maybe a couple of windows as well, definitely solid
    walls, …</li>
<li>Computer security as playing cards: there are adversaries, winning moves,
    gambles, influences, …</li>
<li>Computer security as guarding a museum: priceless artefacts, sneaky attackers
    à la Arsène Lupin, …</li>
<li>…</li>
</ul>
<p>The goal of computer security is to make safer systems, not about waging wars,
and thus shouldn't be envisioned as such. </p>
<p>Of course, if you're working in the military and in infosec, there are overlaps,
but I would argue that this is more about military than it is about computer security.</p>
<p>As <a href="https://www.linkedin.com/in/roybahat">Rob Bahat</a> said in 2016 in his <a href="https://shift.newco.co/2016/11/15/business-is-not-war-lets-stop-talking-like-it-is/">Business Is Not War. Let’s Stop Talking Like It Is.</a> article:</p>
<blockquote>
<p>Business, at its best, is creation — and war,
always, is destruction. They are opposites, and if we want industry to be a
positive force in our personal lives, environment, society, and future, we
should divorce our language about business from the tragic (if sometimes
necessary) conflicts that bring devastation. There are so many good businesses;
but it is hard to find a good war.</p>
</blockquote>
    </div>
  </article>
</section>
    </div></div>]]>
            </description>
            <link>https://dustri.org/b/on-the-pervasive-presence-of-military-language-elements-in-computer-security.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24640198</guid>
            <pubDate>Wed, 30 Sep 2020 16:03:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Failed Promise of Web Components]]>
            </title>
            <description>
<![CDATA[
Score 360 | Comments 223 (<a href="https://news.ycombinator.com/item?id=24640151">thread link</a>) | @lemonberry
<br/>
September 30, 2020 | https://lea.verou.me/2020/09/the-failed-promise-of-web-components/ | <a href="https://web.archive.org/web/*/https://lea.verou.me/2020/09/the-failed-promise-of-web-components/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p>Web Components had so much potential to empower HTML to do more, and make web development more accessible to non-programmers and easier for programmers. Remember how exciting it was every time we got new shiny HTML elements that actually <em>do stuff</em>? Remember how exciting it was to be able to do sliders, color pickers, dialogs, disclosure widgets straight in the HTML, without having to include any widget libraries?</p>



<p>The promise of Web Components was that we’d get this convenience, but for a much wider range of HTML elements, developed much faster, as nobody needs to wait for the full spec + implementation process. We’d just include a script, and boom, we have more elements at our disposal!</p>



<p>Or, that was the idea. Somewhere along the way, the space got flooded by JS frameworks aficionados, who revel in complex APIs, overengineered build processes and dependency graphs that look like the roots of a banyan tree.</p>



<figure><img src="https://live.staticflickr.com/2025/32441377780_e3acf6de12_b.jpg" alt=""><figcaption>This is what the roots of a Banyan tree look like. <a href="https://www.flickr.com/photos/79721788@N00/32441377780/">Photo by David Stanley on Flickr (CC-BY)</a>. </figcaption></figure>



<p>Perusing the components on <a href="https://www.webcomponents.org/">webcomponents.org</a> fills me with anxiety, and I’m perfectly comfortable writing JS — I write JS for a living! What hope do those who can’t write JS have? Using a custom element from the directory often needs to be preceded by a ritual of npm flugelhorn, import clownshoes, build quux, all completely unapologetically because “here is my truckload of dependencies, yeah, what”. Many steps are even omitted, likely because they are “obvious”. Often, you wade through the maze only to find the component doesn’t work anymore, or is not fit for your purpose.</p>



<p>Besides setup, the main problem is that HTML is not treated with the appropriate respect in the design of these components. They are not designed as closely as possible to standard HTML elements, but <em>expect</em> JS to be written for them to do anything. HTML is simply treated as a shorthand, or worse, as merely a marker to indicate where the element goes in the DOM, with all parameters passed in via JS. I recall <a href="https://adactio.com/articles/12839#webcomponents">a wonderful talk by Jeremy Keith</a> a few years ago about this very phenomenon, where he discussed <a href="https://shop.polymer-project.org/">this e-shop Web components demo by Google</a>, which is the poster child of this practice. These are the entire contents of its <code>&lt;body&gt;</code> element:</p>



<pre><code>&lt;body&gt;
	&lt;shop-app unresolved=""&gt;SHOP&lt;/shop-app&gt;
	&lt;script src="node_assets/@webcomponents/webcomponentsjs/webcomponents-loader.js"&gt;&lt;/script&gt;
	&lt;script type="module" src="src/shop-app.js"&gt;&lt;/script&gt;
	&lt;script&gt;window.performance&amp;&amp;performance.mark&amp;&amp;performance.mark("index.html");&lt;/script&gt;
&lt;/body&gt;</code></pre>



<p>If this is how Google is leading the way, how can we hope for contributors to design components that follow established HTML conventions?</p>



<p>Jeremy criticized this practice from the aspect of backwards compatibility: when JS is broken or not enabled, or the browser doesn’t support Web Components, the entire website is blank. While this is indeed a serious concern, my primary concern is one of <strong>usability</strong>: <strong>HTML is a lower barrier to entry language</strong>. Far more people can write HTML than JS. Even for those who do eventually write JS, it often comes after spending years writing HTML &amp; CSS.</p>



<p>If components are designed in a way that requires  JS, this excludes thousands of people from using them. And even for those who <em>can</em> write JS, HTML is often easier: you don’t see many people rolling their own sliders or using JS-based ones once <code>&lt;input type="range"&gt;</code> became widely supported, right?</p>



<p>Even when JS is unavoidable, it’s not black and white. A well designed HTML element can reduce the amount and complexity of JS needed to a minimum. Think of the <code><a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/dialog">&lt;dialog&gt;</a></code> element: it usually does require *some* JS, but it’s usually rather simple JS. Similarly, the <code>&lt;video&gt;</code> element is perfectly usable just by writing HTML, and has a comprehensive JS API for anyone who wants to do fancy custom things.</p>



<p>The other day I was looking for a simple, dependency free, tabs component. You know, the canonical example of something that is easy to do with Web Components, the example 50% of tutorials mention. I didn’t even care what it looked like, it was for a testing interface. I just wanted something that is small and works like a normal HTML element. Yet, it proved so hard I ended up writing my own!</p>



<h3>Can we fix this?</h3>



<p>I’m not sure if this is a design issue, or a documentation issue. Perhaps for many of these web components, there are easier ways to use them. Perhaps there are vanilla web components out there that I just can’t find. Perhaps I’m looking in the wrong place and there is another directory somewhere with different goals and a different target audience. </p>



<p>But if not, and if I’m not alone in feeling this way, we need a directory of web components with strict inclusion criteria:</p>



<ul><li><strong>Plug and play.</strong> No dependencies, no setup beyond including one <code>&lt;script&gt;</code> tag. If a dependency is absolutely <em>needed</em> (e.g. in a map component it doesn’t make sense to draw your own maps), the component loads it automatically if it’s not already loaded.</li><li>Syntax and API follows <a href="https://www.smashingmagazine.com/2017/02/designing-html-apis/"><strong>conventions established by built-in HTML elements</strong></a> and anything that <em>can</em> be done without the component user writing JS, <em>is</em> doable without JS, per <a href="https://www.w3.org/2001/tag/doc/leastPower.html">the W3C principle of least power</a>.</li><li><strong>Accessible by default</strong> via sensible ARIA defaults, just like normal HTML elements.</li><li><strong>Themable</strong> via <code><a href="https://developer.mozilla.org/en-US/docs/Web/CSS/::part">::part()</a></code>, selective inheritance and custom properties. Very minimal style by default. Normal CSS properties should just “work” to the the extent possible.</li><li><strong>Only one component of a given type</strong> in the directory, that is <strong>flexible</strong> and <strong>extensible</strong> and continuously iterated on and improved by the community. Not 30 different sliders and 15 different tabs that users have to wade through. No branding, no silos of “component libraries”. Only elements that are designed as closely as possible to what a browser would implement in every way the current technology allows.</li></ul>



<p>I would be up for working on this if others feel the same way, since that is not a project for one person to tackle. <em>Who’s with me?</em></p>



<p><strong>UPDATE:</strong> Wow this post blew up! Thank you all for your interest in participating in a potential future effort. I’m currently talking to stakeholders of some of the existing efforts to see if there are any potential collaborations before I go off and create a new one. <a href="https://twitter.com/leaverou">Follow me on Twitter to hear about the outcome</a>!</p>

		</div><!-- .entry-content -->

	</div></div>]]>
            </description>
            <link>https://lea.verou.me/2020/09/the-failed-promise-of-web-components/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24640151</guid>
            <pubDate>Wed, 30 Sep 2020 15:59:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Garry Tan on Posterous, Palantir, YC, Initialized and Influencer Investing]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24639871">thread link</a>) | @rayshan
<br/>
September 30, 2020 | https://www.acquired.fm/episodes/how-yc-rewrote-the-seed-playbook-with-garry-tan-hn | <a href="https://web.archive.org/web/*/https://www.acquired.fm/episodes/how-yc-rewrote-the-seed-playbook-with-garry-tan-hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><strong>Transcript:</strong> <em>(disclaimer: may contain unintentionally confusing, inaccurate and/or amusing transcription errors)</em><strong><br></strong></p><div><p>David: Hello, Acquired LPs. We are coming at you today with a very special episode with Garry Tan of Initialized Fame and before that—Y Combinator, Posterous, and has a long and very illustrious career here in Silicon Valley. We are going to talk about the evolution of early-stage investing.</p><p>Garry has seen it all. I think he started back in the early days when early-stage investing meant a $2 million Series A at a $5 million poster. Maybe that was even high. </p><p>Garry: Yeah, it’s a while.</p><p>David: Goodness, things have changed. I'm so excited to have you here. Thanks for joining us and we can't wait to dive in.</p><p>Garry: Yeah, thank you for having me. Big fan of the show and it means a lot to me that you'd have me.</p><p>David: Likewise that you would come on. Let's just dive right in. We're going to weave in the story of Initialized along the way, but we thought maybe we'd start way back in those prehistoric days of what life is like?</p><p>Garry: So, Arthur Rock.</p><p>David: We've already done that on the Sequoia episodes. Not that far back but when was it that you started Posterous? Was it in 2005?</p><p>Garry: It was 2008, actually. </p><p>David: It was 2008. It’s later than I thought.</p><p>Garry: 2005 I was still at Palantir, so I had just designed the logo for Palantir and built one of the major product teams. Before that, I was Stanford Computer Engineering, and the crazy story for me is that friends of mine were starting a company. And I was the lowest of the low PM at Microsoft.</p><p>Ben: What that’s like?</p><p>Garry: Great place to start, great reach. Friends of mine were starting a company with Peter Thiel. They flew me down to San Francisco to have dinner with Peter right when he wrote the $500,000 check to Facebook. He said, “Garry, what are you doing at Microsoft? You're wasting your time.” I said, “I wanted to work at a startup, but they weren't startups in 2003, 2004.”</p><p>He said, “I'm so sure this is the right thing. You need to quit your job.” He asked me how much a year I made. I told him it was $70,000. He said, “Well, how about this? I'll write you a personal check from my bank account to yours. This is your risk opportunity. Quit your job.” I said, “Thank you very much, Mr. Thiel, but I might make it to level 60 next year,” and I got on a plane and went back to Seattle. That company turned into Palantir. </p><p>David: Oh my gosh.</p><p>Garry: I ended up joining a year later, they had hired away some of my closest friends who were way smarter than me. Bob McGrew, who now runs stuff over at OpenAI. Just so many smart people you get to meet in Silicon Valley over time. Once they hired away people smarter than, I was like, I need to quit my job at Microsoft. At the moment, when your friends are starting a business and you don't know anything about startups, tech, or how these things are funded. You say, well, I have a real job, and you say no.</p><p>David: We're talking about this with Kevin and Julia Hartz on the Eventbrite episode. I imagine you're right out of college. Your parents were probably (if you even told them about this) like, no way would they let you do this.</p><p>Garry: They’re like don’t do it. That seems unsafe. Yeah. The immigrant mentality for sure.</p><p>Ben: Garry, that's an amazing story, and it is absolutely one of survivorship bias because I want to share my story. I had a friend who was starting a YC Company. I had just moved to Seattle, and I was about to start my job at Microsoft. This friend lobbied and lobbied and lobbied. They’d come and get me to co-found the company with them.</p><p>For years, it looked like a huge mistake that I said, are you kidding me? I'd have to give back my signing bonus. I just moved here. This person told me something very similar that they would help definitely pay back the signing bonus. [...] your risk thing, they’d pay for my move. But as years have gone by, that company sold for exactly the preference. It would have been completely awash.</p><p>Garry: Yeah. That's tough.</p><p>Ben: For a while I was like, wow, that's one of several examples in my life where I really blew it on joining something early. Sometimes, not that my choice was the right choice, but unless it's Peter Thiel calling, the story doesn't always end the way you’re—</p><p>Garry: Yeah. These things are crazy risky. I often think about, wow, he was willing to pay that much upfront for an engineer. The rest of my career—even as an investor today—is now actually the inversion of that. Which is now I realize actually, it's the software engineers, designers, product people, and the builders who create the future. That's why we're able to do early-stage at all is that we look a lot more like them at that stage and so they'll pick us.</p><p>On the flip side, because I can still code a little bit and I still do design. I'm probably better at marketing now than I was 10 years ago.</p><p>David: You've diversified your skillset.</p><p>Garry: Yeah. That's right. We look more like them. Then that's the cool thing. I think that fits with the overall series. It's like we're talking about the traitorous eight—sending real typewritten letters across the country to financiers who were totally different from them. Now, what we're talking about—what you guys do and what we're doing—is we're no different. I think that time was for venture capitalists to say we're set apart, we're different.</p><p>David: We're in this ivory tower.</p><p>Garry: Yeah. The ivory tower is different. There's actually a ritualistic aspect that I was talking with Geoff Lewis at Bedrock. He has this theory that is really interesting. There is something to be said for I'm walking up the steps of Sequoia, this is what legends before me did, and I can be a part of that.</p><p>Now it's Zoom. If anything, now it's flipped. Now it's about the one on one conversation that you can have right here. That's why you have the rise of influencer investing. I know, we'll talk about it later, but that's part of the reason why I think YouTube is so important, for me anyway. I'm investing very deeply into it because I think it's a very interesting innovation in the course of how ventures are created.</p><p>David: VCs historically take a long time to catch on. YouTube was founded right around this time that we're talking about, and here we are in 2020 and people only just were starting to catch on.</p><p>Garry: 2005, yeah.</p><p>Ben: Garry, you talked about your time as a builder, and we're going to put a pin in this influencer investing and definitely come back to it because I think it'll be a nice way to round out the full story. Take us through founding Posterous, leaving Palantir, how you raised money for that, and how you went about getting enough proof that there's a there, there to invest more of your time.</p><p>Garry: There's nothing quite like seeing a super early-stage startup for your own eyes. Actually, I've always been really thankful for my time working with Stephen Cohen, Joe Lonsdale, and Alex Karp—just the founders of Palantir. Being able to build software from scratch. The more subtle interesting thing that I feel like I learned was how important it is to basically continue to hire people way smarter than you actually.</p><p>The cult making and the mythmaking of the startup very early are really underplayed. I don't feel like people talk about it enough, and Palantir, I think remains very good at it. The only cult that was stronger than our cult was the Facebook cult (I think). But it's interesting to see. Years later, that's an order of magnitude bigger as a company, which is fascinating to me. I think that actually is directly proportional. How strong your cult will result in how big your company ends up being.</p><p>Assuming you're in the right market and 10 other things that you need to survive. You need to be one of those survivors. A lot of things have to break your way.</p><p>Ben: What's an example of something that was done at Palantir to help build that cult brand?</p><p>Garry: Honestly, I think the simplest thing was even just trying to get the smartest, most capable, and hardworking people, which sounds really stupid simple. It seems like everyone should do that, but honestly, people just don't. When you think about hiring, the mistake that a lot of founders make—and honestly, I made this mistake at some level too when I worked on Posterous—was who can I get? And that's the wrong question.</p><p>You should start with who is the smartest person I know, and it doesn't matter where they're at. Because if I get them, then our self-fulfilling prophecy becomes destiny. If I don't, then it doesn't. I'm not doing myself or them a favor by not going after them. We would just go. </p><p>People would pass out yellow legal pads, and we would force everyone to step away from their computers, and it'd be like, write down the names of 20 people who were the smartest people you've ever met in any walk of life. It didn't have to be engineering, design, or whatever. It was just, who are the smartest people you know in your life. We take it into a backroom and cross-reference it and then those are like our hit list. It's like let's go get those people. We're going to take them to dinner, we're going to take them to lunch, we're going to meet them, we're going to chop down the tree, and we're going to go get them.</p><p>David: That mindset leads to doing things like what Peter offered to you. I can't believe I've never thought of that before. Yeah, you were ungettable. You were at Microsoft, but what if you just offered to personally cover the gap in your salary? It didn't work for you then, but a certain number of people, that's going to work with. And if you're not in that mindset of okay, I don't even go to try to get this person. Well then, you don't know, but once you're like, no, I'm going to try and get them. Well, what can I do?</p><p>Garry: Yeah. It just compounds from there because smart people want to work with smart people. I think that is testament and credit to what they've been able to build over the years. That becomes a self-fulfilling …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.acquired.fm/episodes/how-yc-rewrote-the-seed-playbook-with-garry-tan-hn">https://www.acquired.fm/episodes/how-yc-rewrote-the-seed-playbook-with-garry-tan-hn</a></em></p>]]>
            </description>
            <link>https://www.acquired.fm/episodes/how-yc-rewrote-the-seed-playbook-with-garry-tan-hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-24639871</guid>
            <pubDate>Wed, 30 Sep 2020 15:37:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CycleGAN – Annotated PyTorch Implementation]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24639803">thread link</a>) | @vpj
<br/>
September 30, 2020 | http://lab-ml.com/labml_nn/gan/cycle_gan.html | <a href="https://web.archive.org/web/*/http://lab-ml.com/labml_nn/gan/cycle_gan.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="container">
    
    
    <div id="section-0">
        
            <div>
                <div><pre><span></span><span>import</span> <span>itertools</span>
<span>import</span> <span>random</span>
<span>from</span> <span>pathlib</span> <span>import</span> <span>PurePath</span><span>,</span> <span>Path</span>
<span>from</span> <span>typing</span> <span>import</span> <span>Tuple</span>

<span>import</span> <span>torch</span>
<span>import</span> <span>torch.nn</span> <span>as</span> <span>nn</span>
<span>import</span> <span>torchvision.transforms</span> <span>as</span> <span>transforms</span>
<span>from</span> <span>PIL</span> <span>import</span> <span>Image</span>
<span>from</span> <span>torch.utils.data</span> <span>import</span> <span>DataLoader</span>
<span>from</span> <span>torch.utils.data</span> <span>import</span> <span>Dataset</span>
<span>from</span> <span>torchvision.utils</span> <span>import</span> <span>make_grid</span>
<span>from</span> <span>torchvision.utils</span> <span>import</span> <span>save_image</span>

<span>from</span> <span>labml</span> <span>import</span> <span>lab</span><span>,</span> <span>tracker</span><span>,</span> <span>experiment</span><span>,</span> <span>monit</span><span>,</span> <span>configs</span>
<span>from</span> <span>labml.configs</span> <span>import</span> <span>BaseConfigs</span>
<span>from</span> <span>labml_helpers.device</span> <span>import</span> <span>DeviceConfigs</span>
<span>from</span> <span>labml_helpers.module</span> <span>import</span> <span>Module</span></pre></div>
            </div>
        </div>
    <div id="section-1">
        <div>
                
                <p>The generator is a residual network.</p>
            </div>
            <div>
                <div><pre><span>class</span> <span>GeneratorResNet</span><span>(</span><span>Module</span><span>):</span></pre></div>
            </div>
        </div>
    <div id="section-2">
            
            <div>
                <div><pre>    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>input_shape</span><span>:</span> <span>Tuple</span><span>[</span><span>int</span><span>,</span> <span>int</span><span>,</span> <span>int</span><span>],</span> <span>n_residual_blocks</span><span>:</span> <span>int</span><span>):</span>
        <span>super</span><span>()</span><span>.</span><span>__init__</span><span>()</span></pre></div>
            </div>
        </div>
    <div id="section-3">
            <div>
                
                <p>The number of channels in the input image, which is 3 for RGB images.</p>
            </div>
            <div>
                <div><pre>        <span>channels</span> <span>=</span> <span>input_shape</span><span>[</span><span>0</span><span>]</span></pre></div>
            </div>
        </div>
    <div id="section-4">
            <div>
                
                <p>This first block runs a $7\times7$ convolution and maps the image to
a feature map.
The output feature map has same height and width because we have
a padding of $3$.
Reflection padding is used because it gives better image quality at edges.</p>
<p><code>inplace=True</code> in <code>ReLU</code> saves a little bit of memory.</p>
            </div>
            <div>
                <div><pre>        <span>out_features</span> <span>=</span> <span>64</span>
        <span>layers</span> <span>=</span> <span>[</span>
            <span>nn</span><span>.</span><span>Conv2d</span><span>(</span><span>channels</span><span>,</span> <span>out_features</span><span>,</span> <span>kernel_size</span><span>=</span><span>7</span><span>,</span> <span>padding</span><span>=</span><span>3</span><span>,</span> <span>padding_mode</span><span>=</span><span>'reflect'</span><span>),</span>
            <span>nn</span><span>.</span><span>InstanceNorm2d</span><span>(</span><span>out_features</span><span>),</span>
            <span>nn</span><span>.</span><span>ReLU</span><span>(</span><span>inplace</span><span>=</span><span>True</span><span>),</span>
        <span>]</span>
        <span>in_features</span> <span>=</span> <span>out_features</span></pre></div>
            </div>
        </div>
    <div id="section-5">
            <div>
                
                <p>We down-sample with two $3 \times 3$ convolutions
with stride of 2</p>
            </div>
            <div>
                <div><pre>        <span>for</span> <span>_</span> <span>in</span> <span>range</span><span>(</span><span>2</span><span>):</span>
            <span>out_features</span> <span>*=</span> <span>2</span>
            <span>layers</span> <span>+=</span> <span>[</span>
                <span>nn</span><span>.</span><span>Conv2d</span><span>(</span><span>in_features</span><span>,</span> <span>out_features</span><span>,</span> <span>kernel_size</span><span>=</span><span>3</span><span>,</span> <span>stride</span><span>=</span><span>2</span><span>,</span> <span>padding</span><span>=</span><span>1</span><span>),</span>
                <span>nn</span><span>.</span><span>InstanceNorm2d</span><span>(</span><span>out_features</span><span>),</span>
                <span>nn</span><span>.</span><span>ReLU</span><span>(</span><span>inplace</span><span>=</span><span>True</span><span>),</span>
            <span>]</span>
            <span>in_features</span> <span>=</span> <span>out_features</span></pre></div>
            </div>
        </div>
    <div id="section-6">
            <div>
                
                <p>We take this through <code>n_residual_blocks</code>.
This module is defined below.</p>
            </div>
            <div>
                <div><pre>        <span>for</span> <span>_</span> <span>in</span> <span>range</span><span>(</span><span>n_residual_blocks</span><span>):</span>
            <span>layers</span> <span>+=</span> <span>[</span><span>ResidualBlock</span><span>(</span><span>out_features</span><span>)]</span></pre></div>
            </div>
        </div>
    <div id="section-7">
            <div>
                
                <p>Then the resulting feature map is up-sampled
to match the original image height and width.</p>
            </div>
            <div>
                <div><pre>        <span>for</span> <span>_</span> <span>in</span> <span>range</span><span>(</span><span>2</span><span>):</span>
            <span>out_features</span> <span>//=</span> <span>2</span>
            <span>layers</span> <span>+=</span> <span>[</span>
                <span>nn</span><span>.</span><span>Upsample</span><span>(</span><span>scale_factor</span><span>=</span><span>2</span><span>),</span>
                <span>nn</span><span>.</span><span>Conv2d</span><span>(</span><span>in_features</span><span>,</span> <span>out_features</span><span>,</span> <span>kernel_size</span><span>=</span><span>3</span><span>,</span> <span>stride</span><span>=</span><span>1</span><span>,</span> <span>padding</span><span>=</span><span>1</span><span>),</span>
                <span>nn</span><span>.</span><span>InstanceNorm2d</span><span>(</span><span>out_features</span><span>),</span>
                <span>nn</span><span>.</span><span>ReLU</span><span>(</span><span>inplace</span><span>=</span><span>True</span><span>),</span>
            <span>]</span>
            <span>in_features</span> <span>=</span> <span>out_features</span></pre></div>
            </div>
        </div>
    <div id="section-8">
            <div>
                
                <p>Finally we map the feature map to an RGB image</p>
            </div>
            <div>
                <div><pre>        <span>layers</span> <span>+=</span> <span>[</span><span>nn</span><span>.</span><span>Conv2d</span><span>(</span><span>out_features</span><span>,</span> <span>channels</span><span>,</span> <span>7</span><span>,</span> <span>padding</span><span>=</span><span>3</span><span>,</span> <span>padding_mode</span><span>=</span><span>'reflect'</span><span>),</span> <span>nn</span><span>.</span><span>Tanh</span><span>()]</span></pre></div>
            </div>
        </div>
    <div id="section-9">
            <div>
                
                <p>Create a sequential module with the layers</p>
            </div>
            <div>
                <div><pre>        <span>self</span><span>.</span><span>layers</span> <span>=</span> <span>nn</span><span>.</span><span>Sequential</span><span>(</span><span>*</span><span>layers</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-10">
            <div>
                
                <p>Initialize weights to $\mathcal{N}(0, 0.2)$</p>
            </div>
            <div>
                <div><pre>        <span>self</span><span>.</span><span>apply</span><span>(</span><span>weights_init_normal</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-11">
            
            <div>
                <div><pre>    <span>def</span> <span>__call__</span><span>(</span><span>self</span><span>,</span> <span>x</span><span>):</span>
        <span>return</span> <span>self</span><span>.</span><span>layers</span><span>(</span><span>x</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-12">
        <div>
                
                <p>This is the residual block, with two convolution layers.</p>
            </div>
            <div>
                <div><pre><span>class</span> <span>ResidualBlock</span><span>(</span><span>Module</span><span>):</span></pre></div>
            </div>
        </div>
    <div id="section-13">
            
            <div>
                <div><pre>    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>in_features</span><span>:</span> <span>int</span><span>):</span>
        <span>super</span><span>()</span><span>.</span><span>__init__</span><span>()</span>
        <span>self</span><span>.</span><span>block</span> <span>=</span> <span>nn</span><span>.</span><span>Sequential</span><span>(</span>
            <span>nn</span><span>.</span><span>Conv2d</span><span>(</span><span>in_features</span><span>,</span> <span>in_features</span><span>,</span> <span>kernel_size</span><span>=</span><span>3</span><span>,</span> <span>padding</span><span>=</span><span>1</span><span>,</span> <span>padding_mode</span><span>=</span><span>'reflect'</span><span>),</span>
            <span>nn</span><span>.</span><span>InstanceNorm2d</span><span>(</span><span>in_features</span><span>),</span>
            <span>nn</span><span>.</span><span>ReLU</span><span>(</span><span>inplace</span><span>=</span><span>True</span><span>),</span>
            <span>nn</span><span>.</span><span>Conv2d</span><span>(</span><span>in_features</span><span>,</span> <span>in_features</span><span>,</span> <span>kernel_size</span><span>=</span><span>3</span><span>,</span> <span>padding</span><span>=</span><span>1</span><span>,</span> <span>padding_mode</span><span>=</span><span>'reflect'</span><span>),</span>
            <span>nn</span><span>.</span><span>InstanceNorm2d</span><span>(</span><span>in_features</span><span>),</span>
            <span>nn</span><span>.</span><span>ReLU</span><span>(</span><span>inplace</span><span>=</span><span>True</span><span>),</span>
        <span>)</span></pre></div>
            </div>
        </div>
    <div id="section-14">
            
            <div>
                <div><pre>    <span>def</span> <span>__call__</span><span>(</span><span>self</span><span>,</span> <span>x</span><span>:</span> <span>torch</span><span>.</span><span>Tensor</span><span>):</span>
        <span>return</span> <span>x</span> <span>+</span> <span>self</span><span>.</span><span>block</span><span>(</span><span>x</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-15">
        <div>
                
                <p>This is the discriminator.</p>
            </div>
            <div>
                <div><pre><span>class</span> <span>Discriminator</span><span>(</span><span>Module</span><span>):</span></pre></div>
            </div>
        </div>
    <div id="section-16">
            
            <div>
                <div><pre>    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>input_shape</span><span>:</span> <span>Tuple</span><span>[</span><span>int</span><span>,</span> <span>int</span><span>,</span> <span>int</span><span>]):</span>
        <span>super</span><span>()</span><span>.</span><span>__init__</span><span>()</span>
        <span>channels</span><span>,</span> <span>height</span><span>,</span> <span>width</span> <span>=</span> <span>input_shape</span></pre></div>
            </div>
        </div>
    <div id="section-17">
            <div>
                
                <p>Output of the discriminator is also map of probabilities*
whether each region of the image is real or generated</p>
            </div>
            <div>
                <div><pre>        <span>self</span><span>.</span><span>output_shape</span> <span>=</span> <span>(</span><span>1</span><span>,</span> <span>height</span> <span>//</span> <span>2</span> <span>**</span> <span>4</span><span>,</span> <span>width</span> <span>//</span> <span>2</span> <span>**</span> <span>4</span><span>)</span>

        <span>self</span><span>.</span><span>layers</span> <span>=</span> <span>nn</span><span>.</span><span>Sequential</span><span>(</span></pre></div>
            </div>
        </div>
    <div id="section-18">
            <div>
                
                <p>Each of these blocks will shrink the height and width by a factor of 2</p>
            </div>
            <div>
                <div><pre>            <span>DiscriminatorBlock</span><span>(</span><span>channels</span><span>,</span> <span>64</span><span>,</span> <span>normalize</span><span>=</span><span>False</span><span>),</span>
            <span>DiscriminatorBlock</span><span>(</span><span>64</span><span>,</span> <span>128</span><span>),</span>
            <span>DiscriminatorBlock</span><span>(</span><span>128</span><span>,</span> <span>256</span><span>),</span>
            <span>DiscriminatorBlock</span><span>(</span><span>256</span><span>,</span> <span>512</span><span>),</span></pre></div>
            </div>
        </div>
    <div id="section-19">
            <div>
                
                <p>Zero pad on top and left to keep the output height and width same
with the $4 \times 4$ kernel</p>
            </div>
            <div>
                <div><pre>            <span>nn</span><span>.</span><span>ZeroPad2d</span><span>((</span><span>1</span><span>,</span> <span>0</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>)),</span>
            <span>nn</span><span>.</span><span>Conv2d</span><span>(</span><span>512</span><span>,</span> <span>1</span><span>,</span> <span>kernel_size</span><span>=</span><span>4</span><span>,</span> <span>padding</span><span>=</span><span>1</span><span>)</span>
        <span>)</span></pre></div>
            </div>
        </div>
    <div id="section-20">
            <div>
                
                <p>Initialize weights to $\mathcal{N}(0, 0.2)$</p>
            </div>
            <div>
                <div><pre>        <span>self</span><span>.</span><span>apply</span><span>(</span><span>weights_init_normal</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-21">
            
            <div>
                <div><pre>    <span>def</span> <span>forward</span><span>(</span><span>self</span><span>,</span> <span>img</span><span>):</span>
        <span>return</span> <span>self</span><span>.</span><span>layers</span><span>(</span><span>img</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-22">
        <div>
                
                <p>This is the discriminator block module.
It does a convolution, an optional normalization, and a leaky relu.</p>
<p>It shrinks the height and width of the input feature map by half.</p>
            </div>
            <div>
                <div><pre><span>class</span> <span>DiscriminatorBlock</span><span>(</span><span>Module</span><span>):</span></pre></div>
            </div>
        </div>
    <div id="section-23">
            
            <div>
                <div><pre>    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>in_filters</span><span>:</span> <span>int</span><span>,</span> <span>out_filters</span><span>:</span> <span>int</span><span>,</span> <span>normalize</span><span>:</span> <span>bool</span> <span>=</span> <span>True</span><span>):</span>
        <span>super</span><span>()</span><span>.</span><span>__init__</span><span>()</span>
        <span>layers</span> <span>=</span> <span>[</span><span>nn</span><span>.</span><span>Conv2d</span><span>(</span><span>in_filters</span><span>,</span> <span>out_filters</span><span>,</span> <span>kernel_size</span><span>=</span><span>4</span><span>,</span> <span>stride</span><span>=</span><span>2</span><span>,</span> <span>padding</span><span>=</span><span>1</span><span>)]</span>
        <span>if</span> <span>normalize</span><span>:</span>
            <span>layers</span><span>.</span><span>append</span><span>(</span><span>nn</span><span>.</span><span>InstanceNorm2d</span><span>(</span><span>out_filters</span><span>))</span>
        <span>layers</span><span>.</span><span>append</span><span>(</span><span>nn</span><span>.</span><span>LeakyReLU</span><span>(</span><span>0.2</span><span>,</span> <span>inplace</span><span>=</span><span>True</span><span>))</span>
        <span>self</span><span>.</span><span>layers</span> <span>=</span> <span>nn</span><span>.</span><span>Sequential</span><span>(</span><span>*</span><span>layers</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-24">
            
            <div>
                <div><pre>    <span>def</span> <span>__call__</span><span>(</span><span>self</span><span>,</span> <span>x</span><span>:</span> <span>torch</span><span>.</span><span>Tensor</span><span>):</span>
        <span>return</span> <span>self</span><span>.</span><span>layers</span><span>(</span><span>x</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-25">
        <div>
                
                <p>Initialize convolution layer weights to $\mathcal{N}(0, 0.2)$</p>
            </div>
            <div>
                <div><pre><span>def</span> <span>weights_init_normal</span><span>(</span><span>m</span><span>):</span></pre></div>
            </div>
        </div>
    <div id="section-26">
            
            <div>
                <div><pre>    <span>classname</span> <span>=</span> <span>m</span><span>.</span><span>__class__</span><span>.</span><span>__name__</span>
    <span>if</span> <span>classname</span><span>.</span><span>find</span><span>(</span><span>"Conv"</span><span>)</span> <span>!=</span> <span>-</span><span>1</span><span>:</span>
        <span>torch</span><span>.</span><span>nn</span><span>.</span><span>init</span><span>.</span><span>normal_</span><span>(</span><span>m</span><span>.</span><span>weight</span><span>.</span><span>data</span><span>,</span> <span>0.0</span><span>,</span> <span>0.02</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-27">
        <div>
                
                <p>Loads an image and change to RGB if in grey-scale.</p>
            </div>
            <div>
                <div><pre><span>def</span> <span>load_image</span><span>(</span><span>path</span><span>:</span> <span>str</span><span>):</span></pre></div>
            </div>
        </div>
    <div id="section-28">
            
            <div>
                <div><pre>    <span>image</span> <span>=</span> <span>Image</span><span>.</span><span>open</span><span>(</span><span>path</span><span>)</span>
    <span>if</span> <span>image</span><span>.</span><span>mode</span> <span>!=</span> <span>'RGB'</span><span>:</span>
        <span>image</span> <span>=</span> <span>Image</span><span>.</span><span>new</span><span>(</span><span>"RGB"</span><span>,</span> <span>image</span><span>.</span><span>size</span><span>)</span><span>.</span><span>paste</span><span>(</span><span>image</span><span>)</span>

    <span>return</span> <span>image</span></pre></div>
            </div>
        </div>
    <div id="section-29">
        
            <div>
                <div><pre><span>class</span> <span>ImageDataset</span><span>(</span><span>Dataset</span><span>):</span></pre></div>
            </div>
        </div>
    <div id="section-30">
            
            <div>
                <div><pre>    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>root</span><span>:</span> <span>PurePath</span><span>,</span> <span>transforms_</span><span>,</span> <span>unaligned</span><span>:</span> <span>bool</span><span>,</span> <span>mode</span><span>:</span> <span>str</span><span>):</span>
        <span>root</span> <span>=</span> <span>Path</span><span>(</span><span>root</span><span>)</span>
        <span>self</span><span>.</span><span>transform</span> <span>=</span> <span>transforms</span><span>.</span><span>Compose</span><span>(</span><span>transforms_</span><span>)</span>
        <span>self</span><span>.</span><span>unaligned</span> <span>=</span> <span>unaligned</span>

        <span>self</span><span>.</span><span>files_a</span> <span>=</span> <span>sorted</span><span>(</span><span>str</span><span>(</span><span>f</span><span>)</span> <span>for</span> <span>f</span> <span>in</span> <span>(</span><span>root</span> <span>/</span> <span>f</span><span>'</span><span>{mode}</span><span>A'</span><span>)</span><span>.</span><span>iterdir</span><span>())</span>
        <span>self</span><span>.</span><span>files_b</span> <span>=</span> <span>sorted</span><span>(</span><span>str</span><span>(</span><span>f</span><span>)</span> <span>for</span> <span>f</span> <span>in</span> <span>(</span><span>root</span> <span>/</span> <span>f</span><span>'</span><span>{mode}</span><span>B'</span><span>)</span><span>.</span><span>iterdir</span><span>())</span></pre></div>
            </div>
        </div>
    <div id="section-31">
            
            <div>
                <div><pre>    <span>def</span> <span>__getitem__</span><span>(</span><span>self</span><span>,</span> <span>index</span><span>):</span>
        <span>return</span> <span>{</span><span>"x"</span><span>:</span> <span>self</span><span>.</span><span>transform</span><span>(</span><span>load_image</span><span>(</span><span>self</span><span>.</span><span>files_a</span><span>[</span><span>index</span> <span>%</span> <span>len</span><span>(</span><span>self</span><span>.</span><span>files_a</span><span>)])),</span>
                <span>"y"</span><span>:</span> <span>self</span><span>.</span><span>transform</span><span>(</span><span>load_image</span><span>(</span><span>self</span><span>.</span><span>files_b</span><span>[</span><span>index</span> <span>%</span> <span>len</span><span>(</span><span>self</span><span>.</span><span>files_b</span><span>)]))}</span></pre></div>
            </div>
        </div>
    <div id="section-32">
            
            <div>
                <div><pre>    <span>def</span> <span>__len__</span><span>(</span><span>self</span><span>):</span>
        <span>return</span> <span>max</span><span>(</span><span>len</span><span>(</span><span>self</span><span>.</span><span>files_a</span><span>),</span> <span>len</span><span>(</span><span>self</span><span>.</span><span>files_b</span><span>))</span></pre></div>
            </div>
        </div>
    <div id="section-33">
        <div>
                
                <p>Replay buffer is used to train the discriminator.
Generated images are added to the replay buffer and sampled from it.</p>
<p>The replay buffer returns the newly added image with a probability of $0.5$.
Otherwise it sends an older generated image and and replaces the older image
with the new generated image.</p>
<p>This is done to reduce model oscillation.</p>
            </div>
            
        </div>
    <div id="section-34">
            
            <div>
                <div><pre>    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>max_size</span><span>:</span> <span>int</span> <span>=</span> <span>50</span><span>):</span>
        <span>self</span><span>.</span><span>max_size</span> <span>=</span> <span>max_size</span>
        <span>self</span><span>.</span><span>data</span> <span>=</span> <span>[]</span></pre></div>
            </div>
        </div>
    <div id="section-35">
            
            <div>
                <div><pre>    <span>def</span> <span>push_and_pop</span><span>(</span><span>self</span><span>,</span> <span>data</span><span>:</span> <span>torch</span><span>.</span><span>Tensor</span><span>):</span></pre></div>
            </div>
        </div>
    <div id="section-36">
            
            <div>
              …</div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://lab-ml.com/labml_nn/gan/cycle_gan.html">http://lab-ml.com/labml_nn/gan/cycle_gan.html</a></em></p>]]>
            </description>
            <link>http://lab-ml.com/labml_nn/gan/cycle_gan.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24639803</guid>
            <pubDate>Wed, 30 Sep 2020 15:32:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ideas from My Development Setup: Always Tmux]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24639599">thread link</a>) | @ceda_ei
<br/>
September 30, 2020 | https://cedaei.com/posts/ideas-from-my-dev-setup-always-tmux/ | <a href="https://web.archive.org/web/*/https://cedaei.com/posts/ideas-from-my-dev-setup-always-tmux/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
        <p>Back when I first learnt tmux, I realized it was a really valuable tool. Soon
afterwards, I found myself in need of wanting to make a split only to find out
I wasn’t in tmux. This would lead to:</p>
<ul>
<li>Killing the running process.</li>
<li>Starting tmux.</li>
<li>Restarting the previous process.</li>
</ul>
<p>In pursuit of an ideal solution, I added a tiny script in my scripts directory
which was called by my bashrc.</p>
<h2 id="current-workflow">Current Workflow<a href="#current-workflow" arialabel="Anchor">⌗</a> </h2>
<p>My current workflow simply starts by opening the terminal. Instead of the bash
prompt, I am greeted by this.</p>
<pre><code>Choose the terminal to attach:
1 - 12: 3 windows (created Wed Sep 30 14:26:37 2020) (attached)
2 - tana: 3 windows (created Wed Sep 30 18:17:24 2020) (attached)
3 - userbot: 1 windows (created Tue Sep 29 18:37:19 2020)
4 - ytc: 1 windows (created Tue Sep 29 18:37:19 2020)

Create a new session by entering a name for it
</code></pre><p>At this point, I either</p>
<ul>
<li>enter a number (in this case from 1 to 4) to connect to an existing session.</li>
<li>enter a name to create a named tmux session.</li>
<li>hit enter (or C-D) to create an unnamed session (tmux will name it
sequentially).</li>
<li>type nil and hit enter to drop to shell without starting tmux</li>
</ul>
<h2 id="implementation">Implementation<a href="#implementation" arialabel="Anchor">⌗</a> </h2>
<p>In my <code>.bashrc</code>, live these lines.</p>
<div><pre><code data-lang="bash"><span>if</span> <span>[[</span> ! -v TMUX <span>&amp;&amp;</span> $TERM_PROGRAM !<span>=</span> <span>"vscode"</span> <span>]]</span>; <span>then</span>
	tmux_chooser <span>&amp;&amp;</span> exit
<span>fi</span>
</code></pre></div><p>Although I use vim as my sole editor, I needed to demo something in VSCode and
for that case I have added an exception so that the script does not run the
<code>tmux_chooser</code> in VSCode’s integrated terminal.</p>
<p>Here is the source of <code>tmux_chooser</code> called above.</p>
<div><pre><code data-lang="bash"><span>#!/usr/bin/bash
</span><span></span><span># shellcheck disable=SC2207</span>

<span># Doesn't let you press Ctrl-C</span>
<span>function</span> ctrl_c<span>()</span> <span>{</span>
	echo -e <span>"\renter nil to drop to normal prompt"</span>
<span>}</span>

trap ctrl_c SIGINT

no_of_terminals<span>=</span><span>$(</span>tmux list-sessions | wc -l<span>)</span>
IFS<span>=</span><span>$'\n'</span>
output<span>=(</span><span>$(</span>tmux list-sessions<span>)</span><span>)</span>
output_names<span>=(</span><span>$(</span>tmux list-sessions -F<span>\#</span>S<span>)</span><span>)</span>
k<span>=</span><span>1</span>
echo <span>"Choose the terminal to attach: "</span>
<span>for</span> i in <span>"</span><span>${</span>output[@]<span>}</span><span>"</span>; <span>do</span>
	echo <span>"</span>$k<span> - </span>$i<span>"</span>
	<span>((</span>k++<span>))</span>
<span>done</span>
echo
echo <span>"Create a new session by entering a name for it"</span>
read -r input
<span>if</span> <span>[[</span> $input <span>==</span> <span>""</span> <span>]]</span>; <span>then</span>
	tmux new-session
<span>elif</span> <span>[[</span> $input <span>==</span> <span>'nil'</span> <span>]]</span>; <span>then</span>
	exit <span>1</span>
<span>elif</span> <span>[[</span> $input <span>=</span>~ ^<span>[</span>0-9<span>]</span>+$ <span>]]</span> <span>&amp;&amp;</span> <span>[[</span> $input -le $no_of_terminals <span>]]</span>; <span>then</span>
	terminal_name<span>=</span><span>"</span><span>${</span>output_names[input - 1]<span>}</span><span>"</span>
	tmux attach -t <span>"</span>$terminal_name<span>"</span>
<span>else</span>
	tmux new-session -s <span>"</span>$input<span>"</span>
<span>fi</span>
exit <span>0</span>
</code></pre></div>
      </div></div></div>]]>
            </description>
            <link>https://cedaei.com/posts/ideas-from-my-dev-setup-always-tmux/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24639599</guid>
            <pubDate>Wed, 30 Sep 2020 15:16:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Beginner's Guide to Arguing Constructively]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24639504">thread link</a>) | @liamrosen
<br/>
September 30, 2020 | http://liamrosen.com/arguments.html | <a href="https://web.archive.org/web/*/http://liamrosen.com/arguments.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<div><p><span>First published September 2020</span></p><p>

<em>Questions? Suggestions? E-mail me:</em>&nbsp;<img alt="" height="22" src="http://liamrosen.com/liamrosen.png" title="" width="164"></p></div>

<h2>CONTENTS</h2>

<p><a href="#intro">PART I: INTRO</a><br>
<a href="#mindset">PART II: MINDSET</a><br>
<a href="#prework">PART III: PRE-WORK</a><br>
<a href="#debatebreakdown">PART IV: BREAKING DOWN A DEBATE</a><br>
<a href="#strategies">PART V: STRATEGIES</a><br>
<a href="#tips">PART VI: TIPS</a><br>
<a href="#thanks">PART VII: CONCLUSION</a></p>

<h2><a id="intro" name="intro">INTRO</a></h2>

<p>The vast majority of people on earth argue in a <em>destructive </em>fashion. Debates, especially in online spaces, are viewed as a battle of the wits in which egos are put on display and there can be only one "winner".</p>

<p>Instead, we should be arguing in a <em>constructive </em>fashion: treating arguments as an opportunity to expand knowledge, finding points of disagreement, and collaborating towards a common truth.</p>

<p>I have a confession to make: I used to be a destructive arguer. When I was younger, my goal in any argument was not to learn something new, but rather to assure my superiority over what I felt to be the clear stupidity of the other side. I even used to save screenshots of debates I had on various forums and social media platforms, returning periodically to reminisce about past skirmishes in which I "<a href="https://knowyourmeme.com/memes/trigger-the-libs">owned the conservatives</a>".</p>

<p>Luckily, several years spent abroad gave me a different perspective. I realized that in the small-sided debates I used to engage in back home, my positions lacked the nuance and context of the greater world. For the first time, I began to do deep research on how to think — and argue — &nbsp;more clearly, drawing from concepts from philosophy, psychology, and behavioral economics.</p>

<p>This widened outlook led me to see arguments as a chance to build value, rather than destroy it. Instead of going through the mental anguish of battle, I now follow a collaborative approach to debate that I'd like to share in this guide in hopes that it will inspire others to argue more constructively.</p>

<p>Note that the content in this guide will focus on arguments about public issues, like politics and religion, as opposed to personal issues, like "you need to communicate more" or "you haven't done the dishes in weeks". Though there is overlap between the two, interpersonal arguments are much more complex and require more nuance than this guide can provide, plus there are already a ton of great resources out there that explore these topics more thoroughly.</p>

<h2><a id="mindset" name="mindset">MINDSET</a></h2>

<blockquote>
<p><strong><span><em>&nbsp;"An argument should be a collaboration between two people to find the truth."</em></span></strong></p>
</blockquote>

<p>If I had to distill this guide down to one sentence, it would be the above. Even if you forget the individual tenets and strategies this guide has to offer, as long as you are treating any given argument as a collaboration in search of truth, you can't go wrong.</p>

<p>Arguing more effectively requires detaching yourself from the idea of "winning" in the traditional sense. Instead, you should declare victory when you have argued in good faith and kept an open mind.</p>

<p>True collaboration requires that both parties open an investigation into why they may be wrong and consider changing their beliefs. Which brings us to the three core tenets of a constructive debate mindset:</p>

<h3>Acknowledge You May Be Wrong, and Be Willing to Change Your Mind <a href="#Acknowledge You May Be Wrong, and Be Willing to Change Your Mind" id="Acknowledge You May Be Wrong, and Be Willing to Change Your Mind" name="Acknowledge You May Be Wrong, and Be Willing to Change Your Mind"><img alt="" src="http://liamrosen.com/anchor.png"></a></h3>

<p>Was there ever a time in which you had a deeply-held belief about something, but slowly came to realize that you were wrong? Maybe you thought a past partner was "the one", or you were devoted to a religious faith. Or perhaps something as simple as believing in Santa Claus.</p>

<p>What's to say that couldn't happen with the rest of your deeply-held beliefs, given enough evidence?</p>

<p>Go into every debate with the mindset that you may not know everything about the topic at hand, and in fact <em>may be wrong</em>.</p>

<p>If you successfully acknowledge that you may be wrong, it follows that you must then be willing to change your mind. Having the humility to admit that your mind has been changed is one of the most honorable positions in a good faith debate.</p>

<h3>Arguments Are Not Soldiers <a href="#Arguments Are Not Soldiers" id="Arguments Are Not Soldiers" name="Arguments Are Not Soldiers"><img alt="" src="http://liamrosen.com/anchor.png"></a></h3>

<p>In a war, all soldiers take an oath to fight for their own side, no matter what amount they agree with its principles. <a href="https://www.lesswrong.com/posts/9weLK2AJ9JEt2Tt8f/politics-is-the-mind-killer">Eliezer Yudkowsky once observed</a> that in political debates, arguments were treated like soldiers: "<em>Once you know which side you're on, you must support all arguments of that side, and attack all arguments that appear to favor the enemy side; otherwise it's like stabbing your soldiers in the back.</em>"</p>

<p>Because most people go into debate with a war-like mentality, they feel they must fly the flag for all points that <em>their</em><em> side</em> supports, regardless of how much they actually agree with them.</p>

<p>The red state gun-owner must be pro-religion, anti-abortion, anti-drugs, anti-tax, and skeptical of gender issues.</p>

<p>The blue state Subaru-owner must be anti-religion, pro-abortion, pro-drugs, pro-tax(ing-the-rich), and concerned about gender issues.</p>

<p>Most annoying is that given the societal expectations for this divide, being for or against one issue immediately assigns you to a "side" in the views of everyone involved. Breaking out of this Arguments as Soldiers mindset involves two steps:</p>

<p>1. Do not be afraid to agree with the arguments of the other side when they strike you as reasonable, and critique the arguments of your own side when they strike you as unreasonable (better yet, try not to have a side).</p>

<p>2. On the flip side, avoid stereotyping your debate partner based on one opinion. If you are engaging with someone in debate for the first time, assume that they agree with you on every other position than the one they are defending, until proven otherwise.</p>

<h3>There's Always Someone Who Thinks the Jedi Are Evil <a href="#There's Always Someone Who Thinks the Jedi Are Evil" id="There's Always Someone Who Thinks the Jedi Are Evil" name="There's Always Someone Who Thinks the Jedi Are Evil"><img alt="" src="http://liamrosen.com/anchor.png"></a></h3>

<p><em>Brace yourself, Star Wars references incoming:</em></p>

<p>In a given debate, almost everyone thinks they are a member of the Jedi order, fighting for all that is virtuous and good in the universe. Yet for every Jedi, there's a Sith out there <a href="http://www.youtube.com/watch?v=llLKar19XhA">who thinks that the Jedi are evil</a> and wrong and that <em>they</em> are actually the ones fighting for virtue and good. Remember that this person might even be <em>you</em>.</p>

<p>Of course, you are not a full agent of good, and your debate partner is not an agent of evil, or vice versa. You are simply citizens of the galaxy who happen to be operating with different sets of information. Look at the situation from a different perspective: if you were raised with Sith beliefs from childhood, don't you think you might believe the exact same things a Sith would?</p>

<p>In debate, your goal should not be to <a href="https://www.youtube.com/watch?v=rMNKwZTv1d0">strike down the side of evil with all your hatred</a>, but rather work together with them to uncover the true facts about the universe, and in doing so perhaps change both your perspectives.</p>

<h2><a id="mindset" name="prework">PRE-WORK</a></h2>

<p>It would be great if choosing to pursue the path of arguing constructively was just a matter of changing your mindset overnight, but as Carl Sagan once said: <a href="https://youtu.be/BkHCO8f2TWs?t=9">"If you wish to bake an apple pie from scratch, you must first invent the universe."</a></p>

<p>In the same vein, if you wish to improve the constructiveness of the debates you engage in, you must first spend time re-inventing your entire mind.</p>

<p>This is because our mind is constantly working against us, plagued by ancient errors from the times in which we lived in caves and hunted woolly mammoths. These errors work against us in the form of cognitive biases and logical fallacies, which hinder our ability to clearly see reality and engage in sound debate.</p>

<h3>Recognize and Avoid Cognitive Biases <a href="#Recognize and Avoid Cognitive Biases" id="Recognize and Avoid Cognitive Biases" name="Recognize and Avoid Cognitive Biases"><img alt="" src="http://liamrosen.com/anchor.png"></a></h3>

<p>Cognitive biases are limits and mistakes in human judgement that prevent someone from acting rationally. They are present in every aspect of human life, and in tense situations like arguments, they tend to appear more often as emotions are heightened and the brain gets overloaded.</p>

<p>Common examples that relate to debates are <em>confirmation bias</em>, or the tendency of humans to seek out information that confirms existing beliefs, and <em>ingroup bias</em>, or the tendency to agree more strongly with people that appear to be part of our "tribe", but there are over 100 identified biases, and it's worth reading through the Wikipedia article on the <a href="https://en.wikipedia.org/wiki/List_of_cognitive_biases">most common cognitive biases</a> so you can recognize when they might be clouding your thinking.</p>

<h3>Recognize and Avoid Logical Fallacies <a href="#Recognize and Avoid Logical Fallacies" id="Recognize and Avoid Logical Fallacies" name="Recognize and Avoid Logical Fallacies"><img alt="" src="http://liamrosen.com/anchor.png"></a></h3>

<p>In part caused by cognitive biases, logical fallacies are errors in argument that give off an air of decisiveness, despite making points that don't hold up to logical scrutiny. While these are often used unintentionally, due to bias, carelessness, or ignorance, unfortunately, they can also be wielded intentionally by a shrewd debate partner.</p>

<p>Common examples in debate include the <em>false dilemma fallacy</em>: "you're either with us or against us", and the <em>slippery slope fallacy</em>: "if we allow the gays to marry, what's next: plants?" Just like cognitive biases, there are a large number of identified logical fallacies, and it's worth it to review the <a href="https://en.wikipedia.org/wiki/List_of_fallacies">entire list</a>, so you can spot them in your own arguments and in those of others.</p>

<h2><a id="debatebreakdown" name="debatebreakdown">BREAKING DOWN A DEBATE</a></h2>

<p>To the untrained eye, a debate might look like two or more parties trading argumentative points back and forth. But interestingly, these points can almost perfectly be classified into a few categories. Understanding these categories, and why some types of arguments are better than others, is crucial for learning how we and those whom we engage with in debate might shape their points. In a brilliant post called <em><a href="https://slatestarcodex.com/2018/05/08/varieties-of-argumentative-experience/">Varieties of Argumentative Experience</a></em>, Scott Alexander does just this, illuminating and labeling practically every part of a debate. The post itself is basically required reading, but is long-ish<em>,</em> so I will summarize here.</p>

<p>Think of a debate as a pyramid: <a href="#debatepyramid" id="debatepyramid" name="debatepyramid"><img alt="" src="http://liamrosen.com/anchor.png"></a></p>

<p><img alt="" height="548" src="http://liamrosen.com/Pyramid%20of%20Argumentative%20Experience.svg" width="978"></p>

<p>In general, the lower on the pyramid you are, the worse debate you're having. The goal should be to start as high as possible and continue to work your way towards the top.</p>

<p>Debates on twitter and other forms of social media are almost guaranteed to never rise above the lower dotted line, as these platform don't allow for more nuanced debate. Everything above the higher dotted line is our gold standard: two intelligent, charitable, and versed debaters can successfully maintain a debate at this level until some form of resolution.</p>

<p>The blue side represents the discussion …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://liamrosen.com/arguments.html">http://liamrosen.com/arguments.html</a></em></p>]]>
            </description>
            <link>http://liamrosen.com/arguments.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24639504</guid>
            <pubDate>Wed, 30 Sep 2020 15:08:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Personality Does Not Define Success]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24639493">thread link</a>) | @tmatthe
<br/>
September 30, 2020 | https://tiffanymatthe.com/personality-success | <a href="https://web.archive.org/web/*/https://tiffanymatthe.com/personality-success">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="skip-nav"><p><time>30.09.2020</time> — <a href="https://tiffanymatthe.com/tags/success">Success</a> — <span>2<!-- --> min read</span></p><section><img src="https://tiffanymatthe.com/static/5e02aed394b5a39a819f8367c9cd4555/a6c62/personality-success.jpg"><p>Tim Cook <a href="https://poy.time.com/2012/12/19/runner-up-tim-cook-the-technologist/">wakes up at 3:45 am</a>. Yoshiro Nakamatsu <a href="https://web.archive.org/web/20120330154757/http://www.whatagreatidea.com/nakamatsu.htm">dives underwater for the best ideas</a>. Marissa Mayer <a href="https://www.reuters.com/article/us-yahoo-hiring-idUSBRE92B06R20130312">personally approves every hire</a>. These quirky habits of successful people are plastered throughout the internet, often lauded as the golden tickets to success.</p><p>This is as true as Oompa-Loompas. Habits and routines affect people differently, and they cannot exist by themselves. You could wake up at 3:45 am and do nothing of your day. You could dive underwater and come up with amazing ideas but never invent anything . You could approve every hire but have a weak business vision.</p><p>Similarly, personality does not define success.</p><p>Steve Jobs was known to be extremely harsh towards his employees if something wasn't up to his standards. This anecdote does not mean you need to be ruthless to be as successful as him. You could emulate all of his personality traits, but end up nowhere.</p><p>Although self-focused and competitive people seem to meet their goals more (<a href="https://www.sciencedirect.com/science/article/abs/pii/S0191886917305962">at least for men</a>), they are more prone to be <a href="https://www.tandfonline.com/doi/abs/10.1080/02678370903282600?journalCode=twst20">less resilient in the workplace</a> and alienate those around them.</p><p>On the other hand, some may believe that being nice does not lead to anywhere either. You feel cheap, easy to please, relatable, the exact opposite of the elite successful class. And there is some truth to this. According to <a href="https://journals.sagepub.com/doi/abs/10.1177/001979391106400509">a study in the UK</a>, they found that there exists at least a weak "negative linear relationship between wages and agreeableness".</p><p>Agreeable people sacrifice their own success for others. They are passive in conflict. However, they also contribute to psychological safety, which is the most important dynamic of Google's <a href="https://rework.withgoogle.com/blog/five-keys-to-a-successful-google-team/">five keys to a successful team</a>.</p><p><strong>All personality traits have multiple facets that can be advantageous or detrimental to success.</strong> The difference between Steve Jobs and a regular grumpy manager is what their personality is built on. Is it built on a skillful person with a passion for their work? Or is it built on a hollow husk with no direction?</p><p>A house's external façade can play a big role in attracting buyers, but in the end, the prospective residents will be living inside. If it's ugly or empty, nothing will ever happen. The effectiveness of a personality is not self-contained. It depends on your passions, your skills, context, luck, etc.</p><p>You can change your personality to push you towards your goals, but remember that it is not the defining factor of success.</p></section></div></div>]]>
            </description>
            <link>https://tiffanymatthe.com/personality-success</link>
            <guid isPermaLink="false">hacker-news-small-sites-24639493</guid>
            <pubDate>Wed, 30 Sep 2020 15:07:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Skill Stacking]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24639304">thread link</a>) | @mcrittenden
<br/>
September 30, 2020 | https://critter.blog/2020/09/30/skill-stacking/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/09/30/skill-stacking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-825">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>Scott Adams, the creator of Dilbert, <a href="https://dilbertblog.typepad.com/the_dilbert_blog/2007/07/career-advice.html">wrote</a> about how to reach the top:</p>



<blockquote><p>If you want something extraordinary, you have two paths:</p><p>1. Become the best at one specific thing.<br>2. Become good (top 25%) at two or more things.</p><cite>Scott Adams (<a href="https://dilbertblog.typepad.com/the_dilbert_blog/2007/07/career-advice.html">source</a>)</cite></blockquote>



<p>Number one, he says, is as good as impossible but number two is easy. </p>



<p>It’s called <strong>Skill Stacking</strong>. I went down the rabbit hole and found <a href="https://forge.medium.com/how-to-become-the-best-in-the-world-at-something-f1b658f93428">this excellent post</a> with this image:</p>



<figure><img data-attachment-id="1710" data-permalink="https://critter.blog/stackiing/" data-orig-file="https://mikecrittendenhome.files.wordpress.com/2020/09/stackiing.png" data-orig-size="1400,787" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="stackiing" data-image-description="" data-medium-file="https://mikecrittendenhome.files.wordpress.com/2020/09/stackiing.png?w=300" data-large-file="https://mikecrittendenhome.files.wordpress.com/2020/09/stackiing.png?w=580" src="https://mikecrittendenhome.files.wordpress.com/2020/09/stackiing.png?w=1024" alt="" srcset="https://mikecrittendenhome.files.wordpress.com/2020/09/stackiing.png?w=1024 1024w, https://mikecrittendenhome.files.wordpress.com/2020/09/stackiing.png?w=150 150w, https://mikecrittendenhome.files.wordpress.com/2020/09/stackiing.png?w=300 300w, https://mikecrittendenhome.files.wordpress.com/2020/09/stackiing.png?w=768 768w, https://mikecrittendenhome.files.wordpress.com/2020/09/stackiing.png 1400w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>See that little fella in the middle there? That’s the sweet spot. </p>



<p>I will never be the best in the world at running or programming or writing or agile process. But I can be in the top 25% of each. If I can find a way to combine two or more of them, then I can be the best at that combination. </p>



<p>I could build an audiobook reader app specifically for runners. I could create a niche blog for programmers who run. I could apply for Strava’s engineering team. I could write a book on how to apply agile principles to running. </p>



<p>Here’s another example, plucked from a random Hacker News comment:</p>



<blockquote><p>I learned this lesson from Clifford Stoll. He said that astronomers figure he must be an exceptional programmer, since he’s clearly a mediocre astronomer. While programmers figure he must be an exceptional astronomer, since his programming is strictly middle-of-the-road!</p><cite><a href="https://news.ycombinator.com/item?id=24263882">samatman on HN</a></cite></blockquote>



<p>Of course, there are different types of skills. You’ll have trouble combining some skills, but others are universal. Public speaking, writing, marketing, programming, charisma; these can stack with almost anything. Scott Adams says this about public speaking:</p>



<blockquote><p>I always advise young people to become good public speakers (top 25%). Anyone can do it with practice. If you add that talent to any other, suddenly you’re the boss of the people who have only one skill.</p><cite>Scott Adams</cite></blockquote>



<p>It’s a fun thought experiment. List the things you’re pretty good at, and brainstorm ways to combine 2 or more of them. What do you come up with?</p>



		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/09/30/skill-stacking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24639304</guid>
            <pubDate>Wed, 30 Sep 2020 14:52:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Coinbase post was 100% right. Here's what you can do about it]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 20 (<a href="https://news.ycombinator.com/item?id=24638995">thread link</a>) | @ihm
<br/>
September 30, 2020 | https://parametricity.com/posts/2020-power/ | <a href="https://web.archive.org/web/*/https://parametricity.com/posts/2020-power/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<p>Recently there was a minor controversy over a blogpost from Coinbase’s <a href="https://blog.coinbase.com/coinbase-is-a-mission-focused-company-af882df8804">CEO</a>
discouraging employees from thinking about politics, and encouraging them to focus on profit-making.
I really appreciated this post, because I think it can be very clarifying for those employees who think their
company can be a pure force for good. The Coinbase blogpost gives the honest truth that in the final calculus,
corporations whose primary goal is profit-maximization can only incidentally and in small ways advance any other
aim.</p>
<p>At the same time, there is a lot of promise for good in the actual technology underlying the crypto industry. This post will argue</p>
<ol>
<li><strong>If work is organized through for-profit corporations, there will be strong pressure from management and capital to
distort positive aspects of the technology in favor of profit-making</strong></li>
<li>The <strong>naive utopianism</strong> which has sustained the industry so far and helped produce some good technology <strong>is no match for this pressure</strong></li>
<li><strong>The only realistic way to combat this</strong> distorting pressure and focus on the socially-beneficial aspects of the technology <strong>is for workers</strong>
(the other human factor of production apart from management and capitalists) <strong>to use their collective power to push back</strong>.</li>
</ol>
<p>This argument is not surprisingly somewhat controversial among executives and VCs, but happily that same group loves
free speech and hates cancel-culture, so I assume I will not be attacked for expressing it.</p>
<h2 id="what-is-the-web-and-what-should-it-be">What is the web and what should it be?</h2>
<p>What should the web be? It should be a medium for personal communication, organization for people in projects, art and creative expression, etc. that is oriented around the goals of individual and collective flourishing. That would be ideal.</p>
<p>In reality, it is not operated that way. It – like almost everything in our society – is operated as a profit-extraction machine in the service of a small group of people.
This machine started off performing the above functions (of course, already distorted by its origins as a technology for the military and academia).
Soon, an industry of for-profit companies sprung up around developing the internet. Many of these companies became large enough to have a decisive influence on what the web would be.</p>
<p>As the years went by, the parts of it that did not contribute much to profit generation (like weird personal websites) were scrapped under the influence of these companies,
and new pieces which enhanced profit generation were added. It happened this way because there is enormous pressure from management and investors to focus on profit-generation
to the exclusion of all else.</p>
<p>Of course, because these modifications were made primarily in pursuit of profit with other reasons being secondary, this resulted in a bunch of unintended (or un-“cared about”) negative consequences like</p>
<ul>
<li>creepy data-collection and surveillance which is used to manipulate us into buying things</li>
<li>right-wing radicalization which has resulted in widespread political violence</li>
<li>distribution of misinformation</li>
<li>an enormous carbon footprint</li>
<li>collective billions in wasted minutes spent scrolling because we were tricked by the algorithm to stay on just a bit longer</li>
</ul>
<p>All of these things are natural results of a system that cannot “see” the concept of social good and can only see profits.
These problems just do not matter to the system, and only could in the event that they interfered with profit-generation.</p>
<h2 id="how-to-push-back">How to push back</h2>
<p>Let’s say you are a worker at a crypto company who sees this history and want to make sure that in crypto, socially useful aspects of
the technology are prioritized rather than those that make the most profit. What should you do?</p>
<p>First, I think it is necessary to deal with the most popular response, which is a utopian faith that the decentralized
nature of some crypto technology will inherently stop bad things from happening.</p>
<h3 id="crypto-utopianism">Crypto-utopianism</h3>
<p>There’s a lot of utopianism in crypto. This ranges from the lowest Bitcoin-booster all the way up to people like Vitalik.</p>
<p>This quote is somewhat <a href="https://www.coindesk.com/this-political-conversation-with-vitalik-buterin-shows-how-ethereum-could-change-the-world">examplary</a>:</p>
<blockquote>
<p>These three white men talked about the protests erupting across the United States. To his credit, the Russian-Canadian Buterin spoke broadly instead of attempting to comment on inequality in American politics. He said the current generation is facing a global “crisis of legitimacy,” concerning both corporations and “many types of governments.”</p>
</blockquote>
<blockquote>
<p>“The challenge here is can we create systems that allow some groups of people to cooperate without that downside of a centralized or trusted actor having to be in the middle,” Buterin said.</p>
</blockquote>
<p>Crypto-utopianism usually includes a suggestion that crypto will replace existing systems (which are bad because they’re “centralized” or some other vague reason) and be better because they are “decentralized” (whatever that might mean).</p>
<p>These analyses give crypto projects a sense of grandeur and importance which is motivating to developers and investors alike. Unfortunately, if your goal is to push back against the existing profit-maximizing power structures, you need to have a better analysis than “centralized bad, decentralized good”. It sounds good, but it doesn’t actually constitute a plan to defeat the Facebooks of the world or even to resist pressure from investors.</p>
<p>The crypto-utopian prescription for all that ails the web is some new technology.
Technology is great and a necessary part of the puzzle, but unless Glenn Weyl has a way of forcing Facebook to use quadratic voting for corporate governance, it’s not useful yet.
<strong>The existing power structure can always pick-and-choose the new technology that best advances its goals.</strong>
If you have goals which are distinct from theirs, you need to build power that is capable of a serious challenge.</p>
<h3 id="what-kind-of-power-do-they-have">What kind of power do they have?</h3>
<p>What kind of power does the existing “power structure” consisting of senior management and capitalists have?
It has</p>
<ul>
<li><a href="https://www.theverge.com/2019/11/25/20983053/google-fires-four-employees-memo-rebecca-rivers-laurence-berland-union-busting-accusation-walkout">the ability to fire people</a> that won’t comply with its goals</li>
<li>the ability to withhold funding from companies that won’t comply with its goals (this is kind of another version of the previous)</li>
<li><a href="https://parametricity.com/posts/2020-power/news.ycombinator.com">public platforms</a> to spread <a href="https://blog.coinbase.com/coinbase-is-a-mission-focused-company-af882df8804">messaging that argues in favor of its goals</a></li>
<li>control of platforms which allows them to <a href="https://itsgoingdown.org/on-facebook-banning-anarchist-and-antifascist-pages-the-digital-censorship-to-come/">censor unfavorable currents in the culture at large</a></li>
<li>endless legal resources to neutralize those that won’t comply with its goals</li>
<li>in some cases, relationships with law enforcement that can be used against those that won’t comply with its goals
and surely much more.</li>
</ul>
<p>Profit-maximization is the “prime directive” of the existing power structure and as a result challenging it inevitably provokes a fight.
This fight is usually waged (on their end) by making use of all the above tools and more.</p>
<h3 id="what-kind-of-power-do-you-have">What kind of power do you have?</h3>
<p>What kind of power do you, a worker at a crypto company, have to resist all of the above? On your own, basically none. If you
make too much trouble, you will simply be fired and then you’re out of luck. Some small number of people can try starting a company (which I have done)
but you’re still subject to some of the same kinds of retaliation as funding can be withheld, which either “fires” the company or redirects
it toward whatever profit-maximization opportunity is available. And even if you have an independent revenue stream, you will be competing
against firms that are willing to do whatever it takes to maximize profits.</p>
<p>As a group however, workers have an enormous amount of power. It is sometimes considered controversial to say so, but VCs and senior
management cannot actually do anything without workers. As such, if workers organize together into a strong company or industry-wide union,
they can make demands of the existing power structure and refuse to participate in the production process (i.e., strike) if those demands are not met.
This power can be augmented with legal resources, platforms of their own, etc.</p>
<p>If you are interested in building power with your fellow workers to advance your own goals rather than those of the profit-maximizers,
both within your company and across your industry, I recommend reaching out to <a href="https://techworkerscoalition.org/">Tech Workers Coalition</a>
who can provide further guidance. You can also get in touch with or <a href="https://act.dsausa.org/donate/membership2020">join your local DSA</a> to
build your analysis, help push more broadly for a world beyond profit maximization, and get support.</p>

		</div></div>]]>
            </description>
            <link>https://parametricity.com/posts/2020-power/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24638995</guid>
            <pubDate>Wed, 30 Sep 2020 14:22:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gitter Is Moving to Element]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24638802">thread link</a>) | @ingve
<br/>
September 30, 2020 | https://blog.gitter.im/2020/09/30/gitter-element-acquisition/ | <a href="https://web.archive.org/web/*/https://blog.gitter.im/2020/09/30/gitter-element-acquisition/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
				
				<div>
					<p>Yes! Another big move for Gitter! Gitter is being acquired by <a href="https://element.io/">Element</a> and will become part of the bigger <a href="https://matrix.org/">Matrix ecosystem</a>. Don’t worry, all of the Gitter things are staying around and we will continue to support your communities better than ever.</p><p>If you’re curious about what Element and Matrix is and the future of Gitter, the <a href="https://matrix.org/blog/posts">blog post over on Matrix.org</a> explains it phenomenally!</p><p>You can try out Element and see what Matrix is about by chatting and asking questions over on &nbsp;<a href="https://matrix.to/#/#gitter:matrix.org">#gitter:matrix.org</a> - which is also bridged with <a href="https://gitter.im/matrix-org/gitter">https://gitter.im/matrix-org/gitter</a>.</p><p>Thanks for keeping up with Gitter and reading about the rip-roaring times ahead!</p><p> &nbsp;– Eric, the Element team, and the whole Matrix community</p>
				</div> 
				
			</article></div>]]>
            </description>
            <link>https://blog.gitter.im/2020/09/30/gitter-element-acquisition/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24638802</guid>
            <pubDate>Wed, 30 Sep 2020 14:03:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How real-time stream processing works – a visual guide]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24638766">thread link</a>) | @rmoff
<br/>
September 30, 2020 | https://www.confluent.io/blog/how-real-time-stream-processing-works-with-ksqldb/ | <a href="https://web.archive.org/web/*/https://www.confluent.io/blog/how-real-time-stream-processing-works-with-ksqldb/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="___gatsby"><div tabindex="-1" id="gatsby-focus-wrapper"><div><section><div><p><time datetime="2020-09-29T17:50:00.000Z">September 29, 2020</time></p><div><div data-swiftype-name="body" data-swiftype-type="text"><p><a href="http://ksqldb.io/">ksqlDB</a>, the event streaming database, is becoming one of the most popular ways to work with Apache Kafka<sup>®</sup>. Every day, we answer many questions about the project, but here’s a question with an answer that we are always trying to improve: How does ksqlDB work?</p>
<p>The mechanics behind stream processing can be challenging to grasp. The concepts are abstract, and many of them involve motion—two things that are hard for the mind’s eye to visualize. Let’s pop open the hood of ksqlDB to explore its essential concepts, how each works, and how it all relates to Kafka.</p>
<p>If you like, you can follow along by executing the example code yourself. <a href="https://ksqldb.io/quickstart.html">ksqlDB’s quickstart</a> makes it easy to get up and running.</p>
<div>
<h2 id="declaring-a-stream"><a id="declaring-a-stream"></a>Declaring a stream</h2>
<p>Stream processing is a programming paradigm for computing over events as they arrive. But where do those events come from? In Kafka, you store a collection of events in a <em>topic</em>. Each event can contain any raw bytes that you want. In ksqlDB, you store events in a <em>stream</em>. A stream is a topic with a strongly defined schema. You declare it like this:</p>
<pre><code>
CREATE STREAM readings (
    sensor VARCHAR KEY,
    location VARCHAR,
    reading INT
) WITH (
    kafka_topic = 'readings',
    partitions = 3,
    value_format = 'json'
);
</code></pre>
<p>When you fire off this statement from ksqlDB’s client to its server, what actually happens? If the topic that backs this stream doesn’t exist, the server issues a call to the Kafka brokers to make a new topic with the specified number of partitions. The stream metadata, like the column layout, serialization scheme, and other information, is placed into ksqlDB’s command topic, which is its internal cluster communication channel. Each ksqlDB server materializes the command topic information to a local metadata store, giving it a global catalog of objects.</p>
<p>A newly declared stream has no data in it:</p>

</div>
<div>
<h2 id="inserting-rows"><a id="inserting-rows"></a>Inserting rows</h2>
<p>Empty collections aren’t terribly interesting. You need to write events to them to make something happen. In Kafka, you model an event as a <em>record</em> and put it into a topic. In ksqlDB, you model an event as a <em>row</em> and put it into a stream. A row is just a record with additional metadata. You <em>insert</em> rows like this:</p>
<pre><code>
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-1', 'wheel', 45);
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-2', 'motor', 41);
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-1', 'wheel', 42);
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-3', 'muffler', 42);
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-3', 'muffler', 40);

INSERT INTO readings (sensor, location, reading) VALUES ('sensor-4', 'motor', 43);
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-6', 'muffler', 43);
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-5', 'wheel', 41);
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-5', 'wheel', 42);
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-4', 'motor', 41);

INSERT INTO readings (sensor, location, reading) VALUES ('sensor-7', 'muffler', 43);
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-8', 'wheel', 40);
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-9', 'motor', 40);
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-9', 'motor', 44);
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-7', 'muffler', 41);
</code></pre>
<p>Each time you invoke an <code>INSERT</code> statement, a request with the payload is sent to a ksqlDB server. The server checks that the shape of the data is coherent with respect to the stream’s schema—malformed rows are rejected. If the row’s data types are sane, the server creates a record and automatically serializes its content using the format of choice as defined in the stream’s declaration. It uses the Kafka producer client to insert that record into the backing Kafka topic. All of the stream’s data is persisted on directly on the broker. None of it lives in ksqlDB’s servers.</p>
<p>After the inserts complete, the stream now looks like what you see below. Hover over each row to see its contents—the data displayed describes the underlying Kafka record. Notice how the rows are ordered by offset from right to left. In the animations you’ll see below, time is depicted as flowing rightward.</p>

<p>Why does some of the row data end up in the key of the record and some in the value? ksqlDB superimposes a flat column abstraction on top of Kafka’s key/value model. Here’s how it works in this case.</p>
<p>In the declaration of the stream, <code>sensor</code> is qualified with the <code>KEY</code> keyword. That piece of syntax tells ksqlDB to look for the data for this column in the key portion of the record. The data for other columns is read from the record’s value. When ksqlDB produces the record to the underlying topic, its key content is hashed to select a partition for it to reside in. This causes all rows with the same key to be written to the same partition, which is a useful <a href="https://docs.confluent.io/current/kafka/introduction.html#topics-and-logs">ordering guarantee</a>.</p>
</div>
<div>
<h2 id="transforming-a-stream"><a id="transforming-a-stream"></a>Transforming a stream</h2>
<p>No one ever sends data to Kafka just to let it sit there. You always want to do something with it. And most often, the data isn’t yet in the exact form that you need in order to work with it. You need to change it in some way.</p>
<p>The most elementary way you could do this is by writing a program that uses the Kafka producer and consumer clients. The program would read from the source topic whose data you want to change, apply a function to each record, and write the new record to the output topic. It would loop and run forever. This works, but it is rather low-level. You need to manage schemas, serializers, partitioning strategies, and other pieces of configuration.</p>
<p>In ksqlDB, you issue a <em>persistent query</em> to <em>transform</em> one stream into another using its SQL programming model. You derive a new stream from an existing one by selecting and manipulating columns of interest:</p>
<pre><code>
-- process from the beginning of each stream
set 'auto.offset.reset' = 'earliest';
                
CREATE STREAM clean AS
    SELECT sensor,
           reading,
           UCASE(location) AS location
    FROM readings
    EMIT CHANGES;
</code></pre>
<p>Persistent queries are little stream processing programs that run indefinitely. In this case, it continually reads rows from <code>readings</code>, applies the transformation logic, and writes rows to <code>clean</code>. You are relieved of all data janitorial work: There are no schemas to manage, no serializers to configure, no partitioning strategies to choose. But what is actually happening when you launch this query?</p>
<p>Each time you run a persistent query, ksqlDB’s server compiles the query’s textual representation to a physical execution plan as a Kafka Streams topology. The topology runs as a daemon, reacting to new topic records as soon as they become available. This means that all of the processing work happens on ksqlDB server; no processing work happens on the Kafka brokers. If you run ksqlDB as a cluster, the topology scales horizontally across the nodes by internally using Kafka Streams application IDs.</p>
<p>When everything is connected together and the data is flowing, it looks like this. Take it in for a few moments—we’ll walk through it in detail below.</p>

<p>What is going on here? What do the moving arrows mean? Why are those numbers changing? And what is <code>pq1</code>?</p>
<p>When a persistent query is created, it is assigned a generated name (in this case, we call it <code>pq1</code>). Rows are read from the stream partitions that the query selects from. As each row passes through the persistent query, the transformation logic is applied to create a new row, which is what the change of color signifies. Reading a record from Kafka does not delete it—you effectively receive a copy of it. That is why the leftmost rows remain in place, and clones of them appear to the right of each partition before they are sent to the persistent query box.</p>
<p>Persistent queries completely manage their own processing progression, even in the presence of faults. ksqlDB durably maintains the highest offset of each input partition. The incrementing numbers underneath the query box describe those values at each point in time. Moreover, the arrows that move from right to left on the input streams show the corresponding offsets currently being processed, giving you a spatial sense of progress. (If you’re an experienced Kafka user, note that these aren’t the <em>committed</em> offsets.)</p>
<p>Pause the animation and hover over the output rows. Notice how the column that the transformation targets has changed, while all the other columns remain intact. ksqlDB has taken care of all the bookkeeping for you.</p>
<p>As you watch the data flowing through the topology, you might be wondering how ksqlDB chooses which input partition it will read from next. Is it random? Is it round robin? The answer to that question is the foundation of how ksqlDB deals with out-of-order data, and it’s something that we’ll describe in a future blog post all on its own. (Spoiler: <a href="https://www.confluent.io/resources/kafka-summit-2020/the-flux-capacitor-of-kafka-streams-and-ksqldb">It picks the smallest timestamp available</a>.)</p>
</div>
<div>
<h2 id="filtering-rows-out-of-stream"><a id="filtering-rows-out-of-stream"></a>Filtering rows out of a stream</h2>
<p>Let’s look at another simple operation: filtering. Filters are used to discard rows that you do not need or want. Just like transforms, filters are specified using simple SQL syntax.</p>
<pre><code>
CREATE STREAM high_readings AS
    SELECT sensor, reading, location
    FROM clean
    WHERE reading &gt; 41
    EMIT CHANGES;
</code></pre>
<p>When you write ksqlDB programs, you chain streams (and tables) together. You create a figurative pathway for your data to traverse, with each step in the way performing a step of processing. ksqlDB handles the mechanics of how your data is propagated through the chain.</p>

<h2 id="combining-many-operations"><a id="combining-many-operations"></a>Combining many operations into one</h2>
<p>A crucial rule of thumb in data processing is that you should get rid of data that you don’t need as early as possible. The longer you keep irrelevant data around, the higher the cost to repeatedly store, process, and transfer it. If you use the Kafka client to process data, it is up to you to manage where each processing step takes place.</p>
<p>In…</p></div></div></div></div></section></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.confluent.io/blog/how-real-time-stream-processing-works-with-ksqldb/">https://www.confluent.io/blog/how-real-time-stream-processing-works-with-ksqldb/</a></em></p>]]>
            </description>
            <link>https://www.confluent.io/blog/how-real-time-stream-processing-works-with-ksqldb/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24638766</guid>
            <pubDate>Wed, 30 Sep 2020 13:59:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Random forest classifier from scratch in Python]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24638370">thread link</a>) | @the_origami_fox
<br/>
September 30, 2020 | https://liorsinai.github.io/coding/2020/09/29/random-forests.html | <a href="https://web.archive.org/web/*/https://liorsinai.github.io/coding/2020/09/29/random-forests.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
      <div>

        <p><em>A random forest classifier in 270 lines of Python code. It is written from (almost) scratch. It is modelled on Scikit-Learn’s RandomForestClassifier.</em></p>

<figure>
<img src="https://liorsinai.github.io/assets/posts/random-forests/Random_forest_diagram_complete.png" alt="Simplified random forest">
<figcaption>Simplified random forest classifier (source unknown) </figcaption>
</figure>

<p>I recently learnt about Random Forest Classifiers/Regressors. It is a supervised machine learning technique that performs well on interpolation problems. 
It was formally introduced in 2001 by <a href="https://link.springer.com/article/10.1023/A:1010933404324">Leo Breiman</a>.
They are much easier to train and much smaller than the more modern, but more powerful, neural networks.
They are often included in major machine learning software and libraries, including R and Scikit-learn.</p>

<p>There are many article describing the theory behind random forests. See for example <a href="https://www.kdnuggets.com/2017/10/random-forests-explained.html]">1</a> or <a href="https://towardsdatascience.com/an-implementation-and-explanation-of-the-random-forest-in-python-77bf308a9b76">2</a>. 
By far the best and most detailed explanation I have seen is given by Jeremy Howard in his <a href="https://course18.fast.ai/lessonsml1/lessonsml1.html]">FastAI course</a>.
A few sources describe how to implement them from scratch, such as <a href="https://carbonati.github.io/posts/random-forests-from-scratch/">3</a> or <a href="https://machinelearningmastery.com/implement-random-forest-scratch-python/">4</a>.</p>

<p>My aim here is to describe my own implementation of a random forest from scratch for teaching purposes. It is assumed the reader is already familiar with the theory. 
I hope this post will clarify in-depth questions.
The first version was based on the code in the FastAI course, but I have made it more advanced. The full code can be accessed at my Github <a href="https://github.com/LiorSinai/randomForests">repository</a>. 
The version presented here is slightly simpler and more compact.</p>

<p>Scikit-learn’s <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html">RandomForestClassifier</a> is far superior to mine. 
It is written in several thousand lines of code; mine was written in just 270.
The main advantages of it are:</p>
<ul>
  <li>it is much faster (by more than 100x) because it is written in Cython, utilises multiple cores to parallelise jobs and also because of more advanced coding optimisation algorithms.</li>
  <li>it has more options and features for the user.</li>
  <li>it does more data validation and input checking.</li>
</ul>

<p>Having been inspired by Jeremy Howard’s teaching methods, I will present this post in a top-down fashion.
First I’ll introduce two datasets and show how the random forest classifier can be used on them.
Next, I’ll explain the top level <code>RandomForestClassifier</code> class, then the <code>DecisionTree</code> class it is composed of, 
and finally the <code>BinaryTree</code> class that that is composed of.
All code is also explained top-down.</p>

<h2 id="practice-data-sets">Practice Data Sets</h2>

<h3 id="the-iris-flower-dataset">The Iris flower dataset</h3>

<p>The <a href="https://en.wikipedia.org/wiki/Iris_flower_data_set">Iris flower dataset</a> is commonly used for beginner machine learning problems. The full dataset can be found on Kaggle at 
<a href="https://www.kaggle.com/arshid/iris-flower-dataset">www.kaggle.com/arshid/iris-flower-dataset</a>. 
It consists of 150 entries for 3 types of iris plants, and 4 features: sepal length and width, and petal length and width.<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup></p>

<p>The variable distributions are as follows:</p>
<figure>
<img src="https://liorsinai.github.io/assets/posts/random-forests/Iris_features.png" alt="Feature distributions for the Iris flower dataset">
</figure>

<p>Based on these, a simple baseline model can be developed:</p>
<ol>
  <li>If PetalLength &lt; 2.5cm, class is Setosa.</li>
  <li>Else determine scores score1 and score2 as follows:
	  <ul>
		 <li> score1: add 1 for each of the following that is true:
			 <ul>
			   <li> 2.5cm &lt; PetalLength ≤ 5.0cm </li>
			   <li> 1.0cm≤ PetalWidth ≤ 1.8cm </li>
			 </ul>
		 </li>
		 <li> score2: add 1 for each of the following that is true:
			<ul>
			   <li> 7.0cm≤ SepalLength  </li>
			   <li> 3.5cm≤ SepalWidth  </li>
			   <li> 5.0cm≤ PetalLength  </li>
			   <li> 1.7cm&lt; PetalWidth  </li>
			</ul>
		 </li>
	  </ul>
   </li>
   <li>If score1&nbsp;&gt;&nbsp;score2, classify as Veriscolor. If score1&nbsp;&lt;&nbsp;score2, classify as Virginica. If score1&nbsp;=&nbsp;score2, leave unknown, or classify at random. </li>
</ol>
<p>This simple strategy guarantees that 140 samples, which is 93.3% of the samples, will be correctly classified.</p>

<p>I used my code to make a random forest classifier with the following parameters:</p>

<p><code>forest = RandomForestClassifier(n_trees=10, bootstrap=True, max_features=2, min_samples_leaf=3)</code></p>

<p>I randomly split the data into 120 training samples and 30 test samples.
The forest took 0.23 seconds to train. 
It had trees with depths in the range of 3 to 7, and 65 leaves in total.
It  misclassified one sample in the training and test set each, for an accuracy of 99.2% and 96.7% respectively.
This is a clear improvement on the baseline.</p>

<p>This is a simple  flattened representation of one of the trees. Each successive dash represents a level lower in the tree, and left children come before right:</p>

<figure><pre><code data-lang="python"><span>000</span>  <span>n_samples</span><span>:</span> <span>120</span><span>;</span> <span>value</span><span>:</span> <span>[</span><span>43</span><span>,</span> <span>39</span><span>,</span> <span>38</span><span>];</span> <span>impurity</span><span>:</span> <span>0.6657</span><span>;</span> <span>split</span><span>:</span> <span>PetalLength</span><span>&lt;=</span><span>2.450</span>
<span>001</span> <span>-</span> <span>n_samples</span><span>:</span> <span>43</span><span>;</span> <span>value</span><span>:</span> <span>[</span><span>43</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>];</span> <span>impurity</span><span>:</span> <span>0.0000</span>
<span>002</span> <span>-</span> <span>n_samples</span><span>:</span> <span>77</span><span>;</span> <span>value</span><span>:</span> <span>[</span><span>0</span><span>,</span> <span>39</span><span>,</span> <span>38</span><span>];</span> <span>impurity</span><span>:</span> <span>0.4999</span><span>;</span> <span>split</span><span>:</span> <span>PetalLength</span><span>&lt;=</span><span>4.750</span>
<span>003</span> <span>--</span> <span>n_samples</span><span>:</span> <span>34</span><span>;</span> <span>value</span><span>:</span> <span>[</span><span>0</span><span>,</span> <span>34</span><span>,</span> <span>0</span><span>];</span> <span>impurity</span><span>:</span> <span>0.0000</span>
<span>004</span> <span>--</span> <span>n_samples</span><span>:</span> <span>43</span><span>;</span> <span>value</span><span>:</span> <span>[</span><span>0</span><span>,</span> <span>5</span><span>,</span> <span>38</span><span>];</span> <span>impurity</span><span>:</span> <span>0.2055</span><span>;</span> <span>split</span><span>:</span> <span>PetalWidth</span><span>&lt;=</span><span>1.750</span>
<span>005</span> <span>---</span> <span>n_samples</span><span>:</span> <span>7</span><span>;</span> <span>value</span><span>:</span> <span>[</span><span>0</span><span>,</span> <span>4</span><span>,</span> <span>3</span><span>];</span> <span>impurity</span><span>:</span> <span>0.4898</span><span>;</span> <span>split</span><span>:</span> <span>SepalWidth</span><span>&lt;=</span><span>2.650</span>
<span>006</span> <span>----</span> <span>n_samples</span><span>:</span> <span>3</span><span>;</span> <span>value</span><span>:</span> <span>[</span><span>0</span><span>,</span> <span>1</span><span>,</span> <span>2</span><span>];</span> <span>impurity</span><span>:</span> <span>0.4444</span>
<span>007</span> <span>----</span> <span>n_samples</span><span>:</span> <span>4</span><span>;</span> <span>value</span><span>:</span> <span>[</span><span>0</span><span>,</span> <span>3</span><span>,</span> <span>1</span><span>];</span> <span>impurity</span><span>:</span> <span>0.3750</span>
<span>008</span> <span>---</span> <span>n_samples</span><span>:</span> <span>36</span><span>;</span> <span>value</span><span>:</span> <span>[</span><span>0</span><span>,</span> <span>1</span><span>,</span> <span>35</span><span>];</span> <span>impurity</span><span>:</span> <span>0.0540</span><span>;</span> <span>split</span><span>:</span> <span>SepalLength</span><span>&lt;=</span><span>5.950</span>
<span>009</span> <span>----</span> <span>n_samples</span><span>:</span> <span>5</span><span>;</span> <span>value</span><span>:</span> <span>[</span><span>0</span><span>,</span> <span>1</span><span>,</span> <span>4</span><span>];</span> <span>impurity</span><span>:</span> <span>0.3200</span>
<span>010</span> <span>----</span> <span>n_samples</span><span>:</span> <span>31</span><span>;</span> <span>value</span><span>:</span> <span>[</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>31</span><span>];</span> <span>impurity</span><span>:</span> <span>0.0000</span></code></pre></figure>

<p>The value is the number of samples in each class in that node. The impurity is a measure of the mix of classes in the node. A pure node has only 1 type of class and 0 impurity.
More will be explained on this later.
The split is the rule for determining which values go to the left or right child.
For example, the first split is almost the same as the first rule in the baseline model.</p>

<h3 id="universal-bank-loans">Universal Bank loans</h3>

<p>The next dataset I tested was the Bank_Loan_Classification dataset available on Kaggle at <a href="http://www.kaggle.com/sriharipramod/bank-loan-classification/">www.kaggle.com/sriharipramod/bank-loan-classification/</a>.
This dataset has 5000 entries with 11 features. The target variable is “Personal Loan”, and it can be 0 or 1. (Personal Loan approved? Or paid? I don’t know.)</p>

<p>The variable distributions are as follows:</p>
<figure>
<img src="https://liorsinai.github.io/assets/posts/random-forests/UniversalBank_features.png" alt="Feature distributions for the Universal Bank loans dataset">
</figure>

<p>The Pearson correlation coefficients between the features and the target variables are:</p>
<table>
<thead>
  <tr>
    <th></th>
    <th>Feature</th>
    <th>Correlation</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>1</td>
    <td>Income</td>
    <td>0.5025</td>
  </tr>
  <tr>
    <td>2</td>
    <td>CCAvg</td>
    <td>0.3669</td>
  </tr>
  <tr>
    <td>3</td>
    <td>CD Account</td>
    <td>0.3164</td>
  </tr>
  <tr>
    <td>4</td>
    <td>Mortgage</td>
    <td>0.1421</td>
  </tr>
  <tr>
    <td>5</td>
    <td>Education</td>
    <td>0.1367</td>
  </tr>
  <tr>
    <td>6</td>
    <td>Family</td>
    <td>0.0614</td>
  </tr>
  <tr>
    <td>7</td>
    <td>Securities Account</td>
    <td>0.0220</td>
  </tr>
  <tr>
    <td>8</td>
    <td>Experience</td>
    <td>-0.0074</td>
  </tr>
  <tr>
    <td>9</td>
    <td>Age</td>
    <td>-0.0077</td>
  </tr>
  <tr>
    <td>10</td>
    <td>Online</td>
    <td>0.0063</td>
  </tr>
  <tr>
    <td>11</td>
    <td>CreditCard</td>
    <td>0.0028</td>
  </tr>
</tbody>
</table>

<p>For the baseline model, we could always predict a 0, and claim an accuracy of 90.4%. 
But this has an F1 score of 0.<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup> A better baseline is simply to have: 1 if Income&nbsp;&gt;&nbsp;100 else 0. This has an accuracy of 83.52% and a F1 score of  0.516 over the whole dataset.</p>

<p>I used my code to make a random forest classifier with the following parameters:</p>

<p><code>forest = RandomForestClassifier(n_trees=20, bootstrap=True, max_features=3, min_samples_leaf=3)</code></p>

<p>I randomly split the data into 4000 training samples and 1000 test samples and trained the <code>forest</code> on it.
The forest took about 10 seconds to train.
The trees range in depth from 11 to 17, with 51 to 145 leaves. The total number of leaves is 1609.
The training accuracy is 99.60% and the test accuracy is 98.70%. The F1 score for the test set is 0.926.
This is a large improvement on the baseline, especially for the F1 score.</p>

<p>We can inspect the random forest and calculate a feature importance for each feature. The following graph is a comparison between two types of (normalised) feature importances. 
The orange bars are based on how much that feature contributes to decreasing the impurity levels in the tree.
The blue bars are based on randomly scrambling that feature column, and recording how much this decreases the overall accuracy of the model.
More detail on these calculations will be given later.</p>

<figure>
<img src="https://liorsinai.github.io/assets/posts/random-forests/UniversalBank_feature_importances.png" alt="Feature importances for the Universal Bank classifier">
</figure>

<h2 id="code">Code</h2>
<h3 id="randomforestclassifier">RandomForestClassifier</h3>

<p>The first step is create the <code>RandomForestClassifier</code>. Initialising an instance of the class only sets the internal parameters and does not fit the data, 
as with the equivalent Scikit-learn class. I’ve included the most important parameters from Scikit-learn, and added one of my own, <code>sample_size</code>.<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup> 
This parameter sets the sample size used to make each tree. If <code>bootstrap=False</code>, it will randomly select a subset of unique samples for the training dataset. 
If <code>bootstrap=True</code>, it will randomly draw samples with replacement from the dataset, which will most likely result in duplicate samples.</p>

<figure><pre><code data-lang="python"><span>import</span> <span>numpy</span> <span>as</span> <span>np</span>
<span>import</span> <span>pandas</span> <span>as</span> <span>pd</span>
<span>import</span> <span>warnings</span>
<span>from</span> <span>DecisionTree</span> <span>import</span> <span>DecisionTree</span>
<span>from</span> <span>utilities</span> <span>import</span> <span>*</span>

<span>class</span> <span>RandomForestClassifier</span><span>:</span>
    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>n_trees</span><span>=</span><span>100</span><span>,</span> <span>random_state</span><span>=</span><span>None</span><span>,</span> <span>max_depth</span><span>=</span><span>None</span><span>,</span>  
                 <span>max_features</span><span>=</span><span>None</span><span>,</span> <span>min_samples_leaf</span><span>=</span><span>1</span><span>,</span> <span>sample_size</span><span>=</span><span>None</span><span>,</span> 
                 <span>bootstrap</span><span>=</span><span>True</span><span>,</span>  <span>oob_score</span><span>=</span><span>False</span><span>):</span>
        <span>self</span><span>.</span><span>n_trees</span> <span>=</span> <span>n_trees</span>
        <span>self</span><span>.</span><span>RandomState</span> <span>=</span> <span>check_RandomState</span><span>(</span><span>random_state</span><span>)</span>
        <span>self</span><span>.</span><span>max_depth</span> <span>=</span> <span>max_depth</span>
        <span>self</span><span>.</span><span>max_features</span> <span>=</span> <span>max_features</span>
        <span>self</span><span>.</span><span>min_samples_leaf</span><span>=</span><span>min_samples_leaf</span>
        <span>self</span><span>.</span><span>sample_size</span> <span>=</span> <span>sample_size</span>
        <span>self</span><span>.</span><span>bootstrap</span> <span>=</span> <span>bootstrap</span>
        <span>self</span><span>.</span><span>oob_score</span> <span>=</span> <span>oob_score</span></code></pre></figure>

<p>I’ve shown the imports for two internal modules, <code>DecisionTree</code> which I’ll describe later, and <code>utilities</code>, which imports some useful functions.
Many of those are also part of the Sklearn package; I just wanted my code to be completely independent. 
If you wish to see these, have a look at the Github <a href="https://github.com/LiorSinai/randomForests">repository</a></p>

<p>The supervised learning is done by calling the <code>fit()</code> function. 
First it internally one-hot encodes the target variable <em>Y</em>, which makes it easier to deal with multiple categories.
Then it creates the trees one at a time. 
Most of the heavy lifting is done by other functions. 
Afterwards, it sets attributes including the feature importances and the out-of-bag (OOB) score. 
The random state is saved before each tree is made, because this can be used to exactly regenerate the random indices for the OOB score.
This is much more memory efficient than saving the whole list of random indices for each tree.</p>

<figure><pre><code data-lang="python"><span>def</span> <span>fit</span><span>(</span><span>self</span><span>,</span> <span>X</span><span>,</span> <span>Y</span><span>):</span>
    <span>if</span> <span>Y</span><span>.</span><span>ndim</span> <span>==</span> <span>1</span><span>:</span>
        <span>Y</span> <span>=</span> <span>encode_one_hot</span><span>(</span><span>Y</span><span>)</span> <span># one-hot encoded y variable
</span>
    <span># set internal variables
</span>    <span>self</span><span>.</span><span>n_features</span> <span>=</span> <span>X</span><span>.</span><span>shape</span><span>[</span><span>1</span><span>]</span>
    <span>self</span><span>.</span><span>n_classes</span> <span>=</span> <span>Y</span><span>.</span><span>shape</span><span>[</span><span>1</span><span>]</span>
    <span>self</span><span>.</span><span>features</span> <span>=</span> <span>X</span><span>.</span><span>columns</span>
    <span>n_samples</span> <span>=</span> <span>X</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>]</span>
    <span>self</span><span>.</span><span>sample_size_</span> <span>=</span> <span>n_samples</span> <span>if</span> <span>self</span><span>.</span><span>sample_size</span> <span>is</span> <span>None</span> <span>else</span> <span>self</span><span>.</span><span>sample_size</span>

    <span># create decision trees
</span>    <span>self</span><span>.</span><span>trees</span> <span>=</span> <span>[]</span>
    <span>rng_states</span> <span>=</span> <span>[]</span> <span># save the random states to regenerate the random indices for the oob_score
</span>    <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>self</span><span>.</span><span>n_trees</span><span>):</span>
        <span>rng_states</span><span>.</span><span>append</span><span>(</span><span>self</span><span>.</span><span>RandomState</span><span>.</span><span>get_state</span><span>())</span>
        <span>self</span><span>.</span><span>trees</span><span>.</span><span>append</span><span>(</span><span>self</span><span>.</span><span>_create_tree</span><span>(</span><span>X</span><span>,</span> <span>Y</span><span>))</span>

    <span># set …</span></code></pre></figure></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://liorsinai.github.io/coding/2020/09/29/random-forests.html">https://liorsinai.github.io/coding/2020/09/29/random-forests.html</a></em></p>]]>
            </description>
            <link>https://liorsinai.github.io/coding/2020/09/29/random-forests.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24638370</guid>
            <pubDate>Wed, 30 Sep 2020 13:11:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: We just cracked the problem with sneaker drops and sold out]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24638290">thread link</a>) | @skorski
<br/>
September 30, 2020 | https://gothelist.com/initial-product-offering | <a href="https://web.archive.org/web/*/https://gothelist.com/initial-product-offering">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<div>
<p><img src="https://gothelist.com/media/wysiwyg/products.gif" alt="No Waitlist"></p><h2>No Waitlist.</h2>
<h4>Introducing Initial Product Offering</h4>
<p>Get immediate access and shop highly demanded, limited and hard-to-get products without VIP status, waiting list or queue via IPOs in THE LIST App.</p>

</div>
</div>
<div>
<div>
<p><img src="https://gothelist.com/media/wysiwyg/listed.png" alt="LISTED.">
</p>
<div>
<h2>LISTED.</h2>
<p>We skip the waitlist for you. <br>Highly covetable items, collections &amp; <br>rare, unique products are listed <br>daily at 9:30 AM EST NYC.</p>
</div>
</div>
</div>
<div>
<div>
<p><img src="https://gothelist.com/media/wysiwyg/includes.gif" alt="MUST-HAVES INCLUDED.">
</p>
<div>
<h2>MUST-HAVES <br>INCLUDED.</h2>
<p>THE LIST App offers you over 1,200 brands, <br>from established luxury brands <br>to the coolest, emerging designer labels.</p>
</div>
</div>
</div>
<div>
<div>
<h2>HOW DOES IT WORK<span>?</span></h2>
<div>
<h2>HOW DOES IT WORK<span>?</span></h2>
<h2>SHOP.</h2>
<p>Purchase a product during an IPO <br>for a limited time period <br>at dynamic market price <br>depending on how demanded <br>a product is. Better be fast!</p>
</div>
<p><img src="https://gothelist.com/media/wysiwyg/how-does-it-works.png" alt="HOW DOES IT WORK?">
</p>
</div>
</div>
<div>
<div>
<p><img src="https://gothelist.com/media/wysiwyg/pay1.png" alt="PAY.">
</p>
<div>
<h2>PAY.</h2>
<p>Secure your piece fast <br>within the price lockdown. <br>Only pay a deposit when placing the order, <br>and the remaining balance, <br>once the item is ready to ship.</p>
</div>
</div>
</div>
<div>
<div>
<div>
<h2>GET.</h2>
<p>Your order will be directly delivered <br>from the authorized retailer to you <br>via express shipping.</p>
</div>
<p><img src="https://gothelist.com/media/wysiwyg/get1.png" alt="GET.">
</p>
</div>
</div>
<div>
<div>
<h2>What are you waiting for<span>?</span></h2>

</div>
</div>
</div></div>]]>
            </description>
            <link>https://gothelist.com/initial-product-offering</link>
            <guid isPermaLink="false">hacker-news-small-sites-24638290</guid>
            <pubDate>Wed, 30 Sep 2020 13:01:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Revisiting a 'Smaller Rust']]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24638129">thread link</a>) | @gbrown_
<br/>
September 30, 2020 | https://without.boats/blog/revisiting-a-smaller-rust/ | <a href="https://web.archive.org/web/*/https://without.boats/blog/revisiting-a-smaller-rust/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
			<p>A bit over a year ago, I wrote some <a href="https://without.boats/blog/notes-on-a-smaller-rust">notes on a “smaller Rust”</a> - a higher level language
that would take inspiration from some of Rust’s type system innovations, but would be simpler by
virtue of targeting a domain with less stringent requirements for user control and performance.
During my time of unemployment this year, I worked on sketching out what a language like that would
look like in a bit more detail. I wanted to write a bit about what new conclusions I’ve come to
during that time.</p>
<h2 id="the-purpose-for-our-language">The purpose for our language</h2>
<p>Re-reading my previous post, I’m struck by how vague my statement of purpose for this language is.
My entire blog post is really focused on differentiating the language from <em>Rust</em>, and I frame the
discussion in terms of what I would remove from Rust, and how the language would not support certain
use cases of Rust. This isn’t really surprising: I was working on Rust, and I never had taken the
time to think of this hypothetical language in itself the way I have now.</p>
<p>The goal of this design was to create a language that could compete as an “application programming
language.” The design goals of this language were:</p>
<ol>
<li>It should try not to be notably hard to learn. To the extent possible, it should be familiar to
most programmers. Since I’m comitting by the exercise to trying to apply ownership and borrowing
to the application domain, it will necessarily contain some features most programmers find
pretty novel (like Rust “lifetimes”). But in general, we will try to reduce the onboarding ramp
and simplify things.</li>
<li>It should typecheck and compile quickly. It should not have bad batch compilation performance,
and it should be designed with incremental recompilation in mind, to enable a good experience for
users who integrate their compiler into their development environment (with a full IDE or even
just with a plugin for a text editor). I didn’t even mention this concern in the previous post.
As others have discussed elsewhere; Rust’s poor compile times are not the result of its advanced
type system, but of a combination of other factors. Some are essential, like the runtime
guarantees it makes (e.g. monomorphization) whereas others are accidental, like some aspects of
its module system. None of these factors would be essential for our language, so we would
carefully avoid these pitfalls.</li>
<li>It should have a runtime which suits it well to the major use cases for application programming
languages today. This means mainly being well suited to the developing for the web, both
front-end and back-end. (Being well-suited to the mobile platforms is unrealistic for a language
not sponsored by those platform developers, unfortunately.) Being well-suited to CLIs would also
be beneficial.</li>
</ol>
<p>I want to focus the rest of this post on my thoughts for evolving Rust’s ownership and borrowing
system, but before I do that I want to briefly touch on other design decisions that fell out of this
thought process:</p>
<ul>
<li>I would target WASM, and only WASM, for this language. WASM with reference types is suitable as
an environment for application programming (with shims for future extensions like properly
integrated garbage collection). This way the language designers can piggy back on the work being
done at many companies to establish WASM as a good shared VM platform, instead of being
responsible for things like platform compatibility or using the very slow LLVM. Targeting WASM
would also mean easier FFI integration into other languages that run on the same VM as WASM; that
is, other languages targeting WASM (like Rust) and JavaScript.</li>
<li>I would explore control-flow-capturing closures as a core language abstraction, similar to Kotlin.
As I wrote in <a href="https://without.boats/blog/the-problem-of-effects">an earlier blog post</a> inspired by the design on this hypothetical
language, I think these are a great way to integrate effects well with higher order function
abstractions.</li>
<li>I would provide syntactic sugar for <code>Result</code> and <code>Option</code> as the way to handle null and errors,
similar to Swift.</li>
<li>As I wrote in a previous blog post, I would provide green threads as the sole concurrency model,
with language or standard library provided channels and cells (discussed later) as the way of
sharing data between threads. How these green threads are mapped to CPUs is a matter for the
runtime you choose to run the compiled WASM in.</li>
<li>I didn’t get to the point of designing a polymorphism system; I would probably start with a
strenuous comparison of Rust’s traits and Go’s interfaces, and (knowing the other features of the
language) try to figure out what from Rust’s traits is unimportant.</li>
<li>I would be hope the language could avoid macros, which (in the case of pattern based macros) add a
second meta language to the language that advanced users need to understand, and in all cases
substantially complicate compilation.</li>
</ul>

<p>But now onto the meat of this post: the ownership and borrowing model. In my previous post I made
some points that I largely agree with still, but would probably reframe. Here’s what I wrote:</p>
<blockquote>
<p>Rust works because it enables users to write in an imperative programming style, which is the
mainstream style of programming that most users are familiar with, while avoiding to an impressive
degree the kinds of bugs that imperative programming is notorious for. As I said once, pure
functional programming is an ingenious trick to show you can code without mutation, but Rust is an
even cleverer trick to show you can just have mutation.</p>
<p>…</p>
<p><strong>Resource acquisition is initialization:</strong> Objects should manage conceptual resources like file
descriptors and sockets, and have destructors which clean up resource state when the object goes
out of scope. It should be trivial to be confident the destructor will run when the object goes
out of scope. This necesitates most of ownership, moving, and borrowing.</p>
<p><strong>Aliasable XOR mutable:</strong> The default should be that values can be mutated only if they are not
aliased, and there should be no way to introduce unsynchronized aliased mutation. However, the
language should support mutating values. The only way to get this is the rest of ownership and
borrowing, the distinction between borrows and mutable borrows and the aliasing rules between
them.</p>
<p>In other words, the core, commonly identified “hard part” of Rust - ownership and borrowing - is
essentially applicable for any attempt to make checking the correctness of an imperative program
tractable. So trying to get rid of it would be missing the real insight of Rust, and not building
on the foundations Rust has laid out.</p>
</blockquote>
<p>I still think this is Rust’s “secret sauce” and it does mean what I said: the language would have to
have ownership and borrowing. But what I’ve realized since is that there’s a very important
distinction between the cases in which users <em>want</em> these semantics and the cases where they largely
get in the way. This distinction is between types which represent <em>resources</em> and types which
represent <em>data</em>.</p>
<p>In this mental model, resources are types which represent “a thing” - something with an identity and
a state which can change with time as the program executes. In Rust, almost everything is a
resource: a String is a resource a HashMap is a resource, most user types are resources. In
contrast, data types are just “information” - a fact, which has no meaningful identity, contains no
state that evolves over time, etc. In Rust, types like integers, <code>&amp;str</code>, and so on - which all
implement <code>Copy</code> - are data types. (However, a mutable reference to those types is a resource: more
on this later.)</p>
<p>In Rust, only types which can be cloned by a mempcy can implement <code>Copy</code>. This is because Rust is
designed to encourage treating all heap memory as a <em>resource</em>, the management of which the end
user can control by selecting when the type representing that memory is dropped. This is very
valuable in the domains which Rust is intended to target. However, for higher level applications
that most programmers write, control over heap memory is not <em>usually</em> important. This is what users
mean when they want to “turn off the borrow checker” - they want to let a garbage collector figure
it out for them when this bit of data is freed, because to them it is “just data” and not a
resource.</p>
<p>This hypothetical language would lean into that distinction. Using persistent data structures (like
those from Clojure) and garbage collection, the set of types which could be treated as data types
would not be restricted in this language. The string type would be a data type, rather than
a resource; a dynamically sized array of data types would be a data type as well, as would a map
with keys and values that are data types.</p>
<p>Meanwhile, types representing IO objects would always be resource types. Collections containing
resource types would also be resource types. Composite types (like structs and enums) which contain
a resource type would also have to be a resource type. There would be an easy way to convert data
types to fully owned resource types as well; in the case of persistent data structures, converting
a data type to a resource type would be the point at which the “copy on write” operation occurs.
As a result users can use ownership semantics for things which impact global and external state
(like IO) and for cases where they know it will be an important performance optimization.</p>
<p>And the difference in how the language treats data and resources would be identical to the
difference between how Rust treats Copy and non-Copy types. Only resources would have affine
“ownership” semantics - in which moving them invalidates the previous binding. Data types would have
the standard non-linear semantics users are familiar with from most languages. This means that
writing algorithms using data types would be functionally the same as writing algorithms in other
imperative languages, easing the onboarding of users to the language and limiting their errors
related to linear types to areas where they are certain to care.</p>
<h2 id="borrowing-and-the-two-reference-types">Borrowing and the two reference types</h2>
<p>The previous discussion covers the ground of …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://without.boats/blog/revisiting-a-smaller-rust/">https://without.boats/blog/revisiting-a-smaller-rust/</a></em></p>]]>
            </description>
            <link>https://without.boats/blog/revisiting-a-smaller-rust/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24638129</guid>
            <pubDate>Wed, 30 Sep 2020 12:38:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Hidden Costs from a DevOps Perspective]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24637836">thread link</a>) | @gimmecoffee
<br/>
September 30, 2020 | https://pushbuildtestdeploy.com/on-hidden-costs-and-the-value-of-devops/ | <a href="https://web.archive.org/web/*/https://pushbuildtestdeploy.com/on-hidden-costs-and-the-value-of-devops/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

<p><img src="https://pushbuildtestdeploy.com/images/hidden-cost-devops.png" alt=""></p>

<p>When you think about cost in the DevOps world, the first thing that will come to mind is your AWS bill, or maybe that Datadog subscription. However, the cost is not always as straightforward as receiving an invoice, and in the DevOps world, the hidden cost is about doing it wrong.</p>

<p>I believe that being aware of hidden costs is a “mental model” you can use when making decisions. Without taking it to account, you are making bets with only half of the information.</p>

<p>Hidden cost takes on many forms in DevOps:</p>

<ul>
<li>Idle developers are waiting for builds to finish.</li>
<li>Over architected Jira workflows that take forever to go through - Jireaucracy (not my term).</li>
<li>Automating things that don’t need to scale - we are all lazy engineers who would rather spend a full day scripting something than doing 5 minutes of manual work.</li>
<li>Trying to save cost where there is no real benefit.</li>
<li>Higher Churn Rate.</li>
<li>Technical debt.</li>
</ul>

<p>Let’s try to take a close look at some of these examples.</p>

<h3 id="not-accounting-for-the-human-element">Not accounting for the human element</h3>

<p>In these complicated days, companies are franticly working to reduce their cloud costs. However, there’s a trap that you need to be mindful of when going through such a process.</p>

<p>Let’s look at this oversimplified equation.</p>

<blockquote>
<p><strong>$100</strong> <em>(hourly cost of a developer)</em> <strong>x</strong> <strong>10</strong> <em>(developers)</em> <strong>x</strong> <strong>2</strong> <em>(idle hours a day)</em> <strong>x</strong> <strong>21</strong> <em>(work days in a month)</em> <strong>=</strong> <strong>$42,000</strong></p>
</blockquote>

<p>If, on average, a developer at a company waits on builds or deployment for two hours per day and there are 10 developers on the team, that’s <strong>$2,000/</strong> per day going down the drain. Multiply by 21 workdays per month, and you get <strong>$42,000</strong> of wasted developer time.</p>

<p>Now, suppose that you can cut the idle time by half by adding two new build workers, where each one costs $3000/month. Is it worth it?
It seems trivial when you present it this way but harder to consider when cutting costs across the board.</p>

<p>The problem is that employees are a “fixed cost”, a different budget, and you don’t think of them in the context of wasted resources.</p>

<p>Now think about that developer idling for two hours a day. An idle engineer is a bored engineer, which leads me to the next point -  chasing away competent engineers, or making it more challenging to attract new ones.</p>

<p>You spend significant resources to keep your top engineers, but then they will be the first to jump ship when work is just not fun.</p>

<p>Team leaders spend much of their time in the recruiting process when the company is growing. Time that could be used for onboarding new employees, or mentoring the team, or doing actual development work.</p>

<p>If it takes weeks for engineers to see their work in production or they spend their time chasing the DevOps team to get a simple thing running, they will not stay for long. And worse, you will start getting a bad reputation, resulting in fewer hiring options.</p>

<p>Add burnout to the mix, and now your top developers are producing less, which trickles down to more jr. engineers. You are now stuck with a disgruntled team and no new hires on the horizon.</p>

<h3 id="trying-to-automate-and-scale-at-all-cost">Trying to automate and scale at all cost</h3>

<p>Here is another example that I see all the time - A belief that everything has to be automated and scalable.</p>

<p>“Write this script to automate task XYZ, and don’t forget to document everything and make sure it’s IaC and write a confluence page and…”
But do you really need to automate it? How much time does this task take, and how many times are you planning to perform it?</p>

<p>If it’s an annoying task that takes an hour to perform, and you expect to repeat it three times in the future, does it justify a full week of an engineer to automate?</p>

<p>What about a deployment that is pretty much a one-off? Do you really need to automate it fully? Is it worth your time? Isn’t there something else that is more meaningful for you to do?</p>

<p>I mean, yes, we have standards and workflows and beliefs, but we don’t have to follow them blindly when it doesn’t make sense.</p>

<h3 id="technical-debt">Technical Debt</h3>

<p>Managers who brush off the importance of technical debt are a bit like people who never back up their system. They never saw how technical debt could cripple a company.</p>

<p>If you don’t account for the effects of technical debt, it’s hard to see the cost, but by looking closely, you will soon see how much it affects your velocity, churn, and pretty much every aspect of the value you deliver:</p>

<ol>
<li>It slows down your developers.</li>
<li>Each feature takes twice as much time to complete.</li>
<li>The system keeps crashing.</li>
<li>It burns out your team members.</li>
<li>It makes some business decisions impossible.</li>
</ol>

<p>Think about credit card debt. At one point, the interest rates will make you go bankrupt.
Yes, fixing some of the issues takes time and resources, but can you afford to continue rolling the snowball?</p>

<h2 id="opportunity-cost">Opportunity cost</h2>

<p>In a previous example, I referred to the cost “as is,” using the developer’s direct hourly cost.  But unless you are a service business, a developer hour is worth much more than the cost.</p>

<p>This is why software companies are worth so much - The Developer’s time is a force multiplier. Developers are adding value to the company that is much higher than their yearly cost. The value they add takes the the form of IP and products that you can sell over and over without scaling inventory and distribution.</p>

<p>If we go back to the previous example, if you instead have the developers work on a new product or initiative with those hours, it’s not $42k per month that you are losing, but giving up a much higher future revenue.</p>

<p>And of course, opportunity cost can take on other forms that may not be as intuitive:</p>

<h3 id="milestone-investing">Milestone Investing</h3>

<p>Suppose that you are an early startup that has raised capital with set milestones (<a href="https://avc.com/2009/08/milestone-based-investing/">Milestone Investing</a>). By hitting the next milestone, you will increase your valuation and get a hefty cash infusion.
Now imagine your runway running out, and you have yet to meet the milestone.</p>

<p>Wouldn’t it be great if you had more time to reach your goals?</p>

<p>Suppose that your developers worked much more efficiently. Instead of idling for two hours, automating and simplifying your developers’ workflow added an hour a day of “working in the zone” for each developer.</p>

<p>How much more could you accomplish by having three more hours a day per developer?</p>

<p>Could you meet that arbitrary board goal with an impossible deadline they set for you?</p>

<p>Is it going to help you meet the milestone the investors set for receiving the next cash infusion?</p>

<p>That’s where we, the DevOps engineers (or whatever you call this function at your company), can help move the needle. We can facilitate growth and improve the productivity of our engineering teams.
It’s not just about throwing new technology at the solution and implementing the latest fad.</p>

<h2 id="so-how-can-we-produce-value-as-devops-engineers">So how can we produce Value as DevOps engineers?</h2>

<p>DevOps has always been tied to business value, but it’s rare to see this idea fully implemented in corporate culture.
Even when it does, it’s usually wrapped around a vague user story with a soggy and generic statement that doesn’t make any sense.</p>

<blockquote>
<p><em>“This feature will increase user happiness and deliver more value by making the top navigation bar a bit more blueish.”</em></p>
</blockquote>

<p>One way to create value is by addressing the cost - by reversing it, we can generate value. All you need is to look at it from a different perspective.</p>

<p>I mentioned Churn before as a metric that the business is actively working to reduce, but for engineers, it’s just “downtime.” Engineers are seldomly exposed to the idea that lowering Churn increases customer lifetime value and affects customer acquisition cost.</p>

<p>So put your DevOps cap on for a minute. Can you think of ways to reduce the churn rate?</p>

<ul>
<li>Reduce downtime.</li>
<li>Reduce latency and load speed.</li>
<li>Optimize report generation time.</li>
<li>Increase email deliverability.</li>
<li>Enable toggle features to allow your product team to test their new features on users.</li>
</ul>

<p>The list goes on, and it’s just for reducing Churn.
And yes, these are obvious priorities for operations, but now you have a clear business value tied to it.</p>

<p>Almost every hidden cost I mentioned earlier could turn into a value proposition for a DevOps related project.</p>

<h2 id="make-sure-you-have-all-the-data">Make sure you have all the data</h2>

<p>All of this “Cost” and “Value” talk is almost meaningless or non-actionable if you don’t have metrics in place.</p>

<ul>
<li>You need to have a cloud provider cost breakdown to know how much you’re spending on a project or a server.</li>
<li>Build time statistics.</li>
<li>Build and deployment success rate over time.<br></li>
<li>How long it takes to onboard a new developer to the team.</li>
</ul>

<p>You need the metrics for three reasons:</p>

<ol>
<li>Visibility - You need to be aware of the cost in the first place.</li>
<li>When making a decision, you have to have a benchmark.</li>
<li>To see the impact of your actions when working to reduce the cost.</li>
</ol>

<p>You can’t make informed decisions without having all the data; otherwise, it’s just guessing.</p>



<p>Ask yourself the following questions:</p>

<ol>
<li>Do we really need to scale this?</li>
<li>How much time will it take to reduce a cost? What can your developers do instead?</li>
<li>How can you improve the development workflow? How much time can you save?</li>
<li>Do we have a culture that allows open discussion? Do engineers have a voice when it comes to new projects and features?</li>
<li>How can we share knowledge across the organization, so engineers are aware of the product, sales, and marketing struggles?</li>
</ol>

    </div></div>]]>
            </description>
            <link>https://pushbuildtestdeploy.com/on-hidden-costs-and-the-value-of-devops/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24637836</guid>
            <pubDate>Wed, 30 Sep 2020 12:02:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Ruby One-Liners Cookbook]]>
            </title>
            <description>
<![CDATA[
Score 188 | Comments 32 (<a href="https://news.ycombinator.com/item?id=24637797">thread link</a>) | @asicsp
<br/>
September 30, 2020 | https://learnbyexample.github.io/learn_ruby_oneliners/one-liner-introduction.html | <a href="https://web.archive.org/web/*/https://learnbyexample.github.io/learn_ruby_oneliners/one-liner-introduction.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
        <!-- Provide site root to javascript -->
        

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        

        <!-- Set the theme before any content is loaded, prevents flash -->
        

        <!-- Hide / unhide sidebar before it is displayed -->
        

        <nav id="sidebar" aria-label="Table of contents">
            
            
        </nav>

        <div id="page-wrapper">

            <div class="page">
                
                
                

                
                
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                

                <div id="content">
                    <main>
                        
<p>This chapter will give an overview of <code>ruby</code> syntax for command line usage and some examples to show what kind of problems are typically suited for one-liners.</p>
<h2><a href="#why-use-ruby-for-one-liners" id="why-use-ruby-for-one-liners">Why use Ruby for one-liners?</a></h2>
<p>I assume you are already familiar with use cases where command line is more productive compared to GUI. See also this series of articles titled <a href="https://sanctum.geek.nz/arabesque/series/unix-as-ide/">Unix as IDE</a>.</p>
<p>A shell utility like <code>bash</code> provides built-in commands and scripting features to make it easier to solve and automate various tasks. External *nix commands like <code>grep</code>, <code>sed</code>, <code>awk</code>, <code>sort</code>, <code>find</code>, <code>parallel</code> etc can be combined to work with each other. Depending upon your familiarity with those tools, you can either use <code>ruby</code> as a single replacement or complement them for specific use cases.</p>
<p>Here's some one-liners (options will be explained later):</p>
<ul>
<li><code>ruby -e 'puts readlines.uniq' *.txt</code> — retain only one copy if lines are duplicated from the given list of input file(s)</li>
<li><code>ruby -e 'puts readlines.uniq {|s| s.split[1]}' *.txt</code> — retain only first copy of duplicate lines using second field as duplicate criteria</li>
<li><code>ruby -rcommonregex -ne 'puts CommonRegex.get_links($_)' *.md</code> — extract only the URLs, using a third-party <a href="https://github.com/talyssonoc/CommonRegexRuby">CommonRegexRuby</a> library</li>
<li><a href="https://stackoverflow.com/questions/63954081/bash-remove-duplicate-of-key-values-with-preserving-order">stackoverflow: merge duplicate key values while preserving order</a> — a recent Q&amp;A that I answered with a simpler <code>ruby</code> solution compared to <code>awk</code></li>
</ul>
<p>The main advantage of <code>ruby</code> over tools like <code>grep</code>, <code>sed</code> and <code>awk</code> includes feature rich regular expression engine, standard library and third-party libraries. If you don't already know the syntax and idioms for <code>sed</code> and <code>awk</code>, learning command line options for <code>ruby</code> would be the easier option. The main disadvantage is that <code>ruby</code> is likely to be slower compared to those tools.</p>
<h2><a href="#command-line-options" id="command-line-options">Command line options</a></h2>
<table><thead><tr><th><strong>Option</strong></th><th><strong>Description</strong></th></tr></thead><tbody>
<tr><td><code>-0[octal]</code></td><td>specify record separator (<code>\0</code>, if no argument)</td></tr>
<tr><td><code>-a</code></td><td>autosplit mode with <code>-n</code> or <code>-p</code> (splits <code>$_</code> into <code>$F</code>)</td></tr>
<tr><td><code>-c</code></td><td>check syntax only</td></tr>
<tr><td><code>-Cdirectory</code></td><td>cd to directory before executing your script</td></tr>
<tr><td><code>-d</code></td><td>set debugging flags (set <code>$DEBUG</code> to true)</td></tr>
<tr><td><code>-e 'command'</code></td><td>one line of script. Several <code>-e</code>'s allowed. Omit [programfile]</td></tr>
<tr><td><code>-Eex[:in]</code></td><td>specify the default external and internal character encodings</td></tr>
<tr><td><code>-Fpattern</code></td><td><code>split()</code> pattern for autosplit (<code>-a</code>)</td></tr>
<tr><td><code>-i[extension]</code></td><td>edit <code>ARGV</code> files in place (make backup if extension supplied)</td></tr>
<tr><td><code>-Idirectory</code></td><td>specify <code>$LOAD_PATH</code> directory (may be used more than once)</td></tr>
<tr><td><code>-l</code></td><td>enable line ending processing</td></tr>
<tr><td><code>-n</code></td><td>assume <code>'while gets(); ... end'</code> loop around your script</td></tr>
<tr><td><code>-p</code></td><td>assume loop like <code>-n</code> but print line also like <code>sed</code></td></tr>
<tr><td><code>-rlibrary</code></td><td>require the library before executing your script</td></tr>
<tr><td><code>-s</code></td><td>enable some switch parsing for switches after script name</td></tr>
<tr><td><code>-S</code></td><td>look for the script using PATH environment variable</td></tr>
<tr><td><code>-v</code></td><td>print the version number, then turn on verbose mode</td></tr>
<tr><td><code>-w</code></td><td>turn warnings on for your script</td></tr>
<tr><td><code>-W[level=2|:category]</code></td><td>set warning level; 0=silence, 1=medium, 2=verbose</td></tr>
<tr><td><code>-x[directory]</code></td><td>strip off text before #!ruby line and perhaps cd to directory</td></tr>
<tr><td><code>--jit</code></td><td>enable JIT with default options (experimental)</td></tr>
<tr><td><code>--jit-[option]</code></td><td>enable JIT with an option (experimental)</td></tr>
<tr><td><code>-h</code></td><td>show this message, <code>--help</code> for more info</td></tr>
</tbody></table>
<p>This chapter will show examples with <code>-e</code>, <code>-n</code>, <code>-p</code> and <code>-a</code> options. Some more options will be covered in later chapters, but not all of them are discussed in this book.</p>
<h2><a href="#executing-ruby-code" id="executing-ruby-code">Executing Ruby code</a></h2>
<p>If you want to execute a <code>ruby</code> program file, one way is to pass the filename as argument to the <code>ruby</code> command.</p>
<pre><code>$ echo 'puts "Hello Ruby"' &gt; hello.rb
$ ruby hello.rb
Hello Ruby
</code></pre>
<p>For short programs, you can also directly pass the code as an argument to the <code>-e</code> option.</p>
<pre><code>$ ruby -e 'puts "Hello Ruby"'
Hello Ruby

$ # multiple statements can be issued separated by ;
$ ruby -e 'x=25; y=12; puts x**y'
59604644775390625
$ # or use -e option multiple times
$ ruby -e 'x=25' -e 'y=12' -e 'puts x**y'
59604644775390625
</code></pre>
<h2><a href="#filtering" id="filtering">Filtering</a></h2>
<p><code>ruby</code> one-liners can be used for filtering lines matched by a regexp, similar to <code>grep</code>, <code>sed</code> and <code>awk</code>. And similar to many command line utilities, <code>ruby</code> can accept input from both <code>stdin</code> and file arguments.</p>
<pre><code>$ # sample stdin data
$ printf 'gate\napple\nwhat\nkite\n'
gate
apple
what
kite

$ # print all lines containing 'at'
$ # same as: grep 'at' and sed -n '/at/p' and awk '/at/'
$ printf 'gate\napple\nwhat\nkite\n' | ruby -ne 'print if /at/'
gate
what

$ # print all lines NOT containing 'e'
$ # same as: grep -v 'e' and sed -n '/e/!p' and awk '!/e/'
$ printf 'gate\napple\nwhat\nkite\n' | ruby -ne 'print if !/e/'
what
</code></pre>
<p>By default, <code>grep</code>, <code>sed</code> and <code>awk</code> will automatically loop over input content line by line (with <code>\n</code> as the line distinguishing character). The <code>-n</code> or <code>-p</code> option will enable this feature for <code>ruby</code>. As seen before, the <code>-e</code> option accepts code as command line argument. Many shortcuts are available to reduce the amount of typing needed.</p>
<p>In the above examples, a regular expression (defined by the pattern between a pair of forward slashes) has been used to filter the input. When the input string isn't specified in a conditional context (for example: <code>if</code>), the test is performed against global variable <code>$_</code>, which has the contents of the input line (the correct term would be input <strong>record</strong>, see <a href="https://learnbyexample.github.io/learn_ruby_oneliners/record-separators.html#record-separators">Record separators</a> chapter). To summarize, in a conditional context:</p>
<ul>
<li><code>/regexp/</code> is a shortcut for <code>$_ =~ /regexp/</code></li>
<li><code>!/regexp/</code> is a shortcut for <code>$_ !~ /regexp/</code></li>
</ul>
<p><code>$_</code> is also the default argument for <code>print</code> method, which is why it is generally preferred in one-liners over <code>puts</code> method. More such defaults that apply to the <code>print</code> method will be discussed later.</p>
<blockquote>
<p><img src="https://learnbyexample.github.io/learn_ruby_oneliners/images/info.svg" alt="info"> See <a href="https://ruby-doc.org/core-2.7.1/doc/globals_rdoc.html">ruby-doc: Pre-defined global variables</a> for documentation on <code>$_</code>, <code>$&amp;</code>, etc.</p>
</blockquote>
<p>Here's an example with file input instead of <code>stdin</code>.</p>
<pre><code>$ cat table.txt
brown bread mat hair 42
blue cake mug shirt -7
yellow banana window shoes 3.14

$ # same as: grep -oE '[0-9]+$' table.txt
$ ruby -ne 'puts $&amp; if /\d+$/' table.txt
42
7
14
</code></pre>
<blockquote>
<p><img src="https://learnbyexample.github.io/learn_ruby_oneliners/images/info.svg" alt="info"> The <a href="https://github.com/learnbyexample/learn_ruby_oneliners/tree/master/example_files">learn_ruby_oneliners repo</a> has all the files used in examples.</p>
</blockquote>
<h2><a href="#substitution" id="substitution">Substitution</a></h2>
<p>Use <code>sub</code> and <code>gsub</code> methods for search and replace requirements. By default, these methods operate on <code>$_</code> when the input string isn't provided. For these examples, <code>-p</code> option is used instead of <code>-n</code> option, so that the value of <code>$_</code> is automatically printed after processing each input line.</p>
<pre><code>$ # for each input line, change only first ':' to '-'
$ # same as: sed 's/:/-/' and awk '{sub(/:/, "-")} 1'
$ printf '1:2:3:4\na:b:c:d\n' | ruby -pe 'sub(/:/, "-")'
1-2:3:4
a-b:c:d

$ # for each input line, change all ':' to '-'
$ # same as: sed 's/:/-/g' and awk '{gsub(/:/, "-")} 1'
$ printf '1:2:3:4\na:b:c:d\n' | ruby -pe 'gsub(/:/, "-")'
1-2-3-4
a-b-c-d
</code></pre>
<p>You might wonder how <code>$_</code> is modified without the use of <code>!</code> methods. The reason is that these methods are part of Kernel (see <a href="https://ruby-doc.org/core-2.7.1/Kernel.html">ruby-doc: Kernel</a> for details) and are available only when <code>-n</code> or <code>-p</code> options are used.</p>
<ul>
<li><code>sub(/regexp/, repl)</code> is a shortcut for <code>$_.sub(/regexp/, repl)</code> and <code>$_</code> will be updated if substitution succeeds</li>
<li><code>gsub(/regexp/, repl)</code> is a shortcut for <code>$_.gsub(/regexp/, repl)</code> and <code>$_</code> gets updated if substitution succeeds</li>
</ul>
<blockquote>
<p><img src="https://learnbyexample.github.io/learn_ruby_oneliners/images/info.svg" alt="info"> This book assumes you are already familiar with regular expressions. If not, you can check out my free <a href="https://learnbyexample.github.io/Ruby_Regexp/">Ruby Regexp</a> book.</p>
</blockquote>
<h2><a href="#field-processing" id="field-processing">Field processing</a></h2>
<p>Consider the sample input file shown below with fields separated by a single space character.</p>
<pre><code>$ cat table.txt
brown bread mat hair 42
blue cake mug shirt -7
yellow banana window shoes 3.14
</code></pre>
<p>Here's some examples that is based on specific field rather than the entire line. The <code>-a</code> option will cause the input line to be split based on whitespaces and the field contents can be accessed using <code>$F</code> global variable. Leading and trailing whitespaces will be suppressed and won't result in empty fields. More details is discussed in <a href="https://learnbyexample.github.io/learn_ruby_oneliners/field-separators.html#default-field-separation">Default field separation</a> section.</p>
<pre><code>$ # print the second field of each input line
$ # same as: awk '{print $2}' table.txt
$ ruby -ane 'puts $F[1]' table.txt
bread
cake
banana

$ # print lines only if last field is a negative number
$ # same as: awk '$NF&lt;0' table.txt
$ ruby -ane 'print if $F[-1].to_f &lt; 0' table.txt
blue cake mug shirt -7

$ # change 'b' to 'B' only for the first field
$ # same as: awk '{gsub(/b/, "B", $1)} 1' table.txt
$ ruby -ane '$F[0].gsub!(/b/, "B"); puts $F * " "' table.txt
Brown bread mat hair 42
Blue cake mug shirt -7
yellow banana window shoes 3.14
</code></pre>
<h2><a href="#begin-and-end" id="begin-and-end">BEGIN and END</a></h2>
<p>You can use a <code>BEGIN{}</code> block when you need to execute something before input is read and a <code>END{}</code> block to execute something after all of the input has been processed.</p>
<pre><code>$ # same as: awk 'BEGIN{print "---"} 1; END{print "%%%"}'
$ # note the use of ; after BEGIN block
$ seq 4 | ruby -pe 'BEGIN{puts "---"}; END{puts "%%%"}'
---
1
2
3
4
%%%
</code></pre>
<h2><a href="#env-hash" id="env-hash">ENV hash</a></h2>
<p>When it comes to automation and scripting, you'd often need to construct commands that can accept input from user, file, output of a shell command, etc. As mentioned before, this book assumes <code>bash</code> as the shell being used. To access environment variables of the shell, you can call the special hash variable <code>ENV</code> with the name of the environment variable as a string key.</p>
<pre><code>$ # existing environment variable
$ # output shown here is for my machine, would differ for you
$ ruby -e 'puts ENV["HOME"]'
/home/learnbyexample
$ ruby -e 'puts ENV["SHELL"]'
/bin/bash

$ # defined along with ruby command
$ # note that the variable is placed before the shell command
$ word='hello' ruby -e 'puts ENV["word"]'
hello
$ # the input characters are preserved as is
$ ip='hi\nbye' ruby -e 'puts ENV["ip"]'
hi\nbye
</code></pre>
<p>Here's another example when a regexp is passed as an environment variable content.</p>
<pre><code>$ cat word_anchors.txt
sub par
spar
apparent effort
two spare computers
cart part tart mart

$ # assume 'r' is a shell variable that has to be passed to the ruby command
$ r='\Bpar\B'
$ rgx="$r" ruby -ne 'print if /#{ENV["rgx"]}/' word_anchors.txt
apparent effort
two spare computers
</code></pre>
<blockquote>
<p><img src="https://learnbyexample.github.io/learn_ruby_oneliners/images/info.svg" alt="info"> As an example, see my repo <a href="https://github.com/learnbyexample/command_help/blob/master/ch">ch: command help</a> for a practical shell script, where commands are constructed …</p></blockquote></main></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://learnbyexample.github.io/learn_ruby_oneliners/one-liner-introduction.html">https://learnbyexample.github.io/learn_ruby_oneliners/one-liner-introduction.html</a></em></p>]]>
            </description>
            <link>https://learnbyexample.github.io/learn_ruby_oneliners/one-liner-introduction.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24637797</guid>
            <pubDate>Wed, 30 Sep 2020 11:57:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making the Monte Hall problem weirder but obvious]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24637787">thread link</a>) | @dyno-might
<br/>
September 30, 2020 | https://dyno-might.github.io/2020/09/17/making-the-monty-hall-problem-weirder-but-obvious/ | <a href="https://web.archive.org/web/*/https://dyno-might.github.io/2020/09/17/making-the-monty-hall-problem-weirder-but-obvious/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <div>
        

<div>
    <div>
        <div>
            <p><strong>Sep 17, 2020</strong></p>
            



<p>The <a href="https://en.wikipedia.org/wiki/Monty_Hall_problem">Monty Hall problem</a> is famously unintuitive. This post starts with an extreme version where the solution is blindingly obvious. We then go through a series of small changes. It will be clear that these don’t affect the solution. At the end, we arrive at the classic Monte Hall problem.</p>

<p>For reference, the <a href="https://en.wikipedia.org/wiki/Monty_Hall_problem">classic formulation</a> goes:</p>

<blockquote>
  <p>Suppose you’re on a game show, and you’re given the choice of three doors: Behind one door is a car; behind the others, goats. You pick a door, say No. 1, and the host, who knows what’s behind the doors, opens another door, say No. 3, which has a goat. He then says to you, “Do you want to pick door No. 2?” Is it to your advantage to switch your choice?</p>
</blockquote>

<p>Intuitively, many people guess it doesn’t matter if you switch. But it does. You get the car 2/3 of the time if you switch, and 1/3 of the time if you don’t. Why?</p>



<p>Here’s our first game.</p>

<ol>
  <li>There are 10 doors. A car is randomly placed behind one, and goats behind the other 9.</li>
  <li>You pick one door.</li>
  <li>You get two options:
    <ul>
      <li>Option A: You get whatever is behind the door you picked.</li>
      <li>Option B: You get whatever is behind all of the other 9 doors.</li>
    </ul>
  </li>
</ol>

<p><img src="https://dyno-might.github.io/img/monty-hall/game1.png">
</p>

<p>There’s nothing mysterious here. You should choose option B. There’s only a 10% chance you picked the right door, so there’s a 90% chance the car is behind one of the others.</p>



<p>Now, we slightly update the game (new part in bold).</p>

<ol>
  <li>There are 10 doors. A car is randomly placed behind one, and goats behind the other 9.</li>
  <li>You pick one door.</li>
  <li><strong>Monty says “Hey! I promise you that there is a goat behind at least 8 of the other 9 doors!”</strong></li>
  <li>You get two options:
    <ul>
      <li>Option A: You get whatever is behind the door you picked.</li>
      <li>Option B: You get whatever is behind all of the other 9 doors.</li>
    </ul>
  </li>
</ol>

<p><img src="https://dyno-might.github.io/img/monty-hall/game2.png">
</p>

<p>Monty’s statement changes nothing. You don’t need to rely on his <a href="https://en.wikipedia.org/wiki/Monty_Hall#/media/File:Monty_hall_abc_tv.JPG">trustworthy looks</a>. You already <em>knew</em> there were at least 8 goats! Option B still gets you the car 90% of the time.</p>



<p>Let’s update the game again (new part in bold).</p>

<ol>
  <li>There are 10 doors. A car is randomly placed behind one, and goats behind the other 9.</li>
  <li>You pick one door.</li>
  <li><strong>Monty looks behind the other 9 doors. He chooses 8 with goats behind them, and opens them.</strong></li>
  <li>You get two options:
    <ul>
      <li>Option A: You get whatever is behind the door you picked.</li>
      <li>Option B: You get whatever is behind all of the other 9 doors.</li>
    </ul>
  </li>
</ol>

<p><img src="https://dyno-might.github.io/img/monty-hall/game3.png">
</p>

<p>The key insight is this: When Monty shows you that 8 of the 9 other doors contain goats, you haven’t learned anything relevant to your decision. You <em>already knew there were at least 8 goats behind the other doors</em>! So this is just like game 2. Option B still gets you the car 90% of the time.</p>

<p>Want more intuition? Suppose you picked door 3. Imagne Monty walking past the doors, opening doors 1, 2, 4, 5, 6, <strong>skipping 7</strong>, then opening 8, 9, and 10. Doesn’t door 7 seem special?</p>



<p>Let’s make another change. Finally, we arrive at a game very similar to Monty Hall.</p>

<ol>
  <li>There are 10 doors. A car is randomly placed behind one, and goats behind the other 9.</li>
  <li>You pick one door.</li>
  <li>Monty looks behind the other 9 doors. He chooses 8 of them with goats behind them, and opens them.</li>
  <li>You get two options:
    <ul>
      <li>Option A: You get whatever is behind the door you picked.</li>
      <li>Option B: You get whatever is behind <strong>the other closed door</strong>.</li>
    </ul>
  </li>
</ol>

<p><img src="https://dyno-might.github.io/img/monty-hall/game4.png">
</p>

<p>The only difference with Game 3 is that option B doesn’t get you the 8 visible goats. Since you don’t care about goats, this makes no difference. This is still just like the game 3. You get the car 90% of the time by switching.</p>



<p>Here is the last game. We just change the number of doors from 10 to 3.</p>

<ol>
  <li>There are <strong>3</strong> doors. A car is randomly placed behind one, and goats behind the other <strong>2</strong>.</li>
  <li>You pick one door.</li>
  <li>Monty looks behind the other <strong>2</strong> doors. He chooses one <strong>1</strong> of them with a goat behind it, and opens it.**</li>
  <li>You get two options:
    <ul>
      <li>Option A: You get whatever is behind the door you picked.</li>
      <li>Option B: You get whatever is behind the other closed door.</li>
    </ul>
  </li>
</ol>

<p><img src="https://dyno-might.github.io/img/monty-hall/game5.png">
</p>

<p>Of course, you still want to choose option B. The chance of success is now 2/3 instead of 9/10. This game is exactly Monty Hall, so we’re done.</p>



<ul>
  <li>
    <p>It’s important that Monty looked behind the doors before choosing which to open. This is where people’s intuition usually fails. If he had chosen a door at random — <em>in a way that he risked possibly exposing a car</em>, then the situation would be different. (In that case, there’s no advantage or harm in switching.) But he doesn’t choose the door at random. He deliberately chooses to show you goats. Since this is always possible, it tells you nothing. I think this is the crux of what makes this problem unintuitive. Many people intuitively think it doen’t matter if you switch. And that <em>would be correct</em> if the door had been opened at random!</p>
  </li>
  <li>
    <p>It might be helpful to draw a diagram of the relationship of the different games, starting with classic Monty Hall and ending with the extreme version.</p>
  </li>
</ul>

<blockquote>
  <p>Game 5 (Classic Monty Hall)<br>
 ↓<br>
 ↓ (Use 10 doors instead of 3)<br>
 ↓ <br>
Game 4<br>
 ↓<br>
 ↓ (If you switch, get the contents of <em>all</em> other doors, not just the other closed door.)<br>
 ↓<br>
Game 3<br>
 ↓<br>
 ↓ (Monty promises 8 goats behind the other doors instead of showing you.)<br>
 ↓<br>
Game 2<br>
 ↓<br>
 ↓ (Monty doesn’t bother promsising.)<br>
 ↓<br>
Game 1 (Dyno Might© Monty Hall)</p>
</blockquote>

<ul>
  <li>
    <p>There are <a href="https://marginalrevolution.com/marginalrevolution/2019/09/the-intuitive-monty-hall-problem.html">some</a> <a href="https://twitter.com/jben0/status/1174180200072011776">other</a> <a href="https://statmodeling.stat.columbia.edu/2019/09/19/alternative-more-intuitive-formulation-of-monte-hall-problem/">attempts</a> at <a href="https://math.stackexchange.com/questions/96826/the-monty-hall-problem/3360686#3360686">variants</a> of the Monte Hall problem, also intended to be more intuitive. These involve switching the doors for “boxers”.</p>
  </li>
  <li>
    <p>Monty Hall was actually named “Monte” at birth! Given that <a href="https://en.wikipedia.org/wiki/Monte_Carlo_method">Monte Carlo simulations</a> are often used for exploring the Monty Hall problem, that’s either a tragedy for puns or a miracle for confused students.</p>
  </li>
</ul>

        </div>

        

        
        
    </div>
</div>


    </div>
</section></div>]]>
            </description>
            <link>https://dyno-might.github.io/2020/09/17/making-the-monty-hall-problem-weirder-but-obvious/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24637787</guid>
            <pubDate>Wed, 30 Sep 2020 11:56:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unsupervised Learning]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24637758">thread link</a>) | @juanorozcov
<br/>
September 30, 2020 | https://www.brainstobytes.com/unsupervised-learning/ | <a href="https://web.archive.org/web/*/https://www.brainstobytes.com/unsupervised-learning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<!--kg-card-begin: markdown--><p>In a previous article, we learned about supervised learning: using labeled examples for creating models that solve a variety of tasks such as classification and regression.</p>
<p>There is another type of learning that doesn't require labeled examples: unsupervised learning. As it turns out, unlabeled data is much more common than labeled data. Often, you need to create the labels for the examples yourself, a process that might consume vast amounts of time and resources.</p>
<p>That's ok, lack of labels doesn't mean your data is totally useless. There are lots of machine learning tasks that do not require labeled examples, and you can use unsupervised learning to perform data exploration or to extract useful insights from the data that is readily available right now.</p>
<p>In this article, we will discuss some of the most common applications of unsupervised learning. Let's learn how to use unlabeled data to achieve valuable results.</p>
<h4 id="1associationrulelearning">1. Association rule learning</h4>
<p>Association rule learning/mining is a method for discovering relations between elements in large datasets. A typical example is using it to identify which products are more likely to be purchased together.</p>
<p>Association rule mining is usually used to support cross-selling. This is when companies offer the customer extra products they might have forgotten or don't know about yet. As an example, if you are buying a new guitar and an amplifier, you might also want to buy a cable or new strings.</p>
<p>This is done by algorithms that scan historic transactional information and look for the co-occurrence of items. It will generate a series of rules that model the likelihood of certain items being bought together. Two of the most important values generated by these algorithms are support and confidence.</p>
<ul>
<li><strong>Support</strong> is the ratio of transactions that include the specific set of items against the total number of transactions. It tells you <em>how frequently the set of items occur together</em>. For example, if {guitar, amplifier, cable} have a support value of 2%, it means that 2% of all purchases include all 3 items.</li>
<li><strong>Confidence</strong> is a measure of how likely it is that Z will be bought if we are already buying A. It is defined as the ratio between the transactions that include Z and A against all the ones that included A. A confidence of 30% between guitar and amplifier means that 30% of the customers who bought a guitar also bought an amplifier.</li>
</ul>
<p>These algorithms can generate massive amounts of rules and not all of them are useful. Often, only rules with high values of support and confidence are allowed to stay, the rest are discarded.</p>
<p>Physical stores can use this information to group items together to promote purchases, and online stores can offer you items at checkout-time and even provide some discounts for specific items. It is known that demographical information about customers increases the effectiveness of these algorithms, so most shops offer loyalty cards with discounts in exchange for your data.</p>
<h4 id="2segmentation">2. Segmentation</h4>
<p>Segmentation is one of the most useful data science techniques. It aims to group the elements of a dataset into subgroups that have characteristics in common. While the task is not that difficult in a 2d plane, sets with lots of attributes make it impossible for a human to accomplish this task. By leveraging data science you can find some useful and counterintuitive groups in data.</p>
<p>Segmentation can dramatically improve the effectiveness of marketing campaigns. Instead of sending the same campaign to everyone, you could create segments of users and target them with only the information they need. You can even create specialized campaigns aimed at different subgroups. This has two upsides: first, you don't bother people with offerings they don't care about. Second, it lets you save money and increase the success of campaigns by focusing the resources were you have the most chances to succeed.</p>
<p>Machines are much better at uncovering unknown subsets in data than humans are. After they have created segments, a human expert can inspect the set to ensure they make sense.</p>
<p>This technique transcends beyond marketing and has a wide array of applications, ranging from identifying gene sequences to patterns in population groups, ecosystems and documents.</p>
<p><img src="https://www.brainstobytes.com/content/images/2020/01/Segmentation.png" alt="Segmentation"></p>
<h4 id="3outlierdetection">3. Outlier detection</h4>
<p>Outlier detection is in some way the opposite of segmentation. In segmentation, you want to create groups containing only similar elements, in outlier detection you want to separate the instances that are different from the rest. The goal of outlier detection is to find anomalies or special cases within our dataset.</p>
<p>This can be achieved in 3 ways:</p>
<ul>
<li>Create two big clusters of data using segmentation. Typical cases will be grouped together and outliers will be the elements out of the group.</li>
<li>Measure the distance between each element and the center of the data. Anomalies will usually be the ones farther away from the group.</li>
<li>Train a classification model to divide instances into two groups. This is difficult because you need (as you remember) training data for the classifier, and outliers are by definition rare, representing just a small portion of the training set. This affects the performance of many types of classifiers.</li>
</ul>
<p>Outlier detection is used by financial institutions to identify fraudulent transactions or other forms of fraudulent behavior. It can also be used to detect malicious network activity or attacks on software systems.</p>
<p><img src="https://www.brainstobytes.com/content/images/2020/01/OutlierDetection.png" alt="OutlierDetection"></p>
<h2 id="unlabeleddataispowerful">Unlabeled data is powerful</h2>
<p>Unsupervised learning is a very powerful idea with lots of applications. Part of this power derives from being able to make use of the most common type of data available: unlabeled examples. We explored 3 common applications, but it doesn't mean those are the only things you can do with unsupervised learning. It's also possible to build classification and regression models!</p>
<p>For building a classifier, you could use a clustering algorithm (like k-means clustering) to discover natural segments in your data. After that, you could compute the distance between a new example and the centroids (among many other possibilities) to classify it in any of the clusters. Using a similar idea you can build a regression model: you could calculate the similarity between a new example and a specific number of data points in your data. After finding the data points with the most similarities with your new example, you can use their aggregated attributes to extrapolate the target value of the new example.</p>
<p>You can also use supervised learning to assist the process of creating a new data solution. A common first task when dealing with machine learning problems is using clustering and outlier detection to discover underlying patterns or clean your datasets from noise.</p>
<p>No matter what you choose, becoming familiar with this set of techniques and ideas will be very useful in your career as a data scientist.</p>
<p>Thank you for reading!</p>
<h2 id="whattodonext">What to do next</h2>
<ul>
<li>Share this article with friends and colleagues. Thank you for helping me reach people who might find this information useful.</li>
<li>This article is based on Data Science for Business: What You Need to Know about Data Mining and Data-Analytic Thinking. This and other very helpful books can be found in the <a href="https://www.brainstobytes.com/recommended-books/">recommended reading list</a>.</li>
<li>Send me an email with questions, comments or suggestions (it's in the <a href="https://www.brainstobytes.com/about">About Me page</a>)</li>
</ul>
<!--kg-card-end: markdown-->
					</div></div>]]>
            </description>
            <link>https://www.brainstobytes.com/unsupervised-learning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24637758</guid>
            <pubDate>Wed, 30 Sep 2020 11:51:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Spotify’s Failed Squad Goals]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24637656">thread link</a>) | @cocoflunchy
<br/>
September 30, 2020 | https://www.jeremiahlee.com/posts/failed-squad-goals/?repost | <a href="https://web.archive.org/web/*/https://www.jeremiahlee.com/posts/failed-squad-goals/?repost">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<!-- Spread 1 -->
<section>
<section>
<video autoplay="true" muted="true" loop="true">
<source srcset="https://www.jeremiahlee.com/posts/failed-squad-goals/cover.png" media="(prefers-reduced-motion: reduce)">
<source src="https://www.jeremiahlee.com/posts/failed-squad-goals/cover.webm" type="video/webm">
<source src="https://www.jeremiahlee.com/posts/failed-squad-goals/cover.m4v" type="video/mp4">
<img src="https://www.jeremiahlee.com/posts/failed-squad-goals/cover.png" alt="Taylor Swift and her squad walking away from an explosion in front of the Spotify office at Birger Jarlsgatan.">
</video>
</section>
<section>
<div>

<p><b>Spotify</b> doesn’t use <em>“the Spotify model”</em><br>and neither should you.</p>
<p>By Jeremiah Lee</p>
<p>Sunday, April 19, 2020 • <a href="https://anchor.fm/jeremiah-oral-lee/episodes/Spotifys-Failed-SquadGoals-edia0p">Listen</a> •&nbsp;<a href="https://oyomy.fr/2020/04/l-echec-du-modele-spotify/" hreflang="fr">En français</a> •&nbsp;<a href="https://jp.quora.com/q/agile/Spotify%E3%81%AF-Spotify%E3%83%A2%E3%83%87%E3%83%AB-%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%A6%E3%81%84%E3%81%AA%E3%81%84" hreflang="ja">日本語で</a> • <a href="https://flavioclesio.com/2020/05/18/o-modelo-de-squadgoals-do-spotify-falhou/" hreflang="pt-br">Português (Brasil)</a></p>
</div>
</section>
</section>
<!-- Spread 2 -->
<section>
<section>
<div>
<p>Of all the allures of startup culture, few are more desireable than the speed and nimbleness of a small team. Maintaining that feeling as a company grows is a challenge. In 2012, Spotify shared its way of working and suggested it had figured it out.<sup><a href="#1">1</a></sup></p>
<p>I was excited to see <em>the Spotify model</em> in action when I interviewed for a product management role at its Stockholm headquarters in 2017. However, the recruiter surprised me before the first interview. She cautioned me to not expect Spotify to be an <a href="https://en.wikipedia.org/wiki/Agile_software_development">Agile</a> utopia.</p>
<p>I joined the company after it had tripled in size to 3,000 people over 18 months. I learned the famed squad model was only ever aspirational and never fully implemented. I witnessed organizational chaos as the company’s leaders incrementally transitioned to more traditional management structures.</p>
<p>When I asked my coworkers why the content was not removed or updated to reflect reality, I never got a good answer. Many people ironically thought the posts were great for recruiting. I no longer work at Spotify, so I am sharing my experience to set the record straight. The Spotify squad model failed Spotify and it will fail your company too.</p>
</div>
</section>
<section>
<div>
<h3>But you don’t have to take my word for it.</h3>
<p>The co-author of the Spotify model<sup><a href="#2">2</a></sup> and multiple agile coaches who worked at Spotify have been telling people to not copy it for years. Unfortunately, truth doesn’t spread as quickly or as widely as an idea people want to believe in.</p>
<blockquote>
<p>“Even at the time we wrote it, we weren’t doing it. It was part ambition, part approximation. People have really struggled to copy something that didn’t really exist.”</p>
</blockquote>
<p>—Joakim Sundén, agile coach at Spotify&nbsp;2011–2017<sup><a href="#4">4</a></sup></p>
<blockquote>
<p><em>“It worries me when people look at what we do and think it’s a framework they can just copy and implement.</em> … We are really trying hard now to emphasize we have problems as well. It’s not all ‘shiny and everything works well and all our squads are super amazing’.”</p>
</blockquote>
<p>—Anders Ivarsson, co-author of the Spotify&nbsp;whitepaper<sup><a href="#3">3</a></sup></p>
</div>
</section>
</section>
<!-- Spread 3 -->
<section>
<section>
<div>
<h2>Recap</h2>
<p>You can read and watch the <a href="#1">original content</a> in less than 30 minutes or <a href="#spread-4">skip to the next section</a> if you are familiar. Here is a brief summary.</p>
<p>Spotify had teams it called <em>squads</em> because it sounded cooler (not joking). A group of teams were organized into a department called a <em>tribe</em>. Each team was intended to be an autonomous mini-startup, with a product manager acting as mini-CEO for a feature area. The teams had designers and software engineers with a range of specializations. The intent was that a team should have every skill necessary without needing to rely on another team for success.</p>
<p>Product managers had a traditional management structure. A product manager for a team reported to their department’s product director (<em>“tribe lead”</em>). Same for designers. Software engineers, however, were managed outside of the team structure.</p>
</div>
</section>
<section>
<div>
<p><em>“Chapter leads”</em> managed software engineers specializing in a specific type of software development across the department. For example, all of the software engineers working on backend APIs across all the teams within the department would have one manager and all of the Android mobile engineers in the department would have a different manager. The intent was to allow engineers to be moved between teams within the department to best meet business requirements without them having to change managers.</p>
<figure>
<video autoplay="true" muted="true" loop="true">
<source src="https://www.jeremiahlee.com/posts/failed-squad-goals/scaling-spotify-squads.webm" type="video/webm">
<source src="https://www.jeremiahlee.com/posts/failed-squad-goals/scaling-spotify-squads.m4v" type="video/mp4">
<img src="https://www.jeremiahlee.com/posts/failed-squad-goals/scaling-spotify-squads.png" alt="Spotify matrix organization diagram. A department is called a tribe and has multiple squads, another name for a team. Each squad has a product owner, another name for a product manager. Software engineers of the same discipline across multiple teams are called a chapter and managed by a chapter lead, another name for an engineering manager.">
</video>
<figcaption>Spotify tried a long-lived matrix team structure with unusual word choices.<sup><a href="#1">1</a></sup> It did not work well.</figcaption>
</figure>
</div>
</section>
</section>
<!-- Spread 4 -->
<section id="spread-4">
<section>

</section>
<section id="matrix-management-sucks">
<div>
<h3>Matrix management solved the wrong problem</h3>
<p>The “full stack” agile team worked well, but the matrix management of software engineers introduced more problems than it solved.</p>
<ul>
<li><p>Teams at Spotify were rather long-lived. The benefit of not having to change manager when moving to another team was limited.</p></li>
<li><p>Engineering managers in this model had little responsibility beyond the career development of the people they managed. Even then, their ability to help with interpersonal people skills development was limited. An engineering manager would not manage enough of the other people on the team or be involved enough in the daily context to independently assess conflict within the team.</p></li>
</ul>
</div>
</section>
</section>
<!-- Spread 5 -->
<section>
<section>
<div>
<ul>
<li><p>Without a single engineering manager responsible for the engineers on a team, the product manager lacked an equivalent peer—the mini-CTO to their mini-CEO role. There was no single person accountable for the engineering team’s delivery or who could negotiate prioritization of work at an equivalent level of responsibility.</p><p>When disagreements within the engineering team arose, the product manager needed to negotiate with all of the engineers on the team. If the engineers could not reach a consensus, the product manager needed to escalate to as many engineering managers as there were engineering specializations within the team. A team with backend, Web app, and mobile app engineers would have at least 3 engineering managers who might need to get involved. If those engineering managers could not reach a consensus, a single team’s issue would have to escalate to the department’s engineering director.</p></li>
</ul>
</div></section>
<section id="matrix-management-sucks">
<div>
<blockquote>
<p>“Chapter leads are servant-leaders who help you grow as an individual. They don’t really work with any team. They have direct reports on all the teams. They don’t have really any accountability for the delivery. They aren’t taking that responsibility. It’s easy to see the product owner as the manager for the team.”</p>
</blockquote>
<p>—Joakim Sundén, agile coach at Spotify<sup><a href="#4">4</a></sup></p>
<p><strong>Learn from Spotify’s mistakes:</strong></p>
<ul>
<li>A product—design—engineering team typically contains more engineers than designers or product managers. Having a single engineering manager for the engineers on the team creates an accountable escalation path for conflict within the team.</li>
<li>Product managers should have an equivalent peer for engineering. Product managers should be accountable for the prioritization of work. Engineering managers should be accountable for the engineers’ execution, which includes being able to negotiate speed and quality tradeoffs with the product manager.</li>
</ul>
</div>
</section>
</section>
<!-- Spread 6 -->
<section>
<section id="too-much-autonomy">
<div>
<h3>Spotify fixated on team autonomy</h3>
<p>When a company is small, teams have to do a wide range of work to deliver and have to shift initiatives frequently. As a company grows from startup to scale-up, duplicated functions across teams move to new teams dedicated to increasing organization efficiency by reducing duplication. With more teams, the need for a team to shift initiative decreases in frequency. Both of these changes allow for teams to think more deeply and long term about the problems they are scoped to solve. Faster iteration, however, is not guaranteed. Every responsibility a team cedes to increase its focus becomes a new cross-team dependency.</p>
<p>Spotify did not define a common process for cross-team collaboration. Allowing every team to have a unique way of working meant each team needed a unique way of engagement when collaborating. Overall organization productivity suffered.</p>
<p>The Spotify model was documented when Spotify was a much smaller company. It was supposed to be a multiple part series, according to Anders Ivarsson. Autonomy made the first cut, but the parts on alignment and accountability were never completed.</p>
</div>
</section>
<section>
<div>
<p><strong>Learn from Spotify’s mistakes:</strong></p>
<ul>
<li>Autonomy requires alignment. Company priorities must be defined by leadership. Autonomy does not mean teams get to do whatever they want.</li>
<li>Processes for cross-team collaboration must be defined. Autonomy does not mean leaving teams to self-organize every problem.</li>
<li>How success is measured must be defined by leadership so people can effectively negotiate cross-team dependency prioritization.</li>
<li>Autonomy requires accountability. Product management is accountable for value. The team is accountable for delivering ‘done’ increments. Mature teams can justify their independence with their ability to articulate business value, risk, learning, and the next optimal move.<sup><a href="#6">6</a></sup></li>
</ul>
</div>
</section>
</section>
<!-- Spread 7 -->
<section>
<section id="too-much-autonomy">
<div>
<blockquote>
<p>“If I were to do one thing differently, I would say we should not be focusing so much on autonomy.</p>
<p>“Every time you have a new team, they have to reinvent the wheel in how they should be working. Maybe, just maybe, we should have a ‘minimum viable agility’. You start with that. You are free to opt out, but people shouldn’t have to opt-in all the time.</p>
<p>“At what point do you start inserting this process? Probably when it’s too late.”</p>
</blockquote>
<p>—Joakim Sundén, agile coach at Spotify<sup><a href="#4">4</a></sup></p>
</div>
</section>
<section>
<div>
<blockquote>
<p>“Henrik Kniberg talked about how we're not that good at large initiatives and we’re still not that good at large initiatives.</p>
<p>“If you have inconsistent ways of working, it’s more difficult for people to move. If it’s more difficult for people to move, it’s more likely you have inconsistent ways of working. It will just reinforce until all of a sudden, you’re not really working for the same company anymore. You’re working for these kind of weird subcultures.”</p>
</blockquote>
<p>—Jason Yip, agile coach at Spotify<br>2015–time of writing<sup><a href="#5">5</a></sup></p>
</div>
</section>
</section>
<!-- Spread 8 -->
<section>
<section id="collaboration-is-a-competency">
<div>
<h3>Collaboration was an assumed competency</h3>
<p>While Spotify gave teams control over their way of working, many people did not have a basic understanding of Agile practices. This resulted in teams iterating through process tweaks in blind hope of finding the combination that would help them improve their delivery. People lacked a common language to effectively discuss the process problems, the education to solve them, and the experience to evaluate performance. It was not really <em>agile</em>. It was just <em>not-waterfall</em>.</p>
<p><em>“Agile coaches”</em> were internal consultants Spotify provided teams to teach and suggest process improvements. While well-intentioned, there were not enough coaches to help every team. A coach’s engagement with a team was rarely long enough to span a project’s completion to help a team evaluate performance. More so, they were not accountable for anything.</p>
</div>
</section>
<section>
<div>
<blockquote>
<p>“Control without competence is chaos.”</p>
</blockquote>
<p>—L. David Marquet, <a href="https://www.indiebound.org/book/9781591846406"><cite>Turn the Ship Around!</cite></a></p>
<p><strong>Learn from Spotify’s …</strong></p></div></section></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.jeremiahlee.com/posts/failed-squad-goals/?repost">https://www.jeremiahlee.com/posts/failed-squad-goals/?repost</a></em></p>]]>
            </description>
            <link>https://www.jeremiahlee.com/posts/failed-squad-goals/?repost</link>
            <guid isPermaLink="false">hacker-news-small-sites-24637656</guid>
            <pubDate>Wed, 30 Sep 2020 11:35:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Six Figures in 6 days]]>
            </title>
            <description>
<![CDATA[
Score 622 | Comments 283 (<a href="https://news.ycombinator.com/item?id=24637405">thread link</a>) | @brunojppb
<br/>
September 30, 2020 | https://tr.af/6 | <a href="https://web.archive.org/web/*/https://tr.af/6">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-lax-preset="fadeIn">
        <p>This title is a little misleading.</p>

<p>Sure, it took me 6 days to amass 3,626 sales for a total of $101,528, but like any overnight success, it was years in the making. In my case, about 7 years.</p>

<p>In 2013, the jailbreaking days of iOS were in full effect. Inspired, I created and sold an icon set titled 'Greyish HD' on the Cydia store for $0.99. It was the first few dollars I ever made on the internet. I think I made a total of $17, and it was magical.</p>

<p>It wasn't about the $17, obviously; it was how I earned it. I spent time creating something that I thought was cool, then hit publish. After a few days, random strangers I've never met before decided to spend their hard-earned cents on my icon set, oftentimes while I was working on something else entirely. Without realizing it, I just discovered digital content leverage: <strong>create something once with sufficient effort, then sell it repeatedly with minimal effort.</strong></p>

<p>Fast forward 7 years later, minus 6 days. I saw some people sharing screenshots of their iPhones after discovering that iOS 14 now allows you to add custom icons to your home screen using the Siri Shortcuts app. This was the first time you can really customize iOS, and it was catching on. </p>

<p>This is something people have been doing for years on jailbroken iOS and Android devices, except this time, you can do it natively on iOS.</p>

<p>As soon as I noticed the hype, I put together some <a href="https://icons.tr.af/">icons</a> in my own style, downloaded some widgets, and tried it all out. I thought it looked cool, so I shared a screenshot of it on Twitter. Right away, people started asking about the icons in the screenshot. So I quickly packaged them, uploaded them to <a href="https://gumroad.com/">Gumroad</a>, and embedded them on a <a href="https://notion.so/">Notion</a> site using <a href="https://super.so/">Super</a>. All of this took about two hours.</p>

<p>The next day, the tweet had hundreds of retweets, thousands of likes, and over 100k impressions. The day after that, almost a million. The next thing I knew, it was everywhere. My icons got published on notable tech sites like <a href="https://www.cultofmac.com/723490/ios-14-iphone-home-screen-customization/">Cult of Mac</a>, <a href="https://www.imore.com/people-are-making-real-money-selling-icon-sets-ios-14-home-screens">iMore</a>, <a href="https://allthingst3ch.com/ios14homescreen">AllThingsTech</a>, and <a href="https://gridfiti.com/aesthetic-ios-home-screen-ideas">Gridfiti</a>. I think at this time I was around the $6k mark in sales.</p>

<p>Then, MKBHD happened. He shared a <a href="https://youtu.be/cH66LWWluVE">video</a> about all of this—using my icons for his setup, and linked them in the description. The next thing I knew, I was making $28 what felt like every 28 seconds. My phone turned into the ultimate dopamine dispenser (if it wasn't already). I had to disable notifications.</p>

<p>The day after, sales jumped from $6k to about $40k, and during the time of this writing, sales are at $116,147 from 4,188 customers.</p>

<p>All from one. Single. <a href="https://twitter.com/traf/status/1307707156788060160">Tweet</a>.</p>

<p>The right content, posted at the right time, can create unimaginable results. Although there's likely plenty of other variables that went into making this work, there are a few key insights that I think increased my odds.</p>

<h3>Publish often</h3>

<p>Continually putting things out into the world creates proof of work. The difference between where you are and where you want to be could be as little as sharing what you build, or even what you know.</p>

<p>There's only so much we can control once pushing something out into the world, but publishing often will increase your odds at finding something that sticks. They say that fortune favors the bold. In the internet age, the bold are those that aren't afraid to publish their work for the world to see. The internet is a never-ending stream of content, the idea of being annoying or over-sharing is only an idea that you invent to stop you from sharing. </p>

<h3>Act immediately</h3>

<p>I could have easily ignored the requests for the icons, or directed people to icon sets that already existed, but that would be a missed opportunity. Since I've done similar icon sets so many times already in the past, I was ready for it. Acting quickly is crucial if you plan on riding the wave. </p>

<h3>Be transparent</h3>

<p>I shared <a href="https://twitter.com/traf/status/1308158718975111175">this tweet</a> the day after posting my home screen with details of all the hype, and it created even more hype. It brought another 540,000 impressions and added fuel to an already growing fire. <strong>Share what works, and share what doesn't.</strong> Transparency is visibility.</p>

<h3>Have a clear schedule</h3>

<p>A lot of this was happening on a Monday morning. If I were working a more traditional job, or had time commitments that I had previously scheduled, I wouldn't have been able to act on my ideas as quickly as I did. I get that not everyone has the privilege of a flexible schedule, but almost anyone can start to move towards it if they want it badly enough. Freedom of a clear schedule allowed me to take action as soon as the inspiration hit, which was incredibly important to maximize exposure. Inspiration is a productivity-multiplier, but it's perishable—so act quickly.</p>

<h3>Charge more</h3>

<p>If I would have asked anyone what to price these at, most would have said $2, or maybe $5. One thing I knew for sure was that the people most likely to buy these were not the same people who were jailbreaking their iOS devices in the past. These are first time iOS customizers, so there's no notion of what an iOS icon set should be priced at.</p>

<h3>Do it for the art</h3>

<p>If I would have done this exclusively for the goal of making money, I'm convinced it wouldn't have worked nearly as well as it did. I see copycats showing up everywhere. They see success, and try to replicate exactly how it happened, but it won't work. At least not nearly as well. The reasons for this post is not to teach you how to sit on the edge of your seat, foaming at the mouth at the chance to exploit the next big internet trend, but it's to push you to keep working at the things you enjoy, share them with the world, and letting the internet do the rest.</p>

<h3>Aftermath</h3>

<p>So what came of all this? I suspect this is why most of you are here reading this, so here's a recap of everything that came from last week in numbers, from the time of this writing:</p>

<h4>Short-term metrics:</h4>

<ul><li>4,188 total icon sales</li><li>$116,147 in revenue</li><li>97% profit margins</li><li>6.2m impression</li><li>216,800 visitors</li></ul>

<h4>Long-term metrics:</h4>

<ul><li>5,216 email subscribers</li><li>4,620 Twitter followers</li><li>180 <a href="https://super.so/">Super</a> customers</li></ul>

<h3>What's next?</h3>

<p>In the same way that creating icon sets 7 years ago prepared me for last week, this whole experiment has likely prepared me for what's to come years from now.</p>

<p>The best part about this is the freedom its bought me, to keep building things that'll create even more freedom. <strong>Spending time on things that will buy you time is always a good use of it.</strong> When people buy into what ever it is you're selling, they're not only giving you money, but they're contributing to your future freedom.</p>

<p>The market will decide a huge part of what comes after sharing something, so continually increase your odds by building, publishing, then repeating. Try many things once to figure out what you want to do twice. Figure out what you've got stored in your brain that can be of value to others, then share it with the world. You might be surprised of what comes of it.</p>

<p>Thanks for reading.</p>

<p>PS. For proof that I did this in 2013, here's my <a href="https://deviantart.com/jtraf">DeviantArt profile</a>.<br>PPS. For details about the Notion/Super/Gumroad combo: <a href="https://www.makerpad.co/deep-dives/the-community-creator-how-to-run-a-low-cost-membership-community-or-creator-business-with-circle-memberspace-gumroad-notion-super-so">Makerpad deep-dive</a>.</p>

<p>— <a href="https://twitter.com/traf">@traf</a></p>
      </div></div>]]>
            </description>
            <link>https://tr.af/6</link>
            <guid isPermaLink="false">hacker-news-small-sites-24637405</guid>
            <pubDate>Wed, 30 Sep 2020 10:59:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gitlab CI/CD for cross-platform Unreal Engine 4 projects]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24637248">thread link</a>) | @me2too
<br/>
September 30, 2020 | https://pgaleone.eu/cicd/unreal-engine/2020/09/30/continuous-integration-with-unreal-engine-4/ | <a href="https://web.archive.org/web/*/https://pgaleone.eu/cicd/unreal-engine/2020/09/30/continuous-integration-with-unreal-engine-4/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<p>Continuous Integration (CI) is an essential step in the development pipeline of well-designed software infrastructure. The goal of CI is to <strong>automatize the boring stuff</strong> by letting the developers focusing on the code and, at the same time, helping them in producing good quality software.</p>
<p>Often, we read together two acronyms (and this article makes no exception) CI &amp; CD. While CI always stands for Continuous Integration, CD has two different meanings:</p>
<ol>
<li><strong>Continuous Delivery</strong> where a developer’s change is automatically bug-tested and uploaded to a repository, or</li>
<li><strong>Continuous Deployment</strong> where a developer’s change is automatically released to the production environment, where the customer can use this brand-new version.</li>
</ol>
<p>In this article, I’m going to show you how to configure and use the CI/CD tool provided by GitLab to correctly manage the CI/CD pipeline of an <strong>Unreal Engine 4 (UE4) project</strong> that needs to work (and thus, to be tested) on 3 different platforms:</p>
<ul>
<li>Windows</li>
<li>macOS</li>
<li>Linux</li>
</ul>
<p>In the following, “CD” will stand for Continuous Delivery - so I won’t cover the Deployment part.</p>

<p><a href="https://about.gitlab.com/">GitLab</a> is a complete DevOps platform: it offers us a complete CI/CD toolchain, an amazing issue tracking suite, and exposes in a user-friendly-way almost every Git’s feature.</p>
<p><img src="https://pgaleone.eu/images/ciue4/cicd_pipeline_infograph.png" alt="GitLab Continuous Integration pipeline"></p>
<p>The CI/CD toolchain is composed of 3 main parts:</p>
<ul>
<li>The <code>gitlab-ci.yml</code> file that contains the configuration of the CI/CD pipeline. Using this YAML file we can configure the CI/CD behavior: what should happen on every commit or merge request, what should happen at scheduled times, and <a href="https://docs.gitlab.com/ee/ci/yaml/">many many more</a>. This file contains the commands to execute (a batch of commands is called “job”) on the specified runner.</li>
<li><a href="https://docs.gitlab.com/runner/">GitLab Runners</a>. A runner is a software able to receive from GitLab a job, execute it, and send back the result to GitLab. Several runners can (and should) run in parallel, allowing the whole infrastructure to scale. The execution of the job is delegated to an “executor”.</li>
<li><strong>The executor</strong>. During the configuration of the runner, we can specify what type of executor to use. In particular, it’s possible to use the machine where the runner is installed to run directly in its shell the commands (that’s the shell executor), or use Docker to execute the commands into a container, or even use a virtual machine or a Kubernetes cluster (for a complete reference see: https://docs.gitlab.com/runner/executors/).</li>
</ul>
<p>The amazing thing is that GitLab Runner is a software written in Go: this means that it can run perfectly on our three target platforms: Windows, macOS, and Linux.</p>
<p>Moreover, installing it is trivial as explained in <a href="https://docs.gitlab.com/runner/#install-gitlab-runner">the documentation</a>.</p>
<h2 id="executors-for-ue4-projects">Executors for UE4 projects</h2>
<p><a href="https://www.unrealengine.com/en-US/">Unreal Engine</a> is a cross-platform game engine, quoting the official website:</p>
<blockquote>
<p>Unreal Engine is the world’s most open and advanced real-time 3D creation tool. Continuously evolving to serve not only its original purpose as a state-of-the-art game engine, today it gives creators across industries the freedom and control to deliver cutting-edge content, interactive experiences, and immersive virtual worlds.</p>
</blockquote>
<p>UE4 is really an amazing project, but this amazingness comes at a cost: it’s <strong>heavy</strong>. The engine itself, <a href="https://docs.unrealengine.com/en-US/GettingStarted/DownloadingUnrealEngine/index.html">available on GitHub</a>, weights ~132GB on Linux:</p>
<div><div><pre><code><span>du</span> <span>-hs</span> /opt/unreal-engine/
132G    /opt/unreal-engine/
</code></pre></div></div>
<p>Since our goal is to create an environment that contains the compiled engine (for our three target platforms) and use it inside our CI. Using a <strong>Docker executor</strong> it is perhaps the best possible solution.</p>
<h3 id="docker-executor">Docker executor</h3>
<p>As previously stated, one of the costs of using UE4 is its size: when we have enough resources this isn’t a problem (you need a good amount of storage and a lot of memory and CPU power to compile and use the engine), and it’s not a problem even when using Docker on Linux. However, building a Docker image containing UE4 on Windows is somehow a difficult and long process, because there is a well-know and <em>unresolved</em> issue about the creation of <a href="https://github.com/moby/moby/issues/37581">filesystem layers lager than 8 GiB</a>.</p>
<p>Although there are well-known issues (only on Windows), using a Docker executor have a lot of advantages like:</p>
<ul>
<li>Spawning a container is a cheap operation.</li>
<li>Every container is isolated.</li>
<li>It is possible to scale the solution easily (easy to parallelize).</li>
<li>Customizing/Creating a Dockerfile is easy.</li>
</ul>
<p>Creating docker containers with unreal-engine inside is a challenge that <a href="https://adamrehn.com/">Adam Rehn</a> with his <a href="https://unrealcontainers.com/">Unreal Containers</a> <strong>amazingly faced</strong>.</p>
<p><img src="https://pgaleone.eu/images/ciue4/ue-plus-docker.svg" alt="UnrealContainer logo"></p>
<p>The project, and Python package, <a href="https://docs.adamrehn.com/ue4-docker/read-these-first/introduction-to-ue4-docker">ue4-docker</a> contains all we need to create a docker image that we will later on use in our <code>.gitlab-ci.yml</code> file.</p>
<p>Using <code>ue4-docker</code> creating an image is so easy as:</p>
<div><div><pre><code><span>REPO_URL</span><span>=</span><span>"&lt;set url here&gt;"</span>
<span>BRANCH</span><span>=</span><span>"&lt;set branch here&gt;"</span>
ue4-docker build custom:4.25.3 <span>-repo</span><span>=</span><span>"</span><span>$REPO_URL</span><span>"</span> <span>-branch</span><span>=</span><span>"</span><span>$BRANCH</span><span>"</span> <span>\</span>
           <span>--exclude</span> debug <span>\ </span><span># exclude debug symbols to reduce the image and workaround the windows issue</span>
           <span>--exclude</span> templates <span>\ </span><span># exclude the templates since we don't need them in our CI</span>
           <span>--exclude</span> ddc <span># exclude DDC to speed up the image creation </span>
</code></pre></div></div>
<p>The same command can be executed in a Linux and in a Windows machine. Personally, I prefer having a Linux machine that executes a docker container, instead of using a Windows machine to execute a docker container containing a Linux image (for performance reasons and to save time during the creation of the images too).</p>
<p>At the end of the execution of the <code>ue4-docker</code> command, we end up with a set of images ready to use like:</p>
<div><div><pre><code>docker images | grep ue4

adamrehn/ue4-full                           4.25.3                        01562ee9c264        9 days ago          15.6GB
adamrehn/ue4-full                           4.25.3-opengl                 01562ee9c264        9 days ago          15.6GB
adamrehn/ue4-minimal                        4.25.3                        561beaae1f0f        9 days ago          14GB
adamrehn/ue4-minimal                        4.25.3-opengl                 561beaae1f0f        9 days ago          14GB
adamrehn/ue4-engine                         4.25.3                        717a019f5917        9 days ago          85.6GB
adamrehn/ue4-engine                         4.25.3-opengl                 717a019f5917        9 days ago          85.6GB
adamrehn/ue4-source                         4.25.3                        dce5e2cdbc65        9 days ago          54.7GB
adamrehn/ue4-source                         4.25.3-opengl                 dce5e2cdbc65        9 days ago          54.7GB
adamrehn/ue4-build-prerequisites            opengl                        ec75c0a656c0        7 months ago        584MB
</code></pre></div></div>
<p>A complete description of what is inside every image is available in the <a href="https://docs.adamrehn.com/ue4-docker/building-images/available-container-images">List of available container images</a> page.</p>
<p>Using Docker we can cover the CI for the Linux and Windows platforms. macOS, instead, can’t run inside a container :( hence we have to use another executor.</p>
<h3 id="shell-executor">Shell executor</h3>
<p>The shell executor is just “the current machine”. Thus, we can install <a href="https://docs.gitlab.com/runner/install/osx.html">GitLab Runner on macOS</a> and manually install all the dependencies that are, in our case, only unreal engine and the Xcode toolchain.</p>
<p>Differently from the Docker executor, the Shell executor has several disadvantages:</p>
<ul>
<li>No isolation at all.</li>
<li>No native support for parallel and isolated executions.</li>
<li>It doesn’t scale well.</li>
<li>We have to clean up the dirt left by the operations we do in the CI (e.g. temporary files).</li>
</ul>
<p>The only advantage we have is the simplicity of installation: we just have to install UE4 on our machine and we are ready to go.</p>
<p>Supposing to have Unreal Engine already installed (the setup on Mac, Linux, Windows is straightforward; it’s just a matter of following the <a href="https://docs.unrealengine.com/en-US/GettingStarted/Installation/index.html">guide</a>), the only thing we need to do is to install another Python tool created by Adam Rehn: <a href="https://docs.adamrehn.com/ue4cli/overview/introduction-to-ue4cli">ue4cli</a>.</p>
<p>This Python package implements a command-line tool called <code>ue4</code>: this tool simplifies the invocation/usage of the UE4 toolchain and, perhaps more importantly, it unifies the interface we have to use on different platforms.</p>
<p>The tool is installed into the <code>ue4-full</code> images and that’s the reason we’re going to use these images in our <code>gitlab-ci.yml</code> file.</p>
<h2 id="the-cicd-pipeline">The CI/CD pipeline</h2>
<p>As introduced at the beginning of the article, after setting up the runners and the executor, we are ready to describe the CI/CD pipeline in the <code>.gitlab-ci.yml</code> file.</p>
<h3 id="continuous-integration">Continuous Integration</h3>
<p>Let’s start with the automatization of the boring stuff, we need to find a way to automatically answer these questions:</p>
<ol>
<li>Is the code following the code style / required formatting?</li>
<li>Does the code I want to merge compile correctly on every platform?</li>
<li>Am I introducing regressions?</li>
</ol>
<p>To answer all these questions, and be ready for the continuous delivery stuff, we need to define the variables and the stages (of the pipeline) we plan to execute.</p>
<div><div><pre><code><span>variables</span><span>:</span>
    <span>GIT_SUBMODULE_STRATEGY</span><span>:</span> <span>"</span><span>recursive"</span>
    <span>GIT_STRATEGY</span><span>:</span> <span>"</span><span>fetch"</span>
    <span>GIT_CHECKOUT</span><span>:</span> <span>"</span><span>true"</span>
    <span>GIT_SSL_NO_VERIFY</span><span>:</span> <span>"</span><span>1"</span>
    <span>GET_SOURCES_ATTEMPTS</span><span>:</span> <span>"</span><span>10"</span>

<span>stages</span><span>:</span>
    <span>-</span> <span>static-analysis</span>
    <span>-</span> <span>build</span>
    <span>-</span> <span>tests</span>
    <span>-</span> <span>package</span>
</code></pre></div></div>
<ul>
<li>The <strong>static-analysis</strong> stage will contain the jobs related to the source code analysis. The checks for the source code formatting (the only one presented in this article) and other checks related to the analysis of the source code itself.</li>
<li>The <strong>build</strong> stage will contain the jobs that answer question 2.</li>
<li>The <strong>test</strong> stage contains the execution of the test cases (because every unreal project uses the unreal test suite - isn’t it?)</li>
<li>The <strong>package</strong> stage contains the continuous delivery part of the pipeline.</li>
</ul>
<h5 id="static-analysis">Static Analysis</h5>
<p>Every C++ project should follow a code style. This CI job uses <code>clang-format</code> and <code>dos2unix</code> to check if every committed file has the correct encoding (we need UTF-8 encoded files to be sure that every compiler on every platform can read them well) and follows the style rules present in the <code>.clang-format</code> file that should be present into every project :)</p>
<div><div><pre><code><span>clang-format</span><span>:</span>
    <span>image</span><span>:</span> <span>alpine</span>
    <span>stage</span><span>:</span> <span>static-analysis</span>
    <span>variables</span><span>:</span>
        <span>GIT_LFS_SKIP_SMUDGE</span><span>:</span> <span>"</span><span>1"</span>
    <span># empty dependencies = do not need artifacts from previous stages</span>
    <span>dependencies</span><span>:</span> <span>[]</span>
    <span>script</span><span>:</span>
        <span>-</span> <span>apk update &amp;&amp; apk add clang git bash dos2unix</span>
        <span>-</span> <span>exclude=$(for d in $(git …</span></code></pre></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pgaleone.eu/cicd/unreal-engine/2020/09/30/continuous-integration-with-unreal-engine-4/">https://pgaleone.eu/cicd/unreal-engine/2020/09/30/continuous-integration-with-unreal-engine-4/</a></em></p>]]>
            </description>
            <link>https://pgaleone.eu/cicd/unreal-engine/2020/09/30/continuous-integration-with-unreal-engine-4/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24637248</guid>
            <pubDate>Wed, 30 Sep 2020 10:33:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Book: Epic Alignment – How the best Product Managers work with feature documents]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24637233">thread link</a>) | @njanse
<br/>
September 30, 2020 | https://www.delibr.com/ebook | <a href="https://web.archive.org/web/*/https://www.delibr.com/ebook">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<h3>What's inside</h3>
<p>How can you drive the thinking on what to develop, why and how to
do it — leveraging the insights from both team and stakeholders — all the way from idea to
deploy?</p>
<p>This book tries to answer the above question. As part of our own
product development at Delibr, we interviewed over 300 Product Managers to understand how they work
and collaborate around feature development, what problems they face, and the many approaches to
solving those problems. </p>
<p>"Epic alignment" describes four broad approaches that we saw help
Product Managers excel.</p>
<h3>What you'll learn</h3>
<ul>
<li>How to drive product development towards impact based on research</li>
<li>How to use user stories as a shared language to align your entire team</li>
<li>How to write feature documents that drive joint understanding and act as a single source of
truth
</li>
<li>How to tackle the massive amounts of decisions needed for every epic</li>
</ul>
</div></div>]]>
            </description>
            <link>https://www.delibr.com/ebook</link>
            <guid isPermaLink="false">hacker-news-small-sites-24637233</guid>
            <pubDate>Wed, 30 Sep 2020 10:29:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Most popular GraphgQL server implementations]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24637210">thread link</a>) | @oczek
<br/>
September 30, 2020 | https://blog.graphqleditor.com/graphql-servers/ | <a href="https://web.archive.org/web/*/https://blog.graphqleditor.com/graphql-servers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>GraphQL is a query language for APIs that describes how to ask &amp; fetch the data from the server to the client which of course requires setting up a server. Below you will find a list of the most popular GraphgQL server implementations. There’s quite a few of them so we’re not going to get through the lot of them in one go.</p>
<h2>Express GraphQL</h2>
<p>It is said that <a href="https://github.com/graphql/express-graphql">Express GraphQL</a> is the simplest way to run a GraphQL API server. Express is a popular web application framework for Node.js allowing you to create a GraphQL server with any HTTP web framework supporting connect styled middleware including <a href="https://expressjs.com/">Express</a>, <a href="http://restify.com/">Restify</a> and, of course, <a href="https://github.com/senchalabs/connect">Connect</a>. Getting started is as easy as installing some additional dependencies in form of <code>npm install express express-graphql graphql --save</code></p>
<p><span>
      <a href="https://blog.graphqleditor.com/static/d8c5b170d7059b55a31da3c1de450fb5/21b4d/express.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Express GraphQL" title="Express GraphQL" src="https://blog.graphqleditor.com/static/d8c5b170d7059b55a31da3c1de450fb5/fcda8/express.png" srcset="https://blog.graphqleditor.com/static/d8c5b170d7059b55a31da3c1de450fb5/12f09/express.png 148w,
https://blog.graphqleditor.com/static/d8c5b170d7059b55a31da3c1de450fb5/e4a3f/express.png 295w,
https://blog.graphqleditor.com/static/d8c5b170d7059b55a31da3c1de450fb5/fcda8/express.png 590w,
https://blog.graphqleditor.com/static/d8c5b170d7059b55a31da3c1de450fb5/efc66/express.png 885w,
https://blog.graphqleditor.com/static/d8c5b170d7059b55a31da3c1de450fb5/c83ae/express.png 1180w,
https://blog.graphqleditor.com/static/d8c5b170d7059b55a31da3c1de450fb5/21b4d/express.png 1280w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://graphql.org/graphql-js/running-an-express-graphql-server/">graphql.org</a></h5>
<h2>Apollo GraphQL Server</h2>
<p><a href="https://github.com/apollographql/apollo-server">Apollo GraphQL Server</a> is an open-source GraphQL server compatible with any GraphQL client and it’s an easy way to build a production-ready, self-documenting GraphQL API that can use data from any source. Apollo Server can be used as a stand-alone GraphQL server, a plugin to your application’s Node.js middleware, or as a gateway for a federated data graph. Apollo GraphQL Server offers:</p>
<ul>
<li><strong>easy setup</strong> - client-side can start fetching data instantly,</li>
<li><strong>incremental adoption</strong> - elastic approach to adding new features, you can add them easily later on when you decide they’re needed,</li>
<li><strong>universality</strong> - compatibility with any data source, multiple
build tools and GraphQL clients,</li>
<li><strong>production-ready</strong> - tested across various enterprise-grade projects.</li>
</ul>
<p><span>
      <a href="https://blog.graphqleditor.com/static/b7f98cac82ca2ea3fce952f1f25867a3/23266/apollo.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Apollo GraphQL Server" title="Apollo GraphQL Server" src="https://blog.graphqleditor.com/static/b7f98cac82ca2ea3fce952f1f25867a3/fcda8/apollo.png" srcset="https://blog.graphqleditor.com/static/b7f98cac82ca2ea3fce952f1f25867a3/12f09/apollo.png 148w,
https://blog.graphqleditor.com/static/b7f98cac82ca2ea3fce952f1f25867a3/e4a3f/apollo.png 295w,
https://blog.graphqleditor.com/static/b7f98cac82ca2ea3fce952f1f25867a3/fcda8/apollo.png 590w,
https://blog.graphqleditor.com/static/b7f98cac82ca2ea3fce952f1f25867a3/efc66/apollo.png 885w,
https://blog.graphqleditor.com/static/b7f98cac82ca2ea3fce952f1f25867a3/23266/apollo.png 923w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://github.com/apollographql/apollo-server">apollographql.com</a></h5>
<h2>Hot Chocolate</h2>
<p><a href="https://hotchocolate.io/">Hot Chocolate</a> is a GraphQL server you can use to create GraphQL endpoints,  merge schemas, etc. Hot Chocolate is a part of a .NET based <a href="https://github.com/ChilliCream/hotchocolate">ChilliCream GraphQL Platform</a> that can help you build a GraphQL layer over your existing and new infrastructure. It provides pre-built templates that let you start in seconds, supporting both ASP.Net Core as well as ASP.Net Framework out of the box.</p>
<p><span>
      <a href="https://blog.graphqleditor.com/static/0e8f4aada898797c50c04bb75e6a98ec/23266/hotchoc.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Hot Chocolate is a part of ChilliCream GraphQL Platform" title="Hot Chocolate is a part of ChilliCream GraphQL Platform" src="https://blog.graphqleditor.com/static/0e8f4aada898797c50c04bb75e6a98ec/fcda8/hotchoc.png" srcset="https://blog.graphqleditor.com/static/0e8f4aada898797c50c04bb75e6a98ec/12f09/hotchoc.png 148w,
https://blog.graphqleditor.com/static/0e8f4aada898797c50c04bb75e6a98ec/e4a3f/hotchoc.png 295w,
https://blog.graphqleditor.com/static/0e8f4aada898797c50c04bb75e6a98ec/fcda8/hotchoc.png 590w,
https://blog.graphqleditor.com/static/0e8f4aada898797c50c04bb75e6a98ec/efc66/hotchoc.png 885w,
https://blog.graphqleditor.com/static/0e8f4aada898797c50c04bb75e6a98ec/23266/hotchoc.png 923w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://github.com/ChilliCream/hotchocolate">github.com/ChilliCream/hotchocolate</a></h5>
<h2>Hasura GraphQL Engine</h2>
<p><a href="https://github.com/hasura/graphql-engine">Hasura GraphQL Engine</a> is a GraphQL server that gives you realtime GraphQL APIs over Postgres, making easy building your new Postgress-backed GraphQL app or adding a GraphQL layer for your existing Postgres bases app.  Hasura GraphQL Engine offers built-in filtering, pagination, merging remote schemas along with many other useful features. All that keeping high-performance &amp; footprint at the lowest possible rate.</p>
<p><span>
      <a href="https://blog.graphqleditor.com/static/522960eb8b0af0ea8789fac5f6c91c9b/d9199/hasura.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Hasura GraphQL Engine" title="Hasura GraphQL Engine" src="https://blog.graphqleditor.com/static/522960eb8b0af0ea8789fac5f6c91c9b/fcda8/hasura.png" srcset="https://blog.graphqleditor.com/static/522960eb8b0af0ea8789fac5f6c91c9b/12f09/hasura.png 148w,
https://blog.graphqleditor.com/static/522960eb8b0af0ea8789fac5f6c91c9b/e4a3f/hasura.png 295w,
https://blog.graphqleditor.com/static/522960eb8b0af0ea8789fac5f6c91c9b/fcda8/hasura.png 590w,
https://blog.graphqleditor.com/static/522960eb8b0af0ea8789fac5f6c91c9b/efc66/hasura.png 885w,
https://blog.graphqleditor.com/static/522960eb8b0af0ea8789fac5f6c91c9b/d9199/hasura.png 960w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://github.com/hasura/graphql-engine">github.com/hasura</a></h5>
<h2>API PLATFORM</h2>
<p><a href="https://github.com/api-platform/api-platform">API Platform</a> is a set of tools that combined build a modern framework for building REST and GraphQL APIs including GraphQL Server. The server solution is located in the API Platform Core Library which is built on top of Symfony 4 (PHP) microframework and the Doctrine ORM. API Platform Core Library is a highly flexible solution allowing you to build fully-featured GraphQL API in minutes.</p>
<p><span>
      <a href="https://blog.graphqleditor.com/static/06c54d11146913c58117559a32674596/2cefc/apiplatform.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="API PLATFORM" title="API PLATFORM" src="https://blog.graphqleditor.com/static/06c54d11146913c58117559a32674596/fcda8/apiplatform.png" srcset="https://blog.graphqleditor.com/static/06c54d11146913c58117559a32674596/12f09/apiplatform.png 148w,
https://blog.graphqleditor.com/static/06c54d11146913c58117559a32674596/e4a3f/apiplatform.png 295w,
https://blog.graphqleditor.com/static/06c54d11146913c58117559a32674596/fcda8/apiplatform.png 590w,
https://blog.graphqleditor.com/static/06c54d11146913c58117559a32674596/efc66/apiplatform.png 885w,
https://blog.graphqleditor.com/static/06c54d11146913c58117559a32674596/c83ae/apiplatform.png 1180w,
https://blog.graphqleditor.com/static/06c54d11146913c58117559a32674596/2cefc/apiplatform.png 1400w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://api-platform.com/">api-platform.com</a></h5>
<h2>Parse Server GraphQL API</h2>
<p>In addition to the traditional REST API, Parse Server automatically generates a GraphQL API basing on a given schema. <a href="https://docs.parseplatform.org/graphql/guide/">Parse Server GraphQL API</a> follows Relay specification along with the latest industry standards which makes it a perfect choice for modern projects requiring the highest-scalability.</p>
<p><span>
      <a href="https://blog.graphqleditor.com/static/48c5fb34b2f1914c334930add2472828/00d43/parse.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Parse Server GraphQL API " title="Parse Server GraphQL API " src="https://blog.graphqleditor.com/static/48c5fb34b2f1914c334930add2472828/fcda8/parse.png" srcset="https://blog.graphqleditor.com/static/48c5fb34b2f1914c334930add2472828/12f09/parse.png 148w,
https://blog.graphqleditor.com/static/48c5fb34b2f1914c334930add2472828/e4a3f/parse.png 295w,
https://blog.graphqleditor.com/static/48c5fb34b2f1914c334930add2472828/fcda8/parse.png 590w,
https://blog.graphqleditor.com/static/48c5fb34b2f1914c334930add2472828/efc66/parse.png 885w,
https://blog.graphqleditor.com/static/48c5fb34b2f1914c334930add2472828/00d43/parse.png 1000w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://docs.parseplatform.org/graphql/guide/">docs.parseplatform.org/graphql/guide</a></h5>
<p>That’s it for the first look at GraphQL servers. So if I missed your favorite one, just mention it in the comments and stay tuned for the next parts!</p></div><p>The GraphQL Editor is a supportive tool for both advanced GraphQL users as well as those taking their first steps with GraphQL APIs. Our all-in-one development environment for GraphQL will help you build, manage &amp; deploy your GraphQL API much faster thanks to dozens of built-in micro features. Its graphical interface will also fix communication within your product team. Visualization is the key!</p></div>]]>
            </description>
            <link>https://blog.graphqleditor.com/graphql-servers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24637210</guid>
            <pubDate>Wed, 30 Sep 2020 10:26:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Commodore 64 Program Discovered on 35-Year Old Vinyl Album (2019)]]>
            </title>
            <description>
<![CDATA[
Score 204 | Comments 56 (<a href="https://news.ycombinator.com/item?id=24637146">thread link</a>) | @clockworksoul
<br/>
September 30, 2020 | https://popcultureretrorama.com/2019/11/25/35-years-later-a-commodore-64-program-was-found-on-this-1984-album/ | <a href="https://web.archive.org/web/*/https://popcultureretrorama.com/2019/11/25/35-years-later-a-commodore-64-program-was-found-on-this-1984-album/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1304">
	
	<div>
		
<p>Friends, this should give you a little boost at the end of your day – because 8-Bit Show and Tell has located a Commodore 64 program hidden within Prodigal’s 1984 album entitled Electric Eye. I was just goofing around on YouTube when I came across this video – which was originally uploaded back on October 19th of this year. Since I have been known to talk about my love of the Commdore 64 computer of my youth – the title of the video caught my attention pretty quickly. And seriously, how absolutely amazing is it that in this day and age we can still be surprised by little Easter eggs from 35 years ago? As Robin will demonstrate on the video itself the program was hidden in the runout groove on the B side of <em>Electric Eye</em>  – which you can plainly see in this article image header has a “C-64” scratched into said groove. Probably one of the reasons that not a lot of people know about the program is because it needed to be played on your turntable where you could record the hidden program on a cassette tape to upload it on your C64… that is a little bit of work. As the video will show – sometimes using older technology takes a couple of tries – or even totally different equipment in some cases.</p>







<p>I will have to in the near future share an article about the Mattel Electronics Aquarius computer that we obtained at the arcade – in fact I talked just a bit about it in the <em><a href="https://popcultureretrorama.com/2019/11/24/diary-of-an-arcade-employee-podcast-1up-night-stalker/">Night Stalker</a></em> podcast earlier today. Robin was able to make contact with one of the surviving members of <strong>Prodigal</strong> by the way – which was a Christian rock group, active from 1975 until 1986 – to ask how and why this 35 year-old computer program was included on the <em>Electric Eye</em> album. </p>



<div><figure><img data-attachment-id="1306" data-permalink="https://popcultureretrorama.com/2019/11/25/35-years-later-a-commodore-64-program-was-found-on-this-1984-album/35-years-later-a-commodore-64-program-electric-eye/" data-orig-file="https://i0.wp.com/popcultureretrorama.com/wp-content/uploads/2019/11/35-Years-Later-A-Commodore-64-Program-Electric-Eye.jpg?fit=700%2C394&amp;ssl=1" data-orig-size="700,394" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="35-Years-Later-A-Commodore-64-Program-Electric-Eye" data-image-description="" data-medium-file="https://i0.wp.com/popcultureretrorama.com/wp-content/uploads/2019/11/35-Years-Later-A-Commodore-64-Program-Electric-Eye.jpg?fit=300%2C169&amp;ssl=1" data-large-file="https://i0.wp.com/popcultureretrorama.com/wp-content/uploads/2019/11/35-Years-Later-A-Commodore-64-Program-Electric-Eye.jpg?fit=640%2C360&amp;ssl=1" loading="lazy" width="640" height="360" src="https://i0.wp.com/popcultureretrorama.com/wp-content/uploads/2019/11/35-Years-Later-A-Commodore-64-Program-Electric-Eye.jpg?resize=640%2C360&amp;ssl=1" alt="" srcset="https://i0.wp.com/popcultureretrorama.com/wp-content/uploads/2019/11/35-Years-Later-A-Commodore-64-Program-Electric-Eye.jpg?w=700&amp;ssl=1 700w, https://i0.wp.com/popcultureretrorama.com/wp-content/uploads/2019/11/35-Years-Later-A-Commodore-64-Program-Electric-Eye.jpg?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/popcultureretrorama.com/wp-content/uploads/2019/11/35-Years-Later-A-Commodore-64-Program-Electric-Eye.jpg?resize=150%2C84&amp;ssl=1 150w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/popcultureretrorama.com/wp-content/uploads/2019/11/35-Years-Later-A-Commodore-64-Program-Electric-Eye.jpg?w=700&amp;ssl=1 700w, https://i0.wp.com/popcultureretrorama.com/wp-content/uploads/2019/11/35-Years-Later-A-Commodore-64-Program-Electric-Eye.jpg?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/popcultureretrorama.com/wp-content/uploads/2019/11/35-Years-Later-A-Commodore-64-Program-Electric-Eye.jpg?resize=150%2C84&amp;ssl=1 150w" data-lazy-src="https://i0.wp.com/popcultureretrorama.com/wp-content/uploads/2019/11/35-Years-Later-A-Commodore-64-Program-Electric-Eye.jpg?resize=640%2C360&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<p>The discovery of what amounts to a simple message from <strong>Prodigal</strong> 35 years later might not be the most groundbreaking thing you’ll see today… but I thought it was special enough that I had to share it. Watching this particular 8-Bit Show and Tell video will in addition show you how to hack your turntable to disable the auto return if you need to!</p>



<figure><p><span><iframe width="640" height="360" src="https://www.youtube.com/embed/6_CZpFqvDQo?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span>
</p></figure>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

			<div>
	
	<p>
		An avid devotee to pretty much all things pop culture and retro related - I love to share my memories and passion for films, comics, gaming, podcasting... and curiously enough my overwhelming desire to never stop eating beef jerky.		<a href="https://popcultureretrorama.com/author/vicsagepopculture/" rel="author">
			View more posts		</a>
	</p><!-- .author-description -->
</div><!-- .author-bio -->
	
</article></div>]]>
            </description>
            <link>https://popcultureretrorama.com/2019/11/25/35-years-later-a-commodore-64-program-was-found-on-this-1984-album/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24637146</guid>
            <pubDate>Wed, 30 Sep 2020 10:13:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Brief Guide to OTP in Elixir]]>
            </title>
            <description>
<![CDATA[
Score 229 | Comments 89 (<a href="https://news.ycombinator.com/item?id=24637121">thread link</a>) | @NaeosPsy
<br/>
September 30, 2020 | https://serokell.io/blog/elixir-otp-guide | <a href="https://web.archive.org/web/*/https://serokell.io/blog/elixir-otp-guide">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>One of the main advantages of Elixir is that it is awesome for server-side systems. Forget using a million different technologies for things like data persistence, background jobs, and service crash recovery, OTP can supply you with everything.</p><p><em>So what exactly is this magical thing?</em></p><p>In this article, I will introduce you to OTP, look at basic process loops, the GenServer and Supervisor behaviours, and see how they can be used to implement an elementary process that stores funds.</p><p>(This article assumes that you are already familiar with the basics of Elixir. If you’re not, you can check out the <a href="https://elixir-lang.org/getting-started/introduction.html">Getting Started guide</a> on Elixir’s website or use one of the other resources listed in our <a href="https://serokell.io/blog/learn-elixir">Elixir guide</a>.)</p><h2 id="what-is-otp%3F">What is OTP?</h2><p>OTP is an awesome set of tools and libraries that Elixir inherits from Erlang, <a href="https://serokell.io/blog/history-of-erlang-and-elixir">a programming language on whose VM it runs</a>.</p><p>OTP contains a lot of stuff, such as the Erlang compiler, databases, test framework, profiler, debugging tools. But, when we talk about OTP in the context of Elixir, we usually mean the Erlang actor model that is based on lightweight processes and is the basis of what makes Elixir so efficient.</p><h2 id="processes">Processes</h2><p><img src="https://serokell.io/files/dg/dg0wowcg.processes_(1).jpg" alt="Processes divider"></p><p>At the foundation of OTP, there are tiny things called processes.</p><p>Unlike OS processes, they are really, really lightweight. Creating them takes microseconds, and a single machine can easily run multiple thousands of them, simultaneously.</p><p>Processes loosely follow the <a href="https://en.wikipedia.org/wiki/Actor_model">actor model</a>. Every process is <em>basically</em> a mailbox that can receive messages, and in response to those messages it can:</p><ul>
<li>Create new processes.</li>
<li>Send messages to other processes.</li>
<li>Modify its private state.</li>
</ul><p><img src="https://serokell.io/files/j1/j1smm7kp.process.jpg" alt="Process graph"></p><h3 id="spawning-processes">Spawning processes</h3><p>The most basic way to spawn a process is with the spawn command. Let’s open IEx and launch one.</p><pre><code>iex(<span>1</span>)&gt; process = spawn(<span>fn</span> -&gt; IO.puts(<span>"hey there!"</span>) <span>end</span>)
</code></pre><p>The above function will return:</p><pre><code>hey there!

</code></pre><p>First is the result of the function, second is the output of spawn – PID, a unique process identification number.</p><p>Meanwhile, we have a problem with our process. While it did the task we asked it to do, it seems like it is now… dead? 😱</p><p>Let’s use its PID (stored in the variable <code>process</code>) to query for life signs.</p><pre><code>iex(<span>2</span>)&gt; Process.alive?(process)
<span>false</span>
</code></pre><p>If you think about it, it makes sense. The process did what we asked it to do, fulfilled its reason for existence, and closed itself. But there is a way to extend the life of the process to make it more worthwhile for us.</p><h3 id="receive-do-loop">Receive-do loop</h3><p>Turns out, we can extend the process function to a loop that can hold state and modify it.</p><p>For example, let’s imagine that we need to create a process that mimics the funds in a palace treasury. We’ll create a simple process to which you can store or withdraw funds, and ask for the current balance.</p><p>We’ll do that by creating a loop function that responds to certain messages while keeping the state in its argument.</p><pre><code><span><span>defmodule</span> <span>Palace</span></span>.SimpleTreasury <span>do</span>

  <span><span>def</span> <span>loop</span></span>(balance) <span>do</span>
      receive <span>do</span>
        {<span>:store</span>, amount} -&gt;
          loop(balance + amount)
        {<span>:withdraw</span>, amount} -&gt;
          loop(balance - amount)
        {<span>:balance</span>, pid} -&gt;
          send(pid, balance)
          loop(balance)
      <span>end</span>
    <span>end</span>
<span>end</span>
</code></pre><p>In the body of the function, we put the receive statement and pattern match all the messages we want our process to respond to. Every time the loop runs, it will check from the bottom of the mailbox (in order they were received) for messages that match what we need and process them.</p><p>If the process sees any messages with atoms <code>store</code>, <code>withdraw</code>, <code>balance</code>, those will trigger certain actions.</p><p>To make it a bit nicer, we can add an <code>open</code> function and also dump all the messages we don’t need to not pollute the mailbox.</p><pre><code><span><span>defmodule</span> <span>Palace</span></span>.SimpleTreasury <span>do</span>

  <span><span>def</span> <span>open</span></span>() <span>do</span>
    loop(<span>0</span>)
  <span>end</span>

  <span><span>def</span> <span>loop</span></span>(balance) <span>do</span>
    receive <span>do</span>
      {<span>:store</span>, amount} -&gt;
        loop(balance + amount)
      {<span>:withdraw</span>, amount} -&gt;
        loop(balance - amount)
      {<span>:balance</span>, pid} -&gt;
        send(pid, balance)
        loop(balance)
      <span>_</span> -&gt;
        loop(balance)
      <span>end</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre><p>While this seems quite concise, there’s already some boilerplate lurking, and we haven’t even covered corner cases, tracing, and reporting that would be necessary for production-level code.</p><p>In real life, we don’t need to write code with receive do loops. Instead, we use one of the behaviours created by people much smarter than us.</p><h2 id="behaviours">Behaviours</h2><p>Many processes follow certain similar  patterns. To abstract over these patterns, we use behaviours. Behaviours have two parts: abstract code that we don’t have to implement and a callback module that is implementation-specific.</p><p>In this article, I will introduce you to <a href="https://hexdocs.pm/elixir/GenServer.html">GenServer</a>, short for <em>generic server</em>, and <a href="https://hexdocs.pm/elixir/Supervisor.html">Supervisor</a>. Those are not the only behaviours out there, but they certainly are one of the most common ones.</p><h3 id="genserver">GenServer</h3><p><img src="https://serokell.io/files/za/za1kwa33.genserver.jpg" alt="GenServer divider"></p><p>To start off, let’s create a module called <code>Treasury</code>, and add the GenServer behaviour to it.</p><pre><code><span><span>defmodule</span> <span>Palace</span></span>.Treasury <span>do</span>
  <span>use</span> GenServer
<span>end</span>
</code></pre><p>This will pull in the necessary boilerplate for the behaviour. After that, we need to implement the callbacks for our specific use case.</p><p>Here’s what we will use for our basic implementation.</p><table>
  <tbody><tr>
   <td>Callback
   </td>
   <td>What it does
   </td>
   <td>What it <em>usually</em> returns
   </td>
  </tr>
  <tr>
   <td><code>init(state)</code>
   </td>
   <td>Initializes the server.
   </td>
   <td><code>{:ok, state}</code>
   </td>
  </tr>
  <tr>
   <td><code>handle_cast(pid, message)</code>
   </td>
   <td>An async call that doesn’t demand an answer from the server.
   </td>
   <td><code>{:noreply, state}</code>
   </td>
  </tr>
  <tr>
   <td><code>handle_call(pid, from, message)</code>
   </td>
   <td>A synchronous call that demands an answer from the server.
   </td>
   <td><code>{:reply, reply, state}</code>
   </td>
  </tr>
</tbody></table><p>Let’s start with the easy one – <code>init</code>. It takes a state and starts a process with that state.</p><pre><code> <span><span>def</span> <span>init</span></span>(balance) <span>do</span>
   {<span>:ok</span>, balance}
 <span>end</span> 
</code></pre><p>Now, if you look at the simple code we wrote with <code>receive</code>, there are two types of triggers. The first one (<code>store</code> and <code>withdraw</code>)  just asks for the treasury to update its state asynchronously, while the second one (<code>get_balance</code>) waits for an answer. <code>handle_cast</code> can handle the async ones, while <code>handle_call</code>can handle the synchronous one.</p><p>To handle adding and subtracting, we will need two casts. These take a message with the command and the transaction amount and update the state.</p><pre><code><span><span>def</span> <span>handle_cast</span></span>({<span>:store</span>, amount}, balance) <span>do</span>
  {<span>:noreply</span>, balance + amount}
<span>end</span>

<span><span>def</span> <span>handle_cast</span></span>({<span>:withdraw</span>, amount}, balance) <span>do</span>
  {<span>:noreply</span>, balance - amount}
<span>end</span>
</code></pre><p>Finally, <code>handle_call</code>takes the balance call, the caller, and state, and uses all that to reply to the caller and return the same state.</p><pre><code><span><span>def</span> <span>handle_call</span></span>(<span>:balance</span>, _from, balance) <span>do</span>
  {<span>:reply</span>, balance, balance}
<span>end</span>
</code></pre><p>These are all the callbacks we have:</p><pre><code><span><span>defmodule</span> <span>Palace</span></span>.Treasury <span>do</span>
  <span>use</span> GenServer

  <span><span>def</span> <span>init</span></span>(balance) <span>do</span>
    {<span>:ok</span>, balance}
  <span>end</span>

  <span><span>def</span> <span>handle_cast</span></span>({<span>:store</span>, amount}, balance) <span>do</span>
    {<span>:noreply</span>, balance + amount}
  <span>end</span>

  <span><span>def</span> <span>handle_cast</span></span>({<span>:withdraw</span>, amount}, balance) <span>do</span>
    {<span>:noreply</span>, balance - amount}
  <span>end</span>

  <span><span>def</span> <span>handle_call</span></span>(<span>:balance</span>, _from, balance) <span>do</span>
    {<span>:reply</span>, balance, balance}
  <span>end</span>
<span>end</span>
</code></pre><p>To hide the implementation details, we can add client commands in the same module. Since this will be the only treasury of the palace, let’s also give a name to the process equal to its module name when spawning it with <code>start_link.</code>This will make it easier to refer to it.</p><pre><code><span><span>defmodule</span> <span>Palace</span></span>.Treasury <span>do</span>
  <span>use</span> GenServer

  

  <span><span>def</span> <span>open</span></span>() <span>do</span>
    GenServer.start_link(__MODULE_<span>_</span>, <span>0</span>, <span>name:</span> __MODULE_<span>_</span>)
  <span>end</span>

  <span><span>def</span> <span>store</span></span>(amount) <span>do</span>
    GenServer.cast(__MODULE_<span>_</span>, {<span>:store</span>, amount})
  <span>end</span>

  <span><span>def</span> <span>withdraw</span></span>(amount) <span>do</span>
    GenServer.cast(__MODULE_<span>_</span>, {<span>:withdraw</span>, amount})
  <span>end</span>

  <span><span>def</span> <span>get_balance</span></span>() <span>do</span>
    GenServer.call(__MODULE_<span>_</span>, <span>:balance</span>)
  <span>end</span>

  

  <span><span>def</span> <span>init</span></span>(balance) <span>do</span>
    {<span>:ok</span>, balance}
  <span>end</span>

  <span><span>def</span> <span>handle_cast</span></span>({<span>:store</span>, amount}, balance) <span>do</span>
    {<span>:noreply</span>, balance + amount}
  <span>end</span>

  <span><span>def</span> <span>handle_cast</span></span>({<span>:withdraw</span>, amount}, balance) <span>do</span>
    {<span>:noreply</span>, balance - amount}
  <span>end</span>

  <span><span>def</span> <span>handle_call</span></span>(<span>:balance</span>, _from, balance) <span>do</span>
    {<span>:reply</span>, balance, balance}
  <span>end</span>
<span>end</span>
</code></pre><p>Let’s try it out:</p><pre><code><span><span>iex</span><span>(<span>1</span>)</span></span>&gt; Palace<span>.Treasury</span><span>.open</span>()
{:ok, #PID&lt;<span>0.138</span>.<span>0</span>&gt;}
<span><span>iex</span><span>(<span>2</span>)</span></span>&gt; Palace<span>.Treasury</span><span>.store</span>(<span>400</span>)
:ok
<span><span>iex</span><span>(<span>3</span>)</span></span>&gt; Palace<span>.Treasury</span><span>.withdraw</span>(<span>100</span>)
:ok
<span><span>iex</span><span>(<span>4</span>)</span></span>&gt; Palace<span>.Treasury</span><span>.get_balance</span>()
<span>300</span>
</code></pre><p>It works. 🥳</p><p>Here’s <a href="https://elixir-lang.org/cheatsheets/gen-server.pdf">a cheatsheet on GenServer</a> to help you remember where to put what.</p><h3 id="supervisor">Supervisor</h3><p><img src="https://serokell.io/files/7j/7jpa2q4j.supervisor_(1).jpg" alt="Supervisor divider"></p><p>However, just letting a treasury run without supervision is a bit irresponsible, and a good way to lose your funds or your head. 😅</p><p>Thankfully, OTP provides us with the <a href="https://hexdocs.pm/elixir/Supervisor.html">supervisor behaviour</a>. Supervisors can:</p><ul>
<li>start and shutdown applications,</li>
<li>provide fault tolerance by restarting crashed processes,</li>
<li>be used to make a hierarchical supervision structure, called a <em>supervision tree</em>.</li>
</ul><p>Let’s equip our treasury with a simple supervisor.</p><pre><code><span><span>defmodule</span> <span>Palace</span></span>.Treasury.Supervisor <span>do</span>
  <span>use</span> Supervisor

  <span><span>def</span> <span>start_link</span></span>(init_arg) <span>do</span>
    Supervisor.start_link(__MODULE_<span>_</span>, init_arg,  <span>name:</span> __MODULE_<span>_</span>)
  <span>end</span>

  <span><span>def</span> <span>init</span></span>(_init_arg) <span>do</span>
    children = [
      %{
       <span>id:</span> Palace.Treasury,
       <span>start:</span> {Palace.Treasury, <span>:open</span>, []}
      }
    ]   


    Supervisor.init(children, <span>strategy:</span> <span>:one_for_one</span>)
  <span>end</span>
<span>end</span>
</code></pre><p>In its most basic, a supervisor has two functions: <code>start_link()</code>, which runs the supervisor as a process, and <code>init</code>, which provides the arguments necessary for the supervisor to initialize.</p><p>Things we need to pay attention to are:</p><ul>
<li><strong>The list of children.</strong> Here, we list all the processes that we want the supervisor to start, together with their init functions and starting arguments. Each of the processes is a map, with at least the <code>id</code>and <code>start</code> keys in it.</li>
<li><strong>Supervisor’s <code>init</code> function.</strong> To it, we supply the list of children processes and a supervision strategy. Here, we use <code>:one_for_one</code>– if a child process will crash, only that process will be restarted. There are <a href="https://hexdocs.pm/elixir/Supervisor.html#module-strategies">a few more</a>.</li>
</ul><p>Running the <code>Palace.Treasury.Supervisor.start_link()</code> function will open a treasury, which will be supervised by the process. If the treasury crashes, it will get restarted with the initial state – 0.</p><p>If we wanted, we could add several other processes to this supervisor that are relevant to the treasury function, such as a process that can exchange looted items for their monetary value.</p><p>Additionally, we could also duplicate or persist the state of the treasury …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://serokell.io/blog/elixir-otp-guide">https://serokell.io/blog/elixir-otp-guide</a></em></p>]]>
            </description>
            <link>https://serokell.io/blog/elixir-otp-guide</link>
            <guid isPermaLink="false">hacker-news-small-sites-24637121</guid>
            <pubDate>Wed, 30 Sep 2020 10:08:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Little Book of Algorithms: Teach Python to kids (2019)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24636942">thread link</a>) | @asg
<br/>
September 30, 2020 | http://www.mrlaulearning.com/2019/04/LBOA.html | <a href="https://web.archive.org/web/*/http://www.mrlaulearning.com/2019/04/LBOA.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-4531756548067310499" itemprop="description articleBody">
<div dir="ltr" trbidi="on">
<p><a href="https://1.bp.blogspot.com/-6azi-qqwv_U/XoBdl891T6I/AAAAAAAAF8w/CUTzpWBgM2gMYKcvanWVmE1LOXrfuZovQCLcBGAsYHQ/s1600/LBOA%2Bkindle.tif" imageanchor="1"><img data-original-height="1240" data-original-width="874" height="320" src="https://1.bp.blogspot.com/-6azi-qqwv_U/XoBdl891T6I/AAAAAAAAF8w/CUTzpWBgM2gMYKcvanWVmE1LOXrfuZovQCLcBGAsYHQ/s320/LBOA%2Bkindle.tif" width="225"></a></p>
<p><span><br></span>
<span><br>Version 2.0 has now been released and you can read about this <a href="http://www.mrlaulearning.com/2020/06/LBOA2.html" target="_blank">here</a>.&nbsp;</span><br>
<span><br></span>
<span>The text below refers to the original version.</span>
<span><br></span><br>
<span>The Little book of Algorithms is designed to help students build fluency in their Python programming. The book would suit students who have already been introduced to the three basic programming constructs of structured programming, namely sequence, selection and iteration.</span><br>
<span><span><br></span>
<span><span>Following the publishing philosophy of Al Sweigart, "I write books to teach beginners to code. I put them online for free, because programming is too valuable and needs to be accessible to all. (Though I sell print versions to pay rent.)&nbsp;</span></span><span>Get started. It's a great journey."</span></span><br>
<span><span><br></span>
<span>You can buy printed copies directly <a href="https://www.computercombatcards.com/shop" target="_blank">here</a>&nbsp; or via Amazon&nbsp;<a href="https://www.amazon.co.uk/dp/1916116302" target="_blank">here</a>.</span><span><span></span></span></span><br>
<span><span><br></span>
<span>Download the PDF <a href="https://drive.google.com/drive/folders/1FCAfXUKKfVu-i_HzKC9pOaRMM_DjjnvJ?usp=sharing" target="_blank">here</a>&nbsp;which you can print yourself</span></span><br>
<span><span><br></span>
<span>An embedded book is also below:</span></span><br>
<span>

<span><span>Full description:</span></span></span><br>
<span><span><br>This book is designed to help those learning and teaching Computer Science. The aim of the book is to help students build fluency in their Python programming. The book would suit students who have already been introduced to the three basic programming constructs of structured programming, namely sequence, selection and iteration. The learning curve for programming can be quite steep and this book aims to ease this transition by encouraging practise and gradually introducing more complex concepts such as lists and 2D lists, file writing and using procedures and functions. Originally, the book was written for my 14-16 year old students studying for their GCSE Computer Science programming exam. However, I hope a wide range of students and teachers will find this book useful.</span></span></p></div>

</div></div>]]>
            </description>
            <link>http://www.mrlaulearning.com/2019/04/LBOA.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24636942</guid>
            <pubDate>Wed, 30 Sep 2020 09:29:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Letter to the Patent Office from Professor Donald Knuth (1994)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24636837">thread link</a>) | @pncnmnp
<br/>
September 30, 2020 | http://www.pluto.it/files/meeting1999/atti/no-patents/brevetti/docs/knuth_letter_en.html | <a href="https://web.archive.org/web/*/http://www.pluto.it/files/meeting1999/atti/no-patents/brevetti/docs/knuth_letter_en.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<h2><cite>Programming Freedom</cite> - February 1995 - Number 11</h2>

<p>League For Programming Freedom<br>
1 Kendall Square #143<br>
P.O. Box 9171<br>
Cambridge, MA 02139 </p>

<p><em>Programming Freedom</em> is the Newsletter of The League For Programming Freedom.
Visit our web page: <a href="http://lpf.ai.mit.edu/">http://lpf.ai.mit.edu </a>. 
Reproduction of <em>Programming Freedom</em> via all media is encouraged. To reproduce a signed 
article individually, please contact the author for permission.</p>

<hr>

<h2><a name="knuth">Letter to the Patent Office From Professor Donald Knuth</a></h2>

<p>Professor Donald Knuth of Stanford University is the world's leading authority on
algorithms. His magnum opus, the three volume work the "The Art of Computer
Programming," is the most important reference work on algorithms. Knuth also
developed the mathematical text formatter TeX and the idea of "literate
programming". Supporting evidence of Knuth's position are the following distinctions:

</p><dl>
  <dt>National Medal of Science </dt>
  <dt>Member, National Academy of Sciences </dt>
  <dt>Member, National Academy of Engineering </dt>
  <dt>Fellow, American Academy of Arts and Sciences </dt>
  <dt>Turing Award, Association for Computing Machinery </dt>
  <dt>18 Honorary Doctorates </dt>
</dl>

<p>The first four of these distinctions are the highest American awards for scientists.
Since there is no Nobel prize in computing, the receipt of the Turing award is often
regarded as having a similar status.</p>

<p>Through these honors, Knuth is perhaps the most distinguished living exponent of the
field of computer science. He is also now a member of the League for Programming Freedom.</p>

<p>Here is the letter he sent in February 1994 to the Patent Commissioner on the subject
of software patents.</p>

<pre>Commissioner of Patents and Trademarks
Box 4
Patent and Trademark Office
Washington, DC 20231

Dear Commissioner:

Along with many other computer scientists, I would like to ask you to 
reconsider the current policy of giving patents for computational 
processes.  I find a considerable anxiety throughout the community of 
practicing computer scientists that decisions by the patent courts and the 
Patent and Trademark Office are making life much more difficult for 
programmers.

In the period 1945-1980, it was generally believed that patent law did not 
pertain to software.  However, it now appears that some people have 
received patents for algorithms of practical importance - e.g., Lempel-Ziv 
compression and RSA public key encryption - and are now legally preventing 
other programmers from using these algorithms.

This is a serious change from the previous policy under which the computer 
revolution became possible, and I fear this change will be harmful for 
society.  It certainly would have had a profoundly negative effect on my 
own work: For example, I developed software called TeX that is now used to 
produce more than 90% of all books and journals in mathematics and physics 
and to produce hundreds of thousands of technical reports in all scientific 
disciplines.  If software patents had been commonplace in 1980, I would not 
have been able to create such a system, nor would I probably have ever 
thought of doing it, nor can I imagine anyone else doing so.

I am told that the courts are trying to make a distinction between 
mathematical algorithms and nonmathematical algorithms.  To a computer 
scientist, this makes no sense, because every algorithm is as mathematical 
as anything could be.  An algorithm is an abstract concept unrelated to 
physical laws of the universe.

Nor is it possible to distinguish between "numerical" and "nonnumerical" 
algorithms, as if numbers were somehow different from other kinds of 
precise information.  All data are numbers, and all numbers are data.  
Mathematicians work much more with symbolic entities than with numbers.

Therefore the idea of passing laws that say some kinds of algorithms belong 
to mathematics and some do not strikes me as absurd as the 19th century 
attempts of the Indiana legislature to pass a law that the ratio of a 
circle's circumference to its diameter is exactly 3, not approximately 
3.1416.  It's like the medieval church ruling that the sun revolves about 
the earth.  Man-made laws can be significantly helpful but not when they 
contradict fundamental truths.

Congress wisely decided long ago that mathematical things cannot be 
patented.  Surely nobody could apply mathematics if it were necessary to 
pay a license fee whenever the theorem of Pythagoras is employed.  The 
basic algorithmic ideas that people are now rushing to patent are so 
fundamental, the result threatens to be like what would happen if we 
allowed authors to have patents on individual words and concepts.  
Novelists or journalists would be unable to write stories unless their 
publishers had permission from the owners of the words.  Algorithms are 
exactly as basic to software as words are to writers, because they are the 
fundamental building blocks needed to make interesting products.  What 
would happen if individual lawyers could patent their methods of defense, 
or if Supreme Court justices could patent their precedents?

I realize that the patent courts try their best to serve society when they 
formulate patent law.  The Patent Office has fulfilled this mission 
admirably with respect to aspects of technology that involve concrete laws 
of physics rather than abstract laws of thought.  I myself have a few 
patents on hardware devices.  But I strongly believe that the recent trend 
to patenting algorithms is of benefit only to a very small number of 
attorneys and inventors, while it is seriously harmful to the vast majority 
of people who want to do useful things with computers.

When I think of the computer programs I require daily to get my own work 
done, I cannot help but realize that none of them would exist today if 
software patents had been prevalent in the 1960s and 1970s.  Changing the 
rules now will have the effect of freezing progress at essentially its 
current level.  If present trends continue, the only recourse available to 
the majority of America's brilliant software developers will be to give up 
software or to emigrate.  The U.S.A.  will soon lose its dominant position.

Please do what you can to reverse this alarming trend.  There are far 
better ways to protect the intellectual property rights of software 
developers than to take away their right to use fundamental building 
blocks.

Sincerely,
Donald E. Knuth
Professor Emeritus
</pre>

<hr>

<p><a href="http://lpf.ai.mit.edu/">http://lpf.ai.mit.edu</a>


</p></div>]]>
            </description>
            <link>http://www.pluto.it/files/meeting1999/atti/no-patents/brevetti/docs/knuth_letter_en.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24636837</guid>
            <pubDate>Wed, 30 Sep 2020 09:02:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Things you should know before beginning with AI projects]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24636568">thread link</a>) | @danroseai
<br/>
September 30, 2020 | http://www.danrose.ai/blog/6-things-you-should-know-before-beginning-with-ai-projects | <a href="https://web.archive.org/web/*/http://www.danrose.ai/blog/6-things-you-should-know-before-beginning-with-ai-projects">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" id="item-5f743a28e5310349ea445dcf"><div><div><div data-block-type="2" id="block-c8418527ee189da586b5"><div><p>Artificial intelligence(AI) projects are becoming commonplace for big business and entrepreneurs alike. As a result many people with no prior experience with AI are now being put in charge of AI projects. Almost 5 years ago that happened to me for the first time and I’ve since learned a lot. So here’s six things I wish I had known, when I did my first AI project.</p><h2>1. Data is the most expensive part</h2><p>AI is often talked about as being technically very difficult requiring extensive resources to develop. But in fact that’s not the complete truth. The development can be costly but the vast majority of the work and resources needed is usually in acquiring, cleaning and preparing data for the development to take place.&nbsp;<br></p><p>Data is also the most crucial element when trying to make the AI successfully do its job. As a result you should always prefer superior data over superior technology when making AI models.<br></p><p>So when budgeting for an AI project make sure that you set a side most of the time and money for getting a lot of good quality data. And remember that you might even need to acquire fresh data continuously if the domain you work in has changing conditions.</p><h2>2. AI technology is more accessible than you think</h2><p>In a very short time AI have made the jump from requiring specialist data scientists and machine learning engineers to where we can now make AI models without a single line of code. A multitude of AutoML(Automatic machine learning) vendors have appeared in the later years and they are rapidly improving. That means that getting started on AI doesn’t require as much investment as before.&nbsp;<br></p><p>The data acquisition and the human processes, like training and onboarding, still requires hard work though and neither should be underestimated.</p><h2>3. AI is experimental&nbsp;</h2><p>Developing AI is an experimental process. You cannot know how long it will take to develop what you have in mind or how good it will be. In some cases you cannot even be sure that AI is a feasible solution to your problem before trying.&nbsp;<br></p><p>The best way to succeed with uncertain project conditions like this, is to time cap and milestone fund the project. Set short milestones and only release more funds for a project if the goals for each milestone has been met or at least that you see meaningful progress. If you fund the whole project up front you might end up pouring all your money into a dead end that could have been caught early.&nbsp;</p><h2>4. Be clear on what the succes is to your project&nbsp;</h2><p>Before getting started you should be very clear with your stakeholders what a successful project will look like. New technology like AI can quickly be held to golden standards that it will never achieve. If expectations are not aligned before the kick off you might end up thinking you made a fantastic solution while some of your stakeholders are disappointed. In my experience the exact same AI solution can amaze some people and seem novel to others.<br></p><p>A good way to deal with this is to make all stakeholders agree that the first version of the AI should just be able to deliver the status quo. From there you can improve and gradually increase the value.</p><h2>5. Users will lose sense of control</h2><p>It can be hard to explain the inner workings and the reasoning behind an AI’s output. At the same time you cannot exactly know what output it will give, given a specific input. That will make it feel just as or even more unpredictable than humans doing the same tasks. As the users of an AI cannot ask questions or know if feedback given the AI will make a difference, the users will often feel a lost sense of control.&nbsp;<br></p><p>To avoid that feeling you must first of all prepare the user of this new paradigm. It’s much easier if they buy in on these conditions before they get to try the AI. If possible you can also provide feedback mechanisms so the users will at least feel that they can make a difference. Not that it will work every time but it’s better than nothing.&nbsp;<br></p><p>It’s also a good idea to manage expectations through the right narrative. Make it clear if the AI is a decision system, that makes decisions on it’s own or a support system that is just suggesting. By clearly understanding the purpose of the AI the users usually get more comfortable with it quicker.</p><h2>6. People have very different understandings of what AI is&nbsp;</h2><p>As a rule of thumb everyone has a different understanding of AI. The managers, users, developers and all other stakeholders will have their unique understanding of what AI actually is. That’s very fair since AI does not have one definite definition, but it will be a source of problems if everyone involved in a project has a different understanding of what is going on. So before you start a project, make sure not to take for granted that anybody thinks the way you do. Be explicit about what AI means to you and how you will approach it.</p></div></div></div></div></div></div></div>]]>
            </description>
            <link>http://www.danrose.ai/blog/6-things-you-should-know-before-beginning-with-ai-projects</link>
            <guid isPermaLink="false">hacker-news-small-sites-24636568</guid>
            <pubDate>Wed, 30 Sep 2020 08:02:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Dark Side of ITER]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24636418">thread link</a>) | @olvy0
<br/>
September 30, 2020 | https://news.newenergytimes.net/2020/06/15/the-dark-side-of-iter/ | <a href="https://web.archive.org/web/*/https://news.newenergytimes.net/2020/06/15/the-dark-side-of-iter/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<div>
<p><img src="http://newenergytimes.com/v2/images/ITER-dark.jpg"></p>
<p><a href="http://news.newenergytimes.net/iter-fusion-power-output-consumption-facts-and-falsehoods/">Return to ITER Power Facts Main Page</a></p>
<p><strong>Summary</strong></p>
<p>Since at least 1993, scientists representing the nuclear fusion community have convinced members of the U.S. Congress that the International Thermonuclear Experimental Reactor (ITER), under construction in Southern France, is designed to produce 500 million Watts of thermal power, ten times more electrical power than the reactor is designed to consume.</p>
<p>This is not true.</p>
<p>Later, other fusion scientists convinced the European Parliament and European Commission to publish similar falsehoods about ITER. In fact, the <a href="http://newenergytimes.com/v2/sr/iter/ITER-fusion-reactor-effects.shtml">list of organizations</a> that have, as a result of the fusion scientists’ <a href="http://newenergytimes.com/v2/sr/iter/ITER-fusion-reactor-causes.shtml">claims</a>, inadvertently published falsehoods about ITER in the last decade is extensive.</p>
<p>As revealed by <em>New Energy Times</em> in 2017 and in a subsequent 2019 statement from the United Kingdom Atomic Energy Authority, if the ITER reactor works according to design, the ITER reactor should produce about as much power from fusion as the electricity required to operate the entire device. A statement by a Japanese government fusion organization also describes the expected overall device power balance accurately: “ITER is about equivalent to a zero (net) power reactor, when the plasma is burning.” A German government document uncovered by <em>New Energy Times</em> also reveals that the reactor’s overall output will be equivalent to zero net power.</p>
<p>The actual design goal for the ITER reactor is to create a plasma of 500 megawatts (thermal) for around twenty minutes while 50 megawatts of thermal power are injected into the tokamak, resulting in a ten-fold gain of plasma heating power, not reactor power.</p>
<p>The enormity of this false science claim, in terms of involved scientists, expenditure of taxpayer funds from China, the European Union, India, Japan, Korea, Russia, and the United States is unprecedented and is therefore difficult to conceive. Deception and fraud are ugly words that nobody in the scientific world wants to be associated with. Nevertheless, over the course of three decades, it happened.</p>
<p>Much like the perpetual motion frauds from a century ago, which employed hidden mechanical devices to supply power, scientists promoting ITER have hidden the reactor’s expected input power through specific wording, omitted facts, undisclosed terminology, and deceit.</p>
<p>“<a href="http://newenergytimes.com/v2/sr/iter/The-Dark-Side-of-ITER-20200615.pdf">The Dark Side of ITER</a>,” published on June 15, 2020, by Steven B. Krivit, editor of <em>New Energy Times</em>, explains what happened.</p>
			</div><!--/entry -->
		</div></div>]]>
            </description>
            <link>https://news.newenergytimes.net/2020/06/15/the-dark-side-of-iter/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24636418</guid>
            <pubDate>Wed, 30 Sep 2020 07:24:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It Is Never a Compiler Bug Until It Is]]>
            </title>
            <description>
<![CDATA[
Score 244 | Comments 130 (<a href="https://news.ycombinator.com/item?id=24636326">thread link</a>) | @nullc
<br/>
September 30, 2020 | http://r6.ca/blog/20200929T023701Z.html | <a href="https://web.archive.org/web/*/http://r6.ca/blog/20200929T023701Z.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>Last week I was trying to add some <a href="https://github.com/bitcoin-core/secp256k1/pull/822/commits/aa833603a6b4c947c21da04aeac40d80444ebcc1#diff-b04459e37839cd223176618536295715R425">testing code to libsecp256k1</a> and I was pulling out my hair trying to get it to work.
No amount of <code>printf</code> was working to illuminate what I was doing wrong.
Finally, out of desperation, I thought I would do a quick check to see if there are any compiler bugs related to <code>memcmp</code>, and lo and behold, I found <a href="https://gcc.gnu.org/bugzilla/show_bug.cgi?id=95189">GCC bug #95189: memcmp being wrongly stripped like strcmp</a>.</p><p>Honestly this was a pretty horrifying bug to read about.
Under some circumstances GCC 9 and 10 will cause <code>memcmp</code> to return an incorrect value when one of the inputs is statically known array that contains <code>NULL</code> bytes.
As I rushed to <a href="https://gist.githubusercontent.com/roconnor/2b8e22e829ed80088ed6690cc3c7f3a8/raw/455571a6d9053c597c1585debe6f9dbd6af85071/gistfile1.txt">recompile my computer system using GCC 8</a>, I contemplated the vast consequences of such a bug could be, and pondered how it was possible that computers could function at all.</p><p>However over the week, with the help of my colleagues, we managed to get a better understanding of the scope of the bug.
The bug can only convert non-zero values to zero values.
The static array needs to have a <code>NULL</code> byte within the first 4 bytes.
Most importantly, the <code>memcmp</code> result must not immediately be compared to <code>0</code> for equality or inequality, or any equivalent test.
A different code path is taken in the compiler in that case.
That explained why computers were still functioning.
I expect the vast majority of the uses of <code>memcmp</code> does an immediate test for equality with <code>0</code>.</p><p>I still wondered though, how much code was being affected. My colleague Tim suggested that it would be possible to instrument GCC to emit a message when it was about to miscompile a program.
Together we came up with <a href="https://gcc.gnu.org/bugzilla/attachment.cgi?id=49276&amp;action=diff">a patch</a> to GCC 9 and 10 that would print a debugging message.
Once again, I recompiled my entire system, to see what GCC was miscompiling.
This is what I found:</p><ul>
<li><a href="https://github.com/unicode-org/icu/blob/4fb47b12a70737ee12326220e71c2d73c5ec658f/icu4c/source/common/uniset_props.cpp#L709">https://github.com/unicode-org/icu/blob/4fb47b12a70737ee12326220e71c2d73c5ec658f/icu4c/source/common/uniset_props.cpp#L709</a></li>
<li><a href="https://github.com/xiph/flac/blob/ce6dd6b5732e319ef60716d9cc9af6a836a4011a/src/flac/decode.c#L1310">https://github.com/xiph/flac/blob/ce6dd6b5732e319ef60716d9cc9af6a836a4011a/src/flac/decode.c#L1310</a></li>
<li><a href="https://github.com/torvalds/linux/blob/fb0155a09b0224a7147cb07a4ce6034c8d29667f/drivers/atm/zatm.c#L1172">https://github.com/torvalds/linux/blob/fb0155a09b0224a7147cb07a4ce6034c8d29667f/drivers/atm/zatm.c#L1172</a></li>
<li><a href="https://github.com/nss-dev/nss/blob/1f3746f5107535a47bb4e3969f561e1bd1314bab/gtests/pk11_gtest/pk11_chacha20poly1305_unittest.cc#L425">https://github.com/nss-dev/nss/blob/1f3746f5107535a47bb4e3969f561e1bd1314bab/gtests/pk11_gtest/pk11_chacha20poly1305_unittest.cc#L425</a></li>
<li><a href="https://github.com/GNOME/glib/blob/010569b3734f864fcf584f771915b78bd391eb5f/glib/tests/refstring.c#L70">https://github.com/GNOME/glib/blob/010569b3734f864fcf584f771915b78bd391eb5f/glib/tests/refstring.c#L70</a></li>
<li><a href="https://github.com/heimdal/heimdal/blob/7ae2dfd853c87f9cbecb6f399de4dad09bad4606/lib/gssapi/krb5/arcfour.c#L390">https://github.com/heimdal/heimdal/blob/7ae2dfd853c87f9cbecb6f399de4dad09bad4606/lib/gssapi/krb5/arcfour.c#L390</a>, <a href="https://github.com/heimdal/heimdal/blob/7ae2dfd853c87f9cbecb6f399de4dad09bad4606/lib/gssapi/krb5/arcfour.c#L661">https://github.com/heimdal/heimdal/blob/7ae2dfd853c87f9cbecb6f399de4dad09bad4606/lib/gssapi/krb5/arcfour.c#L661</a>, <a href="https://github.com/heimdal/heimdal/blob/7ae2dfd853c87f9cbecb6f399de4dad09bad4606/lib/gssapi/krb5/arcfour.c#L1279">https://github.com/heimdal/heimdal/blob/7ae2dfd853c87f9cbecb6f399de4dad09bad4606/lib/gssapi/krb5/arcfour.c#L1279</a></li>
<li><a href="https://github.com/zeromq/libzmq/blob/22d218a182855f28038e865cb75bf5897ff0c786/tests/test_mock_pub_sub.cpp#L203">https://github.com/zeromq/libzmq/blob/22d218a182855f28038e865cb75bf5897ff0c786/tests/test_mock_pub_sub.cpp#L203</a></li>
<li><a href="https://github.com/pigoz/mplayer-svn/blob/8d651873a9eb193f5155ffb51ece206f187cf00f/sub/sub_cc.c#L391-L412">https://github.com/pigoz/mplayer-svn/blob/8d651873a9eb193f5155ffb51ece206f187cf00f/sub/sub_cc.c#L391-L412</a></li>
</ul>
<p>On my entire system I only found 10 lines of code that were miscompiled.
Three lines are tests.
All of the lines could be rewritten as a comparison to 0.
None of the lines looked that serious.
I am not sure which one is the worse: the reduced message integrity code(?) from some ARCFOUR implementation or the something something from an ATM driver?</p><p>The mplayer miscompilation is the most mysterious.
The code surrounding that function all appears to be immediately compare <code>memcmp</code> with <code>0</code>.
And given that my debug message refused to point to exactly what line is being miscompiled in that function, I fear some set of optimizations has happened to allow this code to be miscompiled in some way.</p><p>With more hardware I could do <a href="https://hydra.nixos.org/jobset/nixpkgs/trunk#tabs-jobs">a more thorough investigation</a> of the consequences of this GCC bug.
Until then I am going to stick with GCC 8 until GCC 9 and 10 have a new point releases.

</p></div></div>]]>
            </description>
            <link>http://r6.ca/blog/20200929T023701Z.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24636326</guid>
            <pubDate>Wed, 30 Sep 2020 07:01:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deutsch's Algorithm]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24636246">thread link</a>) | @keyboardman
<br/>
September 29, 2020 | https://leimao.github.io/blog/Deutsch-Algorithm/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/Deutsch-Algorithm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>Deutsch’s algorithm is the simplest quantum computing algorithm invented to solve a slightly contrived problem. Suppose we have a black-box function $f(x)$ which maps from the set $\{0,1\}$ to the set $\{0,1\}$. It is easy to speculate that there are four possible mappings for $f(x)$. We call the function $f(x)$ constant if $f(0) = f(1)$, otherwise we call the function $f(x)$ balanced.</p>



<p>With classical circuits, we would have to run the black-box $f(x)$ twice to evaluate $f(0)$ and $f(1)$ and compare the values of $f(0)$ and $f(1)$ to see if they are equivalent or not. With quantum circuits, because we could take advantage of superposition, probably we could do better with fewer runs and operations.</p>



<p>In this blog post, I would like to discuss the Deutsch’s algorithm.</p>

<h3 id="prerequisites">Prerequisites</h3>

<h4 id="separable-and-entangled-states">Separable and Entangled States</h4>

<p>States that can be broken into the Kronecker product of states from the constituent subsystems are called separable states, whereas states that are unbreakable are referred to as entangled states.</p>



<p>For example, we have the following two states $| \psi \rangle$ and $| \psi^{\prime} \rangle$.</p><p>

\[\begin{align}
| \psi \rangle &amp;= \frac{| 0, 0 \rangle - | 0, 1 \rangle + | 1, 0 \rangle - | 1, 1 \rangle}{2}\\
&amp;= \frac{| 0\rangle \otimes | 0 \rangle - | 0\rangle \otimes | 1 \rangle + | 1\rangle \otimes | 0 \rangle - | 1\rangle \otimes | 1 \rangle}{2}\\
&amp;= \frac{| 0 \rangle + | 1 \rangle}{\sqrt{2}} \otimes \frac{| 0 \rangle - | 1 \rangle}{\sqrt{2}} \\
| \psi^{\prime} \rangle &amp;= \frac{| 0, 1 \rangle + | 1, 0 \rangle}{\sqrt{2}}\\
\end{align}\]

</p><p>$| \psi \rangle$ is separable and $| \psi^{\prime} \rangle$ is entangled.</p>

<h4 id="unitary-quantum-operator">Unitary Quantum Operator</h4>

<p>Every quantum operator $U$ is unitary and thus reversible. Because $UU^{\dagger} = U^{\dagger}U = I$, we have</p><p>

\[\begin{align}
U^{\dagger} (U |\varphi\rangle) &amp;= (U^{\dagger} U) |\varphi\rangle \\
&amp;= I |\varphi\rangle \\ 
&amp;= |\varphi\rangle \\ 
\end{align}\]

</p><h4 id="hadamard-operator">Hadamard Operator</h4>

<p>Hardmard operator is a special quantum operator.</p><p>

\[\begin{align}
H &amp;= 
\begin{bmatrix} 
    \frac{1}{\sqrt{2}} &amp; \frac{1}{\sqrt{2}} \\
    \frac{1}{\sqrt{2}} &amp; -\frac{1}{\sqrt{2}} \\
\end{bmatrix}  
\end{align}\]

</p><p>Notice that $H^{\dagger} = H$, therefore</p><p>

\[\begin{align}
H^{\dagger} (H |\varphi\rangle) &amp;= H (H |\varphi\rangle) \\
&amp;= (H^2) |\varphi\rangle \\
&amp;= I |\varphi\rangle \\ 
&amp;= |\varphi\rangle \\ 
\end{align}\]

\[\begin{align}
H|0\rangle &amp;= 
\begin{bmatrix} 
    \frac{1}{\sqrt{2}} &amp; \frac{1}{\sqrt{2}} \\
    \frac{1}{\sqrt{2}} &amp; -\frac{1}{\sqrt{2}} \\
\end{bmatrix}  
\begin{bmatrix} 
    1 \\
    0 \\
\end{bmatrix}  \\
&amp;= 
\begin{bmatrix} 
    \frac{1}{\sqrt{2}} \\
    \frac{1}{\sqrt{2}} \\
\end{bmatrix}  \\
&amp;= \frac{|0\rangle + |1\rangle}{\sqrt{2}}
\end{align}\]

\[\begin{align}
H\frac{|0\rangle + |1\rangle}{\sqrt{2}} &amp;= HH|0\rangle \\
&amp;= I|0\rangle \\
&amp;= |0\rangle \\
\end{align}\]

\[\begin{align}
H|1\rangle &amp;= 
\begin{bmatrix} 
    \frac{1}{\sqrt{2}} &amp; \frac{1}{\sqrt{2}} \\
    \frac{1}{\sqrt{2}} &amp; -\frac{1}{\sqrt{2}} \\
\end{bmatrix}  
\begin{bmatrix} 
    0 \\
    1 \\
\end{bmatrix}  \\
&amp;= 
\begin{bmatrix} 
    \frac{1}{\sqrt{2}} \\
    -\frac{1}{\sqrt{2}} \\
\end{bmatrix}  \\
&amp;= \frac{|0\rangle - |1\rangle}{\sqrt{2}}
\end{align}\]

\[\begin{align}
H\frac{|0\rangle - |1\rangle}{\sqrt{2}} &amp;= HH|1\rangle \\
&amp;= I|1\rangle \\
&amp;= |1\rangle \\
\end{align}\]

</p><h4 id="reducing-sum-or-difference-to-boolean">Reducing Sum or Difference to Boolean</h4>

<p>If $f(x)$ maps from the set $\{0,1\}$ to the set $\{0,1\}$, we have</p><p>

\[\begin{align}
(-1)^{f(1) - f(0)} = (-1)^{f(0) \oplus f(1)}
\end{align}\]

</p><p>Where $\oplus$ is $\text{XOR}$ (binary addition modulo 2).</p>

<h3 id="deutschs-algorithm">Deutsch’s Algorithm</h3>

<p>The black-box $f(x)$ is represented using a quantum gate $U_f$. Just like the classical gate for $f(x)$, it has four possible candidates. Our job is to determine whether the $f(x)$ corresponding to the $U_f$ is constant or balanced.</p>

<div>
<figure>
    <img src="https://leimao.github.io/images/blog/2020-06-23-Deutsch-Algorithm/Uf.png">
    <figcaption>$U_f$</figcaption>
</figure>
</div>

<p>The quantum gate $U_f$ is a unitary matrix which maps from $| x \rangle \otimes | y \rangle$ to $| x \rangle \otimes | y \oplus f(x) \rangle$, namely $U_f (| x \rangle \otimes | y \rangle) = | x \rangle \otimes | y \oplus f(x) \rangle$, for $x, y \in \{0, 1\}$. When $y = 0$, $| y \oplus f(x) \rangle = | 0 \oplus f(x) \rangle = | f(x) \rangle $, $| y \oplus f(x) \rangle$ is just $| f(x) \rangle$.</p>



<p>Note that the above mapping is only valid when $| x \rangle$ and $| y \rangle$ are basic qubit states $| 0 \rangle$ or $| 1 \rangle$. When $| x \rangle$ and $| y \rangle$ are superpositions, the mapping does not necessarily hold.</p>



<p>Let’s further check when $| x \rangle$ and $| y \rangle$ are superpositions, what the outputs from $U_f$ will be. Perhaps we could achieve fewer runs with superpositions.</p>

<h4 id="first-attempt">First Attempt</h4>

<p>In the first attempt, we made the first qubit input to $U_f$ a superposition, which is achieved by applying a Hadamard operator to the input basic state $|0\rangle$. The superposition is</p><p>

\[\begin{align}
H|0\rangle &amp;= \frac{|0\rangle + |1\rangle}{\sqrt{2}}
\end{align}\]

</p><p>The second qubit input to $U_f$ is just a normal  basic state $|0\rangle$.</p>

<div>
<figure>
    <img src="https://leimao.github.io/images/blog/2020-06-23-Deutsch-Algorithm/attempt-1.png">
    <figcaption>First Attempt</figcaption>
</figure>
</div><p>

\[\begin{align}
|\varphi_0\rangle &amp;= |0\rangle \otimes |0\rangle\\
&amp;= |0, 0\rangle \\
\end{align}\]

\[\begin{align}
|\varphi_1\rangle &amp;= (H \otimes I) |\varphi_0\rangle \\
&amp;= (H \otimes I) (|0\rangle \otimes |0\rangle) \\
&amp;= H|0\rangle \otimes I |0\rangle \\
&amp;= \frac{|0\rangle + |1\rangle}{\sqrt{2}} \otimes |0\rangle \\
&amp;= \frac{|0\rangle \otimes |0\rangle + |1\rangle \otimes |0\rangle }{\sqrt{2}} \\
&amp;= \frac{|0, 0\rangle + |1, 0\rangle}{\sqrt{2}} \\
\end{align}\]

\[\begin{align}
|\varphi_2\rangle &amp;= U_f |\varphi_1\rangle \\
&amp;= U_f \frac{|0, 0\rangle + |1, 0\rangle}{\sqrt{2}} \\
&amp;= \frac{U_f |0, 0\rangle + U_f |1, 0\rangle}{\sqrt{2}} \\
&amp;= \frac{U_f (|0\rangle \otimes |0\rangle) + U_f (|1\rangle \otimes |0\rangle)}{\sqrt{2}} \\
&amp;= \frac{|0\rangle \otimes |0 \oplus f(0)\rangle + |1\rangle \otimes |0 \oplus f(1)\rangle}{\sqrt{2}} \\
&amp;= \frac{|0\rangle \otimes |f(0)\rangle + |1\rangle \otimes |f(1)\rangle}{\sqrt{2}} \\
&amp;= \frac{|0, f(0)\rangle + |1, f(1)\rangle}{\sqrt{2}} \\
\end{align}\]

</p><p>If $f(0) = 0$, $f(1) = 1$, one of the balanced cases,</p><p>

\[\begin{align}
|\varphi_2\rangle &amp;= \frac{|0, 0\rangle + |1, 1\rangle}{\sqrt{2}} \\
\end{align}\]

</p><p>Note that this $|\varphi_2\rangle$ is entangled and could be be expressed as the Kronecker product of two qubits. The first qubit output from $U_f$ is not $H|0\rangle$ either. In fact it could not be described using single qubit! The two qubits must be described as a whole due to quantum entanglement. When we observe either the first qubit output or the second qubit output, we immediately know the observation of the other qubit. For example, if we observed the second qubit is 0, we know the observation of the first qubit must be 0. There are 50-50 percent chance observing 0 or 1 for both the first qubit and the second qubit.</p>



<p>If $f(0) = 1$, $f(1) = 0$, one of the balanced cases,</p><p>

\[\begin{align}
|\varphi_2\rangle &amp;= \frac{|0, 1\rangle + |1, 0\rangle}{\sqrt{2}} \\
\end{align}\]

</p><p>This $|\varphi_2\rangle$ is entangled and there are 50-50 percent chance observing 0 or 1 for both the first qubit and the second qubit.</p>



<p>If $f(0) = 0$, $f(1) = 0$, one of the constant cases,</p><p>

\[\begin{align}
|\varphi_2\rangle &amp;= \frac{|0, 0\rangle + |1, 0\rangle}{\sqrt{2}} \\
&amp;= \frac{|0\rangle + |1\rangle}{\sqrt{2}} \otimes |0\rangle\\
&amp;= \frac{-|0\rangle - |1\rangle}{\sqrt{2}} \otimes (-|0\rangle)\\
\end{align}\]

</p><p>This $|\varphi_2\rangle$ is separable. Although we are not sure the exact state the two qubit outputs would be in, due to the phase is not defined, we are sure that the observation of the bottom qubit must be 0.</p>



<p>If $f(0) = 1$, $f(1) = 1$, one of the constant cases,</p><p>

\[\begin{align}
|\varphi_2\rangle &amp;= \frac{|0, 1\rangle + |1, 1\rangle}{\sqrt{2}} \\
&amp;= \frac{|0\rangle + |1\rangle}{\sqrt{2}} \otimes |1\rangle\\
&amp;= \frac{-|0\rangle - |1\rangle}{\sqrt{2}} \otimes (-|1\rangle)\\
\end{align}\]

</p><p>This $|\varphi_2\rangle$ is separable. Although we are not sure the exact state the two qubit outputs would be in, due to the phase is not defined, we are sure that the observation of the bottom qubit must be 1.</p>



<p>However, all of these are not helpful if we are only allowed to run once. After running once, no matter what we observed from the first qubit and the second qubit, we are not sure whether $f(x)$ is constant or balanced.</p>

<h4 id="second-attempt">Second Attempt</h4>

<p>In the second attempt, we made the second qubit input to $U_f$ a superposition, which is achieved by applying a Hadamard operator to the input basic state $|1\rangle$. The superposition is</p><p>

\[\begin{align}
H|1\rangle &amp;= \frac{|0\rangle - |1\rangle}{\sqrt{2}}
\end{align}\]

</p><p>The second qubit input to $U_f$ is a variable and it could be either $|0\rangle$ or $|1\rangle$.</p>

<div>
<figure>
    <img src="https://leimao.github.io/images/blog/2020-06-23-Deutsch-Algorithm/attempt-2.png">
    <figcaption>Second Attempt</figcaption>
</figure>
</div><p>

\[\begin{align}
|\varphi_0\rangle &amp;= |x\rangle \otimes |1\rangle\\
&amp;= |x, 1\rangle \\
\end{align}\]

\[\begin{align}
|\varphi_1\rangle &amp;= (I \otimes H) |\varphi_0\rangle \\
&amp;= (I \otimes H) (|x\rangle \otimes |1\rangle) \\
&amp;= I|x\rangle \otimes H |1\rangle \\
&amp;= |x\rangle \otimes \frac{|0\rangle - |1\rangle}{\sqrt{2}} \\
&amp;= \frac{|x, 0\rangle - |x, 1\rangle}{\sqrt{2}} \\
\end{align}\]

\[\begin{align}
|\varphi_2\rangle &amp;= U_f |\varphi_1\rangle \\
&amp;= U_f \frac{|x, 0\rangle - |x, 1\rangle}{\sqrt{2}} \\
&amp;= \frac{U_f |x, 0\rangle - U_f |x, 1\rangle}{\sqrt{2}} \\
&amp;= \frac{U_f (|x\rangle \otimes |0\rangle) - U_f (|x\rangle \otimes |1\rangle)}{\sqrt{2}} \\
&amp;= \frac{|x\rangle \otimes |0 \oplus f(x)\rangle - |x\rangle \otimes |1 \oplus f(x)\rangle}{\sqrt{2}} \\
&amp;= \frac{|x\rangle \otimes |f(x)\rangle - |x\rangle \otimes |\overline{f(x)}\rangle}{\sqrt{2}} \\
&amp;= |x\rangle \otimes \frac{|f(x)\rangle - |\overline{f(x)}\rangle}{\sqrt{2}} \\
\end{align}\]

</p><p>Because $\frac{|f(x)\rangle - |\overline{f(x)}\rangle}{\sqrt{2}}$ is either $\frac{|0\rangle - |1\rangle}{\sqrt{2}}$ or $\frac{|1\rangle - |0\rangle}{\sqrt{2}}$, $|\varphi_2\rangle $ could be further simplified as</p><p>

\[\begin{align}</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://leimao.github.io/blog/Deutsch-Algorithm/">https://leimao.github.io/blog/Deutsch-Algorithm/</a></em></p>]]>
            </description>
            <link>https://leimao.github.io/blog/Deutsch-Algorithm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24636246</guid>
            <pubDate>Wed, 30 Sep 2020 06:43:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding How UUIDs Are Generated]]>
            </title>
            <description>
<![CDATA[
Score 160 | Comments 58 (<a href="https://news.ycombinator.com/item?id=24636204">thread link</a>) | @aryamansharda
<br/>
September 29, 2020 | https://digitalbunker.dev/2020/09/30/understanding-how-uuids-are-generated/ | <a href="https://web.archive.org/web/*/https://digitalbunker.dev/2020/09/30/understanding-how-uuids-are-generated/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="mainEntityOfPage">
<h2><strong>Introduction</strong></h2>
<p>You’ve likely used UUIDs in projects before and assumed them to be unique. Today, we’ll take a look at the main aspects of the implementation and understand why UUIDs are <em>practically </em>unique, though an incredibly small potential for duplication exists.&nbsp;</p>
<p>The modern day implementation of UUIDs can be tied back to <a href="https://tools.ietf.org/html/rfc4122" target="_blank" rel="noreferrer noopener">RFC 4122 </a>which introduced 5 different approaches for generating these identifiers. We’ll take a look at each one and we’ll step through the implementation details of Version 1 &amp; Version 4 in a moment.&nbsp;</p>
<h2><strong>Background</strong></h2>
<p>UUIDs, or universally unique IDentifiers, are simply a 128 bit number used to uniquely identify items in software development. Their canonical textual representation is as a series of 32 hexadecimal characters which are separated into five groups by hyphens in the form 8-4-4-4-12.&nbsp;</p>
<p>For example,&nbsp;</p>
<p><code>3422b448-2460-4fd2-9183-8000de6f8343</code></p>
<p>Embedded inside this seemingly random series of hexadecimal characters is information about the UUID implementation.&nbsp;</p>
<p><code>xxxxxxxx-xxxx-<strong>M</strong>xxx-<strong>N</strong>xxx-xxxxxxxxxxxx</code></p>
<p>The values in the M and N locations uniquely identify the UUID version and variant respectively.</p>
<h4><strong>Version</strong></h4>
<p>The version number is identified by looking at the most significant 4 bits of the value in the M position.&nbsp;</p>
<p>The following table lists the currently defined versions:</p>
<div><figure><img src="https://lh3.googleusercontent.com/1ePxhp-OP2JdmdHVLd3rbfDc9dcNP5J9QQncT0bYPdJ5W3_2pAHfGZ9a7Q7m3mav6VA1syO22nTIavepVicTMW9YxqiuGcSePUOanJeyz67K_bZwDbd_KO25oLgPirr53qj1wZq9" alt="" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>
<h4><strong>&nbsp;Variant</strong></h4>
<p>The variant field determines the layout of the information embedded in the UUID. The interpretation of all other bits in the UUID depends on the value of the variant.&nbsp;</p>
<p>We identify the variant by considering the first 1-3 most significant bits of N.&nbsp;</p>
<div><figure><img src="https://lh3.googleusercontent.com/FeXxFJcHdVVJA7IorpHtQx67F3eiSkMJVAr2Q5E4t3IierXggi-DR1uthMBOgRBXRP4JzcdRMuHbVqMMkCWZ47fo7sUO8sDBQcwgALwr45qLdpC9bSUBoXKQF9Bhdnnc9kN-g8p9" alt="" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>
<p>The most common implementation nowadays is Variant 1 where the MSB0&nbsp; is fixed as 1 and MSB1 is fixed as 0. This means that considering our wildcard values – the bits marked with an <code>x</code> above – the only possible values are 8, 9, A, or B.</p>
<blockquote><p><strong>Quick Reminder:&nbsp;</strong></p><p>1 0 0 0 = 8&nbsp;</p><p>1 0 0 1 = 9</p><p>1 0 1 0 = A</p><p>1 0 1 1 = B</p></blockquote>
<p>So, if you ever see a UUID with these values in the N position, you’ll know it’s the common Variant 1 type.&nbsp;</p>
<h4><strong>Version 1 (Time Based + Unique or Random Host Identifier)&nbsp;</strong></h4>
<p>In this version, the UUID is generated by taking the current timestamp and some identifying property of the device generating the UUID – most commonly, the MAC address (also called the node ID).&nbsp;</p>
<p>This UUID is generated by concatenating the 48 bit MAC address, a 60 bit-timestamp, and a 14 bit “uniquifying” clock sequence, along with the 6 reserved bits for version and variant to generate a unique UUID.&nbsp;</p>
<blockquote><p>The clock sequence is simply a value incremented every time the clock is modified.&nbsp;</p></blockquote>
<p>The timestamp used in this version is the number of 100 nanosecond time intervals since October 15, 1582 – the date of Gregorian reform to the Christian calendar.&nbsp;</p>
<blockquote><p>You may be familiar with Unix systems and time since epoch. This is simply just a different Day 0. There are several algorithms online that allow you to convert one time representation to the other, so we won’t go over this here.</p></blockquote>
<p>Though this implementation seems fairly straightforward and robust, because it reveals the MAC address of the machine it was generated on, this approach is not suitable for all use cases.&nbsp; Especially, when security is a major concern. Instead, some implementations will use 6 random bytes sourced from a cryptographically secure random number generator as a replacement for the node ID.&nbsp;</p>
<p>&nbsp;To assemble a Version 1 UUID, we’ll do the following steps:&nbsp;</p>
<ol><li>Take the low 32 bits of the current UTC timestamp. This will be the first 4 bytes / 8 hex characters of our UUID [TimeLow]</li><li>Take the middle 16 bits of the current UTC timestamp. These will be the following 2 bytes / 4 hex characters. [TimeMid]</li><li>The next 2 bytes / 4 hex characters will concat the 4 bit UUID version with the remaining high 12 bits of the current UTC timestamp (which is 60 bits in total). [TimeHighAndVersion]</li><li>Now, the next 1-3 bits will specify the variant of the UUID version. The remaining bits will contain the clock sequence which is meant to contribute some small amount of randomness to this implementation. In doing so, it helps avoid collisions in the event multiple UUID generators are running on the same system, a system clock for a UUID generator is set backwards, or the system clock doesn’t advance fast enough. [ClockSequenceHiAndRes &amp;&amp; ClockSequenceLow]</li><li>The final 6 bytes / 12 hex characters / 48 bits are the “node id” which is most commonly the MAC address of the issuing device. [NodeID]</li></ol>
<p>Putting everything together, our Version 1 UUID is generated by concatenating:</p>
<p><code>TimeLow + TimeMid + TimeHighAndVersion + (ClockSequenceHiAndRes &amp;&amp; ClockSequenceLow) + NodeID&nbsp;</code></p>
<p>Due to this implementation’s reliance on the clock, there are some edge cases we’ll need to handle. Firstly, to minimize correlation across systems, the clock sequence is defaulted to a random number – this will only happen once in the lifetime of a system. This has the added benefit of allowing us to support node identifiers that may move from system to system as the initial value of the clock sequence is completely agnostic of the node identifier.&nbsp;</p>
<p>Remember that the main purpose of the clock sequence is to introduce some amount of randomness into the equation. The bits allocated for the clock sequence help us extend the timestamp and account for situations where multiple UUIDs are generated before the processor clock advances. This helps us avoid the potential creation of duplicates when the clock is set backwards in time (device is powered off) or the node ID changes. If the clock is set backwards, or might have been set backwards (e.g., while the system was powered off), and the UUID generator can not be sure that no UUIDs were generated with timestamps larger than the value to which the clock was set, then the clock sequence has to be changed. If the previous value of the clock sequence is known, it can just be incremented; otherwise it should be set to a random or high-quality pseudo-random value.</p>
<h4><strong>Version 2 (Distributed Computing Environment Security)</strong></h4>
<p>The main difference between this version and Version 1 is that this implementation uses some identifier specific to the system in place of the “randomness” generated by using the least significant bits of the clock sequence. This value is often just the current user’s ID. This version is less common and only a small deviation from Version 1, so we won’t explore it any further.&nbsp;</p>
<h4><strong>Version 3 (Name-based + MD5 Hash)</strong></h4>
<p>In the event that you want to have unique identifiers for information within a namespace or for “nameable” information more generally, UUID version 3 and version 5 are your preferred options.&nbsp;</p>
<p>They’ll encode any “nameable” entity (website, DNS information, plain text, etc) into the UUID value. The main takeaway here is that for the same namespace and text, the generated UUID will be the same.&nbsp;</p>
<p>Take note that the namespace itself is a UUID.</p>
<pre><code>let namespace = “digitalbunker.dev”
let namespaceUUID = UUID3(.DNS, namespace)

// Ex: 
UUID3(namespaceUUID, “/category/things-you-should-know-1/”) 
4896c91b-9e61-3129-87b6-8aa299028058

UUID3(namespaceUUID, “/category/things-you-should-know-2/”) 
29be0ee3-fe77-331e-a1bf-9494ec18c0ba

UUID3(namespaceUUID, “/category/things-you-should-know-3/”) 
33b06619-1ee7-3db5-827d-0dc85df1f759
</code></pre>
<p>In this implementation, the UUID of the namespace is transformed to a string of bytes, concatenated with the input name, then hashed with MD5, yielding the 128 bits for the UUID. Then, we’ll overwrite some of those bits to accurately reflect the version and variant information leaving the rest unchanged.&nbsp;</p>
<p>It’s also important to understand that neither the namespace nor the inputted name can be generated from the UUID. This is a one-way operation. The only exception here would be through a brute force approach if one of the values (namespace or text) were known by the attacker.</p>
<p>For Version 3 and Version 5, as long as you use the same inputs, the generated UUID will be deterministic.&nbsp;</p>
<h4><strong>Version 4 (PRNG)</strong></h4>
<p>This is probably the simplest implementation of the bunch.</p>
<p>As we’ve now seen, 6 bits are reserved for the version and variant information leaving us 122 bits free to decide. This version simply generates all 128 random bits and then fills in the values for the version and variant information as a secondary step.&nbsp;</p>
<p>UUIDs of this variety rely heavily on the quality of the PRNG in use (pseudo-random number generator). If the PRNG is lacking a sophisticated algorithm or the correct seed and initialization values, the likelihood of a duplicate can increase. To better understand how computers generate random numbers, <a href="https://digitalbunker.dev/2020/09/08/how-do-computers-generate-random-numbers/" target="_blank" rel="noreferrer noopener">check out my previous article.</a>&nbsp;</p>
<p>Version 4 is what you’ll find most commonly implemented in modern programming languages.</p>
<p>It’s implementation is reasonably simple.&nbsp;</p>
<ol><li>Generate 128 random bits</li><li>Now, we’ll need to overwrite some of these bits with the correct version and variant information&nbsp;<ol><li>Take the 7th byte and perform an AND operation with <code>0x0F</code> to clear out the high nibble. Then, OR it with <code>0x40</code> to set the version number to 4.&nbsp;</li><li>Next, take the 9th byte and perform an AND operation with <code>0x3F</code> and then OR it with <code>0x80</code>.&nbsp;</li></ol></li><li>Convert the 128 bits to hexadecimal representation and insert the hyphens to achieve the canonical text representation.&nbsp;</li></ol>
<h4><strong>Version 5 (Name-based + SHA-1 Hash)</strong></h4>
<p>This version is no different than Version 3 with the exception that the <code>SHA-1</code> hashing algorithm is used here in place of <code>MD5</code>. This version is preferred to Version 3 (SHA-1 &gt; MD5).&nbsp;</p>
<h2><strong>In Practice</strong></h2>
<p>One of the notable benefits of UUIDs is that their uniqueness does not depend on a central authority or coordination between different systems. Anyone can create UUIDs with reasonable assurance that a duplicate value does not exist and will conceivably not be made in the future.&nbsp;</p>
<p>This has the added benefit of allowing UUIDs generated by independent parties to be combined into a single database or moved across databases with a trivial probability of duplication / collision.&nbsp;</p>
<p>Due to this uniqueness, you can use UUIDs as primary keys in databases, unique filenames for uploaded files, unique names for any web resource, or …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://digitalbunker.dev/2020/09/30/understanding-how-uuids-are-generated/">https://digitalbunker.dev/2020/09/30/understanding-how-uuids-are-generated/</a></em></p>]]>
            </description>
            <link>https://digitalbunker.dev/2020/09/30/understanding-how-uuids-are-generated/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24636204</guid>
            <pubDate>Wed, 30 Sep 2020 06:31:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A categorized list of all Java and JVM features since JDK 8 to 15]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24636197">thread link</a>) | @pjmlp
<br/>
September 29, 2020 | https://advancedweb.hu/a-categorized-list-of-all-java-and-jvm-features-since-jdk-8-to-15/ | <a href="https://web.archive.org/web/*/https://advancedweb.hu/a-categorized-list-of-all-java-and-jvm-features-since-jdk-8-to-15/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p><strong>Last updated</strong> on 2020/09/29 to include changes up to <a href="https://openjdk.java.net/projects/jdk/15/">JDK 15</a>.</p> <p>Since the release of version 8, up to version 15, Java is shaped by 163 <a href="http://openjdk.java.net/jeps/0">JDK Enhancement Proposals</a> (JEPs), each of which brings some improvement to the platform. This page is a <strong>categorized</strong> and <strong>curated</strong> list of the most important improvements.</p> <p><img alt="JDK timeline" integrity="sha256-LaVVHICMYi3voV98aHwg0mrUzl6D7m+MpNnEXwTXOWk=" crossorigin="anonymous" src="https://advancedweb.hu/assets/posts/post_java_8/jdktimeline-v3-2da5551c808c622defa15f7c687c20d26ad4ce5e83ee6f8ca4d9c45f04d73969.jpg"></p> <p><strong>Contents of this page:</strong></p> <ul> <li><a href="#new-language-features">New Language Features</a></li> <li><a href="#new-apis">New APIs</a></li> <li><a href="#performance-improvements">Performance Improvements</a></li> <li><a href="#security-improvements">Security Improvements</a></li> <li><a href="#bytecode">Bytecode Changes</a></li> <li><a href="#launching">Launching</a></li> <li><a href="#packaging">Packaging</a></li> <li><a href="#javadoc">Javadoc</a></li> <li><a href="#new-supported-platforms">New Platforms</a></li> <li><a href="#deprecation-and-removal">Deprecation and Removal</a></li> <li><a href="#new-version-scheme">New Version Scheme</a></li> </ul> <p>The full list of JEPs can be found on the OpenJDK website under the <a href="https://openjdk.java.net/projects/jdk/">jdk</a> and <a href="https://openjdk.java.net/projects/jdk9/">jdk9</a> projects.</p> <p>All features are generally available and enabled by default, except if they are labelled with one of the following:</p> <ul> <li> <strong>Preview</strong> 🔍 features are fully specified and implemented, but not yet considered to be final. They are considered to be almost complete, waiting for an additional round of real-world feedback. They have to be <a href="https://openjdk.java.net/jeps/12">explicitly enabled</a>.</li> <li> <strong>Experimental</strong> 💥 features are less stable, and more likely to change. They also have to be explicitly enabled.</li> <li> <strong>Incubator</strong> 🥚 modules are non-final tools and API’s, and are <a href="https://openjdk.java.net/jeps/11">distributed in separate modules</a>.</li> </ul> <h2 id="new-language-features">New Language Features</h2> <p>When Java 8 introduced lambdas it was a pretty huge change. While recent versions did not add such impactful features, lots of smaller improvements were made to the language.</p> <p>Here’s a quick recap on what happened in the last years. For a more in-depth guide, see <a href="https://advancedweb.hu/new-language-features-since-java-8-to-14/">New language features since Java 8</a>.</p><div> <p> Related </p> <div> <p><a href="https://advancedweb.hu/new-language-features-since-java-8-to-14/"> <img integrity="sha256-Ko5UWYfecL05QXbtkFEINWvtXxZRNvydy8FQEPm7Vsw=" crossorigin="anonymous" src="https://advancedweb.hu/assets/53487f-15f99cf9213eacf6f30f40e8d76a4dea7f587df024e1fe2ffa4cf085fa462d21.jpg"> </a> </p> <div>  <p> Enhancements to the Java language you should know </p> </div> </div> </div> <ul> <li>Text Blocks<br> <a href="https://openjdk.java.net/jeps/378">JDK 15</a> (Preview in <a href="https://openjdk.java.net/jeps/368">JDK 14</a> <a href="https://openjdk.java.net/jeps/355">JDK 13</a>) <div> <div><pre><code><span>String</span> <span>html</span> <span>=</span> <span>"""
            &lt;html&gt;
                &lt;body&gt;
                    &lt;p&gt;Hello, world&lt;/p&gt;
                &lt;/body&gt;
            &lt;/html&gt;
            """</span><span>;</span>
</code></pre></div> </div> </li> <li>Sealed Classes can restrict which other classes may extend them (<strong>Preview</strong> 🔍)<br> <a href="https://openjdk.java.net/jeps/360">JDK 15</a> <div> <div><pre><code><span>public</span> <span>abstract</span> <span>sealed</span> <span>class</span> <span>Shape</span>
    <span>permits</span> <span>Circle</span><span>,</span> <span>Rectangle</span> <span>{...}</span>

<span>public</span> <span>class</span> <span>Circle</span> <span>extends</span> <span>Shape</span> <span>{...}</span> <span>// OK</span>
<span>public</span> <span>class</span> <span>Rectangle</span> <span>extends</span> <span>Shape</span> <span>{...}</span> <span>// OK</span>
<span>public</span> <span>class</span> <span>Triangle</span> <span>extends</span> <span>Shape</span> <span>{...}</span> <span>// Compile error</span>

<span>// No need for default case if all permitted types are covered</span>
<span>double</span> <span>area</span> <span>=</span> <span>switch</span> <span>(</span><span>shape</span><span>)</span> <span>{</span>
    <span>case</span> <span>Circle</span> <span>c</span>    <span>-&gt;</span> <span>Math</span><span>.</span><span>pow</span><span>(</span><span>c</span><span>.</span><span>radius</span><span>(),</span> <span>2</span><span>)</span> <span>*</span> <span>Math</span><span>.</span><span>PI</span>
    <span>case</span> <span>Rectangle</span> <span>r</span> <span>-&gt;</span> <span>r</span><span>.</span><span>a</span><span>()</span> <span>*</span> <span>r</span><span>.</span><span>b</span><span>()</span>
<span>};</span>
</code></pre></div> </div> </li> <li>Records (<strong>Preview</strong> 🔍)<br> <a href="https://openjdk.java.net/jeps/384">JDK 15</a> <a href="https://openjdk.java.net/jeps/359">JDK 14</a> <div> <div><pre><code><span>record</span> <span>Point</span><span>(</span><span>int</span> <span>x</span><span>,</span> <span>int</span> <span>y</span><span>)</span> <span>{</span> <span>}</span>
</code></pre></div> </div> </li> <li>Pattern Matching for instanceof (<strong>Preview</strong> 🔍)<br> <a href="https://openjdk.java.net/jeps/375">JDK 15</a> <a href="https://openjdk.java.net/jeps/305">JDK 14</a> <div> <div><pre><code><span>if</span> <span>(</span><span>obj</span> <span>instanceof</span> <span>String</span> <span>s</span><span>)</span> <span>{</span>
    <span>System</span><span>.</span><span>out</span><span>.</span><span>println</span><span>(</span><span>"obj is a String and it' length is "</span> <span>+</span> <span>s</span><span>.</span><span>length</span><span>());</span>
<span>}</span>
</code></pre></div> </div> </li> <li>Switch Expressions<br> <a href="https://openjdk.java.net/jeps/361">JDK 14</a> (Preview in <a href="https://openjdk.java.net/jeps/325">JDK 12</a> <a href="https://openjdk.java.net/jeps/354">JDK 13</a>) <div> <div><pre><code><span>int</span> <span>numLetters</span> <span>=</span> <span>switch</span> <span>(</span><span>day</span><span>)</span> <span>{</span>
    <span>case</span> <span>MONDAY</span><span>,</span> <span>FRIDAY</span><span>,</span> <span>SUNDAY</span> <span>-&gt;</span> <span>6</span><span>;</span>
    <span>case</span> <span>TUESDAY</span>                <span>-&gt;</span> <span>7</span><span>;</span>
    <span>default</span>      <span>-&gt;</span> <span>{</span>
      <span>String</span> <span>s</span> <span>=</span> <span>day</span><span>.</span><span>toString</span><span>();</span>
      <span>int</span> <span>result</span> <span>=</span> <span>s</span><span>.</span><span>length</span><span>();</span>
      <span>yield</span> <span>result</span><span>;</span>
    <span>}</span>
<span>};</span>
</code></pre></div> </div> </li> <li>Helpful NullPointerExceptions describing precisely which variable was null<br> <a href="https://bugs.openjdk.java.net/browse/JDK-8233014">JDK 15</a> (Enabled with <code>-XX:+ShowCodeDetailsInExceptionMessages</code> in <a href="https://openjdk.java.net/jeps/358">JDK 14</a>) <div> <div><pre><code><span>a</span><span>.</span><span>b</span><span>.</span><span>c</span><span>.</span><span>i</span> <span>=</span> <span>99</span><span>;</span>
<span>---</span>
<span>Exception</span> <span>in</span> <span>thread</span> <span>"main"</span> <span>java</span><span>.</span><span>lang</span><span>.</span><span>NullPointerException</span><span>:</span>
      <span>Cannot</span> <span>read</span> <span>field</span> <span>"c"</span> <span>because</span> <span>"a.b"</span> <span>is</span> <span>null</span>
</code></pre></div> </div> </li> <li>Introduction of <code>var</code> to make local variable declarations less ceremonious<br> <a href="https://openjdk.java.net/jeps/323">JDK 11</a> (Without lambda support in <a href="https://openjdk.java.net/jeps/286">JDK 10</a>) <div> <div><pre><code><span>var</span> <span>greeting</span> <span>=</span> <span>"Hello World!"</span><span>;</span>
</code></pre></div> </div> </li> <li>Opt-in and backwards-compatible Module System to avoid <code>ClassDefNotFoundErrors</code> at runtime and create internal APIs<br> <a href="https://openjdk.java.net/jeps/261">JDK 9</a> (Project Jigsaw) <div> <div><pre><code><span>module</span> <span>hu</span><span>.</span><span>advancedweb</span><span>.</span><span>helloworld</span> <span>{</span>
    <span>requires</span> <span>hu</span><span>.</span><span>advancedweb</span><span>.</span><span>somedependency</span><span>;</span>
    <span>exports</span> <span>hu</span><span>.</span><span>advancedweb</span><span>.</span><span>hello</span>
<span>}</span>
</code></pre></div> </div> </li> <li> <p>Private methods in interfaces<br> <a href="https://openjdk.java.net/jeps/213">JDK 9</a> (Milling Project Coin)</p> </li> <li> <p>Diamond operator for anonymous inner classes<br> <a href="https://openjdk.java.net/jeps/213">JDK 9</a> (Milling Project Coin)</p> </li> <li> <p>Try-with-resources allows effectively final variables<br> <a href="https://openjdk.java.net/jeps/213">JDK 9</a> (Milling Project Coin)</p> </li> <li> <p><code>@SafeVargs</code> on private instance methods<br> <a href="https://openjdk.java.net/jeps/213">JDK 9</a> (Milling Project Coin)</p> </li> <li>No deprecation warnings on <code>import</code> statements<br> <a href="https://openjdk.java.net/jeps/211">JDK 9</a> </li> </ul> <p> We write articles like this regularly. <a href="#bottom-promo">Join our mailing list</a> and let's keep in touch. </p> <h2 id="new-apis">New APIs</h2> <p>Let’s continue with the Java Standard Library, focusing on the new features that we can use in day-to-day coding.</p> <p>If you are curious about all the API level differences between Java 8 and 14, check the <a href="https://github.com/AdoptOpenJDK/jdk-api-diff">AdoptOpenJDK/jdk-api-diff on GitHub</a>.</p> <h3 id="general">General</h3> <ul> <li> <p>Support Non-Volatile Mapped Byte Buffers in the FileChannel API<br> <a href="https://openjdk.java.net/jeps/352">JDK 14</a></p> </li> <li> <p><code>Files.mismatch</code>: find the first mismatched byte in the content of two files<br> <a href="https://docs.oracle.com/en/java/javase/12/docs/api/java.base/java/nio/file/Files.html">JDK 12</a></p> </li> <li> <p><code>Collectors.teeing</code> to create a Collector that is a composite of two downstream collectors<br> <a href="https://docs.oracle.com/en/java/javase/12/docs/api/java.base/java/util/stream/Collectors.html#teeing(java.util.stream.Collector,java.util.stream.Collector,java.util.function.BiFunction)">JDK 12</a></p> </li> <li> <p>String enhancements: <code>indent</code> and <code>transform</code><br> <a href="https://docs.oracle.com/en/java/javase/12/docs/api/java.base/java/lang/String.html">JDK 12</a></p> </li> <li>Standard HTTP Client featuring HTTP/2, WebSocket support and non-blocking API<br> <a href="https://openjdk.java.net/jeps/321">JDK 11</a> (<strong>Incubator</strong> 🥚 in <a href="https://openjdk.java.net/jeps/110">JDK 9</a>) <div> <div><pre><code><span>HttpClient</span> <span>httpClient</span> <span>=</span> <span>HttpClient</span><span>.</span><span>newBuilder</span><span>().</span><span>build</span><span>();</span>

<span>HttpRequest</span> <span>request</span> <span>=</span>
  <span>HttpRequest</span><span>.</span><span>newBuilder</span><span>()</span>
    <span>.</span><span>uri</span><span>(</span><span>URI</span><span>.</span><span>create</span><span>(</span><span>"https://advancedweb.hu/"</span><span>))</span>
    <span>.</span><span>GET</span><span>()</span>
    <span>.</span><span>build</span><span>();</span>

<span>HttpResponse</span><span>&lt;</span><span>String</span><span>&gt;</span> <span>response</span> <span>=</span>
  <span>httpClient</span><span>.</span><span>send</span><span>(</span><span>request</span><span>,</span> <span>BodyHandlers</span><span>.</span><span>ofString</span><span>());</span>
</code></pre></div> </div> </li> <li> <p>String enhancements, like <code>isBlank</code>, <code>lines</code>, <code>repeat</code> and <code>strip</code><br> <a href="https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/lang/String.html">JDK 11</a></p> </li> <li>Convenience Factory Methods for Collections to ease the pain of not having collection literals<br> <a href="https://openjdk.java.net/jeps/269">JDK 9</a> <div> <div><pre><code><span>Set</span><span>&lt;</span><span>Integer</span><span>&gt;</span> <span>mySet</span> <span>=</span> <span>Set</span><span>.</span><span>of</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>);</span>
<span>List</span><span>&lt;</span><span>Integer</span><span>&gt;</span> <span>myList</span> <span>=</span> <span>List</span><span>.</span><span>of</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>);</span>
<span>Map</span><span>&lt;</span><span>String</span><span>,</span> <span>Integer</span><span>&gt;</span> <span>myMap</span> <span>=</span> <span>Map</span><span>.</span><span>of</span><span>(</span><span>"one"</span><span>,</span> <span>1</span><span>,</span> <span>"two"</span><span>,</span> <span>2</span><span>);</span>
</code></pre></div> </div> </li> <li> <p>Reactive Streams publish-subscribe framework for asynchronous stream processing with non-blocking backpressure<br> <a href="https://openjdk.java.net/jeps/266">JDK 9</a></p> </li> <li> <p>Time-based enhancements to <code>CompletableFuture</code> (timeout, delay)<br> <a href="https://openjdk.java.net/jeps/266">JDK 9</a></p> </li> <li> <p>More options to transform (<code>dropWhile</code>, <code>takeWhile</code>) and generate (<code>iterate</code>, <code>ofNullable</code>) streams; readonly collectors (<code>toUnmodifiableList</code>); optionals can be transformed to streams<br> <a href="https://docs.oracle.com/javase/9/docs/api/java/util/stream/Stream.html#iterate-T-java.util.function.UnaryOperator-">JDK 9</a></p> </li> <li> <p><code>Arrays.mismatch</code>: find the first mismatching element between two arrays<br> <a href="https://docs.oracle.com/javase/9/docs/api/java/util/Arrays.html#mismatch-java.lang.Object:A-java.lang.Object:A-">JDK 9</a></p> </li> <li> <p>Stack-Walking API that allows laziness and stack-frame filtering<br> <a href="https://openjdk.java.net/jeps/259">JDK 9</a></p> </li> <li> <p>Process API provides more info and control (e.g. process ID, arguments, CPU time, parent/child processes), enhance <code>ProcessBuilder</code> to aid the creation of process pipelines<br> <a href="https://openjdk.java.net/jeps/102">JDK 9</a></p> </li> <li> <p><code>VarHandle</code> API to replace the field and array related operations of <code>java.util.concurrent.atomic</code> and <code>sun.misc.Unsafe</code> in order to and provide low-level access mechamisms, e.g. atomic write.<br> <a href="https://openjdk.java.net/jeps/193">JDK 9</a></p> </li> <li> <p>New combinators and lookup methods for <code>MethodHandle</code><br> <a href="https://openjdk.java.net/jeps/274">JDK 9</a></p> </li> <li> <p>Enhanced Deprecation policy. <code>@Deprecated</code> can be marked with <code>forRemoval</code>, which emits a new warning.<br> <a href="https://openjdk.java.net/jeps/277">JDK 9</a></p> </li> <li> <p>OASIS Standard XML Catalog API to manage external resources in XMLs in a secure and performant manner<br> <a href="https://openjdk.java.net/jeps/268">JDK 9</a></p> </li> <li> <p>Update JDK’s XML parser, Xerces, to version 2.11.0<br> <a href="https://openjdk.java.net/jeps/255">JDK 9</a></p> </li> <li>TIFF Support for Image I/O Framework<br> <a href="https://openjdk.java.net/jeps/262">JDK 9</a> </li> </ul> <h3 id="internationalization">Internationalization</h3> <ul> <li> <p>Unicode 10.0, adding roughly 27.000 characters, 10 blocks, and more than 30 scripts<br> <a href="https://openjdk.java.net/jeps/327">JDK 11</a> (Unicode 8.0 support in <a href="https://openjdk.java.net/jeps/267">JDK 9</a>)</p> </li> <li> <p><code>java.util.Locale</code> and related APIs support currency type, time zone and more<br> <a href="https://openjdk.java.net/jeps/314">JDK 10</a></p> </li> <li> <p><code>ResourceBundle</code> loads properties files in UTF-8 instead of ISO-8859-1<br> <a href="https://openjdk.java.net/jeps/226">JDK 9</a></p> </li> <li> <p>CLDR Locale Data Enabled by Default<br> <a href="https://openjdk.java.net/jeps/252">JDK 9</a></p> </li> </ul> <h3 id="graphics-and-desktop-applications">Graphics and Desktop Applications</h3> <ul> <li> <p>Desktop features for all platforms like login/logout/lock event listener and task bar interactions<br> <a href="https://openjdk.java.net/jeps/272">JDK 9</a></p> </li> <li> <p><code>MultiResolutionImage</code> that makes easy to retrieve a resolution-specific image for a DPI<br> <a href="https://openjdk.java.net/jeps/251">JDK 9</a></p> </li> <li> <p>HiDPI Graphics on Windows and Linux<br> <a href="https://openjdk.java.net/jeps/263">JDK 9</a></p> </li> <li> <p>Enable GTK 3 on Linux for JavaFX, Swing, and AWT<br> <a href="https://openjdk.java.net/jeps/283">JDK 9</a></p> </li> <li> <p>Replace <code>@beaninfo</code> Javadoc tags with <code>@BeanInfo</code> annotations for Swing<br> <a href="https://openjdk.java.net/jeps/256">JDK 9</a></p> </li> <li> <p>Update GStreamer included in JavaFX/Media to version 1.4.4<br> <a href="https://openjdk.java.net/jeps/257">JDK 9</a></p> </li> <li> <p>Replace the existing ICU OpenType font-layout engine with HarfBuzz<br> <a href="https://openjdk.java.net/jeps/258">JDK 9</a></p> </li> </ul> <h2 id="performance-improvements">Performance Improvements</h2> <h3 id="general-1">General</h3> <ul> <li> <p>Foreign-Memory Access API to safely and efficiently use off-heap memory (<strong>Incubator</strong> 🥚)<br> <a href="https://openjdk.java.net/jeps/383">JDK 15</a> <a href="https://openjdk.java.net/jeps/370">JDK 14</a></p> </li> <li> <p>Enable dynamic archiving of classes at the end of Java application execution<br> <a href="https://openjdk.java.net/jeps/350">JDK 13</a></p> </li> <li> <p>Application Class-Data Sharing to improve startup time and reduce footprint by sharing class metadata between Java processes.<br> <a href="https://openjdk.java.net/jeps/310">JDK 10</a></p> </li> <li> <p>Class-Data Sharing archive of the default class list is enabled by default to improve out-of-the-box startup time<br> <a href="https://openjdk.java.net/jeps/341">JDK 12</a></p> </li> <li> <p>Space-efficient, Compact Strings that stores Latin-1 only Strings more efficiently<br> <a href="https://openjdk.java.net/jeps/254">JDK 9</a></p> </li> <li> <p>Code caches of profiled and non-profiled compiled code is separated, resulting in improved performance and memory footprint<br> <a href="https://openjdk.java.net/jeps/197">JDK 9</a></p> </li> <li> <p>Store Interned Strings in Class-Data Sharing archives to reduce memory consumption<br> <a href="https://openjdk.java.net/jeps/250">JDK 9</a></p> </li> </ul> <h3 id="library">Library</h3> <ul> <li> <p>Improved intrinsics for <code>java.lang.Math</code> <code>sin</code>, <code>cos</code> and <code>log</code> functions on AArch64 processors<br> <a href="https://openjdk.java.net/jeps/315">JDK 11</a></p> </li> <li> <p>Security Manager performance improvements<br> <a href="https://openjdk.java.net/jeps/232">JDK 9</a></p> </li> <li> <p>Spin-Wait Hint (<code>Thread#onSpinWait</code>) to optimize busy-waiting style loops<br> <a href="https://openjdk.java.net/jeps/285">JDK 9</a></p> </li> <li> <p>Use Marlin Renderer in Java 2D as the default graphics rasterizer instead of Pisces<br> <a href="https://openjdk.java.net/jeps/265">JDK 9</a></p> </li> <li> <p>Improved GHASH and RSA performance by leveraging recently-introduced SPARC and Intel x64 CPU instructions<br> <a href="https://openjdk.java.net/jeps/246">JDK 9</a></p> </li> </ul> <h3 id="concurrency">Concurrency</h3> <ul> <li> <p>Thread-Local Handshakes to stop individual threads<br> <a href="https://openjdk.java.net/jeps/312">JDK 10</a></p> </li> <li> <p>Improved performance of contended object monitors<br> <a href="https://openjdk.java.net/jeps/143">JDK 9</a></p> </li> <li> <p>Extra space on thread stack for critical sections, mitigating the risk of a deadlock in <code>java.util.concurrent</code> locks in case of a stack overflow<br> <a href="https://openjdk.java.net/jeps/270">JDK 9</a></p> </li> </ul> <h3 id="compiler">Compiler</h3> <ul> <li> <p>Ahead-of-Time Compilation capability for Linux (<strong>Experimental</strong> 💥)<br> <a href="https://openjdk.java.net/jeps/246">JDK 10</a> (Graal as an experimental JIT Compiler) <a href="https://openjdk.java.net/jeps/243">JDK 9</a> (JVM Compiler Interface) <a href="https://openjdk.java.net/jeps/295">JDK 9</a> (Graal as an AoT Compiler)</p> </li> <li> <p>Performance improvement in javac: new strategy for type checking poly expressions<br> <a href="https://openjdk.java.net/jeps/215">JDK 9</a></p> </li> </ul> <h3 id="g1-garbage-collector-default">G1 Garbage Collector (default)</h3> <ul> <li> <p>NUMA-Aware Memory Allocation<br> <a href="https://openjdk.java.net/jeps/345">JDK 14</a></p> </li> <li> <p>Abortable mixed collections to meet user-supplied pause goals<br> <a href="https://openjdk.java.net/jeps/344">JDK 12</a></p> </li> <li> <p>Automatically return heap memory to the operating system when idle<br> <a href="https://openjdk.java.net/jeps/346">JDK 12</a></p> </li> <li> <p>Parallel Full GC to improve worst-case latencies<br> <a href="https://openjdk.java.net/jeps/307">JDK 10</a></p> </li> <li> <p>G1 Garbage Collector is now the default instead of Parallel GC<br> <a href="https://openjdk.java.net/jeps/248">JDK 9</a></p> </li> </ul> <h3 id="other-garbage-collectors">Other Garbage Collectors</h3> <ul> <li> <p>Z Garbage Collector, offering very low pause times on large heaps<br> <a href="https://openjdk.java.net/jeps/379">JDK 15</a> (<strong>Experimental</strong> 💥 in <a href="https://openjdk.java.net/jeps/365">JDK 14</a> (Windows) <a href="https://openjdk.java.net/jeps/364">JDK 14</a> (OS X) <a href="https://openjdk.java.net/jeps/333">JDK 11</a> (Linux) )</p> </li> <li> <p>Shenandoah Garbage Collector, offering similar benefits as ZGC but based on a different algorithm<br> <a href="https://openjdk.java.net/jeps/377">JDK 15</a> (<strong>Experimental</strong> 💥 in <a href="https://openjdk.java.net/jeps/189">JDK 12</a> )</p> </li> <li> <p>Epsilon Garbage Collector, which does not implement actual memory reclamation, striving for the lowest overhead possible<br> <a href="https://openjdk.java.net/jeps/318">JDK 11</a></p> </li> <li> <p><code>XX:AllocateHeapAt=&lt;path&gt;</code> to support Alternative Memory Devices<br> <a href="https://openjdk.java.net/jeps/316">JDK 10</a></p> </li> </ul> <h3 id="diagnostic-and-tools">Diagnostic and Tools</h3> <ul> <li> <p>Flight Recorder Event Streaming: profiling data is available via an <a href="https://cr.openjdk.java.net/~egahlin/jep-349/javadocs/api/jdk.jfr/jdk/jfr/consumer/package-summary.html">API</a>, making …</p></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://advancedweb.hu/a-categorized-list-of-all-java-and-jvm-features-since-jdk-8-to-15/">https://advancedweb.hu/a-categorized-list-of-all-java-and-jvm-features-since-jdk-8-to-15/</a></em></p>]]>
            </description>
            <link>https://advancedweb.hu/a-categorized-list-of-all-java-and-jvm-features-since-jdk-8-to-15/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24636197</guid>
            <pubDate>Wed, 30 Sep 2020 06:29:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple’s T2 security chip jailbreak]]>
            </title>
            <description>
<![CDATA[
Score 726 | Comments 374 (<a href="https://news.ycombinator.com/item?id=24636166">thread link</a>) | @Yeri
<br/>
September 29, 2020 | https://reportcybercrime.com/hackers-jailbreak-apples-t2-security-chip-powered-by-bridgeos/ | <a href="https://web.archive.org/web/*/https://reportcybercrime.com/hackers-jailbreak-apples-t2-security-chip-powered-by-bridgeos/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>The Apple T2 security chip has finally been jailbroken! Here’s all you need to know about it.&nbsp; &nbsp; &nbsp;</p>
<h2><span id="The_Apple_T2_Security_chip_now_has_a_jailbreak"><strong>The Apple T2 Security chip now has a jailbreak</strong><span></span></span></h2>
<p>The <a href="https://yalujailbreak.net/checkra1n-jailbreak-ios-14/">latest update of checkra1n</a> adds support for bridgeOS – the operating system that powers the Apple T2 security chip.</p>
<p>For what it’s worth, the T2 chip is not A10 per se but it is derived from the Apple A10 Fusion architecture.&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p><strong>bridgeOS</strong> is a proprietary operating system created by Apple for its hardware. It is responsible for operating the Touch Bar and managing secure data.&nbsp;&nbsp;&nbsp;</p>
<p>Here’s what hacker Jamie Bishop had to say about this development.&nbsp;&nbsp;</p>
<blockquote data-width="550" data-dnt="true">
<p lang="en" dir="ltr">With <a href="https://twitter.com/checkra1n?ref_src=twsrc%5Etfw" target="_blank" rel="nofollow noopener noreferrer">@checkra1n</a> 0.11.0, you can now jailbreak the T2 chip in your Mac. An incredible amount of work went into this and it required changes at multiple levels.</p>
<p>There’s too many people to tag, but shoutout to everyone who worked on getting this incredible feature shipped.</p>
<p>— Jamie Bishop (@jamiebishop123) <a href="https://twitter.com/jamiebishop123/status/1308355178307948545?ref_src=twsrc%5Etfw" target="_blank" rel="nofollow noopener noreferrer">September 22, 2020</a></p>
</blockquote>
<p>Since checkra1n is still in beta, there are a few issues you need to be aware of. Firstly, you might have to reconnect your device after jailbreaking for bootstrap upload.</p>
<p>Secondly, macOS takes over the USB connection and blocks communication after bootup.&nbsp;</p>
<p>If you are interested in jailbreaking the T2 chip, download checkra1n jailbreak v0.11 from this <a href="https://yalujailbreak.net/checkra1n-jailbreak-ios-14/">link</a>.&nbsp;</p>
<h2><span id="What_can_a_bridgeOS_jailbreak_be_used_for"><strong>What can a bridgeOS jailbreak be used for?&nbsp;</strong><span></span></span></h2>
<p>The T2 security processor and the Touch Bar can run while the operating system is shutdown.</p>
<p>Apparently, jailbreak tweak developers could develop tweaks for the Touch Bar if it gets Substrate support in the future.</p>
<p>At present, there are no publicly dumped headers available for bridgeOS. It lacks a MobileSubstrate port too. However, that could change in the future because it shares some of the components of watchOS and iOS frameworks.</p>
<p>Once we get Substrate working, <strong>tweaking and theming could become possible.</strong></p>

<p>The ability to exploit the T2 processor could also allow you to bypass the anti-repair mechanism built into the Touch Bar. Further, it may allow hackers to get rid of the password or unlock MDM-locked systems.&nbsp;</p>
<p>As far as the OS goes, we could also add secure boot certificates like Microsoft’s secure boot signing or a self-signed Linux certificate.&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p>It will definitely be interesting to see what the future holds for the <em>T2 security chip</em> following the release of checkra1n.&nbsp; &nbsp; &nbsp;</p>
<p>Don’t forget to follow us on Twitter and Facebook for the latest jailbreak news and updates.&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</p>
</div></div>]]>
            </description>
            <link>https://reportcybercrime.com/hackers-jailbreak-apples-t2-security-chip-powered-by-bridgeos/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24636166</guid>
            <pubDate>Wed, 30 Sep 2020 06:19:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elements of Programmnig]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24635947">thread link</a>) | @todsacerdoti
<br/>
September 29, 2020 | http://www.pathsensitive.com/2020/09/book-review-elements-of-programmnig.html | <a href="https://web.archive.org/web/*/http://www.pathsensitive.com/2020/09/book-review-elements-of-programmnig.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>

<p>The C++ STL may be the most impressive achievement in language standard libraries. Where most programmers are stuck complaining that their language’s default strings aren’t performant enough, about every standard C++ function for strings actually runs on arbitrary character sequences. Design your own container? <span>std::find_if</span> works just as well as for the built-ins. And it does this while often being more performant than the code you’d write yourself.</p>

<p>Alex Stepanov is the man who made this happen, and Elements of Programming (EOP) is his 200-page paean to his method for writing generic code. He’s a believer that programming can be turned from an art to a rigorous discipline based on mathematics, and I’ve long admired him for his deep knowledge and impact. Indeed, he’s spent years at  #1 on my list of people I’d like to have lunch with. (Hey readers — can anyone help?)</p>

<p>And now, I’m about to ruin all that by writing a negative review.</p>

<p>EOP has a strong beginning and a strong finish. The first chapter explains core programming language concepts such as types and state — using non-standard terminology, but probably intentionally, judging by the explanation’s lucidity. This culminates in his big idea of being able to write programs on any type that offers a bundle of operations and properties called a concept, explained in this book over a decade before they entered the C++ standard. The afterword is a few pages of reflection on the power of this approach.</p>

<p>Between them is 11 chapters where he plays the same game: define a new abstraction and then show a bunch of functions that can be written using it. And unfortunately, these functions and abstractions are largely not very interesting.</p>

<p>There’s a famous site called Project Euler, where users write code to solve mathy problems such as “In a modified version of the board game Monopoly, on what three squares is a player most likely to land?” My former programming-contest coach advocated against using it to practice, because “It’s not really programming, and it’s not really math.”</p>

<p>I think this is an apt description of EOP, particularly the first half. This starts from Chapter 2, which is about cool algorithms that involve applying some function to itself repeatedly (iteration). One of my <a href="https://www.cs.cmu.edu/~cdm/pdf/lect-05.pdf">favorite lectures</a> in undergrad was on this topic, and yet I still couldn’t enjoy this chapter, as I know no application of these algorithms outside of niche mathematical topics. This gets taken up another notch in Chapter 5, where, in about 5 pages, he goes from explaining commutativity to defining the algebraic structures of monoids, groups, and rings, all the way up to algebraic modules (no relation to software modules). I cannot fathom these explanations being useful to someone who does not already know these concepts, and certainly not to someone who already does. And while I do know many uses of groups in software engineering — as an abstraction of the idea of an invertible operation — he actually spends the remainder of this chapter considering generalizations of the greatest common divisor function.</p>

<p>I slogged through these chapters, excited for the second half of the book, which focused largely on iterators and containers, things more relevant to typical software engineering. Yet after encountering endless listings of variations of list-copy functions, I found myself no more fulfilled, and soon regressed to skimming through the pages.</p>

<p>Aside from my long-term goal to find all the good writing on software design, I had a short-term goal when reading this book: a student wanted me to teach a lesson based on it. But, halfway through the book, my deadline was fast approaching, and I hadn’t found any material useful enough for a software design lesson for experienced engineers.</p>

<p>I then noticed all the chapters were generated by the deeper principle of coming up with a good abstraction to write generic functions against. I got the idea that maybe I could use EOP as a problem book, telling them to look at the descriptions of generic functions, and then come up with both the code and the abstractions they can be written against. Alas, the topic selection is not suitable for this purpose. One section of the book, for example, deals with computing integer sequences by matrix exponentiation. Asking students to come up with this themselves would be too familiar for many who have taken a linear algebra course, and impossible for those who haven’t. I did design a lesson where students come up with their own abstractions for generic programming problems, but I used examples completely unrelated to the book.</p>

<p>I asked the friend who recommended EOP what he got out of the book, and his first answer was a technique for elegantly expressing state machines using goto’s. I similarly loved that part, but, alas, that was the only concrete thing I got out of this book. I’ll explain it at the end of this review and spare you the other 200 pages.</p>

<p>I have an undergraduate degree in mathematics and have authored several papers on generic programming, so I knew I was reading it for others’ benefit. Still, I don’t think my opinion would be changed were this not the case, and I’d really like help understanding the viewpoint of the many readers who did thoroughly enjoy it. Instead, I find myself agreeing with this Amazon reviewer, although I have too much admiration for Stepanov to contemplate a 1-star rating:</p>

<blockquote>If you've ever written a generic function, you already know that the type parameters must obey a set of preconditions. This book lays out a big pile of definitions for types, numbers, algebraic structures, iterators, and such, so as to bamboozle people easily impressed by mathematical notation. It does so sloppily and writes some trivial generic algorithms in C++. To whatever extent one might accomplish something interesting with this topic, this book doesn't. Avoid.</blockquote>

<p>As I read other material by Stepanov, I mourn for the book that could have been. Stepanov clearly cares about these abstractions and algorithms, to the point where he wrote a <a href="https://www.amazon.com/Mathematics-Generic-Programming-Alexander-Stepanov/dp/0321942043">second book</a> on largely the same material, with a chattier exposition and chapters more explicitly focusing on pure math. How different would it be had he managed to transmit this appreciation to me? The day after finishing, I watched <a href="https://www.youtube.com/watch?v=W2tWOdzgXHA&amp;t=1344s">this talk</a> by a close colleague of Stepanov. “In this menu, you can select a bunch of rows and drag them somewhere else,” he explained over animated slides. “How many of you could implement this in one line?” It made me want to open section 10.4 on “rotation algorithms” again.</p>

<p>I’ve started watching <a href="https://www.youtube.com/playlist?list=PLHxtyCq_WDLXryyw91lahwdtpZsmo4BGD">a seminar</a> he gave at Amazon. I’m only a few lectures in, but I’m already enthralled by his high teaching ability. I feel like I’m there with him working through problems. I feel like I’ve learned a great secret as he tells the story of how he invented “regular types,” something used throughout EOP but never motivated. To be honest, I still don’t know what this lecture series is about, but nonetheless expect to recommend it when I’m done.</p>

<p>In short, Stepanov has given many gifts to the world of programming, and EOP is not one of them.</p>

<p><b>Overall rating</b>: <span>Not recommended</span></p>

<p>With a smattering of exceptions, EOP neither teaches abstractions useful in everyday programming, nor teaches you the skills to invent your own.</p>

<h2><b>Addendum</b>: State machines by goto’s</h2>

<blockquote>“The fastest way to go from one place in code to another is goto.”</blockquote><p>

— <a href="https://www.youtube.com/watch?v=sp_IBYVqMeQ&amp;list=PLHxtyCq_WDLXryyw91lahwdtpZsmo4BGD">Alexander Stepanov</a></p><p>Many iterative algorithms can be described as state machines: first it looks for an X, then it does Y with it, then it looks for another X, and so on. Rather than trying to massage the cycles in the state machine into structured loops, Stepanov advocates a style using goto’s, with one goto-label per machine state.</p>

<p>In searching for an example to best illustrate this, I wanted something where the code was under 40 lines (which ruled out Stepanov’s examples), understandable with little context or knowledge of C++, and which was not equivalent to a regular expression. And so:</p>

<p>In my defunctionalization talk, I showed that many state machines are derived from recursive functions, being turned into iterative traversals by creating a state for each point in the program between recursive calls. For that talk, I demonstrated this in full for the example of printing a binary tree. It turns out that adding parentheses makes this derivation substantially harder, as an arbitrary number of close-parentheses may need to be printed after processing a node. And that difficulty comes from trying to massage a state machine into a loop.</p>

<p>In this case, seeing as I came up with this example by starring with a recursive function, the recursive version is quite simple:</p>

<div><pre><span>void</span> <span>print_tree_rec</span><span>(tree</span> <span>*</span><span>t)</span> <span>{</span>
  <span>if</span> <span>(t</span> <span>!=</span> <span>NULL)</span> <span>{</span>
    <span>printf(</span><span>"("</span><span>);</span>
    <span>print_tree_rec(t</span><span>-&gt;</span><span>left);</span>
    <span>printf(</span><span>" %d "</span><span>,</span> <span>t</span><span>-&gt;</span><span>element);</span>
    <span>print_tree_rec(t</span><span>-&gt;</span><span>right);</span>
    <span>printf(</span><span>")"</span><span>);</span>
  <span>}</span>
<span>}</span>
</pre></div>


<p>But, for other state machines, the recursive version is not so easy. For example, Dijkstra created the “shunting yard” algorithm for parsing an arithmetic expression all the way back in 1961, yet I’m not aware of the recursive equivalent being discovered <a href="https://www.brics.dk/RS/07/7/BRICS-RS-07-7.pdf">until 2007</a>, using the technique of refunctionalization.</p>

<p>Here’s the state machine:</p><p><span id="docs-internal-guid-068c5e82-7fff-aeae-61d2-74453ca23aeb"><span><span><img height="566" src="https://lh4.googleusercontent.com/bfYT7CeU0eo8KAoMt8gB5Y4FDgD7Y1UlUJYSNI3ndYZ6jQpZv5Nwpyqyqoqffi_tgSRBYslU93EZy_nCil9ub6FZraaRGOBoABGPk0i9DoNbgr1fWAnkQzXMxPvLvEYFSDRWZ1RL" width="572"></span></span></span></p>

<p>A confession: the first time I thought about how to make this recursive function function iterative, I didn’t get it, and had to look it up. The solution is to merge the “Next from stack” state in the diagram with its successors, resulting in a solution with two nested while-loops, at the cost of some duplicated code.</p>

<p>However, the version based on goto’s reads off this diagram rather nicely. One C++-ism in this code to note: while the stack s is initialized to NULL, the  <span>push()</span> and  <span>pop()</span> calls can actually change it.</p>

<!--HTML generated using hilite.me--><div><pre><span>void</span> <span>print_tree</span><span>(tree</span> <span>*</span><span>t)</span> <span>{</span>
  <span>tree</span> <span>*</span><span>cur</span> <span>=</span> <span>t;</span>
  <span>stack</span> <span>*</span><span>s</span> <span>=</span> <span>NULL;</span>
  
<span>begin_print_node:</span>
  <span>if</span> <span>(cur</span> <span>==</span> <span>NULL)</span> <span>{</span>
    <span>goto</span> <span>dispatch_stack_frame;</span>
  <span>}</span> <span>else</span> <span>{</span>
    <span>printf(</span><span>"("</span><span>);</span>
    <span>push(LEFT_CHILD,</span> <span>cur,</span> <span>s);</span>
    <span>cur</span> <span>=</span> <span>cur</span><span>-&gt;</span><span>left;</span>
    <span>goto</span> <span>begin_print_n…</span></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.pathsensitive.com/2020/09/book-review-elements-of-programmnig.html">http://www.pathsensitive.com/2020/09/book-review-elements-of-programmnig.html</a></em></p>]]>
            </description>
            <link>http://www.pathsensitive.com/2020/09/book-review-elements-of-programmnig.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24635947</guid>
            <pubDate>Wed, 30 Sep 2020 05:28:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Notes on the future of media by Balaji S]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24635654">thread link</a>) | @dayve
<br/>
September 29, 2020 | https://cephalopods.blog/2020/09/18/some-notes-on-balaji-srinivasans-talk-on-the-future-of-media/ | <a href="https://web.archive.org/web/*/https://cephalopods.blog/2020/09/18/some-notes-on-balaji-srinivasans-talk-on-the-future-of-media/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>A few weeks ago Balaji Srinivasan was featured in a virtual meetup hosted by Joshua Fox. Balaji gave a talk on decentralized alternatives to legacy media, with a definite overtone of<em> New York Times delenda est</em>. It was a very good talk. I feel the need to get my head around what he said, and I often find the “5th grade book report” approach of summarizing something to be highly useful in this regard.  So this post is just me going over some of his arguments and predictions. </p>



<h2>Of Oracles and Advocates</h2>



<p>Balaji imagines a future where there is a separation between truth aggregation and narrative in  journalism. That is, he predicts that mechanisms will arise that will reliably correlate with reality, expressing the appropriate degrees of uncertainty. And then on top of the mechanisms, either decentralized contractors, or eventually text models like GPT-3, will apply a layer of narrative gloss, obsoleting the publisher and maybe even the journalists altogether. He refers to this class of mechanisms as “feeds/oracles” and those people or algorithms that apply the narrative gloss as “advocates”</p>



<p>He mentions financial and sports journalism as prototypical examples where such a separation exists today. Many such stories are largely just raw scores or stock prices converted rather mechanically (whether by a human or an algorithm) into narrative form. <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Narrative_Science" target="_blank">Narrative Science</a> is a company with a rather old-fashioned template-based text generator which is writing millions of such stories every day, using the feed + narrative gloss approach. He has a great line about this in the talk:</p>



<blockquote><p>Stock market stories are just text wrappers around Bloomberg data, sports stories just <em>text wrappers</em> around scores, and political stories are just <em>text wrappers</em> around tweets.</p></blockquote>



<p>I particularly like “Political stories are just text wrappers around tweets” – both true,  discomfiting and amusing all at once.</p>



<p>After introducing this distinction between “feeds/oracles” and “advocates” he then described the “ledger of record,” which is his word for the sort of generalized space of all active blockchains. </p>



<p>To place my possibly unjustified biases on the table, since reading all the white papers of some of  the highest market-cap ERC20 tokens, I have been pretty skeptical of cryptocurrency. I will refrain from writing the three-paragraph rant that would be required to adequately describe the amount of stupid that was present in some those white papers but suffice it to say it turned me off the whole scene. </p>



<p>But despite my distaste for the stuff, a good cook can make a fine meal of the most exotic ingredients and Balaji waxes quite well on the value of decentralized ledgers. The main value-adds he mentions are payments and trustless timestamps, particularly the role of timestamps in allowing pseudonyms to accrue reputation. His slogan for this is “first payments, then truth.”</p>



<p>One easy thing you can prove with a blockchain is that this particular string was signed with this particular key, and existed at this particular time. By hashing the string, you can do this without revealing the contents. One can imagine a pseudonymous data aggregator establishing a reputation by time-stamping facts in this way before they become commonly known. And then selling access to a stream of such data. </p>



<p>One problem that pops up in my head now is it seems like you would end up with a lot of <a href="https://en.wikipedia.org/wiki/List_of_confidence_tricks#Baltimore_Stockbroker_/_Psychic_Sports_Picks">Baltimore stockbrokers</a>. Maybe this would not be a problem though, as once you are aware of a data aggregator you are immune to such selection effects going forward. Time is not on the side of a Baltimore stockbroker.  So maybe prominence would screen off such people. But these types of selection effects confuse my squib brain and my intuitions here are not very clear. I wish I had asked him about the Baltimore stockbroker problem during the Q&amp;A.</p>



<p>Regardless, a plain-text public feed does not have this problem, and will probably be the most common. Especially if it is not pseudonymous. If pseudonymous, there is always the temptation of defecting, especially if your feeds are used by smart contracts to settle various bets. I know Augur and other projects are working on solutions to this, and his opinion on the efficacy of such mechanisms is another question I regret not asking. </p>



<p>My impression so far is there does not appear to be much activity on any decentralized prediction markets, despite them existing for many years. Perhaps this is related to it being provably irrational to participate in an unsubsidized predication market. </p>



<p>Subsidizing a prediction market with inflation seems like it could have been a good idea for Bitcoin or Ethereum, but would be hard to implement now. In general, inflation strikes me as an ideal way to subsidize public goods (such as information aggregation) and I think it is a big lost opportunity that Ethereum and Bitcoin use it exclusively to fund security.  It’s a shame inflation is such a dirty word among the blockchain crowd, as it is ironically the most powerful tool in their arsenal. </p>



<h2>Advocates or Agents?</h2>



<p><br>He talked about the incentives for citizen journalists, and one of them is a notion of duty. One problem with duty as a sole incentive is that a pathological means of amplifying one’s sense of duty is indoctrination into an ideology.  And I wonder if, in a world where duty is one of the only remaining incentives for journalism, this will only amplify ideologues of various stripes. </p>



<p>I would prefer a sort of “mechanisms all the way up” approach, and (as mentioned) Balaji speculated about  a means to do this. It certainly seems science fictional now, but the idea of prediction markets, centralized or decentralized, solidifying a sort of agreed-upon ontology of the present and future is highly appealing to me. </p>



<p>Scott Alexander describes this potential well here:</p>



<blockquote><p>A democratic vote among the scientific establishment is insufficient to settle these topics. The most important problem is that it gives massive power to the people who determine who gets to be part of “the scientific establishment”. … So not having any Schelling point – being hopelessly confused about the legitimacy of academic ideas – sucks. But a straight democratic vote of academics would also suck and be potentially unfair.</p><p>Prediction markets avoid these problems. There is no question of who the experts are: anyone can invest in a prediction market. There’s no question of special interests taking it over; this just distributes free money to more honest investors. Not only do they escape real bias, but more importantly they escape perceived bias. It is breathtakingly beautiful how impossible it is to rail that a prediction market is the tool of the liberal media or whatever. …</p><p>Nate Silver might do better than a prediction market, I don’t know. But Nate Silver is not a Schelling point. Nobody chose him as Official Statistics Guy via a fair process. And if someone objected to his beliefs, they could accuse him of bias and he would have no recourse until it was too late. If a prediction market is almost as good as Nate, and it is also unbiased and impossible to accuse of bias, we have our Schelling point. …</p></blockquote>



<p>In Balaji’s vision, this shelling point would be reified in the “ledger of record” mentioned earlier. </p>



<p>A humorous thought I had is if we do get an agreed upon method of selecting policies that is effective then a utilitarian could have their GPT-N bot rationalize these policies to them through a utilitarian lens, and others could have their GPT-N rationalize these policies as what Marx truly intended, the culmination of the non-aggression principle, the obvious result of Kantian universality, or the culmination of neo-liberalism. A recipe for Utopia if I ever heard one!</p>



<p>Balaji addressed the obvious objection that most news consumption is largely about affiliation rather than truth-seeking, saying that those people who want truth will have an incentive to use the best means available even if most people prefer a circus. And this should undoubtedly be an improvement over what we have today. </p>



<p>After the talk,  Balaji hanged out for a bit in the breakout rooms with our regulars.</p>



<p> I won’t go too far into details here but he mentioned this on Twitter so I think it is safe to share: I made a claim about the inability to transfer reputation between pseudonyms and within about 20 seconds he came up with a scheme, using known cryptographic primitives, that partially bypassed my objections, pointing out that things like Reddit and Stack Overflow karma are fungible and so can be transferred to pseudonyms without unmasking them using something like Zcash.  I did a little Googling afterward and it appears it was an entirely novel idea that seems likely to work, and it just popped into his head before I had finished making my point. </p>



<p>I am still skeptical about pseudonyms being useful given the 33 bit problem, but it was impressive.</p>



<p>It is quite plausible that my interpretations of his arguments are much weaker than his actual arguments, so sign up to his mailing list at <a href="https://balajis.com/signup/">https://balajis.com/signup/</a>, where he will be releasing a video of a more polished version of the same talk to get the pure stuff.</p>
	</div></div>]]>
            </description>
            <link>https://cephalopods.blog/2020/09/18/some-notes-on-balaji-srinivasans-talk-on-the-future-of-media/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24635654</guid>
            <pubDate>Wed, 30 Sep 2020 04:18:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[From zero to main(): How to write a bootloader from scratch]]>
            </title>
            <description>
<![CDATA[
Score 330 | Comments 44 (<a href="https://news.ycombinator.com/item?id=24635383">thread link</a>) | @tigerlily
<br/>
September 29, 2020 | https://interrupt.memfault.com/blog/how-to-write-a-bootloader-from-scratch | <a href="https://web.archive.org/web/*/https://interrupt.memfault.com/blog/how-to-write-a-bootloader-from-scratch">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        <p>This is the third post in our <a href="https://interrupt.memfault.com/blog/tag/zero-to-main">Zero to main() series</a>,
where we bootstrap a working firmware from zero code on a
cortex-M series microcontroller.</p>

<p>Previously, <a href="https://interrupt.memfault.com/blog/zero-to-main-1">we wrote a startup file to bootstrap our C environment</a>, and <a href="https://interrupt.memfault.com/blog/how-to-write-linker-scripts-for-firmware">a linker
script to get the right data at the right addresses</a>. These two will allow us to
write a monolithic firmware which we can load and run on our microcontrollers.</p>

<p>In practice, this is not how most firmware is structured. Digging through vendor
SDKs, you’ll notice that they all recommend using a <em>bootloader</em> to load your
applications. A bootloader is a small program which is responsible for loading
and starting your application.</p>

<!-- excerpt start -->
<p>In this post, we will explain why you may want a
bootloader, how to implement one, and cover a few advanced techniques you may
use to make your bootloader more useful.
<!-- excerpt end --></p>

<p>Like Interrupt? <a href="http://eepurl.com/gpRedv" target="_blank">Subscribe</a> to get our latest posts straight to your mailbox.</p>



<h2 id="why-you-may-need-a-bootloader">Why you may need a bootloader</h2>

<p>Bootloaders serve many purposes, ranging from security to software architecture.</p>

<p>Most commonly, you may need a bootloader to load your software. Some
microcontrollers like Dialog’s
<a href="https://www.dialog-semiconductor.com/products/connectivity/bluetooth-low-energy/smartbond-da14580-and-da14583">DA14580</a>
have little to no onboard flash and instead rely on an external device to store
firmware code. In that case, it is the bootloader’s job to copy code from
non-executable storage, such as a SPI flash, to an area of memory that can be
executed from, such as RAM.</p>

<p>Bootloaders also allow you to decouple parts of the program that are mission
critical, or that have security implications, from application code which
changes regularly.  For example, your bootloader may contain firmware update
logic so your device can recover no matter how bad a bug ships in your
application firmware.</p>

<p>Last but certainly not least, bootloaders are an essential component of a
trusted boot architecture.  Your bootloader can, for example, verify a
cryptographic signature to make sure the application has not been replaced or
tampered with.</p>

<h2 id="a-minimal-bootloader">A minimal bootloader</h2>
<p>Let’s build a simple bootloader together. To start, our bootloader must do two
things:</p>

<ol>
  <li>Execute on MCU boot</li>
  <li>Jump to our application code</li>
</ol>

<p>We’ll need to decide on a memory map, write some bootloader code, and update our
application to make it bootload-able.</p>

<h3 id="setting-the-stage">Setting the stage</h3>

<p>For this example, we’ll be using the same setup as we did in our previous Zero
to Main posts:</p>
<ul>
  <li>Adafruit’s <a href="https://www.adafruit.com/product/3505">Metro M0 Express</a> as our
development board,</li>
  <li>a simple <a href="https://www.adafruit.com/product/2764">CMSIS-DAP Adapter</a></li>
  <li>OpenOCD (the <a href="https://github.com/arduino/OpenOCD">Arduino fork</a>) for
programming</li>
</ul>

<h3 id="deciding-on-a-memory-map">Deciding on a memory map</h3>

<p>We must first decide on how much space we want to dedicate to our bootloader.
Code space is precious - your application may come to need more of it - and you
will not be able to change this without updating your bootloader, so make
this as small as you possibly can.</p>

<p>Another important factor is your flash sector size: you want to make sure you
can erase app sectors without erasing bootloader data, or vice versa.
Consequently, your bootloader region must end on a flash sector boundary
(typically 4kB).</p>

<p>I decided to go with a 16kB region, leading to the following memory map:</p>

<div><div><pre><code>        0x0 +---------------------+
            |                     |
            |     Bootloader      |
            |                     |
     0x4000 +---------------------+
            |                     |
            |                     |
            |     Application     |
            |                     |
            |                     |
    0x30000 +---------------------+
</code></pre></div></div>

<p>We can transcribe that memory into a linker script:</p>

<div><div><pre><code>/* memory_map.ld */
MEMORY
{
  bootrom  (rx)  : ORIGIN = 0x00000000, LENGTH = 0x00004000
  approm   (rx)  : ORIGIN = 0x00004000, LENGTH = 0x0003C000
  ram      (rwx) : ORIGIN = 0x20000000, LENGTH = 0x00008000
}

__bootrom_start__ = ORIGIN(bootrom);
__bootrom_size__ = LENGTH(bootrom);
__approm_start__ = ORIGIN(approm);
__approm_size__ = LENGTH(approm);
</code></pre></div></div>

<p>Since linker scripts are composable, we will be able to <code>include</code> that memory
map into the linker scripts we write for our bootloader and our application.</p>

<p>You’ll notice that the linker script above declares some variables. We’ll need
those for our bootloader to know where to find the application. To make them
accessible in C code, we declare them in a header file:</p>

<div><div><pre><code><span>/* memory_map.h */</span>
<span>#pragma once
</span>
<span>extern</span> <span>int</span> <span>__bootrom_start__</span><span>;</span>
<span>extern</span> <span>int</span> <span>__bootrom_size__</span><span>;</span>
<span>extern</span> <span>int</span> <span>__approm_start__</span><span>;</span>
<span>extern</span> <span>int</span> <span>__approm_size__</span><span>;</span>
</code></pre></div></div>

<h3 id="implementing-the-bootloader-itself">Implementing the bootloader itself</h3>
<p>Next up, let’s write some bootloader code. Our bootloader needs to start
executing on boot and then jump to our app.</p>

<p>We know how to do the first part from our previous post: we need a valid stack
pointer at address <code>0x0</code> , and a valid <code>Reset_Handler</code>  function setting up our
environment at address <code>0x4</code>. We can reuse our previous startup file and linker
script, with one change: we use  <code>memory_map.ld</code> rather than define our own
<code>MEMORY</code> section.</p>

<p>We also need to put our code in the <code>bootrom</code> region from our memory rather than
the <code>rom</code> region in our previous post.</p>

<p>Our linker script therefore looks like this:</p>

<div><div><pre><code>/* bootloader.ld */
INCLUDE memory_map.ld

/* Section Definitions */
SECTIONS
{
    .text :
    {
        KEEP(*(.vectors .vectors.*))
        *(.text*)
        *(.rodata*)
        _etext = .;
    } &gt; bootrom
  ...
}
</code></pre></div></div>

<p>To jump into our application, we need to know where the <code>Reset_Handler</code> of the
app is, and what stack pointer to load.  Again, we know from our previous post
that those should be the first two 32-bit words in our binary, so we just need
to dereference those addresses using the <code>__approm_start__</code> variable from our
memory map.</p>

<div><div><pre><code><span>/* bootloader.c */</span>
<span>#include &lt;inttypes.h&gt;
#include "memory_map.h"
</span>
<span>int</span> <span>main</span><span>(</span><span>void</span><span>)</span> <span>{</span>
  <span>uint32_t</span> <span>*</span><span>app_code</span> <span>=</span> <span>(</span><span>uint32_t</span> <span>*</span><span>)</span><span>__approm_start__</span><span>;</span>
  <span>uint32_t</span> <span>app_sp</span> <span>=</span> <span>app_code</span><span>[</span><span>0</span><span>];</span>
  <span>uint32_t</span> <span>app_start</span> <span>=</span> <span>app_code</span><span>[</span><span>1</span><span>];</span>
  <span>/* TODO: Start app */</span>
  <span>/* Not Reached */</span>
  <span>while</span> <span>(</span><span>1</span><span>)</span> <span>{}</span>
<span>}</span>
</code></pre></div></div>

<p>Next we must load that stack pointer and jump to the code. This will require a
bit of assembly code.</p>

<p>ARM MCUs use the <a href="http://www.keil.com/support/man/docs/armasm/armasm_dom1361289882044.htm"><code>msr</code> instruction
</a> to
load immediate or register data into system registers, in this case the MSP
register or “Main Stack Pointer”.</p>

<p>Jumping to an address is done with a branch, in our case with a <a href="http://www.keil.com/support/man/docs/armasm/armasm_dom1361289866466.htm"><code>bx</code>
instruction</a>.</p>

<p>We wrap those two into a <code>start_app</code> function which accepts our <code>pc</code> and <code>sp</code> as
arguments, and get our minimal bootloader:</p>

<div><div><pre><code><span>/* app.c */</span>
<span>#include &lt;inttypes.h&gt;
#include "memory_map.h"
</span>
<span>static</span> <span>void</span> <span>start_app</span><span>(</span><span>uint32_t</span> <span>pc</span><span>,</span> <span>uint32_t</span> <span>sp</span><span>)</span> <span>__attribute__</span><span>((</span><span>naked</span><span>))</span> <span>{</span>
    <span>__asm</span><span>(</span><span>"           </span><span>\n</span><span>\
          msr msp, r1 /* load r1 into MSP */</span><span>\n</span><span>\
          bx r0       /* branch to the address at r0 */</span><span>\n</span><span>\
    "</span><span>);</span>
<span>}</span>

<span>int</span> <span>main</span><span>(</span><span>void</span><span>)</span> <span>{</span>
  <span>uint32_t</span> <span>*</span><span>app_code</span> <span>=</span> <span>(</span><span>uint32_t</span> <span>*</span><span>)</span><span>__approm_start__</span><span>;</span>
  <span>uint32_t</span> <span>app_sp</span> <span>=</span> <span>app_code</span><span>[</span><span>0</span><span>];</span>
  <span>uint32_t</span> <span>app_start</span> <span>=</span> <span>app_code</span><span>[</span><span>1</span><span>];</span>
  <span>start_app</span><span>(</span><span>app_start</span><span>,</span> <span>app_sp</span><span>);</span>
  <span>/* Not Reached */</span>
  <span>while</span> <span>(</span><span>1</span><span>)</span> <span>{}</span>
<span>}</span>
</code></pre></div></div>

<blockquote>
  <p>Note: hardware resources initialized in the bootloader must be de-initialized
before control is transferred to the app. Otherwise, you risk breaking
assumptions the app code is making about the state of the system</p>
</blockquote>

<h3 id="making-our-app-bootloadable">Making our app bootloadable</h3>

<p>We must update our app to take advantage of our new memory map. This is again
done by updating our linker script to include <code>memory_map.ld</code> and changing our
sections to go to the <code>approm</code> region rather than <code>rom</code>.</p>

<div><div><pre><code>/* app.ld */
INCLUDE memory_map.ld

/* Section Definitions */
SECTIONS
{
    .text :
    {
        KEEP(*(.vectors .vectors.*))
        *(.text*)
        *(.rodata*)
        _etext = .;
    } &gt; approm
  ...
}
</code></pre></div></div>

<p>We also need to update the <a href="https://developer.arm.com/docs/dui0552/latest/the-cortex-m3-processor/exception-model/vector-table"><em>vector
table</em></a>
used by the microcontroller. The vector table contains the address of every
exception and interrupt handler in our system. When an interrupt signal comes
in, the ARM core will call the address at the corresponding offset in the vector
table.</p>

<p>For example, the offset for the Hard fault handler is <code>0xc</code>, so when a hard
fault is hit, the ARM core will jump to the address contained in the table at
that offset.</p>

<p>By default, the vector table is at address <code>0x0</code>, which means that when our chip
powers up, only the bootloader can handle exceptions or interrupts! Fortunately, ARM
provides the <a href="https://developer.arm.com/docs/dui0552/latest/cortex-m3-peripherals/system-control-block/vector-table-offset-register">Vector Table Offset
Register</a>
to dynamically change the address of the vector table. The register is at
address <code>0xE000ED08</code> and has a simple layout:</p>

<div><div><pre><code>31                                  7              0
+-----------------------------------+--------------+
|                                   |              |
|              TBLOFF               |   Reserved   |
|                                   |              |
+-----------------------------------+--------------+
</code></pre></div></div>

<p>Where <code>TBLOFF</code> is the address of the vector table. In our case, that’s the start
of our text section, or <code>_stext</code>. To set it in our app, we add the following to
our <code>Reset_Handler</code>:</p>

<div><div><pre><code><span>/* startup_samd21.c */</span>
<span>/* Set the vector table base address */</span>
<span>uint32_t</span> <span>*</span><span>vector_table</span> <span>=</span> <span>(</span><span>uint32_t</span> <span>*</span><span>)</span> <span>&amp;</span><span>_stext</span><span>;</span>
<span>uint32_t</span> <span>*</span><span>vtor</span> <span>=</span> <span>(</span><span>uint32_t</span> <span>*</span><span>)</span><span>0xE000ED08</span><span>;</span>
<span>*</span><span>vtor</span> <span>=</span> <span>((</span><span>uint32_t</span><span>)</span> <span>vector_table</span> <span>&amp;</span> <span>0xFFFFFFF8</span><span>);</span>
</code></pre></div></div>

<p>One quirk of the ARMv7-m architecture is the alignment requirement for the
vector table, as specified in section B1.5.3 of the <a href="https://static.docs.arm.com/ddi0403/eb/DDI0403E_B_armv7m_arm.pdf">reference
manual</a>:</p>

<blockquote>
  <p>The Vector table must be naturally aligned to a power of two whose alignment value is greater than or equal
to (Number of Exceptions supported x 4), with a minimum alignment of 128 bytes.The entry at offset 0 is
used to initialize the value for SP_main, see The SP registers on page B1-8. All other entries must have bit
[0] set, as the bit is used to define the EPSR T-bit on exception entry (see Reset behavior on page B1-20 and
Exception entry behavior on page B1-21 for details).</p>
</blockquote>

<p>Our SAMD21 MCU has 28 interrupts on top of the 16 system reserved exceptions,
for a total of 44 entries in the table. Multiply that by 4 and you get 176. The
next power of 2 is 256, so our vector table must be 256-byte aligned.</p>

<h3 id="putting-it-all-together">Putting it all together</h3>

<p>Because it is hard to witness the bootloader execute, we add a print line to
each of our programs:</p>

<div><div><pre><code><span>/* boootloader.c */</span>
<span>#include &lt;inttypes.h&gt;
#include "memory_map.h"
</span>
<span>static</span> <span>void</span> <span>s…</span></code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://interrupt.memfault.com/blog/how-to-write-a-bootloader-from-scratch">https://interrupt.memfault.com/blog/how-to-write-a-bootloader-from-scratch</a></em></p>]]>
            </description>
            <link>https://interrupt.memfault.com/blog/how-to-write-a-bootloader-from-scratch</link>
            <guid isPermaLink="false">hacker-news-small-sites-24635383</guid>
            <pubDate>Wed, 30 Sep 2020 03:19:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The UX of Banking]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24635364">thread link</a>) | @Garbage
<br/>
September 29, 2020 | https://builtformars.co.uk/banks/ | <a href="https://web.archive.org/web/*/https://builtformars.co.uk/banks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-elementor-type="wp-page" data-elementor-id="3032" data-elementor-settings="[]">
<div>
<div>
<section data-id="2898fc6" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">

<div>
<div>
<div data-id="4964a44" data-element_type="column">
<div>
<div>

<div data-id="0a3485f" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;none&quot;}" data-widget_type="heading.default">
<p>
<h3>What the challenger banks did differently: a study into the UX of banking.</h3> </p>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="535cf2f" data-element_type="section">

</section>
<section data-id="9be0ee4" data-element_type="section">
<div>
<div>
<div data-id="bf5c18d" data-element_type="column">
<div>
<div>

<div data-id="b431a25" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;none&quot;}" data-widget_type="heading.default">
<p>
<h4>Billion dollar experiences</h4> </p>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="b910384" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
<div>
<div>
<div data-id="96fe065" data-element_type="column">
<div>
<div>
<div data-id="3c618a0" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>Monzo, Revolut and Starling—often called the challenger banks—have built billion-dollar businesses around the belief that they offer the best overall banking experience.</p>
</div>
</div>
<div data-id="941ff44" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>But are they actually any better, or is it all clever marketing? To answer that question I opened 12 real bank accounts, and logged <em>everything</em>.</p>
</div>
</div>
<div data-id="8bb4b6b" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>Each chapter provides a forensic analysis of a particular feature or user journey.</p>
</div>
</div>
<div data-id="78b3d97" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>But more importantly, I’ve highlighted what can we all learn from the challenger banks, and used real examples to teach you how to craft better experiences in the future.</p>
</div>
</div>
</div>
</div>
</div>
<div data-id="560e042" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
<div>
<div>
<div data-id="9643ce0" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p><strong>Subscribe to get more content like this!</strong></p>
</div>
</div>

</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="546fd67" data-element_type="section">
<div>
<div>
<div data-id="4cd7bfe" data-element_type="column">
<div>
<div>
<div data-id="bdaeb8e" data-element_type="widget" data-widget_type="image.default">
<div>
<p><a href="https://builtformars.com/banks/opening/">
<img width="562" height="343" src="https://builtformars.com/wp-content/uploads/2020/06/AllCardsFixed.jpg" alt="" loading="lazy" srcset="https://builtformars.com/wp-content/uploads/2020/06/AllCardsFixed.jpg 562w, https://builtformars.com/wp-content/uploads/2020/06/AllCardsFixed-300x183.jpg 300w, https://builtformars.com/wp-content/uploads/2020/06/AllCardsFixed-100x61.jpg 100w" sizes="(max-width: 562px) 100vw, 562px"> </a>
</p>
</div>
</div>


<div data-id="29b9a8f" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>It took <strong>18x longer</strong> to open an account with HSBC that it did with Monzo.</p>
</div>
</div>

</div>
</div>
</div>
<div data-id="4a8ea32" data-element_type="column">
<div>
<div>
<div data-id="c26ace2" data-element_type="widget" data-widget_type="image.default">
<div>
<p><a href="https://builtformars.com/banks/first-payment">
<img width="562" height="343" src="https://builtformars.com/wp-content/uploads/2020/06/FirstPaymentFixed-1.jpg" alt="" loading="lazy" srcset="https://builtformars.com/wp-content/uploads/2020/06/FirstPaymentFixed-1.jpg 562w, https://builtformars.com/wp-content/uploads/2020/06/FirstPaymentFixed-1-300x183.jpg 300w, https://builtformars.com/wp-content/uploads/2020/06/FirstPaymentFixed-1-100x61.jpg 100w" sizes="(max-width: 562px) 100vw, 562px"> </a>
</p>
</div>
</div>


<div data-id="410d84b" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>Payment notifications were <strong>at least 2x faster</strong> with the challenger banks, and in some cases <strong>100x faster</strong>.</p>
</div>
</div>

<div data-id="5892a2c" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>⚡️ Includes <strong>12</strong><strong>&nbsp;case studies</strong></p>
</div>
</div>
</div>
</div>
</div>
<div data-id="671df6e" data-element_type="column">
<div>
<div>
<div data-id="2d3db91" data-element_type="widget" data-widget_type="image.default">
<div>
<p><a href="https://builtformars.com/banks/freezing/">
<img width="562" height="343" src="https://builtformars.com/wp-content/uploads/2020/06/FrozenCardsFixed.jpg" alt="" loading="lazy" srcset="https://builtformars.com/wp-content/uploads/2020/06/FrozenCardsFixed.jpg 562w, https://builtformars.com/wp-content/uploads/2020/06/FrozenCardsFixed-300x183.jpg 300w, https://builtformars.com/wp-content/uploads/2020/06/FrozenCardsFixed-100x61.jpg 100w" sizes="(max-width: 562px) 100vw, 562px"> </a>
 </p>
</div>
</div>


<div data-id="caa9ed8" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>There were the <strong>only 3</strong> banks to send notifications when someone attempted to use a frozen card.</p>
</div>
</div>

<div data-id="f06833c" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>⚡️ Includes <strong>10</strong><strong>&nbsp;case studies</strong></p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="894506f" data-element_type="section">
<div>
<div>
<div data-id="df064b1" data-element_type="column">
<div>
<div>
<div data-id="28c4ea8" data-element_type="widget" data-widget_type="image.default">
<div>
<p><a href="https://builtformars.com/banks/international/">
<img width="562" height="343" src="https://builtformars.com/wp-content/uploads/2020/06/InternationalFixed.jpg" alt="" loading="lazy" srcset="https://builtformars.com/wp-content/uploads/2020/06/InternationalFixed.jpg 562w, https://builtformars.com/wp-content/uploads/2020/06/InternationalFixed-300x183.jpg 300w, https://builtformars.com/wp-content/uploads/2020/06/InternationalFixed-100x61.jpg 100w" sizes="(max-width: 562px) 100vw, 562px"> </a>
</p>
</div>
</div>


<div data-id="b437d79" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>It cost <strong>at least £20</strong> to send £1 (GBP) to a US bank (USD) with three banks.</p>
</div>
</div>

<div data-id="f6c6bbc" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>⚡️ Includes <strong>12</strong><strong>&nbsp;case studies</strong></p>
</div>
</div>
</div>
</div>
</div>
<div data-id="8e4c759" data-element_type="column">
<div>
<div>
<div data-id="c4df7a5" data-element_type="widget" data-widget_type="image.default">
<div>
<p><a href="https://builtformars.com/banks/open-banking/">
<img width="562" height="343" src="https://builtformars.com/wp-content/uploads/2020/06/OpenBankingFixed.jpg" alt="" loading="lazy" srcset="https://builtformars.com/wp-content/uploads/2020/06/OpenBankingFixed.jpg 562w, https://builtformars.com/wp-content/uploads/2020/06/OpenBankingFixed-300x183.jpg 300w, https://builtformars.com/wp-content/uploads/2020/06/OpenBankingFixed-100x61.jpg 100w" sizes="(max-width: 562px) 100vw, 562px"> </a>
</p>
</div>
</div>


<div data-id="977ae52" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>It took nearly <strong>4x longer</strong>&nbsp;to authorise an Open Banking payment with Lloyds than it did with Starling.</p>
</div>
</div>

<div data-id="4b3bec9" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>⚡️ Includes <strong>10</strong><strong>&nbsp;case studies</strong></p>
</div>
</div>
</div>
</div>
</div>
<div data-id="4ff6bfc" data-element_type="column">
<div>
<div>
<div data-id="3fac4a8" data-element_type="widget" data-widget_type="image.default">
<div>
<p><a href="https://builtformars.com/banks/support/">
<img width="562" height="343" src="https://builtformars.com/wp-content/uploads/2020/07/CustomerServiceFixed.jpg" alt="" loading="lazy" srcset="https://builtformars.com/wp-content/uploads/2020/07/CustomerServiceFixed.jpg 562w, https://builtformars.com/wp-content/uploads/2020/07/CustomerServiceFixed-300x183.jpg 300w, https://builtformars.com/wp-content/uploads/2020/07/CustomerServiceFixed-100x61.jpg 100w" sizes="(max-width: 562px) 100vw, 562px"> </a>
</p>
</div>
</div>


<div data-id="56418e4" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>Revolut only ever replied to <strong>20%</strong> of my live chat support messages, and don’t have a phone line.</p>
</div>
</div>

</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="178d96c" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">

</section>
<section data-id="d2d652f" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
<div>
<div>
<div data-id="39958a6" data-element_type="column">
<div>
<div>

<div data-id="bd6b341" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;none&quot;}" data-widget_type="heading.default">
<p>
<h4>Thank you for all your support</h4> </p>
</div>
</div>
</div>
</div>

</div>
</div>
</section>
<section data-id="832fa78" data-element_type="section">
<div>
<div>
<div data-id="4d4f429" data-element_type="column">
<div>
<div>
<div data-id="0df1ab9" data-element_type="widget" data-widget_type="image.default">
<div>
<p><img width="2136" height="839" src="https://builtformars.com/wp-content/uploads/2020/04/ATM-light-smaller.png" alt="" loading="lazy" srcset="https://builtformars.com/wp-content/uploads/2020/04/ATM-light-smaller.png 2136w, https://builtformars.com/wp-content/uploads/2020/04/ATM-light-smaller-300x118.png 300w, https://builtformars.com/wp-content/uploads/2020/04/ATM-light-smaller-1024x402.png 1024w, https://builtformars.com/wp-content/uploads/2020/04/ATM-light-smaller-768x302.png 768w, https://builtformars.com/wp-content/uploads/2020/04/ATM-light-smaller-1536x603.png 1536w, https://builtformars.com/wp-content/uploads/2020/04/ATM-light-smaller-2048x804.png 2048w, https://builtformars.com/wp-content/uploads/2020/04/ATM-light-smaller-100x39.png 100w, https://builtformars.com/wp-content/uploads/2020/04/ATM-light-smaller-700x275.png 700w, https://builtformars.com/wp-content/uploads/2020/04/ATM-light-smaller-1600x628.png 1600w" sizes="(max-width: 2136px) 100vw, 2136px"> </p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="c7e323d" data-element_type="section">
<div>
<div>

<div data-id="75df2de" data-element_type="column">
<div>
<div>
<div data-id="f2bc236" data-element_type="widget" data-widget_type="html.default">
<div>
<blockquote><p lang="en" dir="ltr">No research could be crisper in explaining the sense of "Frictionless experience" and Frictionless IT that I kept talking about for years. Must-read and must-subscribe. &gt; "What the challenger banks did differently" by <a href="https://twitter.com/PeteRamsey?ref_src=twsrc%5Etfw">@PeteRamsey</a> <a href="https://t.co/zWmxpYG0LT">https://t.co/zWmxpYG0LT</a></p>— Alessandro Perilli ✪ AI￨Automation￨Cybersecurity (@giano) <a href="https://twitter.com/giano/status/1263436408745844741?ref_src=twsrc%5Etfw">May 21, 2020</a></blockquote>  </div>
</div>




</div>
</div>
</div>
<div data-id="9072e4a" data-element_type="column">
<div>
<div>
<div data-id="c9ef61c" data-element_type="widget" data-widget_type="html.default">
<div>
<blockquote data-conversation="none"><p lang="en" dir="ltr">This should be required reading by every exec at traditional banks. Fantastic work</p>— Alex Barkley (@alexfintec) <a href="https://twitter.com/alexfintec/status/1264827065725059072?ref_src=twsrc%5Etfw">May 25, 2020</a></blockquote>  </div>
</div>




</div>
</div>
</div>

</div>
</div>
</section>
</div>
</div>
</div></div>]]>
            </description>
            <link>https://builtformars.co.uk/banks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24635364</guid>
            <pubDate>Wed, 30 Sep 2020 03:15:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Raspberry Pi Touchscreen Internet Radio, Music Player and Weather Display]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24635359">thread link</a>) | @azeemarif
<br/>
September 29, 2020 | https://smarttechnotes.com/raspberry-pi-touchscreen-internet-radio | <a href="https://web.archive.org/web/*/https://smarttechnotes.com/raspberry-pi-touchscreen-internet-radio">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-42">

	

	
			<figure>
				<img width="1568" height="1118" src="https://marifnotes.files.wordpress.com/2020/08/20200831_125150-1.jpg?w=1568" alt="" loading="lazy" srcset="https://marifnotes.files.wordpress.com/2020/08/20200831_125150-1.jpg?w=1568 1568w, https://marifnotes.files.wordpress.com/2020/08/20200831_125150-1.jpg?w=150 150w, https://marifnotes.files.wordpress.com/2020/08/20200831_125150-1.jpg?w=300 300w, https://marifnotes.files.wordpress.com/2020/08/20200831_125150-1.jpg?w=768 768w, https://marifnotes.files.wordpress.com/2020/08/20200831_125150-1.jpg?w=1024 1024w, https://marifnotes.files.wordpress.com/2020/08/20200831_125150-1.jpg 1883w" sizes="(max-width: 1568px) 100vw, 1568px" data-attachment-id="140" data-permalink="https://smarttechnotes.com/2020/08/21/raspberry-pi-touchscreen-internet-radio/20200831_125150-1/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/20200831_125150-1.jpg" data-orig-size="1883,1342" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.5&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SM-G960W&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1598878310&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.3&quot;,&quot;iso&quot;:&quot;250&quot;,&quot;shutter_speed&quot;:&quot;0.028571428571429&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="20200831_125150-1" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/20200831_125150-1.jpg?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/20200831_125150-1.jpg?w=750">			</figure><!-- .post-thumbnail -->

		
	<div>
		
<p>In this post I’d like to share how to make a Raspberry Pi internet radio player with music, audio-books and podcast playback over Bluetooth. In addition to all these features, it also serves as a weather station.</p>



<figure><img data-attachment-id="45" data-permalink="https://smarttechnotes.com/20200821_114111/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/20200821_114111.jpg" data-orig-size="1874,2200" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.4&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SM-N975W&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1598010000&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.3&quot;,&quot;iso&quot;:&quot;400&quot;,&quot;shutter_speed&quot;:&quot;0.016949152542373&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="20200821_114111" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/20200821_114111.jpg?w=256" data-large-file="https://marifnotes.files.wordpress.com/2020/08/20200821_114111.jpg?w=750" src="https://marifnotes.files.wordpress.com/2020/08/20200821_114111.jpg?w=872" alt="" srcset="https://marifnotes.files.wordpress.com/2020/08/20200821_114111.jpg?w=872 872w, https://marifnotes.files.wordpress.com/2020/08/20200821_114111.jpg?w=1744 1744w, https://marifnotes.files.wordpress.com/2020/08/20200821_114111.jpg?w=128 128w, https://marifnotes.files.wordpress.com/2020/08/20200821_114111.jpg?w=256 256w, https://marifnotes.files.wordpress.com/2020/08/20200821_114111.jpg?w=768 768w" sizes="(max-width: 872px) 100vw, 872px"></figure>



<p>When fully setup, the player can be controlled using the touch screen or remotely via a web interface. It plays media on wireless Bluetooth speaker.</p>



<p>We need the following items for this project</p>



<h4>Hardware</h4>



<ul><li>Raspberry Pi<ul><li>power supply</li><li>micro SD card</li></ul></li><li>Touchscreen LCD</li><li>Raspberry Pi case fit for holding an LCD</li><li>Bluetooth speaker</li><li>for initial setup, it would be nice to have<ul><li> Keyboard and Mouse</li><li>Monitor</li></ul></li></ul>



<h4>Software</h4>



<ul><li>Raspberry Pi OS</li><li>Peppy media player</li></ul>



<p>Any Raspberry Pi board with Wifi and Bluetooth is good for this project.</p>



<figure><img data-attachment-id="49" data-permalink="https://smarttechnotes.com/maker0x4cdate2017-9-26ver4lenskan03actlar01e-y/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/img_20180411_213104.jpg" data-orig-size="3417,2197" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 2 XL&quot;,&quot;caption&quot;:&quot;Maker:0x4c,Date:2017-9-26,Ver:4,Lens:Kan03,Act:Lar01,E-Y&quot;,&quot;created_timestamp&quot;:&quot;1523482264&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.459&quot;,&quot;iso&quot;:&quot;522&quot;,&quot;shutter_speed&quot;:&quot;0.033298&quot;,&quot;title&quot;:&quot;Maker:0x4c,Date:2017-9-26,Ver:4,Lens:Kan03,Act:Lar01,E-Y&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Maker:0x4c,Date:2017-9-26,Ver:4,Lens:Kan03,Act:Lar01,E-Y" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/img_20180411_213104.jpg?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/img_20180411_213104.jpg?w=750" src="https://marifnotes.files.wordpress.com/2020/08/img_20180411_213104.jpg?w=1024" alt="" srcset="https://marifnotes.files.wordpress.com/2020/08/img_20180411_213104.jpg?w=1024 1024w, https://marifnotes.files.wordpress.com/2020/08/img_20180411_213104.jpg?w=2048 2048w, https://marifnotes.files.wordpress.com/2020/08/img_20180411_213104.jpg?w=150 150w, https://marifnotes.files.wordpress.com/2020/08/img_20180411_213104.jpg?w=300 300w, https://marifnotes.files.wordpress.com/2020/08/img_20180411_213104.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Raspberry Pi</figcaption></figure>



<p>I used a 3.5 inch touchscreen LCD from <a href="http://www.kumantech.com/kuman-35-inch-tft-lcd-display-480x320-rgb-pixels-touch-screen-monitor-for-raspberry-pi-3-2-model-b-b-a-a-module-spi-interface-with-touch-pen-sc06_p0014.html">Kuman tech</a>.</p>



<div data-carousel-extra="{&quot;blog_id&quot;:181821324,&quot;permalink&quot;:&quot;https:\/\/smarttechnotes.com\/2020\/08\/21\/raspberry-pi-touchscreen-internet-radio\/&quot;}"><figure><img data-attachment-id="53" data-permalink="https://smarttechnotes.com/samsung-camera-pictures-2/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/04170004-1.jpg" data-orig-size="2922,1793" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;4.5&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;NX3000&quot;,&quot;caption&quot;:&quot;SAMSUNG CAMERA PICTURES&quot;,&quot;created_timestamp&quot;:&quot;1524004145&quot;,&quot;copyright&quot;:&quot;Copyright 2014&quot;,&quot;focal_length&quot;:&quot;28&quot;,&quot;iso&quot;:&quot;1600&quot;,&quot;shutter_speed&quot;:&quot;0.02&quot;,&quot;title&quot;:&quot;SAMSUNG CAMERA PICTURES&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="SAMSUNG CAMERA PICTURES" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/04170004-1.jpg?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/04170004-1.jpg?w=750" src="https://marifnotes.files.wordpress.com/2020/08/04170004-1.jpg?w=1024" alt="" srcset="https://marifnotes.files.wordpress.com/2020/08/04170004-1.jpg?w=1024 1024w, https://marifnotes.files.wordpress.com/2020/08/04170004-1.jpg?w=2048 2048w, https://marifnotes.files.wordpress.com/2020/08/04170004-1.jpg?w=150 150w, https://marifnotes.files.wordpress.com/2020/08/04170004-1.jpg?w=300 300w, https://marifnotes.files.wordpress.com/2020/08/04170004-1.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Raspberry Pi and Touchscreen</figcaption></figure></div>



<div data-carousel-extra="{&quot;blog_id&quot;:181821324,&quot;permalink&quot;:&quot;https:\/\/smarttechnotes.com\/2020\/08\/21\/raspberry-pi-touchscreen-internet-radio\/&quot;}"><figure><img data-attachment-id="57" data-permalink="https://smarttechnotes.com/samsung-camera-pictures-4/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/04170002-1.jpg" data-orig-size="4769,2177" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;4.5&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;NX3000&quot;,&quot;caption&quot;:&quot;SAMSUNG CAMERA PICTURES&quot;,&quot;created_timestamp&quot;:&quot;1524004110&quot;,&quot;copyright&quot;:&quot;Copyright 2014&quot;,&quot;focal_length&quot;:&quot;28&quot;,&quot;iso&quot;:&quot;3200&quot;,&quot;shutter_speed&quot;:&quot;0.02&quot;,&quot;title&quot;:&quot;SAMSUNG CAMERA PICTURES&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="SAMSUNG CAMERA PICTURES" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/04170002-1.jpg?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/04170002-1.jpg?w=750" src="https://marifnotes.files.wordpress.com/2020/08/04170002-1.jpg?w=1024" alt="" srcset="https://marifnotes.files.wordpress.com/2020/08/04170002-1.jpg?w=1024 1024w, https://marifnotes.files.wordpress.com/2020/08/04170002-1.jpg?w=2046 2046w, https://marifnotes.files.wordpress.com/2020/08/04170002-1.jpg?w=150 150w, https://marifnotes.files.wordpress.com/2020/08/04170002-1.jpg?w=300 300w, https://marifnotes.files.wordpress.com/2020/08/04170002-1.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Raspberry Pi and Touchscreen</figcaption></figure></div>



<p>We need a case that can hold the LCD screen securely so that it does not move when using the touchscreen. I used <a href="https://www.amazon.ca/MagiDeal-Acrylic-Enclosure-Raspberry-3-5inch/dp/B07FTB1RCD">this case</a> from Amazon but you may find many others like this if you search for “Layer Acrylic Case Raspberry Pi”.</p>



<figure><img data-attachment-id="55" data-permalink="https://smarttechnotes.com/20200821_111038-1/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1.jpg" data-orig-size="3274,1753" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.4&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SM-N975W&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1598008238&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.3&quot;,&quot;iso&quot;:&quot;400&quot;,&quot;shutter_speed&quot;:&quot;0.025&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="20200821_111038-1" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1.jpg?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1.jpg?w=750" src="https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1.jpg?w=1024" alt="" srcset="https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1.jpg?w=1024 1024w, https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1.jpg?w=2048 2048w, https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1.jpg?w=150 150w, https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1.jpg?w=300 300w, https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Acrylic Case for Raspberry Pi  with 3.5 inch LCD Display</figcaption></figure>



<p>And finally, we need a speaker to play the sound. It could very well be a wired speaker that is directly connected to Raspberry Pi using the 3.5mm headphone connector or a USB port but I used a wireless Bluetooth speaker so that we I can move it around easily.</p>



<figure><img data-attachment-id="60" data-permalink="https://smarttechnotes.com/20200821_231233-1/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/20200821_231233-1.jpg" data-orig-size="3410,1688" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.5&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SM-N975W&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1598051553&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.3&quot;,&quot;iso&quot;:&quot;250&quot;,&quot;shutter_speed&quot;:&quot;0.025&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="20200821_231233-1" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/20200821_231233-1.jpg?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/20200821_231233-1.jpg?w=750" src="https://marifnotes.files.wordpress.com/2020/08/20200821_231233-1.jpg?w=1024" alt="" srcset="https://marifnotes.files.wordpress.com/2020/08/20200821_231233-1.jpg?w=1024 1024w, https://marifnotes.files.wordpress.com/2020/08/20200821_231233-1.jpg?w=2048 2048w, https://marifnotes.files.wordpress.com/2020/08/20200821_231233-1.jpg?w=150 150w, https://marifnotes.files.wordpress.com/2020/08/20200821_231233-1.jpg?w=300 300w, https://marifnotes.files.wordpress.com/2020/08/20200821_231233-1.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Bluetooth Speaker</figcaption></figure>







<h4>Initial Setup</h4>



<p>For the initial setup, connect a USB keyboard and mouse and a monitor (using HDMI cable) to the Raspberry Pi. On a computer download Raspberry Pi OS and install the image on a micro SD card.</p>



<p><a href="https://www.raspberrypi.org/downloads/raspberry-pi-os/">Raspberry Pi OS download</a></p>



<p><a href="https://www.raspberrypi.org/documentation/installation/installing-images/README.md">Installing Raspberry Pi OS on a micro SD card</a></p>



<p>After SD card is ready, insert it into Raspberry Pi board and switch the power on. Follow the instructions on the screen to complete <a href="https://projects.raspberrypi.org/en/projects/install-raspberry-pi-desktop/5">Raspberry Pi OS installation</a>. After the installation you should see Raspberry Pi desktop.</p>



<figure><img data-attachment-id="65" data-permalink="https://smarttechnotes.com/raspbian_2019-04_application_menu/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/raspbian_2019.04_application_menu.jpg" data-orig-size="1280,800" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="raspbian_2019.04_application_menu" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/raspbian_2019.04_application_menu.jpg?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/raspbian_2019.04_application_menu.jpg?w=750" src="https://marifnotes.files.wordpress.com/2020/08/raspbian_2019.04_application_menu.jpg?w=1024" alt="" srcset="https://marifnotes.files.wordpress.com/2020/08/raspbian_2019.04_application_menu.jpg?w=1024 1024w, https://marifnotes.files.wordpress.com/2020/08/raspbian_2019.04_application_menu.jpg?w=150 150w, https://marifnotes.files.wordpress.com/2020/08/raspbian_2019.04_application_menu.jpg?w=300 300w, https://marifnotes.files.wordpress.com/2020/08/raspbian_2019.04_application_menu.jpg?w=768 768w, https://marifnotes.files.wordpress.com/2020/08/raspbian_2019.04_application_menu.jpg 1280w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Raspberry Pi Desktop</figcaption></figure>



<p>Using icons on top right connect to your WiFi network and pair with your Bluetooth speaker. Play some music or a YouTube video to test that the network and Bluetooth connections are working.</p>



<p>Also, using the menu <em>“Preferences-&gt;Raspberry Pi Configuration</em>” enable SSH to be able to login to Raspberry Pi remotely from other computers.</p>



<figure><img data-attachment-id="74" data-permalink="https://smarttechnotes.com/enable-ssh-raspberry-pi/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/enable-ssh-raspberry-pi.jpg" data-orig-size="404,389" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="enable-ssh-raspberry-pi" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/enable-ssh-raspberry-pi.jpg?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/enable-ssh-raspberry-pi.jpg?w=404" src="https://marifnotes.files.wordpress.com/2020/08/enable-ssh-raspberry-pi.jpg?w=300" alt="" srcset="https://marifnotes.files.wordpress.com/2020/08/enable-ssh-raspberry-pi.jpg?w=300 300w, https://marifnotes.files.wordpress.com/2020/08/enable-ssh-raspberry-pi.jpg?w=150 150w, https://marifnotes.files.wordpress.com/2020/08/enable-ssh-raspberry-pi.jpg 404w" sizes="(max-width: 300px) 100vw, 300px"></figure>







<h5>Install Peppy media player</h5>



<p>While searching for a media player for Raspberry Pi that is suitable for a small touchscreen I came across <a href="https://github.com/project-owner/Peppy.doc/wiki">Peppy</a>. It is an open source media player that includes internet radio, audio-books and podcast playback along with the usual audio file and stream playback.  The source code for Peppy is available at GitHub <a href="https://github.com/project-owner/Peppy">https://github.com/project-owner/Peppy</a>.</p>



<p>Follow the instructions at <a href="https://github.com/project-owner/Peppy.doc/wiki/Expert">https://github.com/project-owner/Peppy.doc/wiki/Expert</a> to install Peppy except don’t change the Raspberry Pi OS Boot Option to <em>“login to console with automatic login as pi user”</em> and don’t modify <em>“/etc/rc.local”</em> yet as we want to make sure that the player works fine as a Desktop application before we switch to full screen mode.</p>



<p>I also skipped most other configuration listed on this page that I did not need at this time including <em>“shairport-sync installation”</em>, <em>“raspotify installation”</em>, <em>“Equalizer Configuration”</em>, <em>“Peppyalsa Plugin Configuration”</em>, <em>“Splash Screen Configuration”</em>, <em>“Configure LIRC and Pylirc”</em> and <em>“Rotary Encoders Configuration”</em>.</p>



<p>I did not follow <em>“Adafruit 3.5″ LCD Configuration”</em> as I used a different LCD (from Kumantech as mentioned above).</p>



<p>But I did set up Peppy to play audio via Bluetooth speaker we connected earlier by following instructions <em>“Configure Bluetooth speaker as ALSA device”</em> given at <a href="https://github.com/project-owner/Peppy.doc/wiki/Bluetooth-Devices">https://github.com/project-owner/Peppy.doc/wiki/Bluetooth-Devices</a>. Also, change the configuration in <code>/home/pi/Peppy/config.txt</code>.</p>


<pre title="">bluetooth = True
</pre>


<p>When the player is installed, open a terminal window and launch the player by running the following command (assuming that the player is installed at<code> /home/pi/Peppy</code>)</p>


<pre title="">cd /home/pi/Peppy
python3 peppy.py
</pre>


<p> This should open Peppy as a normal Desktop application. Make sure that the controls are working and Peppy is able to play an internet radio via the Bluetooth speaker. If something is not working, we need to fix it now before attempting to run Peppy full screen.</p>



<figure><img data-attachment-id="97" data-permalink="https://smarttechnotes.com/2020-08-24-181722_480x320_scrot/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/2020-08-24-181722_480x320_scrot.png" data-orig-size="480,320" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-08-24-181722_480x320_scrot" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/2020-08-24-181722_480x320_scrot.png?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/2020-08-24-181722_480x320_scrot.png?w=480" src="https://marifnotes.files.wordpress.com/2020/08/2020-08-24-181722_480x320_scrot.png?w=480" alt="" srcset="https://marifnotes.files.wordpress.com/2020/08/2020-08-24-181722_480x320_scrot.png 480w, https://marifnotes.files.wordpress.com/2020/08/2020-08-24-181722_480x320_scrot.png?w=150 150w, https://marifnotes.files.wordpress.com/2020/08/2020-08-24-181722_480x320_scrot.png?w=300 300w" sizes="(max-width: 480px) 100vw, 480px"></figure>







<h4>Making LCD touchscreen work</h4>



<p>After Peppy media player is fully working as a Desktop application, it is time to make the LCD touchscreen work.</p>



<p>Peppy player’s wiki gives instruction to configure <a href="https://github.com/project-owner/Peppy.doc/wiki/Adafruit-PiTFT">Adafruit LCD</a> and most other Raspberry Pi displays work with <a href="https://github.com/goodtft/LCD-show">goodtft </a>driver from GitHub.  But for the LCD I used I download the LCD driver from Kumantech website (go to the <a href="http://www.kumantech.com/help/documents-and-recources_h0037.html">download page</a> and select 3.5″ LCD) as none of the other drivers worked.</p>



<p>Extract the driver compressed file and run</p>


<pre title="">sudo LCD35-show
</pre>


<p> It installs a bunch of stuff and modifies <em>/boot/config.txt</em>. After the reboot the LCD touchscreen should work.</p>



<p>One thing I noticed that the picture was upside-down (the power connection was at the bottom but I wanted it at the top so that I can place the Raspberry Pi on a desk)</p>



<p>It is easy to rotate the picture by changing</p>


<pre title="">dtoverlay=tft35a
</pre>


<p>to</p>


<pre title="">dtoverlay=tft35a:rotate=270
</pre>


<p>in <em>/boot/config.txt</em> file.</p>







<h4>Starting Peppy player in fullscreen mode</h4>



<p>First we need to disable the Desktop environment starting at reboot. To do this, connect to your Raspberry Pi through SSH from a computer and run the following command after logging in</p>


<pre title="">sudo raspi-config
</pre>


<p>Select the following items in menu:</p>



<ul><li>Boot Options<br>Desktop CLI/Console Autologin To login to console with automatic login as pi user</li></ul>



<p>Installation instructions in Peppy player’s wiki suggest that if we add the following line at the end of<code> <em>/etc/rc.local</em></code> file just before <code>'exit 0'</code> line, We should get Peppy player started at reboot in the fullscreen mode.</p>


<pre title="">su pi -c 'cd /home/pi/Peppy; openvt -s -- python3 peppy.py'
</pre>


<p>It worked except that there was no touchscreen functionality. It seems that the touchscreen driver is not loaded when we try to run Peppy this way. One thing to note was that touchscreen was working in the Desktop environment in the previous step before we disabled it and decided to boot in the console mode.</p>



<p>I came up with the following workaround which is not the most elegant one but it did the job. First, I reverted the change in <code><em>/etc/rc.local</em></code> file. Then I created the <em><code>/home/pi/.xinitrc</code></em> file with the following code</p>


<pre title="">session=${1:-lxde}

case $session in
    lxde           ) exec startlxde-pi;;
    lxterm         ) exec lxterminal;;
    peppy          ) exec lxterminal -e "cd /home/pi/Peppy; python3 peppy.py";;
esac
</pre>


<p>If after booting into the console mode, the <code>startx</code> command is run with the first option <code>lxde</code> (which is also the default option), it starts Raspberry Pi OS Desktop.</p>


<pre title="">startx ~/.xinitrx lxde
</pre>


<p>The second option starts an <code>lxterminal</code> in full screen mode. Even though it is a terminal, it is a desktop terminal application, so X server is started and touchscreen driver is loaded.</p>


<pre title="">startx ~/.xinitrc lxterm
</pre>


<p> The third option starts an <code>lxterminal</code> with a command to run inside it. The command passed using the <code>'-c'</code> tells <code>lxterminal</code> to change directory to Peppy player’s installation directory and start the player from there.</p>


<pre title="">startx ~/.xinitrc peppy
</pre>


<p>If this command is added to <code>.bashrc</code> file, it will be executed automatically after every reboot (actually after every login, but we have selected to boot to console with autologin above). We just have to make sure that we don’t run this command when logging in via SSH from a remote computer.</p>


<pre title="">if [ -n "$SSH_CLIENT" ] || [ -n "$SSH_TTY" ]; then
        echo "SSH session, not starting X server."
else
        startx ~/.xinitrc peppy
fi
</pre>






<h4>Raspberry Pi Touchscreen Internet Radio, Music Player</h4>



<p>And here is it. After the reboot, Peppy player should start in full screen mode with touchscreen functionality.</p>



<figure><img data-attachment-id="104" data-permalink="https://smarttechnotes.com/20200827_143923-1/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/20200827_143923-1.jpg" data-orig-size="3121,1863" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.1&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SM-N975W&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1598539164&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;6&quot;,&quot;iso&quot;:&quot;400&quot;,&quot;shutter_speed&quot;:&quot;0.016949152542373&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="20200827_143923-1" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/20200827_143923-1.jpg?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/20200827_143923-1.jpg?w=750" src="https://marifnotes.files.wordpress.com/2020/08/20200827_143923-1.jpg?w=1024" alt="" srcset="https://marifnotes.files.wordpress.com/2020/08/20200827_143923-1.jpg?w=1024 1024w, https://marifnotes.files.wordpress.com/2020/08/20200827_143923-1.jpg?w=2048 2048w, https://marifnotes.files.wordpress.com/2020/08/20200827_143923-1.jpg?w=150 150w, https://marifnotes.files.wordpress.com/2020/08/20200827_143923-1.jpg?w=300 300w, https://marifnotes.files.wordpress.com/2020/08/20200827_143923-1.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Internet Radio</figcaption></figure>



<figure><img data-attachment-id="105" data-permalink="https://smarttechnotes.com/20200826_214143/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/20200826_214143.jpg" data-orig-size="4032,1908" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.4&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SM-N975W&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1598478103&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.3&quot;,&quot;iso&quot;:&quot;400&quot;,&quot;shutter_speed&quot;:&quot;0.0083333333333333&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="20200826_214143" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/20200826_214143.jpg?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/20200826_214143.jpg?w=750" src="https://marifnotes.files.wordpress.com/2020/08/20200826_214143.jpg?w=1024" alt="" srcset="https://marifnotes.files.wordpress.com/2020/08/20200826_214143.jpg?w=1024 1024w, https://marifnotes.files.wordpress.com/2020/08/20200826_214143.jpg?w=2048 2048w, https://marifnotes.files.wordpress.com/2020/08/20200826_214143.jpg?w=150 150w, https://marifnotes.files.wordpress.com/2020/08/20200826_214143.jpg?w=300 300w, https://marifnotes.files.wordpress.com/2020/08/20200826_214143.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Internet Radio</figcaption></figure>



<figure><img data-attachment-id="127" data-permalink="https://smarttechnotes.com/20200828_143507-1/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/20200828_143507-1.jpg" data-orig-size="1790,1141" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.1&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SM-N975W&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1598625219&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;6&quot;,&quot;iso&quot;:&quot;640&quot;,&quot;shutter_speed&quot;:&quot;0.0169&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="20200828_143507-1" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/20200828_143507-1.jpg?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/20200828_143507-1.jpg?w=750" src="https://marifnotes.files.wordpress.com/2020/08/20200828_143507-1.jpg?w=1024" alt="" srcset="https://marifnotes.files.wordpress.com/2020/08/20200828_143507-1.jpg?w=1024 1024w, https://marifnotes.files.wordpress.com/2020/08/20200828_143507-1.jpg?w=150 150w, https://marifnotes.files.wordpress.com/2020/08/20200828_143507-1.jpg?w=300 300w, https://marifnotes.files.wordpress.com/2020/08/20200828_143507-1.jpg?w=768 768w, https://marifnotes.files.wordpress.com/2020/08/20200828_143507-1.jpg 1790w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Internet Radio</figcaption></figure>


<div data-carousel-extra="{&quot;blog_id&quot;:181821324,&quot;permalink&quot;:&quot;https:\/\/smarttechnotes.com\/2020\/08\/21\/raspberry-pi-touchscreen-internet-radio\/&quot;}"><div data-carousel-extra="{&quot;blog_id&quot;:181821324,&quot;permalink&quot;:&quot;https:\/\/smarttechnotes.com\/2020\/08\/21\/raspberry-pi-touchscreen-internet-radio\/&quot;}"><div data-carousel-extra="{&quot;blog_id&quot;:181821324,&quot;permalink&quot;:&quot;https:\/\/smarttechnotes.com\/2020\/08\/21\/raspberry-pi-touchscreen-internet-radio\/&quot;}"><div data-carousel-extra="{&quot;blog_id&quot;:181821324,&quot;permalink&quot;:&quot;https:\/\/smarttechnotes.com\/2020\/08\/21\/raspberry-pi-touchscreen-internet-radio\/&quot;}"><figure><img data-attachment-id="106" data-permalink="https://smarttechnotes.com/20200827_160212_1/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/20200827_160212_1.gif" data-orig-size="490,368" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="20200827_160212_1" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/20200827_160212_1.gif?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/20200827_160212_1.gif?w=490" srcset="https://marifnotes.files.wordpress.com/2020/08/20200827_160212_1.gif?strip=info&amp;w=368 368w" alt="" data-height="368" data-id="106" data-link="https://marifnotes.wordpress.com/20200827_160212_1/" data-url="https://marifnotes.files.wordpress.com/2020/08/20200827_160212_1.gif" data-width="490" src="https://marifnotes.files.wordpress.com/2020/08/20200827_160212_1.gif"></figure></div></div></div></div>


<div data-carousel-extra="{&quot;blog_id&quot;:181821324,&quot;permalink&quot;:&quot;https:\/\/smarttechnotes.com\/2020\/08\/21\/raspberry-pi-touchscreen-internet-radio\/&quot;}"><figure><img data-attachment-id="98" data-permalink="https://smarttechnotes.com/20200821_113525/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/20200821_113525.jpg" data-orig-size="4032,1908" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.4&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SM-N975W&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1598009726&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.3&quot;,&quot;iso&quot;:&quot;200&quot;,&quot;shutter_speed&quot;:&quot;0.016949152542373&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="20200821_113525" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/20200821_113525.jpg?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/20200821_113525.jpg?w=750" src="https://marifnotes.files.wordpress.com/2020/08/20200821_113525.jpg" alt=""><figcaption>Audio book player</figcaption></figure></div>



<figure><img data-attachment-id="144" data-permalink="https://smarttechnotes.com/20200831_125037-1/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/20200831_125037-1.jpg" data-orig-size="2099,1710" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.5&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SM-G960W&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1598878183&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.3&quot;,&quot;iso&quot;:&quot;250&quot;,&quot;shutter_speed&quot;:&quot;0.027777777777778&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="20200831_125037-1" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/20200831_125037-1.jpg?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/20200831_125037-1.jpg?w=750" src="https://marifnotes.files.wordpress.com/2020/08/20200831_125037-1.jpg?w=1024" alt="" srcset="https://marifnotes.files.wordpress.com/2020/08/20200831_125037-1.jpg?w=1024 1024w, https://marifnotes.files.wordpress.com/2020/08/20200831_125037-1.jpg?w=2048 2048w, https://marifnotes.files.wordpress.com/2020/08/20200831_125037-1.jpg?w=150 150w, https://marifnotes.files.wordpress.com/2020/08/20200831_125037-1.jpg?w=300 300w, https://marifnotes.files.wordpress.com/2020/08/20200831_125037-1.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Podcast player</figcaption></figure>







<h4>Weather station</h4>



<p>Another good thing about Peppy player is that it has a <a href="https://github.com/project-owner/Peppy.doc/wiki/Configuration">WebUI for configuration</a>. It can be used to configure your current location to fetch the weather information from the internet.</p>





<p>After configuring the location, just set ‘weather’ as the screensaver and we have a weather station.</p>



<figure><img data-attachment-id="90" data-permalink="https://smarttechnotes.com/20200821_111038-1-1/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1-1.jpg" data-orig-size="3274,1753" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.4&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SM-N975W&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1598008238&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.3&quot;,&quot;iso&quot;:&quot;400&quot;,&quot;shutter_speed&quot;:&quot;0.025&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="20200821_111038-1-1" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1-1.jpg?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1-1.jpg?w=750" src="https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1-1.jpg?w=1024" alt="" srcset="https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1-1.jpg?w=1024 1024w, https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1-1.jpg?w=2048 2048w, https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1-1.jpg?w=150 150w, https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1-1.jpg?w=300 300w, https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1-1.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Weather Station</figcaption></figure>



<figure><img data-attachment-id="94" data-permalink="https://smarttechnotes.com/20200821_111502/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/20200821_111502.jpg" data-orig-size="2464,1764" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.4&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SM-N975W&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1598008502&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.3&quot;,&quot;iso&quot;:&quot;200&quot;,&quot;shutter_speed&quot;:&quot;0.025641025641026&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="20200821_111502" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/20200821_111502.jpg?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/20200821_111502.jpg?w=750" src="https://marifnotes.files.wordpress.com/2020/08/20200821_111502.jpg?w=1024" alt="" srcset="https://marifnotes.files.wordpress.com/2020/08/20200821_111502.jpg?w=1024 1024w, https://marifnotes.files.wordpress.com/2020/08/20200821_111502.jpg?w=2048 2048w, https://marifnotes.files.wordpress.com/2020/08/20200821_111502.jpg?w=150 150w, https://marifnotes.files.wordpress.com/2020/08/20200821_111502.jpg?w=300 300w, https://marifnotes.files.wordpress.com/2020/08/20200821_111502.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Weather Station</figcaption></figure>



<p>And that’s it! Enjoy your new internet radio.&nbsp;</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://smarttechnotes.com/raspberry-pi-touchscreen-internet-radio</link>
            <guid isPermaLink="false">hacker-news-small-sites-24635359</guid>
            <pubDate>Wed, 30 Sep 2020 03:14:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nobody seems to give a crap about Google’s monopoly on search, not even Google]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24635322">thread link</a>) | @pcr910303
<br/>
September 29, 2020 | https://thejollyteapot.com/2020/09/29/nobody-seems-to-give-a-crap-about-google-s-monopoly-on-search-not-even-google | <a href="https://web.archive.org/web/*/https://thejollyteapot.com/2020/09/29/nobody-seems-to-give-a-crap-about-google-s-monopoly-on-search-not-even-google">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><a href="https://thejollyteapot.com/2020/09/29/nobody-seems-to-give-a-crap-about-google-s-monopoly-on-search-not-even-google">29 September 2020</a></p>
<p>Quick summary of the situation, from the <a href="https://www.android.com/choicescreen/">Choice Screen webpage on the Android website</a>:</p>
<blockquote>
<p>On August 2, 2019, following the European Commission’s July 2018 Android decision, Google announced that it would implement a choice screen for general search providers on all new Android phones and tablets shipped into the European Economic Area (<span>EEA</span>) where the Google Search app is pre-installed. This updated Help Center article describes a modified choice screen design that was developed in consultation with the European Commission.</p>
<p>The choice screen will appear during initial device setup and will feature multiple search providers, including Google. An illustrative version of the choice screen follows. Providers may vary by country. […]</p>
<p>Eligible search providers will need to fill out an application form and can bid for inclusion based on an auction. The auction process is explained in greater detail below.</p>
</blockquote>
<p>Considering how much this farce has been <a href="https://www.neowin.net/news/duckduckgo-blasts-googles-android-choice-screen-says-it-incentivizes-ads">covered</a> <a href="https://techcrunch.com/2020/07/30/googles-no-choice-screen-on-android-isnt-working-says-ecosia-querying-the-eus-approach-to-antitrust-enforcement/">already</a>, I will not repeat what <a href="https://www.businessinsider.com/google-android-choice-screen-eu-duckduckgo-2020-9?IR=T">everybody knows</a>. Instead I will just point out how Google announced the result of the auctions <a href="https://www.android.com/choicescreen-winners/">on the Android website</a>: four sentences, two footnotes, a table listing the<span></span> <span>“</span>winners” per country, a title that reads do-not-give-a-shit, and that’s it.</p>
<p>Also, I don’t think I have ever heard of — <em>check notes</em> — PrivacyWall and info.com.<span></span> <span>’</span>What are they?’, you may ask: they are search engines apparently, and they are the only two search engine options offered to Android users in France that are not Google or Bing. And yes, in case you’re wondering, <a href="https://www.youtube.com/watch?v=nfHuZ5qrYX4">Bing is still around</a>. Ecosia, DuckDuckGo, barely appear on the list.</p>
<p>If anything, this whole thing will reinforce Google’s monopoly on search. Users will see this<span></span> <span>’</span>choice screen’ and think:<span></span> <span>“</span><span>OK</span>, so two shady things I don’t know, Bing (laughs), and yep, Google. Why would they even ask me to choose?”</p>
<p>It’s like asking kids who have only ever watched the movie <em>Ratatouille</em> if they want to watch Ratatouille again, or another movie from this list: <a href="https://www.imdb.com/title/tt2120120/?ref_=fn_al_tt_1"><em>Pixels</em></a> (even the kids would know it sucks), <em><a href="https://www.imdb.com/title/tt0257778/?ref_=ttls_li_tt">The Hunchback of Notre Dame <span>II</span>: The Secret of the Bell</a></em> (you’re lucky if the kids even know about the first one), and <em><a href="https://www.imdb.com/title/tt0083630/?ref_=nv_sr_srsg_0">The Beastmaster</a></em>.</p>

          
          <p>
            <a href="https://thejollyteapot.com/tagged/technology">Technology</a>
          </p>

          
          


      

          <a href="https://thejollyteapot.com/2020/08/18/samsung-commits-to-deliver-three-years-of-android-updates-for-its-phones">
            <h5>Previous post</h5>
            <span>Samsung commits to deliver three years of Android updates for its phones</span>
            
          </a>

          <a href="https://thejollyteapot.com/2020/10/1/looking-back-at-my-short-list-of-apple-wishes-from-april">
            <h5>Next post</h5>
            <span>Looking back at my short list of Apple wishes from April</span>
          </a>

        </div></div>]]>
            </description>
            <link>https://thejollyteapot.com/2020/09/29/nobody-seems-to-give-a-crap-about-google-s-monopoly-on-search-not-even-google</link>
            <guid isPermaLink="false">hacker-news-small-sites-24635322</guid>
            <pubDate>Wed, 30 Sep 2020 03:07:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Live dashboard of every email Trump and Biden are sending]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24635143">thread link</a>) | @greggblanchard
<br/>
September 29, 2020 | https://sendview.io/trump-v-biden | <a href="https://web.archive.org/web/*/https://sendview.io/trump-v-biden">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <div>
            <!--
            <h2 style="margin-bottom: 25px;">
              <em class="fa fa-calendar"></em>
              Live Campaign Timeline
              <span>Last 50, Newest to Oldest</span>
            </h2>-->
            <div>
              <p>
                <h2>
                  <em></em>
                  Live Campaign Timeline
                  <span>Camapaigns Listed Newest to Oldest</span>
                </h2>
              </p>
              
              
            </div>
              
                                        <p><a href="https://sendview.io/s/a_aHIwOxAj9MYZ2kuR" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                WE LOVE TRUMP <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  5mins ago</span>
              </a>
                                        <a href="https://sendview.io/s/a_bZ30Fjnd6XrKTU8h" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                My father <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  1h 30m ago </span>
              </a>
                                        <a href="https://sendview.io/s/a_aKeZzyTnINHJhdq9" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                Respectfully asking for $25 <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  1h 37m ago </span>
              </a>
                                        <a href="https://sendview.io/s/a_eQRKJ9gsyYrOV3Xa" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                I â�¤ï¸� Trump Shirt <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  2h 48m ago </span>
              </a>
                                        <a href="https://sendview.io/s/a_i7IPDOYjJHhM9m2y" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                NEW POLL <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  4h 2m ago </span>
              </a>
                                        <a href="https://sendview.io/s/a_dW5IXAVEQTOsUN20" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                Will you join the battle to 270 electoral votes? <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  4h 19m ago </span>
              </a>
                                        <a href="https://sendview.io/s/a_Emv73toR9kYyMZFg" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                ATTN: The President has a video message for you <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  7h 17m ago </span>
              </a>
                                        <a href="https://sendview.io/s/a_fqP4u2U6S3TgBHcw" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                this email is a little different <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  7h 28m ago </span>
              </a>
                                        <a href="https://sendview.io/s/a_9fNLqxPj6VmkFu7g" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                URGENT: ðŸ“Ž Video message from President Trump <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  9h 31m ago </span>
              </a></p><p>
                FRIDAY, OCT 2, 2020              </p>
                            <p><a href="https://sendview.io/s/a_KqnCSMGkw07LHFQZ" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                I'd like to give you a call <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  8:31pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_fSAgmyN2U7MGpI8H" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Lyinâ€™ Obama <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  5:26pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_hcWgLrIAMy5zpSFK" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                re: your RSVP for my event today <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  3:57pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_7iE9KWVLCjR3kozY" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Your Matching Check <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  3:15pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_CXtLcqnNoMbSPAz6" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Youâ€™re going to love this <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  2:12pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_XbEVhKT8d6nFH2oR" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                President Obama and Kamala are counting on you <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  1:37pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_1UjPHg54QoMSaYsu" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Your flight to Houston <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  7:15am</span>
              </a>
                                        <a href="https://sendview.io/s/a_IkizDcuOT8ylBC4H" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Update on our goal <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  5:13am</span>
              </a></p><p>
                THURSDAY, OCT 1, 2020              </p>
                            <p><a href="https://sendview.io/s/a_Rlb26OAG8p9JSZjq" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                You + Me in LA <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  11:10pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_T0cKaYwRMfSVeX5G" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                Are you free tomorrow? <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  11:00pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_8wfpsh7CGvimO3nQ" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Become a Trump MVP <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  9:15pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_Ok52vWoDCfpXqJcA" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Your chance, Donald <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  8:13pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_nTg8lvFtqHN7rh2I" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                You, me, and President Obama tomorrow <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  7:36pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_C49HAINZvdL7qfYF" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Weâ€™ve got some just for you <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  7:10pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_F9iYc1rtlGE0ex8p" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                ðŸŒž Sunny LA ðŸŒž <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  6:13pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_FeVqHJo9mNEpId6j" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                We are in the fight of our life <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  5:10pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_986tWrmfPQL7d3TA" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Time is running out <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  3:24pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_BaW56ywqAEbDr7iP" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                President Obama and Kamala Harris want to know if you're free tomorrow <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  1:32pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_eBGadSwkztgQc6xF" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Congratulations! <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  1:28pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_1sBaJHTnCL6QMkhG" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                September 31st <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  11:46am</span>
              </a>
                                        <a href="https://sendview.io/s/a_P2Kcmzw5H38fXiB9" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                Thank you for your support <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  10:36am</span>
              </a>
                                        <a href="https://sendview.io/s/a_u7YIdQZaELOiHhWm" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Letâ€™s meet up <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  9:07am</span>
              </a>
                                        <a href="https://sendview.io/s/a_fSjtBVY9CzRmWT35" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Itâ€™s not too late <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  7:13am</span>
              </a>
                                        <a href="https://sendview.io/s/a_MYU9n5oZziDfXmy6" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Take the Official Presidential Debate Approval Poll NOW <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  3:08am</span>
              </a>
                                        <a href="https://sendview.io/s/a_okW9C2DTvq8bdcwE" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                ðŸš¨ End-of-Quarter ALERT ðŸš¨ <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  1:07am</span>
              </a>
                                        <a href="https://sendview.io/s/a_4psIDmQouE7Oyg3G" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Your 850%-MATCHING check <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  12:07am</span>
              </a></p><p>
                WEDNESDAY, SEP 30, 2020              </p>
                            <p><a href="https://sendview.io/s/a_8PVaoth0nDJNEykg" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                Will you be one of our final September donors? <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  11:23pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_RpcftUMWwi8JkxG3" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Deadline: MIDNIGHT <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  11:08pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_35UwrGOA0ezop4l8" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                We have to do this FIRST <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  10:07pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_sOn9lPbojwGCEKMu" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                FINAL THREE HOURS <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  9:07pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_g2hXH6RLT8MpJejP" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Election Day is ALMOST here <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  8:23pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_aT8wySMDbYRtKlQn" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                Joe, Kamala, Barack, Hillary, and more all emailed you <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  8:00pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_mbgOeCs2aNpLfH3w" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                We need to CRUSH our goal <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  7:38pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_uW3BVxv78zT9oUjh" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Itâ€™s now or never <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  6:52pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_cuLdqJb0gS6zPXCQ" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                ONLY 6 hours to step up <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  6:08pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_e8MqBiXOY4bt2Fzm" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                I'm worried we might fall short <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  5:42pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_g6weXC74azqjEROk" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                FINAL NOTICE <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  5:21pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_ZGMDk7Jf520IUnHE" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                We need to keep going <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  4:06pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_gGD6aAfpl1SZ2W7i" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                BIDEN WILL PACK THE COURTS <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  2:10pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_EAJO4ailPtzcrvj2" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                I'm asking personally <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  12:45pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_YRjK5yF0L6euZxVi" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                â�°â�° 12-hour deadline alert â�°â�° <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  12:00pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_UC0hbDl6nYpSAFq9" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                Please <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  10:40am</span>
              </a>
                                        <a href="https://sendview.io/s/a_i8Wxynv2m4AYKISe" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                âœ”ï¸� First Presidential Debate <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  9:09am</span>
              </a>
                                        <a href="https://sendview.io/s/a_PqzUhvEjTtuSNp3A" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                What did you think of the debate? <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  7:09am</span>
              </a>
                                        <a href="https://sendview.io/s/a_8yrCmnIS4P7ZwaMc" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Special 800%-MATCH <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  5:08am</span>
              </a>
                                        <a href="https://sendview.io/s/a_T3yfNaQluA6vPtpX" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Did you watch the debate? <em></em>
                <span>Trump &nbsp; / &nbsp;  
        …</span></a></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sendview.io/trump-v-biden">https://sendview.io/trump-v-biden</a></em></p>]]>
            </description>
            <link>https://sendview.io/trump-v-biden</link>
            <guid isPermaLink="false">hacker-news-small-sites-24635143</guid>
            <pubDate>Wed, 30 Sep 2020 02:25:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I tracked and analyzed 13,159 Hacker News posts. Here's what I learned]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24634991">thread link</a>) | @mellosouls
<br/>
September 29, 2020 | https://www.ankle.io/posts/hacker-news-analysis | <a href="https://web.archive.org/web/*/https://www.ankle.io/posts/hacker-news-analysis">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2 id="motivation"><a href="#motivation" aria-label="motivation permalink"></a>Motivation</h2>
<p>Hitting the front page of Hacker News is an incredible source of short-term traffic to your website or article.</p>
<p>According to this <a href="https://thehftguy.com/2017/09/26/hitting-hacker-news-front-page-how-much-traffic-do-you-get" rel="nofollow">article</a>, in 2017, being on the front page brings a sudden influx of between 10k and 30k visitors to your website/article, something many content marketers, product people, and entrepreneurs undoubtedly salivate over, including me.</p>
<p>I occasionally post to Hacker News (with random things and personal stuff) but have never reached the front page before. Therefore, I decided to dig a little deeper into the mechanics of Hacker News and the best approach to take if the sole goal is to hit the front page.</p>
<p>Obviously, a critical part of hitting the front page is submitting an interesting article which resonates with the HN audience. But beyond this, there are other factors at play—timing, title, upvotes, etc.</p>
<h2 id="methodology-a-unique-approach"><a href="#methodology-a-unique-approach" aria-label="methodology a unique approach permalink"></a>Methodology: A unique approach</h2>
<p>I am not the only person to want to know the best approach to hitting the front page. A few people have analyzed data from <a href="https://console.cloud.google.com/marketplace/details/y-combinator/hacker-news" target="_blank" rel="nofollow noopener noreferrer">Google’s Hacker News Dataset</a> on BigQuery to find the best time to submit to Hacker News.</p>
<p>The problem with this approach is that BigQuery doesn’t know how long a post spent on the front page, nor how long it was there for or what position it reached. It can only provide the total number of upvotes.</p>
<p>With this in mind, I wrote a small NodeJS script to poll Hacker News every 2 minutes. Using a Postgres database, I stored every post, user, and upvote over two weeks.</p>
<p>With this information, I compiled a list of useful information and insights below.</p>
<p>Note: To filter out posts that are either flagged or transiently featured, I set an arbitrary duration of 60+ minutes as a time requirement in the top for a post to be considered a “front page post.”</p>
<h2 id="limitations"><a href="#limitations" aria-label="limitations permalink"></a>Limitations</h2>
<p>Obviously, the lack of data (13,159 posts) and time spent collecting data (2 weeks) is the most significant limitation of my results. Nonetheless, I believe the results are still relatively useful, at least for the next few weeks or months.</p>
<h2 id="results"><a href="#results" aria-label="results permalink"></a>Results</h2>
<h3 id="basic-stats"><a href="#basic-stats" aria-label="basic stats permalink"></a>Basic stats</h3>
<ul>
<li>I tracked a total of 13,159 posts over two weeks.</li>
<li>Of these, 1,073 made the front page for more than 60 minutes.</li>
<li>That’s a hit rate of 8.15%</li>
<li>Frontpage posts stayed at the top for an average of 483.3 minutes (8 hours)</li>
<li>30% of posts reaching the front page were posted by users who posted more than once over the two weeks.</li>
</ul>
<p><strong>Takeaway:</strong> In my opinion, more posts reach the front page than expected and for longer than expected.</p>
<h3 id="types-of-posts-breakdown"><a href="#types-of-posts-breakdown" aria-label="types of posts breakdown permalink"></a>Types of posts breakdown</h3>

<h3 id="hit-rate--of-different-post-types-making-the-front-page"><a href="#hit-rate--of-different-post-types-making-the-front-page" aria-label="hit rate  of different post types making the front page permalink"></a>Hit rate % of different post types making the front page</h3>

<p><strong>Takeaway:</strong> Interestingly, “Show HN” posts make the front page by proportion very slightly less than “Links,” which goes against previous thought that “Show HN” posts perform better due to an algorithm bias. That being said, there may well be an algorithm bias, just many “Show HN” posts are simply not worth upvoting.</p>
<h3 id="when-is-the-best-day-to-post-to-hacker-news-in-2020"><a href="#when-is-the-best-day-to-post-to-hacker-news-in-2020" aria-label="when is the best day to post to hacker news in 2020 permalink"></a>When is the best day to post to Hacker News in 2020?</h3>

<p>The chart above shows that you should post on the weekend to stand the best chance of reaching the front page of Hacker News. The difference from the worst to the best day is only 3.2%, so there’s not a lot in it.</p>
<p>The weekend likely gives you a higher chance to reach the front page because fewer posts are submitted, probably due to lower traffic.</p>
<p><strong>Takeaway</strong>: If your goal is to reach the front page regardless of traffic, posting on the weekend is your best bet. However, because the difference in chance is relatively low throughout the week, posting on a more popular day might be a better risk-reward ratio based on the considerable difference in the traffic you’d likely receive.</p>
<h3 id="when-is-the-best-time-to-post-to-hacker-news-in-2020"><a href="#when-is-the-best-time-to-post-to-hacker-news-in-2020" aria-label="when is the best time to post to hacker news in 2020 permalink"></a>When is the best time to post to Hacker News in 2020?</h3>

<p>Taking a more granular look at the combined hours of all the posts submitted, the chart above highlights a much more significant difference (10.9%) between the chance of reaching the front page of Hacker News.</p>
<p>The best time to post to Hacker News is between 6 am—12 pm UTC (11 pm—5 am PDT). Again, the reason is likely because this is when the website traffic is at it’s lowest, and therefore the competition is relatively low.</p>
<p>I imagine the US is responsible for most of Hacker News’s web traffic, which lines up with the results above. Therefore, if you are posting a link for a US-specific audience to HN, it’s probably best to pick a different time like 4 pm UTC (9 am PDT), or midnight UTC (5 pm PDT).</p>
<p><strong>Takeaway:</strong> If your link requires a US-specific audience, post at 4 pm UTC (9 am PDT / 12 pm EDT), or midnight UTC (5 pm PDT). Otherwise, post between 6 am—12 pm UTC (11 pm—5 am PDT) for the best chance of reaching the front page of Hacker News.</p>
<h3 id="when-in-the-best-day-and-time-to-post-to-hacker-news-in-2020"><a href="#when-in-the-best-day-and-time-to-post-to-hacker-news-in-2020" aria-label="when in the best day and time to post to hacker news in 2020 permalink"></a>When in the best day and time to post to Hacker News in 2020?</h3>
<p>Combining both days and hours into a total weekly picture is even more evident when it is best to post. However, please note, the lack of data makes this chart vulnerable to skewed results.</p>

<p>The chart above illustrates wild fluctuations between the different hours of the week. The lowest chance of reaching the front page is 1-2%, and the highest is 18%-27%. That’s a massive difference.</p>
<p>Looking at the chart, below are generally the best days &amp; times to post to Hacker News:</p>
<ul>
<li><strong>Monday:</strong> 1 am—4 pm UTC (6 pm—9 am PDT)</li>
<li><strong>Tuesday, Wednesday &amp; Thursday:</strong> 12 am—6 am &amp; 9 am—12 pm UTC (5 pm—11 pm &amp; 2 am—5 am PDT)</li>
<li><strong>Friday:</strong> 5 am—12 pm UTC (10 pm—5 am PDT)</li>
<li><strong>Saturday:</strong> 4 am—9 am UTC (9 pm—2 am PDT)</li>
<li><strong>Sunday:</strong> 3 am—8 am &amp; 10 am—6 pm UTC (8 pm—1 am &amp; 3 am—11 am PDT)</li>
</ul>
<p>And here are the best times specifically (bear in mind these may not be the case week-in-week-out because the amount of data limits the results):</p>
<ul>
<li><strong>Monday:</strong> 12 pm UTC (5 am PDT)</li>
<li><strong>Tuesday:</strong> 9 am UTC (2 am PDT)</li>
<li><strong>Wednesday:</strong> 10 am UTC (3 am PDT)</li>
<li><strong>Thursday:</strong> 12 pm UTC (5 pm PDT)</li>
<li><strong>Friday:</strong> 8 am UTC (1 am PDT)</li>
<li><strong>Saturday:</strong> 9 am UTC (2 am PDT)</li>
<li><strong>Sunday:</strong> 5 am OR 1 pm (10 pm OR 6 am PDT)</li>
</ul>
<p><strong>Takeaway:</strong> It’s pretty clear that the best times to post on Hacker News to reach the front page are usually around 6 am UTC (11 pm PDT), 9 am UTC (2 am PDT), or 12 pm UTC (5 am PDT), when the US is asleep.</p>
<p>However, given that 8 hours is the average time spent on the front page, it’s probably best to post at 12 pm UTC on Monday, Thursday, Saturday or Sunday to maximize traffic for when the US wakes up.</p>
<h3 id="how-many-votes-does-a-post-need-to-reach-the-front-page-of-hacker-news-in-2020"><a href="#how-many-votes-does-a-post-need-to-reach-the-front-page-of-hacker-news-in-2020" aria-label="how many votes does a post need to reach the front page of hacker news in 2020 permalink"></a>How many votes does a post need to reach the front page of Hacker News in 2020?</h3>
<p>5.22 is the average number of votes a post needed within an average time of 27.1 minutes to reach the front page for the first time.</p>
<p>Below is a chart of box plots to illustrate the variation of votes required over 24 hours.</p>

<p>Interestingly, this graph clearly shows every post, regardless of time, required at least three upvotes, and for 75% of posts, they never needed more than eight votes to reach the front page of Hacker News.</p>
<p>Expectedly, the range of upvotes required is lower for the first half of the day than the second half, roughly matching up to the timings above.</p>
<p>In some cases, posts required a lot more votes to reach the front page. Presumably, because either the time it took to get these votes was over more time, or there was a lot of competition.</p>
<p><strong>Takeaway:</strong> The votes required to be seen on the front page is relatively small. For the best chance of getting on the front page, you’ll need between 4-6 votes in about 30 minutes, posting in the first half of the day (12 am—12pm UTC).</p>
<h3 id="how-much-karma-do-you-need-to-reach-the-front-page-of-hacker-news-in-2020"><a href="#how-much-karma-do-you-need-to-reach-the-front-page-of-hacker-news-in-2020" aria-label="how much karma do you need to reach the front page of hacker news in 2020 permalink"></a>How much karma do you need to reach the front page of Hacker News in 2020?</h3>
<p>Finally, I thought it would be interesting to see the relationship between karma and reaching the front page of Hacker News.</p>
<p>This first pie chart demonstrates the proportion of posts being posted by users with varying levels of karma.</p>

<p>Surprisingly, over 50% of posts are submitted by users with over 1,000 karma points. However, the largest single segment is by users with little to no karma.</p>

<p>The chart above shows that newer users (0-50 karma) make the front page proportionally less than more experienced users. Interestingly, really experienced users (over 10,000 karma) reached the front page significantly more than experienced users.</p>
<p><strong>Takeaway:</strong> It’s hard to say whether karma has anything to do with rankings. Likely, users with more karma are just better at posting content that resonates with the Hacker News audience.</p></div></div>]]>
            </description>
            <link>https://www.ankle.io/posts/hacker-news-analysis</link>
            <guid isPermaLink="false">hacker-news-small-sites-24634991</guid>
            <pubDate>Wed, 30 Sep 2020 01:43:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Guima Cloud – TLA+ Online Simple REPL]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24634705">thread link</a>) | @pfeodrippe
<br/>
September 29, 2020 | https://guima.cloud/editor?state=ezpibG9jay9ibG9ja3MgW3s6YmxvY2sucmVwbC9jb2RlICIoKiA8LS0gQmVnaW5uaW5nIG9mIGEgY29tbWVudGFyeS5cbiAgICBcbiAgSGksIHRoaXMgaXMgeW91ciBvbmxpbmUgVExBKyBSRVBMIChub24tb2ZpY2lhbCksXG4gIHdlbGNvbWUgby9cbiAgIFxuICBVc2UgQ1RSTCtFTlRFUiB0byBldmFsIHRoZSBSRVBMIGNvZGUsXG4gIEFMVCtFTlRFUiB0byBjcmVhdGUgYSBuZXcgUkVQTCBibG9jay4uLiBhbmQgdGhhdCBpcyBhbGwuXG4gICAgXG4gIFNlZSByZXN1bHQgYXQgdGhlIHJpZ2h0IG9mIHRoZSBibG9jay5cbiAgICBcbiAgU2hhcmUgd2l0aCB5b3VyIGZyaW5kIHVzaW5nIHRoZSBcIlNoYXJlXCIgYnV0dG9uIGF0IHRoZSB0b3AgKHRoZSB1cmxcbiAgaXMgY29wcGllZCB0byB5b3VyIGNsaXBib2FyZCkuXG4gICAgXG4gIFRoaXMgaXMgYSB2ZXJ5IHJvdWdoIGV4cGVyaW1lbnQsIGhhdmUgZnVuLCBzaGFyZSBrbm93bGVkZ2UuXG4gICAgXG4gIFdlIGxldmVyYWdlIFwiaHR0cHM6Ly9naXRodWIuY29tL3RsYXBsdXMvUGx1c1B5XCIgdG8gcnVuIHRoZSBjb2RlLCBcbiAgYXdlc29tZSBwcm9qZWN0ISEgXG4gIFxuICBTZWUgXCJodHRwczovL2xlYXJudGxhLmNvbVwiIHRvIGxlYXJuIFRMQSsgc3ludGF4LlxuICAgIFxuICBIZWF2aWx5IGluc3BpcmVkICh5b3UgY291bGQgc2F5IGNvcGllZCkgYnkgXCJodHRwczovL3d3dy5tYXJpYS5jbG91ZC9cIiA9RFxuICBcbiAgRW5kIG9mIGEgY29tbWVudGFyeS4gLS0+ICopIn0gezpibG9jay5yZXBsL2NvZGUgIigqIEEgc3VtICopXG4xICsgNCJ9IHs6YmxvY2sucmVwbC9jb2RlICIoKiBDcmVhdGVzIGEgc2V0IHNxdWFyaW5nIGEgbnVtYmVyLCB3aGVyZSB0aGlzIG51bWJlciBpc1xuICAgYSBlbGVtZW50IG9mIHRoZSBzZXQgezEsIDJ9ICopXG57eCAqIHggOiB4IFxcaW4gezEsIDJ9fSJ9IHs6YmxvY2sucmVwbC9jb2RlICIoKiBDb25jYXQgbGlzdCAqKVxuPDwgMSA+PiBcXG8gPDwgMiwgMyA+PiJ9IHs6YmxvY2sucmVwbC9jb2RlICIoKiBUaGlzIHdpbGwgcmFpc2UgYW4gZXJyb3IsIHNlZSBzb2x1dGlvbiBhdCB0aGUgbmV4dCBibG9jayAqKVxuU29tZXRoaW5nID09IDJcbjEgKyBTb21ldGhpbmcifSB7OmJsb2NrLnJlcGwvY29kZSAiKCogRm9yIG11bHRpbGluZSBibG9ja3MsIHVzZSA0IC0gLSAtIC0gKilcblNvbWV0aGluZyA9PSAyXG4tLS0tXG4xICsgU29tZXRoaW5nIn1dfQ== | <a href="https://web.archive.org/web/*/https://guima.cloud/editor?state=ezpibG9jay9ibG9ja3MgW3s6YmxvY2sucmVwbC9jb2RlICIoKiA8LS0gQmVnaW5uaW5nIG9mIGEgY29tbWVudGFyeS5cbiAgICBcbiAgSGksIHRoaXMgaXMgeW91ciBvbmxpbmUgVExBKyBSRVBMIChub24tb2ZpY2lhbCksXG4gIHdlbGNvbWUgby9cbiAgIFxuICBVc2UgQ1RSTCtFTlRFUiB0byBldmFsIHRoZSBSRVBMIGNvZGUsXG4gIEFMVCtFTlRFUiB0byBjcmVhdGUgYSBuZXcgUkVQTCBibG9jay4uLiBhbmQgdGhhdCBpcyBhbGwuXG4gICAgXG4gIFNlZSByZXN1bHQgYXQgdGhlIHJpZ2h0IG9mIHRoZSBibG9jay5cbiAgICBcbiAgU2hhcmUgd2l0aCB5b3VyIGZyaW5kIHVzaW5nIHRoZSBcIlNoYXJlXCIgYnV0dG9uIGF0IHRoZSB0b3AgKHRoZSB1cmxcbiAgaXMgY29wcGllZCB0byB5b3VyIGNsaXBib2FyZCkuXG4gICAgXG4gIFRoaXMgaXMgYSB2ZXJ5IHJvdWdoIGV4cGVyaW1lbnQsIGhhdmUgZnVuLCBzaGFyZSBrbm93bGVkZ2UuXG4gICAgXG4gIFdlIGxldmVyYWdlIFwiaHR0cHM6Ly9naXRodWIuY29tL3RsYXBsdXMvUGx1c1B5XCIgdG8gcnVuIHRoZSBjb2RlLCBcbiAgYXdlc29tZSBwcm9qZWN0ISEgXG4gIFxuICBTZWUgXCJodHRwczovL2xlYXJudGxhLmNvbVwiIHRvIGxlYXJuIFRMQSsgc3ludGF4LlxuICAgIFxuICBIZWF2aWx5IGluc3BpcmVkICh5b3UgY291bGQgc2F5IGNvcGllZCkgYnkgXCJodHRwczovL3d3dy5tYXJpYS5jbG91ZC9cIiA9RFxuICBcbiAgRW5kIG9mIGEgY29tbWVudGFyeS4gLS0+ICopIn0gezpibG9jay5yZXBsL2NvZGUgIigqIEEgc3VtICopXG4xICsgNCJ9IHs6YmxvY2sucmVwbC9jb2RlICIoKiBDcmVhdGVzIGEgc2V0IHNxdWFyaW5nIGEgbnVtYmVyLCB3aGVyZSB0aGlzIG51bWJlciBpc1xuICAgYSBlbGVtZW50IG9mIHRoZSBzZXQgezEsIDJ9ICopXG57eCAqIHggOiB4IFxcaW4gezEsIDJ9fSJ9IHs6YmxvY2sucmVwbC9jb2RlICIoKiBDb25jYXQgbGlzdCAqKVxuPDwgMSA+PiBcXG8gPDwgMiwgMyA+PiJ9IHs6YmxvY2sucmVwbC9jb2RlICIoKiBUaGlzIHdpbGwgcmFpc2UgYW4gZXJyb3IsIHNlZSBzb2x1dGlvbiBhdCB0aGUgbmV4dCBibG9jayAqKVxuU29tZXRoaW5nID09IDJcbjEgKyBTb21ldGhpbmcifSB7OmJsb2NrLnJlcGwvY29kZSAiKCogRm9yIG11bHRpbGluZSBibG9ja3MsIHVzZSA0IC0gLSAtIC0gKilcblNvbWV0aGluZyA9PSAyXG4tLS0tXG4xICsgU29tZXRoaW5nIn1dfQ==">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://guima.cloud/editor?state=ezpibG9jay9ibG9ja3MgW3s6YmxvY2sucmVwbC9jb2RlICIoKiA8LS0gQmVnaW5uaW5nIG9mIGEgY29tbWVudGFyeS5cbiAgICBcbiAgSGksIHRoaXMgaXMgeW91ciBvbmxpbmUgVExBKyBSRVBMIChub24tb2ZpY2lhbCksXG4gIHdlbGNvbWUgby9cbiAgIFxuICBVc2UgQ1RSTCtFTlRFUiB0byBldmFsIHRoZSBSRVBMIGNvZGUsXG4gIEFMVCtFTlRFUiB0byBjcmVhdGUgYSBuZXcgUkVQTCBibG9jay4uLiBhbmQgdGhhdCBpcyBhbGwuXG4gICAgXG4gIFNlZSByZXN1bHQgYXQgdGhlIHJpZ2h0IG9mIHRoZSBibG9jay5cbiAgICBcbiAgU2hhcmUgd2l0aCB5b3VyIGZyaW5kIHVzaW5nIHRoZSBcIlNoYXJlXCIgYnV0dG9uIGF0IHRoZSB0b3AgKHRoZSB1cmxcbiAgaXMgY29wcGllZCB0byB5b3VyIGNsaXBib2FyZCkuXG4gICAgXG4gIFRoaXMgaXMgYSB2ZXJ5IHJvdWdoIGV4cGVyaW1lbnQsIGhhdmUgZnVuLCBzaGFyZSBrbm93bGVkZ2UuXG4gICAgXG4gIFdlIGxldmVyYWdlIFwiaHR0cHM6Ly9naXRodWIuY29tL3RsYXBsdXMvUGx1c1B5XCIgdG8gcnVuIHRoZSBjb2RlLCBcbiAgYXdlc29tZSBwcm9qZWN0ISEgXG4gIFxuICBTZWUgXCJodHRwczovL2xlYXJudGxhLmNvbVwiIHRvIGxlYXJuIFRMQSsgc3ludGF4LlxuICAgIFxuICBIZWF2aWx5IGluc3BpcmVkICh5b3UgY291bGQgc2F5IGNvcGllZCkgYnkgXCJodHRwczovL3d3dy5tYXJpYS5jbG91ZC9cIiA9RFxuICBcbiAgRW5kIG9mIGEgY29tbWVudGFyeS4gLS0+ICopIn0gezpibG9jay5yZXBsL2NvZGUgIigqIEEgc3VtICopXG4xICsgNCJ9IHs6YmxvY2sucmVwbC9jb2RlICIoKiBDcmVhdGVzIGEgc2V0IHNxdWFyaW5nIGEgbnVtYmVyLCB3aGVyZSB0aGlzIG51bWJlciBpc1xuICAgYSBlbGVtZW50IG9mIHRoZSBzZXQgezEsIDJ9ICopXG57eCAqIHggOiB4IFxcaW4gezEsIDJ9fSJ9IHs6YmxvY2sucmVwbC9jb2RlICIoKiBDb25jYXQgbGlzdCAqKVxuPDwgMSA+PiBcXG8gPDwgMiwgMyA+PiJ9IHs6YmxvY2sucmVwbC9jb2RlICIoKiBUaGlzIHdpbGwgcmFpc2UgYW4gZXJyb3IsIHNlZSBzb2x1dGlvbiBhdCB0aGUgbmV4dCBibG9jayAqKVxuU29tZXRoaW5nID09IDJcbjEgKyBTb21ldGhpbmcifSB7OmJsb2NrLnJlcGwvY29kZSAiKCogRm9yIG11bHRpbGluZSBibG9ja3MsIHVzZSA0IC0gLSAtIC0gKilcblNvbWV0aGluZyA9PSAyXG4tLS0tXG4xICsgU29tZXRoaW5nIn1dfQ==</link>
            <guid isPermaLink="false">hacker-news-small-sites-24634705</guid>
            <pubDate>Wed, 30 Sep 2020 00:42:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Presentation on the noa voxel game engine, made and presented in-engine (2015)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24634564">thread link</a>) | @trynewideas
<br/>
September 29, 2020 | http://andyhall.github.io/noa-lt/ | <a href="https://web.archive.org/web/*/http://andyhall.github.io/noa-lt/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="slideBox">
      
      
      <div id="intro1">
        <p>Voxels in V8</p>
        <div><p>
          To start, click and allow pointer lock.
          </p><p>Slides thataway! → 
        </p></div>
        <p>Andy Hall
          <br>2015.7.16
        </p>
      </div>
      
      
      
      <div id="intro2">
        <p>
          Using this presentation:
        </p>
        <div>
          <p>
            move around:<br>
            invert mouse:<br>
            destroy block:<br>
            place block:<br> 
            pick block:<br> 
            camera zoom:<br> 
            jump:<br> 
            jet pack:<br>
            pause:
          </p>
          <p><code>WASD</code>, arrows
            <br> <code>I</code>
            <br> LMB, tap
            <br> <code>E</code>, RMB
            <br> <code>Q</code>, middle mouse
            <br> <code>F</code>, scroll
            <br> <code>space</code>
            <br> <code>R</code>
            <br> <code>P</code>
          </p>
        </div>
        <p>
          (mobile users: sorry lol)
        </p>
      </div>

      <div id="intro3">
        <p>
          About me:
        </p>
        <p><img src="http://andyhall.github.io/noa-lt/pics/profile.png"></p><p><span>
            @fenomas
          </span>
          <br> free gamedev, sometime technical evangelist
          <br> github/andyhall
          <br> aphall.com
        </p>
      </div>



      <div id="voxel1">
        <p>
          Voxels - definition
        </p>
        <div><p>
          tl;dr:
          </p><p>
            Ever seen Minecraft? 
            <br> Yeah those.
          </p>
        </div>
      </div>

      <div id="voxel2">
        <p>
          Voxels - proper definition
        </p>
        <p>
            Rasterized 3D data.
          </p>
        <p>
          Colloquially, if pixels represent
          the rasterization of 2D data,
          voxels are the 3D equivalent.
        </p>
        <p>
          (Hence "voxel": volumetric pixel)
        </p>
      </div>

      <div id="voxel3">
        <p><img src="http://andyhall.github.io/noa-lt/pics/sampling.png"></p><p>
          Conceptually, voxels are a <i>sampling</i> over some 3D space,
          just as pixels in a bitmap are samples of 
          some 2D data (vector graphics, photos, etc).
        </p>
        <p>
          (Note: click this block for the 
          <i>amazing</i> webGL demo <br>I stole that image from)
        </p>
        <!-- note to any semantic purists viewing source: -->
        <!-- Those <i> tags are just my way of saying "howdy!" <3 -->
      </div>

      <div id="voxel4">
        <p>
          Note: nothing (per se) to do with gaming!
        </p>
        <p><img src="http://andyhall.github.io/noa-lt/pics/ct_scan.jpg"></p><p>
          (CT scan data)
        </p>
      </div>




      <div id="game1">
        <p>
          Voxels and Gaming
        </p>
        <p><img src="http://andyhall.github.io/noa-lt/pics/Comanche_1992.png"></p><p>
          Comanche, 1992
        </p>
        <p>
          (Click: list of games with voxels)
        </p>
      </div>

      <div id="game2">
        <p>
          Voxel advantages
        </p>
        <p><img src="http://andyhall.github.io/noa-lt/pics/Shogi_Ban_Koma.jpg"></p><p>
          Provides game with easily grasped structure -
          <br>
          Equivalent to grids in 2D games
        </p>
      </div>

      <div id="game3">
        <p>
          Conceptually easy to work with
        </p>
        <div>
          <ul>
            <li>Technical tradeoffs (e.g. CPU vs memory) 
              largely similar to vectors/bitmaps</li>
            <li>Some hard things become easy 
              (raycasting, collision tests..)</li>
            <li>(Of course some easy things become hard..)</li>
          </ul>
        </div>
      </div>

      <div id="game4">
        <p>
          Voxel advantages
        </p>
        <p>
            Mutable worlds for free! (ish)
          </p>
        <p>
          (click: anywhere but here, yo)
        </p>
      </div>

      <div id="game5">
        <p>
          World-affecting game rules
        </p>
        <p><img src="http://andyhall.github.io/noa-lt/pics/Gospers_glider_gun.gif"></p><p>
          c.f. "Emergent gameplay"
        </p>
        <div>
          <p>
            Note:
          </p>
          <p><code>"3"</code> to place a Conway Block
            <br><code>"4"</code> to stop/start simulation
            <br><span>(click: explanation)</span>
          </p>
        </div>
      </div>

      <div id="game6">
        <p>
          Note: not just for rendering!
        </p>
        <p>
          Voxels are often useful behind the scenes 
          regardless of how a game looks
          (e.g. for physics simulation).
        </p>
        <p>
          Conceptually: 3D games should use voxels wherever 
          a 2D game would use a grid.
        </p>
      </div>




      <div id="render1">
        <p>
          Rendering Voxels
        </p>
        <p>
            GPUs do not grok voxels!
          </p>
        <p>
          In general a conversion step ("meshing")
          is necessary to convert voxels into 
          stuff that GPUs understand
          (vertex lists, normals, etc).
        </p>
        <p>
          Here are three approaches:
        </p>
      </div>

      <div id="render2">
        <p>
          Naive Meshing
        </p>
        <p><img src="http://andyhall.github.io/noa-lt/pics/doob.png"></p><p>
          (click: mrdoob's voxel demo)
        </p>
        <p>
          Create one cubic mesh per voxel
        </p>
        <p>
          Problems: poly counts, draw calls
        </p>
      </div>

      <div id="render3">
        <p>
          Culled Meshing
        </p>
        <p><img src="http://andyhall.github.io/noa-lt/pics/culled.png"></p><p>
          Merge voxels into one large mesh, 
          <br>omitting faces between adjacent voxels.
        </p>
        <p>
          Result: fewer draw calls, still a lot of polys
        </p>
      </div>

      <div id="render4">
        <p>
          "Greedy Meshing"
        </p>
        <p><img src="http://andyhall.github.io/noa-lt/pics/greedy.png"></p><p>
          Scan across voxel slices, merging faces of 
          adjacent voxels (of the same value).
        </p>
        <p>
          Credit: all-around genius 
          <span>Mikola Lysenko</span>
        </p>
        <p>
          (click: algo explanation + live demo)
        </p>
      </div>

      <div id="render5">
        <p>
          Chunking
        </p>
        <p><img src="http://andyhall.github.io/noa-lt/pics/chunk.png"></p><p>
          Necessary tradeoff for large worlds:
          <br> faster meshing, more draw calls.
        </p>
        <p>
          Minecraft chunks: 16x16x256 (divided vertically)
          <br>This demo: arbitrary (32x32x32 at the moment)
        </p>
      </div>

      <div id="render6">
        <p>
          Ambient Occlusion
        </p>
        <p><img src="http://andyhall.github.io/noa-lt/pics/ao.jpg"></p><p>
          Comparatively simple for voxels, 
          <br> and greatly improves visuals
        </p>
        <p><span>Click: toggle AO in this demo</span>
          <br>(then place a block to trigger meshing)
        </p>
      </div>

      <div id="render7">
        <p>
          Note: Voxels needn't be blocks!
        </p>
        <div>
          <div>
            <p><img src="http://andyhall.github.io/noa-lt/pics/voxel-quest.png">
            </p>
            <p>
              Voxel Quest
            </p>
            <p>
              (click: it's beautiful)
            </p>
          </div>
          <div>
            <p><img src="http://andyhall.github.io/noa-lt/pics/ct.jpg">
            </p>
            <p>
              CT scan data
            </p>
            <p>
              (google "marching squares")
            </p>
          </div>
        </div>
      </div>

      <div id="render8">
        <p>
          In fact...
        </p>
        <p><img src="http://andyhall.github.io/noa-lt/pics/crooked.png"></p>
      </div>



      <div id="world1">
        <p>
          World generation
        </p>
        <p>
          Driven deterministically by 
          noise (Perlin, simplex) and hashing.
        </p>
        <p>
          In this demo:
        </p>
        <p>
          2D noise: height map
          <br> 3D noise: clouds
          <br> Hashing: tree/flower placement
        </p>
        <p>
          (click: my homemade n-dimensional hash!)
        </p>
      </div>

      <div id="world2">
        <p>
          Other world algorithms
        </p>
        <p>
          Many voxel algos extend naturally from 
          2D cases (often heavily researched).
        </p>
        <div>
          <ul>
            <li>Collision tests: simple grid check</li>
            <li>Raycasting: equivalent to line rasterization (e.g. Bresenham)</li>
            <li>Physics: had to roll my own, but easier than 3D</li>
          </ul>
        </div>
      </div>




      <div id="noa1">
        <div><p>
          noa (this engine)
          </p><p>
           And how I built it
        </p></div>
      </div>

      <div id="noa2">
        <p>
          Dev stack:
        </p>
        <p><img src="http://andyhall.github.io/noa-lt/pics/browserify_with_hat.png"></p><p>
          node | npm | browserify | beefy
        </p>
        <p>
          (this slide is out of date, <br>I use webpack now..)
        </p>
      </div>

      <div id="noa3">
        <p>
          Why roll a new engine?
        </p>
        <p>
          I started trying to use 
          <span>voxel.js</span>
        </p>
        <p><img src="http://andyhall.github.io/noa-lt/pics/voxeljs.png"></p><div>
          <p>
            Pros:
            <br> Tons of great code
            <br> Extremely modular
          </p>
          <p>
            Cons:
            <br> Massively coupled
            <br> Dependency hell
            <br> Renders on bare metal
          </p>
        </div>
      </div>

      <div id="noa4">
        <p>
          noa's approach:
        </p>
        <div>
          <ul>
            <li>Reuse code from voxel.js where feasible 
              <br> (raycasting, meshing..)</li>
            <li>Otherwise written from scratch 
              <br> (physics, rendering, controls, AO..)</li>
            <li><span>Babylon.js for rendering (click)</span></li>
          </ul>
        </div>
      </div>

      <div id="noa5">
        <p>
          State of the project
        </p>
        <div>
          <ul>
            <li>Works(?), performant(?) </li>
            <li>No docs, all APIs in flux</li>
            <li><span>Features: see testbed app (click)</span></li>
            <li>Collaboration welcome, drop me a mail/issue/etc</li>
          </ul>
        </div>
      </div>



      <div id="thoughts1">
        <p>
          "Is [HTML/JS] really [ready/fast enough] for gaming yet?"
        </p>
        <p>
          My thoughts after 5 months:
        </p>
      </div>
      
      
      <div id="thoughts2">
        <p>
          Mainly depends on how broad your scope is
        </p>
        <div>
          <ul>
            <li>Targeting one version of one browser makes for an easy life ;)</li>
            <li>Modern JS is a solid dev platform, if you modularize responsibly</li>
            <li>The more you use the DOM, the more performance will vary across browsers</li>
            <li>Mobile: what's that? Does it taste good?</li>
          </ul>
        </div>
      </div>


      <div id="thoughts3">
        <p>
          Performance in V8
        </p>
        <div>
          <ul>
            <li>V8 is very fast, but temperamental</li>
            <li>Getting great performance is still ~50% black magic</li>
          </ul>
        </div>
      </div>


      <div id="thoughts4">
        <p>
          Key takeaway #1:
        </p>
        <div>
          <ul>
            <li>Don't waste time guessing what will perform well in V8 - it can't be done</li>
            <li>Master the dev tools instead</li>
            <li><strong>Profile</strong></li>
          </ul>
        </div>
      </div>

      <div id="thoughts5">
        <p>
          Key takeaway #2:
        </p>
        <div>
          <ul>
            <li><strong>Deopts</strong> murder performance!</li>
            <li>They can occur unpredictably, and for bizarre reasons.</li>
            <li>When all else fails: <br><code>chrome --js-flags = "--trace-deopt"</code></li>
          </ul>
        </div>
      </div>



      <div id="thanks">
        <p>
          Thanks!
        </p>
        <p>
          @fenomas
          <br>
          <span>github.com/andyhall</span>
        </p>
      </div>

      
      
      
      
      
    </div></div>]]>
            </description>
            <link>http://andyhall.github.io/noa-lt/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24634564</guid>
            <pubDate>Wed, 30 Sep 2020 00:17:30 GMT</pubDate>
        </item>
    </channel>
</rss>
