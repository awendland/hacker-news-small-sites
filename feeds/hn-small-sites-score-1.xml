<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Thu, 04 Feb 2021 20:28:58 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Thu, 04 Feb 2021 20:28:58 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[How to set up Kubernetes on Exoscale]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26012261">thread link</a>) | @anticristi
<br/>
February 3, 2021 | https://elastisys.com/elastisys-engineering-how-to-set-up-kubernetes-on-exoscale/ | <a href="https://web.archive.org/web/*/https://elastisys.com/elastisys-engineering-how-to-set-up-kubernetes-on-exoscale/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><div data-elementor-type="wp-post" data-elementor-id="9644" data-elementor-settings="[]"><div><div><section data-id="39453a45" data-element_type="section"><div><div><div data-id="28daaf9d" data-element_type="column"><div><div><div data-id="6259e7" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>In this Elastisys Engineering blog post, we show how to set up a production-ready Kubernetes cluster on Exoscale using kubespray and Terraform. It gets a control plane and a set of worker nodes, and leverages Rook and Ceph to get Persistent Volume support.</p><h2 id="why">Why install Kubernetes using kubespray?</h2><p>The reasons why one might want to install Kubernetes “manually” are many:</p><ul><li>Allows you to run Kubernetes on cloud providers even if they do not offer a managed Kubernetes service such as AKS, EKS, or GKE.</li><li>Not entangled with the cloud provider’s IAM or other services, which makes a multi-cloud strategy easier to implement in practice. This way, your tools and processes will not be cloud-vendor specific.</li><li>Allows full control over the control plane: if you want to install, e.g., an OpenID Connect provider such as Dex to integrate with your Identity Provider (IdP), you can. With a managed service, what you can or cannot do is at the mercy of your cloud provider.</li></ul><p>So let’s get to it!</p><h2 id="requirements">Requirements</h2><p>Our cluster setup is as following:</p><ul><li>One control plane node: 2GB RAM, 2 vCPU, 50GB local storage.</li><li>Three worker nodes: 8GB RAM, 4 vCPU, 100GB local storage each.</li></ul><p>All nodes are running Ubuntu 20.04 LTS. The cluster is running Kubernetes v1.19.7 and is installed using kubespray 2.15.0. You will also need Terraform to follow along with this guide.</p><h2 id="infrastructure">Infrastructure</h2><p>The first thing that is needed is to set up all the infrastructure needed for the cluster.</p><h3 id="terraform">Terraform</h3><p>The easiest way to deploy a production-ready Kubernetes cluster is to use the Terraform script from <a href="https://github.com/kubernetes-sigs/kubespray" target="_blank" rel="noopener">kubespray</a></p><p>Clone kubespray for the script. Exoscale support is on master right now.</p><pre><code>git clone https://github.com/kubernetes-sigs/kubespray.git
cd kubespray<br></code></pre><p>Create a new folder in the inventory folder for your cluster.</p><pre><code>CLUSTER=my-exoscale-cluster
cp -r inventory/sample inventory/$CLUSTER
cp contrib/terraform/exoscale/default.tfvars inventory/$CLUSTER/
cd inventory/$CLUSTER</code></pre><p>Edit <code>default.tfvars</code> and make sure that <code>ceph_partition_size</code> for all the workers is set to 50. <em>(To match the reference setup)</em></p><p>For authentication you can use a encrypted credentials file ~/.cloudstack.ini or ./cloudstack.ini. This file can be created by running:</p><pre><code>cat &lt;&lt; EOF &gt; cloudstack.ini
[cloudstack]
key = 
secret = 
EOF
sops --encrypt --in-place --pgp  cloudstack.ini
sops cloudstack.ini</code></pre><p>Insert your API key in <code>key</code> and API secret in <code>secret</code>. Follow the <a href="https://community.exoscale.com/documentation/iam/quick-start/" target="_blank" rel="noopener">Exoscale IAM Quick-start</a> to learn how to generate API keys.</p><p>To create the cluster, run the following and follow the instructions on the screen.</p><pre><code>terraform init ../../contrib/terraform/exoscale
sops exec-file -no-fifo cloudstack.ini 'CLOUDSTACK_CONFIG={} terraform apply -var-file default.tfvars ../../contrib/terraform/exoscale'</code></pre><p>You should now have a inventory file <code>inventory.ini</code> that you can use with kubespray. To test it and to make sure that all the nodes are properly up and running, run the following:</p><pre><code>ansible -i inventory.ini -m ping all</code></pre><h3 id="other-setup">Other setup</h3><p>If you are setting up the nodes by yourself, please keep in mind that Exoscale at the time of writing doesn’t have support for adding additional disks. Therefore you need to split the root disk into multiple partitions.</p><p>This can be achieved by making sure that your instance has more than 50GB of disk and that the following lines is added to your user-data before booting.</p><pre><code>#cloud-config
bootcmd:
- [ cloud-init-per, once, move-second-header, sgdisk, --move-second-header, /dev/vda ]
- [ cloud-init-per, once, create-ceph-part, parted, --script, /dev/vda, 'mkpart 2 50GB -1' ] # Create ceph partition spanning from 50GB from start to end</code></pre><p>More information about this can be found in this blog post, <a href="https://elastisys.com/elastisys-engineering-how-to-set-up-rook-with-ceph-on-kubernetes/" target="_blank" rel="noopener">Rook Ceph on Kubernetes</a>.</p><h3 id="kubespray">kubespray</h3><p>When the infrastructure is up and running, it’s time to add Kubernetes on top of all this. If you have followed the suggested way of spinning up the infrastructure, you should be able to run:</p><pre><code>ansible-playbook -i inventory.ini ../../cluster.yml -b -v</code></pre><p><em>NOTE: You might want to set the value <code>kubeconfig_localhost</code> in the file <code>group_vars/k8s-cluster/k8s-cluster.yml</code> to <code>true</code> to get the kubeconfig file. Just remember that it will use the private IP of the server, so update the server IP to match the IP of the control plane load balancer.</em></p><p>When Ansible is finished, verify that you have access to the Kubernetes cluster by running:</p><pre><code>kubectl get nodes</code></pre><h3 id="rook">Rook</h3><p>Install rook by installing the rook operator chart.</p><pre><code>helm repo add rook-release https://charts.rook.io/release
kubectl create namespace rook-ceph
helm upgrade --install --namespace rook-ceph rook-ceph rook-release/rook-ceph --version v1.5.5 --wait

# Need to use ceph v15.2.7 to be able to use partitions
# See https://github.com/rook/rook/issues/6849
curl -s https://raw.githubusercontent.com/rook/rook/d381196/cluster/examples/kubernetes/ceph/cluster.yaml | kubectl apply -n rook-ceph -f -
curl -s https://raw.githubusercontent.com/rook/rook/d381196/cluster/examples/kubernetes/ceph/csi/rbd/storageclass.yaml | kubectl apply -n rook-ceph -f -</code></pre><h2 id="summary">Summary</h2><p>In this article, we have shown how to set up a production-ready Kubernetes cluster on Exoscale using kubespray and Terraform, complete with Persistent Volume support via Rook and Ceph. These steps help you set up Kubernetes clusters on cloud environments where no managed service is available. Or if your use-case is such that you do not want to use one.<br></p><div data-elementor-type="wp-post" data-elementor-id="9541" data-elementor-settings="[]"><div><div><section data-id="d3f586e" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="8fa69b1" data-element_type="column"><div><div><div data-id="8fde8da" data-element_type="widget" data-widget_type="heading.default"><p><h2>Read more of our <b>engineering blog posts</b></h2></p></div><div data-id="2940dd4" data-element_type="widget" data-widget_type="text-editor.default"><div><p>This blog post is part of our engineering blog post series. Experience and expertise, straight from our engineering team. Always with a focus on technical, hands-on HOWTO content with copy-pasteable code or CLI commands.<br>Would you like to read more content like this? Click the button below and see the other blog posts in this series!</p></div></div></div></div></div></div></div></section></div></div></div> <br><div data-elementor-type="wp-post" data-elementor-id="8990" data-elementor-settings="[]"><div><div><section data-id="31e2d16" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="247a263" data-element_type="column"><div><div><div data-id="0b295df" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Want to keep up with the latest in cloud and Kubernetes?</p><p>Let us deliver it straight to your inbox!</p></div></div></div></div></div></div></div></div></section></div></div></div></div></div></div></div></div></div></div></div></section></div></div></div></div></div>]]>
            </description>
            <link>https://elastisys.com/elastisys-engineering-how-to-set-up-kubernetes-on-exoscale/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26012261</guid>
            <pubDate>Wed, 03 Feb 2021 10:11:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Embedded Covid mask detection on an Arm Cortex-M7 processor using PyTorch]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26012231">thread link</a>) | @isusmelj
<br/>
February 3, 2021 | https://lightly.ai/post/embedded-covid-mask-detection-on-an-arm-m7-using-pytorch | <a href="https://web.archive.org/web/*/https://lightly.ai/post/embedded-covid-mask-detection-on-an-arm-m7-using-pytorch">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p><strong>How we built a visual COVID-19 mask quality inspection prototype running on-device on an OpenMV-H7 board and the challenges on the way.</strong></p><p>‍</p><p>TLDR; The source code to train and deploy your own image classifier can be found here: <a href="https://github.com/ARM-software/EndpointAI/tree/master/ProofOfConcepts/Vision/OpenMvMaskDefaults" target="_blank">https://github.com/ARM-software/EndpointAI/tree/master/ProofOfConcepts/Vision/OpenMvMaskDefaults</a></p><p>‍</p><p>In the summer of 2020, we worked with Arm to build an easy-to-use tutorial on how to train and deploy an image classifier on an Arm microcontroller. In this post, we show how we approached and solved the following challenges:</p><ul role="list"><li>Convert a PyTorch ResNet to TensorFlow and quantize it to use 8-bit integer values</li><li>Collect, select, and annotate data of faulty and non-faulty masks</li><li>Use self-supervised pre-training to boost model performance when working on fewer images.</li></ul><p>‍</p><h3>The Results to Expect</h3><p>The goal of this project was to show an end-to-end workflow on how to train and deploy a convolutional neural network to an OpenMV-H7 board.</p><p>The video below showcases how our classifier detects faulty masks in real-time.</p><figure id="w-node-1e0674653ff8-e7e87989"><p><iframe allowfullscreen="true" frameborder="0" scrolling="no" src="https://www.youtube.com/embed/ba1c1JkBnNc"></iframe></p></figure><h3>The OpenMV-H7 Board</h3><p>The board consists of an <a href="https://www.st.com/en/microcontrollers/stm32h743vi.html" target="_blank">STM32H743VI</a> Arm Cortex-M7 processor running at 480MHz, multiple peripherals, and a camera module mounted on it.<br>The camera module has an <a href="http://www.ovt.com/products/sensor.php?id=80" target="_blank">OV7725</a> sensor from OmniVision and can record in VGA resolution (640x480) at 75 FPS.</p><p>Since the board has limited computing power and memory, we aimed for a very small deep learning model. We call the variant ResNet-9 since it’s more of a cut in half ResNet-18 variant. Below you can find some numbers about the model configuration, runtime, and other metrics.</p><ul role="list"><li><strong>Input size:</strong> 64x64x3 </li><li><strong>CPU Freq.:</strong> 480 MHz</li><li><strong>Operations:</strong> 33.4 MOp</li><li><strong>Model size: </strong>90 kBytes</li><li><strong>Inference Time: </strong>150 ms</li><li><strong>Operations/s</strong>: 249 MOp/s</li></ul><p>Detailed specs can be found on the official website of OpenMV <a href="https://openmv.io/products/openmv-cam-h7" target="_blank">here</a>.</p><figure id="w-node-54c1c743c46b-e7e87989"><p><img src="https://uploads-ssl.webflow.com/5f7ac1d59a6fc121dde87967/6006dd1b05a6ba9ae8de6dd0_1*tN005NiVE1kZbBK9BwCRmw.jpeg" alt=""></p><figcaption>A close-up picture of the OpenMV H7 Board we used.</figcaption></figure><h3>Data Collection</h3><p>Neural networks are very data-hungry. In order to efficiently collect enough training data we did the following:</p><ol role="list"><li>We used the camera on the OpenMV-H7 board to record video sequences. With the USB interface and the <a href="https://openmv.io/pages/download" target="_blank">OpenMV IDE</a>, we were able to easily record the camera stream and save it as a video file.</li><li>To simulate a real production line we mounted the camera on cardboard to make sure the camera is stable. The optics point to the production line which is a metal plate with tall borders. This setup ensures, that the camera sees defect and non-defect masks within the same environment.</li><li>Finally, we moved masks through our inspection line using a combination of push and pull.</li></ol><figure id="w-node-aeaf7ee059b3-e7e87989"><p><img src="https://uploads-ssl.webflow.com/5f7ac1d59a6fc121dde87967/6006dd1b93ae233273724258_1*fULWu10pKzaaYevH6g1wAw.jpeg" alt=""></p><figcaption>A picture of our data collection pipeline. We cut a small hole into the cardboard to clamp the USB table holding the board into it.</figcaption></figure><h3>Data Selection and Annotation</h3><p>At this stage we have multiple video files, each having captured a few minutes. The next challenge is to extract the frames and annotate the data. We use FFmpeg for the frame extraction and <a href="http://lightly.ai/" target="_blank">Lightly</a> to select a diverse set of frames. Note that we had more than 20k frames but no time to annotate all of them. Using <a href="http://lightly.ai/" target="_blank">Lightly</a> we selected a few hundred frames covering all relevant scenarios.<br><a href="http://lightly.ai/" target="_blank">Lightly</a> uses self-supervised learning to get good representations of the images. It then uses these representations to select the most interesting images which should be annotated. The benefit of this method is that we can access the pre-trained model and fine-tune it on only a handful of labeled images.</p><figure id="w-node-d0a8cad91e90-e7e87989"><p><img src="https://uploads-ssl.webflow.com/5f7ac1d59a6fc121dde87967/6006dd1bb94b015a4b0f3fab_1*PReJtvsyDDVwhWxQXDaI9w.jpeg" alt=""></p><figcaption>Example images taken with the OpenMV H7 camera showing the three labels for the data. From left to right: good mask, defect mask, no mask.</figcaption></figure><figure><p><img src="" alt=""></p></figure><p><strong>Model Fine-Tuning<br></strong>To prevent the model from overfitting, we simply froze the pre-trained backbone and added a linear classification head to the model. We then trained the classifier for 100 epochs on a total of 500 annotated images.</p><p>‍</p><h3>From PyTorch to Keras to TensorFlow Lite</h3><p>Moving the pre-trained PyTorch model to TensorFlow Lite turned out to be the most difficult part of our endeavor.</p><p>‍</p><p>We tried out several tricks with ONNX to export our model. A simple library called <a href="https://github.com/nerox8664/pytorch2keras" target="_blank">pytorch2keras</a> worked fine for a model only consisting of linear layers but not for our conv + linear model. </p><p>The main problem we encountered, was that PyTorch uses the CxHxW (channel, height, width) format for tensors whereas TensorFlow uses HxWxC. This meant that, after transforming our model to TensorFlow Lite, the output of the layer just before the classifier was permuted, and hence, the output of the classifier was incorrect. In order to address this problem, we considered manually permuting the weights of the linear classifier. </p><p>However, we decided to go for a simpler solution. We pooled the output of the last convolutional layer into a Cx1x1 shape. That way, changing the order of the channels does not affect the output of the neural network.</p><p>‍</p><p>The final step is to quantize and export the Keras model to TensorFlow Lite. In our case quantization reduces the model size and speeds up running the model in inference at the cost of a few percent lower accuracy.</p><p>Special thanks to our collaborators at Arm and <a href="https://medium.com/u/297b71d663f3" target="_blank">Philipp Wirth</a> from Lightly for making this project possible. The <a href="https://github.com/ARM-software/EndpointAI/tree/master/ProofOfConcepts/Vision/OpenMvMaskDefaults" target="_blank">full source code is available here</a>. You can easily train your own classifier and run it on an embedded device. Feel free to reach out or leave a comment if you have any questions!</p><p>‍</p><p>Igor, co-founder<br><a href="http://lightly.ai/" target="_blank">Lightly.ai</a></p><p>‍</p></div></div></div></div>]]>
            </description>
            <link>https://lightly.ai/post/embedded-covid-mask-detection-on-an-arm-m7-using-pytorch</link>
            <guid isPermaLink="false">hacker-news-small-sites-26012231</guid>
            <pubDate>Wed, 03 Feb 2021 10:07:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Leaked FSFE email reveals sexism, exploitation in diversity plan]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26012069">thread link</a>) | @fsfellowship
<br/>
February 3, 2021 | https://fsfellowship.eu/leaked-fsfe-diversity-strategy-contains-misogyny/ | <a href="https://web.archive.org/web/*/https://fsfellowship.eu/leaked-fsfe-diversity-strategy-contains-misogyny/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>As the fallout of the <a href="https://fsfellowship.eu/court-case-fsfe-women-and-volunteers-face-modern-day-slavery/">FSFE stalking scandal continues</a>, we are publishing below the leaked FSFE diversity strategy.</p>

<p>Here are the highlights we identified:</p>

<blockquote><em>For the FSFE front page we asked women to provide quotes with picture:
 This worked for <a href="https://duckduckgo.com/?t=ffab&amp;q=Amaelle+Guiton&amp;ia=web">Amaelle</a>. Other female contributors were also initially
 interested in providing a quote, but other constrains prevented them
 from doing so.</em></blockquote>

<p>What is the real reason women don't want their name and picture on the FSFE web site?</p>

<blockquote><em>At our events we encourage female speakers, as well as new speakers,
 and from different countries (e.g. LLW, but also at the summit).</em></blockquote>

<p>FSFE's biggest event is LLW but it is never advertised.  The registration process and the Call for Papers are hidden from the former Fellows and the Supporters.  Women will not participate in other Free Software events as long as the biggest events, like LLW, are hidden in the shadows.</p>

<blockquote><em>For internships we meanwhile give preference to women.</em></blockquote>

<p>Women employed as interns, men employed on permanent contracts.  As the recent court case demonstrates, all women on permanent contracts were <a href="https://fsfellowship.eu/court-case-fsfe-women-and-volunteers-face-modern-day-slavery/">sacked for talking about equality</a>.  What Matthias Kirschner describes is analogous to the <a href="https://en.wikipedia.org/wiki/Untermensch">Untermensch concept from the Third Reich</a>.  This isn't the first time <a href="https://fsfellowship.eu/matthias-kirschner-fsfe-nazi-comparisons/">we find Kirschner's conduct is close to that of the Third Reich</a>.</p>

<p><img width="33%" alt="Olga Gkotsopoulou, FSFE, open source, intern, internship, Vrije Universiteit Brussel, VUB, law" src="https://fsfellowship.eu/assets/girlie-hacking-grey-front-large.jpg"></p><blockquote><em>we also encourage female interns to stay active in the
 FSFE after their internships:
 <ul>
 <li>We hired Polina (<a href="https://fsfellowship.eu/assets/fsfe-llw-conflict-of-interest.pdf">resigned after FSFE/LLW Conflict of Interest scandal</a>) after her internship</li>
 <li><b>Nikos is currently talking with <a href="https://duckduckgo.com/?q=Olga+Gkotsopoulou+fsfe+women+scandal&amp;t=ffab&amp;ia=web">Olga</a> about her becoming the Greek
   deputy coordinator</b>.</li>
 <li>With <a href="https://duckduckgo.com/?t=ffab&amp;q=lucile+falgueyrac+fsfe&amp;ia=web">Lucile</a> we have regular contact and invite her to meetings (she
   has very little time).</li>
 <li>We work a lot with <a href="https://duckduckgo.com/?t=ffab&amp;q=Eszter+Bako+fsfe&amp;ia=web">Eszter</a>, who is now assistent of <a href="https://en.wikipedia.org/wiki/Julia_Reda">Julia Reda</a>, but
   it might be difficult to include her further at the moment.</li>
 <li><a href="https://duckduckgo.com/?t=ffab&amp;q=Lusy+Vaseva+fsfe">Lusy</a>
is at the moment organising a Free Software event and
   coordinating with Matthias.</li>
 </ul>
</em></blockquote>

<p>Why would <a href="https://duckduckgo.com/?q=Olga+Gkotsopoulou+fsfe+women+scandal&amp;t=ffab&amp;ia=web">Olga Gkotsopoulou</a>, a woman from Greece, want to continue working for Free after her paid German internship ends?  Why would a woman in Greece want to send money to a misogynist in Berlin?  What will this Greek money be used for, hiring more female interns in Kirschner's cramped little office?</p>

<p>Kirschner appears to be delusional about his obligation to pay people.  An internship is a contract that ensures the woman can never acquire maternity rights, the contract always finishes before they can become pregnant.  Women resent this.</p>

<blockquote><em>### In Progress

</em><ul><em>
</em><li><em> Finish and implement Code of Conduct:
<ul>
 <li>Continue with the CoC, implement it, also against some critism (Erik
   worked on it with Heiki, but as it should be valid for the whole
   organisation so we said it would be good that we do not have several
   CoCs in the FSFE but try to merge it with the LLW CoC).</li>
  <li>help our groups to enforce it with a training about that topic next
   year (for the LLW Polina worked on a detailed guide what to keep in
   mind about that)</li>
</ul>
</em></li></ul></blockquote>

<p>This was the only definite action from the strategy, another Code of Conduct.  The way Kirschner <a href="https://fsfellowship.eu/court-case-fsfe-women-and-volunteers-face-modern-day-slavery/">went to this woman's home</a> demonstrates the reality of the Code of Conduct: leaders of open source organizations see themselves as God, they can do whatever they want and only apply their "enforcement" venom to their political rivals.</p>

<p><img width="33%" alt="Olga Gkotsopoulou, FSFE, open source, intern, internship, Vrije Universiteit Brussel, VUB, law" src="https://fsfellowship.eu/assets/girlie-hacking-grey-back-large.jpg"></p><h3>The FSFE diversity strategy in full</h3>

<blockquote><em>
<p>Subject: Re: diversity and expanding the GA<br>
Date: Mon, 14 Aug 2017 10:51:58 +0000<br>
From: Matthias Kirschner <mk@fsfe.org><br>
To: ga@fsfeurope.org</mk@fsfe.org></p>

<p>Dear GA members,

</p><p>thank you all for raising your points in this thread. As Hugo pointed
out we repeatedly had that discussion, and also worked on some points.
Still there were some new ideas in the thread and from the Council we
suggest a few action items to make further progress. But first, so that
everybody is on the same page, some examples of existing activities on
that topic.,/p&gt;

</p><p>## Some examples of what we already do/did

</p><ul>
<li>When we have pictures on our website we try to have equal wo/man on
 them. For example have a look at
 https://fsfe.org/campaigns/ilovefs/whylovefs/gallery.en.html (this
 year we had some additions, before IIRC the ratio was better).</li>

<li>For the FSFE front page we asked women to provide quotes with picture:
 This worked for <a href="https://duckduckgo.com/?t=ffab&amp;q=Amaelle+Guiton&amp;ia=web">Amaelle</a>. Other female contributors were also initially
 interested in providing a quote, but other constrains prevented them
 from doing so.</li>
<li>At our events we encourage female speakers, as well as new speakers,
 and from different countries (e.g. LLW, but also at the summit).
 Although we have the same problem most conferences have, that is is
 really difficult to achieve that.</li>

<li>For the Legal Network council we started by picking the same ratio
 with men as with women.</li>

<li>For internships we meanwhile give preference to women. One reason is
 also because becoming intern is also increasing the chance to become
 an employment in the Free Software area.
 (https://fsfe.org/contribute/internship.en.html says "We want more
 women to be involved in Free Software. That's why we will give
 preference to applications from suitably qualified female
 candidates.")</li>

<li> As with males we also encourage female interns to stay active in the
 FSFE after their internships:
 <ul>
 <li>We hired Polina (<a href="https://fsfellowship.eu/assets/fsfe-llw-conflict-of-interest.pdf">resigned after FSFE/LLW Conflict of Interest scandal</a>) after her internship</li>
 <li>Nikos is currently talking with <a href="https://duckduckgo.com/?q=Olga+Gkotsopoulou+fsfe+women+scandal&amp;t=ffab&amp;ia=web">Olga</a> about her becoming the Greek
   deputy coordinator.</li>
 <li>With <a href="https://duckduckgo.com/?t=ffab&amp;q=lucile+falgueyrac+fsfe&amp;ia=web">Lucile</a> we have regular contact and invite her to meetings (she
   has very little time).</li>
 <li>We work a lot with <a href="https://duckduckgo.com/?t=ffab&amp;q=Eszter+Bako+fsfe&amp;ia=web">Eszter</a>, who is now assistent of <a href="https://en.wikipedia.org/wiki/Julia_Reda">Julia Reda</a>, but
   it might be difficult to include her further at the moment.</li>
 <li><a href="https://duckduckgo.com/?t=ffab&amp;q=Lusy+Vaseva+fsfe">Lusy</a>
is at the moment organising a Free Software event and
   coordinating with Matthias.</li>
 </ul></li>

<li>Staff was following-up with proposals from the past. For example
 Patrick Ohnewein before proposed Sonia Montegiove. Matthias had
 several talks with her and invited her to the FSFE summit. The problem
 is that she is quite shy when speaking English.</li>
<li>This year we had a
moderations workshop for our staff. Before it we
 clarified with the trainer that one of our goals is to enable our
 staff running more inclusive meetings. The workshop was documented in
 the wiki https://wiki.fsfe.org/Internal/Moderation (some permission
 problem at the moment, hope it is soon fixed).</li>
</ul>

<p>## Next Steps</p>

<p>### In Progress</p>

<ul>
<li> Finish and implement Code of Conduct:
 <ul>
 <li> Continue with the CoC, implement it, also against some critism (Erik
   worked on it with Heiki, but as it should be valid for the whole
   organisation so we said it would be good that we do not have several
   CoCs in the FSFE but try to merge it with the LLW CoC).</li>
 <li>help our groups to enforce it with a training about that topic next
   year (for the LLW Polina worked on a detailed guide what to keep in
   mind about that).</li>
  </ul>
</li>
</ul>

<p>### Possible actions</p>

<ul>
<li>Discussion with Ulrike about the topic. She studied gender studies and
 is very interested in the topic) about the topic. Together with her
 identify strategies for more diversity inside the FSFE community and
 the GA, by</li>
<ul>
<li>having a budget for counselling on diversity (as several
people
   pointed out, just because someone is a women in IT, does not know
   they know about diversity).</li>
<li> have a time budget for Ulrike to
help on this issue next year.</li>

<li> As some hesitate to just add women to the GA without first being
 involved in other areas, make it a priority to support already active
 or interested females (or other under represented groups).  * This
could include that we encourage them to join us in teams, and
   mentor them, or to invite them to events so we can meet them (could
   also include priority for travel funding in case we have to choose).
</li></ul>

<li>GA participation:
<ul><li>You might have realised that all our male
staffers are GA members,
   but none of our female staffers is. That is bad. We should encourage
   Polina and Ulrike to think about joining, too.</li>
 <li>Depending on the outcome of the FSFE2020 discussion: if we enlarge
   the council (as the FSFE board) introduce a quote there (as Daniel
   proposed to have a second VP position, with a requirement that at
   least one of the VP positions must not be male.)</li>
 <li>Depending on the Italian GA member's feedback, we could invite her
   as a guest to the next GA, or if they think it would be a good idea
   we can ask her to first become another coordinator for Italy as a
   first step.</li>
  </ul></li>

<li>https://fsfe.org/contribute/internship.en.html starts with a quote by
 a former male and female interns. But we should update one of the
 quotes by Erik or Hugo on that page with former quotes.</li>

<li>Make sure we have balanced quotes by women on our website / as well as
 the front page. E.g.
 https://fsfe.org/campaigns/ilovefs/whylovefs/whylovefs.en.html (either
 get more or think about removing this page for next years in the
 campaign)</li>
</ul>

<p>Best Regards,<br>
Matthias</p>
</em></blockquote>


  </div>

</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://fsfellowship.eu/leaked-fsfe-diversity-strategy-contains-misogyny/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26012069</guid>
            <pubDate>Wed, 03 Feb 2021 09:38:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing high performance F# code]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26012007">thread link</a>) | @pjmlp
<br/>
February 3, 2021 | https://bartoszsypytkowski.com/writing-high-performance-f-code/ | <a href="https://web.archive.org/web/*/https://bartoszsypytkowski.com/writing-high-performance-f-code/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

		<!-- .post-header -->


		<div>
			<!--kg-card-begin: markdown--><p>While this post is addressed to F# .NET developers, it introduces much wider concepts starting from hardware architecture to overall .NET runtime and JIT compiler optimizations. It shouldn't be a surprise - optimizing the application performance requires us to understand the relationships between our high level code and what actually happens on the hardware.</p>
<p>There's a popular opinion that F# code must be slower than equivalent C# code. This opinion is mostly false, however it comes with some rationale. Usually comparison doesn't use <strong>equivalent</strong> code in both languages, and F# is generally more high level and declarative in nature. "Idiomatic" F# code doesn't always play well with .NET virtual machine. Writing code that is high level, declarative and fast on .NET platform is not an easy task.</p>
<p>In the examples below we'll use some common tools that will help us get better insight into nature of F# code:</p>
<ul>
<li><a href="https://sharplab.io/">Sharplab</a> allows us to easily inspect generated JIT intermediate representation, assembly or even equivalent C# code (which sometimes is approximate, since not all IL idioms are representable in C#) for a given F# snippet. For assembly code usually some extra mangling with params may be necessary for code to be generated as SharpLab sometimes cannot introspect F# core lib code.</li>
<li><a href="https://github.com/SergeyTeplyakov/ObjectLayoutInspector">Object Layout Inspector</a> lets us see how structs and classes will actually be represented in memory.</li>
<li><a href="https://benchmarkdotnet.org/articles/overview.html">BenchmarkDotNet</a> is very popular library for writing micro benchmarks. We'll use it to show heap allocations and execution times of our code.</li>
</ul>
<p>A correct profiling of the executing application is crucial before starting any work on optimizing the code - there's no sense in shaving last possible CPU cycles out of the function that's executed for 0.1% of the time.</p>
<p>Keep in mind that for most day-to-day business applications, first way to solve performance problems is to reduce obvious mistakes (eg. replacing multiple I/O requests with one, writing more efficient database query etc.). If that was not the case, next step for satisfactory solution can be simply writing more imperative code - to make it easier to reason about for the compiler rather than human - or picking better-suited data structures. This is especially prevalent in F#, where we can observe pervasive usage of types like <code>'t list</code> (tip: if you're looking which collection to use and want good performance, F# list is almost never a good answer). Here we're about to go deeper, into area where we're about to compete with the prefabricated data types and algorithms.</p>
<h2 id="understandmemorylayoutofvaluetypes">Understand memory layout of value types</h2>
<p>One of the big performance gains, that .NET runtime uses to take advantage over other managed virtual machines (like JVM) in race for ultimate performance, often comes from using value types. So if we're about to go fast, we first need to understand how they work.</p>
<p>.NET structs represent types, which are not allocated separately on the managed memory heap, but rather inlined within the containing scope (instance of the class in case of fields, thread stack for variables, etc.). This means that usually they are cheaper and easier to access in high-allocation scenarios.</p>
<p><img src="https://bartoszsypytkowski.com/content/images/2021/02/class-vs-struct-layout.png" alt="class-vs-struct-layout"></p>
<p>Historically, F# code was not very promising, when it comes to utilizing value types. Nowadays we got things like struct tuples - <code>struct('a * 'b)</code> which unfortunately are not widely used in F# even though in practice they should be preferable choice when working with tuples - and <code>[&lt;Struct&gt;]</code> attribute, that can be used on records and discriminated unions (we'll return to them later), making use of them became much more feasible.</p>
<p>However this doesn't necessarily mean, that replacing all reference types with value types will make our code magically go faster. In fact, this may be quite opposite. Why? Imagine what happens when we want to pass a record as a parameter. How is it done? Usually passing object to a function happens by copying reference to that object, which is either 4B or 8B depending on our OS being x86 or x64, and therefore fits perfectly into standard CPU register.</p>
<pre><code>type A() =
  class
    [&lt;DefaultValue&gt;] val mutable x: int
    [&lt;DefaultValue&gt;] val mutable y: int
    [&lt;DefaultValue&gt;] val mutable z: int
  end

let print (value: 't) = System.Console.WriteLine(value.ToString())

let a = A() // sub rsp, 0x28
            // mov rcx, 0x7ff91b23d1a8
            // call 0x00007ff9730aade0 ; allocate A on the heap
print a     // mov rdx, rax            ; copy reference to a to the stack
            // mov rcx, 0x7ff91b23d5f8
            // call _.print[[System.__Canon, System.Private.CoreLib]](System.__Canon)
</code></pre>
<p>Now what if we're using structs? For reference types we copy object's reference on the stack - since reference is just a single address, it always can fit into register and be done within a single operation. For value types, we copy entire value instead. If they don't fit into register, we'll have to copy them over in multiple steps.</p>
<pre><code>type B =
  struct
    [&lt;DefaultValue&gt;] val mutable x: int
    [&lt;DefaultValue&gt;] val mutable y: int
    [&lt;DefaultValue&gt;] val mutable z: int
  end

let b = B() // sub rsp, 0x38
            // xor eax, eax       ; zero field b.x
            // xor ecx, ecx       ; zero field b.y
            // xor edx, edx       ; zero field b.z
print b     // lea r8, [rsp+0x28]
            // mov [r8], ecx      ; copy field b.x to the stack
            // mov [r8+4], eax    ; copy field b.y to the stack
            // mov [r8+8], edx    ; copy field b.z to the stack
            // lea rcx, [rsp+0x28]
            // call _.print[[_+B, _]](B)
</code></pre>
<p>Each of these steps is a machine instruction that takes time to execute. However, sometimes .NET can optimize that - pointer-sized registers are not only ones available in modern machines. We also have a special purpose SIMD (Single Instruction Multiple Data) ones, that are much bigger and can be used as long as passed data fits into them perfectly.</p>
<pre><code>type C =
  struct
    [&lt;DefaultValue&gt;] val mutable x: int
    [&lt;DefaultValue&gt;] val mutable y: int
    [&lt;DefaultValue&gt;] val mutable z: int
    [&lt;DefaultValue&gt;] val mutable zz: int
  end
  
let c = C() // sub rsp, 0x48
            // xor eax, eax             ; zero register
            // mov [rsp+0x38], rax      ; init fields b.x and b.y together with zero'ed register
            // mov [rsp+0x40], rax      ; init fields b.z and b.zz together with zero'ed register
print c     // vmovupd xmm0, [rsp+0x38] ; copy all 4 fields together on the stack using SIMD registers
            // vmovupd [rsp+0x28], xmm0
            // lea rcx, [rsp+0x28]
            // call _.print[[_+C, _]](C)
</code></pre>
<p>Another thing available in .NET, that allows us addressing inefficiencies of passing structs as arguments are so called by-ref parameters. There are 3 types of these, marked using <code>'t inref</code>, <code>'t outref</code>  and <code>'t byref</code>:</p>
<pre><code>let print(value: 't inref) = ...
let c = C()
print &amp;c // lea rcx, [rsp+0x28] ; copy address of the struct head onto the stack
         // call _.print[[_+C, _]](C ByRef)
</code></pre>
<p>Please, don't confuse by-ref parameters with <code>ref</code> data type:</p>
<ul>
<li><code>'a ref</code> is actually an alias for <code>Ref&lt;'a&gt;</code> class, therefore allocated on the heap and passed by reference. In general, using this class in F# very rarely has sense (outside of writing exemplar, idiomatic code).</li>
<li><code>'a byref</code> is equivalent to C# <code>ref</code> parameter tag - it means that we're passing reference (memory address) to an object or struct. It expects it to be initialized and can be used to change the contents of the underlying value. For this reason F# requires fields and variables passed as <code>byref</code> to be declared with <code>mutable</code> keyword.</li>
<li><code>'a outref</code> is equivalent to C# <code>out</code> parameter tag - it always must be initialized by the end of the function body. This may sound a bit tricky as F# doesn't put that requirement explicitly. If we didn't make that assignment in any of the code branches, F# compiler will simply initialize it for us with default value (just like using <code>Unchecked.defaultof&lt;_&gt;</code>), which sometimes may lead to null reference exceptions.</li>
<li><code>'a inref</code> is the youngest of these and is equivalent of C# <code>in</code> parameter - while in C# structs passed as arguments for that parameters don't have to be tagged,  F# will always require to mark passing by ref (using <code>&amp;</code> prefix for passed argument) for any parameter marked with <code>byref</code>/<code>inref</code>/<code>outref</code>. <code>inref</code> is basically an optimization technique for what we saw above - it allows us to pass struct into a function using only its memory address, without copying entire struct contents. Additionally <code>inref</code> says that parameter is treated as read only, so it cannot be modified inside of function body. .NET JIT can utilize this information in some cases to reduce number of safety checks, therefore reducing number of instructions to be executed.</li>
</ul>
<p>While using by-ref parameters is usually good idea when it comes to writing code targeting complex value types, there are several limitations to it.</p>
<p>One is that arguments passed using by-ref params cannot be captured by closures/lambdas/anonymous functions, which prevents them from being used in more abstract code:</p>
<pre><code>// WRONG!
let doSomething (a: int inref) =
  [1..10]
  |&gt; List.map (fun x -&gt; x + a) // `a` is captured by closure, which is compilation error
  
// RIGHT
let doSomething (a: int inref) =
  let mutable result = []
  for x=10 downto 1 do
    result &lt;- (x + a)::result
  result
</code></pre>
<p>This includes problems even for common inlined functions like eg. pipe operator <code>|&gt;</code>. That's the price, we have to pay for speed (at least for now).</p>
<p>Second issue is that, at the moment by-ref parameters cannot be involved in building nested functions (regardless if they capture the values from function in outer scope or not). This again makes very inconvenient to use them in cases like tail recursive loop pattern:</p>
<pre><code>// WRONG!
let doSomething (a: 'a) =
  let rec loop n (x: 'a inref) = // this nested function won't compile
    if n = 0 then ()
    else loop (n-1) &amp;x
  loop 100 &amp;a

// RIGHT
let rec loop n (x: 'a inref) =
  if n = 0 then ()
  else loop (n-1) &amp;x
  
let doSomething (a: …</code></pre></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bartoszsypytkowski.com/writing-high-performance-f-code/">https://bartoszsypytkowski.com/writing-high-performance-f-code/</a></em></p>]]>
            </description>
            <link>https://bartoszsypytkowski.com/writing-high-performance-f-code/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26012007</guid>
            <pubDate>Wed, 03 Feb 2021 09:29:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mastodon is crumbling – and it will only get worse]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 29 (<a href="https://news.ycombinator.com/item?id=26011818">thread link</a>) | @todsacerdoti
<br/>
February 3, 2021 | https://sporks.space/2021/02/02/mastodon-really-is-crumbling-and-it-will-only-get-worse/ | <a href="https://web.archive.org/web/*/https://sporks.space/2021/02/02/mastodon-really-is-crumbling-and-it-will-only-get-worse/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-297">
	<!-- .entry-header -->

	
		<div>
			
<p>I am 100% serious with the title, despite the appearance of click-bait. Mastodon has a serious structural rot that is only worsening as time gets on. I think this is for a few reasons which I will outline below.</p>



<p>Ironically, I don’t feel safe posting this directly to the fediverse because of the very forces I’m about to describe. I’m not worried about the cancel crew, I just don’t want to deal with hostile interactions right now. I might link to this post but it’s less likely to get hate mail I suspect if I do it that way rather than write this all up in a giant thread on fedi.</p>



<p>What I am presenting is largely anecdotal opinion, although it has been gathered from countless others (I’m not going to name any names, they deserve better than harassment or people trying to change their views and in the process merely reinforcing them).</p>



<h2>Background on myself</h2>



<p>I’ve been on Mastodon since April 2017. I was on “fedi” (well, the ostatus fediverse) before that, on long-gone instances I forgot the name of. I was on Mastodon in the very early days of its development, when content warnings were brand new, blocking/silencing was seriously broken, and fedi was just getting exciting due to press coverage. Before this, I was on IRC since 2005 and an IRC operator on a small network (it’s not glamorous, trust me).</p>



<h2>The problem</h2>



<p>Fedi has a problem as the title says: it’s crumbling. It’s a lot less vibrant than when I joined up, even back when GNUSocial roamed the earth (it was a pile of shit trying to imitate Twitter and mostly filled with people banned from Twitter for GamerGate and going too far, even for Twitter’s lax standards of the day).</p>



<p>It actually baffles me why so much of the Mastodon userbase can be traced back to the Tumblr/Twitter leftist crowd, when Fedi’s beginnings were on a network largely consisting of ultra-right people thrown off Twitter. I can only speculate, but I suspect the main reasons are they believed they would be safer (which is a joke), and many themselves (or their friends at least) were banned from those platforms for similarly shitty behaviour.</p>



<p>But it’s a mistake to believe that Fedi is safer at all. In fact, in many ways, it’s worse.</p>



<h3>Fedi is the least safe place around</h3>



<p>The thing about Fedi is that due to its nature, it has a low bar to entry. Anyone can make an instance at any time for not a whole lot of money. There are tons of far-right instances littering the place, and few admins can truly keep up (the worst-kept secret amongst Mastodon admins I would say). Most of the userbase just blocks them on an ad-hoc basis and moves on (or doesn’t notice them), but the fact that the Nazis haven’t really taken over the place is only by their mere incompetence.</p>



<p>To illustrate the problem, I will tell you about this: the largest instance on the Fediverse.</p>



<p>Oh, no, not mastodon.social. They’re big, but not as big as the largest. The largest is Pawoo, with around a million users last I checked. It’s owned by Pixiv, a Japanese company (think Japanese DeviantArt). And if Fedi knew even a rudimentary level of Japanese (this would require widespread non-Western cultural awareness they do not possess), they wouldn’t have joined in the first place. Japanese nationalism is everywhere on Pawoo, and the admins largely don’t care (granted: I don’t pay much attention to it and filtered it a long time ago, this may not be the case any longer). There is a certain irony I love about the largest Fedi instance being a commercial entity, despite the English speakers of the Fediverse largely eschewing corporations and brands. They also allow loli and (fictional) artwork of children, which is not banned in Japan but is a grey area in the US as advised by legal counsel for IF (I personally don’t want to test it, if you want to, have fun, leave me out of it).</p>



<p>Pawoo mostly sits there, under the radar, because they don’t speak English, and many instances blocked them a long time ago (I remember the great Pawoo discourse of 2017). There are tons and tons of other instances that most people don’t even know about that spew things that are far worse.  We at mst3k actually have <a href="https://mst3k.interlinked.me/about/more" target="_blank" rel="noreferrer noopener">a pretty big list</a>, and it ain’t even close to how many are actually out there. I just block them as I see them. Granted, many of those instances are long-gone, but there are many more to replace them.</p>



<h3>The faux-woke crowd is making fedi less safe</h3>



<p>I know this one is going to get me flamed and called racist or whatever the fuck, but so be it.</p>



<p>Now, full disclosure: I am partially Romani, Native American, but mostly (and certainly culturally raised) white, but <a href="https://weirder.earth/@WeirderAdmin/105640549522292568" target="_blank" rel="noreferrer noopener">I’ve listened to what other PoC have to say on this matter.</a></p>



<p>Fedi has a really bad problem: race-based trolling. There is a huge contingent on Fedi that is taking advantage of white guilt to troll the ever-loving fuck out of people.</p>



<p>I know this sounds like an amusing thing and is very much a “so what, they’re white” moment.  But I assure you, it’s anything but funny, and it’s causing minorities to be shed from Fedi.</p>



<p>Let me give a specific example: in mid-2020, a Jewish non-binary person was harassed by a member of one of the instances that host many of these trolls. People were still reluctant to do the right thing and block the instance, because they didn’t want to be called racist. The thing is, you can be a minority and still be a fucking dickhead, and you can also still be racist (without even realising it!) and act in bigoted ways against other minorities (go look up the Cherokee freedmen controversy for a really, really, really bad look into how far this can go). But nothing about your skin colour or ethnicity says “I can troll whoever I want.” Anyone who tells you otherwise is a troll and you should block and report them. If their admin won’t do anything, remove them.</p>



<p>The thing is, these kinds of games cheapen real racial justice. These people are less interested in racial justice for all and more interested in getting a rise out of people. And people are too afraid to stand up to it. This is a cancer silently driving people back to Twitter. I don’t think it’s the only thing stacked against Fedi, but it’s a huge one.</p>



<h3>The cancel crowd</h3>



<p>I’m going to say it: the canceldon crowd are obnoxious. They’re a holdover from Twitter and Tumblr. I won’t go into the whole “why cancelling is a waste of time” thing, but suffice it to say: cancelling doesn’t really fucking work, and it’s just a nice way of saying “doing what 4chan does to people it hates, but poorly.” Which is to say, harassment and trolling people. And of course people think it’s okay, even when they fuck up and sometimes cancel the wrong person or have bad info or got led on (this is never discussed, of course, and there is never an apology).</p>



<p>These people are literally making Fedi inherently less safe for everyone, and are no better than the crowd that used to be on Fedi (and still are to an extent) before Gargron decided to co-opt the Fediverse for his own gain.</p>



<h3>The people who write the software are fucking dickheads</h3>



<p>I’m going to be honest with you: Gargron (the guy who makes Mastodon) is an asshole. His reputation precedes him, so I won’t go into detail. However, I found out from a former IRL friend of mine (who will remain nameless) that he once asked her if he could continue to refer to her by her dead name. Said friend referred to Gargron as a “shitty liberal,” and I do not mean in the US sense.</p>



<p>The people at Pleroma are not much better. I mean, Alex Gleeson, enough said.</p>



<p>The only two relevant pieces of Fedi software are Pleroma and Mastodon. ActivityPub is such a horrible protocol, and Mastodon has butchered it so much, it’s impossible to make an interoperable implementation without man-months of work. To reimplement Mastodon from the ground up would be a nightmare. And forking Mastodon sounds great, but you’re up against a huge pile of technical debt. You could fork Pleroma, but then you’d have to know Elixir (a language few people know).</p>



<p>Also, the last time a major fork happened in Mastodon (aside from Glitch), it was mostly a group of non-developers who hoped they could cult their way into a dev team. It didn’t work.</p>



<p>I wanted to fix this problem but I decided it wasn’t worth it, and you’d have to be up against a community who is watching your every mistake and will find a reason to pillory you if you fuck up.</p>



<h3>“Mastodon” never developed a culture of its own</h3>



<p>You know, if you leave a container of yoghurt out for 4 years, it develops a culture. That’s more than can be said for the Mastodon part of Fedi, which has never outgrown being an offshoot of Twitter and Tumblr.</p>



<p>This is to its detriment, as it’s not a compelling place on the surface. People come in waves, and most leave again when Twitter and Tumblr rights its wrongs. I’ve seen this happen multiple times.</p>



<p>Mastodon users would do well to stop treating Fedi as Twitter, but of course, Mastodon and Pleroma as platforms basically both treat Fedi as Twitter expanded universe. It’s no coincidence <a href="https://techcrunch.com/2021/01/15/twitters-vision-of-decentralization-could-also-be-the-far-rights-internet-endgame/" target="_blank" rel="noreferrer noopener">Gargron has joined Twitter’s federation initative.</a> I have no hopes Fedi will develop a meaningful distinct culture before its too late.</p>



<h3>The tools to protect users are rotten fruit in an opaque bag</h3>



<p><em>Note: this was edited in after the fact. I meant to include it in the original.</em></p>



<p>I’m going to say what many admins lack the bravery or vision to say: the tools to protect the users of Mastodon are inadequate. Pleroma got this better, but many Mastodon users cancel any Pleroma user on sight (as I explain below).</p>



<p>The filtering sucks (it displays “filtered” unless you choose to permanently delete any posts containing a keyword). The default guide for setting up ElasticSearch (the thing that enables search) had (may still have for all I know) no mention of using a firewall or listening only on localhost (Gargron pushed back on requests to mention this), which would enable anyone in theory to connect to …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sporks.space/2021/02/02/mastodon-really-is-crumbling-and-it-will-only-get-worse/">https://sporks.space/2021/02/02/mastodon-really-is-crumbling-and-it-will-only-get-worse/</a></em></p>]]>
            </description>
            <link>https://sporks.space/2021/02/02/mastodon-really-is-crumbling-and-it-will-only-get-worse/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26011818</guid>
            <pubDate>Wed, 03 Feb 2021 08:47:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Evidence that brain iron in normal range is associated with Alzheimer's disease]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26011779">thread link</a>) | @JPLeRouzic
<br/>
February 3, 2021 | https://padiracinnovation.org/News/2021/02/evidence-from-a-post-mortem-cohort-that-brain-iron-within-normal-range-is-associated-with-alzheimers-disease | <a href="https://web.archive.org/web/*/https://padiracinnovation.org/News/2021/02/evidence-from-a-post-mortem-cohort-that-brain-iron-within-normal-range-is-associated-with-alzheimers-disease">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span typeof="v:Breadcrumb"><a property="v:title" rel="v:url" href="https://padiracinnovation.org/News/">Home</a></span> » <span typeof="v:Breadcrumb"><a property="v:title" rel="v:url" href="https://padiracinnovation.org/News/category/english">English</a></span> » Evidence from a post-mortem cohort that brain iron within normal range is associated with Alzheimer's disease</p><section itemprop="blogPost" itemscope="itemscope" itemtype="http://schema.org/BlogPosting">
    <div>
        <div>    
               
            <div>
                                                                                <div>
                    						
					                    <p>
                        <span itemprop="datePublished">03 February 2021</span> - Posted in 
                        <span itemprop="articleSection"><a href="https://padiracinnovation.org/News/category/english">English</a></span> by 
                        
                    </p>
                </div>
                <div itemprop="articleBody">                                   
                    <p>Brain iron dyshomeostasis with iron accumulation is a known feature of brain aging. 
The cause of this iron accumulation is aging is unknown, but the immune system is less active in older people, and as viruses replicate more efficiently in iron-rich senescent cells, they may have developed the ability to induce this phenotype in aging host tissues.</p>

<p>It <a href="https://pubmed.ncbi.nlm.nih.gov/33220280/">has been proposed several times</a> that metal dyshomeostasis could be an underlying mechanism responsible for the initiation and progression of the pathological changes associated with neurodegenerative disorders, including the motor and extra-motor symptoms of ALS.</p>

<p>A <a href="https://pubmed.ncbi.nlm.nih.gov/33491917/">new paper proposes</a> an update of the iron hypothesis of Alzheimer's disease (Alzheimer's disease), based on large scale emerging evidence.</p>

<p>Iron featured historically early in Alzheimer's disease research efforts for its involvement in the amyloid and tau proteinopathies, yet iron neurochemistry remains peripheral in mainstream Alzheimer's disease research.</p>

<p>Much of the effort investigating iron in Alzheimer's disease has focused on the potential for iron to provoke the onset of disease, by promoting proteinopathy through increased protein expression, phosphorylation, and aggregation.</p>

<p>The authors provide new evidence from a large post mortem cohort that brain iron levels within the normal range are associated with accelerated ante mortem disease progression in cases with underlying proteinopathic neuropathology.</p>

<p>These results corroborate recent findings that argue for an additional downstream role for iron as an effector of neurodegeneration, acting independently of tau or amyloid pathologies.</p>

<p>The researchers hypothesize that the level of tissue iron is a trait that dictates the probability of neurodegeneration in Alzheimer's disease by ferroptosis.</p>

<p>Ferroptosis is a type of programmed cell death dependent on iron and characterized by the accumulation of lipid peroxides, and is genetically and biochemically distinct from other forms of regulated cell death such as apoptosis.</p>

<p>Ferroptosis is initiated by the failure of the glutathione-dependent antioxidant defenses, resulting in unchecked lipid peroxidation and eventual cell death. Lipophilic antioxidants and iron chelators can prevent ferroptotic cell death.</p>

<p>A substantial body of <a href="https://pubmed.ncbi.nlm.nih.gov/33513737/">preclinical evidence and early clinical data</a> has demonstrated that deferoxamine and other iron chelators have strong disease-modifying impacts in Alzheimer's disease, Parkinson's disease, ischemic stroke. Acting by the disease-nonspecific pathway of iron chelation, deferoxamine targets each of these complex diseases via multifactorial mechanisms.</p>

<p>Deferiprone another iron chelator <a href="https://clinicaltrials.gov/ct2/results?cond=Amyotrophic%20Lateral%20Sclerosis&amp;term=chelator&amp;cntry=&amp;state=&amp;city=&amp;dist=&amp;Search=Search">is tested in clinical trials against ALS</a> in France’s Lille CHU hospital.</p>

<h3><u>Advertisement</u></h3>

<p><a href="https://www.amazon.com/dp/1698147899">
<img src="https://images-na.ssl-images-amazon.com/images/I/51pNZDKvmIL._SX331_BO1,204,203,200_.jpg" width="200">
<br>
This book retraces the main achievements of ALS research over the last 30 years, presents the drugs under clinical trial, as well as ongoing research on future treatments likely to be able stop the disease in a few years and to provide a complete cure in a decade or two.<br>
</a></p>
                </div><!--//desc-->
                
                
                                                                                    
                            </div><!--//item-->                       
        </div><!--//content-->  
    </div><!--//section-inner-->                 
</section></div>]]>
            </description>
            <link>https://padiracinnovation.org/News/2021/02/evidence-from-a-post-mortem-cohort-that-brain-iron-within-normal-range-is-associated-with-alzheimers-disease</link>
            <guid isPermaLink="false">hacker-news-small-sites-26011779</guid>
            <pubDate>Wed, 03 Feb 2021 08:40:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apache Kafka Meets Table Football]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26011650">thread link</a>) | @gaetancollaud
<br/>
February 3, 2021 | https://www.confluent.io/blog/using-kafka-ksqldb-quarkus-for-real-time-sports-tracking/ | <a href="https://web.archive.org/web/*/https://www.confluent.io/blog/using-kafka-ksqldb-quarkus-for-real-time-sports-tracking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="___gatsby"><div tabindex="-1" id="gatsby-focus-wrapper"><div><section><div><p><time datetime="2021-01-29T16:36:02.000Z">January 29, 2021</time></p><div><div data-swiftype-name="body" data-swiftype-type="text"><p>What happens when you let engineers go wild building an application to track the score of a table football game? This blog post shares SPOUD’s story of engineering a simple application with Apache Kafka<sup>®</sup>, ksqlDB, and Red Hat’s Quarkus. Spoiler alert: It was a blast!</p>
<h2 id="introduction"><a id="introduction"></a>Introduction</h2>
<p>We are SPOUD, a small company based in Bern, the capital of Switzerland. We’re specialised in event-driven architectures, real-time decision-making, and streaming technologies, especially Kafka. Similar to other startups with spare office space, we created a small playground in the office to play table football. Being the geeks we are, we always find ways to make simple things look fancy, which is why we created “Töggelomat” (in Swiss German, “töggele” means “table football”), an application that keeps track of game scores and matches players according to their skills. Unfortunately, due to COVID-19, we don’t play as much as we used to.</p>
<h2 id="goal"><a id="goal"></a>Goal</h2>
<p>We initially decided to make Töggelomat a reality at last year’s SPOUD hackathon. As stated earlier, we use Kafka a lot and have expertise in running clusters, connecting to data with Kafka Connect, and using AI together with stream processing. However, we hadn’t gotten the chance to really use <a href="https://ksqldb.io/" target="_blank" rel="noopener noreferrer">ksqlDB</a>, and we wanted to try it out with Quarkus.</p>
<h2 id="play"><a id="play"></a>Let’s play</h2>
<p>As we now dive deep into the technical details behind building Töggelomat, you can look at our <a href="https://github.com/spoud/toeggelomat" target="_blank" rel="noopener noreferrer">GitHub project </a>for the source code. Note: the ksqlDB queries are very interesting.</p>
<p>First, we needed to think in terms of events versus static databases because everything is an event. Using the <a href="https://martinfowler.com/eaaDev/EventSourcing.html" target="_blank" rel="noopener noreferrer">event sourcing technique</a>, we created a topic with a list of current employees.</p>
<p>Then, using ksqlDB queries, we created players with a starting score of 500 points.</p>
<pre>INSERT INTO toeggelomat_player
      SELECT 
            uuid,
            nickName, 
            email,
            500 as defensePoints,
            500 as offensePoints
       FROM employee;
</pre>
<p>With the query above, the <code>toeggelomat_player</code> compacted topic is filled every time a new employee is added to the topic <code>employee</code>.</p>
<p>To generate a new match, the Töggelomat application reads the last state from the <code>toeggelomat_player</code> topic and <a href="https://github.com/spoud/toeggelomat/blob/master/backend/src/main/java/io/spoud/services/MatchRandomizeService.java" target="_blank" rel="noopener noreferrer">randomizes a fair match</a>. Once the players are chosen, the application generates a new match and displays it in the front end. When the match is done, the score is entered in the UI and the application publishes the topic <code>toeggelomat_match_result</code>. The topic is visible in SPOUD’s data platform product, <a href="http://agoora.com/" target="_blank" rel="noopener noreferrer">Agoora</a>, and displays the description of the topic, the inferred schema, and the profile with some example data. Feel free to register and try it out for yourself.</p>
<p>After a match result, we need to compute the score, which is based on the skills of the players. If two higher-ranked players win against two lower-ranked players, they will not earn a lot of points. In reverse, if the lower-ranked players win, they will be generously rewarded. The point computation is done <a href="https://github.com/spoud/toeggelomat/blob/55ec5dc879169333f147b0f24f12dc183ce11042/backend/src/main/java/io/spoud/services/MatchPointsService.java#L55-L71" target="_blank" rel="noopener noreferrer">in the application</a>, and the score is published on the topic <code>toeggelomat_scores</code>.</p>
<p>With ksqlDB, we create four entries (one for each player) in the topic <code>toeggelomat_point_change</code> based on the score published in the topic <code>toeggelomat_scores</code>. The point changes are then applied to the topic <code>toeggelomat_player</code>, to close the loop.<img src="https://cdn.confluent.io/wp-content/uploads/to%CC%88ggelomat-process.png" alt="Töggelomat process" width="701" height="447" srcset="https://cdn.confluent.io/wp-content/uploads/to%CC%88ggelomat-process.png 1999w, https://cdn.confluent.io/wp-content/uploads/to%CC%88ggelomat-process-300x191.png 300w, https://cdn.confluent.io/wp-content/uploads/to%CC%88ggelomat-process-1024x653.png 1024w, https://cdn.confluent.io/wp-content/uploads/to%CC%88ggelomat-process-768x489.png 768w, https://cdn.confluent.io/wp-content/uploads/to%CC%88ggelomat-process-1536x979.png 1536w, https://cdn.confluent.io/wp-content/uploads/to%CC%88ggelomat-process-350x223.png 350w, https://cdn.confluent.io/wp-content/uploads/to%CC%88ggelomat-process-600x382.png 600w" sizes="(max-width: 701px) 100vw, 701px">In summary:</p>
<ul>
<li>Employees are converted to Töggelomat players</li>
<li>At the end of a match, the result is written</li>
<li>Scores are calculated from the result</li>
<li>Match scores produce point changes for each player</li>
<li>Point changes are applied to the players</li>
</ul>
<h2 id="result"><a id="result"></a>Result</h2>
<p>After two hackathon days and a few beers, the results looked like this, with the main page of the application showing the rank of each player:<br>
<img src="https://cdn.confluent.io/wp-content/uploads/scoreboard.png" alt="Scoreboard" width="859" height="455" srcset="https://cdn.confluent.io/wp-content/uploads/scoreboard.png 1999w, https://cdn.confluent.io/wp-content/uploads/scoreboard-300x159.png 300w, https://cdn.confluent.io/wp-content/uploads/scoreboard-1024x543.png 1024w, https://cdn.confluent.io/wp-content/uploads/scoreboard-768x407.png 768w, https://cdn.confluent.io/wp-content/uploads/scoreboard-1536x814.png 1536w, https://cdn.confluent.io/wp-content/uploads/scoreboard-350x186.png 350w, https://cdn.confluent.io/wp-content/uploads/scoreboard-600x318.png 600w" sizes="(max-width: 859px) 100vw, 859px"><br>
Then players are selected and a random match is generated.<br>
<img src="https://cdn.confluent.io/wp-content/uploads/random-match.png" alt="Random match" width="843" height="636" srcset="https://cdn.confluent.io/wp-content/uploads/random-match.png 1802w, https://cdn.confluent.io/wp-content/uploads/random-match-300x226.png 300w, https://cdn.confluent.io/wp-content/uploads/random-match-1024x772.png 1024w, https://cdn.confluent.io/wp-content/uploads/random-match-768x579.png 768w, https://cdn.confluent.io/wp-content/uploads/random-match-1536x1158.png 1536w, https://cdn.confluent.io/wp-content/uploads/random-match-348x262.png 348w, https://cdn.confluent.io/wp-content/uploads/random-match-600x452.png 600w" sizes="(max-width: 843px) 100vw, 843px"><br>
We expose the data as an “offer,” similar to what we call them in <a href="https://agoora.com/" target="_blank" rel="noopener noreferrer">Agoora</a>. The offer has a description as well as the data schema and profile. The profile is useful to data scientists who want to look more closely at the data.<br>
<img src="https://cdn.confluent.io/wp-content/uploads/match-result-profile.png" alt="Match result profile" width="852" height="543" srcset="https://cdn.confluent.io/wp-content/uploads/match-result-profile.png 1999w, https://cdn.confluent.io/wp-content/uploads/match-result-profile-300x191.png 300w, https://cdn.confluent.io/wp-content/uploads/match-result-profile-1024x653.png 1024w, https://cdn.confluent.io/wp-content/uploads/match-result-profile-768x489.png 768w, https://cdn.confluent.io/wp-content/uploads/match-result-profile-1536x979.png 1536w, https://cdn.confluent.io/wp-content/uploads/match-result-profile-350x223.png 350w, https://cdn.confluent.io/wp-content/uploads/match-result-profile-600x382.png 600w" sizes="(max-width: 852px) 100vw, 852px"></p>
<h2 id="conclusion"><a id="conclusion"></a>Conclusion</h2>
<p>It’s honestly overkill to use so many topics for such a small use case, but the main point was to learn something, and we did! First of all, Quarkus is awesome and could really be the next Spring Boot. It’s a perfect match for Kafka and the cloud in general. Its reactive nature really helps when writing an event-driven application. Plus, its startup time and low memory footprint are better than that of a standard Java application.</p>
<p>Ever since the hackathon, SPOUD has been integrating Quarkus more and more. KsqlDB is also really great and easy to use. It gives you the sense of a database management system (DBMS), but you are in fact working with event streams.</p>
<p>At the same time, you can even join streams! Isn’t that awesome? Think about all the possibilities! Yet, our use case also highlighted some pain points. For example, there is a loop, the match score is dependent on the player’s ranking, and the ranking is also influenced by the score. In a DBMS, you have a defined state at any moment, and all changes in the state are ensured by transactions. Although this makes ensuring consistency easier, events give you the flexibility to scale. For this particular use case, there is at most one match every five minutes, so the loop has the time to complete before the next match. With time-sensitive use cases, you want to avoid loops as much as possible.</p>
<p>The use case presented in this blog post used <a href="http://confluent.io/confluent-cloud">Confluent Cloud</a>, which was inexpensive since there wasn’t a lot of data.</p>
<table>
<tbody>
<tr>
<td>ℹ️</td>
<td><a href="https://www.confluent.io/confluent-cloud">Sign up for Confluent Cloud</a> and get $200 off usage each month for your first three months. In addition, you can use the promo code <strong>CL60BLOG</strong> for an additional $60 of free Confluent Cloud usage.<a href="https://www.confluent.io/confluent-cloud-promo-disclaimer/">*</a></td>
</tr>
</tbody>
</table>
<p>Confluent also allows you to leverage ksqlDB as a service, although in our case the lowest instance available was bigger than what we were looking for. And because an SLA wasn’t essential for our use case, we decided to run our own ksqlDB server based on the documentation and using the Docker image from Confluent.</p>
<h2 id="next"><a id="next"></a>What’s next?</h2>
<p>Now that this project works we can think of what’s next? Here are some additional ideas that we could implement based on the modularity of dedicated topics:</p>
<ul>
<li>Real-time game information (e.g., a dashboard on a screen)</li>
<li>Slack integration</li>
<li>Achievements</li>
</ul>
<p>For more information about Töggelomat, <a href="https://www.confluent.io/resources/kafka-summit-2020/improve-the-quality-of-breaks-with-kafka/">check out our Kafka Summit 2020 talk</a>.</p>
<p><a href="https://www.confluent.io/resources/kafka-summit-2020/improve-the-quality-of-breaks-with-kafka/" rel="noopener noreferrer">Watch Now</a></p>
<div>

<p>Gaétan Collaud works as a senior full-stack developer at SPOUD. Throughout his professional career, he has been working as a software engineer and developer mainly at startups, but he also has experience at large organizations like state departments and insurance companies. He is the co-owner of an IoT company specialized in ultra-low power devices using the LoRa network. Gaétan is passionate about cloud-based projects and is a real explorer—he loves to try out new technologies and stay abreast of the latest and greatest technological developments.</p>
</div>
</div></div></div></section><section><div><h2>Did you like this blog post? Share it now</h2></div></section><section><p>Subscribe to the Confluent blog</p></section><section><h2>More Articles Like This</h2><div><div><h3><a rel=" noreferrer" href="https://www.confluent.io/blog/best-kafka-tools-that-boost-developer-productivity/">Helpful Tools for Apache Kafka Developers</a></h3><p>Apache Kafka® is at the core of a large ecosystem that includes powerful components, such as Kafka Connect and Kafka Streams. This ecosystem also includes many tools and utilities that</p></div><div><h3><a rel=" noreferrer" href="https://www.confluent.io/blog/how-zendesk-secures-kafka-with-mtls-authentication-system/">Implementing mTLS and Securing Apache Kafka at Zendesk</a></h3><p>At Zendesk, Apache Kafka® is one of our foundational services for distributing events among different internal systems. We have pods, which can be thought of as isolated cloud environments where</p></div><div><h3><a rel=" noreferrer" href="https://www.confluent.io/blog/ksqldb-0-14-0-features-updates/">Announcing ksqlDB 0.14.0</a></h3><p>We’re pleased to announce ksqlDB 0.14, one of our most significant releases of the year. This version includes expanded query support over materialized views, incremental schema alteration, variable substitution, additional</p></div></div></section></div></div></div></div>]]>
            </description>
            <link>https://www.confluent.io/blog/using-kafka-ksqldb-quarkus-for-real-time-sports-tracking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26011650</guid>
            <pubDate>Wed, 03 Feb 2021 08:14:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: An Index for Data Sets on Ethereum]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26011569">thread link</a>) | @timdaub
<br/>
February 2, 2021 | https://timdaub.github.io/2020/12/11/rugpullindex/ | <a href="https://web.archive.org/web/*/https://timdaub.github.io/2020/12/11/rugpullindex/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <h2 id="tldr">TL;DR</h2>
<p><strong>TL;DR:</strong> I built a financial index that <strong>rates data sets</strong> by their markets' performance (<strong>liquidity</strong> and <strong>equality of liquidity shares</strong>). <strong>Check out the <a target="_blank" rel="noopener" href="https://rugpullindex.com/">website</a></strong> and the minimalistic <a target="_blank" rel="noopener" href="https://rugpullindex.com/changelog.txt">blog</a>, or keep on reading the article.</p>
<p><img src="https://timdaub.github.io/assets/images/rugpullindex.png" alt="A screenshot of the
rugpullindex.com website"></p>
<h2 id="why-building-a-data-set-index">Why Building a Data Set Index?</h2>
<p><strong>Would you pay a stranger on the internet</strong> to buy a data set they're offering without knowing them or ever having seen the data? Tough decision! But that's precisely the type of situation <a target="_blank" rel="noopener" href="https://oceanprotocol.com/">Ocean Protocol</a> users face in its newly-launched decentralized <a target="_blank" rel="noopener" href="https://market.oceanprotocol.com/">data set market</a> [3].</p>
<p>I'll spare you most of the details of how it all works and say this: 2020's most transforming technology has been <strong>on-chain markets</strong>. In particular, the implementation that <a target="_blank" rel="noopener" href="https://uniswap.org/">uniswap.org</a> is using called <strong>automated market makers</strong>.</p>
<p>Simply put, they work by incentivizing users to <em>pool</em> a pair of assets at a ratio they deem as the assets' current prices. These users, I herein call them <strong>liquidity providers</strong>, e.g., pool 1 ETH and 540 USDC, so that when a buyer of either asset comes along, they can immediately trade 1 ETH for 540 USDC or 540 USDC for 1 ETH. This principle works fantastically at scale, as the pool incentivizes liquidity-providing by charging buyers and sellers a small fee, which is distributed by the pool to each liquidity provider, respectively [1].</p>
<p><img src="https://timdaub.github.io/assets/images/marketmakers.png"></p>
<p>This model has been so successful that there've been days where decentralized trading on Uniswap outperformed volumes on Coinbase! Which, of course, has lots of implications on the cryptocurrency space. I think it's no overstatement to say that automated market makers may be <strong>the killer app for crypto</strong>.</p>

<p>But there's one implication I've been particularly keen on exploring: all <strong>the openly-accessible data produced by on-chain markets</strong>. See, if you ever tried building a trading bot, you'll have noticed the terrible resolution publicly-available market data has. You might have also noticed that it's quite difficult even to find data at all. It's not by accident. <strong>Trading data is valuable</strong>.</p>
<h2 id="rating-a-data-set-by-its-markets-performance">Rating a Data Set by its Market's Performance</h2>
<p>Remember when I asked you at the beginning of this article about <strong>buying a data set from a random stranger on the internet?</strong> Well, it turns out that Ocean Protocol is now betting on the same technology that made Uniswap successful. They allow users to publish a data set, along with a fungible <strong>data token</strong> and an integrated <strong>automated market maker</strong>. Meaning, you can now buy access to a data set by purchasing tokens. These tokens get priced by liquidity providers providing a ratio of OCEAN Tokens to <em>data tokens</em>.</p>
<p>However, just because data sets are now available for sale on the market, doesn't mean you know they're valuable! After all, if ebay.com didn't have a rating system for sellers, how would you know which seller to trust?</p>
<p>On ebay.com, you know which seller to trust because you can see how many articles they've sold and what each buyer's experience was. It's a simple identity-based rating system.</p>
<p>But within the anarchistic world of cryptocurrencies, there are no working identity-based rating systems! Instead, the space is filled with <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Sock_puppet_account">sock puppets</a> and <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Sybil_attack">sybils</a>. <strong>Then, without buying a data set first, how are we supposed to know if a data set is valuable or an outright scam?</strong></p>
<h2 id="introducing-rugpullindex.com">Introducing rugpullindex.com</h2>
<p>That's where <a target="_blank" rel="noopener" href="https://rugpullindex.com/">rugpullindex.com</a> comes into play. <strong>We crawl all of Ocean Protocol's data token pools daily</strong> and rate each market's liquidity provider distribution by its equality using the <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Gini_coefficient">Gini coefficient</a>. While ranking markets based on their liquidity is common industry-practice, calculating a Gini score for each market's liquidity provider shares isn't. The idea behind this is that the more liquidity providers with an equal share back an asset in the market, the less likely it is for a "rug pull" attack to happen (details <a target="_blank" rel="noopener" href="https://github.com/oceanprotocol/multi-repo-issue/issues/30#issuecomment-726132174">here</a>). By factoring in a pool's relative liquidity, it allows us to derive a score <span><span><math><semantics><mrow><mi>s</mi></mrow><annotation encoding="application/x-tex">s</annotation></semantics></math></span></span> that is <span><span><math><semantics><mrow><mn>0</mn><mo>&lt;</mo><mi>s</mi><mo>&lt;</mo><mn>100</mn></mrow><annotation encoding="application/x-tex">0 &lt; s &lt; 100</annotation></semantics></math></span></span>.</p>
<p>For users of <a target="_blank" rel="noopener" href="https://rugpullindex.com/">rugpullindex.com</a>, this <strong>yields a few attractive benefits</strong>:</p>
<ol type="1">
<li>They can now choose to adjust their data set investments based on market data.</li>
<li>They can decide to invest in data sets relative to their performance on to <em>increase their diversivication and hence lower their exposure risk</em>. And finally;</li>
<li>If they're unsure about <strong>sending a random stranger on the internet money for a data set</strong>, they can check out the data set's market performance to make an informed decision.</li>
</ol>
<p>It's a widely-known fact that index-based investment yields superior results compared to stock picking [2]. The same is true when <em>investing</em> in data, which makes me excited about working on this project.</p>
<h2 id="what-does-the-future-hold">What Does The Future Hold?</h2>
<p>I have many ideas for <a target="_blank" rel="noopener" href="https://rugpullindex.com/">rugpullindex.com</a> and not as much time as I'd like to have. However, my overarching goal is to make the ranking so reliable that I can build a smart contract-based index fund on top of it.</p>
<p>I think that rating assets based on their markets' performance is valuable occupation in itself. Not only within the data set market but beyond. I'm particularly interested in rating a wide range of on-chain asset markets, but I'm also thinking about rating more on-chain intellectual property markets. I'm eager to crawl more data and explore. Until then, I hope you're having fun using <a target="_blank" rel="noopener" href="https://rugpullindex.com/">rugpullindex.com</a>.</p>
<p><em><strong>If you have questions, feedback, or business inquiries, please contact me: tim@daubenschuetz.de</strong>. If you want to follow along by building journey, <strong>please subscribe to my newsletter at the end of the page!</strong></em></p>
<h2 id="references">References</h2>
<ul>
<li>1: <a target="_blank" rel="noopener" href="https://ethresear.ch/t/improving-front-running-resistance-of-x-y-k-market-makers/1281">Ethresearch: Improving front running resistance of x*y=k market makers</a></li>
<li>2: KAHNEMAN, Daniel. Thinking, fast and slow. Macmillan, 2011.</li>
<li>3: <a target="_blank" rel="noopener" href="https://blog.oceanprotocol.com/oceans-on-ethereum-mainnet-ba9be1aee0ce">Ocean’s on Ethereum Mainnet</a></li>
</ul>

  </div></div>]]>
            </description>
            <link>https://timdaub.github.io/2020/12/11/rugpullindex/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26011569</guid>
            <pubDate>Wed, 03 Feb 2021 07:58:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Time tracking with plain text files]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26011522">thread link</a>) | @ingve
<br/>
February 2, 2021 | https://www.jotaen.net/9zRPA/klog-time-tracking-plain-textfiles/ | <a href="https://web.archive.org/web/*/https://www.jotaen.net/9zRPA/klog-time-tracking-plain-textfiles/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <main>
      

      <p>One topic that kept me thinking on and off for a couple of years now is time tracking. That is for very practical reasons, as I was (and still am) interested to keep track of my working hours. Back in the day, when I used to work full-time, I wanted to know how well on track I was with the 40&nbsp;hours that I agreed to devote to my employer. Nowadays, as a freelancer, I need to log my working hours for bookkeeping reasons, as my invoices are based on an hourly rate.</p>

<p>There exist countless web services for time tracking, some of which offering an impressive feature set that cater for all imaginable use-cases. However, I never felt too much appeal to use them. It’s not that I have any special requirements or practice an extravagant workflow. My reluctance is instead stemming from a conceptual thought: keeping track of times is a rather mundane and simple thing to do, so why rely on (semi-) commercial online services that build on complex technology stacks for something that you can basically do with a pencil and a piece of paper?</p>

<p>What did the trick somewhat well for me throughout the years was a spreadsheet that I setup and maintained by hand. It allowed me to enter data quickly and I could also run some simple evaluations, e.g. in order to aggregate the entries by week or month. While this solution was both simple and flexible, it also felt a bit cumbersome, especially for things like writing more sophisticated formulas or configuring pivot tables. As luck would have it I am in the fortunate position of being able to build my own tools. But before we get to this I need to share another thing with you first.</p>

<p>The longer I have been working with computers the more I appreciate the freedom and simplicity of plain text files: not being bound to proprietary software for opening or editing them; not being exposed to the risk that your data gets sold to advertising companies; no lock-in on arbitrary subscription plans; no connectivity issues that would prevent or slow down access. Instead, the data is just there, it’s all yours and you can rest assured that you will be able to work with it for decades to come. Viewing or manipulating the files can be done with any off-the-shelf text editor, and syncing them across multiple devices is as easy as putting them into your Dropbox folder. While plain-text formats don’t work for each and every application obviously, they seem to be a more than reasonable choice for this task here.</p>

<p>Born out of this conception I experimented with different formats to record time tracking data using plain text files. Over the past weeks I tried out various structures to model and layout the information. What I came up with is a lightweight format with minimal syntax that I called “klog”. The idea is to record the data in a similar style as you would using a physical notebook: it’s basically the date, then time-related entries such as a time range or duration of how long something took, and maybe a short note about what you did.</p>

<p><img src="https://www.jotaen.net/posts/2021-01-31-klog/demo.gif" alt="A terminal window demonstrating the file format and the command line tool usage"></p>

<p>I implemented a parser for the klog file format along with a small command line tool that allows to evaluate the data programatically. You find the project <a href="https://github.com/jotaen/klog">on Github</a>, where you can also download the binary in order to experiment with klog. If you happen to be interested in this idea I’d appreciate some feedback and learn about your use-cases – drop me an <a href="https://www.jotaen.net/mail">email</a> or open an issue on Github. klog obviously fits <em>my</em> needs, but I aimed for making it general-purpose enough so that other people may find it useful too.</p>

<p>Building klog was not just a fun programming exercise, I also ran into some interesting questions along the way: is it necessary to support timezones? Is it okay to restrict time values to hours and minutes, but to omit the seconds part for convenience? What if someone starts an activity close to midnight and finishes it on the next day, like working a night shift? Which of the numerous date and time notations need to be understood? How can you start tracking something that’s not yet finished and therefore doesn’t have an end time? I wrote a brief guide (that you find in the repository) that gives a tour of klog and also covers these questions.</p>

<p>The command line tool is fairly minimalistic for now, as I first and foremostly want to validate that my basic idea sustains before investing more work into it. The cli tool has read-only functionality so far and can basically pretty-print, filter and evaluate files. I attributed special attention to error handling, so in case there are formatting errors you should see precise and (hopefully) helpful error messages. The application is written in Go, which ensures that it runs cross-platform without relying on runtime dependencies, and – as a bonus – it’s also quite fast even on large data sets.</p>

<p>And as for the name, “klog” is what we call a “Kofferwort” in German: since my original use-case was tracking work times it is a blend of the two terms “work” and “log”.</p>

    </main>
  </div></div>]]>
            </description>
            <link>https://www.jotaen.net/9zRPA/klog-time-tracking-plain-textfiles/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26011522</guid>
            <pubDate>Wed, 03 Feb 2021 07:48:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Exploiting the Nespresso smart cards for fun and (profit) coffee]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26011464">thread link</a>) | @giuliomagnifico
<br/>
February 2, 2021 | https://pollevanhoof.be/nuggets/smart_cards/nespresso | <a href="https://web.archive.org/web/*/https://pollevanhoof.be/nuggets/smart_cards/nespresso">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span><span><a href="https://pollevanhoof.be/privacy">Privacy Policy</a> </span><span>| </span><span><br></span><span>Copyright © 2021</span><span> - </span><span><br></span><span>Design by <a href="https://pollevanhoof.be/">Polle Vanhoof</a></span></span></p></div></div>]]>
            </description>
            <link>https://pollevanhoof.be/nuggets/smart_cards/nespresso</link>
            <guid isPermaLink="false">hacker-news-small-sites-26011464</guid>
            <pubDate>Wed, 03 Feb 2021 07:37:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Private messengers: what can they see?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26011449">thread link</a>) | @aiNohY6g
<br/>
February 2, 2021 | https://our.status.im/private-messengers-what-can-they-really-see/ | <a href="https://web.archive.org/web/*/https://our.status.im/private-messengers-what-can-they-really-see/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
                <div>
                    <div>
                        <div>
                            <p>This article aims to provide a fair and thorough comparison of the current private messaging apps in terms of their privacy, security, and anonymity†. However, it must be abundantly clear that this post is written by Status (one of the above messengers). We strongly encourage you to verify our sources, do your own due diligence, and correct us if we are wrong.</p><p><em>†For the purposes of simplicity for the average reader, anonymity will be defined as a complete dissociation of one's chat identity and their true identity.</em></p><h2 id="signal"><strong>Signal</strong><br></h2><h3 id="what-can-signal-servers-see">What can Signal servers see?</h3><p>Not much. Your messages, attachments, calls, sender metadata, group chats and group metadata are all end-to-end encrypted. However, Signal (and Amazon) can infer who talks to who with a fair degree of accuracy by analyzing the network traffic. Signal is the only entity that runs the Signal servers, and <a href="https://signal.org/blog/looking-back-on-the-front/">they host all such servers on Amazon Web Services</a>. Here is a simple breakdown of what the network traffic could look like if Alice (1.1.1.1) sent a message to Bob (2.2.2.2):</p><p><strong>08:23:02</strong> — IP Address 1.1.1.1 sends 512 bytes to Signal's server.</p><p><strong>08:23:04</strong> — IP Address 2.2.2.2 receives 512 bytes from Signal's server.</p><p>This is what Jeff Bezos can see. Now, this, on its own, doesn't necessarily mean that Alice is talking to Bob. It could just be a coincidence — Bob happened to receive a different and entirely unrelated packet two seconds after Alice sent one of equal size.</p><p>However, if this coincidence were to happen, ten, twenty or a hundred times, with packets of equal sizes going back and forth from Alice and Bob, it would soon become apparent that these two IP addresses are likely talking to each other. At this point, one simply has to ask the respective Internet Service Provider (such as Comcast or AT&amp;T) who is behind a given IP address to uncover their legal identity.</p><p>So basically, Jeff Bezos can know who you talk to on Signal with a fair degree of accuracy via traffic analysis. This can be done even without Signal's cooperation, as Amazon has direct access to all incoming and outgoing traffic on the centralized Signal servers. In fact, Moxie Marlinspike, the creator of Signal, <a href="https://youtu.be/Nj3YFprqAr8?t=2034">acknowledged this flaw in the Q&amp;A session</a> of his 36C3 talk "The ecosystem is moving."</p><p>If Signal were to cooperate in such traffic analysis attacks, it would become much easier, as Signal does have access to the recipient metadata (<a href="https://signal.org/blog/sealed-sender/">but not sender metadata</a>). In other words, they can see who the envelope is addressed to, but not who it came from. This, in addition to the traffic analysis, would allow Signal to infer nearly all the sender/recipient metadata, in addition to some of the group metadata.</p><h3 id="is-signal-anonymous">Is Signal anonymous?</h3><p>No. You are required to provide your phone number — which, in many parts of the world, is synonymous with providing your government-issued ID. In addition, Signal will leak your IP address to your contacts that call you by default (you can change this in the settings by enabling the option "Always Relay Calls"). Signal also has the technical capability of associating your IP address and your Signal account (<a href="https://signal.org/bigbrother/">but they probably don't do this</a>). This means that even a burner number isn't enough for total anonymity if you assume the Signal servers are malicious or compromised.<br></p><p>It is worth noting that Signal has never claimed to be an anonymous tool. These points do not detract from the fact that they do care about your privacy — they are simply approaching it in a different manner.</p><h3 id="is-signal-easy-to-shut-down">Is Signal easy to shut down?</h3><p>If you don't have any faith in the US government, the answer is yes. If you do, the answer is probably not. Signal is the sole operator of the Signal servers, and they are based in the United States. There is no federation, and there is no peer-to-peer architecture. If Signal is legally compelled to shut down their servers, that's it. All forms of communication through Signal would immediately halt. However, the likelihood of such an event is debatable, and will be left to the reader.</p><p>It would be very difficult to quickly move Signal to a different jurisdiction, as they have thus far operated under the assumption that the US will not ban them. Moxie Marlinspike lives in the US, as does the overwhelming majority of Signal's employees, and their only two legal entities <a href="https://signal.org/legal/">were incorporated in the US</a>. In addition, given the centralized nature of their server architecture, Signal themselves could shut down Signal (this may seem obvious, but certain decentralized architectures prevent even the creator of something from shutting it down, such as Bitcoin).</p><hr><h2 id="telegram"><strong>Telegram</strong><br></h2><h3 id="what-can-telegram-servers-see">What can Telegram servers see?</h3><p>Basically everything. They can see <a href="https://www.howtogeek.com/710344/psa-telegram-chats-arent-end-to-end-encrypted-by-default/">every message you've ever sent in a group chat</a>, most of your 1:1 conversations (not secret chats), all your contacts, your profile picture and your bio. They know who you talk to, and at what time (even if it's a secret chat!). They know the members, name, and icon of every single group (including private ones) .</p><p>This may sound completely contrary to what Telegram says. The reason is that Telegram fundamentally operates on a different trust model. They assume that you trust Telegram, but not the government.</p><p>Telegram splits up their encryption keys and stores the separate pieces in several different jurisdictions. In theory, this means that all of the jurisdictions used by Telegram would have to cooperate in order to obtain any user data. They claim this has allowed them to <a href="https://telegram.org/faq#q-do-you-process-data-requests">not release a single byte of user data</a>. These claims, by their very nature, are unverifiable, and require that you trust Telegram. If that's good enough for you, use Telegram.</p><h3 id="is-telegram-anonymous">Is Telegram anonymous?</h3><p>Kinda. If you trust Telegram, then Telegram can be anonymous, as you are given the option hide your phone number and use a username of your choice. If you don't trust Telegram, it is not anonymous in any way, as they will have your phone number and <a href="https://telegram.org/privacy#5-2-safety-and-security">they can see your IP address</a>.</p><h3 id="is-telegram-easy-to-shut-down">Is Telegram easy to shut down?</h3><p>Probably not. Telegram intentionally set up its legal structure to be agile and resistant to overreaching governments. If Dubai (<a href="https://telegram.org/privacy#8-2-telegrams-group-companies">their current jurisdiction</a>) bans them, they would likely move to another. Dubai is a flag of convenience for Telegram. However, given the centralized nature of their server architecture, Telegram themselves could shut down Telegram.</p><hr><h2 id="whatsapp"><strong>WhatsApp</strong><br></h2><h3 id="what-can-whatsapp-servers-see">What can WhatsApp servers see?</h3><p>All the metadata, but none of the content. They can see your profile picture, who you talk to, and when. They can see who is a member of a given private group, the group icon, the group name, and which members are the administrators of said group. But your messages, pictures, attachments, status updates and calls are all end-to-end encrypted.</p><p>However, it is very important to note that the end-to-end encryption of WhatsApp messages has been repeatedly compromised through <a href="https://www.ghacks.net/2018/09/04/whatsapp-backups-android/">unencrypted Google or iCloud backups</a>. Although these backups are technically optionally, they are repeatedly suggested to the user with a coercive user interface. Even if you do not enable these backups, there is a good chance your conversation partner did, which compromises the integrity of the end-to-end encryption for both of you.</p><h3 id="is-whatsapp-anonymous">Is WhatsApp anonymous?</h3><p>No. You are required to provide your phone number — which, in many parts of the world, is synonymous with providing your government-issued ID. In addition, WhatsApp <a href="https://www.whatsapp.com/legal/updates/privacy-policy/?lang=en">logs your IP address</a> and directly associates it with your chat identity.</p><h3 id="is-whatsapp-easy-to-shut-down">Is WhatsApp easy to shut down?</h3><p>Not really, given the scale of Facebook and the nature of public corporations. However, it is very likely that WhatsApp could be forced to include a backdoor into their clients. There would be no way around this, as the clients are all proprietary. With all other messaging apps in this list, one could simply download the code prior to the backdoor, build it, and run that version of the client which still correctly encrypts the messages. Decentralized messaging architectures such as Status or Matrix would be even more resilient against such coercion, as there would be no central servers to shut down.</p><hr><h2 id="matrix"><strong>Matrix</strong><br></h2><h3 id="what-can-federated-matrix-servers-see">What can federated Matrix servers see?</h3><p>All the metadata, but none of the content. They can see your profile picture, your private room aliases, your device names, who you talk to, and when. They can see who is a member of a given private room, the room icon, the room name, and which members are the administrators of said room. They can see who talks and when in private rooms. But your messages, pictures and files are all end-to-end encrypted by default.</p><p>Although some homeserver implementations have <a href="https://github.com/matrix-org/synapse/issues/4565#issuecomment-540320761">stopped storing this metadata by default</a>, all homeservers still have the technical ability to access it. Some of these metadata issues may be resolved with the latest developments in <a href="https://matrix.org/blog/2020/06/02/introducing-p-2-p-matrix">P2P Matrix</a>, but it is unclear as to whether or not this will be effective in regards to room metadata such as membership or administrator privileges.</p><p>It should be noted that the relative ease of hosting your own Matrix server diminishes the value of any metadata leaks. If all of your contacts use a Matrix server that you trust (which could be one that you host), it doesn't matter if the server can see this metadata. However, in practice, most people just use someone else's server (such as the matrix.org one).</p><h3 id="is-matrix-anonymous">Is Matrix anonymous?</h3><p>Kinda. If you trust the federated homeserver you are connected to not to disclose your IP address, you are anonymous. If not, you are not anonymous, as the homeserver you connect to will be able to directly associate <a href="https://github.com/matrix-org/synapse/blob/f31f8e63198cfe46af48d788dbb294aba9155e5a/synapse/storage/databases/main/schema/delta/16/users.sql#L42">your chat identity and IP</a>.</p><p>Although it technically is possible to host a Matrix homeserver as an anonymous Tor onion service, it is highly impractical to do so as the process has <a href="https://github.com/matrix-org/synapse/issues/7088">yet to be streamlined</a>.</p><h3 id="is-matrix-easy-to-shut-down">Is Matrix easy to shut down?</h3><p>No. It would be practically impossible to entirely shut Matrix down. The Matrix Foundation cannot shut down Matrix. However, significant damage could be done given the current points of centralization. First, if the …</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://our.status.im/private-messengers-what-can-they-really-see/">https://our.status.im/private-messengers-what-can-they-really-see/</a></em></p>]]>
            </description>
            <link>https://our.status.im/private-messengers-what-can-they-really-see/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26011449</guid>
            <pubDate>Wed, 03 Feb 2021 07:33:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A friendly reminder that we first solve problems and then write beautiful code]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26011286">thread link</a>) | @brslv
<br/>
February 2, 2021 | https://www.bobi.page/2021/02/you-have-to-solve-problem-first.html | <a href="https://web.archive.org/web/*/https://www.bobi.page/2021/02/you-have-to-solve-problem-first.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-3897191975409227409">
<p>I have a piece of actionable advice for all the devs out there.<span></span></p><p>If you have to write a block of code, that should solve a particular problem, do write the simplest, dumbest, most trivial version of that code.</p><p>With hardcoded values, nested ifs, a lot of copy-pasting, with everything that you've heard is a "bad practice".</p><p>Start with a beginner's mind. Start simple. Eliminate all the burden of thinking about how this piece of code should fit in the grand scheme of your project. Or how a senior dev (like you are, I'm sure) should write beautiful, extensible, and flexible code.</p><p>Forget all that bullshit and focus on being useful for your company/team/yourself.</p><p>Just solve that problem.</p>
</div></div>]]>
            </description>
            <link>https://www.bobi.page/2021/02/you-have-to-solve-problem-first.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26011286</guid>
            <pubDate>Wed, 03 Feb 2021 06:57:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Book Review: A Philosophy of Software Design (2020)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26011271">thread link</a>) | @lwhsiao
<br/>
February 2, 2021 | https://johz.bearblog.dev/book-review-philosophy-software-design/ | <a href="https://web.archive.org/web/*/https://johz.bearblog.dev/book-review-philosophy-software-design/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div><p>This review is largely in response to the article "<a href="https://qntm.org/clean">It's probably time to stop recommending Clean Code</a>", and the ensuing <a href="https://www.reddit.com/r/programming/comments/hhlvqq/its_probably_time_to_stop_recommending_clean_code/">Reddit discussion</a>.  A lot of really interesting points were brought up, but the big question that the author themself wasn't able to answer was: "What should we recommend instead?"</p>
<p>I believe the book we should be recommending is <em>A Philosophy of Software Design</em> by John Ousterhout.  In this post I want to spend a bit of time reviewing it and giving an overview of the contents, and then I want to explain why, in my opinion, it is such a good recommendation.</p>
<h2 id="an-empirical-philosophy-book">An Empirical Philosophy Book</h2>
<p>The elevator pitch of John Ousterhout's book <em>A Philosophy of Software Design</em> is fairly simple: he is a university professor (albeit one with almost two decades of experience in the "real world", also the inventor of Tcl, creator of RAFT, company founder amongst <a href="https://www.reddit.com/r/programming/comments/lb8zrn/an_alternative_to_clean_code_a_philosophy_of/glt3e4n/">other things</a>), who each year teaches students how to actually design software in a practical, hands-on course where the students are expected to design and modify "a substantial piece of software" in an iterative way, hopefully understanding more about the practice of software design each time around.</p>
<p>The book, then, is a synthesis of the pieces of wisdom that Ousterhout has himself learned from his own experiences, tempered and refined by the practical examples he has been able to draw from his students.  In this way, it has a (somewhat) scientific, research-based approach, where the author's assertions are backed up with examples from student projects that worked (or didn't).</p>
<p>At it's core, though, this is still philosophy - the book doesn't just list the things that worked well, and the things that worked poorly.  Instead, Ousterhout attempts in each chapter to divine broader truths that apply to software design in general.  There are no lists of what to do and what not to do, but instead principles to follow, red flags to be aware of, and warnings against taking anything too far.</p>
<h2 id="structure">Structure</h2>
<p>The book is split into a series of chapters, each of which generally explores a single principle.  These range from the very high level ("Working Code Isn't Enough", "Modules Should Be Deep") to the more practical questions ("Choosing Names").  The whole book is relatively short (about 180 pages), and many chapters flow together nicely, which means that it's quite easy to go from cover-to-cover, rather than approach the book as a reference manual.  That said, the final pages provide summaries of the design principles and red flags found in the book, making it easy to reference key parts of the book.</p>
<p>Within each chapter, Ousterhout generally starts by stating a problem or motivation that software engineers will face, and then defining a principle to solve this.  The rest of the chapter is then a discussion of the principle, the dangers of alternative approaches, the red flags that indicate that the principle needs to be applied (or in some cases avoided), and some notes about taking ideas too far.</p>
<p>The examples are often based on problems that Ousterhout has given his classes, which means that they generally feel meaty enough to be worth discussing.  An example of a text editor appears in Chapter 6, but is extended in Chapters 7, 8, 9, and 10 in different contexts.  Enough is omitted from most examples to make the point clear, but enough is kept in to give the feeling of real code.</p>
<h2 id="ousterhout-s-principles">Ousterhout's Principles</h2>
<p>The overriding theme throughout the book is that good code <em>looks</em> good.  Ousterhout thinks very much in terms of abstraction and interfaces - where "interfaces" refers to the contact points between different units of abstraction, rather than any similarly-named construct in any particular language.  Most of the book is dedicated to figuring out how to spot bad abstractions and rework them into good abstractions.</p>
<p>To a certain extent, this feels at odds with certain common mantras in software engineering circles today, where we encourage enough other to Keep It Simple, Stupid, and worry about premature abstractions.  <em>Philosophy</em> seems to worry less about the dangers of over-abstraction, and more concerned with how to make sure that the chosen abstraction is a good one.</p>
<p>This approach makes for a more positive experience than in many other programming circles - rather than being warned into a very conservative approach, Ousterhout encourages his readers to go out and make abstractions, but to be careful about designing the correct ones.</p>
<p>This isn't to say that the book isn't also cautionary - in the summary pages at the back, the list of red flags gets more page space than the list of principles, and throughout the book these red flags mark out moments when readers are given the go ahead to use these abstraction techniques.  There are also warnings about when a principle might be used too much.</p>
<h2 id="everyone-s-a-critic">Everyone's a Critic</h2>
<p>Beyond the mild danger of encouraging excess abstraction, the biggest issue in <em>Philosophy</em> is probably the missing parts - the topic of testing gets a single page in Chapter 19 (Software Trends), and ideas about effective use of a type system to avoid issues are largely ignored.  Ousterhout's principles will still apply in these areas, but it would be nice to see some more specific discussion of these areas.</p>
<h2 id="the-target-audience">The Target Audience</h2>
<p>It can be a bit unclear at times to whom Ousterhout writes.  A lot of the examples clearly relate to his students, and the projects that they come from have a somewhat academic feel - a text editor here, and an HTTP protocol parser there.  The code in the examples is generally object-oriented (Java and occasional C++), although it generally feels like it could be replaced with most imperative/OO languages without much of an effect.</p>
<p>The use of the phrase "software design" might make one think more of broader software architecture, but Ousterhout uses it more to describe the design of individual modules and functions <em>within</em> a program, rather than the broader architecture of the program itself (although he occasionally touches on that).</p>
<p>More functionally-minded people might think they can simply side-step a lot of the discussion here, in the same way that they can when discussing the Gang of Four's design patterns, but the principle "design errors out of existence" (Chapter 10) and its corollary "design special cases out of existence" should ring bells for people in this area who are also aware of the principle of making illegal states unrepresentable.</p>
<p>Ultimately, I think this book aims at a space that is slightly deeper than a lot of existing software literature.  Where books like <em>Design Patterns</em>, Fowler's <em>Refactoring</em>, and the aforementioned <em>Clean Code</em> are aimed at more traditional "enterprise" software development, <em>Philosophy</em> feels more widely applicable, albeit at the cost of being more abstract and difficult to apply.</p>
<p>In general, I think <em>Philosophy</em> is a good read if you are both (a) working with software regularly, and (b) conscious of the inherent maintenance cost in software, and aiming to minimise it.</p>
<h2 id="a-book-to-recommend">A Book to Recommend</h2>
<p>The original question I wanted to answer was what we, as software engineers, should recommend over books like <em>Clean Code</em>.  As I said, my answer to that question is <em>A Philosophy of Software Design</em>.</p>
<p>Software engineering (indeed, engineering in general) is not a science, insofar as there are no (or at least very few) exact answers.  Everything from the database you use to your choice of testing strategy will be dependent on the context of the software you're writing.  This means that the advice that we give to each other will probably be very context-specific.  In general, you probably shouldn't use a NoSQL database, but in a lot of specific contexts you probably should.</p>
<p>This isn't a problem if we don't run into these exceptional cases often, but engineering is all about exceptional cases - if there were no exceptional cases, we wouldn't need to write any new software, because our existing tools would do the job.  This is where books like <em>Philosophy</em> come in - rather than give situational advice, it attempts to define wider principles that the reader will then need to apply to different situations.</p>
<p>Take, for example, my favourite principle: "Modules should be deep" (explored in Chapter 4).  The idea is that an individual unit of abstraction should do a lot of work (i.e. be deep, and contain a lot of complexity), but it should have a relatively simple interface (i.e. be narrow).  Essentially, if you're going to abstract something, make sure your abstraction is deep.</p>
<p>Notice that this principle says nothing about functions, classes, lines, blocks, parameters, or anything specific to a single language or paradigm.  However, when we apply it, for example to the Java code Robert C. Martin talks about in <em>Clean Code</em>, we can derive some of his ideas from this principle.  Assuming a function is our unit of abstraction (for now, at least), the parameters are its interface, therefore we should reduce the number of parameters to the minimum necessary.</p>
<p>However, because our principle is more general, we can actually correct some of the mistakes Martin makes.  Martin talks about removing parameters by adding private fields to the class that the method belongs to.  When we think in terms of interfaces, we notice that this <em>hasn't decreased the interface at all</em> - we've lost a parameter, but we've gained a private field, and in the process made things harder for the consumer of our abstraction.</p>
<h2 id="teaching-principles-over-rules">Teaching Principles Over Rules</h2>
<p>When I recommend books, I generally hope that the other person will learn something from the book I have suggested.  If I were to recommend <em>Clean Code</em>, I would hope that the reader would learn something about how to write clean Java code, but I suspect they would mainly learn how to write code like Robert C. Martin - or more accurately, like someone copying Robert C. Martin's actions without always understanding why he's taking them.</p>
<p>I do not feel this way about <em>A Philosophy of Software Design</em>.  When I recommend it, I …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://johz.bearblog.dev/book-review-philosophy-software-design/">https://johz.bearblog.dev/book-review-philosophy-software-design/</a></em></p>]]>
            </description>
            <link>https://johz.bearblog.dev/book-review-philosophy-software-design/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26011271</guid>
            <pubDate>Wed, 03 Feb 2021 06:54:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Everything you never wanted to know about ANSI escape codes]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 11 (<a href="https://news.ycombinator.com/item?id=26011198">thread link</a>) | @brendanfalk
<br/>
February 2, 2021 | https://notes.burke.libbey.me/ansi-escape-codes/ | <a href="https://web.archive.org/web/*/https://notes.burke.libbey.me/ansi-escape-codes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<header>

<p>2019-02-13</p>
</header>
<p><strong>See also: <a href="https://ankiweb.net/shared/info/1616925913">Flash cards (Anki deck) for memorization</a></strong></p>
<p>My team writes a lot of command line tools, and we like to assume that people aren’t using a literal <a href="https://en.wikipedia.org/wiki/VT100">VT100</a> (meaning: we liberally use colours, italics, and basically every other terminal feature available to us). This tends to result in strings in our code that look a little like this:</p>
<pre><code>"\x1b[A\r\x1b[K\x1b[1;32mopened \x1b[1;4;34m%s\x1b[0;1;32m in your browser.\x1b[0m\n"</code></pre>
<p>If you’re like most people, your face just melted, but it’s actually really simple. This page is a crash course in what all of these things mean, and how to learn to read and write them effectively.</p>
<h3 id="x1b"><code>\x1b</code></h3>
<p>ANSI escapes always start with <code>\x1b</code>, or <code>\e</code>, or <code>\033</code>. These are all the same thing: they’re just various ways of inserting the byte 27 into a string. If you look at an <a href="http://www.asciitable.com/">ASCII table</a>, <code>0x1b</code> is literally called <code>ESC</code>, and this is basically why.</p>
<h3 id="control-sequences">Control sequences</h3>
<p>The majority of these escape codes start with <code>\x1b[</code>. This pair of bytes is referred to as <code>CSI</code>, or “Control Sequence Introducer”. By and large, a control sequence looks like:</p>
<pre><code>0x1B + "[" + &lt;zero or more numbers, separated by ";"&gt; + &lt;a letter&gt;</code></pre>
<p>It’s helpful to think of it this way: the terminating letter is a function name, and the intervening numbers as function arguments, delimited by semicolons rather than the typical commas.</p>
<p>If you see <code>\x1b[0;1;34m</code>, you can read it like this:</p>
<pre><code>\x1b[  # call a function
0;1;34 # function arguments (0, 1, 34)
m      # function name</code></pre>
<p>In effect, this is <code>m(0, 1, 34)</code>. Similarly, <code>\x1b[A</code> is just <code>A()</code>.</p>
<h3 id="available-functions">Available functions</h3>
<p>So with that mental model—reading escape sequences as function invocations—here’s an abridged documentation of the “standard library”, as it were:</p>
<table>
<colgroup>
<col>
<col>
<col>
<col>
</colgroup>
<thead>
<tr>
<th></th>
<th>name</th>
<th>signature</th>
<th>description&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</th>
</tr>
</thead>
<tbody>
<tr>
<td>A</td>
<td>Cursor Up</td>
<td>(n=1)</td>
<td>Move cursor up by <code>n</code></td>
</tr>
<tr>
<td>B</td>
<td>Cursor Down</td>
<td>(n=1)</td>
<td>Move cursor down by <code>n</code></td>
</tr>
<tr>
<td>C</td>
<td>Cursor Forward</td>
<td>(n=1)</td>
<td>Move cursor forward by <code>n</code></td>
</tr>
<tr>
<td>D</td>
<td>Cursor Back</td>
<td>(n=1)</td>
<td>Move cursor back by <code>n</code></td>
</tr>
<tr>
<td>E</td>
<td>Cursor Next Line</td>
<td>(n=1)</td>
<td>Move cursor to the beginning of the line <code>n</code> lines down</td>
</tr>
<tr>
<td>F</td>
<td>Cursor Previous Line</td>
<td>(n=1)</td>
<td>Move cursor to the beginning of the line <code>n</code> lines up</td>
</tr>
<tr>
<td>G</td>
<td>Cursor Horizontal Absolute</td>
<td>(n=1)</td>
<td>Move cursor to the the column <code>n</code> within the current row</td>
</tr>
<tr>
<td>H</td>
<td>Cursor Position</td>
<td>(n=1, m=1)</td>
<td>Move cursor to row <code>n</code>, column <code>m</code>, counting from the top left corner</td>
</tr>
<tr>
<td>J</td>
<td>Erase in Display</td>
<td>(n=0)</td>
<td>Clear part of the screen. 0, 1, 2, and 3 have various specific functions</td>
</tr>
<tr>
<td>K</td>
<td>Erase in Line</td>
<td>(n=0)</td>
<td>Clear part of the line. 0, 1, and 2 have various specific functions</td>
</tr>
<tr>
<td>S</td>
<td>Scroll Up</td>
<td>(n=1)</td>
<td>Scroll window up by <code>n</code> lines</td>
</tr>
<tr>
<td>T</td>
<td>Scroll Down</td>
<td>(n=1)</td>
<td>Scroll window down by <code>n</code> lines</td>
</tr>
<tr>
<td>s</td>
<td>Save Cursor Position</td>
<td>()</td>
<td>Save current cursor position for use with <code>u</code></td>
</tr>
<tr>
<td>u</td>
<td>Restore Cursor Position</td>
<td>()</td>
<td>Set cursor back to position last saved by <code>s</code></td>
</tr>
<tr>
<td>f</td>
<td>…</td>
<td>…</td>
<td>(same as G)</td>
</tr>
<tr>
<td>m</td>
<td>SGR</td>
<td>(*)</td>
<td>Set graphics mode. More below</td>
</tr>
</tbody>
</table>
<p>For practice, you might try interpreting the following string:</p>
<pre><code>\x1b[3A\x1b[4D\x1b[shello\x1b[J\x1b[1;3Hworld\x1b[u\x1b[13T</code></pre>
<h3 id="sgr">SGR</h3>
<p>The SGR (“Select Graphics Rendition”) function (<code>m</code>) has a much more complex signature than the other functions. An—again, abridged—guide to SGR arguments:</p>
<table>
<colgroup>
<col>
<col>
</colgroup>
<thead>
<tr>
<th>value</th>
<th>name&nbsp;/&nbsp;description&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>Reset: turn off all attributes</td>
</tr>
<tr>
<td>1</td>
<td>Bold (or bright, it’s up to the terminal and the user config to some extent)</td>
</tr>
<tr>
<td>3</td>
<td>Italic</td>
</tr>
<tr>
<td>4</td>
<td>Underline</td>
</tr>
<tr>
<td>30–37</td>
<td>Set text colour from the basic colour palette of 0–7</td>
</tr>
<tr>
<td>38;5;<em>n</em></td>
<td>Set text colour to index <code>n</code> in a <a href="https://commons.wikimedia.org/wiki/File:Xterm_256color_chart.svg">256-colour palette</a> (e.g.&nbsp;<code>\x1b[38;5;34m</code>)</td>
</tr>
<tr>
<td>38;2;<em>r</em>;<em>g</em>;<em>b</em></td>
<td>Set text colour to an RGB value (e.g.&nbsp;<code>\x1b[38;2;255;255;0m</code>)</td>
</tr>
<tr>
<td>40–47</td>
<td>Set background colour</td>
</tr>
<tr>
<td>48;5;<em>n</em></td>
<td>Set background colour to index <code>n</code> in a 256-colour palette</td>
</tr>
<tr>
<td>48;2;<em>r</em>;<em>g</em>;<em>b</em></td>
<td>Set background colour to an RGB value</td>
</tr>
<tr>
<td>90–97</td>
<td>Set text colour from the <strong>bright</strong> colour palette of 0–7</td>
</tr>
<tr>
<td>100–107</td>
<td>Set background colour from the <strong>bright</strong> colour palette of 0–7</td>
</tr>
</tbody>
</table>
<p>Multiple SGR arguments can always be concatenated using another <code>;</code>, and they will be applied in the order they are encountered. It’s especially common to see <code>0;</code> before some other argument, in order to reset the state before applying our own.</p>
<h3 id="colour-palettes">Colour Palettes</h3>
<p>The basic colour palette has 8 entries:</p>
<ul>
<li>0: black</li>
<li>1: red</li>
<li>2: green</li>
<li>3: yellow</li>
<li>4: blue</li>
<li>5: magenta</li>
<li>6: cyan</li>
<li>7: white</li>
</ul>
<p>A useful way to help remember this, or at least to select colours for use, is that, with the exception of 0/black, the colours are ordered by usefulness, with highest first: red text is very useful for indicating failures, green is useful for indicating extreme success, yellow for warnings, and then blue, magenta, and cyan for progressively more obscure conditions or decoration.</p>
<p>0 and 7 are less useful for text because one or the other will generally look nearly-unreadable depending on whether the user has a light or a dark background.</p>
<p>Terminals will also have a “bright” version of this palette (activated using 90–97 / 100–107). These are the same (black/red/green/etc.) but generally noticeably brighter than their regular counterparts.</p>
<p>For practice, you might try to figure out how this string would display:</p>
<pre><code>\x1b[38;2;255;255;0mH\x1b[0;1;3;35me\x1b[95ml\x1b[42ml\x1b[0;41mo\x1b[0m</code></pre>
<h3 id="miscellany">Miscellany</h3>
<p>Another pair of useful escapes is <code>\x1b[?25h</code> and <code>\x1b[?25l</code>. These show and hide the cursor, respectively. Try not to think too hard about the syntax here: <code>?25</code> means something to do with the cursor and <code>h</code> and <code>l</code> stand for “high” and “low”: imagine a bit indicating whether the cursor should be visible. The “high” value (1) would indicate “show”; the “low” value (0) would indicate “hide”.</p>
<p>Show/hide is useful when you’re going to draw some stuff that’ll cause the cursor to jump around like crazy, for example, repainting a couple of the last few lines to update them with new content.</p>
<p>One other thing that we use frequently is <code>\r</code>, or Carriage Return, which is functionally similar or identical to <code>\x1b[1G</code>. It just moves the cursor to the start of the line.</p>
<h3 id="summary">Summary</h3>
<p>That was a lot of information, but that’s essentially everything you need to know in order to competently read and write ANSI escape codes in a terminal.</p>
<p>If you want to learn this more thoroughly, <a href="https://ankiweb.net/shared/info/1616925913">I’ve put together a set of flash cards to help</a>.</p>



</div>]]>
            </description>
            <link>https://notes.burke.libbey.me/ansi-escape-codes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26011198</guid>
            <pubDate>Wed, 03 Feb 2021 06:41:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Parody of a typical comp.theory newsgroup discussion on a P≠NP proof (2004)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26011150">thread link</a>) | @not_knuth
<br/>
February 2, 2021 | http://blog.geomblog.org/2004/04/meta-proof.html | <a href="https://web.archive.org/web/*/http://blog.geomblog.org/2004/04/meta-proof.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-108208290541715043"><p>
inspired by <a href="http://www.pandagon.net/mtarchives/001749.html">pandagon</a>: a meta-proof of P=/!=NP, coming to a <a href="http://groups.google.com/groups?hl=en&amp;lr=&amp;ie=UTF-8&amp;group=comp.theory">newsgroup near you</a>:
</p><p>
P: I would like to announce my proof of P=/!=NP. The proof is very short and demonstrates how to solve/not solve SAT in polynomial time. You may find a write up of the proof <a href="http://">here</a>.
</p><p>
|-- V: I started reading your proof and when you claim 'foobar' do you mean 'foobar' or 'phishbang' ? 
<br>|----P: I meant 'phishbang'. Thanks for pointing that out. An updated version is <a href="http://">here.</a>
<br>|------V: Well if you meant 'phishbang' then statement "in this step we assume the feefum" is incorrect.
<br>|--------P: No no, you don't understand. I can assume feefum because my algorithm has a glemish.
<br>|-----------V: It has a glemish ? !! But having a glemish doesn't imply anything. All algorithms have glemishes !!
<br>|----V': Yes, and in fact in the 3rd step of argument 4, your glemish contradicts the first propum. 
<br>|--V'': I think you need to understand some basic facts about complicity theory before you can go further. Here is a book to read.
<br>|----P: My proof is quite clear, and I don't see why I have to explain it to you if you don't understand. I have spent a long time on this.
<br>|------V': Um, this is a famous problem, and there are many false proofs, and so you do have to convince us that the argument using glemishes can   actually work.
<br>|--------P: But what is wrong in my proof ? I don't see any problems with it, and if you can't point one out, how can you say it is wrong.
<br>|----------V'''': I don't have to read the entire proof: glemished algorithms are well known not to work.
<br>|------------V'''''': Check out this reference by </p><well known="" person=""> to see why.
<br>P: &lt;silence&gt;
<br>|--P: &lt;answering earlier post&gt;. This is what I mean by a glemish. it is really a flemish, not a glemish, which answers your objection.
<br>|----P': Keep up the good work P. I tried publishing my result, and these people savaged my proof without even trying to identify a problem. All great mathematical progress has come from amateurs like us. See this <a href="http://">link</a> of all the theorems proved by non-experts.
<br>|------V': Oh jeez, not P' again. I thought we had established that your proof was wrong.
<br>|--------P': no you didn't: in fact I have a new version that explains the proof in such simple language even dumb&amp;%&amp;%s like you can get it.
<br>|------P: Thanks P', I understand that there will be resistance from the community since I have proved what they thought to be so hard. 
<br>|--V': P, I'm trying to understand your proof, with the flemishes, and it seems that maybe there is a problem in step 517 with the brouhaha technique.
<br>P: &lt;silence&gt;
<br>|----P: V', thanks for pointing out that mistake. you are right. Instead of a brouhaha technique I need a slushpit. The details are complicated, so I will fix it and post a corrected version of the proof shortly. Thanks to all those who gave me constructive advice. I am glad that at least some of you have an open mind to accept new ideas. 
<hr>
<p>
This was prompted by the latest P=NP fiasco on comp.theory. I can only express my amazement and wonder at the few tireless souls (and they seem to be the same ones) who patiently try to address each new crackpot proof that comes down the pipe. 
</p>
</well></div></div>]]>
            </description>
            <link>http://blog.geomblog.org/2004/04/meta-proof.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26011150</guid>
            <pubDate>Wed, 03 Feb 2021 06:29:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cold Paths]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26011141">thread link</a>) | @todsacerdoti
<br/>
February 2, 2021 | https://timkellogg.me/blog/2021/01/29/cold-paths | <a href="https://web.archive.org/web/*/https://timkellogg.me/blog/2021/01/29/cold-paths">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post">
	<p id="time">
		<time pubdate="true">
			Fri January 29, 2021
		</time>
	</p>
	<p><em>Faced with yet another crisis caused by a bug hidden in a cold path, I found
myself Googling for a quick link to Slack out to the engineering team about cold paths.
Unfortunately, I can’t find a focused write-up; and so here I am writing this.</em></p>

<p>A <strong>cold path</strong> is a path through the code or situation that rarely happens. By contrast,
<strong>hot paths</strong>
happen frequently. You don’t find bugs in hot paths. By nature, bugs are found
in places that you didn’t think to look. Bugs are always in cold paths — every bug is
found in a path colder than all the paths you tested.</p>

<p>Here are some real world “cold paths” with big consequences:</p>

<ul>
  <li><a href="https://blog.thousandeyes.com/impacts-expired-tls-certificate/">An outage caused by an expired TLS certificate</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Year_2000_problem">Y2K</a></li>
</ul>

<p>Rare events are <a href="https://www.amazon.com/Black-Swan-Improbable-Robustness-Fragility/dp/081297381X">hard to predict</a>. That’s just the nature of them. As engineers,
I belive it’s our responsibility to do our best to try harder and get better at planning for
these rare bugs. Is that it? Try harder?</p>

<p>Better: Don’t have cold paths</p>


<p>I watched one of Gil Tene’s many amazing talks on Azul’s C4 garbage collector (not <a href="https://www.infoq.com/presentations/Java-GC-Azul-C4/">this talk</a>,
but similar) where he claimed that normally it takes 10 years to harden a garbage
collector. Azul didn’t have 10 years to produce a viable business, so they avoided almost all
cold paths in the collector and they were able to harden it in 4 years (I never tried verifying
this claim).</p>

<p>For a garbage collector, this means things like offering fewer options, or having a simpler
model to avoid cold paths around promoting objects between generations. For your app it will
mean something different.</p>

<p>You can <strong>test less</strong> to achieve high quality by <strong>reducing the size</strong> of your application. 
Less edge cases is equivalent to less testing surface area, which implies less testing work
and fewer missed test cases. There’s something to be said for avoiding config options and
making solutions less generic.</p>


<p>While I worked at AWS I had this beaten into my skull, but thankfully they’ve published 
guidence an excellent piece titled <a href="https://aws.amazon.com/builders-library/avoiding-fallback-in-distributed-systems/?did=ba_card&amp;trk=ba_card">“avoiding fallback in distributed systems”</a>. The 
hope is that, when system 1 fails you would like to automatically fallback to system 2.</p>

<p>For example, let’s say we have a process that sends logs to another service. For the hot 
path, we send logs directly via an HTTP request. But if the log service fails (e.g. 
overloaded, maintenence, etc.) we fallback by writing to a file and have a secondary process 
send those logs to the service when it comes back.</p>

<ul>
  <li>System 1: directly send logs to server</li>
  <li>System 2: send asynchronously via file append</li>
</ul>

<p>If system 2 is more reliable than system 1, then why don’t we always choose system 2? 
Always write to the file and ship logs asynchronously rather than send directly to the 
server. This is surprisingly strong logic that isn’t considered often enough. More often,
by asking the question you end up finding a way to make system 1 more robust.</p>

<p>In cases where fallback can’t be avoided they suggest always exercising the fallback. 
For example, on every request, randomly decide to use either system 1 or system 2, 
thereby ensuring that the cold path isn’t cold because both are exercised on the hot path,
at least sometimes.</p>


<p>In <a href="https://danluu.com/deconstruct-files/">“files are fraught with problems”</a>, Dan Luu demonstrates that it’s unexpectedly
difficult to write a file to disk correctly. Juggling issues like handling random power loss or 
strange ext4 behavior becomes a full-time job. It’s a lot to keep in your head, just to 
write a file.</p>

<p>Is it better to:</p>

<ol>
  <li>Ignore the cold paths and hope for the best</li>
  <li>Correctly implement &amp; test each file write event and ship late</li>
  <li>Use a system that does it correctly for you, like MySQL or SQLite</li>
</ol>

<p>Choice #3 delegates the testing of all those pesky cold paths to a 3rd party. 
Therefore, #3 is always the best choice, unless your company is in the file writing 
business (e.g. you’re AWS and working on DynamoDB or S3).</p>

<p>Alternnate take on the same idea: <a href="https://mcfunley.com/choose-boring-technology">Choose boring technology</a></p>


<p>The practice of avoiding cold paths is often presented as “simple code”. Unfortunately, “simple”
has such wildly varying meanings that it’s often antagonistic to use it outside a
mathematical setting. I’ve found that centering conversations around “avoiding cold paths”
gives more clarity on how to proceed.</p>

<p>In system design, the conversation about what is “simple” is even tougher due to the 
amorphous nature of it. The principle of “avoiding cold paths” can be extended to mean,
“delegating cold paths” to a trusted third party, like an open source project or a cloud
provider. An earnest discussion about your capacity for testing might be
appropriate. It lets you disengage from “building cool stuff” and instead view it as
“testing burden I’d rather not have”.</p>


</div></div>]]>
            </description>
            <link>https://timkellogg.me/blog/2021/01/29/cold-paths</link>
            <guid isPermaLink="false">hacker-news-small-sites-26011141</guid>
            <pubDate>Wed, 03 Feb 2021 06:27:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Clocks for Software Engineers (2017)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26011104">thread link</a>) | @rudedogg
<br/>
February 2, 2021 | https://zipcpu.com/blog/2017/09/18/clocks-for-sw-engineers.html | <a href="https://web.archive.org/web/*/https://zipcpu.com/blog/2017/09/18/clocks-for-sw-engineers.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>If you have a software background and you want to pick up digital design,
then one of the first things you need to learn about early on is the concept
of the clock.  To many software engineers turned beginning
<a href="https://en.wikipedia.org/wiki/Hardware_description_language">Hardware Description Language
(HDL)</a>
designers, the concept of a clock is an annoyance.  Without using a
clock, they can turn
<a href="https://en.wikipedia.org/wiki/Hardware_description_language">HDL</a>
into a programming language–with $display’s, <code>if</code>’s,
and <code>for</code> loops like any other programming language.  Yet the clock that these
beginning designers ignore is often the most fundamental part of any digital
design.</p>

<p>This difficulty is never more present then when reviewing some of the first
designs that beginning
<a href="https://en.wikipedia.org/wiki/Hardware_description_language">HDL</a>
developers produce.  I’ve now talked with several of these individuals who
have posted questions on the forums I participate within.  When I’ve then
drilled down into what they are doing, I’ve had to cringe at what I’ve found.</p>

<p>As an example, one student came to me struggling to understand why no one
on-line seemed to think much of his
<a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard">Advanced Encryption Standard (AES)</a>
<a href="https://en.wikipedia.org/wiki/Hardware_description_language">HDL</a>
implementation.
I’ll spare him the embarrassment of being named, or of linking to his project.
Instead, I’m just going to call him a <em>student</em>.  (No, <a href="https://zipcpu.com/about">I’m not a
professor</a>.)
This “student” had created a Verilog design to do not one round of
<a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard">AES</a>
encryption, but <em>every round</em>, <em>all in combinatorial logic with no clocks</em> in
between.  I can’t remember if he was doing
<a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard">AES</a>-128,
<a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard">AES</a>-192, or
<a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard">AES</a>-256,
but <a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard">AES</a>
requires between 10 and 14 rounds.  As I recall, his encryption engine
worked perfectly in the simulator, yet it only used one clock to encrypt or
decrypt his data.  He was proud of his work, but couldn’t understand why
those who looked at it told him he was thinking like a software engineer,
and not like a hardware designer.</p>

<table><caption>Fig 1: Software is Sequential</caption><tbody><tr><td><img src="https://zipcpu.com/img/sw-is-serial.svg" alt="Software runs serially" width="128"></td></tr></tbody></table>
<p>Indeed, I’ve now had the opportunity to counsel many of these software
engineers, new to
<a href="https://en.wikipedia.org/wiki/Hardware_description_language">HDL</a>,
like this “student”.  Many of them like to treat
<a href="https://en.wikipedia.org/wiki/Hardware_description_language">HDL</a> like
just another <em>software programming</em> language.  Having programmed before, they
go and look for the basics in any software programming language: how to
declare variables, how to make an if statement, a case statement, how to write
loops, etc.  They then write their code like a computer program–where
everything needs to run sequentially (Fig 1), yet completely ignoring the
reality of digital design which is that everything runs in parallel.</p>

<p>Sometimes these programmers will find a simulator, such as
<a href="https://www.veripool.org/wiki/verilator">Verilator</a>,
<a href="http://iverilog.icarus.com/">iverilog</a>,
or the
<a href="https://www.edaplayground.com/">EDA playground</a>.
They’ll then use a bunch of <code>$display</code> commands in their logic, treat them like
sequential “printf”s and use them to get their code to work–<em>without using
a clock</em>.  Their design then “runs” in the simulator using combinatorial logic
alone.</p>

<p>These students then describe their designs to me, and explain to me that their
design “works without a clock”.</p>

<p>Say what?</p>

<p>The reality is that no digital logic design can work “without a clock”.
There is always some physical process creating the
inputs.  These inputs must all be valid at some start time–this time forms the
first clock “tick” in their design.  Likewise, the outputs are then required
from those inputs some time later.  The time when all the outputs are
valid given for a given set of inputs forms the next “clock” in a “clockless”
design.  Perhaps the first clock “tick” is when the set the last switch on
their board is adjusted and the last clock “tick” is when their eye reads the
result.  It doesn’t matter: there is a clock.</p>

<p>The result is that someone who claims that their design “has no clock” is
either stating that he is using the simulator in an unrealistic fashion, or
that the design has an external clock setting the inputs and reading the
outputs–which is another way of saying that the design really <em>does</em> have
a clock.</p>

<p>If you find yourself struggling to understand the necessity of having a clock
when working in digital logic, or if you know someone who might be struggling
with this concept, then this post is for you.</p>

<p>Let’s spend a moment or two discussing the clock, and why it is so important
to build and design your logic around a clock.</p>

<h2 id="lesson-1-hardware-design-is-parallel-design">Lesson #1: Hardware design is parallel design</h2>

<p>The first and perhaps most difficult part of learning hardware design is
to learn that all hardware design is parallel design.  Things don’t take
place serially, as in one instruction after another (Fig 1), like they do in a
<a href="https://en.wikipedia.org/wiki/Central_processing_unit">computer</a>.
Instead, everything happens at once, as in Fig 2.</p>

<table><caption>Fig 2: Hardware logic runs in Parallel</caption><tbody><tr><td><img src="https://zipcpu.com/img/hw-is-parallel.svg" alt="Hardware runs in parallel" width="780"></td></tr></tbody></table>

<p>This changes a <em>lot</em> of things.</p>

<table><caption>Fig 3: A software loop</caption><tbody><tr><td><img src="https://zipcpu.com/img/sw-loop.svg" alt="Figure of a software loop" width="200"></td></tr></tbody></table>

<p>The first thing that changes needs to be the developer.  You need to <a href="https://zipcpu.com/blog/2017/08/21/rules-for-newbies.html">learn to
<em>think</em> in
parallel</a>.</p>

<p>Perhaps a good example of this difference would be a hardware loop.</p>

<p>In software, a loop consists of a series of
instructions, as Fig 3 illustrates.  These instructions create a set of
initial conditions.  Logic is then performed within the loop.  Then a loop
variable is used to make and define this logic, and it is often incremented
each time through the loop.  Until the
loop variable reaches the termination condition, the
<a href="https://en.wikipedia.org/wiki/Central_processing_unit">CPU</a>
continues to repeat
the instructions and logic within the loop.  The more times the loop runs,
the longer it takes to run the program.</p>

<p><a href="https://en.wikipedia.org/wiki/Hardware_description_language">HDL</a>
based hardware loops are not like this at all.  Instead, the
<a href="https://en.wikipedia.org/wiki/Hardware_description_language">HDL</a>
synthesis
tool uses the loop description to make several copies of the logic all
running in parallel.  The logic used to create the loop, such as the index,
to increment that index, to check the index against the final condition, etc.,
doesn’t need to be synthesized–so it is usually removed.  Further, since
the synthesis tool is creating physical wires and logic blocks, the number
of times through the loop cannot change after synthesis time.  After that
time, the amount of hardware is fixed and can no longer be changed.</p>

<p>The structure that results, shown in Fig 4 below, is <em>very</em> different from
the structure of a software loop in Fig 3 above.</p>

<table><caption>Fig 4: An HDL generated loop</caption><tbody><tr><td><img src="https://zipcpu.com/img/hw-loop.svg" alt="Figure of an HDL generated loop" width="780"></td></tr></tbody></table>

<p>This has several consequences.  For example, loop iterations can’t necessarily
depend upon the output of prior loop iterations like they could in software.
As a result, it’s hard to run a loop of logic across all of the data in a set
have an answer in the next clock.</p>

<p>But … now we’ve come back to the concept of the clock again.</p>

<p>The clock is central to any
<a href="https://en.wikipedia.org/wiki/Field-programmable_gate_array">FPGA</a>
design.  Everything revolves around it.
Indeed, I would argue that all of your logic development should <em>start</em> with
the clock.  It’s not an afterthought, but rather the clock forms the
structure of how you think about digital design in the first place.</p>

<h2 id="why-the-clock-is-important">Why the clock is important</h2>

<p>Step one is to understand that everything within a digital logic design takes
time to do in hardware.  Not only that, but
different operations take different amounts of time.  Traveling from one
part of the chip to another also takes time.</p>

<p>Perhaps the way to visualize this is with a chart.  Let’s place the
inputs to our algorithm on the top, the logic in the middle, and the outputs
on the bottom.  Time, as an axis, will run from top to bottom, from one clock
to the next.  The result of this visualization might look something like
Fig 5, below.</p>

<table><caption>Fig 5: Logic takes time, three operations</caption><tbody><tr><td><img src="https://zipcpu.com/img/clk-poor-design.svg" alt="Figure showing several logic operations, and their impact on the clock rate" width="780"></td></tr></tbody></table>

<p>Fig 5 shows several different operations: an addition, a multiply, and several
rounds of
<a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard">AES</a>–although
for discussion purposes it could be several rounds of any algorithm.
I’ve used the size of the operation boxes, in the vertical direction, to
indicate notionally how much time each operation might require.  Further,
operations that depend upon other operations stack up.  Hence, if you want
to do many rounds of
<a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard">AES</a> within
one clock, you’ll need to know that the second round cannot begin until
the first is complete.  Fitting this logic in, therefore, will increase the
amount of time between clock ticks and slow down your overall clock rate.</p>

<p>Now let’s look at the pink boxes.</p>

<p>The pink boxes represent the wasted capacity in your hardware
circuit–times when you might have been able to do something,
but since you had to wait for the clock, or perhaps wait for your inputs
to be processed first, you couldn’t do anything.  For example, in our notional
diagram above the multiply doesn’t take as long as one round of
<a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard">AES</a>,
neither does the addition.  However, you can’t do anything with the results
of those two operations while the
<a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard">AES</a>
calculations are taking place since those operations need to wait for
the next clock to get their next inputs.  This is what the “pink” boxes
represent in Fig 5: idle circuitry.  Further, because all of the
<a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard">AES</a>
rounds are pushing the next clock into the distance, there’s a lot of
idle circuitry presented in Fig 5.  This design, therefore, will not run as
fast as the hardware would allow.</p>

<p>If all we did was pipeline the
<a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard">AES</a>
algorithm, so that one round could be calculated on every clock, we could
then get the entire design to run faster with less wasted capacity.</p>

<p>Fig 6 shows this idea.</p>

<table><caption>Fig 6: Breaking up the operations speeds up the clock</caption><tbody><tr><td><img src="https://zipcpu.com/img/clk-aes-better.svg" alt="Figure: several operations, with immediate results between each" width="780"></td></tr></tbody></table>

<p>As a result of breaking our operation up into smaller operations, each of
which could be accomplished between clock ticks, our design now has much
less wasted capacity.  Even better, instead of encrypting only one block
of data at a time, we can pipeline the encryption algorithm.  The resulting
logic won’t encrypt a single block any faster than Fig 5 above, but if you
can keep the pipeline full you should be able to increase your
<a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard">AES</a>
encryption throughput by somewhere between 10-14x faster.</p>

<p>This is therefore a better design.</p>

<p>Can we do better?  Indeed we could!  If you are familiar with
<a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard">AES</a>,
then you know that each round of
<a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard">AES</a>,
has discrete steps within it.  These
can be broken up, allowing us to increase our clock speed until the
<a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard">AES</a>
round logic takes less time than the multiply.  This will increase the number
of adds and multiplies you can do, as well as micro-pipelining your
encryption engine so that you can run even more data through it on a per
clock basis.</p>

<p>Not bad.</p>

<p>Fig 6 above, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://zipcpu.com/blog/2017/09/18/clocks-for-sw-engineers.html">https://zipcpu.com/blog/2017/09/18/clocks-for-sw-engineers.html</a></em></p>]]>
            </description>
            <link>https://zipcpu.com/blog/2017/09/18/clocks-for-sw-engineers.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26011104</guid>
            <pubDate>Wed, 03 Feb 2021 06:18:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Leaky Abstractions and GME: Fintech’s Institutional Failure to Build]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26011099">thread link</a>) | @jacobajit
<br/>
February 2, 2021 | http://jacobajit.com/leaky-abstractions-gme | <a href="https://web.archive.org/web/*/http://jacobajit.com/leaky-abstractions-gme">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      
<!-- Copy and paste the converted output. -->

<!-----
NEW: Check the "Suppress top comment" option to remove this info from the output.

Conversion time: 0.481 seconds.


Using this Markdown file:

1. Paste this output into your source file.
2. See the notes and action items below regarding this conversion run.
3. Check the rendered output (headings, lists, code blocks, tables) for proper
   formatting and use a linkchecker before you publish this page.

Conversion notes:

* Docs to Markdown version 1.0β29
* Tue Feb 02 2021 22:11:10 GMT-0800 (PST)
* Source doc: Leaky Abstractions and GME: Fintech’s Institutional Failure to Build
----->



<p>February 2021</p>

<p>Last week’s GameStop (GME) speculative frenzy stirred a motley crew  of Redditors, politicians, and venture capitalists, each using the volatility to push their preferred narratives. <em>Evil hedge funds are <a href="https://www.wsj.com/articles/citadel-point72-to-invest-2-75-billion-into-melvin-capital-management-11611604340">propping up their buddies</a> and astroturfing misinformation. Market makers are evil for <a href="https://www.wsj.com/articles/gamestop-frenzy-puts-spotlight-on-trading-giant-citadel-securities-11612089000">profiting off retail order flow</a>. Robinhood has forsaken its namesake and is in cahoots with the aforementioned parties.</em> There are plenty of villains in this story, or none at all, depending on your view of the financial industry.</p>

<p>The real answer to why Robinhood restricted trading on GME turned out to be <a href="https://www.nytimes.com/live/2021/02/01/business/us-economy-coronavirus#robinhood-needed-3-billion-to-cover-risky-trades-its-chief-told-elon-musk">far more mundane</a>. To recap, settlement of stock trades takes multiple days, and in the meantime, the clearinghouses that facilitate trades for brokers require that some collateral be placed to account for risk that the buyer or seller does not fulfill their side of the trade. Since this risk increases with stock volatility, clearinghouses demanded $3 billion collateral from Robinhood to account for their users holding GME, a meme stock that was routinely seeing +/- 50% swings but threatened to crash to earth at any moment. Robinhood was forced to deal with the imminent liquidity challenge by raising emergency funding. In the meantime, to manage risk, they placed limits on purchasing GME shares. So goes the story recounted by Robinhood CEO Vlad Tenev (or as Elon Musk called him, “<a href="https://www.marketwatch.com/story/tesla-ceo-elon-musk-calls-robinhood-ceo-vlad-the-stock-impaler-and-grills-him-over-the-gamestop-saga-11612180184">Vlad the stock impaler</a>”).</p>

<p>Yet this surface-level explanation likely leaves the observant investor with more questions. <em>Okay, so plausibly if we’re trading on margin, Robinhood could face a liquidity crunch. But what’s the problem if we’re trading using our own settled cash?</em> Cash trades need to settle and we have to put down collateral to insure against risk in the meantime. <em>That’s no problem, the internet enables us to process transactions quickly, right?</em> No, it takes two days. <em>Why does it take two days?</em> Transactions are processed at night in batches. <em>Fine then, can’t you use the money we just put up as collateral?</em> You can’t use client funds for that purpose. <em>Why not? Wait, wouldn’t this all be a non-issue if trades cleared near-instantly? Isn’t this a self-imposed problem within the financial industry?</em></p>

<p>Indeed, this doesn’t seem to be how we would design the system from first principles. As it turns out, Robinhood’s liquidity incident only exposes the surface of deeper troubles in fintech. Underneath a world of seamless consumer transacting represented by Robinhood, Venmo, and other apps of their generation lies an underbelly of interconnected financial systems that struggle to meet modern demands. Fintech’s attempts at abstracting away such complexity run into challenges when long-tail events occur, leaving customers frustrated and institutions in danger. A firmer foundational infrastructure from the Fed involving features like open banking, instant P2P payments, and real-time trade settlement (update: <a href="https://blog.robinhood.com/news/2021/2/2/its-time-for-real-time-settlement">Robinhood themselves called for this now!</a>) would allow us to build a more robust layer of services while minimizing rent-seeking middlemen. <strong><a href="https://a16z.com/2020/04/18/its-time-to-build/">It’s Time to Build</a>.</strong></p>

<h2 id="when-abstractions-fail">When Abstractions Fail</h2>

<p>Software engineers define leaky abstractions as when underlying implementation details of a process, meant to be hidden away, become relevant as things fail. From this perspective, Robinhood manifested <strong>an</strong> <strong>abstraction that was not simply leaking but gushing out from every news report</strong> and flooding investors’ brokerage accounts. By hiding the details of a complex settlement process and marking sale proceeds as immediately available to a customer, Robinhood presents a simplified trading process to customers while handling the settlement and margin details behind the scenes. It all works well until some Redditors decide to send a stock to the moon and your platform bears the brunt, I guess. In any case upon discovery of a software bug, it’s an all-too-familiar experience to realize a certain library call isn’t working, and find yourself having to dig further and further into the annals of ancient source code down the chain to figure out where something went wrong.</p>

<p>Since you were never intended to dig this far (you’d never need to, right?), they sure won’t make it easy to dig down there, with obfuscated binaries, hidden state effects, and other nasty monsters of the underworld. Likewise, delving into the GME situation is a hopeless exercise for an average investor who, faced with a sudden message of “trading suspended”, rationally wants to get to the bottom of this. They would quickly find a wall of opaque financial rules with regards to the clearing process that seem to exist on a “need to know’’ basis. If Vlad the CEO himself <a href="https://www.youtube.com/watch?v=2M7X2dsW_Xw">“doesn’t quite know how the formula works”</a>, what hope does the average citizen have to track down the source of this seeming bug in the system? Perhaps we should all just give up, raise pitchforks against Citadel, and call it a day.</p>

<p>The financial world is not new to abstractions, of course. Almost any tangible object or collection of intangibles has been securitized, packaged into new securities, tranched once or twice for good measure, and repackaged - repeat until satisfied. New engineered securities are then available for boomer 401k portfolios, sovereign wealth funds, and anyone else who wants in from the peripheries. These abstractions, in their defense, have usually made the markets in which they’re employed <a href="http://www.oeconomia.actapol.net/pub/9_3_181.pdf">far more efficient and liquid</a>. Mortgage-backed securities, as much as they were maligned for their role in precipitating the Great Recession, made it dramatically easier for cash-strapped homebuyers in North Carolina to be matched up with someone on the other side of the world looking to [in theory] buy a bunch of uncorrelated assets (we all know how that ended though) for their investment portfolio. In exchange for the hard work and research that goes into assembling these securities, <a href="https://www.epi.org/publication/causes-of-wage-stagnation/">financial middlemen wages have shot up dramatically since 1970</a> against a backdrop of broader economic inequality.</p>

<p>But <strong>abstractions are only useful when they’re built upon a well-designed foundation of primitives</strong>. When abstractions are instead used as patches over flimsy Swiss cheese layers of infrastructure, they’re bound to go wrong and leak, making their presence known to the world at the most inopportune time. Like, say, when GME is attempting to go to the moon but passengers are getting ejected for mysterious reasons. <a href="https://www.joelonsoftware.com/2002/11/11/the-law-of-leaky-abstractions/">Joel Spolsky’s Law of Leaky Abstractions</a> asserts that “All non-trivial abstractions, to some degree, are leaky.” Assuming the truth of this statement, building unnecessary layers of complex abstractions compounds the risk for no good return.</p>

<h2 id="fintechs-stopgap-unicorns">Fintech’s Stopgap Unicorns</h2>

<p>The brave new world of fintech software consists of many such abstractions that really ought not to exist in an ideal world with better financial infrastructure. It’s a classic American story of governmental inaction and private opportunists seeking to fill the gap, providing acceptable service and pocketing some hefty middleman profits in the meantime. The existence of these entrenched middlemen further dampens any political interest in solving root causes of central dysfunction, and so the cycle is perpetuated.</p>

<p>Take Venmo for example. Nations around the world have begun setting up open banking APIs for peer-to-peer payments and other services by legally mandating interconnectability. The European Union’s <a href="https://en.wikipedia.org/wiki/Payment_Services_Directive">Revised Payment Services Directive</a> went into effect in 2018 putting Europe at the forefront of open banking initiatives. Supporting payments is a core function that makes a bank a bank, and in the 21st century, those payments occur over the internet and so we expect instant deposits. Instead, if we rely on existing open standards for payment in the US, ie. ACH deposits, it seems the <a href="https://www.nerdwallet.com/article/banking/ach-transfers">fastest we can do is a few business days</a> or pay up for expensive wire transfers. And conveniently those are extra days where funds are in limbo mean that banks can earn some extra interest.</p>

<p>The US has taken a market-driven approach to hoping for more interconnectedness between banks, resulting in Zelle, a P2P payment system created by a bank consortium that <a href="https://www.nytimes.com/2018/04/22/business/zelle-banks-fraud.html">is sometimes secure</a>. Meanwhile Venmo has the first-mover advantage in the P2P payment space, and has built out a formidable network of users in a domain where implicit trust in identities is critical. Don’t like those options? You’re also free to use Messenger Pay, Apple Pay, CashApp, among a myriad set of options. Clearly, the fragmentation is killing us here, making what intuitively wants to be a well-designed protocol a mess of walled gardens with varying functionality. These days, it’s hard to even grasp how protocols like email, or heck even USPS mail, ever came to fruition against the alternative crop of self-interested ecosystems.</p>

<p>Venmo won by building an abstracted network that appears to support instant peer-to-peer payments based just on a username. Underneath, of course, it rarely arranges for any bank transfers at all, and simply adjusts numbers in a database until a user actually wants to cash out. In the meantime, parent company PayPal can enjoy <a href="https://www.marketplace.org/2018/02/20/what-are-apps-venmo-doing-your-money/">the returns on idle capital</a> chilling in user wallets. This middleman profit, along with various fees for third-party integrations, seems like a fair concession for the services provided. But it gets worse: <a href="https://github.com/ccorcos/venmo-dark-patterns">Venmo is filled with dark patterns</a> that try to encourage you to share as much financial data as possible with them and others, in vague hopes of building “a social network” since apparently that’s the only end game allowed in the Valley. Perhaps outsourcing critical financial functions to growth-hungry companies with flimsy morals wasn’t such a great idea after all.</p>

<p>Plaid is another example of a Silicon Valley fintech darling filling in a gap resulting from our lack of an interbank API. Plaid allows users to connect bank accounts to other apps by logging into bank accounts on users’ behalf and scraping relevant data. Again, it’s easy to spot the …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://jacobajit.com/leaky-abstractions-gme">http://jacobajit.com/leaky-abstractions-gme</a></em></p>]]>
            </description>
            <link>http://jacobajit.com/leaky-abstractions-gme</link>
            <guid isPermaLink="false">hacker-news-small-sites-26011099</guid>
            <pubDate>Wed, 03 Feb 2021 06:16:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Property-Based Testing in Python]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26010998">thread link</a>) | @yingw787
<br/>
February 2, 2021 | https://bytes.yingw787.com/posts/2021/02/02/property_based_testing/ | <a href="https://web.archive.org/web/*/https://bytes.yingw787.com/posts/2021/02/02/property_based_testing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <p>NOTE: This blog post complements <a href="https://www.meetup.com/pydistrict/events/274066238/">a PyDistrict
presentation</a> on the same
topic posted on this date.</p>
<p>Thanks to <a href="https://necaris.net/">Rami Chowdhury</a> for inviting me to speak, and
the PyDistrict organizers for hosting me.</p>
<p>Code samples from this talk are available at <a href="https://github.com/yingw787/pydistrict_pbt">this GitHub
repository</a>.</p>
<p>The full YouTube talk can be seen <a href="https://youtu.be/nUwXwZevenA">here</a>.</p>
<hr>
<p><a href="https://news.ycombinator.com/item?id=26010998">Hacker News</a></p>
<p><a href="https://lobste.rs/s/tdvcvf/property_based_testing_with_hypothesis">Lobste.rs</a></p>
<hr>
<h2 id="overview">Overview</h2>
<p>Writing tests today sucks. Tests are expensive to write. They're even more
expensive to maintain. They're somewhat opaque to anybody who's not intimately
familiar with the test harness. You can't always be sure whether you're writing
the “right” tests for your situation. Worst of all, it's sometimes difficult to
persuade a non-technical stakeholder that software testing actually does
anything underneath the hood, except maybe inflate operational expenses for your
software budget. <a href="https://news.ycombinator.com/item?id=18442941">Every software development horror
story</a> I've heard comes with some
discussion around tests, and that's because not only does software fail in more
ways than anybody without job security may care to admit, it fails in novel and
unpredictable manners.</p>
<p>What sucks even more is <em>just how important effective software testing is</em> for
software engineers to quickly and confidently contribute value. The absolute
first thing I do after cloning most <code>git</code> repositories these days, for work or
otherwise, is run the test suite. Test suites are self-documenting and always
more accurate than a wiki or other forms of documentation, and since they're
programmatic it's much easier to tie into the rest of your developer workflow
(say when setting up automated deployments to production).</p>
<hr>
<p>Honestly, this probably isn't news to you if you've been working in industry for
a while, and it's easy to fall into a trap of powerlessness and believing any
endemic lack of alignment is eternal. And while it's not always (and usually
not) the fault of technical limitations, it may be useful to think of technical
ways to grow beyond the immediate problem. So I'd like to say there are two
great aspects about professional software that could be applied to software
testing.</p>
<p>The first is we're usually using paradigms that are decades old. Professional
software is usually incremental in action and incrementalist in thinking. This
implies there's often new concepts in academia or research that might solve
current problems. One professor I talked to around graduation 4 years ago
brought up how the A* path-finding algorithm was invented 20 years before its
adoption in the video game industry (and apparently that's at least one reason
why NPCs don't collide with in-world walls anymore).</p>
<p>The second is test suites usually under the full control of engineering. There
might be a QA department within engineering, but I have yet to see a
sales/marketing department care deeply about how you structure a test harness,
vs. the layout of a landing page. While serving the company is the goal of any
business-oriented engineering department, this means there's more agency than
usual in how engineering approaches testing, than say product implementation or
devops.</p>
<p>What we're looking for as software engineers is to write as many good tests as
possible within some limited time frame.</p>
<h2 id="different-software-testing-strategies-ive-used">Different software testing strategies I've used</h2>
<p>The most important thing about writing good tests is to start writing good
source code and develop good habits. This might involve separating concerns in a
codebase by using functions instead of classes, gradually applying type
signatures using <code>mypy</code> or <code>pyre-check</code> and adding a typechecking step to your
CI pipeline, and paying attention to software properties like immutability
(updating an object creates a copy of the object with the update instead of
mutating the original object) and idempotency (running a code block generates
the same output for the same input even for multiple runs). You can bring a lot
of value to the table by using tools + infrastructure like <code>black</code> for
autoformatting and Docker / <code>docker-compose</code> for running local infrastructure,
and a lot of this undergirds higher-order testing strategies like property-based
testing later on.</p>
<p>Some of these strategies I've applied in the field revolve around these simpler
ideas. When I'm building a webapp frontend or backend, I adopted the idea of
“functional core, imperative shell”, where you have a soup of decoupled methods
within your app that are easily unit testable, and a set of well-defined I/O
interfaces and stubs to imperative resources like your network or database to
create the cheapest possible integration tests. This is nice for stateless,
pass-through entities, but works less well when you're primarily looking for
effects (e.g. it'd be very difficult to unit test most of PostgreSQL
effectively). So when I became a data engineer, and I spent most of my day
interacting with effectful systems, I attempted with some success to write a set
of <a href="https://bytes.yingw787.com/posts/2018/11/07/data_driven_testing">data-driven integration tests using
<code>pytest</code></a> and leverage its ability to
parameterize over fixtures using data to create essentially a mongodump of test
descriptions. This solution was nice since it allowed me to scale the amount of
data I tested far beyond the amount of code I needed to write. However, I still
needed to come up with my own oracle values to test with. It's easy to run an
expensive integration test with very little added value.</p>
<p>This is where my interest in property-based testing stems from. I'd also mention
that even with property-based testing, all these testing strategies (and others
I haven't covered or discovered yet) have their place and their tradeoffs. You
should decide for yourself when to apply or to not apply each.</p>
<h2 id="what-is-property-based-testing">What is property-based testing?</h2>
<p>At its simplest, property-based testing is the inverse of normal unit testing.
Instead of providing some amount of data and a transformation so the computer
can assert a property, you provide a property and a transformation, so the
computer can provide some data.</p>
<p>Let's go back to the basics. Say you defined a method <code>addOne()</code> to increment an
integer by one:</p>
<div><pre><code data-lang="python"><span>def</span> <span>addOne</span>(x: int) <span>-</span><span>&gt;</span> int:
    <span>return</span> x <span>+</span> <span>1</span>
</code></pre></div><p>In order to test method <code>addOne()</code>, you can define a set of unit tests:</p>
<div><pre><code data-lang="python"><span>def</span> <span>test_addOne</span>():
    <span>assert</span> addOne(<span>5</span>) <span>==</span> <span>6</span>
</code></pre></div><p>You can even parameterize a list of oracle inputs and expected values:</p>
<div><pre><code data-lang="python"><span>import</span> pytest

<span>@pytest.mark.parametrize</span>(<span></span><span>'</span><span>_input, _expected</span><span>'</span>, [(<span>5</span>,<span>6</span>), (<span>6</span>,<span>7</span>), (<span>7</span>,<span>8</span>)])
<span>def</span> <span>test_addOne</span>(_input, _expected):
    <span>assert</span> addOne(_input) <span>==</span> _expected
</code></pre></div><p>The final leap is realizing that instead of coming up with your own oracle
values, you just care that the inputs are integers and the outputs are a
functional, deterministic transform resulting in an integer output. This is
where property-based testing:</p>
<div><pre><code data-lang="python"><span>from</span> hypothesis <span>import</span> given, strategies <span>as</span> st

<span>@given</span>(st<span>.</span>integers())
<span>def</span> <span>test_addOne</span>(_input):
    <span>assert</span> addOne(_input) <span>==</span> _input <span>+</span> <span>1</span>
</code></pre></div><p>For some properties, you can define and apply the opposite transform, which when
combined with the original transform, generates the identity function, which
should then leave the input untouched:</p>
<div><pre><code data-lang="python"><span>def</span> <span>subOne</span>(x: int) <span>-</span><span>&gt;</span> int:
    <span>return</span> x <span>-</span> <span>1</span>

<span>from</span> hypothesis <span>import</span> given, strategies <span>as</span> st
<span>@given</span>(st<span>.</span>integers())
<span>def</span> <span>test_addsub_returns_value</span>(_input):
    <span>assert</span> subOne(addOne(_input)) <span>==</span> _input
</code></pre></div><p>So what else is it similar to / different from? One's <em>generative testing</em>,
which are tests that create tests. Since we're creating a spec here,
<code>hypothesis</code> is generating tests underneath the hood for us and running them.
Otherwise, property-based testing is a bit different as it supports intelligent
search strategies that allow us to shrink the error space.</p>
<p>Another testing paradigm similar to property-based testing is <em>fuzz testing</em>,
where random inputs are inserted into a program to see how it behaves and
whether it crashes. To me, fuzz testing is more an extension of black-box
integration testing, and extends more into devops or security related testing,
rather than the unit-focused nature of property-based testing.</p>
<h2 id="what-is-hypothesis">What is <code>hypothesis</code>?</h2>
<p><code>hypothesis</code> is one of the more popular implementations of property-based
testing in Python. I had thought it originated from a PBT library called
<a href="https://hackage.haskell.org/package/QuickCheck"><strong><code>QuickCheck</code></strong></a> in Haskell,
but after reading through a Haskell book earlier this year and <a href="https://lobste.rs/s/ovebeq/pythonista_s_review_haskell#c_gz09vc">talking to some
folks online</a>,
there's a more “intelligent” PBT library in Haskell it came from called
<a href="https://hackage.haskell.org/package/hedgehog"><strong><code>Hedgehog</code></strong></a>, which applies
built-in shrinking as part of the test generation suite.</p>
<p>You can find the <code>hypothesis</code> for Python documentation
<a href="https://hypothesis.readthedocs.io/en/latest">here</a>, and additional
documentation around the team behind Hypothesis
<a href="https://hypothesis.works/">here</a>.</p>
<h3 id="hypothesis-strategies"><code>hypothesis</code> strategies</h3>
<p>The key idea behind <code>hypothesis</code> is strategy generation. You can see examples of
it by running this code segment in your <code>python</code> terminal:</p>
<div><pre><code data-lang="python"><span>from</span> hypothesis <span>import</span> strategies <span>as</span> st

st<span>.</span>text()<span>.</span>example()
</code></pre></div><p><code>hypothesis</code> supports basic strategies like those targeting Python's “primitive”
types. You can create <code>st.integers()</code> or <code>st.text()</code>. You can also do more
advanced things, like create strategies from structs like dictionaries or lists,
combine strategies together, infer strategies from a regular expression, and
build strategies from well-recognized third-party classes from <code>pandas</code> or
Django.</p>
<h3 id="hypothesis-tactics"><code>hypothesis</code> tactics</h3>
<p>I took a lot of these tactics from <a href="https://www.youtube.com/watch?v=KcyGUVzL7HA">a talk by Zac Hatfield-Dodds introducing PBT
at PyCon US</a>. Check out his website
<a href="https://zhd.dev/">here</a>.</p>
<p>The types of properties you can apply with <code>hypothesis</code> allow for certain
tactics you can play with in <code>hypothesis</code>.</p>
<p>One of these tactics might be manually defining the property, then letting
<code>hypothesis</code> generate the test cases for you. One common way this tactic is
applied is to look for “round-trip” properties, where you look for the inverse
method and check that applying both would result in the identity method.</p>
<p>Another tactic might be to use an oracle function. This can be really helpful if
you're refactoring a piece of code and you want to carry forward the original
behavior of that method, regardless of whether it's correct or incorrect. In
this case, that method becomes an oracle and you can apply the equal-by-value
constraint between the original and refactored methods as a …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bytes.yingw787.com/posts/2021/02/02/property_based_testing/">https://bytes.yingw787.com/posts/2021/02/02/property_based_testing/</a></em></p>]]>
            </description>
            <link>https://bytes.yingw787.com/posts/2021/02/02/property_based_testing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26010998</guid>
            <pubDate>Wed, 03 Feb 2021 05:58:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Lose Money]]>
            </title>
            <description>
<![CDATA[
Score 127 | Comments 45 (<a href="https://news.ycombinator.com/item?id=26010977">thread link</a>) | @maverik
<br/>
February 2, 2021 | https://www.getrevue.co/profile/andrewtye/issues/how-to-lose-money-323332 | <a href="https://web.archive.org/web/*/https://www.getrevue.co/profile/andrewtye/issues/how-to-lose-money-323332">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><!--[if mso | IE]>
<table role="presentation" border="0" cellpadding="0" cellspacing="0"><tr><td style="vertical-align:top;width:600px;">
<![endif]--><div aria-labelledby="mj-column-per-100"><div><div>
      <p><strong>1. Trade Options</strong></p><p><em>Fastest</em></p><p>No doubt you have heard all about how easy it is for people to lose their life savings trading securities in the stock market. But there is actually a much faster way – options. I’m not going to get into the nuts and bolts of trading options (actually, most people who lose money with options don’t understand how they work anyway) but I will give you a quick definition and then show how efficient these instruments-of-wealth-destruction really are.&nbsp;</p><p>There are two types of options – calls and puts. If you buy a call option, you are purchasing the right to but the underlying stock at a specified price. So, you might pay $3,000 dollars for the right to buy 100 shares Microsoft stock at $200 per share. Then, if the stock goes up to $300 you can either buy 100 shares at $200, or you can sell the option to some other idiot and they can use it to buy the shares. But, as you might imagine, that options contract is worth a lot more than $3,000 now, and you can sell it for a premium. This is how leverage works to make money. But we’re concerned about how to use leverage to lose money.&nbsp;</p><p>The nice thing about options is that there isn’t just one way to lose money. No, you can lose money in many different ways – far more than I can write on this page. But, if you’re looking to lose money don’t bother to read up on the different ways to trade options. Just go for it, and I’m certain you will lose everything. I’ll give you a few real-life examples of how I’ve lost money in options. First, buy options that are about ready to expire. In the previous example, if you bought the Microsoft options for $3,000, but the stock went to $195 instead of $300, you could lose all your money. Another easy way to lose money with options is to buy contracts that are way out of the money (OTM). This simply means you might buy Microsoft options that give you the right to buy stock at $200 – except this time, the stock is at $150 per share. If you do this, you won’t find anyone willing to buy the option contract back from you (after all, why would someone pay for the right to buy stock at $200 if it’s already at $150). And if you can’t find anyone to buy the contract from you it will expire worthless and you’ll lose all your money. Another favorite is not cutting your losses. If your contract is losing money (this often happens if you think the stock is going to go up but it goes down) and you want to lose more money, just hold it and don’t sell. Options decay with time so the longer you hold it the more likely it is that you will lose all your money. So, simply hold your position when it starts to go south and you’ll lose way more money.</p><p>Pro tip – Make sure to buy a bunch of contracts (say 10 of them) so you lose $30,000 instead of $3,000.</p><p>I could go on but I think you get the point. I have personally lost thousands of dollars using these methods and would highly recommend them to anyone looking for a fast way to lose it all. I’d recommend you try losing a small amount in stocks first to get your feet wet – then dive into options. If you’re anxious to give it a go, <a href="https://cash.app/app/TDZWWPC?utm_campaign=UA-188825179-1&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" target="_blank">use this link to start trading with Cash App</a> and you’ll get free money to lose right away.</p><p>The only options trader who doesn’t lose money is the one who never starts.</p><p><em>- Andrew Tye</em></p><p><strong>2. Write a Book</strong></p><p><em>Most consistent</em></p><p>You might think writing a book is a great way to make a bunch of cash – and you’d be wrong. In spite of the many books that will tell you how to make money writing a book, I’m here to let you in on a secret –writing a book is actually a fantastic way to lose money. I’ve written four short books and they have literally grossed hundreds of dollars. Now – hearing that I’ve sold some books might make you think you should write one also. But it’s a trap – you will spend hundreds of hours writing a book and then make hundreds of dollars in return. Not sure about you, but if I’m working for $1/hour I’m losing money fast. My latest book probably has more pages than it has copies sold – <a href="https://gum.co/getajob?utm_campaign=UA-188825179-1&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" target="_blank">take a look here</a> if you want a quick reference on how to get a job.</p><p><strong>3. Teach Online Courses</strong></p><p><em>Most helpful</em>&nbsp;</p><p>Aw, I love this one. You can help other people learn a skill and lose your money at the same time. Win-lose. Some folks think they can make a great online course and it will make them a nice living or side income. Most of those nice people are wrong. News flash – more people lose money creating online courses than make money from them. The good news for you is that there really aren’t many barriers to entry here. Get yourself a cheap mic (who needs quality audio anyway) and an inexpensive webcam. And go to town without bothering to make an outline. I’ve found a couple approaches that both work well. Option A - read the script from a piece of paper. Option B – don’t plan at all and just wing the recording.&nbsp;</p><p>This is a strategy that I’ve already proven out for you. I created a few classes online and over the past 5 years they have actually generated thousands of dollars. But net returns are certainly negative because for those thousands of dollars I spent hundreds of hours creating content, answering questions, and buying likes. If you’d like a good idea of what to expect, I have over 40,000 students taking my online courses and they have generated a few thousand in gross revenues.</p><p>Pro tip – make your courses free from the start – you will recoup less of your investment this way, and end up losing quite a bit more overall.</p><p><strong>4. Get a Degree</strong></p><p><em>Most socially acceptable</em></p><p>This tactic is harder to lose money with, but when you lose you lose big. Books and courses are more consistent losers, but they don’t add up as fast as big tuition debt combined with time off work. As mentioned, you do have to be careful with this one because it is possible to get a degree and actually make money. But here is what you do to ensure loss. First, choose a degree that you aren’t passionate about, or that doesn’t have high paying jobs, or that doesn’t really have any jobs (<a href="https://lunarjobs.co/radar?utm_campaign=UA-188825179-1&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" target="_blank">research here</a>). Second, don’t get a side job during school and take all of the student loans you can get your hands on. Third, be very picky about which of the few jobs you take and only take ones that are in fact low paying (high cost of living is also preferred when choosing location). </p><p>Pro tip – fail a few classes to extend your time to graduation – that way you can take on more debt.&nbsp;</p><p>One thing to watch out for is accidentally choosing a degree that can actually make you money. Like engineering or computer science. But even this caution is less important now than when I went to college because places like Lambda School are making four year university degrees more certain losers. I’ve been on both sides of this one. I spent two years studying software development and about 4 years studying engineering. Both of those degrees were inexpensive, I worked part-time while studying, and have made money with both of them. But, thankfully I learned my lesson and managed to lose a lot of money by the time I got an MBA. I could have started a company with the money, or just worked my way up in an engineering role. But by taking on a bunch of debt and forgoing a salary for a couple years I was able to lose way more money than if I’d simply started a company. I think I actually lost more by going to business school than if I’d started a company and lost all of the investors’ money!</p><p><strong>5. Become an Inventor</strong></p><p><em>Most fun</em></p><p>Okay people, this has to be one of the most enjoyable ways to lose money! I have drummed up all sorts of new inventions. Of course, they don’t make any money but that’s sort of the point right! Most of my awesome inventions failed make money because someone else took them to market before me. Other times it was because they were so stupid nobody wanted to buy them (or even look at them actually).</p><p>I’ve invented lots of awesome products that lost money, but here is one of my favorite no-hits:</p><p><em>Barking Bulb</em>: Scare away intruders with a bark</p><p>Don’t want a dog in your backyard? Fine, get a bulb that barks when intruders are detected. Light, motion sensing and sound in one bulb. I thought this was so brilliant. Safe as having a guard dog, but you don’t have to clean up after it. Literally the best of both worlds. Coming soon to a Home Depot near you!&nbsp;</p><p>Pro tip: Go straight for all of the full, non-provisional patents you can before you know if anyone wants the idea. Don’t wait to see if it’s manufacturable. Don’t do market research to see if competitive products exist. Just talk to an attorney and get the patents drawn up. This shortcut will let you lose $20,000 to $40,000 upfront before you even start doing hardcore R&amp;D or go to production.</p><p><strong>6. Do Internet Advertising </strong></p><p><em>Most controversial&nbsp;</em></p><p>Another interesting way to lose money is with online advertising. What I like most about this one is you can lose money consistently and sound smart to your friends at the same time. Where do you spend your money they ask? Oh, I have a website with ads. Wow. That is so cool. What you do is setup a website with some content (e.g. a blog about how to lose money) and you put some ads (from Google AdSense or affiliates) on it that will generate money for you. Then, to get more people to your blog you also buy ads from Google Ads or Facebook. If you do it just right there is arbitrage here – for every dollar you spend buying ads to get traffic to your site you can get 70 cents of income from the ads on your blog. You can consistently lose $0.30 for every $1.00 you spend. The downside is nearly unlimited as long as you pick a topic that has significant search traffic.</p><p>This one is somewhat controversial because a lot of people think that putting ads on your site and then buying other ads to get more traffic is actually a good way to make money. I’ve proven that it’s much easier to lose money with this method than it is to make money. So you can ignore the doubters.</p><p><strong>7. Stop finishing Projects</strong></p><p><em>Biggest loss</em></p><p>I have completely mastered this one. It has a sweet combination of money lost from working for …</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.getrevue.co/profile/andrewtye/issues/how-to-lose-money-323332">https://www.getrevue.co/profile/andrewtye/issues/how-to-lose-money-323332</a></em></p>]]>
            </description>
            <link>https://www.getrevue.co/profile/andrewtye/issues/how-to-lose-money-323332</link>
            <guid isPermaLink="false">hacker-news-small-sites-26010977</guid>
            <pubDate>Wed, 03 Feb 2021 05:53:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Product Manager vs. Product Marketing Manager vs. Product Owner]]>
            </title>
            <description>
<![CDATA[
Score 64 | Comments 35 (<a href="https://news.ycombinator.com/item?id=26010927">thread link</a>) | @DamilolaA
<br/>
February 2, 2021 | https://www.damilolaa.xyz/Product-Manager-vs-Product-Marketing-Manager-vs-Product-Owner | <a href="https://web.archive.org/web/*/https://www.damilolaa.xyz/Product-Manager-vs-Product-Marketing-Manager-vs-Product-Owner">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><p>This is a question that often arises in the product world and it requires our time to unpack it. Though these roles are somewhat similar and they work towards achieving the same set of goals, we then ought to look at the clear line distinction in the line of duty of the individuals and performance metric used to evaluate the success achieved by each role to help us understand them better and also help you figure out the most suitable for you.</p><p>These roles vary from company to company as in the case of a startup, a product manager is often tasked with the duty of these 3 roles while in larger or enterprise companies, there are 3 or more different roles in the product team working at different capacities to ensure that the right product is shipped and meet the demands of users.</p><p>While the product manager’s role is one that has come to limelight, the product marketing manager and product owner role have also been adopted by a lot of companies depending on their product and company culture. In this article, we will explain the difference between these roles and the job requirement of the individual involved.</p><h3 id="the-product-manager">The Product Manager</h3><p>These individuals are often referred to as mini CEOs of a product. They conduct customer surveys to figure out the customer’s pain and build solutions to address it. The PM also prioritizes what features are to be built next and prepares and manages a cohesive and digital product roadmap and strategy.</p><h3 id="the-product-marketing-manager">The Product Marketing Manager</h3><p>The PMM communicates vital product value — the “why”, “what” and “when” of a product to intending buyers. He manages the go-to-market strategy/roadmap and also oversees the pricing model of the product. The primary goal of a PMM is to create demand for the products through effective messaging and marketing programs so that the product has a shorter sales cycle and higher revenue.</p><h3 id="the-product-owner">The Product Owner</h3><p>This role exists in a scrum environment — <em><a href="https://www.scrum.org/resources/what-is-scrum" title="Scrum" target="_blank" rel="noreferrer">Scrum</a> is a framework for project management that emphasizes teamwork, accountability, and iterative progress toward a well-defined goal.</em></p><p>A product owner (PO) maximizes the value of a product through the creation and management of the product backlog, creation of user stories for the development team. The product owner is the customer’s representative to the development team. He addresses customer’s pain points by managing and prioritizing a visible product backlog. The PO is the first point of call when the development team needs clarity about interpreting a product feature to be implemented.</p><p><span>
      <span></span>
  <picture>
        <source srcset="https://www.damilolaa.xyz/static/0b33b68ff9b4c94d698dd11d756d6319/06fd5/pm.webp 700w" sizes="(max-width: 700px) 100vw, 700px" type="image/webp">
        <source srcset="https://www.damilolaa.xyz/static/0b33b68ff9b4c94d698dd11d756d6319/f6cdf/pm.png 700w" sizes="(max-width: 700px) 100vw, 700px" type="image/png">
        <img tabindex="0" src="https://www.damilolaa.xyz/static/0b33b68ff9b4c94d698dd11d756d6319/f6cdf/pm.png" alt="Product Manager vs Product Marketing Manager vs Product Owner" title="Photo by Marvin Meyer on Unsplash" loading="lazy">
      </picture>
    </span></p><p>Going more practical, we will use a hypothetical case study of a tech company, Slyde, to explain these roles to clearly understand their day-to-day duties.</p><p>Slyde is a financial technology company based in Lagos, Nigeria with coverage in other African countries. The company has been providing payment solutions through its web-based application but has noticed a large churn rate in areas with poor internet connection which in turn delay users from completing their transaction. The product team made this observation and has been tasked to come up with a solution.</p><h3 id="where-does-the-product-manager-product-marketing-manager-and-the-product-owner-come-in">Where does the Product Manager, Product Marketing Manager, and the Product Owner come in?</h3><p><strong>PM</strong>: The Product Manager will interface with the users through user interviews/feedback surveys or other means to hear directly from the users. They will come up with hypotheses alongside the team and validate them through prototyping and user testing. They will then create a strategy on the feature and align the team and stakeholders around it. The PM who is also the chief custodian of the entire product roadmap will, therefore, be tasked with the duty of prioritization. Before going ahead to carry out research and strategy, they will have to convince the stakeholders if it is a good choice to build the feature in context at that particular time or wait a bit longer based on the content of the roadmap.</p><p><strong>PMM</strong>: The product marketing manager is tasked with market feasibility and discovering if the features being built align with the company’s sales and revenue plan for the period. They also make research on how sought-after the feature is being anticipated and how it will impact the budget. They communicate the values of the feature; the why, what, and when to potential buyers — In this case users in countries with poor internet connection.</p><p><strong>PO</strong>: The product owner will first have to prioritize the backlog to see if there are no important tasks to be executed and if this new feature is worth leaving whatever is being built currently. They will also consider the development effort required to build the feature i.e the time, tools, and skill set that will be required. They will be the one to tell if the expertise of the current developers is enough or if more engineers or designers are needed to be able to deliver at the scheduled time. The product owner is also armed with the task of interpreting the product/feature requirements for the development team. They serve as the interface between the stakeholders and the development team.</p><hr><p>Lastly,</p><p>The goal of a product team is to delight its user by providing an excellent solution to their pain points regardless of the job title/role. Irrespective of your job role on a product team, you should always be driven by user empathy and the company’s goal as this will in-turn make you collaborate better among the team. A product person should first and foremost see themselves as a product leader — one who makes sure the user’s need is always advocated for, despite top executive declination, the product person is to persuasively align the executive to this.</p><blockquote><blockquote><p>Product Owner is a role you play on a Scrum team. Product Manager is the job. — Melissa Perri</p></blockquote></blockquote><p>So, regardless of your job role, a great product person will always act in the stead of a product manager and never streamline herself to the JD only but be actively involved directly or indirectly in every phase of the product development cycle. When the role is clearly understood and the duties implemented collaboratively as a team, every aspect of the product comes together in one beautiful piece.</p><p>This article first appeared on my <a href="https://blog.usejournal.com/product-manager-vs-product-marketing-manager-vs-product-owner-8ab08bc45662" title="Medium" target="_blank" rel="noreferrer">Medium</a></p><p>Thanks to <a href="https://www.linkedin.com/in/olufisayo-babalola/" target="_blank" rel="noreferrer">Olufisayo Babalola</a> for reviewing this article.</p><hr><h3 id="sources">Sources:</h3><ul><li><a href="https://unsplash.com/s/photos/product-manager?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" target="_blank" rel="noreferrer">Hero Image by airfocus on Unsplash</a></li></ul></div></article></div>]]>
            </description>
            <link>https://www.damilolaa.xyz/Product-Manager-vs-Product-Marketing-Manager-vs-Product-Owner</link>
            <guid isPermaLink="false">hacker-news-small-sites-26010927</guid>
            <pubDate>Wed, 03 Feb 2021 05:39:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What makes a startup idea viable?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26010689">thread link</a>) | @elsakrandrew
<br/>
February 2, 2021 | https://www.20answers.co/post/when-did-you-know-that-your-startup-idea-was-viable | <a href="https://web.archive.org/web/*/https://www.20answers.co/post/when-did-you-know-that-your-startup-idea-was-viable">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="8.17.5"><div dir="ltr"><div><h3 id="viewer-c8v37"><span><span><strong>10 paying customers</strong></span><strong><span> </span></strong></span></h3><p id="viewer-8f9rj"><span>I've brought a handful of different products to the market and I think there were different moments along the way where I thought the idea was viable, but the 3 things that have stood out as the most important: </span></p><ul><li id="viewer-c7geb"><p>The first time I pitched the idea and it resonated with a person who would be a core buyer (when you see the "light bulb" go off) </p></li><li id="viewer-fa6hj"><p>10 paying customers </p></li><li id="viewer-e8p4d"><p>1M dollars  </p></li></ul><p id="viewer-6otii"><span>Those I think are the big 3, but if I had to choose 1 I would say it is the 10 paying customers, at that point I know I have something that can scale. </span></p><p id="viewer-9ifm7"><span><span>- </span>Adam Weber<span>, Co-Founder and CPO, </span><a href="https://emplify.com/" target="_blank" rel="noopener"><span><u>Emplify</u></span></a><span> </span></span></p><h3 id="viewer-q0ku"><span><span><strong>Bootstrapped for 3.5 years </strong></span></span></h3><p id="viewer-73c5u"><span>I never was trying to create a startup, I was trying to create a professional services lifestyle business for myself. Our product (dbt) was a tool that I wanted to use in order to deliver services, and I honestly never believed at the outset that there would be many other folks in the world who wanted to use it. But it turns out that there are. So it took a full 3.5 years from launching dbt and watching its growth before I felt confident that we had a real shot at being a "big" company. This is one of the main reasons we waited for so long to raise capital--we bootstrapped the entire way until we felt like we had that confidence.  </span></p><p id="viewer-cj0e4"><span>It's an unusual approach and I'm not sure it would work for every situation and every founder, but our path has had a ton of really unique benefits for us and I wouldn't trade it for anything.</span></p><p id="viewer-b0ecd"><span><span>- Tristan Handy, </span>Founder and CEO<span>, </span><a href="https://www.fishtownanalytics.com/" target="_blank" rel="noopener"><u><span>Fishtown Analytics</span></u></a> </span></p><h3 id="viewer-63li0"><span><span><strong>Breaking even from a Thanksgiving promotion</strong></span></span></h3><p id="viewer-394rh"><span>Honestly, I knew it was "viable" ever since I started the company - otherwise I certainly wouldn't have started it :)</span></p><p id="viewer-64kiv"><span>When I knew we'd hit the inflection point of growth though is when we ran a promotion one time, I think it was a Thanksgiving day promotion - and we sold enough in those couple days that paid for the monthly expenses at the time. That single even made us breakeven and I knew we had something that people would pay for, and that could grow quickly.</span></p><p id="viewer-fsd94"><span><span>- </span>Zeb Evans, Founderf &amp; CEO, <a href="http://clickup.com/" target="_blank" rel="noopener"><u><span>ClickUp</span></u></a> </span></p><h3 id="viewer-bugts"><span><strong><span>Scalable + Repeatable + Margins </span></strong></span></h3><p id="viewer-8p59e"><span>When we had a scalable and repeatable sales motion with acceptable margins and a large enough addressable market. I realize that’s kind of an obvious answer but I’m not sure how else to answer - this isn’t the part that’s rocket science :)</span></p><p id="viewer-7rehb"><span><span>- Geoff Schmidt, CEO and Co-Founder, </span><a href="https://www.apollographql.com/" target="_blank" rel="noopener"><u><span>Apollo GraphQL</span></u></a> </span></p><h3 id="viewer-7ks1o"><span><strong><span>First renewal and large contract upsell</span></strong></span></h3><p id="viewer-7iu79"><span>There wasn't an aha moment when everything clicked, rather it was a gradual realization that things were working when looking backwards. There were early indicators around 12 to 18 months into Tonic when we started signing up customers who were paying real amounts. They were putting up with our buggy early versions and eagerly asking for when certain new features would be available. Over the next 6 months we had our first renewal and a large contract upsell, that's when things realized things had been viable for a while.</span></p><p id="viewer-1fout"><span><span>- Karl Hanson, Co-Founder COO, </span><a href="https://tonic.ai/" target="_blank" rel="noopener"><u><span>Tonic</span></u></a> </span></p><h3 id="viewer-9ek41"><span><strong><span>Open-source project with organic adoption</span></strong></span></h3><p id="viewer-buitk"><span>It wasn't a hard question for me. It was because my startup was built around an open-source project. The project was adopted organically by multiple enterprises, and developers (who are our main users) gave us pretty positive feedback. So it was clear that idea was viable long before we started thinking about founding a company.</span></p><p id="viewer-dqpja"><span><span>- Maxim Fateev, Founder, </span><a href="https://temporal.io/" target="_blank" rel="noopener"><u><span>Temporal Technologies</span></u></a> </span></p><h3 id="viewer-avmqj"><span><strong><span>Positive feedback on prototype</span></strong></span></h3><p id="viewer-bm6qc"><span>When we started Animoto in 2006 our first priority was to create a video creation product that we wanted to use ourselves. Before Animoto, it was too difficult and time-consuming to create great-looking video. Cloud-based video rendering had never been done before so we gave ourselves three months to create a prototype that would both prove out the technical concept and allow us to get user feedback. While entrepreneurs always have to be optimistic, it was only once we proved out the technical concept and got positive user experience feedback from family and friends that we knew our idea and product was viable.</span></p><p id="viewer-7tp4h"><span><span>- </span>Brad Jefferson<span>, CEO &amp; Co-Founder, </span><a href="https://animoto.com/" target="_blank" rel="noopener"><u><span>Animoto</span></u></a><span> </span></span></p><h3 id="viewer-2mf9g"><span><strong><span>First enterprise customer on annual contract</span></strong></span></h3><p id="viewer-2prob"><span>In my startup Qwiklabs when we had a first enterprise customer sign an annual contract I knew my product/startup idea was viable. At this point we had a minimalist product addressing the critical user journey. It was unclear at that point if there was a product/market fit (that is: if we had a great product for a large market). But it was clear that our idea and MVP were unique and useful enough for a large enterprise to pay for it. We established product/market fit a year from then when over a dozen enterprise customers were paying for the full-fledged version of the product.  In my view founders have an inkling/gut feeling about an idea; founders should bring that idea to a minimalist life and very quickly start validating it. </span></p><p id="viewer-e67l1"><span><span>- Jitesh Shetty, Co-Founder, </span><a href="https://infinichains.com/" target="_blank" rel="noopener"><u><span>Infinichains</span></u></a> </span></p><h3 id="viewer-2l3n1"><span><strong><span>The first dollar</span></strong></span></h3><p id="viewer-18vsj"><span>I have a very simple answer... it was when the first dollar came through the door. At that moment I remember thinking that if one customer was willing to trust us and pay us, there are likely many more out there and we have a viable idea. To me it was completely eye-opening and even unexpected that someone was willing to pay for a product we had just built and was still incredibly raw. I knew that if we kept building, kept learning and improving we would reach many more people. Honestly that first payment we received was a really emotional moment and the energy it created to forge ahead was enormous.  </span></p><p id="viewer-2ohu"><span><span>- Michael Balyasny,  CEO, </span><a href="https://attendify.com/" target="_blank" rel="noopener"><u><span>Attendify</span></u></a><span> </span></span></p><h3 id="viewer-f3oe0"><span><strong><span>You never know until it is (but there are milestones)</span></strong></span></h3><p id="viewer-bpr5f"><span>the honest answer is you never know until it is, and even then you question it, or at least i do.  however, i think some milestones might include:  </span></p><p id="viewer-22roj"><span>1.	when we got our first ever contract </span></p><p id="viewer-27cvq"><span>1.5 	when we raised our first seed round </span></p><p id="viewer-5vr4i"><span>2.	when companies that previously had said "oh, what a cute idea (im paraphrasing)" </span></p><p id="viewer-63d5t"><span>	actually starting using the technology </span></p><p id="viewer-873k9"><span>3.	when we got our first enterprise contract  </span></p><p id="viewer-7a6ag"><span>i realize these all have to do with money, which is not really why i became an entrepreneur - however, viability as a for-profit enterprise involves selling your product so... that's my answer.</span></p><p id="viewer-396ac"><span><span>- Frida Polli, CEO and Co-Founder, </span><a href="https://www.pymetrics.ai/" target="_blank" rel="noopener"><u><span>pymetrics</span></u></a><span> </span></span></p><h3 id="viewer-4bdfv"><span><strong><span>Customer requests and usage despite drawbacks</span></strong></span></h3><p id="viewer-7c6nq"><span>I don’t think there’s any particular framework. You feel the pull of p/m fit when customers come to you to ask for more things in your product or willing to use yours despite all the drawbacks.</span></p><p id="viewer-1lham"><span><span>- Vivek Ravisankar, Co-Founder &amp; CEO, </span><a href="https://www.hackerrank.com/" target="_blank" rel="noopener"><span><u>HackerRank</u></span></a> </span></p><h3 id="viewer-62bhe"><span><strong><span>When others can sell consistently without founder involvement</span></strong></span></h3><p id="viewer-74rts"><span>I knew it was viable when other sellers were able to consistently sell licenses of Suzy without me being involved in any way :)</span></p><p id="viewer-608sr"><span><span>- Matt Britton, CEO, </span><a href="https://suzy.com/" target="_blank" rel="noopener"><u><span>SUZY</span></u></a><span> </span></span></p><h3 id="viewer-91drf"><span><strong><span>Personally knew the problem to be solved</span></strong></span></h3><p id="viewer-5645b"><span>I personally knew the core problem we were trying to solve with Fictiv b/c of my background and time at Ford. From there, you have to listen to your early customers and challenge all of the hypotheses you have while staying true to the vision or disruption you know the market needs. For us, that's building a virtual CM that doesn't own a single machine or factory. It's been an amazing 8yr and we're only getting started!</span></p><p id="viewer-hevs"><span><span>- Dave Evans, CEO and Co-Founder, </span><a href="https://www.fictiv.com/" target="_blank" rel="noopener"><u><span>Fictiv</span></u></a><span> </span></span></p><h3 id="viewer-7glbk"><span><strong><span>First customer renewal</span></strong></span></h3><p id="viewer-favc"><span>I would say I knew the idea was viable when we renewed our first customer for an additional 1 year term. You can't really know if your product is adding value until a customer pays and renews.</span></p><p id="viewer-bsf77"><span><span>- Michael Smalls, CEO, </span><a href="https://www.hoopla.net/" target="_blank" rel="noopener"><u><span>Hoopla</span></u></a><span> </span></span></p><h3 id="viewer-7d449"><span><strong><span>Profitability</span></strong></span></h3><p id="viewer-8ckdf"><span>I knew my business had a chance to be viable from day one, but I really knew it was viable when the P&amp;L statement showed that we'd be profitable with our available cash.</span></p><p id="viewer-b1on0"><span><span>- </span>Ken Accardi<span>, CEO, </span><a href="https://www.ankota.com/" target="_blank" rel="noopener"><u><span>Ankota</span></u></a> </span></p><h3 id="viewer-ac2ii"><span><strong><span>Growth is easy</span></strong></span></h3><p id="viewer-7f6j6"><span>PostHog pivoted a lot. We changed what we were doing a total of 5 times in the first year - working on products ranging from a 1:1 tool for sales leaders, to a tool to monitor technical debt. The biggest thing that we knew we'd finally got it right was how it felt to grow. We published our open source product analytics platform on a big developer forum and it has grown organically ever since, at an increasing rate as we've focussed on the product. Every other idea we had, I was pushing very hard just to get one user at a time to try it out, whereas after just the first month of building PostHog, it just suddenly felt like running downhill. If you're not finding it easy to grow, then you probably aren't quite there yet. The end result was after we got the idea right, we were able to build a community of thousands of developers and to raise $12M within less than a year.</span></p><p id="viewer-63kho"><span><span>- James Hawkins, Co-Founder &amp; CEO, </span><a href="https://posthog.com/" target="_blank" rel="noopener"><u><span>PostHog</span></u></a><span> </span></span></p><h3 id="viewer-bs5qc"><span><strong><span>Gradually</span></strong></span></h3><p id="viewer-ccpq1"><span>As with the business of growing old, there is not one moment but a gradual, inevitable realization. Incrementally surreptitious.</span></p><p id="viewer-3vkh0"><span><span>- Avinash Misra, CEO and Co-Founder, </span><a href="http://skan.ai/" target="_blank" rel="noopener"><u><span>Skan.ai</span></u></a> </span></p><h3 id="viewer-13man"><span><strong><span>Reactions from potential users</span></strong></span></h3><p id="viewer-2v5ao"><span>quick answer is by talking to a lot of potential customers and seeing their reactions to my proposed startup idea.</span></p><p id="viewer-a65k2"><span><span>- Sanish Mondkar, Founder and CEO, </span><a href="http://legion.co/" target="_blank" rel="noopener"><u><span>Legion Technologies</span></u></a><span> </span></span></p><h3 id="viewer-c71hj"><span><strong><span>The early technology and team</span></strong></span></h3><p id="viewer-8o1ak"><span>I knew it was viable once I felt I had assembled a core of very good technical people and once I saw that the early technology could do things I thought were very valuable and could not be done with existing tech. This, of course, was a big gamble because we did not have concrete client interest in our tech—so it was mainly based on what I thought could happen given what I saw at the time and the caliber of the people working with us.</span></p><p id="viewer-c81jp"><span><span>- </span>Anonymous </span></p><h3 id="viewer-98nsb"><span><strong><span>Not all great ideas, or businesses, are the same</span></strong></span></h3><p id="viewer-dc3mg"><span>I think it's easy for most mythology around startups to be about "product market fit" which is true to a certain degree - this idea that you know viability when you hit clear mark of demand for some feature/service offering you have that clearly satisfies a sizable audience.  </span></p><p id="viewer-84j6q"><span>The trouble with this is that it misrepresents what a "great business' can be. By that I mean the tech industry in particular over romanticizes the idea of venture …</span></p></div></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.20answers.co/post/when-did-you-know-that-your-startup-idea-was-viable">https://www.20answers.co/post/when-did-you-know-that-your-startup-idea-was-viable</a></em></p>]]>
            </description>
            <link>https://www.20answers.co/post/when-did-you-know-that-your-startup-idea-was-viable</link>
            <guid isPermaLink="false">hacker-news-small-sites-26010689</guid>
            <pubDate>Wed, 03 Feb 2021 04:45:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Happiness Is a Boring Stack]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26010671">thread link</a>) | @tardismechanic
<br/>
February 2, 2021 | https://www.expatsoftware.com/Articles/happiness-is-a-boring-stack.html | <a href="https://web.archive.org/web/*/https://www.expatsoftware.com/Articles/happiness-is-a-boring-stack.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					
	
<div>
	
	<p>
I spend way too much time on <a href="https://news.ycombinator.com/">Hacker News</a>.  It's a fun place, and a good way to keep up to date on all the new tech that us developer folk seem to need to know about.  But it also leaves a fella feeling like he <b>really needs to keep up</b> with all this stuff.  I mean, if you don't have a side project using the latest client-side framework, well, good luck ever finding a job again in this industry.
</p>
<p>
Thinking about it, I find that I straddle the line on this. As a long-time contractor, I try to stay up to date on the New Shiny and will happily run with whatever flavor of the month language, framework, and programming paradigm that a given gig wants. Yeah, sure, Node.js with tons of functional stuff mixed in pulling from a NoSQL store and React on the front end. I'm your guy. We're gonna change the world!
</p>
<p>
But for 
<a href="https://www.twiddla.com/">my</a>
<a href="https://unwaffle.com/">own</a>
<a href="https://www.s3stat.com/">stuff</a>, 
there's no way I'd use any of that crap. Good old C#, SQL Server and a proper boring stack and tool set that I know won't just up and fall over on a Saturday morning and leave me debugging NPM dependencies all weekend instead of bouldering in the forest with the kids. This stuff is my proper income stream, and the most important thing is that it works. If that means I have to write a "for" loop and declare variables and risk 19 year old kids snooting down at my code, so be it.
</p>
<h4>I can't tell you how nice it is to have software in production on a boring stack. It gives you freedom to do other things.</h4>

<p>
I can (and often do) go entire months without touching the codebase of my main rent-paying products. It means I can, among other things, pick up a full-time development gig to sock away some extra runway, take off and go backpacking around the world, or better still, build yet another rent-paying product without having to spend a significant amount of time keeping the old stuff alive.
</p>
<p>
It seems like on a lot of stacks, keeping the server alive, patched and serving webpages is a part-time job in itself. In my world, that's Windows Update's job. Big New Releases come and go, but they're all 100% backwards compatible, so when you get around to upgrading it's just a few minutes of point and clicking with nothing broken.
</p>
<p>
I see it as analogous to <b>Compound Interest, but to productivity</b>. The less effort you need to spend on maintenance, the more pace you can keep going forward.
</p>
<p>
But yeah, the key is to never get so far down in to that comfy hole that you can't hop back into the present day when it's time to talk shop with the cool kids.  Shine on, flavor of the week!
</p>

	

	<p><small>
		<a href="https://news.ycombinator.com/submitlink?u=https://www.expatsoftware.com/Articles/happiness-is-a-boring-stack.html&amp;t=Happiness%20is%20a%20Boring%20Stack" id="ctl00_ctl00_contentBody_contentMain_blogEntry_linkHN" title="Discuss on HackerNews"><img src="https://www.expatsoftware.com/images/hackernews_14.gif" alt="HackerNews" height="14" width="14"> Discuss on hacker news</a>
	</small>

</p></div>
	

				</div></div>]]>
            </description>
            <link>https://www.expatsoftware.com/Articles/happiness-is-a-boring-stack.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26010671</guid>
            <pubDate>Wed, 03 Feb 2021 04:40:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AI Dubs over Subs? Translating and Dubbing Videos with AI]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26010409">thread link</a>) | @Clewza313
<br/>
February 2, 2021 | https://daleonai.com/translate-dub-videos-with-ml | <a href="https://web.archive.org/web/*/https://daleonai.com/translate-dub-videos-with-ml">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>Alongside cooking for myself and walking laps around the house, Japanese cartoons (or “anime” as the kids are calling it) are something I’ve learned to love during quarantine.</p>

<p>The problem with watching anime, though, is that short of learning Japanese, you become dependent on human translators and voice actors to port the content to your language. Sometimes you get the subtitles (“subs”) but not the voicing (“dubs”). Other times, entire seasons of shows aren’t translated at all, and you’re left on the edge of your seat with only Wikipedia summaries and 90s web forums to ferry you through the darkness.&nbsp;</p>

<p>So what are you supposed to do? The answer is obviously not to ask a computer to transcribe, translate, and voice-act entire episodes of a TV show from Japanese to English. Translation is a careful art that can’t be automated, and requires the loving touch of a human hand. Besides, even if you did use machine learning to translate a video, you couldn’t use a computer to dub… I mean, who would want to listen to machine voices for an entire season? It’d be awful. Only a real sicko would want that.</p>

<p>So in this post, I’ll show you how to use machine learning to transcribe, translate, and voice-act videos from one language to another, i.e. “AI-Powered Video Dubs.” It might not get you Netflix-quality results, but you can use it to localize online talks and YouTube videos in a pinch. We’ll start by transcribing audio to text using Google Cloud’s <a href="https://cloud.google.com/speech-to-text">Speech-to-Text API</a>. Next, we’ll translate that text with the <a href="https://cloud.google.com/translate">Translate API</a>. Finally, we’ll “voice act” the translations using the <a href="https://cloud.google.com/text-to-speech">Text-to-Speech API</a>, which produces voices that are, according to the docs, “humanlike.”</p>

<p>(By the way, before you flame-blast me in the comments, I should tell you that YouTube will <a href="https://support.google.com/youtube/answer/6373554#zippy=%2Cautomatic-captions-on-videos-on-demand">automatically and for free</a> transcribe and translate your videos for you. So you can treat this project like your new hobby of baking sourdough from scratch: a really inefficient use of 30 hours.)</p>

<h2 id="ai-dubbed-videos-do-they-axe-usually-sound-grood">AI-Dubbed Videos: Do they axe usually sound grood?&nbsp;</h2>

<p>Before you embark on this journey, you probably want to know what you have to look forward to. What quality can we realistically expect to achieve from an ML-video-dubbing pipeline?</p>

<p>Here’s one example dubbed automatically from English to Spanish (the subtitles are also automatically generated in English). I haven’t done any tuning or adjusting on it:</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/cURHKESgNaI" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>As you can see, the transcriptions are decent but not perfect, and the same for the translations. (Ignore the fact that the speaker sometimes speaks too fast–more on that later.) Overall, you can easily get the gist of what’s going on from this dubbed video, but it’s not exactly near human-quality.</p>

<p>What makes this project trickier (read: more fun) than most is that there are at least three possible points of failure:</p>

<ol>
  <li>The video can be incorrectly transcribed from audio to text by the Speech-to-Text API</li>
  <li>That text can be incorrectly or awkwardly translated by the Translation API</li>
  <li>Those translations can be mispronounced by the Text-to-Speech API</li>
</ol>

<p>In my experience, the most successful dubbed videos were those that featured a single speaker over a clear audio stream and that were dubbed from English to another language. This is largely because the quality of transcription (Speech-to-Text) was much higher in English than other source languages.</p>

<p>Dubbing from non-English languages proved substantially more challenging. Here’s one particularly unimpressive dub from Japanese to English of one of my favorite shows, Death Note:</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/gWNRfeEHmp4" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>If you want to leave translation/dubbing to humans, well–I can’t blame you. But if not, read on!</p>

<h2 id="building-an-ai-translating-dubber">Building an AI Translating Dubber</h2>

<p>As always, you can find all of the code for this project in the <a href="https://github.com/google/making_with_ml/tree/master/ai_dubs">Making with Machine Learning Github repo</a>. To run the code yourself, follow the README to configure your credentials and enable APIs. Here in this post, I’ll just walk through my findings at a high level.</p>

<p>First, here are the steps we’ll follow:</p>

<ol>
  <li>Extract audio from video files</li>
  <li>Convert audio to text using the Speech-to-Text API</li>
  <li><strong>Split transcribed text into sentences/segments for translation</strong></li>
  <li>Translate text</li>
  <li>Generate spoken audio versions of the translated text</li>
  <li><strong>Speed up the generated audio to align with the original speaker in the video</strong></li>
  <li>Stitch the new audio on top of the fold audio/video</li>
</ol>

<p>I admit that when I first set out to build this dubber, I was full of hubris–all I had to do was plug a few APIs together, what could be easier? But as a programmer, all hubris must be punished, and boy, was I punished.</p>

<p>The challenging bits are the ones I bolded above, that mainly come from having to align translations with video. But more on that in a bit.</p>

<h2 id="using-the-google-cloud-speech-to-text-api">Using the Google Cloud Speech-to-Text API</h2>

<p>The first step in translating a video is transcribing its audio to words. To do this, I used Google Cloud’s <a href="https://daleonai.com/translate-dub-videos-with-ml?utm_source=blog&amp;utm_medium=partner&amp;utm_campaign=CDR_dal_aiml_ai-dubs_020221">Speech-to-Text API</a>. This tool can recognize audio spoken in 125 languages, but as I mentioned above, the quality is highest in English. For our use case, we’ll want to enable a couple of special features, like:</p>

<ul>
  <li><a href="https://cloud.google.com/speech-to-text/docs/enhanced-models?utm_source=blog&amp;utm_medium=partner&amp;utm_campaign=CDR_dal_aiml_ai-dubs_020221">Enhanced models</a>. These are Speech-to-Text models that have been trained on specific data types (“video,” “phone_call”) and are usually higher-quality. We’ll use the “video” model, of course.</li>
  <li>Profanity filters. This flag prevents the API from returning any naughty words.</li>
  <li>Word time offsets. This flag tells the API that we want transcribed words returned along with the times that the speaker said them. We’ll use these timestamps to help align our subtitles and dubs with the source video.</li>
  <li><a href="https://cloud.google.com/speech-to-text/docs/context-strength?utm_source=blog&amp;utm_medium=partner&amp;utm_campaign=CDR_dal_aiml_ai-dubs_020221">Speech Adaption</a>. Typically, Speech-to-Text struggles most with uncommon words or phrases. If you know certain words or phrases are likely to appear in your video (i.e. “gradient descent,” “support vector machine”), you can pass them to the API in an array that will make the more likely to be transcribed:</li>
</ul>

<div><div><pre><code><span>client</span> <span>=</span> <span>speech</span><span>.</span><span>SpeechClient</span><span>()</span>  
<span># Audio must be uploaded to a GCS bucket if it's &gt; 5 min
</span><span>audio</span> <span>=</span> <span>speech</span><span>.</span><span>RecognitionAudio</span><span>(</span><span>uri</span><span>=</span><span>"gs://path/to/my/audio.wav"</span><span>)</span>
    
<span>config</span> <span>=</span> <span>speech</span><span>.</span><span>RecognitionConfig</span><span>(</span>
  <span>language_code</span><span>=</span><span>"en-US"</span>
  <span># Automatically transcribe punctuation 
</span>  <span>enable_automatic_punctuation</span><span>=</span><span>True</span><span>,</span>
  <span>enable_word_time_offsets</span><span>=</span><span>True</span><span>,</span>
  <span>speech_contexts</span><span>=</span><span>[</span>
    <span># Boost the likelihood of recognizing these words:
</span>    <span>{</span><span>"phrases"</span><span>:</span> <span>[</span><span>"gradient descent"</span><span>,</span> <span>"support vector machine"</span><span>],</span> 
     <span>"boost"</span><span>:</span> <span>15</span><span>}</span>
  <span>],</span>
  <span>profanity_filter</span><span>=</span><span>True</span><span>,</span>
  <span>use_enhanced</span><span>=</span><span>"video"</span><span>,</span>
  <span>model</span><span>=</span><span>"video"</span><span>)</span>

<span>res</span> <span>=</span> <span>client</span><span>.</span><span>long_running_recognize</span><span>(</span><span>config</span><span>=</span><span>config</span><span>,</span> <span>audio</span><span>=</span><span>audio</span><span>).</span><span>result</span><span>()</span>
</code></pre></div></div>

<p>The API returns the transcribed text along with word-level timestamps as JSON. As an example, I transcribed <a href="https://youtu.be/o6nGn1euRjk">this video</a>. You can see the JSON returned by the API in <a href="https://gist.github.com/dalequark/e983b929b6194adb49d00a9c55ae4e33">this gist</a>. The output also lets us do a quick quality sanity check:</p>

<p><em>What I actually said:</em></p>

<blockquote>
  <p>“Software Developers. We’re not known for our rockin’ style, are we? Or <em>are</em> we? Today, I’ll show you how I used ML to make me trendier, taking inspiration from influencers.”</p>
</blockquote>

<p><em>What the API thought I said:</em></p>

<blockquote>
  <p>“Software developers. We’re not known for our Rock and style. Are we or are we today? I’ll show you how I use ml to make new trendier taking inspiration from influencers.”</p>
</blockquote>

<p>In my experience, this is about the quality you can expect when transcribing high-quality English audio. Note that the punctuation is a little off. If you’re happy with viewers getting the gist of a video, this is probably good enough, although it’s easy to manually  correct the transcripts yourself if you speak the source language.</p>

<p>At this point, we can use the API output to generate (non-translated) subtitles. In fact, if you run my script with the `–srt` flag, it will do exactly that for you (<a href="https://blog.hubspot.com/marketing/srt-file#:~:text=An%20SRT%20file%20(otherwise%20known,the%20sequential%20number%20of%20subtitles.">srt</a> is a file type for closed captions):</p>

<div><div><pre><code>python dubber.py my_movie_file.mp4 <span>"en"</span> outputDirectory <span>--srt</span> <span>--targetLangs</span> <span>[</span><span>"es"</span><span>]</span>
</code></pre></div></div>

<h2 id="machine-translation">Machine Translation</h2>

<p>Now that we have the video transcripts, we can use the <a href="https://daleonai.com/cloud.google.com/translate?utm_source=blog&amp;utm_medium=partner&amp;utm_campaign=CDR_dal_aiml_ai-dubs_020221">Translate API</a> to… uh… translate them.</p>

<p>This is where things start to get a little 🤪.</p>

<p>Our objective is this: we want to be able translate words in the original video and then play them back at roughly the same point in time, so that my “dubbed” voice is speaking in alignment with my actual voice.</p>

<p>The problem, though, is that translations aren’t word-for-word. A sentence translated from English to Japanese may have word order jumbled. It may contain fewer words, more words, different words, or (as is the case with idioms) completely different wording.</p>

<p>One way we can get around this is by translating entire <em>sentences</em> and then trying to align the time boundaries of those sentences. But even this becomes complicated, because how do you denote a single sentence? In English, we can split words by punctuation mark, i.e.:</p>

<p><code>"Hi! My name is Dale. What's up?" --&gt; ["Hi", "My name is Dale", "What's up"]</code></p>

<p>But punctuation differs by language (there’s no ¿ in English), and some languages don’t separate sentences by punctuation marks at all.</p>

<p>Plus, in real life speech, we often don’t talk in complete sentences. Y’know?</p>

<p>Another wrinkle that makes translating transcripts difficult is that, in general, the <em>more</em> context you feed into a translation model, the higher quality translation you can expect. So for example, if I translate the following sentence into French:</p>

<p>“I’m feeling blue, but I like pink too.”</p>

<p>I’ll get the translation:</p>

<p>“Je me sens bleu, mais j’aime aussi le rose.”</p>

<p>This is accurate. But if I split that sentence in two (“I’m feeling blue” and “But I like pink too”) and translate each part separately, I get:</p>

<p>“Je me sens triste, mais j’aime aussi le rose”, i.e. “I’m feeling sad, but I like pink too.”</p>

<p>This is all to say that the more we chop up text before sending it to the Translate API, the worse quality the translations will be (though it’ll be more easy to temporally align them with the video).</p>

<p>Ultimately, the strategy I chose was to split up spoken words every time the speaker took a greater-than-one-second pause in speaking. Here’s an example of what that looked like:</p>

<div><div><pre><code><span>   </span><span>{</span><span>
        </span><span>"en"</span><span>:</span><span> </span><span>"Software developers."</span><span>,</span><span>
        </span><span>"start_time"</span><span>:</span><span> </span><span>0.2</span><span>,</span><span>
        </span><span>"end…</span></code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://daleonai.com/translate-dub-videos-with-ml">https://daleonai.com/translate-dub-videos-with-ml</a></em></p>]]>
            </description>
            <link>https://daleonai.com/translate-dub-videos-with-ml</link>
            <guid isPermaLink="false">hacker-news-small-sites-26010409</guid>
            <pubDate>Wed, 03 Feb 2021 03:50:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The free market and rent-seeking]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26010329">thread link</a>) | @CharlesW
<br/>
February 2, 2021 | https://pluralistic.net/2021/02/02/euthanize-rentiers/#poor-doors | <a href="https://web.archive.org/web/*/https://pluralistic.net/2021/02/02/euthanize-rentiers/#poor-doors">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1833">
	<!-- .entry-header -->

	
	
	<div>
		<p><!--
Tags:


Summary:
Criti-Hype; Right to Repair is back for 2021; The free market and rent-seeking

URL:
https://pluralistic.net/2021/02/02/euthanize-rentiers/

Title:
Pluralistic: 02 Feb 2021 euthanize-rentiers

Bullet:
🧵

Separator:
_,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,_

Top Sources:
Today's top sources: Beka Valentine (https://twitter.com/beka_valentine?, Naked Capitalism (https://www.nakedcapitalism.com).

--><br>
<a href="https://pluralistic.net/2021/02/02/euthanize-rentiers/"><img src="https://i2.wp.com/craphound.com/images/02Feb2021.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/craphound.com/images/02Feb2021.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></p>

<ul>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2021/02/02/euthanize-rentiers/#dont-believe-the-hype">Criti-Hype</a>: Tech bros will settle for "evil genius."
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2021/02/02/euthanize-rentiers/#r2r">Right to Repair is back for 2021</a>: Will Apple sabotage this one too?
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2021/02/02/euthanize-rentiers/#poor-doors">The free market and rent-seeking</a>: Unauthorized bread and poor doors.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2021/02/02/euthanize-rentiers/#retro">This day in history</a>: 2011, 2016
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2021/02/02/euthanize-rentiers/#bragsheet">Colophon</a>: Recent publications, upcoming/recent appearances, current writing projects, current reading
</li>
</ul>

<hr>
<p><a name="dont-believe-the-hype"></a><br>
<img src="https://i2.wp.com/craphound.com/images/critihype.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/craphound.com/images/critihype.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>There's a Yom Kippur joke I love: the rabbi and the richest man in town are praying, "Oh Lord, I am nothing, I am nothing!"</p>
<p>The synagogue's janitor sees them and joins in: "I am nothing!"</p>
<p>The richest man says to the rabbi: "Look who thinks he's nothing."</p>
<p>The humblebrag is a wild phenomena, and it's endemic to a certain kind of tech criticism. When a technologist – what Maria Farrell calls a "prodigal tech bro" – confesses that he's an evil genius, then "genius" is the point.</p>
<p><a href="https://crookedtimber.org/2020/09/23/story-ate-the-world-im-biting-back/">https://crookedtimber.org/2020/09/23/story-ate-the-world-im-biting-back/</a></p>
<p>Think of the "AI" scientists who claim that they are about to be responsible for massive waves of technological unemployment, seeming to confess to a sin while actually overpromising on their AI.</p>
<p><a href="https://pluralistic.net/2020/03/24/grandparents-optional-party/#what-automation">https://pluralistic.net/2020/03/24/grandparents-optional-party/#what-automation</a></p>
<p>Or the critique of "surveillance capitalism" that takes at face value ad-tech's outlandish boasts about how good they are at changing peoples' minds with data-mining, and then warns that we're all about to be enslaved to mind-control tech.</p>
<p><a href="https://onezero.medium.com/how-to-destroy-surveillance-capitalism-8135e6744d59">https://onezero.medium.com/how-to-destroy-surveillance-capitalism-8135e6744d59</a></p>
<p>Or the hand-wringing over the "trolley problem" of self-driving cars, as though the issue with these cars will be their reliable fine-grained judgments, rather than their unreliability and anticompetitive fealty to their manufacturers.</p>
<p><a href="https://this.deakin.edu.au/self-improvement/car-wars">https://this.deakin.edu.au/self-improvement/car-wars</a></p>
<p>This is what Lee Vinsel calls "criti-hype," criticism that actually builds on – and depends on – maintaining the halo of devastating potency that surrounds overhyped technologies.</p>
<p><a href="https://sts-news.medium.com/youre-doing-it-wrong-notes-on-criticism-and-technology-hype-18b08b4307e5">https://sts-news.medium.com/youre-doing-it-wrong-notes-on-criticism-and-technology-hype-18b08b4307e5</a></p>
<p>While it's true that the social problems that technologies create have unique, subtle elements that require a fine-grained understanding of the underlying science, it's a mistake to assume this obviates historical lessons.</p>
<p>Like, blockchain and proof-of-work and cryptography do bring unique facets to the problems of financial engineering, money-laundering and fraud – but all the problems of financial engineering and money-laundering and fraud are still in the mix.</p>
<p>Ad-tech and engagement-maximization systems add new wrinkles to the problems of communications monopolies and the epistemological chaos created by corrupt institutions, but the chaos and the monopolies are still central to these problems.</p>
<p>The problem with many metacritics of tech – people who criticize tech critics – is their assumption that tech is irrelevant. The problem with tech critics themselves is their assumption that tech is dispositive.</p>
<p>The reality is that tech has formal characteristics – the universality of Turing completeness – that both expand the policy toolkit (the power of interoperability mandates) and constrain it (the futility of cryptography back-doors).</p>
<p>Criti-hype is real, and its remedy isn't to ignore technicalities and criticize tech as though it was just another industry – the remedy is to really understand what tech can and can't do, and to understand that the industry isn't run by super-genuises (evil or otherwise) nor science heroes (or villains).</p>
<hr>
<p><a name="r2r"></a><br>
<img src="https://i1.wp.com/craphound.com/images/tinker-tech_1.png?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/craphound.com/images/tinker-tech_1.png?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>2018 was almost the year we won the Right to Repair.</p>
<p>Instead, 2018 turned out to be the year we lost R2R: 20 bills defeated in 20 state houses, and it was mostly Apple's fault.</p>
<p>Apple has a problem. As CEO Tim Cook warned his investors at the conclusion of his company's repair-killing lobbying spree, Apple's profits depend on people throwing away their devices, not fixing them.</p>
<p><a href="https://www.apple.com/newsroom/2019/01/letter-from-tim-cook-to-apple-investors/">https://www.apple.com/newsroom/2019/01/letter-from-tim-cook-to-apple-investors/</a></p>
<p>By monopolizing repairs, Apple doesn't just get to gouge you on parts and service – the real action is in pronouncing your device DOA, beyond repair. Then you have to buy another one.</p>
<p>Other companies lobbied hard against R2R: John Deere, GM, and other monopolists backed Apple's play. But Apple wrote the playbook, coming up with risible bullshit like claims that blocking independent repair is essential to protecting privacy.</p>
<p><a href="https://judiciary.house.gov/sites/democrats.judiciary.house.gov/files/documents/apple%20rfi%20-%20signed.pdf">https://judiciary.house.gov/sites/democrats.judiciary.house.gov/files/documents/apple%20rfi%20-%20signed.pdf</a></p>
<p>Apple's anti-repair FUD got picked up and amplified by Big Car in 2020, when they spent millions fighting an automotive R2R ballot initiative in Massachusetts, claiming that letting independent mechanics at your car would lead to your actual <em>murder</em>.</p>
<p><a href="https://pluralistic.net/2020/11/13/said-no-one-ever/#r2r">https://pluralistic.net/2020/11/13/said-no-one-ever/#r2r</a></p>
<p>2018 is the year we lost Right to Repair, but 2021 might be the year we win it. We're only a month in and 14 states are already debating R2R legislation, with more to come. The Repair Coalition and PIRG are leading the fight, buoyed by massive R2R successes in the EU.</p>
<p>Independent repair isn't just fair and it isn't just good for the planet – it's also good for the nation and its economy. The average US family loses $330/year thanks to anti-repair practices, a $40b drag on the American economy.</p>
<p>Repair creates local jobs for SMEs whose earnings – from helping their neighbors – are taxed (not hidden in offshore tax-havens) and contribute to their communities. These are on-shore, dignified tech jobs – not slave labor in Xinjiang or coerced labor in a Foxconn plant.</p>
<p>Repair diverts ewaste from landfills. Each kiloton of ewaste creates &lt;1 landfill jobs, or 15 recyling jobs.</p>
<p>But that same kiloton of ewaste creates 200 local repair jobs.</p>
<p><a href="https://www.ifixit.com/Right-to-Repair/Jobs-Revolution">https://www.ifixit.com/Right-to-Repair/Jobs-Revolution</a></p>
<p>Repair creates a secondary market for low-cost devices that find their way into the hands of people on the wrong side of the digital divide – a divide that got starker and more consequential during the pandemic, and will only get more important in years to come.</p>
<p>Speaking of the pandemic: anti-repair laws meant that when PB840 ventilators (the most common ventilator, sold by the monopolist Medtronic, which benefits from the largest-ever tax-avoidance "reverse takeover" in corporate history) broke, they couldn't be legally fixed.</p>
<p>Instead, desperate med-tech people turned to a lone Polish hacker who built Medtronic defeat devices into old guitar-pedals and clock radios to get around the anti-repair measures in the ventilators that hospitals had bought and paid for.</p>
<p><a href="https://pluralistic.net/2020/07/10/flintstone-delano-roosevelt/#medtronic-again">https://pluralistic.net/2020/07/10/flintstone-delano-roosevelt/#medtronic-again</a></p>
<p>R2R is a fight for justice. For the right to decide who fixes your stuff. For the right to set up shop and help your neighbors. For self-reliance and resiliency over profits. For on-shore small businesses over multinational cheaters.</p>
<p>Once again, a wave of R2R laws is sweeping the nation. The monopolists who profiteered off our misery during the pandemic will once again turn out to stop them. PIRG and the Repair Coalition need our support – as do their coalition allies like EFF.</p>
<hr>
<p><a name="poor-doors"></a><br>
<img src="https://i1.wp.com/craphound.com/images/9069359_b10168b971_o.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/craphound.com/images/9069359_b10168b971_o.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>When you hear the phrase "free market," you probably think of "a market that is free from regulation" but that's the opposite of the phrase's original meaning!</p>
<p>Adam Smith used the term to describe a market that was free from "economic rents" – money earned by owning things, rather than doing things. Smith recognized that markets attract parasites – "rentiers" – who seek to drain wealth by "investing" rather than building and doing.</p>
<p>Which meant that, in the absence of muscular state  intervention, markets would become less and less free – more and more dependent on the whims of rentiers who used money to breed money by creating toll-barriers between parts of the productive economy.</p>
<p>For Smith, markets were only free if they were regulated. But that's the opposite of the way that we talk about free markets today. Today, a free market is a market where you are free to collect rents – passive income from owning things, at the expense of people doing things.</p>
<p>This is true in so many metaphorical ways, but it's especially true when we're talking about actual rent – actual homes that people need to survive and produce, whose primary role today is to serve as an asset class to be maximized, not a basic human right.</p>
<p>London is ground zero for the conversion of housing from a human right to a speculative asset, a city at war with itself, filled up with empty safe-deposit boxes in the sky, while productive workers – the "essential workers" of the pandemic – triple-up in substandard housing.</p>
<p>The conversion of London from a city to an asset was hugely profitable, primarily for offshore "investors," especially criminals who were attracted by London's veneer of respectability, which allowed them to convert their loot to legitimate earnings through property sales.</p>
<p>The overslosh of these tremendous cash flows has hopelessly corrupted London's planning authorities, who are absolutely helpless and hopeless at holding developers to their own promises – new builds get extra storeys and shed public concessions without penalty.</p>
<p>And just as the tax-authorities who despair of enforcing against the real cheats turn their efforts to everyday people who can't afford to fight investigations, London's planners spend their days making life miserable for homeowners trying to make minor improvements.</p>
<p>I spent two years fighting Hackney for the right to build a small, windowed greenhouse on my flat's balcony, finally giving up on growing my own veggies. Meanwhile, the for-profit "student residence" across the street replaced hundreds of small offices, overbuilt and busted.</p>
<p>Today, it's a failed Wework, while the four-storey "boutique hotel" across the street has been transformed into eight+ storeys, with multiple storeys of office space, all without any planning enforcement.</p>
<p>The conversion of London into a …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pluralistic.net/2021/02/02/euthanize-rentiers/#poor-doors">https://pluralistic.net/2021/02/02/euthanize-rentiers/#poor-doors</a></em></p>]]>
            </description>
            <link>https://pluralistic.net/2021/02/02/euthanize-rentiers/#poor-doors</link>
            <guid isPermaLink="false">hacker-news-small-sites-26010329</guid>
            <pubDate>Wed, 03 Feb 2021 03:34:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TSLint – An extensible linter for the TypeScript language]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26010213">thread link</a>) | @pabs3
<br/>
February 2, 2021 | https://palantir.github.io/tslint/ | <a href="https://web.archive.org/web/*/https://palantir.github.io/tslint/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>:warning: <strong>TSLint <a href="https://medium.com/palantir/tslint-in-2019-1a144c2317a9">has been deprecated</a> as of 2019</strong>. Please see this issue for more details: <a href="https://github.com/palantir/tslint/issues/4534">Roadmap: TSLint → ESLint</a>. <a href="https://typescript-eslint.io/">typescript-eslint</a> is now your best option for linting TypeScript.</p>

<p>TSLint is an extensible static analysis tool that checks <a href="http://www.typescriptlang.org/">TypeScript</a> code for readability, maintainability, and functionality errors. It is widely supported across modern editors &amp; build systems and can be customized with your own lint rules, configurations, and formatters.</p>

<h2 id="quick-start">Quick start</h2>

<div><div><pre><code><span># Install the global CLI and its peer dependency</span>
yarn global add tslint typescript

<span># Navigate to your sources folder</span>
<span>cd </span>path/to/project

<span># Generate a basic configuration file</span>
tslint <span>--init</span>

<span># Lint TypeScript source globs</span>
tslint <span>-c</span> tslint.json <span>'src/**/*.ts'</span>
</code></pre></div></div>

<p>Check out <a href="https://palantir.github.io/tslint/usage/cli">the full usage guide</a> to learn more.</p>


        

    </div></div>]]>
            </description>
            <link>https://palantir.github.io/tslint/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26010213</guid>
            <pubDate>Wed, 03 Feb 2021 03:19:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Insiders' Game]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26010053">thread link</a>) | @exolymph
<br/>
February 2, 2021 | https://www.persuasion.community/p/the-insiders-game-799 | <a href="https://web.archive.org/web/*/https://www.persuasion.community/p/the-insiders-game-799">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F6c98bd4d-f535-47c1-bd99-7597dd862ac8_6016x4016.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F6c98bd4d-f535-47c1-bd99-7597dd862ac8_6016x4016.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/6c98bd4d-f535-47c1-bd99-7597dd862ac8_6016x4016.jpeg&quot;,&quot;height&quot;:972,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:17806698,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>As the apex predators of capitalism, hedge funds are accustomed to  raking in billions by driving companies into the ground and feasting on  the carcasses. So there was widespread satisfaction last week when  members of an online discussion group called WallStreetBets started  beating the Wall Street bully boys at their own game. Ringleaders of the  group noticed that hedge funds had taken a short position in the  videogame retailer GameStop that <a href="https://www.reddit.com/r/wallstreetbets/comments/ip6jnv/the_real_greatest_short_burn_of_the_century/?utm_source=share&amp;utm_medium=ios_app&amp;utm_name=iossmf">far exceeded</a> the number of shares available to trade. Motivated as much by <a href="https://www.reddit.com/r/wallstreetbets/comments/l6omry/an_open_letter_to_melvin_capital_cnbc_boomers_and/">revenge</a>  as by profit, these influencers in the group encouraged the 2.7 million  members (since risen to around 8 million) to purchase the stock in  order to drive the price higher and create a massive short squeeze. This  quickly became a movement with a cause similar to that of Occupy Wall  Street, except much more effective because it hit the intended target  where they would feel it the most, in the wallet. “The only way to beat a  rigged game,” one WallStreetBets leader <a href="https://www.reddit.com/r/wallstreetbets/comments/ip6jnv/the_real_greatest_short_burn_of_the_century/?utm_source=share&amp;utm_medium=ios_app&amp;utm_name=iossmf">said</a>, “is to rig it even harder.”&nbsp;</p><p>GameStop  stock, which closed at $17.69 a share on Jan. 8, shot up to $347.51 by  the close last Wednesday. With combined losses of almost $20 billion,  hedge funds were on the ropes and close to bleeding out, selling their  longs in an increasingly futile effort to cover their shorts. One fund,  Melvin Capital, <a href="https://www.cnbc.com/2021/01/31/melvin-capital-lost-more-than-50percent-after-betting-against-gamestop-wsj.html">lost over half its value</a> and had to be bailed out by <a href="https://markets.businessinsider.com/news/stocks/steve-cohen-ken-griffin-invest-3-billion-gamestop-short-seller-2021-1-1030003305">hedge fund sugar daddies</a>  Ken Griffin (Citadel) and Steve Cohen (Point 72). An even bigger fund,  Citron, was teetering on the brink of collapse. All this outsider army  needed to win was the continued ability to communicate with each other  online, and their collective ability to keep piling into the “Buy” side  of the trade. Within hours, they would be hobbled on the first front and  crippled on the second.&nbsp;</p><p><strong>The Empire Strikes Back</strong></p><p>First, the digital distribution platform Discord <a href="https://www.theverge.com/2021/1/27/22253251/discord-bans-the-r-wallstreetbets-server">banned</a> the WallStreetBets account after the close Wednesday for “<a href="https://www.businessinsider.com/discord-bans-wallstreetbets-server-hate-speech-reddit-gamestop-gme-2021-1">hate speech, glorifying violence, and spreading misinformation</a>.” (For a moment, it looked like <a href="https://www.reddit.com/r/StockMarket/comments/l6i26r/discord_and_reddit_remove_rwallstreetbets/">Reddit had also banned </a>the  group, but they resisted pressure to do so.) If the quoted  justification sounds familiar, it’s nearly identical to the one given by  Google, Apple, and Amazon for deplatforming Parler just three weeks  earlier. Echoing Amazon, Discord said it had sent the group repeated  warnings about objectionable content before deciding, on that day of all  days, to shut them down.&nbsp;</p><p>Meanwhile, WallStreetBets investors  were locked out of their trading accounts by online brokers such as  Robinhood on Thursday morning. Based on new collateral requirements that  it says were imposed by an industry consortium, Robinhood forbade its  users from buying GameStop and other stocks that WallStreetBets had  identified as short squeeze opportunities. Users were allowed only to  “close their positions”—in other words, to sell to the shorts desperate  to buy. When angry users registered their disapproval by leaving over  100,000 one-star reviews of the Robinhood app in the Google Play Store,  Google <a href="https://www.theverge.com/2021/1/28/22255245/google-deleting-bad-robinhood-reviews-play-store">deleted</a> them.&nbsp;</p><p>Normal  trading was allowed to resume Friday, but the hedge funds used their  24-hour sole ownership of the battlefield to fortify their positions,  covering the most vulnerable shorts. Wall Street then sent in  reinforcements, as new short positions were taken at these high price  levels, virtually guaranteed to pay out when, inevitably, the air leaks  out of the balloon. Faced with a game that, for once, they couldn’t rig  in their favor, it appeared that the insiders tipped the board over and  started a new game. As a massively decentralized online group of scrappy  outsiders, the only tools at WallStreetBets’ disposal were online  trading and social networking. Both were frozen at the crucial moment,  and the hedge fund insiders were let off the hook. The weaponization of  censorship is a big part of the reason why.&nbsp;</p><p><strong>Down the Slippery Slope</strong></p><p>Some of us <a href="https://davidsacks.medium.com/the-speech-cartel-b3f5555f7787">warned</a>  of a slippery slope when Parler was taken down and a sitting president  was systematically ghosted from every online speech platform. But we  could not have foreseen how slippery the slope would be, or how fast we  would slide down it. We were told that the curbs on speech of President  Trump and his supporters were necessary to prevent further  “insurrection” and protect the peaceful transition of power. However,  much like the troops and barricades that still ring the Capitol, these  speech restrictions remain in place well after the transition of power  has occurred. The censorship power is always justified in response to a  genuine outrage or crisis, but it is rarely relinquished once the threat  passes. Rather it gets weaponized to protect powerful, connected  insiders, as the GameStop fiasco illustrates.</p><p>How do we suppose  Discord chose that moment to enforce its “Community Guidelines” against  WallStreetBets? Almost certainly, one of the hedge funds whose ox was  being gored combed through their message boards looking for anything  that might violate the terms of service. And surely they found it, as  these boards contain the same raunchy language you would hear if you  visited any trading floor or boiler room on Wall Street. They presumably  reported the content to Discord, which took the group down.&nbsp;</p><p>Did Discord warn WallStreetBets of content violations before last Wednesday? I’m sure they did. Amazon <a href="https://www.geekwire.com/2021/amazon-responds-parlers-lawsuit-calls-meritless-cites-content-advocating-violence/">sent</a>  such a warning letter to Parler as well. Frankly, such a letter could  be, and likely is, sent to every large message board on the web. The  founder of a user-generated content site described it to me as “the One  Percent Problem.” Every user-generated content site will have a small  percentage of offensive material that gets through, no matter how many  content moderators are hired. For example, Facebook, Twitter, and  YouTube <a href="https://www.vox.com/recode/22221285/trump-online-capitol-riot-far-right-parler-twitter-facebook">allowed far more content</a> advocating for and planning the Capitol riot than Parler. But instead of acknowledging this, they were eager to <a href="https://www.washingtonpost.com/technology/2021/01/13/facebook-role-in-capitol-protest/">blame</a>  the upstart, which had recently taken over the top spot in the social  networking category in the app store. Scapegoating Parler served the  dual purpose of deflecting blame and squashing a competitor.</p><p>Critics  of social networks insist that these sites simply need to double down  on censorship in order to finally rid us of problematic speech. But that  ignores how social media moderation actually works. Algorithms set to  recognize keywords capture only a small fraction of problematic posts,  leaving millions of posts for humans to review. The work is so  voluminous that it’s outsourced to far-flung locales where English may  not even be the first language. Low-level employees must decipher  complicated guidelines while navigating our increasingly Byzantine world  of political and cultural hot-buttons. Mistakes are inevitable, and the  harder a company tightens the standards to get the One Percent Problem  down to 0.1 or 0.01 percent, the more undeserving accounts—from <a href="https://www.newsweek.com/ron-paul-blocked-accessing-facebook-page-over-violating-community-standards-1560639">Ron Paul</a> to the <a href="https://www.wsws.org/en/articles/2021/01/23/pers-j23.html">Socialist Equality Party</a>—will  be swept up in the dragnet. With the Town Square now digitized,  centralized, and privatized in the hands of a cartel of Big Tech  companies, the protections of the First Amendment no longer apply.&nbsp;</p><p><strong>Insiders Vs. Outsiders</strong></p><p>Censorship  is about who has the power to censor, and what checks are placed upon  that power. Right now, tech companies have all the power, and they  exercise it as a like-minded cartel. When we see Alexandria  Ocasio-Cortez and Ted Cruz voice similar concerns over what happened to  WallStreetBets last week, we should realize that the politics of this  issue in the post-Trump era will no longer divide along an axis of Left  and Right, but of insider and outsider.&nbsp;</p><p>Elizabeth Warren, when  she started landing blows against Wall Street after the 2008 financial  crisis, met with President Obama’s economics adviser, the former  treasury secretary and Harvard president Larry Summers. He presented her  with a choice: “I could be an insider or I could be an outsider,” she  recalled in her 2014 memoir, <em>A Fighting Chance</em>. “Outsiders can  say whatever they want. But people on the inside don’t listen to them.  Insiders, however, get lots of access and a chance to push their ideas.  People—powerful people—listen to what they have to say. But insiders  also understand one unbreakable rule: <em>They don’t criticize other insiders</em>.”&nbsp;&nbsp;</p><p>It’s  precisely this insider-protection scheme that the internet and social  media have most disrupted. Insiders are massively powerful but few in  number. Outsiders have always been numerous but unorganized. Social  networking and online organizing have given the outsiders real power to  effect change, and finally register their disgust at the way incompetent  elites protect each other. The elites of Big Business, Big Media, Wall  Street, and Washington are terrified of this, and will leverage any  censorship power to keep the outsiders at bay.&nbsp;</p><p><strong>The Real “Big Lie”</strong></p><p>After  the storming of the Capitol building on Jan. 6, we heard a lot about  the “Big Lie” perpetrated by Trump and his allies that the election was  “stolen.” In reality, this narrative never got far. It was rejected by  the media (including Fox News), thrown out by the courts, labeled by  social networks as “disputed,” and dismissed by politicians, including  Trump’s own vice president. Yes, some far-right groups like the Proud  Boys and Oath Keepers came to Washington to commit acts of violence, but  they were roundly denounced. For a Big Lie to be successful, it has to  have buy-in from the people in power, moneyed interests, the  narrative-framers in the media generally, all of whom have to benefit  from the lie and therefore repeat it.&nbsp;</p><p>But what issue could  possibly unite all of these constituencies? For several years, elites in  the media, government, and now finance have denounced social media as a  tool for propaganda, disinformation and hate. Social media was to blame  for the Russian disinformation that supposedly elected Trump in 2016.  Social …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.persuasion.community/p/the-insiders-game-799">https://www.persuasion.community/p/the-insiders-game-799</a></em></p>]]>
            </description>
            <link>https://www.persuasion.community/p/the-insiders-game-799</link>
            <guid isPermaLink="false">hacker-news-small-sites-26010053</guid>
            <pubDate>Wed, 03 Feb 2021 02:56:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sputnik V vaccine peer reviewed with efficacy of 91.6%]]>
            </title>
            <description>
<![CDATA[
Score 66 | Comments 64 (<a href="https://news.ycombinator.com/item?id=26009932">thread link</a>) | @The_rationalist
<br/>
February 2, 2021 | https://sputnikvaccine.com/newsroom/pressreleases/a-vaccine-for-all-mankind-sputnik-v-s-efficacy-in-fighting-covid-19-is-validated-by-internationally-/ | <a href="https://web.archive.org/web/*/https://sputnikvaccine.com/newsroom/pressreleases/a-vaccine-for-all-mankind-sputnik-v-s-efficacy-in-fighting-covid-19-is-validated-by-internationally-/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<ul>
<li>
<p>
In an interim analysis of a Phase III clinical trial, Sputnik V <b>showed strong efficacy, immunogenicity and safety results.</b>
</p>
</li>
<li>
<p>
<b>Efficacy of Sputnik V against COVID-19 was reported at 91.6%.</b>
</p>
<ul>
<li>
<p>
Analysis included data on 19,866 volunteers, who received both the first and second doses of the Sputnik V vaccine or placebo at the final control point of 78 confirmed COVID-19 cases.
</p>
</li>
<li>
<p>
Efficacy in the elderly group of 2,144 volunteers over 60 years old was 91.8% and did not differ statistically from the 18-60 group.
</p>
</li>
</ul>
</li>
<li>
<p>
<b>Sputnik V provides full protection against severe cases of COVID-19.</b>
</p>
</li>
<li>
<p>
<b>Among the cases analyzed, over 98% of volunteers developed humoral immune response and 100% - cellular immune response.</b>
</p>
</li>
<li>
<p>
<b>The level of virus neutralizing antibodies of volunteers vaccinated with Sputnik V is 1.3-1.5 times higher</b> than the level of antibodies of patients who recovered from COVID-19.
</p>
</li>
<li>
<p>
<b>Excellent safety profile. Most adverse events (94%) were mild</b> and included flu-like syndromes, injection site reactions, headache and asthenia.
</p>
<ul>
<li>
<p>
<b>No serious adverse events associated with vaccination, as confirmed by Independent Data Monitoring Committee.</b>
</p>
</li>
<li>
<p>
<b>No strong allergies, no anaphylactic shock.</b>
</p>
</li>
</ul>
</li>
<li>
<p>
<b>Sputnik V is one of the three vaccines in the world with efficacy of over 90%. Furthermore, Sputnik V stands out among these vaccines thanks to a number of key advantages:</b>
</p>
<ul>
<li>
<p>
<b>Based on a platform of human adenoviral vectors proven to be safe over decades of use.</b>
</p>
</li>
<li>
<p>
<b>Easy distribution worldwide: storage temperature of between two and eight degrees Celsius.</b>
</p>
</li>
<li>
<p>
<b>One of the most affordable vaccines in the world with a price of less than $10 per shot.</b>
</p>
</li>
</ul>
</li>
<li>
<p>
<b>Sputnik V is already registered in 16 countries:</b> Russia, Belarus, Serbia, Argentina, Bolivia, Algeria, Palestine, Venezuela, Paraguay, Turkmenistan, Hungary, UAE, Iran, Republic of Guinea, Tunisia and Armenia.
</p>
</li>
<li>
<p>
<b>In the first week of February, vaccination with Sputnik V will start in the following 12 countries:</b> Bolivia, Kazakhstan, Turkmenistan, Palestine, UAE, Paraguay, Hungary, Armenia, Algeria, Bosnian Serb Republic, Venezuela and Iran.
</p>
<ul>
<li>
<p>
<b>In 10 countries out of 12, Sputnik V will be the first coronavirus vaccine approved for civil circulation.</b>
</p>
</li>
</ul>
</li>
</ul>
<p>
<b>Moscow, February 2, 2021</b> – The Gamaleya National Research Center of Epidemiology and Microbiology of the Ministry of Health of the Russian Federation and the Russian Direct Investment Fund (RDIF, Russia’s sovereign wealth fund) announce that the Lancet, one of the world's oldest and most respected medical journals, has published interim results of a Phase III clinical trial of Sputnik V, confirming the vaccine’s high efficacy and safety. Sputnik V, which is based on a well-studied human adenoviral vectors platform, is the world’s first registered vaccine against coronavirus.
</p>
<p>
In the interim efficacy analysis of the randomized, double-blind, placebo-controlled clinical trial, where data on 19,866 volunteers were included in the efficacy analysis (14,964 of whom received the vaccine and 4,902 the placebo), the two-dose treatment of Sputnik V administered 21 days apart demonstrated efficacy of 91.6% against COVID-19. The calculation is based on the analysis of 78 confirmed cases of COVID-19 identified in the placebo group (62 cases) and in the vaccine group (16 cases). Sputnik V generated a robust humoral and cell mediated immune response.
</p>
<p>
<b>Alexander Gintsburg, Director of the Gamaleya Research Institute of Epidemiology and Microbiology,</b> said:
</p>
<p>
“The publication of internationally peer reviewed data on Sputnik V’s clinical trial results is a great success in the global battle against the COVID-19 pandemic. The Russian vaccine’s safety and high efficacy are shown by the hard scientific data presented and I congratulate the entire team of Gamaleya National Research Center for this monumental achievement. Several vaccines have already been created based on human adenoviruses and this tool is one of the most promising for development of new vaccines in the future.”
</p>
<p>
<b>Kirill Dmitriev, CEO of the Russian Direct Investment Fund,</b> commented:
</p>
<p>
“This is a great day in the fight against the COVID-19 pandemic. The data published by The Lancet proves that not only Sputnik V is the world’s first registered vaccine, but also one of the best. It fully protects against severe COVID-19 according to data which has been independently compiled and reviewed by peers and then published in The Lancet. Sputnik V is one of only three vaccines in the world with efficacy of over 90% but outperforms them in terms of safety, ease of transportation due to storage requirements of +2 to +8 degrees and a more affordable price. Sputnik V is a vaccine for all mankind.”
</p>
<p>
<b>Hildegund C.J. Ertl, M.D., Professor, Vaccine &amp; Immunotherapy Center, The Wistar Institute, USA,</b> said:
</p>
<p>
“The vaccine is 100% effective in preventing serious disease or death, which in the end is the most crucial parameter; we can all deal with the sniffles as long as we stay out of the hospital or the graveyard. Even after a single dose of this prime-boost regimen protection against disease was at 87.6%. Sputnik V is thus more effective than the AstraZeneca or Johnson&amp;Johnson. Sputnik V, which, unlike the equally efficacious RNA vaccines of Pfizer and Moderna, can be stored in the fridge, will be of tremendous value to combat the global COVID-19 pandemic.”
</p>
<p>
<b>Cecil Czerkinsky, PhD, M.D., Research Director, National Institute of Health and Medical research (Inserm), France,</b> said:
</p>
<p>
“The interim results of the phase 3 clinical trial of Sputnik V COVID adenovirus vector vaccine are fairly impressive. This vaccine appears to be highly efficacious and immunogenic across age groups. This is clearly good news as this dual formulation vaccine is comparatively easy to manufacture and to deploy amid the anticipated global shortage of vaccines and logistical problems in vaccination roll-out of temperature-sensitive vaccines recently authorized for emergency use.”
</p>
<p>
<b>Omar Sued, President of the Society of infectologists, Argentina,</b> said:
</p>
<p>
“The paper, published in The Lancet, confirms successful results and provides additional information about the efficacy and the safety of this vaccine in different subgroups. From the public health´s point of view, the efficacy of the vaccine was very high. The safety profile was very good. The dissemination of this information is vital for informing the scaling up and rollout of this vaccine worldwide.”
</p>
<p>
<b>David Livermore, Professor of Medical Microbiology at the University of East Anglia, UK,</b> said:
</p>
<p>
“Presently the world needs all the good vaccines that it can get against COVID-19. And these are impressive results: Sputnik V is the first adenovirus vector vaccine to achieve the 90% efficacy seen with the two mRNA vaccines.”
</p>
<p>
According to the peer-reviewed study results, the vaccine provides full protection against severe cases of the novel coronavirus infection. Among the confirmed severe cases of COVID-19, 20 were recorded in the placebo group, while none were recorded in the vaccine group. Due to the time needed for the immune response to develop, in the first week after vaccination there was no significant difference in protection against severe cases of COVID-19 between the vaccine and placebo groups, while in the period from 7 to 14 days the vaccine’s efficacy rose to 50%, in the period from 14 to 21 days to 74.1%, and to 100% from the 21st day, giving full protection against severe cases of the coronavirus.
</p>
<p>
Importantly, the study included 2,144 volunteers over 60 years old with the maximum ages of 87 years (vaccine group) and 84 years (placebo group), showing great safety results for the elder age strata. The vaccine’s efficacy for the elderly was shown at 91.8% and did not differ statistically from the group of 18-60 years old, also demonstrating great safety and immunogenicity results.
</p>
<p>
Sputnik V has demonstrated an excellent safety profile: 70 episodes of serious adverse events (SAE) not related to COVID-19 were recorded in 68 study participants: in 45 volunteers from the vaccine group and 23 volunteers from the placebo group. None of these events were associated with the vaccination as confirmed by Independent Data Monitoring Committee. Most adverse events (94%) were mild and were limited to flu-like syndromes, injection site reactions, headache and asthenia.
</p>
<p>
Sputnik V is one of only three vaccines in the world to have demonstrated efficacy of over 90%. Sputnik V stands out among these vaccines thanks to a number of key advantages, namely: a well-studied and highly efficient human adenoviral vector mechanism proven safe over decades; the vaccine’s low cost in comparison to other approaches; and fewer logistics requirements with a storage temperature of between two to eight degrees Celsius allowing for easier distribution worldwide.
</p>
<p>
The safety of vaccines based on human adenoviruses has been confirmed in more than 75 international publications and more than 250 clinical trials conducted during the past two decades - while the history of use of human adenoviruses in vaccine development started in 1953. Adenovirus vectors are genetically modified viruses of the regular flu that cannot reproduce in a human body. When the Sputnik V vaccine is used, the coronavirus itself does not enter the body as the vaccine only contains genetic information about part of its outer protein coat, the so called "spikes" forming its crown. This completely eliminates the possibility of getting infected as a result of vaccination while also causing the body to generate a stable immune response.
</p>
<p>
In addition, Sputnik V uses two different vectors - based on human adenovirus serotypes Ad5 and Ad26 - in two separate shots, allowing for a more effective defense against the coronavirus than vaccines using the same vector for both shots. By deploying two different vectors, Sputnik V avoids a possible neutralizing effect and generates a durable and longer-lasting immune response.
</p>
<p>
***
</p>
<p>
<b>The …</b></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sputnikvaccine.com/newsroom/pressreleases/a-vaccine-for-all-mankind-sputnik-v-s-efficacy-in-fighting-covid-19-is-validated-by-internationally-/">https://sputnikvaccine.com/newsroom/pressreleases/a-vaccine-for-all-mankind-sputnik-v-s-efficacy-in-fighting-covid-19-is-validated-by-internationally-/</a></em></p>]]>
            </description>
            <link>https://sputnikvaccine.com/newsroom/pressreleases/a-vaccine-for-all-mankind-sputnik-v-s-efficacy-in-fighting-covid-19-is-validated-by-internationally-/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26009932</guid>
            <pubDate>Wed, 03 Feb 2021 02:38:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding Integration Testing in React]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26009823">thread link</a>) | @rozenmd
<br/>
February 2, 2021 | https://testingreactjs.com/understanding-integration-testing-react | <a href="https://web.archive.org/web/*/https://testingreactjs.com/understanding-integration-testing-react">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Do you sometimes worry that your tests don't make sense? Struggling to <em>get</em> what people mean by "test from the user's perspective" and the classic piece of advice "test functionality, not implementation details"?</p><p>You're not alone!</p><p>I felt the same thing when I moved from Enzyme to React Testing Library. I used to think of testing as just checks you had to do on individual components, directly asserting against props and state, and would struggle to think about how to test the integration of several components together.</p><h2 id="what-does-integration-test-even-mean"><a href="#what-does-integration-test-even-mean" aria-label="understanding integration testing react permalink"></a>What does "integration test" even mean?</h2><p>It helps to think of integration testing like a bigger unit test, except the unit you're testing is the combination of several smaller components.</p><p>More concretely, instead of just testing a <code>Button</code> component, or a <code>TextField</code> component in isolation, we're going to test that they work when placed together into a form.</p><h2 id="lets-get-started"><a href="#lets-get-started" aria-label="understanding integration testing react permalink"></a>Let's get started!</h2><p>We're going to be testing a form almost every public web app you're going to build has: a Login form. It's probably one of the most important parts of your app (in terms of business value), so let's be confident it actually works!</p><p><img src="https://testingreactjs.com/assets/understanding-integration-testing-react/react-login-form.png" alt="React Login Form"></p><h2 id="setup"><a href="#setup" aria-label="understanding integration testing react permalink"></a>Setup</h2><p>We're going to be using <a href="https://reactjs.org/docs/create-a-new-react-app.html">create-react-app</a>, because it comes bundled with <a href="https://testing-library.com/docs/react-testing-library/intro">@testing-library/react</a>. I'm also using <a href="https://react-hook-form.com/">react-hook-form</a> to build our form, because it's the quickest way I could think of to display the form data in our web app.</p><p>You can either:</p><ol><li>Clone the <a href="https://github.com/rozenmd/react-integration-testing">repo</a></li><li>Follow the steps <a href="#manual-steps">below</a> to set this up manually (you'll still need to download the <a href="https://github.com/rozenmd/react-integration-testing">repo</a>)</li></ol><h3 id="manual-steps"><a href="#manual-steps" aria-label="understanding integration testing react permalink"></a>Manual steps</h3><ol><li><p>Run:</p><div><pre data-language="bash"><p><span>npx create-react-app </span><span>&lt;</span><span>YOUR_APP_NAME</span><span>&gt;</span><span></span></p></pre></div></li><li><p>Run:</p></li><li><p>[Only for react-hook-form]<!-- --> Run:</p><div><pre data-language="bash"><p><span>yarn</span><span> </span><span>add</span><span> react-hook-form mutationobserver-shim</span></p><p><span></span><span>npm</span><span> </span><span>install</span><span> react-hook-form mutationobserver-shim</span></p></pre></div></li><li><p>[Only for react-hook-form]<!-- --> In <code>src/setupTests.js</code>, in a new line, add <code>import 'mutationobserver-shim';</code></p></li><li><p>Copy the <code>src/</code> directory from the <a href="https://github.com/rozenmd/react-integration-testing">repo</a> into your <code>src/</code> directory, overriding existing files</p></li><li><p>Run:</p><p>You should see something like this: <img src="https://testingreactjs.com/assets/understanding-integration-testing-react/react-login-form-before.png" alt="React Login Form after starting"></p></li><li><p>At this point, if you ran <code>yarn test</code>, you would see the following:</p></li></ol><div><pre><p><span> PASS  src/pages/Login.test.js</span></p><p><span>  ✓ renders all inputs (75ms)</span></p><p><span>  ✓ integration test (110ms)</span></p><p><span>Test Suites: 1 passed, 1 total</span></p><p><span>Tests:       2 passed, 2 total</span></p><p><span>Snapshots:   0 total</span></p><p><span>Time:        3.883s</span></p><p><span>Ran all test suites.</span></p><p><span>Watch Usage: Press w to show more.</span></p></pre></div><h2 id="so-how-do-we-get-here"><a href="#so-how-do-we-get-here" aria-label="understanding integration testing react permalink"></a>So how do we get here?</h2><p>Let's start off with a render test:</p><div><pre data-language="jsx"><p><span>import</span><span> React </span><span>from</span><span> </span><span>'react'</span><span>;</span><span></span></p><p><span></span><span>import</span><span> </span><span>{</span><span> render </span><span>}</span><span> </span><span>from</span><span> </span><span>'@testing-library/react'</span><span>;</span><span></span></p><p><span></span><span>import</span><span> Login </span><span>from</span><span> </span><span>'./Login'</span><span>;</span><span></span></p><p><span></span><span>test</span><span>(</span><span>'renders all inputs'</span><span>,</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>const</span><span> </span><span>{</span><span> getByLabelText </span><span>}</span><span> </span><span>=</span><span> </span><span>render</span><span>(</span><span>&lt;</span><span>Login</span><span> </span><span>/&gt;</span><span>)</span><span>;</span><span></span></p><p><span>  </span><span>const</span><span> userInput </span><span>=</span><span> </span><span>getByLabelText</span><span>(</span><span>/username/i</span><span>)</span><span>;</span><span></span></p><p><span>  </span><span>expect</span><span>(</span><span>userInput</span><span>)</span><span>.</span><span>toBeInTheDocument</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span>  </span><span>const</span><span> passwordInput </span><span>=</span><span> </span><span>getByLabelText</span><span>(</span><span>/password/i</span><span>)</span><span>;</span><span></span></p><p><span>  </span><span>expect</span><span>(</span><span>passwordInput</span><span>)</span><span>.</span><span>toBeInTheDocument</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span></span><span>}</span><span>)</span><span>;</span><span></span></p></pre></div><p>It's not the most complicated test out there, and it's already giving us benefits beyond what a unit test would give. It's also technically an integration test.</p><p>In particular, we're saying "on my login form, I want a username input to be visible at the same time as the password input".</p><p>Now let's test the happy path of our login form:</p><div><pre data-language="jsx"><p><span>import</span><span> React </span><span>from</span><span> </span><span>'react'</span><span>;</span><span></span></p><p><span></span><span>import</span><span> </span><span>{</span><span> render</span><span>,</span><span> fireEvent </span><span>}</span><span> </span><span>from</span><span> </span><span>'@testing-library/react'</span><span>;</span><span></span></p><p><span></span><span>import</span><span> user </span><span>from</span><span> </span><span>'@testing-library/user-event'</span><span>;</span><span></span></p><p><span></span><span>import</span><span> Login </span><span>from</span><span> </span><span>'./Login'</span><span>;</span><span></span></p><p><span></span><span>test</span><span>(</span><span>'integration test'</span><span>,</span><span> </span><span>async</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>const</span><span> </span><span>USER</span><span> </span><span>=</span><span> </span><span>'some-username'</span><span>;</span><span></span></p><p><span>  </span><span>const</span><span> </span><span>PASS</span><span> </span><span>=</span><span> </span><span>'some-pass'</span><span>;</span><span></span></p><p><span>  </span><span>const</span><span> </span><span>{</span><span> getByLabelText</span><span>,</span><span> findByText</span><span>,</span><span> getByText </span><span>}</span><span> </span><span>=</span><span> </span><span>render</span><span>(</span><span>&lt;</span><span>Login</span><span> </span><span>/&gt;</span><span>)</span><span>;</span><span></span></p><p><span>  </span><span>const</span><span> userInput </span><span>=</span><span> </span><span>getByLabelText</span><span>(</span><span>/username/i</span><span>)</span><span>;</span><span></span></p><p><span>  user</span><span>.</span><span>type</span><span>(</span><span>userInput</span><span>,</span><span> </span><span>USER</span><span>)</span><span>;</span><span></span></p><p><span>  </span><span>const</span><span> passwordInput </span><span>=</span><span> </span><span>getByLabelText</span><span>(</span><span>/password/i</span><span>)</span><span>;</span><span></span></p><p><span>  user</span><span>.</span><span>type</span><span>(</span><span>passwordInput</span><span>,</span><span> </span><span>PASS</span><span>)</span><span>;</span><span></span></p><p><span>  </span><span>const</span><span> submitButton </span><span>=</span><span> </span><span>getByText</span><span>(</span><span>/submit/i</span><span>)</span><span>;</span><span></span></p><p><span>  fireEvent</span><span>.</span><span>click</span><span>(</span><span>submitButton</span><span>)</span><span>;</span><span></span></p><p><span>  </span><span>expect</span><span>(</span><span>await</span><span> </span><span>findByText</span><span>(</span><span>/your username/i</span><span>)</span><span>)</span><span>.</span><span>toBeInTheDocument</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span>  </span><span>expect</span><span>(</span><span>await</span><span> </span><span>findByText</span><span>(</span><span>/your password/i</span><span>)</span><span>)</span><span>.</span><span>toBeInTheDocument</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span></span><span>}</span><span>)</span><span>;</span><span></span></p></pre></div><p>This integration test builds on top of our initial test in a few ways:</p><ul><li>We've imported the <code>'@testing-library/user-event'</code> library to allow us to type into our inputs</li><li>We've imported <code>fireEvent</code> from the <code>'@testing-library/react'</code> library to allow us to click on our <code>Button</code> component</li><li>We've marked the test <code>async</code> to enable us to use <code>findByText()</code><ul><li>findByText is neat because it returns a Promise, letting us wait until it finds the text it's looking for before continuing</li></ul></li><li>Most importantly, we've built a test that can type into our <code>TextField</code> components, click on our <code>Button</code> component, and trigger the <code>Form</code> component's <code>onSubmit</code> function!</li></ul><p>If you're confused about <code>findByText</code> vs <code>getByText</code>, don't worry - that's normal. React Testing Library's <a href="https://testing-library.com/docs/react-testing-library/cheatsheet">cheatsheet</a> has tips to help you decide which one to use.</p><h2 id="conclusion"><a href="#conclusion" aria-label="understanding integration testing react permalink"></a>Conclusion</h2><p>You've just started to understand integration testing, but you best believe there's a lot more to it than this article!</p><p>If you want a more advanced perspective of integration testing your forms, I highly recommend reading the testing section of React Hook Form's <a href="https://react-hook-form.com/advanced-usage/#TestingForm">Advanced Usage</a> guide.</p></div></div></div>]]>
            </description>
            <link>https://testingreactjs.com/understanding-integration-testing-react</link>
            <guid isPermaLink="false">hacker-news-small-sites-26009823</guid>
            <pubDate>Wed, 03 Feb 2021 02:21:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cool SaaS Tools on Mac]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26009736">thread link</a>) | @yusuf_giftworks
<br/>
February 2, 2021 | https://yusuf.is/captivated-by-software | <a href="https://web.archive.org/web/*/https://yusuf.is/captivated-by-software">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><article id="block-captivated-by-software"><div><div><p><span>Description</span></p><p><span><span>Thought you might like these</span></span></p></div></div><h2 id="block-6167001744994c60afb8d57462bb1f05"><span id="6167001744994c60afb8d57462bb1f05"></span><span><span><a href="https://raycast.com/" target="_blank" rel="noopener noreferrer"><strong>Raycast</strong></a></span></span></h2><p><span><span>Raycast is like your Mac Spotlight got infected by a radioactive virus and gained superpowers.</span></span></p><p><span><span>As a Spotlight replacement, here are a few things that you can do on Raycast, but you can't with Spotlight: Calculate the numbers of days left between 2 dates, view calendar events, view clipboard history, search files in Google Drive, view Bitcoin price, connect to GitHub, change system theme with a keyboard shortcut, schedule and start Zoom meetings, toggle repeat on Apple Music, restart computer, copy lorem ipsum text, run your own command scripts, and many, many more.</span></span></p><div id="block-8e881152c1a24ad097ea3644de666b0d"><div><p><img alt="image" src="https://yusuf.is/_next/image?url=https%3A%2F%2Fapi.super.so%2Fasset%2Fyusuf.is%2F6de5ee65-81e2-4dd2-af29-c24b494bf4a7.png&amp;w=2048&amp;q=100" srcset="https://yusuf.is/_next/image?url=https%3A%2F%2Fapi.super.so%2Fasset%2Fyusuf.is%2F6de5ee65-81e2-4dd2-af29-c24b494bf4a7.png&amp;w=750&amp;q=100 1x, https://yusuf.is/_next/image?url=https%3A%2F%2Fapi.super.so%2Fasset%2Fyusuf.is%2F6de5ee65-81e2-4dd2-af29-c24b494bf4a7.png&amp;w=1920&amp;q=100 2x, https://yusuf.is/_next/image?url=https%3A%2F%2Fapi.super.so%2Fasset%2Fyusuf.is%2F6de5ee65-81e2-4dd2-af29-c24b494bf4a7.png&amp;w=2048&amp;q=100 3x" decoding="async"></p></div></div><h2 id="block-b9eacda0d6044cffa2dd0126777298c3"><span id="b9eacda0d6044cffa2dd0126777298c3"></span><span><span><a href="https://www.yourtempo.co/" target="_blank" rel="noopener noreferrer"><strong>Tempo</strong></a></span></span></h2><p><span><span>Tempo is like using a classic typewriter to send email on a beautiful evening by the lake.</span></span></p><p><span><span>Arguably one of the most beautifully designed and well-thought email client, Tempo solves your email fatigue by sorting your emails in batches. This means that all of your emails are bundled together and snoozed until the time you set to read them.</span></span></p><p><span><span>One of the best features of Tempo, however, is the Focus Mode. Whenever you received an email that requires you to think carefully before you reply, enter Focus Mode. The interface is so clean and distraction-free, the act of replying to an email feels magical. Sometimes, you just wish you would have an email to reply just to experience the zen-like moment.</span></span></p><div id="block-92d42c14be2a4f1399b123a77035b252"><div><p><img alt="image" src="https://yusuf.is/_next/image?url=https%3A%2F%2Fapi.super.so%2Fasset%2Fyusuf.is%2F77f761c9-5529-4587-bd30-8ce922a44cc9.png&amp;w=3840&amp;q=100" srcset="https://yusuf.is/_next/image?url=https%3A%2F%2Fapi.super.so%2Fasset%2Fyusuf.is%2F77f761c9-5529-4587-bd30-8ce922a44cc9.png&amp;w=1920&amp;q=100 1x, https://yusuf.is/_next/image?url=https%3A%2F%2Fapi.super.so%2Fasset%2Fyusuf.is%2F77f761c9-5529-4587-bd30-8ce922a44cc9.png&amp;w=3840&amp;q=100 2x" decoding="async"></p></div></div><h2 id="block-433a05c2462946b684309d8b3606abdb"><span id="433a05c2462946b684309d8b3606abdb"></span><span><span><a href="https://linear.app/" target="_blank" rel="noopener noreferrer"><strong>Linear</strong></a></span></span></h2><p><span><span>Linear is like PS5 for project management professionals.</span></span></p><p><span><span>Being marketed as the issue tracking tool for software teams, my use of Linear is probably an outlier. I use Linear as a personal project management and productivity tool.</span></span></p><p><span><span>It has everything productivity nerds can ever wish for; blazing speed, elegant user interface, theme customizability, integration with 3rd party tools, global command line, keyboard shortcuts for everything, thoughtful design and workflow, team features, activity history, offline mode, and the list goes on.</span></span></p><div id="block-3874ec2ff2be458a8e4c9daccdea945f"><div><p><img alt="image" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div></div><h2 id="block-a407ba184b11473d978fd2d7a4a91468"><span id="a407ba184b11473d978fd2d7a4a91468"></span><span><span><a href="https://pitch.com/" target="_blank" rel="noopener noreferrer"><strong>Pitch</strong></a></span></span></h2><p><span><span>Pitch is like creating slide presentations for your significant other.</span></span></p><p><span><span>Aside from the delightful 3-D image assets, Pitch is a robust presentation software for teams and individuals. Creating slides in Pitch feels less stressful and is surprisingly very fun. The bright interface makes the editing environment a pleasant experience to work in. If you are a keyboard master, you will appreciate the quick menu feature and keyboard shortcuts. If you are not, you should try to become one because these features will transform the way you work with slides.</span></span></p><div id="block-86391a83f82d44cdac27eb2837b9baf6"><div><p><img alt="image" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div></div><h2 id="block-e5fc14edba984ebc82cff236e99cfc17"><span id="e5fc14edba984ebc82cff236e99cfc17"></span><span><span><a href="https://spline.design/" target="_blank" rel="noopener noreferrer">Spline</a></span></span></h2><p><span><span>Spline is like Disney Land for 3-D illustrators</span></span></p><p><span><span>If you ever wanted to try creating cute and modern 3-D illustrations on your own for your projects, Spline makes it so easy to start. No prior design knowledge needed. It is that simple to use. If you have no idea what to create as a starting point, Spline has a gallery of templates designed by them and other talented illustrators, free to use.</span></span></p><div id="block-7b03b62cf8af47729e04c436e9fac006"><div><p><img alt="image" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div></div><h2 id="block-f9abbf67835d4268b982fcf32d64db53"><span id="f9abbf67835d4268b982fcf32d64db53"></span><span><span><a href="http://workflowy.com/" target="_blank" rel="noopener noreferrer"><strong>Workflowy</strong></a></span></span></h2><p><span><span>Workflowy is like a luxury playground for your thoughts.</span></span></p><p><span><span>On a very clean interface, you start with a bullet point and expand your thoughts from there. Each bullet point in Workflowy is a document. You can go as deep as you want and link each bullet to connect the dots. It's the ideal host for your modern digital garden.</span></span></p><div id="block-22b0dae40f394628a63221f70ebd4e94"><div><p><img alt="image" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div></div><h2 id="block-6bb7c648eb584385941e6fcc6e529dc8"><span id="6bb7c648eb584385941e6fcc6e529dc8"></span><span><span><a href="https://www.meetsidekick.com/" target="_blank" rel="noopener noreferrer"><strong>Sidekick</strong></a></span></span></h2><p><span><span>Sidekick is like Google Chrome’s Batman.</span></span></p><p><span><span>If you ever feel Google Chrome is draining and slowing your Mac down, you are going to appreciate Sidekick. Sidekick is a Chromium-based browser with a built-in productivity suite. Beautiful search command to find tabs and files, use multiple YouTube accounts in the same window, create personal and work workspaces, a built-in ad-blocker, finger-printing defense, and more.</span></span></p><div id="block-75ed3fde3da74a81bdee5036fbdfca01"><div><p><img alt="image" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div></div><p><span><span>There you go, I hope you liked it.</span></span></p><p><span><span><code>Happy to chat</code></span></span></p><ul><li id="block-4aebbc3cacbf40f78fabcf907f664af5"><span><span>Tweet me on </span><span><a href="https://twitter.com/yusufgiftworks" target="_blank" rel="noopener noreferrer">Twitter</a></span></span></li></ul></article></div></div></div>]]>
            </description>
            <link>https://yusuf.is/captivated-by-software</link>
            <guid isPermaLink="false">hacker-news-small-sites-26009736</guid>
            <pubDate>Wed, 03 Feb 2021 02:02:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Amazon won't spin off AWS, and that's too bad for AWS (2019)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26009599">thread link</a>) | @forrestbrazeal
<br/>
February 2, 2021 | https://forrestbrazeal.com/2019/07/24/cloud-irregular-amazon-wont-spin-off-aws-and-thats-too-bad-for-aws/ | <a href="https://web.archive.org/web/*/https://forrestbrazeal.com/2019/07/24/cloud-irregular-amazon-wont-spin-off-aws-and-thats-too-bad-for-aws/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <section>
          <section>
              

              
              
              <article>
                  

<p><img src="https://forrestbrazeal.com/images/cloud-irregular.png" alt="cloud-irregular"></p>

<p><em>In each issue of the “Cloud Irregular” newsletter, I’ll try to provide a useful piece of commentary on some tech-related topic. After that I’ll let you know about any new stuff I’ve published, or upcoming talks. Then I’ll give you something extremely silly, just to cleanse your palate, and we’ll be done.</em></p>

<p><em>Sound good? If so, throw in your email at the bottom of this post.</em></p>

<h3 id="amazon-won-t-spin-off-aws-and-that-s-too-bad-for-aws">Amazon won’t spin off AWS, and that’s too bad for AWS</h3>

<p>First let’s make one thing perfectly clear: Amazon and AWS are not splitting up. AWS CEO Andy Jassy has <a href="https://www.cnbc.com/2019/06/11/aws-ceo-we-would-follow-the-law-if-regulators-demand-amazon-spin-out.html">repeatedly avowed</a> that the only way AWS will ever leave the mothership is if federal regulators feed him feet first into a wood chipper.</p>

<p>On one level, this makes sense. AWS still generates something like <a href="https://www.cnbc.com/2019/04/25/aws-earnings-q1-2019.html">half of Amazon’s operating income</a>. Amazon can wrap its tentacles around every facet of the consumer experience because of the big dollars rolling in from its cloud business. AWS’s dominance fuels big AMZN share prices and funds new innovation, etc, etc. We get it: Amazon will let go of AWS when you pry it from <a href="https://www.telegraph.co.uk/technology/2017/07/28/biceps-billionaire-doesnt-matter-jeff-bezos-not-worlds-richest/">Jeff Bezos’ weirdly fearsome biceps</a>.</p>

<p>That’s what AWS does for Amazon. But what does Amazon do for AWS? Increasingly, as far as I can tell, bad things.</p>

<p>Let’s lay aside for a moment the whole regulatory question, whether AWS and Amazon will someday be trust-busted and broken up by force. The 2020 presidential candidates can <a href="https://www.nytimes.com/2019/03/08/us/politics/elizabeth-warren-amazon.html">hash that out</a>. Amazon is causing other political problems for AWS already.</p>

<p>Look, Amazon is huge; it’s owned by the richest man in the world, who increasingly owns <a href="https://www.marketwatch.com/story/its-not-just-amazon-and-whole-foods-heres-jeff-bezos-enormous-empire-in-one-chart-2017-06-21">other things</a> as well. That means bad vibes from some other venture can poison AWS deals.</p>

<p>Remember <a href="https://defensesystems.com/articles/2018/07/26/jedi-hits-the-street.aspx">JEDI</a>, that $10 billion single-vendor Department of Defense contract AWS has been craving for what seems like years? Apparently the whole bid process <a href="https://www.theregister.co.uk/2019/07/18/jedi_cloud_donald_trump/">is now on hold</a>, not because of anything AWS did wrong, but because, well, Jeff Bezos also owns the Washington Post, which Donald Trump does not appreciate, and so it’s all a mess. (Also, I love that Oracle has been apparently fomenting all this strife via Machiavellian backstage dealings, which I guess is Oracle’s whole brand now.)</p>

<p>There’s also the issue of AWS selling technology, directly or indirectly, to government agencies and police forces who use it for dubious purposes like <a href="https://www.theverge.com/2018/6/22/17492106/amazon-ice-facial-recognition-internal-letter-protest">facial recognition</a>. Werner Vogels’ recent AWS Summit keynote address suffered <a href="https://www.wsj.com/articles/protesters-disrupt-amazon-event-over-its-ties-with-ice-11562882825">no fewer than five interruptions</a> from protesters angry that AWS services support the operations of US Immigrations and Customs Enforcement (ICE).</p>

<p>While this might seem to be AWS’s problem, I guarantee that the name recognition of Amazon among everyday consumers drives a lot of the public outrage. (That’s why you often see Amazon-dot-com protests misdirected at AWS events. I’ve seen protesters interrupt an AWS summit with signs and shouts about Amazon warehouse conditions. The lines are blurry and it’s no wonder people get confused.)</p>

<p>Take Amazon out of the equation, and for better or worse the scrutiny of AWS goes down. To put it another way, there’s like a 50% chance that anyone running a big Oracle cluster at this point is a supervillain, but you don’t see Oracle getting protested.</p>

<p>Leaving aside the public sector issues, we have Gartner’s new magic quadrant report (I know, stay with me) <a href="https://www.crn.com.au/news/aws-azure-and-google-top-gartners-iaas-magic-quadrant-528501">reminding us</a> that many companies, particularly retailers, are now eschewing AWS out of an existential fear that they are funneling dollars indirectly to their biggest competitor. <a href="https://www.geekwire.com/2018/least-one-retailer-online-outlet-zulily-still-willing-sign-amazon-web-services/">Walmart, Target, and Kroger</a> are all notorious for their no-AWS tech policies, with Amazon’s 2017 acquisition of Whole Foods apparently the last straw.</p>

<p>This is bad enough, but survivable: AWS can and does thrive without Walmart’s business. But Walmart actually takes their policy a lot further: they now <a href="https://www.techrepublic.com/article/walmart-forces-tech-partners-to-leave-aws-following-whole-foods-acquisition/">require their tech partners to stay off AWS as well</a>. These retailers (and <a href="https://www.digitalcommerce360.com/2019/06/09/nearly-50-of-health-systems-see-amazon-as-a-threat/">healthcare providers</a>, and <a href="https://www.cnbc.com/2019/03/16/why-volkswagen-chose-microsoft-azure-over-aws.html">car companies</a>, and whatever industry Amazon disrupts next) are fighting for their lives, and they’ll play every card they hold to swing their sizable partner ecosystems toward Microsoft or Google. The competing cloud platforms, for their part, are perfectly willing to push this narrative, <a href="https://www.cnbc.com/2019/02/12/microsoft-google-cloud-pitch-vs-aws-we-wont-compete-with-you.html">swearing up and down</a> that they won’t “compete with partners”.</p>

<p>So here’s the reality on the ground. I just got back from <a href="https://www.dashcon.io/talks/when-bad-architectures-happen-to-good-people/">speaking at Dash</a>, Datadog’s New York conference focused on next-generation ops and infrastructure (though mostly, let’s be real, focused on Datadog). I took an informal survey of tech leads there, people building SaaS platforms for everything from real estate to nonprofits to IoT. Not things Amazon competes with directly. But nearly all of these vendors have, or want to believe that they will land, the kind of big customer that may have a “no AWS” policy.</p>

<p>So with few exceptions, they are hedging their bets. They build on containers in a misplaced belief that will make quick migrations easier, they architect dubious “multi-cloud” workloads … the point is, they’re not using AWS the way it’s designed to be used, as a holistic, deeply integrated platform, and the looming shadow of Amazon is the reason why.</p>

<p>Of course, the whole “I can’t go all-in on AWS because some of my own customers might distrust AWS, because they in turn fear Amazon” thing is such a delightfully screwy reason for making suboptimal tech choices. It reminds me of the old fundamentalist idea of <a href="https://www.patheos.com/blogs/religionnow/2017/10/secondary-separation-islam/">secondary separation</a>, where you shun an innocent person because they’ve insufficiently disassociated themselves from heretics.</p>

<p>The problem with secondary separation, as the fundamentalists discovered, is that it has no logical stopping point. What degree of separation is enough? How many layers of vendors must you purge before you can be sure you’re not bankrolling heresy, or Amazon? The whole conversation is faintly dumb, but it’s <em>happening</em>, and that’s a problem for AWS as much as for the engineering teams who have to work around them.</p>

<p>So let’s recap the reasons Amazon may be harming AWS:</p>

<ul>
<li><p>Amazon’s name recognition creates a target on AWS’s back when they want to work in politically-charged areas</p></li>

<li><p>Jeff Bezos’s other business ventures and feud with the president jeopardize AWS’s government contracts</p></li>

<li><p>Companies that compete with Amazon don’t want to use AWS services</p></li>

<li><p>Companies that want to attract business from Amazon competitors avoid AWS, or use it less fully</p></li>
</ul>

<p>None of these things are that bad on their own, at least not yet. But they all keep AWS from being the best, most juggernaut-y version of itself. They keep AWS’s services from competing on equal footing in the marketplace. And that’s a shame, because the tech itself is often pretty great.</p>

<p>It’s worth noting that <a href="https://www.businessinsider.com/scott-galloway-amazon-will-spin-off-amazon-web-services-ignition-2018-12">some smart people</a> think Amazon will eventually have to spin off AWS just because AWS would be so valuable and do so well in the market as a “pure cloud” player. But AWS is a victim of its own success. It’s not going anywhere because Amazon depends on it. And as Amazon expands to threaten more industries, AWS may paradoxically become less successful. It’s a weird bind.</p>

<p>At any rate, unless something big changes in the regulatory landscape, Amazon and AWS will probably remain joined at the hip. And I’ll keep having frustrating conversations with more and more clients about why they can’t use the best cloud services on the market.</p>

<p><em>Disclaimer: I work for an AWS consulting partner, but I own no $AMZN stock and have no direct interest in what Amazon does with AWS.</em></p>

<h3 id="links-and-events">Links and events</h3>

<ul>
<li><p>ServerlessConf is <a href="https://nyc2019.serverlessconf.io/">coming up again</a> in October! Check out the <a href="https://nyc2019.serverlessconf.io/agenda.html">agenda</a> and make plans to join me in NYC for the hottest conference in the cloud. There’s a great balance of speakers, both serverless “old-timers” and new faces, and a heavy concentration of hands-on use case stories. Should be a lot of fun.</p></li>

<li><p>Check out this <a href="https://www.youtube.com/watch?v=M215idpHA6E">recording</a> of a recent webinar I did with AWS and Epsagon on modern application development. If the word “webinar” makes your eyes go glassy, call it a “parley” or a “confabulation”. There’s a lot of good material in there.</p></li>

<li><p>I wrote up <a href="https://dev.to/trek10inc/ci-cd-aws-and-serverless-5-tips-i-learned-the-hard-way-223p">a few tips</a> learned the hard way about serverless CI/CD on AWS.</p></li>

<li><p>Jared Short and I are trying an experiment with <a href="https://serverless.help/">serverless.help</a> – submit your serverless question, we’ll answer it and add it to a public repository so others can benefit. It’s a conscious effort to get more shared knowledge out of Slack groups and back onto the public web. You can also add your own questions and answers directly to the <a href="https://github.com/trek10inc/serverless.help">repo</a>.</p></li>
</ul>

<p>My brain-augmentation story <a href="https://www.mysteriononline.com/2019/06/the-mark.html">“The Mark”</a> is free to read this month at Mysterion.</p>

<h3 id="just-for-fun">Just for fun</h3>

<p>Five completely useless books that I greatly enjoy:</p>

<p><a href="https://www.powells.com/book/-9780802170606">How I Became A Famous Novelist</a> by Steve Hely</p>

<p><a href="https://www.powells.com/book/-9780879235147">The Decline and Fall of Practically Everybody</a> by Will Cuppy</p>

<p><a href="https://www.powells.com/book/-2221141745616">Versus</a> by Ogden Nash</p>

<p><a href="https://www.powells.com/book/-9780836218510">The Prehistory of the Far Side</a> by Gary Larson</p>

<p><a href="https://www.powells.com/book/-9781853261138">The Prisoner of Zenda</a> by Anthony Hope</p>

              </article>
              <center>
              <p>
                      If you enjoy my articles, comics, and stories, why not sign up for the mailing list?
                  </p>
              
            </center>
              
          </section>
          <br>
          

      </section>

    </div></div>]]>
            </description>
            <link>https://forrestbrazeal.com/2019/07/24/cloud-irregular-amazon-wont-spin-off-aws-and-thats-too-bad-for-aws/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26009599</guid>
            <pubDate>Wed, 03 Feb 2021 01:40:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple, Its Control over the iPhone, the Internet, and the Metaverse]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26009300">thread link</a>) | @jger15
<br/>
February 2, 2021 | https://www.matthewball.vc/all/applemetaverse | <a href="https://web.archive.org/web/*/https://www.matthewball.vc/all/applemetaverse">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page" role="main">
        
          <article data-page-sections="5d8e94500fa50d2aaaa7c406" id="sections">
  
    <section data-test="page-section" data-section-theme="" data-section-id="5d8e94500fa50d2aaaa7c408" data-controller="SectionWrapperController, MagicPaddingController" data-current-styles="{
&quot;imageOverlayOpacity&quot;: 0.15,
&quot;backgroundWidth&quot;: &quot;background-width--full-bleed&quot;,
&quot;sectionHeight&quot;: &quot;section-height--medium&quot;,
&quot;customSectionHeight&quot;: 10,
&quot;horizontalAlignment&quot;: &quot;horizontal-alignment--center&quot;,
&quot;verticalAlignment&quot;: &quot;vertical-alignment--middle&quot;,
&quot;contentWidth&quot;: &quot;content-width--wide&quot;,
&quot;customContentWidth&quot;: 50,
&quot;sectionTheme&quot;: &quot;&quot;,
&quot;sectionAnimation&quot;: &quot;none&quot;,
&quot;backgroundMode&quot;: &quot;image&quot;
}" data-animation="none">
  
  <div>
    <div>
      
      
      
      
      <div data-content-field="main-content" data-item-id="">
  <article id="article-">
  
    <div>
      

      <div>
        <div><div data-layout-label="Post Body" data-type="item" id="item-6019e1745ac59c60629d17ba"><div><div><div data-block-type="5" id="block-06e5bdc7554e81e2c74b"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1612289339255-PK5IQQ1WEESTCEF11JG1/ke17ZwdGBToddI8pDm48kNMKN8uTEjMfGGUa7RJsRBYUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2djHslMPvDnuEvFowRrw-1vv85u65HS3d-cBV2zKbGbRC3WUfc_ZsVm9Mi1E6FasEnQ/image-asset.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1612289339255-PK5IQQ1WEESTCEF11JG1/ke17ZwdGBToddI8pDm48kNMKN8uTEjMfGGUa7RJsRBYUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2djHslMPvDnuEvFowRrw-1vv85u65HS3d-cBV2zKbGbRC3WUfc_ZsVm9Mi1E6FasEnQ/image-asset.jpeg" data-image-dimensions="1794x897" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="6019e1745ac59c60629d17b7" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1612289339255-PK5IQQ1WEESTCEF11JG1/ke17ZwdGBToddI8pDm48kNMKN8uTEjMfGGUa7RJsRBYUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2djHslMPvDnuEvFowRrw-1vv85u65HS3d-cBV2zKbGbRC3WUfc_ZsVm9Mi1E6FasEnQ/image-asset.jpeg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-78a04d1642024dbcaa69"><div><p><strong>Chapter One: The Creation of Today’s Internet and the Needs of Tomorrow’s</strong></p><p>One of the neat things about the internet is who created it, why, and how.&nbsp;</p><p>Throughout the 1960s to 1990s, the foundation of today’s internet was built through a variety of consortiums and informal working groups composed of government research labs, public universities and independent technologists. These typically not-for-profit collectives typically focused on establishing common standards that would help them share information from one server to another (i.e. messages or files), and in doing so, make it easier to collaborate on future technologies, projects and ideas.&nbsp;</p><p>The internet’s quirky provenance is responsible for many of its best modern attributes. Today, everyone can create content on the internet, everyone is technically capable of accessing everything on the internet, and every web page on the internet can connect to another without the user needing to change browser, device or client. This flexibility, interoperability and universality isn’t by decree - there’s no Head of the Internet mandating the right to create, host or access/connect to a website.&nbsp;</p><p>Instead, this is a byproduct of the internet’s open standards, programming, markup languages and so on. These ensure that a user doesn’t need to pay for a web browser or to load a website, nor does the owner of a website need to pay for the code used by their website. Services like Zoom also work because they leverage actively maintained standards that are free to use and designed to support any device. Every device maker needs to support these standards in order to have happy customers. Some of us now recoil against aggressive data collection, ad insertions and tracking, but this is partly because we don’t <em>need</em> to give these up. The use of standards, such as HTML, means that browser extensions can block ads or tracking. We may be willing to give up data for a free service, but the Internet’s makeup means we don’t have to.</p><p>The benefits here are hard to overstate. But just imagine, for example, how the internet might differ if it had been created by multinational media conglomerates in order to sell things, serve ads or harvest user data for profits. Downloading a .JPG could cost money, with a .PNG costing 50% more. Teleconferencing software might have required the use of a broadband operator’s app or portal (e.g. Welcome to your Xfinity Browser™, click here for Xfinitybook™ or XfinityCalls™ powered by Zoom™). Websites might only work in Internet Explorer <em>or</em> Chrome - and need to pay a given browser an annual fee for the privilege. Or maybe users would need to pay their broadband provider extra fees to read certain programming languages or use a given web technology (“This website requires Xfinity Premium with 3D Rendering”). Regardless of the specific differences, it’s likely internet penetration would be lower, as would usage and associated commerce.</p><p>The web’s cross-platform, standards-based and non-profit origins are inseparable from the internet’s rapid growth, the trillions of dollars in companies that have been founded over the past 30 years, and the positive societal impact of these companies (e.g. a drop in the cost and increase in the quality of communications, the reduction in gatekeeper power, lowered transaction fees, etc.).&nbsp;</p><p>Today’s heavily conglomerated internet giants remain mindful of the fact that open APIs, common standards, exportable data, etc., all help grow both the internet technology acceptance model and, in most cases, their own bottom lines. But these companies are less concerned with how the overall market grows than their share and control of this growth. Technology companies, almost by definition, prefer that the market build on top of or through them than have new entrants build around or in competition with them. As a result, the same companies that emerged thanks to openness tend to reject these principles where they might undermine their strategic position.</p><p>This isn’t an unusual disposition for a for-profit company, but the implications are particularly powerful in digital markets. In the offline world, free market economics enable robust competition that typically delivers the best products, variety and prices for consumers, and moderates the power of the strongest market players (if only due to diseconomies of scale). Online, incredibly powerful network effects and zero-cost marginal revenues/distribution has enabled dominant platforms to push back against the open nature of the internet, forcing consumers and creators to use them as universal intermediaries, and subduing standard market forces.</p><p>Right now, we are on the cusp of the next internet. The terms used for this future vary and the degree to which you believe in one label or vision is not particularly relevant. And the technologies to design, enable and support the fullest version of this are as far from the capabilities of 2021 as the 1990s Internet is from us today. But what matters is that a growing share of our time will be spent within virtual spaces and with virtual goods — for education, work, health, politics and leisure. Sometimes these spaces and goods will be purely virtual, other times virtual twins of physical ones, and sometimes augmented reality. For related reasons, a growing percentage of our income will be spent on virtual assets, goods, experiences — many of which we’ll be able to sell, trade, share, use or improve. And of course, enormous new industries, marketplaces and resources will emerge to enable these opportunities, with novel types of labor, skills, professions and certifications invented to serve them.&nbsp;</p><p>There’s no way for this future to be developed as the original internet was. The US government and public research institutions led the development of the information superhighway in part because few in private businesses understood the commercial potential of a World Wide Web, but also because these non-profits were essentially the only entities with the computational talent, resources and ambitions to build it. Conversely, all of today’s mega-tech companies are deep believers in this future internet, and are best positioned (via resources and talent) to build it.&nbsp;</p><p>The most important impediment today is Apple. Although no company has done more to propel the last 15 years of the internet, its policies are unlikely to produce the most prosperous overall ecosystem and do not lay a strong groundwork for the “next Internet”. Instead, Apple is inhibiting this future Internet. And it does so via tolls, controls, and technologies that not only deny what made and still makes the open web so powerful, but also prevents competition, and prioritize Apple’s own profits.</p><p><span><strong>Chapter Two: There’s Apple, then GAFM</strong></span></p><p>Apple’s adverse effects stem from three interconnected and increasingly powerful elements.</p><p>First, Apple believes it knows better than consumers, the developer community, and the market at large. This includes which technologies should be adopted by the internet community, the role of user agency (and the extent to which users are capable of informed consent), and common business practices around user data, privacy and security.</p><p>This disposition led Apple to limit the role of the marketplace <em>on its </em>device (something the company did not do for the Mac). Specifically, Apple mandates that on its devices:</p><ol data-rte-list="default"><li><p>All applications would need to be distributed by the Apple App Store, and could not be directly downloaded from the app maker or a third party app store</p></li><li><p>All applications distributed by the App Store would need to be approved by Apple, and approval would be contingent upon an extensive list of policies and requirements</p></li><li><p>All applications distributed by the Apple App Store would need to conform with the App Store’s billing policies, which typically meant that Apple was the exclusive in-app biller for iOS applications</p></li></ol><p>These three layers are technically different — the ability to use an operating system driver has nothing to do with the ability to distribute an app to the consumer or charge for them for a given piece of content or function. However, Apple’s iOS devices forced them together. If a developer wants to make an app, they need access to native drivers. And if a developer wants access to native drivers, their apps need to be distributed by the App Store. And if they want to use the App Store, they must adhere to Apple’s policies, which means using Apple’s billing systems.&nbsp;</p><p>Apple’s control and integration allowed it to offer a best-in-class mobile experience that also helped repel the most pernicious aspects of the online world; onboard and engage less technically savvy users; and develop a richly monetized app ecosystem. This, in turn, led to unprecedented success. <a href="https://www.ben-evans.com/benedictevans/2020/8/18/app-stores">Today, the iPhone has 66% market share in the United States, 75% of U.S. App Store revenues, and over 80% of time spent on the mobile internet</a> (iOS’s share of physical e-commerce transactions is likely somewhere in the middle of this range). And this dominance is also growing. Eighty percent of U.S. teenagers have iPhones and the device held 90% of smartphone activations in the week after Christmas 2020.</p><p>While Apple’s closed approach is why the company’s products are so successful, it’s success is also the reason why its closed approach has become so onerous. There is no proprietary, closed system that affects more lives on a daily basis than that of iOS. Due to this fact, Apple has become a de facto regulator for the internet; a single for-profit body that wields enormous soft, hard, and even accidental power.&nbsp;&nbsp;</p><p>There are almost no large companies in the world that can live without a mobile app (these …</p></div></div></div></div></div></div></div></div></article></div></div></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.matthewball.vc/all/applemetaverse">https://www.matthewball.vc/all/applemetaverse</a></em></p>]]>
            </description>
            <link>https://www.matthewball.vc/all/applemetaverse</link>
            <guid isPermaLink="false">hacker-news-small-sites-26009300</guid>
            <pubDate>Wed, 03 Feb 2021 00:57:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Composition with Semantically Rich Names]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26009267">thread link</a>) | @freshelectrons
<br/>
February 2, 2021 | https://about.scarf.sh/post/composition-with-semantically-rich-names | <a href="https://web.archive.org/web/*/https://about.scarf.sh/post/composition-with-semantically-rich-names">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>In my <a href="https://about.scarf.sh/post/shea-levy-composition-fanatic">previous post</a>, I remarked on the fact that composition, while central to our work as engineers, is often poorly supported by the tools we use. In this post I want to explore a specific trend away from this state of affairs, where composition is given the first-class treatment it deserves.</p><p>When engineering with atoms, composing components often consists of literally putting them together: you take piece A, move it close to piece B, and combine them by inserting tab X into slot Y. Sometimes an analogous case occurs in software: developers may instantiate instances of two particular design patterns in a class definition and compose them by ensuring the overlap meets both requirements, or copy in a template or project scaffold to compose a general structure with their specific use case.</p><p>Most of the time, however, software engineers compose by <em>reference</em>, making one part of the system conform to the interface of another and indirectly interact with the component exposing the interface through some pointer, handle, or name. These layers of indirection allow for more efficient reuse of components, clearer conceptual boundaries, and more specialized and dynamic composition. This benefits both the humans using the tools and the automated systems operating behind the scenes, at various time scales. Composition by named reference is so fundamental that <a href="https://en.wikipedia.org/wiki/Lambda_calculus">one of the two foundational models of computation</a> revolves exclusively around referencing by name and resolving those references!</p><h2>Programming and networking</h2><p>Traditionally, most sophisticated name-based composition acted at the levels of building programs or of connecting entire machines.</p><p>Composition by name is ubiquitous in programming. We reference packages we want to use by a name and a version. We identify libraries we depend on by name. We call functions, consume data, implement interfaces, etc., all via their names. Then our tools take over: Our editors provide us documentation by name, our compilers look up type information and calling conventions by name, our static and dynamic linkers connect needed functionality across binary components by name.</p><p>Any user of post-Internet computers is intimately familiar with our industry's other venerable usage of names: finding another machine on the network. Every time you type a URL in your search bar, click a link, or configure an application to point to some specific service, you are composing computer resources by name. The most systematized and sophisticated aspect of these names is the <a href="https://en.wikipedia.org/wiki/Domain_Name_System">domain name system</a>, which gives you a high quality way to connect a top level name to a specific machine. Most of the rest of the URL is particular to each individual system, with at best weak conventions governing their use and meaning. But for both human and machine consumers, the domain name contains very precise semantics for composition at the machine level.</p><p>These names are not only crucial operationally, to put everything together in the system, they are also crucial cognitively, to put everything together in our minds. It's a clichéd joke that naming something is one of the two hardest problems in computer science, but that joke is based on the very serious fact that a name lets us treat a complex system as a single unit, and a good name helps us do that effectively.</p><p>DNS and programming language symbol resolution are at this point completely entrenched. They've been around in the relevant forms for the entire productive career of a huge portion of our industry. In more recent decades, however, some new approaches to name-based composition in new domains have emerged.</p><h2>Semantically-meaningful resource naming</h2><p>After the previous section, some of you may be wondering: What about the filesystem? It's true that files and other system resources have long been named by strings, with some weak structure for navigating trees of resources (i.e., the directory separator) and, on some systems, the type of file being named (the file extension). Similarly, other resources have long been referenced by name: <a href="https://google.com/">https://google.com</a> names not the server at google.com, but the specific HTTPS service exposed by that server over TCP port 443.</p><p>The problem with these and other naming systems is that they put too much of the work of composition onto the users. With a few minor exceptions like the <a href="https://en.wikipedia.org/wiki/Filesystem_Hierarchy_Standard">filesystem hierarchy standard</a> and file extensions, file paths tell you almost nothing about the file in question that you didn't already know. Almost no one looks at the full URL of a hyperlink and extracts meaningful information from it that wasn't present in the context of the link. This results in the status quo: these names are almost always treated as fully opaque identifiers, and very few common naming rules apply across teams and systems.</p><p>Some systems have taken steps to move beyond this situation, however. In this section I will briefly cover a few novel tools that in some cases have succeeded in and in others promise to provide <em>semantically meaningful</em> names to compose different computational resources.</p><h3>git</h3><p>I assume most of you are familiar with <a href="https://git-scm.com/">git</a>, at a high level. At a primitive level, git operates on various types of <em>objects</em>, such as blobs, commits, or symlinks. At the human interface level, many of these objects are ultimately referenced by ad hoc unstructured names, such as "file x/y/z on branch foo". That being said, you've probably seen commits referenced by a <em>hash</em>, such as 4149457c6358f702fffbefcc2b7f6e8a87f802fb. Hashes like this are what the human-readable names are translated into, and how all of the objects internally refer to each other.</p><p>What do the hashes mean? Each object can be <em>serialized</em>, i.e. written to a file such that it can be correctly reconstructed later, including references to any other objects it depends on. These serializations are <em>canonical</em>, such that any two objects that are the same will have byte for byte the same serialization. Using a <a href="https://en.wikipedia.org/wiki/Cryptographic_hash_function">cryptographic hash function</a> on the contents of these serialized files then allows the git tools to give each object a short name that captures the full information content of the object, modulo unlikely hash collisions. We therefore call these <em>content-addressed</em> names.</p><p>Why should we use content-addressed names? In short, because they allow different components of the system to cheaply refer to each other with a high degree of reliability: If some commit object says that its associated filesystem tree has some file at a particular path, I know that whenever I refer to that file via relative references from the commit, I will get a file with exactly the same contents.</p><p>This allows for safe deduplication of files across commits and efficient communication protocols for distributing repositories across the network. It also gives a much more precise meaning to the names in question: "the file at x/y/z" can refer, at different times and on different systems, to any kind of file the relevant filesystem supports, whereas "the file at x/y/z in the tree of commit 4149457c6358f702fffbefcc2b7f6e8a87f802fb" refers, for most intents and purposes, to exactly one file with specific contents.</p><h3>Nix</h3><p><a href="https://nixos.org/manual/nix/stable/#ch-about-nix">Nix</a> is a package manager for Unix systems. It is built on several innovations, but the one relevant for this post is the Nix store, where the filesystem resources associated with packages are managed.</p><p>Like git, Nix manages some of its filesystem resources by content-addressed name, using essentially the same logic as git's hash-based content addressing. By themselves, however, such names are inadequate to Nix's goal of highly reliable and accurate dependency management with composition across packages. If I've built package foo 1.0 against some specific content-addressed instance of package bar 2.0, I can calculate the content and thus a content-addressed name of the resulting package. But if you want to build foo 1.0 against the newly released bar 2.1, you can't reuse anything in that content addressed name and must rebuild from scratch.</p><p>Nix addresses this issue with what I call <em>recipe-addressed</em> names: Some filesystem resources are named not by their own content but by the content of a serialization of <em>a deterministic build recipe</em> for creating it. The nature of these build recipes is such that it is much easier to substitute in different versions, configurations, etc. anywhere in the dependency tree and recalculate what the new name of the results should be.</p><p>With content-addressed names for bootstrapping, and recipe-addressed names for building up more complex packages, Nix opens up a whole new world of package management. Nix can ensure that many different machines, however different their configurations, have exactly the same package installed.</p><p>Nix can safely reuse common dependencies between packages, parallelize builds, and distribute builds across multiple machines. Large centralized binary caches are possible with a <a href="https://www.tweag.io/blog/2020-12-16-trustix-announcement/">decentralized trust mechanism</a> built on top. On top of these capabilities, <a href="https://nixos.org/guides/how-nix-works.html#nixos">entire system configurations</a> can be deterministically captured in a single name, allowing reproducible deployments and much more reliable migration of personal systems across computers.</p><h3>Nelson</h3><p><a href="https://getnelson.io/">Nelson</a> is a "cloud-native" service orchestration framework built to take advantage of modern distribution, resource management, and coordination mechanisms. Among other things, Nelson enables deploying an <a href="https://www.digitalocean.com/community/tutorials/what-is-immutable-infrastructure">immutable infrastructure</a>-style network topology while retaining efficient garbage collection of unneeded services. Nelson achieves this by requiring services to reference each other via name resolution mechanisms it populates from high level service configurations. Each service configuration specifies the other services it depends upon, providing both a service name, which has meaning to the user, and a <a href="https://semver.org/"><em>semantic version</em></a>, which contains information about cross-version compatibility. Nelson leverages the information in the dependency specification and keeps track of which services depend on which, allowing it to safely remove old instances of services that are not …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://about.scarf.sh/post/composition-with-semantically-rich-names">https://about.scarf.sh/post/composition-with-semantically-rich-names</a></em></p>]]>
            </description>
            <link>https://about.scarf.sh/post/composition-with-semantically-rich-names</link>
            <guid isPermaLink="false">hacker-news-small-sites-26009267</guid>
            <pubDate>Wed, 03 Feb 2021 00:52:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Sliding Window Algorithm]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26009069">thread link</a>) | @swyx
<br/>
February 2, 2021 | https://blog.narendras.vercel.app/sliding-window | <a href="https://web.archive.org/web/*/https://blog.narendras.vercel.app/sliding-window">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="__next"><main><article><div><div><p><img src="https://blog.narendras.vercel.app/avatar.jpg" alt="Nanda Syahrasyad"></p><p>Nanda Syahrasyad</p></div><p>February 4, 2021</p></div><h2>A Subarray Problem</h2><p>The sliding window pattern is a neat and simple pattern to optimize problems involving <em>subarrays</em>. Let's go over a simple problem to see how this can be useful.</p><p>For this problem, we are given an array <code>arr</code>, and a subarray size <code>k</code>, and we are asked to find the <em>average</em> of <em>all</em> subarrays in <code>arr</code> of size <code>k</code>. So given an array like <code>[1, 2, 3, 4]</code> and a subarray size <code>k = 2</code>, the correct answer would be <code>[1.5, 2.5, 3.5]</code> because:</p><ul><li><code>[1, 2, 3, 4]</code> has three subarrays of size 2, namely <code>[1, 2], [2, 3], [3, 4]</code>.</li><li>The average of the first subarray is <code>1 + 2 / 2 = 1.5</code>, the average of the second is <code>2.5</code> (using the same formula), and the average of the third is <code>3.5</code>.</li><li>Putting this together we get the final result <code>[1.5, 2.5, 3.5]</code>.</li></ul><p>Given these steps, it seems pretty clear that in designing an algorithm to solve this problem we would have to (1) iterate through every subarray then (2) find the average of each and append it to the result array.</p><p>A straightforward way to find every subarray of an array is to iterate through each index of the array and <em>construct</em> the subarray that begins at that index by iterating <code>k</code> more times. In this second iteration we can also sum up the numbers to compute the resulting average. Here's what that would look like:</p><p>Doing that for <em>every</em> index in the array, we get the final algorithm:</p><p>Notice the number on the top right of the animation. This number represents the total number of steps required to compute the result given the inputs <code>arr</code> and <code>k</code>. Try adding two more items and see how that number changes—it went up, by a <em>lot</em>.</p><p>Is there a better way?</p><p>Looking back at the algorithm, notice that most of the time we're counting numbers that we've already included before. Let's look at the animation again, this time highlighting all the double counts in red:</p><p>When the algorithm finishes, only 2 elements <strong>were not double counted!</strong> It turns out that no matter what inputs, this implementation will <em>always</em> double count every element except for the first and the last (try playing around with the inputs to convince yourself).</p><p>So why are we double counting in the first place? If we look at the first two subarrays, we see there's a lot of overlap:</p><p>What if, on each step, we only take into account the <em>differences</em> instead? In other words, is there a way to get the sum of the second subarray from the sum of the first? If so, we would be able to <em>derive</em> the sum of the second subarray rather than recounting every element again.</p><p>In the example above, we can get the sum of the <strong>second subarray by subtracting 1 and adding 5</strong> to the sum of the first.</p><p>This reduces the sum computation from <code>k</code> iterations to only one iteration! This is also where the sliding window namesake comes from—it's as if we have a window of 4 items that we <em>slide</em> to the next subarray.</p><p>Maybe adding a border around the items would make the window more clear:</p><p>With this key insight let's rewrite the algorithm. Remember that the algorithm receives two inputs - an array of numbers <code>arr</code> and a size of subarray <code>k</code>.</p><ol><li>At the start, we <em>build</em> the window—iterate until our window contains <code>k</code> items—while keeping track of the sum.</li><li>Then, we <em>slide</em> the window one item over, updating the sum by subtracting the item no longer in the window and adding the item that was added to the window. By doing this we ensure that the sum stays in sync with the items that are in the window.</li><li>With this sum we can compute the average as before.</li></ol><p>And that's the find all averages problem using the sliding window pattern! Notice how this implementation only needs 7 steps to calculate the sum instead of 13 with the previous implementation. Now that doesn't seem to be too big of a difference, but look how blazing fast the optimal implementation is compared to our previous one:</p><p>While the window is building, both algorithms are going at the same pace (try changing the size of k to equal to the size of the array—both algorithms will finish at the same time!). However, once the window is complete, the optimal algorithm blazes off and terminates in less than half the time it takes for the naive algorithm to finish.</p><h2>Generalizing the Pattern</h2><p>Of course we're not limited to only counting averages. The sliding window pattern can be generalized to any problem that involves computing <em>something</em> in the subarray. As long as the problem has some definition of a window size, the pattern essentially boils down to:</p><ol><li>Maintaining some <strong>state</strong> in that window, and</li><li>keeping that state in sync with the items in the window through <strong>constant-time operations</strong>.</li></ol><p>By "constant-time operations" I mean without using further iterations and only using the stuff that leaves/enters the window.</p><p>In the case of the averages problem, the state that we're maintaining is the <strong>sum of the items</strong>. We're keeping this sum in sync with the items in the window by subtracting the item that's leaving and adding the item that's entering.</p><h3>Permutation in a String</h3><p>Here's another problem that makes use of the same concept of maintaining state and synchronizing that state. The problem's pretty simple—given a string and some pattern, determine if the string contains any <em>permutation</em> of that pattern. For example, given the string <code>aaacb</code> and the pattern <code>abc</code>, the algorithm should return <code>true</code> because the substring <code>acb</code> is a permutation of <code>abc</code>.</p><p>This is not as obvious of a sliding window problem than the problem we just worked through, but if you think of a string as an array of characters and a substring as a subarray, then the similarities start to show.</p><p>I'm not going to walk through each logical step to get to the optimal solution (that would take a minute!), but here are the main ideas:</p><ol><li>A string can only be a permutation of another if it's the same length. <em>This gives us the size of the window = <code>pattern.length</code></em>.</li><li>A string is <strong>exactly</strong> a permutation of another if it contains the exact same number of letters. A way to keep track of this is through a map of character -&gt; count pairs. <em>This gives us the state that we have to maintain</em>.</li><li>We need a way to update <em>and compare</em> the map in constant time. <em>Through this we fulfill the second condition of synchronizing state through constant operations</em>.</li></ol><p>With those ideas, here's the final solution:</p><p>If you're interested in more details of the algorithm (particularly the constant-time updates and comparison), open the note below!</p></article></main></div></div>]]>
            </description>
            <link>https://blog.narendras.vercel.app/sliding-window</link>
            <guid isPermaLink="false">hacker-news-small-sites-26009069</guid>
            <pubDate>Wed, 03 Feb 2021 00:28:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Crossplane vs. Cloud Provider Infrastructure Addons]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26009017">thread link</a>) | @hasheddan
<br/>
February 2, 2021 | https://blog.crossplane.io/crossplane-vs-cloud-infrastructure-addons/ | <a href="https://web.archive.org/web/*/https://blog.crossplane.io/crossplane-vs-cloud-infrastructure-addons/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>Kubernetes has demonstrated the power of a well architected control plane with a great API. The industry is beginning to notice that this control plane can be used to do much more than orchestrate containers, and are increasingly looking to use the Kubernetes control plane to manage all of their infrastructure.</p><p>Several “cloud provider infrastructure” addons exist for Kubernetes. These addons provide a Kubernetes interface to a cloud provider’s infrastructure - databases, queues, etc. The three major clouds each maintain their own - Google Config Connector, Azure Service Operator, and Amazon Controllers for Kubernetes. Each exposes their respective cloud’s control plane APIs as custom resources, allowing Kubernetes users to manage an RDS instance (for example) using the same tools they would use to manage a <code>Deployment</code> or a <code>ConfigMap</code>.</p><figure><img src="https://blog.crossplane.io/content/images/2021/02/HeaderHero.svg"><figcaption>Crossplane exposes all of the major cloud provider control plane APIs as custom resources.</figcaption></figure><p>Crossplane is often compared to the various cloud provider infrastructure addons. There are certainly similarities - it is also a Kubernetes addon, and it also exposes all of the major cloud provider control plane APIs as custom resources. Crossplane even <a href="https://blog.crossplane.io/accelerating-crossplane-provider-coverage-with-ack-and-azure-code-generation-towards-100-percent-coverage-of-all-cloud-services/">shares code with some of these addons</a>. Where Crossplane differs is in how we expose cloud provider APIs.</p><blockquote>
<p>The Crossplane community believes that the typical developer using Kubernetes to deploy their application shouldn’t have to deal with low level infrastructure APIs.</p>
</blockquote>
<p>Drawing on our experiences as platform builders, SREs, and application developers we’ve designed Crossplane as a toolkit to build your own custom resources on top of any API - often those of the cloud providers. We think this approach is critical to enable <em>usable</em> self-service infrastructure in Kubernetes.</p><p>In this post we’ll demonstrate that seemingly simple tasks like spinning up a new database in the cloud for your applications to consume can often be more complicated than it would at first seem, and how Crossplane is designed to help tame that complexity.</p><p>Crossplane today consists of three things:</p><ol><li><em>Providers</em> extend Crossplane with custom resources that can be used to declaratively configure a system. The AWS provider for example, adds custom resources for AWS services like RDS and S3. We call these ‘managed resources’. Managed resources match the APIs of the system they represent as closely as possible, but they’re also opinionated. Common functionality like status conditions and references work the same no matter which provider you’re using - all managed resources comply with the Crossplane Resource Model, or XRM.</li><li><em>Composition</em> allows a platform team to define new custom resources that are composed of managed resources. We call these composite resources, or XRs. An XR typically groups together a handful of managed resources into one logical resource, exposing only the settings that the platform team deems useful and deferring the rest to an API-server-side template we call a ‘Composition’.</li><li><em>Packages</em> allow a platform team to quickly package, share, and declaratively install new kinds of composite resources and the providers they build on.</li></ol><blockquote>Despite the name, “provider” doesn’t necessarily mean “cloud provider”. Crossplane has providers that add support for managing databases on a SQL server, managing Helm releases, and <a href="https://blog.crossplane.io/providers-101-ordering-pizza-with-kubernetes-and-crossplane/">ordering pizza</a>.</blockquote><figure><img src="https://blog.crossplane.io/content/images/2021/02/Crossplanecity.svg"><figcaption>When we founded Crossplane we focused on supporting the most useful resources.</figcaption></figure><p>When we founded the Crossplane project we started at the managed resource layer. We focused on the resources we thought would be the most useful to application developers - things like cloud databases, caches, and storage buckets. We quickly heard from early adopters that being able to spin up these resources alone <em>wasn’t enough</em>. An RDS instance might also need a security group or a subnet group to be reachable. GCP Cloud SQL instances and Azure SQL servers face similar issues. This pattern permeates cloud infrastructure; another example we see often is folks wanting to create an IAM policy for each DynamoDB table they create. </p><p>Let’s dig into the example of an application developer requesting an SQL database for their application to use. An experience you initially hope will look like this:</p><pre><code>apiVersion: database.aws.crossplane.io/v1beta1
kind: RDSInstance
metadata:
  name: example-rds
spec:
  forProvider:
    dbInstanceClass: db.t3.medium
    engine: mysql
    allocatedStorage: 20
</code></pre>
<p>Can easily end up looking like this:</p><pre><code>apiVersion: database.aws.crossplane.io/v1beta1
kind: RDSInstance
metadata:
  name: example-rds
spec:
  forProvider:
    region: "us-west-2"
    dbInstanceClass: "db.t3.medium"
    engine: mysql
    engineVersion: "5.7"
    dbSubnetGroupName: external-subnet-group
    vpcSecurityGroupIDRef:
      name: example-sg
    masterUsername: cooladmin
    skipFinalSnapshotBeforeDeletion: false
    publiclyAccessible: true
    allocatedStorage: 20
    autoMinorVersionUpgrade: true
    backupRetentionPeriod: 30
    caCertificateIdentifier: "rds-ca-2019"
    copyTagsToSnapshot: true
    deletionProtection: true
    enableIAMDatabaseAuthentication: false
    enablePerformanceInsights: true
    performanceInsightsRetentionPeriod: 7
    finalDBSnapshotIdentifier: example-rds-snapshot
    licenseModel: general-public-license
    multiAZ: true
    port: 3306
    preferredBackupWindow: "06:15-06:45"
    preferredMaintenanceWindow: "sat:09:21-sat:09:51"
    storageEncrypted: false
    storageType: "gp2"
  writeConnectionSecretToRef:
    namespace: app-team-a
    name: example-rds
---
apiVersion: ec2.aws.crossplane.io/v1beta1
kind: SecurityGroup
metadata:
  name: example-sg
spec:
  forProvider:
    region: us-west-2
    vpcId: externally-managed-vpc
    groupName: crossplane-getting-started
    description: Allow access to MySQL
    ingress:
      - fromPort: 3306
        toPort: 3306
        ipProtocol: tcp
        ipRanges:
          - cidrIp: "10.0.10.0/0"
            description: Production
---
apiVersion: mysql.sql.crossplane.io/v1alpha1
kind: ProviderConfig
metadata:
  name: example-rds
spec:
  credentials:
    source: MySQLConnectionSecret
    connectionSecretRef:
      namespace: platform-infra
      name: example-rds
---
apiVersion: mysql.sql.crossplane.io/v1alpha1
kind: Database
metadata:
  name: example
spec:
  providerConfigRef:
    name: example-rds
---
apiVersion: mysql.sql.crossplane.io/v1alpha1
kind: User
metadata:
  name: example-user
spec:
  providerConfigRef:
    name: example-rds
  writeConnectionSecretToRef:
    namespace: app-team-a
    name: example-rds-user
---
apiVersion: mysql.sql.crossplane.io/v1alpha1
kind: Grant
metadata:
  name: example
spec:
  providerConfigRef:
    name: example-rds
  forProvider:
    privileges:
    - SELECT
    - INSERT
    - DELETE
    - UPDATE
    - EXECUTE
    userRef:
      name: example-user
    databaseRef:
      name: example
</code></pre>
<p>You might notice that we create a database and a user in the above example - something the RDS API does not support natively.</p><blockquote>Sometimes spinning up practically functional infrastructure requires multiple providers - even if you only use one cloud. In this case we use the SQL provider to finish what we started with the AWS provider.</blockquote><p>This will be an imposing amount of configuration for some application developers. They want to be able to self service their infrastructure needs, but shouldn’t need to be experts in the features and functionality of cloud provider APIs to do so. This is where Composition comes in - it allows a platform team to offer their application developers an experience much closer to the one they originally envisioned. Using Composition the application developer experience can look like this:</p><pre><code>apiVersion: example.org/v1
kind: ExampleCoDatabase
metadata:
  name: example
spec:
  parameters:
    storageGB: 20
    username: example-user
  compositionSelector:
    matchLabels:
      engine: mysql
      class: production
  writeConnectionSecretToRef:
    name: example-database-credentials 
</code></pre>
<p>This is a composite resource - an XR.</p><blockquote>When an application developer creates, updates, or deletes this XR Crossplane can create, update, or delete the more verbose set of managed resources from the previous example.</blockquote><p>Composition allows the infrastructure experts - the platform team - to determine what settings their application developers need, and how to use those settings to produce an RDS instance, security group, database, etc. In this example the application developer can influence the size of the database but not its backup settings, which are enforced by the platform team.</p><figure><img src="https://blog.crossplane.io/content/images/2021/02/CrossplaneConsole@2x.png"><figcaption>Framing your opinions at the API level fosters automation and eases integration.</figcaption></figure><p>You may wonder why a platform team would use Composition rather than a familiar, existing tool like Helm or Kustomize. While it’s true that there are similarities, we feel that it’s better to frame your organisation's opinions at the API level, rather than via client-side tooling. For example when you use Crossplane to expose the above purpose-built <code>ExampleCoDatabase</code> API:</p><ul><li>Any REST client (from kubectl to curl to Python) can create an <code>ExampleCoDatabase</code> with a single API call. This fosters automation and eases integration with other systems.</li><li>Policy is enforced. RBAC can ensure at the API level that application developers may influence only the fields exposed by an <code>ExampleCoDatabase</code> XR. The platform team can ensure application developers have RBAC access to configure the settings they need, and nothing else.</li><li>RBAC is framed around your desired abstractions. Access is granted “to create an ExampleCo database”, not “to create an RDS instance, a security group, etc etc”.</li></ul><p>One novel design folks notice when they start using Crossplane is that most Crossplane custom resources are cluster scoped - they exist above the scope of any Kubernetes namespace. While this can seem odd at first, it’s another decision that was informed by real world scenarios.</p><p>Take the above <code>ExampleCoDatabase</code> XR. Assume that several teams of application developers, each with their own namespace, want …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.crossplane.io/crossplane-vs-cloud-infrastructure-addons/">https://blog.crossplane.io/crossplane-vs-cloud-infrastructure-addons/</a></em></p>]]>
            </description>
            <link>https://blog.crossplane.io/crossplane-vs-cloud-infrastructure-addons/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26009017</guid>
            <pubDate>Wed, 03 Feb 2021 00:21:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Mystery of Recursion – Understanding How to Implement It in Python]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26009015">thread link</a>) | @tmonty_12
<br/>
February 2, 2021 | https://tmonty.tech/the-mystery-of-recursion-understanding-how-to-implement-it-in-python | <a href="https://web.archive.org/web/*/https://tmonty.tech/the-mystery-of-recursion-understanding-how-to-implement-it-in-python">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1612311419772/nO8756MGq.jpeg?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=compress"><div><div itemprop="text"><h2 id="what-is-recursion">What is Recursion?</h2>
<p>If you understand the underlying concept of recursion but struggle to implement it like myself, or you don't even know what it is, then this post if for you.</p>
<p>Recursion is defined as solving a complex problem by breaking the problem into smaller versions of itself that can be solved. In programming, this is done by having a function call itself.</p>
<p>The underlying principle of recursion are these two cases:</p>
<ol>
<li><p><strong>Base Case</strong>: this case defines the smallest instance of a problem. In certain recursive solutions, there can be multiple base cases but for the purpose of this post's explanation, my example will only incorporate one. When coding, the base case prevents an infinite loop of the function calling itself.</p>
</li>
<li><p><strong>Recursive Case</strong>: this case manipulates the problem in order to approach the base case. In programming, this is the case in which the function calls itself.</p>
</li>
</ol>
<p>Put simply, the recursive case will breakdown the problem until it arrives at the base case, after which the the sub solutions build up to solve the original problem.</p>
<p>Do not worry if your understanding of recursion is hazy because the above definitions will make sense when implementing a recursive solution in Python.</p>
<h2 id="the-call-stack">The Call Stack</h2>
<p>In order to truly understand how recursion is implemented in Python, it is necessary to familiarize yourself with the call stack. </p>
<p>The call stack uses the stack data structure to keep track of local variables and previous function calls. The stack is a last-in, first-out data structure. This means that the last item to be placed in the stack will be the first to be removed. To help visualize, think of a stack of plates:</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1612217672194/K8ZCDamI8.jpeg?auto=compress" alt="brooke-lark-sG-PR0BNwb4-unsplash.jpg"></p>
<p>Whatever plate is placed last on the stack is the first one to be removed.</p>
<p>In terms of programming, the stack has two simple operations: push and pop. Push adds an item onto the stack and pop removes an item from the stack, returning its value.</p>
<p>In python, the call stack consists of frames. The bottom most frame is the global or module frame. This consists of all the global variables. Every time a function is called a new frame is pushed onto the stack containing its local variables and function arguments. When a function call returns, the frame is popped off the stack and its value is passed to where it was called in the previous frame.</p>
<h2 id="a-famous-recursion-example-factorial">A Famous Recursion Example - Factorial</h2>
<p>The factorial of a number is defined as so:</p>
<p>4! = 4 * 3 * 2 * 1 = 24</p>
<p>If we were to define the factorial of a number <code>n</code> as a mathematical equation, it would be:</p>
<p><code>factorial(n) = n * factorial(n-1)</code></p>
<p>The right side of the equation will be the <em>recursive case</em> of our solution. Notice, how the recursive case takes the original problem,<code>factorial(n)</code>, and makes it a simpler problem of multiplying <code>n</code> by whatever <code>factorial(n-1)</code> is.</p>
<p>We can define a function <code>factorial</code> that takes a parameter <code>n</code>. However, if we only defined this function with the above equation, it would call itself infinitely leading to an error.</p>
<p>This is because we did not define a <em>base case</em>. The most basic factorial is the factorial of 1 which equals 1. So we can tell the program that once it reaches the factorial of 1, instead of calling <code>1 * factorial(0)</code>, to just <code>return 1</code>. After which, the Python call stack will handle multiplying out the numbers.</p>
<p>After defining both the recursive and base cases, we arrive at the Python program below:</p>
<pre><code><span><span>def</span> <span>factorial</span>(<span>n</span>):</span>
    <span>if</span> n &lt;= <span>1</span>:
        <span>return</span> <span>1</span>
    <span>else</span>:
        <span>return</span> n * factorial(n<span>-1</span>)
</code></pre><h2 id="in-depth-recursive-function-implementation">In Depth Recursive Function Implementation</h2>
<p>Before calling the factorial function, the Python call stack would look like:</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1612222009642/RKv1SGozi.png?auto=compress" alt="Call Stack - 1 (3).png"></p>
<p>Then, we call the factorial function passing in an argument of 4. </p>
<pre><code><span>factorial</span>(<span>4</span>)
</code></pre><p>A frame for the factorial function would be pushed onto to the call stack, setting the argument <code>n</code> equal to <code>4</code>.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1612222128046/cNmno7-YI.png?auto=compress" alt="Call Stack - 2.png"></p>
<p>The Python interpreter will then process the function and since <code>n</code> is not <code>&lt;= 1</code>, it will evaluate <code>n * factorial(n-1)</code>. However before the function can return a value, it must evaluate <code>factorial(n-1)</code>. This will cause another factorial frame to be pushed on the stack, with the argument <code>n</code> set to <code>3</code>.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1612222294743/zXgfi23TF.png?auto=compress" alt="Call Stack - 3.png"></p>
<p>Again, since <code>n</code> is not <code>&lt;= 1</code>, the function will evaluate <code>n * factorial(n-1)</code>. Likewise, the function must evaluate <code>factorial(n-1)</code> before returning a value. </p>
<p>This pattern will continue until the factorial frame with the argument n equal to 1 is pushed onto the stack.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1612222730246/6jJduzt8q.png?auto=compress" alt="Call Stack - 5 (1).png"></p>
<p>When this occurs, the function reaches the base case, so it instead returns 1. As I mentioned early when explaining the call stack, when a function returns, it pops its frame off the stack, transferring its value to where it was called in the previous frame.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1612222867866/Npx8dueYc.png?auto=compress" alt="Call Stack - 6.png"></p>
<p>Now since the value for <code>factorial(n-1)</code> has been evaluated, the factorial function can evaluate the product and return it to the previous frame, pushing the current frame off the stack.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1612222963799/kJ7D_a-7I.png?auto=compress" alt="Call Stack - 7.png"></p>
<p>This pattern continues until we reach the original function call...</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1612223032269/rxZsqVaa8.png?auto=compress" alt="Call Stack - 8.png"></p>
<p>As you might have guessed, the factorial function with argument 4 returns a value of 24.</p>
<h2 id="summary">Summary</h2>
<p>When writing a recursive solution in Python, think of the problem in terms of a base case and recursive case. Ask yourself: "How can I define a recursive case that will help me reduce the problem towards a base case?"</p>
<p>When trying to understand a recursive solution, I find it best to visualize the call stack in my head.  Every time a function is called an item is added onto the stack and any time you encounter the return keyword, it pops an item off the stack and returns its value to the previous function call.</p>
<p>If you have made it this far and have enjoyed my post, please follow me on  <a target="_blank" href="https://hashnode.com/@tmonty">Hashnode</a>  and  <a target="_blank" href="https://twitter.com/tmonty_12">Twitter</a>. I plan on posting more content and am open to suggestions or requests!</p>
</div></div></section></div></div>]]>
            </description>
            <link>https://tmonty.tech/the-mystery-of-recursion-understanding-how-to-implement-it-in-python</link>
            <guid isPermaLink="false">hacker-news-small-sites-26009015</guid>
            <pubDate>Wed, 03 Feb 2021 00:21:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Invest in Undervalued People]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26008943">thread link</a>) | @forrestbrazeal
<br/>
February 2, 2021 | https://acloudguru.com/blog/business/why-you-should-invest-in-undervalued-people | <a href="https://web.archive.org/web/*/https://acloudguru.com/blog/business/why-you-should-invest-in-undervalued-people">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="8a920a5" data-element_type="widget" data-widget_type="theme-post-content.default"><div><p>It’s very hard to get hired as an entry-level software developer today.</p><p>There are more than ten times as many senior web developer jobs for every junior web developer job on both VentureLoop.com (jobs at startups) and Indeed.com. Browsing through companies that have recently IPO’d or raised $100M+ rounds — where one would expect a company to be able to hire junior developers — all I can find are jobs that require at least three or more years of experience or are explicitly only hiring “Senior” or “Developer II” or higher.</p><p>I have been working with bootcamp graduates and community-college graduates for years. But from my vantage point, when growth companies hire people with no development job experience, they are usually hiring top-tier, four-year college graduates. (There are some exceptions! Twitter’s <a href="https://careers.twitter.com/en/university.html">internship program</a> is admirable, although I don’t know in practice how restrictive the admissions end up being).<a href="https://twitter.com/shaft/status/1355696154990628864"></a></p><p><a href="https://twitter.com/mxcl/status/608682016205344768"></a>One can understand wanting to make sure that the first few hires into any department have enough experience to build and maintain high quality software, except that</p><p>a) that often doesn’t prevent terrible technical debt, and</p><p>b) no one ever changes the expectations over time.</p><p>And so the culture just becomes, “we only hire people with experience.” I am a huge fan of <a href="https://www.segment.com/">Segment</a> (and a happy customer for more than five years), but despite their senior-developer-packed engineering roster, they seem to have to rebuild their <a href="https://segment.com/blog/goodbye-microservices/">entire architecture</a> <a href="https://techcrunch.com/2021/01/05/how-segment-redesigned-its-core-systems-to-solve-an-existential-scaling-crisis/">every</a> <a href="https://segment.com/blog/rebuilding-our-infrastructure/">few</a> years. Every company starts by hiring seniors; most seem to keep hiring seniors, and many have to keep throwing away code constantly.</p><figure><img src="https://lh4.googleusercontent.com/BsxIM1LBghJkWOwT56C-wwa7lGYJbB9sJPYjYd-A2Dq7zKkJVO98_I3qSOZazzGzxkJkx_gqA4KBK1lm0st213MAaiRfakQxgcACtziqc7hsW5z3wfbtzmbN87DR9bB4NtACKSi2" alt=""></figure><p>Everyone agrees that talent is scarce, and that hires often fail — and that failure is expensive. Why don’t companies ever take a conscious look at how to build talent instead of buying it?</p><p>Put another way, it’s ironic that an industry that tends to want to build everything instead of buying it chooses to buy the absolute most expensive thing on the market: talent.&nbsp;</p><h2 id="h-the-problems-with-senior-developers">The Problems with Senior Developers</h2><p><strong>It is a fallacy that only hiring senior developers will lead to better results than hiring many junior developers</strong>. There are bad things about senior developers that no one should want in their organization, and without juniors to counterbalance, you’ll be overindexed to these downsides.</p><h4 id="h-senior-skills-can-stagnate">Senior skills can stagnate</h4><p>The most common error I see senior developers make comes, ironically, from their prior successes, combined with the pace of technology.</p><p>Most developers at the beginning of their careers are good at knowing and using most of the best practices at that time. But there is no continuing education in software development, and compensation is tied to shipping, not learning. So once a developer is five or more years into their career, there’s a really good chance they’re still relying upon tools, libraries, and practices that are no longer the best way to build, deploy, and run software.</p><p>Case in point: Instagram, all on the public cloud, <a href="https://www.dailymail.co.uk/news/article-2127343/Facebook-buys-Instagram-13-employees-share-100m-CEO-Kevin-Systrom-set-make-400m.html">sells to Facebook</a> for $1B with 13 employees in 2012; Bank of America <a href="https://newsroom.ibm.com/2019-11-06-IBM-Developing-Worlds-First-Financial-Services-Ready-Public-Cloud-Bank-of-America-Joins-as-First-Collaborator">makes its first announcement</a> to do anything with the public cloud in November of 2019. Kevin Systrom <a href="https://www.businessinsider.com/instagram-founder-kevin-systrom-has-no-formal-programming-training-2012-4">had only just learned to program</a> when he started Instagram; Bank of America’s technology organization is run by people who are decades from being practitioners. (Lest anyone try to argue Bank of America’s slowness is due to regulatory issues, <a href="https://get.acloudguru.com/capital-one-case-study">consider Capital One</a>).</p><h4 id="h-senior-developers-can-be-a-solution-in-search-of-a-problem">Senior developers can be a solution in search of a problem</h4><p>Another problem with senior-developer-only organizations is that <strong>most organizations don’t have constant flows of work that require lots of experience</strong>. A tremendous amount of software development is updating interfaces to add functionality or improve usability, not building back ends from scratch that have to scale to hundreds of millions of daily users.</p><p>And as we have better and more powerful <a href="https://www.infoq.com/articles/serverless-sea-change/">cloud services</a> to build on (e.g., AWS, GCP, Azure, Netlify, Twilio, Stripe), more developer focus turns to interfaces. Having an organization filled with senior developers who aren’t mentoring junior developers is asking to find senior-developer problems to solve, even if they’re best solved by an existing service.</p><h2 id="h-finding-undervalued-people">Finding Undervalued People</h2><p>Many developers are systemically undervalued because they do not fit central casting for appearance or mentality. Others are undervalued because organizations typically aren’t willing to hire software developers who need some training to do the job effectively.&nbsp;</p><p>Instead, whatever cargo-cult exercise an individual had to learn to become an interviewer (e.g., inverting binary trees on a whiteboard) tends to be viewed like a fraternity hazing ritual: “I had to go through it, so I’ll make everyone else after me go through it.”</p><p>There are excellent software developers who hate hackathons and would rather spend time raising their children on weekends than on coding side projects. There are people who are neuroatypical who can’t deal well with your unrealistic, on-the-spot brain teasers. There are people who need some additional training and mentorship to be able to ship software effectively for most organizations. These people are all undervalued by the standard hiring practices in tech, which means that, with some effort on your part, they’ll give the highest return on investment of any hires you can make.</p><h2 id="h-when-you-invest-in-people-people-invest-in-you">When you invest in people, people invest in you</h2><p>Over the past twenty years, I have seen a real difference between hiring software developers with the view of, “You’re a superstar and we need you to come in and kick ass” versus, “We will bring you in, teach you how we think and build, and then you’ll help us achieve our mission.”</p><p>The former attitude can lead to developers thinking they are better than other departments and other people in the organization, because no one else can do what they do. (After all, they are superstars!) The latter is fundamentally aligning to a mission and a team and a culture.</p><p>Remember, all software developers pick up bad habits. They usually don’t know all the latest best practices. They generally haven’t been given work time and space to experiment with new technologies. They won’t know all of your code or your stack or how your teams’ specific approaches to software development. These generalizations hold true for all developers, junior to senior.</p><p>You can choose to not invest any effort into training and aligning senior developers and still see things ship, but that doesn’t mean that you’re growing cohesive teams that are making the right decisions for your organization. You should invest in bringing everyone up to speed and together. When you do that, you realize that <strong>bringing junior developers onboard is not necessarily a greater effort than bringing senior developers onboard</strong>, especially if your criteria for success is successful, happy teams that are making the best decisions.</p><h2 id="h-how-to-build-undervalued-talent">How to build undervalued talent</h2><p>If you hire undervalued people and you train them to be successful for your organization, you will end up with teams that are more aligned and more loyal to your mission. The right way to do this is to onboard people in stages that end up with developers working on your codebase, as opposed to hiring everyone with the expectation that they’re working high-priority tickets on day one.</p><p>For example, at Branch, we have a multi-stage process where entry-level developers are initially granted a stipend to fund living expenses while taking online courses, working through sample exercises, and attending office hours for any questions. The end of the first stage is completing the Branch take-home developer hiring exercise that we have used to hire all developers.</p><p>The second stage is a paid internship that has the goal of learning how to work as part of the development team, but having the space to go slowly and ask lots of questions, and the expectation that there may be many PR revisions. We identify tickets in our backlog as “intern” work, so that there isn’t high pressure to complete anything in a short period of time.</p><p>This entire process does take time from the existing development staff, but it can be contained (mostly) into onboarding, office hours, code reviews, and weekly 1-on-1s. And it allows you to make hiring decisions that exclude bad cultural fits because you will find enough talent by investing in your workforce. You’ll create a massive competitive advantage over your competitors who are still stuck in their fraternity-hazing ruts.</p><h2 id="h-the-roi-of-building-talent">The ROI of building talent</h2><figure><div><blockquote data-width="500" data-dnt="true"><div lang="en" dir="ltr"><p>There is a delicious irony that so many venture-backed companies seek only to hire out of expensive four-year universities or people with experience working at other VC-backed startups, yet want their teams to be dedicated to the company's mission.</p><p>1/</p></div>— Joe Emison (@JoeEmison) <a href="https://twitter.com/JoeEmison/status/1343222725226209280?ref_src=twsrc%5Etfw">December 27, 2020</a></blockquote> </div></figure><p>Many venture-backed companies seek people dedicated to their missions, but then shoot themselves in the foot by only looking to hire people from “elite” schools or out of “name-brand” venture-backed companies. Those hiring pools are filled with people who are ready and able to job-hop to further themselves, and are often very weakly committed to company missions. In contrast, if a company invests in undervalued people who need some mentorship, training, and experience to reach their full potential, those people are much more likely to commit to the company and the mission with their full selves.</p><p><em>Joe Emison is the CTO of Branch Insurance, which provides home and auto insurance. Previously, Joe founded BuildFax (acquired by DMGT), Spaceful (acquired by Xceligent), and BluePrince (acquired by Harris Computer). Joe graduated with degrees in English and Mathematics from Williams College and has a law degree from Yale Law School.</em></p></div></div></div>]]>
            </description>
            <link>https://acloudguru.com/blog/business/why-you-should-invest-in-undervalued-people</link>
            <guid isPermaLink="false">hacker-news-small-sites-26008943</guid>
            <pubDate>Wed, 03 Feb 2021 00:12:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Scena360.com – Host more natural and private meetups on the web]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26008786">thread link</a>) | @djoksimo
<br/>
February 2, 2021 | https://links.scena360.com/pWwIZm | <a href="https://web.archive.org/web/*/https://links.scena360.com/pWwIZm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://links.scena360.com/pWwIZm</link>
            <guid isPermaLink="false">hacker-news-small-sites-26008786</guid>
            <pubDate>Tue, 02 Feb 2021 23:54:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I'm Glad for Using 1Password]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26008709">thread link</a>) | @jugjug
<br/>
February 2, 2021 | https://marcel.is/1password/ | <a href="https://web.archive.org/web/*/https://marcel.is/1password/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In the past month, two things happened to me that made me realize how glad I'm for using a password manager, namely <a href="https://1password.com/">1Password</a>.</p>
<p>First thing is about a login page. I was searching for a Github repo on DuckDuckGo, and I clicked on a link in the search results. As I was about to fill in the password with a 1Password shortcut, I noticed that 1Password wasn't filling in the login details. How strange, I thought. Puzzled, I looked at the url. And then I saw it—I almost fell for a phishing attack! The url was <a href="https://marcel.is/1password/github.com.cnpmjs.org">github.com.cnpmjs.org</a> instead of <a href="https://github.com/">github.com</a>. I knew of phishing attacks, and thought I'd never fell for such a simple trick. Yet, I almost did.</p>
<p>Second thing is about email. As I'm migrating away from gmail, I thought I would check out the spam folder. I usually don't do that, but I thought I'd peek in. One email caught my eye: the email subject was my password. The site must have been compromised and the attacker got hold of my email and password. Fortunately, the damage radius was minimal, as I have generated unique passwords for each site.</p>
<p><img src="https://marcel.is/img/1password-email.png" alt="1password-email"></p></div></div>]]>
            </description>
            <link>https://marcel.is/1password/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26008709</guid>
            <pubDate>Tue, 02 Feb 2021 23:46:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Smoke Signals of a Great Startup from the Lens of the Pitch Deck]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26008545">thread link</a>) | @nickfrost
<br/>
February 2, 2021 | https://cupofzhou.com/the-smoke-signals-of-a-great-startup-from-the-lens-of-the-pitch-deck/ | <a href="https://web.archive.org/web/*/https://cupofzhou.com/the-smoke-signals-of-a-great-startup-from-the-lens-of-the-pitch-deck/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-3343">
		<!-- .entry-header -->

	
	<div>
		
<figure><img loading="lazy" src="https://i2.wp.com/cupofzhou.com/wp-content/uploads/2021/01/chair-scaled.jpg?fit=525%2C316&amp;ssl=1" alt="best startup pitch deck" width="672" height="405" srcset="https://i2.wp.com/cupofzhou.com/wp-content/uploads/2021/01/chair-scaled.jpg?w=2560&amp;ssl=1 2560w, https://i2.wp.com/cupofzhou.com/wp-content/uploads/2021/01/chair-scaled.jpg?resize=300%2C181&amp;ssl=1 300w, https://i2.wp.com/cupofzhou.com/wp-content/uploads/2021/01/chair-scaled.jpg?resize=1024%2C617&amp;ssl=1 1024w, https://i2.wp.com/cupofzhou.com/wp-content/uploads/2021/01/chair-scaled.jpg?resize=768%2C463&amp;ssl=1 768w, https://i2.wp.com/cupofzhou.com/wp-content/uploads/2021/01/chair-scaled.jpg?resize=1536%2C926&amp;ssl=1 1536w, https://i2.wp.com/cupofzhou.com/wp-content/uploads/2021/01/chair-scaled.jpg?resize=2048%2C1234&amp;ssl=1 2048w" sizes="(max-width: 525px) 100vw, 525px"></figure>



<p>Founders often ask me, what slides on my pitch deck do I have to make sure I get right? The short answer, all of them. Then again, if you’re focusing on all of them, you’re focusing on none of them. So I’ll break it down by fundraising stages:</p>



<ol><li>Pre-seed/seed (might as well include angels here too)</li><li>Series A/B</li></ol>



<p>Since I spend almost no time in the later stages, I’ll refrain from extrapolating from any anecdotes there.</p>



<p>If you’re using <a href="https://www.docsend.com/">DocSend</a>, you already have the numbers for your deck viewership in front of you. As DocSend’s CEO Russ Heddleston said in his <a href="https://www.youtube.com/watch?v=CuzWbFztdDE&amp;t=2791s">interview with Jason Calacanis</a>, VCs often spend ~3.5 minutes on your deck. Though I’ve never timed myself, it seems to be in the same ballpark for myself as well. After all, it’s the deck that gets the meeting, not the deck that determines if you get funding or not.</p>



<p>Nevertheless, I hope the below contextualizes the time spent beyond the numbers, and what goes on in an investor’s head when we’re skimming through.</p>



<h2>Pre-seed/seed</h2>



<h3><strong>Team</strong></h3>



<ol><li><em>What is the <a href="https://cupofzhou.com/the-different-types-of-risk-a-vc-evaluates/">biggest risk</a> this business is taking on?</em></li><li><em>Is the person who can address the biggest risk of this business on this slide?</em><ul><li>And does this person have decision-making power?</li></ul></li></ol>



<p>Let’s say your biggest risk is that you’re creating a market where there isn’t one. Do you have that marketing/positioning specialist – either yourself or on your team – to tackle this problem? As much as I love techies, three CS PhDs are going to give me doubts.</p>



<p>Similarly, the biggest risk for a hypothetical enterprise SaaS business is  often a sales risk. Then I need proof either via your network/experience or LOIs (letters of intent) that you have corporations who will buy your product.</p>



<p>Or if it’s a tech risk, I’ll be hesitant if I see two MBAs pursuing this. Even if their first hire is an ML engineer, who owns 2% of the business. Because it doesn’t sound like the one person who can solve the biggest risk for the business has been given the trust to make the decisions that will move the needle.</p>



<p>This might be a bit controversial, but having talked with several VCs, I know I’m not alone here. I don’t care about <em>quantity</em> – number of years in the industry or at X company. Maybe a little more if you were a founding team member who helped scale a startup to $100M ARR. I do care for <em>quality </em>– your earned secret, which bleeds into the next slide.</p>



<h3><strong>Solution/product</strong></h3>



<p>The million-dollar question here is: <em>What do you know that makes money that everyone else is overlooking, underestimating, or just totally missed?</em> If you’re a frequent reader of this blog, you’ll be no stranger to this question. I’ve talked about it <a href="https://cupofzhou.com/myths-around-startups-and-business-ideas/">here</a> and <a href="https://cupofzhou.com/competitive-awareness-as-a-founder/">here</a>, just to name a few.</p>



<p>Or in other words, having spent time in the <a href="https://cdixon.org/2013/08/04/the-idea-maze">idea maze</a>, what is your earned secret? Here are two more ways of looking at it is: </p>



<ol><li>Is there an inflection point you found, as <a href="https://ventureunlocked.substack.com/p/mikemaples019">Mike Maples Jr. of Floodgate calls</a> it, in the socio-economic/technological trends that makes the future you speak of more probable?</li><li>Is it a process/mental model that you’ve built over X years in the industry that grafts extremely well to an adjacent or a broader industry?</li></ol>



<p>I believe that’s what’ll greatly increase the chances of your startup winning. Or at least hold your incumbents at bay until you reach product-market fit. If you’re able to find the first insight, then you’ll be able to find the second. And by pattern recognition, you’ll be able to find the third, fourth, and fifth in extreme velocity. It’s what we, on the VC side, call insight development. And your product/solution is the culmination of everything you and your team has learned faster and better than your competitors.</p>



<p>Of course, your product still has to address your customers’ greatest pain points. You don’t have to be the best at everything, but you have to be the best (or <a href="https://cupofzhou.com/being-the-only/">the only</a>) one who can solve your customers’ greatest frustration. So VCs, in studying how you plot out the user journey, look for: do you actually solve what you claim this massive problem in the market is?</p>



<h2>Series A/B</h2>



<h3><strong>Traction</strong></h3>



<ul><li>What are your unit economics? I’m looking for something along the lines of LTV:CAC ~3-5x.</li><li>Who’s paying?<ul><li>For enterprise, which big logo is your customer? And who are your 5-7 referenceable customers?</li><li>For consumer:<ul><li>If it’s freemium, what percent of premium users do you have? I’m looking for at least a 3-5% here.</li><li>If your platform is free, how are people paying with their time? DAU/MAU&gt;25-30%? Is your virality coefficient k&gt;1? 30- and 90-day retention cohorts &gt; 20%, ideally 40%.</li></ul></li></ul></li><li>What does your conversion funnel look like? What part of the funnel are you really winning? Subsequently, what might you need more work on?</li></ul>



<h3 id="competition"><strong>The competition</strong></h3>



<p>95 out of every 100 decks, I see two kinds of competitor slides:</p>



<ul><li>2×2 matrix/Cartesian <em>graph</em>, where the respective startup is on the upper right hand corner</li><li>The <em>checklist</em>, where the respective startup has all the boxes checked and their competitors have some percentage of the boxes checked</li></ul>



<p>Neither are inherently wrong in nature, but they give rise to two different sets of questions.</p>



<p>The former, the <em>graph</em>, often leads to the trap of including <em>vanity competitors</em>. For the sake of populating the graph, founders include the logos of companies who hypothetically could be their competitors, but when it comes down to reality, they never or rarely compete on a deal with their target user/customer. <a href="https://twitter.com/aprildunford">April Dunford</a>, author of <a href="https://www.amazon.com/Obviously-Awesome-Product-Positioning-Customers/dp/1999023005/">Obviously Awesome</a>, calls these “<a href="https://twitter.com/aprildunford/status/1334143529573081089?s=20">theoretical competitors</a>.”</p>



<p>A simple heuristic is if you jumped on a call with a customer right now and ask: “What would you use currently if our solution did not exist?”, would the names of the competitors you listed actually pop up during the call? Or with a potential customer, what did they use before you arrived? For enterprise software, Dunford says that startups usually lose <a href="https://www.lennysnewsletter.com/p/positioning">25% of their customers</a> when the answer to the above question is “nothing”. When your greatest incumbent is a habitual cycle deeply engrained in your user’s behavior, you need to either reposition your solution, or find ways to educate the market and greatly reduce the friction it takes to go from 0 to 60.</p>



<p>The latter, the <em>checklist</em>, usually sponsors a second kind of trap – <em>vanity features</em>. Founders often list a whole table’s worth of “awesome features” that their competitors don’t have, but many of which may not resolve a customer’s frustration. And on the one that does, their competitors have already taken significant market share. The key question here: Do all features listed resolve a fundamental problem your customers/users have? Which are necessary, which are nice-to-have’s? Are you winning on the features that solve fundamental problems?</p>



<p>The question I ask, as it pertains to competition, in the first or second meeting is: <em><a href="https://cupofzhou.com/competitive-awareness-as-a-founder/">What are your competitors doing right</a>?</em> If you were to put yourself in your competitor’s shoes, what did they ace and what can you learn from the success of their experiment?</p>



<h3><strong>Financial projections</strong></h3>



<ol><li><em>What are you basing the numbers off of?</em></li><li><em>What are your underlying assumptions?</em></li></ol>



<p>How fast do you claim you can double the business growth? Is it reasonable? If we’re calculating bottom-up, can you actually sell the number of units/subscriptions you claim to? What partnerships/distribution channels are you already in advanced talks with? Anything further than 2 years out, for the most part, VCs dismiss. The future is highly unpredictable. And the further out it is, the less likely you’re able to predict that.</p>



<p>I also say financial projections for Series A/B decks is because only with traction can you reasonably predict what the 12-month forward revenue is going to look like. Maybe 18 months, depending on your pending contracts as well. In the pre-seed/seed, when you’re still testing out the product with small set of beta users, it’s hard to predict. And pre-seed/seed decks that have projections without much traction are often heavily scrutinized than their counterparts that don’t have that slide.</p>



<h2>In closing</h2>



<p>Of course, that doesn’t mean you should neglect any slide on your deck. Rather, the above is just a lens for you to see which slides an investor might allocate special attention to. If you can answer the above questions well in your pitch deck, then you’re one step closer to a winning strategy not only in fundraising, but in building a company that will change the world.</p>



<p>Photo by <a href="https://unsplash.com/@ripato?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Ricardo Gomez Angel</a> on <a href="https://unsplash.com/s/photos/unique?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></p>



<hr id="block-f27d4d8e-0d1a-49ad-819b-f9e1d17d2399">



<p id="block-d65df6dd-37ad-406c-bc9d-0be2d1e7227e"><em>Stay up to date with the weekly cup of cognitive adventures inside venture capital and startups, as well as cataloging the history of tomorrow through the bookmarks of yesterday!</em></p>









	</div><!-- .entry-content -->

	 <!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://cupofzhou.com/the-smoke-signals-of-a-great-startup-from-the-lens-of-the-pitch-deck/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26008545</guid>
            <pubDate>Tue, 02 Feb 2021 23:27:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Running Debian on a $5 Single Board Computer with 32MB RAM – The Lichee Nano Pi]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26008279">thread link</a>) | @technlogger
<br/>
February 2, 2021 | https://techscoop.xyz/2021/02/02/running-debian-on-a-5-single-board-computer-the-lichee-nano-pi/ | <a href="https://web.archive.org/web/*/https://techscoop.xyz/2021/02/02/running-debian-on-a-5-single-board-computer-the-lichee-nano-pi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
				<div id="content">
			
	<div id="primary">
		<main id="main">
			
<article id="post-150" itemtype="https://schema.org/CreativeWork" itemscope="">
	<div>
				
					
			
		<div itemprop="text">
			
<h2>Introduction</h2>



<p>The Modern Single Board Computer such as the infamous Raspberry Pi are designed to run full fledged desktop operating systems, consume a tiny amount of power and be affordable for just about anyone. </p>



<div><p>What happens if the typical SBC is scaled down tenfold? What would someone do with such a device? </p><p>The Lichee Nano Pi is exactly this, the entire Computer is the size of an SD card, runs Linux and has 20 GPIO pins including SPI, TWI and UART. </p><p>Many would recognise this device as a micro controller along the lines of an Arduino Nano or RPI Pico although this is absolutely not the case. With 32MB of DDR SDRAM, 16MB SPI Flash and a 900MHz Arm 926EJS CPU its actually a very small computer! </p></div>



<p>Out of the box the Lichee Nano Pi supports the following Operating Systems:</p>



<ul><li>BSP Linux 3.10.</li><li>Mainline Linux 4.10.</li><li>RT-Thread</li></ul>



<p>Common Linux distributions are few and far between however community members have worked on various ports. Buildroot makes it simple to create a bootable install for either the built-in SPI flash or SD card. </p>



<p>Unfortunately Armbian have not released their distro for the Lichee Nano Pi. However I spent some time over the Xmas period to create a Debian port. </p>



<h2>Running Debian on the Lichee Nano Pi</h2>



<figure><img src="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/image.png?resize=750%2C132&amp;ssl=1" data-src="https://i0.wp.com/blog.jmdawson.co.uk/wp-content/uploads/2021/01/image.png?resize=750%2C132&amp;ssl=1" alt="Debian on the Lichee nano Pi"></figure>



<div><p>Debian runs almost flawlessly! Consuming just 7MB of RAM at idle there are plenty of resources free, the 900MHz ARM 926EJS CPU performs perfectly fine and networking is handled via a USB OTG Ethernet Adaptor – Whilst the SPIO Wifi module would work in Debian you do loose access to the Micro SD card slot and sadly a Debian install will not fit on the 16MB SPI flash. </p><p>You can find out how I created a Debian install over at my <a href="https://blog.jmdawson.co.uk/lichee-nano-pi-will-it-run-debian/" target="_blank" rel="noreferrer noopener">blog</a>. <br>Find out more about my projects on <a href="https://twitter.com/jmdawson_blog" target="_blank" rel="noreferrer noopener">Twitter</a>. </p></div>




		</div>

				
			</div>
</article>

			

					</main>
	</div>

	

	</div>
</div></div>]]>
            </description>
            <link>https://techscoop.xyz/2021/02/02/running-debian-on-a-5-single-board-computer-the-lichee-nano-pi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26008279</guid>
            <pubDate>Tue, 02 Feb 2021 23:03:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Four books professional developers should read (and a few you don't need to)]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 6 (<a href="https://news.ycombinator.com/item?id=26007626">thread link</a>) | @eatonphil
<br/>
February 2, 2021 | https://notes.eatonphil.com/books-developers-should-read.html | <a href="https://web.archive.org/web/*/https://notes.eatonphil.com/books-developers-should-read.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <p>These are the books I recommend to developers wanting to improve their
skills as professional programmers because of high information
density, believable premises/examples, and being well edited.</p>
<p>You don't need to read books to improve as a developer but
they are unparalleled in quickly helping you gain depth in a subject.</p>
<h3 id="effective-python:-90-specific-ways-to-write-better-python">Effective Python: 90 Specific Ways to Write Better Python</h3><p>If you're a Python developer wanting to improve your craft you should
read this. Good Python starts with a deep understanding of the
standard library and language.</p>
<h3 id="high-performance-browser-networking">High Performance Browser Networking</h3><p>If your code is triggered by a desktop or mobile browser you should
read this. It is a thorough high level introduction to mobile
networks, browser network protocols, and fundementals of networking.</p>
<h3 id="designing-data-intensive-applications">Designing Data-Intensive Applications</h3><p>If your databases and APIs are a bottleneck you should read this. A
solid introduction to distributed computing, data transfer, indexing,
etc.</p>
<h3 id="site-reliability-engineering:-how-google-runs-production-services">Site Reliability Engineering: How Google Runs Production Services</h3><p>If you are responsible for services in production you should read
this. It's Google specific but is an excellent background on practices
for monitoring and maintaining production environments.</p>
<h3 id="that's-it!">That's it!</h3><p>Generic software books conspicuously not on this list for
me:</p>
<ul>
<li>Clean Code</li>
<li>JavaScript the Good Parts</li>
<li>Design Patterns/Gang of Four</li>
<li>Structure and Interpretation of Computer Programs</li>
<li>A Philosophy of Software Design</li>
</ul>
<p>They're not all bad but give nowhere near as much return for the
investment of your time.</p>
<h4 id="feedback">Feedback</h4><p>As always, I'd love to <a href="mailto:me@eatonphil.com">hear from you</a> with
questions or ideas.</p>
<blockquote><p lang="en" dir="ltr">Four books I recommend to professional developers wanting to improve their craft, and a few I'd not<a href="https://t.co/1aTrfqZ9bd">https://t.co/1aTrfqZ9bd</a></p>— Phil Eaton (@phil_eaton) <a href="https://twitter.com/phil_eaton/status/1356391931274756096?ref_src=twsrc%5Etfw">February 2, 2021</a></blockquote> 

      </div>
    </div></div>]]>
            </description>
            <link>https://notes.eatonphil.com/books-developers-should-read.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26007626</guid>
            <pubDate>Tue, 02 Feb 2021 22:13:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Killing Containers at Scale]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26007428">thread link</a>) | @flurly
<br/>
February 2, 2021 | https://blog.repl.it/killing-containers-at-scale | <a href="https://web.archive.org/web/*/https://blog.repl.it/killing-containers-at-scale">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>To make it so that anyone with a web browser can code on Replit, our backend infrastructures runs on preemptible VMs. That means the computer running your code can shutdown at any time! We've made it really fast for repls to reconnect when that happens. Despite our best efforts, though, people had been seeing repls stuck connecting for a long time. After some profiling and digging into the Docker source code, we found and fixed the problem. Our session connection error rate dropped from 3% to under 0.5% and our 99th percentile session boot time dropped from 2 minutes to 15 seconds.</p>
<p>There were many different causes of stuck repls, varying from: unhealthy machines, race conditions that lead to deadlock, and slow container shutdowns. This post focuses how we fixed the last cause, slow container shutdowns. Slow container shutdowns affected nearly everyone using the platform and would cause a repl to be inaccesible for up to a minute.</p>
<h3 id="replit-architecture">Replit Architecture</h3>
<p>Before going in depth on fixing slow container shutdowns, you'll need some knowledge of Replit's architecture.</p>
<p>When you open a repl, the browser opens a websocket connection to a Docker container running on a preemptible VM. Each of the VMs run something we call <code>conman</code>, which is short for container manager.</p>
<p>We must ensure that there is only a single container per repl at anytime. The container is used to facilitate multiplayer features, so its important that every user in the repl connects to the same container.</p>
<p>When a machine that hosts these Docker containers shuts down, we have to wait for each container to be destroyed before they can be started again on some other machine. Since we use preemptible instances, this process happens frequently.</p>
<p>Below you can see the typical flow when trying to access a repl on a mid-shutdown instance.</p>
<p><img src="https://blog.repl.it/images/destroying-stuck-repls/simplified_arch.png" alt="Simplified diagram of repl.it conman architecture"></p>
<ol>
<li>A user opens their repl which opens the IDE and attempts to connect to the backend evaluation server via a WebSocket.</li>
<li>The request hits a load balancer which selects a conman instance to proxy to based on CPU usage.</li>
<li>A healthy, living conman gets the request. Conman notices that the request is for a container that is living on a different conman and proxies the request there.</li>
<li>Sadly this conman is shutting down and rejects the WebSocket connection!</li>
</ol>
<p>Requests will continue to fail until either:</p>
<ol>
<li>The docker container is shut down and the repl container entry in the global store is removed.</li>
<li>Conman finishes shutting down and is no longer accessible. In this case, the first conman will remove the old repl container entry and start a new container.</li>
</ol>
<h3 id="slow-container-shutdowns">Slow Container Shutdowns</h3>
<p>Our preemptible VMs are given 30 seconds to cleanly shutdown before they are forcibly terminated. After some investigation, we found that we rarely finished shutting down within those 30 seconds. This prompted us to dig further and instrument the machine shutdown routine.</p>
<p>After adding some more logging and metrics around machine shutdowns, it became clear that calls to <code>docker kill</code> were taking much longer than expected. <code>docker kill</code> usually took a few milliseconds to kill a repl container during normal operation, but we spent 20+ seconds killing 100-200 containers at the same time during shutdown.</p>
<p>Docker offers two ways to stop a container: <code>docker stop</code> and <code>docker kill</code>. Docker stop sends a <code>SIGTERM</code> signal to the container and gives it a grace period to gracefully shutdown. If the container doesn't shutdown within the grace period, the container is sent <code>SIGKILL</code>. We don't care about gracefully shutting down the container and would rather shut it down as quickly as possible. <code>docker kill</code> sends <code>SIGKILL</code> which should kill the container immediately. For some reason, the theory did not match reality, <code>docker kill</code> shouldn't be taking on the order of seconds to <code>SIGKILL</code> the container. There must be something else going on.</p>
<p>To dig into this, here is a script which will create 200 docker containers and time how long it takes to kill them at the same time.</p>
<pre><code><span>#!/bin/bash
</span>
COUNT=200
<span>echo</span> <span>"Starting <span>$COUNT</span> containers..."</span>
<span>for</span> i <span>in</span> $(seq 1 <span>$COUNT</span>); <span>do</span>
    <span>printf</span> .
    docker run -d --name <span>test</span>-<span>$i</span> nginx &gt; /dev/null 2&gt;&amp;1
<span>done</span>

<span>echo</span> -e <span>"\nKilling <span>$COUNT</span> containers..."</span>
time $(docker <span>kill</span> $(docker container ls -a --filter <span>"name=test"</span> --format <span>"{{.ID}}"</span>) &gt; /dev/null 2&gt;&amp;1)

<span>echo</span> -e <span>"\nCleaning up..."</span>
docker rm $(docker container ls -a --filter <span>"name=test"</span> --format <span>"{{.ID}}"</span>) &gt; /dev/null 2&gt;&amp;1</code></pre>
<p>Running this on the same kind of VM we run in production, a GCE n1-highmem-4 instance, yields:</p>
<pre><code>Starting 200 containers...
................................&lt;trimmed&gt;
Killing 200 containers...

real    0m37.732s
user    0m0.135s
sys     0m0.081s

Cleaning up...</code></pre><p>This confirmed our suspicions that something is going in inside the Docker runtime which causes shutdowns to be so slow. Time to dig into Docker itself...</p>
<p>Docker daemon has an option to <a href="https://docs.docker.com/config/daemon/#enable-debugging">enable debug logging</a>. These logs let us peak into what what's happening inside of dockerd and each entry has a timestamp so it might provide some insight into where all this time is being spent.</p>
<p>With debug logging enabled, let's rerun the script and look at dockerd's logs. This will output a lot of log messages since we are dealing with 200 container, so I've hand-selected portions of the logs that are of interest.</p>
<pre><code>2020-12-04T04:30:53.084Z    dockerd    Calling GET /v1.40/containers/json?all=1&amp;filters=%7B%22name%22%3A%7B%22test%22%3Atrue%7D%7D
2020-12-04T04:30:53.084Z    dockerd    Calling HEAD /_ping
2020-12-04T04:30:53.468Z    dockerd    Calling POST /v1.40/containers/33f7bdc9a123/kill?signal=KILL
2020-12-04T04:30:53.468Z    dockerd    Sending kill signal 9 to container 33f7bdc9a1239a3e1625ddb607a7d39ae00ea9f0fba84fc2cbca239d73c7b85c
2020-12-04T04:30:53.468Z    dockerd    Calling POST /v1.40/containers/2bfc4bf27ce9/kill?signal=KILL
2020-12-04T04:30:53.468Z    dockerd    Sending kill signal 9 to container 2bfc4bf27ce93b1cd690d010df329c505d51e0ae3e8d55c888b199ce0585056b
2020-12-04T04:30:53.468Z    dockerd    Calling POST /v1.40/containers/bef1570e5655/kill?signal=KILL
2020-12-04T04:30:53.468Z    dockerd    Sending kill signal 9 to container bef1570e5655f902cb262ab4cac4a873a27915639e96fe44a4381df9c11575d0
...</code></pre><p>Here we can see the requests to kill each container, and that <code>SIGKILL</code>is sent almost immediately to each container.</p>
<p>Heres some log entries seen around 30 seconds after executing <code>docker kill</code>:</p>
<pre><code>...
2020-12-04T04:31:32.308Z    dockerd    Releasing addresses for endpoint test-1's interface on network bridge
2020-12-04T04:31:32.308Z    dockerd    ReleaseAddress(LocalDefault/172.17.0.0/16, 172.17.0.2)
2020-12-04T04:31:32.308Z    dockerd    Released address PoolID:LocalDefault/172.17.0.0/16, Address:172.17.0.2 Sequence:App: ipam/default/data, ID: LocalDefault/172.17.0.0/16, DBIndex: 0x0, Bits: 65536, Unselected: 65529, Sequence: (0xfa000000, 1)-&gt;(0x0, 2046)-&gt;(0x1, 1)-&gt;end Curr:202
2020-12-04T04:31:32.308Z    dockerd    Releasing addresses for endpoint test-5's interface on network bridge
2020-12-04T04:31:32.308Z    dockerd    ReleaseAddress(LocalDefault/172.17.0.0/16, 172.17.0.6)
2020-12-04T04:31:32.308Z    dockerd    Released address PoolID:LocalDefault/172.17.0.0/16, Address:172.17.0.6 Sequence:App: ipam/default/data, ID: LocalDefault/172.17.0.0/16, DBIndex: 0x0, Bits: 65536, Unselected: 65530, Sequence: (0xda000000, 1)-&gt;(0x0, 2046)-&gt;(0x1, 1)-&gt;end Curr:202
2020-12-04T04:31:32.308Z    dockerd    Releasing addresses for endpoint test-3's interface on network bridge
2020-12-04T04:31:32.308Z    dockerd    ReleaseAddress(LocalDefault/172.17.0.0/16, 172.17.0.4)
2020-12-04T04:31:32.308Z    dockerd    Released address PoolID:LocalDefault/172.17.0.0/16, Address:172.17.0.4 Sequence:App: ipam/default/data, ID: LocalDefault/172.17.0.0/16, DBIndex: 0x0, Bits: 65536, Unselected: 65531, Sequence: (0xd8000000, 1)-&gt;(0x0, 2046)-&gt;(0x1, 1)-&gt;end Curr:202
2020-12-04T04:31:32.308Z    dockerd    Releasing addresses for endpoint test-2's interface on network bridge
2020-12-04T04:31:32.308Z    dockerd    ReleaseAddress(LocalDefault/172.17.0.0/16, 172.17.0.3)
2020-12-04T04:31:32.308Z    dockerd    Released address PoolID:LocalDefault/172.17.0.0/16, Address:172.17.0.3 Sequence:App: ipam/default/data, ID: LocalDefault/172.17.0.0/16, DBIndex: 0x0, Bits: 65536, Unselected: 65532, Sequence: (0xd0000000, 1)-&gt;(0x0, 2046)-&gt;(0x1, 1)-&gt;end Curr:202</code></pre><p>These logs don't give us a full picture of everything dockerd is doing, but this makes it seem like dockerd might be spending a lot of time releasing network addresses.</p>
<p>At this point in my adventure, I decided it was time to start digging into docker engine's source code and build my own version of dockerd with some extra logging.</p>
<p>I started out by looking for the codepath that handles container kill requests. I added some extra log messages with timings of different spans and eventually I found out where all this time was being spent:</p>
<p><code>SIGKILL</code> is sent to the container and then before responding to the HTTP request, the engine waits for the container to no longer be running (<a href="https://github.com/docker/engine/blob/ab373df1125b6002603456fd7f554ef370389ad9/daemon/kill.go#L174">source</a>)</p>
<pre><code>    &lt;-container.Wait(context.Background(), containerpkg.WaitConditionNotRunning)</code></pre><p>The <code>container.Wait</code> function returns a channel which receives the exit code and any error from the container. Unfortunately, to get the exit code and error, a lock on the interal container struct must be acquired. (<a href="https://github.com/docker/engine/blob/ab373df1125b6002603456fd7f554ef370389ad9/container/state.go#L212-L233">source</a>)</p>
<pre><code>  ...

    <span>go</span> <span><span>func</span><span>()</span></span> {
        <span>select</span> {
        <span>case</span> &lt;-ctx.Done():
            
            resultC &lt;- StateStatus{
                exitCode: <span>-1</span>,
                err:      ctx.Err(),
            }
            <span>return</span>
        <span>case</span> &lt;-waitStop:
        <span>case</span> &lt;-waitRemove:
        }

        s.Lock() 
        result := StateStatus{
            exitCode: s.ExitCode(),
            err:      s.Err(),
        }
        s.Unlock()

        resultC &lt;- result
    }()

    <span>return</span> resultC

  ...</code></pre>
<p>As it turns out, this container lock is held while cleaning up network resources and the <code>s.Lock()</code> above ends up waiting for a long time. This happens inside <a href="https://github.com/docker/engine/blob/ab373df1125b6002603456fd7f554ef370389ad9/daemon/monitor.go#L27-L103"><code>handleContainerExit</code></a>. The container lock is held for the duration of the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.repl.it/killing-containers-at-scale">https://blog.repl.it/killing-containers-at-scale</a></em></p>]]>
            </description>
            <link>https://blog.repl.it/killing-containers-at-scale</link>
            <guid isPermaLink="false">hacker-news-small-sites-26007428</guid>
            <pubDate>Tue, 02 Feb 2021 21:58:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Silence Is a Commons (1983)]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 7 (<a href="https://news.ycombinator.com/item?id=26007100">thread link</a>) | @cardamomo
<br/>
February 2, 2021 | http://www.davidtinapple.com/illich/1983_silence_commons.html | <a href="https://web.archive.org/web/*/http://www.davidtinapple.com/illich/1983_silence_commons.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<div><span size="+2">Silence is a Commons by Ivan Illich</span><p>
						
						Computers are doing to communication<br>
						what fences did to pastures<br>
						and cars did to streets.</p><p>
						
						by Ivan Illich</p><p>
						
						
						
						
						Minna-san, gladly I accept the honour of addressing this forum on Science and Man. The theme that Mr. Tsuru proposes, "The Computer-Managed Society," sounds an alarm. Clearly you foresee that machines which ape people are tending to encroach on every aspect of people's lives, and that such machines force people to behave like machines. The new electronic devices do indeed have the power to force people to "communicate" with them and with each other on the terms of the machine. Whatever structurally does not fit the logic of machines is effectively filtered from a culture dominated by their use.</p><p>
						
						The machine-like behaviour of people chained to electronics constitutes a degradation of their well-being and of their dignity which, for most people in the long run, becomes intolerable. Observations of the sickening effect of programmed environments show that people in them become indolent, impotent, narcissistic and apolitical. The political process breaks down, because people cease to be able to govern themselves; they demand to be managed.</p><p>
						
						I congratulate Asahi Shimbun on its efforts to foster a new democratic consensus in Japan, by which your more than seven million readers become aware of the need to limit the encroachment of machines on the style of their own behaviour. It is important that precisely Japan initiate such action. Japan is looked upon as the capital of electronics; it would be marvellous if it became for the entire world the model of a new politics of self-limitation in the field of communication, which, in my opinion, is henceforth necessary if a people wants to remain self-governing.</p><p>
						
						Electronic management as a political issue can be approached in several ways. I propose, at the beginning of this public consultation, to approach the issue as one of political ecology. Ecology, during the last ten years, has acquired a new meaning. It is still the name for a branch of professional biology, but the term now increasingly serves as the label under which a broad, politically organized general public analyzes and influences technical decisions. I want to focus on the new electronic management devices as a technical change of the human environment which, to be benign, must remain under political (and not exclusively expert) control. I have chosen this focus for my introduction, because I thus continue my conversation with those three Japanese colleagues to whom I owe what I know about your country - Professors Yoshikazu Sakamoto, Joshiro Tamanoi and Jun Ui.</p><p>
						
						In the 13 minutes still left to me on this rostrum I will clarify a distinction that I consider fundamental to political ecology. I shall distinguish the environment as commons from the environment as resource. On our ability to make this particular distinction depends not only the construction of a sound theoretical ecology, but also - and more importantly - effective ecological jurisprudence Minna-san, how I wish, at this point, that I were a pupil trained by your Zen poet, the great Basho. Then perhaps in a bare 17 syllables I could express the distinction between the commons within which people's subsistence activities are embedded, and resources that serve for the economic production of those commodities on which modem survival depends. If I were a poet, perhaps I would make this distinction so beautifully and incisively that it would penetrate your hearts and remain unforgettable. Unfortunately I am not a Japanese poet. I must speak to you in English, a language that during the last 100 years has lost the ability to make this distinction, and - in addition - I must speak through translation. Only because I may count on the translating genius of Mr. Muramatsu do I dare to recover Old English meanings with a talk in Japan.</p><p>
						
						"Commons" is an Old English word. According to my Japanese friends, it is quite close to the meaning that iriai still has in Japanese "Commons," like iriai, is a word which, in preindustrial times, was used to designate certain aspects of the environment. People called commons those parts of the environment for which customary law exacted specific forms of community respect. People called commons that part of the environment which lay beyond their own thresholds and outside of their own possessions, to which, however, they had recognized claims of usage, not to produce commodities but to provide for the subsistence of their households. The customary law which humanized the environment by establishing the commons was usually unwritten. It was unwritten law not only because people did not care to write it down, but because what it protected was a reality much too complex to fit into paragraphs. The law of the commons regulates the right of way, the right to fish and to hunt, to graze, and to collect wood or medicinal plants in the forest.</p><p>
						
						An oak tree might be in the commons. Its shade, in summer, is reserved for the shepherd and his flock; its acorns are reserved for the pigs of the neighbouring peasants; its dry branches serve as fuel for the widows of the village; some of its fresh twigs in springtime are cut as ornaments for the church - and at sunset it might be the place for the village assembly. When people spoke about commons, iriai, they designated an aspect of the environment that was limited, that was necessary for the community's survival, that was necessary for different groups in different ways, but which, in a strictly economic sense, was not perceived as scarce.</p><p>
						
						When today, in Europe, with university students I use the term "commons" (in German Almende or Gemeinheit, in Italian gli usi civici) my listeners immediately think of the eighteenth century. They think of those pastures in England on which villagers each kept a few sheep, and they think of the "enclosure of the pastures" which transformed the grassland from commons into a resource on which commercial flocks could be raised. Primarily, however, my students think of the innovation of poverty which came with enclosure: of the absolute impoverishment of the peasants, who were driven from the land and into wage labour, and they think of the commercial enrichment of the lords.</p><p>
						
						In their immediate reaction, my students think of the rise of a new capitalist order. Facing that painful newness, they forget that enclosure also stands for something more basic. The enclosure of the commons inaugurates a new ecological order: Enclosure did not just physically transfer the control over grasslands from the peasants to the lord. Enclosure marked a radical change in the attitudes of society towards the environment. Before, in any juridical system, most of the environment had been considered as commons from which most people could draw most of their sustenance without needing to take recourse to the market. After enclosure, the environment became primarily a resource at the service of "enterprises" which, by organizing wage-labor, transformed nature into the goods and services on which the satisfaction of basic needs by consumers depends. This transformation is in the blind spot of political economy.</p><p>
						
						This change of attitudes can be illustrated better if we think about roads rather than about grasslands. What a difference there was between the new and the old parts of Mexico City only 20 years ago. In the old parts of the city the streets were true commons. Some people sat on the road to sell vegetables and charcoal. Others put their chairs on the road to drink coffee or tequila. Others held their meetings on the road to decide on the new headman for the neighbourhood or to determine the price of a donkey. Others drove their donkeys through the crowd, walking next to the heavily loaded beast of burden; others sat in the saddle. Children played in the gutter, and still people walking could use the road to get from one place to another.</p><p>
						
						Such roads were not built for people. Like any true commons, the street itself was the result of people living there and making that space liveable. The dwellings that lined the roads were not private homes in the modern sense - garages for the overnight deposit of workers. The threshold still separated two living spaces, one intimate and one common. But neither homes in this intimate sense nor streets as commons survived economic development.</p><p>
						
						In the new sections of Mexico City, streets are no more for people. They are now roadways for automobiles, for buses, for taxis, cars, and trucks. People are barely tolerated on the streets unless they are on their way to a bus stop. If people now sat down or stopped on the street, they would become obstacles for traffic, and traffic would be dangerous to them. The road has been degraded from a commons to a simple resource for the circulation of vehicles. People can circulate no more on their own. Traffic has displaced their mobility. They can circulate only when they are strapped down and are moved. </p><p>
						
						The appropriation of the grassland by the lords was challenged, but the more fundamental transformation of grassland (or of roads) from commons to resource has happened, until recently, without being subjected to criticism. The appropriation of the environment by the few was clearly recognized as an intolerable abuse By contrast, the even more degrading transformation of people into members of an industrial labour force and into consumers was taken, until recently, for granted. For almost a hundred years the majority of political parties has challenged the accumulation of environmental resources in private hands. However, the issue was argued in terms of the private utilization of these resources, not the distinction of commons. Thus …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.davidtinapple.com/illich/1983_silence_commons.html">http://www.davidtinapple.com/illich/1983_silence_commons.html</a></em></p>]]>
            </description>
            <link>http://www.davidtinapple.com/illich/1983_silence_commons.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26007100</guid>
            <pubDate>Tue, 02 Feb 2021 21:35:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using HTMX with Asp.net Core: Introduction – Jerrie Pelser's Blog]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26007023">thread link</a>) | @076ae80a-3c97-4
<br/>
February 2, 2021 | https://www.jerriepelser.com/blog/using-htmx-with-aspnet-core | <a href="https://web.archive.org/web/*/https://www.jerriepelser.com/blog/using-htmx-with-aspnet-core">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><strong>PS:</strong> If you need assistance on any of your ASP.NET Core projects, I am <!-- --> <a href="https://www.jerriepelser.com/hire/">available for hire</a> <!-- --> for freelance work.</p><div><h2>Introduction</h2>
<p>A few years ago I wrote a series of blog posts around the theme of <a href="https://www.jerriepelser.com/blog/you-might-not-need-angular-introduction/">“You might not need Angular”</a>. The premise of that series was that we want to add tiny bits of interactivity to web pages in many situations without having to resort to a client-side framework such as Angular.</p>
<p>In that post, I mentioned that Blazor (<em>which at that stage was at version 0.5.0</em>) could improve things in the future. Blazor has since been released, and in many cases, it is a viable alternative to SPA frameworks. However, for me, it is still not feasible in many situations. Blazor Server suffers from latency and scalability issues, and Blazor WebAssembly has a big download size.</p>

<p>I believe there is still a middle ground where you may be happy with using Razor Pages or MVC, but want to add <em>sprinkles</em> of interactivity to some of your pages to give a better user experience.</p>
<p>In this new series, I will introduce you to <a href="https://htmx.org/">HTMX</a>, a library that allows you to do this. It works in a very similar fashion to the now-deprecated <a href="https://github.com/aspnet/jquery-ajax-unobtrusive">jQuery Unobtrusive Ajax library</a> which I used in the first series. I will also work through a few common scenarios and demonstrate how you can implement it with Razor Pages and HTMX.</p>
<p>This series consists of the following blog posts:</p>
<ol>
<li>Introduction (this blog post)</li>
<li><a href="https://www.jerriepelser.com/blog/htmx-deleting-items/">Deleting items from a list</a></li>
<li>Do a full page refresh when deleting items (coming 9 February)</li>
<li>Inline editing (coming 16 February)</li>
<li>Infinite scrolling (coming 23 February)</li>
<li>Real-time search (coming 2 March)</li>
</ol>
<h2>The HTMX library</h2>
<p>HTMX is a library that allows you to add features such as AJAX and DOM updates to your web pages. Instead of requiring you to write JavaScript, HTMX enables you to add this functionality by adding some attributes to your HTML markup.</p>
<p>To get a better understanding of this model, let’s look at the following example from the HTMX website:</p>
<div data-language="html"><pre><code><span><span><span>&lt;</span>button</span> <span>hx-post</span><span><span>=</span><span>"</span>/clicked<span>"</span></span> <span>hx-swap</span><span><span>=</span><span>"</span>outerHTML<span>"</span></span><span>&gt;</span></span>
    Click Me
<span><span><span>&lt;/</span>button</span><span>&gt;</span></span></code></pre></div>
<p>You can see that we have a <code>button</code> element with two additional <code>hx-*</code> attributes defined.</p>
<ol>
<li>The <code>hx-post</code> attribute tells HTMX that when a user clicks on the button, it should perform an HTTP POST request to <code>/clicked</code>.</li>
<li>The <code>hx-swap</code> attribute tells HTMX that it should replace the <code>button</code> element with the content from this request’s response.</li>
</ol>
<p>We will cover HTMX in more detail in the remaining blog posts in this series, but you can also refer to the <a href="https://htmx.org/docs/">HTMX documentation</a> if you want a better understanding of it.</p>
<h2>Installing HTMX in an ASP.NET Core application</h2>
<p>The quickest way to add HTMX to your ASP.NET Core application is to reference the script via <a href="https://unpkg.com/">UNPKG</a>. To do that, add the following script to the Razor Pages where you want to use it:</p>
<div data-language="html"><pre><code><span><span><span>&lt;</span>script</span> <span>src</span><span><span>=</span><span>"</span>https://unpkg.com/htmx.org@1.1.0<span>"</span></span> <span>integrity</span><span><span>=</span><span>"</span>sha384-JVb/MVb+DiMDoxpTmoXWmMYSpQD2Z/1yiruL8+vC6Ri9lk6ORGiQqKSqfmCBbpbX<span>"</span></span> <span>crossorigin</span><span><span>=</span><span>"</span>anonymous<span>"</span></span><span>&gt;</span></span><span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span></code></pre></div>
<p>The script above uses version 1.1.0, but you can refer to the <a href="https://htmx.org/docs/#installing">installation section</a> on the HTMX website for the latest version and installation instructions.</p>
<p>If you prefer to make use of <a href="https://docs.microsoft.com/en-us/aspnet/core/client-side/libman/?view=aspnetcore-5.0">LibMan</a>, you can run the following command:</p>
<div data-language="bash"><pre><code>libman <span>install</span> htmx.org@1.1.0 --provider unpkg --files dist/htmx.min.js</code></pre></div>
<p>Then, proceed to add the reference to the HTMX file as follows:</p>
<div data-language="html"><pre><code><span><span><span>&lt;</span>script</span> <span>src</span><span><span>=</span><span>"</span>~/lib/htmx.org/dist/htmx.min.js<span>"</span></span><span>&gt;</span></span><span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span></code></pre></div>
<h2>Conclusion</h2>
<p>In this blog post, I gave you a brief introduction to this series and HTMX and demonstrated how you could add the HTMX library to your existing ASP.NET Core application. In the <a href="https://www.jerriepelser.com/blog/htmx-deleting-items">next blog post</a>, I will show you how to use HTMX to delete items from a list.</p>
<p>You can find the source code for this series at <a href="https://github.com/jerriepelser-blog/htmx-with-aspnet-core">https://github.com/jerriepelser-blog/htmx-with-aspnet-core</a>.</p></div></div>]]>
            </description>
            <link>https://www.jerriepelser.com/blog/using-htmx-with-aspnet-core</link>
            <guid isPermaLink="false">hacker-news-small-sites-26007023</guid>
            <pubDate>Tue, 02 Feb 2021 21:31:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Usenet Hosted Amazon’s First Job Posting]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26006987">thread link</a>) | @elvis70
<br/>
February 2, 2021 | http://www.ngrblog.com/amazon-usenet-post/ | <a href="https://web.archive.org/web/*/http://www.ngrblog.com/amazon-usenet-post/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>On August 22, 1994 (over 25 years ago) Jeff Bezos posted the first Amazon job offer to Usenet seeking a very talented developer to help launch the site. While Bezos hadn’t named it Amazon yet, the job posting on Usenet clearly shows that he needs a coder with lots of talent. In return he promises “meaningful equity ownership”. We can only imagine what that would be worth in Amazon stock today. Shel Kaphan, Amazon’s first CTO was hired shortly after the newsgroup post. It’s not clear whether or not he responded to the post but it’s very cool to see the history represented on Usenet.&nbsp; Here’s a look at the post.</p>
<p><img loading="lazy" src="http://1t21h7uca2ehzzcj298yrla12.wpengine.netdna-cdn.com/wp-content/uploads/2019/07/amazon-job-post.png" alt="Amazon's first job post" width="580" height="504" srcset="http://1t21h7uca2ehzzcj298yrla12.wpengine.netdna-cdn.com/wp-content/uploads/2019/07/amazon-job-post.png 580w, http://1t21h7uca2ehzzcj298yrla12.wpengine.netdna-cdn.com/wp-content/uploads/2019/07/amazon-job-post-300x261.png 300w" sizes="(max-width: 580px) 100vw, 580px"></p>
<p>The post reads:</p>
<blockquote><p>Well-capitalized start-up seeks extremely talented C/C++/Unix developers to help pioneer commerce on the Internet. You must have experience designing and building large and complex (yet maintainable) systems, and you should be able to do so in about one-third the time that most competent people think possible. You should have a BS, MS, or PhD in Computer Science or the equivalent. Top-notch communication skills are essential. Familiarity with web servers and HTML would be helpful but is not necessary.</p>
<p>Expect talented, motivated, intense, and interesting co-workers. Must be willing to relocate to the Seattle area (we will help cover moving costs).</p>
<p>Your compensation will include meaningful equity ownership.</p>
<p>Send resume and cover letter to Jeff Bezos:</p>
<p>mail: be…@netcom.com<br>
fax: 206/828-0951<br>
US mail: Cadabra, Inc.<br>
10704 N.E. 28th St.<br>
Bellevue, WA 98004</p>
<p>We are an equal opportunity employer.</p>
<p>“It’s easier to invent the future than to predict it.” — Alan Kay</p></blockquote>
<p>First job posting to world domination in 25 years, all from a single Usenet post 🙂</p>
<!--<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="http://www.ngrblog.com/amazon-usenet-post/"
    dc:identifier="http://www.ngrblog.com/amazon-usenet-post/"
    dc:title="Usenet Hosted Amazon&#8217;s First Job Posting"
    trackback:ping="http://www.ngrblog.com/amazon-usenet-post/trackback/" />
</rdf:RDF>-->
</div></div>]]>
            </description>
            <link>http://www.ngrblog.com/amazon-usenet-post/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26006987</guid>
            <pubDate>Tue, 02 Feb 2021 21:28:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Confidence is the natural result of positive reinforcement]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26006936">thread link</a>) | @aminozuur
<br/>
February 2, 2021 | https://eftegarie.com/confidence/ | <a href="https://web.archive.org/web/*/https://eftegarie.com/confidence/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-4357">

			<h2>Confidence</h2>

			<div>

	
				<p>Confidence is a rare commodity.&nbsp;It&nbsp;grows organically after <em>positive reinforcement</em>. Without positive reinforcement, there can be no confidence.</p>
<p>People who&nbsp;say otherwise,&nbsp;generally conflict fake confidence&nbsp;for the real thing. Fake confidence can backfire as&nbsp;a wise person&nbsp;can see right through your bullshit.</p>
<p>Luckily, you can do things that lead to positive reinforcement, on&nbsp;whatever subject you’re insecure about. A world-class kickboxer might feel confident in the ring,&nbsp;yet nervous when filing his taxes.&nbsp;His accountant might feel anxious talking to hot girls. And a womanizer might feel retarded trying to learn web development.</p>
<p>As long as you’re willing to adopt a&nbsp;<em>beginner’s mindset</em>&nbsp;and keep learning and iterating, you&nbsp;will become better at whatever you’re doing. And once you experience enough positive reinforcement, your confidence will grow naturally.</p><p>
February 2, 2021


			</p></div>
		</div></div>]]>
            </description>
            <link>https://eftegarie.com/confidence/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26006936</guid>
            <pubDate>Tue, 02 Feb 2021 21:25:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Past, Present, and Future of React State Management]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26006594">thread link</a>) | @leerob
<br/>
February 2, 2021 | https://leerob.io/blog/react-state-management | <a href="https://web.archive.org/web/*/https://leerob.io/blog/react-state-management">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>React was introduced in May 2013. Its paradigm shift was that <strong>your UI was a function of your state</strong>. Given some component state, React can determine what your component will look like. React is <em>built</em> upon the idea of state. However, state has long been one of the most difficult parts of building a React application.</p><p>Let's imagine state management in React as a rugged tool belt. You've used this tool belt for years, slowly adding new tools as needed. Each tool serves a very specific purpose. You don't use your hammer to screw in bolts. As a craftsman, you've learned the right time and place to use each tool.</p><p><strong>State management with React is a rugged tool belt, but not everyone has the prior experience to know which tool to reach for.</strong> This post will explain the past, present, and future of state management to help you make the correct decision for your team, project, or organization.</p><h2 id="glossary">Glossary</h2><p>Before we begin, it's critical you understand some of the terms commonly used. These aren't the canonical names. A few different variations of each float around, but the underlying ideas are the same:</p><ul><li>UI State â€“ State used for controlling interactive parts of our application (e.g. dark mode toggle, modals).</li><li>Server Cache State â€“ State from the server, which we cache on the client-side for quick access (e.g. call an API, store the result, use it in multiple places).</li><li>Form State â€“ The many different states of a form (e.g. loading, submitting, disabled, validation, retrying). There's also <a target="_blank" rel="noopener noreferrer" href="https://reactjs.org/docs/forms.html">controlled &amp; uncontrolled form state</a>.</li><li>URL State â€“ State managed by the browser (e.g. filter products, saving to query parameters, and refreshing the page to see the same products filtered)</li><li>State Machine â€“ An explicit model of your state over time (e.g. a stoplight goes from green â†’ yellow â†’ red, but never green â†’ red).</li></ul><h2 id="past">Past</h2><p>React's component model helped create reusable, composable applications. Each component had its own local state. As web apps became more complex, new solutions emerged to more easily share logic between components.</p><h3 id="timeline">Timeline</h3><p>To help you understand how state management has evolved over time, here's a rough timeline of popular state management solutions in React. This list is heavily focused on UI State. This list is not comprehensive, but is enough to give context.</p><ul><li>2013 â€“ Introduction</li><li>2014 â€“ Flux (many libraries)</li><li>2015 â€“ Redux</li><li>2016 â€“ MobX</li><li>2018 â€“ Context</li><li>2019 â€“ Hooks Introduced (+ React Query, SWR)</li><li>2019 â€“ Zustand</li><li>2019 â€“ xState</li><li>2020 â€“ Jotai, Recoil, Valtio</li><li>2021 â€“ useSelectedContext</li></ul><p>Just because an item is listed on this timeline does not know you need to learn it. More on this later. Let's dive into the history of state management in React.</p><h3 id="redux">Redux</h3><p><a target="_blank" rel="noopener noreferrer" href="https://redux-toolkit.js.org/">Redux</a> was originally created as an implementation of the "<a target="_blank" rel="noopener noreferrer" href="https://blog.isquaredsoftware.com/2017/05/idiomatic-redux-tao-of-redux-part-1/#redux-was-built-as-a-flux-architecture-implementation">Flux Architecture</a>", which was a pattern first suggested by Facebook in 2014. Redux came out in 2015 and quickly became the most popular of many Flux-inspired libraries. It's ecosystem of tools and libraries encapsulated both UI state and server caching state. <strong>Redux is still extremely popular and widely used.</strong></p><div><p><img alt="Redux Growth" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div><h3 id="server-caching-state">Server Caching State</h3><p>In the early days of React, lots of state management boiled down to fetching data from APIs and caching it for use across the application. The community leaned heavily on libraries like Redux because there wasn't an easy, widely used way to manage <em>just</em> the server cache state.</p><p>With the release of <a target="_blank" rel="noopener noreferrer" href="https://reactjs.org/blog/2019/02/06/react-v16.8.0.html">React Hooks</a>, encapsulating logic into shared hooks became much easier and accessible. Libraries like <a target="_blank" rel="noopener noreferrer" href="https://swr.vercel.app/">SWR</a> and <a target="_blank" rel="noopener noreferrer" href="https://react-query.tanstack.com/">React Query</a> emerged to solve this problem specifically.</p><p>You might think "Why have a separate library just for server caching state?". Well, <strong>caching is hard</strong>. Server caching state solves different problems than UI state. Here's a shortlist of some of the things these libraries handle for you:</p><ul><li>Polling on interval</li><li>Revalidation on focus</li><li>Revalidation on network recovery</li><li>Local mutation (Optimistic UI)</li><li>Smart error retrying</li><li>Pagination and scroll position recovery</li></ul><p>Do you want to implement those yourself? <em>Probably not.</em></p><h3 id="react-context">React Context</h3><p>With <a target="_blank" rel="noopener noreferrer" href="https://reactjs.org/blog/2018/03/29/react-v-16-3.html">v16.3</a>, React Context gave us a first-party solution to share logic between components. This also prevented passing values down as props through multiple levels of nested components (i.e. "<a target="_blank" rel="noopener noreferrer" href="https://kentcdodds.com/blog/prop-drilling">prop-drilling</a>").</p><p>React Context itself is <a target="_blank" rel="noopener noreferrer" href="https://blog.isquaredsoftware.com/2021/01/context-redux-differences/">not state management</a>. It can, however, <a target="_blank" rel="noopener noreferrer" href="https://kentcdodds.com/blog/application-state-management-with-react">be paired with hooks</a> like <code>useReducer</code> to become a state management solution. This combination solved UI state for many common use cases.</p><div><p><img alt="React Context" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div><h2 id="present">Present</h2><p>In 2021, there are various ways to handle state management in React. As the community has grown to understand the different types of state, more granular libraries have been created solving very specific use cases.</p><h3 id="state-machines">State Machines</h3><p>Let's consider a switch statement. If the value of <code>state</code> matches any <code>case</code>, the corresponding code runs. There's a finite set of cases. This is the most simple state machine â€“ an explicit model of your state.</p><pre><code><span>switch</span> <span>(</span>state<span>)</span> <span>{</span>
  <span>case</span> state <span>===</span> <span>'loading'</span><span>:</span>
    
    <span>break</span><span>;</span>
  <span>case</span> state <span>===</span> <span>'success'</span><span>:</span>
    
    <span>break</span><span>;</span>
  <span>default</span><span>:</span>
  
<span>}</span>
</code></pre><p><a target="_blank" rel="noopener noreferrer" href="https://xstate.js.org/docs/about/concepts.html#finite-state-machines">Finite State Machines</a> and <a target="_blank" rel="noopener noreferrer" href="https://xstate.js.org/docs/about/concepts.html#statecharts">Statecharts</a> are fundamental Computer Science concepts, so this isn't anything React specific. You can turn <a target="_blank" rel="noopener noreferrer" href="https://reactjs.org/docs/hooks-reference.html#usereducer"><code>useReducer</code></a> into a state machine without any third-party libraries.</p><p>State Machines are well-adopted everywhere, including databases, electronics, cars, and more. As state management evolved in the React ecosystem, we realized these old ideas could solve modern state management issues. State Machines are most prevalent for solving form state.</p><p>With a Finite State Machine, you have a finite number of states your application or component could be in. In practice, State Machines help you uncover bugs as you're required to think through and define edge cases. For much more information on this, I'd recommend checking out the <a target="_blank" rel="noopener noreferrer" href="https://xstate.js.org/docs/">xState</a> docs or watching <a target="_blank" rel="noopener noreferrer" href="https://egghead.io/courses/introduction-to-state-machines-using-xstate">this course</a>. You can also <a target="_blank" rel="noopener noreferrer" href="https://xstate.js.org/viz/">visualize entire state machines online</a>.</p><div><p><img alt="State Machines" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div><h3 id="zustand-recoil-jotai-valtio-oh-my">Zustand, Recoil, Jotai, Valtio, Oh My!</h3><p>Why do so many different libraries for React state management even exist?</p><p>Let's consider Figma (or any other design tool). You have a toolbar of controls that affect other elements outside of its "local" state, or where the component is rendered.</p><div><p><img alt="Figma" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div><p>As you can imagine, an application of this scale would require a complex state management solution. Performance and frame rate are critical for a good user experience here, so you want control over when &amp; how to re-render. Unique use cases like this have led to lots of exploration in the state management space.</p><p>To summarize the differences between these libraries, let's hear from <a target="_blank" rel="noopener noreferrer" href="https://twitter.com/dai_shi/status/1348257768130560008">Daishi Kato</a>:</p><ul><li><strong>Valtio</strong> uses proxies to provide a mutation-style API</li><li><strong>Jotai</strong> is optimized for "computed values" and async actions</li><li><strong>Zustand</strong> is a very thin library specifically focused on module state</li><li><strong>Recoil</strong> is an experimental library using a data-flow graph</li></ul><p>Having complex state doesn't necessarily mean you <em>have</em> to pull for a third-party library. You can start with React and JavaScript and see how far it takes you. If optimizing requires a state management library, you can track that metric (e.g. frame rate), measure it, and verify it solves a real problem.</p><p><strong>Don't choose one of these libraries unless there's an obvious need.</strong></p><h3 id="immutable-state">Immutable State</h3><p>Another debate is mutable vs. immutable state. There's no right answers, just opinions. If you were doing state management with vanilla JavaScript, you'll likely have mutable state. You initialize a variable, and then later set it equal to some new value. There are <a target="_blank" rel="noopener noreferrer" href="https://overreacted.io/on-let-vs-const/">entire debates</a> on <code>let</code> vs. <code>const</code>.</p><p>Immutable state gained a lot of popularity with React. The immutable crowd argues that allowing your state management solution of choice to mutate state directly results in more bugs. The mutable crowd argues it's not worth the complexity trade-off. Direct manipulation will always be less safe than indirect manipulation. It's a tradeoff between convenience and risk, which is up to you and your team.</p><p>Solutions like <a target="_blank" rel="noopener noreferrer" href="https://overreacted.io/on-let-vs-const/">Immer</a> allow you to write mutable code but <em>execute</em> it immutably. Fancy. The basic idea is you apply your changes to a <em>draft state</em>, which is a proxy of the <em>current state</em>. Once the mutations have completed Immer will produce the <em>next state</em> based on the changes to the draft state.</p><div><p><img alt="Immer Immutable State" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div><h3 id="url-state">URL State</h3><p>Let's say you're building an e-commerce website like Amazon. You search for React books and filter by 4+ stars. This state is persisted as query parameters and managed by the browser. When you refresh the page, you see the same list of products. You can share this URL with others and they also see the same results.</p><div><p><img alt="Amazon URL State" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div><p>Another interesting example of this is Nomad List. We can transform the browser URL state into a function of our data. Plus, we can make human-readable URLs (which Google prefers).</p><div><p><img alt="Nomad List URL State" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div><h3 id="future">Future</h3><p>For large applications, it's possible a naive Context-based state management solutions (e.g. with <code>useReducer</code>) could have issues with excessive re-rendering. When a context value changes, all components that <code>useContext</code> will re-render. This makes UI interactions feel slow and janky. If you can't visually notice it, you can <a target="_blank" rel="noopener noreferrer" href="https://brycedooley.com/debug-react-rerenders/">use React Dev Tools</a> to investigate re-rendering.</p><p>The React team has proposed a <code>useSelectedContext</code> hook to prevent performance issues with Context at scale. This <a target="_blank" rel="noopener noreferrer" href="https://github.com/reactjs/rfcs/pull/119">RFC was introduced</a> in July 2019 and <a target="_blank" rel="noopener noreferrer" href="https://github.com/facebook/react/pull/20646">progress has started</a> as of January 2021 behind a feature flag. This hook allows you to select a "slice" of Context and only re-render when that piece changes.</p><p>There are ways to work around re-rendering performance already (e.g. <code>useMemo</code>) but a first-party solution for Context is preferred. There's also a community library <a target="_blank" rel="noopener noreferrer" href="https://www.notion.so/Past-Present-and-Future-of-React-State-Management-493ffbc810ed41f8bc66e37c86db4af1">useContextSelector</a>, which takes a similar approach (<a target="_blank" rel="noopener noreferrer" href="https://codesandbox.io/s/usecontextselector-demo-sixdr?file=/src/App.js">demo</a>). <a target="_blank" rel="noopener noreferrer" href="https://github.com/pmndrs/jotai">Jotai</a> and <a target="_blank" rel="noopener noreferrer" href="https://formik.org/blog/formik-3-alpha">Formik 3</a> use this under the hood. Having <code>useSelectedContext</code> as part of the React standard library will eliminate complexity and code size in external libraries, as well as provide more performant options by default.</p><p>In the longer-term future, React will automatically figure out which components to re-render ("<a target="_blank" rel="noopener noreferrer" href="https://github.com/reactjs/rfcs/pull/119#issuecomment-586390430">auto-memoization</a>").</p><h2 id="state-management-options">State Management Options</h2><p>This is not a comprehensive list. It's also open-source, so please open a PR if you disagree or if something is …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://leerob.io/blog/react-state-management">https://leerob.io/blog/react-state-management</a></em></p>]]>
            </description>
            <link>https://leerob.io/blog/react-state-management</link>
            <guid isPermaLink="false">hacker-news-small-sites-26006594</guid>
            <pubDate>Tue, 02 Feb 2021 21:02:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I discovered FaaS and what it changed for me]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26006415">thread link</a>) | @feross
<br/>
February 2, 2021 | https://releasecandidate.dev/posts/2021/discovery-faasd-and-openfaas/ | <a href="https://web.archive.org/web/*/https://releasecandidate.dev/posts/2021/discovery-faasd-and-openfaas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><p>Regularly, I discover myself thinking <em>"wow, that's so simple I can build this in a weekend"</em>. My rational brain kicks in at some point: <em>"Waaaaiiit a second, if it's so simple, why am I not seeing this done a million times?"</em>. Here I usually start better scoping and either find the answer to my question.</p><p>Often, my developer mind insists on "it's actually just two API endpoints and then I could do this and that". And often this holds true for the core functionality. If some <a href="https://peterthaleikis.com/business-idea-validation/">basic validation</a> gives a green light for working on it from a commercial perspective, I still need to consider the tech stack and marketing approach, as <a href="https://roadmap.sh/guides/why-build-it-and-they-will-come-wont-work-anymore">building alone doesn't do it</a>.</p><p>I'm not super fixed on the approach, my main goal is usually to keep long term overhead low. Laravel is my go-to solution for anything backend-heavy, but its power comes at a complexity cost too. For two little API endpoints used in, for example, a browser extension is a bit of an overkill.</p><p>Function as a service sounds like a great step towards "just having a few API endpoints". AWS Lambda is the name everyone is having in mind here. But any gains from simplicity are eaten up by AWS complexity. If you are new to AWS (Lambda), it easily takes you double or more time to get it running as you spend building the little lean function in the first place. This doesn't go well with the plan to "just chuck this out over the weekend".</p><h2 id="enter%3A-faasd">Enter: faasd <a href="#enter%3A-faasd">#</a></h2><p>Function as a Service should be easy. Here comes <a href="https://www.openfaas.com/blog/introducing-faasd/">faasd</a> into play. It's a self-hosted alternative to run functions. It allows you to run a simple copy &amp; paste installer script on your machine getting it up and running. It takes less than ten minutes to get to work. It's production-ready and helps to remove the learning curve involved with Kubernetes and co.</p><blockquote><p>faasd is a self-hosted alternative to AWS Lambda to run functions. Production-ready within minutes ⏲️</p></blockquote><p>Once you have deployed your faasd instance, it's a matter of one command to push your function into production. From there it's up to you what you like to build. I catch myself breaking up the structure of larger applications in functions. It builds the container, publishes, and deploys your function code ready-to-use in seconds. To run this you will need the <a href="https://github.com/openfaas/faas-cli">FaaS CLI</a>. Again this is installed in under one minute thanks to copy and paste that just works.</p><p>Found a great library but it's written in the "wrong" language? Thanks to the flexibility, you can also jump between programming languages easily. I use a mix of nodejs, PHP, and Python by now.</p><blockquote><p>With functions you libraries aren't in the <em>wrong</em> language anymore.</p></blockquote><p>This helps to truly break up large applications into functional parts using the best tool for you. You can get a rich list of the official templates by running:</p><pre><code>$ faas-cli template store list<p>NAME                     SOURCE             DESCRIPTION<br>csharp                   openfaas           Classic C<br>dockerfile               openfaas           Classic Dockerfile template<br>go                       openfaas           Classic Golang template<br>java8                    openfaas           Java <span>8</span> template<br>java11                   openfaas           Java <span>11</span> template<br>java11-vert-x            openfaas           Java <span>11</span> Vert.x template<br>node12                   openfaas           HTTP-based Node <span>12</span> template<br>node                     openfaas           Classic NodeJS <span>8</span> template<br>php7                     openfaas           Classic PHP <span>7</span> template<br>python                   openfaas           Classic Python <span>2.7</span> template<br>python3                  openfaas           Classic Python <span>3.6</span> template<br>python3-dlrs             intel              Deep Learning Reference Stack v0.4 <span>for</span> ML workloads<br>ruby                     openfaas           Classic Ruby <span>2.5</span> template<br>ruby-http                openfaas           Ruby <span>2.4</span> HTTP template<br>python27-flask           openfaas           Python <span>2.7</span> Flask template<br>python3-flask            openfaas           Python <span>3.7</span> Flask template<br>python3-flask-debian     openfaas           Python <span>3.7</span> Flask template based on Debian<br>python3-http             openfaas           Python <span>3.7</span> with Flask and HTTP<br>python3-http-debian      openfaas           Python <span>3.7</span> with Flask and HTTP based on Debian<br>golang-http              openfaas           Golang HTTP template<br>golang-middleware        openfaas           Golang Middleware template<br>python3-debian           openfaas           Python <span>3</span> Debian template<br>powershell-template      openfaas-incubator Powershell Core Ubuntu:16.04 template<br>powershell-http-template openfaas-incubator Powershell Core HTTP Ubuntu:16.04 template<br>rust                     booyaa             Rust template<br>crystal                  tpei               Crystal template<br>csharp-httprequest       distantcam         C<br>csharp-kestrel           burtonr            C<br>vertx-native             pmlopes            Eclipse Vert.x native image template<br>swift                    affix              Swift <span>4.2</span> Template<br>lua53                    affix              Lua <span>5.3</span> Template<br>vala                     affix              Vala Template<br>vala-http                affix              Non-Forking Vala Template<br>quarkus-native           pmlopes            Quarkus.io native image template<br>perl-alpine              tmiklas            Perl language template based on Alpine image<br>crystal-http             koffeinfrei        Crystal HTTP template<br>rust-http                openfaas-incubator Rust HTTP template<br>bash-streaming           openfaas-incubator Bash Streaming template<br>cobol                    devries            COBOL Template</p></code></pre><p>There are also inofficial templates you can find with a bit of research on GitHub.</p><p>Start with a new function by running:</p><pre><code>faas-cli new function-name --lang node12</code></pre><p>This creates a function based on the node12 template. Now you can develop the function in the <code>handler.js</code>-file. This approach works similarly for all other functions. Once you ready run <code>faas-cli up</code> to deploy the function.</p><h2 id="building-a-function">Building a Function <a href="#building-a-function">#</a></h2><p>I like to learn by doing. So I started by building a simple <a href="https://github.com/spekulatius/faasd-franc">function to detect the language</a> of a given string. The <a href="https://github.com/spekulatius/faasd-franc/blob/master/franc/handler.js">whole function</a> including access control is only 31 lines with plenty of space:</p><pre><code><span>'use strict'</span><p><span>const</span> fs <span>=</span> <span>require</span><span>(</span><span>'fs'</span><span>)</span><br><span>const</span> fsPromises <span>=</span> fs<span>.</span>promises<br><span>let</span> franc <span>=</span> <span>require</span><span>(</span><span>'franc'</span><span>)</span></p><p>module<span>.</span><span>exports</span> <span>=</span> <span>async</span> <span>(</span><span>event<span>,</span> context</span><span>)</span> <span>=&gt;</span> <span>{</span><br>  <br>  <span>let</span> secret <span>=</span> <span>await</span> fsPromises<span>.</span><span>readFile</span><span>(</span><span>"/var/openfaas/secrets/franc-token"</span><span>,</span> <span>"utf8"</span><span>)</span><br>  <span>let</span> auth <span>=</span> event<span>.</span>headers<span>[</span><span>"authorization"</span><span>]</span><br>  <span>if</span><span>(</span><span>!</span>auth <span>&amp;&amp;</span> auth <span>!=</span> <span>"Bearer: "</span> <span>+</span> secret<span>)</span> <span>{</span><br>    <span>return</span> context<br>      <span>.</span><span>status</span><span>(</span><span>403</span><span>)</span><br>      <span>.</span><span>headers</span><span>(</span><span>{</span><span>"Content-Type"</span><span>:</span> <span>"application/json"</span><span>}</span><span>)</span><br>      <span>.</span><span>succeed</span><span>(</span><span>{</span><span>"status"</span><span>:</span> <span>"Unauthorized"</span><span>}</span><span>)</span><br>  <span>}</span></p><p>  <span>let</span> response <span>=</span> <span>{</span><span>}</span><br>  <span>if</span> <span>(</span>event<span>.</span>query<span>.</span>query <span>==</span> <span>undefined</span> <span>||</span> event<span>.</span>query<span>.</span>query<span>.</span>length <span>==</span> <span>0</span><span>)</span> <span>{</span><br>    response<span>.</span>status <span>=</span> <span>'Error'</span><br>    response<span>.</span>message <span>=</span> <span>'No query string provided'</span><br>  <span>}</span> <span>else</span> <span>{</span><br>    response<span>.</span>status <span>=</span> <span>'Success'</span><br>    response<span>.</span>result <span>=</span> franc<span>.</span><span>all</span><span>(</span>event<span>.</span>query<span>.</span>query<span>)</span><span>.</span><span>splice</span><span>(</span><span>0</span><span>,</span> <span>10</span><span>)</span><br>  <span>}</span></p><p>  <span>return</span> context<br>    <span>.</span><span>status</span><span>(</span><span>200</span><span>)</span><br>    <span>.</span><span>headers</span><span>(</span><span>{</span><span>"Content-Type"</span><span>:</span> <span>"application/json"</span><span>}</span><span>)</span><br>    <span>.</span><span>succeed</span><span>(</span>response<span>)</span><br><span>}</span></p></code></pre><p>Functions as a service are made for this: You can easily try out a library or different programming language as it's made to be disposable. Don't like how it's going? Drop it, delete the function and your system is clean once more. No compilers, dependencies, and other tooling remain on your system.</p><h2 id="lessons-learned-along-the-way">Lessons learned along the way <a href="#lessons-learned-along-the-way">#</a></h2><p>At the beginning, I didn't want to run my own container registry. I expected additional overhead and "another thing to maintain". This turned out to be a mistake, as the setup was almost as easy as faasd itself. Plus, the performance is much better than relying on Docker Hub.</p><p>I got it up and running on my <a href="https://peterthaleikis.com/hetzner">Hetzner server</a> in a few minutes using some guides from <a href="https://peterthaleikis.com/digitalocean">DigitalOcean</a>.</p><p>After spinning up your server, the steps break down to:</p><ul><li><a href="https://docs.docker.com/engine/install/ubuntu/">installing docker</a>,</li><li>setting up the <a href="https://www.digitalocean.com/community/tutorials/how-to-set-up-a-private-docker-registry-on-ubuntu-18-04">container registry</a>, and</li><li><a href="https://www.digitalocean.com/community/tutorials/how-to-secure-nginx-with-let-s-encrypt-on-ubuntu-18-04">securing nginx</a>.</li></ul><p>Another really interesting option is <a href="https://get-arkade.dev/">arkade</a>. It allows you to abstract the steps.</p><p>I should have also paid closer attention to the <a href="https://github.com/openfaas/workshop/">OpenFaaS workshop</a> at the beginning. It guides you through the basics with examples better than purely self-discovery does. This is especially true for me, as I'm not deep in the serverless space.</p><h2 id="worry-about-scaling%2C-when-you-get-to-scale">Worry about scaling, when you get to scale <a href="#worry-about-scaling%2C-when-you-get-to-scale">#</a></h2><p>As with any solution approach, there are limitations. For the most time, I leave these concerns out. It simply doesn't matter if my functions can scale to millions of users, as I don't have millions of users. Migrating to a more scalable approach such as <a href="https://github.com/openfaas/openfaas-cloud">OpenFaaS Cloud</a> should be very doable.</p><blockquote><p>Worry about scaling, when you get to scale. Until then build and market.</p></blockquote><p>We can probably agree: The people behind a project matter to its success for a large part. The OpenFaaS project is driven by <a href="https://blog.alexellis.io/">Alex Ellis</a>, a passionate developer. He and the contributors maintain an active slack channel - questions from newbie-level to expert find answers there. Alex is supporting this effort with contracting, but other options such as sponsorship of <a href="https://github.com/sponsors/openfaas">OpenFaaS</a> or <a href="https://github.com/sponsors/alexellis">Alex</a> directly are available (and recommended).</p><h2 id="get-playing">Get Playing <a href="#get-playing">#</a></h2><p>As with any reading: It can only take you so far. Make sure to put a few hours aside and check out faasd! It does come with a little overhead to learn and keep up. Especially for independent developers eyeing to monetize an API or build a small SaaS this could be a great solution.</p><ul><li>Head over to <a href="https://github.com/openfaas/faasd">faasd</a>! Feel free to star or fork the project on GitHub!</li><li>If you like to discover new open-source projects and see how you could apply them, <a href="https://twitter.com/spekulatius1984">follow me on Twitter</a> and <a href="https://buttondown.email/spekulatius">sign up for my newsletter</a>.</li></ul><p>Want to dive in proper? Check out the <a href="https://gumroad.com/a/998896755">"serverless for the rest of us" ebook</a> by OpenFaaS-developer Alex Ellis.</p><p>Since you've made it this far, <a href="https://releasecandidate.dev/posts/2021/discovery-faasd-and-openfaas/" on-click="share">sharing</a> this article on your favorite social media network would be highly appreciated 💖! For feedback, please <a href="https://twitter.com/spekulatius1984" rel="noopener" target="_blank">ping me on Twitter.</a></p><share-widget></share-widget><p>Published <time datetime="2021-01-13">13 Jan 2021</time></p></article></div></div>]]>
            </description>
            <link>https://releasecandidate.dev/posts/2021/discovery-faasd-and-openfaas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26006415</guid>
            <pubDate>Tue, 02 Feb 2021 20:47:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Best platforms and tools for freelancers to make more money]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26006378">thread link</a>) | @sdneirf
<br/>
February 2, 2021 | https://remotehq.co/3oLMsYi | <a href="https://web.archive.org/web/*/https://remotehq.co/3oLMsYi">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://remotehq.co/3oLMsYi</link>
            <guid isPermaLink="false">hacker-news-small-sites-26006378</guid>
            <pubDate>Tue, 02 Feb 2021 20:45:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reduce Noise, Not Cognitive Biases]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26006307">thread link</a>) | @lame-robot-hoax
<br/>
February 2, 2021 | https://commoncog.com/blog/reduce-noise-not-cognitive-biases/ | <a href="https://web.archive.org/web/*/https://commoncog.com/blog/reduce-noise-not-cognitive-biases/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      <section>
        <!--kg-card-begin: html-->
<!--kg-card-end: html--><p>This is a story that long-time readers of Commonplace would know.</p><p>In 2010, IARPA (Intelligence Advanced Research Projects Activity — basically, <a href="https://en.wikipedia.org/wiki/DARPA">ARPA</a>, but for the intelligence community) — started a research initiative called the Aggregate Contingent Estimation Program. ACE was a competition to determine the best ways to ‘elicit, weight, and combine the judgment of many intelligence analysts’, and it was motivated by IARPA’s desire to know how much money, exactly, they were wasting on geopolitical analysis. In the beginning, it consisted of five competing research programs. Within two years, only one survived: this was Phillip Tetlock, Barbara Mellers and Don Moore’s Good Judgment Project.</p><p>The GJP was a forecasting tournament. It asked individual participants questions like “What are the odds that Greece would leave the Eurozone by the end of 2011?” and “What are the odds that Tesla declares bankruptcy by the end of 2021?” — questions asked months in advance of the event dates. To these prompts, you would respond with a probability estimation — 0.9 meant you were pretty damned sure Greece would leave, while 0.5 meant you were on the fence; 0.1 meant you were sure Greece would stay put. Individual forecasters were evaluated according to something called a <a href="https://en.wikipedia.org/wiki/Brier_score">Brier score</a>: this rewarded you handsomely the more confident you were (you got a huge bump if you said 0.9 and Greece <em>did</em> leave the Eurozone) but also a huge punishment if you were confident and the result you were betting on didn’t happen (e.g. you said 0.9 and Greece didn’t leave). The researchers quickly discovered that a small group of participants were very good at predicting the future — they called these people ‘superforecasters’ — and then spent quite a bit of time studying what these individuals did differently from the rest.</p><p>Over time, the program runners began to realise that the GJP was a <em>fantastic</em> test bed for all sorts of interesting judgment and decision making questions. For instance, one question you could reasonably ask is: “Are there ways to improve forecasting performance for the average forecaster?”, followed by <a href="https://en.wikipedia.org/wiki/Daniel_Kahneman">Daniel Kahneman’s</a>: “Do superforecasters have less cognitive biases than normal forecasters? And if they do (and it turned out they <em>did</em> show less cognitive bias!) — are these people different because they did things differently, or are they different because they are different types of people?” (answer: yes, a bit of both) and the logical next question: ‘Are there ways to reduce cognitive biases amongst forecasters?’</p><p>To <em>that</em> question, the researchers discovered three interventions that worked:</p><ul><li>Training — At the beginning of the tournament, the researchers provided forecasters with a short presentation about best practices: they taught people how to think about probabilities, where to get probabilistic information, how to average professional forecasts, and then they presented participants with a list of common biases in human judgment. The goal: to reduce cognitive biases.</li><li>Teaming — Put forecasters in teams, with an online forum to discuss each prediction. The goal: to prevent biases such as group think and failures to pool information.</li><li>Tracking — Put forecasters together in teams with other forecasters of similar performance. The goal: to see if elite teams would be more accurate than regular teams.</li></ul><p>In the end, the researchers were pleased with the results of all three interventions. They wrote up a number of research papers, talking up their achievements in improving forecasting performance; Phillip Tetlock wrote a popular science book called <em><a href="https://www.goodreads.com/book/show/23995360-superforecasting">Superforecasting</a></em> with Dan Gardner, which made a huge splash in a bunch of different domains. More recently, Tetlock and Joseph Cergniglia published a <a href="https://jpm.pm-research.com/content/45/5/125">paper in the Journal of Portfolio Management</a> about something they called the ‘Alpha-Brier Process’ — a method to accelerate learning in active investment management. And the GJP authors and their collaborators crowed about the power of training interventions to reduce cognitive bias (<a href="http://journal.sjdm.org/16/16511/jdm16511.pdf">Chang et al, 2016</a>), and marvelled at the abilities of superforecasters at picking up subtle signals (<a href="https://journals.sagepub.com/doi/abs/10.1177/1745691615577794">Mellers et al, 2015</a>).</p><p>Except that it turned out most of these interventions didn’t work by decreasing cognitive biases or increasing detection of subtle signals; they worked by tamping down on noise.</p><h2 id="the-paper">The Paper</h2><p>The reason I said long-time Commonplace readers would be familiar with this story is because I wrote a <a href="https://commoncog.com/blog/the-forecasting-series/">series about Superforecasting and the Good Judgment Project</a> at the end of 2019. If you want to save yourself some time chasing down books and papers, go and read that series — I’ve made it as comprehensive as I possibly could.</p><p>At the <a href="https://commoncog.com/blog/how-the-superforecasters-do-it/">end of my <em>Superforecasting</em> summary</a>, I wrote:</p><blockquote>In the years since the GJP concluded, Barbara Mellers has continued to dig into the data generated by the forecasting tournaments — this time with an eye to explain why the interventions worked as well as they have.<p>The original intention of all three interventions was to reduce cognitive biases, in line with the Kahneman and Tversky research project of the time. But this didn’t turn out to be the case. In a recent interview, Mellers and INSEAD professor Ville Satopӓӓ explained that they went back and applied a statistical model to the entire 2011-2015 GJP dataset, designed to tease out the effects of bias, information and noise (BIN) respectively. Satopӓӓ writes:</p><p><em>How does the BIN model work? Simply put, it analyses the entire “signal universe” around a given question. Signals are pieces of information that the forecasters may take into account when trying to guess whether something will happen. In formulating predictions, one can rely upon either meaningful signals (i.e. information extraction) or irrelevant signals (i.e. noise). One can also organise information along erroneous lines (i.e. bias). Comparing GJP groups that experienced one or more of the three interventions to those that did not, the BIN model was able to disaggregate the respective contributions of noise, information and bias to overall improvements in prediction accuracy.</em></p><p>This explanation isn’t satisfying to me, but apart from an interview with Mellers and Satopӓӓ, there’s not much else to go on — the paper is still in progress, and hasn’t been published.</p><p>But the conclusions are intriguing. Here’s Satopӓӓ again:</p><p><em>Our experiments with the BIN model have also produced results that were more unexpected. Recall that teaming, tracking and training were deployed for the express purpose of reducing bias. Yet it seems that only teaming actually did so. Two of the three — teaming and tracking — increased information. Surprisingly, all three interventions reduced noise. In light of our current study, it appears the GJP’s forecasting improvements were overwhelmingly the result of noise reduction (emphasis added). As a rule of thumb, about 50 percent of the accuracy improvements can be attributed to noise reduction, 25 percent to tamping down bias, and 25 percent to increased information.</em></p><p>The authors have little to offer by way of actionable insight. In their interview, they suggest that using algorithms would improve noise reduction, but they also note that machines aren’t great at the multi-perspective synthesis that human superforecasters are so great at. It’s unclear to me if this is actionable. I’ll wait for the paper and report back to you once that’s out.</p></blockquote><p>That paper is titled <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3540864">Bias, Information, Noise: The BIN Model of Forecasting</a>. It was completed on the 19th of February, 2020, and was <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3540864">published to SSRN</a> in April last year — all of which I completely missed out on, because it happened right smack in the middle of the global lockdown.</p><p>The paper has two primary contributions. The first is the BIN model itself, which is a statistical model designed to tease out the respective contributions of bias, partial information, and noise to forecasting performance — at least within the context of the GJP. &nbsp;The second is what the authors use the BIN model <em>to do</em>: that is, to measure the degree their interventions improved each of the three elements. How much did tracking and teaming tamp down on cognitive bias? And how much did it help forecasters reduce noise?</p><p>The answer is exactly what Satopӓӓ reported in his original <a href="https://knowledge.insead.edu/strategy/the-secret-ingredients-of-superforecasting-12721">INSEAD piece</a>:</p><ol><li>All three interventions reduced noise. Only one intervention — teaming — reduced cognitive biases. This was <em>despite the fact that the GJP researchers targeted cognitive biases with their interventions</em> — which is a little bit like aiming for one target in an archery range and hitting a bullseye on the lane next to it. The researchers said they were taken aback by this result, and that it demanded a re-evaluation of the findings from their prior work.</li><li>Across all interventions, the rough breakdown of accuracy improvements are as follows: 50% to noise reduction, 25% to tamping down on bias, and 25% to increased information.</li></ol><p>We’ll talk about what this means in a bit; for now, I want to give you a sketch of the BIN model in action.</p><h2 id="how-the-bin-model-works">How The BIN Model Works</h2><p>The formal definition of noise is ‘unpredictable, nonsystematic error’.</p><p>Imagine that in order to make a forecast, you observe a set of signals over time. Some signals are useful, and they cause you to update your forecast. This is partial information. Other signals are irrelevant, and may cause you to update erroneously. This is noise. And some signals you misinterpret due to cognitive bias — which should lead to judgment drift in a particular direction. This is bias. The differences between noise and bias is best illustrated using the following diagram:</p><figure><img src="https://commoncog.com/blog/content/images/2021/02/Screenshot-2021-01-27-at-1.45.34-AM.png" alt="" srcset="https://commoncog.com/blog/content/images/size/w600/2021/02/Screenshot-2021-01-27-at-1.45.34-AM.png 600w, https://commoncog.com/blog/content/images/size/w1000/2021/02/Screenshot-2021-01-27-at-1.45.34-AM.png 1000w, https://commoncog.com/blog/content/images/2021/02/Screenshot-2021-01-27-at-1.45.34-AM.png 1052w" sizes="(min-width: 720px) 720px"></figure><p>Keep this diagram in mind; it’ll come in handy in a bit.</p><p>In 2016, Daniel Kahneman co-authored a famous article in the Harvard Business Review titled <a href="https://hbr.org/2016/10/noise">Noise: How to Overcome the High, Hidden Cost of Inconsistent Decision Making</a>. The article is useful because it gives us several additional examples of noise in decision-making. Kahneman et al begin their argument with a quick comparison between bias and noise, using a …</p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://commoncog.com/blog/reduce-noise-not-cognitive-biases/">https://commoncog.com/blog/reduce-noise-not-cognitive-biases/</a></em></p>]]>
            </description>
            <link>https://commoncog.com/blog/reduce-noise-not-cognitive-biases/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26006307</guid>
            <pubDate>Tue, 02 Feb 2021 20:39:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tidy.js: Tidy up your data with JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26006232">thread link</a>) | @codenberg
<br/>
February 2, 2021 | https://pbeshai.github.io/tidy/ | <a href="https://web.archive.org/web/*/https://pbeshai.github.io/tidy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><main><section><div><div><div><h3>Readable code</h3><p>tidy.js prioritizes making your data transformations readable, so future you and your teammates can get up and running quickly.</p></div><div><h3>Standard transformation verbs</h3><p>Inspired by <a href="https://dplyr.tidyverse.org/" target="_blank" rel="noopener noreferrer">dplyr</a> and the <a href="https://www.tidyverse.org/" target="_blank" rel="noopener noreferrer">tidyverse</a> in R, tidy.js is built using battle-tested verbs that can handle any data wrangling need.</p></div><div><h3>Work with plain JS objects</h3><p>No wrapper classes needed — all tidy.js needs is an array of plain old-fashioned JS objects to get started.</p></div></div></div></section><section><div><h3>Function List</h3><p>Here's a quick jumping off point to see the API for all the functions provided by tidy.js.</p></div></section></main></div></div>]]>
            </description>
            <link>https://pbeshai.github.io/tidy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26006232</guid>
            <pubDate>Tue, 02 Feb 2021 20:32:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Your Software Engineering Resume – what to avoid]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26006110">thread link</a>) | @mcenedella
<br/>
February 2, 2021 | https://leetresumes.com/blog/your-software-engineering-resume-what-to-avoid | <a href="https://web.archive.org/web/*/https://leetresumes.com/blog/your-software-engineering-resume-what-to-avoid">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><div><div><p>At Leet Resumes, we write <a href="https://leetresumes.com/">free technical resumes for experienced software engineers</a>. With experience writing thousands of resumes, I’ll jump right in with the tl;dr and then tell you why:</p><p><strong>AVOID:</strong></p><ul><li>Colors</li><li>Graphics</li><li>“Fancy” formats</li><li>Two-column formats (or three-column for that matter)</li><li>MS Word templates</li><li>LinkedIn pdf exports</li><li>Headers and footers</li></ul><p>The readers of your resumes do this for a living. It’s understandable that you’d like your resume to look unique, but it’s much more important for your readers to be able to understand your career and background, quickly and clearly.</p><p>Let me give you an analogy. When you’re using Yelp, Zillow, Apartments.com, DoorDash or Grubhub, you don’t want each listing to have a different format.  You’d like for each listing to be in the same format so that it makes it easy for you to find the information you want.  Same thing goes for engineering managers, technical recruiters, and HR staff -- they want to find the information they need on your resume easily. Please help them by avoiding these mistakes.</p><p><strong>Colors on your resume are a distraction.</strong> The large blue sidebar, the crimson top shading, the colorful curly-cue lines along the sides or bottom – all of these are distractions from the hiring manager reading about your relevant experience for their job.  And in certain cases when the background color requires the font to be white, you’re asking your reader to spend more effort to read your resume than they are on understanding your career.  It’s an easy mistake to avoid.</p><p><strong>Graphics should be avoided on a resume.</strong> As detailed in my <a href="https://www.theladders.com/career-advice/resume-parser-ceos-advice-for-your-resume">long interview</a> with the CEOs and technical experts at the world’s five largest resume parsing companies, graphics are ignored by the software that reads the world’s resumes. This makes it especially sad for resumes where “level of skill” in different programming languages is represented by a bar of a certain height. It’s illegible to resume reading software and therefore unhelpful in advancing your career goals.</p><p><strong>Fancy or complex formats don’t help.</strong> Again, it’s understood that your resume is a very, very special document to you. This is your one, true resume, so you feel it warrants a certain degree of sophistication, complexity, and finely-tuned placement of informational elements, thereby hinting at the refined capabilities of the professional behind the resume. This, again, is an error.  A resume isn’t an 18th century calling card meant to make a statement in the foyer. Your human readers are bewildered by your unique choices for data placement, and the resume parsers that turn your resume into useful information for HR’s software systems will, I assure you, make many errors interpreting your novel design.</p><p><strong>Two-column formats cause comprehension mistakes. </strong>Because columns are often implemented as cells, what frequently occurs is that an entire column is flattened together, and then the next, and then the next. This causes important data that belongs together to become separated - employment dates and employment experiences, for example. This, too, makes your resume useless for its intended purpose. By the same lights, you should also avoid three-column resume formats.</p><p><strong>Starting with an MS Word template is another blunder to sidestep.</strong> Many MS Word templates are ancient and have layer upon layer of hidden formatting embedded below their placid surface. This causes all sorts of mischief as your resume is passed about among different recipients, and different companies’ HR systems. </p><p><strong>LinkedIn PDF exports are purposely broken.</strong> LinkedIn makes the majority of its $8 billion in annual revenue by selling access to your information for recruiting purposes. From a business standpoint, they understandably don’t want that data exported and put into someone else’s system for free. So their PDF profile exports are purposely formatted verbosely, with a poor structure that does not play well with the world’s resume parsers.</p><p>And, finally, <strong>headers and footers should be avoided.</strong> On a one-page resume they should be avoided because they’re unnecessary, and on a two-page resume because they’ll be interpreted as part of the data immediately before and after the footer/header. This causes errors ingesting your resume.</p><p>This is a short list of items to avoid on a software engineering resume. If you’d like Leet Resumes to <a href="https://leetresumes.com/">write your technical resume for free</a>, sign up on our <a href="https://leetresumes.com/">homepage</a>, and we’ll avoid these, and many other, hidden errors. <a href="https://leetresumes.com/testimonials">Our users love us!</a></p></div></div></div></div>]]>
            </description>
            <link>https://leetresumes.com/blog/your-software-engineering-resume-what-to-avoid</link>
            <guid isPermaLink="false">hacker-news-small-sites-26006110</guid>
            <pubDate>Tue, 02 Feb 2021 20:23:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Flutter / Dart database benchmarks released alongside new version]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26005920">thread link</a>) | @greenrobot_de
<br/>
February 2, 2021 | https://objectbox.io/objectbox-dart-flutter-v0-11-database-performance-relations/ | <a href="https://web.archive.org/web/*/https://objectbox.io/objectbox-dart-flutter-v0-11-database-performance-relations/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					
<p>Flutter Databases are few. Therefore, we’re happy to take a big step towards 1.0 with this <a href="https://pub.dev/packages/objectbox">ObjectBox Dart v0.11 release</a>, improving performance and bringing the much-desired relations support known from <a href="https://objectbox.io/dev-get-started/" target="_blank" rel="noreferrer noopener">other ObjectBox DB language bindings</a> to Dart/Flutter.</p>



<p>For those of you new to ObjectBox: ObjectBox is a superfast NoSQL object database for Flutter / Dart and here is how you can save data in your Dart / Flutter apps:</p>


<!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		<div id="crayon-601c5149704dd112808314" data-settings=" minimize scroll-mouseover disable-anim">
		
			
			<div>
				<table>
					<tbody><tr>
				<td data-settings="show">
					<div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p><p>7</p><p>8</p><p>9</p><p>10</p><p>11</p><p>12</p><p>13</p><p>14</p><p>15</p><p>16</p><p>17</p><p>18</p><p>19</p><p>20</p><p>21</p><p>22</p><p>23</p><p>24</p><p>25</p><p>26</p><p>27</p></div>
				</td>
						<td><div><p><span>@</span><span>Entity</span><span>(</span><span>)</span></p><p><span>class</span><span> </span><span>Person</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;</span><span>int</span><span> </span><span>id</span><span>;</span></p><p><span>&nbsp;&nbsp;</span><span>String</span><span> </span><span>firstName</span><span>;</span></p><p><span>&nbsp;&nbsp;</span><span>String</span><span> </span><span>lastName</span><span>;</span></p><p><span>}</span></p><p><span>final</span><span> </span><span>store</span><span> </span><span>=</span><span> </span><span>Store</span><span>(</span><span>getObjectBoxModel</span><span>(</span><span>)</span><span>)</span><span>;</span></p><p><span>final</span><span> </span><span>box</span><span> </span><span>=</span><span> </span><span>store</span><span>.</span><span>box</span><span>&lt;</span><span>Person</span><span>&gt;</span><span>(</span><span>)</span><span>;</span></p><p><span>var</span><span> </span><span>person</span><span> </span><span>=</span><span> </span><span>Person</span><span>(</span><span>)</span></p><p><span>&nbsp;&nbsp;</span><span>.</span><span>.</span><span>firstName</span><span> </span><span>=</span><span> </span><span>"Joe"</span></p><p><span>&nbsp;&nbsp;</span><span>.</span><span>.</span><span>lastName</span><span> </span><span>=</span><span> </span><span>"Green"</span><span>;</span></p><p><span>final</span><span> </span><span>id</span><span> </span><span>=</span><span> </span><span>box</span><span>.</span><span>put</span><span>(</span><span>person</span><span>)</span><span>;</span><span>&nbsp;&nbsp;</span><span>// Create</span></p><p><span>person</span><span> </span><span>=</span><span> </span><span>box</span><span>.</span><span>get</span><span>(</span><span>id</span><span>)</span><span>;</span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>// Read</span></p><p><span>person</span><span>.</span><span>lastName</span><span> </span><span>=</span><span> </span><span>"Black"</span><span>;</span></p><p><span>box</span><span>.</span><span>put</span><span>(</span><span>person</span><span>)</span><span>;</span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span>// Update</span></p><p><span>box</span><span>.</span><span>remove</span><span>(</span><span>person</span><span>.</span><span>id</span><span>)</span><span>;</span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span>// Delete</span></p><p><span>// find all people whose name start with letter 'J'</span></p><p><span>final</span><span> </span><span>query</span><span> </span><span>=</span><span> </span><span>box</span><span>.</span><span>query</span><span>(</span><span>Person_</span><span>.</span><span>firstName</span><span>.</span><span>startsWith</span><span>(</span><span>'J'</span><span>)</span><span>)</span><span>.</span><span>build</span><span>(</span><span>)</span><span>;</span></p><p><span>final</span><span> </span><span>people</span><span> </span><span>=</span><span> </span><span>query</span><span>.</span><span>find</span><span>(</span><span>)</span><span>;</span><span>&nbsp;&nbsp;</span><span>// find() returns List&lt;Person&gt;</span></p></div></td>
					</tr>
				</tbody></table>
			</div>
		</div>
<!-- [Format Time: 0.0005 seconds] -->



<p>To learn about more ObjectBox features, like relations, queries and data sync, check our <a href="https://pub.dev/packages/objectbox">ObjectBox pub.dev page</a>.</p>



<h2>How fast is ObjectBox Dart? Performance Benchmarks</h2>



<p>Speed is important for data persistence solutions. Accordingly, we wanted to test how ObjectBox compares performance-wise to other Flutter Dart database options. Therefore, we looked for libraries with comparable levels of storage abstraction and feature set –&nbsp; so not just plain SQL/Key-value storage but also <a href="https://greenrobot.org/android/sqlite-access-with-an-orm-faq/">ORM</a>-like features. <a href="https://objectbox.io/flutter-databases-sqflite-hive-objectbox-and-moor" target="_blank" rel="noreferrer noopener">There doesn’t seem to be that much choice…&nbsp;</a></p>



<p>We looked at some two popular approaches: <strong>sqflite</strong> a SQLite wrapper for Flutter (no Dart Native support), and <strong>Hive, </strong>a key-value store with Class-adapters which seems still popular although its technology is phased out (see below). As a third alternative we pulled in <a href="https://en.wikipedia.org/wiki/Firebase" target="_blank" rel="noreferrer noopener nofollow">Firestore</a>, which does not really fit as it is no local database, but would be fun to compare anyway.</p>



<h3>What we tested</h3>



<p>To get an overview of the databases, we tested <strong>CRUD</strong> operations (create, read, update, delete). Each test was run multiple times and executed manually outside of the measured time. Data preparation and evaluation was also done outside of the measured time.</p>



<p>We tried to keep the test implementations as close as possible to each other while picking the approaches recommended by the docs for each database. We open sourced the test code at <a href="https://github.com/objectbox/objectbox-dart-performance">https://github.com/objectbox/objectbox-dart-performance</a> if you want to have a closer look.</p>



<h3>Performance Benchmark Results</h3>



<figure><img width="2222" height="1338" src="https://t3j8z7g9.rocketcdn.me/wordpress/wp-content/uploads/2021/02/objectbox-dart-performance.png" alt="" srcset="https://t3j8z7g9.rocketcdn.me/wordpress/wp-content/uploads/2021/02/objectbox-dart-performance.png 2222w, https://t3j8z7g9.rocketcdn.me/wordpress/wp-content/uploads/2021/02/objectbox-dart-performance-1280x771.png 1280w, https://t3j8z7g9.rocketcdn.me/wordpress/wp-content/uploads/2021/02/objectbox-dart-performance-980x590.png 980w, https://t3j8z7g9.rocketcdn.me/wordpress/wp-content/uploads/2021/02/objectbox-dart-performance-480x289.png 480w" sizes="(min-width: 0px) and (max-width: 480px) 480px, (min-width: 481px) and (max-width: 980px) 980px, (min-width: 981px) and (max-width: 1280px) 1280px, (min-width: 1281px) 2222px, 100vw" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%202222%201338'%3E%3C/svg%3E" data-lazy-srcset="https://t3j8z7g9.rocketcdn.me/wordpress/wp-content/uploads/2021/02/objectbox-dart-performance.png 2222w, https://t3j8z7g9.rocketcdn.me/wordpress/wp-content/uploads/2021/02/objectbox-dart-performance-1280x771.png 1280w, https://t3j8z7g9.rocketcdn.me/wordpress/wp-content/uploads/2021/02/objectbox-dart-performance-980x590.png 980w, https://t3j8z7g9.rocketcdn.me/wordpress/wp-content/uploads/2021/02/objectbox-dart-performance-480x289.png 480w" data-lazy-src="https://t3j8z7g9.rocketcdn.me/wordpress/wp-content/uploads/2021/02/objectbox-dart-performance.png"></figure>



<p>Looking at the results, we can see ObjectBox performing significantly faster than sqflite across the board, with up to 70 times speedup in case of create &amp; update operations. Compared to Hive, the results are a little more varied, with Hive being faster at reading objects than ObjectBox (we come to that later in our outlook), and ObjectBox being faster at creating objects, about four times faster at updates and three times for deletes. As a mostly-online database, it becomes clear that Firestore’s performance is not really comparable.</p>



<h3>Implementation notes</h3>



<p><strong>ObjectBox:</strong> This release largely boosted the performance. The remaining bottlenecks are due to Dart itself and how it allows to modify byte buffers. There’s potential to double the speed if we look at other languages supported by ObjectBox. And if that’s not happening soon, we’d still have the option to do some low-level hacks…</p>



<p><strong>Sqflite:</strong> a wrapper around SQLite, which is a relational database without direct support for Dart objects. Each dart object field is mapped to a column in the database, as per <a href="https://pub.dev/packages/sqflite#sql-helpers">sqflite docs</a>, i.e. converting between the Dart class and a Map.</p>



<p><strong>Hive:</strong> We’ve tested with the latest Hive release, which is <a href="https://github.com/hivedb/hive/issues/246">technically discontinued</a>. The author hit two architectural roadblocks (RAM usage and queries) and is currently in the process to do a rewrite from scratch.<br><strong>Update:</strong> strictly speaking it’s not straightforward to directly compare e.g. ObjectBox vs. Hive. In Hive, the high read numbers result from Dart objects already cached in memory. If the objects are fetched using the async API from disk, the numbers drop by factor 1000.</p>



<p><strong>Firestore:</strong> This is totally apples and oranges, but we still decided to include Firebase/Firestore as it seems at least somewhat popular to “persist data”. It’s quite Cloud centric and thus offers limited offline features. For example, in order to use batches (“transactions”), an internet connection is required to “commit”. Also, due to its low performance, the test configuration was different: batches of 500 objects and only 10 runs.</p>



<h3>Test setup</h3>



<p>We ran the benchmarks as a Flutter app on a Android 10 device with a Kirin 980 CPU. The app executed all operations in batches of 10.000 objects, with each batch forming a single transaction. Each test was run 50 times, averaging the results over all the runs. This ensured the VM warmup (optimization) during the first run and garbage collections don’t affect the overall result significantly. (We care about accurate benchmarks; <a href="https://objectbox.io/how-to-benchmark-database-performance-and-objectbox/">read more about our benchmarking best practices here.</a>)</p>



<h2>Outlook</h2>



<p>With this latest release, we’re not far away from a stable API for a 1.0 release (<strong>🎉</strong>), so please share your thoughts and feedback. For the next release, we’ll add features like async operations, more relation types and some smaller improvements. We are also working on an <a href="https://github.com/objectbox/objectbox-dart/issues/185"><strong>ObjectBox variant for the Web platform</strong></a> that is planned close to the 1.0 release. And of course there is <a href="https://objectbox.io/sync/">ObjectBox Data Sync</a> for Flutter/Dart. If you want to be first in line to try, <a href="mailto:contact@objectbox.io">drop us a line</a>, we can put you on the shortlist.</p>
					</div></div>]]>
            </description>
            <link>https://objectbox.io/objectbox-dart-flutter-v0-11-database-performance-relations/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26005920</guid>
            <pubDate>Tue, 02 Feb 2021 20:09:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[$1M in grants to researchers studying the future of the Internet]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26005911">thread link</a>) | @infodocket
<br/>
February 2, 2021 | https://www.isocfoundation.org/2021/01/announcing-1m-in-grants-to-researchers-studying-the-future-of-the-internet/ | <a href="https://web.archive.org/web/*/https://www.isocfoundation.org/2021/01/announcing-1m-in-grants-to-researchers-studying-the-future-of-the-internet/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-node="5c39191705c37">
<div>
<p><strong>We recently awarded over $1 million through our </strong><a href="https://www.isocfoundation.org/grant-programme/research-grant-programme/">Research grant programme</a><strong> to seven exciting projects that examine the future and sustainability of the Internet. </strong>In its pilot year, this programme seeks to support a diverse group of researchers who are generating solutions today to meet the Internet challenges of tomorrow.</p>
<p>The selected projects examine important issues around the Internet’s relationship to society, such as: the economic cost of the digital gender gap, the impact of digital labour platforms on worker’s rights, what climate solutions might help decarbonize the subsea cable network, and more.</p>
<p>Recommended for funding by an Independent Programme Review Committee, the awardees hail from Australia, Austria, India, Malawi, and the U.S. These grants are intended for applied research that will be published and made available to the scientific community at no cost.</p>
<p>Through these grants, we look forward to enabling new and valuable research on the future of the Internet, research that will influence policy and industry decisions and ultimately help shape a more equitable and sustainable future for the Internet and the people it serves.</p>
<p>Learn more about each awardee in the list below.</p>
<p>1<a href="https://www.eli.org/news/internet-society-foundation-funds-new-research-environmental-footprint-digital-economy">. Environmental Law Institute</a> <strong>– USA <strong>–</strong></strong> <strong>$200,000 &nbsp;</strong></p>
<p><strong>Theme:</strong> Greening the Internet</p>
<p><strong>Project Title:</strong> Creating a Research Strategy to Green the Internet</p>
<p><strong>Research Question:</strong> How can we identify high-value, high-impact research on the energy and environmental impacts of the digital economy?</p>

<p>2. <a href="https://cis-india.org/">The Centre for Internet and Society</a><strong> – India <strong>–</strong> $200,000 &nbsp;</strong></p>
<p><strong>Theme:</strong> The Internet Economy</p>
<p><strong>Project Title:</strong> Labour futures: Intersectional policy making for the platform economy</p>
<p><strong>Research Question: </strong>How are digital platforms broadly, and digital labour platforms specifically, occupying and performing their roles as intermediaries and infrastructure in the global south?<br></p>

<p>3. <strong>Chomora Mikeka (Independent Researcher) – Malawi <strong>–</strong> $57,017 &nbsp;</strong></p>
<p><strong>Theme:</strong> Greening the Internet</p>
<p><strong>Project Title:</strong> Greening Internet of Things (IoT) for Smart Cities</p>
<p><strong>Research Question:</strong> Can IoT Sensors used for Smart Garbage Collection in Smart Cities be Green Powered?</p>

<p>4. <a href="https://worlddata.io/">World Data Lab</a><strong> – Austria <strong>–</strong> $193,660 &nbsp;</strong></p>
<p><strong>Theme:</strong> The Internet Economy</p>
<p><strong>Project Title</strong>: International Internet Inequality Index</p>
<p><strong>Research Question</strong>: Which economic and demographic factors contribute to global Internet access in the future?</p>

<p>5. <a href="https://webfoundation.org/">World Wide Web Foundation</a><strong> – USA <strong>–</strong> $199,974 &nbsp;</strong></p>
<p><strong>Theme:</strong> The Internet Economy</p>
<p><strong>Project Title</strong>: The Cost of Excluding Women: The Digital Gender Gap &amp; Economic Prospects</p>
<p><strong>Research Question:</strong> What is the economic impact of not having women participate in digital economies due to the digital gender gap?</p>
<p>6. <a href="https://digitalrightswatch.org.au/">Digital Rights Watch</a><strong> – Australia – $187,299 – 18 months</strong></p>
<p><strong>Theme:</strong> The Internet Economy</p>
<p><strong>Project Title:</strong> An International Internet for Local Needs</p>
<p><strong>Research Question:</strong> How can we rebalance bargaining power between local actors and international Internet players?</p>
<p>7.<a href="https://www.totaltele.com/508363/SubOptic-Association-Launches-the-SubOptic-Foundation"> SubOptic Foundation</a><strong> – USA – $200,000 – 24 months</strong></p>
<p><strong>Theme:</strong> Greening the Internet</p>
<p><strong>Project Title:</strong> Decarbonizing the Subsea Cable Network</p>
<p><strong>Research Question</strong>: What is the average carbon footprint of a cable station, and what climate solutions might help to mitigate this footprint?</p>
<p><em>The </em><a href="https://www.isocfoundation.org/grant-programme/research-grant-programme/"><em>Research programme</em></a><em> is open to independent researchers and research institutions worldwide and is currently accepting statements of interest, to be reviewed on a rolling basis. </em><em>Grants of up to US$200,000 will be awarded for research lasting up to 2 years.</em></p>

</div>
</div></div>]]>
            </description>
            <link>https://www.isocfoundation.org/2021/01/announcing-1m-in-grants-to-researchers-studying-the-future-of-the-internet/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26005911</guid>
            <pubDate>Tue, 02 Feb 2021 20:08:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Israel’s vaccination success: exchange citizens data for 10M doses]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26005844">thread link</a>) | @KoftaBob
<br/>
February 2, 2021 | https://www.politico.eu/article/israel-coronavirus-vaccine-success-secret/ | <a href="https://web.archive.org/web/*/https://www.politico.eu/article/israel-coronavirus-vaccine-success-secret/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
									
							<div id="amazon-polly-audio-table">
				<p>Press play to listen to this article</p>
				
		</div>
<p>Just three weeks since the first Israeli citizen received the BioNTech/Pfizer jab — Prime Minister Benjamin Netanyahu himself — the country has raced ahead of the rest of world with vaccinations, covering about 20 percent of its population to date.</p>



<p>Reasons behind this roaring start are fast emerging: Netanyahu revealed on January 7 that Israel struck an agreement with Pfizer to exchange citizens' data for 10 million doses of the coronavirus vaccine, including a promise of shipments of 400,000-700,000 doses every week. </p>



<p>Under this agreement, Israel will provide details<strong> </strong>to Pfizer (as well as and the World Health Organization) about the age, gender and medical history of those receiving the jab as well as its side effects and efficacy. No identifying information will be given in order to maintain some privacy. </p>



<p>Ten million doses are a drop in the ocean for Pfizer, which has pledged to produce 1.3 billion vaccine doses in 2021 — and is likely to produce more. Once regulatory approval came in mid-December — ahead of the EU — Israel was waiting with its syringes out, making it worthwhile for Pfizer to remove the first vaccines from its production line to one of the first countries that would use them.</p>



<p>The news couldn't come soon enough for Israel. It has reported more than&nbsp;495,000 COVID-19 cases and 3,689&nbsp;deaths since the beginning of the pandemic — alarmingly high figures for the small country of 9 million.</p>



<p>Pfizer clearly has much to gain by rolling out its vaccine in Israel, turning it into the global pilot for a rapid vaccination campaign — and the depth of results now available to Pfizer, especially if successful, can boost marketing worldwide. </p>



<p>"We convinced them that if they give their vaccine to us first, we will know exactly how to administer it in the shortest time possible — and this is precisely what happened," Israeli Health Minister Yuli Edelstein told POLITICO via his spokesperson.&nbsp;"We were prepared early, signed the agreements early, and told pharmaceuticals they would see results early. It's a win-win situation."&nbsp;</p>



<p>With some days seeing more than 150,000 people getting vaccinated, Edelstein said, he's confident about Israel's success: "We continue to lead worldwide."&nbsp;</p>



<p>Still, health authorities aren't answering direct questions about the exact number of doses Israel has secured or how much it paid for them, saying only that the country signed secret agreements with manufacturers as the vaccination campaign began. </p>



<p>Also unclear was the price it had paid for the Pfizer jab — until January 5, when officials disclosed off-the-record that Israel paid $30 per person. That's more than twice the amount listed by Belgium, for example, which accidentally revealed its vaccine price list when <a rel="noreferrer noopener" href="https://www.politico.eu/article/belgian-secretary-of-state-accidentally-reveals-eu-vaccine-prices/" target="_blank">Belgium's secretary of state</a> tweeted it. Then, on Monday night,&nbsp;<a rel="noreferrer noopener" target="_blank" href="https://www.timesofisrael.com/israel-said-to-be-paying-average-of-47-per-person-for-pfizer-moderna-vaccines/">an Israeli public broadcaster</a>&nbsp;reported an even higher price, at $47 per person.</p>



<p>Netanyahu — who is hoping to get reelected in March — has also repeatedly brought up his close relationships with the chief executives of Pfizer and Moderna, suggesting his connections helped secure millions of doses.&nbsp;</p>



<p>"I speak to them all the time," Netanyahu said. He added that Pfizer CEO Albert Bourla, a descendant of a Jewish family from Thessaloniki, is "a great friend" of Israel.</p>



<h3>Small country, strong health care</h3>



<p>Israel has a mandatory public health system connected to a nationwide digital network. Health maintenance organizations keep digital records of all patients, allowing any authorized computer to extract people's medical data since birth — including past hospitalizations, prescribed medications and vaccinations.</p>



<p>"An operation at such scale could not have happened in a private health care system," said a senior nurse at Israel's renowned Ichilov hospital in Tel Aviv, who preferred to remain anonymous. She has vaccinated hundreds of people against the coronavirus so far.</p>



<p>"I have never seen so many health care workers volunteering their free time for the greater cause like this," she explained. The sense of social solidarity and the feeling of being in this together has contributed massively to the speed of Israel's vaccination campaign — "perhaps more so than in other countries," she said.&nbsp;</p>



<p>For now, Israel is prioritizing people older than 60, health workers and people with medical conditions, followed by over-55s with underlying conditions. At this point, more than 72 percent of people aged 60 and older have been vaccinated.</p>



<h3>Not without hurdles</h3>



<p>Israelis have so far only been receiving the Pfizer jab, but the country has also secured deals with Britain's AstraZeneca and U.S. manufacturer Moderna. The latter announced last Tuesday that its vaccine had been approved by the Israeli health ministry.&nbsp;</p>



<p>Moderna promised to supply 6 million doses, enough to vaccinate 3 million people<strong>. </strong>Israel&nbsp;has already received the first of an expected four shipments coming over the next few weeks, with a second shipment of about 480,000 doses expected Wednesday or Thursday.&nbsp; </p>



<p>Bottlenecks or distribution hurdles aren't solved once imported doses cross the border, however. Unlike the Oxford/AstraZeneca jab, the Pfizer vaccine needs to be kept at minus 70 degrees Celsius, which requires special storage techniques.</p>



<p>These jabs are handled by SLE, the logistics unit of Teva Pharmaceutical Industries. Thirty underground freezers located in a facility near Israel's main international airport hold about 5 million doses, which are then repackaged into 100-dose bundles and delivered across the country.</p>



<p>Distributing the jabs quickly is crucial, and this is one area where the eagerness among Israelis to get vaccinated is accelerating the effort. Interest is so high that every day, <a href="https://www.globes.co.il/news/article.aspx?did=1001356148,%20https://www.themarker.com/news/health/.premium-MAGAZINE-1.9430992]" target="_blank">queues of younger people</a> hoping for leftover doses form in front of inoculation stations. WhatsApp groups filled with people contacting each other to secure these doses have also appeared.&nbsp;</p>



<h3>Ahead of the pack </h3>



<p>Despite leading vaccination campaigns worldwide, Israel has come under fire from human rights groups and news organizations for failing to provide vaccines to Palestinians in the West Bank and Gaza. The Palestinian health ministry has more than 100,000 confirmed cases in the West Bank, with more than 1,100 deaths, in a population of roughly 3 million. Gaza has reported over 45,000 cases in 2 million residents, with more than 400 fatalities.</p>



<p>There is also the issue of cross-border traffic: About 60,000 Palestinian workers enter Israel every day, most of whom work in the construction industry. But Israel only started testing them in December, when the Coordinator of Government Activities in the Territories (COGAT) announced it would start conducting sample testing.</p>



<p>Despite the urgent situation, the Palestinian Authority (PA) in the West Bank has not publicly asked for Israeli assistance in vaccine procurement, and Hamas, which controls the Gaza strip, is highly unlikely to coordinate with Israel in any vaccination effort. </p>



<p>But according to the Russian Direct Investment Fund (RDIF), which is responsible for marketing the main Russian vaccine against COVID-19, known as Sputnik V, the Palestinian health ministry has approved its jab for use on Monday, with the first shipment of the shot expected to arrive next month.</p>



<p>Over the weekend, Palestinian general director of public health Yasser Bozyeh said that the PA had also sought supplies from Moderna, AstraZeneca and Johnson &amp; Johnson, in addition to supplies expected through COVAX, the WHO's vaccine program for poor and middle-income countries.</p>



<p>Still, Israeli media&nbsp;<a rel="noreferrer noopener" href="https://www.jpost.com/arab-israeli-conflict/israel-sends-palestinian-authority-vaccines-for-humanitarian-cases-654508" target="_blank">reported last Wednesday</a>&nbsp;that thousands of doses have already been passed to the West Bank, a claim which was&nbsp;<a rel="noreferrer noopener" href="https://www.jpost.com/arab-israeli-conflict/palestinians-accuse-israel-of-shirking-duty-to-supply-covid-19-vaccines-654946" target="_blank">later denied by the PA Health Ministry</a>.</p>



<p>There also remain pockets of communities that might hold out. Israel's Arab minority — about 21 percent of the population — has <a href="https://datadashboard.health.gov.il/COVID-19/general" target="_blank">shown wariness</a> towards vaccination. And numerous ultra-orthodox Jewish communities are <a href="https://www.nytimes.com/2021/01/06/world/middleeast/israel-coronavirus-vaccine-palestinians.html,%20https://www.wsj.com/articles/israels-covid-19-vaccinations-hold-lessons-for-u-s-11610307240," target="_blank">ignoring</a> the coronavirus-control measures altogether, resulting in infection rates sometimes five times higher than in many secular cities. </p>



<p>In the meantime, Netanyahu has vowed to increase Israel's vaccination pace to at least 170,000 people per day. But as many of his critics point out, it takes more than a country’s leader to secure such operation.</p>



<p>"Personally, I am truly excited to take part in the vaccination efforts,"&nbsp;said the Ichilov senior nurse, who's also a fierce critic of the prime minister.&nbsp;"The amount of people wholeheartedly committed to this operation is what made it all possible."</p>



<p><em>&nbsp;UPDATE: This story has been updated to include new media reports about the vaccine price.</em></p>



<p><em>This article is part of </em><span>POLITICO</span><em>’s premium policy service: Pro Health Care. From drug pricing, EMA, vaccines, pharma and more, our specialized journalists keep you on top of the topics driving the health care policy agenda. Email <a href="https://www.politico.eu/article/israel-coronavirus-vaccine-success-secret/%E2%80%9Cmailto:pro@politico.eu%E2%80%9D" target="_blank"><span data-cfemail="2f5f5d406f5f4043465b464c40014a5a">[email&nbsp;protected]</span></a> for a complimentary trial.</em></p>								</div></div>]]>
            </description>
            <link>https://www.politico.eu/article/israel-coronavirus-vaccine-success-secret/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26005844</guid>
            <pubDate>Tue, 02 Feb 2021 20:03:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Engineering productivity can be measured, just not how you'd expect]]>
            </title>
            <description>
<![CDATA[
Score 135 | Comments 88 (<a href="https://news.ycombinator.com/item?id=26005758">thread link</a>) | @tomasrb
<br/>
February 2, 2021 | https://www.okayhq.com/blog/engineering-productivity-can-be-measured | <a href="https://web.archive.org/web/*/https://www.okayhq.com/blog/engineering-productivity-can-be-measured">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>From each of our <a href="https://www.linkedin.com/in/antoineboulanger/" rel="nofollow noopener noreferrer" target="_blank">two</a>  <a href="https://www.linkedin.com/in/tomasrb/" rel="nofollow noopener noreferrer" target="_blank">experiences</a> starting out as introductory-level engineers at Box, to becoming first-time managers overseeing five-person teams, then directors overseeing 30-50, and ultimately VPs managing hundreds, we've experienced software engineering from every angle.</p>
<p>At every step of the way, we asked ourselves: "how do we know if we are bringing value as engineering leaders?" Effective leadership uniquely blends human qualities - influence, empathy, courage, and <strong>results</strong>. This latter quality always brings the question of productivity - how effective are you at producing results through enabling others?</p>
<p>Since the advent of the software industry, most engineering teams have seen productivity as a black box. Only recently have people even begun to build internal tools that optimize performance. Unfortunately, most of these tools measure the wrong metrics and are shockingly similar across companies. We even built some of these tools and made mistakes. Now, we'd like to share the way forward.Â&nbsp;</p>
<h2 id="engineering-effectiveness-is-behind-the-times">Engineering Effectiveness is Behind the TimesÂ&nbsp;</h2>
<p>Engineering teams are both the most expensive and most fundamental part of tech companies. As <a href="https://www.wsj.com/articles/every-company-is-now-a-tech-company-1543901207" rel="nofollow noopener noreferrer" target="_blank">more companies become tech-enabled</a>, the importance of engineering will only increase. Yet today, a full three decades after the advent of the internet, most engineering departments still rely exclusively on qualitative signals of performance.</p>
<p><strong>The evolution of engineering effectiveness is paralleling the spirit of sales' recent transformation</strong>. In the early 2000s, sales was considered an art, so sales leaders could skate by on charisma alone. Today, with tools like <a href="https://www.salesforce.com/" rel="nofollow noopener noreferrer" target="_blank">Salesforce</a>, <a href="https://www.clari.com/" rel="nofollow noopener noreferrer" target="_blank">Clari</a>, and <a href="https://people.ai/get-demo/?utm_campaign=demorequest&amp;utm_source=google&amp;utm_medium=ppc&amp;utm_term=se-goog-1089&amp;utm_content=demorequest&amp;gclid=CjwKCAiAxp-ABhALEiwAXm6Iye9qQZaeojCPMvXn73zi-TRqbT93l7waQz3_uSadhOtpXncm8OLtvBoClTkQAvD_BwE" rel="nofollow noopener noreferrer" target="_blank">People.ai</a>, sales has fully executed the transition toward scientific, metric-based leadership for analyzing and improving performance.</p>
<p>In the coming years, engineering will adopt a similar, data-driven mode of management. In making this transition, however, most engineering teams are making these mistakes:</p>
<h3 id="mistake-1-measuring-approximations-of-output">Mistake #1: Measuring Approximations of Output</h3>
<p>In their haste to become more data-driven, many engineering leaders are measuring their team's performance based on metrics intended to approximate output. <strong>These metrics fail because they encourage engineers to game the system.</strong></p>
<p>If you measure a fixed metric like lines of code or number of tickets closed, your engineers will begin splitting code into more lines or breaking bug fixes into multiple tickets. Even sprint points, which attempt to convert engineering work into a standard unit, suffer from this pitfall: Some engineers will slow down after reaching their sprint points for the week while others will strategically inflate their tasks to be awarded additional points.</p>
<p><strong>Experienced engineers will recognize that this type of measurement is fake</strong>. While they may not be as influenced to "play the game," their morale will plummet and they will self-select out. By rewarding approximated metrics of output, you're encouraging engineers to increase them regardless of how they correlate with software development success.</p>
<blockquote>
<p>No matter which metrics you choose, abstract output approximations will distract engineers from their actual jobs, ultimately decreasing both your team's effectiveness and morale.</p>
</blockquote>
<h3 id="mistake-2-not-measuring-anything">Mistake #2: Not Measuring Anything</h3>
<p>On the other end of the spectrum sit engineering leaders who avoid measurement entirely. Many of these leaders have heard about the dangers of measuring the wrong metrics and therefore <strong>ricochet to the other extreme</strong>. They may emphasize the artisanal and social dimensions of engineering, claiming "software engineering is too complex to measure."</p>
<p>Non-measurement can even be self-reinforcing, because it places the leader into the position of being "the good guy." Instead of being a metrics-obsessed big brother, the leader can be the <strong>friendly older brother exclusively focused on keeping their team happy</strong>.</p>
<p><strong>Non-measurement fails because it prioritizes politics over productivity.</strong> If you don't measure any metrics, your engineering leaders will simply justify failures, telling stories like "The customer didn't give us the right requirements" or "We were surprised by unexpected vacations." Software development is complex enough that something always goes wrong; if you don't measure any data, you're at the mercy of individual stories.</p>
<blockquote>
<p>Non-measurement unfairly rewards people with charisma while productive but less-persuasive engineers wallow in frustration.</p>
</blockquote>
<p>At some point, your top performers will see through these political machinations and quit because your culture lacks accountability.</p>
<p>In the short term, non-measurement can have a positive effect on team morale but it destroys morale in the long-term, especially among high performers.Â&nbsp;</p>
<h2 id="the-solution-measure-blockers-at-the-team-level">The Solution: Measure Blockers at the Team LevelÂ&nbsp;</h2>
<p>Instead of measuring some approximation of engineering output, software teams should measure actual, observable metrics that directly correlate to effectiveness.</p>
<p>Productivity is a relationship between inputs and output. In software development, the inputs are a blend of factors--technical, individual, human, etc.--while the output should be functional software that creates value for customers. <strong>Productivity in engineering therefore naturally increases when you remove the blockers getting in the way of your team.</strong></p>
<h3 id="why-you-should-measure-blockers">Why You Should Measure Blockers</h3>
<p>Even at the beginning of the software revolution, there existed the notion that engineers should be nurtured. Starting with Microsoft in the '80s, tech companies gave engineers free resources (like <a href="https://www.businessinsider.com/free-food-silicon-valley-tech-employees-apple-google-facebook-2018-7#google-has-so-much-free-food-employees-worry-about-gaining-the-google-15-4" rel="nofollow noopener noreferrer" target="_blank">food</a> and <a href="https://www.businessinsider.com/companies-amazing-health-and-fitness-benefits-2019-8" rel="nofollow noopener noreferrer" target="_blank">gyms</a>) that would remove blockers to their work. Empirical management practices over the last forty years have reinforced the importance of "<a href="https://www.axelos.com/news/blogs/january-2020/the-importance-of-servant-leadership" rel="nofollow noopener noreferrer" target="_blank">servant leadership</a>" and "<a href="https://www.mugo.ca/Blog/The-most-important-web-project-management-skill-the-ability-to-unblock-others" rel="nofollow noopener noreferrer" target="_blank">unblocking your team</a>," while <a href="https://puppet.com/resources/report/2020-state-of-devops-report/" rel="nofollow noopener noreferrer" target="_blank">recent research</a> emphasizes the importance of optimized inputs and best practices.</p>
<p>For engineers, these inputs include:</p>
<ul>
<li>Quality of developer tools</li>
<li>Frequency and quality of internal activities (like meetings or code reviews)Â&nbsp;</li>
<li>Focused <a href="http://www.paulgraham.com/makersschedule.html" rel="nofollow noopener noreferrer" target="_blank">maker time</a> (free from disruptive meetings)</li>
<li>Easy access to documentation</li>
<li>Psychological safety on the team</li>
<li>Work-life balance</li>
<li>Presence of other high-performersÂ&nbsp;</li>
<li>A fair system of rewards</li>
</ul>
<p>The blockers to these inputs already exist and can be quantified, such as:</p>
<ul>
<li>How much free, uninterrupted time does an engineer have to code?</li>
<li>How long is an engineer waiting on a response from another engineer's review?</li>
<li>How often do dev tools get in the way instead of helping accelerate work?Â&nbsp;</li>
<li>How often are engineers required to <a href="https://en.wikipedia.org/wiki/Context_switch" rel="nofollow noopener noreferrer" target="_blank">context switch</a>, preventing <a href="https://www.calnewport.com/books/deep-work/" rel="nofollow noopener noreferrer" target="_blank">deep work</a>?</li>
<li>How often do engineers receive pages outside of business hours, interrupting their sleep or family life?</li>
</ul>
<p><strong>An engineering leader exists to enable their team to achieve their goals.</strong> Together, these quantified blockers allow engineering leaders to answer key questions like:</p>
<ul>
<li>What is preventing the engineers from building faster?</li>
<li>What issues are arising in real time?Â&nbsp;Â&nbsp;</li>
<li>What technology or process investments would increase team engagement?</li>
</ul>
<p>Each engineering team is unique, so its blockers will be specific. It's not so simple as "more maker time is better." If your engineering team is new or temporarily misaligned on key goals, more meeting time might be the answer. What never changes is the need for measurement and well-considered, deliberate decisions.</p>
<p>Over the last year, COVID-19 has helped demonstrate the value of measuring blockers. For many leaders running newly remote teams, <a href="https://www.ventureharbour.com/remote-work-challenges-solutions/" rel="nofollow noopener noreferrer" target="_blank">new blockers have arisen</a> that would never have been noticed if managers were only focusing on the desired outcome.</p>
<blockquote>
<p>If your team is full of competent, driven engineers, removing their blockers is the fastest way to enable forward movement.</p>
</blockquote>
<h3 id="why-team-is-the-right-level-to-improve">Why "Team" is the Right Level to Improve</h3>
<p>Since software development requires complex interaction between team members, it would be inappropriate to assign individuals their own metrics: Some engineers are effective individual contributors while others enable their teammates to perform. Engineers also <a href="https://techcrunch.com/2020/12/02/okay-nabs-funding-from-sequoia-to-build-performance-dashboards-for-engineering-managers/" rel="nofollow noopener noreferrer" target="_blank">hate being micromanaged</a>, so tracking individual activity can make them feel untrusted.</p>
<p><strong>Just as a sports team wins or loses together, so too should the engineering team be treated as the fundamental unit of success.</strong></p>
<p>Approaching engineering at the team level also places the proper accountability on the manager. It raises helpful questions like "What behaviors, structures, and work habits are preventing us from succeeding?"</p>
<p>Looking at the team level also enables managers to catch blockers as they evolve. Small issues, for instance, may not be apparent when the company is young, but can evolve into 10,000 papercuts only apparent at the team level. If code reviews take days instead of hours, at first one engineer complains, then two, then three... and if you don't pay attention, years later the engineering culture is shot. By compiling these small quantifications and observing their trends, a manager can understand whether a report is one individual's experience or truly relevant to the overall performance of the team.</p>
<p>Perhaps most important, if blockers follow a constant evolution (e.g. one person is often the canary in the coalmine), an engineering leader can map how the new blockers are likely to evolve and prioritize which should be solved first.</p>
<p>Just as an airplane pilot must monitor dozens of different metrics to keep the plane flying, so too would an engineering leader benefit from viewing their team's metrics to understand overall performance.</p>
<blockquote>
<p>In an optimal engineering dashboard, a leader would be able to assess the blockers that prevent the ultimate success of their team.Â&nbsp;</p>
</blockquote>
<h2 id="toward-engineering-effectiveness">Toward Engineering EffectivenessÂ&nbsp;</h2>
<p>"Productivity" is an appropriate measure for someone making widgets at a factory: "How many products did you produce in an hour?"</p>
<p>Engineering should instead be about effectiveness: "How able is this engineer to effect positive impact?"</p>
<p>Looking forward, engineering effectiveness will have three parts:</p>
<ol>
<li>Measuring the experience of engineering teams in their most frequent activities. (Think<a href="https://www.scalyr.com/blog/distributed-tracing-important-2019/" rel="nofollow noopener noreferrer" target="_blank"> distributed tracing</a>, but for human activities.)</li>
<li>Using the …</li></ol></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.okayhq.com/blog/engineering-productivity-can-be-measured">https://www.okayhq.com/blog/engineering-productivity-can-be-measured</a></em></p>]]>
            </description>
            <link>https://www.okayhq.com/blog/engineering-productivity-can-be-measured</link>
            <guid isPermaLink="false">hacker-news-small-sites-26005758</guid>
            <pubDate>Tue, 02 Feb 2021 19:57:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Criti-Hype]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26005581">thread link</a>) | @samizdis
<br/>
February 2, 2021 | https://pluralistic.net/2021/02/02/euthanize-rentiers/#dont-believe-the-hype | <a href="https://web.archive.org/web/*/https://pluralistic.net/2021/02/02/euthanize-rentiers/#dont-believe-the-hype">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1833">
	<!-- .entry-header -->

	
	
	<div>
		<p><!--
Tags:


Summary:
Criti-Hype; Right to Repair is back for 2021; The free market and rent-seeking

URL:
https://pluralistic.net/2021/02/02/euthanize-rentiers/

Title:
Pluralistic: 02 Feb 2021 euthanize-rentiers

Bullet:
🧵

Separator:
_,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,_

Top Sources:
Today's top sources: Beka Valentine (https://twitter.com/beka_valentine?, Naked Capitalism (https://www.nakedcapitalism.com).

--><br>
<a href="https://pluralistic.net/2021/02/02/euthanize-rentiers/"><img src="https://i2.wp.com/craphound.com/images/02Feb2021.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/craphound.com/images/02Feb2021.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></p>

<ul>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2021/02/02/euthanize-rentiers/#dont-believe-the-hype">Criti-Hype</a>: Tech bros will settle for "evil genius."
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2021/02/02/euthanize-rentiers/#r2r">Right to Repair is back for 2021</a>: Will Apple sabotage this one too?
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2021/02/02/euthanize-rentiers/#poor-doors">The free market and rent-seeking</a>: Unauthorized bread and poor doors.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2021/02/02/euthanize-rentiers/#retro">This day in history</a>: 2011, 2016
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2021/02/02/euthanize-rentiers/#bragsheet">Colophon</a>: Recent publications, upcoming/recent appearances, current writing projects, current reading
</li>
</ul>

<hr>
<p><a name="dont-believe-the-hype"></a><br>
<img src="https://i2.wp.com/craphound.com/images/critihype.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/craphound.com/images/critihype.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>There's a Yom Kippur joke I love: the rabbi and the richest man in town are praying, "Oh Lord, I am nothing, I am nothing!"</p>
<p>The synagogue's janitor sees them and joins in: "I am nothing!"</p>
<p>The richest man says to the rabbi: "Look who thinks he's nothing."</p>
<p>The humblebrag is a wild phenomena, and it's endemic to a certain kind of tech criticism. When a technologist – what Maria Farrell calls a "prodigal tech bro" – confesses that he's an evil genius, then "genius" is the point.</p>
<p><a href="https://crookedtimber.org/2020/09/23/story-ate-the-world-im-biting-back/">https://crookedtimber.org/2020/09/23/story-ate-the-world-im-biting-back/</a></p>
<p>Think of the "AI" scientists who claim that they are about to be responsible for massive waves of technological unemployment, seeming to confess to a sin while actually overpromising on their AI.</p>
<p><a href="https://pluralistic.net/2020/03/24/grandparents-optional-party/#what-automation">https://pluralistic.net/2020/03/24/grandparents-optional-party/#what-automation</a></p>
<p>Or the critique of "surveillance capitalism" that takes at face value ad-tech's outlandish boasts about how good they are at changing peoples' minds with data-mining, and then warns that we're all about to be enslaved to mind-control tech.</p>
<p><a href="https://onezero.medium.com/how-to-destroy-surveillance-capitalism-8135e6744d59">https://onezero.medium.com/how-to-destroy-surveillance-capitalism-8135e6744d59</a></p>
<p>Or the hand-wringing over the "trolley problem" of self-driving cars, as though the issue with these cars will be their reliable fine-grained judgments, rather than their unreliability and anticompetitive fealty to their manufacturers.</p>
<p><a href="https://this.deakin.edu.au/self-improvement/car-wars">https://this.deakin.edu.au/self-improvement/car-wars</a></p>
<p>This is what Lee Vinsel calls "criti-hype," criticism that actually builds on – and depends on – maintaining the halo of devastating potency that surrounds overhyped technologies.</p>
<p><a href="https://sts-news.medium.com/youre-doing-it-wrong-notes-on-criticism-and-technology-hype-18b08b4307e5">https://sts-news.medium.com/youre-doing-it-wrong-notes-on-criticism-and-technology-hype-18b08b4307e5</a></p>
<p>While it's true that the social problems that technologies create have unique, subtle elements that require a fine-grained understanding of the underlying science, it's a mistake to assume this obviates historical lessons.</p>
<p>Like, blockchain and proof-of-work and cryptography do bring unique facets to the problems of financial engineering, money-laundering and fraud – but all the problems of financial engineering and money-laundering and fraud are still in the mix.</p>
<p>Ad-tech and engagement-maximization systems add new wrinkles to the problems of communications monopolies and the epistemological chaos created by corrupt institutions, but the chaos and the monopolies are still central to these problems.</p>
<p>The problem with many metacritics of tech – people who criticize tech critics – is their assumption that tech is irrelevant. The problem with tech critics themselves is their assumption that tech is dispositive.</p>
<p>The reality is that tech has formal characteristics – the universality of Turing completeness – that both expand the policy toolkit (the power of interoperability mandates) and constrain it (the futility of cryptography back-doors).</p>
<p>Criti-hype is real, and its remedy isn't to ignore technicalities and criticize tech as though it was just another industry – the remedy is to really understand what tech can and can't do, and to understand that the industry isn't run by super-genuises (evil or otherwise) nor science heroes (or villains).</p>
<hr>
<p><a name="r2r"></a><br>
<img src="https://i1.wp.com/craphound.com/images/tinker-tech_1.png?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/craphound.com/images/tinker-tech_1.png?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>2018 was almost the year we won the Right to Repair.</p>
<p>Instead, 2018 turned out to be the year we lost R2R: 20 bills defeated in 20 state houses, and it was mostly Apple's fault.</p>
<p>Apple has a problem. As CEO Tim Cook warned his investors at the conclusion of his company's repair-killing lobbying spree, Apple's profits depend on people throwing away their devices, not fixing them.</p>
<p><a href="https://www.apple.com/newsroom/2019/01/letter-from-tim-cook-to-apple-investors/">https://www.apple.com/newsroom/2019/01/letter-from-tim-cook-to-apple-investors/</a></p>
<p>By monopolizing repairs, Apple doesn't just get to gouge you on parts and service – the real action is in pronouncing your device DOA, beyond repair. Then you have to buy another one.</p>
<p>Other companies lobbied hard against R2R: John Deere, GM, and other monopolists backed Apple's play. But Apple wrote the playbook, coming up with risible bullshit like claims that blocking independent repair is essential to protecting privacy.</p>
<p><a href="https://judiciary.house.gov/sites/democrats.judiciary.house.gov/files/documents/apple%20rfi%20-%20signed.pdf">https://judiciary.house.gov/sites/democrats.judiciary.house.gov/files/documents/apple%20rfi%20-%20signed.pdf</a></p>
<p>Apple's anti-repair FUD got picked up and amplified by Big Car in 2020, when they spent millions fighting an automotive R2R ballot initiative in Massachusetts, claiming that letting independent mechanics at your car would lead to your actual <em>murder</em>.</p>
<p><a href="https://pluralistic.net/2020/11/13/said-no-one-ever/#r2r">https://pluralistic.net/2020/11/13/said-no-one-ever/#r2r</a></p>
<p>2018 is the year we lost Right to Repair, but 2021 might be the year we win it. We're only a month in and 14 states are already debating R2R legislation, with more to come. The Repair Coalition and PIRG are leading the fight, buoyed by massive R2R successes in the EU.</p>
<p>Independent repair isn't just fair and it isn't just good for the planet – it's also good for the nation and its economy. The average US family loses $330/year thanks to anti-repair practices, a $40b drag on the American economy.</p>
<p>Repair creates local jobs for SMEs whose earnings – from helping their neighbors – are taxed (not hidden in offshore tax-havens) and contribute to their communities. These are on-shore, dignified tech jobs – not slave labor in Xinjiang or coerced labor in a Foxconn plant.</p>
<p>Repair diverts ewaste from landfills. Each kiloton of ewaste creates &lt;1 landfill jobs, or 15 recyling jobs.</p>
<p>But that same kiloton of ewaste creates 200 local repair jobs.</p>
<p><a href="https://www.ifixit.com/Right-to-Repair/Jobs-Revolution">https://www.ifixit.com/Right-to-Repair/Jobs-Revolution</a></p>
<p>Repair creates a secondary market for low-cost devices that find their way into the hands of people on the wrong side of the digital divide – a divide that got starker and more consequential during the pandemic, and will only get more important in years to come.</p>
<p>Speaking of the pandemic: anti-repair laws meant that when PB840 ventilators (the most common ventilator, sold by the monopolist Medtronic, which benefits from the largest-ever tax-avoidance "reverse takeover" in corporate history) broke, they couldn't be legally fixed.</p>
<p>Instead, desperate med-tech people turned to a lone Polish hacker who built Medtronic defeat devices into old guitar-pedals and clock radios to get around the anti-repair measures in the ventilators that hospitals had bought and paid for.</p>
<p><a href="https://pluralistic.net/2020/07/10/flintstone-delano-roosevelt/#medtronic-again">https://pluralistic.net/2020/07/10/flintstone-delano-roosevelt/#medtronic-again</a></p>
<p>R2R is a fight for justice. For the right to decide who fixes your stuff. For the right to set up shop and help your neighbors. For self-reliance and resiliency over profits. For on-shore small businesses over multinational cheaters.</p>
<p>Once again, a wave of R2R laws is sweeping the nation. The monopolists who profiteered off our misery during the pandemic will once again turn out to stop them. PIRG and the Repair Coalition need our support – as do their coalition allies like EFF.</p>
<hr>
<p><a name="poor-doors"></a><br>
<img src="https://i1.wp.com/craphound.com/images/9069359_b10168b971_o.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/craphound.com/images/9069359_b10168b971_o.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>When you hear the phrase "free market," you probably think of "a market that is free from regulation" but that's the opposite of the phrase's original meaning!</p>
<p>Adam Smith used the term to describe a market that was free from "economic rents" – money earned by owning things, rather than doing things. Smith recognized that markets attract parasites – "rentiers" – who seek to drain wealth by "investing" rather than building and doing.</p>
<p>Which meant that, in the absence of muscular state  intervention, markets would become less and less free – more and more dependent on the whims of rentiers who used money to breed money by creating toll-barriers between parts of the productive economy.</p>
<p>For Smith, markets were only free if they were regulated. But that's the opposite of the way that we talk about free markets today. Today, a free market is a market where you are free to collect rents – passive income from owning things, at the expense of people doing things.</p>
<p>This is true in so many metaphorical ways, but it's especially true when we're talking about actual rent – actual homes that people need to survive and produce, whose primary role today is to serve as an asset class to be maximized, not a basic human right.</p>
<p>London is ground zero for the conversion of housing from a human right to a speculative asset, a city at war with itself, filled up with empty safe-deposit boxes in the sky, while productive workers – the "essential workers" of the pandemic – triple-up in substandard housing.</p>
<p>The conversion of London from a city to an asset was hugely profitable, primarily for offshore "investors," especially criminals who were attracted by London's veneer of respectability, which allowed them to convert their loot to legitimate earnings through property sales.</p>
<p>The overslosh of these tremendous cash flows has hopelessly corrupted London's planning authorities, who are absolutely helpless and hopeless at holding developers to their own promises – new builds get extra storeys and shed public concessions without penalty.</p>
<p>And just as the tax-authorities who despair of enforcing against the real cheats turn their efforts to everyday people who can't afford to fight investigations, London's planners spend their days making life miserable for homeowners trying to make minor improvements.</p>
<p>I spent two years fighting Hackney for the right to build a small, windowed greenhouse on my flat's balcony, finally giving up on growing my own veggies. Meanwhile, the for-profit "student residence" across the street replaced hundreds of small offices, overbuilt and busted.</p>
<p>Today, it's a failed Wework, while the four-storey "boutique hotel" across the street has been transformed into eight+ storeys, with multiple storeys of office space, all without any planning enforcement.</p>
<p>The conversion of London into a …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pluralistic.net/2021/02/02/euthanize-rentiers/#dont-believe-the-hype">https://pluralistic.net/2021/02/02/euthanize-rentiers/#dont-believe-the-hype</a></em></p>]]>
            </description>
            <link>https://pluralistic.net/2021/02/02/euthanize-rentiers/#dont-believe-the-hype</link>
            <guid isPermaLink="false">hacker-news-small-sites-26005581</guid>
            <pubDate>Tue, 02 Feb 2021 19:42:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Use Your Shell's History]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26005529">thread link</a>) | @hidden-spyder
<br/>
February 2, 2021 | https://letterstoanewdeveloper.com/2021/02/01/use-your-shells-history/ | <a href="https://web.archive.org/web/*/https://letterstoanewdeveloper.com/2021/02/01/use-your-shells-history/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Dear new developer,</p>



<p>The <a href="https://letterstoanewdeveloper.com/2019/02/04/learn-the-command-line/">command line is a powerful tool</a>, and writing shell scripts lets you write a series of commands once and replay them any time you like.</p>



<p>But sometimes you will write a series of commands without putting them into a script. This may be because you are exploring a problem or because you haven’t bothered to put together a script. No sense in making something repeatable if you aren’t sure exactly how you are going to repeat it.</p>



<p>But you may want to look back over past commands you have run, whether to run them again, modify them or even just remind yourself what you’ve done. For this, the shell history is very handy. Another time I often look at the shell history is when I am signing into a machine that I don’t visit very often. Perhaps there’s a command to look at some log files that I know, distantly, in the back of my mind, that I ran four weeks ago. I could have documented it, but maybe I didn’t. If I look in my command line history, I can see it.</p>



<p>All of the examples below are for the bash shell. Why? This is a very common shell, more modern shells like zsh are roughly compatible, and most importantly, this is the shell I know.</p>



<p>To use the shell history, first you have to know it exists and then you have to see it. You can also view the history by typing <code>history</code> in your terminal or at the shell prompt. Here’s an example from one of my shells:</p>


<pre title="">  520  vi text.adoc
  521  git status
  522  git add text.adoc
  523  git commit -m "Initial pass at examples and documentation."
  524  vi text.adoc
  525  git add text.adoc
  526  git commit -m "Added one more example." text.adoc
  527  git push origin add-example-docs
  528  history
</pre>


<p>Each line is one command and is numbered. From here, I can repeat a command by number. So if I type <code>!524</code> the command <code>vi text.adoc</code> will be run. I can also search for a certain string by using grep:</p>


<pre title="">history | grep 'ssh' # will show all my ssh commands
</pre>


<p>The above commands are all pretty simple, but you can also link commands together. I often will do something like this:</p>


<pre title="">cd directory &amp;&amp; mvn jar &amp;&amp; cp file.jar ~/place/jar/goes &amp;&amp; cd otherdirectory
</pre>


<p>Once I get this command right, I can run it over and over again by referencing its line number. The <code>&amp;&amp;</code> means that each command has to succeed before subsequent commands are run. So if the <code>mvn</code> command fails, the <code>cp</code> will not run.</p>



<p>This is fine for running tasks that are not going to change, but what about if I want to edit my previous commands. You can navigate the history by using the arrow keys (there are other ways as well, but arrow keys are the default and most accessible). Each up arrow takes you one step further back in your history, and each down arrow takes you one step forward. At any point you can edit the command you are currently on and hit the enter key and run it.</p>



<p><strong>The bang shortcuts</strong></p>



<p>If you know you want to edit whatever command you ran previously, you can use some bang operator shortcuts (so called because “bang” refers to a <code>!</code>). Let’s say I want to get the latest <code>main</code> branch from my git repo. </p>



<p>Suppose I run the command:</p>


<pre title="">gti fetch origin main
</pre>


<p>I see an error message because I misspelled <code>git</code>. Whoops. I can type:</p>


<pre title="">git !*
</pre>


<p><code>!*</code> expands to everything except the first argument in the previous line, so this is the command that is run:</p>


<pre title="">git fetch origin main
</pre>


<p>Now I want to check out the <code>main</code> branch</p>


<pre title="">git checkout !$
</pre>


<p><code>!$</code> refers to the last argument of the command, so <code>main</code> in this case. The command which is run is then:</p>


<pre title="">git checkout main
</pre>


<p>Knowing these shortcuts will help you avoid tediously hitting the arrow keys, editing the previous command and re-running it. There’s one more bang shortcut which is very useful. Suppose I want to install something on a linux box:</p>


<pre title="">apt-get install pkgname
</pre>


<p>Whoops again! I’ll get an error message because I’m not root. Easily fixed by typing:</p>


<pre title="">sudo !!
</pre>


<p><code>!!</code> expands to the entire previous command, so what is actually run is:</p>


<pre title="">sudo apt-get install pkgname
</pre>


<p>I use this very often when working with linux on the command line.</p>



<p><strong>Controlling what is saved</strong></p>



<p>You can control how much history is kept. Sometimes on my development machine I keep an infinite amount of it. I’ve also been on production instances where there was no history kept, I believe as a security measure. Remember, any command you run, including opening up a database connection using a command line client, will be kept in the history buffer. If you put a password on the command line, it will be recorded in this history.</p>



<p>To avoid that, don’t put the password on the command line. Another trick is to set the <code>HISTCONTROL</code> variable. When this is set to <code>ignoreboth</code> any command you type with a space in front won’t be stored in the history.</p>


<pre title="">export HISTCONTROL=ignoreboth # previously set
echo "hello" # included in history
 echo "goodbye" # not included
</pre>


<p>You can also control explicitly how many commands to store in your history with the <code>HISTSIZE</code> setting:</p>


<pre title="">export HISTSIZE=2000 # will save 2000 commands
</pre>


<p>Finally, be aware that all the bash shells opened share the same history file. Unless you take special care (<a href="https://unix.stackexchange.com/questions/57724/keep-all-commands-in-bash-history">as outlined here</a>) the last one closed will win.</p>



<p>Being able to quickly re-run commands you’ve built previously, whether unchanged or not, can be helpful when you are navigating around the command line in pursuit of your software goals. Knowing a few history commands lets you do so.</p>



<p>Sincerely,</p>



<p>Dan</p>
	</div></div>]]>
            </description>
            <link>https://letterstoanewdeveloper.com/2021/02/01/use-your-shells-history/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26005529</guid>
            <pubDate>Tue, 02 Feb 2021 19:38:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Calculate LTV for Ecommerce]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26005418">thread link</a>) | @cedricd
<br/>
February 2, 2021 | https://blog.narrator.ai/how-to-calculate-ltv/ | <a href="https://web.archive.org/web/*/https://blog.narrator.ai/how-to-calculate-ltv/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p><em><em>Photo by </em><a href="https://unsplash.com/@jplenio">Johannes Plenio</a><em> on <a href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></em></em></p><p>Understanding what Customer Lifetime Value is, why it's a useful metric, and how to compute it.</p><!--kg-card-begin: html--><!--kg-card-end: html--><h2 id="why-is-ltv-useful">Why is LTV useful?</h2><p>Lifetime Value (LTV) allows us to make decisions about our customers by considering their value today and their value in the future.</p><p>LTV allows us to have a common metric that represents what someone is worth today and what we expect them to be worth in the future so we can make decisions to influence future revenue.</p><blockquote>Note that this is LTV for retail e-commerce businesses with multiple single purchases. For subscriptions / SaaS products LTV is calculated differently and will be the topic of a future post.</blockquote><h2 id="ltv-explained">LTV Explained</h2><p>LTV is a modeled value that gives us a simple way to reason about a customer's changing behavior (purchase amount, retention, and cadence) using a simple metric.</p><p><br>It’s a prediction of future value generated from each customer and it's made up of the following components:</p><ol><li><strong>Retention</strong> Customers become more valuable as they have more orders</li><li><strong>Average Order Value</strong> Customers who spend more are more valuable</li><li><strong>Time Between Orders</strong> The time it takes for customers to come back will drive the time horizon over which LTV is realized</li></ol><h2 id="calculating-ltv">Calculating LTV</h2><blockquote>Before we dive in: Narrator can provide this analysis and many others in minutes using your data. <a href="https://calendly.com/narrator-team/demo?utm_source=blog">Chat</a> with us and we'll show you how!</blockquote><p>LTV uses retention patterns to understand a customer's likelihood to reach the nth order, then multiplies it with the revenue value in order to come up with the expected revenue from the nth order. Finally, the expected revenue is summed up across all orders. From there we'll use the time it takes for customers to order again to estimate the amount of time it will take to realize LTV.</p><figure><img src="https://blog.narrator.ai/content/images/2021/01/Blog-Diagrams---Page-3--1-.png" alt="" srcset="https://blog.narrator.ai/content/images/size/w600/2021/01/Blog-Diagrams---Page-3--1-.png 600w, https://blog.narrator.ai/content/images/size/w1000/2021/01/Blog-Diagrams---Page-3--1-.png 1000w, https://blog.narrator.ai/content/images/size/w1600/2021/01/Blog-Diagrams---Page-3--1-.png 1600w, https://blog.narrator.ai/content/images/2021/01/Blog-Diagrams---Page-3--1-.png 2115w" sizes="(min-width: 720px) 720px"></figure><p><strong>LTV is a converged value.</strong> LTV is based on the <em>expected</em> revenue that a single customer will generate. We look at the chance for customers overall to make subsequent orders. Eventually the likelihood to reach order number 4, for example, becomes so small that the expected revenue gains from another order stop mattering (diminishing returns). This is the point when LTV converges.</p><p>For example:</p><p>The LTV of a Narrator Demo customer converges at <strong>$154.25</strong>. It takes <strong>180</strong> days for a customer to reach <strong>95%</strong> of this value.</p><figure><img src="https://blog.narrator.ai/content/images/2021/01/Blog-Diagrams---Export--1-.png" alt="" srcset="https://blog.narrator.ai/content/images/size/w600/2021/01/Blog-Diagrams---Export--1-.png 600w, https://blog.narrator.ai/content/images/size/w1000/2021/01/Blog-Diagrams---Export--1-.png 1000w, https://blog.narrator.ai/content/images/size/w1600/2021/01/Blog-Diagrams---Export--1-.png 1600w, https://blog.narrator.ai/content/images/size/w2400/2021/01/Blog-Diagrams---Export--1-.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>LTV over time for Narrator's demo customer</figcaption></figure><h3 id="what-drives-ltv">What drives LTV</h3><p>LTV is a single number that represents a complex relationship between multiple variables, so we can reason about the combination customers' time, average order value, and retention and focus on the most valuable customers.</p><p>Behavioral drivers of LTV:</p><ol><li><strong>Customer Retention</strong></li><li><strong>Average Order Value</strong></li><li><strong>Time Between Orders</strong></li></ol><h3 id="modeling-customer-retention">Modeling Customer Retention</h3><p><strong>Retention is the biggest driver of LTV because the retention rate is carried over to subsequent orders</strong></p><p>Recall that the equation of LTV is a function of <strong>likelihood to reach the Nth order</strong>. And because the likelihood to reach the Nth order is dependent on the likelihood to reach the (N-1)th order, even small changes in retention are amplified throughout the calculation. This is what makes retention a significant driver of LTV.</p><figure><img src="https://blog.narrator.ai/content/images/2021/01/Blog-Diagrams---LTV.png" alt="" srcset="https://blog.narrator.ai/content/images/size/w600/2021/01/Blog-Diagrams---LTV.png 600w, https://blog.narrator.ai/content/images/2021/01/Blog-Diagrams---LTV.png 881w" sizes="(min-width: 720px) 720px"></figure><p>Overall the calculation goes like this</p><ol><li>Remove the most recent X days of data. </li><li>For each order occurrence (1st, 2nd, etc) look at the conversion rate to the next order</li><li>Sum the conversion rates to get the likelihood to reach Nth order</li></ol><p><strong>Ignore Recent Data</strong></p><p>First we need to ignore the most recent days of data – we need to give a chance for customers to order multiple times.</p><p>We can do this by looking at the number of days between completed orders for each customer. Of all the total orders, some were completed 1 day after the last one. Some were done 2 days after, and so on. When we add them all up, the number at which we hit 85% of all orders is a good stopping point. In our sample data that's 119 days. </p><p><strong>Likelihood to Reach Nth Order</strong></p><p>Generally (though not always) a returning customer is more likely to buy again than a brand new customer. </p><p>The problem is that any given customer isn't likely to have many orders – at each step a significant number of customers are dropping off along the way.</p><p>In our example, we see that 9.6% of customers purchase again after the first order, and of those 36% purchase after the second. </p><figure><img src="https://blog.narrator.ai/content/images/2021/01/Blog-Diagrams---Export--2-.png" alt="" srcset="https://blog.narrator.ai/content/images/size/w600/2021/01/Blog-Diagrams---Export--2-.png 600w, https://blog.narrator.ai/content/images/size/w1000/2021/01/Blog-Diagrams---Export--2-.png 1000w, https://blog.narrator.ai/content/images/size/w1600/2021/01/Blog-Diagrams---Export--2-.png 1600w, https://blog.narrator.ai/content/images/size/w2400/2021/01/Blog-Diagrams---Export--2-.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>To calculate the likelihood to reach the Nth order we just need to multiply the conversion rate of all the previous orders (note that we're only looking at customers who have ordered already, so the likelihood to reach the first order is 1). </p><p>Likelihood to reach 2nd order: 9.62%</p><p>Likelihood to reach 3rd order: 9.62% * 35.7% = 3.43%</p><p>... and so on</p><figure><img src="https://blog.narrator.ai/content/images/2021/01/Blog-Diagrams---Page-3.png" alt="" srcset="https://blog.narrator.ai/content/images/size/w600/2021/01/Blog-Diagrams---Page-3.png 600w, https://blog.narrator.ai/content/images/size/w1000/2021/01/Blog-Diagrams---Page-3.png 1000w, https://blog.narrator.ai/content/images/2021/01/Blog-Diagrams---Page-3.png 1006w" sizes="(min-width: 720px) 720px"><figcaption>Likelihood to Reach Order i</figcaption></figure><p>When plotted it looks like this</p><figure><img src="https://blog.narrator.ai/content/images/2021/01/Blog-Diagrams---Export--3-.png" alt="" srcset="https://blog.narrator.ai/content/images/size/w600/2021/01/Blog-Diagrams---Export--3-.png 600w, https://blog.narrator.ai/content/images/size/w1000/2021/01/Blog-Diagrams---Export--3-.png 1000w, https://blog.narrator.ai/content/images/size/w1600/2021/01/Blog-Diagrams---Export--3-.png 1600w, https://blog.narrator.ai/content/images/2021/01/Blog-Diagrams---Export--3-.png 1660w" sizes="(min-width: 720px) 720px"></figure><p>This will be the first part of our LTV calculation. </p><p>There's one interesting thing to note here: the fastest way to increase LTV is to increase the conversion to multiple orders. Here the drop off is fairly drastic, so any improvement will have an important effect.</p><blockquote>In our example, most customers are lost after the first purchase, so improving first order retention will have a huge impact on LTV.</blockquote><p>Now for the next part of the LTV calculation.</p><hr><h3 id="modeling-average-order-value">Modeling Average Order Value</h3><p>Customers may change their spending habits as they continue to purchase.</p><p>When valuing a customer, it's important to understand if they are going to spend more or less over time. For example, a customer who spends a lot up front but a little for each returning purchase might be less valuable than a customer spending less up front up a lot on each recurring purchase.</p><p>In short, spending behavior is an important input to the LTV calculation. LTV is the sum of the expected revenue gained at each order. Since we already know the likelihood that a customer will reach the Nth order, we just need to multiply that with the revenue value to get the expected revenue for that order.</p><figure><img src="https://blog.narrator.ai/content/images/2021/01/Blog-Diagrams---LTV--2-.png" alt="" srcset="https://blog.narrator.ai/content/images/size/w600/2021/01/Blog-Diagrams---LTV--2-.png 600w, https://blog.narrator.ai/content/images/2021/01/Blog-Diagrams---LTV--2-.png 882w" sizes="(min-width: 720px) 720px"></figure><p>Here we're predicting, based on the order number, how much money a customer will spend.</p><p>So we just need to compute the average order value by occurrence, which is fairly straightforward.</p><figure><img src="https://blog.narrator.ai/content/images/2021/01/Blog-Diagrams---Export--4-.png" alt="" srcset="https://blog.narrator.ai/content/images/size/w600/2021/01/Blog-Diagrams---Export--4-.png 600w, https://blog.narrator.ai/content/images/size/w1000/2021/01/Blog-Diagrams---Export--4-.png 1000w, https://blog.narrator.ai/content/images/2021/01/Blog-Diagrams---Export--4-.png 1540w" sizes="(min-width: 720px) 720px"></figure><hr><h3 id="putting-it-together">Putting it Together</h3><p>With both our pieces in place we can now compute LTV. So here's the equation one last time: </p><figure><img src="https://blog.narrator.ai/content/images/2021/01/Blog-Diagrams---Page-3--1-.png" alt="" srcset="https://blog.narrator.ai/content/images/size/w600/2021/01/Blog-Diagrams---Page-3--1-.png 600w, https://blog.narrator.ai/content/images/size/w1000/2021/01/Blog-Diagrams---Page-3--1-.png 1000w, https://blog.narrator.ai/content/images/size/w1600/2021/01/Blog-Diagrams---Page-3--1-.png 1600w, https://blog.narrator.ai/content/images/2021/01/Blog-Diagrams---Page-3--1-.png 2115w" sizes="(min-width: 720px) 720px"></figure><p>Recall that for each occurrence the likelihood to reach the Nth order is the product of all the ones before it. So we just multiply that by our average order value to get the expected order value by Nth order. Adding all those together gives us LTV!</p><!--kg-card-begin: markdown--><table>
<thead>
<tr>
<th>Nth Order</th>
<th>Likelihood of Nth Order</th>
<th>Average Order Value</th>
<th>Expected Value</th>
</tr>
</thead>
<tbody>
<tr>
<td>1st</td>
<td>1</td>
<td>$122.00</td>
<td>$122.00</td>
</tr>
<tr>
<td>2nd</td>
<td>0.093</td>
<td>$244.17</td>
<td>$22.70</td>
</tr>
<tr>
<td>3rd</td>
<td>0.034</td>
<td>$243.50</td>
<td>$8.28</td>
</tr>
<tr>
<td>4th</td>
<td>0.012</td>
<td>$257.03</td>
<td>$2.96</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td><strong>Sum</strong></td>
<td><strong>$155.94</strong></td>
</tr>
</tbody>
</table>
<!--kg-card-end: markdown--><p>The sum after the 4th order is $156. But what's the value after <strong>all </strong>the orders? At each step the expected value is going down fairly rapidly. It's obviously converging.</p><p>So where do we stop? When the LTV changes by no more than 1%, which will sum up to 95% of its total value. </p><p>For our example, the expected value of the seventh order is $1.22. This is less than 1% of the sum to that point, so we can stop there. That sum is $160.66, so dividing it by 0.95 brings us to a converged value of $169.11</p><figure><img src="https://blog.narrator.ai/content/images/2021/01/Blog-Diagrams---Graphs--11-.png" alt="" srcset="https://blog.narrator.ai/content/images/size/w600/2021/01/Blog-Diagrams---Graphs--11-.png 600w, https://blog.narrator.ai/content/images/size/w1000/2021/01/Blog-Diagrams---Graphs--11-.png 1000w, https://blog.narrator.ai/content/images/size/w1600/2021/01/Blog-Diagrams---Graphs--11-.png 1600w, https://blog.narrator.ai/content/images/size/w2400/2021/01/Blog-Diagrams---Graphs--11-.png 2400w" sizes="(min-width: 720px) 720px"></figure><hr><h2 id="modeling-time-to-accrue-revenue">Modeling Time to Accrue Revenue</h2><p>Now that we know that most of the LTV is accrued in the first 7 orders, we can compute how long it takes a customer to reach this point – we need to understand how much time passes between each order.</p><!--kg-card-begin: markdown--><blockquote>
<p><strong>A common error in LTV timing calculations</strong></p>
<div><p>A common mistake is to use historical data to see how long it took customers to reach the converged number of orders (in our case 7).</p><p>

<strong>Why it's dangerous</strong></p></div>
<div><p>The sample size of customers who reached 7 orders will very small, so using them to calculate the time to reach LTV will introduce a lot of error.</p><p>

<strong>A better way</strong></p></div>
<p>Instead, we'll use the median time between orders to calculate a better estimate of the time it takes to reach a given order ocurrence.</p>
</blockquote>
<!--kg-card-end: markdown--><p>This is fairly straightforward. We'll just look at the days between orders and sum them all together.</p><figure><img src="https://blog.narrator.ai/content/images/2021/01/Blog-Diagrams---Export--5-.png" alt="" srcset="https://blog.narrator.ai/content/images/size/w600/2021/01/Blog-Diagrams---Export--5-.png 600w, https://blog.narrator.ai/content/images/size/w1000/2021/01/Blog-Diagrams---Export--5-.png 1000w, https://blog.narrator.ai/content/images/2021/01/Blog-Diagrams---Export--5-.png 1460w" sizes="(min-width: 720px) 720px"></figure><p>Summing the days between orders up to the 7th order gives us a total of <strong>266 </strong>days. In other words, we're predicting that it takes 266 days from their first order for customers to reach 95% of their LTV.</p><p>This number can be a very useful timeframe for thinking about return on investment. For example, this can be used to compute the time to recover customer acquisition costs. </p><hr><h2 id="ltv-and-beyond">LTV and Beyond</h2><p>And there it is. Our complete LTV. </p><figure><img src="https://blog.narrator.ai/content/images/2021/01/Blog-Diagrams---Export--6-.png" alt="" srcset="https://blog.narrator.ai/content/images/size/w600/2021/01/Blog-Diagrams---Export--6-.png 600w, https://blog.narrator.ai/content/images/size/w1000/2021/01/Blog-Diagrams---Export--6-.png 1000w, https://blog.narrator.ai/content/images/size/w1600/2021/01/Blog-Diagrams---Export--6-.png 1600w, https://blog.narrator.ai/content/images/2021/01/Blog-Diagrams---Export--6-.png 1620w" sizes="(min-width: 720px) 720px"></figure><p>So where do we go from here? </p><p><strong>Use LTV instead of Average Order Value to represent the value of a customer</strong></p><p>Use LTV for analyses when you need to represent the value of a customer because LTV allows you to reason about their spending, retention, and timing simply using a single metric.</p><ul><li>Ensure operating and acquisition costs stay below LTV to ensure a positive business ROI</li><li>Ensure Product teams prioritize improvements that cater towards high LTV users</li></ul><p><strong>Work on improving order retention and other drivers of LTV</strong></p><p>Conduct a follow up analysis to dive into each of the behaviors that drive LTV. This will &nbsp;identify the areas to focus that will have the biggest impact.</p><hr><h2 id="is-there-an-easier-way">Is there an easier way?</h2><p>Doing a full LTV analysis like this is clearly a lot of work. Luckily we've already done it. </p><p>Our company, <a href="https://www.narrator.ai/?utm_source=blog">Narrator</a>, provides these kinds of in-depth analyses (what we call <a href="https://www.narrator.ai/narratives?utm_source=blog">Narratives</a>) in minutes using your own data. Our library of Narratives includes this exact LTV analysis, along with many others. We'll also write about our optimizing LTV Narrative in a future blog post. </p><p>If you're interested <a href="https://calendly.com/narrator-team/demo?utm_source=blog">book a demo</a> or <a href="mailto:contact@narrator.ai">reach out</a> and we can chat about it.</p><figure><img src="https://blog.narrator.ai/content/images/2021/01/image-10.png" alt=""></figure>
                </div>
            </section></div>]]>
            </description>
            <link>https://blog.narrator.ai/how-to-calculate-ltv/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26005418</guid>
            <pubDate>Tue, 02 Feb 2021 19:29:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Accessibility Learning Resources Collection]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26005384">thread link</a>) | @enriquecastl
<br/>
February 2, 2021 | https://jeldergl.gitlab.io/accessibility-cache/ | <a href="https://web.archive.org/web/*/https://jeldergl.gitlab.io/accessibility-cache/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
			

<p>This is by no means an extensive list, but one that should allow you to learn and apply accessible practices no matter your familiarity, skillset, or interest. Start with the list below and be sure to contribute your own.</p>

<p><strong>Categories</strong></p>

<ul>
  <li><a href="#books">Books</a></li>
  <li><a href="#color">Color</a></li>
  <li><a href="#content">Content</a></li>
  <li><a href="#education">Education</a></li>
  <li><a href="#guidelines">Guidelines</a></li>
  <li><a href="#laws">Laws</a></li>
  <li><a href="#live-examples">Live examples</a></li>
  <li><a href="#media">Media</a></li>
  <li><a href="#screen-readers">Screen readers</a></li>
  <li><a href="#testing">Testing</a></li>
  <li><a href="#who-to-follow">Who to follow</a></li>
  <li><a href="#workflow">Workflow</a></li>
</ul>

<hr>

<h2 id="books">Books</h2>

<ul>
  <li><a href="https://shop.smashingmagazine.com/products/inclusive-design-patterns">Inclusive Design Patterns</a>, by Heydon Pickering</li>
  <li><a href="https://www.smashingmagazine.com/printed-books/inclusive-components/">Inclusive Components</a>, by Heydon Pickering</li>
  <li><a href="https://shop.smashingmagazine.com/products/form-design-patterns-by-adam-silver">Form Design Patterns</a>, by Adam Silver</li>
  <li><a href="https://abookapart.com/products/color-accessibility-workflows">Color Accessibility Workflows</a>, by Geri Coady</li>
  <li><a href="https://accessibility.deque.com/agile-accessibility-handbook">Agile Accessibility Handbook</a>, by Dylan Barrell</li>
  <li><a href="https://abookapart.com/products/accessibility-for-everyone">Accessibility for Everyone</a>, by Laura Kalbag</li>
</ul>

<hr>

<h2 id="color">Color</h2>

<h3 id="contrast">Contrast</h3>

<ul>
  <li><a href="https://contrast-ratio.com/">Contrast Ratio</a></li>
  <li><a href="https://accessible-colors.com/">Accessible Colors</a></li>
  <li><a href="https://color.review/">Color Review</a></li>
  <li><a href="https://whocanuse.com/">whocanuse</a></li>
  <li><a href="https://learnui.design/tools/accessible-color-generator.html">Accessible Color Generator</a></li>
  <li><a href="https://contrast-finder.tanaguru.com/">Tanaguru contrast finder</a></li>
  <li><a href="http://www.brandwood.com/a11y/">Text on background image a11y check</a></li>
  <li><a href="https://webaim.org/resources/linkcontrastchecker/">Link Contrast Checker</a></li>
  <li><a href="https://contrast-grid.eightshapes.com/">Contrast Grid</a></li>
  <li><a href="http://a11yrocks.com/colorPalette/">A11y Color Palette</a></li>
  <li><a href="https://hexnaw.com/">Hex Naw</a></li>
  <li><a href="https://abc.useallfive.com/">Accessible Brand Colors</a></li>
</ul>

<h3 id="data-visualization">Data visualization</h3>

<ul>
  <li><a href="https://projects.susielu.com/viz-palette">Viz Palette</a></li>
  <li><a href="https://learnui.design/tools/data-color-picker.html">Data Color Picker</a></li>
  <li><a href="https://colorbrewer2.org/#type=sequential&amp;scheme=BuGn&amp;n=3">ColorBrewer</a></li>
  <li><a href="https://medium.com/design-ibm/inclusive-color-sequences-for-data-viz-in-6-steps-712869b910c2">Inclusive Color Sequences for Data Viz in 6 Steps</a></li>
  <li><a href="https://venngage.com/blog/color-blind-friendly-palette/">How to Use Color Blind Friendly Palettes to Make Your Charts Accessible</a></li>
</ul>

<h3 id="palettes">Palettes</h3>

<ul>
  <li><a href="https://toolness.github.io/accessible-color-matrix/">Accessible color palette builder</a></li>
  <li><a href="https://colorbox.io/">ColorBox</a></li>
  <li><a href="http://colorsafe.co/">Color Safe</a></li>
  <li><a href="https://geenes.app/">Geenes</a></li>
</ul>

<h3 id="color-blindness">Color blindness</h3>

<ul>
  <li><a href="https://www.toptal.com/designers/colorfilter">Colorblind Web Page Filter</a></li>
  <li><a href="https://michelf.ca/projects/sim-daltonism/">Sim Daltonism</a></li>
  <li><a href="https://www.color-blindness.com/coblis-color-blindness-simulator/">Colblindor</a></li>
</ul>

<h3 id="theory-and-practice">Theory and practice</h3>

<ul>
  <li><a href="http://colorisrelative.com/color/">Color is Relative</a></li>
  <li><a href="https://stripe.com/blog/accessible-color-systems">Designing accessible color systems</a></li>
</ul>

<hr>

<h2 id="content">Content</h2>

<ul>
  <li><a href="http://www.hemingwayapp.com/">Hemingway Editor</a></li>
  <li><a href="https://datayze.com/readability-analyzer.php">Readability Analyzer</a></li>
</ul>

<hr>

<h2 id="education">Education</h2>

<h3 id="courses---paid">Courses - Paid</h3>

<ul>
  <li><a href="https://dequeuniversity.com/">Deque University</a></li>
  <li><a href="https://www.levelaccess.com/solutions/training/access-university/">Access University</a></li>
  <li><a href="https://www.paciellogroup.com/products/tpg-tutor/">The Paciello Group ARC TPG Tutor</a></li>
  <li><a href="https://www.udemy.com/topic/web-accessibility/">Udemy Accessibility Courses</a></li>
  <li><a href="https://webaim.org/training/">WebAIM Web Accessibility Training</a></li>
  <li><a href="https://frontendmasters.com/courses/web-accessibility/aria/">FrontendMasters - ARIA</a>, by Jon Kuperman</li>
</ul>

<h3 id="courses---free">Courses - Free</h3>

<ul>
  <li><a href="https://www.linkedin.com/learning/ux-foundations-accessibility/welcome?u=2255073">UX Foundations: Accessibility</a>, by Derek Featherstone</li>
  <li><a href="https://www.linkedin.com/learning/accessibility-for-web-design/welcome?u=2255073">Accessibility for Web Design</a>, by Derek Featherstone</li>
  <li><a href="https://www.udacity.com/course/web-accessibility--ud891">Web Accessibility</a>, by Google</li>
  <li><a href="https://egghead.io/courses/start-building-accessible-web-applications-today">Start Building Accessible Web Applications Today</a>, by Marcy Sutton</li>
  <li><a href="https://www.edx.org/course/web-accessibility-introduction">Introduction to Web Accessibility</a>, by edX</li>
  <li><a href="https://siteimprove.litmos.com/self-signup/register/1039634?type=1">Accessibility Fundamentals for the Web</a>, by Siteimprove</li>
  <li><a href="https://it.rutgers.edu/it-accessibility-initiative/knowledgebase/accessibility-training-workshops/">Accessibility Training &amp; Workshops</a>, by Rutgers</li>
  <li><a href="https://www.coursera.org/learn/accessibility">An Introduction to Accessibility and Inclusive Design</a></li>
</ul>

<h3 id="talks-and-series">Talks and series</h3>

<ul>
  <li><a href="https://www.youtube.com/playlist?list=PLNYkxOF6rcICWx0C9LVWWVqvHlYJyqw7g">A11ycasts</a>, with Rob Dodson</li>
  <li><a href="https://www.youtube.com/watch?v=B9qzdVcIj5U&amp;feature=youtu.be">Debugging Accessibility with Alice Boxhall</a></li>
  <li><a href="https://marcysutton.com/talks/">Marcy Sutton Talks</a></li>
</ul>

<h3 id="guides">Guides</h3>

<ul>
  <li><a href="https://accessibility.digital.gov/">Accessibility for Teams</a></li>
  <li><a href="https://teachaccess.github.io/">Teach Access</a></li>
  <li><a href="https://www.accessibility-developer-guide.com/">Accessibility Developer Guide</a></li>
  <li><a href="https://labs.levelaccess.com/index.php/Main_Page">Level Access Accessible Web Demo wiki</a></li>
</ul>

<hr>

<h2 id="guidelines">Guidelines</h2>

<ul>
  <li><a href="https://www.w3.org/TR/WCAG21/">Web Content Accessibility Guidelines (WCAG) 2.1</a></li>
  <li><a href="https://www.w3.org/TR/wcag-3.0/">W3C Accessibility Guidelines (WCAG) 3.0 (Working Draft)</a></li>
  <li><a href="https://www.w3.org/TR/ATAG20/">Authoring Tool Accessibility Guidelines (ATAG) 2.0</a></li>
  <li><a href="https://www.w3.org/TR/wai-aria-practices-1.1/">WAI-ARIA Authoring Practices 1.1</a></li>
</ul>

<hr>

<h2 id="laws">Laws</h2>

<h3 id="united-states">United States</h3>

<ul>
  <li><a href="https://www.section508.gov/manage/laws-and-policies">Section 508</a></li>
  <li><a href="https://www.ada.gov/2010ADAstandards_index.htm">ADA Standards for Accessible Design</a></li>
  <li><a href="https://www.fcc.gov/consumers/guides/21st-century-communications-and-video-accessibility-act-cvaa">21st Century Communications and Video Accessibility Act (CVAA)</a></li>
</ul>

<h3 id="canada">Canada</h3>

<ul>
  <li><a href="https://www.aoda.ca/">Accessibility for Ontarians with Disabilities Act (AODA)</a></li>
</ul>

<h3 id="europe">Europe</h3>

<ul>
  <li><a href="http://mandate376.standards.eu/standard">Accessibility requirements suitable for public procurement of ICT products and services in Europe</a> - EU</li>
  <li><a href="https://www.legislation.gov.uk/ukpga/2010/15/contents">Equality Act 2010</a> - UK</li>
  <li><a href="https://www.numerique.gouv.fr/publications/rgaa-accessibilite/">Référentiel général d’amélioration de l’accessibilité – RGAA Version 4</a> - France</li>
  <li><a href="http://www.gesetze-im-internet.de/bitv_2_0/index.html">Barrierefreie-Informationstechnik-Verordnung (BITV 2) </a> - Germany</li>
  <li><a href="http://www.irishstatutebook.ie/eli/2005/act/14/enacted/en/html">Disability Act 2005</a> - Ireland</li>
</ul>

<h3 id="other">Other</h3>

<ul>
  <li><a href="https://humanrights.gov.au/our-work/disability-rights/world-wide-web-access-disability-discrimination-act-advisory-notes-ver">World Wide Web Access: Disability Discrimination Act Advisory Notes ver 4.1 (2014)</a> - Australia</li>
  <li><a href="https://web.guidelines.gov.in/">Guidelines for Indian Government Websites</a> - India</li>
  <li><a href="https://www.digital.govt.nz/standards-and-guidance/nz-government-web-standards/">NZ Government Web Standards</a> - New Zealand</li>
  <li><a href="https://www.w3.org/WAI/policies/">Web Accessibility Laws &amp; Policies</a> - Global list of governemtal policies</li>
</ul>

<hr>

<h2 id="live-examples">Live examples</h2>

<ul>
  <li><a href="https://inclusive-components.design/">Inclusive Components</a></li>
  <li><a href="https://nostyle.herokuapp.com/">No Style Design System</a></li>
  <li><a href="https://ebay.gitbook.io/mindpatterns/">eBay MIND Patterns</a></li>
  <li><a href="https://a11y-style-guide.com/style-guide/">A11Y Style Guide</a></li>
</ul>

<hr>



<ul>
  <li><a href="https://www.descript.com/">Descript</a></li>
</ul>

<hr>

<h2 id="screen-readers">Screen readers</h2>

<ul>
  <li><a href="https://dequeuniversity.com/screenreaders/">Screen Reader Keyboard Shortcuts and Gestures</a></li>
</ul>

<hr>

<h2 id="testing">Testing</h2>

<h3 id="companies">Companies</h3>

<ul>
  <li><a href="https://makeitfable.com/">Fable</a></li>
  <li><a href="https://tenon.io/">Tenon</a></li>
</ul>

<h3 id="tools">Tools</h3>

<ul>
  <li><a href="https://wave.webaim.org/extension/">WAVE</a></li>
  <li><a href="https://www.deque.com/axe/">axe</a></li>
  <li><a href="https://squizlabs.github.io/HTML_CodeSniffer/">HTML_CodeSniffer</a></li>
  <li><a href="https://khan.github.io/tota11y/">tota11y</a></li>
  <li><a href="https://www.w3.org/WAI/eval/report-tool/#!/">WCAG-EM Report Tool</a></li>
  <li><a href="https://www.powermapper.com/products/sortsite/">SortSite</a></li>
</ul>

<hr>

<h2 id="who-to-follow">Who to follow</h2>

<ul>
  <li><a href="https://twitter.com/feather">Derek Featherstone</a></li>
  <li><a href="https://twitter.com/marcysutton">Marcy Sutton</a></li>
  <li><a href="https://twitter.com/heydonworks?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor">Heydon Pickering</a></li>
  <li><a href="https://twitter.com/LeonieWatson">Léonie Watson</a></li>
  <li><a href="https://twitter.com/adambsilver">Adam Silver</a></li>
  <li><a href="https://twitter.com/rob_dodson">Rob Dodson</a></li>
  <li><a href="https://twitter.com/sundress">Alice Boxhall</a></li>
  <li><a href="https://twitter.com/atCharlesHall">Charles Hall</a></li>
  <li><a href="https://twitter.com/modulist">Claudio Luís Vera</a></li>
  <li><a href="https://twitter.com/muqueca">Marcelo Paiva</a></li>
  <li><a href="https://twitter.com/mattmay">Matt May</a></li>
</ul>

<hr>

<h2 id="workflow">Workflow</h2>

<ul>
  <li><a href="http://bit.ly/accessibility-toolkit">A Toolkit for Digital Accessibility Requirements</a></li>
  <li><a href="https://www.figma.com/community/file/779827094223635810/Accessibility-bluelines">Accessibility Bluelines annotation tools for content and behavior</a></li>
</ul>

			
		</div></div>]]>
            </description>
            <link>https://jeldergl.gitlab.io/accessibility-cache/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26005384</guid>
            <pubDate>Tue, 02 Feb 2021 19:26:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Chinese Proposal on strengthening education aimed at making boys more masculine]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26005348">thread link</a>) | @fireeyed
<br/>
February 2, 2021 | https://www.globaltimes.cn/page/202101/1214536.shtml | <a href="https://web.archive.org/web/*/https://www.globaltimes.cn/page/202101/1214536.shtml">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          
          <p>Proposal on strengthening education aimed at making boys more 'masculine' triggers debate</p>
          
          
        </div><div>
          <div> <center><img src="https://www.globaltimes.cn/Portals/0/attachment/2018/2018-05-14/9ee69188-9ab3-4185-895a-6ed011f9059c.jpeg"></center>
<p>Students in Foshan, Guangdong Province, play rope skipping after class. File&nbsp;Photo: VCG</p><p>Chinese education authority has recently vowed to enhance physical education and psychological direction in a response to a previous proposal from a top policy advisor calling on the country to strengthen "masculinity" education for boys, which has ignited heated debate on the internet.&nbsp;</p><p>The proposal has won some support, while many on the internet believe it might lead to gender stereotyping. Experts noted that the goals of education should be to train students to be more responsible, and called for a more tolerant and diversified evaluation system for children.</p><p>In a Thursday reply to the proposal on "avoiding feminization of teenage boys," the Chinese Ministry of Education said it will solve the problems from several aspects including enhancing the research on issues related to youth mental health education.</p><p>In May 2020, during the national Two Sessions, Si Zefu, a member of the Standing Committee of the 13th CPPCC National Committee and chairman of Harbin Electric Corporation, said that the "feminization" trend of Chinese teenagers, if not managed effectively, will harm the existence and development of China. "Many Chinese teenage boys nowadays have the characteristics of weakness, low self-esteem and timidity, and they tend to follow the pretty-boy superstars," said Si.&nbsp;</p><p>Si believed this phenomenon could be attributed to the fact that most teachers in schools from kindergarten to high school stage are women, as well as to the frequent appearance of "pretty boys" in TV and films.</p><p>The reply from the Ministry of Education triggered a widespread discussion on the internet over the weekend. The related hashtag has been viewed more than 2 billion times with 250,000 comments as of press time on Sina Weibo.</p><p>Discussions focus on what "masculinity" is and what the boys really need in education.</p><p>"It is a beauty for men to show their toughness in demeanor, spirit, and physique… Education is not only meant to foster 'men' and 'women,' but also duty and responsibility," read a CCTV editorial on Sunday.</p><p>"The anxiety about lack of 'masculinity' is itself a discrimination due to certain kind of mindset. In subconsciousness, such people consider 'female', 'girly' and 'feminine' are bad and each sex should have a certain kind of look in life," noted an editorial on iFeng.com. "Why doesn't the Ministry of Education worry that more physical exercise will make girls too 'masculine?'"</p><p>Sun Yunxiao, an education expert, was quoted by the CNR as saying that while it is true some boys are relatively 'weak,' and the situation calls for attention, people's 'temperaments' are naturally diversified and there is nothing good or bad about it. "We should not attach stereotypes to sexes."</p><p>"Girls could be tough, and boys could be gentle," he said.</p><p>"If masculinity means a boy should not cry, then it is a stereotype," Yu Ka, a primary school teacher in East China's Fujian Province, told the Global Times.</p><p>But Yu also shared his observation that some boys are not as tough as many girls among her students. "I feel boys are too spoiled by families and the society," Yu said, pointing to the traditional mindset of valuing boys.</p><p>Chu Zhaohui, a research fellow at China's National Institute of Education Sciences, called for a diversified evaluation system. "Currently, evaluation is based on scores to a large extent. Even if boys perform well in areas other than learning, they won't get much appreciation. For many boys, they cannot do what they want to do, which is not conducive to cultivating independence, courage and perseverance," Chu told the Global Times.</p><p>"Masculinity means having a relatively strong sense of independence, willpower and perseverance, including physical fitness," Chu said.</p><p>"We should leave it to the nature of the person. We have destroyed the natural state of students and what we need to do now is to correct it and let them return to normal and be more natural," Chu said.</p></div>
        </div></div>]]>
            </description>
            <link>https://www.globaltimes.cn/page/202101/1214536.shtml</link>
            <guid isPermaLink="false">hacker-news-small-sites-26005348</guid>
            <pubDate>Tue, 02 Feb 2021 19:23:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bad TypeScript Habits]]>
            </title>
            <description>
<![CDATA[
Score 221 | Comments 215 (<a href="https://news.ycombinator.com/item?id=26005330">thread link</a>) | @jgwil2
<br/>
February 2, 2021 | https://startup-cto.net/10-bad-typescript-habits-to-break-this-year/ | <a href="https://web.archive.org/web/*/https://startup-cto.net/10-bad-typescript-habits-to-break-this-year/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
            <!--kg-card-begin: markdown--><p>TypeScript and JavaScript have steadily evolved over the last years, and some of the habits we built over the last decades have become obsolete. Some might never have been meaningful. Here's a list of 10 habits that we all should break.</p>
<p>If you are interested in more articles and news about web product development and entrepreneurship, please feel free to <a href="https://twitter.com/intent/follow?original_referer=https%253A%252F%252Fstartup-cto.net%252F&amp;ref_src=twsrc%5Etfw&amp;region=follow_link&amp;screen_name=The_Startup_CTO&amp;tw_p=followbutton">follow me on Twitter</a>.</p>
<p>Onto the examples! Please note that each "What it should look like" only fixes the issue discussed, even if there are further code smells that should be addressed.</p>
<h2 id="1notusingstrictmode">1. Not using <code>strict</code> mode</h2>
<h3 id="whatitlookslike">What it looks like</h3>
<p>Using a <code>tsconfig.json</code> without strict mode.</p>
<pre><code>{
  "compilerOptions": {
    "target": "ES2015",
    "module": "commonjs"
  }
}
</code></pre>
<h3 id="whatitshouldlooklike">What it should look like</h3>
<p>Just enable <code>strict</code> mode:</p>
<pre><code>{
  "compilerOptions": {
    "target": "ES2015",
    "module": "commonjs",
    "strict": true
  }
}
</code></pre>
<h3 id="whywedoit">Why we do it</h3>
<p>Introducing stricter rules in an existing codebase takes time.</p>
<h3 id="whyweshouldnt">Why we shouldn't</h3>
<p>Stricter rules will make it easier to change code in the future, so the time spent on fixing the code is returned and then some when working on the repository in the future.</p>
<h2 id="2definingdefaultvalueswith">2. Defining default values with <code>||</code></h2>
<h3 id="whatitlookslike">What it looks like</h3>
<p>Falling back with <code>||</code> for optional values:</p>
<pre><code>function createBlogPost (text: string, author: string, date?: Date) {
  return {
    text: text,
    author: author,
    date: date || new Date()
  }
}
</code></pre>
<h3 id="whatitshouldlooklike">What it should look like</h3>
<p>Use the new <code>??</code> operator, or, even better, define the fallback right at the parameter level.</p>
<pre><code>function createBlogPost (text: string, author: string, date: Date = new Date())
  return {
    text: text,
    author: author,
    date: date
  }
}
</code></pre>
<h3 id="whywedoit">Why we do it</h3>
<p>The <code>??</code> operator has just been introduced last year, and when using values in the middle of a long function it might be hard to set them already as parameter defaults.</p>
<h3 id="whyweshouldnt">Why we shouldn't</h3>
<p><code>??</code>, unlike <code>||</code>, falls back only for <code>null</code> or <code>undefined</code>, not for all falsy values. Also, if your functions are so long that you cannot define defaults at the beginning, then splitting them might be a good idea.</p>
<h2 id="3usinganyastype">3. Using <code>any</code> as type</h2>
<h3 id="whatitlookslike">What it looks like</h3>
<p>Using <code>any</code> for data when you are unsure about the structure.</p>
<pre><code>async function loadProducts(): Promise&lt;Product[]&gt; {
  const response = await fetch('https://api.mysite.com/products')
  const products: any = await response.json()
  return products
}
</code></pre>
<h3 id="whatitshouldlooklike">What it should look like</h3>
<p>In almost every situation where you type something as <code>any</code>, you should type it as <code>unknown</code> instead.</p>
<pre><code>async function loadProducts(): Promise&lt;Product[]&gt; {
  const response = await fetch('https://api.mysite.com/products')
  const products: unknown = await response.json()
  return products as Product[]
}
</code></pre>
<h3 id="whywedoit">Why we do it</h3>
<p><code>any</code> is convenient, as it basically disables all type-checks. Often, <code>any</code> is used even in official typings (e. g. <code>response.json()</code> from the example above is typed as <code>Promise&lt;any&gt;</code> by the TypeScript team).</p>
<h3 id="whyweshouldnt">Why we shouldn't</h3>
<p>It basically disables all type-checks. Anything that comes in via <code>any</code> will completely forego any type-checks. This leads to hard to catch bugs, as code will fail only when our assumptions about type structure are relevant to the runtime code.</p>
<h2 id="4valassometype">4. <code>val as SomeType</code></h2>
<h3 id="whatitlookslike">What it looks like</h3>
<p>Forcefully telling the compiler about a type that it cannot infer.</p>
<pre><code>async function loadProducts(): Promise&lt;Product[]&gt; {
  const response = await fetch('https://api.mysite.com/products')
  const products: unknown = await response.json()
  return products as Product[]
}
</code></pre>
<h3 id="whatitshouldlooklike">What it should look like</h3>
<p>That's what type guards are for.</p>
<pre><code>function isArrayOfProducts (obj: unknown): obj is Product[] {
  return Array.isArray(obj) &amp;&amp; obj.every(isProduct)
}

function isProduct (obj: unknown): obj is Product {
  return obj != null
    &amp;&amp; typeof (obj as Product).id === 'string'
}

async function loadProducts(): Promise&lt;Product[]&gt; {
  const response = await fetch('https://api.mysite.com/products')
  const products: unknown = await response.json()
  if (!isArrayOfProducts(products)) {
    throw new TypeError('Received malformed products API response')
  }
  return products
}
</code></pre>
<h3 id="whywedoit">Why we do it</h3>
<p>When converting from JavaScript to TypeScript, the existing codebase often makes assumptions about types that cannot be deduced automatically by the TypeScript compiler. In these cases, throwing in a quick <code>as SomeOtherType</code> can speed up the conversion without having to loosen the settings in tsconfig.</p>
<h3 id="whyweshouldnt">Why we shouldn't</h3>
<p>Even if the assertion might be save right now, this might change when someone moves code around. The type guard will ensure that all checks are explicit.</p>
<h2 id="5asanyintests">5. <code>as any</code> in tests</h2>
<h3 id="whatitlookslike">What it looks like</h3>
<p>Creating incomplete stand-ins when writing tests.</p>
<pre><code>interface User {
  id: string
  firstName: string
  lastName: string
  email: string
}

test('createEmailText returns text that greats the user by first name', () =&gt; {
  const user: User = {
    firstName: 'John'
  } as any
  
  expect(createEmailText(user)).toContain(user.firstName)
}
</code></pre>
<h3 id="whatitshouldlooklike">What it should look like</h3>
<p>If you need to mock data for your tests, move the mocking logic next to the thing you mock and make it reusable.</p>
<pre><code>interface User {
  id: string
  firstName: string
  lastName: string
  email: string
}

class MockUser implements User {
  id = 'id'
  firstName = 'John'
  lastName = 'Doe'
  email = 'john@doe.com'
}

test('createEmailText returns text that greats the user by first name', () =&gt; {
  const user = new MockUser()

  expect(createEmailText(user)).toContain(user.firstName)
}
</code></pre>
<h3 id="whywedoit">Why we do it</h3>
<p>When writing tests in a codebase that doesn't have great test coverage yet, there are often complicated big data structures, but only parts of it are needed for the specific functionality under test. Not having to worry about the other properties is easier in the short term.</p>
<h3 id="whyweshouldnt">Why we shouldn't</h3>
<p>Foregoing the creation of a mock will bite us, latest when one of the properties changes and we need to change it in all tests instead of one central location. Also, there will be situations where the code under test relies on properties that we did not deem important before, and then all tests for that functionality need to be updated.</p>
<h2 id="6optionalproperties">6. Optional properties</h2>
<h3 id="whatitlookslike">What it looks like</h3>
<p>Marking properties as optional that are sometimes there and sometimes not.</p>
<pre><code>interface Product {
  id: string
  type: 'digital' | 'physical'
  weightInKg?: number
  sizeInMb?: number
}
</code></pre>
<h3 id="whatitshouldlooklike">What it should look like</h3>
<p>Explicitly model which combinations exist and which don't.</p>
<pre><code>interface Product {
  id: string
  type: 'digital' | 'physical'
}

interface DigitalProduct extends Product {
  type: 'digital'
  sizeInMb: number
}

interface PhysicalProduct extends Product {
  type: 'physical'
  weightInKg: number
}
</code></pre>
<h3 id="whywedoit">Why we do it</h3>
<p>Marking properties as optional instead of splitting out types is easier and produces less code. It also requires a deeper understanding of the product being build and might limit usage of code if assumptions about the product change.</p>
<h3 id="whyweshouldnt">Why we shouldn't</h3>
<p>The big benefit of type systems is that they can replace runtime checks with compile-time checks. With more explicit typing, it is possible to get compile-time checks for bugs that otherwise might have gotten unnoticed, e. g. by making sure that every <code>DigitalProduct</code> has a <code>sizeInMb</code>.</p>
<h2 id="7onelettergenerics">7. One letter generics</h2>
<h3 id="whatitlookslike">What it looks like</h3>
<p>Naming a generic with one letter</p>
<pre><code>function head&lt;T&gt; (arr: T[]): T | undefined {
  return arr[0]
}
</code></pre>
<h3 id="whatitshouldlooklike">What it should look like</h3>
<p>Giving a full descriptive type name.</p>
<pre><code>function head&lt;Element&gt; (arr: Element[]): Element | undefined {
  return arr[0]
}
</code></pre>
<h3 id="whywedoit">Why we do it</h3>
<p>This habit grew I guess because <a href="https://www.typescriptlang.org/docs/handbook/generics.html">even the official docs use one-letter names</a>. It is also quicker to type and requires less thinking to press <code>T</code> instead of writing a full name.</p>
<h3 id="whyweshouldnt">Why we shouldn't</h3>
<p>Generic type variables are variables, like any other. We have abandoned the idea of describing the technicalities of variables in their names when IDEs started to just show us these technicalities. E. g. instead of <code>const strName = 'Daniel'</code> we now only write <code>const name = 'Daniel'</code>. Also, one letter variable names are generally frowned upon because it can be hard to decipher what they mean without looking at their declaration.</p>
<h2 id="8nonbooleanbooleanchecks">8. Non-boolean boolean checks</h2>
<h3 id="whatitlookslike">What it looks like</h3>
<p>Checking whether a value is defined by passing the value directly to an <code>if</code> statement.</p>
<pre><code>function createNewMessagesResponse (countOfNewMessages?: number) {
  if (countOfNewMessages) {
    return `You have ${countOfNewMessages} new messages`
  }
  return 'Error: Could not retrieve number of new messages'
}
</code></pre>
<h3 id="whatitshouldlooklike">What it should look like</h3>
<p>Explicitly checking for the condition we care about.</p>
<pre><code>function createNewMessagesResponse (countOfNewMessages?: number) {
  if (countOfNewMessages !== undefined) {
    return `You have ${countOfNewMessages} new messages`
  }
  return 'Error: Could not retrieve number of new messages'
}
</code></pre>
<h3 id="whywedoit">Why we do it</h3>
<p>Writing the check in short looks more succinct and allows us to avoid thinking about what we actually want to check.</p>
<h3 id="whyweshouldnt">Why we shouldn't</h3>
<p>Maybe we should think about what we actually want to check. The examples above for example handle the case of <code>countOfNewMessages</code> being <code>0</code> differently.</p>
<h2 id="9thebangbangoperator">9. The Bang Bang operator</h2>
<h3 id="whatitlookslike">What it looks like</h3>
<p>Converting a non-boolean value to boolean.</p>
<pre><code>function createNewMessagesResponse (countOfNewMessages?: number) {
  if (!!countOfNewMessages) {
    return `You have ${countOfNewMessages} new messages`
  }
  return 'Error: Could not retrieve number of new messages'
}
</code></pre>
<h3 id="whatitshouldlooklike">What it should look like</h3>
<p>Explicitly checking for the condition we care about.</p>
<pre><code>function createNewMessagesResponse (countOfNewMessages?: number) {
  if (countOfNewMessages !== undefined) {
    return `You have ${countOfNewMessages} new messages`
  }
  return 'Error: Could not retrieve number of new messages'
}
</code></pre>
<h3 id="whywedoit">Why we do it</h3>
<p>To some, understanding <code>!!</code> is like an initiation ritual to the world of JavaScript. It looks short and succinct, and if you are already used to it, then you know what it is about. It is a shortcut to convert any value to a boolean. Especially if, in a codebase, there is no clear semantic separation between falsy values like <code>nu…</code></p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://startup-cto.net/10-bad-typescript-habits-to-break-this-year/">https://startup-cto.net/10-bad-typescript-habits-to-break-this-year/</a></em></p>]]>
            </description>
            <link>https://startup-cto.net/10-bad-typescript-habits-to-break-this-year/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26005330</guid>
            <pubDate>Tue, 02 Feb 2021 19:22:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Insiders' Game]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26005319">thread link</a>) | @herbertl
<br/>
February 2, 2021 | https://www.persuasion.community/p/the-insiders-game | <a href="https://web.archive.org/web/*/https://www.persuasion.community/p/the-insiders-game">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F6c98bd4d-f535-47c1-bd99-7597dd862ac8_6016x4016.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F6c98bd4d-f535-47c1-bd99-7597dd862ac8_6016x4016.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/6c98bd4d-f535-47c1-bd99-7597dd862ac8_6016x4016.jpeg&quot;,&quot;height&quot;:972,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:17806698,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>As the apex predators of capitalism, hedge funds are accustomed to raking in billions by driving companies into the ground and feasting on the carcasses. So there was widespread satisfaction last week when members of an online discussion group called WallStreetBets started beating the Wall Street bully boys at their own game. Ringleaders of the group noticed that hedge funds had taken a short position in the videogame retailer GameStop that <a href="https://www.reddit.com/r/wallstreetbets/comments/ip6jnv/the_real_greatest_short_burn_of_the_century/?utm_source=share&amp;utm_medium=ios_app&amp;utm_name=iossmf">far exceeded</a> the number of shares available to trade. Motivated as much by <a href="https://www.reddit.com/r/wallstreetbets/comments/l6omry/an_open_letter_to_melvin_capital_cnbc_boomers_and/">revenge</a> as by profit, these influencers in the group encouraged the 2.7 million members (since risen to around 8 million) to purchase the stock in order to drive the price higher and create a massive short squeeze. This quickly became a movement with a cause similar to that of Occupy Wall Street, except much more effective because it hit the intended target where they would feel it the most, in the wallet. “The only way to beat a rigged game,” one WallStreetBets leader <a href="https://www.reddit.com/r/wallstreetbets/comments/ip6jnv/the_real_greatest_short_burn_of_the_century/?utm_source=share&amp;utm_medium=ios_app&amp;utm_name=iossmf">said</a>, “is to rig it even harder.”&nbsp;</p><p>GameStop stock, which closed at $17.69 a share on Jan. 8, shot up to $347.51 by the close last Wednesday. With combined losses of almost $20 billion, hedge funds were on the ropes and close to bleeding out, selling their longs in an increasingly futile effort to cover their shorts. One fund, Melvin Capital, <a href="https://www.cnbc.com/2021/01/31/melvin-capital-lost-more-than-50percent-after-betting-against-gamestop-wsj.html">lost over half its value</a> and had to be bailed out by <a href="https://markets.businessinsider.com/news/stocks/steve-cohen-ken-griffin-invest-3-billion-gamestop-short-seller-2021-1-1030003305">hedge fund sugar daddies</a> Ken Griffin (Citadel) and Steve Cohen (Point 72). Another fund, Citron, was teetering on the brink of collapse. All this outsider army needed to win was the continued ability to communicate with each other online, and their collective ability to keep piling into the “Buy” side of the trade. Within hours, they would be hobbled on the first front and crippled on the second.&nbsp;</p><p><strong>The Empire Strikes Back</strong></p><p>First, the digital distribution platform Discord <a href="https://www.theverge.com/2021/1/27/22253251/discord-bans-the-r-wallstreetbets-server">banned</a> the WallStreetBets account after the close Wednesday for “<a href="https://www.businessinsider.com/discord-bans-wallstreetbets-server-hate-speech-reddit-gamestop-gme-2021-1">hate speech, glorifying violence, and spreading misinformation</a>.” (For a moment, it looked like <a href="https://www.reddit.com/r/StockMarket/comments/l6i26r/discord_and_reddit_remove_rwallstreetbets/">Reddit had also banned </a>the group, but they resisted pressure to do so.) If the quoted justification sounds familiar, it’s nearly identical to the one given by Google, Apple, and Amazon for deplatforming Parler just three weeks earlier. Echoing Amazon, Discord said it had sent the group repeated warnings about objectionable content before deciding, on that day of all days, to shut them down.&nbsp;</p><p>Meanwhile, WallStreetBets investors were locked out of their trading accounts by online brokers such as Robinhood on Thursday morning. Based on new collateral requirements that it says were imposed by an industry consortium, Robinhood forbade its users from buying GameStop and other stocks that WallStreetBets had identified as short squeeze opportunities. Users were allowed only to “close their positions”—in other words, to sell to the shorts desperate to buy. When angry users registered their disapproval by leaving over 100,000 one-star reviews of the Robinhood app in the Google Play Store, Google <a href="https://www.theverge.com/2021/1/28/22255245/google-deleting-bad-robinhood-reviews-play-store">deleted</a> them.&nbsp;</p><p>Normal trading was allowed to resume Friday, but the hedge funds used their 24-hour sole ownership of the battlefield to fortify their positions, covering the most vulnerable shorts. Wall Street then sent in reinforcements, as new short positions were taken at these high price levels, virtually guaranteed to pay out when, inevitably, the air leaks out of the balloon. Faced with a game that, for once, they couldn’t rig in their favor, it appeared that the insiders tipped the board over and started a new game. As a massively decentralized online group of scrappy outsiders, the only tools at WallStreetBets’ disposal were online trading and social networking. Both were frozen at the crucial moment, and the hedge fund insiders were let off the hook. The weaponization of censorship is a big part of the reason why.&nbsp;</p><p><strong>Down the Slippery Slope</strong></p><p>Some of us <a href="https://davidsacks.medium.com/the-speech-cartel-b3f5555f7787">warned</a> of a slippery slope when Parler was taken down and a sitting president was systematically ghosted from every online speech platform. But we could not have foreseen how slippery the slope would be, or how fast we would slide down it. We were told that the curbs on speech of President Trump and his supporters were necessary to prevent further “insurrection” and protect the peaceful transition of power. However, much like the troops and barricades that still ring the Capitol, these speech restrictions remain in place well after the transition of power has occurred. The censorship power is always justified in response to a genuine outrage or crisis, but it is rarely relinquished once the threat passes. Rather it gets weaponized to protect powerful, connected insiders, as the GameStop fiasco illustrates.</p><p>How do we suppose Discord chose that moment to enforce its “Community Guidelines” against WallStreetBets? Almost certainly, one of the hedge funds whose ox was being gored combed through their message boards looking for anything that might violate the terms of service. And surely they found it, as these boards contain the same raunchy language you would hear if you visited any trading floor or boiler room on Wall Street. They presumably reported the content to Discord, which took the group down.&nbsp;</p><p>Did Discord warn WallStreetBets of content violations before last Wednesday? I’m sure they did. Amazon <a href="https://www.geekwire.com/2021/amazon-responds-parlers-lawsuit-calls-meritless-cites-content-advocating-violence/">sent</a> such a warning letter to Parler as well. Frankly, such a letter could be, and likely is, sent to every large message board on the web. The founder of a user-generated content site described it to me as “the One Percent Problem.” Every user-generated content site will have a small percentage of offensive material that gets through, no matter how many content moderators are hired. For example, Facebook, Twitter, and YouTube <a href="https://www.vox.com/recode/22221285/trump-online-capitol-riot-far-right-parler-twitter-facebook">allowed far more content</a> advocating for and planning the Capitol riot than Parler. But instead of acknowledging this, they were eager to <a href="https://www.washingtonpost.com/technology/2021/01/13/facebook-role-in-capitol-protest/">blame</a> the upstart, which had recently taken over the top spot in the social networking category in the app store. Scapegoating Parler served the dual purpose of deflecting blame and squashing a competitor.</p><p>Critics of social networks insist that these sites simply need to double down on censorship in order to finally rid us of problematic speech. But that ignores how social media moderation actually works. Algorithms set to recognize keywords capture only a small fraction of problematic posts, leaving millions of posts for humans to review. The work is so voluminous that it’s outsourced to far-flung locales where English may not even be the first language. Low-level employees must decipher complicated guidelines while navigating our increasingly Byzantine world of political and cultural hot-buttons. Mistakes are inevitable, and the harder a company tightens the standards to get the One Percent Problem down to 0.1 or 0.01 percent, the more undeserving accounts—from <a href="https://www.newsweek.com/ron-paul-blocked-accessing-facebook-page-over-violating-community-standards-1560639">Ron Paul</a> to the <a href="https://www.wsws.org/en/articles/2021/01/23/pers-j23.html">Socialist Equality Party</a>—will be swept up in the dragnet. With the Town Square now digitized, centralized, and privatized in the hands of a cartel of Big Tech companies, the protections of the First Amendment no longer apply.&nbsp;</p><p><strong>Insiders Vs. Outsiders</strong></p><p>Censorship is about who has the power to censor, and what checks are placed upon that power. Right now, tech companies have all the power, and they exercise it as a like-minded cartel. When we see Alexandria Ocasio-Cortez and Ted Cruz voice similar concerns over what happened to WallStreetBets last week, we should realize that the politics of this issue in the post-Trump era will no longer divide along an axis of Left and Right, but of insider and outsider.&nbsp;</p><p>Elizabeth Warren, when she started landing blows against Wall Street after the 2008 financial crisis, met with President Obama’s economics adviser, the former treasury secretary and Harvard president Larry Summers. He presented her with a choice: “I could be an insider or I could be an outsider,” she recalled in her 2014 memoir, <em>A Fighting Chance</em>. “Outsiders can say whatever they want. But people on the inside don’t listen to them. Insiders, however, get lots of access and a chance to push their ideas. People—powerful people—listen to what they have to say. But insiders also understand one unbreakable rule: <em>They don’t criticize other insiders</em>.”&nbsp;&nbsp;</p><p>It’s precisely this insider-protection scheme that the internet and social media have most disrupted. Insiders are massively powerful but few in number. Outsiders have always been numerous but unorganized. Social networking and online organizing have given the outsiders real power to effect change, and finally register their disgust at the way incompetent elites protect each other. The elites of Big Business, Big Media, Wall Street, and Washington are terrified of this, and will leverage any censorship power to keep the outsiders at bay.&nbsp;</p><p><strong>The Real “Big Lie”</strong></p><p>After the storming of the Capitol building on Jan. 6, we heard a lot about the “Big Lie” perpetrated by Trump and his allies that the election was “stolen.” In reality, this narrative never got far. It was rejected by the media (including Fox News), thrown out by the courts, labeled by social networks as “disputed,” and dismissed by politicians, including Trump’s own vice president. Yes, some far-right groups like the Proud Boys and Oath Keepers came to Washington to commit acts of violence, but they were roundly denounced. For a Big Lie to be successful, it has to have buy-in from the people in power, moneyed interests, the narrative-framers in the media generally, all of whom have to benefit from the lie and therefore repeat it.&nbsp;</p><p>But what issue could possibly unite all of these constituencies? For several years, elites in the media, government, and now finance have denounced social media as a tool for propaganda, disinformation and hate. Social media was to blame for the Russian disinformation that supposedly elected Trump in 2016. Social media was fingered as the main culprit in an “insurrection” that attempted to overthrow an election. And now, WallStreetBets is accused …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.persuasion.community/p/the-insiders-game">https://www.persuasion.community/p/the-insiders-game</a></em></p>]]>
            </description>
            <link>https://www.persuasion.community/p/the-insiders-game</link>
            <guid isPermaLink="false">hacker-news-small-sites-26005319</guid>
            <pubDate>Tue, 02 Feb 2021 19:21:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[There Is Beauty in Simplicity]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26005291">thread link</a>) | @Bluestein
<br/>
February 2, 2021 | https://readir.net/blog/#there-is-beauty-in-simplicity | <a href="https://web.archive.org/web/*/https://readir.net/blog/#there-is-beauty-in-simplicity">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://readir.net/blog/#there-is-beauty-in-simplicity</link>
            <guid isPermaLink="false">hacker-news-small-sites-26005291</guid>
            <pubDate>Tue, 02 Feb 2021 19:19:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[This is the Future. and It Sucks]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 14 (<a href="https://news.ycombinator.com/item?id=26005270">thread link</a>) | @MaurizioPz
<br/>
February 2, 2021 | https://open.lbry.com/@Lunduke:e/TheFutureSucks:b?r=333G8YicUkjwx3FXtVfrCosJ3K4HCNW6 | <a href="https://web.archive.org/web/*/https://open.lbry.com/@Lunduke:e/TheFutureSucks:b?r=333G8YicUkjwx3FXtVfrCosJ3K4HCNW6">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://open.lbry.com/@Lunduke:e/TheFutureSucks:b?r=333G8YicUkjwx3FXtVfrCosJ3K4HCNW6</link>
            <guid isPermaLink="false">hacker-news-small-sites-26005270</guid>
            <pubDate>Tue, 02 Feb 2021 19:17:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Is Cardano?]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 6 (<a href="https://news.ycombinator.com/item?id=26005048">thread link</a>) | @richardfsr
<br/>
February 2, 2021 | https://readir.net/blog/#what-is-cardano | <a href="https://web.archive.org/web/*/https://readir.net/blog/#what-is-cardano">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://readir.net/blog/#what-is-cardano</link>
            <guid isPermaLink="false">hacker-news-small-sites-26005048</guid>
            <pubDate>Tue, 02 Feb 2021 18:59:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Helm never felt like it belonged]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26004997">thread link</a>) | @lukadante3
<br/>
February 2, 2021 | https://littlechimera.com/posts/helm-design/ | <a href="https://web.archive.org/web/*/https://littlechimera.com/posts/helm-design/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
            

            <p>Kubernetes is one the largest and fastest growing open-source projects. Since its inception in 2014, Kubernetes received tens of thousands of contributions from the community, and enhanced by plethora of new tools. But that doesn’t come without its downsides. Namely, every now and then, there’s a tool that doesn’t adhere to Kubernetes core principles, and I think one such tool is <em>Helm</em>.</p>

<p>I have tried for so long to understand why Kubernetes community chooses Helm over the other tools, especially given my experience with a tool that has some similar features to it (as you’ll see later). To finally get some insight, I decided to write this blog post to learn more about Helm and its community.</p>

<p>If you search on Google for Kubernetes principles, you are unlikely to find <a href="https://github.com/kubernetes/community/blob/master/contributors/design-proposals/architecture/principles.md">this document</a>. While the principles outlined are very succinct, most of Kubernetes developers could probably talk about each of these ideas at length. One such <a href="https://www.youtube.com/watch?v=ZuIQurh_kDk">talk</a>, although probably not exhaustive, comes from <a href="https://github.com/saad-ali">Saad Ali</a> at KubeCon. If you’re not deeply familiar with Kubernetes, I highly suggest to give it a listen before you read the rest of the text. Now without delaying any further, here are the principles mentioned in the talk, and why I think Helm breaks <em>some</em> of these principles<em>.</em></p>

<h2 id="principles">Principles</h2>

<ul>
<li>Kubernetes APIs are declarative rather than imperative.</li>
<li>The Kubernetes control plane is transparent. There are no hidden internal APIs.</li>
<li>Meet the user where they are.</li>
<li>Workload portability.</li>
</ul>



<p>One of the very first examples mentioned in the talk is about the downsides of client-side. Many of the same problems presented for scripting on the cluster is introduced by Helm as well. What if your machine dies? What if you lose connection? What if your colleague runs the same command at the same time? But also, what if you run a wrong version of Helm? The answer is - you’re possibly going to be in an inconsistent state between two versions. The underlying cause of it is that Helm workflow is imperative, and not declarative. As opposed to using kubectl + Kustomize, for example, whose joint job is to declare the new state of the Kubernetes cluster, Helm can be used to manage the lifecycle of the objects, and apply them in certain order - most notably with hooks.</p>

<p>When I mentioned lifecycle, I immediately thought of only one thing - Kubernetes control plane. As you’ll see in the related talk, it’s quite clear that only lifecycle managers should be <em>controllers</em>, and they should run inside the cluster itself. Strong push for server-side is most evident in recently introduced <a href="https://kubernetes.io/docs/reference/using-api/server-side-apply/">Server Side Apply (SSA)</a>, which is trying to fix some of the issues with kubectl by removing one of the last pieces of code that are running client-side.</p>



<p>One of my favourite features of Kubernetes is its transparency. Everything goes through a single endpoint, and everything is available to all parties (with right access permissions). This means that I can start using new piece of software for Kubernetes and inspect what it’s doing to the cluster. That’s why when I think about working with Kubernetes, I mostly think about using kubectl.</p>

<p>With Helm, this is rather different. It is actively trying to hide what it’s doing by providing abstractions between you and the actual state of the cluster. This comes in two forms - CLI and Charts. The former creates new concepts of working with the cluster, that are not consistent with declarative intent of Kubernetes project. Instead of declaring the state of the cluster, it introduces additional <em>commands</em> to describe <em>how</em> to get to desired state of the cluster, also further violating the first principle. More importantly, both hide the information about what Kubernetes objects are being changed on the cluster. Charts especially encourage users to ignore underlying Kubernetes objects by providing additional parameterization abstraction over them. This inevitably ends up being restrictive for end users who want to change fields that are not parametrized by Helm and thus cannot be changed without creating your own copy of the Chart.</p>



<p>One of the early problems of Kubernetes was that its API was pretty verbose and static. Since Kubernetes didn’t meet users with any solution at that time, it prompted many of them (including me) to try something different other than using pure kubectl &amp; YAML. Roughly four years ago, at the time when I was first faced with this problem, I was just at the start of my journey with Ansible. Having not too much experience with Kubernetes, and seeing how much Ansible is flexible and given that it already had the support for interfacing with Kubernetes, I decided to give Ansible and its Jinja templating a try. Things didn’t work out so great.</p>

<p>A year later, I learned about Helm which aimed to solve this same (and more). The trouble is, to me it looked exactly like Jinja. It used a similar structure-unaware templating engine to generate structured data. Most notably, the engine is partially unaware of indents needed to create YAML structures. So, in order to make generated document properly indented, you need to resort to ugly hacks like <a href="https://github.com/helm/charts/blob/d792245e710ef759578bbbe956ec1e01efc27af4/stable/airflow/templates/webserver/webserver-deployment.yaml#L193">explicitly specifying number of indents</a> or <a href="https://github.com/helm/charts/blob/d792245e710ef759578bbbe956ec1e01efc27af4/stable/airflow/templates/webserver/webserver-deployment.yaml#L220">prefixing blocks with whitespace truncation</a>. And this really felt like trying to put Legos together with glue, all the while being blindfolded. Since then, Helm was supposed to get Lua support which would address the drawbacks of using a general purpose templating engine, but it hasn’t happened yet. Even if it did at some point, bringing Lua as addition only, without deprecating the current templating engine, won’t solve the original problem.</p>

<p>Everything about Helm seems to me like an “obvious solution” (as Saad Ali put it) to the problem of deploying workloads on Kubernetes. Just like my first approach, it gave <em>an</em> answer to “What” to do about this problem, but not the “Why” it’s done that way. The currently used Go templating engine, used to generate Helm manifests, could’ve easily been Jinja, if the project was started in Python. Or even simpler, it could’ve been Python itself with no extra libraries to generate structured YAML outputs from dicts.</p>

<p>Nowadays, there seems to be much better tools for composing pieces of structured data. <a href="https://kustomize.io/">Kustomize</a>, <a href="https://jsonnet.org/">jsonnet</a>, <a href="https://cuelang.org/">CUE</a>, <a href="https://carvel.dev/ytt/">ytt</a>, <a href="https://dhall-lang.org/">Dhall</a> are just some of the tools that are simply better fitted for the job. Similar goes for managing the lifecycle of the applications. Kubernetes, for example, has built-in controllers for managing deployments and statefulsets. These might not fit your use-case, and you certainly don’t have to agree with how they are implemented, but you’re entirely free to build your own <a href="https://book.kubebuilder.io/">controller</a>/<a href="https://sdk.operatorframework.io/docs/building-operators/">operator</a> to manage lifecycle of your apps in a different way. However, Helm has chosen to stay client side. Something that’s increasingly moved away from, and most obvious with the addition of SSA.</p>

<h2 id="meeting-long-time-kubernetes-users-the-other-way">Meeting long-time Kubernetes users the other way</h2>

<p>On a similar topic, whilst Kubernetes tried its best to build the tools in place to make the new users feel welcome, Helm did not seem to bother trying to apply the same principle for existing Kubernetes users. I previously mentioned how Helm binary is trying to replace kubectl. As a long time Kubernetes user and operator, I really (and I mean <em>reallyyyyyy…</em>) have gotten used to be able to view transparent APIs through the single lens of kubectl to debug and solve issues. Helm instead takes this power away from you, and fragments the ecosystem.</p>



<p>To get a sense whether the Helm project is at least going in the right direction of correcting some of the design flaws I mentioned above, I looked at some of the new features they’re adding. Two of them are chart values validation, and a post renderer. While you might argue that both of these features are very useful (and I wouldn’t dare to deny that), both of them seem to be breaking either the Kubernetes design or engineering principles.</p>

<h2 id="post-renderer">Post-renderer</h2>

<p>The post-renderer comes as a solution to the problem that Helm itself introduced. Helm charts that are published are not fully customisable by the users. This is because Helm broke one of the key ideas of Kubernetes and decided to hide and abstract Kubernetes objects away from the users. To solve this issue, the Helm project introduced <a href="https://helm.sh/docs/topics/advanced/#post-rendering">post-rendering feature</a>. While I was initially excited about the idea of Helm embracing configuration engines other than Go templating (such as Kustomize, which is explicitly mentioned in the docs), the feature still doesn’t fully adhere to some of the same core ideas of the Kubernetes project. Specifically speaking, post-rendering is not a declarative feature. You cannot specify in code that a post-render must be used to install a particular Helm chart. Rather, it relies on manually specifying the correct flag on issuing the helm command, and thus breaks declarative intent of configuration management.</p>

<p>​​It’s even more important to note that this feature goes directly against the core idea of Helm - abstraction. If you want to use post-rendering, you probably need to be intimately familiar with the templates of the upstream Chart. Even though such move is welcome to a certain extent, Helm design clearly continues to prioritize abstraction over transparent APIs and additionally introduces some very puzzling and contradictory design.</p>

<h2 id="chart-values-validation">Chart values validation</h2>

<p>One of the most prominent features of Helm Charts is the ability to abstract away configuration of Kubernetes objects and instead give the user the ability to provide high-level settings they would like to set for their installation of the particular Chart. These high-level settings are configured in the shape of a free-form YAML document. Unfortunately, free-form YAML is not exactly best suited for providing parameters with predefined structure. If you want to change anything about your deployment, the usual way to do so is to look up the default values (present in the Helm Chart), and then specify overrides for what you want to change. But default values are not …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://littlechimera.com/posts/helm-design/">https://littlechimera.com/posts/helm-design/</a></em></p>]]>
            </description>
            <link>https://littlechimera.com/posts/helm-design/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26004997</guid>
            <pubDate>Tue, 02 Feb 2021 18:54:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The completed reproduction Altair 8800 Kit Computer]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26004994">thread link</a>) | @Bluestein
<br/>
February 2, 2021 | http://www.altairkit.com/diffcompare.html | <a href="https://web.archive.org/web/*/http://www.altairkit.com/diffcompare.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.altairkit.com/diffcompare.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26004994</guid>
            <pubDate>Tue, 02 Feb 2021 18:54:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: All-in-one platform to invent, build and grow products]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26004936">thread link</a>) | @tablet
<br/>
February 2, 2021 | https://fibery.io/product-management | <a href="https://web.archive.org/web/*/https://fibery.io/product-management">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<!-- Google Tag Manager (noscript) -->

<!-- End Google Tag Manager (noscript) -->

<section>

    

    <article>
        

        <p>
            While growing ours, ha-ha! ðŸ¦Š
        </p>

        
    </article>

</section>


<section>
    <article>
        <article>
            <p><img src="https://images.fibery.io/website/0.1.0-ci.n1068.692e7f9/img/landing/cl-logo1.svg" alt="Aiwo">
            </p>
            <p><img src="https://images.fibery.io/website/0.1.0-ci.n1068.692e7f9/img/landing/cl-logo6.svg" alt="Vochi">
            </p>
            <p><img src="https://images.fibery.io/website/0.1.0-ci.n1068.692e7f9/img/landing/cl-logo3.svg" alt="Rosetta Stone">
            </p>
            <p><img src="https://images.fibery.io/website/0.1.0-ci.n1068.692e7f9/img/landing/cl-logo4.svg" alt="Kontur">
            </p>
            <p><img src="https://images.fibery.io/website/0.1.0-ci.n1068.692e7f9/img/landing/cl-logo5.svg" alt="Vase">
            </p>
            <p><img src="https://images.fibery.io/website/0.1.0-ci.n1068.692e7f9/img/landing/cl-logo2.svg" alt="Plex">
            </p>
        </article>
        <p>Join some awesome product teams.</p>
    </article>
</section>



<section>

    <article>

        <p><img src="https://images.fibery.io/website/0.1.0-ci.n1068.692e7f9/img/landing/chel4.svg" alt="">
        </p>
        <h2>Customer Feedback</h2>
        <p>
            Treat each conversation as an opportunity to improve the product, and turn each release day into Boxing Day for your customers.
        </p>


        <div>
            <div>
                <div id="create-z3-1" data-duration="6" data-next="create-z3-2">
                    <h3>Tag Conversations</h3>
                    <p>
                        Sync feedback from Intercom, Discourse, and more. Link parts of conversations to insights and features.
                    </p>
                    

                    <p><img src="https://images.fibery.io/website/0.1.0-ci.n1068.692e7f9/img/landing/feedback1.png" alt="">
                    </p>

                </div>
                <div id="create-z3-2" data-next="create-z3-3" data-duration="6">
                    <h3>Drive Development</h3>
                    <p>
                        Identify top requests, dig deeper into the linked feedback, invent solutions, and invite requesters to test them out.
                    </p>
                    

                    <p><img src="https://images.fibery.io/website/0.1.0-ci.n1068.692e7f9/img/landing/feedback2.png" alt="">
                    </p>
                </div>
                <div id="create-z3-3" data-next="create-z3-1" data-duration="6">
                    <h3>Close the Loop</h3>
                    <p>
                        Once a feature is live, notify the customers. Use the linked feedback to make each message personal ðŸ’�
                    </p>
                    

                    <p><img src="https://images.fibery.io/website/0.1.0-ci.n1068.692e7f9/img/landing/feedback3.png" alt="">
                    </p>
                </div>
            </div>
            
        </div>

    </article>
    <article>
        <article>

            <p><img src="https://images.fibery.io/website/0.1.0-ci.n1068.692e7f9/img/landing/int-logo3.svg" alt="">
            </p>
            <p><img src="https://images.fibery.io/website/0.1.0-ci.n1068.692e7f9/img/landing/int-logo6.svg" alt="">
            </p>
            <p><img src="https://images.fibery.io/website/0.1.0-ci.n1068.692e7f9/img/landing/int-logo-z.svg" alt="">
            </p>
        </article>
        <p>Automatically grab conversations as they happen.</p>
    </article>

</section>


<section>

    <article>

        <p><img src="https://images.fibery.io/website/0.1.0-ci.n1068.692e7f9/img/landing/chel2.svg" alt="">
        </p>
        <h2>Ideation</h2>
        <p>
          Come up with unexpected ðŸ‘» solutions by talking and typing.<br>
          Remote is sometimes a feature, not a bug.
        </p>


        <div>
            <div>
                <div>
                    <p>01</p>
                    <h3>Digital Whiteboards</h3>
                    <p>
                        Build CJMs and mindmaps, brainstorm and organize ideas. Turn the craziest ones into features and stories.
                    </p>
                </div>
                <p><img src="https://images.fibery.io/website/0.1.0-ci.n1068.692e7f9/img/landing/desktop1.jpg" alt="">
                </p>
            </div>
            <div>
                <div>
                    <p>02</p>
                    <h3>Collaborative Documents</h3>
                    <p>
                        Write beautiful briefs together in real time, mention teammates, create tasks right from the editor. Also, have we mentioned backlinks?
                    </p>
                </div>
                <p><img src="https://images.fibery.io/website/0.1.0-ci.n1068.692e7f9/img/landing/documents.jpg" alt="">
                </p>
            </div>
        </div>

    </article>
</section>

<section>
    <article>
        <div>
            
            <div>
                <p><span>â€�</span></p><p>
                    We were finally able to have product planning, high-level executive views, marketing initiatives,
                    content calendars, and async meeting organization
                    all in one place while all referencing the same underlying data.
                </p>
                <div>
                    <p><img src="https://images.fibery.io/website/0.1.0-ci.n1068.692e7f9/img/landing/cl-logo2.svg" alt="Plex">
                    </p>
                    <p><b>Jason Williams</b>
                        <span>Director, Product &amp; Growth</span>
                    </p>
                </div>
            </div>
        </div>
    </article>
</section>


<section>
    <article>

        <p><img src="https://images.fibery.io/website/0.1.0-ci.n1068.692e7f9/img/landing/chel3.svg" alt="">
        </p>
        <h2>
            Product Management
        </h2>
        <p>
            From product vision to goals and features â€” link a shared <em>why</em> with clear <em>what</em> and <em>when</em>.
            Without everyone-is-scrolling-twitter meetings.
        </p>

    </article>
</section>

<article>
    <div>
        <div>
            <div>
                <h4>Strategy</h4>
                <p>
                    Align teams around common goals, bridge the gap to features and tasks, and see if outputs correlate with outcomes.
                </p>
            </div>
            <div>
                <h4>Backlog</h4>
                <p>
                    Welcome new ideas but prioritize fiercely. Use RICE, WSJF, MoSCoW, or your own fancy method ðŸŽ²
                </p>
            </div>
            <div>
                <h4>Roadmap</h4>
                <p>
                    Plan features on a timeline or on a simple now-next-later board. Group by goal, team, or product.
                </p>
            </div>

        </div>
    </div>
    
</article>

<section>
    <article>
        <div>
            <h2>Go for it</h2>
            <p>
                Make it easier for your team to create a product that people love.
            </p>
            <p><a href="https://fibery.io/sign-up?job=product">Try Fibery</a>
        </p></div>
    </article>
    <canvas></canvas>
</section>


<section>

    <article>

        <p><img src="https://images.fibery.io/website/0.1.0-ci.n1068.692e7f9/img/landing/chel6.svg" alt="">
        </p>
        <h2>Software Development</h2>
        <p>
            Decompose features into stories, marry design with code, and ship as often as you dare.
        </p>


        <div>
            <div>
                <div id="softdev-1" data-duration="6" data-next="softdev-2">
                    <h3>Integrate</h3>
                    <p>
                        Automatically link pull requests to stories and bugs.
                        Or start with Jira integration before fully migrating to Fibery.
                    </p>
                    

                    <p><img src="https://images.fibery.io/website/0.1.0-ci.n1068.692e7f9/img/landing/integrate.png" alt="">
                    </p>
                </div>
                <div id="softdev-2" data-next="softdev-3" data-duration="6">
                    <h3>Iterate</h3>
                    <p>
                        Estimate and prioritize stories, run sprints, and analyze velocity to keep plans realistic.
                    </p>
                    

                    <p><img src="https://images.fibery.io/website/0.1.0-ci.n1068.692e7f9/img/landing/scrum.png" alt="">
                    </p>
                </div>
                 <div id="softdev-3" data-next="softdev-1" data-duration="6">
                     <h3>Coordinate</h3>
                     <p>
                         Define a custom workflow for your Kanban board, distribute work within the team, and track time (or don't).
                     </p>
                     

                     <p><img src="https://images.fibery.io/website/0.1.0-ci.n1068.692e7f9/img/landing/kanban.png" alt="">
                     </p>
                </div>
            </div>
            
        </div>

    </article>
    <article>
        <article>
            <p><img src="https://images.fibery.io/website/0.1.0-ci.n1068.692e7f9/img/landing/int-logo4.svg" alt="Gitlab">
            </p>
            <p><img src="https://images.fibery.io/website/0.1.0-ci.n1068.692e7f9/img/landing/int-logo1.svg" alt="Github">
            </p>
            <p><img src="https://images.fibery.io/website/0.1.0-ci.n1068.692e7f9/img/landing/int-logo5.svg" alt="Jira Software">
            </p>
            <p><img src="https://images.fibery.io/website/0.1.0-ci.n1068.692e7f9/img/landing/int-logo-z.svg" alt="">
            </p>

        </article>
        <p>Sync issues, pull requests, and commits from dev tools.</p>
    </article>

</section>


<section>

    <article>

        <p><img src="https://images.fibery.io/website/0.1.0-ci.n1068.692e7f9/img/landing/chel1.svg" alt="">
        </p>
        <h2>User Research</h2>
        <p>
            Conduct thoughtful interviews, identify pain points,
            and find out why your latest glorious idea won't work.
        </p>


        <div>
            <div>
                <div id="users-1" data-duration="6" data-next="users-2">
                    <h3>Organize studies</h3>
                    <p>
                        Describe goals, prepare interview templates, and schedule sessions.
                    </p>
                    

                    <p><img src="https://images.fibery.io/website/0.1.0-ci.n1068.692e7f9/img/landing/customer-discovery-1.png" alt="">
                    </p>

                </div>
                <div id="users-2" data-next="users-3" data-duration="6">
                    <h3>Capture highlights</h3>
                    <p>
                        Take smart notes: mention common themes, missing features, and top competitors.
                    </p>
                    

                    <p><img src="https://images.fibery.io/website/0.1.0-ci.n1068.692e7f9/img/landing/%C3%91%EF%BF%BDapture-highlights.png" alt="">
                    </p>
                </div>
                <div id="users-3" data-next="users-1" data-duration="6">
                    <h3>Share insights</h3>
                    <p>
                        Analyze data and collaborate to turn recurring observations into rectangles on the product roadmap.
                    </p>
                    

                    <p><img src="https://images.fibery.io/website/0.1.0-ci.n1068.692e7f9/img/landing/capture-insights.png" alt="">
                    </p>
                </div>
            </div>
            
        </div>
    </article>
</section>



<section>
    <article>
        <p><img src="https://images.fibery.io/website/0.1.0-ci.n1068.692e7f9/img/landing/chels-demo.svg" alt="">
        </p>
        <div>
            <h2>Request a demo</h2>
            <p>
                This brochure looks neat, but you'd like a guided tour with Q&amp;A?
            </p>
            </div>
    </article>
    <canvas></canvas>
</section>



<section>
    <article>

        <div>
            <div>
                <h2>Simply connected</h2>
                <p>
                    Escape isolated | work | management | tools and bring teams closer together. No information silos, no copy-pasting, and no integration to maintain.
                </p>
            </div>
            
        </div>

        <p><img src="https://images.fibery.io/website/0.1.0-ci.n1068.692e7f9/img/landing/conected.png" alt="">
        </p>

    </article>
</section>

<!-- <section class="section-wrapper landing-section sm">
    <article class="about-feature-content">
        <h2 class="def-headline">
            Product Management Software
        </h2>
        <p class="def-headline-descr" style="margin-bottom: 4rem;">
            We have sacrificed this section to SEO gods.<br>
            Dear product manager, CPO, or Head of Product, we will compensate for your time reading this, once you abandon your current product management tool and become a customer.
        </p>

        <div class="svg-wrap">
            <img src="https://images.fibery.io/website/0.1.0-ci.n1068.692e7f9/img/landing/chel-l.svg" alt="">
        </div>
    </article>
</section> -->


<section>
    <article>
        <h2>
            Suprisingly customizable
        </h2>
        <p>
          Fibery adapts to your team, incorporates JTBD and GIST, embraces Scrum, Kanban, and Waterfall, and supports product management frameworks that are not yet invented. How? It's a no-code platform.
        </p>

        <p><img src="https://images.fibery.io/website/0.1.0-ci.n1068.692e7f9/img/landing/chel-l.svg" alt="">
        </p>
    </article>
</section>


<section>
    <article>
        <div>
            <p><img src="https://images.fibery.io/website/0.1.0-ci.n1068.692e7f9/img/landing/chel5.svg" alt="">
            </p>
            <h2>Escape scattered tools</h2>
            <p>
                Get a single connected workspace<br>
                where all teams are welcome.
            </p>
            <p><a href="https://fibery.io/sign-up?job=product">Try Fibery</a>
        </p></div>
    </article>
    <canvas></canvas>
</section>






<!-- Calendly link widget begin -->


<!-- Calendly link widget end -->






</div>]]>
            </description>
            <link>https://fibery.io/product-management</link>
            <guid isPermaLink="false">hacker-news-small-sites-26004936</guid>
            <pubDate>Tue, 02 Feb 2021 18:50:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Storing Machine Code in REM Statements on the Vic-20]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26004928">thread link</a>) | @elvis70
<br/>
February 2, 2021 | https://techtinkering.com/articles/storing-machine-code-in-rem-statements-on-the-vic-20/ | <a href="https://web.archive.org/web/*/https://techtinkering.com/articles/storing-machine-code-in-rem-statements-on-the-vic-20/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
        <p>BASIC programs often contain machine code routines but they take up quite a lot of space in BASIC.  An interesting way to reduce the amount of space that they take is to store the machine code in <code>REM</code> statements.  This is much more compact and also means that we can call the routine directly from the location it is stored in memory rather than having to copy it to a further location.  This doesn't just apply to machine code, we could also do this for storing other data such as a custom character set.</p>
<h2>How BASIC is Stored in Memory</h2>
<p>A BASIC program consists of a series of BASIC lines followed by two 00 octets to signify the end of the program. The BASIC statements are condensed using tokens such as $8F for <code>REM</code>.</p>
<p><img src="https://techtinkering.com/img/articles/vic20_basic_lines_memory_layout.png" title="Layout of BASIC lines in memory"></p><h2>Storing Machine Code in DATA Statements</h2>
<p><img src="https://techtinkering.com/img/articles/vic20_machine_code_in_data_statements_basic_listing.png" title="BASIC listing with machine in DATA statements"></p><p>A machine code routine in BASIC is often stored in <code>DATA</code> statements and then copied to another area of memory for execution.  However, this uses up more memory than storing the routine in <code>REM</code> statements as we will see later.</p>
<p>The following BASIC program copies a machine code routine stored in <code>DATA</code> statements into locations 673-692.  The machine language routine we're using cycles the screen border and background colours and is from the article: <a href="https://techtinkering.com/articles/hand-assembling-to-machine-code-on-the-commodore-vic-20/">Hand Assembling to Machine Code on the Commodore VIC-20</a>.</p>
<pre><code>10 FORA=673TO692:READB:POKEA,B:NEXTA
20 DATA173,15,144,162,255,142,15,144,160,255
30 DATA136,208,253,202,208,245,141,15,144,96
40 SYS673
</code></pre>
<h2>Storing Machine Code in REM Statements</h2>
<p>The machine code routine stored in <code>DATA</code> statements above is position independent and is represented by the following octets which we can also see in the table below.</p>
<pre><code>AD 0F 90 A2 FF
8E 0F 90 A0 FF
88 D0 FD CA D0
F5 8D 0F 90 60
</code></pre>
<p>On an unexpanded Vic, BASIC programs start at $1001 (4097).  We would use a different location for Vics with more memory.  To create a <code>REM</code> statement with the above machine code we would enter the following in memory.  We could easily <code>POKE</code> the values from BASIC into memory starting at location 4097 ($1001) or we could use a simple hex loader or a machine language monitor.</p>
<table>
  <tbody><tr><th>Location</th><th>Octets</th><th>Explanation</th></tr>
  <tr><td>$1001</td><td>1C 10</td><td>Next line link.  Here this is also the end of BASIC program - $101C</td></tr>
  <tr><td>$1003</td><td>0A 00</td><td>Line number - 10</td></tr>
  <tr><td>$1005</td><td>8F</td><td>REM token</td></tr>
  <tr><td>$1006</td><td>20</td><td>Space character</td></tr>
  <tr>
    <td>$1007</td>
    <td>AD 0F 90 A2 FF 8E 0F 90 A0 FF 88 D0 FD CA D0 F5 8D 0F 90 60</td>
    <td>Machine language routine</td>
  </tr>
  <tr><td>$101B</td><td>00</td><td>End of BASIC line</td></tr>
  <tr><td>$101C</td><td>00 00</td><td>End of BASIC program</td></tr>
</tbody></table>
<p>After we have entered the line into memory we must remember to update locations 45/46 to indicate the end of our BASIC program and the start of variables.</p>
<br>
<h3>Using VICMON to Create REM Statement Containing Machine Code</h3>
<p><img src="https://techtinkering.com/img/articles/vic20_vicmon_code_in_rem_basic_listing.png" title="BASIC listing with machine embedded in REM statement, entered using VICMON"></p><p>If we have a machine language monitor, such as VICMON, then the process is really easy.  We just alter the bytes in memory, exit to BASIC, update the end of BASIC program pointer and then enter our <code>SYS</code> statement on the following line.</p>

<p>In VICMON we first have to enable a virtual zero page otherwise the monitor would overwrite bytes in memory necessary for BASIC.</p>
<pre><code>.E 1200
</code></pre>
<p>Enter BASIC <code>REM</code> lines containing machine code at location $1001 (4097), the start of BASIC on an unexpanded Vic.</p>
<pre><code>.M 1001
.:1001 1C 10 0A 00 8F
.:1006 20 AD 0F 90 A2
.:100B FF 8E 0F 90 A0
.:1010 FF 88 D0 FD CA
.:1015 D0 F5 8D 0F 90
.:101A 60 00 00 00
</code></pre>
<p>Exit to BASIC.</p>
<pre><code>.X
</code></pre>
<p>Move the pointer to end of BASIC program, which is the next location after the end of the BASIC program marker.  This is stored in LSB MSB order and here is $101E (4126).</p>
<pre><code>POKE 45, 30
POKE 46, 16
</code></pre>
<p>Add line to jump to the machine code contained in the <code>REM</code> statement.</p>
<pre><code>20 SYS4103
</code></pre>
<h2>Memory Use Comparison</h2>
<p>The following BASIC statement shows how much memory is free for BASIC programs.</p>
<pre><code>PRINT FRE(0)
</code></pre>
<p>On an unexpanded Vic, that has just been switched on, it shows 3581 bytes free.</p>
<p>The following table shows how much memory is used by the two programs above.</p>
<table>
  <tbody><tr><th>Program Version</th><th>Memory free (bytes)</th><th>Usage (bytes)</th></tr>
  <tr><td>DATA statements</td><td>3460</td><td>121</td></tr>
  <tr><td>REM statement</td><td>3544</td><td>37</td></tr>
</tbody></table>
<p>We can see from this table that the version of the program that stored the machine code routine in a <code>REM</code> statement used 84 bytes less memory than the one that stored the routine in <code>DATA</code> statements.  It also saved using up memory at 673-692 which could possibly be used for something else.</p>
<h2>Conclusion</h2>
<p>This method is a great way to save memory in BASIC programs, however it isn't without its problems.  The machine code routine can't contain a <code>00</code> byte as this indicates the end of the BASIC line.  It isn't suitable for listings and it is a pain if we want to alter the machine code stored in the <code>REM</code> statements.  Despite this, it is an interesting method which gives us some incite into how BASIC is stored in memory and can be useful in certain situations.</p>
<h2>Video</h2>
<p>The following video shows a machine code routine being entered into both <code>DATA</code> statements and <code>REM</code> statements.  It also shows the code being run directly from the area in memory where it is embedded within the <code>REM</code> statement.</p>
<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/PHJeQlGrTpQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>
      </div></div>]]>
            </description>
            <link>https://techtinkering.com/articles/storing-machine-code-in-rem-statements-on-the-vic-20/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26004928</guid>
            <pubDate>Tue, 02 Feb 2021 18:50:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Git Bisect Succinctly]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26004556">thread link</a>) | @zdw
<br/>
February 2, 2021 | https://leontrolski.github.io/git-bisect.html | <a href="https://web.archive.org/web/*/https://leontrolski.github.io/git-bisect.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><a href="https://leontrolski.github.io/index.html"><img src="https://leontrolski.github.io/pic.png">â‡¦</a><p>I can never remember how to <code>git bisect</code>, it's occasionally super-useful and there are extensive posts about it elsewhere, but I've never needed more than:</p><pre><code>cd ../top-of-repo

#                sad  happy
git bisect start HEAD HEAD~200 --

# run the test you wrote
git bisect run sh -c 'cd somewhere; pytest something'

# tests run
# then you see like:
# abcd123... is the first bad commit
# then to clean up
git bisect reset</code></pre>
</div>]]>
            </description>
            <link>https://leontrolski.github.io/git-bisect.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26004556</guid>
            <pubDate>Tue, 02 Feb 2021 18:21:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Chats with James Podcast 006: Bryan Cantrill]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26004553">thread link</a>) | @jamesmunns
<br/>
February 2, 2021 | https://jamesmunns.com/podcast/006-bryan/ | <a href="https://web.archive.org/web/*/https://jamesmunns.com/podcast/006-bryan/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <p><span>2021-02-02</span></p><hr>
  <p>James chats with <a href="https://twitter.com/bcantrill">Bryan Cantrill</a> of Oxide Computer to discuss the open source hardware explosion, Oxide's experience with Embedded Rust, the importance of a culture of sharing knowledge, and the joy of fixing hard-to-diagnose systems problems.</p>
<p><strong>Originally Recorded on 2021-01-10.</strong></p>

<h2 id="audio">Audio</h2>
<p><strong>FLAC</strong></p>
<p><audio controls="" src="https://delivery.jamescdn.com/2021-02-02-bryan-cantrill.flac">
Your browser does not support embedding FLAC
</audio></p>
<p><a href="https://delivery.jamescdn.com/2021-02-02-bryan-cantrill.flac">Download as FLAC</a></p>
<h3 id="m4a">M4A</h3>
<p><audio controls="" src="https://delivery.jamescdn.com/2021-02-02-bryan-cantrill.m4a">
Your browser does not support embedding M4A.
</audio></p>
<p><a href="https://delivery.jamescdn.com/2021-02-02-bryan-cantrill.m4a">Download as M4A</a></p>
<h3 id="mp3">MP3</h3>
<p><audio controls="" src="https://delivery.jamescdn.com/2021-02-02-bryan-cantrill.mp3">
Your browser does not support embedding MP3.
</audio></p>
<p><a href="https://delivery.jamescdn.com/2021-02-02-bryan-cantrill.mp3">Download as MP3</a></p>
<h2 id="show-notes">Show Notes</h2>
<ul>
<li>Bryan on the Internet
<ul>
<li><a href="https://twitter.com/bcantrill">Twitter</a></li>
<li><a href="https://github.com/bcantrill">GitHub</a></li>
<li><a href="http://dtrace.org/blogs/bmc">Blog</a></li>
</ul>
</li>
<li><a href="https://en.wikipedia.org/wiki/2021_storming_of_the_United_States_Capitol">January 6th storming of the US Capitol</a></li>
<li><a href="https://oxide.computer/">Oxide Computer Company</a></li>
<li><a href="https://www.linkedin.com/in/steve-tuck-02b4313/">Steve Tuck</a> and <a href="https://twitter.com/jessfraz">Jess Frazelle</a></li>
<li><a href="https://en.wikipedia.org/wiki/Hyperscale_computing">Hyperscaler (computing)</a></li>
<li><a href="https://www.joyent.com/">Joyent (cloud computing)</a></li>
<li><a href="https://en.wikipedia.org/wiki/Sun_Microsystems">Sun Microsystems</a></li>
<li><a href="https://en.wikipedia.org/wiki/Oracle_Corporation">Oracle Corporation</a></li>
<li><a href="https://jamesmunns.com/podcast/002-chris/">Chat with Christopher Hunt where we mentioned CORBA and SunRPC</a></li>
<li><a href="https://en.wikipedia.org/wiki/Thin_client">Thin Clients</a></li>
<li><a href="https://en.wikipedia.org/wiki/Teleprinter">TTY or Teleprinter Terminals</a></li>
<li><a href="https://www.linkedin.com/in/duanenorthcutt/">Duane Northcutt</a></li>
<li><a href="https://en.wikipedia.org/wiki/Sun_Ray">SunRay</a> - and <a href="https://www.youtube.com/watch?v=_qQZRC1-w-A">a SunRay demo</a></li>
<li><a href="https://en.wikipedia.org/wiki/Smart_card">Smart Card</a></li>
<li><a href="https://www.youtube.com/watch?v=_NE1hp_uDT0">iPhone announcement</a></li>
<li><a href="https://en.wikipedia.org/wiki/Windows_Mobile">Windows Mobile</a>, and the <a href="https://en.wikipedia.org/wiki/HTC_TyTN">HTC 8525</a></li>
<li><a href="https://scratch.mit.edu/">Scratch Programming Language</a></li>
<li><a href="https://en.wikipedia.org/wiki/List_of_custom_Android_distributions">Android ROMs</a></li>
<li><a href="https://puri.sm/products/librem-5/">Purism Librem 5</a></li>
<li><a href="https://en.wikipedia.org/wiki/Chromebook">Chromebook</a></li>
<li><a href="https://en.wikipedia.org/wiki/Gentoo_Linux">Gentoo Linux</a></li>
<li><a href="https://en.wikipedia.org/wiki/DTrace">DTrace</a></li>
<li><a href="https://en.wikipedia.org/wiki/Window_manager">Window managers</a></li>
<li><a href="https://en.wikipedia.org/wiki/I3_(window_manager)">i3 Window Manager</a></li>
<li><a href="https://en.wikipedia.org/wiki/FVWM">FVWM Window Manager</a></li>
<li><a href="https://asahilinux.org/">Asahi Linux</a></li>
<li><a href="https://twitter.com/marcan42">Hector Martin - Marcan</a></li>
<li>Marcan Exploting the <a href="https://www.cnet.com/news/sonys-playstation-3-experiences-its-biggest-hack-yet/">PS3</a>, <a href="https://fail0verflow.com/blog/2015/console-hacking-2015-liner-notes/">PS4</a>, and the <a href="https://wii.marcan.st/">Wii</a></li>
<li><a href="https://www.apple.com/mac/m1/">Apple M1 Macs</a></li>
<li><a href="https://www.tomsguide.com/news/mac-mini-m1-benchmarks-revealed-and-they-crush-intel">Apple M1 Benchmarks</a></li>
<li><a href="https://www.patreon.com/marcan">Marcan's Patreon</a></li>
<li><a href="https://asahilinux.org/about/">Asahi and McIntosh apples</a></li>
<li><a href="https://en.wikipedia.org/wiki/Software_as_a_service">Software as a Service (SaaS)</a></li>
<li><a href="https://www.kicad.org/">KiCad</a></li>
<li><a href="https://oshpark.com/">OSH Park</a> and <a href="https://jlcpcb.com/">JLCPCB</a></li>
<li><a href="https://en.wikipedia.org/wiki/Field-programmable_gate_array">FPGAs - Field-programmable gate arrays</a></li>
<li><a href="https://en.wikipedia.org/wiki/RISC-V">RISC-V</a></li>
<li><a href="https://en.wikipedia.org/wiki/Wafer_(electronics)">Silicon Wafer</a></li>
<li><a href="https://efabless.com/open_shuttle_program">Open Shuttle Program</a> for open source silicon hardware designs, sponsored by Google</li>
<li><a href="https://www.latticesemi.com/">Lattice Semiconductor</a>, manufacturer of <a href="https://www.latticesemi.com/en/Products/FPGAandCPLD/iCE40">iCE40</a> and <a href="https://www.latticesemi.com/en/Products/FPGAandCPLD/ECP5">ECP5</a> FPGAs</li>
<li><a href="https://github.com/parallella/openeda">OpenEDA</a></li>
<li><a href="https://bluespec.com/">bluespec</a></li>
<li><a href="https://en.wikipedia.org/wiki/Verilog">Verilog</a></li>
<li><a href="https://en.wikipedia.org/wiki/VHDL">VHDL</a></li>
<li><a href="https://github.com/nmigen/nmigen">nMigen</a></li>
<li><a href="https://en.wikipedia.org/wiki/SystemVerilog">SystemVerilog</a></li>
<li><a href="https://anachro.computer/">Anachro Computer</a></li>
<li><a href="https://en.wikipedia.org/wiki/Northbridge_(computing)">Northbridge</a></li>
<li><a href="https://en.wikipedia.org/wiki/Serial_Peripheral_Interface">SPI</a></li>
<li><a href="https://en.wikipedia.org/wiki/PCI_Express">PCIe - PCI Express</a></li>
<li><a href="https://en.wikipedia.org/wiki/Application-specific_integrated_circuit">ASIC - Application-specific integrated Circuit</a></li>
<li><a href="https://en.wikipedia.org/wiki/Hypervisor">Hypervisor</a></li>
<li><a href="https://en.wikipedia.org/wiki/Control_plane">Control Plane</a></li>
<li><a href="https://en.wikipedia.org/wiki/Printed_circuit_board">PCB - Printed Circuit Boards</a></li>
<li><a href="https://en.wikipedia.org/wiki/FR-4">FR-4</a></li>
<li><a href="https://podcasts.apple.com/us/podcast/pick-place-podcast/id1518253009">Pick, Place, Podcast</a></li>
<li><a href="https://www.broadstreetreview.com/books/the-sloan-technology-series">Sloan Technology Series</a> of books</li>
<li><a href="https://en.wikipedia.org/wiki/Photolithography">Photolithography</a></li>
<li><a href="https://en.wikipedia.org/wiki/Earworm">brainworm</a></li>
<li><a href="https://en.wikipedia.org/wiki/GNU_Compiler_Collection">GCC - GNU Compiler Collection</a></li>
<li><a href="https://en.wikipedia.org/wiki/Arm_Ltd.">Arm Ltd.</a></li>
<li><a href="https://en.wikipedia.org/wiki/Microcontroller">MCU - Microcontroller Unit</a></li>
<li><a href="https://en.wikipedia.org/wiki/Raspberry_Pi">Raspberry Pi</a></li>
<li><a href="https://en.wikipedia.org/wiki/Broadcom_Inc.">Broadcom, Inc.</a></li>
<li><a href="https://raspberrytips.com/raspberry-pi-history/">Raspberry Pi History</a></li>
<li><a href="https://en.wikipedia.org/wiki/Bastard_Operator_From_Hell">Bastard Operator From Hell</a></li>
<li><a href="https://osfc.io/">Open Source Firmware Conference</a></li>
<li><a href="https://en.wikipedia.org/wiki/Spectre_(security_vulnerability)">Spectre and Meltdown vulnerabilities</a></li>
<li><a href="https://en.wikipedia.org/wiki/Proprietary_device_driver">Proprietary Blobs</a></li>
<li><a href="https://github.com/rust-embedded/wg">Rust Embedded Working Group</a></li>
<li><a href="https://en.wikipedia.org/wiki/STMicroelectronics">STMicroelectronics</a></li>
<li><a href="https://knurling.ferrous-systems.com/">Ferrous' Knurling Tools</a></li>
<li><a href="https://knurling.ferrous-systems.com/tools/#defmt"><code>defmt</code></a> - A deferred formatting logging utility for embedded systems</li>
<li><a href="http://dtrace.org/blogs/bmc/2020/10/11/rust-after-the-honeymoon/">Rust after the honeymoon</a> Blog Post</li>
<li><a href="https://rust-embedded.github.io/book/intro/no-std.html">Rust's no_std</a> environment</li>
<li><a href="https://en.wikipedia.org/wiki/DWARF">DWARF debugging format</a></li>
<li><a href="https://app.element.io/#/room/#rust-embedded:matrix.org">Rust Embedded Matrix Room</a></li>
<li><a href="https://jamesmunns.com/podcast/006-bryan/ferrous-systems.com/">Ferrous Systems</a> - A consultancy focused on the Rust programming language</li>
<li><a href="https://ferrous-systems.com/rust-experts/">Rust Experts</a> - a chat based support service for the Rust programming language</li>
<li><a href="https://en.wikipedia.org/wiki/Benevolent_dictator_for_life">BDFL - Benevolent Dictator For Life</a></li>
<li><a href="https://www.youtube.com/watch?v=HiWkMFE8uRE">James' C++ and Rust talk - Access All Arenas</a></li>
<li><a href="https://twitter.com/ekuber/status/1319476290395664384">"There are no bad programmers, only insufficiently advanced compilers"</a> - <a href="https://twitter.com/ekuber/">Esteban Kuber</a></li>
<li><a href="https://en.wikipedia.org/wiki/Aviation_accidents_and_incidents">Aviation Disaster Investigations</a></li>
<li><a href="https://en.wikipedia.org/wiki/Boeing_737_MAX">Boeing 737 MAX</a></li>
<li><a href="https://www.bloomberg.com/news/articles/2021-01-20/faulty-automatic-throttle-eyed-in-indonesia-jet-crash-probe">January 2021 Sriwijaya Air 737-500 crash</a></li>
<li><a href="https://en.wikipedia.org/wiki/Boeing_737_rudder_issues">Boeing 737 Rudder Issues</a></li>
<li><a href="https://en.wikipedia.org/wiki/United_Airlines_Flight_585">UA Flight 585 Accident</a></li>
<li><a href="https://en.wikipedia.org/wiki/Wake_turbulence">Wake Turbulence</a></li>
<li><a href="https://en.wikipedia.org/wiki/USAir_Flight_427">USAir Flight 427 Accident</a></li>
<li><a href="https://www.amazon.com/Mystery-Flight-427-Inside-Investigation/dp/1588340899">Mystery of Flight 427</a> book</li>
<li><a href="https://sre.google/sre-book/postmortem-culture/">Postmortem Analysis Culture</a></li>
<li><a href="https://en.wikipedia.org/wiki/Core_dump">Core Dump or Crash Dump</a></li>
<li><a href="https://en.wikipedia.org/wiki/Flight_recorder">Flight or "Black Box" Recorder</a></li>
<li><a href="https://rr-project.org/">rr - time traveling debugger</a></li>
<li><a href="https://en.wikipedia.org/wiki/Walk-off_home_run">Walk-off home run</a></li>
<li><a href="https://en.wikipedia.org/wiki/Pebble_(watch)">Pebble watch</a></li>
<li><a href="https://jamesmunns.com/podcast/004-francois/">Talk with François Baldassari from Pebble</a></li>
<li><a href="https://en.wikipedia.org/wiki/System_call">System Call or "syscall"</a></li>
<li><a href="https://memfault.com/">Memfault</a></li>
<li><a href="https://emp.jamesmunns.com/">Embedded: The Missing Parts book</a></li>
<li><a href="https://gist.github.com/jamesmunns/33743c451372b36701a773304f6f771e">Table of Contents</a> for Embedded: The Missing Parts</li>
<li><a href="https://github.com/rust-lang/mdBook">mdBook tool</a></li>
<li><a href="https://interrupt.memfault.com/blog/">Interrupt Blog</a></li>
<li><a href="https://doc.rust-lang.org/book/ch03-02-data-types.html#integer-overflow">Rust and Integer Overflow (or underflow)</a></li>
<li><a href="https://en.wikipedia.org/wiki/Lint_(software)">LINTers</a></li>
<li><a href="https://www.cvedetails.com/cve/CVE-2016-1826/">DTrace integer overflow allowing escaped read</a> CVE</li>
<li><a href="https://oxide.computer/podcast/">On The Metal podcast</a></li>
</ul>
<h2 id="transcript">Transcript</h2>
<p>Transcript not made yet.</p>
<h2 id="credits">Credits</h2>
<p>Thanks to <a href="https://louiezong.bandcamp.com/">Louie Zong</a> for the music.</p>

</div></div>]]>
            </description>
            <link>https://jamesmunns.com/podcast/006-bryan/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26004553</guid>
            <pubDate>Tue, 02 Feb 2021 18:21:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Facebook Software Engineer teaching free live class on Programming]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26004477">thread link</a>) | @samiri2018
<br/>
February 2, 2021 | https://keat.co/upcomingclass/fundamentals-of-programming-1612212653701x556236334813151200 | <a href="https://web.archive.org/web/*/https://keat.co/upcomingclass/fundamentals-of-programming-1612212653701x556236334813151200">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://keat.co/upcomingclass/fundamentals-of-programming-1612212653701x556236334813151200</link>
            <guid isPermaLink="false">hacker-news-small-sites-26004477</guid>
            <pubDate>Tue, 02 Feb 2021 18:15:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Pilot – The Free Version of Resurface's API Observability Solution]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26004293">thread link</a>) | @gooseontheloose
<br/>
February 2, 2021 | https://resurface.io/pilot-edition | <a href="https://web.archive.org/web/*/https://resurface.io/pilot-edition">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><h5><span>Capture</span> all API data, including request and response headers<!-- --> </h5><h5><span>Store</span> your API activity across multiple dimensions</h5><h5><span>Search</span>,<!-- --> <span>analyze</span>, and<!-- --> <span>share</span> API details across teams</h5><h5>Pilot Edition goodness includes:</h5><ul><li>Database licensed for internal non-production use</li><li>Open-source loggers for Java, Node.js, Python, and Ruby</li><li>SQL data access using pre-configured Presto instance</li><li>API Explorer application for search &amp; reporting</li><li>Community support by email or Slack</li></ul></div></div></div></div>]]>
            </description>
            <link>https://resurface.io/pilot-edition</link>
            <guid isPermaLink="false">hacker-news-small-sites-26004293</guid>
            <pubDate>Tue, 02 Feb 2021 18:01:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Matrix Metadata Leaks]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26004189">thread link</a>) | @Sami_Lehtinen
<br/>
February 2, 2021 | https://serpentsec.1337.cx/matrix | <a href="https://web.archive.org/web/*/https://serpentsec.1337.cx/matrix">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>One question I'm often asked is what metadata <a href="https://matrix.org/" rel="nofollow">Matrix</a> leaks. It does get tiring answering the same questions, so I'm creating an article I can simply link to any time someone asks.</p>

<hr>

<p>I am on record many times saying Matrix leaks metadata. However, one thing that many people fail to understand is exactly what Matrix leaks, and why.</p>

<p><em><strong>Note:</strong> For the purposes of this article, it's assumed users are communicating using end-to-end encryption (E2EE). In non-E2EE rooms, you can expect everything mentioned here to be leaked, as well as actual message contents.</em></p>

<h3 id="what-is-a-metadata-leak">What is a metadata leak?</h3>

<p>Metadata leaks are when your messaging app includes <a href="https://ia801306.us.archive.org/28/items/content-metadata-matrix/content-metadata-matrix_text.pdf" rel="nofollow">metadata</a> in a way that's not encrypted end-to-end. This includes the dates and times you send messages, who you send them to, how frequently you send messages, and more. Many messengers allow you to set status messages and profile pictures. These are not encrypted, and are thus leaked. The issue with metadata leaks is they can fairly easily <a href="https://www.pbs.org/newshour/science/your-phone-metadata-is-more-revealing-than-you-think" rel="nofollow">reveal sensitive information</a>, even when you don't expect them to.</p>

<h3 id="what-metadata-does-matrix-leak">What metadata does Matrix leak?</h3>

<p>Matrix supports end-to-end encryption (E2EE). This protects the contents of messages, such that nobody can read them except the intended recipients. E2EE can be enabled manually in Matrix rooms, but is also enabled by default in 1:1 chats (DMs). Some clients may not enable E2EE by default,  so you should always verify whether messages are sent E2EE.</p>

<p>Matrix's E2EE does not, however, encrypt everything. The following information is not encrypted:</p>
<ul><li>Message senders
<ul><li>Message senders are never encrypted</li></ul></li>
<li>Session/device IDs
<ul><li>Due to Matrix's design, encrypting this would break verification</li></ul></li>
<li>Message timestamps
<ul><li>It's impossible to prevent timestamps from leaking, since the server can simply note when an event is received anyway</li></ul></li>
<li>Room members (join/leave/invite events)
<ul><li>Join/leave/invite and other room events are never encrypted</li></ul></li>
<li>Message edit events
<ul><li>While contents are not leaked, an attacker can know when messages are edited</li></ul></li>
<li>Message reactions
<ul><li>Reactions are never encrypted</li></ul></li>
<li>Read receipts
<ul><li>Read receipts are never encrypted</li></ul></li>
<li>Nicknames
<ul><li>Nicknames are never encrypted</li></ul></li>
<li>Profile pictures
<ul><li>Profile pictures are never encrypted</li></ul></li></ul>

<p>To demonstrate some examples of these leaks, I have made some examples available: <a href="https://snippets.serpentsec.1337.cx/matrix-metadata-leaks" rel="nofollow">https://snippets.serpentsec.1337.cx/matrix-metadata-leaks</a></p>

<h3 id="who-can-view-metadata">Who can view metadata?</h3>

<p>The following metadata can be seen by any homeserver with at least 1 member in an E2EE room:</p>
<ul><li>Message senders</li>
<li>Session/device IDs</li>
<li>Message timestamps</li>
<li>Room members (join/leave/invite events)</li>
<li>Message edit events</li>
<li>Message reactions</li>
<li>Read receipts</li>
<li>Room-specific nicknames</li>
<li>Room-specific profile pictures</li></ul>

<p>The following information is publicly available:</p>
<ul><li>Global nicknames
<ul><li>Matrix allows setting room-specific nicknames, which are less visible to attackers</li></ul></li>
<li>Profile pictures
<ul><li>Matrix allows setting room-specific profile pictures, which are less visible to attackers</li></ul></li></ul>

<h4 id="examples">Examples</h4>
<ul><li>A room has 2 members, both from <em>homeserver1.example.com</em>. Any attacker with access to <em>homeserver1.example.com</em> can see metadata from that room. This includes homeserver admins, as well as anyone who manages to compromise the homeserver.</li>
<li>A room has 2 members, one from <em>homeserver1.example.com</em>, and another from <em>homeserver2.example.com</em>. Any attacker with access to <em>homeserver1.example.com</em> or <em>homeserver2.example.com</em> can see metadata from that room. This includes homeserver admins, as well as anyone who manages to compromise one (or more) of the homeservers.</li>
<li>I think you get the idea...</li></ul>

<h3 id="why-does-matrix-leak-metadata">Why does Matrix leak metadata?</h3>

<p>Federated networks are naturally more vulnerable to metadata leaks than P2P or centralized networks. These leaks can be fixed, at the expense of increased complexity of the protocol (thus making it more vulnerable to faulty implementations). Matrix's failure to prevent these leaks is necessary for proper functioning of the protocol.</p>

<p>Some metadata must be leaked due to features Matrix provides. For example, Matrix's message verification requires knowing which user and device sent a message (to know which key to verify with). In other cases (such as global profile pictures and nicknames), the information is considered public anyway, and therefore has no need to be encrypted. Matrix's failure to prevent these leaks is a triviality.</p>

<p>Some metadata leaks are accepted for performance requirements. For example, message reactions and read receipts might not be encrypted because Matrix's E2EE is slower than normal (non-E2EE) messaging. Encrypting reactions and read receipts could provide a painful user experience (UX). Matrix's failure to prevent these leaks is a design feature.</p>

<p>Some metadata leaks are simply a matter of the protocol's failure to consider them. For example, room-specific nicknames, room-specific profile pictures, and message edit events could all be encrypted without breaking the protocol. Matrix's failure to prevent these leaks is a design flaw.</p>

<p><strong>Note:</strong> Though edit events are leaked, message contents are not.</p>

<p><i>All original non-code content is committed to the public domain, except where otherwise explicitly stated. Code is licensed under the <a href="https://opensource.org/licenses/BSD-3-Clause" rel="nofollow">BSD 3-clause license</a>, except where otherwise explicitly stated. Content not originally created by Serpent Security may be subject to separate licensing terms.</i></p>
</div></div>]]>
            </description>
            <link>https://serpentsec.1337.cx/matrix</link>
            <guid isPermaLink="false">hacker-news-small-sites-26004189</guid>
            <pubDate>Tue, 02 Feb 2021 17:52:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Loop V2 – Free high quality UI Components for building faster on figma]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26004170">thread link</a>) | @sampsonferd
<br/>
February 2, 2021 | https://www.devwares.com/product/loop | <a href="https://web.archive.org/web/*/https://www.devwares.com/product/loop">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>Design System created to help speed up your next design project</h2><p>Use the Loop design system UI kit to get your next design project to your clients as fast as possible. We have created alll the essential components you will need to create your designs and make them as elegant as possible</p><p><a href="https://www.devwares.com/app/downloads">Get Loop</a></p></div></div>]]>
            </description>
            <link>https://www.devwares.com/product/loop</link>
            <guid isPermaLink="false">hacker-news-small-sites-26004170</guid>
            <pubDate>Tue, 02 Feb 2021 17:51:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Alexei Navalny sentenced to 3.5 years in prison for violating probation]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26004153">thread link</a>) | @boa00
<br/>
February 2, 2021 | https://www.cbc.ca/news/world/russia-navalny-court-1.5897347 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/world/russia-navalny-court-1.5897347">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Russian opposition leader Alexei Navalny was sentenced to more than three years in prison in a Moscow court hearing on Tuesday, but not before calling the proceedings a vain attempt by the Kremlin to scare millions of Russians into submission.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5897934.1612293165!/fileImage/httpImage/image.JPG_gen/derivatives/16x9_780/russia-politics-navalny.JPG"></p></div><figcaption>Russian opposition leader Alexei Navalny makes a heart gesture with his hands while in a cage in the Moscow City Court on Tuesday. His suspended sentence from his 2014 criminal conviction was ultimately converted to a prison term.<!-- --> <!-- -->(Press Service of Simonovsky District Court/Handout/Reuters)</figcaption></figure><p><span><p>A Moscow court on Tuesday ordered Russian opposition leader Alexei Navalny to prison for 3½ years for violating&nbsp;the terms of his probation while he was recuperating in Germany from nerve-agent poisoning.</p>  <p>With time he has previously served under house arrest, it will leave Navalny to serve just over 2½ years in prison to finish the sentence.&nbsp;Navalny's legal team is expected to appeal the sentence.</p>  <p>Just before the ruling, Navalny, who is the most prominent critic of President Vladimir Putin, had denounced the proceedings as a vain attempt by the Kremlin to scare millions of Russians into submission.</p>  <p>After the verdict that was announced at about 8 p.m. local time, protesters converged on an area of central Moscow and gathered on St. Petersburg's main avenue, Nevsky Prospekt. Helmeted riot police grabbed demonstrators without obvious provocation and put them in police vehicles.</p>  <p>The ruling came despite massive protests across Russia over the past two weekends and Western calls to free the 44-year-old anti-corruption campaigner.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5898094.1612298525!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/russia-navalny.jpg 300w,https://i.cbc.ca/1.5898094.1612298525!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/russia-navalny.jpg 460w,https://i.cbc.ca/1.5898094.1612298525!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/russia-navalny.jpg 620w,https://i.cbc.ca/1.5898094.1612298525!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/russia-navalny.jpg 780w,https://i.cbc.ca/1.5898094.1612298525!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/russia-navalny.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5898094.1612298525!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/russia-navalny.jpg"></p></div><figcaption>Police detain a Navalny supporter in Moscow's Red Square on Tuesday.<!-- --> <!-- -->(Pavel Golovkin/The Associated Press)</figcaption></figure></span></p>  <p>The prison sentence stems from a 2014 embezzlement conviction that Navalny has rejected as fabricated and politically motivated.</p>  <p>Police were out in force outside the Moscow courthouse on Tuesday, cordoning off the nearby streets and making random arrests. More than 900 people were detained before and after the court ruling, according to the OVD-Info group that monitors arrests.</p>  <h2>'You can't jail the entire country'&nbsp;</h2>  <p>As the order was read, Navalny smiled and pointed to his wife,&nbsp;Yulia, in the courtroom, making&nbsp;the outline of a heart with his hands in the glass cage where he was being held. "Everything will be fine," he told her as guards led him away.</p>  <p>Navalny was arrested on Jan. 17 upon returning from Germany, where he spent five months recovering from a nerve-agent poisoning that he blames on the Kremlin. Russian authorities deny the charge and claim, despite tests by several European labs, that there is no proof he was poisoned.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5897907.1612292566!/fileImage/httpImage/image.JPG_gen/derivatives/original_300/russia-politics-navalny-protests.JPG 300w,https://i.cbc.ca/1.5897907.1612292566!/fileImage/httpImage/image.JPG_gen/derivatives/original_460/russia-politics-navalny-protests.JPG 460w,https://i.cbc.ca/1.5897907.1612292566!/fileImage/httpImage/image.JPG_gen/derivatives/original_620/russia-politics-navalny-protests.JPG 620w,https://i.cbc.ca/1.5897907.1612292566!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/russia-politics-navalny-protests.JPG 780w,https://i.cbc.ca/1.5897907.1612292566!/fileImage/httpImage/image.JPG_gen/derivatives/original_1180/russia-politics-navalny-protests.JPG 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5897907.1612292566!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/russia-politics-navalny-protests.JPG"></p></div><figcaption>Navalny's wife, Yulia Navalnaya, leaves the courthouse after Tuesday's hearing.<!-- --> <!-- -->(Maxim Shemetov/Reuters)</figcaption></figure></span></p>  <p>Speaking from a glass cage in the courtroom, Navalny attributed his arrest to Putin's "fear and hatred," saying the Russian leader will go down in&nbsp;history as a "poisoner."</p>  <p>"I have deeply offended him simply by surviving the assassination attempt that he ordered," Navalny&nbsp;said.</p>  <p>"The aim of that hearing is to scare a great number of people," he&nbsp;went on. "You can't jail millions. You can't jail the entire country."</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5897490.1612278902!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/1230924913.jpg 300w,https://i.cbc.ca/1.5897490.1612278902!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/1230924913.jpg 460w,https://i.cbc.ca/1.5897490.1612278902!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/1230924913.jpg 620w,https://i.cbc.ca/1.5897490.1612278902!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/1230924913.jpg 780w,https://i.cbc.ca/1.5897490.1612278902!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/1230924913.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5897490.1612278902!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/1230924913.jpg"></p></div><figcaption>Police officers detain people near the Moscow City Court during Navalny's hearing on Tuesday.<!-- --> <!-- -->(Kirill Kudryavtsev/AFP/Getty Images)</figcaption></figure></span></p>  <p>Russia's penitentiary service alleges that Navalny violated the probation conditions of his suspended sentence from a 2014 money-laundering conviction that he has rejected as politically motivated.</p>  <p>He emphasized that the European Court of Human Rights has ruled that his conviction was unlawful and Russia paid him compensation in line with the ruling.</p>  <p>Navalny and his lawyers have argued that while he was recovering in Germany from the poisoning, he couldn't register with Russian authorities in person as required by his probation. Navalny also insisted that his due process rights were crudely violated during his arrest and described his jailing as a travesty of justice.</p>  <p>"I came back to Moscow after I completed the course of treatment," Navalny said during Tuesday's hearing. "What else could I have done?"</p>  <p><span><blockquote lang="en"><p>Canada is appalled by the decision to imprison Russian opposition leader, Alexey &lt;a href="https://twitter.com/navalny?ref_src=twsrc%5Etfw"&gt;@Navalny&lt;/a&gt;. We call on Russia to release those unjustly detained immediately, including peaceful protestors and journalists.</p>&amp;mdash;<a href="https://twitter.com/MarcGarneau/status/1356666097169297414">@MarcGarneau</a></blockquote></span></p>  <h2>Arrests outside&nbsp;court building</h2>  <p>Navalny's jailing has triggered massive protests across Russia for the past two weekends, with tens of thousands taking to the streets to demand his release and chant slogans against Putin.</p>  <p>Police detained more than&nbsp;5,750 people on Sunday, including more than 1,900 in Moscow, the biggest number the country&nbsp;has seen since Soviet times. Most were released after being handed a court summons, and they face fines or jail terms of seven to 15 days. Several people faced criminal charges over alleged violence against police.</p>  <p>"I am fighting and will keep doing it even though I am now in the hands of people who love to put chemical weapons everywhere and no one would give three kopecks for my life," Navalny said.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5897913.1612292966!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/russia-navalny.jpg 300w,https://i.cbc.ca/1.5897913.1612292966!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/russia-navalny.jpg 460w,https://i.cbc.ca/1.5897913.1612292966!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/russia-navalny.jpg 620w,https://i.cbc.ca/1.5897913.1612292966!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/russia-navalny.jpg 780w,https://i.cbc.ca/1.5897913.1612292966!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/russia-navalny.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5897913.1612292966!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/russia-navalny.jpg"></p></div><figcaption>Members of the Russian National Guard gather outside Red Square to prevent a protest rally on Tuesday.<!-- --> <!-- -->(Pavel Golovkin/The Associated Press)</figcaption></figure></span></p>  <p>Some Navalny supporters still managed to approach the building. A young woman climbed a large pile of snow across the street from the courthouse and held up a poster reading,&nbsp;"Freedom to Navalny." Less than a minute later, a police officer took her away.</p>  <p>After his arrest, Navalny's team released a two-hour YouTube video featuring an opulent Black Sea residence allegedly built for Putin.</p>  <p>The video has been viewed more than&nbsp;100 million times, fuelling discontent as ordinary Russians struggle with an economic downturn, the coronavirus pandemic and widespread corruption during Putin's years in office.</p>  <p><strong><em>LISTEN |&nbsp;Alexei Navalny, the 'anti-Putin':</em></strong></p>  <p><span><span><div><div role="button" tabindex="0" title="Alexei Navalny, the 'anti-Putin'"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/547/667/frontburner-640x360.jpg" alt=""></p><p><span>Front Burner</span><span>21:01</span><span>Alexei Navalny, the 'anti-Putin'</span></p></div></div></div><span>Tens of thousands of protesters took to the streets of Moscow, St. Petersburg and across Russia to demand the release of prominent Kremlin critic Alexei Navalny this past weekend. Police used force to break up the protests and detained more than 2,500 people. Navalny is best known for his anti-corruption investigations and was recently the subject of an assassination attempt. After recovering from his poisoning in Germany, Navalny returned to Russia only to be arrested and imprisoned in Moscow. CBC Russia correspondent Chris Brown talks to host Jayme Poisson about the growing movement in support of Navalny, and whether it might actually challenge President Vladimir Putin’s hold on power in Russia.<!-- --> <!-- -->21:01</span></span></span></p>  <p>Putin insisted last week that neither he nor his relatives own any of the properties mentioned in the video, and his longtime confidant, construction magnate Arkady Rotenberg, claimed that he owns it.</p>  <p>As part of efforts to squelch the protests, the authorities have targeted Navalny's associates and activists across the country. His brother Oleg, top ally Lyubov Sobol and several others were put under house arrest for two months and face criminal charges of violating coronavirus restrictions.</p>  <h2>International condemnation</h2>  <p>The jailing of Navalny and the crackdown on protests have stoked international outrage, with Western officials — including Canadian Foreign Affairs Minister Marc Garneau — calling for his release and condemning the arrests of demonstrators.</p>  <p>British Foreign Secretary&nbsp;Dominic Raab was quick to release a condemnation of the ruling.</p>  <p>"Today's perverse ruling, targeting the victim of a poisoning rather than those responsible, shows Russia is failing to meet the most basic commitments expected of any responsible member of the international community," he said.</p>  <p><span><blockquote lang="en"><p>In the wake of Alexei Navalny's arrest, Russian opposition politician &lt;a href="https://twitter.com/vkaramurza?ref_src=twsrc%5Etfw"&gt;@vkaramurza&lt;/a&gt; says it's time for countries like Canada to use targeted sanctions against those surrounding Vladimir Putin, by using the Magnitsky Law. &lt;a href="https://t.co/GqMnuBhrMj"&gt;pic.twitter.com/GqMnuBhrMj&lt;/a&gt;</p>&amp;mdash;<a href="https://twitter.com/PnPCBC/status/1356408149574623234">@PnPCBC</a></blockquote></span></p>  <p>U.S. Secretary of State Antony Blinken called for Navalny's&nbsp;"immediate and unconditional release," while German&nbsp;Foreign Minister Heiko Maas characterized it as "a bitter blow against fundamental freedoms and the rule of law in Russia."</p>  <p>"Sweden and the EU are concerned about the situation with democracy, civil society and human rights in Russia," Swedish Foreign Minister Ann Linde, the current chair of the Organization for Security and Co-operation in Europe, said during talks with Russian Foreign Minister Sergey Lavrov in Moscow.</p>  <p>The diplomat said Navalny's poisoning and the response by Russian authorities to the street protests will be part of the discussion.</p>  <p>European Union foreign policy chief Josep Borrell, who will visit Moscow later this week, has criticized the detentions and the disproportionate use of force against protesters, emphasizing that Russia must comply with its international commitments on human rights.</p>  <p><em><strong>WATCH | Navalny sentenced to prison for parole violation:</strong></em></p>  <p><span><span><div><div title="Navalny sentenced to prison for parole violation" role="button" tabindex="0"><div><div aria-labelledby="1852453443753-metadata-" title="Navalny sentenced to prison for parole violation"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/238/279/navalny-court-russia-brown-020221.jpg" alt="" loading="lazy"></p></div></div></div></div></div><span>A Russian court has sentenced Alexei Navalny, one of Vladimir Putin's fiercest critics, to prison to three and a half years in prison for an alleged parole violation, which he says is politically motivated. The sentencing sparked more protests in Moscow and hundreds were arrested.<!-- --> <!-- -->2:03</span></span></span></p>  <p>Russia has dismissed U.S. and EU officials' criticism as meddling in its domestic affairs and said that Navalny's current situation is a procedural matter for the court, not an issue for the government.</p>  <p>More than a dozen Western diplomats attended Tuesday's court hearing, and Russian Foreign Ministry spokesperson&nbsp;Maria Zakharova charged that their presence was part of efforts by the West to contain Russia, adding that it could be an attempt to exert "psychological pressure" on the judge.</p>  <p>Kremlin spokesperson&nbsp;Dmitry Peskov said Tuesday …</p></span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cbc.ca/news/world/russia-navalny-court-1.5897347">https://www.cbc.ca/news/world/russia-navalny-court-1.5897347</a></em></p>]]>
            </description>
            <link>https://www.cbc.ca/news/world/russia-navalny-court-1.5897347</link>
            <guid isPermaLink="false">hacker-news-small-sites-26004153</guid>
            <pubDate>Tue, 02 Feb 2021 17:50:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Is a Startup Studio? – An Inside Look at Wilbur Labs]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26004021">thread link</a>) | @statico
<br/>
February 2, 2021 | https://www.wilburlabs.com/blueprints/what-is-a-startup-studio-an-inside-look-at-wilbur-labs | <a href="https://web.archive.org/web/*/https://www.wilburlabs.com/blueprints/what-is-a-startup-studio-an-inside-look-at-wilbur-labs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span>Blueprints</span></p><h2><span>What Is a Startup Studio? | An Inside Look at Wilbur Labs</span></h2><div><div><p><img src="https://storage.googleapis.com/wl-blog/author-avatar/Phil_Santoro_Headshot_favicon.jpg" alt="avatar"></p><div><p><span><time>Jan 13, 2021</time> Â· 5 min read</span></p></div></div></div></div><div><div><p dir="ltr">At Wilbur Labs, we are often asked, â€œwhat is a startup studio?â€� The short answer is that a startup studio is a company that builds other companies. When David and I prepared to launch Wilbur Labs in 2016, the startup studio model was still developing. There wasnâ€™t a standard approach, and the business model was unproven.</p>
<p dir="ltr">We had to rethink how companies should be built. We knew that the vast majority of startups fail, and that money alone canâ€™t build big businesses. As a result, we operate very differently from other investors, incubators, or accelerators in existence.</p>
<p dir="ltr">We believe that organizational knowledge, or what we call studio knowledge, is far more valuable than capital. Each time we research an idea, solve a problem, launch a company, and learn from our successes and failures, we build on our studio knowledge. Studio knowledge collects, compounds, and carries through to all current and future portfolio companies. This uniquely allows our portfolio companies to move faster and further than is possible when raising capital through traditional sources.</p>
<p dir="ltr">We also realized that while many investors claim to provide operational support, in reality, this support is mostly limited to high-level advice. When building a startup, execution is everything. We needed to be on the ground floor to effectively help our portfolio companies build and grow. Whether itâ€™s setting up payroll, building a team, maintaining compliance, setting a product roadmap, or acquiring customers, our studio team of entrepreneurs has done this before, bringing battle-tested processes and learnings every step of the way. The end result is a better foundation for growth and fewer distractions for our portfolio company leadership teams, which can focus singularly on building great products for customers.</p>
<p dir="ltr">Three attributes differentiate Wilbur Labs from other investors or methods of building a company: our focus on building companies, providing shared resources across our portfolio to scale at an accelerated pace, and our operational involvement to help each business take off.<br></p></div><h2>A Company That Builds Companies</h2><div><p dir="ltr">Wilbur Labs focuses on turning bold ideas into market-leading companies. While we also invest and acquire existing companies, building from 0 to 1 is our core focus. Launching a startup is typically a one-time event, but at Wilbur Labs, <a href="https://www.wilburlabs.com/blueprints/how-to-get-startup-ideas">generating startup ideas</a>, then <a href="https://www.wilburlabs.com/blueprints/how-to-turn-an-idea-into-a-business">turning those ideas into a business</a>, is a repeatable and standardized process.</p>
<p dir="ltr">We identify big customer pain points and build businesses to solve these problems. After an idea is validated in the Lab, we bring in industry leaders with domain expertise to manage and grow the company. Wilbur Labs continues to provide funding, shared resources, and operational support to ensure management is focused on solving problems that matter.</p></div><h2>Shared Resources</h2><div><p dir="ltr">We have shared resources that allow for more rapid development and faster progression through the idea, launch, and growth stage. From playbooks to shared teams, processes, and infrastructure, these resources allow our companies to move faster than traditional companies.</p>
<p dir="ltr">Distractions and lack of focus are responsible for killing many startups. At Wilbur Labs, we reduce time spent on non-core tasks by giving our companies access to shared resources, advisors, and domain experts. That way, the founding team can focus on solving core user and business problems.<br></p>
</div><h2>Operational Involvement</h2><div><p dir="ltr">Wilbur Labs is more operationally involved, especially early on, compared to accelerators or venture capital firms. We believe in â€œmore wood behind fewer arrows,â€� meaning we build fewer companies with more resources behind each one. By leaning on the experience and repeatable processes of our studio team â€” which launches multiple companies every year â€” weâ€™re able to reduce risk and expedite growth.</p>
<div dir="ltr"><p>Over the years, as others have seen our companies grow at a rapid pace, we have commonly fielded the question, â€œwhat is your secret sauce?â€� The truth is that we focus on solving big problems better, and by doing so, our companies grow. No matter how far you dig into that question, you will never find a single secret sauce, piece of technology, strategy, playbook, tool, or person responsible for what we do best. Instead, digging further into that question will uncover our studio knowledge: 1,000+ processes, plans, decisions, people, playbooks, approaches, technologies, checklists, roadmaps, learnings, and values. Together, this studio knowledge allows us to solve bigger problems, faster, with reduced risk than would otherwise be possible.</p><p>We believe that dedicated, standalone teams are necessary to solve big problems over a long period of time. Our operational involvement is highest at the beginning and then drops as the companyâ€™s team and traction increases.</p></div>
</div><h2>WhatÊ¼s Next</h2><div><p dir="ltr">With our focus on solving big problems using shared studio resources, operational support, and studio knowledge, we still consider this day 1. Since 2016, we have built and invested in over 15 technology companies, including <a href="https://www.vacationrenter.com/">VacationRenter</a>, <a href="https://www.joblist.com/">Joblist</a>, <a href="https://www.vitabox.com/">Vitabox</a>, and <a href="https://www.barkbus.com/">Barkbus</a>, and have several companies at the pre-launch stage. Today, our portfolio companies help billions of people travel the world, find a job, order everyday essentials, take care of their pets, and sign up for the right insurance plan â€” among other daily needs that make a positive impact on peopleâ€™s lives. We believe that continuously challenging the status quo to serve people better is the best way to build sustainable businesses over the long-term. </p>
<p dir="ltr">Our startup studio model is here to build for the next 100+ years â€” not just the next few quarters.</p>
<p>For more information on how we build companies, read our blueprints on how to <a href="https://www.wilburlabs.com/blueprints/how-to-get-startup-ideas">come up with startup ideas</a> or <a href="https://www.wilburlabs.com/blueprints/how-to-turn-an-idea-into-a-business">turn an idea into a business</a>.</p>
<p>Want to work with us or have an idea? We are always looking for talented people to work with and exciting projects to partner on. Feel free to check out our <a href="https://www.wilburlabs.com/careers">available openings</a> or <a href="https://www.wilburlabs.com/contact">contact us</a>.</p>
</div></div><div><p>Wilbur Labs is a San Francisco-based startup studio. We turn bold ideas into market-leading companies.</p><p><a href="https://www.wilburlabs.com/about">Learn More â†’</a></p></div></div>]]>
            </description>
            <link>https://www.wilburlabs.com/blueprints/what-is-a-startup-studio-an-inside-look-at-wilbur-labs</link>
            <guid isPermaLink="false">hacker-news-small-sites-26004021</guid>
            <pubDate>Tue, 02 Feb 2021 17:43:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gigafactory Berlin will be filled with graffiti art, says Elon Musk]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26003860">thread link</a>) | @CarCooler
<br/>
February 2, 2021 | https://www.teslaoracle.com/2021/02/02/gigafactory-berlin-filled-graffiti-art-elon-musk/ | <a href="https://web.archive.org/web/*/https://www.teslaoracle.com/2021/02/02/gigafactory-berlin-filled-graffiti-art-elon-musk/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
			<figure data-amp-original-style="margin-bottom:30px;">
            <figcaption data-amp-original-style="border:1px dotted blue; margin:2px 0; text-align:center;">Advertisement</figcaption>
            <amp-ad width="100vw" height="320" type="adsense" data-ad-client="ca-pub-0923072950810999" data-ad-slot="4076643206" data-auto-format="rspv" data-full-width="" i-amphtml-layout="fixed">
              
            </amp-ad>
            </figure>
				<!-- .Adsense Ad -->

		
<p>According to his last tweet, Tesla CEO Elon Musk is now enjoying his Twitter holiday for a while. But before his temporary leave, he dropped an interesting bit about Tesla Gigafactory Berlin, “It will be filled with graffiti art,” he responded to his own drone video of the factory construction progress.</p>



<figure></figure>



<p>You can expect anything from <a href="https://www.teslaoracle.com/topic/elon-musk/">Elon Musk</a>‘s wildly imaginative mind. Looks like this idea is not too odd coming from the Meme Lord himself, who also happens to be the owner of stankmemes.com — just awesome!</p>



<div><figure><a href="https://evannex.com/?ref=Iqtidar_TeslaOracle_EVANNEX_Banner" target="_blank" rel="sponsored noopener noreferrer"><amp-img src="https://www.teslaoracle.com/wp-content/uploads/2020/10/evannex_googlead_300x250.jpg" alt="" width="300" height="250" layout="intrinsic" i-amphtml-layout="intrinsic"><img src="https://www.teslaoracle.com/wp-content/uploads/2020/10/evannex_googlead_300x250.jpg" alt="" width="300" height="250" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzI1MCcgd2lkdGg9JzMwMCcgeG1sbnM9J2h0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnJyB2ZXJzaW9uPScxLjEnLz4="></amp-img></a><figcaption>– Sponsored –</figcaption></figure></div>



<p>Using my Photoshop ninjitsu I overlayed a graffiti photo above the roof of Gigafactory Berlin and it does look kind of cool. However, it is not clear from Elon Musk’s short tweet if the entire factory will be painted with graffiti art or just the selected portions of the huge manufacturing structure will be filled.</p>



<figure data-amp-lightbox="true"><amp-img width="1024" height="576" src="https://www.teslaoracle.com/wp-content/uploads/2021/02/Giga-Berlin-Grafitti-1024x576.jpg" alt="An illustration of Tesla Gigafactory Berlin roof filled with graffiti art." srcset="https://www.teslaoracle.com/wp-content/uploads/2021/02/Giga-Berlin-Grafitti-1024x576.jpg 1024w, https://www.teslaoracle.com/wp-content/uploads/2021/02/Giga-Berlin-Grafitti-300x169.jpg 300w, https://www.teslaoracle.com/wp-content/uploads/2021/02/Giga-Berlin-Grafitti-768x432.jpg 768w, https://www.teslaoracle.com/wp-content/uploads/2021/02/Giga-Berlin-Grafitti-1200x675.jpg 1200w, https://www.teslaoracle.com/wp-content/uploads/2021/02/Giga-Berlin-Grafitti.jpg 1280w" sizes="(max-width: 1024px) 100vw, 1024px" data-amp-lightbox="" lightbox="" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"><img loading="lazy" width="1024" height="576" src="https://www.teslaoracle.com/wp-content/uploads/2021/02/Giga-Berlin-Grafitti-1024x576.jpg" alt="An illustration of Tesla Gigafactory Berlin roof filled with graffiti art." srcset="https://www.teslaoracle.com/wp-content/uploads/2021/02/Giga-Berlin-Grafitti-1024x576.jpg 1024w, https://www.teslaoracle.com/wp-content/uploads/2021/02/Giga-Berlin-Grafitti-300x169.jpg 300w, https://www.teslaoracle.com/wp-content/uploads/2021/02/Giga-Berlin-Grafitti-768x432.jpg 768w, https://www.teslaoracle.com/wp-content/uploads/2021/02/Giga-Berlin-Grafitti-1200x675.jpg 1200w, https://www.teslaoracle.com/wp-content/uploads/2021/02/Giga-Berlin-Grafitti.jpg 1280w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzU3Nicgd2lkdGg9JzEwMjQnIHhtbG5zPSdodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZycgdmVyc2lvbj0nMS4xJy8+"></amp-img><figcaption>An illustration of Tesla Gigafactory Berlin roof filled with graffiti art. Image Sources: Tesla, EVClicks.co.uk. Editing: Iqtidar Ali / TeslaOracle.com</figcaption></figure>



<p>Usually, a large area of a Gigafactory roof is reserved for solar panels to absorb vast amounts of energy that the Sun provides us for free and without polluting our environment. The initial <a href="https://www.teslaoracle.com/tag/giga-berlin/">Gigafactory Berlin</a> render posted by Tesla also shows a large number of solar panels on its roof. However, there are blank spaces on the roof as well, perfect for painting some Giga Graffiti art.</p>



<figure data-amp-lightbox="true"><amp-img width="1024" height="576" src="https://www.teslaoracle.com/wp-content/uploads/2020/07/Giga-Berlin-Model-Y-Factory-Render-1024x576.jpg" alt="Tesla Gigafactory Berlin Render (Model Y Factory)." srcset="https://www.teslaoracle.com/wp-content/uploads/2020/07/Giga-Berlin-Model-Y-Factory-Render-1024x576.jpg 1024w, https://www.teslaoracle.com/wp-content/uploads/2020/07/Giga-Berlin-Model-Y-Factory-Render-300x169.jpg 300w, https://www.teslaoracle.com/wp-content/uploads/2020/07/Giga-Berlin-Model-Y-Factory-Render-768x432.jpg 768w, https://www.teslaoracle.com/wp-content/uploads/2020/07/Giga-Berlin-Model-Y-Factory-Render.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px" data-amp-lightbox="" lightbox="" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"><img loading="lazy" width="1024" height="576" src="https://www.teslaoracle.com/wp-content/uploads/2020/07/Giga-Berlin-Model-Y-Factory-Render-1024x576.jpg" alt="Tesla Gigafactory Berlin Render (Model Y Factory)." srcset="https://www.teslaoracle.com/wp-content/uploads/2020/07/Giga-Berlin-Model-Y-Factory-Render-1024x576.jpg 1024w, https://www.teslaoracle.com/wp-content/uploads/2020/07/Giga-Berlin-Model-Y-Factory-Render-300x169.jpg 300w, https://www.teslaoracle.com/wp-content/uploads/2020/07/Giga-Berlin-Model-Y-Factory-Render-768x432.jpg 768w, https://www.teslaoracle.com/wp-content/uploads/2020/07/Giga-Berlin-Model-Y-Factory-Render.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzU3Nicgd2lkdGg9JzEwMjQnIHhtbG5zPSdodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZycgdmVyc2lvbj0nMS4xJy8+"></amp-img><figcaption>Tesla Gigafactory Berlin Render (Model Y Factory). Source: Tesla Inc. (TSLA).</figcaption></figure>



<p>Snowfall at the Gigafactory Berlin-Brandenburg has covered the entire factory roof and land for a while now. This has made the factory look whiter than ever. Tobias Lindh, a local Giga Berlin observer has covered this in his latest drone photos and video from this past weekend.</p>



<p>Tesla’s next US <a href="https://www.teslaoracle.com/tag/giga-austin/">Gigafactory in Austin, Texas</a> also received a rare snowfall around the Christmas days, <a href="https://www.teslaoracle.com/2021/01/11/under-construction-giga-texas-looks-majestic-on-a-snowy-day-drone-video/">captured in a drone video</a>.</p>



<figure>
<amp-ad width="100vw" height="320" type="adsense" data-ad-client="ca-pub-0923072950810999" data-ad-slot="7514654329" data-auto-format="rspv" data-full-width="" i-amphtml-layout="fixed">
  
</amp-ad>
</figure>



<figure data-amp-lightbox="true"><amp-img width="1024" height="512" src="https://www.teslaoracle.com/wp-content/uploads/2021/02/Gigafactory-Berlin-Roof_30-1-2021_Tobias-Lindh-web-1024x512.jpg" alt="The giant Gigafactory Berlin roof in snow. Aerial photo taken on 01-30-2021 by Tobias Lindh / YouTube." srcset="https://www.teslaoracle.com/wp-content/uploads/2021/02/Gigafactory-Berlin-Roof_30-1-2021_Tobias-Lindh-web-1024x512.jpg 1024w, https://www.teslaoracle.com/wp-content/uploads/2021/02/Gigafactory-Berlin-Roof_30-1-2021_Tobias-Lindh-web-300x150.jpg 300w, https://www.teslaoracle.com/wp-content/uploads/2021/02/Gigafactory-Berlin-Roof_30-1-2021_Tobias-Lindh-web-768x384.jpg 768w, https://www.teslaoracle.com/wp-content/uploads/2021/02/Gigafactory-Berlin-Roof_30-1-2021_Tobias-Lindh-web-1536x768.jpg 1536w, https://www.teslaoracle.com/wp-content/uploads/2021/02/Gigafactory-Berlin-Roof_30-1-2021_Tobias-Lindh-web-1200x600.jpg 1200w, https://www.teslaoracle.com/wp-content/uploads/2021/02/Gigafactory-Berlin-Roof_30-1-2021_Tobias-Lindh-web.jpg 1920w" sizes="(max-width: 1024px) 100vw, 1024px" data-amp-lightbox="" lightbox="" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"><img loading="lazy" width="1024" height="512" src="https://www.teslaoracle.com/wp-content/uploads/2021/02/Gigafactory-Berlin-Roof_30-1-2021_Tobias-Lindh-web-1024x512.jpg" alt="The giant Gigafactory Berlin roof in snow. Aerial photo taken on 01-30-2021 by Tobias Lindh / YouTube." srcset="https://www.teslaoracle.com/wp-content/uploads/2021/02/Gigafactory-Berlin-Roof_30-1-2021_Tobias-Lindh-web-1024x512.jpg 1024w, https://www.teslaoracle.com/wp-content/uploads/2021/02/Gigafactory-Berlin-Roof_30-1-2021_Tobias-Lindh-web-300x150.jpg 300w, https://www.teslaoracle.com/wp-content/uploads/2021/02/Gigafactory-Berlin-Roof_30-1-2021_Tobias-Lindh-web-768x384.jpg 768w, https://www.teslaoracle.com/wp-content/uploads/2021/02/Gigafactory-Berlin-Roof_30-1-2021_Tobias-Lindh-web-1536x768.jpg 1536w, https://www.teslaoracle.com/wp-content/uploads/2021/02/Gigafactory-Berlin-Roof_30-1-2021_Tobias-Lindh-web-1200x600.jpg 1200w, https://www.teslaoracle.com/wp-content/uploads/2021/02/Gigafactory-Berlin-Roof_30-1-2021_Tobias-Lindh-web.jpg 1920w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzUxMicgd2lkdGg9JzEwMjQnIHhtbG5zPSdodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZycgdmVyc2lvbj0nMS4xJy8+"></amp-img><figcaption>The giant Gigafactory Berlin roof in snow. Aerial photo as taken on 01-30-2021 by Tobias Lindh / YouTube (full video below).</figcaption></figure>



<p>The front part seen in the above picture is the roof of the casting area where <a href="https://www.teslaoracle.com/2020/10/19/footings-for-the-giga-casting-machines-at-giga-berlin-are-being-prepared/">8 Tesla Giga Casting machines</a> will be installed for producing Model Y single-piece rear and front underbody castings.</p>



<p>Tesla has been constantly hiring engineers and related staff for Giga Berlin. Just before last Christmas, the automaker posted an interesting <a href="https://www.teslaoracle.com/2020/12/24/tesla-gives-a-sneak-preview-of-4680-cell-production-at-giga-berlin-in-the-latest-video/">video showcasing the future 4680 cell production</a> at Giga Berlin asking engineers to apply for related jobs.</p>



<p>During the <a href="https://www.teslaoracle.com/2021/02/01/listen-to-tesla-q4-2020-earnings-call-detailed-summary-of-musks-answers/">Tesla Q4 2020 Earnings Call</a>, CEO Elon Musk said that Gigafactory Berlin will start producing <a href="https://www.teslaoracle.com/topic/model-y/">Tesla Model Y SUVs</a> later this year. Competition in the European electric vehicle market will stiffen after Giga Berlin becomes functional and the EV landscape will become more interesting.</p>



<p>Stay tuned for constant Tesla updates, follow us on:&nbsp;<br><a href="https://news.google.com/publications/CAAqBwgKMOarmgswgLayAw" target="_blank" rel="noreferrer noopener">Google News</a>&nbsp;|&nbsp;<a href="https://flipboard.com/@TeslaOracle" target="_blank" rel="noreferrer noopener nofollow">Flipboard</a>&nbsp;|&nbsp;<a href="https://feedly.com/i/subscription/feed%2Fhttps%3A%2F%2Fwww.teslaoracle.com%2Ffeed%2F" target="_blank" rel="noreferrer noopener nofollow">RSS (Feedly)</a>.</p>



<figure><div>
<amp-youtube data-videoid="94P9giyaRD4" layout="responsive" width="700" height="394" title="Giga Berlin | 2021-01-30 | Casting roof" i-amphtml-layout="responsive"><i-amphtml-sizer></i-amphtml-sizer><a placeholder="" href="https://www.youtube.com/watch?v=94P9giyaRD4"><amp-img src="https://i.ytimg.com/vi/94P9giyaRD4/hqdefault.jpg" layout="fill" object-fit="cover" alt="Giga Berlin | 2021-01-30 | Casting roof" i-amphtml-layout="fill"></amp-img></a></amp-youtube>
</div><figcaption>Drone video of Tesla Gigafactory Berlin shot on 01-30-2021 by Tobias Lindh.</figcaption></figure>
		<!-- Adsense Matched -->
        <figure>
        <amp-ad width="100vw" height="320" type="adsense" data-ad-client="ca-pub-0923072950810999" data-ad-slot="9763094783" data-auto-format="mcrspv" data-full-width="" i-amphtml-layout="fixed">
          
        </amp-ad>
        </figure><!-- Adsense Matched End -->
		</div></div>]]>
            </description>
            <link>https://www.teslaoracle.com/2021/02/02/gigafactory-berlin-filled-graffiti-art-elon-musk/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26003860</guid>
            <pubDate>Tue, 02 Feb 2021 17:32:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A cool coding library I somehow overlooked – FSharpPlus]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26003793">thread link</a>) | @todsacerdoti
<br/>
February 2, 2021 | https://danielbmarkham.com/how-didnt-i-know-about-this-fsharpplus/ | <a href="https://web.archive.org/web/*/https://danielbmarkham.com/how-didnt-i-know-about-this-fsharpplus/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div id="post-body">
        <p>The other day somebody on reddit asked the age-old question: <a href="https://old.reddit.com/r/fsharp/comments/la1mz5/a_simple_question/">why didn't F# have typeclasses or functors?</a></p><p>That's a long discussion, but while reading replies, somebody mentioned this cool litte <a href="https://github.com/fsprojects/FSharpPlus">F#+ library.</a></p><p>Over to GitHub we go!</p><p>Over the years, as I've written more and more solutions in F#, I've come across stuff I wanted to do where it seemed as if I were fighting the language too much. Stuff like common conversions with strings. Turns out a lot of other people have those issues also, so folks started collecting little goodies here and there. You're coding along, and suddenly you realize you want to make sure that string is all lower case. Wouldn't it be nice if there were a method to automatically do that, something like "foo".toLower()?</p><p>As most every coder knows, that's already don. It's in there. But it's not just that one little method. During regular coding you run across all kinds of stuff that hasn't been coded. Let's say you want to put hyphens in a string (why, I don't know)</p><!--kg-card-begin: markdown--><pre><code>    // Extensions
    let allCapsString = "I LIKE HYPHENS!"
    printfn "Extensions to core types"
    printfn "Original"
    printfn "%s" allCapsString
    let stickSomeHyphensInThere =  String.intersperse '-'
    printfn "Fixed"
    printfn "%s" (stickSomeHyphensInThere allCapsString)
    ```</code></pre>
<!--kg-card-end: markdown--><p>That's trivial stuff, but damn stuff like that gets old. And it's not just trivial stuff. Let's you've got a list and you're expecting only one element in it. Lots of business logic revolves around making sure you have one and only one thing. How about this?</p><!--kg-card-begin: markdown--><pre><code>    let singletonTestData1=[1]
    let singletonTestData2=[]
    // reuturns the value or throws an error
    let singletonRet1=List.exactlyOne singletonTestData1
    // returns the value or none
    let singletonRet2:Option&lt;int&gt;=
        Option.protect List.exactlyOne singletonTestData2
</code></pre>
<!--kg-card-end: markdown--><p>That's pretty nifty because you can make sure it's only one item (or throw an error), catch the error and deal with it later (not shown here), or bail out on any decision-making entirely and let somebody else worry about it, ie, use an option.</p><p>I imagine we could do the same with atLeastOne. In fact, I might code that up as a PR. That's also a very common business requirement.</p><p>And you can extend generics too. How many times have you written a function and wanted to use it later as an operator? That kinda thing is fairly common in C++, and you can certainly do it in NET, but many times to get it done it seems unnecessarily complicated. How about this?</p><!--kg-card-begin: markdown--><pre><code>
    // turn any function into an operator
    let smallerThan a b=a &lt; b
    // isSmaller = true
    let isSmaller = 10 &lt;/smallerThan/&gt; 20
    ```</code></pre>
<!--kg-card-end: markdown--><p>I'm not crazy about that syntax, but fooling around with it some, I can see where the FSharpPlus guys were coming from. There are some odd language issues at stake, and this looks like a good compromise. I think this works better than some of the other options.</p><p>Once again, none of this is rocket science. All along you could have made this happen in whatever .NET language you use. It's nice having it already in there. Thanks guys!</p><p>I saw this one and almost had a nerdgasm. Every now and then you'll have a string and want to convert it to bytes, perhaps for some low-level fun with bits. Ever try to do that from scratch? Wow, it's a pain. There are excellent reasons it's a pain: there's encoding, there's collation rules, the list goes on and on. Human languages are tough. But what about just a dang default? Try this.</p><!--kg-card-begin: markdown--><pre><code>    // Generic operators
    // Whatever I've got, make it bytes
    let myBufferBytes =
        "This is something I need to do bit-level stuff with" |&gt; toBytes
        ```</code></pre>
<!--kg-card-end: markdown--><p>Because that's a type extension on a generic, that works with all types of stuff. Just throw whatever you've got to toBytes and move on.</p><p>You can do this on your own, but you'll kill precious development time (and focus) wading through docs. And if you only do it one or two times a year it'll be that same pain, over and over again.</p><!--kg-card-begin: markdown--><pre><code>    // Need to splay out a bunch of processing and then sum when done?
    let res42 = map ((+) 21) (async {return 21})
    let myComputationallyHardAnswer = extract res42
</code></pre>
<!--kg-card-end: markdown--><p>Here we've wrapped up some common threading stuff along with collection traversal.</p><p>Of course, it's all composable with all of the other tools you have.</p><p>In another post I'll do some of the other cool stuff, like all of the mondad things they have, &nbsp;but that really gets into the technical part of coding itself instead of the convenience provided here. For now, <a href="https://github.com/fsprojects/FSharpPlus">you should check it out</a>.</p><figure><img src="https://danielbmarkham.com/content/images/2021/02/2018-12-Daniel-Signature.png" alt="" srcset="https://danielbmarkham.com/content/images/size/w600/2021/02/2018-12-Daniel-Signature.png 600w, https://danielbmarkham.com/content/images/size/w1000/2021/02/2018-12-Daniel-Signature.png 1000w, https://danielbmarkham.com/content/images/size/w1600/2021/02/2018-12-Daniel-Signature.png 1600w, https://danielbmarkham.com/content/images/size/w2400/2021/02/2018-12-Daniel-Signature.png 2400w" sizes="(min-width: 720px) 720px"></figure>    </div>
</div></div>]]>
            </description>
            <link>https://danielbmarkham.com/how-didnt-i-know-about-this-fsharpplus/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26003793</guid>
            <pubDate>Tue, 02 Feb 2021 17:27:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Revolut has stopped trading GME and AMC]]>
            </title>
            <description>
<![CDATA[
Score 74 | Comments 34 (<a href="https://news.ycombinator.com/item?id=26003731">thread link</a>) | @powerandr
<br/>
February 2, 2021 | https://www.mrhack.io/blog/revolut-stops-trading-gme-amc-stocks-statement/ | <a href="https://web.archive.org/web/*/https://www.mrhack.io/blog/revolut-stops-trading-gme-amc-stocks-statement/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page-content" itemprop="mainContentOfPage">
	<section><div><div><div><div><div><div><p><i></i>3,949<span> views</span></p><p><time datetime="2021-02-02T17:20:03+00:00" title="2 February 2021 at 17:20:03 +00:00" itemprop="datePublished">2 Feb at 5:20 pm</time></p></div><div><div><p><iframe title="Breaking - Revolut STOPS TRADING $GME &amp; $AMC stocks" width="640" height="360" src="https://www.youtube.com/embed/1d2bB1PfSTI?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p></div></div><div itemprop="text"><p>Here is a full statement from Revolut.</p>
<p>Revolut customers in Europe received this email around 4.54PM CET.</p>
<h2>Trading Update for GME &amp; AMC</h2>
<div>
<div>
<div>
<div>
<div>
<div>
<p>Hi …,</p>
<p>From today, we will only be able to facilitate the selling of GameStop (NYSE: <strong>GME</strong>) and AMC Entertainment (NYSE: <strong>AMC</strong>) stocks for the time being. Unfortunately, our broker-dealer in the US, DriveWealth, can no longer offer Buys on these stocks due to increased capital requirements set by the Depository Trust Company (DTC) in the US.</p>
<h3>What does this mean for me?</h3>
<p>You can only sell out your existing holdings in these stocks. Any outstanding buy orders on these two symbols made after Monday’s (1 February) close will automatically be cancelled prior to market open on February 2 2021.</p>
<p>None of our other stocks are affected at this time and are available to trade as normal.</p>
<p>For customers with no holdings in these 2 stocks, neither GME, nor AMC will appear when searched. This is a standard practice when a position moves to sell only, as we don’t want to show you stocks you’re not able to buy at that time. As soon as they become available to buy again, you’ll be able to see them in the app.</p>
</div>
</div>
</div>
</div>
</div>
</div>
<div>
<div>
<div>
<div>
<div>
<div>
<h3>Why is this happening?</h3>
<p>When a stock is traded, it takes two days for the proceeds to go from the broker to the clearing house. This is known as T+2 settlement. Within this time, the clearing house requires the broker to front cash or capital guarantees to ensure funds are available through the settlement process.</p>
<p>The required amount of capital is usually around 10-15% of the value of a security’s holdings on broker’s books. However, this percentage can vary based on stock volatility. In the case of GME and AMC, the DTC has enforced an increase of capital requirements by 250% upon DriveWealth’s clearing partners.</p>
<p>This increase means that DriveWealth is now obligated to restrict trading in GME and AMC, as each stock has its own capital requirement rather than a broker wide requirement.</p>
</div>
</div>
</div>
</div>
</div>
</div>
<div>
<div>
<div>
<div>
<div>
<div>
<h3>When will they be available again to buy?</h3>
<p>This is not a decision Revolut has made, simply one that we are obligated to carry out. We are monitoring the situation very closely and will update you when our partner, DriveWealth, re-enables Buys for GME and AMC. We apologise for any inconvenience caused.</p>
<p>Team Revolut</p>
</div>
</div>
</div>
</div>
</div>
</div>
<div>
<div>
<div>
<div>
<div>
<div>
<p><strong>Capital at Risk</strong></p>
<p>The value of a stock may fall as well as rise and you may get back less than what you initially paid, and in some cases the stock may lose its entire value and you may lose your initial investment. This is not investment advice. It is strongly recommended that you seek professional investment advice before making any investment decision.</p>
<p><strong>Disclaimer:</strong> Revolut Trading Ltd. is an appointed representative of Resolution Compliance Ltd which is authorised and regulated by the Financial Conduct Authority (FRN:574048).</p>
</div>
</div>
</div>
</div>
</div>
</div>
<p>Revolut is one of the most popular investing apps in Europe. Maybe it is not that well-known in US yet.</p>
<p>But, until recently, it was one of possible alternatives to Robinhood to buy $GME and $AMC stocks.<br>
<iframe title="How to buy $GME &amp; $AMC stock in Revolut app?" width="640" height="360" src="https://www.youtube.com/embed/82uUmO9L80o?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>
What are alternatives to Revolut in Europe – to buy $GME and $AMC stocks?</p>
<p>According to <a href="https://invezz.com/news/2021/02/02/revolut-competitors/" target="_blank" rel="noopener">Invezz</a>, you can still buy these stocks in:</p>
<ul>
<li>Saxo</li>
<li>BlackBull markets</li>
<li>AvaTrade</li>
</ul>


<blockquote>
<p lang="en" dir="ltr">Revolut in the UK. WOW. <a href="https://twitter.com/wsbmod?ref_src=twsrc%5Etfw">@wsbmod</a> <a href="https://t.co/ypLOGVsMLl">pic.twitter.com/ypLOGVsMLl</a></p>
<p>— Nakamoto Plaza (@NakamotoPlaza) <a href="https://twitter.com/NakamotoPlaza/status/1356626544173711360?ref_src=twsrc%5Etfw">February 2, 2021</a></p></blockquote>

<blockquote>
<p lang="en" dir="ltr">The GameStop stock is tanking. Who knows where it goes from here, but if you're someone who's been trying to hang on, curious to hear what the ride has been like for you. My DMs are open, email is patrick.klepek@vice.com</p>
<p>— Patrick Klepek (@patrickklepek) <a href="https://twitter.com/patrickklepek/status/1356636750471389190?ref_src=twsrc%5Etfw">February 2, 2021</a></p></blockquote>

<blockquote>
<p lang="en" dir="ltr"><a href="https://twitter.com/freetrade?ref_src=twsrc%5Etfw">@freetrade</a> deciding to mysteriously limit stock purchases for <a href="https://twitter.com/hashtag/GME?src=hash&amp;ref_src=twsrc%5Etfw">#GME</a> and <a href="https://twitter.com/hashtag/AMC?src=hash&amp;ref_src=twsrc%5Etfw">#AMC</a> but still letting you put in sell orders before market open today.</p>
<p>Going the way of <a href="https://twitter.com/RobinhoodApp?ref_src=twsrc%5Etfw">@RobinhoodApp</a> are we? 🤔🤔🤔</p>
<p>— Vall Syrene – Legendary Hunts Out Now! #BLM (@Valldoesdnd) <a href="https://twitter.com/Valldoesdnd/status/1356249868675780612?ref_src=twsrc%5Etfw">February 1, 2021</a></p></blockquote>

<blockquote>
<p lang="en" dir="ltr">Now <a href="https://twitter.com/hashtag/revolut?src=hash&amp;ref_src=twsrc%5Etfw">#revolut</a> is also not allowing GME or AMC… :/ <a href="https://twitter.com/search?q=%24gme&amp;src=ctag&amp;ref_src=twsrc%5Etfw">$gme</a> <a href="https://twitter.com/search?q=%24amc&amp;src=ctag&amp;ref_src=twsrc%5Etfw">$amc</a> <a href="https://t.co/X68sL8y24X">pic.twitter.com/X68sL8y24X</a></p>
<p>— Michael (@MykeJD1) <a href="https://twitter.com/MykeJD1/status/1356609588569726977?ref_src=twsrc%5Etfw">February 2, 2021</a></p></blockquote>


</div></div></div></div></div></div></section>
</div></div>]]>
            </description>
            <link>https://www.mrhack.io/blog/revolut-stops-trading-gme-amc-stocks-statement/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26003731</guid>
            <pubDate>Tue, 02 Feb 2021 17:22:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Is React: A Visual Introduction for Beginners]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26003666">thread link</a>) | @swyx
<br/>
February 2, 2021 | https://learnreact.design/posts/what-is-react | <a href="https://web.archive.org/web/*/https://learnreact.design/posts/what-is-react">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2><a id="introduction" href="#introduction"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="20" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg>Introduction</a></h2><blockquote><p>React is a JavaScript library for building user interfaces.</p></blockquote><p>This is the official definition of React. But what if you are not familiar with JavaScript? What if you are not a developer? Would you still be able to make sense of (and learn) React?</p><p>My answer is a firm YES. That's why I wrote this article: what is React exactly? Why is it so popular? What problems does React solve?</p><p>This article is an introduction to React for beginners. It's the first post you'd want to read before learning the specifics of React. I'll explain the core ideas of React in plain English (and doodles <span>🌴</span>). No JavaScript experience? No problem! As long as you have some basic HTML knowledge (e.g. the format of an HTML tag), you should be able to enjoy this article.</p><p>This is a bird's-eye view <span>🦅</span> but I'll also equip you with a pair of binoculars <svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" viewBox="0 -48 512 512"><g fill="#40404c"><path d="M211.023 137.027h89.95v145.938h-89.95zm0 0M298.3 72.402V52.211c0-24.637 19.973-44.61 44.614-44.61a44.665 44.665 0 0124.809 7.528 44.657 44.657 0 0116.425 20.066l7.207 17.473"></path><path d="M279.29 123.621v171.84l128.757-23.563 89.082-16.308L430.344 93.69a78.505 78.505 0 00-28.906-35.308 78.457 78.457 0 00-47.641-13.153c-41.5 2.067-74.508 36.383-74.508 78.391zm0 0"></path></g><path fill="#5b5b68" d="M353.797 45.23l54.25 226.668 89.082-16.308L430.344 93.69a78.505 78.505 0 00-28.906-35.308 78.457 78.457 0 00-47.641-13.153zm0 0"></path><path fill="#e4e4ef" d="M504.398 295.457c0 62.164-50.394 112.559-112.558 112.559-62.164 0-112.555-50.395-112.555-112.559 0-62.164 50.39-112.559 112.555-112.559 62.164 0 112.558 50.395 112.558 112.559zm0 0"></path><path fill="#40404c" d="M471.434 295.457c0 43.957-35.637 79.59-79.594 79.59-43.953 0-79.59-35.633-79.59-79.59s35.637-79.59 79.59-79.59c43.957 0 79.594 35.633 79.594 79.59zm0 0"></path><path fill="#589ce0" d="M314.191 277.918c7.985 35.52 39.715 62.062 77.641 62.062 37.922 0 69.664-26.542 77.648-62.062-7.984-35.52-39.714-62.055-77.64-62.055-37.934 0-69.664 26.535-77.649 62.055zm0 0"></path><path fill="#40404c" d="M120.645 52.668l7.203-17.473a44.69 44.69 0 0116.43-20.066 44.665 44.665 0 0124.808-7.527c24.637 0 44.613 19.972 44.613 44.609v20.191"></path><path fill="#5b5b68" d="M232.71 123.621v171.84l-128.757-23.563-89.082-16.308L81.656 93.69a78.522 78.522 0 0128.903-35.308 78.479 78.479 0 0147.644-13.153c41.5 2.067 74.508 36.383 74.508 78.391zm0 0"></path><path fill="#40404c" d="M158.203 45.23l-54.25 226.668-89.082-16.308L81.656 93.69a78.522 78.522 0 0128.903-35.308 78.479 78.479 0 0147.644-13.153zm0 0"></path><path fill="#e4e4ef" d="M232.715 295.457c0 62.164-50.39 112.559-112.555 112.559-62.164 0-112.558-50.395-112.558-112.559 0-62.164 50.394-112.559 112.558-112.559 62.164 0 112.555 50.395 112.555 112.559zm0 0"></path><path fill="#40404c" d="M199.75 295.457c0 43.957-35.637 79.59-79.59 79.59-43.957 0-79.594-35.633-79.594-79.59s35.637-79.59 79.594-79.59c43.953 0 79.59 35.633 79.59 79.59zm0 0"></path><path fill="#589ce0" d="M197.809 277.918c-7.985 35.52-39.715 62.062-77.641 62.062-37.922 0-69.664-26.542-77.648-62.062 7.984-35.52 39.714-62.055 77.64-62.055 37.934 0 69.664 26.535 77.649 62.055zm0 0"></path><path fill="#357fbc" d="M89.21 295.46c0 15.548 4.45 30.04 12.165 42.29-29.281-7.094-52.234-30.371-58.863-59.832 7.988-35.52 39.718-62.055 77.64-62.055a79.306 79.306 0 0124.325 3.793C112.422 229.93 89.21 259.98 89.21 295.461zm0 0M360.89 295.46c0 15.548 4.45 30.04 12.165 42.29-29.282-7.094-52.235-30.371-58.864-59.832 7.989-35.52 39.72-62.055 77.641-62.055 8.484 0 16.66 1.328 24.324 3.793-32.054 10.274-55.265 40.324-55.265 75.805zm0 0"></path><path d="M120.16 208.266c-48.078 0-87.191 39.113-87.191 87.191s39.113 87.191 87.191 87.191c48.074 0 87.188-39.113 87.188-87.191s-39.114-87.191-87.188-87.191zm0 15.203c33.645 0 61.961 23.203 69.817 54.445-3.766 15.024-12.426 28.625-24.551 38.45-12.75 10.327-28.824 16.015-45.262 16.015-16.441 0-32.516-5.688-45.27-16.016-12.124-9.824-20.789-23.425-24.554-38.449 7.855-31.242 36.172-54.445 69.82-54.445zm0 143.976c-33.863 0-62.32-23.504-69.96-55.05a87.387 87.387 0 0015.128 15.78c15.45 12.516 34.922 19.407 54.836 19.407 19.91 0 39.383-6.89 54.832-19.406a87.712 87.712 0 0015.121-15.778c-7.644 31.543-36.097 55.047-69.957 55.047zm0 0"></path><path d="M504.188 252.852a225.242 225.242 0 00-2.055-5.059l-64.762-157c-7.98-19.344-22.355-34.59-40.105-43.727l-6.09-14.77A52.095 52.095 0 00371.94 8.81 52.135 52.135 0 00342.911 0c-28.79 0-52.212 23.422-52.212 52.21v17.528c-11.883 14.766-19.02 33.504-19.02 53.887v5.8h-31.363v-5.8c0-20.383-7.136-39.121-19.02-53.887V52.211C221.297 23.42 197.876 0 169.087 0c-10.36 0-20.399 3.047-29.04 8.816a52.092 52.092 0 00-19.226 23.48l-6.09 14.77C96.984 56.203 82.605 71.45 74.63 90.793l-16.625 40.3a7.6 7.6 0 004.129 9.927 7.593 7.593 0 009.922-4.13l16.625-40.3c10.992-26.645 36.718-43.86 65.539-43.86 39.09 0 70.894 31.801 70.894 70.895V237.02c-20.566-36.79-59.902-61.723-104.957-61.723-28.219 0-54.191 9.785-74.719 26.129l16.407-39.774c1.601-3.879-.25-8.324-4.13-9.925-3.878-1.602-8.323.25-9.925 4.128L9.867 247.79c-.594 1.367-2.215 5.414-2.289 5.672C2.684 266.539 0 280.69 0 295.457c0 66.254 53.902 120.156 120.16 120.156 66.254 0 120.156-53.902 120.156-120.156v-4.89h31.368v4.89c0 66.254 53.902 120.156 120.156 120.156 66.258 0 120.16-53.902 120.16-120.156 0-14.996-2.77-29.355-7.813-42.605zM154.217 37.527c-6.874 0-13.6.82-20.081 2.36l.738-1.793a36.915 36.915 0 0113.621-16.64 36.969 36.969 0 0120.59-6.255c20.406 0 37.012 16.606 37.012 37.012v2.754c-14.438-10.934-32.41-17.438-51.88-17.438zM342.915 15.2c7.344 0 14.461 2.164 20.578 6.246a36.926 36.926 0 0113.633 16.649l.738 1.793a86.64 86.64 0 00-20.086-2.36c-19.465 0-37.437 6.504-51.875 17.438V52.21c0-20.406 16.602-37.012 37.012-37.012zm-56.027 108.426c0-39.094 31.8-70.895 70.894-70.895 28.82 0 54.547 17.215 65.535 43.86l43.247 104.836c-20.528-16.344-46.504-26.13-74.723-26.13-45.055 0-84.39 24.934-104.953 61.72zm-15.203 21.004v72.969h-31.368v-72.97zM120.16 400.414c-57.875 0-104.957-47.082-104.957-104.957S62.285 190.5 120.16 190.5c57.871 0 104.953 47.082 104.953 104.957S178.031 400.414 120.16 400.414zm120.156-125.05v-42.567h31.368v42.566zm151.524 125.05c-57.871 0-104.953-47.082-104.953-104.957S333.969 190.5 391.84 190.5c57.875 0 104.957 47.082 104.957 104.957S449.715 400.414 391.84 400.414zm0 0"></path><path d="M450.883 241.547c-3.356 2.523-4.024 7.289-1.5 10.644 5.844 7.758 9.976 16.438 12.289 25.66-3.758 15.047-12.426 28.676-24.57 38.512-12.747 10.328-28.82 16.016-45.262 16.016-16.438 0-32.516-5.688-45.266-16.016-12.125-9.82-20.789-23.422-24.554-38.441 7.851-31.246 36.171-54.453 69.82-54.453 14.426 0 28.344 4.25 40.242 12.289a7.599 7.599 0 0010.555-2.043 7.6 7.6 0 00-2.043-10.555c-14.422-9.742-31.282-14.894-48.754-14.894-48.078 0-87.192 39.113-87.192 87.191s39.114 87.191 87.192 87.191 87.191-39.113 87.191-87.191c0-19.082-6.054-37.207-17.508-52.41-2.52-3.356-7.285-4.027-10.64-1.5zM391.84 367.445c-33.856 0-62.313-23.5-69.953-55.043a87.422 87.422 0 0015.12 15.774c15.45 12.515 34.923 19.406 54.837 19.406 19.91 0 39.383-6.89 54.832-19.406A87.382 87.382 0 00461.8 312.39c-7.64 31.55-36.098 55.054-69.961 55.054zm0 0"></path></svg> . You'll not only see the <strong>big picture</strong> of what makes React special, but also zoom in to get some <strong>hands-on experience</strong> of writing an actual React component. And yes, no JS knowledge required!</p><p>Remember: You don't need to be an experienced developer to understand the core ideas of React!</p><p>Ready to start the journey?</p><div><p>Of course, eventually you'd need to write code to use React. That's why I'm building an email course to help you on that.</p><p>I believe you'd be able to do useful work with React after a few days of learning, <strong>even if you are new to coding</strong>. If you are interested, sign up and I'll let you know when the course is ready!</p></div><h2><a id="a-few-things-about-the-web" href="#a-few-things-about-the-web"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="20" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg>A few things about the Web</a></h2><p>Let's get started with something you might have heard many times, the DOM.</p><h3><a id="what-is-the-dom" href="#what-is-the-dom"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="20" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg>What is the DOM?</a></h3><p>When you enter the address of your favorite website into a browser, your computer starts a conversation with another computer far away, commonly referred to as <em>server</em>. Typically your computer makes a request for some information and the server responds:</p><blockquote><p><strong>Your computer:</strong> Yo, what's good about this random site learnreact.design?</p><p><strong>The server:</strong> Hang on, let me grab something for you. Beep. Boop.</p></blockquote><p>The main part of the server's response usually includes three items: HTML, CSS and JavaScript.</p><p>HTML lists the content of a web page and describes its structure. How many headings and paragraphs are there? What images should a user see? Are this button and that textbox contained in the same box?</p><p>Using this information, the browser creates something called... the DOM!</p><div><p><img alt="Introducing the DOM" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div><p>Wait a second, the DOM is a ... tree? Yup, a tree! Oddly enough, a lot of things in our computer look like a tree. Let's give our tree friend a nickname... hmm what about Domo?</p><p>Domo works as a model at the prestigious art studio "Web Browser". His job is to pose in front of the artist who paints a portrait (or perhaps millions of portraits).</p><div><p><img alt="Domo at the art studio Web Browser" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div><p>In real life, DOM stands for Document Object Model. It's indeed a model -- a model of the document (aka the web page). It strikes a pose. The browser paints a portrait. The portraits are what we see on a web page: the textboxes, the paragraphs, the images and so on. A developer's job is like that of a director who tells Domo what to wear and what pose to strike. This determines what those portraits look like in the end.</p><p>To check out what the DOM looks like, if you are using a desktop browser, right-click on this very page and choose "Inspect". Can you make sense of what's in the Elements tab?</p><div><p><img alt="Inspect in Chrome" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div><h3><a id="the-dom-api" href="#the-dom-api"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="20" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg>The DOM API</a></h3><p>We often want a web page to be dynamic and interactive -- that means its content changes from time to time: adding or removing text here and there, showing a modal, or updating a chart based on some new data coming from the server.</p><p>Remember, in order to change what's on a web page, we need to update the DOM. The artist isn't able to paint new portraits until Domo changes to a new pose.</p><p>How would we get Domo to change to a new pose?</p><p>We just talk to him. He listens. Interestingly, Domo's ears happen to have a name: <em>DOM API</em>.</p><div><p><img alt="A developer works with DOM API" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div><p>To manipulate the DOM, a developer would write code in JavaScript which talks to the DOM API, and in turn, updates the content of the web page.</p><h3><a id="the-increasing-complexity" href="#the-increasing-complexity"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="20" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg>The increasing complexity</a></h3><p><em>Directly</em> talking to Domo has been the standard approach of web development for years, especially when the web content was mostly static. A developer would sprinkle some interactivity on top of the static pages by writing small amount of JavaScript code.</p><p>However, with the emergence of SPAs (Single Page Application) such as Gmail and Google Maps, people started to expect a lot more. Instead of mostly static web <em>pages</em>, they want web <em>apps</em> that are interactive, fast and responsive.</p><p>The code required to build web apps becomes increasingly large and complex. It often requires the collaboration of many team members.</p><p>The traditional approach stopped working. It becomes chaotic and inefficient to always directly talk to Domo.</p><div><p><img alt="Directly working with the DOM API is getting chaotic" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div><h2><a id="the-core-ideas-of-react" href="#the-core-ideas-of-react"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="20" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg>The Core Ideas of React</a></h2><p>Let me introduce you to the superhero, React:</p><div><p><img alt="Introducing React" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div><p>With React, developers no longer directly talk to Domo. React acts as an agent between a developer and Domo. He smoothens the communication and streamlines the process of portrait creation.</p><div><p><img alt="React as an agent between a developer and the DOM" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div><p>React is made up of JavaScript code. It's built in a way that we no longer need to directly work with the DOM API in most cases. Instead, we write simpler code while React handles the conversation with the DOM under the hood.</p><p>React has a few superpowers to tackle the ever-growing complexity of web development:</p><ul><li>Components</li><li>Declarative UI</li><li>Reactive DOM updates</li></ul><p>If these terms sound scary to you, don't be intimidated! As promised, I'll use plain English and doodles to help you make sense of them. Trust me, it's not that hard!</p><p>Just read on!</p><h3><a id="components" href="#components"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="20" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg>Components</a></h3><p>Components are the flagship feature of React. The core idea is based on a simple strategy: divide-and-conquer. If it's difficult to grok a problem all at once, we break it into smaller problems, solve them one at a time and then combine the results.</p><div><p><img alt="React breaks a problem into components" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div><p>Building an app in React is almost all about working with components: breaking the app into components, finding the best components for the job, fitting one with another, creating new components from existing ones etc.</p><p>Nowadays, design tools such as Framer and Figma have components too (and symbols in Sketch). They are a lot like React components, except that the latter are more flexible and powerful. In fact, the inspiration of components in design tools came directly from components in software engineering. Once a component is created, we can create multiple instances of it. We can use it to construct other components. If we change a component, everything that includes this component will be updated automatically.</p><p>Components in React have two important properties:</p><ol><li>Components are <em>composable</em>. They are made for reuse. We can make a new component with other components.</li><li>Components are <em>independent</em> of each other. If we change the code in one place, other parts don't break.</li></ol><p>If this sounds abstract to you, don't worry! I'll show you some examples and explain these properties in details soon.</p><h3><a id="declarative-ui" href="#declarative-ui"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="20" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg>Declarative UI</a></h3><h4><a id="imperative-vs-declarative" href="#imperative-vs-declarative"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="20" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg>Imperative vs. declarative</a></h4><p>When directly working with the DOM API, we'd have to specify what element to change at the right time, in the right order. This is equivalent to describing to Domo how to position his head, arms and legs step by step, for each and every portrait.</p><div><p><img alt="Imperative programming" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div><p>Heck, this sounds tedious and error-prone! Why can't we just tell Domo <em>what</em> we want instead of <em>how</em> to pose? In fact, this is exactly how to build a UI in React. A developer draws a quick sketch of what he or she wants. React explains it to Domo how to pose.</p><div><p><img alt="Declarative programming in React" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div><p>Because the apps we build are dynamic, we often want Domo to change poses fairly quickly. We draw many sketches and hand them to React in a big pile. React stacks these sketches together and flips them like a flipbook. A dynamic UI comes live!</p><div><p><img alt="React treats input as a flipbook" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div><p>In tech terms, if the code defines <em>how</em> we want it to be done, it's <strong>imperative</strong>; if it defines <em>what</em> we want, it's <strong>declarative</strong>. The traditional way of directly working with the DOM API is imperative, and the React way is declarative.</p><p>Imperative programming emerged from the day when the computers were primitive. People had to instruct them in detail: where to store the numbers, how to multiply etc. But this eventually got unmanageable, people wrote smart software that convert definition of problems into detailed instructions. Declarative programming was born.</p><h4><a id="virtual-dom" href="#virtual-dom"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="20" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg>Virtual DOM</a></h4><p>Besides making the life of a developer easier, declarative programming in React also offers opportunities for performance optimization.</p><p>When React has all the sketches beforehand, he can sort through them, remove any duplication and make sure that Domo and the artist do as little work as possible.</p><div><p><img alt="React diffing with virtual DOM" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div><p>These sketches are called <em>Virtual DOM</em>. Virtual DOM is much faster to manipulate than the DOM. Developers work with Virtual DOM most of the time instead of directly managing the DOM. React handles the dirty work of managing the slow DOM.</p><h3><a id="reactive-dom-updates" href="#reactive-dom-updates"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="20" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg>Reactive DOM updates</a></h3><p>Even cooler, imagine if we can leave placeholders in our sketches to represent different variations of a same pose. This way, when somebody asks for portraits of Domo wearing a different hat, we don't have to talk to React again. We can just sit back and let React change it for us.</p><div><p><img alt="Thinker with a hat: Placeholder in JSX" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div><p>This trick is how React got its name. The UI built with React is <strong>reactive</strong> -- it appears that the DOM "reacts" to any changes to the underlying data. No need to track the data. No need to worry about when to update the DOM. It just gets updated automatically (by React). The idea of reactive UI greatly simplifies UI development.</p><div><div><p>Now let's review what we have learned so far and get our hands dirty on a few real React components. To make it easy for you to understand, I left out some details in the code (notedly JavaScript). The goal is to let the core ideas shine through without being bogged down by JS syntax. If you are comfortable with reading JavaScript code, feel free to check out the <a href="https://codesandbox.io/s/domos-hat-shop-4x7n0?file=/src/App.js" target="_blank" rel="nofollow noopener noreferrer">real source code</a>.</p><p>Alright. Let's say we want to help Domo build an online hat store 🧢 .</p><h3><a id="components-are-composable" href="#components-are-composable"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="20" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg>Components are composable</a></h3><p>We can break the UI into a few parts:</p><ul><li>Header: the header on the top</li><li>Main: the main content area</li><li>Footer: the footer on …</li></ul></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://learnreact.design/posts/what-is-react">https://learnreact.design/posts/what-is-react</a></em></p>]]>
            </description>
            <link>https://learnreact.design/posts/what-is-react</link>
            <guid isPermaLink="false">hacker-news-small-sites-26003666</guid>
            <pubDate>Tue, 02 Feb 2021 17:16:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pa(dding|rtitioning) oracles, and another hot take on PAKEs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26003632">thread link</a>) | @arkadiyt
<br/>
February 2, 2021 | https://emilymstark.com/2021/02/01/padding-partitioning-oracles-and-another-hot-take-on-pakes.html | <a href="https://web.archive.org/web/*/https://emilymstark.com/2021/02/01/padding-partitioning-oracles-and-another-hot-take-on-pakes.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>I’ve been trying to read more applied crypto papers here and there, and this
past week, <a href="https://eprint.iacr.org/2020/1491.pdf">Partitioning Oracle Attacks</a>
(Len, Grubbs, Ristenpart) came up on my reading list. This paper presents a new
class of attack against certain cryptographic protocols that are based on
low-entropy secrets (e.g., passwords). It’s a way to dramatically speed up
guessing attacks – for example, in some cases the attack allows the attacker to
binary-search over a dictionary of passwords instead of trying them one-by-one.
This type of attack seems likely to become a classic because it applies to some
well-known encryption schemes and many different applications.</p>

<p>In this post, I’ll give a high-level overview of another classic oracle attack
(padding oracles), and compare and contrast to the new concept of partitioning
oracle attacks as I understand them; my goal here is to make these attacks
accessible to people with minimal cryptography background. Then I’ll give one of
my hot takes about PAKEs, which is probably mostly of interest to people who
have read the partitioning oracles paper or similar.</p>

<h2 id="oracles-by-example">Oracles by example</h2>

<p>In cryptography, “oracle” means a black-box function or system that takes an
input and returns an output. In the context of an attack, an oracle is used to
formally model unexpected information leakage that gives the attacker some extra
information. Oracle attacks are interesting and educational because they
illustrate why it’s so important that an encryption of a message reveals <em>no
(efficiently computable) information</em> about the message itself: even seemingly
innocuous extraneous information can be used, surprisingly, to break the
encryption scheme entirely.</p>

<p>Typically, when cryptographers describe an attacker for a cryptosystem, they
<a href="https://en.wikipedia.org/wiki/Chosen-plaintext_attack">model</a> the attacker as
having certain capabilities, such as the capability to request encryptions for a
reasonable number of messages of their choice. Then the attacker has a challenge
that they have to solve, such as distinguishing an encryption of another message
of their choice from an encryption of a random message.</p>

<p>But in a real implementation of that cryptosystem, the attacker might learn a
lot more than is modeled in these formal enumerations of their capabilities. The
attacker might be able to observe the time that it takes to encrypt a message,
or might even learn something about the contents of a message from elsewhere in
the system. Oracles are a way to formally describe this type of leakage. For
example, suppose a server decrypts a message and then inserts it into a
database, and the database returns an error in a short-circuit if the message’s
first byte is <code>0x00</code>, and goes on to do some other processing otherwise. An
attacker can learn from observing the timing of this database operation whether
the message starts with <code>0x00</code>. We can model this as an oracle, by saying that
the attacker has the capability to query an oracle function whose output is 1 if
and only the message starts with <code>0x00</code>.</p>

<p>The classic example of an oracle attack is a padding oracle, where the attacker
learns a single extra bit about any arbitrary ciphertext: whether it is padded
correctly. “Padding” here refers to the fact that many encryption schemes don’t
work on messages of arbitrary lengths. For example, it’s common for encryption
algorithms to process messages in blocks of 16 bytes, so messages have to be
padded to a multiple of 16 bytes, with some well-defined and reversible padding
scheme. One example of a padding scheme is to fill in the padding bytes with the
length of the padding. In this scheme, a message of length 60 bytes will be
padded with 4 bytes set to the value <code>0x04</code>, so that the ciphertext is an even
16 x 4 = 64 bytes long.</p>

<p>When implementing cryptographic algorithms, it’s easy to accidentally provide a
padding oracle to attackers. The oracle often comes from a timing side-channel,
because it’s tempting to short-circuit if padding is invalid and not go on to do
other processing that is done for correctly padded messages.</p>

<p>And it’s not too hard to implement a padding oracle attack for many encryption
schemes. I’ll illustrate this with a hypothetical example that demonstrates the
basic concept.</p>

<p>Suppose you have an encryption scheme where flipping a bit in a ciphertext flips
the corresponding bit in the underlying plaintext. So if you encrypt some
message <em>m</em>, flip the last bit in the ciphertext, and then decrypt it, you’ll
get a message which is the same as <em>m</em> but with the last bit flipped. (It might
seem, intuitively, that a secure encryption scheme shouldn’t have this property
that you can transform a ciphertext to produce a predictable transformation in
the plaintext, but this property on its own isn’t actually enough to break the
encryption algorithm. The property is called <em>malleability</em>, and some common
encryption algorithms have it and others don’t.)</p>

<p>Suppose you’re using this encryption scheme with the padding scheme I described
above: messages are padded with <em>n</em> bytes, each set to the value <em>n</em>, to extend
the message length to a multiple of 16 bytes. We’ll say that there’s always at
least one byte of padding added, so a message that is originally 16 bytes would
be padded to 32 bytes.</p>

<p>Now consider an attacker who has some ciphertext which is an encryption of a
message <em>m</em>, and the attacker wants to learn what <em>m</em> is. The attacker can
request decryptions for an arbitrary number of ciphertexts to learn if the
underlying plaintexts have valid padding – this is the padding oracle. Here’s
the attacker’s algorithm:</p>

<ul>
  <li>First, we need to figure out what the padding value is. The attacker will do
this by searching for how to transform the original message into a message
that has only one byte of padding. The attacker iteratively chooses a byte <em>b</em>
from <code>0x01</code> to <code>0xff</code>, and at each iteration, the attacker xors the last byte
of the ciphertext with <em>b</em> and queries to see if the padding is valid.
(Technically we don’t have to check every possible value of <em>b</em>, because we
know there are only so many possible values of the real underlying padding
byte, but that’s an optimization we can ignore for simplicity.)
    <ul>
      <li>When the attacker finds a value for b that produces valid padding, then
the attacker has learned that the last byte of the message xored with <em>b</em>
is (probably<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>) equal to <code>0x01</code>, which allows them to recover the actual
last byte of the message – the length of the original message’s padding.</li>
      <li>If every possible value of <em>b</em> results in a padding error, then the
attacker knows that the actual padding value is <code>0x01</code>.</li>
    </ul>
  </li>
  <li>Suppose the attacker has now discovered that there are 3 bytes of padding in
the original message, so the last 3 bytes of the message are <code>0x03</code>. The
attacker is now going to search for the value of the 4th-to-last byte of the
message (which is the last byte of the original unpadded message). They’ll do
this by transforming the last 3 bytes of the message from <code>0x03</code> to <code>0x04</code>, and
then searching for how to transform the 4th-to-last byte to <code>0x04</code>:
    <ul>
      <li>To transform the last 3 bytes of the underlying message from <code>0x03</code> to
<code>0x04</code>, the attacker xors the last 3 bytes of the ciphertext with <code>0x07</code>
(because <code>0x03 ⊕ 0x07 = 0x04</code>).</li>
      <li>If at this point the ciphertext produces valid padding, then the attacker
knows that the 4th-to-last byte is <code>0x04</code>.</li>
      <li>Otherwise, now the attacker again iterates from <em>b</em> = <code>0x01</code> to <code>0xff</code> and
xors the 4th-to-last byte of the ciphertext with <em>b</em>. When the attacker
finds a value of <em>b</em> that produces valid padding, they know that the
4th-to-last byte’s value xored with <em>b</em> is (again, probably) <code>0x04</code>, and
from that they can recover that byte’s value.</li>
    </ul>
  </li>
  <li>Now it’s a simple matter of iterating this procedure for each remaining byte,
from last to first, to recover the entire message!</li>
</ul>

<p>The high-level idea is that if an attacker can transform a ciphertext in a way
that produces a predictable change in the plaintext, they can use this to search
for transformations that produce valid padding. If they know that a transformed
byte of ciphertext produces a valid padding byte in the plaintext, then they
might be able to learn what the original byte of plaintext was by undoing that
transformation.</p>

<h2 id="partitioning-oracles">Partitioning oracles</h2>

<p>Now that I’ve talked so much about padding oracles, you might be a bit peeved to
hear that partitioning oracles are not really like padding oracles at all. I
believe that they both will be classic oracle attacks with significant practical
impact, but that’s mostly where the similarity ends. I mostly explained padding
oracles because they are a relatively straightforward example of what an oracle
is and how it can be used, and because they can help explain partitioning
oracles as a series of contrasts.</p>

<h3 id="attack-target-plaintext-versus-password">Attack target: plaintext versus password</h3>

<p>Whereas a padding oracle attack aims to recover a plaintext from a ciphertext, a
partitioning oracle attack aims to recover the secret key – which is far more
devastating, because it allows the attacker to subsequently decrypt any message.
Padding oracles are relevant to any cryptosystem that uses a padding scheme, but
partitioning oracle attacks specifically target cryptosystems that derive keys
from low-entropy secrets like passwords.</p>

<p>Password-based cryptosystems are inherently weaker than systems where a key is
chosen at random. The space of passwords is usually smaller than the space of
possible keys, and passwords can be chosen weakly, often coming from a large
dictionary of common passwords. Password-based cryptosystems aim to at least
avoid offline brute-force attackers, where an attacker can eavesdrop on some
communication and then try a bunch of different passwords offline. Instead, the
attacker should be forced to interact with the legitimate parties; in the real
world, this is a significant deterrent since the attacker will be subject to
denial-of-service and anti-fraud protections if they have to interact with a
real server, plus the time required to process each guess will be slowed down by
network latency and other factors.</p>

<p>So, the partitioning oracle setting is …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://emilymstark.com/2021/02/01/padding-partitioning-oracles-and-another-hot-take-on-pakes.html">https://emilymstark.com/2021/02/01/padding-partitioning-oracles-and-another-hot-take-on-pakes.html</a></em></p>]]>
            </description>
            <link>https://emilymstark.com/2021/02/01/padding-partitioning-oracles-and-another-hot-take-on-pakes.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26003632</guid>
            <pubDate>Tue, 02 Feb 2021 17:13:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Cognitive Science Behind How Programmers Think and Learn (Episode 35)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26003510">thread link</a>) | @madamdo
<br/>
February 2, 2021 | https://www.software-engineering-unlocked.com/how-programmers-think-and-learn/ | <a href="https://web.archive.org/web/*/https://www.software-engineering-unlocked.com/how-programmers-think-and-learn/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="7554d9db" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><h2>Transcript: How programmers think and learn</h2><p><em>[If you want, you can help make the transcript better, and improve the podcast’s accessibility via&nbsp;</em><a href="https://github.com/mgreiler/se-unlocked/tree/master/Transcripts" target="_blank" rel="noopener">Github</a><em><a href="https://github.com/mgreiler/se-unlocked/tree/master/Transcripts" target="_blank" rel="noopener">.</a>&nbsp;I’m happy to lend a hand to help you get started with pull requests, and open source work.]</em></p><p><span>Michaela:</span>&nbsp;[00:00:00] Hello, and welcome to the soft engineering unlocked podcast. I’m your host, Dr. McKayla. And today I have the pleasure to talk to Felienne Hermans about how we can learn to program faster, better, and more easily. But before I start, I want to tell you a bit more about ConfigCat – today’s sponsor of this episode. ConfigCat is a feature flag management tool that allows you to seamless and effortless switch features on and off in your application through an intuitive user interface. Everyone on the team, independent of the tech skills, is ready to go within 10 minutes of training to configure the feature set that your user sees based on rules. You can even start to do sophisticated A/B testing, hassle-free and intuitively within a few minutes.</p><p>Super interesting for my listeners doing business within Europe, ConfigCat allows you to have your data distributed in the European Union only so you can easily stay GDPR compliant. So if you want to tap into the sheer possibilities of feature flag management, go have a look at&nbsp;<a href="https://configcat.com/" rel="nofollow">https://configcat.com/</a></p><p>I tried it and I promise you’re up and running within few minutes. Feature flags mean faster deploys with less risks. Less risks is also the generous free plan of ConfigCat. You can start for free today. And with each paid plan, they plant a tree. Cool. Right?</p><p>But now back to Felienne. Felienne is an associate professor at the university of Leiden and investigate how we can best learn how to program Felina is also active in the developer community and organize several developer, meetups, and conferences. She’s a big fan of legal and served for many years as a legal judge at local competitions for kids, her passionate for bringing young kids into TAFE also leads her to being a teacher at the high school in the Netherlands. Currently feeling also writes a book called programmer’s brain explaining what happens in our brain when we learn to code, but also when we read and drive and try to understand code. So I’m super thrilled to have Nina here with me, the unit, what? Come to</p><p><span>Felienne:</span>&nbsp;[00:01:57] Michelle. Thanks for having me.</p><p><span>Michaela:</span>&nbsp;[00:01:59] Yeah, I’m really, really happy. It took quite some time, but now you’re here. And I’m so I’m so curious to learn more about the program is brain, because this is an area that I’m super interested. I mean, we both have been doing the PhD together right. In the same research group, but we were sitting in the same office and I was researching program comprehension. So how are people understanding code. And so this is so close to what really interests me, what really fascinates me. So I’m super thrilled to learn more about that. So can you tell me a little bit about the book, but also your research? Because I think the book is very close to your research that you are doing at university of Leiden,</p><p><span>Felienne:</span>&nbsp;[00:02:38] right? Yeah. That’s correct. And maybe we have to go once. So Beko about what lead me to write this book and what lead me to, to do this research because initially what exactly we were doing your PhD at the same time. And then I wasn’t so interested in program comprehension. I was more interested in developer tools at that time, but then what happened is I started to teach. And then when I started to teach, I realized that. Programming is so hard. I think I sort of forgot because I was already programming for such a long time for myself, that all these parts of programming, like there is so much you have to get, right. If you’re making a program, you have to make a plan in your head. Like this is where I’m going, which requires you to understand the domain, the problem that you’re solving. But at the same time, you also have to be like ridiculously precise. You have to get. Periods and semi-colons and brackets and everything has to fit at so many different levels that when I started to teach kids, it’s like, Oh my God, this is so hard. Why is this so hard? Why is it so hard, for example, for children to remember syntax? Why is it so hard for kids to remember what I was working on there? Sometimes I saw kids was very engaged in a problem, and then I explained something to them. And then a few days later it was like, Oh, I have no recollection of this. And I was like, but I explained this to you, like just a few days ago, how do you not remember? Or I saw them very determined of, Oh, I’m making a game and a cat has to catch fish or something. This is what I’m doing. And then they sorta got sidetracked. And then you, you walk past five minutes later and it was like, Why aren’t you making a game with a cat and it goes like, Oh yeah, that’s true. I totally forgot. He goes, I fell into some hole of a variable or a loop. So that just got me really, really excited to understand more about how do people think, how do people remember things? And of course there was so much research already that wasn’t so connected to programming. This is relatively easy to read all sorts of introduction, books into cognition and cognitive science. But then I realized there wasn’t really a book that explains. Beginner, cognitive science in the context of programming. So then I was like, I could write that book because now I know a lot.</p><p><span>Michaela:</span>&nbsp;[00:04:51] Oh, yeah, very good. And so I actually watched one of your talks. I forgot where it was, but it was really good to talk about programming and understanding program. And you were also talking about kids and when I watched that, and also when I heard you talk right now, I’m wondering, but can we actually generalized from kids to adults? Right. So do we struggled the same way as kids. I struggle. And I definitely do see like this abstraction levels. Right. You have to be very detailed as you said, with the center rugs and semi-colons, or even like tabs and so on. And then you have like this, this larger vision that you have to keep in mind, but do we struggle in the same way or do adults have different problems also compared to</p><p><span>Felienne:</span>&nbsp;[00:05:31] kids? That’s a great question. So in general, adults and kids do learn and struggle at the same level, but that is the case for Morphis adults. So if, if a 10 year old is learning to program and let’s say your next door neighbor is also learning to program, and they’re not a programmer, right. Then they will very much struggle with the same thing. However, if you, if your question is about expert programmers, then they don’t, then they also struggle, but they struggle in different ways. So you already know Java and now you want to learn R then your circle will be different than someone that doesn’t know Java that is learning. Whether that’s a kid or an adult. Okay. Yeah,</p><p><span>Michaela:</span>&nbsp;[00:06:09] I see. And so something else that, that I also thought when, when I heard you talk about all different concepts and you were saying, well, next word known something different than like a novice or, or struggles differently. Like for example, I’m trying to learn new programming languages. Right. And so I, I know Java, I know C-sharp, I know Hiten and a little bit of JavaScript, but. You know, the further it goes away from the languages that I initially learned with her Java and object oriented programming, the more I’m struggling. Right. So I’m struggling, I think, because I have all these preconceived ideas, mental models notions off, you know, what’s right. And what’s wrong, how to do that. And then sometimes I feel like. Oh, this doesn’t work so well now in PI 10, right there, maybe this is not that I’m not meant to do it that way. Right. And so how can, how can people that already know language? How can they overcome those things are some techniques that we can employ, right. To get better at learning new languages. Yeah,</p><p><span>Felienne:</span>&nbsp;[00:07:08] definitely. So one of the things that I talk about in my book is the concept of transfer. So transfer is you already know something about domain a and that helps you to learn domain B. So if you have two languages that are very close together, let’s say she’s sharp in Java. Then you probably experienced lots of positive trends. Like, Oh, I already know this. Oh, it’s exactly the same in Jaffa. That’s no issue. So that’s positive transfer, but then you also have. Negative transfer where you assume that something works a certain way and then it doesn’t. And for example, if you do, Oh, object oriented programming in Java, and then you go to Python, then there’s also object oriented programming. There’s also classes and methods. So maybe you’re like. I know this stuff. I understand what a method is. And then suddenly stuff, of course in Python happens as real time. And then you’re like, Whoa, everything I knew was wrong. So there you have negative transfer where you might assume that you know something and especially if you’re an expert and also you think this cannot be hard. I am already an expert programmer, so probably Python. Isn’t very hard. And then it’s harder than you think. And then of course you also run into issues of motivation where you’re like. I will never learn this because it’s so hard. So actually, if you want to improve on transfer, there are two techniques that people typically use and the techniques are called hugging and bridging. So hugging is where you try to get the concepts to be really close together. An example of hugging is if you already know Java. Then it might be easier for you to solve a problem in Java. So first you solve the problem in Java and then you simply, it’s not always simple, but simply translate your solution into, let’s say Python, if you’re learning that. So that makes it easier than the are. You’re trying to get the languages closer together. And with bridging you’re deliberately looking for concepts that are the same. So you, …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.software-engineering-unlocked.com/how-programmers-think-and-learn/">https://www.software-engineering-unlocked.com/how-programmers-think-and-learn/</a></em></p>]]>
            </description>
            <link>https://www.software-engineering-unlocked.com/how-programmers-think-and-learn/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26003510</guid>
            <pubDate>Tue, 02 Feb 2021 17:03:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Worldwide Python-Only Job Board]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26003229">thread link</a>) | @vmesel_
<br/>
February 2, 2021 | https://pyjobs.com.br/en/ | <a href="https://web.archive.org/web/*/https://pyjobs.com.br/en/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-push-subscribe-label="Subscribe" id="push-subscribe">
    <push data-push-unsubscribe-label="Unsubscribe" id="push-unsubscribe">
    
    
    
    
    
      
    
    
      
    
    
    
    
  

  
  
  <meta name="service-worker-js" content="/webpush/service-worker.js">
  <meta name="django-webpush-vapid-key" content="BEsU93K1O_CVaZg1AczxLWcZCElfWlMchmsZ-hb5AyWomQ04cl9dXbcR1PvXlvJwaA7MONgPkt7go57hyJQIZzE">


    <!-- Hotjar Tracking Code for www.pyjobs.com.br -->
    



    <!-- Google Tag Manager (noscript) -->
    
    <!-- End Google Tag Manager (noscript) -->
    <section id="push-sub-div">
      <div>
              <p>
                  <h3>Get our push notifications!</h3>
              </p>
              
          </div>
    </section>
    <nav>
        <div>
            <a href="https://pyjobs.com.br/en/">
                      
                        <img src="https://pyjobs.com.br/static/assets/img/pyjobs.com.br/logo.webp">
                      
                        
                    </a>
            
            
        </div>
      </nav>
      
    

    <header>
            <div>
                <div>
                    <div>
                        <h2>
                             Find here the best jobs and pros on Python 
                        </h2>
                        <p>
                             PyJobs is the largest Python professionals website in Brazil. We already have more than 15 thousand highly qualified professionals and more than 5 years of developer experience Python. 
                        </p>
                        <p>
                            or check out the <a href="#cards">jobs listed below</a>
                        </p>
                    </div>
                    
                </div>
            </div>
    </header>
    <section>
        <div>
            <p>
                <h2>USE OUR FILTER TO SEARCH FOR THE BEST JOB POSITION FOR YOU</h2>
            </p>
            <form method="get" action="/en/jobs/">
                
                     
                     
                
            </form>
            </div>
        </section>
        <section>
            <div>
                <p>
                    <h2>Job Posts</h2>
                </p>
                <p> Here you will have access to the most recent jobs and best jobs you can apply to! If you are a company and want to find the best Pythonistas,   <a href="https://pyjobs.com.br/en/contact/">contact us</a> and find the ideal professional for your team!</p>
            </div>
        </section>
        <!-- COLOCAR COL-LG-4 PARA TAMANHO DOS CARDS -->
        <section id="cards">
            <div>
                <div>
                    
                    <div>
                        <div>
                            <div>
                                <a href="https://pyjobs.com.br/en/job/2055/">
                                    <h3>Desenvolvedor(a) Web</h3>
                                </a>
                                <ul>
                                        <li><b>Company:</b> Deeper Systems</li>
                                        <li><b>Salary Range:</b> Not Informed</li>
                                        <li><b>Location:</b> Natal - Rio Grande do Norte</li>
                                        <li><b>Level:</b> Middle Level</li>
                                        <li><b>Accepts Remote:</b>  Yes </li>
                                    </ul>
                                
                                
                                </div>
                        </div>
                    </div>
                    
                    
                    <div>
                        <div>
                            <div>
                                <a href="https://pyjobs.com.br/en/job/2054/">
                                    <h3>Desenvolvedor(a) Web</h3>
                                </a>
                                <ul>
                                        <li><b>Company:</b> Deeper Systems</li>
                                        <li><b>Salary Range:</b> Not Informed</li>
                                        <li><b>Location:</b> Natal - Rio Grande do Norte</li>
                                        <li><b>Level:</b> Middle Level</li>
                                        <li><b>Accepts Remote:</b>  Yes </li>
                                    </ul>
                                
                                
                                </div>
                        </div>
                    </div>
                    
                    
                    <div>
                        <div>
                            <div>
                                <a href="https://pyjobs.com.br/en/job/2053/">
                                    <h3> Analista Desenvolvedor RPA Pâ€¦</h3>
                                </a>
                                <ul>
                                        <li><b>Company:</b>  Grupo Dream Work</li>
                                        <li><b>Salary Range:</b> Not Informed</li>
                                        <li><b>Location:</b> HÃ­brido, SÃ£o Paulo - Vila OlÃ­mpia - Other</li>
                                        <li><b>Level:</b> Middle Level</li>
                                        <li><b>Accepts Remote:</b>  No </li>
                                    </ul>
                                
                                
                                </div>
                        </div>
                    </div>
                    
                        </div>
                        <div>
                    
                    
                    
                    
                    
                    <div>
                        <div>
                            <div>
                                <a href="https://pyjobs.com.br/en/job/2051/">
                                    <h3> Desenvolvedor Python Pleno </h3>
                                </a>
                                <ul>
                                        <li><b>Company:</b> Pasquali Solution</li>
                                        <li><b>Salary Range:</b> Not Informed</li>
                                        <li><b>Location:</b> â€¢	Remoto - Other</li>
                                        <li><b>Level:</b> Middle Level</li>
                                        <li><b>Accepts Remote:</b>  Yes </li>
                                    </ul>
                                
                                
                                </div>
                        </div>
                    </div>
                    
                    
                    <div>
                        <div>
                            <div>
                                <a href="https://pyjobs.com.br/en/job/2050/">
                                    <h3>DESENVOLVEDOR PYTHON</h3>
                                </a>
                                <ul>
                                        <li><b>Company:</b> UNDER</li>
                                        <li><b>Salary Range:</b> 3.000,01 - 6.000,00</li>
                                        <li><b>Location:</b> HIBRIDA OU REMOTO - Rio Grande do Sul</li>
                                        <li><b>Level:</b> Middle Level</li>
                                        <li><b>Accepts Remote:</b>  Yes </li>
                                    </ul>
                                
                                
                                </div>
                        </div>
                    </div>
                    
                        </div>
                        <div>
                    
                    
                    <div>
                        <div>
                            <div>
                                <a href="https://pyjobs.com.br/en/job/2049/">
                                    <h3>Desenvolvedor Python</h3>
                                </a>
                                <ul>
                                        <li><b>Company:</b> Pasquali Solution</li>
                                        <li><b>Salary Range:</b> 10.000,01 - 13.000,00</li>
                                        <li><b>Location:</b> Home Office - Other</li>
                                        <li><b>Level:</b> Middle Level</li>
                                        <li><b>Accepts Remote:</b>  Yes </li>
                                    </ul>
                                
                                
                                </div>
                        </div>
                    </div>
                    
                    
                    <div>
                        <div>
                            <div>
                                <a href="https://pyjobs.com.br/en/job/2048/">
                                    <h3> Java Developer </h3>
                                </a>
                                <ul>
                                        <li><b>Company:</b>  Union It Digital</li>
                                        <li><b>Salary Range:</b> Not Informed</li>
                                        <li><b>Location:</b> Remoto e Presencial (Zona Oeste - SP) - Other</li>
                                        <li><b>Level:</b> Other</li>
                                        <li><b>Accepts Remote:</b>  Yes </li>
                                    </ul>
                                
                                
                                </div>
                        </div>
                    </div>
                    
                    
                    
                    
                        </div>
                        
                
            </div>
        </section>
        <section>
            <div>
                <div>
                    <div>
                        <h3> Learn about other opportunities in Python </h3>
                        <p>All opportunities on PyJobs went through a screening process to ensure the best quality possible on the jobs. Our partnership with companies are made in a totally transparent way, looking for the best opportunities and conditions for developers.</p>
                        </div>
                    <p><img src="https://pyjobs.com.br/static/assets/img/pyjobs.com.br/joinha.webp" alt="" loading="lazy">
                        
                    </p>
                </div>

            </div>
        </section>
        <section>
            <div>
                <p>
                    <h3>Get to know some developers from our platform!</h3>
                </p>
            </div>
        </section>
        <section>
            <div>
                <p>
                    <center>
                        <iframe src="https://www.youtube.com/embed/T6jwRBEI7Gw" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
                    </center>
                </p>
                <p>
                    <center>
                        <iframe src="https://www.youtube.com/embed/WOxRlCCFGQk" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
                    </center>
                </p>
            </div>
        </section>
        <section>
            
        </section>
  
    
    
    
    
    
    
        




        
    
    
    
    
  
  
  


</push></div></div>]]>
            </description>
            <link>https://pyjobs.com.br/en/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26003229</guid>
            <pubDate>Tue, 02 Feb 2021 16:46:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Recovering a Bricked SSD with JTAG and a Raspberry Pi]]>
            </title>
            <description>
<![CDATA[
Score 45 | Comments 4 (<a href="https://news.ycombinator.com/item?id=26003176">thread link</a>) | @fanf2
<br/>
February 2, 2021 | https://fmad.io/blog-ssd-bricked-restore.html | <a href="https://web.archive.org/web/*/https://fmad.io/blog-ssd-bricked-restore.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

			<p>
				SSD`s are the life blood of our fmadio 10G, 40G, 100G ethernet capture systems. They provide backing storage that well exceeds that of conventional RAM, are super fast and light weight. Thus its prudent to keep the SSD farms in top nick, optimal health, and occasionally perform emergency room brain surgery on them. Unfortunately today is one of those days.
			</p>
			<br>

			<div>                        
				<ul>                            
					<li><img width="60%" src="https://fmad.io/images/blog/20141229_ssd_jtag_close.jpg" alt="ssd connected to jtag"></li>
				</ul>                        
			</div>


		<p>
As with all things, it happened late on a Friday night when I was adding a new feature to the system that wipes all capture data from the system. This is simple button click on the web UI page as our clients data is quite sensitive thus needs to be deleted when the box moves internally or externally. The wipe is implemented using the "Secure Erase" ATA-8 command, you can read all about it <a href="https://ata.wiki.kernel.org/index.php/ATA_Secure_Erase">here</a>. Its essentially a restore-to-factory-setting operation. Meaning after the SecureErase the drive`s internal state is the same as "just left the factory". 
		</p>
		
		<p>
Which is great when it works, but this kind of low level drive formatting is pretty complicated with many (presumably) asynchronous operations going on in parallel... and doing 100 of these operations back to back at high speed is probably something the vendor did not expect (I was testing dammit!). In our case this bricked 6 SSD`s rendering them completely useless causing myself quite the stress as I now have several thousand dollars worth of inventory destroyed!  - not a good day.
</p>


				<p><img width="1024px" src="https://fmad.io/images/blog/money_burn.jpg" alt="fmadio ssd lost"></p><p>
The result is a wall of rather intimidating errors indicating imminent doom with the disk is for all intensive purposes <a href="https://en.wikipedia.org/wiki/Brick_%28electronics%29"><b>BRICKED</b></a>.

<code>

kernel: [18633.754193] ata2.00: exception Emask 0x0 SAct 0x0 SErr 0x0 action 0x0
kernel: [18633.754204] ata2.00: irq_stat 0x40000001
kernel: [18633.754206] ata2.00: failed command: READ DMA
kernel: [18633.754209] ata2.00: cmd c8/00:08:00:00:00/00:00:00:00:00/e0 tag 0 dma 4096 in
kernel: [18633.754209]          res 51/04:00:00:00:00/00:00:00:00:00/60 Emask 0x1 (device error)
kernel: [18633.754210] ata2.00: status: { DRDY ERR }
kernel: [18633.754211] ata2.00: error: { ABRT }
kernel: [18633.754515] ata2.00: supports DRM functions and may not be fully accessible
kernel: [18633.754614] ata2.00: failed to get NCQ Send/Recv Log Emask 0x1
kernel: [18633.759150] ata2.00: supports DRM functions and may not be fully accessible
kernel: [18633.759215] ata2.00: failed to get NCQ Send/Recv Log Emask 0x1
kernel: [18633.763495] ata2.00: configured for UDMA/133
kernel: [18633.770136] ata2: EH complete
kernel: [18633.770278] ata2.00: exception Emask 0x0 SAct 0x0 SErr 0x0 action 0x0
kernel: [18633.770280] ata2.00: irq_stat 0x40000001
kernel: [18633.770281] ata2.00: failed command: READ DMA
kernel: [18633.770284] ata2.00: cmd c8/00:08:00:00:00/00:00:00:00:00/e0 tag 1 dma 4096 in
kernel: [18633.770284]          res 51/04:00:00:00:00/00:00:00:00:00/60 Emask 0x1 (device error)
kernel: [18633.770286] ata2.00: status: { DRDY ERR }
kernel: [18633.770286] ata2.00: error: { ABRT }
kernel: [18633.770572] ata2.00: supports DRM functions and may not be fully accessible
kernel: [18633.770641] ata2.00: failed to get NCQ Send/Recv Log Emask 0x1
kernel: [18633.775164] ata2.00: supports DRM functions and may not be fully accessible
kernel: [18633.775210] ata2.00: failed to get NCQ Send/Recv Log Emask 0x1
kernel: [18633.779527] ata2.00: configured for UDMA/133
kernel: [18633.786094] ata2: EH complete
kernel: [18633.786205] ata2.00: exception Emask 0x0 SAct 0x0 SErr 0x0 action 0x0
kernel: [18633.786207] ata2.00: irq_stat 0x40000001
kernel: [18633.786208] ata2.00: failed command: READ DMA
</code>


</p><p>
The usual suspects to recover were tried and failed, leaving only a few options.
<br>
</p>

<h5>a) RMA the boards back to the seller<br>
b) Contact vendor support<br>
c) Perform surgery</h5>


<p>
Option a) of RMA`ing the boards was the safest option, tho usually you get some other previously recycled RMA`ed device back. Option b) of contacting the vendor is always such a brutally painful experience. It would likely end up with some random "Customer Support" person with a strange accent... giving the default completely useless response of RMA the device and get a replacement kind of thing... ho hum. Which leaves surgery! Now I usually don't go messing with hardware like this (anymore... :) ) because it takes up quite a bit time. However SSD health and prosperity is directly linked to our profitability thus deemed it a worth while time investment to have a more intimate relationship with our SSD models of choice. 
</p>
<br>

<div><p>
The process starts with a general reconnaissance mission of what pins are accessible, and what those pins are for. First up was finding the UART / serial interface but it was silent and likely disabled by the firmware. Next up was what most likely looked like a JTAG interface and... bingo, full JTAG interface connecting and operating as expected.
</p><p>

 JTAG is a hardware based system debugger that for CPU`s let you control instruction execution and read/write memory anywhere. You can see in the picture below some soldering of header pins was required, that is then wired to a breadboard which is wired to a Raspberry PI.
</p></div>


	<p><img width="1024px" src="https://fmad.io/images/blog/20141229_ssd_jtag.jpg" alt="fmadio ssd with jtag connected"></p><div><p>
Raspberry PI? wtf ? In this case the Raspberry PI was converted into a JTAG debugger using the outstanding software over at <a href="http://openocd.sourceforge.net/">OpenOCD</a>. As "real" JTAG debuggers are quite expensive ranging from $100 - $1000+ making OCD coupled with the PI an excellent low cost alternative. 
</p><p>

At this point you get a small rush as you gain access and poke the device, after which the vastness of having no idea what anything does starts to weigh you down. Then slowly bit by bit, instruction after instruction, string after string you gain some intuition on the memory map, what the code does, how its setup and eventually find something interesting.
</p></div> 

<p>

The first entry point to look for is the classic printf / trace / debug operation which gives you insight into what the software is doing. And eventually managed to track down the code that`s basically

<code>
void trace(char* Message, ...)
{ 
	va_arg list;
	va_start(arglist, Message);

	char buf[1024];
	vsprintf(buf, Message, arglist);

	if (debug_enable)
	{
		fwrite(output, buf, strlen(buf));
	}
}
</code>

which writes out a string to a console to tell the developer on whats going on. Note that the code has to "flatten" the string first before even deciding to output or not, which gives us a nice window to sniff the string with JTAG even if nothing is written to the console. 
</p>


<p>
After sniffing strings for a while and getting a better feel for whats happening noticed that the SSD is receiving commands from the SATA host no problem. But there`s some sort of funkyness going on that causes the SSD to send no response back - kind of a one-way-street. One idea to resolve this is: in theory the security erase operation restores everything back to good health. The question tho, is the device actually processing a security erase request ?  
</p>


<p>
... and using our printf JTAG sniffer... it most certainly is processing the request! But failing miserably due to an incorrect password. You can see the sniffed printf jtag string in the output below. Hint: <i>"&lt;SED&gt; Credential Comparison Failed"</i> ASCIIZ string.
</p>


	<p><img width="1024px" src="https://fmad.io/images/blog/20141229_ssd_security_erase_fail.jpg" alt="fmadio ssd security erase fail"></p><p>
Which makes it clear why the security erase / factory reset failed but more importantly you can track down the offending bit of code from this string. That results in the following snippet of assembler courtesy of the IDA toolset below.
</p> 

<p><img width="1024px" src="https://fmad.io/images/blog/20141229_ssd_security_check.jpg" alt="fmadio ssd security erase password check"></p><p>
To decode that for you its doing a 32 byte long compare against some expected cryptographic hash key. Then the <i>"magic compare"</i> aka instruction <b>CMP R5, #1</b> is testing if the keys matched. Then doing a conditional jump to a printf routine based on that comparison result <b>BLNE sub_80...</b>. And finally  the functions return value is the result of the comparison <b>MOV R0, R5</b>. Nothing particularly fancy going on.
</p> 


<p>
There`s a few ways to go from here. One would be to reverse engineer how the 32B key is generated and create  a general purpose exploit. The other would be to just patch the binary such that it thinks it passed the security check. eg Fake a correct password response. We chose the latter as it only takes a few minutes and all I want is to restore the SSD farm`s health. Patching the binary with JTAG is trivial, console output is shown below.
</p> 


<p><img width="1024px" src="https://fmad.io/images/blog/20141229_ssd_security_erase_patch.jpg" alt="fmadio ssd security erase password fake"></p><div><p>
The above shows disassembling the patched code first, the "before" section. This is to check we overwrite the correct bit of code. Then patch it using the command <b>cpu0 arm mww</b> with the value 0xe3a05001. Then disassemble again "after section" to confirm the patch worked and has the correct instruction. 
</p><p>

In this case we replaced <b>BLNE</b> instruction (print error message to the console) with <b>MOV r5, #1</b> at address 0x8009abe4 (shown in blue). The result of the "magic check" is 0 for fail, 1 for pass and write it to register r5. All we did is ignore the whole comparison and simply override it and say the security check always passes (r5 = 1).
</p></div> 

<p>
...
</p>

<p>
Now its patched, with cpu`s resumed its the moment of truth. Issuing the security erase operation from the host system via hdparm. 
<br>
<code>
$ sudo hdparm --security-erase 1234  /dev/sdb
security_password="1234"

/dev/sdb:
 Issuing SECURITY_ERASE command, password="1234, user=user
$
</code>
<br>
... and it worked! the SSD is back to life, working as normal and running at high speed!  ... with <b>several thousand dollars worth of SSD`s back in business</b> making our 10G, 40G, 100G network capture systems more resilient than ever. Now if the SSD vendor (who shall remain nameless) would fix the dam bug so excessive back-to-back security password/erase does NOT brick the device, life would be so much better. 
</p>


	</div></div>]]>
            </description>
            <link>https://fmad.io/blog-ssd-bricked-restore.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26003176</guid>
            <pubDate>Tue, 02 Feb 2021 16:43:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[U.S. Digital Response need tech volunteers for responding to Covid-19]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26002989">thread link</a>) | @jayliew
<br/>
February 2, 2021 | https://www.usdigitalresponse.org/raising-your-hand/ | <a href="https://web.archive.org/web/*/https://www.usdigitalresponse.org/raising-your-hand/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-elementor-type="popup" data-elementor-id="920" data-elementor-settings="{&quot;entrance_animation&quot;:&quot;fadeInUp&quot;,&quot;exit_animation&quot;:&quot;fadeIn&quot;,&quot;entrance_animation_duration&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;size&quot;:&quot;0.5&quot;,&quot;sizes&quot;:[]},&quot;triggers&quot;:{&quot;page_load_delay&quot;:2,&quot;page_load&quot;:&quot;yes&quot;},&quot;timing&quot;:{&quot;times_times&quot;:1,&quot;times_count&quot;:&quot;close&quot;,&quot;times&quot;:&quot;yes&quot;}}"><div><section data-id="3ec3ab1c" data-element_type="section"><div><div><div data-id="65be9ec" data-element_type="column"><div><div><div data-id="ce132ab" data-element_type="widget" data-widget_type="heading.default"><p><h6>By using this website, you agree to our use of cookies. We use cookies to provide you with a great experience and to help our website run effectively.</h6></p></div></div></div></div><div data-id="560c3ad5" data-element_type="column"><div><div><div data-id="3a054b23" data-element_type="widget" data-widget_type="button.default"><div><div> <p><a href="#elementor-action%3Aaction%3Dpopup%3Aclose%26settings%3DeyJkb19ub3Rfc2hvd19hZ2FpbiI6IiJ9" role="button"> <span> <span>OK</span> </span> </a></p></div></div></div></div></div></div></div></div></section></div></div></div>]]>
            </description>
            <link>https://www.usdigitalresponse.org/raising-your-hand/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26002989</guid>
            <pubDate>Tue, 02 Feb 2021 16:29:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Generating Text with Markov Chains]]>
            </title>
            <description>
<![CDATA[
Score 66 | Comments 21 (<a href="https://news.ycombinator.com/item?id=26002911">thread link</a>) | @healeycodes
<br/>
February 2, 2021 | https://healeycodes.com/generating-text-with-markov-chains/ | <a href="https://web.archive.org/web/*/https://healeycodes.com/generating-text-with-markov-chains/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>I wanted to write a program that I could feed a bunch of novels and then produce similar text to the author’s writing.</p>
<p>One method of generating fake but familiar looking text is to use a Markov chain generator. There is a fantastic Python library for doing this called <a href="https://github.com/jsvine/markovify">jsvine/markovify</a> but I wanted to learn more about how it works under the hood so I implemented the algorithms from scratch!</p>
<p>Before we get to text generation, let’s start by generating some fake weather. Skip the following section if you’re familiar with Markov chains.</p>
<h2 id="fake-weather-generation"><a href="#fake-weather-generation" aria-label="fake weather generation permalink"></a>Fake Weather Generation</h2>
<p>I have some historical weather data from my town. The weather here is either sunny or rainy. When it’s sunny, there’s a good chance that it remains sunny the next day. It rarely rains but when it does it often rains for a few days.</p>
<p>Rather than using a naive probability (e.g. there’s an ~83% chance it is sunny vs. rainy on any given day) we’ll use a Markov chain to generate more realistic looking data. Our generated data will have streaks of weather which will more closely resemble real life patterns.</p>
<p>To be specific, if it’s sunny there’s a 10% chance it will be rainy the next day and a 90% chance it will stay sunny. If it’s rainy then there’s 50% chance it will be sunny the next day and a 50% chance it will stay rainy.</p>
<p>Here’s a diagram of this two-state Markov process.</p>
<p><span>
      <a href="https://healeycodes.com/static/e4ae284c37dcdeb9323b73b3637b6709/b6699/weather-markov-chain.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="A Markov chain with the sunny/rainy values as described above." title="A Markov chain with the sunny/rainy values as described above." src="https://healeycodes.com/static/e4ae284c37dcdeb9323b73b3637b6709/b6699/weather-markov-chain.png" srcset="https://healeycodes.com/static/e4ae284c37dcdeb9323b73b3637b6709/a8a0d/weather-markov-chain.png 300w,
https://healeycodes.com/static/e4ae284c37dcdeb9323b73b3637b6709/b6699/weather-markov-chain.png 405w" sizes="(max-width: 405px) 100vw, 405px" loading="lazy">
  </a>
    </span></p>
<p>Instead of using weights to describe probability, let’s distribute the states in a list that we randomly pick from. I find that defining Markov chains like this (while far more computationally expensive) is easier to debug.</p>
<div data-language="python"><pre><code>weather_chain <span>=</span> <span>{</span>
    <span>'sun'</span><span>:</span> <span>[</span><span>'sun'</span><span>,</span> <span>'sun'</span><span>,</span> <span>'sun'</span><span>,</span> <span>'sun'</span><span>,</span> <span>'sun'</span><span>,</span> <span>'sun'</span><span>,</span> <span>'sun'</span><span>,</span> <span>'sun'</span><span>,</span> <span>'sun'</span><span>,</span> <span>'rain'</span><span>]</span><span>,</span>
    <span>'rain'</span><span>:</span> <span>[</span><span>'sun'</span><span>,</span> <span>'rain'</span><span>]</span>
<span>}</span></code></pre></div>
<p>We consume this model by picking a random starting state and using the current state to choose randomly from the possible future states. We do this over and over to generate a sequence.</p>
<div data-language="python"><pre><code><span>import</span> random


weather <span>=</span> <span>[</span>random<span>.</span>choice<span>(</span><span>list</span><span>(</span>weather_chain<span>.</span>keys<span>(</span><span>)</span><span>)</span><span>)</span><span>]</span>

<span>for</span> i <span>in</span> <span>range</span><span>(</span><span>10</span><span>)</span><span>:</span>
    weather<span>.</span>append<span>(</span>random<span>.</span>choice<span>(</span>weather_chain<span>[</span>weather<span>[</span>i<span>]</span><span>]</span><span>)</span><span>)</span></code></pre></div>
<p>In this example output, we can see that rainy days are ‘sticky’ as we would expect from the model. </p>
<div data-language="python"><pre><code><span>[</span><span>'rain'</span><span>,</span> <span>'rain'</span><span>,</span> <span>'rain'</span><span>,</span> <span>'sun'</span><span>,</span> <span>'sun'</span><span>,</span> <span>'sun'</span><span>,</span> <span>'sun'</span><span>,</span> <span>'sun'</span><span>,</span> <span>'rain'</span><span>,</span> <span>'rain'</span><span>,</span> <span>'sun'</span><span>]</span></code></pre></div>
<h2 id="fake-text-generation"><a href="#fake-text-generation" aria-label="fake text generation permalink"></a>Fake Text Generation</h2>
<p>Instead of having a predefined Markov chain like we saw in the previous section, let’s build one from real data. The full source code for this article and the text corpuses can be found at <a href="https://github.com/healeycodes/markov-chain-generator">healeycodes/markov-chain-generator</a>.</p>
<p>The code excerpts assume that we’re generating fiction. So the source text must have capital letters at the start of sentences and full stops at the end of sentences. We can use these two markers to generate text chunks that have a beginning and an end.</p>
<p>In our weather example, the state size was one — to decide the next step in the sequence, we only considered one previous day of weather. When it comes to generating language, a state size of one sometimes isn’t big enough and the arrangement of words can be too random to be interesting. A state size of two is a good starting point. Going higher than two can produce text that is too similar to the original text corpus.</p>
<p>The following function builds a Markov chain in the same format as our weather example. It takes a source text and a state size and returns a dictionary where the keys are the current state and their values are a list of possible future states. The lists contain duplicates and this is how we handle the probabilities of future states.</p>
<div data-language="python"><pre><code><span>def</span> <span>build_model</span><span>(</span>source<span>,</span> state_size<span>)</span><span>:</span>
    <span>'''
    Given a corpus and a state size, build a Markov chain.
    '''</span>
    source <span>=</span> source<span>.</span>split<span>(</span><span>)</span>
    model <span>=</span> <span>{</span><span>}</span>
    <span>for</span> i <span>in</span> <span>range</span><span>(</span>state_size<span>,</span> <span>len</span><span>(</span>source<span>)</span><span>)</span><span>:</span>
        current_word <span>=</span> source<span>[</span>i<span>]</span>
        previous_words <span>=</span> <span>' '</span><span>.</span>join<span>(</span>source<span>[</span>i<span>-</span>state_size<span>:</span>i<span>]</span><span>)</span>
        <span>if</span> previous_words <span>in</span> model<span>:</span>
            model<span>[</span>previous_words<span>]</span><span>.</span>append<span>(</span>current_word<span>)</span>
        <span>else</span><span>:</span>
            model<span>[</span>previous_words<span>]</span> <span>=</span> <span>[</span>current_word<span>]</span>

    <span>return</span> model</code></pre></div>
<p>Given a tiny source of <code>'An apple is very good. An orange is very bad.'</code> and a state size of <code>2</code> it will produce the following Markov chain. Since the source was so small there are only four possible complete sentences.</p>
<div data-language="json"><pre><code><span>{</span>
  <span>"An apple"</span><span>:</span><span>[</span>
    <span>"is"</span>
  <span>]</span><span>,</span>
  <span>"apple is"</span><span>:</span><span>[</span>
    <span>"very"</span>
  <span>]</span><span>,</span>
  <span>"is very"</span><span>:</span><span>[</span>
    <span>"good."</span><span>,</span>
    <span>"bad."</span>
  <span>]</span><span>,</span>
  <span>"very good."</span><span>:</span><span>[</span>
    <span>"An"</span>
  <span>]</span><span>,</span>
  <span>"good. An"</span><span>:</span><span>[</span>
    <span>"orange"</span>
  <span>]</span><span>,</span>
  <span>"An orange"</span><span>:</span><span>[</span>
    <span>"is"</span>
  <span>]</span><span>,</span>
  <span>"orange is"</span><span>:</span><span>[</span>
    <span>"very"</span>
  <span>]</span>
<span>}</span></code></pre></div>
<p>The following function consumes the Markov chain model and generates some fake text for us. To achieve a minimum length, we keep generating until we hit the minimum length and then keep going until we reach a token that ends with a full stop. To find a correct starting point, we pick a random key (two words) where the first character is a capital letter.</p>
<div data-language="python"><pre><code><span>def</span> <span>generate_text</span><span>(</span>model<span>,</span> state_size<span>,</span> min_length<span>)</span><span>:</span>
    <span>'''
    Consume a Markov chain model (make sure to specify the &lt;state_size&gt; used)
    to generate text that is at least &lt;min_length&gt; size long.
    '''</span>
    <span>def</span> <span>get_new_starter</span><span>(</span><span>)</span><span>:</span>
        <span>return</span> random<span>.</span>choice<span>(</span><span>[</span>s<span>.</span>split<span>(</span><span>' '</span><span>)</span> <span>for</span> s <span>in</span> model<span>.</span>keys<span>(</span><span>)</span> <span>if</span> s<span>[</span><span>0</span><span>]</span><span>.</span>isupper<span>(</span><span>)</span><span>]</span><span>)</span>
    text <span>=</span> get_new_starter<span>(</span><span>)</span>

    i <span>=</span> state_size
    <span>while</span> <span>True</span><span>:</span>
        key <span>=</span> <span>' '</span><span>.</span>join<span>(</span>text<span>[</span>i<span>-</span>state_size<span>:</span>i<span>]</span><span>)</span>
        <span>if</span> key <span>not</span> <span>in</span> model<span>:</span>
            text <span>+=</span> get_new_starter<span>(</span><span>)</span>
            i <span>+=</span> <span>1</span>
            <span>continue</span>

        next_word <span>=</span> random<span>.</span>choice<span>(</span>model<span>[</span>key<span>]</span><span>)</span>
        text<span>.</span>append<span>(</span>next_word<span>)</span>
        i <span>+=</span> <span>1</span>
        <span>if</span> i <span>&gt;</span> min_length <span>and</span> text<span>[</span><span>-</span><span>1</span><span>]</span><span>[</span><span>-</span><span>1</span><span>]</span> <span>==</span> <span>'.'</span><span>:</span>
            <span>break</span>
    <span>return</span> <span>' '</span><span>.</span>join<span>(</span>text<span>)</span></code></pre></div>
<p>Here are those four possible complete sentences from our previous Markov chain. These can be combined infinitely by our function.</p>
<div data-language="text"><pre><code>'An apple is very bad.'
'An orange is very bad.'
'An orange is very good.'
'An apple is very good.'</code></pre></div>
<h2 id="some-examples"><a href="#some-examples" aria-label="some examples permalink"></a>Some Examples</h2>
<p>We can now feed in large amounts of text from an author and generate fake writing! In fact, any corpus that uses sentences will work with our program. For example, here is the result of feeding in a few Wikipedia articles.</p>
<blockquote>
<p>Cricket is more similar to dust devils and landspouts. They form when a homicide rate of 34.2 per 100,000 was reported. This included 15 officer-involved shootings. One shooting led to the latest hour of it; and lately, I know of but love, desperate love, the worst of all the more remote islands. At around the field. One of Wollstonecraft’s most popular metaphors draw on military concepts: Disease is an early type of fiction that were quick to resort to violence. One of Wollstonecraft’s favorite arguments.</p>
</blockquote>
<p>Here’s some Edgar Allen Poe.</p>
<blockquote>
<p>Count could recollect, it was never worth the trouble of the stranger. But, as usual, enveloped in frequent rolls, or bandages, of linen; but, in place of conference with the whole matter as a natural result of the river, and, plunging through a single slender gold chain, and throws a tranquil but magical radiance over all. I cannot enter into details just now: but it was found, on Sunday morning, that he was forced to allow, had ever suspected of existing in the heathen is unwonted; and fickle-mindedness has ever thought of this life and of cutting him off with a layer of plaster, thickly gilt and painted.</p>
</blockquote>
<h2 id="further-resources"><a href="#further-resources" aria-label="further resources permalink"></a>Further Resources</h2>
<p>The sun/rain example was taken from <a href="https://en.wikipedia.org/wiki/Examples_of_Markov_chains#A_simple_weather_model">Wikipedia</a>. Victor Powell’s article, <a href="https://setosa.io/ev/markov-chains/">Markov Chains</a>, was also helpful for my initial understanding and is worth checking out for the interactive graphics alone.</p>
<p>Some of the articles about Markov chains are a little inaccessible to those without a maths background. However, there’s a Simple English version of Wikipedia. Many articles have an alternative page which you can find by replacing the <code>en</code> in the URL bar with <code>simple</code>. For example, the <a href="https://simple.wikipedia.org/wiki/Markov_chain">simple version</a> of the Markov chain page.</p>
<p>Daniel Shiffman also covered Markov chains in a Coding Challenge on <a href="https://www.youtube.com/watch?v=eGFJ8vugIWA">The Coding Train</a>.</p></section></div>]]>
            </description>
            <link>https://healeycodes.com/generating-text-with-markov-chains/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26002911</guid>
            <pubDate>Tue, 02 Feb 2021 16:24:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TikTok leveraged memes to become the first YouTube challenger]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26002887">thread link</a>) | @FOMO_capital
<br/>
February 2, 2021 | https://npappag.com/2020/10/29/audio-memes-why-tiktok-is-the-first-youtube-challenger/ | <a href="https://web.archive.org/web/*/https://npappag.com/2020/10/29/audio-memes-why-tiktok-is-the-first-youtube-challenger/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<h2>And how memetics will guide future tech products</h2>



<figure><audio controls="" src="https://npappag.files.wordpress.com/2020/11/audio-first-memes3.mp3"></audio><figcaption>Full audio version</figcaption></figure>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">Who controls the memes,<br>controls the Universe</p>— Elon Musk (@elonmusk) <a href="https://twitter.com/elonmusk/status/1276418907968925696?ref_src=twsrc%5Etfw">June 26, 2020</a></blockquote></div>
</div></figure>



<p>“Who controls the memes controls the universe” tweeted Elon Musk, referencing a line from <em>Dune</em>. Somehow it feels both trollish and profound.</p>



<p>If you live on the internet, you know it when you see it. Memes are everywhere. More importantly, it feels like memes matter today. A well-crafted internet joke like Musk’s can yield more attention than a well-funded PR campaign. </p>



<p>Lately, I’ve been reading a fascinating <a href="https://en.wikipedia.org/wiki/The_Meme_Machine">book</a> on the topic. First, I learned the academic definition of memes is far more expansive than just internet jokes. Richard Dawkins coined the term meme to refer to fashions, ceremonies, customs, and technologies that spread across human brains. The mechanism: mimesis, better known as imitation.</p>



<blockquote><p><em>[Dawkins] discussed [meme] propagation by jumping from brain to brain, likened them to parasites infecting a host, treated them as physically realised living structures, and showed how mutually assisting memes will gang together in groups just as genes do. Most importantly, he treated the meme as a replicator in its own right. </em><strong><em>Everything you have learned by imitation from someone else is a meme.</em></strong><em> But we must be clear what is meant by the word ‘imitation’, because our whole understanding of memetics depends on it. Dawkins said that memes jump from ‘brain to brain via a process which, in the broad sense, can be called imitation’ (1976, p. 192)…</em></p><p><em>Everything that is passed from person to person in this way is a meme. This includes all the words in your vocabulary, the stories you know, the skills and habits you have picked up from others and the games you like to play. It includes the songs you sing and the rules you obey. So, for example, whenever you drive on the left (or the right!), eat curry with lager or pizza and coke, whistle the theme tune from ‘Neighbours’ or even shake hands, you are dealing in memes. Each of these memes has evolved in its own unique way with its own history, but each of them is using your behaviour to get itself copied.</em></p><cite><strong>Susan Blackmore “The Meme Machine”</strong></cite></blockquote>



<p>Think of memes as the smallest atomic unit of culture. Some memes are funny, some are relatable, and some are not very useful and don’t spread widely. </p>



<p>Memetic theory says these mind-viruses compete against each other for their slot in the next human brain. Some memes make it. Others don’t. (Even more interestingly, some memes make it without regard to their real-world usefulness—only their ability to <a href="https://bitesizebio.com/1344/selfish-genes-and-gene-centered-evolution/">replicate</a> most effectively.) Memes, they argue, are part of a Darwinian system. This is all rooted in the idea of <a href="https://en.wikipedia.org/wiki/Universal_Darwinism#:~:text=Universal%20Darwinism%20(also%20known%20as,of%20biological%20evolution%20on%20Earth.">Universal Darwinism</a>, which says evolution applies to any “replicator” with the following conditions:</p>



<ul><li><strong>selection </strong>– the fittest survive</li><li><strong>variation </strong>– there are slight changes between copies</li><li><strong>heredity </strong>– the offspring inherits characteristics from the parent</li></ul>



<p>Memes satisfy these conditions and replicate “cultural instructions” just like genes do. </p>



<p>Of course, our lives are increasingly digital. Arguably, more culture is mediated through media and tech platforms than in real life. Thinkers like Richard Dawkins and Daniel Dennett were talking about <a href="https://youtu.be/5f-JlzBuUUU?t=932">cultural evolution</a> and the <a href="https://www.youtube.com/watch?v=KzGjEkp772s">theory of mind</a> abstractly more than, say, lip-syncing TikToks. Even so, types of social media posts—as digital shipping containers for memes—help them propagate.</p>



<p>To social media’s credit, they’ve taken the Darwin-governed world of memes and built fairly Darwinian systems around them. Now, a retweet button here or a like button there governs how memes spread (or struggle for life). Digital memes satisfy all the evolutionary pre-conditions:</p>



<ul><li><strong>selection </strong>– some posts get comments &amp; likes, going viral and becoming part of public awareness</li><li><strong>variation </strong>– every story gets told slightly differently</li><li><strong>heredity </strong>– Meme image templates, quote tweeting, TikTok duets all derive from existing content</li></ul>



<p>You can expect a lineage to form from the most “successful” genres of social media posts. Viral templates survive for a reason.</p>



<p>Seeing social media through a memetic lens is, admittedly, a bit confusing. It’s hard to know where the shipping container begins and ends. In theory, they’re merely vehicles for culture to hitch a ride on. (As Blackmore wrote, memes are “substrate-neutral.”) But the mechanisms are worth studying. The difference between a Twitter meme (e.g. “Time for a thread”)  and newspaper meme (e.g. “Area man…”) is the memetic evolution has been turned up a few notches. It spawns imitators way faster. Anyone can chime in with their own version.</p>



<p>If memes behave like genes, perhaps the various tech platforms resemble the different climate zones, where possessing a certain trait is highly adaptive. (Aside: Is Facebook akin to a tropical rainforest, enabling the most memeo-diversity? It might not be provable or even helpful to ponder.) The point is certain memes are naturally selected based on their product choices.</p>



<p>Finally, and most notably, memes travel across regions at a startling pace. Like an invasive species caught in a ballast tank, digital shipping containers spread memes farther and faster than ever. Every human brain is now a potential target.</p>



<h2>The first great meme machine</h2>



<p>In 2006, internet analyst Mary Meeker was asked how Google could justify its acquisition of YouTube for $1.65B. Meeker made the bull case and pointed out that YouTube felt like a natural evolution:</p>



<blockquote><p><em>“What’s interesting to me about the evolution of media today is that these 3 minutes clips–and I’m generalizing–that are amateur in nature are often times very funny. Because people happen to be in the right place at the right time. When I first watched some funny videos on the internet, I was reminded of the early days of MTV when music was presented in a different way. And I was also reminded of the early days of Saturday Night Live…my hope and my bet is that [YouTube] was an event that will push the traditional content creators to focus more aggressively on monetizing their content on the internet.</em></p><cite><strong>Mary Meeker (</strong><a href="https://twitter.com/NpappaG/status/1059891535553138689?s=20"><strong>full clip</strong></a><strong>)</strong></cite></blockquote>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><div lang="en" dir="ltr"><p>Tech Analyst GOALS: vintage edition</p><p>Mary Meeker on Google's then-insane purchase of YouTube (circa 2006). </p><p>-believed in amateur content far before it was obvious<br>-uses great analogies (MTV, SNL) <br>-prescient call on YT's creator network<br>(h/t <a href="https://twitter.com/mlcwong?ref_src=twsrc%5Etfw">@mlcwong</a>) <a href="https://t.co/HsAK7Slobx">pic.twitter.com/HsAK7Slobx</a></p></div>— Nick Pappageorge (@NpappaG) <a href="https://twitter.com/NpappaG/status/1059891535553138689?ref_src=twsrc%5Etfw">November 6, 2018</a></blockquote></div>
</div></figure>



<p>The analysis still looks spot-on 14 years later.</p>



<p>What made YouTube special was its ability to aggregate short, punchy clips that are “amateur in nature.” The rest is history. With time, that ushered in a whole creator economy and encouraged media corporates to buy in. Now, banks value YouTube at $200B – $300B alone, making it one of the greatest M&amp;A deals of all time.</p>



<p>YouTube’s scale and early start allowed it to enjoy a near-monopoly on virality, at least in video form. “<a href="https://www.youtube.com/watch?v=kfFcyTuopbI">Damn Daniel</a>” and countless other memes from YouTube have ported over to everyday conversation. Previously, viral internet ideas spread as static images with editable text. Video added a new level of fidelity.&nbsp;</p>



<p>Now, YouTube’s scale allows the world’s ideas, jokes, and culture get replicated to the tune of <a href="https://npappag.com/2020/01/10/youtube-is-the-worlds-biggest-radio-station/">100 billion hours per day</a>. Like any good social technology, YouTube unleashed an extremely powerful broadcast tool. In its wake, trillions of bits of cultural material spread from brain to brain. YouTube perhaps the first great meme machine on the internet.</p>



<p>In terms of meme replication power, YouTube enjoyed the last decade without a credible challenger. That is, until the rise of TikTok.</p>



<h2>The second great (video) meme machine</h2>



<p>TikTok has famously taken video virality to another level. There’s some great write-ups about the <a href="https://www.eugenewei.com/blog/2020/8/3/tiktok-and-the-sorting-hat">history of TikTok</a>, and how it <a href="https://turner.substack.com/p/the-rise-of-tiktok-and-understanding">pivoted </a>its app Musical.ly into what it is today. Personally, I think the most remarkable feature is TikTok’s explicit focus on memes.</p>



<p>TikTok’s main differentiator is audio-related. In every video, the audio itself can easily be “forked”—or copied—into a half-original new creation. All you have to do is film something compelling over it. This is not a huge secret. Every TikTok user knows there’s a song ID at the bottom of every video, and if pressed, will show you all the other videos using that song. From there, it will even encourage you to film your own imitation, lowering the friction to creation.</p>



<div><figure><video controls="" src="https://videos.files.wordpress.com/5xatgbOO/rpreplay_final1603556317.mp4"></video></figure><div>
<h4>Audio forking spawns thousands of imitations</h4>



<p>Currently, Fleetwood Mac’s song “Dreams” is <a href="https://www.cnn.com/2020/10/22/entertainment/fleetwood-mac-dreams-charts-trnd/index.html">back in the charts</a> again thanks to Doggface208 <a href="https://www.tiktok.com/@420doggface208/video/6876424179084709126?source=h5_m">posting</a> a TikTok video lip-syncing on a skateboard while drinking Ocean Spray. Thousands of others have “forked” the Fleetwood Mac audio, and replicated DoggFace208’s video while skateboarding on their own. Other hit songs have minted entire video genres. [See video left]</p>
</div></div>



<p>The platform offers more than just dancing along to famous songs. The same applies to videos with original audio, which also can go equally viral as people iterate on the audio-meme. Often, this is done with the “duet” feature, where creators anticipate remixes on a script they create.</p>



<p>TikTok’s chief innovation is often said to be the creation tools, the mobile focus, the constrained time limit, or the superior algorithm. Those are all important. But I suggest the most important factor is this “A/V forking”–splitting audio and video–that encourages imitation.</p>



<p>By splitting content into the audio and visual, the hurdle for creating an entertaining video gets (1) easier for the creator and (2) exponentially more competitive in aggregate. Often, the original post of a viral TikTok is outdone by imitators that “perform” over the audio in an <em>even more</em> entertaining way. As a result, TikTok’s native content is far more explosive and gripping compared to YouTube.</p>



<p>The way TikTok focuses on memes is intentional and apparently the product of rigorous focus group testing. From <a href="https://www.theinformation.com/articles/how-a-youtube-star-helped-make-tiktok-a-global-hit">The Information</a>‘s paywalled piece:</p>



<blockquote><p><em>TikTok …</em></p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://npappag.com/2020/10/29/audio-memes-why-tiktok-is-the-first-youtube-challenger/">https://npappag.com/2020/10/29/audio-memes-why-tiktok-is-the-first-youtube-challenger/</a></em></p>]]>
            </description>
            <link>https://npappag.com/2020/10/29/audio-memes-why-tiktok-is-the-first-youtube-challenger/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26002887</guid>
            <pubDate>Tue, 02 Feb 2021 16:22:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Framing Your Bets (and All Startups Are Bets)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26002849">thread link</a>) | @opsgal
<br/>
February 2, 2021 | https://boringstartupstuff.com/newsletter/feb-2nd-2021-how-to-make-big-decisions | <a href="https://web.archive.org/web/*/https://boringstartupstuff.com/newsletter/feb-2nd-2021-how-to-make-big-decisions">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span>A friend received an offer from a seed-stage startup this week. Already at another seed-stage startup, she asked my thoughts on the offer itself and on the switch between companies. I walked through the factors I consider in my own decisions, but as I talked, I felt less sure of my own process. Nothing in the startup world is certain; </span><a href="https://medium.com/@justincie/startup-success-isnt-about-genius-it-s-about-manipulating-the-odds-873d93d02029" rel="follow noopener" target="_blank"><span>we are all just betting on outcomes</span></a><span>. We can optimize for certain factors, but in the end, we must decide how to play our hand. Plenty has been written about joining a startup, but how do we decide when to leave one?&nbsp;&nbsp;</span></p>

<p><span>A startup is </span><a href="https://medium.com/start-up-vision/a-startup-is-either-growing-or-dying-564af328a6c4" rel="follow noopener" target="_blank"><span>either growing or dying</span></a><span>, and a well-positioned one should have a strong market, assets, and team. Even with all three, the journey will still be difficult. If the bus is going to run out of gas before reaching the destination, does it matter </span><a href="https://www.jimcollins.com/concepts/first-who-then-what.html" rel="follow noopener" target="_blank"><span>if I’m in the right seat</span></a><span>? First think through business viability to figure out if you even want to be on the bus. Here are questions I use to get started.</span></p>

<p><b>Market</b></p>
<p><span>If the market is established:</span></p>
<ul>
<li aria-level="2"><span>Who are the competitors in the space?</span></li>
<li aria-level="2"><span>What do the recent IPOs/acquisitions look like?</span></li>
<li aria-level="2"><span>What is the company’s competitive edge?</span></li>
</ul>

<p><span>If the market is new:</span></p>
<ul>
<li aria-level="1"><span>Why is now the right time to start the market?</span></li>
<li aria-level="1"><span>Why will the company succeed in places other companies haven’t gone?</span></li>
</ul>

<p><b>Assets</b></p>
<ul>
<li aria-level="1"><span>How far along is the product?</span></li>
<li aria-level="1"><span>Who are the customers and how are the relationships?</span></li>
<li aria-level="1"><span>What’s the funding situation?</span></li>
<li aria-level="1"><span>Who are the investors?</span></li>
</ul>

<p><b>Team</b></p>
<ul>
<li aria-level="1"><span>Does the team have the right experience to execute what needs to happen?</span></li>
<li aria-level="1"><span>Are there growth plans to mitigate the obstacles that lie ahead?</span></li>
<li aria-level="1"><span>Do people know their own strengths and weaknesses?</span></li>
<li aria-level="1"><span>Are difficult and honest conversations being had about the company’s direction?</span></li>
</ul>

<p><span>Feeling good about all three? Plenty can still go wrong, but your company might have a chance. If two of the three are in a good place, is there a route to quickly strengthen the third? What would it take to make that happen and how likely is the company to execute on it? It’s impossible to predict all of the factors crucial to success, but it doesn’t hurt to ask the questions.</span></p>

<p><span>Maybe the startup is doing incredibly well, but you’re feeling less sure about your seat on the bus. Is that a sign you need to leave or just </span><a href="https://medium.com/@ubiquityvc/startup-vs-big-tech-why-the-grass-isnt-always-greener-e8cebb6d5191" rel="follow noopener" target="_blank"><span>“grass is greener”</span></a><span> syndrome?&nbsp;</span></p>

<p><span>Try running a </span><a href="https://www.businessinsider.com/why-negative-thinking-can-help-you-successfully-make-decisions-2020-10" rel="follow noopener" target="_blank"><span>pre-mortem</span></a><span> on your career trajectory. Write out how you might fail and what the fallout could be. Will you lose relationships because of the long hours you put into the startup? Will the stress of the long hours cause you to pack on pounds? Will you end up wishing that you had stayed at your startup until it went public?&nbsp;</span></p>

<p><span>Looking at the worst case scenario can show us that what we most fear either won’t be that bad or that we can proactively avoid it. Identify the paths you’ll regret most and </span><a href="https://alyjuma.medium.com/the-regret-minimization-framework-how-jeff-bezos-made-decisions-4d5a86deaf24" rel="follow noopener" target="_blank"><span>work to avoid them</span></a><span>.</span></p>

<p><span>But what about the best case scenario in which your hard-earned equity turns into millions? </span><a href="https://www.financialsamurai.com/stock-options-are-for-suckers-who-accept-below-market-rate-pay/" rel="follow noopener" target="_blank"><span>It’s highly unlikely</span></a><span> but not impossible. Are you optimizing the factors that matter most to you where you are?&nbsp;</span></p>

<p><b>Salary</b></p>
<p><span>Early-stage startups aren’t known for particularly high salaries, but if you’re with the company as it goes through additional rounds of funding, this can change. Significant contributors have more leeway on compensation than they might know, especially if additional funding has come through.</span></p>

<p><b>Title</b></p>
<p><span>Yes, titles are subjective because they differ widely between companies, but they can also give weight to your credentials. Are there still opportunities to move up the ladder where you are, even if that will mean creating a new title? Would you be able to get the same title outside of your company?</span></p>

<p><b>Equity</b></p>
<p><span>Do you have enough stake in the company to feel that your contributions could eventually pay off? Again, it’s unlikely, but we have to </span><a href="https://eriktorenberg.substack.com/p/take-asymmetric-bets" rel="follow noopener" target="_blank"><span>take asymmetric bets</span></a><span> to win big.</span></p>

<p><b>Knowledge</b></p>
<p><span>Learning doesn’t pay the bills, but incredible experience from one role can shape the rest of your career.</span></p>
<ul>
<li><span>Are you getting more responsibility than you might at another company?&nbsp;</span></li>
<li><span>Are you in the room when big decisions are being made?</span></li>
<li><span>Are you working alongside industry experts that you may not have the chance to be near again?</span></li>
<li><span>Are you establishing relationships (customers, investors, coworkers) that will propel you forward later on?</span></li>
<li><span>Is your impact more significant where you are than at a larger, more established organization?&nbsp;</span></li>
</ul>

<p><span>If all else fails, determine where you ultimately want to go and </span><a href="https://medium.com/@m2jr/how-to-build-a-breakthrough-3071b6415b06" rel="follow noopener" target="_blank"><span>backtrack from there</span></a><span>. If you’re unsure of the destination, it doesn’t really matter which bus you get on.</span></p>
</div></div>]]>
            </description>
            <link>https://boringstartupstuff.com/newsletter/feb-2nd-2021-how-to-make-big-decisions</link>
            <guid isPermaLink="false">hacker-news-small-sites-26002849</guid>
            <pubDate>Tue, 02 Feb 2021 16:20:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A network performance measurement tools based on Microsoft's Ethr]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26002722">thread link</a>) | @teleforce
<br/>
February 2, 2021 | https://golangexample.com/a-network-performance-measurement-tools-base-on-microsoft-ethr/ | <a href="https://web.archive.org/web/*/https://golangexample.com/a-network-performance-measurement-tools-base-on-microsoft-ethr/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                                    <div><h2 id="ethrkai">ethr-kai</h2>
<p>This repo fork from karminski/ethr-kai and modified by Karminski-牙医. A WEB UI with websocket was added in this fork.</p>
<p>Ethr is a cross platform network performance measurement tool written in golang. The goal of this project is to provide a native tool for comprehensive network performance measurements of bandwidth, connections/s, packets/s, latency, loss &amp; jitter, across multiple protocols such as TCP, UDP, HTTP, HTTPS, and across multiple platforms such as Windows, Linux and other Unix systems.</p>
<p>Ethr takes inspiration from existing open source network performance tools and builds upon those ideas. For Bandwidth measurement, it is similar to iPerf3, for TCP &amp; UDP traffic. iPerf3 has many more options for doing such as throttled testing, richer feature set, while Ethr has support for multiple threads, that allows it to scale to 1024 or even higher number of connections, multiple clients communication to a single server etc. For latency measurements, it is similar to latte on Windows or sockperf on Linux.</p>
<p>Ethr provides more test measurements as compared to other tools, e.g. it provides measurements for bandwidth, connections/s, packets/s, latency, and TCP connection setup latency, all in a single tool. In the future, there are plans to add more features (hoping for others to contribute) as well as more protocol support to make it a comprehensive tool for network performance measurements.</p>
<p>Ethr is natively cross platform, thanks to golang, as compared to compiling via an abstraction layer like cygwin that may limit functionality. It hopes to unify performance measurement by combining the functionality of tools like iPerf3, ntttcp, psping, sockperf, and latte and offering a single tool across multiple platforms and multiple protocols.</p>

<p><a href="https://github.com/Microsoft/ethr/releases/latest">https://github.com/Microsoft/ethr/releases/latest</a></p>

<p>We need two computer: A, B.</p>
<p>Get released program from upper link .</p>
<p>Run on machine A:</p>
<pre><code>ethr-kai -s -web
</code></pre>
<p>And open your browser, type http://{machine A IP address}:8080/ the you can view the web page.</p>
<p>Run on machine B:</p>
<pre><code>ethr-kai -c {machine A IP address} -d {duration} -n {threads}
</code></pre>
<p>e.g.</p>
<pre><code>ethr-kai -c 192.168.1.2 -d 602 -n 4
</code></pre>
<p>And when test start, you can receive test data from browser.</p>

<p>Note: go version 1.11 or higher is required building it from the source.</p>
<h2 id="buildingfromsource">Building from Source</h2>
<p>We use go-module to manage Ethr dependencies. for more information please check <a href="https://github.com/golang/go/wiki/Modules#how-to-use-modules">how to use go-modules!</a></p>
<pre><code>git clone https://github.com/Microsoft/ethr.git
cd ethr
go get ./...
go build
</code></pre>
<p>If Ethr is cloned inside of the <code>$GOPATH/src</code> tree, please make sure you invoke the <code>go</code> command with <code>GO111MODULE=on</code>!</p>
<h2 id="docker">Docker</h2>
<p>Build image using command:</p>
<pre><code>docker build -t karminski/ethr-kai .
</code></pre>
<p>Make binary:</p>
<p><strong>Linux</strong></p>
<pre><code>docker run -e GOOS=linux -v $(pwd):/out karminski/ethr-kai make build-docker
</code></pre>
<p><strong>Windows</strong></p>
<pre><code>docker run -e BINARY_NAME=ethr.exe -e GOOS=windows -v $(pwd):/out karminski/ethr-kai make build-docker
</code></pre>
<p><strong>OS X</strong></p>
<pre><code>docker run -e BINARY_NAME=ethr-kai -e GOOS=darwin -v $(pwd):/out karminski/ethr-kai make build-docker
</code></pre>
<h2 id="usinggoget">Using go get</h2>
<pre><code>go get github.com/Microsoft/ethr
</code></pre>
<h2 id="usingarchlinuxaur">Using ArchLinux AUR</h2>
<p>Assuming you are using <a href="https://aur.archlinux.org/packages/yay/"><code>yay</code></a> (<a href="https://github.com/Jguer/yay">https://github.com/Jguer/yay</a>):</p>
<pre><code>yay -S ethr
</code></pre>

<p>Follow the topic Building from Source to build ethr.exe</p>
<p>Modify ethr.nuspec to add new release version</p>
<pre><code>vim ethr.nuspec
</code></pre>
<p>Create a nuget package(like Ethr.0.2.1.nupkg)</p>
<pre><code>nuget.exe pack ethr.nuspec
</code></pre>
<p>Upload the package to nuget.org.</p>

<h2 id="simpleusage">Simple Usage</h2>
<p>Help:</p>
<pre><code>ethr-kai -h
</code></pre>
<p>Server:</p>
<pre><code>ethr-kai -s
</code></pre>
<p>Server with Text UI:</p>
<pre><code>ethr-kai -s -ui
</code></pre>
<p>Server with WEB UI:</p>
<pre><code>ethr-kai -s -web
</code></pre>
<p>Client:</p>
<pre><code>ethr-kai -c &lt;server ip&gt;
</code></pre>
<p>Examples:</p>
<pre><code>// Start server
ethr-kai -s

// Start client for default (bandwidth) test measurement using 1 thread
ethr-kai -c localhost

// Start bandwidth test using 8 threads
ethr-kai -c localhost -n 8

// Start connections/s test using 64 threads
ethr-kai -c localhost -t c -n 64
</code></pre>
<h2 id="completecommandline">Complete Command Line</h2>
<pre><code>Ethr-改 (ethr-kai) - A comprehensive network performance measurement tool with web ui.
Version: [VERSION: UNKNOWN]
It supports 4 modes. Usage of each mode is described below:

Common Parameters
================================================================================
	-h 
		Help
	-no 
		Disable logging to file. Logging to file is enabled by default.
	-o &lt;filename&gt;
		Name of log file. By default, following file names are used:
		Server mode: 'ethrs.log'
		Client mode: 'ethrc.log'
		External server mode: 'ethrxs.log'
		External client mode: 'ethrxc.log'
	-debug 
		Enable debug information in logging output.
	-4 
		Use only IP v4 version
	-6 
		Use only IP v6 version

Mode: Server
================================================================================
	-s 
		Run in server mode.
	-ui 
		Show output in text UI.
	-web 
		Show output and charts on http port 8080.
	-ports &lt;k=v,...&gt;
		Use custom port numbers instead of default ones.
		A comma separated list of key=value pair is used.
		Key specifies the protocol, and value specifies base port.
		Ports used for various tests are calculated from base port.
		Example: For TCP, Bw: 9999, CPS: 9998, PPS: 9997, Latency: 9996
		Control is used for control channel communication for ethr.
		Note: Same configuration must be used on both client &amp; server.
		Default: 'control=8888,tcp=9999,udp=9999,http=9899,https=9799'

Mode: Client
================================================================================
	-c &lt;server&gt;
		Run in client mode and connect to &lt;server&gt;.
		Server is specified using name, FQDN or IP address.
	-r 
		For Bandwidth tests, send data from server to client.
	-d &lt;duration&gt;
		Duration for the test (format: &lt;num&gt;[ms | s | m | h]
		0: Run forever
		Default: 10s
	-n &lt;number&gt;
		Number of Parallel Sessions (and Threads).
		0: Equal to number of CPUs
		Default: 1
	-ncs 
		No per Connection Stats would be printed if this flag is specified.
		This is useful to suppress verbose logging when large number of
		connections are used as specified by -n option for Bandwidth tests.
	-l &lt;length&gt;
		Length of buffer to use (format: &lt;num&gt;[KB | MB | GB])
		Only valid for Bandwidth tests. Max 1GB.
		Default: 16KB
	-p &lt;protocol&gt;
		Protocol ("tcp", "udp", "http", "https", or "icmp")
		Default: tcp
	-ic 
		Ignore Certificate is useful for HTTPS tests, for cases where a
		middle box like a proxy is not able to supply a valid Ethr cert.
	-ports &lt;k=v,...&gt;
		Use custom port numbers instead of default ones.
		A comma separated list of key=value pair is used.
		Key specifies the protocol, and value specifies base port.
		Ports used for various tests are calculated from base port.
		Example: For TCP, Bw: 9999, CPS: 9998, PPS: 9997, Latency: 9996
		Control is used for control channel communication for ethr.
		Note: Same configuration must be used on both client &amp; server.
		Default: 'control=8888,tcp=9999,udp=9999,http=9899,https=9799'
	-t &lt;test&gt;
		Test to run ("b", "c", "p", or "l")
		b: Bandwidth
		c: Connections/s or Requests/s
		p: Packets/s
		l: Latency, Loss &amp; Jitter
		Default: b - Bandwidth measurement.
	-i &lt;iterations&gt;
		Number of round trip iterations for each latency measurement.
		Default: 1000

Mode: External Server
================================================================================
	-m &lt;mode&gt;
		'-m x' MUST be specified for external mode.
	-s 
		Run in server mode.
	-ports &lt;k=v,...&gt;
		Use custom port numbers instead of default ones.
		A comma separated list of key=value pair is used.
		Key specifies the protocol, and value specifies the port.
		Default: 'tcp=9999,http=9899,https=9799'

Mode: External Client
================================================================================
	-m &lt;mode&gt;
		'-m x' MUST be specified for external mode.
	-c &lt;destination&gt;
		Run in external client mode and connect to &lt;destination&gt;.
		&lt;destination&gt; is specified using host:port format.
		Example: www.microsoft.com:443 or 10.1.0.4:22 etc.
	-d &lt;duration&gt;
		Duration for the test (format: &lt;num&gt;[ms | s | m | h]
		0: Run forever
		Default: 10s
	-n &lt;number&gt;
		Number of Parallel Sessions (and Threads).
		0: Equal to number of CPUs
		Default: 1
	-ncs 
		No per Connection Stats would be printed if this flag is specified.
		This is useful to suppress verbose logging when large number of
		connections are used as specified by -n option for Bandwidth tests.
	-l &lt;length&gt;
		Length of buffer to use (format: &lt;num&gt;[KB | MB | GB])
		Only valid for Bandwidth tests. Max 1GB.
		Default: 16KB
	-p &lt;protocol&gt;
		Protocol ("tcp", "http", "https", or "icmp")
		Default: tcp
	-t &lt;test&gt;
		Test to run ("b", "c", or "cl")
		b: Bandwidth
		c: Connections/s or Requests/s
		cl: TCP connection setup latency
		Default: cl - TCP connection setup latency.
	-g &lt;gap&gt;
		Time interval between successive measurements (format: &lt;num&gt;[ms | s | m | h]
		0: No gap
		Default: 1s

</code></pre>

<table>
<thead>
<tr>
<th>Protocol</th>
<th>Bandwidth</th>
<th>Connections/s</th>
<th>Packets/s</th>
<th>Latency</th>
</tr>
</thead>
<tbody>
<tr>
<td>TCP</td>
<td>Yes</td>
<td>Yes</td>
<td>No</td>
<td>Yes</td>
</tr>
<tr>
<td>UDP</td>
<td>Yes</td>
<td>NA</td>
<td>Yes</td>
<td>No</td>
</tr>
<tr>
<td>HTTP</td>
<td>Yes</td>
<td>No</td>
<td>No</td>
<td>Yes</td>
</tr>
<tr>
<td>HTTPS</td>
<td>Yes</td>
<td>No</td>
<td>No</td>
<td>No</td>
</tr>
<tr>
<td>ICMP</td>
<td>No</td>
<td>NA</td>
<td>No</td>
<td>No</td>
</tr>
</tbody>
</table>

<p><strong>Windows</strong></p>
<p>Tested: Windows 10, Windows 7 SP1</p>
<p>Untested: Other Windows versions</p>
<p><strong>Linux</strong></p>
<p>Tested: Ubuntu Linux 18.04.1 LTS, OpenSuse Leap 15</p>
<p>Untested: Other Linux versions</p>
<p><strong>OSX</strong></p>
<p>Tested: OSX is tested by contributors</p>
<p><strong>Other</strong></p>
<p>No other platforms are tested at this time</p>

<p>Todo list work items are shown below. Contributions are most welcome for these work items or any other features and bugfixes.</p>
<ul>
<li>Test Ethr on other Windows versions, other Linux versions, FreeBSD and other OS</li>
<li>Support for UDP bandwidth &amp; latency testing</li>
<li>Support for HTTPS bandwidth, latency, requests/s</li>
<li>Support for HTTP latency and requests/s</li>
<li>Support for ICMP bandwidth, latency and packets/s</li>
</ul>
<h2 id="github">GitHub</h2>
</div>
                                </div></div>]]>
            </description>
            <link>https://golangexample.com/a-network-performance-measurement-tools-base-on-microsoft-ethr/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26002722</guid>
            <pubDate>Tue, 02 Feb 2021 16:11:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Should I test private methods? Q&A from talks about unit testings]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26002573">thread link</a>) | @rozkminiacz
<br/>
February 2, 2021 | https://kotlintesting.com/q-a-from-conferences-2020/ | <a href="https://web.archive.org/web/*/https://kotlintesting.com/q-a-from-conferences-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>In 2020 I had an opportunity to present my thoughts about crucial element of unit testing - test doubles. I discussed various examples of test doubles, ways to implement them and how they fit into specific test cases. Links to the conference talks you can find at the bottom of the article. </p><p>Every talk had time for Q&amp;A, and now I answer some of the questions that were asked. </p><h3 id="how-to-approach-testing-private-methods">How to approach testing private methods?</h3><blockquote>tl;dr: you don't test it directly, but within context </blockquote><p>Let's take a look at example:</p><pre><code>class ShouldITestPrivateMethods {
    fun processSomething(input: Int): String {
        return if (input &gt;= 420) {
            "Number is greater or equal 420"
        } else {
            "You need to add ${420 - input} to get 420"
        }
    }
}</code></pre><p>This class is pretty simple - returns some text based on input number. There is no private methods here. We write parameterized test for some cases and we compare result to expected values. </p><p>But during refactor we could've change it to something like this:</p><pre><code>class ShouldITestPrivateMethods {
    fun processSomething(input: Int): String {
        return if (input &gt;= CONSTANT_NUMBER) {
            "Number is greater or equal $CONSTANT_NUMBER"
        } else {
            "You need to add ${calculateDifference(input)} to get $CONSTANT_NUMBER"
        }
    }

    private fun calculateDifference(input: Int) = CONSTANT_NUMBER - input
    
    companion object{
        private const val CONSTANT_NUMBER = 420
    }
}</code></pre><p>Now we have private method here. Do we need to test that private method? If we provided enough reasonable test cases for method <em>processSomething() </em>then we should be secure about that. </p><p>On the other hand, if for some reason that calculation become more complex, we could think about extracting this private method into separate class, that would be tested alone in isolation.</p><pre><code>class DifferenceCalculator {
    fun differenceBetween(first: Int, second: Int): Int {
        return first - second
    }
}

class ShouldITestPrivateMethods(
    private val differenceCalculator: DifferenceCalculator
) {
    fun processSomething(input: Int): String {
        return if (input &gt;= CONSTANT_NUMBER) {
            "Number is greater or equal $CONSTANT_NUMBER"
        } else {
            "You need to add ${calculateDifference(input)} to get $CONSTANT_NUMBER"
        }
    }

    fun calculateDifference(input: Int) = differenceCalculator.differenceBetween(
        first = CONSTANT_NUMBER,
        second = input
    )

    companion object {
        private const val CONSTANT_NUMBER = 420
    }
}</code></pre><p>To sum things up:</p><ul><li>test private behavior in context of public accessors</li><li>refactor private behavior - extract it to higher component</li><li>don't just change private modifier to public to test code</li></ul><p>And last, but not least, don't make private method public. Your future self will thank you for keeping strict property access. </p><h3 id="do-you-use-verifynomoreinteractions">Do you use verifyNoMoreInteractions?</h3><blockquote>tl;dr In unit tests - almost never. In integrations tests - sometimes.</blockquote><p>Let's take a look at javadoc for <em>Mockito.verifyNoMoreInteractions:</em></p><pre><code>/**
* Checks if any of given mocks has any unverified interaction.
* &lt;p&gt;
* You can use this method after you verified your mocks - to make sure that nothing
* else was invoked on your mocks.
**/</code></pre><p>Where it could be useful? Lets take a look at example.</p><pre><code>import java.util.function.Consumer

class System(
    private val consumer: Consumer&lt;Any&gt;
) : AutoCloseable {

    var shouldAccept = true

    fun ping() {
        if (shouldAccept) {
            consumer.accept(Any())
        }
    }

    override fun close() {
        shouldAccept = false
    }
}</code></pre><p>Now we'd like to assert that consumer won't accept value if system was already closed:</p><pre><code>import com.nhaarman.mockitokotlin2.*
import org.junit.jupiter.api.Test

class Verifications {
    @Test
    fun checkVerifications() {
        val mockConsumer = mock&lt;Consumer&lt;Any&gt;&gt;()
        val system = System(consumer = mockConsumer)

        system.ping()
        system.ping()

        verify(mockConsumer, times(2)).accept(any())

        system.close()
        system.ping()

        verifyNoMoreInteractions(mockConsumer)
    }
}</code></pre><p> We're checking that after system creation and two <em>ping() </em>method invocations, consumer accepted two values. Then, we close system and make one more extra assertion: no more interactions on mock.</p><p>We can refactor this test method to check the same behavior without using <em>noMoreInteractions:</em></p><pre><code>class Verifications {
    @Test
    fun checkVerifications() {
        val mockConsumer = mock&lt;Consumer&lt;Any&gt;&gt;()
        val system = System(consumer = mockConsumer)

        system.ping()
        system.ping()

        system.close()
        system.ping()

        verify(mockConsumer, times(2)).accept(any())
    }
}</code></pre><p>And now we have one assertion at the end of the test.</p><p>Is using <em>verifyNoMoreInteractions</em> worth it? Maybe it is, for work-in-progress tests when you are not sure how to approach given test scenario or for more complex integrations test when you have to be sure that nothing else happened on given mock. But I'm sure that in unit test scenario there are better tools to do the same job.</p><h3 id="should-android-developers-exchange-mockito-with-mockk">Should Android developers exchange Mockito with MockK?</h3><blockquote>tl;dr: it's up to your preferences and your coding style</blockquote><p>I would rephrase this question to <em>should Kotlin developers exchange Mockito with MockK</em>, since most of new native Android projects are written in Kotlin.</p><p>For new projects: <strong>absolutely</strong> <strong>yes</strong>. Mockk gives you first-class Kotlin support (such as mocking suspend functions). </p><p><strong>You don't have to rewrite all your test doubles from Mockito to MockK</strong> - it is possible to use together even within the same test class, but for the sake of readability, use one mocking framework for one test class. If you just adding new test cases to existing class - use mocking framework that was used there before.</p><h3 id="how-about-using-mockito-kotlin-instead-of-regular-mockito-in-kotlin-projects">How about using Mockito-Kotlin instead of regular Mockito in Kotlin projects?</h3><blockquote>tl;dr It's the way.</blockquote><p>For rewriting regular Mockito test case to Mockito-Kotlin DSL check this article:</p><figure><a href="https://kotlintesting.com/using-mockito-in-kotlin-projects/"><div><p>Using Mockito in Kotlin projects</p><p>Refactoring Java Mockito based test suite to Mockito-Kotlin DSL</p><p><img src="https://kotlintesting.com/favicon.png"><span>Kotlin Testing</span></p></div><p><img src="https://kotlintesting.com/content/images/2020/10/mint.jpeg"></p></a></figure><h3 id="how-to-approach-building-test-suite-for-project-that-has-no-tests-at-all">How to approach building test suite for project that has no tests at all?</h3><blockquote>tl;dr: start with integration tests and once they are passing, refactor and write unit tests</blockquote><p>That surely depends on complexity of your project. If there are no test at all, you would focus on testing components that has highest business value. You may start here with integration or E2E tests. </p><p>For backend project - you can start with testing REST controller - &nbsp;you setup in-memory database, setup rest of Spring context and just invoke controllers method with given set of params. </p><p>For backend projects in Ktor - check this article:</p><figure><a href="https://kotlintesting.com/intro-to-testing-ktor-controllers/"><div><p>Testing Ktor Controllers</p><p>Functional tests in Ktor - how to mock application server with TestApplicationEngine?</p><p><img src="https://kotlintesting.com/favicon.png"><span>Jarosław Michalik</span><span>Kotlin Testing</span></p></div><p><img src="https://kotlintesting.com/content/images/2020/11/Zrzut-ekranu-2020-11-8-o-12.05.19.png"></p></a></figure><p>For mobile projects - you may record test cases with Espresso recorder or start with integration test for presentation layer.</p><p>If you have happy few paths tested - you may start with refactoring code to clean architecture approach. Once SOLID, or at least dependency inversion principle are introduced, create unit test. &nbsp;</p><p><strong>But what if I'm not sure which components has the highest business value? </strong>Check this tool. It will give you some insights about code based on git repository history, including which files were edited most frequently and which files where changed together with others.</p><figure><a href="https://codescene.io/"><div><p>CodeScene</p><p>CodeScene by Empear - The history of your code will decide its future.</p><p><img src="https://codescene.io/favicon.png"><span>Empear</span></p></div><p><img src="https://codescene.io/symbols/playcloud.svg"></p></a></figure><h3 id="when-to-use-mock-and-when-to-use-fake">When to use mock, and when to use fake?</h3><p>In this context we call <em>mock </em>a test double generated by framework such as Mockito or MockK, and <em>fake -</em> lightweight implementation of system under test dependency.</p><p>That surely depends on your test case. For stubbing - go with fake. If your test case need using side effect verification - use mock. </p><p>General rules I try to follow when deciding if I should go with fake or with mock:</p><ul><li>if I have single method interface - fake</li><li>if I have to throw exception inside method - fake</li><li>if I have to match specific argument - mock + matchers</li><li>if I have to create test double for larger component and I don't feel like implementing all methods - mock</li></ul><p>Or in simpler words - choose faster method. </p><hr><h3 id="fake-it-till-you-make-it-effective-use-of-test-doubles">Fake it till you make it - effective use of test doubles</h3><p>Thanks again for inviting me to Droidcon series and Devfest Poland - it was great pleasure to be among great speakers! Hopefully we will come back to offline conferences quickly.</p><figure><a href="https://www.droidcon.com/media-detail?video=491024627"><div><p>Fake it till you make it - effective use of test doubles</p><p>Test doubles are powerful tool in developer trying to write unit tests. Mocks allow us to keep system under test isolated so we can check given scenarios and perform assertions on singular piece of logic with ease. In this talk I will dive into fakes, mocks and other test doubles and I will present …</p><p><img src="https://www.droidcon.com/droidcon-exo-theme/android-icon-192x192.png"><span>droidcon News Tech Showcases, Developer Resources &amp; Partners /portal/rest/jcr/repository/collaboration/Groups/spaces/droidcon_hq/Documents/public/home-details/EmployerBrandingHeader EmployerBrandingHeader https://jobs.droidcon.com/ /portal/rest/jcr/repository/collaboration/Groups/spaces/droidcon_hq/Documents/public/employerbranding/jobs-droidcon/jobs.droidcon.com jobs.droidcon.com Latest Android Jobs http://www.kotlinweekly.net/ /portal/rest/jcr/repository/collaboration/Groups/spaces/droidcon_hq/Documents/public/employerbranding/kotlin-weekly/Kotlin Weekly Kotlin Weekly Your weekly dose of Kotlin https://proandroiddev.com/ /portal/rest/jcr/repository/collaboration/Groups/spaces/droidcon_hq/Documents/public/employerbranding/pad/ProAndroidDev ProAndroidDev Android Tech Blogs, Case Studies and Step-by-Step Coding /detail?content-id=/repository/collaboration/Groups/spaces/droidcon_hq/Documents/public/employerbranding/Zalando/Zalando /portal/rest/jcr/repository/collaboration/Groups/spaces/droidcon_hq/Documents/public/employerbranding/Zalando/Zalando Zalando Meet one of Berlin's top employers …</span></p></div></a></figure></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kotlintesting.com/q-a-from-conferences-2020/">https://kotlintesting.com/q-a-from-conferences-2020/</a></em></p>]]>
            </description>
            <link>https://kotlintesting.com/q-a-from-conferences-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26002573</guid>
            <pubDate>Tue, 02 Feb 2021 16:02:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Behaviours to avoid in a software architecture role]]>
            </title>
            <description>
<![CDATA[
Score 204 | Comments 126 (<a href="https://news.ycombinator.com/item?id=26002543">thread link</a>) | @geidies
<br/>
February 2, 2021 | https://www.danielwatts.info/post/7-behaviours-to-avoid-software-architect/ | <a href="https://web.archive.org/web/*/https://www.danielwatts.info/post/7-behaviours-to-avoid-software-architect/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>Over the years, I’ve had the opportunity to work in architecture roles alongside experienced software/technical/solution architects. Through observing others and my own trial and error, I’ve learned a little bit about what <em>not</em> to do in these roles (because it’s often easier to reflect on what didn’t work rather than what did). Even though I lean towards the idea that everyone should be architecting the system rather than having architects solely responsible - I recognise that some organisations are far from that ideal, and it’s those folks I hope find this list helpful. So here it is, 7 behaviours to avoid if you’re in a software architecture role:</p>
<h2 id="1-dont-ignore-the-engineering-team">1. Don’t ignore the engineering team</h2>
<p>If you’re not “hands-on” with the engineering team either through writing or reviewing code or deep in the technical discussions, then the likelihood is you aren’t close enough to the problems and the individuals on the team. If you’re not feeling their pain, then you are probably lacking the empathy and understanding to provide effective guidance. If you find yourself in this position, I would consider beginning with one-on-ones and pairing with engineers as the quickest way to increase empathy and understanding. Then look to participate in feature kick-offs, technical design discussions and code reviews where necessary.</p>
<h2 id="2-dont-ignore-the-domain">2. Don’t ignore the domain</h2>
<p>It’s part of the role to become a domain expert. This knowledge can be used to act as an effective translator between business and engineering. That said, you’ll want to avoid being a communication bottleneck too, so it’s important to teach, translate and document domain context and business value for the engineering team. This is where techniques like <a href="https://www.atlassian.com/continuous-delivery/principles/value-stream-mapping">value-stream mapping</a>, <a href="https://en.wikipedia.org/wiki/Event_storming">event storming</a> and <a href="https://twitter.com/ntcoding/status/1342805885224177666">domain-driven design</a> can really help.</p>
<h2 id="3-dont-prescribe-or-mandate-architectures">3. Don’t prescribe or mandate architectures</h2>
<p>For the most part, our industry has moved past the notion that a system’s architecture is designed in isolation (or in an ivory tower) and handed-off to engineers to deliver. However, it definitely still happens. Software architecture and development should be inter-weaving activities, with feedback from one influencing the other. Keeping that feedback loop as short as possible will likely lead to better outcomes. So if you would like to design and create more resilient systems and your organisation tends to mandate or prescribe architectures; consider how you can best empower engineers to make sound architecture decisions instead. Working with the engineers to agree on a foundation of architectural principles and accepting that architecture is never done, it should evolve and change over time are good places to begin (see the <a href="https://www.thoughtworks.com/books/building-evolutionary-architectures">Building Evolutionary Architectures</a> book for more on this).</p>
<h2 id="4-dont-just-seek-architectural-consistency">4. Don’t just seek architectural consistency</h2>
<p>Consistency certainly has a place in organisations that build and maintain many systems in order to to help prevent complexity. In my opinion, it’s better to see it as a guideline that will likely have exceptions. Simply seeking or worse, enforcing consistency is a sure-fire way to slow the team down, squash innovation and reduce learning opportunities.</p>
<h2 id="5-dont-forget-about-the-current-architectural-state">5. Don’t forget about the current architectural state</h2>
<p>It can be useful to model a target architecture based on agreed principles and in collaboration with engineers (see #1 and #3 above). However, it must be founded in all the nuance and understanding of the current architecture. Anything else could lead towards a doomed rewrite, an unhappy team or a failed pitch to some confused engineers.</p>
<p>On a similar note, I’ve seen many conversations where stakeholders begin to assume the target state is in fact the current state. This can have significant downsides for the engineering team, for example; a sense of moving too slow, missed tasks that were presumed completed or a lack of appreciation upon completing a large chunk of technical work. Stakeholder discussions about target state may need to include regular reminders about the current state.</p>
<h2 id="6-dont-get-too-attached-to-the-desired-architecture">6. Don’t get too attached to the desired architecture</h2>
<p>It can be easy to fall into the trap of attaching an opinion to your identity, particularly if you’ve got the task of providing a technical direction for an engineering team. New information and unforeseen circumstances will emerge, so any target state will 100% change. As these scenarios surface, you will need to keep an open mind to adapt your view and the direction. A fixed view will only hold back progress. As mentioned in #3, the architecture should be going through constant, incremental change.</p>
<h2 id="7-dont-let-review-processes-stagnate">7. Don’t let review processes stagnate</h2>
<p>As an architect in a large organisation you are likely to be responsible for or actively involved in architectural and security review processes, either as a reviewer or seeking a review. These processes are often change approval reviews that give the green-light for a production release. They can be long and drawn out, unclear in their value, involve reviewers who have zero context, and result in unwanted or unnecessary outcomes; making them the perfect candidates for resisting change. As a more senior figure, an architect should be working hard against that intuition. They should seek to understand the purpose and value of the review process and relay it to others. They should be leading or guiding engineering teams through these processes, particularly for the first time. But most importantly, they should be constantly pushing to <a href="https://cloud.google.com/solutions/devops/devops-process-streamlining-change-approval">improve, reduce or potentially remove a review process</a> depending on its purpose and added value.</p>
<p>There you have it! Hopefully I’ll learn even more things to avoid in future but for now, avoid these and you should be good; or at the very least better than a bunch of scenarios I’ve witnessed. For more advice on the topic of software architecture, check out these excellent reads too:</p>
<ul>
<li><a href="https://martinfowler.com/articles/architect-elevator.html">The  Architect Elevator</a> - Visiting the upper floors</li>
<li><a href="https://martinfowler.com/articles/value-architectural-attribute.html">The Elephant in the Architecture</a> - Why business value should be treated as an architectural attribute</li>
<li><a href="https://mailchi.mp/4aeb4085ec6a/17-dear-architects?e=65367d58cd">This book reading list</a> by <a href="https://www.deararchitects.xyz/">Dear Architects,</a> has five books worth reading, including <a href="https://www.thoughtworks.com/de/books/building-evolutionary-architectures">Building Evolutionary Architectures</a>, and sums them up better than I could. It’s also an excellent newsletter.</li>
</ul>
<p><em>Thanks to Vivek Jain, Hugo Nogueira and Robin Weston for reviewing various versions of this post.</em></p>

    </div></div>]]>
            </description>
            <link>https://www.danielwatts.info/post/7-behaviours-to-avoid-software-architect/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26002543</guid>
            <pubDate>Tue, 02 Feb 2021 16:00:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting better at Linux with mini-projects]]>
            </title>
            <description>
<![CDATA[
Score 892 | Comments 111 (<a href="https://news.ycombinator.com/item?id=26002335">thread link</a>) | @carltheperson
<br/>
February 2, 2021 | https://carltheperson.com/posts/10-things-linux | <a href="https://web.archive.org/web/*/https://carltheperson.com/posts/10-things-linux">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><i>2020-11-28<!-- --> Carl Riis</i></p><hr><h3>How do you advance your Linux skills when you are already comfortable with the basics? My solution was to come up with 10 subjects to learn and create an accompanying mini-project.</h3><p>All the source code for the projects can be found in <a href="https://github.com/carltheperson/10-things-linux">this</a> GitHub repository.</p><h2>1. UNIX - <a href="https://github.com/carltheperson/10-Things-Linux/tree/master/1_UNIX__Recat">Recat</a></h2><p>The first thing I wanted to learn more about was UNIX since Linux is a UNIX-like operating system. I also never really felt that I fully understood what exactly UNIX was, besides being a family of fairly similar operating systems.</p><p>The first thing I did was to read the entire Wikipedia page on UNIX. I also read <a href="https://people.eecs.berkeley.edu/~brewer/cs262/unix.pdf">this</a> original paper written by Dennis Ritchie and Ken Thompson from 1974, which was really interesting though I can’t say I understood all of it. After some more reading and some Youtube videos, I felt comfortable that I understood what UNIX was, and what makes it interesting.</p><p>For the project, I decided to try and write my first C program. Following the Unix philosophy, I made sure that it did one thing only. That thing ended up being a program that reverses the contents of a text file. Since this is just a reverse version of <em>cat</em>, I called the program <em>recat</em>.</p><p><img src="https://carltheperson.com/media/10-things-linux/1_UNIX__Recat/screenshot.png" alt=""></p><h2>2. What is a shell? - <a href="https://github.com/carltheperson/10-Things-Linux/tree/master/2_What_is_a_shell__SeaShell">SeaShell</a></h2><p>For this project, I was curious to find out what exactly a shell was. Even though it is something that I use often, I was still confused about what differentiates it from the terminal. Turns out it’s really not that complicated. I learned this by rereading the <em>shell</em> part of <a href="https://people.eecs.berkeley.edu/~brewer/cs262/unix.pdf">the paper</a> from the previous project, and some explanations online like <a href="https://www.tutorialspoint.com/unix/unix-what-is-shell.htm">this</a> and <a href="https://linuxcommand.org/lc3_lts0010.php">this one</a>. The Unix shell Wikipedia entry was also very informative.</p><p>Since this project is about the shell, I found it appropriate to try and write my own. I settled on the name <em>SeaShell</em>, which I found way too funny. It’s not very advanced, but it does the job.</p><p><img src="https://carltheperson.com/media/10-things-linux/2_What_is_a_shell__SeaShell/screenshot.png" alt=""></p><h2>3. Ownership and permissions - <a href="https://github.com/carltheperson/10-Things-Linux/tree/master/3_Ownership_and_permissions__Tellaccess">Tellaccess</a></h2><p>This is one of the things that I know is really important for Linux, but have never really understood. I have tried before but never been able to get the knowledge to stick, maybe because I didn't really care about security until now.</p><p>The ownership and permission system turned out to be really intuitive, and I was able to understand the basics from <a href="https://www.thegeekdiary.com/understanding-basic-file-permissions-and-ownership-in-linux/">this</a> one article. I later discovered <a href="https://linuxhandbook.com/linux-file-permissions/">this one</a> from Linux Handbook which was more comprehensive.</p><p>For the project, I decided to create a program that tells you in human-readable form, the ownership and permissions of a file. I called the project <em>tellaccess</em> because it tells you who can access the file in what ways.</p><p><img src="https://carltheperson.com/media/10-things-linux/3_Ownership_and_permissions__Tellaccess/screenshot.png" alt=""></p><h2>4. Grep - <a href="https://github.com/carltheperson/10-Things-Linux/tree/master/4_Grep__Grep_detective">Grep detective</a></h2><p>Grep is the sort of UNIX magic I have always wanted to learn. Since <em>grep</em> is all about regular expressions I would have to learn that first. This was actually quite difficult because grep uses the <em>POSIX Basic Regular Expressions</em>, which is not that common. The <a href="https://en.wikibooks.org/wiki/Regular_Expressions/POSIX_Basic_Regular_Expressions">Wikipedia entry</a> was a lifesaver. Besides that, I also used the man page for <em>grep</em> as a reference.</p><p>For the project, I thought that a fun idea might be to create a detective game. In the game, you get a folder full of files, and it’s your job to extract information. I called the game <em>Grep detective</em>.</p><p><img src="https://carltheperson.com/media/10-things-linux/4_Grep__Grep_detective/screenshot.png" alt=""></p><h2>5. Awk and sed - <a href="https://github.com/carltheperson/10-Things-Linux/tree/master/5_Awk_and_sed__Passwdinfo">Passwdinfo</a></h2><p><em>Awk</em> and <em>sed</em> are more of the UNIX magic that I have always thought was really cool, though I never really understood what they were used for. I often saw answers on Stack Overflow with people using them in crazy one-liners, but I always copy-pasted them without much thought. Well, time to unravel the mystery.</p><p>I primarily used <a href="https://www-users.york.ac.uk/~mijp1/teaching/2nd_year_Comp_Lab/guides/grep_awk_sed.pdf">this</a> paper to learn about them. For the project, I wanted to create my own one-liner that shows information about the users on your system in a clear way. I found just reading the <em>/etc/passwd</em> a little too messy, so the project <em>passwdinfo</em>, displays the most important information in a neat table. I found information about the <em>/etc/passwd</em> file <a href="https://www.cyberciti.biz/faq/understanding-etcpasswd-file-format/">here</a>.</p><p><img src="https://carltheperson.com/media/10-things-linux/5_Awk_and_sed__Passwdinfo/screenshot.png" alt=""></p><h2>6. Find - <a href="https://github.com/carltheperson/10-Things-Linux/tree/master/6_Find__Find_treasure_hunt">Find treasure hunt</a></h2><p>Another important tool I never really got around to learning. Learning how to use <em>find</em> was fairly easy, it was mostly about memorizing the different flags, and the format you set the flags in. I used <a href="https://kb.iu.edu/d/admm">this</a> as a reference.</p><p>For the project, I created a treasure hunt where you look for clues in files with different attributes. I first wrote a script that created a bunch of small files and directories as noise. Then a selected few of the files got clues to the whereabouts of the other ones. In the end, you find the treasure, which I won’t tell you what is.</p><p><img src="https://carltheperson.com/media/10-things-linux/6_Find__Find_treasure_hunt/screenshot.png" alt=""></p><h2>7. File system - <a href="https://github.com/carltheperson/10-Things-Linux/tree/master/7_File_system__Root_tour">Root tour</a></h2><p>Ever since I executed my first <em>ls /</em> I have wondered what all those directories were for. Time to unveil the mystery. The first thing I did was read <a href="https://www.linux.com/training-tutorials/linux-filesystem-explained/">this</a> article as it explained each directory in root and provided a nice graph. <a href="https://tldp.org/LDP/intro-linux/html/sect_03_01.html">This</a> resource was also nice since it had a table that summed up each directory in one or two sentences.</p><p>The project ended up being a program that gives you descriptions for directories in your own root folder.</p><p><img src="https://carltheperson.com/media/10-things-linux/7_File_system__Root_tour/screenshot.png" alt=""></p><h2>8. Processes - <a href="https://github.com/carltheperson/10-Things-Linux/tree/master/8_Processes__Stranger_danger">Stranger danger</a></h2><p>Processes are another important element of Linux that I have never gotten around to learning. Like many other subjects I have covered here, it turned out to be fairly intuitive. <a href="https://www.geeksforgeeks.org/processes-in-linuxunix/">This</a> article was really easy to understand.</p><p>I was contemplating for a while what kind of project I could create but ultimately came up with a command that prints all processes that don’t belong to you or root. That way, you can keep a close eye on who is creating processes. Note, there are many legitimate reasons that other users would run processes on your system, and it rarely means someone has gained access to your computer.</p><p><img src="https://carltheperson.com/media/10-things-linux/8_Processes__Stranger_danger/screenshot.png" alt=""></p><h2>9. Systemd services - <a href="https://github.com/carltheperson/10-Things-Linux/tree/master/9_Systemd_services__Createservice">Createservice</a></h2><p>Whenever I try to set up a database on a Linux machine I have been confused about how to configure the <em>systemd</em> service. I have also been in situations where I needed to create a service from a binary but always struggled. The struggle ends now.
As with any new subject, it’s always a good idea to read the Wikipedia page, so that is where I started. Surprisingly, I learned that <em>systemd</em> is a quite controversial piece of software, but I still wanted to learn it and judge it for myself.
For understanding the basics of <em>systemd</em> I read <a href="https://www.digitalocean.com/community/tutorials/how-to-use-systemctl-to-manage-systemd-services-and-units">this</a> and for understanding how to create a new service I read <a href="https://www.tecmint.com/create-new-service-units-in-systemd/">this</a>.</p><p>For the project, I made <em>createservice</em>, which allows you to make a <em>systemd</em> service from any executable that will automatically start up on boot. Here I test it out on Prometheus:</p><p><img src="https://carltheperson.com/media/10-things-linux/9_Systemd_services__Createservice/screenshot.png" alt=""></p><h2>10. Bash scripting - <a href="https://github.com/carltheperson/10-Things-Linux/tree/master/10_Bash_scripting__Penguin_cipher">Penguin cipher</a></h2><p>Bash scripting is something I have been avoiding for a long time. Partly because I believe that my programming language of choice, Go, is almost as handy when it comes to scripting, and partly because I think that Bash syntax looks horrible. Can’t knock it till you try it, so here I am trying to learn Bash scripting.</p><p><a href="https://www.howtogeek.com/67469/the-beginners-guide-to-shell-scripting-the-basics/">This</a> was a nice introduction, and after finding <a href="https://devhints.io/bash">this</a> cool cheatsheet I felt comfortable trying to create a project.</p><p>The project ended up being a cipher program I called <em>Penguin cipher</em> after Linux’s mascot. It allows you to encrypt text into something like this: <em>MTExIDIxMSAzMTMgNDAyIDQ2OCA0NjQgMTU5IDI0MSAyMzAgMzY3IDM3NCA1MjYgMTM3IDIyMiAyOTUgMzYzIDQzNCA0MzUg</em></p><p><img src="https://carltheperson.com/media/10-things-linux/10_Bash_scripting__Penguin_cipher/screenshot.png" alt=""></p><hr><p>Follow me on <a href="https://twitter.com/carltheperson">Twitter</a></p><div><p>Email me at: <!-- -->  </p><div><p>c</p><p>a</p><p>r</p><p>l</p><p>t</p><p>h</p><p>e</p><p>p</p><p>e</p><p>r</p><p>s</p><p>o</p><p>n</p><p>_</p><p>p</p><p>r</p><p>o</p><p>t</p><p>o</p><p>n</p><p>m</p><p>a</p><p>i</p><p>l</p><p>:</p><p>c</p><p>o</p><p>m</p></div></div></div></div></div>]]>
            </description>
            <link>https://carltheperson.com/posts/10-things-linux</link>
            <guid isPermaLink="false">hacker-news-small-sites-26002335</guid>
            <pubDate>Tue, 02 Feb 2021 15:47:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Engineering a real-time phishing simulation proxy in Rust]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26002299">thread link</a>) | @juxhindb
<br/>
February 2, 2021 | https://www.phishdeck.com/blog/phinn-on-engineering-a-real-time-phishing-simulation-proxy/#content | <a href="https://web.archive.org/web/*/https://www.phishdeck.com/blog/phinn-on-engineering-a-real-time-phishing-simulation-proxy/#content">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Advanced phishing attacks are becoming <a href="https://enterprise.verizon.com/resources/reports/dbir/" target="_blank">increasingly commonplace</a>
with tools that allow attackers to harvest credentials, bypass Two-factor authentication (2FA), as well as run automated post-exploit scripts the instant you enter your credentials. This post takes a look at our journey towards releasing <strong>Phinn</strong>, the real-time phishing simulation proxy that sits at the core of the PhishDeck phishing simulation platform.</p><p>In recent years we have seen a dramatic surge and shift in the phishing landscape that we have not seen in a very long time. We now have open-source tools that make it far more accessible than ever before for attackers to set up phishing websites that are virtually indistinguishable from their original counterparts both visually and, more importantly, in their behaviour.</p><blockquote><div lang="en" dir="ltr"><p>Recently we chased a skilled red team in <a href="https://twitter.com/hashtag/AWS?src=hash&amp;ref_src=twsrc%5Etfw">#AWS</a> that:</p><p>- bypassed MFA<br>- intercepted user sessions w/ <a href="https://twitter.com/hashtag/Evilginx?src=hash&amp;ref_src=twsrc%5Etfw">#Evilginx</a><br>- deployed python-based backdoors on EC2 instances<br>- located key creds on Redshift db<br>- escalated privs via role assumptions</p><p>More details here: <a href="https://t.co/sf25Ovij3w">https://t.co/sf25Ovij3w</a></p></div>— Jon Hencinski (@jhencinski) <a href="https://twitter.com/jhencinski/status/1333808403400024065?ref_src=twsrc%5Etfw">December 1, 2020</a></blockquote><p>With the adoption of 2FA (albeit somewhat slow) we increase the barrier of entry for attackers. Security vendors have been innovative with their drive towards WebAuthn/U2F solutions, however we see slower adoption in phishing simulation platforms to actively reflect advanced phishing and social engineering attacks to gauge the former’s effectiveness, particularly with WebAuthn being clearer and more precise. Anyone that operates in, or with, a security blue-team (i.e. defense) knows that time-saving and effective solutions are imperative to act as a counterbalance that they can rely on and use.</p><p>The security community has been phenomenal at open-sourcing multiple standalone tools and sharing their knowledge through <a href="https://rhinosecuritylabs.com/aws/mfa-phishing-on-aws/" target="_blank">technical articles</a>
as well as <a href="https://youtu.be/glzq5yL8LCE" target="_blank">conference talks</a>
around real-time phishing. The primary objective of these tools are to act as standalone tools that form part of a red-team’s, security consultant’s or pentester’s toolkit during security engagements — harvesting user credentials, sessions and 2FA/MFA tokens as well as run post-exploit automation scripts.</p><p>As a phishing simulation platform, PhishDeck’s scope is different, and therefore has different requirements that need to be met, be that performance, scalability or safety. We could have simply turned to popular open-source real-time phishing tools such as <a href="https://github.com/kgretzky/evilginx2" target="_blank">EvilGinx2</a>
, <a href="https://github.com/drk1wi/Modlishka" target="_blank">Modlishka</a>
or <a href="https://github.com/muraenateam/muraena" target="_blank">Muraena</a>
and be done with it. However, since PhishDeck is not designed to run red-team exercises or penetration tests (or to be used maliciously), we wanted to make sure that our product is as safe as possible to use for both the person being targeted, and the organization running the simulation.</p><p>On top of this, being the first phishing simulation vendor to incorporate this type of simulation, we wanted to make sure using it was easy to use. This means it needed to be faster, more feature-rich and tightly-knit with the rest of the PhishDeck platform. Users need to be able to be able to simulate real-time phishing campaigns without having to host their own infrastructure, manage domains, or fiddle with HTML, CSS and JavaScript code.</p><p>When we initially started working on a real time phishing simulation proxy we had explored going down the route of developing a hard-fork of EvilGinx2 for a number of reasons.</p><ol><li>It’s open-source license was permissive for private and commercial use;</li><li>A lot of plumbing around service configuration (what EvilGinx2 refers to as phishlets), and Let’s Encrypt certificate generation was already implemented;</li><li>We could use and expand on community-written services, initially thinking it would develop into a fairly large template library without breaking compatibility with our hard-fork;</li><li>Merging with upstream from time to time would not be too difficult as the codebase was fairly small and updates weren’t <strong>too</strong> frequent (e.g. daily).</li></ol><p>We went ahead and developed a heavily stripped down version of EvilGinx2. Implementing some key functionality around client-side code injection (which the project now supports) and security validation via JWT tokens for our users. We also removed a lot of the built-in functionality–no victim sessions (i.e. session database), no interactive terminal, and no credential harvesting. Only the certificate generator and the HTTP phishing proxy.</p><p>As time went on, we started hitting some notable problems that were going to become more and more difficult to overcome, effectively making the hard-fork model unsustainable.</p><ol><li>Using the <a href="https://letsencrypt.org/docs/challenge-types/" target="_blank">HTTP-01 challenge type</a>
for TLS certificate generation heavily limited what type of services we could proxy. Our aim was to be able to proxy services that operate on wildcard subdomains (e.g. <code>*.slack.com</code>) that are exceptionally popular and make for very convincing phishing simulations. Achieving this requires us to move to the DNS-01 challenge type, but also requires the service configuration and core proxy to be “wildcard-aware” which is no small feat.</li><li>Community service configurations (i.e. phishlets) didn’t pick up at the frequency that we had originally anticipated. We really wanted to contribute more here, but found ourselves spending too much time on the proxy and very little on adding new services.</li><li>We ended up deviating heavily from upstream, including the core proxy. Merging ended up being a very arduous and manual process, particularly with breaking schema changes around service configurations.</li></ol><p>Key takeaway for us here, as most people in the software industry already know, is that maintaining a hard-fork is difficult. With that said, if we had to go back and face the same decision, we would have proceeded in the same direction. The EvilGinx2 hard-fork was a fantastic proof-of-value and really allowed us to prototype our ideas in the context of a larger phishing simulation platform and gauge our market fit better.</p><p>With a working prototype and a handful of lessons learnt, we went back to the drawing board and fleshed out the requirements for a new in-house proxy. One that is tightly integrated with PhishDeck. We love naming things and our namespace is ripe for all sorts of word play, so we named our new real-time phishing proxy, <strong>Phinn</strong>.</p><p>We came up with a few notable requirements that we had to achieve in order to provide value as well as scale our platform to the general public.</p><ul><li><strong>Wildcard DNS support</strong>. We want to be able to support wildcard domains to be able ro simulate realistic, targeted attacks against a variety of services.</li><li><strong>Performant</strong>. Since we are effectively mirroring/replaying traffic, we are duplicating our response times, making it less likely for Targets to engage with the phishing website and making it costlier for us to operate. Additionally, each PhishDeck user on average will translate to tens or hundreds of Targets, resulting in substantial increase of our proxy traffic when contrasted to our platform traffic.</li><li><strong>Safety</strong>. The objective for Phinn is to <strong>only</strong> proxy traffic for legitimate Targets that form part of a <strong>verified</strong> phishing simulation Campaign and to track specific events with the least amount of event metadata. We <strong>do not</strong> want to process, store or use any user sessions or credentials.</li></ul><p>The scope of the initial proxy was to come up with a crude real-time phishing proxy implementation to gauge the practical soundness of the idea.</p><p>We managed to get a working prototype going over HTTP (no TLS) within a day or so, applied some synthetic HTTP load and monitored CPU/memory usage. Everything fell within our required parameters and so we started laying out the tracks for what version 1.0 would look like. We had to future-proof the design as much as possible as we knew we would not be implementing all features right off the bat.</p><p>We needed to lay the foundations that would serve us for future improvements over the coming years.
The first key design artefact we committed to was the high-level sequence of what a successful proxied request behaves like. This is helpful as it helps better visualise the traffic replay aspect of the proxy and allows us to break down the implementation into smaller segments.</p><p><img src="https://www.phishdeck.com/blog/phinn-on-engineering-a-real-time-phishing-simulation-proxy/proxy-traffic-sequence-flow.png#figure" alt="" title="real-time phishing simulation proxy traffic flow"></p><p>We also needed to factor-in how the phishing proxy would operate with the rest of the PhishDeck platform. It needs to perform as one holistic platform and needs to propagate data from the PhishDeck Campaign, to the Target via the Campaign’s phishing email, to Phinn, all the way back to the same PhishDeck Campaign (full circle).</p><p>After some tweaking and testing we settled on the following set of components. The following diagram may be quite heavy, but I encourage you to take some time and grasp it segment by segment, using the flow markers (i.e. numbers) as your guide.</p><p><img src="https://www.phishdeck.com/blog/phinn-on-engineering-a-real-time-phishing-simulation-proxy/phinn-component-view.png#figure" alt="" title="PhishDeck real-time phishing simulation proxy component view"></p><p><strong>Note</strong> – The way we designed our Callback tokens (step 5 above) are similar to how <a href="https://security.stackexchange.com/questions/87338/in-oauth-what-is-the-benefit-of-the-access-token-being-opaque">opaque tokens</a> work in certain OAuth flows. We pack the metadata internally and only push an opaque Callback token (i.e. reference) to the Target. This suits our needs well as it avoids us ever having to pass sensitive Target metadata (e.g. email) over the wire.</p><p>In the platform, we are then able to show interesting metrics and charts for that specific Campaign, specifically the <em>Linked Clicked</em> and <em>Credentials Entered</em> data points, which are two distinct callback tokens that fire in the Target’s browser depending on their activity.</p><p><img src="https://www.phishdeck.com/blog/phinn-on-engineering-a-real-time-phishing-simulation-proxy/phishdeck-campaign-funnel.png#screenshot" alt="" title="PhishDeck Campaign funnel"></p><p>These designs were originally a lot less neat, primarily consisting of whiteboard drafts formalized into interim architecture design records (ADRs). Having such documentation in place early can be invaluable, particularly for software projects with a well-defined problem definition upfront. They act as our north star and allow us to break down seemingly complicated problems into multiple smaller problems to be solved.</p><p>We always eyed Rust as the primary candidate for the new phishing proxy. In the security world, being able to have performance and safety in the same box is rare and Rust fits that to a tee. The largest single defining factor establishing the move to Rust for the core …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.phishdeck.com/blog/phinn-on-engineering-a-real-time-phishing-simulation-proxy/#content">https://www.phishdeck.com/blog/phinn-on-engineering-a-real-time-phishing-simulation-proxy/#content</a></em></p>]]>
            </description>
            <link>https://www.phishdeck.com/blog/phinn-on-engineering-a-real-time-phishing-simulation-proxy/#content</link>
            <guid isPermaLink="false">hacker-news-small-sites-26002299</guid>
            <pubDate>Tue, 02 Feb 2021 15:44:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Software Development Outsourcing: Our Story]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 107 (<a href="https://news.ycombinator.com/item?id=26002217">thread link</a>) | @eagle323
<br/>
February 2, 2021 | https://ascendixtech.com/software-development-outsourcing-our-story/ | <a href="https://web.archive.org/web/*/https://ascendixtech.com/software-development-outsourcing-our-story/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span data-contrast="none">Nowadays, there are thousands of well-known companies with hundreds&nbsp;</span><span data-contrast="none">of corporate</span><span data-contrast="none">&nbsp;offices in multiple&nbsp;</span><span data-contrast="none">countries. It is hard to imagine and believe that many years</span><span data-contrast="none">&nbsp;ago there&nbsp;</span><span data-contrast="none">was</span><span data-contrast="none">&nbsp;only the idea and motivation of founders to create something big. </span></p><p><span data-contrast="none">Ascendix&nbsp;</span><span data-contrast="none">Technologies&nbsp;</span><span data-contrast="none">is no exception</span><span data-contrast="none">&nbsp;and</span><span data-contrast="none">&nbsp;</span><span data-contrast="none">today we want to tell you our story&nbsp;</span><span data-contrast="none">of&nbsp;</span><span data-contrast="none">becom</span><span data-contrast="none">ing&nbsp;</span><span data-contrast="none">a&nbsp;</span><span data-contrast="none">leading&nbsp;</span><span data-contrast="none">software</span><span data-contrast="none">&nbsp;development company</span><span data-contrast="none">&nbsp;with&nbsp;</span><span data-contrast="none">diverse</span><span data-contrast="none">&nbsp;expertise</span><span data-contrast="none">.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p><p><span data-contrast="none">In order to&nbsp;</span><span data-contrast="none">leave no detail to chance, we asked our Chief Technical Officer and Managing Partner&nbsp;</span><span data-contrast="none">Todd Terry to describe the Ascendix journey into software development</span><span data-contrast="none">&nbsp;in first person</span><span data-contrast="none">.</span><span data-contrast="none">&nbsp;So, let’s get down to business.</span></p></div><div data-anchor="Birth of an Idea "><h2><strong>Birth of an Idea</strong></h2><p><span lang="EN-US" xml:lang="EN-US" data-contrast="none"><span>It was a Saturday afternoon in October, about 25 years ago, when my longtime friend Wes Snow and I were grabbing a beer during&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-contrast="none"><span>halftime of the</span></span><span lang="EN-US" xml:lang="EN-US" data-contrast="none"><span>&nbsp;Texas/OU game in Dallas. </span></span></p><p><span lang="EN-US" xml:lang="EN-US" data-contrast="none"><span>The way I remember the conversation, we were wondering out loud how cool it would be to start our own business of sorts. I’m not sure we knew exactly what we would do – no defining idea, no special market opportunity</span></span><span lang="EN-US" xml:lang="EN-US" data-contrast="none"><span>. </span></span></p><p><span lang="EN-US" xml:lang="EN-US" data-contrast="none"><span>We were</span></span><span lang="EN-US" xml:lang="EN-US" data-contrast="none"><span>&nbsp;just two recent university grads, still suffering from a terrible economy and generally dissatisfied with our current career options. </span></span></p><p><span lang="EN-US" xml:lang="EN-US" data-contrast="none"><span>Wes was working&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-contrast="none"><span>on a helpdesk</span></span><span lang="EN-US" xml:lang="EN-US" data-contrast="none"><span>&nbsp;for a financial services company and I was working on a helpdesk for an oil and gas exploration company.</span></span></p><div id="attachment_2017"><p><img aria-describedby="caption-attachment-2017" title="Todd and Wes on the Texas-OU game | Ascendix" src="https://ascendixtech.com/wp-content/uploads/2020/12/Screenshot_1.jpg" data-src="https://ascendixtech.com/wp-content/uploads/2020/12/Screenshot_1.jpg" alt="Todd and Wes on the Texas-OU game" width="799" height="603" data-srcset="https://ascendixtech.com/wp-content/uploads/2020/12/Screenshot_1.jpg 799w, https://ascendixtech.com/wp-content/uploads/2020/12/Screenshot_1-300x226.jpg 300w, https://ascendixtech.com/wp-content/uploads/2020/12/Screenshot_1-768x580.jpg 768w" data-sizes="(max-width: 799px) 100vw, 799px" srcset="https://ascendixtech.com/wp-content/uploads/2020/12/Screenshot_1.jpg 799w, https://ascendixtech.com/wp-content/uploads/2020/12/Screenshot_1-300x226.jpg 300w, https://ascendixtech.com/wp-content/uploads/2020/12/Screenshot_1-768x580.jpg 768w"></p><p id="caption-attachment-2017">Todd Terry and Wes Snow</p></div><p><span lang="EN-US" xml:lang="EN-US" data-contrast="none"><span>A few weeks (or maybe a few months) later, Wes calls me with a proposition of sorts. A company that had implemented a contact management system for his current employer had been acquired by a startup out of Arizona and was looking for reseller/implementation partners. </span></span></p><p><span lang="EN-US" xml:lang="EN-US" data-contrast="none"><span>Wes had become a good acquaintance of&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-contrast="none"><span>the&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-contrast="none"><span>acquired company</span></span><span lang="EN-US" xml:lang="EN-US" data-contrast="none"><span>’s owner</span></span><span lang="EN-US" xml:lang="EN-US" data-contrast="none"><span>, and he was now trying to recruit partners in Dallas. </span></span></p><p><span lang="EN-US" xml:lang="EN-US" data-contrast="none"><span>So, <strong>Wes called me with the idea that we would fly to Scottsdale, get trained, and certified to start selling and supporting productivity software for salespeople (now known as CRM). </strong></span></span></p><p><span lang="EN-US" xml:lang="EN-US" data-contrast="none"><span>It seemed like a terrible idea to me at the time, but I was up for a junket to Scottsdale with my good buddy, so I agreed.</span></span></p></div><div><div><div><div><p> <iframe data-data-cli-class="cli-blocker-script" data-cli-label="Youtube embed" data-cli-script-type="" data-cli-block="true" data-cli-block-if-ccpa-optout="false" data-cli-element-position="body" data-cli-placeholder="Accept consent to view this" data-cli-src="https://www.youtube.com/embed/to5BRgwlHr0?rel=0&amp;autoplay=1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p></div></div></div></div><div data-bg="https://ascendixtech.com/wp-content/uploads/2020/12/cta-background.jpg"><div><div><div><div><h4>Get Our Software Development Hourly Rates</h4><p>Looking for a software development partner? Answer our quick quiz to get a ball-park cost of developing your software</p></div></div></div></div></div><div data-anchor="First Steps Towards the Launch "><h2><strong>First Steps Towards the Launch</strong></h2><p><span data-contrast="none">In retrospect, the trip was life-changing. </span></p><p><span data-contrast="none">In less than two weeks, we both learned how to implement and customize a </span><span data-contrast="none">rather sophisticated</span><span data-contrast="none">&nbsp;client-server system that had&nbsp;</span><span data-contrast="none">cutting edge</span><span data-contrast="none">&nbsp;remote database synchronization capabilities (in 1996)</span><span data-contrast="none">. </span></p><p><span data-contrast="none">They were</span><span data-contrast="none">&nbsp;perfect for a remote field sales team, as connectivity&nbsp;</span><span data-contrast="none">wasn’t</span><span data-contrast="none">&nbsp;so ubiquitous then. </span></p><p><span data-contrast="none">Wes and I both had some technical background from our university&nbsp;</span><span data-contrast="none">coursework</span><span data-contrast="none">, so we understood&nbsp;</span><span data-contrast="none">high-level</span><span data-contrast="none"> concepts, but this was our first jump into the realm of business software solutions.</span></p></div><div><div><p> <span>“</span> We didn’t understand fully at the time, but to be successful with what would&nbsp;become today’s CRM software, we needed to become experts at “sudden expertise:”&nbsp;the idea that a consultant can drop into your business, learn it in a matter of a few days, then propose how to tailor a productivity system to help them do business…&nbsp;better.&nbsp; <span>”</span></p></div></div><div><p>We had no typical client – they were small, medium, and large, financial, hospitality, manufacturing, healthcare, construction, and heavy equipment, but they were all&nbsp;trying to solve the same pains.</p><p>They wanted to&nbsp;help their customer-facing workers make better-informed decisions, and somehow gain visibility into what was happening with their sales pipeline.</p></div><div data-anchor="Primary Ups and Downs "><h2><strong>Primary Ups and Downs</strong></h2><p><span data-contrast="none">We had some early successes that helped fund our business. </span></p></div><div data-bg="https://ascendixtech.com/wp-content/uploads/2020/10/cta-background.jpg"><div><div><div><p><h4><strong>Our second customer, a member of the Fortune 500, found us on the Internet and never asked us for references.</strong></h4></p></div></div></div></div><div><p>They just liked us, our presentation (we flew to their&nbsp;headquarters&nbsp;to present), and our price, and accepted our proposal for a&nbsp;200-user system that was meant to be temporary while their department waited in line for an upcoming Siebel implementation.</p><p><span data-contrast="none">We&nbsp;</span><span data-contrast="none">maneuvered</span><span data-contrast="none">, worked with the administrative assistant of the department head, and in a matter of&nbsp;</span><span data-contrast="none">10</span><span data-contrast="none">-12 weeks had this department of a Fortune 500 company with a new, successfully running system that they used for years. </span></p><p><strong>(Funny fact, their server sat under the desk of the admin assistant, unknown and untouched by the IT team for more than a year before it was finally brought into the server room.) </strong></p><p><span data-contrast="none">This referenceable Fortune 500 client (whose name exists </span><span data-contrast="none">in</span><span data-contrast="none">&nbsp;NFL stadiums) would help us continue our success for many more years.</span></p><p><span data-contrast="none">We also had our share of failures, and from these, we really learned about what makes good software and a successful project, and this became part of our company DNA. </span></p><p><span data-contrast="none">Our failures were primarily due to taking on projects with compromises – projects where we didn’t focus on the user’s needs, but the needs of those managing the users. </span></p><p><span data-contrast="none">This&nbsp;</span><span data-contrast="none">experience&nbsp;</span><span data-contrast="none">allowed us to&nbsp;</span><span data-contrast="none">learn how to advocate for the user in order to help their managers and stakeholders achieve their objectives as well.</span></p></div><div data-anchor="Defining Our Competitive Advantage "><h2><strong>Defining Our Competitive Advantage</strong></h2><p><span data-contrast="none">Enterprise business software is not user friendly. </span></p><p><span data-contrast="none">It’s generally not well-liked by users (especially salespeople, who are typically successful for reasons other than good computer skills). </span></p><p><span data-contrast="none">It’s usually hard to find information, </span><span data-contrast="none">difficult</span><span data-contrast="none">&nbsp;to act on this&nbsp;</span><span data-contrast="none">data,</span><span data-contrast="none">&nbsp;and&nbsp;</span><span data-contrast="none">tough&nbsp;</span><span data-contrast="none">to use this information in a way that helps you be a more effective professional.</span></p></div><div data-bg="https://ascendixtech.com/wp-content/uploads/2020/10/cta-background.jpg"><div><div><div><p><h4><strong>Comparing today’s business productivity software to what we used 25 years ago, in my opinion,&nbsp;evolution has been slow and unremarkable.</strong></h4></p></div></div></div></div><div><p><span data-contrast="none">Yes, that remote database syncing client-server system Wes and I learned to implement and customize back in 1996 is quite ugly and out-of-date looking compared to today’s interface in Salesforce or Dynamics, but the functionality is remarkably unchanged. </span></p><p><strong>Moreover,&nbsp;the challenges we faced&nbsp;then&nbsp;are still real today:&nbsp;user adoption, user stickiness.</strong></p><p><span data-contrast="none">I</span><span data-contrast="none">’ll never forget the day, about 10 years ago, I was sitting in a conference room in Seattle for a global commercial real estate client (400+ offices and 15K people). </span></p><p><span data-contrast="none">We had just wrapped phase 1 of the project and completed a full day’s training for our first wave of users. </span></p><p><span data-contrast="none">The president, who was deeply involved in the project since the vendor selection stage looked at me and said: “Todd, you guys have done a great job building exactly what we’ve looked for, but I still wonder why CRM software still has to be so hard to use.” </span></p><p><span data-contrast="none">I was a bit taken aback, as 75% of our solution for commercial real estate was more about usability, and the other 25% specifically about real estate, and he just said it was still hard to use.</span></p></div><div><div><p> "<strong>You should build your products like Apple. Like LinkedIn. Like Amazon.</strong> If I can network on LinkedIn, or build my playlist on Apple, or find the products I need on Amazon without going through a full day of training, then I should be able to do the same with your software. While yours is the best I’ve seen, I think it can be better!"</p><p><h6>- Ascendix client</h6></p></div></div><div><p><span data-contrast="none">I made my informed excuses about enterprise software – that you must give up some usability in order to have flexibility and customizability. </span></p><p><span data-contrast="none">He reluctantly agreed, but I got his point.</span></p><p><span data-contrast="none">Our differentiator over these 25 years started by advocating for the user and making our client’s software easier to use. </span></p><p><span data-contrast="none">We hired&nbsp;</span><span data-contrast="none">really smart</span><span data-contrast="none"> and talented developers who could develop and implement seamlessly integrated usability solutions to otherwise hard-to-use software.</span></p></div><div data-bg="https://ascendixtech.com/wp-content/uploads/2020/10/cta-background.jpg"><div><div><div><p><h4><strong>We made it easier for users to search for information, easier for users to organize the information, easier to act on it.</strong></h4></p></div></div></div></div><div><p><span data-contrast="none">We put ourselves in our users’ shoes and mapped end-to-end process flow with the system, and then built plug-ins to plug the holes in those end-to-end flows. </span></p><p><span data-contrast="none">We started using these solutions for all our implementations, then started to use it as a framework to combine it with our growing business experience in certain industries (Commercial Real Estate, Financial Services, Professional Services) as modules and industry solutions. </span></p><p><span data-contrast="none">The first industry solution we built for companies who sold private REIT products to registered representatives, which fueled our start in software development until the global financial crisis arrived in 2007.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p><p><iframe data-cli-class="cli-blocker-script" data-cli-label="Youtube embed" data-cli-script-type="" data-cli-block="true" data-cli-block-if-ccpa-optout="false" data-cli-element-position="body" data-cli-placeholder="Accept consent to view this" data-cli-src="https://www.youtube.com/embed/Vcq0PQVwnIQ" width="100%" height="515" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p></div><div data-anchor="Outsourcing Software Development"><h2><strong>Starting a Software Development Outsource Story </strong></h2><p><span data-contrast="none">Our journey also took us to different parts of the world.&nbsp;</span></p><p><span data-contrast="none">Wes and I decided to bootstrap our product development with a combination of reinvestment of profits and debt vehicles.</span></p><p><strong> This&nbsp;meant a model where we develop software that may not bring us revenue for months, or sometimes even years after an investment&nbsp;of&nbsp;capital. </strong></p><p><span data-contrast="none">We looked for ways to stretch the dollar, which inevitably means outsourcing. </span></p><p><span data-contrast="none">Our vendor&nbsp;</span><span data-contrast="none">search</span><span data-contrast="none">&nbsp;took us to China and India. Then, hurting from the lost hours due to cultural and time differences, we&nbsp;</span><span data-contrast="none">near-shored</span><span data-contrast="none"> in Argentina and Mexico.</span></p><p><strong>It wasn’t&nbsp;successful&nbsp;until we worked&nbsp;on a&nbsp;special pilot project with a company in Ukraine that we became real believers that outsourcing could work so effectively. </strong></p><p><span data-contrast="none">After a couple of very successful years working&nbsp;</span><span data-contrast="none">as</span><span data-contrast="none"> a partner, we decided it was time to continue our growth by acquiring our team and establishing our own location there.</span></p></div><div data-bg="https://ascendixtech.com/wp-content/uploads/2020/10/cta-background.jpg"><div><div><div><p><h4><strong>Our team,&nbsp;from&nbsp;our original 8 members,&nbsp;was around 30 when they made the transition, and now we are on our way to 200.</strong></h4></p></div></div></div></div><p><span data-contrast="none">The original team architected our search and big data solutions, and now we have 6 separate product offerings: from industry-specific solutions on Salesforce and Dynamics to mobile, desktop, marketing, and publishing solutions architected with various technologies in </span><a href="https://ascendixtech.com/technologies/net-application-development/"><span data-contrast="none">.NET</span></a><span data-contrast="none">, <a href="https://ascendixtech.com/technologies/java-software-development/">Java</a>, <a href="https://ascendixtech.com/technologies/javascript-app-development/">JavaScript</a>, and <a href="https://ascendixtech.com/technologies/xamarin-app-development/">Xamarin</a>, leveraging search and data platforms like Elasticsearch, Couchbase, Cosmos DB and deployed through Azure and Amazon cloud.</span></p><div><div><p> <span>“</span> We have evolved our services/custom&nbsp;software&nbsp;development practice largely based on our experiences with more than 20 years of user-centric advocacy and best practices for product development and support. <span>”</span></p><p><h6>Todd Terry, CTO &amp; Managing Partner</h6></p></div></div><div><p>We have&nbsp; Agile project teams, dedicated client teams, or anything in between.</p><p><strong>We’ve evolved a great practice where we can run a project in the US, blend a team from Ukraine, or run it entirely out of Ukraine with personnel who have very …</strong></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ascendixtech.com/software-development-outsourcing-our-story/">https://ascendixtech.com/software-development-outsourcing-our-story/</a></em></p>]]>
            </description>
            <link>https://ascendixtech.com/software-development-outsourcing-our-story/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26002217</guid>
            <pubDate>Tue, 02 Feb 2021 15:39:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Study: Mobile CX Issues Highlight Use Cases for iOS App Clips]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26002147">thread link</a>) | @encorekt
<br/>
February 2, 2021 | https://www.heady.io/blog/market-study-mobile-customer-experience-issues-highlight-use-cases-for-ios-app-clips | <a href="https://web.archive.org/web/*/https://www.heady.io/blog/market-study-mobile-customer-experience-issues-highlight-use-cases-for-ios-app-clips">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
      

      
      <div>
        <h2>How is exploding app growth affecting consumer behavior?</h2>
<p>The mobile app economy is expected to double by 2024 and reach a staggering <strong><a href="https://techcrunch.com/2020/04/01/mobile-app-spending-to-double-by-2024-despite-economic-impacts-of-covid-19/#:~:text=For%20starters%2C%20global%20spending%20in,year%20to%20hit%20%24102%20billion.">$171 billion</a></strong>. That’s roughly the value of the entire <strong><a href="https://www.macrotrends.net/stocks/charts/MCD/mcdonalds/market-cap">McDonald’s Corporation</a></strong>.</p>
<p>Is your company looking to carve out a piece of that multi-billion-dollar pie?</p>
<p>With nearly <strong><a href="https://www.lifewire.com/how-many-apps-in-app-store-2000252">2 million apps</a></strong> available in Apple’s App Store and <strong><a href="https://www.statista.com/statistics/1020964/apple-app-store-app-releases-worldwide/#:~:text=Number%20of%20monthly%20Apple%20App%20Store%20app%20releases%20worldwide%202020&amp;text=This%20statistic%20shows%20the%20average,through%20the%20Apple%20App%20Store.">30,000 more</a></strong> added every month, so is everyone else.</p>
<p>We wanted to know how the app economy’s exploding growth is affecting consumer behavior, so we surveyed smartphone users to find out.</p>
<p>Specifically, as more brands launch and promote their own mobile apps, we wanted to know how users feel when they’re required to install these apps to place an order, use a product or try a service.</p>
<ul>
<li><strong>Did they find it frustrating?</strong></li>
<li><strong>How likely were they to install the app?</strong></li>
<li><strong>How regularly do they delete apps?</strong></li>
<li><strong>Does deleting an app affect their opinion of a brand?</strong></li>
</ul>
<p>Our research uncovered 11 app statistics that highlight significant customer pain points with the current state of mobile transactions. Going forward, companies must find solutions to these pain points. Those that don’t risk suffering both decreased market share and irrelevance.</p>
<p>With iOS 14, Apple is giving businesses a solution: <strong>App Clips.</strong></p>
<p>App Clips are small, lightweight portions of your full app that isolate a specific functionality and offer it to users as needed. They integrate seamlessly into tasks mobile users already are performing—such as browsing the web, searching for location-based recommendations or scanning visual tags—and offer brands organic opportunities to step in and provide value.</p>
<p>If you’re trying to rise above the noise in today’s overcrowded mobile app landscape, Apple iOS 14’s new App Clips are a no-brainer.</p>
<p>These 11 app statistics illustrate why.</p>
      </div>
      
      
      


    </div>
  </div><div>
    <div>
      

      
      <div>
        <h3>The Take-Home Message</h3>
<p>Let’s recap what the data tells us about the current mobile app-related purchasing experience:</p>
<ul>
<li><strong>68.5% of mobile phone users are moderately or extremely frustrated when they’re required to install an app to complete a transaction.</strong></li>
<li><strong>77.9% report abandoning a transaction because they didn’t want to install a required app.</strong></li>
<li><strong>30.3% say they’ve saved at least $100 in the last year by abandoning these transactions, with 7.8% saving at least $500.</strong></li>
<li><strong>58.5% who ultimately decide to install the required app still find the whole experience moderately or extremely frustrating and are 65.2% more likely to clean out their app inventory by deleting apps every week.</strong></li>
<li><strong>31.6% say deleting an app makes them think less of the company that created the app.</strong></li>
</ul>
<h3>Where Apps Are Falling Short Today</h3>
<p>Those app statistics paint a clear picture and highlight three purchase-related pain points and inefficiencies:</p>
<p><strong>1. Astounding numbers of abandoned transactions due to that frustration </strong></p>
<p><strong>2. Increasing user demand for mobile apps</strong></p>
<p><strong>3. Persistent and pervasive consumer frustration with current app-driven checkout processes</strong></p>
<p>Add all that up, and there’s an obvious and growing reservoir of unmet demand waiting to be tapped by businesses that can create seamless online purchasing experiences that facilitate instead of frustrate.</p>
<blockquote>iOS App Clips presents businesses with a high-impact way to increase mobile app downloads, build positive brand sentiment and increase customer engagement by leveraging the functionality currently built into their mobile app.</blockquote>

<h4>iOS 14 is Empowering Brands</h4>
<p>With the introduction of App Clips in iOS 14, Apple is giving businesses a way to do just that by enabling organic, frustration-free, app-powered checkout processes. Now, businesses can embed select portions of their full mobile app’s functionality for customers to interact with natively without requiring installation.</p>
<p>This addresses all three of those pain points and inefficiencies:</p>
<p><strong>1.Customers aren’t required to install an app to complete their transaction and enjoy a smooth, positive experience.</strong></p>
<p><strong>2.Businesses capture more sales. </strong></p>
<p><strong>3.Customers associate their positive experience with both the business’s mobile app and brand, making them more likely to install the full app for future transactions.</strong></p>
<p>iOS App Clips presents companies with a high-impact way to increase mobile app downloads, build positive brand sentiment and increase customer engagement by leveraging the functionality currently built into their mobile app.</p>
<p>And for businesses that don’t have a mobile app but want to take advantage of App Clips to create a customer-centric experience, now is the perfect time to design, build and launch an app with App Clips in mind.</p>

      </div>
      
      
      


    </div>
  </div></div>]]>
            </description>
            <link>https://www.heady.io/blog/market-study-mobile-customer-experience-issues-highlight-use-cases-for-ios-app-clips</link>
            <guid isPermaLink="false">hacker-news-small-sites-26002147</guid>
            <pubDate>Tue, 02 Feb 2021 15:35:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Supabase Beta January 2021]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26002062">thread link</a>) | @raiyu
<br/>
February 2, 2021 | https://supabase.io/blog/2021/02/02/supabase-beta-january-2021 | <a href="https://web.archive.org/web/*/https://supabase.io/blog/2021/02/02/supabase-beta-january-2021">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>New year, new features. We've been busy at Supabase during January and our community has been even busier. Here's a few things you'll find interesting.</p><h3>Quick demo</h3><p>Watch a full demo:</p><iframe width="640" height="385" src="https://www.youtube.com/embed/DlybOLANG4s" frameborder="1" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><h3>Count functionality</h3><p>Anyone who has worked with Firebase long enough has become frustrated over the <a href="https://stackoverflow.com/questions/49979714/how-to-get-count-of-documents-in-a-collection" target="_blank" rel="noopener noreferrer">lack</a> of <code>count</code> functionality. This isn't a problem with PostgreSQL! Our libraries now have support for PostgREST's <a href="https://postgrest.org/en/v7.0.0/api.html?highlight=count#exact-count" target="_blank" rel="noopener noreferrer">exact</a>, <a href="https://postgrest.org/en/v7.0.0/api.html?highlight=count#planned-count" target="_blank" rel="noopener noreferrer">planned</a>, and <a href="https://postgrest.org/en/v7.0.0/api.html?highlight=count#estimated-count" target="_blank" rel="noopener noreferrer">estimated</a> counts. A massive thanks to <a href="https://github.com/supabase/postgrest-js/issues/94#event-4210564301" target="_blank" rel="noopener noreferrer">@dshukertjr</a> for this adding support to our client library.</p><p><img alt="Supabase now supports count functionality" src="https://supabase.io/assets/images/postgres-count-61769063793865f88b9990c381ce5408.png"></p><h3>New Auth Providers</h3><p>We enabled 2 new Auth providers - Facebook and Azure. Thanks to <a href="https://github.com/supabase/gotrue/pull/54" target="_blank" rel="noopener noreferrer">@Levet</a> for the Azure plugin, and once again to <a href="https://github.com/netlify/gotrue/issues/107" target="_blank" rel="noopener noreferrer">Netlify's amazing work</a> with GoTrue to implement Facebook.</p><p><img alt="Supabase now supports Azure and Facebook Oauth providers" src="https://supabase.io/assets/images/auth-azure-and-facebook-d2076e9b623aa3d6c0a9078faaab1108.png"></p><h3>Auth Audit Trail</h3><p>We have exposed the audit trail directly in the dashboard, as well as the GoTrue logs. Great for security and debugging.</p><p><img alt="Supabase exposes the Auth Audit trail on the dashboard" src="https://supabase.io/assets/images/auth-audit-be5822f988f346d33bdf984b01ea8380.png"></p><h3>Auth UI widget</h3><p>In case our Auth endpoints aren't easy enough already, we've built a React <a href="http://ui.supabase.com/?path=/story/auth-auth--default" target="_blank" rel="noopener noreferrer">Auth Widget</a> for you to drop into your app and to get up-and-running in minutes. </p><p><img alt="Supabase has released a React Auth widget" src="https://supabase.io/assets/images/auth-widget-550166fe8c936ab962b5ffa8ec2ce34c.png"></p><h3>New <code>auth.email()</code> function</h3><p>We added a helper function for extracting the logged in user's email address. </p><p><img alt="Supabase added an email function for using with Policies" src="https://supabase.io/assets/images/policies-email-24652011030a325fb770785aba2bf257.png"></p><h3>New Regions</h3><p>Launch your database in London or Sydney!</p><p><img alt="Launch your database in London or Sydney" src="https://supabase.io/assets/images/regions-london-sydney-138da27d385eed35b07982e93c62b849.png"></p><h3>Copy rows as Markdown</h3><p>You can now copy SQL results as Markdown - super useful for adding to blogs and issues.</p><p><img alt="Copy query results as markdown" src="https://supabase.io/assets/images/countries-14cac1a82a9a40b2aa419d8acc602dcd.gif"></p><h3>React server components</h3><p>If you're excited by React Server components then check out the Supabase + Server Components experimental repo. <a href="https://github.com/supabase/next-server-components" target="_blank" rel="noopener noreferrer">https://github.com/supabase/next-server-components</a></p><p><img alt="Use supabase with React Server components" src="https://supabase.io/assets/images/react-server-components-supabase-c398ba9cc4b8fa2132df95e97c8cdd45.png"></p><h3>Learn</h3><p>We know that Auth can be a bit daunting when you're just starting out, so we have created some intro videos to get you up to speed in no time:</p><ul><li><a href="https://youtu.be/v3Exg5YpJvE" target="_blank" rel="noopener noreferrer">Supabase Auth Deep Dive Part 1: JWTs</a></li><li><a href="https://youtu.be/qY_iQ10IUhs" target="_blank" rel="noopener noreferrer">Supabase Auth Deep Dive Part 2: Restrict Table Access</a></li><li><a href="https://youtu.be/0LvCOlELs5U" target="_blank" rel="noopener noreferrer">Supabase Auth Deep Dive Part 3: User Based Access Policies</a></li></ul><p><img alt="We released a Auth Video Series" src="https://supabase.io/assets/images/supabase-auth-series-c499fdefbd277c1830cd869b564cc7b9.png"></p><h3>Kaizen</h3><ul><li>Performance: We migrated all of our subdomains to Route53, implementing custom Let's Encrypt certs for your APIs. As a result, our read benchmarks are measuring up 12% faster.</li><li>Performance: We upgrade your databases to the new <a href="https://aws.amazon.com/about-aws/whats-new/2020/12/introducing-new-amazon-ebs-general-purpose-volumes-gp3/" target="_blank" rel="noopener noreferrer">GP3</a> storage for faster and more consistent throughput.</li></ul><h3>Community</h3><ul><li>@kiwicopple chats to @bdougie on HeavyBit's Jamstack Radio: <a href="https://www.heavybit.com/library/podcasts/jamstack-radio/ep-71-open-source-firebase-alternative-with-paul-copplestone-of-supabase" target="_blank" rel="noopener noreferrer">Link</a></li><li>Watch @leerob from Vercel deploy a full Next.js app with Supabase in just 2 minutes:
<a href="https://twitter.com/leeerob/status/1351576575888797696" target="_blank" rel="noopener noreferrer">Link</a></li><li>Redwood now supports Supabase:
<a href="https://twitter.com/redwoodjs/status/1347311574415863811" target="_blank" rel="noopener noreferrer">Link</a></li><li>Deploy a full analytics solution using Umami:
<a href="https://twitter.com/mkalvas/status/1353880637506260994" target="_blank" rel="noopener noreferrer">Link</a></li><li>Check out this open source Trello Clone:
<a href="https://twitter.com/joshnuss/status/1352094804335857664" target="_blank" rel="noopener noreferrer">Link</a></li><li>Get started with Expo + Supabase using this starter template from Kiki:
<a href="https://twitter.com/kikiding/status/1352086899242856449" target="_blank" rel="noopener noreferrer">Link</a></li><li>Use Supabase Auth with NestJS:
<a href="https://twitter.com/atsuhio/status/1348516650144780288?s=21" target="_blank" rel="noopener noreferrer">Link</a></li><li>The community has made some serious advances on the <a href="https://github.com/supabase?q=dart&amp;type=&amp;language=" target="_blank" rel="noopener noreferrer">Dart</a>, <a href="https://github.com/supabase?q=csharp&amp;type=&amp;language=" target="_blank" rel="noopener noreferrer">C#</a>, <a href="https://github.com/supabase?q=python&amp;type=&amp;language=" target="_blank" rel="noopener noreferrer">Python</a>, and <a href="https://github.com/supabase?q=kotlin&amp;type=&amp;language=" target="_blank" rel="noopener noreferrer">Kotlin</a> libraries.</li><li>We were one of the fastest growing open source startups in Q4 last year: <a href="https://twitter.com/RunaCapital/status/1351122231791910916" target="_blank" rel="noopener noreferrer">Link</a></li></ul><p><img alt="This image shows the Supabase GitHub star growth." src="https://supabase.io/assets/images/jan-21-starcount-4cac154d0faaf5250503965a80d35ed2.png"></p><small>Source: <a href="https://repository.surf/supabase" target="_blank" rel="noopener noreferrer">repository.surf/supabase</a></small><h3>Coming next</h3><p>We're ramping up to "Launch week" at the end of Q1, where we will be giving you some very exciting new features (including Storage!).</p><h3>Get started</h3><ul><li>Start using Supabase today: <a href="https://app.supabase.io/" target="_blank" rel="noopener noreferrer">app.supabase.io</a></li><li>Make sure to <a href="https://github.com/supabase/supabase" target="_blank" rel="noopener noreferrer">star us on GitHub</a></li><li>Follow us <a href="https://twitter.com/supabase_io" target="_blank" rel="noopener noreferrer">on Twitter</a></li><li>Subscribe to our <a href="https://www.youtube.com/channel/UCNTVzV1InxHV-YR0fSajqPQ" target="_blank" rel="noopener noreferrer">YouTube channel</a></li><li>Become a <a href="https://github.com/sponsors/supabase" target="_blank" rel="noopener noreferrer">sponsor</a></li></ul></section></div>]]>
            </description>
            <link>https://supabase.io/blog/2021/02/02/supabase-beta-january-2021</link>
            <guid isPermaLink="false">hacker-news-small-sites-26002062</guid>
            <pubDate>Tue, 02 Feb 2021 15:29:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Growing Importance of Metadata Management Systems]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26001976">thread link</a>) | @thedataexchange
<br/>
February 2, 2021 | https://gradientflow.com/the-growing-importance-of-metadata-management-systems/ | <a href="https://web.archive.org/web/*/https://gradientflow.com/the-growing-importance-of-metadata-management-systems/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-11339">

	

	
			<figure>
				<img width="1568" height="835" src="https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata3.jpg?fit=1568%2C835&amp;ssl=1&amp;is-pending-load=1" alt="tools, services, and companies in our Metadata and Governance stack" loading="lazy" data-attachment-id="11345" data-permalink="https://gradientflow.com/metadata3/" data-orig-file="https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata3.jpg?fit=2196%2C1170&amp;ssl=1" data-orig-size="2196,1170" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="metadata3" data-image-description="" data-medium-file="https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata3.jpg?fit=300%2C160&amp;ssl=1" data-large-file="https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata3.jpg?fit=750%2C400&amp;ssl=1" data-lazy-srcset="https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata3.jpg?w=2196&amp;ssl=1 2196w, https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata3.jpg?resize=300%2C160&amp;ssl=1 300w, https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata3.jpg?resize=1024%2C546&amp;ssl=1 1024w, https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata3.jpg?resize=768%2C409&amp;ssl=1 768w, https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata3.jpg?resize=1536%2C818&amp;ssl=1 1536w, https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata3.jpg?resize=2048%2C1091&amp;ssl=1 2048w, https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata3.jpg?resize=1200%2C639&amp;ssl=1 1200w, https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata3.jpg?resize=1568%2C835&amp;ssl=1 1568w" data-lazy-sizes="(max-width: 1568px) 100vw, 1568px" data-lazy-src="https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata3.jpg?fit=1568%2C835&amp;ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">			</figure><!-- .post-thumbnail -->

		
	<div>
		<h3>Metadata  will be the foundation for data governance solutions, data catalogs, and other enterprise data systems.</h3>
<p><strong>By Assaf Araki and Ben Lorica.</strong></p>
<h2>Introduction</h2>
<p>As companies embrace digital technologies to transform their operations and products, many are using best-of-breed software, open source tools, and software as a service (SaaS) platforms to rapidly and efficiently integrate new technologies. This often means that data required for reports, analytics, and machine learning (ML) reside on disparate systems and platforms. As such, IT initiatives in companies increasingly involve tools and frameworks for data fusion and integration. Examples include tools for building data pipelines, data quality and data integration solutions, customer data platform (<a href="https://en.wikipedia.org/wiki/Customer_data_platform">CDP</a>) , <a href="https://en.wikipedia.org/wiki/Master_data_management">master data management</a>, and <a href="https://gradientflow.com/data-collection-and-data-markets-in-the-age-of-privacy-and-machine-learning/">data markets</a>.</p>
<p>Collecting, unifying, preparing, and managing data from diverse sources and formats has become imperative in this era of rapid digital transformation. Organizations that invest in <a href="https://gradientflow.com/becoming-a-machine-learning-company-means-investing-in-foundational-technologies/">foundational data technologies</a> are much more likely to build solid foundation applications, ranging from BI and analytics to machine learning and AI.</p>
<p>In recent years, several technology companies developed internal metadata management systems and shared the challenges that led them to focus on metadata (this list includes: Airbnb’s <a href="https://medium.com/airbnb-engineering/democratizing-data-at-airbnb-852d76c51770">Dataportal</a>, Netflix’s <a href="https://github.com/Netflix/metacat">Metacat</a>, Uber’s <a href="https://eng.uber.com/databook/">Databook</a>, LinkedIn’s <a href="https://github.com/linkedin/datahub">Datahub</a>, Lyft’s <a href="https://www.amundsen.io/">Amundsen</a>, WeWork’s <a href="https://github.com/MarquezProject/marquez">Marquez</a>, Spotify’s <a href="https://engineering.atspotify.com/2020/02/27/how-we-improved-data-discovery-for-data-scientists-at-spotify/">Lexikon</a>). These companies were facing fragmented data landscapes, while growing teams of analysts, data scientists, and engineers were needing to build data and machine learning products. The blog posts announcing these metadata management tools made it clear that these companies have come to rely on these metadata systems to power an array of data and machine learning services.</p>
<p>Beyond the need to unify and tame data from diverse systems, other reasons for the resurgence in interest in metadata technologies include:</p>
<ul>
<li>
<p>Regulations like <a href="https://gradientflow.com/managing-machine-learning-in-the-enterprise-lessons-from-banking-and-health-care/">SR-11</a>, GDPR, and the California Privacy Rights Act (CPRA) require organizations to manage data privacy, access, and control efficiently and at scale.</p>
</li>
<li>
<p>Debugging and root cause analysis are essential for machine learning and AI applications. The advent of new regulations raises the possibility of audits, making tools for data governance, model governance, and data lineage particularly critical.</p>
</li>
<li>
<p>Data governance at scale requires a certain level of automation, especially when many different software systems and platforms are involved.</p>
</li>
<li>
<p>Data discovery is particularly important for productivity reasons. Many users spend significant time finding and understanding the right data. A good data discovery product can help in this regard.</p>
</li>
</ul>
<p>In this post, we examine emerging tools for managing metadata and data governance. A CxO or a VP of R&amp;D might ask themselves why they need a metadata management system at all: are existing data governance and data catalog solutions not adequate? We argue that solutions built on top of metadata management systems result in data governance systems that are global in scope. Metadata management systems provide end-to-end data governance solutions that cover source systems, data warehouses, data management systems, and data pipelines that power enterprise applications. Advanced data protection techniques including masking, differential privacy, data synthesis can be integrated. The resulting data catalogs will be comprehensive, and changes will immediately be reflected in dependency mappings between data assets. As a result, users (analysts, data scientists, and engineers) will be able to search and discover trustworthy data that complies with internal and external regulations.</p>
<figure id="attachment_11343" aria-describedby="caption-attachment-11343"><img data-attachment-id="11343" data-permalink="https://gradientflow.com/metadata1/" data-orig-file="https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata1.jpg?fit=2140%2C1338&amp;ssl=1" data-orig-size="2140,1338" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="metadata1" data-image-description="" data-medium-file="https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata1.jpg?fit=300%2C188&amp;ssl=1" data-large-file="https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata1.jpg?fit=750%2C469&amp;ssl=1" loading="lazy" src="https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata1.jpg?resize=750%2C469&amp;ssl=1" alt="evolution of data and metadata systems" width="750" height="469" srcset="https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata1.jpg?resize=1024%2C640&amp;ssl=1 1024w, https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata1.jpg?resize=300%2C188&amp;ssl=1 300w, https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata1.jpg?resize=768%2C480&amp;ssl=1 768w, https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata1.jpg?resize=1536%2C960&amp;ssl=1 1536w, https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata1.jpg?resize=2048%2C1280&amp;ssl=1 2048w, https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata1.jpg?resize=1200%2C750&amp;ssl=1 1200w, https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata1.jpg?resize=1568%2C980&amp;ssl=1 1568w" sizes="(max-width: 750px) 100vw, 750px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata1.jpg?resize=1024%2C640&amp;ssl=1 1024w, https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata1.jpg?resize=300%2C188&amp;ssl=1 300w, https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata1.jpg?resize=768%2C480&amp;ssl=1 768w, https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata1.jpg?resize=1536%2C960&amp;ssl=1 1536w, https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata1.jpg?resize=2048%2C1280&amp;ssl=1 2048w, https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata1.jpg?resize=1200%2C750&amp;ssl=1 1200w, https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata1.jpg?resize=1568%2C980&amp;ssl=1 1568w" data-lazy-src="https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata1.jpg?resize=750%2C469&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption id="caption-attachment-11343">Figure 1: The evolution of data and metadata systems. Image courtesy of Intel Capital.</figcaption></figure>
<h2>Metadata Management Architecture</h2>
<p>Metadata systems typically have three building blocks:</p>
<figure id="attachment_11344" aria-describedby="caption-attachment-11344"><img data-attachment-id="11344" data-permalink="https://gradientflow.com/metadata2/" data-orig-file="https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata2.jpg?fit=2202%2C1126&amp;ssl=1" data-orig-size="2202,1126" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="metadata2" data-image-description="" data-medium-file="https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata2.jpg?fit=300%2C153&amp;ssl=1" data-large-file="https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata2.jpg?fit=750%2C384&amp;ssl=1" loading="lazy" src="https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata2.jpg?resize=750%2C384&amp;ssl=1" alt="The metadata and governance stack" width="750" height="384" srcset="https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata2.jpg?resize=1024%2C524&amp;ssl=1 1024w, https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata2.jpg?resize=300%2C153&amp;ssl=1 300w, https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata2.jpg?resize=768%2C393&amp;ssl=1 768w, https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata2.jpg?resize=1536%2C785&amp;ssl=1 1536w, https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata2.jpg?resize=2048%2C1047&amp;ssl=1 2048w, https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata2.jpg?resize=1200%2C614&amp;ssl=1 1200w, https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata2.jpg?resize=1568%2C802&amp;ssl=1 1568w" sizes="(max-width: 750px) 100vw, 750px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata2.jpg?resize=1024%2C524&amp;ssl=1 1024w, https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata2.jpg?resize=300%2C153&amp;ssl=1 300w, https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata2.jpg?resize=768%2C393&amp;ssl=1 768w, https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata2.jpg?resize=1536%2C785&amp;ssl=1 1536w, https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata2.jpg?resize=2048%2C1047&amp;ssl=1 2048w, https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata2.jpg?resize=1200%2C614&amp;ssl=1 1200w, https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata2.jpg?resize=1568%2C802&amp;ssl=1 1568w" data-lazy-src="https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata2.jpg?resize=750%2C384&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption id="caption-attachment-11344">Figure 2: The metadata and governance stack. Image courtesy of Intel Capital.</figcaption></figure>
<p>The first layer, unified schema, is for collecting data into a unified platform. Metadata needs to be collected from all systems, including operational systems, analytics systems, and other software. This layer has three components:</p>
<ul>
<li>
<p><strong>Extract, load, transform (ELT) </strong>– Depending on how ELT is implemented, data collection can be done using a push (changes and updates are sent automatically) or pull (metadata ELT periodically extracts changes or updates) mechanism.</p>
</li>
<li>
<p><strong>Refinement and storage </strong>– A data management system stores all the metadata data in a format that will be easy to retrieve. Linkedin, for example, found that a “<a href="https://pardhugunnam.medium.com/announcing-metaphor-data-c86170c81202">knowledge graph of metadata</a> unleashed many services and applications.”</p>
</li>
<li>
<p><strong>Access </strong>– APIs or domain-specific languages for extracting data from the metadata system are used to build the upper layers, Data Catalog and Governance.</p>
</li>
</ul>
<p>In 2015, <a href="http://radar.oreilly.com/2015/10/we-need-open-and-vendor-neutral-metadata-services.html">academic researchers began pointing out</a> the potential applications of metadata management systems for data governance and other areas of data management. As we noted, several technology companies have built systems to begin realizing this vision. Recent posts by teams behind metadata management systems at <a href="https://engineering.linkedin.com/blog/2019/data-hub">Linkedin</a> and <a href="https://www.amundsen.io/">Lyft</a> highlight the power of providing users with tools for discovering, accessing, and consuming trusted data. At Linkedin, a metadata management system <a href="https://pardhugunnam.medium.com/announcing-metaphor-data-c86170c81202">“powers numerous mission-critical use cases</a>.”</p>
<p>The second layer, Data Catalog, organizes data into an informative, searchable, and trusted inventory of all data assets. A Data Catalog has the following components:</p>
<ul>
<li>
<p><strong>Data description </strong>– A detailed description, including summaries, of all data elements.</p>
</li>
<li>
<p><strong>Data lineage </strong>– Dataflow for the origin and evolution of data. In large organizations with multiple levels of data dependencies, for example, change management and communication with downstream users is a challenge that can be addressed with a knowledge graph.</p>
</li>
<li>
<p><strong>Data version control </strong>– A system responsible for tracking changes in datasets over time.</p>
</li>
<li>
<p><strong>Data usage </strong>– Tracking data usage and consumption by human users or by applications and systems. Data usage includes the ability to observe the actual flow of data in an organization. Data usage and consumption tracking can also help build cost-management solutions.</p>
</li>
</ul>
<p>The final layer, Governance, manages the availability, integrity, and security of data in enterprise systems, based on internal data standards and policies that control data usage. Effective data governance ensures that data is consistent and trustworthy, and doesn’t get misused. This layer has four components:</p>
<ul>
<li>
<p><strong>Data discovery </strong>– A service that includes detecting sensitive data across all data platforms, saving time and limiting risk from manual errors.</p>
</li>
<li>
<p><strong>Data masking </strong>– A collection of techniques to reduce the unnecessary spread and exposure of sensitive data while simultaneously maintaining its usability.</p>
</li>
<li>
<p><strong>Data access management </strong>– A fine-grained access control on the cell level that maintains adherence to organizational policy and regulations.</p>
</li>
<li>
<p><strong>Data quality </strong>– The accuracy, completeness, consistency, and relevance of data. Data quality tools help assess quality and fix issues in data.</p>
</li>
</ul>
<h2>Snapshot of Companies</h2>
<p>Below is a partial list of companies that have solutions in the three building block layers we described. In this graphic, a company or an open source project that appears in one of the layers may only address a subset of the components in that layer. Moreover, some companies span multiple layers, but for the sake of space and clarity, we opted not to place them in all the layers for which they potentially have solutions.</p>
<figure id="attachment_11345" aria-describedby="caption-attachment-11345"><img data-attachment-id="11345" data-permalink="https://gradientflow.com/metadata3/" data-orig-file="https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata3.jpg?fit=2196%2C1170&amp;ssl=1" data-orig-size="2196,1170" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="metadata3" data-image-description="" data-medium-file="https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata3.jpg?fit=300%2C160&amp;ssl=1" data-large-file="https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata3.jpg?fit=750%2C400&amp;ssl=1" loading="lazy" src="https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata3.jpg?resize=750%2C400&amp;ssl=1" alt="tools, services, and companies in our Metadata and Governance stack" width="750" height="400" srcset="https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata3.jpg?resize=1024%2C546&amp;ssl=1 1024w, https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata3.jpg?resize=300%2C160&amp;ssl=1 300w, https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata3.jpg?resize=768%2C409&amp;ssl=1 768w, https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata3.jpg?resize=1536%2C818&amp;ssl=1 1536w, https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata3.jpg?resize=2048%2C1091&amp;ssl=1 2048w, https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata3.jpg?resize=1200%2C639&amp;ssl=1 1200w, https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata3.jpg?resize=1568%2C835&amp;ssl=1 1568w" sizes="(max-width: 750px) 100vw, 750px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata3.jpg?resize=1024%2C546&amp;ssl=1 1024w, https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata3.jpg?resize=300%2C160&amp;ssl=1 300w, https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata3.jpg?resize=768%2C409&amp;ssl=1 768w, https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata3.jpg?resize=1536%2C818&amp;ssl=1 1536w, https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata3.jpg?resize=2048%2C1091&amp;ssl=1 2048w, https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata3.jpg?resize=1200%2C639&amp;ssl=1 1200w, https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata3.jpg?resize=1568%2C835&amp;ssl=1 1568w" data-lazy-src="https://i2.wp.com/gradientflow.com/wp-content/uploads/2021/01/metadata3.jpg?resize=750%2C400&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption id="caption-attachment-11345">Figure 3: Representative examples of tools, services, and companies in our Metadata and Governance stack. Image courtesy of Intel Capital.</figcaption></figure>
<h2>Summary</h2>
<p>In this post, we describe a new set of metadata management systems and how they will impact data governance solutions, data catalogs, and other enterprise data systems. We close this post with the following observations about the future of metadata management solutions:</p>
<ul>
<li>
<p>A couple of startups already focus on metadata management, and we expect <a href="https://medium.com/knowledge-technologies/review-metadata-day-2020-e38c28c4cf1a">more companies to follow</a>.</p>
</li>
<li>
<p>We believe metadata management systems will be the foundation for many data management applications, as outlined in Figure 2 above.</p>
</li>
<li>
<p>As AI and data applications increasingly rely on disparate data sources, data governance solutions must be global in scope—in other words, end-to-end data governance solutions that cover source systems, data warehouses, data management systems, and data pipelines</p>
</li>
<li>
<p>It’s important to emphasize that business value lies in global data governance, which can be best achieved through a unified schema.</p>
</li>
</ul>
<hr>
<p>Assaf Araki is an investment manager at Intel Capital. His contributions to this post are his personal opinion and do not represent the opinion of the Intel Corporation. Intel Capital is an investor in Immuta. #IamIntel</p>
<p>Ben Lorica is co-chair of the Ray Summit, chair of the NLP Summit, and principal at<a href="https://gradientflow.com/about/"> Gradient Flow</a>. He is an advisor to Metaphor Data.</p>
<hr>
<p><strong>Related content</strong>: Previous posts by Assaf Araki and Ben Lorica.</p>
<ul>
<li>
<p><a href="https://gradientflow.com/ai-and-automation-meet-bi/">AI and Automation meet BI</a></p>
</li>
<li>
<p><a href="https://gradientflow.com/demystifying-ai-infrastructure/">Demystifying AI Infrastructure</a></p>
</li>
<li>
<p><a href="https://gradientflow.com/software-20-takes-shape/">Software 2.0 takes shape</a></p>
</li>
</ul>
<center><strong>FREE report</strong>:</center>
<p><a href="https://gradientflow.com/2021trendsreport/"><img data-attachment-id="11155" data-permalink="https://gradientflow.com/clipboard-gf-logo/attachment/trends-report/" data-orig-file="https://i1.wp.com/gradientflow.com/wp-content/uploads/2030/05/trends-report.jpg?fit=1562%2C1156&amp;ssl=1" data-orig-size="1562,1156" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="trends-report" data-image-description="" data-medium-file="https://i1.wp.com/gradientflow.com/wp-content/uploads/2030/05/trends-report.jpg?fit=300%2C222&amp;ssl=1" data-large-file="https://i1.wp.com/gradientflow.com/wp-content/uploads/2030/05/trends-report.jpg?fit=750%2C555&amp;ssl=1" loading="lazy" src="https://i1.wp.com/gradientflow.com/wp-content/uploads/2030/05/trends-report.jpg?resize=300%2C222&amp;ssl=1" alt="" width="300" height="222" srcset="https://i1.wp.com/gradientflow.com/wp-content/uploads/2030/05/trends-report.jpg?resize=300%2C222&amp;ssl=1 300w, https://i1.wp.com/gradientflow.com/wp-content/uploads/2030/05/trends-report.jpg?resize=1024%2C758&amp;ssl=1 1024w, https://i1.wp.com/gradientflow.com/wp-content/uploads/2030/05/trends-report.jpg?resize=768%2C568&amp;ssl=1 768w, https://i1.wp.com/gradientflow.com/wp-content/uploads/2030/05/trends-report.jpg?resize=1536%2C1137&amp;ssl=1 1536w, https://i1.wp.com/gradientflow.com/wp-content/uploads/2030/05/trends-report.jpg?resize=1200%2C888&amp;ssl=1 1200w, https://i1.wp.com/gradientflow.com/wp-content/uploads/2030/05/trends-report.jpg?w=1562&amp;ssl=1 1562w" sizes="(max-width: 300px) 100vw, 300px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/gradientflow.com/wp-content/uploads/2030/05/trends-report.jpg?resize=300%2C222&amp;ssl=1 300w, https://i1.wp.com/gradientflow.com/wp-content/uploads/2030/05/trends-report.jpg?resize=1024%2C758&amp;ssl=1 1024w, https://i1.wp.com/gradientflow.com/wp-content/uploads/2030/05/trends-report.jpg?resize=768%2C568&amp;ssl=1 768w, https://i1.wp.com/gradientflow.com/wp-content/uploads/2030/05/trends-report.jpg?resize=1536%2C1137&amp;ssl=1 1536w, https://i1.wp.com/gradientflow.com/wp-content/uploads/2030/05/trends-report.jpg?resize=1200%2C888&amp;ssl=1 1200w, https://i1.wp.com/gradientflow.com/wp-content/uploads/2030/05/trends-report.jpg?w=1562&amp;ssl=1 1562w" data-lazy-src="https://i1.wp.com/gradientflow.com/wp-content/uploads/2030/05/trends-report.jpg?resize=300%2C222&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></p><center><a href="https://gradientflow.com/2021trendsreport/">Download</a></center>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://gradientflow.com/the-growing-importance-of-metadata-management-systems/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26001976</guid>
            <pubDate>Tue, 02 Feb 2021 15:24:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[RISC-V isn’t as interesting as you think]]>
            </title>
            <description>
<![CDATA[
Score 120 | Comments 145 (<a href="https://news.ycombinator.com/item?id=26001972">thread link</a>) | @glhaynes
<br/>
February 2, 2021 | https://sporks.space/2021/02/01/risc-v-isnt-as-interesting-as-you-think/ | <a href="https://web.archive.org/web/*/https://sporks.space/2021/02/01/risc-v-isnt-as-interesting-as-you-think/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-47">
	<!-- .entry-header -->

	
		<div>
			
<p><em>I had wrote this before the Unleashed was revealed, so some of the bits on economics have changed. As of writing this, I still stand by my other beliefs. </em>One of the most hyped things in hardware design is RISC-V, the open ISA available without license fees. Many organizations including <a href="https://www.westerndigital.com/company/innovations/risc-v">Western Digital</a> have pledged support for RISC-V, and the open source community has a lot of faith in it, and with <a href="https://www.anandtech.com/show/16080/nvidia-to-acquire-arm-for-40-billion">Nvidia’s recent purchase of Arm</a>, people are concerned. However, I feel these hopes are somewhat misleading, as RISC-V’s openness is less at the benefit of the user and more for CPU vendors.</p>

<p><strong>Royalties</strong>. One of the biggest benefits of RISC-V is not having to pay any royalties for a CPU using it. You might pay SiFive or someone else for a realization of their cores on hard silicon, but that’s for the design, not an abstract implementation of the ISA. Openness here means there’s more profit margin on the tiny chips running washing machines, since they don’t have to pay ARM or Synopsys. While the savings could be passed onto you, the ISA’s openness will never be of concern when the program is on a one-time-programmable ROM.</p>



<p><strong>ISA fragmentation</strong>. RISC-V intentionally defines a small ISA with extensions (for example, multiplication, which actually encompasses divide too… which is even more expensive to implement than multiply, but it’s a package deal). While most larger implementations will implement a common set of extensions, having basic functionality in extensions could make software compatibility for binary distributions harder. This is made worse by RISC-V explicitly encouraging custom instructions for task-specific tweaks on vendor silicon – great for embedded, not so hot for general purpose computers and operating systems supporting them.</p>



<p><strong>Economics</strong>. RISC-V has actively courted embedded, which makes sense as a niche. Much of the hype of RISC-V is hoping for laptop/desktop/server class silicon. This is unlikely, because the economics of embedded are different. ISA doesn’t matter as much in embedded programming (code reuse matters, but it’s not like you’re running arbitrary binaries), whereas user/enterprise focused computing usually lives and dies by binary compatibility (to protect investments in existing applications) and performance gained by things most RISC-V implementations don’t have yet like superscalar execution (To say nothing how these impact implementation complexity and security!).</p>



<p><strong>Openness doesn’t tickle down</strong>. The openness of an ISA doesn’t have much impact on the implementation. A design with restricted signing keys is completely acceptable under their licensing – and is very likely, considering the embedded dominance RISC-V is likely to have. There are no guarantees of openness in ways that impact a user (i.e controlling the root of trust), since a user doesn’t exactly have access to a fab.</p>



<p><strong>Design flaws</strong>. RISC-V seems like it hasn’t learned anything from CPUs designed after 1991. Between some <a href="https://gist.github.com/erincandescent/8a10eeeea1918ee4f9d9982f7618ef68">rookie mistakes</a> like few <a href="https://lobste.rs/s/yqqhxu/llvm_for_m68k_completed_not_merged">addressing modes</a> (register churn, code density) and <a href="https://lobste.rs/s/icegvf/will_risc_v_revolutionize_computing#c_8wbb6t">blowing out the encoding space</a>. However, despite its flaws, it’s poised to take over embedded and possibly beyond anyways – worse truly is better.</p>



<p>Overall, RISC-V will lead in a revolution for nationalist vanity CPUs (think Loongson; no one will run them but for show and perhaps a niche of radical ideologues) , academic projects, and embedded vendors wanting to save on their balance sheets, but it probably won’t affect users or developers.</p>
					</div><!-- .entry-content -->

	
	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://sporks.space/2021/02/01/risc-v-isnt-as-interesting-as-you-think/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26001972</guid>
            <pubDate>Tue, 02 Feb 2021 15:24:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Asynchronous programming. Blocking I/O and non-blocking I/O]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26001957">thread link</a>) | @kordlessagain
<br/>
February 2, 2021 | https://luminousmen.com/post/asynchronous-programming-blocking-and-non-blocking | <a href="https://web.archive.org/web/*/https://luminousmen.com/post/asynchronous-programming-blocking-and-non-blocking">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p>This is the first post in a series on asynchronous programming. The whole series tries to answer a simple question: "What is asynchrony?". In the beginning, when I first started digging into the question, I thought I knew what it is. It turned out that I didn't know the slightest thing about asynchrony. So let's find out!</p>
<p>Whole series:</p>
<ul>
<li><a href="https://luminousmen.com/post/asynchronous-programming-blocking-and-non-blocking">Asynchronous programming. Blocking I/O and non-blocking I/O</a></li>
<li><a href="https://luminousmen.com/post/asynchronous-programming-cooperative-multitasking">Asynchronous programming. Cooperative multitasking</a></li>
<li><a href="https://luminousmen.com/post/asynchronous-programming-await-the-future">Asynchronous programming. Await the Future</a></li>
<li><a href="https://luminousmen.com/post/asynchronous-programming-python3.5">Asynchronous programming. Python3.5+</a></li>
</ul>
<p>In this post, we will be talking about networking but you can easily map it to other input/output(I/O) operations, for example, change sockets to file descriptors. Also, this explanation is not focusing on any specific programming language although the examples will be given in Python(what can I say – I love Python!).</p>
<hr>
<p>One way or another, when you have a question about blocking or non-blocking calls, <a href="https://insights.stackoverflow.com/survey/2018/">most commonly it means dealing with I/O</a>. The most frequent case in our age of information, microservices, and lambda functions will be request processing. We can immediately imagine that you, dear reader, are a user of a web site, while your browser (or the application where you're reading these lines) is a client. Somewhere in the depths of the Amazon, there is a server that handles your incoming requests to generate the same lines that you're reading.</p>
<p>In order to start an interaction in such client-server communications, the client and the server must first establish a connection with each other. We will not go into the depths of the <a href="https://en.wikipedia.org/wiki/OSI_model">7-layer model</a> and the protocol stack that is involved in this interaction, as I think it all can be easily found on the Internet. What we need to understand is that on both sides (client and server) there are special connection points known as sockets. Both the client and server must be bound to each other's sockets, and listen to them to understand what the other says on the opposite side of the wire.</p>
<p><img src="https://iamluminousmen-media.s3.amazonaws.com/media/asynchronous-programming-blocking-and-non-blocking/asynchronous-programming-blocking-and-non-blocking-1.jpg" alt="Client-server communication"></p>
<p>In our communication, the server doing something — either processes the request, converts markdown to HTML or looks where the images are, it performs some kind of processing.</p>
<p><img src="https://iamluminousmen-media.s3.amazonaws.com/media/latency-of-events.png" alt="CPU speed and network speed"></p>
<p>If you look at the ratio between CPU speed and network speed, the difference is a couple of orders of magnitude. It turns out that if our application uses I/O most of the time, in most cases the processor simply does nothing. This type of application is called I/O-bound. For applications that require high performance, it is a bottleneck, and that is what we will talk about next.</p>
<p>There are two ways to organize I/O (I will give examples based on Linux): <strong>blocking</strong> and <strong>non-blocking</strong>.</p>
<p>Also, there are two types of I/O operations: synchronous and asynchronous.</p>
<p>All together they represent possible I/O models.</p>
<p><img src="https://iamluminousmen-media.s3.amazonaws.com/media/asynchronous-programming-blocking-and-non-blocking/asynchronous-programming-blocking-and-non-blocking-3.JPG" alt="I/O models"></p>
<p>Each of these I/O models has usage patterns that are advantageous for particular applications. Here I will demonstrate the difference between the two ways of organizing I/O.</p>
<h2>Blocking I/O</h2>
<p>With the blocking I/O, when the client makes a connection request to the server, the socket processing that connection and the corresponding thread that reads from it is blocked until some read data appears. This data is placed in the network buffer until it is all read and ready for processing. Until the operation is complete, the <strong>server can do nothing more but wait</strong>.</p>
<p>The simplest conclusion from this is that we cannot serve more than one connection within a single thread. By default, TCP sockets work in blocking mode.</p>
<p>A simple example on Python, client:</p>
<pre><code>import socket
import sys
import time


def main() -&gt; None:
    host = socket.gethostname()
    port = 12345

    # create a TCP/IP socket
    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:
        while True:
            sock.connect((host, port))
            while True:
                data = str.encode(sys.argv[1])
                sock.send(data)
                time.sleep(0.5)

if __name__ == "__main__":
    assert len(sys.argv) &gt; 1, "Please provide message"
    main()
</code></pre>
<p>Here we send a message with 50ms interval to the server in the endless loop. Imagine that this client-server communication consist of downloading a big file — it takes some time to finish.<span data-ez-name="luminousmen_com-large-leaderboard-2"></span></p>
<p>And the server:</p>
<pre><code>import socket


def main() -&gt; None:
    host = socket.gethostname()
    port = 12345
    
    # create a TCP/IP socket
    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:
        # bind the socket to the port
        sock.bind((host, port))
        # listen for incoming connections
        sock.listen(5)
        print("Server started...")

        while True:
            conn, addr = sock.accept()  # accepting the incoming connection, blocking
            print('Connected by ' + str(addr))
            while True:
                data = conn.recv(1024)  # receving data, blocking
                if not data: 
                    break
                print(data)

if __name__ == "__main__":
    main()
</code></pre>
<p>I am running this in separate terminal windows with several clients as:</p>
<pre><code>$ python client.py "client N"
</code></pre>
<p>And server as:</p>
<pre><code>$ python server.py
</code></pre>
<p>Here we just listen to the socket and accept incoming connections. Then we try to receive data from this connection.</p>
<p>In the above code, the server will essentially be blocked by a single client connection! If we run another client with another message, you will not see it. I highly recommend that you play with this example to understand what is happening.</p>
<p><em>What is going on here?</em></p>
<p>The <code>send()</code> method will try to send all data to the server while the write buffer on the server will continue to receive data. When the system call for reading is called, the application is blocked and the context is switched to the kernel. The kernel initiates reading - the data is transferred to the user-space buffer. When the buffer becomes empty, the kernel will wake up the process again to receive the next portion of data to be transferred.</p>
<p>Now in order to handle two clients with this approach, we need to have several threads, i.e. to allocate a new thread for each client connection. We will get back to that soon.</p>

<h2>Non-blocking I/O</h2>
<p>However, there is also a second option — <strong>non-blocking I/O</strong>. The difference is obvious from its name — instead of blocking, any operation is executed immediately. Non-blocking I/O means that the request is immediately queued and the function is returned. The actual I/O is then processed at some later point.</p>
<p>By setting a socket to a non-blocking mode, you can effectively interrogate it. If you try to read from a non-blocking socket and there is no data, it will return an error code (<code>EAGAIN</code> or <code>EWOULDBLOCK</code>).</p>
<p>Actually, this polling type is a bad idea. If you run your program in a constant cycle of polling data from the socket, it will consume expensive CPU time. This can be extremely inefficient because in many cases the application must busy-wait until the data is available or attempt to do other work while the command is performed in the kernel. A more elegant way to check if the data is readable is using <code>select()</code>.</p>
<p>Let us go back to our example with the changes on the server:</p>
<pre><code>import select
import socket


def main() -&gt; None:
    host = socket.gethostname()
    port = 12345

    # create a TCP/IP socket
    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:
        sock.setblocking(0)
        # bind the socket to the port
        sock.bind((host, port))
        # listen for incoming connections
        sock.listen(5)
        print("Server started...")

        # sockets from which we expect to read
        inputs = [sock]
        outputs = []

        while inputs:
            # wait for at least one of the sockets to be ready for processing
            readable, writable, exceptional = select.select(inputs, outputs, inputs)

            for s in readable:
                if s is sock:
                    conn, addr = s.accept()
                    inputs.append(conn)
                else:
                    data = s.recv(1024)
                    if data:
                        print(data)
                    else:
                        inputs.remove(s)
                        s.close()

if __name__ == "__main__":
    main()
</code></pre>
<p>Now if we run this code with &gt;1 clients you will see that the server is not blocked by a single client and it handles everything that can be detected by the messages displayed. Again, I suggest that you try this example yourself.</p>
<p><em>What's going on here?</em></p>
<p>Here the server does not wait for all the data to be written to the buffer. When we make a socket non-blocking by calling <code>setblocking(0)</code>, it will never wait for the operation to be completed. So when we call the <code>recv</code> method, it will return to the main thread. The main mechanical difference is that <code>send</code>, <code>recv</code>, <code>connect</code> and <code>accept</code> can return without doing anything at all.</p>
<p>With this approach, we can perform multiple I/O operations with different sockets from the same thread concurrently. But since we don't know if a socket is ready for an I/O operation, we would have to ask each socket with the same question and essentially spin in an infinite loop (this non-blocking but the still synchronous approach is called I/O multiplexing).</p>
<p>To get rid of this inefficient loop, we need <strong>polling readiness mechanism</strong>. In this mechanism, we could interrogate the readiness of all sockets, and they would tell us which one is ready for the new I/O operation and which one is not without being explicitly asked. When any of the sockets is ready, we will perform operations in the queue and then be able to return to the blocking state, waiting for the sockets to be ready for the next I/O operation.</p>
<p>There are several polling readiness mechanisms, they are different in performance and detail, but usually, the details are hidden "under the hood" and not visible to us.</p>
<h3>Keywords to search:</h3>
<p>Notifications:</p>
<ul>
<li>Level Triggering (state)</li>
<li>Edge Triggering (state changed)</li>
</ul>
<p>Mechanics:</p>
<ul>
<li><code>select()</code>, <code>poll()</code></li>
<li><code>epoll()</code>, <code>kqueue()</code></li>
<li><code>EAGAIN</code>, <code>EWOULDBLOCK</code></li>
</ul>

<h2>Multitasking</h2>
<p>Therefore, our goal …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://luminousmen.com/post/asynchronous-programming-blocking-and-non-blocking">https://luminousmen.com/post/asynchronous-programming-blocking-and-non-blocking</a></em></p>]]>
            </description>
            <link>https://luminousmen.com/post/asynchronous-programming-blocking-and-non-blocking</link>
            <guid isPermaLink="false">hacker-news-small-sites-26001957</guid>
            <pubDate>Tue, 02 Feb 2021 15:22:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple is removing the controversial ContentFilterExclusionList in macOS 11.2]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26001747">thread link</a>) | @HelenePhisher
<br/>
February 2, 2021 | https://blog.obdev.at/a-wall-without-a-hole/ | <a href="https://web.archive.org/web/*/https://blog.obdev.at/a-wall-without-a-hole/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
        <article>
            
            

            <section>
                <!--kg-card-begin: html-->
<!--kg-card-end: html--><!--kg-card-begin: image--><figure><img src="https://blog.obdev.at/content/images/2021/01/closed-hole.jpg"></figure><!--kg-card-end: image--><p><em><strong>Update:</strong> Apple has released macOS 11.2 on February 1, 2021, removing the controversial ContentFilterExclusionList</em>.</p><p>It seems that Apple is willing to admit mistakes. The unfortunate <a href="https://blog.obdev.at/a-hole-in-the-wall">hole in the wall</a> that raised a lot of privacy and security concerns in the Mac community appears to get closed in the upcoming version 11.2 of macOS Big Sur, allowing third-party firewalls like Little Snitch to reliably monitor and filter <em>any</em> network traffic again.</p><p>Thanks Apple for listening!</p><!--kg-card-begin: html--><p>Credits: Image by clipground.com licensed under <a href="https://creativecommons.org/licenses/by/4.0">CC BY 4.0</a></p><!--kg-card-end: html-->
            </section>

             
                
            
        </article>
    </div></div>]]>
            </description>
            <link>https://blog.obdev.at/a-wall-without-a-hole/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26001747</guid>
            <pubDate>Tue, 02 Feb 2021 15:06:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MusicBrainz and Plex: Not your usuage service outage]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26001732">thread link</a>) | @mayhemchaos
<br/>
February 2, 2021 | https://blog.metabrainz.org/2021/02/02/incident-report-january-27th-service-outage/ | <a href="https://web.archive.org/web/*/https://blog.metabrainz.org/2021/02/02/incident-report-january-27th-service-outage/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

<div id="primary">
	<main id="main" role="main">
		
<article id="post-8663">
	<!-- .entry-header -->

	
	
	<div>
		
<p>On January 27th, starting at 4:31UTC we were hit with increasing amounts of traffic from what appeared to be hundreds of different IP addresses mostly belonging to Amazon Web Service IP addresses. At 8:46UTC the inbound traffic overwhelmed our systems and brought nearly all of our services to a standstill.</p>



<p>After investigating the situation and receiving no meaningful assistance from Hetzner (our ISP who advertises DDoS mitigation services as part of their offerings) we blocked three subnets of IP addresses in order to restore our services. At 13:14UTC we put the block in place and our services started recovering.</p>



<p>We reported the issue to Hetzner and to AWS shortly after restoring our service. The next morning we received a friendly email from Andy, who works for one of our supporters at <a href="https://www.plex.tv/">Plex</a>, stating that they received a complaint from AWS. What happened next and how this matter was resolved is told by Andy himself:</p>



<blockquote><p><em>Overnight on Wednesday, first thing Thursday morning, we received an abuse report that our servers were flooding an IP that corresponded to musicbrainz.org. We scrambled to investigate, as we are happy MusicBrainz partners, but it was a strange report because we run our MusicBrainz server and hit that instance rather than communicating with musicbrainz.org directly. And the IPs mentioned were specifically related to our metadata servers, not the IPs that would be receiving data updates from upstream. Just as some of our key engineering team members were starting to wake up and scrub in, it started to seem that it was a coincidence and we weren’t the actual source of the traffic and had simply been caught up in an overeager blocking of a large IP range to get the services back up. Never trust a coincidence. We continued to stay in touch with the team at MusicBrainz and within a few hours we had clear evidence that our IPs were the source of the traffic. We got the whole engineering team involved again to do some investigation, and we still couldn’t figure much out since we never make requests to musicbrainz.org and we had already worked to rule out the potential of any rogue access to our servers. By isolating our services and using our monitoring tools, we finally discovered that the issue was actually our traffic to coverartarchive.org, not musicbrainz.org, as they happen to be serviced by the same IP address. And this made much more sense, as we do depend on some API calls to the Cover Art Archive.</em></p><p><em>The root cause was an update to the Plex Media Server which had been released earlier in the week. There was a bug in that update that caused extra metadata requests to our own infrastructure. We had noticed the spike in our autoscaling to accommodate the extra traffic and already put together another update to fix the bug. That extra traffic on our infrastructure also translated to a more modest increase in requests to some of our metadata partners, including CAA. While the fix was already rolling out to Plex Media Servers, this provided a good opportunity to evaluate the CAA traffic and put our own rate limit in place to protect against future issues. We wrapped up that change in the afternoon on Thursday.</em></p><p><em>Throughout the ordeal, we appreciated the communication back and forth with our partners at MusicBrainz so that we could work together to investigate and follow leads to find a timely resolution.</em></p><cite>Andy from Plex</cite></blockquote>



<p>While this whole situation was very stressful and frustrating to us, in the end it was resolved by a very friendly and technical detective game to identify and resolve the issue. It is always nice when geeks talk to geeks to resolve issues and get services working again. Thank you to Andy and his team — let’s hope we can avoid an issue like this in the future.</p>



<p>We’d apologize for the trouble caused by our IP address block and for our services being unavailable for several hours.</p>



<p>EDIT: We should also mention that all of our services are served from one single gateway IP address, so coverartarchive.org and musicbrainz.org have the same IP address.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article><!-- #post-8663 -->

<!-- .comments-area -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
	</main><!-- .site-main -->

	
</div><!-- .content-area -->


	<!-- .sidebar .widget-area -->

		</div></div>]]>
            </description>
            <link>https://blog.metabrainz.org/2021/02/02/incident-report-january-27th-service-outage/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26001732</guid>
            <pubDate>Tue, 02 Feb 2021 15:05:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Reshaped Mac Experience]]>
            </title>
            <description>
<![CDATA[
Score 86 | Comments 71 (<a href="https://news.ycombinator.com/item?id=26001540">thread link</a>) | @yannovitch
<br/>
February 2, 2021 | http://morrick.me/archives/9150 | <a href="https://web.archive.org/web/*/http://morrick.me/archives/9150">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<p>Yesterday, a short <a href="https://twitter.com/lapcatsoftware/status/1355514848717791234">Twitter thread</a> by the excellent <a href="https://lapcatsoftware.com/articles/">Jeff Johnson</a> caught my eye. Since he often deletes past tweets, I’ll quote the relevant ones here (emphasis mine):</p>
<blockquote><p><strong>The selling point of the Macintosh was never the hardware, it was the user interface. So if the selling point now is the hardware, that’s a damning indictment of the current user interface.</strong></p>

<p><strong>I cannot emphasize enough how everyone seems to have lowered their standards with regard to the user interface.</strong> The “<a href="https://en.wikipedia.org/wiki/Overton_window">Overton window</a>” has moved. The Overton window now has rounded rects.</p>

<p>We’ve gone from “insanely great” and “It just works” to “Catalyst is good enough for most people.”</p>
<p>That’s fucking BS, and I won’t tolerate it.</p>

<p>Windows is “good enough for most people”. That’s why Windows has a 90% market share. Why should we aspire to that level, shouldn’t we have much higher aspirations? Mac is a niche. “Most people” are not even using Macs, so the majority is not even relevant. Mac is a premium brand.</p>

<p>The way I see it, the Mac now is merely milking the brand reputation and loyalty it previously built. That Jobs previously built. But neither Cook nor the current Mac deserves that reputation or loyalty.</p>

<p>Steve Jobs wasn’t an engineer. Not a hardware engineer, not a software engineer. At Apple, his role was as “proxy” for the&nbsp;users.</p>
<p>Apple no longer has a proxy for the users. Tim Cook is a proxy for the shareholders, nothing more.</p></blockquote>
<p>Jeff himself says that this criticism is hardly new, that these are things he already pointed out “a thousand times, to no effect”. While I am in no position to affect Apple or Mac development, this short Twitter rant had the effect of reminding me of something I, too, believe in; something I myself should emphasise more frequently. It’s those first two tweets I’ve quoted above.</p>
<p>As someone who still puts vintage Macs and older computers and devices to good use, the Mac’s user interface and user experience are in large part what still makes using 15–20-year-old machines enjoyable. This, by the way, also applies to other products of course. It’s thanks to well-designed user interfaces that we enjoy driving a classic car, or shooting with a 50-year-old film camera, or listening to vinyl records on a 40-year-old record-player and hi-fi stereo.</p>
<p>A couple of weeks ago I was on a group videochat with some friends and when I said that, frankly, using my 12-inch PowerBook G4 (2003) with Mac OS X 10.5 Leopard was more enjoyable than using my 13-inch retina MacBook Pro (2015) with Mac OS 11 Big Sur, the common reaction was that I was just being ‘nostalgic’; that surely my MacBook Pro was the better choice because it is orders of magnitude faster, with a ‘more modern’ OS, and that the sum of those parts was a better Mac experience. That I should ‘be rational’ and accept that.</p>
<p>Here, bringing up nostalgia is missing the point. And the point is that an admittedly faster hardware plus a purportedly ‘more modern’ operating system <em>do not necessarily</em> equal a better Mac experience. It’s interesting that my friends’ reaction was not to ask me <em>why</em> I was finding using an 18-year-old machine more enjoyable than an up-to-date Mac, but to promptly want to readjust my enjoyment, implying that there was something ‘wrong’ with&nbsp;it.</p>
<p>I’m finding that many people not only have lowered their standards with regard to the user interface, but more and more often when I bring up the subject, they seem to consider it a somewhat secondary aspect, something that’s only good for ‘geek talk’. The same kind of amused reaction laymen have to wine or coffee connoisseurs when they describe flavours and characteristics using specific lingo. Something that makes sense only to wine or coffee geeks but has little to no meaning or impact for the regular person.</p>
<p>The problem is that if an increasing number of people start viewing user interface design as an afterthought, or something that isn’t fundamental to the design of a product or experience — it’s all just ‘geek talk’ — then there is a reduced incentive to care about it on the part of the maker of the product. It’s more like a vicious circle, really; if Apple software’s quality declines but only a bunch of professional users and enthusiasts point that out, then Apple isn’t particularly incentivised to do a better job at it — the “good enough for most people” is really a dangerous, self-indulgent excuse. And in turn most people are fine with it, and in turn Apple think they’re on a ‘good’ path, and so&nbsp;forth.</p>
<p>At the very end of my piece <a href="http://morrick.me/archives/9141"><em> What about the M1 Macs?</em></a>, I&nbsp;wrote:</p>
<blockquote><p>They’re unbelievably good machines, and everything that is genuinely good about them and future Apple Silicon-based Macs — sheer performance, astounding power-efficiency, and great backward compatibility with Intel software thanks to Rosetta 2 — will also allow Apple to get away with a lot of things with regard to platform control, design decisions, and so&nbsp;forth.</p></blockquote>
<p>If you take a look at Jason Snell’s <a href="https://sixcolors.com/post/2021/01/apple-in-2020-the-six-colors-report-card/"><em>Apple in 2020: The Six Colors report card</em></a>, the Mac scored very good points overall, 4.7 out of 5, with a year-over-year increment of 1.1 points. The main reason has been of course the M1 Macs and Apple Silicon. Don’t get me wrong, Apple Silicon <em>is</em> groundbreaking, and Rosetta 2 is really an incredible performer on the software side. But what I contend is that a leap in hardware architecture and performance doesn’t necessarily mean that suddenly all is fine with the Mac as a platform or as an experience.</p>
<p>The Mac’s user interface is undergoing plastic surgery by the hand of surgeons who have studied on iOS books. The result is pretty much the same as when you see a favourite celebrity after a procedure. They look ‘younger’ but there’s also something weird about their appearance. Their traits have changed a bit. In certain cases you almost fail to recognise the person at first glance.</p>
<p>Similarly, the Mac experience today feels disjointed. The hardware has unquestionably improved with the introduction of Apple Silicon, and yes, it’s something worth celebrating and it’s something worth praising. On the other hand, the software that drives this hardware is a bit of a paradox: Big Sur and Apple Silicon Macs fit and work together well from a technical, architectural standpoint. From a user interface standpoint, however, Big Sur embodies what I’ve been fearing in recent years — a progressive iOS-ification of Mac OS. Big Sur provides a general user experience that is the least Mac-like in the history of the Mac. Going through Big Sur’s user interface with a fine-tooth comb reveals arbitrary design decisions that prioritise looks over function, and therefore reflect an un-learning of tried-and-true user interface and usability mechanics that used to make for a seamless, thoughtful, enjoyable Mac experience.</p>
<p>iOS was born as a ‘spinoff’ of Mac OS X, a sort of Lite version aimed at mobile devices like the iPhone and the iPod touch. The two platforms have maintained their separate paths and trajectories for years, and for a while using a Mac and an iPhone (or iPad) felt like having the best experience of each world. Then Apple became obsessed with thoughts of convergence, and features, UI ideas, paradigms, started bleeding through both platforms and in turn the respective experiences have become less clear-cut over time, with the software not fully capable of bringing out all that hardware power and potential.</p>
<p>This convergence will continue, of course, with Macs becoming more and more like ‘senior iOS devices’ from a UI and user experience standpoint. It seems clear to me that Apple is prioritising ecosystem experience because, let’s be honest, having a unified ‘operating system core’ underlying all platforms means having fewer framework-specific headaches and probably a faster, streamlined process when deploying new features. But this loss of differentiation is especially detrimental to Mac OS, which is being reduced to the lowest common denominator and loses an increasing amount of user interface ideas and conventions that were central to its superior user experience and ease of&nbsp;use.</p>
<p>I’m not annoyed because I see pieces of UI history fading away. I’m annoyed because I see pieces of <em>good</em> UI design fading away and being replaced by decisions that are puzzling and arbitrary, or the product of a trial-and-error process, rather than a meaningful, purposeful design.</p>
<p>You want an example that I find particularly glaring? Big Sur’s UI features a general increase of space between elements — icons, menus, labels, toolbars, sidebars, pretty much everywhere. On the surface it doesn’t seem like a bad decision. If you zoom in on certain parts of the user interface, you could say that more space between elements means that things looks cleaner, airier, sleeker.</p>
<p>But you’re looking at it on a 27-inch retina display. What about a display half that size? What about an 11-inch, non-retina display, like the one of the older 2013–2015 MacBook Airs that can be updated to Big Sur? It’s less pretty.</p>
<p><a href="https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png"><img loading="lazy" src="https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?resize=960%2C600" alt="" width="960" height="600" srcset="https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?w=2560 2560w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?resize=260%2C163 260w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?resize=640%2C400 640w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?resize=768%2C480 768w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?resize=1536%2C960 1536w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?resize=2048%2C1280 2048w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?resize=1194%2C746 1194w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?w=1920 1920w" sizes="(max-width: 960px) 100vw, 960px" data-recalc-dims="1"></a></p>
<p>I usually work with a lot of app windows and Finder windows, but when I’m using my 13-inch retina MacBook Pro with Big Sur, the workspace constantly feels cramped, while on the other hand I have no problems using High Sierra on my 11-inch MacBook Air. Sometimes it feels like looking at a zoomed-in interface. That increased space between elements becomes less of a good idea because it doesn’t scale gracefully when the overall screen real estate is reduced. It becomes an interference. Before installing Big Sur, the amount of icons on the right of the menu bar had never really been a concern. Now, the simple addition of a couple of third-party apps like Dropbox and iStat Menus — both essential for me — is enough to make that menu bar look crowded. (And thankfully Apple has been reducing the space between menu icons, because in the first Big Sur betas icon padding was so bad I had to remove a few icons and use Control Centre to check on their status).</p>
<p>This, like other UI design decisions in Big Sur, feels like …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://morrick.me/archives/9150">http://morrick.me/archives/9150</a></em></p>]]>
            </description>
            <link>http://morrick.me/archives/9150</link>
            <guid isPermaLink="false">hacker-news-small-sites-26001540</guid>
            <pubDate>Tue, 02 Feb 2021 14:49:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Comprehensive Course on Python Pandas]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26001532">thread link</a>) | @asicsp
<br/>
February 2, 2021 | https://www.gormanalysis.com/blog/python-pandas-for-your-grandpa/ | <a href="https://web.archive.org/web/*/https://www.gormanalysis.com/blog/python-pandas-for-your-grandpa/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><h2 id="python-pandas-for-your-grandpa">Python Pandas For Your Grandpa</h2>
<p>Wanna learn Pandas? I did. And I consolidated everything I learned into a 43 videos spanning roughly three hours of content, including 23 lecture videos (~2 hrs) and 20 challenge videos (~1 hr).</p>
<iframe width="800" height="450" src="https://www.youtube.com/embed/TF8lxoQhxC0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
<h2 id="course-curriculum">Course Curriculum</h2>
<ol>
<li><strong>Introduction</strong><br>
<a href="https://www.gormanalysis.com/blog/python-pandas-for-your-grandpa-1-1-introduction" rel="">1.1 Introduction</a></li>
<li><strong>Series</strong><br>
<a href="https://www.gormanalysis.com/blog/python-pandas-for-your-grandpa-2-1-series-creation" rel="">2.1 Series Creation</a><br>
<a href="https://www.gormanalysis.com/blog/python-pandas-for-your-grandpa-2-2-series-basic-indexing" rel="">2.2 Series Basic Indexing</a><br>
<a href="https://www.gormanalysis.com/blog/python-pandas-for-your-grandpa-2-3-series-basic-operations" rel="">2.3 Series Basic Operations</a><br>
<a href="https://www.gormanalysis.com/blog/python-pandas-for-your-grandpa-2-4-series-boolean-indexing" rel="">2.4 Series Boolean Indexing</a><br>
<a href="https://www.gormanalysis.com/blog/python-pandas-for-your-grandpa-2-5-series-missing-values" rel="">2.5 Series Missing Values</a><br>
<a href="https://www.gormanalysis.com/blog/python-pandas-for-your-grandpa-2-6-series-vectorization" rel="">2.6 Series Vectorization</a><br>
<a href="https://www.gormanalysis.com/blog/python-pandas-for-your-grandpa-2-7-series-apply" rel="">2.7 Series <code>apply()</code></a><br>
<a href="https://www.gormanalysis.com/blog/python-pandas-for-your-grandpa-2-8-series-view-vs-copy" rel="">2.8 Series View vs Copy</a><br>
<a href="https://www.gormanalysis.com/blog/python-pandas-for-your-grandpa-2-9-challenge-baby-names" rel="">2.9 Challenge: Baby Names</a><br>
<a href="https://www.gormanalysis.com/blog/python-pandas-for-your-grandpa-2-10-challenge-bees-knees" rel="">2.10 Challenge: Bees Knees</a><br>
<a href="https://www.gormanalysis.com/blog/python-pandas-for-your-grandpa-2-11-challenge-car-shopping" rel="">2.11 Challenge: Car Shopping</a><br>
<a href="https://www.gormanalysis.com/blog/python-pandas-for-your-grandpa-2-12-challenge-price-gouging" rel="">2.12 Challenge: Price Gouging</a><br>
<a href="https://www.gormanalysis.com/blog/python-pandas-for-your-grandpa-2-13-challenge-fair-teams" rel="">2.13 Challenge: Fair Teams</a></li>
<li><strong>DataFrame</strong><br>
<a href="https://www.gormanalysis.com/blog/python-pandas-for-your-grandpa-3-1-dataframe-creation" rel="">3.1 DataFrame Creation</a><br>
<a href="https://www.gormanalysis.com/blog/python-pandas-for-your-grandpa-3-2-dataframe-to-and-from-csv" rel="">3.2 DataFrame To And From CSV</a><br>
<a href="https://www.gormanalysis.com/blog/python-pandas-for-your-grandpa-3-3-dataframe-basic-indexing" rel="">3.3 DataFrame Basic Indexing</a><br>
<a href="https://www.gormanalysis.com/blog/python-pandas-for-your-grandpa-3-4-dataframe-basic-operations" rel="">3.4 DataFrame Basic Operations</a><br>
<a href="https://www.gormanalysis.com/blog/python-pandas-for-your-grandpa-3-5-dataframe-apply" rel="">3.5 DataFrame <code>apply()</code></a><br>
<a href="https://www.gormanalysis.com/blog/python-pandas-for-your-grandpa-3-6-dataframe-view-vs-copy" rel="">3.6 DataFrame View vs Copy</a><br>
<a href="https://www.gormanalysis.com/blog/python-pandas-for-your-grandpa-3-7-dataframe-merge" rel="">3.7 DataFrame <code>merge()</code></a><br>
<a href="https://www.gormanalysis.com/blog/python-pandas-for-your-grandpa-3-8-dataframe-aggregation" rel="">3.8 DataFrame Aggregation</a><br>
<a href="https://www.gormanalysis.com/blog/python-pandas-for-your-grandpa-3-9-dataframe-groupby" rel="">3.9 DataFrame <code>groupby()</code></a><br>
<a href="https://www.gormanalysis.com/blog/python-pandas-for-your-grandpa-3-10-challenge-hobbies" rel="">3.10 Challenge: Hobbies</a><br>
<a href="https://www.gormanalysis.com/blog/python-pandas-for-your-grandpa-3-11-challenge-party-time" rel="">3.11 Challenge: Party Time</a><br>
<a href="https://www.gormanalysis.com/blog/python-pandas-for-your-grandpa-3-12-challenge-vending-machines" rel="">3.12 Challenge: Vending Machines</a><br>
<a href="https://www.gormanalysis.com/blog/python-pandas-for-your-grandpa-3-13-challenge-cradle-robbers" rel="">3.13 Challenge: Cradle Robbers</a><br>
<a href="https://www.gormanalysis.com/blog/python-pandas-for-your-grandpa-3-14-challenge-pot-holes" rel="">3.14 Challenge: Pot Holes</a></li>
<li><strong>Advanced</strong><br>
<a href="https://www.gormanalysis.com/blog/python-pandas-for-your-grandpa-4-1-strings" rel="">4.1 Strings</a><br>
<a href="https://www.gormanalysis.com/blog/python-pandas-for-your-grandpa-4-2-dates-and-times" rel="">4.2 Dates And Times</a><br>
<a href="https://www.gormanalysis.com/blog/python-pandas-for-your-grandpa-4-3-categoricals" rel="">4.3 Categoricals</a><br>
<a href="https://www.gormanalysis.com/blog/python-pandas-for-your-grandpa-4-4-multiindex" rel="">4.4 MultiIndex</a><br>
<a href="https://www.gormanalysis.com/blog/python-pandas-for-your-grandpa-4-5-dataframe-reshaping" rel="">4.5 DataFrame Reshaping</a><br>
<a href="https://www.gormanalysis.com/blog/python-pandas-for-your-grandpa-4-6-challenge-class-transitions" rel="">4.6 Challenge: Class Transitions</a><br>
<a href="https://www.gormanalysis.com/blog/python-pandas-for-your-grandpa-4-7-challenge-rose-thorn" rel="">4.7 Challenge: Rose Thorn</a><br>
<a href="https://www.gormanalysis.com/blog/python-pandas-for-your-grandpa-4-8-challenge-product-volumes" rel="">4.8 Challenge: Product Volumes</a><br>
<a href="https://www.gormanalysis.com/blog/python-pandas-for-your-grandpa-4-9-challenge-session-groups" rel="">4.9 Challenge: Session Groups</a><br>
<a href="https://www.gormanalysis.com/blog/python-pandas-for-your-grandpa-4-10-challenge-ob-gym" rel="">4.10 Challenge: OB-GYM</a></li>
<li><strong>Final Boss</strong><br>
<a href="https://www.gormanalysis.com/blog/python-pandas-for-your-grandpa-5-1-challenge-covid-tracing" rel="">5.1 Challenge: COVID Tracing</a><br>
<a href="https://www.gormanalysis.com/blog/python-pandas-for-your-grandpa-5-2-challenge-pickle" rel="">5.2 Challenge: Pickle</a><br>
<a href="https://www.gormanalysis.com/blog/python-pandas-for-your-grandpa-5-3-challenge-tv-commercials" rel="">5.3 Challenge: TV Commercials</a><br>
<a href="https://www.gormanalysis.com/blog/python-pandas-for-your-grandpa-5-4-challenge-family-iq" rel="">5.4 Challenge: Family IQ</a><br>
<a href="https://www.gormanalysis.com/blog/python-pandas-for-your-grandpa-5-5-challenge-concerts" rel="">5.5 Challenge: Concerts</a></li>
</ol>
</div></div>]]>
            </description>
            <link>https://www.gormanalysis.com/blog/python-pandas-for-your-grandpa/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26001532</guid>
            <pubDate>Tue, 02 Feb 2021 14:48:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CompilerGym: A toolkit for reinforcement learning for compiler optimization]]>
            </title>
            <description>
<![CDATA[
Score 133 | Comments 16 (<a href="https://news.ycombinator.com/item?id=26001480">thread link</a>) | @azhenley
<br/>
February 2, 2021 | https://facebookresearch.github.io/CompilerGym/getting_started.html | <a href="https://web.archive.org/web/*/https://facebookresearch.github.io/CompilerGym/getting_started.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
    <nav data-toggle="wy-nav-shift">
      
    </nav>

    <section data-toggle="wy-nav-shift">

      
      <nav aria-label="top navigation">
        
          <i data-toggle="wy-nav-top"></i>
          <a href="https://facebookresearch.github.io/CompilerGym/index.html">CompilerGym</a>
        
      </nav>


      <div>
        
        <div>
        
          
















          <div role="main" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div id="getting-started">

<p><a href="https://colab.research.google.com/github/facebookresearch/CompilerGym/blob/development/examples/getting-started.ipynb"><img alt="https://colab.research.google.com/assets/colab-badge.svg" src="https://colab.research.google.com/assets/colab-badge.svg"></a></p><p>CompilerGym is a toolkit for applying reinforcement learning to compiler
optimization tasks. This document provides a short walkthrough of the key
concepts, using the codesize reduction task of a production-grade compiler
as an example. It will take about 20 minutes to work through. Lets get
started!</p>

<div id="key-concepts">
<h2><a href="#id3">Key Concepts</a><a href="#key-concepts" title="Permalink to this headline">¶</a></h2>
<p>CompilerGym exposes compiler optimization problems as environments for
reinforcement learning. It uses the <a href="https://gym.openai.com/">OpenAI Gym</a>
interface to expose the “agent-environment loop” of reinforcement learning:</p>
<p><img alt="_images/overview.png" src="https://facebookresearch.github.io/CompilerGym/_images/overview.png"></p><p>The ingredients for reinforcement learning that CompilerGym provides are:</p>
<ul>
<li><p><strong>Environment</strong>: a compiler optimization task. For example,
<em>optimizing a C++ graph-traversal program for codesize using LLVM</em>. The
environment encapsulates an instance of a compiler and a particular program
that is being compiled. As an agent interacts with the environment, the state
of the program, and the compiler, can change.</p></li>
<li><p><strong>Action Space</strong>: the actions that may be taken at the current environment
state. For example, this could be a set of optimization transformations that
the compiler can apply to the program.</p></li>
<li><p><strong>Observation</strong>: a view of the current environment state. For example, this
could be the Intermediate Representation (IR) of the program that is being
compiled. The types of observations that are available depend on the compiler.</p></li>
<li><p><strong>Reward</strong>: a metric indicating the quality of the previous action. For
example, for a codesize optimization task this could be the change to the
number of instructions of the previous action.</p></li>
</ul>
<p>A single instance of this “agent-environment loop” represents the compilation of
a particular program. The goal is to develop an agent that maximises the
cumulative reward from these environments so as to produce the best programs.</p>
</div>
<div id="installation">
<h2><a href="#id4">Installation</a><a href="#installation" title="Permalink to this headline">¶</a></h2>
<p>Install the latest CompilerGym release using:</p>
<div><div><pre><span></span>$ pip install compiler_gym
</pre></div>
</div>
<p>The binary works on macOS and Linux (on Ubuntu 18.04, Fedora 28, Debian
10 or newer equivalents).</p>
<div id="building-from-source">
<h3><a href="#id5">Building from Source</a><a href="#building-from-source" title="Permalink to this headline">¶</a></h3>
<p>If you prefer, you may build from source. This requires a modern C++
toolchain. On macOS you can use the system compiler. On linux, install
the required toolchain using:</p>
<div><div><pre><span></span>$ sudo apt install clang libtinfo5 patchelf
$ export CC=clang
$ export CXX=clang++
</pre></div>
</div>
<p>We recommend using
<a href="https://docs.conda.io/projects/conda/en/latest/user-guide/install/">conda</a>
to manage the remaining build dependencies. First create a conda
environment with the required dependencies:</p>
<div><div><pre><span></span>$ conda create -n compiler_gym python=3.8 bazel=3.1.0 cmake pandoc
$ conda activate compiler_gym
</pre></div>
</div>
<p>Then clone the CompilerGym source code using:</p>
<div><div><pre><span></span>$ git clone https://github.com/facebookresearch/CompilerGym.git
$ cd CompilerGym
</pre></div>
</div>
<p>Install the python development dependencies using:</p>

<p>Then run the test suite to confirm that everything is working:</p>

<p>To build and install the python package, run:</p>

<p>When you are finished, you can deactivate and delete the conda
environment using:</p>
<div><div><pre><span></span>$ conda deactivate
$ conda env remove -n compiler_gym
</pre></div>
</div>
</div>
</div>
<div id="using-compilergym">
<h2><a href="#id6">Using CompilerGym</a><a href="#using-compilergym" title="Permalink to this headline">¶</a></h2>
<p>Begin by firing up a python interpreter:</p>

<p>To start with we import the gym module and the CompilerGym environments:</p>
<div><div><pre><span></span><span>&gt;&gt;&gt; </span><span>import</span> <span>gym</span>
<span>&gt;&gt;&gt; </span><span>import</span> <span>compiler_gym</span>
</pre></div>
</div>
<p>Importing <a href="https://facebookresearch.github.io/CompilerGym/compiler_gym/compiler_gym.html#module-compiler_gym" title="compiler_gym"><code><span>compiler_gym</span></code></a> automatically registers the compiler environments.</p>
<p>We can see what environments are available using:</p>
<div><div><pre><span></span><span>&gt;&gt;&gt; </span><span>compiler_gym</span><span>.</span><span>COMPILER_GYM_ENVS</span>
<span>['llvm-v0', 'llvm-ic-v0', 'llvm-autophase-ic-v0', 'llvm-ir-ic-v0']</span>
</pre></div>
</div>
<div id="selecting-an-environment">
<h3><a href="#id7">Selecting an environment</a><a href="#selecting-an-environment" title="Permalink to this headline">¶</a></h3>
<p>CompilerGym environments are named using one of the following formats:</p>
<ol>
<li><p><code><span>&lt;compiler&gt;-&lt;observation&gt;-&lt;reward&gt;-&lt;version&gt;</span></code></p></li>
<li><p><code><span>&lt;compiler&gt;-&lt;reward&gt;-&lt;version&gt;</span></code></p></li>
<li><p><code><span>&lt;compiler&gt;-&lt;version&gt;</span></code></p></li>
</ol>
<p>Where <code><span>&lt;compiler&gt;</span></code> identifiers the compiler optimization task,
<code><span>&lt;observation&gt;</span></code> is the default type of observations that are provided,
and <code><span>&lt;reward&gt;</span></code> is the reward signal.</p>
<div>
<p>Note</p>
<p>A key concept is that
CompilerGym environments enables <strong>lazy evaluation</strong> of observations and
reward signals. This makes the environment much more computationally
efficient for scenarios in which you do not need to compute a reward or
observation for every step. If an environment omits a <code><span>&lt;observation&gt;</span></code>
or <code><span>&lt;reward&gt;</span></code> tag, this means that no observation or reward is
provided by default. See <a href="https://facebookresearch.github.io/CompilerGym/compiler_gym/views.html"><span>compiler_gym.views</span></a> for
further details.</p>
</div>
<p>For this tutorial, we will use the following environment:</p>
<ul>
<li><p><strong>Compiler</strong>: <a href="https://facebookresearch.github.io/CompilerGym/llvm/index.html"><span>LLVM</span></a>.</p></li>
<li><p><strong>Observation Type</strong>: <a href="https://facebookresearch.github.io/CompilerGym/llvm/index.html#autophase"><span>Autophase</span></a>.</p></li>
<li><p><strong>Reward Signal</strong>: <a href="https://facebookresearch.github.io/CompilerGym/llvm/index.html#codesize"><span>IR Instruction count relative to -Oz</span></a>.</p></li>
</ul>
<p>Create an instance of this environment using:</p>
<div><div><pre><span></span><span>&gt;&gt;&gt; </span><span>env</span> <span>=</span> <span>gym</span><span>.</span><span>make</span><span>(</span><span>"llvm-autophase-ic-v0"</span><span>)</span>
</pre></div>
</div>
</div>
<div id="installing-benchmarks">
<h3><a href="#id8">Installing benchmarks</a><a href="#installing-benchmarks" title="Permalink to this headline">¶</a></h3>
<p>A compiler requires a program as input. For the purposes of CompilerGym we call
these input programs <em>benchmarks</em>, and collections of benchmarks are assembled
into <em>datasets</em>. You may provide your own programs to use as benchmarks, or
download one of our pre-assembled datasets.</p>
<p>The benchmarks that are available to an environment can be queried using
<a href="https://facebookresearch.github.io/CompilerGym/compiler_gym/envs.html#compiler_gym.envs.CompilerEnv.benchmarks" title="compiler_gym.envs.CompilerEnv.benchmarks"><code><span>env.benchmarks</span></code></a>:</p>

<p>As you can see, there are no benchmarks installed by default. We have provided
a collection of pre-assembled
<a href="https://facebookresearch.github.io/CompilerGym/llvm/index.html#datasets"><span>LLVM benchmark datasets</span></a> that can be
installed using
<a href="https://facebookresearch.github.io/CompilerGym/compiler_gym/envs.html#compiler_gym.envs.CompilerEnv.require_dataset" title="compiler_gym.envs.CompilerEnv.require_dataset"><code><span>env.require_dataset()</span></code></a>.
For this tutorial we will use the
<a href="https://www.nas.nasa.gov/publications/npb.html">NAS Parallel Benchmarks</a>
dataset:</p>
<div><div><pre><span></span><span>&gt;&gt;&gt; </span><span>env</span><span>.</span><span>require_dataset</span><span>(</span><span>"npb-v0"</span><span>)</span>
</pre></div>
</div>
<p>Now, <a href="https://facebookresearch.github.io/CompilerGym/compiler_gym/envs.html#compiler_gym.envs.CompilerEnv.benchmarks" title="compiler_gym.envs.CompilerEnv.benchmarks"><code><span>env.benchmarks</span></code></a> lists
the 123 benchmarks that comprise the dataset we just installed:</p>
<div><div><pre><span></span><span>&gt;&gt;&gt; </span><span>env</span><span>.</span><span>benchmarks</span>
<span>['benchmark://npb-v0/46', 'benchmark://npb-v0/17', ...]</span>
</pre></div>
</div>
</div>
<div id="the-compiler-environment">
<h3><a href="#id9">The compiler environment</a><a href="#the-compiler-environment" title="Permalink to this headline">¶</a></h3>
<p>If you have experience using <a href="https://gym.openai.com/">OpenAI Gym</a>, the
CompilerGym environments will be familiar. If not, you can call <code><span>help()</span></code>
on any function, object, or method to query the documentation:</p>

<p>The action space is described by
<a href="https://facebookresearch.github.io/CompilerGym/compiler_gym/envs.html#compiler_gym.envs.CompilerEnv.action_space" title="compiler_gym.envs.CompilerEnv.action_space"><code><span>env.action_space</span></code></a>.
The <a href="https://facebookresearch.github.io/CompilerGym/llvm/index.html#action-space"><span>LLVM Action Space</span></a> is discrete:</p>
<div><div><pre><span></span><span>&gt;&gt;&gt; </span><span>env</span><span>.</span><span>action_space</span><span>.</span><span>dtype</span>
<span>dtype('int64')</span>
<span>&gt;&gt;&gt; </span><span>env</span><span>.</span><span>action_space</span><span>.</span><span>n</span>
<span>138</span>
</pre></div>
</div>
<p>The observation space is described by
<a href="https://facebookresearch.github.io/CompilerGym/compiler_gym/envs.html#compiler_gym.envs.CompilerEnv.observation_space" title="compiler_gym.envs.CompilerEnv.observation_space"><code><span>env.observation_space</span></code></a>.
The <a href="https://facebookresearch.github.io/CompilerGym/llvm/index.html#autophase"><span>Autophase</span></a> observation space is a 56-dimension
vector of integers:</p>
<div><div><pre><span></span><span>&gt;&gt;&gt; </span><span>env</span><span>.</span><span>observation_space</span><span>.</span><span>shape</span>
<span>(56,)</span>
<span>&gt;&gt;&gt; </span><span>env</span><span>.</span><span>observation_space</span><span>.</span><span>dtype</span>
<span>dtype('int64')</span>
</pre></div>
</div>
<p>The upper and lower bounds of the reward signal are described by
<code><span>env.reward_range</span></code>:</p>
<div><div><pre><span></span><span>&gt;&gt;&gt; </span><span>env</span><span>.</span><span>reward_range</span>
<span>(0.0, inf)</span>
</pre></div>
</div>
<p>As with other Gym environments,
<a href="https://facebookresearch.github.io/CompilerGym/compiler_gym/envs.html#compiler_gym.envs.CompilerEnv.reset" title="compiler_gym.envs.CompilerEnv.reset"><code><span>reset()</span></code></a>
must be called before a CompilerGym environment may be used:</p>
<div><div><pre><span></span><span>&gt;&gt;&gt; </span><span>env</span><span>.</span><span>reset</span><span>()</span>
<span>array([   0,    0,  399,  381,   10,  399,  147,    8,  137,  147,    0,</span>
<span>          0,    0,  556,    0,  546,    0,   15,  693,  574, 1214, 1180,</span>
<span>        384,  399,  214,    0,  120,  116,    0,   88,  468,    8,  546,</span>
<span>         16, 1073,  147,    0, 1551,    0,    0,    0,   10,  766,    0,</span>
<span>          0,  505,   46,    0,    0,    0,  556, 5075, 3261,   13,    0,</span>
<span>       2441])</span>
</pre></div>
</div>
<p>The numpy array that is returned here is the initial
<a href="https://facebookresearch.github.io/CompilerGym/llvm/index.html#autophase"><span>Autophase</span></a> observation. Calling
<a href="https://facebookresearch.github.io/CompilerGym/compiler_gym/envs.html#compiler_gym.envs.CompilerEnv.reset" title="compiler_gym.envs.CompilerEnv.reset"><code><span>env.reset()</span></code></a> starts an
instance of the compiler and selects a random benchmark to use. You can see
which benchmark is currently being used by an environment using
<a href="https://facebookresearch.github.io/CompilerGym/compiler_gym/envs.html#compiler_gym.envs.CompilerEnv.benchmark" title="compiler_gym.envs.CompilerEnv.benchmark"><code><span>env.benchmark</span></code></a>:</p>
<div><div><pre><span></span><span>&gt;&gt;&gt; </span><span>env</span><span>.</span><span>benchmark</span>
<span>'benchmark://npb-v0/90'</span>
</pre></div>
</div>
<p>If we want to force the environment to use a specific benchmark, we can pass the
name of the benchmark as an argument to
<a href="https://facebookresearch.github.io/CompilerGym/compiler_gym/envs.html#compiler_gym.envs.CompilerEnv.reset" title="compiler_gym.envs.CompilerEnv.reset"><code><span>env.reset()</span></code></a>:</p>
<div><div><pre><span></span><span>&gt;&gt;&gt; </span><span>env</span><span>.</span><span>reset</span><span>(</span><span>benchmark</span><span>=</span><span>"benchmark://npb-v0/50"</span><span>)</span>
<span>array([   0,    0,   26,   25,    1,   26,   10,    1,    8,   10,    0,</span>
<span>          0,    0,   37,    0,   36,    0,    2,   46,  175, 1664, 1212,</span>
<span>        263,   26,  193,    0,   59,    6,    0,    3,   32,    0,   36,</span>
<span>         10, 1058,   10,    0,  840,    0,    0,    0,    1,  416,    0,</span>
<span>          0,  148,   60,    0,    0,    0,   37, 3008, 2062,    9,    0,</span>
<span>       1262])</span>
</pre></div>
</div>
</div>
<div id="interacting-with-the-environment">
<h3><a href="#id10">Interacting with the environment</a><a href="#interacting-with-the-environment" title="Permalink to this headline">¶</a></h3>
<p>Once an environment has been initialized, you interact with it in the same way
that you would with any other <a href="https://gym.openai.com/">OpenAI Gym</a>
environment. <a href="https://facebookresearch.github.io/CompilerGym/compiler_gym/envs.html#compiler_gym.envs.LlvmEnv.render" title="compiler_gym.envs.LlvmEnv.render"><code><span>env.render()</span></code></a> prints
the Intermediate Representation (IR) of the program in the current state:</p>
<div><div><pre><span></span><span>&gt;&gt;&gt; </span><span>env</span><span>.</span><span>render</span><span>()</span>
<span>; ModuleID = 'benchmark://npb-v0/83'</span>
<span>target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"</span>
<span>target triple = "x86_64-pc-linux-gnu"</span>
<span>...</span>
</pre></div>
</div>
<p><a href="https://facebookresearch.github.io/CompilerGym/compiler_gym/envs.html#compiler_gym.envs.CompilerEnv.step" title="compiler_gym.envs.CompilerEnv.step"><code><span>env.step()</span></code></a> runs an action:</p>
<div><div><pre><span></span><span>&gt;&gt;&gt; </span><span>observation</span><span>,</span> <span>reward</span><span>,</span> <span>done</span><span>,</span> <span>info</span> <span>=</span> <span>env</span><span>.</span><span>step</span><span>(</span><span>0</span><span>)</span>
</pre></div>
</div>
<p>This returns four values: a new observation, a reward, a boolean value
indicating whether the episode has ended, and a dictionary of additional
information:</p>
<div><div><pre><span></span><span>&gt;&gt;&gt; </span><span>observation</span>
<span>array([   0,    0,   26,   25,    1,   26,   10,    1,    8,   10,    0,</span>
<span>          0,    0,   37,    0,   36,    0,    2,   46,  175, 1664, 1212,</span>
<span>        263,   26,  193,    0,   59,    6,    0,    3,   32,    0,   36,</span>
<span>         10, 1058,   10,    0,  840,    0,    0,    0,    1,  416,    0,</span>
<span>          0,  148,   60,    0,    0,    0,   37, 3008, 2062,    9,    0,</span>
<span>       1262])</span>
<span>&gt;&gt;&gt; </span><span>reward</span>
<span>0.3151595744680851</span>
<span>&gt;&gt;&gt; </span><span>done</span>
<span>False</span>
<span>&gt;&gt;&gt; </span><span>info</span>
<span>{'action_had_no_effect': True, 'new_action_space': False}</span>
</pre></div>
</div>
<p>For this environment, reward represents the reduction in code size of the
previous action, scaled to the total codesize reduction achieved with LLVM’s
<code><span>-Oz</span></code> optimizations enabled. A cumulative reward greater than one means
that the sequence of optimizations performed yields better results than LLVM’s
default optimizations. Let’s run 100 random actions and see how close we can
get:</p>
<div><div><pre><span></span><span>&gt;&gt;&gt; </span><span>env</span><span>.</span><span>reset</span><span>(</span><span>benchmark</span><span>=</span><span>"benchmark://npb-v0/50"</span><span>)</span>
<span>&gt;&gt;&gt; </span><span>episode_reward</span> <span>=</span> <span>0</span>
<span>&gt;&gt;&gt; </span><span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>1</span><span>,</span> <span>101</span><span>):</span>
<span>... </span>    <span>observation</span><span>,</span> <span>reward</span><span>,</span> <span>done</span><span>,</span> <span>info</span> <span>=</span> <span>env</span><span>.</span><span>step</span><span>(</span><span>env</span><span>.</span><span>action_space</span><span>.</span><span>sample</span><span>())</span>
<span>... </span>    <span>if</span> <span>done</span><span>:</span>
<span>... </span>        <span>break</span>
<span>... </span>    <span>episode_reward</span> <span>+=</span> <span>reward</span>
<span>... </span>    <span>print</span><span>(</span><span>f</span><span>"Step </span><span>{</span><span>i</span><span>}</span><span>, quality=</span><span>{</span><span>episode_reward</span><span>:</span><span>.3%</span><span>}</span><span>"</span><span>)</span>
<span>...</span>
<span>Step 1, quality=44.299%</span>
<span>Step 2, quality=44.299%</span>
<span>Step 3, quality=44.299%</span>
<span>Step 4, quality=44.299%</span>
<span>Step 5, quality=44.299%</span>
<span>Step 6, quality=54.671%</span>
<span>Step 7, quality=54.671%</span>
<span>Step 8, quality=54.608%</span>
<span>Step 9, quality=54.608%</span>
<span>Step 10, quality=54.608%</span>
<span>Step 11, quality=54.608%</span>
<span>Step 12, quality=54.766%</span>
<span>Step 13, quality=54.766%</span>
<span>Step 14, quality=53.650%</span>
<span>Step 15, quality=53.650%</span>
<span>...</span>
<span>Step 97, quality=88.104%</span>
<span>Step 98, quality=88.104%</span>
<span>Step 99, quality=88.104%</span>
<span>Step 100, quality=88.104%</span>
</pre></div>
</div>
<p>Not bad, but clearly there is room for improvement! Because at each step we are
taking random actions, your results will differ with every run. Try running it
again. Was the result better or worse? Of …</p></div></div></div></div></div></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://facebookresearch.github.io/CompilerGym/getting_started.html">https://facebookresearch.github.io/CompilerGym/getting_started.html</a></em></p>]]>
            </description>
            <link>https://facebookresearch.github.io/CompilerGym/getting_started.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26001480</guid>
            <pubDate>Tue, 02 Feb 2021 14:43:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Microsoft Aims to Revive Deceased Loved Ones as AI Chatbots with Its New Patent]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26001445">thread link</a>) | @conse_lad
<br/>
February 2, 2021 | https://scienceswitch.com/2021/02/02/microsoft-patent-aims-to-revive-dead-people-as-ai-chatbots/ | <a href="https://web.archive.org/web/*/https://scienceswitch.com/2021/02/02/microsoft-patent-aims-to-revive-dead-people-as-ai-chatbots/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

					
						<div>

							<p><span>In what can be considered as the next step in the human quest for immortality, tech behemoth Microsoft has reportedly signed a patent titled “Creating a Conversational Chatbot of a Specific Person.”</span></p>
<p><span>The patent grants the company to develop an Artificial Intelligence (AI) chatbot that aims to emulate voices of the deceased loved ones.&nbsp;</span></p>
<p><span>The creation of chatbot would rely on the personal information of a deceased person. </span></p>
<p><span>Social data, such as “images, voice data, social media posts, electronic messages, written letters, etc.” may also be accessed so that the AI could create an index that reflects the personality of the person being simulated.</span></p>
<figure data-shortcode="caption" id="attachment_39738" aria-describedby="caption-attachment-39738"><img data-attachment-id="39738" data-permalink="https://scienceswitch.com/2021/02/02/microsoft-patent-aims-to-revive-dead-people-as-ai-chatbots/microsoft-aims-to-revive-deceased-loved-ones-as-ai-chatbots-with-its-newly-filed-patent/" data-orig-file="https://scienceswitch.files.wordpress.com/2021/02/microsoft-aims-to-revive-deceased-loved-ones-as-ai-chatbots-with-its-newly-filed-patent.jpg" data-orig-size="1920,875" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Microsoft Aims To Revive Deceased Loved Ones As AI Chatbots With Its Newly Filed Patent" data-image-description="" data-medium-file="https://scienceswitch.files.wordpress.com/2021/02/microsoft-aims-to-revive-deceased-loved-ones-as-ai-chatbots-with-its-newly-filed-patent.jpg?w=300" data-large-file="https://scienceswitch.files.wordpress.com/2021/02/microsoft-aims-to-revive-deceased-loved-ones-as-ai-chatbots-with-its-newly-filed-patent.jpg?w=616" title="Microsoft has filed a patent that grants the company to create digital alternatives of deceased loved ones. The patent also includes the notion of generating 2D or 3D models of specific people. [The image being presented is purely decorative]" src="https://scienceswitch.files.wordpress.com/2021/02/microsoft-aims-to-revive-deceased-loved-ones-as-ai-chatbots-with-its-newly-filed-patent.jpg?w=616" alt="" srcset="https://scienceswitch.files.wordpress.com/2021/02/microsoft-aims-to-revive-deceased-loved-ones-as-ai-chatbots-with-its-newly-filed-patent.jpg?w=616 616w, https://scienceswitch.files.wordpress.com/2021/02/microsoft-aims-to-revive-deceased-loved-ones-as-ai-chatbots-with-its-newly-filed-patent.jpg?w=1232 1232w, https://scienceswitch.files.wordpress.com/2021/02/microsoft-aims-to-revive-deceased-loved-ones-as-ai-chatbots-with-its-newly-filed-patent.jpg?w=150 150w, https://scienceswitch.files.wordpress.com/2021/02/microsoft-aims-to-revive-deceased-loved-ones-as-ai-chatbots-with-its-newly-filed-patent.jpg?w=300 300w, https://scienceswitch.files.wordpress.com/2021/02/microsoft-aims-to-revive-deceased-loved-ones-as-ai-chatbots-with-its-newly-filed-patent.jpg?w=768 768w, https://scienceswitch.files.wordpress.com/2021/02/microsoft-aims-to-revive-deceased-loved-ones-as-ai-chatbots-with-its-newly-filed-patent.jpg?w=1024 1024w" sizes="(max-width: 616px) 100vw, 616px"><figcaption id="caption-attachment-39738">Microsoft has filed a patent that grants the company to create digital alternatives of deceased loved ones. The patent also includes the notion of generating 2D or 3D models of specific people. [The image being presented is purely decorative]</figcaption></figure><p><span>“The specific person [who the chatbot represents] may correspond to a past or present entity (or a version thereof), such as a friend, a relative, an acquaintance, a celebrity, a fictional character, a historical figure, a random entity etc,” <a href="https://pdfpiw.uspto.gov/.piw?PageNum=0&amp;docid=10853717&amp;IDKey=6E72242A6301&amp;HomeUrl=http%3A%2F%2Fpatft.uspto.gov%2Fnetacgi%2Fnph-Parser%3FSect1%3DPTO2%2526Sect2%3DHITOFF%2526p%3D1%2526u%3D%25252Fnetahtml%25252FPTO%25252Fsearch-bool.html%2526r%3D31%2526f%3DG%2526l%3D50%2526co1%3DAND%2526d%3DPTXT%2526s1%3Dmicrosoft.ASNM.%2526OS%3DAN%2Fmicrosoft%2526RS%3DAN%2Fmicrosoft" target="_blank" rel="noopener">the patent reads</a>.</span></p>
<p><span>It further adds, “The specific person may also correspond to oneself (e.g., the user creating/training the chat bot, ” insinuating that living users could create and train their own version of AI chatbot to be a digital replacement after they’re gone.&nbsp;</span></p>
<p><span>The company has even introduced the idea of generating 2D and 3D models based on images, depth information and video data associated with the specific person. And, interaction with these new digital alternatives may be activated through mobile devices or voice computing platforms.</span></p>
<p><span>The concept of simulating someone, who has passed, sounds something straight out of science fiction, and it’s certainly not a novelty.&nbsp; </span><span>If you have seen Netflix’s Black Mirror, its episode “Be Right Back” of Season 2 centers around the same exact premise, where a woman, whose recent death of her boyfriend had left her in great distress, seeks a service to bring an AI-powered chatbot version of her partner into her life.</span></p>
<p><span>Everyone has lost their dearly beloved, and at some point, wished they could have one last conversation with them. Microsoft maybe able to grant you something similar of that sort.&nbsp;</span></p>
<p>So how would you feel about having to have your dearly-departed loved one(s) immortalized?</p>
<p>Source: <a href="https://pdfpiw.uspto.gov/.piw?PageNum=0&amp;docid=10853717&amp;IDKey=6E72242A6301&amp;HomeUrl=%2F" target="_blank" rel="noopener">United States Patent and Trademark Office</a></p>
			
			
			
							
						</div>

					
					

				</div></div>]]>
            </description>
            <link>https://scienceswitch.com/2021/02/02/microsoft-patent-aims-to-revive-dead-people-as-ai-chatbots/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26001445</guid>
            <pubDate>Tue, 02 Feb 2021 14:41:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Searching for dark matter through the fifth dimension]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26001405">thread link</a>) | @conse_lad
<br/>
February 2, 2021 | https://www.uni-mainz.de/presse/aktuell/13053_ENG_HTML.php | <a href="https://web.archive.org/web/*/https://www.uni-mainz.de/presse/aktuell/13053_ENG_HTML.php">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
            <!-- Hier kommen Imagescroller und ZGN, sowie... -->
            <!-- Offene Universität Scroller --><!-- Default Row -->
            <!-- Spaltenlayout gemäß Einstellungen für option_schalter_linke_spalte, option_schalter_rechte_spalte -->
            <!-- Ende linke Spalte -->
            <article id="spaltemitte">
               <!-- Beginn Inhalt Spalte Mitte -->
               <!-- Indexüberschrift:  -->
               <h3>
                  A discovery in theoretical physics could help to unravel the mysteries of dark matter
               </h3>
               <p>
                  1 February 2021
               </p>
               <p>
                  Theoretical physicists of the PRISMA<sup>+</sup>&nbsp;Cluster of Excellence at Johannes Gutenberg University Mainz (JGU) are working on a theory that goes beyond the Standard Model of particle physics and can answer questions where the Standard Model has to pass – for example, with respect to the hierarchies of the masses of elementary particles or the existence of dark matter. The central element of the theory is an extra dimension in spacetime. Until now, scientists have faced the problem that the predictions of their theory could not be tested experimentally. They have now overcome this problem in a publication in the current issue of the <em>European Physical Journal C</em>.
               </p>
               <p>
                  Already in the 1920s, in an attempt to unify the forces of gravity and electromagnetism, Theodor Kaluza and Oskar Klein speculated about the existence of an extra dimension beyond the familiar three space dimensions and time – which in physics are combined into 4-dimensional spacetime. If it exists, such a new dimension would have to be incredible tiny and unnoticeable to the human eye. In the late 1990s, this idea has seen a remarkable renaissance&nbsp;when it was realized that the existence of a fifth dimension could resolve some of the profound open questions of particle physics. In particular, Yuval Grossman of Stanford University and Matthias Neubert, then a professor at Cornell University in the US, showed in a highly cited publication that the embedding of the Standard Model of particle physics in a 5-dimensional spacetime could explain the so far mysterious patterns seen in the masses of elementary particles.
               </p>
               <p>
                  Another 20 years later, the group of Professor Matthias Neubert – since 2006 on the faculty of Johannes Gutenberg University Mainz and spokesperson of the PRISMA<sup>+</sup> Cluster of Excellence – made another unexpected discovery: they found that the 5-dimensional field equations predicted the existence of a new&nbsp;heavy particle with similar properties as the famous Higgs boson but a much heavier mass – so heavy, in fact, that it cannot be produced even at the highest-energy particle collider in the world,&nbsp;the Large Hadron Collider (LHC) at the European Center for Nuclear Research CERN near Geneva in Switzerland. "It was a nightmare,"&nbsp;recalled&nbsp;Javier Castellano Ruiz, a PhD student involved in the research.&nbsp;"We were excited by the idea that our theory predicts a new particle, but it appeared to be impossible to confirm this prediction in any foreseeable experiment."
               </p>
               <h4>
                  The detour through the fifth dimension
               </h4>
               <p>
                  In a recent paper published in the <em>European Physical Journal C</em>, the researchers found a spectacular resolution to this dilemma. They discovered that their proposed particle would necessarily mediate a new force between the known elementary particles of our visible universe&nbsp;and the mysterious dark matter, the dark sector. Even the abundance of dark matter in the cosmos, as observed in astrophysical experiments, can be explained by their theory. This offers exciting new ways to search for the constituents of the dark matter – literally via a detour through the extra dimension – and obtain clues about the physics at a very early stage in the history of our universe, when dark matter was produced. "After years of searching for possible confirmations of our theoretical predictions, we are now confident that the mechanism we have discovered would make dark matter accessible to forthcoming experiments, because the properties of the new interaction between ordinary matter and dark matter – which is mediated by our proposed particle – can be calculated accurately within our theory,"&nbsp;said Professor Matthias Neubert, head of the research team. "In the end – so our hope – the new particle may be discovered first through its interactions with the dark sector."&nbsp;This example nicely illustrates the fruitful interplay between experimental and theoretical basic science – a hallmark of the PRISMA<sup>+</sup> Cluster of Excellence.
               </p><!-- Ende Inhalt Spalte Mitte -->
            </article>            <!--Ende-->
                     </div></div>]]>
            </description>
            <link>https://www.uni-mainz.de/presse/aktuell/13053_ENG_HTML.php</link>
            <guid isPermaLink="false">hacker-news-small-sites-26001405</guid>
            <pubDate>Tue, 02 Feb 2021 14:38:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Clerics are moving to YouTube in Turkey, and the government is watching]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26001392">thread link</a>) | @RealDeinonychus
<br/>
February 2, 2021 | https://restofworld.org/2021/the-cleric-has-uploaded-a-new-video/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2021/the-cleric-has-uploaded-a-new-video/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

			<!-- Article Start -->
			
<p><span>A</span>n Islamic<em> sohbet</em> is a little like a jazz gig, and its current master in Turkey is an imam named Ahmet in Cassocks. The Arabic-rooted word means “conversation,” but for Sufis, a sohbet consists of a lonely cleric sitting behind a lectern, pontificating, often for hours, before an audience that listens in reverent silence. Ahmet in Cassocks, the John Coltrane of sohbet sessions, has no problem captivating his 856,000 YouTube followers with his free-spirited, experimental rants that consider practical concerns of modernity through the ancient teachings of Islam. In a throaty voice that occasionally betrays a hint of sarcasm, he invokes the Quran<em> </em>and the hadith, a collection of Prophet Mohammad’s sayings and anecdotes. With his lustrous silver beard and wooden walking stick, Ahmet cuts a distinctive figure as he explodes the internet.</p>



<p>Ahmet’s sohbets, streamed online <a href="https://www.youtube.com/playlist?list=PL1HL4WPXNP1XovsUGrd771__CBqYuj2sy">every Thursday</a>, have attracted more than <a href="https://www.youtube.com/c/CubbeliAhmetHoca/about">200 million views</a> since he launched his YouTube channel in 2013. One might engage with Darwin’s theories; another will touch on the war between Armenia and Azerbaijan. His most popular sohbet, <a href="https://www.youtube.com/watch?v=vHJ5BtnekwY&amp;t=5s">watched 3.8 million times</a>, lasts just six minutes<em> </em>and ponders the religious implications of oral sex. In other videos, he recommends masturbation as a method to avoid the temptations of rape and questions whether handling a smartphone in the bathroom is religiously acceptable. (He claims that it is, as long as the user is reading <em>Ensonhaber</em>, a Turkish pro-government news site.) But most of his lectures are more subdued. In a recent three-hour sohbet, Ahmet riffed on inheritance law, trending topics on Twitter, and the financial strains Muslims face in the wake of the coronavirus pandemic. All are free to view, though, in 2020, he tested a membership scheme: for roughly $4 a month (30 liras), <a href="https://www.youtube.com/channel/UC3QqKQIjA_MSjWnTpyByeGA/join">subscribers</a> to his YouTube channel received early access to new material and <a href="https://www.youtube.com/post/UgwScBj5DLCaBmpH9nx4AaABCQ">had emojis of Islamic flags</a> attached to their usernames.</p>



<p>As a leading spokesperson of Naqshbandi, one of the oldest and most powerful Islamic orders in history, Ahmet in Cassocks wields immense power. There are 30 main branches of Sufism active in Turkey today — Naqshbandi is one of them — and 400 sub-branches, including the community that Ahmet belongs to. In total, these branches, or tariqas, are believed to have 10 million followers, including the 8 million that Naqshbandi claims. Like the American evangelical pastor Rick Warren or the German guru Eckhart Tolle, these Sufi clerics devote their lives to authoring books, delivering speeches, and, if they’re truly successful, shaping public conversation. Islamic sects led by charismatic sheikhs and their appointed spokespersons have existed in Turkey, India, and Pakistan since at least the 12th century, but thanks to the internet and more recently the restrictions imposed by Covid-19, they have been enjoying a revival. To a global Muslim audience yearning for content and community, YouTube clerics offer the best of both worlds: spiritual wisdom enjoyed from the safety of one’s living room.</p>



<p>Turkish authorities have for centuries had a complicated relationship with Sufi clerics. In 1925, Mustafa Kemal Atatürk, founder of modern Turkey, announced a wholesale ban on Sufi sects, as their sites of worship had earned a reputation for being “brothels and wine houses,” in the words of one prominent sheikh. This attitude changed after a conservative opposition party came to power in 1950, and since then, Turkish leaders have not only been sympathetic to tariqas but often are quiet believers. The current health minister, for instance, is reportedly aligned with the İskenderpaşa order, and President Recep Tayyip Erdoğan is close to several Naqshbandi sheikhs. While the Turkish government will aggressively go after anybody it perceives to be an enemy, including academics and journalists, perhaps because of these ties, clerics have largely been spared.</p>



<p>This winter, religious-themed streaming content grew rapidly as Covid-19 raced around the world and restrictions on in-person gatherings became the norm. For some anxious Turks faith became a savior. In one national poll conducted last June by Istanbul’s İbn Haldun University, 86 percent of 3,070 interviewees reported using prayer and worship to deal with the fear, anxiety and stress brought about by the coronavirus. While Turks are about as religious as they have been for years, there are more opportunities to engage with religion than ever before. In part because of new technologies, “religion is more integrated into daily life,” Ismihan Simsek, a media commentator and author of&nbsp;<em>Popstar Islamic Preachers</em>, told me. She cited a study by Erciyes University which demonstrated that the internet has become a primary source of religious information, alongside books and family.</p>



<figure><p>
<iframe data-src="https://www.youtube.com/embed/YqsdYYJ6e2k?feature=oembed" title="Telefonu Elimden Düşürmüyorum, Millet de Telefon Düşkünü Sanıyor Oysa Sebebi Başka" width="640" height="360" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p><figcaption>Ahmet in Cassocks’s sohbets have attracted more than 200 million views since he launched his YouTube channel in 2013.</figcaption></figure>



<p>Ekrem Süle, a medical supply salesman, is a 32-year-old follower of Ahmet. What he admires in the cleric is “his way of telling stories, his diction,” and the breadth of his knowledge about Islam. Süle stresses that Ahmet is <em>ehl-i sünnet</em>,<em> </em>an Islamic term that means someone belongs to a community that embraces a spiritual path. Harun Boyacı, another follower, has been enjoying Ahmet’s talks for the past 25 years. “His oratory is so beautiful and impressive,” he says, adding that his relationship with Islam has been “very much strengthened,” thanks to Ahmet’s talks. Cevahir Topaloğlu, a 19-year-old journalist who works as an editor at a local newspaper in the Black Sea city of Rize shared similar feelings but noted that he only allows himself to watch the cleric’s videos on his phone at night. “If we use our gadgets all day long for viewing sohbets, they’ll of course create addiction. We have to schedule our use,” says Topaloğlu, who said that his life changed after he began following Ahmet.</p>



<p>On social media, debate about Islam is dominated by about a dozen well-known clerics. They create trending topics through public arguments and controversies — Ahmet has accused fellow clerics of sacrilege and been called <a href="https://www.indyturk.com/node/258931/alparslan-kuytul-c%25252525C3%25252525BCbbeli%25252525E2%2525252580%2525252599nin-kitaplar%25252525C4%25252525B1n%25252525C4%25252525B1-basmak-satmak-ve-ilmi-ara%25252525C5%252525259Ft%25252525C4%25252525B1rma-maksad%25252525C4%25252525B1-d%25252525C4%25252525B1%25252525C5%252525259F%25252525C4%25252525B1nda">an informant for the Turkish government</a> — and play off each other’s successes and failures to win new followers. After spending decades traveling to remote Anatolian towns to deliver sohbets, Ahmet has seen social media prove an especially efficient way to grow his audience. The hours-long format of the traditional sohbet<em> </em>has given way to snippets that can go viral on Twitter or on Instagram, and like all savvy modern-day preachers, he tailors his speeches to better fit those platforms. Covid-19 also pushed him to scale up. His organization now releases between 20 and 25 new programs a week — up from three or four — and produces live sermons for broadcast. Ahmet and the community’s leaders have “a very direct relationship” with the IT department, observed <a href="https://www.xing.com/profile/AytugHalil_Akar">Aytuğ Halil Akar</a>, a ’90s-era-coder-turned-pious-Muslim who oversees production.</p>



<p>The growing influence of these independent clerics has not gone unnoticed by the country’s leaders, who have a track record of censoring tech platforms for hosting content they disapprove of. Turkey banned YouTube in 2007 for a video that “insulted Turkishness,” again in 2014 for secretly taped recordings of government officials, in 2015 for videos depicting the assassination of a Turkish state prosecutor, and in 2016 for ISIS-produced execution videos of Turkish soldiers. In addition, authorities temporarily banned <a href="https://www.bbc.com/news/technology-12639279">Blogspot and Blogger and shut down</a> Twitter for two weeks, after the last refused to remove tweets alleging government corruption. According to Turkey’s Freedom of Expression Association, in 2019 alone, <a href="https://bianet.org/english/media/226856-report-turkey-banned-130-000-web-addresses-in-2019">the government banned 130,000 web addresses</a>, 7,000 Twitter accounts, 6,251 Facebook posts, and over 10,000 YouTube videos. A study published in 2020 found that Turkey ranks third on the list of countries with the most VPN users. Finally, just last winter, the government began enforcing legislation mandating that foreign social media platforms appoint representatives in Turkey to execute removal requests. If the companies failed to comply, they would be fined, and their bandwidth for Turkish traffic would be slowed by 90%. After being forced to pay about $5.4 million (40 million liras), YouTube gave in. On January 8, TikTok — where impersonations of Ahmet are a popular pastime — followed suit, as did Facebook shortly thereafter.&nbsp;</p>



<p>Digital clerics are beginning to come under similar scrutiny — including Ahmet in Cassocks. Wary of his popularity, Erdoğan has made clear that he can pull the plug on the preacher any time he likes; while Ahmet, who openly supports Erdoğan, has boasted that his sohbet sessions 25 years ago may have helped raise the autocrat to power — and hinted that his new ones could do the opposite, if he so desired. Last year, in a show of force, Erdoğan <a href="https://www.hurriyet.com.tr/gundem/son-dakika-cubbeli-ahmet-ifadeye-cagrildi-selefi-dernekleri-silahlaniyor-iddiasi-41617783">ordered Ahmet to police headquarters for questioning</a>. Yet even in this climate, digital sohbets remain a popular way to speak out about sensitive issues. Since taking office in 2002, Turkey’s ruling AKP, the party of Erdoğan, has promised to create a “New Turkey” — a country in which religious freedom would be prioritized in the name of democracy. Internet clerics serve this Islam-friendly agenda, but they pose their own problems. Among the legions of YouTube sheikhs fawning over the government, there are also those subjecting it to thoughtful scrutiny on Twitter. And now, as more and more would-be clerics and followers have come of age in this new Turkey, they are joining a flourishing ecosystem that won’t easily be contained by authorities in Ankara.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/NT-TurkeyDigitalClerics34_-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/NT-TurkeyDigitalClerics34_-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/NT-TurkeyDigitalClerics34_-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/02/NT-TurkeyDigitalClerics34_-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2021/02/NT-TurkeyDigitalClerics34_-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/02/NT-TurkeyDigitalClerics34_-1600x1068.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/02/NT-TurkeyDigitalClerics34_-2800x1869.jpg 2800w, " sizes="(max-width: 640px) 100vw, calc(100vw - 40px)" alt="Erdoğan’s AKP party has courted Islamists through promises of prioritizing religious freedom. In 2020, his administration converted the Hagia Sophia, a former UNESCO World Heritage site, back into a functioning mosque.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder"><a href="http://www.nicoletung.com/" target="_blank" rel="noopener noreferrer">Photography by Nicole Tung for Rest of World</a></span>
			</figcaption>
		</figure>


<hr>



<p><strong>Alparslan Kuytul is</strong> an internet-famous preacher known for his passionate speeches, bold political statements, and suave good looks. On <a href="https://www.youtube.com/channel/UCo-PFV0pYzYoxDfg9JIiriQ">his YouTube channel</a>, which has gotten more than 14 million …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://restofworld.org/2021/the-cleric-has-uploaded-a-new-video/">https://restofworld.org/2021/the-cleric-has-uploaded-a-new-video/</a></em></p>]]>
            </description>
            <link>https://restofworld.org/2021/the-cleric-has-uploaded-a-new-video/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26001392</guid>
            <pubDate>Tue, 02 Feb 2021 14:37:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elastic License v2, simplified and more permissive]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26001297">thread link</a>) | @dhd415
<br/>
February 2, 2021 | https://www.elastic.co/blog/elastic-license-v2 | <a href="https://web.archive.org/web/*/https://www.elastic.co/blog/elastic-license-v2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="__next"><div><div><div><section><div><div><div><div><div><p>When we announced our license change for Elasticsearch and Kibana, moving the Apache 2.0-licensed source code to be dual licensed under both the Elastic License and SSPL, we also <a href="https://www.elastic.co/blog/license-change-clarification">mentioned</a> we would work closely with the community on a simplified and more permissive version of the Elastic License. I am happy to share the results with you.</p><p>The Elastic License is already widely used. More than 90% of our downloads are under the Elastic License, and those users enjoy the significant additional <a href="https://www.elastic.co/subscriptions">value provided</a> under the free and open Basic tier. Thanks to this value, the majority of our users and community are already using the software under the Elastic License, so they viewed our recent license change as a non-event. We are happy to see it, because our intent is to minimize any disruption to our community.</p><p>We took this opportunity to engage with our community and find ways to further simplify the Elastic License. After talking to users who reached out for clarification, we believe this new version will help to significantly address the majority of your&nbsp;concerns while protecting our products from <a href="https://twitter.com/kimchy/status/1351534442993446917">abuse, misinformation, and confusion</a>.
</p></div><h2>Elastic License v2
</h2><p>The <a href="https://www.elastic.co/licensing/elastic-license">Elastic License v2 (ELv2)</a> is a very simple, non-copyleft license, allowing for the right to "use, copy, distribute, make available, and prepare derivative works of the software” and has only three high-level limitations. You cannot:
</p><ol><li>Provide the products to others as a managed service&nbsp;</li><li>Circumvent the license key functionality or remove/obscure features protected by license keys&nbsp;</li><li>Remove or obscure any licensing, copyright, or other notices</li></ol><p>ELv2 applies to all of Elasticsearch and Kibana. It covers the distribution as well as the source code of all free and paid features.<br></p><p>We share our source code for both free and paid features in the spirit of openness. Unfortunately, our <a href="https://www.elastic.co/blog/dear-search-guard-users-including-amazon-elasticsearch-service-open-distro-and-others">copyrights</a> and <a href="https://twitter.com/kimchy/status/1351534442993446917">trademarks</a> have been abused and misused. Our goal with this updated license is to be as permissive as possible while including a minimum set of protections. I hope these protections make sense. <a href="https://www.elastic.co/licensing/elastic-license/faq">See our FAQ</a> for more information about ELv2.
</p><div><p>We created ELv2 to hopefully allow others to adopt it. This is the license we wished was available in 2015 when we were a small company facing <a href="https://twitter.com/kimchy/status/1351534442993446917">misinformation</a>. It incorporates all of our learnings from our experience and others who have made similar changes (<a href="https://www.mongodb.com/blog/post/mongodb-now-released-under-the-server-side-public-license">MongoDB</a>, <a href="https://www.cockroachlabs.com/blog/oss-relicensing-cockroachdb/">CockroachDB</a>, <a href="https://redislabs.com/blog/redis-labs-modules-license-changes/">RedisLabs</a>, <a href="https://blog.timescale.com/blog/building-open-source-business-in-cloud-era-v2/">TimescaleDB</a>, <a href="https://www.graylog.org/post/graylog-v4-0-licensing-sspl">Graylog</a>, etc.). Hopefully we helped a little here. There are many companies out there facing a similar decision. I hope that over time, those of us with similar goals can coalesce around a smaller number of licenses and that ELv2 will be a catalyst for that.</p><p>In that spirit, we worked on ELv2 with <a href="https://heathermeeker.com/about-me/">Heather Meeker</a>, a lawyer who is well known for helping to draft many OSS licenses, including the Mozilla Public License 2.0, as well as helping a number of organizations build similar-in-spirit licenses like the <a href="https://www.confluent.io/confluent-community-license/">Confluent Community License</a>, <a href="https://www.mongodb.com/licensing/server-side-public-license/faq">SSPL</a>, and others. We are also reaching out to initiatives like the <a href="https://polyformproject.org/">Polyform Project</a> and <a href="https://faircode.io/">Fair-code</a> as additional efforts to raise awareness of this license and look for ways to promote its wider use.&nbsp;
</p></div><h2>SSPL remains an option for the source code
</h2><div><p>We added <a href="https://www.mongodb.com/licensing/server-side-public-license">SSPL</a>, which is a copyleft license created by <a href="https://www.mongodb.com/blog/post/mongodb-now-released-under-the-server-side-public-license">MongoDB</a>, as an option to minimize the effect this license change would have on our users. MongoDB is one of the most popular projects out there, used by millions of developers who are happy with SSPL. </p><p>Since we made this announcement, we had many of our users reach out and say that they are thankful we provided this option. Their organizations are already using MongoDB, and this made our license change a non-event for them.</p><p>The SSPL is a licensing option for the source code, as shown below:
</p></div><p><img src="https://images.contentstack.io/v3/assets/bltefdd0b53724fa2ce/bltd65944c1b54a1e0b/6018987f29a02c49ba1f3e4a/chart-license-update-2021.jpg"></p><p>And to be clear, we are <a href="https://writing.kemitchell.com/2021/01/20/Righteous-Expedient-Wrong.html">still</a> not claiming that either SSPL or the Elastic License are OSI-approved licenses.
</p><h2>Still no impact to our cloud and on-premises customers&nbsp;
</h2><p>It is important to repeat: there is no impact to any of our Elastic Cloud or self-managed customers. Our customers already use the default distribution under the Elastic License, and their use is governed by the terms of their subscription agreement, which continues to grant them access to additional features, access to support, and other Elastic commitments (for example, IP infringement indemnification) as before.
</p><h2>The path forward
</h2><p>These changes, including making the Elastic License more permissive, are intended to help us focus on building great products and investing in our community. This means building more great features, many of which we will provide for free and which will be developed in the open. But our commitment goes beyond the code. These license changes let us focus on what matters: helping you find success with our products.
</p></div></div></div></div></section></div></div></div></div></div>]]>
            </description>
            <link>https://www.elastic.co/blog/elastic-license-v2</link>
            <guid isPermaLink="false">hacker-news-small-sites-26001297</guid>
            <pubDate>Tue, 02 Feb 2021 14:30:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Should I be wearing two masks?]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 42 (<a href="https://news.ycombinator.com/item?id=26001277">thread link</a>) | @fortran77
<br/>
February 2, 2021 | https://www.macleans.ca/news/should-i-be-wearing-two-masks/ | <a href="https://web.archive.org/web/*/https://www.macleans.ca/news/should-i-be-wearing-two-masks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>With the arrival of new, more contagious variants of COVID-19 in Canada, experts are recommending an upgrade in the quality—and quantity—of our face coverings</p><div>
																		<p><span>Look at photos of </span><a href="https://www.huffingtonpost.ca/entry/double-mask-coronavirus_ca_60140605c5b653f644d2ed5b?ncid=tweetlnkcahpmg00000002"><span>President Joe Biden and you’ll notice he often wears two masks</span></a><span>: a light cloth or paper one over a heavy-duty N95 mask. “If you have a physical covering with one layer, you put another layer on,” </span><a href="https://www.cnbc.com/2021/01/25/dr-fauci-double-mask-during-covid-makes-common-sense-more-effective.html"><span>said Dr. Anthony Fauci</span></a><span>, who has also frequently </span><a href="https://twitter.com/MayorBowser/status/1341835973722734592?s=20"><span>worn two masks</span></a><span>. “It just makes common sense that it likely would be more effective.”&nbsp;</span></p>
<p><span>But there is also some urgency to this shift: With the arrival of new and more contagious variants to Canada, experts are asking everyone to think once again about the quality of our masks and how we use them. “We all need a bit of a reset regarding [COVID-19] precautions,” says Dr. Lynora Saxinger, </span><span>an infectious diseases physician in Edmonton. “We tend to cut corners and relax when something becomes commonplace.”&nbsp;</span></p>
<p><span>For one thing, she says,</span><span> don’t shove a mask into your pocket after wearing it; if you’re asymptomatic, then the virus will be easily transferred from the mask to your hands. For another, don’t be complacent regarding the type and quality of your face coverings, such as masks that are comfortable to wear because they use porous materials, or </span><a href="https://www.canada.ca/en/public-health/services/diseases/2019-novel-coronavirus-infection/prevention-risks/about-non-medical-masks-face-coverings.html#a9"><span>neck gaiters, which can easily slip</span></a><span>.&nbsp;</span></p>
<blockquote><p><strong>RELATED:&nbsp;<a href="https://www.macleans.ca/society/health/covid-19-in-canada-how-our-battle-against-the-second-wave-is-going/" target="_blank" rel="noopener">COVID-19 in Canada: How our battle against the second wave is going</a></strong></p></blockquote>
<p><span>In fact, many of the masks we’re using aren’t as good as they should be. And, unlike last spring when the initial guidance around masks included recommending face coverings of tightly woven fabric, the risk perception has now changed. The new variants are so much more effective at infecting people that it’s time for a refresher course in face protection.&nbsp;</span></p>
<p><a href="https://www.canada.ca/en/public-health/services/diseases/2019-novel-coronavirus-infection/prevention-risks/about-non-medical-masks-face-coverings.html"><span>Health Canada’s guidelines</span></a><span> emphasize that masks need proper structure, material and fit to reduce the spread of infectious respiratory droplets. For example, Saxinger uses a couple of well-fitted multi-layer fabric masks, each with added filters of polypropylene material which she bought separately, in addition to cycling through lightly-worn medical masks, which she stores in separate envelopes for a few days before using them. And now, unlike in the spring, medical-quality disposable masks as well as more tightly fitted KN95 masks are available through retailers</span> <span>including </span><a href="https://www.costco.ca/kn95-disposable-5-layer-face-mask%2C-20-pack.product.100672009.html"><span>Costco</span></a><span>, </span><a href="https://www.canadiansafetysupplies.com/Level-2-Hospital-Medical-3-Ply-Surgical-Masks-p/350117.htm?gclid=Cj0KCQiA6t6ABhDMARIsAONIYywfEhF1lBHDuf6XEc1nB9jQgZ_kni7_n69ikdQ7cCcEJJR2jNETNncaAti8EALw_wcB"><span>health care supply firms</span></a><span> and </span><a href="https://www.wellwise.ca/en-ca/products/total-care-kn95-mask"><span>pharmacies</span></a><span> (supplies can fluctuate; also, many of the disposable masks and KN95s on the market are not medical grade).&nbsp;</span></p>
<blockquote><p><strong>RELATED:&nbsp;<a href="https://www.macleans.ca/opinion/20000-canadians-have-died-of-covid-19-each-of-their-stories-teaches-us-about-life/" target="_blank" rel="noopener">20,000 Canadians have died of COVID-19. Each of their stories teaches us about life.</a></strong></p></blockquote>
<p><span>While there is no official Canadian or U.S. guidance regarding double-masking or the need to upgrade to better quality masks, </span><a href="https://www.npr.org/sections/coronavirus-live-updates/2021/01/26/960893423/some-european-countries-move-to-require-medical-grade-masks-in-public"><span>Germany, Austria and France</span></a><span> recently told their residents to upgrade their face coverings from cloth versions to specific medical-grade ones, including KN95s, when they are in public spaces, including stores, or when near others for a prolonged period.&nbsp;&nbsp;&nbsp;</span></p>
<p><span>“The more layers the better, as long as they are breathable,” says Saxinger. Doubling up with whatever masks you have—whether two cloth ones, or a cloth and a disposable one—can offer more protection, as they can provide another layer of filtration and force a tighter fit.&nbsp;</span></p>
<blockquote><p><strong>RELATED:&nbsp;<a href="https://www.macleans.ca/news/how-much-protection-does-the-first-dose-of-the-covid-19-vaccine-provide/" target="_blank" rel="noopener">How much protection does the first dose of the COVID-19 vaccine provide?</a></strong></p></blockquote>
<p><span>In a </span><a href="https://www.cell.com/med/pdf/S2666-6340(20)30072-6.pdf"><span>recent commentary in </span><i><span>Med</span></i></a><span>, two experts in the transmission of viruses gave two recommendations to the public: either wear a properly layered, fitted cloth mask or double up and “wear a cloth mask tightly on top of a surgical mask where the surgical mask acts as a filter and the cloth mask provides an additional layer of filtration while improving the fit.” </span></p>

				
			</div></div>]]>
            </description>
            <link>https://www.macleans.ca/news/should-i-be-wearing-two-masks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26001277</guid>
            <pubDate>Tue, 02 Feb 2021 14:28:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Enso 2.0 alpha (formerly Luna) twitch about using Java in a visual way is live]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26001239">thread link</a>) | @wdanilo
<br/>
February 2, 2021 | https://www.twitch.tv/enso_org | <a href="https://web.archive.org/web/*/https://www.twitch.tv/enso_org">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.twitch.tv/enso_org</link>
            <guid isPermaLink="false">hacker-news-small-sites-26001239</guid>
            <pubDate>Tue, 02 Feb 2021 14:24:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[IU Compilers Course (Lecture Videos & Notes): The Incremental Nano-Pass Approach]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26001237">thread link</a>) | @matt_d
<br/>
February 2, 2021 | https://iucompilercourse.github.io/IU-P423-P523-E313-E513-Fall-2020/ | <a href="https://web.archive.org/web/*/https://iucompilercourse.github.io/IU-P423-P523-E313-E513-Fall-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <header>
        
        
        

        <p>Web page for IU Compiler Course for Fall 2020</p>

        
        <p><a href="https://github.com/IUCompilerCourse/IU-P423-P523-E313-E513-Fall-2020">View the Project on GitHub <small>IUCompilerCourse/IU-P423-P523-E313-E513-Fall-2020</small></a></p>
        

        

        
      </header>
      <section>

      

<p>Indiana University, Fall 2020</p>

<p>High-level programming languages like Racket make it easier to program
relative to low-level languages such as x86 assembly code. But how do
high-level languages work? There’s a big gap between Racket and
machine instructions for modern computers. In this class you learn how
to translate Racket programs (a dialect of Scheme) all the way to x86
assembly language.</p>

<p>Traditionally, compiler courses teach one phase of the compiler at a
time, such as parsing, semantic analysis, and register allocation. The
problem with that approach is it is difficult to understand how the
whole compiler fits together and why each phase is designed the way it
is. Instead, each week we implement a successively larger subset of
the Racket language. The very first subset is a tiny language of
integer arithmetic, and by the time we are done the language includes
first-class functions.</p>

<p><strong>Prerequisites:</strong> B521 or C311. Fluency in Racket is highly recommended
as students will do a lot of programming in Racket. Prior knowledge of
an assembly language helps, but is not required.</p>

<p><strong>Textbook:</strong> The notes for the course are available
<a href="https://www.dropbox.com/s/ktdw8j0adcc44r0/book.pdf?dl=1">here</a>. If
you have suggestions for improvement, please either send an email to
Jeremy or, even better, make edits to a branch of the book and perform
a pull request. The book is at the following location on github:</p>

<div><div><pre><code>https://github.com/IUCompilerCourse/Essentials-of-Compilation
</code></pre></div></div>

<p><strong>Lecture:</strong> Tuesday and Thursday, 3:15pm to 4:30pm, on Zoom Meeting ID
  950 3713 8921. (See the Piazza announcement for the password.)</p>

<p><strong>Lecture Notes and Recordings:</strong></p>

<ul>
  <li>
    <p>August 25 <a href="https://iucompilercourse.github.io/IU-P423-P523-E313-E513-Fall-2020/lecture-Aug-25.html">Notes</a>, <a href="https://iu.mediaspace.kaltura.com/media/Compiler+Course/1_hwlujpzd">Video</a>: Introduction, Concrete and Abstract Syntax, Racket Structures, Grammars,</p>
  </li>
  <li>
    <p>August 27 <a href="https://iucompilercourse.github.io/IU-P423-P523-E313-E513-Fall-2020/lecture-Aug-27.html">Notes</a>, <a href="https://iu.mediaspace.kaltura.com/media/Compiler+Course%2C+August+27%2C+2020/0_pmzfbou3">Video</a>: Interpreters, Compiler Correctness, R1 Language, x86</p>
  </li>
  <li>
    <p>September 1 <a href="https://iucompilercourse.github.io/IU-P423-P523-E313-E513-Fall-2020/lecture-Sep-1.html">Notes</a>, <a href="https://iu.mediaspace.kaltura.com/media/Compiler+Course%2C+September+1%2C+2020/1_7o6702no">Video</a>: Uniquify, Remove Complex Operands, Explicate Control</p>
  </li>
  <li>
    <p>September 3 <a href="https://iucompilercourse.github.io/IU-P423-P523-E313-E513-Fall-2020/lecture-Sep-3.html">Notes</a>, <a href="https://iu.mediaspace.kaltura.com/media/Compiler+Course%2C+September+3%2C+2020/1_sqpe15y2">Video</a>: Select Instructions, Assign Homes, Path Instructions, Print x86</p>
  </li>
  <li>
    <p>September 8 <a href="https://iucompilercourse.github.io/IU-P423-P523-E313-E513-Fall-2020/lecture-Sep-8.html">Notes</a>, <a href="https://iu.mediaspace.kaltura.com/media/Compiler+Course/1_vizyqbn0">Video</a>: Code review of compiling integers and variables.</p>
  </li>
  <li>
    <p>September 10 <a href="https://iucompilercourse.github.io/IU-P423-P523-E313-E513-Fall-2020/lecture-Sep-10.html">Notes</a>, <a href="https://iu.mediaspace.kaltura.com/media/Compiler+Course%2C+September+10%2C+2020/1_gk7ace03">Video</a>: Register Allocation (Liveness Analysis, Build Interference Graph)</p>
  </li>
  <li>
    <p>September 15 <a href="https://iucompilercourse.github.io/IU-P423-P523-E313-E513-Fall-2020/lecture-Sep-15.html">Notes</a>, <a href="https://iu.mediaspace.kaltura.com/media/Compiler+Course/1_bhbvoxal">Video</a>: Register Allocation (Graph Coloring)</p>
  </li>
  <li>
    <p>September 17 <a href="https://iucompilercourse.github.io/IU-P423-P523-E313-E513-Fall-2020/lecture-Sep-17.html">Notes</a>, <a href="https://iu.mediaspace.kaltura.com/media/Compiler+Course%2C+September+17%2C+2020/1_ana9y0v2">Video</a>: Booleans and Control Flow</p>
  </li>
  <li>
    <p>September 22 <a href="https://iucompilercourse.github.io/IU-P423-P523-E313-E513-Fall-2020/lecture-Sep-22.html">Notes</a>, <a href="https://iu.mediaspace.kaltura.com/media/Compiler+Course%2C+September+22%2C+2020/1_edqiv033">Video</a>: Code review of register allocation.</p>
  </li>
  <li>
    <p>September 24 <a href="https://iucompilercourse.github.io/IU-P423-P523-E313-E513-Fall-2020/lecture-Sep-24.html">Notes</a>, <a href="https://iu.mediaspace.kaltura.com/media/Compiler+Course%2C+September+24%2C+2020/1_a3nbfe77">Video</a>: More x86, Explicate Control with Branching.</p>
  </li>
  <li>
    <p>September 29 <a href="https://iucompilercourse.github.io/IU-P423-P523-E313-E513-Fall-2020/lecture-Sep-29.html">Notes</a>, <a href="https://iu.mediaspace.kaltura.com/media/Compiler+Course%2C+September+29%2C+2020/1_n9c7bzm4">Video</a>: Impact of branching on instruction selection and register allocation. Challenge: optmizing and removing jumps.</p>
  </li>
  <li>
    <p>October 1 <a href="https://iucompilercourse.github.io/IU-P423-P523-E313-E513-Fall-2020/lecture-Oct-1.html">Notes</a>, <a href="https://iu.mediaspace.kaltura.com/media/Compiler+Course%2C+October+1%2C+2020/1_j9g6xli5">Video</a>: Garbage Collection: 2-space Copy Collector</p>
  </li>
  <li>
    <p>October 6 <a href="https://iucompilercourse.github.io/IU-P423-P523-E313-E513-Fall-2020/lecture-Oct-6.html">Notes</a>, <a href="https://iu.mediaspace.kaltura.com/media/Compiler+Course%2C+October+6%2C+2020/1_1yjdbvrg">Video</a>: Code review of booleans and control flow</p>
  </li>
  <li>
    <p>October 8 <a href="https://iucompilercourse.github.io/IU-P423-P523-E313-E513-Fall-2020/lecture-Oct-8.html">Notes</a>, <a href="https://iu.mediaspace.kaltura.com/media/Compiler+Course%2C+October+8%2C+2020/1_r8jzdnu3">Video</a>: Tuples and Garbage Collection: the Compiler Passes</p>
  </li>
  <li>
    <p>October 13 <a href="https://iucompilercourse.github.io/IU-P423-P523-E313-E513-Fall-2020/lecture-Oct-13.html">Notes</a>, <a href="https://iu.mediaspace.kaltura.com/media/Compiler+Course%2C+October+13%2C+2020/1_8nm19wcy">Video</a>: Functions and Efficient Tail Calls</p>
  </li>
  <li>
    <p>October 15 <a href="https://iucompilercourse.github.io/IU-P423-P523-E313-E513-Fall-2020/lecture-Oct-15.html">Notes</a>, <a href="https://iu.mediaspace.kaltura.com/media/Compiler+Course%2C+October+15%2C+2020/1_hy383s9a">Video</a>: Compiling Functions, the Passes</p>
  </li>
  <li>
    <p>October 20 <a href="https://iucompilercourse.github.io/IU-P423-P523-E313-E513-Fall-2020/lecture-Oct-20.html">Notes</a>, <a href="https://iu.mediaspace.kaltura.com/media/Compiler+Course%2C+October+20%2C+2020/1_k0t1wmat">Video</a>: Compiling Functions, Examples, Start of Lambda</p>
  </li>
  <li>
    <p>October 22 <a href="https://iucompilercourse.github.io/IU-P423-P523-E313-E513-Fall-2020/lecture-Oct-22.html">Notes</a>, <a href="https://iu.mediaspace.kaltura.com/media/Compiler+Course%2C+October+22%2C+2020/1_vlnmv3sj">Video</a>: Lambdas and Closure Conversion</p>
  </li>
  <li>
    <p>October 27 <a href="https://iucompilercourse.github.io/IU-P423-P523-E313-E513-Fall-2020/lecture-Oct-27.html">Notes</a>, <a href="https://iu.mediaspace.kaltura.com/media/Compiler+Course%2C+October+27%2C+2020/1_q6dmk6st">Video</a>: Code Review of Tuple &amp; Garbage Collection</p>
  </li>
  <li>
    <p>October 29 <a href="https://iucompilercourse.github.io/IU-P423-P523-E313-E513-Fall-2020/lecture-Oct-29.html">Notes</a>, <a href="https://iu.mediaspace.kaltura.com/media/Compiler+Course%2C+October+29%2C+2020/1_hm4ono61">Video</a>: Closure Conversion, The Compiler Pass</p>
  </li>
  <li>
    <p>November 3 <a href="https://iucompilercourse.github.io/IU-P423-P523-E313-E513-Fall-2020/lecture-Nov-3.html">Notes</a>, <a href="https://iu.mediaspace.kaltura.com/media/Compiler+Course%2C+November+3%2C+2020/1_pw8wgk8w">Video</a>: Dynamic Typing</p>
  </li>
  <li>
    <p>November 5 <a href="https://iucompilercourse.github.io/IU-P423-P523-E313-E513-Fall-2020/lecture-Nov-5.html">Notes</a>, <a href="https://iu.mediaspace.kaltura.com/media/Compiler+Course%2C+November+5%2C+2020/1_4jkvtqka">Video</a>: Dynamic Typing, continued</p>
  </li>
  <li>
    <p>November 10 <a href="https://iucompilercourse.github.io/IU-P423-P523-E313-E513-Fall-2020/lecture-Nov-10.html">Notes</a>, <a href="https://iu.mediaspace.kaltura.com/media/Compiler+Course%2C+November+10%2C+2020/1_zt4xgnmm">Video</a>: Code Review of Functions</p>
  </li>
  <li>
    <p>November 12 <a href="https://iucompilercourse.github.io/IU-P423-P523-E313-E513-Fall-2020/lecture-Nov-12.html">Notes</a>, <a href="https://iu.mediaspace.kaltura.com/media/Compiler+Course%2C+November+12%2C+2020/1_nj17t942">Video</a>: Optimizing Closures</p>
  </li>
  <li>
    <p>November 17 <a href="https://iucompilercourse.github.io/IU-P423-P523-E313-E513-Fall-2020/lecture-Nov-17.html">Notes</a>, <a href="https://iu.mediaspace.kaltura.com/media/Compiler+Course%2C+November+17%2C+2020/1_h0iqmju7">Video</a>: Dataflow Analysis</p>
  </li>
  <li>
    <p>November 19 <a href="https://iucompilercourse.github.io/IU-P423-P523-E313-E513-Fall-2020/lecture-Nov-19.html">Notes</a>, <a href="https://iu.mediaspace.kaltura.com/media/Compiler+Course%2C+November+19%2C+2020/1_42fqjvwz">Video</a>: Compiling Loops and Liveness Analysis via Dataflow</p>
  </li>
  <li>
    <p>December 1 <a href="https://iucompilercourse.github.io/IU-P423-P523-E313-E513-Fall-2020/lecture-Dec-1.html">Notes</a>, <a href="https://iu.mediaspace.kaltura.com/media/Compiler+Course%2C+December+1%2C+2020/1_n2dmgkw1">Video</a>: Assignment and Begin</p>
  </li>
  <li>
    <p>December 3: Review of Dynamic Typing (see notes for Nov. 3 and 5)</p>
  </li>
  <li>
    <p>December 8 <a href="https://iucompilercourse.github.io/IU-P423-P523-E313-E513-Fall-2020/lecture-Dec-8.md">Notes</a>, <a href="https://iu.mediaspace.kaltura.com/media/Compiler+Course%2C+December+8%2C+2020/1_71h0sbk8">Video</a>: Code Review of Compiling Lambda</p>
  </li>
  <li>
    <p>December 10 <a href="https://iucompilercourse.github.io/IU-P423-P523-E313-E513-Fall-2020/lecture-Dec-10.html">Notes</a>, <a href="https://iu.mediaspace.kaltura.com/media/Compiler+Course%2C+December+10%2C+2020/1_b08zavdn">Video</a>: Review of Compiling Functions</p>
  </li>
</ul>

<p><strong>Office hours</strong></p>

<ul>
  <li>
    <p>Jeremy Siek (jsiek): Tuesdays and Thursdays 4:30-5:30pm.
Zoom Meeting ID: 949 1594 8290.</p>
  </li>
  <li>
    <p>Caner Derici (cderici): Mondays 11am-12pm, Wednesdays 11am-12pm.
Zoom Meeting ID: 774 5516 2736.</p>
  </li>
</ul>

<p><strong>Topics:</strong></p>

<ul>
  <li>
    <p>Instruction Selection</p>
  </li>
  <li>
    <p>Register Allocation</p>
  </li>
  <li>
    <p>Static type checking</p>
  </li>
  <li>
    <p>Conditional control flow</p>
  </li>
  <li>
    <p>Mutable data</p>
  </li>
  <li>
    <p>Garbage collection</p>
  </li>
  <li>
    <p>Procedures and calling conventions</p>
  </li>
  <li>
    <p>First-class functions and closure conversion</p>
  </li>
  <li>
    <p>Dynamic typing</p>
  </li>
  <li>
    <p>Generics</p>
  </li>
  <li>
    <p>High-level optimization (inlining, constant folding, copy
propagation, etc.)</p>
  </li>
</ul>

<p><strong>Grading:</strong></p>

<p>Course grades are based on the following items. For the weighting, see
the Canvas panel on the right-hand side of this web page.  Grading
will take into account any technology problems that arrise, i.e., you
won’t fail the class because your internet went out.</p>

<ul>
  <li>Assignments</li>
  <li>Quizzes</li>
  <li>Midterm Exam (October 23, Online as a Canvas Quiz)</li>
  <li>Final Exam (December 15, Online as a Canvas Quiz)</li>
</ul>

<p><strong>Assignments:</strong></p>

<p>Organize into teams of 2-4 students. Assignments will be due bi-weekly
on Mondays at 11:59pm. Teams that include one or more graduate
students are required to complete the challenge exercises.</p>

<p>Assignment descriptions are posted on Canvas.
Turn in your assignments by creating a github repository and giving
access to Jeremy (jsiek) and Caner (cderici).</p>

<p>Assignments will be graded based on how many test cases they succeed on.
Partial credit will be given for each “pass” of the compiler.
Some of the tests are in the public support code (see Resources below)
and the rest of the tests will be made available on Sunday night, one
day prior to the due date. The testing will be done on the linux
machine kj.luddy.indiana.edu named
after <a href="https://en.wikipedia.org/wiki/Katherine_Johnson">Katherine
Johnson</a> of NASA
fame. The testing will include both new tests and all of the tests
from prior assignments.</p>

<p>You may request feedback on your assignments prior to the due date.
Just commit your work to github and send us email.</p>

<p>Students are responsible for understanding the entire assignment and
all of the code that their team produces. The midterm and final exam
are designed to test a student’s understanding of the assignments.</p>

<p>Students are free to discuss and get help on the assignments from
anyone or anywhere. When posting questions on Piazza, it is OK to post
your code.</p>

<p>In contrast, for quizzes and exams, students are asked to work
alone. The quizzes and exams are closed book.  We will be using
Respondus Monitor for online proctoring.</p>

<p>The Final Project is due Dec. 4 and may be turned in late up to
Dec. 11.</p>

<p><strong>Late assignment policy:</strong> Assignments may be turned in up to one
week late with a penalty of 10%.</p>

<p><strong>Email Discussion Group:</strong> on <a href="http://piazza.com/iu/fall2020/p423p523e313e513">Piazza</a></p>

<p><strong>Slack Chat/Messaging:</strong>
  <a href="http://iu-compiler-course.slack.com/">Workspace</a> (see invitation
  link on Piazza or
  <a href="https://join.slack.com/t/iu-compiler-course/signup?x=x-p1325281886868-1312364974614-1331891515409">signup</a>
  using your iu email address).</p>

<p><strong>Resources:</strong></p>

<ul>
  <li><a href="https://github.com/IUCompilerCourse/public-student-support-code">Github repository for support code and test suites is here</a></li>
  <li><a href="https://download.racket-lang.org/">Racket</a></li>
  <li><a href="https://docs.racket-lang.org/">Racket Documentation</a></li>
  <li><a href="http://web.cecs.pdx.edu/~apt/cs491/x86-64.pdf">Notes on x86-64 programming</a></li>
  <li><a href="https://www.cs.cmu.edu/~fp/courses/15411-f13/misc/asm64-handout.pdf">x86-64 Machine-Level Programming</a></li>
  <li><a href="http://www.intel.com/content/dam/www/public/us/en/documents/manuals/64-ia-32-architectures-software-developer-manual-325462.pdf?_ga=1.200286509.2020252148.1452195021">Intel x86 Manual</a></li>
  <li><a href="https://software.intel.com/sites/default/files/article/402129/mpx-linux64-abi.pdf">System V Application Binary Interface</a></li>
  <li><a href="https://iu.instructure.com/courses/1735985/files/82131907/download?wrap=1">Uniprocessor Garbage Collection Techniques</a> by Wilson.</li>
  <li><a href="https://www.cs.indiana.edu/~dyb/pubs/inlining.pdf">Fast and Effective Procedure Inlining</a> by Waddell and Dybvig.</li>
</ul>

<p><strong>Bias-Based Incident Reporting.</strong></p>

<p>Bias-based incident reports can be made by students, faculty and
staff. Any act of discrimination or harassment based on race,
ethnicity, religious affiliation, gender, gender identity, sexual
orientation or disability can be reported through any of the options:</p>

<p>1) email biasincident@indiana.edu or incident@indiana.edu;</p>

<p>2) call the Dean of Students Office at (812) 855-8188 or</p>

<p>3) use the IU mobile App (m.iu.edu). Reports can be made anonymously.</p>

<p><strong>Dean on Call.</strong></p>

<p>The Dean of Students office provides support for students dealing with
serious or emergency situations after 5 p.m. in which an immediate
response is needed and which cannot wait until the next business
day. Faculty or staff who are concerned about a student’s welfare
should feel free to call the Dean on Call at (812) 856-7774. This
number is not to be given to students or families but is for internal
campus use only. If someone is in immediate danger or experiencing an
emergency, call 911.</p>

<p><strong>Boost.</strong></p>

<p>Indiana University has developed an award-winning smartphone app to
help students stay on top of their schoolwork in Canvas. The app is
called “Boost,” it is available for free to all IU students, and it
integrates with Canvas to provide reminders about deadlines and other
helpful notifications. For more information, see
https://kb.iu.edu/d/atud.</p>

<p><strong>Counseling and Psychological Services.</strong></p>

<p>CAPS has expanded their services. For information about the variety of
services offered to students by CAPS visit:
http://healthcenter.indiana.edu/counseling/index.shtml.</p>

<p><strong>Disability Services for Students (DSS).</strong></p>

<p>The process to establish accommodations for a student with a
disability is a responsibility shared by the student and the DSS
Office. Only DSS approved accommodations should be utilized in the
classroom. After the student has met with DSS, it is the student’s
responsibility to share their accommodations with the faculty
member. For information about support services or accommodations
available to students with disabilities and for the procedures to be
followed by students and instructors, please visit:
https://studentaffairs.indiana.edu/disability-services-students/.</p>

<p><strong>Reporting Conduct and Student Wellness Concerns.</strong></p>

<p>All members of the IU community including faculty and staff may report
student conduct and wellness concerns to the Division of Student
Affairs using an online form located at
https://studentaffairs.indiana.edu/dean-students/student-concern/index.shtml.</p>

<p><strong>Students needing additional financial or other assistance.</strong></p>

<p>The Student Advocates Office (SAO) can help students work through
personal and academic problems as well as financial difficulties and
concerns. SAO also assists students working through grade appeals and
withdrawals from all classes. SAO also has …</p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://iucompilercourse.github.io/IU-P423-P523-E313-E513-Fall-2020/">https://iucompilercourse.github.io/IU-P423-P523-E313-E513-Fall-2020/</a></em></p>]]>
            </description>
            <link>https://iucompilercourse.github.io/IU-P423-P523-E313-E513-Fall-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26001237</guid>
            <pubDate>Tue, 02 Feb 2021 14:24:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Primer on Bézier Curves]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26001218">thread link</a>) | @lnyan
<br/>
February 2, 2021 | https://pomax.github.io/bezierinfo/ | <a href="https://web.archive.org/web/*/https://pomax.github.io/bezierinfo/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="chapters">
				<section id="introduction">
					
					<p>
						Let's start with the good stuff: when we're talking about Bézier curves, we're talking about the things that you can see in the following
						graphics. They run from some start point to some end point, with their curvature influenced by one or more "intermediate" control points.
						Now, because all the graphics on this page are interactive, go manipulate those curves a bit: click-drag the points, and see how their
						shape changes based on what you do.
					</p>
					

					<p>
						These curves are used a lot in computer aided design and computer aided manufacturing (CAD/CAM) applications, as well as in graphic design
						programs like Adobe Illustrator and Photoshop, Inkscape, GIMP, etc. and in graphic technologies like scalable vector graphics (SVG) and
						OpenType fonts (TTF/OTF). A lot of things use Bézier curves, so if you want to learn more about them... prepare to get your learn on!
					</p>
				</section>
				<section id="whatis">
					
					<p>
						Playing with the points for curves may have given you a feel for how Bézier curves behave, but what <em>are</em> Bézier curves, really?
						There are two ways to explain what a Bézier curve is, and they turn out to be the entirely equivalent, but one of them uses complicated
						maths, and the other uses really simple maths. So... let's start with the simple explanation:
					</p>
					<p>
						Bézier curves are the result of <a href="https://en.wikipedia.org/wiki/Linear_interpolation">linear interpolations</a>. That sounds
						complicated but you've been doing linear interpolation since you were very young: any time you had to point at something between two other
						things, you've been applying linear interpolation. It's simply "picking a point between two points".
					</p>
					<p>
						If we know the distance between those two points, and we want a new point that is, say, 20% the distance away from the first point (and
						thus 80% the distance away from the second point) then we can compute that really easily:
					</p>
					<!--
\setmainfont[Ligatures=TeX]TeX Gyre Pagella \setmathfontTeX Gyre Pagella Math
 
                                      ╭       p = some point       ╮
                                      │        1                   │
                                      │       p = some other point │
                                      │        2                   │
                                Given │ distance= (p  - p )        │, our new point = p  + distance  · ratio
                                      │             2    1         │                   1
                                      │           percentage       │
                                      │    ratio= ──────────       │
                                      ╰              100           ╯
-->
					<img src="https://pomax.github.io/bezierinfo/images/chapters/whatis/c3f06301f5ce610df1217bc633257297.svg" width="501px" height="103px" loading="lazy">
					<p>
						So let's look at that in action: the following graphic is interactive in that you can use your up and down arrow keys to increase or
						decrease the interpolation ratio, to see what happens. We start with three points, which gives us two lines. Linear interpolation over
						those lines gives us two points, between which we can again perform linear interpolation, yielding a single point. And that point —and all
						points we can form in this way for all ratios taken together— form our Bézier curve:
					</p>
					<graphics-element title="Linear Interpolation leading to Bézier curves" width="825" height="275" src="./chapters/whatis/interpolation.js">
						<fallback-image>
							<span>Scripts are disabled. Showing fallback image.</span>
							<img width="825px" height="275px" src="https://pomax.github.io/bezierinfo/images/chapters/whatis/524dd296e96c0fe2281fb95146f8ea65.png" loading="lazy">
							<label></label>
						</fallback-image>
						
					</graphics-element>
					<p>And that brings us to the complicated maths: calculus.</p>
					<p>
						While it doesn't look like that's what we've just done, we actually just drew a quadratic curve, in steps, rather than in a single go. One
						of the fascinating parts about Bézier curves is that they can both be described in terms of polynomial functions, as well as in terms of
						very simple interpolations of interpolations of [...]. That, in turn, means we can look at what these curves can do based on both "real
						maths" (by examining the functions, their derivatives, and all that stuff), as well as by looking at the "mechanical" composition (which
						tells us, for instance, that a curve will never extend beyond the points we used to construct it).
					</p>
					<p>
						So let's start looking at Bézier curves a bit more in depth: their mathematical expressions, the properties we can derive from them, and
						the various things we can do to, and with, Bézier curves.
					</p>
				</section>
				<section id="explanation">
					
					<p>
						Bézier curves are a form of "parametric" function. Mathematically speaking, parametric functions are cheats: a "function" is actually a
						well defined term representing a mapping from any number of inputs to a <strong>single</strong> output. Numbers go in, a single number
						comes out. Change the numbers that go in, and the number that comes out is still a single number.
					</p>
					<p>
						Parametric functions cheat. They basically say "alright, well, we want multiple values coming out, so we'll just use more than one
						function". An illustration: Let's say we have a function that maps some value, let's call it <i>x</i>, to some other value, using some
						kind of number manipulation:
					</p>
					<!--
\setmainfont[Ligatures=TeX]TeX Gyre Pagella \setmathfontTeX Gyre Pagella Math
 
                                                               f(x) = cos (x)
-->
					<img src="https://pomax.github.io/bezierinfo/images/chapters/explanation/0cc876c56200446c60114c1b0eeeb2cc.svg" width="96px" height="17px" loading="lazy">
					<p>
						The notation <i>f(x)</i> is the standard way to show that it's a function (by convention called <i>f</i> if we're only listing one) and
						its output changes based on one variable (in this case, <i>x</i>). Change <i>x</i>, and the output for <i>f(x)</i> changes.
					</p>
					<p>So far, so good. Now, let's look at parametric functions, and how they cheat. Let's take the following two functions:</p>
					<!--
\setmainfont[Ligatures=TeX]TeX Gyre Pagella \setmathfontTeX Gyre Pagella Math
 
                                                               f(a) = cos (a)
                                                               f(b) = sin (b)
-->
					<img src="https://pomax.github.io/bezierinfo/images/chapters/explanation/a2891980850ddbb27d308ac112d69f74.svg" width="93px" height="36px" loading="lazy">
					<p>
						There's nothing really remarkable about them, they're just a sine and cosine function, but you'll notice the inputs have different names.
						If we change the value for <i>a</i>, we're not going to change the output value for <i>f(b)</i>, since <i>a</i> isn't used in that
						function. Parametric functions cheat by changing that. In a parametric function all the different functions share a variable, like this:
					</p>
					<!--
\setmainfont[Ligatures=TeX]TeX Gyre Pagella \setmathfontTeX Gyre Pagella Math
 
                                                             ╭ f (t) = cos (t)
                                                             ╡  a              
                                                             │ f (t) = sin (t)
                                                             ╰  b
-->
					<img src="https://pomax.github.io/bezierinfo/images/chapters/explanation/7acc94ec70f053fd10dab69d424b02a6.svg" width="100px" height="40px" loading="lazy">
					<p>
						Multiple functions, but only one variable. If we change the value for <i>t</i>, we change the outcome of both <i>f<sub>a</sub>(t)</i> and
						<i>f<sub>b</sub>(t)</i>. You might wonder how that's useful, and the answer is actually pretty simple: if we change the labels
						<i>f<sub>a</sub>(t)</i> and <i>f<sub>b</sub>(t)</i> with what we usually mean with them for parametric curves, things might be a lot more
						obvious:
					</p>
					<!--
\setmainfont[Ligatures=TeX]TeX Gyre Pagella \setmathfontTeX Gyre Pagella Math
 
                                                               { x = cos (t) 
                                                                 y = sin (t)
-->
					<img src="https://pomax.github.io/bezierinfo/images/chapters/explanation/6914ba615733c387251682db7a3db045.svg" width="77px" height="40px" loading="lazy">
					<p>There we go. <i>x</i>/<i>y</i> coordinates, linked through some mystery value <i>t</i>.</p>
					<p>
						So, parametric curves don't define a <i>y</i> coordinate in terms of an <i>x</i> coordinate, like normal functions do, but they instead
						link the values to a "control" variable. If we vary the value of <i>t</i>, then with every change we get <strong>two</strong> values,
						which we can use as (<i>x</i>,<i>y</i>) coordinates in a graph. The above set of functions, for instance, generates points on a circle: We
						can range <i>t</i> from negative to positive infinity, and the resulting (<i>x</i>,<i>y</i>) coordinates will always lie on a circle with
						radius 1 around the origin (0,0). If we plot it for <i>t</i> from 0 to 5, we get this:
					</p>
					<graphics-element title="A (partial) circle: x=sin(t), y=cos(t)" width="275" height="275" src="./chapters/explanation/circle.js">
						<fallback-image>
							<span>Scripts are disabled. Showing fallback image.</span>
							<img width="275px" height="275px" src="https://pomax.github.io/bezierinfo/images/chapters/explanation/959762e39ae32407e914a687d804ff3a.png" loading="lazy">
							<label>A (partial) circle: x=sin(t), y=cos(t)</label>
						</fallback-image>
						
					</graphics-element>
					<p>
						Bézier curves are just one out of the many classes of parametric functions, and are characterised by using the same base function for all
						of the output values. In the example we saw above, the <i>x</i> and <i>y</i> values were generated by different functions (one uses a
						sine, the other a cosine); but Bézier curves use the "binomial polynomial" for both the <i>x</i> and <i>y</i> outputs. So what are
						binomial polynomials?
					</p>
					<p>You may remember polynomials from high school. They're those sums that look like this:</p>
					<!--
\setmainfont[Ligatures=TeX]TeX Gyre Pagella \setmathfontTeX Gyre Pagella Math
 
                                                                3         2
                                                   f(x) = a  · x  + b  · x  + c  · x + d
-->
					<img src="https://pomax.github.io/bezierinfo/images/chapters/explanation/855a34c7f72733be6529c3fb33fa1a23.svg" width="213px" height="20px" loading="lazy">
					<p>
						If the highest order term they have is <i>x³</i>, they're called "cubic" polynomials; if it's <i>x²</i>, it's a "square" polynomial; if
						it's just <i>x</i>, it's a line (and if there aren't even any terms with <i>x</i> it's not a polynomial!)
					</p>
					<p>
						Bézier curves are polynomials of <i>t</i>, rather than <i>x</i>, with the value for <i>t</i> being fixed between 0 and 1, with
						coefficients <i>a</i>, <i>b</i> etc. taking the "binomial" form, which sounds fancy but is actually a pretty simple description for mixing
						values:
					</p>
					<!--
\setmainfont[Ligatures=TeX]TeX Gyre Pagella \setmathfontTeX Gyre Pagella Math
 
                                         linear= (1-t) + t                                        
                                                      2                      2
                                         square= (1-t)  + 2  · (1-t)  · t + t                     
                                                      3             2                       2    3
                                          cubic= (1-t)  + 3  · (1-t)   · t + 3  · (1-t)  · t  + t 
-->
					<img src="https://pomax.github.io/bezierinfo/images/chapters/explanation/2493468e73b73f43eba8f66f0c189d1a.svg" width="367px" height="64px" loading="lazy">
					<p>
						I know what you're thinking: that doesn't look too simple! But if we remove <i>t</i> and add in "times one", things suddenly look pretty
						easy. Check out these binomial terms:
					</p>
					<!--
\setmainfont[Ligatures=TeX]TeX Gyre Pagella \setmathfontTeX Gyre Pagella Math
 
                                                          linear=  1 + 1           
                                                          square=  1 + 2 + 1       
                                                           cubic=  1 + 3 + 3 + 1   
                                                         quartic= 1 + 4 + 6 + 4 + 1
-->
					<img src="https://pomax.github.io/bezierinfo/images/chapters/explanation/8986c536df8153b30197c3a5407d233a.svg" width="184px" height="87px" loading="lazy">
					<p>
						Notice that 2 is the same as 1+1, and 3 is 2+1 and 1+2, and 6 is 3+3... As you can see, each time we go up a dimension, we simply start
						and end with 1, and everything in between is just "the two numbers above it, added together", giving us a simple number sequence known as
						<a href="https://en.wikipedia.org/wiki/Pascal%27s_triangle">Pascal's triangle</a>. Now <i>that's</i> easy to remember.
					</p>
					<p>
						There's an equally simple way to figure out how the polynomial terms work: if we rename <i>(1-t)</i> to <i>a</i> and <i>t</i> to <i>b</i>,
						and remove the weights for a moment, we get this:
					</p>
					<!--
     \setmainfont[Ligatures=TeX]TeX Gyre Pagella \setmathfontTeX Gyre Pagella Math
      
linear= \colorbluea + \colorredb                                                                                                                      
square= \colorbluea  · \colorbluea + \colorbluea  · \colorredb + \colorredb  · \colorredb                                                             
 cubic= \colorbluea  · \colorbluea  · \colorbluea + \colorbluea  · \colorbluea  · \colorredb + \colorbluea  · \colorredb  · \colorredb + \colorredb  ·
                                                                                       
                                                                                       
                                                               \colorredb  · \colorredb
-->
					<img src="https://pomax.github.io/bezierinfo/images/chapters/explanation/2c47081c2a9c20d2110f13daa482a3ab.svg" width="301px" height="60px" loading="lazy">
					<p>
						It's basically just a sum of "every combination of <i>a</i> and <i>b</i>", progressively replacing <i>a</i>'s with <i>b</i>'s after every
						+ sign. So that's actually pretty simple too. So now you know binomial polynomials, and just for completeness I'm going to show you the
						generic function for this:
					</p>
					<!--
\setmainfont[Ligatures=TeX]TeX Gyre Pagella \setmathfontTeX Gyre Pagella Math
 
                          __ n                                                                                          n-i     i
            Bézier(n,t) = ❯      \undersetbinomial term\underbrace\binomni  · \ \undersetpolynomial term\underbrace(1-t)     · t 
                          ‾‾ i=0
-->
					<img src="https://pomax.github.io/bezierinfo/images/chapters/explanation/f79dd2f2d992e22b8d057fdc641290b0.svg" width="300px" height="55px" loading="lazy">
					<p>
						And that's the full description for Bézier curves. Σ in this function indicates that this is a series of additions (using the variable
						listed below the Σ, starting at ...=&lt;value&gt; and ending at the value listed on top of the Σ).
					</p>
					<div>
						<h3>How to implement the basis function</h3>
						<p>We could naively implement the basis function as a mathematical construct, using the function as our guide, like this:</p>

						

						<p>
							I say we could, because we're not going to: the factorial function is <em>incredibly</em> expensive. And, as we can see from the above
							explanation, we can actually create Pascal's triangle quite easily without it: just start at [1], then [1,1], then [1,2,1], then
							[1,3,3,1], and so on, with each next row fitting 1 more number than the previous row, starting and ending with "1", with all the numbers
							in between being the sum of the previous row's elements on either side "above" the one we're computing.
						</p>
						<p>
							We can generate this as a list of lists lightning fast, and then never have to compute the binomial terms because we have a lookup
							table:
						</p>

						<table>
							<tbody><tr>
								<td>1</td>
								<td rowspan="18">
									
								</td>
							</tr>
							<tr>
								<td>2</td>
							</tr>
							<tr>
								<td>3</td>
							</tr>
							<tr>
								<td>4</td>
							</tr>
							<tr>
								<td>5</td>
							</tr>
							<tr>
								<td>6</td>
							</tr>
							<tr>
								<td>7</td>
							</tr>
							<tr>
								<td>8</td>
							</tr>
							<tr>
								<td>9</td>
							</tr>
							<tr>
								<td>10</td>
							</tr>
							<tr>
								<td>11</td>
							</tr>
							<tr>
								<td>12</td>
							</tr>
							<tr>
								<td>13</td>
							</tr>
							<tr>
								<td>14</td>
							</tr>
							<tr>
								<td>15</td>
							</tr>
							<tr>
								<td>16</td>
							</tr>
							<tr>
								<td>17</td>
							</tr>
							<tr>
								<td>18</td>
							</tr>
						</tbody></table>

						<p>
							So what's going on here? First, we declare a lookup table with a size that's reasonably large enough to accommodate most lookups. Then,
							we declare a function to get us the values we need, and we make sure that if an <i>n/k</i> pair is requested that isn't in the LUT yet,
							we expand it first. Our basis function now looks like this:
						</p>

						

						<p>
							…</p></div></section></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pomax.github.io/bezierinfo/">https://pomax.github.io/bezierinfo/</a></em></p>]]>
            </description>
            <link>https://pomax.github.io/bezierinfo/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26001218</guid>
            <pubDate>Tue, 02 Feb 2021 14:22:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On the Security of WhatsApp and Telegram]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 18 (<a href="https://news.ycombinator.com/item?id=26001191">thread link</a>) | @tyrion
<br/>
February 2, 2021 | https://germano.dev/whatsapp-vs-telegram/ | <a href="https://web.archive.org/web/*/https://germano.dev/whatsapp-vs-telegram/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>

<p>Many people, even among security experts and privacy advocates, hold the firm
belief that WhatsApp is more <em>secure</em> and privacy-wise better than Telegram.
After having thoroughly studied the issue, I do not believe this to be true.
In this article I will try to highlight the necessary facts to enable the
reader to form a more informed opinion on the matter.</p>
<section>
<h2 id="contents">Contents</h2>
<ol>
<li><a href="#prologue">Prologue</a></li>
<li><a href="#fallacies">The fallacies</a></li>
<li><a href="#threat-modeling">Threat modeling</a></li>
<li><a href="#e2ee">End-to-end encryption</a><ol>
<li><a href="#app-trust">Trust in the app</a></li>
<li><a href="#secure-backups">Secure backups</a></li>
<li><a href="#auth">Authentication</a></li>
<li><a href="#sync">Device synchronization</a></li>
</ol></li>
<li><a href="#telegram">Criticism of Telegram</a><ol>
<li><a href="#default-e2ee">No end-to-end encryption by default</a></li>
<li><a href="#rolled-their-own">They rolled their own crypto</a></li>
<li><a href="#vulns">History of Telegram vulnerabilities</a></li>
<li><a href="#defamation">Defamation</a></li>
</ol></li>
<li><a href="#conclusion">Conclusion</a></li>
</ol>
</section>
<h2 id="prologue">Prologue</h2>
<p>Most sources which praise WhatsApp and criticize Telegram make bold claims,
presenting them as objective truth, without
sufficiently motivating them or backing them up with facts. In many cases they
rely on <a href="https://en.wikipedia.org/wiki/Argument_from_authority" target="_blank" rel="nofollow noopener noreferrer">arguments from authority</a>:</p>
<blockquote>
<p>[Telegram] By default, it is less safe than @WhatsApp, which makes [it] dangerous
for non-experts. — <a href="https://twitter.com/Snowden/status/778597417797226496" target="_blank" rel="nofollow noopener noreferrer">Ed. Snowden (Sep, 2016)</a></p>
</blockquote>
<p>I realize that many of you will be sceptical now. After all, if Edward Snowden
said so, it <em>must</em> be true. Why would you question it? And why, above all, should we <em>believe</em> you instead?</p>
<p>Well, the point is exactly this. I am not asking you to believe <em>me</em>, but to
evaluate the facts, with an open mind, before forming an opinion.
Moreover, even if it might be hard to accept, even heroes and geniuses like Edward
Snowden can be wrong from time to time!</p>
<p>I made a good faith attempt to research all the facts and present them as
objectively as possible, without including personal biases. However, please
keep in mind that I do not consider myself infallible, and thus there might be
some mistakes. Feel free to let me know what you think.</p>




<h2 id="fallacies">The fallacies</h2>
<p>The vast majority of things I read on this topic can be reduced to a combination
of the following factors:</p>

<ol>
<li>Not considering a <a href="https://en.wikipedia.org/wiki/Threat_model" target="_blank" rel="nofollow noopener noreferrer">threat model</a>.</li>
<li>The <a href="https://en.wikipedia.org/wiki/False_premise" target="_blank" rel="nofollow noopener noreferrer">false premise</a> that end-to-end encryption alone is a necessary and
sufficient condition for good security and privacy.</li>
<li>The erroneous conclusion that everything that is not end-to-end encrypted is
inherently less secure and must be avoided at all cost.</li>
<li>The huge respect for <a href="https://en.wikipedia.org/wiki/Moxie_Marlinspike" target="_blank" rel="nofollow noopener noreferrer">Moxie Marlinspike</a>, one of the authors of the
<a href="https://en.wikipedia.org/wiki/Signal_Protocol" target="_blank" rel="nofollow noopener noreferrer">end-to-end encryption protocol</a> used by WhatsApp and
Signal, leading to <a href="https://en.wikipedia.org/wiki/Argument_from_authority" target="_blank" rel="nofollow noopener noreferrer">arguments from authority</a>.</li>
<li>Outright lies about the insecurity of the cryptographic protocol used by
Telegram.</li>
</ol>
<p>The rest of the article is dedicated to amply clarify each of the points
above. In <a href="#threat-models">section 3</a> I will articulate the importance of considering threat
models when trying to determine if a system is <em>secure</em>. In <a href="">section 4</a>
I will discuss end-to-end encryption, the challenges that it entails and how it
is implemented in WhatsApp and Telegram. In <a href="#telegram">section 5</a> I will address the most
common criticisms of Telegram, and finally, in <a href="#conclusion">section 6</a>, I will draw some conclusions.</p>


<h2 id="threat-modeling">Threat modeling</h2>
<blockquote>
<p>Threat modeling answers questions like “Where am I most vulnerable to attack?”, “What are the most relevant threats?”, and “What do I need to do to safeguard against these threats?”. — <a href="https://en.wikipedia.org/wiki/Threat_model" target="_blank" rel="nofollow noopener noreferrer">Wikipedia</a></p>
</blockquote>
<p>Searching on Hacker News for <a href="https://hn.algolia.com/?dateRange=all&amp;page=0&amp;prefix=false&amp;query=%22whatsapp%20is%20more%20secure%22&amp;sort=byPopularity&amp;type=all" target="_blank" rel="nofollow noopener noreferrer">“WhatsApp is more secure”</a>
yields some typical comments from people arguing that WhatsApp is more secure
than Telegram</p>
<blockquote>
<p>Telegram is more fun (bots and stickers), but <strong>WhatsApp is more secure</strong>
(no messages on server, no rolled-your-own-crypto). — <a href="https://news.ycombinator.com/item?id=14374644" target="_blank" rel="nofollow noopener noreferrer">hn</a></p>
</blockquote>
<p>Or even that Telegram is the least secure</p>
<blockquote>
<p>How can anyone call “Telegram” secure? Those days are over. It’s the least
secure messaging app of them all now. <strong>Even WhatsApp is more secure than
Telegram</strong> (let alone Threema). — <a href="https://news.ycombinator.com/item?id=13032192" target="_blank" rel="nofollow noopener noreferrer">hn</a></p>
</blockquote>
<p>But, what does it really mean that WhatsApp is <em>more secure</em>? Secure against the
government? Secure against your friendly neighbourhood hacker snooping on
the Wi-Fi at Starbucks?
Secure against throwing rocks at your phone? Secure against your mom trying to
read your messages?</p>
<p>Defending from an adversary with practically unlimited budget and computational
resources, such as a powerful government, is going to be much harder than
defending against a curious neighbour sniffing on your Wi-Fi.</p>
<p><strong>Saying that WhatsApp is more secure than Telegram,
without specifying against what kind of adversary or against what kind of threat,
does not mean much.</strong></p>

<p>Without considering these questions and only craving for <em>“more security”</em>, <strong>is
not necessarily a smart thing</strong> either.
In the same way that putting your possessions in a nuclear bunker
might be more secure, in
case of a nuclear war, than locking them in a small safe in your room, but could
not be the best choice if all you are trying to do is protect your Blu-ray
collection from your flatmate!
Moreover, <strong>increasing security is often not free</strong>, because
it increases complexity, thus development cost, and can decrease usability. Exactly like a nuclear bunker
is going to be much more expensive than a small safe and is also not going to be
as easy to use.
Lastly, it is important to note that <strong>you are as secure as the weakest link in your system</strong>.
Therefore, if you want a nuclear bunker, with all the challenges and costs that
it entails, but then forget to put a lock on its door, it might not protect you that
much after all.</p>


<p>Consequently, let us now try to examine which of the <em>components</em> involved in
using a messaging app can be potentially attacked by a malicious agent,
compromising our security.
For each of these, <em>you</em> need to establish if you blindly trust it to function
correctly, or if you believe it could be compromised and thus need to find a way
to defend it from the potential threat.</p>

<ul>
<li><strong>The companies running the servers needed by the app to work</strong>. That is,
Facebook, Telegram and whatever other third party services they decide to
use or share your data with.<ol>
<li>Are you OK with them being able to read your messages?</li>
<li>Do you trust them on keeping your data safe? So that it does not get
stolen, for example.</li>
<li>Are you OK with them selling your data or meta-data to advertisers?</li>
</ol></li>
<li><strong>The app itself</strong>. That is, the WhatsApp or Telegram apps on your
phone.<ol>
<li>Do you trust that it does exactly what it says and is not malicious? For
example that it is always encrypting your messages.</li>
<li>Do you trust its developers to be good citizens and not insert backdoors?</li>
</ol></li>
<li><strong>The communication medium</strong>. That is, the Internet.<ol>
<li>Do you trust the connection between you and the app’s servers to be
secure?</li>
<li>Do you trust your ISP?</li>
</ol></li>
<li><strong>The distribution and update process</strong>. For example, the Play Store, App
Store or F-Droid. Do you trust Google and Apple to give you the real app,
and not a specially crafted one to spy on you?</li>
<li><strong>The other apps on your phone</strong>. Do you trust all the other apps on your
phone, or do you think some of them might be malware?</li>
<li><strong>The OS</strong>. That is, Android or iOS. Do you trust your
operative system and its developers (e.g. Google, Samsung, Apple)? For example,
do you trust that no malicious actor can remotely <a href="https://www.tripwire.com/state-of-security/latest-security-news/gaps-in-google-play-store-xfo-allow-attackers-to-remotely-install-malware-on-android-devices/" target="_blank" rel="nofollow noopener noreferrer">install</a>
or <a href="https://android-developers.googleblog.com/2010/06/exercising-our-remote-application.html" target="_blank" rel="nofollow noopener noreferrer">uninstall</a> software on your device?</li>
<li><strong>The firmware and the hardware</strong>. Do you trust your phone is not running
malware at the firmware or hardware level,
<a href="https://redmine.replicant.us/projects/replicant/wiki/SamsungGalaxyBackdoor" target="_blank" rel="nofollow noopener noreferrer">like it was discovered on Samsung phones in 2014</a>?</li>
</ul>
<p>Whew, that was quite a list!</p>
<p>But, <strong>do we really need to care about all of this stuff?</strong> Well, not many
people do.
However, if you want to evaluate which messaging app best suits your needs and
you care a bit about security and privacy, then it is essential.
This process will enable you to decide for yourself, without basing your decision
on some tweet saying that one app is <em>more secure</em> than the other.</p>

<p>Nonetheless, it is important to reiterate that if you are worried that a powerful
adversary, like a government, might want to directly target you (as opposed to
compromise you as part of a mass surveillance program), you cannot defend only
against one attack vector and ignore the others.
You can have the most secure messaging app in the world, but if your phone can be hacked
with an SMS, there is not much of a difference.</p>


<p>You might wonder why couldn’t we just try to defend ourselves against all possible
threats and attacks. It is because, as we said before and as we will show in more
detail in the next section, increasing security is not free but comes
with the cost of increased complexity and very often decreased usability.</p>

<h2 id="e2ee">End-to-end encryption</h2>
<p>Let us now address the most common reason that induces people to believe that
WhatsApp is a better choice: <a href="https://en.wikipedia.org/wiki/End-to-end_encryption" target="_blank" rel="nofollow noopener noreferrer">end-to-end encryption</a>.</p>

<p>WhatsApp describes end-to-end encryption (or E2EE for short) in the following way:</p>
<blockquote>
<p>End-to-end encryption ensures only you and the person you’re communicating
with can read or listen to what is sent, and nobody in between, not even
WhatsApp. This is because with end-to-end encryption, your messages are
secured with a lock, and only the recipient and you have the special key
needed to unlock and read them. All of this happens automatically: no need to
turn on any special settings to secure your messages. — <a href="https://faq.whatsapp.com/general/security-and-privacy/end-to-end-encryption/?lang=en" target="_blank" rel="nofollow noopener noreferrer">WhatsApp FAQ</a></p>
</blockquote>
<p>WhatsApp nowadays has end-to-end encryption enabled by default for all chats,
while Telegram has not enabled it by default and does not support it on group
chats.</p>
<p>This is undoubtedly a very nice property to have. If implemented correctly it
allows us to communicate securely, even in the case in which the server (i.e.
WhatsApp or Telegram) cannot be trusted and is considered malicious.
However, if we decide to go down this road and not trust any more the companies
running our app, we introduce a series of new complications.</p>
<p>However, one could argue that even in the case in which we decide to trust the
Service, it is beneficial to have end-to-end encryption. This is a valid point because, while
we might trust the Service, for sure we do not trust some potential malicious
actors compromising the Service’s infrastructure and getting access to our data. In
this scenario our data should still be safe because not even the Service has
access to it, and therefore an attacker cannot steal the decryption key nor
coerce the Service to disclose it. This is the major strength of
E2EE.
Nonetheless, it is worth to stress that in this scenario we assumed to trust
the …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://germano.dev/whatsapp-vs-telegram/">https://germano.dev/whatsapp-vs-telegram/</a></em></p>]]>
            </description>
            <link>https://germano.dev/whatsapp-vs-telegram/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26001191</guid>
            <pubDate>Tue, 02 Feb 2021 14:19:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Racket News – Issue 45]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26001174">thread link</a>) | @azhenley
<br/>
February 2, 2021 | https://racket-news.com/2021/02/racket-news-issue-45.html | <a href="https://web.archive.org/web/*/https://racket-news.com/2021/02/racket-news-issue-45.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <header>
    <p>
<time datetime="2021-02-01" pubdate="true">2021-02-01</time></p>
  </header>
  <small>Permalink: <a href="https://racket-news.com/2021/02/racket-news-issue-45.html">https://racket-news.com/2021/02/racket-news-issue-45.html</a></small>

<p>Welcome to the forty-fifth issue of Racket News.</p>

<div><p><img src="https://racket-news.com/img/issue45/happybday-2021.jpg" alt=""></p></div>

<p>Today the is second birthday of Racket News. The first issue was released exactly 2 years ago on Feb 1st, 2019. A lot has happened in Racket in the last few years and it’s going stronger than ever : as a language, implementation, and community. Many thanks to all of you who have been following Racket News, sending suggestions for improvements and contributions to the issues. Cheers to a new year!</p>

<p>With the good news out of the way, my apologies for the delayed issue. We missed the mid-month issue in January as I had a rough start of the year but I am now on the right track and things should proceed as normal. The next issue should be here on February 15th, and the following one on March 1st.</p>

<p>Grab a coffee and lets dive in!</p>



<ol>
 <li><a href="#whatsnew">What’s New?</a></li>
 <li><a href="#aroundtheweb">Racket Around the Web</a></li>
 <li><a href="#newreleases">New Releases</a></li>
 <li><a href="#calltoracket">Call to Racket!</a></li>
 <li><a href="#spotlight">Project in the Spotlight</a></li>
 <li><a href="#featuredpaper">Featured Racket Paper</a></li>
 <li><a href="#meetups">Upcoming Meetups</a></li>
 <li><a href="#stats">Racket Project Statistics</a></li>
 <li><a href="#sponsors">Sponsors</a></li></ol>





<ul>
 <li>On Friday, Feb. 19, there will be a Metaprogram-off between Sam Tobin-Hochstadt and Quinn Wilton on #PLTalk. Watch and join the live chat on <a href="https://twitch.tv/jeanqasaur">Twitch</a>. For more information on #PLTalk, check its <a href="https://github.com/jeanqasaur/pltalk">GitHub repo</a>.</li>
 <li>Not a recent article, but a good read nonetheless: <a href="https://levelup.gitconnected.com/a-guide-to-programming-with-drracket-bcac4153710e">A Guide to Programming with Racket (DrRacket)</a> by Justin Chae.</li>
 <li>Sam Tobin-Hochstadt has done <a href="https://gist.github.com/samth/2f0996c80ef7e81f8e0aaba32fd7aaf1">some quick analysis</a> and concluded Racket is now 16 times faster than it was in 2004.</li>
 <li>Have you ever wanted the classic bomberman written in Racket? There <a href="https://github.com/Leystryku/mpbomberman_racket">you go… just for you</a>!</li>
 <li>There have been many developments in quickscript world - here are a few quickscripts picked for you.</li>
 <li><a href="https://gist.github.com/Metaxal/77391e388303af5513d09bcd640f116c">url2script</a>: Easily install quickscripts found in gists, gitlab snippets, pasterack and pastebin.</li>
 <li><a href="https://gist.github.com/Metaxal/f5ea8e94b802eac947fe9ea72870624b">Workspaces for DrRacket</a> and also related, <a href="https://github.com/sorawee/drracket-restore-workspace">restore workspce for DrRacket</a>.</li>
 <li><a href="https://gist.github.com/Metaxal/3ed323747e1af0bd4df5acd56b03b45e">Open multiple files at once</a></li>
 <li><a href="https://github.com/Quickscript-Competiton/July2020entries/blob/master/scripts/open-recent.rkt">Open Recent</a></li></ul>





<p>Do you blog about Racket? <a href="mailto:pmatos@linki.tools">Let me know!</a></p>

<ul>
 <li><a href="https://blog.racket-lang.org/2021/01/racket-status.html">Racket Compiler and Runtime Status: January 2021</a> by Matthew Flatt.</li>
 <li><a href="https://micahcantor.xyz/blog/racket-programming-the-fun-way-review">Book Review: Racket Programming the Fun Way by James Stelly</a> by Micah Cantor.</li>
 <li><a href="https://andregarzia.com/2021/01/converted-site-from-frog-to-pollen.html">Converted site from Frog to Pollen</a> by Andre Alves Garzia.</li>
 <li><a href="https://defn.io/2021/01/19/racket-cs-on-ios/">Running Racket CS on iOS</a> by Bogdan Popa.</li>
 <li><a href="https://alex-hhh.github.io/2021/01/plot-animations.html">Plot Animations</a> by Alex Harsányi.</li>
 <li><a href="https://opensource.com/article/21/1/racket-guess-number">Start programming in Racket by writing a “guess the number” game</a> by Cristiano L. Fontana.</li>
 <li><a href="https://medium.com/better-programming/why-i-still-lisp-and-you-should-too-18a2ae36bd8">Why I Still Lisp (and You Should Too)</a> by Anurag Mendhekar.</li></ul>





<p>If you know of library releases or maybe your own libraries and you want them to be featured, please <a href="mailto:pmatos@linki.tools">let me know</a>.</p>

<ul>
 <li><code>elle</code>(<a href="https://pkgs.racket-lang.org/package/elle">pkg</a>/<a href="https://github.com/tail-reversion/elle">src</a>) is a Racket-like language with reimagined syntax and updated features by Kelly Smith.</li>
 <li><code>resyntax</code>(<a href="https://pkgs.racket-lang.org/package/resyntax">pkg</a>/<a href="https://github.com/jackfirth/resyntax/tree/master">src</a>) is an experimental refactoring tool built on top of syntax-parse by Jack Firth.</li>
 <li><code>termconfig</code>(<a href="https://pkgs.racket-lang.org/package/termconfig">pkg</a>/<a href="https://github.com/dodgez/termconfig/tree/main">src</a>) is a cross-platform terminal helper library in Racket by Zachary Dodge.</li></ul>





<p>Want to contribute to Racket? Don’t know where to start? Each RN issue I choose an easy issue to fix to get you started contributing to Racket. Come, give it a go.</p>

<p>We started with a call to fix <a href="https://github.com/racket/racket/issues/3603">issue 3603</a> of Racket. This is still ongoing with a PR being merged soon. The next issue is <a href="https://github.com/racket/racket/issues/2883">issue 2883</a> of Racket. If you are interested in fixing this but need some guidance, feel free to comment on the issue page. Will you be our next Champion?</p>

<p>Good luck!</p>





<p>This week’s project in the spotlight is <a href="https://docs.racket-lang.org/resyntax/index.html"><code>resyntax</code></a> by Jack Firth.</p>

<p>From the website:</p>

<blockquote>
 <p>Resyntax is a refactoring tool for Racket. The tool can be guided by refactoring rules, which are macro-like functions defined in terms of syntax-parse that specify how to search for and refactor different coding patterns.</p>
 <p>This tool is extremely experimental. Do not attempt to incorporate it into your projects yet. For now, the refactoring suggestions produced by resyntax are best viewed as glimpses into one possible distant future of static analysis for Racket. Feedback, questions, and ideas are all greatly appreciated and are best directed at the GitHub repository.</p>
 <p>Resyntax does not have anything approaching a public API yet. If you want to actually try using it, open the source code of the resyntax module using DrRacket’s “Open Require Path” menu option, change the file path given to the refactor-file! function in the main submodule, then run it. Choosing a file checked into Git (or another version control system) is highly recommended in order to make it easier to view the diff and easier to undo the changes.</p></blockquote>

<p>It’s unusual for me to spotlight a recently released project but I find that one of the things that are really needed in the Racket ecosystem are devtools like these, therefore this is a spotlight for the experimental version. I hope it excites you as much as it does me.</p>





<p>This issue’s featured paper is <a href="https://drive.google.com/file/d/1wtaSi4HUG8S2P6gyLks1DTkr04hIbWYf/view?usp=sharing">Programming Languages as Operating Systems (or Revenge of the Son of the Lisp Machine)</a> by Matthew Flatt, Robert Findler, Shriram Krishnamurti, and Matthias Felleisen.</p>

<p>Abstract:</p>

<blockquote>
 <p>The MrEd virtual machine serves both as the implementation platform for the DrScheme programming environment, and as the underlying Scheme engine for executing expressions and programs entered into DrScheme’s read-eval-print loop. We describe the key elements of the MrEd virtual machine for building a programming environment, and we step through the implementation of a miniature version of DrScheme in MrEd. More generally, we show how MrEd defines a high-level operating system for graphical programs.</p></blockquote>





<p>Do you know of any upcoming meetups I can advertise? <a href="mailto:pmatos@linki.tools">Let me know</a>.</p>

<ul>
 <li>Racket users video meetup brought to you by Stephen De Gabrielle and Sam Phillips - Feb. 6, 2021 at 8pm CET, via <a href="https://gather.town/app/wH1EDG3McffLjrs0/racket-users">Gather Town</a>. Paper for discussion (optional pre-reading) is: <a href="https://www2.ccs.neu.edu/racket/pubs/scheme04-bo.pdf">A Foreign Function Interface</a> by Eli Barzilay &amp; Dmitry Orlovsky.</li></ul>





<p>Some data about the activity in the <a href="https://github.com/racket">Racket</a> et al. repositories, for the month of January, 2021.</p>
<!-- Repo racket-->
<!-- # Commits: 79-->
<!-- Issues: 35/25/423-->
<!-- PRs: 35/34/81-->
<!-- Repo drracket-->
<!-- # Commits: 12-->
<!-- Issues: 6/10/195-->
<!-- PRs: 3/2/3-->
<!-- Repo typed-racket-->
<!-- # Commits: 12-->
<!-- Issues: 10/7/244-->
<!-- PRs: 13/12/22-->
<!-- Repo scribble-->
<!-- # Commits: 3-->
<!-- Issues: 0/0/70-->
<!-- PRs: 5/3/17-->
<!-- Repo plot-->
<!-- # Commits: 3-->
<!-- Issues: 1/1/7-->
<!-- PRs: 0/0/0-->
<!-- Repo redex-->
<!-- # Commits: 1-->
<!-- Issues: 0/0/42-->
<!-- PRs: 0/0/7-->

<div>
 <table>
  <thead>
   <tr>
    <th></th>
    <th># commits</th>
    <th>Issues (new/closed/open)</th>
    <th>PRs (new/closed/open)</th></tr></thead>
  <tbody><tr>
   <td>racket</td>
   <td>79</td> 
   <td>35/25/423</td> 
   <td>35/34/81</td></tr>
  <tr>
   <td>drracket</td>
   <td>12</td> 
   <td>6/10/195</td> 
   <td>3/2/3</td></tr>
  <tr>
   <td>typed-racket</td>
   <td>12</td> 
   <td>10/7/244</td> 
   <td>13/12/22</td></tr>
  <tr>
   <td>scribble</td>
   <td>3</td> 
   <td>0/0/70</td> 
   <td>5/3/17</td></tr>
  <tr>
   <td>plot</td>
   <td>3</td> 
   <td>1/1/7</td> 
   <td>0/0/0</td></tr>
  <tr>
   <td>redex</td>
   <td>1</td> 
   <td>0/0/42</td> 
   <td>0/0/7</td></tr></tbody></table></div>

<p>Contributions by (25):</p>

<ul>
 <li>Alex Harsányi</li>
 <li>Alexis King</li>
 <li>Bob Burger</li>
 <li>Bogdan Popa</li>
 <li>Davis Silverman</li>
 <li>Dominik Pantůček</li>
 <li>Fred Fu</li>
 <li>Gustavo Massaccesi</li>
 <li>Jack Firth</li>
 <li>Jarhmander</li>
 <li>John Clements</li>
 <li>Matthew Flatt</li>
 <li>Mike Sperber</li>
 <li>Noah Ma</li>
 <li>Pavel Panchekha</li>
 <li>Robby Findler</li>
 <li>Ryan Culpepper</li>
 <li>Sam Tobin-Hochstadt</li>
 <li>Sergiu Ivanov</li>
 <li><code>bdeket</code></li>
 <li><code>dyb</code></li>
 <li><code>shuhung</code></li>
 <li><code>sorawee</code></li>
 <li><code>yjqww6</code></li>
 <li><code>ymdarake</code></li></ul>

<p>
 <small>Repositories included above are: <code>racket</code>, <code>ChezScheme</code>, <code>redex</code>, <code>typed-racket</code>, <code>drracket</code>, <code>scribble</code>, <code>plot</code>.</small></p>





<p>Many thanks to my <a href="https://github.com/sponsors/pmatos/">sponsors</a>:</p>

<ul>
 <li><a href="http://serverracket.com/">Jesse Alama</a>. Jesse is a Racketeer, Mathematician, and writer based in Main, Germany. He is the organizer of <a href="https://racketfest.com/">RacketFest</a>, and writer of various <a href="https://gumroad.com/jessealama">Racket books</a> and <a href="https://pkgd.racket-lang.org/pkgn/search?tags=author%3Ajesse%40serverracket.com">libraries</a>.</li>
 <li><a href="https://samth.github.io/">Sam Tobin-Hochstadt</a>. Sam is Researcher and Assistant Professor at Indiana University, a member of the core Racket team, and the brains behind Typed Racket and Pycket.</li>
 <li>and my private sponsor, who shall remain anonymous.</li></ul>

<p>If you wish to sponsor me and my work on Racket and Racket News - feel free to visit my <a href="https://github.com/sponsors/pmatos/">GitHub Sponsors</a> webpage. All sponsorship levels are welcome.</p>



<p>Thanks to</p>

<ul>
 <li>Jesse Alama</li>
 <li>Laurent Orseau</li>
 <li>Stephen De Gabrielle</li></ul>

<p>for their contributions to this issue.</p>



<p>This issue is brought to you by <a href="mailto:pmatos@linki.tools">Paulo Matos</a>. Any mistakes or inaccuracies are solely mine and they do not represent the views of the <a href="http://www.racket-lang.org/team.html">PLT Team</a>, who develop Racket.</p>

<p>I have also tried to survey the most relevant things that happened in Racket lang recently. If you have done something awesome, wrote a blog post or seen something that I missed - my apologies. <a href="mailto:pmatos@linki.tools">Let me know</a> so I can rectify it in the next issue.</p>
  
</article><p>Have you seen something cool related Racket? Send it in and we will feature it in the next issue.</p></div>]]>
            </description>
            <link>https://racket-news.com/2021/02/racket-news-issue-45.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26001174</guid>
            <pubDate>Tue, 02 Feb 2021 14:17:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: HTTP2SQL – Query any SQL database directly from an HTTP request]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26000928">thread link</a>) | @cosbgn
<br/>
February 2, 2021 | https://zero.sh/labs/http2sql | <a href="https://web.archive.org/web/*/https://zero.sh/labs/http2sql">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Http2SQL is a free api which will allow you to query any SQL database from an HTTP request.
It uses <a href="https://sequelize.org/" rel="nofollow noopener noreferrer" target="_blank">Sequelize</a> to handle the connection</p>
<p>It's free to use and doesn't require an API key or authentication. The code is available on <a href="https://github.com/Cosbgn/zero-labs/blob/master/api/http2sql.js" rel="nofollow noopener noreferrer" target="_blank">Github</a></p>
<p>With Zero you can build great interactive dashboards pulling data directly from your SQL database! It's free!
Give it a try at <a href="https://zero.sh/play" rel="nofollow noopener noreferrer" target="_blank">https://zero.sh/play</a></p>
<h2 id="1-make-sure-that-your-request-is-private-and-from-a-secure-connection">1. Make sure that your request is private and from a secure connection</h2>
<p>This API requires that you pass the entire database connection URI. This contains your username and password so never use this API directly from your frontend or from somewhere where users can access it.</p>
<p>If you use it on Zero.sh save your connection string on a <code>secret</code> and use that.</p>
<h2 id="2-format-your-request">2. Format your request</h2>
<p>This API accepts only <strong>POST</strong> requests to this endpoint: <code>https://labs.zero.sh/api/http2sql</code></p>
<p>The following data is allowed:</p>
<ul>
<li><strong>uri</strong>:
You database connection uri, e.g. <code>postgres:// ...</code>.</li>
<li><strong>query</strong>:
Your SQL query, e.g. <code>Select * from "Users"</code></li>
<li><strong>config_object</strong>:
If you don't want to pass the URI you can alternatively pass a <a href="https://sequelize.org/master/manual/getting-started.html" rel="nofollow noopener noreferrer" target="_blank">Sequelize connection object</a> - e.g. <code>{dialect: 'mysql', etc}</code></li>
</ul>
<p>You always need to pass a <code>query</code> and either the <code>uri</code> or the <code>config_object</code></p>
<h2 id="3-your-response">3. Your response</h2>
<p>The tool will either return and error or, in case of success the sequelize response. (Note: This can be null, for example <code>INSERT INTO</code> statements)</p>
<h2 id="4-an-example">4. An example:</h2>
<p>This is how you would create a table of users on Zero:</p>
<div><pre><code>

<span>const</span> post_data <span>=</span> <span>{</span>
  uri<span>:</span>secrets<span>.</span><span>db_uri</span><span>,</span> 
  query<span>:</span> <span><span>`</span><span>Select * from "Users"</span><span>`</span></span>
<span>}</span>
<span>const</span> <span>{</span>data<span>}</span> <span>=</span> <span>await</span> api<span>.</span><span>post</span><span>(</span><span>"https://labs.zero.sh/api/http2sql"</span><span>,</span> post_data<span>)</span>

<span>return</span> data
</code></pre></div>
<h2 id="questions">Questions?</h2>
<p>Feel free to send us an email at <a href="mailto:support@zero.sh">support@zero.sh</a> or open an issue on <a href="https://github.com/Cosbgn/zero-labs" rel="nofollow noopener noreferrer" target="_blank">Github</a></p></div></div></div>]]>
            </description>
            <link>https://zero.sh/labs/http2sql</link>
            <guid isPermaLink="false">hacker-news-small-sites-26000928</guid>
            <pubDate>Tue, 02 Feb 2021 13:52:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We don't need to boycott Wayland]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26000797">thread link</a>) | @soraminazuki
<br/>
February 2, 2021 | https://refi64.com/posts/dont-boycott-wayland.html | <a href="https://web.archive.org/web/*/https://refi64.com/posts/dont-boycott-wayland.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-content">
    
<div id="preamble">
<div>
<div id="teaser">
<div>
<p>If you couldn’t tell by the title, this is a response to
<a href="https://gist.github.com/probonopd/9feb7c20257af5dd915e3a9f2d1f2277">this gist</a>, stating
that we should boycott Wayland because something something Red Hat evil and breakage
and…​global menus? Well, there were quite a few exaggerations and misrepresentations in
the gist, which will be shown and explained here.</p>
</div>
</div>
</div>
</div>
<!-- Make all the headers smaller -->


<p>I’ll start off with this: many of the links are misquoted, some don’t even support the
points made with them, and some are highlighted supposed "broken" functionality with
either wrong dates or bugs that <em>have already been fixed</em>.</p>
<p>Yes, Wayland is different than Xorg. It was a complete re-imagining of how a modern and
less monolithic display protocol should look. Of course, breakage isn’t necessarily a
<em>good</em> thing…​but at the same time, some form of breakage is going to be inevitable. As
we’ll see soon, the breakage has mostly been confined to a few specific places (screen
capture most notably), where the current X way simply would not work with a more
secure protocol.</p>
<p>Now, I would be lying if I said this hasn’t taken a long time to develop, or that I
haven’t missed some of these features, but Linux apps and development are done by many
individual developers, whether volunteers or paid. As a result, a lot of work <em>does</em> take
a long time to complete. That being said, X’s current policy towards things like screen
capture and key binding is simply insecure, and it is inevitable that we will have to move
away from it eventually.</p>
<p>Furthermore, is it really worth throwing the entire protocol away for screen casting
(which works but needs more adoption) and…​global menus? I’ve been using Wayland on my
primary system for ages, and the flag workarounds for screen capture in Chromium (as
mentioned below) have been working fine for me. It’s not a perfect solution, but the
benefits Wayland provides have far exceeded the amount of time I’ve had to spend tweaking
the few things that weren’t working out of the box.</p>
<p>Some of Xorg’s core issues that required breakage to be solved in Wayland, such as it being
trivially easy to create keyloggers or view <em>any window without permissions</em> really are
things that you’d expect to see /r/linuxmasterrace mocking Windows over, not problems that
we should ignore on a supposedly secure system.</p>
<p>One more thing I’d like to add: <em>many of these links honestly make no sense as sources</em> or
were talking about entirely different things, with some discussion cherry-picked without
context. Without further ado…​</p>
<!-- Make all the headers smaller -->


<p>Screen recording has been available in Wayland for quite some time now, via
{link-pipewire} and {link-xdg-desktop-portal}. Now, the gist <em>does</em> make allusions to this:</p>
<div>
<blockquote>
<p>Or force more Red Hat/Gnome components (glib, Portals, Pipewire) on everyone! [...]
There is a workaround for OBS Studio that requires a obs-xdg-portal plugin (which is known
to be Red Hat/Flatpak-centric, GNOME-centric, "perhaps" works with other desktops)</p>
</blockquote>
</div>
<p>This is…​really, just completely wrong.</p>
<p>I have no idea why anything here would require clients to use GLib. All of the portal
APIs work over D-Bus, and Pipewire doesn’t even require GLib.</p>

<p>Even just looking at the
<a href="https://github.com/flatpak/xdg-desktop-portal/graphs/contributors">top contributors</a>,
we see contributions from employees of Collabora, Igalia, and Mozilla, not just Red Hat.</p>
<p>Pipewire also is not really a project that’s particularly tied to Red Hat; yes, the main
developer is from Red Hat, but he’s also a multimedia expert and one of the two creators
of <a href="https://en.wikipedia.org/wiki/GStreamer#Early_days">GStreamer</a> (a project founded while
the developer was still at Collabora). As of right now, Collabora is
<a href="https://www.collabora.com/about-us/open-source/open-source-projects/pipewire.html">a leading contributor to Pipewire as well</a>.
Even <a href="http://libregraphicsworld.org/blog/entry/podcast-ep-003-paul-davis-on-fixing-big-linux-audio-issues#main:~:text=PipeWire%20is%20an%20interesting%20project">
the creator of JACK is interested in Pipewire</a>, despite initially being skeptical.</p>
<p>A lot of the particular linked examples are just bizarre extrapolations:</p>

<p>This was targeting Linux screencasting <em>in general</em> as highlighted by the ffmpeg reference.</p>
<div>
<blockquote>
<p><a href="https://github.com/vkohaupt/vokoscreenNG/issues/51">https://github.com/vkohaupt/vokoscreenNG/issues/51</a> broken since at least 7 Mar 2020.
("I have now decided that there will be no Wayland support for the time being. Reason,
there is no budget for it. Let’s see how it looks in a year or two.") - This is the key
problem. Wayland breaks everything and then expects others to fix the wreckage it caused
on their own expense.</p>
</blockquote>
</div>
<p>Looks like I missed the part where the Wayland developers had the ability to update every
single project in existence and add full Wayland support. Better yet, the issue would
indicate more lack of time by the developer to be able to push updates, not that Wayland
"breaks everything".</p>

<p>Okay, this one is just laughable. An OBS developer also stated in the same thread:</p>
<div>
<blockquote>
<p>For reference X11 solutions are very close to the worst possible interface one could design.</p>
</blockquote>
</div>
<p>which would imply that we can’t really stay with X screencasting either, thus ruining the
entire "just stick with X argument".</p>
<p>Better yet, <a href="https://github.com/obsproject/rfcs/pull/14">there’s already an RFC open for
Wayland support</a>. All the portals they mentioned as "incomplete" do already support the
screencast APIs anyway, so their knowledge at the time about it was likely already
outdated.</p>
<p>Now onto "screen sharing", which is the same API problem as "screen casting", but let’s
entertain the idea that it’s actually two separate points:</p>
<div>
<blockquote>

<p><a href="https://github.com/jitsi/jitsi-meet/issues/6389">https://github.com/jitsi/jitsi-meet/issues/6389</a> broken since 24 Jan 2016 ("Closing since
there is nothing we can do from the Jitsi Meet side.") See? Wayland breaks stuff and
leaves application developers helpless and unable to fix the breakage, even if they wanted.</p>
</blockquote>
</div>
<p>First off…​this is two issues from the same repo. How does this count as two separate
breakages? I don’t even know where "2016" comes from, because the second issue was created
this year.</p>
<p>The quoted text was not in response to Wayland missing functionality; Pipewire already
existed at this point. Rather it was related to browsers implementing the screencast API.
This has been implemented in Chromium behind a flag for years at least, and it was only
behind a flag because parts of Chromium’s UI flow assumed there was no permissions model,
so it would ask the user to select a window to share after they already selected it in the
Wayland compositor. This is actively being worked on in both
<a href="https://webrtc-review.googlesource.com/c/src//189544[WebRTC]%20andhttps://chromium-review.googlesource.com/c/chromium/src//1942327">Chromium itself</a>.</p>

<div>
<blockquote>
<p><a href="https://github.com/flathub/us.zoom.Zoom/issues/22">https://github.com/flathub/us.zoom.Zoom/issues/22</a> Zoom broken since at least 4 Jan 2019.
("Can not start share, we only support wayland on GNOME with Ubuntu (17, 18), Fedora (25
to 29), Debian 9, openSUSE Leap 15, Arch Linux"). No word about non-GNOME!</p>
</blockquote>
</div>
<p>"Yes, let’s highlight a Linux client that is notoriously buggy and generally terrible."</p>
<!-- Make all the headers smaller -->


<p>Again, I don’t know why this is split into three sections. But first off:</p>

<p><strong>The issue had nothing to do with this, and this is a gross misquoting.</strong> The issue reads:</p>
<div>
<blockquote>
<p>This Gtk+4 fact, will be sad and will make Gtk+ unusable to the Gnome Global Menu
extension, as it’s implemented now. That’s why the Gnome Global Menu extension will be
discontinued again. The first reason was because the lack of the Gtk+ Wayland support for
the Global Menu, that was resolved here and now will be because Gtk+ will no longer
supports generic loadable modules.</p>
</blockquote>
</div>
<p>In other words, this issue was showing something unrelated, and at the time, Wayland
support was already working. The date used in the gist ("broken since 24 Aug 2018") is
also incorrect, since it’s pointing to the date the linked issue was filed, at which point
Wayland support was again working.</p>
<p>GTK’s own lack of support for global menus over Wayland itself had little to do with
Wayland and more to do with GTK itself not wanting to support global menus, as the current
global menu implementation was very closely targeting Xorg.</p>
<p>Next up:</p>

<p>In other words…​if you actually read the article, they were able to make it work on
Wayland <strong>without</strong> the re-engineering. In fact, the whole point of the article was to
highlight that they were able to get it to work.</p>
<div>
<blockquote>
<p>KDE had to do additional work to work around it. And it still did not work:</p>

</blockquote>
</div>
<p>The linked bug literally says this was fixed in 5.20.</p>

<p><strong>This is literally the same link as above</strong>. Why is this a separate point?</p>

<!-- Make all the headers smaller -->



<p><strong>Once again, this has been fixed:</strong></p>
<div>
<blockquote>
<p>The best solution is for Qt including the QPA platform plugin and having a proper
auto-detection based on XDG_SESSION_TYPE. The situation will improve with Qt 5.11, but it
doesn’t really help as the Qt LTS versions will continue to face the problem.</p>
<p>For now we implemented a change in Plasma 5.13 so that we don’t need to set the env variable
any more. Plasma is able to select the appropriate platform plugin based on XDG_SESSION_TYPE
environment variable. Non-Plasma processes will use the default platform plugin. With Qt
&lt; 5.11 this is xcb, with Qt 5.11 this will most likely change to wayland. KDE’s flatpak
applications pick Wayland by default in a Wayland session and are unaffected by the change.</p>
</blockquote>
</div>
<p>Really, I’d argue the actual problem is trying to bundle every individual dependency into
a single file and expecting the users to never have to add anything else? This is pretty
bizarre especially because it’s no different than having to include the global menu
platform plugin to make global menus work, which AppImages already need! In other words,
this is just an AppImage problem and its style clashing with the Qt reliance on various
forms of dynamically-loaded plugins.</p>
<!-- Make all the headers smaller -->


<p>The opening to the article says:</p>
<div>
<blockquote>
<p>Wayland solves no issues I have</p>
</blockquote>
</div>
<p>I’d like to make a quick jab at this statement: just because you don’t have issues doesn’t
imply that aren’t issues that others are stuck dealing with or fixing. Xorg’s APIs are
quite nasty, and developers have to deal with them. There are things that Wayland can
support easily but X cannot, and there are people who have to deal with those.</p>
<p><a href="https://www.linux-magazine.com/Online/Features/Is-Wayland-the-New-X">This article</a> covers
a few of the reasons X is a mess:</p>
<div>
<blockquote>
<p>Stone traces the earliest origins of Wayland to a page on the X.Org wiki started by Adam Jackson called X12. “It wasn’t a serious attempt at a design,” Stone stresses, “but a list of things we would do differently if we had a chance to rework the core protocol.”</p>
<p>For many developers, this list helped codify the problems …</p></blockquote></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://refi64.com/posts/dont-boycott-wayland.html">https://refi64.com/posts/dont-boycott-wayland.html</a></em></p>]]>
            </description>
            <link>https://refi64.com/posts/dont-boycott-wayland.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26000797</guid>
            <pubDate>Tue, 02 Feb 2021 13:38:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AirPods Max: An Audiophile Review]]>
            </title>
            <description>
<![CDATA[
Score 299 | Comments 358 (<a href="https://news.ycombinator.com/item?id=26000698">thread link</a>) | @drclau
<br/>
February 2, 2021 | https://mariusmasalar.me/airpods-max | <a href="https://web.archive.org/web/*/https://mariusmasalar.me/airpods-max">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>
          <p><a href="https://mariusmasalar.me/airpods-max">December 18, 2020</a></p>

		 <h4>Surprising sound let down by serious comfort problems</h4>

		 
<p><img src="https://marius.imgix.net/AirPodsMax-1.jpg?auto=compress&amp;q=75&amp;fit=clip&amp;w=1500&amp;s=6b8a0daf46384709fee2520ad544cdff"></p>
<p>I’m conflicted about Apple’s latest foray into audio products, the AirPods Max over-ear headphones.</p>
<p>In striking opposition to every other review I’ve seen so far, I get to begin mine by stating that I <em>am</em> an audiophile. A friendly, reasonable one, but still—<a href="https://mariusmasalar.me/plague-inc-the-cure">audio is my jam</a>. I’ve been writing music for games and film for over 10 years, so one would hope that I’ve learned a thing or two about audio production in that time. It is, therefore, my sworn duty to be skeptical of consumer technology companies encroaching on the territory of high-end audio equipment built by companies with decades of experience.</p>

<p>Apple has had a long and fruitful relationship with music, but their track record with audio hardware is inconsistent. Somehow, the company that makes the HomePod—a marvel of mono speaker engineering—is also the company that continues to make and sell Beats products. Beats are a common entry point into the world of audio, but they’re priced the way they are because of their brand power, not because their quality justifies it. You can get much better sound, comfort, features, and build for less money.</p>
<p>Today, I find myself wondering to what extent that is also true for the AirPods Max.</p>
<p>Having forked over just under $900 <span>CAD</span> for the privilege of owning a pair, I wanted to see whether Apple is aiming to establish itself as a purveyor of quality audio gear—deserving of a high price tag—or whether we’ll once again be paying for style over substance.</p>
<p><img src="https://marius.imgix.net/AirPodsMax-5.jpg?auto=compress&amp;q=75&amp;fit=clip&amp;w=1500&amp;s=3b6c49e79651f9f936486a7886ff54db"></p>

<p>I laughed when I pulled the AirPods Max out of their box. I knew they would be heavy, but the experience of that weight is really something else.</p>
<p>For context, the Sennheiser <span>PXC</span> 550—my current headphone choice for travel—weigh 227g. The famously comfortable Bose 700 weigh 254g, a weight that’s matched by the popular Sony WH-1000XM4. Premium pairs like the Bang &amp; Olufsen <span>H9</span> (third generation) weigh 295g, and the Bowers &amp; Wilkins <span>PX7</span> just barely crest the 300g mark.</p>
<p>The AirPods Max weigh <em>385g</em>.</p>
<p>In the same way that the iPhone 12’s aluminum build <em>looks</em> less fancy but <em>feels</em> nicer in use than its Pro counterparts and their stainless steel, the mostly-metal build of the AirPods Max is a choice that favours fashion over comfort.</p>
<p>The reason that other high-end headphone manufacturers lean heavily on plastic and even wood in their builds isn’t that they can’t afford metal. It’s because they’re interested in having human beings wear these products on their heads for hours at a time.</p>
<p>As one such human being with a head, I wish Apple had taken some cues from the competition on this front. Even after adjusting the way I wear them, I can’t escape the fact that these are just plain <em>uncomfortable</em> for long listening sessions. The mesh headband and foam ear cups do their best to mitigate this, but they can’t compensate for the sheer weight.</p>
<p>The headband is terrific. It may be my favourite approach to one that I’ve seen on a headphone. I have to wear the band further back on my head than I do with other headphones, but once I figured that out I was able to wear them for longer before needing a break. The ear cups are less impressive. They’re spacious and fairly well padded, but the material that’s used feels somewhat cheap and scratchy in texture. I suspect it’s more breathable than typical leather or vinyl ear cups, but the physical impression isn’t as good and I don’t particularly like how they feel on my face.</p>
<p>Then there’s the clamping force, which is <em>very</em> strong; AirPods Max squeeze your head like a musical bear hug. This is a common problem with heavy headphones, so I wasn’t surprised to see it here, but it accounts for the majority of the comfort problems I have.</p>
<p>The pressure points will differ depending on your fit, but I offered these to two other people in my vicinity for some extended listening and both reported discomfort; one on the top of their head, the other around their ears where the clamp force put pressure on the jaw. Personally, I experience it mainly as a headache after about the half hour to one hour mark.</p>
<p>Let’s disregard weight for a moment, though. These are fine for shorter listening sessions and everyone’s head is different, so I’m sure there are folks out there who will find them to be perfectly comfortable. The problems with metal go beyond weight: by prioritizing fashion value over practical value, Apple has committed a series of unforced errors.</p>
<p>Anodized aluminum feels nice and soft, but that softness means they scuff easily…like, say, when you fold them flat and notice that the ear cups bump and scratch against each other. This happens all the time and it makes me cringe every time; it’s like the horrible scraping that iMac users will be familiar with from trying to plug something into the rear ports. Also, parts of the world experience a season called winter, where the temperature drops and metal surfaces become dangerous things your skin will stick to.</p>
<p>Now, about that<span></span> <span>“</span>protective case”.</p>
<p><img src="https://marius.imgix.net/AirPodsMax-8.jpg?auto=compress&amp;q=75&amp;fit=clip&amp;w=1500&amp;s=392ed93e8e6a65298b215cf68f228603"></p>
<p>I want to save myself some typing and point you to <a href="https://youtu.be/Gvvo6vUpJRc?t=639" target="_blank">the part of <span>MKBHD</span><span></span><span>’</span>s review video</a> where he talks about the storage solution that these $900 headphones ship with. Go ahead and give that a watch. Back? Great. What he said. Before getting these, I thought the hate for the case was hyperbolic, but the truth is it really <em>does</em> feel cheap and pointless, particularly after <a href="https://support.apple.com/en-us/HT211886" target="_blank">Apple clarified</a> that it isn’t necessary for putting the headphones into standby mode.</p>
<p>Before we leave the topic of their physical design, I want to share one last complaint about the AirPods Max: the buttons. I don’t mind the feel of them myself (though a friend felt they were cheap and unpleasant), but I <em>do</em> mind the way they work. The Digital Crown, which controls volume, is also the button that controls playback and Siri. The other, larger button is used to switch between the listening modes: Active Noise Cancellation (<span>ANC</span>), Transparency mode, and none.</p>
<p>I appreciate having physical controls for these things, but I intuitively expected that all the audio-related functions would be accessed from one button and that the playback and feature controls would be accessed from the other. Tying playback controls to the volume knob feels strange to me, and increases the chances of unintentional volume changes when you’re trying to execute a double or triple press—something made even trickier if you’re wearing gloves.</p>
<p>There is, naturally, no way to configure these button assignments. At best, you’re able to change the scrolling direction of the volume knob and restrict which listening modes the other button switches between, but that’s about it. That latter feature also seems to be buggy in the current firmware (<span>3C16</span>) because despite enabling all three, I find that it defaults back to just Noise Cancellation or Transparency whenever I reconnect.</p>
<p>Deal-breaker? No.&nbsp;But another strange design choice to wrap up this section.</p>
<p><img src="https://marius.imgix.net/AirPodsMax-7.jpg?auto=compress&amp;q=75&amp;fit=clip&amp;w=1500&amp;s=f6b19d4c7ef961a06df1a759fc2f45b5"></p>
<p>Wait, one more complaint: the battery life is the shortest of any headphone in this category. This isn’t an issue in and of itself considering they’ll still last through a full day of listening. Still, I hoped that some of that excess size and weight would translate into battery capacity.</p>
<p>On the topic of power, Apple has indicated that the AirPods Max have two low-power states and you <em>don’t</em> need the case to access them—great news since I refuse to use that stupid thing. Here’s <a href="https://support.apple.com/en-us/HT211886" target="_blank">what they say</a>:</p>
<blockquote>
<p>If you set your AirPods Max down and leave them stationary for 5 minutes, they go into a low power mode to preserve battery charge. After 72 stationary hours out of the Smart Case, your AirPods Max go into a lower power mode that turns off Bluetooth and Find My to preserve battery charge further. If you put your AirPods Max in the Smart Case when you’re not using them, they go into a low power mode immediately to preserve battery charge. After 18 hours in the Smart Case, your AirPods Max go into an ultralow power mode that turns off Bluetooth and Find My and maximizes battery life.</p>
</blockquote>
<p>Okay, <em>now</em> I’m done talking about the physical characteristics.</p>
<h2 id="sonic-boom">Sonic Boom</h2>
<p>So there I was, shaking my head at the weight and the design while I got them connected. I was already looking up Apple’s holiday return policy when I hit play on my usual suite of test material and…oh.</p>
<p><em>Oh</em>.</p>
<p><img src="https://marius.imgix.net/AirPodsMax-4.jpg?auto=compress&amp;q=75&amp;fit=clip&amp;w=1500&amp;s=a34de6bb9c7c71b5c5ccbfad05e1c8f6"></p>
<p>I was reminded of <a href="http://toolsandtoys.net/reviews/the-bowers-wilkins-p7-wireless-headphones-review/" target="_blank">the first time</a> a pair of wireless headphones impressed me. I put them on and somehow found myself lying on the floor of my room, two hours later, having become completely lost in the music. Since then, <a href="https://mariusmasalar.me/bang-olufsen-h9i">other headphones</a> have achieved this magical time-dilation effect, but I didn’t expect to feel it coming from an Apple product.</p>
<p>Don’t get me wrong, Apple has amazing audio engineers. <a href="https://mariusmasalar.me/airpods-pro">I adore my AirPods Pro</a>. They’re not the best value for money in terms of sound, but they have a pleasant, relatively neutral profile and have become my daily listening companions. Similarly, the HomePod is my favourite smart speaker for sound because it manages to provide a remarkably full and dynamic listening experience for a compact mono sound source.</p>
<p>In a word, the AirPods Max sound <em>sublime</em>.</p>
<p>They have a beautiful way of making you feel immersed and enveloped by the music, with a tremendously wide soundstage, solid instrument placement, and some of the most articulate dynamics I’ve heard from consumer equipment. They remind me of my open-back studio headphone and amp setup (the geeky audiophile equipment) more than other wireless headphones.</p>
<p>Several hours of listening later, I wanted to make sure I wasn’t just experiencing some sort of hallucination caused by the extreme clamping force of these metallic behemoths, so I called up my friend and had him bring over his pair of Bang &amp; Olufsen H9i—<a href="https://thesweetsetup.com/articles/a-roundup-of-the-best-wireless-active-noise-cancelling-headphones/" target="_blank">my previous benchmark</a> for best wireless <span>ANC</span> headphones—to do some critical listening.</p>
<p>We cruised through our respective music libraries, selecting favourite tracks and listening, each of us with one of the pairs on. Then we’d swap <a href="https://atp.fm/409" target="_blank">(as others have pointed …</a></p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mariusmasalar.me/airpods-max">https://mariusmasalar.me/airpods-max</a></em></p>]]>
            </description>
            <link>https://mariusmasalar.me/airpods-max</link>
            <guid isPermaLink="false">hacker-news-small-sites-26000698</guid>
            <pubDate>Tue, 02 Feb 2021 13:28:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sigmund Jähn: Why isn't This Man a Hero? (2018)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26000696">thread link</a>) | @Tomte
<br/>
February 2, 2021 | https://www.zeit.de/wissen/geschichte/2018-08/sigmund-jaehn-first-german-in-space-gdr/komplettansicht | <a href="https://web.archive.org/web/*/https://www.zeit.de/wissen/geschichte/2018-08/sigmund-jaehn-first-german-in-space-gdr/komplettansicht">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <section>
                        <h3>zeit.de mit Werbung</h3>
                        <p>Um der Nutzung mit Werbung zuzustimmen, muss JavaScript in Ihrem Browser aktiviert sein.</p>
                    </section>
                    <section>
                        <div>
                            <header>
                                <h3>zeit.de mit Werbung</h3>
                            </header>
                            
            <p>Besuchen Sie zeit.de wie gewohnt mit Werbung und Tracking. Details zum Tracking finden Sie in der <a href="https://www.zeit.de/hilfe/datenschutz" data-ct-label="datenschutz_link">Datenschutzerklärung</a> und im <span data-pmid="222776" data-ct-label="privacy_manager_link">Privacy Center</span>.</p>
            
                            <div>
                                
                            </div>
                            
                        </div>
                        <div>
                            <div>
                                
                            </div>
                        </div>
                    </section>
                    <section>
                        <div>
                            <header>
                                <h3>zeit.de Pur</h3>
                            </header>
                            <p>Nutzen Sie zeit.de mit weniger Werbung und ohne Werbetracking für 1,20 €/Woche (für Digital-Abonnenten nur 0,40 €/Woche).</p>
                            <div>
                                <p><a href="https://premium.zeit.de/bestellung/1932788?angebot=https%3A%2F%2Fpremium.zeit.de%2Fbestellung%2F1932788&amp;entry_service=pur&amp;url=https%3A%2F%2Fmeine.zeit.de%2Fbestellung_abschliessen" data-ct-label="purabo_button" data-encode-level="1">
                                <span>zeit.de Pur: </span>Jetzt abonnieren
                            </a>
                            </p></div>
                            
                        </div>
                    </section>
                </div></div>]]>
            </description>
            <link>https://www.zeit.de/wissen/geschichte/2018-08/sigmund-jaehn-first-german-in-space-gdr/komplettansicht</link>
            <guid isPermaLink="false">hacker-news-small-sites-26000696</guid>
            <pubDate>Tue, 02 Feb 2021 13:28:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[1280×832 image synthesis with Visual Transformers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26000674">thread link</a>) | @giorgiop
<br/>
February 2, 2021 | https://compvis.github.io/taming-transformers/ | <a href="https://web.archive.org/web/*/https://compvis.github.io/taming-transformers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

		<!-- Banner -->
			

			<!-- One -->
				<section id="one">
					<div>
                    <p><img src="https://compvis.github.io/taming-transformers/paper/teaser.png" alt="">
                      <strong>TL;DR:</strong>
                      We combine the efficiancy of convolutional approaches with
                      the expressivity of transformers by introducing a
                      convolutional <em>VQGAN</em>, which learns a codebook of
                      context-rich visual parts, whose composition is modeled
                      with an autoregressive transformer.
                    </p>
						<div>
							
							<div>
                
                <p>
  Designed to learn long-range interactions on sequential data, transformers
  continue to show state-of-the-art results on a wide variety of tasks.  In
  contrast to CNNs, they contain no inductive bias that prioritizes local
  interactions. This makes them expressive, but also computationally infeasible
  for long sequences, such as high-resolution images.  We demonstrate how
  combining the effectiveness of the inductive bias of CNNs with the
  expressivity of transformers enables
  them to model and thereby synthesize high-resolution images.
  We show how to (i) use CNNs to learn a context-rich vocabulary of
  image constituents, and in turn (ii) utilize transformers to efficiently
  model their composition within high-resolution images.
  Our approach is readily applied to conditional synthesis tasks, where both
  non-spatial information, such as object classes, and spatial information,
  such as segmentations, can
  control the generated image.
  In particular, we present the first results on semantically-guided synthesis
  of megapixel images with transformers.
                </p>
							</div>
						</div>
            <!--
          <p style="text-align:center">Related work <br/><a
             href="https://compvis.github.io/iin/">"A Disentangling
             Invertible Interpretation Network for Explaining Latent
           Representations"</a></p>
					</div>
            -->
				</div></section>

			<!-- Two -->
				<section id="two">
					<div>
						<header>
							<h2>Results</h2>
							<p>and applications of our model.</p>
						</header>

            <div>
<div>
<div>
<p>
<video controls="">
<source src="https://compvis.github.io/taming-transformers/images/taming.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
</p><p>
Sampling landscapes conditioned on semantic layouts.
</p></div>
</div>
<div>

<div>
<p>
<video controls="">
<source src="https://compvis.github.io/taming-transformers/images/taming3d.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
</p><p>
Visualizing depth-to-image sampling in 3D.
</p></div>
</div>
</div>
<div>
<div>

<p><a href="https://compvis.github.io/taming-transformers/images/article-Figure2-1.jpg">
<img src="https://compvis.github.io/taming-transformers/images/article-Figure2-1.jpg" alt="">
</a>
Figure 2. Our approach uses a convolutional VQGAN to learn a codebook of context-rich visual parts, whose composition is subsequently modeled with an autoregressive transformer architecture. A discrete codebook provides the interface between these architectures and a patch-based discriminator enables strong compression while retaining high perceptual quality. This method introduces the efficiency of convolutional approaches to transformer based high resolution image synthesis.
</p>
</div>
<div>

<p><a href="https://compvis.github.io/taming-transformers/images/article-Table1-1.jpg">
<img src="https://compvis.github.io/taming-transformers/images/article-Table1-1.jpg" alt="">
</a>
Table 1. Comparing Transformer and PixelSNAIL architectures across different datasets and model sizes. For all settings, transformers outperform the state-of-the-art model from the PixelCNN family, PixelSNAIL in terms of NLL. This holds both when comparing NLL at fixed times (PixelSNAIL trains roughly 2 times faster) and when trained for a fixed number of steps. See Sec. 4.1 for the abbreviations.
</p>
</div>
</div>
<div>
<div>

<p><a href="https://compvis.github.io/taming-transformers/images/article-Figure5-1.jpg">
<img src="https://compvis.github.io/taming-transformers/images/article-Figure5-1.jpg" alt="">
</a>
Figure 5. Samples generated from semantic layouts on S-FLCKR. Sizes from top-to-bottom: 1280 × 832, 1024 × 416 and 1280 × 240 pixels. Best viewed zoomed in. A larger visualization can be found in the appendix, see Fig 13.
</p>
</div>
<div>

<p><a href="https://compvis.github.io/taming-transformers/images/article-Figure6-1.jpg">
<img src="https://compvis.github.io/taming-transformers/images/article-Figure6-1.jpg" alt="">
</a>
Figure 6. Applying the sliding attention window approach (Fig. 3) to various conditional image synthesis tasks. Top: Depth-to-image on RIN, 2nd row: Stochastic superresolution on IN, 3rd and 4th row: Semantic synthesis on S-FLCKR, bottom: Edge-guided synthesis on IN. The resulting images vary between 368 × 496 and 1024× 576, hence they are best viewed zoomed in.
</p>
</div>
</div>
<div>
<div>

<p><a href="https://compvis.github.io/taming-transformers/images/article-Figure11-1.jpg">
<img src="https://compvis.github.io/taming-transformers/images/article-Figure11-1.jpg" alt="">
</a>
Figure 11. Comparing our approach with the pixel-based approach of [7]. Here, we use our f = 16 S-FLCKR model to obtain high-fidelity image completions of the inputs depicted on the left (half completions). For each conditioning, we show three of our samples (top) and three of [7] (bottom).
</p>
</div>
<div>

<p><a href="https://compvis.github.io/taming-transformers/images/article-Figure12-1.jpg">
<img src="https://compvis.github.io/taming-transformers/images/article-Figure12-1.jpg" alt="">
</a>
Figure 12. Comparing our approach with the pixel-based approach of [7]. Here, we use our f = 16 S-FLCKR model to obtain high-fidelity image completions of the inputs depicted on the left (half completions). For each conditioning, we show three of our samples (top) and three of [7] (bottom).
</p>
</div>
</div>
<div>
<div>

<p><a href="https://compvis.github.io/taming-transformers/images/article-Figure4-1.jpg">
<img src="https://compvis.github.io/taming-transformers/images/article-Figure4-1.jpg" alt="">
</a>
Figure 4. Transformers within our setting unify a wide range of image synthesis tasks. We show 256 × 256 synthesis results across different conditioning inputs and datasets, all obtained with the same approach to exploit inductive biases of effective CNN based VQGAN architectures in combination with the expressivity of transformer architectures. Top row: Completions from unconditional training on ImageNet. 2nd row: Depth-to-Image on RIN. 3rd row: Semantically guided synthesis on COCO-Stuff (left) and ADE20K (right). 4th row: Pose-guided person generation on DeepFashion. Bottom row: Class-conditional samples on RIN.
</p>
</div>
<div>

<p><a href="https://compvis.github.io/taming-transformers/images/article-Figure23-1.jpg">
<img src="https://compvis.github.io/taming-transformers/images/article-Figure23-1.jpg" alt="">
</a>
Figure 23. Unconditional samples from a model trained on LSUN Churches &amp; Towers, using the sliding attention window.
</p>
</div>
</div>
<div>
<div>

<p><a href="https://compvis.github.io/taming-transformers/images/article-Figure13-1.jpg">
<img src="https://compvis.github.io/taming-transformers/images/article-Figure13-1.jpg" alt="">
</a>
Figure 13. Samples generated from semantic layouts on S-FLCKR. Sizes from top-to-bottom: 1280 × 832, 1024 × 416 and 1280 × 240 pixels.
</p>
</div>
<div>

<p><a href="https://compvis.github.io/taming-transformers/images/article-Figure14-1.jpg">
<img src="https://compvis.github.io/taming-transformers/images/article-Figure14-1.jpg" alt="">
</a>
Figure 14. Samples generated from semantic layouts on S-FLCKR. Sizes from top-to-bottom: 1536× 512, 1840× 1024, and 1536× 620 pixels.
</p>
</div>
</div>
<div>
<div>

<p><a href="https://compvis.github.io/taming-transformers/images/article-Figure15-1.jpg">
<img src="https://compvis.github.io/taming-transformers/images/article-Figure15-1.jpg" alt="">
</a>
Figure 15. Samples generated from semantic layouts on S-FLCKR. Sizes from top-to-bottom: 2048× 512, 1460× 440, 2032× 448 and 2016× 672 pixels.
</p>
</div>
<div>

<p><a href="https://compvis.github.io/taming-transformers/images/article-Figure16-1.jpg">
<img src="https://compvis.github.io/taming-transformers/images/article-Figure16-1.jpg" alt="">
</a>
Figure 16. Samples generated from semantic layouts on S-FLCKR. Sizes from top-to-bottom: 1280 × 832, 1024 × 416 and 1280 × 240 pixels.
</p>
</div>
</div>
<div>
<div>

<p><a href="https://compvis.github.io/taming-transformers/images/article-Figure17-1.jpg">
<img src="https://compvis.github.io/taming-transformers/images/article-Figure17-1.jpg" alt="">
</a>
Figure 17. Depth-guided neural rendering on RIN with f = 16 using the sliding attention window.
</p>
</div>
<div>

<p><a href="https://compvis.github.io/taming-transformers/images/article-Figure18-1.jpg">
<img src="https://compvis.github.io/taming-transformers/images/article-Figure18-1.jpg" alt="">
</a>
Figure 18. Depth-guided neural rendering on RIN with f = 16 using the sliding attention window.
</p>
</div>
</div>
<div>
<div>

<p><a href="https://compvis.github.io/taming-transformers/images/article-Figure19-1.jpg">
<img src="https://compvis.github.io/taming-transformers/images/article-Figure19-1.jpg" alt="">
</a>
Figure 19. Intentionally limiting the receptive field can lead to interesting creative applications like this one: Edge-to-Image synthesis on IN with f = 8, using the sliding attention window.
</p>
</div>
<div>

<p><a href="https://compvis.github.io/taming-transformers/images/article-Figure20-1.jpg">
<img src="https://compvis.github.io/taming-transformers/images/article-Figure20-1.jpg" alt="">
</a>
Figure 20. Additional results for stochastic superresolution with an f = 16 model on IN, using the sliding attention window.
</p>
</div>
</div>
<div>
<div>

<p><a href="https://compvis.github.io/taming-transformers/images/article-Figure21-1.jpg">
<img src="https://compvis.github.io/taming-transformers/images/article-Figure21-1.jpg" alt="">
</a>
Figure 21. Samples generated from semantic layouts on S-FLCKR with f = 16, using the sliding attention window.
</p>
</div>
<div>

<p><a href="https://compvis.github.io/taming-transformers/images/article-Figure22-1.jpg">
<img src="https://compvis.github.io/taming-transformers/images/article-Figure22-1.jpg" alt="">
</a>
Figure 22. Samples generated from semantic layouts on S-FLCKR with f = 32, using the sliding attention window.
</p>
</div>
</div>
<div>
<div>

<p><a href="https://compvis.github.io/taming-transformers/images/article-Figure7-1.jpg">
<img src="https://compvis.github.io/taming-transformers/images/article-Figure7-1.jpg" alt="">
</a>
Figure 7. Evaluating the importance of effective codebook for HQ-Faces (CelebA-HQ and FFHQ) for a fixed sequence length |s|= 16·16 = 256. Globally consistent structures can only be modeled with a context-rich vocabulary (right). All samples are generated with temperature t = 1.0 and top-k sampling with k = 100. Last row reports the speedup over the f1 baseline which operates directly on pixels and takes 7258 seconds to produce a sample on a NVIDIA GeForce GTX Titan X.
</p>
</div>
<div>

<p><a href="https://compvis.github.io/taming-transformers/images/article-Figure8-1.jpg">
<img src="https://compvis.github.io/taming-transformers/images/article-Figure8-1.jpg" alt="">
</a>
Figure 8. Trade-off between negative log-likelihood (nll) and reconstruction error. While context-rich encodings obtained with large factors f allow the transformer to effectively model long-range interactions, the reconstructions capabilities and hence quality of samples suffer after a critical value (here, f = 16). For more details, see Sec. B.
</p>
</div>
</div>
<div>
<div>

<p><a href="https://compvis.github.io/taming-transformers/images/article-Figure9-1.jpg">
<img src="https://compvis.github.io/taming-transformers/images/article-Figure9-1.jpg" alt="">
</a>
Figure 9. We compare the ability of VQVAEs and VQGANs to learn perceptually rich encodings, which allow for high-fidelity reconstructions with large factors f . Here, using the same architecture and f = 16, VQVAE reconstructions are blurry and contain little information about the image, whereas VQGAN recovers images faithfully. See also Sec. B.
</p>
</div>
<div>

<p><a href="https://compvis.github.io/taming-transformers/images/article-Figure10-1.jpg">
<img src="https://compvis.github.io/taming-transformers/images/article-Figure10-1.jpg" alt="">
</a>
Figure 10. Samples on landscape dataset (left) obtained with different factors f , analogous to Fig. 7. In contrast to faces, a factor of f = 32 still allows for faithful reconstructions (right). See also Sec. B.
</p>
</div>
</div>
<div>
<div>

<p><a href="https://compvis.github.io/taming-transformers/images/article-Figure24-1.jpg">
<img src="https://compvis.github.io/taming-transformers/images/article-Figure24-1.jpg" alt="">
</a>
Figure 24. Additional 256× 256 results on the ADE20K dataset.
</p>
</div>
<div>

<p><a href="https://compvis.github.io/taming-transformers/images/article-Figure25-1.jpg">
<img src="https://compvis.github.io/taming-transformers/images/article-Figure25-1.jpg" alt="">
</a>
Figure 25. Additional 256× 256 results on the COCO-Stuff dataset.
</p>
</div>
</div>
<div>
<div>

<p><a href="https://compvis.github.io/taming-transformers/images/article-Figure26-1.jpg">
<img src="https://compvis.github.io/taming-transformers/images/article-Figure26-1.jpg" alt="">
</a>
Figure 26. Conditional samples for the depth-to-image model on IN.
</p>
</div>
<div>

<p><a href="https://compvis.github.io/taming-transformers/images/article-Figure27-1.jpg">
<img src="https://compvis.github.io/taming-transformers/images/article-Figure27-1.jpg" alt="">
</a>
Figure 27. Conditional samples for the pose-guided synthesis model via keypoints on DeepFashion.
</p>
</div>
</div>
<div>
<div>

<p><a href="https://compvis.github.io/taming-transformers/images/article-Figure28-1.jpg">
<img src="https://compvis.github.io/taming-transformers/images/article-Figure28-1.jpg" alt="">
</a>
Figure 28. Samples produced by the class-conditional model trained on RIN.
</p>
</div>
<div>

<p><a href="https://compvis.github.io/taming-transformers/images/article-Figure29-1.jpg">
<img src="https://compvis.github.io/taming-transformers/images/article-Figure29-1.jpg" alt="">
</a>
Figure 29. Samples synthesized by the class-conditional IN model.
</p>
</div>
</div>
<div>
<div>

<p><a href="https://compvis.github.io/taming-transformers/images/article-Figure30-1.jpg">
<img src="https://compvis.github.io/taming-transformers/images/article-Figure30-1.jpg" alt="">
</a>
Figure 30. Top: All sequence permutations we investigate, illustrated on a 4× 4 grid. Bottom: The transformer architecture is permutation invariant but next-token prediction is not: The average loss on the validation split of ImageNet, corresponding to the negative log-likelihood, differs significantly between different prediction orderings. Among our choices, the commonly used row-major order performs best.
</p>
</div>
<div>

<p><a href="https://compvis.github.io/taming-transformers/images/article-Figure31-1.jpg">
<img src="https://compvis.github.io/taming-transformers/images/article-Figure31-1.jpg" alt="">
</a>
Figure 31. Random samples from transformer models trained with different orderings for autoregressive prediction as described in Sec. 4.4.
</p>
</div>
</div>


				  </div>
				</section>

<!-- related works !-->

				<section id="one">
					<div>
						<div>
<p>
  <h4>Related Work on Modular Compositions of Deep Learning Models</h4>
</p>


<div>
  <p><a href="https://compvis.github.io/net2net/">
      <img src="https://compvis.github.io/net2net/paper/teaser.png">
    </a>
  </p>
</div>
<p>
  Given the ever-increasing computational costs of modern machine learning models, we need to find new ways to reuse such expert models and thus tap into the resources that have been invested in their creation. Recent work suggests that the power of these massive models is captured by the representations they learn. Therefore, we seek a model that can relate between different existing representations and propose to solve this task with a conditionally invertible network. This network demonstrates its capability by (i) providing generic transfer between diverse domains, (ii) enabling controlled content synthesis by allowing modification in other domains, and (iii) facilitating diagnosis of existing representations by translating them into interpretable domains such as images. Our domain transfer network can translate between fixed representations without having to learn or finetune them. This allows users to utilize various existing domain-specific expert models from the literature that had been trained with extensive computational resources. Experiments on diverse conditional image synthesis tasks, competitive image modification results and experiments on …</p></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://compvis.github.io/taming-transformers/">https://compvis.github.io/taming-transformers/</a></em></p>]]>
            </description>
            <link>https://compvis.github.io/taming-transformers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26000674</guid>
            <pubDate>Tue, 02 Feb 2021 13:26:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A New Beginning]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26000183">thread link</a>) | @bengtan
<br/>
February 2, 2021 | https://bengtan.com/blog/a-new-beginning/ | <a href="https://web.archive.org/web/*/https://bengtan.com/blog/a-new-beginning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
<div>
  <article>
    

    

    
    <p>This blog represents a new beginning and I’m both excited and trepidatious.</p>
<p>You see, I’ve considered blogging at one time or another over the last 15-20 years, but I’ve always been too busy with more important or fun ‘stuff’. Everytime I think about it, it sounds like a great idea … and then it fizzles out.</p>
<p>I have a history of building things. Software/tech/web things that are supposed to make money. Call them micro-startups or side projects or lifestyle businesses or whatever. I’ve done a smattering of them.</p>
<p>Aside from jobs and freelancing gigs, I would spend my discretionary time on building something … that I hoped would make money. It’s great fun.</p>
<p>Except when they don’t make money. Then it’s just a time sink.</p>
<p>Of the things that I’ve tried to monetise, sometimes the results were modest. Other times, the results were mediocre or downright terrible.</p>
<p>In my most recent project, I wrote a <a href="http://www.gigobooks.com/">non-subscription accounting app</a> for people with gigs or simple affairs. I had a lot of fun writing it. And I use it for myself (ie. dogfooding) too. Awesome!</p>
<p>I’ve spent the better part of nine months building it and I’ve shipped the MVP. Problem is … Where are my users?</p>
<p>Uh, oh.</p>
<p>It’s happened again.</p>
<p>I built something. And the users aren’t coming. Even worse, this time, they don’t even know about it.</p>
<p>I have tried to get some word out and I’ve posted on various forums over the Internet. I’ve got a tiny trickle of people who visit the website and then, AFAICT, don’t come back. That’s about it. No one (other than myself) is actually using the app.</p>
<p>Granted, I didn’t spend a lot of time doing ‘marketing’ things, but I did spend <em>some</em> time, and the results have been underwhelming. It also doesn’t help that I have no pre-existing audience. No blog, no twitter followers. Nada.</p>
<p>Distribution is a hard problem. Maybe it’s sometimes even harder than writing software. Lack of distribution has killed my previous projects before. Several times. If I don’t solve this problem, it’s going to kill this latest project too.</p>
<p>So I took a step back and thought about things.</p>
<p>* * *</p>
<p>I need to learn how to do distribution. And marketing and all that other stuff.</p>
<p>I can build things, but if I can’t reach users, then what’s the point?</p>
<p>On my to-do list of marketing activities, I had ‘content marketing’ ie. writing articles and blogging. Maybe I should jump straight to it and give it a try.</p>
<p>A related thought … There are numerous posts on the Internet about people who are making X thousands of dollars N months after launching, or they do a kickstarter project and smash through the funding target.</p>
<p>The common thread? They already had an email newsletter of 3000 readers, or they had 10000 twitter followers, or they were already a well-known member of an existing forum, or something.</p>
<p>I don’t have that.</p>
<p>But if I want to solve distribution, I’m gonna need something like that. I need people who are reading what I’m writing. I need to interact with people who I can bounce ideas off. I need people who I can reach.</p>
<p>Alright. Fine.</p>
<p>Let’s give this content-marketing/blogging thing a try. Let’s learn more about ‘marketing stuff’.</p>
<p>But let’s not just read about it. Let’s do it.</p>
<p>So I’m gonna write a blog, get some practical experience at content marketing, and see how things go.</p>
<p>Either it’s going to work: The next time I launch a new project, it will be more likely to succeed as I’ll be better at distribution (hopefully).</p>
<p>Or it’s not going to work: I should stop building things and concentrate on paid work instead.</p>
<p>* * *</p>
<p>So I’m gonna write a blog.</p>
<p>But let’s refine the idea a bit more.</p>
<p>I don’t want to do something where I’m blatantly blogging just to monetise or to push a sale. I don’t want to be a shill for my next project (whatever that might be). It’s not all just about money.</p>
<p>I want to write about stuff I’m interested in (Software, technology, startups, life, etc.). Otherwise it’ll turn in a drag and I’ll lose motivation. There has to be some intrinsic value in it too.</p>
<p>Having opened my mind to the idea of blogging, I’ve suddenly had a lot of ideas for things to write about. Things that my subconscious has always wanted to talk about but never got the chance.</p>
<p>I’m excited. Yes, it’s new and very different from building things, but it sounds like it could be fun too. (I’m also a little nervous) Hopefully, it also turns out well.</p>
<p>I spent most of nine months writing Gig’o’Books. Imagine if I spent nine months blogging. I wonder what the results would be? Only one way to find out.</p>
<p>So here I am. A new beginning. Let’s do it.</p>
<p>Wish me luck!</p>

    
      



    
  </article>


</div>
    </div></div>]]>
            </description>
            <link>https://bengtan.com/blog/a-new-beginning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26000183</guid>
            <pubDate>Tue, 02 Feb 2021 12:28:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Create Kubernetes federated clusters on AWS]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26000141">thread link</a>) | @tbobm
<br/>
February 2, 2021 | https://particule.io/en/blog/aws-federated-eks/ | <a href="https://web.archive.org/web/*/https://particule.io/en/blog/aws-federated-eks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

<section>
    <div>
        <div>
            <div>
              <p><a href="https://particule.io/en/blog/">&lt; Back </a>
                <img src="https://particule.io/images/thumbnails/eks.png" alt="Post-Image"></p>
                <p><span>By</span>
                    Theo "Bob" Massard
                    <span>at</span>
                    <span>January 21, 2021</span>
                </p>
                <p>AWS recently introduced <a href="https://aws.amazon.com/about-aws/whats-new/2021/01/introducing-federated-amazon-eks-clusters-aws/">their new solution</a> to orchestrate Federated EKS Clusters. The solution
is based on kubefed and deploys an infrastructure with a bastion cluster to operate the clusters
and two EKS clusters in different regions. You can now have highly available EKS setup bootstrapped
using a CloudFormation template in less than an hour.</p>
<h3 id="but-first-what-is-kubefed-">But first, what is kubefed ?</h3>
<p>Kubefed (for “Kubernetes Cluster Federation”) allows to orchestrate multiple Kubernetes Cluster
by exposing a high-level control pane. Your kubernetes clusters can join the federation cluster
allowing you to create <code>Federated</code> CRDs.</p>
<p>Kubefed repository: <a href="https://github.com/kubernetes-sigs/kubefed">https://github.com/kubernetes-sigs/kubefed</a></p>
<p>By doing so, you can create <a href="https://github.com/kubernetes-sigs/kubefed/blob/master/docs/userguide.md#replicaschedulingpreference">distributed deployments accross multiple clusters</a>
and even share resources such as <code>ConfigMap</code> or <code>Secret</code>.</p>
<p>Using Amazon’s Federated EKS, we will setup a kubefedctl bastion and provision two
EKS Clusters using <code>eksctl</code> to create a multi-region federated Kubernetes cluster.</p>
<p><img src="https://particule.io/images/kubefed-cluster.png" alt="kubefed clusters">
<em>kubefed-based clusters concept</em></p>
<h3 id="what-is-federated-amazon-eks-">what is Federated Amazon EKS ?</h3>
<p>The Federated Amazon EKS is a solution aiming to facilitate the deployment of a kubefed-based
multi-cluster infrastructure, using CloudFormation templates. The template provides a way of
creating a bastion host that will act as the kubefed control plane.</p>
<p>This bastion will be bootrstrapped with all the necessary utilities, such as:</p>
<ul>
<li><code>eksfedctl</code> for federation administration</li>
<li><code>eksctl</code> for cluster configuration</li>
<li><code>kubectl</code> pre-configured to be used in the federation cluster context</li>
</ul>
<p>Implementation guide: <a href="https://aws.amazon.com/solutions/implementations/federated-amazon-eks-clusters-on-aws/">federated-amazon-eks-clusters-on-aws</a></p>
<p>In order to setup a Federated Amazon EKS cluster, we will do the following:</p>
<ul>
<li>Apply the bastion host CloudFormation template</li>
<li>Run <code>eksfedctl</code> to create EKS clusters in the appropriate regions</li>
<li>Ensure the federated EKS clusters are properly setup</li>
</ul>
<p>The eksfedctl utility will automatically provision the required infrastructure, VPCs, subnets and
setup VPC peering between the bastion host’s VPC and the EKS Clusters’ VPCs.</p>
<p><img src="https://d1.awsstatic.com/Solutions/Solutions%20Category%20Template%20Draft/Solution%20Architecture%20Diagrams/federated-eks-clusters-ra.12d7f93988d634ebf16d60ed4be42a0bac92c7ed.png" alt="Federated Amazon EKS Cluster architecture">
<em>Federated Amazon EKS Cluster architecture - © Credits AWS</em></p>
<h3 id="lets-try-it-out">let’s try it out</h3>
<p><em>Pre-requisite: Make sure you have the sufficient permissions to create the resources mentioned above.
A user policy example is available in the <a href="https://raw.githubusercontent.com/awslabs/federated-amazon-eks-clusters-on-aws/master/source/solution-user-policy.json">awslabs/federated-amazon-eks-clusters</a> repository.</em></p>
<h4 id="provision-the-bastion-template">provision the bastion template</h4>
<p>The CloudFormation template for the bastion is pretty straight-forward. Beside the region,
there is no need to configure much, except some extra tags or the default bastion’s instance
type. The template is available at the following address:</p>
<p><a href="https://s3.amazonaws.com/solutions-reference/federated-amazon-eks-clusters-on-aws/latest/federated-amazon-eks-clusters-on-aws.template">federated-amazon-eks-clusters-on-aws.template</a></p>
<p>The default template’s bastion is a <code>t3.micro</code> instance which will be used to provision
the EKS clusters.</p>
<h4 id="setup-your-federated-eks-clusters">setup your federated EKS clusters</h4>
<p>Once the bastion is up and running, we can access it and provision our clusters.</p>
<pre><code data-lang="console">$ tmux  # the eksfedctl executable requires to be run
$ eksfedctl create --regions us-east-1 us-east-2
</code></pre><p><code>eksfedctl</code> will take care of:</p>
<ul>
<li>Creating the VPC, the subnets, peering the VPCs together</li>
<li>Creating the EKS Cluster, provisioning the instances, scaling groups</li>
<li>Configuring the EKS Clusters to join the federated cluster</li>
</ul>
<p>This might take a while, as it involves quite a few operations. Each child
CloudFormation stack is available in its own region.</p>
<p>Upon succesful termination of the <code>eksfedctl</code> command, we can observe our
freshly created clusters by running:</p>
<pre><code data-lang="console">$ kubectl -n kube-federation-system get kubefedclusters
NAME              AGE   READY
federated-eks-1   3s   True
federated-eks-2   1s   True
</code></pre><h4 id="using-the-federated-clusters">using the federated clusters</h4>
<p>We can now try out kubefed’s features, by setting a NameSpace as federated.</p>
<pre><code data-lang="console">$ kubectl create ns federate-me
namespace/federate-me created
$ kubefedctl federate ns federate-me
I0121 13:36:23.823163     843 federate.go:472] Resource to federate is a namespace. Given namespace will itself be the container for the federated namespace
I0121 13:36:23.837406     843 federate.go:501] Successfully created FederatedNamespace "federate-me/federate-me" from Namespace
</code></pre><p>Kubefed also provides the ability to propagate specific resources:</p>
<pre><code data-lang="console">$ kubectl create cm -n federate-me my-cm --from-literal=data=bob
configmap/my-cm created
$ kubefedctl -n federate-me federate configmap my-cm
I0121 13:41:12.032669     878 federate.go:501] Successfully created FederatedConfigMap "federate-me/my-cm" from ConfigMap
</code></pre><p>When using the <code>federate</code> verb, kubefed create a FederatedResource (such as a <code>FederatedConfigMap</code>)
and begins propagating the resource to the federated clusters.</p>
<p>Describing the FederatedResource allows visualising the propagation state:</p>
<div><pre><code data-lang="yaml"><span>Name</span>:         data-cm
<span>Namespace</span>:    federate-me
<span>Labels</span>:       &lt;none&gt;
<span>Annotations</span>:  &lt;none&gt;
<span>API Version</span>:  types.kubefed.io/v1beta1
<span>Kind</span>:         FederatedConfigMap
<span>Metadata</span>: <span># ...</span>
<span>Spec</span>:
  <span>Placement</span>:
    <span>Cluster Selector</span>:
      <span>Match Labels</span>:
  <span>Template</span>:
    <span>Data</span>:
      <span>Data</span>:  bob
<span>Status</span>:
  <span>Clusters</span>:
    <span>Name</span>:  federated-eks<span>-2</span>
    <span>Name</span>:  federated-eks<span>-1</span>
  <span>Conditions</span>:
    <span>Last Transition Time</span>:  <span>2021-01-21T14:00:02Z</span>
    <span>Last Update Time</span>:      <span>2021-01-21T14:00:02Z</span>
    <span>Status</span>:                True
    <span>Type</span>:                  Propagation
  <span>Observed Generation</span>:     <span>1</span>
<span>Events</span>:
  Type     Reason                 Age   From                           Message
  ----     ------                 ----  ----                           ------<span>-
</span><span>  Normal   CreateInCluster        25m   federatedconfigmap-controller  Creating ConfigMap "federate-me/data-cm" in cluster "federated-eks-1"</span>
  Normal   CreateInCluster        25m   federatedconfigmap-controller  Creating ConfigMap <span>"federate-me/data-cm"</span> in cluster <span>"federated-eks-2"</span>
  Warning  CreateInClusterFailed  25m   federatedconfigmap-controller  Failed to create ConfigMap <span>"federate-me/data-cm" in cluster "federated-eks-1": </span>An update will be attempted instead of a creation due to an existing resource
</code></pre></div><p><em>example output from a federated resource description</em></p>
<p>As previously mentionned, federated clusters go way beyond “simply” sharing configs and secrets.
This setup allows you to leverage the power <code>ReplicaSchedulingPreference</code> by targeting
FederatedDeployments and applying weight to different clusters, but also
<a href="https://github.com/kubernetes-sigs/kubefed/blob/master/docs/userguide.md#multi-cluster-ingress-dns">Multi-Cluster Ingress DNS</a> and <a href="https://github.com/kubernetes-sigs/kubefed/blob/master/docs/userguide.md#multi-cluster-service-dns">Multi-Cluster Service DNS</a>.</p>
<h3 id="deploying-an-application">deploying an application</h3>
<p>We will deploy a Hello World application using our freshly created Federated cluster.
A <code>Deployment</code> is registered under the default API-group, therefore the <code>FederatedDeployment</code>
is available without further configuration.</p>
<div><pre><code data-lang="yaml">---
<span>apiVersion</span>: types.kubefed.io/v1beta1
<span>kind</span>: FederatedDeployment
<span>metadata</span>:
  <span>name</span>: test-hello-world
  <span>namespace</span>: federate-me
<span>spec</span>:
  <span>template</span>:
    <span>metadata</span>:
      <span>labels</span>:
        <span>app</span>: hello-world
    <span>spec</span>:
      <span>replicas</span>: <span>3</span>
      <span>selector</span>:
        <span>matchLabels</span>:
          <span>app</span>: hello-world
      <span>template</span>:
        <span>metadata</span>:
          <span>labels</span>:
            <span>app</span>: hello-world
        <span>spec</span>:
          <span>tolerations</span>:
            - <span>effect</span>: NoExecute
              <span>key</span>: node.kubernetes.io/unreachable
              <span>operator</span>: Exists
              <span>tolerationSeconds</span>: <span>30</span>
            - <span>effect</span>: NoExecute
              <span>key</span>: node.kubernetes.io/not-ready
              <span>operator</span>: Exists
              <span>tolerationSeconds</span>: <span>30</span>
          <span>containers</span>:
            - <span>image</span>: particule/helloworld
              <span>name</span>: helloworld
  <span>placement</span>:
    <span>clusterSelector</span>: {}
</code></pre></div><p><em>Deploy a hello-world application using FederatedDeployment</em></p>
<p>This <code>FederatedDeployment</code> will create a Deployment with a single container
named helloworld based on the image <code>particule/helloworld</code>. The 3 replicas
requested will be split amongst the two registered federated clusters. We can increase
the replica count accross the clusters using a <code>ReplicaSchedulingPreference</code>
with the same namespace/name as our <code>FederatedDeployment</code> and by setting
the <code>.spec.totalReplicas</code> count with the the new value of 7.</p>
<div><pre><code data-lang="yaml">---
<span>apiVersion</span>: scheduling.kubefed.io/v1alpha1
<span>kind</span>: ReplicaSchedulingPreference
<span>metadata</span>:
  <span>name</span>: test-hello-world
  <span>namespace</span>: federate-me
<span>spec</span>:
  <span>targetKind</span>: FederatedDeployment
  <span>totalReplicas</span>: <span>7</span>
  <span>rebalance</span>: <span>true</span>
</code></pre></div><p><em>Edit the number of replicas accross clusters</em></p>
<p>It might take a few moments to propagate the new deployment but after a while, the
federated clusters will have the required number of replicas for our hello-world app.</p>
<pre><code data-lang="console">$ kubectl get pods -lapp=hello-world -n federate-me -o wide --context=federated-eks-1
NAME                               READY   STATUS    RESTARTS   AGE     IP              NODE
test-hello-world-d6d58457b-bkbl5   1/1     Running   0          4m46s   172.21.79.120   ip-172-21-87-11.eu-west-1.compute.internal
test-hello-world-d6d58457b-mz9d5   1/1     Running   0          4m46s   172.21.86.18    ip-172-21-87-11.eu-west-1.compute.internal
test-hello-world-d6d58457b-ndfrr   1/1     Running   0          4m46s   172.21.90.117   ip-172-21-87-11.eu-west-1.compute.internal
$ kubectl get pods -lapp=hello-world -n federate-me -o wide --context=federated-eks-2
NAME                               READY   STATUS    RESTARTS   AGE     IP              NODE
test-hello-world-d6d58457b-5nwdt   1/1     Running   0          4m35s   172.22.91.188   ip-172-22-92-176.eu-west-2.compute.internal
test-hello-world-d6d58457b-fh59n   1/1     Running   0          4m35s   172.22.66.58    ip-172-22-92-176.eu-west-2.compute.internal
test-hello-world-d6d58457b-tqvvm   1/1     Running   0          4m35s   172.22.65.158   ip-172-22-92-176.eu-west-2.compute.internal
test-hello-world-d6d58457b-xh4x6   1/1     Running   0          105s    172.22.77.219   ip-172-22-92-176.eu-west-2.compute.internal
</code></pre><p><em>Example output from ReplicaSchedulingPreference with replicas=7</em></p>
<p>As for the Deployment resource kind, the <code>Service</code> resource does not require
any additional configuration to be configured using a <code>FederatedService</code>.
This will ensure that both our clusters can expose our applications through their own Service.</p>
<div><pre><code data-lang="yaml">---
<span>apiVersion</span>: types.kubefed.io/v1beta1
<span>kind</span>:…</code></pre></div></div></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://particule.io/en/blog/aws-federated-eks/">https://particule.io/en/blog/aws-federated-eks/</a></em></p>]]>
            </description>
            <link>https://particule.io/en/blog/aws-federated-eks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26000141</guid>
            <pubDate>Tue, 02 Feb 2021 12:24:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AQT and collaborators demonstrate 24 qubit entanglement]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26000100">thread link</a>) | @EvgeniyZh
<br/>
February 2, 2021 | https://www.aqt.eu/24-qubit-entanglement/ | <a href="https://web.archive.org/web/*/https://www.aqt.eu/24-qubit-entanglement/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
		<a href="#content">Skip to content</a>

	<div id="boxed-wrapper">
		
		<div id="wrapper">
			
			
				
			<header>
				
				
			</header>
							
				
		
				
				
			
			
						<main id="main">
				<div>

<section id="content">
	
					<article id="post-1294">
										<span>AQT and collaborators demonstrate 24 qubit entanglement</span>
			
				
						<div>
				<div><div><div><div><div><p>January 2021:&nbsp;We at AQT are thrilled to share that the first research paper on our compact ion-trap quantum computing demonstrator is now available on the <a href="https://arxiv.org/abs/2101.11390">arXiv</a>, demonstrating 24 qubit GHZ entanglement in a room-temperature setup housed in two 19-inch racks.</p>
<p>This research work in cooperation with the University of Innsbruck marks an important step in the steady progress of quantum information processing (QIP) from a purely academic discipline towards applications throughout science and industry. Transitioning from lab-based, proof-of-concept experiments to robust, integrated realizations of QIP hardware is a crucial step in this process. Not an easy one, however, because the nature of traditional laboratory setups does not offer itself readily to scaling up system sizes or allow for applications outside of laboratory-grade environments.</p>
<p>What we demonstrate here is that we have overcome challenges in engineering and integration without sacrificing the state-of-the-art performance of laboratory implementations.</p>
</div></div></div></div></div>

							</div>

												<span><span><a href="https://www.aqt.eu/author/aqt/" title="Posts by Thomas Monz" rel="author">Thomas Monz</a></span></span><span>2021-01-28T16:54:25+01:00</span>																								
																	</article>
	</section>
						
					</div>  <!-- fusion-row -->
				</main>  <!-- #main -->
				
				
								
					
		 <!-- fusion-footer -->

		
					

												</div> <!-- wrapper -->
		</div> <!-- #boxed-wrapper -->
		
		
		
		<a></a>

		<div>
			<div>
	<div>
		<span>We use cookies and analysis software in order to design our website as user-friendly as possible. By proceeding, you accept using this service. <a href="https://www.aqt.eu/privacy-policy/">More information</a>					</span>
		<a href="#" data-alt-text="Update Settings" data-orig-text="Ok">
			Ok		</a>
	</div>
	</div>






				
						</div>

			
		


</div>]]>
            </description>
            <link>https://www.aqt.eu/24-qubit-entanglement/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26000100</guid>
            <pubDate>Tue, 02 Feb 2021 12:20:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Serverless Sending and Receiving Emails, the CDK Way]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26000040">thread link</a>) | @weeefun
<br/>
February 2, 2021 | https://www.sebastianhesse.de/2021/01/16/5-ways-to-bundle-a-lambda-function-within-an-aws-cdk-construct/ | <a href="https://web.archive.org/web/*/https://www.sebastianhesse.de/2021/01/16/5-ways-to-bundle-a-lambda-function-within-an-aws-cdk-construct/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-674" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">
<div>

<div itemprop="text">
<p>Have you ever tried to publish a CDK construct that was using a Lambda function, for example to create a custom resource or provide a REST API endpoint? It’s relatively easy to publish your construct if your Lambda function is just using the AWS SDK. But it gets more complicated as soon as other dependencies are involved as well. This post will present you five different ways to bundle your Lambda function within a CDK construct and tells you about the advantages and disadvantages of each option.</p>
<h2>Problem Context</h2>
<p>Recently I started digging more into the <a href="https://aws.amazon.com/cdk/" target="_blank" rel="noreferrer noopener">AWS CDK</a> world and wanted to build a simple single page application. I had some special requirement for which I couldn’t find an existing CDK construct available in TypeScript. So I thought let’s create it myself and publish it later to NPM. I wanted to include a Lambda function in this CDK construct that was using an external dependency apart from the AWS SDK. <strong>The problem is</strong> that if you require other dependencies in an AWS Lambda function, you need to bundle them with your function (the AWS SDK is always available for Node.js runtimes). This means, you have to create an artifact that includes all required dependencies. However, I wanted to avoid that my resulting CDK construct package gets too big. I had some ideas in my mind but also asked <a href="https://twitter.com/seeebiii/status/1348716172649361408?s=20" target="_blank" rel="noreferrer noopener">CDK experts on Twitter</a> for their opinion and experiences. Below are the results of my ideas and their suggestions!</p>
<p>You have another idea how to <strong>include a Lambda function in a CDK construct</strong>? Please comment below ⬇️ or let me know <a href="https://twitter.com/seeebiii" target="_blank" rel="noreferrer noopener">via Twitter @seeebiii</a>. If you’re curious about developing AWS Lambda functions in general, I can recommend you my article about <a href="https://www.sebastianhesse.de/2020/03/31/going-serverless-why-and-how-2/">best practices developing AWS Lambda functions</a>.</p>
<h2>Inline Code in CDK Construct</h2>
<p>The easiest solution is to write some inline code within the CDK code. It usually looks like this when using the <code><a href="https://docs.aws.amazon.com/cdk/api/latest/docs/@aws-cdk_aws-lambda.Function.html" target="_blank" rel="noreferrer noopener">Function</a></code> construct from the <code><a href="https://docs.aws.amazon.com/cdk/api/latest/docs/aws-lambda-readme.html" target="_blank" rel="noreferrer noopener">@aws-cdk/aws-lambda</a></code> package:</p>
<pre><code>new Function(this, 'MyFunction', {
  handler: 'index.handler',
  code: Code.fromInline(`
    exports.handler = async (event) =&gt; {
      console.log('event: ', event)
    };
  `),
  runtime: Runtime.NODEJS_12_X
});</code></pre>
<p>This code will create a Lambda function with a very basic implementation. You can of course extend it further. However, you are a bit limited in terms of which dependencies you can include. For example, you can only refer to external dependencies like the AWS SDK and regular Node.js modules like <code>path</code> of <code>fs</code>. Also, this approach only works for runtimes that interpret text files, like Python or Node.js. It does not work for languages like Java.</p>
<h3>Advantages:</h3>
<ul><li>Quick and easy way to write a Lambda function</li><li>No extra bundle steps necessary</li></ul>
<h3>Disadvantages</h3>
<ul><li>You are very limited what your function can do</li><li>No IDE support while writing your code</li><li>No testing possible, only manual tests</li></ul>
<h2>Separate File(s) in CDK Construct</h2>
<p>Instead of providing inline code, you can also move your Lambda function code outside of the CDK code into a separate file. Then, you just link to your file from the CDK construct your using. For example:</p>
<pre><code>new Function(this, 'MyFunction', {
  runtime: Runtime.NODEJS_12_X,
  handler: 'index.handler',
  code: Code.fromAsset(`${path.resolve(__dirname)}/lambda`)
});</code></pre>
<p>The <code>code</code> property is referencing an external asset which points to the file of your Lambda function. It assumes the following folder structure:</p>
<pre><code>root/
 - my-stack.js
 - lambda/
   - index.js</code></pre>
<p>When deploying a stack with this function code, the CDK will simply take the <code>index</code> file of your Lambda function and use it as your Lambda function’s code. You can do something similar using other runtimes like Java or Python. Just reference the appropriate artifact like a JAR or Python file. Although this approach is much more preferred than writing inline code, it still has the drawback that you can not simply include other dependencies apart from the AWS SDK, at least for Node.js. You could of course zip your <code>index.js</code> file together with your <code>node_modules</code> folder and use that as your artifact. However, this approach is <strong>not recommended</strong> because it unnecessarily slows down your Lambda function due to a bigger artifact size. You’re just carrying around code which you’re not using.</p>
<h3>Advantages</h3>
<ul><li>Keep CDK stack code and Lambda function code separated</li><li>You can test your Lambda function’s code using automated tests</li><li>IDE support while writing your Lambda function’s code</li></ul>
<h3>Disadvantages</h3>
<ul><li>External dependencies (apart from AWS SDK) not supported</li></ul>
<h2>Bundle Lambda Function Before Publishing</h2>
<p>If you want to use other external dependencies, you need to make sure that those dependencies are available when your Lambda function is executed. Therefore, the next logical step is to bundle your Lambda function’s code and generate a code artifact with all the dependencies included. This artifact is used by your CDK construct and in the end used by the users of your construct. In your CDK construct you still use the same <code>Function</code> definition as above where you include the code asset. However, you have to make sure to bundle your code before you publish your CDK construct to any registry like NPM. For example, if you’re writing a TypeScript Lambda function, you can use <a href="https://esbuild.github.io/" target="_blank" rel="noreferrer noopener">esbuild</a> (or webpack or similar) to compile and bundle it to “native” Node.js code that your Lambda function understands:</p>
<pre><code>esbuild lambda/index.ts --bundle --platform=node --target=node12 --external:aws-sdk --outfile=lambda/build/index.js</code></pre>
<p>This command creates an <code>index.js</code> file with all dependencies included, except the AWS SDK since this is already provided by the Lambda runtime. If you want to speed up your Lambda function even more, you can append <code>--minify</code> to use minification and reduce the output size. Here the output file is created under <code>lambda/build</code>, so take care to adjust the <code>Function</code> definition. For example:</p>
<pre><code>new Function(this, 'MyFunction', {
  runtime: Runtime.NODEJS_12_X,
  handler: 'index.handler',
  code: Code.fromAsset(`${path.resolve(__dirname)}/lambda/build`)
});</code></pre>
<p>In order to include the Lambda function’s code in your published CDK construct, consider the following:</p>
<ul><li>Make sure the <code>lambda/build</code> folder is not ignored by NPM (this is usually configured in <code>.npmignore</code>)</li><li>Before publishing the construct, you have to bundle the Lambda function first – otherwise your published construct is missing the code for your Lambda function</li></ul>
<h3>Advantages</h3>
<ul><li>Everything from the previous section about having separate files</li><li>You don’t make any assumptions about the environment of the users that use your construct (will be important in the following sections)</li><li>You throw out all unnecessary code by only bundling the relevant code and maybe even minifying it</li></ul>
<h3>Disadvantages</h3>
<ul><li>It takes another build step and slightly increases the size of your CDK construct</li></ul>


<h2>Bundle Lambda Function Before Deploying</h2>
<p>Instead of bundling the code before publishing your CDK construct, you can also bundle your Lambda function code before the construct is deployed to AWS. The AWS CDK provides a construct for Node.js Lambda functions called <code><a href="https://docs.aws.amazon.com/cdk/api/latest/docs/@aws-cdk_aws-lambda-nodejs.NodejsFunction.html" target="_blank" rel="noreferrer noopener">NodejsFunction</a></code> from the <a href="https://docs.aws.amazon.com/cdk/api/latest/docs/aws-lambda-nodejs-readme.html" target="_blank" rel="noreferrer noopener"><code>@aws-cdk/aws-lambda-nodejs</code> package</a>. This construct will build the Lambda function as soon as your CDK construct is deployed within a stack. The <code>NodejsFunction</code> construct is using esbuild to do that or a Docker container if esbuild is not available (<a href="https://docs.aws.amazon.com/cdk/api/latest/docs/@aws-cdk_aws-lambda-nodejs.NodejsFunction.html" target="_blank" rel="noreferrer noopener">read more about it in the documentation</a>). Using it in your construct is similar to how you define a regular <code><a href="https://docs.aws.amazon.com/cdk/api/latest/docs/@aws-cdk_aws-lambda.Function.html" target="_blank" rel="noreferrer noopener">Function</a></code> – however, it already defines some useful defaults. An example definition can look like this:</p>
<pre><code>new NodejsFunction(this, 'MyFunction', {
  entry: `${path.resolve(__dirname)}/lambda/index.js`
});</code></pre>
<p>As you can see, it’s pretty simple and short. Unfortunately the big disadvantage is that you make assumptions about the environment where your construct is deployed. If they don’t have esbuild or Docker available, it won’t work. Therefore it only makes sense to use <code>NodejsFunction</code> in an constructs where you control the environment or if you let your users know about this requirement.</p>
<h3>Advantages</h3>
<ul><li>Everything from the previous section about having separate files</li><li>You throw out all unnecessary code by only bundling the relevant code and maybe even minifying it</li></ul>
<h3>Disadvantages</h3>
<ul><li>You make assumptions about the environment of the users of your construct</li><li>It takes another build step and slightly increases the size of your CDK construct</li></ul>
<h2>Publish Lambda Function to Serverless Application Repository or Using Docker</h2>
<p>A completely different option compared to the ones above is to use the Serverless Application Repository. It’s a repository for serverless application that you can build and <a href="https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/serverless-sam-template-publishing-applications.html" target="_blank" rel="noreferrer noopener">publish to AWS using the SAM CLI</a>. Then you can use this application in other stacks using the <a href="https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/sam-resource-application.html" target="_blank" rel="noreferrer noopener">CloudFormation SAM type <code>AWS::Serverless::Application</code></a>. The CDK equivalent is <a href="https://docs.aws.amazon.com/cdk/api/latest/docs/@aws-cdk_aws-sam.CfnApplication.html" target="_blank" rel="noreferrer noopener">CfnApplication</a> from the <a href="https://docs.aws.amazon.com/cdk/api/latest/docs/aws-sam-readme.html" target="_blank" rel="noreferrer noopener">@aws-cdk/aws-sam</a> package. Since those applications can be made public to everyone, you have a neat way to host your Lambda function outside of your CDK construct, i.e. without bundling it inside your CDK construct. You could even <a href="https://docs.aws.amazon.com/serverlessrepo/latest/devguide/sharing-lambda-layers.html" target="_blank" rel="noreferrer noopener">share your AWS Lambda Layer in the same way</a> and reference that instead of a full serverless application (see <a href="https://levelup.gitconnected.com/blog-md-9bd47be8b3ad" target="_blank" rel="noreferrer noopener">how to use Layers in AWS CDK here</a>). This has the advantage that you can still use the <code>Function</code> construct as explained above and just add a <a href="https://docs.aws.amazon.com/cdk/api/latest/docs/@aws-cdk_aws-lambda.LayerVersion.html" target="_blank" rel="noreferrer noopener"><code>LayerVersion</code> construct</a>. Similarly, you can <a href="https://aws.amazon.com/blogs/compute/using-container-image-support-for-aws-lambda-with-aws-sam/" target="_blank" rel="noreferrer noopener">publish your Lambda function as a container nowadays</a> and reference that in your CDK construct. The CDK provides a <code><a href="https://docs.aws.amazon.com/cdk/api/latest/docs/aws-lambda-readme.html#docker-images" target="_blank" rel="noreferrer noopener">DockerImageFunction</a></code> for this case.</p>
<p>Although these options sound like a good idea because you are much more flexible in how your Lambda function is built, the solution has two disadvantages: First, you are referencing an unknown external stack or dependency that you should make your users aware of so they can verify it. Second, it adds much more complexity than often necessary. Especially if you’re using a Node.js runtime, none of these step should be necessary for bundling a Lambda function within your CDK construct. It’s much easier to use one of the other options above.</p>
<h3>Advantages</h3>
<ul><li>Separation of concerns</li><li>Flexibility of which …</li></ul></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.sebastianhesse.de/2021/01/16/5-ways-to-bundle-a-lambda-function-within-an-aws-cdk-construct/">https://www.sebastianhesse.de/2021/01/16/5-ways-to-bundle-a-lambda-function-within-an-aws-cdk-construct/</a></em></p>]]>
            </description>
            <link>https://www.sebastianhesse.de/2021/01/16/5-ways-to-bundle-a-lambda-function-within-an-aws-cdk-construct/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26000040</guid>
            <pubDate>Tue, 02 Feb 2021 12:13:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CadCAD Can't Simulate Humans]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25999718">thread link</a>) | @ritchan
<br/>
February 2, 2021 | http://tokengineer.com/cadcad-cant-simulate-humans/ | <a href="https://web.archive.org/web/*/http://tokengineer.com/cadcad-cant-simulate-humans/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-163">

	

	<div>
		
<p>Now and then, when people hear I code economic simulations with <a href="https://github.com/cadCAD-org/cadCAD">cadCAD</a> (and I just heard about its rust cousin <a href="https://github.com/BenSchZA/radCAD">radCAD</a>), they want me to write one for them. And it usually involves asking how humans would behave in a specific situation.</p>



<p>here’s the thing</p>



<figure><blockquote><p>I don’t know.</p><cite>I can’t simulate human psychology.</cite></blockquote></figure>



<p>What would people do in this or that case? This is not what a simulation does. A simulation says “given these conditions, and behaviours, this will happen (most/some of the time)”. One must be very clear about what these behaviours are and formulate the question in such a way that we can answer it without having to program mini-humans. Mini-humans are impossible to verify anyway.</p>



<p>Bad question: “What would humans do if I raised taxes?”<br>Better question: “How many people would stay in my system given a group of humans (with income distribution A, differing tolerances for tax raises B) and if I raised taxes above a certain threshold?”</p>



<p>You get the idea.</p>



<p>Math helps to set your intentions in stone. If you can express every interaction and change as an equation, everyone can verify that the simulation is working as intended. After all, if I write a complex system that I claim simulates how humans would behave, how is anybody going to verify that? I was probably just guessing; and it’s hard to verify if the code does what I intended. It’s far easier to test if an equation computed the right result.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article></div>]]>
            </description>
            <link>http://tokengineer.com/cadcad-cant-simulate-humans/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25999718</guid>
            <pubDate>Tue, 02 Feb 2021 11:23:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sudo Exploit Writeup (CVE-2021-3156)]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25999667">thread link</a>) | @NicolaiS
<br/>
February 2, 2021 | https://www.kalmarunionen.dk/writeups/sudo/ | <a href="https://web.archive.org/web/*/https://www.kalmarunionen.dk/writeups/sudo/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
<div>
  <article>
    

    
  

    
    
    <h2>Overview</h2>
    <nav id="TableOfContents">
  <ul>
    <li><a href="#introduction">Introduction</a></li>
    <li><a href="#vulnerability">Vulnerability</a>
      <ul>
        <li><a href="#properties-of-the-overflow">Properties of the overflow</a></li>
      </ul>
    </li>
    <li><a href="#exploitation">Exploitation</a>
      <ul>
        <li><a href="#heap-grooming">Heap Grooming</a></li>
      </ul>
    </li>
    <li><a href="#conclusion">Conclusion</a></li>
  </ul>
</nav>
    <p>Writeup by: <a href="https://twitter.com/alexanderkrog">Zanderdk</a></p>
<h2 id="introduction">Introduction</h2>
<p>On the 2021-01-26 qualy released this <a href="https://www.qualys.com/2021/01/26/cve-2021-3156/baron-samedit-heap-based-overflow-sudo.txt">article</a> describing a “new” (actually 10 year old) bug in sudo that allows an attacker to do privilege escalation though a heap buffer overflow.
Unfortunately they did not release exploit/POC so I decided to build one myself and failed. It turned out that Pewz from the CTF team bootplug had the same thought and our combined forces allowed us to successfully exploit this bug on the newest libc 2.32 in an arch environment with sudo version 1.9.4p2.</p>
<h2 id="vulnerability">Vulnerability</h2>
<p>I will only briefly cover the vulnerability here as it’s quite well described in the article.</p>
<p>In an essence an attacker can overflow a heap chunk by inserting a single backslash at the end of any argv or env argument given to sudo, causing the following argument to be written out of bound. Let’s look at a simplified version of one of the code snippets from the article.</p>
<div><pre><code data-lang="C"><span>for</span> (size <span>=</span> <span>0</span>, av <span>=</span> NewArgv <span>+</span> <span>1</span>; <span>*</span>av; av<span>++</span>)
  size <span>+=</span> strlen(<span>*</span>av) <span>+</span> <span>1</span>;
...
<span>if</span> (size <span>==</span> <span>0</span> <span>||</span> (user_args <span>=</span> malloc(size)) <span>==</span> NULL) {
  <span>//do some stuff we don't care about
</span><span></span>}
...
<span>for</span> (to <span>=</span> user_args, av <span>=</span> NewArgv <span>+</span> <span>1</span>; (from <span>=</span> <span>*</span>av); av<span>++</span>) {
  <span>while</span> (<span>*</span>from) {
    <span>if</span> (from[<span>0</span>] <span>==</span> <span>'\\'</span> <span>&amp;&amp;</span> <span>!</span>isspace((<span>unsigned</span> <span>char</span>)from[<span>1</span>]))
      from<span>++</span>;
    <span>*</span>to<span>++</span> <span>=</span> <span>*</span>from<span>++</span>;
    }
    <span>*</span>to<span>++</span> <span>=</span> <span>' '</span>;
}
</code></pre></div><p>As we see in the first for loop we are iterating over each argument and finding the size (plus null terminator) of it using <code>strlen</code>. Now lets say we have the string <code>"AAAA\\"</code> (<code>\\</code> is one char).</p>
<p>The size will be 5 and it will only do an allocation of 5 bytes assuming this is the only argument.</p>
<p>In the next part we have a outer for loop over arguments and an inner loop copying the contents of all the arguments into the single buffer, <code>user_args</code>, essentially concatenating all arguments.</p>
<p>Considering the same string as before, <code>"AAAA\\"</code>, when we hit <code>from[0]=='\\'</code> we go into the if and increment <code>from</code> by <code>from++</code>, incrementing <code>from</code> so it points to the null terminator. After that we continue the loop with the next statement <code>*to++ = *from++;</code> copying the null terminator and again incrementing <code>from</code> to continue copying bytes after the null terminator we continue copying out of bounds.</p>
<p>This happens because it expects that every <code>\\</code> is followed by a meta-character, which the authors came up with a clever way of avoiding, leaving this vulnerable to a overflow. Read the article if you want to know why and how we can end up having a single <code>\\</code> in the args when entering this block.</p>
<p>By using the symbolic link <code>sudoedit</code> to <code>sudo</code> we can make this happen:</p>
<p><img src="https://www.kalmarunionen.dk/images/overflow.png" alt="sudo exploit overflowing"></p>
<h3 id="properties-of-the-overflow">Properties of the overflow</h3>
<p>The authors state 3 important properties about this overflow which make it quite powerful.</p>
<p>First and simplest we control the allocation size of <code>user_args</code> as we chose how many and how long we make the arguments to sudo.</p>
<p>Second we control the contents of the overflowed area.
This we can achieve by using the supplied environment variables. The environment variables is infact stored right after the last argument passed to <code>sudoedit</code> meaning that if we do <code>env -i 'A=BBBB' sudoedit -s 'CCCCCCCCCCCCCCCC'</code> we insert the C’s into the user_args buffer and <code>A=BBBB</code> will follow in the out of bounds area. Be aware that chunk size’s align to sizes of 0x10 so e.g. <code>env -i 'A=BB' sudoedit -s 'CCCCBBBBBBBB'</code> will only fill the buffer.</p>
<p>If you paid close attention to the inner loop in our concatenation block you probably noticed that we can exploit this multiple times. By ending a environment variable with <code>\\</code> we can make another skip to the next environment variable. So why would we like that? Because as the <code>from++</code> increments the pointer to the null terminator on the following <code>to++ = *from++;</code> it will insert that null terminator. This makes us able to insert 0x0 as well without ending the overflow making this overflow extremely powerful.</p>
<p>Example from the authors:</p>
<p><code>env -i 'AA=a\' 'B=b\' 'C=c\' 'D=d\' 'E=e\' 'F=f' sudoedit -s '1234567890123456789012\'</code></p>
<p>This will end up like this in the buffer:</p>
<pre><code>--|--------+--------+--------+--------|--------+--------+--------+--------+--
  |        |        |12345678|90123456|789012.A|A=a.B=b.|C=c.D=d.|E=e.F=f.|
--|--------+--------+--------+--------|--------+--------+--------+--------+--
              size  &lt;---- user_args buffer ----&gt;  size      fd       bk
</code></pre><p>So we wont go into what forward (fd) or backwards (bk) pointers of a heap chunk mean as we are only exploiting in use memory.
Super short and oversimplified description:</p>
<ul>
<li>the first size is the size of the following chunk. It is equal to 0x10 + argument given to malloc as we also need space for size itself and alignment/previous size.</li>
<li>the next size is the contiguous chunks size.</li>
<li>fd and bk are pointers to the next and previous chunk respectively in this linked list of freed chunks. This only applies to freed chunks. Otherwise this space is available to the caller of malloc.</li>
</ul>
<p>If you want to know more about this topic I strongly encourage you to read the <a href="https://azeria-labs.com/heap-exploitation-part-1-understanding-the-glibc-heap-implementation/">Azeria’s blog about heap exploitation</a>.</p>
<p>Now an important note to make here about the null terminator insertion I think the original paper lacks is that we can insert multiple contiguous null bytes as well.</p>
<p>First thing to understand is that environment variables don’t have to in the form of <code>SOMETHING=something_more</code>. As everything else these are just char arrays and we can do what we can with them in C. as example:</p>
<div><pre><code data-lang="C"><span>char</span> <span>*</span>args[] <span>=</span> { <span>"/usr/bin/sudoedit"</span>, <span>"-s"</span>, <span>"AAAAAAAA"</span>, NULL };
<span>char</span> <span>*</span>env[] <span>=</span> { <span>"BBBBBBBB"</span>, <span>"</span><span>\\</span><span>"</span>, <span>"</span><span>\\</span><span>"</span>, <span>"CCCCCCCC"</span>, NULL };
execve(<span>"/usr/bin/sudoedit"</span>, argv, env);
</code></pre></div><p>Here we are using execve to execute the process with full control of the environment variables.
In the inner for loop we run into the if statement at ´"\\“´ and by that skipping one char by <code>from++</code> the backslash and only inserting the null jumping onto the next ´”\\“´ and consequently inserting two null bytes in a row.</p>
<h2 id="exploitation">Exploitation</h2>
<p>While the authors mention 3 possible targets here in this writeup we will only cover the second one.</p>
<p>Reasons:</p>
<ul>
<li>no brute-force involved in contrast to the first option where they partially overflow a function pointer defeating ASLR with brute-force.</li>
<li>They state that they did it successfully for 3 operating systems where both the other two were only one.</li>
</ul>
<p>In the second option we try to overflow into a <code>service_user</code> struct stored on the heap.</p>
<div><pre><code data-lang="C"><span>typedef</span> <span>struct</span> service_user
{
  <span>/* And the link to the next entry.  */</span>
  <span>struct</span> service_user <span>*</span>next;
  <span>/* Action according to result.  */</span>
  lookup_actions actions[<span>5</span>];
  <span>/* Link to the underlying library object.  */</span>
  service_library <span>*</span>library;
  <span>/* Collection of known functions.  */</span>
  <span>void</span> <span>*</span>known;
  <span>/* Name of the service (`files', `dns', `nis', ...).  */</span>
  <span>char</span> name[<span>0</span>];
} service_user;
</code></pre></div><p>This struct is used in the <code>nss_load_library</code> of libc quite often after the overflow happens for loading new dynamically linked libraries, and can we overflow the name filed then we control what library to load.
Then we can target some non privileged library we can craft that will run with the privileges of root. :-)</p>
<p>The function looks like this:</p>
<div><pre><code data-lang="C"><span>static</span> <span>int</span>
<span>nss_load_library</span> (service_user <span>*</span>ni)
{
  <span>if</span> (ni<span>-&gt;</span>library <span>==</span> NULL)
    {
      <span>static</span> name_database default_table;
      ni<span>-&gt;</span>library <span>=</span> nss_new_service (service_table <span>?:</span> <span>&amp;</span>default_table,
				     ni<span>-&gt;</span>name);
      <span>if</span> (ni<span>-&gt;</span>library <span>==</span> NULL)
	<span>return</span> <span>-</span><span>1</span>;
    }

  <span>if</span> (ni<span>-&gt;</span>library<span>-&gt;</span>lib_handle <span>==</span> NULL)
    {
      <span>/* Load the shared library.  */</span>
      size_t shlen <span>=</span> (<span>7</span> <span>+</span> strlen (ni<span>-&gt;</span>name) <span>+</span> <span>3</span>
		      <span>+</span> strlen (__nss_shlib_revision) <span>+</span> <span>1</span>);
      <span>int</span> saved_errno <span>=</span> errno;
      <span>char</span> shlib_name[shlen];

      <span>/* Construct shared object name.  */</span>
      __stpcpy (__stpcpy (__stpcpy (__stpcpy (shlib_name,
					      <span>"libnss_"</span>),
				    ni<span>-&gt;</span>name),
			  <span>".so"</span>),
		__nss_shlib_revision);

      ni<span>-&gt;</span>library<span>-&gt;</span>lib_handle <span>=</span> __libc_dlopen (shlib_name);
      <span>//continue long long function
</span></code></pre></div><p>The goal with this function is to hit the <code>ni-&gt;library-&gt;lib_handle = __libc_dlopen(shlib_name)</code> loading a new library we control.</p>
<p>Here there are two things to be aware of the first the one mentioned in the article.
If <code>ni-&gt;library</code> is not <code>NULL</code> we will use that pointer in the <code>ni-&gt;library-&gt;lib_handle</code> and as ASLR is a bitch we can’t predict a valid pointer without a leak which we don’t have.
Fortunately there is a initial case for this struct where if this is null we set it by <code>ni-&gt;library = nss_new_service (...</code>. Now the multiple null byte write comes in handy!</p>
<p>Then we just need to overflow this struct all the way to it’s name field to change it to an unprivileged library we control.</p>
<p>The second challenge is that we have this next pointer <code>struct service_user *next;</code> inside the struct forming a linked list that will be traversed when the loading happens.
So if we accidentally overflow another <code>service_user</code> struct in the process we will write a garbage pointer if we overflow with fx A’s leading to a seg fault.
This can be circumvented by inserting null bytes in that spot but that creates another problem, we now break the linked list and our target struct could now be completely removed from the list leaving no pointers to it in the entire memory space.</p>
<p>This means that we have to target the first struct in the linked list that comes after our allocated area.
This turned out to be the biggest challenge to overcome as you can imagine this requires pretty good control of the heap allocation.</p>
<p>In the article they target a <code>service_user</code> with the name <code>systemd</code> which we by no means were able to target.
So we set a breakpoint just before the allocation to inspect the linked list. Then we search for <code>systemd</code> and traverse the list backwards until we find the first <code>service_user</code> close to our allocation. (Combined with some trial and error overflowing of A’s to see what struct it crashes on :-))</p>
<p>Here I show the different <code>service_user</code> names in memory and below vmmaps listed in same order. As seen on the picture the second vmmap corresponds to a systemd in the …</p></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.kalmarunionen.dk/writeups/sudo/">https://www.kalmarunionen.dk/writeups/sudo/</a></em></p>]]>
            </description>
            <link>https://www.kalmarunionen.dk/writeups/sudo/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25999667</guid>
            <pubDate>Tue, 02 Feb 2021 11:16:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The 4 Key Ways We Fail As Engineering Managers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25999607">thread link</a>) | @ochronus
<br/>
February 2, 2021 | https://ochronus.online/engineering-manager-4-ways-of-failure/ | <a href="https://web.archive.org/web/*/https://ochronus.online/engineering-manager-4-ways-of-failure/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<div itemprop="text">

<p>Management tends to get bad rap and unfortunately many times rightfully so. Having a bad manager can make one’s life miserable and hinder their growth. Managers can seem like politicians who don’t know anything about our trade yet they give us directions.</p>
<p>On the other hand having a good manager can make you feel supported, can boost your career (and sometimes personal) growth and help make your team and company a happy place.</p>
<p>For better or worse, managers have a huge impact on their teams’ and direct report’s lives. It’s extremely important to understand some usual failure scenarios so we can course correct and provide better service and support to them.</p>
<p>Let’s see four usual ways we fail as managers.</p>
<h2 id="0-1-low-self-confidence">1. Low self-confidence</h2>
<blockquote><p>It’s not the lack of ability or opportunity that holds you back; it is only a lack of confidence in yourself.</p><p>—&nbsp;Richard Monckton Milnes</p></blockquote>
<p>I’ve known much more engineering managers with low self-confidence than otherwise. Honestly, I can relate! It’s usually really hard to see our work’s positive effect, feedback loops are just too long, and cause-and-effect relations aren’t always trivial to see.</p>
<p>This is especially true for new managers, who just stepped into a completely new skill area and often try to cling to what they already know. It’s really taxing on one’s confidence to suddenly be a beginner again after previously being highly performing (engineer, many times). The end result is that we are trying to prove to ourselves (and sometimes to others, too) that we do deserve the manager role.</p>
<p>Feeling like this is entirely natural, and it can motivate us to learn and do better. Troubles start, though when this inspires the wrong kinds of behaviors in managers.</p>
<p>For one, continually demonstrating insecurity, in general, can undermine people’s confidence in us as leaders who can enforce our negative thoughts and create a vicious circle – we start noticing others don’t have much faith in us.</p>
<p>People with low self-confidence usually have a hard time saying “I don’t know”, which is essential as an engineering manager. We cling to the thought that we have to know answers to everything that comes up; otherwise, we’re just not performing well.</p>
<p>I’ve seen some insecure managers trying to do team members’ jobs. They do this not because they don’t trust their team, but they need something they’re proficient with to feel more secure and confident. This was partially the motivation for me to write one of my old posts titled&nbsp;<a href="https://ochronus.online/engineering-managers-stop-coding/">Engineering Managers, Stop Coding!</a></p>
<p>Another way for such managers to feel that they are still worth something is to be too nitpicky, for example, in code reviews or simply when giving feedback. Among many things, all this can lead to the team’s engineers feeling that their engineering manager is competing against them in a way.</p>
<p>I’ve seen another behavior of low self-confidence managers: they sometimes complain about their direct reports to other direct reports (please&nbsp;<strong>never ever</strong>&nbsp;do this!) or their manager.</p>
<p>Usually, this is only a transition period, but sometimes managers get stuck in this for years. A good support circle (the other managers in the company) and a good manager of the manager can help tremendously. Being able to discuss insecurities and fears with others can make you understand that this is normal, you’re not alone, and you can learn good coping and growth strategies from more seasoned peers.</p>
<h2 id="1-2-the-silver-bullet-aka-the-one-trick-pony">2. The silver bullet a.k.a. the one-trick pony</h2>
<blockquote><p>Yesterday I was clever, so I wanted to change the world. Today I am wise, so I am changing myself.</p><p>—&nbsp;Jelaluddin Rumi</p></blockquote>
<p>We might not be conscious about it, but we all have a natural, default style when it comes to management. This is shaped by our general personality, our experiences and things we’ve learnt along the way.<br>As managers, we unconsciously rely on this style, and without guidance, we tend to use that style with every direct report. Even when it becomes conscious, we justify this with ‘this is who I am’ and sometimes even with core values and our self-image (see my earlier post&nbsp;<a href="https://ochronus.online/stories-we-tell-ourselves/">Stories We Tell Ourselves</a>). Also, in many cases this style is actually the way&nbsp;<em>we</em>&nbsp;prefer to be managed.</p>
<p>While having strong core values is vital to being a successful leader, using a single management style just simply won’t work with all your direct reports over the years. Acting this way will harm some of your direct reports (and of course hinder your performance as an engineering manager, too).</p>
<p>One-trick managers often talk about the one true way to do things. They get overprotective about their style as they face more and more challenge. They often see the failure to be with the direct reports who don’t respond well to their style instead of adapting to theirs.</p>
<p>This usually shows in hiring, too – engineering managers who are stuck with one single style of leadership often prefer to hire people who are like them instead of diversifying the team.</p>
<blockquote><p>INTERVIEWER 1: I think you’ll be a really good culture fit, Dave.<br>INTERVIEWER 2: I have to say Dave, your answers really impressed us.<br>CANDIDATE: Thank you, Dave. You too, Dave.<br><a href="https://twitter.com/tef_ebooks/status/1355757158458138624" target="_blank" rel="noopener">@tef_ebooks on Twitter</a></p></blockquote>
<p>These managers will have a fantastic relationship with some of the team members who’ll get most of their attention, leaving the others in the limbo a bit. These engineers who are left out will get frustrated and might end up doubting their performance if they don’t realize what’s happening.</p>
<p>As managers, it’s our core job to form a good working relationship with our direct reports. When this requires us to adapt our style or adopt new styles, it’s&nbsp;<em>our</em>&nbsp;job to do so. It’s not fair to expect our direct reports to adapt to our way of management.&nbsp;<a href="https://situational.com/situational-leadership/" target="_blank" rel="noopener">Situational Leadership</a>&nbsp;is a part of this.</p>

<h2 id="2-3-too-much-business-focus-vs-too-much-people-focus">3. Too much business focus vs. too much people focus</h2>
<blockquote><p>I still believe in synergy, but I call it natural law.</p><p>—&nbsp;Barry Diller</p></blockquote>
<p>We’ve all met managers who are only into business and view their direct reports as “resources”. They seemingly don’t care too much about their folks’ wellbeing and are only driven by deadlines, impact and KPIs. If the team is successful, it’ll make them happy, right?</p>
<p>We sometimes (much more rarely) see leaders who are only into the people part of their job. They create safe havens for their direct reports, try to protect them from the ‘evils’ of the world and the company and don’t seem to care about performance and business results too much. With a happy team, everything will just work out eventually, right?</p>
<p>These are obviously polar extremes – in reality, this works much more like a balance. Some business-focused managers actually do care a lot about their direct reports but firmly believe that the only way to happiness is a successful business. People-only leaders do sometimes nurture amazingly performing teams.</p>
<p>I just said ‘balance’, but I don’t view these to focuses as opposites. It’s much more about the balance of the short term and the long term. This balance manifests in many areas – solution quality vs. time to market, investing in the people vs. investing in the business, etc. etc..</p>
<p>Too much focus on the business in a leader will sometimes result in that leader prioritizing short term wins over long term ones. Such managers will talk a lot about holding people accountable. They are quick to ‘abandon’ direct reports who don’t fall in line in terms of team commitments and performance instead of coaching them and working on alignment. The sacrifice here can be tremendous: company culture suffers, and this setup won’t work in the long term. People will get burnt out and will leave. Sure, they will hire new engineers, but there’s the cost of onboarding and slowing down, lack of tenure and an overarching understanding of the product and systems and the job market will know what kind of place their company is.</p>
<p>Only focusing on the people without considering that you as a team are responsible for making the business successful can be equally detrimental. As an extreme case, a failed business won’t be able to eventually employ (as many) engineers. Individual and team success needs to align with the business’ success. Such leaders will often position themselves as gatekeepers of core values versus the rest of the company, or senior management. They will view their team as the last stand against the tides of evil.</p>
<p>This, in the end, is not about balance, I think, but rather about synergy (look, look, a buzzword!) – not building a silo of a safe haven for your team but finding a way for the individuals to grow and be successful in tandem with the business’ goals. Naturally, you need the right kind of company for this – if the company’s core values aren’t aligned with nurturing happy teams, it’ll naturally fail as a business, too. If you feel as a leader or as an individual contributor that you cannot stand by your company’s core values, by all means, do yourself the favor of finding a better place for yourself (unless you believe you can steer the company, of course).</p>
<p><strong>I’ve personally only seen high performing AND happy teams when business results and team happiness/health were aligned.</strong>https://newsletter.ochronus.online/embed</p>
<h2 id="3-4-too-much-solving-not-enough-listening">4. Too much solving, not enough listening</h2>
<blockquote><p>I remind myself every morning: Nothing I say this day will teach me anything. So if I’m going to learn, I must do it by listening.</p><p>—&nbsp;Larry King</p></blockquote>
<p>Interestingly this can happen both when we’re not confident as leaders and when we are too confident. We tend to focus on solutions too much instead of supporting/empowering others or listening for more context.</p>
<p>Sometimes people only need someone to vent to and are not looking for solutions immediately.<br>Even when they are, we can act as coaches and guide them to the solutions, helping them grow in the process so that next time they will be able to solve on their own.<br>Even when they need an immediate solution, we might fail to get the whole context by not authentically listening to them.</p>
<p>Such leaders usually jump to solutions right after hearing about an issue, and even when they ask for more details and input, they are not …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ochronus.online/engineering-manager-4-ways-of-failure/">https://ochronus.online/engineering-manager-4-ways-of-failure/</a></em></p>]]>
            </description>
            <link>https://ochronus.online/engineering-manager-4-ways-of-failure/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25999607</guid>
            <pubDate>Tue, 02 Feb 2021 11:09:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Focus on the Good Parts]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25999603">thread link</a>) | @yagizdegirmenci
<br/>
February 2, 2021 | http://brooker.co.za/blog/2020/09/02/learning.html | <a href="https://web.archive.org/web/*/http://brooker.co.za/blog/2020/09/02/learning.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post">


<p>Skepticism and cynicism can get in your way.</p>


<p>Back in May, I wrote <a href="http://brooker.co.za/blog/2020/05/25/reading.html">Reading Research: A Guide for Software Engineers</a>, answering common questions I get about why and how to read research papers. In that post, I wrote about three modes of reading: <em>solution finding</em>, <em>discovery</em>, and <em>curiosity</em>. In subsequent conversations, I've realized there's another common issue that gets in engineers' ways when they read research, especially in the <em>discovery</em> and <em>curiosity</em> modes: too much skepticism.</p>

<blockquote><p><em>The chief deficiency I see in the skeptical movement is its polarization: Us vs. Them — the sense that we have a monopoly on the truth; that those other people who believe in all these stupid doctrines are morons; that if you're sensible, you'll listen to us; and if not, to hell with you.</em> (from Carl Sagan's <em>The Demon Haunted World</em>)</p></blockquote>

<p>I could blame it on comment thread culture, racing to make that top comment pointing out errors in the paper. I could blame it on the low signal-to-noise ratio of content in general. I could blame it on poor research, poor writing, or incorrect data. But whatever is to blame, many readers approach technical content with their first goal being to find errors and mistakes, gaps in logic, or incomplete justifications of statements. When a mistake is found, the reader is justified in throwing out the whole piece of writing (<em>unreliable!</em>), the authors (<em>sloppy!</em>), their institutions (<em>clueless!</em>), or even the whole field (<em>substandard!</em>). It's also a perfect opportunity to write that comment or tweet pointing out the problems. After all, if you found the author's mistake, doesn't that make you smarter and better than the author?</p>

<p>This approach gets in the way of your ability to learn from reading. I'd encourage you to take a different one: read with the goal of finding the good stuff. Dig for the ideas, the insights, the analyses and the data points that provide value. Look for what you can learn.</p>

<p>I'm not suggesting that you don't carefully approach what you read. You absolutely should make sure what you believe is well-supported. Don't waste your life reading crap. Your time is too valuable for that.</p>

<p>The flip side of this is relying too much on social proof. If you open the comment thread first, you'll find that the piece you're about to read is <em>great</em> or it's <em>crap</em> or it's <em>another piece of junk published by <strong>those people</strong> (you know, them, the incompetent ones)</em>. Then, when you finally read the paper, you'll be less smart. You'll be biased towards confirming the opinions of others, rather than reading and understanding the material. I'm not against comment threads, but I never read them first.</p>

<p>Again, you can go too far in this direction. A lot of academic publishing is an exercise in social proof. Almost all the filtering we use to reduce the firehose of content down to a manageable stream depends on social proof. We use these tools because they're powerful, and scalable. But remember than popularity with Hacker News commenters, and even publication in a prestigious conference or journal, is only weak evidence of quality. Unpopularity, and rejection, are weak evidence of a lack of quality.</p>

<p><strong>An Example</strong></p>

<p>Fox and Brewer's classic paper <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.33.411&amp;rep=rep1&amp;type=pdf">Harvest, Yield, and Scalable Tolerant Systems</a> contains many great ideas. The framing of Harvest and Yield is very useful, and I've found it's had a big influence on the way that I have approached system design over the years. The first time I read it, though, I put it down. The parts describing CAP (Section 2 and 3) are confusing at best and wrong at worst (as I've <a href="http://brooker.co.za/blog/2014/10/12/harvest-yield.html">blogged about before</a>). I couldn't get past them.</p>

<p>It was only after being encouraged by a colleague that I read the whole thing. Taken as a whole, it's full of great ideas. If I had kept tripping over my skepticism, and getting stuck on the bad parts, I never would have been able to learn from it.</p>

</div></div>]]>
            </description>
            <link>http://brooker.co.za/blog/2020/09/02/learning.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25999603</guid>
            <pubDate>Tue, 02 Feb 2021 11:08:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Typesafe Enum Class Bitmasks in C++]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25999076">thread link</a>) | @noch
<br/>
February 2, 2021 | https://www.strikerx3.dev/cpp/2019/02/27/typesafe-enum-class-bitmasks-in-cpp.html | <a href="https://web.archive.org/web/*/https://www.strikerx3.dev/cpp/2019/02/27/typesafe-enum-class-bitmasks-in-cpp.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>I’ve been working on <a href="https://github.com/StrikerX3/virt86">virt86</a> for a few weeks now, and some of the things I decided to focus on were type safety and making good use of modern C++ features. I did many things to reduce the chances for users to shoot their own foot with the library, such as <a href="https://github.com/StrikerX3/virt86/blob/d050883ee3931e6a0a74d3da9f6b948ee3cd0533/modules/core/include/virt86/platform/platform.hpp#L77">deleting move and copy constructors and assignment operators</a> from classes to make sure there is only one instance obtained from a known source, <a href="https://github.com/StrikerX3/virt86/blob/d050883ee3931e6a0a74d3da9f6b948ee3cd0533/modules/core/include/virt86/vp/vp.hpp#L108">deleting</a> or <a href="https://github.com/StrikerX3/virt86/blob/d050883ee3931e6a0a74d3da9f6b948ee3cd0533/modules/core/include/virt86/vm/vm.hpp#L326">hiding</a> the address operator <code>&amp;</code> so that users cannot get a pointer to objects that are not meant to be <code>delete</code>d and using <code>enum class</code> for type-safe enumerations.</p>

<p>I figured it would be interesting to use <code>enum class</code>es as bitmasks for their type-safety. Unfortunately, you cannot use them as is with bitwise operators, but you can use other C++ features to make them behave like a bitmask type.</p>

<!-- more -->

<h2 id="a-basic-version">A basic version</h2>

<p>I knew very little about <code>enum class</code>es at the time, so my first idea was to add methods to the type, assuming they would work like a <code>class</code>, however C++ disallows that. The next solution I thought of was to define operator overloads outside them, which I found out to be allowed by the language. Templates would make that even better.</p>

<p>While researching a bit about using <code>enum class</code> as bitmasks I came across a <a href="http://blog.bitwigglers.org/using-enum-classes-as-type-safe-bitmasks/">blog post</a> by Andre Haupt, which the author says is “a reiteration of a <a href="https://www.justsoftwaresolutions.co.uk/cplusplus/using-enum-classes-as-bitfields.html">blog post</a> by Anthony Williams”, which is exactly the kind of solution I envisioned. The post progressively expands from a motivating example based on <code>unsigned</code> values and regular <code>enums</code>, to a simple set of overloaded operators for an specific type of enumeration, to templates which encompass every <code>enum class</code> type, finishing with SFINAE to ensure only types tagged as bitmasks actually have access to the bitwise operators.</p>

<p>I took his code and modernized it a bit by introducing an alias template for the bitmask enum type trait value and using the alias template <code>std::underlying_type_t</code>, both of which saves a bit of typing overall. Here’s my version:</p>

<div><div><pre><code><span>#define ENABLE_BITMASK_OPERATORS(x)  \
template&lt;&gt;                           \
struct is_bitmask_enum&lt;x&gt; {          \
    static const bool enable = true; \
};
</span>
<span>template</span><span>&lt;</span><span>typename</span> <span>Enum</span><span>&gt;</span>
<span>struct</span> <span>is_bitmask_enum</span> <span>{</span>
    <span>static</span> <span>const</span> <span>bool</span> <span>enable</span> <span>=</span> <span>false</span><span>;</span>
<span>};</span>

<span>template</span><span>&lt;</span><span>class</span> <span>Enum</span><span>&gt;</span>
<span>inline</span> <span>constexpr</span> <span>bool</span> <span>is_bitmask_enum_v</span> <span>=</span> <span>is_bitmask_enum</span><span>&lt;</span><span>Enum</span><span>&gt;::</span><span>enable</span><span>;</span>

<span>// ----- Bitwise operators ----------------------------------------------------
</span>
<span>template</span><span>&lt;</span><span>typename</span> <span>Enum</span><span>&gt;</span>
<span>typename</span> <span>std</span><span>::</span><span>enable_if_t</span><span>&lt;</span><span>is_bitmask_enum_v</span><span>&lt;</span><span>Enum</span><span>&gt;</span><span>,</span> <span>Enum</span><span>&gt;</span>
<span>operator</span> <span>|</span><span>(</span><span>Enum</span> <span>lhs</span><span>,</span> <span>Enum</span> <span>rhs</span><span>)</span> <span>{</span>
    <span>using</span> <span>underlying</span> <span>=</span> <span>typename</span> <span>std</span><span>::</span><span>underlying_type_t</span><span>&lt;</span><span>Enum</span><span>&gt;</span><span>;</span>
    <span>return</span> <span>static_cast</span><span>&lt;</span><span>Enum</span><span>&gt;</span> <span>(</span>
        <span>static_cast</span><span>&lt;</span><span>underlying</span><span>&gt;</span><span>(</span><span>lhs</span><span>)</span> <span>|</span>
        <span>static_cast</span><span>&lt;</span><span>underlying</span><span>&gt;</span><span>(</span><span>rhs</span><span>)</span>
    <span>);</span>
<span>}</span>

<span>// ... similarly for &amp; and ^ and ~
</span>
<span>// ----- Bitwise assignment operators -----------------------------------------
</span>
<span>template</span><span>&lt;</span><span>typename</span> <span>Enum</span><span>&gt;</span>
<span>typename</span> <span>std</span><span>::</span><span>enable_if_t</span><span>&lt;</span><span>is_bitmask_enum_v</span><span>&lt;</span><span>Enum</span><span>&gt;</span><span>,</span> <span>Enum</span><span>&gt;</span>
<span>operator</span> <span>|=</span><span>(</span><span>Enum</span><span>&amp;</span> <span>lhs</span><span>,</span> <span>Enum</span> <span>rhs</span><span>)</span> <span>{</span>
    <span>using</span> <span>underlying</span> <span>=</span> <span>typename</span> <span>std</span><span>::</span><span>underlying_type_t</span><span>&lt;</span><span>Enum</span><span>&gt;</span><span>;</span>
    <span>lhs</span> <span>=</span> <span>static_cast</span><span>&lt;</span><span>Enum</span><span>&gt;</span> <span>(</span>
        <span>static_cast</span><span>&lt;</span><span>underlying</span><span>&gt;</span><span>(</span><span>lhs</span><span>)</span> <span>|</span>
        <span>static_cast</span><span>&lt;</span><span>underlying</span><span>&gt;</span><span>(</span><span>rhs</span><span>)</span>
    <span>);</span>
    <span>return</span> <span>lhs</span><span>;</span>
<span>}</span>

<span>// ... similarly for &amp;= and ^=
</span></code></pre></div></div>

<p>This is how the author demonstrated its usage, which is unchanged with my version:</p>

<div><div><pre><code><span>enum</span> <span>Permissions</span> <span>{</span>
    <span>Readable</span> <span>=</span> <span>0x4</span><span>,</span> <span>Writable</span> <span>=</span> <span>0x2</span><span>,</span> <span>Executable</span> <span>=</span> <span>0x1</span>
<span>};</span>

<span>Permissions</span> <span>p</span> <span>=</span> <span>Permissions</span><span>::</span><span>Readable</span> <span>|</span> <span>Permissions</span><span>::</span><span>Writable</span><span>;</span>  
<span>p</span> <span>|=</span> <span>Permissions</span><span>::</span><span>Executable</span><span>;</span>  
<span>p</span> <span>&amp;=</span> <span>~</span><span>Permissions</span><span>::</span><span>Writable</span><span>;</span>
</code></pre></div></div>

<h2 id="limitations">Limitations</h2>

<p>The original version falls short when it comes to another common use case for bitmasks: checking if a bitmask contains a particular bit. You have to do some convoluted and repetitive code to achieve that:</p>

<div><div><pre><code><span>if</span> <span>((</span><span>p</span> <span>&amp;</span> <span>Permissions</span><span>::</span><span>Executable</span><span>)</span> <span>==</span> <span>Permissions</span><span>::</span><span>Executable</span><span>)</span> <span>{</span>
    <span>// p has Executable
</span><span>}</span>
</code></pre></div></div>

<p>And what if we need to check if the bitmask contains at least one bit of a set of multiple bits?</p>

<div><div><pre><code><span>Permissions</span> <span>rw</span> <span>=</span> <span>Permissions</span><span>::</span><span>Readable</span> <span>|</span> <span>Permissions</span><span>::</span><span>Writable</span><span>;</span>
<span>if</span> <span>((</span><span>p</span> <span>&amp;</span> <span>rw</span><span>)</span> <span>...</span> <span>??</span><span>)</span> <span>{</span>
    <span>// p has at least one of Readable, Writable
</span><span>}</span>
</code></pre></div></div>

<p>One way to solve this problem is to add a <code>None = 0</code> entry to the enum. Or you could resort to <code>static_cast</code>:</p>

<div><div><pre><code><span>Permissions</span> <span>rw</span> <span>=</span> <span>Permissions</span><span>::</span><span>Readable</span> <span>|</span> <span>Permissions</span><span>::</span><span>Writable</span><span>;</span>
<span>if</span> <span>((</span><span>p</span> <span>&amp;</span> <span>rw</span><span>)</span> <span>!=</span> <span>static_cast</span><span>&lt;</span><span>Permissions</span><span>&gt;</span><span>(</span><span>0</span><span>))</span> <span>{</span>
    <span>// p has at least one of Readable, Writable
</span><span>}</span>
</code></pre></div></div>

<p>But this is still too cumbersome. Wouldn’t it be great if you could write those conditions like this?</p>

<div><div><pre><code><span>if</span> <span>(</span><span>p</span><span>.</span><span>AllOf</span><span>(</span><span>Permissions</span><span>::</span><span>Executable</span><span>))</span> <span>{</span>
    <span>// p has Executable
</span><span>}</span>
<span>if</span> <span>(</span><span>p</span><span>.</span><span>AnyOf</span><span>(</span><span>Permissions</span><span>::</span><span>Readable</span> <span>|</span> <span>Permissions</span><span>::</span><span>Writable</span><span>))</span> <span>{</span>
    <span>// p has at least one of Readable, Writable
</span><span>}</span>
</code></pre></div></div>

<p>We could even introduce new checks, such as:</p>

<div><div><pre><code><span>if</span> <span>(</span><span>p</span><span>.</span><span>NoneOf</span><span>(</span><span>Permissions</span><span>::</span><span>Writable</span><span>))</span> <span>{</span>
    <span>// p does not have Writable, but may have other bits
</span><span>}</span>
<span>if</span> <span>(</span><span>p</span><span>.</span><span>AnyExcept</span><span>(</span><span>Permissions</span><span>::</span><span>Executable</span><span>))</span> <span>{</span>
    <span>// p does not have Executable and has at least one of the other bits
</span><span>}</span>
</code></pre></div></div>

<p>Unfortunately, we hit the same wall again: <code>enum class</code>es cannot have methods.</p>

<h2 id="enter-the-struct">Enter the struct</h2>

<p>The solution I came up with is to introduce a <code>struct</code> template which wraps an <code>enum class</code> and provides the check methods.</p>

<div><div><pre><code><span>template</span><span>&lt;</span><span>typename</span> <span>Enum</span><span>&gt;</span>
<span>struct</span> <span>BitmaskEnum</span> <span>{</span>
    <span>const</span> <span>Enum</span> <span>value</span><span>;</span>
    <span>static</span> <span>const</span> <span>Enum</span> <span>none</span> <span>=</span> <span>static_cast</span><span>&lt;</span><span>Enum</span><span>&gt;</span><span>(</span><span>0</span><span>);</span>

    <span>using</span> <span>underlying</span> <span>=</span> <span>typename</span> <span>std</span><span>::</span><span>underlying_type_t</span><span>&lt;</span><span>Enum</span><span>&gt;</span><span>;</span>

    <span>BitmaskEnum</span><span>(</span><span>Enum</span> <span>value</span><span>)</span> <span>:</span> <span>value</span><span>(</span><span>value</span><span>)</span> <span>{</span>
        <span>static_assert</span><span>(</span><span>is_bitmask_enum_v</span><span>&lt;</span><span>Enum</span><span>&gt;</span><span>);</span>
    <span>}</span>

    <span>// ... operations here
</span><span>};</span>
</code></pre></div></div>

<p>The basic checks we want to implement are:</p>

<ul>
  <li><code>Any()</code>: <code>true</code> if the bitmask contains any bits</li>
  <li><code>None()</code>: <code>true</code> if the bitmask is empty</li>
  <li><code>AnyOf(Enum)</code>: <code>true</code> if the bitmask contains one or more bits from the given bitmask</li>
  <li><code>AllOf(Enum)</code>: <code>true</code> if the bitmask contains all bits from the given bitmask</li>
  <li><code>NoneOf(Enum)</code>: <code>true</code> if the bitmask doesn’t contain any bit from the given bitmask</li>
  <li><code>AnyExcept(Enum)</code>: <code>true</code> if the bitmask contains any bits excluding those from the given bitmask</li>
  <li><code>NoneExcept(Enum)</code>: <code>true</code> if the bitmask doesn’t contain any bits excluding those from the given bitmask</li>
</ul>

<p>It would be very handy to have an <code>EnumBitmask</code> to convert back into the <code>Enum</code> value or a <code>bool</code>, the latter of which is a very common use case with regular <code>enum</code>s or even <code>int</code>s to check if the bitmask has any bits set.</p>

<p>The implementations of these operations are left as an exercise to the reader.</p>

<p>Here’s how to use the <code>BitmaskEnum</code>:</p>

<div><div><pre><code><span>Permissions</span> <span>p</span> <span>=</span> <span>Permissions</span><span>::</span><span>Readable</span> <span>|</span> <span>Permissions</span><span>::</span><span>Writable</span><span>;</span>
<span>auto</span> <span>pBM</span> <span>=</span> <span>BitmaskEnum</span><span>(</span><span>p</span><span>);</span>
<span>if</span> <span>(</span><span>pBM</span><span>.</span><span>AllOf</span><span>(</span><span>Permissions</span><span>::</span><span>Executable</span><span>))</span> <span>{</span>
    <span>// p has Executable
</span><span>}</span>
<span>if</span> <span>(</span><span>pBM</span><span>.</span><span>AnyOf</span><span>(</span><span>Permissions</span><span>::</span><span>Readable</span> <span>|</span> <span>Permissions</span><span>::</span><span>Writable</span><span>))</span> <span>{</span>
    <span>// p has at least one of Readable, Writable
</span><span>}</span>
<span>if</span> <span>(</span><span>pBM</span><span>.</span><span>NoneOf</span><span>(</span><span>Permissions</span><span>::</span><span>Writable</span><span>))</span> <span>{</span>
    <span>// p does not have Writable, but may have other bits
</span><span>}</span>
<span>if</span> <span>(</span><span>pBM</span><span>.</span><span>AnyExcept</span><span>(</span><span>Permissions</span><span>::</span><span>Executable</span><span>))</span> <span>{</span>
    <span>// p does not have Executable and has at least one of the other bits
</span><span>}</span>
</code></pre></div></div>

<p>Much nicer and easier to understand. The best part of it? It’s a <a href="http://www.stroustrup.com/ETAPS-corrected-draft.pdf">zero overhead abstraction</a>. No runtime costs at all. Here’s a <a href="https://gist.github.com/StrikerX3/46b9058d6c61387b3f361ef9d7e00cd4">gist</a> containing a header file taken straight out of <a href="https://github.com/StrikerX3/virt86/blob/master/modules/core/include/virt86/util/bitmask_enum.hpp">virt86</a>, along with a cpp file you can use in <a href="https://godbolt.org/">Compiler Explorer</a> to check that this is indeed free. (Except MSVC, which still compiles every method in the struct, even though none of them are used, but the <code>test()</code> function is essentially the same.)</p>

<p><a href="https://www.strikerx3.dev/assets/2.1-compiler-explorer.png" target="_blank"><img src="https://www.strikerx3.dev/assets/2.1-compiler-explorer.png" alt="Optimized down to a simple return!"></a><br>
<strong>Optimized down to a simple return!</strong></p>

<h2 id="caveats">Caveats</h2>

<p>One thing to keep in mind, however, is that it is illegal to specialize a template in a different namespace. This will happen if you define an <code>enum class</code> in a namespace and immediately use the macro still within the namespace:</p>

<div><div><pre><code><span>namespace</span> <span>foo</span> <span>{</span>

<span>enum</span> <span>class</span> <span>Bar</span> <span>{</span>
    <span>...</span>
<span>}</span>
<span>ENABLE_BITMASK_OPERATORS</span><span>(</span><span>Bar</span><span>)</span>
<span>// error: specialization of ‘template&lt;class Enum&gt; struct is_bitmask_enum’ in different namespace [-fpermissive]
</span>
<span>}</span>
</code></pre></div></div>

<p>One solution to this is to use the macro after the namespace block, referring to the <code>enum class</code> via its namespace:</p>

<div><div><pre><code><span>namespace</span> <span>foo</span> <span>{</span>

<span>enum</span> <span>class</span> <span>Bar</span> <span>{</span>
    <span>...</span>
<span>}</span>

<span>}</span>

<span>ENABLE_BITMASK_OPERATORS</span><span>(</span><span>foo</span><span>::</span><span>Bar</span><span>)</span>
<span>// good to go
</span>
</code></pre></div></div>

<p>I hope this helps you use the type-safe <code>enum class</code> as bitmasks more comfortably!</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://www.strikerx3.dev/cpp/2019/02/27/typesafe-enum-class-bitmasks-in-cpp.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25999076</guid>
            <pubDate>Tue, 02 Feb 2021 09:57:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Book Review: Refactoring for Software Design Smells]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25999057">thread link</a>) | @sandordargo
<br/>
February 2, 2021 | https://www.sandordargo.com/blog/2021/01/30/refactoring-for-software-design-smells | <a href="https://web.archive.org/web/*/https://www.sandordargo.com/blog/2021/01/30/refactoring-for-software-design-smells">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    
    <p>I was looking for some books for these months taking into consideration that I should improve my architecture and design skills. So <a href="https://devreads.sandordargo.com/emergent-design/">I recently read Emergent Design</a> and now <a href="https://amzn.to/36rDKbh">Refactoring for Software Design Smells</a>. I don’t remember where I saw it recommended, but when I started to browse the book (I use O’Reilly), I saw it was recommended by the ACM fellow, Grady Booch. The person who authored <a href="https://amzn.to/2MBmvNU">Object-Oriented Analysis and Design With Applications</a> and who said that code should read like well-written prose. It seemed to be a good recommendation.</p>

<p>Was it worth to read the book? Let’s find it out together.
<!--more--></p>

<h2 id="what-is-technical-debt">What is technical debt?</h2>

<p>In the part of the book, the authors discuss what is technical debt, what kinds of technical debts are out there and what are their root causes.</p>

<h3 id="the-well-known-metaphor">The well-known metaphor</h3>

<p>The authors use the well-known metaphor, originally introduced by Ward Cunningham, the one that compares technical debt to financial debt.</p>

<p>You might invest in something that you don’t have money for at a given point in time, by taking on some loans. That’s possible and sometimes even desirable. But if you do so, you have to soon start paying back your debts, you have to pay the interests. If you don’t do that, if you postpone paying back your dues, the amount of interest will rise. They will keep rising until a point where they become unbearable and you have to declare bankruptcy and lose your home, your investment, etc.</p>

<p>Technical debt is like that. You can introduce some sloppy solutions to hit the market faster, to get faster feedback, but that doesn’t come for free.</p>

<p>You either pay back your technical debt, by cleaning up your code, by refactoring it, or the inevitable changes will be more difficult to implement. They can become so difficult that you simply wouldn’t even date to touch the code.</p>

<h3 id="four-kinds-of-technical-debt">Four kinds of technical debt</h3>

<p>The authors differentiate among 4 different categories of technical debt:</p>

<ul>
  <li>code debt</li>
  <li>design debt</li>
  <li>test debt</li>
  <li>documentation debt</li>
</ul>

<p>I think that test documentation debt are self-explaining categories. You either don’t write tests or documentation and therefore your level of trust in the code, your level of confidence to change it will decrease (test code), or it will be simply difficult to get relevant information about the code, about the features as you lack documentation.</p>

<p>The line between code and design bet can be thin, but in general code debt, code smells refer to much lower-level problems such as how you write a loop, how your functions are structured within a class, while design debt is more about how classes and even modules interact with each other.</p>

<p>The book focuses on the design debt, the design smells and how to remove them from a technical point of view.</p>

<h3 id="why-do-we-have-technical-debt">Why do we have technical debt?</h3>

<p>There are different reasons why technical debt is introduced. And just like for financial debt, there can be good and wrong reasons.</p>

<p>One cause is <strong>schedule pressure</strong>. If it’s constant and happens all the time, then it’s obviously bad and most probably you won’t take the time to fix the introduced smells. But from time to time, it can be crucial to get out to the market as fast as possible, and you can win big with it.</p>

<p>The other three reasons identified by the authors can hardly be categorized as good reasons. It’s simply bad people or bad technical management:</p>

<ul>
  <li>lack of good/skilled designers</li>
  <li>lack of application design principles</li>
  <li>lack of awareness of design smells and refactoring</li>
</ul>

<p>Management either doesn’t hire the right people for the job / the composition of the team is not a good match for the problems to tackle.</p>

<p>This book teaches about the principles of good design and makes the readers aware of the relevant design smalls and the available refactoring techniques. Though if you need more details on the refactoring techniques, you’ll have to follow up with other sources.</p>

<h2 id="design-smells">Design smells</h2>

<p>Before jumping into the details of the many different design smells, the authors lay down the foundations by stating what they mean by design smells and what characteristics they have.</p>

<blockquote>
  <p>“Design smells are certain structures in the design that indicate violation of fundamental design principles and negatively impact design quality.”</p>
</blockquote>

<h3 id="affected-attributes-of-a-software">Affected attributes of a software</h3>

<p>Design smells can hurt software in many different ways. In the <a href="https://amzn.to/36rDKbh">book</a>, there are seven quality attributes listed.</p>

<ul>
  <li>Understandability: how easy it is to understand the design of an application?</li>
  <li>Changeability: how easy it is to change the functionality of an application, or will it just break at unexpected places?</li>
  <li>Extensibility: in case of the need for new functionality arises, will it be easy to implement or…?</li>
  <li>Reusability: can you reuse some parts of the software at other places?</li>
  <li>Testability: is the design welcoming for tests or will it be a difficult challenge resulting that people will eventually stop testing?</li>
  <li>Reliability: with the design in place is easy to implement the requirements correctly? Will it help to avoid runtime issues?</li>
</ul>

<p>Later in the book, for each design smell, it’s studies which quality attributes they affect.</p>

<h3 id="what-are-the-main-design-principles">What are the main design principles?</h3>

<p>The authors enumerate 4 design principles and they use those to categorize the smells too:</p>

<ul>
  <li>Abstraction: eliminate the details and generalize</li>
  <li>Encapsulation: hide the details</li>
  <li>Modularization:  Abstractions should be cohesive and loosely coupled</li>
  <li>Hierarchy: organize abstractions in clear hierarchical structures</li>
</ul>

<h3 id="why-are-the-principles-violated">Why are the principles violated?</h3>

<p>Sometimes, <em>we simply don’t know about them</em> so we cannot take them into consideration. Other times, <em>we misunderstand them</em>. We try to create something according to a pattern we read about, but we lack the experience and we implement it in an incorrect way.</p>

<p>Often it happens that <em>we don’t think in an object-oriented way</em> and we come up with implementations that are procedural. It might be because we worked in a language where that was enforced and <em>there were strong language limitations</em> preventing the devs from using modern designs.</p>

<p>Or we simply don’t care for any reason…</p>

<h2 id="so-many-design-smells">So many design smells</h2>

<p>In the biggest part of the book, you will find 25 design smells discussed in details. The scope of this book review obviously doesn’t let me introduce you all of them, so I picked 3 design smells that I want to mention.</p>

<h3 id="imperative-abstraction">Imperative Abstraction</h3>

<p>I choose this one because that’s something I regularly do myself. I turn operations into classes.</p>

<p>You can recognize this smell when there is only one - public - method defined within the class. Even worse, the class name and the method name might be the same. In C++, sometimes I just override the <code>operator()</code> to get rid of this problem.</p>

<p>As a solution, the authors suggest to move such an operation to the abstraction that uses it, often there is only one user of this class/method.</p>

<p>By that, the design becomes cleaner and less complex.</p>

<p>When I offend this role, it’s often because I have to fix some legacy code and I have no time, to do major a refactoring, but I want to extract some behaviour, in fact, an operation, so that I can easily test it.</p>

<p>I understand it would be better to extract the data along with the behaviour so that they constitute a cohesive entity, even though it takes more effort to refactor that way.</p>

<h3 id="multifaceted-abstraction">Multifaceted Abstraction</h3>

<p>This is something that happens a lot. We see it everywhere and we also contribute with our fair share to worsen the situation.</p>

<p>A multifaceted abstraction has a too wide API, it has too many responsibilities. In fact, it’s an offence against the <a href="https://en.wikipedia.org/wiki/Single-responsibility_principle">Single Responsibility Principle</a>.</p>

<p>The authors bring many examples, even from the core of Java SDK libraries.</p>

<p>The solution is quite straightforward, but of course, not so easy to carry out all the time: extract classes, divide them into smaller, cohesive abstractions.</p>

<h3 id="deficient-encapsulation">Deficient Encapsulation</h3>

<p>Do you automatically create a pair of getters and setters for the members of a class? Some IDEs will even help you do that.</p>

<p>With that, you’ll leak many implementation details. Details that the clients of the class should not depend on.</p>

<p>The problem is that it’s quite difficult to change the situation. You might also know this as <a href="https://www.hyrumslaw.com/">Hyrum’s law</a>:</p>

<blockquote>
  <p>With a sufficient number of users of an API,
it does not matter what you promise in the contract:
all observable behaviours of your system
will be depended on by somebody.</p>
</blockquote>

<p>Often, it’s compelling to make internal methods publicly accessible for the sake of testability, but if you have to do that, it only means that your design is bad.</p>

<p>You have to take into consideration the effects. Often, if you work in an internal codebase, it will be an acceptable compromise. You expose a method, you make it testable and you know that the external world will have no access to it. But if you’d it a library used by many, you should really look for another solution.</p>

<h2 id="conclusion">Conclusion</h2>

<p>In <a href="https://amzn.to/36rDKbh">Refactoring for Software Design Smells</a> the authors explain what 4 design principles should we use to achieve a high-quality design and what are the main reasons behind failure to achieve it.</p>

<p>Then they analyze 25 design smells categorized by the 4 design principles. For each we read about how they appear, what quality attributes they hurt and what can we do about them.</p>

<p>If you are looking for levelling up your software design knowledge, I think this book is worth to read. You’ll realize how many smells you also introduce to your code with the best intention and you’ll also get some recipes on how to avoid them.</p>

<p>Happy reading!</p>

    
  </section></div>]]>
            </description>
            <link>https://www.sandordargo.com/blog/2021/01/30/refactoring-for-software-design-smells</link>
            <guid isPermaLink="false">hacker-news-small-sites-25999057</guid>
            <pubDate>Tue, 02 Feb 2021 09:54:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[UUID Primary Key in Elixir Phoenix with PostgreSQL and Ecto]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25998969">thread link</a>) | @pawurb
<br/>
February 2, 2021 | https://pawelurbanek.com/elixir-phoenix-uuid | <a href="https://web.archive.org/web/*/https://pawelurbanek.com/elixir-phoenix-uuid">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<p><img title="UUID in PostgreSQL Ecto and Phoenix are presented by sheep Photo by Massimiliano Martini on Unsplash" alt="UUID in PostgreSQL Ecto and Phoenix are presented by sheep Photo by Massimiliano Martini on Unsplash" data-src="https://pawelurbanek.com/assets/phoenix-uuid-berries-5f0a260a1179e9d85a99e145fe21aac830bf6ce4f69f8bbf020559f7daeca581.jpg" src="https://pawelurbanek.com/assets/phoenix-uuid-berries-thumb-0e16f18ada64c57876f3eee963c36f40cace0df97c72189ecb3dca601e5b1521.jpg">
</p>
<br>


<p>UUID also known as GUID is an alternative primary key type for SQL databases. It offers some non-obvious advantages compared to standard integer-based keys. Phoenix provides reliable support for working with UUID using its Ecto PostgreSQL adapter. In this tutorial, we will dive deep into UUIDs with all their cons and pros.</p>
<h2 id="benefits-of-using-uuids-instead-of-integers">Benefits of using UUIDs instead of integers</h2>
<p>UUID is a random string in a predefined format. Sample value looks like that:</p>
<p><code>ccbb63c0-a8cd-47b7-8445-5d85e9c80977</code></p>
<p>UUID is superior to integer-based primary keys in many ways. One caveat might be the size of database indexes, but for non-big-data tables, you shouldn’t notice the difference between integers and UUIDs.</p>


<h3 id="exposing-non-public-information-in-urls">Exposing non-public information in URLs</h3>
<p>A primary key value is usually publicly discoverable in URLs and API network logs. In turn, everyone can roughly estimate the app’s resources, total number, and pace of growth. Do you really want to expose how many users are signing up to your service or how many products you are selling with public URLs like:</p>
<div><div><pre><code>/orders/2234/checkout
/users/287/profile
</code></pre></div></div>
<p>This issue could be mitigated by adding slugs, but these are just duplicated unique keys with additional maintenance required.</p>
<p>Switching to UUID results in URLs that don’t expose any potentially confidential information:</p>
<div><div><pre><code>/orders/cc7a4c8b-1a90-4287-a983-3f6e10bd88d4/checkout
/users/6b6cabb3-e37d-4dd1-ae18-a4eb893b07ae/profile
</code></pre></div></div>
<h3 id="access-scoping-bugs">Access scoping bugs</h3>
<p>Properly scoping access to resources in web apps with non-trivial business logic is hard. It’s possible to ship code like:</p>
<figure><pre><code data-lang="elixir"><span>defmodule</span> <span>YourAppWeb</span><span>.</span><span>InvoiceController</span> <span>do</span>
  <span># ...</span>

  <span>def</span> <span>show</span><span>(</span><span>conn</span><span>,</span> <span>%{</span><span>"</span><span>id"</span> <span>=&gt;</span> <span>id</span><span>})</span> <span>do</span>
    <span>invoice</span> <span>=</span> <span>Repo</span><span>.</span><span>get</span><span>(</span><span>Invoice</span><span>,</span> <span>id</span><span>)</span>

    <span>render</span><span>(</span><span>conn</span><span>,</span> <span>"</span><span>show.html"</span><span>,</span> <span>invoice:</span> <span>invoice</span><span>)</span>
  <span>end</span>
<span>end</span></code></pre></figure>
<p>instead of:</p>
<figure><pre><code data-lang="elixir"><span>defmodule</span> <span>YourAppWeb</span><span>.</span><span>InvoiceController</span> <span>do</span>
  <span># ...</span>

  <span>def</span> <span>show</span><span>(</span><span>conn</span><span>,</span> <span>%{</span><span>"</span><span>id"</span> <span>=&gt;</span> <span>id</span><span>},</span> <span>current_user</span><span>)</span> <span>do</span>
    <span>invoice</span> <span>=</span> <span>Repo</span><span>.</span><span>one</span><span>(</span>
                <span>from</span> <span>a</span> <span>in</span> <span>Invoice</span><span>,</span>
                <span>where:</span> <span>a</span><span>.</span><span>id</span> <span>==</span> <span>^</span><span>id</span> <span>and</span> <span>a</span><span>.</span><span>user_id</span> <span>==</span> <span>^</span><span>current_user</span><span>.</span><span>id</span>
              <span>)</span>

    <span>render</span><span>(</span><span>conn</span><span>,</span> <span>"</span><span>show.html"</span><span>,</span> <span>invoice:</span> <span>invoice</span><span>)</span>
  <span>end</span>
<span>end</span></code></pre></figure>
<p>This example might seem obvious, but in apps with multiple user roles and complex logic for who can access what, it’s not always possible to completely prevent similar mistakes.</p>
<p>If invoice ID was a UUID type in the above example, it would make it impossible for an attacker to sequentially scan integer ID values looking for a security hole. This simple change makes a range of potential security bugs extremely unlikely to exploit.</p>
<p>By no means, I claim that using UUID releases you from the necessity to scope access to resources in your web app. Still, it might save you in case a similar security loophole was discovered in your project.</p>
<h3 id="frontend-independence">Frontend “independence”</h3>
<p>UUID primary keys allow frontend applications to independently generate new objects, together with IDs, without talking to the backend. A unique ID can be created using the JavaScript code, and the chances of collision with already existing objects are negligible.</p>
<p>This approach opens up a whole array of possibilities for frontend developers, e.g., to batch create objects together with their associations without the overhead of API calls.</p>
<h2 id="uuid-formats-in-elixir-ecto">UUID formats in Elixir Ecto</h2>
<p>You can generate UUID with Elixir by running:</p>
<figure><pre><code data-lang="elixir"><span>Ecto</span><span>.</span><span>UUID</span><span>.</span><span>generate</span><span>()</span>
<span># "b436517a-e294-4211-8312-8576933f2db1"</span></code></pre></figure>
<p>Under the hood string format of UUID is converted to binary when interacting with the database layer. To generate a sample binary UUID run:</p>
<figure><pre><code data-lang="elixir"><span>Ecto</span><span>.</span><span>UUID</span><span>.</span><span>bingenerate</span><span>()</span>
<span># &lt;&lt;72, 143, 56, 198, 127, 12, 78, 152, 141, 149, 101, 55, 70, 15, 236, 224&gt;&gt;</span></code></pre></figure>
<p>You can convert one format to another in the following way:</p>
<figure><pre><code data-lang="elixir"><span>Ecto</span><span>.</span><span>UUID</span><span>.</span><span>dump</span><span>(</span><span>"</span><span>b436517a-e294-4211-8312-8576933f2db1"</span><span>)</span>

<span># {:ok, &lt;&lt;180, 54, 81, 122, 226, 148, 66, 17, 131, 18, 133, 118, 147, 63, 45, 177&gt;&gt;}</span>

<span>Ecto</span><span>.</span><span>UUID</span><span>.</span><span>load</span><span>(</span><span>&lt;&lt;</span><span>180</span><span>,</span> <span>54</span><span>,</span> <span>81</span><span>,</span> <span>122</span><span>,</span> <span>226</span><span>,</span> <span>148</span><span>,</span> <span>66</span><span>,</span> <span>17</span><span>,</span> <span>131</span><span>,</span> <span>18</span><span>,</span> <span>133</span><span>,</span> <span>118</span><span>,</span> <span>147</span><span>,</span> <span>63</span><span>,</span> <span>45</span><span>,</span> <span>177</span><span>&gt;&gt;</span><span>)</span>

<span># {:ok, "b436517a-e294-4211-8312-8576933f2db1"}</span></code></pre></figure>
<h2 id="how-to-start-using-uuid-in-elixir-phoenix-apps">How to start using UUID in Elixir Phoenix apps</h2>
<p>First, generate the following migration:</p>
<p><code>priv/repo/migrations/20201217143615_create_users.exs</code></p>
<figure><pre><code data-lang="elixir"><span>defmodule</span> <span>YourApp</span><span>.</span><span>Repo</span><span>.</span><span>Migrations</span><span>.</span><span>CreateUsers</span> <span>do</span>
  <span>use</span> <span>Ecto</span><span>.</span><span>Migration</span>

  <span>def</span> <span>change</span> <span>do</span>
    <span>create</span> <span>table</span><span>(</span><span>:users</span><span>,</span> <span>primary_key:</span> <span>false</span><span>)</span> <span>do</span>
      <span>add</span> <span>:id</span><span>,</span> <span>:uuid</span><span>,</span> <span>primary_key:</span> <span>true</span><span>,</span> <span>null:</span> <span>false</span>

      <span>timestamps</span><span>()</span>
    <span>end</span>
  <span>end</span>
<span>end</span></code></pre></figure>
<p>Don’t forget to run it:</p>
<figure><pre><code data-lang="bash">mix ecto.migrate</code></pre></figure>
<p>Now add the corresponding schema module:</p>
<p><code>lib/your_app/accounts/user.ex</code></p>
<figure><pre><code data-lang="elixir"><span>defmodule</span> <span>YourApp</span><span>.</span><span>Accounts</span><span>.</span><span>User</span> <span>do</span>
  <span>use</span> <span>Ecto</span><span>.</span><span>Schema</span>
  <span>import</span> <span>Ecto</span><span>.</span><span>Changeset</span>

  <span>@primary_key</span> <span>{</span><span>:id</span><span>,</span> <span>Ecto</span><span>.</span><span>UUID</span><span>,</span> <span>autogenerate:</span> <span>true</span><span>}</span>

  <span>schema</span> <span>"</span><span>users"</span> <span>do</span>
    <span>timestamps</span><span>()</span>
  <span>end</span>
<span>end</span></code></pre></figure>
<p>You can use string UUID format when building queries. Just remember always to prefix even the literal values with <code>^</code> because otherwise, you’ll get a somewhat cryptic error:</p>
<figure><pre><code data-lang="elixir"><span># Incorrect</span>

<span>Repo</span><span>.</span><span>one</span><span>(</span>
  <span>from</span> <span>a</span> <span>in</span> <span>Area</span><span>,</span>
  <span>where:</span> <span>a</span><span>.</span><span>id</span> <span>==</span> <span>"</span><span>1e24165e-7f1d-4169-8ebe-869b7d1b7c90"</span>
<span>)</span>

<span># ** (EXIT from #PID&lt;0.470.0&gt;) shell process exited with reason: an exception was raised:</span>
<span># ** (ArgumentError) argument error</span>
<span># (stdlib 3.13.2) :io.put_chars(:standard_io, :unicode</span>

<span>Repo</span><span>.</span><span>one</span><span>(</span>
  <span>from</span> <span>a</span> <span>in</span> <span>Area</span><span>,</span>
  <span>where:</span> <span>a</span><span>.</span><span>id</span> <span>==</span> <span>^</span><span>"</span><span>1e24165e-7f1d-4169-8ebe-869b7d1b7c90"</span>
<span>)</span>

<span># %YourApp.Accounts.User{ ... }</span></code></pre></figure>
<h3 id="generating-uuid-using-postgresql-function">Generating UUID using PostgreSQL function</h3>
<p><code>autogenerate: true</code> configures Ecto to generate random UUID values for newly created objects. Alternatively, you could generate UUIDs at the PostgreSQL level by editing your migration like that:</p>
<figure><pre><code data-lang="elixir"><span>defmodule</span> <span>YourApp</span><span>.</span><span>Repo</span><span>.</span><span>Migrations</span><span>.</span><span>CreateUsers</span> <span>do</span>
  <span>use</span> <span>Ecto</span><span>.</span><span>Migration</span>

  <span>def</span> <span>change</span> <span>do</span>
    <span>execute</span> <span>"</span><span>CREATE EXTENSION IF NOT EXISTS pgcrypto"</span>

    <span>create</span> <span>table</span><span>(</span><span>:users</span><span>,</span> <span>primary_key:</span> <span>false</span><span>)</span> <span>do</span>
      <span>add</span> <span>:id</span><span>,</span> <span>:uuid</span><span>,</span> <span>primary_key:</span> <span>true</span><span>,</span> <span>null:</span> <span>false</span><span>,</span> <span>default:</span> <span>fragment</span><span>(</span><span>"</span><span>gen_random_uuid()"</span><span>)</span>

      <span>timestamps</span><span>()</span>
    <span>end</span>
  <span>end</span>
<span>end</span></code></pre></figure>
<p>If you decide to do it, remember to use the <code>returning</code> option when inserting new objects. Without it, Ecto would not fetch default column values generated by PostgreSQL functions.</p>
<figure><pre><code data-lang="elixir">  <span>def</span> <span>create_user</span><span>(</span><span>attrs</span><span>)</span> <span>do</span>
    <span>%</span><span>User</span><span>{}</span>
    <span>|&gt;</span> <span>User</span><span>.</span><span>changeset</span><span>(</span><span>attrs</span><span>)</span>
    <span>|&gt;</span> <span>Repo</span><span>.</span><span>insert</span><span>(</span><span>returning:</span> <span>[</span><span>:id</span><span>])</span>
  <span>end</span></code></pre></figure>
<p>Let’s have a look at the resulting SQL query with and without <code>returning: [:id]</code> config:</p>
<figure><pre><code data-lang="sql"><span>INSERT</span> <span>INTO</span> <span>"users"</span> <span>(</span><span>"email"</span><span>,</span><span>"inserted_at"</span><span>,</span><span>"updated_at"</span><span>)</span>
  <span>VALUES</span> <span>(</span><span>$</span><span>1</span><span>,</span><span>$</span><span>2</span><span>,</span><span>$</span><span>3</span><span>)</span>
  <span>[</span><span>"<a href="https://pawelurbanek.com/cdn-cgi/l/email-protection" data-cfemail="c3a6aea2aaaf83a6bba2aeb3afa6eda0acae">[email&nbsp;protected]</a>"</span><span>,</span> <span>~</span><span>N</span><span>[</span><span>2021</span><span>-</span><span>01</span><span>-</span><span>14</span> <span>15</span><span>:</span><span>46</span><span>:</span><span>49</span><span>],</span> <span>~</span><span>N</span><span>[</span><span>2021</span><span>-</span><span>01</span><span>-</span><span>14</span> <span>15</span><span>:</span><span>46</span><span>:</span><span>49</span><span>]]</span></code></pre></figure>
<p>Insert query without <code>returning</code> option</p>
<figure><pre><code data-lang="sql"><span>INSERT</span> <span>INTO</span> <span>"users"</span> <span>(</span><span>"email"</span><span>,</span><span>"inserted_at"</span><span>,</span><span>"updated_at"</span><span>)</span>
  <span>VALUES</span> <span>(</span><span>$</span><span>1</span><span>,</span><span>$</span><span>2</span><span>,</span><span>$</span><span>3</span><span>)</span> <span>RETURNING</span> <span>"id"</span>
  <span>[</span><span>"<a href="https://pawelurbanek.com/cdn-cgi/l/email-protection" data-cfemail="92f7fff3fbfed2f7eaf3ffe2fef7bcf1fdff">[email&nbsp;protected]</a>"</span><span>,</span> <span>~</span><span>N</span><span>[</span><span>2021</span><span>-</span><span>01</span><span>-</span><span>14</span> <span>15</span><span>:</span><span>46</span><span>:</span><span>49</span><span>],</span> <span>~</span><span>N</span><span>[</span><span>2021</span><span>-</span><span>01</span><span>-</span><span>14</span> <span>15</span><span>:</span><span>46</span><span>:</span><span>49</span><span>]]</span></code></pre></figure>
<p>Insert query with <code>returning</code> option</p>
<h3 id="using-uuid-as-a-default">Using UUID as a default</h3>
<p>If you’re starting a new project and would like all your schemas to leverage UUIDs for primary keys without customizing their migrations, you need to add the following line to your config file.</p>
<p><code>config/config.exs</code></p>
<figure><pre><code data-lang="elixir"><span>config</span> <span>:your_app</span><span>,</span> <span>yourapp</span><span>.</span><span>repo</span><span>,</span> <span>migration_primary_key:</span> <span>[</span><span>type:</span> <span>:uuid</span><span>]</span></code></pre></figure>
<p>If you did not create the project yet, you could use a <code>--binary-id</code> flag to configure it automatically:</p>
<figure><pre><code data-lang="bash">mix phx.new your_app <span>--binary-id</span></code></pre></figure>
<h2 id="how-to-migrate-a-table-from-integer-to-uuid-primary-key">How to migrate a table from integer to UUID primary key?</h2>
<p>Changing the primary key type in the table is not straightforward. You need to start by running a similar migration that will create a new <code>uuid</code> column. Then rename the old <code>id</code> column to <code>integer_id</code>, unset it as the primary key in favor of the new <code>uuid</code> column after renaming it to <code>id</code>.</p>
<figure><pre><code data-lang="elixir"><span>defmodule</span> <span>YourApp</span><span>.</span><span>Repo</span><span>.</span><span>Migrations</span><span>.</span><span>UsersPrimaryKey</span> <span>do</span>
  <span>use</span> <span>Ecto</span><span>.</span><span>Migration</span>

  <span>def</span> <span>up</span>
    <span>alter</span> <span>table</span><span>(</span><span>"</span><span>users"</span><span>)</span> <span>do</span>
      <span>add</span> <span>:uuid</span><span>,</span> <span>:uuid</span><span>,</span> <span>default:</span> <span>fragment</span><span>(</span><span>"</span><span>gen_random_uuid()"</span><span>),</span> <span>null:</span> <span>false</span>
    <span>end</span>

    <span>rename_column</span> <span>table</span><span>(</span><span>"</span><span>users"</span><span>),</span> <span>:id</span><span>,</span> <span>to:</span> <span>:integer_id</span>
    <span>rename_column</span> <span>table</span><span>(</span><span>"</span><span>users"</span><span>),</span> <span>:uuid</span><span>,</span> <span>to:</span> <span>:id</span>

    <span>execute</span> <span>"</span><span>ALTER TABLE users drop constraint users_pkey;"</span>
    <span>execute</span> <span>"</span><span>ALTER TABLE users ADD PRIMARY KEY (id);"</span>

    <span># Optionally you remove auto-incremented</span>
    <span># default value for integer_id column</span>
    <span>execute</span> <span>"</span><span>ALTER TABLE ONLY users ALTER COLUMN integer_id DROP DEFAULT;"</span>

    <span>alter</span> <span>table</span><span>(</span><span>"</span><span>users"</span><span>)</span> <span>do</span>
      <span>modify</span> <span>:integer_id</span><span>,</span> <span>:bigint</span><span>,</span> <span>null:</span> <span>true</span>
    <span>end</span>

    <span>execute</span> <span>"</span><span>DROP SEQUENCE IF EXISTS users_id_seq"</span>
  <span>end</span>

  <span>def</span> <span>down</span> <span>do</span>
    <span>raise</span> <span>Ecto</span><span>.</span><span>MigrationError</span><span>,</span> <span>"</span><span>Irreversible migration"</span>
  <span>end</span>
<span>end</span></code></pre></figure>
<p>I will not detail how to migrate associations because it will differ for every use case. You need to follow the similar steps of adding a new GUID type column and based on the value from the old integer foreign key, you must assign correct UUID keys.</p>
<h2 id="caveats-of-working-with-uuid">Caveats of working with UUID</h2>
<h3 id="binary-logs">Binary logs</h3>
<p>You only need the string format to construct the UUID queries. Unfortunately, currently, Ecto displays the binary format in the logs, so you’ll need to do the manual conversion to work with them. I’ve <a href="https://github.com/elixir-ecto/ecto_sql/pull/292" target="_blank" rel="noopener noreferrer">opened a PR</a> trying to improve it.</p>
<p><img alt="Binary UUID format displayed in Elixir Phoenix logs" title="Binary UUID format displayed in Elixir Phoenix logs" loading="lazy" src="https://pawelurbanek.com/assets/uuid-binary-logs-611dd7b6b8e97ef17a33c1f45402ff8aadb410e0a4bce533f717415717dceb94.png"></p>
<p>Binary UUID format displayed in Phoenix logs</p>
<h3 id="implicit-ordering-issue">Implicit ordering issue</h3>
<p><code>first</code> and <code>last</code> Query.API methods may seem broken when used with UUIDs. By default, they sort objects based on their primary key.</p>
<p>Integer primary keys are generated sequentially. We can assume that the most recently created object will have the highest ID value.</p>
<p>On the contrary, due to UUID’s totally random nature, it is generated in a non-sequential order. PostgreSQL can still sort them using the deterministic algorithm. It means that a single UUID from the table will always have a first place when sorting. Unfortunately, it has nothing to do with when it was generated compared to other UUID values from the same table.</p>
<p>It results in a seemingly buggy behavior of first and last methods. To remediate that, make sure to always explicitly pass the column name by which you want to sort your collection. In most cases, you’ll probably want to use <code>inserted_at</code> instead of <code>id</code>. One catch here is that the <code>inserted_at</code> column is not guaranteed to be unique. To avoid inconsistent results, always make sure to subsort your results by primary key:</p>
<figure><pre><code data-lang="elixir"><span># Without UUIDs</span>

<span>User</span> <span>|&gt;</span> <span>first</span> <span>|&gt;</span> <span>Repo</span><span>.</span><span>one</span>

<span># With UUIDs</span>

<span>User</span> <span>|&gt;</span> <span>first</span><span>([</span><span>:inserted_at</span><span>,</span> <span>:id</span><span>])</span> <span>|&gt;</span> <span>Repo</span><span>.</span><span>one</span></code></pre></figure>
<p>BTW you can check out my <a href="https://github.com/pawurb/ecto_extras" target="_blank" rel="noopener noreferrer">EctoExtras package</a>. It implements a set of simple helper functions that I find missing from the default Ecto implementation. With <code>EctoExtras</code>, the above example could look like that:</p>
<figure><pre><code data-lang="elixir"><span># Without UUIDs</span>

<span>Re…</span></code></pre></figure></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pawelurbanek.com/elixir-phoenix-uuid">https://pawelurbanek.com/elixir-phoenix-uuid</a></em></p>]]>
            </description>
            <link>https://pawelurbanek.com/elixir-phoenix-uuid</link>
            <guid isPermaLink="false">hacker-news-small-sites-25998969</guid>
            <pubDate>Tue, 02 Feb 2021 09:37:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Use Axios Interceptors]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25998870">thread link</a>) | @kgar
<br/>
February 2, 2021 | https://khaledgarbaya.net/articles/4-ways-to-use-axios-interceptors | <a href="https://web.archive.org/web/*/https://khaledgarbaya.net/articles/4-ways-to-use-axios-interceptors">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><p><img src="https://images.ctfassets.net/3bc97k4uk5q7/5nVOM5g4KVnas4Yu7u7EXn/df1acdbad3d40a417d8077bacf2adf12/g70a7545352e758468fe6b01ed47e86fa7c4496a46650169e660886d2d5b3fb492502eda7e5920ac6297b4c5458499a4f_1280.jpg?w=740" alt="rg45 wires - credit ElasticComputeFarm "></p>
<h2 id="what-is-axios"><a href="#what-is-axios" aria-label="what is axios permalink"></a>What is Axios?</h2>
<p>Axios is a promise-based HTTP client for the browser and node.js. It comes with many useful defaults like automatically detecting JSON responses and returning an object instead of plain text, throwing an error if the response status code is greater than 400.</p>
<h2 id="what-is-an-axios-interceptor"><a href="#what-is-an-axios-interceptor" aria-label="what is an axios interceptor permalink"></a>What is an axios interceptor?</h2>
<p>An Axios  <a href="https://github.com/axios/axios#interceptors">interceptor</a>  is a function that the library calls every time it sends or receives the request. You can intercept requests or responses before they are handled by “then” or “catch”.</p>
<p>Example:</p>
<div data-language="js"><pre><code>
axios<span>.</span>interceptors<span>.</span>request<span>.</span><span>use</span><span>(</span><span>function</span> <span>(</span><span>config</span><span>)</span> <span>{</span>
    
    <span>return</span> config<span>;</span>
  <span>}</span><span>,</span> <span>function</span> <span>(</span><span>error</span><span>)</span> <span>{</span>
    
    <span>return</span> Promise<span>.</span><span>reject</span><span>(</span>error<span>)</span><span>;</span>
  <span>}</span><span>)</span><span>;</span>


axios<span>.</span>interceptors<span>.</span>response<span>.</span><span>use</span><span>(</span><span>function</span> <span>(</span><span>response</span><span>)</span> <span>{</span>
    
    
    <span>return</span> response<span>;</span>
  <span>}</span><span>,</span> <span>function</span> <span>(</span><span>error</span><span>)</span> <span>{</span>
    
    
    <span>return</span> Promise<span>.</span><span>reject</span><span>(</span>error<span>)</span><span>;</span>
  <span>}</span><span>)</span><span>;</span></code></pre></div>
<p>You can also remove the interceptor from Axios.</p>
<div data-language="js"><pre><code><span>const</span> myInterceptor <span>=</span> axios<span>.</span>interceptors<span>.</span>request<span>.</span><span>use</span><span>(</span><span>function</span> <span>(</span><span>{</span><span>}</span><span>)</span><span>;</span>
axios<span>.</span>interceptors<span>.</span>request<span>.</span><span>eject</span><span>(</span>myInterceptor<span>)</span><span>;</span></code></pre></div>

<p>There is a big chance when building an app that you will use an API that requires some credentials like api_token or a user Auth token. Usually, you will have to append the required headers with every HTTP request you make. Using Axios interceptors, you can set this up once, and anywhere you call your Axios instance, you are sure that the token is there.</p>
<div data-language="js"><pre><code>axios<span>.</span>interceptors<span>.</span>request<span>.</span><span>use</span><span>(</span><span>req</span> <span>=&gt;</span> <span>{</span>
  
  
  req<span>.</span>headers<span>.</span>authorization <span>=</span> ‘Bearer mytoken’<span>;</span>
  <span>return</span> req<span>;</span>
<span>}</span><span>)</span><span>;</span>



<span>const</span> res <span>=</span> <span>await</span> axios<span>.</span><span>get</span><span>(</span>‘https<span>:</span><span>/</span><span>/</span>api<span>.</span>example<span>.</span>com’<span>)</span><span>;</span></code></pre></div>
<h2 id="log-every-request-and-response-using-interceptors"><a href="#log-every-request-and-response-using-interceptors" aria-label="log every request and response using interceptors permalink"></a>Log every request and response using interceptors.</h2>
<p>Logging requests can be beneficial, especially when you have a large app and you don’t know where all your requests are triggered. Using an Axios interceptor, you can log every request and response quickly.</p>
<div data-language="js"><pre><code><span>const</span> axios <span>=</span> <span>require</span><span>(</span>‘axios’<span>)</span><span>;</span>

axios<span>.</span>interceptors<span>.</span>request<span>.</span><span>use</span><span>(</span><span>req</span> <span>=&gt;</span> <span>{</span>
  console<span>.</span><span>log</span><span>(</span><span><span>`</span><span><span>${</span><span>JSON</span><span>.</span><span>stringify</span><span>(</span>req<span>,</span> <span>null</span><span>,</span> <span>2</span><span>)</span><span>}</span></span><span>`</span></span><span>)</span><span>;</span>
  
  <span>return</span> req<span>;</span>
<span>}</span><span>)</span><span>;</span>

axios<span>.</span>interceptors<span>.</span>response<span>.</span><span>use</span><span>(</span><span>res</span> <span>=&gt;</span> <span>{</span>
  console<span>.</span><span>log</span><span>(</span>res<span>.</span>data<span>.</span>json<span>)</span><span>;</span>
  
  <span>return</span> res<span>;</span>
<span>}</span><span>)</span><span>;</span>

<span>await</span> axios<span>.</span><span>post</span><span>(</span>‘https<span>:</span><span>/</span><span>/</span>example<span>.</span>com<span>/</span>‘<span>)</span><span>;</span></code></pre></div>
<h2 id="error-handling-using-axios-interceptors"><a href="#error-handling-using-axios-interceptors" aria-label="error handling using axios interceptors permalink"></a>Error handling using Axios interceptors</h2>
<p>You can use An Axios interceptor to capture all errors and enhance them before reaching your end user. If you use multiple APIs with different error object shapes, you can use an interceptor to transform them into a standard structure.</p>
<div data-language="js"><pre><code><span>const</span> axios <span>=</span> <span>require</span><span>(</span>‘axios’<span>)</span><span>;</span>
axios<span>.</span>interceptors<span>.</span>response<span>.</span><span>use</span><span>(</span>
  <span>res</span> <span>=&gt;</span> res<span>,</span>
  <span>err</span> <span>=&gt;</span> <span>{</span>
    <span>throw</span> <span>new</span> <span>Error</span><span>(</span>err<span>.</span>response<span>.</span>data<span>.</span>message<span>)</span><span>;</span>
  <span>}</span>
<span>)</span>
<span>const</span> err <span>=</span> <span>await</span> axios<span>.</span><span>get</span><span>(</span>‘http<span>:</span><span>/</span><span>/</span>example<span>.</span>com<span>/</span>notfound’<span>)</span><span>.</span>
  <span>catch</span><span>(</span><span>err</span> <span>=&gt;</span> err<span>)</span><span>;</span>

err<span>.</span>message<span>;</span></code></pre></div>
<h2 id="add-rate-limiting-to-requests-using-interceptors"><a href="#add-rate-limiting-to-requests-using-interceptors" aria-label="add rate limiting to requests using interceptors permalink"></a>Add rate limiting to requests using interceptors.</h2>
<p>Backend resources are limited and can cost a lot of money. As a client, you help reduce the load on your server by rate-limiting your HTTP calls.
Here’s how you can do it using an Axios interceptor.</p>
<div data-language="js"><pre><code><span>const</span> axios <span>=</span> <span>require</span><span>(</span>‘axios’<span>)</span><span>;</span>
<span>const</span> debounce <span>=</span> <span>require</span><span>(</span><span>'lodash.debounce'</span><span>)</span><span>;</span>
axios<span>.</span>interceptors<span>.</span>request<span>.</span><span>use</span><span>(</span>
  <span>res</span> <span>=&gt;</span> <span>{</span>
<span>return</span> <span>new</span> <span>Promise</span><span>(</span><span>(</span><span>resolve</span><span>)</span> <span>=&gt;</span> <span>{</span>

       <span>debounce</span><span>(</span>
          <span>(</span><span>)</span> <span>=&gt;</span> <span>resolve</span><span>(</span>config<span>)</span><span>,</span><span>2000</span><span>)</span><span>;</span>
       <span>}</span><span>)</span><span>;</span>
    <span>}</span><span>)</span><span>;</span>
  <span>}</span>
<span>)</span></code></pre></div></section></div></div>]]>
            </description>
            <link>https://khaledgarbaya.net/articles/4-ways-to-use-axios-interceptors</link>
            <guid isPermaLink="false">hacker-news-small-sites-25998870</guid>
            <pubDate>Tue, 02 Feb 2021 09:21:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Self Hosted VPN with WireGuard]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25998852">thread link</a>) | @modmodmod
<br/>
February 2, 2021 | https://cri.dev/posts/2021-02-01-5-dollar-easy-self-hosted-vpn-setup/ | <a href="https://web.archive.org/web/*/https://cri.dev/posts/2021-02-01-5-dollar-easy-self-hosted-vpn-setup/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
<p>This will take you less than 5 minutes to get a private VPN on your own Ubuntu server.</p>
<p>What you need to get started:</p>
<ul>
<li>a VPS (Ubuntu 20.04 LTS preferrably)</li>
<li>docker and docker-compose installed</li>
</ul>
<h2 id="setting-up-docker-compose"><a href="#setting-up-docker-compose">#</a> Setting up docker-compose</h2>
<p>On the VPS, I suggest to do the following:</p>
<p>Create a folder <code>wireguard/config</code> in your $HOME:</p>
<pre><code>mkdir -p wireguard/config
</code></pre>
<p>Inside the <code>wireguard</code> folder (next to the <code>config</code> folder), create the docker-compose file:</p>
<pre><code>vim docker-compose.yml
</code></pre>
<p>With the following contents:</p>
<pre><code>version: "2.1"
services:
  wireguard:
    image: linuxserver/wireguard
    container_name: wireguard
    cap_add:
      - NET_ADMIN
      - SYS_MODULE
    environment:
      - PUID=1000
      - PGID=1000
      - TZ=Europe/Rome
      - SERVERURL=YOUR_IP_OR_DNS_NAME_OF_YOUR_SERVER #optional
      - SERVERPORT=51820
      - PEERS=5
    volumes:
      - /home/YOUR_USERNAME/wireguard/config:/config
      - /lib/modules:/lib/modules
    ports:
      - 51820:51820/udp
    sysctls:
      - net.ipv4.conf.all.src_valid_mark=1
    restart: always
</code></pre>
<p>Simply change the <code>SERVERURL</code> variable, or delete that line if you want to use the server IP.</p>
<p>Additionally, change the location of your wireguard config path in the <code>volumes</code> section. (use <code>pwd</code> to get the current path you are in).</p>
<p><strong>For more info and environment variables, check out the official <a href="https://hub.docker.com/r/linuxserver/wireguard" target="_blank" rel="nofollow noopener external">linuxserver/wireguard doc</a>.</strong></p>
<p>I’ve used <code>restart: always</code> so that WireGuard comes up after a system restart.</p>
<p>Changed <code>PEERS</code> to 5, so that I have 5 configurations available for my devices.</p>
<h2 id="launching-the-container"><a href="#launching-the-container">#</a> Launching the container</h2>
<p>Start the container in the background with</p>
<pre><code>docker-compose up -d
</code></pre>
<p>This will create the needed configurations in the <code>wireguard/config</code> folder.</p>
<p>The structure of your <code>wireguard</code> folder looks something like this</p>
<pre><code>.
├── config
│&nbsp;&nbsp; ├── coredns
│&nbsp;&nbsp; │&nbsp;&nbsp; └── Corefile
│&nbsp;&nbsp; ├── peer1
│&nbsp;&nbsp; │&nbsp;&nbsp; ├── peer1.conf
│&nbsp;&nbsp; │&nbsp;&nbsp; ├── peer1.png
│&nbsp;&nbsp; │&nbsp;&nbsp; ├── privatekey-peer1
│&nbsp;&nbsp; │&nbsp;&nbsp; └── publickey-peer1
.............................
│&nbsp;&nbsp; ├── server
│&nbsp;&nbsp; │&nbsp;&nbsp; ├── privatekey-server
│&nbsp;&nbsp; │&nbsp;&nbsp; └── publickey-server
│&nbsp;&nbsp; ├── templates
│&nbsp;&nbsp; │&nbsp;&nbsp; ├── peer.conf
│&nbsp;&nbsp; │&nbsp;&nbsp; └── server.conf
│&nbsp;&nbsp; └── wg0.conf
└── docker-compose.yml
</code></pre>
<h2 id="firewall-configuration"><a href="#firewall-configuration">#</a> Firewall configuration</h2>
<p>If you’re using <code>ufw</code>, simply enable the port <code>51820</code> so that you can connect to your server from outside:</p>
<pre><code>ufw enable 51820
ufw reload
</code></pre>
<p>If you run <code>sudo ufw status</code> you should see:</p>
<pre><code>Status: active

To                         Action      From
--                         ---      ----
....................................................
51820                      ALLOW       Anywhere
51820 (v6)                 ALLOW       Anywhere (v6)
</code></pre>
<h2 id="connecting-devices"><a href="#connecting-devices">#</a> Connecting devices</h2>
<p>Now you can <code>cat</code> or <code>scp</code> the configurations individually to your devices.</p>
<p>The configurations are located in the <code>config/peerX</code> folder, where <code>X</code> represents the peer number.</p>
<p>E.g. I could <code>cat/scp</code> the configuration in <code>wireguard/config/peer1/peer1.conf</code> and put it in <code>/etc/wireguard/wg0.conf</code> on my host machine.</p>
<p>View the configuration for peer 1 on your server with</p>
<pre><code>cat /home/YOUR_USERNAME/wireguard/config/peer1/peer1.conf
</code></pre>
<p>and place it in <code>/etc/wireguard/wg0.conf</code> on your host machine.</p>
<p>If you want to use <code>scp</code>, you could run the following on your local machine:</p>
<pre><code>scp <a href="https://cri.dev/cdn-cgi/l/email-protection" data-cfemail="257076607765766077736077">[email&nbsp;protected]</a>:/home/YOUR_USERNAME/wireguard/config/peer1/peer1.conf /etc/wireguard/wg0.conf
</code></pre>
<p>To connect to your newly created WireGuard VPN from one of your devices, you’ll need to install <code>wireguard-tools</code>.</p>
<p>E.g. <code>apt install wireguard-tools</code> , <code>pacman -S wireguad-tools</code> based on your distro</p>
<p><a href="https://www.wireguard.com/install/" target="_blank" rel="nofollow noopener external">Here you can find a more detailed explanation</a></p>
<p>Now you can simply run <strong><code>wg-quick up wg0</code></strong> and you’re connected to your VPN.</p>
<p>Test it out by running <code>curl ipinfo.io</code> and inspect the output.</p>
<h2 id="connecting-mobile-device-with-qr-code"><a href="#connecting-mobile-device-with-qr-code">#</a> Connecting mobile device with QR code</h2>
<p>On your mobile device, install the WireGuard client.</p>
<p>Then add a new WireGuard tunnel by creating a new configuration scanning a QR code.</p>
<p>On your VPS run the following to output a QR code on the terminal that you can scan on your mobile device:</p>
<pre><code>docker exec -it wireguard app/show-peer 1
</code></pre>
<h2 id="inspecting-connections"><a href="#inspecting-connections">#</a> Inspecting connections</h2>
<p>If you want to understand who is connected and which profiles are in use, simply run the following on your VPS:</p>
<pre><code>docker exec -it wireguard wg
</code></pre>
<p>This will give you more information about your connections with the following output:</p>
<pre><code>interface: wg0
  public key: (redacted)
  private key: (hidden)
  listening port: 51820

peer: (redacted)
  endpoint: (redacted):51820
  allowed ips: (redacted)/32
  latest handshake: 27 seconds ago
  transfer: 5.04 MiB received, 172.64 MiB sent

...

peer: (redacted)
  allowed ips: (redacted)/32
</code></pre>
<h2 id="conclusion"><a href="#conclusion">#</a> Conclusion</h2>
<p>This was most definitely the easiest way I found to connect computers and mobile devices to your own WireGuard VPN.</p>
<p>Let me know if you had troubles setting it up yourself!</p>
</div></div>]]>
            </description>
            <link>https://cri.dev/posts/2021-02-01-5-dollar-easy-self-hosted-vpn-setup/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25998852</guid>
            <pubDate>Tue, 02 Feb 2021 09:18:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Visualisation of Co-Occurring Types with Rust]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25998835">thread link</a>) | @batterylow
<br/>
February 2, 2021 | https://shahinrostami.com/posts/programming/rust-notebooks/visualisation-of-co-occurring-types/ | <a href="https://web.archive.org/web/*/https://shahinrostami.com/posts/programming/rust-notebooks/visualisation-of-co-occurring-types/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<pre>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]</pre>
</div></div>]]>
            </description>
            <link>https://shahinrostami.com/posts/programming/rust-notebooks/visualisation-of-co-occurring-types/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25998835</guid>
            <pubDate>Tue, 02 Feb 2021 09:15:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Unofficial DynASM Documentation]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25998833">thread link</a>) | @lelf
<br/>
February 2, 2021 | https://corsix.github.io/dynasm-doc/index.html | <a href="https://web.archive.org/web/*/https://corsix.github.io/dynasm-doc/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              <p>DynASM is a preprocessor and tiny runtime library for creating assemblers and JIT compilers in C or C++.</p>
        <p>DynASM was written for, and is maintained as part of, <a href="http://luajit.org/">LuaJIT</a>. LuaJIT 1 used
           DynASM in a JIT role. LuaJIT 2 doesn't use DymASM in a JIT role, but LuaJIT 2's interpreter is hand-written in assembly,
           and it uses DynASM as a powerful cross-platform assembler.</p>
        <p>To get the latest copy of DymASM, run the following:</p>
        <pre><span>git clone http://luajit.org/git/luajit-2.0.git</span>
<span>cd luajit-2.0/dynasm</span></pre>
        <p>The <a href="http://luajit.org/dynasm.html">official documentation</a> for DynASM is extremely spartan, which can
           make it difficult to get started with DynASM. For using DynASM in a JIT role, this unofficial documentation's
           <strong><a href="https://corsix.github.io/dynasm-doc/tutorial.html">tutorial</a></strong> is recommended as a starting point. Once you're more familiar with DynASM,
           the <strong><a href="https://corsix.github.io/dynasm-doc/reference.html">reference</a></strong> and <strong><a href="https://corsix.github.io/dynasm-doc/instructions.html">instruction listing</a></strong>
           pages are recommended reading for fleshing out your DynASM knowledge.</p>
        <p>Note that DynASM supports the x86, x64, ARM, PowerPC, and MIPS instruction sets, but this unofficial documentation
           only covers x86 and x64.</p>
      </div></div>]]>
            </description>
            <link>https://corsix.github.io/dynasm-doc/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25998833</guid>
            <pubDate>Tue, 02 Feb 2021 09:14:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elektra 0.9.4 Release]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25998799">thread link</a>) | @mpranj
<br/>
February 2, 2021 | https://www.libelektra.org/news/0.9.4-release | <a href="https://web.archive.org/web/*/https://www.libelektra.org/news/0.9.4-release">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.libelektra.org/news/0.9.4-release</link>
            <guid isPermaLink="false">hacker-news-small-sites-25998799</guid>
            <pubDate>Tue, 02 Feb 2021 09:10:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Plausible Analytics in Your Next.js App]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25998700">thread link</a>) | @jopesch
<br/>
February 2, 2021 | https://johnschmidt.de/blog/using-plausible-analytics-in-your-next-js-app | <a href="https://web.archive.org/web/*/https://johnschmidt.de/blog/using-plausible-analytics-in-your-next-js-app">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span>John Schmidt</span></p><p><span>1<!-- --> min read</span><span>–</span><time datetime="2021-01-03">January 3rd, 2021</time></p></div></div><div><p>I was looking for a pure, lightweight and privacy-friendly way to get simple stats about my personal homepage. I ruled out Google Analytics as they sustain little issues with privacy, and it does not fit into the mentioned attributes. So, what's out there in the market? Until this point, I've come across the following:</p><ul><li>umami (self-hosted, open source),</li><li>Simple Analytics (paid),</li><li>Fathom Analytics (paid),</li><li>Splitbee (paid),</li><li>and Plausible (paid or self-hosted, open source)</li></ul><p>If possible, I'd rather avoid a paid service (at least for now). Having used umami for a client project recently being quite fond of it, I've moved to <a href="https://plausible.io/" target="_blank" rel="noopener noreferrer">Plausible</a>, an open-source project based in the European Union, for this project. Plausible offers a pretty clean <a href="https://github.com/plausible/hosting" target="_blank" rel="noopener noreferrer">self-hosting setup via Docker</a>. Alternatively, they offer a paid managed service on their platform for those who prefer.</p><p>Either via plausible.io or self-hosted - after creating your site in the Plausible dashboard you're provided with a simple <code>&lt;script&gt;</code> tag looking somewhat like this:</p><pre><p><span>&lt;</span><span>script</span><span></span></p><p><span>  </span><span>async</span><span></span></p><p><span>  </span><span>defer</span><span></span></p><p><span>  </span><span>data-domain</span><span>=</span><span>"</span><span>johnschmidt.de</span><span>"</span><span></span></p><p><span>  </span><span>src</span><span>=</span><span>"</span><span>https://stats.johnschmidt.cloud/js/plausible.js</span><span>"</span><span></span></p><p><span></span><span>/&gt;</span></p></pre><p>Of course the <code>src</code> and <code>data-domain</code> attributes might differ depending on your setup. That's all you need from Plausible itself.</p><h2 id="setting-up-your-application">Setting up Your Application<a href="#setting-up-your-application"><span>Anchor link for: <!-- -->Setting up Your Application</span><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 256 256"><rect width="256" height="256" fill="none"></rect><line x1="43.63636" y1="96" x2="224" y2="96" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="24"></line><line x1="176" y1="40" x2="144" y2="216" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="24"></line><line x1="112" y1="40" x2="80" y2="216" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="24"></line><line x1="32" y1="160" x2="212.36376" y2="160" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="24"></line></svg></a></h2><p>In your Next.js project we need to modify the <a href="https://nextjs.org/docs/advanced-features/custom-document" target="_blank" rel="noopener noreferrer">custom document</a> <code>/pages/_document.js</code> file. There's a few possible approaches to implement the tracker. In this case, I implemented it manually. However, there is a <a href="https://github.com/4lejandrito/next-plausible" target="_blank" rel="noopener noreferrer">small package</a> providing you with a <code>&lt;PlausibleProvider&gt;</code> wrapper. The simplest approach is by adding the <code>&lt;script&gt;</code> tag in the <code>&lt;Head&gt;</code> component.</p><pre><p><span>import</span><span> Document</span><span>,</span><span> </span><span>{</span><span> Html</span><span>,</span><span> Head</span><span>,</span><span> Main</span><span>,</span><span> NextScript </span><span>}</span><span> </span><span>from</span><span> </span><span>'next/document'</span><span></span></p><p><span></span><span>class</span><span> </span><span>HomepageDocument</span><span> </span><span>extends</span><span> </span><span>Document</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>static</span><span> </span><span>async</span><span> </span><span>getInitialProps</span><span>(</span><span>ctx</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>    </span><span>const</span><span> initialProps </span><span>=</span><span> </span><span>await</span><span> Document</span><span>.</span><span>getInitialProps</span><span>(</span><span>ctx</span><span>)</span><span></span></p><p><span>    </span><span>return</span><span> </span><span>{</span><span> </span><span>...</span><span>initialProps </span><span>}</span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span>  </span><span>render</span><span>(</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>    </span><span>return</span><span> </span><span>(</span><span></span></p><p><span>      </span><span>&lt;</span><span>Html</span><span> </span><span>lang</span><span>=</span><span>'</span><span>en</span><span>'</span><span>&gt;</span><span></span></p><p><span>        </span><span>&lt;</span><span>Head</span><span>&gt;</span><span></span></p><p><span>          </span><span>&lt;</span><span>script</span><span></span></p><p><span>            </span><span>async</span><span></span></p><p><span>            </span><span>defer</span><span></span></p><p><span>            </span><span>data-domain</span><span>=</span><span>'</span><span>johnschmidt.de</span><span>'</span><span></span></p><p><span>            </span><span>src</span><span>=</span><span>'</span><span>https://stats.johnschmidt.cloud/js/plausible.js</span><span>'</span><span></span></p><p><span>          </span><span>/&gt;</span><span></span></p><p><span>        </span><span>&lt;/</span><span>Head</span><span>&gt;</span><span></span></p><p><span>        </span><span>&lt;</span><span>body</span><span> </span><span>className</span><span>=</span><span>'</span><span>antialiased dark:bg-black dark:text-white</span><span>'</span><span>&gt;</span><span></span></p><p><span>          </span><span>&lt;</span><span>Main</span><span> </span><span>/&gt;</span><span></span></p><p><span>          </span><span>&lt;</span><span>NextScript</span><span> </span><span>/&gt;</span><span></span></p><p><span>        </span><span>&lt;/</span><span>body</span><span>&gt;</span><span></span></p><p><span>      </span><span>&lt;/</span><span>Html</span><span>&gt;</span><span></span></p><p><span>    </span><span>)</span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span></span><span>}</span><span></span></p><p><span></span><span>export</span><span> </span><span>default</span><span> HomepageDocument</span></p></pre><p>In the easiest scenario this would be it - you're good to go. The script will be included into the app bundle on every page. Once deployed, the script will automatically run the tracker function and count visitors and page views. The results will be displayed in the Plausible dashboard almost instantly.</p><h2 id="avoiding-counts-in-preview-deployments">Avoiding Counts in Preview Deployments<a href="#avoiding-counts-in-preview-deployments"><span>Anchor link for: <!-- -->Avoiding Counts in Preview Deployments</span><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 256 256"><rect width="256" height="256" fill="none"></rect><line x1="43.63636" y1="96" x2="224" y2="96" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="24"></line><line x1="176" y1="40" x2="144" y2="216" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="24"></line><line x1="112" y1="40" x2="80" y2="216" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="24"></line><line x1="32" y1="160" x2="212.36376" y2="160" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="24"></line></svg></a></h2><p><em>There's just this one little caveat: </em>Plausible does not differ between the domain or referring URL (yet) you call the script from. Using Vercel or Netlify for your deployments, you might use preview URLs quite frequently. A visit to one of these would trigger an event like in the production environment. As far as I could evaluate, there's essentially two options to avoid:</p><ol><li>exclude yourself from tracking on the client-side or</li><li>include the script only on the desired production URL (e.g. johnschmidt.de)</li></ol><p>The First option could be achieved with a custom rule in a script-blocking extension of sorts (e.g. uBlock, Adblock Plus).  The second approach is a bit trickier at the moment. To avoid the <code>&lt;script&gt;</code> to render in the preview URLs we need to include the snippet conditionally, based on the current hostname. The <code>Window</code> object can provide this information quite simply in <code>window.location.hostname</code>. It'll be offered as a string. This moves the code from <code>/pages/_document.js</code> to <code>/pages/_app.js</code> since we need to check our conditions on the client-side.</p><pre><p><span>import</span><span> Head </span><span>from</span><span> </span><span>'next/head'</span><span></span></p><p><span></span><span>function</span><span> </span><span>HomepageApp</span><span>(</span><span>{</span><span> Component</span><span>,</span><span> pageProps </span><span>}</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>return</span><span> </span><span>(</span><span></span></p><p><span>    </span><span>&lt;</span><span>&gt;</span><span></span></p><p><span>      </span><span>&lt;</span><span>Head</span><span>&gt;</span><span></span></p><p><span>        </span><span>{</span><span>typeof</span><span> window </span><span>!==</span><span> </span><span>'undefined'</span><span> </span><span>&amp;&amp;</span><span></span></p><p><span>          window</span><span>.</span><span>location</span><span>.</span><span>hostname </span><span>===</span><span> </span><span>'johnschmidt.de'</span><span> </span><span>&amp;&amp;</span><span> </span><span>(</span><span></span></p><p><span>            </span><span>&lt;</span><span>script</span><span></span></p><p><span>              </span><span>async</span><span></span></p><p><span>              </span><span>defer</span><span></span></p><p><span>              </span><span>data-domain</span><span>=</span><span>'</span><span>johnschmidt.de</span><span>'</span><span></span></p><p><span>              </span><span>src</span><span>=</span><span>'</span><span>https://stats.johnschmidt.cloud/js/plausible.js</span><span>'</span><span></span></p><p><span>            </span><span>/&gt;</span><span></span></p><p><span>          </span><span>)</span><span>}</span><span></span></p><p><span>      </span><span>&lt;/</span><span>Head</span><span>&gt;</span><span></span></p><p><span>      </span><span>&lt;</span><span>Component</span><span> </span><span>{</span><span>...</span><span>pageProps</span><span>}</span><span> </span><span>/&gt;</span><span></span></p><p><span>    </span><span>&lt;/</span><span>&gt;</span><span></span></p><p><span>  </span><span>)</span><span></span></p><p><span></span><span>}</span><span></span></p><p><span></span><span>export</span><span> </span><span>default</span><span> HomepageApp</span></p></pre><p>Before reading the <code>window.location.hostname</code> parameter we need to make sure that it is only called in a client-side setting. We can check if the <code>Window</code> object is defined and render the script tag conditionally. Since Next.js statically generates our page on the server-side, it would try to call the <code>Window</code> object in a Node.js environment - albeit <code>Window</code> does not exist there. Once a visitor opens our app on the production URL, the script should be rendered on hydration and Plausible can start collecting your events as usual.</p><h2 id="wrapping-up">Wrapping up<a href="#wrapping-up"><span>Anchor link for: <!-- -->Wrapping up</span><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 256 256"><rect width="256" height="256" fill="none"></rect><line x1="43.63636" y1="96" x2="224" y2="96" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="24"></line><line x1="176" y1="40" x2="144" y2="216" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="24"></line><line x1="112" y1="40" x2="80" y2="216" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="24"></line><line x1="32" y1="160" x2="212.36376" y2="160" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="24"></line></svg></a></h2><p>Plausible provides a good alternative to Google Analytics, especially on the privacy side of things. The only downside is the fairly narrow adjustability within a continuous deployment environment like Vercel or Netlify. With a little tweak, however, it can work like a charm. For a small project like this homepage, it seemed like one of the best solutions to get lightweight stats and baseline analytics.</p><p>Since this is my first post of this kind, let me know if this post was helpful to you and reach out <a href="https://twitter.com/jope_sh" target="_blank" rel="noopener noreferrer">to me on Twitter</a> (@jope_sh) with feedback and ideas!</p></div></div>]]>
            </description>
            <link>https://johnschmidt.de/blog/using-plausible-analytics-in-your-next-js-app</link>
            <guid isPermaLink="false">hacker-news-small-sites-25998700</guid>
            <pubDate>Tue, 02 Feb 2021 08:54:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Demystifying useEffect's clean-up function]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25998648">thread link</a>) | @rozenmd
<br/>
February 2, 2021 | https://maxrozen.com/demystifying-useeffect-cleanup-function | <a href="https://web.archive.org/web/*/https://maxrozen.com/demystifying-useeffect-cleanup-function">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>When you're starting to write React hooks, it can be hard to understand what's going on with useEffect, particularly if you're trying to translate Hooks to lifecycle methods in class components.</p><p>You read everywhere that you <em>shouldn't</em> compare useEffect to lifecycle methods, but then where do you start?</p><p>Thankfully, not knowing how useEffect's clean-up function works isn't as bad as getting the <a href="https://maxrozen.com/learn-useeffect-dependency-array-react-hooks">dependency array wrong</a>, or passing <a href="https://maxrozen.com/stop-useeffect-running-every-render-with-usecallback">constantly redeclared functions into useEffect</a>.</p><p>That being said though, there are some nifty uses of the clean-up function that you should know about.</p><h2 id="useeffects-clean-up-function-doesnt-just-run-once"><a href="#useeffects-clean-up-function-doesnt-just-run-once" aria-label="demystifying useeffect cleanup function permalink"></a>useEffect's clean-up function doesn't just run once</h2><p>If you take nothing else away from this article, remember this: useEffect's clean-up function doesn't <em>just</em> run on unmount (assuming your dependency array isn't empty).</p><p>See this often overlooked sentence in the <a href="https://reactjs.org/docs/hooks-reference.html#cleaning-up-an-effect">React Hooks API reference</a>:</p><blockquote><p>Additionally, if a component renders multiple times (as they typically do), the previous effect is cleaned up before executing the next effect</p></blockquote><h2 id="so-when-does-clean-up-run"><a href="#so-when-does-clean-up-run" aria-label="demystifying useeffect cleanup function permalink"></a>So when does clean-up run?</h2><p>useEffect's clean-up runs after the next render, before the next useEffect.</p><p>This might mess with your brain a little bit, but check out this example:</p><div><pre data-language="jsx"><p><span>import</span><span> React</span><span>,</span><span> </span><span>{</span><span> useEffect</span><span>,</span><span> useState </span><span>}</span><span> </span><span>from</span><span> </span><span>'react'</span><span>;</span><span></span></p><p><span></span><span>export</span><span> </span><span>default</span><span> </span><span>function</span><span> </span><span>App</span><span>(</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>const</span><span> </span><span>[</span><span>state</span><span>,</span><span> setState</span><span>]</span><span> </span><span>=</span><span> </span><span>useState</span><span>(</span><span>null</span><span>)</span><span>;</span><span></span></p><p><span>  </span><span>useEffect</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>    console</span><span>.</span><span>log</span><span>(</span><span>'I am the effect'</span><span>)</span><span>;</span><span></span></p><p><span>    </span><span>return</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>      console</span><span>.</span><span>log</span><span>(</span><span>'I run after re-render, but before the next useEffect'</span><span>)</span><span>;</span><span></span></p><p><span>    </span><span>}</span><span>;</span><span></span></p><p><span>  </span><span>}</span><span>)</span><span>;</span><span></span></p><p><span>  console</span><span>.</span><span>log</span><span>(</span><span>'I am just part of render'</span><span>)</span><span>;</span><span></span></p><p><span>  </span><span>return</span><span> </span><span>(</span><span></span></p><p><span>    </span><span>&lt;</span><span>&gt;</span><span></span></p><p><span>      </span><span>&lt;</span><span>button</span><span></span></p><p><span>        </span><span>onClick</span><span>=</span><span>{</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>          </span><span>setState</span><span>(</span><span>'Some v. important state.'</span><span>)</span><span>;</span><span></span></p><p><span>        </span><span>}</span><span>}</span><span></span></p><p><span>      </span><span>&gt;</span><span></span></p><p><span>        Click me</span></p><p><span>      </span><span>&lt;/</span><span>button</span><span>&gt;</span><span></span></p><p><span>      </span><span>&lt;</span><span>p</span><span>&gt;</span><span>state</span><span>:</span><span> </span><span>{</span><span>state</span><span>}</span><span>&lt;/</span><span>p</span><span>&gt;</span><span></span></p><p><span>    </span><span>&lt;/</span><span>&gt;</span><span></span></p><p><span>  </span><span>)</span><span>;</span><span></span></p><p><span></span><span>}</span><span></span></p></pre></div><table><thead><tr><th></th></tr></thead><tbody><tr><td><em>This example is also available as a <a href="https://codesandbox.io/s/useeffect-cleanup-example-1qgw2?file=/src/App.js">CodeSandbox</a>.</em></td></tr></tbody></table><p>When the above component first renders, in the console you see:</p><div><pre><p><span>&gt; I am just part of render</span></p><p><span>&gt; I am the effect</span></p></pre></div><p>If you then click the button (triggering a re-render), the following lines are printed underneath:</p><div><pre><p><span>&gt; I am just part of render</span></p><p><span>&gt; I run after re-render, but before the next useEffect</span></p><p><span>&gt; I am the effect</span></p></pre></div><p>Even though the clean-up function is <em>running</em> in the new render, it still has the old prop values since it was <em>declared</em> in the previous render.</p><p>More concretely:</p><div><pre data-language="jsx"><p><span>useEffect</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>  console</span><span>.</span><span>log</span><span>(</span><span>'id: '</span><span>,</span><span> id</span><span>)</span><span>;</span><span></span></p><p><span>  </span><span>return</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>    console</span><span>.</span><span>log</span><span>(</span><span>'id: '</span><span>,</span><span> id</span><span>)</span><span>;</span><span></span></p><p><span>  </span><span>}</span><span>;</span><span></span></p><p><span></span><span>}</span><span>,</span><span> </span><span>[</span><span>props</span><span>.</span><span>id</span><span>]</span><span>)</span><span>;</span><span></span></p></pre></div><ul><li><code>id</code> starts as <code>1</code>.</li><li>Component renders, displaying <code>id</code> as <code>1</code> in the UI</li><li>useEffect runs, calling <code>console.log</code> and prints <code>id: 1</code></li><li>Props change, setting <code>id</code> to <code>2</code></li><li>Component re-renders, displaying <code>id</code> as <code>2</code> in the UI</li><li>useEffect clean-up function fires, calling <code>console.log</code> and prints <code>id: 1</code></li><li>useEffect runs, calling <code>console.log</code> and prints <code>id: 2</code></li></ul><h2 id="what-to-actually-use-useeffects-clean-up-functions-for"><a href="#what-to-actually-use-useeffects-clean-up-functions-for" aria-label="demystifying useeffect cleanup function permalink"></a>What to actually use useEffect's clean-up functions for</h2><p>Honestly, it's pretty rare that I find a use for useEffect's clean-up function in my day-to-day work as I don't use subscriptions at work (so I never need to unsubscribe from connections in the clean-up function).</p><p>You <em>can</em> use it to avoid race conditions in async requests, which is pretty nifty.</p><p>From <a href="https://maxrozen.com/race-conditions-fetching-data-react-with-useeffect">Fixing Race Conditions in React with useEffect</a>:</p><div><pre data-language="jsx"><p><span>useEffect</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>let</span><span> active </span><span>=</span><span> </span><span>true</span><span>;</span><span></span></p><p><span>  </span><span>const</span><span> </span><span>fetchData</span><span> </span><span>=</span><span> </span><span>async</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>    </span><span>const</span><span> response </span><span>=</span><span> </span><span>await</span><span> </span><span>fetch</span><span>(</span><span>`</span><span>https://swapi.dev/api/people/</span><span>${</span><span>props</span><span>.</span><span>id</span><span>}</span><span>/</span><span>`</span><span>)</span><span>;</span><span></span></p><p><span>    </span><span>const</span><span> newData </span><span>=</span><span> </span><span>await</span><span> response</span><span>.</span><span>json</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span>    </span><span>if</span><span> </span><span>(</span><span>active</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>      </span><span>setFetchedId</span><span>(</span><span>props</span><span>.</span><span>id</span><span>)</span><span>;</span><span></span></p><p><span>      </span><span>setData</span><span>(</span><span>newData</span><span>)</span><span>;</span><span></span></p><p><span>    </span><span>}</span><span></span></p><p><span>  </span><span>}</span><span>;</span><span></span></p><p><span>  </span><span>fetchData</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span>  </span><span>return</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>    active </span><span>=</span><span> </span><span>false</span><span>;</span><span></span></p><p><span>  </span><span>}</span><span>;</span><span></span></p><p><span></span><span>}</span><span>,</span><span> </span><span>[</span><span>props</span><span>.</span><span>id</span><span>]</span><span>)</span><span>;</span><span></span></p></pre></div><p>You can also use an AbortController to cancel your requests instead of a boolean flag, see <a href="https://maxrozen.com/race-conditions-fetching-data-react-with-useeffect#useeffect-clean-up-function-with-abortcontroller">the example here</a>.</p><h2 id="dedicated-unmount-hook"><a href="#dedicated-unmount-hook" aria-label="demystifying useeffect cleanup function permalink"></a>Dedicated unmount hook</h2><p>While React doesn't have a dedicated unmount hook, you can always use useEffect's clean-up function with an empty dependency array:</p><div><pre data-language="jsx"><p><span>import</span><span> React</span><span>,</span><span> </span><span>{</span><span> useEffect </span><span>}</span><span> </span><span>from</span><span> </span><span>'react'</span><span>;</span><span></span></p><p><span></span><span>const</span><span> </span><span>SomeComponent</span><span> </span><span>=&gt;</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>     </span><span>useEffect</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>        </span><span>return</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>         </span><span>}</span><span></span></p><p><span>     </span><span>}</span><span>,</span><span> </span><span>[</span><span>]</span><span>)</span><span></span></p><p><span> </span><span>}</span><span></span></p></pre></div><p>I'm not sure why you'd want this (nor have I needed this), but it's worth knowing that it's possible.</p></div></div></div>]]>
            </description>
            <link>https://maxrozen.com/demystifying-useeffect-cleanup-function</link>
            <guid isPermaLink="false">hacker-news-small-sites-25998648</guid>
            <pubDate>Tue, 02 Feb 2021 08:47:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Space temple for peace of universe including earth and human safety in space]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25998604">thread link</a>) | @rguiscard
<br/>
February 2, 2021 | https://www.terraspace.jp/press-release/20210201 | <a href="https://web.archive.org/web/*/https://www.terraspace.jp/press-release/20210201">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main" dir="ltr"><section id="h.e34255cb8b2199c_36"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.e34255cb8b2199c_39"><div><p><h3 id="h.1e59uzt3hiki" dir="ltr">2021/2/1</h3><h3 id="h.gy12guze6umz" dir="ltr"><span>人工衛星開発のテラスペース、人工衛星による宇宙寺院の開発と打ち上げに向け業務技術提携を実施</span></h3></p></div></div></div></div></div></div></div></div></section><section id="h.e34255cb8b2199c_40"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.e34255cb8b2199c_43"><div><div><p dir="ltr"><span>テラスペース株式会社(本社:京都市左京区、代表取締役:北川貞大、以下、テラスペース)は、世界遺産 京都 醍醐寺 (総本山:京都市伏見区、座主:仲田順和、以下、醍醐寺)と人工衛星による宇宙寺院の開発と打ち上げに向け業務技術 提携を行いました。</span></p><p dir="ltr"><span>テラスペースは、2023年度打ち上げ予定のIoT衛星内の区画を活用し、人工衛星に宇宙寺院の役割も持たせます。今回の 業務技術提携に伴い、人工衛星の開発に加え、醍醐寺と一緒に劫蘊寺実行委員会を発足させ、宇宙寺院の運用と事務局の 業務を行います。</span></p><p dir="ltr"><span>また、醍醐寺などと協力し、携帯電波の届かない山間部の文化財保護にIoT衛星を役立てます。</span></p><p dir="ltr"><span>宇宙寺院は「浄天院劫蘊寺(じょうてんいんごううんじ)」(以下 劫蘊寺)と命名されました。劫蘊寺は、鎮護宇宙を 趣旨とする醍醐寺の法流を汲む寺院になります。地球を含む宇宙全体の平和と、人類の宇宙での活動の安全のための、宇 宙法要が、醍醐寺などで定期的に開催されます。宇宙寺院というのは、文字の通り、宇宙に浮かぶお寺のことで、高度4 00km〜500kmの地球低軌道で運用を行い、約1時間半かけて地球を一周します。宇宙寺院の現在地情報などはスマホア プリで確認できるようになる予定です。</span></p><p dir="ltr"><span>【劫蘊寺公式H P】</span><span><a href="https://www.google.com/url?q=https%3A%2F%2Fwww.gounji.space%2F&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNGILtSJIOi8Urzit6yGt0xbD46aiw" target="_blank">https://www.gounji.space/</a></span><span> </span></p><p dir="ltr"><span>【醍醐寺公式H P】</span><span><a href="https://www.google.com/url?q=https%3A%2F%2Fwww.daigoji.or.jp%2F&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNH4l02j46FSCbTWVrKRySIocBsJhw" target="_blank">https://www.daigoji.or.jp/</a></span></p></div></div></div></div></div></div></div></div></div></section><section id="h.19cb177f5fb6139f_3"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.19cb177f5fb6139f_0"><div><div><p><img src="https://lh4.googleusercontent.com/wtSbdJ2dj1okMcPCtFxeTNpf4FFUJR5V0hlpVqKjWV2cJzDyOA6XAHPpxaC0IskV9eK5lMavafaajXFtIhRkTTfxmIz4pPr7epyGNyG4IkXadRT1Wqg=w1280" role="img"></p></div></div></div></div><div><div id="h.19cb177f5fb6139f_8"><div><p dir="ltr"><span>左:テラスペース代表 北川貞大  右:総本山醍醐寺座主 仲田順和猊下</span></p></div></div></div></div></div></div></div></div></section><section id="h.597c5cd814811569_7"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.597c5cd814811569_4"><div><div><p><img src="https://lh4.googleusercontent.com/R_s8Xv2Jp_z1BOkmsaYl-7QCWiZH4ej7Aa-takXjj80KD9C6DpzkW1JyC-YaLwedJkW5gVenFDr6xGjjzrsjgdZAVZPnmMRcbqBR9sCLkNN4FGiEdQ=w1280" role="img"></p></div></div></div></div></div></div></div></div></div></section><section id="h.19cb177f5fb6139f_13"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.19cb177f5fb6139f_10"><div><div><p dir="ltr"><span>広報担当:今村誠子</span></p><p dir="ltr"><span>TEL: 0774-74-8202</span></p><p dir="ltr"><span>Email: info@terraspace.jp</span></p></div></div></div></div></div></div></div></div></div></section></div></div>]]>
            </description>
            <link>https://www.terraspace.jp/press-release/20210201</link>
            <guid isPermaLink="false">hacker-news-small-sites-25998604</guid>
            <pubDate>Tue, 02 Feb 2021 08:40:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[“Reasoning about code” is a scam]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25998554">thread link</a>) | @BerislavLopac
<br/>
February 2, 2021 | https://www.sicpers.info/2021/01/reasoning-about-code-is-a-scam/ | <a href="https://web.archive.org/web/*/https://www.sicpers.info/2021/01/reasoning-about-code-is-a-scam/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>Another day, another post telling me to do something, or not do something, or adopt some technology, or not adopt some technology, or whatever it is that they want me to do, because it makes it easier to “reason about the code”.</p>
<p>It’s a scam.</p>
<p>More precisely, it’s a thought-terminating cliche. Ironic, as the phrase “reason about” is used as a highfalutin synonym for “think about”. The idea is that there’s nowhere to go from here. I want to do things one way, some random on medium dot com wants me to do things another way, their way makes it easier to reason about the code, therefore that’s the better approach.</p>
<p>It’s a scam.</p>
<p>Let’s start with the fact that people don’t think—sorry, reason—about things the same way. If we did, then there’d be little point to things like film review sites, code style guides, or democracy. We don’t know precisely <em>what</em> influences different people to think in different ways about different things, but we have some ideas. Some of the ideas just raise other questions: like if you say “it’s a cultural difference” then we have to ask “well, why is it normal for all of the people in that culture to think this way, and all of the people in this culture to think that way?”</p>
<p>This difference between modes of thought arises in computing. We know, for example, that you can basically use any programming language for basically any purpose, because back in the days when there were intellectual giants in computering they demonstrated that all of these languages are interchangeable. They did so before we’d designed the languages. So choice of programming language is arbitrary, unless motivated by external circumstances like which vendor your CTO plays squash with or whether you are by nature populist or contrarian.</p>
<p>Such differences arise elsewhere than in choice of language. Comprehension of paradigms, for example: the Smalltalk folks noticed it was easier to teach object-oriented programming to children than to professional programmers, because the professional programmers already had mental toolkits for comprehending programming that didn’t integrate with the object model. It’s easier for them to “reason about” imperative code than objects.</p>
<p>OK, so when someone says that something makes it easier to “reason about” the code, what they mean is that <em>that person</em> find it easier to think about code in the presence of this property. I mean, assuming they <em>do</em>, and are not disingenuously proposing a suggestion that you do something when they’ve run out of reasons you should do it but still think it’d be a good idea.  But wait.</p>
<p>It’s a scam.</p>
<p>Code is a particular representation of, at best, <em>yesterday’s</em> understanding of the problem you’re trying to solve. “Reasoning about code” is by necessity accidental complexity: it’s reflecting on and trying to understand a historical solution of the problem as you once thought it was. That’s effort that could better be focussed on checking whether your understanding of the problem is indeed correct, or needs updating. Or on capturing a solution to an up-to-the-minute model of the problem in executable form.</p>
<p>This points to a need for code to be <em>deletable</em> way faster than it needs to be thought about.</p>
<p>Reasoning about code is a scam.</p>
	</div></div>]]>
            </description>
            <link>https://www.sicpers.info/2021/01/reasoning-about-code-is-a-scam/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25998554</guid>
            <pubDate>Tue, 02 Feb 2021 08:31:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fixing a Bricked SSD with JTAG]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25998328">thread link</a>) | @drudru11
<br/>
February 1, 2021 | https://fmad.io/blog-ssd-bricked-restore.html | <a href="https://web.archive.org/web/*/https://fmad.io/blog-ssd-bricked-restore.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

			<p>
				SSD`s are the life blood of our fmadio 10G, 40G, 100G ethernet capture systems. They provide backing storage that well exceeds that of conventional RAM, are super fast and light weight. Thus its prudent to keep the SSD farms in top nick, optimal health, and occasionally perform emergency room brain surgery on them. Unfortunately today is one of those days.
			</p>
			<br>

			<div>                        
				<ul>                            
					<li><img width="60%" src="https://fmad.io/images/blog/20141229_ssd_jtag_close.jpg" alt="ssd connected to jtag"></li>
				</ul>                        
			</div>


		<p>
As with all things, it happened late on a Friday night when I was adding a new feature to the system that wipes all capture data from the system. This is simple button click on the web UI page as our clients data is quite sensitive thus needs to be deleted when the box moves internally or externally. The wipe is implemented using the "Secure Erase" ATA-8 command, you can read all about it <a href="https://ata.wiki.kernel.org/index.php/ATA_Secure_Erase">here</a>. Its essentially a restore-to-factory-setting operation. Meaning after the SecureErase the drive`s internal state is the same as "just left the factory". 
		</p>
		
		<p>
Which is great when it works, but this kind of low level drive formatting is pretty complicated with many (presumably) asynchronous operations going on in parallel... and doing 100 of these operations back to back at high speed is probably something the vendor did not expect (I was testing dammit!). In our case this bricked 6 SSD`s rendering them completely useless causing myself quite the stress as I now have several thousand dollars worth of inventory destroyed!  - not a good day.
</p>


				<p><img width="1024px" src="https://fmad.io/images/blog/money_burn.jpg" alt="fmadio ssd lost"></p><p>
The result is a wall of rather intimidating errors indicating imminent doom with the disk is for all intensive purposes <a href="https://en.wikipedia.org/wiki/Brick_%28electronics%29"><b>BRICKED</b></a>.

<code>

kernel: [18633.754193] ata2.00: exception Emask 0x0 SAct 0x0 SErr 0x0 action 0x0
kernel: [18633.754204] ata2.00: irq_stat 0x40000001
kernel: [18633.754206] ata2.00: failed command: READ DMA
kernel: [18633.754209] ata2.00: cmd c8/00:08:00:00:00/00:00:00:00:00/e0 tag 0 dma 4096 in
kernel: [18633.754209]          res 51/04:00:00:00:00/00:00:00:00:00/60 Emask 0x1 (device error)
kernel: [18633.754210] ata2.00: status: { DRDY ERR }
kernel: [18633.754211] ata2.00: error: { ABRT }
kernel: [18633.754515] ata2.00: supports DRM functions and may not be fully accessible
kernel: [18633.754614] ata2.00: failed to get NCQ Send/Recv Log Emask 0x1
kernel: [18633.759150] ata2.00: supports DRM functions and may not be fully accessible
kernel: [18633.759215] ata2.00: failed to get NCQ Send/Recv Log Emask 0x1
kernel: [18633.763495] ata2.00: configured for UDMA/133
kernel: [18633.770136] ata2: EH complete
kernel: [18633.770278] ata2.00: exception Emask 0x0 SAct 0x0 SErr 0x0 action 0x0
kernel: [18633.770280] ata2.00: irq_stat 0x40000001
kernel: [18633.770281] ata2.00: failed command: READ DMA
kernel: [18633.770284] ata2.00: cmd c8/00:08:00:00:00/00:00:00:00:00/e0 tag 1 dma 4096 in
kernel: [18633.770284]          res 51/04:00:00:00:00/00:00:00:00:00/60 Emask 0x1 (device error)
kernel: [18633.770286] ata2.00: status: { DRDY ERR }
kernel: [18633.770286] ata2.00: error: { ABRT }
kernel: [18633.770572] ata2.00: supports DRM functions and may not be fully accessible
kernel: [18633.770641] ata2.00: failed to get NCQ Send/Recv Log Emask 0x1
kernel: [18633.775164] ata2.00: supports DRM functions and may not be fully accessible
kernel: [18633.775210] ata2.00: failed to get NCQ Send/Recv Log Emask 0x1
kernel: [18633.779527] ata2.00: configured for UDMA/133
kernel: [18633.786094] ata2: EH complete
kernel: [18633.786205] ata2.00: exception Emask 0x0 SAct 0x0 SErr 0x0 action 0x0
kernel: [18633.786207] ata2.00: irq_stat 0x40000001
kernel: [18633.786208] ata2.00: failed command: READ DMA
</code>


</p><p>
The usual suspects to recover were tried and failed, leaving only a few options.
<br>
</p>

<h5>a) RMA the boards back to the seller<br>
b) Contact vendor support<br>
c) Perform surgery</h5>


<p>
Option a) of RMA`ing the boards was the safest option, tho usually you get some other previously recycled RMA`ed device back. Option b) of contacting the vendor is always such a brutally painful experience. It would likely end up with some random "Customer Support" person with a strange accent... giving the default completely useless response of RMA the device and get a replacement kind of thing... ho hum. Which leaves surgery! Now I usually don't go messing with hardware like this (anymore... :) ) because it takes up quite a bit time. However SSD health and prosperity is directly linked to our profitability thus deemed it a worth while time investment to have a more intimate relationship with our SSD models of choice. 
</p>
<br>

<div><p>
The process starts with a general reconnaissance mission of what pins are accessible, and what those pins are for. First up was finding the UART / serial interface but it was silent and likely disabled by the firmware. Next up was what most likely looked like a JTAG interface and... bingo, full JTAG interface connecting and operating as expected.
</p><p>

 JTAG is a hardware based system debugger that for CPU`s let you control instruction execution and read/write memory anywhere. You can see in the picture below some soldering of header pins was required, that is then wired to a breadboard which is wired to a Raspberry PI.
</p></div>


	<p><img width="1024px" src="https://fmad.io/images/blog/20141229_ssd_jtag.jpg" alt="fmadio ssd with jtag connected"></p><div><p>
Raspberry PI? wtf ? In this case the Raspberry PI was converted into a JTAG debugger using the outstanding software over at <a href="http://openocd.sourceforge.net/">OpenOCD</a>. As "real" JTAG debuggers are quite expensive ranging from $100 - $1000+ making OCD coupled with the PI an excellent low cost alternative. 
</p><p>

At this point you get a small rush as you gain access and poke the device, after which the vastness of having no idea what anything does starts to weigh you down. Then slowly bit by bit, instruction after instruction, string after string you gain some intuition on the memory map, what the code does, how its setup and eventually find something interesting.
</p></div> 

<p>

The first entry point to look for is the classic printf / trace / debug operation which gives you insight into what the software is doing. And eventually managed to track down the code that`s basically

<code>
void trace(char* Message, ...)
{ 
	va_arg list;
	va_start(arglist, Message);

	char buf[1024];
	vsprintf(buf, Message, arglist);

	if (debug_enable)
	{
		fwrite(output, buf, strlen(buf));
	}
}
</code>

which writes out a string to a console to tell the developer on whats going on. Note that the code has to "flatten" the string first before even deciding to output or not, which gives us a nice window to sniff the string with JTAG even if nothing is written to the console. 
</p>


<p>
After sniffing strings for a while and getting a better feel for whats happening noticed that the SSD is receiving commands from the SATA host no problem. But there`s some sort of funkyness going on that causes the SSD to send no response back - kind of a one-way-street. One idea to resolve this is: in theory the security erase operation restores everything back to good health. The question tho, is the device actually processing a security erase request ?  
</p>


<p>
... and using our printf JTAG sniffer... it most certainly is processing the request! But failing miserably due to an incorrect password. You can see the sniffed printf jtag string in the output below. Hint: <i>"&lt;SED&gt; Credential Comparison Failed"</i> ASCIIZ string.
</p>


	<p><img width="1024px" src="https://fmad.io/images/blog/20141229_ssd_security_erase_fail.jpg" alt="fmadio ssd security erase fail"></p><p>
Which makes it clear why the security erase / factory reset failed but more importantly you can track down the offending bit of code from this string. That results in the following snippet of assembler courtesy of the IDA toolset below.
</p> 

<p><img width="1024px" src="https://fmad.io/images/blog/20141229_ssd_security_check.jpg" alt="fmadio ssd security erase password check"></p><p>
To decode that for you its doing a 32 byte long compare against some expected cryptographic hash key. Then the <i>"magic compare"</i> aka instruction <b>CMP R5, #1</b> is testing if the keys matched. Then doing a conditional jump to a printf routine based on that comparison result <b>BLNE sub_80...</b>. And finally  the functions return value is the result of the comparison <b>MOV R0, R5</b>. Nothing particularly fancy going on.
</p> 


<p>
There`s a few ways to go from here. One would be to reverse engineer how the 32B key is generated and create  a general purpose exploit. The other would be to just patch the binary such that it thinks it passed the security check. eg Fake a correct password response. We chose the latter as it only takes a few minutes and all I want is to restore the SSD farm`s health. Patching the binary with JTAG is trivial, console output is shown below.
</p> 


<p><img width="1024px" src="https://fmad.io/images/blog/20141229_ssd_security_erase_patch.jpg" alt="fmadio ssd security erase password fake"></p><div><p>
The above shows disassembling the patched code first, the "before" section. This is to check we overwrite the correct bit of code. Then patch it using the command <b>cpu0 arm mww</b> with the value 0xe3a05001. Then disassemble again "after section" to confirm the patch worked and has the correct instruction. 
</p><p>

In this case we replaced <b>BLNE</b> instruction (print error message to the console) with <b>MOV r5, #1</b> at address 0x8009abe4 (shown in blue). The result of the "magic check" is 0 for fail, 1 for pass and write it to register r5. All we did is ignore the whole comparison and simply override it and say the security check always passes (r5 = 1).
</p></div> 

<p>
...
</p>

<p>
Now its patched, with cpu`s resumed its the moment of truth. Issuing the security erase operation from the host system via hdparm. 
<br>
<code>
$ sudo hdparm --security-erase 1234  /dev/sdb
security_password="1234"

/dev/sdb:
 Issuing SECURITY_ERASE command, password="1234, user=user
$
</code>
<br>
... and it worked! the SSD is back to life, working as normal and running at high speed!  ... with <b>several thousand dollars worth of SSD`s back in business</b> making our 10G, 40G, 100G network capture systems more resilient than ever. Now if the SSD vendor (who shall remain nameless) would fix the dam bug so excessive back-to-back security password/erase does NOT brick the device, life would be so much better. 
</p>


	</div></div>]]>
            </description>
            <link>https://fmad.io/blog-ssd-bricked-restore.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25998328</guid>
            <pubDate>Tue, 02 Feb 2021 07:51:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Exploring FPGA Graphics (2020)]]>
            </title>
            <description>
<![CDATA[
Score 134 | Comments 38 (<a href="https://news.ycombinator.com/item?id=25998154">thread link</a>) | @rbanffy
<br/>
February 1, 2021 | https://projectf.io/posts/fpga-graphics/ | <a href="https://web.archive.org/web/*/https://projectf.io/posts/fpga-graphics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>Welcome to <em>Exploring FPGA Graphics</em>. In this series, we explore graphics at the hardware level and get a feel for the power of FPGAs. We start by learning how displays work, before racing the beam with Pong, starfields and sprites, simulating life with bitmaps, drawing lines and triangles, and finally creating simple 3D models. I’ll be writing and revising this series throughout 2020 and 2021.</p>
<p>In this first post, we learn how computer displays work and animate simple shapes with an FPGA.</p>
<p><em>Updated 2021-01-28. Get in touch with <a href="https://twitter.com/WillFlux">@WillFlux</a> or open an <a href="https://github.com/projf/projf-explore/issues">issue on GitHub</a>.</em></p>
<blockquote>
<p>In all beginnings dwells a magic force<br>
<em>Herman Hesse, Stages from <a href="https://en.wikipedia.org/wiki/The_Glass_Bead_Game">The Glass Bead Game</a></em></p>
</blockquote>
<h3 id="series-outline">Series Outline</h3>
<ul>
<li>Exploring FPGA Graphics (this post) - learn how displays work and animate simple shapes</li>
<li><a href="https://projectf.io/posts/fpga-pong/">FPGA Pong</a> - race the beam to create the arcade classic</li>
<li><a href="https://projectf.io/posts/hardware-sprites/">Hardware Sprites</a> - fast, colourful, graphics with minimal resources</li>
<li><a href="https://projectf.io/posts/fpga-ad-astra/">FPGA Ad Astra</a> - demo with hardware sprites and animated starfields</li>
<li><a href="https://projectf.io/posts/framebuffers/">Framebuffers</a> - driving the display from a bitmap in memory</li>
<li><a href="https://projectf.io/posts/life-on-screen/">Life on Screen</a> - the screen comes alive with Conway’s Game of Life</li>
<li><a href="https://projectf.io/posts/lines-and-triangles/">Lines and Triangles</a> - drawing lines and triangles with a framebuffer</li>
</ul>
<p><em>More parts to follow.</em></p>
<h3 id="requirements">Requirements</h3>
<p>For this series, you need an FPGA board with video output. We’ll be working at 640x480, so pretty much any video output will work. It helps to be comfortable with programming your FPGA board and reasonably familiar with Verilog.</p>
<p>We’ll be demoing the designs with two boards:</p>
<ul>
<li><strong><a href="https://docs.icebreaker-fpga.org/hardware/icebreaker/">iCEBreaker</a></strong> (Lattice iCE40) with <strong><a href="https://docs.icebreaker-fpga.org/hardware/pmod/dvi/">12-Bit DVI Pmod</a></strong></li>
<li><strong><a href="https://reference.digilentinc.com/reference/programmable-logic/arty-a7/reference-manual">Digilent Arty A7-35T</a></strong> (Xilinx Artix-7) with <strong><a href="https://reference.digilentinc.com/reference/pmod/pmodvga/reference-manual">Pmod VGA</a></strong></li>
</ul>
<h3 id="source">Source</h3>
<p>The SystemVerilog designs featured in this series are available from the <a href="https://github.com/projf/projf-explore/">projf-explore</a> repo on GitHub. The designs are open source hardware under the permissive MIT licence, but this blog is subject to normal copyright restrictions.</p>
<blockquote>
<p><strong>Quick Aside: SystemVerilog?!</strong><br>
We’ll be using a few choice features from SystemVerilog to make Verilog a little more pleasant (no laughing at the back). If you’re familiar with Verilog, you’ll have no trouble.</p>
</blockquote>
<h2 id="space-and-time">Space and Time</h2>
<p>The screen you’re looking at is a little universe with its own rules of space and time.</p>
<p>Looking at a screen from afar, you see a smooth two-dimensional image. Look more closely, and you see many individual blocks: these are <strong>pixels</strong>, made up of red, green, and blue components. A typical high-definition image is 1920 pixels across and 1080 lines down: over 2 million pixels in total. Even a 640x480 image has over 300,000 pixels. The need to handle so much information so quickly is a big part of the challenge of working with graphics at a hardware level.</p>
<p>A VGA cable has five main signals: red, green, blue, horizontal sync, and vertical sync. There are no addressing signals to tell the screen where to draw pixels; the secret is time, defined by the sync signals. The red, green, and blue wires carry the colour of each pixel in turn. Each pixel lasts a fixed length of time; when the display receives a <strong>horizontal sync</strong>, it starts a new line; when it receives a <strong>vertical sync</strong>, it begins a new frame. Showing many frames in quick succession provides the illusion of a moving image.</p>
<p>The sync signals are part of <strong>blanking</strong> intervals. Originally designed to allow an electron gun to move to the next line or top of the screen, blanking intervals have been retained and repurposed in contemporary displays: HDMI uses them to transmit audio. The blanking interval has three parts: <strong>front porch</strong>, <strong>sync</strong>, and <strong>back porch</strong>.</p>
<p><img src="https://projectf.io/img/posts/fpga-graphics/display-timings.png" alt="Display Timings" title="Display Timings"></p>
<h2 id="display-timings">Display Timings</h2>
<p>In this series, we’re going to use <strong>640x480</strong> as our display resolution. Almost all displays support 640x480, and its low resource requirements make it simple to work with on small FPGAs. All the same principles apply at higher resolutions, such as 1280x720 or 4K.</p>
<p>We’ll use traditional horizontal and vertical timings, based on the original VGA monitor and adapter:</p>
<div><pre><code data-lang="plaintext">    640x480 Timings      HOR    VER
    -------------------------------
    Active Pixels        640    480
    Front Porch           16     10
    Sync Width            96      2
    Back Porch            48     33
    Blanking Total       160     45
    Total Pixels         800    525
    Sync Polarity        neg    neg
</code></pre></div><p><em>Learn more from <a href="https://projectf.io/posts/video-timings-vga-720p-1080p/">Video Timings: VGA, SVGA, 720p, 1080p</a>.</em></p>
<p>Taking blanking into account, we have a total of 800x525 pixels. A typical LCD refreshes 60 times a second, so the number of pixels per second is <code>800 x 525 x 60 = 25,200,000</code>, which equates to a <strong>pixel clock</strong> of 25.2 MHz.</p>
<blockquote>
<p><strong>CAUTION: CRT Monitors</strong><br>
Any modern display, including <a href="https://en.wikipedia.org/wiki/Multisync_monitor">multisync CRTs</a>, should be fine with a 25.2 or 25 MHz pixel clock. Fixed-frequency CRTs, such as the original IBM 85xx series, could be damaged by an out-of-spec signal. Use these designs at your own risk.</p>
</blockquote>
<h2 id="running-to-time">Running to Time</h2>
<p>We’ve decided we need a pixel clock of 25.2 MHz pixel clock, but neither of our demo boards has such a clock. To reach the required frequency, we’re going to use a <strong><a href="https://en.wikipedia.org/wiki/Phase-locked_loop">phase-locked loop</a></strong> (PLL). Almost all FPGAs include one or more PLLs, but there isn’t a standard way to configure them in Verilog, so we have to use vendor-specific designs.</p>
<p>We have provided implementations for Xilinx 7 Series (XC7) and Lattice iCE40; for other FPGAs, you’ll need to consult your vendor documentation. If you can’t reach 25.2 MHz exactly, then 25 MHz or thereabouts should be fine (but see note about CRTs, above). The iCE40 can’t generate 25.2 MHz using the oscillators on iCEBreaker but works fine at 25.125 MHz.</p>
<h3 id="clock-generator-modules">Clock Generator Modules</h3>
<ul>
<li>Xilinx 7 Series: <strong><a href="https://github.com/projf/projf-explore/blob/master/common/xc7/clock_gen.sv">xc7/clock_gen.sv</a></strong></li>
<li>Lattice iCE40: <strong><a href="https://github.com/projf/projf-explore/blob/master/common/ice40/clock_gen.sv">ice40/clock_gen.sv</a></strong></li>
</ul>
<h2 id="display-timings-module">Display Timings Module</h2>
<p>Using our ~25 MHz pixel clock, we can generate timings for our 640x480 display. Creating display timings is straightforward: there’s one counter for horizontal position and one for vertical. We use these counters to decide on the correct time for sync signals.</p>
<p>640x480 display timings generator <strong>[<a href="https://github.com/projf/projf-explore/blob/master/common/display_timings_480p.sv">display_timings_480p.sv</a>]</strong>:</p>
<div><pre><code data-lang="verilog"><span>module</span> display_timings_480p (
    <span>input</span>  <span>wire</span> <span>logic</span> clk_pix,   <span>// pixel clock
</span><span></span>    <span>input</span>  <span>wire</span> <span>logic</span> rst,       <span>// reset
</span><span></span>    <span>output</span>      <span>logic</span> [<span>9</span><span>:</span><span>0</span>] sx,  <span>// horizontal screen position
</span><span></span>    <span>output</span>      <span>logic</span> [<span>9</span><span>:</span><span>0</span>] sy,  <span>// vertical screen position
</span><span></span>    <span>output</span>      <span>logic</span> hsync,     <span>// horizontal sync
</span><span></span>    <span>output</span>      <span>logic</span> vsync,     <span>// vertical sync
</span><span></span>    <span>output</span>      <span>logic</span> de         <span>// data enable (low in blanking interval)
</span><span></span>    );

    <span>// horizontal timings
</span><span></span>    <span>parameter</span> HA_END <span>=</span> <span>639</span>;           <span>// end of active pixels
</span><span></span>    <span>parameter</span> HS_STA <span>=</span> HA_END <span>+</span> <span>16</span>;   <span>// sync starts after front porch
</span><span></span>    <span>parameter</span> HS_END <span>=</span> HS_STA <span>+</span> <span>96</span>;   <span>// sync ends
</span><span></span>    <span>parameter</span> LINE   <span>=</span> <span>799</span>;           <span>// last pixel on line (after back porch)
</span><span></span>
    <span>// vertical timings
</span><span></span>    <span>parameter</span> VA_END <span>=</span> <span>479</span>;           <span>// end of active pixels
</span><span></span>    <span>parameter</span> VS_STA <span>=</span> VA_END <span>+</span> <span>10</span>;   <span>// sync starts after front porch
</span><span></span>    <span>parameter</span> VS_END <span>=</span> VS_STA <span>+</span> <span>2</span>;    <span>// sync ends
</span><span></span>    <span>parameter</span> SCREEN <span>=</span> <span>524</span>;           <span>// last line on screen (after back porch)
</span><span></span>
    <span>always_comb</span> <span>begin</span>
        hsync <span>=</span> <span>~</span>(sx <span>&gt;=</span> HS_STA <span>&amp;&amp;</span> sx <span>&lt;</span> HS_END);  <span>// invert: negative polarity
</span><span></span>        vsync <span>=</span> <span>~</span>(sy <span>&gt;=</span> VS_STA <span>&amp;&amp;</span> sy <span>&lt;</span> VS_END);  <span>// invert: negative polarity
</span><span></span>        de <span>=</span> (sx <span>&lt;=</span> HA_END <span>&amp;&amp;</span> sy <span>&lt;=</span> VA_END);
    <span>end</span>

    <span>// calculate horizontal and vertical screen position
</span><span></span>    <span>always_ff</span> @ (<span>posedge</span> clk_pix) <span>begin</span>
        <span>if</span> (sx <span>==</span> LINE) <span>begin</span>  <span>// last pixel on line?
</span><span></span>            sx <span>&lt;=</span> <span>0</span>;
            sy <span>&lt;=</span> (sy <span>==</span> SCREEN) <span>?</span> <span>0</span> <span>:</span> sy <span>+</span> <span>1</span>;  <span>// last line on screen?
</span><span></span>        <span>end</span> <span>else</span> <span>begin</span>
            sx <span>&lt;=</span> sx <span>+</span> <span>1</span>;
        <span>end</span>
        <span>if</span> (rst) <span>begin</span>
            sx <span>&lt;=</span> <span>0</span>;
            sy <span>&lt;=</span> <span>0</span>;
        <span>end</span>
    <span>end</span>
<span>endmodule</span>
</code></pre></div><p><em>ProTip: The last assignment wins in Verilog, so the reset overrides the existing <code>sx</code> and <code>sy</code>.</em></p>
<p><strong>sx</strong> and <strong>sy</strong> store the horizontal and vertical position; their maximum values are 800 and 525 respectively, so we need 10 bits to hold them (2<sup>10</sup> = 1024). <strong>de</strong> is <em>data enable</em>, which is low during the blanking interval: we use it to decide when to draw pixels.</p>
<p>Display modes vary in the polarity of their sync signals; for traditional 640x480, the polarity is negative for both <strong>hsync</strong> and <strong>vsync</strong>. Negative polarity means the voltage is mostly high, with low voltage indicating a sync signal.</p>
<p>The following simulation shows the vertical sync starting at the 490th line (counting starts at zero):</p>
<p><img src="https://projectf.io/img/posts/fpga-graphics/hsync-vsync-vga.png" alt="Sync Signal Simulation" title="Simulating VGA horizontal &amp; vertical sync signals"></p>
<h2 id="test-benches">Test Benches</h2>
<p>You can exercise the designs with the included test benches (Xilinx only):</p>
<ul>
<li><strong><a href="https://github.com/projf/projf-explore/tree/master/common/xc7/clock_gen_tb.sv">Clock Gen Test Bench</a></strong> (Xilinx 7 Series)</li>
<li><strong><a href="https://github.com/projf/projf-explore/tree/master/common/xc7/display_timings_tb.sv">Display Timings Test Bench</a></strong> (Xilinx 7 Series)</li>
</ul>
<p>Some things to check:</p>
<ul>
<li>What is the pixel clock period?</li>
<li>How long does the pixel clock take to lock?</li>
<li>Does a frame last exactly 1/60th of a second?</li>
<li>How much time does a single line last?</li>
<li>What is the maximum values of <code>sx</code> and <code>sy</code> when <code>de</code> is low?</li>
</ul>
<p><em>You can find instructions for running the simulation in the source <a href="https://github.com/projf/projf-explore/tree/master/fpga-graphics">README</a>.</em></p>
<h2 id="top-display">Top Display</h2>
<p>Now we have our display signals we’re ready to start drawing. To begin, we’re going to keep it simple and draw a coloured square. When the screen x and y coordinates are both less than 32 we draw in orange; otherwise, we use blue. Because our colour output has 4 bits per channel, we can use a single hex digit from 0-F to represent the intensity of red, green, and blue.</p>
<p>There are two versions of this top module, one for each demo board:</p>
<ul>
<li>Xilinx XC7: <strong><a href="https://github.com/projf/projf-explore/blob/master/fpga-graphics/xc7/top_square.sv">xc7/top_square.sv</a></strong></li>
<li>Lattice iCE40: <strong><a href="https://github.com/projf/projf-explore/blob/master/fpga-graphics/ice40/top_square.sv">ice40/top_square.sv</a></strong></li>
</ul>
<h3 id="arty-vga">Arty VGA</h3>
<p>Shown below is the version for Arty A7-35T (XC7) with Pmod VGA:</p>
<div><pre><code data-lang="verilog"><span>module</span> top_square (
    <span>input</span>  <span>wire</span> <span>logic</span> clk_100m,     <span>// 100 MHz clock
</span><span></span>    <span>input</span>  <span>wire</span> <span>logic</span> btn_rst,      <span>// reset button (active low)
</span><span></span>    <span>output</span>      <span>logic</span> vga_hsync,    <span>// horizontal sync
</span><span></span>    <span>output</span>      <span>logic</span> vga_vsync,    <span>// vertical sync
</span><span></span>    <span>output</span>      <span>logic</span> [<span>3</span><span>:</span><span>0</span>] vga_r,  <span>// 4-bit VGA red
</span><span></span>    <span>output</span>      <span>logic</span> [<span>3</span><span>:</span><span>0</span>] vga_g,  <span>// 4-bit VGA green
</span><span></span>    <span>output</span>      <span>logic</span> [<span>3</span><span>:</span><span>0</span>] vga_b   <span>// 4-bit VGA blue
</span><span></span>    );

    <span>// generate pixel clock
</span><span></span>    <span>logic</span> clk_pix;
    <span>logic</span> clk_locked;
    clock_gen clock_640x480 (
       .clk(clk_100m),
       .rst(<span>!</span>btn_rst),  <span>// reset button is active low
</span><span></span>       .clk_pix,
       .clk_locked
    );

    <span>// display timings
</span><span></span>    <span>localparam</span> CORDW <span>=</span> <span>10</span>;  <span>// screen coordinate width in bits
</span><span></span>    <span>logic</span> [CORDW<span>-</span><span>1</span><span>:</span><span>0</span>] sx, sy;
    <span>logic</span> hsync, vsync, de;
    …</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://projectf.io/posts/fpga-graphics/">https://projectf.io/posts/fpga-graphics/</a></em></p>]]>
            </description>
            <link>https://projectf.io/posts/fpga-graphics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25998154</guid>
            <pubDate>Tue, 02 Feb 2021 07:13:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Seeking Calm – Bikeshed 279]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25998137">thread link</a>) | @Liriel
<br/>
February 1, 2021 | https://www.bikeshed.fm/279 | <a href="https://web.archive.org/web/*/https://www.bikeshed.fm/279">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  


<header>
  
    <p>
        
  <h6>
      <span>
        Episode 279
      </span>
      <span>·</span>
    <span>
      February 2nd, 2021
    </span>
    <span>·</span>
    <span>
      35 mins 7 secs
    </span>
  </h6>

  </p>

</header>




  



<nav>
  <ul>
      <li><a href="https://www.bikeshed.fm/rss"><i></i> RSS</a></li>
      <li><a href="https://itunes.apple.com/us/podcast/the-bike-shed/id935763119"><i></i> Apple Podcasts</a></li>
      <li><a href="https://www.google.com/podcasts?feed=aHR0cDovL3NpbXBsZWNhc3QuY29tL3BvZGNhc3RzLzI4Mi9yc3M%3D"><i></i> Google Podcasts</a></li>
      <li><a href="https://overcast.fm/itunes935763119/the-bike-shed"><i></i> Overcast</a></li>
      <li><a href="https://pca.st/thebikeshed"><i></i> Pocket Casts</a></li>
      <li><a href="https://radiopublic.com/the-bike-shed-6rNAd9"><i></i> RadioPublic</a></li>
      <li><a href="https://www.iheart.com/podcast/269-the-bike-shed-48758545/"><i></i> iHeartRadio</a></li>
      <li><a href="https://open.spotify.com/show/2GM7Lo15uxyqhIv5uXfBpM"><i></i> Spotify</a></li>
      <li><a href="https://www.stitcher.com/s?fid=57659&amp;refid=stpr"><i></i> Stitcher</a></li>
      <li><a href="https://tunein.com/radio/The-Bike-Shed-p1255806/"><i></i> TuneIn</a></li>
      <li>
    <a href="#share_modal" data-modal=""> Share</a>
  </li>

  </ul>
</nav>


<section>
  <div>
    <header>
      <h3>
        About this Episode
      </h3>
    </header>

    <p>On this week's episode Steph and Chris discuss some of characteristics and behaviors they've observed in high-performing teams, touching on pull request sizing and prioritizing code review, deploy cadence, error monitoring and response, and minimizing the number of themes being tackled by the team in parallel.  They also touch on moving to Netlify and simplifying deploys, an odd edge case with 303 vs 302 status code, and the quirks of the ActiveRecord <code>or</code> method.</p>

<hr>

<p>This episode is brought to you by <a href="https://scoutapm.com/bikeshed" rel="nofollow">ScoutAPM</a>. Give Scout a try for free today and Scout will donate $5 to the open source project of your choice when you deploy</p>

<hr>

<ul>
<li><a href="https://www.netlify.com/" rel="nofollow">Netlify</a></li>
<li><a href="https://www.netlify.com/products/build/plugins/" rel="nofollow">Netlify build plugins</a></li>
<li><a href="https://git-lfs.github.com/" rel="nofollow">Git LFS</a></li>
<li><a href="https://github.com/inertiajs/inertia/issues/419" rel="nofollow">Issue opened on Inertia for 302 vs 303s</a></li>
<li><a href="https://thoughtbot.com/blog/scoping-or-clauses-with-common-joins" rel="nofollow">"Scoping .or clauses with common joins" post</a></li>
<li><a href="https://www.youtube.com/watch?v=PJjmw9TRB7s" rel="nofollow">Derek Prior's Building a Culture of Code Review</a></li>
<li><a href="https://twitter.com/mipsytipsy?lang=en" rel="nofollow">Charity Majors</a></li>
<li><a href="https://www.honeycomb.io/" rel="nofollow">Honeycomb.io</a></li>
</ul>

<p>Become a <a href="https://thoughtbot.com/sponsorship" rel="nofollow">Sponsor</a> of The Bike Shed!</p>


      <p><a target="_blank" rel="payment" href="https://github.com/sponsors/thoughtbot">Support The Bike Shed</a></p><div>
        <h5>Episode Sponsors</h5>
        <ul>
              <li>
                <a href="https://scoutapm.com/bikeshed">
                  <header>
                    Scout
                  </header>
                  <p>Give Scout a try for free today and Scout will donate $5 to the open source project of your choice when you deploy.</p>

</a>              </li>
        </ul>
      </div>


  </div>

  
</section>


  <nav>
      <a href="https://www.bikeshed.fm/278">← Previous episode</a>
      <a>
        Next episode →
</a>  </nav>
</div></div>]]>
            </description>
            <link>https://www.bikeshed.fm/279</link>
            <guid isPermaLink="false">hacker-news-small-sites-25998137</guid>
            <pubDate>Tue, 02 Feb 2021 07:10:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Small-time crooks make money by reporting Instagram accounts]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25998014">thread link</a>) | @n_kb
<br/>
February 1, 2021 | https://www.mediapart.fr/journal/international/010221/comment-de-petits-escrocs-font-fermer-des-comptes-instagram/ | <a href="https://web.archive.org/web/*/https://www.mediapart.fr/journal/international/010221/comment-de-petits-escrocs-font-fermer-des-comptes-instagram/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.mediapart.fr/journal/international/010221/comment-de-petits-escrocs-font-fermer-des-comptes-instagram/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25998014</guid>
            <pubDate>Tue, 02 Feb 2021 06:45:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Do less and do it better]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25997935">thread link</a>) | @quyleanh
<br/>
February 1, 2021 | https://qmacro.org/2021/02/01/do-less-and-do-it-better/ | <a href="https://web.archive.org/web/*/https://qmacro.org/2021/02/01/do-less-and-do-it-better/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><em>In 2021 I want to consolidate and improve upon some skills I already have, rather than add more. Here’s what I mean, and how I got inspired.</em></p>

<p>In October last year Samir Talwar <a href="https://twitter.com/SamirTalwar/status/1318904227935227905">tweeted</a> something simple yet profound: “<em>Do less, and do it better</em>”.</p>

<p>In my work and play I discover and start using various tools and technologies. The pace of change in this industry, coupled with the (not unpleasant) demands on what I have to produce, means that I often end up with only a shallow understanding of things. And sometimes these are things I use every day.</p>

<p>The nature of my job as a developer advocate (but I think this extends to development in general), in the context of that fast pace of change, means that there’s always something new to learn, to adopt, and to incorporate into a workflow, process or solution. But that can come at a price - of limited comprehension and mastery.</p>

<p>To explain further, I’m going to stretch a metaphor relating to ploughing a field and sowing seeds.</p>

<p><strong>Ploughing and sowing</strong></p>

<p>As an individual, I sometimes feel as though I’m trying to prepare a large field and plant seeds there using a poorly hand-constructed and inefficient plough made of the wrong sort of wood and bits of string, combined with a seed drill made out of old toilet rolls and sticky tape. Not only that, but I’m trying to plant across the entire field, 50 furrows wide, as I move along.</p>

<p>Needless to say, the ploughing doesn’t go very well, and the seeds are planted imprecisely, sometimes superficially, mostly wastefully, resulting in poor distribution, low growth and high energy expenditure.</p>

<p>But if I were to abandon the idea of going wide, and instead go narrow, focusing on just a handful of furrows, I could afford to take the time to correctly plant each seed, nurturing &amp; watering each one, producing strong plants with deep roots and healthy growth.</p>

<p>I’ve thought this for a while but never got round to doing anything about it. Samir’s tweet has galvanised me into spending some time working out what that means for me.</p>

<p><strong>Consolidating</strong></p>

<p>So this year I’m attempting to “do less, and do it better” by acknowledging the tools I use day in day out, and learn more about them, restricting myself to a narrow set of topics, move a step closer towards mastery in each, and really benefit from everything they have to offer.</p>

<p>Here’s an example from this weekend; I read the entirety of the main README for the excellent fuzzy-finder tool <a href="https://github.com/junegunn/fzf"><code>fzf</code></a>, all 16 pages. That might seem ridiculous to say (16 pages is not a lot) but I’ve used <code>fzf</code> for a year or so and never RTFM’d before. In my defence, I’ve also been constantly and painfully aware that I’ve merely scratched the surface. I’ve now discovered some <code>fzf</code> gems that I can put into practice immediately, and some areas that I need to dig into more.</p>

<p>Likewise for other tools that I use, tools that are not only essential, but which, when mastered, can make my workflows even better. I’m thinking of Vim (I’ve recently started watching my friend and colleague David Kunz’s <a href="https://www.youtube.com/channel/UCFU7a7OMYfcpjtIpu2j47_Q">DevOnDuty</a> series, which I can strongly recommend), <a href="https://github.com/tmux/tmux/wiki"><code>tmux</code></a> (<a href="http://rwxrob.live/">rwxrob</a> is a great practitioner, and I should re-read Brian P. Hogan’s great <a href="https://pragprog.com/titles/bhtmux2/tmux-2/">book on tmux</a> too) and of course the environment and language that ties it all together for me - <a href="https://www.gnu.org/software/bash/">Bash</a>.</p>

<p>The lockdown has afforded me time to read more, and I need to embrace that and work out how I can keep that momentum up. I want to tip the balance over from always having my fingers on the keyboard towards stepping away from the keyboard to read, reflect and consolidate my learning.</p>

<hr>

<p>Update 02 Feb 2021: I’ve started digging deeper into <code>fzf</code> - see <a href="https://qmacro.org/autodidactics/2021/02/02/fzf-the-basics-1-layout/">fzf - the basics part 1 - layout</a> over on my <a href="https://qmacro.org/autodidactics/">Autodidactics</a> blog.</p>

  </div>

</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://qmacro.org/2021/02/01/do-less-and-do-it-better/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25997935</guid>
            <pubDate>Tue, 02 Feb 2021 06:22:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Short Writing Is the Future of Writing]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25997778">thread link</a>) | @hieunc229
<br/>
February 1, 2021 | https://pigg.in/posts/nC38jbAhLTP-short-writing-is-the-future-of-writing | <a href="https://web.archive.org/web/*/https://pigg.in/posts/nC38jbAhLTP-short-writing-is-the-future-of-writing">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="str-vOKpYe5nW" data-connect-field="content"><p>Many claimed longer content rank higher [1] in search results. It should be changed soon. Either be less biased about short writing, or make the length criteria less important.</p><p>Because many of us need the right information, not long content.</p><p>Let’s start with the 2 main target users who search for things.</p><p>The first target enjoys reading. It’s like enjoy a video game, a movie, or a song. They enjoy a good experience, a type of content that opens their imagination. Then sail them through any details the author intended. Those types of content use descriptive paragraphs, transitions, with fancy words. It makes readers feel great.</p><p>The second target is in need to search for a piece of information. They prefer a straightforward and simple answer. Which means minimal, concise sentences, with no fancy words.</p><p>I used to enjoy and have no problem reading long content. But recently, I'd spend 5 seconds scanning relevant headings. Then another minute to find the information, or go back and look for another search result.</p><p>To me, this is a horrible reading habit. I realized my attention span getting shorter.</p><p>As our reading habits changed. We need a better format to diggest information. For example, video content is getting more popular. It required less effort to diggest.</p><p>3 common examples are:</p><ul><li>Medium (a blogging platform) rolled out a new model for short content. They found [2] that readers spend more time on good and short content</li><li>Seth Godin, well-known for finding out what's next for marketing. <a href="https://seths.blog/">His daily posts</a> are in between <a href="https://i.imgur.com/N28JSX3.png">50 to &gt; 300 words</a>.</li><li>Successful products that provide sumarize service: Blinklist (sumarize books service) or <a href="https://trends.vc/">TrendsVC</a> (a newsletter summarize recent trend in many categories), or <a href="https://www.producthunt.com/posts/i-lazy-to-read">I Lazy To Read</a> (summarize any article into 5-sentences)</li></ul><p>That goes with the search results. When someone needs an answer, it should be minimal, concise, and straightforward. It's easier to generate short content anyway.</p><hr><p>[cover photo] credit <a href="https://unsplash.com/photos/SSh9O_-sTzg">Priscilla Du Preez</a></p><p>[1] i.e <a href="https://backlinko.com/search-engine-ranking#:~:text=The%20average%20Google%20first%20page%20result%20contains%201,447%20words">Search engine ranking</a>, or <a href="https://www.sweor.com/seocontentlength#:~:text=The%20average%20content%20length%20for,content%20each%20web%20page%20has">SEO Content Length</a></p><p>[2] <a href="https://help.medium.com/hc/en-us/articles/360036691193-Calculating-earnings-in-the-Partner-Program#:~:text=we%E2%80%99ve%20found%20that%20readers%20will%20end%20up%20spending%20more%20time%20with%20the%20piece">How will shorter pieces perform in this new model?</a></p></div></div>]]>
            </description>
            <link>https://pigg.in/posts/nC38jbAhLTP-short-writing-is-the-future-of-writing</link>
            <guid isPermaLink="false">hacker-news-small-sites-25997778</guid>
            <pubDate>Tue, 02 Feb 2021 05:40:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Proportional Pricing Model]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25997510">thread link</a>) | @Windson
<br/>
February 1, 2021 | https://osjobs.net/blog/posts/the-proportional-pricing-model/ | <a href="https://web.archive.org/web/*/https://osjobs.net/blog/posts/the-proportional-pricing-model/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
    <div>

        

        <article data-small-caps="true" data-align="default" data-type="posts" data-toc-num="true">

            

            

            
                
            

            
                

<p><time datetime="2021-02-02T12:38:32+08:00"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M400 64h-48V12c0-6.627-5.373-12-12-12h-40c-6.627 0-12 5.373-12 12v52H160V12c0-6.627-5.373-12-12-12h-40c-6.627 0-12 5.373-12 12v52H48C21.49 64 0 85.49 0 112v352c0 26.51 21.49 48 48 48h352c26.51 0 48-21.49 48-48V112c0-26.51-21.49-48-48-48zm-6 400H54a6 6 0 0 1-6-6V160h352v298a6 6 0 0 1-6 6zm-52.849-200.65L198.842 404.519c-4.705 4.667-12.303 4.637-16.971-.068l-75.091-75.699c-4.667-4.705-4.637-12.303.068-16.971l22.719-22.536c4.705-4.667 12.303-4.637 16.97.069l44.104 44.461 111.072-110.181c4.705-4.667 12.303-4.637 16.971.068l22.536 22.718c4.667 4.705 4.636 12.303-.069 16.97z"></path></svg>&nbsp;2021.2.2</time>
    
    
    
        
        
        
            
        
    
    
        
        <span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M497.9 142.1l-46.1 46.1c-4.7 4.7-12.3 4.7-17 0l-111-111c-4.7-4.7-4.7-12.3 0-17l46.1-46.1c18.7-18.7 49.1-18.7 67.9 0l60.1 60.1c18.8 18.7 18.8 49.1 0 67.9zM284.2 99.8L21.6 362.4.4 483.9c-2.9 16.4 11.4 30.6 27.8 27.8l121.5-21.3 262.6-262.6c4.7-4.7 4.7-12.3 0-17l-111-111c-4.8-4.7-12.4-4.7-17.1 0zM124.1 339.9c-5.5-5.5-5.5-14.3 0-19.8l154-154c5.5-5.5 14.3-5.5 19.8 0s5.5 14.3 0 19.8l-154 154c-5.5 5.5-14.3 5.5-19.8 0zM88 424h48v36.3l-64.5 11.3-31.1-31.1L51.7 376H88v48z"></path></svg>&nbsp;1391</span>
    
    
        
        <span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M256 8C119 8 8 119 8 256s111 248 248 248 248-111 248-248S393 8 256 8zm0 448c-110.5 0-200-89.5-200-200S145.5 56 256 56s200 89.5 200 200-89.5 200-200 200zm61.8-104.4l-84.9-61.7c-3.1-2.3-4.9-5.9-4.9-9.7V116c0-6.6 5.4-12 12-12h32c6.6 0 12 5.4 12 12v141.7l66.8 48.6c5.4 3.9 6.5 11.4 2.6 16.8L334.6 349c-3.9 5.3-11.4 6.5-16.8 2.6z"></path></svg>&nbsp;7&nbsp;mins</span>
    
    
    
</p>

            

            <div>
              <p><span>S</span>ix months ago, <a href="https://osjobs.net/co/" target="_blank" rel="noopener">Overseas Rabbit Course</a> started using a new pricing model. After applying the new strategy, revenue from each customer has increased by 2000%. According to this data, the new pricing strategy seems to gain great success. Of course, it would be a danger if we simple inferring the reasons for succeeding from numbers. But after such a large improvement in revenue, I still tend to analyze the reasons behind it.</p>
<h3 id="table-of-contents"><a href="#table-of-contents"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>Table of Contents</h3>
<ul>
<li>Previous pricing model</li>
<li>New pricing model</li>
<li>What happened</li>
<li>Streaming media platform subscription</li>
<li>How to fix it</li>
<li>New problems</li>
<li>Summary</li>
</ul>
<h3 id="previous-pricing-model"><a href="#previous-pricing-model"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>Previous pricing model</h3>
<p>Overseas Rabbit Course is an interview course for programmers including resume review and mock interview services. The previous pricing model is quite straight forward. It started in April 2018, the day Overseas Rabbit went online. our original pricing model charged a uniform price to each customer for the same course. Customers choose the desired course and pay for it, then we apply the related course for them.</p>
<p><img src="https://cdn.jsdelivr.net/gh/OSJobs/osjobs-info@master/assets/imgs/old%20price.png" alt="Old pricing model"></p>
<p>Just like other service platforms, a common problem for this pricing model is to find the best price to achieve profit maximization, so we adjusted the price in a while. Under the premise that the reduction of price would lead to more customers. However, it doesn’t work that well. Looking back, even though this pricing model is used everywhere but may not be the one we need.</p>
<h3 id="new-pricing-model"><a href="#new-pricing-model"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>New pricing model</h3>
<p>Until June 2020, a customer proposed to use 50% of his monthly salary to pay for our course. It reminds me of another programmer course I have seen before. It is also charged in proportion to the salary. I had doubts about this pricing model at that moment for two reasons:</p>
<ol>
<li>Paying by proportion is much more expensive than a fixed fee. The median salary of Chinese programmers is about 12,000 yuan, and 50% of the salary is almost 10 times more than the original fee. I’m not sure how many customers are willing to pay for it.</li>
<li>Job hunting is a combination of ability and luck. Some customers may take a few months to be successfully recruited. Such uncertainty may cause unstable revenue.</li>
</ol>
<p>However, after we found a customer is willing to pay by proportion. We made some adjustments to the course content and adopted a dynamic charging strategy. <strong>Nowadays, all of our courses are free to join, and we charge 50% of the customer’s salary only after they had been recruited succeed.</strong> I call this pricing strategy Proportional Pricing Model. I believe someone must have discovered it earlier than me and has named it, such as the programmer course I saw before. (Welcome to leave a comment if you found the source. ) Surprisingly, under the new pricing model, there are more customers than before, and we successfully increased our revenue by 20 times recently.</p>
<p><img src="https://cdn.jsdelivr.net/gh/OSJobs/osjobs-info@master/assets/imgs/new%20price.png" alt="New pricing model"></p>
<h3 id="why"><a href="#why"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>Why</h3>
<p>I suppose there are some potential factors for the increasing revenue:</p>
<ol>
<li>Consequentialism</li>
<li>Dynamic price</li>
<li>Willingness of payment</li>
<li>Risk estimation</li>
</ol>
<h4 id="consequentialism"><a href="#consequentialism"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>Consequentialism</h4>
<p>In the beginning, we thought that customers want to improve the ability for interviewing, but we were wrong. What customers really need is getting a job, <strong>and there is a huge difference between them.</strong> Most people will only judge the quality of the course based on the result after completing it. Under the previous price model, customers will balance between the course cost and interview skills obtained with their criterion. But now, Proportional Pricing Model closely connects the recruitment certainty with our course so customers would balance the course cost with the success of recruitment.</p>
<h4 id="dynamic-price"><a href="#dynamic-price"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>Dynamic price</h4>
<ol>
<li>Proportional Pricing Model means the payment varies with the salary level, customers cannot know the actual number they will pay before getting the job which will make them feel less expensive.</li>
<li>Proportional payment is fairer. Higher cost means a higher salary. Customers should expect to pay as much as possible because it means they have a higher salary.</li>
<li>Percentages cannot be directly compared. If setting a fixed fee, such as 6,000 yuan per customer, the customer can directly compare 6,000 yuan with what he/she could purchase, such as books or other courses.&nbsp;</li>
</ol>
<h4 id="willingness-of-payment"><a href="#willingness-of-payment"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>Willingness of payment</h4>
<ol>
<li>Everyone likes free products, customers can attend our courses for free until they found a job. Since 60% of our customers are unemployed, they don’t want to pay another bill.</li>
<li><strong>Customers will pay for what they think is worth.</strong> More than one customer has said that they are willing to spend more than 50% of their salary to exchange successful recruitment, which has never happened under the previous strategy.</li>
</ol>
<h4 id="wrong-risk-estimation"><a href="#wrong-risk-estimation"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>Wrong risk estimation</h4>
<p>“It’s obvious that” most people will eventually get a job. However, lots of customers will overestimate the risk of unable to find a job when affected by the fear of unemployment.</p>
<h3 id="streaming-media-platform-subscription"><a href="#streaming-media-platform-subscription"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>Streaming media platform subscription</h3>
<p>Let me talk about one more example to use Proportional Pricing Model. From Netflix, Youtube to Chinese media platforms like Tencent Video, Mango TV uses a monthly subscription price model. Although they use some strategies to attract customers continuously subscribing, such as 30 days of free trial, continuous monthly discounts, annual discounts, family membership package, there are still several problems:</p>
<h4 id="it-cost-the-platform-a-lot"><a href="#it-cost-the-platform-a-lot"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>It cost the platform a lot</h4>
<p>Usually, customers subscribe to the service because of a certain episode, and they will cancel their subscription after watching it (the first-month cancellation rate of streaming media platform is higher than 40%). Therefore, streaming media platforms need to continuously spend money on producing new content or purchasing copyrights, which would bring a lot of costs.</p>
<h4 id="customer-is-not-happy"><a href="#customer-is-not-happy"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>Customer is not happy</h4>
<p>Some platforms want customers to automatically renew so they try different ways to prevent users from canceling, like bad UI, complicated steps, etc. Moreover, no customer feels they could take advantage of the same price.</p>
<ol>
<li>Customers who watch less (like me) will regret that they have spent too much on subscription fees. I hate monthly subscription, even though the monthly subscription price is cheaper than one cup of coffee.</li>
<li>Customer who watches more will not satisfy as well for the following two reasons: 1) Because there are a huge amount of videos, it’s difficult to measure how many videos you need to watch to get the fee back. 2) Mostly, watching videos is just a kind of entertainment. People may feel guilty if they spend too much time on it every month, and it leads to subscription cancellation.</li>
</ol>
<h3 id="how-to-fix-it"><a href="#how-to-fix-it"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>How to fix it</h3>
<p>With Proportional Pricing Model, I propose a new way to fix it:</p>
<ol>
<li>Customers can join streaming media membership for free and they can watch everything from the platform.</li>
<li><strong>The platform will charge the customer only if his/her monthly watching time is top 30% among all customers</strong>. For example, if Youtube has 10 million members, only 3 million customers will be charged every month, 7 million customers can enjoy services for free.</li>
</ol>
<p>The advantages of this scheme are as follows:</p>
<h4 id="dynamic-price-1"><a href="#dynamic-price-1"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>Dynamic price</h4>
<p>Since customers are hard to predict whether they have to pay for this month:</p>
<ol>
<li>Their watching time may unconsciously reach the level of charging.</li>
<li>They are no longer need to decide whether to subscribe to the platform depend on a specific episode.</li>
</ol>
<h4 id="willingness-to-pay"><a href="#willingness-to-pay"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>Willingness to pay</h4>
<ol>
<li>Charging everyone a fixed price is unfair. Just like electricity bills, charging everyone the same price bill will cause controversy. Therefore, members are charged based on how long they watched is more reasonable.</li>
<li>Everyone likes free products. who will cancel them when auto-renew is free.</li>
<li>It’s quite interesting to guess whether you need to pay this month. If people don’t have to pay for this month, people would feel like they earned money.</li>
</ol>
<h3 id="new-problems"><a href="#new-problems"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>New problems</h3>
<ol>
<li>In the Proportional Pricing Model, We don’t know how to set the number of percentages, 30% or 50%? Should we use the A/B test or there are other better ways for testing.</li>
<li>It is harder to get the money back, Overseas Rabbit may take several months to get the money from customer. Youtube may fail to charge some of the customers after every month.</li>
</ol>
<h3 id="summary"><a href="#summary"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>Summary</h3>
<p>From my point of view, there are two conditions to build the best pricing model</p>
<ol>
<li>Easy to understand, customer willing to pay</li>
<li>Make money when the customer didn’t aware of it</li>
</ol>
<h3 id="last"><a href="#last"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>Last</h3>
<ul>
<li>Feel free to email me (contact at osjobs.net) if you have any ideas about this article</li>
<li>Thanks to Mr. Peng and Liu Chang for reviewing this article. Thanks to Mary Ma for helping me translating.</li>
</ul>
            </div>

            
    
    
        
    



        </article>

        

        
    <p><span title="Updated @ 2021-02-02 12:38:32 CST">

<svg xmlns="http://www.w3.org/2000/svg" width="130" height="20"><linearGradient id="b" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"></stop><stop offset="1" stop-opacity=".1"></stop></linearGradient><clipPath id="a"><rect width="130" height="20" rx="3" fill="#fff"></rect></clipPath><g clip-path="url(#a)"><path d="M0 0h55v20H0z"></path><path d="M55 0h75v20H55z"></path><path fill="url(#b)" d="M0 0h130v20H0z"></path></g><g fill="#fff" text-anchor="middle" font-size="110"><text x="285" y="150" fill="#010101" fill-opacity=".3" textLength="450" transform="scale(.1)">updated</text><text x="285" y="140" textLength="450" transform="scale(.1)">updated</text><text x="915" y="150" fill="#010101" fill-opacity=".3" textLength="650" transform="scale(.1)">2021-02-02</text><text x="915" y="140" textLength="650" transform="scale(.1)">2021-02-02</text></g></svg>
        </span></p>



        


        




        
    
    



        
    



        


        


        
    
        
        
    
    
    
    



        


    </div>
</div></div>]]>
            </description>
            <link>https://osjobs.net/blog/posts/the-proportional-pricing-model/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25997510</guid>
            <pubDate>Tue, 02 Feb 2021 04:40:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Go 1.16 will make system calls through Libc on OpenBSD]]>
            </title>
            <description>
<![CDATA[
Score 291 | Comments 172 (<a href="https://news.ycombinator.com/item?id=25997506">thread link</a>) | @lladnar
<br/>
February 1, 2021 | https://utcc.utoronto.ca/~cks/space/blog/programming/Go116OpenBSDUsesLibc | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/programming/Go116OpenBSDUsesLibc">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>Go 1.16 will make system calls through libc on OpenBSD</h2>

	<p><small>February  1, 2021</small></p>
</div><div><p>One of the unusual things about <a href="https://golang.org/">Go</a> is that
it started out with the approach of directly making system calls
on Unix, instead of calling the standard C library functions that
correspond to those system calls. <a href="https://utcc.utoronto.ca/~cks/space/blog/programming/GoCLibraryAPIIssues">There are reasonably good reasons
for Go to make direct system calls</a> and this
works well on Linux, but other Unixes are different. The official
API for Illumos and Solaris system calls requires you to use their
C library, and OpenBSD wants you to do this as well for security
reasons (for <a href="https://lwn.net/Articles/806776/">OpenBSD system call origin verification</a>). Go has used the C library on
Solaris and Illumos for a long time, but through Go 1.15 it made
direct system calls on OpenBSD and so current released versions of
OpenBSD had a special exemption from their system call origin
verification because of it.</p>

<p>The news of the time interval for Go 1.16 is that this is changing. To
quote from the current draft release notes (which are probably soon to
be the official release notes):</p>

<blockquote><p>On the 64-bit x86 and 64-bit ARM architectures on OpenBSD (the
<code>openbsd/amd64</code> and <code>openbsd/arm64</code> ports), system calls are now
made through <code>libc</code>, instead of directly using the <code>SYSCALL/SVC</code>
instruction. This ensures forward-compatibility with future versions
of OpenBSD. In particular, OpenBSD 6.9 onwards will require system
calls to be made through <code>libc</code> for non-static Go binaries.</p>
</blockquote>

<p>As far as I know, Go programs that look up host names or do a few other
operations are very likely to not be statically linked. You can force
static linking (and you'll normally get it if you cross-build), but it
has some drawbacks for hostname lookups in some configurations and you
can't do some other operations at all.</p>

<p>At one level everything is okay with this situation. OpenBSD 6.9 will
almost certainly include Go 1.16 in its ports collection, since it will
be the only version of Go that works on it, and from there you can build
Go programs that will run fine on 6.9. At another level, any dynamically
linked Go program you have will need to be rebuilt with Go 1.16 before
you can run it on OpenBSD 6.9. Hopefully you have the source code and
can still build it (in what will be a 'modular by default' world in Go
1.16). This is nothing really new for OpenBSD, which has always made it
clear that they don't promise ABI or even API compatibility; you always
need to be prepared to rebuild your programs for new OpenBSD versions,
and perhaps to update them to more secure APIs.</p>

<p>(Statically linked Go programs built by Go 1.15 or earlier will likely
keep working on OpenBSD 6.9, assuming that there are no other ABI
changes that affect them. But you should probably plan to rebuild them
with Go 1.16 just to be sure. I don't know what the situation will be
if you want to create Go binaries that work across a range of OpenBSD
versions.)</p>

<p>As the release notes say, Go 1.16 will make system calls through libc
for all programs, whether they're dynamically linked or statically
linked. Right now OpenBSD only requires this for dynamically linked
programs (well, will require it), but always calling via libc is simpler
than to maintain two sets of system call code. And someday OpenBSD may
do something more elaborate so that making system calls via libc is
required even for statically linked programs.</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/programming/Go116OpenBSDUsesLibc</link>
            <guid isPermaLink="false">hacker-news-small-sites-25997506</guid>
            <pubDate>Tue, 02 Feb 2021 04:39:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Polymorphisation: Improving Rust compilation times through intelligent monomorp [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25997495">thread link</a>) | @todsacerdoti
<br/>
February 1, 2021 | https://davidtw.co/media/masters_dissertation.pdf | <a href="https://web.archive.org/web/*/https://davidtw.co/media/masters_dissertation.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://davidtw.co/media/masters_dissertation.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25997495</guid>
            <pubDate>Tue, 02 Feb 2021 04:37:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AlmaLinux Beta: A Community-Driven Replacement for CentOS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25997458">thread link</a>) | @_-david-_
<br/>
February 1, 2021 | https://blog.almalinux.org/introducing-almalinux-beta-a-community-driven-replacement-for-centos/ | <a href="https://web.archive.org/web/*/https://blog.almalinux.org/introducing-almalinux-beta-a-community-driven-replacement-for-centos/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<div>

                                <p><span>CloudLinux is proud to announce the release of AlmaLinux Beta. We’ve collected community feedback and built our new beta release around what you would expect from an enterprise-level Linux distribution. AlmaLinux is a completely free 1:1 binary compatible fork of Red Hat Enterprise Linux (RHEL) 8, inspired by the community and built by the engineers and talent behind CloudLinux. Visit <a href="https://repo.almalinux.org/almalinux/8.3-beta/isos/x86_64/">this link</a></span><span>&nbsp;to download Beta images.</span></p>

<p><span>With the Beta release deployed, we’d like to ask the community to be involved and provide feedback. We aim to build a Linux distribution entirely from community contributions and feedback. During AlmaLinux Beta, we ask for assistance in testing, documentation, support and future direction for the operating system. Together, we can build a Linux distribution that fills the gap left by the now unsupported CentOS distribution.</span></p>
<p><span>The AlmaLinux team set up all the necessary infrastructure to make it convenient for our contributors to provide their input. The public repository on </span><a href="https://github.com/AlmaLinux"><span>Github</span></a><span> is where we will finalize the source code for the system, and any additional documentation will be posted on the </span><a href="https://wiki.almalinux.org/"><span>wiki</span></a><span>. We set up the wiki and repository to make it easy for the community to provide as much information and feedback as possible. The AlmaLinux team will review every comment and request, but we ask that only registered contributors </span><a href="https://bugs.almalinux.org/login_page.php"><span>file bug reports</span></a><span> to filter out spam.</span></p>
<p><span>To facilitate communication and help answer some of the common questions you might already have, we will be hosting a live QA webinar with the AlmaLinux team. </span><span>The webinar will take place on February 10, </span><span>5 PM (UTC) / 9 AM (PST). Among the participants present will be Igor Seletskiy, CEO of CloudLinux, and Alexander Vinogradov, Head of Engineering at AlmaLinux.</span></p>
<p><span>You can sign up for our webinar </span><a href="https://blog.almalinux.org/webinars/almalinux-beta-qa-webinar/"><span>here</span></a><span>.</span></p>
<p><span>If you have any questions, comments, feedback or concerns, please feel free to send us your thoughts to </span><a href="https://blog.almalinux.org/cdn-cgi/l/email-protection#b8d0ddd4d4d7f8d9d4d5d9d4d1d6cdc096d7cadf"><span><span data-cfemail="6a020f0606052a0b06070b0603041f124405180d">[email&nbsp;protected]</span></span></a><span> or send them during the webinar on Twitter with the hashtag #AlmaLinuxBeta.</span></p>
<p><span>CloudLinux and the AlmaLinux team would like to thank the community for their input. This is just the beginning for AlmaLinux, and we look forward to continued improvements and updates for the next generation enterprise-level Linux operating system.</span></p>
<p><span>Thank you for your contribution, input, and support throughout launching AlmaLinux! The infrastructure was the first step, now we need your help to make the next one!</span></p>


<p><strong>Release Notes for AlmaLinux 8 beta</strong></p>
<p><span>The release code name: Purple <a href="https://en.wikipedia.org/wiki/Pallas%27s_cat">Manul</a>.</span></p>
<p><span>CloudLinux is proud to present the beta version of AlmaLinux. After roughly a month and a half from the announcement, here is a 1:1 RHEL binary compatible replacement for your RHEL-based systems.&nbsp;</span></p>
<p><span>This is for the community and by the community, you’re the soul of Linux. Thank you for your interest and suggestions so far, keep them coming.</span></p>
<p><span>Use this version to thoroughly test your workloads and report any unintended features (ie, bugs) you may find, it will help make AlmaLinux better.</span></p>

<h2><span>Installation instructions</span></h2>

<p><span>There are three installation ISO images available:</span></p>
<ul>
<li aria-level="1"><a href="https://repo.almalinux.org/almalinux/8.3-beta/isos/x86_64/AlmaLinux-8.3-beta-1-x86_64-boot.iso"><span>AlmaLinux-8.3-beta-1-x86_64-boot.iso</span></a><span> – a single network installation CD image that downloads packages over the Internet.</span></li>
<li aria-level="1"><a href="https://repo.almalinux.org/almalinux/8.3-beta/isos/x86_64/AlmaLinux-8.3-beta-1-x86_64-minimal.iso"><span>AlmaLinux-8.3-beta-1-x86_64-minimal.iso</span></a><span> – a minimal self-containing DVD image that makes possible offline installation.</span></li>
<li aria-level="1"><a href="https://repo.almalinux.org/almalinux/8.3-beta/isos/x86_64/AlmaLinux-8.3-beta-1-x86_64-dvd1.iso"><span>AlmaLinux-8.3-beta-1-x86_64-dvd1.iso</span></a><span> – a full installation DVD image that contains mostly all AlmaLinux packages. We don’t really recommend using it unless you need to set up and use AlmaLinux on a machine without internet access.</span></li>
</ul>

<p><span>Download a preferable ISO image and verify its checksum. Here is an example for GNU/Linux:</span></p>
<blockquote>
<pre><span># download and import the AlmaLinux public key</span>
<span>$ wget </span><a href="https://repo.almalinux.org/almalinux/RPM-GPG-KEY-AlmaLinux"><span>https://repo.almalinux.org/almalinux/RPM-GPG-KEY-AlmaLinux</span></a>
<span>$ gpg --import RPM-GPG-KEY-AlmaLinux</span>

<span># download a checksums list</span>
<span>$ wget </span><a href="https://repo.almalinux.org/almalinux/8.3-beta/isos/x86_64/CHECKSUM"><span>https://repo.almalinux.org/almalinux/8.3-beta/isos/x86_64/CHECKSUM</span>
</a><span>
# verify the checksums list, we are looking for “Good signature”</span>
<span>$ gpg --verify CHECKSUM </span>
<span>gpg: Signature made Thu 28 Jan 2021 11:39:12 PM MSK</span>
<span>gpg:&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; using RSA key 51D6647EC21AD6EA</span>
<span>gpg: <strong>Good signature from "AlmaLinux &lt;<a href="https://blog.almalinux.org/cdn-cgi/l/email-protection" data-cfemail="e69687858d87818394a6878a8b878a8f88939ec8899481">[email&nbsp;protected]</a>&gt;"</strong> [unknown]</span>
<span>gpg: WARNING: This key is not certified with a trusted signature!</span>
<span>gpg:&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; There is no indication that the signature belongs to the owner.</span>
<span>Primary key fingerprint: 5E9B 8F56 17B5 066C E920&nbsp; 57C3 488F CF7C 3ABB 34F8</span>
<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Subkey fingerprint: E53C F5EF 91CE B0AD 1812&nbsp; ECB8 51D6 647E C21A D6EA</span>

<span># download the network install ISO</span>

<span>$ wget </span><a href="https://repo.almalinux.org/almalinux/8.3-beta/isos/x86_64/AlmaLinux-8.3-beta-1-x86_64-boot.iso"><span>https://repo.almalinux.org/almalinux/8.3-beta/isos/x86_64/AlmaLinux-8.3-beta-1-x86_64-boot.iso</span></a>
<span># calculate the downloaded ISO SHA256 checksum</span>
<span>$ sha256sum AlmaLinux-8.3-beta-1-x86_64-boot.iso </span>
<span>d15be406f417e81382b46a54d87dff01c8ca770c847c18703f19146587b61a1f&nbsp; AlmaLinux-8.3-beta-1-x86_64-boot.iso</span>

<span># compare it with expected checksum, it should be the same</span>
<span>$ cat CHECKSUM | grep -E 'SHA256.*AlmaLinux-8.3-beta-1-x86_64-boot.iso'</span>
<span>SHA256 (AlmaLinux-8.3-beta-1-x86_64-boot.iso) = d15be406f417e81382b46a54d87dff01c8ca770c847c18703f19146587b61a1f</span></pre>
</blockquote>

<p><span>If you decided to use the AlmaLinux-8.3-beta-1-x86_64-boot.iso image, you will need to provide this </span><a href="https://repo.almalinux.org/almalinux/8.3-beta/BaseOS/x86_64/kickstart/"><span>https://repo.almalinux.org/almalinux/8.3-beta/BaseOS/x86_64/kickstart/ </span></a><span>repository as the Installation Source:</span></p>

<p><img loading="lazy" src="http://blog.almalinux.org/wp-content/uploads/2021/02/source-2.png" alt="" width="731" height="507" srcset="https://blog.almalinux.org/wp-content/uploads/2021/02/source-2.png 1053w, https://blog.almalinux.org/wp-content/uploads/2021/02/source-2-300x208.png 300w, https://blog.almalinux.org/wp-content/uploads/2021/02/source-2-1024x710.png 1024w, https://blog.almalinux.org/wp-content/uploads/2021/02/source-2-150x104.png 150w, https://blog.almalinux.org/wp-content/uploads/2021/02/source-2-768x532.png 768w" sizes="(max-width: 731px) 100vw, 731px"></p>

<p><span>If you are going to install a non-minimal environment, you will need to add the AppStream repository to the additional repositories: </span><a href="https://repo.almalinux.org/almalinux/8.3-beta/AppStream/x86_64/os/"><span>https://repo.almalinux.org/almalinux/8.3-beta/AppStream/x86_64/os/</span></a><span>.</span></p>
<p><span>There are no extra Installation Sources required if you decided to go with AlmaLinux-8.3-beta-1-x86_64-minimal.iso or AlmaLinux-8.3-beta-1-x86_64-dvd1.iso images.</span></p>

<h2><span>How to set up a usb key to install AlmaLinux</span></h2>
<blockquote>
<pre><span>dd if=AlmaLinux-8.3-beta-1-x86_64-boot.iso of=/dev/sdX</span></pre>
</blockquote>
<p><span>Where </span><b>sdX</b><span> is your usb device</span></p>

<h2><span>Known issues</span></h2>
<ul>
<li><span>Our libreport/abrt packages aren’t integrated with the bugs.almalinux.org bug-tracker yet, so a user will have to submit a crash report manually. Issue: </span><a href="https://bugs.almalinux.org/view.php?id=2"><span>almbz#2</span></a><span>.</span></li>
<li><span>The “perl:5.30” module support is incomplete in the beta release, it will be finished in the stable.</span></li>
<li><span>We don’t have the latest “jmc” and “maven” module versions. They will be updated later.</span></li>
<li><span>The “satellite-5-client” module is located in the BaseOS repository instead of the AppStream. Issue: </span><a href="https://bugs.almalinux.org/view.php?id=4"><span>almbz#4</span></a><span>.</span></li>
<li><span>There is no support for Secure Boot in the beta release. Issue: </span><a href="https://bugs.almalinux.org/view.php?id=3"><span>almbz#3</span></a><span>.</span></li>
<li><span>The debuginfo repositories are empty and will be populated in a couple of days after the beta release.</span></li>
</ul>



                             </div>



                            </div></div>]]>
            </description>
            <link>https://blog.almalinux.org/introducing-almalinux-beta-a-community-driven-replacement-for-centos/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25997458</guid>
            <pubDate>Tue, 02 Feb 2021 04:30:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Journal of Illusion (JOI): open-access journal to promote the study of illusions]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25997298">thread link</a>) | @sohkamyung
<br/>
February 1, 2021 | https://journalofillusion.net/index.php/joi/index | <a href="https://web.archive.org/web/*/https://journalofillusion.net/index.php/joi/index">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="customblock-about">
	<div>
		<p><span>About the journal</span></p>
<p>Journal of Illusion (JOI) is an open-access journal that aims at gathering resources to promote the study of illusion. JOI defines an illusion as the perception of an object or phenomenon that is considered to be inconsistent with individual’s or group’s prior knowledge, recognition, or belief as to what the object or phenomenon should be in perception, cognition, and/or physics.&nbsp; Therefore, JOI focuses on perceptual illusions, cognitive illusions (e.g. magic or misunderstanding) or physical illusions (e.g. mirage or the Doppler effect). For perceptual illusions, not only visual illusions but also illusions at various sensory modalities are welcome. Trompe l’oeil as well as illusion artworks are also welcome. <strong><a href="https://journals.openacademia.net/index.php/joi/about">Learn more &gt;&gt;</a></strong></p>
	</div>
</div><div id="customblock-whypublish">
	<div>
		<p><span>Why publish with <strong><em>Journal of Illusion</em></strong>?</span></p>
<p><span>Open Access</span>&nbsp;–&nbsp;<em>Journal of Illusion</em>&nbsp;is free from all access barriers, allowing for the widest possible dissemination of your work.</p>
<p><span>Retain copyright&nbsp;</span>– you are free to disseminate your work, make unlimited copies, and deposit it in any repository.&nbsp;</p>
<p><span>Personal service</span>&nbsp;–&nbsp;<em>Journal of Illusion</em>&nbsp;is published in partnership with <a href="https://openacademia.net/index.html">Open Academia</a>, a Publishing Partner dedicated to giving you excellent service.&nbsp;</p>
<p><span>Self-archiving</span>&nbsp;– you can deposit&nbsp;<em>any</em>&nbsp;version of your manuscript in any required repository or archive, or post it to your personal or institutional website.&nbsp;</p>
<p><strong>Post-publication statistics</strong> – metrics shown with each article make it easy to check how often your paper is being downloaded via the JOI website.</p>
<p><strong>Add supplementary material</strong> – you can make data sets, protocols, very large illustrations, videos, questionnaires etc. available to readers alongside your article, free of charge.&nbsp;</p>
	</div>
</div></div>]]>
            </description>
            <link>https://journalofillusion.net/index.php/joi/index</link>
            <guid isPermaLink="false">hacker-news-small-sites-25997298</guid>
            <pubDate>Tue, 02 Feb 2021 03:58:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The anthem of Russia on YouTube was “privatized” by an American company]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25997296">thread link</a>) | @sjreese
<br/>
February 1, 2021 | https://en.topwar.ru/179591-gimn-rossii-v-youtube-okazalsja-privatizirovan-amerikanskoj-kompaniej.html | <a href="https://web.archive.org/web/*/https://en.topwar.ru/179591-gimn-rossii-v-youtube-okazalsja-privatizirovan-amerikanskoj-kompaniej.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
<meta property="og:type" content="article">
<meta property="og:title" content="The anthem of Russia on YouTube was &quot;privatized&quot; by an American company">
<meta property="article:author" content="novosti">
<meta property="article:section" content="Новости">
<meta property="article:tag" content="Новости">
<meta property="article:published_time" content="2021-02-02T06:35:55+0300">
<meta itemprop="datePublished" content="2021-02-02T06:35:55+0300">
<meta itemprop="identifier" content="179591">
<p><a href="https://topwar.ru/uploads/posts/2021-02/1612236802_5.jpg" target="_blank"><img loading="lazy" src="https://topwar.ru/uploads/posts/2021-02/thumbs/1612236802_5.jpg" alt=""></a></p><p>The network is actively discussing a situation that any adequate person perceives as nonsense. The point is that YouTube video hosting users have noticed the following, to put it mildly, oddity. When trying to upload video content with the Russian anthem to their channels, bloggers were faced with warnings that this allegedly violates the copyrights of some American copyright holders. </p><p>Blogger Yuri Khovansky tried to figure out the situation when he was faced with a warning from the video hosting about “controversial content”.</p><p>It turned out that the music of the Russian anthem, written in Soviet times by the composer Alexander Alexandrov, was somehow "privatized" by the American corporation BMI. Bloggers note that now, in order to use the video with the anthem of Russia on your YouTube channel, you must submit an application to the "copyright holder". Phantasmagoria…</p><p>A detailed study of the situation revealed that this is not only the case with the Russian anthem on YouTube. It turned out that a few months ago this video hosting showed a tendency in which Western companies, including those in the music business, submitted data on the "ownership" of a number of Soviet songs, marches, etc. Thus, the American company The Orchard Music "registered rights "to the Soviet musical compositions" Victory Day "and" Holy War ". This was followed by a whole ninth wave of American "privatization" of Soviet cultural heritage on YouTube. The "rights" of American companies were registered in respect of those songs of Soviet performers who had the largest number of streams on the Internet.</p><p>Thus, it should be stated that American video hosting is actually trying to legitimize outright digital raiding or even piracy, while also encouraging it. This is another example of how far the American digital giants have gone, considering themselves the right to dispose of not only user accounts, but also cultural<a href="https://en.topwar.ru/history/" title="история">historical</a> heritage, to which they themselves have nothing to do.
</p></div></div>]]>
            </description>
            <link>https://en.topwar.ru/179591-gimn-rossii-v-youtube-okazalsja-privatizirovan-amerikanskoj-kompaniej.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25997296</guid>
            <pubDate>Tue, 02 Feb 2021 03:57:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kafka as a Database? Yes or No]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25997256">thread link</a>) | @matthewhelm
<br/>
February 1, 2021 | https://davidxiang.com/2021/01/10/kafka-as-a-database/ | <a href="https://web.archive.org/web/*/https://davidxiang.com/2021/01/10/kafka-as-a-database/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="penci-post-entry-inner"><p>I recently read through a Hacker News <a href="https://news.ycombinator.com/item?id=25346851" target="_blank" rel="noreferrer noopener nofollow">thread</a> discussing the <a href="https://materialize.com/kafka-is-not-a-database/" target="_blank" rel="noreferrer noopener">article</a> “Kafka Is Not A Database”, by <a href="https://twitter.com/narayanarjun" target="_blank" rel="noreferrer noopener nofollow">Arjun Narayan</a>&nbsp;and&nbsp;<a href="https://twitter.com/frasergeorgew?lang=en" target="_blank" rel="noreferrer noopener nofollow">George Fraser</a>. The opinions behind this topic are fascinating and I enjoyed sifting through comments from both sides of the table. For the purposes of this post, I’ve labeled these two broad groups of thoughts as Team Blue and Team Red.</p><p>Team Blue believes that <a href="https://kafka.apache.org/" target="_blank" rel="noreferrer noopener">Kafka</a>, a popular streaming platform, has the potential to be the source-of-truth for your data—replacing one of the key responsibilities of conventional databases.</p><p>Team Red strongly disagrees.</p><p>The following is high-level summary of these opinions.</p> <h2><strong>Kafka As A Database</strong></h2><h3>TL;DR Streams,Events,Kafka</h3><p>First, a conceptual model of streams:</p><blockquote><p>In&nbsp;<a href="https://en.wikipedia.org/wiki/Computer_science">computer science</a>, a&nbsp;<strong>stream</strong>&nbsp;is a&nbsp;<a href="https://en.wikipedia.org/wiki/Sequence">sequence</a>&nbsp;of&nbsp;<a href="https://en.wikipedia.org/wiki/Data_element">data elements</a>&nbsp;made available over time.&nbsp;A stream can be thought of as items on a&nbsp;<a href="https://en.wikipedia.org/wiki/Conveyor_belt">conveyor belt</a>&nbsp;being processed one at a time rather than in large batches.</p><cite>Wikipedia.org</cite></blockquote><p>Imagine that you’ve hired an invisible assistant. This assistant’s only responsibility is to record everything you do:</p><ol><li>Wakes up @ 8 am</li><li>Brushes teeth @ 8:35 am</li><li>Begins showering @ 8:40 am</li><li>…</li></ol><p>As you go about your day, your assistant meticulously captures your activity and adds new entries into your daily log. This growing log represents a <strong>stream </strong>of your day-to-day activity. The data elements that comprise the stream are known as <strong>events</strong>. Once an event is recorded, it is immutable; the fact that you brushed your teeth at 8:35 am yesterday will never change.</p><p>While your invisible assistant is following you around and <strong>producing</strong> new events to your stream, who is <strong>consuming</strong> them? Anyone who cares! I’m sure your mom would be thrilled to process through your activities and call you if there are any anomalies.</p><p>What about <strong>Kafka</strong>?</p><blockquote><p><strong>Apache Kafka</strong>&nbsp;is an&nbsp;<a href="https://en.wikipedia.org/wiki/Open-source_software" target="_blank" rel="noreferrer noopener nofollow">open-source</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Stream_processing" target="_blank" rel="noreferrer noopener nofollow">stream-processing</a>&nbsp;software platform developed by the&nbsp;<a href="https://en.wikipedia.org/wiki/Apache_Software_Foundation" target="_blank" rel="noreferrer noopener nofollow">Apache Software Foundation</a>, written in&nbsp;<a href="https://en.wikipedia.org/wiki/Scala_(programming_language)" target="_blank" rel="noreferrer noopener">Scala</a>&nbsp;and&nbsp;<a href="https://en.wikipedia.org/wiki/Java_(programming_language)" target="_blank" rel="noreferrer noopener">Java</a>.&nbsp;</p><cite>Wikipedia.org</cite></blockquote><p>Kafka is a platform (large set of software tools) that helps programmers work with streams.</p><h2>Team Blue – Streams Everywhere</h2><p>Team Blue believes that streams are a natural model for both life and computing. Your users produce a stream of clicks, sign-ups, and orders. Your code produces a stream of logs, metrics, and programmatic events. Team Blue believes that the intuitive nature of streams can lead to intuitive software architectures.</p><p>An essential component of any system is the database—a convenient place to read and write whatever you want. How can a stream replace this concept that we are so used to? If streams are a never-ending series of immutable events, then the property of state is the culmination of events up to a certain point in time. For example, the latest state of a database is the culmination of all operations made to that database. In computing, this is referred to as <a href="https://docs.microsoft.com/en-us/azure/architecture/patterns/event-sourcing" target="_blank" rel="noreferrer noopener">Event Sourcing</a>. This paradigm is very different to how many developers are used to thinking about their data.</p><p>Beyond data storage, Team Blue is bullish on the idea of stream-focused architectures in general. Streams work well with microservices, promote loose coupling of systems, and have the potential to create leverage in your software. If you’re thinking about streams, you will inevitably think about Kafka—one of the industry’s leading streaming platforms.</p><p><strong>Can</strong> you use Kafka as a database? Team Blue says yes.</p><p><strong>Should</strong> you use Kafka as a database? That’s up to you.</p><h2>Team Red – You Need Databases</h2><p>On the other side of the table is Team Red who believes that programmers are making a mistake by replacing conventional databases with Kafka.</p><p>Team Red believes that 99% of applications need the features of a conventional database—especially the features handling complex concurrency issues. Many of us use these features and they are critical for the success of our applications. Modern databases are battle-tested and have been iterated on for decades. Team Red believes that the message of “Kafka As A Database” is a dangerous message that leads developers into architectures they’re not equipped to handle.</p><h2>The People On Each Team</h2><p>There is no shortage of influential people who align with Team Blue. One notable engineer is <a href="https://twitter.com/jaykreps" target="_blank" rel="noreferrer noopener">Jay Kreps</a>, CEO of <a href="https://www.confluent.io/blog/okay-store-data-apache-kafka/" target="_blank" rel="noreferrer noopener">Confluent</a>. Confluent is an organization that sells Kafka as a solution to enterprises. There is a direct correlation between using streams and using Kafka; I’m sure Jay has a few extra reasons to be bullish on streams beyond his personal software architecture preferences.</p><p>Another influencer aligned with Team Blue is <a href="https://twitter.com/martinkl" target="_blank" rel="noreferrer noopener">Martin Kleppmann</a>, author of the extremely popular book <a href="https://www.amazon.com/Designing-Data-Intensive-Applications-Reliable-Maintainable/dp/1449373321" target="_blank" rel="noreferrer noopener">Designing Data-Intensive Applications</a>. Martin Kleppmann is a researcher who loves the idea of streams. His goal is to educate as many programmers as possible. Martin’s only qualm with Team Red’s opinion is the tone of their blog post. In his <a href="https://twitter.com/martinkl/status/1336336852890963977" target="_blank" rel="noreferrer noopener">own words</a>:</p><blockquote><p>Nice blog post [Kafka Is Not A Database] explaining why the “database inside out” approach is not for everyone. <a href="https://twitter.com/narayanarjun">@narayanarjun</a> and <a href="https://twitter.com/frasergeorgew">@frasergeorgew</a> are right —&nbsp;if you need to maintain constraints before events are written (e.g. not selling more items than you have in stock), it’s easier to use a DB and CDC.</p><p>On the other hand, the message is also a bit patronising. It basically says “you’re not clever enough to use an event log correctly — leave database stuff to the experts”. I respectfully disagree: it is good to explore new approaches. Learn about the trade-offs, educate yourself.</p><cite>Martin Kleppmann</cite></blockquote><p>Engineers on Team Red’s side include <a href="https://materialize.com/author/arjun/" target="_blank" rel="noreferrer noopener nofollow">Arjun Narayan</a>&nbsp;and&nbsp;<a href="https://materialize.com/author/george-fraser/" target="_blank" rel="noreferrer noopener nofollow">George Fraser</a>, co-authors of the <a href="https://materialize.com/kafka-is-not-a-database/" target="_blank" rel="noreferrer noopener">article</a> which refutes the idea of “Kafka As A Database.” They have decided to put a large, yellow caution sign in front of Team Blue’s message. Team Red has no issue with Kafka or streams; they have an issue with eager developers throwing out their <a href="https://en.wikipedia.org/wiki/Relational_database#RDBMS" target="_blank" rel="noreferrer noopener">RDMSs</a> and jumping on the stream bandwagon. Their only extra agenda might be to get extra eyeballs on their engineering blogs.</p><h2>Arguments From Team Blue</h2><p>The following points are summaries of topics discussed in Martin Kleppmann’s <a href="https://www.youtube.com/watch?v=fU9hR3kiOK0&amp;t=2089s" target="_blank" rel="noreferrer noopener">video</a>.</p><h3>High Integrity Data – Never Deleted</h3><p>With a database, your information is easily susceptible to being lost. Once your Postgres row is updated, it’s difficult to recover the previous state of that row without introducing custom accountability software. Databases and the records inside them are designed to be mutable. It’s both a great convenience and a great risk. If a table accidentally gets deleted, you might find yourself scrambling to restore your database from a backup. This is particularly painful in production.</p><p>On the other hand, if your data exists as a log of immutable events—and that log happens to be retained forever—the history of your changes never runs the risk of being erased. Accounting is a great example of this—accountants balance their books by only appending new entries to their ledgers. An error in a financial transaction is always fixed by another transaction.</p><p>Team Blue believes that this characteristic can be an asset to software architectures. As a permanent log of events, data will always have its historical context and can easily be audited. Furthermore, the lack of an “eraser” forces programmers and processes to be held highly accountable for their actions.</p><div> <p><span>Trade-Off</span>: </p><p> One concern of storing all your data in a log is that the size of your logs may become unwieldy over time. Do we really care about how a customer changed their email 3 years ago or do we only care about what it is today? Large Kafka logs can also complicate consumers—catching up from offset 0 may not be so easy. Kafka has implemented features like <a href="https://kafka.apache.org/documentation.html#compaction" target="_blank" rel="noopener"> Log Compaction </a> to mitigate this. However, this is yet another complexity for programmers to manage and debug. </p><p> Another trade-off of this architecture is that it can become cumbersome for privacy concerns. There are administrative use-cases (GDPR) when you are required to completely <strong>hard delete</strong> all of your customer’s personal information from your system. This takes additional effort if the data to be deleted is scattered across logs and storage systems.</p></div><h3>Separation Of Concerns – Reading / Writing</h3><p>Team Blue points out that one of the great conveniences of databases is also one of its greatest challenges. The convenience of databases is undeniable—an easy one-stop shop to read and write anything. The drawback to being a one-stop shop is that you can’t be the best at any <strong>one</strong> thing, which becomes problematic as you scale.</p><p>Conventional databases easy conflate reads and writes, two very different styles of operations. As you scale, the access patterns in your software will inevitably force you to optimize for a certain set of operations. If an operation-specific optimization is done in a centralized location, it will likely degrade the performance of other operations in that location. If you optimize reads, you complicate writes—and vice versa.</p><p>One of the first steps in optimizing SQL reads is to begin denormalizing (duplicating) data across various tables. Once your data is duplicated, queries require less joins and respond faster. However, the drawback of denormalization is that it creates additional complications on the write pathway. Programmers need to remember to update and synchronize the duplicated data across multiple tables.</p><p>This pattern grows in complexity as you scale. If denormalization isn’t getting you the required read performance, the usual next step is to introduce a cache in front of your database. A cache is extremely convenient and can be designed to precisely answer the questions your clients are asking. However, as many programmers are intimately aware of, maintaining a cache is never easy. You now to need synchronize writes across network boundaries, worry about distributed transactions, and debug subtle invalidation issues.</p><p>Going back to our make-believe example, my assistant only has <strong>one</strong> responsibility—log my daily activity. One day, I decide that I want to look back in time to see how my activities are categorized. Unfortunately, I can’t ask my assistant this question because it’s too specific; all he knows how to do is produce events. To get insights on my activity, …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://davidxiang.com/2021/01/10/kafka-as-a-database/">https://davidxiang.com/2021/01/10/kafka-as-a-database/</a></em></p>]]>
            </description>
            <link>https://davidxiang.com/2021/01/10/kafka-as-a-database/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25997256</guid>
            <pubDate>Tue, 02 Feb 2021 03:47:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Barbarians Past the Gate]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25996935">thread link</a>) | @AngelusNovus
<br/>
February 1, 2021 | https://otherlife.co/barbarians-past-the-gate/ | <a href="https://web.archive.org/web/*/https://otherlife.co/barbarians-past-the-gate/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="div_block-73-2180"><div id="inner_content-74-2180"><section id="section-2-306"><div><div id="inner_content-3-306"><p>Legacy institutions are at war with distributed collective intelligence, but the legacy institutions are losing—badly.</p>
<p>2 million full-time “content creators,” outside any professional sanction; the election of Donald Trump against an airtight media consensus certain of its impossibility; mass, hysterical preference falsification due to a normalization of political correctness, with silent mass migration into countless private communities; Big Tech’s capitulation to censorship on all major social platforms; the resilient rise in the price of Bitcoin and a proliferation of <a href="https://forefront.market/ranking">durable social currencies on Ethereum;</a> and most recently, an unprecedented execution of decentralized social intelligence, which minted more than a few millionaires out of thin air, by <a href="https://share.transistor.fm/s/05408a92">a niche internet community hacking the source code of finance capitalism.</a></p>
<p>Most of the essential requirements for a functioning polity—fiat currency, leaders, laws, and shared identity—have been fully decoded and open-sourced in the form of cryptocurrencies, content creators, Smart Contracts, and fandoms. It seems inevitable that our roughly 195 nation states must increasingly give way to thousands of digital micro-polities, as these embryonically political structures grow in economic and psychological power.</p>
<p>The only other defining characteristic of autonomous polities—a monopoly on the use of force—is increasingly obsolete as the payoff to peaceful trade raises the opportunity cost of physical violence. Hence the relative dearth of interstate war since the end of World War II.</p>
<p>If you doubt the claim that “content creators” are budding politicians—whether they know it or not—consider the curious case of Mr. Beast.</p>
<p>The most powerful Youtubers are accidentally rediscovering the nature of Aristocracy, a type of social role we like to think we abolished.</p>
<p>Mr. Beast is a Youtuber who currently enjoys 52 million subscribers and earns somewhere in the ballpark of $20-30 million annually at the age of 22. Jimmy Donaldson built one of the most influential and economically successful Youtube channels through a specific concept: Outrageous and conspicuous acts of generosity. His typical video involves him gifting large sums of money or lavish objects to random people, poor people, or friends.</p>
<p>As true aristocrats have always known, and as contemporary elites have forgotten, lavish generosity towards the needy demonstrates one’s authentic nobility, wins public attention and admiration, and genuinely improves society while increasing the political and economic power of the donor.</p>
<p>The so-called “creator economy” is only a becoming-liquid of the circuit connecting noble traits, admiration, and capital, such that the previously abolished form of Aristocracy re-appears in a distributed and ungovernable format. You could try to govern it, but you would need someone as organically admirable as the target, or else Mr. Beast fans will never even hear about your new law, let alone respect it (especially after they upload themselves full-time to the Mr. Beast VR pod and earn all of their income through Mr. Beast’s branded gaming engine). National law enforcement does not generally excel in the domain of authentic nobility, ergo the new form of distributed Aristocracy will not be put back in the bottle.</p>
<p>I am not suggesting Mr. Beast will become the effective President of a new country within the United States. I am suggesting Mr. Beast will be one of <em>thousands</em> who effectively constitute micro-polities, each one optimizing for different personality types and demographic buckets. Power laws dictate a small minority of creators will enjoy audiences far larger than the rest, but I suspect at least several thousands of creators will operate all-inclusive <em>weltanschauungen</em> for audiences of several thousands. I am pulling these specific numbers out of thin air, but I am directionally confident; I would encourage someone to explore more sophisticated modeling of this question.</p>
<p>If you still doubt that someone like Mr. Beast is an embryonic statesman, you might be impressed to learn about his long-term goal. His stated goal is to create a nation-wide system of homeless shelters and food banks. That’s right, he’s going to build a <a href="https://www.tubefilter.com/2020/11/19/mrbeast-philanthropy-food-bank/">national system of public housing.</a> I see no reason why he cannot succeed, given that he has already proven a business model that turns charismatic philanthropy into attention, admiration, and wealth for himself. Given that the USA Department of Housing and Urban Development doesn’t even try to create housing any more, it is not particularly speculative or sci-fi to suggest that Mr. Beast is on his way to becoming a kind of shadow Secretary of Housing in the United States. It’s there for the taking, it’s his stated goal, and he’s on track to do it. If he falters, it’s hard to imagine that the next generation of creators will also fail to appreciate such historic opportunities in front of them.</p>
<p>Bitcoin feeds directly into content creators becoming governors, not additively but multiplicatively—in a few ways. This means you should watch out for non-linear takeoffs, where things seem to be unfolding gradually, gradually… and then all at once.</p>
<p>First of all, Bitcoin is becoming the leading inflation-hedge asset as the US government engages in unprecedented money printing. Censorship-resistant and inflation-proof money is becoming increasingly accessible, normalized, and trusted at the same time that legacy institutions are doubling down on… censorship and inflation. It’s not inconceivable that eventually the US government needs Bitcoin—and the intellectual/communication services of leading content creators—much more than anyone needs the US government. If the US government’s balance sheet gets worse, and Bitcoin continues to get better, this alone could trigger a non-linear event where all smart money rushes into Bitcoin rapidly, and the US government’s balance sheet collapses with equal rapidity.</p>
<p>Second, most of the leading content creators have hardly even begun utilizing cryptocurrency. They will. Given the mimetic nature of financial value, leading Youtubers could single-handedly increase the price of any given cryptocurrency, simply by promoting it, using it, and whipping their fans into a frenzy.</p>
<p>Just recently Elon Musk put the word “Bitcoin” in his Twitter profile and <a href="https://www.coindesk.com/elon-musk-prompted-bitcoin-price-surge-causes-liquidation-of-387m-in-shorts">the price of Bitcoin immediately rose 15%.</a> If for any reason Bitcoin becomes fashionable among leading creators, the result will be non-linear. The creators would be making themselves even richer, simply by adopting Bitcoin and triggering price increases, so I consider this to be a game-theoretic inevitability (even if many don’t want to take this opportunity at time t1, rising creators who do take this opportunity at time t2 will dominate the others, which means it is hard to imagine a future in which this opportunity is not taken).</p>
<p>Just as we watched the Reddit community Wallstreetbets pump the price of Gamestop on the stock exchange, without a leader, any community with a leader will be all the more capable of such a feat. The Robinhood app was able to halt purchases of Gamestop, but there already exist decentralized crypto exchanges, on which nobody has the power to halt trades. Technically unstoppable versions of the Gamestop pump therefore seem inevitable on decentralized exchanges, meaning communities will eventually have unprecedented power to affect the value of assets by sheer belief and collective will.</p>
<p>There is already a new breed of avant-garde content creators—small compared to Mr. Beast but large enough to be dangerous—investing heavily in crypto assets and infrastructure. Consider Trevor McFedries, creator of the first CGI influencer Lil’ Miquela. He’s minted his own social currency $FWB on the Ethereum blockchain, and its value has been <a href="https://www.coingecko.com/en/coins/friends-with-benefits">rising steadily</a> as the value of his community increases. If he and his community continue to create value inside the community, the value of $FW will continue to rise, and everyone in the community will see their wealth increase in proportion to their $FWB holdings. It is hard to imagine that there will not eventually be a creator as big as Mr. Beast and as crypto-savvy as McFedries, who runs a private digital community with a market cap as great as the GDP of many countries.</p>
<p>The most influential content creators will build cabinets of advisors and shareholders drawn from different domains: A chief technologist drawn from Silicon Valley, a chief financial officer drawn from Wall Street, etc. This is when the political nature of content creators will become unmistakable. These companies will look and feel like small national governments, running a combination of revenue-generating enterprises for profit and philanthropic enterprises for citizen-recruitment, all organized around their own state-sponsored media.</p>
<p>The nation state may well persist, but only as a shell of its former self, and mainly by hitching its wagon to the leading micro-polities. One can imagine a scenario in which Heads of State and leading content creators broker an informal bargain that allow Heads of State to save face on condition they defer to the new power-holders. In the near future, the relationship of the US President and leading American Youtubers may be analogous to the relationship between the Queen of England and Parliament.</p>
<p>Many micro-polities will initially appear to mainstream observers as religious “cults,” driven by “conspiracy theories,” led by charismatic “grifters,” operating massive “pyramid schemes.” Eventually it will be realized that such things have always been the building blocks of nations. As the myth of Romulus attests, the founding of a nation is always a crime—until it’s the law.</p>
</div></div></section></div>

</div></div>]]>
            </description>
            <link>https://otherlife.co/barbarians-past-the-gate/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25996935</guid>
            <pubDate>Tue, 02 Feb 2021 02:50:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Cracking the top product design interviews]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25996721">thread link</a>) | @nishthadalal
<br/>
February 1, 2021 | https://nishthadalal.com/the-product-design-interview | <a href="https://web.archive.org/web/*/https://nishthadalal.com/the-product-design-interview">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-89ca65980cf20cd29b4a"><div><p>Compiling my learnings, experience, and tactics having been on both sides of the interview process. For every step of the process, I share: </p><ul data-rte-list="default"><li><p>Insights from the hiring panel’s perspective from my experience in building out design teams and designing interview guides</p></li><li><p>Learnings from interviewing with &amp; landing offers from renowned product design orgs</p></li></ul><p>There is no snippet of code that can magically help you crack the product design interview. Ultimately, every design interview is unique as it hinges on the work presented by the candidate. This book will guide you through every step of the interview process, break down what you are being assessed on, and help you walk out of every interview knowing you put your best foot forward.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1610994000314_6568"><p><em>Downloadable guides for companies like Facebook, Airbnb, Spotify and more coming soon. These will be included as extras in the book.</em></p></div></div>]]>
            </description>
            <link>https://nishthadalal.com/the-product-design-interview</link>
            <guid isPermaLink="false">hacker-news-small-sites-25996721</guid>
            <pubDate>Tue, 02 Feb 2021 02:10:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Surprising Security Vulnerability on the Google Search Results Page]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25996667">thread link</a>) | @patelajay285
<br/>
February 1, 2021 | https://ajayp.app/posts/2021/01/a-surprising-security-vulnerability-on-the-google-search-results-page/ | <a href="https://web.archive.org/web/*/https://ajayp.app/posts/2021/01/a-surprising-security-vulnerability-on-the-google-search-results-page/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Back in 2015, I discovered a surprising security vulnerability that allowed you to run malicious JavaScript code on the Google search engine results page, which might be one of the most secure pages on the internet given how much daily traffic it recieves. It wasn’t until <a href="#the-fix">4 years later (or 2019) that they finally closed the case on it</a> and I could share it without breaking my nondisclosure agreement with Google.</p><p>This sounds like a lot like an <a href="https://en.wikipedia.org/wiki/Cross-site_scripting">XSS attack</a>, which you would imagine Google would sanitize for, but it’s not and it’ll soon become clear why as I explain.</p><p>I was on Google searching for something like <em>“text-to-speech javascript libraries”</em>. I went from the Google search results page to clicking the first result, back to the Google search results page, to clicking on the second result, back to the Google search results page, etc. What I noticed was that my speakers kept making a clicking noise, like they were turning on and off—but just for a second.</p><figure><img src="https://media.ajayp.app/posts/2021/01/google-search.png" loading="lazy" width="340"></figure><p>I thought maybe there was some other program running on my computer or that my speakers were busted, but I realized it happened everytime I went to the Google search results page for this query. It also happened everytime I went to the first search results page, which was of a company that had a demo of their text-to-speech solution on it.</p><p>I figured the company’s page was loading their text-to-speech engine, that seemed to use the <a href="https://developer.mozilla.org/en-US/docs/Web/API/SpeechSynthesis">SpeechSynthesis interface of the WebSpeech API</a>, and that’s why the speakers were turning on. But why were they on the Google page? That seemed like Google was maybe pulling in code on the search results page from the company’s page. That should never happen though, surely Google sanitizes anything that ever gets displayed on their pages from containing HTML or <code>&lt;script&gt;</code> tags.</p><p>This seemed like a plausible attack vector if there was some bug that allowed you to bring arbitrary code on to the Google search results page and a huge one at that.</p><p>I dumped the source code of the search results page and started looking at the HTML around the search result, but it didn’t look like any <code>&lt;script&gt;</code> or HTML tags were making it through. I started looking for instances of the company’s domain and found something like:</p><div><pre><code data-lang="html">&lt;<span>link</span> <span>rel</span><span>=</span><span>"prerender"</span> <span>href</span><span>=</span><span>"https://thecompanyspage.com/example"</span>&gt;
</code></pre></div><p>I was not familiar with <code>rel="prerender"</code> myself in 2015. Indeed, it seemed to be some sort of <a href="https://www.w3.org/TR/2015/WD-resource-hints-20150717/#dfn-prerender">new mechanism for pre-fetching and pre-loading a page</a> to speed up page transistions and load times as an optimization.</p><p>Google seemed to have invented <code>rel="prerender"</code> to prefetch and load the first search result in the background, so that when you clicked on the first search result (as most users do), it would instantly be ready for viewing.</p><p>The <code>rel="prerender"</code> has to execute JavaScript to load dynamic content, but it wasn’t blocking the WebSpeech API from playing audio possibly. Luckily for Google, the pre-rendered content is loaded in its own origin and, therefore, sensitive resources like cookies on the Google page were not at risk from being harvested by attackers like they would be in an XSS attack.</p><p>After learning this, the next step was to prove this out with my own website on Google’s search results page and see what I could make of it.</p><p>I needed a long obscure phrase that I could get the #1 Google search result spot for and that no one would accidently stumble upon so I could keep the vulnerability relatively secret until Google could fix it. I chose the apt phrase “Alphabet Spoke to Me In My Dreams” and purchased the <code>alphabetspoketomeinmydreams.xyz</code> domain name (now expired) that would show up as the first Google search result for the phrase. This was around the time <a href="https://www.nytimes.com/2015/08/11/technology/google-alphabet-restructuring.html">Google restructured into Alphabet Inc</a>.</p><p>The first malicious thing I could think to do was to “vandalize” the Google search results page with one of those “win a prize” scams pretending to be Google to phish their users. I also thought it would be sufficiently creepy to show how you were able to access standard information about the user like their location, ISP, IP address while being prerendered and speak it back to them. I know <a target="_blank" href="https://youtu.be/iZ6bamP8wZk?t=46">Dwight Schrute would be scared of that</a>.</p><figure><div><p><iframe width="560" height="315" src="https://www.youtube.com/embed/1bFlquq0GcY" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p></div><figcaption><span>Google Search Results Page Proof-of-Concept</span>
JavaScript code executing to play speech synthesis audio on the Google search results page.</figcaption></figure><p>So this looks pretty bad, but you would think that a user might notice if they click on the first result that it was a 3rd-party page causing the audio to play not Google right? Yes, except you can use the <a href="https://developer.mozilla.org/en-US/docs/Web/API/Document/hidden"><code>document.hidden</code> property</a> to detect prerender mode and condition your code so that it only runs in <code>rel="prerender"</code> mode on the Google search engine results page! This creates a pretty robust appearance for impersonation as nothing happens if you go to the page directly.</p><div><pre><code data-lang="javascript"><span>if</span> (<span>document</span>.hidden) {
  <span>// The page is being loaded in rel="prerender", run the WebSpeech API code
</span><span></span>} <span>else</span> {
  <span>// The page is being loaded normally, don't do anything
</span><span></span>}
</code></pre></div><h2 id="chrome-vulnerability">Chrome Vulnerability</h2><p>While testing this, I found that this doesn’t only work on the Google search results page, but it turns out Chrome also “prerenders” the first result of the autocomplete in the URL search bar. Therefore, you can start playing WebSpeech audio without even having a page loaded in the browser frame.</p><figure><div><p><iframe width="560" height="315" src="https://www.youtube.com/embed/pqyOnzGDRlg" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p></div><figcaption><span>Google Chrome Proof-of-Concept</span>
JavaScript code executing to play speech synthesis audio in the Chrome browser before any page is loaded in the browser at all when triggered by a user typing in a search into the URL search bar.</figcaption></figure><h2 id="denial-of-service-possibilities">Denial-of-Service Possibilities</h2><p>After testing other APIs, it seemed clear that only the WebSpeech API was making it through to the parent page. Things like <code>alert()</code> boxes were deferred from being visible until the page was actually loaded. But it also seemed clear that, while certain APIs were not available, JavaScript was running unrestricted. What happens if you do an infinite loop on the prerendered page?</p><div><pre><code data-lang="javascript"><span>while</span> (<span>true</span>) {
  <span>// Infinite loop
</span><span></span>}
</code></pre></div><p>Yep, you could “denial of service” the Google search results page from being displayed. This is not an attack on their servers, but rather you lock up the user’s browser so Google’s search results page cannot load.</p><figure><img src="https://media.ajayp.app/posts/2021/01/dos.png" loading="lazy" alt="Google Search Results Page Denial-of-Service" title="Google Search Results Page Denial-of-Service" width="600"><figcaption><span>Google Search Results Page Denial-of-Service</span>
Preventing the Google search results page from even loading by infinite looping in the prerendered page.</figcaption></figure><p>I shared the live example and a locally reproducible example of the vulnerability to Google.</p><h2 id="googles-response">Google’s Response</h2><p>Google’s security team responded promptly and professionally within 24 hours and decided to award a monetary reward for the vulnerability. The Chrome team did not dual-award since Google had already awarded. The Chrome team, however, were responsible for fixing the issue. I was not able to share this bug for quite some time due to the nondisclosure terms of Google’s vulnerability program.</p><h2 id="the-fix">The Fix</h2><p>The bug report and discussion is now public and visible <a href="https://bugs.chromium.org/p/chromium/issues/detail?id=520275">here</a>.</p><p>I was suprised at how long it took to resolve and how difficult the fix seemed to be. It proved very difficult to break this API out from being enabled in the prerender context. In fact, at one point, one of the developers mentioned: <em>“This is currently our oldest &gt;= Medium severity security bug."</em> It was not until 2019 that they finally closed the bug after prerendering support was completely dropped from Chrome, due to it causing headaches like this, and the proof-of-concept could no longer be reproduced.</p><p>So, it seems premature optimization like <code>rel="prerender"</code> being the root of all evil isn’t just true because you might spend time <a href="https://xkcd.com/1691/">optimizing something that isn’t worth it</a>, but also because it likely increases the complexity and surface area for serious security bugs.</p></div></div>]]>
            </description>
            <link>https://ajayp.app/posts/2021/01/a-surprising-security-vulnerability-on-the-google-search-results-page/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25996667</guid>
            <pubDate>Tue, 02 Feb 2021 02:00:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unfinished Metropolis: once and future Berlin (2020)]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25996656">thread link</a>) | @benbreen
<br/>
February 1, 2021 | https://www.degradedorbit.com/articles/unfinished-metropolis-once-and-future-berlin | <a href="https://web.archive.org/web/*/https://www.degradedorbit.com/articles/unfinished-metropolis-once-and-future-berlin">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="canvas">

    
    

    

    

    <!-- // page image or divider -->
    
      
        
      
    

    <section id="page" role="main" data-content-field="main-content" data-collection-id="5b7c34c2575d1f429a26358f" data-edit-main-image="Banner">

      <!-- // CATEGORY NAV -->
      

      <div>



  <article id="article-5f971be7bd69686acb65cf50" data-item-id="5f971be7bd69686acb65cf50">

    <!--POST HEADER-->

    <header>
  		
      
    </header>

    <!--SPECIAL CONTENT-->

    
      
    

    <!--POST BODY-->

    <div><div data-layout-label="Post Body" data-type="item" data-updated-on="1603739264296" id="item-5f971be7bd69686acb65cf50"><div><div><div data-block-type="2" id="block-95e54367cabc56f751eb"><div><p><strong><em>Unfinished Metropolis</em></strong><em><br></em><a href="https://dom-publishers.com/collections/monographs/products/unfinished-metropolis" target="_blank"><strong>DOM Publishers</strong></a><br>750pp, 2 volumes in slipcase, € 48.00</p><p><strong>THE GENESIS OF</strong> Berlin as we know it today happened just over a century ago, when, on October 1, 1920, the modern city of Greater Berlin (“Groß-Berlin”) was formed from eight adjacent cities and dozens of outlying districts. The formation of this new super-city doubled Berlin’s population from 1.9 million to what was, at the time, a staggering 3.9 million people, making it the world’s fifth-largest city after Tokyo.</p><p>While it is far from unusual to see major world cities expand and contract over time, as well as for the major cities of past eras to be overtaken by the new megacities of Asia, Africa, and South America, it is practically unheard of for a city on the scale of Berlin to be smaller in 2020 than it was 100 years before. The catastrophic destruction of WWII and the Battle of Berlin, which caused the population to plummet back to nearly its pre-Groß-Berlin level, also brought about the conditions that would keep the population low well into the following century. The crushing geopolitical gravity generated by Berlin’s position at the heart of the Cold War acted as a colossal reduction gear, stifling growth in both the Western and Eastern sectors of the city as each side threw all available resources into countering the advances of the other.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1603726593778_131865"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/56911f0d0ab377deeecbd785/1604320816015-FQFMQKKVLMHV5JPE9GYQ/ke17ZwdGBToddI8pDm48kJG14txsHgzjB7nppdaw8plZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpwu0TqNuiaV5_GOW_VJjc9kxccpf3lnWHr2NP-nONA3GVqI9aFR2ZcSR0-pFiy2cfQ/9783869222493_innenansicht_04_1024x1024.jpg" data-image="https://images.squarespace-cdn.com/content/v1/56911f0d0ab377deeecbd785/1604320816015-FQFMQKKVLMHV5JPE9GYQ/ke17ZwdGBToddI8pDm48kJG14txsHgzjB7nppdaw8plZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpwu0TqNuiaV5_GOW_VJjc9kxccpf3lnWHr2NP-nONA3GVqI9aFR2ZcSR0-pFiy2cfQ/9783869222493_innenansicht_04_1024x1024.jpg" data-image-dimensions="747x515" data-image-focal-point="0.5,0.5" alt="9783869222493_innenansicht_04_1024x1024.jpg" data-load="false" data-image-id="5f9ffe2f41d2a92c7a015277" data-type="image" src="https://www.degradedorbit.com/articles/9783869222493_innenansicht_04_1024x1024.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604309519192_38189"><div><p>From our current viewpoint&nbsp; two decades into the 21st century and three into a reunified Germany, Greater Berlin’s first century appears as a repeating cycle of destruction and renewal. This cyclical progression informs both the subject matter and the overarching structure of <strong><em>Unfinished Metropolis</em></strong>, a monumental new 2-volume work from Berlin’s Dom Publishers. The book accompanies the exhibition of the same name (“Unvollendete Metropole”; info at end of article), and takes a many-faceted view of Berlin, starting with an examination of the newly-unified Groß-Berlin, a unification that only happened, unsurprisingly (and much like the BER Airport debacle of the 21st century) after decades of conflict and barely-there consensus. As the introduction points out, Greater Berlin has spent the majority of its existence outside of democratic rule:</p><p><em>Greater Berlin was not ruled by democratically elected governments for many years of its history. It was only governed democratically in the period from 1920 to 1933 and then again more recently since 1990. The Greater Berlin project has suffered many setbacks. The city is an incomplete project.</em></p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1603726593778_145993"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/56911f0d0ab377deeecbd785/1604320881705-FXBQOP4YZQD6NUP8B34Z/ke17ZwdGBToddI8pDm48kLmtpSGpfTWRR3a7ID72iKlZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PId1dPce1hbL_xovi9-_ZRgZkcCx6byhA5r5lUBWSe_W4KMshLAGzx4R3EDFOm1kBS/9783869222493_innenansicht_06_1024x1024.jpg" data-image="https://images.squarespace-cdn.com/content/v1/56911f0d0ab377deeecbd785/1604320881705-FXBQOP4YZQD6NUP8B34Z/ke17ZwdGBToddI8pDm48kLmtpSGpfTWRR3a7ID72iKlZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PId1dPce1hbL_xovi9-_ZRgZkcCx6byhA5r5lUBWSe_W4KMshLAGzx4R3EDFOm1kBS/9783869222493_innenansicht_06_1024x1024.jpg" data-image-dimensions="984x570" data-image-focal-point="0.5,0.5" alt="9783869222493_innenansicht_06_1024x1024.jpg" data-load="false" data-image-id="5f9ffe7073e1561a65f75106" data-type="image" src="https://www.degradedorbit.com/articles/9783869222493_innenansicht_06_1024x1024.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604268871222_13256"><p>The rest of the book takes this idea to heart, and views Berlin through numerous lenses of <em>becoming</em>, rather than of <em>being. </em>Its perspective zooms out, for example, for dictator’s-eye view of the Nazi fantasia of Germania and the massive Socialist project Stalinallee. In a remarkable cartoon that compresses the curvature of the earth from Rome through Dresden and Berlin and beyond, reminiscent of Saul Steinberg’s “View of the World from 9th Avenue”, it even cast the Axis of WWII phantasmagorically onto the curvature of the earth. More frequently, though, its perspective zooms <em>in</em> on a staggering array of Berlin neighborhoods and city centers (Berlin’s paradoxical nature as a city with numerous “centers” is a recurring theme in the book), from lasting “centers” like Alexanderplatz and Zoologischer Garten to outlying districts like Friedenau in the West and Marzahn in the East, as well as yet more microscopic examinations of plazas, parks, and even specific artworks.</p></div><div data-block-type="5" id="block-yui_3_17_2_1_1603726593778_154562"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/56911f0d0ab377deeecbd785/1604320920366-J8O3AC6S80MEPZ7QIN3Y/ke17ZwdGBToddI8pDm48kKMvhmW4XDVUvRNeVjTih8AUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcd2YDz7CbvKCMbhI-eX1RxOvukNcWl0sYLLJkXo0Z3h0ciZVMsGk1jiC50VUmjlSD/9783869222493_innenansicht_17_1024x1024.jpg" data-image="https://images.squarespace-cdn.com/content/v1/56911f0d0ab377deeecbd785/1604320920366-J8O3AC6S80MEPZ7QIN3Y/ke17ZwdGBToddI8pDm48kKMvhmW4XDVUvRNeVjTih8AUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcd2YDz7CbvKCMbhI-eX1RxOvukNcWl0sYLLJkXo0Z3h0ciZVMsGk1jiC50VUmjlSD/9783869222493_innenansicht_17_1024x1024.jpg" data-image-dimensions="1022x577" data-image-focal-point="0.5,0.5" alt="9783869222493_innenansicht_17_1024x1024.jpg" data-load="false" data-image-id="5f9ffe9731ce363ec2d96c55" data-type="image" src="https://www.degradedorbit.com/articles/9783869222493_innenansicht_17_1024x1024.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604268871222_13674"><div><p>Unsurprisingly, maps are fundamental to the book, which features countless versions of the mapped city: street maps, transit maps, agricultural maps, Cold War maps from both East and West, comical maps by political cartoonists, utopian maps from the 1960s and 1970s, maps of neighborhoods long destroyed by war and property speculation, maps of futures that never came to pass. While such a vast array of maps might seem overwhelming, their overall effect is, paradoxically, one of greater focus. The accumulation of so many varied views of the city leads to a surprisingly unified view of the whole, like a cubist painting or a musical composition with a repeating theme. Berlin has spent the past century proving itself to be one of the world’s most unmappable cities (from a conventional perspective), with monumental buildings constructed and razed to the ground within decades – and, in the case of the Stadtschloß, built up again. The city has seen whole neighborhoods built, destroyed, and rebuilt, streets changing names from decade to decade, and of course its 30-year stint as two divided cities.&nbsp;</p><blockquote><h3><em>The accumulation of so many varied views of the city leads to a surprisingly unified view of the whole, like a cubist painting or a musical composition with a repeating theme</em></h3></blockquote><p>True to its cyclical take on Berlin’s history, the book favors a thematic progression over a chronological one, moving backwards and forwards in history, from the 1920s (and even earlier) right up to bleeding-edge current events like COVID-19, the new BER Airport, and the still-under-construction Tesla Gigafactory. While current mayor Michael Müller provides an introductory text, the true “host” of the book is <strong>Gustav Böß</strong>, mayor of Greater Berlin from 1921 to 1929. Böß possesses not only a far-reaching futurism – “Urban development should never be driven by current needs, but rather by how it will meet future needs” – but also a timeless weariness appropriate to anyone who has attempted to obtain a consensus in the cranky, contentious politics of Berlin. His words written in the 1920s resonate prophetically over the next century’s worth of maps, documents, and photographs, and introduce each major new thematic section, from Berlin’s rail network to its roads and streets to the issue of its numerous “centers”.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1603726593778_150290"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/56911f0d0ab377deeecbd785/1604321034824-T90IAJ1SL0Y8R11AKPHQ/ke17ZwdGBToddI8pDm48kPf-9IFiXHlN5wUHqhl69w4UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcOXFSvWCyvgJTrEeQb128qZmUj8S1UqnZWcPfld7eae8dRUyPxgfIWWzZJ3F5ed1Y/9783869222493_innenansicht_9_1024x1024.jpg" data-image="https://images.squarespace-cdn.com/content/v1/56911f0d0ab377deeecbd785/1604321034824-T90IAJ1SL0Y8R11AKPHQ/ke17ZwdGBToddI8pDm48kPf-9IFiXHlN5wUHqhl69w4UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcOXFSvWCyvgJTrEeQb128qZmUj8S1UqnZWcPfld7eae8dRUyPxgfIWWzZJ3F5ed1Y/9783869222493_innenansicht_9_1024x1024.jpg" data-image-dimensions="1022x571" data-image-focal-point="0.5,0.5" alt="9783869222493_innenansicht_9_1024x1024.jpg" data-load="false" data-image-id="5f9fff09501b164da3d2e69a" data-type="image" src="https://www.degradedorbit.com/articles/9783869222493_innenansicht_9_1024x1024.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1603726593778_154122"><p>Fittingly, for a project so open to moving forward and backward in time, the second volume sets its eyes on the next half-century. This companion volume documents the “International Urban Planning Competition for Berlin-Brandenburg 2070”, where competitors sought to present comprehensive visions for the next 50 years. The competition, as well as Volume Two itself, take an international view of city planning, looking abroad to other European capitals from London to Paris to Moscow. The text offers ample historical context for each city covered, ultimately highlighting the ways in which Berlin’s challenges are either different from – or, more frequently, surprisingly similar to – those of other cities.</p></div><div data-block-type="5" id="block-yui_3_17_2_1_1603726593778_141204"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/56911f0d0ab377deeecbd785/1603738806470-1G6RZB8TWWCFG26BSAUT/ke17ZwdGBToddI8pDm48kMkblXQQFbdNlTnVTtJ-j2sUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcyQHbZDoZOEFGy2lUoL7MEoudnTLDJTBZlw1qylfth9wtQRRgu06LHCr8P_KT66ke/9783869222493_innenansicht_22_1024x1024.jpg" data-image="https://images.squarespace-cdn.com/content/v1/56911f0d0ab377deeecbd785/1603738806470-1G6RZB8TWWCFG26BSAUT/ke17ZwdGBToddI8pDm48kMkblXQQFbdNlTnVTtJ-j2sUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcyQHbZDoZOEFGy2lUoL7MEoudnTLDJTBZlw1qylfth9wtQRRgu06LHCr8P_KT66ke/9783869222493_innenansicht_22_1024x1024.jpg" data-image-dimensions="1023x637" data-image-focal-point="0.5,0.5" alt="9783869222493_innenansicht_22_1024x1024.jpg" data-load="false" data-image-id="5f971cb6fcd1705a9b248425" data-type="image" src="https://www.degradedorbit.com/articles/9783869222493_innenansicht_22_1024x1024.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1603726593778_159263"><div><p><em>Unfinished Metropolis</em> provides many useful lenses through which Berlin’s often haphazard, unfinished, and imperfect urban systems can be viewed. Its willingness to travel quickly between past and future makes for a highly readable text, which nonetheless remains grounded in reality. Most importantly, it shows Berlin’s resilience in outliving adversity. The shadows of a global pandemic and an imperiled EU may still be looming, but Berlin has seen more than its share of challenges over the past century, none of which have broken its capacity for self-reinvention.</p><p><em>The exhibition “Unvollendete Metropole: 100 Jahre Städtebau für Groß-Berlin” runs at </em><a href="https://www.visitberlin.de/de/event/unvollendete-metropole-100-jahre-staedtebau-fuer-gross-berlin" target="_blank"><strong><em>Kronprinzenpalais</em></strong></a><em> through January 3, 2021. Current COVID-19 restrictions may affect access and opening hours.</em></p></div></div></div></div></div></div>
    


    <!--POST FOOTER-->

    


  </article>



<!--PAGINATION-->


  



  <!-- COMMENTS -->

  


</div><!-- /article-wrapper -->



    </section>

    

    <!-- <div class="page-divider bottom-divider"></div> -->

    

    

  </div></div>]]>
            </description>
            <link>https://www.degradedorbit.com/articles/unfinished-metropolis-once-and-future-berlin</link>
            <guid isPermaLink="false">hacker-news-small-sites-25996656</guid>
            <pubDate>Tue, 02 Feb 2021 01:58:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Portmaster – open-source firewall. Could be better than simplewall?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25996609">thread link</a>) | @0ldGREENtree
<br/>
February 1, 2021 | https://safing.io/portmaster/ | <a href="https://web.archive.org/web/*/https://safing.io/portmaster/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <nav>
  
  <label for="menu-toggle">
    <svg stroke="currentColor" fill="none" viewBox="0 0 24 24">
      <path :class="{'hidden': open, 'inline-flex': !open }" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h16"></path>
      <path :class="{'hidden': !open, 'inline-flex': open }" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12"></path>
    </svg>
  </label>
  
  
</nav>

    <div>
  <p><img src="https://safing.io/assets/img/icons/info.svg">
    <span>Portmaster is Alpha Software - expect hickups here and there</span>
  </p>
</div>
<header>
  <div>
    <div>
      <div>
        
        <div>
          <p>
            Portmaster is a free and open-source application that puts you back in charge over all your computer's network connections.
          </p>
          
        </div>
      </div>
      <p><img src="https://safing.io/assets/img/page-specific/portmaster/full-interface.png" alt="">
      </p>
      <p><span>
        <img src="https://safing.io/assets/img/page-specific/portmaster/wave.png" alt="">
      </span>
    </p></div>
  </div>
</header>
<section id="features">
  <div id="network-all-network-activity">
    <div>
      <div>
        <p><img src="https://safing.io/assets/img/icons/info.svg">
          Alpha Software: Portmaster is in active development
        </p>
        
        <p>
          Discover everything that is happening on your computer. Expose every connection your applications make and detect evil ones. Finally get the power to act accordingly.
        </p>
      </div>
    </div>
    <p><img src="https://safing.io/assets/img/page-specific/portmaster/monitor-network-activity.png" alt="">
    </p>
  </div>
  <div id="manually-allow-or-block-connections">
    <div>
      <div>
        <p><img src="https://safing.io/assets/img/icons/info.svg">
          Alpha Software: Portmaster is in active development
        </p>
        
        <p>
          Add your own rules to block specific domains you dislike. Enable Prompt Mode and decide the fate of every new connection. Block or Allow.
        </p>
      </div>
    </div>
    <p><img src="https://safing.io/assets/img/page-specific/portmaster/manually-allow-ord-block-connections.png" alt="">
    </p>
  </div>
  <div id="auto-block-via-selected-filter-lists">
    <div>
      <div>
        <p><img src="https://safing.io/assets/img/icons/info.svg">
          Alpha Software: Portmaster is in active development
        </p>
        
        <p>
          Block ads, trackers, malware and NSFW sites via trusted domain-lists, which are also used by Ad-Blockers, etc. Easily change the defaults to fit your needs.
        </p>
      </div>
      <!-- <div class="py-10 sm:py-10 text-center sm:flex">
        <a href="https://docs.safing.io/">
          <button type="button" style="background-color: #000;" class="transform hover:scale-95 inline-flex items-center px-10 py-3 border border-transparent text-xs leading-5 font-extrabold rounded-full text-white hover:bg-indigo-500 focus:outline-none focus:border-indigo-700 active:bg-indigo-700 transition duration-150 ease-in-out uppercase">
            Checkout our Docs
          </button>
        </a>
      </div> -->
    </div>
    <p><img src="https://safing.io/assets/img/page-specific/portmaster/block-trackers-system-wide.png" alt="">
    </p>
  </div>
  <div id="enforce-dns-over-tls">
    <div>
      <div>
        <p><img src="https://safing.io/assets/img/icons/info.svg">
          Alpha Software: Portmaster is in active development
        </p>
        
        <p>
          Even with invasive connections gone, you do not want to share your dns requests out in the open. With the Portmaster, you can easily re-route all your dns queries to a DNS-over-TLS provider of your choice.
        </p>
      </div>
    </div>
    <p><img src="https://safing.io/assets/img/page-specific/portmaster/enforce-dns-over-tls.png" alt="">
    </p>
  </div>
  <div id="explore-the-docs-and-source-code">
    <div>
      <div>
        <p><img src="https://safing.io/assets/img/icons/info.svg">
          Alpha Software: Portmaster is in active development
        </p>
        
        <p>
          In the age of Mass Surveillance, what good is a service when you cannot see what it is really doing? We believe in open source. We also document everything as good as we can.
        </p>
      </div>
      
    </div>
    <p><img src="https://safing.io/assets/img/page-specific/portmaster/explore-the-docs-and-source-code.png" alt="">
    </p>
  </div>
  <div id="configure-settings-for-different-networks">
    <div>
      <div>
        <p><img src="https://safing.io/assets/img/icons/info.svg">
          Alpha Software: Portmaster is in active development
        </p>
        
        <p>
          The Wi-Fi in your local coffee shop is riskier than yours at home. Set up your settings for different networks and then simply press a button when changing location. All settings will adjust immediately.
        </p>
      </div>
    </div>
    <p><img src="https://safing.io/assets/img/page-specific/portmaster/configure-settings-for-different-networks.png" alt="">
    </p>
  </div>
  <div id="set-global-and-app-settings">
    <div>
      <div>
        <p><img src="https://safing.io/assets/img/icons/info.svg">
          Alpha Software: Portmaster is in active development
        </p>
        
        <p>
          Make your own rules. Completely cut off applications from the Internet. Or block all p2p connections except for certain apps. Or never connect to specific countries. The Portmaster has you covered.
        </p>
      </div>
    </div>
    <p><img src="https://safing.io/assets/img/page-specific/portmaster/Set-global-and-per-app-configureation.png" alt="">
    </p>
  </div>
</section>
<section>
  <div>
    <div>
      <div>
        <div>
          <div>
            <div>
              
              <p><img src="https://safing.io/assets/img/icons/info.svg">
                Portmaster is Alpha Software, treat as such; expect bugs here and there. Early Adopters welcome.
              </p>
            </div>
            
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<section id="faq">
  <div>
    <div>
      <div>
        
        <p>
          You have a question? We answered some already, but you can always contact us at <a href="mailto:hello@safing.io">hello@safing.io</a>
        </p>
      </div>
      <div>
        <dl>
          
            <div>
              
              <dd>
                <p>
                  Our business model is Freemium. First, provide local privacy for free, forever. Second, let happy users support us by paying for a powerful VPN alternative. Third, reinvest earnings into making all our products better.
                </p>
              </dd>
              
                <p>
                  <a href="https://safing.io/spn/">
                    Find out more about the VPN alternative.
                  </a>
                </p>
              
            </div>
          
            <div>
              
              <dd>
                <p>
                  Yes, we highly recommend to continue using adblockers, such as uBlock Origin, uMatrix, or similar. They give you more fine grained control over domains. iE you can allow certain domains to allow css files &amp; images while blocking cookies &amp; javascripts. The Portmaster cannot make this distinction.
                </p>
              </dd>
              
            </div>
          
            <div>
              
              <dd>
                <p>
                  Currently we support Windows and Linux. Mac and Mobile are planned, but are further down the road.
                </p>
              </dd>
              
            </div>
          
          
        </dl>
      </div>
    </div>
  </div>
</section>

    

  

</div>]]>
            </description>
            <link>https://safing.io/portmaster/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25996609</guid>
            <pubDate>Tue, 02 Feb 2021 01:51:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to hire a software engineering contractor]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25996457">thread link</a>) | @muxcmux
<br/>
February 1, 2021 | https://www.tonkata.com/posts/how-to-not-hire-a-software-engineering-contractor/ | <a href="https://web.archive.org/web/*/https://www.tonkata.com/posts/how-to-not-hire-a-software-engineering-contractor/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>For almost 4 years now I have been a web development contractor.</p>
<p>To me, a software contracting job is about bringing in extra resources to help
you or your company solve a problem. Something you can’t solve or it’s too
economically disadvantageous to solve by only relying on your current staff.
Kinda like if you had to add a downpipe to your guttering - you probably will
get it done, but chances are it’s gonna take more time, money, and pain than
if you had instead opted for a handyman to do the job.</p>
<p>Needing a contractor automatically implies a few things. First, you actually
have a concrete problem. This might be rolling out a new feature, fixing some
old bugs, or improving an existing user journey - a project in a sense. Whatever
it is - you know exactly (or nearly) what you want. Second, your engineers can’t
be allocated to the task, they have better things to do. Third, you want to
bring someone on board who knows their shit. You are not interested in investing
in their future or growing an in-house team. You just want to get stuff done.
And finally - you have a budget and a time constraint to work with.</p>
<p>So the question is - How the heck do you know if the person you are interviewing
is going to do a job of acceptable quality, on time, and within budget?</p>
<p>Well, how do you work out if the handyman can do your guttering?</p>
<p>I would instinctively ask them about the work they’ve already done. Have they
worked on guttering before? If yes - what kind? Maybe they’ve worked with
plastic pipes or perhaps they prefer old fashioned copper systems? Hell, if the
convo’s going well, I might ask them to show me some of their previous work! Why
stop there - ask them about how they are going to carry the job out? All good
questions, no doubt, and it seems most people will take a similar approach when
looking for a handyman.</p>
<p>So why is it then, when I apply for a software contracting job in your company,
you are asking me to solve a 2sum problem? Why do you insist I implement a
<a href="https://www.youtube.com/watch?v=YQs6IC-vgmo">linked list</a>? How is me inverting
a binary tree helping you decide if I can build your GraphQL API? Does it really
help you work out if I’ll be able to fix that mess of a legacy networking
library your ex-principal engineer left behind if I can convert Roman numerals
to Arabic and back?</p>
<p>No, none of this will help you figure it out. Just like it won’t help you work
out if the handyman can fix your guttering if you ask them to demonstrate to you
how to climb a ladder, drive a screw, or fix a light bulb.</p>
<p>If you need to ask these questions at an interview, then you most certainly
don’t need a contractor. You want permanent employees. What you need is to
grow the organisation and have people you can continuously invest in. You don’t
necessarily have an immediate problem requiring you to bring in extra help. It’s
either that or you just heard FAANGs are hiring this way, so I’mma do it too.</p>
<p>I’m not 22 and definitely not fresh out of gradschool. I <a href="https://www.tonkata.com/work/">have been around for a
while</a> and I know my shit. I’ve seen things and I have no
problem showing you my work or walking you through it. I have no illusions of
being a genius or the best and that’s reflected in my day rate. I’m a contractor
with real world experience. Experience from the same world your paying customers
live in - not the imaginary problems and shitty data structures one.</p>
<p>So please don’t waste my time with your pretend problems and ego scratching.
It’s not a contractor you are after.</p>
</section></div>]]>
            </description>
            <link>https://www.tonkata.com/posts/how-to-not-hire-a-software-engineering-contractor/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25996457</guid>
            <pubDate>Tue, 02 Feb 2021 01:23:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The “induced demand“ case against YIMBYism is wrong]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25996426">thread link</a>) | @jseliger
<br/>
February 1, 2021 | https://www.slowboring.com/p/induced-demand | <a href="https://web.archive.org/web/*/https://www.slowboring.com/p/induced-demand">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Today I want to talk about an idea that I don’t think has much purchase in real-world politics but seems to loom large both on the internet and in academic circles — the idea that new real estate development activity actually <em>causes gentrification</em> through some kind of induced demand phenomenon. </p><p>Nathan Robinson in his <a href="https://www.currentaffairs.org/2021/01/the-only-thing-worse-than-a-nimby-is-a-yimby">anti-YIMBY screed</a> explores a scenario in which replacing smaller buildings with larger ones increases housing scarcity even while adding units because “we're luring rich people from elsewhere to our city.” He’s doing a thought-experiment, but clearly one he thinks is plausible, while <a href="https://shelterforce.org/2018/11/05/heres-what-we-actually-know-about-market-rate-housing-development-and-displacement/">Amee Chew</a> in a 2018 Shelterforce article states that “numerous studies show that market-rate housing development has price ripple effects on surrounding neighborhoods, driving up rents and increasing the burden on lower-income households.”</p><p>Chew’s studies don’t really say that (more on this later) but the studies do say what I also know from personal experience which is that people living through a gentrification process often <em>say</em> this is what’s going on. This is all exacerbated by the fact that many people, as in this recent Washington Post article about Mt Pleasant, <em>define</em> gentrification as the presence of new-built condos with chain store retail on the ground floor. And it is definitely true that if what you mean by “gentrification” is “new buildings and chain stores” then blocking new buildings and chain stores will block gentrification.</p><p>But the argument here is supposed to be about prices, displacement, and ultimately people’s living standards. </p><p>And the induced demand objection fails on four scores:</p><ul><li><p>It is empirically false, at least most of the time. </p></li><li><p>Accepting its logic would counsel against <em>all</em> efforts to improve quality of life.</p></li><li><p>If it were true, it still wouldn’t follow that new construction is bad.</p></li><li><p>It misconstrues what the YIMBY proposal is in the first place.</p></li></ul><p>As I say, I don’t really believe that people believing in the induced demand argument explains any of the proximate barriers to housing reform. But it does come up a lot online, so I’d like to have a resource for explaining to people what’s wrong with it.</p><h4>The induced demand intuition</h4><p>The WMATA Green Line was extended to Columbia Heights in 1999, which meant that by 2003 a young person such as myself looking for a cheap place to live in a walkable neighborhood with good access to mass transit might pick it blindly off Google Maps and Craigslist as a good place to rent a basement apartment. </p><p>It was actually a fairly dismal neighborhood at the time, largely because the immediate vicinity of the metro station was a bunch of unsightly vacant lots and construction sites. But if you went to the no-longer-extant Columbia Heights Coffee Shop, all the talk among the gentrifiers was “there’s going to be a Target soon.” And, indeed, a few years later the construction sites were transformed into apartment buildings and retail, so if you go today, the immediate environs of the Metro station feature a Giant, a Target, a Best Buy, a Wawa, a Starbucks, and a bunch of other national chains along with some locally owned businesses. Then the slightly less proximate commercial areas either north on 14th Street or over on 11th Street are thriving ecologies of local businesses.     </p><p>There is clearly some kind of flywheel effect whereby the new retail amenities make the neighborhood a better place to live, which attracts more (and more affluent) residents, which in turn makes it a more attractive place to locate your business. </p><p>Now I think it’s obvious that the start of the Columbia Heights flywheel was the opening of the Green Line, especially given the largest context of falling urban crime during this period. The reason you could find white people in a coffee shop talking about how they were looking forward to the Target opening is that the gentrification cycle was already underway. Neighborhoods normally experience an initial hipster phase of gentrification (typified by dive bars, yoga studios, and independent coffee shops) <em>before</em> the major real estate developments and national chains arrive. </p><p>But we can argue intuitions all day — the real question is research.</p><h4>Empirically, more supply lowers prices</h4><p>Back when I wrote <em>The Rent Is Too Damn High</em>, I said that the impact of new development on hyper-local prices was theoretically ambiguous and the important thing was to look at city-wide effects that are not. </p><p>Fortunately, the past few years have seen a good amount of empirical work on this question. And it turns out that in most cases studied, new units reduce prices even on a very local scale. </p><ul><li><p><a href="https://www.dropbox.com/s/oplls6utgf7z6ih/Pennington_JMP.pdf?dl=0">Kate Pennington</a>’s recent study of San Francisco is very precise: “I find that rents fall by 2% for parcels within 100m of new construction. Renters’ risk of being displaced to a lower-income neighborhood falls by 17%. Both effects decay linearly to zero within 1.5km.”</p></li><li><p><a href="https://docs.wixstatic.com/ugd/7fc2bf_ee1737c3c9d4468881bf1434814a6f8f.pdf">Xiaodi Li</a> looked at New York: “For every 10% increase in the housing stock, rents decrease 1% and sales prices also decrease within 500 feet.”</p></li><li><p><a href="https://noahpinion.substack.com/p/the-left-nimby-canon">Brian Asquith, Evan Mast, and Davin Reed</a> look specifically at new market-rate housing in low-income neighborhoods in eleven cities and find: “New buildings decrease nearby rents by 5 to 7 percent relative to locations slightly farther away or developed later, and they increase in-migration from low-income areas.”</p></li></ul><p>There are some more studies along these lines, but I don’t want to inundate you with them because I do agree that the impact is theoretically ambiguous and someday, someone, somewhere will find the opposite result. </p><p>It is striking, though, that induced demand theory doesn’t yet have its Card &amp; Kruger paper that changed the game on the minimum wage. There is no Arin Dube of induced demand theory who’s published a series of rigorous empirical papers demonstrating that there’s something weird in this market. Instead you get this from Chew:</p><blockquote><p>Studies show that market-rate housing development is linked to the mass displacement of neighboring low-income residents (Davidson and Lees&nbsp;<a href="http://journals.sagepub.com/doi/10.1068/a3739">2005</a>,&nbsp;<a href="https://wordpress.clarku.edu/mdavidson/files/2012/02/Davidson-Lees-2010-New-Build-Gentrification.pdf">2010</a>; Pearsall&nbsp;<a href="http://journals.sagepub.com/doi/pdf/10.1068/c08126">2010</a>). Such displacement occurs even when low-income housing is not directly demolished and destroyed to make way for new development—because it operates through indirect and exclusionary means, such as “price shadowing” (Davidson and Lees&nbsp;<a href="http://journals.sagepub.com/doi/10.1068/a3739">2005</a>,&nbsp;<a href="https://wordpress.clarku.edu/mdavidson/files/2012/02/Davidson-Lees-2010-New-Build-Gentrification.pdf">2010</a>). Market-rate housing production causes significant price impacts in surrounding neighborhoods, raising area rents and real estate taxes (Oliva&nbsp;<a href="https://drum.lib.umd.edu/bitstream/handle/1903/4205/umi-umd-4016.pdf;sequence=1">2006</a>; Pearsall&nbsp;<a href="http://journals.sagepub.com/doi/pdf/10.1068/c08126">2010</a>; Zuk and Chapple&nbsp;<a href="http://www.urbandisplacement.org/sites/default/files/images/udp_research_brief_052316.pdf">2016</a>).&nbsp;</p></blockquote><p>So I checked the links.</p><p>The two Davidson and Lees papers are concerned with a definitional question in urban geography. According to them, the traditional meaning of gentrification in the literature is something like “rich people move into old homes and renovate them.” They argue that we should extend the definition to include things like new mixed-use housing and retail developments in underused industrial spaces. They <em>assert</em> but do not demonstrate that “price shadowing” occurs in these cases, and then argue that this sort of phenomenon ought to count as gentrification.</p><p><a href="https://www.urbandisplacement.org/sites/default/files/images/udp_research_brief_052316.pdf">Zuk and Chapple</a> actually say: “At the regional level, both market-rate and subsidized housing reduce displacement pressures, but subsidized housing has over double the impact of market-rate units.”</p><p>Pearsall says that cleaning up brownfields raises prices in nearby Census tracts, which is interesting and raises the question of whether “make people live near toxic waste” is really the affordable housing strategy we want. </p><p>Last we get to Oliva, who at last actually finds induced demand. He looks at the Inner Harbor project in Baltimore which transformed a largely derelict stretch of waterfront into a tourist attraction featuring a convention center, an amazing aquarium, a cool park, and a bunch of hotels and restaurants. Note that in this case promoting economic development was the intended goal of the initiative (Baltimore is poor) and the point of his study is that it was a limited success story — home values did rise, but “this impact has been far more pronounced on the prices of properties located within a short distance from the water even decades after the initial projects on the waterfront were started.”</p><p>This is all good empirical work. But note that I don’t think anyone has ever argued that building an aquarium will reduce housing cost burdens. The Inner Harbor is (by design) a tourist attraction. A couple of weeks ago, I took my kid to the Maryland Zoo in Baltimore, then we drove down to the Inner Harbor, got some takeout from Shake Shack, walked around waterfront, and bought a couple of bottles of water somewhere. This is what a successful tourist attraction is supposed to accomplish — you bring in retail dollars and tax revenue. We’ll come back post-pandemic and see the aquarium. It’s a nice place to visit. And Oliva shows that if you build a nice place to visit in the middle of a city, then the immediately adjacent homes become more desirable. Similarly, per Pearsall, if you clean up a brownfield the adjacent homes become more desirable.</p><p>New infill housing appears to empirically neutralize the induced demand by simultaneously inducing supply. But conceptually there’s a question here — is it bad to make neighborhoods better places to live? </p><h4>Better neighborhoods are better</h4><p>Here’s the problem. Consider the following argument:</p><ol><li><p>Constructing new buildings will bring new retail amenities to the neighborhood.</p></li><li><p>New amenities will make the neighborhood a more attractive place to live.</p></li><li><p>Because the neighborhood is now more attractive, prices will rise.</p></li><li><p>Rising prices will displace some existing residents.</p></li><li><p>Therefore we shouldn’t allow new buildings to be constructed.</p></li></ol><p>In place of (1) you could put all kinds of things:</p><ul><li><p>Constructing a new park</p></li><li><p>Reducing the crime rate</p></li><li><p>Renovating the local high school</p></li><li><p>Improving bus service to downtown</p></li><li><p>Fixing the potholes</p></li></ul><p>In other words, you could imagine this kind of logic becoming an infinite cycle of bad urban policy. Defund police will lead to more murders? Well, that’s good for housing affordability. …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.slowboring.com/p/induced-demand">https://www.slowboring.com/p/induced-demand</a></em></p>]]>
            </description>
            <link>https://www.slowboring.com/p/induced-demand</link>
            <guid isPermaLink="false">hacker-news-small-sites-25996426</guid>
            <pubDate>Tue, 02 Feb 2021 01:19:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: View on mobile 2.0 – View any website mobile version from desktop]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25996246">thread link</a>) | @azabraao
<br/>
February 1, 2021 | https://azabraao.me/view-on-mobile | <a href="https://web.archive.org/web/*/https://azabraao.me/view-on-mobile">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://azabraao.me/view-on-mobile</link>
            <guid isPermaLink="false">hacker-news-small-sites-25996246</guid>
            <pubDate>Tue, 02 Feb 2021 00:56:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[So, is Signal good or bad?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25995819">thread link</a>) | @type0
<br/>
February 1, 2021 | https://current.workingdirectory.net/posts/2021/signal/ | <a href="https://web.archive.org/web/*/https://current.workingdirectory.net/posts/2021/signal/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">







<div id="pagebody">

<div id="content" role="main">
<p>After <a href="https://arstechnica.com/tech-policy/2021/01/whatsapp-users-must-share-their-data-with-facebook-or-stop-using-the-app/">Facebook updated their Whatsapp privacy
policy</a>,
and a certain rich capitalist who doesn't like Facebook for reasons different
then mine told the world to use Signal, Signal's downloads <a href="https://www.businessinsider.com/whatsapp-facebook-data-signal-download-telegram-encrypted-messaging-2021-1?op=1">went up by
4,200%</a>.</p>

<p>As often happens when something becomes popular, the criticisms start to fly!</p>

<p>For the record, I currently think promoting <a href="https://signal.org/">Signal</a> is
an important tactical strategy for the left. [I also think we should promote
and install federated chat apps like <a href="https://conversations.im/">conversations</a>
and <a href="https://element.io/">element</a> and <a href="https://delta.chat/en/">delta chat</a>
whereever it is possible.]</p>

<p>Here are some of the main criticisms I hear that I think are a distraction:</p>

<ul>
<li><p><strong>Signal forces you to use the Google Play store and Google Services</strong>: This
isn't true any more. You can download <a href="https://signal.org/android/apk/">the apk
directly</a> on a phone without any Google
services and it works great. The app will alert you to new versions.</p>

<p>Don't get me wrong: the Signal network still depends on Google services.
And, we <em>should</em> be avoiding corporate technology and building our own
infrastructure. However, in practice, Signal is an alternative to Whatsapp
and Telegram - which not only use the same corporate services but are
proprietary technology that is fully owned by powerful tech giants. Signal
is still a non-profit organization with a vastly different mission.</p></li>
<li><p><strong>Signal's approach to privacy isn't perfect</strong> (the most common variation on
this theme is that a state actor could monitor your outgoing communications
and the incoming communications of the person you are communicating with and
prove that you are communicating with each other).</p>

<p>This criticism missed what makes Signal so important. The beauty of Signal
is that it addresses the "woops!" moment most privacy activists had when
Snowden's data trove become public: it provides <em>mass</em> privacy to stop
<em>mass</em> surveillance. Prior to 2013, most tech/privacy activists were focused
on the "targeted" individual approach to privacy, working hard to make sure
our tools were as absolutely perfect as possible for the tiny percentage of
people who know they are under surveillance. Very little effort went into
getting them adopted on a mass scale.</p>

<p>Criticizing Signal for not providing perfect privacy misses that fact that
these things often are trade offs.</p>

<p>This trade-off also applies to the first point - dependency on Google
services makes installation far easier for suporting millions of people.</p></li>
</ul>


<p>Here are some criticisms that I think are nuanced:</p>

<ul>
<li><p><strong>Signal is a centralized app</strong>: this criticism often includes examples of
Moxie (Signal's founder) refusing and actively discouraging attempts by
others to write software that interacts with Signal.</p>

<p>Signal is free software, which is a major improvement over most corporate
technology. But since it's entirely controlled by one entity, it can be
shutdown in a heart beat. And, if Signal changes direction, we cannot easily
take the work we have all invested in learning signal and create our own
version that reflects our values.</p>

<p>This problem is in contrast to federated systems like email - where anyone
can run their own email server and apply their own policies. If one email
serveer is shutdown, you can move to another.</p>

<p>I agree with this critique, but I think it's nuanced because of the trade
offs. Having full control over the entire network and all the software
provides a level of reliability and consistency that would not be possible
with a federated protocol. And, we already have three different, fully
viable federated chat protocols (see above). I'd rather have Signal be
Signal and invest our energy on a federated chat system via the existing,
well-developed alternatives.</p>

<p>This opinion is tactical - and could change at any moment. I think there
will come a time when we are going to tell the world to move from Signal to
the best available federated protocol. But I'm not convinced we have a
robust enough federated chat infrastructure to support that move.</p></li>
<li><p><strong>Signal forces you to use your phone number as an identifier</strong>: You can't
get a Signal account without a phone number. And you generally can't get a
phone number without revealing some aspect of your identity. That makes
staying anoymous very difficult. There are reports of a new Signal feature
making it possible to avoid revealing your phone number when communicating
with others, but you would still need a phone number to get an account
because a SMS or phone call confirmation is required.</p></li>
<li><p><strong>Signal isn't getting ahead of the curve on abuse</strong>: There's an interesting
<a href="https://www.platformer.news/p/-the-battle-inside-signal">piece informed by former Signal staff
people</a> about the
management's resistance to getting ahead of the curve when it comes to
abuse. How would signal respond to reports of harrassment? What would signal
do if it recognized facsists movements organizing on its platform? Any mass
platform that is not planning for abuse is going to be in big trouble very
soon.</p></li>
</ul>


<p>These last two are not exactly two sides of the same coin, but they are
related. How Signal manages to balance privacy and protection from abuse will
be the real test as to whether promoting Signal continues to be a useful
strategy for the left.</p>

</div>









</div>



</div></div>]]>
            </description>
            <link>https://current.workingdirectory.net/posts/2021/signal/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25995819</guid>
            <pubDate>Mon, 01 Feb 2021 23:56:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Conventions of Safety (2019)]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25995786">thread link</a>) | @luu
<br/>
February 1, 2021 | https://ceri.storey.name/posts/2019-08-18-unconventional-safety.html | <a href="https://web.archive.org/web/*/https://ceri.storey.name/posts/2019-08-18-unconventional-safety.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <p>Thanks to some discussions in my team recently, I’ve been thinking recently about how design conventions can help or harm safety.<!--more--> One place this comes up is in application layout, and what kinds of behaviour we put where.</p>
<p>To my mind, the biggest value in having conventions around service layout is to lower the cost of change. Let’s say we have a component that listens for events from others. In that case, you might have a habit of putting those listeners into a file named <code>listener.rs</code>. If this becomes a habit, you will know to look at the listener file, instead of needing to search for it.</p>
<p>When we write a service then change it rarely afterwards, this habit can be very useful. If you are unfamiliar with a section of the codebase, these kinds of <em>affordances</em> can make life easier. This results in less time sifting through code, and so makes it easier to change.</p>
<p>Another way to lower the cost of change is to have clear roles for each module within it. (And these roles themselves can follow clear patterns). Even then, these roles serve to hide some detail from the rest of the system.</p>
<p>A good interface means that a caller can express intent clearly, and let someone else worry about the details. For example, a database library lets you can pose <em>queries</em> and get results back. Without it, you’d need to know exactly how to turn your application’s data into something the database understands, and vica versa.</p>
<p>A good interface should also make clear what it needs. Let’s say some people in an office want to number documents. We can keep a logbook with the last number used. We can read the previous value we gave out, write down the next number, and use that for our document.</p>
<p>If lots of people want to number documents at the same time, then we encounter a problem. What if two people read then write the same numbers, and have the same number for their documents? People shouldn’t make this mistake, as they’ll notice that someone else is holding the book, and won’t race to write in it before the other has finished. Some people describe this as “common sense”.</p>
<p>Computers don’t have common sense. This is why we need to spell everything out to them in exacting detail. If they have read the last document number, they won’t know to check no-one else has changed it when they write down the new number, either.</p>
<p>So, in a distributed system we can use a centralised lock service to solve this problem. With this, the computer will take the lock, update the number and release the lock. Even then, if the new number routine does not know anything about the lock mechanism, it’s still possible to make the same mistake. A programmer might forget that they need to take the lock to call the new number routine, for example.</p>
<p>So, we have ways to solve this. One is we make the new number routine manage the lock itself. This is fine as long as it controls everything itself, but once we have other routines that use locks involved, then things get more complicated. This is okay if the lock for the new number is only for that new number. But if we share it with other routines, we risk problems like deadlocks.</p>
<p>Another solution is to inform the new number routine that we hold the lock, and have the routine fail if we do not. For example, the lock server may provide a <a href="https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html">token</a> the routine can verify. .</p>
<p>The logical conclusion to this is in the rust standard library. The <code>Mutex&lt;T&gt;</code> type holds a value of some type T, and will only permit access via a guard that guarantees we hold the lock.</p>
<p>A big part of designing safe systems is understanding how things go right over the long term. A big part of this is to ensure that it’s easy to do the safe thing, and difficult to do something unsafe.</p>
<p>The example of numbering documents is quite a low stakes task. In a bank though, we need to number payment cards, so we know whose account to charge. Having two cards with the same card number may mean one person can spend another’s money. This is bad for the customer, and leaves the bank liable for the mistake.</p>
<p>Now, these may seem like mistakes that are simple to avoid, but in complex systems, <a href="https://how.complexsystems.fail/">things go wrong all the time</a>. So it’s wise to design assuming that mistakes will happen, both from machines and people. For example, a tired, or rushed developer may not know to hold a lock while calling the new number routine. Having the routine fail in that case will mean that at they discover their mistake quickly.</p>
<p>So we should design our components and interfaces to be safe, and error resistant. And precisely because conventions can be so powerful, we should design them to encourage safe ways of working.</p>
</article></div>]]>
            </description>
            <link>https://ceri.storey.name/posts/2019-08-18-unconventional-safety.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25995786</guid>
            <pubDate>Mon, 01 Feb 2021 23:53:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Can the PinePhone replace your Android or iOS device?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25995418">thread link</a>) | @viktork11
<br/>
February 1, 2021 | https://techscoop.xyz/2021/02/01/can-the-pinephone-replace-your-android-or-ios-device/ | <a href="https://web.archive.org/web/*/https://techscoop.xyz/2021/02/01/can-the-pinephone-replace-your-android-or-ios-device/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			
<p>One of the most anticipated Linux phones of 2020 is finally available, after months of waiting and anticipation the PinePhone is now available to purchase. Well, sort of… Ok, so its the <a href="https://pine64.com/product/pinephone-community-edition-mobian-limited-edition-linux-smartphone/?v=0446c16e2e66">community edition </a>on pre-order and it won’t ship until Feb but that’s progress. Right?</p>



<p>The new PinePhone is a Linux phone for the developer community, it’s affordable and comes from the guys over at Pine64 who brought us the <a href="https://www.pine64.org/pinebook-pro/">Pinebook Pro</a> laptop. Its open-source and is supported by a vast majority of Linux phone projects.</p>



<p>It’s encouraging to finally see an alternative to Android for fellow Linux partisans who rightly want to have ultimate control over their mobile phone. Let’s be honest here, its a budget phone at heart and it does come with some limitations but the concept of the PinePhone is intriguing.</p>



<p>If you’re a Linux diehard, a security practitioner or just like many others, you’re looking for something more than Android and IOS this may be the handset for you.</p>



<p>The phone comes with the Quad-Core ARM Cortex A53 64-Bit SOC which is standard on the Pine A64 Single Board Computer. Running <a href="https://mobian-project.org/">Mobian</a> Linux with 2GB of LPDDR3 RAM and retails at $149.</p>



<figure><img loading="lazy" src="https://techscoop.xyz/wp-content/uploads/2021/02/Mobian600-1.png" data-src="https://techscoop.xyz/wp-content/uploads/2021/02/Mobian600-1.png" alt="PinePhone" width="600" height="600" data-srcset="https://techscoop.xyz/wp-content/uploads/2021/02/Mobian600-1.png 600w, https://techscoop.xyz/wp-content/uploads/2021/02/Mobian600-1-300x300.png 300w, https://techscoop.xyz/wp-content/uploads/2021/02/Mobian600-1-150x150.png 150w" data-sizes="(max-width: 600px) 100vw, 600px" srcset="https://techscoop.xyz/wp-content/uploads/2021/02/Mobian600-1.png 600w, https://techscoop.xyz/wp-content/uploads/2021/02/Mobian600-1-300x300.png 300w, https://techscoop.xyz/wp-content/uploads/2021/02/Mobian600-1-150x150.png 150w"><figcaption>PinePhone</figcaption></figure>



<h2>SPECIFICATIONS</h2>



<ul><li>Allwinner A64 Quad Core SoC with Mali 400 MP2 GPU</li><li>2GB of LPDDR3 RAM</li><li>5.95″ LCD 1440×720, 18:9 aspect ratio (hardened glass)</li><li>Bootable Micro SD</li><li>16GB eMMC</li><li>HD Digital Video Out</li><li>USB Type C (Power, Data and Video Out)</li><li>Quectel EG-25G with worldwide bands</li><li>WiFi: 802.11 b/g/n, single-band, hotspot capable</li><li>Bluetooth: 4.0, A2DP</li><li>GNSS: GPS, GPS-A, GLONASS</li><li>Vibrator</li><li>RGB status LED</li><li>Selfie and Main camera (2/5Mpx respectively)</li><li>Main Camera: Single OV6540, 5MP, 1/4″, LED Flash</li><li>Selfie Camera: Single GC2035, 2MP, f/2.8, 1/5″</li><li>Sensors: accelerator, gyro, proximity, compass, ambient light</li><li>3 External Switches: up down and power</li><li>HW switches: LTE/GNSS, WiFi, Microphone, Speaker, Cameras&nbsp;</li><li>Samsung J7 form-factor 3000mAh battery</li><li>Case is matte black finished plastic</li><li>Headphone Jack</li></ul>



<p>The aim of the new PinePhone is to help create a market for a device like this where a functional affordable Linux phone can support existing projects for end-users, while also helping developers work together to drive support for the community-driven device.</p>



<p>The PinePhone isn’t trying to be the next flagship phone, its objectives are clear, it wants to be a reliable, customisable alternative to mainstream Android and IOS. We have to acknowledge that this phone is aimed at Linux Partisans and Dev’s specifically and isn’t suited to technophobes and users who fear the unknown. If you like the thought of physical kill switches and privacy toggles this may be your time to shine.</p>



<h2>Tech Specifications</h2>



<figure><table><tbody><tr><td>BODY</td><td>Dimensions: 160.5mm x 76.6mm x 9.2mm<br>Weight: 185 grams<br>Build: Plastic with Mobian logo<br>Colour: Black<br>SIM: Micro-SIM</td></tr><tr><td>Display</td><td>Type: HD IPS capacitive touchscreen, 16M colors<br>Size: 5.95 inches<br>Resolution: 1440×720 pixels, 18:9 ratio</td></tr><tr><td>PLATFORM</td><td>OS: Mobian OS build<br>Chipset: Allwinner A64<br>CPU: 64-bit Quad-core 1.2 GHz ARM Cortex A-53<br>GPU: MALI-400MP2</td></tr><tr><td>MEMORY</td><td>Internal Flash Memory: 16GB eMMC<br>System Memory: 2GB LPDDR3 SDRAM<br>Expansion: micro SD Card support SDHC and SDXC, up to 2TB</td></tr><tr><td>CAMERA</td><td>Main Camera: Single 5MP, 1/4″, LED Flash<br>Selfie Camera: Single 2MP, f/2.8, 1/5″</td></tr><tr><td>SOUND</td><td>Loudspeaker: Yes, mono<br>3.5mm jack with mic: Yes, stereo</td></tr><tr><td>COMMUNICATION</td><td>Worldwide, Global LTE bands<br>LTE-FDD: B1/ B2/ B3/ B4/ B5/ B7/ B8/ B12/ B13/ B18/ B19/ B20/ B25/ B26/ B28<br>LTE-TDD: B38/ B39/ B40/ B41<br>WCDMA: B1/ B2/ B4/ B5/ B6/ B8/ B19<br>GSM: 850/900/1800/1900MHz<br>WLAN: Wi-Fi 802.11 b/g/n, single-band, hotspot<br>Bluetooth: 4.0, A2DP<br>GPS: Yes, with A-GPS, GLONASS</td></tr><tr><td>FEATURES</td><td>USB: type C, USB Host, DisplayPort Alternate Mode output<br>Sensors: Accelerometer, gyro, proximity, ambient light, magnetometer(compass)<br>Actuator: Vibrator<br>Privacy Switches: LTE (include GPS), Wifi/BT, Mic, and Camera</td></tr><tr><td>BATTERY</td><td>Removable Li-Po 2750-3000 mAh battery<br>Charging: USB type-C, 15W – 5V 3A Quick Charge, follows USB PD specification</td></tr></tbody></table></figure>



<h2>Who is Pine64</h2>



<p>Pine64 have been selling ARM Linux devices since 2015, they started out originally with Single Board Computers such as the <a href="https://www.pine64.org/devices/single-board-computers/pine-a64/">Pine A64</a>. Much similar to the Well known Raspberry Pi but have now expanded into many other product areas. The guys over at Pine64 sell Laptops, Smartwatches and even Tablets and Server Clusters.</p>



<figure><img loading="lazy" width="600" height="600" src="https://techscoop.xyz/wp-content/uploads/2021/02/Pinebook_Pro-photo-1-2.png" data-src="https://techscoop.xyz/wp-content/uploads/2021/02/Pinebook_Pro-photo-1-2.png" alt="" data-srcset="https://techscoop.xyz/wp-content/uploads/2021/02/Pinebook_Pro-photo-1-2.png 600w, https://techscoop.xyz/wp-content/uploads/2021/02/Pinebook_Pro-photo-1-2-300x300.png 300w, https://techscoop.xyz/wp-content/uploads/2021/02/Pinebook_Pro-photo-1-2-150x150.png 150w" data-sizes="(max-width: 600px) 100vw, 600px" srcset="https://techscoop.xyz/wp-content/uploads/2021/02/Pinebook_Pro-photo-1-2.png 600w, https://techscoop.xyz/wp-content/uploads/2021/02/Pinebook_Pro-photo-1-2-300x300.png 300w, https://techscoop.xyz/wp-content/uploads/2021/02/Pinebook_Pro-photo-1-2-150x150.png 150w"></figure>



<h2>PinePhone Editions</h2>



<p>The PinePhone has gone through multiple prototypes before the first public release. BraveHeart began shipping in Jan 2020 and since then we now have the new community edition.</p>



<p>BraveHeart was the first PinePhone to go on sale early Nov 2019 and was sold without an OS installed, it was available direct from the Pine64 website and It sold out in days! The BraveHeart handsets were shipped to early adopters in Jan 2020.</p>



<p>There are some slight differences between BraveHeart and the later models, notably the inability for BraveHeart to connect to external monitors via USB Type-C. Laters models can do this so it’s worth doing your research before purchasing.</p>



<p>Community Editions, the successor the BraveHeart.</p>



<p>The PinePhone Ubports Community Edition was the first handset in the community lineup. It went on sale in May 2020 and came with pre-loaded Ubuntu Touch. This handset had minor hardware revisions and sold out almost instantly.</p>



<p>The second community edition was shipped with PostmarketOS and It went on sale in July 2020. This was the first PinePhone to support video over USB Type-C.</p>



<p>September provided us with a<a href="https://www.omgubuntu.co.uk/2020/08/pinephone-manjaro-community-edition"> </a>Manjaro edition handset, followed by a Plasma Mobile device in December 2020.</p>



<p>All units to date have been similar in style and design.</p>



<h2>Linux Support</h2>



<p>As of writing, there are <a href="https://wiki.pine64.org/index.php?title=PinePhone_Software_Releases">18 operating systems</a> available for the PinePhone. Bear in mind the OS’s are in various stages of the development lifecycle. Many have been written from the ground up for the mobile community such as Ubuntu Touch and Sailfish. A lot of the others are from existing desktop Linux distributions.</p>



<ul id="block-e4f6503d-217f-4c38-80f5-47d13aab6e12"><li>Arch Linux ARM</li><li>Fedora</li><li>Gentoo</li><li>GloDroid</li><li>KDE Neon</li><li>LuneOS</li><li>Maemo Leste</li><li>Manjaro ARM</li><li>Mobian</li><li>Nemo Mobile</li><li>NixOS</li><li>OpenMandriva Lx</li><li>openSUSE</li><li>postmarketOS</li><li>SailfishOS</li><li>SkiffOS</li><li>Sxmo</li><li>Ubuntu Touch</li></ul>



<h2>Where can I buy a PinePhone?</h2>



<p>You can buy a Pinephone&nbsp; Community Edition from the <a href="https://pine64.com/product-category/pinephone/">Pine64 Store</a>. </p>



<p>Note, Community Limited Edition PinePhones are aimed solely for developer and early adopter. More specifically, only intend for these units to find their way into the hands of users with extensive Linux experience.</p>



<h2>PinePhone Summary</h2>



<p>My favourite distro is <a href="https://wiki.mobian-project.org/doku.php?id=intro">Mobian</a> and the desire we have for the success of PinePhone isn’t because its cheap, it’s because is built for a multitude of community-driven OS’s on a secure device that has a real chance to deliver mobile Linux to the community. </p>



<p>Like you, I want an open source mobile phone. But my concerns are that it will only truly stake its market share once there’s a semi polished platform like that of Android.&nbsp;</p>



<p>Linux has so much to offer to the mobile market and challenging the likes of apple and android can only be a good thing.&nbsp;</p>



<p>It’s commendable what Pine64 are trying to achieve, deliver the hardware that mobile distros can develop upon.&nbsp;</p>



<p>But until the PinePhone is more polished and has a fully functioning operating and echo system I worry people will struggle using it as a daily device.&nbsp;</p>



<p>Its early days so be ready for quirks and rough finishes, its not flash and polished yet. </p>



<p>But remember, that’s not why you bought this device. You bought it because like me you found it exciting to be part of something that isn’t mainstream. To hopefully one day free people from the grasp of Android and IOS and deliver them into the tender loving arms of Linux.</p>
		</div></div>]]>
            </description>
            <link>https://techscoop.xyz/2021/02/01/can-the-pinephone-replace-your-android-or-ios-device/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25995418</guid>
            <pubDate>Mon, 01 Feb 2021 23:11:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How we reduced our AI labeling cost by 10x]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25995293">thread link</a>) | @antimatter15
<br/>
February 1, 2021 | https://cresta.com/blog/how-we-reduced-our-labeling-cost-by-10x | <a href="https://web.archive.org/web/*/https://cresta.com/blog/how-we-reduced-our-labeling-cost-by-10x">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>At Cresta, we are democratizing expertise for sales and support teams by making every agent an expert. <a href="https://www.cresta.ai/blog/software-that-learns">To distill such expertise into software</a>, we ask top agents to demonstrate, and in turn, help us label best practices. Machine Learning models are then trained for customers to maximize their KPIs. Our models continuously learn what top agents do differently and scale those behaviors across entire teams.</p>
<p>Apart from providing goal-directed suggestions during ongoing live chats which we talked about in our recent <a href="https://cresta.com/blog/action-directed-gpt-2">Action Directed GPT-2 blogpost</a>, another unique feature that Cresta offers is real-time coaching assist. As shown below, Cresta provides personalized coaching at key moments in a live chat, to inculcate the required behaviors for every agent to perform like a top agent.</p>
</div><div><p>The Real-time Coaching and Agent Assist features mentioned above are powered by our Natural Language Understanding (NLU) pipeline, which is responsible for producing models that help us understand and track the state of the conversation as a chat progresses between an agent and a visitor. The 2 most common tasks which our NLU pipeline solves for, are:</p>
<ol>
<li><strong>Intent Classification</strong>: detecting the intent behind each message from both agent and visitor</li>
<li><strong>Chat Driver Classification</strong>: detecting and tracking the main objective behind the visitor reaching out</li>
</ol>
<p>In 2019, as our customer base started to rapidly grow, one of the biggest challenges we faced was the time and effort required to label data required by our NLU Classification pipeline. To scale as a software company, we strive to maximize our speed of developing and iterating on the required models. In this blog post, we share how our classification pipeline evolved over time and how we reduced our labeling cost and efforts by over 10x, while continuously pushing our accuracy benchmarks forward.</p>
<h2>Deep Transfer Learning</h2>
<p>As was the case for most NLP pipelines across the world in 2019, the first big jump in efficiency came with the introduction of Deep Transfer Learning. Transfer learning, in the form of pre-trained language models, has revolutionized the field of NLP, leading to state-of-the-art results on a wide range of tasks. The idea is to first pre-train a model on a large unlabeled dataset using a language modeling objective, and then fine-tune it on a smaller labeled dataset using a supervised task of choice.</p>
<figure id="attachment_19481" aria-describedby="caption-attachment-19481"><a href="https://cresta.com/static/49c936488d40a0a581c63e208c03b817/DeepTransferLearning.svg"><img loading="lazy" src="https://d33wubrfki0l68.cloudfront.net/7dc3d3fbd8815267d9bc196690d81f500c864251/30a8b/static/49c936488d40a0a581c63e208c03b817/deeptransferlearning.svg" alt="deep-transfer-learning" width="1175" height="623"></a><figcaption id="caption-attachment-19481">A loose analogy depicting Deep Transfer Learning with large pre-trained language models</figcaption></figure>
<p>Many practical applications of NLP occur in scenarios where there is a scarcity of labeled data. This is where fine-tuning large pre-trained language models has changed the game completely. These models have shown to be <a href="https://arxiv.org/pdf/1801.06146.pdf" target="_blank" rel="noopener noreferrer" data-token-index="4" data-reactroot="">extremely sample-efficient</a>, capable of achieving good performance on many tasks with only a few hundred labeled samples.</p>
<p>At the start of 2019, with <a href="https://arxiv.org/pdf/1806.08730.pdf" target="_blank" rel="noopener noreferrer" data-token-index="1" data-reactroot="">multi-task learning in NLP</a> increasingly showing <a href="https://www.aclweb.org/anthology/P19-1441.pdf" target="_blank" rel="noopener noreferrer" data-token-index="3" data-reactroot="">great empirical results</a>, we deployed a multi-headed <a href="https://arxiv.org/pdf/1810.04805.pdf" target="_blank" rel="noopener noreferrer" data-token-index="6" data-reactroot="">BERT</a> for all the different tasks in our classification pipeline. As shown in the image below, this enabled us to train all of them together with a shared BERT encoder, maximizing each head’s learning from all the available labeled data. As a result, the final outcome was us reducing the number of labeled samples required per customer while pushing our accuracy benchmarks to previously uncharted regions.</p>
<figure id="attachment_19595" aria-describedby="caption-attachment-19595"><a href="https://cresta.com/static/c32940d6d127c78f2ee15def9fd31c19/MultiTaskModel.svg"><img loading="lazy" src="https://d33wubrfki0l68.cloudfront.net/b06d84f31cd820198db7a8d7d60ec129bdc5da02/572c8/static/c32940d6d127c78f2ee15def9fd31c19/multitaskmodel.svg" alt="MultiTaskModel" width="650" height="544"></a><figcaption id="caption-attachment-19595">Multi-head BERT for multiple NLU classification tasks</figcaption></figure>
<h2>One-vs-all Classification</h2>
<p>Buoyed by the success of the multi-head architecture, we turned our attention to a problem which was proving to be a costly step in our labeling process: handling a <span data-token-index="2" data-reactroot="">growing Label Taxonomy</span>.</p>
<p>For a model to track the state of a conversation using the classifiers described above, not all messages necessarily belong to a class of interest. As depicted in the image below, this meant that the multi-class classifiers which were deployed had a “None” class, to account for any messages that didn’t fall under the existing set of classes of interest. Instead of starting with a minimal set and then iteratively making data-driven additions to the taxonomy for each customer, this multi-class classification problem formulation forced us to spend considerable time upfront determining the granularity and details of the required taxonomy, and carefully defining what constitutes the “None” class – else otherwise, any future iterations on the taxonomy meant re-visiting all the labeled samples under a large “None” class and updating labels as required.</p>
<p>In short, our workflow was highly resistant to any taxonomy changes, which invariably happened as we entered new verticals and iterated with new customers, causing a lot of re-labeling and label quality issues.</p>
<figure id="attachment_19489" aria-describedby="caption-attachment-19489"><a href="https://cresta.com/static/8f33f77cd519328648e22cd7418828c9/Taxonomy.svg"><img loading="lazy" src="https://d33wubrfki0l68.cloudfront.net/ed4f6e9d53dbdc39bfed1638dfa522c57d508b23/39870/static/8f33f77cd519328648e22cd7418828c9/taxonomy.svg" alt="taxonomy" width="1086" height="1107"></a><figcaption id="caption-attachment-19489">“None” class allowing an agent intent classifier to abstain from messages of no interest</figcaption></figure>
<p>To address the above challenge of iterating on a growing label taxonomy, we converted the multi-class classification problem to a <a href="https://www.jmlr.org/papers/volume5/rifkin04a/rifkin04a.pdf" target="_blank" rel="noopener noreferrer" data-token-index="3" data-reactroot="">one-vs-all</a> classification problem using a multi-head architecture. As shown in the image below, each head acted as a binary classifier (True/False) for one of the classes, and a False from all the heads implied the “None” class.</p>
<figure id="attachment_19597" aria-describedby="caption-attachment-19597"><a href="https://cresta.com/static/5f384297bcae22f0b5ff76b621e92618/OneVsAllModel.svg"><img loading="lazy" src="https://d33wubrfki0l68.cloudfront.net/21af77eae2ce7cf1246837df83aa1cf7a2641935/a37a0/static/5f384297bcae22f0b5ff76b621e92618/onevsallmodel.svg" alt="OneVsAllModel" width="650" height="555"></a><figcaption id="caption-attachment-19597">Multi-head BERT for One-vs-all Intent Classification</figcaption></figure>
<p>The above architecture gave us the flexibility of adding more classes as we iterated on the taxonomy required to produce the experience desired by our customers, without having having to re-label our existing dataset each time. This architecture could be used both for a single-task or in a multi-task setting by simply prepending the class name with the task name to create a unique identifier for each head.</p>
<h2>Binary Labeling Interface with Loss Masking</h2>
<p>Data labeling interfaces and best practices, in general, have been an under-researched area – as was touched upon by François Chollet’s recent <a href="https://twitter.com/fchollet/status/1353422914071142400">tweet</a>, which sparked a debate amongst the research community. Our experience while trying to scale Machine Learning for business use-cases, pushed us to consider data curation and labeling as any other research problem we were looking to solve.</p>
<p>Labeling cost has 2 dimensions –&nbsp;the number of labeled samples required and the average time required to “correctly” label a sample. We realized that the effort and cost required to reach a high quality labeled dataset was often turning out to be a costly step requiring multiple quality assurance iterations. With a much more flexible one-vs-all architecture, instead of just looking for ways to reduce the number of labeled samples required by our models, we started iterating on optimizing our labeling interface with the goal of reducing the difficulty of labeling a given sample.</p>
<p>Humans usually have a small attention span, and labeling often can be a very tedious and mundane task. We A/B tested a new labeling interface where labelers would be making a single binary decision at a time, True/False for a pair of (sample, class), determining whether the sample belongs to that class or not.</p>
<figure id="attachment_19479" aria-describedby="caption-attachment-19479"><a href="https://cresta.com/static/659a310e5fce053badfc32f2150dde8e/BinaryLabelingInterface.svg"><img loading="lazy" src="https://d33wubrfki0l68.cloudfront.net/fe846b3dac1d4f4d9fae9261260cd632397cb78a/02ec0/static/659a310e5fce053badfc32f2150dde8e/binarylabelinginterface.svg" alt="binary-labeling-interface" width="650" height="753"></a><figcaption id="caption-attachment-19479">Labeler makes a binary decision and focuses on 1 class at a time with clear labeling guidelines and examples</figcaption></figure>
<p>A labeler could pick a class they wanted to focus on and the interface would present a sample to be labeled in a binary fashion, accompanied by clear labeling guidelines and examples, as shown in the image above. This interface allowed labelers to think about one class at a time, resulting in a lower cognitive load for them, while also allowing us to scale and distribute the labeling tasks more efficiently among the labelers. Our results showed that this interface resulted in ~2x faster labeling, with fewer mistakes made by the labelers.</p>
<p>Integrating the Binary Labeling Interface with our one-vs-all architecture meant we had to solve 1 problem: there was no guarantee that for a given sample, all the classes would be labeled. More explicitly, given the large amount of unlabeled data we usually work with, the design choice of labeling one class per sample meant that it was highly likely that for a given labeled sample in our training set, we would not have a supervision signal for all the heads. To address this, we implemented Loss Masking, where for a given sample we masked the loss for all the heads we didn’t have a label for. As demonstrated in the image below, for each sample, the loss is only applied to heads for which we have a label in the training batch.</p>
<figure id="attachment_19624" aria-describedby="caption-attachment-19624"><a href="https://cresta.com/static/f9db1b2a9ad8afa293ecf0eaf6356e67/LossMasking.svg"><img loading="lazy" src="https://d33wubrfki0l68.cloudfront.net/68b42654328635ee23f9cb533634466d86347fb6/1705a/static/f9db1b2a9ad8afa293ecf0eaf6356e67/lossmasking.svg" alt="LossMasking" width="1180" height="868"></a><figcaption id="caption-attachment-19624">Loss masking to handle sparse labels for different heads</figcaption></figure>
<h2>Active Learning</h2>
<p>Next, we turned our attention towards pushing the boundary around how sample-efficient Deep Transfer Learning could be, by introducing Active Learning in the pipeline. Our goal was to explore what can be achieved both in terms of accuracy and the associated labeling cost when these large pre-trained language models are used in conjunction with Active Learning techniques.</p>
<p>Similar to how humans learn, giving a model the power to interactively query a human to obtain labels at certain data points – i.e. introducing human guidance at various intervals – can dramatically improve the learning process. This is the key idea behind <a href="https://en.wikipedia.org/wiki/Active_learning_(machine_learning)" target="_blank" rel="noopener noreferrer" data-token-index="3" data-reactroot="">Active Learning</a>: that a machine learning algorithm can achieve greater accuracy with fewer training labels if it is allowed to choose the data from which it learns.</p>
<figure id="attachment_19613" aria-describedby="caption-attachment-19613"><a href="https://cresta.com/static/2123331ca4ae632e8022d3d8eb8c5b65/ActiveLearningPlot.svg"><img loading="lazy" src="https://d33wubrfki0l68.cloudfront.net/44b66a594734fd9b8905fa5fccd4e340ec8a1462/32156/static/2123331ca4ae632e8022d3d8eb8c5b65/activelearningplot.svg" alt="ActiveLearningPlot" width="1242" height="352"></a><figcaption id="caption-attachment-19613">As described in the above plot using a toy dataset, choosing the optimal data points to label can dramatically reduce the amount of labeled data the model might need (<a href="http://burrsettles.com/pub/settles.activelearning.pdf">Image credits</a>)</figcaption></figure>
<p>Active Learning is an iterative process, which can be described by the following steps</p>
<ul>
<li><strong>Step 1</strong>: Label a small set of data, instead of investing huge labeling resources and cost upfront</li>
<li><strong>Step 2</strong>: Train a model on the above and then use it to predict outputs on unlabeled data</li>
<li><strong>Step 3</strong>: From the predictions, select data points based on a sampling strategy (for example Uncertainty Sampling – which selects data points the model is most uncertain about) and label those to include in the training dataset</li>
<li><strong>Step 4</strong>: (Back to Step 2) Retrain the model with the updated dataset and repeat the rest of the steps until a satisfactory quality is achieved</li>
</ul>
<h2>Wor…</h2></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cresta.com/blog/how-we-reduced-our-labeling-cost-by-10x">https://cresta.com/blog/how-we-reduced-our-labeling-cost-by-10x</a></em></p>]]>
            </description>
            <link>https://cresta.com/blog/how-we-reduced-our-labeling-cost-by-10x</link>
            <guid isPermaLink="false">hacker-news-small-sites-25995293</guid>
            <pubDate>Mon, 01 Feb 2021 22:57:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Microsoft Security Adventures Game]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25995146">thread link</a>) | @technion
<br/>
February 1, 2021 | https://mssecurityadventure.com/game.html | <a href="https://web.archive.org/web/*/https://mssecurityadventure.com/game.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://mssecurityadventure.com/game.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25995146</guid>
            <pubDate>Mon, 01 Feb 2021 22:43:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Talking Head Anime from a Single Image via Deep Learning]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25994963">thread link</a>) | @Cixelyn
<br/>
February 1, 2021 | https://pkhungurn.github.io/talking-head-anime-2/ | <a href="https://web.archive.org/web/*/https://pkhungurn.github.io/talking-head-anime-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    	<p><span>
	      \(
	      \def\sc#1{\dosc#1\csod}
	      \def\dosc#1#2\csod{{\rm #1{\small #2}}}
	      \)
    	</span></p>
      
      <p>
      <a href="http://pkhungurn.github.io/">Pramook Khungurn</a>
      </p>
      
    </div><div>
					
		

		<p><b>Abstract.</b> I extended the <a href="https://pkhungurn.github.io/talking-head-anime/">animation-from-a-single-image neural network system I created in 2019</a> so that the characters can make more types of facial expressions. While the old system can only open/close the eyes and the mouth, this new version affords more eye/mouth shapes and can control the eyebrows and the irises. They allow a character to show various emotions and give more convincing impression of speech.</p>

		<table>
				<tbody><tr>
					<td>
						<p><img src="https://pkhungurn.github.io/talking-head-anime-2/data/characters/otogibara_era/headshot.png">	
						</p>
					</td>
					<td>
						<p><img src="https://pkhungurn.github.io/talking-head-anime-2/data/characters/otogibara_era/emotion/00000001.png">	
						</p>
					</td>
					<td>
						<p><img src="https://pkhungurn.github.io/talking-head-anime-2/data/characters/otogibara_era/emotion/00000002.png">	
						</p>
					</td>
					<td>
						<p><img src="https://pkhungurn.github.io/talking-head-anime-2/data/characters/otogibara_era/emotion/00000003.png">	
						</p>
					</td>
				</tr>
				<tr>
					<td><span size="2">Input <a href="#fn_gibara">[copyright]</a></span></td>
					<td><span size="2">Happy</span></td>
					<td><span size="2">Sad</span></td>
					<td><span size="2">Angry</span></td>
				</tr>
				<tr>
					<td>
						<p><img src="https://pkhungurn.github.io/talking-head-anime-2/data/characters/otogibara_era/emotion/00000004.png">	
						</p>
					</td>
					<td>
						<p><img src="https://pkhungurn.github.io/talking-head-anime-2/data/characters/otogibara_era/emotion/00000005.png">	
						</p>
					</td>
					<td>
						<p><img src="https://pkhungurn.github.io/talking-head-anime-2/data/characters/otogibara_era/emotion/00000006.png">
						</p>
					</td>
					<td>
						<p><img src="https://pkhungurn.github.io/talking-head-anime-2/data/characters/otogibara_era/emotion/00000007.png">	
						</p>
					</td>
				</tr>
				<tr>
					<td><span size="2">Disgusted</span></td>
					<td><span size="2">Condescending</span></td>
					<td><span size="2">Uwamedukai <a href="#fn_uwamedukai">[footnote]</a></span></td>
					<td><span size="2">Gangimari-Gao <a href="#fn_gangimari">[footnote]</a></span></td>
				</tr>	
			</tbody></table>			
		

		

		<p>With the new network, I can drive character illustrations with motions authored for 3D models.</p>

		<p>
		<iframe width="560" height="315" src="https://www.youtube.com/embed/mfENtYixnNE" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>		
		</p>

		<p>I also created a real-time motion transfer tool that provides more controls over the character's face.</p>

		<p>
			<iframe width="560" height="315" src="https://www.youtube.com/embed/m13MLXNwdfY" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
		</p>

		<p>I modified the tool to record my motion and was later able make multiple characters talk and sing with more dynamic lip and face movements.</p>

		<p>
			<iframe width="560" height="315" src="https://www.youtube.com/embed/_O5BEcUz3Bw" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
		</p>
			

		
		<h2>1 &nbsp; Motivation</h2>		

		<p>With the goal of making it easier to become a <a href="https://en.wikipedia.org/wiki/Virtual_YouTuber">virtual YouTuber</a> (VTuber), in 2019, I created a <a href="https://pkhungurn.github.io/talking-head-anime">neural network system</a> that can animate the face of any existing anime character, given only an image of it. The system, however, cannot yet be considered practical for becoming a VTuber. The most important shortcoming is that it can only close the eyes and mouth, robbing the character the ability to make most facial expressions. Characters used by professional VTubers, on the other hand, can deform the eyebrows, eyelids, irises, and mouth into various shapes. My goal in this article is to improve my system's expressiveness by increasing the types of movements it can produce.</p>

		<h2>2 &nbsp; Summary of Approach</h2>

		<p>My neural network system takes two inputs. First is a <a href="https://en.wikipedia.org/wiki/Head_shot">head shot</a> of a character looking straight at the viewer, and second is a six-dimensional <i>pose vector</i> that specifies the pose the user wants the character to take. It outputs another image of the same character taking the specified pose. By varying the pose vector over time, the character can be animated. It can perform six types of movements because the pose vector is six-dimensional. However, excluding rotating the face, it can only closes its eyes and mouth.</p>

		<p>The system poses a given character in two steps, each carried out by its own separate subnetwork. The <i>face morpher</i> closes the eyes and the mouth, and the <i>face rotator</i> rotates the face.</p>

		<table>
	            <tbody><tr>
	                <td>
	                    <a href="https://pkhungurn.github.io/talking-head-anime-2/data/overview_two_step_process.png"><img src="https://pkhungurn.github.io/talking-head-anime-2/data/overview_two_step_process.png" width="600"></a>
	                </td>
	            </tr>
	            <tr>
	                <td>
	                    <b>Figure 2.1</b>  
	                    An overview of how the 2019 system poses a character's face. The character is <a href="https://www.youtube.com/channel/UC4YaOt1yT-ZeyB0OmxHgolA/videos">Kizuna AI</a> (© Kizuna AI).
	                </td>
	            </tr>
	        </tbody></table>
	    

	    <p>To increase types of movement, I started by preparing larger datasets. From the <a href="https://pkhungun.github.io/talking-head-anime/index.html#dataset">collection of approximately 8,000 3D models</a> I collected for my last system, I identified 39 common movements of facial parts and generated new datasets containing them. (You can see the list of movements <a href="https://pkhungurn.github.io/talking-head-anime-2/full.html#face-params">here</a>.) The movements encompass all the four movable facial features (eyebrows, eyelids, irises, and mouth) that can be observed in industrial characters. The size of the pose vector increased from 6 to 42 as a result <a href="#fn_pose_vector_length">[footnote]</a>.</p>

	    

	    <p>To deal with larger pose vectors, I propose a new architecture for the face morpher network, the overview of which is depicted in Figure 2.2.</p>

		<table>
	            <tbody><tr>
	                <td>
	                    <a href="https://pkhungurn.github.io/talking-head-anime-2/data/face_morpher_two_steps.png"><img src="https://pkhungurn.github.io/talking-head-anime-2/data/face_morpher_two_steps.png" width="600"></a>
	                </td>
	            </tr>
	            <tr>
	                <td>
	                    <b>Figure 2.2</b> 
	                    An overview of the new face morpher architecture. It morphs the face in two steps: the first morphs the eyebrow, and the second morphs the eyes and the mouth. The character is <a href="https://www.youtube.com/channel/UCp6993wxpyDPHUpavwDFqgg">Tokino Sora</a> (© Tokino Sora Ch.).
	                </td>
	            </tr>
	        </tbody></table>
	    

	    <p>The new face morpher has two subnetworks: the <b>eyebrow morpher</b> and the <b>eye &amp; mouth morpher</b>, with each network deforming the organ(s) in its name. The pose vector is divided into parts that can be fed into the relevant subnetworks.</p>

	    <h3>2.1 &nbsp; Eyebrow Morpher</h3>

	    <p>The eyebrow morpher first segments out the eyebrows with a dedicated subnetwork called the <b>eyebrow segmenter</b>. It then uses another subnetwork called the <b>eyebrow warper</b> to deform eyebrow and then composite the result back to the original image.</p>

	    <table>
	            <tbody><tr>
	                <td>
	                    <a href="https://pkhungurn.github.io/talking-head-anime-2/data/eyebrow_morpher_overview.png"><img src="https://pkhungurn.github.io/talking-head-anime-2/data/eyebrow_morpher_overview.png" width="600"></a>
	                </td>
	            </tr>
	            <tr>
	                <td>
	                    <b>Figure 2.3</b> 
	                    An overview of the architecture of the eyebrow morpher.
	                </td>
	            </tr>
	        </tbody></table>
	    

	    <p>The two networks have similar structures. It contains an encoder-decoder network that turns the input image(s) and the (optional) pose vector into an intermediate feature representation, which is then used to perform several image manipulation steps. I employ three types of image manipulation, each encapsulated into a reusable neural network unit.

	    </p><ol>
	    	<li><b>Partial image change</b>. The feature tensor is used to produce an alpha mask and another image that represents changes to the original image. The mask and the change image are then used to perform <a href="https://en.wikipedia.org/wiki/Alpha_compositing">alpha blending</a> with the input image to partially modify it. I take this step from the ECCV 2018 paper by Pumarola et al., which successfully applies it to alter facial expressions in human photos <a href="#fn_pumarola_2018">[2018]</a>.</li>

	    	<li><b>Combining</b>. The feature tensor is used to produce an alpha mask, which is then used to combine two images through alpha blending.</li>

	    	<li><b>Warping.</b> The feature tensor is transformed into an <b>appearance flow</b>, a map which tells, for each pixel of the output, which input image pixel to copy from <a href="#fn_zhou_2016">[Zhou et al. 2016]</a>. The appearance flow is then used to warp another image as it tells where each pixel should be moved to.</li>
	    </ol>
	    
	    

	   	<p>The eyebrow segmenter does its job with two partial image changes. The eyebrow warper deforms the extracted eyebrows with a warp and a partial image change. It then combines them back to the face image. Their architectures are given in Figure 2.4 and 2.5.</p>

	   	<p>
			<a href="https://pkhungurn.github.io/talking-head-anime-2/data/eyebrow_segmenter.png"><img src="https://pkhungurn.github.io/talking-head-anime-2/data/eyebrow_segmenter.png" width="600"></a><br>
			<b>Figure 2.4</b> Architecture of the eyebrow segmenter.
		</p>

		<p>
			<a href="https://pkhungurn.github.io/talking-head-anime-2/data/eyebrow_warper.png"><img src="https://pkhungurn.github.io/talking-head-anime-2/data/eyebrow_warper.png" width="600"></a><br>
			<b>Figure 2.5</b> Architecture of the eyebrow warper.
		</p>

		<p>During research, I discovered that it was very important to process the eyebrows separately from other facial features. Network architectures that used the same network to morph all facial features blurred the eyebrows after morphing them. By having separate networks morph the eyebrows after segmenting them out, I introduced a strong bias to preserve the eyebrow pixels, yielding crisp results.</p>

		
		<p><b>Figure 2.6</b> The effect of using separate networks to segment, morph, and then composite the eyebrows as proposed above.
		</p>
	
		

		<h3>2.2 &nbsp; Eye &amp; Mouth Morpher</h3>

	    <p>The eye &amp; mouth morpher has a similar architecture to the previous two networks. After passing the input image (the output of the eyebrow morpher) and the relevant part of the pose vector to an encoder-decoder network, it performs the following image manipulation steps:
		</p><ol>
			<li>a warp to deform the mouth and the irises,</li>
			<li>a partial image change to retouch the output of the last step, and</li>
			<li>another partial image change to deform the eyelids.</li>
		</ol>
		

		<p>
			<a href="https://pkhungurn.github.io/talking-head-anime-2/data/eye_and_mouth_morpher.png"><img src="https://pkhungurn.github.io/talking-head-anime-2/data/eye_and_mouth_morpher.png" width="600"></a><br>
			<b>Figure 2.7</b> Architecture of the eye &amp; mouth morpher.
		</p>

		<p>The above rather complicated process was a result of my iterating on the architecture. The first warping step is required to preserve high-frequency details of the irises. If partial image change were used, iris patterns drawn by artists would be lost.</p>

		
		<p><b>Figure 2.8</b> The effect of the first warping step of the eye &amp; mouth morpher on the quality of the irises. The character is <a href="https://www.youtube.com/channel/UCzrw4K7D9Ti3FP8WMTVPImg">Weatheroid Airi</a> (© Weathernews Inc.).
		</p>
	
		

		<p>The last step is necessary to produce artifact-free closed eyelids. If I were to deform the eyelids together with other facial features, they would be covered by the first warping step. I discovered that this led to small lines near the eyes being smeared, and the eyelids would be blemished as a result.</p>

		
		<p><b>Figure 2.9</b> The effect of processing the eyelids with a partial image change in a separate step. Notice the blemish produced by the architecture with warping. It is the result of the network's dragging the eyelid down and thereby smearing the small line inside the ground truth's red box. My proposed architecture simply fills the space with a solid color, yielding an artifact-free image. The character is <a href="https://www.youtube.com/channel/UCyb-cllCkMREr9de-hoiDrg">Yamato Iori</a> (© Appland, Inc.).
		</p>
	
		

		<h2>3 &nbsp; Results</h2>

		<p>I applied my system to 200 images of VTubers and related characters to generate a short video clip for each, and I put all the videos together in the <a href="#eyecatcher">eyecatcher</a>. You can watch the individual videos in the figure below.</p>

		<table>
				<tbody><tr>
					<td>Image being animated</td>
					<td>Video</td>
				</tr>
				<tr>
					<td id="characterImageCell">
						<img src="https://pkhungurn.github.io/talking-head-anime-2/data/characters/tsukino_mito/headshot.png">
					</td>
					<td id="characterVideoCell">
						<video muted="" controls="" loop="">
					    <source src="https://pkhungurn.github.io/talking-head-anime-2/data/characters/tsukino_mito/video.mp4" type="video/mp4">
					    </video>
					</td>
				</tr>
				<tr>
					<td colspan="2">
						
					</td>
				</tr>
			</tbody></table>
			<p><b>Figure 3.1</b> Videos of characters being animated by my system.</p>			
				

		

		<p>Below is a selection of characters making the 7 facial expressions shown at the beginning of the article.</p>
	</div><div>

		<p>The above figure demonstrates the versatility of my system. It could handle both male and female characters with very different eye and face shapes. It sensibly deformed the eyes even when partially occluded by hair or seen through translucent glasses. It hallucinates plausible mouth shapes in cases where the input image has a closed mouth while my previous system would just leave the mouth as is.</p>

		<p>Another strengths of my system is its flexibility: I can combine it with any source of pose parameters. I thus use it to create a number of content creation tools and <a href="https://en.wikipedia.org/wiki/Vidding">fanvids</a>.</p>

		<p>First, I created a desktop application that allows the user to manipulate an anime character's facial expression and face rotation by dragging sliders. The resulting image can be saved for later use.</p>

		<p>
			<iframe width="560" height="315" src="https://www.youtube.com/embed/535mjOjpy38" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
		</p>

		<p>Second, I wrote a program that converts motions authored for 3D models into sequences to pose parameters, allowing me use them to drive 2D character illustrations. With this tool, I created 4 music videos.</p>

		<p>
	…</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pkhungurn.github.io/talking-head-anime-2/">https://pkhungurn.github.io/talking-head-anime-2/</a></em></p>]]>
            </description>
            <link>https://pkhungurn.github.io/talking-head-anime-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25994963</guid>
            <pubDate>Mon, 01 Feb 2021 22:27:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[RISC-V isn't as interesting as you think]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25994836">thread link</a>) | @todsacerdoti
<br/>
February 1, 2021 | https://sporks.space/2021/02/01/risc-v-isnt-as-interesting-as-you-think/ | <a href="https://web.archive.org/web/*/https://sporks.space/2021/02/01/risc-v-isnt-as-interesting-as-you-think/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-47">
	<!-- .entry-header -->

	
		<div>
			
<p><em>I had wrote this before the Unleashed was revealed, so some of the bits on economics have changed. As of writing this, I still stand by my other beliefs. </em>One of the most hyped things in hardware design is RISC-V, the open ISA available without license fees. Many organizations including <a href="https://www.westerndigital.com/company/innovations/risc-v">Western Digital</a> have pledged support for RISC-V, and the open source community has a lot of faith in it, and with <a href="https://www.anandtech.com/show/16080/nvidia-to-acquire-arm-for-40-billion">Nvidia’s recent purchase of Arm</a>, people are concerned. However, I feel these hopes are somewhat misleading, as RISC-V’s openness is less at the benefit of the user and more for CPU vendors.</p>

<p><strong>Royalties</strong>. One of the biggest benefits of RISC-V is not having to pay any royalties for a CPU using it. You might pay SiFive or someone else for a realization of their cores on hard silicon, but that’s for the design, not an abstract implementation of the ISA. Openness here means there’s more profit margin on the tiny chips running washing machines, since they don’t have to pay ARM or Synopsys. While the savings could be passed onto you, the ISA’s openness will never be of concern when the program is on a one-time-programmable ROM.</p>



<p><strong>ISA fragmentation</strong>. RISC-V intentionally defines a small ISA with extensions (for example, multiplication, which actually encompasses divide too… which is even more expensive to implement than multiply, but it’s a package deal). While most larger implementations will implement a common set of extensions, having basic functionality in extensions could make software compatibility for binary distributions harder. This is made worse by RISC-V explicitly encouraging custom instructions for task-specific tweaks on vendor silicon – great for embedded, not so hot for general purpose computers and operating systems supporting them.</p>



<p><strong>Economics</strong>. RISC-V has actively courted embedded, which makes sense as a niche. Much of the hype of RISC-V is hoping for laptop/desktop/server class silicon. This is unlikely, because the economics of embedded are different. ISA doesn’t matter as much in embedded programming (code reuse matters, but it’s not like you’re running arbitrary binaries), whereas user/enterprise focused computing usually lives and dies by binary compatibility (to protect investments in existing applications) and performance gained by things most RISC-V implementations don’t have yet like superscalar execution (To say nothing how these impact implementation complexity and security!).</p>



<p><strong>Openness doesn’t tickle down</strong>. The openness of an ISA doesn’t have much impact on the implementation. A design with restricted signing keys is completely acceptable under their licensing – and is very likely, considering the embedded dominance RISC-V is likely to have. There are no guarantees of openness in ways that impact a user (i.e controlling the root of trust), since a user doesn’t exactly have access to a fab.</p>



<p><strong>Design flaws</strong>. RISC-V seems like it hasn’t learned anything from CPUs designed after 1991. Between some <a href="https://gist.github.com/erincandescent/8a10eeeea1918ee4f9d9982f7618ef68">rookie mistakes</a> like few <a href="https://lobste.rs/s/yqqhxu/llvm_for_m68k_completed_not_merged">addressing modes</a> (register churn, code density) and <a href="https://lobste.rs/s/icegvf/will_risc_v_revolutionize_computing#c_8wbb6t">blowing out the encoding space</a>. However, despite its flaws, it’s poised to take over embedded and possibly beyond anyways – worse truly is better.</p>



<p>Overall, RISC-V will lead in a revolution for nationalist vanity CPUs (think Loongson; no one will run them but for show and perhaps a niche of radical ideologues) , academic projects, and embedded vendors wanting to save on their balance sheets, but it probably won’t affect users or developers.</p>
					</div><!-- .entry-content -->

	
	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://sporks.space/2021/02/01/risc-v-isnt-as-interesting-as-you-think/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25994836</guid>
            <pubDate>Mon, 01 Feb 2021 22:17:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Polyaxon v1.5: Cloud Native Events, Hooks, and Joins]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25994303">thread link</a>) | @plx
<br/>
February 1, 2021 | https://blog.polyaxon.com/polyaxon-v1-5/ | <a href="https://web.archive.org/web/*/https://blog.polyaxon.com/polyaxon-v1-5/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><h2>Joins</h2>
<p>Until now, Polyaxon provided several interfaces for fanning out operations either with a list of parameters using <a href="https://polyaxon.com/docs/automation/mapping/">Mapping</a> or based on a <a href="https://polyaxon.com/docs/automation/optimization-engine/">hyperparameter tuning algorithm</a> supported by the Matrix section.</p>
<p>The <a href="https://polyaxon.com/docs/automation/joins/">Join interface</a> is a new abstraction that allows performing fan-in operations. A typical use-case for such interface is the map-reduce pattern, but it’s also the interface used by Polyaxon to provide performance-based Tensorboards, i.e. starting a Tensorbaord based on a search: <code>{query: metrics.loss:&lt; 0.01, sort: metrics.loss, limit: 10}</code>.</p>
<p>Polyaxon <code>Join</code> is not a replacement to other map-reduce frameworks, rather it provides a very convenient way to collect all; <code>Inputs</code>, <code>Outputs</code>, <code>Lineages</code>, <code>Contexts</code>, <code>Artifacts</code> from upstream runs based on <a href="https://polyaxon.com/docs/core/query-language/">Polyaxon Query Language</a>.</p>
<p>A <code>Join</code> can be used both in an independent operation or in the context of a DAG. And each operation can perform one or multiple joins.</p>
<p>Let’s look at some concrete examples.</p>
<h3>Performance-based Tensorboard</h3>
<p>A performance-based Tensorboard operation allows starting a Tensorboard, dynamically, based on some criteria without prior knowledge of the runs’ ids.</p>
<div data-language="yaml"><pre><code><span>version</span><span>:</span> <span>1.1</span>
<span>kind</span><span>:</span> operation
<span>name</span><span>:</span> compare<span>-</span>top<span>-</span>experiments
<span>joins</span><span>:</span>
<span>-</span> <span>query</span><span>:</span> <span>"metrics.loss:&lt;0.01"</span>
  <span>sort</span><span>:</span> <span>"metrics.loss"</span>
  <span>limit</span><span>:</span> <span>"5"</span>
  <span>params</span><span>:</span>
    <span>tensorboards</span><span>:</span>
      <span>value</span><span>:</span> <span>{</span><span>dirs</span><span>:</span> <span>"{{ artifacts.tensorboard }}"</span><span>}</span>
<span>component</span><span>:</span>
  <span>inputs</span><span>:</span>
  <span>-</span> <span>{</span><span>name</span><span>:</span> tensorboards<span>,</span> <span>type</span><span>:</span> artifacts<span>,</span> <span>toInit</span><span>:</span> <span>true</span><span>}</span>
  <span>run</span><span>:</span>
    <span>kind</span><span>:</span> service
    <span>ports</span><span>:</span>
    <span>-</span> <span>6006</span>
    <span>container</span><span>:</span>
      <span>image</span><span>:</span> tensorflow/tensorflow<span>:</span>2.2.0
      <span>command</span><span>:</span>
      <span>-</span> tensorboard
      <span>args</span><span>:</span>
      <span>-</span> <span>'--logdir={{globals.artifacts_path}}'</span>
      <span>-</span> <span>'--port={{globals.ports[0]}}'</span>
      <span>-</span> <span>'--path_prefix={{globals.base_url}}'</span>
      <span>-</span> <span>'--host=0.0.0.0'</span></code></pre></div>
<p>In this example, Polyaxon will automatically perform a search and collect artifacts logged under the name <code>tensorboard</code>.
Note that using the <code>artifacts</code> prefix, Polyaxon will look in the lineage table, however, if you do not log the lineage using Polyaxon, you can still pass a subpath, e.g. <code>sub-path/in/each/run/in/the/search</code>.</p>
<h3>Map-Reduce</h3>
<p>Joins can be used as an automated process to perform <code>fan-out -&gt; fan-in</code> or <code>map-reduce</code> process.</p>
<div data-language="yaml"><pre><code><span>version</span><span>:</span> <span>1.1</span>
<span>kind</span><span>:</span> component
<span>run</span><span>:</span>
  <span>kind</span><span>:</span> dag
  <span>operations</span><span>:</span>
  <span>-</span> <span>name</span><span>:</span> fan_out
    <span>hubRef</span><span>:</span> <span>"my-component:v1"</span>
    <span>matrix</span><span>:</span>
      <span>kind</span><span>:</span> random
      <span>numRuns</span><span>:</span> <span>20</span>
      <span>params</span><span>:</span>
        <span>learning_rate</span><span>:</span>
          <span>kind</span><span>:</span> linspace
          <span>value</span><span>:</span> 0.001<span>:</span>0.1<span>:</span><span>5</span>
        <span>dropout</span><span>:</span>
          <span>kind</span><span>:</span> choice
          <span>value</span><span>:</span> <span>[</span><span>0.25</span><span>,</span> <span>0.3</span><span>]</span>
        <span>conv_activation</span><span>:</span>
          <span>kind</span><span>:</span> pchoice
          <span>value</span><span>:</span> <span>[</span><span>[</span>relu<span>,</span> <span>0.1</span><span>]</span><span>,</span> <span>[</span>sigmoid<span>,</span> <span>0.8</span><span>]</span><span>]</span>
        <span>epochs</span><span>:</span>
          <span>kind</span><span>:</span> choice
          <span>value</span><span>:</span> <span>[</span><span>5</span><span>,</span> <span>10</span><span>]</span>
  <span>-</span> <span>name</span><span>:</span> fan_in
    <span>params</span><span>:</span>
      <span>matrix_uuid</span><span>:</span>
        <span>ref</span><span>:</span> ops.fan_out
        <span>value</span><span>:</span> globals.uuid
        <span>contextOnly</span><span>:</span> <span>true</span>
    <span>joins</span><span>:</span>
    <span>-</span> <span>query</span><span>:</span> <span>"metrics.accuracy:&gt;0.9, pipeline:{{ matrix_uuid }}"</span>
      <span>sort</span><span>:</span> <span>"-metrics.accuracy"</span>
      <span>params</span><span>:</span>
        <span>uuids</span><span>:</span> <span>{</span><span>value</span><span>:</span> <span>"globals.uuid"</span><span>,</span> <span>contextOnly</span><span>:</span> <span>true</span><span>}</span>
        <span>learning_rates</span><span>:</span> <span>{</span><span>value</span><span>:</span> <span>"inputs.learning_rate"</span><span>,</span> <span>contextOnly</span><span>:</span> <span>true</span><span>}</span>
        <span>accuracies</span><span>:</span> <span>{</span><span>value</span><span>:</span> <span>"outputs.accuracy"</span><span>,</span> <span>contextOnly</span><span>:</span> <span>true</span><span>}</span>
        <span>losses</span><span>:</span> <span>{</span><span>value</span><span>:</span> <span>"outputs.loss"</span><span>,</span> <span>contextOnly</span><span>:</span> <span>true</span><span>}</span>
    <span>component</span><span>:</span>
      <span>run</span><span>:</span>
        <span>kind</span><span>:</span> job
        <span>container</span><span>:</span>
          <span>image</span><span>:</span> image
          <span>command</span><span>:</span> <span>[</span><span>"/bin/bash"</span><span>,</span> <span>"-c"</span><span>]</span>
          <span>args</span><span>:</span> <span>[</span>echo <span>{</span><span>{</span> uuids <span>}</span><span>}</span>; "echo <span>{</span><span>{</span> learning_rates <span>}</span><span>}</span>; "echo <span>{</span><span>{</span> accuracies <span>}</span><span>}</span>; echo <span>{</span><span>{</span> losses <span>}</span><span>}</span>"<span>]</span></code></pre></div>
<p>In the example above, instead of searching the complete project, we restrict the search to a specific subset defined by the pipeline managing the random search algorithm (the same logic can be used for Mapping, grid search, Bayesian optimization, …).</p>
<p>In this example, the reduce operation is not doing anything important, just printing some of the inputs and outputs collected.</p>
<h2>Hooks</h2>
<blockquote>
<p><strong>Note</strong>: Hooks are currently on the commercial version only, but will be available on Polyaxon CE soon</p>
</blockquote>
<p>If you are using Polyaxon, you are already aware that you can provide:</p>
<ul>
<li><a href="https://polyaxon.com/docs/core/specification/init/">init containers</a>: an interface for users to run init containers before the main container containing the logic for training models or processing data.</li>
<li><a href="https://polyaxon.com/docs/core/specification/sidecars/">sidecar containers</a>: specialized containers running as sidecars to the main container.</li>
</ul>
<p><a href="https://polyaxon.com/docs/automation/hooks/">The hooks interface</a> is an extension to complete the lifecycle with a post-done logic.
Typically, hooks, are operations that run after the main logic, to notify external systems, trigger evaluation logic, generate reports, …</p>
<p>Compared to <code>init</code> and <code>sidecars</code> abstractions, we made the decision to run hooks outside of the pod where the main logic is running for several reasons:</p>
<ul>
<li>To allow users to release important resources, e.g. GPU/TPU that might not be needed for running the hook(s).</li>
<li>To make a distinction of what users should be running in such operations, normally we expect that users should use this interface to run recurrent and abstracted logic that depends on an upstream operation, yet applies to most operations with similar characteristics.</li>
</ul>
<p>Users can run full components, with their own <code>init</code> and <code>sidecars</code> in hooks, and can run many hooks per operation following:</p>
<ul>
<li>A trigger.</li>
<li>A set of conditions</li>
<li>And based on the full context of the main operation.</li>
</ul>
<p>All valid hooks will be automatically scheduled to run as soon as the main operation reaches a final status.</p>
<h2>Events</h2>
<p><a href="https://polyaxon.com/docs/automation/events/">Events</a> are the last major addition to the Polyaxonfile specification in this release, users can now run DAGs with full events support.</p>
<p>Most workflow orchestrators support an aggregated upstream condition, e.g. <code>all succeeded</code>, <code>all failed</code>, or <code>all done</code>, basically an orchestrator would schedule an operation or a task only after the upstream is finished. That was also the case for Polyaxon until this release.</p>
<p><code>Events</code> allow starting an operation in response to any event generated by an upstream entity. In this release, the entity is an operation running in the same DAG context. In the future, the entity could be anything from a Git commit, a new S3 blob, to an internal alert, or a new registered model version.</p>
<p>Here’s an example of starting a Tensorboard as soon as a training operation starts running:</p>
<div data-language="yaml"><pre><code><span>version</span><span>:</span> <span>1.1</span>
<span>kind</span><span>:</span> component
<span>name</span><span>:</span> experiment<span>-</span>with<span>-</span>tensorboard
<span>run</span><span>:</span>
  <span>kind</span><span>:</span> dag
  <span>operations</span><span>:</span>
  <span>-</span> <span>name</span><span>:</span> experiment
    <span>pathRef</span><span>:</span> <span>"./experiment.yml"</span>
    <span>params</span><span>:</span>
      <span>learning_rate</span><span>:</span>
        <span>value</span><span>:</span> <span>0.005</span>
      <span>epochs</span><span>:</span>
        <span>value</span><span>:</span> <span>10</span>
  <span>-</span> <span>name</span><span>:</span> tensorboard
    <span>hubRef</span><span>:</span> tensorboard
    <span>termination</span><span>:</span>
      <span>timeout</span><span>:</span> <span>7200</span>
    <span>params</span><span>:</span>
      <span>uuid</span><span>:</span>
        <span>ref</span><span>:</span> ops.experiment
        <span>value</span><span>:</span> globals.uuid
    <span>events</span><span>:</span>
      <span>-</span> <span>ref</span><span>:</span> ops.experiment
        <span>kinds</span><span>:</span> <span>[</span>run_status_running<span>]</span></code></pre></div>
<p>This DAG will schedule two operations, a job for training a DL experiment and a Tensorboard to visualize the outputs of the experiment.
Instead of waiting for the experiment to finish before starting a Tensorboard, or copying the UUID of the job to start the Tensorboard manually, this DAG will schedule the Tensorboard automatically as soon as the training starts running. If the training fails because of some compilation error, the Tensorboard will be marked as skipped.</p>
<h2>Compiler</h2>
<h3>Optimized compilation and context resolution</h3>
<p>This version brings several new heuristics to optimize the process of resolving and converting Polyaxonfiles, from a couple of milliseconds to a second in some cases, which should translate to faster scheduling of operations.</p>
<p>We also consolated the interface for requesting and resolving information from the compiler’s context, as well as moving the context to its own <a href="https://polyaxon.com/docs/core/context/">documentation section</a>.</p>
<h3>Improved init artifacts specification</h3>
<p>This was requested several times, extending the artifacts initializer to allow providing a custom destination path where it should store the artifacts collected:</p>
<div data-language="yaml"><pre><code><span>init</span><span>:</span>
  <span>files</span><span>:</span>
    <span>-</span> file1
    <span>-</span> <span>-</span> file2
      <span>-</span> path/to/store/file2
  <span>dirs</span><span>:</span>
    <span>-</span> dir1
    <span>-</span> <span>-</span> dir2
      <span>-</span> path/to/store/dir2</code></pre></div>
<p><code>file1</code> and <code>dir1</code> are what users were familiar with. <code>file2</code> and <code>dir2</code> are the new capability, the initializer accepts a tuple to specify the path from and the path to.</p>
<h3>Restart with copy improvement</h3>
<p>As a result of the previous enhancement, when a user restarts an operation using the copy mode, the copied information will be initialized automatically under the new run.</p>
<blockquote>
<p><strong>Note</strong>: Restart with copy mode is an advanced feature to allow users to resume training of an experiment with updated code/params/configuration/resources multiple times without mutating the original run.</p>
</blockquote>
<h3>New input type UUID</h3>
<p>Polyaxonfile parser can now validate <code>uuid</code> types properly, users can use this new type instead of <code>str</code> to validate the inputs and fail faster.</p>
<h2>UI</h2>
<h3>Serveral new lineage tabs</h3>
<p>It was always possible to filter all upstream/downstream runs based on another run or all runs that are clones of a specific run. But pulling such information required doing a manual search in the comparison table.</p>
<p>Polyaxon UI now exposes several new lineage tabs to show:</p>
<ul>
<li>Artifacts &amp; Connections requested for a specific run:</li>
</ul>
<p><span>
<a href="https://blog.polyaxon.com/static/62dbd837f4a0476d1bc3f310c1961dac/218ba/feature-1.png" target="_blank" rel="noopener">
<span></span>
<img alt="feature1" title="feature1" src="https://blog.polyaxon.com/static/62dbd837f4a0476d1bc3f310c1961dac/f97d7/feature-1.png" srcset="https://blog.polyaxon.com/static/62dbd837f4a0476d1bc3f310c1961dac/0eb09/feature-1.png 500w, https://blog.polyaxon.com/static/62dbd837f4a0476d1bc3f310c1961dac/1263b/feature-1.png 1000w, https://blog.polyaxon.com/static/62dbd837f4a0476d1bc3f310c1961dac/f97d7/feature-1.png 2000w, https://blog.polyaxon.com/static/62dbd837f4a0476d1bc3f310c1961dac/218ba/feature-1.png 2144w" sizes="(max-width: 2000px) 100vw, 2000px" loading="lazy">
</a>
</span></p>
<ul>
<li>All clones:</li>
</ul>
<p><span>
<a href="https://blog.polyaxon.com/static/690372bb90e36147cb6cb20ed5903858/bcfad/feature-2.png" target="_blank" rel="noopener">
<span></span>
<img alt="feature2" title="feature2" src="https://blog.polyaxon.com/static/690372bb90e36147cb6cb20ed5903858/bcfad/feature-2.png" srcset="https://blog.polyaxon.com/static/690372bb90e36147cb6cb20ed5903858/0eb09/feature-2.png 500w, https://blog.polyaxon.com/static/690372bb90e36147cb6cb20ed5903858/1263b/feature-2.png 1000w, https://blog.polyaxon.com/static/690372bb90e36147cb6cb20ed5903858/bcfad/feature-2.png 1396w" sizes="(max-width: 1396px) 100vw, 1396px" loading="lazy">
</a>
</span></p>
<ul>
<li>Upstream &amp; Downstream edge runs:</li>
</ul>
<p><span>
<a href="https://blog.polyaxon.com/static/ee169824c349d9e08f4b3f85c2414f25/9ddde/feature-3.png" target="_blank" rel="noopener">
<span></span>
<img alt="feature3" title="feature3" src="https://blog.polyaxon.com/static/ee169824c349d9e08f4b3f85c2414f25/f97d7/feature-3.png" srcset="https://blog.polyaxon.com/static/ee169824c349d9e08f4b3f85c2414f25/0eb09/feature-3.png 500w, https://blog.polyaxon.com/static/ee169824c349d9e08f4b3f85c2414f25/1263b/feature-3.png 1000w, https://blog.polyaxon.com/static/ee169824c349d9e08f4b3f85c2414f25/f97d7/feature-3.png 2000w, https://blog.polyaxon.com/static/ee169824c349d9e08f4b3f85c2414f25/9ddde/feature-3.png 2784w" sizes="(max-width: 2000px) 100vw, 2000px" loading="lazy">
</a>
</span></p>
<h3>Improved run’s overview page</h3>
<ul>
<li>Namespace and artifacts store:</li>
</ul>
<p> <span>
<a href="https://blog.polyaxon.com/static/295330902bfdb7d7f9cc543cbba9d739/56508/feature-4.png" target="_blank" rel="noopener">
<span></span>
<img alt="feature4" title="feature4" src="https://blog.polyaxon.com/static/295330902bfdb7d7f9cc543cbba9d739/56508/feature-4.png" srcset="https://blog.polyaxon.com/static/295330902bfdb7d7f9cc543cbba9d739/0eb09/feature-4.png 500w, https://blog.polyaxon.com/static/295330902bfdb7d7f9cc543cbba9d739/1263b/feature-4.png 1000w, https://blog.polyaxon.com/static/295330902bfdb7d7f9cc543cbba9d739/56508/feature-4.png 1696w" sizes="(max-width: 1696px) 100vw, 1696px" loading="lazy">
</a>
</span></p>
<ul>
<li>Better documentation with Readme (the markdown preview has a similar style as the run’s overview page, in both light and dark themes):</li>
</ul>
<p><span>
<a href="https://blog.polyaxon.com/static/1eeb946e75848e39f887fe17d8e35e04/b1b5c/feature-5-1.png" target="_blank" rel="noopener">
<span></span>
<img alt="feature5-1" title="feature5-1" src="https://blog.polyaxon.com/static/1eeb946e75848e39f887fe17d8e35e04/f97d7/feature-5-1.png" srcset="https://blog.polyaxon.com/static/1eeb946e75848e39f887fe17d8e35e04/0eb09/feature-5-1.png 500w, https://blog.polyaxon.com/static/1eeb946e75848e39f887fe17d8e35e04/1263b/feature-5-1.png 1000w, https://blog.polyaxon.com/static/1eeb946e75848e39f887fe17d8e35e04/f97d7/feature-5-1.png 2000w, https://blog.polyaxon.com/static/1eeb946e75848e39f887fe17d8e35e04/b1b5c/feature-5-1.png 2864w" sizes="(max-width: 2000px) 100vw, 2000px" loading="lazy">
</a>
</span></p>
<p><span>
<a href="https://blog.polyaxon.com/static/c23214109d9ab2f01d651ecc7b64e552/b1b5c/feature-5-2.png" target="_blank" rel="noopener">
<span></span>
<img alt="feature5-2" title="feature5-2" src="https://blog.polyaxon.com/static/c23214109d9ab2f01d651ecc7b64e552/f97d7/feature-5-2.png" srcset="https://blog.polyaxon.com/static/c23214109d9ab2f01d651ecc7b64e552/0eb09/feature-5-2.png 500w, https://blog.polyaxon.com/static/c23214109d9ab2f01d651ecc7b64e552/1263b/feature-5-2.png 1000w, https://blog.polyaxon.com/static/c23214109d9ab2f01d651ecc7b64e552/f97d7/feature-5-2.png 2000w, https://blog.polyaxon.com/static/c23214109d9ab2f01d651ecc7b64e552/b1b5c/feature-5-2.png 2864w" sizes="(max-width: 2000px) 100vw, 2000px" loading="lazy">
</a>
</span></p>
<ul>
<li>IO tables with search and pagination:</li>
</ul>
<p> <span>
<a href="https://blog.polyaxon.com/static/933623297bb16a89b97cc6eda7eeb5ff/1fcef/feature-6.png" target="_blank" rel="noopener">
<span></span>
<img alt="feature6" title="feature6" src="https://blog.polyaxon.com/static/933623297bb16a89b97cc6eda7eeb5ff/1fcef/feature-6.png" srcset="https://blog.polyaxon.com/static/933623297bb16a89b97cc6eda7eeb5ff/0eb09/feature-6.png 500w, https://blog.polyaxon.com/static/933623297bb16a89b97cc6eda7eeb5ff/1263b/feature-6.png 1000w, https://blog.polyaxon.com/static/933623297bb16a89b97cc6eda7eeb5ff/1fcef/feature-6.png 1919w" sizes="(max-width: 1919px) 100vw, 1919px" loading="lazy">
</a>
</span></p>
<ul>
<li>Copying of the complete inputs and outputs as JSON objects:</li>
</ul>
<p> <span>
<a href="https://blog.polyaxon.com/static/e72e1847b33220e8eff7acfbfb436b17/1fcef/feature-7.png" target="_blank" rel="noopener">
<span></span>
<img alt="feature7" title="feature7" src="https://blog.polyaxon.com/static/e72e1847b33220e8eff7acfbfb436b17/1fcef/feature-7.png" srcset="https://blog.polyaxon.com/static/e72e1847b33220e8eff7acfbfb436b17/0eb09/feature-7.png 500w, https://blog.polyaxon.com/static/e72e1847b33220e8eff7acfbfb436b17/1263b/feature-7.png 1000w, https://blog.polyaxon.com/static/e72e1847b33220e8eff7acfbfb436b17/1fcef/feature-7.png 1919w" sizes="(max-width: 1919px) 100vw, 1919px" loading="lazy">
</a>
</span></p>
<h3>Wait time</h3>
<p>The dashboard will show a new field <code>wait time</code>, this time represents all phases that come before an operation is scheduled on Kubernetes.
This information is available on the overview page, and on the comparison table. Users can query and sort by the wait time similar to other meta data.</p>
<p> <span>
<a href="https://blog.polyaxon.com/static/53c7baf679e277b03b46e8fe4563bec3/9e144/feature-8.png" target="_blank" rel="noopener">
<span></span>
<img alt="feature8" title="feature8" src="https://blog.polyaxon.com/static/53c7baf679e277b03b46e8fe4563bec3/9e144/feature-8.png" srcset="https://blog.polyaxon.com/static/53c7baf679e277b03b46e8fe4563bec3/9e144/feature-8.png 226w" sizes="(max-width: 226px) 100vw, 226px" loading="lazy">
</a>
</span></p>
<p>By analyzing the wait time of runs filterd by specific queue, you should have more context to optimize and organize your queues.</p>
<h3>Consolidated pipeline overview</h3>
<p>We moved several aspects that provide information about the pipeline into a subsection:</p>
<ul>
<li>Pipeline Concurrency</li>
<li>Children run kinds</li>
<li>Pipeline progress</li>
</ul>
<p> <span>
<a href="https://blog.polyaxon.com/static/182f05b9b4e9b842d005332663455b0b/cfc60/feature-9.png" target="_blank" rel="noopener">
<span></span>
<img alt="feature9" title="feature9" src="https://blog.polyaxon.com/static/182f05b9b4e9b842d005332663455b0b/cfc60/feature-9.png" srcset="https://blog.polyaxon.com/static/182f05b9b4e9b842d005332663455b0b/0eb09/feature-9.png 500w, https://blog.polyaxon.com/static/182f05b9b4e9b842d005332663455b0b/cfc60/feature-9.png 776w" sizes="(max-width: 776px) 100vw, 776px" loading="lazy">
</a>
</span></p>
<h2>Docs</h2>
<p>We published a new section <code>how-tos</code> that should feature short guides on how to use Kubernetes capabilities, as well as answer …</p></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.polyaxon.com/polyaxon-v1-5/">https://blog.polyaxon.com/polyaxon-v1-5/</a></em></p>]]>
            </description>
            <link>https://blog.polyaxon.com/polyaxon-v1-5/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25994303</guid>
            <pubDate>Mon, 01 Feb 2021 21:35:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Changelog Spec]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25994262">thread link</a>) | @haskellandchill
<br/>
February 1, 2021 | https://opticdev.github.io/changelog-spec-demo/ | <a href="https://web.archive.org/web/*/https://opticdev.github.io/changelog-spec-demo/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://opticdev.github.io/changelog-spec-demo/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25994262</guid>
            <pubDate>Mon, 01 Feb 2021 21:32:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Repl.it __logs]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25994177">thread link</a>) | @agmm
<br/>
February 1, 2021 | https://blog.repl.it/__logs | <a href="https://web.archive.org/web/*/https://blog.repl.it/__logs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://blog.repl.it/__logs</link>
            <guid isPermaLink="false">hacker-news-small-sites-25994177</guid>
            <pubDate>Mon, 01 Feb 2021 21:24:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Staircase of the Self: An Illustrated Dive into the Progression of Identity]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25994026">thread link</a>) | @LYeo
<br/>
February 1, 2021 | https://moretothat.com/the-staircase-of-the-self/ | <a href="https://web.archive.org/web/*/https://moretothat.com/the-staircase-of-the-self/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>When children copy us, we think it’s cute. When adults copy us, we threaten to sue.</p><p>This odd dynamic shines a light on our relationship with imitation, and the way it morphs over time. When we interact with a child, we operate under the assumption that the child is still learning about her place in the world, so we accept emulation as a prerequisite to her development. It’s not only normal to see the child copying the behavior of adults, it’s something that brings us immense joy to see.</p><p><a href="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A01-Kids-and-imitation.png"><img loading="lazy" src="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A01-Kids-and-imitation.png" alt="child imitating parents" width="1500" height="1100" srcset="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A01-Kids-and-imitation.png 1500w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A01-Kids-and-imitation-300x220.png 300w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A01-Kids-and-imitation-1024x751.png 1024w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A01-Kids-and-imitation-768x563.png 768w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A01-Kids-and-imitation-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p><p>Psychologist Alfred Adler believed that this imitative behavior is the result of an “inferiority complex” that is universal in childhood. Since all children enter a world inhabited by towering adults, the sheer physical differences between themselves and their parents causes this feeling of inferiority to develop. To alleviate this, the child will emulate the behavior of these lumbering giants, and will learn how to overcome various challenges by copying what they do.</p><p>Another way to look at this is that the sense of self is not strongly cultivated in a child. Most of the child’s connection to her individuality is purely based on sense data – it’s limited to the pang of hunger she feels, the physical warmth she experiences, the discomfort she wants you to resolve.</p><p>But her awareness of who she is as a unique person has been offloaded to the adults. My wife and I will look at <a href="https://moretothat.com/a-letter-to-my-newborn-daughter/" target="_blank" rel="noopener noreferrer">our newborn daughter</a> and say things like, “She seems quite introverted” or “She’s sensitive to people’s energy,” but my daughter (likely) isn’t making any of these character interpretations about herself.</p><p><a href="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A02-Wonder-what-she-is-thinking.png"><img loading="lazy" src="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A02-Wonder-what-she-is-thinking.png" alt="deep thinker" width="1500" height="1100" srcset="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A02-Wonder-what-she-is-thinking.png 1500w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A02-Wonder-what-she-is-thinking-300x220.png 300w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A02-Wonder-what-she-is-thinking-1024x751.png 1024w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A02-Wonder-what-she-is-thinking-768x563.png 768w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A02-Wonder-what-she-is-thinking-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p><p>This lack of a sense of self is a spiritual goal for many adults, but that’s only because we know how to take care of our basic biological needs. Young children, on the other hand, literally cannot survive without the presence of caretakers, so having no sense of self doesn’t do them any good. The survival of the self is reliant upon interactions with others, so the shaping of their identity depends on who is there to provide for them regularly.</p><p>Imitation is the birthplace of human behavior. There’s no way around this fact, and we all intuitively understand this to be true. However, why is it also intuitive for us to scorn imitation as we age? Why does it become desirable to discard societal norms to become our “authentic selves,” or to escape this sense of self entirely?</p><p>Well, to answer these questions, we’re going to have to take a journey through the stages of one’s identity, and how we internalize it at each level. To do this, I’d like to introduce what I call <span><strong>The Staircase of the Self</strong></span>:</p><p><a href="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A03-The-Staircase-of-the-Self.png"><img loading="lazy" src="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A03-The-Staircase-of-the-Self.png" alt="the staircase of the self" width="1500" height="1100" srcset="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A03-The-Staircase-of-the-Self.png 1500w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A03-The-Staircase-of-the-Self-300x220.png 300w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A03-The-Staircase-of-the-Self-1024x751.png 1024w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A03-The-Staircase-of-the-Self-768x563.png 768w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A03-The-Staircase-of-the-Self-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p><p>As the diagram indicates, the position of each step is tied to how strongly one identifies with their sense of self, or the feeling of being a distinct individual navigating the world. One thing you’ll notice is that the diagram is symmetrical, so there are two steps occupying the same horizontal position at different points in the journey (e.g. Self-Esteem and Self-Actualization). This is because both these steps embody a similar association with identity, but do so with different lenses. We’re going to go into this in more detail later.</p><p>But for the time being, we’re going to focus on the first two steps, and see what it means to move out of utter dependency, and into a semblance of independence.</p><h3>From Inferiority to Self-Esteem</h3><div><p><a href="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A04-From-Inferiority-to-Self-Esteem.png"><img loading="lazy" src="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A04-From-Inferiority-to-Self-Esteem.png" alt="inferiority to self-esteem" width="1500" height="1100" srcset="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A04-From-Inferiority-to-Self-Esteem.png 1500w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A04-From-Inferiority-to-Self-Esteem-300x220.png 300w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A04-From-Inferiority-to-Self-Esteem-1024x751.png 1024w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A04-From-Inferiority-to-Self-Esteem-768x563.png 768w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/A04-From-Inferiority-to-Self-Esteem-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p></div><p>The feeling of inferiority is largely due to an absence of a sense of self, but not in the way monks and meditators view it. This texture of “no self” originates from the helplessness we all experience as infants, and the complete reliance we must have on others to sustain our lives. Our behaviors are driven by fear, this fear lends itself to inferiority, and this inferiority causes us to outsource our identities to whoever we think has the answers.</p><p>So how do we identify the presence of our own unique intellect?</p><p>The feeling of inferiority is certainly not limited to infants, but by viewing this question through the lens of child psychology, we’ll arrive at a pretty good answer.</p><p>Jean Piaget, an influential 20th century psychologist, keenly observed that infants develop their intellect not through social interaction, but by personal action. Piaget initially thought that language was the primary developer of the intellect, but he noticed that an infant’s rapid capacity to interact with her physical surroundings is how she actually learned. Contrary to popular belief, it wasn’t “goo-goo gah-gah”ing with family members that developed her mind, but the way she used her senses to navigate the material world around her.</p><p>Piaget used this observation to propose that intellectual development happens in four distinct stages, each of which progresses from the more concrete (touching and arranging objects) to the more abstract (categorization to verbal reasoning). What makes progression possible is the child’s ability to build a “schema” (aka mental model) of the world, to introduce something foreign to that schema, and then to have the child update that schema to accommodate that foreign thing.</p><p>So for example, let’s say you show a child two glasses of different sizes. One is tall and thin (which holds water), while the other is short and wide (which is empty):</p><p><a href="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B01-Glasses-of-water.png"><img loading="lazy" src="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B01-Glasses-of-water.png" alt="cups experiment" width="1500" height="1100" srcset="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B01-Glasses-of-water.png 1500w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B01-Glasses-of-water-300x220.png 300w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B01-Glasses-of-water-1024x751.png 1024w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B01-Glasses-of-water-768x563.png 768w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B01-Glasses-of-water-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p><p>Then let’s take the contents of the tall glass and pour it into the short glass:</p><p><a href="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B02-Glasses-of-water.png"><img loading="lazy" src="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B02-Glasses-of-water.png" alt="pouring big cup into small cup" width="1500" height="1100" srcset="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B02-Glasses-of-water.png 1500w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B02-Glasses-of-water-300x220.png 300w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B02-Glasses-of-water-1024x751.png 1024w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B02-Glasses-of-water-768x563.png 768w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B02-Glasses-of-water-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p><p>If this is the first time the child has seen this, she will believe that the shorter glass now holds less water than the taller one did. Since her existing schema takes differences in height to indicate changes in quantity, she will be unable to understand how both cups contain the same amount of water.</p><p><a href="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B03-Glasses-of-water-rev.png"><img loading="lazy" src="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B03-Glasses-of-water-rev.png" alt="being surprised at the cup" width="1500" height="1100" srcset="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B03-Glasses-of-water-rev.png 1500w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B03-Glasses-of-water-rev-300x220.png 300w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B03-Glasses-of-water-rev-1024x751.png 1024w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B03-Glasses-of-water-rev-768x563.png 768w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B03-Glasses-of-water-rev-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p><p>The only way for the child to accommodate this new knowledge is for her to take action and try it out herself. It doesn’t matter how much you sit her down and explain the mechanics, the only way for her to update her schema is to break the old one by integrating this foreign reality.</p><p><a href="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B04-Glasses-of-water.png"><img loading="lazy" src="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B04-Glasses-of-water.png" alt="pouring from small cup to big cup" width="1500" height="1100" srcset="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B04-Glasses-of-water.png 1500w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B04-Glasses-of-water-300x220.png 300w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B04-Glasses-of-water-1024x751.png 1024w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B04-Glasses-of-water-768x563.png 768w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/B04-Glasses-of-water-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p><p>Intellectual development is deeply personal, and can only occur when one takes on the experiential challenges required to update their schemas. This is why Piaget called for classrooms where each child’s progress was individually accommodated by the teacher, and learning was more interactive. Agency plays a big role in how we cultivate our intellectual curiosity, as this type of willful action is what allows us to trust our own cognitive capabilities.</p><p>At its core, <span><strong>self-esteem is about having the confidence to solve problems on your own accord</strong></span>. And the way you do this is by regularly facing challenges that stretch the boundaries of your mind, which in turn shatter and update the preexisting models you had of the world. The more you do this, the more you cultivate your sense of judgment, which allows you to shut the door to inferiority.</p><p>This is easier said than done, largely because inferiority is the platform in which existence begins. It’s what you feel when you look to other people’s solutions to solve your personal problems, and this type of emulative behavior is what is required to progress through childhood. But with each challenge we face and resolve, we slowly transcend our reliance on others, and develop our unique lens to view the world through.</p><p><a href="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C01-Climbing-to-Self-Esteem.png"><img loading="lazy" src="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C01-Climbing-to-Self-Esteem.png" alt="moving up a step" width="1500" height="1100" srcset="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C01-Climbing-to-Self-Esteem.png 1500w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C01-Climbing-to-Self-Esteem-300x220.png 300w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C01-Climbing-to-Self-Esteem-1024x751.png 1024w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C01-Climbing-to-Self-Esteem-768x563.png 768w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C01-Climbing-to-Self-Esteem-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p><p>As you reach the step of self-esteem, the sense of self grows in turn. Confidence is a belief in how strongly your sense of agency is tied to favorable life outcomes, and the greater it is, the more you carve out a space for yourself in this world.</p><p>Self-esteem is invaluable in discovering who you are, but there comes a point where this independence begins to thirst for something greater.</p><p>And it is here where the utility of self-esteem begins to fall apart.</p><h3>From Self-Esteem to Pride</h3><div><p><a href="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C02-From-Self-Esteem-to-Pride.png"><img loading="lazy" src="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C02-From-Self-Esteem-to-Pride.png" alt="self-esteem to pride" width="1500" height="1100" srcset="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C02-From-Self-Esteem-to-Pride.png 1500w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C02-From-Self-Esteem-to-Pride-300x220.png 300w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C02-From-Self-Esteem-to-Pride-1024x751.png 1024w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C02-From-Self-Esteem-to-Pride-768x563.png 768w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C02-From-Self-Esteem-to-Pride-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p></div><blockquote><p><em>All social disturbances and upheavals have their roots in a crisis of individual self-esteem, and the great endeavors in which the masses most readily unite [are] basically a search for pride.</em></p><p>– Bruce Lee</p></blockquote><p>The paradox of self-esteem is that in order to have confidence in yourself, you need to better understand the social context in which you operate in. For example, if you want to be a great manager, you have to be acutely aware of all the dynamics you have with your team members. If you want to be a great entrepreneur, you have to figure out how to build an awesome solution that other people would find helpful.</p><p>This is inevitable because even though life is a single-player game, meaning is ultimately derived <a href="https://moretothat.com/the-meaning-of-life-is-absurd/" target="_blank" rel="noopener noreferrer">on multi-player mode</a>. We can only navigate existence through our own lens, but it’s through the connections we make with other people that gives the journey its purpose.</p><p>Self-esteem is complicated for this very reason. So much of it is tied into <a href="https://moretothat.com/the-omnipresence-of-work/" target="_blank" rel="noopener noreferrer">how useful we are to others</a>, and our confidence grows the more we are rewarded for our actions. This confidence boost leads to a higher attachment to the sense of self, which means that we look to further differentiate ourselves from everyone else.</p><p>And when it comes to differentiation, humanity has used one crude tool to achieve this since the dawn of our existence:</p><p>The desire for status.</p><p><a href="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C03-Status-vial.png"><img loading="lazy" src="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C03-Status-vial.png" alt="people desiring status" width="1500" height="1100" srcset="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C03-Status-vial.png 1500w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C03-Status-vial-300x220.png 300w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C03-Status-vial-1024x751.png 1024w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C03-Status-vial-768x563.png 768w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C03-Status-vial-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p><p>Any quest for status begins with an attachment to some identity, and then using a strong sense of self to climb up that particular silo. Corporate ladders are a common example of this phenomenon. Academic hierarchies are another. Others are primarily concerned with influence, which can be seen in abundance on social media or any other <a href="https://moretothat.com/pursue-mastery-not-status/" target="_blank" rel="noopener noreferrer">metric-heavy medium</a>.</p><p>The first thing status does is that it changes the nature of confidence. Confidence is no longer gauged by your internal benchmark of progress; it is contingent upon the praise you receive from others. This makes your sense of self fragile, as its condition hinges upon reactions that are not your own. The tide of other people’s opinions never follow any predictable pattern, so you begin to operate from an unstable foundation.</p><p>In order to compensate for this, we introduce the element of pride.</p><p><a href="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C06-From-Pride-to-Self-Actualization-rev.png"><img loading="lazy" src="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C06-From-Pride-to-Self-Actualization-rev.png" alt="people's opinions vs my pride" width="1500" height="1100" srcset="https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C06-From-Pride-to-Self-Actualization-rev.png 1500w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C06-From-Pride-to-Self-Actualization-rev-300x220.png 300w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C06-From-Pride-to-Self-Actualization-rev-1024x751.png 1024w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C06-From-Pride-to-Self-Actualization-rev-768x563.png 768w, https://2m93ao7jjy53ndft63v8tvcp-wpengine.netdna-ssl.com/wp-content/uploads/2021/01/C06-From-Pride-to-Self-Actualization-rev-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p><p>Pride is an overcorrection to our fragility in confidence. It’s a staunch attachment to an identity, regardless of what <a href="https://moretothat.com/why-everyone-can-face-the-truth/" target="_blank" rel="noopener noreferrer">may or may not be true</a>. It’s our way of …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://moretothat.com/the-staircase-of-the-self/">https://moretothat.com/the-staircase-of-the-self/</a></em></p>]]>
            </description>
            <link>https://moretothat.com/the-staircase-of-the-self/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25994026</guid>
            <pubDate>Mon, 01 Feb 2021 21:12:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Splatoon 2’s Netcode and Matchmaking: An In-Depth Look (2018)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25993639">thread link</a>) | @ignitionmonkey
<br/>
February 1, 2021 | https://oatmealdome.me/blog/splatoon-2s-netcode-an-in-depth-look/ | <a href="https://web.archive.org/web/*/https://oatmealdome.me/blog/splatoon-2s-netcode-an-in-depth-look/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Splatoon 2’s netcode and matchmaking has been criticized for many different reasons. Some of the common complaints are frequent disconnections, low tick rate, lag, and that the netcode uses a peer-to-peer architecture. In this blog post, I will attempt to explain how the netcode works and address some people’s complaints. This post is the culmination of a year’s worth of research and collaboration with others. I hope that you will learn something from it!</p>
<p>If you are allergic to essays, I’ve included a list of key points at the end of the post. I still recommend to try and read the whole thing, however.</p>
<p>(The listing image was taken by <a href="https://steamcommunity.com/sharedfiles/filedetails/?id=1193479292">Ethan</a>. Thank you so much!)</p>
<h3>Need-to-Know</h3>
<p>Let’s go over some basic information first.</p>
<h4>Basic Netcode Terminology</h4>
<p>Please have a look over <a href="https://www.pcgamer.com/netcode-explained/">PCGamer’s excellent netcode overview</a> to review basic information about what netcode is and its associated terminology. I will not be explaining every term or concept here otherwise this post would be a million words long. (As if it wasn’t already that long in the first place…)</p>
<h4>Pia</h4>
<p>At its core, Splatoon 2 uses a library called “pia”. Pia was developed by Nintendo in order to make creating networking features for games easier. It implements network features based on a “peer-to-peer” architecture, unlike the traditional “client-server” architecture. This means that instead of one server having a “one-on-one conversation” between each Nintendo Switch console to exchange information, all of the consoles communicate directly with each other to share information.</p>
<figure><img data-attachment-id="155" data-permalink="https://oatmealdome.me/blog/splatoon-2s-netcode-an-in-depth-look/peer-to-peer/" data-orig-file="https://cdn.oatmealdome.me/wp-content/uploads/2019/05/09210009/Peer-to-peer.png" data-orig-size="620,308" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Peer-to-peer" data-image-description="" data-medium-file="https://cdn.oatmealdome.me/wp-content/uploads/2019/05/09210009/Peer-to-peer-300x149.png" data-large-file="https://cdn.oatmealdome.me/wp-content/uploads/2019/05/09210009/Peer-to-peer.png" src="https://cdn.oatmealdome.me/wp-content/uploads/2019/05/09210009/Peer-to-peer.png" alt="" data-lazy-src="https://cdn.oatmealdome.me/wp-content/uploads/2019/05/09210009/Peer-to-peer.png?is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption> from bitcoinwiki.org, CC BY-SA </figcaption></figure>
<p>However, this doesn’t mean that there isn’t a “master console” similar to what a server would be. Pia assigns one console as the “host” of the session. This is usually the person who opened the session first, and people who join the session are considered to be regular clients. (Contrary to popular belief, it hasn’t been definitively proven that the person at the top of the matchmaking screen is the host of the session.) But how do other people find each other to join sessions?</p>
<h4>NEX</h4>
<p>NEX is a two-part system comprising of a game server and an API used to communicate with the servers. NEX handles matchmaking for peer-to-peer sessions, NAT traversal (helping people behind a firewall or router with getting connected to others), and rankings. Pia has built-in support for NEX’s matchmaking and NAT traversal features, making it easy for developers who are already using pia to implement online play. (NEX actually has its own peer-to-peer networking library independent of pia called VSocket, but Splatoon 2 does not use this. As far as I know, I don’t think any game does…)</p>
<p>NEX actually began its life as <a href="http://www.quazal.com/rendez-vous.htm">Quazal Technologies Inc.’s Rendez-Vous</a>, which started development <a href="https://www.gamasutra.com/view/feature/130572/middleware_postmortem_quazal_.php?page=3">all the way back in 2003</a>. Several games from the 2000s used technology from Quazal to implement multiplayer features. <a href="https://www.gamesindustry.biz/articles/quazal-ubisoft-deal-latter-to-employ-former-s-multiplayer-middleware">Ubisoft later acquired Quazal Technologies in 2010</a>. Rendez-Vous lives on to at least 2015, as <a href="https://jpboivin.me/wp/">Ubisoft Montreal continues to add features to the library</a>.</p>
<p>As for NEX, it appears Nintendo must have either bought or licensed Rendez-Vous from Quazal. They then proceeded to make various changes to the library and rebrand it as NEX.</p>
<h4>“Libraries”?</h4>
<p>In the previous sections, I referred to pia and NEX as “libraries”. If you don’t know, a library is a set of code meant to be shared between different programs. You might see where I’m going with this…</p>
<p>Pia and NEX are actually used by multiple games on the 3DS, Wii U, and Switch. They were not built specifically for Splatoon 2. Here’s a selection of software that uses them:</p>
<p><strong>3DS</strong></p>
<ul><li>Friends service (NEX)</li></ul>
<p><strong>Wii U</strong></p>
<ul><li>Splatoon</li><li>Mario Kart 8</li><li>Friends service (NEX)</li></ul>
<p><strong>Switch</strong></p>
<ul><li>Splatoon 2 (yes, this means that Splatoon 2’s netcode is an evolution of Splatoon 1’s)</li><li>Mario Kart 8 Deluxe</li><li>ARMS</li><li>Nintendo Entertainment System – Nintendo Switch Online</li></ul>
<p>As you can see, it’s all first party software. This isn’t an exhaustive list – I’m less familiar with 3DS games, though pia is definitely available for 3DS. Nintendo <em>does</em> provide the libraries to third-party developers but I haven’t seen any third-party games using pia or NEX yet.</p>
<h3>Splatoon 2</h3>
<p>Now that we know the basics, let’s apply our knowledge to Splatoon 2!</p>
<h4>Clones</h4>
<p>Splatoon 2’s netcode is built entirely using a feature of pia called “clones”. A clone is created by a console, and other consoles can “subscribe” to the clone. If the owning console makes changes to the clone, the subscribing consoles are notified of any changes. For example, a clone can be made using a variable called “X”. If the owning console changes X to 5, then all of the subscribers will be notified that the value of X was changed to 5. Splatoon 2 does not use any other method of data synchronization other than clones, though pia supports sending messages directly between consoles without using clones.</p>
<p>There are three types of clones:</p>
<ul><li>Unreliable – changing the clone will cause a notification to be sent to subscribing consoles, but the notification may or may not arrive at the subscribers because of packet loss</li><li>Reliable – a notification will be sent to subscribing consoles, with more being sent if they are not received, guaranteeing synchronization</li><li>Event – clone synchronization is guaranteed, and any data changes in rapid succession are guaranteed to be processed in the order that they were made</li></ul>
<p>Here are some examples of where the various clone types are used:</p>
<ul><li>Unreliable – player position, as the game can interpolate (guess) where the player is heading towards based off their current speed and position if there is data loss</li><li>Reliable – basic player information like their name and equipment, as this information is required to be synchronized between consoles, but the order in which it is received does not matter</li><li>Event – a boss Salmonid spawning in Salmon Run, as other consoles need to know that this happened and the order in which bosses spawn in</li></ul>
<p>In addition, clones have various “access permissions” that can be set:</p>
<ul><li>Send – values can be only set and sent to subscribers with an associated Receive clone</li><li>Receive – values can be only received from an associated Send clone</li><li>Sequential – all consoles can set the values, though because of this an Event clone cannot also be a Sequential clone (impossible to preserve the order of values set)</li><li>Atomic – all consoles can set the values, but only one console can set the value at a time</li></ul>
<p>To keep synchronization, each console starts up a “clone clock”. For Splatoon 2, this clock goes up 120 units per second and continues until the session closes. (For the nerds, an integer overflow wouldn’t happen for a very, very long time. It would be over a year before it overflows assuming that the data type is an unsigned integer.) If the clocks become out of sync, the clocks are resynchronized. This can occur if, for example, there is a sudden spike in CPU load and the game can’t keep up with its refresh rate. This clock value is also occasionally used as a “seed” for the random number generator (RNG), which is used in various in-game actions that involve randomness. </p>
<h4>Tick rate</h4>
<p>The tick rate situation in Splatoon 2 is complicated and marred with controversy. The controversy part mainly comes from <a href="https://web.archive.org/web/20170801024252/https://octo.im/2017/07/31/splatoon-2-online-multiplayer-analysis/">a post by Oliver Brammer</a>, who published an article saying that Splatoon 2 runs at 15.75Hz. This isn’t entirely true.</p>
<p>To start off, the game ticks at 60Hz. (Fun fact – when the game enters the plaza and halves the frame rate, it accomplishes this by lowering the entire tick rate of the game to 30Hz.) Each tick, the game tells pia to send packets, receive packets, and process any events. This means that the netcode also processes at 60Hz. <em>However</em>, Nintendo set a configuration flag that says clone data should only be sent every 4 ticks. This means that the tick rate for sending data is artificially constrained to 15Hz. Normal processing of packets occurs at 60Hz, so receiving and processing clone data runs at “normal speed”.</p>
<p><strong>What does this 15Hz send rate mean?</strong></p>
<p>The pia library will combine packets during the 4 tick waiting period into one big packet at the end. (This coalescing of data explains why Oliver Brammer found an increase of average packet size compared to Splatoon 1.) This waiting period also means that data may arrive at minimum 4 ticks later. However, remember that event clones will always be processed in the order that they occur. Event clones are used for things like player damage, inking the map, and bullet spawning. <em>This may mitigate some of the effects caused by the lower tick rate.</em></p>
<p><strong>Why is Nintendo artificially constraining the tick rate?</strong></p>
<p>This is likely for bandwidth reasons, as Oliver Brammer stated. According to his data, there was a 45% reduction in bandwidth going from Splatoon 1 to Splatoon 2. It could also be for stability reasons. By using less data, it can allow players with less capable Internet connections to be able to play online. This is especially beneficial for mobile hotspots.</p>
<p><strong>How does this compare to Splatoon 1?</strong></p>
<p>Unfortunately, it’s very hard to analyze Splatoon 1’s netcode. Nintendo made it easy for me to analyze Splatoon 2 since they accidentally left debugging information for many versions. Splatoon 1, on the other hand, is essentially a black box. I have found a configuration setting that may be similar to the “waiting period” setting in Splatoon 2, but I have been unable to confirm this. In addition, Splatoon 1 uses a very old version of pia, and there have been several major changes to the library since (mostly relating to how packets are serialized). It would be unfair to do a “direct” comparison between Splatoon 1 and Splatoon 2.</p>
<p>However, I do want to say that I believe Oliver Brammer’s claim that Splatoon 1 had trouble keeping up at 25Hz is incorrect. The fluctuation in data size could be there for other reasons. For example, the waiting period may be set lower, causing clone data to not be coalesced as often. This would result in lower overall packet sizes and data to be sent much more frequently.</p>
<h4>Disconnects</h4>
<p>The game has three …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://oatmealdome.me/blog/splatoon-2s-netcode-an-in-depth-look/">https://oatmealdome.me/blog/splatoon-2s-netcode-an-in-depth-look/</a></em></p>]]>
            </description>
            <link>https://oatmealdome.me/blog/splatoon-2s-netcode-an-in-depth-look/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25993639</guid>
            <pubDate>Mon, 01 Feb 2021 20:44:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Estimates, Design and the Payoff Line]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25993563">thread link</a>) | @nvader
<br/>
February 1, 2021 | https://danverbraganza.com/writings/estimates-design-and-the-payoff-line | <a href="https://web.archive.org/web/*/https://danverbraganza.com/writings/estimates-design-and-the-payoff-line">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content" itemscope="" itemtype="http://schema.org/BlogPosting" itemid="estimates-design-and-the-payoff-line">
        
        
        <p itemprop="about"><i>How inaccuracies in estimation lead to a systematic undervaluing of the importance of Design</i></p>
        <p>
        by  on <i itemprop="datePublished">2021-01-31</i></p>
        <p><span itemprop="articleBody">
          <p>In Martin Fowler's
<a href="https://www.martinfowler.com/bliki/DesignStaminaHypothesis.html">DesignStaminaHypothesis</a>,
he asks the question of when is it worth the time to design properly, and when
it is acceptable to take on tech debt by neglecting design. By neglecting design
and long-term thinking, you're able to take an individual product or feature to
market much faster, but you slow down your overall rate of delivery for the
whole project. The article is great and I encourage you to read it.</p>

<p>From the article, I've reproduced the following graph, with one addition.</p>

<p>Mark calls out the design payoff line, below which you can achieve a faster
delivery by taking on technical debt, but above which technical debt hurts in
the long run. I want to point out how errors in estimation, or driving to
deadlines, can hurt this process.</p>

<figure>
<img src="https://danverbraganza.com/assets/design-hypothesis-annotated.png" title="An annotated graph of cumulative functionality delivered with respect to time">
<figcaption>
Fig. 1: An annotated graph of cumulative functionality delivered with respect to time
</figcaption>
</figure>

<p>I've added two lines to this graph. There's an estimated delivery time, and an
actual one. If we are able to deliver the project on the estimated schedule,
then it apparently makes sense to skip the in-depth design work, since the
amount of cumulative features shipped is higher with the blue line than the red.
However, in this example, if the actual delivery date slips, then you would have
been better off investing in design. At the actual delivery time, the amount of
features shipped by the red line is more than the blue.</p>

<p>The core rub here is that given any estimate of delivery, we should expect the
mean value of the actual delivery to be later than that!<sup id="fnref:0"><a href="#fn:0">1</a></sup> Delivery dates are
dominated by their right tail. Consider that a project can never be delivered
earlier than its start date, but it <em>can</em> be prolonged indefinitely.</p>

<p>This seems like an extreme claim, but my experience bears it out. If it were not
true, we would expect to see at least half of all projects to be delivered
earlier than their deadline. In fact it would need to be the overwhelming
majority delivered ahead of schedule, to make up for the rare but extreme
outliers that miss their estimates. In practice, however, work expands to fill
the time available even in cases where the project is running well.</p>

<p>This means that an attempt to rationally decide whether a project can skip
design and incurr tech debt based on an estimate has a systemic risk. This risk
can blow up and hurt you in two ways. Not only is the project itself now
delayed, but the entire codebase is worse off than if you had chosen a slower
approach. If this project happened to be part of a larger coordinated schedule
that is also time-constrained, well now your problems have only just begun.</p>

<p>I recommend that the next time you feel pressured to incur under-design tech
debt because of a deadline or a low estimate, model out the scenario of what
happens if the actual delivery time slips. If that scenario is unacceptable, it
is worth your while to push back against incurring tech debt.</p>

<p>Remember, slow is smooth, and smooth is fast.</p>

<p>Have a comment? I'd love to hear your thoughts at <a href="https://news.ycombinator.com/item?id=25993563">this thread on Hacker News</a></p>


        </span></p><section>
	  <h4>Other articles you may like</h4>
          <ul>
	    
            <li>
              <b><a href="https://danverbraganza.com/writings/software-names-to-avoid">Names to avoid in Software Engineering</a></b>
	      An incomplete list of poor names for libraries, modules, projects and teams
            </li>
            
            <li>
              <b><a href="https://danverbraganza.com/writings/distributed-circuit-breakers-at-hipmunk">Distributed Circuit Breakers at Hipmunk</a></b>
	      How we implemented Circuit Breakers at Hipmunk to automatically deal with third party outages.
            </li>
            
            <li>
              <b><a href="https://danverbraganza.com/writings/misapplying-lazy-recursive-defaultdict">Misapplying LazyRecursiveDefaultDict</a></b>
	      A cautionary tale of how I misapplied the wrong software tool to a problem, and what I've learned from it.
            </li>
            
          </ul>
	</section>
	
	
	<section>
	This article was filed under:
	<p><span>Software Engineering</span> 
	</p>
	</section>
	
      </div></div>]]>
            </description>
            <link>https://danverbraganza.com/writings/estimates-design-and-the-payoff-line</link>
            <guid isPermaLink="false">hacker-news-small-sites-25993563</guid>
            <pubDate>Mon, 01 Feb 2021 20:39:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Esoteric Programming Languages – The Obscure and Unconventional]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25993381">thread link</a>) | @azhenley
<br/>
February 1, 2021 | https://thecodebytes.com/esoteric-programming-languages/ | <a href="https://web.archive.org/web/*/https://thecodebytes.com/esoteric-programming-languages/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article id="post-863"><header> <img width="1280" height="800" src="https://thecodebytes.com/wp-content/uploads/2020/11/computer-3163436_1280.png" alt="Esoteric Programming Languages" loading="lazy" srcset="https://thecodebytes.com/wp-content/uploads/2020/11/computer-3163436_1280.png 1280w, https://thecodebytes.com/wp-content/uploads/2020/11/computer-3163436_1280-300x188.png 300w, https://thecodebytes.com/wp-content/uploads/2020/11/computer-3163436_1280-1024x640.png 1024w, https://thecodebytes.com/wp-content/uploads/2020/11/computer-3163436_1280-768x480.png 768w" sizes="(max-width: 1280px) 100vw, 1280px" data-srcset="https://thecodebytes.com/wp-content/uploads/2020/11/computer-3163436_1280.png 1280w, https://thecodebytes.com/wp-content/uploads/2020/11/computer-3163436_1280-300x188.png 300w, https://thecodebytes.com/wp-content/uploads/2020/11/computer-3163436_1280-1024x640.png 1024w, https://thecodebytes.com/wp-content/uploads/2020/11/computer-3163436_1280-768x480.png 768w" data-src="https://thecodebytes.com/wp-content/uploads/2020/11/computer-3163436_1280.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></header><section><h2>Introduction</h2> We all know that programming languages can be incredibly useful tools. However, what if there were languages that were not created to be used? Ones that test the boundaries of programming language design and cause even the most experienced programmers to bang their heads against the wall trying to build a simple program? Enter esoteric programming languages.<h2>What Are Esoteric Programming Languages?</h2> Most programming languages are designed for the purpose of widespread use and productivity. However, Esoteric programming languages (esolang) are a segment of programming languages that are not built for usability, but rather for entertainment, artistic intent, or to prove a concept. The word "esoteric" is <a href="https://www.etymonline.com/word/esoteric" target="_blank" rel="noopener noreferrer">derived from the Greek word "esoterikos"</a>, which means “belonging to an inner circle”. Esoteric languages are not intended to be widely understood.<h2>The Purpose of Esoteric Languages</h2> The first-ever esoteric programming language was <a href="http://catb.org/~esr/intercal/" target="_blank" rel="noopener noreferrer">INTERCAL</a>. A parody created by <a href="https://en.wikipedia.org/wiki/Don_Woods_(programmer)" target="_blank" rel="noopener noreferrer">Don Woods</a> and James M. Lyon in 1972 that mimicked popular languages at the time, such as <a href="https://stackoverflow.blog/2020/04/20/brush-up-your-cobol-why-is-a-60-year-old-language-suddenly-in-demand/">COBOL.</a> The idea was later revived in 1993 when Wouter van Oortmerssen designed <a href="http://strlen.com/false-language/" target="_blank" rel="noopener noreferrer">FALSE</a>. The concept was to build a powerful, tiny implementation (compiler executable of 1024 bytes) programming language with an obfuscated syntax that was disorienting to its users. From here, more recognizable names such as <a href="https://esolangs.org/wiki/Brainfuck" target="_blank" rel="noopener noreferrer">brainfuck</a> and <a href="https://esolangs.org/wiki/Befunge" target="_blank" rel="noopener noreferrer">Befunge</a> began to emerge and the concept of esoteric languages began to take shape as a concept.  As previously stated, esoteric languages have four main purposes. To act as a proof of concept, for competitive sport, display an artistic process and simply for entertainment. To better grasp these ideas, let's look into each of them with an example language.<h3>Proof of Concept (Brainfuck)</h3> The first purpose of esoteric languages we are going to look at is proof of concept. A language that was able to present a proof of concept to the computer science community was <a href="https://esolangs.org/wiki/Brainfuck" target="_blank" rel="noopener noreferrer">Brainfuck.</a> A minimalist programming language that contains an astonishing eight characters in total while still proving to be <a href="https://medium.com/@evinsellin/what-exactly-is-turing-completeness-a08cc36b26e2" target="_blank" rel="noopener noreferrer">Turing-complete</a>. The language should not be used for practical projects due to its complexity at scale (as the name suggests). However, it is interesting to see that a programming language can have its utilities with such a small amount of primitives. Here is an example of the language:  <h3>Competitive (Malbolge)</h3> Esoteric languages can also be viewed in a competitive context, such as Malbolge. Languages like Malbolge were created with the sole intent to be exceptionally incomprehensible and difficult to use. Achieved through self-modification, non-intuitive operators and encryption, Malbolge is one of the hardest programming languages to learn. It also very well could be the first of its kind for this purpose in mind. The competition revolving around Malbolge is contained within the premise of the language. That anyone able to make a useful program with Malbolge deserves bragging rights. Here's a sample of how difficult the language is to use.  <h3>Artistic (Shakespeare)</h3> The third purpose of esolang's are for artistic purposes. A popular example of this is the <a href="http://shakespearelang.com/" target="_blank" rel="noopener noreferrer">Shakespeare language</a>. A unique programming language that is meant to resemble the writing from Shakespearean plays. The language is unique, as it redefines the entire programming paradigm. Instead of focusing on producing an intended result, the goal is to make the code itself look more elegant. If only all our code looked as clean as this!  <h3>Entertainment (COW)</h3> Finally, some esoteric programming languages are simply meant to be entertaining.&nbsp; Such as the <a href="https://esolangs.org/wiki/COW" target="_blank" rel="noopener noreferrer">COW language by Sean Heber</a>. As a derivative of the Brainfuck language mentioned above, COW only has 12 primitive. All of which are different capitalizations of the word 'moo'. It's hard to imagine why someone would go through so much effort to create this language. In a way, this comical language really does grasp what programming is all about: incredibly frustrating, a little silly and most importantly, fun.  <h2>The Interesting Thing About Esoteric Languages</h2> So that's pretty much all you need to know about esoteric programming languages. In a strange way, they are like the 'conceptual art' of the programming world. Unconventional and weird, but often thought-provoking and fascinating. Esoteric languages break the recycled formula that most conventional languages follow. Making me believe that these languages could one day be the key to new applications of programming.  Although, if nothing else, they are fascinating designs to look at. Which remain untouched over years, without the over looming necessity to stay 'current' like the majority of popular languages today. Allowing them to only become more interesting with age.  You can check out a full list of esoteric programming languages, <a href="https://esolangs.org/wiki/Language_list" target="_blank" rel="noopener noreferrer">here.</a> If you have anything to add, I would love to hear it in the comment section below!  If you are a programmer that is interested in making passive income, <a href="https://thecodebytes.com/make-passive-income-programming-5-incomes-for-software-developers/">check out this</a>.  Most of the insights I gathered from this post were from <a href="https://esolangs.org/wiki/Main_Page" target="_blank" rel="noopener noreferrer">esolangs.org</a> and <a href="https://morr.cc/esolangs/esolangs.pdf" target="_blank" rel="noopener noreferrer">Esoteric Programming Languages by Sebastian Morr</a>.  Happy coding everyone!  &nbsp;</section></article></div></div>]]>
            </description>
            <link>https://thecodebytes.com/esoteric-programming-languages/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25993381</guid>
            <pubDate>Mon, 01 Feb 2021 20:27:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Weights and Biases raises $45m to build better tools for ML practitioners]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25993297">thread link</a>) | @shcheklein
<br/>
February 1, 2021 | https://wandb.ai/wandb/news/reports/Weights-and-Biases-raises-45m-to-build-better-tools-for-ML-practitioners--Vmlldzo0NDExMTE | <a href="https://web.archive.org/web/*/https://wandb.ai/wandb/news/reports/Weights-and-Biases-raises-45m-to-build-better-tools-for-ML-practitioners--Vmlldzo0NDExMTE">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://wandb.ai/wandb/news/reports/Weights-and-Biases-raises-45m-to-build-better-tools-for-ML-practitioners--Vmlldzo0NDExMTE</link>
            <guid isPermaLink="false">hacker-news-small-sites-25993297</guid>
            <pubDate>Mon, 01 Feb 2021 20:21:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[XRP Pump and Dump]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25993128">thread link</a>) | @yuzugit
<br/>
February 1, 2021 | https://yuzu.dev/2021-02-01/xrp-pump-dump | <a href="https://web.archive.org/web/*/https://yuzu.dev/2021-02-01/xrp-pump-dump">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
  <p><span>Written by</span>
    
        Benjamin Robert
    

    
      <br>
      <span>on&nbsp;</span><time datetime="2021-02-01 00:00:00 +0000">February 01, 2021</time>
    
  </p>

  
  

  

<p><a href="https://en.wikipedia.org/wiki/Ripple_(payment_protocol)"><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAJcAAAB9CAMAAACYngGvAAAAaVBMVEX///8AAADx8fH7+/vs7OzMzMxqamr09PQGBgbf39/o6Og2NjbZ2dmsrKzj4+NHR0eZmZl1dXVdXV1kZGS4uLjAwMArKytNTU1/f3/S0tJYWFimpqYhISHGxsYwMDAbGxsTExONjY09PT0abePRAAAEsUlEQVR4nO1bx2KrQAykYzDNNjHNSRz//0c+E/LikhFoQbtcPFfaoJltWq31biPUlinU8Pu+Zfnwws4QrR1Fy7KaFYlhWs1wsdmsRMyFtDbN/+tYykA7rwMt4gAs5V4zrf2YiAOIiLkaWbkBFNF/vCuBxA4aeWERk+fbImh+fVJCETfR3xuTM5RSEy0o4vlPtHpkMLB6ItbCb2X45ugT3VyF4qzCCn3oE4g4AJt/L90qXdxBQBEHRPCBSpgXjJZNRqtHckSPtJJShtBbH6O0THQX7A7iERk2v5THXGx5oiXeI/qAEZOR0oHRmhJxAO7HZMyPLc+IVo8Ymj93FrNycvTiY8x9PsKtcikxB7fEkX7rGTE0f77M/C6M1qen8o4YvqNSescTPOitnC3igGwLpZzfKnF3umVa/gYPm38uMQ9bfoYAGZZS+QdHXpbPelkm110QHcS8f7S8C7SEolOviKFZL7NbUQabkLKU+DWt+v/9wsE/qmb+EId9US+Nu2il1k30OAsHjxhLydeAaNYLRBwQwt89cd8bn2DABWZNHpaSN9omWMQl49mNGFTiwvFYBi2fi9CihrbHxAsEThO1Yus+B67a7XTisRQ+FSyfX/4CL5DtYMy+If4Z4eU7XiLbBfWVsMAPSKc7HJyusrcFMrFXwHZo2wdBEQfghV+Punz8mFPinLwtuAy9J0ZErMdHnfpNDz+t4fLzJ1pa8qKUlGyMNpMlIMzPhL6cKN4HYGKnMblNZNRY0dKZc6c2dBjR0srqCqK/nEChm5Zlvc2g9aafFjmK05AcqcfgdnASSuDU6XX8PWJypPmDevFMXgkRT8yAlaEURTLNLFBIuQnC6cg5xhVtZ8juAG7c7dHS4rLvYnNux/D8sr6PW1WXvtCCRwKu12PtIL3wwgsvvKAXcVOmXdelZWN2ukUj9ovndfih8Fdm56UtTtxs23S9sbscnxkG5RqkvA5WWjxg0xkPGpV4e9bTwIL2DiXcAoQ4mlPTU8ue7A2J+aayqu1xMpIG4C9pb9Bfbu2pJicGBJq1xFvLDMzfNOYgUrXWDSeNGYFobrS+I6aNWAwrXNk4axrMce3hDzbbvKqqfDs2OB21pFFw8dU3tsV7EjthGDpx8j4yQh01SIlLSK/Yp895GyclBwRxYg3REncJSkm4CZFPP01v8iohw5bPffIJH+6K2+eZNTkYuEB5YiMZbyOPlRsr08KVTVOaNLiKSYwYLhxl1M4RhQRCUuJqA96BATzKi5i/gZZnbr3iTd6zADFs+Zb9PJZysceI02v8PCqxl0p3MCwkcLxTO4yCzwktitgSy08QW2J+X+hAHT4eN1tKueN0OGIzieGTpPM2qrH539emJUhM+nirUHchfxwYr4cVI6bjlLIAMT1nlBdLWWqIVg8cMXYiClduSFSy4Igx0z2YlkxKBkeMRQyL+CVCy7K+5kqJoyVFiyI2GTHdtGYS009rFjG85JOlRREbWYxiWvIpeFzbRhIzE60eShEzFa0eChHDtDottCyr4xIzS4tNzDQtJjGst05aFLEHP69Bi0FsHVqTxBS7OUGMdk2YlpntTDypKtamNUIM0zKyk/kNPIMp/gEDuTul11+UXgAAAABJRU5ErkJggg==" alt="XRP"></a></p>

<p>This week-end, as I was looking at the dogecoin situation, my attention got droven to a new cryptocurrency I didn’t know so far: XRP. I am pretty new to investment and cryptocurrency. Actually, I earnt one bitcoin in 2013 by playing online poker and I sold it for around $300 when the price got “high”. That gives you a pretty good view of my trading skill (for those you don’t know, here’s the current value of one bitcoin: <a href="https://coinmarketcap.com/currencies/bitcoin/">check how much I didn’t win</a>. However I was in the mood to trade a bit but didn’t want to join the $DOGE hype. After a quick research, I discover $XRP from <a href="https://en.wikipedia.org/wiki/Ripple_(payment_protocol)">Ripple</a> and assume that it was a good time to invest in that. By the time I’ve bought (Saturday, 02/30/2021), value was at 0.28€.</p>

<p><img src="https://raw.githubusercontent.com/yuzugit/yuzugit.github.io/master/img/boughtTime.png" alt="What and invest!"></p>


<p>Rumours started to spread all over the web that r/wallstreetbets guys or other groups were going to pump XRP a lot, like what happened with $GME (if you are not familiar with this, check out this article <a href="https://time.com/5933242/gamestop-stock-gme/">on Time.com</a>). During the Sunday, 31, the value started to increase a lot, up to 0,40 in the morning (+61,14%). I started to wonder “Is it a good time to sell?”. Afraid to see the whole bitcoin situation happening again (even if they were no actual factors prouving that) and having invested a really small amount of money, I decided to wait and check out the telegram group and r/xrp.</p>

<p><img src="https://raw.githubusercontent.com/yuzugit/yuzugit.github.io/master/img/xrpValueSunday.jpg" alt="Stonks"></p>


<p>What I saw in the telegram group was really strange. More than 120k of people were on XRP telegram channel, sending memes, asking to “GO TO THE MOON” and “BUY AND HOLD”. Most of them didn’t have a telegram avatar. The hype was getting really strong for a value explosion of XRP, some people prediction $1, others even $4 to $5. I started to look around some books, article and youtube channel during that day and I learnt about “pump and dump” (as said earlier, really new into trading and finance).</p>

<p><img src="https://raw.githubusercontent.com/yuzugit/yuzugit.github.io/master/img/pumpanddump.png" alt="Pump and Dump"></p>

<p><a href="https://en.wikipedia.org/wiki/Pump_and_dump">P&amp;D or Pump and Dump</a> is a model where you manipulate investors (in that case small retail ones) to “pump” a value (meaning pushing a lot of people to invest) via false informations to make profit from the same value you bought before the pump. The “dump” part reflecting the side where big investors sell all of their shares, causing the value to decrease quickly. As in thoses cases, a lot of investors are inexperienced and small, they probably going to panique and sell too before the value crash too much.</p>

<p>In the XRP case, it happen around 0.62 (I speak in euros, it was around .7 in dollars). A lot of people had the false information that a group in germany were going to push the value beyond $1 are people kept buying at 0.5/0.6. Causing them to loose a lot of money during the dump. I was in the telegram group and I don’t know how much is true but people talk about the month rent they invested, life saving and stuff like that. I know and a lot of people who start trading for fun over nights or week-end knows that you must only invest money that you are “confortable” to loose but the call is hard to resist for some.</p>

<p>When I’m writing this article, the value droped -15,90% and still droping. Worthing 0.32€. I didn’t manage the risk a lot and I had the chance to purchase low, before the drop, and to be not too greedy to make a good profit.</p>


<p>Why am I saying all this? Just to say “hey a lot of people got fucked, a small amount of people got rich. I got okay.”. A trying to stay okay is my advice for small investors. The hardest part is to manage risk. You always want to go bigger and try to “reach the moon” and that’s sometimes how you crash into an asteroid (okay that metaphor is wierd). People make fun of me when I tell them I sold a bitcoin for $300 but the point is, I made money off that investment. Sure I could made a lot more and more talented or experienced people have the skills to do that but, to me, the important part is not to loose money. I’ve invested €300 dollars on XRP and still have €300 invested. Maybe they will worth 200 in a couple of weeks/months, maybe they will worth 400. I don’t care that much as I have returned my investment and I can no follow the trends without fear or need. I know it seems like a pretty basic stuff and you can say “okay all that story to tell something as simple as that” but I believe that it’s a game that can make you really passionate and appeal to your lowest instincts. It’s important to stay humble and logical. To know what you are risking. To not only think of the screenshot you will send to your friends saying “hey, I’ve made x10 on that one.”.</p>

<p>Remember that this game is tricky, that some people with a lot of means and money can turn your “big opportunity” into a big loss. Don’t listen too blindly to people that promise you the world or the moon. You invest in something (a currency, a company value, anything), you should be sure that it worth the stock price. But again, I’m just a guy that makes video games.</p>

</div>




    </div></div>]]>
            </description>
            <link>https://yuzu.dev/2021-02-01/xrp-pump-dump</link>
            <guid isPermaLink="false">hacker-news-small-sites-25993128</guid>
            <pubDate>Mon, 01 Feb 2021 20:10:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Decred 1.6 implements Lightning, cryptocurrency mix and decentralized treasury]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25992908">thread link</a>) | @GE56x
<br/>
February 1, 2021 | https://www.explica.co/decred-updates-its-code-and-integrates-the-lightning-network/ | <a href="https://web.archive.org/web/*/https://www.explica.co/decred-updates-its-code-and-integrates-the-lightning-network/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
			



<p>The Decred team announced a few days ago the release of version 1.6 of their software.  It is one of the technological updates that qualify as one of the most important of the project to date, in which the Lightning Network (LN) is integrated into its platform.</p>
<p>Under the name Decrediton, the new version is announced on Decred’s official website.  There it is explained that the new code is already complete, waiting for the next activation.  It will be launched through a consensus vote that will take place when enough stakeholders have updated to the new version.  In that sense, version 1.6 version is now available for download.</p>








<p>New features added to the network with this update include LN integration.  The team highlights the properties of this second-layer micro-payment network, by facilitating<strong> the instant sending of transactions off the blockchain, with low fees.</strong> It is a compatibility that “brings great benefits for scalability and user privacy,” says the publication.</p>
<p>Additionally, in terms of privacy, Decrediton incorporates CoinShuffle ++, a protocol for mixing P2P coins that allows creating CoinJoin transactions, those that use jumps and mixes in order to obfuscate exit addresses.  With that, <strong>the ability to send private transactions on the network is added,</strong> as it is possible for users to mix their cryptocurrencies with those of others.</p>
<p>Once mixed up, tracing the coins back to the original wallet will not be feasible, as explained in the post.  This optional privacy feature had only been available on Decred for more technical users since August 2019.</p>

<p>On the other hand, the new version also supports the use of a new form of VSP (voting service provider), now identified as VSPD.  Its use facilitates <strong>purchase of voting tickets</strong> with mixed cryptocurrencies, which will not be tied to a single address.  “There is no need to register an account with an email address and there is no redemption script to support,” they say.</p>
<p><img loading="lazy" width="700" height="368" alt="" srcset="https://mk0criptonoticijjgfa.kinstacdn.com/wp-content/uploads/2021/01/nueva-version-decred.jpg 700w, https://mk0criptonoticijjgfa.kinstacdn.com/wp-content/uploads/2021/01/nueva-version-decred-300x158.jpg 300w, https://mk0criptonoticijjgfa.kinstacdn.com/wp-content/uploads/2021/01/nueva-version-decred-560x294.jpg 560w" data-lazy-sizes="(max-width: 700px) 100vw, 700px" src="https://mk0criptonoticijjgfa.kinstacdn.com/wp-content/uploads/2021/01/nueva-version-decred.jpg"><img loading="lazy" width="700" height="368" src="https://mk0criptonoticijjgfa.kinstacdn.com/wp-content/uploads/2021/01/nueva-version-decred.jpg" alt="" srcset="https://mk0criptonoticijjgfa.kinstacdn.com/wp-content/uploads/2021/01/nueva-version-decred.jpg 700w, https://mk0criptonoticijjgfa.kinstacdn.com/wp-content/uploads/2021/01/nueva-version-decred-300x158.jpg 300w, https://mk0criptonoticijjgfa.kinstacdn.com/wp-content/uploads/2021/01/nueva-version-decred-560x294.jpg 560w" sizes="(max-width: 700px) 100vw, 700px">The new software version implements Lightning, cryptocurrency mix and decentralized treasury.  Source: Decred.org</p>
<p>VSPs had already been implemented in June 2020 at Decred.  As CriptoNoticias reported at the time, the main objective of this implementation is <strong>provide users with greater privacy.</strong> However, until now it was only tested as a custom client tool, not suitable for everyday use.</p>
<h2 id="h-avances-en-la-descentralizaci-n-de-la-tesorer-a-de-decred">Advances in the decentralization of Decred’s Treasury</h2>
<p>With the release of version v1.6, the project takes a new step in the <strong>decentralization process of its treasury.</strong> Decrediton delivers a higher level of participation to its community of stakeholders, the people who vote to decide on changes to the consensus rules and governance, as well as on treasury and policy issues of the blockchain platform.</p>
<p>“When the code is activated (after the community completes the update), all Decred stakeholders will have the power to veto or approve all expenses from the treasury,” the team says on its website.</p>

<p>In 2018, the project gave the community the power to vote on how treasury funds are spent with the launch of Politeia, its off-chain proposal system.  But now, if the new voting system is approved, stakeholders <strong>they will be able to review the movements every month</strong> to vote for approval or rejection, through your wallet.  The aim of this process is to give greater transparency to treasury spending and to eliminate the risk of theft of funds, increasing security levels.</p>
<p>The Decred project was born more than three years ago as a proposal based on community participation.  It uses a hybrid mining algorithm between Proof of Work (PoW) and Proof of Stake (POS).  At the time of writing this article, the price of the network’s native cryptocurrency, DCR, is USD 67.88, with a rise of 27% in the last 7 days in Live Coin Watch data.</p>




<!-- AI CONTENT END 1 -->
		</div></div>]]>
            </description>
            <link>https://www.explica.co/decred-updates-its-code-and-integrates-the-lightning-network/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25992908</guid>
            <pubDate>Mon, 01 Feb 2021 19:55:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Craig Hunter Exits Sony Pictures TV to Join YouTube]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25992825">thread link</a>) | @sodrick
<br/>
February 1, 2021 | https://relayvibe.co/craig-hunter-is-leaving-sony-pictures-tv | <a href="https://web.archive.org/web/*/https://relayvibe.co/craig-hunter-is-leaving-sony-pictures-tv">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1651">
	
		<div>
<figure>
<img src="https://i1.wp.com/relayvibes.co/wp-content/uploads/2021/02/Craig-Hunter-Is-Leaving-Sony-Pictures-TV.jpg?resize=678%2C381&amp;ssl=1" alt="Craig Hunter Is Leaving Sony Pictures TV" title="">
</figure>

<div><p><a href="https://relayvibes.co/tag/Youtube">Youtube</a> has added to its system the Director of Kids Networks at <a href="https://relayvibes.co/tag/sonypicturestelevision">Sony Pictures Television</a>, <a href="https://relayvibes.co/tag/craighunter">Craig Hunter</a>. He will head( as the global head) the YouTube Originals Preschool Content.</p>
<p>Hunter is currently in London, he is leaving planning to leave for Unites States, LA to be precise, this summer. This is a newly created role and as the Global head of Preschool Content, he will be reporting to Nadine Zylstra, Head of Family Learning and Impact for YouTube Originals.</p>
<p>All preschool content that falls around the kids and families vertical covering scripted and unscripted programming will be under his management.</p>
<p>Zylstra commended Craig in a statement as highly skilled and experienced international content specialist in kids and family space. “His experience and creative background will help lead us in our commitment to invest in the future of quality kids, family and educational programming — as part of the $100 million commitment to original content that we announced.”</p>
<p>Spent almost 9 years with Sony Pictures, Hunter has been managing Sony Pictures Television’s kids’ linear and VOD brands, content acquisitions, commissioning, programming and strategy all around the UK. He was also in charge for the Pop brand. Hunter, who is a Bachelor of Arts (Hons) in graphic design and advertising from Buckinghamshire New University, started his career with Disney after which he moved on to work at BBC Studios. Later he went to Nickelodeon where he spent more than 6<a href="https://finance.yahoo.com/finance/news/youtube-hires-sony-pictures-tv-173131614.html#:~:text=Variety-,YouTube%20Hires%20Sony%20Pictures%20TV%20Exec%20Craig,Head%20Preschool%20Kids'%20Original%20Content&amp;text=YouTube%20tapped%20veteran%20executive%20Craig,the%20internet%20platform's%20originals%20team." target="_blank" rel="noopener"> years</a> .</p>

</div>

	</div><div id="text-13">			<p><img loading="lazy" src="https://i0.wp.com/relayvibes.co/wp-content/uploads/2020/08/ad-300x250-mh-magazine-3.png?resize=300%2C250" alt="" width="300" height="250" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/relayvibes.co/wp-content/uploads/2020/08/ad-300x250-mh-magazine-3.png?resize=300%2C250&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
		</div></article></div>]]>
            </description>
            <link>https://relayvibe.co/craig-hunter-is-leaving-sony-pictures-tv</link>
            <guid isPermaLink="false">hacker-news-small-sites-25992825</guid>
            <pubDate>Mon, 01 Feb 2021 19:50:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Killing Containers at Scale]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25992627">thread link</a>) | @amasad
<br/>
February 1, 2021 | https://blog.repl.it/killing-containers-at-scale | <a href="https://web.archive.org/web/*/https://blog.repl.it/killing-containers-at-scale">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>To make it so that anyone with a web browser can code on Replit, our backend infrastructures runs on preemptible VMs. That means the computer running your code can shutdown at any time! We've made it really fast for repls to reconnect when that happens. Despite our best efforts, though, people had been seeing repls stuck connecting for a long time. After some profiling and digging into the Docker source code, we found and fixed the problem. Our session connection error rate dropped from 3% to under 0.5% and our 99th percentile session boot time dropped from 2 minutes to 15 seconds.</p>
<p>There were many different causes of stuck repls, varying from: unhealthy machines, race conditions that lead to deadlock, and slow container shutdowns. This post focuses how we fixed the last cause, slow container shutdowns. Slow container shutdowns affected nearly everyone using the platform and would cause a repl to be inaccesible for up to a minute.</p>
<h3 id="replit-architecture">Replit Architecture</h3>
<p>Before going in depth on fixing slow container shutdowns, you'll need some knowledge of Replit's architecture.</p>
<p>When you open a repl, the browser opens a websocket connection to a Docker container running on a preemptible VM. Each of the VMs run something we call <code>conman</code>, which is short for container manager.</p>
<p>We must ensure that there is only a single container per repl at anytime. The container is used to facilitate multiplayer features, so its important that every user in the repl connects to the same container.</p>
<p>When a machine that hosts these Docker containers shuts down, we have to wait for each container to be destroyed before they can be started again on some other machine. Since we use preemptible instances, this process happens frequently.</p>
<p>Below you can see the typical flow when trying to access a repl on a mid-shutdown instance.</p>
<p><img src="https://blog.repl.it/images/destroying-stuck-repls/simplified_arch.png" alt="Simplified diagram of repl.it conman architecture"></p>
<ol>
<li>A user opens their repl which opens the IDE and attempts to connect to the backend evaluation server via a WebSocket.</li>
<li>The request hits a load balancer which selects a conman instance to proxy to based on CPU usage.</li>
<li>A healthy, living conman gets the request. Conman notices that the request is for a container that is living on a different conman and proxies the request there.</li>
<li>Sadly this conman is shutting down and rejects the WebSocket connection!</li>
</ol>
<p>Requests will continue to fail until either:</p>
<ol>
<li>The docker container is shut down and the repl container entry in the global store is removed.</li>
<li>Conman finishes shutting down and is no longer accessible. In this case, the first conman will remove the old repl container entry and start a new container.</li>
</ol>
<h3 id="slow-container-shutdowns">Slow Container Shutdowns</h3>
<p>Our preemptible VMs are given 30 seconds to cleanly shutdown before they are forcibly terminated. After some investigation, we found that we rarely finished shutting down within those 30 seconds. This prompted us to dig further and instrument the machine shutdown routine.</p>
<p>After adding some more logging and metrics around machine shutdowns, it became clear that calls to <code>docker kill</code> were taking much longer than expected. <code>docker kill</code> usually took a few milliseconds to kill a repl container during normal operation, but we spent 20+ seconds killing 100-200 containers at the same time during shutdown.</p>
<p>Docker offers two ways to stop a container: <code>docker stop</code> and <code>docker kill</code>. Docker stop sends a <code>SIGTERM</code> signal to the container and gives it a grace period to gracefully shutdown. If the container doesn't shutdown within the grace period, the container is sent <code>SIGKILL</code>. We don't care about gracefully shutting down the container and would rather shut it down as quickly as possible. <code>docker kill</code> sends <code>SIGKILL</code> which should kill the container immediately. For some reason, the theory did not match reality, <code>docker kill</code> shouldn't be taking on the order of seconds to <code>SIGKILL</code> the container. There must be something else going on.</p>
<p>To dig into this, here is a script which will create 200 docker containers and time how long it takes to kill them at the same time.</p>
<pre><code><span>#!/bin/bash
</span>
COUNT=200
<span>echo</span> <span>"Starting <span>$COUNT</span> containers..."</span>
<span>for</span> i <span>in</span> $(seq 1 <span>$COUNT</span>); <span>do</span>
    <span>printf</span> .
    docker run -d --name <span>test</span>-<span>$i</span> nginx &gt; /dev/null 2&gt;&amp;1
<span>done</span>

<span>echo</span> -e <span>"\nKilling <span>$COUNT</span> containers..."</span>
time $(docker <span>kill</span> $(docker container ls -a --filter <span>"name=test"</span> --format <span>"{{.ID}}"</span>) &gt; /dev/null 2&gt;&amp;1)

<span>echo</span> -e <span>"\nCleaning up..."</span>
docker rm $(docker container ls -a --filter <span>"name=test"</span> --format <span>"{{.ID}}"</span>) &gt; /dev/null 2&gt;&amp;1</code></pre>
<p>Running this on the same kind of VM we run in production, a GCE n1-highmem-4 instance, yields:</p>
<pre><code>Starting 200 containers...
................................&lt;trimmed&gt;
Killing 200 containers...

real    0m37.732s
user    0m0.135s
sys     0m0.081s

Cleaning up...</code></pre><p>This confirmed our suspicions that something is going in inside the Docker runtime which causes shutdowns to be so slow. Time to dig into Docker itself...</p>
<p>Docker daemon has an option to <a href="https://docs.docker.com/config/daemon/#enable-debugging">enable debug logging</a>. These logs let us peak into what what's happening inside of dockerd and each entry has a timestamp so it might provide some insight into where all this time is being spent.</p>
<p>With debug logging enabled, let's rerun the script and look at dockerd's logs. This will output a lot of log messages since we are dealing with 200 container, so I've hand-selected portions of the logs that are of interest.</p>
<pre><code>2020-12-04T04:30:53.084Z    dockerd    Calling GET /v1.40/containers/json?all=1&amp;filters=%7B%22name%22%3A%7B%22test%22%3Atrue%7D%7D
2020-12-04T04:30:53.084Z    dockerd    Calling HEAD /_ping
2020-12-04T04:30:53.468Z    dockerd    Calling POST /v1.40/containers/33f7bdc9a123/kill?signal=KILL
2020-12-04T04:30:53.468Z    dockerd    Sending kill signal 9 to container 33f7bdc9a1239a3e1625ddb607a7d39ae00ea9f0fba84fc2cbca239d73c7b85c
2020-12-04T04:30:53.468Z    dockerd    Calling POST /v1.40/containers/2bfc4bf27ce9/kill?signal=KILL
2020-12-04T04:30:53.468Z    dockerd    Sending kill signal 9 to container 2bfc4bf27ce93b1cd690d010df329c505d51e0ae3e8d55c888b199ce0585056b
2020-12-04T04:30:53.468Z    dockerd    Calling POST /v1.40/containers/bef1570e5655/kill?signal=KILL
2020-12-04T04:30:53.468Z    dockerd    Sending kill signal 9 to container bef1570e5655f902cb262ab4cac4a873a27915639e96fe44a4381df9c11575d0
...</code></pre><p>Here we can see the requests to kill each container, and that <code>SIGKILL</code>is sent almost immediately to each container.</p>
<p>Heres some log entries seen around 30 seconds after executing <code>docker kill</code>:</p>
<pre><code>...
2020-12-04T04:31:32.308Z    dockerd    Releasing addresses for endpoint test-1's interface on network bridge
2020-12-04T04:31:32.308Z    dockerd    ReleaseAddress(LocalDefault/172.17.0.0/16, 172.17.0.2)
2020-12-04T04:31:32.308Z    dockerd    Released address PoolID:LocalDefault/172.17.0.0/16, Address:172.17.0.2 Sequence:App: ipam/default/data, ID: LocalDefault/172.17.0.0/16, DBIndex: 0x0, Bits: 65536, Unselected: 65529, Sequence: (0xfa000000, 1)-&gt;(0x0, 2046)-&gt;(0x1, 1)-&gt;end Curr:202
2020-12-04T04:31:32.308Z    dockerd    Releasing addresses for endpoint test-5's interface on network bridge
2020-12-04T04:31:32.308Z    dockerd    ReleaseAddress(LocalDefault/172.17.0.0/16, 172.17.0.6)
2020-12-04T04:31:32.308Z    dockerd    Released address PoolID:LocalDefault/172.17.0.0/16, Address:172.17.0.6 Sequence:App: ipam/default/data, ID: LocalDefault/172.17.0.0/16, DBIndex: 0x0, Bits: 65536, Unselected: 65530, Sequence: (0xda000000, 1)-&gt;(0x0, 2046)-&gt;(0x1, 1)-&gt;end Curr:202
2020-12-04T04:31:32.308Z    dockerd    Releasing addresses for endpoint test-3's interface on network bridge
2020-12-04T04:31:32.308Z    dockerd    ReleaseAddress(LocalDefault/172.17.0.0/16, 172.17.0.4)
2020-12-04T04:31:32.308Z    dockerd    Released address PoolID:LocalDefault/172.17.0.0/16, Address:172.17.0.4 Sequence:App: ipam/default/data, ID: LocalDefault/172.17.0.0/16, DBIndex: 0x0, Bits: 65536, Unselected: 65531, Sequence: (0xd8000000, 1)-&gt;(0x0, 2046)-&gt;(0x1, 1)-&gt;end Curr:202
2020-12-04T04:31:32.308Z    dockerd    Releasing addresses for endpoint test-2's interface on network bridge
2020-12-04T04:31:32.308Z    dockerd    ReleaseAddress(LocalDefault/172.17.0.0/16, 172.17.0.3)
2020-12-04T04:31:32.308Z    dockerd    Released address PoolID:LocalDefault/172.17.0.0/16, Address:172.17.0.3 Sequence:App: ipam/default/data, ID: LocalDefault/172.17.0.0/16, DBIndex: 0x0, Bits: 65536, Unselected: 65532, Sequence: (0xd0000000, 1)-&gt;(0x0, 2046)-&gt;(0x1, 1)-&gt;end Curr:202</code></pre><p>These logs don't give us a full picture of everything dockerd is doing, but this makes it seem like dockerd might be spending a lot of time releasing network addresses.</p>
<p>At this point in my adventure, I decided it was time to start digging into docker engine's source code and build my own version of dockerd with some extra logging.</p>
<p>I started out by looking for the codepath that handles container kill requests. I added some extra log messages with timings of different spans and eventually I found out where all this time was being spent:</p>
<p><code>SIGKILL</code> is sent to the container and then before responding to the HTTP request, the engine waits for the container to no longer be running (<a href="https://github.com/docker/engine/blob/ab373df1125b6002603456fd7f554ef370389ad9/daemon/kill.go#L174">source</a>)</p>
<pre><code>    &lt;-container.Wait(context.Background(), containerpkg.WaitConditionNotRunning)</code></pre><p>The <code>container.Wait</code> function returns a channel which receives the exit code and any error from the container. Unfortunately, to get the exit code and error, a lock on the interal container struct must be acquired. (<a href="https://github.com/docker/engine/blob/ab373df1125b6002603456fd7f554ef370389ad9/container/state.go#L212-L233">source</a>)</p>
<pre><code>  ...

    <span>go</span> <span><span>func</span><span>()</span></span> {
        <span>select</span> {
        <span>case</span> &lt;-ctx.Done():
            
            resultC &lt;- StateStatus{
                exitCode: <span>-1</span>,
                err:      ctx.Err(),
            }
            <span>return</span>
        <span>case</span> &lt;-waitStop:
        <span>case</span> &lt;-waitRemove:
        }

        s.Lock() 
        result := StateStatus{
            exitCode: s.ExitCode(),
            err:      s.Err(),
        }
        s.Unlock()

        resultC &lt;- result
    }()

    <span>return</span> resultC

  ...</code></pre>
<p>As it turns out, this container lock is held while cleaning up network resources and the <code>s.Lock()</code> above ends up waiting for a long time. This happens inside <a href="https://github.com/docker/engine/blob/ab373df1125b6002603456fd7f554ef370389ad9/daemon/monitor.go#L27-L103"><code>handleContainerExit</code></a>. The container lock is held for the duration of the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.repl.it/killing-containers-at-scale">https://blog.repl.it/killing-containers-at-scale</a></em></p>]]>
            </description>
            <link>https://blog.repl.it/killing-containers-at-scale</link>
            <guid isPermaLink="false">hacker-news-small-sites-25992627</guid>
            <pubDate>Mon, 01 Feb 2021 19:33:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fast Incremental Builds with Speculation and Cancellation]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25992590">thread link</a>) | @stuhood
<br/>
February 1, 2021 | https://blog.pantsbuild.org/fast-incremental-builds-speculation-cancellation/ | <a href="https://web.archive.org/web/*/https://blog.pantsbuild.org/fast-incremental-builds-speculation-cancellation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<!--kg-card-begin: html--><!--kg-card-end: html--><!--kg-card-begin: markdown-->
<p>Because they decouple your iteration time from the total size of your codebase, fast incremental re-builds are critical in large codebases and monorepos. As discussed in <a href="https://blog.pantsbuild.org/dependency-inference/">our post about dependency inference</a>, having fine-grained dependency information reduces the amount of work that is invalidated after an edit by ignoring irrelevant changes.</p>
<p>But modern build tools are also able to avoid wasted work when a file that your build depends on <em>has</em> (maybe!) changed. And thanks to its deep support for cancellation and side-effect free execution model, <a href="https://www.pantsbuild.org/">Pants</a> is able to further reduce re-build latency by speculatively re-executing work!</p>

<p>In many cases while building your code, files will change in ways that don’t actually affect the outcome of the build. Common examples are cases like changing comments in compiled or code-generated languages (Java and Protobuf, for example), or touching files on disk without actually editing their contents. In these cases, avoiding running the dependent compiles or other logic is a significant benefit.</p>
<p>Pants uses SHA256 hashing and deep equality to determine whether <code>@rules</code> (used to write <a href="https://www.pantsbuild.org/docs/rules-api-concepts">build logic in Pants</a>) and processes need to re-run, but because build processes should always be deterministic, we can more quickly provide incremental results in these cases. To do so, Pants supports what the <a href="https://www.microsoft.com/en-us/research/uploads/prod/2018/03/build-systems.pdf">Build Systems à la Carte</a> paper calls “early cutoff”.</p>
<p>Early cutoff (also known as “cleaning”) is implemented in Pants by deciding whether to re-run an <code>@rule</code> (after a file that it depends on -- likely indirectly -- has changed on disk) by comparing a record of previous “generation” values for each dependency <code>@rule</code> to up-to-date generation values. This generation value is incremented each time the previous output value of a <code>@rule</code> is not identical to its new output value: it acts as a very memory efficient record of which versions of its dependencies an <code>@rule</code> used. When the generation values of all of an <code>@rule</code>s dependencies are equal to those from its previous run, we know that it does not need to re-run, and that its previous output value is still valid. When <code>@rule</code>s are cleaned this way, it’s very likely that their dependents in the graph will be cleaned as well, which “cuts off” the need to run any <code>@rule</code> logic, dramatically reducing runtime.</p>
<p>Pants’ dependency inference (for Python; elsewhere soon!) also presents a really useful case for early cutoff. Dependency inference extracts import statements from the content of individual files, but while editing your code, the vast majority of your edits to files will be to non-import statements. This means that the dependency inference <code>@rule</code>s will very frequently trigger early cutoff!</p>

<p>But the combination of dependency inference and cleaning is interesting for another reason: because the dependencies of your code fundamentally drive “which” <code>@rule</code> logic needs to run (“what do I need to compile before compiling this module?”, “which files need to be in the sandbox for this test?”, etc), the output of the dependency inference <code>@rule</code>s will very frequently be a <a href="https://en.wikipedia.org/wiki/Data_dependency">data dependency</a> of other <code>@rule</code> logic … and dependency inference represents a very fundamental data dependency!</p>
<p>Neil Mitchell’s <a href="https://neilmitchell.blogspot.com/2020/11/data-types-for-build-system-dependencies.html">excellent blog post on the topic of dependencies in build systems</a> introduces a particularly costly example of ignoring a data dependency: a computed “is_optimized” flag might fundamentally affect which (and how much!) work needs to be done in a build. If between two builds, the computed value of <code>is_optimized</code> changes from <code>True</code> to <code>False</code> (potentially representing an order of magnitude difference in runtime), it’s particularly critical that a user does not need to wait for the stale result before the updated result is computed.</p>
<p>Pants’ monadic plugin API allows <code>@rule</code> authors to write natural, seemingly imperative code. But as described in Mitchell’s post, the existence of data dependencies between <code>@rule</code> outputs in a monadic build system would suggest that Pants needs to be careful to clean a graph of <code>@rule</code>s in the order that dependencies were originally requested in. And dependency inference is no exception: in the build after an import statement has been removed from your code, Pants must not force you to wait for that removed dependency to be rebuilt!</p>
<p>But this is potentially problematic: data dependencies are costly because they force ordering. Dependency inference requires parsing the AST of your code to extract import statements: a data dependency between extracting the imports of a file and running a test in that file (for example), implies that while cleaning the <code>@rule</code> graph after that file has changed, we should not start running the test until after we’ve finished extracting imports. And as mentioned before, the imports of your test file are much less likely to have changed than its other content, meaning that an infrequently changing output blocks computing the key result of your build: whether your test passed!</p>
<!--kg-card-end: markdown--><!--kg-card-begin: html--><!--kg-card-end: html--><!--kg-card-begin: markdown--><p>This represents an interesting challenge: is it possible for Pants to preserve the excellent usability properties of dependency inference (avoiding needing to maintain redundant, potentially-stale copies of your import statements in both your code and in <code>BUILD</code> files), without forcing the running of a test to wait for import parsing? Yes, we can: via speculative execution!</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown-->
<p><a href="https://en.wikipedia.org/wiki/Speculative_execution">Speculative execution</a> (aka “speculation”) is a technique used (somewhat infamously: more on that later) in CPUs, but which is also employed when sending RPCs in distributed systems (where it might be referred to as using <a href="https://blog.acolyer.org/2015/01/15/the-tail-at-scale/">hedged requests</a>).</p>
<p>Applying speculative execution to reducing the cost of data dependencies means applying prior knowledge about the likelihood that a data-dependency will have a particular output value to decide to eagerly launch a data-dependent task with the predicted input <em>before</em> its data-dependency has completed. Concretely: it means being able to launch the extraction of imports <em>and</em> the running of the test <em>in parallel</em>!</p>
<p>And so: Pants uses its record of the generation values of the previous build to <a href="https://github.com/pantsbuild/pants/pull/11308">clean the <code>@rule</code> graph speculatively</a>, sidestepping the data dependency in incremental rebuilds!</p>
<!--kg-card-end: markdown--><!--kg-card-begin: html--><!--kg-card-end: html--><!--kg-card-begin: markdown-->
<p>To ensure correctness, safe speculation requires that speculated work never has side-effects (which is where speculation in CPUs <a href="https://en.wikipedia.org/wiki/Speculative_execution#Security_vulnerabilities">went astray</a>). And reducing speculation’s costs requires the ability to quickly and cleanly cancel speculated work when you determine that your guesses were incorrect.</p>
<p>Fortunately, both purity (the absence of side-effects) and interruptibility are already fundamental to the architecture of Pants 2.0!</p>
<h2 id="pure">Pure</h2>
<p>Pants’ <code>@rule</code> API was designed from the ground up to be side-effect free. With the exception of specially classified “Goal” rules (which “finalize” the run from an end user’s perspective), <code>@rule</code>s are intended to be <a href="https://en.wikipedia.org/wiki/Pure_function">pure</a> coroutines.</p>
<p><code>@rule</code>s consume specialized APIs that present <a href="https://www.pantsbuild.org/v2.2/docs/rules-api-file-system">an atomic, read-only view of the filesystem</a>, and precise tracking of <code>@rule</code> dependencies (down to the level of syscalls to expand symlinks, etc) ensures that -- although the filesystem might look like a global static -- the relevant <code>@rule</code>s can be restarted in cases where files change during a run to preserve atomicity guarantees.</p>
<p>Build tools <a href="https://www.microsoft.com/en-us/research/uploads/prod/2018/03/build-systems.pdf">“excel”</a> at running processes: your typechecker, compiler, code generator, test, etc. But most processes that run during your build produce outputs, and ensuring that these outputs are not observable side-effects is an interesting challenge! To isolate processes, Pants fundamentally operates on content-addressable collections of files (known as <code>Snapshots</code>, and implemented using the Bazel <a href="https://github.com/bazelbuild/remote-apis/blob/9e72daff42c941baaf43a4c370e2607a984c58a7/build/bazel/remote/execution/v2/remote_execution.proto#L819-L857">Remote APIs</a>) rather than on filesystem state. This means that process inputs and outputs are always immutable values, and never references into a mutable store like the filesystem.</p>
<p>Rather than writing out the results of processes into a shared mutable working directory as is common in many build tools, Pants stores all process inputs and outputs in a database (backed locally by <a href="https://symas.com/lmdb/">LMDB</a>, and remotely by a Remote API <a href="https://github.com/bazelbuild/remote-apis/blob/9e72daff42c941baaf43a4c370e2607a984c58a7/build/bazel/remote/execution/v2/remote_execution.proto#L185-L257">CAS</a> instance), and executes processes inside of chroots. Only the final results that a user directly requested via a high level “goal” (<code>fmt</code>, <code>test</code>, <code>package</code>, etc) are actually materialized as a visible side-effect in their workspace.</p>
<p>This fundamental isolation is critical to speculation, because it means that Pants can always spawn multiple copies of processes, without worrying that they will collide or otherwise observe one-another’s results!</p>
<h2 id="interruptible">Interruptible</h2>
<p>Being free of side-effects eliminates one common challenge of providing interruptibility: there is no need to “clean up” after canceled processes, because their execution could not affect any mutable resources in ways that might need to be reverted. But the other requirement is ensuring that you don’t waste CPU time on those trees as they fall in that unobserved forest: and cancelling work once you’ve launched it can be, in-and-of-itself, tricky.</p>
<p>Native threads in all common operating systems are eager: once you’ve launched them they run to completion, killing them without their cooperation is a <a href="https://unix.stackexchange.com/questions/403988/how-to-kill-an-individual-thread-under-a-process-in-linux">risky proposition</a>, and getting their cooperation at a fine-grained level would require peppering your code with “<code>is_it_time_to_give_up()</code>?” checks.</p>
<p>Luckily, the core of Pants is written in Rust, and -- rather than using native threads -- uses <a href="https://tokio.rs/">tokio</a> to support running thousands of lightweight user-space tasks. Due to their <a href="https://rust-lang.github.io/async-book/02_execution/02_future.html">pull-based/lazy</a> design, Rust Futures (which back its excellent <code>async/await</code> feature) are inherently cancellable: with <a href="https://docs.rs/tokio/1.0.1/tokio/fn.spawn.html">rare</a> and <a href="https://docs.rs/tokio/1.0.1/tokio/process/index.html#droppingcancellation">well-noted</a> exceptions, dropping a <code>Future</code> value recursively cancels all associated work at its next <code>await</code>.</p>
<p>And because we use tokio to spawn processes, receive UNIX signals, interact with the filesystem, communicate with remote servers, etc, this deep support for cancellation pervades Pants’ APIs, and continuously minimizes the overhead of speculation.</p>
<p>Another very visible feature enabled by inherent support for cancellation is getting the expected behavior when a user running Pants …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.pantsbuild.org/fast-incremental-builds-speculation-cancellation/">https://blog.pantsbuild.org/fast-incremental-builds-speculation-cancellation/</a></em></p>]]>
            </description>
            <link>https://blog.pantsbuild.org/fast-incremental-builds-speculation-cancellation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25992590</guid>
            <pubDate>Mon, 01 Feb 2021 19:30:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Disinformation: The Game of Belief is now a War]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25992531">thread link</a>) | @ztratar
<br/>
February 1, 2021 | https://www.zachtratar.com/Disinformation-The-Game-of-Belief-is-now-a-War.html#.YBhVpHdKjUI | <a href="https://web.archive.org/web/*/https://www.zachtratar.com/Disinformation-The-Game-of-Belief-is-now-a-War.html#.YBhVpHdKjUI">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>A mass hijacking of our minds is currently underway. Perhaps you’ve felt it for a while now.</p>

<p>Underlying facts seem increasingly rare, “the truth” is debated back and forth without progress, and people’s behaviors continuously bend towards the irrational. It’s all so weirdly ironic — aren’t we supposed to be living in the so-called “Information Age”?</p>

<p>What the heck happened?</p>

<p>Well, we’re all human &amp; sometimes believe in things that aren’t true. It’s a complicated psychological weakness — after all, “what is truth” is a hard question! As we seek truth as individuals, we’re lucky that most of our personal misjudgments are unique and relatively harmless. At scale, however, people have learned our psychology becomes predictable. And exploitable.</p>

<p>Individuals and organizations — especially the media, political parties and politicians — above all seek to increase their power and status. Thus, in their communication, their primary goal is not to tell the truth or describe reality, but instead to win the game they are playing. This incentive leads them to build their audience by engaging in disinformation campaigns and “<em>Narrative Warfare”</em> tactics<em>.</em> They create stories &amp; perceptions — some real, some fake — to manipulate our emotions and align us with <em>their</em> narrative &amp; <em>their</em> goals.</p>

<p>Information, reality, and truth… none of them really matter as long as we end up joining their side and reinforcing their power.</p>

<p>Although mass manipulation is a trend throughout all of history, it turns out that giving everyone smartphones and instant access to every other human <em>changes everything</em>. The internet is jet fuel. Through Facebook and online media, disinformation now spreads to millions within minutes, is targeted to the specific people who will believe it, and evolves social groups to purge skeptics.</p>

<p>Over time, these attacks on our information ecosystem turn many people into fact-resistant conspiracy theorists and radicals — their identity and daily thoughts become dominated by a tribal battles they believe they are fighting. Once enough people radicalize, Politicians need their votes and are forced to radicalize as well to get elected. Finally, the cycle completes: once in power, politicians opt to accelerate Narrative Warfare to reinforce their power instead of summoning the courage to lead. This is what we have seen play out in the US over the past decade and it’s a downward spiral we must reverse. It threatens the core foundations of successful democracy: empathy, collaboration, useful debate, and truthful speech.</p>

<p>Unfortunately, <a href="https://www.zachtratar.com/voter-fraud-debunk.html#.YBcYCelKjUI">I’ve met these politicians</a> and observed these social patterns. From 2008 to 2010 I founded a political polling company and learned how political parties didn’t just want your data — they wanted to know who your family was, how to convince you of things, and which buttons to push. I got out of politics. Then, from 2011 to 2014 I was the first employee at a well-funded social media startup. We walked into the office every day desiring to “create community”, and even though some of us were educated in psychology, we were totally naive. No where in our heads did we imagine the acceleration of misinformation and disinformation at scale. While we only reached millions of people, Facebook successfully spread to billions and doubled-down on exploitable technologies.</p>

<p>So now we’re all living in manipulated realities, attacking each other on a daily basis, and often resorting to conspiratorial thinking. To get out of this, we all have a responsibility to grow wiser to “truth”, mitigate tribalism and take back control of our minds.</p>

<p>First, let’s start by better understanding the war we’re in.</p>

<h2 id="table-of-contents">Table of Contents</h2>

<ol>
  <li>Complexity of Truth</li>
  <li>Psychology of Truth</li>
  <li>Group Dynamics of Truth</li>
  <li>Societal Truth</li>
  <li>The Game of Belief</li>
  <li>Narrative Warfare</li>
  <li>Technological Acceleration</li>
  <li>What Next?</li>
</ol>

<h2 id="complexity-of-truth">Complexity of Truth</h2>

<p>We attempt to determine truth as individuals by making judgements, and these judgements are all based on information we encounter in various forms (e.g. school, books, facebook posts, conversations, etc.</p>

<p>Truth is complex and tricky, though — philosophers call its study “<a href="https://plato.stanford.edu/entries/epistemology/">epistemology</a>,” which roughly translates to “the reason of knowledge and understanding”.</p>

<blockquote>
  <p>“Any fool can know. The point is to understand”</p>

  <p><span><em>-</em> Albert Einstein</span></p>
</blockquote>

<p>To know “the truth” you need not only good information, but all of the context required to create a full understanding. Without context, you are viewing only one piece to a larger puzzle. Most communication — especially short-form communication on the internet — is missing substantial context, which leads to misinterpretation.</p>

<p>Ask yourself two questions:</p>

<ul>
  <li>How often are your words on the internet fully understood and interpreted correctly by other people?</li>
  <li>How often do you think, when you’re reading the news, you’re getting robust context?</li>
</ul>

<p>The more complex a topic — like hedge fund market dynamics — the more context is necessary to create a full understanding. Since civilization is advanced, the problems of the world are all quite complex, and people need to spend the extra care to gather context. With some topics, such as “building a growing economy”, the complexity is so staggeringly high that no single human can ever understand the entire problem. Literally <em>no one knows the full truth.</em></p>

<blockquote><p lang="en" dir="ltr">History of epistemology:<br>300 BC: you can't know anything.<br>600: some stuff you can.<br>1600: no, not even that.<br>1800: what about this?<br>2000: no.</p>— Existential Comics (@existentialcoms) <a href="https://twitter.com/existentialcoms/status/857396828110675968?ref_src=twsrc%5Etfw">April 27, 2017</a></blockquote>


<p>Even if you understand complexity and have “done your research”, when are you done? There are always “unknown unknowns” — context and perspectives out there that you didn’t even know you had to research in the first place. How unfair!</p>

<p>Thus, “the full truth” is never fully attainable by anyone. Nevertheless, at some point we accept the reality we perceive, make judgements, and take action anyways. There’s no other option — we must try to seek our personal truth over time. As is said “the Truth will set you free,” so we must learn to wade through the complexity and our manage our personal biases.</p>

<div>

  <p><strong>Example:</strong> Recently GameStop has been in the news for it’s skyrocketing stock after a historic short squeeze, led by regular retail traders from Reddit, drove hedge funds to lose billions of dollars. Robinhood and other brokers limited $GME trading, and there was a massive backlash against the apps. The narrative? Robinhood was obeying orders from Billionaire Hedge Funds and the system was rigged. Both Ted Cruz and <a href="https://twitter.com/AOC/status/1354830697459032066">AOC</a> seem to agree with that narrative.
Context that came out later:</p>

  <ul>
    <li>Robinhood faced a liquidity crunch and <a href="https://www.businessinsider.com/robinhood-ceo-defends-gamestop-amc-nokia-trading-restrictions-2021-1">proactively borrowed several hundred million dollars</a>. They then limited trading so they could afford financial settlement with acceptable risk. <a href="https://www.foxbusiness.com/markets/robinhood-ceo-refutes-conspiracy-theory-hedge-funds-prompted-gamestop-trading-halt">It wasn’t that they wanted to help Billionaires</a>, but instead survive as a business.</li>
    <li>Regular retail traders were the loud voices in the news, but other <a href="https://www.wsj.com/articles/gamestop-frenzy-puts-spotlight-on-trading-giant-citadel-securities-11612089000">hedge funds aligned with them to exploit the stock</a>. This wasn’t as clean as “Wall Street vs Main Street,” as many wanted to believe.</li>
  </ul>

</div>

<h2 id="psychology-of-truth">Psychology of Truth</h2>

<p>We all have our flaws. Unfortunately — you and I — we’re absolutely terrible at determining what is real from what isn’t.</p>

<p>Some of our psychological vulnerabilities:</p>

<ul>
  <li><strong>Confirmation Bias</strong>: Once we make judgements, we stick with them, and any information that appears to support our worldview will be welcomed instantly — even if it’s a stretch. Evidence to the contrary is ignored, and even causes us, on average, to irrationally <a href="https://www.newyorker.com/magazine/2017/02/27/why-facts-dont-change-our-minds">dig into their own beliefs</a> instead of question them.</li>
  <li><strong>Self-gain</strong>: We look for information to help us increase our status. We share information we think others will like, because then they’ll like us.</li>
  <li><strong>Entertainment</strong>: The more sensationalist and crazy sounding the news, the more we are likely to engage with it, talk about it, and share it.</li>
  <li><strong>Fear</strong>: If something makes us fearful, most people will first <em>assume it is true</em> to hedge risk. After all, if it’s not true then there’s nothing to worry about!</li>
  <li><strong>Lack of Time &amp;</strong> <strong>Laziness</strong>: It’s a luxury to have time to do your own research. Even if you have the time, do you want to read a 5 sentence summary or a 10 page paper? Short content captures attention more easily, but leaves no room for nuance or context. This is best shown by the fact that we only read headlines — <a href="https://www.chicagotribune.com/business/blue-sky/ct-share-this-link-without-reading-it-ap-bsi-20160618-story.html">59% of all social media shares happen without reading the article</a>.</li>
  <li><strong>Repetition Reinforcement:</strong> if we hear something multiple times, we are more likely to believe it. This was the core propaganda technique of the Nazi party.</li>
  <li><strong>Incorrect Focus</strong>: Too much information about the wrong thing distracts us. If others talk about a single aspect of a topic, we naturally assume other aspects are less meaningful. This happens in science, for example, where the topics discussed are only those which are well funded.</li>
  <li><strong>Hero Effect:</strong> We are inclined to believe powerful people are out to get us. We actively want to be a protagonist against a planned, well-executing group of powerful, evil people. For example, <a href="https://www.pewresearch.org/fact-tank/2020/07/24/a-look-at-the-americans-who-believe-there-is-some-truth-to-the-conspiracy-theory-that-covid-19-was-planned/ft_20-07-15_conspiracies_new_01/">40-50% of less educated Americans think COVID was intentionally planned by powerful people.</a></li>
  <li><strong>Short Working Memory:</strong> To hold nuanced views we have to be able to hold multiple topics in working, short-term memory. But when we are bombarded with hyper-active amounts of information, nothing stays in working memory long enough to create nuanced views.</li>
</ul>

<p>And that’s just to name a few! There are hundreds more, such as <a href="https://en.wikipedia.org/wiki/List_of_cognitive_biases">this list of 100+ cognitive biases</a>.</p>

<p>For most of us, what we believe is more predicated on our psychological vulnerabilities rather than what is true and real. This is why the scientific method was so revolutionary — it’s a framework for determining truth without requiring trust, faith, or belief in other people.</p>

<p>We all suck at determining truth.</p>

<h2 id="group-dynamics-of-truth">Group Dynamics of Truth</h2>

<p>Things get really chaotic once you move beyond the individual psychological level and into groups. From a very young age, we all seek to be accepted as part of an in-group — a community. It’s hard-wired into us.</p>

<p>In …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.zachtratar.com/Disinformation-The-Game-of-Belief-is-now-a-War.html#.YBhVpHdKjUI">https://www.zachtratar.com/Disinformation-The-Game-of-Belief-is-now-a-War.html#.YBhVpHdKjUI</a></em></p>]]>
            </description>
            <link>https://www.zachtratar.com/Disinformation-The-Game-of-Belief-is-now-a-War.html#.YBhVpHdKjUI</link>
            <guid isPermaLink="false">hacker-news-small-sites-25992531</guid>
            <pubDate>Mon, 01 Feb 2021 19:25:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unbroken Enigma Message]]>
            </title>
            <description>
<![CDATA[
Score 92 | Comments 40 (<a href="https://news.ycombinator.com/item?id=25992462">thread link</a>) | @akakievich
<br/>
February 1, 2021 | https://enigma.hoerenberg.com/index.php?cat=Unbroken | <a href="https://web.archive.org/web/*/https://enigma.hoerenberg.com/index.php?cat=Unbroken">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://enigma.hoerenberg.com/index.php?cat=Unbroken</link>
            <guid isPermaLink="false">hacker-news-small-sites-25992462</guid>
            <pubDate>Mon, 01 Feb 2021 19:20:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How we develop FDA-compliant machine learning algorithms]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 35 (<a href="https://news.ycombinator.com/item?id=25992363">thread link</a>) | @yshrestha
<br/>
February 1, 2021 | https://innolitics.com/articles/machine-learning-development-for-medical-devices/ | <a href="https://web.archive.org/web/*/https://innolitics.com/articles/machine-learning-development-for-medical-devices/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div>
    
    <p>
      by Grace Adams and Yujan Shrestha on January 26, 2021
    </p>
    
    <p>Want to know how we develop safe, effective, and FDA compliant machine learning algorithms? This article describes how we develop machine learning algorithms, points out common pitfalls, and makes documentation recommendations.</p>

<p>When developing a machine learning or AI algorithm, it’s easy to become overly focused on making the best model possible. While model performance is important, to incorporate the model into a commercial medical device, you’ll need to be able to demonstrate to the FDA that the model is safe and effective. Therefore, it’s critical to thoroughly document the algorithm’s development lineage in your design history file. The process outlined in this article will help you do this. We’ve used it to develop AI algorithms within a recently 510(k)-cleared class-II medical device for one of our clients.</p>

<p>The FDA released its <a href="https://www.fda.gov/media/145022/download"><em>Artificial Intelligence/Machine Learning (AI/ML)-Based Software as a Medical Device (SaMD) Action Plan</em></a> in January of 2021. In it, they discuss upcoming changes to their approach for regulating ML-based medical devices. The exact details aren’t public, but we suspect following a consistent development process will be part of it.</p>
      <h2 id="focus-on-process-documentation">
        
        
          Focus on process documentation <a href="#focus-on-process-documentation">🔗</a>
        
        
      </h2>

<p>Our AI development process includes generating reports that detail the input data, model performance, and model selection process. These reports streamline model development by helping developers recognize and correct some of the most common pitfalls in algorithm development, thereby increasing confidence in the AI/ML algorithm’s safety and efficacy. As a convenient side effect, these reports are a powerful tool when designing a QMS suitable for AI and navigating the FDA clearance process.</p>
    
      <h3 id="some-common-pitfalls-we-have-identified-are">
        
        
          Some common pitfalls we have identified are: <a href="#some-common-pitfalls-we-have-identified-are">🔗</a>
        
        
      </h3>

<ul>
  <li>Laser-focus on chasing higher accuracy metrics and forgetting about the business, clinical, and regulatory context</li>
  <li>Errors in data import and preprocessing</li>
  <li>Clinically unrealistic data augmentation</li>
  <li>Algorithm performance metrics—such as the Dice score—are not a perfect proxy to clinical performance but are treated as such</li>
  <li>Data leakage or improper training/validation splits leads to undetectable overfitting and a false sense of stellar algorithm performance</li>
  <li>Using data that was acquired with non-clinical (research) protocols that are too different from the device’s intended use thereby leading to regulatory risk. <sup><a href="#acknowledgments">1</a></sup></li>
  <li>Not being aware of sampling bias in the data thereby leading to regulatory risk. For example, certain age groups may be underrepresented or certain scanner vendors may be overrepresented. <sup><a href="#acknowledgments">1</a></sup></li>
</ul>
    
      <h3 id="these-pitfalls-can-be-mitigated-by-the-following-reports">
        
        
          These pitfalls can be mitigated by the following reports: <a href="#these-pitfalls-can-be-mitigated-by-the-following-reports">🔗</a>
        
        
      </h3>

<ul>
  <li>Input Verification Report</li>
  <li>Data Augmentation Quality Assurance Report</li>
  <li>Model Performance Report</li>
  <li>Model Comparison Report</li>
</ul>
    
      <h3 id="input-verification-report">
        
        
          Input Verification Report <a href="#input-verification-report">🔗</a>
        
        
      </h3>

<p>The input verification report should visualize the dataset as close to the model training step as possible. A common source of error can be simple data processing errors. This report is also an excellent way to verify the quality of the data. If the input data is not very accurate to start with, it will be hard to train an accurate model. In other words, “garbage in equals garbage out.”</p>

<p><a href="http://innolitics.com/innolitics.github.io.downloads/2021-01-26-machine-learning-development-for-medical-devices/Input_Verification_Report.pdf">Click here to view an example</a></p>
    
      <h3 id="data-augmentation-quality-assurance-qa-report">
        
        
          Data Augmentation Quality Assurance (QA) Report <a href="#data-augmentation-quality-assurance-qa-report">🔗</a>
        
        
      </h3>

<p>Data augmentation is a powerful technique that effectively increases the size of your dataset, reducing the risk of overfitting and increasing accuracy. However, going overboard with data augmentation techniques could distort the images beyond realistic boundaries. The data augmentation QA report takes a random sample of the dataset and produces several augmentations of that image and its annotations. This report allows you to confirm the augmented images are still clinically valid and that the annotations—such as segmentations and fiducial markers—are augmented properly.</p>

<p><a href="http://innolitics.com/innolitics.github.io.downloads/2021-01-26-machine-learning-development-for-medical-devices/Data_Augmentation_QA_Report.pdf">Click here to view an example</a></p>
    
      <h3 id="model-performance-report">
        
        
          Model Performance Report <a href="#model-performance-report">🔗</a>
        
        
      </h3>

<p>The model performance report can vary greatly depending on the problem. However, there are four essential properties that this report should have:</p>

<ol>
  <li>Training graphs: These graphs should show how the accuracy and loss metrics develop from epoch to epoch for the training and validation set. They can help you determine if the model converges, when it begins to overfit, and the likelihood of data leakage.</li>
  <li>Statistics table: This table shows any relevant information for the model, such as the training set accuracy at the end of the last training epoch, the validation set accuracy, and the number of parameters in the model.</li>
  <li>Model Architecture: Information about the structure of the model itself. Tensorflow has a built-in function for visualizing this quickly.</li>
  <li>Visualized Inference: This portion of the report will look a lot like the input verification report for the validation set, but it will also include both the human and AI annotations. We place the worst performers at the top of the report to help focus analysis and subsequent iteration.</li>
</ol>

<p><a href="http://innolitics.com/innolitics.github.io.downloads/2021-01-26-machine-learning-development-for-medical-devices/Model_Output_Verification_Report.pdf">Click here to view an example</a></p>
    
      <h3 id="model-comparison-report">
        
        
          Model Comparison Report <a href="#model-comparison-report">🔗</a>
        
        
      </h3>

<p>During the development of any ML model, there are likely to be hundreds of models trained, each with different hyperparameters, data augmentations, or even different architecture configurations. Additionally, model improvements are likely to be made in the post-market phase as more data is acquired and newer ML techniques are discovered. Therefore, it is essential to have a way to compare multiple models so that you can empirically determine which model performs better. The model comparison report includes the training graphs for each of the models, a statistics table for easy model comparison, and the inferences from each of the models on the same validation dataset. Visualizing all of the different models’ inferences is particularly important since the loss function alone is not the full story. For example, a model with worse metrics could be because it is actually finding more human annotation errors than the others.</p>

<p><a href="http://innolitics.com/innolitics.github.io.downloads/2021-01-26-machine-learning-development-for-medical-devices/Models_Comparison_Report.pdf">Click here to view an example</a></p>
    
      <h2 id="the-process">
        
        
          The Process <a href="#the-process">🔗</a>
        
        
      </h2>

<p>The process we have developed is rooted in the idea that good machine learning practices will lead to algorithms that will generalize to a real clinical setting and thus be safe and reliable. Here I’ll use an example project, segmenting the lungs in chest x-rays, to go step-by-step through our development process. I’ll be detailing the use of the four reports and pointing out common sources of errors along the way.</p>
    
      <h2 id="step-1-problem-definition">
        
        
          Step 1: Problem definition <a href="#step-1-problem-definition">🔗</a>
        
        
      </h2>

<p>When beginning any project, it is vital to understand the goals and limitations. We work closely with our clients to make sure that we can meet all their requirements. Some important considerations are:</p>

<ul>
  <li>Speed: Should this run on an embedded device? Should inference be possible without a GPU? How many concurrent inferences are necessary and on what hardware?</li>
  <li>Accuracy: What accuracy do we think is necessary for a clinically useful model? If an algorithm suggests a segmentation for the physician to edit, the minimum accuracy threshold is probably lower than if the algorithm’s segmentations are used directly for diagnosis. A risk analysis coupled with a literature review can help determine this threshold.</li>
  <li>Development budget: Where should we be on the 80/20 rule? Each .9% added to the accuracy target will scale the cost exponentially. Should we use off the shelf architectures or something more customized? How fast do we need to develop the model? Is this a feasibility study, or do we need to observe more rigorous medical device design controls?</li>
</ul>

<p><em>Example: For the Lung Segmentation problem, it doesn’t need to run on an embedded device and should always have access to a GPU. The goal is to make the model as accurate as possible, but there will usually be several inferences running concurrently. Ideally, the model will be as small as possible without sacrificing accuracy, as inferences time is related to model size. The budget and timeline are limited, so existing architecture implementations are preferred.</em></p>
    
      <h2 id="step-2-get-data">
        
        
          Step 2: Get data <a href="#step-2-get-data">🔗</a>
        
        
      </h2>

<p>The data used to train and test the model is an essential part of ML development. If a client already has a dataset ready to go, that’s great! But if not, we are happy to connect them with tools and services for image annotation as needed.</p>

<p><em>Example: I chose to go with a dataset from Kaggle, a machine learning hub where users can find and publish datasets and other resources to advance the data science field. Link to the dataset I used: https://www.kaggle.com/nikhilpandey360/chest-xray-masks-and-labels</em></p>
    
      <h2 id="step-3-data-partition-strategy">
        
        
          Step 3: Data partition strategy <a href="#step-3-data-partition-strategy">🔗</a>
        
        
      </h2>

<p>Once we have a dataset, there are several data processing steps to get it into a form readily consumable by ML. Usually, this involves splitting the dataset into training, validation, and test sets.</p>

<p>First, we work with our client to set aside a test set. The test set should be reasonably representative of the data commonly seen in clinical scenarios. It will not be used at all during model training. Instead, we will use it to see how well the algorithm performs on unseen data. It will also be the “acceptance criteria” used for the final deliverable and to verify the validity of incremental changes in future versions of the model.</p>

<p>After setting aside the test set, we split the remaining data into …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://innolitics.com/articles/machine-learning-development-for-medical-devices/">https://innolitics.com/articles/machine-learning-development-for-medical-devices/</a></em></p>]]>
            </description>
            <link>https://innolitics.com/articles/machine-learning-development-for-medical-devices/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25992363</guid>
            <pubDate>Mon, 01 Feb 2021 19:14:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building Docker Images the Proper Way]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25992209">thread link</a>) | @dreamy_borg
<br/>
February 1, 2021 | https://martinheinz.dev/blog/42 | <a href="https://web.archive.org/web/*/https://martinheinz.dev/blog/42">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://martinheinz.dev/blog/42</link>
            <guid isPermaLink="false">hacker-news-small-sites-25992209</guid>
            <pubDate>Mon, 01 Feb 2021 19:05:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Going Global]]>
            </title>
            <description>
<![CDATA[
Score 58 | Comments 22 (<a href="https://news.ycombinator.com/item?id=25991988">thread link</a>) | @tosh
<br/>
February 1, 2021 | https://blog.repl.it/global | <a href="https://web.archive.org/web/*/https://blog.repl.it/global">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>We had the idea for Replit in Jordan, launched as a startup in New York, and incorporated as a company in San Mateo. The US gave us the infrastructure, the capital, and network to launch our business, and for that we're forever grateful. However, to us, the internet is a <a href="https://www.eff.org/cyberspace-independence">new country</a> and we want to make our citizenship official and our commitment real. We're joining our global community of hackers, students, teachers, and entrepreneurs and becoming a global company and service. Starting today:</p>
<ul>
<li>Our first two non-US compute regions are up --  Mumbai, India and London, England -- making us a global service</li>
<li>We're hiring worldwide making us a globally distributed company</li>
</ul>
<h2 id="global-routing">Global routing</h2>
<p>Previously, Replit has been operating out of a single datacenter in
the United States. When you start a repl, or join multiplayer, all
of your traffic had to make it to our one datacenter.</p>
<p>While that's not a significant issue if you live nearby, for our
friends all over the world it means every time you type a letter,
you had to cross an ocean at least twice! That means you could see
latencies as high as 300ms for each keystroke in the terminal! Now, when you create
a repl, it lives in the datacenter closest to you. Instead of
everyone having to cross the ocean multiple times, you can feel even
closer than your own computer! And if you have friends far away, things
will feel better too. Instead of connecting to a datacenter that is
far away, you'll connect to the datacenter closest to you, and
we'll deliver your bits as quickly as possible,
so you don't have to travel the world all on your own.</p>
<p>If you lived in India prior to our new data center, you saw significant delay in actions like running your code:</p>
<p><img src="https://blog.repl.it/images/global/before.gif" alt="before latency"></p>
<p>This is what you'll see today:</p>
<p><img src="https://blog.repl.it/images/global/after.gif" alt="after latency"></p>
<p>With these changes coding with friends and coworkers from all
over the world will feel closer than ever, and we're only just
getting started! We've made it super easy for us to ship to even
more countries, datacenters, and devices around the world. Before you
know it you might even be able to have a Replit data center in your
own home!</p>
<p><a href="https://blog.repl.it/killing-containers-at-scale">Read more</a> about our infrastructure and challenges with running a globally distributed multiplayer service.</p>

<p>Because we're still a highly collaborative small team and we haven't perfected the art of asynchronous we require employees to overlap with PST working hours for four hours a day. Otherwise you can be wherever you want in the world. </p>
<p><a href="https://repl.it/careers">Apply here</a>.</p>

	</div></div>]]>
            </description>
            <link>https://blog.repl.it/global</link>
            <guid isPermaLink="false">hacker-news-small-sites-25991988</guid>
            <pubDate>Mon, 01 Feb 2021 18:51:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Weblorg: A Static HTML Generator for Emacs and Org-Mode]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25991966">thread link</a>) | @clarete
<br/>
February 1, 2021 | https://emacs.love/weblorg/posts/v0-1-1-we-re-live.html | <a href="https://web.archive.org/web/*/https://emacs.love/weblorg/posts/v0-1-1-we-re-live.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="text-2">
<p>
With weblorg, one can first automate the process of finding Org-Mode
files, parsing them and feeding them into a template and then
rendering the final output into an HTML file.  Without further ado,
that's how one would do it in Emacs-Lisp:
</p>

<div>
<pre>(<span>require</span> '<span>weblorg</span>)

(weblorg-route
 <span>:name</span> <span>"posts"</span>
 <span>:input-pattern</span> <span>"./posts/*.org"</span>
 <span>:template</span> <span>"post.html"</span>
 <span>:output</span> <span>"./posts/{{ slug }}.html"</span>
 <span>:url</span> <span>"/posts/{{ slug }}.html"</span>)

(weblorg-export)
</pre>
</div>

<p>
That is enough to tell weblorg to find all Org-Mode files within the
directory posts and render them with the template <code>post.html</code>.
</p>

<p>
If you don't want to flex your design skills while spinning up a new
website or blog, worry not. A lean but mean theme is shipped by
default with weblorg.  To allow users to easily copy static assets
from a theme, one can use the following:
</p>

<div>
<pre>
(weblorg-copy-static
 <span>:output</span> <span>"static/{{ file }}"</span>
 <span>:url</span> <span>"/static/{{ file }}"</span>)
</pre>
</div>

<p>
Check out the <a href="https://emacs.love/weblorg/doc/index.html">Documentation</a> with a full article on how to setup a
new website and more.
</p>
</div></div>]]>
            </description>
            <link>https://emacs.love/weblorg/posts/v0-1-1-we-re-live.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25991966</guid>
            <pubDate>Mon, 01 Feb 2021 18:50:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Full Transcript – Elon Musk vs. Vlad Tenev on Clubhouse]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25991946">thread link</a>) | @powerandr
<br/>
February 1, 2021 | https://www.mrhack.io/blog/elon-musk-vlad-tenev-robinhood-ceo-full-transcript/ | <a href="https://web.archive.org/web/*/https://www.mrhack.io/blog/elon-musk-vlad-tenev-robinhood-ceo-full-transcript/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p><iframe src="https://www.youtube.com/embed/1L8mI0i4XSA" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<p><strong>Vlad Tenev: </strong>… It’s actually a couple of companies. So there’s an introducing broker dealer called “RobinHood Financial”. And that basically is the app that, you know and love. It processes trades. You’re a customer of of Robinhood Financial. Then there’s a clearing broker dealer, Robinhood Securities, that clears and settles the trades. And then we have Robinhood Crypto, which is our crypto business, of which all of these are kind of different entities that are differently operated.</p>
<p>So basically Wednesday of last week, we just had, you know, unprecedented volume, unprecedented load on the system. A lot of these so-called meme stocks were going viral on social media and people or people were joining Robinhood. And there was a lot of net by activity on them, as you guys all know. And Robinhood at this time, I think was number one on the App Store and pretty close, if not number one on on Google Play as well.</p>
<p>So just unprecedented activity. And so Thursday morning, so I’m sleeping. But at three thirty a.m. Pacific, our operations team receives a file from the NSCC, which is the National Securities Clearing Corporation. So basically, as a broker, as a clearing broker, and this is where Robinhood Securities comes in, we have to put up money to the NSCC, based on some factors, including things like the volatility of the trading activity, concentration into certain securities. And this is this is the equities business. So it’s based on stock trading and not options trading or anything else.</p>
<p>So they gave us a file with the deposit and the the request was around three billion dollars, which is about an order of magnitude more than what it typically is.</p>
<p><strong>Elon Musk:</strong> So why is this kind of like this seems like like it sounds like this is an unprecedented increase in demand for capital. What formula that they use to calculate that?</p>
<p><strong>Vlad Tenev:</strong> Well, yeah, and just to give context, Robinhood, up until that point, has raised a little bit around two billion dollars in total venture capital.</p>
<p>Up until now. So it’s a big number, like three billion dollars. This is a large number. So basically, the and you know, the details are we don’t have the full details. It’s a little bit of an opaque formula, but there’s a component called the VAR of it, which is value at risk. And that’s based on kind of some fairly quantitative things, although it’s not it’s not fully transparent. So there are ways to reverse engineer it, but it’s not kind of publicly shared.</p>
<p>And then there’s a special component, which is discretionary. So that’s that kind of acts as a multiplier and basically…</p>
<p><strong>Elon Musk:</strong> discretionary discretionary meaning, like it’s just their opinion.</p>
<p><strong>Vlad Tenev:</strong> Yeah, it’s it’s a little bit I mean, I’m sure there’s there’s definitely more more than just their opinion, but basically…</p>
<p><strong>Elon Musk:</strong> I mean, I guess what they’ve gone through, everyone wants to know whatever it was like, did something maybe shady go down here? Like, it just seems weird that you get a sudden ten billion dollar demand, you know, three billion or even more. Sorry, how much?</p>
<p><strong>Vlad Tenev:</strong> Yeah, it was three billion</p>
<p><strong>Elon Musk:</strong> up two to three billion around. You know, just suddenly out of nowhere and what does</p>
<p><strong>Vlad Tenev:</strong> I wouldn’t I wouldn’t I wouldn’t impute shadiness to it or anything like that. And actually, you know, the NSCC was reasonable subsequent to this. And they’ve been they’ve been they worked with us to actually lower it. So it was unprecedented activity. You know, we don’t I don’t have the full context about, you know, what was what was going on in what’s going on in the in that is key to make these calculations.</p>
<p>But, yeah, essentially…</p>
<p><strong>Elon Musk:</strong> if anyone holding you hostage right now…</p>
<p><strong>Vlad Tenev: </strong>But no, I’m OK. Yeah. Thanks for asking. But anyway, so this was this was obviously nerve wracking and I actually was asleep at this point. You know, the operations team was was fielding this had at three o’clock and then, you know, we got back, we put our heads together, you know, chief operating officer basically said, look, let’s call up the higher ups at the NSCC and kind of figure out what’s going on.</p>
<p>Maybe there’s some way we can work with them. And basically, there was another call and they lowered it to something like one point four billion dollars from three. So we were making some progress reports and then but still high number and then. We basically proposed. Well, let’s let’s explain how we plan to let’s explain how we’ll manage risk in these symbols throughout the day. We proposed marking these volatile stocks that were kind of driving, driving the activity position, closing only.</p>
<p>And then at about an hour before the market closed, market opened. So 5:30 or 5 in the morning, they came back and they said, OK, the charges or the deposit. Seven hundred million, which we then deposited and paid promptly and then everything was fine. So that essentially explains why we had to we had to mark these symbols. Position closing only. And also why we didn’t want to we knew this was a bad outcome for customers.</p>
<p>You know, part of what’s been really difficult is Robinhood stands for democratizing access to stocks. And we want we want to give people the access. So that’s been very, very challenging. But we had no choice in this case. We had to conform to our regulatory capital requirements. And so the team did did what they could to make sure we were available for customers.</p>
<p><strong>Elon Musk:</strong> Who controls the success of this organization, this Clearing House?</p>
<p><strong>Vlad Tenev:</strong> You know, it’s a it’s a consortium, it’s not it’s not quite a government agency, you know, I don’t really know the details of of all of that.</p>
<p><strong>Elon Musk: </strong>OK.</p>
<p><strong>Vlad Tenev: </strong>But, you know, and to be fair, we were we were I think there was legitimate sort of turmoil in the markets, like these are unprecedented events with these meme stocks. And, you know, there was a lot of activity. So there probably is. So some amount of extra risk in the system that warrants higher, higher requirements. So it’s not entirely unreasonable, but we do operational processes to make sure that customers that had positions could sell their open positions because obviously restricting someone we got a lot of questions about.</p>
<p>OK, you had to restrict buying. Why didn’t you also restrict selling? The fact of the matter is, people get really pissed off if they’re holding stock and they want to sell it and they can’t. So I think that’s that’s categorically worse. So and lots of other brokers, I think we’re in the same situation. Robinhood was in the news. But you you sort of heard this industry wide. Right. Other brokers basically restricted the same exact activity.</p>
<p><strong>Elon Musk: </strong>All right, so it sounds like this association should cozy up and they basically have a gun to your head, either the head of this money or else. And so because I mean, basically what people are wondering is like, did you sell down the river or do you have no choice? If you had no choice, that’s understandable. But then we got to find out why you had no choice. And who are the people that are saying you have no choice?</p>
<p><strong>Vlad Tenev: </strong>Yeah, I think that’s where we have to comply with these requirements. Financial institutions have requirements. You know, the the formula behind these requirements. I think it would obviously be ideal if there was a little bit more transparency so we could plan better around that, you know, but to be fair, we were able to open and serve our customers. And, you know, twenty four hours later, our team raised over a billion dollars in capital, so that when we when we did open, when we do open tomorrow morning, we’ll be able to kind of relax the stringent position limits that we put on these securities on Friday.</p>
<p><strong>Elon Musk: </strong>Will there be any limits?</p>
<p><strong>Vlad Tenev: </strong>Well, I think there’s always going to be some theoretical limit, like we don’t have infinite capital and on Friday there were limits. So there’s always there’s always going to have to be some limit. I think the question is, you know, will the limits be high enough to the point where, you know, some they won’t impact ninety nine point nine plus percent of customers. So, you know, if someone were to deposit one hundred billion dollars and and decide to trade in one stock like that, that wouldn’t be possible.</p>
<p><strong>Elon Musk: </strong>All right. All right. Well, I guess people really want to know if you had no choice, then you had no choice, that is the situation. And then that’s understandable. But then whoever put that gun to your head. Should you be willing to ask for public.</p>
<p><strong>Vlad Tenev: </strong>Yeah, listen, and, yeah, I know there’s this crisis. This is unprecedented times, and to be fair to those guys, I’ve been they’ve been reasonable. So we are I think the one thing that is maybe not clear to people is Robinhood is a participant in the financial system. So we have to work with all of these counter parties. So we do get a lot of questions about, you know, why do you work with market makers? Why do you work with clearing houses? Vertically integrating and getting. It is hard enough to introducing a clearing broker dealer? Not too many people have done that. But the financial system that allows customers to trade shares is sort of a complex web of multiple parties. And, you know, it’s hard to think.</p>
<p>Everyone says it could be better, it could be improved. It’s it’s just the necessity of of trading equities in the US that you have to do all these things.</p>
<p><strong>Elon Musk: </strong>To what degree are you beholden to Citadel? I mean, like basically said it was unhappy than I thought then what happened?</p>
<p><strong>Vlad Tenev: </strong>Yes, there was a rumor that Citadel or other market makers kind of pressured us into doing this, and now that’s just false. Market makers execute our trades, they execute trades off of every broker dealer.</p>
<p>And this was this was a clearing house. This was a clearing house decision. And it was just based on the capital requirements. So Citadel and other market makers weren’t involved in that.</p>
<p><strong>Elon Musk: </strong>But …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.mrhack.io/blog/elon-musk-vlad-tenev-robinhood-ceo-full-transcript/">https://www.mrhack.io/blog/elon-musk-vlad-tenev-robinhood-ceo-full-transcript/</a></em></p>]]>
            </description>
            <link>https://www.mrhack.io/blog/elon-musk-vlad-tenev-robinhood-ceo-full-transcript/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25991946</guid>
            <pubDate>Mon, 01 Feb 2021 18:49:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Defining a Custom Class Constructor in Python]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25991832">thread link</a>) | @sethdandridge
<br/>
February 1, 2021 | https://sethdandridge.com/blog/defining-a-custom-class-constructor-in-python | <a href="https://web.archive.org/web/*/https://sethdandridge.com/blog/defining-a-custom-class-constructor-in-python">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>Python gives you tremendous visibility into its internal workings. The degree to which you can pop open the hood and modify what’s happening at runtime is powerful and terrifying. The author of the venerable Flask web framework Armin Ronacher gave a fantastic talk on this topic called <a href="https://www.youtube.com/watch?v=qCGofLIzX6g">How Python was Shaped by Leaky Internals</a>.</p>

<p>One way to take advantage of these leaky internals is by overwriting the built-in class constructor. Whenever you define a class, the function <code>__build_class__</code> is called behind the scenes. <code>__build_class__</code> is passed the class code (which is actually, suprisingly, a function) and the class name as arguments. The result of executing <code>__build_class__</code> is your class being created in the appropriate namespace. I’m <a href="https://www.pythoninsight.com/2019/03/what-happens-when-a-class-is-created/">simplifying</a>, but bear with me.</p>



<p>To see this in action, let’s define a simple class called <code>Dog</code> and observe <code>__build_class__</code> do its job.</p>

<figure><pre><code data-lang="python"><span>class</span> <span>Dog</span><span>:</span>
  <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>):</span>
    <span>print</span><span>(</span><span>'bark bark'</span><span>)</span>

<span>dog</span> <span>=</span> <span>Dog</span><span>()</span>
<span>#&gt; bark bark</span></code></pre></figure>

<p>Now let’s define a custom build class function to see a bit of what’s happening under the hood.</p>

<figure><pre><code data-lang="python"><span>def</span> <span>custom_build_class</span><span>(</span><span>*</span><span>args</span><span>):</span>
  <span>print</span><span>(</span><span>args</span><span>)</span>

<span>__builtins__</span><span>.</span><span>__build_class__</span> <span>=</span> <span>custom_build_class</span>

<span>class</span> <span>Dog</span><span>:</span>
  <span>pass</span>
<span>#&gt; (&lt;function Dog at 0x10f6ff6a8&gt;, 'Dog')</span></code></pre></figure>

<p>You can see the two arguments that are passed to <code>__build_class__</code> are the <code>Dog</code> function (the code of the <code>Dog</code> class) and the name of the class, <code>'Dog'</code>. Because we don’t ever call the “real” <code>__build_class__</code>, the class is never defined in the namespace. Curiously, however, accessing the variable <code>Dog</code> doesn’t throw <code>NameError</code>. Instead, it’s just<code>None</code>.</p>

<figure><pre><code data-lang="python"><span>print</span><span>(</span><span>Dog</span><span>)</span>
<span>#&gt; None</span></code></pre></figure>

<p>Not sure why this is—evidently there’s something outside of <code>__build_class__</code> that’s modifying the namespace. Worth further investigation.</p>


<p>Now let’s redefine the built-in class constructor so that no matter what class you define, the <code>__build_class__</code> function assigns the code for <code>Dog</code> to that class name instead of the code of the class you’re defining.</p>

<figure><pre><code data-lang="python"><span>class</span> <span>Dog</span><span>:</span>
  <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>):</span>
    <span>print</span><span>(</span><span>'woof woof'</span><span>)</span>

<span>def</span> <span>custom_build_class</span><span>(</span><span>*</span><span>args</span><span>):</span>
  <span>return</span> <span>Dog</span>

<span>__builtins__</span><span>.</span><span>__build_class__</span> <span>=</span> <span>custom_build_class</span>

<span>class</span> <span>Cat</span><span>:</span>
  <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>):</span>
    <span>print</span><span>(</span><span>'meow meow'</span><span>)</span>

<span>cat</span> <span>=</span> <span>Cat</span><span>()</span>
<span>#&gt; bark bark
</span>
<span>print</span><span>(</span><span>type</span><span>(</span><span>cat</span><span>))</span>
<span>#&gt; &lt;class '__main__.Dog'&gt;</span></code></pre></figure>

<p>Chaos reigns!</p>



<p>Aside from impressing your friends and coworkers with verboten Python magic, why would you ever want to do any of this? I actually can’t think of a legitimate reason. Perhaps you need a hook that registers every class upon its creation? However, this case would probably be better served with a metaclass. If you can think of a legitimate real-world scenario for overriding <code>__build_class__</code>, let me know.</p>

<p>This is the second in a series of blog entries I’m calling “baby snakes”, bits of Python arcana aimed at intermediate and advanced Python developers. For a similar exercise in Python’s built-in abuse, see <a href="https://sethdandridge.com/blog/redefining-pythons-print-function">Redefining Python’s Print() Function</a> and check back soon for even more!</p>


  </div></div>]]>
            </description>
            <link>https://sethdandridge.com/blog/defining-a-custom-class-constructor-in-python</link>
            <guid isPermaLink="false">hacker-news-small-sites-25991832</guid>
            <pubDate>Mon, 01 Feb 2021 18:41:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Identifying Linear Relationships Between Variables in Machine Learning]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25991608">thread link</a>) | @danielmp1202
<br/>
February 1, 2021 | https://www.narrativetext.co/the-linear-model/identifying-linear-relationships-between-variables-in-machine-learning | <a href="https://web.archive.org/web/*/https://www.narrativetext.co/the-linear-model/identifying-linear-relationships-between-variables-in-machine-learning">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><img src="https://www.narrativetext.co/assets/application/160x160/img3.jpg" alt="Image Description"></p><h2>Join our private community in Slack</h2>
          <p>
            Keep up to date by participating in this global community of data
            scientists. We talk about data science use cases, we share notebooks,
            we participate in data science competitions, we help each other,
            and we share new ML techniques and much more!
          </p>
        </div></div>]]>
            </description>
            <link>https://www.narrativetext.co/the-linear-model/identifying-linear-relationships-between-variables-in-machine-learning</link>
            <guid isPermaLink="false">hacker-news-small-sites-25991608</guid>
            <pubDate>Mon, 01 Feb 2021 18:26:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Expresso: A faster, drop-in replacement for the ExpressJS router]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25991516">thread link</a>) | @newtang
<br/>
February 1, 2021 | https://blog.jonnew.com/posts/express-router-part-2-expresso | <a href="https://web.archive.org/web/*/https://blog.jonnew.com/posts/express-router-part-2-expresso">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p><a href="https://blog.jonnew.com/posts/express-router-part-1">In my previous post</a>, I noted that the default router for Express, an extremely popular Node module, hasn’t seen any substantial optimization in years. So, I was curious if I could make a faster, drop-in replacement router, and in early summer of 2020, I broke ground on this project. In the ensuing months, I made incremental progress, and I’m thrilled to share that the <a href="https://www.npmjs.com/package/expresso-router">first public version of Expresso is now available</a>!</p>



<p>My goals were to make Expresso faster than the default Express router, reasonably backwards compatible, throw helpful errors on problematic setup, and finally, to allow routes to be added in an order-independent manner. Let’s walk through these!</p>

<h3 id="speed">Speed</h3>

<p>I tweaked <a href="https://github.com/delvedor/router-benchmark">router-benchmark</a> to include Expresso, and I included the results in my API doc. For static routes Expresso wins hands down, at least according to my quick and dirty local testing environment.</p>

<div><div><pre><code>
<span>====================</span>
 expresso benchmark
<span>====================</span>
short static: 8,375,979 ops/sec
static with same radix: 8,533,307 ops/sec
long static: 7,822,262 ops/sec

<span>=================================</span>
 default express router benchmark
<span>=================================</span>
short static: 1,676,429 ops/sec
static with same radix: 1,590,129 ops/sec
long static: 829,426 ops/sec

</code></pre></div></div>

<p>For parameterized routes (ie <code>/api/v1/:user</code>), Expresso-router is again faster, but the difference isn’t as stark.</p>

<div><div><pre><code><span>====================</span>
 expresso benchmark
<span>====================</span>
dynamic route: 928,018 ops/sec
mixed static dynamic: 765,725 ops/sec

<span>=================================</span>
 default express router benchmark
<span>=================================</span>
dynamic route: 743,979 ops/sec
mixed static dynamic: 613,461 ops/sec
</code></pre></div></div>

<p>The truth is, I’m certain I left some optimization on the table, particularly for parameterized routes, but I was getting anxious to share this with the public. Also, I want to point out that the default express router can get slower as more routes are added. For example, if it has 100 routes, it would run through all of them until it found a match. Expresso-router utilizes a tree for parameterized routes, so it scales much more efficiently.</p>

<h3 id="backwards-compatible">Backwards compatible</h3>

<p>The <a href="https://github.com/newtang/expresso/blob/HEAD/API.md#api-1">API for Expresso is basically identical to the default Express router</a> . However, there are a few missing features like wildcards, and support for parameters in the <code>use</code> function. I have <a href="https://github.com/newtang/expresso/issues">issues</a> filed for several of these, and some <a href="https://github.com/newtang/expresso/blob/HEAD/API.md#migration">additional details in the Migration section</a>.</p>

<h3 id="errors">Errors</h3>

<p>If possible, it’s preferable to make the right thing easy to do, and make the wrong thing, like a source of common mistakes, something destructive, or a suboptimal decision, more difficult. Expresso tries to warn users about common mistakes on setup, but <a href="https://github.com/newtang/expresso/blob/HEAD/API.md#config">allows some optional, explicit overrides in the constructor</a>. Here’s a couple examples.</p>

<figure><pre><code data-lang="javascript"><span>const</span> <span>router</span> <span>=</span> <span>expresso</span><span>();</span>
<span>router</span><span>.</span><span>get</span><span>(</span><span>'</span><span>/api</span><span>'</span><span>,</span> <span>()</span> <span>=&gt;</span> <span>{...});</span>
<span>router</span><span>.</span><span>get</span><span>(</span><span>'</span><span>/api</span><span>'</span><span>,</span> <span>()</span> <span>=&gt;</span> <span>{...});</span> <span>//throws exception for duplicate route</span></code></pre></figure>

<figure><pre><code data-lang="javascript"><span>const</span> <span>router</span> <span>=</span> <span>expresso</span><span>();</span>
<span>router</span><span>.</span><span>get</span><span>(</span><span>'</span><span>/id/:id</span><span>'</span><span>,</span> <span>()</span> <span>=&gt;</span> <span>{...});</span>
<span>router</span><span>.</span><span>get</span><span>(</span><span>'</span><span>/id/:value</span><span>'</span><span>,</span> <span>()</span> <span>=&gt;</span> <span>{...});</span> <span>//throws exception for duplicate route</span></code></pre></figure>

<figure><pre><code data-lang="javascript"><span>const</span> <span>router</span> <span>=</span> <span>expresso</span><span>({</span><span>allowDuplicatePaths</span><span>:</span> <span>true</span><span>});</span>
<span>router</span><span>.</span><span>get</span><span>(</span><span>'</span><span>/api</span><span>'</span><span>,</span> <span>()</span> <span>=&gt;</span> <span>{...});</span>
<span>router</span><span>.</span><span>get</span><span>(</span><span>'</span><span>/api</span><span>'</span><span>,</span> <span>()</span> <span>=&gt;</span> <span>{...});</span>

<span>router</span><span>.</span><span>get</span><span>(</span><span>'</span><span>/id/:id</span><span>'</span><span>,</span> <span>()</span> <span>=&gt;</span> <span>{...});</span>
<span>router</span><span>.</span><span>get</span><span>(</span><span>'</span><span>/id/:value</span><span>'</span><span>,</span> <span>()</span> <span>=&gt;</span> <span>{...});</span></code></pre></figure>

<p>Although these compact examples might look a little silly or improbable, these errors are more likely to manifest themselves if the routes are distributed across multiple files.</p>

<h3 id="order-independence">Order Independence</h3>

<p>Order independence is a big feature for Expresso. In the default Express router, this situation was possible:</p>

<figure><pre><code data-lang="javascript"><span>router</span><span>.</span><span>get</span><span>(</span><span>'</span><span>/api/v1/:user</span><span>'</span><span>,</span> <span>(</span><span>req</span><span>,</span> <span>res</span><span>)</span> <span>=&gt;</span> <span>{</span><span>res</span><span>.</span><span>send</span><span>(</span><span>req</span><span>.</span><span>params</span><span>.</span><span>user</span><span>)});</span>

<span>// will never get called in default Express router, but will get called in Expresso </span>
<span>router</span><span>.</span><span>get</span><span>(</span><span>'</span><span>/api/v1/settings</span><span>'</span><span>,</span> <span>(</span><span>req</span><span>,</span> <span>res</span><span>)</span> <span>=&gt;</span> <span>{</span><span>res</span><span>.</span><span>send</span><span>(</span><span>'</span><span>settings</span><span>'</span><span>)});</span></code></pre></figure>

<p>In the above example, a GET request to <code>/api/v1/settings</code> will never trigger the second route in the default Express router because the first one would match even though it’s less specific. However, with Expresso, this is no longer a concern. Routes are order independent, and Expresso will check the most specific route first.</p>

<h3 id="conclusion">Conclusion</h3>

<p>Naively, this project took a little longer than I intended. There were a lot of details to get right, and there’s some interesting features the default Express router has that are easy to overlook. For example, it handles all HEAD and OPTIONS requests, and carefully adjusts the <code>url</code> and <code>baseUrl</code> properties on the <code>req</code> object when multiple routers are used. A lot of these I discovered while going through the default router’s tests to maximize backwards compatibility where I could.</p>

<p>Because it took longer than estimated, I have some mild regret taking on this project. It wasn’t particularly distinct from my <a href="https://mapbox.com/">day job</a>, so I started to lose a little bit of momentum towards the end. I’ll probably be reinvigorated to add missing features if someone finds Expresso useful.</p>


          </div></div>]]>
            </description>
            <link>https://blog.jonnew.com/posts/express-router-part-2-expresso</link>
            <guid isPermaLink="false">hacker-news-small-sites-25991516</guid>
            <pubDate>Mon, 01 Feb 2021 18:18:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Browser plugin that adds extra features to Metrc]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25991509">thread link</a>) | @nosmokewhereiam
<br/>
February 1, 2021 | https://www.gosellout.com/metrc-toolkit | <a href="https://web.archive.org/web/*/https://www.gosellout.com/metrc-toolkit">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.gosellout.com/metrc-toolkit</link>
            <guid isPermaLink="false">hacker-news-small-sites-25991509</guid>
            <pubDate>Mon, 01 Feb 2021 18:18:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Everything You Hate About Clubhouse Is Why It Will Win]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25991386">thread link</a>) | @swyx
<br/>
February 1, 2021 | https://www.swyx.io/clubhouse-hate/ | <a href="https://web.archive.org/web/*/https://www.swyx.io/clubhouse-hate/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><em>You can listen to <a href="https://share.transistor.fm/s/6719542d">an audio version of this essay here</a>.</em></p>
<p>Trust me, I <em>tried</em> to make the Clubhouse bear case.</p>
<p>The original title of this post was "Everything Clubhouse Did Right — and Why It Will Fail Anyway". The exercise forced me to list the reasons why it wasn't worth $1 billion - why live conference calls are inferior to existing formats like podcasts and Discord.</p>
<p>When I was done, I went for a walk to think about it. By the time I came back, I had done a complete 180. (Note - <em>this was even before I heard about the Elon event</em>)</p>
<p>I <em>still</em> dislike the Clubhouse experience. I wouldn't recommend it to you. But all the reasons I dislike it are the same reasons it will work:</p>
<ul>
  <li><strong>Clubhouse is exclusive</strong>. You have hoops to jump and gates to open every step of the way. It's iOS only. Invite only. Requires your phone number for no goddamn reason. And once you're through <em>all of that</em> you gain the privilege of being in the voiceless audience hoping senpai will notice your raised hand and puffed up bio.</li>
  <li><strong>Clubhouse is ephemeral</strong>. Conversations aren't recorded. Your work doesn't compound and isn't searchable. This is <em>horrible</em> for ROI on your time as a content creator.</li>
  <li><strong>Clubhouse is live-only</strong>. If all the convos are happening in Pacific Time and you live in Europe, tough luck. If you came in halfway and have no idea what was said, tough luck. The only way to be fully involved is to turn on mobile notifications and track scheduled chats. Causing more — not less — distraction and work for you.</li>
  <li><strong>Clubhouse enhances existing privilege</strong>. Because automated recommendations aren't possible, Clubhouse mostly relies on a Twitter-like follow graph. To gain a following you mostly already have to be famous off-platform or well-connected to people who will bring you up on stage ("second-degree famous"). Choosing a <a href="https://www.eugenewei.com/blog/2019/2/19/status-as-a-service">Status as a Service</a> model (Twitter) over a <a href="https://www.eugenewei.com/blog/2020/8/3/tiktok-and-the-sorting-hat">Sorting Hat</a> model (TikTok) sacrifices discovery for establishment.</li>
  <li><strong>Clubhouse is a terrible listening experience</strong>. There's no audience chat or polling. Obnoxious speakers can dominate the conversation. <a href="https://twitter.com/wongmjane/status/1355817942093496320?s=20">Trolls</a> and <a href="https://www.dailydot.com/unclick/tiffany-haddish-bullies-doctor-on-clubhouse-covid/">harassment</a> abound. You can't play at 2x or rewind an important part. Podcasts were trending towards better audio and editing, Clubhouse regresses to shitty phone mics with feedback and connection issues. Signal is scarce, noise is rampant.</li>
</ul>
<p>In my original write up I listed the many better offerings in every dimension. Want to listen to interviews with great audio and show notes? Podcasts. Want ultrascalable livestreaming? Twitch. Want livestreamed audio with recording and submitted questions? <a href="https://twitter.com/N8Elliott/status/1355203379392176131?s=20">Capiche</a>. Want to do an audio webinar? Use Zoom with the camera off. Want voice with text chat? Discord. Just want a Clubhouse clone with less friction? <a href="https://twitter.com/TwitterSpaces">Twitter Spaces</a>.</p>
<p>When I was done listing the alternatives, I knew I had made a mistake. They checked more boxes on a feature comparison basis. But social media doesn't work like that. I was trying to be logical in a <em>socio</em>-logical domain.</p>
<p>I had conclusively <em>PROVED</em>, with my big brain and fancy words, how profoundly inferior Clubhouse was. No compounding creator should prefer it, and no self respecting listener should enjoy it, compared to alternatives.</p>
<p>But the majority of people don't work like that:</p>
<ul>
  <li>Some people are turned off by exclusivity and friction. But <em>most people</em> take it as social proof of something cool.</li>
  <li>Some creators are turned off by ephemerality. But <em>more people</em> will start trying precisely because it's easy and doesn't matter. The Elon Musks and Vlad Tenevs of the world will be less guarded, despite clearly knowing anything they say will be recorded, because <em><a href="https://en.wikipedia.org/wiki/The_medium_is_the_message">the medium is the message</a></em>.</li>
  <li>Some people are turned off by demands on their time. But <em>most people</em> leave mobile notifications on and the live nature of chats creates some of the most urgent notifications you'll get on your phone, second only to a call from your mother. The synchronicity creates an <em>event</em> — a clear Before and After where you can excitedly gossip and feel superior to people out of the loop. This is a rarity in an everything-async world.</li>
  <li>Some people are turned off by stacked decks. But <em>most people</em> just want to follow celebrities and experts and aren't interested in the challenging, messy work of finding people on the way up.</li>
  <li>Some people are turned off by the listening experience. But Clubhouse is <a href="https://www.swyx.io/good-enough/">Good Enough</a>, especially if content is created sooner and in bigger quantity than available anywhere else.</li>
</ul>
<p>Clubhouse should've died <a href="https://www.theverge.com/interface/2020/7/8/21316172/clubhouse-content-moderation-taylor-lorenz-harassment-abuse">in July when the VC and Media abuse cases erupted</a>. Instead it came back stronger than ever, standing at <a href="https://web.archive.org/web/20210131175202/https://www.businessinsider.com/why-the-hype-about-1-billion-clubhouse-not-so-crazy-2021-1">2 million weekly active users</a>. <strong>If any of these negatives mattered</strong>, the app should have seen extreme churn. Instead, <a href="https://a16z.com/2021/01/24/investing-in-clubhouse/">Andrew Chen</a>, <a href="https://twitter.com/rrhoover/status/1353393250552270850">Ryan Hoover</a>, and <a href="https://twitter.com/shl/status/1353406140495798272">Sahil Lavingia</a> — who do this for a living and have insider knowledge of metrics — value it above $1 billion dollars, six months after it was <a href="https://www.forbes.com/sites/alexkonrad/2020/05/15/andreessen-horowitz-wins-vc-sweepstakes-to-back-clubhouse-voice-app/?sh=5b8466d56f2a">valued at $100 million</a>.</p>
<p><strong>People. Aren't. Churning.</strong> No matter how much you may hate the app — usage is going <em>up</em>. This is scary and worth taking note. Clubhouse is already showing signs of successful expansion in Asia (read: non-English Clubhouses).</p>
<p>Instagram had 30 million MAUs when Facebook bought it for $1 billion. Whatsapp had 450m for $19 billion. By Whatsapp metrics, Clubhouse is wildly overvalued (lets say it has 10m MAU right now). But audio isn't text. <a href="https://alexdanco.com/2019/10/17/the-audio-revolution/">Alex Danco says</a> that texting is a cold medium, while audio is the hottest medium of all. He was mildly wrong — podcasting is still kinda lukewarm — but <strong><em>live, ephemeral</em></strong> audio is so hot you will literally drop everything and stay up late and ignore your partner to go listen to Elon.</p>
<p>Worse is better. The exact reasons you hate Clubhouse — the kind of thing that drives you to read an article like this to the end — are the exact same reasons it is going to win.</p>
</div></div>]]>
            </description>
            <link>https://www.swyx.io/clubhouse-hate/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25991386</guid>
            <pubDate>Mon, 01 Feb 2021 18:08:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AlmaLinux Beta: A Community-Driven Replacement for CentOS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25991329">thread link</a>) | @jaboutboul
<br/>
February 1, 2021 | https://blog.almalinux.org/introducing-almalinux-beta-a-community-driven-replacement-for-centos/ | <a href="https://web.archive.org/web/*/https://blog.almalinux.org/introducing-almalinux-beta-a-community-driven-replacement-for-centos/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<div>

                                <p><span>CloudLinux is proud to announce the release of AlmaLinux Beta. We’ve collected community feedback and built our new beta release around what you would expect from an enterprise-level Linux distribution. AlmaLinux is a completely free 1:1 binary compatible fork of Red Hat Enterprise Linux (RHEL) 8, inspired by the community and built by the engineers and talent behind CloudLinux. Visit <a href="https://repo.almalinux.org/almalinux/8.3-beta/isos/x86_64/">this link</a></span><span>&nbsp;to download Beta images.</span></p>

<p><span>With the Beta release deployed, we’d like to ask the community to be involved and provide feedback. We aim to build a Linux distribution entirely from community contributions and feedback. During AlmaLinux Beta, we ask for assistance in testing, documentation, support and future direction for the operating system. Together, we can build a Linux distribution that fills the gap left by the now unsupported CentOS distribution.</span></p>
<p><span>The AlmaLinux team set up all the necessary infrastructure to make it convenient for our contributors to provide their input. The public repository on </span><a href="https://github.com/AlmaLinux"><span>Github</span></a><span> is where we will finalize the source code for the system, and any additional documentation will be posted on the </span><a href="https://wiki.almalinux.org/"><span>wiki</span></a><span>. We set up the wiki and repository to make it easy for the community to provide as much information and feedback as possible. The AlmaLinux team will review every comment and request, but we ask that only registered contributors </span><a href="https://bugs.almalinux.org/login_page.php"><span>file bug reports</span></a><span> to filter out spam.</span></p>
<p><span>To facilitate communication and help answer some of the common questions you might already have, we will be hosting a live QA webinar with the AlmaLinux team. </span><span>The webinar will take place on February 10, </span><span>5 PM (UTC) / 9 AM (PST). Among the participants present will be Igor Seletskiy, CEO of CloudLinux, and Alexander Vinogradov, Head of Engineering at AlmaLinux.</span></p>
<p><span>You can sign up for our webinar </span><a href="https://blog.almalinux.org/webinars/almalinux-beta-qa-webinar/"><span>here</span></a><span>.</span></p>
<p><span>If you have any questions, comments, feedback or concerns, please feel free to send us your thoughts to </span><a href="https://blog.almalinux.org/cdn-cgi/l/email-protection#b8d0ddd4d4d7f8d9d4d5d9d4d1d6cdc096d7cadf"><span><span data-cfemail="6a020f0606052a0b06070b0603041f124405180d">[email&nbsp;protected]</span></span></a><span> or send them during the webinar on Twitter with the hashtag #AlmaLinuxBeta.</span></p>
<p><span>CloudLinux and the AlmaLinux team would like to thank the community for their input. This is just the beginning for AlmaLinux, and we look forward to continued improvements and updates for the next generation enterprise-level Linux operating system.</span></p>
<p><span>Thank you for your contribution, input, and support throughout launching AlmaLinux! The infrastructure was the first step, now we need your help to make the next one!</span></p>


<p><strong>Release Notes for AlmaLinux 8 beta</strong></p>
<p><span>The release code name: Purple <a href="https://en.wikipedia.org/wiki/Pallas%27s_cat">Manul</a>.</span></p>
<p><span>CloudLinux is proud to present the beta version of AlmaLinux. After roughly a month and a half from the announcement, here is a 1:1 RHEL binary compatible replacement for your RHEL-based systems.&nbsp;</span></p>
<p><span>This is for the community and by the community, you’re the soul of Linux. Thank you for your interest and suggestions so far, keep them coming.</span></p>
<p><span>Use this version to thoroughly test your workloads and report any unintended features (ie, bugs) you may find, it will help make AlmaLinux better.</span></p>

<h2><span>Installation instructions</span></h2>

<p><span>There are three installation ISO images available:</span></p>
<ul>
<li aria-level="1"><a href="https://repo.almalinux.org/almalinux/8.3-beta/isos/x86_64/AlmaLinux-8.3-beta-1-x86_64-boot.iso"><span>AlmaLinux-8.3-beta-1-x86_64-boot.iso</span></a><span> – a single network installation CD image that downloads packages over the Internet.</span></li>
<li aria-level="1"><a href="https://repo.almalinux.org/almalinux/8.3-beta/isos/x86_64/AlmaLinux-8.3-beta-1-x86_64-minimal.iso"><span>AlmaLinux-8.3-beta-1-x86_64-minimal.iso</span></a><span> – a minimal self-containing DVD image that makes possible offline installation.</span></li>
<li aria-level="1"><a href="https://repo.almalinux.org/almalinux/8.3-beta/isos/x86_64/AlmaLinux-8.3-beta-1-x86_64-dvd1.iso"><span>AlmaLinux-8.3-beta-1-x86_64-dvd1.iso</span></a><span> – a full installation DVD image that contains mostly all AlmaLinux packages. We don’t really recommend using it unless you need to set up and use AlmaLinux on a machine without internet access.</span></li>
</ul>

<p><span>Download a preferable ISO image and verify its checksum. Here is an example for GNU/Linux:</span></p>
<blockquote>
<pre><span># download and import the AlmaLinux public key</span>
<span>$ wget </span><a href="https://repo.almalinux.org/almalinux/RPM-GPG-KEY-AlmaLinux"><span>https://repo.almalinux.org/almalinux/RPM-GPG-KEY-AlmaLinux</span></a>
<span>$ gpg --import RPM-GPG-KEY-AlmaLinux</span>

<span># download a checksums list</span>
<span>$ wget </span><a href="https://repo.almalinux.org/almalinux/8.3-beta/isos/x86_64/CHECKSUM"><span>https://repo.almalinux.org/almalinux/8.3-beta/isos/x86_64/CHECKSUM</span>
</a><span>
# verify the checksums list, we are looking for “Good signature”</span>
<span>$ gpg --verify CHECKSUM </span>
<span>gpg: Signature made Thu 28 Jan 2021 11:39:12 PM MSK</span>
<span>gpg:&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; using RSA key 51D6647EC21AD6EA</span>
<span>gpg: <strong>Good signature from "AlmaLinux &lt;<a href="https://blog.almalinux.org/cdn-cgi/l/email-protection" data-cfemail="e69687858d87818394a6878a8b878a8f88939ec8899481">[email&nbsp;protected]</a>&gt;"</strong> [unknown]</span>
<span>gpg: WARNING: This key is not certified with a trusted signature!</span>
<span>gpg:&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; There is no indication that the signature belongs to the owner.</span>
<span>Primary key fingerprint: 5E9B 8F56 17B5 066C E920&nbsp; 57C3 488F CF7C 3ABB 34F8</span>
<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Subkey fingerprint: E53C F5EF 91CE B0AD 1812&nbsp; ECB8 51D6 647E C21A D6EA</span>

<span># download the network install ISO</span>

<span>$ wget </span><a href="https://repo.almalinux.org/almalinux/8.3-beta/isos/x86_64/AlmaLinux-8.3-beta-1-x86_64-boot.iso"><span>https://repo.almalinux.org/almalinux/8.3-beta/isos/x86_64/AlmaLinux-8.3-beta-1-x86_64-boot.iso</span></a>
<span># calculate the downloaded ISO SHA256 checksum</span>
<span>$ sha256sum AlmaLinux-8.3-beta-1-x86_64-boot.iso </span>
<span>d15be406f417e81382b46a54d87dff01c8ca770c847c18703f19146587b61a1f&nbsp; AlmaLinux-8.3-beta-1-x86_64-boot.iso</span>

<span># compare it with expected checksum, it should be the same</span>
<span>$ cat CHECKSUM | grep -E 'SHA256.*AlmaLinux-8.3-beta-1-x86_64-boot.iso'</span>
<span>SHA256 (AlmaLinux-8.3-beta-1-x86_64-boot.iso) = d15be406f417e81382b46a54d87dff01c8ca770c847c18703f19146587b61a1f</span></pre>
</blockquote>

<p><span>If you decided to use the AlmaLinux-8.3-beta-1-x86_64-boot.iso image, you will need to provide this </span><a href="https://repo.almalinux.org/almalinux/8.3-beta/BaseOS/x86_64/kickstart/"><span>https://repo.almalinux.org/almalinux/8.3-beta/BaseOS/x86_64/kickstart/ </span></a><span>repository as the Installation Source:</span></p>

<p><img loading="lazy" src="http://blog.almalinux.org/wp-content/uploads/2021/02/source-2.png" alt="" width="731" height="507" srcset="https://blog.almalinux.org/wp-content/uploads/2021/02/source-2.png 1053w, https://blog.almalinux.org/wp-content/uploads/2021/02/source-2-300x208.png 300w, https://blog.almalinux.org/wp-content/uploads/2021/02/source-2-1024x710.png 1024w, https://blog.almalinux.org/wp-content/uploads/2021/02/source-2-150x104.png 150w, https://blog.almalinux.org/wp-content/uploads/2021/02/source-2-768x532.png 768w" sizes="(max-width: 731px) 100vw, 731px"></p>

<p><span>If you are going to install a non-minimal environment, you will need to add the AppStream repository to the additional repositories: </span><a href="https://repo.almalinux.org/almalinux/8.3-beta/AppStream/x86_64/os/"><span>https://repo.almalinux.org/almalinux/8.3-beta/AppStream/x86_64/os/</span></a><span>.</span></p>
<p><span>There are no extra Installation Sources required if you decided to go with AlmaLinux-8.3-beta-1-x86_64-minimal.iso or AlmaLinux-8.3-beta-1-x86_64-dvd1.iso images.</span></p>

<h2><span>How to set up a usb key to install AlmaLinux</span></h2>
<blockquote>
<pre><span>dd if=AlmaLinux-8.3-beta-1-x86_64-boot.iso of=/dev/sdX</span></pre>
</blockquote>
<p><span>Where </span><b>sdX</b><span> is your usb device</span></p>

<h2><span>Known issues</span></h2>
<ul>
<li><span>Our libreport/abrt packages aren’t integrated with the bugs.almalinux.org bug-tracker yet, so a user will have to submit a crash report manually. Issue: </span><a href="https://bugs.almalinux.org/view.php?id=2"><span>almbz#2</span></a><span>.</span></li>
<li><span>The “perl:5.30” module support is incomplete in the beta release, it will be finished in the stable.</span></li>
<li><span>We don’t have the latest “jmc” and “maven” module versions. They will be updated later.</span></li>
<li><span>The “satellite-5-client” module is located in the BaseOS repository instead of the AppStream. Issue: </span><a href="https://bugs.almalinux.org/view.php?id=4"><span>almbz#4</span></a><span>.</span></li>
<li><span>There is no support for Secure Boot in the beta release. Issue: </span><a href="https://bugs.almalinux.org/view.php?id=3"><span>almbz#3</span></a><span>.</span></li>
<li><span>The debuginfo repositories are empty and will be populated in a couple of days after the beta release.</span></li>
</ul>



                             </div>



                            </div></div>]]>
            </description>
            <link>https://blog.almalinux.org/introducing-almalinux-beta-a-community-driven-replacement-for-centos/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25991329</guid>
            <pubDate>Mon, 01 Feb 2021 18:05:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A financial insider's take on GameStonk]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25991180">thread link</a>) | @davidd8
<br/>
February 1, 2021 | https://www.davidexmachina.com/2021/02/cant-stonk-wont-stonk-game-stonk.html | <a href="https://web.archive.org/web/*/https://www.davidexmachina.com/2021/02/cant-stonk-wont-stonk-game-stonk.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.davidexmachina.com/2021/02/cant-stonk-wont-stonk-game-stonk.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25991180</guid>
            <pubDate>Mon, 01 Feb 2021 17:54:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Argo Workflows v3.0]]>
            </title>
            <description>
<![CDATA[
Score 66 | Comments 11 (<a href="https://news.ycombinator.com/item?id=25991077">thread link</a>) | @dnsmichi
<br/>
February 1, 2021 | https://blog.argoproj.io/argo-workflows-v3-0-4d0b69f15a6e | <a href="https://web.archive.org/web/*/https://blog.argoproj.io/argo-workflows-v3-0-4d0b69f15a6e">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p id="3ed4">We’re incredibly proud of how far <a href="https://github.com/argoproj/argo" rel="noopener"><strong>Argo Workflows</strong></a> has come since its <a rel="noopener" href="https://blog.argoproj.io/introducing-argo-a-container-native-workflow-engine-for-kubernetes-55c0b4b76fac"><strong>inception</strong></a> three years ago!</p><ul><li id="01a4">17th Oct 2017 — first commit</li><li id="947c">6th Feb 2018 — v2.0 rewritten in Go</li><li id="dcbd">2nd Sep 2019 — first 1,000 stars</li><li id="9355">17th Apr 2020 — <a href="https://www.cncf.io/blog/2020/04/07/toc-welcomes-argo-into-the-cncf-incubator/" rel="noopener">became a CNCF incubator project</a></li><li id="5b9b">22nd Jan 2021 — 373 contributors, 2k commits, 7.3k stars, 1.3k forks, 5.2k Slack members</li></ul><p id="0265">With this all behind us — we’re round to announce <strong>Argo Workflows v3.0.</strong></p><h2 id="aaf7">What is Argo Workflows?</h2><p id="7875"><strong>Argo Workflows</strong> is a cloud-native workflow engine that can run 10,000s of concurrent workflows, each with 1,000s of steps.</p><h2 id="29df">What can I use it for?</h2><ul><li id="5678">Machine Learning</li><li id="46b6">ETL, Data Analytics &amp; Data Science</li><li id="061c">Data processing pipelines</li><li id="b4d2">Batch processing</li><li id="bce1">Serverless</li><li id="084c">CI/CD</li></ul><h2 id="1f24">Who uses Argo?</h2><p id="d00f">Argo is used to “discover new physics” at CERN, for 3D rendering at CoreWeave (on a 1,000 node cluster with 6,000 GPUs), and in Intuit’s Machine Learning and Data Processing platforms. Argo Workflows is actively used in production by well over <a href="https://github.com/argoproj/argo/blob/master/USERS.md" rel="noopener">100 organizations</a>, including <strong>Adobe, Alibaba Cloud, BlackRock, Capital One, Data Dog, Datastax, Google, GitHub, IBM, Intuit, NVIDIA, SAP, New Relic, and RedHat.</strong></p><h2 id="6abc">Why would I use Argo?</h2><p id="bc11">When we asked our users who were using tools like Kubeflow, Apache Airflow, AWS Batch, AWS Lambda, KNative, TektonCD, and <a href="https://blog.kintohub.com/how-do-we-ditch-jenkins-for-argo-1c0b4df5dab0" rel="noopener">Jenkins</a> why they also use Argo, they said<strong> they love that it is cloud-native, simple, fast, scales, and cost-effective.</strong></p><h2 id="aa48">Big new features every release</h2><p id="d3b3">In the last 12 months, every release has had major new features:</p><ul><li id="34ce"><a rel="noopener" href="https://blog.argoproj.io/whats-coming-up-in-argo-workflows-v2-12-3899bae53562">v2.12: reports and metrics, SSO+RBAC</a></li><li id="9317"><a rel="noopener" href="https://blog.argoproj.io/argo-workflows-v2-11-a8b6189bf60e">v2.11: webhooks, memorization</a></li><li id="7fdb"><a rel="noopener" href="https://blog.argoproj.io/argo-workflows-v2-10-d20beeee5df3">v2.10: Java and Python SDKs, semaphores, and mutexes</a></li><li id="acc8"><a rel="noopener" href="https://blog.argoproj.io/argo-workflows-v2-9-47b9c2b5f456">v2.9: single-sign-on, Windows support, workflow template ref</a></li><li id="3ff0"><a rel="noopener" href="https://blog.argoproj.io/whats-new-in-argo-workflow-v2-8-5356ee1d4f7f">v2.8: cluster workflow templates</a></li><li id="ab13"><a rel="noopener" href="https://blog.argoproj.io/argo-workflows-v2-7-6ace8c210798">v2.7: submittable workflow templates, Prometheus metrics</a></li><li id="50f0"><a href="https://github.com/argoproj/argo/releases/tag/v2.6.0" rel="noopener">v2.6: Gomodules, filtering labels</a></li><li id="20d1"><a rel="noopener" href="https://blog.argoproj.io/argo-workflows-v2-5-released-ce7553bfd84c">v2.5: API server, the workflow archive, cron workflows</a></li></ul><ul><li id="ed9f">Major upgrade (20k new lines of code) to the user interface with many new features and much more robust</li><li id="1469">Brand new APIs for Argo Events</li><li id="04b7">Controller High-Availability</li><li id="54c8">Key-only artifacts make it easier to perform map-reduce operations</li><li id="0dd0">Moving the repository</li><li id="6230">Go modules support</li></ul><h2 id="cca4">Argo Events API and UI</h2><p id="19ec">Argo Workflows v3.0 comes with a new UI that now also supports Argo Events! The UI is also more robust and reliable.</p><ul><li id="0c4a">New API endpoints for Argo Events</li><li id="d65d">New event-flow page</li><li id="379d">Create, edit, and view log event sources and sensors in the UI</li><li id="ff13">Embeddable widgets</li><li id="9cb9">New workflow log viewer</li><li id="5094">Configurable “Get Help” button</li><li id="d657">More configurable link buttons (e.g. for linking into your logging facility)</li><li id="1e6f">Seamless reconnection on network errors</li><li id="9264">Refactored code to use more robust React functional components</li></ul><p id="f8ca">The<strong> event-flow page</strong> allows users to understand how event sources and sensors are connected together, as well as linking in the workflows created by triggers, and displaying animations whenever a message is seen.</p><figure><p><img alt="Image for post" src="https://miro.medium.com/proxy/1*qi3-DdjCLGEa3V86YhCZyQ.png"></p><figcaption>Event-flow</figcaption></figure><p id="3b26">You can <strong>create and update event sources and sensors</strong> directly in the user interface using the same visual language we use for workflows:</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1334/1*CnLN8MIMQoofSlpAaDSGfg.png" width="667" height="274" srcset="https://miro.medium.com/max/552/1*CnLN8MIMQoofSlpAaDSGfg.png 276w, https://miro.medium.com/max/1104/1*CnLN8MIMQoofSlpAaDSGfg.png 552w, https://miro.medium.com/max/1280/1*CnLN8MIMQoofSlpAaDSGfg.png 640w, https://miro.medium.com/max/1334/1*CnLN8MIMQoofSlpAaDSGfg.png 667w" sizes="667px" data-old-src="https://miro.medium.com/max/60/1*CnLN8MIMQoofSlpAaDSGfg.png?q=20"></p></div></div><figcaption>Event Sources</figcaption></figure><p id="3435">We’ve added some simple <strong>widgets </strong>you can use to embed the status and progress of a workflow or the latest workflow created by a workflow template or cron workflow:</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1238/1*7iql7XVD9v9-1_-UfjO4LA.png" width="619" height="721" srcset="https://miro.medium.com/max/552/1*7iql7XVD9v9-1_-UfjO4LA.png 276w, https://miro.medium.com/max/1104/1*7iql7XVD9v9-1_-UfjO4LA.png 552w, https://miro.medium.com/max/1238/1*7iql7XVD9v9-1_-UfjO4LA.png 619w" sizes="619px" data-old-src="https://miro.medium.com/max/52/1*7iql7XVD9v9-1_-UfjO4LA.png?q=20"></p></div></div><figcaption>Widgets</figcaption></figure><p id="f0ac">Rather than editing your workflow by hand, you can also <strong>submit from a template</strong>:</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1150/1*3c0kAYITJpSt4A4FtbvRsA.png" width="575" height="237" srcset="https://miro.medium.com/max/552/1*3c0kAYITJpSt4A4FtbvRsA.png 276w, https://miro.medium.com/max/1104/1*3c0kAYITJpSt4A4FtbvRsA.png 552w, https://miro.medium.com/max/1150/1*3c0kAYITJpSt4A4FtbvRsA.png 575w" sizes="575px" data-old-src="https://miro.medium.com/max/60/1*3c0kAYITJpSt4A4FtbvRsA.png?q=20"></p></div></div><figcaption>Workflow Creator</figcaption></figure><p id="b213">The log viewer has been updated to allow you to view the init and wait containers easier (helping debug artifact issues). It also allows you to <strong>tail the whole workflow</strong>:</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1626/1*aDmxHb6qK0YXPFDqN-bnlQ.png" width="813" height="736" srcset="https://miro.medium.com/max/552/1*aDmxHb6qK0YXPFDqN-bnlQ.png 276w, https://miro.medium.com/max/1104/1*aDmxHb6qK0YXPFDqN-bnlQ.png 552w, https://miro.medium.com/max/1280/1*aDmxHb6qK0YXPFDqN-bnlQ.png 640w, https://miro.medium.com/max/1400/1*aDmxHb6qK0YXPFDqN-bnlQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*aDmxHb6qK0YXPFDqN-bnlQ.png?q=20"></p></div></div></div><figcaption>Log Viewer</figcaption></figure><p id="e514">If you want to try it yourself, you can take a look around the <a href="https://workflows.apps.argoproj.io/" rel="noopener"><strong>test environment</strong></a><strong>.</strong></p><p id="ed2e">We have an extensive demo video you can watch online from January’s community meeting (starts at 41m):</p><figure><div></div></figure><h2 id="a0d4">Controller High-Availability</h2><p id="c675">The v3.0 release introduces a hot-standby workflow controller feature for high availability and quick recovery by leveraging the Kubernetes leader election feature. The default install enables leader election and one has a pod, which is the leader. Whenever a controller pod crashes, Kubernetes will restart it. To reduce startup time, you can now run two pods. The second pod will be on hot-standby and take over immediately if the leader dies.</p><pre><span id="43b2">kubectl scale deployment/workflow-controller --replicas=2 </span></pre><h2 id="5b79">Key-Only Artifacts</h2><p id="f857">Argo Workflows v3.0 introduces a default artifact repository reference and key-only artifacts, two new features that work together.</p><ul><li id="83b6">Users can configure a default artifact repository for their namespace rather than having to define it explicitly for each workflow.</li><li id="98bd">Workflow specifications do not need to provide non-key fields (e.g. bucket, username/password secret key). They can use just the key (hence “key-only”), and the non-key fields will be inherited from the artifact repository.</li><li id="e292">Users can specify the key to reference artifacts globally without using parameterized inputs and outputs.</li><li id="fc9b">Easier to specify fan-in artifact patterns, simplifying map-reduce style workflows.</li></ul><p id="c415">As a consequence, we no longer need to replicate non-key elements in manifests, reducing the disk-space needed for workflows.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1766/1*jqBXCrmex2GmJYj_ZlTwZQ.png" width="883" height="483" srcset="https://miro.medium.com/max/552/1*jqBXCrmex2GmJYj_ZlTwZQ.png 276w, https://miro.medium.com/max/1104/1*jqBXCrmex2GmJYj_ZlTwZQ.png 552w, https://miro.medium.com/max/1280/1*jqBXCrmex2GmJYj_ZlTwZQ.png 640w, https://miro.medium.com/max/1400/1*jqBXCrmex2GmJYj_ZlTwZQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*jqBXCrmex2GmJYj_ZlTwZQ.png?q=20"></p></div></div></div></figure><h2 id="424c">New Repository Location</h2><p id="ab61">We’ll be renaming the Argo workflow repository to <code>argo-workflows</code>rather than <code>argo</code>. The new name makes it clear that this is the repo for Argo Workflows and not the overall Argo Project.</p><p id="d21a">Github automatically forwards when a repository is renamed, so users should not be significantly impacted.</p><h2 id="1ebd">Go Modules + Go Client v1.19</h2><p id="7eba">In 2020, we migrated to Go modules. Unfortunately, migrating to Go modules is a breaking change and we never completed the work, and it was still not possible to <code>go get github.com/argoproj/argo</code> without some hackery. Release v3 will fix this.</p><h2 id="e08b">v2.12 Long-term Support</h2><p id="2529">We plan to provide long-term support for v2.12. There will be bug fixes, but no new features, for 6+ months.</p><p id="a9d3">What we expect to back-port:</p><ul><li id="0ce7">Bug fixes.</li><li id="a583">Changes to complete features new in v1.12 (e.g SSO+RBAC).</li></ul><p id="57d1">We don’t plan to back-port:</p><ul><li id="b6e9">UI bug fixes that are based on refactoring that is unique to v3.0. But you can run the v3.0 UI with the v2.12 controller.</li><li id="5658">New features.</li></ul><p id="295a">Argo Workflows v3.1 will contain enhancement to make it easier to write fan-out-fan-in workflows using artifacts, and well as conditional artifacts.</p><p id="f19c">Nothing as big as this is the work of one person, so beyond the core team, we must recognize these major contributors:</p><ul><li id="5fcb">Daisuke Taniwaki — Preferred Networks</li><li id="0754">Yuan Tang — Ant Group</li><li id="79bc">Mark White</li><li id="1c43">Daniel Herman</li><li id="3e99">Sam Elder — Keblotix</li><li id="25af">Michael Crenshaw — Colaberry/CCRi</li><li id="1d3f">Xianlu Bird — Aliyun</li><li id="d18e">Peter Salanik — CoreWeave</li><li id="e8b9">J.P. Zivalich — Pipekit</li><li id="30d6">Niklas Hansson — Sandvik CODE</li><li id="f435">Antoine Dao — Pollination</li><li id="8eca">Clemens Lange — CERN</li><li id="ba08">Vaibhav Page — Blackrock</li><li id="c4e7">Sumit Nagal — Intuit</li><li id="2139">David Breitgand — IBM</li></ul></div></div></div>]]>
            </description>
            <link>https://blog.argoproj.io/argo-workflows-v3-0-4d0b69f15a6e</link>
            <guid isPermaLink="false">hacker-news-small-sites-25991077</guid>
            <pubDate>Mon, 01 Feb 2021 17:47:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why shorter food supply chains aren’t necessarily better]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25991044">thread link</a>) | @finphil
<br/>
February 1, 2021 | https://nuadox.com/post/641939640543232000/short-food-supply-chains-conversation | <a href="https://web.archive.org/web/*/https://nuadox.com/post/641939640543232000/short-food-supply-chains-conversation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 
                 
                    
                    <article id="641939640543232000">
                        <div>
                            <div>
                                <a href="https://nuadox.com/post/641939640543232000/short-food-supply-chains-conversation"><h2>Let’s talk logistics: Why shorter food supply chains aren’t necessarily better</h2></a>
                                <figure data-orig-height="853" data-orig-width="1280"><img src="https://64.media.tumblr.com/3b6d3de257c70ad7108584d25c3ed612/e23af1d6cf07b765-fe/s1280x1920/5b2470073c2a32381da64c12642abe9e83d58676.png" data-orig-height="853" data-orig-width="1280" width="1280" height="853" alt="image"></figure><p><b>- By Richard Gray , Horizon -</b></p><p>

Fears over supermarket shortages during the early stages of the Covid-19 pandemic <a href="https://href.li/?https://eit.europa.eu/news-events/news/eit-food-report-reveals-impact-covid-19-pandemic-european-food-behaviours?b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F641939640543232000%2Fshort-food-supply-chains-conversation&amp;m=0&amp;ts=1612470590">led many people to buy their food from local producers</a>, raising the prospect of a transformation in the way people get their food in the future. But while eating locally and shorter supply chains are <a href="https://href.li/?https://ec.europa.eu/eip/agriculture/sites/agri-eip/files/eip-agri_brochure_short_food_supply_chains_2019_en_web.pdf?b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F641939640543232000%2Fshort-food-supply-chains-conversation&amp;m=0&amp;ts=1612470590">often viewed as a more sustainable alternative to our global food system</a>, the reality is much more complicated, explains Dr Tessa Avermaete, a bioeconomist at the Katholieke Universiteit Leuven in Belgium.

<br></p><p><b>What has the pandemic revealed about the way Europe gets its food?</b></p><p>On the consumer side there were really only a few problems with supplies in Europe. In Belgium, for example, we had some issues with yeast because suddenly everyone was at home and started baking. There were also some issues with <a href="https://href.li/?https://www.cbi.eu/news/bittersweet-impact-covid-19-cocoa-chocolate-market?b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F641939640543232000%2Fshort-food-supply-chains-conversation&amp;m=0&amp;ts=1612470590">chocolate due to the cacao supply</a> and a specific type of <a href="https://href.li/?https://www.euronews.com/2020/12/20/greek-olive-harvest-hit-as-pandemic-leads-to-labour-shortage?b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F641939640543232000%2Fshort-food-supply-chains-conversation&amp;m=0&amp;ts=1612470590">olives</a>. Not really things you need for a healthy diet.&nbsp;</p><p>What I think the Covid-19 crisis has shown is that actually the food supply chains are very robust. No one in Europe really went hungry because of Covid-19. But some farmers in Europe have suffered, particularly if they are exporting. In the potato sector, those exporting to China, for example, had tonnes of potatoes left. It has shown that we need to think about what happens when food supply chains are disrupted.</p><p><b>What have been the solutions to that?</b></p><p>One thing that people have talked a lot about is <a href="https://href.li/?http://www.fao.org/documents/card/en/c/cb1020en/?b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F641939640543232000%2Fshort-food-supply-chains-conversation&amp;m=0&amp;ts=1612470590">shorter supply chains</a>. Certainly, during the pandemic many more people have been finding they have a local farmer or supplier out there they can buy from. This can be good for the local economy and be a way of getting healthy food. But we have to be honest – it is only a tiny part of the overall market. And it is quite likely that people will go back to their normal retailer once the crisis is over. But what I like is that it has started to get people thinking more about where their food comes from. When you look at the food system it is actually quite complex.</p><p><b>Is buying local always more sustainable than buying from big retailers? </b></p><p>It’s easy to think that doing things locally is the right solution because it might on the surface seem to have a lower (environmental) footprint and reduce the risk of disruption. But not everything can be grown everywhere. There are some regions that have the right kind of fertile land needed for arable crops while others are better suited as pasture for livestock. Some land is suitable for soy but can’t be used to grow apple trees on. It makes sense to use your land in the way it is best suited for, and this is what our global food supply chains have allowed us to do.</p><p>We did some calculations at our university that if we tried to produce the livestock we consume in Belgium completely locally, then we would need double the land we have today just to produce fodder for the animals. In many cases it is more sustainable to produce food somewhere else and import it than grow it locally. Growing something in a heated greenhouse at a local farm can require more energy than growing it somewhere with more suitable climate and importing it by boat. The same applies with water - if it is too dry where you live, it can take a lot of extra water from the environment to grow some crops.</p><p>Bad weather conditions and plant diseases, or political disruption and wars could also prevent food from being produced locally at certain times. Global trade has given us some resilience to these.&nbsp;&nbsp;</p><p><b>Do local food networks have any advantages?</b></p><p>During the <a href="https://href.li/?https://cordis.europa.eu/project/id/613532?b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F641939640543232000%2Fshort-food-supply-chains-conversation&amp;m=0&amp;ts=1612470590">TRANSMANGO project</a> (to assess the vulnerability and resilience of Europe’s food systems) we looked at how certain <a href="https://href.li/?https://link.springer.com/article/10.1007/s12571-018-0860-x?b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F641939640543232000%2Fshort-food-supply-chains-conversation&amp;m=0&amp;ts=1612470590">alternative food networks contribute to food security</a>. These are things like small organic farms, farmers markets, local deliveries and community supported agriculture. They have a really important social factor because they can bring together communities. But in terms of overall food availability their contribution is limited. And we also saw that many of these alternative food networks are only accessible to people in middle and high socioeconomic classes. They don’t reach out to people in the lower classes.</p><p><b>Are there other disadvantages?</b></p><p>There is also an important issue when it comes to food processing. With a lot of these initiatives you get unprocessed food – people have to do a lot of preparation to be able to then eat it. That ability to prepare food is just as important as the availability itself as you can only eat food if you know how to prepare it properly.&nbsp;Unless you know this, you are going to be food insecure.</p><p><b>What do you mean by being ‘food insecure’?</b></p><p>It’s about food availability, but also it’s about nutritional value. If we look at a global level, we produce enough calories to feed the world. But if you look in terms of fruit and vegetables, there is still a lack. So, the problem is that we don’t have enough to feed the world in a healthy way. But that’s just one side of the story – there are so many people who are overweight and the health costs that go together with that are huge. Here in Europe it is an area that needs far more attention than malnutrition.</p><p><b>Are there any problems you see coming in the future?&nbsp;</b></p><p>One of the biggest challenges at the moment is the need for policies that strengthen the position of the farmer and simultaneously reduce the environmental impact of the sector. We need governments that take action based on scientific evidence, not based on beliefs or driven by electoral concerns. I have no doubt that Europe has smart and ambitious farmers, but they need to be incentivised to take actions that contribute to a more sustainable, future-proof food system. Local food networks have a part to play, but I hope we don’t lose sight of how important big producers are for food security too.</p><p><i>The research in this article was funded by the EU.</i></p><p><i> This post&nbsp;<a href="https://href.li/?https://horizon-magazine.eu/article/qa-why-shorter-isn-t-necessarily-better-when-it-comes-food-supply-chains.html?b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F641939640543232000%2Fshort-food-supply-chains-conversation&amp;m=0&amp;ts=1612470590">Q&amp;A: Why shorter isn’t necessarily better when it comes to food supply chains</a>&nbsp;was originally published on&nbsp;<a href="https://href.li/?https://horizon-magazine.eu/?b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F641939640543232000%2Fshort-food-supply-chains-conversation&amp;m=0&amp;ts=1612470590">Horizon: the EU Research &amp; Innovation magazine | European Commission</a>&nbsp;under a Creative Commons license.</i></p><p>–</p><h2><b>Read Also</b></h2><p><a href="https://nuadox.com/post/632440031725912064/food-waste-and-cities">Food waste: Cities can make the difference</a></p>
                    
                      
                    
                    
                    
                    
                    
                    
                    
                    
                                             
                                <p><span>
                                    <p>
                                    
                                        <a href="https://nuadox.com/tagged/food">food</a>
                                    
                                        <a href="https://nuadox.com/tagged/supply-chain">supply chain</a>
                                    
                                        <a href="https://nuadox.com/tagged/logistics">logistics</a>
                                    
                                        <a href="https://nuadox.com/tagged/agriculture">agriculture</a>
                                    
                                        <a href="https://nuadox.com/tagged/sustainability">sustainability</a>
                                    
                                        <a href="https://nuadox.com/tagged/nutrition">nutrition</a>
                                    
                                        <a href="https://nuadox.com/tagged/health">health</a>
                                    
                                        <a href="https://nuadox.com/tagged/featured">featured</a>
                                    
                                        <a href="https://nuadox.com/tagged/economics">economics</a>
                                    
                                        <a href="https://nuadox.com/tagged/retail">retail</a>
                                    
                                    </p>
                                </span></p>
                                
                            </div>
                        </div>
                    </article>
                 
                </div></div>]]>
            </description>
            <link>https://nuadox.com/post/641939640543232000/short-food-supply-chains-conversation</link>
            <guid isPermaLink="false">hacker-news-small-sites-25991044</guid>
            <pubDate>Mon, 01 Feb 2021 17:45:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Cult of Best Practice]]>
            </title>
            <description>
<![CDATA[
Score 77 | Comments 62 (<a href="https://news.ycombinator.com/item?id=25990929">thread link</a>) | @zdw
<br/>
February 1, 2021 | https://domk.website/blog/2021-01-31-cult-of-best-practise.html | <a href="https://web.archive.org/web/*/https://domk.website/blog/2021-01-31-cult-of-best-practise.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <p><time datetime="2021-01-31">31 Jan 2021</time>
    /
    <span>~7 min</span>
  </p>
  


<p>Best practices are, despite the name, not universally good.</p>

<p>Many best practices in programming don’t meet the definition. They spread not based on merit or evidence but thanks to authority bias and social utility. As they spread, they lose nuance. As they lose nuance, they become easier to evangelise. Combined with lack of experience, they can lead to cult-like behaviour.</p>

<p>Think of an engineering team that got obsessed with a best practice, like test-driven development or writing user stories, to the point of detriment. Many developers have fallen into that trap, myself included.</p>

<p>Why can best practices be harmful? Why do we like following them? When and how do they go wrong? To answer these questions, we need to understand where they come from and how they spread in the context of programming.</p>

<h2 id="impostor-best-practices">Impostor Best Practices</h2>

<p>The main reason some programming best practices are harmful is that they are not real best practices.</p>

<p>Look at the official definition: “A best practice is a method or technique that has been generally accepted as superior to any alternatives because it produces results that are superior to those achieved by other means […]”. <sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> The key parts of the definition are “generally accepted” and “superior to any alternatives”.</p>

<p>The problem with many programming best practices is that they <em>pretend</em> to conform to that definition, but they do not.</p>

<p>Some best practices aren’t generally accepted. They come from different, less reliable sources of authority. It could be a prominent individual or a specific community who present something as widely accepted when it’s their own experience or opinion.</p>

<p>We might have a proponent of object-oriented programming saying that it is an accepted best practice, but not everyone agrees. If the proponent is respected and followed in the programming community, many people will put a lot of weight on their opinion, but that doesn’t make it generally accepted. There are different competing paradigms each with their pros and cons.</p>

<p>Some best practices are not superior in outcomes. They claim they are, but objectively there are equivalent alternatives. For example, is functional programming superior to object-oriented? We can’t say one is better than the other, even though they are both presented as a best practice by some.</p>

<p>The problem with superiority is that most programming best practices aren’t evidence-based. Programming is too young, fast-changing and complex to have done the research to establish the evidence for something consistently producing better outcomes. We work in the world of opinions, feelings and anecdotal evidence.</p>

<p>Some best practices are also very volatile. Fast-moving languages and frameworks declare something best practice and supersede it a year later. That isn’t inherently wrong, but it’s a sign of how fast our understanding of best can evolve, while best practices are expected to be time-tested. <sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup></p>

<p>However, not all best practices in programming are impostors. There are time-tested, generally accepted, and superior practices. For example, the general idea of automated testing now meets that definition.</p>

<p>Nor are all impostor best practices bad. Not being universally accepted can mean they aren’t universally accepted <em>yet</em>. Not being superior in general might be a scope problem, and the practice is superior in specific situations.</p>

<p>However, these cases need to be interpreted with nuance, which brings us to the next problem.</p>

<h2 id="lost-in-translation">Lost In Translation</h2>

<p>Good best practices are <em>simple and universal</em>. Many programming best practices tackle complex issues that require nuance and context — but that nuance and context get lost as the best practice spreads.</p>

<p>Consider this example: someone, through a lot of trial and error, found a good way to tackle a problem. Because of the learning process, they understand the nuances in how and when to apply it.</p>

<p>The solution works for them and they start sharing their lessons as best practice. This gets picked up by people who skipped the learning and went straight to applying it, missing out on some nuance. Those people share it again. A new cohort of people picks it up. They misunderstand it more and share it again.</p>

<p>Soon, all understanding of why the practice works is lost. People are parroting it as a simplified, absolute catchphrase. “Always write the tests before the implementation”. <sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup></p>

<p>The complexity can increase over time too. An idea that was originally simple that required a lot of nuanced interpretation is made increasingly complex by people who miss the point.</p>

<p>Take the example of “agile”. Originally a set of 12 principles, it has been turned into monstrous frameworks that oppose those principles by consultancies that sell organisational transformation.</p>

<p>Once all nuance is lost, the conditions are perfect for the idea to spread. It originated from someone with respect, experience, and authority. The simplicity makes it sound easy. People who don’t understand it sell it as a panacea. As a result, people can learn about it quickly and start evangelising. Despite its merit-based origin, it has become a social phenomenon.</p>



<p>The social aspect of how best practices spread helps us answer the next question — why do we like following them?</p>

<p>When we lack the experience and confidence to form our own opinions, we defer to the next best thing: an authority. This is a well-known cognitive bias. <sup id="fnref:4" role="doc-noteref"><a href="#fn:4">4</a></sup></p>

<p>Thanks to the authority bias, best practices have a social utility. They give us something that people are biased to believe that we can lean on. There are many examples of this utility:</p>

<ul>
  <li>A way to hedge our bets. If we are wrong, we can defend ourselves by saying that we just followed best practices. How could someone blame us?</li>
  <li>A way to mimic the best. If someone we see as an authority does something, it’s natural for us to try to learn and copy what they do.</li>
  <li>A virtue-signalling mechanism. If something is “the best”, we naturally want to signal to everyone that we also do what is best.</li>
  <li>A way to fit in. If everyone around us considers something “the best”, we would be hard-pressed to go against our peers.</li>
</ul>

<h2 id="the-cult">The Cult</h2>

<p>Because of the social nature of best practices, it’s easy for herd mentality to kick in.</p>

<p>Imagine a team of inexperienced developers with no one seasoned to lean on. They can’t make all decisions in an informed way — following best practices is the next best option.</p>

<p>They struggle with something, and they search for a solution. They come across a simple-looking practice that addresses their problem, supported by someone prominent. Is your code buggy and unreliable? Write more tests. Is your code hard to test? Adopt test-driven development! <sup id="fnref:3:1" role="doc-noteref"><a href="#fn:3">3</a></sup></p>

<p>Once a solution like that is found, everyone is motivated by the authority and social utility of it. It gets adopted ad absurdum. All nuance is lost. Soon you have a team that insists that every ticket is written as a user story, or that every class has to have tests because it’s <em>best practice</em>.</p>

<h2 id="way-out">Way Out</h2>

<p>It might seem obvious that adopting something obsessively is a bad idea, but many teams out there operate exactly like that.</p>

<p>The way out of the cult starts with understanding what the commonly presented best practices are — a social phenomenon.</p>

<p>Once we realise that, the first step is understanding where they come from and what problem they solve — understand their origins and the subtleties of applying them successfully. <sup id="fnref:5" role="doc-noteref"><a href="#fn:5">5</a></sup></p>

<p>The next step is to make our own mistakes and learn from them. Break the rules and understand what happens when we don’t follow a particular practice. Follow it to its logical conclusion and see what happens then. <sup id="fnref:6" role="doc-noteref"><a href="#fn:6">6</a></sup></p>

<p>The trial and error learning involved gives us knowledge much deeper than what we would gain by following the rules.</p>

<p>Having made our own mistakes, the third and final step is to form our own opinions and speak up.</p>

<p>If we’ve understood where a best practice comes from, and we’ve tried what happens when we don’t follow it, we should have the confidence to make and defend our own opinions about it. We can help the rest of our team see the full picture and break the cult.</p>

<p>Going against the flow like that can be hard. Convincing the rest of a team that something they believe in isn’t what it promised to be, requires skill and patience. Telling them won’t be enough. You need to take them on the same learning journey you went on. That’s how you make progress.</p>

<p>To short-circuit that learning process and prevent best practice cults from forming in the first place, you need to have enough senior engineers on your teams. Each team needs to have someone who is experienced and confident enough to become a trusted authority for their colleagues. Someone who can make informed decisions and bring the necessary nuance.</p>

<p>We need to encourage open-mindedness and independent thinking. We need to scrutinise best practices and understand them in depth. That’s how we stop the cult.</p>

<hr>



</article></div>]]>
            </description>
            <link>https://domk.website/blog/2021-01-31-cult-of-best-practise.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25990929</guid>
            <pubDate>Mon, 01 Feb 2021 17:37:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pip has dropped support for Python 2]]>
            </title>
            <description>
<![CDATA[
Score 68 | Comments 49 (<a href="https://news.ycombinator.com/item?id=25990891">thread link</a>) | @feross
<br/>
February 1, 2021 | https://pip.pypa.io/en/stable/news/#id4 | <a href="https://web.archive.org/web/*/https://pip.pypa.io/en/stable/news/#id4">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<li><p><strong>PROCESS</strong> Version numbers are now simply <code><span>X.Y</span></code> where the leading <code><span>1</span></code>
has been dropped.</p></li>
<li><p><strong>BACKWARD INCOMPATIBLE</strong> Dropped support for Python 3.1.</p></li>
<li><p><strong>BACKWARD INCOMPATIBLE</strong> Removed the bundle support which was deprecated in
1.4. (#1806)</p></li>
<li><p><strong>BACKWARD INCOMPATIBLE</strong> File lists generated by <cite>pip show -f</cite> are now
rooted at the location reported by show, rather than one (unstated)
directory lower. (#1933)</p></li>
<li><p><strong>BACKWARD INCOMPATIBLE</strong> The ability to install files over the FTP protocol
was accidentally lost in pip 1.5 and it has now been decided to not restore
that ability.</p></li>
<li><p><strong>BACKWARD INCOMPATIBLE</strong> PEP 440 is now fully implemented, this means that
in some cases versions will sort differently or version specifiers will be
interpreted differently than previously. The common cases should all function
similarly to before.</p></li>
<li><p><strong>DEPRECATION</strong> <code><span>pip</span> <span>install</span> <span>--download-cache</span></code> and
<code><span>pip</span> <span>wheel</span> <span>--download-cache</span></code> command line flags have been deprecated and
the functionality removed. Since pip now automatically configures and uses
it’s internal HTTP cache which supplants the <code><span>--download-cache</span></code> the
existing options have been made non functional but will still be accepted
until their removal in pip v8.0. For more information please see
<a href="https://pip.pypa.io/en/stable/reference/pip_install.html#caching">https://pip.pypa.io/en/stable/reference/pip_install.html#caching</a></p></li>
<li><p><strong>DEPRECATION</strong> <code><span>pip</span> <span>install</span> <span>--build</span></code> and <code><span>pip</span> <span>install</span> <span>--no-clean</span></code> are now
<em>NOT</em> deprecated.  This reverses the deprecation that occurred in v1.5.3.
(#906)</p></li>
<li><p><strong>DEPRECATION</strong> Implicitly accessing URLs which point to an origin which is
not a secure origin, instead requiring an opt-in for each host using the new
<code><span>--trusted-host</span></code> flag (<code><span>pip</span> <span>install</span> <span>--trusted-host</span> <span>example.com</span> <span>foo</span></code>).</p></li>
<li><p>Allow the new <code><span>--trusted-host</span></code> flag to also disable TLS verification for
a particular hostname.</p></li>
<li><p>Added a <code><span>--user</span></code> flag to <code><span>pip</span> <span>freeze</span></code> and <code><span>pip</span> <span>list</span></code> to check the
user site directory only.</p></li>
<li><p>Silence byte compile errors when installation succeed. (#1873)</p></li>
<li><p>Added a virtualenv-specific configuration file. (#1364)</p></li>
<li><p>Added site-wide configuration files. (1978)</p></li>
<li><p>Added an automatic check to warn if there is an updated version of pip
available. (#2049)</p></li>
<li><p><cite>wsgiref</cite> and <cite>argparse</cite> (for &gt;py26) are now excluded from <cite>pip list</cite> and
<cite>pip freeze</cite>. (#1606, #1369)</p></li>
<li><p>Add <code><span>--client-cert</span></code> option for SSL client certificates. (#1424)</p></li>
<li><p><cite>pip show --files</cite> was broken for wheel installs. (#1635, #1484)</p></li>
<li><p>install_lib should take precedence when reading distutils config.
(#1642, #1641)</p></li>
<li><p>Send <cite>Accept-Encoding: identity</cite> when downloading files in an attempt to
convince some servers who double compress the downloaded file to stop doing
so. (#1688)</p></li>
<li><p>Stop breaking when given pip commands in uppercase (#1559, #1725)</p></li>
<li><p>pip no longer adds duplicate logging consumers, so it won’t create duplicate
output when being called multiple times. (#1618, #1723)</p></li>
<li><p><cite>pip wheel</cite> now returns an error code if any wheels fail to build. (#1769)</p></li>
<li><p><cite>pip wheel</cite> wasn’t building wheels for dependencies of editable requirements.
(#1775)</p></li>
<li><p>Allow the use of <code><span>--no-use-wheel</span></code> within a requirements file. (#1859)</p></li>
<li><p>Attempt to locate system TLS certificates to use instead of the included
CA Bundle if possible. (#1680, #1866)</p></li>
<li><p>Allow use of Zip64 extension in Wheels and other zip files. (#1319, #1868)</p></li>
<li><p>Properly handle an index or --find-links target which has a &lt;base&gt; without a
href attribute. (#1101, #1869)</p></li>
<li><p>Properly handle extras when a project is installed via Wheel. (#1885, #1896)</p></li>
<li><p>Added support to respect proxies in <code><span>pip</span> <span>search</span></code>.
(#1180, #932, #1104, #1902)</p></li>
<li><p><cite>pip install --download</cite> works with vcs links. (#798, #1060, #1926)</p></li>
<li><p>Disabled warning about insecure index host when using localhost. Based off of
Guy Rozendorn’s work in #1718. (#1456, #1967)</p></li>
<li><p>Allow the use of OS standard user configuration files instead of ones simply
based around <code><span>$HOME</span></code>. (#2021)</p></li>
<li><p>When installing directly from wheel paths or urls, previous versions were not
uninstalled. (#1825, #804, #1838)</p></li>
<li><p>Detect the location of the <code><span>.egg-info</span></code> directory by looking for any file
located inside of it instead of relying on the record file listing a
directory. (#2075, #2076)</p></li>
<li><p>Use a randomized and secure default build directory when possible.
(#1964, #1935, #676, #2122, CVE-2014-8991)</p></li>
<li><p>Support environment markers in requirements.txt files. (#1433, #2134)</p></li>
<li><p>Automatically retry failed HTTP requests by default. (#1444, #2147)</p></li>
<li><p>Handle HTML Encoding better using a method that is more similar to how
browsers handle it. (#1100, #1874)</p></li>
<li><p>Reduce the verbosity of the pip command by default. (#2175, #2177, #2178)</p></li>
<li><p>Fixed <a href="https://github.com/pypa/pip/issues/2031">#2031</a> - Respect sys.executable on OSX when installing from
Wheels.</p></li>
<li><p>Display the entire URL of the file that is being downloaded when downloading
from a non PyPI repository. (#2183)</p></li>
<li><p>Support setuptools style environment markers in a source distribution. (#2153)</p></li>
</div></div>]]>
            </description>
            <link>https://pip.pypa.io/en/stable/news/#id4</link>
            <guid isPermaLink="false">hacker-news-small-sites-25990891</guid>
            <pubDate>Mon, 01 Feb 2021 17:34:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Analysing Clubhouse’s Growth Strategy: Invite-Only Exclusivity]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25990845">thread link</a>) | @PeteBoyle
<br/>
February 1, 2021 | https://have-a-word.com/clubhouse-marketing | <a href="https://web.archive.org/web/*/https://have-a-word.com/clubhouse-marketing">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				
				
				<div>
				
				
				
<p>Clubhouse is the brand new social media network that’s taking the marketing world by storm.&nbsp;</p>



<p>Seems like every time I log onto other platforms people are either talking about Clubhouse or inviting people to their clubhouse “rooms”.</p>



<p>What’s incredible though is how, at the time of writing, Clubhouse has grown to ~2,000,000 users despite being less than a year old.&nbsp;&nbsp;</p>



<p>With such meteoric growth, we thought Clubhouse’s growth strategy and business was worth a quick analysis.&nbsp;</p>



<p>Here’s what we’ve dug up.&nbsp;&nbsp;</p>



<h2><span id="Clubhouse_in_30_seconds"></span>Clubhouse in 30 seconds<span></span></h2>



<ul><li><strong>Who are we analysing today?: </strong>Clubhouse</li><li><strong>What does Clubhouse do?: </strong>It’s a live-audio social media app</li><li><strong>Why should you care?: </strong>It’s the hottest new social platform and growing at <em>lightspeed</em>.</li><li><strong>How are they doing it?:</strong> Invite-only memberships + strategic PR/content buzz.&nbsp;</li><li><strong>When was Clubhouse founded?</strong> – In March 2020</li></ul>



<h2><span id="Clubhouse_user_base"></span>Clubhouse user base<span></span></h2>



<p>According to the Clubhouse blog, in a single week during January 2021 they managed to get 2,000,000 users.&nbsp;&nbsp;</p>



<p>Up from December 2020’s total of 600,000, which is crazy growth.&nbsp;&nbsp;&nbsp;</p>







<p>According to that same article, those users were made up of…</p>



<ul><li>Musicians</li><li>Scientists</li><li>Creators</li><li>Athletes</li><li>Comedians</li><li>Parents</li><li>Entrepreneurs</li><li>Stock traders</li><li>Non-profit leaders</li><li>Authors</li><li>Artists</li><li>Real-estate agents</li><li>Sports fans</li><li>And more</li></ul>



<p>Which doesn’t really help us in analysing their ideal customer base.&nbsp;&nbsp;</p>



<p>In my experience, I’ve seen a huge number of marketers, VCs, and SaaS founders on the platform.&nbsp;&nbsp;</p>



<p>The main interesting point is how they grew their user base so quickly.&nbsp;</p>



<p>That 600,000 number for 2020 was taken in December, and the 2,000,000 number was in January 2021.&nbsp;</p>



<p>Which means they grew their user base by more than 50% in a 1-2 month time period.&nbsp;&nbsp;</p>



<p>It also puts them at a higher user base than other social media platforms when they were in their first year.&nbsp;</p>







<p>We’ll cover how we think they did this shortly.&nbsp;</p>



<h2><span id="Clubhouse_financials"></span>Clubhouse financials<span></span></h2>



<p>This is where things get interesting with Clubhouse.&nbsp;&nbsp;</p>



<p>There was a lot of buzz in May 2020 when they closed their first round of funding of $10,000,000.</p>



<p>This initial funding round led to them being valued at a whopping $100,000,000. Not bad for 2 months of operation.&nbsp;</p>



<p>However, in 2021, they <a href="https://www.crunchbase.com/organization/clubhouse-voice/company_financials" target="_blank" rel="noreferrer noopener">closed a Series B</a> of $100,000,000 which has pushed their valuation to $1,000,000,000 ($1B).</p>



<div><figure><img loading="lazy" src="https://lh6.googleusercontent.com/RpiCBFv9opf3p4l2w91kX0UjZ4OOhNZureu_eAmfxWYVKRU2HUmLpIWUfjE13ZLOhTFn6m2gLMIkk-pyD6DYWWmUFPte-ZWN3F7TRVWXeYwjQ1QKbDhi5ODffidIWSxSBCihyjxo" alt="Clubhouse funding and valuation" width="789" height="487" title="Points scored" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<p>According to Clubhouse, that Series B is funding from 180 different investors. Which is a crazy huge number and must make their cap table a nightmare to manage.&nbsp;&nbsp;</p>



<h2><span id="Clubhouses_revenue_model"></span>Clubhouse’s revenue model<span></span></h2>



<p>Right now, Clubhouse doesn’t actually have any revenue model.&nbsp;&nbsp;</p>



<p>They don’t charge for usage nor do they run ads on the platform.&nbsp;</p>



<p>Without a public revenue model, it’s hard to say how that $1B valuation is justified.&nbsp;&nbsp;</p>



<p>We’re sure they’ve got plans on monetisation strategies, but they’re not yet public knowledge.&nbsp; We have a few ideas of what they might explore, but it’s all just conjecture right now so we won’t spend a lot of time on this.&nbsp;</p>



<p>Here are a few options we think they might explore.&nbsp;&nbsp;</p>



<ul><li><strong>Sponsorships for people who can generate large audiences</strong> (maybe even build out a sponsor &lt;&gt; influencer management dashboard)</li><li><strong>A membership/patron system like Patreon/Only Fans</strong> (influencers have premium fans who get exclusive access)</li><li><strong>Built-in checkout and payments</strong> (so speakers can generate sales of their books/courses directly from Clubhouse)</li><li><strong>Tip-system like Twitch / YouTube live streaming</strong> (users tip a few bucks if they like the content)</li></ul>



<p>All is hypothetical and pure conjecture at this point.&nbsp;</p>



<p>It’ll be interesting to see how this side of the product develops.&nbsp;&nbsp;</p>



<h2><span id="Clubhouses_growth_strategy"></span>Clubhouse’s growth strategy<span></span></h2>



<div><figure><img loading="lazy" src="https://lh5.googleusercontent.com/11nHwbMdGfJEtmcn1eOsPR1MKw3p0QAH5wl8ImebeKAwt9XLIt41hciHuVbrKo3oLdPsv6t6vP8RvTeGtdhKWgz_i0EW11jU4qsoP2t00NKUWfDS0m5ObdBUZq7hE0ilY9sLs0BO" alt="Clubhouse's velvet rope strategy" width="685" height="513" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<p>Clubhouse is using what’s known as the “Velvet Rope” strategy. They’re creating exclusivity with a combination of invite-only memberships and strategic hype.&nbsp;</p>



<p>If you’ve never heard of the Velvet Rope strategy, think of the VIP area of a club.&nbsp;</p>



<p>It’s often separated by a velvet rope, which separates the “VIPs” from the rest of the crowd.&nbsp;</p>



<p>If you want in, you either need to be special or be invited in by someone special.&nbsp;&nbsp;</p>



<p>Once you’re in, you are now one of the “special people”.&nbsp;</p>



<p>Anything behind that velvet rope is seen as more desirable because it’s hard to acquire. It’s exclusive.</p>



<p>Clubhouse’s invitation-only approach makes their app exclusive, thus, making more people want it.&nbsp;&nbsp;&nbsp;&nbsp;</p>



<h2><span id="Why_is_Clubhouses_Velvet_Rope_Strategy_working_so_well"></span>Why is Clubhouse’s Velvet Rope Strategy working so well?&nbsp;<span></span></h2>



<p>There are some simple, but highly effective psychological principles at play with this strategy.&nbsp;</p>



<p>Let’s unpack them.&nbsp;</p>



<h3>Reason #1) Exclusivity builds FOMO.</h3>



<p>The more insiders are talking about Clubhouse, the more outsiders will want in.&nbsp;</p>



<div><figure><img loading="lazy" src="https://lh4.googleusercontent.com/ThR705zzdBmED6aATShcjoybpFze5sqvfItYOMTkoYpBw4YYfMj-w_IrYZ9zOi74wAs8QYA9wgSOIPShsnVxQM0ZB8R0I8o2A91nYPwrThAkuc5rfuWI0T2vOpz6QCqJ94aW2ZeA" alt="Clubhouse's velvet rope invite-only strategy" width="659" height="493" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<p>And if you spend any time on social, you’ll know a lot of people are talking about Clubhouse.&nbsp;&nbsp;</p>



<p><strong><em>This creates a lot of demand for relatively little supply.&nbsp;</em></strong></p>



<p>The result is people begging their friends for an invite, and people with invites treating them with a lot of care and consideration.</p>



<div><figure><img loading="lazy" src="https://lh4.googleusercontent.com/4sPsfM98Co6BvHKOJDEnLP5ZjG7G0dKtpGEeTkdrfnvvUEUDyPDUVGEMiqncTwjrU6XjsvvaiWXX75a-W0NHwvuBD-u5WaVE0pE2Sf974HVl8-tUEsbPnlrAT0HO_38q5RPybNTB" alt="Clubhouse viral marketing" width="669" height="821" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<div><figure><img loading="lazy" src="https://lh3.googleusercontent.com/iVLyRrI_LvEDUurlGVW1KqUPCe1jOK-sxx4aWwdOEq96nLX0G8btzWF_ysIb7OImq1eY9YCKg9j5fTBaRLSvmR271dNE9D-yres7LWbGk_yITOzlOIN0ygdDPLFKlLcjRdFmYelU" alt="C lubhouse's viral social media marketing" width="690" height="1190" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<h3>Reason #2) Invites from friends build trust in the app.</h3>



<p>It’s not just about getting invited to the app — <em>it’s about getting invited by a friend.</em></p>



<p>If you were to just receive an invite from a random internet stranger….it’d be weird, right?&nbsp;</p>



<p>And if the brand you’d never heard of sent it, would you check it out? Probably not.&nbsp;</p>



<p>But Clubhouse invites come from your friends.&nbsp;</p>



<p>And that means you’re getting “in” to something that’s already been vetted by someone you know and trust.&nbsp;</p>



<p><strong><em>You trust them, they trust Clubhouse, ergo, you trust Clubhouse.</em></strong>&nbsp;</p>



<div><figure><img loading="lazy" src="https://lh6.googleusercontent.com/FOSIARMhDkXCqYfnn5KQ0kL-4B1Lrwq6K3XR_0eWwOYtULABrpB1xalnhyHV0XHhswIcV2apm1zvYklUUhZynsbYs-NvMg9xD6qmH5PlhiUhjHLYLX16CWFNuj7X7CrDPFlJtoih" alt="Friend invites build more trust" width="696" height="521" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<h3>Reason #3) Invites from friends are more likely to convert.</h3>



<p>This doesn’t need any explanation.&nbsp;</p>



<p>The combination of FOMO and the trust friendly invites create means you’re way more likely to take the action.&nbsp;</p>



<h3>Reason #4) Invites from friends make it cheap to scale&nbsp;</h3>



<p>You might think gating your tool or service behind this kind of invite-only joining process would hamper your chances.&nbsp;</p>



<p>But it actually does the opposite.&nbsp;</p>



<p>As we’ve already mentioned, those invites obliterate any trust issues because a friend has already vetted the service.&nbsp;&nbsp;</p>



<p>So the actual sign up is an action happily taken.&nbsp;&nbsp;</p>



<p>It also doesn’t require any financial cost beyond finding the initial users.&nbsp;&nbsp;</p>



<p>As for scale, it also works insanely well.&nbsp;</p>



<p>Most brands can only dream of having each customer refer two of their friends.&nbsp;&nbsp;</p>



<p>If you make the process easy (as Clubhouse has) the potential scale is incredible.&nbsp;</p>



<p>The best illustration of this is to imagine you have a single penny.&nbsp;</p>



<p>Each day that penny’s value doubles.&nbsp;&nbsp;</p>



<p>So on day one you’d have 1p, day two that would double to 2p. Day three would see you collect 4p and so on.&nbsp;</p>



<p>Within 30 days you’d end up with over $5,300,000 dollars.&nbsp;&nbsp;</p>



<div><figure><img loading="lazy" src="https://lh4.googleusercontent.com/JAOBS65_TN66h_BAtglDGlHmCUZjTly5XbsNhafEk4uMXgQmiarbvT2sHDx1hrHc2RvgA9gpGjXvSrJUhycxwlw0tQr0UNKqipZe5hCUszx4JLVanGIS99BYu_y-hdnmA7OP2MBf" alt="Doubling users exponential scale" width="718" height="448" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<p>Once you hit a critical mass of users the scale from a double invite pays huge rewards.&nbsp;</p>



<p>Clubhouse’s invite approach offers the same kind of benefits.&nbsp;</p>



<p>Sure, it might be a low start, but as each person refers 2 others, you end up with an exponential growth machine.&nbsp;&nbsp;</p>



<div><figure><img loading="lazy" src="https://lh3.googleusercontent.com/B7OAUs5XY-MngXlfi-jG64t_mQKxgYakY-UrmM1aZKkR79506-p6BfpeMHMVeBjmhkCIrD8FQ1DzDgR3KhdFJ6OoX5_zG_qLzh0VkziO_llXETfzs_2FRXTId43eaEO7oU4EVeIE" alt="Clubhouse's growth strategy" width="566" height="377" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<h2><span id="How_can_you_recreate_Clubhouses_strategy_in_your_business"></span>How can you recreate Clubhouse’s strategy in your business?&nbsp;<span></span></h2>



<p>It’s easy to look at something that’s already been done and say “that’s genius”.&nbsp;</p>



<p>Knowing how to apply it to your business is another matter. And this is the difference between the brands that grow and those that don’t.&nbsp;</p>



<p>We’re going to attempt to recreate Clubhouse’s invite strategy within this blog article as an experiment.&nbsp;&nbsp;</p>



<div><div>
<div><div>
<p>Below this section you’ll find our own “velvet rope”.&nbsp;</p>



<p id="experiment">Behind it you’ll find a step-by-step process to action a similar strategy in your brand.&nbsp;</p>



<p>The cost of admission is to share this with your network (would be great if you could @ 2 people who would benefit from this info so we can better mimic the Clubhouse approach, that would be great).&nbsp;</p>



<p>This should, in theory, drive more targeted traffic to this post and help us “convert” more people.&nbsp;&nbsp;</p>



<p>Here’s how we’re viewing the experiment.&nbsp;</p>



<ul><li><strong>Hypothesis </strong>– If each interested person invites 2 of their friends to read this, we’ll 10X traffic for free because invites from friends carry intrinsic trust</li><li><strong>Action for you to take</strong> – Click on the below sharing buttons and mention a specific friend who would like this in the share (@friend)&nbsp;</li><li><strong>What you’ll get for helping – </strong>We’re offering a couple of rewards for helping us with this including…&nbsp;<ul><li>Detailed step-by-step guide to implementing a similar system yourself</li><li>A live tracker of traffic generated to this post specifically through this invite system</li><li>The red flags you need to be aware of if using an invite strategy&nbsp;</li><li>Recommendation of tools to use for this</li><li>Ability to join our email list where we detail more of these kinds of experiments</li></ul></li></ul>



<p><strong>If you want that stuff, you’re gonna have to share though. </strong></p>



<p><strong>We’re going through our mentions every day to see who has shared it and then we’re sending them the details in their DMs.  </strong></p>



<p>If you want to help with this experiment, click on one of the buttons below for the network you’re most active on.  </p>



<p>If it’s Twitter, a pre-written Tweet will show up. Feel free to share it as is, or (preferably) add the @name of someone you think could benefit from this.  </p>



<p>If LinkedIn, the button will take you to a post that I’ve written on my profile promoting this piece.  Drop a comment below it tagging the name of the person you think could benefit from this. </p>
</div></div>



<p>If there’s another network you prefer, feel free to simply share it with your friends who would benefit.  </p>
</div></div>















<h5><strong>Velvet rope ~~~~~~~~ Velvet rope</strong></h5>



<p>Thank you so much for helping out with our little experiment.&nbsp;</p>



<p>Below, I’ve listed a couple of actions that we would take were we trying to fully replicate Clubhousse’s invite system.&nbsp;</p>



<h3>#1) Pick the right influencers and get them on board.</h3>



<p>The Velvet Rope Strategy depends heavily on you seeding the “behind the rope” section with some genuine&nbsp; heavy hitters.&nbsp;</p>



<p>Influencers other people want to hear from, listen to, or be associated with.&nbsp;&nbsp;</p>



<p>If you can …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://have-a-word.com/clubhouse-marketing">https://have-a-word.com/clubhouse-marketing</a></em></p>]]>
            </description>
            <link>https://have-a-word.com/clubhouse-marketing</link>
            <guid isPermaLink="false">hacker-news-small-sites-25990845</guid>
            <pubDate>Mon, 01 Feb 2021 17:30:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Detections as Code]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25990739">thread link</a>) | @kartikeypan
<br/>
February 1, 2021 | https://blog.runpanther.io/detections-as-code/ | <a href="https://web.archive.org/web/*/https://blog.runpanther.io/detections-as-code/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                
                <article id="post-1501">

                    
                    
                    
                    
                    
                    <div>
                        
<h4>How modern teams can automate security analysis at scale in the era of everything-as-code.</h4>



<p><em><strong>TL;DR</strong>: Adopt a modern, test-driven methodology for securing your organization with Detections-as-Code.</em></p>



<p>Over the past decade, threat detection has become business-critical and even more complicated. As businesses move to the cloud, manual threat detection processes are no longer able to keep up. How can teams automate security analysis at scale and address the challenges that threaten business objectives? The answer lies in treating threat detections like software or detections-as-code.</p>



<p><em>Watch our&nbsp;</em><a href="https://runpanther.io/webinars/scaling-security-detections-as-code-panther-cedar/"><em><strong>On Demand Webinar: Scaling Security with Detections-as-Code with Cedar</strong></em></a><em>&nbsp;to find out how Cedar uses Panther to leverage Detections-as-Code to build high-signal alerts.</em></p>



<h2 id="what-are-detections"><span id="What_are_Detections"></span>What are Detections?<span></span></h2>



<p>Detections define logic for analyzing security log data to identify attacker behaviors. When a rule is matched, an alert gets sent to your team for containment or investigation.</p>



<h3 id="introduction-to-panther">Introduction to Panther</h3>



<p><a href="https://github.com/panther-labs/panther"><strong>Panther</strong></a>&nbsp;is an open source, security data analytics platform designed to alleviate the problems of traditional SIEMs. Panther is&nbsp;<strong>built</strong>&nbsp;<strong>for security engineers</strong>, by security engineers. Rather than inventing yet another DSL, Panther offers security teams a&nbsp;<strong>Python rules-engine</strong>&nbsp;to write expressive threat detections and automate detection and response at cloud-scale. Its modular and open approach offers easy integrations and&nbsp;<strong>flexible detections</strong>&nbsp;to help you build a modern security operations pipeline.</p>



<h3 id="an-example-detection-in-panther">An Example Detection in Panther</h3>



<p>When writing a detection in Panther, &nbsp;we start with a rule() function which identifies a specific behavior we want to identify. For example, let’s suppose we want to have a detection that sends an alert whenever a brute force Okta login is suspected. The following detection can help identify this behavior with Panther:</p>



<pre><code>from panther_base_helpers import deep_get, okta_alert_context


def rule(event):
    return (deep_get(event, 'outcome', 'result') == 'FAILURE' and
            event['eventType'] == 'user.session.start')


def title(event):
    return 'Suspected brute force Okta logins to account {} due to [{}]'.format(
        deep_get(event, 'actor', 'alternateId'),
        deep_get(event, 'outcome', 'reason'))


def alert_context(event):
    return okta_alert_context(event)</code></pre>



<p><em>Okta Brute Force Login Rule in Panther</em></p>



<p>In the above example:</p>



<ul><li>The rule() function takes one argument of ‘event’ and returns a boolean value.</li><li>The title() function controls the generated alert message sent to analysts. Values from the events can then be interpolated to add helpful contexts.</li></ul>



<p>Rules in Panther can be enabled and tested directly in the Panther UI, or modified and uploaded programmatically with the&nbsp;<a href="https://blog.runpanther.io/panthers-cli-tool/">Panther Analysis tool</a>, which enables you to test, package, and deploy detections via the command-line interface (CLI). And to assist with incident triage, Panther rules contain metadata such as severity, log types, unit tests, runbooks, and more.</p>



<h2 id="detections-as-code-a-new-hope-paradigm"><span id="DetectionsasCode_A_New_(Hope)_Paradigm"></span>Detections-as-Code: A New (Hope) Paradigm<span></span></h2>



<p>Detections-as-Code is a modern, flexible, and structured approach to writing detections that apply software engineering best practices to security. By adopting this new paradigm, teams can build scalable processes for writing and hardening detections to identify sophisticated threats across rapidly expanding environments.</p>



<h2 id="benefits-of-adopting-a-code-driven-workflow"><span id="Benefits_of_Adopting_a_CodeDriven_Workflow"></span>Benefits of Adopting a Code-Driven Workflow<span></span></h2>



<p>Threat detection programs that are fine-tuned for specific environments and systems are the most impactful. By treating detections as&nbsp;<strong>well-written code</strong>&nbsp;that can be tested, checked into source control, and code-reviewed by peers, teams can produce<strong>&nbsp;higher-quality alerts</strong>&nbsp;that reduce fatigue and quickly flag suspicious activity.</p>



<h3 id="1-build-custom-flexible-detections-with-a-programming-language">1- Build Custom, Flexible Detections with a Programming Language</h3>



<div><p>Writing detections in a universally-recognized, flexible, and expressive language such as&nbsp;<strong>Python</strong>&nbsp;offers several advantages instead of using domain-specific languages (DSL) that are too limited. With languages, such as Python, you can write more sophisticated and&nbsp;<strong>tailored detections</strong>&nbsp;to fit the needs specific to your enterprise. These rules also tend to be more readable and easy to understand as the complexity increases.</p><p>Another benefit of this approach is utilizing a rich set of built-in or third-party&nbsp;<strong>libraries</strong>&nbsp;developed by the security community for interacting with APIs or processing data, which increases the effectiveness of the detection.</p></div>



<h3 id="2-test-driven-development-tdd-">2- Test-Driven Development (TDD)</h3>



<p>A proper QA for detection code can enable teams to discover detection blind-spots early on, cover testing for false alerts, and promote&nbsp;<strong>detection efficacy</strong>. A TDD approach allows security teams to think like an attacker, document that knowledge, and curate an internal repository of insight into the attacker’s lifecycle.</p>



<p>The advantage of TDD is more than just validation of code correctness. A TDD approach to writing detections improves the quality of detection code and enables more&nbsp;<strong>modular, extensible, and flexible detections</strong>. Engineers can easily make changes to their detection without fear of breaking alerts or hamstringing everyday operations.</p>



<h3 id="3-collaboration-with-version-control-systems">3- Collaboration with Version Control Systems</h3>



<div><p>When writing new detections or modifying them, version control allows teams to quickly and easily revert to previous states. It also confirms that teams are using the most up-to-date detection rather than referencing outdated or wrong code. Version control can also help give needed context for specific detections that triggered an alert or help pinpoint when detections are changed.</p><p>As new and additional data enters the system over time, detections must also change. A change control process is essential to help teams address and&nbsp;<strong>adjust the detections as needed</strong>, while simultaneously ensuring that all changes are well-documented and well-reviewed.</p></div>



<h3 id="4-automated-workflows-for-reliable-detections">4- Automated Workflows for Reliable Detections</h3>



<p>A Continuous Integration/Continuous Deployment (CI/CD) pipeline can be beneficial for security teams that have long wanted to&nbsp;<a href="https://devops.com/shift-left-without-fear-the-role-of-security-in-enabling-devops/" target="_blank" rel="noreferrer noopener">move security further left</a>. Using a CI/CD pipeline helps achieve the following two goals:</p>



<ul><li>Eliminate&nbsp;<strong>silos</strong>&nbsp;between teams as they work together on a common platform, code-review each other’s work, and stay organized.</li><li>Provide automated testing and delivery pipelines for your security detections. Teams can&nbsp;<strong>stay agile</strong>&nbsp;by focusing on building fine-tuned detections. Instead of manually testing, deploying, and ensuring that the detections aren’t overly tuned, which could trigger false alerts.</li></ul>



<h3 id="5-reusable-code">5- Reusable Code</h3>



<div><p>Last but not least, Detections-as-Code can promote code reusability across a large set of detections. As teams write large numbers of detections over time, they start to see specific patterns emerge. Engineers can&nbsp;<strong>reuse the existing code</strong>&nbsp;to perform the same or very similar function across different detections without starting from scratch.</p><p>Code reusability can be a vital part of detection-writing that allows teams to share functions between detections or modify and adapt detections for specific use-cases. For example, suppose you needed to repeat a set of Allow/Deny lists (let’s say for access management) or a particular processing logic in multiple places. In that case, you can use Helpers in languages such as Python to&nbsp;<strong>share functions</strong>&nbsp;between detections.</p></div>



<h2 id="panther-s-approach-to-detections-as-code"><span id="Panther%E2%80%99s_Approach_to_DetectionsasCode"></span>Panther’s Approach to Detections-as-Code<span></span></h2>



<p>Panther offers reliable and resilient detections that can make it easy to:</p>



<ul><li>Write expressive and&nbsp;<strong>flexible detections in Python</strong>&nbsp;for needs specific to your enterprise.</li><li>Structure and normalize logs into a strict schema that enables detections with Python and&nbsp;<strong>queries with SQL</strong>.</li><li>Perform real-time threat detection and power investigations against&nbsp;<strong>massive volumes</strong>&nbsp;of security data.</li><li>Benefit from&nbsp;<strong>200+ pre-built detections</strong>&nbsp;mapped to specific threats, suspicious activity, and security frameworks like&nbsp;<a href="https://attack.mitre.org/" target="_blank" rel="noreferrer noopener">MITRE ATT&amp;CK</a>.</li></ul>



<figure><img src="https://lh3.googleusercontent.com/RK2uPbvJfk_bMHMCl2QHZDpEfmjVFcfEZ3Rq4bm3Gwvwy18GqBMgtGWHdscyD2sF-A_Xf-uXhbjCboG6bf6apo5lRNHz4OI3u1kljtrRWhpzxQdUk17Xz9eVH6DabIoA7p1VWBSE" alt="The flow of Detections-as-Code in Panther"><figcaption><em>The Flow of Detections-as-Code in Panther</em></figcaption></figure>



<h2 id="get-started"><span id="Get_Started"></span>Get Started<span></span></h2>



<div><p>Are you taking full advantage of all your security data to detect threats and suspicious activity? Follow our&nbsp;<a href="https://docs.runpanther.io/quick-start"><strong>Quick Start</strong></a>&nbsp;Community guide to getting started with Panther or&nbsp;<a href="https://runpanther.io/request-a-demo/"><strong>contact us</strong></a>&nbsp;for a demo.</p><p><em>To learn how you can write custom Python detections in Panther,&nbsp;</em><a href="https://runpanther.io/webinars/writing-custom-python-detections-with-panther/"><em><strong>watch our on-demand webinar</strong></em></a><em>.</em></p><p>Note: This is a two-part blog series on security automation using Detections-as-Code. In Part 2, we’ll show how you can deploy Detections-as-Code with Panther.</p></div>
                                            </div>

                </article>

                
                
                            		        		               
		        
            </div></div>]]>
            </description>
            <link>https://blog.runpanther.io/detections-as-code/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25990739</guid>
            <pubDate>Mon, 01 Feb 2021 17:23:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Legacy database is outgrowing itself]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25990725">thread link</a>) | @sysoleg
<br/>
February 1, 2021 | https://ikonicscale.com/your-legacy-database-is-outgrowing-itself | <a href="https://web.archive.org/web/*/https://ikonicscale.com/your-legacy-database-is-outgrowing-itself">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p><em>A note: this was originally posted on my good friend’s blog, at <a rel="noreferrer noopener" href="https://unstructed.tech/" target="_blank">unstructed.tech</a>. </em></p>



<p>Do you feel your database is growing too big or too old? Hard to maintain? Well, I hope I might be able to help you a bit with that. The text you’re about to read is a real life experience of scaling a monolith database to be able to support a top 250-website (according to <a rel="noreferrer noopener" href="https://www.alexa.com/" target="_blank">alexa.com</a>). At the moment of writing this article, <a rel="noreferrer noopener" href="https://www.alexa.com/" target="_blank">alexa.com</a> ranked <a rel="noreferrer noopener" href="https://www.chess.com/" target="_blank">chess.com</a> at 215th place in the world. We’ve got over 4M unique daily users and over 7B queries hitting all our MySQL databases combined. Went from under 1M unique users a day a year ago to 1.3M in March, to over 4M at the moment, with over 8M games played each day. I know it’s no where near the biggest players on the market, but our experience could help you “fix” your monolith database, and scale it to new heights.</p>



<p>Disclosure: <em>This is my first ever article, and it’s too long as it is – but I had to cut probably as much text as you see here in order to make it actually readable. So, some things might be confusing or not well explained, and I’m sorry for that. Hit me up on <a href="https://www.linkedin.com/in/ikonic/" target="_blank" rel="noreferrer noopener">LinkedIn</a>, and we can get into a deeper discussion.</em></p>



<p>Update: after reading a lot of comments, I’d like to add/clarify a few things. We do use caching, extensively. If we didn’t we wouldn’t survive a day. We do use Redis, often pushing it to its extremes. We’ve tested MongoDB and Vitess, but they didn’t do it for us. </p>



<h2>The state in which we were just couple of years ago</h2>



<p>Somewhere mid-2019 we’ve started noticing that our main DB cluster is slowly growing a bit too big. We had three smaller and less used databases on the side, but everything was always added to the main one. Surprisingly, it was in a fairly decent state for a database that started its life over 12 years ago. Not many unused/redundant indexes, the ones that were there were mostly good. We constantly monitored and improved heavy/slow queries. A nice chunk of data was denormalized, as well. No foreign keys, many things were done in the code itself (filtering, sorting, etc, to make sure the DB only ever uses the most efficient indexes) running on the latest version of MySQL, etc, etc. It wasn’t neglected and it evolved over time into something that did a good job for us. </p>



<p>Disclaimer: I’m not recommending anyone to do these sorts of micro-optimizations. They are working for chess.com, on its scale. We benchmark almost anything we’ve never done before, and see how it turns out, before actually implementing it. We know these work <strong>for us</strong>.</p>



<div>
<p>The biggest problem we were facing at that point in time was that altering almost any table required taking half the hosts out of rotation, run the alter there, put it back in rotation, alter the other half, put them back in. We had to do it off-peak, as taking half the hosts out during the peak time would probably result in the other half crashing. As the website was growing, old features got new improvements, so we had to run alters a lot (if you’re in the business, you know how it goes). Altering would’ve been far less stressful if we could could pull just a small set of tables out of rotation, instead of the entire DB. So, we created a 5 year plan for our main cluster (and boy, were we wrong about our timeline), in which we were to split the database into many smaller ones, and that would make things easier to maintain (we were right about this, at least). The plan assumed ~25% yearly growth, which was what we were seeing in previous years.</p>



<div>
<figure><img src="https://unstructed.tech/wp-content/uploads/2021/01/Untitled-Document-1.png" alt=""><figcaption><em>Where we were ~2 years ago</em></figcaption></figure>
</div>
</div>



<h2>The REAL problem appears and our plan implodes</h2>



<p>You’re all familiar with COVID-19, and how all of that went. Guess what – we weren’t really ready (or we didn’t expect it to have the impact it had on or traffic). Interest in chess exploded when (most of) Europe went into a lockdown. Fun fact – we could tell which country went into a lockdown just by looking at our registrations by country – it was so clear. And numbers skyrocketed across the board. Funnily enough, all our databases were doing fine (not great, but they handled the traffic). But at the same time we noticed that our “reports” host was constantly struggling to keep up with the production hosts (i.e., it was often 30-60 seconds behind on replication), which prompted us to analyse our replication stream and its remaining capacity. And it was close to being full, at peak traffic reaching over 95% of the capacity. At that point we knew that USA (where most of our players are from) would also go into a lock down, soon, and that would mean that our replicas wouldn’t be able to keep up with all the writes going to the master (or even if we just keep growing slowly). This would mean the end of <a href="http://www.chess.com/" target="_blank" rel="noreferrer noopener">chess.com</a>, as the code isn’t ready to handle big replication delays when reading data from replicas, and sending all the selects to master would take it down. That made our goal clear: decrease number of writes going to the main cluster, and do it as quickly as possible! This was actually part of our aforementioned plan, but that plan stretched over 5 years. Now we had just one or two months to do that. </p>



<h2>The solution</h2>



<p>How to decrease number of writes to a single DB? Sounds simple – identify tables that are written the most and rip them away from the DB. That way the number of writes handled remains the same, but they are just split into two separate streams. These can be either tables that get a lot of inserts, or not as many inserts, but with records that are frequently updated. Store them elsewhere. How to do it with no downtime? As you’d imagine – not really that simple. </p>



<p>We first identified all the tables that had most updates (inserts, deletes or updates). Most of them were nicely grouped together based on the feature for which they were used (most of game related tables would be written at a similar pace, etc), and we managed to gather a list of 10-15 tables, for 3 different website features. As soon as we started investigating them, another problem was revealed – since we can’t “join” between databases on different hosts, we would need to move as many tables as the feature used to make the project simpler (we were already aware of this, since when “the plan” first came into place, we did something similar for 3 smaller, less used tables as a PoC, and it turned out fine). </p>



<p>The 3 features we identified as high-traffic were logs (not really a feature, and not really logs, they were just poorly named), games (like you’d expect on a chess gaming platform) and puzzles. For logs we’ve found just 3 very isolated tables, which meant not a lot query/code changes were required. Similar for games, as well. But puzzles had over 15 tables to move, and the queries on those tables had lots of joins towards tables that were to remain in the main database cluster. We’ve rallied our troops, pulled over half of our backend developers, split them into teams, and started pushing on all of these in parallel. </p>



<p>It took just one week to move logs into its dedicated database, running on two hosts, which gave us some breathing space, as those had the most writes, by far. One more month to move games (which was oh so scary, as any mistake there would be a disaster, considering that’s the whole point of the website), and puzzles took over 2 months. After these, we were well under 80% of the replication capacity in the peak, which meant we had time to regroup, and plan upcoming projects a bit better.</p>



<h2>The execution</h2>



<p>So, how did we do it? </p>



<p>As you might assume, there are two sides to a project like this – code and database, and both require a lot of work. On the code side, there are a few prerequisites for a project like this one. First of all, we need some sort of <a href="https://en.wikipedia.org/wiki/Feature_toggle" target="_blank" rel="noreferrer noopener">feature flag</a> (aka feature toggle) system, either internal or 3rd party. Ours is custom built, pretty extensive, and maybe a topic for another post. The bare minimum the feature flag system needs to provide is to allow or deny access to a percent of checks from 0 to 100 percent. Another really useful thing to have is a good test coverage. Our entire codebase was rewritten from scratch a few years ago, so we were lucky enough to have that, as it saved us a couple of times.</p>



<div>
<p>Between code changes and database changes, some things can be done in parallel and some require going by numbers. The easiest thing to start with is to set up the new database. All our new databases pulled from the main one (we call them partitions, and this process partitioning) end up on a 2-host setup (master and failover-master (replica)), but it can really be anything we want. On the partition cluster, we create a new database with identical schema to the one we’re trying to split (just name it according our needs, in this case the first one was named<code> logs</code>). Then a backup of the main database is imported, after which we hook up the master of the partition cluster to be a replica of the main master (this is why we need the identical schema and backup import). This way the new cluster becomes just like any main cluster replica, only with a differently named database. Then it just sits there, looking pretty, replicating traffic, and being up-to-date with the rest of the cluster while we work on the code side of this project.</p>



<div>
<figure><img src="http://unstructed.tech/wp-content/uploads/2021/01/Before-DL-919x1024.png" alt=""><figcaption><em>This is what the cluster looks like after adding new hosts</em></figcaption></figure>
</div>
</div>



<p>Before we started working on this project, we essentially had 2 connections open to the database from the code: read only connection hitting replicas and read/write connection pointing to the master. Both actually hitting HAProxy, to get where they need to go. First thing we did is to create a parallel set of connections, where read/write connection goes to the <code>Partition Master</code> and read-only connection to the <code>Partition Replica</code>.</p>



<p><em>Chess.com is written in PHP, so I’ll use PHP examples to illustrate the needed changes, but I’ll keep it pseudo enough so that anyone can understand what’s going on (you’d be surprised how many websites in the top 1k are written in PHP, and …</em></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ikonicscale.com/your-legacy-database-is-outgrowing-itself">https://ikonicscale.com/your-legacy-database-is-outgrowing-itself</a></em></p>]]>
            </description>
            <link>https://ikonicscale.com/your-legacy-database-is-outgrowing-itself</link>
            <guid isPermaLink="false">hacker-news-small-sites-25990725</guid>
            <pubDate>Mon, 01 Feb 2021 17:21:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Snowflake Generator]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25990723">thread link</a>) | @visviva
<br/>
February 1, 2021 | https://viviariums.com/projects/snowflake/ | <a href="https://web.archive.org/web/*/https://viviariums.com/projects/snowflake/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    
    <p>
      Run the generator
      <a href="https://viviariums.com/projects/snowflake/interactive/">here.</a>
    </p>
    <p>
      This generator cycles a snowflake from a seed to its final state,
      and also loops its crystal distribution kaleidoscopically on two axis.
    </p>
    <p>
      <img src="https://viviariums.com/projects/snowflake/growth.gif"><img src="https://viviariums.com/projects/snowflake/kaleidoscope.gif">
    </p>
    <p>
      It takes the user input and distributes hexagons on a pinion accordingly, applies mirroring
      and sixfold symmetry, generates a height map, and adds lighting and refraction.
      This is done with a fragment shader; the snowflake lies on a plane and there is no geometry created.
    </p>
    <p>
      Thanks to Evan Wallace for the post-processing effects (blur and chromatic aberration).
    </p>
    <p>
      <img src="https://viviariums.com/projects/snowflake/compilation.jpg">
    </p>
  </article></div>]]>
            </description>
            <link>https://viviariums.com/projects/snowflake/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25990723</guid>
            <pubDate>Mon, 01 Feb 2021 17:21:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Continuous delivery makes JVM JIT an anti-pattern]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 33 (<a href="https://news.ycombinator.com/item?id=25990585">thread link</a>) | @foxgrover
<br/>
February 1, 2021 | https://blog.astradot.com/the-jvm-jit-is-an-antipattern-in-a-continuous-delivery-world/ | <a href="https://web.archive.org/web/*/https://blog.astradot.com/the-jvm-jit-is-an-antipattern-in-a-continuous-delivery-world/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <p>The JVM JIT compiler has long been sold as the way Java is able to compete with the performance of compiled languages like C/C++. Every benchmark for Java will tell you to first run your code many times for 'warmup' before you measure its performance, so that its JITed and optimized by the JVM's C2 compiler .</p><p>In the real world though, the calls to your application <em>before</em> its code is 'warmed up' are very much a part of your application's experience.</p><figure><blockquote><p lang="en" dir="ltr">Every Java benchmark is like ‘ignore first 1M calls to let code be fully JITed’. Yeah but those 1M calls are still part of your application, including that first call that caused the class hierarchy to be loaded. And they are pushing the 99th percentile of your app to the moon!</p>— Prashant Deva (@pdeva) <a href="https://twitter.com/pdeva/status/1355754185858420738?ref_src=twsrc%5Etfw">January 31, 2021</a></blockquote>

</figure><h3 id="jvm-jit-and-our-signup-page">JVM JIT and our Signup page</h3><p>Astradot has a Kotlin microservice that takes care of auth activities like signup and login. If you try to signup right after the serviced was redeployed, it feels like the signup page has frozen after you click the 'signup' button. The page can take seconds to respond. It's because the JVM is loading the code of tons of Kotlin/Spring classes for the first time and running it through the interpreter with no optimizations. Sure the response time gets better the more you click the signup button, but the user who was signing up that first time might have thought our system was frozen and gone away. Since we have multiple instances of each microservice running its possible that the 2nd time you try to signup the request goes to a different JVM instance. For that JVM its the first time loading the signup code and so you again encounter the freezing behavior. From the end user's perspective, he has now tried signing up multiple times and encountered slow behavior each time. Thus that is the impression he has of our product now.</p><h3 id="continuous-delivery-kills-jit-compiler-s-core-assumption">Continuous Delivery kills JIT compiler's core assumption</h3><p>One of Astradot's metric collector service gets 500 requests per second per JVM. After a fresh deploy, even at that high throughput it takes a full 2 hours till the JVM C2 compiler is able to fully optimize that code path to get response times drop to their lowest. To put those 2 hours in context, here is a result from Sysdig's latest container usage survey:</p><figure><blockquote><p lang="en" dir="ltr">Latest Sysdig survey shows 74% of containers live &lt; 1 hour. So your Java app perpetually stays in interpreted/C1 non-optimized mode. Those amazing benchmark numbers you got from the C2 JIT, your users will never get to see them. JIT and Continuous Deployment are incompatible. <a href="https://t.co/fqLf7d3f9L">pic.twitter.com/fqLf7d3f9L</a></p>— Prashant Deva (@pdeva) <a href="https://twitter.com/pdeva/status/1356183648131719175?ref_src=twsrc%5Etfw">February 1, 2021</a></blockquote>

</figure><p>74% of containers have lifespans ≤ 1 hour. This changes the core assumption behind the JIT compiler that the JVM is a long running process. Your container will get redeployed before it gets optimized by the JVM C2 compiler. Thus your users will never even get to experience that amazing performance that all those JVM benchmarks promised.</p><p>This gets worse for portions of code that are low throughput. Think of that Signup page I talked about earlier. Even if our auth microservice was deployed for days, the <code>signup()</code> function will still not get enough calls to trigger the C2 compiler to fully optimize it. So users will always experience the unoptimized version of that code.</p><h3 id="rise-of-modern-compiled-languages">Rise of modern compiled languages</h3><p>One of the selling points of the JVM JIT compiler was that it has runtime information so it can do better optimization. That might have been true 20 years ago. But Ahead of Time (AOT) compiled languages have evolved since then. Go, which is Garbage Collected like Java, but AOT compiled, is able to achieve similar or better performance. Rust is able to consistently beat Java in benchmarks.</p><p>This is due to the fundamental design of Java. It encourages uses of virtual methods and allocations on heap. A huge part of the JIT optimization revolves around trying to convert those virtual calls to static calls, inline them, perform escape analysis to convert those heap allocations to stack allocations. Go and Rust encourage use of static method calls and stack allocation everywhere by default thus they don't need all the complexity and overhead of a massive JIT to optimize them at runtime.</p><h3 id="aot-compiled-java">AOT Compiled Java</h3><p>There are signs that Java folks are realizing the pitfalls of JIT. GraalVM has an AOT compiler and frameworks like Quarkus and Micronaut are popping up to use them. They have had little uptake though. The dynamic nature of Java means that features like dynamic class loading, reflection, proxies, etc are unavailable or in limited from in AOT. Production Java apps also typically run with APM tracing agents that rely on runtime bytecode instrumentation. The entire JVM ecosystem is simply not designed around AOT compilation. Molding a 25 year old runtime ecosystem to adapt to AOT compilation feels like putting lipstick on a pig. It is easier to start afresh with modern compiled languages like Go and Rust.</p><h3 id="conclusion">Conclusion</h3><p>JVM vendors want you to ignore the fact that large portions of your code could indeed be running on the interpreter or the unoptimized C1 compiler. Continuous Delivery and the resulting frequent JVM restarts mean the core assumption behind the JIT compiler, that JVMs are long running processes, no longer holds.</p><p>At Astradot, we believe <a href="https://movingfulcrum.com/the-era-of-the-jvm-is-coming-to-an-end/">the era of the JVM is coming to an end</a>. We are writing our backend in AOT compiled languages to give you a great experience 100% of the time. &nbsp;We recently <a href="https://blog.astradot.com/why-we-moved-from-kotlin-spring-boot-to-go/">converted our microservices from Kotlin to Go</a> and found it to be a welcome change.</p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.astradot.com/the-jvm-jit-is-an-antipattern-in-a-continuous-delivery-world/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25990585</guid>
            <pubDate>Mon, 01 Feb 2021 17:11:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Russian Pipeline Is Germany's Greatest Foreign Policy Embarrassment]]>
            </title>
            <description>
<![CDATA[
Score 78 | Comments 94 (<a href="https://news.ycombinator.com/item?id=25990469">thread link</a>) | @Tomte
<br/>
February 1, 2021 | https://www.spiegel.de/international/germany/a-price-too-high-russian-pipeline-is-germany-s-greatest-foreign-policy-embarrassment-a-0fcefa58-ca51-41ca-b480-98015203e9fa | <a href="https://web.archive.org/web/*/https://www.spiegel.de/international/germany/a-price-too-high-russian-pipeline-is-germany-s-greatest-foreign-policy-embarrassment-a-0fcefa58-ca51-41ca-b480-98015203e9fa">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article aria-label="A Price Too High: Russian Pipeline Is Germany's Greatest Foreign Policy Embarrassment" data-area="article">
<header>
<div>

<div>
<h2>
<span>
A Price Too High
</span>
<span><span>Russian Pipeline Is Germany's Greatest Foreign Policy Embarrassment</span>
</span>
</h2>


<p>
Berlin is insisting on the construction of the Nord Stream 2 gas pipeline between Russia and Germany. By doing so, the country is isolating itself in Europe and alienating the United States. The political costs will be too great if the project is completed. It should now be scrapped.
</p>
<p><time datetime="2021-02-01 17:25:39">01.02.2021, 17.25 Uhr</time>
</p>
</div>
</div>
</header>
<div data-article-el="body">
<section data-app-hidden="">


</section>
<section>
<div>
<figure data-component="Image" data-zoom-id="0b658ab8-9ac0-4b7d-9af3-73e864af0ce2" data-settings="{&quot;id&quot;:&quot;9fdd3db3-8707-46ea-8d4a-4197034af156&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;0b658ab8-9ac0-4b7d-9af3-73e864af0ce2&quot;}">
<p><span>
<span data-image-el="aspect">
<span>
<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/9fdd3db3-8707-46ea-8d4a-4197034af156_w948_r1.77_fpx56_fpy56.jpg" srcset="https://cdn.prod.www.spiegel.de/images/9fdd3db3-8707-46ea-8d4a-4197034af156_w520_r1.77_fpx56_fpy56.jpg 520w, https://cdn.prod.www.spiegel.de/images/9fdd3db3-8707-46ea-8d4a-4197034af156_w948_r1.77_fpx56_fpy56.jpg 948w" width="948" height="536" sizes="948px">
</span>
</span>
</span>

</p>
<figcaption>
<span>
Foto: Alexander Demianchuk&nbsp;/ action press
</span>
</figcaption>
</figure>
</div><div>
<p>How much can a natural gas pipeline from Russia be worth to the German government? Is it worth sacrificing Germany’s foreign policy prestige? Is it worth isolating the country within the European Union and straining relations with Joe Biden, the new president of the United States? How can it be reconciled with Germany’s climate targets? And why should the German government back a pipeline that benefits the Russian regime, whose policies it otherwise opposes?</p>


<div>
<p>For years, the German government has stuck to this economically dubious and politically misguided project, the brainchild of Russian President Vladimir Putin and his pal, former Chancellor Gerhard Schröder. The greater the resistance within Europe to the project, the more stubbornly the German government has clung to the endeavor. It is increasingly difficult to find any other explanation for this than pride.</p><p>And this, despite the larger, more fundamental issue question facing Berlin: Can the German government achieve its self-proclaimed target of taking on a more significant role in global politics? Its behavior on Nord Stream 2 thus far suggests the contrary. The pipeline, indeed, has become Germany’s most embarrassing foreign policy problem.</p>
</div>

<p>From the very beginning, Berlin’s claim that the Nord Stream 2 was purely economic and not at all political in nature has been hypocritical. Pipelines are always political. And this is especially true of this pipeline, because Nord Stream 2 would transport natural gas directly from Russia to Germany through the Baltic Sea. It would allow the state-owned company Gazprom to bypass pipelines in Belarus and Ukraine, making the countries even more dependent on Russia because they will lose transit fees they otherwise would have received. The pipeline would also provide an additional source of foreign currency for the Russian government. This runs counter to the spirit of Europe's sanctions against a regime that for years has shown itself to be an adversary of the European Union and has had opposition figure Alexei Navalny poisoned and imprisoned.</p>

<p><strong>The most effective argument used by pipeline proponents</strong> in recent years has been Donald Trump and U.S. sanctions against the project. "We're not going to let them dictate where we buy our gas!" they would say. But Donald Trump has now been voted out of office, and the Americans are by no means the only ones who oppose the pipeline. Indeed, perhaps the strongest argument against Nord Stream 2 doesn’t even have anything to do with the U.S. This pipeline is an anti-European project. And the German government is growing increasingly isolated in the EU on the issue. Almost every Eastern European country is opposed to the project, especially Poland and the Baltic states. The project provides affirmation for critics who view Germany as a two-faced, hegemonic country that speaks of European values but pushes through its own interests in a pinch. Last month, the European Parliament once again voted against the pipeline. There has also been criticism from the European Commission, which wants to reduce dependence on individual supplier countries. Even Paris is voicing skepticism.</p>


<section data-area="contentbox">

</section>
<div>
<p>The pipeline doesn’t even provide any clear economic benefits. It doubles the supply capacity from Russia, but natural gas consumption is stagnating and would have to fall significantly by the middle of the century for Germany to meet its climate targets. The existing pipelines are by far sufficient. Russia is now talking about pumping climate-friendly hydrogen through the pipeline in the future. But those prospects are uncertain and it changes nothing about the political dilemma.</p><p><strong>Of course, the private companies involved</strong> could now try to finish building the last few kilometers of the pipeline, despite the U.S. sanctions – at their own risk. They have invested billions, after all. But the lengths to which some politicians in Germany - particularly within the center-left Social Democratic Party once run by Schröder - are willing to go to support the project has been appalling. Manuela Schwesig, the SPD governor of Mecklenburg-Western Pomerania, where Nord Stream 2’s terminus is located, has even set up a front foundation for environmental protection to complete the environmentally damaging pipeline despite U.S. sanctions. Such shadiness is harmful to Germany's international standing.</p>
</div>
<section>

</section>
<div>
<p>The German government has backed itself into a corner with Nord Stream 2 that can only be explained by economic selfishness or political naivety, but it is ultimately a self-inflicted wound. The time, though, has now come for a clear choice to be made – one that doesn’t chain the country to the pipeline. Nord Stream 2 must be stopped. It would be better to write it off now than to bear the political and economic costs of its completion.</p><p>Angela Merkel should withdraw support for the project, even if that could mean that companies end up having to be compensated. Doing so will be painful politically, but the German government should view the Nord Stream 2 debacle as quittance for the mistakes it has made – and as a lesson for the future.</p>
<p><span><svg aria-labelledby="title-d879d0bc-ca92-47a1-bef9-015a57c8d770" width="10" height="20" viewBox="0 0 10 20" fill="none" xmlns="http://www.w3.org/2000/svg" role="img"><title id="title-d879d0bc-ca92-47a1-bef9-015a57c8d770">Icon: Der Spiegel</title><g id="l-s-flag-d879d0bc-ca92-47a1-bef9-015a57c8d770"><path id="vector-d879d0bc-ca92-47a1-bef9-015a57c8d770" d="M9.85 16.293v-8H3.212V4.667h3.533v2.24h3.212v-3.2C9.85 2.747 8.993 2 8.03 2H1.713C.749 2 0 2.747 0 3.707v7.253h6.638v4.373H3.105v-2.986H0v3.84c0 .96.75 1.706 1.713 1.706H8.03c.963.107 1.82-.64 1.82-1.6z" fill="#000"></path></g></svg>
</span>
</p></div>
</div>
</section>

</div>

</article></div>]]>
            </description>
            <link>https://www.spiegel.de/international/germany/a-price-too-high-russian-pipeline-is-germany-s-greatest-foreign-policy-embarrassment-a-0fcefa58-ca51-41ca-b480-98015203e9fa</link>
            <guid isPermaLink="false">hacker-news-small-sites-25990469</guid>
            <pubDate>Mon, 01 Feb 2021 17:02:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Conway's Distributed Game of Life on Ethereum]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25990196">thread link</a>) | @basicallydan
<br/>
February 1, 2021 | https://conwaysgame.github.io/solidity-ethereum/ | <a href="https://web.archive.org/web/*/https://conwaysgame.github.io/solidity-ethereum/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>➡ Connecting to the network.</p><div>
      <h2>How To Use</h2>
      <p>This web page shows the output of an implementation of Conway's Game of Life written for the Ethereum network as a Smart Contract. In order to evolve the world to its next state (i.e., go to the next turn) one must simply send at least 0.00001 ETH or more to the smart contract's address on the network. Here are some more details:</p>
      <ol>
        <li>Have an Ethereum wallet, ideally as a browser extension like <a href="https://metamask.io/" target="_blank">MetaMask</a> (<a href="https://brave.com/" target="_blank">Brave</a> web brower includes a built-in MetaMask).</li>
        <li>Create an ETH account with your network set to <em>Rinkeby Test Network</em></li>
        <li>Visit <a href="https://faucet.rinkeby.io/" target="_blank">https://faucet.rinkeby.io/</a> and follow instructions to get funds. For now, it needs link of social media share of ethereum account ID.</li>
        <li>Send a transaction of at least <code>0.00001 ETH</code>, or <code>10000000000000 Wei</code> to the following address using the <em>Rinkeby Test Network</em>. You can click the address to start a transaction - I recommend a gas limit of at least 400,000.<br><a><span>Loading...</span></a></li>
      </ol>
    </div><div>
      <h2>How does it work?</h2>
      <p>I wrote up a blog post about this project on <a href="https://danhough.com/blog/conways-game-ethereum/">my website</a>, which explains some of the challenges.</p>
      <p>However, you can inspect the code yourself, it's all on GitHub. Just click the link below:</p>
      <p><a href="https://github.com/conwaysgame/solidity-ethereum"><img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/conwaysgame/solidity-ethereum?style=social"></a>
    </p></div><div>
      <h2>Explanation</h2>
      <p><a href="https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life" target="_blank"><em>Conway's Game of Life</em></a> is a cellular automata, and can also be described as a turn-based "zero-player game."</p>
      <p>It is made up of a two-dimensional grid of cells. You can think of each cell as having the potential to be populated - it can be alive or dead, and during each turn in the game its state is reassessed based on the states of its 8 neighbours. These are the "rules" by which a cell's state is determined each turn.</p>
      <ol>
        <li>Any live cell with fewer than two live neighbours dies, as if by underpopulation.</li>
        <li>Any live cell with two or three live neighbours lives on to the next generation.</li>
        <li>Any live cell with more than three live neighbours dies, as if by overpopulation.</li>
        <li>Any dead cell with exactly three live neighbours becomes a live cell, as if by reproduction.</li>
      </ol>
      <p>Most implementations of the Game of Life simply have</p>
      <h3>Who did this?</h3>
      <p>My name is Dan, I'm a software engineer from the UK who lives in Vancouver, BC in Canada. I have <a href="https://danhough.com/">a website</a> where I talk about software, books, and the surprisingly good music that I make, plus <a href="https://twitter.com/basicallydan">a Twitter</a> and <a href="https://github.com/basicallydan">a GitHub page</a>.</p>
      <h3>Why did you do this?</h3>
      <p>Since 2014 I have been steadily writing <a href="https://github.com/conwaysgame" target="_blank">implementations of the Game of Life</a> in various languages. It's a fun exercise in TDD and a good way to be exposed to new technologies. The ever-increasing interest in cryptocurrencies and slow rise in availability of distributed apps (Dapps) and smart contracts prompted me to experiment with a version of the game which could run as a Dapp. Turns out, it can.</p>
      <h3>How did you do this?</h3>
      <p>I started by completing <a href="https://techbrij.com/hello-world-smart-contract-solidity-ethereum-dapp-part-1" target="_blank">a Hello World tutorial by Brij Mohan</a>, and then started from scratch with a new project. You can read more in <a href="https://danhough.com/blog/conways-gol-ethereum" target="_blank" rel="noopener noreferrer">a blog post I wrote</a> (PENDING).</p>
      <p>If you'd like to see the code, raise an issue, or open a pull request, you can do so on the <a href="https://github.com/conwaysgame/solidity-ethereum" target="_blank">GitHub repository</a>.</p>
    </div></div>]]>
            </description>
            <link>https://conwaysgame.github.io/solidity-ethereum/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25990196</guid>
            <pubDate>Mon, 01 Feb 2021 16:36:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Please Stop Saying 'An AI']]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25990016">thread link</a>) | @YeGoblynQueenne
<br/>
February 1, 2021 | https://www.skynettoday.com/editorials/ai-definition/ | <a href="https://web.archive.org/web/*/https://www.skynettoday.com/editorials/ai-definition/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>        
      
      
      <h4>Popular usage of the term ‘Artificial Intelligence’ adds to misunderstanding of AI as it exists today.</h4>
      
      </div><div>
      <h2 id="the-options">The Options</h2>
<p>Definitions of the term ‘Artificial Intelligence’ tend to fit one of the following categories:</p>

<ol>
  <li>‘field of research’ definitions, e.g.: “a branch of computer science dealing with the simulation of intelligent behavior in computers” (<a href="https://www.merriam-webster.com/dictionary/artificial%20intelligence">Merriam-Webster</a>) , “the theory and development of computer systems able to perform tasks that normally require human intelligence” (Oxford)</li>
  <li>‘machine intelligence’ definitions, e.g.: “the capability of a machine to imitate intelligent human behavior “(<a href="https://www.merriam-webster.com/dictionary/artificial%20intelligence">Merriam-Webster</a>) , “intelligence demonstrated by machines, unlike the natural intelligence displayed by humans and animals.” (<a href="https://en.wikipedia.org/wiki/Artificial_intelligence">Wikipedia</a>) , “the ability of a digital computer or computer-controlled robot to perform tasks commonly associated with intelligent beings.” (<a href="https://www.britannica.com/technology/artificial-intelligence">Encyclopedia Brittanica</a>)</li>
  <li>‘intelligent entity’ definitions, e.g.: “a computer, robot, or other programmed mechanical device having [the] humanlike capacity [to perform operations and tasks analogous to learning and decision making in humans, as speech recognition or question answering]”. (<a href="https://www.dictionary.com/browse/artificial-intelligence">Dictionary.com</a>)</li>
</ol>

<p>While all of these options are similar in that they deal with ‘intelligent behavior’ in computers, they are also quite different. The first refers to a research discipline, while the second and third describe what that research discipline seeks to create. The ways in which the term ‘AI’ can be used depend on which of these definitions you consider valid. For instance, news articles often have titles to the effect of “Google’s new AI learned X” or “A new AI can do Y,” such as:</p>

<ul>
  <li><a href="https://www.theatlantic.com/technology/archive/2017/06/artificial-intelligence-develops-its-own-non-human-language/530436/">“An Artificial Intelligence Developed Its Own Non-Human Language”</a></li>
  <li><a href="https://www.fastcompany.com/90455358/ai-can-now-design-cities-should-we-let-it">“AI can now design cities, but should we let it?”</a></li>
  <li><a href="https://www.forbes.com/sites/danadovey/2020/02/11/first-time-ever-artificial-intelligence-develops-drug-candidate/">“For The First Time Ever, A Drug Developed By AI Will Be Tested In Human Trials”</a></li>
  <li><a href="https://www.sciencealert.com/google-s-ai-built-it-s-own-ai-that-outperforms-any-made-by-humans">“Google AI creates its own ‘child’ AI that’s more advanced than systems built by humans”</a></li>
</ul>

<p>But, such usage (“An AI Developed”, “AI can now”, etc.) is only valid with that third ‘intelligent entity’ definition. If the first ‘field of research’ definition is chosen instead, these titles would have to be rewritten as “Google’s new AI algorithm learned X” or “A new AI system can do Y.” In this piece, I’ll make the case that this definition and form of usage is superior to the alternatives, and should be adopted in most cases.</p>

<h2 id="why-should-we-care">Why Should We Care</h2>
<p>It may seem pedantic to say one of these definitions is better than any of the others, and tempting to just say all of them are fine. However, I argue that the ‘field of research’ definition of AI is better than the alternatives, primarily because of the <a href="https://www.aimyths.org/ai-has-agency">common misunderstanding</a> that AI programs today are independent agents with some amount of ‘free will’. In fact, what AI researchers and engineers build today are just computer programs, which are capable of emulating some aspects of human intelligence but are otherwise (for the most part) no more independent than the apps on our smartphones. Nevertheless, AI researchers recently ranked the idea that the AI algorithms they create have some human-like independence as the most common and problematic myth about AI; it was “number one by a long shot” <a href="https://www.skynettoday.com/podcast/top-ai-myths">according to a survey</a> asking which myths about AI are most common.</p>

<p>I believe part of why this myth is so predominant has to do with thinking of AI in terms of the ‘intelligent entity’ definition type and using the term accordingly by saying statements such as “A new AI can do Y”. Expanding that statement results in “A new Artificial Intelligence can do Y,” and the notion that the sentence refers to ‘An Intelligence’ inevitably implies agency similar to those of animals and humans. AI researcher Julian Togelius addresses this notion well in his blog post <a href="http://togelius.blogspot.com/2017/07/some-advice-for-journalists-writing.html">“Some advice for journalists writing about artificial intelligence”</a>:</p>

<blockquote>
  <p><strong>Keep in mind</strong>: There is no such thing as “an artificial intelligence”. AI is a collection of methods and ideas for building software that can do some of the things that humans can do with their brains. Researchers and developers develop new AI methods (and use existing AI methods) to build software (and sometimes also hardware) that can do something impressive, such as playing a game or drawing pictures of cats.</p>
</blockquote>

<p>AI researcher Zachary Lipton made this point more bluntly:</p>

<figure>
<blockquote><p lang="en" dir="ltr">Dear world (CC <a href="https://twitter.com/businessinsider?ref_src=twsrc%5Etfw">@businessinsider</a>,
<a href="https://twitter.com/Hamilbug?ref_src=twsrc%5Etfw">@Hamilbug</a>):
stop saying "an AI". AI's an aspirational term, not a
thing you build. What Amazon actually built is a "machine learning
system", or even more plainly "predictive model". Using
"an AI" grabs clicks but misleads <a href="https://t.co/0kdTLBsrHJ">https://t.co/0kdTLBsrHJ</a></p>—
Zachary Lipton (@zacharylipton) <a href="https://twitter.com/zacharylipton/status/1050221929477664768?ref_src=twsrc%5Etfw">October
11, 2018</a></blockquote> 
</figure>

<p>As someone who has tried to use my knowledge as an AI researcher to address popular misconceptions about AI, I have observed and continue to observe the usage of “An AI” often, and think it has the negative side effect of feeding misunderstanding of what AI is today. While it may be tempting to once again say this is being pedantic and that it’s fine to have a more ‘pop culture’ view of AI, with AI becoming increasingly embedded in our society it is more important than ever that all of us understand it. Such understanding is crucial so that we can collectively correctly focus on the most pressing issues with respect to AI (such as bias, automation, its use for surveillance, its safety) and not the issues that the agency myth implies (its potential to go rogue a la Skynet in the near term).</p>

<p>Therefore, given the existence of the ‘agency’ myth with respect to AI and the importance of correctly understanding what AI is actually like today, I would argue the first ‘field of research’ definition of the term ‘AI’ is better than the alternatives. As I’ll show next, this is (unsurprisingly) typically how AI researchers themselves use the term.</p>

<h2 id="how-researchers-define-ai">How Researchers Define AI</h2>

<p><a href="https://en.wikipedia.org/wiki/John_McCarthy_(computer_scientist)">John McCarthy</a>, one of the founders of the field of AI, defined AI as follows:</p>

<blockquote>
  <p>“It is the science and engineering of making intelligent machines, especially intelligent computer programs.”</p>
</blockquote>

<p>Professor <a href="https://nlp.stanford.edu/manning/">Christopher Manning</a><a href="https://hai.stanford.edu/sites/default/files/2020-09/AI-Definitions-HAI.pdf"> </a> <a href="https://hai.stanford.edu/sites/default/files/2020-09/AI-Definitions-HAI.pdf">recently cited</a> this as the definition of ‘Artificial Intelligence’ in his summary of definitions of terms related to AI. Similarly, in “Artificial Intelligence: A Modern Approach”, Stuart Russell and Peter Norvig defined AI as:</p>

<blockquote>
  <p>“the designing and building of intelligent agents that receive percepts from the environment and take actions that affect that environment.”</p>
</blockquote>

<p>To cite just one more example, in “The Quest for Artificial Intelligence: A History of Ideas and Achievements” <a href="https://en.wikipedia.org/wiki/Nils_John_Nilsson">Nils J. Nilsson</a> defines AI as follows:</p>

<blockquote>
  <p>“[the] activity devoted to making machines intelligent”</p>
</blockquote>

<p>There are of course many other definitions, but they tend to share the quality of considering AI a research or engineering discipline rather than a term that can be used to refer to singular algorithms or systems.</p>

<p>I conducted an informal survey to check whether AI researchers generally agree with this form of definition, with the following results:</p>

<figure>
<blockquote><div lang="en" dir="ltr"><p>AI Researchers: how do you define the term 'Artificial Intelligence'? </p><p>A: the science and engineering of making intelligent machines, especially intelligent computer programs</p><p>B: intelligence demonstrated by machines, unlike the natural intelligence of animals</p><p>C: Other</p></div>— Skynet Today (@skynet_today) <a href="https://twitter.com/skynet_today/status/1326239401912004611?ref_src=twsrc%5Etfw">November 10, 2020</a></blockquote>  
</figure>

<p>While hardly a careful study of what most AI researchers feel, the result of this poll agrees with my personal observations as an AI researcher that most in the field seem to prefer the John McCarthy definition of AI to the alternatives. I point this out because I think it further lends credence to the idea that the ‘field of research’ definition that does not allow for “An AI” as a phrase is superior to the alternatives. Granted, no one has any right to impose a particular way of defining terms on others, but I still think using the term ‘AI’ the same way the people actually working on AI in the real world (as opposed to science fiction, where ‘An AI’ is appropriate) makes a lot of sense.</p>

<h2 id="tldr">TLDR</h2>
<p>AI researchers tend to define ‘Artificial Intelligence’ to mean something along the lines of “the science and engineering of making intelligent machines, especially intelligent computer programs” – the ‘field of research’ definition. This is in contrast to definitions often used in popular media, which use ‘AI’ to refer to particular programs or systems with sentences – the ‘intelligent entity’ definition. The latter usage of AI reinforces an already common myth that present day AI has some amount of human-like agency, when in fact this is not really the case. Therefore, I believe that the ‘intelligent entity’ type definition should be avoided in favor of the ‘field of research’ definition, and the term should be used accordingly.</p>


    </div></div>]]>
            </description>
            <link>https://www.skynettoday.com/editorials/ai-definition/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25990016</guid>
            <pubDate>Mon, 01 Feb 2021 16:22:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Favorite Podcasts]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25989939">thread link</a>) | @dhruvparamhans
<br/>
February 1, 2021 | https://dhruv-sharma.ovh/blog/podcasts/ | <a href="https://web.archive.org/web/*/https://dhruv-sharma.ovh/blog/podcasts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Quizzing has been an important part of my life for many years now. In fact I have spent more years in my life playing, setting, and enjoying quizzes than I have without them. As I have progressed from school quizzes to university level and now open level quizzes, I have had to increase my knowledge base substantially. While early on, staying abreast with the latest news by reading newspapers or monthly magazines was enough, open quizzes require more in depth knowledge. I have also felt a discomfort in simply knowing superficial details about things, rather than actually taking the time to understand them in sufficient depth. While Feynman isn’t my favorite scientist, I do agree with him when he said that “simply knowing the names of things isn’t knowledge”.</p><p>In the quest of going beyond names of things (like Shakespeare’s last great comedy), I have sought out podcasts as an economical way of understanding the “story” behind the facts. Podcasts have also been a boon over the last few years because doing a masters and then a PhD makes claims on your time that don’t let other activities; however I can always listen to podcasts while I am doing other things like doing dishes or taking out the laundry.</p><p>And I listen to a lot of podcasts! For instance, since September 2019 I have spent close to 8 days listening to podcasts. That translates to close to 200 hours of listening. Also I am subscribed to about 150+ of them. While I obviously don’t listen to all of them on a regular basis, there are some which are my go-to shows. Here is a small-ish selection of them.</p><h2 id="general-listening">General listening</h2><p>These are shows that I listen to quite regularly and they cover a very wide range of subjects.</p><ol><li><a href="https://www.bbc.co.uk/programmes/b006qykl" target="_blank" rel="noopener">In our time</a> - This is probably the best radio show I have ever heard. Each week the host Melvyn Bragg invites 3 subject matter experts for discussing a whole host of topics: everything from feathered dinosaurs to the life of Thomas Aquinas. Each episode lasts about 45 minutes and it’s the best bang for your buck if you want to quickly get a more than superficial understanding of a subject. You can also subscribe to domain specific feeds on science, culture, history and philosophy as well.</li><li><a href="https://dhruv-sharma.ovh/blog/podcasts/philosophizethis.org">Philosophize this</a> - A podcast on philosophy, it gives a brief (20-30 mins) introduction to the major themes in western philosophy starting from the pre-Socratics to modern day philosophers. For a more detailed and global philosophy podcast, there is always “History of Philosophy without any gaps”.</li><li><a href="https://partiallyexaminedlife.com/" target="_blank" rel="noopener">The Partially Examined life</a> - This is another one of those general podcasts that discuss philosophy. What i like most about this podcast is it’s conversational nature. Unlike philosophize this, the discussion around the topic or philosopher at hand makes it, to me at least, a better way to understand things.</li><li><a href="https://dhruv-sharma.ovh/blog/podcasts/entitledopinions.stanford.edu">Entitled opinions</a> - This is one of my favorite podcasts of all time. Hosted by Stanford university professor Robert Harrison, this podcast and radio show takes the same approach as In Our Time but the conversations are even more wide-ranging. Harrison also has none of the coldness that Bragg has which makes it for a great experience. Harrison also sometimes does solo episodes where he talks with equal ease about Dante’s inferno as he does about the music of The Doors.</li></ol><p>In the next few sections, I will discuss some of my favorite podcasts within multiple categories.</p><h2 id="french-language-podcasts">French language podcasts</h2><p>One of the way in which I ended up listening to podcasts was during my <em>stage linguistique</em> as I was learning French. I believe that one of the best ways to actually acquire the language is via active listening and I created my very own, rather unique way of learning the language (more on that for a later blog post). Since 2013, I have reduced my French podcast listening, but I do have some favorites.</p><ol><li><a href="https://www.franceculture.fr/emissions/la-compagnie-des-auteurs" target="_blank" rel="noopener">La compagnie des œuvres</a> - This podcast, much in the same way as In Our Time does, focuses on a specific topic. For this podcast, it is is literary works or more generally <em>oeuvres</em>, creative works of any kind. This is also a radio show which is broadcast mondays to Fridays on France Culture</li><li><a href="https://www.franceculture.fr/emissions/le-cours-de-lhistoire" target="_blank" rel="noopener">Le cours de l’histoire</a> - Another podcast from France Culture is this podcast which focuses on historical events generally.</li><li><a href="https://www.binge.audio/podcast/parler-comme-jamais" target="_blank" rel="noopener">Parler comme jamais</a> - This is another one of my favorite podcasts since it is hosted by two linguists who give a deep dive into the various idiosyncrasies of the French language while also providing commentary on the social and political aspects of the language. This latter aspect is quite interesting because discussions on what is right and wrong in the French language can become a matter of serious contention.</li></ol><h2 id="music">Music</h2><ol><li><a href="https://www.bbc.co.uk/programmes/b006qnmr" target="_blank" rel="noopener">Desert island discs</a> - This is another podcast from the BBC where invited guests talk about and share what kind of music they would take if they were stranded on an island. I find this a great way of finding new music.</li><li><a href="https://www.bbc.co.uk/programmes/p02nrvd3" target="_blank" rel="noopener">Composer of the week</a> - One of the best podcasts there is if you are a fan of classical music. Each week we get to listen to a single composers life and work. There is also extra episodes that focus on a particular composer and follow their musical output throughout the year. Last year was Beethoven which was a real delight. Note that after brexit it seems that the podcast isn’t available in France. I tried with a VPN with some success.</li><li><a href="https://www.wnycstudios.org/podcasts/aria-code" target="_blank" rel="noopener">Aria code</a> - This is one of those serendipitous finds: I found this podcast while searching for shows doing a deep-dive on operas. Rhiannon Giddens, a MacArthur genius musician in her own right, interviews opera performers and they dissect well-known arias from operas. As a person who is a neophyte when it comes to operas, this is a great way of understanding this art form.</li></ol><h2 id="shakespeare">Shakespeare</h2><p>This might seem like a weird category , but I have recently become supremely interested in Shakespeare and his plays. Not just the text, I have also become interested in the historical context behind the plays, the themes and the metaphors at play, and so on. It is not for nothing that authors and thinkers all over the world keep going back to the Bard for inspiration.</p><ol><li><a href="https://shows.acast.com/the-plays-the-thing" target="_blank" rel="noopener">The Plays The Thing</a> - This podcast is an extremely comprehensive introduction to all of Shakespeare’s plays. Each episode takes a deep dive into a particular section of a play, usually a few scenes from an act of the play, and discusses it at length. There is usually also an introductory episode to lay the groundwork so to speak for the play.</li><li><a href="https://www.folger.edu/shakespeare-unlimited" target="_blank" rel="noopener">Folger Shakespeare library</a> - This podcast serves the opposite purpose to the previous one. While “The Plays the thing” focuses on individual plays, this podcast takes a step back and tries to examine the impact that Shakespeare has had on modern culture and popular culture through the years. Everything from the Bard’s influence on science and art to the Game of Thrones is fair play.</li></ol><h2 id="history">History</h2><p>Following on from culture are podcasts that I listen to regularly covering various regions of the world through various periods of history.</p><ol><li><a href="https://thehistoryofrome.typepad.com/revolutions_podcast/" target="_blank" rel="noopener">Revolutions</a> - The revolutions podcast as the name suggests is about…revolutions. While the first season talked about the French revolution, the current season is focusing on the Russian revolution. This is not just a blow by blow accounts of the events, but a detailed examination of the social and political realities that led to the revolution. Mike Duncan, the creator of the podcast, it turns out lives in Paris. Would love to have a chance to share a coffee with him once Covid is behind us.</li><li><a href="https://www.thebritishhistorypodcast.com/" target="_blank" rel="noopener">The British history podcast</a> - As the name suggests, covers British history. The podcast follows a chronological order and is very detailed and covers all aspects of the island across the channel.</li><li><a href="https://historyofafricapodcast.blogspot.com/" target="_blank" rel="noopener">The History of Africa</a> - Africa as a continent is generally neglected when it comes to the study of history. I don’t remember ever having a class or a chapter on African history. So this podcast is a nice entry point to the story of Africa. The first season focused on Egypt and in the current one we are taking a look at Ethiopia.</li><li><a href="https://historyofphilosophy.net/" target="_blank" rel="noopener">The History of Philosophy Without Any Gaps</a> - This was actually one of the earliest podcasts that I subscribed to. The objective of the podcast is a laudable one: it seeks to chart the course of philosophy starting from the pre-Socratics right t the present age. Furthermore, the podcast also tries to cover the story of philosophy from other parts of the world as well- we have sections on Arabic philosophy, Chinese and Indian pholiopshy and also African philosophy. The companion website is also a great resource.</li><li><a href="http://intellectualmathematics.com/opinionated-history-of-mathematics/" target="_blank" rel="noopener">The History of Mathematics</a> - This one is a recent favorite of mine. The podcast tries to give an opinionated account of the history of mathematics and place it within the current context. Highly recommended for people interested in mathematics.</li></ol><h2 id="conclusion">Conclusion</h2><p>In the next blogpost, I will cover other podcasts that I listen to regularly on art, food, fashion and culture along with some other quirky picks.</p></div></div>]]>
            </description>
            <link>https://dhruv-sharma.ovh/blog/podcasts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25989939</guid>
            <pubDate>Mon, 01 Feb 2021 16:14:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Memgraph DB 1.3 release brings high availability replication (HA)]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25989934">thread link</a>) | @karimtr
<br/>
February 1, 2021 | https://memgraph.com/blog/memgraph-1-3-release | <a href="https://web.archive.org/web/*/https://memgraph.com/blog/memgraph-1-3-release">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h3>Introduction</h3>
<p>Hello, graph-wrangling, database-lovin’ folks out there! It’s been a long winter for us all, but we’ve made the best out of the cold, dreary days to bring you a whole new bag of tricks to keep you occupied for a while. Without further ado, we’re happy to announce that <a href="https://memgraph.com/download">Memgraph 1.3</a> is officially out!</p>
<p>If there’s one thing we’re proud of, it’s that from now on, the all-new <a href="https://docs.memgraph.com/memgraph/reference-guide/replication">replication feature</a> will enable you to copy and sync your Memgraph database to multiple servers to ensure your data is always available even if your main server goes down.</p>
<p>Of course, we’ve thrown in some extra goodies to spice things up, so read on and bon appetite!</p>
<h2>Replication</h2>
<p>Starting with this release, if you’re a Memgraph Enterprise user, you’ll be able to sync your data between Memgraph instances that run on different machines. In other words, using the replication feature, you’ll be able to create and run clusters of nodes running synced Memgraph instances, ensuring high availability of your graph data.</p>
<p>We provide the <em>main</em>-<em>replica</em> cluster node relationship model (aka leader-follower). A node may take on the role of the main (containing data to be replicated to other nodes), and the nodes that take on the role of replicas work in concert with the main to reconstruct the data present on the main, and keep in sync with it.</p>
<p>To sync data, you’ll be able to choose between the sync, async and semi-sync mode, depending on how hard your consistency requirements are.</p>
<p><img src="https://i.imgur.com/4cO6nOM.png" alt=""></p>
<p>This simple but powerful setup enables you to create highly flexible and fault-tolerant clusters that can be easily configured and deployed anywhere!</p>
<p>“How does it work and how can I try it out?”, you may ask. Head on over to <a href="https://docs.memgraph.com/memgraph/reference-guide/replication">the reference guide</a> for a more in-depth explanation of replication, and check out the <a href="https://docs.memgraph.com/memgraph/database-functionalities/replication">how-to guide</a> to get you replicating in no time!</p>
<h2>Data Directory Locking</h2>
<p>Memgraph uses snapshots and WAL files as durability files. These are used to reconstruct the database to the most up-to-date version. Up to now, there was no reliable way to back up those durability files while an instance is running, so to back up a database, one had to either dump it (using the <code>DUMP DATABASE</code> query), or kill the instance, and then back up the durability files.</p>
<p>To make a live backup easier, we added a locking query <code>(LOCK | UNLOCK) DATA DIRECTORY</code> that does just what it says - it prevents the instance from deleting durability files from it, giving the user the opportunity to back them up without fear of data loss. No more backup roulette!</p>
<h2>New And Improved Logging</h2>
<p>We’ve also improved the logging, which is now both faster and more configurable. Now the user can control the level of logging with the <code>--log-level</code> flag. No more techno gibberish when you don’t want it, and more gibberish when you need it!</p>
<h2>Query Type Deduction Done Right</h2>
<p>We’ve gotten around to implementing the so-called read-write type deduction properly. We faked it before, just to appease the Neo4j driver gods. Turns out, this type can be actually useful! For example, we use the type of the query to forbid write queries on replicas. Nifty, right?</p>
<h2>What’s Next?</h2>
<p>Go on, try it out! You can <a href="https://memgraph.com/download">download the 1.3 version</a>.</p>
<p>If you’re interested in the replication feature, check out this <a href="https://docs.memgraph.com/memgraph/reference-guide/replication">reference guide</a>, or this <a href="https://docs.memgraph.com/memgraph/database-functionalities/replication">how-to guide</a> if you want to get your hands dirty.</p>
<p>If you catch any bugs or generally weird behavior, please drop us a line on our <a href="https://discourse.memgraph.com/">forum</a>.</p>
<p>Happy hacking!</p>
</div></div>]]>
            </description>
            <link>https://memgraph.com/blog/memgraph-1-3-release</link>
            <guid isPermaLink="false">hacker-news-small-sites-25989934</guid>
            <pubDate>Mon, 01 Feb 2021 16:14:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DynamoDB Foreign Key Support]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25989778">thread link</a>) | @bwship
<br/>
February 1, 2021 | https://docs.getcommandeer.com/blog/latest/introducing-dynamodb-foreign-keys | <a href="https://web.archive.org/web/*/https://docs.getcommandeer.com/blog/latest/introducing-dynamodb-foreign-keys">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p>We have been using <a href="https://aws.amazon.com/dynamodb/" title="DynamoDB" target="_blank" rel="noopener noreferrer">DynamoDB</a> for the past 4-5 years both at Commandeer, and on previous projects we have built, including <a href="https://www.tuition.io/" title="Tuition.io" target="_blank" rel="noopener noreferrer">Tution.io </a>and the <a href="https://speedqueenlaundry.com/app/" title="Speed Queen Laundry App" target="_blank" rel="noopener noreferrer">Speed Queen Laundry App</a>.  It is a really great NoSQL system that allows for infinite scaleability, is easy to use, and provides a great API to allow developers to get and modify data easily.</p> <p>But, one of the hangups we have had with NoSQL, is that often times, even though it is unstructured in nature, we typically build it in a structured way.  This means we do things like having a Membership table that relates to a User table by a Global Secondary Index called userId.  Anytime we need to get data from it however, we were having to pull in developers to code it up.</p> <p>In our upcoming version of Commandeer, 1.7, we will be providing Foreign Key inference on tables.  Let's dive into an example, to visually show you what I am talking about.</p> <blockquote><p><a href="https://getcommandeer.com/" title="Download the Commandeer App" target="_blank" rel="noopener noreferrer">Download the Commandeer App</a> - 15-day Free Trial - The #1 developer IDE to manage your serverless and container infrastructures, both locally and in the cloud. With support for 30+ of the best cloud services out there.</p></blockquote> <h2 id="foreign-key-inference"><a href="#foreign-key-inference">#</a> Foreign Key Inference</h2> <p>For the initial version of foreign keys, if your columns are named things like userId or user_id or userID AND you have a User table, we will link the two.</p> <p>In subsequent releases, we will be adding even more functionality for this via IaC.  There will soon be plugins for <a href="https://www.ansible.com/" title="Ansible" target="_blank" rel="noopener noreferrer">Ansible</a>, <a href="https://www.terraform.io/" title="Terraform" target="_blank" rel="noopener noreferrer">Terraform</a>, and the<a href="https://www.serverless.com/" title="The Serverless Framework" target="_blank" rel="noopener noreferrer"> Serverless Framework</a> that allow you to specify the foreign keys in code, and we will pick them up.  Under the hood, we will then have them as tags on the table, and Commandeer will automatically read from them.</p> <p>Below you can see how our Membership table relates to our User and Team tables.</p> <p><img src="https://images.commandeer.be/_uploads/dynamo-er-diagram-small.png" alt=""></p> <hr> <h2 id="er-diagram"><a href="#er-diagram">#</a> ER Diagram</h2> <p>The first place you can easily see what I am talking about is within the DynamoDB ER Diagram.  This tool allows you to visualize your DynamoDB tables.  Here you can see that many of the tables have a userId column that points to the User table.  And also that some of the tables have a foreign key of teamId pointing to the Team table.</p> <p><img src="https://images.commandeer.be/_uploads/dynamodb-er-diagram.png" alt="DynamoDB ER Diagram" title="DynamoDB ER Diagram"></p> <hr> <h2 id="foreign-key-information"><a href="#foreign-key-information">#</a> Foreign Key Information</h2> <p>If we drill down into the Membership table, you can see the information about not only the Primary and Secondary indexes, but now also the foreign keys and what tables they are linked to.</p> <p><img src="https://images.commandeer.be/_uploads/membership-table.png" alt="DynamoDB Membership Table" title="DynamoDB Membership Table">And zooming in further to the Membership table itself, you can see that the userId column maps to the User table, and the teamId column maps to the Team table.</p> <p><img src="https://images.commandeer.be/_uploads/membership-table-foreign-keys.png" alt="DynamoDB Foreign Key Columns" title="DynamoDB Foreign Key Columns"></p> <p>You can also view this information from the side navigation.</p> <p><img src="https://images.commandeer.be/_uploads/membership-sideview.png" alt="Membership Schema" title="Membership Schema"></p> <div><pre><code># Legend

PK = Primary Key
SK = Sort Key
GSI = Global Secondary Index
FK = Foreign Key
</code></pre></div><hr> <h2 id="the-power-of-the-foreign-key"><a href="#the-power-of-the-foreign-key">#</a> The Power of the Foreign Key</h2> <p>The real power of the Foreign Key is two-fold.  First, as shown above, it gives you a great way to visualize your system with the ER Diagram.  When you are explaining your system to people, you don't have to draw it out on a white board every time to visualize it  The other great feature is that in Commandeer, we allow you to view your related data instantly when looking through a table.</p> <p>Below you can see a few records in the Membership table, and if you have the 'Format Data' toggle turned on, you will see a new drop down link called 'View' on each record.</p> <p><img src="https://images.commandeer.be/_uploads/membership-table2.png" alt=""></p> <p>Clicking on the 'View' link then brings up the related record in a modal.</p> <p><img src="https://images.commandeer.be/_uploads/membership-table-foreign-key-data.png" alt=""></p> <p>On the detail page, you also can view not only your current record, but also any data that might be associated with it.   This is also a good example about it being an inference, as NoSQL doesn't really have foreign keys, meaning that there is not inferential integrity, so the record might not exist.</p> <p><img src="https://images.commandeer.be/_uploads/foreign.png" alt=""></p> <p>This is a great improvement over the old way of using DynamoDB, in which we would have the Membership table and the User table opened in separate tabs.  And then copy the userId from the Membership table, and and it to the query on the User tab.  Under the hood, it is doing a primary key query to retrieve the record, and it is only brought back on demand when you click the link.</p> <hr> <h2 id="conclusion"><a href="#conclusion">#</a> Conclusion</h2> <p>DynamoDB continues to be our go to NoSQL system, because it integrates with AppSync, Athena, and Lambda so well.  Foreign keys add a whole new level of data accessibility that has been lacking in the ecosystem until now.</p> <p>Happy Developing!</p> <blockquote><p><a href="https://getcommandeer.com/" title="Download the Commandeer App" target="_blank" rel="noopener noreferrer">Download the Commandeer App</a> - 15-day Free Trial - The #1 developer IDE to manage your serverless and container infrastructures, both locally and in the cloud. With support for 30+ of the best cloud services out there.</p></blockquote></div><div><!----> <p><span>Last update:</span> <span>February 4, 2021 20:11</span></p></div></div>]]>
            </description>
            <link>https://docs.getcommandeer.com/blog/latest/introducing-dynamodb-foreign-keys</link>
            <guid isPermaLink="false">hacker-news-small-sites-25989778</guid>
            <pubDate>Mon, 01 Feb 2021 16:01:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Guide to Terminal User Interfaces in PowerShell]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25989724">thread link</a>) | @todsacerdoti
<br/>
February 1, 2021 | https://blog.ironmansoftware.com/tui-powershell/ | <a href="https://web.archive.org/web/*/https://blog.ironmansoftware.com/tui-powershell/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content" role="main"><div><h2>The Ultimate Guide to Terminal User Interfaces in PowerShell</h2><h4>January 30, 2021</h4><p>Terminal User Interfaces (TUI) have a long history in computing and were some of the first forms of interfaces between human and machine. Sometimes referred to as text-based user interfaces, they are starting to gain popularity again with projects like <a href="https://github.com/migueldeicaza/gui.cs">Terminal.Gui</a> for .NET. In this guide, we take a deep dive into how to build TUIs with PowerShell and Terminal.Gui.</p><h2 id="table-of-contents">Table of Contents</h2><ul><li><a href="#intro">Intro to Terminal.Gui</a></li><li><a href="#installation">Installation</a></li><li><a href="#createwindow">Creating a Window</a></li><li><a href="#views">Controls</a><ul><li><a href="#buttons">Buttons</a></li><li><a href="#checkboxes">Checkboxes</a></li><li><a href="#dialogs">Dialogs</a></li><li><a href="#frame-view">Frame View</a></li><li><a href="#labels">Labels</a></li><li><a href="#list-view">List View</a></li><li><a href="#menus">Menus</a></li><li><a href="#text-fields">Text Fields</a></li></ul></li><li><a href="#layout-and-sizing">Layout and Sizing</a></li><li><a href="#events">Events</a><ul><li><a href="#click-events">Click Events</a></li><li><a href="#selection-events">Selection Events</a></li><li><a href="#keyboard-events">Keyboard Events</a></li></ul></li><li><a href="#threading">Threading</a><ul><li><a href="#Asynchronous-Execution">Asynchronous Execution</a></li><li><a href="#timers">Timers</a></li></ul></li><li><a href="#threading">Designer</a></li><li><a href="#conclusion">Conclusion</a></li></ul><h2 id="intro">Intro to Terminal.Gui</h2><p>Terminal.Gui is a .NET library for creating robust TUIs. It’s cross-platform and works with various types of terminals. It uses a nested view system that defines basic controls like windows, buttons, labels, and text fields. It also employs an absolute and calculated layout system to easily position controls.</p><p>Here’s an example of the <a href="https://ironmansoftware.com/powershell-pro-tools">PowerShell Pro Tools</a> TUI designer built with Terminal.Gui.</p><p><img src="https://blog.ironmansoftware.com/images/drag.gif" alt=""></p><h2 id="installation">Installation</h2><p>There are a couple ways of installing the Terminal.Gui library but the easiest is to install the <code>Microsoft.PowerShell.ConsoleGuiTools</code> module as it includes the library itself.</p><div><pre><code data-lang="powershell">Install-Module Microsoft.PowerShell.ConsoleGuiTools 
</code></pre></div><p>Once the module is installed, you will the need to load the assembly to ensure that the types are available for creating the TUI.</p><div><pre><code data-lang="powershell">Import-Module Microsoft.PowerShell.ConsoleGuiTools 
$module = (Get-Module Microsoft.PowerShell.ConsoleGuiTools -List).ModuleBase
Add-Type -Path (Join-path $module Terminal.Gui.dll)
</code></pre></div><p>Terminal.Gui requires that top level application be initialized before developing your TUI. This can be done with the <code>Application</code> class.</p><div><pre><code data-lang="powershell"><span>[Terminal.Gui.Application]</span>::Init()
</code></pre></div><p>Now that the library is loaded and initialized, we can start create our first TUI.</p><h2 id="createwindow">Creating a Window</h2><p>To create a window, we can use the <code>Window</code> class and add it to the top level view of the application. All views share similar properties such as position, size, and sub views.</p><p>To create a basic window, we can just invoke the default constructor and set it to a variable. Next, we need to add it to the top level view and run the application.</p><div><pre><code data-lang="powershell">$Window = <span>[Terminal.Gui.Window]</span>::new()
$Window.Title = <span>"Hello, World"</span>
<span>[Terminal.Gui.Application]</span>::Top.Add($Window)
<span>[Terminal.Gui.Application]</span>::Run()
</code></pre></div><p>Once the application is run, the TUI will be shown. You can exit it by pressing <code>Ctrl+Q</code>.</p><p><img src="https://blog.ironmansoftware.com/images/tui-helloworld.png" alt=""></p><h2 id="controls">Controls</h2><p>Now that we’ve looked at how to create a basic application with a window, we can start to look at different types of views, or controls, to add to your TUIs. Controls need to be added to their superview, like a window, in order for them to be displayed.</p><p>This is not a complete list of the available controls. For a complete list, visit the <a href="https://github.com/migueldeicaza/gui.cs#controls--features">Terminal.Guis GitHub page</a>.</p><h3 id="buttons">Buttons</h3><p>Buttons allow you to provide an interactive experience to your user. You can define a button’s text, action and position within the TUI.</p><p>Building on our previous example, we can add a button to a window like this.</p><div><pre><code data-lang="powershell">$Button = <span>[Terminal.Gui.Button]</span>::new()
$Button.Text = <span>"Button"</span> 
$Window.Add($Button)
</code></pre></div><p>The resulting TUI will look like this.</p><p><img src="https://blog.ironmansoftware.com/images/tui-button.png" alt=""></p><h3 id="checkboxes">Checkboxes</h3><p>Checkboxes allow for displaying boolean state or providing a way to the user to turn on or off a setting.</p><p>This example creates a simple check box with a label.</p><div><pre><code data-lang="powershell">$Label = <span>[Terminal.Gui.Label]</span>::new()
$Label.Text = <span>"Enable Disco"</span>
$Label.Height = 1
$Label.Width = 20
$Window.Add($Label)

$Checkbox = <span>[Terminal.Gui.Checkbox]</span>::new()
$Checkbox.Checked = $true
$Checkbox.X = <span>[Terminal.Gui.Pos]</span>::Right($Label)
$Window.Add($Checkbox)
</code></pre></div><p><img src="https://blog.ironmansoftware.com/images/tui-checkbox.png" alt=""></p><h3 id="frame-views">Frame Views</h3><p>Frame views are container views that have a title, border and contain other subviews. They are used to organize regions of your TUI.</p><p>This example creates two side-by-side frame views with labels in each.</p><div><pre><code data-lang="powershell">$Frame1 = <span>[Terminal.Gui.FrameView]</span>::new()
$Frame1.Width = <span>[Terminal.Gui.Dim]</span>::Percent(50)
$Frame1.Height = <span>[Terminal.Gui.Dim]</span>::Fill()
$Frame1.Title = <span>"Frame 1"</span>
$Window.Add($Frame1)

$Frame2 = <span>[Terminal.Gui.FrameView]</span>::new()
$Frame2.Width = <span>[Terminal.Gui.Dim]</span>::Percent(50)
$Frame2.Height = <span>[Terminal.Gui.Dim]</span>::Fill()
$Frame2.X = <span>[Terminal.Gui.Pos]</span>::Right($Frame1)
$Frame2.Title = <span>"Frame 2"</span>
$Window.Add($Frame2)

$Label1 = <span>[Terminal.Gui.Label]</span>::new()
$Label1.Text = <span>"Frame 1 Content"</span>
$Label1.Height = 1
$Label1.Width = 20
$Frame1.Add($Label1)

$Label2 = <span>[Terminal.Gui.Label]</span>::new()
$Label2.Text = <span>"Frame 2 Content"</span>
$Label2.Height = 1
$Label2.Width = 20
$Frame2.Add($Label2)
</code></pre></div><p><img src="https://blog.ironmansoftware.com/images/tui-frame.png" alt=""></p><h3 id="labels">Labels</h3><p>Labels are just text that you can place on your views. For a label to be visible, we need to set the width and height of the view. We’ll talk more about dimensions and sizing in the layout section.</p><div><pre><code data-lang="powershell">$Label = <span>[Terminal.Gui.Label]</span>::new()
$Label.Text = <span>"Hi, Mom!"</span> 
$Label.Width = <span>[Terminal.Gui.Dim]</span>::Fill()
$Label.Height = <span>[Terminal.Gui.Dim]</span>::Fill()
$Window.Add($Label)
</code></pre></div><p><img src="https://blog.ironmansoftware.com/images/tui-label.png" alt=""></p><h3 id="list-view">List View</h3><p>List views allow you to display collections of items in a list. Users can select the items and you can connect event handlers to listen for changes to those selections.</p><div><pre><code data-lang="powershell">$ListView = <span>[Terminal.Gui.ListView]</span>::new()
$ListView.SetSource(@(<span>"Item1"</span>, <span>"Item2"</span>, <span>"Item3"</span>))
$ListView.Width = <span>[Terminal.Gui.Dim]</span>::Fill()
$ListView.Height = <span>[Terminal.Gui.Dim]</span>::Fill()
$Window.Add($ListView)
</code></pre></div><p><img src="https://blog.ironmansoftware.com/images/tui-listview.png" alt=""></p><h3 id="text-fields">Text Fields</h3><p>Text fields are used to allow the user to input data. Text fields can also be used with a mask to allow users to enter passwords. Text fields, like other input controls, support tab stops so you can navigate the TUI by using the keyboard.</p><div><pre><code data-lang="powershell">$Textfield = <span>[Terminal.Gui.Textfield]</span>::new()
$Textfield.Text = <span>"What now?"</span> 
$Textfield.Width = <span>[Terminal.Gui.Dim]</span>::Fill()
$Window.Add($Textfield)
</code></pre></div><p><img src="https://blog.ironmansoftware.com/images/tui-textfield.png" alt=""></p><p>There are many other views that you can use with Terminal.Gui. You can learn about all of them on their documentation.</p><h3 id="dialogs">Dialogs</h3><p>There are various dialog views that you can show over the top of your main window. Dialogs are typically modal and you can allow users to perform specific actions. There are also specific dialogs for opening and saving files.</p><h4 id="message-boxes">Message Boxes</h4><p>The <code>MessageBox</code> class can be used to show information and error messages. It’s easy to use and doesn’t require too much code.</p><p>The following shows a message box with a title and a message.</p><div><pre><code data-lang="powershell"><span>[Terminal.Gui.MessageBox]</span>::Query(<span>"Hello"</span>, <span>"World"</span>)
</code></pre></div><p><img src="https://blog.ironmansoftware.com/images/tui-messsagebox.png" alt=""></p><p>Message boxes can also include buttons and will return the index of the button that was clicked. The below example creates a message box with multiple buttons. If Ok is clicked, the <code>$Result</code> variable will contain <code>0</code> and the web site will be opened.</p><div><pre><code data-lang="powershell">$result = <span>[Terminal.Gui.MessageBox]</span>::Query(<span>"Hello"</span>, <span>"Go to IronmanSoftware.com?"</span>, @(<span>"Ok"</span>, <span>"Cancel"</span>))
<span>if</span> ($result <span>-eq</span> 0)
{
    Start-Process https<span>:</span>//www.ironmansoftware.com
}
</code></pre></div><p><img src="https://blog.ironmansoftware.com/images/tui-messsagebox-buttons.png" alt=""></p><p>Message boxes can also show errors dialogs. You can use the <code>ErrorQuery</code> to show these types of boxes.</p><div><pre><code data-lang="powershell"><span>[Terminal.Gui.MessageBox]</span>::ErrorQuery(<span>"Failed"</span>, <span>"Catastrophic failure"</span>);
</code></pre></div><p><img src="https://blog.ironmansoftware.com/images/tui-error.png" alt=""></p><h4 id="dialogs-1">Dialogs</h4><p>The <code>MessageBox</code> class is a helper for creating dialogs to display simple text and buttons. You can also create dialogs directly. You can still add buttons but you can also add any control you’d like within the content of the dialog.</p><p>This example creates a dialog that includes a text field. You need to call <code>[Application]::Run</code> on the dialog in order to show it.</p><div><pre><code data-lang="powershell">$Dialog = <span>[Terminal.Gui.Dialog]</span>::new()
$Dialog.Title = <span>"Whoa"</span>
$Textfield = <span>[Terminal.Gui.Textfield]</span>::new()
$Textfield.Width = 10
$Dialog.Add($Textfield)
<span>[Terminal.Gui.Application]</span>::Run($Dialog)
</code></pre></div><p><img src="https://blog.ironmansoftware.com/images/tui-dialog.png" alt=""></p><h4 id="open-and-save-dialogs">Open and Save Dialogs</h4><p>Terminal.Gui also contains specific dialogs for open and saving files and folders. You can customize which folder to open to, whether multiple items can be selected and filter based on file type. The following example creates a open dialog that displays <code>.PS1</code> files.</p><div><pre><code data-lang="powershell">$Dialog = <span>[Terminal.Gui.OpenDialog]</span>::new(<span>"Open Powershell Script"</span>, <span>""</span>)
$Dialog.CanChooseDirectories = $false
$Dialog.CanChooseFiles = $true 
$Dialog.AllowsMultipleSelection = $false
$Dialog.AllowedFileTypes = @(<span>".ps1"</span>)
<span>[Terminal.Gui.Application]</span>::Run($Dialog)

<span>[Terminal.Gui.MessageBox]</span>::Query(<span>"File"</span>, $Dialog.FilePath)
</code></pre></div><p><img src="https://blog.ironmansoftware.com/images/tui-opendialog.png" alt=""></p><p>Menus can be added to the top of a window to provide drop down options. Items within the menus can provide actions to take when the menu item is clicked. You can create nested menus that contain sub menu items.</p><p>A basic menu can be added by using the <code>MenuBar</code>, <code>MenuBarItem</code> and <code>MenuItem</code> classes.</p><p>You can define shortcuts to invoke menu items by including a <code>_</code> in front of the character.</p><div><pre><code data-lang="powershell">$MenuItem = <span>[Terminal.Gui.MenuItem]</span>::new(<span>"_About"</span>, <span>""</span>, { <span>[Terminal.Gui.MessageBox]</span>::Query(<span>"About"</span>, <span>"Cool Tutorial 1.0"</span>) })
$MenuBarItem = <span>[Terminal.Gui.MenuBarItem]</span>::new(<span>"Help"</span>, @($MenuItem))
$MenuBar = <span>[Terminal.Gui.MenuBar]</span>::new(@($MenuBarItem))
$Window.Add($MenuBar)
</code></pre></div><p><img src="https://blog.ironmansoftware.com/images/tui-menu.png" alt=""></p><h2 id="layout-and-sizing">Layout and Sizing</h2><p>As you have seen in some of the examples above, we had to set the dimensions of components in order for them to appear within our window. In addition to controlling dimensions, you can also control positioning using both an absolute and a calculated system.</p><h3 id="sizing">Sizing</h3><p>Sizing controls is done using the <code>Dim</code> class. You can size controls based on an absolute value, the remaining size of the screen or a percentage. The width and height of view can be set using the <code>Width</code> and <code>Height</code> properties.</p><h4 id="absolute">Absolute</h4><p>Absolute sizing can be accomplished using the <code>Dim</code> class or by simply setting an integer value to the dimension you wish to set.</p><p>The following example creates a text field that is 5 in width.</p><div><pre><code data-lang="powershell">$Textfield = <span>[Terminal.Gui.Textfield]</span>::new()
$Textfield.Width = 10
$Window.Add($Textfield)
</code></pre></div><p><img src="https://blog.ironmansoftware.com/images/tui-absolute.png" alt=""></p><h4 id="fill">Fill</h4><p>You can use the <code>Fill</code> method of the <code>Dim</code> class to instruct the layout engine to fill the specified dimension with the control. This is useful for making a text field stretch across a window horizontally or stretch a frame view to the bottom of a window.</p><p>In this example, we stretch a text field horizontally across a window.</p><div><pre><code data-lang="powershell">$Textfield = <span>[Terminal.Gui.Textfield]</span>::new()
$Textfield.Width = <span>[Terminal.Gui.Dim]</span>::Fill()
$Window.Add($Textfield)
</code></pre></div><p><img src="https://blog.ironmansoftware.com/images/tui-fill.png" alt=""></p><h4 id="percentage">Percentage</h4><p>You can set a view to …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.ironmansoftware.com/tui-powershell/">https://blog.ironmansoftware.com/tui-powershell/</a></em></p>]]>
            </description>
            <link>https://blog.ironmansoftware.com/tui-powershell/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25989724</guid>
            <pubDate>Mon, 01 Feb 2021 15:57:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The career-changing art of reading the docs]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25989676">thread link</a>) | @forrestbrazeal
<br/>
February 1, 2021 | https://acloudguru.com/blog/engineering/the-career-changing-art-of-reading-the-docs | <a href="https://web.archive.org/web/*/https://acloudguru.com/blog/engineering/the-career-changing-art-of-reading-the-docs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="8a920a5" data-element_type="widget" data-widget_type="theme-post-content.default"><div><p>Every so often I get asked for advice on how to become an <a href="https://aws.amazon.com/developer/community/heroes/">AWS Hero</a>.</p><p>The specific answer isn’t that interesting – “get involved in the community and hope someone nominates you as a Hero” seems to be the process at AWS. I understand that the <a href="https://mvp.microsoft.com/en-us/overview">Microsoft MVP process</a> is a bit more transparent and better prescribed.</p><p>But the general question of “how do I become well-respected in my chosen technical specialty” is VERY interesting. Even if you don’t have any aspirations to build a public following, there is tremendous career value in becoming the go-to person within your technical niche.</p><p>The person who everybody on your team comes to with their toughest question about that language or framework. The person who knows where all the bodies are buried in ActiveDirectory or Typescript or DynamoDB. Those folks have great careers and job security because authoritative knowledge like that is rare.</p><p>To some extent, it’s rare because wisdom only comes with experience. But I know plenty of engineers who’ve sat in the same chair for ten years getting the same year of experience ten times. Heck, I’ve been there myself; I spent a couple of years as an “accidental DBA” who never really learned that much about SQL Server beyond what the daily firefighting required.</p><p>I used to spend a lot of time wondering how other people seemed to level up so quickly on new technologies. How do you break through that stagnant cycle of learning and forgetting stuff in bits and pieces, using the same technology for years without ever feeling like an expert?</p><p>A few years ago I learned a secret for doing this, a cheat code if you will, from my fellow AWS Hero <a href="https://acloudguru.com/blog/author/jared-short">Jared Short</a>. This is his secret recipe for leveling up in tech:</p><p><strong>Read the documentation for one job-relevant technology, cover-to-cover, every week. </strong></p><figure><div><blockquote data-width="500" data-dnt="true"><p lang="en" dir="ltr">Forrest is giving away my secrets, but it's true. I'd estimate around 700+ hours of just reading AWS docs over my career with intent to retain / learn (not just reference). It feels silly until you almost immediately understand some esoteric side-effect or behavior. <a href="https://t.co/juQ0b9mENI">https://t.co/juQ0b9mENI</a></p>— Jared Short (@ShortJared) <a href="https://twitter.com/ShortJared/status/1347629518312378369?ref_src=twsrc%5Etfw">January 8, 2021</a></blockquote> </div></figure><h2 id="h-reading-docs-the-wrong-way-and-the-right-way">Reading docs: the wrong way and the right way</h2><p>I get it, that doesn’t sound revolutionary. “<a href="https://en.wikipedia.org/wiki/RTFM">RTFM</a>” is literally as old as computing itself. It’s the classic kiss-off answer to questions you ought to be able to Google.</p><p>And that betrays a key limitation in how a lot of us think about documentation. We think of it tactically, as a resource to query when we have a specific question or encounter a particular error. We use docs to fill in our <em>known unknowns.</em></p><p>That’s how you can get stuck for years, say, administering a PostgresSQL cluster and never really becoming that deep of an expert on Postgres. If you only learn something new when the situation demands it, your mental model of Postgres (or whatever) will look like a gradually expanding version of this:</p><figure><img loading="lazy" width="2181" height="1647" src="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/01/tactical.png" alt="" srcset="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/01/tactical.png 2181w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/01/tactical.png 300w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/01/tactical.png 1024w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/01/tactical.png 768w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/01/tactical.png 1536w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/01/tactical.png 2048w" sizes="(max-width: 2181px) 100vw, 2181px"></figure><p>Over time, as you encounter more new use cases for the technology, you’ll burn more “never forget” bubbles into the mental model. But you’ll still have this heavy sense of unknown unknowns hanging over you, and you’ll never be sure if you’re really using the optimal approach to solve a new problem.</p><p>Instead, Jared’s approach is to read docs strategically<em>, </em>preemptively, curiously: as a way to fill in your <em>unknown unknowns</em>. The things you might not encounter in ten years, but that would cost you two days of troubleshooting if you ran into them tomorrow.</p><p>Read docs like novels (cover to cover), not like dictionaries (look up the term, cross-reference, and stop). Over time, that strategy will lead to a mental model of your professional domain that looks more like this:</p><figure><img loading="lazy" width="727" height="549" src="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/01/strategic.png" alt="" srcset="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/01/strategic.png 727w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/01/strategic.png 300w" sizes="(max-width: 727px) 100vw, 727px"></figure><p>(This is <a href="https://acloudguru.com/blog/engineering/how-many-certifications-do-i-need-to-get-a-cloud-job">the same benefit</a> you get from studying for certifications, by the way: you’re building a mental map of the domain, so you don’t have to stumble through the darkness on every new quest.)</p><p>On the surface, that sounds simple, but it’s far from easy. Here are three common objections people raise when I advise reading docs as a career-advancement strategy:</p><h4 id="h-i-don-t-have-a-photographic-memory-i-ll-never-remember-a-bunch-of-random-docs"><strong>“I don’t have a photographic memory. I’ll never remember a bunch of random docs.”</strong></h4><p>Back when I was in college, a well-meaning friend convinced me I should read a book on SAP. Forget today — I couldn’t have told you a single thing about SAP <em>ten minutes after finishing that book</em>. I’d never been inside an enterprise, much less understood the problems these ERP integrations I was reading about were supposed to solve. It was like trying to talk to the aliens in the movie <em>Arrival</em>: my brain was the wrong shape.</p><p>Likewise, you probably won’t get much value out of glancing through docs for a technology you don’t use and have no context for.</p><p>So do these two things:</p><p>1. <strong>Focus on docs for technologies you are already using</strong>. We’ve all had that mind-numbing feeling when plowing through some esoteric text that doesn’t relate to our daily lives, where you glaze over for three pages and then go, “what did I just read?”</p><p>Avoid this by focusing on docs for technologies or languages you’ve already got a vested stake in – say, because they’re on your plate at work or you’re trying to build them into a side project.</p><p>Encourage active reading and engagement with the information by asking yourself questions like these as you read:</p><ul id="block-ef7bb5e0-252c-434f-98de-116c8c0e2003"><li>Did I understand that? (If not, maybe read the section again)</li><li>Does what I just read match my existing mental model of how this technology works? (If not, do I need to go review a different doc and then come back to this?)</li><li>Could this feature or fact help me on my current project?</li><li>If I had known this six months ago, what would I have done differently? (“Chosen a different technology” is a totally acceptable answer!)</li></ul><p>Then, <strong>2. Read those docs repeatedly, on a schedule, over and over</strong>. Seriously. If you’re on a team that’s building out centralized CI/CD for Azure, maybe read the part of the Azure DevOps docs on pipelines this week and the part on build agents next week, and when you get to the end, start over. The cloud changes fast. You’ll fold in new information at the same time you’re reinforcing the old.</p><h4 id="h-i-don-t-have-time-to-read-a-bunch-of-documentation"><strong>“I don’t have time to read a bunch of documentation.”</strong></h4><p>Yes, and weeks of work can save you hours of planning. Maybe use some of the time you currently spend injecting “HERE” print statements into your code to figure out why it’s not working.</p><figure><img src="https://faasandfurious.com/pages/debugging-tactics.png" alt="Debugging Tactics"></figure><p>More seriously, it’s not a bad idea to block a bit of time on your calendar each day – 30 minutes, even –  for targeted doc-reading. You may find it hard to carve that time out of your workday, but defending time and setting expectations with your manager is its own skill, worth practicing. Call the block of time “deep work.” It is.</p><h4 id="h-the-docs-for-technology-x-are-no-good-trust-me-they-re-not-worth-reading"><strong>“The docs for [technology X] are no good. Trust me, they’re not worth reading.”</strong></h4><p>I don’t always buy this excuse. The docs might not be that bad; you might just have the wrong expectations.</p><p>For example, the AWS documentation gets <a href="https://twitter.com/IanColdwater/status/1347737875991777280">a terrible rap</a> for being wordy and poorly-organized. And it’s maybe even worse than you’ve heard – if you’re trying to look up the name of an IAM action or the syntax of a CLI command, that is.</p><p>But as an educational tool that dives deep on the architectural underpinnings and technical limitations of services, the AWS docs are <em>fantastic. </em>They’re better than any book you could ever buy about the cloud. (And the <a href="https://aws.amazon.com/builders-library/">Builder’s Library</a> is better still.) The AWS docs are designed not just to be referenced, but to be read. Read ’em!</p><p>On the other hand, some types of docs like step-by-step tutorials are very much designed to be referenced during hands-on builder time. It may not make sense to spend a lot of time reading those in the abstract. So bring your common sense.</p><p>However. There are also plenty of technologies out there where the docs are truly incomplete, out of date, or just plain wrong – many smaller open-source projects, in particular.</p><p>Turns out you have another option here, at least for OSS projects: <em>read the source code.</em> Not sure what a module does, what its edge cases are, what the error code means? Read the source code and find out! It might be faster than (and will definitely be at least as accurate as) looking for the answer in the docs, <em>even if the docs are pretty good. </em></p><p>If you write code for a living, reading other people’s shipped, battle-tested code — not just PRs from your own team — is genuinely one of the most transformative things you can do for your career. Because while you’re answering your immediate question, you’ll also be picking up style, organization, and technique from professional programmers operating under all kinds of interesting constraints. Seriously. Read code.</p><p>(And then, if it’s open-source, maybe consider contributing some docs!)</p><h2 id="h-what-do-i-get-out-of-all-this"><strong>What do I get out of all this?</strong></h2><p>If you read a targeted set of docs consistently over a sustained period — say, a couple of years — while actively practicing on that technology, you will be able to perform magic. That’s a promise.</p><p>Let’s go back to Jared Short again for an example. (Yes, I checked with Jared, he graciously agreed to let me spill his secrets in this piece.) As an engineer at an AWS shop, Jared …</p><ul><li>Reads the documentation for one AWS service, cover to cover, every week.</li><li>Blocks daily time for this on his calendar.</li><li>Focuses on services he’s actually using at work (he tells me that so far in 2021, he’s been through all the docs for Lambda, AppSync, and Step Functions).</li></ul><p>Jared’s been doing this week in, week out, for *years*. And that  unglamorous commitment lets him perform nerd magic like this:</p><figure><div><blockquote data-width="500" data-dnt="true"><p lang="en" dir="ltr">I needed to understand extensions better for a thing, read the docs cover to cover like an insane person.</p>— Jared Short (@ShortJared) <a href="https://twitter.com/ShortJared/status/1347612782389301249?ref_src=twsrc%5Etfw">January 8, 2021</a></blockquote> </div></figure><p>If you don’t want to take the time to read that whole Twitter thread, let me sum it up for you.</p><ol><li>An experienced AWS engineer encounters a weird behavior: AWS Lambda seems to be executing code when it should not be. He posts a plea for help on Twitter.</li><li>Other experienced engineers take a look and go, “huh. Weird.” To be clear, this is not a case of RTFM. The problem is nontrivial and the solution, if there is one, is not well-known. …</li></ol></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acloudguru.com/blog/engineering/the-career-changing-art-of-reading-the-docs">https://acloudguru.com/blog/engineering/the-career-changing-art-of-reading-the-docs</a></em></p>]]>
            </description>
            <link>https://acloudguru.com/blog/engineering/the-career-changing-art-of-reading-the-docs</link>
            <guid isPermaLink="false">hacker-news-small-sites-25989676</guid>
            <pubDate>Mon, 01 Feb 2021 15:51:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Generation X will save the web]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25989659">thread link</a>) | @isolli
<br/>
February 1, 2021 | https://webdevlaw.uk/2021/01/30/why-generation-x-will-save-the-web/ | <a href="https://web.archive.org/web/*/https://webdevlaw.uk/2021/01/30/why-generation-x-will-save-the-web/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<p>I like to make things as difficult for myself as possible, so first, I decided to become an independent-minded female immigrant in a parochial and patriarchal nation; then, when that got boring, I decided to become a woman in tech, where I found myself giving conference talks to rooms of professionals who could, technically and biologically, be my grown adult children.</p>

<p><span>T</span>hen, when that got boring, I pivoted out of code tech to policy tech, where I now find myself in much more forgiving company. Which is to say, for the first time since my non-tech career, I work alongside and in partnership with other Gen Xers.</p>
<p><em>Insert any number of Buzzfeed listicles here about what it’s like to be a GenXer in tech: we learned on floppies and dialup; we coded out of print magazines; we sowed our teenage wild oats on the parental tether of nothing more than a coin in a pay phone; we lived entire years of our student lives without a single photograph being taken of us; we navigated 9/11 on dumb cell phones which had antennas; we now live datafied existences, raising datafied children attending datafied virtual schools, in a world where everything we were raised to believe would sort us for life turned out to be boomer bullshit.</em></p>
<p>All of those formative experiences give us (cough) fortysomethings a perspective on the internet which the boomers who birthed us lack, and which the millenials who followed us will never know.</p>
<p>In fact, we’ve gotten a lot of mileage out of the trope of the internet being threatened by elderly politicians who don’t understand it, or us. And that trope, for the most part, is as true as it ever was.</p>
<p>I can count on one hand the number of boomer-aged Parliamentarians in my network who well and truly understand the internet and its culture. They’re good folks who have my time, anytime. The rest, sadly, have more in common with the editorial board of the now-unreadable Glasgow broadsheet which issues weekly diatribes against the internet and all those who sail in her: every word steeped in all the offended sense of entitlement that bitter old men can muster, every rant beating the same dead horse against an internet which took away the newspaper readership that should, in their opinions, be hanging on every word that comes out of their privileged white Scottish male mouths.</p>
<p>So goes it for lawmakers, who – by nature and by privilege – have been insulated from the social and economic changes which necessitated the shift from the web as a geek hobby to the web as democratised culture. The ones who legislate aginst the web as if trying to restore an old world which existed before it, a world which only ever benefited people who looked and sounded like them.</p>
<p>Those lawmakers were who I expected to spend most of my time dealing with after my full-time pivot to policy.</p>
<p>The reality has been a lot more mind-blowing to comprehend than that.</p>
<p>Brace yourself.</p>
<p>When I was in my early twenties, in the late 90s and early 00s, running work missions across downtown Washington DC – pop into the Capitol complex here, run a folder to the White House there, drop off something for the Secretary of State on a long lunch break – everyone I encountered looked like me. The same age, the same countenance, the same Scully red hair (hey, it worked on me). Government may have been directed by professional politicians, but its actual daily mechanics were run by kids just out of university who had all the energy in the world and nothing and no one holding them down.</p>
<p>That’s universal, and it hasn’t changed. Government and policy – the mechanics and grunt work, not the media showmanship – are powered by an army of hard-working, very young people who have all of the academic knowledge and very little of the practical experience. Those young folks, now, in 2021, who were in nappies when I was on the Hill, now run whatever corridors of power they (virtually) travel through, in professional support of those older politicians.</p>
<p>And it’s these young professionals – <em>not the boomer career politicians</em> – who are setting the tone of internet policy.</p>
<p>And here’s the thing.</p>
<p>We – the GenXers – think of the internet as the open web. The land of dialup telnet Unix systems, the days of table layout, the days of dot com, the days of early tech startups, the days of the internet as a connector, the days of the internet as a business opportunity, the days of the internet as a path to social justice and revolutions, the days of the internet as a light in the darkness. That’s all we have ever known.</p>
<p>Today’s policy facilitators – the millenials – think of the internet as MySpace and Facebook. The closed web. The land of always-on broadband and wifi, the days of content management systems, the days of tech bros, the days of the internet as a divider, the days of the internet as an acquisition for the giants, the days of the internet as a path to radicalisation and hatred, the days of the internet as petrol on a spark. That is all they have ever known.</p>
<p>And that is what they draft policy briefings, proposals, and legislation against.</p>
<p>Laws on freedom of speech. Laws on privacy. Laws on encryption. Laws on private surveillance. Laws on state surveillance.</p>
<p>The truths I held to be self-evident are things they have never known.</p>
<p>And, politically, they are in the driving seat. They are running the show.</p>
<p><em>Not me. Not the old folks. Them.</em></p>
<p>Just like I was, a long time ago, with my Scully hair, in my Unix dialup world, a world before the TV signal briefly went out because the antenna which controlled the TV signal was on top of the tower with the plane-shaped hole in it, the hole which turned one of my university classmates into a centimetre-long fragment of a finger recovered 18 months later.</p>
<p>Today’s young tech policy professionals are are, quite rightfully, responding to the only internet in the only world they have ever known. The awful one. The one where the internet <em>was and is</em> a handful of billion-pound companies. The one where the internet has only ever been petrol on a fire. The one where the internet has been essential infrastructure like water and heat, not a thing you had to request and master. The closed internet made for them. Not the open internet I got to make.</p>
<p>So if you think that the biggest threat to encryption is elderly politicians who still need their secretaries to print out emails for them, it’s time you found yourself in a meeting with someone under the age of 30 who is going to war against encryption because <em>he</em> has never needed encryption in his life.</p>
<p>If you think that the biggest threat to internet freedom is old white men who hate the internet because it does not allow them to attack anyone who does not look or sound like them, it’s time you found yourself in a meeting with someone under the age of 30 who is unabashedly in favour of mandatory identity verification for all users of the internet to protect people who look and sound like her.</p>
<p>And if you think that the biggest threat to freedom of speech on the open web is a tech billionaire in California, it’s time you found yourself in a meeting with someone under the age of 30 who sees a legislative victory against online freedom of speech, cloaked in the mantle of a victory against the tech billionaire, as a useful stepping stone to his political ambitions.</p>
<p>Those old Thatcherites still in politics, the elderly dames in the Lords, the newspaper editors with the offended senses of entitlement, they can whinge all they want about how the internet has changed the world they knew. And you can continue to waste your time on them, and their tropes, if it makes you feel better about yourself.</p>
<p>But political power, now, rests in the hands of young professionals who are – <em>rightfully – </em>legislating to change the only internet they have ever known.</p>
<p>The shitty corporate one.</p>
<p>The open web we let slip through our fingers.</p>
<p>And maybe, just maybe, the best things standing in their way of their spite and their avarice and their political aspirations are the Gen X fortysomethings who saw something better about the open web, and comprehended what was on their screens in a way that nothing has ever touched them since, and still believe in what the open web can be, and understand where things went wrong, and have an idea of how to put things right, and know how to create and use and fork the tools to make it so, and know the north stars they navigate home by, and have never, ever forgotten them, and who need a little bit of reminding, in chaotic times, of what it was like to telnet into a blank screen which contained the entire world.</p>
					</div></div>]]>
            </description>
            <link>https://webdevlaw.uk/2021/01/30/why-generation-x-will-save-the-web/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25989659</guid>
            <pubDate>Mon, 01 Feb 2021 15:49:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reinforcement Learning at Facebook]]>
            </title>
            <description>
<![CDATA[
Score 103 | Comments 27 (<a href="https://news.ycombinator.com/item?id=25989578">thread link</a>) | @agbell
<br/>
February 1, 2021 | https://corecursive.com/061-reinforcement-learning/ | <a href="https://web.archive.org/web/*/https://corecursive.com/061-reinforcement-learning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><i>Note: This podcast is designed to be heard. If you are able, we strongly encourage you to listen to the
audio, which includes emphasis that’s not on the page</i></p><div>
<h2 id="intro"><strong>Intro</strong></h2>
<div>
<picture><source srcset="https://corecursive.com/assets/generated/061/wide-800-8fd4f2a27.webp 800w" type="image/webp"><source srcset="https://corecursive.com/assets/generated/061/wide-800-8fd4f2a27.png 800w" type="image/png"><img width="600px" src="https://corecursive.com/assets/generated/061/wide-800-8fd4f2a27.png" alt="Computer Repair"></picture>
</div>
<p><strong>Adam:</strong>
Hey, so before We get into it, why don’t you state your name and what you do?</p>
<p><strong>Jason:</strong>
My name is Jason Gauci. And yeah, I bring machine learning to billions of people.</p>
<p><strong>Adam:</strong>
Hello and welcome to CoRecursive, the stories behind the code, I’m Adam Gordon Bell. Jason has worked on YouTube recommendations. He was an early contributor to TensorFlow, the open source machine learning platform. His thesis work was cited by DeepMind. They were the people who beat all human players at Go, and that’s StarCraft, I think. And who knows what else?</p>
<p>If you ever wanted to learn about machine learning, you could do worse than have Jason teach you. But what I find so fascinating with Jason is he recognized this problem that was being solved the wrong way and set out to find a solution to it.</p>
<p>The problem was making recommendations, like on Amazon, people who bought this book might like that book. He didn’t exactly know how to solve the problem, but he knew it could be done better. So that’s the show today, Jason’s going to share his story, but you will eventually change the way Facebook works. And we’ll learn about reinforcement learning and neural nets, and just about the stress of pursuing research at a large company. It all started in 2006 when Jason was in grad school.</p>
<h2 id="phd-program"><strong>PHD Program</strong></h2>
<div>
<picture><source srcset="https://corecursive.com/assets/generated/061/computer-repair-800-660802488.webp 800w" type="image/webp"><source srcset="https://corecursive.com/assets/generated/061/computer-repair-800-660802488.jpg 800w" type="image/jpeg"><img width="400px" src="https://corecursive.com/assets/generated/061/computer-repair-800-660802488.jpg" alt="Computer Repair"></picture>
</div>
<p><strong>Jason:</strong>
Yeah, so I went to college, picked computer science, and I remember my parents found out a little strange. They said, “Oh, you could be a doctor or a lawyer or something, you have the brains for it.” And then at one point my dad thought it was kind of like going to school to be a TV repairman. And so he wasn’t really sure, he’s like, “Are you sure you really want to do this? Now I could just buy another TV or another computer if it breaks.” And to this day, I have to explain to people, I really don’t know how to fix computer. If this laptop broke right now, I’d just have to do the same thing my parents do and just go get another one, I have no idea.</p>
<h2 id="capture-the-flag"><strong>Capture The Flag</strong></h2>
<p><strong>Jason:</strong> But I had an option to do a Master’s, PhD hybrid or basically do it all in one shot. And after two years, if I wanted to call it quits, then I would get the Master’s degree. Yeah, at the time I thought I will just do the Master’s, I didn’t really plan on getting a PhD. But actually the very last class that I took in my Master’s was a class called neuro evolution, which was all about trying to solve problems through neural networks and through evolutionary computation.</p>
<p>So America Online had this capture the flag game for free. And I remember I downloaded it on a 56K modem, it took forever. And it was basically like a turn-based capture the flag where you played as one person, and there was a friendly AI for the other three players, and then there was four player enemy AI, and you’re trying to capture the flag. And if the enemy touched you, you’re in jail, but the friendly AI could bail you out of jail.</p>
<p><strong>Adam:</strong>
I think I played this. Do you get to see more and more of the ground as you travel?</p>
<p><strong>Jason:</strong>
Yeah, that’s right. Yeah. Yeah. Do you remember the name of it?</p>

<p><strong>Adam:</strong>
So the game is called Capture the Flag. If you’ve not played it, you view a large field with trees in it from overhead, and you can only see where your players have been, there’s a fog of war like in StarCraft. Except it’s turn-based, you move a certain number of moves and then your players freeze there, and the computer gets to take its turn and move its players.</p>
<h2 id="what-is-a-neural-net"><strong>What Is a Neural Net?</strong></h2>
<div>
<picture><source srcset="https://corecursive.com/assets/generated/061/nn-774-55bf335d9.webp 774w" type="image/webp"><source srcset="https://corecursive.com/assets/generated/061/nn-774-55bf335d9.png 774w" type="image/png"><img width="800px" src="https://corecursive.com/assets/generated/061/nn-774-55bf335d9.png" alt="Capture The Flag"></picture>
</div>
<p><strong>Jason:</strong>
But for my neuro evolution course, my final project, I recreated this game, capture the flag. And then I built an AI for it using neuro evolution. And so just to unpack that, neural networks are effectively like function approximators that are inspired by the way the brain works. And so if you imagine graphing a function on your calculator, I’m sure everyone’s done this on their TI 85. You can punch in Y equals X squared and it’ll draw a little parabola on your TI 85 or whatever the calculator is nowadays. And so what a neural network will do is it will look at a lot of data and it can represent almost any function.</p>
<p><strong>Adam:</strong>
So if it’s your original graph thing, it’s like telling it X is two, Y is three. You’re feeding it all these pairs.</p>
<p><strong>Jason:</strong>
Exactly. Yep.</p>
<p><strong>Adam:</strong>
Memorizes them.</p>
<p><strong>Jason:</strong>
Yep. But because there’s contradictions and there’s noise in the data and all of that, you won’t tell it exactly, force it to be Y is three when X is three. But it’s a hint. You say, “Hey, when X is three, Y’s probably three.” So if you’re not there, get a little bit closer to there. And you do this over and over again for so many different Xs that you end up with some shape that won’t pass through every point, it’s usually impossible, but it will get close to a lot of the points.</p>
<h2 id="where-it-fails">Where It Fails</h2>
<p><strong>Adam:</strong>
This is basically back propagation. It’s a form of supervised learning. You’re training the neural net by supervising it and telling it when it gets the wrong answer, what it should have gotten instead. And to do this, you need to know what the right answer is so that you can train it.</p>
<p><strong>Jason:</strong>
And so that works great to when you have a person going and telling you the perfect answer or the right answer. But for puzzles and games, for example, you don’t have that. So look at Go, to this day, people haven’t found the perfect Go game, a Go game for people who are playing perfectly. And so you don’t have that. And so you have to do something different, you have to learn from experience. So you just say, “Look, this Go game, that’s a really good move. That’s better than any move we’ve ever seen at this point in the game.” It doesn’t mean it’s the best, it doesn’t mean that your goal should be to always make that move, but it’s really good.</p>
<p>A simple way to do that is have a neural network and have it play a lot of Go, and then make a subtle change to it, and have it play a lot of Go again. And then say, “Okay, did that change make this player win more games?”</p>

<p>If it did, then you keep the change. And if it didn’t, then you throw it away. And so if you do this enough times, you will end up in what we call a local optimum. In other words, you’re making these small changes, you’re picking all the changes that make their Go player better, and eventually you just can’t find a small change that makes the player better. And so you could think of evolutionary computation at a high level as doing something like that, but it’s doing it a really large scale.</p>
<p>So maybe you have a thousand small changes and 500 of them make the player better. And you can adapt all 500 of those different players and the existing players, you can take all 501 of those players and make a player that’s step-wise, that’s better in a big way. And you would just keep doing that.</p>
<p><strong>Adam:</strong>
So this is what Jason learned in his neuro evolution class. He would create all these generations of players, which had random changes, and like evolution, have them play capture the flags against each other, slowly breeding better and better players.</p>
<h2 id="jason-watches-his-creation"><strong>Jason Watches His Creation</strong></h2>
<p><strong>Adam:</strong>
Was there a moment where you tested out your algorithm? Did you try to play it and capture the flag?</p>
<p><strong>Jason:</strong>
Yeah, the real aha moment was, having this God’s eye view without the fog of war, because I was just an observer, and watching the AI. And specifically watching this almost like Wolfpack behavior, where three players would surround a player and trap them. Just seeing that thing that you’ve seen in nature just emerge organically, that to me was amazing.</p>
<p>That was unbelievable.</p>
<p>When I saw all the players converge and capture and do this methodical thing and then take the flag. And even, I think at one point two of them had been captured, and so the other two just decided to go for the flag and just forget about any strategy and just go for broke.</p>
<p><strong>Adam:</strong>
Did you watch it and anthropomorphize? Did you cheer for one team?</p>
<p><strong>Jason:</strong>
Yeah. Yeah. Yeah, I did. Naturally, you don’t want to cheer for the underdog. So yeah, you would see this scenario play out where they would chase after one person, even though there was four of them and only two of the other team, they would chase after one and the other one would get the flag.</p>
<p><strong>Adam:</strong>
I didn’t follow the strategy. One runs, and then…</p>
<p><strong>Jason:</strong>
Yeah. So one would run and the other four would all chase after that one. And then the second one would go and get the flag and win.</p>
<p><strong>Adam:</strong>
It’s like a decoy.</p>
<p><strong>Jason:</strong>
Yeah, but it would only happen when the AI was this advantaged. So the way it worked was there’s four players, so there’s a bunch of sensory information that was just repeated four times to make the input of the network. And I guess even though it’s playing against itself, it learned that when two of those inputs are completely shut off, which is what happened when they were captured, to then execute this hail Mary strategy. And yeah, it was just super fun to watch that play out. And I would remember just sitting in the lab cheering for this one person and they would try to come back. In your head, it was hard to know, because it was a big grid, can they get back quick enough to catch this person? So it’d be pretty suspenseful.</p>

<p>And just seeing all of that, just all encoded in this network, neural, excitation back prop and all these things for understanding what a neural network is doing, all this stuff hadn’t been invented yet. So it was just a black box and it was just magic. You would run it on the university cluster, who knows what it would do, you would get it back a few days later and you would just see all this amazing emergent behavior. That to me just really lit the spark.</p>
<p>And so I had already accepted a job with the intention of just getting a Master’s and leaving because I just didn’t see anything that inspired me. But right there at the 11th hour, I took this course. And I said, “This is amazing.” …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://corecursive.com/061-reinforcement-learning/">https://corecursive.com/061-reinforcement-learning/</a></em></p>]]>
            </description>
            <link>https://corecursive.com/061-reinforcement-learning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25989578</guid>
            <pubDate>Mon, 01 Feb 2021 15:39:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Reshaped Mac Experience]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25989450">thread link</a>) | @bluedino
<br/>
February 1, 2021 | http://morrick.me/archives/9150 | <a href="https://web.archive.org/web/*/http://morrick.me/archives/9150">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<p>Yesterday, a short <a href="https://twitter.com/lapcatsoftware/status/1355514848717791234">Twitter thread</a> by the excellent <a href="https://lapcatsoftware.com/articles/">Jeff Johnson</a> caught my eye. Since he often deletes past tweets, I’ll quote the relevant ones here (emphasis mine):</p>
<blockquote><p><strong>The selling point of the Macintosh was never the hardware, it was the user interface. So if the selling point now is the hardware, that’s a damning indictment of the current user interface.</strong></p>

<p><strong>I cannot emphasize enough how everyone seems to have lowered their standards with regard to the user interface.</strong> The “<a href="https://en.wikipedia.org/wiki/Overton_window">Overton window</a>” has moved. The Overton window now has rounded rects.</p>

<p>We’ve gone from “insanely great” and “It just works” to “Catalyst is good enough for most people.”</p>
<p>That’s fucking BS, and I won’t tolerate it.</p>

<p>Windows is “good enough for most people”. That’s why Windows has a 90% market share. Why should we aspire to that level, shouldn’t we have much higher aspirations? Mac is a niche. “Most people” are not even using Macs, so the majority is not even relevant. Mac is a premium brand.</p>

<p>The way I see it, the Mac now is merely milking the brand reputation and loyalty it previously built. That Jobs previously built. But neither Cook nor the current Mac deserves that reputation or loyalty.</p>

<p>Steve Jobs wasn’t an engineer. Not a hardware engineer, not a software engineer. At Apple, his role was as “proxy” for the&nbsp;users.</p>
<p>Apple no longer has a proxy for the users. Tim Cook is a proxy for the shareholders, nothing more.</p></blockquote>
<p>Jeff himself says that this criticism is hardly new, that these are things he already pointed out “a thousand times, to no effect”. While I am in no position to affect Apple or Mac development, this short Twitter rant had the effect of reminding me of something I, too, believe in; something I myself should emphasise more frequently. It’s those first two tweets I’ve quoted above.</p>
<p>As someone who still puts vintage Macs and older computers and devices to good use, the Mac’s user interface and user experience are in large part what still makes using 15–20-year-old machines enjoyable. This, by the way, also applies to other products of course. It’s thanks to well-designed user interfaces that we enjoy driving a classic car, or shooting with a 50-year-old film camera, or listening to vinyl records on a 40-year-old record-player and hi-fi stereo.</p>
<p>A couple of weeks ago I was on a group videochat with some friends and when I said that, frankly, using my 12-inch PowerBook G4 (2003) with Mac OS X 10.5 Leopard was more enjoyable than using my 13-inch retina MacBook Pro (2015) with Mac OS 11 Big Sur, the common reaction was that I was just being ‘nostalgic’; that surely my MacBook Pro was the better choice because it is orders of magnitude faster, with a ‘more modern’ OS, and that the sum of those parts was a better Mac experience. That I should ‘be rational’ and accept that.</p>
<p>Here, bringing up nostalgia is missing the point. And the point is that an admittedly faster hardware plus a purportedly ‘more modern’ operating system <em>do not necessarily</em> equal a better Mac experience. It’s interesting that my friends’ reaction was not to ask me <em>why</em> I was finding using an 18-year-old machine more enjoyable than an up-to-date Mac, but to promptly want to readjust my enjoyment, implying that there was something ‘wrong’ with&nbsp;it.</p>
<p>I’m finding that many people not only have lowered their standards with regard to the user interface, but more and more often when I bring up the subject, they seem to consider it a somewhat secondary aspect, something that’s only good for ‘geek talk’. The same kind of amused reaction laymen have to wine or coffee connoisseurs when they describe flavours and characteristics using specific lingo. Something that makes sense only to wine or coffee geeks but has little to no meaning or impact for the regular person.</p>
<p>The problem is that if an increasing number of people start viewing user interface design as an afterthought, or something that isn’t fundamental to the design of a product or experience — it’s all just ‘geek talk’ — then there is a reduced incentive to care about it on the part of the maker of the product. It’s more like a vicious circle, really; if Apple software’s quality declines but only a bunch of professional users and enthusiasts point that out, then Apple isn’t particularly incentivised to do a better job at it — the “good enough for most people” is really a dangerous, self-indulgent excuse. And in turn most people are fine with it, and in turn Apple think they’re on a ‘good’ path, and so&nbsp;forth.</p>
<p>At the very end of my piece <a href="http://morrick.me/archives/9141"><em> What about the M1 Macs?</em></a>, I&nbsp;wrote:</p>
<blockquote><p>They’re unbelievably good machines, and everything that is genuinely good about them and future Apple Silicon-based Macs — sheer performance, astounding power-efficiency, and great backward compatibility with Intel software thanks to Rosetta 2 — will also allow Apple to get away with a lot of things with regard to platform control, design decisions, and so&nbsp;forth.</p></blockquote>
<p>If you take a look at Jason Snell’s <a href="https://sixcolors.com/post/2021/01/apple-in-2020-the-six-colors-report-card/"><em>Apple in 2020: The Six Colors report card</em></a>, the Mac scored very good points overall, 4.7 out of 5, with a year-over-year increment of 1.1 points. The main reason has been of course the M1 Macs and Apple Silicon. Don’t get me wrong, Apple Silicon <em>is</em> groundbreaking, and Rosetta 2 is really an incredible performer on the software side. But what I contend is that a leap in hardware architecture and performance doesn’t necessarily mean that suddenly all is fine with the Mac as a platform or as an experience.</p>
<p>The Mac’s user interface is undergoing plastic surgery by the hand of surgeons who have studied on iOS books. The result is pretty much the same as when you see a favourite celebrity after a procedure. They look ‘younger’ but there’s also something weird about their appearance. Their traits have changed a bit. In certain cases you almost fail to recognise the person at first glance.</p>
<p>Similarly, the Mac experience today feels disjointed. The hardware has unquestionably improved with the introduction of Apple Silicon, and yes, it’s something worth celebrating and it’s something worth praising. On the other hand, the software that drives this hardware is a bit of a paradox: Big Sur and Apple Silicon Macs fit and work together well from a technical, architectural standpoint. From a user interface standpoint, however, Big Sur embodies what I’ve been fearing in recent years — a progressive iOS-ification of Mac OS. Big Sur provides a general user experience that is the least Mac-like in the history of the Mac. Going through Big Sur’s user interface with a fine-tooth comb reveals arbitrary design decisions that prioritise looks over function, and therefore reflect an un-learning of tried-and-true user interface and usability mechanics that used to make for a seamless, thoughtful, enjoyable Mac experience.</p>
<p>iOS was born as a ‘spinoff’ of Mac OS X, a sort of Lite version aimed at mobile devices like the iPhone and the iPod touch. The two platforms have maintained their separate paths and trajectories for years, and for a while using a Mac and an iPhone (or iPad) felt like having the best experience of each world. Then Apple became obsessed with thoughts of convergence, and features, UI ideas, paradigms, started bleeding through both platforms and in turn the respective experiences have become less clear-cut over time, with the software not fully capable of bringing out all that hardware power and potential.</p>
<p>This convergence will continue, of course, with Macs becoming more and more like ‘senior iOS devices’ from a UI and user experience standpoint. It seems clear to me that Apple is prioritising ecosystem experience because, let’s be honest, having a unified ‘operating system core’ underlying all platforms means having fewer framework-specific headaches and probably a faster, streamlined process when deploying new features. But this loss of differentiation is especially detrimental to Mac OS, which is being reduced to the lowest common denominator and loses an increasing amount of user interface ideas and conventions that were central to its superior user experience and ease of&nbsp;use.</p>
<p>I’m not annoyed because I see pieces of UI history fading away. I’m annoyed because I see pieces of <em>good</em> UI design fading away and being replaced by decisions that are puzzling and arbitrary, or the product of a trial-and-error process, rather than a meaningful, purposeful design.</p>
<p>You want an example that I find particularly glaring? Big Sur’s UI features a general increase of space between elements — icons, menus, labels, toolbars, sidebars, pretty much everywhere. On the surface it doesn’t seem like a bad decision. If you zoom in on certain parts of the user interface, you could say that more space between elements means that things looks cleaner, airier, sleeker.</p>
<p>But you’re looking at it on a 27-inch retina display. What about a display half that size? What about an 11-inch, non-retina display, like the one of the older 2013–2015 MacBook Airs that can be updated to Big Sur? It’s less pretty.</p>
<p><a href="https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png"><img loading="lazy" src="https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?resize=960%2C600" alt="" width="960" height="600" srcset="https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?w=2560 2560w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?resize=260%2C163 260w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?resize=640%2C400 640w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?resize=768%2C480 768w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?resize=1536%2C960 1536w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?resize=2048%2C1280 2048w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?resize=1194%2C746 1194w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?w=1920 1920w" sizes="(max-width: 960px) 100vw, 960px" data-recalc-dims="1"></a></p>
<p>I usually work with a lot of app windows and Finder windows, but when I’m using my 13-inch retina MacBook Pro with Big Sur, the workspace constantly feels cramped, while on the other hand I have no problems using High Sierra on my 11-inch MacBook Air. Sometimes it feels like looking at a zoomed-in interface. That increased space between elements becomes less of a good idea because it doesn’t scale gracefully when the overall screen real estate is reduced. It becomes an interference. Before installing Big Sur, the amount of icons on the right of the menu bar had never really been a concern. Now, the simple addition of a couple of third-party apps like Dropbox and iStat Menus — both essential for me — is enough to make that menu bar look crowded. (And thankfully Apple has been reducing the space between menu icons, because in the first Big Sur betas icon padding was so bad I had to remove a few icons and use Control Centre to check on their status).</p>
<p>This, like other UI design decisions in Big Sur, feels like …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://morrick.me/archives/9150">http://morrick.me/archives/9150</a></em></p>]]>
            </description>
            <link>http://morrick.me/archives/9150</link>
            <guid isPermaLink="false">hacker-news-small-sites-25989450</guid>
            <pubDate>Mon, 01 Feb 2021 15:27:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Emacs: From catching up to getting ahead]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25989422">thread link</a>) | @mpereira
<br/>
February 1, 2021 | https://www.murilopereira.com/emacs-from-catching-up-to-getting-ahead/ | <a href="https://web.archive.org/web/*/https://www.murilopereira.com/emacs-from-catching-up-to-getting-ahead/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>What does Emacs need for us to someday run M-x neuralink-mode and evaluate Lisp in the brain?</p><div><p>I started using <a href="https://github.com/mpereira/.emacs.d/commit/30024f963ed794ec3a4c41229dbd4fab81f9b912">Emacs</a> almost exactly four years ago, after almost a decade
of <a href="https://github.com/mpereira/.vim">Vim</a>. I made the switch cold turkey. I vividly remember being <em>extremely</em>
frustrated by unbearable slowness while editing a Clojure file at work.
With no sane way of debugging it, just moving the cursor up and down would
result in so much lag that I had to step away from the computer to breathe
for a while. When I came back I quit Vim (I knew how at that point), opened
Emacs, and started building my configuration.</p><p>More recently, I’ve been very put off by the performance and stability (or
lack thereof) of building large scale software via Tramp. This has been
sufficient to have me looking out again. On a whim, I installed VSCode for
the first time and tried its “remote development” capabilities and holy
smokes are they good. Getting up and running was trivial and the
performance was great. Saving files was snappy and LSP worked out of the
box. What a different experience from my carefully-put-together,
half-working, slow Emacs setup.</p><p>My common denominator for rage-quitting software seems to be
consistent: <i>bad performance</i>.</p><p>There has recently been more discussion than usual regarding “modernizing”
Emacs, by making keybindings more consistent with other applications and
using more attractive color schemes and visuals, with the end goal of
attracting more users and by extension more contributors.</p><p>In my view improving these aspects of user experience wouldn’t hurt. The
way I see it, though, is that for Emacs to attract more users it needs to
be objectively better than the alternatives. And the way to do it is for
Emacs to become <em>even more</em> like Emacs.</p><p>I see Emacs as being fundamentally two things: a programmable runtime,
and a beacon for free software. I'm talking more about the former.</p><p>It needs to be a <em>more</em> robust, <em>more</em> efficient, and <em>more</em> integrated
platform with a <em>more</em> powerful extension language, to empower its users to
build their own environment.</p><p>Getting LSP integrated <em>pervasively</em> in Emacs in a way that it reliably
<em>just works</em> and performs well out of the box, would go a long way towards
making Emacs more attractive not just to new users, but to existing ones
too. Imagine an experience similar to VSCode’s:</p><ol><li>Open Emacs for the first time</li><li>Open a source code file</li><li>Emacs asks if you want it to configure itself for the programming
language of that source file</li><li>Saying “yes” automatically sets up Emacs to have a modern programming
environment for that programming language with smart code completion,
navigation, and refactoring, rich hover information, highlighting,
automatic formatting, snippets, etc. Maybe even open a side window with
a buffer with a short “getting started” tutorial showing the available
keybindings.</li></ol><p>Given enough users, opinionated community-built Emacs “distributions” like
Spacemacs, Doom, and Prelude will do the job of making it easier for
newcomers to get started with typical contemporary tasks: building software
with popular programming languages, writing documents, managing machines,
etc.</p><p>Building and maintaining these “distributions” also becomes much easier
given a more robust, more efficient, and more integrated platform with a
more powerful extension language.</p><p>Having a <a href="https://blog.polaris64.net/post/could-emacs-have-a-set-up-wizard/">wizard</a> showing up in new Emacs installations might be a great
low-hanging fruit way of making Emacs more accessible. Assuming buy-in from
core maintainers, the wizard could even directly reference popular Emacs
“distributions” like the ones mentioned above, so that new users can
kickstart their lives in Emacs.</p><p>The way to attract contributors can also be <em>stated</em> simply: directly improve
the contribution process.</p><p>Easier said than done.</p><p><a href="https://www.youtube.com/watch?v=VADudzQGvU8">Many</a> have created their Emacs <a href="https://www.jwz.org/doc/xemacs-wishlist.html">wishlists</a>. This is mine:</p><ol><li>Improved single-core efficiency</li><li>Improved display efficiency and rendering engine</li><li>Leveraging preemptive parallelism</li><li>Emacs Lisp improvements</li><li>Enhanced stability</li><li>Dealing with non-text</li><li>Improved contribution and development process</li></ol><p>Let’s get into it.</p><h2 id="1-dot-improved-single-core-efficiency">1. Improved single-core efficiency</h2><p>There are two dimensions to this:</p><ul><li>garbage collection efficiency</li><li>code execution efficiency</li></ul><p>For the past one and a half years, <a href="https://twitter.com/Koral%5F001">Andrea Corallo</a>, a compiler engineer,
has been <a href="https://akrl.sdf.org/gccemacs.html">working</a> on adding native compilation capabilities to the Emacs
Lisp interpreter. His work is available in a branch in the official Emacs
repository. Folks have been trying it out, and according to the reports
I’m hearing, the results are staggeringly positive. I am <em>very</em> excited
about Andrea’s work, which seems to bring enough improvement to the “code
execution speed” side of the equation to make it a non-issue for now.</p><p>Andrea’s work will also allow for more of Emacs to be implemented in Emacs
Lisp itself (instead of C), which is what most contributors are used to.
This is a great win for maintainability and extensibility: incrementally
having more and more of Emacs be implemented in the language with which
it’s extended.</p><p>The garbage collector is still in much need of improvement. Many resort to
hacks to ameliorate frequent and sometimes long pauses that seem to be
unavoidable while working on large git repositories, fast-scrolling
font-locked Eshell buffers, displaying dynamically updating child frames,
navigating big Org files, and many other tasks.</p><p><span>Also, try this out:</span> <code>(setq garbage-collection-messages t)</code></p><h2 id="2-dot-improved-display-efficiency-and-rendering-engine">2. Improved display efficiency and rendering engine</h2><p>The display implementation in Emacs core is… less than ideal.</p><blockquote><p>GNU Emacs is an old-school C program emulating a 1980s Symbolics Lisp
Machine emulating an old-fashioned Motif-style Xt toolkit emulating a
1970s text terminal emulating a 1960s teletype. Compiling Emacs is a
challenge. Adding modern rendering features to the redisplay engine is a
miracle.</p><p>— <a href="https://www.facebook.com/notes/daniel-colascione/buttery-smooth-emacs/10155313440066102/">Daniel Colascione in “Buttery Smooth Emacs” (2016)</a></p></blockquote><p>It would be great if Emacs did like Neovim and decoupled the editor
runtime from the display engine. This would make it possible for the
community to build powerful <a href="https://neovim.io/news/2020/10/#guis">GUIs</a> without having to change <a href="https://raw.githubusercontent.com/emacs-mirror/emacs/master/src/xdisp.c">Emacs core</a>,
possibly <a href="https://lwn.net/ml/emacs-devel/CAO2hHWbUmgirn1gJ4OGbRghhCkOPcEsL=moc82Q-6QO+C=189Q@mail.gmail.com/">using technology</a> <a href="https://lwn.net/ml/emacs-devel/E1jPGhC-0003i1-W4@fencepost.gnu.org/">not fully sanctioned</a> by core maintainers.</p><p>Take a look at the screenshots of these Neovim GUIs:</p><ul><li><a href="https://github.com/Kethku/neovide">neovide</a></li><li><a href="https://github.com/smolck/uivonim">uivonim</a></li></ul><p>They’re powerful, look great, perform well, and more importantly, are
based on industry standard, cross-platform graphics APIs (Vulkan and WebGL
respectively) that get lots of personpower contributions from companies
and individuals alike.</p><p>The <a href="https://www.patreon.com/posts/40303878">Onivim</a> and <a href="https://github.com/xi-editor/xi-editor">Xi</a> text editors could also be sources of inspiration:</p><ul><li>Separating the core runtime from the user interface</li><li><a href="https://en.wikipedia.org/wiki/Rope%5F(data%5Fstructure)">Ropes</a> for faster incremental changes and parallelization of text
operations</li><li>Game-like drawing pipelines</li></ul><h2 id="3-dot-leveraging-preemptive-parallelism">3. Leveraging preemptive parallelism</h2><p>Emacs does not support parallel code execution via multi-core processing.
Code execution happening on any buffer will freeze the whole program,
preventing not only user interaction but other cooperative threads of
execution from making progress as well.</p><p>Adding parallelism to Emacs in a way that automatically makes existing
code run in parallel is about as close to impossible as it can get. What
would be more feasible is including new primitives for parallel execution
that new code could leverage, to build more powerful extensions to Emacs.</p><p><a href="https://github.com/emacs-ng/emacs-ng">Emacs-ng</a> is a recent effort that implements just that: an additive layer
over Emacs that brings not only parallelism, but also asynchronous I/O
capabilities via an embedded <a href="https://deno.land/">Deno</a> runtime, and GPU-based rendering via
<a href="https://github.com/servo/webrender">WebRender</a>. I am <em>super</em> excited about the very fast progress from the folks
working on emacs-ng, and I think the project holds great promise for the
future of Emacs itself.</p><p>There also seems to be advances in the area of immutable data structures
that could be leveraged by the Emacs core, as seen in “<a href="https://public.sinusoid.es/misc/immer/immer-icfp17.pdf">Persistence for the
Masses: RRB-Vectors in a Systems Language</a>”. Persistent data structures
would make building thread-safe parallel code much easier.</p><h2 id="4-dot-enhanced-stability">4. Enhanced stability</h2><p>It is very easy to either freeze Emacs or cause it to run very slowly.
Multiple times a day I have to hit <code>C-g</code> incessantly to bring it back from
being frozen. When that fails, I am sometimes able to get it back with
<code>pkill -SIGUSR2 Emacs</code>. At least once per week I have to <code>pkill -9 Emacs</code>
because it turned completely unresponsive. I suspect doing more work
outside of the main thread might help with this?</p><p>There are many hacks to ameliorate issues caused by long lines, but
they’re still fundamentally there. Advancements in the “display efficiency
and rendering engine” effort would help with this too.</p><p>I recently tried a package that displays pretty icons on completion
prompts, and noticed that it made scrolling through candidates really
slow. Profiling showed that the package was creating thousands of <a href="https://www.gnu.org/software/emacs/manual/html%5Fnode/elisp/Idle-Timers.html">timers</a>,
which were somehow causing the issue. There are lots of cases like this,
where folks attempt to create something nice, but inevitably have to
resort to <a href="https://github.com/domtronn/all-the-icons.el/issues/113">hacks</a> to either achieve acceptable performance, or to be able to
implement the thing at all. Having a more robust/efficient/integrated core
with a more powerful extension language would help here.</p><p>Impressive efforts from folks like Lars Ingebrigtsen who routinely comes
in and <a href="https://lars.ingebrigtsen.no/2020/10/26/5x10/">obliterates 10% of all reported Emacs bugs</a> also have a sizable
impact. We users should follow the lead and do a better job not only
creating good bug reports but also dipping in our toes and helping out:
fixing bugs, writing tests, and documentation.</p><p>Yuan Fu recently wrote a <a href="https://archive.casouri.cat/note/2020/contributing-to-emacs/">nice guide</a> for contributing to Emacs.</p><h2 id="5-dot-emacs-lisp-improvements">5. Emacs Lisp improvements</h2><p>Emacs Lisp is a much better language than Vimscript. Unfortunately, that’s
not saying much. It’s not a particularly good Lisp and has lots of room
for improvement.</p><blockquote><p>For example, if you want to use a map, you have three choices: you can use
alists, plists or hash maps. There are no namespaces in Emacs Lisp, so for
each of the three data types you get a bunch of functions with weird
names. For alists get is <code>assoc</code> and set is <code>add-to-list</code>, for hash maps get
is <code>gethash</code> and set is <code>puthash</code>, for plists get is <code>plist-get</code> and set is
<code>plist-put.</code> For each of those types it …</p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.murilopereira.com/emacs-from-catching-up-to-getting-ahead/">https://www.murilopereira.com/emacs-from-catching-up-to-getting-ahead/</a></em></p>]]>
            </description>
            <link>https://www.murilopereira.com/emacs-from-catching-up-to-getting-ahead/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25989422</guid>
            <pubDate>Mon, 01 Feb 2021 15:24:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Robinhood's awful UX exacerbated the GameStop crisis]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25989369">thread link</a>) | @Signalvwhatsapp
<br/>
February 1, 2021 | https://builtformars.com/how-robinhood-handled-a-crisis/ | <a href="https://web.archive.org/web/*/https://builtformars.com/how-robinhood-handled-a-crisis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section data-id="ca3ca43" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">

<div>
<div>
<div data-id="ec20c55" data-element_type="column">
<div>
<div>
<div data-id="682e138" data-element_type="widget" data-widget_type="theme-post-content.default">
<div>
<div data-elementor-type="wp-post" data-elementor-id="11116" data-elementor-settings="[]">
<div>
<div>
<section data-id="00380cd" data-element_type="section">
<div>
<div>
<div data-id="73400e1" data-element_type="column">
<div>
<div>
<div data-id="c41ab36" data-element_type="widget" data-settings="{&quot;drop_cap&quot;:&quot;yes&quot;}" data-widget_type="text-editor.default">
<div>
<p>Last week Robinhood took unprecedented action and, without warning, temporarily restricted trading on immensely popular stocks like GameStop (GME).</p>
</div>
</div>
<div data-id="89fe3e7" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>The circumstances of these actions were controversial and upset millions of people.</p>
</div>
</div>
<div data-id="1ac2834" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>But this isn’t a hit piece, and my opinion of whether the steps Robinhood took were necessary, fair or illegal are irrelevant.</p>
</div>
</div>
<div data-id="e7928c9" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p>Instead, this provides a perfect example of <strong>why UX matters in a crisis</strong>.&nbsp;</p><p>…</p></div>
</div>
</div>
<div data-id="47c7425" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>In this instance, even the best user experience wouldn’t have stopped people from being upset, but would have acted as damage limitation.</p>
</div>
</div>
<div data-id="2c34603" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>As you’ll see, the total lack of context, explanation or empathy only fuelled the mob.</p>
</div>
</div>
<div data-id="8706992" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>So what can we learn from Robinhood’s actions / inactions?</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="3908660" data-element_type="section">
<div>
<div>
<div data-id="955ff27" data-element_type="column">
<div>
<div>
<div data-id="5795f5f" data-element_type="widget" data-widget_type="heading.default">
<p>
<h3>Summary (what Robinhood did):</h3> </p>
</div>
<section data-id="652f9f4" data-element_type="section">
<div>
<div>

<div data-id="5ed8e3a" data-element_type="column">
<div>
<div>
<div data-id="118ef6c" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>Removing GameStop from <strong>search results</strong>.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="87a1a79" data-element_type="section">
<div>
<div>

<div data-id="f3bb568" data-element_type="column">
<div>
<div>
<div data-id="a86c38b" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>Blocking people from <strong>buying</strong> GameStop shares.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="19bd816" data-element_type="section">
<div>
<div>

<div data-id="8836b54" data-element_type="column">
<div>
<div>
<div data-id="834b30b" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>Made<strong> fractional shares</strong>&nbsp;unavailable.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="1706663" data-element_type="section">
<div>
<div>

<div data-id="847c1f2" data-element_type="column">
<div>
<div>
<div data-id="763d542" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p><strong>Creating sell orders</strong> on your behalf.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="e727702" data-element_type="section">
<div>
<div>

<div data-id="bbf23ee" data-element_type="column">
<div>
<div>
<div data-id="e6be231" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>Failing to get <strong>statements</strong>.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="4c1c44c" data-element_type="section">

</section>
<section data-id="b8fbf65" data-element_type="section">
<div>
<div>
<div data-id="af60e8c" data-element_type="column">
<div>
<div>
<div data-id="ffa8b1d" data-element_type="widget" data-widget_type="heading.default">
<p>
<h3>1. Removing GameStop from search results</h3> </p>
</div>
<div data-id="6044e46" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>The first action that Robinhood took was to suddenly stop people from being able to purchase shares of GameStop.</p>
</div>
</div>
<div data-id="db89608" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>But they also decided to actually <strong>remove GameStop from any search results</strong>.</p>
</div>
</div>
<div data-id="d88ea55" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>This was an awful decision for a few reasons:</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="c969585" data-element_type="section">
<div>
<div>
<div data-id="749e793" data-element_type="column">
<div>
<div>
<section data-id="cc6160e" data-element_type="section">
<div>
<div>

<div data-id="2a438d3" data-element_type="column">
<div>
<div>
<div data-id="412b57c" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p><strong>1. Adds ambiguity</strong></p><p>People <em>knew</em> that GameStop <em>should</em> be there, so just removing it creates ambiguity. Is this a bug? Should they close the app and try again?</p></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="94a2eff" data-element_type="section">
<div>
<div>

<div data-id="ed13002" data-element_type="column">
<div>
<div>
<div data-id="4055d58" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p><b>2. Provides no&nbsp;explanation</b></p><p>By removing it entirely, you’ve not given any chance for the user to learn more about <em>why</em> they’re not seeing it.</p></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="d2f6f2f" data-element_type="section">
<div>
<div>

<div data-id="cb4b003" data-element_type="column">
<div>
<div>
<div data-id="36a01f2" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p><b>3. Adds suspicion</b></p><p>During a crisis, you want to calm your users down, not give them reasons to suspect you’re trying to mislead them.</p></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="2413447" data-element_type="section">
<div>
<div>
<div data-id="b2b6797" data-element_type="column">
<div>
<div>
<div data-id="7c394bd" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>But it didn’t have to be that way—this is what they should have done (right).</p>
</div>
</div>
<div data-id="57fbb73" data-element_type="widget" data-widget_type="image.default">
<div>
<p><img width="720" height="323" src="https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Hidingfromsearch-1-1024x460.jpg" alt="" srcset="https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Hidingfromsearch-1-1024x460.jpg 1024w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Hidingfromsearch-1-300x135.jpg 300w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Hidingfromsearch-1-768x345.jpg 768w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Hidingfromsearch-1-100x45.jpg 100w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Hidingfromsearch-1-700x315.jpg 700w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Hidingfromsearch-1.jpg 1500w" sizes="(max-width: 720px) 100vw, 720px"> </p>
</div>
</div>
<div data-id="9991d1b" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p>Great UX is about being definitive and clear. The <strong><em>absence</em></strong> of information is the opposite of that.</p><p>…</p></div>
</div>
</div>
<div data-id="93ce83a" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>How long would it have taken Robinhood to add a few sentences, and a link to an additional resource? 15 minutes?</p>
</div>
</div>
<div data-id="ff2ce13" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>And if they didn’t have time to write a full article explaining the situation, then they could have linked directly to a Twitter thread. Or, <em>literally anything</em> giving some context about this decision.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="9ab277b" data-element_type="section">
<div>
<div>
<div data-id="11164e6" data-element_type="column">
<div>
<div>
<div data-id="7c8c29e" data-element_type="widget" data-widget_type="heading.default">
<p>
<h3>2. Blocking people from buying GameStop shares</h3> </p>
</div>
<div data-id="914f37f" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>But, even though GameStop shares were hidden from the search results, it was still possible to get to the screen where you can normally buy and sell them.</p>
</div>
</div>
<div data-id="ed5a976" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>Which introduced another complexity: <strong>how should Robinhood stop people from buying the shares, while still allowing them to sell their shares</strong>?</p>
</div>
</div>

<div data-id="bc49f13" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>1: Disable the ‘buy’ button.</p>
</div>
</div>
<div data-id="c854a0e" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>2: Add an unspecific notice explaining that you can’t buy shares right now.</p>
</div>
</div>
<div data-id="7a3a6ce" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p>Robinhood’s users were missing out on what was being touted as the trade of a lifetime, and there’s not even an explanation why.</p><p>…</p></div>
</div>
</div>
<div data-id="d0c3060" data-element_type="widget" data-widget_type="image.default">
<div>
<p><img width="720" height="323" src="https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Block-from-buying-1024x460.jpg" alt="" srcset="https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Block-from-buying-1024x460.jpg 1024w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Block-from-buying-300x135.jpg 300w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Block-from-buying-768x345.jpg 768w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Block-from-buying-100x45.jpg 100w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Block-from-buying-700x315.jpg 700w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Block-from-buying.jpg 1500w" sizes="(max-width: 720px) 100vw, 720px"> </p>
</div>
</div>
<div data-id="8c13831" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>It wouldn’t have taken much to make the UX of this considerably better. Even just a link to an explanation would have helped.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="9c3a6d8" data-element_type="section">
<div>
<div>
<div data-id="c9e092b" data-element_type="column">
<div>
<div>
<div data-id="33475ac" data-element_type="widget" data-widget_type="heading.default">
<p>
<h3>3. Fractional shares are unavailable</h3> </p>
</div>
<div data-id="48c7676" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>After some time, Robinhood announced that they would allow people to purchase a limited number of these shares, this included <strong>not allowing people to purchase <em>part</em> of a share</strong>.</p>
</div>
</div>
<div data-id="a80c454" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>For context, Robinhood is renown for fractional investing. This allows you to invest a small amount of money in companies with a high share price, for example, one share of Amazon costs more than $3,000, but a Robinhood user could invest $300 for 1/10th of a share.</p>
</div>
</div>
<div data-id="72f4a48" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>This is the message they showed to people who tried buying a fraction of a share:</p>
</div>
</div>
<div data-id="57cafaf" data-element_type="widget" data-widget_type="image.default">
<div>
<p><img width="720" height="323" src="https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/FractionalShares-1024x460.jpg" alt="" srcset="https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/FractionalShares-1024x460.jpg 1024w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/FractionalShares-300x135.jpg 300w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/FractionalShares-768x345.jpg 768w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/FractionalShares-100x45.jpg 100w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/FractionalShares-700x315.jpg 700w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/FractionalShares.jpg 1500w" sizes="(max-width: 720px) 100vw, 720px"> </p>
</div>
</div>
<div data-id="021051e" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>There are a few nuances here worth pointing out:</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="c031c3e" data-element_type="section">
<div>
<div>
<div data-id="f789da0" data-element_type="column">
<div>
<div>
<section data-id="a82a513" data-element_type="section">
<div>
<div>

<div data-id="7510cee" data-element_type="column">
<div>
<div>
<div data-id="e2aea7f" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p><strong>1. Clarify that this restriction is <em>temporary</em></strong></p><p>Is Robinhood not facilitating fractional shares anymore? Will this feature come back? Is this related to the other restrictions?</p></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="410dd9a" data-element_type="section">
<div>
<div>

<div data-id="c239494" data-element_type="column">
<div>
<div>
<div data-id="07996bd" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p><b>2. Explain what “enough available” means</b></p><p>During this crisis there were many restrictions, including not being able to buy more than 3 shares. So is “<em>not enough</em>” related to the number of available shares you can buy until you reach that limit?</p></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="166c9fa" data-element_type="section">
<div>
<div>

<div data-id="500e290" data-element_type="column">
<div>
<div>
<div data-id="b815ddd" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p><b>3. Add an&nbsp;explanation</b></p><p>As we’ve demonstrated before, it’s important to give context and rationale behind a decision. <em>Why</em> did they have to take this step?</p></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="2533534" data-element_type="section">
<div>
<div>
<div data-id="166bbd4" data-element_type="column">
<div>
<div>
<div data-id="6a4adcb" data-element_type="widget" data-widget_type="heading.default">
<p>
<h3>4. Creating sell orders on your behalf</h3> </p>
</div>
<div data-id="e53e593" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>As the chaos unfolded, people started complaining that Robinhood were creating sell orders on their account, without their consent. Once these orders were placed, the user could not cancel them, and were instead shown an error message.</p>
</div>
</div>
<div data-id="de68357" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p>If this wasn’t bad enough, many people were complaining that the selling price was <em><strong>below</strong></em> market value, given how volatile the price was.</p><p>…</p></div>
</div>
</div>
<div data-id="91bd643" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>So, if there was ever an example of where a company <strong>needs to take an extra 5 minutes to really explain the situation</strong>, this is it.</p>
</div>
</div>
<div data-id="3ecd1a2" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>Yet instead, Robinhood users saw an error message—and to demonstrate how rushed this entire process was, they forgot to put a full stop at the end.</p>
</div>
</div>
<div data-id="8e3c4b5" data-element_type="widget" data-widget_type="image.default">
<div>
<p><img width="720" height="323" src="https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Soldforyou-1024x460.jpg" alt="" srcset="https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Soldforyou-1024x460.jpg 1024w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Soldforyou-300x135.jpg 300w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Soldforyou-768x345.jpg 768w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Soldforyou-100x45.jpg 100w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Soldforyou-700x315.jpg 700w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Soldforyou.jpg 1500w" sizes="(max-width: 720px) 100vw, 720px"> </p>
</div>
</div>
<div data-id="e630a3b" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>I’ve made a few important changes here:</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="4ee30a4" data-element_type="section">
<div>
<div>
<div data-id="2b6451d" data-element_type="column">
<div>
<div>
<section data-id="b1a285a" data-element_type="section">
<div>
<div>

<div data-id="c9e7b83" data-element_type="column">
<div>
<div>
<div data-id="3d74881" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p><strong>1. Change the title</strong></p><p>This isn’t an ‘error’, so labelling it as one feels misleading. Instead, be clear and tell the user <em>what’s happening</em>.</p></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="06de0be" data-element_type="section">
<div>
<div>

<div data-id="4474737" data-element_type="column">
<div>
<div>
<div data-id="e106a06" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p><b>2. Adding empathy</b></p><p>This isn’t just an inconvenience, it’s potentially costing the user a lot of money. Somehow, saying “we’re sorry” at the beginning just doesn’t cut it.</p></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="6ef3ff9" data-element_type="section">
<div>
<div>

<div data-id="2b24020" data-element_type="column">
<div>
<div>
<div data-id="24cf674" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p><b>3. Add an&nbsp;explanation</b></p><p>You probably saw this one coming—this is a necessity in this instance, and it’s easy to see why many people flocked to Twitter to complain.</p></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="833ae0a" data-element_type="section">
<div>
<div>
<div data-id="9aa0b5d" data-element_type="column">
<div>
<div>
<div data-id="da706b8" data-element_type="widget" data-widget_type="heading.default">
<p>
<h3>5. Failing to get statements</h3> </p>
</div>
<div data-id="2acabad" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>This controversy unravelled over a few days, and led many people vowing to leave Robinhood and take their portfolio elsewhere.</p>
</div>
</div>
<div data-id="e2cc62c" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>But there was a problem: other brokerages were asking for your existing portfolio statement to initiate a transfer, and for some people, Robinhood’s statement download function was broken.</p>
</div>
</div>
<div data-id="32d0c00" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>So lets look at—and improve—the error message they displayed when people were trying to download their statements:</p>
</div>
</div>
<div data-id="53a98c7" data-element_type="widget" data-widget_type="image.default">
<div>
<p><img width="720" height="323" src="https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Servererror-1024x460.jpg" alt="" srcset="https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Servererror-1024x460.jpg 1024w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Servererror-300x135.jpg 300w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Servererror-768x345.jpg 768w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Servererror-100x45.jpg 100w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Servererror-700x315.jpg 700w, https://428579-1344919-1-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2021/01/Servererror.jpg 1500w" sizes="(max-width: 720px) 100vw, 720px"> </p>
</div>
</div>
<div data-id="8bd27d4" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>Unlike the other examples above, this error message doesn’t require more <strong><em>context</em></strong>, but it would have benefitted from suggesting an alternative step (e.g., emailing their customer support).</p>
</div>
</div>
<div data-id="1589ced" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p>This is a task that could be completed manually, and may be urgent. To simply <em>fail</em> is not good enough.</p><p>…</p></div>
</div>
</div>
<div data-id="750f62d" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>Or rather, imagine how frustrated you’d be if your bank’s app was broken and you couldn’t make any payments. You’d appreciate a suggestion of: “<em>call us on [this number] to make a payment over the phone</em>“.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="faa873c" data-element_type="section">
<div>
<div>
<div data-id="c122bc0" data-element_type="column">
<div>
<div>

<div data-id="8a78ff0" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>One thing is certain: Robinhood were scrambling to react to these spontaneous decisions, and the execution was poor.</p>
</div>
</div>
<div data-id="897910b" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>But the rush to push changes is not a valid excuse for a poor experience. In fact, it just fuelled the fire—probably contributing to the hundreds of thousands of 1-star ratings on the app stores, and Robinhood trending on Twitter.</p>
</div>
</div>
<div data-id="85a773b" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p>It’s in moments like this, more than ever, that a thoughtful and empathetic user experience is required.</p><p>…</p></div>
</div>
</div>
<div data-id="90aebad" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>So let’s summarise the key points here:</p>
</div>
</div>
<div data-id="70f3e6c" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p><strong>1: Context matters —</strong> take those extra few minutes to explain to your users <em>why</em> you’ve made a difficult decision.</p>
</div>
</div>
<div data-id="7de0215" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p><strong>2: Remove ambiguity&nbsp; —</strong> give people realistic expectations for when certain restrictions will be lifted, and what they can do in the meantime.</p>
</div>
</div>
<div data-id="f11d414" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p><strong>3: Show empathy&nbsp; —</strong> apologising isn’t enough, you need to demonstrate that you understand why your users will be suffering, and how hard it is for them.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section></div>]]>
            </description>
            <link>https://builtformars.com/how-robinhood-handled-a-crisis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25989369</guid>
            <pubDate>Mon, 01 Feb 2021 15:19:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scraping, analyzing and generating jobs and startups from YC's Work at a Startup]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25989367">thread link</a>) | @misterbrian
<br/>
February 1, 2021 | https://briancaffey.github.io/2021/01/16/i-scraped-analyzed-and-generated-yc-companies-founders-and-work-at-a-startup-job-postings | <a href="https://web.archive.org/web/*/https://briancaffey.github.io/2021/01/16/i-scraped-analyzed-and-generated-yc-companies-founders-and-work-at-a-startup-job-postings">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I always enjoy reading about new batches of YC companies. I came across YC's <a href="https://www.workatastartup.com/" rel="nofollow noopener noreferrer" target="_blank">Work at a Startup</a> (WaaS) recently while browsing HN and got pretty curious about all of the available data points on companies, jobs and founders.</p>
<p>This article will outline my process for collecting, cleaning, visualizing and analyzing the dataset.</p>
<p>After filling out my profile, WaaS recommended 750 matching YC startups which collectively list 1614 open positions. I think this is all of the available job openings and hiring companies, but I'm not sure.</p>
<h2 id="scraping-data">Scraping data</h2>
<p>I've used a few different tools to scrape data and automate web browsers. For collecting this data, I ended up just writing some JavaScript directly in the browser console and <code>Ctrl+S</code>aved the page HTML and assets (company logos and founder photos).</p>
<div><pre><code>
<span>const</span> toggleDetails <span>=</span> <span>document</span><span>.</span><span>getElementsByClassName</span><span>(</span><span>"checkbox-inline"</span><span>)</span><span>[</span><span>0</span><span>]</span>
toggleDetails<span>.</span><span>click</span><span>(</span><span>)</span>


<span>const</span> scroll <span>=</span> <span>setInterval</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span><span>window</span><span>.</span><span>scrollTo</span><span>(</span><span>0</span><span>,</span><span>document</span><span>.</span><span>body</span><span>.</span><span>scrollHeight</span><span>)</span><span>;</span><span>}</span><span>,</span> <span>3000</span><span>)</span>


<span>clearInterval</span><span>(</span>scroll<span>)</span>


<span>const</span> jobs <span>=</span> <span>document</span><span>.</span><span>getElementsByClassName</span><span>(</span><span>"job-name"</span><span>)</span>
<span>for</span> <span>(</span><span>let</span> job <span>of</span> jobs<span>)</span> <span>{</span>
    job<span>.</span><span>click</span><span>(</span><span>)</span>
<span>}</span>


</code></pre></div>
<h2 id="parsing-the-html">Parsing the HTML</h2>
<p>Next I'll parse the company data into a python list of dictionaries and then <code>dumps</code> it into a JSON file. This code is a little bit scrappy, here's the pseudo code:</p>
<div><pre><code>
html <span>=</span> <span>open</span><span>(</span><span>"data.html"</span><span>)</span>
parsed_html <span>=</span> parseHtml<span>(</span>html<span>)</span>

companies <span>=</span> <span>[</span><span>]</span>
<span>for</span> company <span>in</span> parsed_html<span>.</span>find_all<span>(</span><span>"company"</span><span>)</span>
    
    company_details <span>=</span> extract_company_details<span>(</span>company<span>)</span>
    companies<span>.</span>append<span>(</span>company_details<span>)</span>

<span>with</span> <span>open</span><span>(</span><span>"output.json"</span><span>,</span> <span>"wb"</span><span>)</span> <span>as</span> f<span>:</span>
    f<span>.</span>write<span>(</span>json<span>.</span>dumps<span>(</span>companies<span>)</span><span>)</span>
</code></pre></div>
<p>To scrape the data I used my go-to library for this type of task: BeautifulSoup. There were a few tricky parts:</p>
<ul>
<li>
<p>Job details (visa requirements, salary, equity) were all labelled with the same class and they were inconsistent (sometimes salary or equity or both were excluded, for example).</p>
</li>
<li>
<p>Equity was mostly a range of percentages such as <code>1% - 2%</code> and sometimes a single percentage like <code>1.5%</code>. Some salary ranges had typos like <code>$90k - $10k</code></p>
</li>
<li>
<p>Years of experience required was also inconsistent with mixed types like <code>3+ Years</code>, <code>Any (recent grad ok)</code> and <code>Senior or Juniors</code>, for example.</p>
</li>
</ul>
<p>These were all pretty easy to account for, it just required some additional logic to handle default values for <code>&lt;div&gt;</code>s that were not included as well as mixed data types and representations where there were inconsistencies.</p>
<p>The resulting JSON structure for the big array of companies looks like this:</p>
<div><pre><code><span>[</span>
    <span>{</span>
        <span>"company_name"</span><span>:</span> <span>"Startup A"</span><span>,</span>
        <span>"logo"</span><span>:</span> <span>"logo.png"</span><span>,</span>
        <span>"jobs"</span><span>:</span> <span>[</span>
            <span>{</span>
                <span>"title"</span><span>:</span> <span>"Software Engineer"</span><span>,</span>
                <span>"skills"</span><span>:</span> <span>[</span><span>"python"</span><span>,</span> <span>"javascript"</span><span>]</span><span>,</span>
                <span>"salary"</span><span>:</span> <span>{</span>
                    <span>"min"</span><span>:</span> <span>90000</span><span>,</span>
                    <span>"max"</span><span>:</span> <span>110000</span><span>,</span>
                    <span>"avg"</span><span>:</span> <span>100000</span>
                <span>}</span>
            <span>}</span>
        <span>]</span><span>,</span>
        <span>"founders"</span><span>:</span> <span>[</span>
            <span>{</span>
                <span>"name"</span><span>:</span> <span>"Founder Name"</span><span>,</span>
                <span>"linkedin"</span><span>:</span> <span>"https://linkedin.com/founder"</span><span>,</span>
                <span>"education"</span><span>:</span> <span>"University A"</span><span>,</span>
                <span>"image"</span><span>:</span> <span>"abc.png"</span>
            <span>}</span>
        <span>]</span>
    <span>}</span>
<span>]</span>
</code></pre></div>
<h2 id="analysis">Analysis</h2>
<p>Here are some of the biggest questions I wanted to answer along with some simple python I used for extracting data from the main dictionary/JSON object containing all companies and jobs. For the following code, assume I have read the JSON file back into a python dictionary.</p>
<h3 id="what-are-the-most-in-demand-skills-for-yc-jobs">What are the most in demand skills for YC Jobs?</h3>
<p>I think skills are included mostly for engineering roles (not so much for sales, marketing, etc.). Here are the top skills:</p>
<div><pre><code>skills <span>=</span> <span>[</span><span>]</span>
<span>for</span> company <span>in</span> company_list<span>:</span>
    <span>if</span> company<span>[</span><span>"jobs"</span><span>]</span> <span>is</span> <span>not</span> <span>None</span><span>:</span>
        <span>for</span> job <span>in</span> company<span>[</span><span>"jobs"</span><span>]</span><span>:</span>
            <span>if</span> job<span>[</span><span>"job_skills"</span><span>]</span> <span>is</span> <span>not</span> <span>None</span><span>:</span>
                <span>for</span> skill <span>in</span> job<span>[</span><span>"job_skills"</span><span>]</span><span>:</span>
                    skills<span>.</span>append<span>(</span>skill<span>)</span>

top_skills <span>=</span> Counter<span>(</span>skills<span>)</span><span>.</span>most_common<span>(</span><span>)</span>
<span>print</span><span>(</span>top_skills<span>)</span>
</code></pre></div>
<!----><!---->
<p>I'll try to briefly describe what I know about each of these if I know what it means (without Googling!):</p>
<div><pre><code><span>[</span>
 <span>(</span><span>'JAVASCRIPT'</span><span>,</span> <span>330</span><span>)</span><span>,</span> 
 <span>(</span><span>'REACT'</span><span>,</span> <span>323</span><span>)</span><span>,</span> 
 <span>(</span><span>'PYTHON'</span><span>,</span> <span>312</span><span>)</span><span>,</span> 
 <span>(</span><span>'AMAZON WEB SERVICES (AWS)'</span><span>,</span> <span>200</span><span>)</span><span>,</span> 
 <span>(</span><span>'NODE.JS'</span><span>,</span> <span>195</span><span>)</span><span>,</span> 
 <span>(</span><span>'POSTGRESQL'</span><span>,</span> <span>132</span><span>)</span><span>,</span> 
 <span>(</span><span>'TYPESCRIPT'</span><span>,</span> <span>114</span><span>)</span><span>,</span> 
 <span>(</span><span>'JAVA'</span><span>,</span> <span>79</span><span>)</span><span>,</span> 
 <span>(</span><span>'SQL'</span><span>,</span> <span>74</span><span>)</span><span>,</span> 
 <span>(</span><span>'RUBY ON RAILS'</span><span>,</span> <span>72</span><span>)</span><span>,</span> 
 <span>(</span><span>'CSS'</span><span>,</span> <span>71</span><span>)</span><span>,</span> 
 <span>(</span><span>'HTML'</span><span>,</span> <span>71</span><span>)</span><span>,</span>
 <span>(</span><span>'DOCKER'</span><span>,</span> <span>66</span><span>)</span><span>,</span> 
 <span>(</span><span>'KUBERNETES'</span><span>,</span> <span>58</span><span>)</span><span>,</span> 
 <span>(</span><span>'GO'</span><span>,</span> <span>58</span><span>)</span><span>,</span> 
 <span>(</span><span>'REACT NATIVE'</span><span>,</span> <span>58</span><span>)</span><span>,</span>
 <span>(</span><span>'C++'</span><span>,</span> <span>55</span><span>)</span><span>,</span> 
 <span>(</span><span>'GRAPHQL'</span><span>,</span> <span>48</span><span>)</span><span>,</span> 
 <span>(</span><span>'GOOGLE CLOUD'</span><span>,</span> <span>46</span><span>)</span><span>,</span> 
 <span>(</span><span>'RUBY'</span><span>,</span> <span>44</span><span>)</span><span>,</span> 
 <span>(</span><span>'DJANGO'</span><span>,</span> <span>44</span><span>)</span><span>,</span> 
 <span>(</span><span>'MACHINE LEARNING'</span><span>,</span> <span>44</span><span>)</span><span>,</span> 
 <span>(</span><span>'MONGODB'</span><span>,</span> <span>43</span><span>)</span><span>,</span> 
 <span>(</span><span>'IOS'</span><span>,</span> <span>38</span><span>)</span><span>,</span> 
 <span>(</span><span>'MYSQL'</span><span>,</span> <span>36</span><span>)</span><span>,</span> 
 <span>(</span><span>'ANDROID'</span><span>,</span> <span>35</span><span>)</span><span>,</span> 
 <span>(</span><span>'DATA ANALYTICS'</span><span>,</span> <span>32</span><span>)</span><span>,</span> 
 <span>(</span><span>'GIT'</span><span>,</span> <span>30</span><span>)</span><span>,</span> 
 <span>(</span><span>'ANGULAR'</span><span>,</span> <span>29</span><span>)</span><span>,</span> 
 <span>(</span><span>'SWIFT'</span><span>,</span> <span>29</span><span>)</span><span>,</span> 
 <span>(</span><span>'LINUX'</span><span>,</span> <span>28</span><span>)</span><span>,</span> 
 <span>(</span><span>'SOFTWARE ARCHITECTURE'</span><span>,</span> <span>24</span><span>)</span><span>,</span> 
 <span>(</span><span>'KOTLIN'</span><span>,</span> <span>23</span><span>)</span><span>,</span> 
 <span>(</span><span>'TENSORFLOW'</span><span>,</span> <span>22</span><span>)</span><span>,</span> 
 <span>(</span><span>'DISTRIBUTED SYSTEMS'</span><span>,</span> <span>22</span><span>)</span><span>,</span> 
 <span>(</span><span>'PHP'</span><span>,</span> <span>22</span><span>)</span><span>,</span> 
 <span>(</span><span>'DATA WAREHOUSING'</span><span>,</span> <span>22</span><span>)</span><span>,</span> 
 <span>(</span><span>'DEEP LEARNING'</span><span>,</span> <span>20</span><span>)</span><span>,</span> 
 <span>(</span><span>'DATA MODELING'</span><span>,</span> <span>20</span><span>)</span><span>,</span> 
 <span>(</span><span>'C#'</span><span>,</span> <span>19</span><span>)</span><span>,</span> 
 <span>(</span><span>'FLASK'</span><span>,</span> <span>19</span><span>)</span><span>,</span> 
 <span>(</span><span>'C'</span><span>,</span> <span>19</span><span>)</span><span>,</span> 
 <span>(</span><span>'REDIS'</span><span>,</span> <span>18</span><span>)</span><span>,</span> 
 <span>(</span><span>'MICROSERVICES'</span><span>,</span> <span>18</span><span>)</span><span>,</span> 
 <span>(</span><span>'COMPUTER VISION'</span><span>,</span> <span>17</span><span>)</span><span>,</span> 
 <span>(</span><span>'EXPRESS'</span><span>,</span> <span>15</span><span>)</span><span>,</span> 
 <span>(</span><span>'BASH/SHELL'</span><span>,</span> <span>13</span><span>)</span><span>,</span> 
 <span>(</span><span>'OBJECTIVE-C'</span><span>,</span> <span>13</span><span>)</span><span>,</span> 
 <span>(</span><span>'FIREBASE'</span><span>,</span> <span>12</span><span>)</span><span>,</span> 
 <span>(</span><span>'SCALA'</span><span>,</span> <span>11</span><span>)</span><span>,</span> 
 <span>(</span><span>'SOFTWARE SECURITY'</span><span>,</span> <span>11</span><span>)</span><span>,</span>
 <span>(</span><span>'UNITY'</span><span>,</span> <span>11</span><span>)</span><span>,</span> 
 <span>(</span><span>'R'</span><span>,</span> <span>11</span><span>)</span><span>,</span> 
 <span>(</span><span>'KAFKA'</span><span>,</span> <span>10</span><span>)</span><span>,</span> 
 <span>(</span><span>'SPARK'</span><span>,</span> <span>10</span><span>)</span><span>,</span> 
 <span>(</span><span>'ELASTICSEARCH'</span><span>,</span> <span>10</span><span>)</span><span>,</span> 
 <span>(</span><span>'ETL'</span><span>,</span> <span>10</span><span>)</span><span>,</span> 
 <span>(</span><span>'NATURAL LANGUAGE PROCESSING'</span><span>,</span> <span>10</span><span>)</span><span>,</span>
 <span>(</span><span>'HEROKU'</span><span>,</span> <span>10</span><span>)</span><span>,</span> 
 <span>(</span><span>'NGINX'</span><span>,</span> <span>9</span><span>)</span><span>,</span> 
 <span>(</span><span>'JENKINS'</span><span>,</span> <span>9</span><span>)</span><span>,</span> 
 <span>(</span><span>'RUST'</span><span>,</span> <span>9</span><span>)</span><span>,</span> 
 <span>(</span><span>'IMAGE PROCESSING'</span><span>,</span> <span>8</span><span>)</span><span>,</span>
 <span>(</span><span>'SERVERLESS'</span><span>,</span> <span>8</span><span>)</span><span>,</span> 
 <span>(</span><span>'BLOCKCHAIN'</span><span>,</span> <span>8</span><span>)</span><span>,</span>
 <span>(</span><span>'OPENCV'</span><span>,</span> <span>8</span><span>)</span><span>,</span>
 <span>(</span><span>'CAD DESIGN'</span><span>,</span> <span>7</span><span>)</span><span>,</span> 
 <span>(</span><span>'JQUERY'</span><span>,</span> <span>7</span><span>)</span><span>,</span> 
 <span>(</span><span>'HADOOP'</span><span>,</span> <span>6</span><span>)</span><span>,</span> 
 <span>(</span><span>'.NET CORE'</span><span>,</span> <span>6</span><span>)</span><span>,</span> 
 <span>(</span><span>'TCP/IP'</span><span>,</span> <span>6</span><span>)</span><span>,</span> 
 <span>(</span><span>'ELIXIR'</span><span>,</span> <span>6</span><span>)</span><span>,</span> 
 <span>(</span><span>'INTERNET OF THINGS (IOT)'</span><span>,</span> <span>5</span><span>)</span><span>,</span>
 <span>(</span><span>'SASS'</span><span>,</span> <span>5</span><span>)</span><span>,</span> 
 <span>(</span><span>'OPENGL'</span><span>,</span> <span>5</span><span>)</span><span>,</span>
 <span>(</span><span>'DYNAMODB'</span><span>,</span> <span>5</span><span>)</span><span>,</span> 
 <span>(</span><span>'GOOGLE APP ENGINE'</span><span>,</span> <span>5</span><span>)</span><span>,</span> 
 <span>(</span><span>'UNIX'</span><span>,</span> <span>4</span><span>)</span><span>,</span>
 <span>(</span><span>'SPRING FRAMEWORK'</span><span>,</span> <span>4</span><span>)</span><span>,</span> 
 <span>(</span><span>'CUDA'</span><span>,</span> <span>4</span><span>)</span><span>,</span> 
 <span>(</span><span>'DART'</span><span>,</span> <span>4</span><span>)</span><span>,</span> 
 <span>(</span><span>'ERLANG'</span><span>,</span> <span>4</span><span>)</span><span>,</span> 
 <span>(</span><span>'RABBITMQ'</span><span>,</span> <span>4</span><span>)</span><span>,</span> 
 <span>(</span><span>'KERAS'</span><span>,</span> <span>4</span><span>)</span><span>,</span> 
 <span>(</span><span>'SCSS'</span><span>,</span> <span>4</span><span>)</span><span>,</span> 
 <span>(</span><span>'ML'</span><span>,</span> <span>4</span><span>)</span><span>,</span> 
 <span>(</span><span>'MATLAB'</span><span>,</span> <span>4</span><span>)</span><span>,</span> 
 <span>(</span><span>'SPRING'</span><span>,</span> <span>4</span><span>)</span><span>,</span> 
 <span>(</span><span>'CASSANDRA'</span><span>,</span> <span>4</span><span>)</span><span>,</span> 
 <span>(</span><span>'HIVE'</span><span>,</span> <span>3</span><span>)</span><span>,</span> 
 <span>(</span><span>'PUPPET'</span><span>,</span> <span>3</span><span>)</span><span>,</span> 
 <span>(</span><span>'REDSHIFT'</span><span>,</span> <span>3</span><span>)</span><span>,</span> 
 <span>(</span><span>'SQL SERVER'</span><span>,</span> <span>3</span><span>)</span><span>,</span> 
 <span>(</span><span>'GROOVY'</span><span>,</span> <span>3</span><span>)</span><span>,</span> 
 <span>(</span><span>'VERILOG'</span><span>,</span> <span>3</span><span>)</span><span>,</span> 
 <span>(</span><span>'TORCH/PYTORCH'</span><span>,</span> <span>3</span><span>)</span><span>,</span> 
 <span>(</span><span>'CLOJURE'</span><span>,</span> <span>3</span><span>)</span><span>,</span> 
 <span>(</span><span>'MICROSOFT AZURE'</span><span>,</span> <span>3</span><span>)</span><span>,</span> 
 <span>(</span><span>'HBASE'</span><span>,</span> <span>2</span><span>)</span><span>,</span> 
 <span>(</span><span>'RDS/AURORA'</span><span>,</span> <span>2</span><span>)</span><span>,</span> 
 <span>(</span><span>'FIRMWARE'</span><span>,</span> <span>2</span><span>)</span><span>,</span> 
 <span>(</span><span>'ABAP'</span><span>,</span> <span>2</span><span>)</span><span>,</span> 
 <span>(</span><span>'ARDUINO'</span><span>,</span> <span>2</span><span>)</span><span>,</span> 
 <span>(</span><span>'MICROCONTROLLERS'</span><span>,</span> <span>2</span><span>)</span><span>,</span> 
 <span>(</span><span>'SOLIDITY'</span><span>,</span> <span>2</span><span>)</span><span>,</span> 
 <span>(</span><span>'UNREAL ENGINE'</span><span>,</span> <span>2</span><span>)</span><span>,</span> 
 <span>(</span><span>'COFFEESCRIPT'</span><span>,</span> <span>2</span><span>)</span><span>,</span> 
 <span>(</span><span>'LUA'</span><span>,</span> <span>2</span><span>)</span><span>,</span> 
 <span>(</span><span>'MACOS'</span><span>,</span> <span>2</span><span>)</span><span>,</span> 
 <span>(</span><span>'NEO4J'</span><span>,</span> <span>2</span><span>)</span><span>,</span> 
 <span>(</span><span>'INFORMATION SECURITY'</span><span>,</span> <span>2</span><span>)</span><span>,</span> 
 <span>(</span><span>'REINFORCEMENT LEARNING (RL)'</span><span>,</span> <span>2</span><span>)</span><span>,</span> 
 <span>(</span><span>'DEVICE DRIVERS'</span><span>,</span> <span>2</span><span>)</span><span>,</span> 
 <span>(</span><span>'EMBEDDED LINUX'</span><span>,</span> <span>2</span><span>)</span><span>,</span> 
 <span>(</span><span>'ELASTIC STACK (ELK)'</span><span>,</span> <span>1</span><span>)</span><span>,</span> 
 <span>(</span><span>'IIS'</span><span>,</span> <span>1</span><span>)</span><span>,</span> 
 <span>(</span><span>'ORACLE'</span><span>,</span> <span>1</span><span>)</span><span>,</span> 
 <span>(</span><span>'F#'</span><span>,</span> <span>1</span><span>)</span><span>,</span> 
 <span>(</span><span>'SQLITE'</span><span>,</span> <span>1</span><span>)</span><span>,</span> 
 <span>(</span><span>'HASKELL'</span><span>,</span> <span>1</span><span>)</span><span>,</span> 
 <span>(</span><span>'SCHEME'</span><span>,</span> <span>1</span><span>)</span><span>,</span> 
 <span>(</span><span>'MS SQL'</span><span>,</span> <span>1</span><span>)</span><span>,</span> 
 <span>(</span><span>'MARIADB'</span><span>,</span> <span>1</span><span>)</span><span>,</span> 
 <span>(</span><span>'MAVEN'</span><span>,</span> <span>1</span><span>)</span><span>,</span> 
 <span>(</span><span>'SEARCH'</span><span>,</span> <span>1</span><span>)</span><span>,</span> 
 <span>(</span><span>'OCAML'</span><span>,</span> <span>1</span><span>)</span><span>,</span> 
 <span>(</span><span>'JULIA'</span><span>,</span> <span>1</span><span>)</span><span>,</span> 
 <span>(</span><span>'GPU PROGRAMMING'</span><span>,</span> <span>1</span><span>)</span><span>,</span> 
 <span>(</span><span>'HACK'</span><span>,</span> <span>1</span><span>)</span><span>,</span> 
 <span>(</span><span>'XAMARIN'</span><span>,</span> <span>1</span><span>)</span><span>,</span> 
 <span>(</span><span>'CORDOVA'</span><span>,</span> <span>1</span><span>)</span><span>,</span> 
 <span>(</span><span>'SAS'</span><span>,</span> <span>1</span><span>)</span><span>,</span> 
 <span>(</span><span>'ASSEMBLY'</span><span>,</span> <span>1</span><span>)</span><span>,</span> 
 <span>(</span><span>'XML'</span><span>,</span> <span>1</span><span>)</span><span>,</span> 
 <span>(</span><span>'MEMCACHED'</span><span>,</span> <span>1</span><span>)</span><span>,</span> 
 <span>(</span><span>'LESS'</span><span>,</span> <span>1</span><span>)</span><span>,</span> 
 <span>(</span><span>'AMAZON ECHO'</span><span>,</span> <span>1</span><span>)</span> 
<span>]</span>
</code></pre></div>
<p>The list above gives a count of the different skills in all job postings sorted by the most common skills. But what about the most common skills listed together with any given skill? This would allow us to answer questions like "what skills appear most frequently along with JavaScript?"</p>
<p>We can find this with by doing:</p>
<div><pre><code>skills_frequency <span>=</span> defaultdict<span>(</span><span>lambda</span><span>:</span> defaultdict<span>(</span><span>lambda</span><span>:</span> <span>0</span><span>)</span><span>)</span>

<span>for</span> company <span>in</span> company_list<span>:</span>
    <span>if</span> company<span>[</span><span>"jobs"</span><span>]</span> <span>is</span> <span>not</span> <span>None</span><span>:</span>
        <span>for</span> job <span>in</span> company<span>[</span><span>"jobs"</span><span>]</span><span>:</span>
            <span>if</span> job<span>[</span><span>"job_skills"</span><span>]</span> <span>is</span> <span>not</span> <span>None</span><span>:</span>
                job_skills <span>=</span> job<span>[</span><span>"job_skills"</span><span>]</span>

                skill_tuples <span>=</span> itertools<span>.</span>permutations<span>(</span>job_skills<span>,</span> <span>2</span><span>)</span>

                <span>for</span> skill_tuple <span>in</span> skill_tuples<span>:</span>
                    first <span>=</span> skill_tuple<span>[</span><span>0</span><span>]</span>
                    second <span>=</span> skill_tuple<span>[</span><span>1</span><span>]</span>

                    skills_frequency<span>[</span>first<span>]</span><span>[</span>second<span>]</span> <span>+=</span> <span>1</span>

pprint<span>.</span>pprint<span>(</span>
    <span>{</span>
        key<span>:</span> <span>sorted</span><span>(</span>value<span>.</span>items<span>(</span><span>)</span><span>,</span> key<span>=</span><span>lambda</span> kv<span>:</span> <span>-</span>kv<span>[</span><span>1</span><span>]</span><span>)</span>
        <span>for</span> key<span>,</span> value <span>in</span> skills_frequency<span>.</span>items<span>(</span><span>)</span>
    <span>}</span>
<span>)</span>
</code></pre></div>
<!----><!---->
<h3 id="what-are-these-companies-working-on">What are these companies working on?</h3>
<p>Here's a wordcloud made from the short company descriptions:</p>
<p><img alt="png" src="https://briancaffey.github.io/static/company_desc_wc.png"></p>
<div><pre><code><span>import</span> json
<span>import</span> random

<span>from</span> collections <span>import</span> Counter
<span>from</span> os <span>import</span> path

<span>import</span> matplotlib<span>.</span>pyplot <span>as</span> plt
<span>import</span> numpy <span>as</span> np

<span>from</span> PIL <span>import</span> Image
<span>from</span> wordcloud <span>import</span> WordCloud<span>,</span> STOPWORDS

HTML_FILE <span>=</span> <span>"waas_data.json"</span>
<span>with</span> <span>open</span><span>(</span>HTML_FILE<span>,</span> <span>'r'</span><span>)</span> <span>as</span> j<span>:</span>
     company_list <span>=</span> json<span>.</span>loads<span>(</span>j<span>.</span>read<span>(</span><span>)</span><span>)</span>

company_names <span>=</span> <span>[</span>company<span>.</span>get<span>(</span><span>"company_name"</span><span>,</span> <span>" "</span><span>)</span><span>.</span>lower<span>(</span><span>)</span> <span>for</span> company <span>in</span> company_list<span>]</span>
company_description_list <span>=</span> <span>[</span>company<span>.</span>get<span>(</span><span>"company_desc"</span><span>,</span> <span>" "</span><span>)</span><span>.</span>lower<span>(</span><span>)</span><span>.</span>replace<span>(</span><span>"."</span><span>,</span> <span>""</span><span>)</span> <span>for</span> company <span>in</span> company_list<span>]</span>
company_descriptions <span>=</span> <span>" "</span><span>.</span>join<span>(</span>company_description_list<span>)</span>

wc <span>=</span> WordCloud<span>(</span>background_color<span>=</span><span>"white"</span><span>,</span> width<span>=</span><span>1920</span><span>,</span> height<span>=</span><span>1080</span><span>,</span> max_words<span>=</span><span>500</span><span>,</span> stopwords<span>=</span>STOPWORDS<span>,</span> margin<span>=</span><span>10</span><span>,</span>
               random_state<span>=</span><span>1</span><span>)</span><span>.</span>generate<span>(</span>company_descriptions<span>)</span>

default_colors <span>=</span> wc<span>.</span>to_array<span>(</span><span>)</span>

plt<span>.</span>figure<span>(</span>figsize<span>=</span><span>(</span><span>40</span><span>,</span> <span>40</span><span>)</span><span>)</span>
plt<span>.</span>imshow<span>(</span>wc<span>,</span> interpolation<span>=</span><span>"bilinear"</span><span>)</span>

plt<span>.</span>axis<span>(</span><span>"off"</span><span>)</span>
plt<span>.</span>savefig<span>(</span><span>'company_description_wc.png'</span><span>)</span>
plt<span>.</span>show<span>(</span><span>)</span>
</code></pre></div>
<p>Here's a breakdown of YC companies by category and sub category:</p>
<!----><!---->
<h3 id="salary-equity-and-years-of-experience">Salary, Equity and Years of Experience</h3>
<p>Here's a scatterplot showing average salary and average equity for positions categorized by years of experience required.</p>
<!----><!---->
<h3 id="logos">Logos</h3>
<p>Here's a look at about 600 of the 750 logos that were made available in the list of companies. The logos are sorted by their average hex color, which puts them on a gradient of dark to light:</p>
<p><img alt="png" src="https://briancaffey.github.io/static/yc.png"></p>
<div><pre><code><span>import</span> os
<span>import</span> PIL
<span>from</span> PIL <span>import</span> Image
<span>from</span> IPython<span>.</span>display <span>import</span> display<span>,</span> Image <span>as</span> IPyImage
<span>import</span> matplotlib<span>.</span>pyplot <span>as</span> plt
<span>import</span> matplotlib<span>.</span>image <span>as</span> mpimg
<span>%</span>matplotlib inline

LOGO_DIR <span>=</span> <span>'data/waas_full_details_dump_files/'</span>
yc_logos <span>=</span> <span>[</span>LOGO_DIR <span>+</span> x <span>for</span> x <span>in</span> os<span>.</span>listdir<span>(</span>LOGO_DIR<span>)</span> <span>if</span> x<span>.</span>endswith<span>(</span><span>'.png'</span><span>)</span><span>]</span>

<span>def</span> <span>average_img_hex</span><span>(</span>img<span>)</span><span>:</span>
    <span>"""
    https://www.hackzine.org/getting-average-image-color-from-python.html
    """</span>
    img <span>=</span> Image<span>.</span><span>open</span><span>(</span>img<span>)</span>

    
    <span>if</span> img<span>.</span>mode <span>in</span> <span>[</span><span>"LA"</span><span>,</span> <span>"P"</span><span>,</span> <span>"L"</span><span>]</span><span>:</span>
        <span>return</span>

    
    img2 <span>=</span> img<span>.</span>resize<span>(</span><span>(</span><span>1</span><span>,</span> <span>1</span><span>)</span><span>)</span>
    color <span>=</span> img2<span>.</span>getpixel<span>(</span><span>(</span><span>0</span><span>,</span> <span>0</span><span>)</span><span>)</span>
    average_hex <span>=</span> <span>'#{:02x}{:02x}{:02x}'</span><span>.</span><span>format</span><span>(</span><span>*</span>color<span>)</span>

    <span>return</span> average_hex


sorted_images <span>=</span> <span>sorted</span><span>(</span>
    <span>[</span><span>(</span>average_img_hex<span>(</span>img<span>)</span><span>,</span> img<span>)</span> <span>for</span> img <span>in</span> yc_logos <span>if</span> average_img_hex<span>(</span>img<span>)</span> <span>is</span> <span>not</span> <span>None</span><span>]</span><span>,</span>
    key<span>=</span><span>lambda</span> x<span>:</span> x<span>[</span><span>0</span><span>]</span>
<span>)</span>

images <span>=</span> sorted_images<span>[</span><span>:</span><span>600</span><span>]</span>

fig<span>,</span> axes <span>=</span> plt<span>.</span>subplots<span>(</span><span>20</span><span>,</span> <span>30</span><span>,</span> figsize<span>=</span><span>(</span><span>30</span><span>,</span> <span>15</span><span>)</span><span>,</span> sharex<span>=</span><span>False</span><span>,</span> sharey<span>=</span><span>Fal…</span></code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://briancaffey.github.io/2021/01/16/i-scraped-analyzed-and-generated-yc-companies-founders-and-work-at-a-startup-job-postings">https://briancaffey.github.io/2021/01/16/i-scraped-analyzed-and-generated-yc-companies-founders-and-work-at-a-startup-job-postings</a></em></p>]]>
            </description>
            <link>https://briancaffey.github.io/2021/01/16/i-scraped-analyzed-and-generated-yc-companies-founders-and-work-at-a-startup-job-postings</link>
            <guid isPermaLink="false">hacker-news-small-sites-25989367</guid>
            <pubDate>Mon, 01 Feb 2021 15:19:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Games can fix remote team building]]>
            </title>
            <description>
<![CDATA[
Score 71 | Comments 65 (<a href="https://news.ycombinator.com/item?id=25989336">thread link</a>) | @masonhipp
<br/>
February 1, 2021 | https://slideswith.com/blog/games-for-remote-team-building | <a href="https://web.archive.org/web/*/https://slideswith.com/blog/games-for-remote-team-building">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><strong>The problem: remote work makes it dramatically harder to socialize with your teammates.</strong></p>
<p>There's no going to the bar, you can't read body language, and spontaneous conversation evaporates. The fundamentals of team building are the same — communication, shared values, camaraderie, and a belief in the company mission  — but the avenues for establishing those foundations are severely limited when remote.</p>
<p><mark>Online games can solve many of challenges of inherit to remote team building.</mark></p>
<p>Games do several things that make them ideal for building strong connections and creating closeness between peers. They can:</p>
<ul>
<li>lower the bar to social interaction</li>
<li>create unique shared experiences</li>
<li>provide a safe environment for deeper conversation</li>
<li>provide beneficial structure to group interactions</li>
<li>make the most of limited-bandwidth video calls</li>
<li>allow teamwork to be practiced with lower stakes</li>
</ul>
<p>It's also much easier to get buy-in for a trivia night or a game that's fun and amusing than it is to get people excited about yet another zoom happy hour. Let's take a look at why game dynamics are so useful for online connection.</p>
<h2 id="games-create-inclusive-conversations-that-work-online">Games create inclusive conversations that work online</h2>
<p>An important aspect of building a strong team is breaking down the walls between each of the various team members and fostering connections between them. This can be difficult to do naturally in the real world and it is even more challenging virtually.</p>
<p>Most events don't run with an ideal structure for team building, and conversations end up too focused on one speaker or a free-for-all dominated by the loudest voices.</p>
<p><img alt="" src="https://d33wubrfki0l68.cloudfront.net/f9ffbdad43c032944434345296afb2464462dc95/c16e4/images/blog/natural-group-interaction-opt.svg"></p>
<p>With the right game you can create a conversational structure that is much more inclusive and ideal for team boding. Additionally, game conversations are frequently turn-based and lend themselves naturally to online conversation with larger groups.</p>
<p><img alt="" src="https://d33wubrfki0l68.cloudfront.net/8a4599e657de5c00626214a2e1199304450465b2/fed64/images/blog/ideal-group-conversation-opt.svg"></p>
<h2 id="games-teach-teamwork-in-fast-low-risk-environment">Games teach teamwork in fast, low-risk environment</h2>
<p>A high-functioning remote team will be able to work cohesively toward a single goal. The members will understand their strengths, understand how to communicate with one another, and be able to work as an effective and coordinated whole. Learning to do this can take a lot of time.</p>
<p><strong>Games offer a fast iteration cycle with lower consequences of failure, providing an ideal environment for learning to work as a team.</strong></p>
<p>The social cooperation required in games is often very similar to the real world. The communication and interpersonal challenges of a job are frequently replicated in online games — but without the high stakes and risk of real world performance and deadlines.</p>
<p>It's also possible to run through many more teamwork scenarios in a game than it is in a real-world work environment. Being able to play multiple games or challenges in a short period of time can also provide more opportunity to learn how to work together than the equivalent period of time working together on an actual project with real-world consequences.</p>
<h2 id="games-offer-a-safe-space-to-talk-about-real-things">Games offer a safe space to talk about real things</h2>
<p>Creating real friendships between team members requires a degree of vulnerability that can be difficult to surface in a day-to-day conversation, and is particularly challenging over video calls.</p>
<p>Friendships between team members generally start with small talk and slowly grow in trust and closeness over time. When it happens naturally, this process can take a long time and requires a lot of interaction (the ratio of real conversation to small talk is very low).</p>
<p>According to psychologist Arthur Aron, who you might know from the popular NY Times article <a href="https://www.nytimes.com/2015/01/09/style/no-37-big-wedding-or-small.html" rel="nofollow noopener noreferrer" target="_blank">36 Questions to Fall In Love</a>, the key to forming close bonds is a gradual increase in mutual vulnerability (real conversations):</p>
<blockquote>
<p>“One key pattern associated with the development of a close relationship among peers is sustained, escalating, reciprocal, personal self-disclosure.”</p>
<p>— Aurthor Aron, et. al. <a href="https://journals.sagepub.com/doi/pdf/10.1177/0146167297234003" rel="nofollow noopener noreferrer" target="_blank">The Experimental Generation of Interpersonal Closeness</a></p>
</blockquote>
<p>From a corporate team building perspective the point is this: creating bonds inside of your team will eventually require team members to show mutual vulnerability and have real conversations.</p>
<p>At a company office there is an enormous volume of interactions and all of this happens organically, but we don't have that luxury when working virtually. To be most effective at team building online requires a very intentional approach that prioritizes real conversation and self-disclosure.</p>
<p>Games can add exactly this structure to conversations (as mentioned above) and the games themselves can be specifically designed to foster self-disclosure and real conversation in an approachable and fun environment.</p>
<h2 id="games-help-overcome-the-lower-fidelity-of-video-calls">Games help overcome the lower fidelity of video calls</h2>
<p>Interpersonal communication typically uses an incredible amount of information bandwidth: we instinctively monitor body movements, miniscule sound inflections, facial micro-expressions, <a href="https://en.wikipedia.org/wiki/Proxemics" rel="nofollow noopener noreferrer" target="_blank">proxemics</a>, and much more in instantaneous real time.</p>
<p>Trying to have a conversation over video chat, on the other hand, leads to a near complete breakdown of nonverbal cues and a substantial degradation of verbal communication. Experts have roundly agreed that <a href="https://www.nationalgeographic.com/science/2020/04/coronavirus-zoom-fatigue-is-taxing-the-brain-here-is-why-that-happens/" rel="nofollow noopener noreferrer" target="_blank">Zoom fatigue is both real and costly</a>, and many of them agree that the root cause is related to latency, bandwidth, and the breakdown of natural information transfer between parties (e.g. eye contact).</p>
<blockquote>
<p>“For somebody who’s really dependent on non-verbal cues, it can be a big drain not to have them,”</p>
<p>— Andrew Franklin, assistant Professor of Cyberpsychology at Norfolk State University</p>
</blockquote>
<p>Given how much less bandwidth is available during online communication, many teams instinctively gravitate toward a "transactional only" approach to meetings. This can provide some benefits — calls are shorter, reducing overall fatigue, and there is a tighter schedule of defined work — but this approach entirely eliminates relationship building. Some teams can function this way (if they've known each other for a while), but for many this elimination of team interaction is a major problem.</p>
<p>Games can help overcome the bandwidth and latency issues by creating a clear structure for communication. Structured, rule-based conversations remove the need for each participant to dynamically read the room to know when to talk and what to say. <mark>The rule-based structure of games replaces the need to follow the meta-structure of a group conversation, allowing the participants focus on the <em>content</em> of the </mark>communication and not who's turn it is to talk.</p>
<p>Structured communication can also reduce conversational error rates (e.g. people talking over each other) and overall make the most of a reduced-bandwidth environment.</p>
<h2 id="games-lower-social-barriers-and-create-buy-in">Games lower social barriers and create buy-in</h2>
<p>The easiest way to silence a video call is to ask a deep or open-ended question — people will immediately shut down, trying avoid a situation where they might get burned in front of their peers.</p>
<p><img alt="" src="https://d33wubrfki0l68.cloudfront.net/617201462cf33e37820b89fe119005f69bd1e668/e35ff/images/blog/share-personal-information-optimized.svg"></p>
<p><strong>Sharing personal information is inherently risky, but games provide rules that make it safer. Few people will volunteer personal information to a group, but during a game almost everyone will participate freely when it comes to their turn.</strong></p>
<p>Games provide a safe space for interaction that can make it easier and less risky to be yourself, and in fact even rewards everyone for participating. How many people would do an impression of a farm animal in front of a group? How about during a game of charades?</p>
<p>The other interesting benefit of games is that they are more fun by default. Getting your team to buy into a zoom happy hour or team building exercise is tough — but getting them excited about a game of trivia or escape room is much easier.</p>
<h2 id="games-encourage-active-attention">Games encourage active attention</h2>
<p>One very powerful aspect of an online game is that it generally requires all participants to pay attention or risk losing or being called out. <mark>The active attention of a game environment is in direct contrast with many zoom meetings where half of the audience could be in a different tab while you're talking</mark>.</p>
<p>As you might imagine from real-world conversations, paying active attention is a prerequisite for building real relationships and bonds, and games are an excellent tool for creating an environment that's ripe for team building.</p>
<p>A word of caution: active engagement can be very tiring, particularly on video calls, and an overuse of games to force paying attention can easily result in a exhausted audience. The key to avoiding this is proper spacing, breaks, and the right frequency of use.</p>

<p>Think back to a conversation you had with a group of friends or close coworkers. How often did somebody say "do you remember when we did X" .. or ..  "what was that movie we watched during..?"</p>
<p>This kind of information sharing is called <strong>Transactive Memory</strong> and it is a key component to forming close relationships and creating a team that functions well together. <mark>Each person in a highly collaborative team will help <em>maintain the shared group memory and understanding</em> such that the group is maximizing each member's strengths, compensating for weaknesses, and the entire team can work together optimally toward a shared goal</mark>.</p>
<p>Games help to create these shared memories by putting group members into a new experience and then asking everybody to participate, recall information, and work together. These actions all combine into an event that team members can remember together and use to learn and understand each other more deeply.</p>
<blockquote>
<p>The existence of effective transactive memory systems in teams has been found to enhance task performance. Methods of developing transactive memory are therefore an important focus of research. This study aimed to explore one such method, the use of a generic team-skills training program, to develop transactive memory and subsequent task performance [...] <strong>Results confirmed that</strong> <strong>those teams that had been trained to develop a range of team skills such as problem-solving, interpersonal relationships, goal setting, and role allocation evidenced significantly higher team skill, transactive memory, and performance than those that were not trained in …</strong></p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://slideswith.com/blog/games-for-remote-team-building">https://slideswith.com/blog/games-for-remote-team-building</a></em></p>]]>
            </description>
            <link>https://slideswith.com/blog/games-for-remote-team-building</link>
            <guid isPermaLink="false">hacker-news-small-sites-25989336</guid>
            <pubDate>Mon, 01 Feb 2021 15:16:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[These Are the 21 Best Developer Productivity Tools]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25989252">thread link</a>) | @KaiserSanchez
<br/>
February 1, 2021 | https://www.7pace.com/blog/developer-productivity-tools | <a href="https://web.archive.org/web/*/https://www.7pace.com/blog/developer-productivity-tools">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
							
<p>If work in the 21st century has a theme, it’s this: <a href="https://www.7pace.com/blog/how-to-measure-developer-productivity"><u>Productivity</u></a>.</p>



<p>We’re all striving to be more productive —&nbsp;at work, at home, and everywhere in between. And to help us achieve ultimate productivity, there are <em>countless</em>&nbsp;tools and resources that promise to make you able to work harder, better, faster, and stronger.</p>



<p>But not all productivity tools were created equal. Some are just better than others, and some are better suited to different tasks and workflows. That’s where this guide comes in.</p>



<p>If you’re a developer standing in front of the veritable sea of productivity apps and tools available and wondering where to start, don’t worry. We’ve got you. We’ve narrowed down the 21 best developer productivity tools, focusing on resources that will help you stave off distractions, find your flow, and work collaboratively across your team.</p>



<h2>The 21 Developer Productivity Tools You Need to Download Right Now</h2>



<p>Before we dive in, let’s cover the bad news: You’re <a href="https://www.7pace.com/blog/workplace-productivity"><u>never going to become 100 percent productive</u></a>. Sorry, but that’s just not how human brains work.</p>



<p>The first step is to approach this list with the right motives. If you’re looking to work better with your teammates or break bad work habits (like checking social media every few minutes), these tools can help. If your goal is to <a href="https://www.7pace.com/blog/deep-work-in-the-age-of-distraction"><u>deep work for 14 hours a day</u></a>, you need to accept that that’s just unrealistic.</p>



<p>Don’t think of productivity as an end goal or something you will eventually achieve. Think of it as a <a href="https://www.7pace.com/blog/healthier-work-systems"><u>journey you take every time you sit down to work</u></a>. And use these tools to help guide you on that daily journey.</p>



<h3>Developer Productivity Tools for Project Management, Teamwork, and Workflow</h3>



<figure><img loading="lazy" width="970" height="585" src="https://www.7pace.com/wp-content/uploads/2021/01/01-Image-4.jpg" alt="Developer Productivity Tools for Project Management, Teamwork, and Workflow" srcset="https://www.7pace.com/wp-content/uploads/2021/01/01-Image-4.jpg 970w, https://www.7pace.com/wp-content/uploads/2021/01/01-Image-4-300x181.jpg 300w, https://www.7pace.com/wp-content/uploads/2021/01/01-Image-4-768x463.jpg 768w" sizes="(max-width: 970px) 100vw, 970px"></figure>



<p><a href="https://hey.space/" target="_blank" rel="noreferrer noopener"><strong><u>HeySpace</u></strong></a>&nbsp;is a task management software that also has a chat feature —&nbsp;sort of like a combination of Slack and Trello. Its innovative and user-friendly design allows you to see tasks and communications in just one screen. That means no more toggling between different screens (or different apps) to chat with your team about a project or task. HeySpace offers both free and paid premium plans, depending on the number of users on your team.</p>



<p><a href="https://www.codestream.com/" target="_blank" rel="noreferrer noopener"><strong><u>Codestream</u></strong></a>&nbsp;is for developers who are tired of the effort and frustration that come with code reviews. This tool lets you skip the pull request by simply highlighting a code block and adding a note. This means discussing code with your team simply and directly in the coding environment. Codestream offers support for every programming language and makes group problem solving a simple part of any team’s workflow.</p>



<p><a href="https://www.mantisbt.org/" target="_blank" rel="noreferrer noopener"><strong><u>MantisBT</u></strong></a>&nbsp;is the bug tracker of your dreams. Just like its namesake, the Mantis, this tool leaves no stone unturned in its search for bugs in your code. A web-based bug tracking program, MantisBT tracks your code for errors, and then sends an email notification to you and everyone on your team whenever it finds a problem. Don’t worry —&nbsp;you can customize notifications if an email for every bug isn’t your thing.</p>



<p><a href="https://codeanywhere.com/" target="_blank" rel="noreferrer noopener"><strong><u>Codeanywhere</u></strong></a>&nbsp;is a game-changing tool for teams of developers who need to work together on one code block at the same time. Think of it like Google Docs for code. It’s a code editor that supports more than 70 different programming languages, and allows all users to see who’s working on what in real time. All you have to do to get started is send a link to your code editor to anyone who’s on your team.</p>



<p><a href="https://anydesk.com/en" target="_blank" rel="noreferrer noopener"><strong><u>AnyDesk</u></strong></a><strong>&nbsp;</strong>is for anyone who has a killer desktop setup at work, and a similarly killer desktop setup at home, and wants to be able to work on both of them. Setting up the perfect virtual environment is a pain —&nbsp;and can take literal hours. So instead of doing it for every computer you use to code, just do it once and then use AnyDesk to connect to your work PC from any computer anywhere.</p>



<p><a href="https://tuple.app/" target="_blank" rel="noreferrer noopener"><strong><u>Tuple</u></strong></a><strong>&nbsp;</strong>is for developers who have realized that, as much as they’ve become standard for workers in 2020, Slack and Zoom weren’t made for programmers —&nbsp;and it shows. A trio of software engineers created Tuple to make pair programming easier for remote teams, and the result is an app with simple, high-quality screen sharing, crisp audio, and efficient CPU usage so it has full functionality even on a low-latency connection.</p>



<figure><img loading="lazy" width="970" height="585" src="https://www.7pace.com/wp-content/uploads/2021/01/03-Image-3.jpg" alt="todoist" srcset="https://www.7pace.com/wp-content/uploads/2021/01/03-Image-3.jpg 970w, https://www.7pace.com/wp-content/uploads/2021/01/03-Image-3-300x181.jpg 300w, https://www.7pace.com/wp-content/uploads/2021/01/03-Image-3-768x463.jpg 768w" sizes="(max-width: 970px) 100vw, 970px"></figure>



<p><a href="https://todoist.com/home" target="_blank" rel="noreferrer noopener"><strong><u>Todolist </u></strong></a>is the only to-do list app that’s made just for developers. With just how many list apps exist, you’re probably wondering what makes this one good enough to make our list, so here it is: Todolist allows you to do all the same productivity tasks you’d do with any list app —&nbsp;prioritize tasks, filter and group them, and archive them —&nbsp;but from a code-like environment. You manage everything with simple commands that make it easy to check things off your list and queue up a new project, without breaking your flow.</p>



<p><a href="https://www.figma.com/" target="_blank" rel="noreferrer noopener"><strong><u>Figma</u></strong></a><strong>&nbsp;</strong>is a must-have tool for developers who work with designers, product managers, or product teams. It’s a browser-based tool that gives designers one, single link where they can access crucial information and assets like colors, widths, and heights for design elements.</p>



<h3>Developer Productivity Tools for Breaking Bad Habits (and Forming Good Ones)</h3>



<figure><img loading="lazy" width="970" height="585" src="https://www.7pace.com/wp-content/uploads/2021/01/02-Image-3.jpg" alt="Developer Productivity Tools for Breaking Bad Habits (and Forming Good Ones)" srcset="https://www.7pace.com/wp-content/uploads/2021/01/02-Image-3.jpg 970w, https://www.7pace.com/wp-content/uploads/2021/01/02-Image-3-300x181.jpg 300w, https://www.7pace.com/wp-content/uploads/2021/01/02-Image-3-768x463.jpg 768w" sizes="(max-width: 970px) 100vw, 970px"></figure>



<p><a href="https://habitica.com/" target="_blank" rel="noreferrer noopener"><strong><u>Habitica</u></strong></a><strong>&nbsp;</strong>makes it fun to create good habits at work. Using pixel-like design, Habitica turns you into a hero in an in-platform world where you’re tasked with fighting through daily, weekly, and long-term goals. For completing tasks and building up good habits, you earn points, discover new animals, and build your strength. For failing at tasks, you lose strength — and your character can die. For developers who love gaming, this is an entertaining (and effective) way to build better work habits.</p>



<p><a href="https://justgetflux.com/" target="_blank" rel="noreferrer noopener"><strong><u>F.lux</u></strong></a>&nbsp;is the productivity tool that will save you from dry, tired eyes —&nbsp;a problem for developers everywhere. This tool automatically adjusts your screen color based on your time and location, making colors warmer as it gets dark where you are to make your screen more natural for your eyes in the dark. You can also override the automatic color-changes and set your own schedule, which is a great way to remind yourself to take breaks from the harsh light of your computer screen.</p>



<h3>Developer Productivity Tools for Banishing Distractions</h3>



<p><a href="https://www.sublimetext.com/" target="_blank" rel="noreferrer noopener"><strong><u>Sublime Text</u></strong></a>&nbsp;is designed to be a code editor with an easy-to-use interface and eye-friendly work environment. It allows you to markup and program in a variety of coding languages, while also easily moving across files, switching between projects, and changing specific lines of code. But one of the features we love most about Sublime Text is its built-in distraction mode, which is sort of like a do-not-disturb setting for when you want to deep work.</p>



<p><a href="https://pi-hole.net/" target="_blank" rel="noreferrer noopener"><strong><u>Pi-Hole</u></strong></a><strong>&nbsp;</strong>is for those developers who think there’s nothing more distracting than a webpage ad. Think about it: They clutter up your screen. They reduce network performance. By all accounts, they’re an unnecessary obstacle in the way of productive work. Enter Pi-Hole, an ad-blocker that connects to your router instead of your browser, making it able to provide network-wide ad blocking. Pairing Pi-Hole with a VPN protects every device on your network from ads that distract away from work.</p>



<p><a href="https://getcoldturkey.com/" target="_blank" rel="noreferrer noopener"><strong><u>Cold Turkey</u></strong></a><strong>&nbsp;</strong>requires you to know exactly what your vices are. But then it does a really great job at blocking you from accessing them. Set it up to limit access to certain websites, certain apps, and even your internet access. The result? A work environment that’s free of all distractions for as long as you need it to be, allowing you to work without the usual interruptions.</p>



<h3>Developer Productivity Tools for Getting Into Your Flow</h3>



<p><a href="https://chrome.google.com/webstore/detail/strict-workflow/cgmnfnmlficgeijcalkgnnkigkefkbhd?hl=en" target="_blank" rel="noreferrer noopener"><strong><u>Strict Workflow</u></strong></a><strong>&nbsp;</strong>embraces the research-backed success of the Pomodoro method —&nbsp;the idea that for maximum productivity, you should alternate 25-minute focused sprints with 5-minute breaks. Using the Pomodoro method used to require a timer, but not anymore. Strict Workflow is a Chrome extension that acts as a built-in timer for that uber-effective work-and-break cycle. It runs in the background and lets you know when it’s time to work, and when it’s time to take a breather. No egg timer required.</p>



<figure><img loading="lazy" width="970" height="585" src="https://www.7pace.com/wp-content/uploads/2021/01/04-Image-1.jpg" alt="Developer Productivity Tools for Getting Into Your Flow" srcset="https://www.7pace.com/wp-content/uploads/2021/01/04-Image-1.jpg 970w, https://www.7pace.com/wp-content/uploads/2021/01/04-Image-1-300x181.jpg 300w, https://www.7pace.com/wp-content/uploads/2021/01/04-Image-1-768x463.jpg 768w" sizes="(max-width: 970px) 100vw, 970px"></figure>



<p><a href="https://memory.ai/dewo" target="_blank" rel="noreferrer noopener"><strong><u>Dewo</u></strong></a><strong>&nbsp;</strong>is the tool developers need to combat one of their biggest disruptors: Context switching. Dewo bills itself as users’ “personal assistant for deep work,” and that’s pretty much what it does. The app uses AI to analyze your productivity patterns, and then provides you with insights that should help you figure out how to work not harder, but smarter. Dewo can also toggle a do-not-disturb mode that silences other apps and sets your Slack status to “Away” once you enter a flow state, ensuring that nothing gets in the way of that sweet, sweet deep work.</p>



<p><a href="https://github.com/ggreer/the_silver_searcher" target="_blank" rel="noreferrer noopener"><strong><u>The Silver Searcher</u></strong></a><strong>&nbsp;</strong>is another app for developers that’s meant to minimize wasted time at work —&nbsp;by making it easier to search your code. Think about it: If you’re like a lot of devs, you probably spend a fair amount of your “coding time” actually reading and scanning code, not writing it. The Silver Searcher helps combat that by making it much easier —&nbsp;and much, <em>much</em>&nbsp;faster —&nbsp;to search through code.</p>



<p><a href="https://walrus.ai/" target="_blank" rel="noreferrer noopener"><strong><u>Walrus.ai</u></strong></a><strong>&nbsp;</strong>is yet another app that’s here to save money and effort for teams of developers, this time by automating QA testing. It makes testing more efficient and lightweight by providing full end-to-end testing via a single API call, as opposed to cumbersome in-house automated testing or manual QA. And if you’re concerned about accuracy, Walrus employs a whole team to monitor every run and keep a look out for false positives and negatives.</p>



<p><a href="https://www.programmersmusic.com/" target="_blank" rel="noreferrer noopener"><strong><u>Programmer’s Music</u></strong></a>&nbsp;is the perfect app for the developer that wants the perfect soundtrack for productive work, but doesn’t want to put in the time or effort to curate a playlist his or herself. There are plenty of sites out there that offer curated music lists to <a href="https://www.7pace.com/blog/heres-what-science-says-about-how-music-affects-your-productivity"><u>promote focus and productivity</u></a>, but this one is our favorite because of its non-vocal, distraction free songs that can be timed to the Pomodoro method if you want them to be.</p>



<h3>Developer Productivity Tools for Tracking Time (Hint: You Only Need One)</h3>



<figure><img loading="lazy" width="970" height="585" src="https://www.7pace.com/wp-content/uploads/2021/01/05-Image-1.jpg" alt="Developer Productivity Tools for Tracking Time (Hint: You Only Need One)" srcset="https://www.7pace.com/wp-content/uploads/2021/01/05-Image-1.jpg 970w, https://www.7pace.com/wp-content/uploads/2021/01/05-Image-1-300x181.jpg 300w, https://www.7pace.com/wp-content/uploads/2021/01/05-Image-1-768x463.jpg 768w" sizes="(max-width: 970px) 100vw, 970px"></figure>



<p><a href="https://www.7pace.com/timetracker"><strong><u>7pace Timetracker</u></strong></a>&nbsp;…</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.7pace.com/blog/developer-productivity-tools">https://www.7pace.com/blog/developer-productivity-tools</a></em></p>]]>
            </description>
            <link>https://www.7pace.com/blog/developer-productivity-tools</link>
            <guid isPermaLink="false">hacker-news-small-sites-25989252</guid>
            <pubDate>Mon, 01 Feb 2021 15:06:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Robinhood Misled the Poor and Rewarded the Rich]]>
            </title>
            <description>
<![CDATA[
Score 96 | Comments 89 (<a href="https://news.ycombinator.com/item?id=25989199">thread link</a>) | @iamspoilt
<br/>
February 1, 2021 | https://themeasureofaplan.com/robinhood/ | <a href="https://web.archive.org/web/*/https://themeasureofaplan.com/robinhood/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	
		<!-- site-header -->
		<!-- /site-header --><article>
	
	<!-- post-title -->
	 <!-- /post-title -->

	<p>January 31st, 2021 | Posted in

		<a href="https://themeasureofaplan.com/category/uncategorized/">Uncategorized</a>
		</p>

	<img width="700" height="394" src="https://themeasureofaplan.com/wp-content/uploads/2021/01/Robinhood-header-image.jpg" alt="" loading="lazy" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%20394'%3E%3C/svg%3E" data-lazy-src="https://themeasureofaplan.com/wp-content/uploads/2021/01/Robinhood-header-image.jpg">	
	
    <!-- if URL contains "?v=clean" do not show the mailchimp email sign-up box-->
	        
        	
	
<p>[Feb-1 update: a new section “Clearing Houses &amp; the Plumbing Behind Financial Markets” has been added]</p>
<p>[Feb-2: updated with Robinhood’s Q4 2020 revenues from “payment for order flow”]</p>
<p>&nbsp;<br>
This is a story about Robinhood, an online broker that promised to “democratize finance for all”, but ended up deceiving its customers and helping the rich get richer.</p>
<p>So buckle up — we’re heading off to the moon 🚀🌙! But first, let’s pause for a glance at:</p>
<ul>
<li>A run-down of Robinhood’s business model, and how they were fined $65 million for failing to disclose that most of their revenues come from Wall Street partners</li>
<li>The opaque world of “payment for order flow”, and how this creates massive conflicts of interest for Robinhood</li>
<li>The ongoing GameStop ($GME) saga — where Robinhood conveniently ends up siding with the hedge funds, to the detriment of everyday investors around the globe</li>
</ul>

<h2>The Origins of Robinhood</h2>
<p>Robinhood’s co-founders Vlad Tenev and Baiju Bhatt were roommates at Stanford, and set off after graduation to work in New York, building trading software for hedge funds <em>(note to reader: this is one of many ties to the hedge fund world that we’ll come across)</em>.</p>
<p>In 2013, Vlad and Baiju decided to strike off on their own and launched Robinhood — an online platform that allowed investors to trade stocks, ETFs, and other financial assets without paying trading commissions.</p>
<p>At the time, competing brokers were charging $5 to $10 per trade, so Robinhood’s free model helped them to win the trust of millions of customers across America.</p>
<p>Fueled by crisp marketing, simple user interfaces, and their no-fee model, Robinhood grew by leaps and bounds over the next few years. The company now boasts more than 13 million customers, 1,200 employees, and a valuation of $11 billion after raising funds in August 2020.</p>
<p>The chart below from <a href="https://www.ft.com/content/b208cbbe-579c-4cbf-9358-01ae02b4381b" rel="noopener" target="_blank">FT and Pitchbook</a> captures Robinhood’s meteoric rise:</p>
<p><img src="https://themeasureofaplan.com/wp-content/uploads/2021/01/Robinhood-post-money-valuation-timeline-FT.png" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-src="https://themeasureofaplan.com/wp-content/uploads/2021/01/Robinhood-post-money-valuation-timeline-FT.png"></p>

<h2>Robbing the Hood and Giving to the Rich?</h2>
<p>All was green and all was good for Robinhood and the merry men.</p>
<p>Their founders made proud claims that “we believe the financial system should be built to work for everyone”, and <a href="https://www.ft.com/content/c3ed6758-e51c-48b1-b6a6-a17ccb265b28" rel="noopener" target="_blank">“we didn’t build Robinhood to make the rich people richer”</a>.</p>
<p>However, these claims don’t hold up to close scrutiny.</p>
<p>In December 2020, the SEC (America’s financial markets regulator) <a href="https://www.sec.gov/news/press-release/2020-321" rel="noopener" target="_blank">fined Robinhood $65 million</a> for “misleading customers about revenue sources and failing to satisfy duty of best execution”.</p>
<p>This investigation shined a light on how Robinhood was operating beneath the glitzy marketing and lip service towards democratizing finance.</p>
<p>Excerpts from the <a href="https://www.sec.gov/news/press-release/2020-321" rel="noopener" target="_blank">SEC press release</a> (my emphasis added):</p>
<p>According to the SEC’s order, between 2015 and late 2018, <b>Robinhood made misleading statements and omissions in customer communications, including in FAQ pages on its website</b>, about its largest revenue source when describing how it made money – namely, payments from trading firms in exchange for Robinhood sending its customer orders to those firms for execution, also known as “payment for order flow.”</p>
<p>As the SEC’s order finds, one of Robinhood’s selling points to customers was that trading was “commission free,” but due in large part to its unusually high payment for order flow rates, <b>Robinhood customers’ orders were executed at prices that were inferior to other brokers’ prices</b>.  Despite this, according to the SEC’s order, Robinhood falsely claimed in a website FAQ between October 2018 and June 2019 that its execution quality matched or beat that of its competitors.</p>
<p>The order finds that <b>Robinhood provided inferior trade prices that in aggregate deprived customers of $34.1 million even after taking into account the savings from not paying a commission</b>.  Robinhood made these false and misleading statements during the time in which it was growing rapidly.</p>
<p>“Robinhood failed to seek to obtain the best reasonably available terms when executing customers’ orders, causing customers to lose tens of millions of dollars,” said Joseph Sansone, Chief of the SEC Enforcement Division’s Market Abuse Unit.  “Today’s action sends a clear message that the Commission will not allow brokers to ignore their obligations to customers.”</p>
<p>&nbsp;<br>
In other words:</p>
<ul>
<li>Robinhood was selling its customers’ trade data to market makers and high-frequency traders — Wall Street firms that profit off of these trades</li>
<li>This is Robinhood’s largest source of revenue — a fact that they curiously left out on their FAQ page describing how they made money</li>
<li>This practice meant that trades placed on Robinhood weren’t executed at the best price, costing customer tens of millions of dollars, <b>even after taking into account the savings from not paying a commission</b></li>
</ul>
<p>One more time: Robinhood lied about their business model, made money by selling customer data to Wall Street, at the ultimate expense of its own customers.</p>
<p>If you’re looking for other reasons to get riled up, how about this other time Robinhood was fined for <a href="https://www.finra.org/media-center/newsreleases/2019/finra-fines-robinhood-financial-llc-125-million-best-execution" rel="noopener" target="_blank">failing to protect their customers’ best interest</a>, or when Robinhood improperly stored their customers’ passwords, leading to <a href="https://www.bloomberg.com/news/articles/2020-10-15/robinhood-estimates-hackers-infiltrated-almost-2-000-accounts" rel="noopener" target="_blank">2,000 accounts being compromised and having funds siphoned off</a>.</p>
<p>Next — let’s dive into how the murky world of “payment for order flow” works, how Robinhood makes money from it, and why this makes Robinhood beholden to their Wall Street partners.</p>

<h2>Sally Schmo and “Payment for Order Flow”</h2>
<p>As we saw above, Robinhood’s main revenue source comes from selling customer trade data to other firms. This is a controversial practice known as “Payment for Order Flow” (PFOF in financial regulatory lingo).</p>
<p>To give you a sense of it, PFOF was <a href="https://web.archive.org/web/20200817124549/https://money.cnn.com/2000/05/29/investing/q_madoff/" rel="noopener" target="_blank">pioneered by Bernie Madoff</a> (one of history’s greatest con men), and the practice is <a href="https://www.gbm.scotiabank.com/content/dam/gbm/market-insights/etf/october/2019-10-02-Free-Trading.pdf" rel="noopener" target="_blank">banned in Canada</a>.</p>
<p>It’s a bit of a tangled web, so I’ve created the graphic below to lay it out in steps:</p>
<p><img src="https://themeasureofaplan.com/wp-content/uploads/2021/01/Robinhood-NOK-order-flow-v3.png" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-src="https://themeasureofaplan.com/wp-content/uploads/2021/01/Robinhood-NOK-order-flow-v3.png"></p>
<p>Let’s take the example of a Robinhood customer who wants to buy 100 shares of Nokia (NOK).</p>
<ol>
<li>Investor submits an order to buy 100 shares of $NOK at a max price of $4.00 per share ($400 total)</li>
<li>Broker asks the market maker (MM) to find 100 shares of $NOK</li>
<li>MM buys 100 shares of $NOK at the best price it can find — $398 in this example – and collects $2 of profit</li>
<li>Stock exchange delivers 100 shares of $NOK to the MM</li>
<li>MM delivers 100 shares and gives the broker a cut of the profit (aka, PFOF)</li>
<li>Broker delivers 100 shares of $NOK to the investor for a total of $400</li>
</ol>
<p>After all is said and done, the market maker and Robinhood walk away with $2 in profit, and the investor receives 100 shares of Nokia for $400.</p>
<p>The example above is simplified and uses dummy numbers, but the concept holds true.</p>
<p>Robinhood doesn’t carry out customer orders itself, it routes them to MMs (such as Citadel) for the MM to execute.</p>
<p>The MM buys the requested shares for a price, resells those shares to the Robinhood customer at a slightly higher price, pockets the difference, and shares some of the profits with Robinhood.</p>
<p>So what’s the big deal? Why does “payment for order flow” harm the everyday investor?</p>
<p>When you place an order on Robinhood, you don’t get transparency on what the best price was, whether your order was executed at that best price, and how much profit was captured by the MM / Robinhood in the process.</p>
<p>Even though Robinhood customers don’t pay commissions on their trades (the $5 to $10 per trade that brokers used to charge), there is an “invisible cost” to the customer since they are paying more for the shares that they trade.</p>
<p>Taking this from a different angle, why does the MM pay Robinhood for the order? If the MM wasn’t able to make a profit on the execution of these trades what would be in it for them?</p>
<p>Keep in mind that Robinhood was fined $65 million by the SEC because Robinhood customers weren’t getting the best price on their trades, and since Robinhood misled their customer about this practice.</p>

<h2>How Much Does Robinhood Earn from “Payment for Order Flow”?</h2>
<p>According to <a href="https://cdn.robinhood.com/assets/robinhood/legal/RHS%20SEC%20Rule%20606a%20and%20607%20Disclosure%20Report%20Q4%202020.pdf" rel="noopener" target="_blank">Robinhood’s regulatory filings for Q4 2020</a>, Robinhood made a whopping $221 million in revenue from PFOF in Q4 2020 alone.</p>
<p>I’ve tabulated the data in a spreadsheet (<a href="https://drive.google.com/drive/u/0/folders/1pM7iQqZejiZIzmzX8XW36hQft7xJ2Hyt" rel="noopener" target="_blank">available here</a>), and have broken out their revenue from each partner:</p>
<p><img src="https://themeasureofaplan.com/wp-content/uploads/2021/02/Robinhood-Q4-2020-payment-for-order-flow-revenues.png" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-src="https://themeasureofaplan.com/wp-content/uploads/2021/02/Robinhood-Q4-2020-payment-for-order-flow-revenues.png"></p>
<p>Nearly half of Robinhood’s PFOF revenues — $108 million in Q4 2020 alone — come from Citadel. 🚨🚨 Remember that name, as they’ll feature prominently in the epic struggle for GameStop stock that follows.</p>
<p>Citadel is a hedge fund and market maker. Its success has vaulted founder Ken Griffin to a <a href="https://en.wikipedia.org/wiki/Kenneth_C._Griffin" rel="noopener" target="_blank">net worth of more than $20 billion</a>. Technically, the two sides of Citadel (hedge fund / market maker) are split into two separate arms — but they are both under <a href="https://en.wikipedia.org/wiki/Citadel_LLC" rel="noopener" target="_blank">one parent company</a> and both arms are owned by Ken Griffin.</p>
<p>As a side note, Citadel Securities (the market marker arm) has been fined numerous times in the past, for activities such as <a href="https://www.sec.gov/news/pressrelease/2017-11.html" target="_blank" rel="noopener">“misleading customers about pricing trades”</a>, <a href="https://www.bloomberg.com/news/articles/2020-07-21/citadel-securities-fined-by-finra-for-trading-ahead-of-clients" rel="noopener" target="_blank">“trading ahead of clients”</a>, and <a href="https://www.ft.com/content/16cee174-3b7f-11ea-b232-000f4477fbca" rel="noopener" target="_blank">“trading rule violations”</a>.</p>
<p>To reiterate — Robinhood makes hundreds of millions of dollars per quarter from selling customer data to Wall Street firms such as Citadel. These firms profit off of this ‘order flow’. And Robinhood has a documented history of misleading customers about these relationships.</p>
<p>So who is Robinhood beholden to: its customer — the general public who trades on the platform — or the Wall Street firms who profit off of these trades?</p>
<p>What was that in the back? Did someone say “conflict of interest”?</p>
<p>And yes, it’s true that most other brokers also make money from PFOF, but none rely on it nearly as much as Robinhood does.</p>
<p>From <a href="https://www.morningstar.ca/ca/news/208445/robinhood-was-indeed-too-good-to-be-true.aspx" rel="noopener" target="_blank">Forbes / Morningstar</a>:</p>
<p>In the first quarter of 2020, 70% of Robinhood’s revenues derived from payments for order flows, as opposed to 17% for E-Trade and just 3% for Schwab. Yes, Robinhood has observed standard practice–but with distinctly above-average enthusiasm.</p>
<p>Enough about PFOF. Let’s get to the action of the GameStop story to see how conflict of interest plays out in a live situation.</p>

<h2>$GME and Me</h2>
<p>You’ve likely all heard this story already but I’ll …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://themeasureofaplan.com/robinhood/">https://themeasureofaplan.com/robinhood/</a></em></p>]]>
            </description>
            <link>https://themeasureofaplan.com/robinhood/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25989199</guid>
            <pubDate>Mon, 01 Feb 2021 14:59:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reframing Imposter Syndrome]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25989195">thread link</a>) | @staccatomeasure
<br/>
February 1, 2021 | https://staysaasy.com/leadership/2021/01/31/reframing-imposter-syndrome.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/leadership/2021/01/31/reframing-imposter-syndrome.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>For about year when I worked at a 50-person startup, the most common thought that I had was “I have no idea what I’m doing.”</p>

<p>What should we build next? How should we set up a good process for performance reviews? How do we get more people to want to buy our product? Are we shipping too many bugs? Are we overly conservative and shipping too few? Almost every day involved at least one strategic decision that I didn’t feel that I had the qualifications to make.</p>

<p>These moments could be unsettling, and in retrospect I had a classic, low-grade case of imposter syndrome. I felt like I was playing in a band and improvising while everyone else knew the music. With the benefit of hindsight and substantially more experience, I wanted to write up a few thoughts on scaling companies to reframe this imposter syndrome in a more realistic light.</p>

<h2 id="everybody-is-improvising">Everybody is Improvising</h2>

<p>As that same company grew to over 500 people, I kept waiting for the magic moment where I (or others) suddenly knew how to handle the decisions that came our way. As a 50-person company we figured things out as we went along, or made the best call we could with imperfect processes, data, and first-principles thinking. After growing over 10x larger, the problems changed, the processes and data improved, but the approach didn’t.</p>

<p>In retrospect this should have been obvious. Every company and team is different, and there is no sheet music to play from.</p>

<p>Even startups that are widely considered to be successful still need to figure stuff out the old-fashioned way:</p>

<ul>
  <li>People at all levels of the organization, including the highest-level executives, often reason from first principles. There are techniques that one can learn to be more effective; there is no manual for how to respond to any arbitrary new situation.</li>
  <li>Most decisions are made with imperfect or incomplete information.</li>
  <li>Company leadership does not have all the answers, and very smart people make both brilliant decisions and damaging strategic errors.</li>
  <li>Experienced leaders are also capable of being irrational, reacting in an emotionally driven way, or surrendering to groupthink of various forms. People struggle, question decisions that they’ve made, and generally stress out.</li>
</ul>

<p>Simply put, if you’re feeling like a fraud for needing to figure things out from first principles, know that almost everyone else is doing the same at least from time-to-time (although experienced people do tend to have a more zen attitude and realize that it’s just a part of the process). All startups are messy, and things get done by smart people making the best decisions they can with the data and resources that they have. There is no secret cabal of “grownups” who know the secret to scaling companies.</p>

<h2 id="but-experts-are-actually-better-in-some-ways">But Experts Are Actually Better In Some Ways</h2>

<p>Of course, experience is extremely beneficial. I find that there are generally two major areas in which experience matters. Neither of them should make you feel like an imposter, and neither will give you definitive answers on how you should operate your company.</p>

<p>The first important dimension is that experts have a really wide portfolio of operating techniques. To extend the music analogy, these techniques are like chords or guitar licks that you can learn and later use to improvise. It might take a while to build a repertoire, but most startup techniques are straightforward and can be learned through reading, advice, or practice. These are technical skills, not God-given talents.</p>

<p>The other area where experience is critical, is giving you reps in challenging situations. Examples include:</p>

<ul>
  <li>How do you know if you’re wasting time on something unimportant? How do you know what to half-ass vs. whole-ass?</li>
  <li>How do you handle stress over long periods of time? How do you strike a balance between optimism and realism with your team? How do you stay calm in the face of pressure? How do you know when you or someone on your team is burning out?</li>
  <li>How do you handle difficult situations? What do you do the first time someone has a personal tragedy on your team, when you have to fire someone on your team?</li>
  <li>How do you know if a struggling team member’s performance is salvageable, or if they’re unlikely to be able to turn things around?</li>
</ul>

<p>For these skills, the fact of the matter is you just need to live through a lot of situations to build strength at identifying patterns and preparing your mind for future situations. In the musical performance of a startup, these skills are like practicing until your fingers are strong and you can easily play whatever comes your way.</p>

<h2 id="takeaways">Takeaways</h2>

<p>Decision-making from first principles is the default at most companies, even successful ones. There is no sheet music for running your team or business.</p>

<p>Experience can give you more operating techniques and build the muscle required to be a good manager or leader. We try to write about these transferable techniques and perspectives. But there is no playbook that will teach you how to make the right decisions.</p>


    

    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/leadership/2021/01/31/reframing-imposter-syndrome.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25989195</guid>
            <pubDate>Mon, 01 Feb 2021 14:59:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You are wrong about the RISC-V SFENCE.VMA instruction]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25989139">thread link</a>) | @azhenley
<br/>
February 1, 2021 | https://blog.stephenmarz.com/2021/02/01/wrong-about-sfence/ | <a href="https://web.archive.org/web/*/https://blog.stephenmarz.com/2021/02/01/wrong-about-sfence/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	
	<!-- Custom Header -->
		
	
	
	<!--Header Info-->	
	
	<!--/End of Header Info-->
	
	<nav role="navigation">
        
    </nav>
	
		<!-- Breadcrumb Start-->
	<!--========== Breadcrumb ==========-->

<!--========== END Breadcrumb ==========-->	<!-- Breadcrumb End single.php-->
<section id="content">
    <div>
		<div>
							<div>
									<div>
						
						<div>
							
													
							<div>
								
								<div>
									
<p>This post is part of a longer OS tutorial which can be found here: <a href="https://osblog.stephenmarz.com/">https://osblog.stephenmarz.com</a></p>



<h2>Contents</h2>



<ol><li><a href="#s_introduction">Introduction</a></li><li><a href="#s_what_is_satp">What is SATP?</a></li><li><a href="#s_what_is_sfence">What is SFENCE.VMA?</a></li><li><a href="#s_what_is_happening">What is happening?</a></li><li><a href="#s_the_tlb">The Translation Lookaside Buffer</a></li><li><a href="#conclusion">Conclusion</a></li><li><a href="#references">References</a></li></ol>



<hr>



<h2 id="s_introduction">Introduction</h2>



<p>My <a href="https://blog.stephenmarz.com/2020/11/23/back-that-s-up/" data-type="post" data-id="613">last post</a> garnered some attention by those telling me that I “forgot” to execute an SFENCE.VMA after I wrote to the SATP register–some with more tact than others. This post is here to clarify why I did what I did, and to clarify what the specification actually tells us needs to be done.</p>



<hr>



<h2 id="s_what_is_satp">What is SATP?</h2>



<p>The <em>supervisor address translation and protection</em> (SATP) register is a register that tells the MMU what mode it’s in, what address space it is working in, and where to find the first level page table in RAM (this would be level 2 for Sv39).</p>



<div><figure><img loading="lazy" src="https://blog.stephenmarz.com/wp-content/uploads/2020/12/image-1024x76.png" alt="" width="512" height="38" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/12/image-1024x76.png 1024w, https://blog.stephenmarz.com/wp-content/uploads/2020/12/image-300x22.png 300w, https://blog.stephenmarz.com/wp-content/uploads/2020/12/image-768x57.png 768w, https://blog.stephenmarz.com/wp-content/uploads/2020/12/image-1536x114.png 1536w, https://blog.stephenmarz.com/wp-content/uploads/2020/12/image-2048x153.png 2048w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>The SATP Register Fields</figcaption></figure></div>



<p>The SATP register stores three pieces of information, the MODE, the address space identifier (ASID), and the physical page number (PPN).</p>



<h4>The MODE</h4>



<p>If the MODE=0, then the MMU is turned off and any address is not translated. </p>



<p>If MODE=8, we’re in Sv39 (Supervisor 39-bit) mode which means that our virtual addresses are 39-bits long.</p>



<p>There are other modes, but I won’t cover them here.</p>



<h4>The ASID</h4>



<p>The address space identifier tags translations with a unique identifier.</p>



<h4>The PPN</h4>



<p>The physical page number is the upper 44-bits of a 56-bit memory address where we can find the first level page table.</p>



<hr>



<h2 id="s_what_is_sfence">What is SFENCE.VMA?</h2>



<p>In absolute terms, this means <em>supervisor fence</em>.<em>virtual memory address</em>. In real terms, it will flush the cache’s so that the MMU will “see” the new changes in memory. This means that the MMU will be forced to look in RAM where the page tables are stored.</p>



<p>The SFENCE.VMA instruction has several different ways to execute it as shown in the specification. This should clue us in to the fact that executing SFENCE.VMA every time we write to SATP might not be so cut and dry.</p>



<hr>



<h2 id="s_what_is_happening">What is Happening?</h2>



<p>So, why is this not straightforward? The issue is that “walking” a page table–meaning going into RAM and translating a virtual address into a physical address–is not a fast process. There are multiple levels of page tables, and several 8-byte entries that need to be dereferenced by the memory controller.</p>



<p>We can speed these walks up by “caching” frequently translated addresses into a table. The table has the virtual address number and the physical address number, so translation is just a table lookup instead of dereferencing several levels of page tables.</p>



<p>This caching can be speculative. If the MMU doesn’t speculate, then the first time we translate an address, that address will not be in the TLB (the cache table) and we will get what is known as a <em>compulsory miss</em>. If we speculate, we can predict the addresses that will be used and when the memory controller isn’t doing anything else, we can load the virtual address and physical address into cache.</p>



<p>This speculation is one of the reasons for SFENCE.VMA. Another reason is due to the fact that when we translate a page using the MMU, it stores the most recent translations in the TLB as well. </p>



<hr>



<h2 id="s_the_tlb">The Translation Lookaside Buffer</h2>



<p>The translation lookaside buffer or TLB is a fancy term for the MMU cache. It stores the most recent translations to exploit <em>temporal locality</em>–that is, the chances we’re going to translate the same address near in the future is likely. So, instead of having to walk the page tables all over again, we just look in the TLB.</p>



<p>The TLB has several entries, and with RISC-V, it stores an address space identifier (ASID). The address space identifier allows the TLB to store more entries than just the most recent page table. This has always been a problem with TLBs, including with the Intel/AMD processor. Writing to its MMU register (called CR3 for control register #3) will cause a TLB flush. This is NOT the case with RISC-V writing to the SATP register (the MMU register in RISC-V).</p>



<p>The specification just gives the general rules for a manufacturer to use. Therefore, the manufacturer can choose how they want to implement their MMU and TLB as long as it complies with RISC-V’s privileged specification. Here’s a simple implementation of a TLB that complies with the privileged specification.</p>



<hr>



<h2 id="conclusion">Conclusion</h2>



<p>The RISC-V specification doesn’t make it very clear, but you can see clarification on the spec’s github repository. If the MODE is not 0, then the MMU is allowed to <em>speculate</em>, meaning it can pre-populate the MMU based on the addresses it <em>thinks</em> will need to be translated in the near future. The specification allows this, but the MMU cannot throw a page fault if a speculatory translation is invalid.</p>



<p>So, bottom line — SFENCE.VMA should NOT be called every time SATP is changed. This will cause TLB thrashing since every time you context switch, you will need to change the SATP register to the kernel page table, schedule, then change the SATP register to the new scheduled process’ page table.</p>



<p>Instead, the SFENCE.VMA instruction should be invoked when one or more of the following occur:</p>



<ol><li>When software recycles an ASID (i.e., reassociates it with a different page table), it should first change satp to point to the new page table using the recycled ASID, then execute SFENCE.VMA with rs1=x0 and rs2 set to the recycled ASID. Alternatively, software can execute the same SFENCE.VMA instruction while a different ASID is loaded into satp, provided the next time satp is loaded with the recycled ASID, it is simultaneously loaded with the new page table.</li><li>If the implementation does not provide ASIDs, or software chooses to always use ASID 0, then after every satp write, software should execute SFENCE.VMA with rs1=x0. In the common case that no global translations have been modified, rs2 should be set to a register other than x0 but which contains the value zero, so that global translations are not flushed.</li><li>If software modifies a non-leaf PTE, it should execute SFENCE.VMA with rs1=x0. If any PTE along the traversal path had its G bit set, rs2 must be x0; otherwise, rs2 should be set to the ASID for which the translation is being modified.</li><li>If software modifies a leaf PTE, it should execute SFENCE.VMA with rs1 set to a virtual address within the page. If any PTE along the traversal path had its G bit set, rs2 must be x0; otherwise, rs2 should be set to the ASID for which the translation is being modified.</li><li>For the special cases of increasing the permissions on a leaf PTE and changing an invalid PTE to a valid leaf, software may choose to execute the SFENCE.VMA lazily. After modifying the PTE but before executing SFENCE.VMA, either the new or old permissions will be used. In the latter case, a page fault exception might occur, at which point software should execute SFENCE.VMA in accordance with the previous bullet point.</li></ol>



<p>Unfortunately, you have to dig through the issues and updates to the specification on GitHub to find out some of this information. I have provided links in references below.</p>



<hr>



<h2 id="references">References</h2>



<ul><li><a href="https://github.com/riscv/riscv-isa-manual/issues/226">SFENCE.VMA Before or After SATP Write · Issue #226 · riscv/riscv-isa-manual (github.com)</a></li><li><a href="https://github.com/riscv/riscv-isa-manual/issues/538">Can cached translations be visible when translation is off? · Issue #538 · riscv/riscv-isa-manual (github.com)</a></li><li><a href="https://github.com/riscv/riscv-isa-manual/commit/4a29140ef57e38532b3d3e43c9cd49e07066e7e0">PMP changes need an SFENCE when VM is enabled · riscv/riscv-isa-manual@4a29140 (github.com)</a></li><li><a href="https://github.com/riscv/riscv-isa-manual/issues/9">Reconsider SFENCE.VM/ASIDs · Issue #9 · riscv/riscv-isa-manual (github.com)</a></li></ul>
								</div>
							</div>
						</div>
							
				</div>
			</div>
			
		</div><!--/.row-->
	</div> <!--/.container-->
</section>

<!-- Footer Widget Secton -->
   <!--start footer-->
	    
		<hr>
				
		
	</div></div>]]>
            </description>
            <link>https://blog.stephenmarz.com/2021/02/01/wrong-about-sfence/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25989139</guid>
            <pubDate>Mon, 01 Feb 2021 14:53:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dealing with poor rendering performance using will-change CSS property]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25989090">thread link</a>) | @fullstackwife
<br/>
February 1, 2021 | https://spartez-software.com/blog/2021/02/01/analysis-of-rendering-performance-issues-in-whiteboards | <a href="https://web.archive.org/web/*/https://spartez-software.com/blog/2021/02/01/analysis-of-rendering-performance-issues-in-whiteboards">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        

        <main id="page-content">
            
<section>
    <p><img src="https://spartez-software.com/assets/people/spartans560-2379.jpg" alt="Grzegorz Tańczyk">
        
    
    <time>Feb 1st, 2021</time>
</p>

    
</section>
<section>
    <div>
        <div>
            <article>
                                    <div>
                                                <div>
    <p><a href="https://spartez-software.com/products/whiteboards-for-jira">Whiteboards</a> is a real-time application designed for people who want to collaborate on visual elements like shapes, lines, images, or drawings, for managing their work, supporting an online meeting, or drawing diagrams.
</p>

<p>There are several challenges connected to this objective across the entire stack. Client-side performance is one of them.
</p>



<h2>How to implement real-time collaboration canvas</h2>

<p><span></span>Before we start digging into specifics of Whiteboards, let's have a look at the landscape of possible ways of implementing a collaboration canvas:
</p>

<ul>
<li>Native application</li>
<li>Web application
<ul>
<li>HTML5 Canvas API</li>
<li>SVG</li>
<li>DOM-based</li>
<li><strong>Hybrid of DOM, SVG, and HTML5 Canvas API</strong></li>
</ul></li>
</ul>

<p>Whiteboards are going the last way, as it allows us to maintain rapid development pace, good maintainability, better accessibility and interactions, and what’s most important in case of performance: leveraging existing tools and optimizations of web browser engines.
</p>

<p><img src="https://spartez-software.com/assets/traditional-setup-2-(1).png" alt="Online Collaboration on Whiteboards" width="760" height="429"><br>
</p>

<h2>Detecting performance issues</h2>

<p><span></span>A problem can be discovered either with synthetic tests or through user feedback. While we would love to avoid the latter method, because it means dissatisfaction with the product, sometimes it’s the only way to discover unusual combinations of content and the environment.
</p>

<p>Rendering performance can be expressed in an industry-standard metric: <strong>frame rate</strong>, which means how often the content is painted on the screen within one second. High frame rate means:
</p>

<ul>
<li>smooth interactions, unnoticeable delay between user action, and visual feedback;</li>
<li>low consumption of resources: memory, GPU, CPU, and what’s most important: the battery.</li>
</ul>

<p>Web applications rarely function in a vacuum and need to compete for resources with other processes. For Whiteboards, it’s a common situation to fight for CPU with Zoom or Google Meet. <br>End users especially at work usually don’t have top-notch computers, which means not enough memory, no dedicated GPU, and not so modern CPU.
</p>

<p>That’s why it’s important to keep our performance footprint as low as possible.
</p>

<p>Let’s start from customer feedback:
</p>

<blockquote><strong>"performance </strong>- using the whiteboard at train level (80+ users), the tool shows poor performance in terms of reactivity: moving a block can result in a real shift of the element with a delay in time of 3 to 5 seconds. Our need is to use the whiteboard managing together up to 7 agile teams planning 5 sprint each one, plus dependencies board all in the same physical whiteboard"
</blockquote>

<p>Our tool is designed to work fine at such a scale, so it was disappointing to learn that we failed to deliver on this promise. Keeping emotions aside, we should start from the decomposition of the problem into facts:
</p>

<ul>
<li>80 users → 7 teams → 5 sprints each → ~10 issues per sprint + companioning content → more than 100 visual elements on the screen → some of them moving all the time including cursors;</li>
</ul>

<p>Our assumptions, and guiding principles:
</p>

<ul>
<li>elements that are not visible in the viewport should not affect performance and responsiveness;</li>
<li>interactions such as zooming, scrolling, modifying elements should be smooth regardless of the number of elements visible on the screen. </li>
</ul>

<h2>Creating a test environment</h2>

<p><br>The problem can occur for many reasons: networking, server-side performance, application state management, style recalculations, layout, or rendering performance. In this blog post and during the analysis exercise I’m focusing on the last problem: rendering, which is the most expensive part of the page display pipeline:
</p>

<p><img src="https://spartez-software.com/assets/image-20210131-113850.png" alt="Page Display Pipeline" width="944" height="144"><sup>                                                                                                                                                                                      Source: </sup><a href="https://developers.google.com/web/fundamentals/performance/rendering/simplify-paint-complexity-and-reduce-paint-areas" title="https://developers.google.com/web/fundamentals/performance/rendering/simplify-paint-complexity-and-reduce-paint-areas" data-renderer-mark="true"><sup>developers.google.com</sup></a><sup>, licensed under the </sup><sup><a href="https://creativecommons.org/licenses/by/4.0/" title="https://creativecommons.org/licenses/by/4.0/" data-renderer-mark="true">Creative Commons Attribution 4.0 License</a></sup>
</p>





<p>My test environment consists of 350 elements, cards, lines, shapes, and drawings of various sizes layout and content:
</p>

<p><img src="https://spartez-software.com/assets/image-20210131-104417.png" alt="Whiteboards Test Environment" width="935" height="542">
</p>

<p>It does not seem to be a lot of content, so let’s jump into the basic testing procedure.
</p>



<h2>Collecting performance metric</h2>

<p><span></span>My performance smoke test procedure is straightforward: zoom in/zoom out, scroll around. That’s what a user would do as well, and my goal is to have those interactions as smooth as possible. Fortunately, I quickly notice a problem: zooming seems to be clunky. I’m not fully confident about scrolling performance either:
</p>

</div>

                    </div>
                                    <div>
                                                    <p>
        <iframe src="https://www.youtube.com/embed/hoQbwgzrAEA?rel=0&amp;showinfo=0" frameborder="0" allowfullscreen="" data-track="embed-video-iframe"></iframe>
    </p>

                    </div>
                                    <div>
                                                <div>
    

<p>This is additionally embarrassing as it did not require creating enormous test data set to notice the problem, so the likelihood of noticing this issue as an end-user is very high.
</p>

<p>Having this observation I can jump into metrics:
</p>

<h3>CPU/GPU/Memory</h3>



</div>

                    </div>
                                    <div>
                                                    <h2>Scrolling</h2>
                                                    <p>
        <iframe src="https://www.youtube.com/embed/aL7JYY4ahpg?rel=0&amp;showinfo=0" frameborder="0" allowfullscreen="" data-track="embed-video-iframe"></iframe>
    </p>

                    </div>
                                    <div>
                                                    <h2>Zooming</h2>
                                                    <p>
        <iframe src="https://www.youtube.com/embed/JEaBiAFAF6Q?rel=0&amp;showinfo=0" frameborder="0" allowfullscreen="" data-track="embed-video-iframe"></iframe>
    </p>

                    </div>
                                    <div>
                                                <div>
    

<p>Looks like a problem as CPU usage goes up unexpectedly high.
</p>

<h3>Frame rate</h3>

<p><span></span>It is possible to measure the frame rate in at least two ways:
</p>

<ul>
<li>Inside the application itself using the requestAnimationFrame function, which is supposed to execute the callback once the browser is ready for the next paint;</li>
<li>Using browser dev tools.</li>
</ul>

<p>This measurement is supposed to confirm my prior observations, it will not reveal new problems.
</p>

<p>I’m using both tools actually:
</p>

<ol>
<li>Whiteboards mini-devtools show ~12 FPS</li>
<li>Chrome frame rendering stats highlight lots of frames dropped</li>
</ol>

<p>Both facts mean that the browser was not able to render all frames on time, so scrolling/zooming with mouse or touchpad did not result in visual feedback.
</p>

</div>

                    </div>
                                    <div>
                                                    <p>
        <iframe src="https://www.youtube.com/embed/_QAfo9On_c0?rel=0&amp;showinfo=0" frameborder="0" allowfullscreen="" data-track="embed-video-iframe"></iframe>
    </p>

                    </div>
                                    <div>
                                                <div>
    

<h3>Paint flashing</h3>

<p><span></span>Using my prior experience, I immediately switched to <a href="https://developers.google.com/web/fundamentals/performance/rendering/simplify-paint-complexity-and-reduce-paint-areas#use_chrome_devtools_to_quickly_identify_paint_bottlenecks">this handy tool</a> useful for analyzing what is being rendered by the browser. While hovering over various elements, I can see that they are being repainted:
</p>

</div>

                    </div>
                                    <div>
                                                    <p>
        <iframe src="https://www.youtube.com/embed/v8Bd9JrVZ7o?rel=0&amp;showinfo=0" frameborder="0" allowfullscreen="" data-track="embed-video-iframe"></iframe>
    </p>

                    </div>
                                    <div>
                                                <div>
    

<p>This is expected - on hover, the application is adjusting the element so it is ready for interaction. There is no performance problem here.
</p>

<p>I can see the actual problem when zooming or scrolling. Pretty much everything is repainted:
</p>

<p><img src="https://spartez-software.com/assets/image-20210131-111213.png" alt="" width="979" height="462"><br>
</p>



<h2>Background grid seems to be a problem</h2>

<p>The grid is supposed to show lines accordingly to the current zoom, and viewport position, so that the content feels attached to space.
</p>

<p>It seemed to be a perfect suspect: grid is a html5 canvas, re-rendered accordingly to zoom/scroll on each frame, however disabling it did not improve the situation.
</p>

<p> <a href="https://spartez-software.com/products/whiteboards-for-jira">Whiteboard</a> content is still repainted:
</p>

<p><img src="https://spartez-software.com/assets/image-20210131-111615.png" alt="Background grid problem in Whiteboards" width="979" height="463"><br>
</p>

<h2>Common sense: you should not re-render content if it did not change</h2>

<p>It is reasonable to expect from browser to render Whiteboards at a low cost, because in the end, this is just a website, quite lightweight compared to sites you usually visit, that are filled with rich content, images, videos, animations, ads, trackers, social media scripts, etc.
</p>

<p><img src="https://spartez-software.com/assets/image-20210131-112127.png" alt="" width="470" height="470"><br>
</p>

<p>This is the browser's responsibility to render such content in the most effective way. We don’t want to implement our own rendering engine, the Chromium team at Google has much more expertise than we will ever get. This is also not our business objective.
</p>

<p>Whiteboards client is a React application, and from an application state management perspective - everything seemed to be fine. The only property that was changed during the interaction was CSS <strong>transform</strong> on the container element, so we expected everything to work fine - yet it did not!
</p>



<h2>The solution</h2>

<p><span></span>It would take a whole new blog post to explain the solution. Fortunately, I can simply drop <a href="https://developers.google.com/web/fundamentals/performance/rendering/simplify-paint-complexity-and-reduce-paint-areas">a link here</a>:
</p>

<p>Long story short:
</p>

<ul>
<li>the problem was managed with <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/will-change" title="https://developer.mozilla.org/en-US/docs/Web/CSS/will-change" data-renderer-mark="true"><strong>will-change</strong> CSS property</a>;</li>
<li>it creates temporary visual artifacts when zooming;</li>
<li>background grid must be refactored so that literally nothing will be painted during scroll/zoom.</li>
</ul>

</div>

                    </div>
                                    <div>
                                                    <p>
        <iframe src="https://www.youtube.com/embed/PZJM1Nj-CRY?rel=0&amp;showinfo=0" frameborder="0" allowfullscreen="" data-track="embed-video-iframe"></iframe>
    </p>

                    </div>
                                    <div>
                                                <div>
    

<p>This solution was developed a long time ago (6 months before this blog post), but it did not go live, because of the visual artifacts.
</p>

<p>Fortunately, as of February 2021, the browser rendering engine seems to be improved, and our problems are gone, so we will be enabling it shortly.
</p>

<p>Thanks for reading and have happy scrolling!
</p>

</div>

                    </div>
                
            </article>
        </div>
    </div>
    </section>
    
</main></div></div>]]>
            </description>
            <link>https://spartez-software.com/blog/2021/02/01/analysis-of-rendering-performance-issues-in-whiteboards</link>
            <guid isPermaLink="false">hacker-news-small-sites-25989090</guid>
            <pubDate>Mon, 01 Feb 2021 14:45:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Teachers’ Guide to Cranky Uncle]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25989015">thread link</a>) | @ericdanielski
<br/>
February 1, 2021 | https://crankyuncle.com/teachers-guide-to-cranky-uncle/ | <a href="https://web.archive.org/web/*/https://crankyuncle.com/teachers-guide-to-cranky-uncle/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">
	
	<div role="document">

	<div id="content">
	<div itemscope="" itemtype="https://schema.org/BlogPosting">
		<div role="main">
					<article>
			<div><a href="https://crankyuncle.com/wp-content/uploads/2021/01/feature_cover.jpg" data-rel="lightbox" itemprop="image" itemscope="" itemtype="https://schema.org/ImageObject"><img src="https://crankyuncle.com/wp-content/uploads/2021/01/feature_cover.jpg" width="770" height="400" srcset="https://crankyuncle.com/wp-content/uploads/2021/01/feature_cover.jpg 770w, https://crankyuncle.com/wp-content/uploads/2021/01/feature_cover-300x156.jpg 300w, https://crankyuncle.com/wp-content/uploads/2021/01/feature_cover-768x399.jpg 768w" sizes="(max-width: 770px) 100vw, 770px" alt=""><meta itemprop="url" content="https://crankyuncle.com/wp-content/uploads/2021/01/feature_cover.jpg"><meta itemprop="width" content="770"><meta itemprop="height" content="400"></a></div>				<header>

								
				</header>

				<div itemprop="articleBody">
					
<p><a href="http://crankyuncle.com/wp-content/uploads/2021/01/Cranky_Teachers_Guide_v1.pdf">The Teachers’ Guide to Cranky Uncle</a> offers background information and classroom activity ideas for educators interested in using the Cranky Uncle game to teach critical thinking in their classes.</p>



<div><figure><a href="http://crankyuncle.com/wp-content/uploads/2021/01/Cranky_Teachers_Guide_v1.pdf"><img loading="lazy" src="https://crankyuncle.com/wp-content/uploads/2021/01/cover_US_letter-791x1024.png" alt="" width="396" height="512" srcset="https://crankyuncle.com/wp-content/uploads/2021/01/cover_US_letter-791x1024.png 791w, https://crankyuncle.com/wp-content/uploads/2021/01/cover_US_letter-232x300.png 232w, https://crankyuncle.com/wp-content/uploads/2021/01/cover_US_letter-768x994.png 768w, https://crankyuncle.com/wp-content/uploads/2021/01/cover_US_letter-1187x1536.png 1187w, https://crankyuncle.com/wp-content/uploads/2021/01/cover_US_letter.png 1200w" sizes="(max-width: 396px) 100vw, 396px"></a></figure></div>



<p>For teachers interested in using the Cranky Uncle game in their classes, here are the steps to get started:</p>



<ol><li><strong><a href="http://sks.to/crankyclass">Register to get a group code</a>.</strong> I need a few details about your class in order to email you group code/s.</li><li><strong>Receive your group codes by email.</strong> I will get back to you asap with group codes (note that they’re case sensitive).</li><li><strong>Download the game.</strong> There are three ways that your students can access the game:<ol><li>iPhone: <a href="https://sks.to/crankyiphone">https://sks.to/crankyiphone</a></li><li>Android: <a href="https://sks.to/crankyandroid">https://sks.to/crankyandroid</a></li><li>Browser: <a href="https://app.crankyuncle.info/">https://app.crankyuncle.info</a></li></ol></li><li><strong>Research instructions.</strong> Student can voluntarily take part in research – this helps us assess the effectiveness of the game. No identifying info is collected so it is completely anonymous. To participate:<ol><li>If your students are younger than 18, distribute this <a href="https://sks.to/infosheet">Research Information Sheet</a> to your students’ parents (it informs the parents of the research and that the students can opt out any time they like).</li><li>Students check the two consent boxes when the game first starts, then select YES when asked if they want to take part in the research.</li><li>They then fill out a 10-question survey before the game starts.</li><li>Once they’ve completed all the denial techniques, they’ll be asked to fill out another 10-question survey. Once that’s completed, that’s it!</li><li>Note that students can opt-out of the research at any point – they can edit their consent settings via the About screen.</li></ol></li></ol>



<p>I’m keen to hear from teachers who have used the game in their classes. I’ve already been impressed by the creative ways that critical thinking is being taught in the classroom, hence the Teachers’ Guide already has a number of suggested activities. Keen to hear about other creative approaches and how your students responded to the game…</p>
				</div>

				
			</article>
				<!-- /#comments -->

	<section id="respond">
		<!-- #respond -->
		
		</section><!-- /#respond -->
		</div>
		<!-- /aside -->
			</div><!-- /.row-->
		</div><!-- /.content -->
	</div><!-- /.wrap -->
	

		</div></div>]]>
            </description>
            <link>https://crankyuncle.com/teachers-guide-to-cranky-uncle/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25989015</guid>
            <pubDate>Mon, 01 Feb 2021 14:35:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An unexpected find that freed 20GB of unused index space in PostgreSQL]]>
            </title>
            <description>
<![CDATA[
Score 364 | Comments 76 (<a href="https://news.ycombinator.com/item?id=25988871">thread link</a>) | @haki
<br/>
February 1, 2021 | https://hakibenita.com/postgresql-unused-index-size | <a href="https://web.archive.org/web/*/https://hakibenita.com/postgresql-unused-index-size">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article data-progress-indicator="">
        <hr>
<p>Every few months we get an alert from our database monitoring to warn us that we are about to run out of space. Usually we just provision more storage and forget about it, but this time we were under quarantine, and the system in question was under less load than usual. We thought this is a good opportunity to do some cleanups that would otherwise be much more challenging.</p>
<p>To start from the end, <strong>we ended up freeing more than 70GB of un-optimized and un-utilized space</strong> without dropping a single index or deleting any data!</p>
<p>Using conventional technics such as rebuilding indexes and tables we cleared up a lot of space, but then <strong>one surprising find helped us clear an additional ~20GB of unused indexed values!</strong></p>
<p>This is what the free storage chart of one of our databases looked like in the process:</p>
<figure><img alt="Free space over time (higher means more free space)" src="https://hakibenita.com/images/00-postgresql-unused-index-size.png"><figcaption>Free space over time (higher means more free space)</figcaption>
</figure>
<details open="">
    <summary>Table of Contents</summary>

</details>
<hr>
<h2 id="the-usual-suspects"><a href="#the-usual-suspects">The Usual Suspects</a></h2>
<p>Provisioning storage is something we do from time to time, but before we throw money at the problem we like to make sure we make good use of the storage we already have. To do that, we start with the usual suspects.</p>
<h3 id="unused-indexes"><a href="#unused-indexes">Unused Indexes</a></h3>
<p>Unused indexes are double-edged swords; you create them to make things faster, but they end up taking space and slow inserts and updates. Unused indexes are the first thing we always check when we need to clear up storage.</p>
<p>To find unused indexes we use the following query:</p>
<div><pre><span></span><span>SELECT</span>
    <span>relname</span><span>,</span>
    <span>indexrelname</span><span>,</span>
    <span>idx_scan</span><span>,</span>
    <span>idx_tup_read</span><span>,</span>
    <span>idx_tup_fetch</span><span>,</span>
    <span>pg_size_pretty</span><span>(</span><span>pg_relation_size</span><span>(</span><span>indexrelname</span><span>::</span><span>regclass</span><span>))</span> <span>as</span> <span>size</span>
<span>FROM</span>
    <span>pg_stat_all_indexes</span>
<span>WHERE</span>
    <span>schemaname</span> <span>=</span> <span>'public'</span>
    <span>AND</span> <span>indexrelname</span> <span>NOT</span> <span>LIKE</span> <span>'pg_toast_%'</span>
<span>    <span>AND</span> <span>idx_scan</span> <span>=</span> <span>0</span>
</span><span>    <span>AND</span> <span>idx_tup_read</span> <span>=</span> <span>0</span>
</span><span>    <span>AND</span> <span>idx_tup_fetch</span> <span>=</span> <span>0</span>
</span><span>ORDER</span> <span>BY</span>
    <span>pg_relation_size</span><span>(</span><span>indexrelname</span><span>::</span><span>regclass</span><span>)</span> <span>DESC</span><span>;</span>
</pre></div>


<p>The query is looking for <strong>indexes that were not scanned or fetched</strong> since the last time the statistics were reset.</p>
<p>Some indexes may seem like they were not used but they were in-fact used:</p>
<ul>
<li>
<p><a href="https://www.postgresql.org/docs/current/monitoring-stats.html#MONITORING-PG-STAT-ALL-INDEXES-VIEW" rel="noopener">The documentation</a> lists a few scenarios when this is possible. For example, when the optimizer uses meta data from the index, but not the index itself.</p>
</li>
<li>
<p>Indexes used to enforce unique or primary key constraints for tables that were not updated in a while. The indexes will look like they were not used, but it doesn't mean we can dispose of them.</p>
</li>
</ul>
<p>The find the unused indexes you can actually drop, you usually have to go over the list one by one and make a decision. This can be time consuming in the first couple of times, but after you get rid of most unused indexes it becomes easier.</p>
<p>It's also a good idea to <strong>reset the statistics counters from time to time</strong>, usually right after you finished inspecting the list. PostgreSQL provides a few <a href="https://www.postgresql.org/docs/current/monitoring-stats.html#MONITORING-STATS-FUNCS-TABLE" rel="noopener">functions to reset statistics</a> at different levels. When we find an index we suspect is not being used, or when we add new indexes in place of old ones, we usually reset the counters for the table and wait for a while:</p>
<div><pre><span></span><span>-- Find table oid by name</span>
<span>SELECT</span> <span>oid</span> <span>FROM</span> <span>pg_class</span> <span>c</span> <span>WHERE</span> <span>relname</span> <span>=</span> <span>'table_name'</span><span>;</span>
<span>-- Reset counts for all indexes of table</span>
<span>SELECT</span> <span>pg_stat_reset_single_table_counters</span><span>(</span><span>14662536</span><span>);</span>
</pre></div>


<p>We do this every once in a while, so in our case there were no unused indexes to drop.</p>
<h3 id="index-and-table-bloat"><a href="#index-and-table-bloat">Index and Table Bloat</a></h3>
<p>The next suspect is bloat. When you update rows in a table, PostgreSQL marks the tuple as dead and adds the updated tuple in the next available space. This process creates what's called "bloat", which can cause tables to consume more space than they really need. Bloat also affects indexes, so to free up space, bloat is a good place to look.</p>
<p>Estimating bloat in tables and indexes is apparently not a simple task. Lucky for us, some good people on the world wide web already <a href="https://wiki.postgresql.org/wiki/Show_database_bloat" rel="noopener">did the hard work</a> and wrote queries to estimate <a href="https://github.com/ioguix/pgsql-bloat-estimation/blob/master/table/table_bloat.sql" rel="noopener">table bloat</a> and <a href="https://github.com/ioguix/pgsql-bloat-estimation/blob/master/btree/btree_bloat.sql" rel="noopener">index bloat</a>. After running these queries you will most likely find <em>some</em> bloat, so the next thing to do it clear up that space.</p>
<h4 id="clearing-bloat-in-indexes"><a href="#clearing-bloat-in-indexes">Clearing Bloat in Indexes</a></h4>
<p>To clear bloat in an index, you need to rebuild it. There are several ways to rebuild an index:</p>
<ol>
<li>
<p><strong>Re-create the index</strong>: If you re-create the index, it will be built in an optimal way.</p>
</li>
<li>
<p><strong>Rebuild the index</strong>: Instead of dropping and creating the index yourself, PostgreSQL provides a way to re-build an existing index in-place using the <a href="https://www.postgresql.org/docs/current/sql-reindex.html" rel="noopener"><code>REINDEX</code></a> command:</p>
</li>
</ol>
<div><pre><span></span><span>REINDEX</span> <span>INDEX</span> <span>index_name</span><span>;</span>
</pre></div>


<ol>
<li><strong>Rebuild the index concurrently</strong>: The previous methods will obtain a lock on the table and prevent it from being changed while the operation is in progress, which is usually unacceptable. To rebuild the index without locking it for updates, you can <a href="https://www.postgresql.org/docs/current/sql-reindex.html#SQL-REINDEX-CONCURRENTLY" rel="noopener">rebuilt the index concurrently</a>:</li>
</ol>
<div><pre><span></span><span>REINDEX</span> <span>INDEX</span> <span>CONCURRENTLY</span> <span>index_name</span><span>;</span>
</pre></div>


<p>When using <code>REINDEX CONCURRENTLY</code>, PostgreSQL creates a new index with a name suffixed with <code>_ccnew</code>, and syncs any changes made to the table in the meantime. When the rebuild is done, it will switch the old index with the new index, and drop the old one.</p>
<figure>
<figcaption>Clearing bloat in Indexes</figcaption>
</figure>
<p>If for some reason you had to stop the rebuild in the middle, the new index will not be dropped. Instead, it will be left in an invalid state and consume space. To identify invalid indexes that were created during <code>REINDEX</code>, we use the following query:</p>
<div><pre><span></span><span>-- Identify invalid indexes that were created during index rebuild</span>
<span>SELECT</span>
    <span>c</span><span>.</span><span>relname</span> <span>as</span> <span>index_name</span><span>,</span>
    <span>pg_size_pretty</span><span>(</span><span>pg_relation_size</span><span>(</span><span>c</span><span>.</span><span>oid</span><span>))</span>
<span>FROM</span>
    <span>pg_index</span> <span>i</span>
    <span>JOIN</span> <span>pg_class</span> <span>c</span> <span>ON</span> <span>i</span><span>.</span><span>indexrelid</span> <span>=</span> <span>c</span><span>.</span><span>oid</span>
<span>WHERE</span>
    <span>-- New index built using REINDEX CONCURRENTLY</span>
    <span>c</span><span>.</span><span>relname</span> <span>LIKE</span>  <span>'%_ccnew'</span>
    <span>-- In INVALID state</span>
    <span>AND</span> <span>NOT</span> <span>indisvalid</span>
<span>LIMIT</span> <span>10</span><span>;</span>
</pre></div>


<p>Once the rebuild process is no longer active, it should be safe to drop any remaining invalid indexes.</p>
<h4 id="activating-b-tree-index-deduplication"><a href="#activating-b-tree-index-deduplication">Activating B-Tree Index Deduplication</a></h4>
<p>PostgreSQL 13 introduced a new efficient way of storing duplicate values in B-Tree indexes called <a href="https://www.postgresql.org/docs/current/btree-implementation.html#BTREE-DEDUPLICATION" rel="noopener">"B-Tree Deduplication"</a>.</p>
<p>For each indexed value, a B-Tree index will hold in its leaf both the value and a pointer to the row (TID). The larger the indexed values, the larger the index. Up until PostgreSQL 12, when the index contained many duplicate values, all of these duplicate values would be stored in the index leaves. This is not very efficient and can take up a lot of space.</p>
<figure>
<figcaption>B-Tree Index Deduplication</figcaption>
</figure>
<p>Starting at PostgreSQL 13, when B-Tree deduplication is activated, duplicate values are only stored once. This can make a huge impact on the size of indexes with many duplicate values.</p>
<p>In PostgreSQL 13 index deduplication in enabled by default, unless you deactivate it:</p>
<div><pre><span></span><span>-- Activating de-deduplication for a B-Tree index, this is the default:</span>
<span>CREATE</span> <span>INDEX</span> <span>index_name</span> <span>ON</span> <span>table_name</span><span>(</span><span>column_name</span><span>)</span> <span>WITH</span> <span>(</span><span>deduplicate_items</span> <span>=</span> <span>ON</span><span>)</span>
</pre></div>


<p>If you are migrating from PostgreSQL versions prior to 13, you need to rebuild the indexes using the <code>REINDEX</code> command in order to get the full benefits of index de-deduplication.</p>
<p>To illustrate the effect of B-Tree deduplication on the size of the index, create a table with a unique column and a non unique column, and populate it with 1M rows. On each column create two B-Tree indexes, one with deduplication enabled and another with deduplication disabled:</p>
<div><pre><span></span><span>db</span><span>=#</span> <span>CREATE</span> <span>test_btree_dedup</span> <span>(</span><span>n_unique</span> <span>serial</span><span>,</span> <span>n_not_unique</span> <span>integer</span><span>);</span>
<span>CREATE</span> <span>TABLE</span>

<span>db</span><span>=#</span> <span>INSERT</span> <span>INTO</span> <span>test_btree_dedup</span> <span>(</span><span>n_not_unique</span><span>)</span>
<span>SELECT</span> <span>(</span><span>random</span><span>()</span> <span>*</span> <span>100</span><span>)::</span><span>int</span> <span>FROM</span> <span>generate_series</span><span>(</span><span>1</span><span>,</span> <span>1000000</span><span>);</span>
<span>INSERT</span> <span>0</span> <span>1000000</span>

<span>db</span><span>=#</span> <span>CREATE</span> <span>INDEX</span> <span>ix1</span> <span>ON</span> <span>test_btree_dedup</span> <span>(</span><span>n_unique</span><span>)</span>     <span>WITH</span> <span>(</span><span>deduplicate_items</span> <span>=</span> <span>OFF</span><span>);</span>
<span>CREATE</span> <span>INDEX</span>

<span>db</span><span>=#</span> <span>CREATE</span> <span>INDEX</span> <span>ix2</span> <span>ON</span> <span>test_btree_dedup</span> <span>(</span><span>n_unique</span><span>)</span>     <span>WITH</span> <span>(</span><span>deduplicate_items</span> <span>=</span> <span>ON</span><span>);</span>
<span>CREATE</span> <span>INDEX</span>

<span>db</span><span>=#</span> <span>CREATE</span> <span>INDEX</span> <span>ix3</span> <span>ON</span> <span>test_btree_dedup</span> <span>(</span><span>n_not_unique</span><span>)</span> <span>WITH</span> <span>(</span><span>deduplicate_items</span> <span>=</span> <span>OFF</span><span>);</span>
<span>CREATE</span> <span>INDEX</span>

<span>db</span><span>=#</span> <span>CREATE</span> <span>INDEX</span> <span>ix4</span> <span>ON</span> <span>test_btree_dedup</span> <span>(</span><span>n_not_unique</span><span>)</span> <span>WITH</span> <span>(</span><span>deduplicate_items</span> <span>=</span> <span>ON</span><span>);</span>
<span>CREATE</span> <span>INDEX</span>
</pre></div>


<p>Next, compare the sizes of the four indexes:</p>
<table>
<thead>
<tr>
<th>Column</th>
<th>Deduplication</th>
<th>Size</th>
</tr>
</thead>
<tbody>
<tr>
<td>Not unique</td>
<td>Yes</td>
<td>6840 kB</td>
</tr>
<tr>
<td>Not unique</td>
<td>No</td>
<td>21 MB</td>
</tr>
<tr>
<td>Unique</td>
<td>Yes</td>
<td>21 MB</td>
</tr>
<tr>
<td>Unique</td>
<td>No</td>
<td>21 MB</td>
</tr>
</tbody>
</table>
<p>As expected, deduplication had no effect on the unique index, but it had a significant effect on the index that had many duplicate values.</p>
<p>Unfortunately for us, PostgreSQL 13 was still fresh at the time, and our cloud provider did not have support for it yet, so we were unable to use deduplication to clear space.</p>
<h4 id="clearing-bloat-in-tables"><a href="#clearing-bloat-in-tables">Clearing Bloat in Tables</a></h4>
<p>Just like in indexes, tables can also contain dead tuples that cause bloat and fragmentation. However, unlike indexes that contain data from an associated table, a table can not just simply be re-created. To re-create a table you would have to create a new table, migrate the data over while keeping it synced with new data, create all the indexes, constraints and any referential constraints in other tables. Only after all of this is done, you can switch the old table with the new one.</p>
<figure>
<figcaption>Clearing bloat in Tables</figcaption>
</figure>
<p>There are several ways to rebuild a table and reduce bloat:</p>
<ol>
<li>
<p><strong>Re-create the table</strong>: Using this method as described above often requires a lot of development, especially if the table is actively being used as it's being rebuilt.</p>
</li>
<li>
<p><strong>Vacuum the table</strong>: PostgreSQL provides a way to reclaim space occupied by bloat and dead tuples in a table using the <a href="https://www.postgresql.org/docs/current/sql-vacuum.html" rel="noopener"><code>VACUUM FULL</code> command</a>. Vacuum full requires a lock on the table, and is not an ideal solution for tables that need to be available while being vacuumed:</p>
</li>
</ol>
<div><pre><span></span><span>-- Will lock the table</span>
<span>VACUUM</span> <span>FULL</span> <span>table_name</span><span>;</span>
</pre></div>


<p>The two options above require either a significant effort, or some down time.</p>
<h4 id="using-pg_repack"><a href="#using-pg_repack">Using pg_repack</a></h4>
<p>Both built-in options for rebuilding tables are not ideal unless you can afford downtime. One popular solution for rebuilding tables and indexes without downtime is the <a href="https://reorg.github.io/pg_repack/" rel="noopener">pg_repack extension</a>.</p>
<p>Being a popular extension, <code>pg_repack</code> is likely available from your package manager or already installed by your cloud provider. To use <code>pg_repack</code>, you first need to create the extension:</p>
<div><pre><span></span><span>CREATE</span> <span>EXTENSION</span> <span>pg_repack</span><span>;</span>
</pre></div>


<p>To "repack" a table along with its indexes, issue the following command from the console:</p>
<div><pre><span></span><span>$</span> pg_repack -k --table table_name db_name
</pre></div>


<p>To rebuild a table with no downtime, the extension creates a new table, loads the data from the original table into it while keeping it …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hakibenita.com/postgresql-unused-index-size">https://hakibenita.com/postgresql-unused-index-size</a></em></p>]]>
            </description>
            <link>https://hakibenita.com/postgresql-unused-index-size</link>
            <guid isPermaLink="false">hacker-news-small-sites-25988871</guid>
            <pubDate>Mon, 01 Feb 2021 14:17:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Different Ways to Filter Containers in Modern C++]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25988749">thread link</a>) | @joebaf
<br/>
February 1, 2021 | https://www.cppstories.com/2021/filter-cpp-containers/ | <a href="https://web.archive.org/web/*/https://www.cppstories.com/2021/filter-cpp-containers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><img src="https://www.cppstories.com/2021/images/filter.png" alt=""></p>  
          
        

<p>Do you know how many ways we can implement a filter function in C++?</p>

<p>While the problem is relatively easy to understand - take a container, copy elements that match a predicate and the return a new container - it’s good to exercise with the Standard Library and check a few ideas. We can also apply some Modern C++ techniques.</p>

<p>Let’s start!</p>

<h2 id="the-problem-statement">The Problem Statement</h2>

<p>To be precise by <em>filter</em> I mean a function with the following interface:</p>

<pre><code>auto Filter(const Container&amp; cont, UnaryPredicate p) {}
</code></pre>

<p>It takes a container and a predicate, and then it creates an output container with elements that satisfies the predicate.</p>

<p>We can use it like the following:</p>

<pre><code>const std::vector&lt;std::string&gt; vec{ "Hello", "**txt", "World", "error", "warning", "C++", "****" };

auto filtered = FilterRaw(vec, [](auto&amp; elem) { return !elem.starts_with('*'); });
// filtered should have "Hello", "World", "error", "warning", "C++"
</code></pre>

<p>Additionally, we can have a look at <a href="https://en.wikipedia.org/wiki/Filter_(higher-order_function)">a definition from wikipedia</a> and functional programming:</p>

<blockquote>
<p>In functional programming, filter is a higher-order function that processes a data structure (usually a list) in some order to produce a new data structure containing exactly those elements of the original data structure for which a given predicate returns the boolean value true.</p>
</blockquote>

<p>Writing such a function can be a good exercise with various options and algorithms in the Standard Library. What’s more, our function hides internal things like iterators, so it’s more like a range based version.</p>

<p>Let’s start with the first option:</p>

<h2 id="good-old-raw-loops">Good old Raw Loops</h2>

<p>While it’s good to avoid raw loops, they might help us to fully understand the problem, especially for a simple problem like we have:</p>

<pre><code>template &lt;typename T, typename Pred&gt;
auto FilterRaw(const std::vector&lt;T&gt;&amp; vec, Pred p) {
    std::vector&lt;T&gt; out;
    for (auto&amp;&amp; elem : vec)
        if (p(elem))
            out.push_back(elem);
    return out;
}
</code></pre>

<p>Simple yet very effective.</p>

<p>Please notice some nice things about this straightforward implementation.</p>

<ul>
<li>The code uses <code>auto</code> return type deduction, so there’s no need to write the explicit type.</li>
<li>It returns the output vector by value, but the compiler will leverage the copy elision (in most case), or move semantics at worse.</li>
</ul>

<p>Since we’re at raw loops, we need can take a moment and appreciate range based for loops that we get with C++11. Without this functionality our code would look much worse:</p>

<pre><code>template &lt;typename T, typename Pred&gt;
std::vector&lt;T&gt; FilterRawOld(const std::vector&lt;T&gt;&amp; vec, Pred p) {
  std::vector&lt;T&gt; out;
  for (typename std::vector&lt;T&gt;::const_iterator it = begin(vec); it != end(vec); ++it)
    if (p(*it))
      out.push_back(*it);
  return out;
}
</code></pre>

<p>And now let’s move to something better and see some of the existing <code>std::</code> algorithms that might help us with the implementation.</p>

<h2 id="filter-by-std-copy-if">Filter by <code>std::copy_if</code></h2>

<p><code>std::copy_if</code> is probably the most natural choice. We can leverage <code>back_inserter</code> and then push matched elements into the output vector.</p>

<pre><code>template &lt;typename T, typename Pred&gt;
auto FilterCopyIf(const std::vector&lt;T&gt;&amp; vec, Pred p) {
    std::vector&lt;T&gt; out;
    std::copy_if(begin(vec), end(vec), std::back_inserter(out), p);
    return out;
}
</code></pre>

<h2 id="std-remove-copy-if"><code>std::remove_copy_if</code></h2>

<p>But we can also do the reverse:</p>

<pre><code>template &lt;typename T, typename Pred&gt;
auto FilterRemoveCopyIf(const std::vector&lt;T&gt;&amp; vec, Pred p) {
    std::vector&lt;T&gt; out;
    std::remove_copy_if(begin(vec), end(vec), 
                        std::back_inserter(out), std::not_fn(p));
    return out;
}
</code></pre>

<p>Depending on the requirements, we can also use <code>remove_copy_if</code> which copies elements that do not satisfy the predicate. For our implementation, I had to add <code>std::not_fn</code> to reverse the predicate.</p>

<p>One remark: <code>std::not_fn</code> is available since C++17.</p>

<h2 id="the-famous-remove-erase-idiom">The Famous Remove Erase Idiom</h2>

<pre><code>template &lt;typename T, typename Pred&gt;
auto FilterRemoveErase(const std::vector&lt;T&gt;&amp; vec, Pred p) {
    auto out = vec;
    out.erase(std::remove_if(begin(out), end(out), std::not_fn(p)), end(out));
    return out;
}
</code></pre>

<p>Here’s a little inconvenience. Because we don’t want to modify the input container, we had to copy it first. This might cause some extra processing and is less efficient than using <code>back_inserter</code>.</p>

<h2 id="adding-some-c-20">Adding Some C++20</h2>

<p>After seeing a few examples, we can finally see a convenient feature from C++20.</p>

<pre><code>template &lt;typename T, typename Pred&gt;
auto FilterEraseIf(const std::vector&lt;T&gt;&amp; vec, Pred p) {
    auto out = vec;
    std::erase_if(out, std::not_fn(p));
    return out;
}
</code></pre>

<p>One minor thing, this approach copies all elements first. So it might be slower than the approach with <code>copy_if</code>.</p>

<h2 id="adding-some-c-20-ranges">Adding Some C++20 Ranges</h2>

<p>And finally a solution with Ranges:</p>

<pre><code>template &lt;typename T, typename Pred&gt;
auto FilterRangesCopyIf(const std::vector&lt;T&gt;&amp; vec, Pred p) {
    std::vector&lt;T&gt; out;
    std::ranges::copy_if(vec, std::back_inserter(out), p);
    return out;
}
</code></pre>

<p>The code is super simple, and we might even say that our <code>Filter</code> function has no point here, since the Ranges interface is so easy to use in code directly.</p>

<h2 id="making-it-more-generic">Making it More Generic</h2>

<p>So far I showed you code that operates on <code>std::vector</code>. But how about other containers?</p>

<p>Let’s try and make our <code>Filter</code> function more generic. This is easy with <code>std::erase_if</code> which has overloads for many Standard containers:</p>

<pre><code>template &lt;typename TCont, typename Pred&gt;
auto FilterEraseIfGen(const TCont&amp; cont, Pred p) {
    auto out = cont;
    std::erase_if(out, std::not_fn(p));
    return out;
}
</code></pre>

<p>And another version for ranges.</p>

<pre><code>template &lt;typename TCont, typename Pred&gt;
auto FilterRangesCopyIfGen(const TCont&amp; vec, Pred p) {
    TCont out;
    std::ranges::copy_if(vec, std::back_inserter(out), p);
    return out;
}
</code></pre>

<p>Right now it can work with other containers, not only with <code>std::vector</code>:</p>

<pre><code>std::set&lt;std::string&gt; mySet{ 
    "Hello", "**txt", "World", "error", "warning", "C++", "****" 
};
auto filtered = FilterEraseIfGen(mySet, [](auto&amp; elem) { 
    return !elem.starts_with('*'); 
});
</code></pre>

<p>On the other hand, if you prefer not to copy all elements upfront, we might need more work.</p>

<h3 id="generic-copy-if-approach">Generic Copy If Approach</h3>

<p>The main problem is that we cannot use <code>back_inserter</code> on associative containers, or on containers that don’t support <code>push_back()</code> member function. In that case, we can fallback to <code>std::inserter</code> adapter.</p>

<p>That’s why one of a possible solution is to detect if a given container supports <code>push_back</code> :</p>

<pre><code>template &lt;typename T, typename = void&gt;
struct has_push_back : std::false_type {};

template &lt;typename T&gt;
struct has_push_back&lt;T,
  std::void_t&lt;
    decltype(std::declval&lt;T&gt;().push_back(std::declval&lt;typename T::value_type&gt;()))
    &gt;
  &gt; : std::true_type {};

template &lt;typename TCont, typename Pred&gt;
auto FilterCopyIfGen(const TCont&amp; cont, Pred p) {
    TCont out;
    if constexpr(has_push_back&lt;TCont&gt;::value)
        std::copy_if(begin(cont), end(cont), std::back_inserter(out), p);
    else
        std::copy_if(begin(cont), end(cont), std::inserter(out, out.begin()), p);

    return out;
}
</code></pre>

<p>This seems to work! But of course, I’m open to some better code and ideas :)</p>

<p>I took the approach from <a href="https://www.cppstories.com/2019/07/detect-overload-from-chars/">How To Detect Function Overloads in C++17, std::from_chars Example - C++ Stories</a>.</p>

<h2 id="adding-some-concepts">Adding Some Concepts</h2>

<p>Since we can use C++, why not adding some concepts.</p>

<p>For example, if I write:</p>

<pre><code>auto filtered = FilterCopyIf(vec, [](auto&amp; elem, int a) { 
    return !elem.starts_with('*'); 
});
</code></pre>

<p>So it’s two input arguments into an unary predicate I get the following in Visual Studio:</p>

<pre><code>C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.28.29333\include\algorithm(1713,13): error C2672: 'operator __surrogate_func': no matching overloaded function found
1&gt;  C:\Users\Admin\Documents\GitHub\articles\filterElements\filters.cpp(38): message : see reference to function template instantiation '_OutIt std::copy_if&lt;std::_Vector_const_iterator&lt;std::_Vector_val&lt;std::_Simple_types&lt;_Ty&gt;&gt;&gt;,std::back_insert_iterator&lt;std::vector&lt;_Ty,std::allocator&lt;_Ty&gt;&gt;&gt;,Pred&gt;(_InIt,_InIt,_OutIt,_Pr)' being compiled
1&gt;          with
</code></pre>

<p>but then after a few lines, we have</p>

<pre><code>error C2780: 'auto main::&lt;lambda_4&gt;::operator ()(_T1 &amp;,int) const': expects 2 arguments - 1 provided
</code></pre>

<p>We can experiment with concepts and restrict our predicate to be <code>std::predicate</code>, an existing concept from the Standard Library. In our case, we need a function that takes one argument and then returns a type convertible to <code>bool</code>.</p>

<pre><code>template &lt;typename T, std::predicate&lt;const T&amp;&gt; Pred&gt;   // &lt;&lt;
auto FilterCopyIfConcepts(const std::vector&lt;T&gt;&amp; vec, Pred p) {
    std::vector&lt;T&gt; out;
    std::copy_if(begin(vec), end(vec), std::back_inserter(out), p);
    return out;
}
</code></pre>

<p>And then the problematic code:</p>

<pre><code>auto filtered = FilterCopyIfConcepts(vec, [](auto&amp; elem, int a) { 
    return !elem.starts_with('*'); 
});
</code></pre>

<p>Says the following:</p>

<pre><code>1&gt;  filters.cpp(143,19): error C2672: 'FilterCopyIfConcepts': no matching overloaded function found
1&gt;  filters.cpp(143,101): error C7602: 'FilterCopyIfConcepts': the associated constraints are not satisfied
</code></pre>

<p>It’s a bit better, as we have messages about our top-level function and not some internals, but it would be great to see why and which constraint wasn’t satisfied.</p>

<h2 id="making-it-parallel">Making it Parallel?</h2>

<p>Since C++17 we also have parallel algorithms, so why not add it to our list?</p>

<p>As it appears <code>std::copy_if</code> par is not supported in Visual Studio, and this problem is a bit more complicated. We’ll leave this topic for now and try to solve it some next time.</p>

<p>You can write a manual version:</p>

<pre><code>std::mutex mut;
    std::for_each(std::execution::par, begin(vec), end(vec),
        [&amp;out, &amp;mut, p](auto&amp;&amp; elem) {
            if (p(elem))
            {
                std::unique_lock lock(mut);
                out.push_back(elem);
            }
        });
</code></pre>

<p>But this will often block, and it’s probably not the best approach. So stay tuned for our future experiments with this topic.</p>

<h2 id="summary">Summary</h2>

<p>In this article, I’ve shown at least 12 possible ways to filter elements from various containers. We started from code that worked on <code>std::vector</code>, and you’ve also seen multiple …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cppstories.com/2021/filter-cpp-containers/">https://www.cppstories.com/2021/filter-cpp-containers/</a></em></p>]]>
            </description>
            <link>https://www.cppstories.com/2021/filter-cpp-containers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25988749</guid>
            <pubDate>Mon, 01 Feb 2021 14:04:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Julius Ruechel: Bystander at the Switch: The Moral Case Against Covid Lockdowns]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25988743">thread link</a>) | @mrfusion
<br/>
February 1, 2021 | https://www.juliusruechel.com/2021/01/bystander-at-switch-moral-case-against.html?m=1 | <a href="https://web.archive.org/web/*/https://www.juliusruechel.com/2021/01/bystander-at-switch-moral-case-against.html?m=1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-16392354600715661" itemprop="articleBody">
<p>Do you remember the moral riddle taught in grade school called the "Bystander at the Switch" (also known as the <a href="https://en.wikipedia.org/wiki/Trolley_problem" target="_blank">Trolley Problem</a>)? It was a story about a runaway train hurtling towards a cluster of people stuck on the tracks ahead. But you have the option to pull the switch and send the train down another track with a smaller number of people on it. You have the option of saving some lives by sacrificing a smaller number of others. Do you pull the switch?</p><p>In grade school the riddle was posed as a moral dilemma. But it's not. There was only ever one correct choice. We invented universal human rights to make it clear that no person or government has the right to pull the switch to send the train down another track towards a sacrificial group of victims.&nbsp;</p><table><tbody><tr><td><a href="https://1.bp.blogspot.com/-Lvnx8GgBG44/YAShcMP093I/AAAAAAAAAhs/zPCv7xsW1lgf0gQkYuE29BKWxh22I3PDQCLcBGAsYHQ/s1626/Trolley%2BProblem.jpg"><img data-original-height="530" data-original-width="1626" height="91" src="https://1.bp.blogspot.com/-Lvnx8GgBG44/YAShcMP093I/AAAAAAAAAhs/zPCv7xsW1lgf0gQkYuE29BKWxh22I3PDQCLcBGAsYHQ/w640-h208/Trolley%2BProblem.jpg" width="280"></a></td></tr><tr><td>The Trolley Problem (The immoral dilemma of the bystander at the switch)</td></tr></tbody></table><p>In December of 1948, in the aftermath of the human rights violations committed during the Second World War, the member states of the United Nations formally adopted the <a href="https://www.un.org/en/universal-declaration-human-rights/" target="_blank">Universal Declaration of Human Rights</a>. It explicitly forbids government from treating some people as worth less than others. It forbids government from sacrificing some people for the benefit of others. It forbids government from knowingly imposing harm on some individuals in order to serve an alleged greater good. And it forbids government from imposing a hierarchy of rights on their citizens.</p><p>Lockdowns during COVID pose the exact same question as the Bystander at the Switch. But it's not a game; once again there are real lives at stake. Yet in direct violation of the principles of universal human rights, governments around the world are choosing to pull the switch by imposing lockdowns "for our safety." In doing so they have given themselves the authority to play God with our lives.</p><p>Are you essential or non-essential? Each category now has different rights and freedoms and different levels of individual autonomy. Some have the right to earn a living. Others do not. Some have the right to choose how to balance the risks and priorities in their lives. Others do not. How can any job that feeds a family not be essential?&nbsp;</p><p>What about the collateral damage caused by lockdowns? Mandatory lockdowns are leading to the deaths of countless individuals through cancelled/delayed medical operations, suicides, drug overdoses, loneliness and isolation in nursing homes, and more. None of these deaths would happen without lockdowns. Government is throwing one group of people onto the tracks with the goal of saving another.</p><p>How much misery and suffering is government allowed to impose on other people "for your safety"? How many jobs is the government allowed to destroy "for your safety"? How many people will lose their homes "for your safety"? How many people will lose their life savings, have their marriages broken, suffer bankruptcy, lose their careers, have their children's education irreparably damaged, or have their mental health destroyed because of actions taken by the government "for your safety"?&nbsp;</p><p><a href="https://www.thestar.com/news/gta/2020/12/05/one-in-10-canadians-say-theyve-contemplated-suicide-since-the-pandemic-began.html" target="_blank"><img data-original-height="485" data-original-width="821" height="165" src="https://1.bp.blogspot.com/-BCrzBC0_kLo/YAjo4CubHUI/AAAAAAAAAkY/jAtjXaAaJic9Fx_NqHGXPadyMdrRGvIWQCLcBGAsYHQ/w400-h236/1%2Bin%2B10%2BCanadians.jpg" width="280"></a></p><p>And how many people is the government allowed to force into poverty and starvation "for your safety"? Visitors to food banks are not just soaring here at home. We live in an interconnected world. What we do in one part of the world sets precedents and causes economic ripples that reach the farthest corners of the globe. Do those lives matter?&nbsp;</p><p>The head of the World Food Program WFP has warned that the "equivalent of 400 million full-time jobs have been destroyed" by government mandated COVID lockdowns and that there are now "270 million people marching towards the brink of starvation" (full article <a href="https://www.wfp.org/news/wfp-chief-warns-grave-dangers-economic-impact-coronavirus-millions-are-pushed-further-hunger" target="_blank">here</a>).&nbsp;</p><p><a href="https://1.bp.blogspot.com/-iPQaTjJiT8o/YAjTNs7gvtI/AAAAAAAAAig/QI80MazuQ207v9cf8SqVCAgQ0FF0d_BgwCLcBGAsYHQ/s1231/World%2BFood%2BProgram%2BWFP%2529%2BWarning.jpg"><img data-original-height="752" data-original-width="1231" height="170" src="https://1.bp.blogspot.com/-iPQaTjJiT8o/YAjTNs7gvtI/AAAAAAAAAig/QI80MazuQ207v9cf8SqVCAgQ0FF0d_BgwCLcBGAsYHQ/w640-h390/World%2BFood%2BProgram%2BWFP%2529%2BWarning.jpg" width="280"></a></p><p>Here are a few excerpts that I hope make you very uncomfortable:</p><div><p>On jobs lost during COVID:</p><p><a href="https://1.bp.blogspot.com/-L0aDesaThes/YAjTYAbbABI/AAAAAAAAAik/KnXj2JK02Howa3TP9q7A1Jqw3bjjkm_VgCLcBGAsYHQ/s859/WFP-jobs.jpg"><img data-original-height="173" data-original-width="859" height="56" src="https://1.bp.blogspot.com/-L0aDesaThes/YAjTYAbbABI/AAAAAAAAAik/KnXj2JK02Howa3TP9q7A1Jqw3bjjkm_VgCLcBGAsYHQ/w640-h128/WFP-jobs.jpg" width="280"></a></p><p>Increased child deaths in Africa due to missed routine vaccinations:</p></div><p><a href="https://1.bp.blogspot.com/-7Aso8PfH-w4/YAnl6sA3JTI/AAAAAAAAAlg/SKguFSakBkgaPr2mqT1g019_TE4kWy-hQCLcBGAsYHQ/s862/WFP-vaccinations.jpg"><img data-original-height="148" data-original-width="862" height="48" src="https://1.bp.blogspot.com/-7Aso8PfH-w4/YAnl6sA3JTI/AAAAAAAAAlg/SKguFSakBkgaPr2mqT1g019_TE4kWy-hQCLcBGAsYHQ/w640-h110/WFP-vaccinations.jpg" width="280"></a></p><p>Starvation in the Democratic Republic of the Congo:</p><p><a href="https://1.bp.blogspot.com/-aI_p2Wbslpc/YAjULGDGtSI/AAAAAAAAAi8/av7AeDG1gho0vRhOBDJ2M5zZVeD638vAQCLcBGAsYHQ/s873/WFP-DRC.jpg"><img data-original-height="148" data-original-width="873" height="47" src="https://1.bp.blogspot.com/-aI_p2Wbslpc/YAjULGDGtSI/AAAAAAAAAi8/av7AeDG1gho0vRhOBDJ2M5zZVeD638vAQCLcBGAsYHQ/w640-h108/WFP-DRC.jpg" width="280"></a></p><p>Starvation in Nigeria:</p><p><a href="https://1.bp.blogspot.com/-ZicomGhUusU/YAjULUeeroI/AAAAAAAAAjA/f1Guhsfgh041jb5_Xc_GlbzSYdWTPGgaQCLcBGAsYHQ/s837/WFP-Nigeria.jpg"><img data-original-height="155" data-original-width="837" height="51" src="https://1.bp.blogspot.com/-ZicomGhUusU/YAjULUeeroI/AAAAAAAAAjA/f1Guhsfgh041jb5_Xc_GlbzSYdWTPGgaQCLcBGAsYHQ/w640-h118/WFP-Nigeria.jpg" width="280"></a></p><p>Starvation in South Sudan:</p><div><p><a href="https://1.bp.blogspot.com/-xh6wIZYJCfU/YAjULtpQGRI/AAAAAAAAAjE/Syzqyj2-2FcS0SbUCyl_nYlgspwRVg09ACLcBGAsYHQ/s836/WFP-Sudan.jpg"><img data-original-height="128" data-original-width="836" height="42" src="https://1.bp.blogspot.com/-xh6wIZYJCfU/YAjULtpQGRI/AAAAAAAAAjE/Syzqyj2-2FcS0SbUCyl_nYlgspwRVg09ACLcBGAsYHQ/w640-h98/WFP-Sudan.jpg" width="280"></a></p><p>Starvation in Yemen:</p><p><a href="https://1.bp.blogspot.com/-BPYzhn1zC-w/YAjUMN1OBzI/AAAAAAAAAjI/uUwKUrqpPigs8AXG9KSWE1afKzaKNOypwCLcBGAsYHQ/s842/WFP-Yemen.jpg"><img data-original-height="179" data-original-width="842" height="59" src="https://1.bp.blogspot.com/-BPYzhn1zC-w/YAjUMN1OBzI/AAAAAAAAAjI/uUwKUrqpPigs8AXG9KSWE1afKzaKNOypwCLcBGAsYHQ/w640-h136/WFP-Yemen.jpg" width="280"></a></p><p>Starvation in Latin America:</p><p><a href="https://1.bp.blogspot.com/--yBmMPts5Z8/YAjULDLjwZI/AAAAAAAAAi0/TyR08zBb1I0u3pDjTmpF4753F4YLEHLoACLcBGAsYHQ/s844/WFP-Latin%2BAmerica.jpg"><img data-original-height="77" data-original-width="844" height="25" src="https://1.bp.blogspot.com/--yBmMPts5Z8/YAjULDLjwZI/AAAAAAAAAi0/TyR08zBb1I0u3pDjTmpF4753F4YLEHLoACLcBGAsYHQ/w640-h58/WFP-Latin%2BAmerica.jpg" width="280"></a></p><p>Starvation in Burkina Faso:</p><div><p><a href="https://1.bp.blogspot.com/-8depsiUwTXc/YAjULMZ6dgI/AAAAAAAAAi4/gsdA6bD2tSINueQeuVWn5qJYXfzZqRkygCLcBGAsYHQ/s847/WFP-Burkino%2BFaso.jpg"><img data-original-height="101" data-original-width="847" height="33" src="https://1.bp.blogspot.com/-8depsiUwTXc/YAjULMZ6dgI/AAAAAAAAAi4/gsdA6bD2tSINueQeuVWn5qJYXfzZqRkygCLcBGAsYHQ/w640-h76/WFP-Burkino%2BFaso.jpg" width="280"></a></p><p>Let's be clear, this unfolding horror is not because of COVID, it is because of the government's&nbsp;<i>response&nbsp;</i>to COVID. By crossing the line from making recommendations to imposing laws that take away the people's right to decide for themselves how to balance their risks and priorities, economies are grinding to a halt and millions are being forced into starvation. And the carnage doesn't miraculously end when the virus fades away. The slow-moving forces set in motion will be with us for a long time and in the meantime the bodies will just keep piling up. Should they be asked to pay this price "for your safety"? Or perhaps they don't matter since the media isn't counting them and can't leverage them into click-bait to exploit your feeling of vulnerability to the virus?</p><p>The first principle in medicine is the Hippocratic Oath, which says, "First do no harm." One consequence of this rule is that you're not allowed to protect one group of people by harming another. Empathy for one group doesn't give you the right to trample another. In the Trolly Problem, it's completely unethical (medical malpractice) for any doctor to pull the switch.</p><p>Yet health authorities imposing lockdowns are nevertheless inflicting horrific harms on those least at risk from the virus (the young and healthy) with the excuse that this is justified to protect those most at risk (the very old, especially those with pre-existing health conditions). This is a direct violation of the Hippocratic Oath. And it's completely nonsensical. If you're unwilling to risk exposure to the virus, stay home. Your risk as you shelter at home is exactly the same whether I'm at home in lockdown or whether I'm at work to feed my family or visiting my loved ones to protect my (or their) mental health.&nbsp;</p><p>The right to individual autonomy was specifically invented to allow free people to weigh their risks and priorities. For most of us there are many risks in our daily lives (like being unable to feed our families) that are far more dangerous than a virus that even the <a href="https://www.cdc.gov/coronavirus/2019-ncov/hcp/planning-scenarios.html" target="_blank">US CDC says</a> has an infection <i>survival</i> rate of 99.997% for those under 20 years of age, 99.98% for 20 to 49 year olds, 99.5% for 50 to 69 year olds and 94.6% for anyone over the age of 70. To put that in perspective, Dr. John Ioannidis, professor of epidemiology and biomedical statistics at the University of Stanford,&nbsp;<a href="https://www.medrxiv.org/content/10.1101/2020.04.05.20054361v1" target="_blank">has calculated</a> that for people under the age of 65, the COVID death risk is "equivalent to the death risk of driving from between 9 miles per day (in Germany) and 415 miles per day (in New York City)."</p><p><a href="https://1.bp.blogspot.com/-RqXjOJWQMHI/YAi7WuLr8jI/AAAAAAAAAiE/pTQhFrFPWhgCgEcMg3JbQ6xxFIySJ-9xQCLcBGAsYHQ/s409/CDC%2Bplanning%2Bscenarios.jpg"><img data-original-height="409" data-original-width="381" height="320" src="https://1.bp.blogspot.com/-RqXjOJWQMHI/YAi7WuLr8jI/AAAAAAAAAiE/pTQhFrFPWhgCgEcMg3JbQ6xxFIySJ-9xQCLcBGAsYHQ/s320/CDC%2Bplanning%2Bscenarios.jpg"></a></p><p>And are government lockdowns actually protecting those at risk? A very large proportion of COVID deaths worldwide are occurring in long-term care homes (in Canada 72% of COVID deaths have been in long-term care facilities!)&nbsp;</p><p>Lockdowns don't help those most at risk if they are already segregated from society in nursing homes. But isolation does accelerate deteriorating health conditions among nursing home patients who are denied the ability to spend the last few months of their lives surrounded by loved ones.&nbsp;</p><table><tbody><tr><td><a href="https://www.ctvnews.ca/health/facing-another-retirement-home-lockdown-90-year-old-chooses-medically-assisted-death-1.5197140" target="_blank"><img data-original-height="678" data-original-width="796" height="238" src="https://1.bp.blogspot.com/-w0QHXzPCGlk/YAjZDCxEsKI/AAAAAAAAAj0/f2Qa5p9jwRI6SAIkuJN0-p392GjBNjflQCLcBGAsYHQ/w400-h341/Nancy-Russell.jpg" width="280"></a></td></tr><tr><td>Why don't nursing home residents get to decide for themselves if they want to be isolated?</td></tr></tbody></table><p>By trying to "flatten the curve", lockdowns only extend the amount of time it takes for the rest of the population to acquire herd immunity, which increases the amount of time that the most vulnerable are at risk of being exposed to others carrying the virus. Instead of self-isolating for a month while the virus runs its course among the rest of the population (like influenza does every winter) they have now been at risk of catching COVID from the rest of us for almost 10 months - 10 months during which many have been forcibly stuck in isolation, separated from their loved ones!&nbsp;</p><p>In other words, if you don't pull the switch, the vulnerable are at risk. But if you do pull the switch, the risk increases to the most vulnerable while also putting everyone else in harm's way.&nbsp;</p><p>Another excuse given for lockdowns is that the health care system is at risk of getting overwhelmed. It's another bizarre and immoral argument. Since when does access to health care override our right to freedom, individual autonomy, and the ability to try to feed our families? If that were an acceptable excuse for lockdowns, the government would pull the switch and lock down society every winter. Hallway medicine and overworked hospital staff have long been the norm of our poorly managed health care systems every flu season. Here is a small sample of news articles illustrating the problem. Check the dates - <i>all</i> are from <i>before</i>&nbsp;COVID!</p><p>This&nbsp;<a href="https://www.cbc.ca/news/canada/toronto/ontario-hospital-hallway-medicine-healthcare-beyond-capacity-1.5420434" target="_blank">CBC article from January of 2020</a>&nbsp;shows that from January to June 2019 (180 days) some of the most overcrowded hospitals in Ontario spent between 148 and 179 of the 180-day study period operating above 100% capacity. In other words, they were essentially operating above capacity <i>every single day</i>!&nbsp;</p><p><a href="https://1.bp.blogspot.com/-UAxghG47dkw/YAjorm4HkDI/AAAAAAAAAkg/GSv--GCBtd8S3F0qVHR7vejMPq0dOI2dgCPcBGAYYCw/s1494/Ontario%2Bovercapacity.jpg"><img data-original-height="1494" data-original-width="770" height="543" src="https://1.bp.blogspot.com/-UAxghG47dkw/YAjorm4HkDI/AAAAAAAAAkg/GSv--GCBtd8S3F0qVHR7vejMPq0dOI2dgCPcBGAYYCw/w351-h681/Ontario%2Bovercapacity.jpg" width="280"></a></p><p>This <a href="https://www.cbc.ca/news/canada/ottawa/gatineau-hospitals-experiencing-overcrowding-1.4522191" target="_blank">CBC article from February 2018</a> shows&nbsp;hospitals in Quebec running at up to 245% capacity.&nbsp;</p><p><a href="https://1.bp.blogspot.com/-ICcyaUhMTKo/YAjoruYCKCI/AAAAAAAAAko/MlMVG6frqGkYcja6LJT9eaC9-AQSzHoDgCPcBGAYYCw/s1006/Gatineau%2B245%2Bpercent%2Bhospital.jpg"><img data-original-height="1006" data-original-width="745" height="378" src="https://1.bp.blogspot.com/-ICcyaUhMTKo/YAjoruYCKCI/AAAAAAAAAko/MlMVG6frqGkYcja6LJT9eaC9-AQSzHoDgCPcBGAYYCw/w474-h640/Gatineau%2B245%2Bpercent%2Bhospital.jpg" width="280"></a></p><p>This&nbsp;<a href="https://www.cbc.ca/news/canada/sudbury/hospital-health-sciences-north-overcrowding-1.5139909" target="_blank">CBC article from May 2019</a>&nbsp;discusses how common it has become for patients to be housed not just in hallways, but even in bathrooms!</p><p><a href="https://1.bp.blogspot.com/-V-tyjsNoWHU/YAjosRqS4XI/AAAAAAAAAkk/JqXMfB7n29w5D7oq2NLpyDME2V0lqWTVQCPcBGAYYCw/s878/Patients%2Bin%2Bbathrooms.jpg"><img data-original-height="766" data-original-width="878" height="244" src="https://1.bp.blogspot.com/-V-tyjsNoWHU/YAjosRqS4XI/AAAAAAAAAkk/JqXMfB7n29w5D7oq2NLpyDME2V0lqWTVQCPcBGAYYCw/w400-h349/Patients%2Bin%2Bbathrooms.jpg" width="280"></a></p><p>And&nbsp;this&nbsp;<a href="https://www.ctvnews.ca/health/about-1-000-patients-in-hospital-hallways-on-any-given-day-report-1.4276591" target="_blank">CTV article from January 2019</a> demonstrates that in Ontario about 1000 patients were being treated in hospital hallways <i>every single day</i>&nbsp;long before COVID hit. For context, as I write this today, January 21st, 2021, Ontario (a province of over 14 million) has a grand total of 1,533 COVID hospitalizations&nbsp;<i>in the entire province</i>. None are currently being treated in hallways;&nbsp;<a href="https://toronto.ctvnews.ca/toronto-s-icus-will-reach-capacity-by-late-january-as-pandemic-continues-to-worsen-top-doctor-says-1.5271345" target="_blank">some hospitals are nearing capacity</a>, but as I've just finished showing you, that means they are <i>below</i>&nbsp;the typical occupancy levels seen at this time of year prior to COVID.</p><p><a href="https://1.bp.blogspot.com/-MUqU1Yblw3c/YAjorki0N7I/AAAAAAAAAkc/RtaBEk9kgSsQ7ACNvd0TsmjgplXrzypBQCPcBGAYYCw/s792/1000%2Bpatients%2BJan2019.jpg"><img data-original-height="792" data-original-width="742" height="298" src="https://1.bp.blogspot.com/-MUqU1Yblw3c/YAjorki0N7I/AAAAAAAAAkc/RtaBEk9kgSsQ7ACNvd0TsmjgplXrzypBQCPcBGAYYCw/w375-h400/1000%2Bpatients%2BJan2019.jpg" width="280"></a></p><p>I've posted even more examples of the pre-COVID hospital crisis on a Twitter thread&nbsp;<a href="https://mobile.twitter.com/JuliusRuechel/status/1341826835924082690" target="_blank">here</a>. &nbsp;</p><p>The government's failure to provide adequate health care capacity is not an exemption that allows government to suspend the constitutional rights and freedoms of its citizens. But I encourage you to read the Universal Declaration of …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.juliusruechel.com/2021/01/bystander-at-switch-moral-case-against.html?m=1">https://www.juliusruechel.com/2021/01/bystander-at-switch-moral-case-against.html?m=1</a></em></p>]]>
            </description>
            <link>https://www.juliusruechel.com/2021/01/bystander-at-switch-moral-case-against.html?m=1</link>
            <guid isPermaLink="false">hacker-news-small-sites-25988743</guid>
            <pubDate>Mon, 01 Feb 2021 14:03:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenSky Covid-19 Flight Dataset]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25988731">thread link</a>) | @Nightlifer
<br/>
February 1, 2021 | https://opensky-network.org/community/blog/item/6-opensky-covid-19-flight-dataset | <a href="https://web.archive.org/web/*/https://opensky-network.org/community/blog/item/6-opensky-covid-19-flight-dataset">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Over the past year we have been inundated with requests regarding flight data related to the COVID-19 pandemic. While we have done our best to help researchers around the world using our trusted <a href="https://opensky-network.org/data/impala">Impala shell</a>, we have also released a public version of the flight meta data that we have collected over the whole year of 2020 plus the whole year of 2019 for a pre-COVID-19 comparison. If you are only interested in the data, you can find it over at CERN's Zenodo repository: <a href="https://doi.org/10.5281/zenodo.3737101">https://doi.org/10.5281/zenodo.3737101</a></p>
<p>We currently plan to update this dataset monthly during the pandemic. If you have research needs that go beyond this release model, you can <a href="https://opensky-network.org/data/apply">apply for full data access</a> with us.</p>
<p>The main use cases of flight data related to the pandemic are manifold: First, flight data can be used as input for models analysing and predicting the global spread of the virus. Second, flights as an indicator of economic activity can provide insights into the impact of the pandemic on both countries' economies in general and the aviation industry in particular. Finally, the data has become popular for analysis in Earth Systems Sciences over the course of the year. We have a pre-print discussing this here. [1] The data in this dataset is derived and cleaned from the full OpenSky dataset and made fully publicly available for the first time. It spans metadata for all flights seen by the network's more than 3500 members in 2019 and 2020.</p>
<p>The most important point to remember is that as these data are derived from our awesome feeders, we cannot provide every global flight movement in our dataset but only <strong>those ADS-B-equipped aircraft seen within our coverage</strong>!<br>An overview of our coverage is provided for any given day on our <a href="https://opensky-network.org/network/facts">Facts page</a>. An example for yesterday (2020-04-02) is shown here:</p>
<p><img src="https://opensky-network.org/images/coverage.png" alt="coverage"></p>
<p>If you have access to a place that is not yet covered by OpenSky and want to see researchers include that area in the future, please <a href="https://opensky-network.org/contribute/improve-coverage">do provide a feed</a>!</p>
<p>[1] Strohmeier, M., Olive, X., Lübbe, J., Schäfer, M., and Lenders, V.: <a href="https://essd.copernicus.org/preprints/essd-2020-223/">Crowdsourced Air Traffic Data from the OpenSky Network 2019–20</a>, Earth Syst. Sci. Data. [preprint], 2021.&nbsp;</p>
<h2>Usage Examples &amp; Tools</h2>
<p>Xavier Olive from ONERA has made some initial plots using this dataset, illustrating for example the drop in air traffic at specific airports during the early phase of the pandemic:</p>
<p><img src="https://opensky-network.org/images/canvas.png" alt="canvas"></p>

<p>More up-to-date visualisations and code for use with this dataset can be found over at <a href="https://traffic-viz.github.io/scenarios/covid19.html">Impact of COVID-19 on worldwide aviation.</a></p>
<p>Since the dataset is naturally large, we recommend using tools such as <a href="https://opensky-network.org/r-project.org">R</a>, <a href="https://opensky-network.org/python.org">Python</a> or <a href="https://opensky-network.org/mathworks.com">Matlab</a> for processing vast quantities of data. You can find more tools, that interface directly with our Live API and our Impala shell on our <a href="https://opensky-network.org/data/data-tools">data tools subpage</a>.</p>
<p>If you want to split these files into smaller .csv files before loading them into your preferred processing programme, we recommend using<a href="https://www.windows10download.com/csv-splitter/"> CSV Splitter (Windows)</a> or the Linux/<a href="https://eikhart.com/blog/autosplit-csv">MacOS</a> split command.</p>
        </div></div>]]>
            </description>
            <link>https://opensky-network.org/community/blog/item/6-opensky-covid-19-flight-dataset</link>
            <guid isPermaLink="false">hacker-news-small-sites-25988731</guid>
            <pubDate>Mon, 01 Feb 2021 14:01:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Simple Way to Start Measuring Developer Efficiency]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25988662">thread link</a>) | @pickledish
<br/>
February 1, 2021 | http://www.willett.io/posts/developer-friction/ | <a href="https://web.archive.org/web/*/http://www.willett.io/posts/developer-friction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>

			<div>
				<div>
					<p>I’m a monitoring nut. I’m a firm believer that you can’t improve what you’re not measuring, so it’s always fun for me to try to quantify everything at work that people care about – even the stuff that’s generally too challenging to “pin down” to bother. So when the question at work comes up of “how do we make our developers more efficient”, the only response I can come up with is “well, how are we measuring it?”</p>

<p>The conversation around developer efficiency at larger software shops is of course worth having. But in order to make quantifiable progress in this area, we’ll need to have some numerical sense of the friction that developers face in their day-to-day tasks. Here, I’ll briefly describe one method I’ve been using for the last few years, which has served me well enough to start making useful comparisons across months, teams, and companies.</p>

<h2 id="comparing-to-a-baseline">Comparing to a Baseline</h2>

<p><img src="http://www.willett.io/assets/friction-none.png" alt=""></p>

<p>No measurement can be useful without units, right? A number line, an axis, some concept of “zero”. It doesn’t matter <em>where</em> on the number line this zero is; its main purpose is to be a easily-recognizable fixed point which we can compare to other points (and indeed, it allows us to compare points to each other).</p>

<p>In my scale of developer friction, the “zero point” for a software development (or ops) task is “<strong>how long this would take me to do for my own project on a Saturday morning</strong>”. No company infrastructure, no automated test suite and deployment process, no metrics or log aggregation or responsive alerting. Just you, one server with root access, and one or two apps running on that server. In this tiny-world model of your unit of work, how much time do you have to spend in order to see it through?</p>

<p>This kind of comparison against the requirements of a company’s <a href="https://en.wikipedia.org/wiki/Systems_development_life_cycle">SDLC</a> might not be perfectly “fair” for a number of reasons, but by comparing against this baseline, we can at least begin to quantify the help/hurt of that company’s infrastructure.</p>

<h2 id="reducing-friction">Reducing Friction</h2>

<p><img src="http://www.willett.io/assets/friction-less.png" alt=""></p>

<p>A developer facing less friction in getting their change safely validated and deployed is always a good thing, and work in this direction is usually very deliberate. Larger software companies will have entire teams dedicated to the effort. After all, if you can save each developer 5 minutes of time in deploying a change for example, you’re looking at dozens of hours (and thousands of dollars) saved per month.</p>

<p>Examples of reducing developer friction below the “baseline” include:</p>

<ul>
  <li>A CI/CD system which will automatically run <a href="https://www.terraform.io/docs/cli/commands/apply.html"><code>terraform apply</code></a> when a PR to a repository containing <a href="https://en.wikipedia.org/wiki/Infrastructure_as_code">infrastructure as code</a> is merged</li>
  <li>An internal profiling system that allows developers to spend less time figuring out what caused an app’s memory usage to spike, and more time fixing it</li>
</ul>

<h2 id="increasing-friction">Increasing Friction</h2>

<p><img src="http://www.willett.io/assets/friction-more.png" alt=""></p>

<p>In contrast, “increased developer friction” almost universally happens by accident, or at least accumulates slowly over the lifetime of a software product.</p>

<p>Despite first instinct, it doesn’t generally come from leadership having bad prioritization, or coworkers who “just didn’t think things through enough”. Instead, it’s more due to the top-down necessity of additional security/compliance measures, or more often in my experience, added process as a direct result (a “follow-up”) of a previous outage in an effort to avoid the same thing happening again.</p>

<p>Examples of increasing developer friction above the “baseline” include:</p>

<ul>
  <li>A suite of unit tests that include a few “flaky tests”, which occasionally fail after 10 minutes and need to be re-run before a deployment can be triggered</li>
  <li>A change that needs to be executed across several different applications in different places, in a specific order or all at the same time</li>
</ul>

<h2 id="a-real-life-example">A Real Life Example</h2>

<p>One job I’ve done in the past made a <em>particularly good</em> example of this model. It involved the deployment of updates to configuration files that “lived” in various places – some rendered into our base machine image, some rendered at instance creation time, and some pulled dynamically at runtime (using something like <a href="https://www.consul.io/">Consul</a>).</p>

<p>In order to update a configuration file rendered into the base image, we needed to spin up a bare VM, install dependencies, run all provisioning scripts, save the image, hardcode the new image ID in various other places, and create some “real” VMs to verify it worked. This is significantly <strong><span>more friction</span></strong> than our “Saturday morning” baseline – the entire process took hours, and would often fail in the middle since it wasn’t performed very often.</p>

<p>In contrast, updating an instance-creation-time configuration was easy, and just required making a pull request and then running something like <a href="https://www.ansible.com/">Ansible</a> or <a href="https://www.chef.io/">Chef</a> on each already-existing VM. This is <strong>about even</strong> with the baseline – I had to update the file, make a PR, and run a script or two in order to make sure the instances were up to date.</p>

<p>And in comparison, updating a dynamic configuration took barely any thought at all. Our deployment system was always synced to the Git repository, so as soon as the field was updated there, each instance would start seeing the new value immediately. This is much <strong><span>less friction</span></strong> than the task would have been by myself – the update only required a short pull request, and the deployment happened automatically.</p>

<h2 id="vector-addition">Vector Addition</h2>

<p><img src="http://www.willett.io/assets/friction-math.png" alt=""></p>

<p>Of course, any real software project will be more nuanced than any example in a blog post. The real friction your developers feel is affected by dozens of small factors, some negative and some positive, each costing or freeing a few minutes of their time.</p>

<p>Fortunately, there’s no complicated math here, and the total friction they’ll experience is just the <strong>sum of each individual gain or loss</strong> of efficiency. So if a developer loses 10 minutes of her time setting up explicit new permissions for her app, and loses 10 more waiting on a suite of unit tests that have nothing to do with her change, but gained 30 minutes back by having the CD system roll out her change to each region (rolling back automatically when needed, so she doesn’t need to watch dashboards) – that’s a 10-minute win overall!</p>

<p>At the end of the day, requirements will often dictate that making change is slower than it would be on your own server on a Saturday. But hopefully, this can be a useful, <strong>concrete</strong> way to start telling the difference between a developer feeling frustrated or empowered by the company’s infrastructure, and to see if you’re really making progress.</p>

				</div>
			</div>

		</section></div>]]>
            </description>
            <link>http://www.willett.io/posts/developer-friction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25988662</guid>
            <pubDate>Mon, 01 Feb 2021 13:52:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Verify Email Domains with Cognito]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25988617">thread link</a>) | @adzicg
<br/>
February 1, 2021 | https://www.serverless.pub/cognito-verify-email-domains/ | <a href="https://web.archive.org/web/*/https://www.serverless.pub/cognito-verify-email-domains/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
        <div>
            

            <p>
                <a href="https://www.serverless.pub/author/gojko">Gojko Adzic</a> in <a href="https://www.serverless.pub/category/Serverless">Serverless</a> <i></i> <i></i> 

  2 minutes

            </p>

            <p>Mistyped emails can be a huge problem for user registrations. In this quick tip, I’ll show you how to prevent a huge percentage of such problems by adding a Cognito PreSignUp trigger to validate email domains.</p>

<p>At <a href="https://www.narakeet.com/">Narakeet</a>, an online app lets users script narrated videos with markdown, about 10% of user registrations went into a black hole because people mistyped their email. I’ve probably seen every possible way to butcher ‘gmail’ in the email bounce logs.</p>

<p>Because users could not confirm the registration, they could not sign in and use the app. That made a very bad first impression. Visitors might think that the application is broken and never come back, instead of fixing their email during registration. To add insult to injury, with an invalid email, I would not be able to get in touch with them to provide assistance.</p>

<h2 id="presignup-trigger-to-the-rescue">PreSignUp trigger to the rescue</h2>

<p>Cognito user pools can be customised with various triggers. The <code>PreSignUp</code> trigger allows you to modify the sign-up process. Most of the examples online show how to speed up the user funnel, automatically confirming attributes and skipping steps of the usual registration process. However, we can also use this trigger to slow users down then they make a mistake.</p>

<p>Here’s a trivial Node.js Lambda function that will check that the domain of the user provided email exists, and that it is actually configured to receive incoming email. It also logs some basic information for CloudWatch insights.</p>

<div><div><pre><code><span>'</span><span>use strict</span><span>'</span><span>;</span>
<span>const</span> <span>dns</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>dns</span><span>'</span><span>);</span>
<span>exports</span><span>.</span><span>handler</span> <span>=</span> <span>async</span> <span>(</span><span>event</span><span>)</span> <span>=&gt;</span> <span>{</span>
	<span>const</span> <span>email</span> <span>=</span> <span>event</span><span>.</span><span>request</span><span>.</span><span>userAttributes</span><span>.</span><span>email</span><span>,</span>
		<span>domain</span> <span>=</span> <span>email</span><span>.</span><span>replace</span><span>(</span><span>/^.*@/</span><span>,</span> <span>''</span><span>)</span> <span>||</span> <span>''</span><span>;</span>
	<span>try</span> <span>{</span>
		<span>if</span> <span>(</span><span>!</span><span>domain</span><span>)</span> <span>{</span>
			<span>throw</span> <span>'</span><span>Email format invalid</span><span>'</span><span>;</span>
		<span>}</span>
		<span>const</span> <span>servers</span> <span>=</span> <span>await</span> <span>dns</span><span>.</span><span>promises</span><span>.</span><span>resolveMx</span><span>(</span><span>domain</span><span>);</span>
		<span>if</span> <span>(</span><span>Array</span><span>.</span><span>isArray</span><span>(</span><span>servers</span><span>)</span> <span>&amp;&amp;</span> <span>servers</span><span>.</span><span>length</span> <span>&gt;</span> <span>0</span><span>)</span> <span>{</span>
			<span>console</span><span>.</span><span>log</span><span>(</span><span>JSON</span><span>.</span><span>stringify</span><span>({</span><span>verification</span><span>:</span> <span>true</span><span>,</span> <span>domain</span><span>}));</span>
			<span>return</span> <span>event</span><span>;</span>
		<span>}</span> <span>else</span> <span>{</span>
			<span>throw</span> <span>'</span><span>no-servers</span><span>'</span><span>;</span>
		<span>}</span>
	<span>}</span> <span>catch</span> <span>(</span><span>error</span><span>)</span> <span>{</span>
		<span>console</span><span>.</span><span>log</span><span>(</span><span>JSON</span><span>.</span><span>stringify</span><span>({</span><span>verification</span><span>:</span> <span>false</span><span>,</span> <span>domain</span><span>,</span> <span>error</span><span>}));</span>
		<span>throw</span> <span>`Cannot verify email domain </span><span>${</span><span>domain</span><span>}</span><span>. Please check for typos`</span><span>;</span>
	<span>}</span>
<span>};</span>
</code></pre></div></div>

<p>When a user mistypes <code>gmail.com</code> as <code>gmal.com</code>, instead of proceeding with the signup, they will see a message such as the one below:</p>

<p><img src="https://www.serverless.pub/img/cognito-domains-big.png" alt=""></p>

<p>The error isn’t ideal – I would prefer not to have the initial part showing users that a trigger failed, but with Cognito hosted UI that’s the best you can get.</p>

<p>Of course, this doesn’t protect you from people mistyping the first part of their email, or mistyping a domain that can also receive messages, but it will at least prevent a large portion of email issues. Popular email providers tend to buy up similarly-sounding domains to prevent squatting, so in practice this little trick can save a lot of users from dropping off the funnel.</p>



            

        </div><!-- main-content/col -->
    </div> <!--/row -->

</div></div>]]>
            </description>
            <link>https://www.serverless.pub/cognito-verify-email-domains/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25988617</guid>
            <pubDate>Mon, 01 Feb 2021 13:47:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Short Seller’s Warning Helped to Expose Luckin Coffee's Accounting Fraud]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25988496">thread link</a>) | @1experience
<br/>
February 1, 2021 | https://www.wsj.com./articles/coffees-for-closers-how-a-short-sellers-warning-helped-take-down-luckin-coffee-11593423002 | <a href="https://web.archive.org/web/*/https://www.wsj.com./articles/coffees-for-closers-how-a-short-sellers-warning-helped-take-down-luckin-coffee-11593423002">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
         <p>In January, days after the shares of  Luckin Coffee Inc.  hit a record high on the  Nasdaq Stock Market ,  giving the company a $12 billion valuation, a cryptic email arrived in the inboxes of multiple short sellers. </p>
         <p>“A new generation of Chinese Fraud 2.0 has emerged,” it said. “Companies that start off as fundamentally and structurally flawed business model [sic] that evolves into fraud.” The author offered to share customer receipts and videos from Luckin Coffee outlets, attached a long report about the company and said the short sellers could publish and take credit for it.</p>
         <p>Several American money managers reviewed the report, which accused Luckin of inflating its sales. Carson Block of Muddy Waters LLC published it, posting the 89-page report on Twitter on Jan. 31.  </p>
         <p>Luckin’s auditor subsequently discovered that several employees had faked revenue and expenses and on April 2, <a href="https://www.wsj.com/articles/luckin-coffee-accuses-operating-chief-of-financial-misconduct-11585840274?mod=article_inline" target="_blank">the company disclosed</a> that as much as $310 million of its 2019 sales was fabricated. Its shares collapsed, less than 11 months after the company went public, <a href="https://www.wsj.com/articles/luckin-coffee-drops-nasdaq-appeal-shares-to-be-delisted-11593188282?mod=article_inline" target="_blank">and will soon be delisted</a>.</p>
         <p><a href="https://www.wsj.com/articles/behind-the-fall-of-chinas-luckin-coffee-a-network-of-fake-buyers-and-a-fictitious-employee-11590682336?mod=article_inline" target="_blank">The stunning fall of Luckin</a>, an upstart rival to  Starbucks Corp.  in China that touted itself as the country’s largest coffee chain by stores, has sparked a lot of investor soul-searching. Should they have followed the recommendation of Mr. Block, who has bet against multiple listed Chinese companies? Should they have doubted the company when it disputed the allegations in the anonymous report? Could they have done more due diligence to determine whether Luckin’s reported growth was too good to be true?</p>
  </div></div>]]>
            </description>
            <link>https://www.wsj.com./articles/coffees-for-closers-how-a-short-sellers-warning-helped-take-down-luckin-coffee-11593423002</link>
            <guid isPermaLink="false">hacker-news-small-sites-25988496</guid>
            <pubDate>Mon, 01 Feb 2021 13:32:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Barriers and Atomic Smart Pointers in C++20]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25988369">thread link</a>) | @ibobev
<br/>
February 1, 2021 | http://modernescpp.com/index.php/barriers-in-c-20 | <a href="https://web.archive.org/web/*/http://modernescpp.com/index.php/barriers-in-c-20">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="blogContent">
				<p>In my last post, I introduced latches in C++20. A latch enables it threads to wait until a counter becomes zero. Additionally, to a latch, its big sibling barrier can be used more than once. Today, I write about barriers and present atomic smart pointers.</p>

<p>&nbsp;<img src="http://modernescpp.com/images/blog/Cpp20/Barrier/TimelineCpp20.png" alt="TimelineCpp20" width="650" height="224"></p>
<p>If you are not familiar with std::latch, read my last post: <a href="https://bit.ly/39eH23G">Latches in C++20</a>.</p>
<h2 id="h1-std-barrier"><code>std::barrier</code></h2>
<p>There are two differences between a <code>std::latch</code> and a <code>std::barrier</code>. A <code>std::latch</code> is useful for managing one task by multiple threads; a<code> std::barrier</code> is helpful for managing repeated tasks by multiple threads.&nbsp;Additionally, a <code>std::barrier</code> enables you to execute a function in the so-called completion step. The completion step is the state when the counter becomes zero. Immediately after the counter becomes zero, the so-called completion step starts. In this completion step, a callable is invoked. The <code>std::barrier</code> gets its callable in its constructor. A callable unit (short callable) is something that behaves like a function. Not only are these named functions, but also function objects or lambda expressions.</p>
<p>The completion step performs the following steps:</p>
<ol>
<li>All threads are blocked.</li>
<li>An arbitrary thread is unblocked and executes the callable.</li>
<li>If the completion step is done, all threads are unblocked.</li>
</ol>
<p>The following table presents you the interface of a <code>std::barrier bar.</code></p>
<p><img src="http://modernescpp.com/images/blog/Cpp20/Barrier/barrier.png" alt="barrier" width="650" height="222"></p>

<p>The<code> call bar.arrive_and_drop()</code> call means essentially, that the counter is decremented by one for the next phase. The following program<code> fullTimePartTimeWorkers.cpp</code> halves the number of workers in the second phase.</p>
<!-- HTML generated using hilite.me -->
<div>
<pre><span>// fullTimePartTimeWorkers.cpp</span>

<span>#include &lt;iostream&gt;</span>
<span>#include &lt;barrier&gt;</span>
<span>#include &lt;mutex&gt;</span>
<span>#include &lt;string&gt;</span>
<span>#include &lt;thread&gt;</span>

std<span>::</span>barrier workDone(<span>6</span>);
std<span>::</span>mutex coutMutex;

<span>void</span> <span>synchronizedOut</span>(<span>const</span> std<span>::</span>string<span>&amp;</span> s) noexcept {
    std<span>::</span>lock_guard<span>&lt;</span>std<span>::</span>mutex<span>&gt;</span> lo(coutMutex);
    std<span>::</span>cout <span>&lt;&lt;</span> s;
}

<span>class</span> <span>FullTimeWorker</span> {                                                   <span>// (1)</span>
 <span>public:</span>
    FullTimeWorker(std<span>::</span>string n)<span>:</span> name(n) { };
  
    <span>void</span> <span>operator</span>() () {
        synchronizedOut(name <span>+</span> <span>": "</span> <span>+</span> <span>"Morning work done!</span><span>\n</span><span>"</span>);
        workDone.arrive_and_wait();  <span>// Wait until morning work is done     (3)</span>
        synchronizedOut(name <span>+</span> <span>": "</span> <span>+</span> <span>"Afternoon work done!</span><span>\n</span><span>"</span>);
        workDone.arrive_and_wait();  <span>// Wait until afternoon work is done   (4)</span>
        
    }
 <span>private:</span>
    std<span>::</span>string name;
};
  
<span>class</span> <span>PartTimeWorker</span> {                                                   <span>// (2)</span>
 <span>public:</span>
    PartTimeWorker(std<span>::</span>string n)<span>:</span> name(n) { };
  
    <span>void</span> <span>operator</span>() () {
        synchronizedOut(name <span>+</span> <span>": "</span> <span>+</span> <span>"Morning work done!</span><span>\n</span><span>"</span>);
        workDone.arrive_and_drop();  <span>// Wait until morning work is done  // (5)</span>
    }
 <span>private:</span>
    std<span>::</span>string name;
};

<span>int</span> <span>main</span>() {

    std<span>::</span>cout <span>&lt;&lt;</span> <span>'\n'</span>;

    FullTimeWorker herb(<span>"  Herb"</span>);
    std<span>::</span><span>thread</span> herbWork(herb);
  
    FullTimeWorker scott(<span>"    Scott"</span>);
    std<span>::</span><span>thread</span> scottWork(scott);
  
    FullTimeWorker bjarne(<span>"      Bjarne"</span>);
    std<span>::</span><span>thread</span> bjarneWork(bjarne);
  
    PartTimeWorker andrei(<span>"        Andrei"</span>);
    std<span>::</span><span>thread</span> andreiWork(andrei);
  
    PartTimeWorker andrew(<span>"          Andrew"</span>);
    std<span>::</span><span>thread</span> andrewWork(andrew);
  
    PartTimeWorker david(<span>"            David"</span>);
    std<span>::</span><span>thread</span> davidWork(david);

    herbWork.join();
    scottWork.join();
    bjarneWork.join();
    andreiWork.join();
    andrewWork.join();
    davidWork.join();
  
}
</pre>
</div>

<p>This workflow consists of two kinds of workers: full-time workers (1) and part-time workers (2). The part-time worker work in the morning, the full-time worker in the morning and the afternoon. Consequently, the full time workers call<code> workDone.arrive_and_wait()</code> (lines (3) and (4)) two times. On the contrary, the part-time works call <code>workDone.arrive_and_drop()</code> (5) only once. This <code>workDone.arrive_and_drop()</code> call causes the part-time worker to skip the afternoon work. Accordingly, the counter has in the first phase (morning) the value 6, and in the second phase (afternoon) the value 3.</p>
<p><img src="http://modernescpp.com/images/blog/Cpp20/Barrier/fullTimePartTimeWorkers.png" alt="fullTimePartTimeWorkers" width="500" height="328"></p>
<p>Now to something, I missed in my posts to atomics.</p>
<h2 id="h2-atomic-smart-pointers">Atomic Smart Pointers</h2>
<p>A <code>std::shared_ptr</code> consists of a control block and its resource. The control block is thread-safe, but access to the resource is not. This means modifying the reference counter is an atomic operation and you have the guarantee that the resource is deleted exactly once. These are the guarantees <code>std::shared_ptr</code> gives you.</p>
<p>On the contrary, it is crucial that a <code>std::shared_ptr</code> has well-defined multithreading semantics. At first glance, the use of a <code>std::shared_ptr</code> does not appear to be a sensible choice for multithreaded code. It is by definition shared and mutable and is the ideal candidate for non-synchronized read and write operations and hence for undefined behavior. On the other hand, there is the guideline in modern C++: <strong>Don't use raw pointers</strong>. This means, consequently, that you should use smart pointers in multithreading programs when you want to model shared ownership.</p>
<p>The proposal <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4162">N4162</a> for atomic smart pointers directly addresses the deficiencies of the current implementation. The deficiencies boil down to these three points: consistency, correctness, and performance.</p>
<ul>
<li><strong>Consistency</strong>: the atomic operations for <code>std::shared_ptr</code> are the only atomic operations for a non-atomic data type.</li>
<li><strong>Correctness</strong>: the usage of the global atomic operations is quite error-prone because the correct usage is based on discipline. It is easy to forget to use an atomic operation - such as using <code>ptr = localPtr</code> instead of <code>std::atomic_store(&amp;ptr, localPt</code>r). The result is undefined behavior because of a data race. If we used an atomic smart pointer instead, the type-system would not allow it.</li>
<li><strong>Performance</strong>: the atomic smart pointers have a big advantage compared to the free <code>atomic_</code>* functions. The atomic versions are designed for the special use case and can internally have a<code> std::atomic_flag</code> as a kind of cheap <a href="https://en.wikipedia.org/wiki/Spinlock">spinlock</a>. Designing the non-atomic versions of the pointer functions to be thread-safe would be overkill if they are used in a single-threaded scenario. They would have a performance penalty.</li>
</ul>
<p>The correctness argument is probably the most important one. Why? The answer lies in the proposal. The proposal presents a thread-safe singly linked list that supports insertion, deletion, and searching of elements. This singly linked list is implemented in a lock-free way.</p>
<p><img src="http://modernescpp.com/images/blog/Cpp20/Barrier/AtomicSinglyLinkedList.png" alt="AtomicSinglyLinkedList"></p>

<p>All changes that are required to compile the program with a C++11 compiler are marked in red. The implementation with atomic smart pointers is a lot easier and hence less error-prone. C++20's type system does not permit it to use a non-atomic operation on an atomic smart pointer.</p>
<p>The proposal <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4162">N4162</a> proposed the new types <code>std::atomic_shared_ptr</code> and <code>std::atomic_weak_ptr</code> as atomic smart pointers. By merging them in the mainline ISO C++ standard, they became partial template specialization of <a href="https://en.cppreference.com/w/cpp/atomic/atomic">std::atomic</a>: <code>std::atomic&lt;std::shared_ptr&gt;</code>, and <code>std::atomic&lt;std::weak_ptr&gt;</code>.</p>
<p>Consequently, the atomic operations for <code>std::shared_ptr&lt;T&gt;</code> are deprecated with C++20.</p>
<h2 id="h3-what-s-next">What's next?</h2>
<p>With C++20, threads can be cooperatively interrupted.&nbsp; Let me show you in my next, what that means.</p>

<div>
	<p><strong>Thanks a lot to my <a href="https://www.patreon.com/rainer_grimm">Patreon Supporters</a></strong><strong>: Matt Braun, Roman Postanciuc, Tobias Zindl, Marko, </strong><span title="Emyr Williams"><strong>G Prvulovic, Reinhold Dröge, Abernitzke,</strong> </span><strong><span title="Emyr Williams">Frank Grimm</span></strong><span title="Emyr Williams"><strong>, Sakib, Broeserl, </strong></span><strong><span title="Emyr Williams">António Pina, Darshan Mody, Sergey Agafyin, <span data-tag="user-details-full-name">Андрей Бурмистров, Jake, GS, Lawton Shoemake, Animus24, Jozo Leko, John Breland, espkk, Wolfgang Gärtner</span></span><span title="Emyr Williams"><span><span></span></span></span>,&nbsp; Louis St-Amour, Stephan Roslen, Venkat Nandam, Jose Francisco, Douglas Tinkham, Kuchlong Kuchlong, Avi Kohn, Robert Blanch, Truels Wissneth, Kris Kafka, Mario Luoni, Neil Wang, Friedrich Huber, lennonli, Pramod Tikare Muralidhara, Peter Ware, and Tobi Heideman.<br></strong></p>

<p><strong>Thanks in particular to Jon Hess, Lakshman,</strong> <strong>Christian Wittenhorst, Sherhy Pyton, Dendi Suhubdy, Sudhakar Belagurusamy, and Richard Sargeant.<br></strong></p>
<p>My special thanks to Embarcadero <a href="https://www.embarcadero.com/products/cbuilder"><img src="http://modernescpp.com/images/Embarcadero/CBUIDER_STUDIO_FINAL_ICONS_1024_Small.png" alt="CBUIDER STUDIO FINAL ICONS 1024 Small" width="100" height="100"></a></p>

<h2>Seminars</h2>
<p>I'm happy to give online-seminars or face-to-face seminars world-wide. Please call me if you have any questions.</p>
<h3>Bookable (Online)</h3>
<h4>Deutsch</h4>
<ul>
<li><a href="https://www.modernescpp.de/index.php/c/2-c/30-embedded-programmierung-mit-modernem-c20210126195655">Embedded Programmierung mit modernem C++: </a>12.04.2021 - 14.04.2021</li>
</ul>
<h3>Standard Seminars&nbsp;</h3>
<p>Here is a compilation of my standard seminars. These seminars are only meant to give you a first orientation.</p>
<ul>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/22">C++ - The Core Language</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/23">C++ - The Standard Library</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/23">C++ - Compact</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/18">C++11 and C++14</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/19">Concurrency with Modern C++</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/21">Design Patterns and Architecture Patterns with C++</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/17">Embedded Programming with Modern C++</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/17">Generic Programming (Templates) with C++</a></li>
</ul>
<h4>New</h4>
<ul>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/16">Clean Code with Modern C++</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/25">C++20</a></li>
</ul>
<h3>Contact Me</h3>
<ul>
<li>Tel.: +49 7472 917441</li>
<li>Mobil: +49 152 31965939</li>
<li>Mail: <a href="http://modernescpp.com/%3Ca%20href="><span id="cloakde300195e998deadc4afa058a359ae94">This email address is being protected from spambots. You need JavaScript enabled to view it.</span></a></li>
<li>German Seminar Page: <a href="https://www.modernescpp.de/">www.ModernesCpp.de</a></li>
<li>English Seminar Page: <a href="http://www.modernescpp.net/">www.ModernesCpp.net</a></li>
</ul>
<h3>Modernes C++,</h3>
<p><img src="http://modernescpp.com/images/signatur/RainerGrimmSmall.png" alt="RainerGrimmSmall"></p></div>
			</div></div>]]>
            </description>
            <link>http://modernescpp.com/index.php/barriers-in-c-20</link>
            <guid isPermaLink="false">hacker-news-small-sites-25988369</guid>
            <pubDate>Mon, 01 Feb 2021 13:18:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Control Access to your on-prem services with Cloud IAP and inlets PRO]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25988235">thread link</a>) | @alexellisuk
<br/>
February 1, 2021 | https://johansiebens.dev/posts/2020/12/control-access-to-your-on-prem-services-with-cloud-iap-and-inlets-pro/ | <a href="https://web.archive.org/web/*/https://johansiebens.dev/posts/2020/12/control-access-to-your-on-prem-services-with-cloud-iap-and-inlets-pro/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        

<figure>
    <img src="https://johansiebens.dev/uploads/2020-12-29/banner.jpg" alt="photo by Scott Webb on Unsplash"> <figcaption>
            <p>photo by <a href="https://unsplash.com/@scottwebb?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" target="_blank">Scott Webb</a> on <a href="https://unsplash.com/" target="_blank">Unsplash</a></p>
        </figcaption>
</figure>


<h2 id="introduction">Introduction</h2>

<p><a href="https://cloud.google.com/iap" target="_blank"><strong>Google Cloud Identity-aware Proxy</strong></a>, or in short IAP, is an access control tool on the Google Cloud Platform for controlling access based on <em>who</em> is making an HTTP request to your application or <em>who</em> is making SSH connections to your virtual servers. As part of the <a href="https://cloud.google.com/beyondcorp/" target="_blank">BeyondCorp</a> security model, it enables context-aware access from virtually any location to your applications or VMs without the need for bastion hosts or a traditional VPN.</p>

<figure><a href="https://inlets.dev/">
    <img src="https://johansiebens.dev/uploads/2020-12-29/inlets-pro-purple.png" width="80"> </a>
</figure>


<p><a href="https://inlets.dev/" target="_blank"><strong>inlets PRO</strong></a> is a Software Defined Network (SDN) for connecting applications. It allows you to tunnel your private service to a remote network, or get a public IP and serve traffic to your users. As it is Cloud Native by design, it can run on containers or VMs. By running the server part of the tunnel, also known as an exit-node, on a Google Compute Engine instance, and connecting a client running in a private datacenter, your private services become available for your employees or customers from anywhere without the hassle of VPNs.</p>

<p>What if we could combine Google IAP and inlets? In other words, can we use Google Cloud Identity-Aware Proxy and inlets to create context-aware access control for our on-premises services?</p>

<p>I’m sure the combination will be useful in many use cases. Perhaps you would like to give SSH access to some internal servers from anywhere. Or you want to expose administrative services such as Grafana dashboards or PostgreSQL’s admin interface.</p>

<p>inlets PRO is the perfect fit to make such administrative services available with a public endpoint, but exposing them directly to the internet introduces risk. Forwarding TCP traffic with IAP allows you to reduce that risk, ensuring only authorized users gain access to these sensitive services.</p>

<h2 id="tcp-forwarding-with-iap">TCP forwarding with IAP.</h2>

<p>So what does the IAP TCP forwarding looks like?</p>

<p>From the documentation:</p>

<blockquote>
<p><em>You can use IAP TCP forwarding for other TCP-based protocols by using the <code>gcloud compute start-iap-tunnel</code> command to allocate a local port. The local port tunnels data traffic from the local machine to the remote machine in an HTTPS stream. IAP then receives the data, applies access controls, and forwards the unwrapped data to the remote port. Conversely, any data from the remote port is also wrapped before it’s sent to the local port where it’s then unwrapped.</em></p>
</blockquote>

<figure>
    <img src="https://johansiebens.dev/uploads/2020-12-29/gcp-iap-diagram.svg" alt="a PostgreSQL server protected by Google IAP"> <figcaption>
            <p>a PostgreSQL server protected by Google IAP</p>
        </figcaption>
</figure>


<p>As an example, let’s say we have a PostgreSQL server running on a GCE VM instance, named <em>my-postgres-vm</em>. With the following command, we bring the database service to our local machine:</p>
<div><pre><code data-lang="bash">gcloud compute start-iap-tunnel my-postgres-vm <span>5432</span> <span>\
</span><span></span>  --local-host-port<span>=</span>localhost:5432 <span>\
</span><span></span>  --zone<span>=</span>europe-west1-b</code></pre></div>
<p>All traffic sent to localhost:5432 is forwarded to the VM instance. The port is only accessible by applications running on your local computer.</p>

<p>There are some necessary steps to follow before the command above will be successful.</p>

<p>First, to allow IAP to connect to your VM instances, a proper firewall rule is required. With this firewall rule, you allow ingress traffic from the IP range containing all the IP addresses used by IAP for TCP forwarding to all ports you want to be accessible using IAP TCP forwarding.</p>

<p>E.g. to allow PostgreSQL access to all VM instances in your network, run:</p>
<div><pre><code data-lang="bash">gcloud compute firewall-rules create allow-postgresql-ingress-from-iap <span>\
</span><span></span>  --direction<span>=</span>INGRESS <span>\
</span><span></span>  --action<span>=</span>allow <span>\
</span><span></span>  --rules<span>=</span>tcp:5432 <span>\
</span><span></span>  --source-ranges<span>=</span><span>35</span>.235.240.0/20</code></pre></div>
<p>Next, to control which users and groups are allowed to use IAP TCP forwarding and which VM instances they’re allowed to connect to, configure IAM permissions. These permissions can be granted on project-level or instance-level.</p>

<p>E.g.</p>
<div><pre><code data-lang="bash">gcloud projects add-iam-policy-binding PROJECT_ID <span>\
</span><span></span>    --member<span>=</span>user:EMAIL <span>\
</span><span></span>    --role<span>=</span>roles/iap.tunnelResourceAccessor</code></pre></div>
<p>Only users with the correct IAM permissions can access your service from any location via the Cloud Identity-Aware Proxy with those two steps. All ingress traffic is blocked by the firewall, except if coming from IAP, making it a secure setup.</p>

<blockquote>
<p>One extra step would be enabling <a href="https://cloud.google.com/iap/docs/audit-log-howto" target="_blank">Cloud Audit logs for IAP</a>, which lets you view a request and see all the access levels a user has and hasn’t met.</p>
</blockquote>

<h2 id="tcp-tunnelling-with-inlets-pro">TCP tunnelling with inlets PRO.</h2>

<p>The Cloud Native Tunnel for L4 TCP traffic, inlets PRO, is independent of Google Cloud. In fact, you could use any cloud provider to create a public exit-node for your services. The interesting part is that it is using somehow the same techniques as the Cloud IAP.</p>

<p>An inlets PRO client establishes an outbound connection an inlets PRO server over HTTPS. All traffic is sent over an encrypted WebSocket using HTTPS which works well with HTTP proxies, VPNs, and VM networks.</p>

<figure>
    <img src="https://johansiebens.dev/uploads/2020-12-29/gcp-inlets-diagram.svg" alt="inlets PRO exit-node running on Google Cloud Platform"> <figcaption>
            <p>inlets PRO exit-node running on Google Cloud Platform</p>
        </figcaption>
</figure>


<p>The fastest way to create such an exit-node is using a handy utility <code>inletsctl</code>, which automates the task of creating the server node on cloud infrastructure. It has support for many cloud provider, and obviously, Google Cloud Platform is one of them.</p>

<p>After creating a Service Account key file (more info <a href="https://docs.inlets.dev/#/tools/inletsctl?id=example-usage-with-google-compute-engine" target="_blank">here</a>), you are only one command away from having an inlets PRO server:</p>
<div><pre><code data-lang="bash">inletsctl create <span>\
</span><span></span>  --pro <span>\
</span><span></span>  --provider gce <span>\
</span><span></span>  --project-id $PROJECT_ID <span>\ </span>
  --access-token-file ./key.json</code></pre></div>
<p>The output of the command above will display how to connect an inlets PRO client to punch out a service like PostgreSQL:</p>
<div><pre><code data-lang="bash">inlets PRO <span>(</span><span>0</span>.7.0<span>)</span> exit-server summary:
  IP: <span>104</span>.154.249.125
  Auth-token: rekwwOPQhe2792hqtJDJHjrpR3ZhqsAzsFOW6nTSmzBIGCUkpe1tWGgWA3KXJa32

Command:
  export LICENSE<span>=</span><span>""</span>
  export PORTS<span>=</span><span>"8000"</span>
  export UPSTREAM<span>=</span><span>"localhost"</span>

  inlets-pro client --url <span>"wss://104.154.249.125:8123/connect"</span> <span>\
</span><span></span>	--token <span>"rekwwOPQhe2792hqtJDJHjrpR3ZhqsAzsFOW6nTSmzBIGCUkpe1tWGgWA3KXJa32"</span> <span>\
</span><span></span>	--license <span>"</span>$LICENSE<span>"</span> <span>\
</span><span></span>	--upstream $UPSTREAM <span>\
</span><span></span>	--ports $PORTS</code></pre></div>
<p>Now, there are some attention points when creating an exit-node with <code>inletsctl</code>.</p>

<p>For starters, it requires a <code>default</code> network in the target project and, at the time of writing, there is no option to define another network of your choice.</p>

<p>Next, maybe more important, it will create a rather coarse-grained firewall rule, allowing traffic from any source to any port of the instance. I understand the reasoning behind it, because they don’t know which ports a customer wants to expose, but perhaps you would rather see some more fine-grained firewall rules applied. Of course you can always add some stricter rules yourself, only allowing traffic from your datacenter to the control port 8123 and allowing traffic from your customer datacenter to the data port.</p>

<p>Those two remarks are maybe easy to fix, and as it is open source, reporting this as an issue or even contributing to the project is perhaps something I will do later on.</p>

<h2 id="inlets-pro-tunnel-with-identity-aware-proxy">inlets PRO tunnel with Identity-Aware Proxy</h2>

<p>What do we have to do to enable context-aware access control to on-prem service by combining <strong>Identity-Aware Proxy</strong> and <strong>inlets PRO</strong>?</p>

<p>When we combine the two, you will have:</p>

<ul>
<li>a GCE VM instance with a public IP running an inlets PRO server<br></li>
<li>a firewall rule allowing ingress traffic coming from your datacenter to port <code>8123</code>, the control port of inlets PRO<br></li>
<li>a firewall rule allowing ingress traffic coming from the IP range used by IAP to the ports you would like to expose<br></li>
<li>an inlets PRO client running in your datacenter connected to the server via encrypted WebSockets and an authentication token<br></li>
<li>IAM permissions granted to the users allowed to create IAP tunnels</li>
</ul>

<figure>
    <img src="https://johansiebens.dev/uploads/2020-12-29/gcp-iap-inlets-diagram.svg" alt="inlets PRO exit-node protected by Google IAP"> <figcaption>
            <p>inlets PRO exit-node protected by Google IAP</p>
        </figcaption>
</figure>


<p>Now, when a user is allowed to create an IAP tunnel, they can forward TCP traffic to the VM on a certain port. Instead of a service or an application, the inlets PRO server is listening on that specific port, tunnelling all the traffic to the inlets PRO client in your datacenter, which in turn forwards the traffic to the targeted service or application.</p>

<p><em>In short, with the proper IAM roles, one could securely access the on-premises service from everywhere. And that is what <strong>context-aware access</strong> is all about!</em></p>

<h3 id="known-limitations">Known limitations</h3>

<p>While this set up looks very promising, some limitations are worth to mention.</p>

<p>First, IAP’s TCP forwarding feature isn’t intended for bulk transfer of data, and Google reserves the right to rate-limit users abusing this service.</p>

<p>Second, IAP automatically disconnects sessions after 1 hour of inactivity, and they recommend having logic in your applications to handle reestablishing a tunnel when it becomes disconnected.</p>

<p>For use cases such as granting access to your private database servers to execute some administrative tasks, those limitations shouldn’t be a problem.</p>

<h2 id="provisioning-with-terraform">Provisioning with Terraform</h2>

<p>To make it a little bit easier to get you started, I put together a small <a href="https://terraform.io/" target="_blank">Terraform</a> Module.</p>

<p>This Terraform module provisions all the resources mentioned above, from the VM instance running inlets PRO to the firewall rules and IAM permissions.</p>

<p>In the above diagrams, we took PostgreSQL as an example. With the following Terraform manifest, you could easily install the pictured architecture.</p>
<div><pre><code data-lang="hcl">provider "google" {
  project = var.project
  region  = var.region
}

resource "google_compute_network" "inlets" {
  name                    = "inlets"
  auto_create_subnetworks = false
}

resource "google_compute_subnetwork" "inlets" {
  name          = "inlets"
  ip_cidr_range = var.ip_cidr_range
  region        = var.region
  network       = google_compute_network.inlets.id
}

module "postgresql" {
  source     = "../"
  name       = "postgresql"
  zone       = var.zone
  network    = google_compute_network.inlets.name
  subnetwork = google_compute_subnetwork.inlets.name
  ports      = [3306]
  members = [
    "user:jane@example.com",
    "user:john@example.com",
  ]
}

output "postgresql" {
  value = module.postgresql.inlets_cmd
}</code></pre></div>
<p>Just like <code>inletsctl</code>, the outcome of the <code>terraform apply</code> run displays the command for connecting the client …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://johansiebens.dev/posts/2020/12/control-access-to-your-on-prem-services-with-cloud-iap-and-inlets-pro/">https://johansiebens.dev/posts/2020/12/control-access-to-your-on-prem-services-with-cloud-iap-and-inlets-pro/</a></em></p>]]>
            </description>
            <link>https://johansiebens.dev/posts/2020/12/control-access-to-your-on-prem-services-with-cloud-iap-and-inlets-pro/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25988235</guid>
            <pubDate>Mon, 01 Feb 2021 13:00:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Attacking OSS Using Abandoned Resources – EvilPacket]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25988204">thread link</a>) | @DyslexicAtheist
<br/>
February 1, 2021 | https://evilpacket.net/2021/attacking-oss-using-abandoned-resources/ | <a href="https://web.archive.org/web/*/https://evilpacket.net/2021/attacking-oss-using-abandoned-resources/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        

        
            
        

        
        
     
          
          
          

          
          
          

          <p>In December I discovered a supply chain vulnerability that impacted 6,530 public npm package versions, at least I thought I did. Turns out that earlier in October of 2020 Security Innovation published similar research dubbing the issue <a href="https://blog.securityinnovation.com/repo-jacking-exploiting-the-dependency-supply-chain">Repo Jacking</a>. This initially took the wind out of my sails but after I thought about it rediscovery is pretty cool and I was able to expand upon it a bit by focusing on abandoned S3 buckets, Google Cloud Storage bucket, expired domain names, and finding and reporting a vulnerability in GitHub to make exploitation possible in some conditions.</p>
<p>If you want to see if your organization is potentially at risk, here is a <a href="https://evilpacket.net/files/vulnerable_package_versions.csv">list of package versions</a> that were found to be vulnerable. If you are using these particular package versions I would recommend not.</p>
<p>While maintainers were notified by email a lot of those emails bounced. Please do not go screaming into the issues, email, or DMs of these package maintainers… and if you do reach out please be kind and respectful of their volunteer, unpaid, time. I encourage all security practitioners to get more involved in the open source communities they complain about (I too could do a better job here)… Anyway, on to the details!</p>
<h2 id="details">Details</h2>
<p>It’s typical for a Node.js based application to have many 3rd party dependencies. These npm packages can point to resources (the package) that are not hosted by the npm Registry. Typically these types of dependencies will be either a file or git repository that is available via HTTP/HTTPS or SSH.</p>
<p>If the dependency reference (domain, storage bucket, GitHub account) becomes abandoned and made available for an attacker to claim then an attacker can now control this resource as part of the npm install process creating an exploitable situation.</p>
<figure><img src="https://evilpacket.net/images/2021/01/dep1.png" data-sizes="auto" data-src="/images/2021/01/dep1.png" alt=""><figcaption></figcaption></figure>
<h3 id="attack-walk-through">Attack Walk Through</h3>
<p>Let’s look at an example of how this might be exploited using a GitHub repository.</p>
<figure><img src="https://evilpacket.net/images/2021/01/dep2.png" data-sizes="auto" data-src="/images/2021/01/dep2.png" alt=""><figcaption></figcaption></figure>
<p>The attacker registers the available GitHub username and creates a repository with the same name and the code they want to be their payload shaped like an npm package.</p>
<figure><img src="https://evilpacket.net/images/2021/01/dep3.png" data-sizes="auto" data-src="/images/2021/01/dep3.png" alt=""><figcaption></figcaption></figure>
<p>When the app owner runs npm install npm will run a git clone on the referenced repository. Let’s say the dependency reference looks like:  <code>github:evilpacket/beep-boop#beta</code> It will clone <code>evilpacket/beep-boop</code>. Once the clone is complete npm will try to git checkout whatever comes after the #, in this case the <code>beta</code> branch or in the case of the lock file it will checkout a particular commit hash.</p>
<h2 id="what-are-some-mitigating-circumstances">What are some mitigating circumstances</h2>
<p>There are some npm features that can change how exploitable this is from situation to situation.</p>
<p><strong>package-lock.json</strong></p>
<p>package-lock.json can save you in <em>some</em> situations, especially for anything that directly references a file vs a repository (repos are a special). This is because it has the integrity hashes that aren’t going to match when the attacker changes the payload.</p>
<p>Also a package-lock.json won’t help you on initial install or if package-lock.json isn’t being used. You should be checking that file into all your projects and using npm ci for builds.</p>
<p><strong>The local npm cache</strong></p>
<p>If the object that is requested is in the cache, you’re going to get that object and not a public or attacker controlled object.</p>
<p><strong>dev Dependencies</strong></p>
<p>Another aspect that shapes exploitability here is if the vulnerable dependency is a dev (development) dependency or not. Dev dependencies aren’t going to get installed with a typical npm install pkg but could still be useful in a targeted attack against a developer of one of those packages ( but who would want to do that 😈 )</p>
<p><strong>GitHub branch names &amp; policies</strong></p>
<p>GitHub (and others like gitlab) will block the creation of a branch name that is 40 hex characters (the same format as a commit hash) with an error like <code>remote: error: GH002: Sorry, branch or tag names consisting of 40 hex characters are not allowed.</code>, however I found a way around this security control so while I couldn’t forge a commit hash I could name a branch the same as the upstream commit hash and our payload would pass validation in the package-lock.json.</p>
<p>This issue was reported to GitHub security ❤️.</p>
<p>Additionally GitHub claims <code>“To prevent developers from pulling down potentially unsafe packages, we now retire the namespace of any open source project that had more than 100 clones in the week leading up to the owner’s account being renamed or deleted.”</code> That said I did not encounter any block when testing exploitation of this issue with older versions of the popular webpack-cli package, but it’s likely all these packages fall just below the popularity watermark set by this control.</p>
<h2 id="results-numbers-and-thats-it">Results, Numbers, and that’s it.</h2>
<p>While I’m never shocked to find vulnerable dependencies in the npm Registry I wasn’t expecting this many packages to be vulnerable.</p>
<p>You can find the package list here: <a href="https://evilpacket.net/files/vulnerable_package_versions.csv">https://evilpacket.net/files/vulnerable_package_versions.csv</a></p>
<p>Summary breakdown by resource type. As you can see the behavior of using GitHub repositories as dependencies and the forwarding behavior that GitHub allows creates a lot more vulnerability.</p>
<table>
<thead>
<tr>
<th>Resource</th>
<th>PKG Count</th>
</tr>
</thead>
<tbody>
<tr>
<td>Google Cloud Storage Buckets abandoned</td>
<td>2</td>
</tr>
<tr>
<td>AWS S3 Bucket abandoned</td>
<td>7</td>
</tr>
<tr>
<td>Domain Name expired</td>
<td>2</td>
</tr>
<tr>
<td>GitHub Repo (not found or redirect)</td>
<td>743</td>
</tr>
</tbody>
</table>
<p>I think the conclusion of this is that you need to scrutinize the open source you use and your supply chain a lot more than you think you do. Enjoy typing npm install.</p>

    </div></div>]]>
            </description>
            <link>https://evilpacket.net/2021/attacking-oss-using-abandoned-resources/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25988204</guid>
            <pubDate>Mon, 01 Feb 2021 12:55:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Secure your MQTT server with authentication and encryption]]>
            </title>
            <description>
<![CDATA[
Score 88 | Comments 29 (<a href="https://news.ycombinator.com/item?id=25988196">thread link</a>) | @juriansluiman
<br/>
February 1, 2021 | https://jurian.slui.mn/posts/smqttt-or-secure-mqtt-over-traefik/ | <a href="https://web.archive.org/web/*/https://jurian.slui.mn/posts/smqttt-or-secure-mqtt-over-traefik/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">


<article itemscope="" itemtype="http://schema.org/BlogPosting" id="content">
    <header>
        
          <time datetime="" pubdate="" itemprop="datePublished" content="2021-01-31T00:00:00Z" title="2021-01-31T00:00:00Z">January 2021</time>
    </header>

    <section>
      <p>The last days I have been experimenting in different ways how I can secure a
MQTT setup for my home automation. There’s an increasing use of IoT here at my
home and most of the applications communicate over MQTT. You simply cannot
control every device and how it gathers information. To prevent eavesdropping,
it’s time to secure MQTT.</p>
<p>This post is written with the <a href="https://www.troyhunt.com/iot-unravelled-part-3-security/">Troy Hunt IoT series</a>
in mind. Of course, you should patch your devices and put them in a
separate VLAN. However, if you have an MQTT security system and an MQTT light
bulb, did you consider the light bulb had access to the security system via MQTT?
Or did you consider IoT devices that are inside the same VLAN, but don’t use
MQTT themselves, could sniff all (security) messages communicated over your
message broker? It all boils down to the principles of <em>zero trust</em>.</p>
<p>For my home automation I am an avid <a href="https://www.home-assistant.io/">Home Assistant</a>
user. Since a long time I have a Home Assistant setup which controls a variety
of lights, switches and appliances. When I started introducing MQTT to my
setup, I used it without TLS and without authentication. Over time more
applications communicate over MQTT and I was worrying about two things:</p>
<ol>
<li>Untrusted devices could find and connect to the MQTT server without any effort;</li>
<li>Every message in every topic could be listened for anonymously.</li>
</ol>
<p>That’s why I set three goals to tighten things up:</p>
<ol>
<li>Every MQTT client must authenticate via unique usernames/passwords. Every
client gets separate credentials so there’s no reuse of passwords anywhere.</li>
<li>Enable TLS encryption for communication. The MQTT protocol (including
authentication) is plain text, meaning username and password could be sniffed if
no encryption is used.</li>
<li>Use Access Control to prevent devices reading/writing topics they should have
no interest in. If a trusted (authenticated) client sniffs into topics for other
applications, they must be blocked.</li>
</ol>

<p>The message broker I personally use is Mosquitto, as it’s lightweight and
extremely easy to use. Out of the box, it does allow anonymous connections and
no users are registered, so you need to take care of both.</p>
<p>In your <code>mosquitto.conf</code> file, make sure you have those two lines present and
make sure the mosquitto.passwd file exists (just update the path of the password
file based on your installation):</p>
<pre><code>allow_anonymous false
password_file &lt;path/to/mosquitto&gt;/mosquitto.passwd
</code></pre>
<p>Then supply Mosquitto with the credentials you want to add:</p>
<pre><code>mosquitto_passwd &lt;path/to/mosquitto&gt;/mosquitto.passwd &lt;username&gt;
</code></pre>
<p>Again, replace the path &amp; your preferred username and complete the prompt with
the password.</p>
<p>My installation resides inside docker, so in my case, the configuration files
are located at <code>/mosquitto/config/</code> and I add all my clients in bulk (via Ansible)
using the following command (<code>mqtt</code> is the name of my container)</p>
<pre><code>docker exec mqtt mosquitto_passwd -b /mosquitto/config/mosquitto.passwd &lt;user&gt; &lt;password&gt;
docker exec mqtt kill -SIGHUP 1
</code></pre>
<p>The <code>SIGHUP</code> signal is used in Mosquitto to
<a href="https://mosquitto.org/man/mosquitto-8.html#idm296">reload the configuration</a>
without restarting Mosquitto (which otherwise will probably loose some messages
along the way).</p>
<p><strong>Well done: You completed the first part of your goal securing MQTT!</strong></p>

<p>My favourite reverse proxy for production apps and home installation is <a href="https://traefik.io/">Traefik</a>.
It just integrates flawless with the tools I prefer: a dockerized setup and
automated certification renewal via Let’s Encrypt. And it’s so lightweight you
have little overhead for hosts like a Raspberry Pi.</p>
<p>All of my frontend web applications are routed via Traefik’s HTTP(S) proxy. The
fun thing is it also supports TCP and UDP traffic (which I also utilize in my
failover <a href="https://jurian.slui.mn/posts/openvpn-with-traefik-2.2/">TCP+UDP setup for OpenVPN</a>).</p>
<p>MQTT is plain TCP traffic and Traefik is able to create a TLS tunnel for TCP
traffic, so this is a fairly straightforward thing to configure. To understand
the label configuration below, make sure you read the
<a href="https://doc.traefik.io/traefik/routing/providers/docker/">Traefik documentation</a>.</p>
<pre><code>labels:
  - traefik.enable=true
  
  - traefik.tcp.routers.mqtt.rule=HostSNI(`mqtt.example.com`)
  - traefik.tcp.routers.mqtt.entrypoints=mqtt
  - traefik.tcp.routers.mqtt.tls=true
  - traefik.tcp.routers.mqtt.service=mqtt
  
  - traefik.tcp.services.mqtt.loadBalancer.server.port=1883
</code></pre>
<p>Traefik usually connects to a container’s port if there’s only one port exposed.
To be explicit I define a <code>mqtt</code> service in this case, loadbalancing the only port
in the mosquitto container. I make this explicit because the default
(unencrypted) MQTT port is 1883 and the default TLS encrypted port is 8883. If you
ever read back the configuration you should be able to trace things back.</p>
<p>Next, the docker container uses an entrypoint called <code>mqtt</code> defined in the
static configuration. Most Traefik setups use at least a <code>web</code> and <code>websecure</code>
entrypoint, I added <code>mqtt</code> at port <code>8333</code>. This creates a setup where the
docker container itself exposes an (unencrypted) port 1883 towards Traefik, this
container is inaccessible from the outside. Traefik creates an accessible
entrypoint, which will be encrypted, at port 8883. This technique is called
<em>SSL Termination</em>.</p>
<pre><code>[entryPoints]
  [entryPoints.web]
    address = ":80"
  [entryPoints.websecure]
    address = ":443"
  [entryPoints.mqtt]
    address = ":8883"
</code></pre>
<p>Finally, the rule label in the docker container gives a URL to use (like
<code>mqtt.example.com</code>) and with  <code>tls=true</code> you tell Traefik to <a href="https://doc.traefik.io/traefik/https/overview/">handle it as a
TLS connection</a>.</p>
<p><strong>This is great: You are more than halfway through securing MQTT!</strong></p>

<p>Access control in an MQTT server is the final step in securing your messaging
system for IoT. Access control defines access on a per-user basis, so above
steps for authentication and encryption are required to go further down the
security lane. Initiating access control is a principle of a whitelist, anything
<em>not</em> specified means there is <em>no access</em>. You only need to state which clients
have access to which topics, anything else is excluded.</p>
<p>Like the password file, the ACL file is referenced in the mosquitto.conf:</p>
<pre><code>acl_file &lt;path/to/mosquitto&gt;/acl
</code></pre>
<p>Next, you need to fill your ACL file. Jaimyn Mayer has an <a href="https://jaimyn.com.au/mqtt-use-acls-multiple-user-accounts/">excellent tutorial
for composing an ACL file</a>
with the usage of Home Assistant in mind so I won’t elaborate too much on this.</p>
<p>The basic format of the file consists of sections per user, where every topic
is listed to grant read and/or write access. Because of the nested structure of
MQTT topics, you can use wildcards to group topics at a higher level.</p>
<p>From Jaimyn’s example, using Home Assistant, Sonoff (WiFi powered) lights and
light sensors:</p>
<pre><code># Give Home Assitant full access to everything
user homeassist
topic readwrite #

# Allow the sonoffs to read/write to cmnd/# and stat/#
user sonoffswitch
topic readwrite cmnd/#
topic readwrite stat/#

# Allows the light sensor to read/write to the sensor topics
user lightsense
topic cmnd/sensor/#
topic stat/sensor/#
</code></pre>
<p>Tip: if you don’t know which topics are used by your devices, send Mosquitto
the <code>SIGUSR2</code> signal and it outputs a hierarchy of topics:</p>
<pre><code>kill -SIGUSER2 &lt;pid-of-mosquitto&gt;
</code></pre>
<p>In my docker setup this translates to (the output is send to stdout, so you need
to check the container logs):</p>
<pre><code>docker exec mqtt kill -SIGUSR2 1
docker logs mqtt
</code></pre>
<p>Again, when finished composing your ACL file, make sure to reload Mosquitto:</p>
<pre><code>// For normal installation
kill -SIGHUP &lt;pid-of-mosquitto&gt;

// For docker installation
docker exec mqtt kill -SIGHUP 1
</code></pre>
<p><strong>You are awesome! You completed your goal in securing your MQTT message broker!</strong></p>

<p>This ended up as a much longer post than anticipated. I was reluctant to get
going with this setup but it ended up pretty nice. The overhead (and delay in
message delivery) with TLS encryption in comparison with unencrypted MQTT is
unnoticable for me. In addition, it gives me a much safer feeling
compartimentising all the variety of IoT devices. I simply don’t trust all the
‘things’, especially the cheap stuff from far abroad. Now I know that stuff just
can’t sniff around the communication of other devices.</p>
<h2 id="client-tls-capabilities">Client TLS capabilities</h2>
<p>Just to make one thing clear if you go down this road, it may seem obvious but
encrypting MQTT traffic means every client must connect over TLS only. Switching
over to Traefik means you go over the configuration of every MQTT client (lights,
switches, cameras and so on) to enable a security flag in their respective
settings. Otherwise you end up only <em>pretending</em> being a security endboss.</p>
    </section>

    
</article>

  </div></div>]]>
            </description>
            <link>https://jurian.slui.mn/posts/smqttt-or-secure-mqtt-over-traefik/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25988196</guid>
            <pubDate>Mon, 01 Feb 2021 12:54:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Free Python course for 5 days with certificate, starts today]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25988140">thread link</a>) | @cobanov
<br/>
February 1, 2021 | https://globalaihub.com/event/introduction-to-python-programming-1-5-february/ | <a href="https://web.archive.org/web/*/https://globalaihub.com/event/introduction-to-python-programming-1-5-february/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="58158d8" data-element_type="widget" data-widget_type="jet-listing-dynamic-field.default">
<div>
<div><div><div><p>Welcome to our introduction to Python programming course!</p>
<p>In our Introduction to Python Programming course, we will be covering basic topics like syntax, data types, operators, control flows, functions and some libraries in Python. Also we prepared great materials using different worldwide resources to support your learning process!</p>
<p>During the class, we will create simple programs and a few homework will be given after the lessons to improve your coding skills.</p>
<p>Enroll our Python Introduction to Programming course and let’s start coding with the most popular language in today’s world!</p>
<p>You can ask all your questions via Python Hub in Global AI Hub Community.</p>
<p>You can check <a href="https://globalaihub.com/faq/">most frequently questions</a> about this course.</p>
</div></div></div> </div>
</div></div>]]>
            </description>
            <link>https://globalaihub.com/event/introduction-to-python-programming-1-5-february/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25988140</guid>
            <pubDate>Mon, 01 Feb 2021 12:47:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Top trends in Node.js to Watch in 2021]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25988117">thread link</a>) | @annnikiel
<br/>
February 1, 2021 | https://selleo.com/blog/top-trends-in-node-js-to-watch-in-2021 | <a href="https://web.archive.org/web/*/https://selleo.com/blog/top-trends-in-node-js-to-watch-in-2021">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The year 2021 has just started, and everyone is predicting trends in their respective fields. After the COVID-19 pandemic, the E-commerce industry has blossomed like never before. More and more businesses are shifting their business models to virtual markets. In this rapidly growing software development, choosing the right framework has become one of the most important and complicated tasks.</p><p>Developers all over the world are also assuming many predictions for trends in Node.js for 2021. In this article, we will explain the expected trend in Node.js for 2021.</p><p>Let’s start the article by learning more about Node.js and its popularity.</p><h2 id="what-is-nodejs">What is Node.js?</h2><p>Node.js is a JavaScript runtime built on Chrome’s V8 JS engine. It uses an event-driven, asynchronous, non-blocking input/output model (meaning how it interacts with the system’s disk and network, e.g., reading/writing data, making HTTP requests, etc.). It operates on a single thread event loop.</p><p>Node.js was created in 2009 by Ryan Dahl. He argued that software should be able to multi-task and said that the right way to handle several concurrent connections was to have a single-thread, an event loop, and non-blocking I/Os. This all made Node very efficient and eliminated the wait for requests.</p><p>More details about <a href="https://selleo.com/blog/why-choose-node-js">Node.js and why to choose it</a> is linked in the article.</p><h2 id="why-is-nodejs-so-popular">Why is Node.js so popular?</h2><p>The popularity of Node.js has grown significantly in recent years because of its extremely lightweight and high flexibility. Node.js comes with an extensive library of JavaScript</p><p>modules that simplify the development process. Due to its open-source nature, Node.js has become incredibly popular for both web and mobile application development.</p><p>Recent statistics show that:</p><ul><li>As of early 2020, more than 50% of the developers use Node.js in their projects.</li><li>In the USA, more than 28000 websites are built on Node.js technology.</li><li>Big names like eBay, AliExpress, and others are relying on Node.js.</li><li>Node.JS is used by websites that get heavy traffic, such as Netflix, PayPal, and Groupon.</li><li>Since 2009 when Node.js was introduced into the developer world, its popularity has wildly grown. In Github, Node.js has 75.9k stars, 19k forks, and 3k watchers. In Stack share, it has 71.8k followers and 8.3k votes. These numbers alone can show how popular Node.js is. Popular tech giants like Microsoft and Netflix use Node.js.</li><li>Node.js won the top spot in the StackOverflow’s 2020 developer survey. Over half of the respondents in the survey reported having used it in their projects.</li></ul><h2 id="top-nodejs-frameworks">Top Node.js Frameworks</h2><p>There are 6 top Node.js frameworks popular for their lightweight and simplified development process. Let’s get to know each one of them in small details.</p><h3 id="expressjs">Express.js</h3><p>Express.js is one of the top web application frameworks of Node.js. It is highly lightweight and flexible that comes with robust features for the website and mobile app development. The Express.js framework provides a layer of fundamental web application features without obscuring Node.js features. There are numerous popular frameworks based on Express.js.</p><p><img alt="Img" src="https://a.storyblok.com/f/86602/720x405/6f3f4cea60/node-trends2.jpg"></p><h3 id="meteorjs">Meteor.js</h3><p>Meteor.js is an open-source platform that is used by millions of developers to develop web and mobile apps. It is well-known among developers for making javascript applications simple, efficient, and scalable. It took over a decade of hard work by the industry giants to make it to its perfection. Meteor is a mature open-source framework that allows you to build and scale efficiently so you can serve millions of users.</p><h3 id="koajs">Koa.js</h3><p>Koa.js middleware stack flows in a stack-like manner, allowing a developer to perform actions downstream then filter and manipulate the response upstream. Koa is a new web framework designed by the team behind Express, aiming to be a smaller, more expressive, and more robust foundation for web applications and APIs. By leveraging async functions, Koa allows developers to ditch callbacks and greatly increase error-handling. Koa does not bundle any middleware within its core, and it provides an elegant suite of methods that make writing servers fast and enjoyable.</p><h3 id="sailsjs">Sails.js</h3><p>Sails.js  - one of the most famous MVC frameworks for Node.js. It is designed to match the familiar MVC pattern of frameworks like Ruby on Rails, but with support for modern apps' requirements. It provides features like data-driven APIs with a scalable and service-oriented architecture.</p><h3 id="hapijs">Hapi.js</h3><p>Hapi.js is an open-source framework for web and desktop applications. It is most commonly used to build web services such as JSON API, websites, and HTTP proxy applications. The mobile team created the framework at Walmart Labs. Mr. Eran Hammer, who created OAuth, was the brain behind this technology. He designed it to handle their traffic for Black Friday events, one of the busiest days for online shopping in the U.S. calendar. The original versions of Hapi used the Express framework.</p><h3 id="nestjs">NestJS</h3><p>NestJS is an open-source, extensible, versatile, progressive Node.js framework for creating compelling and demanding backend systems. It is currently the fastest-growing Node.js framework in TypeScript. NestJS is used for writing scalable, testable and loosely coupled applications. It brings scalable Node.js servers to a whole new level.</p><p>Check out more reasons why you should choose Nest.js as your desired Framework in this detailed <a href="https://selleo.com/blog/why-choose-nest-js-as-your-backend-framework">article.</a></p><p>Moving on to the main topic of the article and checking out the top trends in Node.js to watch in 2021.</p><h2 id="leading-trends-in-nodejs-to-watch-in-2021">Leading Trends in Node.js to Watch in 2021</h2><p>Here’re some of the most predicted trends in Node.js that will help businesses leverage their potential and get an edge over their competitors in 2021.</p><h3 id="trend--1-graphql-deployment-in-nodejs-apps">Trend # 1: GraphQL Deployment in Node.js apps</h3><p>GraphQL is a query language. By using GraphQL, a client can request for the data they need from the server, and the server will send a JSON response to the query. The interesting thing to note here is that the client can ask for exactly what they need, and they receive only what is required.</p><p><img alt="Img" src="https://a.storyblok.com/f/86602/720x348/67ad47822d/node-trends-1.jpg"></p><h4 id="the-popularity-of-graphql-in-2020">The Popularity of GraphQL in 2020</h4><ul><li>An emerging Node.js trend - GraphQL has grown immensely in popularity over the last two years. Due to its ability to streamline the workflow on multiple platforms, it has become the choice of millions of developers worldwide.</li><li>The GraphQL Foundation, a newly established organization hosted by the Linux Foundation, governs developments around GraphQL. GraphQL servers are available for multiple popular languages, e.g., Java, JavaScript, Ruby, Python, Perl, C#, Go, etc.</li><li>The popularity of GraphQL grew rapidly. E.g., The State of JavaScript 2018 report mentions that only 5% of developers surveyed had used it in 2016. However, 20.4% of developers used it in 2018.</li></ul><h4 id="graphql-is-the-best-alternative-for-rest-api-and-why-should-it-be-used">GraphQL is the best Alternative for REST API And Why should it be used?</h4><p>GraphQL offers several advantages over REST, which are as follows:</p><ul><li>Apps using REST APIs call endpoints. The entire data in that endpoint will be returned in the JSON format. This results in over-fetching as well as under-fetching, which can cause scalability and performance issues. GraphQL, with its queries, schemas, and resolvers, enables developers to design API calls that meet their specific data requirements. This way, GraphQL resolves the over-fetching and under-fetching challenges.</li><li>Due to designing the endpoints according to the view in the application using REST API, it can create a bottleneck when the application needs quick iterations on the frontend. Such iterations might require more data in the frontend, or they might require fewer data. GraphQL doesn’t create such a bottleneck due to its flexibility. The iterations for developing the frontend can continue without having to change the backend.</li><li>Applications built on REST API get all the data in the Endpoint. The application owner can’t gain insights into specific data elements since the entire data is returned every time. Whereas, in GraphQL, a developer can use the specific queries to retrieve specific data elements. This enables the application owner to gain insights into which data elements are in demand. Moreover, they will know which data elements aren’t being used by clients anymore.</li></ul><h3 id="trend--2-mean--mern-stack">Trend # 2: MEAN &amp; MERN Stack</h3><p>MEAN (MongoDB, Express, Angular, Node.JS) and MERN (MongoDB, Express, React, Node.JS) are the two stacks that constitute amazingly powerful technologies in the field of app development. These technologies are rapidly growing open-source web and app development frameworks that enable a developer to develop complex applications and frontend web apps.</p><p>These technologies are used by some of the biggest tech companies, like Netflix, which boost its popularity. Netflix's entire website relies on the MERN stack framework for the smooth web development experience.</p><h3 id="trend--3-real-time-apps">Trend # 3: Real-Time Apps</h3><p>In the year 2021, people demanded real-time apps for different online activities. These real-time apps are the most common cause of Node.js. With amazing user-engagement, real-time apps not only provide a set of incredible features but speed as well. These apps include features like live chats, social media integration, ad servers, gamification, stock exchange features, etc. Node.js fits all the requirements in this ecosystem.</p><p><img alt="Img" src="https://a.storyblok.com/f/86602/720x348/9c304b787f/real-time-assets.jpg"></p><p>Node.js apps can serve thousands of servers for data-intensive and real-time IoT device apps as well. However, there is one drawback of these real-time apps as they can overload a server. Node.js makes the collaboration environment update seamlessly due to Event API and Web Sockets. Trello is one of the biggest examples of a web-app where a real-time collaboration pattern is implemented.</p><p>The other kind of real-time apps which can be build using Node.js frameworks are:</p><ul><li>Video conference apps</li><li>Document sharing apps</li><li>Voice over Internet Protocol</li><li>Online gaming</li><li>E-commerce transactions like stockbroking</li><li>Instant messaging apps</li></ul><p>Because of the fast performance and open-source flexibility, Node.js has been a popular choice among the top-notch web and app developers worldwide.</p><h3 id="trend--4-serverless-architecture">Trend # 4: Serverless Architecture</h3><p>Node.js is most famous for its serverless architecture. It means that to create an …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://selleo.com/blog/top-trends-in-node-js-to-watch-in-2021">https://selleo.com/blog/top-trends-in-node-js-to-watch-in-2021</a></em></p>]]>
            </description>
            <link>https://selleo.com/blog/top-trends-in-node-js-to-watch-in-2021</link>
            <guid isPermaLink="false">hacker-news-small-sites-25988117</guid>
            <pubDate>Mon, 01 Feb 2021 12:42:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The house that Bitcoin built]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25988070">thread link</a>) | @donohoe
<br/>
February 1, 2021 | https://restofworld.org/2021/rise-and-fall-of-the-house-of-bitcoin/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2021/rise-and-fall-of-the-house-of-bitcoin/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

			<!-- Article Start -->
			
<p><span>A</span> small alleyway just a few blocks from the bustling Avenida Santa Fe, Pasaje Voltaire gives the impression that it’s keeping a secret. It carries the aura of the bygone era when bohemian<strong> </strong>artists and intellectuals dominated Palermo, long before it became one of the most fashionable barrios in Buenos Aires. A block over are bars where it’s rare to hear Spanish and common to overpay for drinks. This 100-meter long passageway, however, offers no such attractions. A tourist wouldn’t think twice about walking past it, nor would a local who lives in the area. With its cobblestones and squat houses, Pasaje Voltaire is a bastion of residential silence within the lively neighborhood. It’s completely inconspicuous, save for a two-story edifice dotted with clouded windows that offer no glimpses into what’s happening inside.</p>



<p>Until recently, the building was home to a rotating cast of recent engineering graduates. Here, in Jorge Luis Borges’s former neighborhood, they chased their own kind of dream, one they believed would change the world: cryptocurrency. When they weren’t founding companies, they hosted all-night hackathons, threw elaborate parties, and welcomed friends and allies for deep talks on the nature of the social contract and the inherent value of legal tender.</p>



<p>On the right-hand side<strong> </strong>of the<strong> </strong>façade is the only remaining trace of their presence. It’s a campy illustration of a samurai Darth Vader with an owl on his shoulder. The signature below it reads “Dilucious,” the nom de plume of an artist who used to live in the building. His real name is Agustín, and he’s one of the few people willing to speak to the media about his years in the building, which is known as Voltaire House.</p>



<p>In 2015, Agustín took a sabbatical from work with the aim of reinventing himself as an artist. He had studied engineering at the Buenos Aires Institute of Technology, or ITBA, and was making good money as a developer for an Argentine telecommunications company, but he felt trapped in corporate culture. As luck would have it, he heard about some ITBA alums who had transformed a building into a “crazy hacker haven” for cryptocurrency projects. The founders were on the same spiritual journey as Agustín. After a meeting and a short deliberation, the members of Voltaire House invited Agustín to be their artist-in-residence.</p>



<p>This was before “Bitcoin” became a familiar term and crypto bros began to be stereotyped as overnight millionaires. For the coder community of Argentina at that time, cryptocurrency meant something more serious — a way to create new forms of social interaction and to upend broken economic and political systems. Ever since a coder calling himself Satoshi introduced Bitcoin in a 2008 white paper, the prospect of a decentralized, peer-to-peer monetary system had become synonymous with a potential new world: one controlled not by banks or governmental institutions but by anyone with access to a computer.</p>



<p>This vision was particularly potent in Argentina. The hackers of Voltaire House had grown up amid the turbulence of the 1990s and 2000s — an era of the country’s history defined by corrupt political administration and economic collapse, precipitated by the central government. After the country defaulted on more than $100 billion of debt in 2001, the Argentine peso began a two-decade devaluation, going from 1:1 with the U.S. dollar to 85:1 today. Argentines grew accustomed to their paychecks being devalued the instant the money landed in their bank accounts. There was no access to a stable alternative, either, as U.S. dollars were either banned or severely restricted. Many resorted to buying black-market U.S. dollars, known as “blue dollars,” which often sold for more than twice the official exchange rate.</p>



<p>Cryptocurrency offered a means of circumventing the volatility of the local economy, and the members of Voltaire House were early adopters. They believed that Bitcoin would enable them to build a future that didn’t depend on decaying institutions. Two decades later, with the value of the peso plummeting and Bitcoin trading in Argentina soaring to historic highs, this kind of thinking has emerged again.<strong> </strong>Blockchain evangelists have long touted its revolutionary power to disrupt global economic models and supplant central authorities. While this seems unlikely in countries with stable monetary institutions like the United States, Argentina is in certain respects an ideal test case. Ultimately, however, Voltaire House offered a very different lesson about the cryptocurrency’s transformative power.<strong>&nbsp;</strong></p>



<p>The mainstays of Voltaire House — about 15 people, mostly men who knew one another from ITBA — believed transparency and decentralization could fix their broken country. In pursuit of this, over a roughly three-year period, they hosted daily lunches, fell into heated discussions about theoretical physics and social science, and once invited a hacker who had broken into the servers of the Buenos Aires subway system to come meet with them. All conversations inevitably came back to basic questions of economics and society: What is money? And who should control it? They didn’t just talk: They built what would become some of Argentina’s most successful blockchain companies, including Decentraland, Muun, and OpenZeppelin,<strong> </strong>which facilitated the exchange of tens of millions of real-world dollars.</p>



<p>“The house itself was a project,” said Sacha Lifszyc, a visitor during those years. For the few young programmers in Buenos Aires lucky enough to be extended an invitation, going to Voltaire House was like entering a refuge where everything contained the potential for innovation. From the outset, its members were famously secretive: There’s scarcely any digital footprint of the talks and parties they hosted, and Voltaire’s events and public discussions were promoted <em>boca en boca</em>. Aside from a <a href="https://medium.com/decentraland/an-inside-look-into-how-crypto-projects-are-made-bffae4b20eae">Medium article in 2017</a>, Voltaire House avoided media coverage. All of its key members dodged interview requests for this story, making it clear through intermediaries that they weren’t interested, and strongly discouraged others from speaking. “This ethos of being anonymous really resonates with them,” said Agustín Ferreira, a coder who was friends with many in the house. “Like being Satoshi, you know?”</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/GettyImages-483584244-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/GettyImages-483584244-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/GettyImages-483584244-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/02/GettyImages-483584244-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2021/02/GettyImages-483584244-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/02/GettyImages-483584244-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/02/GettyImages-483584244-2800x1867.jpg 2800w, " sizes="(max-width: 640px) 100vw, 600px(max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="Voltaire House was located in Buenos Aires's Palermo neighborhood, known for its bustling nightlife and touristy offerings.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder">Victor J. Blue/Bloomberg/Getty Images</span>
			</figcaption>
		</figure>


<hr>



<p>Manuel Aráoz founded Voltaire House in 2014 after graduating from ITBA with a degree in computer science and joining a U.S.-based crypto wallet, BitPay, as one of its first employees. Thanks to the success of the e-commerce giant MercadoLibre, Argentina had acquired a reputation as a hotbed for highly trained software developers. Domestic and foreign tech companies employed <a href="https://www.progressivepolicy.org/wp-content/uploads/2016/05/2016.05-DiIonno_Mandel_Argentina_The-Road-to-the-App-Economy.pdf">tens of thousands</a> of coders in the country, <a href="https://www.quora.com/What-is-the-annual-salary-in-USD-of-a-senior-software-web-application-developer-in-Argentina-or-Buenos-Aires">often paying them</a> four or five times the national minimum wage. (Agustín described coding as the second-most lucrative job in the country after football.) Yet while computer engineering was an acceptable career, cryptocurrency was still new, as were most of the companies working with it. When Aráoz joined BitPay, it<strong> </strong>had about $2.5 million in funding. Today, it has raised a total of $72.5 million.</p>



<p>To build out BitPay’s development team in Argentina, Aráoz leased the building that would become Voltaire. The house soon became a creative laboratory for him and his friends. It hosted the regular crew of about 15 coders, with others streaming in and out. House members would congregate around a big table framed by a giant statue of the letter “V” or gather in the little back garden for cookouts. During these years, members were constantly tinkering. A visitor recalled how they had outfitted a small room with VR sensors and once tried to install a system that would play customized music for each person who entered the house.</p>



<p>This early experimentation would lead to Voltaire House’s highest-profile creation: Decentraland, a VR metaverse powered by the Ethereum blockchain with its own crypto token.<strong> </strong>To put it in layman’s terms, Decentraland was a virtual world with a limited number of properties that people could buy through a proprietary currency and sell for real money. It was a petri dish for the ideals of democracy and decentralization they championed, built on the premise that a virtual world controlled by its own “citizens” could more effectively govern itself — and offer more stable investment opportunities — than a real one governed by elites. Decentraland’s founders stipulated that it would be overseen by a “Decentralized Autonomous Organization,” a group of Decentraland residents who would vote on management decisions.&nbsp;</p>



<p>These were the heady days of cryptocurrency, when the possibilities for expansion seemed infinite. Between February and December of 2017 alone, the value of a single Bitcoin jumped from under $1,000 to almost $20,000, and the members of Voltaire House did not want to miss out on the opportunity. In August of that year, Decentraland hosted what is known as an initial coin offering, in which they started publicly selling their token. They <a href="https://bravenewcoin.com/insights/decentraland-raises-24-million-in-35-seconds-leaving-retail-investors-out-in-the-cold">raised</a> $24 million in 35 seconds, before shutting down the ICO. It’s unclear whether the creators ever cashed out, but some users did: One later told <a href="https://www.marketwatch.com/story/people-are-making-more-than-500-buying-property-that-doesnt-actually-exist-2018-09-04">MarketWatch</a> that he spent $60,000 on plots in Decentraland’s first city, which was&nbsp;eventually worth $350,000.</p>



<p>Decentraland is one of about a half-dozen products to achieve international recognition whose origins can be traced to Voltaire, despite the house’s low profile.<strong> </strong>Another of Aráoz’s contributions to the world of crypto was a service called <a href="https://www.coindesk.com/how-block-chain-technology-is-working-to-transform-intellectual-property">Proof of Existence</a>, a decentralized online notary, which made a splash as the first nonfinancial application of blockchain. In 2014, leading crypto-news outlet <em>Coindesk</em> projected that Proof of Existence could “revolutionize intellectual property rights,” and Voltaire House member Esteban Ordano went on <a href="https://blog.po.et/introducing-po-et-digital-media-blockchain-technology-collide-e53728fc1c24">to adapt</a> the technology underlying it for his own company, <a href="https://www.po.et/?utm_source=icodrops">Po.et</a>, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://restofworld.org/2021/rise-and-fall-of-the-house-of-bitcoin/">https://restofworld.org/2021/rise-and-fall-of-the-house-of-bitcoin/</a></em></p>]]>
            </description>
            <link>https://restofworld.org/2021/rise-and-fall-of-the-house-of-bitcoin/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25988070</guid>
            <pubDate>Mon, 01 Feb 2021 12:33:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Regulation as a Service]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25987943">thread link</a>) | @csomar
<br/>
February 1, 2021 | https://omarabid.com/regulation-as-a-service | <a href="https://web.archive.org/web/*/https://omarabid.com/regulation-as-a-service">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="container">
  <article id="5GcF7g1wkjJLTc5cfjqR5t">
	<time datetime="2021-02-01">February  1, 2021</time>
  
	<p><a href="https://bitstamp.net/">Bitstamp</a> recently upped it’s KYC game: The exchange now requires a tons of documentation to allow you trading any amount there. To open an account and start trading you need to provide: Your passport, Proof of residence (some utility bill), You trading history (at other exchanges), Sources of funding (documents such as tax slips), and also you need to fill a questionnaire about your trading activity.</p>

<p>If you thought this is bad, here is one more: It costs 0.5% to trade on Bitstamp; whether you are a maker or a taker. The industry standard seems to be around 0.2-0.1%. Bitstamp is 5 times more expensive and 10 times more burdensome to trade with. Which really begs the question: Is there any reason for Bitstamp to exist?</p>

<p>The answer might be a surprising: Yes</p>

<p>See, centralized exchanges are a dead business. The only reason they exist today is that de-centralized exchanges are still impractical, complicated and very expensive. But this is bound to change: Instantaneous <a href="https://en.bitcoin.it/wiki/Atomic_swap">atomic swaps</a> are mostly theoretical for now, but they will become practical in the future. And much cheaper too.</p>

<p>To trade in a centralized exchange, first, you need to send your crypto to the said exchange and entrust its solvency. Then, you can access the pool of liquidity of that exchange, and rely on arbitrage traders to transfer liquidity from other exchanges. Once the trade is completed, you withdraw your converted crypto.</p>

<p>Things are different in a decentralized landscape: You only send your crypto to execute the trade. This means all the pools of liquidity are possible, and if there exists a good interface to trade with, you should be able to get the best price of all these available pools. Once the trade is settled, you don’t need to withdraw your crypto: There is no counter-party risk.</p>

<p>This completely flips the story: Most exchanges will have to shutdown eventually. There is no business in being a middle-men for traders, or an arbitrage trader. But Bitstamp will probably survive: It’s not exchange after all, it has turned into a regulatory service between crypto, the legacy banking system and the government.</p>

<p>Some players have already got the hint: <a href="https://erikvoorhees.medium.com/no-more-kyc-with-shapeshift-6d95a3e63ddf">Shapeshift has already moved</a> to a decentralized trading system with no KYC. With more pressure from regulators and improved efficiency from DEX exchanges, most of today exchanges will have no business model.</p>

  <figure id="kudo_5GcF7g1wkjJLTc5cfjqR5t">
    <a href="#kudo">
      
    </a>
    <p>3</p>
    <p>Kudos</p>
  </figure>
  <figure id="kudo_side_5GcF7g1wkjJLTc5cfjqR5t">
    <a href="#kudo">
      
    </a>
    <p>3</p>
    <p>Kudos</p>
  </figure>
</article>

</section></div>]]>
            </description>
            <link>https://omarabid.com/regulation-as-a-service</link>
            <guid isPermaLink="false">hacker-news-small-sites-25987943</guid>
            <pubDate>Mon, 01 Feb 2021 12:07:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building cross-platform CLIs on .NET Core]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25987714">thread link</a>) | @waldekm
<br/>
February 1, 2021 | https://blog.mastykarz.nl/building-cross-platform-cli-dotnet-core/ | <a href="https://web.archive.org/web/*/https://blog.mastykarz.nl/building-cross-platform-cli-dotnet-core/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p>Building CLIs on .NET has just changed thanks to a new experimental project that Microsoft is working on.</p> <h2>The revival of CLIs</h2> <p>Since the first release of Windows, graphical applications became the standard. Arcane command-line tools were pushed away to Linux, while the rest of the world enjoyed pointing and clicking. But recently things changed.</p> <p>Graphical interfaces are great for abstracting away the complexities of the underlying software, but they share one big problem. They're hard to make. It's hard to make the UI user-friendly and any adjustment is costly and time-consuming.</p> <p>More than ever, time to market matters. And so organizations, even Microsoft, choose to build command-line tools first, learn from their users, improve, and eventually release UI for the most common use-cases. And it turns out, that the professional audience doesn't mind. They're okay with using command-line tools if it means that they can get them quicker.</p> <h2>CLIs in .NET</h2> <p>Building console applications in .NET was never hard. All you had to do, was to spin up Visual Studio, create a new project and you were good to go. But you had a long way to go to build a true CLI in a console app.</p> <p>You see, a CLI is more than just a console app. It often has multiple commands, each with its own arguments and options, some required, some optional. It validates user input and provides them with meaningful error messages. It exposes rich help with examples that illustrate how the CLI works and what's possible.</p> <p>Yes, you could do all that in a .NET console application, but you had to do all of it yourself. Before you could start implementing the functionality for your CLI, you had to build the plumbing. Parsing user input, validating it, rendering help. In the end, whatever you've built, would work but only on Windows. But this is no longer the case, thanks to DragonFruit.</p> <h2>Easily build cross-platform CLIs on .NET with DragonFruit</h2> <p>DragonFruit is a part of a new experimental set of features meant to <a href="https://github.com/dotnet/command-line-api" target="_blank" rel="noopener">simplify building cross-platform CLIs on .NET</a>. It automatically takes care of the plumbing, allowing you to build a proper CLI in minutes. Literally. Take a look.</p> <h3>The basics</h3> <p>To illustrate the point, let's build a simple CLI with two commands: one that shows a greeting for the specified name and the other that adds two values.</p> <p>Let's start with creating a new console app project:</p>  <p>Next, add reference to the experimental command line packages:</p> <div><div><pre><code data-lang="sh">dotnet add package System.CommandLine.Experimental <span>-v</span> 0.3.0-<span>*</span>
dotnet add package System.CommandLine.DragonFruit <span>-v</span> 0.3.0-<span>*</span>
</code></pre></div></div> <p>In your code editor, open your newly created project and change its code to the following:</p> <div><div><pre><code data-lang="c#"><span>using</span> <span>System</span><span>;</span>
<span>using</span> <span>System.CommandLine</span><span>;</span>
<span>using</span> <span>System.CommandLine.Invocation</span><span>;</span>

<span>namespace</span> <span>netcore_cli</span>
<span>{</span>
  <span>class</span> <span>Program</span>
  <span>{</span>
    <span>static</span> <span>int</span> <span>Main</span><span>(</span><span>string</span><span>[]</span> <span>args</span><span>)</span>
    <span>{</span>
      <span>var</span> <span>cmd</span> <span>=</span> <span>new</span> <span>RootCommand</span><span>();</span>
      <span>cmd</span><span>.</span><span>AddCommand</span><span>(</span><span>greeting</span><span>());</span>
      <span>return</span> <span>cmd</span><span>.</span><span>InvokeAsync</span><span>(</span><span>args</span><span>).</span><span>Result</span><span>;</span>
    <span>}</span>

    <span>private</span> <span>static</span> <span>Command</span> <span>greeting</span><span>()</span> <span>{</span>
      <span>var</span> <span>cmd</span> <span>=</span> <span>new</span> <span>Command</span><span>(</span><span>"greeting"</span><span>,</span> <span>"Shows a greeting"</span><span>);</span>
      <span>cmd</span><span>.</span><span>Handler</span> <span>=</span> <span>CommandHandler</span><span>.</span><span>Create</span><span>(()</span> <span>=&gt;</span> <span>{</span>
        <span>Console</span><span>.</span><span>WriteLine</span><span>(</span><span>"Hello world"</span><span>);</span>
      <span>});</span>
      <span>return</span> <span>cmd</span><span>;</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div> <blockquote> <p>We use <code>--</code> to specify that everything that follows should be passed into our CLI and not to the <code>dotnet</code> CLI.</p> </blockquote> <p>If you test it, you should see the following result:</p> <div><div><pre><code data-lang="sh"><span>$ </span>dotnet run <span>--</span> greeting
Hello world
</code></pre></div></div> <p>To see the added value of DragonFruit and the experimental command-line features, execute:</p>  <p>Your CLI will show an error saying that you haven't specified any command along with help listing all available options and commands. All that, while you haven't programmed a line of code for it!</p> <h3>Accepting user input</h3> <p>In the previous step, we've just scratched the surface. Let's extend our CLI, with the ability to accept user input.</p> <p>Change the code in your application to the following:</p> <div><div><pre><code data-lang="c#"><span>using</span> <span>System</span><span>;</span>
<span>using</span> <span>System.CommandLine</span><span>;</span>
<span>using</span> <span>System.CommandLine.Invocation</span><span>;</span>

<span>namespace</span> <span>netcore_cli</span>
<span>{</span>
  <span>class</span> <span>Program</span>
  <span>{</span>
    <span>static</span> <span>int</span> <span>Main</span><span>(</span><span>string</span><span>[]</span> <span>args</span><span>)</span>
    <span>{</span>
      <span>var</span> <span>cmd</span> <span>=</span> <span>new</span> <span>RootCommand</span><span>();</span>
      <span>cmd</span><span>.</span><span>AddCommand</span><span>(</span><span>greeting</span><span>());</span>
      <span>return</span> <span>cmd</span><span>.</span><span>InvokeAsync</span><span>(</span><span>args</span><span>).</span><span>Result</span><span>;</span>
    <span>}</span>

    <span>private</span> <span>static</span> <span>Command</span> <span>greeting</span><span>()</span> <span>{</span>
      <span>var</span> <span>cmd</span> <span>=</span> <span>new</span> <span>Command</span><span>(</span><span>"greeting"</span><span>,</span> <span>"Greets the specified person"</span><span>);</span>
      <span>cmd</span><span>.</span><span>AddOption</span><span>(</span><span>new</span> <span>Option</span><span>(</span><span>new</span><span>[]</span> <span>{</span> <span>"--name"</span><span>,</span> <span>"-n"</span> <span>},</span> <span>"Name of the person to greet"</span><span>)</span> <span>{</span>
        <span>Argument</span> <span>=</span> <span>new</span> <span>Argument</span><span>&lt;</span><span>string</span><span>&gt;</span> <span>{</span>
          <span>Arity</span> <span>=</span> <span>ArgumentArity</span><span>.</span><span>ExactlyOne</span>
        <span>}</span>
      <span>});</span>
      <span>cmd</span><span>.</span><span>Handler</span> <span>=</span> <span>CommandHandler</span><span>.</span><span>Create</span><span>&lt;</span><span>string</span><span>&gt;((</span><span>name</span><span>)</span> <span>=&gt;</span> <span>{</span>
        <span>Console</span><span>.</span><span>WriteLine</span><span>(</span><span>$"Hello </span><span>{</span><span>name</span><span>}</span><span>"</span><span>);</span>
      <span>});</span>
      <span>return</span> <span>cmd</span><span>;</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div> <p>Test it out, by executing:</p> <div><div><pre><code data-lang="sh"><span>$ </span>dotnet run <span>--</span> greeting <span>--name</span> Joe
Hello Joe
</code></pre></div></div> <p>We've extended our command with an option that allows us to specify a name and can be used either in long format <code>--name</code> or short <code>-n</code> (line 18). Additionally, we said, that our option takes a value of type string (line 19), eg. <code>--name Steve</code> and that it should have exactly one value (line 20). Notice, how DragonFruit automatically maps user input to the arguments of your command handler (line 23)!</p> <h3>Switches</h3> <p>Let's extend the CLI further with an additional switch:</p> <div><div><pre><code data-lang="c#"><span>using</span> <span>System</span><span>;</span>
<span>using</span> <span>System.CommandLine</span><span>;</span>
<span>using</span> <span>System.CommandLine.Invocation</span><span>;</span>

<span>namespace</span> <span>netcore_cli</span>
<span>{</span>
  <span>class</span> <span>Program</span>
  <span>{</span>
    <span>static</span> <span>int</span> <span>Main</span><span>(</span><span>string</span><span>[]</span> <span>args</span><span>)</span>
    <span>{</span>
      <span>var</span> <span>cmd</span> <span>=</span> <span>new</span> <span>RootCommand</span><span>();</span>
      <span>cmd</span><span>.</span><span>AddCommand</span><span>(</span><span>greeting</span><span>());</span>
      <span>return</span> <span>cmd</span><span>.</span><span>InvokeAsync</span><span>(</span><span>args</span><span>).</span><span>Result</span><span>;</span>
    <span>}</span>

    <span>private</span> <span>static</span> <span>Command</span> <span>greeting</span><span>()</span> <span>{</span>
      <span>var</span> <span>cmd</span> <span>=</span> <span>new</span> <span>Command</span><span>(</span><span>"greeting"</span><span>,</span> <span>"Greets the specified person"</span><span>);</span>
      <span>cmd</span><span>.</span><span>AddOption</span><span>(</span><span>new</span> <span>Option</span><span>(</span><span>new</span><span>[]</span> <span>{</span> <span>"--name"</span><span>,</span> <span>"-n"</span> <span>},</span> <span>"Name of the person to greet"</span><span>)</span> <span>{</span>
        <span>Argument</span> <span>=</span> <span>new</span> <span>Argument</span><span>&lt;</span><span>string</span><span>&gt;</span> <span>{</span>
          <span>Arity</span> <span>=</span> <span>ArgumentArity</span><span>.</span><span>ExactlyOne</span>
        <span>}</span>
      <span>});</span>
      <span>cmd</span><span>.</span><span>AddOption</span><span>(</span><span>new</span> <span>Option</span><span>(</span><span>"--polite"</span><span>,</span> <span>"Show a polite greeting"</span><span>));</span>
      <span>cmd</span><span>.</span><span>Handler</span> <span>=</span> <span>CommandHandler</span><span>.</span><span>Create</span><span>&lt;</span><span>string</span><span>,</span> <span>bool</span><span>&gt;((</span><span>name</span><span>,</span> <span>polite</span><span>)</span> <span>=&gt;</span> <span>{</span>
        <span>Console</span><span>.</span><span>WriteLine</span><span>(</span><span>$"</span><span>{(</span><span>polite</span> <span>?</span> <span>"Good day"</span> <span>:</span> <span>"Hello"</span><span>)}</span><span> </span><span>{</span><span>name</span><span>}</span><span>"</span><span>);</span>
      <span>});</span>
      <span>return</span> <span>cmd</span><span>;</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div> <p>And let's test it:</p> <div><div><pre><code data-lang="sh"><span>$ </span>dotnet run <span>--</span> greeting <span>-n</span> Joe <span>--polite</span>
Good day Joe
</code></pre></div></div> <h3>Required options</h3> <p>Let's see what happens, when we run the CLI without specifying the person's name:</p> <div><div><pre><code data-lang="sh"><span>$ </span>dotnet run <span>--</span> greeting
Hello
</code></pre></div></div> <p>Unsurprisingly, we're missing the name. But haven't we specified that it should contain exactly one value with <code>ArgumentArity.ExactlyOne</code>? Yes and no. What it says exactly, is that the option, when specified, should have exactly one value. But it doesn't need to be specified. At the moment of writing this article, there is no built-in support for required options, but you can solve it easily, like this:</p> <div><div><pre><code data-lang="c#"><span>using</span> <span>System</span><span>;</span>
<span>using</span> <span>System.CommandLine</span><span>;</span>
<span>using</span> <span>System.CommandLine.Invocation</span><span>;</span>

<span>namespace</span> <span>netcore_cli</span>
<span>{</span>
  <span>class</span> <span>Program</span>
  <span>{</span>
    <span>static</span> <span>int</span> <span>Main</span><span>(</span><span>string</span><span>[]</span> <span>args</span><span>)</span>
    <span>{</span>
      <span>var</span> <span>cmd</span> <span>=</span> <span>new</span> <span>RootCommand</span><span>();</span>
      <span>cmd</span><span>.</span><span>AddCommand</span><span>(</span><span>greeting</span><span>());</span>
      <span>return</span> <span>cmd</span><span>.</span><span>InvokeAsync</span><span>(</span><span>args</span><span>).</span><span>Result</span><span>;</span>
    <span>}</span>

    <span>private</span> <span>static</span> <span>Command</span> <span>greeting</span><span>()</span> <span>{</span>
      <span>var</span> <span>cmd</span> <span>=</span> <span>new</span> <span>Command</span><span>(</span><span>"greeting"</span><span>,</span> <span>"Greets the specified person"</span><span>);</span>
      <span>cmd</span><span>.</span><span>AddOption</span><span>(</span><span>new</span> <span>Option</span><span>(</span><span>new</span><span>[]</span> <span>{</span> <span>"--name"</span><span>,</span> <span>"-n"</span> <span>},</span> <span>"Name of the person to greet"</span><span>)</span> <span>{</span>
        <span>Argument</span> <span>=</span> <span>new</span> <span>Argument</span><span>&lt;</span><span>string</span><span>&gt;</span> <span>{</span>
          <span>Arity</span> <span>=</span> <span>ArgumentArity</span><span>.</span><span>ExactlyOne</span>
        <span>}</span>
      <span>});</span>
      <span>cmd</span><span>.</span><span>AddOption</span><span>(</span><span>new</span> <span>Option</span><span>(</span><span>"--polite"</span><span>,</span> <span>"Show a polite greeting"</span><span>));</span>
      <span>cmd</span><span>.</span><span>Handler</span> <span>=</span> <span>CommandHandler</span><span>.</span><span>Create</span><span>&lt;</span><span>string</span><span>,</span> <span>bool</span><span>&gt;((</span><span>name</span><span>,</span> <span>polite</span><span>)</span> <span>=&gt;</span> <span>{</span>
        <span>if</span> <span>(</span><span>String</span><span>.</span><span>IsNullOrEmpty</span><span>(</span><span>name</span><span>))</span> <span>{</span>
          <span>Console</span><span>.</span><span>WriteLine</span><span>(</span><span>"Required option name missing"</span><span>);</span>
          <span>return</span> <span>1</span><span>;</span>
        <span>}</span>

        <span>Console</span><span>.</span><span>WriteLine</span><span>(</span><span>$"</span><span>{(</span><span>polite</span> <span>?</span> <span>"Good day"</span> <span>:</span> <span>"Hello"</span><span>)}</span><span> </span><span>{</span><span>name</span><span>}</span><span>"</span><span>);</span>
        <span>return</span> <span>0</span><span>;</span>
      <span>});</span>
      <span>return</span> <span>cmd</span><span>;</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div> <p>We check if the option has a value in the command's handler and show a meaningful error if it doesn't. To properly support using the CLI in scripts, we indicate a failure with a non-zero return value.</p> <h3>Rich formatting</h3> <p>Before we finish, let's take a look at how the experimental features that Microsoft is working help you focus on building the functionality instead of plumbing.</p> <p>Often, CLIs are used to list multiple values, like a list of running processes, active users, etc. For each returned object, you might want to print several properties like ID, display name, etc. Here is how you can do this with the experimental command-line features.</p> <p>Start, by adding a reference to the Rendering package:</p> <div><div><pre><code data-lang="sh">dotnet add package System.CommandLine.Rendering <span>-v</span> 0.3.0-<span>*</span>
</code></pre></div></div> <p>Then, let's change the CLIs code to the following:</p> <div><div><pre><code data-lang="c#"><span>using</span> <span>System</span><span>;</span>
<span>using</span> <span>System.CommandLine</span><span>;</span>
<span>using</span> <span>System.CommandLine.Invocation</span><span>;</span>
<span>using</span> <span>System.CommandLine.Rendering</span><span>;</span>
<span>using</span> <span>System.CommandLine.Rendering.Views</span><span>;</span>

<span>namespace</span> <span>netcore_cli</span> <span>{</span>
  <span>class</span> <span>Program</span> <span>{</span>
    <span>private</span> <span>static</span> <span>InvocationContext</span> <span>invocationContext</span><span>;</span>
    <span>private</span> <span>static</span> <span>ConsoleRenderer</span> <span>consoleRenderer</span><span>;</span>

    <span>static</span> <span>int</span> <span>Main</span><span>(</span><span>InvocationContext</span> <span>invocationContext</span><span>,</span> <span>string</span><span>[]</span> <span>args</span><span>)</span> <span>{</span>
      <span>Program</span><span>.</span><span>invocationContext</span> <span>=</span> <span>invocationContext</span><span>;</span>
      <span>consoleRenderer</span> <span>=</span> <span>new</span> <span>ConsoleRenderer</span><span>(</span>
        <span>invocationContext</span><span>.</span><span>Console</span><span>,</span>
        <span>mode</span><span>:</span> <span>invocationContext</span><span>.</span><span>BindingContext</span><span>.</span><span>OutputMode</span><span>(),</span>
        <span>resetAfterRender</span><span>:</span> <span>true</span><span>);</span>

      <span>var</span> <span>cmd</span> <span>=</span> <span>new</span> <span>RootCommand</span><span>();</span>
      <span>cmd</span><span>.</span><span>AddCommand</span><span>(</span><span>list</span><span>());</span>
      <span>return</span> <span>cmd</span><span>.</span><span>InvokeAsync</span><span>(</span><span>args</span><span>).</span><span>Result</span><span>;</span>
    <span>}</span>

    <span>private</span> <span>static</span> <span>Command</span> <span>list</span><span>()</span> <span>{</span>
      <span>var</span> <span>cmd</span> <span>=</span> <span>new</span> <span>Command</span><span>(</span><span>"list"</span><span>);</span>
      <span>cmd</span><span>.</span><span>Handler</span> <span>=</span> <span>CommandHandler</span><span>.</span><span>Create</span><span>(()</span> <span>=&gt;</span> <span>{</span>
        <span>var</span> <span>users</span> <span>=</span> <span>new</span> <span>User</span><span>[]</span> <span>{</span>
          <span>new</span> <span>User</span> <span>{</span>
            <span>ID</span> <span>=</span> <span>"1"</span><span>,</span>
            <span>Name</span> <span>=</span> <span>"Joe Doe"</span><span>,</span>
            <span>Email</span> <span>=</span> <span>"joe@doe.com"</span>
          <span>},</span>
          <span>new</span> <span>User</span> <span>{</span>
            <span>ID</span> <span>=</span> <span>"2"</span><span>,</span>
            <span>Name</span> <span>=</span> <span>"Jane Doe"</span><span>,</span>
            <span>Email</span> <span>=</span> <span>"jane@doe.com"</span>
          <span>}</span>
        <span>};</span>
        <span>var</span> <span>table</span> <span>=</span> <span>new</span> <span>TableView</span><span>&lt;</span><span>User</span><span>&gt;</span> <span>{</span>
          <span>Items</span> <span>=</span> <span>users</span>
        <span>};</span>
        <span>table</span><span>.</span><span>AddColumn</span><span>(</span><span>user</span> <span>=&gt;</span> <span>user</span><span>.</span><span>ID</span><span>,</span> <span>"ID"</span><span>);</span>
        <span>table</span><span>.</span><span>AddColumn</span><span>(</span><span>user</span> <span>=&gt;</span> <span>user</span><span>.</span><span>Name</span><span>,</span> <span>"Name"</span><span>);</span>

        <span>var</span> <span>screen</span> <span>=</span> <span>new</span> <span>ScreenView</span><span>(</span><span>consoleRenderer</span><span>,</span> <span>invocationContext</span><span>.</span><span>Console</span><span>)</span> <span>{</span> <span>Child</span> <span>=</span> <span>table</span> <span>};</span>
        <span>screen</span><span>.</span><span>Render</span><span>();</span>
      <span>});</span>
      <span>return</span> <span>cmd</span><span>;</span>
    <span>}</span>
  <span>}</span>

  <span>class</span> <span>User</span> <span>{</span>
    <span>public</span> <span>string</span> <span>ID</span> <span>{</span> <span>get</span><span>;</span> <span>set</span><span>;</span> <span>}</span>
    <span>public</span> <span>string</span> <span>Name</span> <span>{</span> <span>get</span><span>;</span> <span>set</span><span>;</span> <span>}</span>
    <span>public</span> <span>string</span> <span>Email</span> <span>{</span> <span>get</span><span>;</span> <span>set</span><span>;</span> <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div> <p>Let's …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.mastykarz.nl/building-cross-platform-cli-dotnet-core/">https://blog.mastykarz.nl/building-cross-platform-cli-dotnet-core/</a></em></p>]]>
            </description>
            <link>https://blog.mastykarz.nl/building-cross-platform-cli-dotnet-core/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25987714</guid>
            <pubDate>Mon, 01 Feb 2021 11:27:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Z-Index by Examples]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25987669">thread link</a>) | @Arkh4m
<br/>
February 1, 2021 | https://juliu.is/z-index-by-examples | <a href="https://web.archive.org/web/*/https://juliu.is/z-index-by-examples">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I’ve been writing software “for a living” for more than ten years. I’m
afraid I have to admit that, for more than ten years, I’ve been using
<code>z-index</code> without really understanding it.</p>
<p><code>z-index</code> is a CSS property that is used to position elements above or
below one another. It’s your weapon of choice if you have two overlapping
elements and you want to decide which one goes on top. It’s quite useful
for modals, tooltips, banners, etc. You can set it to an integer and a
larger value will generally result in the element being rendered on top of
the rest.</p>
<p>That’s pretty much all I knew about it.</p>
<p>Usually, this is great in software: <em>“Learn enough to be dangerous”</em> they
say. But invariably I would find myself fighting with <code>z-index</code> and
spending hours trying to understand what is wrong with Life, the Universe,
and Everything.</p>
<p>I’m pretty sure it’s not just me. It’s common to bump into CSS like this:</p>
<blockquote>
<p>z-index: 99999</p>
</blockquote>
<p>Which is pretty much the equivalent of the developer saying:</p>
<blockquote>
<p>this is too wild, byeee</p>
</blockquote>
<p>Well, let’s tackle this beast with some examples.</p>
<h2>The setup</h2>
<p>I’ve created a <a href="https://z-index.juliu.is/">little app</a> to make things easy. It looks like this:</p>
<p><span>
    <span></span>
    <img alt="preview" title="" src="https://juliu.is/static/0934b66d1336f77082fefca1db90c94f/b9e4f/preview.png" srcset="https://juliu.is/static/0934b66d1336f77082fefca1db90c94f/cf440/preview.png 148w,
https://juliu.is/static/0934b66d1336f77082fefca1db90c94f/d2d38/preview.png 295w,
https://juliu.is/static/0934b66d1336f77082fefca1db90c94f/b9e4f/preview.png 590w,
https://juliu.is/static/0934b66d1336f77082fefca1db90c94f/f9b6a/preview.png 885w,
https://juliu.is/static/0934b66d1336f77082fefca1db90c94f/2d849/preview.png 1180w,
https://juliu.is/static/0934b66d1336f77082fefca1db90c94f/fce90/preview.png 1554w" sizes="(max-width: 590px) 100vw, 590px">
  </span></p>
<p>The boxes on the right are positioned statically. This is the default when
you don’t specify a <code>position</code> property, therefore a statically positioned
box is also known as a <strong>non-positioned</strong> box. I’ve added some negative
margins so they overlap with one another.</p>
<p>On the left-hand side, you can type some styles which will be applied to
the boxes. Notice that you can also share the setup by copying the URL.
Let’s get started now!</p>
<h2>Ordering matters</h2>
<p>Here’s the HTML that powers the page:</p>
<div data-language="html"><pre><code><span><span><span>&lt;</span>div</span> <span>class</span><span><span>=</span><span>"</span>purple<span>"</span></span><span>&gt;</span></span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
<span><span><span>&lt;</span>div</span> <span>class</span><span><span>=</span><span>"</span>blue<span>"</span></span><span>&gt;</span></span>
  <span><span><span>&lt;</span>div</span> <span>class</span><span><span>=</span><span>"</span>green<span>"</span></span><span>&gt;</span></span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
  <span><span><span>&lt;</span>div</span> <span>class</span><span><span>=</span><span>"</span>yellow<span>"</span></span><span>&gt;</span></span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
<span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
<span><span><span>&lt;</span>div</span> <span>class</span><span><span>=</span><span>"</span>red<span>"</span></span><span>&gt;</span></span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span></code></pre></div>
<p>As you can see, ordering in the HTML matters. The red box is positioned
above the rest because it appears later in the code.</p>
<h2>z-index doesn’t work by itself</h2>
<p>Look at <a href="https://z-index.juliu.is/?css=p%2Bz-index%3A%209999">this</a>:</p>
<p><span>
    <span></span>
    <img alt="z-index by itself" title="" src="https://juliu.is/static/fdba47018abddc6f09300b7df6e0c4ac/b9e4f/z-index-alone.png" srcset="https://juliu.is/static/fdba47018abddc6f09300b7df6e0c4ac/cf440/z-index-alone.png 148w,
https://juliu.is/static/fdba47018abddc6f09300b7df6e0c4ac/d2d38/z-index-alone.png 295w,
https://juliu.is/static/fdba47018abddc6f09300b7df6e0c4ac/b9e4f/z-index-alone.png 590w,
https://juliu.is/static/fdba47018abddc6f09300b7df6e0c4ac/f9b6a/z-index-alone.png 885w,
https://juliu.is/static/fdba47018abddc6f09300b7df6e0c4ac/2d849/z-index-alone.png 1180w,
https://juliu.is/static/fdba47018abddc6f09300b7df6e0c4ac/fce90/z-index-alone.png 1554w" sizes="(max-width: 590px) 100vw, 590px">
  </span></p>
<p>That’s rule number one:</p>
<blockquote>
<p>z-index works only on positioned elements.</p>
</blockquote>
<p>So <code>z-index</code> only works on elements that have a <code>position</code> property set to:</p>
<ul>
<li><code>relative</code></li>
<li><code>absolute</code></li>
<li><code>fixed</code></li>
<li><code>sticky</code></li>
</ul>
<p><a href="https://z-index.juliu.is/?css=p%2Bposition%3A%20relative%3Bz-index%3A%209999">There</a> we go:</p>
<p><span>
    <span></span>
    <img alt="z-index positioned" title="" src="https://juliu.is/static/398562e10636c6bc7e9aa822c0b3d584/b9e4f/z-index-positioned.png" srcset="https://juliu.is/static/398562e10636c6bc7e9aa822c0b3d584/cf440/z-index-positioned.png 148w,
https://juliu.is/static/398562e10636c6bc7e9aa822c0b3d584/d2d38/z-index-positioned.png 295w,
https://juliu.is/static/398562e10636c6bc7e9aa822c0b3d584/b9e4f/z-index-positioned.png 590w,
https://juliu.is/static/398562e10636c6bc7e9aa822c0b3d584/f9b6a/z-index-positioned.png 885w,
https://juliu.is/static/398562e10636c6bc7e9aa822c0b3d584/2d849/z-index-positioned.png 1180w,
https://juliu.is/static/398562e10636c6bc7e9aa822c0b3d584/fce90/z-index-positioned.png 1554w" sizes="(max-width: 590px) 100vw, 590px">
  </span></p>
<p>Would you be able to guess what happens when we remove the <code>z-index</code>
property from this example? Go on, I’ll wait.</p>
<p><a href="https://z-index.juliu.is/?css=p%2Bposition%3A%20relative">This</a> is what we see:</p>
<p><span>
    <span></span>
    <img alt="no z-index" title="" src="https://juliu.is/static/e896fb1635a9168646b81b937f7ad11d/b9e4f/no-z-index.png" srcset="https://juliu.is/static/e896fb1635a9168646b81b937f7ad11d/cf440/no-z-index.png 148w,
https://juliu.is/static/e896fb1635a9168646b81b937f7ad11d/d2d38/no-z-index.png 295w,
https://juliu.is/static/e896fb1635a9168646b81b937f7ad11d/b9e4f/no-z-index.png 590w,
https://juliu.is/static/e896fb1635a9168646b81b937f7ad11d/f9b6a/no-z-index.png 885w,
https://juliu.is/static/e896fb1635a9168646b81b937f7ad11d/2d849/no-z-index.png 1180w,
https://juliu.is/static/e896fb1635a9168646b81b937f7ad11d/fce90/no-z-index.png 1554w" sizes="(max-width: 590px) 100vw, 590px">
  </span></p>
<p>It turns out that positioned boxes appear on top of non-positioned boxes.
If you’re inclined, the <a href="https://www.w3.org/TR/CSS2/zindex.html">spec</a> goes
into <strong>much</strong> more detail.</p>
<p>But if all the boxes are positioned, we revert to following the order in
the HTML source. Look at
<a href="https://z-index.juliu.is/?css=b%2Bposition%3A%20relative%7Cp%2Bposition%3A%20relative%7Cr%2Bposition%3A%20relative">this</a>:</p>
<p><span>
    <span></span>
    <img alt="all positioned" title="" src="https://juliu.is/static/d8f35f9142c93f271bd95751879bf1fb/b9e4f/all-positioned.png" srcset="https://juliu.is/static/d8f35f9142c93f271bd95751879bf1fb/cf440/all-positioned.png 148w,
https://juliu.is/static/d8f35f9142c93f271bd95751879bf1fb/d2d38/all-positioned.png 295w,
https://juliu.is/static/d8f35f9142c93f271bd95751879bf1fb/b9e4f/all-positioned.png 590w,
https://juliu.is/static/d8f35f9142c93f271bd95751879bf1fb/f9b6a/all-positioned.png 885w,
https://juliu.is/static/d8f35f9142c93f271bd95751879bf1fb/2d849/all-positioned.png 1180w,
https://juliu.is/static/d8f35f9142c93f271bd95751879bf1fb/fce90/all-positioned.png 1554w" sizes="(max-width: 590px) 100vw, 590px">
  </span></p>
<p>And at that point, specifying a <code>z-index</code> <a href="https://z-index.juliu.is/?css=b%2Bposition%3A%20relative%3Bz-index%3A%201%7Cp%2Bposition%3A%20relative%3Bz-index%3A%202%7Cr%2Bposition%3A%20relative">does
work</a>!</p>
<p><span>
    <span></span>
    <img alt="finally z-index" title="" src="https://juliu.is/static/03a454c21d00f1e6821732738e1d70e1/b9e4f/finally-z-index.png" srcset="https://juliu.is/static/03a454c21d00f1e6821732738e1d70e1/cf440/finally-z-index.png 148w,
https://juliu.is/static/03a454c21d00f1e6821732738e1d70e1/d2d38/finally-z-index.png 295w,
https://juliu.is/static/03a454c21d00f1e6821732738e1d70e1/b9e4f/finally-z-index.png 590w,
https://juliu.is/static/03a454c21d00f1e6821732738e1d70e1/f9b6a/finally-z-index.png 885w,
https://juliu.is/static/03a454c21d00f1e6821732738e1d70e1/2d849/finally-z-index.png 1180w,
https://juliu.is/static/03a454c21d00f1e6821732738e1d70e1/fce90/finally-z-index.png 1554w" sizes="(max-width: 590px) 100vw, 590px">
  </span></p>
<p>Using the powers of <code>z-index</code> we were able to reverse the default stacking order of
the boxes. Go us.</p>
<h2>A new mystery</h2>
<p>Let’s look at <a href="https://z-index.juliu.is/?css=b%2Bposition%3A%20relative%7Cr%2Bposition%3A%20relative%7Cy%2Bposition%3A%20relative%3Bz-index%3A%201%3Bheight%3A%20200px">this
example</a>:</p>
<p><span>
    <span></span>
    <img alt="mystery" title="" src="https://juliu.is/static/24196cc40311cf0559114651d8c9e25d/b9e4f/mystery.png" srcset="https://juliu.is/static/24196cc40311cf0559114651d8c9e25d/cf440/mystery.png 148w,
https://juliu.is/static/24196cc40311cf0559114651d8c9e25d/d2d38/mystery.png 295w,
https://juliu.is/static/24196cc40311cf0559114651d8c9e25d/b9e4f/mystery.png 590w,
https://juliu.is/static/24196cc40311cf0559114651d8c9e25d/f9b6a/mystery.png 885w,
https://juliu.is/static/24196cc40311cf0559114651d8c9e25d/2d849/mystery.png 1180w,
https://juliu.is/static/24196cc40311cf0559114651d8c9e25d/fce90/mystery.png 1554w" sizes="(max-width: 590px) 100vw, 590px">
  </span></p>
<p>Out of the three positioned boxes, the yellow one has <code>z-index: 1</code>, and
therefore appears on top. Good, the world is making sense.</p>
<p>But what if we give a <code>z-index</code> to the blue box, the parent of the yellow box? Our
example would look like
<a href="https://z-index.juliu.is/?css=b%2Bposition%3A%20relative%3Bz-index%3A%200%7Cr%2Bposition%3A%20relative%7Cy%2Bposition%3A%20relative%3Bz-index%3A%201%3Bheight%3A%20200px">this</a>:</p>
<p><span>
    <span></span>
    <img alt="mystery part two" title="" src="https://juliu.is/static/f3119574dc5e9f1877b5d6d8f6e17fd7/b9e4f/mystery-two.png" srcset="https://juliu.is/static/f3119574dc5e9f1877b5d6d8f6e17fd7/cf440/mystery-two.png 148w,
https://juliu.is/static/f3119574dc5e9f1877b5d6d8f6e17fd7/d2d38/mystery-two.png 295w,
https://juliu.is/static/f3119574dc5e9f1877b5d6d8f6e17fd7/b9e4f/mystery-two.png 590w,
https://juliu.is/static/f3119574dc5e9f1877b5d6d8f6e17fd7/f9b6a/mystery-two.png 885w,
https://juliu.is/static/f3119574dc5e9f1877b5d6d8f6e17fd7/2d849/mystery-two.png 1180w,
https://juliu.is/static/f3119574dc5e9f1877b5d6d8f6e17fd7/fce90/mystery-two.png 1554w" sizes="(max-width: 590px) 100vw, 590px">
  </span></p>
<p>What’s happening here? Our yellow box is now rendered below the red one?!
All this because we added a <code>z-index: 0</code> to the blue one?! The world is
making no sense again. 😿</p>
<p>Let’s take a bit of a detour…</p>
<h2>Auto is not zero</h2>
<p>If we don’t set the <code>z-index</code> property of an element, its default value is
going to be <code>auto</code>. Such elements will appear in front of elements with
negative <code>z-index</code> values and below elements with positive <code>z-index</code>
values.
<a href="https://z-index.juliu.is/?css=b%2Bposition%3A%20relative%7Cp%2Bposition%3A%20relative%3Bz-index%3A%201%7Cr%2Bposition%3A%20relative%3Bz-index%3A%20-1">This</a>
should convince you that I’m not lying:</p>
<p><span>
    <span></span>
    <img alt="z-index auto" title="" src="https://juliu.is/static/1786f16b25da7227a7897b16f922c345/b9e4f/z-index-auto.png" srcset="https://juliu.is/static/1786f16b25da7227a7897b16f922c345/cf440/z-index-auto.png 148w,
https://juliu.is/static/1786f16b25da7227a7897b16f922c345/d2d38/z-index-auto.png 295w,
https://juliu.is/static/1786f16b25da7227a7897b16f922c345/b9e4f/z-index-auto.png 590w,
https://juliu.is/static/1786f16b25da7227a7897b16f922c345/f9b6a/z-index-auto.png 885w,
https://juliu.is/static/1786f16b25da7227a7897b16f922c345/2d849/z-index-auto.png 1180w,
https://juliu.is/static/1786f16b25da7227a7897b16f922c345/fce90/z-index-auto.png 1554w" sizes="(max-width: 590px) 100vw, 590px">
  </span></p>
<p>So in a way that element behaves as if we set <code>z-index: 0</code>. Indeed, if we
add that CSS rule, we see no notable changes in the
<a href="https://z-index.juliu.is/?css=b%2Bposition%3A%20relative%3Bz-index%3A%200%7Cp%2Bposition%3A%20relative%3Bz-index%3A%201%7Cr%2Bposition%3A%20relative%3Bz-index%3A%20-1">output</a>:</p>
<p><span>
    <span></span>
    <img alt="z-index zero" title="" src="https://juliu.is/static/e447a471c677ad3ed068d42015735809/b9e4f/z-index-zero.png" srcset="https://juliu.is/static/e447a471c677ad3ed068d42015735809/cf440/z-index-zero.png 148w,
https://juliu.is/static/e447a471c677ad3ed068d42015735809/d2d38/z-index-zero.png 295w,
https://juliu.is/static/e447a471c677ad3ed068d42015735809/b9e4f/z-index-zero.png 590w,
https://juliu.is/static/e447a471c677ad3ed068d42015735809/f9b6a/z-index-zero.png 885w,
https://juliu.is/static/e447a471c677ad3ed068d42015735809/2d849/z-index-zero.png 1180w,
https://juliu.is/static/e447a471c677ad3ed068d42015735809/fce90/z-index-zero.png 1554w" sizes="(max-width: 590px) 100vw, 590px">
  </span></p>
<p>But things changed a lot! Giving a value to <code>z-index</code> to a relatively
positioned box creates a new <strong>stacking context</strong>.</p>
<p>A stacking what?
<a href="https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Positioning/Understanding_z_index/The_stacking_context">MDN</a> says:</p>
<blockquote>
<p>The stacking context is a three-dimensional conceptualization of HTML
elements along an imaginary z-axis relative to the user, who is assumed
to be facing the viewport or the webpage. HTML elements occupy this space
in priority order based on element attributes.</p>
</blockquote>
<p>I thought this is what we were trying to do all along. Let’s keep reading.</p>
<p>The interesting part comes later:</p>
<blockquote>
<p>Within a stacking context, child elements are stacked according to the
same rules previously explained. Importantly, the z-index values of its
child stacking contexts only have meaning in this parent.</p>
</blockquote>
<p>That’s the key point. A stacking context will force the <code>z-index</code> of its
child stacking contexts to only have a local meaning. Let’s look at our
mysterious example again:</p>
<p><span>
    <span></span>
    <img alt="mystery part two" title="" src="https://juliu.is/static/f3119574dc5e9f1877b5d6d8f6e17fd7/b9e4f/mystery-two.png" srcset="https://juliu.is/static/f3119574dc5e9f1877b5d6d8f6e17fd7/cf440/mystery-two.png 148w,
https://juliu.is/static/f3119574dc5e9f1877b5d6d8f6e17fd7/d2d38/mystery-two.png 295w,
https://juliu.is/static/f3119574dc5e9f1877b5d6d8f6e17fd7/b9e4f/mystery-two.png 590w,
https://juliu.is/static/f3119574dc5e9f1877b5d6d8f6e17fd7/f9b6a/mystery-two.png 885w,
https://juliu.is/static/f3119574dc5e9f1877b5d6d8f6e17fd7/2d849/mystery-two.png 1180w,
https://juliu.is/static/f3119574dc5e9f1877b5d6d8f6e17fd7/fce90/mystery-two.png 1554w" sizes="(max-width: 590px) 100vw, 590px">
  </span></p>
<p>Setting <code>z-index: 0</code> on the blue box changed the meaning of the <code>z-index</code>
declaration on the yellow box. Before, the yellow box was out there playing
with the big boys. Now, it can only affect stacking within the blue box.</p>
<p>This is a great cause of frustration. No matter how high you set a
<code>z-index</code> property, you will <em>never</em> be able to ‘escape’ the parent
stacking context.  And every time you are struggling with making <code>z-index</code>
work you can bet that it’s because <em>something</em> created a stacking context
that you can’t escape from.</p>
<p>With this newfound understanding, spend some time explaining why <a href="https://z-index.juliu.is/?css=b%2Bposition%3A%20relative%3Bz-index%3A%201%7Cg%2Bposition%3A%20relative%3Bz-index%3A%2010%7Cp%2Bposition%3A%20relative%3Bz-index%3A%202%7Cr%2Bposition%3A%20relative%7Cy%2Bposition%3A%20relative%3Bz-index%3A%205%3Bheight%3A%20200px">this
example</a> makes perfect sense:</p>
<p><span>
    <span></span>
    <img alt="no mystery" title="" src="https://juliu.is/static/3a1b4c6e74adfd5afaaa323f54c4c699/b9e4f/no-mystery.png" srcset="https://juliu.is/static/3a1b4c6e74adfd5afaaa323f54c4c699/cf440/no-mystery.png 148w,
https://juliu.is/static/3a1b4c6e74adfd5afaaa323f54c4c699/d2d38/no-mystery.png 295w,
https://juliu.is/static/3a1b4c6e74adfd5afaaa323f54c4c699/b9e4f/no-mystery.png 590w,
https://juliu.is/static/3a1b4c6e74adfd5afaaa323f54c4c699/f9b6a/no-mystery.png 885w,
https://juliu.is/static/3a1b4c6e74adfd5afaaa323f54c4c699/2d849/no-mystery.png 1180w,
https://juliu.is/static/3a1b4c6e74adfd5afaaa323f54c4c699/fce90/no-mystery.png 1554w" sizes="(max-width: 590px) 100vw, 590px">
  </span></p>
<p>Also remember that before we said that positioned elements appear on top of
non-positioned elements? Well, now we can generalize by saying that
elements that form a stacking context appear on top of non-positioned
elements.</p>
<h2>The usual suspects</h2>
<p>The
<a href="https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Positioning/Understanding_z_index/The_stacking_context">MDN article</a>
lists all cases when a new stacking context is formed. I’m going to go through a
list of usual suspects.</p>
<p><a href="https://z-index.juliu.is/?css=p%2Bopacity%3A%200.90">Opacity less than 1</a></p>
<p><span>
    <span></span>
    <img alt="opacity" title="" src="https://juliu.is/static/3809618b7219c0eb8aea13f481174227/b9e4f/opacity.png" srcset="https://juliu.is/static/3809618b7219c0eb8aea13f481174227/cf440/opacity.png 148w,
https://juliu.is/static/3809618b7219c0eb8aea13f481174227/d2d38/opacity.png 295w,
https://juliu.is/static/3809618b7219c0eb8aea13f481174227/b9e4f/opacity.png 590w,
https://juliu.is/static/3809618b7219c0eb8aea13f481174227/f9b6a/opacity.png 885w,
https://juliu.is/static/3809618b7219c0eb8aea13f481174227/2d849/opacity.png 1180w,
https://juliu.is/static/3809618b7219c0eb8aea13f481174227/fce90/opacity.png 1554w" sizes="(max-width: 590px) 100vw, 590px">
  </span></p>
<p><a href="https://z-index.juliu.is/?css=p%2Btransform%3A%20rotate(30deg)">Transform and filter effects</a></p>
<p><span>
    <span></span>
    <img alt="transform" title="" src="https://juliu.is/static/2efb5e9bce68c348867bb8a7ba089794/b9e4f/transform.png" srcset="https://juliu.is/static/2efb5e9bce68c348867bb8a7ba089794/cf440/transform.png 148w,
https://juliu.is/static/2efb5e9bce68c348867bb8a7ba089794/d2d38/transform.png 295w,
https://juliu.is/static/2efb5e9bce68c348867bb8a7ba089794/b9e4f/transform.png 590w,
https://juliu.is/static/2efb5e9bce68c348867bb8a7ba089794/f9b6a/transform.png 885w,
https://juliu.is/static/2efb5e9bce68c348867bb8a7ba089794/2d849/transform.png 1180w,
https://juliu.is/static/2efb5e9bce68c348867bb8a7ba089794/fce90/transform.png 1554w" sizes="(max-width: 590px) 100vw, 590px">
  </span></p>
<p><a href="https://z-index.juliu.is/?css=b%2Bdisplay%3A%20flex%7Cp%2Bposition%3A%20relative%3Bz-index%3A%201%7Cy%2Bz-index%3A%202">Flex child with z-index</a></p>
<p><span>
    <span></span>
    <img alt="flex child" title="" src="https://juliu.is/static/bfc982cc7751b6f9c688330abbb6f131/b9e4f/flex-child.png" srcset="https://juliu.is/static/bfc982cc7751b6f9c688330abbb6f131/cf440/flex-child.png 148w,
https://juliu.is/static/bfc982cc7751b6f9c688330abbb6f131/d2d38/flex-child.png 295w,
https://juliu.is/static/bfc982cc7751b6f9c688330abbb6f131/b9e4f/flex-child.png 590w,
https://juliu.is/static/bfc982cc7751b6f9c688330abbb6f131/f9b6a/flex-child.png 885w,
https://juliu.is/static/bfc982cc7751b6f9c688330abbb6f131/2d849/flex-child.png 1180w,
https://juliu.is/static/bfc982cc7751b6f9c688330abbb6f131/fce90/flex-child.png 1554w" sizes="(max-width: 590px) 100vw, 590px">
  </span></p>
<p><a href="https://z-index.juliu.is/?css=b%2Bdisplay%3A%20grid%7Cg%2Bz-index%3A%202%7Cp%2Bposition%3A%20relative%3Bz-index%3A%201">Grid child with z-index</a></p>
<p><span>
    <span></span>
    <img alt="grid child" title="" src="https://juliu.is/static/7b9b78fe695e1dcf2c857e801b593b9b/b9e4f/grid-child.png" srcset="https://juliu.is/static/7b9b78fe695e1dcf2c857e801b593b9b/cf440/grid-child.png 148w,
https://juliu.is/static/7b9b78fe695e1dcf2c857e801b593b9b/d2d38/grid-child.png 295w,
https://juliu.is/static/7b9b78fe695e1dcf2c857e801b593b9b/b9e4f/grid-child.png 590w,
https://juliu.is/static/7b9b78fe695e1dcf2c857e801b593b9b/f9b6a/grid-child.png 885w,
https://juliu.is/static/7b9b78fe695e1dcf2c857e801b593b9b/2d849/grid-child.png 1180w,
https://juliu.is/static/7b9b78fe695e1dcf2c857e801b593b9b/fce90/grid-child.png 1554w" sizes="(max-width: 590px) 100vw, 590px">
  </span></p>
<p>Some of these examples might look surprising. In general, the underlying
reason why these configurations create a new stacking context is that they
render to an offscreen context. But in practice, you don’t need to remember
all of them: when you bump into a situation where <code>z-index</code> isn’t working
as intended, you can quickly check if there’s a runaway stacking context
that’s keeping you locked up.</p>
<p>I recommend going through each one of the examples, playing around with
them, and explaining in your head why they make perfect sense. It might be
helpful to install a browser extension to help check your intuition and
solidify your understanding
(<a href="https://chrome.google.com/webstore/detail/z-context/jigamimbjojkdgnlldajknogfgncplbh">Chrome</a>,
<a href="https://addons.mozilla.org/en-GB/firefox/addon/devtools-z-index/">Firefox</a>).</p>
<p>That’s all I have for you today. As always, thanks for reading!</p></div></div>]]>
            </description>
            <link>https://juliu.is/z-index-by-examples</link>
            <guid isPermaLink="false">hacker-news-small-sites-25987669</guid>
            <pubDate>Mon, 01 Feb 2021 11:16:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Do less and do it better]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25987605">thread link</a>) | @todsacerdoti
<br/>
February 1, 2021 | http://qmacro.org/2021/02/01/do-less-and-do-it-better/ | <a href="https://web.archive.org/web/*/http://qmacro.org/2021/02/01/do-less-and-do-it-better/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><em>In 2021 I want to consolidate and improve upon some skills I already have, rather than add more. Here’s what I mean, and how I got inspired.</em></p>

<p>In October last year Samir Talwar <a href="https://twitter.com/SamirTalwar/status/1318904227935227905">tweeted</a> something simple yet profound: “<em>Do less, and do it better</em>”.</p>

<p>In my work and play I discover and start using various tools and technologies. The pace of change in this industry, coupled with the (not unpleasant) demands on what I have to produce, means that I often end up with only a shallow understanding of things. And sometimes these are things I use every day.</p>

<p>The nature of my job as a developer advocate (but I think this extends to development in general), in the context of that fast pace of change, means that there’s always something new to learn, to adopt, and to incorporate into a workflow, process or solution. But that can come at a price - of limited comprehension and mastery.</p>

<p>To explain further, I’m going to stretch a metaphor relating to ploughing a field and sowing seeds.</p>

<p><strong>Ploughing and sowing</strong></p>

<p>As an individual, I sometimes feel as though I’m trying to prepare a large field and plant seeds there using a poorly hand-constructed and inefficient plough made of the wrong sort of wood and bits of string, combined with a seed drill made out of old toilet rolls and sticky tape. Not only that, but I’m trying to plant across the entire field, 50 furrows wide, as I move along.</p>

<p>Needless to say, the ploughing doesn’t go very well, and the seeds are planted imprecisely, sometimes superficially, mostly wastefully, resulting in poor distribution, low growth and high energy expenditure.</p>

<p>But if I were to abandon the idea of going wide, and instead go narrow, focusing on just a handful of furrows, I could afford to take the time to correctly plant each seed, nurturing &amp; watering each one, producing strong plants with deep roots and healthy growth.</p>

<p>I’ve thought this for a while but never got round to doing anything about it. Samir’s tweet has galvanised me into spending some time working out what that means for me.</p>

<p><strong>Consolidating</strong></p>

<p>So this year I’m attempting to “do less, and do it better” by acknowledging the tools I use day in day out, and learn more about them, restricting myself to a narrow set of topics, move a step closer towards mastery in each, and really benefit from everything they have to offer.</p>

<p>Here’s an example from this weekend; I read the entirety of the main README for the excellent fuzzy-finder tool <a href="https://github.com/junegunn/fzf"><code>fzf</code></a>, all 16 pages. That might seem ridiculous to say (16 pages is not a lot) but I’ve used <code>fzf</code> for a year or so and never RTFM’d before. In my defence, I’ve also been constantly and painfully aware that I’ve merely scratched the surface. I’ve now discovered some <code>fzf</code> gems that I can put into practice immediately, and some areas that I need to dig into more.</p>

<p>Likewise for other tools that I use, tools that are not only essential, but which, when mastered, can make my workflows even better. I’m thinking of Vim (I’ve recently started watching my friend and colleague David Kunz’s <a href="https://www.youtube.com/channel/UCFU7a7OMYfcpjtIpu2j47_Q">DevOnDuty</a> series, which I can strongly recommend), <a href="https://github.com/tmux/tmux/wiki"><code>tmux</code></a> (<a href="http://rwxrob.live/">rwxrob</a> is a great practitioner, and I should re-read Brian P. Hogan’s great <a href="https://pragprog.com/titles/bhtmux2/tmux-2/">book on tmux</a> too) and of course the environment and language that ties it all together for me - <a href="https://www.gnu.org/software/bash/">Bash</a>.</p>

<p>The lockdown has afforded me time to read more, and I need to embrace that and work out how I can keep that momentum up. I want to tip the balance over from always having my fingers on the keyboard towards stepping away from the keyboard to read, reflect and consolidate my learning.</p>

<hr>

<p>Update 02 Feb 2021: I’ve started digging deeper into <code>fzf</code> - see <a href="https://qmacro.org/autodidactics/2021/02/02/fzf-the-basics-1-layout/">fzf - the basics part 1 - layout</a> over on my <a href="https://qmacro.org/autodidactics/">Autodidactics</a> blog.</p>

  </div>

</article>

      </div>
    </div></div>]]>
            </description>
            <link>http://qmacro.org/2021/02/01/do-less-and-do-it-better/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25987605</guid>
            <pubDate>Mon, 01 Feb 2021 11:06:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reality is an evolved illusion]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25987595">thread link</a>) | @paraschopra
<br/>
February 1, 2021 | https://invertedpassion.com/reality-is-an-evolved-illusion/ | <a href="https://web.archive.org/web/*/https://invertedpassion.com/reality-is-an-evolved-illusion/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1514">
		<!-- .entry-header -->
	<div>
		
		
<p>Do we see reality as it is? </p>

<p>I discuss this question with <a href="https://www.cogsci.uci.edu/~ddhoff/">Donald Hoffman</a> who is professor emeritus at the University of California, Irvine. He studies consciousness and perception from an evolutionary point of view. His research has led him to make a bold claim that while we do not yet know what the underlying reality could be like. Rather, reality as we know it now – including space, time, and objects – is a useful fiction that <a href="https://invertedpassion.com/evolution-explains-everything/">evolution</a> invented for us.</p>

<p>His TED talk on our <a href="https://www.youtube.com/watch?v=oYp5XuGYqqY">perception of reality</a> has been watched over 3 million times, and in his recent pop-science book for the wider audience,<a href="https://www.goodreads.com/en/book/show/41817484"> <em>The Case Against Reality</em></a>, he makes a convincing case on how our perceived reality is an illusion that has evolved to help us survive and reproduce.</p>

<figure>
<p>
<iframe title="#3 Donald Hoffman - Reality is an evolved illusion" width="780" height="439" src="https://www.youtube.com/embed/kjxF6rcblTw?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>
</figure>

<h3>What we talk about</h3>

<p><strong>1:46</strong> – Towards building a mathematical understanding perception<br><strong>5:12</strong> – Evolutionary game theory to help understand perception<br><strong>6:26</strong> – Computing truth is expensive, so evolution get rids of it<br><strong>8:00</strong> – Mathematical proof that evolution doesn’t tune us to see the truth<br><strong>9:56</strong> – David Marr’s ideas and inverse optics<br><strong>11:30</strong> – What are fitness payoffs? Why do they matter? How are they determined?<br><strong>16:23</strong> – Maximizing for truth vs maximizing for winning<br><strong>18:40</strong> – Illusions that show physical reality doesn’t exist<br><strong>23:21</strong> – Physical reality not being fundamental as a scientific claim<br><strong>24:23</strong> – Existing physics points to spacetime not being fundamental<br><strong>30:25</strong> – The basics of the interface theory of perception<br><strong>34:40</strong> – We have to guess mathematically the deeper structure of reality<br><strong>38:00</strong> – Model-free planning in reinforcement learning<br><strong>44:45</strong> – Why should we care about what is objective reality?<br><strong>49:20</strong> – How can we use science to go beyond physical reality?<br><strong>56:57</strong> – Reality is a huge social network of conscious agents<br><strong>1:03:41</strong> –  Predictions from the mathematics of conscious agents<br><strong>1:09:26</strong> – “We will be able to warp space and time”<br><strong>1:09:35</strong> – Bridging conscious agents to physical reality<br><strong>1:15:32</strong> – How far along have we come in his journey of building a fundamental theory of reality based on consciousness?<br><strong>1:17:31</strong> – Is mathematics part of the underlying reality or is it a useful fiction too?<br><strong>1:30:12</strong> – Does your research on reality and consciousness impact your personal life and beliefs?</p>

<h3>Notes and Key Insights</h3>

<p>1/ Illusions show that we do not see reality as it is. For example, patches A and B in the image below are of the same color (which means the photons arriving from these two patches are of the same wavelength).</p>

<div>
<figure><img loading="lazy" width="480" height="372" src="https://invertedpassion.com/wp-content/uploads/2021/01/gallery_1425045941-kq2pcqd8jgz7mr0hnz63.png" alt="" srcset="https://invertedpassion.com/wp-content/uploads/2021/01/gallery_1425045941-kq2pcqd8jgz7mr0hnz63.png 480w, https://invertedpassion.com/wp-content/uploads/2021/01/gallery_1425045941-kq2pcqd8jgz7mr0hnz63-300x233.png 300w" sizes="(max-width: 480px) 100vw, 480px"></figure>
</div>

<p>2/ You can verify that the colors in the two patches are exactly the same via a color picker app. <strong>Yet our mind sees them as completely different colors</strong>. This clearly demonstrates that, at least in this case, we’re not seeing reality as it is.</p>

<p>3/ The reason this illusion works is because <strong>our vision isn’t like a camera</strong>. It cannot be because a) unlike a camera sensor, we have a big hole in the middle of our retina (<a href="https://en.wikipedia.org/wiki/Blind_spot_(vision)">blind spot</a>) that we never notice); b) incoming photons pass through many obstructions (most notably neurons) that we never notice.</p>



<p>4/ A true perception of reality should have a big black hole in the middle of the vision. Moreover, become we <a href="https://www.smithsonianmag.com/science-nature/our-eyes-are-always-darting-around-s-not-how-we-see-world-180972414/">saccade our gaze</a> several times a second, <strong>we should see constantly shifting images rather than the stable vision we perceive</strong>.</p>

<p>But we don’t.</p>



<p>5/ The reason our vision is oblivious to rapid eye saccades and the blind spot is that <strong>our senses haven’t evolved to perceive reality as it is</strong>. Rather, our senses have evolved to help us to survive and reproduce.</p>

<p>6/ In terms of calories and energy, it’s costly to process information. Take the housefly, for example. It has a tiny brain and needs fewer calories than us. It has eyes that are used to find food and mates. But given the size of its brain and calories its brain has for processing information, do you suppose the fly has a complete, rich, and accurate perception of the world around it?</p>

<p>7/ Well, from an evolution’s point of view, as long as the fly is able to find food and mates, it’s preferable to have an incomplete and distorted but calorically cheap representation of reality than an accurate perception of reality.</p>

<p>8/ In fact, that is what Donald Hoffman and his colleagues prove via a mathematical theorem called <a href="https://chrisfieldsresearch.com/FitnessBeatsTruth_ActaB_submitted_2019.pdf"><em>Fitness Beats Truth</em>.</a> Put simply, <strong>it suggests that the probability that our senses have evolved to report the truth about reality is zero</strong>. </p>

<p>9/ They suggest that instead of reporting the truth, <strong>our senses report fitness payoffs that our estimates of the potential for acquiring resources</strong>, attracting mates, and getting ahead of others. </p>

<p>In short, fitness payoffs are our estimates of reproductive potential.</p>

<p>10/ <strong>You can imagine fitness payoffs as points in a game</strong>. The more points you accumulate, the longer you can play the game. </p>

<p>In the game, if there are two players: one focused on acquiring as many points as possible (fitness) and another focused on understanding how the game works (truth), guess who will win?</p>

<p>11/ Of course, fitness depends on truth but it isn’t mapped to it one to one.</p>

<p>Take the example of oxygen – too little or too much of it will kill us. We just need the right amount of it.</p>

<p>This means an organism evolved to report the <em>true</em> amount of oxygen will get out-competed by an organism evolved to report the <em>right</em> amount of oxygen.</p>

<p><strong>Reverse engineering from fitness to the truth isn’t trivial.</strong> Oxygen wasn’t discovered until 1771.</p>

<p>12/ In summary, <strong>the claim is that our physical reality is like virtual reality. </strong>We do not know what true reality is but we can be sure that whatever we perceive isn’t likely to be it.</p>

<p>There are a few objections one can raise against this idea.</p>

<p>13/ OBJECTION 1 -&gt; Okay, so <strong>if we don’t perceive reality as it is, why not jump in front of a train?</strong></p>

<p>Donald Hoffman suggests that the reason you don’t jump in front of a train is similar to the reason you don’t drag your important files on your computer to the trash bin icon. Nobody believes that the trash bin icon is real (it’s implemented behind the scenes as transistors and electric signals), yet interaction with it has real consequences for you.</p>

<p>14/ Similarly, even though we don’t perceive true reality, it doesn’t mean that our perceptions are arbitrary. Our actions within the perceived reality have real consequences.</p>

<p>15/ OBJECTION 2 -&gt; <strong>If we are in virtual reality, how do we explain the <a href="https://invertedpassion.com/professional-success-and-personal-success-two-independent-dimensions/">success</a> of science and engineering?</strong> We have sent people to the moon, so surely we must be understand something about what reality is?</p>

<p>16/ Donald Hoffman says that <strong>our engineering success suggests an increased mastery over the virtual reality we’re embedded in</strong>. Just like a player can get better at a game by studying game mechanics, we can master our perceived reality better and better.</p>

<p>But just like a gamer doesn’t understand how the game is implemented under the hood, we don’t necessarily understand what the actual reality is.</p>

<p> 17/ Modern physics actually agrees with the interpretation that the actual reality could be much stranger than our perceptions. <a href="https://en.wikipedia.org/wiki/Bell%27s_theorem">Bell’s theorem</a> suggests that reality is not local and that quantum entanglement over large distances is a real thing. The <a href="https://en.wikipedia.org/wiki/Holographic_principle">holographic principle</a> suggests our 3D universe may actually be a projection from 2D.</p>

<p>18/ <strong>As a theme in physics, reality as we perceive has become less and less tenable</strong>. From this perspective, the claim that we don’t perceive true reality is not surprising.</p>

<p>19/ Although it should be recognized that our perception isn’t completely arbitrary. <strong>We do not have direct access to reality and our only access to it is via our senses</strong>. So when things change <em>out there</em>, our perception changes accordingly. </p>

<p>20/ For example, we perceive many objects as round because they share <em>something</em> that causes roundness to emerge in our perception for <em>all</em> of them. Similarly, different red things share <em>something</em> (a particular wavelength of light) which causes us to see red.</p>

<p>21/ In fact, finding out <a href="https://en.wikipedia.org/wiki/Invariant_(physics)">invariants of the world</a> might be is what science is all about. Coming back to the example of a game, an expert player might master game mechanics better and better, but you know what will be even more effective at winning the game? Reverse engineering how the game works and directly interfering with its source code.</p>

<p>22/ We do not yet have a complete understanding of reality and I’m not even sure if we will ever have it. But the success of science in predicting more and more phenomena over time suggests that we’re understanding the game mechanics of how reality works better and better. </p>

<p>23/ All this sounds nice and logical, but <strong>how do we explain conscious experiences?</strong> Any description of reality must accommodate the subjective experiences we have of seeing red or smelling coffee. Where do these subjective experiences come from?</p>

<p>24/ An incomplete but important answer is that <strong>these perceptions are compressed representations of reality that got evolved for adaptive <a href="https://invertedpassion.com/evidence-of-desire-customer-behavior/">behavior</a></strong>. Color vision helped our ancestors pick ripe fruits from unripe ones. Fragrances told them in an instant what to avoid (bitter) and what to crave (sweet).</p>

<p>25/ That’s good but <strong>it appears that what we subjectively experience represents reality in a completely arbitrary way</strong>. (Although it’s an ongoing area of research and there may be some structure). </p>

<p>For example, try to guess which of the molecules is <a href="https://en.wikipedia.org/wiki/Vanillin">vanilla</a> and which one is <a href="https://en.wikipedia.org/wiki/Thymol">thyme</a>.</p>

<figure>
<ul>
<li>
<figure><img loading="lazy" width="830" height="1024" src="https://invertedpassion.com/wp-content/uploads/2021/02/1920px-Thymol2.svg_-830x1024.png" alt="" data-id="1520" data-full-url="https://invertedpassion.com/wp-content/uploads/2021/02/1920px-Thymol2.svg_.png" data-link="https://invertedpassion.com/?attachment_id=1520" srcset="https://invertedpassion.com/wp-content/uploads/2021/02/1920px-Thymol2.svg_-830x1024.png 830w, https://invertedpassion.com/wp-content/uploads/2021/02/1920px-Thymol2.svg_-243x300.png 243w, https://invertedpassion.com/wp-content/uploads/2021/02/1920px-Thymol2.svg_-768x947.png 768w, https://invertedpassion.com/wp-content/uploads/2021/02/1920px-Thymol2.svg_-1245x1536.png 1245w, https://invertedpassion.com/wp-content/uploads/2021/02/1920px-Thymol2.svg_-1661x2048.png 1661w, https://invertedpassion.com/wp-content/uploads/2021/02/1920px-Thymol2.svg_-1560x1924.png 1560w, https://invertedpassion.com/wp-content/uploads/2021/02/1920px-Thymol2.svg_.png 1920w" sizes="(max-width: 830px) 100vw, 830px"></figure>
</li>
<li>
<figure><img loading="lazy" width="940" height="1024" src="https://invertedpassion.com/wp-content/uploads/2021/02/1920px-Vanillin2.svg_-940x1024.png" alt="" data-id="1521" data-full-url="https://invertedpassion.com/wp-content/uploads/2021/02/1920px-Vanillin2.svg_.png" data-link="https://invertedpassion.com/?attachment_id=1521" srcset="https://invertedpassion.com/wp-content/uploads/2021/02/1920px-Vanillin2.svg_-940x1024.png 940w, https://invertedpassion.com/wp-content/uploads/2021/02/1920px-Vanillin2.svg_-275x300.png 275w, https://invertedpassion.com/wp-content/uploads/2021/02/1920px-Vanillin2.svg_-768x836.png 768w, https://invertedpassion.com/wp-content/uploads/2021/02/1920px-Vanillin2.svg_-1410x1536.png 1410w, https://invertedpassion.com/wp-content/uploads/2021/02/1920px-Vanillin2.svg_-1881x2048.png 1881w, https://invertedpassion.com/wp-content/uploads/2021/02/1920px-Vanillin2.svg_-1560x1699.png 1560w, https://invertedpassion.com/wp-content/uploads/2021/02/1920px-Vanillin2.svg_.png 1920w" sizes="(max-width: 940px) 100vw, 940px"></figure>
</li>
</ul>
</figure>

<p>26/ Can’t guess? That’s okay. </p>

<p>Thankfully, to operate in the world you don’t have to remember the molecular structure. Our brain directly translates the signals originating corresponding smelling these molecules into a distinct subjective experience which you can use to take action.</p>

<p>27/ <strong>It does this translation because the molecular structure of these molecules was irrelevant for our survival and reproduction</strong>. For success in an evolutionary competition, what matters is our actions and this compressed signal that there’s vanilla or thyme around is good enough for informing such actions.</p>

<p>27/ Donald Hoffman suggests that even the …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://invertedpassion.com/reality-is-an-evolved-illusion/">https://invertedpassion.com/reality-is-an-evolved-illusion/</a></em></p>]]>
            </description>
            <link>https://invertedpassion.com/reality-is-an-evolved-illusion/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25987595</guid>
            <pubDate>Mon, 01 Feb 2021 11:04:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Block out input-free time]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25987391">thread link</a>) | @vitabenes
<br/>
February 1, 2021 | https://www.deprocrastination.co/blog/block-out-input-free-time | <a href="https://web.archive.org/web/*/https://www.deprocrastination.co/blog/block-out-input-free-time">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p><img src="https://www.deprocrastination.co/assets/illustrations/block_out_time.png" alt="Block out input-free time"></p><p>How much time do you spend aimlessly scrolling? Looking for new and interesting information? Checking notifications, likes, or emails?</p><p>For many of us, the answer is hours every day. The question is: is that time well spent? Probably not.</p><p>Now, there's nothing wrong with occasionally watching a YouTube video or two in the evening (so long as it doesn't cut into your sleep schedule.) However, always seeking something&nbsp;<em>new</em>&nbsp;is not good for us.</p><p>Our screens have become addictive. They are visually stimulating, offering fast feedback for our actions.&nbsp;<em>Tap</em>&nbsp;and you're rewarded with infinite potentially interesting videos or games.</p><p>Worse, our screens control our behavior by controlling the choices presented to us.</p><h2>The default choice architecture</h2><p>When you have "nothing to do," what do you do?</p><p>You probably take your phone, or open the browser and are presented with choices. Facebook, Instagram, Twitter, TikTok, email,...</p><p>Here's why it's bad: those choices aren't designed to help you.</p><p>When we're presented with options, we choose from them. We rarely create&nbsp;<em>our own</em>&nbsp;additional and better options. That would take effort. We'd have to think. Our actions are guided by the interfaces we're looking at every day.</p><p>It's always easier to tap an icon and watch something than figure out what you need to do next. Yet, the latter is much better for us. The latter helps us make our lives better and easier in the future.</p><h3>The missing apps</h3><p>Here are some "apps" that you don't see when you're looking for something to do.</p><ul><li>Tidy up my room</li><li>Take out the trash</li><li>Wash the dishes</li><li>Think about what you want to accomplish this year</li><li>Re-decorate the room</li><li>Stretch for a bit</li><li>Set a goal and put it on a calendar</li></ul><p>You don't see the above when you open your laptop or unlock your phone. That's a shame, because these actions would actually make your life a bit better, unlike doomscrolling.</p><p>What you see influences what you do. If you're not reminded of productive actions by your surroundings, you'll take unproductive actions instead, against your interests, just because they are the easiest choice at the moment.</p><p>When we're not using our computer to produce something or to connect with someone, our time is often better spent off-screen. Many on-screen actions are optimized to suck away our attention, not use it to improve our lives.</p><p>That's one argument for less screen time. Here's another one.</p><h2>The catch-22 of digital distractions</h2><p>You don't feel great. Your life is not like the life of the celebrities you see on social media. You feel bad about yourself. So you escape. You watch something. You scroll. You turn off your brain and let the memes and silly GIFs take over. It takes your mind off your life.</p><p>Then you get tired or you finally fall asleep, way too late, disrupting your sleep schedule.</p><p>The next day, you wake up and are back at square 0. You still don't feel that great about yourself...</p><p>Digital distractions are self-perpetuating misery machines.</p><h3>Zombie mode: Low effort, low value entertainment</h3><p>You don't feel great, so you choose to get distracted.</p><p>But then you become distracted, which causes you to not feel great. After all, you haven't made any real progress.</p><p>So the cycle continues.</p><p>You rarely get off the Internet feeling excited and ready to take on the world.</p><p>No, you feel distracted. Unsure what to do. Unfocused. That mental state is not great. And it's not useful.</p><p>That's what we call Zombie mode: passively consuming online media to get cheap dopamine.</p><p>Let's stop this cycle.</p><p>"How?" you ask.</p><h2>Let your mind wander</h2><p>The solution is simple: get away from screens.</p><p>With the arrival of information technologies, information has become less and less connected to our daily lives. In other words, less relevant.</p><p>The news, social media, and much of the Internet is utterly irrelevant to your life right now.&nbsp;<strong>You don't need more information, you need to do more with the information you already have.</strong></p><p>And to do that, you need time to process it. Time to take the general lessons of others and figure out how you can implement them in your own life. Time to turn the information into action. Time to go from passive to active.</p><h3>Unprocessed thoughts = heavy burden</h3><p>When you've spent the whole day binging a Netflix show, then you won't have time to process the fact that you're getting out of shape, or that you've let your room be a mess, or that you still have not messaged John,... There's no time for left for it, you're always distracted. Always "not feeling like" doing what needs to be done.</p><p>Over time, unfinished business accumulates in our mind. Promises we've made, things we meant to do, requests from others.</p><p>When we don't create time to let all those things unwind in our mind and deal with them, they become a heavy burden in our mind.</p><h3>Afraid of your thoughts?</h3><p>When the unprocessed thoughts accumulate over long periods of time, they can turn into the fear of being alone with your own thoughts. The idea of thinking about what we need to deal with becomes so stressful that we want avoid it as much as we can.</p><p>We fill our time with podcasts, YouTube videos, Instagram scrolling, watching TikToks, and other passive activities because&nbsp;<strong>we fear the moments when our mind is free of external inputs.</strong></p><p>The only moment when we're alone is when falling asleep or in a shower, and some people fill even those moments with music or podcasts.</p><p>Needless to say, this is terrible for us.</p><h2>Most digital tools aren't suited for figuring things out</h2><p>The problem is that our digital environment is not well suited to letting our mind wander and being intentional.</p><p><strong>When you want to think, reflect, or figure things out, a screen is not your friend.</strong>&nbsp;(The one exception may be a blank screen of a distraction-free editor.)</p><p>To mull over your current circumstances and formulate what to do, go away from screens for an extended periods of time.</p><p>Create big chunks of time (1 hour or more) when you have "nothing to do." Create that space and then don't fill it with low-effort unproductive actions! Instead, let your mind be. Let yourself wander a bit. And then act on thoughts that are at least mildly productive.</p><p>Let yourself process the accumulated unfinished business. Unpack your baggage.</p><p>Here's one way to turn this into practice.</p><h3>⏱ Block out an Input-free Hour</h3><p>Set a timer for 60 minutes, and go away from any screens until the timer goes off.</p><p>Do anything, except for staring at screens. Don't consume any information from the outside, only from your own mind. No podcasts, no news, no social media. Tidy up, nap, go for a walk.</p><p>If you want to, write down some thoughts, but don't look of external information.</p><p>For 60 minutes, do not consume any more information, deal with the stuff already on your mind.</p><p>Put it on your calendar, or do it on the fly by setting a time.</p><p>You can try it right now. Stop reading. Set a timer for 1 hour on your phone, put your phone screen-side down and walk away from it.</p><h2>Block out input-free time in your life</h2><p>Let your mind wander.</p><p>Get away from time-sucking apps and do something offline that will make your life a bit better tomorrow, instead of waking up back at square 1 every day.</p><p><strong>You don't need more information. You need to do more with the information you already have.</strong></p></article></div>]]>
            </description>
            <link>https://www.deprocrastination.co/blog/block-out-input-free-time</link>
            <guid isPermaLink="false">hacker-news-small-sites-25987391</guid>
            <pubDate>Mon, 01 Feb 2021 10:28:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Exploring Kubernetes Operator Pattern]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25987069">thread link</a>) | @alexellisuk
<br/>
February 1, 2021 | https://iximiuz.com/en/posts/kubernetes-operator-pattern | <a href="https://web.archive.org/web/*/https://iximiuz.com/en/posts/kubernetes-operator-pattern">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a name="cut"></a>
I've been using Kubernetes for almost a year now and, to be honest, I like the experience so far. Most of my use cases were rather trivial and thanks to its declarative approach, Kubernetes makes deploying and scaling stateless services pretty simple. I usually just describe my application in a YAML file as a set of interconnected services, feed it to Kubernetes, and let the built-in <a href="https://kubernetes.io/docs/concepts/architecture/controller/">control loops</a> bring the state of the cluster closer to the desired state by creating or destroying some resources for me automagically.</p>
<p>However, many times I've heard that <a href="https://www.lastweekinaws.com/podcast/screaming-in-the-cloud/the-staying-power-of-kubernetes-with-kelsey-hightower/">the real power of Kubernetes comes with its extensibility</a>. Kubernetes designed for automation. It brings a lot of useful automation out of the box. But it also provides extension points that can be used to customize Kubernetes capabilities. The cleverness of the Kubernetes design is that it encourages you to keep the extensions feel native! So when I stumbled upon the first few Kubernetes Operators on my Ops way, I could not even recognize that I'm dealing with custom logic...</p>
<p>In this article, I'll try to take a closer look at the Operators pattern, see which Kubernetes parts are involved in operators implementation, and what makes operators feel like first-class Kubernetes citizens. Of course, with as many pictures as possible.
<a name="eofcut"></a></p>
<h2 id="kubernetes-objects-and-controllers">Kubernetes Objects and Controllers</h2>
<p>Everything in Kubernetes seems to revolve around <a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/kubernetes-objects/">objects</a> and <a href="https://kubernetes.io/docs/concepts/architecture/controller/">controllers</a>.</p>
<p>Kubernetes objects such as Pods, Namespaces, ConfigMaps, or Events are persistent entities in the Kubernetes system. Kubernetes uses these entities to represent the state of your cluster. Objects are also used as "records of intent." By creating (or removing) objects one can describe the <em>desired</em> state of the Kubernetes cluster.</p>
<p><i>Objects are like data structures.</i></p>
<p>On the other hand, controllers are infinite loops that watch the <em>actual</em> and the <em>desired</em> states of your cluster. When these two states diverge, controllers start making changes aiming to bring the current state of the cluster closer to the desired one.</p>
<p><i>Controllers are like algorithms.</i></p>
<p><img src="https://iximiuz.com/kubernetes-operator-pattern/kube-control-loop-3000-opt.png" width="100%" alt="Kubernetes Control Loop">
</p>

<p>I'll get to the controllers part later in this article and now let's focus on the objects.</p>
<h2 id="kubernetes-api-architecture">Kubernetes API Architecture</h2>
<p>All interactions with Kubernetes objects, <a href="https://kubernetes.io/docs/reference/using-api/client-libraries/">directly</a> or <a href="https://kubernetes.io/docs/reference/kubectl/overview/">indirectly</a>, happen through <a href="https://kubernetes.io/docs/concepts/overview/kubernetes-api/">Kubernetes API</a> - a highly structured masterpiece of software design.</p>
<p>There is a ton of documentation written on Kubernetes API and related topics and I spent quite some time digesting it. Since we are going to talk about the Kubernetes Operator pattern which heavily depends on the capabilities of the Kubernetes API, it's important to familiarize ourselves with the API design principles first. Following is my super-condensed excerpt from the docs.</p>
<p>Kubernetes offers a RESTful declarative HTTP API. Still remember those Kubernetes objects? <a href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/#custom-resources">A collection of objects of a certain kind form an <em>API resource</em></a>:</p>
<blockquote>
<p>A resource is an endpoint in the Kubernetes API that stores a collection of API objects of a certain kind; for example, the built-in pods resource contains a collection of Pod objects.</p>
</blockquote>
<p>You can always check the list of available API resources using <code>kubectl api-resources</code> command:</p>
<pre><code>$ kubectl api-resources
NAME          SHORTNAMES   APIVERSION   NAMESPACED   KIND
namespaces    ns           v1           false        Namespace
nodes         no           v1           false        Node
pods          po           v1           true         Pod
deployments   deploy       apps/v1      true         Deployment
jobs                       batch/v1     true         Job
...</code></pre>
<p>OK, great, we've got resources. But Kubernetes evolves quickly. What if a new attribute needs to be added to an existing resource definition? API versioning is always hard. <i>&lt;speculation mode&gt;</i>Apparently, Kubernetes API started with a common prefix <code>/api/&lt;version&gt;/&lt;resource&gt;</code> for all the API resources. However, a change in a single resource would require a whole API version bump. So, with the growth in the number of available resources, the need for some sort of grouping and subversioning emerged.<i>&lt;/speculation mode&gt;</i></p>
<p>API groups to the rescue! <a href="https://kubernetes.io/docs/concepts/overview/kubernetes-api/#api-groups-and-versioning">A bunch of related resources forms an API group</a>:</p>
<blockquote>
<p>To make it easier to evolve and to extend its API, Kubernetes implements API groups that can be enabled or disabled.</p>
</blockquote>
<p>You can also check the list of available API groups and their versions using <code>kubectl api-versions</code> command:</p>
<pre><code>$ kubectl api-versions
admissionregistration.k8s.io/v1
admissionregistration.k8s.io/v1beta1
apiextensions.k8s.io/v1
apiextensions.k8s.io/v1beta1
apiregistration.k8s.io/v1
apiregistration.k8s.io/v1beta1
apps/v1
...</code></pre>
<p>Well, at this point, I should warn you - it seems that in the documentation, the term <em>resource</em> is often used in the meaning of an <em>object</em> (but not vice versa). So, context matters.</p>
<p>In Kubernetes, objects of the same kind are distinguished by their names. So, if you start two Pods, both should get a unique name. But clusters can be pretty big and since names are supposed to be unique within a cluster, we need a mechanism to prevent collisions. Something like lots of logical clusters within one physical cluster. Allow me to introduce you to <a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/#when-to-use-multiple-namespaces"><em>namespaces</em></a>!</p>
<blockquote>
<p>Kubernetes supports multiple virtual clusters backed by the same physical cluster. These virtual clusters are called namespaces.</p>
</blockquote>
<blockquote>
<p>...</p>
</blockquote>
<blockquote>
<p>Namespaces provide a scope for names. Names of resources need to be unique within a namespace, but not across namespaces. Namespaces cannot be nested inside one another and each Kubernetes resource can only be in one namespace.</p>
</blockquote>
<p>Thus, API objects are fully qualified by their API group, resource type, namespace (unless cluster-scoped), and name.</p>
<p>Have you become totally confused by this time? No, worries, I've got a <del>simple</del> diagram for you 🙈</p>
<div>
    <p><img src="https://iximiuz.com/kubernetes-operator-pattern/kube-api-structure-3000-opt.png" width="100%" alt="Kubernetes API structure"></p><p><i>Kubernetes API structure.</i></p>
</div>

<p>So, a quick summary - we've learned about objects, resources, groups, and namespaces. But what's up with the promised customization?</p>
<h2 id="kubernetes-custom-resources">Kubernetes Custom Resources</h2>
<p>It seems like there is <a href="https://github.com/kubernetes/community/blob/master/sig-api-machinery/README.md">a great deal of effort</a> in keeping the Kubernetes API coherent but extensible.</p>
<p>What do I mean by <em>coherent</em> here? Kubernetes API consists of endpoints called <em>resources</em>. These API resources adhere to a set of common requirements - they are nouns and manipulated in a declarative manner (RESTful CRUD), they should be updated relatively infrequently and be reasonably small in size, their names should be <a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#dns-subdomain-names">valid DNS subdomains</a>, etc.</p>
<p>These restrictions allow unifying the resource workflows. For instance, you can get, describe, or update a collection of Pods in pretty much the same way as a collection of Services, Nodes, or RBAC roles:</p>
<pre><code>$ kubectl get pods
$ kubectl get services
$ kubectl get roles

$ kubectl describe pods  # or services, or roles

$ kubectl edit pods  # or services, or roles</code></pre>
<p>Not only <code>kubectl</code> benefits from this uniformity. Here is a full list of <a href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/#common-features">common features</a> enabled by the unified design:</p>
<div>
    <p><img src="https://iximiuz.com/kubernetes-operator-pattern/kube-api-common-features-3000-opt.png" width="100%" alt="Kubernetes API common features"></p>
</div>

<p>It's pretty handy, isn't it?</p>
<p>So, if I were to extend the API, it'd be reasonable for me to expect that my endpoints would benefit from this common functionality as well. But that would mean that the API extension should be done by adding more resources!</p>
<p>And indeed, in Kubernetes, one can easily register <a href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/#custom-resources"><em>custom resources</em></a>. The procedure is fully dynamic and doesn't require restarting or updating the API server.</p>
<p>How such a custom resource can be added? Well, again, it's Kubernetes! Of course, by interacting with another, already existing resource! There is a special API resource called <a href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/#customresourcedefinitions">CustomResourceDefinition (CRD)</a>:</p>
<blockquote>
<p>The CustomResourceDefinition API resource allows you to define custom resources. Defining a CRD object creates a new custom resource with a name and schema that you specify.</p>
</blockquote>
<p>And <a href="https://kubernetes.io/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions/#create-a-customresourcedefinition">from another documentation page</a>:</p>
<blockquote>
<p>When you create a new CustomResourceDefinition (CRD), the Kubernetes API Server creates a new RESTful resource path for each version you specify.</p>
</blockquote>
<h2 id="how-to-create-custom-resource">How to Create Custom Resource</h2>
<p>Let's try to create a custom resource. Remember, a resource specifies a certain kind of Kubernetes object. Canonically, objects possess some attributes. So, our CustomResourceDefinition should be mostly concerned with describing the attributes of our future resource. Additionally, it's good to know that custom resources can be either namespaced or cluster-scoped. This is specified in the CRD's scope field.</p>
<pre><code>apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  name: blogposts.iximiuz.com
spec:
  group: iximiuz.com
  names:
    kind: BlogPost
    listKind: BlogPostList
    plural: blogposts
    singular: blogpost
  scope: Namespaced
  versions:
  - name: v1alpha1
    schema: ...
...</code></pre>
<details><summary>Click here to see the full CRD's YAML.</summary>
<pre><code>kubectl apply -f - &lt;&lt;EOF
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  name: blogposts.iximiuz.com
spec:
  group: iximiuz.com
  names:
    kind: BlogPost
    listKind: BlogPostList
    plural: blogposts
    singular: blogpost
  scope: Namespaced
  versions:
  - name: v1alpha1
    schema:
      openAPIV3Schema:
        description: BlogPost is a custom resource exemplar
        type: object
        properties:
          apiVersion:
            description: 'APIVersion defines the versioned schema of this representation
              of an object. Servers should convert recognized schemas to the latest
              internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources'
            type: string
          kind:
            description: 'Kind is a string value representing the REST resource this
              object represents. Servers may infer this from the endpoint the client
              submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds'
            type: string
          metadata:
            type: object
          spec:
            description: BlogPostSpec is the spec for a BlogPost resource
            type: object
     …</code></pre></details></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://iximiuz.com/en/posts/kubernetes-operator-pattern">https://iximiuz.com/en/posts/kubernetes-operator-pattern</a></em></p>]]>
            </description>
            <link>https://iximiuz.com/en/posts/kubernetes-operator-pattern</link>
            <guid isPermaLink="false">hacker-news-small-sites-25987069</guid>
            <pubDate>Mon, 01 Feb 2021 09:28:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Does Lossless Compression in Fuji RAF Files Work?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25987013">thread link</a>) | @dsego
<br/>
February 1, 2021 | https://capnfabs.net/posts/fuji-raf-compression-algorithm/ | <a href="https://web.archive.org/web/*/https://capnfabs.net/posts/fuji-raf-compression-algorithm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody" id="content"><p>Oh boy, this is going to be a doozy of a blog post.</p><p>I’ve spent the last three months in New York<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> at the <a href="https://www.recurse.com/">Recurse Center</a>, developing an understanding of the fundamentals of digital photography.</p><p>Something that’s been really, really rewarding about this project is that I’ve been able to take my own images, start with the actual bits in a <a href="https://ridiculousfish.com/hexfiend/">hex editor</a>, and interpret them into images that progressively become more faithful and more beautiful, the more code I write.</p><p>Well, almost. There was one minor hiccup – all of the RAW files I’ve shot over the last 3 years have been encoded with Fuji’s lossless image compression algorithm. This is a fantastic technology as a photographer – 50 MB files are swiftly reduced to 25 MB, with literally no reduction in quality – but if you’re writing your own processor, then you need to decompress the data, and compression algorithms are usually <em>complex</em>.</p><h2 id="when-should-you-implement-something-yourself">When should you implement something yourself?</h2><p>I <em>knew</em> that this was going to be a rabbit hole before I started. I could <em>hear</em> the voice of my former boss saying “Fabian. Do you really need to be doing this?”.</p><p>I’ve written about <a href="https://capnfabs.net/posts/when-do-you-stop-writing/">Yak Shaves before</a>, and in theory I should know better – but, part of what attracted me to the Recurse Center in the first place was it seemed like a place where going down rabbit holes was permitted. Maybe not advised, but definitely permitted. So, in the first week of February, I found myself trying to figure out how Fuji’s lossless image compression technology worked.</p><p>The thing was, I already had the ability to load compressed Fuji RAF files in my software – the excellent, albeit minimally documented, <a href="https://www.libraw.org/">LibRaw</a> project has had support for this since 2016, and my code was initially loading files by binding to LibRaw. At some point, though, I got frustrated with not knowing exactly what was <em>in</em> my RAW file. Libraw is functionally very good, but it doesn’t do a good job of surfacing what its sources are for any given piece of data<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>. One thing led to another, and at some point I’d decided to replace LibRaw with my own code. Which meant I’d need to re-implement Fuji’s lossless compression algorithm, at least for the photos from my specific camera model.</p><h2 id="how-does-it-work">How does it work?</h2><p>Fuji RAF lossless compression can be characterised as an adaptive, differential compression algorithm. Let’s break that down:</p><ul><li><em>Adaptive</em>: the algorithm changes with the data it has processed in the past</li><li><em>Differential</em>: the algorithm is predicated on storing the <em>difference</em> between an ‘expected’ value and the actual value.</li></ul><h2 id="step-1-split-into-stripes">Step 1: Split into stripes</h2><p>First, split the image into a set of vertical stripes. My camera (the Fuji X-T2) uses 8. Each of these stripes is encoded independently (i.e. with separate input, output, and state), which means it’s <em>possible to parallelise the encoding and decoding</em>. This turns out to be super important for performance on modern CPUs – parallelising my decoder resulted in a 6x speedup in user time (on a 4-core hyperthreaded machine).</p><figure><figcaption><p>Splitting the image into vertical stripes</p></figcaption></figure><h2 id="step-2-sensor-data--colored-vector-collation">Step 2: Sensor data → Colored vector collation</h2><p>Now that we’ve split the image into stripes, we can break each stripe down further into <em>lines</em> of nx6 pixels. We’ll take each of those lines, and map their pixels into color vectors. It’s probably easiest to explain this with a diagram:</p><figure><figcaption><p>Mapping Sensor Pixels to Colored Blocks</p></figcaption></figure><p>If you’ve never worked with digital imaging before, you might be surprised that each pixel in a camera sensor <em>only represents one color</em>. The pixels themselves aren’t capable of differentiating between different colors of light, just of counting approximate numbers of photons, so manufacturers usually slap a <a href="https://en.wikipedia.org/wiki/Color_filter_array">Color Filter Array</a> on top to narrow the color range that each pixel responds to.</p><p>We collate the pixels by color because later, we’ll apply a transform that encodes the differences between neighbouring pixels. If the neighbouring pixels all represent the same component color, those differences are smaller, which allows for better compression.</p><p>Now that we’ve got the data collated into solid color blocks, we’re ready to start processing.</p><h2 id="step-3-color-vectors--bits">Step 3: Color vectors → bits</h2><p>Here’s where it gets real interesting. Now that we’ve collected the data into color vectors, we interleave two color vectors and compress them together.</p><p>Let’s use R0 and G0 as our first pair of color-lines. We now need to iterate through each item of R and G, but the order is kinda special:</p><blockquote><p>R[0], G[0], R[2], G[2], R[4], G[4], R[6], G[6], R[1], G[1], R[8], G[8], R[3], G[3], …</p></blockquote><p>We start by iterating through the <em>even</em> slots in R and G. After we’ve done the first 4 of each, we can <em>also</em> start iterating through the odd slots, which will always be 5 positions behind the even slots.</p><p>Here it is again in diagram format:</p><figure><figcaption><p>Iteration Order. Notice that we start jumping back to the odd pixels after we’ve started with the even pixels.</p></figcaption></figure><p>This feels weird, but hold with me, we’ll be able to explain it very soon! I promise.</p><h3 id="making-a-sample-for-a-single-value">Making a sample for a single value</h3><p>Now, the idea for a single value is:</p><ul><li>Figure out an <em>expected value</em> for the cell, by (approximately) taking a weighted average of the <em>already processed values</em> around it</li><li>Compute the difference between the <em>actual</em> value and the expected value</li><li>Encode the difference and send to output</li><li>Adapt the encoding process so that it gives better compression ratios in future.</li></ul><p>Let’s examine each of those steps individually:</p><h3 id="computing-an-expected-value">Computing an expected value</h3><p>Loosely, the expected value of a cell is computed as a weighted average of values around it. What’s vital about this, however, is that these are values that we’ve <em>already processed</em>, because when we’re decoding, we’ll use <em>expected value</em> + <em>difference</em> to compute the output value. The decoder will need to be able to compute the <em>expected value</em>, which means that the encoder can only use values it’s already decoded to compute an expected value.</p><p>The details of this are probably better represented in code, but here’s a visual indication of the cells we’re selecting for the weighted average. For even cells, we select these:</p><figure><figcaption><p>Reference pixels for computing Weighted Average, for <strong>even</strong>-indexed pixels</p></figcaption></figure><p>And for odd cells, it’s these:</p><figure><figcaption><p>Reference pixels for computing Weighted Average, for <strong>odd</strong>-indexed pixels</p></figcaption></figure><p>This reveals a couple of important ordering dependencies:</p><ol><li>Part of the reason why we don’t start iterating on odd cells until we’ve done a bunch of even cells is because we need the even cells to be processed in order to process the odd cells<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>.</li><li>To compute the weighed average for each row, we need the values of the previous two rows.</li></ol><p>The specifics of the weighted average formulas feel <em>pretty</em> esoteric to me. I’m inclined to suggest that engineers within Fuji were trying stuff out to see what gave the best compression ratios across a bunch of different sample images, found something that worked and was low-cost, and baked that in to the format<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup>.</p><h3 id="compute-the-difference">Compute the difference</h3><p>This is straightforward! The difference is simply <code>actual_value - expected_value</code>. 🎉</p><h3 id="encode-the-difference">Encode the difference</h3><p>Because photographic images tend to have big blocks of color, and to change slowly across the image, it’s typically possible to represent the difference from the weighted average in less bits than are required to store the value directly. For an image where every pixel is encoded with 14 bits, we can typically represent the difference between neighbouring pixels with maybe 5 or 6 bits.</p><p>Unfortunately, we can’t simply store the differences and call it ‘done’ – just because the differences are <em>typically</em> low, it doesn’t mean they’re <em>always</em> low, and in order to capture <em>every possible</em> difference from the weighted average, we require the same number of bits as we had to start with. We’re going to need a clever encoding scheme to handle this discrepancy.</p><p>Let’s say that we’ve got a difference of 27 from the expected value. We’ll represent that in binary as:</p><pre><code>11011
</code></pre><p>Now, let’s say that most of the time, it only requires 6 bits to encode the difference between neighbouring pixels. We’d pad the binary number out to 6 bits:</p><pre><code>011011
</code></pre><p>… but we still need to encode whether we should add or subtract from the expected value. So let’s use <a href="https://en.wikipedia.org/wiki/Two%27s_complement">two’s complement</a>. We now need to encode 2x the range of numbers (positive and negative), so we need to add another bit. For our example of adding to the expected value, this just means we need to add another zero at the front:</p><pre><code>0011011
</code></pre><p>If we needed to instead <em>subtract</em> 27, we’d use:</p><pre><code>1100101
</code></pre><p>With this 7-bit scheme, we could encode differences between -128 and +127 from the expected value.</p><h3 id="variable-length-codes">Variable Length Codes</h3><p>So, what should we do if we need to encode a difference <em>outside</em> of this range?</p><p>Let’s say that we need to encode a difference of 300 in our 7-bit scheme. We’ll start by converting to binary, which requires 10 bits as a signed two’s complement integer:</p><pre><code>+300 = 0100101100
</code></pre><p>Now, let’s split on the 7-bit boundary. We know we can store the last 7 bits using the scheme we already have:</p><pre><code>???
|   7-bit fixed width
|   |
010 0101100
</code></pre><p>So we’ve got <code>0b010</code> remaining at the front. That translates to 2 in decimal, which is a pretty small number. It’s worth noting that we’d expect it to be less likely for this overflow to be a 3, and even less likely again for it to be a 4, or 5, or a 6, because in general, we’re expecting the differences to be small.</p><p>This sounds like the perfect candidate for a <a href="https://en.wikipedia.org/wiki/Variable-length_code"><em>variable length code</em></a>. In fact, this is exactly what the algorithm does, converting the ‘2’ prefix into two 0s, followed by a 1:</p><pre><code>     2 zeros
     |  terminating one
     |  |
2 =&gt; 00 1
</code></pre><p>Similarly:</p><pre><code>5 =&gt; 000001
4 =&gt; 00001
3 =&gt; 0001
2 =&gt; 001
1 =&gt; 01
0 =&gt; 1
</code></pre><p>Simple, right? And now, we can encode our difference of 300 as:</p><pre><code>        [variable-length]
        |
        |   [7-bit fixed-length]
        |   |
+300 =&gt; 001 0101100
</code></pre><p>For a difference of +300, we’re still only paying 3 + 7 bits = 10 bits, instead of the usual 14 to encode a full sample.</p><h3 id="when-twos-complement-_isnt_-the-right-tool-for-the-job">When two’s complement <em>isn’t</em> the right tool for the job</h3><p>We’ve made a problem for ourselves now: notice how we effectively ‘dropped’ the leading sign bit when we converted to variable length?</p><p>Consider the encoding of the following …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://capnfabs.net/posts/fuji-raf-compression-algorithm/">https://capnfabs.net/posts/fuji-raf-compression-algorithm/</a></em></p>]]>
            </description>
            <link>https://capnfabs.net/posts/fuji-raf-compression-algorithm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25987013</guid>
            <pubDate>Mon, 01 Feb 2021 09:18:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Player Movement System in “The Witness”]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25986914">thread link</a>) | @obl
<br/>
February 1, 2021 | https://caseymuratori.com/blog_0032 | <a href="https://web.archive.org/web/*/https://caseymuratori.com/blog_0032">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://caseymuratori.com/blog_0032</link>
            <guid isPermaLink="false">hacker-news-small-sites-25986914</guid>
            <pubDate>Mon, 01 Feb 2021 09:03:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[BioNTech's Long-Term Dream: From Coronavirus to a Cancer Vaccine]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25986454">thread link</a>) | @lawrenceyan
<br/>
January 31, 2021 | https://www.spiegel.de/international/world/biontech-s-long-term-dream-from-coronavirus-to-a-cancer-vaccine-a-b136a53d-baee-4b94-b43c-e8c45faa19d1 | <a href="https://web.archive.org/web/*/https://www.spiegel.de/international/world/biontech-s-long-term-dream-from-coronavirus-to-a-cancer-vaccine-a-b136a53d-baee-4b94-b43c-e8c45faa19d1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-article-el="body">
<section data-app-hidden="">


</section>
<section>
<div>
<figure data-component="Image" data-zoom-id="f8bcfbc2-68d7-4aa5-9267-dd1cecafee70" data-settings="{&quot;id&quot;:&quot;cbb1c4fd-65e2-4b2e-acb1-6443bdf20dec&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;f8bcfbc2-68d7-4aa5-9267-dd1cecafee70&quot;}">
<p><span>
<span data-image-el="aspect">
<span>
<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/cbb1c4fd-65e2-4b2e-acb1-6443bdf20dec_w948_r1.77_fpx29.61_fpy54.97.jpg" srcset="https://cdn.prod.www.spiegel.de/images/cbb1c4fd-65e2-4b2e-acb1-6443bdf20dec_w520_r1.77_fpx29.61_fpy54.97.jpg 520w, https://cdn.prod.www.spiegel.de/images/cbb1c4fd-65e2-4b2e-acb1-6443bdf20dec_w948_r1.77_fpx29.61_fpy54.97.jpg 948w" width="948" height="536" sizes="948px" title="A BioNTech laboratory in Mainz, Germany: The company jumped into the race for a coronavirus vaccine essentially overnight." alt="A BioNTech laboratory in Mainz, Germany: The company jumped into the race for a coronavirus vaccine essentially overnight.">
</span>
</span>
</span>

</p>
<figcaption>
<p><strong>A BioNTech laboratory in Mainz, Germany: </strong>The company jumped into the race for a coronavirus vaccine essentially overnight.<br></p>
<span>
Foto: Biontech / dpa
</span>
</figcaption>
</figure>
</div><div>
<p>The timing could hardly have been better. The number of coronavirus infections had risen to a horrific high, as had the number of deaths from the virus, when the news hit global headlines: A new kind of vaccine is 90 percent effective against COVID-19.</p>


<div>
<p>"This data brings us a step closer to a possible solution for the current global pandemic," says Uğur Şahin, medical doctor and CEO of BioNTech, the Mainz-based biotech company that developed the vaccine together with the American pharmaceutical firm Pfizer. The two companies are currently seeking regulatory approval in the United States.</p><p>The breakthrough may not only signify the beginning of the end of the corona crisis -- it could also end up radically changing the entire approach to vaccine development. People receiving serums developed with this technology are injected with a packaged molecule containing a construction blueprint in the form of messenger RNA, or mRNA.</p>
</div>

<div>
<p>These molecules are absorbed by cells in the body, whereupon the mRNA prompts them to produce a specific protein. This protein, though, is "foreign" to the body and is attacked by immune cells -- thus developing immunity.</p><h3>"An Historic Result"</h3><p>Research into the technology has been ongoing for decades due to its potential effectiveness in fighting all kinds of diseases, including cancer. And now, in the fight against the SARS-CoV-2 virus, BioNTech and Pfizer have apparently proven that it works.</p><p>"This is a historic result, the first mRNA vaccine to show interim efficacy," says immunologist Nicholas Jackson of the Coalition for Epidemic Preparedness Innovations, an international alliance for the advancement of vaccine research. If there are no setbacks, Jackson told DER SPIEGEL, "this positive result could drive a new era of effort to apply mRNA technologies towards infectious diseases."</p>
</div>

<p>Norbert Pardi, a research assistant professor at the University of Pennsylvania, agrees. In comments to DER SPIEGEL, he said: "It is fantastic that the mRNA vaccine works so well." Should it prove itself, he believes, "there will very likely be more and more approved mRNA vaccines against cancer and infectious diseases in the coming years."</p>
<section>

</section>
<p>Researchers turned to mRNA technology for the production of vaccines in part because traditional methods are so laborious. Such vaccines are produced using weakened viruses or parts of viruses. For the production of the flu vaccine, for example, 500 million eggs are used each year to breed the influenza virus. Furthermore, this approach has proven ineffective in the battle against certain infectious diseases, such as AIDS or Dengue fever - much less in the production of a vaccine for cancer patients.</p>

<div>
<p>As such, it seemed all the more attractive to program cells in the body to produce the vaccine by introducing mRNA containing the appropriate construction blueprint. Researchers began experimenting with this approach more than three decades ago, injecting foreign mRNA into laboratory animals – which then implemented the blueprint and produced the foreign substance in their muscle cells.</p><h3>A Cancer Vaccine?</h3><p>But after this encouraging start, the field saw few advances for quite some time. The reason: mRNA proved to be extremely instable, often breaking down immediately after being injected into the body or disappearing completely. The goal became that of employing molecular tricks to pack the mRNA in such a way that it could find its way into cells without being damaged. Only in the last 10 years, says Pardi, have technical innovations and research funding transformed mRNA into a "promising therapeutic tool."</p><p>The medical expert Özlem Türeci and her husband Uğur Şahin both participated in that research. The couple was hoping to discover improved methods for treating tumors – and early on, they dreamed of being able to produce a cancer vaccine.</p><p>The basis for that vision: When cancerous tissue begins to grow, abnormal cells that look foreign to the immune system are produced. Türeci and Şahin compared healthy tissue with abnormal tissue from a specific cancer patient and were thus able to find those cells that looked foreign. They then produced mRNA containing a blueprint for precisely these foreign structures. They also improved the mRNA so that it would, in fact, reach the target cells in the body.</p><p>In one study, Türeci and Şahin administered the appropriate mRNA to 13 patients suffering from malignant melanoma, and found that each patient's immune system responded. Eight of them experienced no remission in the 12 to 23 months afterward. The treatment is unable to prevent cancer, but it could help treat it and to prevent metastasis.</p>
</div>
<div>

<div>
<p>Similar results expected for the vaccine produced by Moderna in Cambridge, Massachusetts</p>
</div>

</div>
<div>
<p>The trick is that each patient receives an mDNA that is precisely tailored to the genetic profile of the cancer they are suffering from. These personalized cancer immunotherapies are still considered experimental, but the results of the initial study were so promising that Türeci, Şahin and their team were able to publish their results in July 2017 in <em>Nature</em>, the prominent scientific magazine. Almost two years later, a 52-year-old skin cancer patient in the U.S. received the experimental BioNTech treatment, after which he told <em>Nature</em>: "I was actually witnessing the cancer cells shrinking before my eyes."</p><p>Such statements should always be approached with caution, of course, but these days, dozens of companies and universities are conducting research into the technology. Clinical studies with mRNA vaccines - targeting breast cancer, lung cancer, prostate cancer and colon cancer, among others – are underway. The variety of different kinds of cancer being targeted, mRNA expert Pardi said not long ago, prove that mRNA vaccines can be instrumental in the fight against the disease.</p><h3>1.3 Billion Doses</h3><p>In January, though, Türeci and Şahin jumped into the race for a coronavirus vaccine essentially overnight, once they realized the gravity of the looming pandemic. Inside BioNTech, they slapped together a team that was initially 40-people strong. On the basis of the virus' genetic sequence, that team rapidly developed 20 possible vaccine candidates and began testing them on laboratory animals, narrowing down the field of potential serums. At the same time, BioNTech turned to the pharmaceuticals giant Pfizer with an offer to team up for the clinical study phase.</p><p>More than 43,500 people have thus far taken part in the Phase III study. Some of the participants received two injections of a placebo three weeks apart, with the others receiving the vaccine candidate. Neither the test subjects nor the participating doctors knew who received what. Once a total of 94 of the test subjects came down with COVID-19, the data was analyzed for the first time by independent experts. According to that analysis, the vaccine produced "more than 90 percent" protection, as the press release noted.</p><p>What about the other mRNA vaccines in direct competition with BioNTech? Franz-Werner Haas, CEO of the Tübingen-based biotech firm Curevac, told DER SPIEGEL that his company's vaccine candidate has proven to be safe at all dosage levels tested. The decisive study for approval, he said, will begin before the end of the year. And the biotech company Moderna, located in Cambridge, Massachusetts, says Norbert Pardi, could soon be able to show "similar results" to those produced by BioNTech.</p><p>Until that happens, though, all eyes are on the biotech company in Mainz, the mRNA pioneer. Despite the fact that the vaccine has to be stored and transported at minus 70 degrees Celsius, despite the fact that each dose is to cost almost $20 in the U.S., and despite its efficacy not yet being conclusively proven, the vaccine is sold out through the end of 2021. Every single one of the projected 1.3 billion doses.</p>
<p><span><svg aria-labelledby="title-361b9b5a-db63-4db8-99d4-72686d661cf1" width="10" height="20" viewBox="0 0 10 20" fill="none" xmlns="http://www.w3.org/2000/svg" role="img"><title id="title-361b9b5a-db63-4db8-99d4-72686d661cf1">Icon: Der Spiegel</title><g id="l-s-flag-361b9b5a-db63-4db8-99d4-72686d661cf1"><path id="vector-361b9b5a-db63-4db8-99d4-72686d661cf1" d="M9.85 16.293v-8H3.212V4.667h3.533v2.24h3.212v-3.2C9.85 2.747 8.993 2 8.03 2H1.713C.749 2 0 2.747 0 3.707v7.253h6.638v4.373H3.105v-2.986H0v3.84c0 .96.75 1.706 1.713 1.706H8.03c.963.107 1.82-.64 1.82-1.6z" fill="#000"></path></g></svg>
</span>
</p></div>
</div>
</section>

</div></div>]]>
            </description>
            <link>https://www.spiegel.de/international/world/biontech-s-long-term-dream-from-coronavirus-to-a-cancer-vaccine-a-b136a53d-baee-4b94-b43c-e8c45faa19d1</link>
            <guid isPermaLink="false">hacker-news-small-sites-25986454</guid>
            <pubDate>Mon, 01 Feb 2021 07:34:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Case Against Fauci]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 15 (<a href="https://news.ycombinator.com/item?id=25986443">thread link</a>) | @andrewon
<br/>
January 31, 2021 | https://www.thedriftmag.com/the-case-against-fauci/ | <a href="https://web.archive.org/web/*/https://www.thedriftmag.com/the-case-against-fauci/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p><strong>T</strong><span>here is no one in American government — or perhaps any government — quite like Dr. Anthony Fauci. His position, with its mixture of informal power and public visibility, scientific authority and beltway influence, is sui generis. Few other unconfirmed civil servants have access to as many rooms in the executive interagency; no public official commands as much respect in the world of science and medicine. As director of the National Institute of Allergy and Infectious Diseases (NIAID) since 1984, he has advised six presidents (and now a seventh) on domestic and global health issues — HIV/AIDS, SARS, Ebola, Zika, and MERS — and overseen decades of research on infectious disease, pandemics, and virology. Under his stewardship, NIAID’s mission has been reshaped around his personage: its priorities are </span><i><span>his</span></i><span> priorities, its research agenda is </span><i><span>his</span></i><span> research agenda. And that agenda has borne fruit: breakthrough treatments for HIV and other deadly diseases and now, a vaccine for Covid-19. As Stanford microbiologist David Relman told </span><i><span>The</span></i> <i><span>New Yorker</span></i><span> in April, “Tony has essentially become the embodiment of the biomedical and public-health research enterprise in the United States.”</span></p>
<p><span>Although Fauci has no statutory authority to preside over a public health crisis, he has become the nation’s de facto Doctor-in-Chief during this pandemic. His face — elven and expressive — is the face of the medical establishment’s response to the novel coronavirus. I doubt most Americans can name the (</span><a href="https://www.washingtonpost.com/us-policy/2021/01/20/biden-surgeon-general-resignation/" target="_blank" rel="noopener noreferrer"><span>outgoing</span></a><span>) U.S. Surgeon General, CDC Director, or Fauci’s nominal boss, the director of the National Institutes of Health (Jerome Adams, Robert Redfield, and Francis Collins, respectively), but everyone knows Dr. Fauci. His plaintive but never pessimistic patter and disarming outer-borough rasp are soothing sonic features of our daily dirge of death, doom, and statistics. I was relieved when I first saw Fauci on TV — sometime in March 2020 — thinking dimly to myself, for the millionth time, “Ah, an adult in the room.” Amid a ceaseless current of chaos and grief, Fauci’s egoless display of competence, his grandfatherly warmth and irony, were ports in a storm.&nbsp;</span></p>
<p><span>But a comforting bedside manner has done little to mitigate catastrophe. Over 400,000 Americans are dead, twice as many as any other country. Infections, hospitalizations, and deaths are currently at record highs. And although we have a vaccine, the rollout has already been stymied by a dearth of resources and coordination. As one public health expert told <em>The </em></span><i><span>New York Times </span></i><span>on January 17</span><i><span>,</span></i><span> our pandemic response has been “a colossal failure at every level of government.” And herein lies a paradox. America is suffering from a disease outbreak whose morbid scope is the consequence of world-historic negligence. We are desperately and needlessly sick. And yet, the man known as “America’s Doctor,” the undisputed personification of public health research and pandemic preparedness, faces no reputational consequences. On the contrary, Dr. Fauci remains one of our most beloved public figures.&nbsp;&nbsp;</span></p>
<p><span>What explains this? Liberals, who otherwise harshly condemn the federal government’s pandemic response, are especially besotted with the diminutive virologist. For fans of the #Resistance, a well-timed </span><a href="https://www.businessinsider.com/dr-anthony-fauci-did-a-facepalm-during-trumps-coronavirus-briefing-2020-3" target="_blank" rel="noopener noreferrer"><span>facepalm</span></a><span> during one of the Mad King’s early soliloquies guaranteed Fauci’s place on a Mount Rushmore of replacement patriarchs, alongside James Comey and Robert Mueller. (Fauci later insisted the gesture was innocuous; he was merely obscuring his face to dislodge a lozenge from his throat.) Still, Democrats’ devotion has never waned. They see in Fauci a lonely champion of “truth” and “facts” in a White House otherwise hostile to “science.” Brad Pitt earned an Emmy nomination for portraying the 80-year-old physician on Saturday Night Live. One Hamilton-inspired TikTok (“My name is Dr. Anthony Fau-CHEE…”) went viral. Just since the beginning of the “third wave” of Covid infections in October, Fauci has received leadership awards from the National Academy of Medicine, the FBI Agents Association, the Arthur Ashe Institute for Urban Health, and the Boy Scouts of America. Joe Biden has </span><a href="https://www.cnn.com/2020/12/03/politics/anthony-fauci-biden-transition/index.html" target="_blank" rel="noopener noreferrer"><span>asked</span></a><span> Fauci to stay on at NIAID and serve in his administration as a chief medical advisor. D.C. Mayor Muriel Bowser proclaimed “Anthony S. Fauci Day” on December 24.&nbsp;</span></p>
<p><span>Fauci’s celebrity, however, cannot obscure empirical reality. As America’s Doctor would surely agree, the numbers don’t lie: 2,824 Americans died of Covid-19 on Anthony S. Fauci Day.&nbsp;</span></p>
<p><span>Anthony Fauci is no doubt a dedicated public servant, respected by his colleagues, beloved by many Americans. But the puzzle remains: why has the man most closely associated with the public health response to the pandemic entirely avoided accountability for its failure?&nbsp;</span></p>

<p><strong>F</strong><span>irst, the most straightforward defense: it wasn’t his fault. He did the best he could, but Fauci’s better instincts were thwarted by Trump and his coterie of idiots. Of course, there’s truth in this. The uneasy peace between Trump and his medical advisors started to unravel almost before it began. By the end of March, Trump was sweating the stocks and tweeting that the “cure” must not be worse “than the problem itself.” He clashed with Fauci throughout the spring — over masks, hydroxychloroquine, school openings, and Easter. By summer, Trump was publicly lambasting the good doctor, leaking anti-Fauci talking points to the press and sidelining him in task force meetings, which were themselves increasingly rare. Scott Atlas, the libertarian radiologist and herd-immunity advocate whom Trump hired based on his Fox News appearances, was calling the shots.</span></p>
<p><span>But Fauci seldom contradicted the president’s lies outright, opting for tact and de-escalation instead. “I can’t jump in front of the microphone and push him down,” Fauci </span><a href="https://www.theguardian.com/world/2020/mar/23/dr-fauci-press-conference-white-house-coronavirus" target="_blank" rel="noopener noreferrer"><span>said</span></a><span> in late March. “OK, he said it. Let’s try and get it corrected for the next time.” On July 4, Trump said 99 percent of Covid cases were “harmless.” Fauci characterized this as a misinterpretation. (“I’m trying to figure out where the president got that number…” he said.) Though Fauci has a reputation for bluntness, as the </span><i><span>Financial Times</span></i><span>’s Hannah Kuchler </span><a href="https://www.ft.com/content/57834c2c-a078-4736-9173-8fb32cfbbf4e" target="_blank" rel="noopener noreferrer"><span>observed</span></a><span>, “he clearly also tries to hold back, believing he will make a bigger difference to the course of the pandemic if he keeps his job.”</span></p>
<p><span>This logic pervades the most common defense of Fauci’s record. “Tony is unique, in that he has such credibility with politicians that he’s been able to insert hard facts into the conversation,” Nobel laureate biologist David Baltimore told </span><i><span>The</span></i> <i><span>New Yorker</span></i><span> in April. “That has been wonderful for our country and the world.” In this view, Fauci was </span><i><span>handling</span></i><span> Trump, just as he handled previous presidents, including a reluctant Ronald Reagan during the AIDS epidemic. When he pulls his punches, it’s always for the greater good; namely, the cause of remaining in the room. Stepping too far out of line, contradicting Trump with too much vigor, would have imperiled his standing. “The argument for Fauci saying more,” </span><a href="https://www.washingtonpost.com/opinions/2020/07/16/anthony-fauci-built-truce-trump-is-destroying-it/?arc404=true" target="_blank" rel="noopener noreferrer"><span>wrote</span></a><span> Molly Roberts in <em>The</em> </span><i><span>Washington Post</span></i><span>, “… is also an argument for self-exile.” And then what? Truth and facts would have had no advocate inside the White House. As Fauci himself </span><a href="https://www.nytimes.com/2021/01/24/health/fauci-trump-covid.html?action=click&amp;module=Top%20Stories&amp;pgtype=Homepage" target="_blank" rel="noopener noreferrer"><span>told</span></a><span> the </span><i><span>Times</span></i><span> on Sunday, “I felt that if I stepped down, that would leave a void. Someone’s got to not be afraid to speak out the truth.”</span></p>
<p><span>At a briefing in July, Trump </span><a href="https://www.cnn.com/2020/07/28/politics/donald-trump-anthony-fauci-approval-rating/index.html" target="_blank" rel="noopener noreferrer"><span>mused</span></a><span>, “It’s interesting: [Fauci’s] got a very good approval rating. And I like that, it’s good. Because remember, he’s working for this administration. He’s working with us.” Winding his way to his point, Trump said, “So why don’t I have a high approval rating… with respect to the virus?” After a pause, he deadpanned, “It can only be my personality, that’s all.”&nbsp;</span></p>
<p><span>As is often the case with Trump, he had a point, just not the one he meant. The liberal apologia for Fauci </span><i><span>was</span></i><span> internally contradictory. As one scientist said to me, “We can’t deify Fauci’s response to the pandemic as fantastic while simultaneously condemning Trump, when for months, the two were hand in hand.” Indeed, Fauci is only blameless if he was utterly powerless to stop the administration’s disastrous plans. And if he </span><i><span>was</span></i><span> powerless, he should’ve resigned and communicated the truth bluntly to the public long ago. Otherwise, he knowingly lent credibility to an abject failure he couldn’t control.&nbsp;</span></p>
<p><span>To put an even finer point on it, the precise conditions that would maximally exonerate Fauci — i.e., Trump is solely at fault; Fauci had no influence — are conditions under which Fauci </span><i><span>absolutely </span></i><span>should have bolted. The more aberrant Trump’s behavior, the more he diverged from the medically prudent course of action, the greater Fauci’s responsibility to leave and blow the whistle. If Fauci knew better but didn’t say, what use was he inside the room? If he </span><i><span>didn’t</span></i><span> know better, then he shares the blame.&nbsp;</span></p>
<p><span>In recent days, Fauci and Covid task force coordinator Dr. Deborah Birx — another veteran AIDS researcher who’s received slightly </span><a href="https://www.politico.com/news/2020/11/18/biden-coronavirus-team-deborah-birx-437923" target="_blank" rel="noopener noreferrer"><span>less deferential</span></a><span> treatment from the media than her male counterpart — have undertaken a goodwill tour. Birx </span><a href="https://twitter.com/FaceTheNation/status/1353332977560735744?s=20" target="_blank" rel="noopener noreferrer"><span>told</span></a><span> CBS that denialists in the White House “derailed” the pandemic response, putting out information she knew to be false. Fauci joked with Rachel Maddow that Trump had </span><a href="https://www.msnbc.com/rachel-maddow/watch/fauci-to-maddow-i-ve-been-wanting-to-come-on-your-show-for-months-and-months-99905093921" target="_blank" rel="noopener noreferrer"><span>forbidden</span></a><span>&nbsp;him from coming on her show and </span><a href="https://www.usatoday.com/story/news/politics/2021/01/21/anthony-fauci-speaking-covid-liberating-under-biden-vs-trump/4244169001/" target="_blank" rel="noopener noreferrer"><span>told</span></a><span> the White House press corps, “The idea that you can get up here and… let the science speak, it is somewhat of a liberating feeling.” Meanwhile, liberal pundits like Ezra Klein have </span><a href="https://www.nytimes.com/2021/01/18/opinion/biden-covid-19-plan.html" target="_blank" rel="noopener noreferrer"><span>praised</span></a><span> Biden’s “maddeningly obvious” Covid plans, describing their simplicity as a “damning indictment” of Trump’s negligence. But if Biden’s life-saving interventions are so straightforward and crucial, why weren’t Fauci and Birx loudly demanding them months ago?&nbsp;</span></p>
<p><span>“To keep their jobs” should not be a satisfying answer — not for the living or for the dead.&nbsp;</span></p>

<p><strong>F</strong><span>rank assessments of Fauci’s performance are hard to come by. Those in a position to judge him from an informed public …</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.thedriftmag.com/the-case-against-fauci/">https://www.thedriftmag.com/the-case-against-fauci/</a></em></p>]]>
            </description>
            <link>https://www.thedriftmag.com/the-case-against-fauci/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25986443</guid>
            <pubDate>Mon, 01 Feb 2021 07:30:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Element suspended on Google Play Store: now resolved]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25986438">thread link</a>) | @sjamaan
<br/>
January 31, 2021 | https://element.io/blog/element-on-google-play-store/ | <a href="https://web.archive.org/web/*/https://element.io/blog/element-on-google-play-store/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
      
      <div><p>Hi all,</p><p>At 2021-01-29 at 21:35 UTC Google suspended Element from the Play Store without warning or notification. &nbsp;We submitted an appeal asking for clarification at 23:18, and at 05:31 received a generic update from the Google Play Policy team citing that the app has been removed due to content which contravenes their terms of use, and asking us to “make the necessary changes to [our] app” and “upload a new app using a new package name and a new app name”.</p><p>As of 11:44 UTC we’ve submitted a detailed appeal to reiterate that Element is a generic chat app for connecting to the global Matrix communication network, just as Chrome is a generic web browser for connecting to the Web - and just as Google does not control the content on the Web, Element does not control the content on Matrix.</p><p>We have also explained that the Matrix servers that we <em>do</em> run as Element (including the default Matrix.org homeserver, which we run on behalf of <a href="https://matrix.org/foundation">The Matrix.org Foundation</a>) have <a href="https://matrix.org/legal/terms-and-conditions#6-play-nice-clauses">strict Terms of Use</a> which we actively enforce. We abhor abuse, and Element is not an app that caters to abusive content.</p><p>In order to enforce our terms of use on the Matrix servers we run as Element, we have a formal Trust and Safety team hired full-time who are dedicated to investigating and tracking abuse reports sent to <a href="https://element.io/cdn-cgi/l/email-protection#1b7a796e687e5b767a6f6972633574697c"><span data-cfemail="d4b5b6a1a7b194b9b5a0a6bdacfabba6b3">[email&nbsp;protected]</span></a> or reported from the app. &nbsp;The team takes appropriate action on a ticket by ticket basis - deactivating abusive accounts and blocking chatrooms from our servers which contravene our terms of use, and building tooling to help enforce the terms of use on the servers we run.</p><p>Managing abuse is an ongoing activity, and <a href="https://sifted.eu/articles/element-whatsapp-exodus/">Matrix is expanding massively at the moment</a>. We are expanding Element’s Trust and Safety team to match that growth, focusing on improving our anti-abuse mechanisms, and we are also constantly expanding the <a href="https://matrix.org/docs/guides/moderation/">moderation tools</a> we provide to the community.</p><p>Meanwhile, we’re also continuing to work on decentralised reputation as a <a href="https://matrix.org/blog/2020/10/19/combating-abuse-in-matrix-without-backdoors/">scalable solution to empower other users to combat abuse</a> for the wider Matrix network - effectively bringing control back to users and empowering communities to remain safe online.</p><p>Element and Matrix are used by the French, German, UK and US governments, <a href="https://matrix.org/blog/2021/01/29/this-week-in-matrix-2021-01-29#dept-of-status-of-matrix-%EF%B8%8F">countless universities</a>, thousands of businesses and millions of people across the world - we can only apologise for the disruption caused by the app disappearing like this.</p><p>We’re currently waiting for an update to Google and will keep this blog post updated as the situation develops. &nbsp;We look forward to resolving the problem and getting the app back in the store shortly.</p><p>-- The Element Team</p><p>Update: reminder that in the interim you can download a (slightly outdated) version of Element Android from F-Droid at <a href="https://f-droid.org/en/packages/im.vector.app/">https://f-droid.org/en/packages/im.vector.app</a>. &nbsp;We're also looking into running our own F-Droid repository going forwards so the most recent build is always available there.</p><p>UPDATE: At 2021-01-30 23:17 UTC we received a call from a VP at Google who apologised for the bad communication from Google and explained the situation, which related to some extremely abusive content which was accessible on the default matrix.org homeserver. &nbsp;Our Trust and Safety team had already identified and acted on this content to enforce the server's terms of use, and so we've explained how Element and Matrix works, established a channel for communication over any future moderation concerns, and expect the app to be restored shortly.</p><p>UPDATE: The app is restored as of 2021-01-31 00:30 UTC. &nbsp;Huge thanks to everyone for your patience and support while we sorted this out, and to the wider Element team who spent their Saturday on this. &nbsp;Thanks also to Google for being transparent and apologetic and the rapid resolution once we'd established contact.</p></div>
      
    </div>
  </div></div>]]>
            </description>
            <link>https://element.io/blog/element-on-google-play-store/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25986438</guid>
            <pubDate>Mon, 01 Feb 2021 07:29:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[gemini:// space]]>
            </title>
            <description>
<![CDATA[
Score 271 | Comments 166 (<a href="https://news.ycombinator.com/item?id=25986378">thread link</a>) | @pabs3
<br/>
January 31, 2021 | https://spwhitton.name//blog/entry/geminispace/ | <a href="https://web.archive.org/web/*/https://spwhitton.name//blog/entry/geminispace/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">







<div id="pagebody">

<div id="content">
<p>Recently I have become curious about <a href="https://gemini.circumlunar.space/">the Gemini
Project</a> and the content that people have
made available to be retrieved over the gemini:// protocol.  I’m not convinced
by the arguments for not just using http, and mostly it’s just that I
typically find more things that I am interested in casually reading through on
people’s gemlogs than I would on, say, reddit, and similar aggregators.  But
presumably advocates of gemini:// and the text/gemini format would argue that
it’s various respects in which it differs from the web that makes geminispace
conducive to the production of the sort of content you find there.  So I’m
remaining open minded about the possibility that having a completely separate
protocol is important, and not just an annoyance because rss2email doesn’t
work and I had to spend time writing
<a href="https://manpages.debian.org/gmi2email">gmi2email</a>.</p>

<p>I now have a games console at home for the first time in some years, which I
bought in response to the ongoing pandemic, and one thing that I have noticed
is that using it feels like being offline in a way that playing games on a
regular computer never would.  It has a WiFi connection but it doesn’t have a
web browser, and I am glad that using it provides an opportunity to be
disconnected from the usual streams of information.  And perhaps something
similar ought to be said in favour of how the Gemini project does not just use
http.  There is, perhaps, a positive psychological effect induced by making
the boundary between text/gemini and the web as hard as it is made by using
gemini:// rather than http.</p>

<p>Something about which I find myself much more sceptical is how the
specification for gemini:// and text/gemini is not extensible.  Advocates of
Gemini have this idea that they can’t include, say, a version number in the
protocol, because the extensibility of the web is what has led to the problems
they think it has, so they want to make it impossible.  Now on the one hand
perhaps the people behind Gemini are in the best position that anyone is in to
come up with a spec which they will finalise and render effectively
unchangeable, because a lot of them have been using Gopher for decades, and so
they have enough experience to be able to say exactly what Gopher is missing,
and be confident that they’ve not missed anything.  But on the other hand,
Gemini is one technological piece in attempts to make a version of the
Internet which is healthier for humans – the so-called “small Internet”
movement – and maybe there will be new ideas about how the small Internet
should be which would benefit from a new version of the Gemini specification.
So it seems risky to lock-in to one version.</p>

<p><a href="https://news.ycombinator.com/item?id=25986378">Comments on Hacker News</a>.</p>

</div>









</div>



</div></div>]]>
            </description>
            <link>https://spwhitton.name//blog/entry/geminispace/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25986378</guid>
            <pubDate>Mon, 01 Feb 2021 07:14:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cloud Computing Explained: Public vs. Private vs. Virtual Private]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25986359">thread link</a>) | @recepinancc
<br/>
January 31, 2021 | https://recepinanc.com/cloud-computing-explained-public-vs.-private-vs.-virtual-private/ | <a href="https://web.archive.org/web/*/https://recepinanc.com/cloud-computing-explained-public-vs.-private-vs.-virtual-private/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="text">
        
        <p>Let’s talk about cloud in simpler terms!</p>

<p>Coming across different terms about a technology without actually getting your head around what they meant is a common issue. Recently, I decided to study Cloud Computing and I wanted start by learning the terminology and then diving deeper into the specific topics.</p>

<p>With the first post of the “Cloud Computing Explained” series, we will look at a small but commonly used subset of cloud terms:</p>
<ul>
  <li>Public Cloud</li>
  <li>Private Cloud</li>
  <li>Virtual Private Cloud</li>
</ul>

<p>Let’s first look at the definitions, and then create an analogy to make them easy to remember!</p>



<p>A Public Cloud is a set of cloud services provided to you and other customers by a vendor.</p>

<p>The Public Cloud enables us to provision resources on-demand according to our needs. There are many different vendors for public cloud services that offer you variant solutions based on your needs to build your software.</p>

<p>As these solutions’ levels <strong>go down</strong>, it gives you <strong>more control over the resource</strong>. However, this also means more <strong>overhead</strong> since you’ll have more things to do for that resource to be working reliably.</p>

<p>And one of the tremendous benefits of the public cloud is that you only pay for what you use. That gives you the ability to <strong>optimize your expenses</strong>.</p>

<h2 id="different-levels-of-services">Different Levels of Services</h2>

<p>Take a look at the below diagram to visualize solutions at different levels. At the lowest level (bare-metal), you are the most flexible since you got all the control over your system. However, you also have to deal with almost everything by yourself, including scaling, monitoring and, deployment. On the highest level (Serverless, FaaS), you can concentrate solely on writing your application. You give up some of the flexibility for more convenience.</p>

<figure>
  <img src="https://recepinanc.com/assets/images/content/different_levels_of_abstraction.png" alt="Different levels of cloud service abstractions"><figcaption>
      By Nate Schutta (Developer Advocate, Pivotal) at SpringOne Platform 2018

    </figcaption></figure>



<p>The Private Cloud is having a public cloud environment on the infrastructure that is <strong>dedicated to you</strong>.</p>

<p>That brings the disadvantage of being limited by <strong>your infrastructure’s limits</strong> and the advantage of having <strong>no other neighbors to share your resources</strong>.</p>



<p>A Virtual Private Cloud is where a public cloud’s resources are divided into <strong>virtually isolated</strong> divisions - “private clouds”.</p>

<p>Isolating each division from each other creates the illusion of customers have their private cloud - but it’s only there virtually. Virtual Private Clouds are similar to virtual machines where there are no actual physical machines but only the isolation of resources.</p>

<p>Virtual Private Clouds are a type of Hybrid Clouds. Virtual Private Clouds are a type of <a href="https://www.redhat.com/en/topics/cloud-computing/what-is-hybrid-cloud">Hybrid Clouds</a>.</p>

<figure>
  <img src="https://recepinanc.com/assets/images/content/different_clouds.png" alt="Different Cloud Types Visualization"><figcaption>
      Different Cloud Types Visualization

    </figcaption></figure>



<p>Imagine the <strong>public cloud</strong> as an internet cafe where they have these computers and charge you for the time you use them. In that case, the internet cafe is the <strong>vendor</strong> (in real life, this could be Amazon, Google, Microsoft, etc.). When you go and there and ask for a computer, they start your session on one of the available computers in the public area with others, using the same underlying infrastructure.</p>

<p>The private gaming rooms, in which they provide you an isolated internet connection from the ones in the public area and the other private gaming rooms. These rooms can be an analogy for <strong>virtual private clouds</strong>.</p>

<p>Let’s say this internet cafe vendor provides you the service to build one of these private gaming rooms at your house. They use your house’s infrastructure but with their computers and all the software in it. That would be the equivalent of a <strong>private cloud</strong>.</p>



<ul>
  <li><a href="https://azure.microsoft.com/en-us/overview/what-are-private-public-hybrid-clouds/">https://azure.microsoft.com/en-us/overview/what-are-private-public-hybrid-clouds/</a></li>
  <li><a href="https://www.cloudflare.com/learning/cloud/what-is-a-public-cloud/">https://www.cloudflare.com/learning/cloud/what-is-a-public-cloud/</a></li>
  <li><a href="https://www.cloudflare.com/learning/cloud/what-is-a-virtual-private-cloud/">https://www.cloudflare.com/learning/cloud/what-is-a-virtual-private-cloud/</a></li>
  <li><a href="https://www.redhat.com/en/topics/cloud-computing/what-is-public-cloud">https://www.redhat.com/en/topics/cloud-computing/what-is-public-cloud</a></li>
  <li><a href="https://www.redhat.com/en/topics/cloud-computing/public-cloud-vs-private-cloud-and-hybrid-cloud">https://www.redhat.com/en/topics/cloud-computing/public-cloud-vs-private-cloud-and-hybrid-cloud</a></li>
  <li><a href="https://www.youtube.com/watch?v=8tOj4A7jgWg">https://www.youtube.com/watch?v=8tOj4A7jgWg</a></li>
</ul>

        
      </section></div>]]>
            </description>
            <link>https://recepinanc.com/cloud-computing-explained-public-vs.-private-vs.-virtual-private/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25986359</guid>
            <pubDate>Mon, 01 Feb 2021 07:11:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Counterfeiting Stock – Explaining illegal naked shorting and stock manipulation]]>
            </title>
            <description>
<![CDATA[
Score 334 | Comments 386 (<a href="https://news.ycombinator.com/item?id=25986320">thread link</a>) | @lelf
<br/>
January 31, 2021 | http://counterfeitingstock.com/CS2.0/CounterfeitingStock.html | <a href="https://web.archive.org/web/*/http://counterfeitingstock.com/CS2.0/CounterfeitingStock.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<center><b>Counterfeiting Stock 2.0</b></center>

<p>
Illegal naked shorting and stock manipulation are two of Wall Street's deep, dark secrets. These practices have been around for decades and have resulted in trillions of dollars being fleeced from the American public by Wall Street. In the process, many emerging companies have been put out of business. This report will explain the magnitude of this problem, how it happens, why it has been covered up and how short sellers attack a company. It will also show how all of the participants; the short hedge funds, the prime brokers and the Depository Trust Clearing Corp. (DTCC)—make unconscionable profits while the fleecing of the small American investor continues unabated.
</p>
<p>
<span>Why is This Important?</span> This problem affects the investing public. Whether invested directly in the stock market or in mutual funds, IRAs, retirement or pension plans that hold stock — it touches the majority of Americans.
</p>
<p>
The participants in this fraud, which, when fully exposed, will make Enron look like child's play, have been very successful in maintaining a veil of secrecy and impenetrability. Congress and the SEC have unknowingly (?) helped keep the closet door closed. The public rarely knows when its pocket is being picked as unexplained drops in stock price get chalked up to “market forces” when they are often market manipulations.
</p>
<p>
The stocks most frequently targeted are those of emerging companies who went to the stock market to raise start–up capital. Small business brings the vast majority of innovative new ideas and products to market and creates the majority of new jobs in the United States. It is estimated that over 1000 of these emerging companies have been put into bankruptcy or had their stock driven to pennies by predatory short sellers. 
</p>
<p>
It is important to understand that selling a stock short is not an investment in American enterprise. A short seller makes money when the stock price goes down and that money comes solely from investors who have purchased the company's stock. A successful short manipulation takes money from investment in American enterprise and diverts it to feed Wall Street's insatiable greed—the company that was attacked is worse off and the investing public has lost money. Frequently this profit is diverted to off–shore tax havens and no taxes are paid. This national disgrace is a parasite on the greatest capital market in the world.
</p>
<p>
<span>A Glossary of Illogical Terms</span> — The securities industry has its own jargon, laws and practices that may require explaining. Most of these concepts are the creation of the industry, and, while they are promoted as practices that ensure an orderly market, they are also exploited as manipulative tools. This glossary is limited to naked short abuse, or counterfeiting stock as it is more correctly referred to. 
</p>

<ol>
<li><b>Broker Dealer or Prime Broker</b> — The big stockbrokers who clear their own transactions, which is to say they move transacted shares between their customers directly, or with the DTC. Small brokers will clear through a clearing house — also known as a broker's broker.
</li>
<li><b>Hedge Funds</b> — Hedge funds are really unregulated investment pools for rich investors. They have grown exponentially in the past decade and now number over 10,000 and manage over one trillion dollars. They don't register with the SEC, are virtually unregulated and frequently foreign domiciled, yet they are allowed to be market makers with access to all of the naked shorting loopholes. Frequently they operate secretively and collusively. The prime brokers cater to the hedge funds and allegedly receive eight to ten billion dollars annually in fees and charges relating to stock lend to the short hedge funds.
</li>
<li><b>Market Maker</b> — A broker, broker dealer or hedge fund who makes a market in a stock. In order to be a market maker, they must always have shares available to buy and sell. Market makers get certain sweeping exemptions from SEC rules involving naked shorting.
</li>
<li><b>Short Seller</b> — An individual, hedge fund, broker or institution who sells stock short. The group of short sellers is referred to as “the shorts.”
</li>
<li><b>The Securities and Exchange Commission</b> — The SEC is the federal enforcement agency that oversees the securities markets. The top–level management is a five–person Board of Governors who are Presidential appointees. Three of the governors are usually from the securities industry, including the chairman. The SEC adopted Regulation SHO in January 2005 in an attempt to curb naked short abuse.
</li>
<li><b>Depository Trust Clearing Corp</b> — Usually known as the DTCC, this privately held company is owned by the prime brokers and it clears, transacts and holds most stock in this country. It has four subsidiaries, which include the DTC and the NCSS. The operation of this company is described in detail later.
</li>
<li><b>Short Sale</b> — Selling a stock short is a way to make a profit while the stock price declines. For example: If investor S wishes to sell short, he borrows a share from the account of investor L. Investor S immediately sells that share on the open market, so investor S now has the cash from the sale in his account, and investor L has an IOU for the share from investor S. When the stock price drops, investor S takes some of the money from his account and buys a share, called “covering”, which he returns to investor L's account. Investor S books a profit and investor L has his share back.
<p>This relatively simple process is perfectly legal—so far. The investor lending the share most likely doesn't even know the share left his account, since it is all electronic and occurs at the prime broker or DTC level. If shares are in a margin account, they may be loaned to a short without the consent or knowledge of the account owner. If the shares are in a cash account, IRA account or are restricted shares they are not supposed to be borrowed unless there is express consent by the account owner.
</p></li>
<li><b>Disclosed Short</b> — When the share has been borrowed or a suitable share has been located that can be borrowed, it is a disclosed short. Shorts are either naked or disclosed, but, in reality, some disclosed shorts are really naked shorts as a result of fraudulent stock borrowing. 
</li>
<li><b>Naked Short</b> — This is an invention of the securities industry that is a license to create counterfeit shares. In the context of this document, a share created that has the effect of increasing the number of shares that are in the market place beyond the number issued by the company, is considered counterfeit. This is not a legal conclusion, since some shares we consider counterfeit are legal based upon today's rules. The alleged justification for naked shorting is to insure an orderly and smooth market, but all too often it is used to create a virtually unlimited supply of counterfeit shares, which leads to widespread stock manipulation—the lynchpin of this massive fraud. 
<p>
Returning to our example, everything is the same except the part about borrowing the share from someone else's account: There is no borrowed share — instead a new one is created by either the broker dealer or the DTC. Without a borrowed share behind the short sale, a naked short is really a counterfeit share.
</p></li>
<li><b>Fails–to–Deliver</b> — The process of creating shares via naked shorting creates an obvious imbalance in the market as the sell side is artificially increased with naked short shares or more accurately, counterfeit shares. Time limits are imposed that dictate how long the sold share can be naked. For a stock market investor or trader, that time limit is three days. According to SEC rules, if the broker dealer has not located a share to borrow, they are supposed to take cash in the short account and purchase a share in the open market. This is called a “buy–in,” and it is supposed to maintain the total number of shares in the market place equal to the number of shares the company has issued.
<p>
Market makers have special exemptions from the rules: they are allowed to carry a naked short for up to twenty–one trading days before they have to borrow a share. When the share is not borrowed in the allotted time and a buy–in does not occur, and they rarely do, the naked short becomes a fail–to–deliver (of the borrowed share).
</p></li>
<li><b>Options</b> — The stock market also has separate, but related markets that sell options to purchase shares (a “call”) and options to sell shares (a “put”). Options are an integral part of short manipulations, the result of SEC promulgated loopholes in Reg SHO. A call works as follows: Assume investor L has a share in his account that is worth $25. He may sell an option to purchase that share to a third party. That option will be at a specific price, say $30, and expires at a specific future date. Investor L will get some cash from selling this option. If at the expiration date, the market value of the stock is below $30 (the “strike price”), the option expires as worthless and investor L keeps the option payment. This is called “out of the money.” If the market value of the stock is above the strike price, then the buyer of the option “calls” the stock. Assume the stock has risen to $40. The option buyer tenders $30 to investor L and demands delivery of the share, which he may keep or immediately sell for a $10 profit.
</li>
<li><b>Naked call</b> — The same as above except that investor L, who sells the call, has no shares in his account. In other words, he is selling an option on something he does not own. The SEC allows this. SEC rules also allow the seller of a naked short to treat the purchase of a naked call as a borrowed share, thereby keeping their naked short off the SEC's fails–to–deliver list. A share of stock that has a naked call as its borrowed shares is marked as a disclosed short when it is sold, even though nobody in the transaction actually owns a share.
</li>
</ol>




<p>
<span>How The System Transacts Stocks</span> — This explanation has been greatly simplified in the interest of brevity. 
</p>

<img src="http://counterfeitingstock.com/CS2.0/diagram.png">

<ol>
<li><b>Customers</b> — These can be individuals, institutions, hedge funds and prime broker's house accounts.</li></ol></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://counterfeitingstock.com/CS2.0/CounterfeitingStock.html">http://counterfeitingstock.com/CS2.0/CounterfeitingStock.html</a></em></p>]]>
            </description>
            <link>http://counterfeitingstock.com/CS2.0/CounterfeitingStock.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25986320</guid>
            <pubDate>Mon, 01 Feb 2021 06:59:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[F# is gaining independence from .NET]]>
            </title>
            <description>
<![CDATA[
Score 208 | Comments 171 (<a href="https://news.ycombinator.com/item?id=25986316">thread link</a>) | @sidcool
<br/>
January 31, 2021 | https://onurgumus.github.io/2021/01/31/What-the-F.html | <a href="https://web.archive.org/web/*/https://onurgumus.github.io/2021/01/31/What-the-F.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content-wrapper">
      <div>
         <section id="main-content">
            

<p>In a previous <a href="https://onurgumus.github.io/2020/12/26/Functional-Programming.html">post</a> I have explained my motivations for functional programming.
It’s no secret I love F# because F# makes me sleep better. In this post, I would like to discuss some different aspects of F#.</p>

<h2 id="f-is-gaining-independence-from-net">F# is gaining independence from .NET</h2>

<p><img src="https://onurgumus.github.io/assets/posts/2021-01-31-What-the-F/platform.png" alt="F# platforms"></p>

<!--more-->

<p>F# is mostly known to the developer community as the small ignored brother of C# running on the .NET platform. However, what is less known about F# is that it
has come to a level to be .NET independent. Thanks to <a href="https://fable.io/">Fable</a>, today F# can be considered as a complete replacement of TypeScript. Yes,
people do write full-blown SPA, React, Svelte applications by using F# instead of TypeScript. If you think Fable is just a transpiler, think again:  https://github.com/kunjee17/awesome-fable . I would say Fable is on the way being an ecosystem by itself.</p>

<p>There is also a new prototype target for Fable that allows F# code to transpile to Python developed by Dag Brattli.</p>

<p><img src="https://onurgumus.github.io/assets/posts/2021-01-31-What-the-F/python2.gif" alt="Python"></p>

<p>F# also works as on WebAssembly with <a href="https://fsbolero.io/">Bolero</a> which is still based on .NET. And not to forget another F# web platform called <a href="https://websharper.com/">WebSharper</a> from the same people who developed Bolero.</p>

<p>Just like JavaScript people were using NodeJs to bring the front-end devs to the backend zone, F# also can be used to bring the backend-devs to the front-end realm. I am a living example myself. By using F# in the font-end you can practically share the code between your .NET/Node backend and the browser, giving you an isomorphic development experience.</p>

<p>This somewhat puts F# in an interesting position as historically most dotnet has been languages are managed by Microsoft. But Fable simply liberates
F# from Microsoft and .NET.</p>

<h2 id="the-f-fanboys">The F# fanboys</h2>

<p>You might have heard “one of those guys” like me who is talking about how great functional programming and/or F# is. And from that point, it looks like below</p>

<p><img src="https://onurgumus.github.io/assets/posts/2021-01-31-What-the-F/music.png" alt="music"></p>

<p>I know it’s annoying, however, let’s look at it from the side and this is how an F# developer feels when he or she is suggesting you using F#:
<img src="https://onurgumus.github.io/assets/posts/2021-01-31-What-the-F/wheel.png" alt="wheels"></p>

<h2 id="microsofts-and-communitys-stance">Microsoft’s and community’s stance</h2>

<p>From Microsoft’s point of view, F# is actively supported and maintained. There are Microsoft developers actively fixing things and adding new features however as a general Microsoft’s point of view .NET == C# and that is that. From .NET developer community’s
point of view, things are even worse. Since all Microsoft docs and tools geared towards C#, adding up unfamiliarity with the functional paradigm, most people follow C# way and completely ignore its little brother F#. I still think this is a missed 
opportunity for the .NET community. For example, let’s look at the excellent server side F# web framework <a href="https://giraffe.wiki/">Giraffe</a>. 
While C# and asp.net developers are busy memorizing the Microsoft way of handling requests, learning what attributes to decorate their
classes and members, the F# developers who use giraffe, simply rely on functional composition:</p>

<div><div><pre><code><span>let</span> <span>app</span> <span>=</span>
    <span>route</span> <span>"/"</span>
    <span>&gt;=&gt;</span> <span>setHttpHeader</span> <span>"X-Foo"</span> <span>"Bar"</span>
    <span>&gt;=&gt;</span> <span>setStatusCode</span> <span>200</span>
    <span>&gt;=&gt;</span> <span>setBodyFromString</span> <span>"Hello World"</span>
</code></pre></div></div>

<p>As HTTP processing is usually treated as a pipeline by itself on the server-side, it’s an excellent target for functional programming. Just like lego, plug-in your pipes, and you are good to go.</p>

<p>Furthermore, most developers worry about if they could find an F# job whereas companies who consider making the switch worry if they could find an F# developer.
As of today on linked in there are approximately 700 F# jobs and even most of these are not F# specific rather than they are like “C# or F# developers wanted”.</p>

<p>And most non-.NET people are not willing to touch anything related to Microsoft even with a 10 foot pole. (Of course, the major exceptions to this are TypeScript and Visual Studio Code which both are widely popular). The  Functional programmers’ camp also dismisses F# at sight blaming it’s not like Haskell as in for example F# does not support type classes.</p>

<h2 id="couple-of-unique-features-of-f">Couple of unique features of F#</h2>

<p>I am not going to talk about the features of F# but just wanted to highlight a couple of them.</p>

<p>The first one is the file order. Please look at the below photo:</p>

<p><img src="https://onurgumus.github.io/assets/posts/2021-01-31-What-the-F/files.png" alt="file-order"></p>

<p>In F# the order of the files matter. It is somewhat a disliked feature by the newcomers, but it makes the dependencies immediately visible.
So the code in the top file has no dependency on any others below and the 2nd file from the top only depends on the first. When you open a project which you are not 
familiar, file ordering helps to find your way.</p>

<p>The second one is Type Providers:</p>

<p><img src="https://onurgumus.github.io/assets/posts/2021-01-31-What-the-F/sqlprovider.gif" alt="type-providers"></p>

<p>Type providers are somewhat code generators but they do that non-intrusively. Very roughly similar to LISP style macros they expand at compile time. Type providers make it very easy to discover HTML or JSON documents read database rows, file system, and discover DDL and rows within the coding screen without leaving your editor. And everything becomes so type-safe.</p>

<h2 id="develop-fantastic-ui-apps-with-f-and-elmish">Develop fantastic UI apps with F# and Elmish</h2>

<p>Well they say seeing is believing, so let’s see how well F# handles UI development. While React devs on Facebook trying to solve the state problem over and over again by using hooks and perhaps new experimental
recoil and contexts IMHO, all are horrible options as they encourage rendering code inter-mix with business code reminding me asp.net web forms times where you could write your SQL statements right into the page itself.</p>

<p>F# developers have ported elm architecture to something called elmish and it flourished well among F# community.</p>

<p>Here’s a list of things you can do with Elmish as you can write your business code once and port it to any UI platform below:</p>

<ul>
  <li>React: <a href="https://github.com/elmish/react">Elmish React</a></li>
  <li>Windows Desktop: <a href="https://github.com/elmish/Elmish.WPF">Elmish WPF</a></li>
  <li>Gaming: <a href="https://github.com/ChrisPritchard/Xelmish">Xelmish</a></li>
  <li>Cross platform UI: <a href="https://github.com/AvaloniaCommunity/Avalonia.FuncUI">Avalonia.FuncUI</a></li>
  <li>Mobile development: <a href="https://github.com/fsprojects/Fabulous">Fabulous</a></li>
  <li>Terminal: <a href="https://github.com/DieselMeister/Terminal.Gui.Elmish">Terminal.Gui.Elmish</a></li>
  <li>Web Assembly: <a href="https://fsbolero.io/">Bolero</a></li>
</ul>

<p>They all share the same single architecture: Elmish. So you can write your code for one and port it to another.</p>

<h2 id="getting-started-and-some-resources">Getting started and some resources</h2>

<p>If you want to get started to F#, the first place you should check out is <a href="https://fsharp.org/">F# Software Foundation</a></p>

<p><img src="https://onurgumus.github.io/assets/posts/2021-01-31-What-the-F/fsf2.png" alt="fsharp-foundation"></p>

<p>As you can see FSharp Software Foundation offers mentorship programs periodically, which means you can have a free weekly 1 on 1 session with an experienced F# developer! As of today the program is open for people who want to have an F# mentor or want to be
an F# mentor. You can apply from <a href="https://docs.google.com/forms/d/e/1FAIpQLSdKgZaAcjf7ZxVqBZzyZcBi609BOc0etBnV5XhR6BMihdyYRw/viewform">here</a>.</p>

<p>If you are sold with F# there is one important point to highlight. Do not treat F#, just another language with different syntax especially if you are familiar
with Python, Ruby, JavaScript, C#, etc. You have to embrace functional programming as a paradigm. F# is a functional-first programming language. In other words,
although F# has OOP syntax as well, it mostly makes sense to use F# when you want to get benefit from functional programming concepts. If you try to program
F# the same way you program other imperative languages you won’t get much benefit.</p>

<p>If you are a C# develeoper and you want to start functional programming with F# this is the go-to book:
<em>Disclaimer: I do not know the author nor I am affiliated with the publisher by any way</em></p>

<p><a href="https://www.manning.com/books/functional-programming-in-c-sharp">Functional programming in C#</a></p>

<p>Although the book is mostly about C#, it will show you how painful to do functional programming with C# and only perhaps then you can develop
some love for F#. Having that said it will also help you to understand some more new coming but confusing features of C# 9 like Records and Pattern matching.
If you think  C# records are for immutability, no they are not. They are for Value semantics and <a href="https://www.sitepoint.com/what-is-referential-transparency/#:~:text=In%20functional%20programming%2C%20referential%20transparency,the%20result%20of%20the%20program.">referential transparency</a>.</p>

<p>To try F# right away you may use the following links:</p>

<p>https://try.fsharp.org/</p>

<p>https://fable.io/repl/</p>

<p>https://tryfsharp.fsbolero.io/</p>

<h2 id="syntax">Syntax</h2>

<p>When you are unfamiliar with F# syntax, it might look a bit cryptic. And I have seen some people complained that it is very verbose. On the contrary, I would make a bold claim that F# beats most other languages when it comes to conciseness. You don’t believe me? see it your self (make sure you check all implementations)</p>

<p><a href="https://rosettacode.org/wiki/Category:F_Sharp">F# problems on Rosetta Code</a></p>

<h2 id="a-couple-of-toy-projects-of-mine">A couple of toy projects of mine</h2>

<p>I have developed commercial applications with F#, but as public stuff here are a couple of projects I have built. One is a full blazor/web assembly project:</p>

<p>https://github.com/OnurGumus/FBlazorShop</p>

<p>And the actual app for the 3D bin packing problem, in which items of different volumes must be packed into a finite number of bins or containers each of a fixed given volume in a way that minimizes the number of bins used.</p>

<p>https://github.com/OnurGumus/BinDrake</p>

<p>http://bindrake.com/</p>

<p>Trying and learning F# really requires you to dismiss your prejudices and be patient. But in the end, once you master the functional paradigm,
it makes you sleep better as a developer.</p>


             
            
            
            
                  
         </section>
         
      </div>
   </div></div>]]>
            </description>
            <link>https://onurgumus.github.io/2021/01/31/What-the-F.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25986316</guid>
            <pubDate>Mon, 01 Feb 2021 06:59:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Safari and Firefox Decline WebHID and Other Privacy Sensitive APIs (2020)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25986282">thread link</a>) | @jdc
<br/>
January 31, 2021 | https://usefulangle.com/web-updates/post/80/firefox-decines-to-implement-web-usb-api | <a href="https://web.archive.org/web/*/https://usefulangle.com/web-updates/post/80/firefox-decines-to-implement-web-usb-api">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://usefulangle.com/web-updates/post/80/firefox-decines-to-implement-web-usb-api</link>
            <guid isPermaLink="false">hacker-news-small-sites-25986282</guid>
            <pubDate>Mon, 01 Feb 2021 06:51:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[195 gigapixel 360-degree panorama of Shanghai]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25986212">thread link</a>) | @lelf
<br/>
January 31, 2021 | http://pf.bigpixel.cn/zh-CN/pano/771906131130847232.html | <a href="https://web.archive.org/web/*/http://pf.bigpixel.cn/zh-CN/pano/771906131130847232.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="id_pano_ad"><div></div></div><p>大像素看世界第4期：上海</p><p>陆家嘴是上海的经济脉动中心，也是向世界展示中国经济腾飞的窗口。受上海市新闻办的邀请，大像素团队为其创作上海互联网城市名片。</p><div><p> 最热评论</p><a id="social-comment" target="_blank" href="http://pf.bigpixel.cn/zh-CN/downapp.html"><div><p> 暂无评论 </p></div></a><p><a target="_blank" href="http://pf.bigpixel.cn/zh-CN/downapp.html"> 更多 ...</a></p></div></div></div>]]>
            </description>
            <link>http://pf.bigpixel.cn/zh-CN/pano/771906131130847232.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25986212</guid>
            <pubDate>Mon, 01 Feb 2021 06:37:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WallStreetBets vs. Wall Street and the Populist Rebellion]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25986122">thread link</a>) | @lettergram
<br/>
January 31, 2021 | https://austingwalters.com/wallstreetbets-vs-wall-street-and-the-populist-rebellion/ | <a href="https://web.archive.org/web/*/https://austingwalters.com/wallstreetbets-vs-wall-street-and-the-populist-rebellion/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-3831">

<div>
<p>I have been engaging with WSB (<a href="https://www.reddit.com/r/wallstreetbets/" target="_blank" rel="noopener">/r/WallStreetBets</a>) since 2014.</p>
<p>Every regular person on WSB understands it’s a game. You can loose it all, make it big, sometimes both in the same day — it’s all a game. The most accurate assessment of WSB culture was clearly:</p>
<blockquote><p>Like 4chan found a Bloomberg Terminal.</p></blockquote>
<p>While the influx of new users may change the community, prior to January 15, 2021 the above was indeed an accurate description.</p>

<p>Honestly, this world feels like we are in a simulation. The company GameStop appears to be poised to bring down the entire financial system — stopping the game.</p>
<p>The infinity squeeze appears to be coming, what is an infinity squeeze you ask? It’s a really massive short squeeze:</p>
<blockquote><p>A short squeeze occurs when a stock or other asset jumps sharply higher, forcing traders who had bet that its price would fall, to buy it in order to forestall even greater losses. Their scramble to buy only adds to the upward pressure on the stock’s price.</p></blockquote>
<p>Short positions can technically lead to infinite losses. Simply put, if I open a short position for $10 and the share price drops 10%, I make $1. However, if the stock price increases say 10,000% I now owe $1,000.</p>
<p>In the case of GameStop, the situation appears dire. At one point the short positions were 140% of available shares of the market. This means that more shares were lent out than were available on float, i.e. shorts were resold / lent several times. At this point, several things are happening[<a href="https://www.investopedia.com/ask/answers/05/shortsaleclosed.asp" target="_blank" rel="noopener">1</a>]:</p>
<ul>
<li>Those holding short positions are paying ridiculously high interest rates</li>
<li>If the short positions were forced to close, it would cause a major loss to multiple hedge funds (tens of billions total &amp; bankrupcies)</li>
<li>Due to the level of shorting, exiting the short positions would be excessively expensive and cause a <a href="https://www.investopedia.com/terms/s/shortsqueeze.asp" target="_blank" rel="noopener">short squeeze</a></li>
<li>There is less GameStop stock available for purchase</li>
<li>The price of GameStop stock is rising</li>
</ul>
<p>As a result, it appears to me that:</p>
<ul>
<li>Short holders cannot exit their positions without going bankrupt</li>
<li>Short holders are being hit by high interest rates</li>
<li>Closing other positions in the stock market should help them cover the interest rates</li>
<li>Best option for short position holders is is to wait &amp; pray the stock price drops</li>
<li>What happens if not enough people are willing to sell?</li>
</ul>
<p>Personally, I believe all of this will suck all the liquidity from the stock market. Either those shorting suffer the loss and close their positions or wait as the stock continues to stay high… in either case hundreds of billions of dollars is leaving the market.</p>
<p>How did we get here?</p>
<h3>Infinity Squeeze – Short Positions</h3>
<p>There’s a lot to this story I’ll come back an fill in, but the gist is this — In mid-January 2021 GameStop was <em>extremely</em> shorted.</p>
<figure id="attachment_3832" aria-describedby="caption-attachment-3832"><a href="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17.png" alt="" width="424" height="417" srcset="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17.png 424w, https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17-300x295.png 300w" sizes="(max-width: 424px) 100vw, 424px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17.png" data-srcset="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17.png 424w, https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17-300x295.png 300w"></a><figcaption id="caption-attachment-3832">Courtesy of <a href="https://finance.yahoo.com/quote/GME/key-statistics?p=GME" target="_blank" rel="noopener">Yahoo Finance</a></figcaption></figure>
<p>The massive short position and didn’t go unnoticed, WSB had been <a href="https://web.archive.org/web/20201222153244/https://old.reddit.com/r/wallstreetbets/" target="_blank" rel="noopener">discussing it for months</a>. That being said, the massive spikes in purchases did not start until January 12:</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-05-15.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-05-15.png" alt="" width="916" height="411" srcset="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-05-15.png 916w, https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-05-15-300x135.png 300w, https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-05-15-768x345.png 768w" sizes="(max-width: 916px) 100vw, 916px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-05-15.png" data-srcset="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-05-15.png 916w, https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-05-15-300x135.png 300w, https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-05-15-768x345.png 768w"></a></p>
<p>What happened at that time? The <a href="https://web.archive.org/web/20210118091858/https://old.reddit.com/r/wallstreetbets/comments/kxeq23/gme_yolo_update_jan_14_2021/" target="_blank" rel="noopener">YOLO updates</a> definitely started at that time and stocks started to rise. Once the stocks started to rise, I believe institutions and WSB itself started piling into GameStop. The stock started to move and if they could get in they could make a boat load. It’s important to remember WSB is often visited by hedge fund mangers, CEOs, day traders big and small, etc. It’s not always the little guy(s). When they piled in, the price started to rise further.</p>
<h3>Infinity Squeeze – Let’s Make Money</h3>
<p>As they purchased, I personally believe some short sellers managed to exit their positions (about 7m shares, per Yahoo Finance data)</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17-highlighted.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17-highlighted.png" alt="" width="424" height="417" srcset="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17-highlighted.png 424w, https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17-highlighted-300x295.png 300w" sizes="(max-width: 424px) 100vw, 424px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17-highlighted.png" data-srcset="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17-highlighted.png 424w, https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-01-17-highlighted-300x295.png 300w"></a></p>
<p>What this indicates to me is that many of those holding short positions did not realize what was about to happen. They kept holding believing this was a classic pump-and-dump. Even WSB at the time didn’t not necessarily think about much <a href="https://web.archive.org/web/20210115023914/https://old.reddit.com/r/wallstreetbets/" target="_blank" rel="noopener">besides making money</a>. I know I even purchased call options during this week, particularly when the new data came out January 15, 2021. To me, it became clear the stock was about to rocket.</p>
<h3>Infinity Squeeze – Let’s Stick it to the Man</h3>
<p>In light of the massive number of short position(s) open in January 15, 2021, WSB realized they could (a) make money and (b) stick it to the hedge funds. Frankly, WSB have been waging a war on short selling for years. With GameStop they had a company with relatively few shares&nbsp; in float (47m), a low market cap, basically something that purchases would have an outsized impact.</p>
<p>I’m not 100% sure this was intentional, but as people started buying and holding waiting for the squeeze the stock started to rise.The rising stock both led to discussions on news outlets and the stock started going viral on social media platforms outside of WSB – further raising the going rate for a share of GameStop.</p>
<p>Those holding short positions did not want to sell as they’d lose money, so they were searching for capital to cover their leveraged positions. Citadel and Point72 partners appears to have <a href="https://www.wsj.com/articles/citadel-point72-to-invest-2-75-billion-into-melvin-capital-management-11611604340" target="_blank" rel="noopener">come to at least one short sellers aid</a>. This showed they were weak and further emboldened the WSB folks – “Let’s make some money on the hedge funds behalf”</p>
<p>Purchases from Jan 19 to Jan 23, 2021 and the stock price increased exponentially as it went viral:</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-46-17.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-46-17.png" alt="" width="507" height="423" srcset="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-46-17.png 507w, https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-46-17-300x250.png 300w" sizes="(max-width: 507px) 100vw, 507px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-46-17.png" data-srcset="https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-46-17.png 507w, https://austingwalters.com/wp-content/uploads/2021/01/Screenshot-from-2021-01-31-00-46-17-300x250.png 300w"></a></p>
<h3>Infinity Squeeze – The Rebellion</h3>
<p>On January 27, 2021 across the board buying for GameStop was <a href="https://www.clickondetroit.com/money/2021/01/27/robinhood-td-ameritrade-other-brokerages-have-tech-problems-at-market-open/" target="_blank" rel="noopener">restricted (along with multiple other stocks) across various trading platforms</a>. This effectively forced purchase volume lower and as users of these platforms could only sell it drove down the share price. This likely startled many GameStop shareholds and many liquidated their positions, letting the short sellers exit some of their positions. Through January 29, 2021 the ability to purchase in an unrestricted manner has not been restored.</p>
<p>What happened?</p>
<p>Personally, I’m of the opinion that there was not enough shares to go around and likely these platforms colluded to drive down the stock price. What’s more interesting is how few people sold. As of January 29, 2021 the price of a GameStop share was back at $325. This has led to some very VERY strong backlash and I know I’ll be joining a lawsuit at some point (if not filing my own), as this collusion cost me tens to hundreds of thousands of dollars.</p>
<p>One essay that particularly struck me was made on WSB: <a href="https://web.archive.org/web/20210130034124/https://www.reddit.com/r/wallstreetbets/comments/l6omry/an_open_letter_to_melvin_capital_cnbc_boomers_and/" target="_blank" rel="noopener">An Open Letter to Melvin Capital, CNBC, Boomers, and WSB</a></p>
<p>I recommend reading the comments on this essay to really get an under standing of what’s happening. Look at the charts. This is personal now. The market manipulation is obvious and people want revenge. For the current events, for 2008, for the entire corrupt system. They want to send a message. This is a protest.</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2021/01/vymOZEhH.jpg"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2021/01/vymOZEhH.jpg" alt="" width="474" height="567" srcset="https://austingwalters.com/wp-content/uploads/2021/01/vymOZEhH.jpg 474w, https://austingwalters.com/wp-content/uploads/2021/01/vymOZEhH-251x300.jpg 251w" sizes="(max-width: 474px) 100vw, 474px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2021/01/vymOZEhH.jpg" data-srcset="https://austingwalters.com/wp-content/uploads/2021/01/vymOZEhH.jpg 474w, https://austingwalters.com/wp-content/uploads/2021/01/vymOZEhH-251x300.jpg 251w"></a>Many retail investors will hold until the bitter end.</p>
<h3>Infinity Squeeze – End Game</h3>
<p>So what happens next?</p>
<ul>
<li>Starting on January 27-29 people were trying to transfer funds off Robinhood and the other platforms which disabled purchasing of GameStop shares.</li>
<li>Come the <span>first week of February</span> these assets will be again available and can be used to purchase GameStop shares.</li>
<li>Everyone saw much fewer shares being traded Friday</li>
<li>Everyone is talking with their families</li>
<li>People are going to purchase more GameStop shares &amp; hold</li>
<li>I expect many are going to pull their assets out of the stock market</li>
</ul>
<p>There are some unknowns, for instance have the short positions been closed? Have there been backroom deals to stave off the infinity squeeze?</p>
<p>If neither of those assumptions above hold, then what happens when the price rises further and there’s not enough shares for sale?</p>
<p>Hedge funds either bleed out as they pay the massive interest rates on holding those short positions or they will close their short positions causing an infinity squeeze (GameStop shares will be priced in the thousands). In either case hundreds of billions would likely leave the market.</p>
<h3>Conclusion – The Black Hole</h3>
<p>It’s a <a href="https://en.wikipedia.org/wiki/Nash_equilibrium" target="_blank" rel="noopener">Nash Equilibrium</a>, essentially the share holders have every reason to ask the maximum amount they can get for a share of GameStop (i.e. make money). If for some reason these GameStop share holders are unwilling to sell at a low rate, then these hedge funds stand to lose hundreds of billions and will go bankrupt (slowly via interest payments or quickly via short squeeze). To try and pay for their debts, they’ll have to sell off market wide and the entire market collapses.</p>
<p>There are three ways to alleviate the issue:</p>
<ul>
<li>GameStop issues a massive number of new shares</li>
<li>Market manipulation (such as Robinood and friends only enabling selling – of course that didn’t work last time)</li>
<li>Government settles the matter by confiscating shares</li>
</ul>
<p>Personally, I view government involvement as inevitable. They could settle everyone accounts fairly by giving everyone the current share price or what they bought it for, which every is higher. That being said, I suspect the more likely course of action is some flat rate $100/share or something to that effect. In either case, if they don’t get involved, I suspect the system really will collapse.</p>
<p>Unless of course, I am wrong. I am not a financial expert and nothing in this article should be taken as advice.</p>
<p>It’s completely possible I’m inaccurately reading the situation and those shorting GameStop have already exited their position(s) and GameStop is currently just in a classic bubble.</p>

</div>

</article></div>]]>
            </description>
            <link>https://austingwalters.com/wallstreetbets-vs-wall-street-and-the-populist-rebellion/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25986122</guid>
            <pubDate>Mon, 01 Feb 2021 06:18:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[10 Years of Nlnog Ring]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25986010">thread link</a>) | @janvdberg
<br/>
January 31, 2021 | https://ring.nlnog.net/post/10-years-of-nlnog-ring/ | <a href="https://web.archive.org/web/*/https://ring.nlnog.net/post/10-years-of-nlnog-ring/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>This month marks the tenth anniversary of the <a href="https://ring.nlnog.net/">NLNOG RING</a> project.
In this article we look back on how the project came to be and how it evolved over this past decade.</p>
<h3 id="a-network-engineers-tale">A network engineer’s tale…</h3>
<p>The story of NLNOG RING starts on the <a href="https://nlnog.net/irc/">#nlnog</a> IRC channel, at the end of 2010.
A network engineer received complaints that his customers had difficulty reaching various destinations in several Dutch networks.
The case was a curious one, because the problem would come and go.
Some TCP sessions would establish immediately, whereas others would take multiple attempts before a connection was made.
It was clear something was broken, but locating the root cause proved to be difficult.</p>
<p>To find the source of the problem, the engineer proceeded to ask engineers from other networks for traceroute outputs, gathering data about how packets would travel from their networks to his.
The other engineers were of course happy to help, but because each question had to be answered individually it took a long time to gather the necessary data.
All in all it took several days to get a complete picture and identify a root cause, which turned out to be a faulty backbone link within the fabric of a large Dutch internet exchange point.</p>
<p><img src="https://ring.nlnog.net/images/post/10-years-of-nlnog-ring/original-problem.png" alt="Manual coordination of network troubleshooting" title="Manual coordination of network troubleshooting"></p>
<p>During the surrounding discussion on the IRC channel, seeing the amount of effort it took to collect the required information from different vantage points, the question came up: “What if we had a way for an engineer to access other networks securely, and collect troubleshooting data, without having to wait for the other side?”
Several people immediately offered to dedicate servers or virtual machines to the project, and a few others started building tooling for software installation and user management.
And so, in January 2011, NLNOG RING <a href="http://mailman.nlnog.net/pipermail/nlnog/2011-January/002433.html">was born</a>.</p>
<h3 id="architecture-and-tools">Architecture and tools</h3>
<p>The NLNOG RING is a “looking glass on steroids”. Participants join the project by making a (virtual) server available, hosted inside their own network. In return they gain access to their own shell account on all the machines provided by all other participating networks.</p>
<p>Right from the start we were conscious of the fact that we would have to manage a potentially large number of systems with a small group of volunteers.
To do this in a time-efficient manner we deployed <a href="https://puppet.com/">Puppet</a> on all provided systems.
This allowed us to install software tools and configure users in a centralized manner.
To further limit the scope of work we decided to support only a single operating system: <a href="https://ubuntu.com/blog/what-is-an-ubuntu-lts-release">Ubuntu LTS</a>.
For security we did not want to rely on passwords. All user access is controlled through SSH keys and there is no superuser access for any of the participants.</p>
<p>The basis of the NLNOG RING is a shell account, which offers a lot of freedom to participants to run their own troubleshooting scripts or programs.
To add extra value to this, each machine is provisioned with a collection of commonly used network troubleshooting tools.
We provide a DNS-interface and a <a href="https://ring.nlnog.net/toolbox/restful-api/">RESTful API</a> for retrieving participant and node information, and we have a regular BGP <a href="http://lg.ring.nlnog.net/">looking glass</a> providing insight into many networks.</p>
<p>NLNOG RING is a community project.
Over the years, many people have contributed tools and code to make the project more useful.
One of the first tools was <a href="https://github.com/NLNOG/nlnog-ring/blob/master/scripts/ring-trace">ring-trace</a>, a piece of software to run traceroutes from different vantage points, and display them in a graphical format.</p>
<p><img src="https://ring.nlnog.net/images/post/10-years-of-nlnog-ring/trace-ring.nlnog.net.jpeg" alt="Example of ring-trace output" title="Example of ring-trace output"></p>
<p>Another user-contributed tool is <a href="https://github.com/NLNOG/ring-sqa">ring-sqa</a>, a piece of software that attempts to automatically detect connectivity problems between NLNOG RING nodes and notifies their owners.
Events are also correlated to detect larger, sometimes Internet-wide outages, which are published on a <a href="http://sqa.ring.nlnog.net/">dashboard</a>.</p>
<p>Since 2013 we also cooperate with <a href="https://atlas.ripe.net/">RIPE Atlas</a>, to combine the strengths of the two platforms.
NLNOG RING nodes are selectable as <a href="https://atlas.ripe.net/targets/ringnodes/list/">measurement targets</a> in the RIPE Atlas interface.
Furthermore, the RIPE Atlas <a href="https://github.com/RIPE-NCC/ripe-atlas-tools">tools package</a> is installed on all NLNOG RING nodes, so participants can integrate RIPE Atlas measurements in scripts run on the RING.</p>
<h3 id="operating-model-and-sponsoring">Operating model and sponsoring</h3>
<p>The NLNOG RING was started by a couple of network engineers in their free time, and is still completely run by a small number of volunteers.
All participating networks provide their own machines.
In most cases (75%) this is a VM, making the barrier to participate very low.</p>
<p>At the start of the project all management tooling was running on infrastructure from <a href="https://intouch.eu/">InTouch</a>, the employer of one of our founding volunteers.
As the project grew the requirement for some dedicated management infrastructure arose.
In 2013 we successfully held a <a href="https://ring.nlnog.net/post/ring-fundraiser-successfully-closed/">fundraiser</a>, which enabled us to obtain the necessary hardware for hosting our management tooling.
Over the years more <a href="https://ring.nlnog.net/patrons/">sponsors</a> donated resources. These generous donations help us to run the project on essentially zero budget.</p>
<h3 id="growth">Growth</h3>
<p>Because the project originated within the Dutch ISP community, the first participants were all Dutch network operators.
After giving our first public presentation at <a href="https://ripe62.ripe.net/presentations/176-JobSnijders_NLNOG_RING_RIPE62.pdf">RIPE62</a> in May of 2011, ISPs from outside The Netherlands also showed interest in participating.
While The Netherlands is still the country with the most active participants (93 nodes as of January 2021), the majority of participants is based elsewhere.
At the time of writing we have 472 participating autonomous systems, with (virtual) machines in <a href="http://map.ring.nlnog.net/">56 countries</a>.</p>
<p><img src="https://ring.nlnog.net/images/post/10-years-of-nlnog-ring/ring-map=january-2021.png" alt="Map of NLNOG RING nodes (January 2021)" title="Map of NLNOG RING nodes (January 2021)"></p>
<p>Supporting all these machines was significantly increasing in load on our central Puppet server, to a point where in 2016 configuration of a single machine would take more than 30 minutes.
In addition to this we were facing the planned obsolescence of Puppet 2, which meant we would have to rewrite a significant part of our configurations to a syntax supported by Puppet 3.
Altogether a good opportunity to re-evaluate our architecture.</p>
<p>After evaluating several configuration management systems we decided on <a href="https://www.ansible.com/">Ansible</a>, mostly because of its support for a masterless “pull” model.
In this model all servers download their latest configs from a source code repository, and apply their changes locally.
This removes the need for a centralized management server, which means we can scale to a virtually unlimited number of machines.
All configuration files are published on our <a href="https://github.com/NLNOG/ring-ansible/">GitHub repository</a>, so that all participants can contribute.</p>
<p>To further cope with the increased growth in participants and machines we automated <a href="https://ring.nlnog.net/toolbox/health-monitoring/">health monitoring</a>, to automatically notify participants of problems with the (virtual) machines they provided to us.</p>
<h3 id="whats-next">What’s next?</h3>
<p>In ten years the NLNOG RING has grown from a handful of machines in the Netherlands to over 500 nodes worldwide, and we continue to see the number of active nodes grow.
To scale the platform further we plan to invest some time in building more self service tooling for provisioning of machines.
Another item high on our wishlist is a graphing solution that displays latency and packet loss on the full mesh of network paths between all nodes.
We will also continue to add features and tools <a href="https://github.com/NLNOG/ring-ansible/issues">requested</a> by participants.</p>
<p>We of course hope to continue to see a diverse set of ISPs join the project. The success of the project largely depends on the networks that provide us with resources. We thank all <a href="https://ring.nlnog.net/participants/">current participants</a> for making the NLNOG RING a huge success! Tell your friends to join too!</p>

        </div></div>]]>
            </description>
            <link>https://ring.nlnog.net/post/10-years-of-nlnog-ring/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25986010</guid>
            <pubDate>Mon, 01 Feb 2021 06:00:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Many Paths of Length K?: and I Show You How Deep the Rabbit Hole Goes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25985890">thread link</a>) | @chillee
<br/>
January 31, 2021 | http://horace.io/walks.html | <a href="https://web.archive.org/web/*/http://horace.io/walks.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

<p>Here's a (surprisingly interesting) programming problem: Given a directed unweighted graph with V vertices and E edges, how many paths of length K are there from node A to node B? Paths may visit the same node or edge multiple times<sup><a href="#fn1" id="fnref1">[1]</a></sup>. To avoid dealing with very large numbers, assume that we're computing our answer modulo a large prime.</p>
<p engine="dot"><!--?xml version="1.0" encoding="UTF-8" standalone="no"?-->

<!-- Generated by graphviz version 2.40.1 (20161225.0304)
 -->
<!-- Title: Figure Pages: 1 -->
<svg width="466pt" height="270pt" viewBox="0.00 0.00 466.00 269.60" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink">
<g id="graph0" transform="scale(1 1) rotate(0) translate(4 265.6)">
<title>Figure</title>
<polygon fill="#ffffff" stroke="transparent" points="-4,4 -4,-265.6 462,-265.6 462,4 -4,4"></polygon>
<text text-anchor="middle" x="229" y="-245" font-family="Times,serif" font-size="14.00" fill="#000000">There are 2 paths of length 2 from node A to node B</text>
<g id="clust1">
<title>cluster_first</title>
<polygon fill="none" stroke="#000000" points="8,-8 8,-228.8 150,-228.8 150,-8 8,-8"></polygon>
<text text-anchor="middle" x="79" y="-212.2" font-family="Times,serif" font-size="14.00" fill="#000000">Graph</text>
</g>
<g id="clust2">
<title>cluster_second</title>
<polygon fill="none" stroke="#000000" points="158,-8 158,-228.8 300,-228.8 300,-8 158,-8"></polygon>
<text text-anchor="middle" x="229" y="-212.2" font-family="Times,serif" font-size="14.00" fill="#000000">Path 1</text>
</g>
<g id="clust3">
<title>cluster_third</title>
<polygon fill="none" stroke="#000000" points="308,-8 308,-228.8 450,-228.8 450,-8 308,-8"></polygon>
<text text-anchor="middle" x="379" y="-212.2" font-family="Times,serif" font-size="14.00" fill="#000000">Path 2</text>
</g>
<!-- A1 -->
<g id="node1">
<title>A1</title>
<ellipse fill="none" stroke="#000000" cx="79" cy="-178" rx="27" ry="18"></ellipse>
<text text-anchor="middle" x="79" y="-173.8" font-family="Times,serif" font-size="14.00" fill="#000000">A</text>
</g>
<!-- C1 -->
<g id="node3">
<title>C1</title>
<ellipse fill="none" stroke="#000000" cx="43" cy="-106" rx="27" ry="18"></ellipse>
</g>
<!-- A1&#45;&gt;C1 -->
<g id="edge1">
<title>A1-&gt;C1</title>
<path fill="none" stroke="#000000" d="M70.2854,-160.5708C66.0403,-152.0807 60.8464,-141.6929 56.1337,-132.2674"></path>
<polygon fill="#000000" stroke="#000000" points="59.237,-130.6477 51.6343,-123.2687 52.976,-133.7782 59.237,-130.6477"></polygon>
</g>
<!-- D1 -->
<g id="node4">
<title>D1</title>
<ellipse fill="none" stroke="#000000" cx="115" cy="-106" rx="27" ry="18"></ellipse>
</g>
<!-- A1&#45;&gt;D1 -->
<g id="edge3">
<title>A1-&gt;D1</title>
<path fill="none" stroke="#000000" d="M87.7146,-160.5708C91.9597,-152.0807 97.1536,-141.6929 101.8663,-132.2674"></path>
<polygon fill="#000000" stroke="#000000" points="105.024,-133.7782 106.3657,-123.2687 98.763,-130.6477 105.024,-133.7782"></polygon>
</g>
<!-- B1 -->
<g id="node2">
<title>B1</title>
<ellipse fill="none" stroke="#000000" cx="79" cy="-34" rx="27" ry="18"></ellipse>
<text text-anchor="middle" x="79" y="-29.8" font-family="Times,serif" font-size="14.00" fill="#000000">B</text>
</g>
<!-- C1&#45;&gt;B1 -->
<g id="edge2">
<title>C1-&gt;B1</title>
<path fill="none" stroke="#000000" d="M51.7146,-88.5708C55.9597,-80.0807 61.1536,-69.6929 65.8663,-60.2674"></path>
<polygon fill="#000000" stroke="#000000" points="69.024,-61.7782 70.3657,-51.2687 62.763,-58.6477 69.024,-61.7782"></polygon>
</g>
<!-- D1&#45;&gt;B1 -->
<g id="edge4">
<title>D1-&gt;B1</title>
<path fill="none" stroke="#000000" d="M106.2854,-88.5708C102.0403,-80.0807 96.8464,-69.6929 92.1337,-60.2674"></path>
<polygon fill="#000000" stroke="#000000" points="95.237,-58.6477 87.6343,-51.2687 88.976,-61.7782 95.237,-58.6477"></polygon>
</g>
<!-- A2 -->
<g id="node5">
<title>A2</title>
<ellipse fill="none" stroke="#000000" cx="229" cy="-178" rx="27" ry="18"></ellipse>
<text text-anchor="middle" x="229" y="-173.8" font-family="Times,serif" font-size="14.00" fill="#000000">A</text>
</g>
<!-- C2 -->
<g id="node7">
<title>C2</title>
<ellipse fill="none" stroke="#000000" cx="193" cy="-106" rx="27" ry="18"></ellipse>
</g>
<!-- A2&#45;&gt;C2 -->
<g id="edge5">
<title>A2-&gt;C2</title>
<path fill="none" stroke="#ff0000" stroke-width="3" d="M220.2854,-160.5708C216.0403,-152.0807 210.8464,-141.6929 206.1337,-132.2674"></path>
<polygon fill="#ff0000" stroke="#ff0000" stroke-width="3" points="209.237,-130.6477 201.6343,-123.2687 202.976,-133.7782 209.237,-130.6477"></polygon>
</g>
<!-- D2 -->
<g id="node8">
<title>D2</title>
<ellipse fill="none" stroke="#000000" cx="265" cy="-106" rx="27" ry="18"></ellipse>
</g>
<!-- A2&#45;&gt;D2 -->
<g id="edge7">
<title>A2-&gt;D2</title>
<path fill="none" stroke="#000000" d="M237.7146,-160.5708C241.9597,-152.0807 247.1536,-141.6929 251.8663,-132.2674"></path>
<polygon fill="#000000" stroke="#000000" points="255.024,-133.7782 256.3657,-123.2687 248.763,-130.6477 255.024,-133.7782"></polygon>
</g>
<!-- B2 -->
<g id="node6">
<title>B2</title>
<ellipse fill="none" stroke="#000000" cx="229" cy="-34" rx="27" ry="18"></ellipse>
<text text-anchor="middle" x="229" y="-29.8" font-family="Times,serif" font-size="14.00" fill="#000000">B</text>
</g>
<!-- C2&#45;&gt;B2 -->
<g id="edge6">
<title>C2-&gt;B2</title>
<path fill="none" stroke="#ff0000" stroke-width="3" d="M201.7146,-88.5708C205.9597,-80.0807 211.1536,-69.6929 215.8663,-60.2674"></path>
<polygon fill="#ff0000" stroke="#ff0000" stroke-width="3" points="219.024,-61.7782 220.3657,-51.2687 212.763,-58.6477 219.024,-61.7782"></polygon>
</g>
<!-- D2&#45;&gt;B2 -->
<g id="edge8">
<title>D2-&gt;B2</title>
<path fill="none" stroke="#000000" d="M256.2854,-88.5708C252.0403,-80.0807 246.8464,-69.6929 242.1337,-60.2674"></path>
<polygon fill="#000000" stroke="#000000" points="245.237,-58.6477 237.6343,-51.2687 238.976,-61.7782 245.237,-58.6477"></polygon>
</g>
<!-- A3 -->
<g id="node9">
<title>A3</title>
<ellipse fill="none" stroke="#000000" cx="379" cy="-178" rx="27" ry="18"></ellipse>
<text text-anchor="middle" x="379" y="-173.8" font-family="Times,serif" font-size="14.00" fill="#000000">A</text>
</g>
<!-- C3 -->
<g id="node11">
<title>C3</title>
<ellipse fill="none" stroke="#000000" cx="343" cy="-106" rx="27" ry="18"></ellipse>
</g>
<!-- A3&#45;&gt;C3 -->
<g id="edge9">
<title>A3-&gt;C3</title>
<path fill="none" stroke="#000000" d="M370.2854,-160.5708C366.0403,-152.0807 360.8464,-141.6929 356.1337,-132.2674"></path>
<polygon fill="#000000" stroke="#000000" points="359.237,-130.6477 351.6343,-123.2687 352.976,-133.7782 359.237,-130.6477"></polygon>
</g>
<!-- D3 -->
<g id="node12">
<title>D3</title>
<ellipse fill="none" stroke="#000000" cx="415" cy="-106" rx="27" ry="18"></ellipse>
</g>
<!-- A3&#45;&gt;D3 -->
<g id="edge11">
<title>A3-&gt;D3</title>
<path fill="none" stroke="#ff0000" stroke-width="3" d="M387.7146,-160.5708C391.9597,-152.0807 397.1536,-141.6929 401.8663,-132.2674"></path>
<polygon fill="#ff0000" stroke="#ff0000" stroke-width="3" points="405.024,-133.7782 406.3657,-123.2687 398.763,-130.6477 405.024,-133.7782"></polygon>
</g>
<!-- B3 -->
<g id="node10">
<title>B3</title>
<ellipse fill="none" stroke="#000000" cx="379" cy="-34" rx="27" ry="18"></ellipse>
<text text-anchor="middle" x="379" y="-29.8" font-family="Times,serif" font-size="14.00" fill="#000000">B</text>
</g>
<!-- C3&#45;&gt;B3 -->
<g id="edge10">
<title>C3-&gt;B3</title>
<path fill="none" stroke="#000000" d="M351.7146,-88.5708C355.9597,-80.0807 361.1536,-69.6929 365.8663,-60.2674"></path>
<polygon fill="#000000" stroke="#000000" points="369.024,-61.7782 370.3657,-51.2687 362.763,-58.6477 369.024,-61.7782"></polygon>
</g>
<!-- D3&#45;&gt;B3 -->
<g id="edge12">
<title>D3-&gt;B3</title>
<path fill="none" stroke="#ff0000" stroke-width="3" d="M406.2854,-88.5708C402.0403,-80.0807 396.8464,-69.6929 392.1337,-60.2674"></path>
<polygon fill="#ff0000" stroke="#ff0000" stroke-width="3" points="395.237,-58.6477 387.6343,-51.2687 388.976,-61.7782 395.237,-58.6477"></polygon>
</g>
</g>
</svg>
</p><p>This problem is fairly standard -  many of you may have seen it or heard it in an interview. Personally, I've seen this problem on Hackernews in some form at least three times, <a href="https://news.ycombinator.com/item?id=22953404">here</a>, <a href="https://news.ycombinator.com/item?id=19193405">here</a>, and <a href="https://news.ycombinator.com/item?id=17758800">here</a>.</p>
<p>I found this comment from the last link particularly interesting.<br>
<img src="http://horace.io/img/walks_hn.jpg" alt=""></p>
<p>He states of the most advanced level:</p>
<blockquote>
<p>I've never seen anyone get this and I only learned about it after months of asking this question.</p>
</blockquote>
<p>And that's where he left the problem. Seems like a pretty cool problem with plenty of depth, doesn't it?</p>
<p>As it turns out, this problem has even more depth than that Google interviewer thought. What if I told you, that drawing on concepts from coding theory, abstract algebra, and signal processing, we could solve this problem in <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>E</mi><mi>V</mi><mo>+</mo><mi>V</mi><mi>log</mi><mo>⁡</mo><mi>V</mi><mi>log</mi><mo>⁡</mo><mi>K</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(EV + V \log V \log K)</annotation></semantics></math></span></span> time?</p>
<p>To my knowledge, despite being a common problem, I have not seen this faster solution presented anywhere.</p>
<p>Let's dive down the rabbit hole of solutions to this problem, starting from the top.</p>


<p>The most straightforward solution to this problem is to enumerate all the paths and stopping once our path reaches K nodes. We can implement it with a breadth first search, like so:</p>
<pre data-role="codeBlock" data-info="python">ans <span>=</span> <span>0</span>
queue <span>=</span> <span>[</span><span>(</span>A<span>,</span> <span>0</span><span>)</span><span>]</span> 
<span>while</span> <span>not</span> queue<span>.</span>empty<span>(</span><span>)</span><span>:</span>
    curNode<span>,</span> curLength <span>=</span> queue<span>.</span>front<span>(</span><span>)</span>
    queue<span>.</span>pop<span>(</span><span>)</span>
    <span>if</span> curLength <span>==</span> K<span>:</span>
        <span>if</span> curNode <span>==</span> B<span>:</span>
            ans <span>+=</span> <span>1</span>
        <span>break</span>
    <span>for</span> neighbor <span>in</span> neighbors<span>(</span>curNode<span>)</span><span>:</span>
        queue<span>.</span>push<span>(</span><span>(</span>neighbor<span>,</span> curLength <span>+</span> <span>1</span><span>)</span><span>)</span>
</pre><p>However, this solution is exponential. Take this simple graph</p>
<p><!--?xml version="1.0" encoding="UTF-8" standalone="no"?-->

<!-- Generated by graphviz version 2.40.1 (20161225.0304)
 -->
<!-- Title: G Pages: 1 -->
<svg width="152pt" height="62pt" viewBox="0.00 0.00 152.00 62.00" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink">
<g id="graph0" transform="scale(1 1) rotate(0) translate(4 58)">
<title>G</title>
<polygon fill="#ffffff" stroke="transparent" points="-4,4 -4,-58 148,-58 148,4 -4,4"></polygon>
<!-- 0 -->
<g id="node1">
<title>0</title>
<ellipse fill="none" stroke="#000000" cx="27" cy="-18" rx="27" ry="18"></ellipse>
<text text-anchor="middle" x="27" y="-13.8" font-family="Times,serif" font-size="14.00" fill="#000000">0</text>
</g>
<!-- 0&#45;&gt;0 -->
<g id="edge3">
<title>0-&gt;0</title>
<path fill="none" stroke="#000000" d="M11.7729,-33.1666C7.1587,-43.6641 12.2344,-54 27,-54 36.9207,-54 42.4671,-49.3342 43.6394,-43.0884"></path>
<polygon fill="#000000" stroke="#000000" points="47.1015,-42.5736 42.2271,-33.1666 40.1713,-43.5601 47.1015,-42.5736"></polygon>
</g>
<!-- 1 -->
<g id="node2">
<title>1</title>
<ellipse fill="none" stroke="#000000" cx="117" cy="-18" rx="27" ry="18"></ellipse>
<text text-anchor="middle" x="117" y="-13.8" font-family="Times,serif" font-size="14.00" fill="#000000">1</text>
</g>
<!-- 0&#45;&gt;1 -->
<g id="edge1">
<title>0-&gt;1</title>
<path fill="none" stroke="#000000" d="M52.5497,-11.8449C61.4801,-11.2634 71.6762,-11.1082 81.2822,-11.3793"></path>
<polygon fill="#000000" stroke="#000000" points="81.2372,-14.8808 91.3865,-11.8408 81.5566,-7.8881 81.2372,-14.8808"></polygon>
</g>
<!-- 1&#45;&gt;0 -->
<g id="edge2">
<title>1-&gt;0</title>
<path fill="none" stroke="#000000" d="M91.3865,-24.1592C82.45,-24.7387 72.2523,-24.8919 62.6491,-24.6188"></path>
<polygon fill="#000000" stroke="#000000" points="62.6997,-21.1175 52.5497,-24.1551 62.3786,-28.1101 62.6997,-21.1175"></polygon>
</g>
<!-- 1&#45;&gt;1 -->
<g id="edge4">
<title>1-&gt;1</title>
<path fill="none" stroke="#000000" d="M101.7729,-33.1666C97.1587,-43.6641 102.2344,-54 117,-54 126.9207,-54 132.4671,-49.3342 133.6394,-43.0884"></path>
<polygon fill="#000000" stroke="#000000" points="137.1015,-42.5736 132.2271,-33.1666 130.1713,-43.5601 137.1015,-42.5736"></polygon>
</g>
</g>
</svg>
</p><p>Let's count the number of paths of length K from node 0 to node 1. We see that any sequence of 0s and 1s that ends at node 1 is a valid path, implying that there are <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2</mn><mi>K</mi></msup></mrow><annotation encoding="application/x-tex">2^K</annotation></semantics></math></span></span> valid paths. As this solution counts each valid path separately, it must be doing exponential work as well.</p>
<p>An interviewer (like that Googler) wouldn't be too impressed.</p>


<p>Looking at the above solution, we notice that there is a lot of wasted work - our queue will often visit the same state many times. For example, we'll visit node B with a path of length K as many times as our answer. Noticing that the same state is visited multiple times naturally leads to a dynamic programming solution.</p>
<p>In this case, we choose the same state as we did in our above problem: (node, length). This time, however, we consolidate all of our redundant states.</p>
<p>Thus, <code>dp[node][length] = sum(dp[neighbors(node)][length-1])</code>.</p>
<pre data-role="codeBlock" data-info="python">dp<span>[</span>A<span>]</span><span>[</span><span>0</span><span>]</span> <span>=</span> <span>1</span>
<span>for</span> length <span>in</span> <span>0</span><span>.</span><span>.</span>K<span>:</span>
    <span>for</span> node <span>in</span> <span>0</span><span>.</span><span>.</span>N<span>:</span>
        <span>for</span> neighbor <span>in</span> neighbors<span>(</span>node<span>)</span><span>:</span>
            dp<span>[</span>node<span>]</span><span>[</span>length<span>]</span> <span>+=</span> dp<span>[</span>neighbor<span>]</span><span>[</span>length<span>-</span><span>1</span><span>]</span>
</pre><p>We can either do this iteratively (which allows us to reduce memory complexity by only storing one layer of DP at a time), or recursively with memoization. I've presented the iterative solution above.</p>
<p>The complexity of this solution is <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>E</mi><mi>K</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(EK)</annotation></semantics></math></span></span>. So far, this seems like a standard DP problem. Most interviewers would probably be satisfied with this solution.</p>
<p>We aren't. :^)</p>


<p>If there aren't many nodes but <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span></span> is extremely large, then we need to give up on the above DP approach. The naive approach above finds the answer for "how many paths of length <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">K-1</annotation></semantics></math></span></span>" before it finds the answer to "how many paths of length <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span></span>". As a result, even if we <strong>could</strong> find the answer for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span></span> from the answer for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">K-1</annotation></semantics></math></span></span> in constant time, we wouldn't be able to solve this problem with the above constraints.</p>
<p>There's 2 different ways to proceed. The first is to note that we don't actually <em>need</em> the answer for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">K-1</annotation></semantics></math></span></span> before we can find the answer for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span></span>. For example, if we know that that there are 3 paths of length 50 from A to C and 4 paths of length 50 from C to B, then there are <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mo>⋅</mo><mn>4</mn></mrow><annotation encoding="application/x-tex">3 \cdot 4</annotation></semantics></math></span></span> paths of length 100 from A to B with C at the midpoint. More generally, consider any node C. The number of paths from A to B of length <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span></span> that include C at the midpoint is the number of paths from A to C of half length multiplied by the number of paths from C to B of half length. If we sum over all possible nodes for C, then we have our answer for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span></span>.</p>
<p><!--?xml version="1.0" encoding="UTF-8" standalone="no"?-->

<!-- Generated by graphviz version 2.40.1 (20161225.0304)
 -->
<!-- Title: G Pages: 1 -->
<svg width="376pt" height="74pt" viewBox="0.00 0.00 375.87 73.95" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink">
<g id="graph0" transform="scale(1 1) rotate(0) translate(4 69.9469)">
<title>G</title>
<polygon fill="#ffffff" stroke="transparent" points="-4,4 -4,-69.9469 371.8676,-69.9469 371.8676,4 -4,4"></polygon>
<text text-anchor="middle" x="183.9338" y="-49.3469" font-family="Times,serif" font-size="14.00" fill="#000000">12 paths from A to B of length 100 if each edge is of length 50</text>
<!-- A -->
<g id="node1">
<title>A</title>
<ellipse fill="none" stroke="#000000" cx="93.9338" cy="-20.5735" rx="27" ry="18"></ellipse>
<text text-anchor="middle" x="93.9338" y="-16.3735" font-family="Times,serif" font-size="14.00" fill="#000000">A</text>
</g>
<!-- C -->
<g id="node2">
<title>C</title>
<ellipse fill="none" stroke="#000000" cx="183.9338" cy="-20.5735" rx="27" ry="18"></ellipse>
<text text-anchor="middle" x="183.9338" y="-16.3735" font-family="Times,serif" font-size="14.00" fill="#000000">C</text>
</g>
<!-- A&#45;&gt;C -->
<g id="edge1">
<title>A-&gt;C</title>
<path fill="none" stroke="#000000" d="M114.8078,-8.9719C126.167,-6.9892 140.438,-6.5595 153.0593,-7.6829"></path>
<polygon fill="#000000" stroke="#000000" points="152.8064,-11.1792 163.173,-8.9917 153.7049,-4.2371 152.8064,-11.1792"></polygon>
</g>
<!-- A&#45;&gt;C -->
<g id="edge2">
<title>A-&gt;C</title>
<path fill="none" stroke="#000000" d="M120.9368,-20.5735C128.9615,-20.5735 137.9003,-20.5735 146.4647,-20.5735"></path>
<polygon fill="#000000" stroke="#000000" points="146.6389,-24.0736 156.6388,-20.5735 146.6388,-17.0736 146.6389,-24.0736"></polygon>
</g>
<!-- A&#45;&gt;C -->
<g id="edge3">
<title>A-&gt;C</title>
<path fill="none" stroke="#000000" d="M114.8078,-32.175C126.167,-34.1577 140.438,-34.5874 153.0593,-33.4641"></path>
<polygon fill="#000000" stroke="#000000" points="153.7049,-36.9098 163.173,-32.1552 152.8064,-29.9677 153.7049,-36.9098"></polygon>
</g>
<!-- B -->
<g id="node3">
<title>B</title>
<ellipse fill="none" stroke="#000000" cx="273.9338" cy="-20.5735" rx="27" ry="18"></ellipse>
<text text-anchor="middle" x="273.9338" y="-16.3735" font-family="Times,serif" font-size="14.00" fill="#000000">B</text>
</g>
<!-- C&#45;&gt;B -->
<g id="edge4">
<title>C-&gt;B</title>
<path fill="none" stroke="#000000" d="M198.3939,-5.229C212.171,.1403 233.1793,1.1019 249.5467,-2.3441"></path>
<polygon fill="#000000" stroke="#000000" points="248.93,-5.8097 259.5096,-5.243 250.8857,.9116 248.93,-5.8097"></polygon>
</g>
<!-- C&#45;&gt;B -->
<g id="edge5">
<title>C-&gt;B</title>
<path fill="none" stroke="#000000" d="M209.4835,-14.4184C218.4139,-13.8369 228.61,-13.6817 238.216,-13.9528"></path>
<polygon fill="#000000" stroke="#000000" points="238.171,-17.4543 248.3203,-14.4142 238.4904,-10.4615 238.171,-17.4543"></polygon>
</g>
<!-- C&#45;&gt;B -->
<g id="edge6">
<title>C-&gt;B</title>
<path fill="none" stroke="#000000" d="M209.4835,-26.7286C218.4139,-27.3101 228.61,-27.4653 238.216,-27.1942"></path>
<polygon fill="#000000" stroke="#000000" points="238.4904,-30.6854 248.3203,-26.7327 238.171,-23.6927 238.4904,-30.6854"></polygon>
</g>
<!-- C&#45;&gt;B -->
<g id="edge7">
<title>C-&gt;B</title>
<path fill="none" stroke="#000000" d="M198.3939,-35.9179C212.171,-41.2872 233.1793,-42.2488 249.5467,-38.8029"></path>
<polygon fill="#000000" stroke="#000000" points="250.8857,-42.0585 259.5096,-35.9039 248.93,-35.3372 250.8857,-42.0585"></polygon>
</g>
</g>
</svg>
</p><p>This allows us to remove our linear dependence on <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span></span> and transforms it into a logarithmic one, for a <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>V</mi><mn>3</mn></msup><mi>log</mi><mo>⁡</mo><mi>K</mi></mrow><annotation encoding="application/x-tex">V^3 \log K</annotation></semantics></math></span></span> algorithm.</p>
<p>Using graph theory, however, there's an even easier way to come up with this algorithm. One way to represent graphs is as an adjacency matrix <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span></span>. If one views the values in <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">A_{ij}</annotation></semantics></math></span></span> as the number of edges between <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span></span>, then <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>A</mi><mrow><mi>i</mi><mi>j</mi></mrow><mi>k</mi></msubsup></mrow><annotation encoding="application/x-tex">A_{ij}^k</annotation></semantics></math></span></span> represents the number of paths between <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span></span> of length <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span>.</p>
<p>Thus, this problem has been reduced to computing <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>A</mi><mi>k</mi></msup></mrow><annotation encoding="application/x-tex">A^k</annotation></semantics></math></span></span> (i.e: matrix power). This is a standard problem that can be done in <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>V</mi><mn>3</mn></msup><mi>log</mi><mo>⁡</mo><mi>K</mi></mrow><annotation encoding="application/x-tex">V^3 \log K</annotation></semantics></math></span></span> time through <a href="https://news.ycombinator.com/item?id=22946710">binary exponentiation</a>.</p>
<p>The two approaches outlined above end up being identical, but use radically different approaches. The difficulty of the first approach lies in thinking about first principles, while the difficulty of the second approach lies in abstracting the problem to matrices. However, once you've abstracted the problem appropriately, the solution becomes obvious.</p>


<p>For the vast majority of people (including the aforementioned HN commenter), their ability to solve this problem stops here. And thus far, I've covered nothing that existing articles haven't already done (see <a href="http://www.math.ucsd.edu/~gptesler/184a/slides/184a_ch10.3slides_17-handout.pdf">this</a> or <a href="https://www.geeksforgeeks.org/count-possible-paths-source-destination-exactly-k-edges/">this</a>).</p>
<p>At this point, unfortunately, it's not clear how to proceed with standard approaches. We've already used dynamic programming to reduce unneeded work, and then we even reduced the problem to matrix exponentiation. But how can we perform matrix exponentiation even faster?</p>
<p>One approach when we're stuck is to convert our problem into another abstraction. In this case, a concept that's closely related to matrix exponentiation is linear recurrences.</p>


<p>A linear recurrence is a recurrence like: <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>a</mi><mi>k</mi></msub><mo>=</mo><mn>3</mn><msub><mi>a</mi><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><mn>2</mn><msub><mi>a</mi><mrow><mi>k</mi><mo>−</mo><mn>2</mn></mrow></msub><mo>−</mo><msub><mi>a</mi><mrow><mi>k</mi><mo>−</mo><mn>3</mn></mrow></msub></mrow><annotation encoding="application/x-tex">a_k = 3a_{k-1} + 2a_{k-2} - a_{k-3}</annotation></semantics></math></span></span>. One famous example of a linear recurrence is the Fibonacci series (itself an inexplicably popular interview problem)<sup><a href="#fn2" id="fnref2">[2]</a></sup>. The linear recurrence for Fibonacci can be written as <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mi>k</mi></msub><mo>=</mo><msub><mi>A</mi><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>A</mi><mrow><mi>k</mi><mo>−</mo><mn>2</mn></mrow></msub></mrow><annotation encoding="application/x-tex">A_k = A_{k-1} + A_{k-2}</annotation></semantics></math></span></span>. The order of a linear recurrence is the number of terms it depends on. So, the first example would have order 3, and Fibonacci would have order 2.</p>
<p>How are linear recurrences tied to matrix exponentiation? Well, you might know that finding the <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span></span>-th Fibonacci number can be done in <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>K</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\log(K)</annotation></semantics></math></span></span> time using <a href="https://www.nayuki.io/page/fast-fibonacci-algorithms">matrix exponentiation</a>. In fact, this is a special case of the more general algorithm to find the <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span></span>-th term of any order <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span></span> linear recurrence using matrix exponentiation in <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>N</mi><mn>3</mn></msup><mi>log</mi><mo>⁡</mo><mi>K</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(N^3 \log K)</annotation></semantics></math></span></span> time. This is a <a href="https://community.topcoder.com/tc?module=Static&amp;d1=features&amp;d2=010408">good resource if you're unfamiliar</a>.</p>
<p>So, we can convert a linear recurrence problem to a matrix exponentiation problem. Clearly, there is some connection here. Sadly, as we currently have a matrix exponentiation problem, this doesn't immediately help. Could we be lucky enough to have a way to turn a matrix exponentiation problem into a linear recurrence problem?</p>


<p><a href="https://en.wikipedia.org/wiki/Cayley%E2%80%93Hamilton_theorem">Wikipedia</a> writes that</p>
<blockquote>
<p>If A is a given n×n matrix and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>I</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">I_n</annotation></semantics></math></span></span>  is the n×n identity matrix, then the characteristic polynomial of A is defined as<br>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mstyle scriptlevel="0" displaystyle="true"><mi>p</mi><mo stretchy="false">(</mo><mi>λ</mi><mo stretchy="false">)</mo><mo>=</mo><mi>det</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>λ</mi><msub><mi>I</mi><mi>n</mi></msub><mo>−</mo><mi>A</mi><mo stretchy="false">)</mo><mtext>&nbsp;</mtext></mstyle></mrow><annotation encoding="application/x-tex">{\displaystyle p(\lambda )=\det(\lambda I_{n}-A)~}</annotation></semantics></math></span></span></span></p>
</blockquote>
<p>Not immediately helpful (to me at least). However, several lines down we see that</p>
<blockquote>
<p>The [Cayley Hamilton] theorem allows A^n to be expressed as a linear combination of the lower matrix powers of A.</p>
</blockquote>
<p>In other words, we know that this equation holds true for some values of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span></span>.</p>
<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msup><mi>A</mi><mi>n</mi></msup><mo>=</mo><msub><mi>x</mi><mn>0</mn></msub><mi>I</mi><mo>+</mo><msub><mi>x</mi><mn>1</mn></msub><mi>A</mi><mo>+</mo><msub><mi>x</mi><mn>2</mn></msub><msup><mi>A</mi><mn>2</mn></msup><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">A^n = x_0I + x_1A + x_2A^2 ...</annotation></semantics></math></span></span></span></p>
<p>In other words, we are <strong>guaranteed</strong> that the powers of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span></span> form a linear recurrence! This is not obvious at all, but it does highlight some of the powers of math. Good job, Cayley Hamilton.<sup><a href="#fn3" id="fnref3">[3]</a></sup></p>
<p>Now that we know that matrix exponentiation problems can be converted to a linear recurrence problem, this doesn't help us unless we can calculate the k-th term of a linear recurrence faster than we compute the k-th power of a matrix. So... can we?</p>
<p>As you may have inferred, yes! But to do so, we must first take a small detour into polynomials and generating functions.</p>
<h4 id="polynomials-and-generating-functions">Polynomials and Generating Functions</h4>

<p>Let's define a (kinda weird) function <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi></mrow><annotation encoding="application/x-tex">G</annotation></semantics></math></span></span>, which takes in a polynomial and replaces <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>x</mi><mi>k</mi></msup></mrow><annotation encoding="application/x-tex">x^k</annotation></semantics></math></span></span> with the <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span>-th term in our linear recurrence. More formally, given a polynomial <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mo>∑</mo><msub><mi>c</mi><mi>i</mi></msub><msup><mi>x</mi><mi>i</mi></msup></mrow><annotation encoding="application/x-tex">f(x) = \sum c_i x^i</annotation></semantics></math></span></span>, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><mi>f</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">G(f)</annotation></semantics></math></span></span> returns <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>∑</mo><msub><mi>c</mi><mi>i</mi></msub><msub><mi>a</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\sum c_i a_i</annotation></semantics></math></span></span>.</p>
<p>So, for Fibonacci, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mn>0</mn></msup><mo stretchy="false">)</mo><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">G(x^0)=1</annotation></semantics></math></span></span>, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mn>1</mn></msup><mo stretchy="false">)</mo><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">G(x^1) = 1</annotation></semantics></math></span></span>, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mn>2</mn></msup><mo stretchy="false">)</mo><mo>=</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">G(x^2) = 2</annotation></semantics></math></span></span>, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mn>3</mn></msup><mo stretchy="false">)</mo><mo>=</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">G(x^3)=3</annotation></semantics></math></span></span>, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mn>4</mn></msup><mo stretchy="false">)</mo><mo>=</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">G(x^4)=5</annotation></semantics></math></span></span>, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mn>5</mn></msup><mo stretchy="false">)</mo><mo>=</mo><mn>8</mn></mrow><annotation encoding="application/x-tex">G(x^5)=8</annotation></semantics></math></span></span>, and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mi>k</mi></msup><mo stretchy="false">)</mo><mo>=</mo><mi>k</mi></mrow><annotation encoding="application/x-tex">G(x^k) = k</annotation></semantics></math></span></span>-th Fibonacci element (ie: <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">A_k</annotation></semantics></math></span></span>). <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mn>2</mn></msup><mo>+</mo><msup><mi>x</mi><mn>3</mn></msup><mo stretchy="false">)</mo><mo>=</mo><msub><mi>A</mi><mn>2</mn></msub><mo>+</mo><msub><mi>A</mi><mn>3</mn></msub><mo>=</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">G(x^2 + x^3) = A_2 + A_3 = 5</annotation></semantics></math></span></span>. Finally, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi></mrow><annotation encoding="application/x-tex">G</annotation></semantics></math></span></span> is also a linear function, which means that <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><mi>f</mi><mo>+</mo><mi>g</mi><mo stretchy="false">)</mo><mo>=</mo><mi>G</mi><mo stretchy="false">(</mo><mi>f</mi><mo stretchy="false">)</mo><mo>+</mo><mi>G</mi><mo stretchy="false">(</mo><mi>g</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">G(f+g) = G(f) + G(g)</annotation></semantics></math></span></span>.</p>
<p>Some more examples:<br>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mn>2</mn></msup><mo>+</mo><mn>2</mn><msup><mi>x</mi><mn>3</mn></msup><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>=</mo><mi>G</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mn>3</mn></msup><mo>+</mo><mn>2</mn><msup><mi>x</mi><mn>4</mn></msup><mo stretchy="false">)</mo><mo>=</mo><msub><mi>A</mi><mn>3</mn></msub><mo>+</mo><mn>2</mn><msub><mi>A</mi><mn>4</mn></msub><mo>=</mo><mn>3</mn><mo>+</mo><mn>2</mn><mo>⋅</mo><mn>5</mn><mo>=</mo><mn>13</mn></mrow><annotation encoding="application/x-tex">G(x(x^2 + 2x^3)) = G(x^3 + 2x^4) = A_3 + 2A_4 = 3 + 2\cdot 5 = 13</annotation></semantics></math></span></span></span><br>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mn>20</mn></msup><mo>+</mo><mn>3</mn><mo stretchy="false">)</mo><mo>=</mo><msub><mi>A</mi><mn>20</mn></msub><mo>+</mo><mn>3</mn><msub><mi>A</mi><mn>0</mn></msub><mo>=</mo><mn>6765</mn><mo>+</mo><mn>3</mn><mo>=</mo><mn>6768</mn></mrow><annotation encoding="application/x-tex">G(x^{20} + 3) = A_{20} + 3A_0 = 6765 + 3 = 6768</annotation></semantics></math></span></span></span></p>
<p>If someone gave us a magical black box to evaluate <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi></mrow><annotation encoding="application/x-tex">G</annotation></semantics></math></span></span>, we could simply evaluate <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mi>k</mi></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">G(x^k)</annotation></semantics></math></span></span> and get our answer! Unfortunately, no such box exists (I wish). If <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span> was small enough, we could compute the terms up to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span> ourselves. But needing to computing the terms up to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span> ourselves puts us back where we started.</p>
<p>Another way we could evaluate <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mi>k</mi></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">G(x^k)</annotation></semantics></math></span></span> is to find a polynomial equivalent to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mi>k</mi></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">G(x^k)</annotation></semantics></math></span></span> and evaluate that instead. And if this polynomial had low degree, then evaluating this function would be easy.</p>
<p>For example, this is one way to find an equivalent polynomial of lower degree:<br>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mn>5</mn></msup><mo stretchy="false">)</mo><mo>=</mo><mi>G</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mn>3</mn></msup><mo>+</mo><msup><mi>x</mi><mn>4</mn></msup><mo stretchy="false">)</mo><mo>=</mo><mi>G</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mn>3</mn></msup><mo>+</mo><mo stretchy="false">(</mo><msup><mi>x</mi><mn>2</mn></msup><mo>+</mo><msup><mi>x</mi><mn>3</mn></msup><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>=</mo><mi>G</mi><mo stretchy="false">(</mo><mn>2</mn><msup><mi>x</mi><mn>2</mn></msup><mo>+</mo><mn>3</mn><msup><mi>x</mi><mn>3</mn></msup><mo stretchy="false">)</mo><mo>=</mo><mn>2</mn><msub><mi>F</mi><mn>2</mn></msub><mo>+</mo><mn>3</mn><msub><mi>F</mi><mn>3</mn></msub><mo>=</mo><mn>8</mn></mrow><annotation encoding="application/x-tex">G(x^5) = G(x^3 + x^4) = G(x^3 + (x^2 + x^3)) = G(2x^2 + 3x^3) = 2F_2 + 3F_3 = 8</annotation></semantics></math></span></span></span></p>
<p>Note that despite the fact that <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><mn>2</mn><msup><mi>x</mi><mn>2</mn></msup><mo>+</mo><mn>3</mn><msup><mi>x</mi><mn>3</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">G(2x^2 + 3x^3)</annotation></semantics></math></span></span> represents <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mn>5</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">G(x^5)</annotation></semantics></math></span></span>, we only needed to know Fibonacci values up to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mn>3</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">G(x^3)</annotation></semantics></math></span></span>.</p>
<p>Thus, if we could easily compute a polynomial <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span></span> with low degree such that <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mi>k</mi></msup><mo stretchy="false">)</mo><mo>=</mo><mi>G</mi><mo stretchy="false">(</mo><mi>h</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">G(x^k) = G(h)</annotation></semantics></math></span></span>, we would be done! In order to do so, however, we need one final detour into the ominously named "annihilator" polynomials.</p>


<p>An annihilator is a non-zero polynomial <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span></span> such that <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><mi>f</mi><mo stretchy="false">)</mo><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">G(f) = 0</annotation></semantics></math></span></span>. On Fibonacci, for example, examples of annihilators would be <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>x</mi><mn>3</mn></msup><mo>−</mo><msup><mi>x</mi><mn>2</mn></msup><mo>−</mo><msup><mi>x</mi><mn>1</mn></msup></mrow><annotation encoding="application/x-tex">x^3 - x^2 - x^1</annotation></semantics></math></span></span> or <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>x</mi><mn>6</mn></msup><mo>−</mo><msup><mi>x</mi><mn>5</mn></msup><mo>−</mo><msup><mi>x</mi><mn>4</mn></msup></mrow><annotation encoding="application/x-tex">x^6 - x^5 - x^4</annotation></semantics></math></span></span>. Remember that <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi></mrow><annotation encoding="application/x-tex">G</annotation></semantics></math></span></span> turns polynomial terms into Fibonacci terms. So, plugging in the last annihilator into <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi></mrow><annotation encoding="application/x-tex">G</annotation></semantics></math></span></span> provides us <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><msup><mi>x</mi><mn>6</mn></msup><mo>−</mo><msup><mi>x</mi><mn>5</mn></msup><mo>−</mo><msup><mi>x</mi><mn>4</mn></msup><mo stretchy="false">)</mo><mtext>  </mtext><mo>⟹</mo><mtext>  </mtext><msub><mi>F</mi><mn>6</mn></msub><mo>−</mo><msub><mi>F</mi><mn>5</mn></msub><mo>−</mo><msub><mi>F</mi><mn>4</mn></msub><mo>=</mo><mn>0</mn><mtext>  </mtext><mo>⟹</mo><mtext>  </mtext><msub><mi>F</mi><mn>6</mn></msub><mo>=</mo><msub><mi>F</mi><mn>4</mn></msub><mo>+</mo><msub><mi>F</mi><mn>5</mn></msub></mrow><annotation encoding="application/x-tex">G(x^6 - x^5 - x^4) \implies F_6 - F_5 - F_4 = 0 \implies F_6 = F_4 + F_5</annotation></semantics></math></span></span>. In other words, the 6th Fibonacci term is equal to the 5th and 4th Fibonacci terms added together.</p>
<p>Note that the last statement is clearly true. After all, that's the definition of Fibonacci.</p>
<p>This observation leads to an easy way of generating annihilators: We just use the definition of our linear recurrence! If the n-th term of our linear recurrence is some combination of the previous terms, then the n-th term minus those previous terms is equal to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span></span>.</p>
<p>For illustration, let's take the linear recurrence <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>a</mi><mi>n</mi></msub><mo>=</mo><msub><mi>a</mi><mrow><mi>n</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>−</mo><mn>2</mn><msub><mi>a</mi><mrow><mi>n</mi><mo>−</mo><mn>2</mn></mrow></msub><mo>+</mo><mn>3</mn><msub><mi>a</mi><mrow><mi>n</mi><mo>−</mo><mn>3</mn></mrow></msub></mrow><annotation encoding="application/x-tex">a_n = a_{n-1} - 2a_{n-2} + 3a_{n-3}</annotation></semantics></math></span></span>. Specifically, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>a</mi><mn>3</mn></msub><mo>=</mo><msub><mi>a</mi><mn>2</mn></msub><mo>−</mo><mn>2</mn><msub><mi>a</mi><mn>1</mn></msub><mo>+</mo><mn>3</mn><msub><mi>a</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">a_3 = a_2 - 2a_1 + 3a_0</annotation></semantics></math></span></span>. This implies that <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>a</mi><mn>3</mn></msub><mo>−</mo><msub><mi>a</mi><mn>2</mn></msub><mo>+</mo><mn>2</mn><msub><mi>a</mi><mn>1</mn></msub><mo>−</mo><mn>3</mn><msub><mi>a</mi><mn>0</mn></msub><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">a_3 - a_2 + 2a_1 - 3a_0 = 0</annotation></semantics></math></span></span>. Thus, one …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://horace.io/walks.html">http://horace.io/walks.html</a></em></p>]]>
            </description>
            <link>http://horace.io/walks.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25985890</guid>
            <pubDate>Mon, 01 Feb 2021 05:41:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When to Use Vue over React]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25985888">thread link</a>) | @hactually
<br/>
January 31, 2021 | https://michaeltimbs.me/when-to-use-vue-over-react/ | <a href="https://web.archive.org/web/*/https://michaeltimbs.me/when-to-use-vue-over-react/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>A highly opinionated article based on my experience as a front-end web developer over the last four years.</p>
<p>I use <a href="https://reactjs.org/">React</a> professionally at my current job, but I choose <a href="https://vuejs.org/">Vue</a> for all personal projects. It’s my preferred framework of choice. I’ve used Vue in previous (publicly traded) companies, and it scaled incredibly well.</p>
<p>Any seasoned developer will tell you software is all about trade-offs and throwing around objective statements like “Framework x is better than Framework y” are generally meaningless. By what metrics? In whose opinion? For this reason, I’ll compare Vue and React across three main concerns that are often competing trade-offs.</p>
<ol>
<li>Performance</li>
<li>Scalability</li>
<li>Job Market</li>
</ol>
<h2>Performance</h2>
<p>Performance is usually where people want to start when discussing frameworks or languages. Everyone who writes software is building the next FAANG company, and every nanosecond of performance must be extracted from our code.</p>
<p>I’m going to compare both frameworks on two components of performance, namely silicon time and carbon time. <em>Silicon time</em> refers to the raw execution performance — how fast it can run in the browser. <em>Carbon time</em> refers to how fast developers can build products in the code.</p>
<h3>Silicon-time comparison</h3>
<p><span>
      <a href="https://michaeltimbs.me/static/2eb2e4fd514290eb574580d5a9c2cfd9/50e7d/framework-perf-tradeoffs.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="JS framework trade-offs for performance" title="JS framework trade-offs for performance" src="https://d33wubrfki0l68.cloudfront.net/47139e95f26c14568aeaf97616a53b2663e6fa3d/65e58/static/2eb2e4fd514290eb574580d5a9c2cfd9/2a195/framework-perf-tradeoffs.png" srcset="https://d33wubrfki0l68.cloudfront.net/71e8f312d39cb583a83b4501f34069bc5cffd7b2/f6af9/static/2eb2e4fd514290eb574580d5a9c2cfd9/158c9/framework-perf-tradeoffs.png 155w,
https://d33wubrfki0l68.cloudfront.net/058b9d544c7568bcb687e0811ccf6dc66183e78f/3b7d7/static/2eb2e4fd514290eb574580d5a9c2cfd9/5fad2/framework-perf-tradeoffs.png 310w,
https://d33wubrfki0l68.cloudfront.net/47139e95f26c14568aeaf97616a53b2663e6fa3d/65e58/static/2eb2e4fd514290eb574580d5a9c2cfd9/2a195/framework-perf-tradeoffs.png 620w,
https://d33wubrfki0l68.cloudfront.net/5299bc393d5ad765c84310fddb0920581eb78587/a14eb/static/2eb2e4fd514290eb574580d5a9c2cfd9/416ee/framework-perf-tradeoffs.png 930w,
https://d33wubrfki0l68.cloudfront.net/f05d4eda630989d60b934c5b17420e8f3cdd3203/45eaf/static/2eb2e4fd514290eb574580d5a9c2cfd9/7a4b2/framework-perf-tradeoffs.png 1240w,
https://d33wubrfki0l68.cloudfront.net/92d1b36a76d2c9d6ec32ab081ab456b3c944b254/7e6f5/static/2eb2e4fd514290eb574580d5a9c2cfd9/50e7d/framework-perf-tradeoffs.png 1738w" sizes="(max-width: 620px) 100vw, 620px" loading="lazy">
  </a>
    </span><em>JS framework trade-offs for performance</em></p>
<p>React leverages JSX, which gives developers a lot of power to build arbitrarily complex logic. We can harness the Turing-complete power of JavaScript and treat our view as data. Something like Svelte leverages templates for markup that provide a rigid structure to the view layer.</p>
<p>React and Vue both use a <a href="https://stackoverflow.com/questions/21965738/what-is-virtual-dom">virtual DOM</a> (VDOM), which, while practically fast enough, is inherently expensive and <a href="https://svelte.dev/blog/virtual-dom-is-pure-overhead">almost purely overhead</a>. Svelte compiles template code to raw JS and manipulates the DOM directly, which means it doesn’t have the performance overheads of maintaining a VDOM.</p>
<p>What I love about Vue is it hedges its bets a little bit. The most common way to use Vue is to use templates in <a href="https://vuejs.org/v2/guide/single-file-components.html">single-file components</a>. This has allowed the Vue team to do some very clever things in the upcoming Vue 3 release with ahead-of-time (AOT) optimisations.</p>
<p>The structured nature of a templates means a compiler can know things about your code and perform optimisations. The main optimisation Vue introduces is dropping all static data from the VDOM diff. VDOM performance is directly affected by the number of nodes it has to track. By filtering out static data from this VDOM-diffing process, we can reduce the number of nodes being tracked. This makes the code run much faster as it doesn’t have to compare a recursive tree of arbitrary nodes at each render cycle.</p>
<p>While Vue appears to use templates in most cases, the compiler actually turns these templates into <a href="https://vuejs.org/v2/guide/render-function.html">render functions</a> for you under the hood. This means any time the templating of Vue is getting in your way, you can directly drop down and write render functions exactly like you would in React. This means you get all the flexibility of render functions and JSX that you get in React with some of the performance benefits you get from a templated framework like Svelte. Obviously, if you write a Vue application with 100% render functions, you lose all of the template optimisations.</p>
<p>Code benchmarks are a bit of a waste of time, in my opinion, but a few show Vue 2 around 2.5x faster than default React, and Vue 3 is benchmarking 3-5x faster than Vue 2. In practice, the JS framework you use is going to be such a small component of your application that these benchmarks are nearly meaningless. However, if you’re building templates that’ll leverage Vue 3’s AoT optimisations from templates, there’s just no way the same app will be faster written in React.</p>
<p><strong>Winner: Vue</strong></p>
<h3>Carbon-time performance</h3>
<p><span>
      <a href="https://michaeltimbs.me/static/3da73100deb391d774f1a6e4f1e95c02/599ea/carbon-silicon-time.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Carbon cost versus silicon cost for software development" title="Carbon cost versus silicon cost for software development" src="https://d33wubrfki0l68.cloudfront.net/114d131b506056439904ac59ea89a8cf30d02c3f/c875b/static/3da73100deb391d774f1a6e4f1e95c02/2a195/carbon-silicon-time.png" srcset="https://d33wubrfki0l68.cloudfront.net/e70ce6273e8d875734d9c2de8f95812c7c3d1941/3c9ca/static/3da73100deb391d774f1a6e4f1e95c02/158c9/carbon-silicon-time.png 155w,
https://d33wubrfki0l68.cloudfront.net/339310ece365efa3674e27b224e30be3c8490b5c/de697/static/3da73100deb391d774f1a6e4f1e95c02/5fad2/carbon-silicon-time.png 310w,
https://d33wubrfki0l68.cloudfront.net/114d131b506056439904ac59ea89a8cf30d02c3f/c875b/static/3da73100deb391d774f1a6e4f1e95c02/2a195/carbon-silicon-time.png 620w,
https://d33wubrfki0l68.cloudfront.net/82dbbf5f6eed42acc48f78671017fe3727007716/e4234/static/3da73100deb391d774f1a6e4f1e95c02/416ee/carbon-silicon-time.png 930w,
https://d33wubrfki0l68.cloudfront.net/e109f9298665387c5a117300e01fa8ae825ad130/f5b32/static/3da73100deb391d774f1a6e4f1e95c02/7a4b2/carbon-silicon-time.png 1240w,
https://d33wubrfki0l68.cloudfront.net/789c23396ca0e59c7b62624fb264a311fa4107e0/96a70/static/3da73100deb391d774f1a6e4f1e95c02/599ea/carbon-silicon-time.png 1926w" sizes="(max-width: 620px) 100vw, 620px" loading="lazy">
  </a>
    </span><em>Carbon cost versus silicon cost for software development</em></p>
<p>A senior developer will cost you around $150/hr depending on where you are in the world. Even junior to midlevel developers are earning a good enough salary that you want to be factoring in development time and costs into your technical stack. It’s the reason why languages such as PHP, Python, Node, Ruby, etc. are so popular and we don’t just write everything in C.</p>
<p>For front-end applications, we’re constrained by the browser, device resources, and network latency, so silicon performance is still a contributing factor — but carbon performance should also be at the forefront of any CTO’s mind.</p>
<p>In my opinion, the single greatest contributing factor in the success of Vue has been its approachable documentation, resources, and ease of learning. I learned React and Vue at the same time, and Vue was noticeably easier to get started with. If you know HTML, CSS, and the bare basics of JS, you can build an application with Vue. I’ve spent half a day with a design team and had them shipping changes to production front ends in Vue. This frees up a lot of time for the dev team and allows designers to implement A/B tests and design updates without getting blocked by the software backlog.</p>
<p>One of the things I love about Vue is the layered design of its opt-in tooling. You can start by pulling in Vue via a CDN. That means you can play with it without needing to go through complex build steps (webpack/Babel config, npm, etc). You can then progress to the Vue CLI and build basic apps. If you then need a state management solution, there’s an officially supported and documented solution in Vuex. Similarly, Vue Router is an officially endorsed and supported router solution for Vue.</p>
<p>On the other hand, React introduces the <a href="https://en.wikipedia.org/wiki/The_Paradox_of_Choice">paradox of choice,</a> which can make things hard for newcomers.</p>
<p>React is a small-scope, single-purpose library that introduces a component model that receives props and returns a VDOM tree. This provides a lot of flexibility and the React community has built many complex systems on top of this simple library.</p>
<p>There’s a large ecosystem with many, many options available to solve tasks. These are maintained independently by users. This model provides a lot of opportunities for people to build things on top of React and build popular libraries and tools.</p>
<p>It also makes things very difficult to find and learn. You’re stuck choosing the best option for state management or routing or configuring a new application. In my experience, this also makes hiring React developers harder. When there’s multiple ways to do things, onboarding new members to a React project has more friction than onboarding to a Vue project.</p>
<p><strong>Winner: Vue</strong></p>
<h2>Scalability</h2>
<p>Most of my thoughts on the scalability of these frameworks was touched on in the performance section. Scalability is often intrinsically linked with performance, so it’s not surprising.</p>
<p>I generally think of scalability in terms of:</p>
<h3>Scaling the number of views/components/workflows in an application</h3>
<p>In terms of scaling out the number of components, I’m a really big fan of the single-file component (SFC). The logical grouping of a component makes a lot of sense to me. Many people disagree with this, and it’s a matter of opinion rather than an objective statement.</p>
<p>The reason I love SFCs is because they provides a great way to enforce the <a href="https://blog.cleancoder.com/uncle-bob/2014/05/08/SingleReponsibilityPrinciple.html">separation of concerns</a> (SoC).* *Some people argue that mixing HTML, CSS, and JavaScript is doing the opposite of separating concerns. I’ve changed the way I think about this principle on the front end, largely with my obsessive adoption of <a href="https://tailwindcss.com/">Tailwind CSS</a> for styling my components.</p>
<p>Adam Wathan wrote a <a href="https://adamwathan.me/css-utility-classes-and-separation-of-concerns/">great article</a>on the notion of SoC and how it applies to HTML and CSS. I think about my front-end components in a similar way. In my mind, a component is how it looks (HTML/CSS) <em>and</em> how it works. Separating the markup from the JS feels arbitrary to me. If you consider your views as data, then (to me) it makes sense to group them with your data.</p>
<p>Don’t even get me started on JSX and CSS-in-JS. HTML and CSS are not dead. They’re incredibly powerful building blocks of the web. Use them!</p>
<p>The benefits of officially supported solutions to common problems also comes in handy at scale. If you’re having trouble scaling a Vue application, then chances are any other Vue application at scale has used the same architecture, and you’ll be able to find advice and help. You don’t need to worry about people saying, “Just use hooks/<a href="https://mobx.js.org/README.html">MobX</a>/<a href="https://medium.com/p/9a4e0f01e064/edit">Redux</a>/<a href="https://redux-saga.js.org/">Redux-Saga</a>.”</p>
<h3>Scaling the number of developers on a team</h3>
<p>I’ve already mentioned I’ve previously seen a design team empowered to push changes to production with a few hours of help. That’s an insane productivity boost to any consumer-facing application.</p>
<p>The general consensus that Vue is easier to learn also means you can train junior developers to a point of net benefit to the team much much faster. You can also onboard a React developer (assuming they know HTML and CSS) with little effort.</p>
<p>Again, having consistent solutions to common problems makes code review and reasoning about a large codebase that much easier for everyone on the team.</p>
<p>The key thing with both of these is maintaining development velocity while keeping a performant application that meets the needs of your users. Vue strikes the perfect balance here as far as I’m concerned.</p>
<p><strong>Winner: Vue</strong></p>
<h2>The Job Market</h2>
<p>OK, so I’ve convinced you Vue is better than React in every conceivable way. But this is meaningless if you can’t get paid (or find devs to hire).</p>
<p>React has a much higher share of the job market (at least in Australia and the United States). If you look on most job boards, the number of React jobs advertised relative to Vue is significant (nearly 8x as many React jobs at the time of writing this based on 10 seconds of job-board searches).</p>
<p>While React appears to win on this metric, I refuse to let React get points on the board, so I’ll make the following (water-tight, unassailable) argument.</p>
<p>There are opportunities for both React and Vue in the job market. Companies using Vue or React both find it difficult to hire, and, in my experience, there’s a skills shortage for both. As someone looking for work, you can achieve mastery (or perceived mastery) of Vue much …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://michaeltimbs.me/when-to-use-vue-over-react/">https://michaeltimbs.me/when-to-use-vue-over-react/</a></em></p>]]>
            </description>
            <link>https://michaeltimbs.me/when-to-use-vue-over-react/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25985888</guid>
            <pubDate>Mon, 01 Feb 2021 05:41:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Reshaped Mac Experience]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25985859">thread link</a>) | @todsacerdoti
<br/>
January 31, 2021 | http://morrick.me/archives/9150 | <a href="https://web.archive.org/web/*/http://morrick.me/archives/9150">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<p>Yesterday, a short <a href="https://twitter.com/lapcatsoftware/status/1355514848717791234">Twitter thread</a> by the excellent <a href="https://lapcatsoftware.com/articles/">Jeff Johnson</a> caught my eye. Since he often deletes past tweets, I’ll quote the relevant ones here (emphasis mine):</p>
<blockquote><p><strong>The selling point of the Macintosh was never the hardware, it was the user interface. So if the selling point now is the hardware, that’s a damning indictment of the current user interface.</strong></p>

<p><strong>I cannot emphasize enough how everyone seems to have lowered their standards with regard to the user interface.</strong> The “<a href="https://en.wikipedia.org/wiki/Overton_window">Overton window</a>” has moved. The Overton window now has rounded rects.</p>

<p>We’ve gone from “insanely great” and “It just works” to “Catalyst is good enough for most people.”</p>
<p>That’s fucking BS, and I won’t tolerate it.</p>

<p>Windows is “good enough for most people”. That’s why Windows has a 90% market share. Why should we aspire to that level, shouldn’t we have much higher aspirations? Mac is a niche. “Most people” are not even using Macs, so the majority is not even relevant. Mac is a premium brand.</p>

<p>The way I see it, the Mac now is merely milking the brand reputation and loyalty it previously built. That Jobs previously built. But neither Cook nor the current Mac deserves that reputation or loyalty.</p>

<p>Steve Jobs wasn’t an engineer. Not a hardware engineer, not a software engineer. At Apple, his role was as “proxy” for the&nbsp;users.</p>
<p>Apple no longer has a proxy for the users. Tim Cook is a proxy for the shareholders, nothing more.</p></blockquote>
<p>Jeff himself says that this criticism is hardly new, that these are things he already pointed out “a thousand times, to no effect”. While I am in no position to affect Apple or Mac development, this short Twitter rant had the effect of reminding me of something I, too, believe in; something I myself should emphasise more frequently. It’s those first two tweets I’ve quoted above.</p>
<p>As someone who still puts vintage Macs and older computers and devices to good use, the Mac’s user interface and user experience are in large part what still makes using 15–20-year-old machines enjoyable. This, by the way, also applies to other products of course. It’s thanks to well-designed user interfaces that we enjoy driving a classic car, or shooting with a 50-year-old film camera, or listening to vinyl records on a 40-year-old record-player and hi-fi stereo.</p>
<p>A couple of weeks ago I was on a group videochat with some friends and when I said that, frankly, using my 12-inch PowerBook G4 (2003) with Mac OS X 10.5 Leopard was more enjoyable than using my 13-inch retina MacBook Pro (2015) with Mac OS 11 Big Sur, the common reaction was that I was just being ‘nostalgic’; that surely my MacBook Pro was the better choice because it is orders of magnitude faster, with a ‘more modern’ OS, and that the sum of those parts was a better Mac experience. That I should ‘be rational’ and accept that.</p>
<p>Here, bringing up nostalgia is missing the point. And the point is that an admittedly faster hardware plus a purportedly ‘more modern’ operating system <em>do not necessarily</em> equal a better Mac experience. It’s interesting that my friends’ reaction was not to ask me <em>why</em> I was finding using an 18-year-old machine more enjoyable than an up-to-date Mac, but to promptly want to readjust my enjoyment, implying that there was something ‘wrong’ with&nbsp;it.</p>
<p>I’m finding that many people not only have lowered their standards with regard to the user interface, but more and more often when I bring up the subject, they seem to consider it a somewhat secondary aspect, something that’s only good for ‘geek talk’. The same kind of amused reaction laymen have to wine or coffee connoisseurs when they describe flavours and characteristics using specific lingo. Something that makes sense only to wine or coffee geeks but has little to no meaning or impact for the regular person.</p>
<p>The problem is that if an increasing number of people start viewing user interface design as an afterthought, or something that isn’t fundamental to the design of a product or experience — it’s all just ‘geek talk’ — then there is a reduced incentive to care about it on the part of the maker of the product. It’s more like a vicious circle, really; if Apple software’s quality declines but only a bunch of professional users and enthusiasts point that out, then Apple isn’t particularly incentivised to do a better job at it — the “good enough for most people” is really a dangerous, self-indulgent excuse. And in turn most people are fine with it, and in turn Apple think they’re on a ‘good’ path, and so&nbsp;forth.</p>
<p>At the very end of my piece <a href="http://morrick.me/archives/9141"><em> What about the M1 Macs?</em></a>, I&nbsp;wrote:</p>
<blockquote><p>They’re unbelievably good machines, and everything that is genuinely good about them and future Apple Silicon-based Macs — sheer performance, astounding power-efficiency, and great backward compatibility with Intel software thanks to Rosetta 2 — will also allow Apple to get away with a lot of things with regard to platform control, design decisions, and so&nbsp;forth.</p></blockquote>
<p>If you take a look at Jason Snell’s <a href="https://sixcolors.com/post/2021/01/apple-in-2020-the-six-colors-report-card/"><em>Apple in 2020: The Six Colors report card</em></a>, the Mac scored very good points overall, 4.7 out of 5, with a year-over-year increment of 1.1 points. The main reason has been of course the M1 Macs and Apple Silicon. Don’t get me wrong, Apple Silicon <em>is</em> groundbreaking, and Rosetta 2 is really an incredible performer on the software side. But what I contend is that a leap in hardware architecture and performance doesn’t necessarily mean that suddenly all is fine with the Mac as a platform or as an experience.</p>
<p>The Mac’s user interface is undergoing plastic surgery by the hand of surgeons who have studied on iOS books. The result is pretty much the same as when you see a favourite celebrity after a procedure. They look ‘younger’ but there’s also something weird about their appearance. Their traits have changed a bit. In certain cases you almost fail to recognise the person at first glance.</p>
<p>Similarly, the Mac experience today feels disjointed. The hardware has unquestionably improved with the introduction of Apple Silicon, and yes, it’s something worth celebrating and it’s something worth praising. On the other hand, the software that drives this hardware is a bit of a paradox: Big Sur and Apple Silicon Macs fit and work together well from a technical, architectural standpoint. From a user interface standpoint, however, Big Sur embodies what I’ve been fearing in recent years — a progressive iOS-ification of Mac OS. Big Sur provides a general user experience that is the least Mac-like in the history of the Mac. Going through Big Sur’s user interface with a fine-tooth comb reveals arbitrary design decisions that prioritise looks over function, and therefore reflect an un-learning of tried-and-true user interface and usability mechanics that used to make for a seamless, thoughtful, enjoyable Mac experience.</p>
<p>iOS was born as a ‘spinoff’ of Mac OS X, a sort of Lite version aimed at mobile devices like the iPhone and the iPod touch. The two platforms have maintained their separate paths and trajectories for years, and for a while using a Mac and an iPhone (or iPad) felt like having the best experience of each world. Then Apple became obsessed with thoughts of convergence, and features, UI ideas, paradigms, started bleeding through both platforms and in turn the respective experiences have become less clear-cut over time, with the software not fully capable of bringing out all that hardware power and potential.</p>
<p>This convergence will continue, of course, with Macs becoming more and more like ‘senior iOS devices’ from a UI and user experience standpoint. It seems clear to me that Apple is prioritising ecosystem experience because, let’s be honest, having a unified ‘operating system core’ underlying all platforms means having fewer framework-specific headaches and probably a faster, streamlined process when deploying new features. But this loss of differentiation is especially detrimental to Mac OS, which is being reduced to the lowest common denominator and loses an increasing amount of user interface ideas and conventions that were central to its superior user experience and ease of&nbsp;use.</p>
<p>I’m not annoyed because I see pieces of UI history fading away. I’m annoyed because I see pieces of <em>good</em> UI design fading away and being replaced by decisions that are puzzling and arbitrary, or the product of a trial-and-error process, rather than a meaningful, purposeful design.</p>
<p>You want an example that I find particularly glaring? Big Sur’s UI features a general increase of space between elements — icons, menus, labels, toolbars, sidebars, pretty much everywhere. On the surface it doesn’t seem like a bad decision. If you zoom in on certain parts of the user interface, you could say that more space between elements means that things looks cleaner, airier, sleeker.</p>
<p>But you’re looking at it on a 27-inch retina display. What about a display half that size? What about an 11-inch, non-retina display, like the one of the older 2013–2015 MacBook Airs that can be updated to Big Sur? It’s less pretty.</p>
<p><a href="https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png"><img loading="lazy" src="https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?resize=960%2C600" alt="" width="960" height="600" srcset="https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?w=2560 2560w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?resize=260%2C163 260w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?resize=640%2C400 640w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?resize=768%2C480 768w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?resize=1536%2C960 1536w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?resize=2048%2C1280 2048w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?resize=1194%2C746 1194w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?w=1920 1920w" sizes="(max-width: 960px) 100vw, 960px" data-recalc-dims="1"></a></p>
<p>I usually work with a lot of app windows and Finder windows, but when I’m using my 13-inch retina MacBook Pro with Big Sur, the workspace constantly feels cramped, while on the other hand I have no problems using High Sierra on my 11-inch MacBook Air. Sometimes it feels like looking at a zoomed-in interface. That increased space between elements becomes less of a good idea because it doesn’t scale gracefully when the overall screen real estate is reduced. It becomes an interference. Before installing Big Sur, the amount of icons on the right of the menu bar had never really been a concern. Now, the simple addition of a couple of third-party apps like Dropbox and iStat Menus — both essential for me — is enough to make that menu bar look crowded. (And thankfully Apple has been reducing the space between menu icons, because in the first Big Sur betas icon padding was so bad I had to remove a few icons and use Control Centre to check on their status).</p>
<p>This, like other UI design decisions in Big Sur, feels like …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://morrick.me/archives/9150">http://morrick.me/archives/9150</a></em></p>]]>
            </description>
            <link>http://morrick.me/archives/9150</link>
            <guid isPermaLink="false">hacker-news-small-sites-25985859</guid>
            <pubDate>Mon, 01 Feb 2021 05:35:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[This is How Google will Collapse (2017)]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 31 (<a href="https://news.ycombinator.com/item?id=25985843">thread link</a>) | @partingshots
<br/>
January 31, 2021 | https://www.googliath.org/this-is-how-google-will-collapse-by-daniel-colin-james/ | <a href="https://web.archive.org/web/*/https://www.googliath.org/this-is-how-google-will-collapse-by-daniel-colin-james/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
<!-- ARTICAL CONTENT -->
                                                        <h2>Reporting from the very near, post-Google future</h2>
<p>Google made almost all its money from ads. It was a booming business — until it wasn’t. Here’s how things looked right before the most spectacular crash the technology industry had ever seen.<br>
The crumbling of Google’s cornerstone</p>
<p>Search was Google’s only unambiguous win, as well as its primary source of revenue, so when Amazon rapidly surpassed Google as the top product search destination, Google’s foundations began to falter. As many noted at the time, the online advertising industry experienced a major shift from search to discovery in the mid-2010s.</p>
<p>While Google protected its monopoly on the dying search advertising market, Facebook — Google’s biggest competitor in the online advertising space — got on the right side of the trend and dominated online advertising with its in-feed native display advertising.</p>
<p><a href="https://hackernoon.com/how-google-collapsed-b6ffa82198ee" target="_blank" rel="noopener">Read the full article here.</a></p>
                                                    </div></div>]]>
            </description>
            <link>https://www.googliath.org/this-is-how-google-will-collapse-by-daniel-colin-james/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25985843</guid>
            <pubDate>Mon, 01 Feb 2021 05:32:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Create Luck]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25985474">thread link</a>) | @exolymph
<br/>
January 31, 2021 | https://www.swyx.io/create_luck/ | <a href="https://web.archive.org/web/*/https://www.swyx.io/create_luck/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>My entire worldview changed when I realized that <strong>luck can be created</strong>.</p>
<p>More precisely, you can actively <strong>create optimal conditions for lucky things to happen to you</strong>. The more I looked into this, the more I realized that this is not only <em>not</em> a new insight, but successful people have studied this for <em>decades</em> and I am just late to the party.</p>
<p>In this post we'll briefly review the "Literature of Luck", and then I'll end with some personal thoughts on how it could be extended.</p>
<section>
  <h2 id="binary-luck"><a href="#binary-luck">Binary Luck</a></h2>
  <p>Most people have a binary view of luck:</p>
  <p>
    <img src="https://dev-to-uploads.s3.amazonaws.com/i/kgd335km9x3ujfmhxnz7.png" alt="Alt Text">
  </p>
  <p>This is true enough. Some people are born into privilege, some people just win some literal or figurative lottery or other.</p>
  <p>The closing question of every episode of Guy Raz's <a href="https://www.npr.org/podcasts/510313/how-i-built-this">How I Built This</a> podcast asks successful people: <em>"How much of your success is due to skill, and how much is due to luck?"</em></p>
  <p>Those who believe in their own agency answer the former. Others - who've seen people smarter and harder working than them fail - answer the latter. Those who are politically correct cop-out with the half-and-half.</p>
  <p>It can be comforting to subscribe to the binary luck model. If you just got a bad roll of the dice, there's nothing you could do. Your lack of success is not your fault.</p>
  <p>But what if I told you <strong>there are people who have skill at creating luck</strong> for themselves?</p>
</section>
<section>
  <h2 id="luck-surface-area"><a href="#luck-surface-area">Luck Surface Area</a></h2>
  <p>Jason Roberts coined the term "<a href="https://www.codusoperandi.com/posts/increasing-your-luck-surface-area">Luck Surface Area</a>", and it was expanded by <a href="https://www.skmurphy.com/blog/2019/04/03/increase-your-luck-surface-area-to-get-more-customers/">Sean Murphy</a> and popularized by <a href="https://www.perell.com/podcast/patrick-mckenzie-internet-famous">Patrick McKenzie</a>.</p>
  <p>I liken this model of luckiness to a "catchment area" (<a href="https://en.wikipedia.org/wiki/Catchment_area">a term from urban and hydrological geography</a>). Luck is still randomly occurring, but you can position yourself in a way that captures more of it:</p>
  <p>
    <img src="https://dev-to-uploads.s3.amazonaws.com/i/ogbkk8weenqb9nltrl34.png" alt="Alt Text">
  </p>
  <p>Jason has a really simple model of how to grow your LSA - do more things, and tell more people about it. <strong>Doing and Telling</strong>. Already this embodies a more active attitude toward how you can orient your life for more positive random events. It's "<a href="https://www.brainpickings.org/2014/01/29/carol-dweck-mindset/">Fixed vs Growth mindset</a>" adapted for luck.</p>
</section>
<section>
  <h2 id="four-kinds-of-luck"><a href="#four-kinds-of-luck">Four Kinds of Luck</a></h2>
  <p>A parallel, older school of thought dates back to James Austin in 1978 and was repopularized by <a href="https://pmarchive.com/luck_and_the_entrepreneur.html">Marc Andreesen</a> in 2007, then <a href="https://twitter.com/nivi/status/1094940675353784320?lang=en">Naval and Nivi</a> a decade later.</p>
  <p>Here, there are no helpful visuals. James Austin just gives a list of types, and Marc quotes verbatim. <a href="https://twitter.com/naval/status/1093981014920052736">Naval summarizes</a> the 4 kinds of luck as such:</p>
  <blockquote>
    <ol>
      <li>
        <p>Hope luck finds you.</p>
      </li>
      <li>
        <p>Hustle until you stumble into it.</p>
      </li>
      <li>
        <p>Prepare the mind and be sensitive to chances others miss.</p>
      </li>
      <li>
        <p>Become the best at what you do. Refine what you do until this is true. Opportunity will seek you out. Luck becomes your destiny.</p>
      </li>
    </ol>
  </blockquote>
  <p>I've quoted this many times to friends and always had trouble remembering what the 4 types are. I gave it some thought and visualized/organized it as such:</p>
  <p>
    <img src="https://dev-to-uploads.s3.amazonaws.com/i/5ycsicfgoxsvxoyys5ip.png" alt="Alt Text">
  </p>
  <ol>
    <li>
      <p><strong>🌱 Accidental Luck</strong>: You have the same luck as a plant. A plant does not move. Whether or not a plant does well pretty much just depends on where it's seed lands. It's not very interesting since by definition you can't do anything about it, but ofc privilege plays a huge part.</p>
    </li>
    <li>
      <p><strong>🏃🏽‍♀️ Active Luck</strong>: The luck you get from constantly moving around. There's no particular direction in mind, but you're more likely to find something good if you move around and explore instead of stay put and hope. You're more likely to roll a 6 if you roll more dice.</p>
      <blockquote>
        <p>"I have never heard of anyone stumbling on something sitting down." - <a href="https://due.com/blog/keep-going-charles-f-kettering/">Charles Kettering</a></p>
      </blockquote>
      <blockquote>
        <p>"You don’t get extreme results without extreme actions." - <a href="https://sive.rs/extremex">Derek Sivers</a></p>
      </blockquote>
    </li>
    <li>
      <p><strong>💊 Prepared Luck</strong>: The luck you get from noticing that something lucky has happened, that most would miss. The canonical story on this is Alexander Fleming's discovery of penicillin, which was a huge medical breakthrough. The discovery was a total accident (some mold happened to fall in the right spot + Fleming happened to see it + he had a similar experience that was a nonevent 9 years ago), but Fleming was not only "uniquely equipped to observe it" by his background, he took action to confirm the observation.</p>
      <blockquote>
        <p>"Luck is what happens when preparation meets opportunity." - Seneca</p>
      </blockquote>
      <blockquote>
        <p>"Chance favors the prepared mind." - Louis Pasteur</p>
      </blockquote>
      <blockquote>
        <p>"Richard Feynman was fond of giving the following advice on how to be a genius. You have to keep a dozen of your favorite problems constantly present in your mind, although by and large they will lay in a dormant state. Every time you hear or read a new trick or a new result, test it against each of your twelve problems to see whether it helps. Every once in a while there will be a hit, and people will say: “How did he do it? He must be a genius!”" - <a href="http://themattheweffect.org/tag/richard-feynman/">Gian-Carlo Rota</a></p>
      </blockquote>
    </li>
    <li>
      <p><strong>🧲 Magnetic Luck</strong>: <em>"Chance IV comes to you, unsought, because of who you are and how you behave."</em> All sources call it "individualized action" but I've renamed it "magnetic luck" to emphasize the end result rather than how you get there. I'm quite familiar with this as <a href="https://www.swyx.io/writing/learning-gears/#miner">the "Miner" gear of my Learning Gears</a> terminology (since updated to 4 gears in <a href="https://learninpublic.org/">my book</a>). This was already a thing pre-Internet, but search and social media have given tremendous reach and influence to the oddballs and obsessives that become the spiritual leaders of every idea and purpose both big and niche.</p>
    </li>
  </ol>
  <p>I find the 4 of these hard to remember, so I've organized them along two axes - <strong>active vs passive</strong>, and <strong>general vs individual</strong>. The first axis is the same realization as "Luck Surface Area" - you actually have the power to do things to create more luck than you were given.</p>
  <p>The second axis is the insight - that there are forms of luck that apply to everyone, and there are forms of luck that are available only to someone in your unique position. There is a you-shaped hole in the universe and you can either passively occupy it or you can become a beacon for some idea or purpose.</p>
</section>
<section>
  <h2 id="habits-and-strategy"><a href="#habits-and-strategy">Habits and Strategy</a></h2>
  <p>I of course find the Four Kinds of Luck very appealing, since I've quoted it so much to friends that I'm writing this post at all. But upon closer reading I think there's a <em>slightly</em> different direction that is unaddressed by the Four Kinds (I originally thought this was embedded in the Four Kinds, only to discover that it wasn't in the source material and I had completely read my own thinking into it).</p>
  <p>
    <img src="https://dev-to-uploads.s3.amazonaws.com/i/poue5zg9homy1eo4ml05.png" alt="Alt Text">
  </p>
  <p>This model differs in two ways. It treats both axes as a spectrum rather than a 2x2. It also focuses more on <strong>actions</strong> (you can take) rather than <strong>classification</strong> (which are a little more abstract). I've also swapped out "Active vs Passive" for "Active Habits" and "Individual vs General" for "Good Strategy". So my version is more about HOW you get more lucky. It's not very actionable to be "more magnetic", but you can Claim a Domain or Hustle and have a good sense of what those things entail.</p>
  <p>I've written about a few of these ideas in prior posts so I won't elaborate:</p>
  <ul>
    <li><a href="https://www.swyx.io/writing/marketing-yourself/">Claiming a Domain, Personal Branding</a></li>
    <li>"Copywork" I wrote about in the "Clone Open Source Apps" chapter of the book</li>
  </ul>
  <p>I think <strong>Exploring</strong> and <strong>Prospecting</strong> are worth elaborating here.</p>
  <p><strong>Exploring</strong> (and to a lesser extent Grinding and Copywork) are <strong>Actively Habitual, non Strategic</strong> activities. But this doesn't mean it is bad. I think this is what you do when you take in general life and career advice and apply them to yourself. You know there are a list of <strong>Principles</strong> which are just generally good things to do in life, and trust that you will do well if you do those things (e.g. <a href="https://www.swyx.io/writing/learn-in-public/">Learn in Public</a>). Keep doing the "right" things, and "trust the process".</p>
  <p><strong>Prospecting</strong> is a term I've <a href="https://en.wikipedia.org/wiki/Prospecting">borrowed from the oil exploration industry</a>. <strong>Prospecting is a highly Active habit, and highly Strategic.</strong> These days, when you look for oil, there is a whole science to handicapping whether or not a plot of land is likely to have oil. You don't know it for a fact, all you're doing is estimating probabilities. Not to get too tautological, but you will be luckier if you can consistently assess and move towards areas where you are more likely to be "lucky". It might look like luck to others, but the motion and intention you invested to get yourself in a position to be lucky was far from random. I've also written many times about how I think strategic <a href="https://www.google.com/search?&amp;q=swyx.io+%22megatrends%22&amp;oq=swyx.io+%22megatrends%22">manoeuvring for "Megatrends"</a> is a good idea.</p>
</section>
<section>
  <h2 id="in-summary"><a href="#in-summary">In Summary</a></h2>
  <p>
    <img src="https://dev-to-uploads.s3.amazonaws.com/i/5075sq79y4pstxpp4pdk.png" alt="Alt Text">
  </p>
  <p>This is the state of my thinking on luck right now. That last bit you just read is pretty fresh, I might come back and change this in a couple years when I have refined my thoughts. I welcome any and all feedback.</p>
  <p>But overall, the message I really want to leave you with is this: <strong>you can create luck</strong>. That's it. I don't care how you do it, what mental model you use, who you quote. I just care <em>that</em> you do it. <strong>Go make yourself more lucky.</strong></p>
  <blockquote>
    <p>Ordinarily I'd wish you good luck, but now you have something better than a mere wish 😂</p>
  </blockquote>
</section>
<section>
  
  <ul>
    <li>The Serendipity Mindset: The Art and Science of Creating Good Luck (<a href="https://www.amazon.com/gp/product/B0818ZH58R/ref=as_li_tl">Book</a>, <a href="https://www.artofmanliness.com/articles/podcast-662-the-art-and-science-of-creating-good-luck/">Podcast</a>)</li>
    <li><a href="https://www.perell.com/blog/serendipity">How to Maximize Serendipity</a> by David Perell</li>
    <li><a href="https://modernwisdom.libsyn.com/269-richard-meadows-optionality-how-to-make-your-own-luck-in-life">Richard Meadows - Optionality: How To Make Your Own Luck In Life</a></li>
  </ul>
</section>
</div></div>]]>
            </description>
            <link>https://www.swyx.io/create_luck/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25985474</guid>
            <pubDate>Mon, 01 Feb 2021 04:17:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It’s time for a new, progressive supply-side economics]]>
            </title>
            <description>
<![CDATA[
Score 36 | Comments 69 (<a href="https://news.ycombinator.com/item?id=25984996">thread link</a>) | @apsec112
<br/>
January 31, 2021 | https://www.thecgo.org/news/its-time-for-a-new-progressive-supply-side-economics/ | <a href="https://web.archive.org/web/*/https://www.thecgo.org/news/its-time-for-a-new-progressive-supply-side-economics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<article id="post-15709">
<section>
<p><img src="https://www.thecgo.org/wp-content/uploads/2021/01/Benchmark-its-time-for-a-new-Supply-side-economics-1068x396-c-default.jpg" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-src="https://www.thecgo.org/wp-content/uploads/2021/01/Benchmark-its-time-for-a-new-Supply-side-economics-1068x396-c-default.jpg">
</p>
<div>
<h2>We need productivity improvements in the sectors that disproportionately affect the&nbsp;poor</h2>
<p>Supply-side economics has a dirty reputation. Since the late 1970s, the term has been associated with “trickle-down” economics: the now-defunct theory that cuts in the highest tax brackets would boost economic productivity so much that government revenue would increase and all of society, even the poor, would benefit.</p>
<p>The trickle-down theory is all but dead, but there is more to the supply side of the economy than taxes. Thousands of government decisions affect real output and economic productivity. A new supply-side economics would recognize that productivity growth is the right target, but it would reject tax policy as the primary means of stimulating productivity. Instead, it would examine how everything government does — from permitting to procurement — could be improved to increase productivity.</p>
<p>In contrast with the old supply-side economics, this approach could be progressive from the outset. Productivity growth has stagnated for decades, with a particularly sharp decline for the last 15 years. What little productivity growth we have experienced has been uneven — there have been many productivity improvements in television manufacturing and few in hospital services, as Mark Perry’s <a href="https://www.aei.org/carpe-diem/chart-of-the-day-or-century-5/" target="_blank" rel="noopener" data-href="https://www.aei.org/carpe-diem/chart-of-the-day-or-century-5/">famous chart</a> shows.</p>
<figure><img src="https://cdn-images-1.medium.com/max/800/0*963226iwV9_Z3HHo" data-image-id="0*963226iwV9_Z3HHo" data-width="1214" data-height="1406" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E"></figure>
<p>These productivity changes are not neutral with respect to the distribution of income. Some high-cost items impose an especially large burden on the budgets of the poor. If we could increase productivity growth in particular sectors, we would reduce real income inequality. Doing so would also unambiguously grow the size of the overall economy.</p>
<p>What are the sectors where productivity gains would have the biggest progressive effect? A look at the Bureau of Labor Statistics’s Consumer Expenditure Surveys, particularly its <a href="https://www.bls.gov/cex/2019/combined/decile.pdf" target="_blank" rel="noopener" data-href="https://www.bls.gov/cex/2019/combined/decile.pdf">table on income deciles</a>, can help us figure that out.</p>
<h2>Shelter</h2>
<p>By far, the biggest share of the lowest income decile’s consumer expenditures go to housing, and specifically shelter (as opposed to other household expenses such as household operations, housekeeping supplies, or furnishings that all fall under BLS’s housing category). Much has been made about NIMBYism, zoning reform, and the need to decrease housing costs. This emphasis is completely warranted from a progressive supply-side perspective. The lowest decile spends 25.8 percent of its budget on shelter, whereas the top decile spends 17.7 percent. A decrease in the cost of shelter would, therefore, disproportionately benefit the poorest in America.</p>
<figure><img src="https://cdn-images-1.medium.com/max/800/0*KGzix8fAQ2LagqkT" data-image-id="0*KGzix8fAQ2LagqkT" data-width="1600" data-height="1164" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E"></figure>
<p>Progressive supply-siders, therefore, must continue to unite against excessive zoning and NIMBYism. We need to build a lot more housing to drive down its cost. And we must support new and innovative building methods (like Cover’s LEGO-like <a href="https://buildcover.com/product/building-system" target="_blank" rel="noopener" data-href="https://buildcover.com/product/building-system">building system</a>) that leverage economies of scale in construction. A victory on housing productivity would result in hundreds of extra dollars a month in the pockets of the poor.</p>
<p><iframe src="https://player.vimeo.com/video/343493885?title=0&amp;byline=0&amp;portrait=0" width="640" height="360" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<p><a href="https://vimeo.com/343493885">Cover’s Building System</a></p>
<h2>Energy</h2>
<p>The three lowest income deciles spend between 8.7 and 8.9 percent of their budgets on what the BLS calls “utilities, fuels, and public services.” This category includes energy — natural gas, electricity, and heating oil — as well as telephone service and a catchall “water and other public services.” More than half of the category lies in the three energy items.</p>
<figure><img src="https://cdn-images-1.medium.com/max/800/0*9Kua433F5y6OkWDm" data-image-id="0*9Kua433F5y6OkWDm" data-width="1600" data-height="1164" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E"></figure>
<p>We are fortunate in the United States to have achieved energy independence through the shale oil boom. The boom has resulted in ultra-cheap natural gas, which is basically a waste product from the search for petroleum. US electricity prices are a fraction of what they are in Europe. But even so, we have not realized the 1950s-era goal of clean energy too cheap to meter. Instead, we have moderated our per-capita energy consumption, as shown in this chart from J. Storrs Hall’s book, <em>Where’s My Flying Car?</em></p>
<figure><img src="https://cdn-images-1.medium.com/max/800/0*1GRx9e3NBMn9JoaU" data-image-id="0*1GRx9e3NBMn9JoaU" data-width="1600" data-height="878" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E"></figure>
<p>The falling cost of wind and solar electricity combined with my favorite energy technology, <a href="https://www.vox.com/energy-and-environment/2020/10/21/21515461/renewable-energy-geothermal-egs-ags-supercritical" target="_blank" rel="noopener" data-href="https://www.vox.com/energy-and-environment/2020/10/21/21515461/renewable-energy-geothermal-egs-ags-supercritical">advanced geothermal energy</a>, could unlock significantly cheaper energy costs, as well as zero carbon dioxide emissions. The low cost of clean energy would have ramifications not only for the pocketbooks of the poor but also throughout the entire economy.</p>
<h2>Food at&nbsp;home</h2>
<p>Another major line item in the budgets of the lower income deciles is food. All deciles spend about the same percentage of their budget on food away from home — the numbers vary from 5.1 to 5.9 percent. Where the deciles differ is on food at home. The lowest deciles spend 9.7 percent of their total expenditures on food at home, whereas the top decile spends 5.2 percent.</p>
<figure><img src="https://cdn-images-1.medium.com/max/800/0*_CQyuU-3avch6wTC" data-image-id="0*_CQyuU-3avch6wTC" data-width="1600" data-height="1164" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E"></figure>
<p>Food and beverage inflation has increased in the past two decades nearly as much as housing inflation. As the data shows, this budget item hits the poorest the hardest. Through innovation in vertical farming, lab-grown meat, and the energy technologies mentioned in the previous section, we could reduce the cost of groceries and increase the level of nutrition available for any spending level. Cheaper healthy food options could reduce obesity, a condition <a href="https://diabetes.diabetesjournals.org/content/60/11/2667" target="_blank" rel="noopener" data-href="https://diabetes.diabetesjournals.org/content/60/11/2667">disproportionally prevalent</a> among the poor. This food innovation benefits everyone, but it benefits the poor the most.</p>
<h2>Healthcare</h2>
<p>Healthcare is a tricky topic to evaluate from the Consumer Expenditure Surveys, as the surveys only capture costs borne by consumers — their personal portion of the cost of health insurance as well as out-of-pocket medical expenses. It doesn’t include the employer portion of health insurance or the contribution of programs like Medicaid, nor does it include services paid for by insurance. Total <a href="https://www.cms.gov/Research-Statistics-Data-and-Systems/Statistics-Trends-and-Reports/NationalHealthExpendData/NationalHealthAccountsHistorical" target="_blank" rel="noopener" data-href="https://www.cms.gov/Research-Statistics-Data-and-Systems/Statistics-Trends-and-Reports/NationalHealthExpendData/NationalHealthAccountsHistorical">national health expenditures</a>, if we include all of the above, would be 17.7 percent of GDP.</p>
<p>Yet even in personal and out-of-pocket medical expenditures, there is a clear trend suggesting that health innovation would benefit the poor the most. The second income decile spends 11.3 percent of its budget on these health expenses, while the top decile spends 6.6 percent. The first decile may spend less than the second because its household members are younger and healthier — people in the second decile are twice as likely to be elderly than those in the first.</p>
<figure><img src="https://cdn-images-1.medium.com/max/800/0*IkmKcN7Y6D8VxlDU" data-image-id="0*IkmKcN7Y6D8VxlDU" data-width="1600" data-height="1164" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E"></figure>
<p>We badly need health innovation to drive down costs. As <a href="https://fortune.com/2020/12/30/anti-aging-research-health-care-spending-biden/" target="_blank" rel="noopener" data-href="https://fortune.com/2020/12/30/anti-aging-research-health-care-spending-biden/">I argued in <em>Fortune</em></a>, research on biological aging could lead to longer healthspans, compressed morbidity, reduced chronic disease prevalence, and lower medical expenditures. Additionally, consumer medical devices could lower the cost of high-quality medical monitoring, replacing the annual physical with continuous observation of health indicators. With better monitoring, serious conditions could be detected earlier, when they are cheaper to address. Other breakthroughs in biology, like mRNA vaccines and computer-simulated protein folding, could lead to quicker and less expensive cures for virtually every disease.</p>
<h2>Putting it all&nbsp;together</h2>
<p>Combining these four elements — shelter, utilities, food at home, and direct healthcare expenditures — adds up to a lot. Together, they make up 52.7 percent of the first decile’s total expenditures and 53.1 percent of the second decile’s. For the top decile they account for only 33.8 percent of expenditures. Innovation in these sectors, then, directly and disproportionately benefits the poorest in America.</p>
<p>A progressive supply-side agenda, therefore, would target productivity growth in the necessities that make up over half the budget of the poor. Through smarter regulation and entrepreneurial policy, we can drive down the cost of these goods and increase the real standard of living at the bottom of the income distribution.</p>
<p>To be sure, a supply-side approach is a complement, not a substitute, for many government transfer programs. Even so, the potential of progressive supply-side policy exceeds that of transfers over the long run. Total annual expenditures for the first income decile average $25,856. A 10 percent across-the-board increase in productivity — less than five years’ economic growth in the 1960s or the late 1990s — would be worth $2,586 per year to these households, twice the average value of direct public assistance as reported in the survey. A progressive approach that targeted productivity improvements specifically to necessities could do even better, as would productivity gains that compounded over a longer period of time. In addition, progressive supply-side policy could “trickle up” to provide gains in the rest of the income distribution, a benefit worth considering.</p>
<p>As necessary as government transfers are, the policy conversation has overrelied on them. Need to stimulate the economy? Write people checks. Have a poverty problem? People won’t be poor if we send them enough checks. Global pandemic? Checks. These demand-side policies have their virtues — they are simple to implement and they often at least partially achieve their goals.</p>
<p>But for true prosperity across the income distribution, we need a more creative supply-side approach. We policy wonks need to do the hard work of finding policies that increase productivity growth, particularly for those goods and services consumed disproportionately at the bottom of the income distribution.</p>
</div>
<p>
CGO scholars and fellows frequently comment on a variety of topics for the popular press. The views expressed therein are those of the authors and do not necessarily reflect the views of the Center for Growth and Opportunity or the views of Utah State University.
</p>
</section>
</article>
</div></div>]]>
            </description>
            <link>https://www.thecgo.org/news/its-time-for-a-new-progressive-supply-side-economics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25984996</guid>
            <pubDate>Mon, 01 Feb 2021 02:49:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[That’s Big Sir to You]]>
            </title>
            <description>
<![CDATA[
Score 74 | Comments 49 (<a href="https://news.ycombinator.com/item?id=25984970">thread link</a>) | @zdw
<br/>
January 31, 2021 | https://www.shirtpocket.com/blog/index.php/shadedgrey/thats_big_sir_to_you/ | <a href="https://web.archive.org/web/*/https://www.shirtpocket.com/blog/index.php/shadedgrey/thats_big_sir_to_you/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>Hey, folks. Sorry it's been a while, but it's been a busy time. Let's start with the bad news first.</p>

<h2>Bad news</h2>

<p>As you know, SuperDuper 3.3.1 cannot copy a volume with Big Sur on it. We're currently blocked on some issues I don't have direct control over, and as such I don't have a new version for you that <strong>fully</strong> supports Big Sur, nor a timeframe for when that will be released.</p>

<p>Right now, as many of you know, v3.3.1 <strong>will</strong> work with non-boot volumes, but it <strong>won't</strong> work with volumes that have macOS on them, because it will try to do some of the things that no longer work in macOS 11.</p>

<p>I know that's been a disappointment, but that's where we are with v3.3.1.</p>

<h2>Good news!</h2>

<p>However, after wracking my brain for <strong>far</strong> too long, I've come up with a <strong>workaround</strong> that will let you make the backups you need to save your files, and to supplement your Time Machine backup. And for that, we need to go Back...to the Future!</p>

<h2>Huh?</h2>

<p>Let me try to explain.</p>

<p>In Catalina, as I explain in <a href="https://www.shirtpocket.com/blog/index.php/shadedgrey/comments/breaking_the_tape/">Breaking the Tape</a>, Apple split the startup volume into two parts: the System volume and the Data volume. We did a ton of work that year to support this new setup in a way that was transparent to the user; SuperDuper automatically creates the proper volumes, converts the drives to APFS as needed, etc.</p>

<p>Worked great.</p>

<p>In macOS 10.15.5, though, <a href="https://www.shirtpocket.com/blog/index.php/shadedgrey/comments/black_boxes_and_bugs/">Apple broke 3rd party copy tools</a> in a way that couldn't be worked around without the use of <code>asr</code>, a low-level drive copy tool that has its own issues. They fixed that in 10.15.6...but it was a rather ominous sign for the future.</p>

<p>That ominous sign became terrifying reality in macOS 11. Due to the new Sealed System Volume, use of <code>asr</code> became mandatory if you wanted to make a copy that was bootable. And even <strong>that</strong> didn't work <strong>at all</strong> until <a href="https://www.shirtpocket.com/blog/index.php/shadedgrey/comments/big_sur/">November 5th</a> of last year—just before Big Sur's official release.</p>

<p>Even now, as of the time of this writing, <code>asr</code> won't make a bootable copy of an M1-based Mac.</p>

<p>So, as of Big Sur, 3rd party tools like SuperDuper can no longer make bootable copies on their own. For that, it's <code>asr</code> or nothing.</p>

<p>It is, indeed, <a href="https://mjtsai.com/blog/2007/06/13/a-very-sweet-solution/">a <em>very</em> <strong>sweet solution</strong></a>.</p>

<p>But, 3.3.1 doesn't know that. It tries to do all the special stuff that we had to do for Catalina, and those things no longer work. And so, as you've seen, that copy generates errors or seems to hang right at the start (because it's thrown exceptions that stop the copy).</p>

<h2>Didn't You Say "Good News"?</h2>

<p>I'm getting there.</p>

<p>SuperDuper! 3.3.1's magic was all about dealing with the split startup volume. It built on the APFS support and scheduling fixes we put into the previous version...and added new things for compatibility with Catalina.</p>

<p>But...what if it <strong>didn't</strong> do that? What if SuperDuper was...<strong>stupider</strong>?</p>

<h2>Wonderfully Awful</h2>

<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/oUUdW2bTa3Y" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>I've been testing this out for a while in-house. and I've come up with a weird-sounding workaround that...works!</p>

<p>Basically, you can use SuperDuper to copy the Data volume of the volume group. The result contains all <strong>your</strong> data and applications, can be restored in a few different ways...and can even be made bootable.</p>

<blockquote>
  <p>Note that, as I indicated above, M1 Macs <strong>can't readily boot from external drives</strong>. There are things you can do, if you have an external Thunderbolt 3 drive (USB-C isn't sufficient), but even that won't work if the internal drive is dead. Unless things change, bootable backups are basically a thing of the past on M1-based Macs.</p>
</blockquote>

<h2>How?</h2>

<p>It's actually easy. To accomplish this, use an old version of SuperDuper—<a href="https://www.shirtpocket.com/downloads/SuperDuper!+3.2.5.dmg">specifically, v3.2.5</a>—to copy the Data volume, which is shown in the older version!</p>

<p>v3.2.5 is well tested, having been on the market for quite some time, and is reliable. So we don't have to worry about doing a broad beta test of a partially complete new release. It's already tested, and I've been busy doing the additional testing necessary to prove it works on Big Sur.</p>

<p>Again, this will make a copy of the data that you need to preserve <strong>your</strong> stuff, both Applications and Data, while leaving the Sealed System Volume alone.</p>

<p>And it's a valid source for "restore" during a clean install or migration! So restoration is <strong>easy</strong> and <strong>fast</strong> should it become necessary.</p>

<h2>Neat!</h2>

<p>Yeah, I wish I had thought of this earlier.</p>

<p>So, if you're on Big Sur, and you want to copy a startup drive, here's what to do:</p>

<ol>
<li>Make sure you have your license information handy. You can retrieve it from SuperDuper's Register... page should you need to.</li>
<li>Download and install <a href="https://www.shirtpocket.com/downloads/SuperDuper!+3.2.5.dmg">SuperDuper! v3.2.5 from here</a>.</li>
<li>Remove SuperDuper! from the "Full Disk Access" list in the Security &amp; Privacy preference pane and restart your Mac. This is important, and works around an Apple bug triggered by the change of SuperDuper!'s bundle ID.</li>
<li>Run SuperDuper and follow the steps to allow it Full Disk Access.</li>
<li>If your license is missing, re-enter it from your license email. </li>
<li>Turn off "Check for Updates" in our Preferences so we don't nag you about v3.3.1.</li>
<li>Select the "Data" volume in the source pop-up, and a <strong>new</strong> APFS backup volume in the destination pop-up, along with "Backup - all files" (or whatever script you want). If you already have a backup volume, you can use Disk Utility to select and delete <strong>just</strong> the backup System volume, rather than create a new one. After doing this, rename the Data volume to something sensible (remove "- Data"). Note that you may need to repair it with Disk First Aid before it will show up in SuperDuper.</li>
<li>Make your copy as normal, set up your schedule as needed, etc. Your regular Smart Updates will work as expected.</li>
</ol>

<p>To fully restore, it's easiest to boot to recovery, erase the internal drive you want to restore to, <a href="https://support.apple.com/en-us/HT204904">reinstall the OS from Recovery mode</a>, and then, when prompted to restore during the first boot of the fresh copy of macOS, point at the backup. All your data and applications will be brought in automatically.</p>

<blockquote>
  <p>If you want to make the backup bootable and have an Intel Mac, boot to Recovery (Cmd+R during power on) and install Big Sur to the backup drive. You can then start up from the backup. Note, though, that once made bootable, you can no longer copy <strong>to</strong> the backup until you delete the system volume as above. So <strong>don't</strong> do this unless you need to.</p>
</blockquote>

<h2>Forward-Looking Statements</h2>

<p>It seems clear that the future of bootable backups is unclear.</p>

<p>M1 Macs <strong>can't</strong> be copied in a way that makes them bootable. Bare metal recovery on an M1 Mac isn't possible, since they depend on the contents of their internal drive even when booting externally. And the tools required to make bootable copies of Intel Macs are limited, often fail, and produce inscrutable and undocumented diagnostics when they do.</p>

<p>Everything's a tradeoff, and with the M1 Macs, Apple has given us an amazing new platform, while taking away some of the things that made macOS such a joy to work with. And one of those things is bootable backups.</p>

<p>I have <strong>no idea</strong> if this is going to change for the better in whatever the next macOS version brings, and have no insight into Apple's future plans.</p>

<p>But I <a href="https://www.shirtpocket.com/blog/index.php/shadedgrey/comments/practices_make_perfect_backups/">continue to advise multiple backup strategies</a>, including Time Machine (to an APFS volume under Big Sur), SuperDuper! (for a simple copy of your data and applications) and an online backup program (as a last resort).</p>

<p>With that, back to plugging away at a new version.</p>

<p>Thanks for reading, and for using SuperDuper.</p>

</div></div>]]>
            </description>
            <link>https://www.shirtpocket.com/blog/index.php/shadedgrey/thats_big_sir_to_you/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25984970</guid>
            <pubDate>Mon, 01 Feb 2021 02:43:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Covid-19 and the Global Shift Towards Authoritarian Governance]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25984929">thread link</a>) | @mrfusion
<br/>
January 31, 2021 | http://asenseofplacemagazine.com/covid-19-and-the-global-shift-towards-authoritarian-governance/ | <a href="https://web.archive.org/web/*/http://asenseofplacemagazine.com/covid-19-and-the-global-shift-towards-authoritarian-governance/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://asenseofplacemagazine.com/covid-19-and-the-global-shift-towards-authoritarian-governance/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25984929</guid>
            <pubDate>Mon, 01 Feb 2021 02:32:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ariane is just like a web browser but for browsing 'Geminispace']]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25984902">thread link</a>) | @gaius_baltar
<br/>
January 31, 2021 | https://oppen.digital/ariane/ | <a href="https://web.archive.org/web/*/https://oppen.digital/ariane/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://oppen.digital/ariane/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25984902</guid>
            <pubDate>Mon, 01 Feb 2021 02:25:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I Built Conway's Game of Life for Ethereum]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25984884">thread link</a>) | @basicallydan
<br/>
January 31, 2021 | https://danhough.com/blog/conways-game-ethereum/ | <a href="https://web.archive.org/web/*/https://danhough.com/blog/conways-game-ethereum/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<header>
			
			<p>
				<span>Published 31 January 2021 in Vancouver, Canada</span>
				
				<span title="It took me about 7 minutes to read this blog post back to myself.">(~7min read)</span>
				
			</p>
		</header>
		<p>Want to see it??<br>➡️ Visit <a href="https://conwaysgame.github.io/solidity-ethereum/">Conway’s Game of Life for Ethereum</a>.</p>

<p>Since 2014 I have been slowly (very slowly) building <a href="https://github.com/conwaysgame/">implementations of Conway’s Game of Life for different programming languages and technologies</a>.</p>

<p>Most recently I set out to write a version of the Game of Life which “runs on Ethereum”. In other words, it’s a Smart Contract. In other words, it’s a Distributed App (Dapp). In other words, it’s a small application written in Solidity. There are many ways to describe it but the coolest way, in my opinion is, “it’s Conway’s Game of Life for Ethereum.”</p>

<figure>
	
	<img src="https://media.giphy.com/media/iuAP1ssht7ufmaxLmo/source.gif" title="Here's a transaction taking place." alt="Here's a transaction taking place.">
	
	
	<figcaption>Here's a transaction taking place.</figcaption>
	
</figure>

<h2 id="try-it-out">Try it out</h2>

<p>As I’ll explain later, I decided not to deploy this on the Ethereum main-net, so if you want to play with it, you can do so using the Rinkeby Test Network - or you can just watch as others do.</p>

<ul>
  <li>Visit <a href="https://conwaysgame.github.io/solidity-ethereum/">the web application</a>.</li>
  <li>See the current state of the world.</li>
  <li>(Optional) Get some ETH from the <a href="https://faucet.rinkeby.io/">Rinkeby Faucet</a>.</li>
  <li>Transfer 0.00001 ETH to the contract address (and pay the gas charge) listed on the page<br>(you can do this easily via MetaMask, or just manually).</li>
  <li>Check the web app again, the state of the world should have changed.</li>
</ul>

<p>I’d recommend also installing <a href="https://chrome.google.com/webstore/detail/metamask/nkbihfbeogaeaoehlefnkodbefgpgknn?hl=en">MetaMask</a>, or using <a href="https://brave.com/">Brave</a> as your browser, in order to make transactions more easily.</p>

<hr>

<h2 id="howd-i-do-it">How’d I do it?</h2>

<p>I started by completing <a href="https://techbrij.com/hello-world-smart-contract-solidity-ethereum-dapp-part-1">a Hello World tutorial by Brij Mohan</a>, and then started from scratch with a new project. This involved using Truffle, a CLI to help with writing and interacting with smart contracts and Ganache, a personal ethereum blockchain (for much quicker development), among some more common JavaScript tools.</p>

<p>I did it entirely using TDD, so I wrote my tests first (in JavaScript, thank goodness) and then slowly but surely implemented the rules of the game.</p>

<p>I’ve written many Games of Life, but this was the most challenging.</p>

<h2 id="challenges">Challenges</h2>

<h3 id="unforgiving">Unforgiving</h3>

<p>Before starting, I vaguely knew that the more work my contract did, the more ‘expensive’ it was to run. So I focused on trying to make it efficient. Normally when implementing the game of life, I create a two-dimensional array to represent the world, loop through all the possible neighbours of each cell and I check if it is on or off the grid. With the languages I’ve used so far this is straightforward: many allow signed, negative integers for indexes and automatically allocate memory, and often won’t complain if I’m referencing an element which doesn’t exist.</p>

<p>With Solidity, I tried to make sure I wasn’t going to even <em>try</em> to reference a position in the grid that didn’t exist (such as <code>-1</code>), since I’d then need to handle an error. It’s definitely better to <em>avoid</em> an error here.</p>

<p>In an effort to make my contract more efficient, I tried to avoid allocating too much memory for a number, e.g., 16 bits when all I needed was 8. I also tried to avoid switching between byte arrays and strings, when replacing the old world with the new one, so that less casting would be necessary.</p>

<p>Thanks to some very helpful compilers and interpreters doing most of this work for me, my usual programming work (mostly JavaScript) doesn’t often involve quite so much decision-making around integer sizes. This was surprisingly fun and a very different challenge than usual.</p>

<h3 id="deployment---too-much-gas">Deployment - too much Gas?!</h3>

<p>After I got it all working, I started learning more seriously about the cost of Ethereum transactions. It turns out that despite all this thought about performance and the runtime cost, I had inadventedly made my contract expensive even to deploy onto a network.</p>

<p>Ethereum has this concept of “gas.” Each time you perform a transaction of any kind (send ETH, deploy smart contract, interact with smart contract, etc) the initiating party must offer some ETH to the various miners on the network whose hardware processes the transactions. “One gas” is worth an amount in “Gwei”, which is a denomination of the currency worth 0.000000001 ETH. That amount can be set by the person initiating, but the recommended price is a value which fluctuates based on supply and demand.</p>

<p>With all of this in mind, I decided to find out how much it might cost to deploy in a fiat currency such as the US Dollar. I opened up <code>truffle console</code> to estimate the gas by running <code>ConwaysGameOfLife.new.estimateGas()</code>, looked up how much 1 gas would be on the main-net at <a href="https://ethgasstation.info/">https://ethgasstation.info/</a>, and found out the rate of ETH to USD. This is how I worked out the cost.</p>

<div><div><pre><code>gasPrice = 145                        # Obtained from ethgasstation
gasTxCost = 722539                    # Obtained using `estimateGas()`
ethToUSDPrice = 1305.33               # Obtained from Google
costInGwei = gasPrice * gasTxCost     # =&gt; 104768155
costInETH = costInGwei * 0.000000001  # =&gt; 0.104768155
costInUSD = costInETH * ethToUSDPrice # =&gt; $136.76
</code></pre></div></div>

<p>That’s $136.76 USD at the time of writing. This is hypothetical, until I decide to deploy to the main-net.</p>

<p>To me, for a fun little project which probably nobody would use, that price was too high. I don’t know how much I’d be willing to spend, but $136.76 is too much.</p>

<p>I Googled how to improve the efficiency of a contract’s deployment and found <a href="http://article.nadiapub.com/IJGDC/vol10_no12/6.pdf">this little paper</a>. So I got rid of some variables and hard-coded the values instead, among other changes. With each change, I’d run <code>truffle compile</code> and <code>estimateGas()</code>.</p>

<p>First, I got it down to <strong>708,354 gas</strong>, then <strong>644,904 gas</strong>. Then it went up again to <strong>695,936 gas</strong>; some things I did made it worse. Unintuitively, using larger integer types such as <code>uint</code> (256 bits) instead of smaller (<code>uint8</code>) reduces gas costs.</p>

<p>I also experimented with increasing the size of the world from 5x5 to 10x5. That brought the deployment price up to <strong>652,508 gas</strong> and the transaction price to <strong>106,708 gas</strong>. Committing to this, though, would mean re-doing the tests since the size is now hardcoded in the contract. By this point, I had sunk more than enough time into it.</p>

<p>In the end, I settled on a solution with these hypothetical costs:</p>

<ul>
  <li>Deployment price: <strong>611,944 gas</strong>, which would be equivalent to about $115.82.
    <ul>
      <li>Saving: <strong>110,595 gas</strong>, or $20.93.</li>
    </ul>
  </li>
  <li>Transaction price: <strong>72,213 gas</strong>, which would be equivalent to about $13.66.
    <ul>
      <li>Saving: <strong>298,057 gas</strong>, or $56.41.</li>
    </ul>
  </li>
</ul>

<p>I was happy with this amount of rewriting in order to get a more efficient contract working.</p>

<h3 id="networks">Networks</h3>

<p>I’ve become quite familiar with the concept of “Web 3.0.” In this “version” of the web, everything is distributed across a network rather than centralised in servers and served up to clients. It would appear though that for the time being, the only part of traditional web app which gets distributed is the backend.</p>

<p>In order to interact with this backend from a web browser, I had to install <code>web3</code>, a JavaScript API for Ethereum, which involved a lot of async <code>await</code> statements and polling.</p>

<p>In this world, rather than my backend being located at an IP address, resolved by a domain such as <code>gameoflife.com</code>, it’s located at an Ethereum address which is resolved by a contract name such as <code>GameOfLife</code>, which may or may not be on the specified network.</p>

<p>It’s an interesting paradigm shift, but interacting with it through a web browser currently still involves using traditional HTTP-based servers. Maybe there’s a future where that isn’t the case?</p>

<h2 id="whyd-i-do-it">Why’d I do it?</h2>

<p>The future of cryptocurrency is uncertain, and my feelings about the subject change every day. However, Bitcoin and Ethereum are in the news a lot right now, so it feels relevant. There is a chance there’ll be more demand for smart contracts and developers who know how to work with them in the future. It feels important for me to keep on learning new skills not only to progress my career, but to make life more interesting.</p>

<h2 id="why-not-put-it-on-the-main-net">Why not put it on the main-net?</h2>

<p>As I explained earlier, the gas price for deployment is fairly high. After showing it to a few Ethereum enthusiasts, I came to the conclusion that there was no need to spend the money, buy the ETH and put it on the main-net. There are better uses of this blockchain out there than Conway’s Game of Life. My goal here was experimentation and learning, both of which I achieved with the Rinkeby test network. Oh, and if you come across a contract called <code>ConwaysGameOfLife</code> on the main-net, unless I edit this post and mention it here, it isn’t mine!</p>

<h2 id="reflections">Reflections</h2>

<p>I learned that writing basic Smart Contracts for Ethereum isn’t too tricky - like with any sofware, there’s an input and an output. The challenge, as expected, was getting my environment set up. It wasn’t too difficult to do that, though.</p>

<p>I also learned how one can create an interface between “web 2.0” applications and “web 3.0” applications, and the tooling available for that is pretty decent too. <span id="sendEthBlock">For instance, if I wanted to <a href="#">ask for a donation in ETH I could make it super easy with a JavaScript function</a>.</span></p>

<p>Also, a mind to application performance means a heck of a lot more when the operating cost can be measured in direct, immediate currency transactions, as opposed to a some-time-in-the-future slight increase in AWS fees over time, for example.</p>

<hr>

<p>Remember, you can <a href="https://conwaysgame.github.io/solidity-ethereum/">take a look at Conway’s Game of Life for Ethereum</a> right now. If you’d like to check out the code or maybe make some improvements or raise an issue, <a href="https://github.com/conwaysgame/solidity-ethereum">the code is on GitHub</a> and I’d love to hear from you.</p>

<p>As a final note, I’d like to offer sincere thanks to <a href="https://twitter.com/mr_ligi">ligi</a> for trying it out and offering valuable opinions, as well as Reddit users /u/FrequentMushroom, /u/liberated, /u/Phistofeles, /u/hodak2 and /u/squeeze_tooth_paste for trying it also. I’d also like to thank my very good friends for their keen eyes and candid critique: the ever-encouraging and intelligent <a href="https://twitter.com/jonfinerty">Jon Finerty</a> and <a href="https://twitter.com/yjhda">Matt Lewis</a>.</p>




		<p>Heckle me on Twitter <a href="http://twitter.com/basicallydan">@basicallydan</a>.</p>
	</div></div>]]>
            </description>
            <link>https://danhough.com/blog/conways-game-ethereum/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25984884</guid>
            <pubDate>Mon, 01 Feb 2021 02:23:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Evil in Paradise]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25984274">thread link</a>) | @AndrewBissell
<br/>
January 31, 2021 | https://newsinteractives.cbc.ca/longform/peter-nygard-bahamas-allegations | <a href="https://web.archive.org/web/*/https://newsinteractives.cbc.ca/longform/peter-nygard-bahamas-allegations">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
		<article>
						<section>
				
			</section>
						
			<section id="section-1">
				<div>
					<div>
													
							
									<p><strong>WARNING: This story contains graphic content.</strong></p>
<p>One afternoon in 2015, word went out to staff at Peter Nygard's palatial seaside compound in the Bahamas. A meeting between Nygard and a senior politician had the green light. 
</p>
<p>A well-oiled machine comprised of staff members who knew what to do when encounters like these were planned sprang into action. Cash was prepared by accountants. Vehicles were readied. The former Canadian fashion mogul was informed it was time.
</p>
<p>The massive wooden gates at the sprawling estate named for its owner, Nygard Cay, slowly rose to allow a convoy of cars to leave. Nygard would often meet powerful and influential people in the Bahamas under unusual circumstances.
</p>
<p>"I know of the instructions for the accountants to get cash for [Nygard] to take to his private meeting after hours," said a longtime employee, whose identity we are protecting. He still fears retribution from Nygard, and those close to him.
</p>
<ul><li><strong>Watch <a href="https://www.cbc.ca/fifth/">"Peter Nygard: The Secret Videos"</a></strong> on <em>The Fifth Estate</em> and listen to CBC Podcasts' new series about Peter Nygard, <strong><a href="https://www.cbc.ca/listen/cbc-podcasts/475-evil-by-design"><em>Evil By Design</em></a></strong>.</li></ul>
<p>The employee, who worked at Nygard Cay in various roles for nearly eight years starting in 2008, was responsible for directing staff to make arrangements for the meeting. For him, it was a familiar scene. 
</p>
<p>The former employee, and three other sources, describe attempts by Nygard to forge connections at the highest levels in the Bahamas where he is accused of operating an elaborate sex trafficking ring spanning more than two decades, involving dozens of young women and girls, an investigation by the CBC podcast <em>Evil By Design</em> and <em>The Fifth Estate</em> has found.
</p>
<p>"I felt broken, like a piece of me was taken from me," a woman known as Jane Doe No. 1 said in an interview.
</p>
								
																					
							
									
									
									
									
									
									<figure data-src="https://newsinteractives.cbc.ca/craft-assets/images/Jane-Doe-1-revised.jpg">
										<img width="100%" data-srcset="https://newsinteractives.cbc.ca/craft-assets/images/_large/Jane-Doe-1-revised.jpg 1180w,
													https://newsinteractives.cbc.ca/craft-assets/images/_medium/Jane-Doe-1-revised.jpg 940w, 
													https://newsinteractives.cbc.ca/craft-assets/images/_small/Jane-Doe-1-revised.jpg 768w, 
													https://newsinteractives.cbc.ca/craft-assets/images/_x_small/Jane-Doe-1-revised.jpg 490w" data-sizes="(max-width: 490px) 90vw, 60vw" data-src="https://newsinteractives.cbc.ca/craft-assets/images/Jane-Doe-1-revised.jpg" alt="Jane Doe No. 1 was 14 years old when she says Peter Nygard raped her in 2015. (John Badcock/CBC)" srcset="https://newsinteractives.cbc.ca/craft-assets/images/_large/Jane-Doe-1-revised.jpg 1180w,
													https://newsinteractives.cbc.ca/craft-assets/images/_medium/Jane-Doe-1-revised.jpg 940w, 
													https://newsinteractives.cbc.ca/craft-assets/images/_small/Jane-Doe-1-revised.jpg 768w, 
													https://newsinteractives.cbc.ca/craft-assets/images/_x_small/Jane-Doe-1-revised.jpg 490w" src="https://newsinteractives.cbc.ca/craft-assets/images/Jane-Doe-1-revised.jpg">
										<figcaption>
											
											Jane Doe No. 1 was 14 years old when she says Peter Nygard raped her in 2015. (John Badcock/CBC)
																						
										</figcaption>
									</figure>

									

																														
							
									<p>She is one of 10 original women who went public in a class-action lawsuit with allegations against Nygard exposing for the first time what was going on behind the gates at Nygard Cay.</p>
<p>According to the suit, filed in New York last February, she was 14 years old when Nygard raped her in 2015.
</p>
<p>Since then, more than 70 additional women have stepped forward with similar allegations. In December, U.S. authorities charged Nygard with nine counts of sex trafficking, sex assault and racketeering involving at least dozens of survivors. He was arrested in Winnipeg on an extradition request. 
</p>
<p>The CBC investigation, involving interviews with 19 women who say they were raped by Nygard and many more conversations with lawyers, private investigators, politicians, local activists and former employees, reveals an elaborate effort to cultivate influence with prominent decision-makers in the Bahamas, silence victims and block anyone who tried to expose him.
</p>
<p>The tactics include payments to senior politicians and police officers in the Bahamas, drugging and holding young women and girls against their will, an alleged campaign of violence against a group of local people who stood up to him and an aggressive legal offensive aimed at the CBC that began investigating reports of sexual misconduct involving Nygard in the Bahamas as far back as 2009.
</p>
								
																					
							
									
									
									
									
									
									<figure data-src="https://newsinteractives.cbc.ca/craft-assets/images/Nygard-and-Lion-edit.jpg">
										<img width="100%" data-srcset="https://newsinteractives.cbc.ca/craft-assets/images/_large/Nygard-and-Lion-edit.jpg 1180w,
													https://newsinteractives.cbc.ca/craft-assets/images/_medium/Nygard-and-Lion-edit.jpg 940w, 
													https://newsinteractives.cbc.ca/craft-assets/images/_small/Nygard-and-Lion-edit.jpg 768w, 
													https://newsinteractives.cbc.ca/craft-assets/images/_x_small/Nygard-and-Lion-edit.jpg 490w" data-sizes="(max-width: 490px) 90vw, 60vw" data-src="https://newsinteractives.cbc.ca/craft-assets/images/Nygard-and-Lion-edit.jpg" alt="Peter Nygard and Nygard employees are alleged to have used pamper parties at Nygard Cay as a way to recruit woman and girls. (Jonathan Becker/Contour by Getty Images)" srcset="https://newsinteractives.cbc.ca/craft-assets/images/_large/Nygard-and-Lion-edit.jpg 1180w,
													https://newsinteractives.cbc.ca/craft-assets/images/_medium/Nygard-and-Lion-edit.jpg 940w, 
													https://newsinteractives.cbc.ca/craft-assets/images/_small/Nygard-and-Lion-edit.jpg 768w, 
													https://newsinteractives.cbc.ca/craft-assets/images/_x_small/Nygard-and-Lion-edit.jpg 490w" src="https://newsinteractives.cbc.ca/craft-assets/images/Nygard-and-Lion-edit.jpg">
										<figcaption>
											
											Peter Nygard and Nygard employees are alleged to have used pamper parties at Nygard Cay as a way to recruit woman and girls. (Jonathan Becker/Contour by Getty Images)
																						
										</figcaption>
									</figure>

									

																														
							
									<p>Nygard denies all of the allegations, and says they are lies and part of a conspiracy meant to destroy his reputation spearheaded by his former neighbour in the Bahamas, billionaire Louis Bacon.</p>
<p>For the women who told CBC they were assaulted, Nygard’s methods created a climate where it seemed impossible to come forward against someone who appeared so powerfully connected on the Caribbean island, keeping his alleged campaign of rape and sexual assault in the Bahamas a secret for more than two decades. 
</p>
<p>"The government of the Bahamas gave him a sanctuary in which to operate a criminal sex trafficking ring," said Lisa Haba, one of two U.S. lawyers who is suing Nygard on behalf of survivors. 
</p>
<p>"He uses power, his influence, his brand, to show the world that I am Peter Nygard, and I control everything I touch."</p>
								
																					
							
							</div>
						</div>
					</section>
					
					<section>
						<div>
							<div>
																<h2>I: ‘A corrupter of men’</h2>
								
																					
							
									<p>In 1984, Nygard purchased a modest bungalow on a breathtaking piece of property on the western tip of New Providence island in the Bahamas.</p>
<p>Known as Simms Point for more than 400 years, the piece of Caribbean paradise is surrounded on both sides by the sparkling Atlantic Ocean and is perched at the edge of a wealthy gated community called Lyford Cay.
</p>
<p>Nygard, the Finnish-Canadian founder of a Manitoba-based multimillion-dollar fashion empire, had fallen in love with the Bahamas.
</p>
<p>"We'd been living in Winnipeg … with 40 below [temperatures]. And I'd never been to a warm country in my life," he told a Bahamian TV production in 2008.
</p>
<p>"I saw this beautiful place with beautiful white sand, these beautiful people here. And I said, 'That's for me.' "</p>
								
																					
							
									
									
									
									
									
									<figure data-src="https://newsinteractives.cbc.ca/craft-assets/images/Nygard-Cay-drone-shot-1.jpg">
										<img width="100%" data-srcset="https://newsinteractives.cbc.ca/craft-assets/images/_large/Nygard-Cay-drone-shot-1.jpg 1180w,
													https://newsinteractives.cbc.ca/craft-assets/images/_medium/Nygard-Cay-drone-shot-1.jpg 940w, 
													https://newsinteractives.cbc.ca/craft-assets/images/_small/Nygard-Cay-drone-shot-1.jpg 768w, 
													https://newsinteractives.cbc.ca/craft-assets/images/_x_small/Nygard-Cay-drone-shot-1.jpg 490w" data-sizes="(max-width: 490px) 90vw, 60vw" data-src="https://newsinteractives.cbc.ca/craft-assets/images/Nygard-Cay-drone-shot-1.jpg" alt="In 1984, Nygard purchased a modest bungalow on the western tip of New Providence island in the Bahamas and turned it into a Mayan-inspired estate called Nygard Cay. (CBC)" srcset="https://newsinteractives.cbc.ca/craft-assets/images/_large/Nygard-Cay-drone-shot-1.jpg 1180w,
													https://newsinteractives.cbc.ca/craft-assets/images/_medium/Nygard-Cay-drone-shot-1.jpg 940w, 
													https://newsinteractives.cbc.ca/craft-assets/images/_small/Nygard-Cay-drone-shot-1.jpg 768w, 
													https://newsinteractives.cbc.ca/craft-assets/images/_x_small/Nygard-Cay-drone-shot-1.jpg 490w" src="https://newsinteractives.cbc.ca/craft-assets/images/Nygard-Cay-drone-shot-1.jpg">
										<figcaption>
											
											In 1984, Nygard purchased a modest bungalow on the western tip of New Providence island in the Bahamas and turned it into a Mayan-inspired estate called Nygard Cay. (CBC)
																						
										</figcaption>
									</figure>

									

																														
							
									<p>Over the next 20 years, Nygard constructed a 2.4-hectare estate consisting of a series of tree house-type buildings made of rock and glass that jut out over the sea. It has 12 bedrooms, a berth for a 25-metre yacht, pools and jacuzzis carved out of stone, a 21-car garage, tennis courts, volleyball courts, a disco and a movie theatre.</p>
<p>As you approach the compound, tall wooden gates, edged with barbed wire, are under constant surveillance by a series of cameras. From above, a soaring glass roofed structure shaped like a star, known as the main hall, anchors the centre of the property while giant stone lions guard a turquoise lagoon and a vast white sand beach dominates the southern edge of the estate.
</p>
<p>While the natural beauty is striking, it’s a stark contrast to the decades of pain and damage Nygard is accused of inflicting on so many there. 
</p>
<p>The entire compound is styled after a Mayan temple.
</p>
<p>"I've been very careful not to build a Beverly Hills house in the Caribbean," Nygard said in a 2005 legal deposition.
</p>
<p>"It's finally a dream come true that I can do for me and that I can share it with a lot of my friends, the Bahamians."</p>
<p>Indeed, Nygard made influential friends in the Bahamas.</p>
								
																					
							
									<p>In a 1992 letter Nygard sent to a local up-and-coming-politician, he offered a reminder of his "significant" $45,000 pledge to the politician’s party and asked for a series of favours.</p>
<p>The politician at the time was the minister of agriculture, trade and industry in the ruling Progressive Liberal Party, or PLP.
</p>
<p>Nygard wrote that he’d already been "given approval" to extend his property, and that he now wanted to make it a "legal fact." He also asked to officially change the name of his property from Simms Point to Nygard Cay in time for an upcoming shoot with celebrity television show <em>Lifestyles of the Rich and Famous</em>.
</p>
<p>"Obviously, this whole world is based on one hand helping the other," wrote Nygard. "And you know that I am prepared to do whatever is in my capacity to help out the Bahamas and the PLP party and of course yourself in any way I can."</p>
<p>That politician was Perry Christie, who would go on to become prime minister of the Bahamas in 2002. 
</p>
								
																					
							
									
									
									
									
									
									<figure data-src="https://newsinteractives.cbc.ca/craft-assets/images/Loretta-Butler-Turner.JB.JPG">
										<img width="100%" data-srcset="https://newsinteractives.cbc.ca/craft-assets/images/_large/Loretta-Butler-Turner.JB.JPG 1180w,
													https://newsinteractives.cbc.ca/craft-assets/images/_medium/Loretta-Butler-Turner.JB.JPG 940w, 
													https://newsinteractives.cbc.ca/craft-assets/images/_small/Loretta-Butler-Turner.JB.JPG 768w, 
													https://newsinteractives.cbc.ca/craft-assets/images/_x_small/Loretta-Butler-Turner.JB.JPG 490w" data-sizes="(max-width: 490px) 90vw, 60vw" data-src="https://newsinteractives.cbc.ca/craft-assets/images/Loretta-Butler-Turner.JB.JPG" alt="Former Bahamian opposition leader Loretta Butler-Turner says Nygard was 'a corrupter of men.'  (John Badcock/CBC)">
										<figcaption>
											
											Former Bahamian opposition leader Loretta Butler-Turner says Nygard was 'a corrupter of men.'  (John Badcock/CBC)
																						
										</figcaption>
									</figure>

									

																														
							
									<p>Fast forward to 2011. Christie, now leader of the opposition, was preparing a campaign for a second run at prime minister. </p>
<p>He took time to fly to Winnipeg in July to attend the wedding of Nygard’s daughter. He celebrated there with Nygard's friends and family and the mayor of Winnpeg at the time, Sam Katz.
</p>
<p>Nygard "is a significant personality in the Bahamas, known for his philanthropy, a contributor to those who are in need," Christie said in a speech at the wedding, and then he went on to describe a favour he provided to Nygard.
</p>
<p>"He was having some difficulty with his residency. I was introduced to him and facilitated the granting of that certificate that enabled him to be a resident in the Bahamas."</p>
<p>Later that same year, Christie travelled with Nygard to Las Vegas for a conference. Video from that trip shows Nygard introducing a series of young women to Christie in a hotel suite after a meeting. A photo, obtained by CBC News, shows Nygard and Christie seated between two young women in a restaurant. One of the women has a rolled-up wad of cash in her bra.
</p>
								
																					
							
									
									
									
									
									
									<figure data-src="https://newsinteractives.cbc.ca/craft-assets/images/Christie-and-Nygard-at-restaurant.jpg">
										<img width="100%" data-srcset="https://newsinteractives.cbc.ca/craft-assets/images/_large/Christie-and-Nygard-at-restaurant.jpg 1180w,
													https://newsinteractives.cbc.ca/craft-assets/images/_medium/Christie-and-Nygard-at-restaurant.jpg 940w, 
													https://newsinteractives.cbc.ca/craft-assets/images/_small/Christie-and-Nygard-at-restaurant.jpg 768w, 
													https://newsinteractives.cbc.ca/craft-assets/images/_x_small/Christie-and-Nygard-at-restaurant.jpg 490w" data-sizes="(max-width: 490px) 90vw, 60vw" data-src="https://newsinteractives.cbc.ca/craft-assets/images/Christie-and-Nygard-at-restaurant.jpg" alt="Nygard and former Bahamian prime minister Perry Christie in a Las Vegas restaurant with two young women. (Submitted by Stephen Feralio) " srcset="https://newsinteractives.cbc.ca/craft-assets/images/_large/Christie-and-Nygard-at-restaurant.jpg 1180w,
													https://newsinteractives.cbc.ca/craft-assets/images/_medium/Christie-and-Nygard-at-restaurant.jpg 940w, 
													https://newsinteractives.cbc.ca/craft-assets/images/_small/Christie-and-Nygard-at-restaurant.jpg 768w, 
													https://newsinteractives.cbc.ca/craft-assets/images/_x_small/Christie-and-Nygard-at-restaurant.jpg 490w" src="https://newsinteractives.cbc.ca/craft-assets/images/Christie-and-Nygard-at-restaurant.jpg">
										<figcaption>
											
											Nygard and former Bahamian prime minister Perry Christie in a Las Vegas restaurant …</figcaption></figure></div></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://newsinteractives.cbc.ca/longform/peter-nygard-bahamas-allegations">https://newsinteractives.cbc.ca/longform/peter-nygard-bahamas-allegations</a></em></p>]]>
            </description>
            <link>https://newsinteractives.cbc.ca/longform/peter-nygard-bahamas-allegations</link>
            <guid isPermaLink="false">hacker-news-small-sites-25984274</guid>
            <pubDate>Mon, 01 Feb 2021 00:42:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tracking Capital Gains with Hledger]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25984236">thread link</a>) | @swalladge
<br/>
January 31, 2021 | https://www.swalladge.net/archives/2021/01/30/hledger-tracking-capital-gains/ | <a href="https://web.archive.org/web/*/https://www.swalladge.net/archives/2021/01/30/hledger-tracking-capital-gains/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <h2 id="disclaimer">Disclaimer</h2>
<p>While I endeavour to present accurate and useful information here,
I am not an accountant, lawyer, or tax expert.
This should not be taken as legal advice or investment advice.
Use the information here at your own risk.
If in doubt, contact your local accountant or tax agent.</p>
<h2 id="intro">Intro</h2>
<p><a href="https://plaintextaccounting.org/">Plain text accounting</a> is awesome.
I use <a href="https://hledger.org/">hledger</a>, which is a modern rewrite of the original <a href="https://www.ledger-cli.org/">ledger-cli</a>.
It's awesome.</p>
<p>One thing that it doesn't do out of the box though
is tracking lots, capital gains, and capital losses.</p>
<p>The concept of capital gains/losses, and how to model them in a ledger file,
was something I spent some time trying to understand when dabbling in cryptocurrency.
So, I'm sharing a method, tutorial, and example ledger file for tracking transactions to fulfil tax requirements,
in the hope that it may be useful to others who are interested in doing something similar.</p>
<h2 id="method-backstory">Method / Backstory</h2>
<p>So basically, I had two issues:</p>
<ol>
<li>how to use hledger to model capital gains/losses,</li>
<li>and how to record lots as well as physical locations of assets.</li>
</ol>
<p>To model capital gains/losses,
we need to ensure cost basis is recorded whenever a cryptocurrency
(or other asset subject to capital gains) is purchased.
Then when disposing of the asset, the cost basis is subtracted from the sell price,
and the difference determines your profit or loss (usually directly capital gain or capital loss).
It turns out that hledger already supports transaction prices.
We can use them for neatly calculating capital gains/losses,
by recording the cost basis as the transaction price on the asset being sold,
and the current exchange rate (or full sell price) on the asset being purchased.
The capital gain/loss will be the difference, and hledger can auto calculate and enforce that.</p>
<p>As for lots versus physical locations,
the motivation for this split may not be immediately apparent.
Consider this situation:</p>
<ul>
<li>You purchase 1 COIN on Exchange One for 100 AUD, and 1 COIN on Exchange Two for 110 AUD.</li>
<li>The next day you purchase 1 COIN on Exchange Two for 120 AUD.</li>
<li>Now you have 1 COIN on Exchange One, and 2 COIN on Exchange Two,
but you need to record the 2 COIN on Exchange Two as two lots,
since they were purchased at different prices.</li>
<li>Later if you sell the 2 COIN on Exchange Two,
and your country uses FIFO rules for capital gains,
you need to sell the 1 COIN lot from Exchange One at 100 AUD cost basis,
and the 1 COIN lot from Exchange Two at 110 AUD cost basis.</li>
<li>Now you have 1 COIN lot at 120 AUD (purchased on Exchange Two),
but that 1 COIN is physically on Exchange One.</li>
</ul>
<p>So I ended up recording the physical locations with the real postings (ie. sell 2 COIN on Exchange Two),
and <a href="https://hledger.org/hledger.html#virtual-postings">virtual postings</a> for lots.
It involves a bit of manual work to ensure everything is balanced,
but has been working well for me so far.</p>
<h2 id="tutorial">Tutorial</h2>
<p>Here we'll step through an example sequence of transactions and events.
This will build up a complete valid ledger file, which is included in full after this tutorial.</p>
<p>Step 1 is to establish the starting state.
1000 AUD in the bank,
and exists an asset COIN that is currently worth 100 AUD per unit:</p>
<pre><code>; Add as many decimal points as you want to have precision to.
; 2 is usually standard for fiat,
; but you may need more for high value commodities.
commodity AUD
    format 100,000.00 AUD

commodity COIN
    format 100,000.00 COIN

2020-01-01 * opening balances
  assets:bank  1000 AUD
  equity:opening balances

P 2020-01-02 00:00:00 COIN 100 AUD
</code></pre>
<p>Now we're ready to invest in some COIN.
We need to record the exchange rate when it was purchased, to calculate capital gain/loss later.
We also use the real account <code>assets:exchange</code> with the COIN subaccount,
which makes sense because we've just bought COIN and it's on the exchange.</p>
<p>We also add a <a href="https://hledger.org/hledger.html#virtual-postings">virtual posting</a> to record the "lot".
This simply mirrors the COIN purchase, but is credited to an account that specifies which lot this is part of.
For cryptocurrency in Australia, the use case that this tutorial is assuming,
lots are taxed by FIFO (first in, first out), and everything in the lot must have been purchased at the same price.
This means that the simplest method of naming the lot is the date of purchase.</p>
<p>2021-02-03 EDIT: I've been informed that FIFO is not necessarily required in Australia; please do your own research to confirm for your use case.</p>
<pre><code>2020-01-02 * buy COIN
  assets:exchange:COIN  2 COIN @ 100 AUD
  assets:bank  -200 AUD
  (virtual:lots:2020-01-02)  2 COIN @ 100 AUD
</code></pre>
<p>Now the price of COIN versus AUD increases.
We purchase some more, using a new lot because the price has changed since the last lot,
and record everything similarly to last time.
The price then increases again the next day,
and then we move 1 COIN off the exchange to a hardware wallet.</p>
<pre><code>P 2020-01-03 00:00:00 COIN 150 AUD

2020-01-03 * buy more COIN
  assets:exchange:COIN  1 COIN @ 150 AUD
  assets:bank  -150 AUD
  (virtual:lots:2020-01-03)  1 COIN @ 150 AUD

P 2020-01-04 00:00:00 COIN 175 AUD

2020-01-04 * move COIN to hardware wallet
  assets:hardware wallet  1 COIN
  assets:exchange:COIN
</code></pre>
<p>We go into town and by a coffee at a fancy hipster café that accepts COIN.
It's an expensive coffee to make the maths simpler, don't judge.</p>
<pre><code>2020-01-04 * use COIN on hardware wallet
  assets:hardware wallet  -0.5 COIN @ 100 AUD
  expenses:coffee  0.5 COIN @ 175 AUD
  income:capital gains  -37.5 AUD
  (virtual:lots:2020-01-02)  -0.5 COIN @ 100 AUD
</code></pre>
<p>Things to note here:</p>
<p><code>assets:hardware wallet  -0.5 COIN @ 100 AUD</code> shows COIN at <em>cost basis</em>.
<code>expenses:coffee  0.5 COIN @ 175 AUD</code> shows COIN at the current exchange rate.
Since these two are different, the transaction will not be balanced,
and hledger will require an extra posting to balance it out - this is the <code>capital gains</code> posting.
Note that <code>-37.5 AUD</code> is the difference between <code>0.5 COIN @ 100 AUD</code> and <code>0.5 COIN @ 175 AUD</code>.
Hledger will calculate this part automatically if you leave the value out,
but I prefer to enter it to sanity check the value.</p>
<p>We're using the real posting for the physical location (hardware wallet),
and the independent virtual posting for the lot (FIFO, so first lot that still has a balance which is <code>2020-01-02</code>).
The physical location of <code>COIN</code> being spent is tracked, and so is the lot for tax purposes.
This was easy to calculate find the lot (the first lot is just above and we know it had 1 <code>COIN</code>),
and calculate the cost basis (one lot at 100 AUD, so 100 AUD).
We'll see a more complex example later.</p>
<blockquote>
<p>Just a side note here,
If you don't need to track capital gains on this purchase,
then we can make a simpler transaction like the one below.
This may or may not be the case depending on local tax laws, the type of <code>COIN</code>, why you purchased <code>COIN</code>, etc....
you'll need to do you're own research.
This tutorial just covers the basic case and assumes capital gains for everything.
For anything less complicated, you can just drop the AUD prices as in the transaction below.
For anything <em>more</em> complicated you'll need to be a bit more fancy about naming lots and such (for example if you have some lots that aren't subject to capital gains, or need to be sold in a different order for whatever reason).</p>
<pre><code>2020-01-04 * use COIN on hardware wallet
  assets:hardware wallet  -0.5 COIN
  expenses:coffee  0.5 COIN
  (virtual:lots:2020-01-02)  -0.5 COIN
</code></pre>
</blockquote>
<p>Now, just to make things more interesting and to show a more complex transaction later,
let's purchase more <code>COIN</code>, which of course is still increasing in worth.</p>
<pre><code>P 2020-01-05 00:00:00 COIN 200 AUD

2020-01-05 * and buy more COIN
  assets:exchange:COIN  1 COIN @ 200 AUD
  assets:bank  -200 AUD
  (virtual:lots:2020-01-05)  1 COIN @ 200 AUD

P 2020-01-06 00:00:00 COIN 300 AUD
</code></pre>
<p>Let's see what our balances currently are:</p>
<pre><code>❯ hledger bal -R
          450.00 AUD  assets:bank
           3.00 COIN  assets:exchange:COIN
           0.50 COIN  assets:hardware wallet
       -1,000.00 AUD  equity:opening balances
           0.50 COIN  expenses:coffee
          -37.50 AUD  income:capital gains
--------------------
         -587.50 AUD
           4.00 COIN
</code></pre>
<p>So there are 3 COIN on the exchange, and 0.5 COIN on the hardware wallet - two locations.</p>
<pre><code>❯ hledger bal lots
           1.50 COIN  virtual:lots:2020-01-02
           1.00 COIN  virtual:lots:2020-01-03
           1.00 COIN  virtual:lots:2020-01-05
--------------------
           3.50 COIN
</code></pre>
<p>But we have 3 virtual lots of COIN.
Note that if we <em>weren't</em> using virtual lots here, we would have difficulty calculating lot prices after moving COIN between the exchange and a hardware wallet,
and it would be difficult balancing transactions if we sold from the exchange, but needed to dispose of the lot recorded with the hardware wallet first...
Conversely, if we only used lots, we couldn't check the balance of the hardware wallet or exchange from hledger.</p>
<p>Now let's sell some COIN and make some profit!</p>
<pre><code>2020-01-06 * sell COIN on exchange
  assets:exchange:COIN  -2 COIN @ 112.5 AUD  ;(1.5*100 + 0.5*150) / 2 = 112.5
  assets:exchange:AUD  600 AUD
  income:capital gains  -375 AUD  ;(2*112.5 - 600)
  (virtual:lots:2020-01-02)  -1.5 COIN @ 100 AUD
  (virtual:lots:2020-01-03)  -0.5 COIN @ 150 AUD
</code></pre>
<p>So this is a little more complex.
We're selling 2 COIN on the exchange, but this now spans 2 lots.
To write this transaction, we need to follow some manual steps.</p>
<p>First we need to work out which lots to use, and how much from each.
If we run the <code>hledger bal lots</code> command from above,
we see a neat output conveniently ordered by date.</p>
<p>So we can take all of lot <code>2020-01-02</code> (1.5 COIN), and 0.5 COIN from the next lot, <code>2020-01-03</code>,
to sum to the 2 COIN we want.
We can find the cost basis of these lots, from the first time they are mentioned in the ledger file,
and enter the virtual postings in the new transaction.</p>
<p>We then find the cost basis of the entire transaction by multiplying the amount of COIN by the lot price for each lot,
and dividing by the amount of COIN being sold: <code>(1.5*100 + 0.5*150) / 2 = 112.5</code>
Then the total sell price is entered on the other side (600 AUD),
and …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.swalladge.net/archives/2021/01/30/hledger-tracking-capital-gains/">https://www.swalladge.net/archives/2021/01/30/hledger-tracking-capital-gains/</a></em></p>]]>
            </description>
            <link>https://www.swalladge.net/archives/2021/01/30/hledger-tracking-capital-gains/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25984236</guid>
            <pubDate>Mon, 01 Feb 2021 00:38:02 GMT</pubDate>
        </item>
    </channel>
</rss>
