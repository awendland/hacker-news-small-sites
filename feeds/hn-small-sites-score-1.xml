<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Fri, 02 Oct 2020 08:27:23 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Fri, 02 Oct 2020 08:27:23 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Gitlab CI/CD for cross-platform Unreal Engine 4 projects]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24637248">thread link</a>) | @me2too
<br/>
September 30, 2020 | https://pgaleone.eu/cicd/unreal-engine/2020/09/30/continuous-integration-with-unreal-engine-4/ | <a href="https://web.archive.org/web/*/https://pgaleone.eu/cicd/unreal-engine/2020/09/30/continuous-integration-with-unreal-engine-4/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<p>Continuous Integration (CI) is an essential step in the development pipeline of well-designed software infrastructure. The goal of CI is to <strong>automatize the boring stuff</strong> by letting the developers focusing on the code and, at the same time, helping them in producing good quality software.</p>
<p>Often, we read together two acronyms (and this article makes no exception) CI &amp; CD. While CI always stands for Continuous Integration, CD has two different meanings:</p>
<ol>
<li><strong>Continuous Delivery</strong> where a developer’s change is automatically bug-tested and uploaded to a repository, or</li>
<li><strong>Continuous Deployment</strong> where a developer’s change is automatically released to the production environment, where the customer can use this brand-new version.</li>
</ol>
<p>In this article, I’m going to show you how to configure and use the CI/CD tool provided by GitLab to correctly manage the CI/CD pipeline of an <strong>Unreal Engine 4 (UE4) project</strong> that needs to work (and thus, to be tested) on 3 different platforms:</p>
<ul>
<li>Windows</li>
<li>macOS</li>
<li>Linux</li>
</ul>
<p>In the following, “CD” will stand for Continuous Delivery - so I won’t cover the Deployment part.</p>

<p><a href="https://about.gitlab.com/">GitLab</a> is a complete DevOps platform: it offers us a complete CI/CD toolchain, an amazing issue tracking suite, and exposes in a user-friendly-way almost every Git’s feature.</p>
<p><img src="https://pgaleone.eu/images/ciue4/cicd_pipeline_infograph.png" alt="GitLab Continuous Integration pipeline"></p>
<p>The CI/CD toolchain is composed of 3 main parts:</p>
<ul>
<li>The <code>gitlab-ci.yml</code> file that contains the configuration of the CI/CD pipeline. Using this YAML file we can configure the CI/CD behavior: what should happen on every commit or merge request, what should happen at scheduled times, and <a href="https://docs.gitlab.com/ee/ci/yaml/">many many more</a>. This file contains the commands to execute (a batch of commands is called “job”) on the specified runner.</li>
<li><a href="https://docs.gitlab.com/runner/">GitLab Runners</a>. A runner is a software able to receive from GitLab a job, execute it, and send back the result to GitLab. Several runners can (and should) run in parallel, allowing the whole infrastructure to scale. The execution of the job is delegated to an “executor”.</li>
<li><strong>The executor</strong>. During the configuration of the runner, we can specify what type of executor to use. In particular, it’s possible to use the machine where the runner is installed to run directly in its shell the commands (that’s the shell executor), or use Docker to execute the commands into a container, or even use a virtual machine or a Kubernetes cluster (for a complete reference see: https://docs.gitlab.com/runner/executors/).</li>
</ul>
<p>The amazing thing is that GitLab Runner is a software written in Go: this means that it can run perfectly on our three target platforms: Windows, macOS, and Linux.</p>
<p>Moreover, installing it is trivial as explained in <a href="https://docs.gitlab.com/runner/#install-gitlab-runner">the documentation</a>.</p>
<h2 id="executors-for-ue4-projects">Executors for UE4 projects</h2>
<p><a href="https://www.unrealengine.com/en-US/">Unreal Engine</a> is a cross-platform game engine, quoting the official website:</p>
<blockquote>
<p>Unreal Engine is the world’s most open and advanced real-time 3D creation tool. Continuously evolving to serve not only its original purpose as a state-of-the-art game engine, today it gives creators across industries the freedom and control to deliver cutting-edge content, interactive experiences, and immersive virtual worlds.</p>
</blockquote>
<p>UE4 is really an amazing project, but this amazingness comes at a cost: it’s <strong>heavy</strong>. The engine itself, <a href="https://docs.unrealengine.com/en-US/GettingStarted/DownloadingUnrealEngine/index.html">available on GitHub</a>, weights ~132GB on Linux:</p>
<div><div><pre><code><span>du</span> <span>-hs</span> /opt/unreal-engine/
132G    /opt/unreal-engine/
</code></pre></div></div>
<p>Since our goal is to create an environment that contains the compiled engine (for our three target platforms) and use it inside our CI. Using a <strong>Docker executor</strong> it is perhaps the best possible solution.</p>
<h3 id="docker-executor">Docker executor</h3>
<p>As previously stated, one of the costs of using UE4 is its size: when we have enough resources this isn’t a problem (you need a good amount of storage and a lot of memory and CPU power to compile and use the engine), and it’s not a problem even when using Docker on Linux. However, building a Docker image containing UE4 on Windows is somehow a difficult and long process, because there is a well-know and <em>unresolved</em> issue about the creation of <a href="https://github.com/moby/moby/issues/37581">filesystem layers lager than 8 GiB</a>.</p>
<p>Although there are well-known issues (only on Windows), using a Docker executor have a lot of advantages like:</p>
<ul>
<li>Spawning a container is a cheap operation.</li>
<li>Every container is isolated.</li>
<li>It is possible to scale the solution easily (easy to parallelize).</li>
<li>Customizing/Creating a Dockerfile is easy.</li>
</ul>
<p>Creating docker containers with unreal-engine inside is a challenge that <a href="https://adamrehn.com/">Adam Rehn</a> with his <a href="https://unrealcontainers.com/">Unreal Containers</a> <strong>amazingly faced</strong>.</p>
<p><img src="https://pgaleone.eu/images/ciue4/ue-plus-docker.svg" alt="UnrealContainer logo"></p>
<p>The project, and Python package, <a href="https://docs.adamrehn.com/ue4-docker/read-these-first/introduction-to-ue4-docker">ue4-docker</a> contains all we need to create a docker image that we will later on use in our <code>.gitlab-ci.yml</code> file.</p>
<p>Using <code>ue4-docker</code> creating an image is so easy as:</p>
<div><div><pre><code><span>REPO_URL</span><span>=</span><span>"&lt;set url here&gt;"</span>
<span>BRANCH</span><span>=</span><span>"&lt;set branch here&gt;"</span>
ue4-docker build custom:4.25.3 <span>-repo</span><span>=</span><span>"</span><span>$REPO_URL</span><span>"</span> <span>-branch</span><span>=</span><span>"</span><span>$BRANCH</span><span>"</span> <span>\</span>
           <span>--exclude</span> debug <span>\ </span><span># exclude debug symbols to reduce the image and workaround the windows issue</span>
           <span>--exclude</span> templates <span>\ </span><span># exclude the templates since we don't need them in our CI</span>
           <span>--exclude</span> ddc <span># exclude DDC to speed up the image creation </span>
</code></pre></div></div>
<p>The same command can be executed in a Linux and in a Windows machine. Personally, I prefer having a Linux machine that executes a docker container, instead of using a Windows machine to execute a docker container containing a Linux image (for performance reasons and to save time during the creation of the images too).</p>
<p>At the end of the execution of the <code>ue4-docker</code> command, we end up with a set of images ready to use like:</p>
<div><div><pre><code>docker images | grep ue4

adamrehn/ue4-full                           4.25.3                        01562ee9c264        9 days ago          15.6GB
adamrehn/ue4-full                           4.25.3-opengl                 01562ee9c264        9 days ago          15.6GB
adamrehn/ue4-minimal                        4.25.3                        561beaae1f0f        9 days ago          14GB
adamrehn/ue4-minimal                        4.25.3-opengl                 561beaae1f0f        9 days ago          14GB
adamrehn/ue4-engine                         4.25.3                        717a019f5917        9 days ago          85.6GB
adamrehn/ue4-engine                         4.25.3-opengl                 717a019f5917        9 days ago          85.6GB
adamrehn/ue4-source                         4.25.3                        dce5e2cdbc65        9 days ago          54.7GB
adamrehn/ue4-source                         4.25.3-opengl                 dce5e2cdbc65        9 days ago          54.7GB
adamrehn/ue4-build-prerequisites            opengl                        ec75c0a656c0        7 months ago        584MB
</code></pre></div></div>
<p>A complete description of what is inside every image is available in the <a href="https://docs.adamrehn.com/ue4-docker/building-images/available-container-images">List of available container images</a> page.</p>
<p>Using Docker we can cover the CI for the Linux and Windows platforms. macOS, instead, can’t run inside a container :( hence we have to use another executor.</p>
<h3 id="shell-executor">Shell executor</h3>
<p>The shell executor is just “the current machine”. Thus, we can install <a href="https://docs.gitlab.com/runner/install/osx.html">GitLab Runner on macOS</a> and manually install all the dependencies that are, in our case, only unreal engine and the Xcode toolchain.</p>
<p>Differently from the Docker executor, the Shell executor has several disadvantages:</p>
<ul>
<li>No isolation at all.</li>
<li>No native support for parallel and isolated executions.</li>
<li>It doesn’t scale well.</li>
<li>We have to clean up the dirt left by the operations we do in the CI (e.g. temporary files).</li>
</ul>
<p>The only advantage we have is the simplicity of installation: we just have to install UE4 on our machine and we are ready to go.</p>
<p>Supposing to have Unreal Engine already installed (the setup on Mac, Linux, Windows is straightforward; it’s just a matter of following the <a href="https://docs.unrealengine.com/en-US/GettingStarted/Installation/index.html">guide</a>), the only thing we need to do is to install another Python tool created by Adam Rehn: <a href="https://docs.adamrehn.com/ue4cli/overview/introduction-to-ue4cli">ue4cli</a>.</p>
<p>This Python package implements a command-line tool called <code>ue4</code>: this tool simplifies the invocation/usage of the UE4 toolchain and, perhaps more importantly, it unifies the interface we have to use on different platforms.</p>
<p>The tool is installed into the <code>ue4-full</code> images and that’s the reason we’re going to use these images in our <code>gitlab-ci.yml</code> file.</p>
<h2 id="the-cicd-pipeline">The CI/CD pipeline</h2>
<p>As introduced at the beginning of the article, after setting up the runners and the executor, we are ready to describe the CI/CD pipeline in the <code>.gitlab-ci.yml</code> file.</p>
<h3 id="continuous-integration">Continuous Integration</h3>
<p>Let’s start with the automatization of the boring stuff, we need to find a way to automatically answer these questions:</p>
<ol>
<li>Is the code following the code style / required formatting?</li>
<li>Does the code I want to merge compile correctly on every platform?</li>
<li>Am I introducing regressions?</li>
</ol>
<p>To answer all these questions, and be ready for the continuous delivery stuff, we need to define the variables and the stages (of the pipeline) we plan to execute.</p>
<div><div><pre><code><span>variables</span><span>:</span>
    <span>GIT_SUBMODULE_STRATEGY</span><span>:</span> <span>"</span><span>recursive"</span>
    <span>GIT_STRATEGY</span><span>:</span> <span>"</span><span>fetch"</span>
    <span>GIT_CHECKOUT</span><span>:</span> <span>"</span><span>true"</span>
    <span>GIT_SSL_NO_VERIFY</span><span>:</span> <span>"</span><span>1"</span>
    <span>GET_SOURCES_ATTEMPTS</span><span>:</span> <span>"</span><span>10"</span>

<span>stages</span><span>:</span>
    <span>-</span> <span>static-analysis</span>
    <span>-</span> <span>build</span>
    <span>-</span> <span>tests</span>
    <span>-</span> <span>package</span>
</code></pre></div></div>
<ul>
<li>The <strong>static-analysis</strong> stage will contain the jobs related to the source code analysis. The checks for the source code formatting (the only one presented in this article) and other checks related to the analysis of the source code itself.</li>
<li>The <strong>build</strong> stage will contain the jobs that answer question 2.</li>
<li>The <strong>test</strong> stage contains the execution of the test cases (because every unreal project uses the unreal test suite - isn’t it?)</li>
<li>The <strong>package</strong> stage contains the continuous delivery part of the pipeline.</li>
</ul>
<h5 id="static-analysis">Static Analysis</h5>
<p>Every C++ project should follow a code style. This CI job uses <code>clang-format</code> and <code>dos2unix</code> to check if every committed file has the correct encoding (we need UTF-8 encoded files to be sure that every compiler on every platform can read them well) and follows the style rules present in the <code>.clang-format</code> file that should be present into every project :)</p>
<div><div><pre><code><span>clang-format</span><span>:</span>
    <span>image</span><span>:</span> <span>alpine</span>
    <span>stage</span><span>:</span> <span>static-analysis</span>
    <span>variables</span><span>:</span>
        <span>GIT_LFS_SKIP_SMUDGE</span><span>:</span> <span>"</span><span>1"</span>
    <span># empty dependencies = do not need artifacts from previous stages</span>
    <span>dependencies</span><span>:</span> <span>[]</span>
    <span>script</span><span>:</span>
        <span>-</span> <span>apk update &amp;&amp; apk add clang git bash dos2unix</span>
        <span>-</span> <span>exclude=$(for d in $(git …</span></code></pre></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pgaleone.eu/cicd/unreal-engine/2020/09/30/continuous-integration-with-unreal-engine-4/">https://pgaleone.eu/cicd/unreal-engine/2020/09/30/continuous-integration-with-unreal-engine-4/</a></em></p>]]>
            </description>
            <link>https://pgaleone.eu/cicd/unreal-engine/2020/09/30/continuous-integration-with-unreal-engine-4/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24637248</guid>
            <pubDate>Wed, 30 Sep 2020 10:33:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Book: Epic Alignment – How the best Product Managers work with feature documents]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24637233">thread link</a>) | @njanse
<br/>
September 30, 2020 | https://www.delibr.com/ebook | <a href="https://web.archive.org/web/*/https://www.delibr.com/ebook">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<h3>What's inside</h3>
<p>How can you drive the thinking on what to develop, why and how to
do it — leveraging the insights from both team and stakeholders — all the way from idea to
deploy?</p>
<p>This book tries to answer the above question. As part of our own
product development at Delibr, we interviewed over 300 Product Managers to understand how they work
and collaborate around feature development, what problems they face, and the many approaches to
solving those problems. </p>
<p>"Epic alignment" describes four broad approaches that we saw help
Product Managers excel.</p>
<h3>What you'll learn</h3>
<ul>
<li>How to drive product development towards impact based on research</li>
<li>How to use user stories as a shared language to align your entire team</li>
<li>How to write feature documents that drive joint understanding and act as a single source of
truth
</li>
<li>How to tackle the massive amounts of decisions needed for every epic</li>
</ul>
</div></div>]]>
            </description>
            <link>https://www.delibr.com/ebook</link>
            <guid isPermaLink="false">hacker-news-small-sites-24637233</guid>
            <pubDate>Wed, 30 Sep 2020 10:29:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Most popular GraphgQL server implementations]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24637210">thread link</a>) | @oczek
<br/>
September 30, 2020 | https://blog.graphqleditor.com/graphql-servers/ | <a href="https://web.archive.org/web/*/https://blog.graphqleditor.com/graphql-servers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>GraphQL is a query language for APIs that describes how to ask &amp; fetch the data from the server to the client which of course requires setting up a server. Below you will find a list of the most popular GraphgQL server implementations. There’s quite a few of them so we’re not going to get through the lot of them in one go.</p>
<h2>Express GraphQL</h2>
<p>It is said that <a href="https://github.com/graphql/express-graphql">Express GraphQL</a> is the simplest way to run a GraphQL API server. Express is a popular web application framework for Node.js allowing you to create a GraphQL server with any HTTP web framework supporting connect styled middleware including <a href="https://expressjs.com/">Express</a>, <a href="http://restify.com/">Restify</a> and, of course, <a href="https://github.com/senchalabs/connect">Connect</a>. Getting started is as easy as installing some additional dependencies in form of <code>npm install express express-graphql graphql --save</code></p>
<p><span>
      <a href="https://blog.graphqleditor.com/static/d8c5b170d7059b55a31da3c1de450fb5/21b4d/express.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Express GraphQL" title="Express GraphQL" src="https://blog.graphqleditor.com/static/d8c5b170d7059b55a31da3c1de450fb5/fcda8/express.png" srcset="https://blog.graphqleditor.com/static/d8c5b170d7059b55a31da3c1de450fb5/12f09/express.png 148w,
https://blog.graphqleditor.com/static/d8c5b170d7059b55a31da3c1de450fb5/e4a3f/express.png 295w,
https://blog.graphqleditor.com/static/d8c5b170d7059b55a31da3c1de450fb5/fcda8/express.png 590w,
https://blog.graphqleditor.com/static/d8c5b170d7059b55a31da3c1de450fb5/efc66/express.png 885w,
https://blog.graphqleditor.com/static/d8c5b170d7059b55a31da3c1de450fb5/c83ae/express.png 1180w,
https://blog.graphqleditor.com/static/d8c5b170d7059b55a31da3c1de450fb5/21b4d/express.png 1280w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://graphql.org/graphql-js/running-an-express-graphql-server/">graphql.org</a></h5>
<h2>Apollo GraphQL Server</h2>
<p><a href="https://github.com/apollographql/apollo-server">Apollo GraphQL Server</a> is an open-source GraphQL server compatible with any GraphQL client and it’s an easy way to build a production-ready, self-documenting GraphQL API that can use data from any source. Apollo Server can be used as a stand-alone GraphQL server, a plugin to your application’s Node.js middleware, or as a gateway for a federated data graph. Apollo GraphQL Server offers:</p>
<ul>
<li><strong>easy setup</strong> - client-side can start fetching data instantly,</li>
<li><strong>incremental adoption</strong> - elastic approach to adding new features, you can add them easily later on when you decide they’re needed,</li>
<li><strong>universality</strong> - compatibility with any data source, multiple
build tools and GraphQL clients,</li>
<li><strong>production-ready</strong> - tested across various enterprise-grade projects.</li>
</ul>
<p><span>
      <a href="https://blog.graphqleditor.com/static/b7f98cac82ca2ea3fce952f1f25867a3/23266/apollo.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Apollo GraphQL Server" title="Apollo GraphQL Server" src="https://blog.graphqleditor.com/static/b7f98cac82ca2ea3fce952f1f25867a3/fcda8/apollo.png" srcset="https://blog.graphqleditor.com/static/b7f98cac82ca2ea3fce952f1f25867a3/12f09/apollo.png 148w,
https://blog.graphqleditor.com/static/b7f98cac82ca2ea3fce952f1f25867a3/e4a3f/apollo.png 295w,
https://blog.graphqleditor.com/static/b7f98cac82ca2ea3fce952f1f25867a3/fcda8/apollo.png 590w,
https://blog.graphqleditor.com/static/b7f98cac82ca2ea3fce952f1f25867a3/efc66/apollo.png 885w,
https://blog.graphqleditor.com/static/b7f98cac82ca2ea3fce952f1f25867a3/23266/apollo.png 923w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://github.com/apollographql/apollo-server">apollographql.com</a></h5>
<h2>Hot Chocolate</h2>
<p><a href="https://hotchocolate.io/">Hot Chocolate</a> is a GraphQL server you can use to create GraphQL endpoints,  merge schemas, etc. Hot Chocolate is a part of a .NET based <a href="https://github.com/ChilliCream/hotchocolate">ChilliCream GraphQL Platform</a> that can help you build a GraphQL layer over your existing and new infrastructure. It provides pre-built templates that let you start in seconds, supporting both ASP.Net Core as well as ASP.Net Framework out of the box.</p>
<p><span>
      <a href="https://blog.graphqleditor.com/static/0e8f4aada898797c50c04bb75e6a98ec/23266/hotchoc.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Hot Chocolate is a part of ChilliCream GraphQL Platform" title="Hot Chocolate is a part of ChilliCream GraphQL Platform" src="https://blog.graphqleditor.com/static/0e8f4aada898797c50c04bb75e6a98ec/fcda8/hotchoc.png" srcset="https://blog.graphqleditor.com/static/0e8f4aada898797c50c04bb75e6a98ec/12f09/hotchoc.png 148w,
https://blog.graphqleditor.com/static/0e8f4aada898797c50c04bb75e6a98ec/e4a3f/hotchoc.png 295w,
https://blog.graphqleditor.com/static/0e8f4aada898797c50c04bb75e6a98ec/fcda8/hotchoc.png 590w,
https://blog.graphqleditor.com/static/0e8f4aada898797c50c04bb75e6a98ec/efc66/hotchoc.png 885w,
https://blog.graphqleditor.com/static/0e8f4aada898797c50c04bb75e6a98ec/23266/hotchoc.png 923w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://github.com/ChilliCream/hotchocolate">github.com/ChilliCream/hotchocolate</a></h5>
<h2>Hasura GraphQL Engine</h2>
<p><a href="https://github.com/hasura/graphql-engine">Hasura GraphQL Engine</a> is a GraphQL server that gives you realtime GraphQL APIs over Postgres, making easy building your new Postgress-backed GraphQL app or adding a GraphQL layer for your existing Postgres bases app.  Hasura GraphQL Engine offers built-in filtering, pagination, merging remote schemas along with many other useful features. All that keeping high-performance &amp; footprint at the lowest possible rate.</p>
<p><span>
      <a href="https://blog.graphqleditor.com/static/522960eb8b0af0ea8789fac5f6c91c9b/d9199/hasura.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Hasura GraphQL Engine" title="Hasura GraphQL Engine" src="https://blog.graphqleditor.com/static/522960eb8b0af0ea8789fac5f6c91c9b/fcda8/hasura.png" srcset="https://blog.graphqleditor.com/static/522960eb8b0af0ea8789fac5f6c91c9b/12f09/hasura.png 148w,
https://blog.graphqleditor.com/static/522960eb8b0af0ea8789fac5f6c91c9b/e4a3f/hasura.png 295w,
https://blog.graphqleditor.com/static/522960eb8b0af0ea8789fac5f6c91c9b/fcda8/hasura.png 590w,
https://blog.graphqleditor.com/static/522960eb8b0af0ea8789fac5f6c91c9b/efc66/hasura.png 885w,
https://blog.graphqleditor.com/static/522960eb8b0af0ea8789fac5f6c91c9b/d9199/hasura.png 960w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://github.com/hasura/graphql-engine">github.com/hasura</a></h5>
<h2>API PLATFORM</h2>
<p><a href="https://github.com/api-platform/api-platform">API Platform</a> is a set of tools that combined build a modern framework for building REST and GraphQL APIs including GraphQL Server. The server solution is located in the API Platform Core Library which is built on top of Symfony 4 (PHP) microframework and the Doctrine ORM. API Platform Core Library is a highly flexible solution allowing you to build fully-featured GraphQL API in minutes.</p>
<p><span>
      <a href="https://blog.graphqleditor.com/static/06c54d11146913c58117559a32674596/2cefc/apiplatform.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="API PLATFORM" title="API PLATFORM" src="https://blog.graphqleditor.com/static/06c54d11146913c58117559a32674596/fcda8/apiplatform.png" srcset="https://blog.graphqleditor.com/static/06c54d11146913c58117559a32674596/12f09/apiplatform.png 148w,
https://blog.graphqleditor.com/static/06c54d11146913c58117559a32674596/e4a3f/apiplatform.png 295w,
https://blog.graphqleditor.com/static/06c54d11146913c58117559a32674596/fcda8/apiplatform.png 590w,
https://blog.graphqleditor.com/static/06c54d11146913c58117559a32674596/efc66/apiplatform.png 885w,
https://blog.graphqleditor.com/static/06c54d11146913c58117559a32674596/c83ae/apiplatform.png 1180w,
https://blog.graphqleditor.com/static/06c54d11146913c58117559a32674596/2cefc/apiplatform.png 1400w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://api-platform.com/">api-platform.com</a></h5>
<h2>Parse Server GraphQL API</h2>
<p>In addition to the traditional REST API, Parse Server automatically generates a GraphQL API basing on a given schema. <a href="https://docs.parseplatform.org/graphql/guide/">Parse Server GraphQL API</a> follows Relay specification along with the latest industry standards which makes it a perfect choice for modern projects requiring the highest-scalability.</p>
<p><span>
      <a href="https://blog.graphqleditor.com/static/48c5fb34b2f1914c334930add2472828/00d43/parse.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Parse Server GraphQL API " title="Parse Server GraphQL API " src="https://blog.graphqleditor.com/static/48c5fb34b2f1914c334930add2472828/fcda8/parse.png" srcset="https://blog.graphqleditor.com/static/48c5fb34b2f1914c334930add2472828/12f09/parse.png 148w,
https://blog.graphqleditor.com/static/48c5fb34b2f1914c334930add2472828/e4a3f/parse.png 295w,
https://blog.graphqleditor.com/static/48c5fb34b2f1914c334930add2472828/fcda8/parse.png 590w,
https://blog.graphqleditor.com/static/48c5fb34b2f1914c334930add2472828/efc66/parse.png 885w,
https://blog.graphqleditor.com/static/48c5fb34b2f1914c334930add2472828/00d43/parse.png 1000w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://docs.parseplatform.org/graphql/guide/">docs.parseplatform.org/graphql/guide</a></h5>
<p>That’s it for the first look at GraphQL servers. So if I missed your favorite one, just mention it in the comments and stay tuned for the next parts!</p></div><p>The GraphQL Editor is a supportive tool for both advanced GraphQL users as well as those taking their first steps with GraphQL APIs. Our all-in-one development environment for GraphQL will help you build, manage &amp; deploy your GraphQL API much faster thanks to dozens of built-in micro features. Its graphical interface will also fix communication within your product team. Visualization is the key!</p></div>]]>
            </description>
            <link>https://blog.graphqleditor.com/graphql-servers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24637210</guid>
            <pubDate>Wed, 30 Sep 2020 10:26:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Commodore 64 Program Discovered on 35-Year Old Vinyl Album]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24637146">thread link</a>) | @clockworksoul
<br/>
September 30, 2020 | https://popcultureretrorama.com/2019/11/25/35-years-later-a-commodore-64-program-was-found-on-this-1984-album/ | <a href="https://web.archive.org/web/*/https://popcultureretrorama.com/2019/11/25/35-years-later-a-commodore-64-program-was-found-on-this-1984-album/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1304">
	
	<div>
		
<p>Friends, this should give you a little boost at the end of your day – because 8-Bit Show and Tell has located a Commodore 64 program hidden within Prodigal’s 1984 album entitled Electric Eye. I was just goofing around on YouTube when I came across this video – which was originally uploaded back on October 19th of this year. Since I have been known to talk about my love of the Commdore 64 computer of my youth – the title of the video caught my attention pretty quickly. And seriously, how absolutely amazing is it that in this day and age we can still be surprised by little Easter eggs from 35 years ago? As Robin will demonstrate on the video itself the program was hidden in the runout groove on the B side of <em>Electric Eye</em>  – which you can plainly see in this article image header has a “C-64” scratched into said groove. Probably one of the reasons that not a lot of people know about the program is because it needed to be played on your turntable where you could record the hidden program on a cassette tape to upload it on your C64… that is a little bit of work. As the video will show – sometimes using older technology takes a couple of tries – or even totally different equipment in some cases.</p>







<p>I will have to in the near future share an article about the Mattel Electronics Aquarius computer that we obtained at the arcade – in fact I talked just a bit about it in the <em><a href="https://popcultureretrorama.com/2019/11/24/diary-of-an-arcade-employee-podcast-1up-night-stalker/">Night Stalker</a></em> podcast earlier today. Robin was able to make contact with one of the surviving members of <strong>Prodigal</strong> by the way – which was a Christian rock group, active from 1975 until 1986 – to ask how and why this 35 year-old computer program was included on the <em>Electric Eye</em> album. </p>



<div><figure><img data-attachment-id="1306" data-permalink="https://popcultureretrorama.com/2019/11/25/35-years-later-a-commodore-64-program-was-found-on-this-1984-album/35-years-later-a-commodore-64-program-electric-eye/" data-orig-file="https://i0.wp.com/popcultureretrorama.com/wp-content/uploads/2019/11/35-Years-Later-A-Commodore-64-Program-Electric-Eye.jpg?fit=700%2C394&amp;ssl=1" data-orig-size="700,394" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="35-Years-Later-A-Commodore-64-Program-Electric-Eye" data-image-description="" data-medium-file="https://i0.wp.com/popcultureretrorama.com/wp-content/uploads/2019/11/35-Years-Later-A-Commodore-64-Program-Electric-Eye.jpg?fit=300%2C169&amp;ssl=1" data-large-file="https://i0.wp.com/popcultureretrorama.com/wp-content/uploads/2019/11/35-Years-Later-A-Commodore-64-Program-Electric-Eye.jpg?fit=640%2C360&amp;ssl=1" loading="lazy" width="640" height="360" src="https://i0.wp.com/popcultureretrorama.com/wp-content/uploads/2019/11/35-Years-Later-A-Commodore-64-Program-Electric-Eye.jpg?resize=640%2C360&amp;ssl=1" alt="" srcset="https://i0.wp.com/popcultureretrorama.com/wp-content/uploads/2019/11/35-Years-Later-A-Commodore-64-Program-Electric-Eye.jpg?w=700&amp;ssl=1 700w, https://i0.wp.com/popcultureretrorama.com/wp-content/uploads/2019/11/35-Years-Later-A-Commodore-64-Program-Electric-Eye.jpg?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/popcultureretrorama.com/wp-content/uploads/2019/11/35-Years-Later-A-Commodore-64-Program-Electric-Eye.jpg?resize=150%2C84&amp;ssl=1 150w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/popcultureretrorama.com/wp-content/uploads/2019/11/35-Years-Later-A-Commodore-64-Program-Electric-Eye.jpg?w=700&amp;ssl=1 700w, https://i0.wp.com/popcultureretrorama.com/wp-content/uploads/2019/11/35-Years-Later-A-Commodore-64-Program-Electric-Eye.jpg?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/popcultureretrorama.com/wp-content/uploads/2019/11/35-Years-Later-A-Commodore-64-Program-Electric-Eye.jpg?resize=150%2C84&amp;ssl=1 150w" data-lazy-src="https://i0.wp.com/popcultureretrorama.com/wp-content/uploads/2019/11/35-Years-Later-A-Commodore-64-Program-Electric-Eye.jpg?resize=640%2C360&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<p>The discovery of what amounts to a simple message from <strong>Prodigal</strong> 35 years later might not be the most groundbreaking thing you’ll see today… but I thought it was special enough that I had to share it. Watching this particular 8-Bit Show and Tell video will in addition show you how to hack your turntable to disable the auto return if you need to!</p>



<figure><p><span><iframe width="640" height="360" src="https://www.youtube.com/embed/6_CZpFqvDQo?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span>
</p></figure>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

			<div>
	
	<p>
		An avid devotee to pretty much all things pop culture and retro related - I love to share my memories and passion for films, comics, gaming, podcasting... and curiously enough my overwhelming desire to never stop eating beef jerky.		<a href="https://popcultureretrorama.com/author/vicsagepopculture/" rel="author">
			View more posts		</a>
	</p><!-- .author-description -->
</div><!-- .author-bio -->
	
</article></div>]]>
            </description>
            <link>https://popcultureretrorama.com/2019/11/25/35-years-later-a-commodore-64-program-was-found-on-this-1984-album/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24637146</guid>
            <pubDate>Wed, 30 Sep 2020 10:13:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Letter to the Patent Office from Professor Donald Knuth (1994)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24636837">thread link</a>) | @pncnmnp
<br/>
September 30, 2020 | http://www.pluto.it/files/meeting1999/atti/no-patents/brevetti/docs/knuth_letter_en.html | <a href="https://web.archive.org/web/*/http://www.pluto.it/files/meeting1999/atti/no-patents/brevetti/docs/knuth_letter_en.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<h2><cite>Programming Freedom</cite> - February 1995 - Number 11</h2>

<p>League For Programming Freedom<br>
1 Kendall Square #143<br>
P.O. Box 9171<br>
Cambridge, MA 02139 </p>

<p><em>Programming Freedom</em> is the Newsletter of The League For Programming Freedom.
Visit our web page: <a href="http://lpf.ai.mit.edu/">http://lpf.ai.mit.edu </a>. 
Reproduction of <em>Programming Freedom</em> via all media is encouraged. To reproduce a signed 
article individually, please contact the author for permission.</p>

<hr>

<h2><a name="knuth">Letter to the Patent Office From Professor Donald Knuth</a></h2>

<p>Professor Donald Knuth of Stanford University is the world's leading authority on
algorithms. His magnum opus, the three volume work the "The Art of Computer
Programming," is the most important reference work on algorithms. Knuth also
developed the mathematical text formatter TeX and the idea of "literate
programming". Supporting evidence of Knuth's position are the following distinctions:

</p><dl>
  <dt>National Medal of Science </dt>
  <dt>Member, National Academy of Sciences </dt>
  <dt>Member, National Academy of Engineering </dt>
  <dt>Fellow, American Academy of Arts and Sciences </dt>
  <dt>Turing Award, Association for Computing Machinery </dt>
  <dt>18 Honorary Doctorates </dt>
</dl>

<p>The first four of these distinctions are the highest American awards for scientists.
Since there is no Nobel prize in computing, the receipt of the Turing award is often
regarded as having a similar status.</p>

<p>Through these honors, Knuth is perhaps the most distinguished living exponent of the
field of computer science. He is also now a member of the League for Programming Freedom.</p>

<p>Here is the letter he sent in February 1994 to the Patent Commissioner on the subject
of software patents.</p>

<pre>Commissioner of Patents and Trademarks
Box 4
Patent and Trademark Office
Washington, DC 20231

Dear Commissioner:

Along with many other computer scientists, I would like to ask you to 
reconsider the current policy of giving patents for computational 
processes.  I find a considerable anxiety throughout the community of 
practicing computer scientists that decisions by the patent courts and the 
Patent and Trademark Office are making life much more difficult for 
programmers.

In the period 1945-1980, it was generally believed that patent law did not 
pertain to software.  However, it now appears that some people have 
received patents for algorithms of practical importance - e.g., Lempel-Ziv 
compression and RSA public key encryption - and are now legally preventing 
other programmers from using these algorithms.

This is a serious change from the previous policy under which the computer 
revolution became possible, and I fear this change will be harmful for 
society.  It certainly would have had a profoundly negative effect on my 
own work: For example, I developed software called TeX that is now used to 
produce more than 90% of all books and journals in mathematics and physics 
and to produce hundreds of thousands of technical reports in all scientific 
disciplines.  If software patents had been commonplace in 1980, I would not 
have been able to create such a system, nor would I probably have ever 
thought of doing it, nor can I imagine anyone else doing so.

I am told that the courts are trying to make a distinction between 
mathematical algorithms and nonmathematical algorithms.  To a computer 
scientist, this makes no sense, because every algorithm is as mathematical 
as anything could be.  An algorithm is an abstract concept unrelated to 
physical laws of the universe.

Nor is it possible to distinguish between "numerical" and "nonnumerical" 
algorithms, as if numbers were somehow different from other kinds of 
precise information.  All data are numbers, and all numbers are data.  
Mathematicians work much more with symbolic entities than with numbers.

Therefore the idea of passing laws that say some kinds of algorithms belong 
to mathematics and some do not strikes me as absurd as the 19th century 
attempts of the Indiana legislature to pass a law that the ratio of a 
circle's circumference to its diameter is exactly 3, not approximately 
3.1416.  It's like the medieval church ruling that the sun revolves about 
the earth.  Man-made laws can be significantly helpful but not when they 
contradict fundamental truths.

Congress wisely decided long ago that mathematical things cannot be 
patented.  Surely nobody could apply mathematics if it were necessary to 
pay a license fee whenever the theorem of Pythagoras is employed.  The 
basic algorithmic ideas that people are now rushing to patent are so 
fundamental, the result threatens to be like what would happen if we 
allowed authors to have patents on individual words and concepts.  
Novelists or journalists would be unable to write stories unless their 
publishers had permission from the owners of the words.  Algorithms are 
exactly as basic to software as words are to writers, because they are the 
fundamental building blocks needed to make interesting products.  What 
would happen if individual lawyers could patent their methods of defense, 
or if Supreme Court justices could patent their precedents?

I realize that the patent courts try their best to serve society when they 
formulate patent law.  The Patent Office has fulfilled this mission 
admirably with respect to aspects of technology that involve concrete laws 
of physics rather than abstract laws of thought.  I myself have a few 
patents on hardware devices.  But I strongly believe that the recent trend 
to patenting algorithms is of benefit only to a very small number of 
attorneys and inventors, while it is seriously harmful to the vast majority 
of people who want to do useful things with computers.

When I think of the computer programs I require daily to get my own work 
done, I cannot help but realize that none of them would exist today if 
software patents had been prevalent in the 1960s and 1970s.  Changing the 
rules now will have the effect of freezing progress at essentially its 
current level.  If present trends continue, the only recourse available to 
the majority of America's brilliant software developers will be to give up 
software or to emigrate.  The U.S.A.  will soon lose its dominant position.

Please do what you can to reverse this alarming trend.  There are far 
better ways to protect the intellectual property rights of software 
developers than to take away their right to use fundamental building 
blocks.

Sincerely,
Donald E. Knuth
Professor Emeritus
</pre>

<hr>

<p><a href="http://lpf.ai.mit.edu/">http://lpf.ai.mit.edu</a>


</p></div>]]>
            </description>
            <link>http://www.pluto.it/files/meeting1999/atti/no-patents/brevetti/docs/knuth_letter_en.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24636837</guid>
            <pubDate>Wed, 30 Sep 2020 09:02:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It Is Never a Compiler Bug Until It Is]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24636326">thread link</a>) | @nullc
<br/>
September 30, 2020 | http://r6.ca/blog/20200929T023701Z.html | <a href="https://web.archive.org/web/*/http://r6.ca/blog/20200929T023701Z.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>Last week I was trying to add some <a href="https://github.com/bitcoin-core/secp256k1/pull/822/commits/aa833603a6b4c947c21da04aeac40d80444ebcc1#diff-b04459e37839cd223176618536295715R425">testing code to libsecp256k1</a> and I was pulling out my hair trying to get it to work.
No amount of <code>printf</code> was working to illuminate what I was doing wrong.
Finally, out of desperation, I thought I would do a quick check to see if there are any compiler bugs related to <code>memcmp</code>, and lo and behold, I found <a href="https://gcc.gnu.org/bugzilla/show_bug.cgi?id=95189">GCC bug #95189: memcmp being wrongly stripped like strcmp</a>.</p><p>Honestly this was a pretty horrifying bug to read about.
Under some circumstances GCC 9 and 10 will cause <code>memcmp</code> to return an incorrect value when one of the inputs is statically known array that contains <code>NULL</code> bytes.
As I rushed to <a href="https://gist.githubusercontent.com/roconnor/2b8e22e829ed80088ed6690cc3c7f3a8/raw/455571a6d9053c597c1585debe6f9dbd6af85071/gistfile1.txt">recompile my computer system using GCC 8</a>, I contemplated the vast consequences of such a bug could be, and pondered how it was possible that computers could function at all.</p><p>However over the week, with the help of my colleagues, we managed to get a better understanding of the scope of the bug.
The bug can only convert non-zero values to zero values.
The static array needs to have a <code>NULL</code> byte within the first 4 bytes.
Most importantly, the <code>memcmp</code> result must not immediately be compared to <code>0</code> for equality or inequality, or any equivalent test.
A different code path is taken in the compiler in that case.
That explained why computers were still functioning.
I expect the vast majority of the uses of <code>memcmp</code> does an immediate test for equality with <code>0</code>.</p><p>I still wondered though, how much code was being affected. My colleague Tim suggested that it would be possible to instrument GCC to emit a message when it was about to miscompile a program.
Together we came up with <a href="https://gcc.gnu.org/bugzilla/attachment.cgi?id=49276&amp;action=diff">a patch</a> to GCC 9 and 10 that would print a debugging message.
Once again, I recompiled my entire system, to see what GCC was miscompiling.
This is what I found:</p><ul>
<li><a href="https://github.com/unicode-org/icu/blob/4fb47b12a70737ee12326220e71c2d73c5ec658f/icu4c/source/common/uniset_props.cpp#L709">https://github.com/unicode-org/icu/blob/4fb47b12a70737ee12326220e71c2d73c5ec658f/icu4c/source/common/uniset_props.cpp#L709</a></li>
<li><a href="https://github.com/xiph/flac/blob/ce6dd6b5732e319ef60716d9cc9af6a836a4011a/src/flac/decode.c#L1310">https://github.com/xiph/flac/blob/ce6dd6b5732e319ef60716d9cc9af6a836a4011a/src/flac/decode.c#L1310</a></li>
<li><a href="https://github.com/torvalds/linux/blob/fb0155a09b0224a7147cb07a4ce6034c8d29667f/drivers/atm/zatm.c#L1172">https://github.com/torvalds/linux/blob/fb0155a09b0224a7147cb07a4ce6034c8d29667f/drivers/atm/zatm.c#L1172</a></li>
<li><a href="https://github.com/nss-dev/nss/blob/1f3746f5107535a47bb4e3969f561e1bd1314bab/gtests/pk11_gtest/pk11_chacha20poly1305_unittest.cc#L425">https://github.com/nss-dev/nss/blob/1f3746f5107535a47bb4e3969f561e1bd1314bab/gtests/pk11_gtest/pk11_chacha20poly1305_unittest.cc#L425</a></li>
<li><a href="https://github.com/GNOME/glib/blob/010569b3734f864fcf584f771915b78bd391eb5f/glib/tests/refstring.c#L70">https://github.com/GNOME/glib/blob/010569b3734f864fcf584f771915b78bd391eb5f/glib/tests/refstring.c#L70</a></li>
<li><a href="https://github.com/heimdal/heimdal/blob/7ae2dfd853c87f9cbecb6f399de4dad09bad4606/lib/gssapi/krb5/arcfour.c#L390">https://github.com/heimdal/heimdal/blob/7ae2dfd853c87f9cbecb6f399de4dad09bad4606/lib/gssapi/krb5/arcfour.c#L390</a>, <a href="https://github.com/heimdal/heimdal/blob/7ae2dfd853c87f9cbecb6f399de4dad09bad4606/lib/gssapi/krb5/arcfour.c#L661">https://github.com/heimdal/heimdal/blob/7ae2dfd853c87f9cbecb6f399de4dad09bad4606/lib/gssapi/krb5/arcfour.c#L661</a>, <a href="https://github.com/heimdal/heimdal/blob/7ae2dfd853c87f9cbecb6f399de4dad09bad4606/lib/gssapi/krb5/arcfour.c#L1279">https://github.com/heimdal/heimdal/blob/7ae2dfd853c87f9cbecb6f399de4dad09bad4606/lib/gssapi/krb5/arcfour.c#L1279</a></li>
<li><a href="https://github.com/zeromq/libzmq/blob/22d218a182855f28038e865cb75bf5897ff0c786/tests/test_mock_pub_sub.cpp#L203">https://github.com/zeromq/libzmq/blob/22d218a182855f28038e865cb75bf5897ff0c786/tests/test_mock_pub_sub.cpp#L203</a></li>
<li><a href="https://github.com/pigoz/mplayer-svn/blob/8d651873a9eb193f5155ffb51ece206f187cf00f/sub/sub_cc.c#L391-L412">https://github.com/pigoz/mplayer-svn/blob/8d651873a9eb193f5155ffb51ece206f187cf00f/sub/sub_cc.c#L391-L412</a></li>
</ul>
<p>On my entire system I only found 10 lines of code that were miscompiled.
Three lines are tests.
All of the lines could be rewritten as a comparison to 0.
None of the lines looked that serious.
I am not sure which one is the worse: the reduced message integrity code(?) from some ARCFOUR implementation or the something something from an ATM driver?</p><p>The mplayer miscompilation is the most mysterious.
The code surrounding that function all appears to be immediately compare <code>memcmp</code> with <code>0</code>.
And given that my debug message refused to point to exactly what line is being miscompiled in that function, I fear some set of optimizations has happened to allow this code to be miscompiled in some way.</p><p>With more hardware I could do <a href="https://hydra.nixos.org/jobset/nixpkgs/trunk#tabs-jobs">a more thorough investigation</a> of the consequences of this GCC bug.
Until then I am going to stick with GCC 8 until GCC 9 and 10 have a new point releases.

</p></div></div>]]>
            </description>
            <link>http://r6.ca/blog/20200929T023701Z.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24636326</guid>
            <pubDate>Wed, 30 Sep 2020 07:01:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deutsch's Algorithm]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24636246">thread link</a>) | @keyboardman
<br/>
September 29, 2020 | https://leimao.github.io/blog/Deutsch-Algorithm/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/Deutsch-Algorithm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>Deutsch’s algorithm is the simplest quantum computing algorithm invented to solve a slightly contrived problem. Suppose we have a black-box function $f(x)$ which maps from the set $\{0,1\}$ to the set $\{0,1\}$. It is easy to speculate that there are four possible mappings for $f(x)$. We call the function $f(x)$ constant if $f(0) = f(1)$, otherwise we call the function $f(x)$ balanced.</p>



<p>With classical circuits, we would have to run the black-box $f(x)$ twice to evaluate $f(0)$ and $f(1)$ and compare the values of $f(0)$ and $f(1)$ to see if they are equivalent or not. With quantum circuits, because we could take advantage of superposition, probably we could do better with fewer runs and operations.</p>



<p>In this blog post, I would like to discuss the Deutsch’s algorithm.</p>

<h3 id="prerequisites">Prerequisites</h3>

<h4 id="separable-and-entangled-states">Separable and Entangled States</h4>

<p>States that can be broken into the Kronecker product of states from the constituent subsystems are called separable states, whereas states that are unbreakable are referred to as entangled states.</p>



<p>For example, we have the following two states $| \psi \rangle$ and $| \psi^{\prime} \rangle$.</p><p>

\[\begin{align}
| \psi \rangle &amp;= \frac{| 0, 0 \rangle - | 0, 1 \rangle + | 1, 0 \rangle - | 1, 1 \rangle}{2}\\
&amp;= \frac{| 0\rangle \otimes | 0 \rangle - | 0\rangle \otimes | 1 \rangle + | 1\rangle \otimes | 0 \rangle - | 1\rangle \otimes | 1 \rangle}{2}\\
&amp;= \frac{| 0 \rangle + | 1 \rangle}{\sqrt{2}} \otimes \frac{| 0 \rangle - | 1 \rangle}{\sqrt{2}} \\
| \psi^{\prime} \rangle &amp;= \frac{| 0, 1 \rangle + | 1, 0 \rangle}{\sqrt{2}}\\
\end{align}\]

</p><p>$| \psi \rangle$ is separable and $| \psi^{\prime} \rangle$ is entangled.</p>

<h4 id="unitary-quantum-operator">Unitary Quantum Operator</h4>

<p>Every quantum operator $U$ is unitary and thus reversible. Because $UU^{\dagger} = U^{\dagger}U = I$, we have</p><p>

\[\begin{align}
U^{\dagger} (U |\varphi\rangle) &amp;= (U^{\dagger} U) |\varphi\rangle \\
&amp;= I |\varphi\rangle \\ 
&amp;= |\varphi\rangle \\ 
\end{align}\]

</p><h4 id="hadamard-operator">Hadamard Operator</h4>

<p>Hardmard operator is a special quantum operator.</p><p>

\[\begin{align}
H &amp;= 
\begin{bmatrix} 
    \frac{1}{\sqrt{2}} &amp; \frac{1}{\sqrt{2}} \\
    \frac{1}{\sqrt{2}} &amp; -\frac{1}{\sqrt{2}} \\
\end{bmatrix}  
\end{align}\]

</p><p>Notice that $H^{\dagger} = H$, therefore</p><p>

\[\begin{align}
H^{\dagger} (H |\varphi\rangle) &amp;= H (H |\varphi\rangle) \\
&amp;= (H^2) |\varphi\rangle \\
&amp;= I |\varphi\rangle \\ 
&amp;= |\varphi\rangle \\ 
\end{align}\]

\[\begin{align}
H|0\rangle &amp;= 
\begin{bmatrix} 
    \frac{1}{\sqrt{2}} &amp; \frac{1}{\sqrt{2}} \\
    \frac{1}{\sqrt{2}} &amp; -\frac{1}{\sqrt{2}} \\
\end{bmatrix}  
\begin{bmatrix} 
    1 \\
    0 \\
\end{bmatrix}  \\
&amp;= 
\begin{bmatrix} 
    \frac{1}{\sqrt{2}} \\
    \frac{1}{\sqrt{2}} \\
\end{bmatrix}  \\
&amp;= \frac{|0\rangle + |1\rangle}{\sqrt{2}}
\end{align}\]

\[\begin{align}
H\frac{|0\rangle + |1\rangle}{\sqrt{2}} &amp;= HH|0\rangle \\
&amp;= I|0\rangle \\
&amp;= |0\rangle \\
\end{align}\]

\[\begin{align}
H|1\rangle &amp;= 
\begin{bmatrix} 
    \frac{1}{\sqrt{2}} &amp; \frac{1}{\sqrt{2}} \\
    \frac{1}{\sqrt{2}} &amp; -\frac{1}{\sqrt{2}} \\
\end{bmatrix}  
\begin{bmatrix} 
    0 \\
    1 \\
\end{bmatrix}  \\
&amp;= 
\begin{bmatrix} 
    \frac{1}{\sqrt{2}} \\
    -\frac{1}{\sqrt{2}} \\
\end{bmatrix}  \\
&amp;= \frac{|0\rangle - |1\rangle}{\sqrt{2}}
\end{align}\]

\[\begin{align}
H\frac{|0\rangle - |1\rangle}{\sqrt{2}} &amp;= HH|1\rangle \\
&amp;= I|1\rangle \\
&amp;= |1\rangle \\
\end{align}\]

</p><h4 id="reducing-sum-or-difference-to-boolean">Reducing Sum or Difference to Boolean</h4>

<p>If $f(x)$ maps from the set $\{0,1\}$ to the set $\{0,1\}$, we have</p><p>

\[\begin{align}
(-1)^{f(1) - f(0)} = (-1)^{f(0) \oplus f(1)}
\end{align}\]

</p><p>Where $\oplus$ is $\text{XOR}$ (binary addition modulo 2).</p>

<h3 id="deutschs-algorithm">Deutsch’s Algorithm</h3>

<p>The black-box $f(x)$ is represented using a quantum gate $U_f$. Just like the classical gate for $f(x)$, it has four possible candidates. Our job is to determine whether the $f(x)$ corresponding to the $U_f$ is constant or balanced.</p>

<div>
<figure>
    <img src="https://leimao.github.io/images/blog/2020-06-23-Deutsch-Algorithm/Uf.png">
    <figcaption>$U_f$</figcaption>
</figure>
</div>

<p>The quantum gate $U_f$ is a unitary matrix which maps from $| x \rangle \otimes | y \rangle$ to $| x \rangle \otimes | y \oplus f(x) \rangle$, namely $U_f (| x \rangle \otimes | y \rangle) = | x \rangle \otimes | y \oplus f(x) \rangle$, for $x, y \in \{0, 1\}$. When $y = 0$, $| y \oplus f(x) \rangle = | 0 \oplus f(x) \rangle = | f(x) \rangle $, $| y \oplus f(x) \rangle$ is just $| f(x) \rangle$.</p>



<p>Note that the above mapping is only valid when $| x \rangle$ and $| y \rangle$ are basic qubit states $| 0 \rangle$ or $| 1 \rangle$. When $| x \rangle$ and $| y \rangle$ are superpositions, the mapping does not necessarily hold.</p>



<p>Let’s further check when $| x \rangle$ and $| y \rangle$ are superpositions, what the outputs from $U_f$ will be. Perhaps we could achieve fewer runs with superpositions.</p>

<h4 id="first-attempt">First Attempt</h4>

<p>In the first attempt, we made the first qubit input to $U_f$ a superposition, which is achieved by applying a Hadamard operator to the input basic state $|0\rangle$. The superposition is</p><p>

\[\begin{align}
H|0\rangle &amp;= \frac{|0\rangle + |1\rangle}{\sqrt{2}}
\end{align}\]

</p><p>The second qubit input to $U_f$ is just a normal  basic state $|0\rangle$.</p>

<div>
<figure>
    <img src="https://leimao.github.io/images/blog/2020-06-23-Deutsch-Algorithm/attempt-1.png">
    <figcaption>First Attempt</figcaption>
</figure>
</div><p>

\[\begin{align}
|\varphi_0\rangle &amp;= |0\rangle \otimes |0\rangle\\
&amp;= |0, 0\rangle \\
\end{align}\]

\[\begin{align}
|\varphi_1\rangle &amp;= (H \otimes I) |\varphi_0\rangle \\
&amp;= (H \otimes I) (|0\rangle \otimes |0\rangle) \\
&amp;= H|0\rangle \otimes I |0\rangle \\
&amp;= \frac{|0\rangle + |1\rangle}{\sqrt{2}} \otimes |0\rangle \\
&amp;= \frac{|0\rangle \otimes |0\rangle + |1\rangle \otimes |0\rangle }{\sqrt{2}} \\
&amp;= \frac{|0, 0\rangle + |1, 0\rangle}{\sqrt{2}} \\
\end{align}\]

\[\begin{align}
|\varphi_2\rangle &amp;= U_f |\varphi_1\rangle \\
&amp;= U_f \frac{|0, 0\rangle + |1, 0\rangle}{\sqrt{2}} \\
&amp;= \frac{U_f |0, 0\rangle + U_f |1, 0\rangle}{\sqrt{2}} \\
&amp;= \frac{U_f (|0\rangle \otimes |0\rangle) + U_f (|1\rangle \otimes |0\rangle)}{\sqrt{2}} \\
&amp;= \frac{|0\rangle \otimes |0 \oplus f(0)\rangle + |1\rangle \otimes |0 \oplus f(1)\rangle}{\sqrt{2}} \\
&amp;= \frac{|0\rangle \otimes |f(0)\rangle + |1\rangle \otimes |f(1)\rangle}{\sqrt{2}} \\
&amp;= \frac{|0, f(0)\rangle + |1, f(1)\rangle}{\sqrt{2}} \\
\end{align}\]

</p><p>If $f(0) = 0$, $f(1) = 1$, one of the balanced cases,</p><p>

\[\begin{align}
|\varphi_2\rangle &amp;= \frac{|0, 0\rangle + |1, 1\rangle}{\sqrt{2}} \\
\end{align}\]

</p><p>Note that this $|\varphi_2\rangle$ is entangled and could be be expressed as the Kronecker product of two qubits. The first qubit output from $U_f$ is not $H|0\rangle$ either. In fact it could not be described using single qubit! The two qubits must be described as a whole due to quantum entanglement. When we observe either the first qubit output or the second qubit output, we immediately know the observation of the other qubit. For example, if we observed the second qubit is 0, we know the observation of the first qubit must be 0. There are 50-50 percent chance observing 0 or 1 for both the first qubit and the second qubit.</p>



<p>If $f(0) = 1$, $f(1) = 0$, one of the balanced cases,</p><p>

\[\begin{align}
|\varphi_2\rangle &amp;= \frac{|0, 1\rangle + |1, 0\rangle}{\sqrt{2}} \\
\end{align}\]

</p><p>This $|\varphi_2\rangle$ is entangled and there are 50-50 percent chance observing 0 or 1 for both the first qubit and the second qubit.</p>



<p>If $f(0) = 0$, $f(1) = 0$, one of the constant cases,</p><p>

\[\begin{align}
|\varphi_2\rangle &amp;= \frac{|0, 0\rangle + |1, 0\rangle}{\sqrt{2}} \\
&amp;= \frac{|0\rangle + |1\rangle}{\sqrt{2}} \otimes |0\rangle\\
&amp;= \frac{-|0\rangle - |1\rangle}{\sqrt{2}} \otimes (-|0\rangle)\\
\end{align}\]

</p><p>This $|\varphi_2\rangle$ is separable. Although we are not sure the exact state the two qubit outputs would be in, due to the phase is not defined, we are sure that the observation of the bottom qubit must be 0.</p>



<p>If $f(0) = 1$, $f(1) = 1$, one of the constant cases,</p><p>

\[\begin{align}
|\varphi_2\rangle &amp;= \frac{|0, 1\rangle + |1, 1\rangle}{\sqrt{2}} \\
&amp;= \frac{|0\rangle + |1\rangle}{\sqrt{2}} \otimes |1\rangle\\
&amp;= \frac{-|0\rangle - |1\rangle}{\sqrt{2}} \otimes (-|1\rangle)\\
\end{align}\]

</p><p>This $|\varphi_2\rangle$ is separable. Although we are not sure the exact state the two qubit outputs would be in, due to the phase is not defined, we are sure that the observation of the bottom qubit must be 1.</p>



<p>However, all of these are not helpful if we are only allowed to run once. After running once, no matter what we observed from the first qubit and the second qubit, we are not sure whether $f(x)$ is constant or balanced.</p>

<h4 id="second-attempt">Second Attempt</h4>

<p>In the second attempt, we made the second qubit input to $U_f$ a superposition, which is achieved by applying a Hadamard operator to the input basic state $|1\rangle$. The superposition is</p><p>

\[\begin{align}
H|1\rangle &amp;= \frac{|0\rangle - |1\rangle}{\sqrt{2}}
\end{align}\]

</p><p>The second qubit input to $U_f$ is a variable and it could be either $|0\rangle$ or $|1\rangle$.</p>

<div>
<figure>
    <img src="https://leimao.github.io/images/blog/2020-06-23-Deutsch-Algorithm/attempt-2.png">
    <figcaption>Second Attempt</figcaption>
</figure>
</div><p>

\[\begin{align}
|\varphi_0\rangle &amp;= |x\rangle \otimes |1\rangle\\
&amp;= |x, 1\rangle \\
\end{align}\]

\[\begin{align}
|\varphi_1\rangle &amp;= (I \otimes H) |\varphi_0\rangle \\
&amp;= (I \otimes H) (|x\rangle \otimes |1\rangle) \\
&amp;= I|x\rangle \otimes H |1\rangle \\
&amp;= |x\rangle \otimes \frac{|0\rangle - |1\rangle}{\sqrt{2}} \\
&amp;= \frac{|x, 0\rangle - |x, 1\rangle}{\sqrt{2}} \\
\end{align}\]

\[\begin{align}
|\varphi_2\rangle &amp;= U_f |\varphi_1\rangle \\
&amp;= U_f \frac{|x, 0\rangle - |x, 1\rangle}{\sqrt{2}} \\
&amp;= \frac{U_f |x, 0\rangle - U_f |x, 1\rangle}{\sqrt{2}} \\
&amp;= \frac{U_f (|x\rangle \otimes |0\rangle) - U_f (|x\rangle \otimes |1\rangle)}{\sqrt{2}} \\
&amp;= \frac{|x\rangle \otimes |0 \oplus f(x)\rangle - |x\rangle \otimes |1 \oplus f(x)\rangle}{\sqrt{2}} \\
&amp;= \frac{|x\rangle \otimes |f(x)\rangle - |x\rangle \otimes |\overline{f(x)}\rangle}{\sqrt{2}} \\
&amp;= |x\rangle \otimes \frac{|f(x)\rangle - |\overline{f(x)}\rangle}{\sqrt{2}} \\
\end{align}\]

</p><p>Because $\frac{|f(x)\rangle - |\overline{f(x)}\rangle}{\sqrt{2}}$ is either $\frac{|0\rangle - |1\rangle}{\sqrt{2}}$ or $\frac{|1\rangle - |0\rangle}{\sqrt{2}}$, $|\varphi_2\rangle $ could be further simplified as</p><p>

\[\begin{align}</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://leimao.github.io/blog/Deutsch-Algorithm/">https://leimao.github.io/blog/Deutsch-Algorithm/</a></em></p>]]>
            </description>
            <link>https://leimao.github.io/blog/Deutsch-Algorithm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24636246</guid>
            <pubDate>Wed, 30 Sep 2020 06:43:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding How UUIDs Are Generated]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24636204">thread link</a>) | @aryamansharda
<br/>
September 29, 2020 | https://digitalbunker.dev/2020/09/30/understanding-how-uuids-are-generated/ | <a href="https://web.archive.org/web/*/https://digitalbunker.dev/2020/09/30/understanding-how-uuids-are-generated/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="mainEntityOfPage">
<h2><strong>Introduction</strong></h2>
<p>You’ve likely used UUIDs in projects before and assumed them to be unique. Today, we’ll take a look at the main aspects of the implementation and understand why UUIDs are <em>practically </em>unique, though an incredibly small potential for duplication exists.&nbsp;</p>
<p>The modern day implementation of UUIDs can be tied back to <a href="https://tools.ietf.org/html/rfc4122" target="_blank" rel="noreferrer noopener">RFC 4122 </a>which introduced 5 different approaches for generating these identifiers. We’ll take a look at each one and we’ll step through the implementation details of Version 1 &amp; Version 4 in a moment.&nbsp;</p>
<h2><strong>Background</strong></h2>
<p>UUIDs, or universally unique IDentifiers, are simply a 128 bit number used to uniquely identify items in software development. Their canonical textual representation is as a series of 32 hexadecimal characters which are separated into five groups by hyphens in the form 8-4-4-4-12.&nbsp;</p>
<p>For example,&nbsp;</p>
<p><code>3422b448-2460-4fd2-9183-8000de6f8343</code></p>
<p>Embedded inside this seemingly random series of hexadecimal characters is information about the UUID implementation.&nbsp;</p>
<p><code>xxxxxxxx-xxxx-<strong>M</strong>xxx-<strong>N</strong>xxx-xxxxxxxxxxxx</code></p>
<p>The values in the M and N locations uniquely identify the UUID version and variant respectively.</p>
<h4><strong>Version</strong></h4>
<p>The version number is identified by looking at the most significant 4 bits of the value in the M position.&nbsp;</p>
<p>The following table lists the currently defined versions:</p>
<div><figure><img src="https://lh3.googleusercontent.com/1ePxhp-OP2JdmdHVLd3rbfDc9dcNP5J9QQncT0bYPdJ5W3_2pAHfGZ9a7Q7m3mav6VA1syO22nTIavepVicTMW9YxqiuGcSePUOanJeyz67K_bZwDbd_KO25oLgPirr53qj1wZq9" alt="" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>
<h4><strong>&nbsp;Variant</strong></h4>
<p>The variant field determines the layout of the information embedded in the UUID. The interpretation of all other bits in the UUID depends on the value of the variant.&nbsp;</p>
<p>We identify the variant by considering the first 1-3 most significant bits of N.&nbsp;</p>
<div><figure><img src="https://lh3.googleusercontent.com/FeXxFJcHdVVJA7IorpHtQx67F3eiSkMJVAr2Q5E4t3IierXggi-DR1uthMBOgRBXRP4JzcdRMuHbVqMMkCWZ47fo7sUO8sDBQcwgALwr45qLdpC9bSUBoXKQF9Bhdnnc9kN-g8p9" alt="" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>
<p>The most common implementation nowadays is Variant 1 where the MSB0&nbsp; is fixed as 1 and MSB1 is fixed as 0. This means that considering our wildcard values – the bits marked with an <code>x</code> above – the only possible values are 8, 9, A, or B.</p>
<blockquote><p><strong>Quick Reminder:&nbsp;</strong></p><p>1 0 0 0 = 8&nbsp;</p><p>1 0 0 1 = 9</p><p>1 0 1 0 = A</p><p>1 0 1 1 = B</p></blockquote>
<p>So, if you ever see a UUID with these values in the N position, you’ll know it’s the common Variant 1 type.&nbsp;</p>
<h4><strong>Version 1 (Time Based + Unique or Random Host Identifier)&nbsp;</strong></h4>
<p>In this version, the UUID is generated by taking the current timestamp and some identifying property of the device generating the UUID – most commonly, the MAC address (also called the node ID).&nbsp;</p>
<p>This UUID is generated by concatenating the 48 bit MAC address, a 60 bit-timestamp, and a 14 bit “uniquifying” clock sequence, along with the 6 reserved bits for version and variant to generate a unique UUID.&nbsp;</p>
<blockquote><p>The clock sequence is simply a value incremented every time the clock is modified.&nbsp;</p></blockquote>
<p>The timestamp used in this version is the number of 100 nanosecond time intervals since October 15, 1582 – the date of Gregorian reform to the Christian calendar.&nbsp;</p>
<blockquote><p>You may be familiar with Unix systems and time since epoch. This is simply just a different Day 0. There are several algorithms online that allow you to convert one time representation to the other, so we won’t go over this here.</p></blockquote>
<p>Though this implementation seems fairly straightforward and robust, because it reveals the MAC address of the machine it was generated on, this approach is not suitable for all use cases.&nbsp; Especially, when security is a major concern. Instead, some implementations will use 6 random bytes sourced from a cryptographically secure random number generator as a replacement for the node ID.&nbsp;</p>
<p>&nbsp;To assemble a Version 1 UUID, we’ll do the following steps:&nbsp;</p>
<ol><li>Take the low 32 bits of the current UTC timestamp. This will be the first 4 bytes / 8 hex characters of our UUID [TimeLow]</li><li>Take the middle 16 bits of the current UTC timestamp. These will be the following 2 bytes / 4 hex characters. [TimeMid]</li><li>The next 2 bytes / 4 hex characters will concat the 4 bit UUID version with the remaining high 12 bits of the current UTC timestamp (which is 60 bits in total). [TimeHighAndVersion]</li><li>Now, the next 1-3 bits will specify the variant of the UUID version. The remaining bits will contain the clock sequence which is meant to contribute some small amount of randomness to this implementation. In doing so, it helps avoid collisions in the event multiple UUID generators are running on the same system, a system clock for a UUID generator is set backwards, or the system clock doesn’t advance fast enough. [ClockSequenceHiAndRes &amp;&amp; ClockSequenceLow]</li><li>The final 6 bytes / 12 hex characters / 48 bits are the “node id” which is most commonly the MAC address of the issuing device. [NodeID]</li></ol>
<p>Putting everything together, our Version 1 UUID is generated by concatenating:</p>
<p><code>TimeLow + TimeMid + TimeHighAndVersion + (ClockSequenceHiAndRes &amp;&amp; ClockSequenceLow) + NodeID&nbsp;</code></p>
<p>Due to this implementation’s reliance on the clock, there are some edge cases we’ll need to handle. Firstly, to minimize correlation across systems, the clock sequence is defaulted to a random number – this will only happen once in the lifetime of a system. This has the added benefit of allowing us to support node identifiers that may move from system to system as the initial value of the clock sequence is completely agnostic of the node identifier.&nbsp;</p>
<p>Remember that the main purpose of the clock sequence is to introduce some amount of randomness into the equation. The bits allocated for the clock sequence help us extend the timestamp and account for situations where multiple UUIDs are generated before the processor clock advances. This helps us avoid the potential creation of duplicates when the clock is set backwards in time (device is powered off) or the node ID changes. If the clock is set backwards, or might have been set backwards (e.g., while the system was powered off), and the UUID generator can not be sure that no UUIDs were generated with timestamps larger than the value to which the clock was set, then the clock sequence has to be changed. If the previous value of the clock sequence is known, it can just be incremented; otherwise it should be set to a random or high-quality pseudo-random value.</p>
<h4><strong>Version 2 (Distributed Computing Environment Security)</strong></h4>
<p>The main difference between this version and Version 1 is that this implementation uses some identifier specific to the system in place of the “randomness” generated by using the least significant bits of the clock sequence. This value is often just the current user’s ID. This version is less common and only a small deviation from Version 1, so we won’t explore it any further.&nbsp;</p>
<h4><strong>Version 3 (Name-based + MD5 Hash)</strong></h4>
<p>In the event that you want to have unique identifiers for information within a namespace or for “nameable” information more generally, UUID version 3 and version 5 are your preferred options.&nbsp;</p>
<p>They’ll encode any “nameable” entity (website, DNS information, plain text, etc) into the UUID value. The main takeaway here is that for the same namespace and text, the generated UUID will be the same.&nbsp;</p>
<p>Take note that the namespace itself is a UUID.</p>
<pre><code>let namespace = “digitalbunker.dev”
let namespaceUUID = UUID3(.DNS, namespace)

// Ex: 
UUID3(namespaceUUID, “/category/things-you-should-know-1/”) 
4896c91b-9e61-3129-87b6-8aa299028058

UUID3(namespaceUUID, “/category/things-you-should-know-2/”) 
29be0ee3-fe77-331e-a1bf-9494ec18c0ba

UUID3(namespaceUUID, “/category/things-you-should-know-3/”) 
33b06619-1ee7-3db5-827d-0dc85df1f759
</code></pre>
<p>In this implementation, the UUID of the namespace is transformed to a string of bytes, concatenated with the input name, then hashed with MD5, yielding the 128 bits for the UUID. Then, we’ll overwrite some of those bits to accurately reflect the version and variant information leaving the rest unchanged.&nbsp;</p>
<p>It’s also important to understand that neither the namespace nor the inputted name can be generated from the UUID. This is a one-way operation. The only exception here would be through a brute force approach if one of the values (namespace or text) were known by the attacker.</p>
<p>For Version 3 and Version 5, as long as you use the same inputs, the generated UUID will be deterministic.&nbsp;</p>
<h4><strong>Version 4 (PRNG)</strong></h4>
<p>This is probably the simplest implementation of the bunch.</p>
<p>As we’ve now seen, 6 bits are reserved for the version and variant information leaving us 122 bits free to decide. This version simply generates all 128 random bits and then fills in the values for the version and variant information as a secondary step.&nbsp;</p>
<p>UUIDs of this variety rely heavily on the quality of the PRNG in use (pseudo-random number generator). If the PRNG is lacking a sophisticated algorithm or the correct seed and initialization values, the likelihood of a duplicate can increase. To better understand how computers generate random numbers, <a href="https://digitalbunker.dev/2020/09/08/how-do-computers-generate-random-numbers/" target="_blank" rel="noreferrer noopener">check out my previous article.</a>&nbsp;</p>
<p>Version 4 is what you’ll find most commonly implemented in modern programming languages.</p>
<p>It’s implementation is reasonably simple.&nbsp;</p>
<ol><li>Generate 128 random bits</li><li>Now, we’ll need to overwrite some of these bits with the correct version and variant information&nbsp;<ol><li>Take the 7th byte and perform an AND operation with <code>0x0F</code> to clear out the high nibble. Then, OR it with <code>0x40</code> to set the version number to 4.&nbsp;</li><li>Next, take the 9th byte and perform an AND operation with <code>0x3F</code> and then OR it with <code>0x80</code>.&nbsp;</li></ol></li><li>Convert the 128 bits to hexadecimal representation and insert the hyphens to achieve the canonical text representation.&nbsp;</li></ol>
<h4><strong>Version 5 (Name-based + SHA-1 Hash)</strong></h4>
<p>This version is no different than Version 3 with the exception that the <code>SHA-1</code> hashing algorithm is used here in place of <code>MD5</code>. This version is preferred to Version 3 (SHA-1 &gt; MD5).&nbsp;</p>
<h2><strong>In Practice</strong></h2>
<p>One of the notable benefits of UUIDs is that their uniqueness does not depend on a central authority or coordination between different systems. Anyone can create UUIDs with reasonable assurance that a duplicate value does not exist and will conceivably not be made in the future.&nbsp;</p>
<p>This has the added benefit of allowing UUIDs generated by independent parties to be combined into a single database or moved across databases with a trivial probability of duplication / collision.&nbsp;</p>
<p>Due to this uniqueness, you can use UUIDs as primary keys in databases, unique filenames for uploaded files, unique names for any web resource, or …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://digitalbunker.dev/2020/09/30/understanding-how-uuids-are-generated/">https://digitalbunker.dev/2020/09/30/understanding-how-uuids-are-generated/</a></em></p>]]>
            </description>
            <link>https://digitalbunker.dev/2020/09/30/understanding-how-uuids-are-generated/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24636204</guid>
            <pubDate>Wed, 30 Sep 2020 06:31:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A categorized list of all Java and JVM features since JDK 8 to 15]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24636197">thread link</a>) | @pjmlp
<br/>
September 29, 2020 | https://advancedweb.hu/a-categorized-list-of-all-java-and-jvm-features-since-jdk-8-to-15/ | <a href="https://web.archive.org/web/*/https://advancedweb.hu/a-categorized-list-of-all-java-and-jvm-features-since-jdk-8-to-15/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p><strong>Last updated</strong> on 2020/09/29 to include changes up to <a href="https://openjdk.java.net/projects/jdk/15/">JDK 15</a>.</p> <p>Since the release of version 8, up to version 15, Java is shaped by 163 <a href="http://openjdk.java.net/jeps/0">JDK Enhancement Proposals</a> (JEPs), each of which brings some improvement to the platform. This page is a <strong>categorized</strong> and <strong>curated</strong> list of the most important improvements.</p> <p><img alt="JDK timeline" integrity="sha256-LaVVHICMYi3voV98aHwg0mrUzl6D7m+MpNnEXwTXOWk=" crossorigin="anonymous" src="https://advancedweb.hu/assets/posts/post_java_8/jdktimeline-v3-2da5551c808c622defa15f7c687c20d26ad4ce5e83ee6f8ca4d9c45f04d73969.jpg"></p> <p><strong>Contents of this page:</strong></p> <ul> <li><a href="#new-language-features">New Language Features</a></li> <li><a href="#new-apis">New APIs</a></li> <li><a href="#performance-improvements">Performance Improvements</a></li> <li><a href="#security-improvements">Security Improvements</a></li> <li><a href="#bytecode">Bytecode Changes</a></li> <li><a href="#launching">Launching</a></li> <li><a href="#packaging">Packaging</a></li> <li><a href="#javadoc">Javadoc</a></li> <li><a href="#new-supported-platforms">New Platforms</a></li> <li><a href="#deprecation-and-removal">Deprecation and Removal</a></li> <li><a href="#new-version-scheme">New Version Scheme</a></li> </ul> <p>The full list of JEPs can be found on the OpenJDK website under the <a href="https://openjdk.java.net/projects/jdk/">jdk</a> and <a href="https://openjdk.java.net/projects/jdk9/">jdk9</a> projects.</p> <p>All features are generally available and enabled by default, except if they are labelled with one of the following:</p> <ul> <li> <strong>Preview</strong> 🔍 features are fully specified and implemented, but not yet considered to be final. They are considered to be almost complete, waiting for an additional round of real-world feedback. They have to be <a href="https://openjdk.java.net/jeps/12">explicitly enabled</a>.</li> <li> <strong>Experimental</strong> 💥 features are less stable, and more likely to change. They also have to be explicitly enabled.</li> <li> <strong>Incubator</strong> 🥚 modules are non-final tools and API’s, and are <a href="https://openjdk.java.net/jeps/11">distributed in separate modules</a>.</li> </ul> <h2 id="new-language-features">New Language Features</h2> <p>When Java 8 introduced lambdas it was a pretty huge change. While recent versions did not add such impactful features, lots of smaller improvements were made to the language.</p> <p>Here’s a quick recap on what happened in the last years. For a more in-depth guide, see <a href="https://advancedweb.hu/new-language-features-since-java-8-to-14/">New language features since Java 8</a>.</p><div> <p> Related </p> <div> <p><a href="https://advancedweb.hu/new-language-features-since-java-8-to-14/"> <img integrity="sha256-Ko5UWYfecL05QXbtkFEINWvtXxZRNvydy8FQEPm7Vsw=" crossorigin="anonymous" src="https://advancedweb.hu/assets/53487f-15f99cf9213eacf6f30f40e8d76a4dea7f587df024e1fe2ffa4cf085fa462d21.jpg"> </a> </p> <div>  <p> Enhancements to the Java language you should know </p> </div> </div> </div> <ul> <li>Text Blocks<br> <a href="https://openjdk.java.net/jeps/378">JDK 15</a> (Preview in <a href="https://openjdk.java.net/jeps/368">JDK 14</a> <a href="https://openjdk.java.net/jeps/355">JDK 13</a>) <div> <div><pre><code><span>String</span> <span>html</span> <span>=</span> <span>"""
            &lt;html&gt;
                &lt;body&gt;
                    &lt;p&gt;Hello, world&lt;/p&gt;
                &lt;/body&gt;
            &lt;/html&gt;
            """</span><span>;</span>
</code></pre></div> </div> </li> <li>Sealed Classes can restrict which other classes may extend them (<strong>Preview</strong> 🔍)<br> <a href="https://openjdk.java.net/jeps/360">JDK 15</a> <div> <div><pre><code><span>public</span> <span>abstract</span> <span>sealed</span> <span>class</span> <span>Shape</span>
    <span>permits</span> <span>Circle</span><span>,</span> <span>Rectangle</span> <span>{...}</span>

<span>public</span> <span>class</span> <span>Circle</span> <span>extends</span> <span>Shape</span> <span>{...}</span> <span>// OK</span>
<span>public</span> <span>class</span> <span>Rectangle</span> <span>extends</span> <span>Shape</span> <span>{...}</span> <span>// OK</span>
<span>public</span> <span>class</span> <span>Triangle</span> <span>extends</span> <span>Shape</span> <span>{...}</span> <span>// Compile error</span>

<span>// No need for default case if all permitted types are covered</span>
<span>double</span> <span>area</span> <span>=</span> <span>switch</span> <span>(</span><span>shape</span><span>)</span> <span>{</span>
    <span>case</span> <span>Circle</span> <span>c</span>    <span>-&gt;</span> <span>Math</span><span>.</span><span>pow</span><span>(</span><span>c</span><span>.</span><span>radius</span><span>(),</span> <span>2</span><span>)</span> <span>*</span> <span>Math</span><span>.</span><span>PI</span>
    <span>case</span> <span>Rectangle</span> <span>r</span> <span>-&gt;</span> <span>r</span><span>.</span><span>a</span><span>()</span> <span>*</span> <span>r</span><span>.</span><span>b</span><span>()</span>
<span>};</span>
</code></pre></div> </div> </li> <li>Records (<strong>Preview</strong> 🔍)<br> <a href="https://openjdk.java.net/jeps/384">JDK 15</a> <a href="https://openjdk.java.net/jeps/359">JDK 14</a> <div> <div><pre><code><span>record</span> <span>Point</span><span>(</span><span>int</span> <span>x</span><span>,</span> <span>int</span> <span>y</span><span>)</span> <span>{</span> <span>}</span>
</code></pre></div> </div> </li> <li>Pattern Matching for instanceof (<strong>Preview</strong> 🔍)<br> <a href="https://openjdk.java.net/jeps/375">JDK 15</a> <a href="https://openjdk.java.net/jeps/305">JDK 14</a> <div> <div><pre><code><span>if</span> <span>(</span><span>obj</span> <span>instanceof</span> <span>String</span> <span>s</span><span>)</span> <span>{</span>
    <span>System</span><span>.</span><span>out</span><span>.</span><span>println</span><span>(</span><span>"obj is a String and it' length is "</span> <span>+</span> <span>s</span><span>.</span><span>length</span><span>());</span>
<span>}</span>
</code></pre></div> </div> </li> <li>Switch Expressions<br> <a href="https://openjdk.java.net/jeps/361">JDK 14</a> (Preview in <a href="https://openjdk.java.net/jeps/325">JDK 12</a> <a href="https://openjdk.java.net/jeps/354">JDK 13</a>) <div> <div><pre><code><span>int</span> <span>numLetters</span> <span>=</span> <span>switch</span> <span>(</span><span>day</span><span>)</span> <span>{</span>
    <span>case</span> <span>MONDAY</span><span>,</span> <span>FRIDAY</span><span>,</span> <span>SUNDAY</span> <span>-&gt;</span> <span>6</span><span>;</span>
    <span>case</span> <span>TUESDAY</span>                <span>-&gt;</span> <span>7</span><span>;</span>
    <span>default</span>      <span>-&gt;</span> <span>{</span>
      <span>String</span> <span>s</span> <span>=</span> <span>day</span><span>.</span><span>toString</span><span>();</span>
      <span>int</span> <span>result</span> <span>=</span> <span>s</span><span>.</span><span>length</span><span>();</span>
      <span>yield</span> <span>result</span><span>;</span>
    <span>}</span>
<span>};</span>
</code></pre></div> </div> </li> <li>Helpful NullPointerExceptions describing precisely which variable was null<br> <a href="https://openjdk.java.net/jeps/358">JDK 14</a> (enabled with <code>-XX:+ShowCodeDetailsInExceptionMessages</code>) <div> <div><pre><code><span>a</span><span>.</span><span>b</span><span>.</span><span>c</span><span>.</span><span>i</span> <span>=</span> <span>99</span><span>;</span>
<span>---</span>
<span>Exception</span> <span>in</span> <span>thread</span> <span>"main"</span> <span>java</span><span>.</span><span>lang</span><span>.</span><span>NullPointerException</span><span>:</span>
      <span>Cannot</span> <span>read</span> <span>field</span> <span>"c"</span> <span>because</span> <span>"a.b"</span> <span>is</span> <span>null</span>
</code></pre></div> </div> </li> <li>Introduction of <code>var</code> to make local variable declarations less ceremonious<br> <a href="https://openjdk.java.net/jeps/323">JDK 11</a> (Without lambda support in <a href="https://openjdk.java.net/jeps/286">JDK 10</a>) <div> <div><pre><code><span>var</span> <span>greeting</span> <span>=</span> <span>"Hello World!"</span><span>;</span>
</code></pre></div> </div> </li> <li>Opt-in and backwards-compatible Module System to avoid <code>ClassDefNotFoundErrors</code> at runtime and create internal APIs<br> <a href="https://openjdk.java.net/jeps/261">JDK 9</a> (Project Jigsaw) <div> <div><pre><code><span>module</span> <span>hu</span><span>.</span><span>advancedweb</span><span>.</span><span>helloworld</span> <span>{</span>
    <span>requires</span> <span>hu</span><span>.</span><span>advancedweb</span><span>.</span><span>somedependency</span><span>;</span>
    <span>exports</span> <span>hu</span><span>.</span><span>advancedweb</span><span>.</span><span>hello</span>
<span>}</span>
</code></pre></div> </div> </li> <li> <p>Private methods in interfaces<br> <a href="https://openjdk.java.net/jeps/213">JDK 9</a> (Milling Project Coin)</p> </li> <li> <p>Diamond operator for anonymous inner classes<br> <a href="https://openjdk.java.net/jeps/213">JDK 9</a> (Milling Project Coin)</p> </li> <li> <p>Try-with-resources allows effectively final variables<br> <a href="https://openjdk.java.net/jeps/213">JDK 9</a> (Milling Project Coin)</p> </li> <li> <p><code>@SafeVargs</code> on private instance methods<br> <a href="https://openjdk.java.net/jeps/213">JDK 9</a> (Milling Project Coin)</p> </li> <li>No deprecation warnings on <code>import</code> statements<br> <a href="https://openjdk.java.net/jeps/211">JDK 9</a> </li> </ul> <p> We write articles like this regularly. <a href="#bottom-promo">Join our mailing list</a> and let's keep in touch. </p> <h2 id="new-apis">New APIs</h2> <p>Let’s continue with the Java Standard Library, focusing on the new features that we can use in day-to-day coding.</p> <p>If you are curious about all the API level differences between Java 8 and 14, check the <a href="https://github.com/AdoptOpenJDK/jdk-api-diff">AdoptOpenJDK/jdk-api-diff on GitHub</a>.</p> <h3 id="general">General</h3> <ul> <li> <p>Support Non-Volatile Mapped Byte Buffers in the FileChannel API<br> <a href="https://openjdk.java.net/jeps/352">JDK 14</a></p> </li> <li> <p><code>Files.mismatch</code>: find the first mismatched byte in the content of two files<br> <a href="https://docs.oracle.com/en/java/javase/12/docs/api/java.base/java/nio/file/Files.html">JDK 12</a></p> </li> <li> <p><code>Collectors.teeing</code> to create a Collector that is a composite of two downstream collectors<br> <a href="https://docs.oracle.com/en/java/javase/12/docs/api/java.base/java/util/stream/Collectors.html#teeing(java.util.stream.Collector,java.util.stream.Collector,java.util.function.BiFunction)">JDK 12</a></p> </li> <li> <p>String enhancements: <code>indent</code> and <code>transform</code><br> <a href="https://docs.oracle.com/en/java/javase/12/docs/api/java.base/java/lang/String.html">JDK 12</a></p> </li> <li>Standard HTTP Client featuring HTTP/2, WebSocket support and non-blocking API<br> <a href="https://openjdk.java.net/jeps/321">JDK 11</a> (<strong>Incubator</strong> 🥚 in <a href="https://openjdk.java.net/jeps/110">JDK 9</a>) <div> <div><pre><code><span>HttpClient</span> <span>httpClient</span> <span>=</span> <span>HttpClient</span><span>.</span><span>newBuilder</span><span>().</span><span>build</span><span>();</span>

<span>HttpRequest</span> <span>request</span> <span>=</span>
  <span>HttpRequest</span><span>.</span><span>newBuilder</span><span>()</span>
    <span>.</span><span>uri</span><span>(</span><span>URI</span><span>.</span><span>create</span><span>(</span><span>"https://advancedweb.hu/"</span><span>))</span>
    <span>.</span><span>GET</span><span>()</span>
    <span>.</span><span>build</span><span>();</span>

<span>HttpResponse</span><span>&lt;</span><span>String</span><span>&gt;</span> <span>response</span> <span>=</span>
  <span>httpClient</span><span>.</span><span>send</span><span>(</span><span>request</span><span>,</span> <span>BodyHandlers</span><span>.</span><span>ofString</span><span>());</span>
</code></pre></div> </div> </li> <li> <p>String enhancements, like <code>isBlank</code>, <code>lines</code>, <code>repeat</code> and <code>strip</code><br> <a href="https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/lang/String.html">JDK 11</a></p> </li> <li>Convenience Factory Methods for Collections to ease the pain of not having collection literals<br> <a href="https://openjdk.java.net/jeps/269">JDK 9</a> <div> <div><pre><code><span>Set</span><span>&lt;</span><span>Integer</span><span>&gt;</span> <span>mySet</span> <span>=</span> <span>Set</span><span>.</span><span>of</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>);</span>
<span>List</span><span>&lt;</span><span>Integer</span><span>&gt;</span> <span>myList</span> <span>=</span> <span>List</span><span>.</span><span>of</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>);</span>
<span>Map</span><span>&lt;</span><span>String</span><span>,</span> <span>Integer</span><span>&gt;</span> <span>myMap</span> <span>=</span> <span>Map</span><span>.</span><span>of</span><span>(</span><span>"one"</span><span>,</span> <span>1</span><span>,</span> <span>"two"</span><span>,</span> <span>2</span><span>);</span>
</code></pre></div> </div> </li> <li> <p>Reactive Streams publish-subscribe framework for asynchronous stream processing with non-blocking backpressure<br> <a href="https://openjdk.java.net/jeps/266">JDK 9</a></p> </li> <li> <p>Time-based enhancements to <code>CompletableFuture</code> (timeout, delay)<br> <a href="https://openjdk.java.net/jeps/266">JDK 9</a></p> </li> <li> <p>More options to transform (<code>dropWhile</code>, <code>takeWhile</code>) and generate (<code>iterate</code>, <code>ofNullable</code>) streams; readonly collectors (<code>toUnmodifiableList</code>); optionals can be transformed to streams<br> <a href="https://docs.oracle.com/javase/9/docs/api/java/util/stream/Stream.html#iterate-T-java.util.function.UnaryOperator-">JDK 9</a></p> </li> <li> <p><code>Arrays.mismatch</code>: find the first mismatching element between two arrays<br> <a href="https://docs.oracle.com/javase/9/docs/api/java/util/Arrays.html#mismatch-java.lang.Object:A-java.lang.Object:A-">JDK 9</a></p> </li> <li> <p>Stack-Walking API that allows laziness and stack-frame filtering<br> <a href="https://openjdk.java.net/jeps/259">JDK 9</a></p> </li> <li> <p>Process API provides more info and control (e.g. process ID, arguments, CPU time, parent/child processes), enhance <code>ProcessBuilder</code> to aid the creation of process pipelines<br> <a href="https://openjdk.java.net/jeps/102">JDK 9</a></p> </li> <li> <p><code>VarHandle</code> API to replace the field and array related operations of <code>java.util.concurrent.atomic</code> and <code>sun.misc.Unsafe</code> in order to and provide low-level access mechamisms, e.g. atomic write.<br> <a href="https://openjdk.java.net/jeps/193">JDK 9</a></p> </li> <li> <p>New combinators and lookup methods for <code>MethodHandle</code><br> <a href="https://openjdk.java.net/jeps/274">JDK 9</a></p> </li> <li> <p>Enhanced Deprecation policy. <code>@Deprecated</code> can be marked with <code>forRemoval</code>, which emits a new warning.<br> <a href="https://openjdk.java.net/jeps/277">JDK 9</a></p> </li> <li> <p>OASIS Standard XML Catalog API to manage external resources in XMLs in a secure and performant manner<br> <a href="https://openjdk.java.net/jeps/268">JDK 9</a></p> </li> <li> <p>Update JDK’s XML parser, Xerces, to version 2.11.0<br> <a href="https://openjdk.java.net/jeps/255">JDK 9</a></p> </li> <li>TIFF Support for Image I/O Framework<br> <a href="https://openjdk.java.net/jeps/262">JDK 9</a> </li> </ul> <h3 id="internationalization">Internationalization</h3> <ul> <li> <p>Unicode 10.0, adding roughly 27.000 characters, 10 blocks, and more than 30 scripts<br> <a href="https://openjdk.java.net/jeps/327">JDK 11</a> (Unicode 8.0 support in <a href="https://openjdk.java.net/jeps/267">JDK 9</a>)</p> </li> <li> <p><code>java.util.Locale</code> and related APIs support currency type, time zone and more<br> <a href="https://openjdk.java.net/jeps/314">JDK 10</a></p> </li> <li> <p><code>ResourceBundle</code> loads properties files in UTF-8 instead of ISO-8859-1<br> <a href="https://openjdk.java.net/jeps/226">JDK 9</a></p> </li> <li> <p>CLDR Locale Data Enabled by Default<br> <a href="https://openjdk.java.net/jeps/252">JDK 9</a></p> </li> </ul> <h3 id="graphics-and-desktop-applications">Graphics and Desktop Applications</h3> <ul> <li> <p>Desktop features for all platforms like login/logout/lock event listener and task bar interactions<br> <a href="https://openjdk.java.net/jeps/272">JDK 9</a></p> </li> <li> <p><code>MultiResolutionImage</code> that makes easy to retrieve a resolution-specific image for a DPI<br> <a href="https://openjdk.java.net/jeps/251">JDK 9</a></p> </li> <li> <p>HiDPI Graphics on Windows and Linux<br> <a href="https://openjdk.java.net/jeps/263">JDK 9</a></p> </li> <li> <p>Enable GTK 3 on Linux for JavaFX, Swing, and AWT<br> <a href="https://openjdk.java.net/jeps/283">JDK 9</a></p> </li> <li> <p>Replace <code>@beaninfo</code> Javadoc tags with <code>@BeanInfo</code> annotations for Swing<br> <a href="https://openjdk.java.net/jeps/256">JDK 9</a></p> </li> <li> <p>Update GStreamer included in JavaFX/Media to version 1.4.4<br> <a href="https://openjdk.java.net/jeps/257">JDK 9</a></p> </li> <li> <p>Replace the existing ICU OpenType font-layout engine with HarfBuzz<br> <a href="https://openjdk.java.net/jeps/258">JDK 9</a></p> </li> </ul> <h2 id="performance-improvements">Performance Improvements</h2> <h3 id="general-1">General</h3> <ul> <li> <p>Foreign-Memory Access API to safely and efficiently use off-heap memory (<strong>Incubator</strong> 🥚)<br> <a href="https://openjdk.java.net/jeps/383">JDK 15</a> <a href="https://openjdk.java.net/jeps/370">JDK 14</a></p> </li> <li> <p>Enable dynamic archiving of classes at the end of Java application execution<br> <a href="https://openjdk.java.net/jeps/350">JDK 13</a></p> </li> <li> <p>Application Class-Data Sharing to improve startup time and reduce footprint by sharing class metadata between Java processes.<br> <a href="https://openjdk.java.net/jeps/310">JDK 10</a></p> </li> <li> <p>Class-Data Sharing archive of the default class list is enabled by default to improve out-of-the-box startup time<br> <a href="https://openjdk.java.net/jeps/341">JDK 12</a></p> </li> <li> <p>Space-efficient, Compact Strings that stores Latin-1 only Strings more efficiently<br> <a href="https://openjdk.java.net/jeps/254">JDK 9</a></p> </li> <li> <p>Code caches of profiled and non-profiled compiled code is separated, resulting in improved performance and memory footprint<br> <a href="https://openjdk.java.net/jeps/197">JDK 9</a></p> </li> <li> <p>Store Interned Strings in Class-Data Sharing archives to reduce memory consumption<br> <a href="https://openjdk.java.net/jeps/250">JDK 9</a></p> </li> </ul> <h3 id="library">Library</h3> <ul> <li> <p>Improved intrinsics for <code>java.lang.Math</code> <code>sin</code>, <code>cos</code> and <code>log</code> functions on AArch64 processors<br> <a href="https://openjdk.java.net/jeps/315">JDK 11</a></p> </li> <li> <p>Security Manager performance improvements<br> <a href="https://openjdk.java.net/jeps/232">JDK 9</a></p> </li> <li> <p>Spin-Wait Hint (<code>Thread#onSpinWait</code>) to optimize busy-waiting style loops<br> <a href="https://openjdk.java.net/jeps/285">JDK 9</a></p> </li> <li> <p>Use Marlin Renderer in Java 2D as the default graphics rasterizer instead of Pisces<br> <a href="https://openjdk.java.net/jeps/265">JDK 9</a></p> </li> <li> <p>Improved GHASH and RSA performance by leveraging recently-introduced SPARC and Intel x64 CPU instructions<br> <a href="https://openjdk.java.net/jeps/246">JDK 9</a></p> </li> </ul> <h3 id="concurrency">Concurrency</h3> <ul> <li> <p>Thread-Local Handshakes to stop individual threads<br> <a href="https://openjdk.java.net/jeps/312">JDK 10</a></p> </li> <li> <p>Improved performance of contended object monitors<br> <a href="https://openjdk.java.net/jeps/143">JDK 9</a></p> </li> <li> <p>Extra space on thread stack for critical sections, mitigating the risk of a deadlock in <code>java.util.concurrent</code> locks in case of a stack overflow<br> <a href="https://openjdk.java.net/jeps/270">JDK 9</a></p> </li> </ul> <h3 id="compiler">Compiler</h3> <ul> <li> <p>Ahead-of-Time Compilation capability for Linux (<strong>Experimental</strong> 💥)<br> <a href="https://openjdk.java.net/jeps/246">JDK 10</a> (Graal as an experimental JIT Compiler) <a href="https://openjdk.java.net/jeps/243">JDK 9</a> (JVM Compiler Interface) <a href="https://openjdk.java.net/jeps/295">JDK 9</a> (Graal as an AoT Compiler)</p> </li> <li> <p>Performance improvement in javac: new strategy for type checking poly expressions<br> <a href="https://openjdk.java.net/jeps/215">JDK 9</a></p> </li> </ul> <h3 id="g1-garbage-collector-default">G1 Garbage Collector (default)</h3> <ul> <li> <p>NUMA-Aware Memory Allocation<br> <a href="https://openjdk.java.net/jeps/345">JDK 14</a></p> </li> <li> <p>Abortable mixed collections to meet user-supplied pause goals<br> <a href="https://openjdk.java.net/jeps/344">JDK 12</a></p> </li> <li> <p>Automatically return heap memory to the operating system when idle<br> <a href="https://openjdk.java.net/jeps/346">JDK 12</a></p> </li> <li> <p>Parallel Full GC to improve worst-case latencies<br> <a href="https://openjdk.java.net/jeps/307">JDK 10</a></p> </li> <li> <p>G1 Garbage Collector is now the default instead of Parallel GC<br> <a href="https://openjdk.java.net/jeps/248">JDK 9</a></p> </li> </ul> <h3 id="other-garbage-collectors">Other Garbage Collectors</h3> <ul> <li> <p>Z Garbage Collector, offering very low pause times on large heaps<br> <a href="https://openjdk.java.net/jeps/379">JDK 15</a> (<strong>Experimental</strong> 💥 in <a href="https://openjdk.java.net/jeps/365">JDK 14</a> (Windows) <a href="https://openjdk.java.net/jeps/364">JDK 14</a> (OS X) <a href="https://openjdk.java.net/jeps/333">JDK 11</a> (Linux) )</p> </li> <li> <p>Shenandoah Garbage Collector, offering similar benefits as ZGC but based on a different algorithm<br> <a href="https://openjdk.java.net/jeps/377">JDK 15</a> (<strong>Experimental</strong> 💥 in <a href="https://openjdk.java.net/jeps/189">JDK 12</a> )</p> </li> <li> <p>Epsilon Garbage Collector, which does not implement actual memory reclamation, striving for the lowest overhead possible<br> <a href="https://openjdk.java.net/jeps/318">JDK 11</a></p> </li> <li> <p><code>XX:AllocateHeapAt=&lt;path&gt;</code> to support Alternative Memory Devices<br> <a href="https://openjdk.java.net/jeps/316">JDK 10</a></p> </li> </ul> <h3 id="diagnostic-and-tools">Diagnostic and Tools</h3> <ul> <li> <p>Flight Recorder Event Streaming: profiling data is available via an <a href="https://cr.openjdk.java.net/~egahlin/jep-349/javadocs/api/jdk.jfr/jdk/jfr/consumer/package-summary.html">API</a>, making it suitable …</p></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://advancedweb.hu/a-categorized-list-of-all-java-and-jvm-features-since-jdk-8-to-15/">https://advancedweb.hu/a-categorized-list-of-all-java-and-jvm-features-since-jdk-8-to-15/</a></em></p>]]>
            </description>
            <link>https://advancedweb.hu/a-categorized-list-of-all-java-and-jvm-features-since-jdk-8-to-15/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24636197</guid>
            <pubDate>Wed, 30 Sep 2020 06:29:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple’s T2 security chip jailbreak]]>
            </title>
            <description>
<![CDATA[
Score 283 | Comments 105 (<a href="https://news.ycombinator.com/item?id=24636166">thread link</a>) | @Yeri
<br/>
September 29, 2020 | https://reportcybercrime.com/hackers-jailbreak-apples-t2-security-chip-powered-by-bridgeos/ | <a href="https://web.archive.org/web/*/https://reportcybercrime.com/hackers-jailbreak-apples-t2-security-chip-powered-by-bridgeos/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>The Apple T2 security chip has finally been jailbroken! Here’s all you need to know about it.&nbsp; &nbsp; &nbsp;</p>
<h2><span id="The_Apple_T2_Security_chip_now_has_a_jailbreak"><strong>The Apple T2 Security chip now has a jailbreak</strong><span></span></span></h2>
<p>The <a href="https://yalujailbreak.net/checkra1n-jailbreak-ios-14/">latest update of checkra1n</a> adds support for bridgeOS – the operating system that powers the Apple T2 security chip.</p>
<p>For what it’s worth, the T2 chip is not A10 per se but it is derived from the Apple A10 Fusion architecture.&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p><strong>bridgeOS</strong> is a proprietary operating system created by Apple for its hardware. It is responsible for operating the Touch Bar and managing secure data.&nbsp;&nbsp;&nbsp;</p>
<p>Here’s what hacker Jamie Bishop had to say about this development.&nbsp;&nbsp;</p>
<blockquote data-width="550" data-dnt="true">
<p lang="en" dir="ltr">With <a href="https://twitter.com/checkra1n?ref_src=twsrc%5Etfw" target="_blank" rel="nofollow noopener noreferrer">@checkra1n</a> 0.11.0, you can now jailbreak the T2 chip in your Mac. An incredible amount of work went into this and it required changes at multiple levels.</p>
<p>There’s too many people to tag, but shoutout to everyone who worked on getting this incredible feature shipped.</p>
<p>— Jamie Bishop (@jamiebishop123) <a href="https://twitter.com/jamiebishop123/status/1308355178307948545?ref_src=twsrc%5Etfw" target="_blank" rel="nofollow noopener noreferrer">September 22, 2020</a></p>
</blockquote>
<p>Since checkra1n is still in beta, there are a few issues you need to be aware of. Firstly, you might have to reconnect your device after jailbreaking for bootstrap upload.</p>
<p>Secondly, macOS takes over the USB connection and blocks communication after bootup.&nbsp;</p>
<p>If you are interested in jailbreaking the T2 chip, download checkra1n jailbreak v0.11 from this <a href="https://yalujailbreak.net/checkra1n-jailbreak-ios-14/">link</a>.&nbsp;</p>
<h2><span id="What_can_a_bridgeOS_jailbreak_be_used_for"><strong>What can a bridgeOS jailbreak be used for?&nbsp;</strong><span></span></span></h2>
<p>The T2 security processor and the Touch Bar can run while the operating system is shutdown.</p>
<p>Apparently, jailbreak tweak developers could develop tweaks for the Touch Bar if it gets Substrate support in the future.</p>
<p>At present, there are no publicly dumped headers available for bridgeOS. It lacks a MobileSubstrate port too. However, that could change in the future because it shares some of the components of watchOS and iOS frameworks.</p>
<p>Once we get Substrate working, <strong>tweaking and theming could become possible.</strong></p>

<p>The ability to exploit the T2 processor could also allow you to bypass the anti-repair mechanism built into the Touch Bar. Further, it may allow hackers to get rid of the password or unlock MDM-locked systems.&nbsp;</p>
<p>As far as the OS goes, we could also add secure boot certificates like Microsoft’s secure boot signing or a self-signed Linux certificate.&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p>It will definitely be interesting to see what the future holds for the <em>T2 security chip</em> following the release of checkra1n.&nbsp; &nbsp; &nbsp;</p>
<p>Don’t forget to follow us on Twitter and Facebook for the latest jailbreak news and updates.&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</p>
</div></div>]]>
            </description>
            <link>https://reportcybercrime.com/hackers-jailbreak-apples-t2-security-chip-powered-by-bridgeos/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24636166</guid>
            <pubDate>Wed, 30 Sep 2020 06:19:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Book Review: Elements of Programmnig]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24635947">thread link</a>) | @todsacerdoti
<br/>
September 29, 2020 | http://www.pathsensitive.com/2020/09/book-review-elements-of-programmnig.html | <a href="https://web.archive.org/web/*/http://www.pathsensitive.com/2020/09/book-review-elements-of-programmnig.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>

<p>The C++ STL may be the most impressive achievement in language standard libraries. Where most programmers are stuck complaining that their language’s default strings aren’t performant enough, about every standard C++ function for strings actually runs on arbitrary character sequences. Design your own container? <span>std::find_if</span> works just as well as for the built-ins. And it does this while often being more performant than the code you’d write yourself.</p>

<p>Alex Stepanov is the man who made this happen, and Elements of Programming (EOP) is his 200-page paean to his method for writing generic code. He’s a believer that programming can be turned from an art to a rigorous discipline based on mathematics, and I’ve long admired him for his deep knowledge and impact. Indeed, he’s spent years at  #1 on my list of people I’d like to have lunch with. (Hey readers — can anyone help?)</p>

<p>And now, I’m about to ruin all that by writing a negative review.</p>

<p>EOP has a strong beginning and a strong finish. The first chapter explains core programming language concepts such as types and state — using non-standard terminology, but probably intentionally, judging by the explanation’s lucidity. This culminates in his big idea of being able to write programs on any type that offers a bundle of operations and properties called a concept, explained in this book over a decade before they entered the C++ standard. The afterword is a few pages of reflection on the power of this approach.</p>

<p>Between them is 11 chapters where he plays the same game: define a new abstraction and then show a bunch of functions that can be written using it. And unfortunately, these functions and abstractions are largely not very interesting.</p>

<p>There’s a famous site called Project Euler, where users write code to solve mathy problems such as “In a modified version of the board game Monopoly, on what three squares is a player most likely to land?” My former programming-contest coach advocated against using it to practice, because “It’s not really programming, and it’s not really math.”</p>

<p>I think this is an apt description of EOP, particularly the first half. This starts from Chapter 2, which is about cool algorithms that involve applying some function to itself repeatedly (iteration). One of my <a href="https://www.cs.cmu.edu/~cdm/pdf/lect-05.pdf">favorite lectures</a> in undergrad was on this topic, and yet I still couldn’t enjoy this chapter, as I know no application of these algorithms outside of niche mathematical topics. This gets taken up another notch in Chapter 5, where, in about 5 pages, he goes from explaining commutativity to defining the algebraic structures of monoids, groups, and rings, all the way up to algebraic modules (no relation to software modules). I cannot fathom these explanations being useful to someone who does not already know these concepts, and certainly not to someone who already does. And while I do know many uses of groups in software engineering — as an abstraction of the idea of an invertible operation — he actually spends the remainder of this chapter considering generalizations of the greatest common divisor function.</p>

<p>I slogged through these chapters, excited for the second half of the book, which focused largely on iterators and containers, things more relevant to typical software engineering. Yet after encountering endless listings of variations of list-copy functions, I found myself no more fulfilled, and soon regressed to skimming through the pages.</p>

<p>Aside from my long-term goal to find all the good writing on software design, I had a short-term goal when reading this book: a student wanted me to teach a lesson based on it. But, halfway through the book, my deadline was fast approaching, and I hadn’t found any material useful enough for a software design lesson for experienced engineers.</p>

<p>I then noticed all the chapters were generated by the deeper principle of coming up with a good abstraction to write generic functions against. I got the idea that maybe I could use EOP as a problem book, telling them to look at the descriptions of generic functions, and then come up with both the code and the abstractions they can be written against. Alas, the topic selection is not suitable for this purpose. One section of the book, for example, deals with computing integer sequences by matrix exponentiation. Asking students to come up with this themselves would be too familiar for many who have taken a linear algebra course, and impossible for those who haven’t. I did design a lesson where students come up with their own abstractions for generic programming problems, but I used examples completely unrelated to the book.</p>

<p>I asked the friend who recommended EOP what he got out of the book, and his first answer was a technique for elegantly expressing state machines using goto’s. I similarly loved that part, but, alas, that was the only concrete thing I got out of this book. I’ll explain it at the end of this review and spare you the other 200 pages.</p>

<p>I have an undergraduate degree in mathematics and have authored several papers on generic programming, so I knew I was reading it for others’ benefit. Still, I don’t think my opinion would be changed were this not the case, and I’d really like help understanding the viewpoint of the many readers who did thoroughly enjoy it. Instead, I find myself agreeing with this Amazon reviewer, although I have too much admiration for Stepanov to contemplate a 1-star rating:</p>

<blockquote>If you've ever written a generic function, you already know that the type parameters must obey a set of preconditions. This book lays out a big pile of definitions for types, numbers, algebraic structures, iterators, and such, so as to bamboozle people easily impressed by mathematical notation. It does so sloppily and writes some trivial generic algorithms in C++. To whatever extent one might accomplish something interesting with this topic, this book doesn't. Avoid.</blockquote>

<p>As I read other material by Stepanov, I mourn for the book that could have been. Stepanov clearly cares about these abstractions and algorithms, to the point where he wrote a <a href="https://www.amazon.com/Mathematics-Generic-Programming-Alexander-Stepanov/dp/0321942043">second book</a> on largely the same material, with a chattier exposition and chapters more explicitly focusing on pure math. How different would it be had he managed to transmit this appreciation to me? The day after finishing, I watched <a href="https://www.youtube.com/watch?v=W2tWOdzgXHA&amp;t=1344s">this talk</a> by a close colleague of Stepanov. “In this menu, you can select a bunch of rows and drag them somewhere else,” he explained over animated slides. “How many of you could implement this in one line?” It made me want to open section 10.4 on “rotation algorithms” again.</p>

<p>I’ve started watching <a href="https://www.youtube.com/playlist?list=PLHxtyCq_WDLXryyw91lahwdtpZsmo4BGD">a seminar</a> he gave at Amazon. I’m only a few lectures in, but I’m already enthralled by his high teaching ability. I feel like I’m there with him working through problems. I feel like I’ve learned a great secret as he tells the story of how he invented “regular types,” something used throughout EOP but never motivated. To be honest, I still don’t know what this lecture series is about, but nonetheless expect to recommend it when I’m done.</p>

<p>In short, Stepanov has given many gifts to the world of programming, and EOP is not one of them.</p>

<p><b>Overall rating</b>: <span>Not recommended</span></p>

<p>With a smattering of exceptions, EOP neither teaches abstractions useful in everyday programming, nor teaches you the skills to invent your own.</p>

<h2><b>Addendum</b>: State machines by goto’s</h2>

<blockquote>“The fastest way to go from one place in code to another is goto.”</blockquote><p>

— <a href="https://www.youtube.com/watch?v=sp_IBYVqMeQ&amp;list=PLHxtyCq_WDLXryyw91lahwdtpZsmo4BGD">Alexander Stepanov</a></p><p>Many iterative algorithms can be described as state machines: first it looks for an X, then it does Y with it, then it looks for another X, and so on. Rather than trying to massage the cycles in the state machine into structured loops, Stepanov advocates a style using goto’s, with one goto-label per machine state.</p>

<p>In searching for an example to best illustrate this, I wanted something where the code was under 40 lines (which ruled out Stepanov’s examples), understandable with little context or knowledge of C++, and which was not equivalent to a regular expression. And so:</p>

<p>In my defunctionalization talk, I showed that many state machines are derived from recursive functions, being turned into iterative traversals by creating a state for each point in the program between recursive calls. For that talk, I demonstrated this in full for the example of printing a binary tree. It turns out that adding parentheses makes this derivation substantially harder, as an arbitrary number of close-parentheses may need to be printed after processing a node. And that difficulty comes from trying to massage a state machine into a loop.</p>

<p>In this case, seeing as I came up with this example by starring with a recursive function, the recursive version is quite simple:</p>

<div><pre><span>void</span> <span>print_tree_rec</span><span>(tree</span> <span>*</span><span>t)</span> <span>{</span>
  <span>if</span> <span>(t</span> <span>!=</span> <span>NULL)</span> <span>{</span>
    <span>printf(</span><span>"("</span><span>);</span>
    <span>print_tree_rec(t</span><span>-&gt;</span><span>left);</span>
    <span>printf(</span><span>" %d "</span><span>,</span> <span>t</span><span>-&gt;</span><span>element);</span>
    <span>print_tree_rec(t</span><span>-&gt;</span><span>right);</span>
    <span>printf(</span><span>")"</span><span>);</span>
  <span>}</span>
<span>}</span>
</pre></div>


<p>But, for other state machines, the recursive version is not so easy. For example, Dijkstra created the “shunting yard” algorithm for parsing an arithmetic expression all the way back in 1961, yet I’m not aware of the recursive equivalent being discovered <a href="https://www.brics.dk/RS/07/7/BRICS-RS-07-7.pdf">until 2007</a>, using the technique of refunctionalization.</p>

<p>Here’s the state machine:</p><p><span id="docs-internal-guid-068c5e82-7fff-aeae-61d2-74453ca23aeb"><span><span><img height="566" src="https://lh4.googleusercontent.com/bfYT7CeU0eo8KAoMt8gB5Y4FDgD7Y1UlUJYSNI3ndYZ6jQpZv5Nwpyqyqoqffi_tgSRBYslU93EZy_nCil9ub6FZraaRGOBoABGPk0i9DoNbgr1fWAnkQzXMxPvLvEYFSDRWZ1RL" width="572"></span></span></span></p>

<p>A confession: the first time I thought about how to make this recursive function function iterative, I didn’t get it, and had to look it up. The solution is to merge the “Next from stack” state in the diagram with its successors, resulting in a solution with two nested while-loops, at the cost of some duplicated code.</p>

<p>However, the version based on goto’s reads off this diagram rather nicely. One C++-ism in this code to note: while the stack s is initialized to NULL, the  <span>push()</span> and  <span>pop()</span> calls can actually change it.</p>

<!--HTML generated using hilite.me--><div><pre><span>void</span> <span>print_tree</span><span>(tree</span> <span>*</span><span>t)</span> <span>{</span>
  <span>tree</span> <span>*</span><span>cur</span> <span>=</span> <span>t;</span>
  <span>stack</span> <span>*</span><span>s</span> <span>=</span> <span>NULL;</span>
  
<span>begin_print_node:</span>
  <span>if</span> <span>(cur</span> <span>==</span> <span>NULL)</span> <span>{</span>
    <span>goto</span> <span>dispatch_stack_frame;</span>
  <span>}</span> <span>else</span> <span>{</span>
    <span>printf(</span><span>"("</span><span>);</span>
    <span>push(LEFT_CHILD,</span> <span>cur,</span> <span>s);</span>
    <span>cur</span> <span>=</span> <span>cur</span><span>-&gt;</span><span>left;</span>
    <span>goto</span> <span>begin_print_n…</span></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.pathsensitive.com/2020/09/book-review-elements-of-programmnig.html">http://www.pathsensitive.com/2020/09/book-review-elements-of-programmnig.html</a></em></p>]]>
            </description>
            <link>http://www.pathsensitive.com/2020/09/book-review-elements-of-programmnig.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24635947</guid>
            <pubDate>Wed, 30 Sep 2020 05:28:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Notes on the future of media by Balaji S]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24635654">thread link</a>) | @dayve
<br/>
September 29, 2020 | https://cephalopods.blog/2020/09/18/some-notes-on-balaji-srinivasans-talk-on-the-future-of-media/ | <a href="https://web.archive.org/web/*/https://cephalopods.blog/2020/09/18/some-notes-on-balaji-srinivasans-talk-on-the-future-of-media/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>A few weeks ago Balaji Srinivasan was featured in a virtual meetup hosted by Joshua Fox. Balaji gave a talk on decentralized alternatives to legacy media, with a definite overtone of<em> New York Times delenda est</em>. It was a very good talk. I feel the need to get my head around what he said, and I often find the “5th grade book report” approach of summarizing something to be highly useful in this regard.  So this post is just me going over some of his arguments and predictions. </p>



<h2>Of Oracles and Advocates</h2>



<p>Balaji imagines a future where there is a separation between truth aggregation and narrative in  journalism. That is, he predicts that mechanisms will arise that will reliably correlate with reality, expressing the appropriate degrees of uncertainty. And then on top of the mechanisms, either decentralized contractors, or eventually text models like GPT-3, will apply a layer of narrative gloss, obsoleting the publisher and maybe even the journalists altogether. He refers to this class of mechanisms as “feeds/oracles” and those people or algorithms that apply the narrative gloss as “advocates”</p>



<p>He mentions financial and sports journalism as prototypical examples where such a separation exists today. Many such stories are largely just raw scores or stock prices converted rather mechanically (whether by a human or an algorithm) into narrative form. <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Narrative_Science" target="_blank">Narrative Science</a> is a company with a rather old-fashioned template-based text generator which is writing millions of such stories every day, using the feed + narrative gloss approach. He has a great line about this in the talk:</p>



<blockquote><p>Stock market stories are just text wrappers around Bloomberg data, sports stories just <em>text wrappers</em> around scores, and political stories are just <em>text wrappers</em> around tweets.</p></blockquote>



<p>I particularly like “Political stories are just text wrappers around tweets” – both true,  discomfiting and amusing all at once.</p>



<p>After introducing this distinction between “feeds/oracles” and “advocates” he then described the “ledger of record,” which is his word for the sort of generalized space of all active blockchains. </p>



<p>To place my possibly unjustified biases on the table, since reading all the white papers of some of  the highest market-cap ERC20 tokens, I have been pretty skeptical of cryptocurrency. I will refrain from writing the three-paragraph rant that would be required to adequately describe the amount of stupid that was present in some those white papers but suffice it to say it turned me off the whole scene. </p>



<p>But despite my distaste for the stuff, a good cook can make a fine meal of the most exotic ingredients and Balaji waxes quite well on the value of decentralized ledgers. The main value-adds he mentions are payments and trustless timestamps, particularly the role of timestamps in allowing pseudonyms to accrue reputation. His slogan for this is “first payments, then truth.”</p>



<p>One easy thing you can prove with a blockchain is that this particular string was signed with this particular key, and existed at this particular time. By hashing the string, you can do this without revealing the contents. One can imagine a pseudonymous data aggregator establishing a reputation by time-stamping facts in this way before they become commonly known. And then selling access to a stream of such data. </p>



<p>One problem that pops up in my head now is it seems like you would end up with a lot of <a href="https://en.wikipedia.org/wiki/List_of_confidence_tricks#Baltimore_Stockbroker_/_Psychic_Sports_Picks">Baltimore stockbrokers</a>. Maybe this would not be a problem though, as once you are aware of a data aggregator you are immune to such selection effects going forward. Time is not on the side of a Baltimore stockbroker.  So maybe prominence would screen off such people. But these types of selection effects confuse my squib brain and my intuitions here are not very clear. I wish I had asked him about the Baltimore stockbroker problem during the Q&amp;A.</p>



<p>Regardless, a plain-text public feed does not have this problem, and will probably be the most common. Especially if it is not pseudonymous. If pseudonymous, there is always the temptation of defecting, especially if your feeds are used by smart contracts to settle various bets. I know Augur and other projects are working on solutions to this, and his opinion on the efficacy of such mechanisms is another question I regret not asking. </p>



<p>My impression so far is there does not appear to be much activity on any decentralized prediction markets, despite them existing for many years. Perhaps this is related to it being provably irrational to participate in an unsubsidized predication market. </p>



<p>Subsidizing a prediction market with inflation seems like it could have been a good idea for Bitcoin or Ethereum, but would be hard to implement now. In general, inflation strikes me as an ideal way to subsidize public goods (such as information aggregation) and I think it is a big lost opportunity that Ethereum and Bitcoin use it exclusively to fund security.  It’s a shame inflation is such a dirty word among the blockchain crowd, as it is ironically the most powerful tool in their arsenal. </p>



<h2>Advocates or Agents?</h2>



<p><br>He talked about the incentives for citizen journalists, and one of them is a notion of duty. One problem with duty as a sole incentive is that a pathological means of amplifying one’s sense of duty is indoctrination into an ideology.  And I wonder if, in a world where duty is one of the only remaining incentives for journalism, this will only amplify ideologues of various stripes. </p>



<p>I would prefer a sort of “mechanisms all the way up” approach, and (as mentioned) Balaji speculated about  a means to do this. It certainly seems science fictional now, but the idea of prediction markets, centralized or decentralized, solidifying a sort of agreed-upon ontology of the present and future is highly appealing to me. </p>



<p>Scott Alexander describes this potential well here:</p>



<blockquote><p>A democratic vote among the scientific establishment is insufficient to settle these topics. The most important problem is that it gives massive power to the people who determine who gets to be part of “the scientific establishment”. … So not having any Schelling point – being hopelessly confused about the legitimacy of academic ideas – sucks. But a straight democratic vote of academics would also suck and be potentially unfair.</p><p>Prediction markets avoid these problems. There is no question of who the experts are: anyone can invest in a prediction market. There’s no question of special interests taking it over; this just distributes free money to more honest investors. Not only do they escape real bias, but more importantly they escape perceived bias. It is breathtakingly beautiful how impossible it is to rail that a prediction market is the tool of the liberal media or whatever. …</p><p>Nate Silver might do better than a prediction market, I don’t know. But Nate Silver is not a Schelling point. Nobody chose him as Official Statistics Guy via a fair process. And if someone objected to his beliefs, they could accuse him of bias and he would have no recourse until it was too late. If a prediction market is almost as good as Nate, and it is also unbiased and impossible to accuse of bias, we have our Schelling point. …</p></blockquote>



<p>In Balaji’s vision, this shelling point would be reified in the “ledger of record” mentioned earlier. </p>



<p>A humorous thought I had is if we do get an agreed upon method of selecting policies that is effective then a utilitarian could have their GPT-N bot rationalize these policies to them through a utilitarian lens, and others could have their GPT-N rationalize these policies as what Marx truly intended, the culmination of the non-aggression principle, the obvious result of Kantian universality, or the culmination of neo-liberalism. A recipe for Utopia if I ever heard one!</p>



<p>Balaji addressed the obvious objection that most news consumption is largely about affiliation rather than truth-seeking, saying that those people who want truth will have an incentive to use the best means available even if most people prefer a circus. And this should undoubtedly be an improvement over what we have today. </p>



<p>After the talk,  Balaji hanged out for a bit in the breakout rooms with our regulars.</p>



<p> I won’t go too far into details here but he mentioned this on Twitter so I think it is safe to share: I made a claim about the inability to transfer reputation between pseudonyms and within about 20 seconds he came up with a scheme, using known cryptographic primitives, that partially bypassed my objections, pointing out that things like Reddit and Stack Overflow karma are fungible and so can be transferred to pseudonyms without unmasking them using something like Zcash.  I did a little Googling afterward and it appears it was an entirely novel idea that seems likely to work, and it just popped into his head before I had finished making my point. </p>



<p>I am still skeptical about pseudonyms being useful given the 33 bit problem, but it was impressive.</p>



<p>It is quite plausible that my interpretations of his arguments are much weaker than his actual arguments, so sign up to his mailing list at <a href="https://balajis.com/signup/">https://balajis.com/signup/</a>, where he will be releasing a video of a more polished version of the same talk to get the pure stuff.</p>
	</div></div>]]>
            </description>
            <link>https://cephalopods.blog/2020/09/18/some-notes-on-balaji-srinivasans-talk-on-the-future-of-media/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24635654</guid>
            <pubDate>Wed, 30 Sep 2020 04:18:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[From zero to main(): How to write a bootloader from scratch]]>
            </title>
            <description>
<![CDATA[
Score 206 | Comments 20 (<a href="https://news.ycombinator.com/item?id=24635383">thread link</a>) | @tigerlily
<br/>
September 29, 2020 | https://interrupt.memfault.com/blog/how-to-write-a-bootloader-from-scratch | <a href="https://web.archive.org/web/*/https://interrupt.memfault.com/blog/how-to-write-a-bootloader-from-scratch">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        <p>This is the third post in our <a href="https://interrupt.memfault.com/blog/tag/zero-to-main">Zero to main() series</a>,
where we bootstrap a working firmware from zero code on a
cortex-M series microcontroller.</p>

<p>Previously, <a href="https://interrupt.memfault.com/blog/zero-to-main-1">we wrote a startup file to bootstrap our C environment</a>, and <a href="https://interrupt.memfault.com/blog/how-to-write-linker-scripts-for-firmware">a linker
script to get the right data at the right addresses</a>. These two will allow us to
write a monolithic firmware which we can load and run on our microcontrollers.</p>

<p>In practice, this is not how most firmware is structured. Digging through vendor
SDKs, you’ll notice that they all recommend using a <em>bootloader</em> to load your
applications. A bootloader is a small program which is responsible for loading
and starting your application.</p>

<!-- excerpt start -->
<p>In this post, we will explain why you may want a
bootloader, how to implement one, and cover a few advanced techniques you may
use to make your bootloader more useful.
<!-- excerpt end --></p>

<p>Like Interrupt? <a href="http://eepurl.com/gpRedv" target="_blank">Subscribe</a> to get our latest posts straight to your mailbox.</p>



<h2 id="why-you-may-need-a-bootloader">Why you may need a bootloader</h2>

<p>Bootloaders serve many purposes, ranging from security to software architecture.</p>

<p>Most commonly, you may need a bootloader to load your software. Some
microcontrollers like Dialog’s
<a href="https://www.dialog-semiconductor.com/products/connectivity/bluetooth-low-energy/smartbond-da14580-and-da14583">DA14580</a>
have little to no onboard flash and instead rely on an external device to store
firmware code. In that case, it is the bootloader’s job to copy code from
non-executable storage, such as a SPI flash, to an area of memory that can be
executed from, such as RAM.</p>

<p>Bootloaders also allow you to decouple parts of the program that are mission
critical, or that have security implications, from application code which
changes regularly.  For example, your bootloader may contain firmware update
logic so your device can recover no matter how bad a bug ships in your
application firmware.</p>

<p>Last but certainly not least, bootloaders are an essential component of a
trusted boot architecture.  Your bootloader can, for example, verify a
cryptographic signature to make sure the application has not been replaced or
tampered with.</p>

<h2 id="a-minimal-bootloader">A minimal bootloader</h2>
<p>Let’s build a simple bootloader together. To start, our bootloader must do two
things:</p>

<ol>
  <li>Execute on MCU boot</li>
  <li>Jump to our application code</li>
</ol>

<p>We’ll need to decide on a memory map, write some bootloader code, and update our
application to make it bootload-able.</p>

<h3 id="setting-the-stage">Setting the stage</h3>

<p>For this example, we’ll be using the same setup as we did in our previous Zero
to Main posts:</p>
<ul>
  <li>Adafruit’s <a href="https://www.adafruit.com/product/3505">Metro M0 Express</a> as our
development board,</li>
  <li>a simple <a href="https://www.adafruit.com/product/2764">CMSIS-DAP Adapter</a></li>
  <li>OpenOCD (the <a href="https://github.com/arduino/OpenOCD">Arduino fork</a>) for
programming</li>
</ul>

<h3 id="deciding-on-a-memory-map">Deciding on a memory map</h3>

<p>We must first decide on how much space we want to dedicate to our bootloader.
Code space is precious - your application may come to need more of it - and you
will not be able to change this without updating your bootloader, so make
this as small as you possibly can.</p>

<p>Another important factor is your flash sector size: you want to make sure you
can erase app sectors without erasing bootloader data, or vice versa.
Consequently, your bootloader region must end on a flash sector boundary
(typically 4kB).</p>

<p>I decided to go with a 16kB region, leading to the following memory map:</p>

<div><div><pre><code>        0x0 +---------------------+
            |                     |
            |     Bootloader      |
            |                     |
     0x4000 +---------------------+
            |                     |
            |                     |
            |     Application     |
            |                     |
            |                     |
    0x30000 +---------------------+
</code></pre></div></div>

<p>We can transcribe that memory into a linker script:</p>

<div><div><pre><code>/* memory_map.ld */
MEMORY
{
  bootrom  (rx)  : ORIGIN = 0x00000000, LENGTH = 0x00004000
  approm   (rx)  : ORIGIN = 0x00004000, LENGTH = 0x0003C000
  ram      (rwx) : ORIGIN = 0x20000000, LENGTH = 0x00008000
}

__bootrom_start__ = ORIGIN(bootrom);
__bootrom_size__ = LENGTH(bootrom);
__approm_start__ = ORIGIN(approm);
__approm_size__ = LENGTH(approm);
</code></pre></div></div>

<p>Since linker scripts are composable, we will be able to <code>include</code> that memory
map into the linker scripts we write for our bootloader and our application.</p>

<p>You’ll notice that the linker script above declares some variables. We’ll need
those for our bootloader to know where to find the application. To make them
accessible in C code, we declare them in a header file:</p>

<div><div><pre><code><span>/* memory_map.h */</span>
<span>#pragma once
</span>
<span>extern</span> <span>int</span> <span>__bootrom_start__</span><span>;</span>
<span>extern</span> <span>int</span> <span>__bootrom_size__</span><span>;</span>
<span>extern</span> <span>int</span> <span>__approm_start__</span><span>;</span>
<span>extern</span> <span>int</span> <span>__approm_size__</span><span>;</span>
</code></pre></div></div>

<h3 id="implementing-the-bootloader-itself">Implementing the bootloader itself</h3>
<p>Next up, let’s write some bootloader code. Our bootloader needs to start
executing on boot and then jump to our app.</p>

<p>We know how to do the first part from our previous post: we need a valid stack
pointer at address <code>0x0</code> , and a valid <code>Reset_Handler</code>  function setting up our
environment at address <code>0x4</code>. We can reuse our previous startup file and linker
script, with one change: we use  <code>memory_map.ld</code> rather than define our own
<code>MEMORY</code> section.</p>

<p>We also need to put our code in the <code>bootrom</code> region from our memory rather than
the <code>rom</code> region in our previous post.</p>

<p>Our linker script therefore looks like this:</p>

<div><div><pre><code>/* bootloader.ld */
INCLUDE memory_map.ld

/* Section Definitions */
SECTIONS
{
    .text :
    {
        KEEP(*(.vectors .vectors.*))
        *(.text*)
        *(.rodata*)
        _etext = .;
    } &gt; bootrom
  ...
}
</code></pre></div></div>

<p>To jump into our application, we need to know where the <code>Reset_Handler</code> of the
app is, and what stack pointer to load.  Again, we know from our previous post
that those should be the first two 32-bit words in our binary, so we just need
to dereference those addresses using the <code>__approm_start__</code> variable from our
memory map.</p>

<div><div><pre><code><span>/* bootloader.c */</span>
<span>#include &lt;inttypes.h&gt;
#include "memory_map.h"
</span>
<span>int</span> <span>main</span><span>(</span><span>void</span><span>)</span> <span>{</span>
  <span>uint32_t</span> <span>*</span><span>app_code</span> <span>=</span> <span>(</span><span>uint32_t</span> <span>*</span><span>)</span><span>__approm_start__</span><span>;</span>
  <span>uint32_t</span> <span>app_sp</span> <span>=</span> <span>app_code</span><span>[</span><span>0</span><span>];</span>
  <span>uint32_t</span> <span>app_start</span> <span>=</span> <span>app_code</span><span>[</span><span>1</span><span>];</span>
  <span>/* TODO: Start app */</span>
  <span>/* Not Reached */</span>
  <span>while</span> <span>(</span><span>1</span><span>)</span> <span>{}</span>
<span>}</span>
</code></pre></div></div>

<p>Next we must load that stack pointer and jump to the code. This will require a
bit of assembly code.</p>

<p>ARM MCUs use the <a href="http://www.keil.com/support/man/docs/armasm/armasm_dom1361289882044.htm"><code>msr</code> instruction
</a> to
load immediate or register data into system registers, in this case the MSP
register or “Main Stack Pointer”.</p>

<p>Jumping to an address is done with a branch, in our case with a <a href="http://www.keil.com/support/man/docs/armasm/armasm_dom1361289866466.htm"><code>bx</code>
instruction</a>.</p>

<p>We wrap those two into a <code>start_app</code> function which accepts our <code>pc</code> and <code>sp</code> as
arguments, and get our minimal bootloader:</p>

<div><div><pre><code><span>/* app.c */</span>
<span>#include &lt;inttypes.h&gt;
#include "memory_map.h"
</span>
<span>static</span> <span>void</span> <span>start_app</span><span>(</span><span>uint32_t</span> <span>pc</span><span>,</span> <span>uint32_t</span> <span>sp</span><span>)</span> <span>__attribute__</span><span>((</span><span>naked</span><span>))</span> <span>{</span>
    <span>__asm</span><span>(</span><span>"           </span><span>\n</span><span>\
          msr msp, r1 /* load r1 into MSP */</span><span>\n</span><span>\
          bx r0       /* branch to the address at r0 */</span><span>\n</span><span>\
    "</span><span>);</span>
<span>}</span>

<span>int</span> <span>main</span><span>(</span><span>void</span><span>)</span> <span>{</span>
  <span>uint32_t</span> <span>*</span><span>app_code</span> <span>=</span> <span>(</span><span>uint32_t</span> <span>*</span><span>)</span><span>__approm_start__</span><span>;</span>
  <span>uint32_t</span> <span>app_sp</span> <span>=</span> <span>app_code</span><span>[</span><span>0</span><span>];</span>
  <span>uint32_t</span> <span>app_start</span> <span>=</span> <span>app_code</span><span>[</span><span>1</span><span>];</span>
  <span>start_app</span><span>(</span><span>app_start</span><span>,</span> <span>app_sp</span><span>);</span>
  <span>/* Not Reached */</span>
  <span>while</span> <span>(</span><span>1</span><span>)</span> <span>{}</span>
<span>}</span>
</code></pre></div></div>

<blockquote>
  <p>Note: hardware resources initialized in the bootloader must be de-initialized
before control is transferred to the app. Otherwise, you risk breaking
assumptions the app code is making about the state of the system</p>
</blockquote>

<h3 id="making-our-app-bootloadable">Making our app bootloadable</h3>

<p>We must update our app to take advantage of our new memory map. This is again
done by updating our linker script to include <code>memory_map.ld</code> and changing our
sections to go to the <code>approm</code> region rather than <code>rom</code>.</p>

<div><div><pre><code>/* app.ld */
INCLUDE memory_map.ld

/* Section Definitions */
SECTIONS
{
    .text :
    {
        KEEP(*(.vectors .vectors.*))
        *(.text*)
        *(.rodata*)
        _etext = .;
    } &gt; approm
  ...
}
</code></pre></div></div>

<p>We also need to update the <a href="https://developer.arm.com/docs/dui0552/latest/the-cortex-m3-processor/exception-model/vector-table"><em>vector
table</em></a>
used by the microcontroller. The vector table contains the address of every
exception and interrupt handler in our system. When an interrupt signal comes
in, the ARM core will call the address at the corresponding offset in the vector
table.</p>

<p>For example, the offset for the Hard fault handler is <code>0xc</code>, so when a hard
fault is hit, the ARM core will jump to the address contained in the table at
that offset.</p>

<p>By default, the vector table is at address <code>0x0</code>, which means that when our chip
powers up, only the bootloader can handle exceptions or interrupts! Fortunately, ARM
provides the <a href="https://developer.arm.com/docs/dui0552/latest/cortex-m3-peripherals/system-control-block/vector-table-offset-register">Vector Table Offset
Register</a>
to dynamically change the address of the vector table. The register is at
address <code>0xE000ED08</code> and has a simple layout:</p>

<div><div><pre><code>31                                  7              0
+-----------------------------------+--------------+
|                                   |              |
|              TBLOFF               |   Reserved   |
|                                   |              |
+-----------------------------------+--------------+
</code></pre></div></div>

<p>Where <code>TBLOFF</code> is the address of the vector table. In our case, that’s the start
of our text section, or <code>_stext</code>. To set it in our app, we add the following to
our <code>Reset_Handler</code>:</p>

<div><div><pre><code><span>/* startup_samd21.c */</span>
<span>/* Set the vector table base address */</span>
<span>uint32_t</span> <span>*</span><span>vector_table</span> <span>=</span> <span>(</span><span>uint32_t</span> <span>*</span><span>)</span> <span>&amp;</span><span>_stext</span><span>;</span>
<span>uint32_t</span> <span>*</span><span>vtor</span> <span>=</span> <span>(</span><span>uint32_t</span> <span>*</span><span>)</span><span>0xE000ED08</span><span>;</span>
<span>*</span><span>vtor</span> <span>=</span> <span>((</span><span>uint32_t</span><span>)</span> <span>vector_table</span> <span>&amp;</span> <span>0xFFFFFFF8</span><span>);</span>
</code></pre></div></div>

<p>One quirk of the ARMv7-m architecture is the alignment requirement for the
vector table, as specified in section B1.5.3 of the <a href="https://static.docs.arm.com/ddi0403/eb/DDI0403E_B_armv7m_arm.pdf">reference
manual</a>:</p>

<blockquote>
  <p>The Vector table must be naturally aligned to a power of two whose alignment value is greater than or equal
to (Number of Exceptions supported x 4), with a minimum alignment of 128 bytes.The entry at offset 0 is
used to initialize the value for SP_main, see The SP registers on page B1-8. All other entries must have bit
[0] set, as the bit is used to define the EPSR T-bit on exception entry (see Reset behavior on page B1-20 and
Exception entry behavior on page B1-21 for details).</p>
</blockquote>

<p>Our SAMD21 MCU has 28 interrupts on top of the 16 system reserved exceptions,
for a total of 44 entries in the table. Multiply that by 4 and you get 176. The
next power of 2 is 256, so our vector table must be 256-byte aligned.</p>

<h3 id="putting-it-all-together">Putting it all together</h3>

<p>Because it is hard to witness the bootloader execute, we add a print line to
each of our programs:</p>

<div><div><pre><code><span>/* boootloader.c */</span>
<span>#include &lt;inttypes.h&gt;
#include "memory_map.h"
</span>
<span>static</span> <span>void</span> <span>s…</span></code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://interrupt.memfault.com/blog/how-to-write-a-bootloader-from-scratch">https://interrupt.memfault.com/blog/how-to-write-a-bootloader-from-scratch</a></em></p>]]>
            </description>
            <link>https://interrupt.memfault.com/blog/how-to-write-a-bootloader-from-scratch</link>
            <guid isPermaLink="false">hacker-news-small-sites-24635383</guid>
            <pubDate>Wed, 30 Sep 2020 03:19:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The UX of Banking]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24635364">thread link</a>) | @Garbage
<br/>
September 29, 2020 | https://builtformars.co.uk/banks/ | <a href="https://web.archive.org/web/*/https://builtformars.co.uk/banks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-elementor-type="wp-page" data-elementor-id="3032" data-elementor-settings="[]">
			<div>
				<div>
							<section data-id="2898fc6" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
							
							<div>
				<div>
				<div data-id="4964a44" data-element_type="column">
			<div>
					<div>
				
				<div data-id="0a3485f" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;none&quot;}" data-widget_type="heading.default">
				<p>
			<h3>What the challenger banks did differently: a study into the UX of banking.</h3>		</p>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="535cf2f" data-element_type="section">
						
		</section>
				<section data-id="9be0ee4" data-element_type="section">
						<div>
				<div>
				<div data-id="bf5c18d" data-element_type="column">
			<div>
					<div>
				
				<div data-id="b431a25" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;none&quot;}" data-widget_type="heading.default">
				<p>
			<h4>Billion dollar experiences</h4>		</p>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="b910384" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="96fe065" data-element_type="column">
			<div>
					<div>
				<div data-id="3c618a0" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>Monzo, Revolut and Starling—often called the challenger banks—have built billion-dollar businesses around the belief that they offer the best overall banking experience.</p>
				</div>
				</div>
				<div data-id="941ff44" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>But are they actually any better, or is it all clever marketing? To answer that question I opened 12 real bank accounts, and logged <em>everything</em>.</p>
				</div>
				</div>
				<div data-id="8bb4b6b" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>Each chapter provides a forensic analysis of a particular feature or user journey.</p>
				</div>
				</div>
				<div data-id="78b3d97" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>But more importantly, I’ve highlighted what can we all learn from the challenger banks, and used real examples to teach you how to craft better experiences in the future.</p>
				</div>
				</div>
						</div>
			</div>
		</div>
				<div data-id="560e042" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
			<div>
					<div>
				<div data-id="9643ce0" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p><strong>Subscribe to get more content like this!</strong></p>
				</div>
				</div>
				
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="546fd67" data-element_type="section">
						<div>
				<div>
				<div data-id="4cd7bfe" data-element_type="column">
			<div>
					<div>
				<div data-id="bdaeb8e" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><a href="https://builtformars.co.uk/banks/opening/">
							<img width="562" height="343" src="https://builtformars.co.uk/wp-content/uploads/2020/06/AllCardsFixed.jpg" alt="" srcset="https://builtformars.co.uk/wp-content/uploads/2020/06/AllCardsFixed.jpg 562w, https://builtformars.co.uk/wp-content/uploads/2020/06/AllCardsFixed-300x183.jpg 300w, https://builtformars.co.uk/wp-content/uploads/2020/06/AllCardsFixed-100x61.jpg 100w" sizes="(max-width: 562px) 100vw, 562px">								</a>
											</p>
				</div>
				</div>
				
				
				<div data-id="29b9a8f" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>It took <strong>18x longer</strong> to open an account with HSBC that it did with Monzo.</p>
				</div>
				</div>
				
						</div>
			</div>
		</div>
				<div data-id="4a8ea32" data-element_type="column">
			<div>
					<div>
				<div data-id="c26ace2" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><a href="https://builtformars.co.uk/banks/first-payment">
							<img width="562" height="343" src="https://builtformars.co.uk/wp-content/uploads/2020/06/FirstPaymentFixed-1.jpg" alt="" srcset="https://builtformars.co.uk/wp-content/uploads/2020/06/FirstPaymentFixed-1.jpg 562w, https://builtformars.co.uk/wp-content/uploads/2020/06/FirstPaymentFixed-1-300x183.jpg 300w, https://builtformars.co.uk/wp-content/uploads/2020/06/FirstPaymentFixed-1-100x61.jpg 100w" sizes="(max-width: 562px) 100vw, 562px">								</a>
											</p>
				</div>
				</div>
				
				
				<div data-id="410d84b" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>Payment notifications were <strong>at least 2x faster</strong> with the challenger banks, and in some cases <strong>100x faster</strong>.</p>
				</div>
				</div>
				
				<div data-id="5892a2c" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>⚡️ Includes <strong>12</strong><strong>&nbsp;case studies</strong></p>
				</div>
				</div>
						</div>
			</div>
		</div>
				<div data-id="671df6e" data-element_type="column">
			<div>
					<div>
				<div data-id="2d3db91" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><a href="https://builtformars.co.uk/banks/freezing/">
							<img width="562" height="343" src="https://builtformars.co.uk/wp-content/uploads/2020/06/FrozenCardsFixed.jpg" alt="" srcset="https://builtformars.co.uk/wp-content/uploads/2020/06/FrozenCardsFixed.jpg 562w, https://builtformars.co.uk/wp-content/uploads/2020/06/FrozenCardsFixed-300x183.jpg 300w, https://builtformars.co.uk/wp-content/uploads/2020/06/FrozenCardsFixed-100x61.jpg 100w" sizes="(max-width: 562px) 100vw, 562px">								</a>
											</p>
				</div>
				</div>
				
				
				<div data-id="caa9ed8" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>There were the <strong>only 3</strong> banks to send notifications when someone attempted to use a frozen card.</p>
				</div>
				</div>
				
				<div data-id="f06833c" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>⚡️ Includes <strong>10</strong><strong>&nbsp;case studies</strong></p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="894506f" data-element_type="section">
						<div>
				<div>
				<div data-id="df064b1" data-element_type="column">
			<div>
					<div>
				<div data-id="28c4ea8" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><a href="https://builtformars.co.uk/banks/international/">
							<img width="562" height="343" src="https://builtformars.co.uk/wp-content/uploads/2020/06/InternationalFixed.jpg" alt="" srcset="https://builtformars.co.uk/wp-content/uploads/2020/06/InternationalFixed.jpg 562w, https://builtformars.co.uk/wp-content/uploads/2020/06/InternationalFixed-300x183.jpg 300w, https://builtformars.co.uk/wp-content/uploads/2020/06/InternationalFixed-100x61.jpg 100w" sizes="(max-width: 562px) 100vw, 562px">								</a>
											</p>
				</div>
				</div>
				
				
				<div data-id="b437d79" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>It cost <strong>at least £20</strong> to send £1 (GBP) to a US bank (USD) with three banks.</p>
				</div>
				</div>
				
				<div data-id="f6c6bbc" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>⚡️ Includes <strong>12</strong><strong>&nbsp;case studies</strong></p>
				</div>
				</div>
						</div>
			</div>
		</div>
				<div data-id="8e4c759" data-element_type="column">
			<div>
					<div>
				<div data-id="c4df7a5" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><a href="https://builtformars.co.uk/banks/open-banking/">
							<img width="562" height="343" src="https://builtformars.co.uk/wp-content/uploads/2020/06/OpenBankingFixed.jpg" alt="" srcset="https://builtformars.co.uk/wp-content/uploads/2020/06/OpenBankingFixed.jpg 562w, https://builtformars.co.uk/wp-content/uploads/2020/06/OpenBankingFixed-300x183.jpg 300w, https://builtformars.co.uk/wp-content/uploads/2020/06/OpenBankingFixed-100x61.jpg 100w" sizes="(max-width: 562px) 100vw, 562px">								</a>
											</p>
				</div>
				</div>
				
				
				<div data-id="977ae52" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>It took nearly <strong>4x longer</strong>&nbsp;to authorise an Open Banking payment with Lloyds than it did with Starling.</p>
				</div>
				</div>
				
				<div data-id="4b3bec9" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>⚡️ Includes <strong>10</strong><strong>&nbsp;case studies</strong></p>
				</div>
				</div>
						</div>
			</div>
		</div>
				<div data-id="4ff6bfc" data-element_type="column">
			<div>
					<div>
				<div data-id="3fac4a8" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><a href="https://builtformars.co.uk/banks/support/">
							<img width="562" height="343" src="https://builtformars.co.uk/wp-content/uploads/2020/07/CustomerServiceFixed.jpg" alt="" srcset="https://builtformars.co.uk/wp-content/uploads/2020/07/CustomerServiceFixed.jpg 562w, https://builtformars.co.uk/wp-content/uploads/2020/07/CustomerServiceFixed-300x183.jpg 300w, https://builtformars.co.uk/wp-content/uploads/2020/07/CustomerServiceFixed-100x61.jpg 100w" sizes="(max-width: 562px) 100vw, 562px">								</a>
											</p>
				</div>
				</div>
				
				
				<div data-id="56418e4" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>Revolut only ever replied to <strong>20%</strong> of my live chat support messages, and don’t have a phone line.</p>
				</div>
				</div>
				
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="178d96c" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						
		</section>
				<section data-id="d2d652f" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="39958a6" data-element_type="column">
			<div>
					<div>
				
				<div data-id="bd6b341" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;none&quot;}" data-widget_type="heading.default">
				<p>
			<h4>Thank you for all your support</h4>		</p>
				</div>
						</div>
			</div>
		</div>
				
						</div>
			</div>
		</section>
				<section data-id="832fa78" data-element_type="section">
						<div>
				<div>
				<div data-id="4d4f429" data-element_type="column">
			<div>
					<div>
				<div data-id="0df1ab9" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img width="2136" height="839" src="https://builtformars.co.uk/wp-content/uploads/2020/04/ATM-light-smaller.png" alt="" srcset="https://builtformars.co.uk/wp-content/uploads/2020/04/ATM-light-smaller.png 2136w, https://builtformars.co.uk/wp-content/uploads/2020/04/ATM-light-smaller-300x118.png 300w, https://builtformars.co.uk/wp-content/uploads/2020/04/ATM-light-smaller-1024x402.png 1024w, https://builtformars.co.uk/wp-content/uploads/2020/04/ATM-light-smaller-768x302.png 768w, https://builtformars.co.uk/wp-content/uploads/2020/04/ATM-light-smaller-1536x603.png 1536w, https://builtformars.co.uk/wp-content/uploads/2020/04/ATM-light-smaller-2048x804.png 2048w, https://builtformars.co.uk/wp-content/uploads/2020/04/ATM-light-smaller-100x39.png 100w, https://builtformars.co.uk/wp-content/uploads/2020/04/ATM-light-smaller-700x275.png 700w, https://builtformars.co.uk/wp-content/uploads/2020/04/ATM-light-smaller-1600x628.png 1600w" sizes="(max-width: 2136px) 100vw, 2136px">											</p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="c7e323d" data-element_type="section">
						<div>
				<div>
				
				<div data-id="75df2de" data-element_type="column">
			<div>
					<div>
				<div data-id="f2bc236" data-element_type="widget" data-widget_type="html.default">
				<div>
			<blockquote><p lang="en" dir="ltr">No research could be crisper in explaining the sense of "Frictionless experience" and Frictionless IT that I kept talking about for years. Must-read and must-subscribe. &gt; "What the challenger banks did differently" by <a href="https://twitter.com/PeteRamsey?ref_src=twsrc%5Etfw">@PeteRamsey</a> <a href="https://t.co/zWmxpYG0LT">https://t.co/zWmxpYG0LT</a></p>— Alessandro Perilli ✪ AI￨Automation￨Cybersecurity (@giano) <a href="https://twitter.com/giano/status/1263436408745844741?ref_src=twsrc%5Etfw">May 21, 2020</a></blockquote> 		</div>
				</div>
				
				
				
				
						</div>
			</div>
		</div>
				<div data-id="9072e4a" data-element_type="column">
			<div>
					<div>
				<div data-id="c9ef61c" data-element_type="widget" data-widget_type="html.default">
				<div>
			<blockquote data-conversation="none"><p lang="en" dir="ltr">This should be required reading by every exec at traditional banks. Fantastic work</p>— Alex Barkley (@alexfintec) <a href="https://twitter.com/alexfintec/status/1264827065725059072?ref_src=twsrc%5Etfw">May 25, 2020</a></blockquote> 		</div>
				</div>
				
				
				
				
						</div>
			</div>
		</div>
				
						</div>
			</div>
		</section>
						</div>
			</div>
		</div></div>]]>
            </description>
            <link>https://builtformars.co.uk/banks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24635364</guid>
            <pubDate>Wed, 30 Sep 2020 03:15:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Raspberry Pi Touchscreen Internet Radio, Music Player and Weather Display]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24635359">thread link</a>) | @azeemarif
<br/>
September 29, 2020 | https://smarttechnotes.com/raspberry-pi-touchscreen-internet-radio | <a href="https://web.archive.org/web/*/https://smarttechnotes.com/raspberry-pi-touchscreen-internet-radio">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-42">

	

	
			<figure>
				<img width="1568" height="1118" src="https://marifnotes.files.wordpress.com/2020/08/20200831_125150-1.jpg?w=1568" alt="" loading="lazy" srcset="https://marifnotes.files.wordpress.com/2020/08/20200831_125150-1.jpg?w=1568 1568w, https://marifnotes.files.wordpress.com/2020/08/20200831_125150-1.jpg?w=150 150w, https://marifnotes.files.wordpress.com/2020/08/20200831_125150-1.jpg?w=300 300w, https://marifnotes.files.wordpress.com/2020/08/20200831_125150-1.jpg?w=768 768w, https://marifnotes.files.wordpress.com/2020/08/20200831_125150-1.jpg?w=1024 1024w, https://marifnotes.files.wordpress.com/2020/08/20200831_125150-1.jpg 1883w" sizes="(max-width: 1568px) 100vw, 1568px" data-attachment-id="140" data-permalink="https://smarttechnotes.com/2020/08/21/raspberry-pi-touchscreen-internet-radio/20200831_125150-1/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/20200831_125150-1.jpg" data-orig-size="1883,1342" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.5&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SM-G960W&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1598878310&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.3&quot;,&quot;iso&quot;:&quot;250&quot;,&quot;shutter_speed&quot;:&quot;0.028571428571429&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="20200831_125150-1" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/20200831_125150-1.jpg?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/20200831_125150-1.jpg?w=750">			</figure><!-- .post-thumbnail -->

		
	<div>
		
<p>In this post I’d like to share how to make a Raspberry Pi internet radio player with music, audio-books and podcast playback over Bluetooth. In addition to all these features, it also serves as a weather station.</p>



<figure><img data-attachment-id="45" data-permalink="https://smarttechnotes.com/20200821_114111/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/20200821_114111.jpg" data-orig-size="1874,2200" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.4&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SM-N975W&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1598010000&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.3&quot;,&quot;iso&quot;:&quot;400&quot;,&quot;shutter_speed&quot;:&quot;0.016949152542373&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="20200821_114111" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/20200821_114111.jpg?w=256" data-large-file="https://marifnotes.files.wordpress.com/2020/08/20200821_114111.jpg?w=750" src="https://marifnotes.files.wordpress.com/2020/08/20200821_114111.jpg?w=872" alt="" srcset="https://marifnotes.files.wordpress.com/2020/08/20200821_114111.jpg?w=872 872w, https://marifnotes.files.wordpress.com/2020/08/20200821_114111.jpg?w=1744 1744w, https://marifnotes.files.wordpress.com/2020/08/20200821_114111.jpg?w=128 128w, https://marifnotes.files.wordpress.com/2020/08/20200821_114111.jpg?w=256 256w, https://marifnotes.files.wordpress.com/2020/08/20200821_114111.jpg?w=768 768w" sizes="(max-width: 872px) 100vw, 872px"></figure>



<p>When fully setup, the player can be controlled using the touch screen or remotely via a web interface. It plays media on wireless Bluetooth speaker.</p>



<p>We need the following items for this project</p>



<h4>Hardware</h4>



<ul><li>Raspberry Pi<ul><li>power supply</li><li>micro SD card</li></ul></li><li>Touchscreen LCD</li><li>Raspberry Pi case fit for holding an LCD</li><li>Bluetooth speaker</li><li>for initial setup, it would be nice to have<ul><li> Keyboard and Mouse</li><li>Monitor</li></ul></li></ul>



<h4>Software</h4>



<ul><li>Raspberry Pi OS</li><li>Peppy media player</li></ul>



<p>Any Raspberry Pi board with Wifi and Bluetooth is good for this project.</p>



<figure><img data-attachment-id="49" data-permalink="https://smarttechnotes.com/maker0x4cdate2017-9-26ver4lenskan03actlar01e-y/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/img_20180411_213104.jpg" data-orig-size="3417,2197" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 2 XL&quot;,&quot;caption&quot;:&quot;Maker:0x4c,Date:2017-9-26,Ver:4,Lens:Kan03,Act:Lar01,E-Y&quot;,&quot;created_timestamp&quot;:&quot;1523482264&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.459&quot;,&quot;iso&quot;:&quot;522&quot;,&quot;shutter_speed&quot;:&quot;0.033298&quot;,&quot;title&quot;:&quot;Maker:0x4c,Date:2017-9-26,Ver:4,Lens:Kan03,Act:Lar01,E-Y&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Maker:0x4c,Date:2017-9-26,Ver:4,Lens:Kan03,Act:Lar01,E-Y" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/img_20180411_213104.jpg?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/img_20180411_213104.jpg?w=750" src="https://marifnotes.files.wordpress.com/2020/08/img_20180411_213104.jpg?w=1024" alt="" srcset="https://marifnotes.files.wordpress.com/2020/08/img_20180411_213104.jpg?w=1024 1024w, https://marifnotes.files.wordpress.com/2020/08/img_20180411_213104.jpg?w=2048 2048w, https://marifnotes.files.wordpress.com/2020/08/img_20180411_213104.jpg?w=150 150w, https://marifnotes.files.wordpress.com/2020/08/img_20180411_213104.jpg?w=300 300w, https://marifnotes.files.wordpress.com/2020/08/img_20180411_213104.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Raspberry Pi</figcaption></figure>



<p>I used a 3.5 inch touchscreen LCD from <a href="http://www.kumantech.com/kuman-35-inch-tft-lcd-display-480x320-rgb-pixels-touch-screen-monitor-for-raspberry-pi-3-2-model-b-b-a-a-module-spi-interface-with-touch-pen-sc06_p0014.html">Kuman tech</a>.</p>



<div data-carousel-extra="{&quot;blog_id&quot;:181821324,&quot;permalink&quot;:&quot;https:\/\/smarttechnotes.com\/2020\/08\/21\/raspberry-pi-touchscreen-internet-radio\/&quot;}"><figure><img data-attachment-id="53" data-permalink="https://smarttechnotes.com/samsung-camera-pictures-2/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/04170004-1.jpg" data-orig-size="2922,1793" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;4.5&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;NX3000&quot;,&quot;caption&quot;:&quot;SAMSUNG CAMERA PICTURES&quot;,&quot;created_timestamp&quot;:&quot;1524004145&quot;,&quot;copyright&quot;:&quot;Copyright 2014&quot;,&quot;focal_length&quot;:&quot;28&quot;,&quot;iso&quot;:&quot;1600&quot;,&quot;shutter_speed&quot;:&quot;0.02&quot;,&quot;title&quot;:&quot;SAMSUNG CAMERA PICTURES&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="SAMSUNG CAMERA PICTURES" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/04170004-1.jpg?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/04170004-1.jpg?w=750" src="https://marifnotes.files.wordpress.com/2020/08/04170004-1.jpg?w=1024" alt="" srcset="https://marifnotes.files.wordpress.com/2020/08/04170004-1.jpg?w=1024 1024w, https://marifnotes.files.wordpress.com/2020/08/04170004-1.jpg?w=2048 2048w, https://marifnotes.files.wordpress.com/2020/08/04170004-1.jpg?w=150 150w, https://marifnotes.files.wordpress.com/2020/08/04170004-1.jpg?w=300 300w, https://marifnotes.files.wordpress.com/2020/08/04170004-1.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Raspberry Pi and Touchscreen</figcaption></figure></div>



<div data-carousel-extra="{&quot;blog_id&quot;:181821324,&quot;permalink&quot;:&quot;https:\/\/smarttechnotes.com\/2020\/08\/21\/raspberry-pi-touchscreen-internet-radio\/&quot;}"><figure><img data-attachment-id="57" data-permalink="https://smarttechnotes.com/samsung-camera-pictures-4/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/04170002-1.jpg" data-orig-size="4769,2177" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;4.5&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;NX3000&quot;,&quot;caption&quot;:&quot;SAMSUNG CAMERA PICTURES&quot;,&quot;created_timestamp&quot;:&quot;1524004110&quot;,&quot;copyright&quot;:&quot;Copyright 2014&quot;,&quot;focal_length&quot;:&quot;28&quot;,&quot;iso&quot;:&quot;3200&quot;,&quot;shutter_speed&quot;:&quot;0.02&quot;,&quot;title&quot;:&quot;SAMSUNG CAMERA PICTURES&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="SAMSUNG CAMERA PICTURES" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/04170002-1.jpg?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/04170002-1.jpg?w=750" src="https://marifnotes.files.wordpress.com/2020/08/04170002-1.jpg?w=1024" alt="" srcset="https://marifnotes.files.wordpress.com/2020/08/04170002-1.jpg?w=1024 1024w, https://marifnotes.files.wordpress.com/2020/08/04170002-1.jpg?w=2046 2046w, https://marifnotes.files.wordpress.com/2020/08/04170002-1.jpg?w=150 150w, https://marifnotes.files.wordpress.com/2020/08/04170002-1.jpg?w=300 300w, https://marifnotes.files.wordpress.com/2020/08/04170002-1.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Raspberry Pi and Touchscreen</figcaption></figure></div>



<p>We need a case that can hold the LCD screen securely so that it does not move when using the touchscreen. I used <a href="https://www.amazon.ca/MagiDeal-Acrylic-Enclosure-Raspberry-3-5inch/dp/B07FTB1RCD">this case</a> from Amazon but you may find many others like this if you search for “Layer Acrylic Case Raspberry Pi”.</p>



<figure><img data-attachment-id="55" data-permalink="https://smarttechnotes.com/20200821_111038-1/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1.jpg" data-orig-size="3274,1753" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.4&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SM-N975W&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1598008238&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.3&quot;,&quot;iso&quot;:&quot;400&quot;,&quot;shutter_speed&quot;:&quot;0.025&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="20200821_111038-1" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1.jpg?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1.jpg?w=750" src="https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1.jpg?w=1024" alt="" srcset="https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1.jpg?w=1024 1024w, https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1.jpg?w=2048 2048w, https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1.jpg?w=150 150w, https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1.jpg?w=300 300w, https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Acrylic Case for Raspberry Pi  with 3.5 inch LCD Display</figcaption></figure>



<p>And finally, we need a speaker to play the sound. It could very well be a wired speaker that is directly connected to Raspberry Pi using the 3.5mm headphone connector or a USB port but I used a wireless Bluetooth speaker so that we I can move it around easily.</p>



<figure><img data-attachment-id="60" data-permalink="https://smarttechnotes.com/20200821_231233-1/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/20200821_231233-1.jpg" data-orig-size="3410,1688" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.5&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SM-N975W&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1598051553&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.3&quot;,&quot;iso&quot;:&quot;250&quot;,&quot;shutter_speed&quot;:&quot;0.025&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="20200821_231233-1" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/20200821_231233-1.jpg?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/20200821_231233-1.jpg?w=750" src="https://marifnotes.files.wordpress.com/2020/08/20200821_231233-1.jpg?w=1024" alt="" srcset="https://marifnotes.files.wordpress.com/2020/08/20200821_231233-1.jpg?w=1024 1024w, https://marifnotes.files.wordpress.com/2020/08/20200821_231233-1.jpg?w=2048 2048w, https://marifnotes.files.wordpress.com/2020/08/20200821_231233-1.jpg?w=150 150w, https://marifnotes.files.wordpress.com/2020/08/20200821_231233-1.jpg?w=300 300w, https://marifnotes.files.wordpress.com/2020/08/20200821_231233-1.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Bluetooth Speaker</figcaption></figure>







<h4>Initial Setup</h4>



<p>For the initial setup, connect a USB keyboard and mouse and a monitor (using HDMI cable) to the Raspberry Pi. On a computer download Raspberry Pi OS and install the image on a micro SD card.</p>



<p><a href="https://www.raspberrypi.org/downloads/raspberry-pi-os/">Raspberry Pi OS download</a></p>



<p><a href="https://www.raspberrypi.org/documentation/installation/installing-images/README.md">Installing Raspberry Pi OS on a micro SD card</a></p>



<p>After SD card is ready, insert it into Raspberry Pi board and switch the power on. Follow the instructions on the screen to complete <a href="https://projects.raspberrypi.org/en/projects/install-raspberry-pi-desktop/5">Raspberry Pi OS installation</a>. After the installation you should see Raspberry Pi desktop.</p>



<figure><img data-attachment-id="65" data-permalink="https://smarttechnotes.com/raspbian_2019-04_application_menu/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/raspbian_2019.04_application_menu.jpg" data-orig-size="1280,800" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="raspbian_2019.04_application_menu" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/raspbian_2019.04_application_menu.jpg?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/raspbian_2019.04_application_menu.jpg?w=750" src="https://marifnotes.files.wordpress.com/2020/08/raspbian_2019.04_application_menu.jpg?w=1024" alt="" srcset="https://marifnotes.files.wordpress.com/2020/08/raspbian_2019.04_application_menu.jpg?w=1024 1024w, https://marifnotes.files.wordpress.com/2020/08/raspbian_2019.04_application_menu.jpg?w=150 150w, https://marifnotes.files.wordpress.com/2020/08/raspbian_2019.04_application_menu.jpg?w=300 300w, https://marifnotes.files.wordpress.com/2020/08/raspbian_2019.04_application_menu.jpg?w=768 768w, https://marifnotes.files.wordpress.com/2020/08/raspbian_2019.04_application_menu.jpg 1280w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Raspberry Pi Desktop</figcaption></figure>



<p>Using icons on top right connect to your WiFi network and pair with your Bluetooth speaker. Play some music or a YouTube video to test that the network and Bluetooth connections are working.</p>



<p>Also, using the menu <em>“Preferences-&gt;Raspberry Pi Configuration</em>” enable SSH to be able to login to Raspberry Pi remotely from other computers.</p>



<figure><img data-attachment-id="74" data-permalink="https://smarttechnotes.com/enable-ssh-raspberry-pi/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/enable-ssh-raspberry-pi.jpg" data-orig-size="404,389" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="enable-ssh-raspberry-pi" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/enable-ssh-raspberry-pi.jpg?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/enable-ssh-raspberry-pi.jpg?w=404" src="https://marifnotes.files.wordpress.com/2020/08/enable-ssh-raspberry-pi.jpg?w=300" alt="" srcset="https://marifnotes.files.wordpress.com/2020/08/enable-ssh-raspberry-pi.jpg?w=300 300w, https://marifnotes.files.wordpress.com/2020/08/enable-ssh-raspberry-pi.jpg?w=150 150w, https://marifnotes.files.wordpress.com/2020/08/enable-ssh-raspberry-pi.jpg 404w" sizes="(max-width: 300px) 100vw, 300px"></figure>







<h5>Install Peppy media player</h5>



<p>While searching for a media player for Raspberry Pi that is suitable for a small touchscreen I came across <a href="https://github.com/project-owner/Peppy.doc/wiki">Peppy</a>. It is an open source media player that includes internet radio, audio-books and podcast playback along with the usual audio file and stream playback.  The source code for Peppy is available at GitHub <a href="https://github.com/project-owner/Peppy">https://github.com/project-owner/Peppy</a>.</p>



<p>Follow the instructions at <a href="https://github.com/project-owner/Peppy.doc/wiki/Expert">https://github.com/project-owner/Peppy.doc/wiki/Expert</a> to install Peppy except don’t change the Raspberry Pi OS Boot Option to <em>“login to console with automatic login as pi user”</em> and don’t modify <em>“/etc/rc.local”</em> yet as we want to make sure that the player works fine as a Desktop application before we switch to full screen mode.</p>



<p>I also skipped most other configuration listed on this page that I did not need at this time including <em>“shairport-sync installation”</em>, <em>“raspotify installation”</em>, <em>“Equalizer Configuration”</em>, <em>“Peppyalsa Plugin Configuration”</em>, <em>“Splash Screen Configuration”</em>, <em>“Configure LIRC and Pylirc”</em> and <em>“Rotary Encoders Configuration”</em>.</p>



<p>I did not follow <em>“Adafruit 3.5″ LCD Configuration”</em> as I used a different LCD (from Kumantech as mentioned above).</p>



<p>But I did set up Peppy to play audio via Bluetooth speaker we connected earlier by following instructions <em>“Configure Bluetooth speaker as ALSA device”</em> given at <a href="https://github.com/project-owner/Peppy.doc/wiki/Bluetooth-Devices">https://github.com/project-owner/Peppy.doc/wiki/Bluetooth-Devices</a>. Also, change the configuration in <code>/home/pi/Peppy/config.txt</code>.</p>


<pre title="">bluetooth = True
</pre>


<p>When the player is installed, open a terminal window and launch the player by running the following command (assuming that the player is installed at<code> /home/pi/Peppy</code>)</p>


<pre title="">cd /home/pi/Peppy
python3 peppy.py
</pre>


<p> This should open Peppy as a normal Desktop application. Make sure that the controls are working and Peppy is able to play an internet radio via the Bluetooth speaker. If something is not working, we need to fix it now before attempting to run Peppy full screen.</p>



<figure><img data-attachment-id="97" data-permalink="https://smarttechnotes.com/2020-08-24-181722_480x320_scrot/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/2020-08-24-181722_480x320_scrot.png" data-orig-size="480,320" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-08-24-181722_480x320_scrot" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/2020-08-24-181722_480x320_scrot.png?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/2020-08-24-181722_480x320_scrot.png?w=480" src="https://marifnotes.files.wordpress.com/2020/08/2020-08-24-181722_480x320_scrot.png?w=480" alt="" srcset="https://marifnotes.files.wordpress.com/2020/08/2020-08-24-181722_480x320_scrot.png 480w, https://marifnotes.files.wordpress.com/2020/08/2020-08-24-181722_480x320_scrot.png?w=150 150w, https://marifnotes.files.wordpress.com/2020/08/2020-08-24-181722_480x320_scrot.png?w=300 300w" sizes="(max-width: 480px) 100vw, 480px"></figure>







<h4>Making LCD touchscreen work</h4>



<p>After Peppy media player is fully working as a Desktop application, it is time to make the LCD touchscreen work.</p>



<p>Peppy player’s wiki gives instruction to configure <a href="https://github.com/project-owner/Peppy.doc/wiki/Adafruit-PiTFT">Adafruit LCD</a> and most other Raspberry Pi displays work with <a href="https://github.com/goodtft/LCD-show">goodtft </a>driver from GitHub.  But for the LCD I used I download the LCD driver from Kumantech website (go to the <a href="http://www.kumantech.com/help/documents-and-recources_h0037.html">download page</a> and select 3.5″ LCD) as none of the other drivers worked.</p>



<p>Extract the driver compressed file and run</p>


<pre title="">sudo LCD35-show
</pre>


<p> It installs a bunch of stuff and modifies <em>/boot/config.txt</em>. After the reboot the LCD touchscreen should work.</p>



<p>One thing I noticed that the picture was upside-down (the power connection was at the bottom but I wanted it at the top so that I can place the Raspberry Pi on a desk)</p>



<p>It is easy to rotate the picture by changing</p>


<pre title="">dtoverlay=tft35a
</pre>


<p>to</p>


<pre title="">dtoverlay=tft35a:rotate=270
</pre>


<p>in <em>/boot/config.txt</em> file.</p>







<h4>Starting Peppy player in fullscreen mode</h4>



<p>First we need to disable the Desktop environment starting at reboot. To do this, connect to your Raspberry Pi through SSH from a computer and run the following command after logging in</p>


<pre title="">sudo raspi-config
</pre>


<p>Select the following items in menu:</p>



<ul><li>Boot Options<br>Desktop CLI/Console Autologin To login to console with automatic login as pi user</li></ul>



<p>Installation instructions in Peppy player’s wiki suggest that if we add the following line at the end of<code> <em>/etc/rc.local</em></code> file just before <code>'exit 0'</code> line, We should get Peppy player started at reboot in the fullscreen mode.</p>


<pre title="">su pi -c 'cd /home/pi/Peppy; openvt -s -- python3 peppy.py'
</pre>


<p>It worked except that there was no touchscreen functionality. It seems that the touchscreen driver is not loaded when we try to run Peppy this way. One thing to note was that touchscreen was working in the Desktop environment in the previous step before we disabled it and decided to boot in the console mode.</p>



<p>I came up with the following workaround which is not the most elegant one but it did the job. First, I reverted the change in <code><em>/etc/rc.local</em></code> file. Then I created the <em><code>/home/pi/.xinitrc</code></em> file with the following code</p>


<pre title="">session=${1:-lxde}

case $session in
    lxde           ) exec startlxde-pi;;
    lxterm         ) exec lxterminal;;
    peppy          ) exec lxterminal -e "cd /home/pi/Peppy; python3 peppy.py";;
esac
</pre>


<p>If after booting into the console mode, the <code>startx</code> command is run with the first option <code>lxde</code> (which is also the default option), it starts Raspberry Pi OS Desktop.</p>


<pre title="">startx ~/.xinitrx lxde
</pre>


<p>The second option starts an <code>lxterminal</code> in full screen mode. Even though it is a terminal, it is a desktop terminal application, so X server is started and touchscreen driver is loaded.</p>


<pre title="">startx ~/.xinitrc lxterm
</pre>


<p> The third option starts an <code>lxterminal</code> with a command to run inside it. The command passed using the <code>'-c'</code> tells <code>lxterminal</code> to change directory to Peppy player’s installation directory and start the player from there.</p>


<pre title="">startx ~/.xinitrc peppy
</pre>


<p>If this command is added to <code>.bashrc</code> file, it will be executed automatically after every reboot (actually after every login, but we have selected to boot to console with autologin above). We just have to make sure that we don’t run this command when logging in via SSH from a remote computer.</p>


<pre title="">if [ -n "$SSH_CLIENT" ] || [ -n "$SSH_TTY" ]; then
        echo "SSH session, not starting X server."
else
        startx ~/.xinitrc peppy
fi
</pre>






<h4>Raspberry Pi Touchscreen Internet Radio, Music Player</h4>



<p>And here is it. After the reboot, Peppy player should start in full screen mode with touchscreen functionality.</p>



<figure><img data-attachment-id="104" data-permalink="https://smarttechnotes.com/20200827_143923-1/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/20200827_143923-1.jpg" data-orig-size="3121,1863" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.1&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SM-N975W&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1598539164&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;6&quot;,&quot;iso&quot;:&quot;400&quot;,&quot;shutter_speed&quot;:&quot;0.016949152542373&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="20200827_143923-1" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/20200827_143923-1.jpg?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/20200827_143923-1.jpg?w=750" src="https://marifnotes.files.wordpress.com/2020/08/20200827_143923-1.jpg?w=1024" alt="" srcset="https://marifnotes.files.wordpress.com/2020/08/20200827_143923-1.jpg?w=1024 1024w, https://marifnotes.files.wordpress.com/2020/08/20200827_143923-1.jpg?w=2048 2048w, https://marifnotes.files.wordpress.com/2020/08/20200827_143923-1.jpg?w=150 150w, https://marifnotes.files.wordpress.com/2020/08/20200827_143923-1.jpg?w=300 300w, https://marifnotes.files.wordpress.com/2020/08/20200827_143923-1.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Internet Radio</figcaption></figure>



<figure><img data-attachment-id="105" data-permalink="https://smarttechnotes.com/20200826_214143/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/20200826_214143.jpg" data-orig-size="4032,1908" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.4&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SM-N975W&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1598478103&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.3&quot;,&quot;iso&quot;:&quot;400&quot;,&quot;shutter_speed&quot;:&quot;0.0083333333333333&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="20200826_214143" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/20200826_214143.jpg?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/20200826_214143.jpg?w=750" src="https://marifnotes.files.wordpress.com/2020/08/20200826_214143.jpg?w=1024" alt="" srcset="https://marifnotes.files.wordpress.com/2020/08/20200826_214143.jpg?w=1024 1024w, https://marifnotes.files.wordpress.com/2020/08/20200826_214143.jpg?w=2048 2048w, https://marifnotes.files.wordpress.com/2020/08/20200826_214143.jpg?w=150 150w, https://marifnotes.files.wordpress.com/2020/08/20200826_214143.jpg?w=300 300w, https://marifnotes.files.wordpress.com/2020/08/20200826_214143.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Internet Radio</figcaption></figure>



<figure><img data-attachment-id="127" data-permalink="https://smarttechnotes.com/20200828_143507-1/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/20200828_143507-1.jpg" data-orig-size="1790,1141" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.1&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SM-N975W&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1598625219&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;6&quot;,&quot;iso&quot;:&quot;640&quot;,&quot;shutter_speed&quot;:&quot;0.0169&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="20200828_143507-1" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/20200828_143507-1.jpg?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/20200828_143507-1.jpg?w=750" src="https://marifnotes.files.wordpress.com/2020/08/20200828_143507-1.jpg?w=1024" alt="" srcset="https://marifnotes.files.wordpress.com/2020/08/20200828_143507-1.jpg?w=1024 1024w, https://marifnotes.files.wordpress.com/2020/08/20200828_143507-1.jpg?w=150 150w, https://marifnotes.files.wordpress.com/2020/08/20200828_143507-1.jpg?w=300 300w, https://marifnotes.files.wordpress.com/2020/08/20200828_143507-1.jpg?w=768 768w, https://marifnotes.files.wordpress.com/2020/08/20200828_143507-1.jpg 1790w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Internet Radio</figcaption></figure>


<div data-carousel-extra="{&quot;blog_id&quot;:181821324,&quot;permalink&quot;:&quot;https:\/\/smarttechnotes.com\/2020\/08\/21\/raspberry-pi-touchscreen-internet-radio\/&quot;}"><div data-carousel-extra="{&quot;blog_id&quot;:181821324,&quot;permalink&quot;:&quot;https:\/\/smarttechnotes.com\/2020\/08\/21\/raspberry-pi-touchscreen-internet-radio\/&quot;}"><div data-carousel-extra="{&quot;blog_id&quot;:181821324,&quot;permalink&quot;:&quot;https:\/\/smarttechnotes.com\/2020\/08\/21\/raspberry-pi-touchscreen-internet-radio\/&quot;}"><div data-carousel-extra="{&quot;blog_id&quot;:181821324,&quot;permalink&quot;:&quot;https:\/\/smarttechnotes.com\/2020\/08\/21\/raspberry-pi-touchscreen-internet-radio\/&quot;}"><figure><img data-attachment-id="106" data-permalink="https://smarttechnotes.com/20200827_160212_1/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/20200827_160212_1.gif" data-orig-size="490,368" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="20200827_160212_1" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/20200827_160212_1.gif?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/20200827_160212_1.gif?w=490" srcset="https://marifnotes.files.wordpress.com/2020/08/20200827_160212_1.gif?strip=info&amp;w=368 368w" alt="" data-height="368" data-id="106" data-link="https://marifnotes.wordpress.com/20200827_160212_1/" data-url="https://marifnotes.files.wordpress.com/2020/08/20200827_160212_1.gif" data-width="490" src="https://marifnotes.files.wordpress.com/2020/08/20200827_160212_1.gif"></figure></div></div></div></div>


<div data-carousel-extra="{&quot;blog_id&quot;:181821324,&quot;permalink&quot;:&quot;https:\/\/smarttechnotes.com\/2020\/08\/21\/raspberry-pi-touchscreen-internet-radio\/&quot;}"><figure><img data-attachment-id="98" data-permalink="https://smarttechnotes.com/20200821_113525/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/20200821_113525.jpg" data-orig-size="4032,1908" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.4&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SM-N975W&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1598009726&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.3&quot;,&quot;iso&quot;:&quot;200&quot;,&quot;shutter_speed&quot;:&quot;0.016949152542373&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="20200821_113525" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/20200821_113525.jpg?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/20200821_113525.jpg?w=750" src="https://marifnotes.files.wordpress.com/2020/08/20200821_113525.jpg" alt=""><figcaption>Audio book player</figcaption></figure></div>



<figure><img data-attachment-id="144" data-permalink="https://smarttechnotes.com/20200831_125037-1/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/20200831_125037-1.jpg" data-orig-size="2099,1710" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.5&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SM-G960W&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1598878183&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.3&quot;,&quot;iso&quot;:&quot;250&quot;,&quot;shutter_speed&quot;:&quot;0.027777777777778&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="20200831_125037-1" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/20200831_125037-1.jpg?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/20200831_125037-1.jpg?w=750" src="https://marifnotes.files.wordpress.com/2020/08/20200831_125037-1.jpg?w=1024" alt="" srcset="https://marifnotes.files.wordpress.com/2020/08/20200831_125037-1.jpg?w=1024 1024w, https://marifnotes.files.wordpress.com/2020/08/20200831_125037-1.jpg?w=2048 2048w, https://marifnotes.files.wordpress.com/2020/08/20200831_125037-1.jpg?w=150 150w, https://marifnotes.files.wordpress.com/2020/08/20200831_125037-1.jpg?w=300 300w, https://marifnotes.files.wordpress.com/2020/08/20200831_125037-1.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Podcast player</figcaption></figure>







<h4>Weather station</h4>



<p>Another good thing about Peppy player is that it has a <a href="https://github.com/project-owner/Peppy.doc/wiki/Configuration">WebUI for configuration</a>. It can be used to configure your current location to fetch the weather information from the internet.</p>





<p>After configuring the location, just set ‘weather’ as the screensaver and we have a weather station.</p>



<figure><img data-attachment-id="90" data-permalink="https://smarttechnotes.com/20200821_111038-1-1/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1-1.jpg" data-orig-size="3274,1753" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.4&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SM-N975W&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1598008238&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.3&quot;,&quot;iso&quot;:&quot;400&quot;,&quot;shutter_speed&quot;:&quot;0.025&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="20200821_111038-1-1" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1-1.jpg?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1-1.jpg?w=750" src="https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1-1.jpg?w=1024" alt="" srcset="https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1-1.jpg?w=1024 1024w, https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1-1.jpg?w=2048 2048w, https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1-1.jpg?w=150 150w, https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1-1.jpg?w=300 300w, https://marifnotes.files.wordpress.com/2020/08/20200821_111038-1-1.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Weather Station</figcaption></figure>



<figure><img data-attachment-id="94" data-permalink="https://smarttechnotes.com/20200821_111502/" data-orig-file="https://marifnotes.files.wordpress.com/2020/08/20200821_111502.jpg" data-orig-size="2464,1764" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.4&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SM-N975W&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1598008502&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.3&quot;,&quot;iso&quot;:&quot;200&quot;,&quot;shutter_speed&quot;:&quot;0.025641025641026&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="20200821_111502" data-image-description="" data-medium-file="https://marifnotes.files.wordpress.com/2020/08/20200821_111502.jpg?w=300" data-large-file="https://marifnotes.files.wordpress.com/2020/08/20200821_111502.jpg?w=750" src="https://marifnotes.files.wordpress.com/2020/08/20200821_111502.jpg?w=1024" alt="" srcset="https://marifnotes.files.wordpress.com/2020/08/20200821_111502.jpg?w=1024 1024w, https://marifnotes.files.wordpress.com/2020/08/20200821_111502.jpg?w=2048 2048w, https://marifnotes.files.wordpress.com/2020/08/20200821_111502.jpg?w=150 150w, https://marifnotes.files.wordpress.com/2020/08/20200821_111502.jpg?w=300 300w, https://marifnotes.files.wordpress.com/2020/08/20200821_111502.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Weather Station</figcaption></figure>



<p>And that’s it! Enjoy your new internet radio.&nbsp;</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://smarttechnotes.com/raspberry-pi-touchscreen-internet-radio</link>
            <guid isPermaLink="false">hacker-news-small-sites-24635359</guid>
            <pubDate>Wed, 30 Sep 2020 03:14:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nobody seems to give a crap about Google’s monopoly on search, not even Google]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24635322">thread link</a>) | @pcr910303
<br/>
September 29, 2020 | https://thejollyteapot.com/2020/09/29/nobody-seems-to-give-a-crap-about-google-s-monopoly-on-search-not-even-google | <a href="https://web.archive.org/web/*/https://thejollyteapot.com/2020/09/29/nobody-seems-to-give-a-crap-about-google-s-monopoly-on-search-not-even-google">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><a href="https://thejollyteapot.com/2020/09/29/nobody-seems-to-give-a-crap-about-google-s-monopoly-on-search-not-even-google">29 September 2020</a></p>
<p>Quick summary of the situation, from the <a href="https://www.android.com/choicescreen/">Choice Screen webpage on the Android website</a>:</p>
<blockquote>
<p>On August 2, 2019, following the European Commission’s July 2018 Android decision, Google announced that it would implement a choice screen for general search providers on all new Android phones and tablets shipped into the European Economic Area (<span>EEA</span>) where the Google Search app is pre-installed. This updated Help Center article describes a modified choice screen design that was developed in consultation with the European Commission.</p>
<p>The choice screen will appear during initial device setup and will feature multiple search providers, including Google. An illustrative version of the choice screen follows. Providers may vary by country. […]</p>
<p>Eligible search providers will need to fill out an application form and can bid for inclusion based on an auction. The auction process is explained in greater detail below.</p>
</blockquote>
<p>Considering how much this farce has been <a href="https://www.neowin.net/news/duckduckgo-blasts-googles-android-choice-screen-says-it-incentivizes-ads">covered</a> <a href="https://techcrunch.com/2020/07/30/googles-no-choice-screen-on-android-isnt-working-says-ecosia-querying-the-eus-approach-to-antitrust-enforcement/">already</a>, I will not repeat what <a href="https://www.businessinsider.com/google-android-choice-screen-eu-duckduckgo-2020-9?IR=T">everybody knows</a>. Instead I will just point out how Google announced the result of the auctions <a href="https://www.android.com/choicescreen-winners/">on the Android website</a>: four sentences, two footnotes, a table listing the<span></span> <span>“</span>winners” per country, a title that reads do-not-give-a-shit, and that’s it.</p>
<p>Also, I don’t think I have ever heard of — <em>check notes</em> — PrivacyWall and info.com.<span></span> <span>’</span>What are they?’, you may ask: they are search engines apparently, and they are the only two search engine options offered to Android users in France that are not Google or Bing. And yes, in case you’re wondering, <a href="https://www.youtube.com/watch?v=nfHuZ5qrYX4">Bing is still around</a>. Ecosia, DuckDuckGo, barely appear on the list.</p>
<p>If anything, this whole thing will reinforce Google’s monopoly on search. Users will see this<span></span> <span>’</span>choice screen’ and think:<span></span> <span>“</span><span>OK</span>, so two shady things I don’t know, Bing (laughs), and yep, Google. Why would they even ask me to choose?”</p>
<p>It’s like asking kids who have only ever watched the movie <em>Ratatouille</em> if they want to watch Ratatouille again, or another movie from this list: <a href="https://www.imdb.com/title/tt2120120/?ref_=fn_al_tt_1"><em>Pixels</em></a> (even the kids would know it sucks), <em><a href="https://www.imdb.com/title/tt0257778/?ref_=ttls_li_tt">The Hunchback of Notre Dame <span>II</span>: The Secret of the Bell</a></em> (you’re lucky if the kids even know about the first one), and <em><a href="https://www.imdb.com/title/tt0083630/?ref_=nv_sr_srsg_0">The Beastmaster</a></em>.</p>

          
          <p>
            <a href="https://thejollyteapot.com/tagged/technology">Technology</a>
          </p>

          
          


      

          <a href="https://thejollyteapot.com/2020/08/18/samsung-commits-to-deliver-three-years-of-android-updates-for-its-phones">
            <h5>Previous post</h5>
            <span>Samsung commits to deliver three years of Android updates for its phones</span>
            
          </a>

          <a href="https://thejollyteapot.com/2020/10/1/looking-back-at-my-short-list-of-apple-wishes-from-april">
            <h5>Next post</h5>
            <span>Looking back at my short list of Apple wishes from April</span>
          </a>

        </div></div>]]>
            </description>
            <link>https://thejollyteapot.com/2020/09/29/nobody-seems-to-give-a-crap-about-google-s-monopoly-on-search-not-even-google</link>
            <guid isPermaLink="false">hacker-news-small-sites-24635322</guid>
            <pubDate>Wed, 30 Sep 2020 03:07:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Live dashboard of every email Trump and Biden are sending]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24635143">thread link</a>) | @greggblanchard
<br/>
September 29, 2020 | https://sendview.io/trump-v-biden | <a href="https://web.archive.org/web/*/https://sendview.io/trump-v-biden">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <div>
            <!--
            <h2 style="margin-bottom: 25px;">
              <em class="fa fa-calendar"></em>
              Live Campaign Timeline
              <span>Last 50, Newest to Oldest</span>
            </h2>-->
            <div>
              <p>
                <h2>
                  <em></em>
                  Live Campaign Timeline
                  <span>Camapaigns Listed Newest to Oldest</span>
                </h2>
              </p>
              
              
            </div>
              
                                        <p>
                THURSDAY, OCT 1, 2020              </p>
                            <p><a href="https://sendview.io/s/a_Rlb26OAG8p9JSZjq" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                You + Me in LA <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  11:10pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_T0cKaYwRMfSVeX5G" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                Are you free tomorrow? <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  11:00pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_8wfpsh7CGvimO3nQ" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Become a Trump MVP <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  9:15pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_Ok52vWoDCfpXqJcA" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Your chance, Donald <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  8:13pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_nTg8lvFtqHN7rh2I" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                You, me, and President Obama tomorrow <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  7:36pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_C49HAINZvdL7qfYF" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Weâ€™ve got some just for you <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  7:10pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_F9iYc1rtlGE0ex8p" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                ðŸŒž Sunny LA ðŸŒž <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  6:13pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_FeVqHJo9mNEpId6j" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                We are in the fight of our life <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  5:10pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_986tWrmfPQL7d3TA" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Time is running out <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  3:24pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_BaW56ywqAEbDr7iP" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                President Obama and Kamala Harris want to know if you're free tomorrow <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  1:32pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_eBGadSwkztgQc6xF" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Congratulations! <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  1:28pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_1sBaJHTnCL6QMkhG" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                September 31st <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  11:46am</span>
              </a>
                                        <a href="https://sendview.io/s/a_P2Kcmzw5H38fXiB9" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                Thank you for your support <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  10:36am</span>
              </a>
                                        <a href="https://sendview.io/s/a_u7YIdQZaELOiHhWm" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Letâ€™s meet up <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  9:07am</span>
              </a>
                                        <a href="https://sendview.io/s/a_fSjtBVY9CzRmWT35" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Itâ€™s not too late <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  7:13am</span>
              </a>
                                        <a href="https://sendview.io/s/a_MYU9n5oZziDfXmy6" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Take the Official Presidential Debate Approval Poll NOW <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  3:08am</span>
              </a>
                                        <a href="https://sendview.io/s/a_okW9C2DTvq8bdcwE" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                ðŸš¨ End-of-Quarter ALERT ðŸš¨ <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  1:07am</span>
              </a>
                                        <a href="https://sendview.io/s/a_4psIDmQouE7Oyg3G" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Your 850%-MATCHING check <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  12:07am</span>
              </a></p><p>
                WEDNESDAY, SEP 30, 2020              </p>
                            <p><a href="https://sendview.io/s/a_8PVaoth0nDJNEykg" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                Will you be one of our final September donors? <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  11:23pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_RpcftUMWwi8JkxG3" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Deadline: MIDNIGHT <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  11:08pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_35UwrGOA0ezop4l8" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                We have to do this FIRST <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  10:07pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_sOn9lPbojwGCEKMu" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                FINAL THREE HOURS <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  9:07pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_g2hXH6RLT8MpJejP" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Election Day is ALMOST here <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  8:23pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_aT8wySMDbYRtKlQn" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                Joe, Kamala, Barack, Hillary, and more all emailed you <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  8:00pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_mbgOeCs2aNpLfH3w" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                We need to CRUSH our goal <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  7:38pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_uW3BVxv78zT9oUjh" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Itâ€™s now or never <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  6:52pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_cuLdqJb0gS6zPXCQ" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                ONLY 6 hours to step up <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  6:08pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_e8MqBiXOY4bt2Fzm" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                I'm worried we might fall short <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  5:42pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_g6weXC74azqjEROk" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                FINAL NOTICE <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  5:21pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_ZGMDk7Jf520IUnHE" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                We need to keep going <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  4:06pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_gGD6aAfpl1SZ2W7i" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                BIDEN WILL PACK THE COURTS <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  2:10pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_EAJO4ailPtzcrvj2" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                I'm asking personally <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  12:45pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_YRjK5yF0L6euZxVi" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                â�°â�° 12-hour deadline alert â�°â�° <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  12:00pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_UC0hbDl6nYpSAFq9" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                Please <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  10:40am</span>
              </a>
                                        <a href="https://sendview.io/s/a_i8Wxynv2m4AYKISe" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                âœ”ï¸� First Presidential Debate <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  9:09am</span>
              </a>
                                        <a href="https://sendview.io/s/a_PqzUhvEjTtuSNp3A" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                What did you think of the debate? <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  7:09am</span>
              </a>
                                        <a href="https://sendview.io/s/a_8yrCmnIS4P7ZwaMc" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Special 800%-MATCH <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  5:08am</span>
              </a>
                                        <a href="https://sendview.io/s/a_T3yfNaQluA6vPtpX" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Did you watch the debate? <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  3:05am</span>
              </a>
                                        <a href="https://sendview.io/s/a_GT7vWI6naMJZkmXc" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Iâ€™m upping the stakes <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  2:09am</span>
              </a>
                                        <a href="https://sendview.io/s/a_lnjKFNfErRepQAGg" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                800%-MATCH <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  1:09am</span>
              </a>
                                        <a href="https://sendview.io/s/a_N4Fuym97MhcG6RAx" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                I hope I made you proud <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  12:30am</span>
              </a>
                                        <a href="https://sendview.io/s/a_s1EUWeLk89dGDzp2" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                ðŸš¨ 850%-MATCH ðŸš¨ <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  12:09am</span>
              </a></p><p>
                TUESDAY, SEP 29, 2020              </p>
                            <p><a href="https://sendview.io/s/a_h8VmH9snxRl7GyJ3" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                I just stepped off stage <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  11:05pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_Yd1aZVuA8hbsSweX" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                My father is debating Joe Biden <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  10:40pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_4uZ0b1Ne9jEkwOgV" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Make it the BEST quarter EVER <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  9:28pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_HXN4R8D5sVU6hcfy" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Are you watching my father debate? <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  9:28pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_0acVqb5pgKFn89Hx" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                Are you watching? <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  9:23pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_qjEP0MOCNRruoUbi" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Bidenâ€™s handlers donâ€™t trust him <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  8:20pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_eqWpibJBZD3fPy9K" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                ðŸš¨ URGENT ðŸš¨ <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  8:07pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_xHyZ0iSg2ouGfIPz" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                Fwd: Humbly asking <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  7:44pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_avt6A7CfwVropOnG" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Your 850%-MATCHING check <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  6:52pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_Q4oPHGDvjRh50cKU" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Contribution Status: MISSING <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  6:07pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_NIur3Zh9RWkATKd0" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                No no no. <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  5:08pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_MGil0fqhCvRTB8r3" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                President Trump is asking about you <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  4:08pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_7PTYi8ajGnysXRIB" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                TODAY <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  3:08pm</span>
              </a>
                                    …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sendview.io/trump-v-biden">https://sendview.io/trump-v-biden</a></em></p>]]>
            </description>
            <link>https://sendview.io/trump-v-biden</link>
            <guid isPermaLink="false">hacker-news-small-sites-24635143</guid>
            <pubDate>Wed, 30 Sep 2020 02:25:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I tracked and analyzed 13,159 Hacker News posts. Here's what I learned]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24634991">thread link</a>) | @mellosouls
<br/>
September 29, 2020 | https://www.ankle.io/posts/hacker-news-analysis | <a href="https://web.archive.org/web/*/https://www.ankle.io/posts/hacker-news-analysis">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2 id="motivation"><a href="#motivation" aria-label="motivation permalink"></a>Motivation</h2>
<p>Hitting the front page of Hacker News is an incredible source of short-term traffic to your website or article.</p>
<p>According to this <a href="https://thehftguy.com/2017/09/26/hitting-hacker-news-front-page-how-much-traffic-do-you-get" rel="nofollow">article</a>, in 2017, being on the front page brings a sudden influx of between 10k and 30k visitors to your website/article, something many content marketers, product people, and entrepreneurs undoubtedly salivate over, including me.</p>
<p>I occasionally post to Hacker News (with random things and personal stuff) but have never reached the front page before. Therefore, I decided to dig a little deeper into the mechanics of Hacker News and the best approach to take if the sole goal is to hit the front page.</p>
<p>Obviously, a critical part of hitting the front page is submitting an interesting article which resonates with the HN audience. But beyond this, there are other factors at play—timing, title, upvotes, etc.</p>
<h2 id="methodology-a-unique-approach"><a href="#methodology-a-unique-approach" aria-label="methodology a unique approach permalink"></a>Methodology: A unique approach</h2>
<p>I am not the only person to want to know the best approach to hitting the front page. A few people have analyzed data from <a href="https://console.cloud.google.com/marketplace/details/y-combinator/hacker-news" target="_blank" rel="nofollow noopener noreferrer">Google’s Hacker News Dataset</a> on BigQuery to find the best time to submit to Hacker News.</p>
<p>The problem with this approach is that BigQuery doesn’t know how long a post spent on the front page, nor how long it was there for or what position it reached. It can only provide the total number of upvotes.</p>
<p>With this in mind, I wrote a small NodeJS script to poll Hacker News every 2 minutes. Using a Postgres database, I stored every post, user, and upvote over two weeks.</p>
<p>With this information, I compiled a list of useful information and insights below.</p>
<p>Note: To filter out posts that are either flagged or transiently featured, I set an arbitrary duration of 60+ minutes as a time requirement in the top for a post to be considered a “front page post.”</p>
<h2 id="limitations"><a href="#limitations" aria-label="limitations permalink"></a>Limitations</h2>
<p>Obviously, the lack of data (13,159 posts) and time spent collecting data (2 weeks) is the most significant limitation of my results. Nonetheless, I believe the results are still relatively useful, at least for the next few weeks or months.</p>
<h2 id="results"><a href="#results" aria-label="results permalink"></a>Results</h2>
<h3 id="basic-stats"><a href="#basic-stats" aria-label="basic stats permalink"></a>Basic stats</h3>
<ul>
<li>I tracked a total of 13,159 posts over two weeks.</li>
<li>Of these, 1,073 made the front page for more than 60 minutes.</li>
<li>That’s a hit rate of 8.15%</li>
<li>Frontpage posts stayed at the top for an average of 483.3 minutes (8 hours)</li>
<li>30% of posts reaching the front page were posted by users who posted more than once over the two weeks.</li>
</ul>
<p><strong>Takeaway:</strong> In my opinion, more posts reach the front page than expected and for longer than expected.</p>
<h3 id="types-of-posts-breakdown"><a href="#types-of-posts-breakdown" aria-label="types of posts breakdown permalink"></a>Types of posts breakdown</h3>

<h3 id="hit-rate--of-different-post-types-making-the-front-page"><a href="#hit-rate--of-different-post-types-making-the-front-page" aria-label="hit rate  of different post types making the front page permalink"></a>Hit rate % of different post types making the front page</h3>

<p><strong>Takeaway:</strong> Interestingly, “Show HN” posts make the front page by proportion very slightly less than “Links,” which goes against previous thought that “Show HN” posts perform better due to an algorithm bias. That being said, there may well be an algorithm bias, just many “Show HN” posts are simply not worth upvoting.</p>
<h3 id="when-is-the-best-day-to-post-to-hacker-news-in-2020"><a href="#when-is-the-best-day-to-post-to-hacker-news-in-2020" aria-label="when is the best day to post to hacker news in 2020 permalink"></a>When is the best day to post to Hacker News in 2020?</h3>

<p>The chart above shows that you should post on the weekend to stand the best chance of reaching the front page of Hacker News. The difference from the worst to the best day is only 3.2%, so there’s not a lot in it.</p>
<p>The weekend likely gives you a higher chance to reach the front page because fewer posts are submitted, probably due to lower traffic.</p>
<p><strong>Takeaway</strong>: If your goal is to reach the front page regardless of traffic, posting on the weekend is your best bet. However, because the difference in chance is relatively low throughout the week, posting on a more popular day might be a better risk-reward ratio based on the considerable difference in the traffic you’d likely receive.</p>
<h3 id="when-is-the-best-time-to-post-to-hacker-news-in-2020"><a href="#when-is-the-best-time-to-post-to-hacker-news-in-2020" aria-label="when is the best time to post to hacker news in 2020 permalink"></a>When is the best time to post to Hacker News in 2020?</h3>

<p>Taking a more granular look at the combined hours of all the posts submitted, the chart above highlights a much more significant difference (10.9%) between the chance of reaching the front page of Hacker News.</p>
<p>The best time to post to Hacker News is between 6 am—12 pm UTC (11 pm—5 am PDT). Again, the reason is likely because this is when the website traffic is at it’s lowest, and therefore the competition is relatively low.</p>
<p>I imagine the US is responsible for most of Hacker News’s web traffic, which lines up with the results above. Therefore, if you are posting a link for a US-specific audience to HN, it’s probably best to pick a different time like 4 pm UTC (9 am PDT), or midnight UTC (5 pm PDT).</p>
<p><strong>Takeaway:</strong> If your link requires a US-specific audience, post at 4 pm UTC (9 am PDT / 12 pm EDT), or midnight UTC (5 pm PDT). Otherwise, post between 6 am—12 pm UTC (11 pm—5 am PDT) for the best chance of reaching the front page of Hacker News.</p>
<h3 id="when-in-the-best-day-and-time-to-post-to-hacker-news-in-2020"><a href="#when-in-the-best-day-and-time-to-post-to-hacker-news-in-2020" aria-label="when in the best day and time to post to hacker news in 2020 permalink"></a>When in the best day and time to post to Hacker News in 2020?</h3>
<p>Combining both days and hours into a total weekly picture is even more evident when it is best to post. However, please note, the lack of data makes this chart vulnerable to skewed results.</p>

<p>The chart above illustrates wild fluctuations between the different hours of the week. The lowest chance of reaching the front page is 1-2%, and the highest is 18%-27%. That’s a massive difference.</p>
<p>Looking at the chart, below are generally the best days &amp; times to post to Hacker News:</p>
<ul>
<li><strong>Monday:</strong> 1 am—4 pm UTC (6 pm—9 am PDT)</li>
<li><strong>Tuesday, Wednesday &amp; Thursday:</strong> 12 am—6 am &amp; 9 am—12 pm UTC (5 pm—11 pm &amp; 2 am—5 am PDT)</li>
<li><strong>Friday:</strong> 5 am—12 pm UTC (10 pm—5 am PDT)</li>
<li><strong>Saturday:</strong> 4 am—9 am UTC (9 pm—2 am PDT)</li>
<li><strong>Sunday:</strong> 3 am—8 am &amp; 10 am—6 pm UTC (8 pm—1 am &amp; 3 am—11 am PDT)</li>
</ul>
<p>And here are the best times specifically (bear in mind these may not be the case week-in-week-out because the amount of data limits the results):</p>
<ul>
<li><strong>Monday:</strong> 12 pm UTC (5 am PDT)</li>
<li><strong>Tuesday:</strong> 9 am UTC (2 am PDT)</li>
<li><strong>Wednesday:</strong> 10 am UTC (3 am PDT)</li>
<li><strong>Thursday:</strong> 12 pm UTC (5 pm PDT)</li>
<li><strong>Friday:</strong> 8 am UTC (1 am PDT)</li>
<li><strong>Saturday:</strong> 9 am UTC (2 am PDT)</li>
<li><strong>Sunday:</strong> 5 am OR 1 pm (10 pm OR 6 am PDT)</li>
</ul>
<p><strong>Takeaway:</strong> It’s pretty clear that the best times to post on Hacker News to reach the front page are usually around 6 am UTC (11 pm PDT), 9 am UTC (2 am PDT), or 12 pm UTC (5 am PDT), when the US is asleep.</p>
<p>However, given that 8 hours is the average time spent on the front page, it’s probably best to post at 12 pm UTC on Monday, Thursday, Saturday or Sunday to maximize traffic for when the US wakes up.</p>
<h3 id="how-many-votes-does-a-post-need-to-reach-the-front-page-of-hacker-news-in-2020"><a href="#how-many-votes-does-a-post-need-to-reach-the-front-page-of-hacker-news-in-2020" aria-label="how many votes does a post need to reach the front page of hacker news in 2020 permalink"></a>How many votes does a post need to reach the front page of Hacker News in 2020?</h3>
<p>5.22 is the average number of votes a post needed within an average time of 27.1 minutes to reach the front page for the first time.</p>
<p>Below is a chart of box plots to illustrate the variation of votes required over 24 hours.</p>

<p>Interestingly, this graph clearly shows every post, regardless of time, required at least three upvotes, and for 75% of posts, they never needed more than eight votes to reach the front page of Hacker News.</p>
<p>Expectedly, the range of upvotes required is lower for the first half of the day than the second half, roughly matching up to the timings above.</p>
<p>In some cases, posts required a lot more votes to reach the front page. Presumably, because either the time it took to get these votes was over more time, or there was a lot of competition.</p>
<p><strong>Takeaway:</strong> The votes required to be seen on the front page is relatively small. For the best chance of getting on the front page, you’ll need between 4-6 votes in about 30 minutes, posting in the first half of the day (12 am—12pm UTC).</p>
<h3 id="how-much-karma-do-you-need-to-reach-the-front-page-of-hacker-news-in-2020"><a href="#how-much-karma-do-you-need-to-reach-the-front-page-of-hacker-news-in-2020" aria-label="how much karma do you need to reach the front page of hacker news in 2020 permalink"></a>How much karma do you need to reach the front page of Hacker News in 2020?</h3>
<p>Finally, I thought it would be interesting to see the relationship between karma and reaching the front page of Hacker News.</p>
<p>This first pie chart demonstrates the proportion of posts being posted by users with varying levels of karma.</p>

<p>Surprisingly, over 50% of posts are submitted by users with over 1,000 karma points. However, the largest single segment is by users with little to no karma.</p>

<p>The chart above shows that newer users (0-50 karma) make the front page proportionally less than more experienced users. Interestingly, really experienced users (over 10,000 karma) reached the front page significantly more than experienced users.</p>
<p><strong>Takeaway:</strong> It’s hard to say whether karma has anything to do with rankings. Likely, users with more karma are just better at posting content that resonates with the Hacker News audience.</p></div></div>]]>
            </description>
            <link>https://www.ankle.io/posts/hacker-news-analysis</link>
            <guid isPermaLink="false">hacker-news-small-sites-24634991</guid>
            <pubDate>Wed, 30 Sep 2020 01:43:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Guima Cloud – TLA+ Online Simple REPL]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24634705">thread link</a>) | @pfeodrippe
<br/>
September 29, 2020 | https://guima.cloud/editor?state=ezpibG9jay9ibG9ja3MgW3s6YmxvY2sucmVwbC9jb2RlICIoKiA8LS0gQmVnaW5uaW5nIG9mIGEgY29tbWVudGFyeS5cbiAgICBcbiAgSGksIHRoaXMgaXMgeW91ciBvbmxpbmUgVExBKyBSRVBMIChub24tb2ZpY2lhbCksXG4gIHdlbGNvbWUgby9cbiAgIFxuICBVc2UgQ1RSTCtFTlRFUiB0byBldmFsIHRoZSBSRVBMIGNvZGUsXG4gIEFMVCtFTlRFUiB0byBjcmVhdGUgYSBuZXcgUkVQTCBibG9jay4uLiBhbmQgdGhhdCBpcyBhbGwuXG4gICAgXG4gIFNlZSByZXN1bHQgYXQgdGhlIHJpZ2h0IG9mIHRoZSBibG9jay5cbiAgICBcbiAgU2hhcmUgd2l0aCB5b3VyIGZyaW5kIHVzaW5nIHRoZSBcIlNoYXJlXCIgYnV0dG9uIGF0IHRoZSB0b3AgKHRoZSB1cmxcbiAgaXMgY29wcGllZCB0byB5b3VyIGNsaXBib2FyZCkuXG4gICAgXG4gIFRoaXMgaXMgYSB2ZXJ5IHJvdWdoIGV4cGVyaW1lbnQsIGhhdmUgZnVuLCBzaGFyZSBrbm93bGVkZ2UuXG4gICAgXG4gIFdlIGxldmVyYWdlIFwiaHR0cHM6Ly9naXRodWIuY29tL3RsYXBsdXMvUGx1c1B5XCIgdG8gcnVuIHRoZSBjb2RlLCBcbiAgYXdlc29tZSBwcm9qZWN0ISEgXG4gIFxuICBTZWUgXCJodHRwczovL2xlYXJudGxhLmNvbVwiIHRvIGxlYXJuIFRMQSsgc3ludGF4LlxuICAgIFxuICBIZWF2aWx5IGluc3BpcmVkICh5b3UgY291bGQgc2F5IGNvcGllZCkgYnkgXCJodHRwczovL3d3dy5tYXJpYS5jbG91ZC9cIiA9RFxuICBcbiAgRW5kIG9mIGEgY29tbWVudGFyeS4gLS0+ICopIn0gezpibG9jay5yZXBsL2NvZGUgIigqIEEgc3VtICopXG4xICsgNCJ9IHs6YmxvY2sucmVwbC9jb2RlICIoKiBDcmVhdGVzIGEgc2V0IHNxdWFyaW5nIGEgbnVtYmVyLCB3aGVyZSB0aGlzIG51bWJlciBpc1xuICAgYSBlbGVtZW50IG9mIHRoZSBzZXQgezEsIDJ9ICopXG57eCAqIHggOiB4IFxcaW4gezEsIDJ9fSJ9IHs6YmxvY2sucmVwbC9jb2RlICIoKiBDb25jYXQgbGlzdCAqKVxuPDwgMSA+PiBcXG8gPDwgMiwgMyA+PiJ9IHs6YmxvY2sucmVwbC9jb2RlICIoKiBUaGlzIHdpbGwgcmFpc2UgYW4gZXJyb3IsIHNlZSBzb2x1dGlvbiBhdCB0aGUgbmV4dCBibG9jayAqKVxuU29tZXRoaW5nID09IDJcbjEgKyBTb21ldGhpbmcifSB7OmJsb2NrLnJlcGwvY29kZSAiKCogRm9yIG11bHRpbGluZSBibG9ja3MsIHVzZSA0IC0gLSAtIC0gKilcblNvbWV0aGluZyA9PSAyXG4tLS0tXG4xICsgU29tZXRoaW5nIn1dfQ== | <a href="https://web.archive.org/web/*/https://guima.cloud/editor?state=ezpibG9jay9ibG9ja3MgW3s6YmxvY2sucmVwbC9jb2RlICIoKiA8LS0gQmVnaW5uaW5nIG9mIGEgY29tbWVudGFyeS5cbiAgICBcbiAgSGksIHRoaXMgaXMgeW91ciBvbmxpbmUgVExBKyBSRVBMIChub24tb2ZpY2lhbCksXG4gIHdlbGNvbWUgby9cbiAgIFxuICBVc2UgQ1RSTCtFTlRFUiB0byBldmFsIHRoZSBSRVBMIGNvZGUsXG4gIEFMVCtFTlRFUiB0byBjcmVhdGUgYSBuZXcgUkVQTCBibG9jay4uLiBhbmQgdGhhdCBpcyBhbGwuXG4gICAgXG4gIFNlZSByZXN1bHQgYXQgdGhlIHJpZ2h0IG9mIHRoZSBibG9jay5cbiAgICBcbiAgU2hhcmUgd2l0aCB5b3VyIGZyaW5kIHVzaW5nIHRoZSBcIlNoYXJlXCIgYnV0dG9uIGF0IHRoZSB0b3AgKHRoZSB1cmxcbiAgaXMgY29wcGllZCB0byB5b3VyIGNsaXBib2FyZCkuXG4gICAgXG4gIFRoaXMgaXMgYSB2ZXJ5IHJvdWdoIGV4cGVyaW1lbnQsIGhhdmUgZnVuLCBzaGFyZSBrbm93bGVkZ2UuXG4gICAgXG4gIFdlIGxldmVyYWdlIFwiaHR0cHM6Ly9naXRodWIuY29tL3RsYXBsdXMvUGx1c1B5XCIgdG8gcnVuIHRoZSBjb2RlLCBcbiAgYXdlc29tZSBwcm9qZWN0ISEgXG4gIFxuICBTZWUgXCJodHRwczovL2xlYXJudGxhLmNvbVwiIHRvIGxlYXJuIFRMQSsgc3ludGF4LlxuICAgIFxuICBIZWF2aWx5IGluc3BpcmVkICh5b3UgY291bGQgc2F5IGNvcGllZCkgYnkgXCJodHRwczovL3d3dy5tYXJpYS5jbG91ZC9cIiA9RFxuICBcbiAgRW5kIG9mIGEgY29tbWVudGFyeS4gLS0+ICopIn0gezpibG9jay5yZXBsL2NvZGUgIigqIEEgc3VtICopXG4xICsgNCJ9IHs6YmxvY2sucmVwbC9jb2RlICIoKiBDcmVhdGVzIGEgc2V0IHNxdWFyaW5nIGEgbnVtYmVyLCB3aGVyZSB0aGlzIG51bWJlciBpc1xuICAgYSBlbGVtZW50IG9mIHRoZSBzZXQgezEsIDJ9ICopXG57eCAqIHggOiB4IFxcaW4gezEsIDJ9fSJ9IHs6YmxvY2sucmVwbC9jb2RlICIoKiBDb25jYXQgbGlzdCAqKVxuPDwgMSA+PiBcXG8gPDwgMiwgMyA+PiJ9IHs6YmxvY2sucmVwbC9jb2RlICIoKiBUaGlzIHdpbGwgcmFpc2UgYW4gZXJyb3IsIHNlZSBzb2x1dGlvbiBhdCB0aGUgbmV4dCBibG9jayAqKVxuU29tZXRoaW5nID09IDJcbjEgKyBTb21ldGhpbmcifSB7OmJsb2NrLnJlcGwvY29kZSAiKCogRm9yIG11bHRpbGluZSBibG9ja3MsIHVzZSA0IC0gLSAtIC0gKilcblNvbWV0aGluZyA9PSAyXG4tLS0tXG4xICsgU29tZXRoaW5nIn1dfQ==">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://guima.cloud/editor?state=ezpibG9jay9ibG9ja3MgW3s6YmxvY2sucmVwbC9jb2RlICIoKiA8LS0gQmVnaW5uaW5nIG9mIGEgY29tbWVudGFyeS5cbiAgICBcbiAgSGksIHRoaXMgaXMgeW91ciBvbmxpbmUgVExBKyBSRVBMIChub24tb2ZpY2lhbCksXG4gIHdlbGNvbWUgby9cbiAgIFxuICBVc2UgQ1RSTCtFTlRFUiB0byBldmFsIHRoZSBSRVBMIGNvZGUsXG4gIEFMVCtFTlRFUiB0byBjcmVhdGUgYSBuZXcgUkVQTCBibG9jay4uLiBhbmQgdGhhdCBpcyBhbGwuXG4gICAgXG4gIFNlZSByZXN1bHQgYXQgdGhlIHJpZ2h0IG9mIHRoZSBibG9jay5cbiAgICBcbiAgU2hhcmUgd2l0aCB5b3VyIGZyaW5kIHVzaW5nIHRoZSBcIlNoYXJlXCIgYnV0dG9uIGF0IHRoZSB0b3AgKHRoZSB1cmxcbiAgaXMgY29wcGllZCB0byB5b3VyIGNsaXBib2FyZCkuXG4gICAgXG4gIFRoaXMgaXMgYSB2ZXJ5IHJvdWdoIGV4cGVyaW1lbnQsIGhhdmUgZnVuLCBzaGFyZSBrbm93bGVkZ2UuXG4gICAgXG4gIFdlIGxldmVyYWdlIFwiaHR0cHM6Ly9naXRodWIuY29tL3RsYXBsdXMvUGx1c1B5XCIgdG8gcnVuIHRoZSBjb2RlLCBcbiAgYXdlc29tZSBwcm9qZWN0ISEgXG4gIFxuICBTZWUgXCJodHRwczovL2xlYXJudGxhLmNvbVwiIHRvIGxlYXJuIFRMQSsgc3ludGF4LlxuICAgIFxuICBIZWF2aWx5IGluc3BpcmVkICh5b3UgY291bGQgc2F5IGNvcGllZCkgYnkgXCJodHRwczovL3d3dy5tYXJpYS5jbG91ZC9cIiA9RFxuICBcbiAgRW5kIG9mIGEgY29tbWVudGFyeS4gLS0+ICopIn0gezpibG9jay5yZXBsL2NvZGUgIigqIEEgc3VtICopXG4xICsgNCJ9IHs6YmxvY2sucmVwbC9jb2RlICIoKiBDcmVhdGVzIGEgc2V0IHNxdWFyaW5nIGEgbnVtYmVyLCB3aGVyZSB0aGlzIG51bWJlciBpc1xuICAgYSBlbGVtZW50IG9mIHRoZSBzZXQgezEsIDJ9ICopXG57eCAqIHggOiB4IFxcaW4gezEsIDJ9fSJ9IHs6YmxvY2sucmVwbC9jb2RlICIoKiBDb25jYXQgbGlzdCAqKVxuPDwgMSA+PiBcXG8gPDwgMiwgMyA+PiJ9IHs6YmxvY2sucmVwbC9jb2RlICIoKiBUaGlzIHdpbGwgcmFpc2UgYW4gZXJyb3IsIHNlZSBzb2x1dGlvbiBhdCB0aGUgbmV4dCBibG9jayAqKVxuU29tZXRoaW5nID09IDJcbjEgKyBTb21ldGhpbmcifSB7OmJsb2NrLnJlcGwvY29kZSAiKCogRm9yIG11bHRpbGluZSBibG9ja3MsIHVzZSA0IC0gLSAtIC0gKilcblNvbWV0aGluZyA9PSAyXG4tLS0tXG4xICsgU29tZXRoaW5nIn1dfQ==</link>
            <guid isPermaLink="false">hacker-news-small-sites-24634705</guid>
            <pubDate>Wed, 30 Sep 2020 00:42:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Presentation on the noa voxel game engine, made and presented in-engine (2015)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24634564">thread link</a>) | @trynewideas
<br/>
September 29, 2020 | http://andyhall.github.io/noa-lt/ | <a href="https://web.archive.org/web/*/http://andyhall.github.io/noa-lt/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="slideBox">
      
      
      <div id="intro1">
        <p>Voxels in V8</p>
        <div><p>
          To start, click and allow pointer lock.
          </p><p>Slides thataway! → 
        </p></div>
        <p>Andy Hall
          <br>2015.7.16
        </p>
      </div>
      
      
      
      <div id="intro2">
        <p>
          Using this presentation:
        </p>
        <div>
          <p>
            move around:<br>
            invert mouse:<br>
            destroy block:<br>
            place block:<br> 
            pick block:<br> 
            camera zoom:<br> 
            jump:<br> 
            jet pack:<br>
            pause:
          </p>
          <p><code>WASD</code>, arrows
            <br> <code>I</code>
            <br> LMB, tap
            <br> <code>E</code>, RMB
            <br> <code>Q</code>, middle mouse
            <br> <code>F</code>, scroll
            <br> <code>space</code>
            <br> <code>R</code>
            <br> <code>P</code>
          </p>
        </div>
        <p>
          (mobile users: sorry lol)
        </p>
      </div>

      <div id="intro3">
        <p>
          About me:
        </p>
        <p><img src="http://andyhall.github.io/noa-lt/pics/profile.png"></p><p><span>
            @fenomas
          </span>
          <br> free gamedev, sometime technical evangelist
          <br> github/andyhall
          <br> aphall.com
        </p>
      </div>



      <div id="voxel1">
        <p>
          Voxels - definition
        </p>
        <div><p>
          tl;dr:
          </p><p>
            Ever seen Minecraft? 
            <br> Yeah those.
          </p>
        </div>
      </div>

      <div id="voxel2">
        <p>
          Voxels - proper definition
        </p>
        <p>
            Rasterized 3D data.
          </p>
        <p>
          Colloquially, if pixels represent
          the rasterization of 2D data,
          voxels are the 3D equivalent.
        </p>
        <p>
          (Hence "voxel": volumetric pixel)
        </p>
      </div>

      <div id="voxel3">
        <p><img src="http://andyhall.github.io/noa-lt/pics/sampling.png"></p><p>
          Conceptually, voxels are a <i>sampling</i> over some 3D space,
          just as pixels in a bitmap are samples of 
          some 2D data (vector graphics, photos, etc).
        </p>
        <p>
          (Note: click this block for the 
          <i>amazing</i> webGL demo <br>I stole that image from)
        </p>
        <!-- note to any semantic purists viewing source: -->
        <!-- Those <i> tags are just my way of saying "howdy!" <3 -->
      </div>

      <div id="voxel4">
        <p>
          Note: nothing (per se) to do with gaming!
        </p>
        <p><img src="http://andyhall.github.io/noa-lt/pics/ct_scan.jpg"></p><p>
          (CT scan data)
        </p>
      </div>




      <div id="game1">
        <p>
          Voxels and Gaming
        </p>
        <p><img src="http://andyhall.github.io/noa-lt/pics/Comanche_1992.png"></p><p>
          Comanche, 1992
        </p>
        <p>
          (Click: list of games with voxels)
        </p>
      </div>

      <div id="game2">
        <p>
          Voxel advantages
        </p>
        <p><img src="http://andyhall.github.io/noa-lt/pics/Shogi_Ban_Koma.jpg"></p><p>
          Provides game with easily grasped structure -
          <br>
          Equivalent to grids in 2D games
        </p>
      </div>

      <div id="game3">
        <p>
          Conceptually easy to work with
        </p>
        <div>
          <ul>
            <li>Technical tradeoffs (e.g. CPU vs memory) 
              largely similar to vectors/bitmaps</li>
            <li>Some hard things become easy 
              (raycasting, collision tests..)</li>
            <li>(Of course some easy things become hard..)</li>
          </ul>
        </div>
      </div>

      <div id="game4">
        <p>
          Voxel advantages
        </p>
        <p>
            Mutable worlds for free! (ish)
          </p>
        <p>
          (click: anywhere but here, yo)
        </p>
      </div>

      <div id="game5">
        <p>
          World-affecting game rules
        </p>
        <p><img src="http://andyhall.github.io/noa-lt/pics/Gospers_glider_gun.gif"></p><p>
          c.f. "Emergent gameplay"
        </p>
        <div>
          <p>
            Note:
          </p>
          <p><code>"3"</code> to place a Conway Block
            <br><code>"4"</code> to stop/start simulation
            <br><span>(click: explanation)</span>
          </p>
        </div>
      </div>

      <div id="game6">
        <p>
          Note: not just for rendering!
        </p>
        <p>
          Voxels are often useful behind the scenes 
          regardless of how a game looks
          (e.g. for physics simulation).
        </p>
        <p>
          Conceptually: 3D games should use voxels wherever 
          a 2D game would use a grid.
        </p>
      </div>




      <div id="render1">
        <p>
          Rendering Voxels
        </p>
        <p>
            GPUs do not grok voxels!
          </p>
        <p>
          In general a conversion step ("meshing")
          is necessary to convert voxels into 
          stuff that GPUs understand
          (vertex lists, normals, etc).
        </p>
        <p>
          Here are three approaches:
        </p>
      </div>

      <div id="render2">
        <p>
          Naive Meshing
        </p>
        <p><img src="http://andyhall.github.io/noa-lt/pics/doob.png"></p><p>
          (click: mrdoob's voxel demo)
        </p>
        <p>
          Create one cubic mesh per voxel
        </p>
        <p>
          Problems: poly counts, draw calls
        </p>
      </div>

      <div id="render3">
        <p>
          Culled Meshing
        </p>
        <p><img src="http://andyhall.github.io/noa-lt/pics/culled.png"></p><p>
          Merge voxels into one large mesh, 
          <br>omitting faces between adjacent voxels.
        </p>
        <p>
          Result: fewer draw calls, still a lot of polys
        </p>
      </div>

      <div id="render4">
        <p>
          "Greedy Meshing"
        </p>
        <p><img src="http://andyhall.github.io/noa-lt/pics/greedy.png"></p><p>
          Scan across voxel slices, merging faces of 
          adjacent voxels (of the same value).
        </p>
        <p>
          Credit: all-around genius 
          <span>Mikola Lysenko</span>
        </p>
        <p>
          (click: algo explanation + live demo)
        </p>
      </div>

      <div id="render5">
        <p>
          Chunking
        </p>
        <p><img src="http://andyhall.github.io/noa-lt/pics/chunk.png"></p><p>
          Necessary tradeoff for large worlds:
          <br> faster meshing, more draw calls.
        </p>
        <p>
          Minecraft chunks: 16x16x256 (divided vertically)
          <br>This demo: arbitrary (32x32x32 at the moment)
        </p>
      </div>

      <div id="render6">
        <p>
          Ambient Occlusion
        </p>
        <p><img src="http://andyhall.github.io/noa-lt/pics/ao.jpg"></p><p>
          Comparatively simple for voxels, 
          <br> and greatly improves visuals
        </p>
        <p><span>Click: toggle AO in this demo</span>
          <br>(then place a block to trigger meshing)
        </p>
      </div>

      <div id="render7">
        <p>
          Note: Voxels needn't be blocks!
        </p>
        <div>
          <div>
            <p><img src="http://andyhall.github.io/noa-lt/pics/voxel-quest.png">
            </p>
            <p>
              Voxel Quest
            </p>
            <p>
              (click: it's beautiful)
            </p>
          </div>
          <div>
            <p><img src="http://andyhall.github.io/noa-lt/pics/ct.jpg">
            </p>
            <p>
              CT scan data
            </p>
            <p>
              (google "marching squares")
            </p>
          </div>
        </div>
      </div>

      <div id="render8">
        <p>
          In fact...
        </p>
        <p><img src="http://andyhall.github.io/noa-lt/pics/crooked.png"></p>
      </div>



      <div id="world1">
        <p>
          World generation
        </p>
        <p>
          Driven deterministically by 
          noise (Perlin, simplex) and hashing.
        </p>
        <p>
          In this demo:
        </p>
        <p>
          2D noise: height map
          <br> 3D noise: clouds
          <br> Hashing: tree/flower placement
        </p>
        <p>
          (click: my homemade n-dimensional hash!)
        </p>
      </div>

      <div id="world2">
        <p>
          Other world algorithms
        </p>
        <p>
          Many voxel algos extend naturally from 
          2D cases (often heavily researched).
        </p>
        <div>
          <ul>
            <li>Collision tests: simple grid check</li>
            <li>Raycasting: equivalent to line rasterization (e.g. Bresenham)</li>
            <li>Physics: had to roll my own, but easier than 3D</li>
          </ul>
        </div>
      </div>




      <div id="noa1">
        <div><p>
          noa (this engine)
          </p><p>
           And how I built it
        </p></div>
      </div>

      <div id="noa2">
        <p>
          Dev stack:
        </p>
        <p><img src="http://andyhall.github.io/noa-lt/pics/browserify_with_hat.png"></p><p>
          node | npm | browserify | beefy
        </p>
        <p>
          (this slide is out of date, <br>I use webpack now..)
        </p>
      </div>

      <div id="noa3">
        <p>
          Why roll a new engine?
        </p>
        <p>
          I started trying to use 
          <span>voxel.js</span>
        </p>
        <p><img src="http://andyhall.github.io/noa-lt/pics/voxeljs.png"></p><div>
          <p>
            Pros:
            <br> Tons of great code
            <br> Extremely modular
          </p>
          <p>
            Cons:
            <br> Massively coupled
            <br> Dependency hell
            <br> Renders on bare metal
          </p>
        </div>
      </div>

      <div id="noa4">
        <p>
          noa's approach:
        </p>
        <div>
          <ul>
            <li>Reuse code from voxel.js where feasible 
              <br> (raycasting, meshing..)</li>
            <li>Otherwise written from scratch 
              <br> (physics, rendering, controls, AO..)</li>
            <li><span>Babylon.js for rendering (click)</span></li>
          </ul>
        </div>
      </div>

      <div id="noa5">
        <p>
          State of the project
        </p>
        <div>
          <ul>
            <li>Works(?), performant(?) </li>
            <li>No docs, all APIs in flux</li>
            <li><span>Features: see testbed app (click)</span></li>
            <li>Collaboration welcome, drop me a mail/issue/etc</li>
          </ul>
        </div>
      </div>



      <div id="thoughts1">
        <p>
          "Is [HTML/JS] really [ready/fast enough] for gaming yet?"
        </p>
        <p>
          My thoughts after 5 months:
        </p>
      </div>
      
      
      <div id="thoughts2">
        <p>
          Mainly depends on how broad your scope is
        </p>
        <div>
          <ul>
            <li>Targeting one version of one browser makes for an easy life ;)</li>
            <li>Modern JS is a solid dev platform, if you modularize responsibly</li>
            <li>The more you use the DOM, the more performance will vary across browsers</li>
            <li>Mobile: what's that? Does it taste good?</li>
          </ul>
        </div>
      </div>


      <div id="thoughts3">
        <p>
          Performance in V8
        </p>
        <div>
          <ul>
            <li>V8 is very fast, but temperamental</li>
            <li>Getting great performance is still ~50% black magic</li>
          </ul>
        </div>
      </div>


      <div id="thoughts4">
        <p>
          Key takeaway #1:
        </p>
        <div>
          <ul>
            <li>Don't waste time guessing what will perform well in V8 - it can't be done</li>
            <li>Master the dev tools instead</li>
            <li><strong>Profile</strong></li>
          </ul>
        </div>
      </div>

      <div id="thoughts5">
        <p>
          Key takeaway #2:
        </p>
        <div>
          <ul>
            <li><strong>Deopts</strong> murder performance!</li>
            <li>They can occur unpredictably, and for bizarre reasons.</li>
            <li>When all else fails: <br><code>chrome --js-flags = "--trace-deopt"</code></li>
          </ul>
        </div>
      </div>



      <div id="thanks">
        <p>
          Thanks!
        </p>
        <p>
          @fenomas
          <br>
          <span>github.com/andyhall</span>
        </p>
      </div>

      
      
      
      
      
    </div></div>]]>
            </description>
            <link>http://andyhall.github.io/noa-lt/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24634564</guid>
            <pubDate>Wed, 30 Sep 2020 00:17:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Bad Steak Led to a $4B Organization]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24634465">thread link</a>) | @aml183
<br/>
September 29, 2020 | https://www.arilewis.com/aris-posts/how-a-bad-steak-led-to-a-4b-organization | <a href="https://web.archive.org/web/*/https://www.arilewis.com/aris-posts/how-a-bad-steak-led-to-a-4b-organization">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-bc7fa26ba5a57652a526"><div><p>In 1975, Harold Etling went to eat a steak. Harold, a lifelong rancher, left the meal disappointed. His steak didn't meet his expectations. Harold decided to do something about it. He approached the American Angus Association. In January 1978 in West Salem, Ohio, the brand <a href="https://www.certifiedangusbeef.com/">Certified Angus Beef</a> (CAB) launched.</p><p>In the mid-‘70s the USDA lowered their standards for beef. Less quality control over beef meant that the quality could be lessened. If consumers experienced a wide range of tastes when eating beef it could lead to lower consumer demand. This was the issue that Harold Ettling faced.</p><p>The establishment of the Certified Angus Beef brand would solve this. The American Angus Association would manage the brand. Every piece of meat would need to go through rigorous process.</p><p>The program sold its first piece of beef in October 1978. Right after this sale, the USDA canceled the program. They believed the program was misleading. CAB branded beef sold at a premium, which the USDA thought was unfair marketing.</p><p>Mick Colvin, an employee of the American Angus Association, fought the USDA and won. On April 2nd, 1979, the USDA re-approved the brand. In order to be a CAB, you needed to meet <a href="https://davesjubilee.com/departments/meat">10 standards</a>:</p><ul data-rte-list="default"><li><p>Modest or higher marbling – for the taste it ensures customer satisfaction</p></li><li><p>Medium to fine marbling texture – the white “flecks of flavor” in the beef that ensure consistent flavor and juiciness in every bite</p></li><li><p>“A” Maturity – the youngest classification of product delivers superior color, texture and tenderness</p></li><li><p>10- to 16-square-inch ribeye area</p></li><li><p>Less than 1,000-pound carcass weight</p></li><li><p>Less than 1 inch external fat</p></li><li><p>Superior beef muscling – restricts the influence of less-tender dairy cattle</p></li><li><p>Practically free of capillary rupture – ensures the most visually appealing steak</p></li><li><p>No dark cutters – ensures the most visually appealing steak</p></li><li><p>No neck hump exceeding 2 inches – safeguards against cattle with variability in tenderness</p></li></ul><p>Independent USDA graders determine if the beef meets the proper requirements. In the first few years, the CAB grew slowly. <a href="https://www.google.com/search?ei=k5RzX_XbDIyF9PwPy5ux2AQ&amp;gs_lcp=CgZwc3ktYWIQAzIECAAQDTIECAAQDTIECAAQDTIECAAQDTIECAAQDTIKCC4QxwEQrwEQDTIECAAQDTIGCAAQDRAeMgYIABANEB4yBggAEA0QHjoECAAQRzoFCAAQkQI6CwguELEDEMcBEKMCOggILhCxAxCDAToFCAAQsQM6CAgAELEDEIMBOggILhDHARCjAjoCCAA6BAgAEEM6CgguEMcBEKMCEEM6AgguOgcILhCxAxBDOhAILhCxAxCDARDHARCjAhBDOgcILhBDEJMCOgcIABCxAxBDOgQILhBDOgUILhCxAzoHCC4QChCTAjoECAAQCjoFCC4QkwI6BAguEAo6BggAEBYQHlCIGFjMIWD-ImgAcAN4AYABqQGIAcIKkgEEMS4xMJgBAKABAaoBB2d3cy13aXrIAQXAAQE&amp;oq=mick%20colvin&amp;q=mick%20colvin&amp;sclient=psy-ab&amp;sxsrf=ALeKk01A4an2KEZkMMf_XL6Jk0C9hAxEeA%3A1601410195216&amp;uact=5&amp;ved=0ahUKEwi18czulY_sAhWMAp0JHctNDEsQ4dUDCA0">But by, 1983, the program was profitable</a>. The CAB had a leg up on burgeoning competitors. Its tacit endorsement from the USDA was heavily promoted.</p><p>In 2012, <a href="http://www.angus.org/pub/newsroom/releases/101812_SixthRecordSalesYearforTopQualityBeefBrand.html">CAB's growth</a> was far and away above any of its competition:</p><ul data-rte-list="default"><li><p>16,000 licensed partners</p></li><li><p>$4B in annual consumer sales worldwide</p></li><li><p>10% increase year over year wholesale value of a carcass</p></li></ul><p>The last stat is the most impressive. In 2011, the price of CAB carcass was $180.99/cwt. In 2012, the price was $199.71. This proved that consumers <a href="https://www.beefmagazine.com/blog/cab-nolan-ryan-prove-quality-consistency-pay">cared about the CAB brand</a>. Even with a national cattle shortage in 2012, consumers were willing to pay a premium to buy CAB over non CAB beef. Branding really does work.</p><p>It's a significant reason why consumers equate the word Angus with a higher-quality beef. It's also the reason why many associations have started competing certification programs.</p><p>Take McDonald's for an example. Over the past decade, McDonald's has advertised their hamburgers as <a href="https://www.thestreet.com/personal-finance/credit-cards/should-you-pay-extra-angus-beef-12803768">"made with 100% Angus beef"</a>. However, Angus beef isn't always certified Angus beef. If I wasn't writing this article, I wouldn't have known that. How would the average consumer know that?The CAB says that McDonald's burgers aren't CAB. They issued a statement, "Certified Angus Beef does not go to fast-food restaurants. It’s at the higher-end restaurants,” That's been a defining differentiator of CAB since it's inception: premium beef.</p><p>CAB has positioned the company for a middle-upper class audience. Its customer cares about the quality of its beef, has disposable income and is typically white-collar.</p><p>CAB <a href="https://www.hartinc.com/work/case-studies/cab">hired PR firm</a>, Hart, to ensure it's brand wasn't diluted further by fast-food restaurants. Its goal was simple: remind consumers that CAB was the finest premium beef on the market. They used paid, owned and earned media to tell the story. It featured ranchers working from early morning to late evening raising cattle.</p><p>The campaign worked: </p><ul data-rte-list="default"><li><p>92% aided awareness of the Certified Angus Beef brand reached an all-time high. </p></li><li><p>2 to 1 consumer preference of the brand over competing grades and brands of beef. </p></li><li><p>76% of consumers said they would pay $1 extra per pound for Certified Angus Beef </p></li></ul><p>Today, CAB is recognized as the premium beef in the market. It's combination of superior branding and excellent messaging has succeeded. When you think of premium beef, you think Certified Angus Beef. In the fiscal year 2019, <a href="https://news.certifiedangusbeef.com/certified-angus-beef-brand-announces-15th-consecutive-year-of-growth/">CAB sold 1.25B pounds of meat</a>.</p><p>Harold Etling's bad steak in 1975 led to the creation of a brand with $4B+ of sales. The next time you have a good steak at a restaurant, don't forget to thank Harold Etling. He is probably the reason why.</p></div></div></div>]]>
            </description>
            <link>https://www.arilewis.com/aris-posts/how-a-bad-steak-led-to-a-4b-organization</link>
            <guid isPermaLink="false">hacker-news-small-sites-24634465</guid>
            <pubDate>Tue, 29 Sep 2020 23:58:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stop API Bugs by Inferring Data Formats]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24634262">thread link</a>) | @jeanyang
<br/>
September 29, 2020 | https://www.akitasoftware.com/blog/2020/9/29/taking-types-to-the-next-level-stop-api-bugs-by-inferring-data-formats | <a href="https://web.archive.org/web/*/https://www.akitasoftware.com/blog/2020/9/29/taking-types-to-the-next-level-stop-api-bugs-by-inferring-data-formats">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          

          <main>
            
              <section data-content-field="main-content">
                <article id="post-5f739975679d4246c3a8f013" data-item-id="5f739975679d4246c3a8f013">

    
      
    

    <div data-layout-label="Post Body" data-type="item" data-updated-on="1601411504262" id="item-5f739975679d4246c3a8f013"><div><div><div data-block-type="2" id="block-ec1b34ef166efd6e8b4c"><div><p>If you work on web apps, you’ve probably been bitten by a sneaky bug. You know, the kind that takes a long time to debug, but is not glamorous to explain. The whitespace errors; the data format errors. The kind of bug that might torment you for a whole weekend, that you emerge with no victorious war story to tell. This is the kind of bug that types have largely solved in languages like TypeScript and MyPy… but that still lurk at the boundaries of APIs.</p><p>In our <a href="https://www.akitasoftware.com/blog/2020/9/22/faster-better-earlier-catch-breaking-changes-by-diffing-api-behavior?utm_campaign=2020_pre_launch&amp;utm_medium=blog&amp;utm_source=2020_09_29_product_update">last blog post</a>, we talked about how to catch cross-service bugs by watching API traffic. In this blog post, we show specifically how checking data formats across APIs can catch some nasty bugs.</p><h2>😈 An Error that Evades Any Type Checker</h2><p>You finish implementing a new feature. Your unit tests pass and you get that rush of excitement. The integration tests go green; you think today is a good day. Your co-worker and #bff Aki give your changes a +1 and your pull request gets merged. For one moment, everything seems right with the world.</p><p>And then, hours later, DISASTER! You’re playing online games with Aki—and doing better than you ever have before—when you get a page. Customer support creates an incident that has to do with&nbsp; your new code. Customers are irate that they can’t log into your website.&nbsp;</p><p>You rush home and, after spending the rest of your night combing through logs and writing more tests, you figure it out. It turns out that you accidentally used phone.ToString() instead of phone.ToInternationalString(), causing you to send a domestic phone number instead of an international phone number as a string to a third-party API. The integration tests didn’t cover this because they mocked out this third-party API. But now you’ve lost your rare chance to beat Aki at Fall Guys—and you’ve also tripped up some of your customers.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1601411332549_54474"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1601411677399-5IDG23VYLQXROLTDUU55/ke17ZwdGBToddI8pDm48kPpDoBIqNy1gGho9uyT02YZZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVFMU71HPrJlrka-k3KdzI_LQkclrYoo_JyQT2V0r-tdNKQvevUbj177dmcMs1F0H-0/taylor_sad.gif" data-image="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1601411677399-5IDG23VYLQXROLTDUU55/ke17ZwdGBToddI8pDm48kPpDoBIqNy1gGho9uyT02YZZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVFMU71HPrJlrka-k3KdzI_LQkclrYoo_JyQT2V0r-tdNKQvevUbj177dmcMs1F0H-0/taylor_sad.gif" data-image-dimensions="474x264" data-image-focal-point="0.5,0.5" alt="taylor_sad.gif" data-load="false" data-image-id="5f739a4eee510b07270a2163" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1601411332549_54774"><div><div><p>After the incident, you do a postmortem and you become worried. Aki pointed out that even if you adopt language-level type-checking (like TypeScript or MyPy) to catch simple errors, application-level type checking can’t prevent these kinds of errors because it doesn’t check across APIs.&nbsp; And once the type-checked values hit the wire they all get flattened to the same thing, so you would need some sort of magical tool to check across APIs. But what if such a tool existed!</p></div><h2>✅ Find Bugs by Inferring Data Formats</h2><p>Worry no more! We’ve designed Akita to solve exactly this problem of spotting mismatched data formats across the API. With Akita, you can use our data format detection to easily detect issues like this phone number change, without requiring code changes or proxies, simply by allowing Akita to watch your API.&nbsp;</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1601411332549_59847"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1601411952800-JK2S67YP5CF31NPWCLI6/ke17ZwdGBToddI8pDm48kMyRRiflT06lnOxwOXunTyhZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIA6t7DZobKPBVSOztKpfySwZxaCI6SYU1XSvACXqsgGM/Screenshot+from+2020-09-28+22-15-02+cropped.png" data-image="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1601411952800-JK2S67YP5CF31NPWCLI6/ke17ZwdGBToddI8pDm48kMyRRiflT06lnOxwOXunTyhZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIA6t7DZobKPBVSOztKpfySwZxaCI6SYU1XSvACXqsgGM/Screenshot+from+2020-09-28+22-15-02+cropped.png" data-image-dimensions="913x327" data-image-focal-point="0.5,0.5" alt="Screenshot from 2020-09-28 22-15-02 cropped.png" data-load="false" data-image-id="5f739b7077323e2df7bfc2db" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1601411952800-JK2S67YP5CF31NPWCLI6/ke17ZwdGBToddI8pDm48kMyRRiflT06lnOxwOXunTyhZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIA6t7DZobKPBVSOztKpfySwZxaCI6SYU1XSvACXqsgGM/Screenshot+from+2020-09-28+22-15-02+cropped.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1601411332549_60146"><p>Because Akita doesn’t require code changes or proxying, our client is flexible enough to run in either production or test, allowing you to compare cross-API data formats in production with cross-API data formats in test. In this case, Akita would alert you that the data format it observed differed from what it’s been observing, alerting you to the fact that something doesn’t check out, allowing this change to never ever hit production in the first place.</p></div><div data-block-type="5" id="block-yui_3_17_2_1_1601411332549_64928"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1601412109060-KGP84JD9ODP52RRUX779/ke17ZwdGBToddI8pDm48kJpyheux0nskDQnuBO6NswxZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzOPLDh9C41HHctUU2yVgyeUpUWeQq1WB4LsiaPpGbT1yQsc-5Y5TXjYGqI9wQD6R0/taylor_never_ever.gif" data-image="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1601412109060-KGP84JD9ODP52RRUX779/ke17ZwdGBToddI8pDm48kJpyheux0nskDQnuBO6NswxZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzOPLDh9C41HHctUU2yVgyeUpUWeQq1WB4LsiaPpGbT1yQsc-5Y5TXjYGqI9wQD6R0/taylor_never_ever.gif" data-image-dimensions="500x256" data-image-focal-point="0.5,0.5" alt="taylor_never_ever.gif" data-load="false" data-image-id="5f739c09679d4246c3a99af4" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1601411332549_65227"><div><p><br>Akita is able to identify:</p><ul data-rte-list="default"><li><p><strong>Simple Types:</strong> Strings, Integers, Booleans, Floats</p></li><li><p><strong>Countries</strong> - 2 and 3 Letter Country Codes, Names and TLDs</p></li><li><p><strong>Currencies</strong> - Names and Abbreviations</p></li><li><p><strong>Dates and Times</strong> - ISO 8601, RFC 822, RFC 3339, RFC 850, Unix Timestamps and many more</p></li><li><p><strong>Email Address </strong>- RFC 5322 Address and Names</p></li><li><p><strong>Languages</strong> - Language names and ISO 639 2 and 3 Letter abbreviations</p></li><li><p><strong>Phone Numbers -</strong> International and US formatting</p></li><li><p><strong>URLs</strong> - HTTP and HTTPs URLs</p></li></ul><p>Akita works for traffic both to other internal services and for third-party SaaS APIs you might call, like Stripe or Twilio. We’ll talk more in an upcoming blog post about Akita’s specific mechanism for watching outbound API traffic.</p><h2>⚡️ Powered By API-Level Data Format Inference</h2><p>Under the hood, Akita is automatically inferring data formats from the API traffic that it sees. When Akita sees a request hit your service, it infers the data format for each argument as part of the automated API spec generation we described in the <a href="https://www.akitasoftware.com/blog/2020/9/22/faster-better-earlier-catch-breaking-changes-by-diffing-api-behavior?utm_campaign=2020_pre_launch&amp;utm_medium=blog&amp;utm_source=2020_09_29_product_update">last post.</a></p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1601411332549_99871"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1601412377516-AVPK5MR1GWHX5VZQDXKS/ke17ZwdGBToddI8pDm48kKabkCx_A6_n5l8sjGWuzexZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIN_WYAvM0X0a_DzWYffUj58M1ML9geH0aEkZDHcuKpmg/Screen+Shot+2020-09-28+at+10.19.01+PM.png" data-image="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1601412377516-AVPK5MR1GWHX5VZQDXKS/ke17ZwdGBToddI8pDm48kKabkCx_A6_n5l8sjGWuzexZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIN_WYAvM0X0a_DzWYffUj58M1ML9geH0aEkZDHcuKpmg/Screen+Shot+2020-09-28+at+10.19.01+PM.png" data-image-dimensions="915x476" data-image-focal-point="0.5,0.5" alt="Screen Shot 2020-09-28 at 10.19.01 PM.png" data-load="false" data-image-id="5f739d19fd31ed0454ae3504" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1601412377516-AVPK5MR1GWHX5VZQDXKS/ke17ZwdGBToddI8pDm48kKabkCx_A6_n5l8sjGWuzexZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIN_WYAvM0X0a_DzWYffUj58M1ML9geH0aEkZDHcuKpmg/Screen+Shot+2020-09-28+at+10.19.01+PM.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1601411332549_105841"><div><p>It turns out inferring data formats is not as simple as just watching each argument. There might be multiple data formats that a field is eligible for. For instance, `18001112222` could be either a phone number or a time stamp, but a second call to the same endpoint with `1-800-333-4444` makes it clear that parameter is a phone number. A field that accepts strings may accept the occasional email. To infer the most accurate type, Akita compares data from <em>all </em>requests to the same endpoint and identifies the data formats common across all calls.&nbsp; We also use a bit of secret sauce to compare data formats across <em>data flows</em> we detect across your API, but that's the topic of another post.</p><p>Of course, there's always the chance that your API successfully accepts, say, phone numbers and timestamps (or email addresses, country codes, and so on) in the same parameter.&nbsp; In that case, we'll let you know all the data formats that fit the data.</p><p>There are a couple of cool things about how we’re inferring data formats. First, we’re using type inference to infer types at the API level, rather than analyzing source code. Second, we’re inferring specific data formats, with the ability to tell the difference between different phone number formats, on top of simple types like string or int. A bonus is that since Akita automatically infers the entire API spec under the hood, our type inference can use the structure of that spec. More on this in a later post!</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1601411332549_107297"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1601412447877-RPBWJLV50EOV6NNQMLXQ/ke17ZwdGBToddI8pDm48kIisVeufsLaqPYS75OuX1FxZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVGUIyZMpo6jDvOlV8ELZznZDi-rr9EJ6o3n8IpvEJDIMaEcAfnVBrEqrgp1UxUHGkY/taylor_never_find_another.gif" data-image="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1601412447877-RPBWJLV50EOV6NNQMLXQ/ke17ZwdGBToddI8pDm48kIisVeufsLaqPYS75OuX1FxZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVGUIyZMpo6jDvOlV8ELZznZDi-rr9EJ6o3n8IpvEJDIMaEcAfnVBrEqrgp1UxUHGkY/taylor_never_find_another.gif" data-image-dimensions="480x270" data-image-focal-point="0.5,0.5" alt="taylor_never_find_another.gif" data-load="false" data-image-id="5f739d4d556a54782e7388f8" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1601411332549_107596"><div><h2>👀 What’s next?</h2><p>We’ve recently released type inference and would love to have you try it out. We believe we have a one-of-a-kind tool and would love your help in making it as useful as possible in helping developers build great software.</p><ul data-rte-list="default"><li><p><a href="https://www.akitasoftware.com/get-invite?utm_campaign=2020_pre_launch&amp;utm_medium=blog&amp;utm_source=2020_09_29_product_update">Sign up for our private beta</a> if you’re interested in trying things out!</p></li><li><p>We’re constantly trying to make our tool better! If change analysis is an issue for you, please <a href="https://akitasoftware.typeform.com/to/iAbs1tB5?utm_campaign=2020_pre_launch&amp;utm_medium=blog&amp;utm_source=2020_09_29_product_update">fill out this survey</a>—and the opportunity to win a $50 Amazon gift card.</p></li><li><p>Have data formats you’d like us to support? <a href="https://akitasoftware.typeform.com/to/lNd7IT7g?utm_campaign=2020_pre_launch&amp;utm_medium=blog&amp;utm_source=2020_09_29_data_type_survey">Fill out this survey</a> to tell us what you care about.</p></li><li><p>Please spread the word! We’d love all the feedback we can get.</p></li></ul></div></div></div></div></div>

    

    

    <section id="comments-5f739975679d4246c3a8f013">
      
  


    </section>

  </article>





  <nav>

    

    
      <a href="https://www.akitasoftware.com/blog/2020/9/22/faster-better-earlier-catch-breaking-changes-by-diffing-api-behavior">
        <div>
          <p>Next</p>
          <h4>Earlier, Faster, Better, Stronger: Catch Breaking Changes by Diffing API Behavior</h4>
          <div>
            <!--

            Categories

            --><p><span>Approach, Releases</span></p><!--

            Author

            --><p><span>Jean Yang</span></p><!--

            Date

            --><p><time datetime="2020-09-22">September 22, 2020</time></p><!--

            Tags

            --><p><span>semantic diffs, API spec generation</span>
          </p></div>
        </div><!--
        --><svg viewBox="0 0 23 48">
          <g>
            <polyline fill="none" stroke-miterlimit="10" points="1.5,45.7 20.4,23.5 1.5,1.3 "></polyline>
          </g>
        </svg>
      </a>
    

  </nav>
              </section>
            
          </main>

        </div></div>]]>
            </description>
            <link>https://www.akitasoftware.com/blog/2020/9/29/taking-types-to-the-next-level-stop-api-bugs-by-inferring-data-formats</link>
            <guid isPermaLink="false">hacker-news-small-sites-24634262</guid>
            <pubDate>Tue, 29 Sep 2020 23:28:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hitboxes That Feel Good: Reinventing the Goomba Stomp]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24634144">thread link</a>) | @kuiro5
<br/>
September 29, 2020 | https://subpixel.net/2020/03/20/hitboxes-that-feel-good-reinventing-the-goomba-stomp/ | <a href="https://web.archive.org/web/*/https://subpixel.net/2020/03/20/hitboxes-that-feel-good-reinventing-the-goomba-stomp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content" role="main">


		
			<article id="post-479">
    
    		<section>
		    
<p>Update: Ready Set Goat has been released! Check out more at <a href="https://www.readysetgoat.com/">www.ReadySetGoat.com</a></p>



<p>iOS: <a href="https://apps.apple.com/us/app/ready-set-goat/id1498158058?ls=1">https://apps.apple.com/us/app/ready-set-goat/id1498158058?ls=1</a><br>Android: <a href="https://play.google.com/store/apps/details?id=net.subpixel.ReadySetGoat">https://play.google.com/store/apps/details?id=net.subpixel.ReadySetGoat</a></p>



<p>If you’re in a hurry, <a href="#implementation">skip to the approach I used</a>.</p>



<hr>



<p>We’re developing a game that utilizes an age old mechanic – the <a href="https://tvtropes.org/pmwiki/pmwiki.php/Main/GoombaStomp">Goomba Stomp</a>.</p>



<figure><video autoplay="" controls="" loop="" muted="" src="https://www.subpixel.net/wp-content/uploads/2020/03/79214DBD-5D6D-4FBF-8F7D-5FC56D851537.mp4" playsinline=""></video><figcaption>Ready Set Goat gameplay clips</figcaption></figure>



<p>There’s a common classical approach to this mechanic. A single, monolithic hitbox representing the physical space of the character. And that space is used for everything – stomping, getting hurt, and bumping into walls. (If you can’t tell, I’m foreshadowing here.)</p>



<p>Here’s what the Goomba Stomp looks like in Mario, with an overlay of the hitboxes next to it:</p>



<p><img src="https://i2.wp.com/www.subpixel.net/wp-content/uploads/2020/03/ezgif.com-optimize.gif?ssl=1" alt="Mario stomping" data-recalc-dims="1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"> <img src="https://i2.wp.com/www.subpixel.net/wp-content/uploads/2020/03/Mario-Hitboxes.gif?ssl=1" alt="Mario stomping with hitboxes" data-recalc-dims="1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>



<p>By the way, there’s a great video on YouTube that overlays the hitboxes for an entire speedrun. This is just fun to watch; check it out:</p>



<figure><p><span><iframe width="640" height="360" src="https://www.youtube.com/embed/eDaYK1cOCmw?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span>
</p><figcaption>Courtesy user <a href="https://www.youtube.com/channel/UCzYROBp4ypAEOEy7G89aGaQ">qvidz on Youtube</a></figcaption></figure>



<p>The first thing you’ll notice is, <strong>you suck at Mario</strong>.</p>



<p>Just kidding, this is an AI playing the game. At least I think it is…</p>



<p>The second thing you might notice is, the hitboxes are <strong>tight</strong>. They are typically smaller than the character, which gives the player some <strong>breathing room</strong>. You can overlap a few pixels with an enemy – maybe a hair on a mustache, a cheek, or a toe – and not be damaged.</p>



<p>There’s some fudge factor here, and that makes the game slightly more forgiving. This is generally considered a good approach and should help produce a good <a href="https://en.wikipedia.org/wiki/Game_feel">Game Feel</a>. Mario’s movement and feel were largely responsible for its success back in the 80s.</p>



<p>Tight hitboxes are a tried and true method for implementing this mechanic. So why devote a whole blog post to them?</p>



<p>In the course of implementing the Goomba Stomp in Ready Set Goat, I learned that just because it worked in one game, doesn’t mean it would work in mine. And after weeks of playtesting, we decided that <em>something</em> needed to be changed.</p>



<h3>1. Tight Hitboxes</h3>



<p>With tight hitboxes, Mario can stand next to a Goomba and not get punished for being a few pixels off. This is great. It’s forgiving to the player; they probably won’t even notice when it happens. They’d just notice if it <em>wasn’t </em>there.</p>



<p>But here’s the problem:</p>



<div><figure><img loading="lazy" src="https://i2.wp.com/www.subpixel.net/wp-content/uploads/2020/03/Mario-Tight.gif?resize=300%2C300&amp;ssl=1" alt="" width="300" height="300" data-recalc-dims="1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Mario visually stomps an enemy, but gets killed</figcaption></figure></div>



<p>See that? That extra breathing room works both ways. Now it benefits the Goomba.</p>



<p>In this scenario, Mario appears to stomp some of the enemy’s pixels, yet the player receives no reward. What’s worse is that the Goomba continues moving, eventually slamming into Mario, causing the plumber’s untimely demise.</p>



<p>In Ready Set Goat, the action is much more fast paced than Mario; there’s less time for the player to react to a misstep. So these weird situations can happen way more often. Let’s look at some other hitbox approaches and see if they’re any better.</p>



<h3>2. Loose Hitboxes</h3>



<p>Loose hitboxes work the opposite way. They give the player a huge footprint, allowing them to stomp from greater distances. In fact, the player might earn a stomp without any pixels touching. Right out of thin air.</p>



<div><figure><img loading="lazy" src="https://i1.wp.com/www.subpixel.net/wp-content/uploads/2020/03/Mario-Loose1.gif?resize=300%2C300&amp;ssl=1" alt="" width="300" height="300" data-recalc-dims="1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Mario doesn’t quite earn a stomp yet, but is awarded one</figcaption></figure></div>



<p>There are a few downsides to this approach. The first is that it might be too easy to stomp. You might think that that makes the game less challenging. But it actually makes it less <em>predictable</em>. In some cases, the player might not want to stomp because the implications could lead them to their death. So by trying to make things easier, we’ve just made the game more challenging.</p>



<p>In Ready Set Goat, choosing when to stomp is just as important as choosing when not to stomp.</p>



<figure><video autoplay="" controls="" loop="" muted="" src="https://www.subpixel.net/wp-content/uploads/2020/03/5E6F3418-3F1D-40BF-AA8B-8F381B2CAF95.mp4" playsinline=""></video><figcaption>Stomping an enemy at the wrong time could accidentally bounce the goat off into a different enemy.</figcaption></figure>



<p>The worst problem though, is that the player might time a jump <em>really</em> close to the enemy, and clip them on the way up, resulting in the player’s death.</p>



<div><figure><img loading="lazy" src="https://i0.wp.com/www.subpixel.net/wp-content/uploads/2020/03/Mario-Loose2-1.gif?resize=300%2C300&amp;ssl=1" alt="" width="300" height="300" data-recalc-dims="1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Mario should safely jump over the Goomba with this trajectory. But the hitboxes are too big and he gets owned.</figcaption></figure></div>



<h3>3. Pixel Perfect</h3>



<p>Pixel Perfect hitboxes are an opinionated response to the question “How much breathing room should I give the player?” Its answer is<strong> exactly none</strong>. The player’s stomps will connect predictably, but the player gets no leeway if they make a mistake.</p>



<div><figure><img loading="lazy" src="https://i1.wp.com/www.subpixel.net/wp-content/uploads/2020/03/image-8.png?resize=300%2C300&amp;ssl=1" alt="" width="300" height="300" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/www.subpixel.net/wp-content/uploads/2020/03/image-8.png?resize=300%2C300&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Unforgiving pixel-perfect collisions</figcaption></figure></div>



<p>While the community over at <strong><a href="http://reddit.com/r/hitboxporn">/r/hitboxporn</a></strong> might disagree, I believe this approach leads to an unforgiving game. While testing it out, I found myself frustrated with the exactness of Pixel Perfection.</p>



<p>Of course, there are simple ways to correct this. For example, you could only count a collision if more than a certain percentage of pixel overlap. But that still suffers from the problem of being unpredictable.</p>



<h3>4. Composite Hitboxes</h3>



<p>The last common approach I can think of is Composite Hitboxes. However this approach doesn’t answer the question “How much breathing room should I give the player?” It gives you a more accurate representation of the player’s volume (just like Pixel Perfect), but the developer is still left to decide whether that space should be Tight or Loose.</p>



<div><figure><img loading="lazy" src="https://i2.wp.com/www.subpixel.net/wp-content/uploads/2020/03/image-6.png?resize=300%2C300&amp;ssl=1" alt="" width="300" height="300" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/www.subpixel.net/wp-content/uploads/2020/03/image-6.png?resize=300%2C300&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Example of composite hitboxes</figcaption></figure></div>



<p>The approach by itself doesn’t solve anything for us. But what about the idea in general? Multiple hitboxes… maybe we’re on to something here.</p>



<h3>The Elephant… Er…. Goat in the Room</h3>



<p>After considering these four approaches, finally, it hit me like a ton of brick blocks. The hitboxes in Mario (and games like it) are having an identity crisis.</p>



<p>The space where Mario attacks from is the same space in which he’s vulnerable. To complicate things further, it’s also his physical space in the world; platforms and walls use this hitbox to determine if Mario bumped into them.</p>



<p>To some, this sort of ambiguity might be an obvious problem. To me, it was an epiphany.</p>



<h2>A New Player Has Entered the Game</h2>



<p>To solve the problem, I looked outside the platformer genre for inspiration. A common pattern from a different genre gave me some ideas.</p>



<p>Fighting games use a different concept; a <strong>hurtbox</strong> and a <strong>hitbox</strong>. A hurtbox is the space where the player is vulnerable; where they get hurt. A hitbox is where a player’s hits land.</p>



<div><figure><img loading="lazy" src="https://i0.wp.com/www.subpixel.net/wp-content/uploads/2020/03/Ryu-HurtboxHitbox.png?resize=300%2C300&amp;ssl=1" alt="" width="300" height="300" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/www.subpixel.net/wp-content/uploads/2020/03/Ryu-HurtboxHitbox.png?resize=300%2C300&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Fighter games break out character space into two types: Hitboxes and Hurtboxes</figcaption></figure></div>



<p><strong>A quick note on terminology:</strong> I come from a First Person Shooter background. In FPS’s, we define a hitbox as <strong><a href="https://counterstrike.fandom.com/wiki/Hitbox">the area where a character can be hit</a></strong>. If you shoot a bullet at their hitbox, you hit them.</p>



<p>But fighting games would call that a hurtbox.</p>



<p>Regardless, in Mario, there is no differentiation. Your hurtbox is your hitbox, and vice versa. </p>



<p>The swapped terminology is <em>bound</em> to cause confusion, possibly anger. I’m sticking to the FPS-friendly terminology for the rest of the article, because that’s what I know best. But the point of this article is less about terminology, and more about the concept. Call these boxes whatever works best for you in your own projects. AttackBox and DefenseBox are one suggestion.</p>



<p>The different identification of these boxes led me to my final approach: multiple boxes, each defining a different spatial representation of the player.</p>



<h2 id="solution">Hitboxes and Hurtboxes and Bounding Boxes, Oh My!</h2>



<p>I categorized and defined the three different spatial representations of the characters:</p>



<ol><li><strong>Hitbox</strong><br>The area where the character can get hit (where they are vulnerable)</li><li><strong>Hurtbox</strong><br>The area where the character hurts others (where they attack)</li><li><strong>Bounding Box</strong><br>The space the character occupies according to obstacles (platforms, walls)</li></ol>



<p>Then I organized my colliders in game to represent this scheme.</p>



<div><figure><img src="https://i2.wp.com/www.subpixel.net/wp-content/uploads/2020/03/Goat-HitHurtBoundingBox-1.gif?ssl=1" alt="" data-recalc-dims="1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Final box design of my Goat character</figcaption></figure></div>



<p>And I did the same thing with the enemies.</p>



<p>Then I set up my game engine (Unity) with the following rules:</p>



<ol><li>Player Hurtboxes should collide with Enemy Hitboxes</li><li>Enemy Hurtboxes should collide with Player Hitboxes</li><li>Players or Enemies bump into the environment</li></ol>



<p>(I explain how to do all of this in Unity <a href="#implementation">further below</a>)</p>



<h3>The Results</h3>



<p>I’m really happy with this solution, it solves a lot of the problems of the other four. </p>



<p>The player can get a stomp even when the Goat is a few pixels away. This fixes the problem with Tight Hitboxes. See how the Goat’s Hurtbox and the Enemy’s Hitbox connect even from some distance:</p>



<div><figure><img loading="lazy" src="https://i1.wp.com/www.subpixel.net/wp-content/uploads/2020/03/Goat-ForgiveStomp.gif?resize=300%2C300&amp;ssl=1" alt="" width="300" height="300" data-recalc-dims="1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<p>But they can still narrowly avoid an Enemy on the upward jump. This is an improvement over the Loose Hitboxes. Check out how the Goat’s Hitbox and Enemy’s Hurtbox near-miss eachother in this gif:</p>



<div><figure><img loading="lazy" src="https://i1.wp.com/www.subpixel.net/wp-content/uploads/2020/03/Goat-CloseCall.gif?resize=300%2C300&amp;ssl=1" alt="" width="300" height="300" data-recalc-dims="1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<p>The player gets room to breath, but can still stomp without feeling cheated.</p>



<p>I didn’t want my game to be <em>too </em>easy, but now I at least have control over how easy it is. For example, I could increase the width of the Goat’s Hurtbox and the Enemy’s Hitbox with no negative side effects. This would make it easier for the Goat to get a Stomp in, and still stay safe while jumping upward.</p>



<p>It’s pretty easy to get this all set up.</p>



<h2 id="implementation">Implementation in Unity</h2>



<h3><strong>Step 1: Setup your layers</strong></h3>



<p>For a one-size-fits-all solution to this problem in Unity, you’ll need six layers. You could probably get away with less, but this really makes it obvious what’s happening under the hood.</p>



<div><figure><img loading="lazy" src="https://i2.wp.com/www.subpixel.net/wp-content/uploads/2020/03/Screen-Shot-2020-03-19-at-2.04.48-PM-1.png?resize=312%2C417&amp;ssl=1" alt="" width="312" height="417" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/www.subpixel.net/wp-content/uploads/2020/03/Screen-Shot-2020-03-19-at-2.04.48-PM-1.png?resize=312%2C417&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>6 Layers for Hitboxes That Feel Good™️</figcaption></figure></div>



<h3><strong>Step 2: Setup the collision matrix</strong></h3>



<p>You’ll need to tweak the collision matrix to support this scheme, as follows:</p>



<figure><img src="https://i2.wp.com/www.subpixel.net/wp-content/uploads/2020/03/image.png?ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/www.subpixel.net/wp-content/uploads/2020/03/image.png?ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>Notice how few checkmarks there are. There’s really only 3 collisions we need to worry about</p>



<ol><li>Player hurts an Enemy</li><li>Player gets hurt by an Enemy</li><li>Player or Enemy bump into the environment</li></ol>



<h3><strong>Step 3: Setup your characters’ boxes</strong></h3>



<p>Now for the actual characters. Each box will be represented as a Collider2d (this concept works in 3d too however). Since Unity only allows one  Collider per GameObject, we need to store 2 of the Colliders on child GameObjects. This makes the solution a bit more complex, but it’s manageable.</p>



<p>So that’s one parent GameObject representing the character’s Bounding Box. One child GameObject for the …</p></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://subpixel.net/2020/03/20/hitboxes-that-feel-good-reinventing-the-goomba-stomp/">https://subpixel.net/2020/03/20/hitboxes-that-feel-good-reinventing-the-goomba-stomp/</a></em></p>]]>
            </description>
            <link>https://subpixel.net/2020/03/20/hitboxes-that-feel-good-reinventing-the-goomba-stomp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24634144</guid>
            <pubDate>Tue, 29 Sep 2020 23:12:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Benchmarking vol. 2: Pitting Actix against Rocket v0.4 and v0.5-dev (Rust)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24634107">thread link</a>) | @strohel
<br/>
September 29, 2020 | https://matej.laitl.cz/bench-actix-rocket/ | <a href="https://web.archive.org/web/*/https://matej.laitl.cz/bench-actix-rocket/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><img src="https://matej.laitl.cz/images/2020-09-29-bench-actix-rocket/cover.png" alt="illustration">
I present a Rust-specific sequel to my <a href="https://matej.laitl.cz/bench-rust-kotlin-microservices/">previous benchmark of 2 Kotlin and a Rust microservice</a>
â€” itâ€™s hard to resist oneâ€™s own curiosity and popular demand, especially when youâ€™ve been
<a href="https://www.reddit.com/r/rust/comments/is9onc/what_i_learnt_from_benchmarking_http4k_ktor/g57n93y/?utm_source=share&amp;utm_medium=web2x&amp;context=3">nerd</a>-<a href="https://xkcd.com/356/">sniped</a>.
Letâ€™s stress-test the two prominent web frameworks: Actix Web and Rocket.
In addition to stable â€œthreads &amp; blocking callsâ€� Rocket v0.4,
I have included a development snapshot of in-the-works Rocket v0.5,
which is async and <a href="https://github.com/SergioBenitez/Rocket/commit/56a61726">no longer requires nightly Rust</a>.</p>

<p><em>Impatient? <a href="#results">Jump to the results</a>.</em></p>

<h2 id="preamble">Preamble</h2>

<p>Iâ€™ll take advantage of the previous article to fully describe
aspects that apply equally well to this round:</p>
<ul>
  <li><a href="https://matej.laitl.cz/bench-rust-kotlin-microservices/#on-techempower-framework-benchmarks">How this is different than TechEmpower benchmarks</a>.
<em>TL;DR: we want to capture finer nuances and test idiomatic implementations with error reporting,
logging, etc. â€” rather than highly optimised ones.</em></li>
  <li><a href="https://matej.laitl.cz/bench-rust-kotlin-microservices/#the-service">The microservice weâ€™ve benchmarking</a>.
<em>TL;DR: a simple endpoint that does one call to Elasticsearch server.</em></li>
  <li><a href="https://matej.laitl.cz/bench-rust-kotlin-microservices/#recipe">The testing methodology</a>.
<em>TL;DR: repeated runs of a Python script that spins microservice Docker container
and exposes it to an increasing number of concurrent connections using <a href="https://github.com/wg/wrk">wrk</a>.</em></li>
  <li><a href="https://matej.laitl.cz/bench-rust-kotlin-microservices/#runtime-environment">Runtime Environment</a>.
<em>TL;DR: we limit the microservice to 1.5 CPU cores and 512 MiB memory using Docker.</em></li>
  <li><a href="https://matej.laitl.cz/bench-rust-kotlin-microservices/#hardware">Hardware</a>.
<em>TL;DR: Google Cloud Platform VM with 4-core AMD Epyc Rome CPU for the microservice + 12-core machine for the Elasticsearch server.</em></li>
</ul>

<p>We still compile in release mode, target <code>skylake</code>, and utilize <a href="https://deterministic.space/high-performance-rust.html">cheap performance tricks</a>.
What changed is Rust version, we have to use <strong>nightly</strong> because of Rocket v0.4.
More specifically, all implementations are compiled using
<code>rustc 1.47.0-nightly (2d8a3b918 2020-08-26)</code>.<sup id="fnref:nightly" role="doc-noteref"><a href="#fn:nightly">1</a></sup></p>

<h2 id="actix-v30">Actix v3.0</h2>

<p>Code as benchmarked: <a href="https://github.com/strohel/locations-rs/tree/actix-v30">locations-rs tag <code>actix-v30</code></a>.
Uses <strong>Actix Web 3.0.2</strong>.</p>

<p>Just some small things have changed
since the <a href="https://matej.laitl.cz/bench-rust-kotlin-microservices/#the-story-of-locations-rs">version described in the last post</a>:</p>
<ul>
  <li>We now use version 3.0, but note that <a href="https://storage.googleapis.com/strohel-pub/bench-actix-versions/bench-results.html">its performance matches v2.0 in our case</a>.</li>
  <li>OpenAPI (Swagger) support is reintroduced as I was able to <a href="https://github.com/wafflespeanut/paperclip/pull/218">make Paperclip support v3.0, too</a>.</li>
</ul>

<h2 id="rocket-v04">Rocket v0.4</h2>

<p>Code as benchmarked: <a href="https://github.com/strohel/locations-rs-rocket/tree/rocket-v04">locations-rs-rocket tag <code>rocket-v04</code></a>.
Uses stable <strong>Rocket 0.4.5</strong>.</p>

<p>Porting from Actix to Rocket v0.4 was a matter of
<a href="https://github.com/strohel/locations-rs-rocket/commit/f37de2fe">one +175 -150 lines commit</a>.<sup id="fnref:lines" role="doc-noteref"><a href="#fn:lines">2</a></sup>
It looks a bit scary but was mostly mechanical:
converting Actix type to Rocketry ones, and then fixing all compiler errors â€”
I love how <code>rustc</code> essentially works as your to-do list.
There was only one major hurdle:</p>

<h3 id="calling-async-functions-from-blocking-handlers">Calling Async Functions from Blocking Handlers</h3>

<p>Rocket v0.4 handlers are classic blocking (sync) functions, but Reqwest-based
<a href="https://github.com/elastic/elasticsearch-rs">elasticsearch-rs</a> only provides an async API.
Whoops.</p>

<p>The general advice is to propagate the asynchronicity up in caller stack
instead of trying to call async functions from sync code.
But what if we really want to? These are our options:</p>

<ol>
  <li><code>global-rt</code>: launch a global <a href="https://docs.rs/tokio/0.2/tokio/runtime/index.html#threaded-scheduler">threaded Tokio runtime</a>
alongside Rocket workers.
Then call runtimeâ€™s <a href="https://docs.rs/tokio/0.2/tokio/runtime/struct.Handle.html#method.block_on">Handle::block_on()</a>
in endpoint handlers to delegate the work to the global async runtime,
pausing the Rocket worker until the future resolves.</li>
  <li><code>per-worker-rt</code>: create a <a href="https://docs.rs/tokio/0.2/tokio/runtime/index.html#basic-scheduler">basic single-threaded Tokio runtime</a>
<em>per each Rocket worker</em>.<sup id="fnref:per-worker" role="doc-noteref"><a href="#fn:per-worker">3</a></sup>
In endpoint handlers then call <a href="https://docs.rs/tokio/0.2/tokio/runtime/struct.Runtime.html#method.block_on">Runtime::block_on()</a>,
which here has different semantics (!) than the <code>Handle::block_on()</code> above:
the future, and any other spawned async tasks, actually run within this Rocket worker thread.<sup id="fnref:worker-run" role="doc-noteref"><a href="#fn:worker-run">4</a></sup>
This comes with a caveat.
Reqwest::client() seems to <em>attach</em> itself to the async runtime it is first used in.
I had to make Elasticsearch client also local to each Rocket worker.
Otherwise, I got deadlocks or <a href="https://github.com/hyperium/hyper/issues/2112">problems described in hyper issue #2112</a>.</li>
  <li><code>per-req-rt</code>: launch a fresh basic Tokio runtime per each request.
It feels wrong, and it is wrong. Iâ€™ve tried and benchmarked this so that we know <em>how much</em> wrong.</li>
  <li>Patch elasticsearch-rs to provide a blocking API â€” by employing Requestâ€™s
<a href="https://docs.rs/reqwest/0.10/reqwest/blocking/index.html">optional blocking API</a>.
That would be futile, and essentially a sophisticated variant of 2.,
given <a href="https://github.com/seanmonstar/reqwest/blob/v0.10.8/src/blocking/client.rs#L715-L783">the implementation details of the blocking client</a>.</li>
</ol>

<p><a href="https://storage.googleapis.com/strohel-pub/rocket-async-approach/bench-results.html"><strong>Here are the results of benchmarking the first three approaches.</strong></a>
Source code of each variant is available under the respective <a href="https://github.com/strohel/locations-rs-rocket/tags">tag in the locations-rs-rocket repository</a>.</p>

<p>You can almost hear the server crying as it tries to cope with the inefficiency of <code>per-req-rt</code>:
it is more than 7âœ• less efficient than the best performing variant.</p>

<p>The other two more realistic variants are close to each other.
<code>per-worker-rt</code> has a slight edge in peak performance and a clear edge in efficiency,
especially for low connection counts.
It is therefore proclaimed a winner of this qualification round
and represents Rocket v0.4 in later benchmarks.</p>

<p>It is not a surprise that highly-optimised Actix uses a similar approach:
independent single-threaded Tokio runtimes per each worker
instead of a global work-stealing threaded one.</p>

<h3 id="keep-alive-connections">Keep-Alive Connections</h3>

<p><a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Connection_management_in_HTTP_1.x#Persistent_connections">Keep-Alive (persistent) connections</a>
save latency and resources when a client makes more than one request to a given server,
especially when the connection is secured by TLS.
Unfortunately, Rocket v0.4 is not their friend.</p>

<p><strong>First</strong>, to the best of my knowledge,
<a href="https://github.com/SergioBenitez/Rocket/issues/580#issuecomment-698286249">persistent connections donâ€™t work at all in Rocket v0.4</a>
â€” the server closes the connection before reading a second request.
Iâ€™ve <a href="https://github.com/hyperium/hyper/pull/2288/commits/3109103">traced the problem down to a bug in BufReader in old hyper 0.10.x and submitted a fix</a>.
In the 0.11.x branch, the same bug was <a href="https://github.com/hyperium/hyper/commit/d35992d0198d733c251e133ecc35f2bca8540d96#diff-078f367374debbc894f7cc1c4084e467R64-R66">fixed a long ago</a> and released with 0.11.0 in June 2017.
My pull request was <a href="https://github.com/hyperium/hyper/pull/2288#issuecomment-698492487">closed without merging</a>,
as the maintainers were (understandably) not keen on releasing a new version of a legacy branch that was superseded 3 years ago.
In other words, <em>Rocket v0.4 depends on unmaintained hyper</em> for its HTTP handling.</p>

<p><strong>Second,</strong> even if the bug in hyper is patched,
keep-alive connections in hyper 0.10.x are <a href="https://github.com/hyperium/hyper/blob/0.10.x/src/server/mod.rs#L282-L351">implemented naÃ¯vely</a>:
the worker thread is kept busy waiting for the client on the persistent connection,
unable to process other requests.
It is therefore easy to (accidentally) trigger denial-of-service
by opening more persistent connections than available workers,
even with the default keep-alive timeout of 5 s.<sup id="fnref:browsers" role="doc-noteref"><a href="#fn:browsers">5</a></sup>
Note that the first problem prevents this second problem from happening. ;-)</p>

<p>Both issues were long resolved in more modern hyper 0.11+,
and therefore in Rocket v0.5-dev which I happen to benchmark too.</p>

<p>If you run Rocket v0.4 in production,
I recommend you to turn off persistent connections in Rocket config (set <code>keep-alive</code> to <code>0</code>)
â€” while most clients retry the failed second request on a persistent connection gracefully,
at least some versions of Python <code>requests</code> and <code>urllib3</code> were raising exceptions instead.
If you care about latency, I suggest you put an HTTP load-balancer in front of Rocket v0.4 server
to reintroduce persistent connections at least to the client &lt;-&gt; load-balancer hop.</p>

<p><a href="https://storage.googleapis.com/strohel-pub/rocket-keep-alive/bench-results.html"><strong>The benchmarks show that disabling keep-alive causes only a mild performance hit in our case.</strong></a></p>

<p>The red <code>oneshot-*</code> line is Rocket with keep-alive disabled and 16 workers,
while other <code>persistent-*</code> lines represent Rocket with patched hyper, enabled keep-alive, and 16, 32 and 64 workers.
It can be seen that disabling keep-alive hurts latency, but not necessarily throughput
â€” if the number of connections can be increased.
Note that the effect will be more pronounced in reality,
real network latencies are much more significant than that of our loopback interface.</p>

<p>Unfortunately, <code>wrk</code> does not indicate that some of its concurrent connections have failed to connect to the server at all.
But another demonstration of the denial-of-service behaviour is present when keep-alive is enabled:
Notice how the latencies of the 16-, 32-, and 64-worker instances of Rocket <em>cut-off</em> at
16, 32, respectively 64 concurrent connections.
When such saturation happens,
it is indeed impossible to make a new connection using e.g. <code>curl</code> to the Rocket instance.</p>

<p>Because of these 2 problems, Rocket v0.4 has keep-alive disabled in all other benchmarks.</p>

<h3 id="tuning-the-number-of-workers">Tuning The Number of Workers</h3>

<p>If you want to squeeze the highest possible efficiency from a Rocket v0.4 instance,
you should tweak the number of its worker threads.
The optimal count will depend mainly on the number of available CPU cores,
and the ratio of time your endpoints spend CPU-crunching and waiting for I/O.</p>

<p><a href="https://storage.googleapis.com/strohel-pub/rocket-worker-count/bench-results.html"><strong>Here I have benchmarked worker counts from 8 to 256.</strong></a></p>

<p>Instance with 16 workers is the most efficient, although the differences are small.
Most notable variance is, as expected, in memory consumption.
Having in mind that 1.5 CPUs is available the microservice, we arrive at around 10 workers per core.
Rocketâ€™s default is more conservative 2 workers per core.</p>

<h2 id="rocket-v05-dev">Rocket v0.5-dev</h2>

<p><em><strong>Big fat warning</strong>: Rocket v0.5 is still under development.
Version tested in this post is its <a href="https://github.com/SergioBenitez/Rocket/commit/1369dc4">1369dc4 commit</a>.
A lot of things may change in the final release, including all observations here.
You can track Rocket v0.5 progress in its <a href="https://github.com/SergioBenitez/Rocket/issues/1065">async migration tracking issue</a>
and related GitHub milestone.</em></p>

<p>Code as benchmarked: <a href="https://github.com/strohel/locations-rs-rocket/tree/rocket-v05-dev">locations-rs-rocket tag <code>rocket-v05-dev</code></a>.</p>

<p>Porting from async Actix to async Rocket v0.5-dev was even easier than to Rocket v0.4.
<a href="https://github.com/strohel/locations-rs-rocket/commit/879cd88">Here is the 147 insertions, 140 deletions commit that did the job</a>.<sup id="fnref:lines:1" role="doc-noteref"><a href="#fn:lines">2</a></sup></p>

<p>Compared to v0.4, Rocket v0.5-dev is <em>boring</em>, in the best possible sense of the word.
Persistent connections are without problems.
There is no need to fiddle with the number of workers.
I attribute this to porting to up-to-date hyper 0.13.x and async Rust ecosystem.</p>

<h2 id="results">Results</h2>

<p>All graphs below are interactive and infinitely scalable SVGs â€” zoom in if necessary.</p>

<p>The startup time is measured from the moment Docker finishes setting up the container
to the moment when we receive a valid HTTP response to <code>GET /</code>.</p>

<p>No real difference, single-digit milliseconds correspond to the required round-trip to Elasticsearch server.</p>

<p>Error response ratio in percents.</p>

<p>Nicely flat for all frameworks up to extreme 1024 and 2048 connections.
Actix manages to be slightly better there with ~1% of errors, compared to ~1.5% of both Rocket versions.</p>

<p>High-water mark <em>successful</em> requests per second as the number of concurrent connections grows, one of our main metrics.</p>

<p>Recurrin…</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://matej.laitl.cz/bench-actix-rocket/">https://matej.laitl.cz/bench-actix-rocket/</a></em></p>]]>
            </description>
            <link>https://matej.laitl.cz/bench-actix-rocket/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24634107</guid>
            <pubDate>Tue, 29 Sep 2020 23:05:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SkyGrid launches drone app that automates every phase of flight]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24634034">thread link</a>) | @finphil
<br/>
September 29, 2020 | https://nuadox.com/post/630634164690075648/skygrid-drone-automation-app | <a href="https://web.archive.org/web/*/https://nuadox.com/post/630634164690075648/skygrid-drone-automation-app">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 
                 
                    
                    <article id="630634164690075648">
                        <div>
                            <div>
                                <a href="https://nuadox.com/post/630634164690075648/skygrid-drone-automation-app"><h2>SkyGrid launches drone app that automates every phase of flight</h2></a>
                                <figure data-orig-width="1199" data-orig-height="616"><img src="https://64.media.tumblr.com/c5261fbf1a95dac4c9a0a495b62d10c7/e15e14b7497ce16a-8c/s1280x1920/1120360c201c3fc5d18bb73afaa37ec56c13f996.jpg" alt="image" data-orig-width="1199" data-orig-height="616" width="1199" height="616"></figure><p><b>- By <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.skygrid.com%2F&amp;t=NTgzYjhkYmM3ZTQ2MGRhMjZiOTIyZDg1YmZjZDllYjM0OWJkZjAxYSxWcXYzazRZeA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F630634164690075648%2Fskygrid-drone-automation-app&amp;m=0&amp;ts=1601627250">SkyGrid</a> -</b></p><p>

SkyGrid, a Boeing, SparkCognition company, today launched a new application for drone operators and enterprises to automate every phase of flight in one unified solution.&nbsp;</p><p>Now available for free in the <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fc212.net%2Fc%2Flink%2F%3Ft%3D0%26l%3Den%26o%3D2931428-1%26h%3D455054367%26u%3Dhttps%253A%252F%252Fapps.apple.com%252Fus%252Fapp%252Fskygrid-flight-control%252Fid1500582074%26a%3DiPad%2BApp%2BStore&amp;t=ZTVkMWFhNzQ3MzM0M2Y4ODRiMWEzNDM3YWViYWU5MzI4NDZhNTkyNyxWcXYzazRZeA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F630634164690075648%2Fskygrid-drone-automation-app&amp;m=0&amp;ts=1601627250">iPad App Store</a>, <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.skygrid.com%2Fflight-control%2F%3Futm_source%3Dskygrid%26utm_medium%3Dpressrelease%26utm_campaign%3Dflightcontrol&amp;t=MmE3MGU2MjcxNTY1MzY3MjgyNWQxZGRmYzI5NzU5YWE2M2Q2ZjhhYSxWcXYzazRZeA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F630634164690075648%2Fskygrid-drone-automation-app&amp;m=0&amp;ts=1601627250">SkyGrid Flight Control</a>&nbsp;simplifies mission planning and execution, allowing drone operators to autonomously surveil a defined area and detect objects in real-time. Powered by artificial intelligence (AI) computer vision, the solution enables more efficient search and rescue missions, disaster response, perimeter surveillance, site inspections, and more.

<br></p><p>“Traditionally, drone operators have used several different tools to check airspace, get LAANC, plan and execute flights, and gather insights, but it’s a manual, cumbersome process,” said Amir Husain, CEO and founder of SkyGrid. “Recognizing this challenge, SkyGrid has minimized the burden on drone operators by creating one solution that automates airspace, flights, and insights. As the only drone solution built on AI and blockchain technologies, we give operators and enterprises the assurances they need to execute safe, compliant missions.”</p><p>Powered by SkyGrid’s AerialOS, SkyGrid Flight Control enables drone operators to automate airspace authorization, mission planning, flight execution, and object detection in one end-to-end solution. The following features and functionality are available for free within the iPad application:</p><ul><li><b>Airspace intelligence:</b> Provides a map of airspace classes, boundaries, temporary flight restrictions, notices to airmen, and other advisories.</li><li><b>Ground intelligence: </b>Displays population density, obstacles, elevation, and more.</li><li><b>Advanced weather data:</b> Details hyper-local precipitation, wind speed and direction, temperature, cloud cover, and more.</li><li><b>Real-time airspace authorization:</b> Automates authorization to fly in U.S. controlled airspace under 400 feet through integration with the Federal Aviation Administration’s Low Altitude Authorization and Notification Capability (LAANC) 4.0.</li><li><b>Automated mission planning:</b> Automatically generates area exploration, waypoint, and multi-objective missions based on custom flight parameters, such as desired speed, altitude, and location.</li><li><b>Autonomous flight execution:</b> Autonomously launches the drone and performs the pre-defined flight plan.</li><li><b>AI object recognition:</b> Detects objects in real-time as a drone surveils the defined area with AI computer vision.</li></ul><p>More advanced enterprise features are also available for organizations to better manage all drones, pilots, and airspace operations. These features include AI-based mission planning and rerouting, multi-drone missions, custom object detection and counting, geofencing and alerts, and more.</p><p>“SkyGrid Flight Control is an important stepping-stone to enable more complex commercial drone operations and advanced air mobility in urban, regional, and global markets,” said Steve Nordlund, vice president and general manager of Being NeXt and executive board advisor of SkyGrid. “SkyGrid is solving complex problems in unmanned aviation with a system that will safely integrate the future volume of drones, passenger air vehicles, and other autonomous aircraft in the global airspace.”</p><p>–</p><p><i>Header image:&nbsp;SkyGrid Flight Control. Credit <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.prnewswire.com%2Fnews-releases%2Fskygrid-launches-all-in-one-drone-app-to-automate-every-phase-of-flight-301139488.html&amp;t=Y2RlOTYwMjdhOGIyZWJkOGIwODcyYjI3ZjI1NjE4ZmFjMDNmZjViMSxWcXYzazRZeA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F630634164690075648%2Fskygrid-drone-automation-app&amp;m=0&amp;ts=1601627250">SkyGrid</a>.</i></p><p><b>Source: <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.prnewswire.com%2Fnews-releases%2Fskygrid-launches-all-in-one-drone-app-to-automate-every-phase-of-flight-301139488.html&amp;t=Y2RlOTYwMjdhOGIyZWJkOGIwODcyYjI3ZjI1NjE4ZmFjMDNmZjViMSxWcXYzazRZeA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F630634164690075648%2Fskygrid-drone-automation-app&amp;m=0&amp;ts=1601627250">SkyGrid</a></b></p><h2><b>Read Also</b></h2><p><a href="https://nuadox.com/post/183243493212/drones-search-and-rescue">Autonomous drones can help search and rescue after disasters</a></p>
                    
                      
                    
                    
                    
                    
                    
                    
                    
                    
                                             
                                <p><span>
                                    <p>
                                    
                                        <a href="https://nuadox.com/tagged/drone">drone</a>
                                    
                                        <a href="https://nuadox.com/tagged/drones">drones</a>
                                    
                                        <a href="https://nuadox.com/tagged/ai">ai</a>
                                    
                                        <a href="https://nuadox.com/tagged/artificial-intelligence">artificial intelligence</a>
                                    
                                        <a href="https://nuadox.com/tagged/computer-vision">computer vision</a>
                                    
                                        <a href="https://nuadox.com/tagged/aviation">aviation</a>
                                    
                                        <a href="https://nuadox.com/tagged/search-and-rescue">search and rescue</a>
                                    
                                        <a href="https://nuadox.com/tagged/disaster">disaster</a>
                                    
                                        <a href="https://nuadox.com/tagged/inspection">inspection</a>
                                    
                                    </p>
                                </span></p>
                                
                            </div>
                        </div>
                    </article>
                 
                </div></div>]]>
            </description>
            <link>https://nuadox.com/post/630634164690075648/skygrid-drone-automation-app</link>
            <guid isPermaLink="false">hacker-news-small-sites-24634034</guid>
            <pubDate>Tue, 29 Sep 2020 22:55:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Microservices: Architecture Nihilism in Minimalism's Clothes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24633840">thread link</a>) | @aratno
<br/>
September 29, 2020 | https://vlfig.me/posts/microservices | <a href="https://web.archive.org/web/*/https://vlfig.me/posts/microservices">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Some recent <a href="https://twitter.com/gergelyorosz/status/1247132806041546754" target="_blank" rel="nofollow noopener noreferrer">backtracking</a> <a href="https://twitter.com/copyconstruct/status/1247130488667394049" target="_blank" rel="nofollow noopener noreferrer">from</a> what we have been calling “Microservices” has sparked anew the debate around that software architecture pattern. It turns out that for increasingly more software people, having a backend with (<a href="https://www.infoq.com/presentations/monzo-microservices/" target="_blank" rel="nofollow noopener noreferrer">sometimes several</a>) hundreds of services wasn’t that great an idea after all. The debate has <a href="https://riak.com/posts/technical/microservices-please-dont/" target="_blank" rel="nofollow noopener noreferrer">been going on for a while</a> and much has already been said, but there are still a couple of things I’d like to say.</p>
<p><strong>TL;DR</strong> “Microservices” was a good idea taken too far and applied too bluntly. The fix isn’t just to dial back the granularity knob but instead to 1) focus on the split-join criteria as opposed to size; and 2) differentiate between the project model and the deployment model when applying them.</p>
<p>I explain. Allow me to rant a bit first.</p>


<p>There were three main reasons for the initial success of <em>microservices</em> as an architectural pattern for software: 1) forced modularisation, 2) weakened dependencies, and 3) an excuse for having no architecture. In order:</p>
<ol>
<li>In the monoliths of old, you could in theory enforce module boundaries. You could say that your <code>acme-helpers</code> or <code>acme-data-tools</code> could not depend on <code>acme-domain</code>, say, and you even had some tooling to enforce that, but it was fallible. Especially in big companies where these monoliths spanned more than a team’s cognitive horizon, violations of those boundaries were often a simple <code>import</code> away, and of course rife. Angry architects saw in microservices the promise of making those a thing of the past: now the developer is forced to only deal with the API. Codebases parted ways and calls were made to go down the network stack and back.</li>
<li>
<p>So then, one wouldn’t depend on a fellow service at build time, only at runtime. Great. Method calls became http calls. “Now we don’t need to care about dependencies” — actual people said this, as if the dependency wasn’t fundamental and instead just an accidental artifact of the build setup. Everybody brushed up on their HTTP and different server and client implementations, read all about REST and Soap (and RPC, RMI and CORBA while at it) and merrily created a layer of indirection between modules — now <em>services</em> — that was <em>very</em> loose. Typed APIs, granular network policies and contract testing came much later.</p>
<p>It felt liberating until the complexities of API versioning, delivery semantics, error propagation, distributed transaction management and the sprawl of client code in all callers of a service began to show up. This was a gigantic <strong>shift right</strong>, but hey, the build process was simpler.</p>
</li>
<li>
<p>More insidious perhaps was the validation that “doing microservices” brought to organisations that lacked a thesis about how their architecture should be. There was now a sanctioned answer to most architectural dilemmas: another microservice. Another entry in the service catalog for any and all interested parties to call. This ecology of interacting parties, each acting in their own interest for the common good spoke to an underlying, tacit belief that the emergent mesh of services would approximate the latent natural architecture of the domain.</p>
<p>So soft and convenient was the lure of not having to draw hard architectural lines that we got lazy where we weren’t and accepted our lazyness where we already were. If you didn’t subscribe to that belief, the problem was you and your lack of understanding of complex systems, you objectivist cretin.</p>
</li>
</ol>
<p>Yes, there was real pain in managing monoliths and sure, many systems were too monolithic (i.e. had deployables too large) but the zealotry of a newfound purity swung the pendulum too far, as they always do. Not only do we not need to run so many services so small, we also don’t benefit from isolating their codebases so much. To summarise:</p>
<ol>
<li>having a big flat permissive build is no good reason to split deployables;</li>
<li>weakening dependencies between different parts of our systems is a “shift-right” loan with high interest; and</li>
<li>having a ready answer when the thinking gets tough is a soothing lie that just moves complexity about. There is no substitute to the effortful application of cognitive power to a problem.</li>
</ol>

<p>Two things: focus on the right criteria for splitting a service instead of on its size, and apply those criteria more thoughtfully.</p>
<h2 id="size-is-not-the-answer"><a href="#size-is-not-the-answer" aria-label="size is not the answer permalink"></a>Size is not the answer</h2>
<p>The <em>micro</em> in microservices ought to be at best a prediction, never a goal. We may predict services <em>will be</em> micro but they don’t <em>have to be</em>. <a href="https://kalele.io/microservices-and-microservices/" target="_blank" rel="nofollow noopener noreferrer">Vaugh Vernon is right</a> when he speaks about “cohesion for a reason”.</p>
<p>There should be no prescribed <em>a priori</em> granularity of services. There <em>is</em> no prescribed size of a service. There are instead <strong>good and bad reasons to split</strong> parts of a software system.</p>
<p>So the heuristic is:</p>
<div data-language="text"><pre><code>                      Start one, split with a reason.</code></pre></div>
<p>Conversely, if a reason ceases to exist, consider joining them.</p>
<h2 id="the-missing-hinge"><a href="#the-missing-hinge" aria-label="the missing hinge permalink"></a>The missing hinge</h2>
<p>There are however different realms in which “software systems” exist: they exist both as artifacts we interact with and as artifacts computers interact with. Code and binary. We organise them in different ways: the <strong>project model</strong> (repositories, projects, modules and their dependencies) and the <strong>deployment model</strong> (what production environments look like and how deployables run in them).</p>
<figure>
    <span>
      <a href="https://vlfig.me/static/8123a14a0e4efcacfddc6f26f7ad3e78/6246a/monolith.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="A monolithic setup where one big repo builds one single big deployable." title="A monolithic setup where one big repo builds one single big deployable." src="https://vlfig.me/static/8123a14a0e4efcacfddc6f26f7ad3e78/6a068/monolith.jpg" srcset="https://vlfig.me/static/8123a14a0e4efcacfddc6f26f7ad3e78/09b79/monolith.jpg 240w,
https://vlfig.me/static/8123a14a0e4efcacfddc6f26f7ad3e78/7cc5e/monolith.jpg 480w,
https://vlfig.me/static/8123a14a0e4efcacfddc6f26f7ad3e78/6a068/monolith.jpg 960w,
https://vlfig.me/static/8123a14a0e4efcacfddc6f26f7ad3e78/644c5/monolith.jpg 1440w,
https://vlfig.me/static/8123a14a0e4efcacfddc6f26f7ad3e78/6246a/monolith.jpg 1463w" sizes="(max-width: 960px) 100vw, 960px" loading="lazy">
  </a>
    </span>
    <figcaption><p>A monolithic setup where one big repo builds one single big deployable.</p></figcaption>
  </figure>
<p>In the process of going from coarse to granular (i.e. from monolith to microservices) however, little attention was paid to the difference — and possible indirection — between those two models. The hammer hit both fairly indiscriminately and made us split codebases because of runtime concerns and split deployables due to project concerns.</p>
<figure>
    <span>
      <a href="https://vlfig.me/static/fd7e19a50516d91d0b3a84dd16e262ca/6c0a0/stiff-1-1.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="A set of repositories each building their own self-contained independent service." title="Excessive mirroring between the project and deployment models." src="https://vlfig.me/static/fd7e19a50516d91d0b3a84dd16e262ca/6a068/stiff-1-1.jpg" srcset="https://vlfig.me/static/fd7e19a50516d91d0b3a84dd16e262ca/09b79/stiff-1-1.jpg 240w,
https://vlfig.me/static/fd7e19a50516d91d0b3a84dd16e262ca/7cc5e/stiff-1-1.jpg 480w,
https://vlfig.me/static/fd7e19a50516d91d0b3a84dd16e262ca/6a068/stiff-1-1.jpg 960w,
https://vlfig.me/static/fd7e19a50516d91d0b3a84dd16e262ca/6c0a0/stiff-1-1.jpg 1062w" sizes="(max-width: 960px) 100vw, 960px" loading="lazy">
  </a>
    </span>
    <figcaption><p>Excessive mirroring between the project and deployment models.</p></figcaption>
  </figure>
<p>Much like stiffness in a part of the human spine can result in pain in another, <strong>stiffness in our build DAGs is causing excessive mirroring between our project and deployment models</strong>; between our repositories and our services; between the way we organise our code and the way our services run. That mirroring is on the one hand preventing us from shifting left concerns about the relationships between modules that have often been made weak and fragile runtime dependencies, while on the other hand encouraging us to have more services than what the runtime reality would call for. That brings pain.</p>
<figure>
    <span>
      <a href="https://vlfig.me/static/1f3476e5c0b1320f4dd42084cfc102b9/dc6ba/hinge.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="The build DAG as a hinge between the project model and the deployment model." title="A build DAG mediates the project and the deployment models, absorbing the impedance mismatch between what is human friendly and what is machine-friendly." src="https://vlfig.me/static/1f3476e5c0b1320f4dd42084cfc102b9/6a068/hinge.jpg" srcset="https://vlfig.me/static/1f3476e5c0b1320f4dd42084cfc102b9/09b79/hinge.jpg 240w,
https://vlfig.me/static/1f3476e5c0b1320f4dd42084cfc102b9/7cc5e/hinge.jpg 480w,
https://vlfig.me/static/1f3476e5c0b1320f4dd42084cfc102b9/6a068/hinge.jpg 960w,
https://vlfig.me/static/1f3476e5c0b1320f4dd42084cfc102b9/dc6ba/hinge.jpg 1335w" sizes="(max-width: 960px) 100vw, 960px" loading="lazy">
  </a>
    </span>
    <figcaption><p>A build DAG mediates the project and the deployment models, absorbing the impedance mismatch between what is human friendly and what is machine-friendly.</p></figcaption>
  </figure>
<p>Central to resolving this stiffness is the realisation that the build flow, at least conceptually, is a DAG – Directed Acyclic Graph – where the nodes are <em>jobs</em> and <em>versioned artifacts</em> and the edges connect either a job to a versioned artifact (“produces”) or a versioned artifact to a jobs (“dependency_of”). Deployables are by definition the versioned artifacts that are consumed by the deployment jobs.</p>
<figure>
    <span>
      <a href="https://vlfig.me/static/e029adab126c3c2556e80d1647accb16/50066/dag.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="A graph of two types of nodes, jobs and versioned artifacts, connected by edges 'dependency_of' and 'produces'. Versioned artifacts can be further specialised." title="A graph of two types of nodes, jobs and versioned artifacts, connected by edges 'dependency_of' and 'produces'. Versioned artifacts can be further specialised." src="https://vlfig.me/static/e029adab126c3c2556e80d1647accb16/6a068/dag.jpg" srcset="https://vlfig.me/static/e029adab126c3c2556e80d1647accb16/09b79/dag.jpg 240w,
https://vlfig.me/static/e029adab126c3c2556e80d1647accb16/7cc5e/dag.jpg 480w,
https://vlfig.me/static/e029adab126c3c2556e80d1647accb16/6a068/dag.jpg 960w,
https://vlfig.me/static/e029adab126c3c2556e80d1647accb16/50066/dag.jpg 1384w" sizes="(max-width: 960px) 100vw, 960px" loading="lazy">
  </a>
    </span>
    <figcaption><p>A graph of two types of nodes, jobs and versioned artifacts, connected by edges ‘dependency_of’ and ‘produces’. Versioned artifacts can be further specialised.</p></figcaption>
  </figure>
<p>For too long we overlooked how much a flexible and frictionless build DAG allows us to improve our architecture on both sides. With moderately rich build patterns we can have our code where its intent is clearer and more constraints can be validated at build time and still have it deployed into its simplest viable form, running where its execution is cheaper, faster and safer.</p>
<figure>
    <span>
      <a href="https://vlfig.me/static/08e9b2a03b92afa1c2b43018fb141eb0/a18e1/wedding-altar.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="Cheesy cisgender, neurotypical westernised image of a wedding altar with the build dag marrying developer effectiveness with mechanical sympathy." title="Sorry. I had to." src="https://vlfig.me/static/08e9b2a03b92afa1c2b43018fb141eb0/a18e1/wedding-altar.jpg" srcset="https://vlfig.me/static/08e9b2a03b92afa1c2b43018fb141eb0/09b79/wedding-altar.jpg 240w,
https://vlfig.me/static/08e9b2a03b92afa1c2b43018fb141eb0/7cc5e/wedding-altar.jpg 480w,
https://vlfig.me/static/08e9b2a03b92afa1c2b43018fb141eb0/a18e1/wedding-altar.jpg 612w" sizes="(max-width: 612px) 100vw, 612px" loading="lazy">
  </a>
    </span>
    <figcaption><p>Sorry. I had to.</p></figcaption>
  </figure><p>.</p>
<h3 id="why-so-stiff-bro"><a href="#why-so-stiff-bro" aria-label="why so stiff bro permalink"></a>Why so stiff, bro?</h3>
<p>I’m not sure what the historically accurate account is that would explain the excessive simplicity of build patterns across the industry. I do know from experience that too many practices make do with very simple and linear flows where one repository builds independently one and only one service. Regardless of the legitimate argument about code duplication and its tradeoffs, there seems to be an aversion to build-time internal dependencies, even when these bring in clearly desirable data or logic such as message format definitions.</p>
<p>I suspect it might have something to do with how very few CI tools support composition natively (i.e. the outputs of jobs being able to be the inputs of others), how fallible semantic versioning in practice is and the difficulty of automating deterministic version propagation.</p>
<p>By that I mean keeping local copies in sync with CI, builds repeatable, and new upstream versions automatically used by their downstream dependents. It isn’t trivial and requires some versioning and build-fu that, to my knowledge, most practices end up shortcutting to either sacrifice repeatability by using <code>latest</code> or stifling the flow by requiring repeated manual work. Hence the pressure to have a simple build setup.</p>
<p>The exact cause is unimportant though. What is important is that overcoming this is crucial.</p>

<p>Many criteria for splitting or joining software systems, ranging from the social (teams, bounded contexts) to the mechanical (cpu or io boundedness) have been put forth, and they all make some form of sense. However, most of them are either a good reason to split projects or modules, or a good reason to split deployables, rarely both. Keeping that in mind will help us apply them more effectively.</p>
<p>Below are a few possible criteria and some comments about their application. I’m not trying to be exhaustive, just illustrating the kind of reasoning makes sense to me.</p>
<h2 id="runtime-deployment-side-criteria"><a href="#runtime-deployment-side-criteria" aria-label="runtime deployment side criteria permalink"></a>Runtime, deployment side criteria</h2>
<ul>
<li><strong>Different Runtime</strong> – If a part of the codebase compiles to a different runtime it becomes a different deployable and we call it a different service.</li>
<li><strong>Elasticity Profile</strong> – Some parts of the system may have a spikier load profile. It might pay off to have them scale in and out separately from the rest.</li>
<li><strong>Load Type</strong> – Some parts of a generally latency-oriented io-bound system may generate occasional peaks of cpu-bound load which can hurt response times. It might be better to put them in a …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vlfig.me/posts/microservices">https://vlfig.me/posts/microservices</a></em></p>]]>
            </description>
            <link>https://vlfig.me/posts/microservices</link>
            <guid isPermaLink="false">hacker-news-small-sites-24633840</guid>
            <pubDate>Tue, 29 Sep 2020 22:33:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Data Engineer Interview Study Guide]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24633780">thread link</a>) | @dataguy12
<br/>
September 29, 2020 | https://www.coriers.com/the-interview-study-guide-for-data-engineers/ | <a href="https://web.archive.org/web/*/https://www.coriers.com/the-interview-study-guide-for-data-engineers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-content">
					<p>Interviewing for any technical position generally requires preparing, studying and long-all day interviews. As a data engineer, what we need to study is not always clear. Some positions require Hadoop, others SQL, some roles require understanding statistics while still others require heavy amounts of system design.</p>
<p>We have gathered many of the resources that we have used to study and get jobs at companies int the FAANG family as well as other major tech companies. We have yet to find one that requires you to know anything about Hadoop during the interview so that has not bee included in this study guide.</p>
<p>However, as part of this study guide we have created the checklist. Sometimes, studying for interviews can feel like you are getting nothing done. Thus, this checklist will help you keep track so you know where to improve and what you have done.<a href="https://docs.google.com/spreadsheets/d/1GOO4s1NcxCR8a44F0XnsErz5rYDxNbHAHznu4pJMRkw/edit?usp=sharing"> You can find the checklist here.</a></p>
<p><a target="_blank" rel="noopener" href="https://docs.google.com/spreadsheets/d/1GOO4s1NcxCR8a44F0XnsErz5rYDxNbHAHznu4pJMRkw/edit#gid=0"><span>Download The Data Engineering Interview Checklist</span></a></p><p><strong>Outline</strong></p>
<ol>
<li>SQL Pre-Video Problems</li>
<li>SQL Videos</li>
<li>SQL Post Video Problems</li>
<li>Database, Data Warehouse And ETL Design</li>
<li>Algorithm And Data Structures Programming Problems</li>
<li>Operational Programming Problems</li>
<li>System Design Videos</li>
<li>Udemy Courses</li>
<li>Books</li>
</ol>
<h3><strong>SQL&nbsp;</strong></h3>
<p><span>As a data engineer it is almost inevitable that you will get some SQL questions. As someone who has participated in many interviews for a lot of top tech companies like Amazon and Capital One. They usually follow some similar patterns. </span></p>
<p><span>Typically there will be at least one question that requires an aggregation with a filter, another that requires a few joins and then one that requires a subquery. Along with that, there might be a few curve ball questions that require self-joins, recursions and analytic functions. So let’s look at a couple concepts that are good to cover</span></p>
<p><img src="https://i0.wp.com/www.coriers.com/wp-content/uploads/2019/05/d1e66b8f46fed3b4fb839e9b41025f82.gif?resize=450%2C164&amp;ssl=1" alt="" width="450" height="164" data-recalc-dims="1"></p>
<h4>SQL Pre-Video Problems</h4>
<p>These first few problems will help you gauge where you are on different concepts. That way you can take notes on the <a href="https://docs.google.com/spreadsheets/d/1GOO4s1NcxCR8a44F0XnsErz5rYDxNbHAHznu4pJMRkw/edit?usp=sharing">study guide</a> and go back and review what you feel you were not comfortable with.</p>
<h4><strong>Join with Aggregation</strong></h4>
<p><strong><a href="https://leetcode.com/problems/trips-and-users/">262.&nbsp;Trips and Users</a></strong></p>
<p><strong>Problem:</strong> The <code>Trips</code>&nbsp;table holds all taxi trips. Each trip has a unique Id, while Client_Id and Driver_Id are both foreign keys to the Users_Id at the&nbsp;<code>Users</code>&nbsp;table. Status is an ENUM type of (‘completed’, ‘cancelled_by_driver’, ‘cancelled_by_client’).</p>
<p><span>This is usually the 3rd or 4th style of question.</span></p>
<h4><strong>Sql Questions With Complex Logic</strong></h4>
<p><span>Sometimes, you get lucky and only have to deal with SQL questions that involve one point o logic. Sometimes it gets a little trickier. For instance this question asks you to both find cities with 3 consecutive rows and has populations over 100. </span></p>
<p><span>This is usually pretty easy to do when you are working, but can sometimes be a little difficult when you are in the middle of an interview.</span></p>

<p><strong><a href="https://leetcode.com/problems/human-traffic-of-stadium/">601. Human Traffic of Stadium</a></strong></p>
<p><strong>Problem:</strong> X city built a new stadium, each day many people visit it and the stats are saved as these columns:&nbsp;<b>id</b>,&nbsp;<strong>visit_</strong><b>date</b>,&nbsp;<b>people</b></p>
<p>Please write a query to display the records which have 3 or more consecutive rows and the amount of people more than 100(inclusive).</p>

<p><strong><a href="https://leetcode.com/problems/department-top-three-salaries/">185.&nbsp;Department Top Three Salaries</a></strong></p>
<p><strong>Problem: </strong>Write a SQL query to find employees who earn the top three salaries in each of the department. For the above tables, your SQL query should return the following rows (order of rows does not matter).</p>

<p><strong><a href="https://leetcode.com/problems/rising-temperature/">197.&nbsp;Rising Temperature</a></strong></p>
<p><strong>Problem: </strong>Given a&nbsp;<code>Weather</code>&nbsp;table, write a SQL query to find all dates’ Ids with higher temperature compared to its previous (yesterday’s) dates.</p>

<h4><strong>Advanced Join</strong></h4>
<p><strong><a href="https://leetcode.com/problems/exchange-seats/">626. Exchange Seats</a></strong></p>
<p><strong>Problem: </strong>Mary is a teacher in a middle school and she has a table&nbsp;<code>seat</code>&nbsp;storing students’ names and their corresponding seat ids.</p>
<p>The column&nbsp;<b>id</b>&nbsp;is continuous increment.</p>
<p>Mary wants to change seats for the adjacent students.</p>
<p>Can you write a SQL query to output the result for Mary?</p>
<p><a id="508752" href="https://constant-contact.ibfwsl.net/c/2043780/508752/3411"><img src="https://a.impactradius-go.com/display-ad/3411-508752" alt="Help grow your blog with Constant Contact email marketing" width="300" height="250"></a><img src="https://constant-contact.ibfwsl.net/i/2043780/508752/3411" width="0" height="0"></p>
<h4><strong>Simple Joins</strong></h4>
<p><strong><a href="https://www.hackerrank.com/challenges/the-report/problem">The Report</a></strong></p>
<p><em><strong>Problem: </strong>Ketty</em>&nbsp;gives&nbsp;<em>Eve</em> a task to generate a report containing three columns: <em>Name</em>,&nbsp;<em>Grade</em>&nbsp;and&nbsp;<em>Mark</em>.&nbsp;<em>Ketty</em>&nbsp;doesn’t want the NAMES of those students who received a grade lower than&nbsp;<em>8</em>. The report must be in descending order by grade — i.e. higher grades are entered first. If there is more than one student with the same grade (8-10) assigned to them, order those particular students by their name alphabetically. Finally, if the grade is lower than 8, use “NULL” as their name and list them by their grades in descending order. If there is more than one student with the same grade (1-7) assigned to them, order those particular students by their marks in ascending order.</p>
<p>Write a query to help Eve.<img src="https://ad.linksynergy.com/fs-bin/show?id=GjbDpcHcs4w&amp;bids=507388.2192850&amp;type=2&amp;subid=0" width="1" height="1"><br>
<img src="https://ad.linksynergy.com/fs-bin/show?id=GjbDpcHcs4w&amp;bids=596027.14166323990&amp;type=2&amp;subid=0" width="1" height="1"></p>
<h4><strong>Ranking, Row Numbers And Analytic Functions</strong></h4>
<p><strong><a href="https://leetcode.com/problems/nth-highest-salary/">177.&nbsp;Nth Highest Salary</a></strong></p>
<p><strong>Problem: </strong>Write a SQL query to get the&nbsp;<em>n</em><sup>th</sup>&nbsp;highest salary from the&nbsp;<code>Employee</code>table.<br>
<img src="https://ad.linksynergy.com/fs-bin/show?id=GjbDpcHcs4w&amp;bids=596027.816&amp;type=4&amp;subid=0" width="1" height="1"></p>
<h4>Complex Self Joins</h4>
<p><strong><a href="https://www.hackerrank.com/challenges/symmetric-pairs/problem">Symmetric Pairs</a></strong></p>
<p><strong>Problem: </strong>You are given a table,&nbsp;<em>Functions</em>, containing two columns:&nbsp;<em>X&nbsp;</em>and&nbsp;<em>Y</em>.</p>
<p>Two pairs&nbsp;<em>(X<sub>1</sub>, Y<sub>1</sub>)</em>&nbsp;and&nbsp;<em>(X<sub>2</sub>, Y<sub>2</sub>)</em>&nbsp;are said to be&nbsp;<em>symmetric</em>&nbsp;<em>pairs</em>&nbsp;if&nbsp;<em>X<sub>1</sub>&nbsp;= Y<sub>2</sub></em>&nbsp;and&nbsp;<em>X<sub>2</sub>&nbsp;= Y<sub>1</sub></em>.</p>
<p>Write a query to output all such&nbsp;<em>symmetric</em>&nbsp;<em>pairs</em>&nbsp;in ascending order by the value of&nbsp;<em>X</em>.</p>
<p><span>If you need more SQL try these one as well:</span></p>
<p><strong><a href="https://www.hackerrank.com/challenges/occupations/problem">Occupations</a></strong></p>
<p><strong><a href="https://www.hackerrank.com/challenges/harry-potter-and-wands/problem">Ollivander’s Inventory</a></strong></p>


<h4><strong>Videos:</strong></h4>
<p><strong>IQ15: 6 SQL Query Interview Questions</strong></p>
<p><span><iframe type="text/html" width="893" height="503" src="https://www.youtube.com/embed/uAWWhEA57bE?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span></p>

<p><a href="https://www.youtube.com/watch?v=QFj-hZi8MKk"><strong>Learning about ROW_NUMBER and Analytic Functions</strong></a></p>
<p><a href="https://www.youtube.com/watch?v=G3kYPzLWtpo&amp;t=4s"><strong>Advanced Implementation Of Analytic Functions Running Total</strong></a></p>
<p><a href="https://www.youtube.com/watch?v=XecU6Ieyu-4&amp;t=54s"><strong>Advanced Implementation Of Analytic Functions Median</strong></a></p>
<p><a href="https://www.youtube.com/watch?v=2-1XQHAgDsM&amp;list=PL6EDEB03D20332309"><strong>Wise Owl SQL Videos</strong></a></p>
<h3>Post Video SQL Problems</h3>
<p>Once you have finished watching the SQL videos above. Consider trying the new problems below. Try to see if you feel like you are improving. Again, note down any specific topics you feel weak on.</p>
<p><strong><a href="https://www.hackerrank.com/challenges/binary-search-tree-1/problem">Binary Tree Nodes</a></strong></p>
<p><strong><a href="https://leetcode.com/problems/big-countries/">595.&nbsp;Big Countries</a></strong></p>
<p><strong><a href="https://leetcode.com/problems/exchange-seats/" target="_blank" rel="noopener noreferrer">626. Exchange Seats</a></strong></p>
<p><strong><a href="https://www.hackerrank.com/challenges/weather-observation-station-18/problem">Weather Observation Station 18</a></strong></p>
<p><strong><a href="https://www.hackerrank.com/challenges/challenges/problem">Challenges</a></strong></p>
<p><strong><a href="https://www.hackerrank.com/challenges/print-prime-numbers/problem">Print Prime Numbers</a></strong></p>
<p><strong><a href="https://data36.com/sql-interview-questions-tech-screening-data-analysts/">SQL Interview Questions: 3 Tech Screening Exercises (For Data Analysts)</a></strong></p>

<h3><strong>Databases, ETL and Data Warehouses</strong></h3>
<p><img src="https://i0.wp.com/www.coriers.com/wp-content/uploads/2019/05/MySQL-Sample-Database-Schema.png?resize=429%2C343&amp;ssl=1" alt="database interview questions" width="429" height="343" srcset="https://i0.wp.com/www.coriers.com/wp-content/uploads/2019/05/MySQL-Sample-Database-Schema.png?w=701&amp;ssl=1 701w, https://i0.wp.com/www.coriers.com/wp-content/uploads/2019/05/MySQL-Sample-Database-Schema.png?resize=300%2C240&amp;ssl=1 300w" sizes="(max-width: 429px) 100vw, 429px" data-recalc-dims="1"></p>
<p>For database, ETL and data warehouse design questions we have gathered and even created some videos we hope will help you out when it comes to explaining your design in an interview. In addition, we have listed out a few plausible database/DW concepts you could attempt to design out on your own.</p>
<p>*We are working on making similar videos. <a href="https://forms.gle/yfMf7bnckZTyG6Ln7">Sign up to get future emails</a> about our videos.</p>
<p><a href="https://www.youtube.com/watch?v=I_rxqSJAj6U"><strong>Designing A Traditional Relational Database Video</strong></a></p>
<p><a href="https://www.youtube.com/watch?v=--OJpdPeH80"><strong>Data Warehouse Design Video</strong></a></p>
<p><strong>ETL Design Video</strong></p>
<p><span><iframe type="text/html" width="893" height="503" src="https://www.youtube.com/embed/sLhInuwdwcc?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span></p>


<h3>Self Practice Problems:</h3>
<p>For this part of your interview practice we are going to list out a few business systems that you can try to design out. First we recommend designing a relational database, then thinking about how you would design an ETL and DW that rely on that relational DB.</p>
<p>*In addition, we have found it very common that interviewers will base their interview questions off of your design. So think about some of the questions you could answer with your DB and list them out.</p>
<p>Design a Database/ETL and DW for a:</p>
<ul>
<li>Dating App</li>
<li>Bicycle Rental Service</li>
<li>Music Streaming App</li>
<li>Job Search Website</li>
<li>Udemy like website</li>
</ul>
<p>These are just a few ideas. We hope they help you have a clearer idea of what you can practice modeling and designing. Take some time to think about how users interact with these websites before getting started.</p>

<h2>Programming Problems</h2>
<p>Data engineers do a significant amount of programming in there daily life. There are several specific languages data engineers use. In particular, Python is arguable the most common.</p>
<p>If the role requires a lot of Hadoop work, then Java is also a useful language to have. There are a few other useful languages like Java and Powershell (if you work at a Microsoft shop).</p>
<p>There are two types of questions we have experienced. Some interviewers will ask you more operational questions. Others will ask classic algorithm and data structure questions.</p>
<p><img src="https://ad.linksynergy.com/fs-bin/show?id=GjbDpcHcs4w&amp;bids=596027.488&amp;type=4&amp;subid=0" width="1" height="1"></p>
<p>Below are list of them…</p>
<h3>Algorithms And Data Structures</h3>
<p>Before going to deep into data structure and algorithms. Let’s do a quick check to see how you are currently doing in this area. We have listed out 8 leetcode problems that vary in difficulty. Try these out and try to gauge yourself on how long it takes you as well as how many hints you needed. If you are following along with the study guide, then note this down. At the end of this list are a few more questions. So once you have watched all the videos, consider doing those problems and see if you feel like you are improving!</p>
<p><strong>Pre-Study Problems</strong></p>
<ol>
<li><strong><a href="https://leetcode.com/problems/sum-of-even-numbers-after-queries/">985. Sum of Even Numbers After Queries</a></strong></li>
<li><strong><a href="https://leetcode.com/problems/robot-return-to-origin/">657.&nbsp;Robot Return to Origin</a></strong></li>
<li><strong><a href="https://leetcode.com/problems/n-repeated-element-in-size-2n-array/">961.&nbsp;N-Repeated Element in Size 2N Array</a></strong></li>
<li><strong><a href="https://leetcode.com/problems/balanced-binary-tree/">110.&nbsp;Balanced Binary Tree</a></strong></li>
<li><strong><a href="https://leetcode.com/problems/longest-substring-without-repeating-characters/">3.&nbsp;Longest Substring Without Repeating Characters</a></strong></li>
<li><strong><a href="https://leetcode.com/problems/remove-nth-node-from-end-of-list/">19.&nbsp;Remove Nth Node From End of List</a></strong></li>
<li><strong><a href="https://leetcode.com/problems/merge-k-sorted-lists/">23.&nbsp;Merge k Sorted Lists</a></strong></li>
<li><strong><a href="https://leetcode.com/problems/next-permutation/">31.&nbsp;Next Permutation</a></strong></li>
</ol>

<p>Now that you have gone through these 8 questions, and shaken off the rust. Let’s start reviewing these concepts.</p>
<p><strong>Data Structures</strong></p>
<p><strong><a href="https://www.youtube.com/watch?v=bum_19loj9A">Data Structures &amp; Algorithms #1 – What Are Data Structures?</a></strong></p>
<p><strong><a href="https://youtu.be/njTh_OwMljA">Data Structures: Linked Lists</a></strong></p>
<p><strong><a href="https://youtu.be/oSWTXtMglKE" target="_blank" rel="noopener noreferrer">Data Structures: Trees</a></strong></p>
<p><strong><a href="https://youtu.be/t0Cq6tVNRBA" target="_blank" rel="noopener noreferrer">Data Structures: Heaps</a></strong></p>
<p><strong><a href="https://youtu.be/shs0KM3wKv8" target="_blank" rel="noopener noreferrer">Data Structures: Hash Tables</a></strong></p>
<p><strong><a href="https://youtu.be/wjI1WNcIntg" target="_blank" rel="noopener noreferrer">Data Structures: Stacks and Queues</a></strong></p>
<p><strong><a href="https://youtu.be/DuDz6B4cqVc" target="_blank" rel="noopener noreferrer">Data Structures: Crash Course Computer Science #14</a></strong></p>
<p><strong><a href="https://www.youtube.com/watch?v=zIjfhVPRZCg">Data Structures: Tries</a></strong></p>

<p><strong>Algorithms</strong></p>
<p><strong><a href="https://www.youtube.com/watch?v=p65AHm9MX80">Python Algorithms for Interviews</a></strong></p>
<p><strong><a href="https://www.youtube.com/watch?v=zaBhtODEL0w&amp;list=PLX6IKgS15Ue02WDPRCmYKuZicQHit9kFt">Algorithms: Graph Search, DFS and BFS</a></strong></p>
<p><strong><a href="https://youtu.be/P3YID7liBug">Algorithms: Binary Search</a></strong></p>
<p><strong><a href="https://youtu.be/KEEKn7Me-ms" target="_blank" rel="noopener noreferrer">Algorithms: Recursion</a></strong></p>
<p><strong><a href="https://youtu.be/6Gv8vg0kcHc" target="_blank" rel="noopener noreferrer">Algorithms: Bubble Sort</a></strong></p>
<p><strong><a href="https://youtu.be/KF2j-9iSf4Q" target="_blank" rel="noopener noreferrer">Algorithms: Merge Sort</a></strong></p>
<p><strong><a href="https://youtu.be/SLauY6PpjW4" target="_blank" rel="noopener noreferrer">Algorithms: Quicksort</a></strong></p>

<p><strong>Big O Notation</strong></p>
<p><strong><a href="https://www.youtube.com/watch?v=D6xkbGLQesk">Introduction to Big O Notation and Time Complexity (Data Structures &amp; Algorithms #7)</a></strong></p>
<p><strong>Some Interview Walk Throughs</strong></p>
<p><strong><a href="https://www.youtube.com/watch?v=5o-kdjv7FD0">Amazon Coding Interview Question – Recursive Staircase Problem</a></strong></p>
<p><strong><a href="https://www.youtube.com/watch?v=7HgsS8bRvjo">Google Coding Interview – Universal Value Tree Problem</a></strong></p>
<p><strong><a href="https://www.youtube.com/watch?v=GJdiM-muYqc">Google Coding Interview Question and Answer #1: First Recurring Character</a></strong></p>

<p><strong>Post Study Problems</strong></p>
<p>Once you have finished the videos above. Consider trying the algorithm and data structure problems below. Make sure you keep track of how comfortable you felt when working on the problems.</p>
<ol>
<li><strong><a href="https://www.hackerrank.com/challenges/bigger-is-greater/problem">Bigger Is Greater</a></strong></li>
<li><strong><a href="https://leetcode.com/problems/zigzag-conversion/">6.&nbsp;ZigZag Conversion</a></strong></li>
<li><strong><a href="https://leetcode.com/problems/reverse-integer/">7.&nbsp;Reverse Integer</a></strong></li>
<li><strong><a href="https://leetcode.com/problems/combination-sum-ii/">40.&nbsp;Combination Sum II</a></strong></li>
<li><strong><a href="https://leetcode.com/problems/multiply-strings/">43.&nbsp;Multiply Strings</a></strong></li>
<li><strong><a href="https://www.hackerrank.com/challenges/larrys-array/problem">Larry’s Array</a></strong></li>
<li><strong><a href="https://www.hackerrank.com/challenges/short-palindrome/problem">Short Palindrome</a></strong></li>
<li><strong><a href="https://leetcode.com/problems/valid-number/">65.&nbsp;Valid Number</a></strong></li>
</ol>

<p>If you still feel like you need help, then consider taking a course on <a href="https://click.linksynergy.com/deeplink?id=GjbDpcHcs4w&amp;mid=39197&amp;murl=https%3A%2F%2Fwww.udemy.com%2Fcoding-interview-bootcamp-algorithms-and-data-structure%2F">algorithms and data structures</a>.</p>
<h2>Operational Programming Problems</h2>
<p>Operational interview questions are harder to prep for. There are no “classic” interview questions here. However, they are also often easier to figure …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.coriers.com/the-interview-study-guide-for-data-engineers/">https://www.coriers.com/the-interview-study-guide-for-data-engineers/</a></em></p>]]>
            </description>
            <link>https://www.coriers.com/the-interview-study-guide-for-data-engineers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24633780</guid>
            <pubDate>Tue, 29 Sep 2020 22:26:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Syllabus for teaching Scratch programming to kids]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24633742">thread link</a>) | @mathnmusic
<br/>
September 29, 2020 | https://learnawesome.org/items/1c96e03a-ffff-4579-b69a-0387b968b7c6-syllabus-scratch-programming-for-kids | <a href="https://web.archive.org/web/*/https://learnawesome.org/items/1c96e03a-ffff-4579-b69a-0387b968b7c6-syllabus-scratch-programming-for-kids">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<p>I noticed that these days, a lot of parents are being pressured by edtech industry to buy paid courses on "programming for kids" which are all simply using Scratch with bad instructions. Worse, many of them are using industrial languages like Javascript or Python which are completely unsuitable for the purpose of pedagogy. So, I have put together this syllabus/sequence of high-quality learning resources (apps/free courses/articles/videos) that I followed for my own daughter with spectacular success.</p>

<p>We have a peer group of parents and children learning Scratch programming using this syllabus. If you'd like to join, come to <a href="https://learnawesome.org/join_slack">our Slack group</a>.</p>

<h2>Why learn Scratch programming?</h2>

<p>Computational thinking skills may have a lot of practical value. It helps kids understand how computers work, and how to make new things with them. But <a href="https://twitter.com/nileshtrivedi/status/1261600393382883329">if you think programming is all about computers, you're wrong</a>. The core idea of programming is that a tiny set of simple instructions can be combined to produce immensely complex structures. We see this in cooking, knitting, chess, mathematics and much more. Your DNA, for example, is a series of instructions or a  "program".</p>

<p>But more importantly, programming is the only skill that lets you create "interactive" art. Other creators have "readers", "audience", "spectators" etc, but only programmers have "users". <a href="https://twitter.com/nileshtrivedi/status/1261601737854472192">If you haven't felt the joy of programming, you're really missing out</a>.</p>

<p>This joy is what should be the main motivation for teaching programming to kids. Not career success. We don't know what careers will be in vogue 15 years from now, but the joy of creation is an eternal human blessing.</p>

<p>Scratch is a visual programming language, built at MIT, that is used by children all over the globe. This visual language is in the shape of blocks (like Lego), and it allows its users to create online projects, games, apps, and many other things. The blocks eliminate the major source of frustration which comes from syntax errors. Scratch has a very active online community which makes this experience very engaging for kids, and they also learn collaboration and teamwork - besides figuring out how programs work.</p>

<p>Scratch, which is completely free, is what's being used by many edtech platforms. You don't need to pay a lot of money for paid courses because I have collected the best quality resources here for you and put them in a sequence that is not rushed.</p>

<p>In my opinion, it would be a mistake to start too soon with industrial languages like Python, Javascript because the child would be intimidated with a lot of details that only distract. Motivation is the #1 resource with the shortest supply. Do whatever you can to preserve it. I'd actually explore computer games like Age of Empires which provoke questions in their minds: "I wonder how they wrote code for this game!".</p>

<h2>Preparedness:</h2>

<p>Can the child count things correctly? It's NOT easy. Suppose your boss wants you to work from 8am to 11am, and mop floors 8 to 11. Simple - it's one floor per hour, right?</p>

<p>Nope! There are 4 floors to mop (8, 9, 10 and 11) but only 3 hours to work (8-9, 9-10, and 10-11).</p>

<p>Whoa -- we count floors and hours differently? You bet. And somehow, if the boss said "Mop floors 8 to 11 on April 8th to 11th" everything would be ok.</p>

<p>To understand this, read <a href="https://learnawesome.org/items/b269d560-c519-4242-91d5-66ad547cc43b-learning-how-to-count-avoiding-the-fencepost-problem-betterexplained">this article</a> under <a href="https://learnawesome.org/topics/b49bc6fd-b9bc-46c9-a6d3-ebcef2f01b07-counting">Counting</a></p>

<p>Does the child have some exposure to 2D coordinate systems? It's not a prerequisite, but will have to be discussed during the practice stage.
When you reach that stage, use resources from our <a href="https://learnawesome.org/topics/9d1d4677-7ebd-4077-9f1f-218806a340e9-coordinate-plane">co-ordinate plane topic</a>.</p>

<p>Is any one of the parents experienced with <a href="https://learnawesome.org/topics/13b5f596-e6e4-4a45-81f1-843ff7b42d82-computational-thinking">computational thinking</a>? If not, they too should go through this Scratch course. Following along with the child is also fine.</p>

<p>Do you have a computing device at home (a desktop / laptop / tablet)?</p>

<p>Parents should read <a href="https://scratch.mit.edu/parents/">this</a> and <a href="https://learnawesome.org/items/7a92e34a-982d-4d02-8c58-17de1de7f5db-scratch-team-scratch-twitter">follow the Scratch team on Twitter</a></p>

<h2>Motivation and priming:</h2>

<p>A lot of difficulty in programming is how it requires you to be very precise with language and instructions. Bringing this sensitivity is important. You can watch the <a href="https://www.youtube.com/watch?v=cDA3_5982h8">"Exact Instructions Challenge" videos</a>.</p>

<p>It is also important to create the REASON/MOTIVATION to learn Scratch such as to create your own games. So, first you should explore games made on <a href="https://learnawesome.org/items/3e9de8b8-ef9f-4a61-a091-6608d264b1a4-scratch-homepage">Scratch website</a>. See what is possible with Scratch. Remember, kids want to DO interesting things, and not LEARN something.</p>

<h2>Experience:</h2>

<p>Cooking is not very different from algorithms. You can start in the kitchen. Parent and child can enact any of the  <a href="https://www.youtube.com/watch?v=cDA3_5982h8">"Exact Instructions Challenges"</a> on their own. You might want to record a video, but no need to publish it anywhere.</p>

<p>After this, I recommend playing at least the first two levels of the programming puzzle game <a href="https://learnawesome.org/items/2d6e8e6d-0e95-46d6-a4b8-0cf8d83c1634-lightbot">Lightbot</a>. It's a free app which gives a highly-constrained and playful environment for algorithmic thinking that feels like playing a game instead of "learning". Remember, kids want to be able to "do" interesting stuff, not "learn" something.</p>

<p>Avoid <a href="https://learnawesome.org/items/9d0fe359-b80a-4446-bdd5-c7e62afbbccc-scratchjr-home">Scratch Junior</a>. It's better to stop after Lightbot and wait for them to be ready for main Scratch.</p>

<h2>Instruction and Practice:</h2>

<p>Scratch is available both as a website and as an <a href="https://scratch.mit.edu/download">app that works offline</a>.</p>

<p>First try the <a href="https://scratch.mit.edu/projects/editor/?tutorial=getStarted">interactive online tutorial</a>.</p>

<p>More tutorials are available <a href="https://scratch.mit.edu/ideas">here</a>.</p>

<p>Now we are ready for a "course".  <a href="https://learnawesome.org/items/a2dbab26-0c93-49b7-ae52-105f312c075a-programming-in-scratch">The best one is this free course on edX</a> which will explain all the concepts in detail. Complete it as far as you can. Remember to try things out. Coding, like swimming, can only be learnt by doing.</p>

<p>You can join other parents going through this syllabus in <a href="https://learnawesome.org/join_slack">our Slack group</a>. :-)</p>

<h2>Getting help:</h2>

<p>Instead of helping you once, we will teach you how to find help yourself on the Internet:</p>

<ul>
<li>Try these <a href="https://learnawesome.org/items/8cb38a52-03a2-4587-8f20-efc404291590-getting-unstuck-strategies">strategies for getting unstuck</a> here.</li>
<li>Check on <a href="https://learnawesome.org/items/a7b45674-d23e-4d65-bc57-f80c07cf1ed9-scratch-wiki">Scratch wiki</a>.</li>
<li>And the <a href="https://learnawesome.org/items/08fdd0dc-792d-49b2-a24d-a0b16050cedc-discuss-scratch">Scratch forum</a>.</li>
<li>There's a <a href="https://learnawesome.org/items/6afac218-ee56-4539-b9f8-24d8d83125d9-teaching-with-scratch-public-group-facebook">Facebook group</a>.</li>
<li>Tweet to <a href="https://learnawesome.org/items/7a92e34a-982d-4d02-8c58-17de1de7f5db-scratch-team-scratch-twitter">Scratch team</a> or <a href="https://twitter.com/ScratchJr">Scratch Junior team</a></li>
<li>Ask fellow Scratch learners in <a href="https://learnawesome.org/join_slack">our Slack group</a></li>
</ul>

<h2>Performance:</h2>

<ul>
<li>Basic: The student should be able to Create a game with her own idea and publish it on scratch website.</li>
<li>Advanced: Complete this <a href="https://learnawesome.org/items/0db431c8-f480-4a96-8907-85fef9eb6a4a-creative-computing-lab-at-the-harvard-graduate-school-of-education">series of Scratch challenges</a>.</li>
</ul>

<h2>Learn from the experts</h2>

<ul>
<li><p>Let the kid play games on Scratch. They should know what "apps" are, before they get interested in how apps get made. Occasionally, they will get curious and click on the "See Inside" button to bypass a difficult game level. At that point, they are hacking in its true spirit. Count yourself as a successful parent at this point! 😄</p></li>
<li><p>Watch Scratch tutorials on YouTube, such as how to create their own platformer game in Scratch. Be patient at this point though. Let them make simpler games, stories etc before reaching this slightly difficult level.</p></li>
<li><p>Learn how to create custom blocks. This is a rough simulation of how functions work in industrial programming languages.</p></li>
</ul>

<h2>Teach:</h2>

<p>Your child should now teach Scratch to a friend or sibling. Teaching is one of the best ways to consolidate your <a href="https://learnawesome.org/topics/4e9769cb-5233-44fe-91d4-c49d601f6dbe-learning">learning</a>.</p>

<h2>What next after Scratch?</h2>

<p>Frankly, there is no need to rush. Scratch alone can expose them to a wide variety of programming techniques, but if you do want to go forward, try these topics:</p>

<ul>
<li><p><a href="https://learnawesome.org/topics/efde49a5-47bf-4689-88b1-303a7bca5f4b-programming-languages-snap">Snap!</a> This adds two key features to Scratch: Lists as a first-class object (so you can introduce data-structures like tree, stack, queue etc) and higher-order functions. But it doesn't have a great UI or an active community like Scratch does.</p></li>
<li><p><a href="https://learnawesome.org/topics/4cfd43da-19d7-40d4-b3d6-95297b1a31da-programming-languages-processing">Processing</a> is a textual language that still makes it easy to generate concrete, visual things like animations or games. It is important to work on concrete things because it shortens the feedback loop which is crucial for formation of concepts.</p></li>
<li><p><a href="https://learnawesome.org/topics/13b5f596-e6e4-4a45-81f1-843ff7b42d82-computational-thinking">Computational Thinking</a></p></li>
</ul>

<h2>Help us spread the word.</h2>

<p>We are building a community of lifelong learners. If you have landed here, you probably have an immense love for learning like us. We would love to have you join <a href="https://learnawesome.org/join_slack">our Slack group</a>.</p>

				
			
		</div></div>]]>
            </description>
            <link>https://learnawesome.org/items/1c96e03a-ffff-4579-b69a-0387b968b7c6-syllabus-scratch-programming-for-kids</link>
            <guid isPermaLink="false">hacker-news-small-sites-24633742</guid>
            <pubDate>Tue, 29 Sep 2020 22:24:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nix-copy-closure your nix-shell]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24633664">thread link</a>) | @setheron
<br/>
September 29, 2020 | https://fzakaria.com/2020/09/28/nix-copy-closure-your-nix-shell.html | <a href="https://web.archive.org/web/*/https://fzakaria.com/2020/09/28/nix-copy-closure-your-nix-shell.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
    <p>
        Published 2020-09-28
        on <a href="https://fzakaria.com/">Farid Zakaria's Blog</a>
        <span>
          —
          <a href="https://fzakaria.com/2020/09/28/nix-copy-closure-your-nix-shell.html">
            Permalink
          </a>
        </span>
    </p>
    
    <article>
      <blockquote>
  <p>This is a synopsis of <a href="https://github.com/NixOS/nix/issues/1985">https://github.com/NixOS/nix/issues/1985</a>. I recommend reading it for additional detail. Many thanks to contributors on the issue like <a href="https://github.com/Infinisil">Infinisil</a> for adding context.</p>
</blockquote>

<p>Someone reached out to me over e-mail to discuss my previous post on <a href="https://fzakaria.com/2020/08/11/caching-your-nix-shell.html">caching your nix-shell</a>.</p>

<p><em>“What I wish to do is to copy a particular development environment (nix-shell)
from A to B, so that I could run nix-shell on server B. Server B is only accessible through SSH and <strong>does not</strong> have Internet access.”</em></p>

<!--more-->

<p>Seems straightforward, so let’s investigate. Let’s use a very basic <em>shell.nix</em> file.</p>

<blockquote>
  <p>Very important we make sure to pin <em>nixpkgs</em>. In the example below I do it inline in the Nix expression but you can also use <a href="https://github.com/nmattia/niv">niv</a> or pin the channel to a particular commit.</p>
</blockquote>

<div><div><pre><code><span>let</span>
  <span>nixpkgs</span> <span>=</span> <span>import</span> <span>(</span><span>builtins</span><span>.</span><span>fetchTarball</span> <span>{</span>
    <span>name</span> <span>=</span> <span>"nixos-unstable-2020-09-24"</span><span>;</span>
    <span>url</span> <span>=</span>
      <span>"https://github.com/nixos/nixpkgs/archive/5aba0fe9766a7201a336249fd6cb76e0d7ba2faf.tar.gz"</span><span>;</span>
    <span>sha256</span> <span>=</span> <span>"05gawlhizp85agdpw3kpjn41vggdiywbabsbmk76r2dr513188jz"</span><span>;</span>
  <span>})</span> <span>{</span> <span>};</span>
<span>in</span> <span>with</span> <span>nixpkgs</span><span>;</span>
<span>with</span> <span>stdenv</span><span>;</span>
<span>with</span> <span>stdenv</span><span>.</span><span>lib</span><span>;</span>
<span>mkShell</span> <span>{</span>
  <span>name</span> <span>=</span> <span>"example-shell"</span><span>;</span>
  <span>buildInputs</span> <span>=</span> <span>[</span> <span>hello</span> <span>];</span>
  <span>shellHook</span> <span>=</span> <span>''</span><span>
</span><span>    export MESSAGE="$(hello)";</span><span>
</span><span>  ''</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>Let’s see it in action:</p>
<div><div><pre><code>❯ nix-shell shell.nix

<span>[</span>nix-shell:~/code/nix/playground]<span>$ </span><span>echo</span> <span>$MESSAGE</span>
Hello, world!
</code></pre></div></div>

<p>Recently an improvement <a href="https://github.com/NixOS/nixpkgs/pull/95536">#95536</a> by <a href="https://github.com/Infinisil">Infinisil</a> made the workflow to discover the <em>transitive runtime closure</em> much simpler than what I had <a href="https://fzakaria.com/2020/08/11/caching-your-nix-shell.html">blogged about</a>.</p>

<p>✨ A new attribute for derivations <em>inputDerivation</em> is introduced that is <em>always buildable</em> and whose runtime dependences are it’s build dependencies; exactly what we need for nix-shell!</p>

<div><div><pre><code>❯ nix-build <span>--no-out-link</span> shell.nix <span>-A</span> inputDerivation
these derivations will be built:
  /nix/store/bjn4imm9dw7xnxpjrwyrpk0wsy0j7xwh-example-shell.drv
building <span>'/nix/store/bjn4imm9dw7xnxpjrwyrpk0wsy0j7xwh-example-shell.drv'</span>...
/nix/store/rw6i1wk9iv0286xi2b6kpw4ynk4pldyh-example-shell
</code></pre></div></div>

<p>We now have a store path <em>/nix/store/rw6i1wk9iv0286xi2b6kpw4ynk4pldyh-example-shell</em> which we can check the immediate dependencies.</p>

<blockquote>
  <p>The below is simply the <em>immediate</em> dependencies and not the full transitive closure for brevity.</p>
</blockquote>

<div><div><pre><code>❯ nix-store <span>--query</span> <span>--references</span> <span>\</span>
    /nix/store/rw6i1wk9iv0286xi2b6kpw4ynk4pldyh-example-shell

/nix/store/2jysm3dfsgby5sw5jgj43qjrb5v79ms9-bash-4.4-p23
/nix/store/333six1faw9bhccsx9qw5718k6b1wiq2-stdenv-linux
/nix/store/9krlzvny65gdc8s7kpb6lkx8cd02c25b-default-builder.sh
/nix/store/w9yy7v61ipb5rx6i35zq1mvc2iqfmps1-hello-2.10
/nix/store/rw6i1wk9iv0286xi2b6kpw4ynk4pldyh-example-shell
</code></pre></div></div>

<p>I will now copy the <em>shell.nix</em> file to my other machine &amp; copy the transitive closure to it.</p>
<div><div><pre><code>❯ scp shell.nix machine-b:~

❯ nix-copy-closure <span>--to</span> machine-b <span>\</span>
    /nix/store/rw6i1wk9iv0286xi2b6kpw4ynk4pldyh-example-shell
copying 36 paths...
</code></pre></div></div>

<p>Let’s hop on <em>machine B</em> and create a network namespace to pretend we do not have Internet access.</p>

<blockquote>
  <p>A network namespace is logically another copy of the network stack,
with its own routes, firewall rules, and network devices.</p>
</blockquote>

<div><div><pre><code>❯ ssh machine-b

<span># since we won't have any Internet access, hydrate the cache</span>
<span># with our nixpkgs version</span>
❯ nix-prefetch-url <span>--unpack</span> <span>\</span>
https://github.com/nixos/nixpkgs/archive/5aba0fe9766a7201a336249fd6cb76e0d7ba2faf.tar.gz <span>\</span>
<span>--name</span> <span>"nixos-unstable-2020-09-24"</span>

❯ <span>sudo </span>ip netns add nixshell
<span># enter the namespace</span>
❯ <span>sudo </span>ip netns <span>exec </span>nixshell su <span>$USER</span> <span>-c</span> zsh

<span># let's confirm we do not have Internet access</span>
❯ ping google.com
ping: google.com: Temporary failure <span>in </span>name resolution
</code></pre></div></div>

<p>Let’s fire up our <em>nix-shell</em> and see if it works.</p>

<div><div><pre><code><span># don't forget we are within our network namespace</span>
<span># without access to the Internet</span>
❯ nix-shell shell.nix
bash: cannot <span>set </span>terminal process group <span>(</span><span>-1</span><span>)</span>: Inappropriate ioctl <span>for </span>device
bash: no job control <span>in </span>this shell

<span>[</span>nix-shell:~]<span>$ </span><span>echo</span> <span>$MESSAGE</span>
Hello, world!
</code></pre></div></div>

<p>🎆 Huzzah!
We have now copied over our development environment <em>hermetically</em> with the help of Nix. This is a great demonstration of the power of Nix &amp; reproducibility.</p>

<blockquote>
  <p>An important take-away though is that it’s important to make sure <em>we pin</em> the exact version of <em>nixpkgs</em> otherwise the <em>nix-shell</em> may calculate different hashes.</p>
</blockquote>

<p>Do you have an interesting workflow or innovative use of Nix with development environments? <a href="mailto:farid.m.zakaria@gmail.com">Let me know about it.</a></p>


<hr>
    </article>
</div></div>]]>
            </description>
            <link>https://fzakaria.com/2020/09/28/nix-copy-closure-your-nix-shell.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24633664</guid>
            <pubDate>Tue, 29 Sep 2020 22:15:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How India Censors the Web]]>
            </title>
            <description>
<![CDATA[
Score 150 | Comments 43 (<a href="https://news.ycombinator.com/item?id=24633490">thread link</a>) | @srean
<br/>
September 29, 2020 | http://iamkush.me/how-india-censors-the-web/ | <a href="https://web.archive.org/web/*/http://iamkush.me/how-india-censors-the-web/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p><b>Update (11th April 2020): This paper has been accepted at <a href="https://websci20.webscience.org/">ACM Web Science 2020</a>. A preprint can be accessed on <a href="https://arxiv.org/pdf/1912.08590.pdf" target="_blank">arXiv</a>.</b></p>

<p>Nation states around the world engage in web censorship using a variety of legal and technical methods. India is no different in this regard: the Government of India can legally order internet service providers (ISPs) operating in its jurisdiction to block access to certain websites for its users. This makes the situation different from jurisdictions like Iran and China, where internet censorship is largely centralised. Legal provisions in India, namely Section 69A and Section 79 of the Information Technology (IT) Act, allow the Central Government and the various courts in the country to issue website-blocking orders that ISPs are legally bound to comply with. <strong>Most of these orders are not publically available</strong>.</p>

<p>Recent events and the opaque nature of internet censorship in India motivated us at <a href="https://cis-india.org/" target="_blank">The Center for Internet and Society</a> to study India's censorship mechanism in detail. We spent the last year trying to answer two questions pertaining to how internet users in India experience web censorship:</p>

<ol>  
<li>What are the technical methods of censorship used by ISPs in India?</li>  
<li>Are all ISPs blocking the same websites?</li>  
</ol>

<p><strong>Our work has been so far the largest study of web censorship in India</strong>, both in terms of the number of censorship mechanisms that we test for and the number of potentially-blocked websites (PBWs). </p>

<h3 id="datacuration">Data curation</h3>

<p>We compiled a list of PBWs from three sources:  </p>

<ul>  
<li><b>Government orders</b>: A website/URL blocking order may come from the Government of India (Section 69A, IT Act). These orders are usually not in the public domain, as a confidentiality clause prevents any party from disclosing its contents. We collect published and leaked Government orders.</li>  
<li><b>Court orders</b>: The various courts in India also have the power to issue website blocking orders (Section 79, IT Act). Not all such orders are available in the public domain. However, the Government and BSNL (a public company operating as an ISP) have provided portions of this list when under pressure to respond to Right to Information (RTI) requests.</li>  
<li><b>User reports</b>: <a href="https://internetfreedom.in/" target="_blank">The Internet Freedom Foundation</a> collects and publishes reports from internet users who notice blocked websites.</li>  
</ul>

<p>Collecting data from these sources led to a total of 9673 unique URLs, which yielded 5798 unique websites. To limit ourselves to active websites, we exclude all websites for which we could not resolve via Tor circuits, culminating in a corpus of 4379 PBWs.</p>

<h3 id="networktestsfordetectingcensorship">Network tests for detecting censorship</h3>

<p>We designed four network tests that probe the existence of censorship at the DNS, TCP, HTTP, and TLS level. For the sake of brevity, I'll skip elaborating on the tests in this post; the details can be found in our <a href="https://arxiv.org/pdf/1912.08590.pdf" target="_blank">preprint</a>.</p>

<p>We run these tests for each website in our corpus from connections of six different ISPs (Jio, Airtel, Vodafone, MTNL, BSNL, and ACT), <strong>which together serve more than 98% of Internet users in India</strong>. Our findings not only confirm that ISPs are using different techniques to block websites, but also demonstrate that different ISPs are not blocking the same websites.</p>

<h3 id="results">Results</h3>

<p>In terms of censorship methods, our results confirm that ISPs in India are at liberty to use any technical filtering mechanism they wish: there was, in fact, no single mechanism common across ISPs. </p>

<p>We observe ISPs to be using a melange of techniques for blocking access, such as DNS poisoning and HTTP host header inspection. <b>Our tests also discern the use of SNI inspection being employed by the largest ISP in India (Jio) to block HTTPS communication, the use of which is previously undocumented in the Indian context</b>.</p>

<p><img src="https://i.imgur.com/vDAgGnf.png" alt="img">
</p><center>Censorship techniques employed by Indian ISPs</center>

<p>Further, we notice that all ISPs using multiple censorship mechanisms are not blocking the same websites with each mechanism. For instance, ACT uses only DNS censorship for blocking 233 websites, only HTTP censorship for 1873 websites, and both to block 1615 websites. Such irregularities are illustrated below.</p>

<p><img src="https://i.imgur.com/azWaVJW.png" alt="img">
</p><center>Censorship techniques used by (i) ACT, (ii) Airtel, and (iii) Jio for blocking websites. We notice the same ISP using multiple techniques for blocking different websites.</center>

<h3 id="somealarmingdiscoveries">Some alarming discoveries</h3>

<p>Our study has recorded large inconsistencies in website blocklists of different Indian ISPs. From our list of 4379 PBWs, we find that 4033 are being blocked by at least one ISP’s blocklist. In terms of absolute numbers, we notice that ACT blocks the maximum number of websites (3721). Compared to ACT, Airtel blocks roughly half the number of websites (1892).</p>

<p>Perhaps most surprisingly, we find that only 1115 websites out of the 4033 (just 27.64%) are blocked by all six ISPs. <b>Simply stated, we find conclusive proof that Internet users in India can have wildly different experiences of web censorship.</b></p>

<p><img src="https://i.imgur.com/XXaRpuf.png" alt="img"></p>

<p>Analysing inconsistencies in blocklists also makes it clear that ISPs in India are:</p>

<ol>  
<li>Not properly complying with website blocking (or subsequent unblocking orders), and/or </li>  
<li>Arbitrarily blocking websites without the backing of a legal order.</li>  
</ol>

<p>This has important legal ramifications: <b>India’s <a href="https://bit.ly/netneutralityframework" target="_blank">Net Neutrality regulations</a>, codified in the license agreements that ISPs enter with the Government of India, explicitly prohibit such behaviour</b>.</p>

<p>Our study also points to how the choice of technical methods used by ISPs to censor websites can decrease transparency about state-ordered censorship in India. While some ISPs were serving censorship notices, other ISPs made no such effort. For instance, Airtel responded to DNS queries for websites it wishes to block with <strong>NXDOMAIN</strong>. Jio used <strong>SNI-inspection</strong> to block websites, a choice which makes it <strong>technically impossible for them to serve censorship notices</strong>. Thus, the selection of certain technical methods by ISPs exacerbates the concerns created by the opaque legal process that allows the Government to censor websites.</p>

<h3 id="summingup">Summing up</h3>

<p>Web censorship is a curtailment of the right to freedom of expression guaranteed to all Indians. There is an urgent need to reevaluate the legal and technical mechanisms of web censorship in India to make sure the curtailment is transparent, and the actors accountable. </p>

<p>The whimsical attitude towards web censorship from both ISPs and the Government necessitates the development of a crowdsourced tool to <strong>monitor and measure such censorship from different vantage points in the country</strong>. This will shed further light into the geographical variation of censorship practices by ISPs across India, which is still unclear.</p>

<p>To probe this further we have ported our network tests into an android application, and are looking for volunteers who are willing to run it on their mobile networks. The entire process will be <strong>completely anonymous</strong>; we will not be collecting any user-specific information. If you live in India, please consider running <a href="https://play.google.com/store/apps/details?id=com.censorwatch.netprobesapp">Censorwatch</a>.</p>

<p><strong>Acks</strong> - This study was done in collaboration with <a href="https://gurshabad.github.io/" target="_blank">Gurshabad Grover</a> and <a href="https://www.linkedin.com/in/bansalvarun96/" target="_blank">Varun Bansal</a> at <a href="https://cis-india.org/" target="_blank">The Center for Internet and Society</a>, graciously supported by the <a href="https://www.macfound.org/" target="_blank">MacArthur Foundation</a>.</p>
			</section></div>]]>
            </description>
            <link>http://iamkush.me/how-india-censors-the-web/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24633490</guid>
            <pubDate>Tue, 29 Sep 2020 21:55:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vitamin D and Covid: A Review]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24633248">thread link</a>) | @usefulcat
<br/>
September 29, 2020 | https://www.devaboone.com/post/vitamin-d-and-covid?postId=5f729cf1efb0ee0017940a2e | <a href="https://web.archive.org/web/*/https://www.devaboone.com/post/vitamin-d-and-covid?postId=5f729cf1efb0ee0017940a2e">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="7.19.2"><div dir="ltr"><div><div id="viewer-6p6al"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.devaboone.com/post/vitamin-d-and-covid?postId=5f729cf1efb0ee0017940a2e" data-pin-media="https://static.wixstatic.com/media/a27d24_e10b0ace71dc4bf5a0aa0e0dd52147fa~mv2.jpg/v1/fit/w_900,h_458,al_c,q_80/file.png" src="https://static.wixstatic.com/media/a27d24_e10b0ace71dc4bf5a0aa0e0dd52147fa~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p></div></div></div></div><p id="viewer-7n7r8">Recent headlines suggest that I could protect myself from Covid and also cut my risk of dying from Covid <em>by half </em>just by taking Vitamin D. If that is the case, why aren't we all taking it? We hand out masks; why not Vitamin D?</p><p id="viewer-di3pq">Let's pause here for a reality check: Lots of diseases are correlated with Vitamin D deficiency – but most are not caused by it. It’s a correlation, not a causation. Vitamin D deficiency is often a marker of overall poor health; sicker individuals are more likely to develop low Vitamin D. Treating the deficiency treats the symptom, not the cause. In trials of Vitamin D vs. placebo for preventing disease, <a href="https://www.devaboone.com/post/vitamin-d-part-3-the-evidence" target="_blank" rel="noopener"><u>Vitamin D often disappoints.</u></a> </p><p id="viewer-avjvo">But maybe Covid is different. Covid is a respiratory infection, and in meta-analyses severe Vitamin D deficiency does appear to increase the risk of respiratory infections. We also have a plausible mechanism through which Vitamin D could influence Covid. The latest hypothesis asserts that a “bradykinin storm” is largely responsible for the severe symptoms of Covid. A surge of bradykinin, a peptide related to inflammation, leads to blood vessel dilation and increased permeability (“leaky vessels”). This contributes to swelling and fluid retention in the lungs and numerous other effects throughout the body, including cognitive deficits, severe hypokalemia and resulting cardiac arrythmias, and hypotension.</p><p id="viewer-eg7lh">There are complicated pathways involved in the production and regulation of bradykinin. Covid involves the renin-angiotensin system (RAS), which is involved in blood pressure control, fluid management, and inflammation. Vitamin D modulates this system somewhat, which is how it could play a role in modulating the inflammation and bradykinin storm that can occur with Covid. The relationship between Vitamin D and bradykinin is not simple or  straightforward, but it is there (find Vitamin D in the top left of the following image).</p><h3 id="viewer-a9vd1">Pathways involved in a bradykinin storm</h3><div id="viewer-6u3jj"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.devaboone.com/post/vitamin-d-and-covid?postId=5f729cf1efb0ee0017940a2e" data-pin-media="https://static.wixstatic.com/media/3e0600_7997c2251a1040b8be64237b3c6d8346~mv2.jpg/v1/fit/w_1000,h_1000,al_c,q_80/file.png" src="https://static.wixstatic.com/media/3e0600_7997c2251a1040b8be64237b3c6d8346~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p></div></div></div></div><p id="viewer-f1rr2"><em>From: </em><a href="https://pubmed.ncbi.nlm.nih.gov/32633718/" target="_blank" rel="noopener"><em><u>Garvin MR, Alvarez C, Miller JI, Prates ET, Walker AM, Amos BK, Mast AE, Justice A, Aronow B, Jacobson D. A mechanistic model and therapeutic interventions for COVID-19 involving a RAS-mediated bradykinin storm. Elife. 2020 Jul 7;9:e59177.</u></em></a></p><p id="viewer-dpsa1"><strong>It’s not enough, though, to have a plausible explanation for Vitamin D’s role. </strong>We need human studies, and we now have them. Let’s go through some of the studies that have received the most attention. </p><p id="viewer-bd2aq"><strong>1: Observational study of individuals tested for Covid (U.S<span>.): </span></strong><a href="https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2770157" target="_blank" rel="noopener"><strong><u>Association of Vitamin D Status and Other Clinical Characteristics With COVID-19 Test Results [1]</u></strong></a></p><p id="viewer-f2tn1"><span><strong>Question asked:</strong> Do individuals with low Vitamin D have higher rates of Covid infection?</span></p><p id="viewer-9gacj"><span><strong>How the question was answered:</strong> Researchers reviewed records for 489 adults who had been tested for Covid and had had Vitamin D testing within the last year, at a single center in the U.S.</span></p><p id="viewer-5cdp9"><span><strong>Findings</strong>: Those who were deficient in Vitamin D (less than 20 ng/ml) had higher rates of Covid than those with sufficient Vitamin D: 19% vs. 12%. The risk of having a positive test persisted even when correcting for other medical conditions.</span></p><p id="viewer-eo35u"><span><strong>Conclusion: </strong>There is likely an association between Vitamin D deficiency and developing Covid. </span>This does not necessarily imply that the low Vitamin D caused a susceptibility to Covid. People with low Vitamin D could be more susceptible to infection because they have other health issues. For example, nursing home residents are more likely to be deficient in Vitamin D – and they are also at high risk for Covid spread. The study did attempt to correct for some of this and still found an association between Vitamin D and Covid. Overall, this study provides a solid basis for future research, and reinforces the recommendation to correct Vitamin D deficiencies.</p><p id="viewer-d4961"><span><strong>2. Observational study of individuals tested for Covid (U.S.): </strong></span><a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0239252" target="_blank" rel="noopener"><strong><u>SARS-CoV-2 positivity rates associated with circulating 25-hydroxyvitamin D levels [2]</u></strong></a></p><p id="viewer-8pk9p"><strong>Question asked:</strong> Is low Vitamin D associated with rate of Covid infection?</p><p id="viewer-46bul"><strong>How the question was answered</strong>: Researchers sifted through Quest lab results to find patients who had had Covid testing and had also had Vitamin D levels checked within the last year. They ended up with over 190,000 individuals from the United States. All had zip code information available (which was used to estimate race). Vitamin D levels were grouped and then the rate of Covid positivity was compared between groups. </p><p id="viewer-6qj8d"><strong>Finding:</strong> Low Vitamin D levels associated with higher rates of Covid</p><p id="viewer-6l5lr">Here is one graph from the study, showing that as Vitamin D levels rise, Covid positivity rates fall:</p><div id="viewer-ba99b"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.devaboone.com/post/vitamin-d-and-covid?postId=5f729cf1efb0ee0017940a2e" data-pin-media="https://static.wixstatic.com/media/3e0600_e6c5ae0b792f407d86855628a1ce559b~mv2.jpg/v1/fit/w_1000,h_1000,al_c,q_80/file.png" src="https://static.wixstatic.com/media/3e0600_e6c5ae0b792f407d86855628a1ce559b~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p></div></div></div></div><p id="viewer-4emce"><em>For Vitamin D levels under 30 ng/ml, Covid rates appear clearly higher than for levels above 30. After getting above 40 ng/ml, the benefit is less clear. [2]</em></p><p id="viewer-bdn8n"><strong>Conclusion:</strong> This is a convincing association, but not evidence for causation. People with Vitamin D levels under 30 ng/ml seem to have higher rates of Covid infection. But those with low Vitamin D likely had other medical conditions, which were not addressed. This study was not designed to address this – it only looked at lab results, not medical history.</p><p id="viewer-7bq6o">Having said that, the data include a large number of individuals and the effect of Vitamin D level is striking. This provides a solid basis for further research. </p><p id="viewer-bh966"><strong>3. Observational study of Covid patients (Iran): </strong><a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0239799" target="_blank" rel="noopener"><strong><u>Vitamin D sufficiency, a serum 25-hydroxyvitamin D at least 30 ng/mL reduced risk for adverse clinical outcomes in patients with COVID-19 infection [3]</u></strong></a></p><p id="viewer-42e4h"><strong>Question asked</strong>: Is low Vitamin D associated with poor outcomes in patients diagnosed with Covid?</p><p id="viewer-6fd60"><strong>How the question was answered:</strong> Researchers reviewed the records of 235 patients diagnosed with symptomatic Covid in a single emergency department in Iran. They compared patients with Vitamin D levels greater than or equal to 30 ng/ml to those with Vitamin D levels below 30. The also compared the mortality of patients over age 40.</p><p id="viewer-e4o8k"><strong>Findings:</strong> </p><p id="viewer-6cp5">ICU admission and intubation: The two groups had similar rates.</p><p id="viewer-a49o2">Severity of disease: For patients who were sufficient in Vitamin D (30 ng/ml or higher), 63% had “severe” disease, compared to 77% of those who were deficient. Severe disease defined as: reporting shortness of breath, breathing fast, oxygen saturation below or equal to 93%, or lung infiltrates on CT scan covering more than half of the lungs. </p><p id="viewer-3vln1">Mortality: When looking at adults over age 40, the mortality rate was higher for deficient adults: 20% vs. 9.7%. </p><p id="viewer-d8kl7">Scatterplot from the study showing mortality risk.</p><div id="viewer-e4bei"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.devaboone.com/post/vitamin-d-and-covid?postId=5f729cf1efb0ee0017940a2e" data-pin-media="https://static.wixstatic.com/media/3e0600_623993a79fef40719ab14eacbbc54380~mv2.png/v1/fit/w_1000,h_881,al_c,q_80/file.png" src="https://static.wixstatic.com/media/3e0600_623993a79fef40719ab14eacbbc54380~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p></div></div></div></div><p id="viewer-9anh4"><em>Patients who had sufficient levels of Vitamin D had lower death rates than those with deficient Vitamin D. Note that low Vitamin D was not a death sentence - most people with low Vitamin D survived. [3]</em></p><p id="viewer-21b1t"><strong>Interesting to note:</strong> When comparing mortality, they excluded everyone under the age of 40. You can see on the graph that there were lots of young people with low Vitamin D levels who did not die. (No one under 40 died.) This was not described in the methods, which leads me to believe that it was done after the fact in order to find a statistically significant difference in mortality.</p><p id="viewer-bqd04"><span><strong>Conflict of interest alert: </strong></span>The senior author on the last two studies listed was Michael F Holick, MD. Holick has been a very vocal advocate of Vitamin D testing and supplementation. He also has extensive financial ties to the lab testing industry (Quest, as well as two companies that produce Vitamin D tests) and the pharmaceutical industry (multiple corporations that sell supplements and medications frequently prescribed with Vitamin D). He has even received money from the tanning industry. Liz Szabo wrote an <a href="https://www.nytimes.com/2018/08/18/business/vitamin-d-michael-holick.html" target="_blank" rel="noopener"><u>excellent article on Holick</u></a> that was published in the New York Times in 2018.</p><p id="viewer-f414g">Holick's level of association with these industries is concerning. It does not mean that the studies are wrong. But it definitely adds a possibility of bias in the data collection and interpretation.</p><p id="viewer-d24re"><strong>Conclusion:</strong> Ignoring the possible influence that Holick's conflicts of interest had on the study: this is a convincing association between Vitamin D deficiency and disease severity. It was not designed to show causation. It does provide a basis for further studies. </p><p id="viewer-ea8n4"><strong>4. Randomized controlled trial of Covid patients (Spain):<u> </u></strong><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7456194/" target="_blank" rel="noopener"><strong><u>Effect of calcifediol treatment and best available therapy versus best available therapy on intensive care unit admission and mortality among patients hospitalized for COVID-19: A pilot randomized clinical study. [4]</u></strong></a></p><p id="viewer-4v9n0"><strong>Question asked:</strong> Will giving Vitamin D to hospitalized Covid patients improve outcomes?</p><p id="viewer-5ei89"><strong>How the question was answered: </strong>76 Covid patients admitted to a single hospital in Spain were randomized to receive calcifediol with standard therapy vs. standard therapy alone. Calcifediol is Vitamin D 25-OH; it is converted to the active form of Vitamin D. It was given orally on hospitalization days 1, 3 and 7, then weekly. The outcomes reviewed were ICU admission and mortality. </p><p id="viewer-10lrb"><strong>Findings</strong></p><ul><li id="viewer-fu8rq"><p>ICU admission: Just one of the 50 patients (2%) receiving Vitamin D needed to be admitted to the ICU, while 13 of the 26 (50%!) of the patients not receiving Vitamin D were admitted to the ICU. </p></li><li id="viewer-9psdo"><p>Mortality: None of the 50 patients treated with Vitamin D died, while 2 of the 26 patients in the control group died.</p></li></ul><p id="viewer-dlu5i"><strong>Interesting to note:</strong> The patients were randomized, but the groups were small, and they ended up with several notable differences between the groups. Several comorbidities (other diseases that predispose someone to have more severe disease) were more common in the control group than in the Vitamin D treatment group: 19% vs. 6% for diabetes, and 58% vs 24% for hypertension. The control group also had a higher percentage of men. All of these factors could make the control group more likely to develop severe disease (whether Vitamin D had any effect or not). In addition, ICU admission was based partly on comorbidities, so the untreated group was already more likely to go to the ICU. </p><p id="viewer-7gn40"><strong>Another note:</strong> The authors did not look at BMI or the rate of obesity, which is now a well-known risk factor for Covid severity. Vitamin D levels were not measured, so we …</p></div></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.devaboone.com/post/vitamin-d-and-covid?postId=5f729cf1efb0ee0017940a2e">https://www.devaboone.com/post/vitamin-d-and-covid?postId=5f729cf1efb0ee0017940a2e</a></em></p>]]>
            </description>
            <link>https://www.devaboone.com/post/vitamin-d-and-covid?postId=5f729cf1efb0ee0017940a2e</link>
            <guid isPermaLink="false">hacker-news-small-sites-24633248</guid>
            <pubDate>Tue, 29 Sep 2020 21:30:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fujitsu FM Towns Rescue Boot Loader Project]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24633036">thread link</a>) | @app4soft
<br/>
September 29, 2020 | http://ysflight.in.coocan.jp/FM/towns/bootloader/e.html | <a href="https://web.archive.org/web/*/http://ysflight.in.coocan.jp/FM/towns/bootloader/e.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">





        
        
        <p>Let's say you have a almost-functioning FM TOWNS, but its internal 
		CD-ROM drive is dead, floppy-disk drive is dead, and CMOS battery is 
		gone.&nbsp; In that situation, all you could do was pretty much power it 
		up and watch boot-device cycles at the lower-right corner.</p>
<p>Until now.</p>
        
        <p>I have already released a SCSI CD-ROM driver,
		<a href="http://ysflight.in.coocan.jp/FM/towns/internalCDROM/YSSCSICD_E.html">YSSCSICD.SYS</a>.&nbsp; This 
		driver let Towns OS think SCSI-connected CD-ROM drive is an internal 
		drive.&nbsp; However, it had some problems.&nbsp; First, you need to 
		make separate boot disks for Towns OS V1.1 and V2.1.&nbsp; Or, even if 
		your game title is not directly accessing CD-ROM I/O, some of those 
		titles use a special driver or BIOS, in which case you needed a separate 
		boot disk for your game title.</p>
        
        <p>  The second problem is<!--webbot bot="HTMLMarkup" startspan -->
<!--webbot bot="HTMLMarkup" endspan i-checksum="53585" -->

		it doesn't help your FM TOWNS if internal floppy-disk drive is dead as 
		well.&nbsp; In that situation, possible boot devices left were SCSI hard 
		drive, or IC memory card.&nbsp; However, to boot Towns OS from a SCSI 
		hard drive, you need to assign a drive letter, but to assign a drive 
		letter you need to boot Towns OS.&nbsp; It's a same old chicken and egg 
		problem.&nbsp; IC memory card that can be accessed from FM TOWNS 
		virtually doesn't exist any more.</p><p>  The third problem is since it 
relies on a floppy disk, it is impossible to manufacture using Windows 10.&nbsp; 
Well, you could with an earlier version of Windows 10, but not any more.&nbsp; 
If you are able to format a 1232KB floppy disk, you may be able to do something, 
but to do so you need TOWNS.&nbsp; Again, it's a salmon and ikura problem.</p><p>  
On the other hand, <a href="http://ysflight.in.coocan.jp/FM/towns/Tsugaru/e.html">my FM TOWNS Emulator "Tsugaru"</a> 
is now able to emulate SCSI CD-ROM drive.&nbsp; I am able to develop and debug 
an IPL (Initial Program Loader) and boot loader in Tsugaru.</p><p>  So I started FM 
TOWNS Rescue Boot Loader project.&nbsp; TOWNS reads and executes the IPL sector 
of a hard drive regardless of the drive-letter assignment.&nbsp; Therefore, 
theoretically it should be possible to write an IPL that loads IO.SYS from 
external SCSI CD-ROM drive, intercept before it hands off the control to 
MSDOS.SYS, install BIOS redirector, and continue the rest of the boot process.&nbsp; 
Then, TOWNS will think an external SCSI CD-ROM drive is the internal drive.&nbsp; 
Since it installs the BIOS redirector much earlier than CONFIG.SYS, it won't 
require separate disk for different versions of TownsOS.</p><h2>Updates</h2>
<h3>2020/09/29</h3>
<ul>
	<li>CD Boot Sector now supports both internal CD and SCSI CD drives.&nbsp; 
	You don't have to keep two separate discs for internal CD and SCSI CD.</li>
</ul>
<h3>  
2020/09/28</h3>
<ul>
	<li>Added invitation to Demosplash 2020 in the Boot Loader message.&nbsp; 
	Please join us at Demosplash 2020 (and 2021, 2022, ...)&nbsp;
	<a href="http://www.demosplash.org/">http://www.demosplash.org</a> </li>
	<li>Release CD Boot Loader</li>
	<li>Release CD Boot Sector</li>
</ul>
<h3>2020/09/26</h3>
<ul>
	<li>Release FD Boot Loader</li>
</ul>
<h2>What You Need</h2>
<ul>
	<li>A almost-functioning FM TOWNS (of course)</li>
	<li>A SCSI CD-ROM drive (CD-R should work too)</li>
	<li>Cable for connecting FM TOWNS and SCSI CD drive.</li>
</ul>
<p>Now I don't think new SCSI CD drive exists any more, but still you can get 
one from eBay.&nbsp; Good luck!</p>
<h2>CD Boot Loader</h2>
<p>A ground-breaking discovery.&nbsp; FM TOWNS II MX and FM TOWNS II HR's system 
ROM read IPL sector from a SCSI CD drive and jump to IPL.&nbsp; TOWNS 2F didn't.&nbsp; 
My guess is TOWNS II CX and newer models models' system ROM reads IPL from SCSI 
CD drive.&nbsp; On the emulator I confirmed with MX ROM, and actual HR did the 
same.</p>
<p>Therefore, if I write an IPL, I can start a program from SCSI CD-ROM drive 
directly without relying on a floppy disk.</p>
<p>So I did it.&nbsp; How to use is extremely easy.&nbsp; Download the ISO image 
from the following URL and burn to a CD-R.</p>
<p>
<a href="https://github.com/captainys/FM/tree/master/TOWNS/IPL/DISKIMG">https://github.com/captainys/FM/tree/master/TOWNS/IPL/DISKIMG</a></p>
<p>Start your TOWNS II with this CD-R in the SCSI CD drive.&nbsp; You will be 
prompted to change the disc to the one you want to boot and press a button on 
game pad or mouse.&nbsp; If you follow the instruction, your app will start from 
the SCSI CD drive.</p>
<p>There are some limitations:</p>
<ul>
	<li>Some CD drives spin up very slowly, in which case the drive may not be 
	ready before the boot-device cycle reaches the drive.&nbsp; But, it should 
	be recognized in the second cycle.&nbsp; It happens in my TOWNS HR.&nbsp; 
	Well, it happened in my HR, but for some reason it started waiting long time 
	for HD0 since this morning, and therefore it finds my boot loader in SCSI ID 
	3 in the first cycle.&nbsp; I don't know what changed this guy's mind.</li>
	<li>Due to the reason above, make sure to unplug other hard drives and keep 
	floppy-drive empty, or TOWNS will try to boot from whatever boot media found 
	first.&nbsp; (And may fail if CMOS is gone.)</li>
	<li>TOWNS' system ROM apparently only checks SCSI ID from 0 to 4.&nbsp; So, 
	make sure to configure your CD drive to one of four numbers.</li>
	<li>This CD image is confirmed with HR.&nbsp; MX system ROM also seems to be 
	able to recognize it.&nbsp; But, I can set up only one TOWNS at a time due 
	to space limitation.&nbsp; I haven't had chance to test with actual MX.&nbsp; 
	But, 2F ROM is confirmed NOT work.&nbsp; Probably this ISO image is good for 
	TOWNS II models, but not sure.&nbsp; I appreciate if you report successes.</li>
</ul>
<h2>CD Boot Sector</h2>
<p>Actually, you can make a Towns OS directly boot from the SCSI CD drive.&nbsp; 
It's extremely easy.&nbsp; Make an ISO image of the Towns OS disc (can be system 
software or any game), and overwrite the first 6KB with the following binary:</p>
<p><a href="https://github.com/captainys/FM/tree/master/TOWNS/IPL/BOOTSECT">
https://github.com/captainys/FM/tree/master/TOWNS/IPL/BOOTSECT</a></p>
<p>You can just open a .ISO file in a binary editor and overwrite first part 
with this boot sector.&nbsp; In CUE/BIN format, if the data track sector length 
is 2048, you can do the same for BIN file.&nbsp; If the sector length is not 
2048, there are gaps between sector data, and you need to skip those gaps.&nbsp; 
I don't know if there is such a tool.&nbsp; I might write one if there is a 
demand.</p>
<p>Due to some resource issues, I could confirm only Towns System Software 
V2.1L31 on my TOWNS II HR, but on the emulator, it seems to work with majority 
of Towns OS apps as long as it is not directly beating CD-ROM I/O.&nbsp; (Same 
limitation as YSSCSICD.SYS)&nbsp;</p>
<h2>Floppy-Disk Boot Loader</h2>
<p>Floppy-Disk Boot Loader does not solver the problem of floppy-disk 
dependency.&nbsp; However, it at least solves a problem: YSSCSICD.SYS approach 
needed separate disks for Towns OS V1.1 and V2.1.&nbsp; If you have a 
functioning FM TOWNS unit, maybe it's a good idea to make one for the doomsday 
when its CD/FD drives are gone.</p>
<p>In addition to "What You Need", you need at least one floppy disk.</p>
<p>I have confirmed the following image successfully starting Towns OS from 
external CD-ROM drive with FM Towns II MX and II HR.&nbsp; Download FDIMAGE.BIN 
or FDMINI.BIN and write to 1232KB-format floppy disk.</p>
<p>  
        <a href="https://github.com/captainys/FM/tree/master/TOWNS/IPL/DISKIMG">
		https://github.com/captainys/FM/tree/master/TOWNS/IPL/DISKIMG</a></p>
<p>  
        The boot loader uses first 160KB (I reserve 160KB just in case.&nbsp; It 
		is actually using much less.)&nbsp; You can write first 160KB using 
		FDMINI.BIN or entire disk with FDIMAGE.BIN.</p>
<p>  
        Now it is difficult to find a floppy disk without bad sectors.&nbsp; 
		Even in that case, you only need first 160KB.&nbsp; If you have a floppy 
		disk with a bad sector in the middle, you can still recycle it for 
		emergency-boot disk.&nbsp; This boot loader is environmentally friendly.</p>
<p>Once you have a disk, connect your SCSI-CD drive, put Towns OS V1.1 or V2.1 
system disk (or whatever game you have) in the SCSI-CD drive, insert the boot 
floppy disk in drive A or B, and power on.&nbsp; After a while, it boots from 
external SCSI-CD drive.</p>
<p>Well, it's getting more and more difficult to manufacture a 1232KB-format 
floppy disk.&nbsp; But, if you have a working TOWNS, you can format in Towns OS, 
and then use the following command-line tool to write a disk image.</p>
<p>  
        <a href="https://github.com/captainys/FM/tree/master/TOWNS/FDWRITE/EXE">
		https://github.com/captainys/FM/tree/master/TOWNS/FDWRITE/EXE</a></p>
<p>  
        You need to format your floppy disk in 1232KB format with Towns OS or 
		DOS.&nbsp; Then, go into Towns OS Command Mode, and type like:</p>
<p>RUN386 -nocrt FDWRITE.EXP A: FDMINI.BIN</p>
<p>It won't confirm before write.&nbsp; Be careful not to overwrite your 
important floppy disk.</p>
<p>You can see how it goes using my <a href="http://ysflight.in.coocan.jp/FM/towns/Tsugaru/e.html">FM TOWNS 
Emulator "Tsugaru"</a>.&nbsp; Tsugaru GUI is not supporting this, but from CUI, 
you can type like:</p>
<p>.\Tsugaru_CUI.exe ROM_MX -SCSICD5 
TownsOSV2.1L20.cue -FD0 FDIMAGE.BIN</p>
<p>to see how this boot loader starts from SCSI-CD drive.</p>
<h2>SCSI Hard Disk Boot Loader (Coming Soon)</h2>
<p>Let's say your TOWNS has bad floppy-disk drives.&nbsp; None of drive A nor B 
reads a disk.&nbsp; Or, it can be like your TOWNS has a dead CD drive and cannot 
start Towns OS.&nbsp; You don't have a spare TOWNS in working condition.&nbsp; 
And you upgraded your Windows 10 and you can no longer format a floppy disk in 
1232KB format.&nbsp; (Good job, Microsoft!)&nbsp; For those situations, I am 
working on SCSI Hard Disk Boot Loader.</p>
<p>Once CMOS battery depleted, you can no longer start Towns OS from a hard disk 
partition because CMOS retains drive-letter assignments.&nbsp; Nonetheless, the 
system ROM reads the IPL sector (the very first sector of the hard drive) and 
jumps to the IPL.&nbsp; Therefore, theoretically it is possible to start a 
program without relying on the drive letters.&nbsp; In fact, Linux can boot 
regardless of the drive-letter assignments in the CMOS.</p>
<p>Now you can find a virtual hard-disk device such as SCSI2CD.&nbsp; So, if I 
make a bootable hard-disk image, you can write it to the SD card, and start from 
there.&nbsp; I should be able to do the same as the Floppy-Disk Boot Loader 
using a virtual Hard Disk device.</p>
<p>I'm working on it.&nbsp; I'll release it as soon as it's ready and tested on 
actual TOWNS.</p>
<h2>Confirmed Titles</h2>
<ul>
	<li>Towns System Software V1.1 L10</li>
	<li>Towns System Software V2.1 L20</li>
	<li>Afterburner II</li>
	<li>Wing Commander</li>
	<li>New Zealand Story</li>
	<li>Splatter House</li>
	<li>Tatsujin Oh</li>
</ul>
<h2>Confirmed Not-Work Titles</h2>
<p>Basically those require a patch to run with YSSCSICD.SYS won't run with this 
boot loader.</p>
<ul>
	<li>Chase HQ (Need Patch)</li>
	<li>Raiden (Need Patch)</li>
</ul>

    <h2>Technical Information</h2>
<p>During the initial boot process, FM TOWNS' system ROM read the first sector 
of a media to B000:0000, and if the first four bytes are "IPL4", it jumps to 
B000:0004.&nbsp; …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://ysflight.in.coocan.jp/FM/towns/bootloader/e.html">http://ysflight.in.coocan.jp/FM/towns/bootloader/e.html</a></em></p>]]>
            </description>
            <link>http://ysflight.in.coocan.jp/FM/towns/bootloader/e.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24633036</guid>
            <pubDate>Tue, 29 Sep 2020 21:11:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenBSD on the Desktop (Part II)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24633030">thread link</a>) | @upofadown
<br/>
September 29, 2020 | https://paedubucher.ch/articles/2020-09-12-openbsd-on-the-desktop-part-ii.html | <a href="https://web.archive.org/web/*/https://paedubucher.ch/articles/2020-09-12-openbsd-on-the-desktop-part-ii.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>A week ago, I've installed <a href="https://paedubucher.ch/articles/2020-09-05-openbsd-on-the-desktop-part-i.html">OpenBSD on my
Thinkpad</a>.
I've been using it now and then, and already have changed a couple of things in
respect to the original setup described in the article. I also installed OpenBSD
on the Dell Optiplex on which I <a href="https://paedubucher.ch/articles/2020-08-11-freebsd-on-the-desktop.html">previously installed
FreeBSD</a>
a month before. This means that I'm no longer using FreeBSD on the desktop, at
least not for the moment. However, FreeBSD is running on a disk station I built
earlier this summer. Maybe I'll describe that particular setup (using ZFS) in a
later article.</p>
<p>Except for that storage server, I'd like to use OpenBSD for most of my private
computing. In this article, I describe some GUI tweaks and additional setup
tasks I perfmormed in order to feel more at home on my OpenBSD machines. Some of
the tasks performed are <em>not</em> specific to OpenBSD, but could also be applied to
a Linux setup.</p>

<p><code>sudo</code> originally came from the OpenBSD community. It is almost as widely used
in the Unix world as SSH, which is the most prominent OpenBSD project.  However,
<code>sudo</code> became bigger and harder to configure. Therefore, Ted Unangst came up
with a simpler alternative called <code>doas</code>, which stands for <em>Dedicated OpenBSD
Application Subexecutor</em>. <code>doas</code> is less powerful than <code>sudo</code>, but much smaller,
easier to configure, and, thus, more secure. The full rationale can be read in
<a href="https://flak.tedunangst.com/post/doas">Ted Unangst's Blog</a>.</p>
<p>A basic <code>doas</code> setup requires to login as root for one last time. The
configuration shall be kept extremely simple. I'd like to permit all users from
the <code>wheel</code> group (which is just me on my computers) to use <code>doas</code> without
entering the password every time but only once when executing a command that
requires <code>root</code> permissions. This is only a single line in <code>/etc/doas.conf</code>:</p>
<pre><code>permit persist :wheel
</code></pre>
<p>Let's check this setup by logging in as a user of the wheel group and trying to
update the packages:</p>
<pre><code>$ doas pkg_add -u
</code></pre>
<p>This works, so bye bye <code>root</code> account.</p>

<p>By default, <code>dwm</code>, <code>dmenu</code>, and <code>st</code> use a monospace font of size 10, or
pixelsize 12, respectively, which is hard to read on a screen with a high
resolution. On Linux, I use the the TrueType font DejaVu Sans Mono. For OpenBSD,
I'd rather use something more minimalistic: the <a href="http://terminus-font.sourceforge.net/">Terminus bitmap
font</a>.</p>
<p>As <code>pkg_info -Q terminus</code> shows, this font comes in different versions. I prefer
the version with the centered tilde, which I install:</p>
<pre><code>$ doas pkg_add terminus-font-4.47p0-centered_tilde
</code></pre>
<p>Let's reconfigure <code>st</code> first, for testing changes doesn't require a restart of
the window manager. I stored my suckless sources in <code>~/suckless</code>, so the
font for <code>st</code> can be configured in <code>~/suckless/config.h</code>. I replace the existing
font configuration</p>
<pre><code>static char *font = "Liberation Mono:pixelsize=12:antialias=true:autohint=true";
</code></pre>
<p>with</p>
<pre><code>static char *font = "Terminus:pixelsize=24";
</code></pre>
<p>The options <code>antialias</code> and <code>autohinting</code> are not needed for a bitmap font, so I
left them away. 24 pixels is rather big, but my screen is big enough to show two
text editors with more than 80 characters per line next to each other, so let's
keep it this way. I rebuild and reinstall <code>st</code>, then switch to <code>dwm</code>:</p>
<pre><code>$ doas make install
$ cd ../dwm
</code></pre>
<p>The font configuration in the <code>config.h</code> file looks a bit different here:</p>
<pre><code>static const char *fonts =      { "monospace:size=10" };
static const char dmenufont =   "monospace:size=10";
</code></pre>
<p>Let's just use the same font as for <code>st</code> here:</p>
<pre><code>static const char *fonts =      { "Terminus:pixelsize=24" };
static const char dmenufont =   "Terminus:pixelsize=24";
</code></pre>
<p>Note that I'm using <code>pixelsize</code> instead of <code>size</code> here. (24pt would be much
bigger than 24px.) Then I rebuild and reinstall <code>dwm</code>.</p>
<pre><code># make install
</code></pre>
<p>This configuration appllies also to <code>dmenu</code> and <code>slstatus</code>, so we're done with
the fonts.</p>

<p>By default, the desktop background is a pattern of black and grey dots, which is
a strain to the eye. Even though I rarely look at an empty desktop for long, I'd
rather change this to a solid color. This can be done by adding a command to
<code>~/.xinitrc</code>:</p>
<pre><code>xsetroot -solid black
</code></pre>
<p>Right before <code>dwm</code> is executed.</p>

<p>Even though SSH is almost ubiquitous nowadays, a USB flash drive is still useful
when it comes to exchanging data between computers, especially if Windows is
involved, or if the network does not allow SSH.</p>
<p>Block storage devices are accessible through the device nodes <code>/dev/sd*</code>,
whereas <code>*</code> stands for the number of the disk. The disks can be listed as
follows:</p>
<pre><code>$ sysctl hw.disknames
hw.disknames=sd0:ef0268c97ae7a246
</code></pre>
<p>Only <code>sd0</code> is active, even though I already plugged in my USB dongle. However,
the system already figured out that there is a second disk:</p>
<pre><code>$ sysctl hw.diskcount
hw.diskcount=2
</code></pre>
<p>The next free disk would have the name <code>sd1</code>. The device nodes can be created by
running the <code>MAKEDV</code> script in <code>/dev</code>:</p>
<pre><code>$ cd /dev
$ doas sh MAKEDEV sd1
</code></pre>
<p>Let's initialize a new MBR partition schema on <code>sd1</code>:</p>
<pre><code>$ doas fdisk -iy sd1
</code></pre>
<p>The new disk layout can be checked using <code>disklabel</code>:</p>
<pre><code>$ doas disklabel sd1
# /dev/rsd1c
...
</code></pre>
<p>The first line of the output tells us that there's a partition under
<code>/dev/rsd1c</code>. (The <code>r</code> refers to «raw», as opposed to «block».) The partition
can be formatted using <code>newfs</code> by referring to that partition name:</p>
<pre><code>$ doas newfs sd1c
</code></pre>
<p>This creates a default FFS (Fast File System) partition, which is useful to
exchange data between BSD operating systems. The formatted partition is then
ready to be mounted:</p>
<pre><code>$ doas mount /dev/sd1c /mnt
</code></pre>
<h2>Other Partition Types</h2>
<p>Other partition types are available under other utilities.</p>
<h3>FAT32</h3>
<p>The following command creates a FAT32 partition:</p>
<pre><code>$ doas newfs_msdos -F 32 sd1c
</code></pre>
<p>The <code>-F 32</code> parameter specifies FAT32 (as opposed to FAT16 or FAT8). To mount
the partition, use the according <code>mount</code> command:</p>
<pre><code>$ doas mount_msdos /dev/sd1c /mnt
</code></pre>
<h3>EXT2</h3>
<p>In order to create an <code>ext2fs</code> file system, the partition type needs to be
specified accordingly. First, you might consider a GPT partition schema instead
of MBR (additional <code>-g</code> parameter):</p>
<pre><code>$ doas fdisk -igy sd1
</code></pre>
<p>Then use <code>disklabel</code> interactively to define a new partition:</p>
<pre><code>$ doas disklabel -E sd1
</code></pre>
<p>First, delete all the partitions with <code>z</code>. Then, create a new partition with
<code>a</code>, and make sure to specify the type as <code>ext2fs</code> instead of the default
<code>4.2BSD</code>. Notice that the new partition has a different letter (say, <code>a</code>), so
you need to use <code>sd1a</code> instead of <code>sd1c</code> for the next steps. Write the changes
by typing <code>w</code>, then exit with <code>q</code>. Now you can format and mount the partition:</p>
<pre><code>$ doas newfs_ext2fs sd1a
$ doas mount_ext2fs /dev/sd1a /mnt
</code></pre>

<p>In order to access my GitHub repositories, I first create a new SSH key:</p>
<pre><code>$ ssh-keygen -t rsa -b 4096
</code></pre>
<p>Since I manage my passwords with <code>pass</code> (of which more later), I don't know most
of them by heart. So I can't just login to GitHub and add my public key.
Therefore, I copy my public key to my laptop, on which I'm already logged in to
GitHub.</p>
<p>This can be either done using <code>scp</code>, for which <code>sshd</code> has to be running on my
laptop (which currently has the IP <code>192.168.178.53</code>):</p>
<pre><code>$ scp ~/.ssh/id_rsa.pub 192.168.178.53:/home/patrick
</code></pre>
<p>Or using the USB flash drive formatted with <code>ext2</code> from before:</p>
<pre><code>$ doas newfs_ext2fs -I sd1a
$ doas mount_ext2fs /dev/sd1a /mnt
$ doas cp ~/.ssh/id_rsa.pub /mnt/
</code></pre>
<p>Then <code>id_rsa.pub</code> can be copied into the according <a href="https://github.com/settings/ssh/new">GitHub Settings
Page</a>, after which cloning GitHub
repositories should work on the OpenBSD machine:</p>
<pre><code>$ git clone git@github.com:patrickbucher/conf
</code></pre>

<p>My passwords are encrypted using GPG. To encrypt them, I need to copy my private
key from my other machine. First, I list my private keys:</p>
<pre><code>$ gpg --list-keys --keyid-format SHORT
pub   rsa2048/73CE6620 2016-11-11 [SC]
      22F91EE20D641CBCF5B8678E82B7FE3A73CE6620
uid         [ultimate] Patrick Bucher &lt;patrick.bucher@mailbox.org&gt;
sub   rsa2048/AF6246E3 2016-11-11 [E]
</code></pre>
<p>Then I export both public and private key to an according file using the armored
key format:</p>
<pre><code>$ gpg --export --armor 73CE6620 &gt; public.key
$ gpg --export-secret-key --armor 73CE6620 &gt; private.key
</code></pre>
<p>The two key files can be copied via SSH or the USB flash disk again, which I
won't show here.</p>
<p>Back on my OpenBSD machine, I need to install GnuPG first, because OpenBSD only
has <code>signify</code> installed by default:</p>
<pre><code>$ doas pkg_add gnupg
</code></pre>
<p>I pick the 2.2 version. Now I can import my keys:</p>
<pre><code>$ gpg2 --import private.key
$ gpg2 --import public.key
</code></pre>
<p>The key is not trusted so far, so I need to change that:</p>
<pre><code>$ gpg2 --edit-key 73CE6620
&gt; trust
&gt; 5
&gt; y
&gt; quit
</code></pre>
<p>5 stands for ultimate trust, which seems appropriate.</p>

<p>I use <code>pass</code> as a password manager, which can be installed as the
<code>password_store</code> package in OpenBSD:</p>
<pre><code>$ doas pkg_add password-store
</code></pre>
<p>Now that I have both my GPG private key and a working SSH key for GitHub, I can
clone my passwords stored on a private GitHub repository:</p>
<pre><code>$ git clone git@github.com:patrickbucher/pass .password-store
</code></pre>
<p>Now I can copy my GitHub password to the clipboard as follows:</p>
<pre><code>$ pass -c github
</code></pre>

<p>I use a lot of aliases, such as <code>gcl</code> as a shortcut for <code>git clone</code>, and <code>gad</code>
for <code>git add</code>, etc. Since OpenBSD uses a Public Domain Korn Shell by default,
the <code>.bashrc</code> configuration from my Linux machines won't work here, unless I
switch to <code>bash</code>, which is not exactly the point of using OpenBSD.</p>
<p>I define my aliases in <code>~/.kshrc</code> (excerpt):</p>
<pre><code>alias gcl='git clone'
alias gad='git add'
</code></pre>
<p>In order to load those settings, an according <code>ENV</code> parameter needs to be
defined in <code>~/.profile</code> (see <code>man 1 ksh</code> for details):</p>
<pre><code>export ENV=$HOME/.kshrc
</code></pre>
<p>After the next login, <code>~/.profile</code> is reloaded, and the aliases are ready to be
used.</p>

<p>Not only is my enhanced setup now ready to do some serious work, but I also
increased my understanding of some OpenBSD subjects. There are still things to
be improved and to be understood, but my setup is now good enough so that I no
longer need a Linux machine running next to it. I'm looking forward to use and
learn about OpenBSD in the time to come. I'll write additional articles on the
subject as soon as I have enough subject material ready.</p></div></div>]]>
            </description>
            <link>https://paedubucher.ch/articles/2020-09-12-openbsd-on-the-desktop-part-ii.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24633030</guid>
            <pubDate>Tue, 29 Sep 2020 21:10:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Error handling under Unix and Windows: A retrospective and outlook]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24632979">thread link</a>) | @DSpinellis
<br/>
September 29, 2020 | https://www.spinellis.gr/blog/20200929/ | <a href="https://web.archive.org/web/*/https://www.spinellis.gr/blog/20200929/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <!-- Left content -->
  <p>One thing that struck me when I first encountered the 4.3BSD Unix system call documentation in the 1980s, was that each call was followed by an exhaustive list of the errors associated with it. Ten years later, when I was going through the Windows API, I was disappointed to see that very few functions documented their error conditions. This is a big deal.</p>
<p>Consider as an example how the <em>open</em> function can fail. The <a href="https://github.com/dspinellis/unix-history-repo/blob/BSD-4_3/usr/man/man2/open.2#L86">4.3BSD manual page</a> documents 23 possible error conditions. Here is the complete list.</p>
<ul>
<li><strong>[ENOTDIR]</strong> A component of the path prefix is not a directory.</li>
<li><strong>[EINVAL]</strong> The pathname contains a character with the high-order bit set.</li>
<li><strong>[ENAMETOOLONG]</strong> A component of a pathname exceeded 255 characters, or an entire path name exceeded 1023 characters.</li>
<li><strong>[ENOENT]</strong> O_CREAT is not set and the named file does not exist.</li>
<li><strong>[ENOENT]</strong> A component of the path name that must exist does not exist.</li>
<li><strong>[EACCES]</strong> Search permission is denied for a component of the path prefix.</li>
<li><strong>[EACCES]</strong> The required permissions (for reading and/or writing) are denied for the named flag.</li>
<li><strong>[EACCES]</strong> O_CREAT is specified, the file does not exist, and the directory in which it is to be created does not permit writing.</li>
<li><strong>[ELOOP]</strong> Too many symbolic links were encountered in translating the pathname.</li>
<li><strong>[EISDIR]</strong> The named file is a directory, and the arguments specify it is to be opened for writting.</li>
<li><strong>[EROFS]</strong> The named file resides on a read-only file system, and the file is to be modified.</li>
<li><strong>[EMFILE]</strong> The system limit for open file descriptors per process has already been reached.</li>
<li><strong>[ENFILE]</strong> The system file table is full.</li>
<li><strong>[ENXIO]</strong> The named file is a character special or block special file, and the device associated with this special file does not exist.</li>
<li><strong>[ENOSPC]</strong> O_CREAT is specified, the file does not exist, and the directory in which the entry for the new file is being placed cannot be extended because there is no space left on the file system containing the directory.</li>
<li><strong>[ENOSPC]</strong> O_CREAT is specified, the file does not exist, and there are no free inodes on the file system on which the file is being created.</li>
<li><strong>[EDQUOT]</strong> O_CREAT is specified, the file does not exist, and the directory in which the entry for the new fie is being placed cannot be extended because the user's quota of disk blocks on the file system containing the directory has been exhausted.</li>
<li><strong>[EDQUOT]</strong> O_CREAT is specified, the file does not exist, and the user's quota of inodes on the file system on which the file is being created has been exhausted.</li>
<li><strong>[EIO]</strong> An I/O error occurred while making the directory entry or allocating the inode for O_CREAT.</li>
<li><strong>[ETXTBSY]</strong> The file is a pure procedure (shared text) file that is being executed and the open call requests write access.</li>
<li><strong>[EFAULT]</strong> Path points outside the process's allocated address space.</li>
<li><strong>[EEXIST]</strong> O_CREAT and O_EXCL were specified and the file exists.</li>
<li><strong>[EOPNOTSUPP]</strong> An attempt was made to open a socket (not currently implemented).</li>
</ul>
<p>This list allows programmers to judge which errors are likely to occur in a given situation, which can be handled, and what to do about the rest. Modern FreeBSD expands this list to <a href="https://www.freebsd.org/cgi/man.cgi?query=open&amp;apropos=0&amp;sektion=2&amp;manpath=FreeBSD+12.1-RELEASE&amp;arch=default&amp;format=html">40 documented errors</a>, while the Debian distribution of GNU/Linux <a href="https://www.freebsd.org/cgi/man.cgi?query=open&amp;apropos=0&amp;sektion=2&amp;manpath=Debian+8.1.0&amp;arch=default&amp;format=html">documents 32</a>.</p>
<p>In contrast, the <a href="https://docs.microsoft.com/en-us/windows/win32/api/winbase/nf-winbase-openfile">documentation</a> of the Windows <em>OpenFile</em> function only specifies that "If the function fails, the return value is HFILE_ERROR. To get extended error information, call GetLastError.", which can return any of about <a href="https://docs.microsoft.com/en-us/windows/win32/debug/system-error-codes">6000 error codes</a>. As this information is returned at runtime, the main way programmers can find out which errors they need to handle in order to make their programs more resilient is by painful trial and error.</p>
<p>I first identified this problem in an article I wrote in 1997, titled <a href="https://www.spinellis.gr/pubs/jrnl/1997-CSI-WinApi/html/win.html">A Critique of the Windows Application Programming Interface</a>. At that time the possible error codes were 1130. As exemplified by the <a href="https://docs.microsoft.com/en-us/windows/win32/api/winbase/nf-winbase-openfile">documentation</a> of the Windows <em>OpenFile</em> function, things have not improved much in the past quarter century. Yet, there is a glimmer of hope. As I was reading the <a href="https://docs.microsoft.com/en-us/windows/win32/api/winreg/nf-winreg-regqueryvalueexa">documentation</a> of the <em>RegQueryValueExA</em> function, I was struck that it actually documented the reasons it could fail.</p>
<ul>
<li>If the lpData buffer is too small to receive the data, the function returns ERROR_MORE_DATA.</li>
<li>If the lpValueName registry value does not exist, the function returns ERROR_FILE_NOT_FOUND.</li>
</ul>
<p>Excitedly, I installed the 1999 MSDN Library documentation to see how it was documented back then. The error conditions were indeed missing: "ERROR_SUCCESS indicates success. A nonzero error code defined in Winerror.h indicates failure. To get a generic description of the error, call FormatMessage with the FORMAT_MESSAGE_FROM_SYSTEM flag set." Although the error behavior of thousands of Windows functions must still be properly specified, adding such documentation a move in the right direction. After all the <a href="https://s3.amazonaws.com/plan9-bell-labs/7thEdMan/v7vol1.pdf">1979 Seventh Research Edition Unix manual</a> also lacked detailed system call error documentation, lamely arguing that "The possible error numbers are not recited with each writeup in section 2, since many errors are possible for most of the calls." This was fixed a few years later, and we're still enjoying the fruits of that labor.</p>

<p>
<!-- COMMENTS --> <a href="https://www.spinellis.gr/cgi-bin/comment.pl?date=20200929#comments">Read and post comments</a>, or share through&nbsp;&nbsp;&nbsp;
<!-- Go to www.addthis.com/dashboard to customize your tools -->
</p>

</div></div>]]>
            </description>
            <link>https://www.spinellis.gr/blog/20200929/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24632979</guid>
            <pubDate>Tue, 29 Sep 2020 21:05:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Disinformation Demystified]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24632586">thread link</a>) | @animationwill
<br/>
September 29, 2020 | https://icyphox.sh/blog/disinfo/ | <a href="https://web.archive.org/web/*/https://icyphox.sh/blog/disinfo/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
            
            <h2>Misinformation, but deliberate</h2>
            <p>As with the disambiguation of any word, let’s start with its etymology and definiton.
According to <a href="https://en.wikipedia.org/wiki/Disinformation">Wikipedia</a>,
<em>disinformation</em> has been borrowed from the Russian word — <em>dezinformatisya</em> (дезинформа́ция),
derived from the title of a KGB black propaganda department.</p>

<blockquote>
  <p>Disinformation is false information spread deliberately to deceive.</p>
</blockquote>

<p>To fully understand disinformation, especially in the modern age, we need to understand the
key factors of any successful disinformation operation:</p>

<ul>
<li>creating disinformation (what)</li>
<li>the motivation behind the op, or its end goal (why)</li>
<li>the medium used to disperse the falsified information (how)</li>
<li>the actor (who)</li>
</ul>

<p>At the end, we’ll also look at how you can use disinformation techniques to maintain OPSEC.</p>

<p>In order to break monotony, I will also be using the terms “information operation”, or the shortened
forms—“info op” &amp; “disinfo”.</p>

<h2 id="creating-disinformation">Creating disinformation</h2>

<p>Crafting or creating disinformation is by no means a trivial task. Often, the quality
of any disinformation sample is a huge indicator of the level of sophistication of the
actor involved, i.e. is it a 12 year old troll or a nation state?</p>

<p>Well crafted disinformation always has one primary characteristic — “plausibility”.
The disinfo must sound reasonable. It must induce the notion it’s <em>likely</em> true. 
To achieve this, the target — be it an individual, a specific demographic or an entire
nation — must be well researched. A deep understanding of the target’s culture, history,
geography and psychology is required. It also needs circumstantial and situational awareness,
of the target.</p>

<p>There are many forms of disinformation. A few common ones are staged videos / photographs, 
recontextualized videos / photographs, blog posts, news articles &amp; most recently — deepfakes.</p>

<p>Here’s a tweet from <a href="https://twitter.com/thegrugq">the grugq</a>, showing a case of recontextualized
imagery:</p>

<blockquote data-dnt="true" data-theme="dark" data-link-color="#00ffff">
<div lang="en" dir="ltr"><p>Disinformation.
</p><p>
The content of the photo is not fake. The reality of what it captured is fake. The context it’s placed in is fake. The picture itself is 100% authentic. Everything, except the photo itself, is fake.
</p><p>Recontextualisation as threat vector. 
<a href="https://t.co/Pko3f0xkXC">pic.twitter.com/Pko3f0xkXC</a></p></div>— thaddeus e. grugq (@thegrugq) 
<a href="https://twitter.com/thegrugq/status/1142759819020890113?ref_src=twsrc%5Etfw">June 23, 2019</a>
</blockquote>

 

<h2 id="motivations-behind-an-information-operation">Motivations behind an information operation</h2>

<p>I like to broadly categorize any info op as either proactive or reactive. 
Proactively, disinformation is spread with the desire to influence the target
either before or during the occurence of an event. This is especially observed
during elections.<sup id="fnref-1"><a href="#fn-1">1</a></sup>
In offensive information operations, the target’s psychological state can be affected by
spreading <strong>fear, uncertainty &amp; doubt</strong>, or FUD for short.</p>

<p>Reactive disinformation is when the actor, usually a nation state in this case,
screws up and wants to cover their tracks. A fitting example of this is the case
of Malaysian Airlines Flight 17 (MH17), which was shot down while flying over 
eastern Ukraine. This tragic incident has been attributed to Russian-backed 
separatists.<sup id="fnref-2"><a href="#fn-2">2</a></sup> 
Russian media is known to have desseminated a number of alternative &amp; some even
conspiratorial theories<sup id="fnref-3"><a href="#fn-3">3</a></sup>, in response. The number grew as the JIT’s (Dutch-lead Joint
Investigation Team) investigations pointed towards the separatists. 
The idea was to <strong>muddle the information</strong> space with these theories, and as a result,
potentially correct information takes a credibility hit.</p>

<p>Another motive for an info op is to <strong>control the narrative</strong>. This is often seen in use
in totalitarian regimes; when the government decides what the media portrays to the
masses. The ongoing Hong Kong protests is a good example.<sup id="fnref-4"><a href="#fn-4">4</a></sup> According to <a href="https://www.npr.org/2019/08/14/751039100/china-state-media-present-distorted-version-of-hong-kong-protests">NPR</a>:</p>

<blockquote>
  <p>Official state media pin the blame for protests on the “black hand” of foreign interference, 
  namely from the United States, and what they have called criminal Hong Kong thugs.
  A popular conspiracy theory posits the CIA incited and funded the Hong Kong protesters, 
  who are demanding an end to an extradition bill with China and the ability to elect their own leader.
  Fueling this theory, China Daily, a state newspaper geared toward a younger, more cosmopolitan audience, 
  this week linked to a video purportedly showing Hong Kong protesters using American-made grenade launchers to combat police.
  …</p>
</blockquote>



<p>As seen in the above example of totalitarian governments, national TV and newspaper agencies
play a key role in influence ops en masse. It guarantees outreach due to the channel/paper’s
popularity.</p>

<p>Twitter is another, obvious example. Due to the ease of creating accounts and the ability to
generate activity programmatically via the API, Twitter bots are the go-to choice today for 
info ops. Essentially, an actor attempts to create “discussions” amongst “users” (read: bots),
to push their narrative(s). Twitter also provides analytics for every tweet, enabling actors to
get realtime insights into what sticks and what doesn’t.
The use of Twitter was seen during the previously discussed MH17 case, where Russia employed its troll
factory — the <a href="https://en.wikipedia.org/wiki/Internet_Research_Agency">Internet Research Agency</a> (IRA)
to create discussions about alternative theories.</p>

<p>In India, disinformation is often spread via YouTube, WhatsApp and Facebook. Political parties
actively invest in creating group chats to spread political messages and memes. These parties
have volunteers whose sole job is to sit and forward messages.
Apart from political propaganda, WhatsApp finds itself as a medium of fake news. In most cases,
this is disinformation without a motive, or the motive is hard to determine simply because
the source is impossible to trace, lost in forwards.<sup id="fnref-5"><a href="#fn-5">5</a></sup>
This is a difficult problem to combat, especially given the nature of the target audience.</p>

<h2 id="the-actors-behind-disinfo-campaigns">The actors behind disinfo campaigns</h2>

<p>I doubt this requires further elaboration, but in short:</p>

<ul>
<li>nation states and their intelligence agencies</li>
<li>governments, political parties</li>
<li>other non/quasi-governmental groups</li>
<li>trolls</li>
</ul>

<p>This essentially sums up the what, why, how and who of disinformation. </p>

<h2 id="personal-opsec">Personal OPSEC</h2>

<p>This is a fun one. Now, it’s common knowledge that
<strong>STFU is the best policy</strong>. But sometimes, this might not be possible, because
afterall inactivity leads to suspicion, and suspicion leads to scrutiny. Which might
lead to your OPSEC being compromised.
So if you really have to, you can feign activity using disinformation. For example,
pick a place, and throw in subtle details pertaining to the weather, local events
or regional politics of that place into your disinfo. Assuming this is Twitter, you can
tweet stuff like:</p>

<ul>
<li>“Ugh, when will this hot streak end?!”</li>
<li>“Traffic wonky because of the Mardi Gras parade.”</li>
<li>“Woah, XYZ place is nice! Especially the fountains by ABC street.”</li>
</ul>

<p>Of course, if you’re a nobody on Twitter (like me), this is a non-issue for you.</p>

<p>And please, don’t do this:</p>

<p><img src="https://icyphox.sh/static/img/mcafeetweet.png" alt="mcafee opsecfail"></p>

<h2 id="conclusion">Conclusion</h2>

<p>The ability to influence someone’s decisions/thought process in just one tweet is 
scary. There is no simple way to combat disinformation. Social media is hard to control.
Just like anything else in cyber, this too is an endless battle between social media corps
and motivated actors.</p>

<p>A huge shoutout to Bellingcat for their extensive research in this field, and for helping
folks see the truth in a post-truth world.</p>


 
          </article></div>]]>
            </description>
            <link>https://icyphox.sh/blog/disinfo/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24632586</guid>
            <pubDate>Tue, 29 Sep 2020 20:31:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The SaaS Marketing Educational Series]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24632541">thread link</a>) | @hronis
<br/>
September 29, 2020 | https://allfactors.com/blog/saas-marketing/ | <a href="https://web.archive.org/web/*/https://allfactors.com/blog/saas-marketing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<div>


<p>This is a free educational series of comprehensive blog posts intended to give you the knowledge and tools you need to take your SaaS marketing to the next level.</p>
<p>Whether you’re just starting out and want to figure out SaaS marketing or you’re an experienced SaaS marketer who wants to refresh your knowledge and learn new techniques, you’ve come to the right place!</p>
<p>In this SaaS marketing educational series we’ll release a new comprehensive blog post every week covering a topic in SaaS marketing. Starting from the fundamentals, all the way to advanced strategies and tactics. Including step by step guides and examples from other SaaS companies who’ve done it well. </p>
<p>Topics will include:</p>
<h2>1. The SaaS Marketing Plan</h2>
<figure><img loading="lazy" src="https://allfactors.com/wp-content/uploads/2020/09/saas-marketing-plan-1024x682.png" alt="SaaS Marketing Plan allfactors" width="467" height="311" srcset="https://allfactors.com/wp-content/uploads/2020/09/saas-marketing-plan-1024x682.png 1024w, https://allfactors.com/wp-content/uploads/2020/09/saas-marketing-plan-300x200.png 300w, https://allfactors.com/wp-content/uploads/2020/09/saas-marketing-plan-768x512.png 768w, https://allfactors.com/wp-content/uploads/2020/09/saas-marketing-plan-600x400.png 600w, https://allfactors.com/wp-content/uploads/2020/09/saas-marketing-plan.png 1280w" sizes="(max-width: 467px) 100vw, 467px"></figure>
<h3>How to create a SaaS marketing strategy</h3>
<p>SaaS marketing is different from selling products in an e-commerce store. Different goals, different customer behavior, different key performance indicators (KPIs), and a different business type. </p>
<p>The good news is that there is a pattern about SaaS and you can create a marketing strategy for it. We’ll go over the patterns you should know and how to think about marketing for SaaS.</p>
<h3>How to assess strategy-business-fit</h3>
<p>In SaaS you can have product-led motion and pricing structure, and you can have sales led motion and pricing structure. Your strategy has to take into consideration what customer acquisition and pricing motion is right for you, so you can tailor your plan according to that.</p>
<p>We’ll talk in detail about the differences between the go-to-market motions, and how you should approach your marketing so you can plan for strategy-business-fit for your SaaS. </p>
<h3>How to determine who does what </h3>
<p>Once you’ve defined your SaaS marketing strategy, you need to divide and conquer. Allocating the right tasks to the right people and empowering the team with the right tools and knowledge is super important in order to achieve productivity.</p>
<p>We’ll discuss the best ways to break silos between teams and teammates so everyone can be empowered to achieve the collective goals.</p>
<h2>2. The SaaS Marketing Techniques</h2>
<figure><img src="https://allfactors.com/wp-content/uploads/2020/09/saas-marketing-techniques-1024x685.png" alt="SaaS Marketing Techniques_allfactors" width="467" srcset="https://allfactors.com/wp-content/uploads/2020/09/saas-marketing-techniques-1024x685.png 1024w, https://allfactors.com/wp-content/uploads/2020/09/saas-marketing-techniques-300x201.png 300w, https://allfactors.com/wp-content/uploads/2020/09/saas-marketing-techniques-768x514.png 768w, https://allfactors.com/wp-content/uploads/2020/09/saas-marketing-techniques-600x401.png 600w, https://allfactors.com/wp-content/uploads/2020/09/saas-marketing-techniques.png 1280w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
<h3>The techniques that actually work in SaaS</h3>
<p>Online marketing has many techniques, we’ll talk about how to choose the right techniques for SaaS marketing specifically. From SEO to content marketing, to social media platforms and which ones make the most sense. To advertising and what you need to know about running ads for SaaS products.</p>
<p>There are lots of nuances in marketing techniques. It can take a lot of time to figure out what works for SaaS marketing, we’re here to save you time and share all the best practices. </p>
<h3>How to turn techniques into measurable tasks</h3>
<p>There is a popular quote in management that applies to marketing “you can’t manage what you can’t measure.” – Peter Drucker</p>
<p>Once you learn what techniques you should be using for your SaaS marketing, it’s very important to learn how to measure the tasks that every technique entails. </p>
<h3>Common mistakes to avoid when executing</h3>
<p>If you can learn what mistakes to avoid you’ll shorten the learning curve, and achieve your desired results faster. </p>
<p>We’ll have a collection of stories and examples for you of what mistakes to avoid when it comes to SaaS marketing.</p>
<h3>Key Performance Indicators that matter</h3>
<p>When it comes to key performance indicators for your SaaS marketing results, there can be a ton of data points. But there are only a few that really matter and move the needle.</p>
<p>We’ll show you the most important KPIs for SaaS companies and how they should be aligned with the team’s marketing activities. </p>
<h2>3. How to Optimize SaaS Marketing</h2>
<figure><img src="https://allfactors.com/wp-content/uploads/2020/09/optimize-saas-marketing-2-1024x651.png" alt="optimize saas marketing" width="467" srcset="https://allfactors.com/wp-content/uploads/2020/09/optimize-saas-marketing-2-1024x651.png 1024w, https://allfactors.com/wp-content/uploads/2020/09/optimize-saas-marketing-2-300x191.png 300w, https://allfactors.com/wp-content/uploads/2020/09/optimize-saas-marketing-2-768x488.png 768w, https://allfactors.com/wp-content/uploads/2020/09/optimize-saas-marketing-2-600x381.png 600w, https://allfactors.com/wp-content/uploads/2020/09/optimize-saas-marketing-2.png 1471w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
<h3>What metrics you should pay attention to</h3>
<p>To drive growth and move the needle forward we need to pay attention to specific metrics, and ignore other metrics because they can be a distraction or just vanity.</p>
<p>We’ll discuss how to recognize which metrics are the most important for driving growth and which metrics are vanity for SaaS marketing. </p>
<h3>What it takes to consistently move the needle</h3>
<p>The thing about growth is that depending on the SaaS marketing technique, at some point the growth slows down. Especially when it comes to driving growth through ads, when you stop the ads, does the growth stop?</p>
<p>We’ll cover how to make sure that growth doesn’t stop even if one of your techniques stops working or if you run out of budget for ads.</p>
<h3>How to automate and do more of what works</h3>
<p>You can save a lot of time by putting certain SaaS marketing activities on autopilot by using marketing tools. From email marketing automation, to SEO, to advertising. </p>
<p>We’ll look at ways to automate those marketing activities, so they can be ‘working for you while you sleep’. </p>
<h3>Case studies of other SaaS companies doing marketing well</h3>
<p>A great way to learn how to do SaaS marketing and take action is by getting inspired with other SaaS companies who’ve done it well using best practices.</p>
<p>We’ll look at SaaS marketing case studies of companies who are role models for certain strategies executed very well. We’ll go over the execution step by step and explain how they did things, our hypothesis for why it worked, and how it can work for you.</p>
<p><strong>Subscribe to the series and share</strong> </p>
<p>If you haven’t yet, make sure to subscribe to our newsletter via the email box so you can receive a free educational piece every week.</p>
<p>Follow us on Twitter <a href="https://twitter.com/AllFactors" target="_blank" rel="noopener">@AllFactors</a> to receive the latest SaaS marketing tips. </p>
</div>
</div>

</div></div>]]>
            </description>
            <link>https://allfactors.com/blog/saas-marketing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24632541</guid>
            <pubDate>Tue, 29 Sep 2020 20:26:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Choosing a commenting plugin and integrating Hyvor Talk in Hugo]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24632394">thread link</a>) | @lokethien
<br/>
September 29, 2020 | https://www.andreasrein.net/posts/hyvor-talk-hugo-commenting-systems/ | <a href="https://web.archive.org/web/*/https://www.andreasrein.net/posts/hyvor-talk-hugo-commenting-systems/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<article>
  
  <div><p>You can see Disqus on most blogs, but there are multiple privacy-respecting, cheap and appealing alternatives. I have decided to add Hyvor Talk to my blog.</p>

<h2 id="why">Why</h2>

<p>This post is an opinionated guide to picking a cheap/free, appealing, and functional third-party <code>non-self-hosted</code> commenting plugin for a static blog. I have only included service-based plugins to keep it simple.</p>

<p>When I first created this blog, I chose to not include a commenting system since I didn’t see the point of it, and it made the site sluggish (Disqus). I have never been much of a commenter, and you can find my social accounts if you have any questions about the content. But I guess it’s much more convenient for people to drop in a comment without leaving the article.</p>

<p>So the plan is to test it a year and see if the activity can justify the price and maintenance.</p>

<h2 id="alternatives">Alternatives</h2>

<p>There are quite some to choose from, but they vary by their level of trustworthiness and the number of ads, trackers, and <em>American spies</em> they inject.</p>



<ul>
<li>Price from: Free</li>
<li>Size: <strong>267,14 KB</strong> (241,13 KB JS and 26,01 KB CSS)</li>
<li>Ads: Yes but you can remove it by paying</li>
</ul>

<p><img src="https://www.andreasrein.net/images/07-hyvor-talk-hugo/disqus-look.png"></p>

<p>The de-facto standard for online comments, but I have never been a fan of it. It’s also huge and loads nasty ads, so no thanks.</p>

<p>A blog should load blazingly fast so we cannot sacrifice precious speed by adding an enormous amount of JS just for the sake of providing a commenting system. One option is to have a button that loads it so it won’t affect the initial page load.</p>

<p><img src="https://www.andreasrein.net/images/07-hyvor-talk-hugo/disqus-js-files.png"></p>



<ul>
<li>Price: Free</li>
<li>Size: <strong>600,39 KB</strong> (576,65 KB JS and 23,74 KB CSS)</li>
<li>Ads: Yes</li>
</ul>

<p><img src="https://www.andreasrein.net/images/07-hyvor-talk-hugo/fb-look.png"></p>

<p>Ah, Facebook. The interface and overall commenting system are not bad at all. But it’s loaded with trackers, ads, and more trackers. It’s gloomy that we have to load 600 KB of data just to comment online in 2020.</p>

<p><img src="https://www.andreasrein.net/images/07-hyvor-talk-hugo/fb-js-files.png"></p>



<ul>
<li>Price from: $7/month</li>
<li>Size: <strong>49,18 KB</strong> (43,65 KB JS and 5,53 KB CSS)</li>
<li>Ads: No</li>
</ul>

<p><img src="https://www.andreasrein.net/images/07-hyvor-talk-hugo/remarkbox-look.png"></p>

<p>Well, it’s lightweight, fast and have markdown support. Apart from that, it doesn’t have too much going for it. The landing page is nice and you can easily control the behaviour and apperance which is a nice addition.</p>



<ul>
<li>Price from: $5</li>
<li>Size: <strong>36,94 KB</strong> JS</li>
<li>Ads: No</li>
</ul>

<p><img src="https://www.andreasrein.net/images/07-hyvor-talk-hugo/justcomments-look.png"></p>

<p>First impressions from the landing page is good but I don’t feel the same when I see the commenting system itself. It is customizable and JustComments is a pay-as-you-go service so that’s swell.</p>



<ul>
<li>Price from: Free (100 comments per month). $10 for unlimited comments.</li>
<li>Size: <strong>9,79 KB</strong> JS</li>
<li>Ads: No</li>
</ul>

<p><img src="https://www.andreasrein.net/images/07-hyvor-talk-hugo/commentbox-look.png"></p>

<p>CommentBox has a limited free plan and the interface feels familiar. You can reply, vote, flag and pin comments. It’s also extremely lightweight with just under 10 KB of JS.</p>



<ul>
<li>Price from: $5</li>
<li>Size: <strong>14,04 KB</strong> JS</li>
<li>Ads: No</li>
</ul>

<p><img src="https://www.andreasrein.net/images/07-hyvor-talk-hugo/fastcomments-look.png"></p>

<p>FastComments is also very lightweight. The interface is functional and simplistic. They also have a lot of neat features like spam fighting and the ability to import from other commenting systems like Disqus.</p>



<ul>
<li>Price from: $10</li>
<li>Size: <strong>16,48 KB</strong> (9,51 KB JS and 6,97 KB CSS)</li>
<li>Ads: No</li>
</ul>

<p><img src="https://www.andreasrein.net/images/07-hyvor-talk-hugo/commento-look.png"></p>

<p>I like the catchphrase “Embed comments without giving up your privacy.”. The website itself gives a good first impression. Modern, sleek and fast. The design is sleek and pretty. The cheapest plan is tad expensive for a simple dev blog compared to other offers.</p>

<h3 id="hyvor-talk-https-talk-hyvor-com-aff-10484"><a href="https://talk.hyvor.com/?aff=10484">Hyvor Talk</a></h3>

<ul>
<li>Price from: $5</li>
<li>Size: <strong>112,3 KB</strong> (104,34 KB JS and 7,96 KB CSS)</li>
<li>Ads: No</li>
</ul>

<p><img src="https://www.andreasrein.net/images/07-hyvor-talk-hugo/hyvor-look.png"></p>

<p>Hyvor Talk boosts more KB but at least it’s lazy-loaded so it won’t affect the page performance. What wins me over is the playful, lovely, and feature-packed interface. The reactions part is a delightful addition since it doesn’t require much effort for readers to click on and it gives me valuable feedback on my posts.</p>

<p>In other words, Hyvor Talk feels like it was built with love and passion. Those are values I can stand behind and it feels good to support them. So let’s see how it goes and if you want to test it out, scroll to the bottom and write a comment.</p>

<h2 id="add-hyvor-talk-to-hugo">Add Hyvor Talk to Hugo</h2>

<p>To add Hyvor Talk to your Hugo based blog, simply paste this code in the bottom of the footer (found in the template you are using). This code may change so be sure to verify with the <a href="https://talk.hyvor.com/docs/code">official docs</a>.</p>

<pre><code>{{ if in .Page.Dir "posts" }}
&lt;script type="text/javascript"&gt;
    var HYVOR_TALK_WEBSITE = 2018; // DO NOT CHANGE THIS
    var HYVOR_TALK_CONFIG = {
        url: "URL_TO_YOUR_WEBSITE",
        id: 'UNIQUE_POST_ID'
    };
&lt;/script&gt;
{{ end }}
</code></pre>

<p>The ID is a unique ID that links the comments and your post. You can use <code>ìd: '{{ .File.UniqueID }}'</code> but remember that if you change the file name of the post, the ID will also change since it’s a hash of the file name.</p>

<p>The better way is to include an ID in the filename. Example filename: <code>07-hyvor-talk-hugo.md</code> and if you want to use 07 as the ID, use this code <code>id: '{{ index (split .File.LogicalName "-") 0 }}'</code>.</p>

<p>If you disagree, agree, or have anything in your heart, please, feel free to <em>write a comment</em>.</p></div>
</article>
</div></div>]]>
            </description>
            <link>https://www.andreasrein.net/posts/hyvor-talk-hugo-commenting-systems/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24632394</guid>
            <pubDate>Tue, 29 Sep 2020 20:13:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Thoughts on Cloudflare Web Analytics]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24632382">thread link</a>) | @jlelse
<br/>
September 29, 2020 | https://jlelse.blog/thoughts/2020/09/cwa/ | <a href="https://web.archive.org/web/*/https://jlelse.blog/thoughts/2020/09/cwa/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Cloudflare currently celebrate their 10th birthday and launch a new product or feature everyday for a week. Today they launched <a href="https://www.cloudflare.com/web-analytics/" target="_blank" rel="noopener">Cloudflare Web Analytics</a>. Until now you had to proxy your site through Cloudflare to use their analytics, because they collected those stats – “at the edge” – on their servers. But now they are adding an JavaScript-based option, similar to Google Analytics and all the new privacy-focused analytics services like <a href="https://www.goatcounter.com/" target="_blank" rel="noopener">GoatCounter</a> and <a href="https://plausible.io/" target="_blank" rel="noopener">Plausible</a>. But like GoatCounter and Plausible and unlike Google, they promise privacy, because they don’t make their money tracking users, but selling products (that aren’t users) – at least that’s what they say in <a href="https://blog.cloudflare.com/free-privacy-first-analytics-for-a-better-web/" target="_blank" rel="noopener">the announcement post on their blog</a>:</p><blockquote><p>Cloudflare’s business has never been built around tracking users or selling advertising. We don’t want to know what you do on the Internet — it’s not our business. So we wanted to build an analytics service that gets back to what really matters for web creators, not necessarily marketers, and to give web creators the information they need in a simple, clean way that doesn’t sacrifice their visitors' privacy.</p></blockquote><p>They try to be even more privacy-friendly then most of the privacy-focused analytics services by taking a different approach regarding “unique visits”:</p><blockquote><p>What does it mean for us to make our analytics “privacy-first”? Most importantly, it means we don’t need to track individual users over time for the purposes of serving analytics. We don’t use any client-side state, like cookies or localStorage, for the purposes of tracking users. And we don’t “fingerprint” individuals via their IP address, User Agent string, or any other data for the purpose of displaying analytics. (We consider fingerprinting even more intrusive than cookies, because users have no way to opt out.)</p></blockquote><p>That’s the thing that made me write <a href="https://jlel.se/kis3" target="_blank" rel="noopener">my own analytics tool</a>. I don’t need those “unique” statistics, I just want to see very basic stats about which page gets how many views – and I can’t just look at my server logs because I use <a href="https://bunnycdn.com/" target="_blank" rel="noopener">BunnyCDN</a> in front of my origin server. Even many privacy-focused analytics tools generate some kind of identifier (even if they reset it every day) to fingerprint specific users and calculate “unique visitors”.</p><p>I’m interested into whether they provide this analytics service for free or charge some money for it. Currently it’s only available for users who already have a paid Cloudflare plan. But they promise to make this service even available for people not yet using Cloudflare, so that they don’t have to change any DNS entries etc. While I see Cloudflare’s internet dominance with a critical eye and am annoyed when their bot protection system shows me a captcha, I’m grateful that they provide their DNS service for free and also allow at-cost domain registration.</p></div></div>]]>
            </description>
            <link>https://jlelse.blog/thoughts/2020/09/cwa/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24632382</guid>
            <pubDate>Tue, 29 Sep 2020 20:11:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I healed by finding the right diet thanks to a few lines of code]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24632308">thread link</a>) | @camilleroux
<br/>
September 29, 2020 | https://www.camilleroux.com/2020/09/29/irritable-bowel-syndrom-medical-journey-full-of-pitfalls-but-with-a-positive-outcome/ | <a href="https://web.archive.org/web/*/https://www.camilleroux.com/2020/09/29/irritable-bowel-syndrom-medical-journey-full-of-pitfalls-but-with-a-positive-outcome/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
<p>I was diagnosed over a year ago with an <a href="https://en.wikipedia.org/wiki/Irritable_bowel_syndrome" target="_blank" rel="noreferrer noopener">Irritable Bowel Syndrom</a> (also called functional colopathy, IBS, Irritable Colon Syndrom or ICS for those in the know). For about 6 months, I was continuously sick.</p>
<p>I will tell you the story of my chaotic (and sadly common) medical journey with this disease, which strikes about 10% of the world population (<a href="https://www.gastrojournal.org/article/S0016-5085(02)00481-X/abstract" target="_blank" rel="noreferrer noopener">source</a>). I’m also going to tell you about its important negative and positive impacts on my life.</p>
<p>Today, I’m much better. After meeting many doctors and specialists, I have finally found the personalized diet which allows me not to be sick anymore. It was mainly thanks to the help of a dieticien and by reading many articles. I also spent a lot of time finding the links between my episodes and my meals.&nbsp;</p>
<p>For a long time; I was reluctant to openly talk about my disease because I was afraid it could harm me one day. But after a <a href="https://twitter.com/CamilleRoux/status/1138066899110105088" target="_blank" rel="noreferrer noopener">post</a> on Twitter, a lot of comments encouraged me to do so and convinced me it was useful. The lack of information and support by doctors seems unfortunately very common. </p>
<p>I wrote this article in order to:&nbsp;&nbsp;&nbsp;&nbsp; </p>
<ul><li>Encourage and maybe give some ideas to people with the same disease</li><li>Show doctors that some existing diets works. It’s not inevitably about stress. It was useless to recommend alternative medicines to me.</li><li>Show the medical field that, like many patients, I have wasted a lot of time because of the lack of information and doctor’s support.</li><li>Add a witness for the press, patient associations and doctors and show them the urgency for doctors to get training, for the food industry and restaurants to adjust and ease the life of low-FODMAP diet patients, to show the importance of getting sure, true and updated information in French on the web.</li><li>Help to talk openly about intestinal diseases. </li><li>Thank my entourage who support me and adapt to my constraints.&nbsp;&nbsp;&nbsp;&nbsp;</li></ul>
<h2>Act 1: Symptoms Emergence&nbsp;</h2>
<p>All seemed to begin on May 12th, 2018. It was about 7 p.m., I was having a cocktail dinner at home with some common foods: some French cheese (Comté, Ossau-Iraty), hummus, bread and beer. Around the end of the evening, I began to feel nauseous and to get abdominal pain.<br>The next day when I woke up, I felt more nauseous. I was not hungry at all. I forced myself to eat a little bit of white rice at lunch and, at the end of the afternoon, all got right back and I could normally eat again. </p>
<p>Everything was fine in my life. My job was going well and I was going on vacation in the next few days. Nothing was a source of stress for me. </p>
<p>May 15th: For lunch I was preparing a salad, again with some common products: lettuce, tomato, pepper, beetroot, seeds, cereal mix and dried vegetables. At the end of the afternoon, I got nausea and abdominal pain again that lasted all evening. The next morning, my health got back to normal.&nbsp;</p>
<p>But the same thing happened on may 18th and 24th… After each episode, I naively tried to change my diet based on what I read online. I tried to eat less acidic, less fat, to follow a diet advised by a gastroenterologist but nothing got better. </p>
<p>At the first episode, I guessed it could be due to a virus, a gastroenteritis, or food poisoning… But with time it looked like nothing I had ever known.&nbsp;As soon as I came back home from vacation, I decided to see my general practitioner (GP).</p>
<p>I took the habit of writing everything I ate, my symptoms, and my episodes. That allowed me to easily explain the situation to my GP and check any link with food. You’re going to understand its usefullness!</p>
<h3>Description of my usual episode</h3>
<p>All attacks looked alike. Intensity and duration could vary, but it usually started with nausea (that gradually appeared in about 1-2 hours), then tiredness. Nausea lasted for some hours. I rarely skipped more than one meal. Most of the time, I postponed my meal for few hours. It could be along with variable intense abdominal pain and bloating. </p>
<p>Then, usually, I got some intestinal disorders and abdominal pain for few days. Then everything got slowly better.&nbsp;</p>
<p>Unfortunately, I rarely got back to a normal state. Usually, a new episode appeared before the previous one completely disappeared.&nbsp;</p>
<h2>Act 2: The first disapointment</h2>
<div><figure><img loading="lazy" width="244" height="300" src="https://www.camilleroux.com/wp-content/uploads/2020/09/Capture-de%CC%81cran-2020-01-23-a%CC%80-16.27.13-1-244x300.png" alt="" srcset="https://www.camilleroux.com/wp-content/uploads/2020/09/Capture-de%CC%81cran-2020-01-23-a%CC%80-16.27.13-1-244x300.png 244w, https://www.camilleroux.com/wp-content/uploads/2020/09/Capture-de%CC%81cran-2020-01-23-a%CC%80-16.27.13-1-500x615.png 500w, https://www.camilleroux.com/wp-content/uploads/2020/09/Capture-de%CC%81cran-2020-01-23-a%CC%80-16.27.13-1-400x492.png 400w, https://www.camilleroux.com/wp-content/uploads/2020/09/Capture-de%CC%81cran-2020-01-23-a%CC%80-16.27.13-1-250x307.png 250w, https://www.camilleroux.com/wp-content/uploads/2020/09/Capture-de%CC%81cran-2020-01-23-a%CC%80-16.27.13-1-200x246.png 200w, https://www.camilleroux.com/wp-content/uploads/2020/09/Capture-de%CC%81cran-2020-01-23-a%CC%80-16.27.13-1-100x123.png 100w, https://www.camilleroux.com/wp-content/uploads/2020/09/Capture-de%CC%81cran-2020-01-23-a%CC%80-16.27.13-1-76x93.png 76w, https://www.camilleroux.com/wp-content/uploads/2020/09/Capture-de%CC%81cran-2020-01-23-a%CC%80-16.27.13-1-50x61.png 50w, https://www.camilleroux.com/wp-content/uploads/2020/09/Capture-de%CC%81cran-2020-01-23-a%CC%80-16.27.13-1.png 602w" sizes="(max-width: 244px) 100vw, 244px" data-srcset="https://www.camilleroux.com/wp-content/uploads/2020/09/Capture-décran-2020-01-23-à-16.27.13-1-244x300.png 244w, https://www.camilleroux.com/wp-content/uploads/2020/09/Capture-décran-2020-01-23-à-16.27.13-1-500x615.png 500w, https://www.camilleroux.com/wp-content/uploads/2020/09/Capture-décran-2020-01-23-à-16.27.13-1-400x492.png 400w, https://www.camilleroux.com/wp-content/uploads/2020/09/Capture-décran-2020-01-23-à-16.27.13-1-250x307.png 250w, https://www.camilleroux.com/wp-content/uploads/2020/09/Capture-décran-2020-01-23-à-16.27.13-1-200x246.png 200w, https://www.camilleroux.com/wp-content/uploads/2020/09/Capture-décran-2020-01-23-à-16.27.13-1-100x123.png 100w, https://www.camilleroux.com/wp-content/uploads/2020/09/Capture-décran-2020-01-23-à-16.27.13-1-76x93.png 76w, https://www.camilleroux.com/wp-content/uploads/2020/09/Capture-décran-2020-01-23-à-16.27.13-1-50x61.png 50w, https://www.camilleroux.com/wp-content/uploads/2020/09/Capture-décran-2020-01-23-à-16.27.13-1.png 602w" data-src="https://www.camilleroux.com/wp-content/uploads/2020/09/Capture-décran-2020-01-23-à-16.27.13-1-244x300.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure></div>
<p>At the end of May, I went to my GP. I showed her my diet diary, but all seemed right to her. She supposed it was a acidic stomach disorder and prescribed, for few weeks, a treatment with an impressive name: a proton pump inhibitor drug called Lansoprazole in French.&nbsp;</p>
<p>I don’t remember this period very well, but I think I didn’t get any episode until the beginning of July. I thought the drug was working at first but, unfortunately, the episodes reappeared at the beginning of July while I was taking this treatment for a month. </p>
<p>Episodes were linked and overlapped.&nbsp;</p>
<h2>Act 3: Failed attempts of GP</h2>
<p>It was summerime, either my GP or me went on vacation alternatively. So, I consulted different GPs.&nbsp;</p>
<p>Mid-July, I was on vacation in the Pyrenees. I decided to consult a local GP because I’ve been in pain&nbsp; for one week and the long treatment prescribed by my GP wasn’t working at all.&nbsp;<br>I explained the regular episodes I got since the last 2 months. This GP prescribed me a wormer treatment (Fluvermal in French) and charcoal against bloating.<br>No effect at all. </p>
<p>The impact on my life was quite important. I often felt pain and regularly tired. As attacks could happen in a matter of minutes/hours, I often cancelled my outings with my entourage. <br>I finally decided not to plan anything ahead. I dropped&nbsp; all my summer projects. I saw my entourage less and less. This disease started to isolate me. <br>I got more and more episodes and they were linking up. I rarely spent a day without symptoms. </p>
<p>Back from my vacation, I got a new episode. I consulted my GP and she prescribed a treatment against gastric reflux (SODIUM ALGINATE/SODIUM BICARBONATE) and a yeast (Saccharomyces boulardii) in order to go over my intestinal disorders and restore my intestinal flora.<br>No effect at all.</p>
<p>At the end of July, I consulted GP emergency because I was getting an attack during the weekend. It was more painful than usual and my GP was on vacation. For this GP, nothing was alarming and he prescribed me Spasfon and a blood test (which results were normal).&nbsp;<br>Spasfon had no effect. </p>
<p>Consulting different GP was exhausting. Each time I had to explain my situation again, show my diary, detail what the previous GPs ever did.&nbsp;<br>Many of them only focused on stress factor. I often had to argue that stress was not what made me sick. Some of them even argue that I could have been stressed unconsciously.&nbsp;<br>Regularly, they stepped out of their expertise fields by suggesting some alternative medicines: naturopathy, homeopathy, acupuncture… which I categorically refused. </p>
<p>At the beginning of August, after a few days of serenity, a new crisis came. I went again to see my GP who was back from her vacations at least. <br>She took things seriously and sent me for an echography. Results: normal.<br>I also went for a stool analysis. Results: normal.<br>Then, she sent me for a last test for <em>Helicobacter Pylori Infection</em> and said that she would send my to consult a gastroenterologist if the result was negative. <br>One week later, the resultats came back, negative.</p>
<p>I went back to my GP and she gave me a letter to consult a specialist. At that time, I was pretty confident, about a possible solution. I was impatient to meet the specialist in order to finally find why I was so sick.&nbsp;</p>
<p>I made my first phone call but they proposed an appointment several months later. </p>
<p>While my disease was ruining my life, preventing me from working and getting a social life, doctors all agreed that there was no emergency. I just had to take my pain patiently.&nbsp;</p>
<p>I spotted a practice that proposed an appointment at the end of September. This was by far the best date. I have a long month to wait…<br>I asked them if they sometimes had some cancellations. They answered me positively and advised me to call when I want to check if they had any cancellation. I called them twice a day… until I got an appointment on September 5th.&nbsp;</p>
<h2>Act 4: The reserved diagnosis of the gastroenterologist</h2>
<p>September 5th: I was happy to finally explain my situation to a specialist.<br>But I was quickly disillusioned. The consultation was cold and fast (15 minutes). The gastroenterologist didn’t know if the problem was due to the stomach or the intestine. So she decided to prescribe a treatment for both. I left her with very few additional information and a 3 months renewable prescription:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p>
<ul><li>Aflorex (one month): food supplement used to balance the intestinal microbiota</li></ul>
<ul><li>Bedelix: digestive clay dressing</li></ul>
<ul><li>Meteospasmyl: antispasmodic and a silicone dressing</li></ul>
<ul><li>Imodium: antidiarrheal</li></ul>
<ul><li>Trimebutine: regulates intestine motricity</li></ul>
<p>At the end of the appointment, I asked her if she knew what I had. She told me it could be a stomach inflammation, functional colopathy… (the list went on)</p>
<p>The functional colopathy was one of the most probable hypothesis according to her. If so, she told me that the treatment should help me and that, anyway, she wouldn’t be able to do much better.</p>
<h3>Some astonishing food recommendations</h3>
<p>She also gave me dietary advices to regulate my transit and therefore reduce my pain and my episodes:</p>
<p><em>– 2 fresh kiwis on mornings, preferably on an empty belly<br>– Pineapple juice <br>– Non-whole grains at breakfast <br>– Mineral water (brand HEPAR) up to 1 liter a day <br>– Oil RESTRICAL to spice hot meals (do not cook) <br>– Spinach <br>– Oleaginous dry fruits (nuts, hazelnuts, almonds, …) <br>– Cooked prunes on the evening (3 to 4 with cooking juice) <br>– AXAROLA, one pill an evening <br>– FRUITS AND FIBERS, one pill an evening</em></p>
<p>This came from a very good intention, except that with a suspicion of functional colopathy, it was absurd (in my opinion) for several reasons<strong>.</strong></p>
<p>I’m going to explain my point of view later below, but when you have a colopathy, it is often beneficial to remove (or at least diminish) FODMAPs from your diet. The efficiency looks obvious: a study showed that a low-FODMAP diet had a beneficial effect on 86% of …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.camilleroux.com/2020/09/29/irritable-bowel-syndrom-medical-journey-full-of-pitfalls-but-with-a-positive-outcome/">https://www.camilleroux.com/2020/09/29/irritable-bowel-syndrom-medical-journey-full-of-pitfalls-but-with-a-positive-outcome/</a></em></p>]]>
            </description>
            <link>https://www.camilleroux.com/2020/09/29/irritable-bowel-syndrom-medical-journey-full-of-pitfalls-but-with-a-positive-outcome/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24632308</guid>
            <pubDate>Tue, 29 Sep 2020 20:05:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Miniaudio – single file audio playback and capture library]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24632136">thread link</a>) | @jakearmitage
<br/>
September 29, 2020 | https://miniaud.io/index.html | <a href="https://web.archive.org/web/*/https://miniaud.io/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://miniaud.io/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24632136</guid>
            <pubDate>Tue, 29 Sep 2020 19:50:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nothing in user acceptance testing is technical. It’s wholly political]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24632093">thread link</a>) | @ohjeez
<br/>
September 29, 2020 | https://www.functionize.com/blog/3-things-you-ought-to-know-about-user-acceptance-testing/ | <a href="https://web.archive.org/web/*/https://www.functionize.com/blog/3-things-you-ought-to-know-about-user-acceptance-testing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><img width="1080" height="634" src="https://3laqvw22wekb3ykm8z4dbnq8-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/ft-acceptance-beer.jpg" alt="3 things you ought to know about User Acceptance Testing" srcset="https://www.functionize.com/wp-content/uploads/2020/09/ft-acceptance-beer.jpg 1080w, https://www.functionize.com/wp-content/uploads/2020/09/ft-acceptance-beer-300x176.jpg 300w, https://www.functionize.com/wp-content/uploads/2020/09/ft-acceptance-beer-1024x601.jpg 1024w, https://www.functionize.com/wp-content/uploads/2020/09/ft-acceptance-beer-768x451.jpg 768w" sizes="(max-width: 1080px) 100vw, 1080px">      </p>	  
    
        <blockquote><p>The problems you encounter with user acceptance testing aren’t technical. They’re all political. You can’t solve all of the messes when things go wrong – but you can do quite a bit to prevent them.</p></blockquote>
<p>Users are required to have intimate involvement with application development at only two points in a project: at the beginning, and at the very end. At the beginning of the project, the user has to explain what he wants the software to do, so that requirements can be created – whether that specification is as simple as, “I need a utility to back up these files” or a requirements document as long as some novels.</p>
<p>Agile methodologies encourage user participation throughout the development process, which can improve the likelihood of a positive result. Be that as it may, the other point where an end user <em>must</em> get involved is at the end of the project: <a href="https://www.functionize.com/blog/understanding-user-acceptance-testing-for-better-results/">user acceptance testing</a> (UAT). That project phase has a lot of names, though my own working definition is “the last phase of the testing cycle, right before the team goes out for a celebratory beer.”</p>
<p>Only a few challenges in “acceptable” acceptance testing are about the tests. The transition from “bits of code that might work” to an application ready to go into production is more political than technical. The Acceptance Testing phase is the last opportunity for someone outside the QA or development team to stick a thumb in the pie. You know whom I’m talking about: the people for whom the word “deadline” doesn’t seem to apply (“I know I was supposed to identify problems last month, but gosh this is really important”); political shenanigans when management wants to take credit or cover their butts; consulting clients who are determined to find problems to avoid paying a time-based delivery bonus.</p>
<p>As a result, the celebratory beer is short lived if users respond, “This is wrong, and that is not right, and I really wanted this over here, and oh, by the way, we decided that we really didn’t need this functionality after all, so could you take it out?”</p>
<p>Good beer should never be wasted, so let’s see what we can do about this issue. (Note that I collected this input years ago, so I filed off my QA contacts’ names. However, none of their advice has changed.)</p>
<h3>Set expectations</h3>
<p>I seem to have a bullet point about correctly setting expectations in <a href="https://www.functionize.com/blog/5-rules-for-successful-test-automation/">every article I write</a>, but it’s become obvious how much it matters for <em>every</em> QA endeavor. None more importantly, however, than in defining up front what the user considers acceptable. That’s simply <em>got</em> to happen at the beginning of the project – or, failing that, at some point before you drop the completed application in their laps.</p>
<p>When developers create a requirements document, they think primarily about establishing what the application needs to do, and what it must accomplish before the software goes to production. However, defining the acceptance criteria early – as part of the requirements process – both helps you find hidden, unspoken requirements, and shows users what this testing stuff is all about.</p>
<p>As consultant David says, “End users discover something they don’t like – whether it is a real problem or not, whether it is per spec or not. Then they promptly declare the entire product rubbish based on that single point observation. They have no accountability, but seemingly magical authority to send the entire project back to the drawing board, and at the very last stage of the game.”</p>
<p>“An acceptance test is a type of contract between the users (or their representatives) and the producers, saying in essence ‘If you can do <em>this</em>, then the product is acceptable,'” says a tester named Joe. “But as professional QA testers can attest, it’s never quite that simple.” All sorts of unstated assumptions are left out of the Acceptance Criteria, and can become the subject of negotiation near the end of the development cycle. Those can turn into political shenanigans, development bashing, or delaying tactics, if not handled well.</p>
<h3>Put someone In charge</h3>
<p>While it won’t necessarily solve all the problems – I don’t think anything will – some QA professionals find that you can discover or prevent difficulties by creating a UAT team (even if that’s only one person) to deal with the users. That person works closely with the customer, holds their hand, guides them, and cajoles them throughout the project to do what they need to do. That individual should be experienced, able to build relationships, and well respected. (A heart that’s pure and the strength of ten would not go amiss, either.)</p>
<p>It’s also important for the liaison to <a href="https://www.functionize.com/blog/how-to-do-a-product-evaluation-for-enterprise-software/">deal with the right users</a>. The business users who define the functional specs may not be the people who use the system. One tester described a project that had to go back to the drawing board; this time, the functional requirements were created by people who actually used the system. Imagine that.</p>
<p>In other situations, as QA professional Christian points out, managers show up at the beginning of the project to approve milestones and budgets. The managers let actual users or their representatives define requirements and ensure that budgets and timetables are on track. But then, says Christian, the managers show up again at UAT time because the project needs their go-ahead (such as to approve the use of people or machine resources). Suddenly, project management responsibilities are reshuffled. People who were previously uninvolved or had little to say if budgets were on track, are now confronted with the reality of the work and all the imperfections it holds. “<a href="https://www.functionize.com/blog/how-to-recognize-the-warning-signs-of-a-project-crisis/">Here comes the political mess</a>,” Christian says.</p>
<h3>Will the dog eat it?</h3>
<p>Software developers, testers, and users can get so wrapped up in the process of creating an application that they lose sight of the effect of deploying it. Unfortunately, this may not become apparent until it’s time for user acceptance testing.</p>
<p>Fritz, a project management consulting, explains, “A damn good reason for acceptance testing that is to make sure the new functionality will actually enhance, not hinder, business operations. Until a workable product is demonstrated for evaluation, the users may find it hard to understand the ins-and-outs of how their operation will change once the software is deployed, which makes UAT a major risk management effort.” In other words: Once the users discover how the new software affects their jobs, they realize they don’t want it after all.</p>
<p>Fritz sees this as a reason to adopt, if not the full Agile development set of methodologies, at least some of its underlying philosophy. The requirements-development-UAT cycle “demonstrates that the requirements are merely a starting point and the user feedback is essential to refine requirements prior to the next cycle,” he says.</p>
<p>Stephen, a consultant, concurs. “We deliver early, pre-production code, for demonstration and further definition. We go back to the shop to re-tool around the aspects found during the latest discovery session. This can be repeated – based on the scope of the project – several times.”</p>
<p>Whether you do this as an application prototype or as <a href="https://www.functionize.com/blog/lets-make-testing-agile-they-said-uh-what-did-they-mean-by-that/">an Agile development cycle</a>, developers and testers say that it make a huge difference. “This process puts 90% of the acceptance testing up front, and allows us a way to challenge scope creep once the&nbsp; requirements and prototype have been signed off on,” says Scott, an independent software vendor.</p>
<p>In the end, the question comes down to creating an application that adds value to the user. And that’s exactly what makes UAT so messy. “The number one problem with UAT testing is that it is political. Some of the things the user may not like, or that negatively impact their workflow, are not actual functional errors. Therefore, the system may have passed every test run with flying colors and is still ‘wrong,’ says Linda a QA manager. “Overall, it doesn’t matter if you produce a perfectly-balanced, perfectly priced, perfectly packaged dog food if the dog won’t eat it.”</p>
<blockquote><p>One candidate to serve as a end-user liaison might be a <a href="https://www.functionize.com/project/why-your-enterprise-needs-a-cqo-chief-quality-officer/">Chief Quality Officer</a>. Have you considered hiring someone for that role?</p></blockquote>
  </div></div>]]>
            </description>
            <link>https://www.functionize.com/blog/3-things-you-ought-to-know-about-user-acceptance-testing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24632093</guid>
            <pubDate>Tue, 29 Sep 2020 19:46:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Accidentally Reported a Fake Terror Incident]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24632018">thread link</a>) | @jermaustin1
<br/>
September 29, 2020 | https://jeremyaboyd.com/post/that-time-i-accidentally-reported-a-fake-terror-incident | <a href="https://web.archive.org/web/*/https://jeremyaboyd.com/post/that-time-i-accidentally-reported-a-fake-terror-incident">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <div>
            <div>
                <div>
                    <p>The year was 2007, And I just started as a junior/mid/lead developer at a small web development agency called Humankind.</p>
<blockquote>
<p>I've mentioned Humankind a few times, but for a deeper dive into our first product, see <a href="https://jeremyaboyd.com/post/my-first-product-launches">My First Product Launches</a></p>
</blockquote>
<p>My first task after being hired was to fix some bugs and SaaS-ify a product we were partners on called Citizen Notification Service (CNS). It was basically a platform for towns to send out email and SMS blasts to residents about events, or emergencies. The customer was typically a town's Office of Emergency Management.</p>
<p>Our partner, who was a Chief of Police in a Dallas, Texas, suburb, also ran another service called CrimeWeb. CrimeWeb was a similar concept to CNS, but here the customers were police, and journalists. Basically you could sign up for CrimeWeb as a police force and disseminate crime information to journalists. The product was genius. Collect money on both ends.</p>
<p>After a few weeks on the job, I had fixed most of the bugs, and SaaS-ified the CNS product as best as I could with its current code-base (we would rewrite this later), and my next task was to add video upload to CrimeWeb.</p>
<h3 id="out-of-my-depths">Out of my depths</h3>
<p>I'm almost never one to back down from a challenge, but CrimeWeb was written in classic ASP/VBscript, and I was an ASP.Net/C# developer, so I told the owner I wasn't completely sure if I could make this work, but he told me to try anyway, and if I couldn't get the ASP to work, maybe try to add an ASP.Net site to the classic ASP through IIS.</p>
<p>First step though, was to get the site working on my local environment. I grabbed the code off the server, and set it up on my local IIS. I grabbed a database backup from the server and restored it on my local SQL Server. I pointed my IIS to the code, and changed the config file, and like magic, it all worked. I was browsing around CrimeWeb.</p>
<h3 id="dressed-to-impress">Dressed to impress</h3>
<p>That night after dinner, I wanted to impress my new boss, so I changed into something a little more comfortable, and continued working on the site. </p>
<p>I added the video upload service so that after you added a crime, the UUID was passed to the ASP.Net site, and you uploaded a video, and once it was uploaded to YouTube, the YouTube link was saved back on the crime's database record.</p>
<h3 id="all-that-was-left-was-to-test-it">All that was left was to test it.</h3>
<p>So I logged into my super administrator account, and created a new crime that was going to be limited to my local town of only 30,000 people. The title of the crime was something along the lines of "Suspected Terrorist Attack at First National Bank of Alvin. Alligators are reported fine."</p>
<blockquote>
<p>The bank had Alligators... in the bank... Locally the bank was known as Alligator Bank, and the story us kids all heard is the alligators kept your money safe at night. 
My first bank account was there. My first 3 digits of wealth were accumulated there. 
And after 10 years of saving a quarter here and there, my first $100 withdraw was at their counter, in singles.</p>
</blockquote>
<p>The application errored when saving the crime, and it was too late for me to investigate further.</p>
<h3 id="so-i-went-to-bed">So, I went to bed.</h3>
<p>At around 2 in the morning, I woke up to my phone ringing. I answered, and it was my boss.</p>
<p>He had just spent the last hour on the phone with our partner, and he had just spent the last 2 hours answering phone calls from journalists and city officials from my town... who were apparently customers... who saw my crime posting. I felt sick. I said, there is no way for that to have happened, I edited the config, it is pointing to my local database, my browser says local host. </p>
<p>And then I learned about reverse proxying. It was a term I had never come across, in my many many years (2) of web development. </p>
<p>Apparently hidden away (on the main include file, at the very top), there was code that compared your HTTP_HOST variable to "www1" through "www10" and if it wasn't any of them, it would do a reverse proxy to a random "www1-10". </p>
<p>So while I had configured my site to use my local database server, and I was hosting it on my local IIS, I didn't understand the code well enough to know I wasn't on my local host.</p>
<h3 id="i-should-have-been-fired">I should have been fired</h3>
<p>I apologized profusely to my boss, and asked him if I could at least come and get my things from the office in the morning. I didn't have much, but I had a couple of desk ornaments I had accumulated over the month and a half I had been working there.</p>
<p>He asked what I meant. I said that I assumed I was fired, but he said he couldn't answer that yet, as he wasn't sure what the fall out would be with our customers or our partner. I asked him if there was anything I could do. To which he replied the obvious.</p>
<h3 id="i-could-call-our-partner-and-apologize-for-my-colossal-fuck-up">I could call our partner and apologize for my colossal fuck up</h3>
<p>I steeled myself for the worst phone call I had ever had to make... for no reason. Bob was probably the kindest and most gentle person I'd ever met. He basically chalked it up to a learning experience, told me everyone fucks up. He even gave me a great pro-tip. </p>

<p>Words to live by.</p>
<h3 id="i-wasnt-fired">I wasn't fired</h3>
<p>In fact, I stayed at Humankind for 8 very long and mostly fun years.</p>
<p>Through the ups and downs of the economy.</p>
<p>Through the ups and downs in clients.</p>
<p>And eventually firing all of our clients (or really not taking new ones), and working on our own products.</p>
<p>It was a great place to learn, and grow, and discover who I was and who I could become.</p>

                </div>
            </div>
        </div>
    </article></div>]]>
            </description>
            <link>https://jeremyaboyd.com/post/that-time-i-accidentally-reported-a-fake-terror-incident</link>
            <guid isPermaLink="false">hacker-news-small-sites-24632018</guid>
            <pubDate>Tue, 29 Sep 2020 19:40:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduce data-driven culture to your dev team]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24631924">thread link</a>) | @necco908
<br/>
September 29, 2020 | https://linearb.io/blog/how-to-introduce-data-driven-culture-to-your-dev-team/ | <a href="https://web.archive.org/web/*/https://linearb.io/blog/how-to-introduce-data-driven-culture-to-your-dev-team/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="670d84f7" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
			
<figure><img src="https://linearb.io/wp-content/uploads/2020/05/Pointing-at-Dash-2-1024x536.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/05/Pointing-at-Dash-2-1024x536.png 1024w, https://linearb.io/wp-content/uploads/2020/05/Pointing-at-Dash-2-300x157.png 300w, https://linearb.io/wp-content/uploads/2020/05/Pointing-at-Dash-2-768x402.png 768w, https://linearb.io/wp-content/uploads/2020/05/Pointing-at-Dash-2.png 1200w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<figure><table><tbody><tr><td data-align="left"><strong>TL;DR</strong></td></tr><tr><td data-align="left">-Tailoring the “why” for your metrics differently to different people helps w/ translation<p>-Starting small reduces risk and increases the likelihood of bottom-up adoption&nbsp; </p><p>-Adapting your metrics to company goals can increase business alignment&nbsp;</p><p>-Embedding your use of data into daily rituals can help with stickiness</p></td></tr></tbody></table></figure>



<p>The first time I ever thought about using data to help run my team was in 2015. CloudLock was growing fast and overnight (it felt like) I went from leading a single team of 6 devs to leading 5 teams with 50+ devs combined (as VP of Engineering). </p>



<p>I had no experience dealing with an organization of that size. The processes that had worked for us when we were smaller weren’t scaling for our current size and situation. I was pretty sure I needed to be doing more to help my team but I wasn’t sure what. </p>



<p><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://linearb.io/blog/3-dev-leaders-open-up-about-remote-software-development/" target="_blank">I’m not afraid to ask for help</a> so I hired an agile consultant to come in and talk to our entire team – engineering, product management and UX. She made a huge difference. I’m still using a lot of what I learned from her today. </p>



<p>One of the most common challenges I hear from software development leaders is…</p>



<figure><blockquote><p><strong><em>“I want my team to be more data-driven but I’m not sure where to start.”&nbsp;</em></strong></p></blockquote></figure>



<p>Every time I share how we do things at LinearB I hear <a rel="noreferrer noopener" aria-label="Kara Minotti Becker  (opens in a new tab)" href="https://www.linkedin.com/in/karaminottibecker/" target="_blank">Kara Minotti Becker’s </a>voice in my head. So I figured I better see what she’s doing now. It turns out she is still a software development consultant in high demand. It also turns out I still have a lot to learn from her.&nbsp;</p>



<p>The ideas and videos below come from our Zoom conversation on Friday, April 10th.</p>



<p>After we caught up (she has a 7-year old girl, I’m expecting my first later this month), Kara asked me…</p>



<p><em>What prompted you to reach out to me in 2015?&nbsp;</em></p>



<iframe width="560" height="400" src="https://www.youtube.com/embed/eNv-E5Cougw?rel=0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>



<p>The short answer is, I was in over my head 😀</p>



<p>I asked her what she remembered about our engagement.</p>



<p>She mentioned “You guys were really hungry for understanding the cultural piece of agile. How it helps people work together. Not just how we set the machinery up.”&nbsp;</p>



<p>I remember that too. I’ve always cared about culture. When it comes down to it, as a dev leader, I can’t do anything without great engineers who are driven to help the team. So if I don’t create an environment where talented people want to work, where they feel safe to be themselves, where they can make friends and explore their creativity and learn and have fun… I have no chance to deliver results for the business. I also believe in the power of data. And that’s why I’m passionate about this question.&nbsp;</p>







<h2><strong>What steps can engineering leaders take to get their entire team to buy-in to a data-driven culture?&nbsp;</strong></h2>



<p>Kara and I landed on four key areas.&nbsp;</p>



<h3>1. <strong>Start small and take an agile approach</strong></h3>







<blockquote><p><strong><em>“Engineering leaders need to be careful not to crush their teams under the weight of too many metrics.” </em></strong></p><cite>-Kara</cite></blockquote>







<p>When it comes to a new product or feature, we collect the most important requirements, ship an MVP, collect feedback and iterate over time to make it better. For some reason we forget to take that approach with our internal processes.&nbsp;</p>



<p>If we try to measure too many things from the beginning, we introduce risk. Scope creep. Delays. Loss of momentum. Just like a new feature, the first version of your metrics probably won’t be perfect regardless of how long you take to roll them out. You’re better off shipping something fast because you’ll start learning sooner. </p>



<p>Starting small also gives you a better chance of getting bottom-up support. When you pick 1-2 north star metrics that really represent the main goal for your team, it’s easy for everyone to get on board. Anything more than that increases the likelihood of confusion.&nbsp;</p>







<p><strong><em>PRO TIP:</em></strong> At CloudLock, when I had a new indicator I wanted to measure, I would try it out with a single team to start. After they spent some time using it, I would incorporate their feedback. Not only did this help me work out the kinks before rolling it out broadly, but it also created champions with the team who helped me convince everyone else it was a good idea.&nbsp;</p>







<p>See Kara explain the importance of starting small and iterating.</p>



<iframe width="560" height="400" src="https://www.youtube.com/embed/oUgM1NmPWgM?rel=0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>







<h3>2. <strong>Align your engineering metrics to business objectives&nbsp;</strong></h3>



<p>Obviously the next big question is…</p>



<p><strong><em>What are the most important things I should be measuring?&nbsp;</em></strong></p>



<p>If only it were that easy 🙂&nbsp;</p>



<p>Kara emphasized “There are no standard metrics that all agile teams should measure. It’s all about knowing what your company’s goals are and picking metrics that help you figure out how you’re contributing to that.”&nbsp;</p>



<p>She also believes that what you measure needs to adapt over time as your company’s goals change. “<a href="https://linearb.io/blog/align-engineering-metrics-to-your-business-kpis/" target="_blank" rel="noreferrer noopener" aria-label="If your metrics are not aligned to company goals they are pointless. (opens in a new tab)">If your metrics are not aligned to company goals they are pointless.</a>”&nbsp;</p>



<p>I went through three iterations in 5 years at CloudLock.&nbsp;</p>







<p><strong>Value mode:</strong> Early on the company’s mission was to deliver as much new product value as possible. So for engineering, it was all about speed to value for us. We had a lot of incredible ideas for our product and our job was to implement them as quickly as possible. I was an individual contributor developer for most of this phase and I got promoted to team lead towards the end.&nbsp;</p>



<p>I remember our leadership focusing a lot on velocity during this time – the number of story points each team delivered in each sprint.&nbsp;</p>



<p><strong><em>Disclaimer</em></strong></p>



<figure><div>I think velocity is the most dangerous, most misused metric in software development. It can be useful to inform sprint planning within an individual team. But it should never be shared outside of that team and it should definitely never be used to measure productivity.&nbsp;<p>Our leadership was trying to measure dimensions of our process like speed and efficiency. We probably would have benefited from measuring Cycle Time but back then the ideas and tools didn’t exist to get that data easily. So we settled for what we could measure – things like velocity. </p><p>More on Cycle Time later in this post.</p></div></figure>







<p><strong>Growth mode</strong>: At this point, we had a lot of customers but adding more was still the main goal for the company. We had a bunch of salespeople and they were making commitments to prospects. We had a lot of new marketing people and they had launches and PR announcements. We still needed to ship fast but it was even more important to hit our deadlines. Changing from the mindset of “ship new value as fast as possible” to “ship new value more predictably” was not easy. We were still under pressure to deliver more value but we couldn’t change priorities on the fly anymore.&nbsp;</p>



<p>This phase became all about predictability. By now I was the VP of Engineering. I measured iteration churn (how many items came in and out of the sprint after it started) and the percentage of story points delivered versus committed. These metrics were the best proxies I had to determine our consistency.&nbsp;And, to be clear, we only looked at this data for each team and never published these to the whole org or compared teams against each other using these metrics. </p>







<p><strong>Customer mode:</strong> Eventually we reached the point where 500+ large enterprise customers used our product every day and really relied on it. Keeping them happy became our priority. We brought in a VP of Customer Success. We had a top-line company goal of 90% customer retention year over year. This phase was all about quality.</p>



<p>You might think changing our mindset from predictability to quality would be a little easier than changing from speed to predictability. It was actually harder – for three reasons. First, our org was much bigger at this point so there more people we needed to get buy-in from. Second, going fast feels good to everyone. Devs like it. And the business likes it. Nobody likes being told we need to delay a release even if they know a potential bug can have big consequences. Finally, our most important internal customer changed. In predictability, your main internal customers are still sales and marketing. With quality, your main internal customer becomes customer success and technical support.&nbsp;There were new people we had to get to know. </p>



<p>We measured the number of issues, bugs and outages per release which we called “change failure rate”, as well as mean time to restore and mean time to resolve support tickets.&nbsp;</p>







<p><strong><em>PRO TIP: </em></strong>Looking back on it, we were using a lot of output metrics when we should have been using process metrics. When you focus on an output like how many story points you delivered or how many bugs you had, what do you do when you miss your mark? <a href="https://linearb.io/blog/dev-productivity-is-way-down-at-linearb/">Measuring the process</a> helps you figure out where and how you can improve. And many process metrics are leading indicators of your outputs so measuring them actually helps you predict when you have a problem coming and allows you to do something about it proactively.&nbsp;</p>



<figure><a href="https://linearb.io/wp-content/uploads/2020/04/Cycle-time-after-remote.png"><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/02/Cycle-Time.png.webp 2493w" sizes="(max-width: 2493px) 100vw, 2493px">
<img src="https://linearb.io/wp-content/uploads/2020/02/Cycle-Time.png" alt="data-driven culture thrives with the right metrics, like cycle time" srcset="https://linearb.io/wp-content/uploads/2020/02/Cycle-Time.png 2493w, https://linearb.io/wp-content/uploads/2020/02/Cycle-Time-300x145.png 300w, https://linearb.io/wp-content/uploads/2020/02/Cycle-Time-1024x493.png 1024w, https://linearb.io/wp-content/uploads/2020/02/Cycle-Time-768x370.png 768w, https://linearb.io/wp-content/uploads/2020/02/Cycle-Time-1536x740.png 1536w, https://linearb.io/wp-content/uploads/2020/02/Cycle-Time-2048x987.png 2048w" sizes="(max-width: 2493px) 100vw, 2493px">
</picture>
</a></figure>



<p>For example, at LinearB right now, instead of using velocity to measure speed, we look at <a href="https://linearb.io/cycle-time/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Cycle Time</a> which is the time it takes us to deliver new work from first commit to release. By measuring each phase of our cycle, when this metric goes up like it did for us recently after our transition to 100% work-from-home, we know exactly where to focus to get back on track. </p>



<figure><a href="https://linearb.io/wp-content/uploads/2020/04/Cycle-time-transition.png"><img src="https://linearb.io/wp-content/uploads/2020/04/Cycle-time-transition.png" alt="LinearB Cycle time after going remote. data-driven culture" srcset="https://linearb.io/wp-content/uploads/2020/04/Cycle-time-transition.png 1600w, https://linearb.io/wp-content/uploads/2020/04/Cycle-time-transition-300x139.png 300w, https://linearb.io/wp-content/uploads/2020/04/Cycle-time-transition-1024x476.png 1024w, https://linearb.io/wp-content/uploads/2020/04/Cycle-time-transition-768x357.png 768w, https://linearb.io/wp-content/uploads/2020/04/Cycle-time-transition-1536x713.png 1536w" sizes="(max-width: 1600px) 100vw, 1600px"></a></figure>







<h3>3. <strong>Translate the “why” behind your metrics to different audiences differently&nbsp;</strong></h3>







<blockquote><p><strong><em>“Members of software development teams, including engineers, are often scare of metrics… who they’re going to be exposed to.”&nbsp;</em></strong></p><cite>-Kara </cite></blockquote>







<p>I think Kara is right. And it’s not just engineers. </p>



<p>When shared in the wrong way, engineering metrics can be confusing to the rest of the business too.&nbsp;</p>



<iframe width="560" height="400" src="https://www.youtube.com/embed/ZAej8aqlx8Q?rel=0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>



<p>“It is true that you have to show executive staff numbers that have meaning at their level.”</p>



<p>But that doesn’t mean we shouldn’t make an effort to teach our business the key aspects of software development.&nbsp;</p>



<p><a href="https://linearb.io/blog/being-vp-of-software-development-is-harder-than-being-ceo/">As dev leaders we are somewhat caught in the middle</a>. So what can we do?&nbsp;</p>



<p>Context is everything. If you tailor the “why” behind each of your metrics differently for different audiences, you’ll have a better chance to …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://linearb.io/blog/how-to-introduce-data-driven-culture-to-your-dev-team/">https://linearb.io/blog/how-to-introduce-data-driven-culture-to-your-dev-team/</a></em></p>]]>
            </description>
            <link>https://linearb.io/blog/how-to-introduce-data-driven-culture-to-your-dev-team/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24631924</guid>
            <pubDate>Tue, 29 Sep 2020 19:30:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA["Know Your Ropes"–Intro to Spinnaker for Financial Services by Armory (YC W17)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24631837">thread link</a>) | @drodio
<br/>
September 29, 2020 | https://www.armory.io/blog/know-your-ropes-the-introduction-to-spinnaker-for-financial-services/ | <a href="https://web.archive.org/web/*/https://www.armory.io/blog/know-your-ropes-the-introduction-to-spinnaker-for-financial-services/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
                

        <main id="global-main">

                        
                        



<section>
    <div>
        <div id="post-6818">
          
            
            <div><figure><img width="680" height="432" src="https://www.armory.io/wp-content/uploads/2020/09/which-rope-01.gif" alt="" loading="lazy"></figure></div>            <div>
                
                <h2>Introducing “Know Your Ropes” Blog Series</h2>
<p>What does sailing and the Financial Services segment have in common? There are many sailing terms that apply to Financial Services – “Batten down the hatches”, “Hand over fist”, “Loose cannon”, “By and large”, “Know your Ropes”, “A clean bill of health”, and more.</p>
<p>This blog series aim is to focus on the Financial Services industry – Banks, Credit Card Companies, Credit Rating Companies, Financial Services, Insurance, and FinTech Startups.</p>
<p>We will look at real-life examples about how Spinnaker is being used within organizations like the largest U.S. bank, <a href="https://youtu.be/64rhl9sxhSQ">JP Morgan Chase</a> all the way to top-valued fintech, <a href="https://blog.spinnaker.io/future-of-sre-robert-keng-builds-a-deploybot-withspinnaker-70ff3e37c56a">Chime</a> to <a href="https://spinnaker.io/success-stories/">TransUnion</a>, an American consumer credit reporting agency.</p>
<h2>“Know Your Ropes” History</h2>
<p>This idiom originated from shipping. A sailing ship had many ropes that operated the ship’s sails. Sailors had to learn exactly which rope operated each sail and they also had to learn how to tie many different types of knots. When a sailor knew all of this, he “knew the ropes”.</p>
<p>The first known use of the term “Know Your Ropes” comes to us from Richard H. Dana Jr.’s memoir, “Two Years Before the Mast,” in 1840. Old sailing ships had a lot of ropes, and they each had a specific purpose. Those of you who were in Scouts also know the ropes, and realize that most knots have a sailing origin. Today, we use this term when referring to people who are really on top of their game and understand their industry.</p>
<h2>Financial Services Customer Quotes</h2>
<p>“We love the simple command-line interface for administration, integration with multiple platforms, and easy configurability using pipelines.” – <a href="https://www.transunion.com/">TransUnion</a></p>
<p>“We are seeing a significant increase in both frequency and volume of releases with Armory’s integration.” – <a href="https://www.jpmorganchase.com/">JP Morgan Chase</a></p>
<p>“cutting edge! this is where we want to be!” – <a href="https://www.chime.com/">Chime</a></p>
<h2>FinServe Solutions Brief</h2>
<p>The Armory Financial Services Whitepaper is now available! <a href="https://at.armory.io/WEB-FinServe_1Go.html">Download</a> High Yield: Policy-Driven Software Delivery for Financial Services.</p>
<p><a href="https://at.armory.io/WEB-FinServe_1Go.html"><img data-src="https://at.armory.io/rs/644-NAF-166/images/2.jpg" src="https://at.armory.io/rs/644-NAF-166/images/2.jpg"></a></p>
<h2>Sailing Tip</h2>
<p>Sailing is a sport fueled by the wind and the passion of the sailors who take the <a href="https://helm.sh/">helm</a>. Each blog, I’ll plan to include a sailing story, tip, or lesson learned.</p>
<p>The San Francisco Bay is a world-renowned sailing destination. With 25 knots of wind on a regular basis, strong currents, and heavy shipping traffic, the Bay provides the perfect environment for learning to sail.</p>
<p>I have been sailing recreationally in the last few years, but only until the beginning of 2020 did I officially take lessons to get my American Sailing Association license to become a skipper. I won’t be the first and I won’t be the last person, but you really need to “know your ropes” before you go sailing.</p>
<p><a href="https://www.modernsailing.com/">Modern Sailing School &amp; Club</a> provides sailing lessons on San Francisco Bay from the <a href="https://asa.com/">American Sailing Association</a>. In addition to sharing stories from the field, I’ll also share some sailing tips and stories along our journey together.</p>
<p>If you happen to live in the Bay Area or find yourself visiting this year or another time, join Armory on an afternoon sail around the SF Bay. <a href="https://go.armory.io/sail">Sign up</a> if you are interested.</p>
<h2>Keep up to date with Armory</h2>
<p>Get monthly updates and stay up to date with our <a href="https://www.armory.io/blog/">blog</a>.</p>
            </div>
        </div>
    </div>
</section>



<section>
  
</section>
<section>
  <div>
    <div>
      <div>
        <div>

      
<div>
    <p><img src="https://www.armory.io/wp-content/uploads/2020/02/LandingPage-opt-01-I-Have-Jenkins-768x196.png" alt=""></p>
  
    
  
    <p>Upcoming Webinar: I have Jenkins, why do I need Spinnaker?</p>
  
    <p>Jenkins has been offloading developers for years by centralizing continuous integration (CI). Over time, developers have been tasked with understanding and coding for different cloud and Kubernetes deployment targets instead of just writing great code. Find out how Spinnaker has again offloaded the developer from that cognitive thinking and accelerated innovation and time to market. […]</p>
  
  
</div>
      
<div>
    <p><img src="https://www.armory.io/wp-content/uploads/2020/09/working-from-anywhere-768x70.png" alt=""></p>
  
    
  
    <p>Working from anywhere: Living Armory's remote-first culture</p>
  
    <p>The future of work looks very different than it did just a year ago, pre-COVID. Armory has embraced and extended our strong remote culture to become a remote-first company, which means that although we have a physical HQ in San Mateo, CA, we don’t require anyone to be in a physical office, and that HQ […]</p>
  
  
</div>
      
<div>
    <p><img src="https://www.armory.io/wp-content/uploads/2020/09/spring-el.png" alt=""></p>
  
    
  
    <p>Upcoming Webinar: SpEL (aka Pipeline Expressions) Tips and Tricks</p>
  
    <p>Learn some best practices and tips and tricks for using Spinnaker’s Pipeline expressions (otherwise known as the Spring Expression Language or SpEL). Whether you are new to Spinnaker or an intermediate user wanting to learn how to empower your pipelines to do more, this session will cover the basics of getting started with Pipeline Expressions, […]</p>
  
  
</div>
  
        </div>
      </div>
    </div>
  </div>
</section>


        </main>

        

        </div></div>]]>
            </description>
            <link>https://www.armory.io/blog/know-your-ropes-the-introduction-to-spinnaker-for-financial-services/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24631837</guid>
            <pubDate>Tue, 29 Sep 2020 19:21:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Configuration for Reusability in Vue]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24631795">thread link</a>) | @michaelthiessen
<br/>
September 29, 2020 | https://michaelnthiessen.com/using-configuration-for-reusability/ | <a href="https://web.archive.org/web/*/https://michaelnthiessen.com/using-configuration-for-reusability/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
  <iframe src="https://player.vimeo.com/video/456391976" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe>
</p>
<p><em>This is an excerpt of my upcoming course, <a href="https://michaelnthiessen.com/reusable-components">Reusable Components</a>, which will be released on November 3!</em></p>
<p>In Module 3 of Reusable Components we cover the second <a href="https://michaelnthiessen.com/6-levels-of-reusability">level of reusability</a>, Configuration.</p>
<p>Configuration is all about using props to allow for variations in how a component works (you're likely doing some form of this already). For example, instead of writing an entirely new component for each type of button, you can add in a <code>type</code> prop that allows you to switch between the different styles.</p>
<p>In this video we also go over <strong>configuration props</strong> and <strong>state props</strong>, and how they're different.</p>
</div><div data-v-17f0bb0f=""><h2 data-v-17f0bb0f="">Most Popular</h2><!----><div data-v-17f0bb0f=""><a href="https://michaelnthiessen.com/6-levels-of-reusability/" data-v-17f0bb0f=""><h3 data-v-17f0bb0f="">
        The 6 Levels of Reusability
      </h3></a><p data-v-17f0bb0f="">June 2020</p><p data-v-17f0bb0f="">We all want to write less code, but get more done. To make this happen, we build our components so they can be reused more than just once.</p></div><div data-v-17f0bb0f=""><a href="https://michaelnthiessen.com/underdog-framework/" data-v-17f0bb0f=""><h3 data-v-17f0bb0f="">
        The Underdog Framework
      </h3></a><p data-v-17f0bb0f="">January 2020</p><p data-v-17f0bb0f="">If React is so much more popular than Vue, wouldn't it be better to just stick with that? There are 3 specific things here I'd like to cover: 1. Growth of the framework itself (innovation) 2. Career opportunities 3. Ease of learning/getting better</p></div><div data-v-17f0bb0f=""><a href="https://michaelnthiessen.com/most-important-feature-vue/" data-v-17f0bb0f=""><h3 data-v-17f0bb0f="">
        The Most Important Feature in Vue
      </h3></a><p data-v-17f0bb0f="">November 2019</p><p data-v-17f0bb0f="">I've said it before and I'll say it again: Computed properties are the most important feature in Vue. Sure, scoped slots let you create some nice abstractions and watchers are useful too. But I don't think anything comes close to how valuable computed props are.</p></div></div></div>]]>
            </description>
            <link>https://michaelnthiessen.com/using-configuration-for-reusability/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24631795</guid>
            <pubDate>Tue, 29 Sep 2020 19:18:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A request to a YouTube video downloads the title 14 times and displays it twice]]>
            </title>
            <description>
<![CDATA[
Score 75 | Comments 57 (<a href="https://news.ycombinator.com/item?id=24631698">thread link</a>) | @anderspitman
<br/>
September 29, 2020 | https://apitman.com/25/#a-request-to-a-youtube-video-downloads-the-title-14-times-and-displays-it-twice | <a href="https://web.archive.org/web/*/https://apitman.com/25/#a-request-to-a-youtube-video-downloads-the-title-14-times-and-displays-it-twice">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
            <div>
              <p>I have a project idea that could involve doing some scraping of YouTube videos, so I started poking
around the HTML output of curling YT links. These things are a site (sp) to behold. If you curl the following
well-known URL and store it in a file:</p>
<p><code>https://www.youtube.com/watch?v=dQw4w9WgXcQ</code></p>
<p>Just searching for the title yields 14 results, spread throughout random HTML and JS. But it's only actually
displayed to the user once on the page, and probably again in the browser tab. It's not just the title
either, there's a ton of duplicated data and bloat throughout the file. I'm guessing it compresses well. I
checked a few other files and they all had between 10 and 18 copies of the title.</p>
<p>I'm not sure what conclusions to draw from this. A lot of them are obviously intended to be
machine-readable for things like <a href="https://ogp.me/">ogp</a>, but do you really need 14 identical copies?</p>
<p>EDIT:</p>
<p>Since this errant observation somehow made it to the <a href="https://news.ycombinator.com/item?id=24631698">Hacker News front page</a>, and eventually got flagged, I have a few more thoughts:</p>
<ul>
<li><p>Sorry the title ended up more clickbatey than intended. It's not making 14 extra HTTP requests just for the title. It originally started with "An HTTP request" but it was a few characters too long for HN, and I didn't spend much time rethinking it.</p>
</li>
<li><p>I agree the extra text isn't a problem (like I said, that'll compress well). I'm more concerned about the underlying complexity it signals. There is more obvious evidence of this complexity (it makes 70 network requests when you load the page even if you pause the video immediately), this is just a novel one for me.</p>
</li>
<li><p>I appreciate the copies which are intended to interoperate with other systems like Twitter and OGP.</p>
</li>
<li><p>I actually appreciate the fact that a JSON blob of all the video metadata is embedded in the HTML. It'll make my scraping task much simpler.</p>
</li>
</ul>

            </div>
          </div></div>]]>
            </description>
            <link>https://apitman.com/25/#a-request-to-a-youtube-video-downloads-the-title-14-times-and-displays-it-twice</link>
            <guid isPermaLink="false">hacker-news-small-sites-24631698</guid>
            <pubDate>Tue, 29 Sep 2020 19:08:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How real-time stream processing works with ksqlDB, animated]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24631670">thread link</a>) | @mjdrogalis
<br/>
September 29, 2020 | https://www.confluent.io/blog/how-real-time-stream-processing-works-with-ksqldb/ | <a href="https://web.archive.org/web/*/https://www.confluent.io/blog/how-real-time-stream-processing-works-with-ksqldb/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="___gatsby"><div tabindex="-1" id="gatsby-focus-wrapper"><div><section><div><p><time datetime="2020-09-29T17:50:00.000Z">September 29, 2020</time></p><div><div data-swiftype-name="body" data-swiftype-type="text"><p><a href="http://ksqldb.io/">ksqlDB</a>, the event streaming database, is becoming one of the most popular ways to work with Apache Kafka<sup>®</sup>. Every day, we answer many questions about the project, but here’s a question with an answer that we are always trying to improve: How does ksqlDB work?</p>
<p>The mechanics behind stream processing can be challenging to grasp. The concepts are abstract, and many of them involve motion—two things that are hard for the mind’s eye to visualize. Let’s pop open the hood of ksqlDB to explore its essential concepts, how each works, and how it all relates to Kafka.</p>
<p>If you like, you can follow along by executing the example code yourself. <a href="https://ksqldb.io/quickstart.html">ksqlDB’s quickstart</a> makes it easy to get up and running.</p>
<div>
<h2 id="declaring-a-stream"><a id="declaring-a-stream"></a>Declaring a stream</h2>
<p>Stream processing is a programming paradigm for computing over events as they arrive. But where do those events come from? In Kafka, you store a collection of events in a <em>topic</em>. Each event can contain any raw bytes that you want. In ksqlDB, you store events in a <em>stream</em>. A stream is a topic with a strongly defined schema. You declare it like this:</p>
<pre><code>
CREATE STREAM readings (
    sensor VARCHAR KEY,
    location VARCHAR,
    reading INT
) WITH (
    kafka_topic = 'readings',
    partitions = 3,
    value_format = 'json'
);
</code></pre>
<p>When you fire off this statement from ksqlDB’s client to its server, what actually happens? If the topic that backs this stream doesn’t exist, the server issues a call to the Kafka brokers to make a new topic with the specified number of partitions. The stream metadata, like the column layout, serialization scheme, and other information, is placed into ksqlDB’s command topic, which is its internal cluster communication channel. Each ksqlDB server materializes the command topic information to a local metadata store, giving it a global catalog of objects.</p>
<p>A newly declared stream has no data in it:</p>

</div>
<div>
<h2 id="inserting-rows"><a id="inserting-rows"></a>Inserting rows</h2>
<p>Empty collections aren’t terribly interesting. You need to write events to them to make something happen. In Kafka, you model an event as a <em>record</em> and put it into a topic. In ksqlDB, you model an event as a <em>row</em> and put it into a stream. A row is just a record with additional metadata. You <em>insert</em> rows like this:</p>
<pre><code>
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-1', 'wheel', 45);
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-2', 'motor', 41);
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-1', 'wheel', 42);
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-3', 'muffler', 42);
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-3', 'muffler', 40);

INSERT INTO readings (sensor, location, reading) VALUES ('sensor-4', 'motor', 43);
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-6', 'muffler', 43);
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-5', 'wheel', 41);
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-5', 'wheel', 42);
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-4', 'motor', 41);

INSERT INTO readings (sensor, location, reading) VALUES ('sensor-7', 'muffler', 43);
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-8', 'wheel', 40);
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-9', 'motor', 40);
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-9', 'motor', 44);
INSERT INTO readings (sensor, location, reading) VALUES ('sensor-7', 'muffler', 41);
</code></pre>
<p>Each time you invoke an <code>INSERT</code> statement, a request with the payload is sent to a ksqlDB server. The server checks that the shape of the data is coherent with respect to the stream’s schema—malformed rows are rejected. If the row’s data types are sane, the server creates a record and automatically serializes its content using the format of choice as defined in the stream’s declaration. It uses the Kafka producer client to insert that record into the backing Kafka topic. All of the stream’s data is persisted on directly on the broker. None of it lives in ksqlDB’s servers.</p>
<p>After the inserts complete, the stream now looks like what you see below. Hover over each row to see its contents—the data displayed describes the underlying Kafka record. Notice how the rows are ordered by offset from right to left. In the animations you’ll see below, time is depicted as flowing rightward.</p>

<p>Why does some of the row data end up in the key of the record and some in the value? ksqlDB superimposes a flat column abstraction on top of Kafka’s key/value model. Here’s how it works in this case.</p>
<p>In the declaration of the stream, <code>sensor</code> is qualified with the <code>KEY</code> keyword. That piece of syntax tells ksqlDB to look for the data for this column in the key portion of the record. The data for other columns is read from the record’s value. When ksqlDB produces the record to the underlying topic, its key content is hashed to select a partition for it to reside in. This causes all rows with the same key to be written to the same partition, which is a useful <a href="https://docs.confluent.io/current/kafka/introduction.html#topics-and-logs">ordering guarantee</a>.</p>
</div>
<div>
<h2 id="transforming-a-stream"><a id="transforming-a-stream"></a>Transforming a stream</h2>
<p>No one ever sends data to Kafka just to let it sit there. You always want to do something with it. And most often, the data isn’t yet in the exact form that you need in order to work with it. You need to change it in some way.</p>
<p>The most elementary way you could do this is by writing a program that uses the Kafka producer and consumer clients. The program would read from the source topic whose data you want to change, apply a function to each record, and write the new record to the output topic. It would loop and run forever. This works, but it is rather low-level. You need to manage schemas, serializers, partitioning strategies, and other pieces of configuration.</p>
<p>In ksqlDB, you issue a <em>persistent query</em> to <em>transform</em> one stream into another using its SQL programming model. You derive a new stream from an existing one by selecting and manipulating columns of interest:</p>
<pre><code>
-- process from the beginning of each stream
set 'auto.offset.reset' = 'earliest';
                
CREATE STREAM clean AS
    SELECT sensor,
           reading,
           UCASE(location) AS location
    FROM readings
    EMIT CHANGES;
</code></pre>
<p>Persistent queries are little stream processing programs that run indefinitely. In this case, it continually reads rows from <code>readings</code>, applies the transformation logic, and writes rows to <code>clean</code>. You are relieved of all data janitorial work: There are no schemas to manage, no serializers to configure, no partitioning strategies to choose. But what is actually happening when you launch this query?</p>
<p>Each time you run a persistent query, ksqlDB’s server compiles the query’s textual representation to a physical execution plan as a Kafka Streams topology. The topology runs as a daemon, reacting to new topic records as soon as they become available. This means that all of the processing work happens on ksqlDB server; no processing work happens on the Kafka brokers. If you run ksqlDB as a cluster, the topology scales horizontally across the nodes by internally using Kafka Streams application IDs.</p>
<p>When everything is connected together and the data is flowing, it looks like this. Take it in for a few moments—we’ll walk through it in detail below.</p>

<p>What is going on here? What do the moving arrows mean? Why are those numbers changing? And what is <code>pq1</code>?</p>
<p>When a persistent query is created, it is assigned a generated name (in this case, we call it <code>pq1</code>). Rows are read from the stream partitions that the query selects from. As each row passes through the persistent query, the transformation logic is applied to create a new row, which is what the change of color signifies. Reading a record from Kafka does not delete it—you effectively receive a copy of it. That is why the leftmost rows remain in place, and clones of them appear to the right of each partition before they are sent to the persistent query box.</p>
<p>Persistent queries completely manage their own processing progression, even in the presence of faults. ksqlDB durably maintains the highest offset of each input partition. The incrementing numbers underneath the query box describe those values at each point in time. Moreover, the arrows that move from right to left on the input streams show the corresponding offsets currently being processed, giving you a spatial sense of progress. (If you’re an experienced Kafka user, note that these aren’t the <em>committed</em> offsets.)</p>
<p>Pause the animation and hover over the output rows. Notice how the column that the transformation targets has changed, while all the other columns remain intact. ksqlDB has taken care of all the bookkeeping for you.</p>
<p>As you watch the data flowing through the topology, you might be wondering how ksqlDB chooses which input partition it will read from next. Is it random? Is it round robin? The answer to that question is the foundation of how ksqlDB deals with out-of-order data, and it’s something that we’ll describe in a future blog post all on its own. (Spoiler: <a href="https://www.confluent.io/resources/kafka-summit-2020/the-flux-capacitor-of-kafka-streams-and-ksqldb">It picks the smallest timestamp available</a>.)</p>
</div>
<div>
<h2 id="filtering-rows-out-of-stream"><a id="filtering-rows-out-of-stream"></a>Filtering rows out of a stream</h2>
<p>Let’s look at another simple operation: filtering. Filters are used to discard rows that you do not need or want. Just like transforms, filters are specified using simple SQL syntax.</p>
<pre><code>
CREATE STREAM high_readings AS
    SELECT sensor, reading, location
    FROM clean
    WHERE reading &gt; 41
    EMIT CHANGES;
</code></pre>
<p>When you write ksqlDB programs, you chain streams (and tables) together. You create a figurative pathway for your data to traverse, with each step in the way performing a step of processing. ksqlDB handles the mechanics of how your data is propagated through the chain.</p>

<h2 id="combining-many-operations"><a id="combining-many-operations"></a>Combining many operations into one</h2>
<p>A crucial rule of thumb in data processing is that you should get rid of data that you don’t need as early as possible. The longer you keep irrelevant data around, the higher the cost to repeatedly store, process, and transfer it. If you use the Kafka client to process data, it is up to you to manage where each processing step takes place.</p>
<p>In…</p></div></div></div></div></section></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.confluent.io/blog/how-real-time-stream-processing-works-with-ksqldb/">https://www.confluent.io/blog/how-real-time-stream-processing-works-with-ksqldb/</a></em></p>]]>
            </description>
            <link>https://www.confluent.io/blog/how-real-time-stream-processing-works-with-ksqldb/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24631670</guid>
            <pubDate>Tue, 29 Sep 2020 19:06:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding Kubernetes Services and Ingress Networking]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24631671">thread link</a>) | @anishdhar
<br/>
September 29, 2020 | https://www.getcortexapp.com/post/understanding-kubernetes-services-ingress-networking | <a href="https://web.archive.org/web/*/https://www.getcortexapp.com/post/understanding-kubernetes-services-ingress-networking">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In the previous<a href="https://www.getcortexapp.com/post/understanding-kubernetes" target="_blank"> article</a>, we looked into the basics of Kubernetes and setting up and running Kubernetes in a local machine. There we had briefly discussed Kubernetes objects called Services. Services are Kubernetes resources that enable network access to Pods. In this article, we will look deeply into the concepts of Kubernetes Services and its different types. We will also look into Kubernetes Ingress, which is not a service but is another way of routing traffic to your services and your cluster.</p><h3><strong>Kubernetes Services</strong></h3><p>As we know, a Kubernetes cluster consists of a set of node machines, running containerized applications inside objects named <em>Pods</em>. The pods are grouped based on the type of service they provide into various groups. Pods must be able to accept connections in some way, from your cluster or from outside your cluster.</p><p>In the case of external access, we know that pods inside the cluster are present inside an internal pod network and cannot be accessed by the node’s IP address. A user should be able to communicate with the application using the IP address of the node.&nbsp;</p><p>In the case of internal communication, we know that each pod in the system is assigned with its own unique IP known as Pod IP. But these IPs are not static, as we know the pods can go down any time and new pods are created all the time in a cluster. So we cannot rely on these IPs for Internal communication.</p><p>So we need something that is consistent so that things outside or inside the cluster might be able to access it persistently. A <strong>Service</strong> is a Kubernetes object that acts as an endpoint for enabling the communication between various components within and outside the application. In other words, a service is a stable address for pods. The three important Service types in Kubernetes are:</p><ol role="list"><li>ClusterIP</li><li>NodePort</li><li>LoadBalancer</li></ol><h4><strong>ClusterIP</strong></h4><p>A full-stack web application typically is made up of different kinds of pods hosting different parts of the application. It may have a set of pods running a backend server, a set of pods running the front-end web server and a set of pods running a database, and so on. All these sets of pods need to communicate with each other. As we discussed, we can’t depend on the IP addresses of pods, since they are not static.</p><p>ClusterIP is a Kubernetes service type that is used to group pods together and provide a single interface to access them. For example, an incoming request by another service will be forwarded to one of the pods in the ClusterIP randomly.</p><p>Now let’s look at an example. Before creating the ClusterIP service we can start by creating a simple pod based on a definition file.</p><p><em>front-end-pod-definition.yml</em></p><blockquote>apiVersion: v1<br>kind: Pod<br>metadata:<br> name: myapp-pod<br> labels:<br> &nbsp; app: myapp<br> &nbsp; type: front-end<br>spec:<br> containers:<br> &nbsp; - name: nginx-container<br> &nbsp; &nbsp; image: nginx</blockquote><p>As we can see our pod is simply a container that has the Nginx web server behind it. We have added labels <em>app</em> and <em>type</em>. Pod will be grouped into the type front-end. Next, we need to run the create command to create the pod.</p><blockquote>kubectl create -f frontend-pod-definition.yml</blockquote><p>Let's look at the ClusterIP service definition:</p><p><em>fe-clusterip-service-definition.yml</em></p><blockquote>apiVersion: v1<br>kind: Service<br>metadata:<br> name: front-end-service<br>spec:<br> type: ClusterIP<br> selector:<br> &nbsp; app: myapp<br> &nbsp; type: front-end<br> ports:<br> &nbsp; - targetPort: 80<br> &nbsp; &nbsp; port: 80</blockquote><p>The Service definition has type as ClusterIP (it's not mandatory, as by default services are of kind ClusterIP). We can see that we have used the selector to link the service to a set of pods. Under ports, we have a target port and port.&nbsp;</p><p>The <strong>target port</strong> is the port where the front-end service is exposed which in this case is 80 and the <strong>port</strong> is where the ClusterIP service is exposed which is also 80.</p><p>Now we can create the service by the create command.</p><blockquote>kubectl create -f clusterip-service-definition.yml</blockquote><p>Let’s look at the service created</p><figure><p><img src="https://assets.website-files.com/5ec5ad145468d2d2ff78b364/5f6bc5225587b6be7c95e156_i9voFNRyRthFr7g2dH40vaqeQNw7srlhOe4BlZKsWJBlBZrw1lQdb6hmio0_vxDbohpPx_qdCNZHTV3KcsXhPb1fNYLCrN-QHIlusoMKlOhSmvW3ov44pDqbL377PWbZQT6hb3g.png" alt=""></p></figure><p>We can see that in addition to the default Kubernetes ClusterIP a new ClusterIP of the name <em>front-end-service</em> is created with an IP address. The name of the service can be used by other pods to access it.</p><h4><strong>NodePort</strong></h4><p>NodePort is a Kubernetes service type that listens on a port on the node and forward requests on that port to a pod on the node. Let's look at an example.&nbsp;</p><ul role="list"><li>We have a node with IP address <em>10.1.3.4</em>.&nbsp;</li><li>The internal pod network of the node is in the range 10.244.0.0</li><li>The pod itself has an IP of 10.244.0.2.&nbsp;</li><li>The actual web server is running on port 80 in the pod.&nbsp;</li></ul><p>Essentially, we want to forward requests coming to 10.1.3.4 to the pod.</p><p>When we create a NodePort service, the service is assigned a high port on all nodes. When a request comes in for <em>node:port</em>, it will act as a built-in load balancer and send the request to one of the pods at random.</p><p>Let’s create a NodePort service to forward the incoming request to the node to port 80 of the pod. Let’s start by creating a service definition:</p><p>nodeport-service-definition.yml</p><blockquote>apiVersion: v1<br>kind: Service<br>metadata:<br> name: myapp-service<br>spec:<br> type: NodePort<br> selector:<br> &nbsp; app: myapp<br> &nbsp; type: front-end<br> ports:<br> &nbsp; - targetPort: 80<br> &nbsp; &nbsp; port: 80<br> &nbsp; &nbsp; nodePort: 32593</blockquote><p>We can see three values in the ports section.&nbsp;</p><p><strong>targetPort</strong>: The port on the pod where the actual web server is running, that is 80 in this case. Service forwards the requests to the target port. If no ports are provided in the spec, it will default to 80</p><p><strong>port</strong>: Like all Kubernetes objects, the Service is a virtual server inside the node. Inside the cluster, it will have its own IP address. The ‘port’ is the port exposed to the NodePort service itself. This value is mandatory.</p><p><strong>nodePort: </strong>The port on the node which is used to access the web server externally. These ports can only be in a valid range from 30000 to 32767. This is not a mandatory field, if it is not provided a free port from the range is selected.</p><p>Now we can create the service by the command,</p><blockquote>kubectl create -f nodeport-service-definition.yml</blockquote><p>Let's check if the service is created.</p><figure><p><img src="https://assets.website-files.com/5ec5ad145468d2d2ff78b364/5f6bc522c1dac43f794be000_AIDxqYyNHBc2JxSPheW8ML0VJVtHeUW6PN6kSD0u-LShhTA4_2oZTcPs9N7nYvjIcJg_--8EYDoPyFO-xqmjPavONwZo9Uee4JKd8Jan3nNJg1M8xPSOCEJsoQabVJuFqT4VLXM.png" alt=""></p></figure><p>Let's try to access the service using the IP of the node</p><p>Since I am using Minikube, the IP of the node is different from the local IP of the system. To get that value, type the command below&nbsp; in the terminal</p><blockquote>minikube ip</blockquote><p>Let's use curl to access the app using the NodePort in this IP</p><blockquote>curl 192.168.99.101:32593</blockquote><figure><p><img src="https://assets.website-files.com/5ec5ad145468d2d2ff78b364/5f6bc5224d5a3d39180e7560_Xphy_GvMOUKXeCtxr8yqhjNzsjqB9Ud_3LsLCtTmoooC6Q8oZmRHWvm2NxoWczFNJG2CMlNy9_Rl-ApmBicvvTffdy-V_ip1pluzFWqDl3_5SSWHaMMv_hbiewo8ZC9X6C7dHC8.png" alt=""></p></figure><p>Great! We got a response from the pod.</p><h4><strong>LoadBalancer</strong></h4><p>Using nodePort we were able to expose our web app to the internet. However, there’s a problem - multiple instances of the web app can be deployed across multiple nodes in our cluster. To access this web app, we’d need to provide both a node IP and the node port to the user. In real life, it’s difficult to determine which node IP and node port should be provided to the user, manually. Instead, we need to have a load balancer to expose our web app to the internet.</p><p>A LoadBalancer is a service that provides (as you may have guessed) a load balancer for our application, in supported cloud providers. The service becomes accessible through a provided load balancer service. Most cloud providers like AWS, GCP, Azure offer this functionality. Once you create a service of type LoadBalancer, cloud providers will create a load balancer in the backend and generate a public IP address. This public IP can be used to access our web app from the public internet.</p><p>This is the standard way to directly expose a service to the Internet. It is similar to the NodePort where all the traffic on the port we specify will be forwarded to the service. Almost all kinds of traffic like HTTP, TCP, UDP, Websockets, gRPC etc can be sent to this service.</p><p>Let's look at an example definition file:</p><blockquote>apiVersion: v1<br>kind: Service<br>metadata:<br> name: my-service<br>spec:<br> selector:<br> &nbsp; app: myapp<br> type: LoadBalancer<br> ports:<br> &nbsp; - nodePort: 31000<br> &nbsp; &nbsp; port: 80<br> &nbsp; &nbsp; targetPort: 9376</blockquote><p>We can see that this is almost the same as a NodePort definition file.</p><p>Let's create the service with create command</p><blockquote>kubectl create -f load-balancer-service-definition.yml</blockquote><p>Now let's look at the service that got created using the command.&nbsp;</p><blockquote>kubectl get services</blockquote><figure><p><img src="https://assets.website-files.com/5ec5ad145468d2d2ff78b364/5f6bc522e9914240281c4d1a_I27mI6NbO5gl6KqJFVQ0zJTr8t7r5aV43JKZEGNtfUkG_XXarnt1_RavpLnhhL66aDErRKDQemO728-Uog59_xwdOhUGwbuUU9c6gncjaDP43Aq71OVTM13Oq6GzRCao3bnrlB0.png" alt=""></p></figure><p>You can see that since I am using Minikube the value of the external IP is shown as &lt;pending&gt;. However, in an actual cloud setup, the IP will be generated and can be used to access the application. This is the IP that can be used by our users to access our web app from the internet.</p><h3><strong>Ingress Networking</strong></h3><p>We have seen in the Kubernetes services sections on how to expose our application to the outside world using the NodePort and LoadBalancer. If we only have to have a single service port we can use NodePort. In the case of multiple instances of the same service, we have to use the LoadBalancer.&nbsp;</p><p>But what if we have to add one more service to our node and access it from another URL. In this case, we will have to add another load balancer to our cluster. This means that each service exposed with a LoadBalancer will get its own IP address and we will have to pay for each of these load balancers which can be quite expensive.</p><p>An Ingress is used when we have multiple services on our cluster and we want the user request routed to the service based on their path. Consider an example, I have two services foo and bar in our cluster. When we type<a href="http://www.example.com/foo"> www.example.com/foo</a> we should be routed to the foo service and <a href="http://www.example.com/bar">www.example.com/bar</a> should be routed to bar service. These routings will be performed by an Ingress. Unlike NodePort or LoadBalancer, Ingress is not actually a type of service. Instead, it is an entry point that sits in front of multiple services in the cluster. It can be defined as a collection of routing rules that govern how external users access services running inside a Kubernetes cluster.</p><p>Ingress is most useful if you want to expose multiple services under the same IP address, and these services all use the same L7 protocol (typically HTTP). You only pay for one load balancer if you are using the native GCP integration, and because Ingress is “smart” you can get a lot of features out of the box (like SSL, Auth, Routing, etc)</p><p>Ingress can be considered as the best way to expose multiple services under the same IP. Also, we should only pay for a …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.getcortexapp.com/post/understanding-kubernetes-services-ingress-networking">https://www.getcortexapp.com/post/understanding-kubernetes-services-ingress-networking</a></em></p>]]>
            </description>
            <link>https://www.getcortexapp.com/post/understanding-kubernetes-services-ingress-networking</link>
            <guid isPermaLink="false">hacker-news-small-sites-24631671</guid>
            <pubDate>Tue, 29 Sep 2020 19:06:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We built an app to fix our own meeting fatigue]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24631659">thread link</a>) | @tylertreat
<br/>
September 29, 2020 | https://witful.com/our-story/ | <a href="https://web.archive.org/web/*/https://witful.com/our-story/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section data-id="4a8b33e4" data-element_type="section">
						<div>
							<div>
					<div data-id="4f865481" data-element_type="column">
			<div>
							<div>
						<div data-id="5c040c31" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div>
<h2><strong>How we built an app to fix our own meeting fatigue</strong><img loading="lazy" src="https://witful.com/wp-content/uploads/2020/09/Witful-Evolution-1024x374.png" alt="" width="580" height="212" srcset="https://witful.com/wp-content/uploads/2020/09/Witful-Evolution-1024x374.png 1024w, https://witful.com/wp-content/uploads/2020/09/Witful-Evolution-300x109.png 300w, https://witful.com/wp-content/uploads/2020/09/Witful-Evolution-768x280.png 768w, https://witful.com/wp-content/uploads/2020/09/Witful-Evolution-1536x561.png 1536w, https://witful.com/wp-content/uploads/2020/09/Witful-Evolution-1200x438.png 1200w, https://witful.com/wp-content/uploads/2020/09/Witful-Evolution.png 1918w" sizes="(max-width: 580px) 100vw, 580px"></h2>


<p>We’re not building a generic notes app. We’re also not building an app for everyone. We are building a product that reduces the cognitive load for people with lots of meetings. Something that enables people with lots of context switching to ensure they don’t miss follow-ups. Something that makes relevant information immediately accessible. We care about being on point in our meetings. This means clearing away all the clutter and noise to help us be prepared and focused.</p>


<p>The idea for Witful started when I was managing a large team of people. I believe one-on-one meetings are a crucial part of being an effective manager, and I take lots of notes in my one-on-ones. I like to track what is happening with my coworkers and reports because it allows me to better support them. As I was managing larger and larger teams across diverse products and projects, I noticed how difficult it was to keep this all organized and feel in touch with my teams.</p>


<p>When we started <a href="https://realkinetic.com/">Real Kinetic</a>, I focused on&nbsp;the administrative tasks of starting and running a consulting business in addition to being responsible for our business development and sales. I quickly realized that the same need existed in these roles. I was in several meetings with various attorneys and accountants each week. I was on calls with multiple clients and sales prospects daily. I was on calls with our team internally. <em>I was constantly switching contexts, jumping from one meeting to the next.</em></p>


<p>Then, in an effort to develop leads and grow our client base, I started developing relationships with investors and other networkers. This added a new level of complexity to my note organization because I wanted to associate notes from these calls with that person, but also with other clients. I tried every note-taking solution on the market and none met my needs.</p>


<p>After a lot of fruitless searching for the right solution, I began sketching mockups on my whiteboard. These sketches quickly evolved into code, resulting in a simple prototype that let me play with the idea. It was immediately obvious that it was something worth pursuing.</p>


<p>In early 2019, we decided to have Alex dedicate time to build out the prototype. He translated the rough prototype into a usable product by the end of August 2019. Mike, Tyler, Nick, and myself started using Witful in our day-to-day consulting work. The value of our idea was clear, and we started getting excited. I showed Witful to my wife who was responsible for project management and managing client relationships at a software development consulting group. In her role managing a large number of client and internal relationships, the value of the product was even more apparent. After a couple weeks of using it, she came home and told me, “I no longer stress missing follow-ups because they’re just there.”</p>


<p>We decided to invest in developing the product and hired Coury to accelerate development. Through the fall, Coury and I worked to build and deploy features that helped us, as actual users, do our <em>real jobs</em> more efficiently.&nbsp;</p>


<p>We have continued to both add and remove features as we iterate on the product. We are constantly finding that some features seem like clear and certain must-haves, but after they have been implemented everyone uses it for a day and then never again. We realized smart organization, intelligent layout, intuitive user experience, and search are far more important than one-off home run features.</p>


<p>What has been most exciting for me is seeing how seemingly minor additions, revisions, and touches have been the most impactful to the experience.</p>


<p>We’re real users of our product and we’re excited to share it with you. We are hopeful that Witful can improve your work and restore sanity to your day as it has for us. Our vision for Witful is to build the product that lets you be brilliant at what you do.</p>
<p><img loading="lazy" src="https://witful.com/wp-content/uploads/2020/09/2020-09-24-171018_570x266_scrot-300x140.png" alt="" width="176" height="82" srcset="https://witful.com/wp-content/uploads/2020/09/2020-09-24-171018_570x266_scrot-300x140.png 300w, https://witful.com/wp-content/uploads/2020/09/2020-09-24-171018_570x266_scrot.png 570w" sizes="(max-width: 176px) 100vw, 176px"></p>


<p>– Robert&nbsp;&nbsp;</p>
</div>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section></div>]]>
            </description>
            <link>https://witful.com/our-story/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24631659</guid>
            <pubDate>Tue, 29 Sep 2020 19:04:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Swallowing the Elephant (2018)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24631637">thread link</a>) | @noch
<br/>
September 29, 2020 | https://pharr.org/matt/blog/2018/07/08/moana-island-pbrt-1.html | <a href="https://web.archive.org/web/*/https://pharr.org/matt/blog/2018/07/08/moana-island-pbrt-1.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Walt Disney Animation Studios (WDAS) has just given the rendering research
community an incredible gift with their release of the <a href="https://www.disneyanimation.com/technology/datasets">full scene
description for the island from
<em>Moana</em></a>.  Between
geometry and textures, it’s just over 70 GB of data on disk for a single
frame, making it a stellar example of the degree of complexity that
production rendering deals with today; never before have rendering
researchers and developers outside of film studios been able to
work with realistic production scenes like this.</p>

<p>Here’s a rendering of it with today’s pbrt:</p>

<p><img src="https://pharr.org/matt/blog/images/pbrt-moana-island.jpg"> Moana
<i>island rendered with <a href="https://github.com/mmp/pbrt-v3">pbrt-v3</a> at 2048x858 resolution
with 256 samples per pixel.  Total rendering time using a 12 core / 24
thread Google Compute Engine instance running at 2 GHz with the latest
version of pbrt-v3 was 1h 44m 45s.</i></p>

<p>It was a huge amount of work on Disney’s side to extract the scene from
their internal scene representation and convert it to a format that’s
generally accessible; major props to them for taking the time to package
and prepare this data for widespread use.  I’m confident that their work to
do this will be well repaid in the future as researchers use this scene to
dig into the issues related to efficiently rendering scenes of this
complexity.</p>

<p>This scene has already taught me a lot and has made pbrt a better renderer,
but before we get into that, first a little story for context.</p>

<h2 id="the-hash-table-that-wasnt">The hash table that wasn’t</h2>

<p>Years ago while interning in the rendering group at Pixar, I learned an
important lesson: “interesting” things almost always come to light when a
software system is given input with significantly different characteristics
than it’s seen before.  Even for well-written and mature software systems,
new types of input almost always expose heretofore unknown shortcomings in
the existing implementation.</p>

<p>I first learned this lesson while <em>Toy Story 2</em> was in production.  At some
point, someone noticed that a surprising amount of time was being spent
parsing the RIB scene description files.  Someone else in the rendering
group (I believe it was Craig Kolb) whipped out the profiler and started
digging in.</p>

<p>It turned out that most of the parsing time was spent doing lookups in a
hash table that was used to <a href="https://en.wikipedia.org/wiki/String_interning">intern
strings</a>.  The hash table
was a small fixed size, perhaps 256 elements, and it used chaining when
multiple values hashed to the same cell.  Much time had passed since the
hash table was first implemented and scenes now had tens of thousands of
objects, so naturally such a small hash table would quickly fill and become
ineffective.</p>

<p>The expedient thing to do was to just make the hash table larger—all this
was happening in the thick of production, so there was no time to do
something fancy like make the hash table grow as it filled up.  One line
change, rebuild and do a quick test before committing, and… no
performance improvement whatsoever.  Just as much time was being spent on
hash table lookups.  Fascinating!</p>

<p>Upon further digging, it was discovered that the hash function that was
being used was the equivalent of:</p>

<div><pre><code>int hash(const char *str) {
    return str[0];
}
</code></pre>
</div>

<p>(Forgive me Pixar, if I’ve posted super-secret RenderMan source code
there.)</p>

<p>The “hash” function had been implemented in the 1980s, at which time
someone had apparently decided that the computational expense of actually
incorporating some contribution from all of the characters in the string in
the hash value wasn’t worth it.  (And if you’ve only got a handful of
objects in the scene and a 256 entry hash table, maybe, I guess.)</p>

<p>Another historic implementation detail added insult to injury: once Pixar
started making movies, the names for objects in scenes had grown fairly
long, along the lines of “BuzzLightyear/LeftArm/Hand/IndexFinger/Knuckle2”.
However, some earlier phase of the production pipeline used a fixed-size
buffer for storing object names and would shorten any longer names, keeping
only the end and helpfully adding a few periods to show that something had
been lost: “…year/LeftArm/Hand/IndexFinger/Knuckle2”.</p>

<p>Thence, all of the object names the renderer saw were of that form, the
hash function hashed all of them to the bucket for ‘.’, and the hash table
was actually a big linked list.  Good times.  At least the fix was simple
once all that was figured out.</p>

<h2 id="an-intriguing-invitation">An intriguing invitation</h2>

<p>That lesson came to mind last year when Heather Pritchett and Rasmus
Tamstorf from WDAS reached out to me and asked if I was interested in
helping make sure that the <em>Moana</em> scene would render reasonably well with
<a href="https://pbrt.org/">pbrt</a>.<sup id="fnref:ptex"><a href="#fn:ptex">1</a></sup> Naturally I said yes.  I was delighted to
help out and curious to see how it’d go.</p>

<p>The foolish optimist in me was hopeful that there wouldn’t be any huge
surprises—after all, pbrt was first released around 15 years ago and many
people have used it and studied the code over the years.  It should be safe
to assume there weren’t any embarrassments like RenderMan’s old hash
function, right?</p>

<p>Of course, the answer is “wrong”.  (And that’s why we’re here today, and
for a few more posts after this one.)  While I was a little disappointed
that pbrt wasn’t awesome out of the box, I think that my experience working
with the <em>Moana</em> scene is a first validation of the value of having this scene
available; pbrt is already a better system from my having dug into how it
performed with it.</p>

<h3 id="first-renderings">First renderings</h3>

<p>I immediately downloaded the scene once I had access to it (waiting a few
hours for it to make its way over my home Internet connection) and untarred
it, giving me 29 GB of pbrt files and 38 GB of <a href="http://ptex.us/">ptex</a>
texture maps<sup id="fnref:size"><a href="#fn:size">2</a></sup>.  I threw caution into the wind, and tried to render it
on my home system (feat. 16 GB of RAM and a 4 core CPU).  I came back a
little while later to find the computer unresponsive, all of the RAM used,
and pbrt still trying to finish parsing the scene description.  The OS was
doing its best to make it happen with virtual memory, but it seemed
hopeless.  After killing the job, it was still about a minute before the
system was responsive again.</p>

<p>Next up was a Google Compute Engine instance, allowing for more RAM (120 GB)
and more CPUs (32 threads on 16 CPUs).  The good news is that pbrt could
successfully render the scene (thanks to Heather and Rasmus’s efforts
to get it into pbrt’s format). Seeing that pbrt could generate reasonable
pixels for feature film content was thrilling, but the performance was
something else: 34m 58s just to parse the scene description, with memory
use upward of 70 GB during rendering.</p>

<p>Now, it was 29 GB of pbrt scene description files on disk to parse and turn
into something that could be rendered, so I wasn’t expecting a ten second
startup phase.  But half an hour before rays start being traced? That’s bad
enough to make it fairly difficult to work with the scene at all.</p>

<p>One good thing about seeing that sort of performance is that it seemed very
likely that there’s some really stinky stuff going on; not just “matrix
inversion could be made 10% faster”, but “oops, we’re walking through a
100,000 element linked list”. I was optimistic that it’d be possible to
chop that down significantly once I understood what was happening.</p>

<h3 id="no-help-from-the-statistics">No help from the statistics</h3>

<p>The first place I looked for insight was the statistics that pbrt dumps out
after rendering. pbrt’s major phases of execution are instrumented so that
rough profiling data can be gathered by recording what’s actually running
at periodic interrupts during rendering.  Unfortunately, the statistics
didn’t explain much: of the nearly 35 minutes before rendering started, 4m
22s was reported to be spent building BVHs, but none of the rest of the
time was accounted for in any further detail.</p>

<p>Building BVHs is the only meaningful computational task that happens during
scene parsing; everything else is essentially just deserializing shape and
material descriptions.  Knowing how much time was spent on BVH construction
gave a sense of how (in)efficient the system was: what’s left is roughly
30 minutes to parse 29 GB of data, or about 16.5 MB/s.  Well-optimized JSON
parsers, which perform essentially the same task, seem to run at the rate
of 50-200 MB/s, which validates the sense that there’s room for
improvement.</p>

<p>To better understand where the time was going, I ran pbrt using the Linux
<a href="https://perf.wiki.kernel.org/index.php/Main_Page">perf</a> tool, which I’d
never used before, but seemed like it would do the trick.  I did have to
instruct it to actually look at the DWARF symbols to get function names
(<code>--call-graph dwarf</code>), and had to dial down the sampling frequency from
the default 4000 samples per second to 100 (<code>-F 100</code>) so I didn’t get 100
GB trace files, but with that, things were lovely, and I was pleasantly
surprised that the <code>perf report</code> tool had a nice curses interface.</p>

<p>Here’s what it had to say after a run with pbrt as it was at the start of
all this:</p>

<p><img src="https://pharr.org/matt/blog/images/perf-screenshot.png">
<i>I'm actually serious about “nice curses interface”.</i>
</p>

<p>We can see that over half of the time was spent on the mechanics of
parsing: <code>yyparse()</code> is the parser generated by
<a href="https://www.gnu.org/software/bison/">bison</a> and <code>yylex()</code> is the lexer
generated by <a href="https://github.com/westes/flex">flex</a>.  Over half of the time
in <code>yylex()</code> was spent in <code>strtod()</code>, which converts strings to doubles.
We’ll hold off on attacking <code>yyparse()</code> and <code>yylex()</code> until the third
posting in this series, but we already have a good indication that
reducing the amount of data we throw at the renderer might be a good idea.</p>

<h3 id="from-text-to-ply">From text to PLY</h3>

<p>One way to spend less time parsing a text representation of data is to
convert the data to something more efficient to parse.  Quite a bit of
those 29 GB of scene description files is triangle meshes, and pbrt already
had native support for <a href="https://en.wikipedia.org/wiki/PLY_(file_format)">PLY
files</a>, which provide an
efficient binary representation of polygon meshes.  pbrt also has a
<code>--toply</code> command-line flag that will parse a pbrt scene description file,
convert any triangle meshes it finds to PLY files, and emit a new pbrt file
that refers to those PLY files instead.</p>

<p>One catch was that the Disney scene makes extensive use of
<a href="http://ptex.us/">ptex</a> textures, which in turn require a <code>faceIndex</code> value</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pharr.org/matt/blog/2018/07/08/moana-island-pbrt-1.html">https://pharr.org/matt/blog/2018/07/08/moana-island-pbrt-1.html</a></em></p>]]>
            </description>
            <link>https://pharr.org/matt/blog/2018/07/08/moana-island-pbrt-1.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24631637</guid>
            <pubDate>Tue, 29 Sep 2020 19:03:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust 2021: GUI]]>
            </title>
            <description>
<![CDATA[
Score 342 | Comments 205 (<a href="https://news.ycombinator.com/item?id=24631611">thread link</a>) | @clarkmoody
<br/>
September 29, 2020 | https://raphlinus.github.io/rust/druid/2020/09/28/rust-2021.html | <a href="https://web.archive.org/web/*/https://raphlinus.github.io/rust/druid/2020/09/28/rust-2021.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>This is a response to the Rust <a href="https://blog.rust-lang.org/2020/09/03/Planning-2021-Roadmap.html">call for blogs 2021</a> and also a followup to <a href="https://raphlinus.github.io/rust/druid/2019/10/31/rust-2020.html">last year’s entry</a>. It will be entirely focused on GUI.</p>

<p>There is considerable interest in GUI toolkits for Rust. As one data point, it was the 6th highest rated challenge for adoption in the <a href="https://blog.rust-lang.org/2020/04/17/Rust-survey-2019.html#rust-adoption---a-closer-look">2019 Rust survey</a>, just behind async I/O. There is also a fair amount of activity towards this goal, though as a community it still feels a bit unfocused. A characteristic sign is that a new GUI toolkit seems to pop up every couple of months or so.</p>

<p>I believe there is great potential for a high-quality GUI toolkit in Rust. At the same time, it’s an incredibly ambitious task. Subtasks within it, for example accelerated GPU drawing and text layout, are in and of themselves incredibly ambitious tasks. I wouldn’t consider a toolkit “ready” for production use until it supported accessibility, and as far as I know there is nothing in the Rust space even starting to work on this.</p>

<p>Yet, perhaps against my better judgment, I find myself devoting most of my time and energy towards building GUI in Rust. In this post I will set out my hopes but also frankly discuss the challenges.</p>

<h2 id="why-gui-in-rust">Why GUI in Rust?</h2>

<p>Simply put, I believe that the strengths of Rust translate well to writing GUI applications, and that the missing piece is the existence of a good toolkit. One strength is Rust’s wide “dynamic range” – the ability to describe application logic in high level terms while still being attentive to low level details. Another is <em>strong</em> cross-platform compatibility. The increasingly rich crate ecosystem is compelling in many domains. And don’t lose sight of the importance of safety. In traditional object-oriented GUI in C++ especially, object lifetimes can be complicated, and it’s not hard to cause crashes, especially on takeoffs and landings.</p>

<p>I do pay attention to the competitive space, and one thing I see is Electron being used more and more, because it solves real problems. But I also believe that the success of Electron creates a real opportunity for a higher performance, lighter weight alternative. And in general for the projects I see in other languages, I find myself <em>wanting</em> to compete against them.</p>

<h2 id="about-druid">About Druid</h2>

<p>The <a href="https://github.com/linebender/druid">Druid</a> toolkit has made impressive progress in the last year, but is still nowhere near stable or complete. If you are looking for a GUI toolkit to develop your application today, Druid is not it.</p>

<p>We are developing the font editor <a href="https://github.com/linebender/runebender">Runebender</a> as the primary motivating application, but, while a lot of pieces are in place, it is sadly not yet usable for day to day font creation work. One of my goals for the rest of the year is to start creating a font in it.</p>

<p>That said, I am very proud of the work that’s been done in the last year. To hit on some of the highlights, we’re just landing basic but capable <a href="https://www.cmyr.net/blog/piet-text-work.html">rich text layout</a>. The keyboard event is close to browser quality (based on <a href="https://crates.io/crates/keyboard-types">keyboard-types</a>). There is incremental painting based on damage regions. Multi-window support is solid, with support for controlling window placement and dynamic hi-dpi. There is tab-focusing between text boxes. All of these are hard problems. Even more so, I am pleased that a lot of the work came from people in the community.</p>

<h2 id="converging-a-vision">Converging a vision</h2>

<p>Imagine a thought experiment for a bit. Obviously Rust is promising for implementing async, but there isn’t a consensus on the best way to do it. Some people feel it should be done with callbacks, and invest considerable effort into overcoming the serious problems with that approach. Others feel it should be done with a polling future trait, but there are multiple versions of that trait: some get the context from thread local storage, others pass it into the poll method. And of course some people feel the syntax should be <code>future.await</code> while others insist on <code>await!(future)</code>. Every couple of months somebody pops up on /r/rust with a new crate that promises to solve “the async problem,” complete with a nice-looking echo server demo.</p>

<p>That’s about where we are today with GUI toolkits. In many ways, I think converging on a single vision in GUI is a harder problem than for async. For one, people have different things they want to do. I’m personally most interested in things that resemble document editors. Others want 3D or video content. In the future, there might be commercial interest in enterprise line-of-business apps or interfaces for medical devices. These all have quite different requirements in the best ways to express UI logic, and how to build them. Not to mention the endless opportunities to bikeshed.</p>

<p>I am not (yet) proposing Druid as the singular vision that the Rust community should converge on. I’m enjoying reading codebases and learning from other Rust GUI projects. In particular, I’m finding lots to like about <a href="https://github.com/hecrj/iced">Iced</a>: it has good solutions to async, 3D graphics (through wgpu), being able to function in a guest window (important for VST plug-ins), among other problems. And I’m getting the sense that it’s easier for developers. The Elm-like reactive architecture maps nicely to Rust, and depending on exactly what you’re trying to do, it’s not hard to figure out how to express your app-specific logic. By contrast, Druid’s reactive model, while efficient and powerful in many ways, has complex concepts such as Haskell-like lenses, and places a burden on the developer to carefully design the “app data” to fit the Druid model. The <a href="https://raphlinus.github.io/rust/druid/2020/09/25/principled-reactive-ui.html">Crochet research prototype</a> is an active exploration into making that simpler. I am thankful to Iced (and other toolkits) for being a model to study.</p>

<p>The work to build consensus is complex and multifaceted, and it cannot be rushed. From my side, I hope to improve the designs and implementations to the point where they are compelling. I also hope to listen to criticisms, many of which are valid. I also think there is more work the community can be doing here. I’d love to see more active effort in trying to learn from the ongoing work and try to synthesize it. The GUI-related threads on /r/rust are sadly not a place where that happens; they most often consist of a statement of requirements (usually presented very informally), followed by a bit of bikeshedding. I don’t have a good answer for how to improve this situation, but put it out there as a problem I’m feeling.</p>

<p>While I think a converged vision is an admirable and ambitious goal, it may not be necessary for a successful GUI ecosystem in Rust. It’s possible that different types of GUI programs will simply require different infrastructure, so even in the long term it makes sense to have ecosystem diversity. Certainly that’s the case in the short and medium term as well, just to explore the space. And even without a grand unifying vision, there is lots of scope to work on infrastructural crates for important pieces of the GUI story, including text layout and related problems.</p>

<h2 id="learning-and-community">Learning and community</h2>

<p>Many Rust projects these days come with what’s basically a marketing pitch: “adopt this codebase, it’s awesome.” I am starting to see the Druid project in a somewhat different light. I consider its primary mission to be <em>teaching and learning</em> the knowledge required to build GUI. To that extent, the community we’re building, hosted on <a href="https://xi.zulipchat.com/">our Zulip instance,</a> is just as important as the code.</p>

<p>The knowledge needed to build GUI has many aspects, and is at all levels. Some of it is at a high level, like the best way to express reactive UI. Some of it is at a low level, like the keyboard event processing. A common thread is that a lot of it is very arcane, not really written down properly anywhere. Fortunately, a lot of it is accessible through reading the code of other open source projects, whether in Rust or in other languages (I’ve found both Chromium and Gecko to be especially useful).</p>

<p>So I consider this a goal, a success criterion, of the Druid project. If somebody wants to know how to solve a problem in GUI, the Druid codebase should be one of the best places to look for answers.</p>

<p>I love research more than most anything, and a lot of my own work has a strong research flavor. That has caused some confusion; some of the things I’m exploring are very speculative and will likely take years to come to fruition. Certainly my research into compute-centric GPU rendering is of that nature; I’m excited about the fact that it promises dramatic performance improvements over the current state of the art, but it’s nowhere near ready to put into production yet. I’m striving for clearer communication so people can have a better idea what is speculative, based on grand futuristic visions, and what is on track to being usable reasonably soon. But both are important aspects of what I consider to be the main mission: fostering learning about how to build GUI.</p>

<h2 id="baby-steps">Baby steps</h2>

<p>While I am driven by a long-term, ambitious vision, the goal of Druid in 2021 is not to deliver a general UI toolkit. Rather, we are deliberately continuing to follow a narrow scope. The primary goal remains the font editor project, and we plan to re-focus attention on that. I do think this is an attainable goal. I also think that what we learn from trying to build a real application with users will be extremely valuable to the more ambitious task.</p>

<p>One project management technique that is proving effective is “cycles.” Instead of trying to solve the most ambitious version of a problem, we choose up front what to push to a future cycle, reducing the scope for the current implementation cycle. An example is the choice to defer BiDi from our recent text work. This is obviously an essential feature for a real GUI toolkit, but we also know it could take weeks or months to get it right. To have any chance of shipping, we have to carefully budget our time and energy on subprojects that easily could expand to absorb our full attention.</p>

<p>A common development pattern for a fledgling GUI toolkit is to have a “hero app” that drives development. It really helps clarify requirements, and also makes it …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://raphlinus.github.io/rust/druid/2020/09/28/rust-2021.html">https://raphlinus.github.io/rust/druid/2020/09/28/rust-2021.html</a></em></p>]]>
            </description>
            <link>https://raphlinus.github.io/rust/druid/2020/09/28/rust-2021.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24631611</guid>
            <pubDate>Tue, 29 Sep 2020 19:00:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Have a Feedback Loop]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24631466">thread link</a>) | @jerodsanto
<br/>
September 29, 2020 | https://www.iamjonas.me/2020/09/have-feedback-loop.html | <a href="https://web.archive.org/web/*/https://www.iamjonas.me/2020/09/have-feedback-loop.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.iamjonas.me/2020/09/have-feedback-loop.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24631466</guid>
            <pubDate>Tue, 29 Sep 2020 18:48:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What 4M Slack Messages Tell Us About Collaboration]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24631435">thread link</a>) | @knoxa2511
<br/>
September 29, 2020 | https://productiv.com/what-4-million-slack-messages-tell-us-about-collaboration/ | <a href="https://web.archive.org/web/*/https://productiv.com/what-4-million-slack-messages-tell-us-about-collaboration/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section data-id="64352fa9" data-element_type="section">
						<div>
							<div>
					<div data-id="5bad87c" data-element_type="column">
			<div>
							<div>
						<div data-id="3d378fd8" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><img loading="lazy" src="https://productiv.com/wp-content/uploads/2020/09/Is-Slack-Worth-the-SaaS-Investment_600x.jpg" alt="" width="600" height="300" srcset="https://productiv.com/wp-content/uploads/2020/09/Is-Slack-Worth-the-SaaS-Investment_600x.jpg 600w, https://productiv.com/wp-content/uploads/2020/09/Is-Slack-Worth-the-SaaS-Investment_600x-300x150.jpg 300w" sizes="(max-width: 600px) 100vw, 600px"></p><p><span>What value is your company getting out of Slack?</span></p><p><span>We’ve got the data. Using engagement analytics from Productiv’s SaaS Management platform, we looked at over </span><b>4,000,000 Slack messages</b><span> across approximately </span><b>40,000 users</b><span>. We compared this data to a similar number of messages from companies using other messaging tools. From this data we pulled concrete observations around how enterprises are using — and driving value — from Slack.</span></p><p><span>Read on to get the hard numbers on how Slack drives open collaboration, cross-team collaboration, and external collaboration — as well as how you can use Productiv’s engagement analytics to prove the value you’re getting from SaaS platforms like Slack.</span></p><h3><b>Understanding Productiv and its Data</b></h3><p><span>Before diving into the data itself, let’s provide context for where the data comes from. Productiv is an enterprise </span><a href="http://productiv.com/"><span>SaaS management</span></a><span> platform. Our mission is to unlock productivity from your SaaS portfolio by giving you insights into how your employees are using their applications. Whether its collaboration, communications, project management, or any other SaaS application, Productiv serves as your central system of record for how these applications are used; licensing costs; and renewals.</span></p><p><span>Our focus on </span><a href="https://productiv.com/application-engagement-analytics-the-key-to-rethinking-saas-management/"><span>application engagement analytics</span></a><span>, combined with this centralized system puts us into an excellent place to extract trends across many enterprises for any number of applications. All of the data presented below is derived solely from Productiv’s platform, and aggregated across customer environments. This data in turn can help enterprises better understand how they are getting ROI out of the applications they invest time and money into.</span></p><h3><b>How to Measure Slack ROI</b></h3><p><a href="https://techcrunch.com/2020/03/19/slack-adds-7k-customers-in-7-weeks-amid-remote-work-boom-besting-its-preceding-2-quarters-results/"><span>Slack is booming</span></a><span>, as companies invest heavily in collaboration solutions that allow people to work more effectively, even as more people are working from home. But how do you know how much value youâ€™re getting out of a collaboration solution such as Slack?Â&nbsp;</span></p><p><span>We looked at the common questions asked by CIOs:</span></p><ul><li><span>If we invest in Slack, how much will our employees actually use it?Â&nbsp;</span></li><li><span>Does Slack improve collaboration between employees?Â&nbsp;</span></li><li><span>How do we measure the value of this collaboration to show Return on Investment?</span></li></ul><p><span>On a day-to-day basis, you might be able to measure messages across public and private channels. What does that really mean, though — are employees making the most of Slack?Â&nbsp;</span></p><p><span>To understand the value your organization is getting from a SaaS investment such as Slack, itâ€™s not enough to look at how many licenses you have provisioned. In fact, itâ€™s not enough to look at </span><a href="https://slack.com/blog/news/work-is-fueled-by-true-engagement"><span>daily average users</span></a><span> either – what you need to measure is </span><b>user engagement </b><span>to see if employees are truly getting value from their tools</span><b>.</b><span>Â&nbsp;</span></p><p><span>User engagement is how an individual interacts with a product or service.</span></p><p><span>Engagement looks at what features your employees use, how frequently they use it, and (critically) what kind of value they get from it — as value for employees translates into value for the business.</span></p><p><span>You can tell when employees are engaged with their collaboration tools and using it for deep work when they’re doing more with the platform than just using the basic features – for example in the case of messaging, lightweight private messages to other team members. Specifically, we break down value from thisÂ&nbsp; engagement into three metrics.</span></p><h3><b>An Analysis of The Three Metrics of Slack Engagement</b></h3><p>Many think of Slack simply as a chat platform. Our data however supports the idea that Slack has evolved into a collaboration platform, with three types of collaboration that we can measure. Let’s break down these three types of collaboration and examine the supporting data.</p><h4><span>1. Open Collaboration</span></h4><p>The idea ofÂ&nbsp;<a href="https://opensym.org/about-us/definition/">open collaboration</a>Â&nbsp;is employees freely working with other employees. Compared to rigid, hierarchical structures, open collaboration mixes things up. Anyone can join in. (Think company-wide brainstorming sessions, or town hall-style meetings.)</p><p>In Slack,Â&nbsp;<span>â€œopen collaborationâ€� can be measured by how users utilize public channels</span>.Â&nbsp;<a href="https://medium.com/ragtag-notes/set-up-your-team-for-organizing-27563b0ab189">Public channels</a>Â&nbsp;are open to anyone in the workplace, with the exception of guests — theyâ€™re meant for company-wide announcements, updates, or general information sharing.</p><p>According to Productiv data,Â&nbsp;<span>those who use Slack are more than twice as likely to use public channels for messaging</span>Â&nbsp;than comparable messaging products.</p><p>Our analytics show thatÂ&nbsp;<span>74% of Slack users send messages through public channels</span>, compared to justÂ&nbsp;<span>34% of users for other enterprise collaboration platforms</span>. Slack isnâ€™t just a private chat platform — it drives open, public collaboration.</p><p>Anecdotally, we see Slack customers echo this philosophy. For example,Â&nbsp;<a href="https://slack.com/customer-stories/td-ameritrade">Neal Obermeyer at TD Ameritrade</a>Â&nbsp;noted, â€œ<a href="https://slack.com/features/channels/">Slack channels</a>, virtual spaces for sharing information and files, cut through information silos by making company knowledge available across the organization. By moving communication to public channels, we removed the subjectivity of sharing information so internal knowledge could scale as needed.â€� This type of approach is well reflected in our data.</p><h4><span>2. Cross-Team Collaboration</span></h4><p>Beyond open collaboration (conversations that anyone can join), cross-team collaboration means teams using Slack to work together. For example, someone from HR communicating to someone in Accounting, versus accounting only talking to accounting or HR only messaging HR.</p><p>On average, we found thatÂ&nbsp;<span>~80% of Slack users send cross-team messages</span>.</p><p><img loading="lazy" src="https://productiv.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-7.45.28-PM-1024x422.png" alt="" width="1024" height="422" srcset="https://productiv.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-7.45.28-PM-1024x422.png 1024w, https://productiv.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-7.45.28-PM-300x124.png 300w, https://productiv.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-7.45.28-PM-768x317.png 768w, https://productiv.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-7.45.28-PM.png 1377w" sizes="(max-width: 1024px) 100vw, 1024px"></p><p><i>How a high-growth software company (1000+ employees) uses Slack between teams. (Source: Productiv analytics)</i></p><p>Our analytics show that companies see much greater cross-team collaboration with Slack than other messaging platforms. In fact,Â&nbsp;<span>90%+ of companies using Slack</span>Â&nbsp;haveÂ&nbsp;<span>70%+ of their users engaging in cross-team collaboration.Â&nbsp;</span></p><p><img loading="lazy" src="https://productiv.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-3.37.21-PM-1024x526.png" alt="" width="1024" height="526" srcset="https://productiv.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-3.37.21-PM-1024x526.png 1024w, https://productiv.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-3.37.21-PM-300x154.png 300w, https://productiv.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-3.37.21-PM-768x394.png 768w, https://productiv.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-3.37.21-PM.png 1472w" sizes="(max-width: 1024px) 100vw, 1024px"></p><p><i>How a large technology company (10,000+ employees) uses Slack for cross-team collaboration. (Source: Productiv analytics)</i></p><h4><span>3. External Collaboration</span></h4><p><a href="https://innovationmanagement.se/2017/01/06/a-quick-guide-to-external-collaboration/">External collaboration</a>Â&nbsp;refers to how well employees work outside your company — say, with suppliers, consultants, or customers. While employees certainly need to collaborate with each other, external collaboration leads to greater innovation, happier customers, and a more valuable business.</p><p>According to our data, Slack is effective at driving more external collaboration.Â&nbsp;<span>For every ten messages in internal public channels,</span>Â&nbsp;<span>Productivâ€™s Slack users send an average of 4.8 external messages.Â&nbsp;</span>In other words, the ratio is about 1 external message for every 2 internal messages.</p><p>And that number is growing: between August 2019 and August 2020,Â&nbsp;<span>43% of the businesses we analyzed have increased the volume of external messages sent through Slack</span>.</p><p>Slack Connect allows teams to move the conversations theyâ€™re having with external partners, vendors, or customers into Slack channels.</p><p><img loading="lazy" src="https://productiv.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-3.40.26-PM-1024x362.png" alt="" width="1024" height="362" srcset="https://productiv.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-3.40.26-PM-1024x362.png 1024w, https://productiv.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-3.40.26-PM-300x106.png 300w, https://productiv.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-3.40.26-PM-768x271.png 768w, https://productiv.com/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-3.40.26-PM.png 1460w" sizes="(max-width: 1024px) 100vw, 1024px"></p><p><i>How Slack increases internal collaboration (black line), cross-team collaboration (green line), and external collaboration (blue line). (Source: Productiv analytics)</i><i>Â&nbsp;</i></p><p>Â&nbsp;</p><p>Â&nbsp;</p><p>Â&nbsp;</p><p>Â&nbsp;</p><p>Â&nbsp;</p><p>Â&nbsp;</p><p>Â&nbsp;</p><p>Â&nbsp;</p><p>Â&nbsp;</p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section></div>]]>
            </description>
            <link>https://productiv.com/what-4-million-slack-messages-tell-us-about-collaboration/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24631435</guid>
            <pubDate>Tue, 29 Sep 2020 18:44:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding Kubernetes Init Containers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24631324">thread link</a>) | @pj3677
<br/>
September 29, 2020 | https://www.learncloudnative.com/blog/2020-09-26-init-containers/ | <a href="https://web.archive.org/web/*/https://www.learncloudnative.com/blog/2020-09-26-init-containers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>Init containers allow you to separate your application from the initialization logic and provide a way to run the initialization tasks such as setting up permissions, database schemas, or seeding data for the main application, etc. The init containers may also include any tools or binaries that you don't want to have in your primary container image due to security reasons.</p><p>The init containers are executed in a sequence before your primary or application containers start. On the other hand, any application containers have a non-deterministic startup order, so you can't use them for the initialization type of work.</p><p>The figure below shows the execution flow of the init containers and the application containers.</p><p><span>
      <a href="https://www.learncloudnative.com/static/9d90a818ebe0c8029d1b58facf7e414a/9f82e/init-containers.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Init Containers" title="Kubernetes Init Containers" src="https://d33wubrfki0l68.cloudfront.net/9eec2180e1c0fbe463738e707c7a23e64f161f5c/efbec/static/9d90a818ebe0c8029d1b58facf7e414a/9f82e/init-containers.png" srcset="https://d33wubrfki0l68.cloudfront.net/974b7854c6dd364ca80b766e83b5fcc160ed52a8/85291/static/9d90a818ebe0c8029d1b58facf7e414a/2eb24/init-containers.png 215w,https://d33wubrfki0l68.cloudfront.net/b19eb655fd61ef64249f1a32972ca729f67eb88a/5ea0c/static/9d90a818ebe0c8029d1b58facf7e414a/05ed2/init-containers.png 430w,https://d33wubrfki0l68.cloudfront.net/9eec2180e1c0fbe463738e707c7a23e64f161f5c/efbec/static/9d90a818ebe0c8029d1b58facf7e414a/9f82e/init-containers.png 820w" sizes="(max-width: 820px) 100vw, 820px" loading="lazy">
  </a>
    </span></p><p>The application containers will wait for the init containers to complete successfully before starting. If the init containers fail, the Pod is restarted (assuming we didn't set the restart policy to <code>RestartNever</code>), which causes the init containers to run again. When designing your init containers, make sure they are idempotent, to run multiple times without issues. For example, if you're seeding the database, check if it already contains the records before re-inserting them again.</p><p>Since init containers are part of the same Pod, they share the volumes, network, security settings, and resource limits, just like any other container in the Pod. </p><p>Let's look at an example where we use an init container to clone a GitHub repository to a shared volume between all containers. The Github repo contains a single <code>index.html</code>. Once the repo is cloned and the init container has executed, the primary container running the Nginx server can use <code>index.html</code> from the shared volume and serve it.</p><p>You define the init containers under the <code>spec</code> using the <code>initContainers</code> field, while you define the application containers under the <code>containers</code> field. We define an <code>emptyDir</code> volume and mount it into both the init and application container. When the init container starts, it will run the <code>git clone</code> command and clone the repository into the <code>/usr/share/nginx/html</code> folder. This folder is the default folder Nginx serves the HTML pages from, so when the application container starts, we will be able to access the HTML page we cloned. </p><div data-language="yaml"><pre><code><span>apiVersion</span><span>:</span> v1
<span>kind</span><span>:</span> Pod
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> website
<span>spec</span><span>:</span>
  <span>initContainers</span><span>:</span>
    <span>-</span> <span>name</span><span>:</span> clone<span>-</span>repo
      <span>image</span><span>:</span> alpine/git
      <span>command</span><span>:</span>
        <span>-</span> git
        <span>-</span> clone
        <span>-</span> <span>-</span><span>-</span>progress
        <span>-</span> https<span>:</span>//github.com/peterj/simple<span>-</span>http<span>-</span>page.git
        <span>-</span> /usr/share/nginx/html
      <span>volumeMounts</span><span>:</span>
        <span>-</span> <span>name</span><span>:</span> web
          <span>mountPath</span><span>:</span> <span>"/usr/share/nginx/html"</span>
  <span>containers</span><span>:</span>
    <span>-</span> <span>name</span><span>:</span> nginx
      <span>image</span><span>:</span> nginx
      <span>ports</span><span>:</span>
        <span>-</span> <span>name</span><span>:</span> http
          <span>containerPort</span><span>:</span> <span>80</span>
      <span>volumeMounts</span><span>:</span>
        <span>-</span> <span>name</span><span>:</span> web
          <span>mountPath</span><span>:</span> <span>"/usr/share/nginx/html"</span>
  <span>volumes</span><span>:</span>
    <span>-</span> <span>name</span><span>:</span> web
      <span>emptyDir</span><span>:</span> <span>{</span><span>}</span></code></pre></div><p>Save the above YAML to <code>init-container.yaml</code> and create the Pod using <code>kubectl apply -f init-container.yaml</code>.</p><p>If you run <code>kubectl get pods</code> right after the above command, you should see the status of the init container:</p><div data-language="bash"><pre><code>$ kubectl get po
NAME      READY   STATUS     RESTARTS   AGE
website   <span>0</span>/1     Init:0/1   <span>0</span>          1s</code></pre></div><p>The number <code>0/1</code> indicates a total of 1 init containers, and 0 containers have been completed so far. In case the init container fails, the status changes to <code>Init:Error</code> or <code>Init:CrashLoopBackOff</code> if the container fails repeatedly.</p><p>You can also look at the events using the <code>describe</code> command to see what happened:</p><div data-language="text"><pre><code>Normal  Scheduled  19s   default-scheduler  Successfully assigned default/website to minikube
Normal  Pulling    18s   kubelet, minikube  Pulling image "alpine/git"
Normal  Pulled     17s   kubelet, minikube  Successfully pulled image "alpine/git"
Normal  Created    17s   kubelet, minikube  Created container clone-repo
Normal  Started    16s   kubelet, minikube  Started container clone-repo
Normal  Pulling    15s   kubelet, minikube  Pulling image "nginx"
Normal  Pulled     13s   kubelet, minikube  Successfully pulled image "nginx"
Normal  Created    13s   kubelet, minikube  Created container nginx
Normal  Started    13s   kubelet, minikube  Started container nginx</code></pre></div><p>You will notice as soon as Kubernetes schedules the Pod, the first Docker image is pulled (<code>alpine/git</code>), and the init container (<code>clone-repo</code>) is created and started. Once that's completed (the container cloned the repo) the main application container (<code>nginx</code>) starts.</p><p>Additionally, you can also use the <code>logs</code> command to get the logs from the init container by specifying the container name using the <code>-c</code> flag:</p><div data-language="bash"><pre><code>$ kubectl logs website -c clone-repo
Cloning into <span>'/usr/share/nginx/html'</span><span>..</span>.
remote: Enumerating objects: <span>6</span>, done.
remote: Counting objects: <span>100</span>% <span>(</span><span>6</span>/6<span>)</span>, done.
remote: Compressing objects: <span>100</span>% <span>(</span><span>4</span>/4<span>)</span>, done.
remote: Total <span>6</span> <span>(</span>delta <span>0</span><span>)</span>, reused <span>0</span> <span>(</span>delta <span>0</span><span>)</span>, pack-reused <span>0</span>
Receiving objects: <span>100</span>% <span>(</span><span>6</span>/6<span>)</span>, done.</code></pre></div><p>Finally, to actually see the static HTML page can use <code>port-forward</code> to forward the local port to the port <code>80</code> on the container:</p><div data-language="bash"><pre><code>$ kubectl port-forward pod/website <span>8000</span>:80
Forwarding from <span>127.0</span>.0.1:8000 -<span>&gt;</span> <span>80</span>
Forwarding from <span>[</span>::1<span>]</span>:8000 -<span>&gt;</span> <span>80</span></code></pre></div><p>You can now open your browser at <code>http://localhost:8000</code> to open the static page as shown in figure below.</p><p><span>
      <a href="https://www.learncloudnative.com/static/9c0a3a9db42df7251937675e882b29f9/01e7c/simple-http-page.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Static HTML From Github Repo" title="Static HTML From Github Repo" src="https://d33wubrfki0l68.cloudfront.net/eb837020adf8929b21c1216ccba09d735bfe4686/ef2be/static/9c0a3a9db42df7251937675e882b29f9/01e7c/simple-http-page.png" srcset="https://d33wubrfki0l68.cloudfront.net/2178c0862319f9f33792560202123e4702a50d89/8edeb/static/9c0a3a9db42df7251937675e882b29f9/2eb24/simple-http-page.png 215w,https://d33wubrfki0l68.cloudfront.net/187c313f77573848e4ade2d37023d3376329ec92/2b16d/static/9c0a3a9db42df7251937675e882b29f9/05ed2/simple-http-page.png 430w,https://d33wubrfki0l68.cloudfront.net/eb837020adf8929b21c1216ccba09d735bfe4686/ef2be/static/9c0a3a9db42df7251937675e882b29f9/01e7c/simple-http-page.png 512w" sizes="(max-width: 512px) 100vw, 512px" loading="lazy">
  </a>
    </span></p><p>Lastly, delete the Pod by running <code>kubectl delete po website</code>.</p></article></div>]]>
            </description>
            <link>https://www.learncloudnative.com/blog/2020-09-26-init-containers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24631324</guid>
            <pubDate>Tue, 29 Sep 2020 18:33:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Magnum Engine integrates Python and C++]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24631106">thread link</a>) | @jakearmitage
<br/>
September 29, 2020 | https://blog.magnum.graphics/announcements/introducing-python-bindings/ | <a href="https://web.archive.org/web/*/https://blog.magnum.graphics/announcements/introducing-python-bindings/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>
<!-- content -->
<p>The new Mag­num Python bind­ings, while still
<abbr title="to allow breaking API changes">la­beled ex­per­i­men­tal</abbr>, al­ready give you
a pack­age us­able in re­al work­flows — a NumPy-com­pat­i­ble con­tain­er li­brary,
graph­ics-ori­ent­ed math class­es and func­tions, OpenGL buf­fer, mesh, shad­er and
tex­ture APIs, im­age and mesh da­ta im­port and a SDL / GLFW ap­pli­ca­tion class
with key and mouse events. Head over to the
<a href="https://doc.magnum.graphics/python/building/">in­stal­la­tion doc­u­men­ta­tion</a> to get it your­self; if you
are on Arch­Lin­ux or use Home­brew, pack­ages are al­ready there, wait­ing for you:</p>
<pre>brew tap mosra/magnum
brew install --HEAD corrade magnum magnum-plugins magnum-bindings</pre>
<p>And of course it has all good­ies you’d ex­pect from a “Python-na­tive” li­brary
— full slic­ing sup­port, er­rors re­port­ed through Python ex­cep­tions in­stead of
re­turn codes (or hard as­serts) and prop­er­ties in­stead of set­ters/get­ters where
it makes sense. To get you a quick over­view of how it looks and how is it used,
the first few ex­am­ples are port­ed to it:</p>


<section id="enter-pybind11">
<h2><a href="#enter-pybind11">En­ter py­bind11</a></h2>
<p>I dis­cov­ered <a href="https://github.com/pybind/pybind11">py­bind11</a> by a lucky ac­ci­dent in
<a href="https://github.com/mosra/magnum/issues/228">ear­ly 2018</a> and im­me­di­ate­ly had to try it. Learn­ing
the ba­sics and ex­pos­ing some min­i­mal ma­trix/vec­tor math took me about
<em>two hours</em>. It was an ex­treme fun and I have to thank all py­bind11 de­vel­op­ers
for mak­ing it so straight­for­ward to use.</p>
<figure>
<pre><span>py</span><span>::</span><span>class_</span><span>&lt;</span><span>Vector3</span><span>&gt;</span><span>(</span><span>m</span><span>,</span> <span>"Vector3"</span><span>)</span>
    <span>.</span><span>def_static</span><span>(</span><span>"x_axis"</span><span>,</span> <span>&amp;</span><span>Vector3</span><span>::</span><span>xAxis</span><span>,</span> <span>py</span><span>::</span><span>arg</span><span>(</span><span>"length"</span><span>)</span> <span>=</span> <span>1.0f</span><span>)</span>
    <span>.</span><span>def_static</span><span>(</span><span>"y_axis"</span><span>,</span> <span>&amp;</span><span>Vector3</span><span>::</span><span>yAxis</span><span>,</span> <span>py</span><span>::</span><span>arg</span><span>(</span><span>"length"</span><span>)</span> <span>=</span> <span>1.0f</span><span>)</span>
    <span>.</span><span>def_static</span><span>(</span><span>"z_axis"</span><span>,</span> <span>&amp;</span><span>Vector3</span><span>::</span><span>zAxis</span><span>,</span> <span>py</span><span>::</span><span>arg</span><span>(</span><span>"length"</span><span>)</span> <span>=</span> <span>1.0f</span><span>)</span>
    <span>.</span><span>def</span><span>(</span><span>py</span><span>::</span><span>init</span><span>&lt;</span><span>Float</span><span>,</span> <span>Float</span><span>,</span> <span>Float</span><span>&gt;</span><span>())</span>
    <span>.</span><span>def</span><span>(</span><span>py</span><span>::</span><span>init</span><span>&lt;</span><span>Float</span><span>&gt;</span><span>())</span>
    <span>.</span><span>def</span><span>(</span><span>py</span><span>::</span><span>self</span> <span>==</span> <span>py</span><span>::</span><span>self</span><span>)</span>
    <span>.</span><span>def</span><span>(</span><span>py</span><span>::</span><span>self</span> <span>!=</span> <span>py</span><span>::</span><span>self</span><span>)</span>
    <span>.</span><span>def</span><span>(</span><span>"is_zero"</span><span>,</span> <span>&amp;</span><span>Vector3</span><span>::</span><span>isZero</span><span>)</span>
    <span>.</span><span>def</span><span>(</span><span>"is_normalized"</span><span>,</span> <span>&amp;</span><span>Vector3</span><span>::</span><span>isNormalized</span><span>)</span>
    <span>.</span><span>def</span><span>(</span><span>py</span><span>::</span><span>self</span> <span>+=</span> <span>py</span><span>::</span><span>self</span><span>)</span>
    <span>.</span><span>def</span><span>(</span><span>py</span><span>::</span><span>self</span> <span>+</span> <span>py</span><span>::</span><span>self</span><span>)</span>
    <span>.</span><span>def</span><span>(</span><span>py</span><span>::</span><span>self</span> <span>*=</span> <span>Float</span><span>{})</span>
    <span>.</span><span>def</span><span>(</span><span>py</span><span>::</span><span>self</span> <span>*</span> <span>Float</span><span>{})</span>
    <span>.</span><span>def</span><span>(</span><span>py</span><span>::</span><span>self</span> <span>*=</span> <span>py</span><span>::</span><span>self</span><span>)</span></pre>
<p>That’s what it took to bind a vec­tor class.</p>
</figure>
<p>How­ev­er, dif­fer­ent things took a pri­or­i­ty and so the pro­to­type got shelved
un­til it got re­vived again this year. But I learned one main thing — even
just the math class­es alone were some­thing <em>so use­ful</em> that I kept the built
Python mod­ule around and used it from time to time as an en­hanced cal­cu­la­tor.
Now, with the <a href="https://doc.magnum.graphics/python/magnum/math/">mag­num.math</a> mod­ule be­ing al­most com­plete, it’s an ev­ery­day
tool I use for quick cal­cu­la­tions. Feel free to do the same.</p>
<div>
<figure>
<pre><span>&gt;&gt;&gt; </span><span>from</span> <span>magnum</span> <span>import</span> <span>*</span>
<span>&gt;&gt;&gt; </span><span>Matrix3</span><span>.</span><span>rotation</span><span>(</span><span>Deg</span><span>(</span><span>45</span><span>))</span>
<span>Matrix(0.707107, -0.707107, 0,</span>
<span>    0.707107, 0.707107, 0,</span>
<span>    0, 0, 1)</span></pre>
<p>Quick, where are the mi­nus signs in a 2D ro­ta­tion ma­trix?</p>
</figure>
</div>
</section>
<section id="what-python-apis-and-docs-could-learn-from-c">
<h2><a href="#what-python-apis-and-docs-could-learn-from-c">What Python APIs (and docs) could learn from C++</a></h2>
<p>Ev­ery time some­one told me they’re us­ing <a href="https://numpy.org/">numpy</a> for
“do­ing math quick­ly in Python”, I as­sumed it’s the rea­son­able thing to do —
un­til I ac­tu­al­ly tried to use it. I get that my use case of 4×4 ma­tri­ces
<em>at most</em> might not align well with NumPy’s goals, but the prob­lem is, as far
as I know,
<span>there’s no full-fea­tured math li­brary for Python that would give me the whole pack­age</span><a href="#id2" id="id1">1</a>
in­clud­ing <a href="https://doc.magnum.graphics/python/magnum/Quaternion/">Quater­nion</a>s or <a href="https://doc.magnum.graphics/python/magnum/Matrix4/">2D/3D trans­for­ma­tion ma­tri­ces</a>.</p>
<p>As an ex­cer­cise, for us­abil­i­ty com­par­i­son I tried to ex­press the ro­ta­tion
ma­trix shown in the box above in SciPy / NumPy. It took me a good half an hour
of star­ing at the docs of <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.transform.Rotation.html#scipy.spatial.transform.Rotation">scipy.spa­tial.trans­form.Ro­ta­tion</a> un­til I
ul­ti­mate­ly de­cid­ed it’s not worth my time. The over­ar­ch­ing prob­lem I have with
all those APIs is that it’s not clear at all what types I’m ex­pect­ed to feed to
them and pro­vid­ed ex­am­ple code looks like I’m sup­posed to do half of the
cal­cu­la­tions my­self any­way.</p>
<figure>
<pre><span>&gt;&gt;&gt;</span> <span>from</span> <span>scipy.spatial.transform</span> <span>import</span> <span>Rotation</span> <span>as</span> <span>R</span>
<span>&gt;&gt;&gt;</span> <span>r</span> <span>=</span> <span>R</span><span>.</span><span>from_quat</span><span>([</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>np</span><span>.</span><span>sin</span><span>(</span><span>np</span><span>.</span><span>pi</span><span>/</span><span>4</span><span>),</span> <span>np</span><span>.</span><span>cos</span><span>(</span><span>np</span><span>.</span><span>pi</span><span>/</span><span>4</span><span>)])</span></pre>
<blockquote>
<p>Ro­ta­tion.from_quat(quat, nor­mal­ized=False)</p>
<p>Pa­ram­e­ters:</p>
<dl>
<dt><strong>quat: ar­ray_­like, shape (N, 4) or (4,)</strong></dt>
<dd>Each row is a (pos­si­bly non-unit norm) quater­nion in scalar-last
(x, y, z, w) for­mat.</dd>
</dl>
<p>—<a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.transform.Rotation.from_quat.html#scipy.spatial.transform.Rotation.from_quat">scipy.spa­tial.trans­form.Ro­ta­tion.from_quat()</a></p>
</blockquote>
<p>Type in­for­ma­tion in the SciPy doc­u­men­ta­tion is vague at best.
<em>Al­so, I’d like some­thing that would make the quater­nion for me, as well.</em></p>
</figure>
<p>To avoid the type con­fu­sion, with Mag­num Python bind­ings I de­cid­ed to use
strong types where pos­si­ble — so in­stead of a sin­gle dy­nam­ic ma­trix / vec­tor
type akin to <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray">numpy.ndar­ray</a>, there’s a clear dis­tinc­tion be­tween ma­tri­ces
and vec­tors of dif­fer­ent sizes. So then if you do <code><span>Matrix4x3</span><span>()</span> <span>@</span> <span>Matrix2x4</span><span>()</span></code>,
docs of <a href="https://doc.magnum.graphics/python/magnum/Matrix4x3/#__matmul__-da39a">Ma­trix4x3.__­mat­mul__()</a> will tell you the re­sult is <a href="https://doc.magnum.graphics/python/magnum/Matrix2x3/">Ma­trix2x3</a>.
For NumPy it­self, there’s a pro­pos­al for im­proved type an­no­ta­tions at
<a href="https://github.com/numpy/numpy/issues/7370">numpy/numpy#7370</a> which would help a lot, but the doc­u­men­ta­tion tools
<em>have to</em> make use of that. <a href="#everyone-just-uses-sphinx-you">More on that be­low</a>.</p>
<p>One lit­tle thing with big im­pact of the C++ API is strong­ly-typed an­gles. You
no longer need to re­mem­ber that trig func­tions use ra­di­ans in­ter­nal­ly but HSV
col­ors or Ope­nAL jug­gles with de­grees in­stead — sim­ply use what­ev­er you
please. So Python got the <a href="https://doc.magnum.graphics/python/magnum/Deg/">Deg</a> and <a href="https://doc.magnum.graphics/python/magnum/Rad/">Rad</a> as well. Python doesn’t
have any us­er-de­fined lit­er­als (and I’m not aware of any pro­pos­als to add it),
how­ev­er <a href="https://stackoverflow.com/a/37204095">there’s a way to make Python rec­og­nize them</a>.
I’m not yet sure if this amount of mag­ic is wise to ap­ply, but I might try it
out once.</p>
<dl>
<dt id="id2">1.</dt>
<dd><span><a href="#id1">^</a></span> As <a href="https://www.reddit.com/r/cpp/comments/d5pilr/how_magnum_engine_exposes_c_to_python/f0nqese/">/u/Ni­hon­Nukite point­ed out on Red­dit</a>,
there’s <a href="https://github.com/adamlwgriffiths/Pyrr">Pyrr</a> that pro­vides
the above miss­ing func­tion­al­i­ty, ful­ly in­te­grat­ed with numpy. The on­ly
po­ten­tial down­side is that it’s all pure Python, not op­ti­mized na­tive code.</dd>
</dl>
</section>
<section id="hard-things-are-suddenly-easy-if-you-use-a-different-language">
<h2><a href="#hard-things-are-suddenly-easy-if-you-use-a-different-language">Hard things are sud­den­ly easy if you use a dif­fer­ent lan­guage</a></h2>
<pre><span>&gt;&gt;&gt; </span><span>a</span> <span>=</span> <span>Vector4</span><span>(</span><span>1.5</span><span>,</span> <span>0.3</span><span>,</span> <span>-</span><span>1.0</span><span>,</span> <span>1.0</span><span>)</span>
<span>&gt;&gt;&gt; </span><span>b</span> <span>=</span> <span>Vector4</span><span>(</span><span>7.2</span><span>,</span> <span>2.3</span><span>,</span> <span>1.1</span><span>,</span> <span>0.0</span><span>)</span>
<span>&gt;&gt;&gt; </span><span>a</span><span>.</span><span>wxy</span> <span>=</span> <span>b</span><span>.</span><span>xwz</span>
<span>&gt;&gt;&gt; </span><span>a</span>
<span>Vector(0, 1.1, -1, 7.2)</span></pre>
<p>If you ev­er used GLSL or any oth­er shad­er lan­guage, you prob­a­bly fell in love
with vec­tor swiz­zles right at the mo­ment you saw them … and then be­came sad
af­ter a re­al­iza­tion that such APIs are <em>prac­ti­cal­ly im­pos­si­ble</em><a href="#id5" id="id3">2</a> to have
in C++. Swiz­zle op­er­a­tions are nev­er­the­less use­ful and as­sign­ing each com­po­nent
sep­a­rate­ly would be a pain, so Mag­num pro­vides <a href="https://doc.magnum.graphics/magnum/namespaceMagnum_1_1Math.html#aeda0faa04b927f5c7aa2bbc3a8794d7d">Math::gath­er()</a> and
<a href="https://doc.magnum.graphics/magnum/namespaceMagnum_1_1Math.html#a04d57d5b0e229035590046fed3496502">Math::scat­ter()</a> that al­low you to ex­press the above:</p>
<pre><span>a</span> <span>=</span> <span>Math</span><span>::</span><span>scatter</span><span>&lt;</span><span>'w'</span><span>,</span> <span>'x'</span><span>,</span> <span>'y'</span><span>&gt;</span><span>(</span><span>a</span><span>,</span> <span>Math</span><span>::</span><span>gather</span><span>&lt;</span><span>'x'</span><span>,</span> <span>'w'</span><span>,</span> <span>'z'</span><span>&gt;</span><span>(</span><span>b</span><span>));</span></pre>
<p>Ver­bose<a href="#id7" id="id4">3</a> but <em>prac­ti­cal­ly</em> pos­si­ble. Point is, how­ev­er, that the above is
im­ple­mentable very eas­i­ly in Python us­ing <code><span>__getattr__</span><span>()</span></code> and
<code><span>__setattr__</span><span>()</span></code> … and a ton of er­ror check­ing on top.</p>
<dl>
<dt id="id5">2.</dt>
<dd><span><a href="#id3">^</a></span> GLM <em>does have</em> those, if you en­able <code><span>GLM_FORCE_SWIZZLE</span></code>, but do­ing
so adds <em>three sec­onds</em><a href="#id8" id="id6">4</a> to com­pi­la­tion time of each file that
in­cludes GLM head­ers. I’d say that makes swiz­zles pos­si­ble <em>in the­o­ry</em> but
such over­head makes them <em>prac­ti­cal­ly</em> use­less.</dd>
<dt id="id7">3.</dt>
<dd><span><a href="#id4">^</a></span> Math func­tions are <em>func­tions</em> and so do not mu­tate their ar­gu­ments,
that’s why the fi­nal self-as­sign­ment. It would of course be bet­ter to be
able to write <code><span>Math</span><span>::</span><span>gather</span><span>&lt;</span><span>"wxy"</span><span>&gt;</span><span>(</span><span>b</span><span>)</span></code> or at least
<code><span>Math</span><span>::</span><span>gather</span><span>&lt;</span><span>'</span><span>wxy</span><span>'</span><span>&gt;</span><span>(</span><span>b</span><span>)</span></code> but C++ <em>in­sists</em> on the first be­ing
im­pos­si­ble and the sec­ond be­ing un­portable. And
<a href="https://github.com/SephDB/constexpr-format">cre­at­ing a us­er-de­fined lit­er­al</a> just to
spec­i­fy a swiz­zle seems ex­ces­sive.</dd>
<dt id="id8">4.</dt>
<dd><span><a href="#id6">^</a></span> I did a cou­ple of bench­marks for a yet-to-be-pub­lished ar­ti­cle com­par­ing
math li­brary im­ple­men­ta­tions, and this was a shock­er. The on­ly oth­er
li­brary that could come close was <a href="https://github.com/boostorg/geometry">Boost.Ge­om­e­try</a>,
with two sec­onds per file.</dd>
</dl>
<section id="but-on-the-contrary-c-has-it-easier-with-overloads">
<h3><a href="#but-on-the-contrary-c-has-it-easier-with-overloads">… but on the con­trary, C++ has it eas­i­er with over­loads</a></h3>
<p>I was very de­light­ed up­on dis­cov­er­ing that py­bind11 sup­ports func­tion over­loads
<em>just like that</em> — if you bind more than one func­tion of the same name, it’ll
take a type­less <code><span>(</span><span>*</span><span>args</span><span>,</span> <span>**</span><span>kwargs</span><span>)</span></code> and dis­patch to a cor­rect over­load
based on ar­gu­ment types. It’s prob­a­bly not blaz­ing­ly fast (and in some cas­es
you could prob­a­bly beat its speed by do­ing the dis­patch you­self), but it’s
there and much bet­ter than hav­ing to in­vent new names for over­load­ed func­tions
(and con­struc­tors!). With the <abbr title="well, relatively">new</abbr> <a href="https://docs.python.org/3/library/typing.html#module-typing">typ­ing</a>
mod­ule, it’s pos­si­ble to achieve a sim­i­lar thing in pure Python us­ing the
<a href="https://docs.python.org/3/library/typing.html#typing.overload">@over­load</a> dec­o­ra­tor — though on­ly for doc­u­men­ta­tion
pur­pos­es, you’re still re­spon­si­ble to im­ple­ment the type dis­patch your­self. In
case of <a href="https://doc.magnum.graphics/python/magnum/math/#dot">math.dot()</a> im­ple­ment­ed in pure Python, this could look like
this:</p>
<pre><span>@overload</span>
<span>def</span> <span>dot</span><span>(</span><span>a</span><span>:</span> <span>Quaternion</span><span>,</span> <span>b</span><span>:</span> <span>Quaternion</span><span>)</span> <span>-&gt;</span> <span>float</span><span>:</span>
    <span>...</span>
<span>@overload</span>
<span>def</span> <span>dot</span><span>(</span><span>a</span><span>:</span> <span>Vector2</span><span>,</span> <span>b</span><span>:</span> <span>Vector2</span><span>)</span> <span>-&gt;</span> <span>float</span><span>:</span>
    <span>...</span>
<span>def</span> <span>dot</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>):</span>
    <span># actual implementation</span></pre>
<p>What was ac­tu­al­ly <em>hard</em> though, was the fol­low­ing, look­ing com­plete­ly or­di­nary
to a C++ pro­gram­mer:</p>
<figure>
<pre><span>&gt;&gt;&gt; </span><span>a</span> <span>=</span> <span>Matrix3</span><span>.</span><span>translation</span><span>((</span><span>4.0</span><span>,</span> <span>2.0</span><span>))</span>
<span>&gt;&gt;&gt; </span><span>a</span>
<span>Matrix(1, 0, 4,</span>
<span>       0, 1, 2,</span>
<span>       0, 0, 1)</span>
<span>&gt;&gt;&gt; </span><span>a</span><span>.</span><span>translation</span> <span>=</span> <span>Vector2</span><span>(</span><span>5.0</span><span>,</span> <span>3.0</span><span>)</span>
<span>&gt;&gt;&gt; </span><span>a</span>
<span>Matrix(1, 0, 5,</span>
<span>       0, 1, 3,</span>
<span>       0, 0, 1)</span></pre>
<p>Is the Python lan­guage po­lice go­ing to ar­rest me now?</p>
</figure>
<p>While the case of <a href="https://doc.magnum.graphics/python/magnum/Matrix3/#scaling-da39a">Ma­trix3.scal­ing()</a> vs. <code><span>mat</span><span>.</span><span>scaling</span><span>()</span></code> — where
the for­mer re­turns a scal­ing <a href="https://doc.magnum.graphics/python/magnum/Matrix3/">Ma­trix3</a> and lat­ter a scal­ing <a href="https://doc.magnum.graphics/python/magnum/Vector3/">Vec­tor3</a>
out of a scal­ing ma­trix — was eas­i­er and could be done just via a dis­patch
based on ar­gu­ment types (“if the first ar­gu­ment is an in­stance of <a href="https://doc.magnum.graphics/python/magnum/Matrix3/">Ma­trix3</a>,
be­have like the mem­ber func­tion”), in case of <a href="https://doc.magnum.graphics/python/magnum/Matrix3/#translation">Ma­trix3.trans­la­tion()</a> it’s
ei­ther a stat­ic method or an in­stance <em>prop­er­ty</em>. Ul­ti­mate­ly I man­aged to solve
it by sup­ply­ing a cus­tom meta­class that does a cor­rect dis­patch when
en­coun­ter­ing ac­cess to the <code>translation</code> at­tribute.</p>
<p>But yeah, while al­most any­thing is pos­si­ble in Python, it could give a hand
here — am I the first per­son ev­er that needs this func­tion­al­i­ty?</p>
</section>
</section>
<section id="zero-copy-data-transfer">
<h2><a href="#zero-copy-data-transfer">Ze­ro-copy da­ta trans­fer</a></h2>
<p>One very im­por­tant part of Python is the <a href="https://docs.python.org/3/c-api/buffer.html">Buf­fer Pro­to­col</a>.
It al­lows ze­ro-copy shar­ing of ar­bi­trati­ly shaped da­ta be­tween C and Python —
sim­ple tight­ly-packed lin­ear ar­rays, 2D ma­tri­ces, or a green chan­nel of a low­er
right quar­ter of an im­age flipped up­side down. Hav­ing a full sup­port for the
buf­fer pro­to­col was among the rea­sony why <a href="https://doc.magnum.graphics/corrade/classCorrade_1_1Containers_1_1StridedArrayView.html">Con­tain­ers:…</a></p></section></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.magnum.graphics/announcements/introducing-python-bindings/">https://blog.magnum.graphics/announcements/introducing-python-bindings/</a></em></p>]]>
            </description>
            <link>https://blog.magnum.graphics/announcements/introducing-python-bindings/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24631106</guid>
            <pubDate>Tue, 29 Sep 2020 18:11:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Recurrent neural networks: building a custom LSTM cell]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24631016">thread link</a>) | @sergioskar
<br/>
September 29, 2020 | https://theaisummer.com/understanding-lstm/ | <a href="https://web.archive.org/web/*/https://theaisummer.com/understanding-lstm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                            
                            

<p>An infinite amount of times I have found myself in desperate situations because I had no idea what was happening under the hood. And, for a lot of people in the computer vision community, recurrent neural networks (RNNs) are like this. More or less, <strong>another black box in the pile</strong>.</p>

<p>However, in this tutorial, we will attempt to open the RNN magic black box and unravel its mysteries!</p>

<p>Even though I have come across hundreds of tutorials on LSTM’s out there, I felt there was something missing. Therefore, I honestly hope that <strong>this tutorial serves as a modern guide to RNNs</strong>. We try to deal with multiple details of practical nature. To this end, we <strong>will build upon their fundamental concepts.</strong></p>

<p>The vast application field of RNN’s includes <a href="https://theaisummer.com/Bitcon_prediction_LSTM/" target="_blank">sequence prediction</a>, activity recognition, video classification as well as a variety of natural language processing tasks. After a careful inspection of the equations, <strong>we will build our own LSTM cell to validate our understanding</strong>. Finally, we will make some associations with convolutional neural networks to maximize our comprehension. Accompanying code for this tutorial can be found <a href="https://drive.google.com/file/u/0/d/1Rb8OiF-AZ_Y3uFj1O2S0IyocFMhHoTCV/edit" rel="noopener" target="_blank">here</a>.</p>

<p>It is true that by the moment you start to read about RNN’s, especially with a computer vision background, concepts misleadings start to arise. Less literally:</p>

<p>“Backpropagation with stochastic gradient descent (SGD) does not magically make your network work. Batch normalization does not magically make it converge faster. <strong>Recurrent Neural Networks (RNNs) don’t magically let you “plug in” sequences</strong>. (…) If you insist on using the technology without understanding how it works you are likely to fail.” ~ <strong><a href="https://twitter.com/karpathy" rel="noopener" target="_blank">Andrey Karpathy</a></strong> (Director of AI at Tesla)</p>

<p>The abstraction of RNN’s implementations doesn’t allow users to understand how we deal with the time dimension in sequences! However, by understanding how it works you can write optimized code and practice extensibility, in a way that you weren’t confident enough to do before.</p>

<p>Finally, a more holistic approach in RNN’s can be found on <a href="https://click.linksynergy.com/deeplink?id=r24KwW5qbBo&amp;mid=40328&amp;murl=https%3A%2F%2Fwww.coursera.org%2Flearn%2Fnlp-sequence-models" rel="noopener" target="_blank">Sequence models from the Deep Learning specialization course</a> offered by Coursera.</p>

<h3 id="contents">Contents</h3>
<ul id="markdown-toc">
  <li><a href="#a-simple-rnn-cell" id="markdown-toc-a-simple-rnn-cell">A simple RNN cell</a></li>
  <li><a href="#what-is-back-propagation-through-time" id="markdown-toc-what-is-back-propagation-through-time">What is Back-propagation through time?</a></li>
  <li><a href="#lstm-long-short-term-memory-cells" id="markdown-toc-lstm-long-short-term-memory-cells">LSTM: Long-short term memory cells</a></li>
  <li><a href="#writing-a-custom-lstm-cell-in-pytorch" id="markdown-toc-writing-a-custom-lstm-cell-in-pytorch">Writing a custom LSTM cell in Pytorch</a></li>
  <li><a href="#connecting-lstm-cells-across-time-and-space" id="markdown-toc-connecting-lstm-cells-across-time-and-space">Connecting LSTM cells across time and space</a></li>
  <li><a href="#validation-learning-a-sine-wave-with-an-lstm" id="markdown-toc-validation-learning-a-sine-wave-with-an-lstm">Validation: Learning a sine wave with an LSTM</a></li>
  <li><a href="#bidirectional-lstm-and-its-pytorch-documentation" id="markdown-toc-bidirectional-lstm-and-its-pytorch-documentation">Bidirectional LSTM and it’s Pytorch documentation</a></li>
  <li><a href="#input-to-output-mappings-with-recurrent-models" id="markdown-toc-input-to-output-mappings-with-recurrent-models">Input to output mappings with recurrent models</a></li>
  <li><a href="#the-theoretical-limit-of-modeling-a-large-dimension-recurrency-vs-convolution" id="markdown-toc-the-theoretical-limit-of-modeling-a-large-dimension-recurrency-vs-convolution">The theoretical limit of modeling a large dimension: Recurrency VS Convolution</a></li>
  <li><a href="#discussion-and-conclusion" id="markdown-toc-discussion-and-conclusion">Discussion and conclusion</a></li>
</ul>

<h2 id="a-simple-rnn-cell">A simple RNN cell</h2>

<p>Recurrent cells are neural networks (usually small) for processing <strong>sequential data</strong>. As we already know, convolutional layers are specialized for processing grid-structured values (i.e. images). On the contrary, <strong>recurrent layers are designed for processing long sequences</strong>, without any extra sequence-based design choice [1].</p>

<p>One can achieve this by connecting the timesteps’ output to the input! This is called sequence <strong>unrolling.</strong> By processing the whole sequence, we have an algorithm that takes into account the previous states of the sequence. In this manner, we have the <strong>first notion of memory</strong> (a cell)! Let’s look at it:</p>

<p><img src="https://theaisummer.com/assets/img/posts/understanding-lstm/rnn-cell-time-unfold.png" alt="rnn-cell-time-unfold">
<em>Visualization is borrowed from <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network" rel="noopener" target="_blank">Wiki</a></em></p>

<p>The majority of common recurrent cells can also process sequences of variable length. This is really important for many applications such as videos, that contain a different number of images. One can view the RNN cell as a common <strong>neural network with</strong> <strong>shared weights for the multiple timesteps.</strong> With this modification, the weights of the cell now have access to the previous states of the sequence.</p>

<p>But <strong>how</strong> can we possibly train such sequential models?</p>

<h2 id="what-is-back-propagation-through-time">What is Back-propagation through time?</h2>

<p>Most practitioners with computer vision background have little idea of what recurrency means. And it is indeed difficult to understand. Because the frameworks assume that you already know how it works. However, if you want to find an efficient solution to your problem, you should carefully design your architecture based on the problem.</p>

<p><strong>The magic of RNN networks that nobody sees is the input unrolling</strong>. The latter means that given a sequence of length N, you process the input into timesteps.</p>

<blockquote>
  <p>We choose to model the time dimension with RNN’s, because we want to learn temporal and often long-term dependencies.</p>
</blockquote>

<p>Right now, it is true that convolutions cannot handle because they have a finite receptive field. Note that, in theory, you can apply a recurrent model in any dimension.</p>

<p>In terms of training an RNN model, the issue is that now we have a time-sequence. That’s why input unrolling is the only way we can make backpropagation work!</p>

<p>So, how can you learn a time-sequence? Ideally, we would like the memory (parameters) of the cells to have taken into account all the input sequences. Otherwise, we would not be able to learn the desired mapping. In essence, <strong>backpropagation requires a separate layer for each time step with the same weights for all layers</strong> (<strong>input unrolling)</strong>! The following image helps to understand this tricky idea.</p>

<p><img src="https://theaisummer.com/assets/img/posts/understanding-lstm/input-unrolling-and-backpropagation-through-time.png" alt="input-unrolling-and-backpropagation-through-time">
<em>Source: O’Reilly: hands-on-reinforcement-learning](Source: O’Reilly: hands-on-reinforcement-learning)</em></p>

<p>Backpropagation through time was created based on the pre-described observation. So, <strong>based on the chunked (unrolled) input, we can calculate a different loss per timestep</strong>. Then, we can backpropagate the error of multiple losses to the memory cells. In this direction, <strong>one can compute the gradients from multiple paths (timesteps) that then are added to calculate the final gradient</strong>. For this reason, we may use different optimizers or normalization methods in recurrent architectures.</p>

<p>In other words, we represent the RNN as a repeated (feedforward) network. More importantly, <strong>the time and space complexity to produce the output of the RNN is asymptotically linear to the input length (timesteps)</strong>. This practical bottleneck introduces the computational limit of training really large sequences.</p>

<p>In fact, a similar idea is implemented in practice when you have a small GPU and you want to train your model with a bigger batch size than your memory supports. You perform forward propagation with the first batch and calculate the loss. Afterwards, you repeat the same thing with the second batch and average the losses from different batches. In this way, gradients are <strong><a href="https://www.quora.com/What-does-it-mean-that-gradients-are-accumulated-in-Pytorch-and-what-is-the-use-for-it" rel="noopener" target="_blank">accumulated</a>.</strong> With this trick of the low budget machine learners, you basically perform a similar operation to backpropagation through time. Finally,<a href="https://www.youtube.com/watch?v=6jfw8MuKwpI" rel="noopener" target="_blank"> siamese networks</a> with shared weights also roughly exploit this concept.</p>

<p>Let’s now see the inside of an LSTM [5] cell.</p>

<h2 id="lstm-long-short-term-memory-cells">LSTM: Long-short term memory cells</h2>

<h3 id="why-lstm">Why LSTM?</h3>

<p>One of the most fundamental works in the field was by <a href="https://arxiv.org/abs/1503.04069" rel="noopener" target="_blank">Greff et al. 2016</a> [4]. Briefly, they showed that <strong>the proposed variations of RNN do not provide any significant improvement in a large scale study compared to LSTM</strong>. Therefore, LSTM is the dominant architecture in RNNs. That’s why we will focus on this RNN variation.</p>

<h3 id="how-lstm-works">How LSTM works?</h3>

<p>We can write forever about what an LSTM cell is, or how it is used in many applications. However, the language of mathematics makes this world beautiful and compact for us. Let’s see the math. Don’t be scared! <strong>We will slowly clarify every term, by inspecting every equation separately</strong>.</p>

<blockquote>
  <p>Before we begin, note that in all the equations, the weight matrices (W) are indexed, with the <strong>first index being the vector that they process</strong>, while the <strong>second index refers to the representation</strong> (i.e. input gate, forget gate).</p>
</blockquote>

<p>To avoid confusion and maximize understanding, we will use the common notation: <strong>matrices are depicted with capital bold letters while vectors with non-capital bold letters</strong>. For the element-wise multiplication, I used the dot with the outer circle symbol, referred to as the <a href="https://en.wikipedia.org/wiki/Hadamard_product_(matrices)" rel="noopener" target="_blank">Hadamard product</a> [9] in the bibliography.</p>

<h3 id="equations-of-the-lstm-cell">Equations of the LSTM cell</h3>

<p>For \(\textbf{x}_t \in R^{N}\) , where N is the feature length of each timestep, while \(\textbf{i}_t,\textbf{f}_t,\textbf{o}_t,\textbf{h}_t,\textbf{h}_{t-1},\textbf{c}_t,\textbf{c}_{t-1},\textbf{b}  \in R^{H}\) , where H is the hidden state dimension, the LSTM equations are the following:</p><p>

\[\textbf{i}_t = \sigma( \textbf{W}_{xi} \textbf{x}_t + \textbf{W}_{hi} \textbf{h}_{t-1} + \textbf{W}_{ci} \textbf{c}_{t-1} + \textbf{b}_i)  \quad\quad(1)\]

\[\textbf{f}_t = \sigma( \textbf{W}_{xf} \textbf{x}_t + \textbf{W}_{hf} \textbf{h}_{t-1} + \textbf{W}_{cf} \textbf{c}_{t-1} + \textbf{b}_f) \quad\quad(2)\]

\[\textbf{c}_t = \textbf{f}_t \odot \textbf{c}_{t-1} + \textbf{i}_t \odot tanh( \textbf{W}_{xc} x_t + \textbf{W}_{hc} \textbf{h}_{t-1} + \textbf{b}_c ) \quad\quad(3)\]

\[\textbf{o}_t = \sigma( \textbf{W}_{xo} \textbf{x}_t + \textbf{W}_{h0} \textbf{h}_{t-1} + \textbf{W}_{co} \textbf{c}_{t} + \textbf{b}_o)  \quad\quad(4)\]

\[\textbf{h}_t = \textbf{o}_t \odot tanh(\textbf{c}_t) \quad\quad(5)\]

</p><p>The LSTM cell equations were written based on <a href="https://pytorch.org/docs/stable/nn.html?highlight=lstm#torch.nn.LSTM" rel="noopener" target="_blank">Pytorch documentation</a> because you will probably use the existing layer in your project. In the original paper, \(\textbf{c}_{t-1}\)  is included in the Equation (1) and (2), but you can omit it. For consistency reasons with the Pytorch docs, I will not include these computations in the code. For the record, these kind of connections are called peephole connection in the literature.</p>

<h3 id="equation-1-the-input-gate">Equation 1: the input gate</h3><p>

\[\textbf{i}_t = \sigma( \textbf{W}_{xi} \textbf{x}_t + \textbf{W}_{hi} \textbf{h}_{t-1} + \textbf{W}_{ci} \textbf{c}_{t-1} + \textbf{b}_i)\]

</p><p>The depicted <strong>weight matrices represent the memory of the cell</strong>. You see the input \(\textbf{x}_t\) is in the current input timestep, <strong>while h and c are indexed with the previous timestep</strong>. Every matrix <strong>W</strong> is a linear layer (or simply a matrix multiplication). This equation enables us to the following:</p>

<p>a) take multiple linear combinations of <strong>x</strong>,<strong>h</strong>,<strong>c</strong>, and</p>

<p>b) match the dimensionality of input <strong>x</strong> to the one of <strong>h</strong> and <strong>c</strong>.</p>

<p>The dimensionalities of <strong>h</strong> and <strong>c</strong> are basically the <strong>hidden states</strong> …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://theaisummer.com/understanding-lstm/">https://theaisummer.com/understanding-lstm/</a></em></p>]]>
            </description>
            <link>https://theaisummer.com/understanding-lstm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24631016</guid>
            <pubDate>Tue, 29 Sep 2020 18:03:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[He Social Dilemma Is a Great Conversation Starter but What Does the Science Say?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24630893">thread link</a>) | @laurex
<br/>
September 29, 2020 | https://www.psychoftech.org/blog/2020/9/28/the-social-dilemma-is-a-great-conversation-starter-but-what-does-the-science-say | <a href="https://web.archive.org/web/*/https://www.psychoftech.org/blog/2020/9/28/the-social-dilemma-is-a-great-conversation-starter-but-what-does-the-science-say">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-3d2d994e3c2ce78e7eaa"><div><p>Despite the occasional dash of <a href="https://ourworldindata.org/"><span>statistical optimism</span></a>, it’s difficult to escape the sense that things — broadly considered — are not going well. The pandemic wears on. Protesters fill the streets. The election is imperiled. Wherever one looks, the world (or at least the United States) appears to be on a downward slide. It is tempting, amid this plethora of apparent problems, to seek out a root cause. <a href="https://www.netflix.com/browse?jbv=81254224"><span><em>The Social Dilemma</em></span></a>, a new documentary from Netflix, makes the case for a potential culprit: social media, the business models that drive it, and the misaligned incentives that inevitably result.</p><p>As an activist call-to-arms, the film is chilling and effective. Using a mix of interviews and dramatizations, director Jeff Orlowski depicts and describes all the headline issues: addiction, distraction, depression, anxiety, social comparison, echo chambers, polarization, radicalization, misinformation, and conspiracy theory. Readers acquainted with the <a href="https://www.humanetech.com/"><span>Center for Humane Technology</span></a> will recognize many familiar faces and arguments. Tristan Harris, the Center’s founder, headlines a long list of technology insiders explaining how they’ve come to view the products they built as destructive.</p><p>Harris <a href="https://samharris.org/podcasts/218-welcome-cult-factory/"><span>has stated</span></a> that one of his great hopes is that, in a world where shared realities have broken down, this film will at least provide “a new shared reality <em>about that breakdown of our shared reality</em>.” But as <a href="https://twitter.com/ShuhBillSkee/status/1305805667735830529?s=20"><span>mixed reactions</span></a> to the film attest, building consensus about a topic as complex and controversial as this one is difficult in our day and age. If <em>The Social Dilemma</em> works to stir up a larger public conversation about technology and its damaging effects, we hope that the next phase of that conversation can be informed by the best scientific research. In that spirit, below we address some of the issues raised in the film and what the science has to say about them.</p><h3><strong>Addiction</strong></h3><p>Dr. Anna Lembke, a Stanford psychiatrist and addiction expert, summarizes her view in the film thus: “Social media is a drug.” Depending on who is saying it and what they say afterwards, this statement can mean many things, from the banal claim that “social media can be fun to use” to the preposterous <em>Independent</em> headline, <a href="https://www.independent.co.uk/news/education/education-news/child-smart-phones-cocaine-addiction-expert-mandy-saligari-harley-street-charter-clinic-technology-teenagers-a7777941.html"><span>“Giving your child a smartphone is like giving them a gram of cocaine.”</span></a> Lembke’s view falls somewhere in between: she doesn’t draw any direct comparisons to cocaine, but she warns that social media plays upon our “biological imperative to connect with other people,” which acts through “the release of dopamine in the reward pathway” -- the <a href="https://www.drugabuse.gov/publications/research-reports/cocaine/how-does-cocaine-produce-its-effects"><span>same pathway</span></a> the cocaine acts on.&nbsp;</p><p>Of course, connecting with others in person releases dopamine as well. If social media is an addiction, we have to explain why in terms that go beyond a healthy teenage interest in social life. Psychology of Technology Institute (PTI) advisor Adam Alter is <a href="https://www.youtube.com/watch?v=F3WZv5sv-qI&amp;list=PLhM_FlxNBM3pyKEcnphj1wHO12GR52x3l&amp;index=12"><span>quick to distinguish</span></a> between substance addictions of the kind fostered by drugs and behavioral addictions like gambling. Social media addiction would fall in the latter category. But as he points out in <a href="https://www.youtube.com/watch?v=3-szkJew1j4&amp;list=PLhM_FlxNBM3pyKEcnphj1wHO12GR52x3l&amp;index=13"><span>our interview with him</span></a>, using the term “addiction” too loosely can lead to the conclusion that a compulsive behavior like <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1360-0443.1990.tb01618.x"><span>breathing is an “addiction”</span></a> too. Pathology is the crucial factor here: to claim that social media is addictive in the clinical sense, we have to show that it has harmful effects.</p><p>In the film, Lembke’s commentary is played alongside a dramatization in which a family attempts to impose a no-screens-at-dinner rule. The attempt fails when the younger daughter in the family smashes the time-locked container the phones are being held in with a hammer. In the process, she breaks her older brother’s phone screen, leading to a deal: if the son can abstain from using his phone for a week, the mother agrees to buy him a new screen.&nbsp;</p><p>Here, the filmmakers make an important point. The powerful algorithms and engagement teams behind social media platforms are personified in the film by a three-person team (all played by Vincent Kartheiser) in a control room. When the son begins his week of abstinence, the team springs into action, sending him a notification that his crush has begun dating another guy. The fact that these dramas of teenage life are now frequently mediated by third parties with independent interests (even if those third parties are faceless algorithms) should give all of us cause for concern. Plausibly, the sight of the notification leads the son to forfeit the deal and check his phone, only to be thrown into a depressive scrolling stupor by the news.&nbsp;</p><p>But the film’s dramatic strategies raise some questions as well. The negative effect on the son’s mood is determined by the bad news in his social life, not by social media alone. Whereas a night of binge-drinking might have negative effects independent of what spurred it, social media platforms are hard to distinguish from the content -- good and bad -- that they host. To avoid a <a href="https://journals.sagepub.com/doi/full/10.1177/1745691620919372"><span>moral panic</span></a> borne of careless cocaine analogies, we have to be clear about the precise conditions and mechanisms that lead social media to be harmful, when in fact it is.</p><h3><strong>Wellbeing</strong></h3><p>Ben, the son in the film, begins a steady descent soon after his night of scrolling. He begins losing sleep and cutting sports practices to stare into his phone. This downward slide is presented as all but inexorable, as the three men in the control room guide Ben’s every choice. <a href="https://www.youtube.com/watch?v=YSV8GT7y3_E">The reality is more complicated</a>. A <a href="https://www.psychologytoday.com/us/blog/brain-waves/201905/worry-over-social-media-use-and-well-being-may-be-misplaced"><span>large meta-analysis</span></a> of social media’s impact on wellbeing by PTI advisor Jeff Hancock revealed little to no effect. <a href="https://www.pnas.org/content/pnas/116/21/10226.full.pdf"><span>Other studies</span></a> have shown that social media’s negative impact on teens in particular is gender-specific (it is more harmful for girls), and dependent on excessive use. A growing consensus suggests a <a href="https://journals.sagepub.com/doi/10.1177/0956797616678438"><span>“goldilocks effect”</span></a>: both too little use of social media and too much are associated with reduced wellbeing, while moderate use can have beneficial effects.</p><p>This shouldn’t be cause for complacency; after all, social media companies do not have any concept of “too much use.” From their point of view, the more we use their services, the better. As Harris points out in the film, we have regulations to prevent energy companies from profiting from our excessive use. To the extent that social media companies have a similar perverse incentive, regulation may be in order.&nbsp;</p><p>But just as “screen-time” is too imprecise a metric to be useful, different types and uses of social media can have very different effects. This shouldn’t be surprising: three hours spent messaging with the love of one’s life over Facebook Messenger likely has more salutary effects on wellbeing than even 15 minutes of indulging in political outrage. <a href="https://www.researchgate.net/publication/283283846_It's_Complicated_Facebook's_Relationship_with_the_Need_to_Belong_and_Depression"><span>Some research</span></a> has borne this out, but much more will be needed if we want to approach regulation responsibly.&nbsp;</p><h3><strong>Echo Chambers</strong></h3><p>Ben’s woes take a dystopian turn when he gets sucked into the rabbithole of an unspecified conspiracy and becomes radicalized by the “extreme center.” His sister’s efforts to dissuade him fall on deaf ears, and soon his whole world becomes enveloped by propagandists telling him not to trust the system. If <em>The Social Dilemma</em> has a primary thesis, it’s that the information siloing that leads to Ben’s radicalization is unsustainable for democracy. Ben’s case, which has many <a href="https://www.theatlantic.com/ideas/archive/2020/05/shadowland-introduction/610840/"><span>depressing real-life analogues</span></a>, is portrayed as an extreme version of what has happened to all of us: recommendation algorithms create echo chambers that erode our shared reality and turn us against one another.</p><p>In the popular imagination, echo chambers act as <a href="https://www.youtube.com/watch?v=VAGnAl9s6OA&amp;list=PLhM_FlxNBM3rzVC0v6ih9P8vSS-tvXxdE&amp;index=7"><span>hermetically sealed</span></a> ideological bubbles that prevent exposure to the other side. On this account, polarization and radicalization occur because we simply don’t know the other side’s positions. In the case of the political left and right, this is <a href="https://5harad.com/papers/bubbles.pdf"><span>not generally true</span></a>. Most politically engaged people <em>do</em> get exposed to the other side; it’s just that this exposure happens in a context that incentivizes <a href="https://static1.squarespace.com/static/538ca3ade4b090f9ef331978/t/5a53c0d49140b7212c35b20e/1515438295247/Crockett_2017_NHB_Outrage.pdf"><span>outrage</span></a> and moral grandstanding rather than mutual understanding. In fact, <a href="https://www.pnas.org/content/115/37/9216"><span>a 2018 study</span></a> showed that more exposure to opposing views online actually <em>increases</em> polarization.</p><p>As we wrote in a prior newsletter, the philosopher C. Thi Nguyen <a href="https://www.cambridge.org/core/journals/episteme/article/echo-chambers-and-epistemic-bubbles/5D4AC3A808C538E17C50A7C09EC706F0"><span>introduces some helpful distinctions here</span></a>. Nguyen distinguishes <em>epistemic bubbles</em> from <em>echo chambers</em>. The former function by excluding opposing views; the latter actively discredit opposing views in advance. Nguyen calls this discrediting “evidential pre-emption.” Because opposing evidence is preemptively dismissed as untrustworthy, echo chambers survive and even strengthen in the face of counter-arguments. This makes them exceedingly difficult to combat. Evidential pre-emption can be seen everywhere from cults to partisan cable news.</p><p>As portrayed in the film, this process interacts in an especially pernicious way with recommendation algorithms. These algorithms do not have infinite capacities; rather, they excel at identifying particular rabbit holes to which they can then pattern-match our interests. As PTI advisor Stuart Russell points out in <a href="https://www.youtube.com/watch?index=3&amp;list=PLhM_FlxNBM3qcXMiZcTxdsFParh_6viiF&amp;v=80M9q1tWN1o"><span>our interview with him</span></a>, one way for a recommendation algorithm to meet its objective of predicting your interests is to <em>make your interests more predictable</em>. And since a political ideologue will be much easier for a recommendation algorithm to satisfy than someone with nuanced views, these algorithms tend to serve us information that makes us more partisan.</p><h3><strong>Polarization</strong></h3><p>As Harris explains in <a href="https://samharris.org/podcasts/218-welcome-cult-factory/"><span>an interview on the Making Sense podcast</span></a>, “we’re about ten years into this mass psychology experiment…[and] actually all of us are kind of running malware and bad code. It’s not just that the other side is wrong; it’s that all of us have been living in such narrow views of reality that we can no longer empathize with each other.” The tricky thing about addressing polarization in a polarized world is that we all tend to see the other side as the problem. Though we can observe the <a href="https://www.pewresearch.org/politics/interactives/political-polarization-1994-2017/"><span>trend of overall polarization</span></a> over time, this does little to moderate our views. Your echo chamber is my oasis of truth …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.psychoftech.org/blog/2020/9/28/the-social-dilemma-is-a-great-conversation-starter-but-what-does-the-science-say">https://www.psychoftech.org/blog/2020/9/28/the-social-dilemma-is-a-great-conversation-starter-but-what-does-the-science-say</a></em></p>]]>
            </description>
            <link>https://www.psychoftech.org/blog/2020/9/28/the-social-dilemma-is-a-great-conversation-starter-but-what-does-the-science-say</link>
            <guid isPermaLink="false">hacker-news-small-sites-24630893</guid>
            <pubDate>Tue, 29 Sep 2020 17:54:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A gentle intro to Laplace transform]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24630882">thread link</a>) | @R3G1R
<br/>
September 29, 2020 | https://mathvault.ca/laplace-transform/ | <a href="https://web.archive.org/web/*/https://mathvault.ca/laplace-transform/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><div><div id="theme-content-section"><div><section data-css="tve-u-16ec5d248bb"><p>Let us take a moment to ponder how truly bizarre the <strong><a href="https://mathvault.ca/hub/higher-math/math-symbols/calculus-analysis-symbols/#Key_Transforms" target="_blank" aria-label="Laplace transform (opens in a new tab)" rel="noreferrer noopener">Laplace transform</a></strong> is.</p><p>You put in a sine and get an oddly simple, <strong>arbitrary-looking fraction</strong>. Why do we suddenly have squares?</p><p>You look at the table of <strong>common Laplace transforms</strong> to find a pattern and you see no rhyme, no reason, no obvious link between different functions and their different, very different, results.</p><p>What’s going on here?</p><p>Or so we thought when we first encountered the cursive $\mathcal{L}$ in school.</p><div><figure><img loading="lazy" width="888" height="367" src="https://mathvault.ca/wp-content/uploads/Laplace-Transform.png" alt="Laplace transform of function f" title="Laplace Transform"></figure></div><h2><span id="What_does_the_Laplace_transform_do,_really"></span><a href="#toc">What does the Laplace transform do, really?</a><span></span></h2><p>At a high level, Laplace transform is an <strong><a aria-label="integral transform (opens in a new tab)" href="https://en.wikipedia.org/wiki/Integral_transform#:~:text=In%20mathematics%2C%20an%20integral%20transform,in%20the%20original%20function%20space." target="_blank" rel="noreferrer noopener">integral transform</a></strong> mostly encountered in differential equations — in electrical engineering for instance — where electric circuits are represented as differential equations.</p><p>In fact, it takes a <strong>time-domain function</strong>, where $t$ is the variable, and outputs a <strong>frequency-domain function</strong>, where $s$ is the variable. Definition-wise, Laplace transform takes a function of real variable $f(t)$ (defined for all $t \ge 0$) to a function of complex variable $F(s)$ as follows:</p>\[\mathcal{L}\{f(t)\} = \int_0^{\infty} f(t) e^{-st} \, dt = F(s) \]<h2><span id="Some_Preliminary_Examples"></span><a href="#toc">Some Preliminary Examples</a><span></span></h2><p>What fate awaits <strong>simple functions</strong> as they enter the Laplace transform?</p><p>Take the simplest function: the <strong>constant function</strong> $f(t)=1$. In this case, putting $1$ in the transform yields $1/s$, which means that we went from a constant to a variable-dependent function.</p><iframe src="https://www.youtube.com/embed/OiNh2DswFt4?start=174" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><p>(Odd but not too worrying. After all, we’ve seen $1/x$ integrating to $\ln x$ in calculus. Not a constant-to-variable situation of course, but an unexpected transformation nonetheless.)</p><p>Let us take it up a notch, with the <strong>linear function</strong> $f(t) = t$. After the transformation, it is turned into $1/s^2$, which means that we went from $1 \to 1/s$ to $t \to 1/s^2$. A pattern begins to emerge.</p><p>Now what about $f(t)=t^n$? With this simple <strong>power function</strong>, we end up with: \[ \mathcal{L}\{ t^n \} = \frac{n!}{s^{n+1}}\] So there was a factorial in $\mathcal{L}\{t\}$ all along, hidden by the fact that $1! = 1$. What else is the transform hiding?</p><p>Here, a glance at a table of <strong><a aria-label="common Laplace transforms (opens in a new tab)" rel="noreferrer noopener" href="https://tutorial.math.lamar.edu/pdf/Laplace_Table.pdf" target="_blank">common Laplace transforms</a></strong> would show that the emerging pattern cannot explain other functions easily. Things get weird, and the weirdness escalates quickly — which brings us back to the sine function.</p><h2><span id="Looking_Inside_the_Laplace_Transform_of_Sine"></span><a href="#toc">Looking Inside the Laplace Transform of Sine</a><span></span></h2><p>Let us unpack what happens to our sine function as we Laplace-transform it. We begin by noticing that a sine function can be expressed as a <strong>complex exponential</strong> — an indirect result of the celebrated <a href="https://mathvault.ca/euler-formula/" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener">Euler’s formula</a>:\[e^{it} = \cos t + i \sin t\]In fact, a sine is often expressed in terms of exponentials for <strong>ease of calculation</strong>, so if we apply that to the function $f(t) = \sin (at)$, we would get: \[ \sin(at) = \frac{e^{iat}-e^{-iat}}{2i} \]Thus the <strong>Laplace transform</strong> of $\sin(at)$ then becomes:<br>\[ \mathcal{L}\{\sin(at)\} = \frac{1}{2i} \int\limits_0^{\infty} (e^{iat}-e^{-iat}) e^{-st} \, dt \]which means that we have a <strong>product of exponentials</strong>. Distributing the terms, we get:<br>\[ \mathcal{L}\{\sin(at)\} = \frac{1}{2i} \int\limits_0^{\infty} e^{iat-st}-e^{-iat-st} \, dt \]</p><p>Here, <strong>factoring</strong> the $t$ in the exponents yields:<br>\[ \mathcal{L}\{\sin(at)\} = \frac{1}{2i} \int\limits_0^{\infty} e^{(ia-s)t}-e^{(-ia-s)t} \, dt \]and since $\mathrm{Re}(s) \gt 0$ by assumption, we can proceed with the integration from $0$ to $\infty$ as usual:<br>\[ \mathcal{L}\{\sin(at)\} = \left.\frac{e^{(ia-s)t}}{2i (ia-s)}\right|_0^{\infty}-\left.\frac{e^{(-ia-s)t}}{2i (-ia-s)}\right|_0^{\infty} \]</p><p>Let us simplify further. <strong>Distributing</strong> the $i$ inside the parentheses, we get:<br>\[ \mathcal{L}\{\sin(at)\} = \left.\frac{e^{(ia-s)t}}{2(-a-is)}\right|_0^{\infty}-\left.\frac{e^{(-ia-s)t}}{2(a-is)}\right|_0^{\infty} \]By evaluating the $t$ at the <strong>boundaries</strong>, we get:<br>\[ \mathcal{L}\{\sin(at)\} = \left( \frac{e^{(ia-s) \cdot \infty}}{2(-a-is)}-\frac{e^{(ia-s) \cdot 0}}{2 (-a-is)}\right)-\left(\frac{e^{(-ia-s)\cdot\infty}}{2(a-is)}-\frac{e^{(-ia-s)\cdot 0}}{2(a-is)}\right) \]And because $\mathrm{Re}(s) &gt; 0$ by assumption, both $e^{(ia-s) \cdot \infty}$ and $e^{(-ia-s)\cdot\infty}$ oscillate to $0$ (i.e., <strong><a aria-label="vanish at infinity (opens in a new tab)" rel="noreferrer noopener" href="https://mathvault.ca/math-glossary/#vanish" target="_blank">vanish at infinity</a></strong>), after which we are then left with:\[ \mathcal{L}\{\sin(at)\} = \frac{1}{-2(-a-is)} + \frac{1}{2(a-is)} \]Once there, merging the <strong>fractions</strong> together would yield:\begin{align*} \mathcal{L}\{\sin(at)\} &amp; = \frac{2(a-is)-2(-a-is)}{-4 (a-is)(-a-is)} \\ &amp; = \frac{2a-2is + 2a+2is}{4 (a^2 + isa-isa + s^2)} \\ &amp; = \frac{4a}{4(a^2 + s^2)} \\ &amp; = \frac{a}{a^2 + s^2} \end{align*}which shows that after Laplace transform, a sine is turned into a more tractable <strong>geometric function</strong>. By following similar reasoning, the Laplace transform of cosine can be shown to be equal to the following expression as well: \[ \mathcal{L}\{\cos (at)\} = \frac{s}{a^2 + s^2} \qquad (\mathrm{Re}(s) &gt; 0) \] But then, one might argue “Why do we need to transform trigonometric functions like this when we can just <strong>integrate</strong> them?”</p><h2><span id="Diverging_Functions_What_the_Laplace_Transform_is_for"></span><a href="#toc">Diverging Functions: What the Laplace Transform is for</a><span></span></h2><p>What if we throw a wrench in there by introducing a <strong>diverging function</strong>, say, $f(t)=e^{at}$? As it turns out, the Laplace transform of the exponential $e^{at}$ is actually deceptively simple: \begin{align*} \mathcal{L}\{e^{at}\} &amp; = \int_0^{\infty} e^{at}e^{-st} \, dt \\ &amp; = \int_0^{\infty} e^{(a-s)t} \, dt \end{align*}Here, we see that so long as $\mathrm{Re}(s) \gt a$, we would get that: \begin{align*} \int_0^{\infty} e^{(a-s)t} \, dt &amp; = \left. \frac{e^{(a-s)t}}{a-s} \right|_0^{\infty} \\ &amp; = 0-\frac{1}{a-s}  \\ &amp; = \frac{1}{s-a} \end{align*} That is, as long as $\mathrm{Re}(s) &gt; a$, the Laplace transform of $e^{at}$ is a simple $1/(s-a)$. Here’s a <strong>video version</strong> of the derivation for the record.</p><iframe src="https://www.youtube.com/embed/33TYoybjqPg?start=50" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><p>On the other hand, if we mix the exponential $e^{at}$ with the <strong>power function</strong> $t^n$, we would then have: \[ \mathcal{L}\{t^n e^{at}\} = \int\limits_0^{\infty} t^n e^{at} e^{-st} \, dt \] which, after a bit of <a aria-label="recursion (opens in a new tab)" href="https://mathvault.ca/math-glossary/#recursion" target="_blank" rel="noreferrer noopener">recursion</a> and <a aria-label="integration by parts (opens in a new tab)" href="https://mathvault.ca/integration-overshooting-method/#Integration_By_Parts" target="_blank" rel="noreferrer noopener">integration by parts</a>, would become:\[ \frac{n!}{(s-a)^{n+1}} \]Here, notice how the transforms of exponential and power function are both <strong>represented</strong> in the expression, with the factorial $n!$, the $1/(s-a)$ fraction, and the $n + 1$ exponent.</p><p>In fact, it turns out that we can integrate <em>any</em> function with the Laplace transform, as long as it does not <strong>diverge</strong> faster than the $e^{at}$ exponential. In the tables of Laplace transforms, you might have noticed the $\mathrm{Re}(s) \gt a$ condition. That is what the condition is alluding to.</p><h2><span id="A_Transform_of_Unfathomable_Power"></span><a href="#toc">A Transform of Unfathomable Power</a><span></span></h2><p>However, what we have seen is only the tip of the iceberg, since we can also use Laplace transform to transform the <strong>derivatives</strong> as well. In goes $f^{(n)}(t)$. Something happens. Then out goes:\[ s^n \mathcal{L}\{f(t)\}-\sum_{r=0}^{n-1} s^{n-1-r} f^{(r)}(0) \]For example, when $n=2$, we have that:\[ \mathcal{L}\{f^{\prime\prime}(t)\} = s^2 \mathcal{L}\{f(t)\}-sf(0)-f'(0) \]In addition to the derivatives, the $\mathcal{L}$ can also process some <strong>integrals</strong>: the integral sine, cosine and exponential, as well as the <a href="https://mathvault.ca/hub/higher-math/math-symbols/probability-statistics-symbols/#Continuous_Probability_Distributions_and_Associated_Functions" target="_blank" aria-label="error function (opens in a new tab)" rel="noreferrer noopener">error function</a> — to name a few.</p><p>But that’s not all. There is also the <strong><a aria-label="inverse Laplace transform (opens in a new tab)" rel="noreferrer noopener" href="https://mathvault.ca/hub/higher-math/math-symbols/calculus-analysis-symbols/#Key_Transforms" target="_blank">inverse Laplace transform</a></strong>, which takes a frequency-domain function and renders a time-domain function.</p><p>In fact, performing the transform from time to frequency and back once introduces a factor of $1/2\pi$. Sometimes, you’ll see the whole fraction in front of the inverse function, while other times, the transform and its inverse share a factor of $1/\sqrt{2\pi}$.</p><p>This is as if the Kraken could restitute the boat intact — but only for a factor of $1/2\pi$.</p><p>The Laplace transform, even after all those years, never ceases to bring us awe with its power. Here’s a <strong>table</strong> summarizing the transforms we’ve discussed thus far:</p><figure><table><thead><tr><th data-align="center">Function</th><th data-align="center">Laplace Transform</th></tr></thead><tbody><tr><td data-align="center">$1$</td><td data-align="center">$\dfrac{1}{s}$</td></tr><tr><td data-align="center">$t$</td><td data-align="center">$\dfrac{1}{s^2}$</td></tr><tr><td data-align="center">$t^n$</td><td data-align="center">$\dfrac{n!}{s^{n+1}}$</td></tr><tr><td data-align="center">$e^{at}$</td><td data-align="center">$\dfrac{1}{s-a}$</td></tr><tr><td data-align="center">$\sin(at)$</td><td data-align="center">$\dfrac{a}{a^2+s^2}$</td></tr><tr><td data-align="center">$\cos(at)$</td><td data-align="center">$\dfrac{s}{a^2+s^2}$</td></tr><tr><td data-align="center">$t^n e^{at}$</td><td data-align="center">$\dfrac{n!}{(s-a)^{n+1}}$</td></tr><tr><td data-align="center">$f^{(2)}(t)$</td><td data-align="center">$\displaystyle s^2 \mathcal{L}\{f(t)\}-sf(0)-f'(0)$</td></tr><tr><td data-align="center">$f^{(n)}(t)$</td><td data-align="center">$\displaystyle s^n \mathcal{L}\{f(t)\}-\sum_{r=0}^{n-1} s^{n-1-r} f^{(r)}(0)$</td></tr></tbody></table></figure> <span id="tve_leads_end_content"></span></section><div data-ct="thrive_author_box" data-ct-name="About the Author" data-shortcode="thrive_author_box" data-css="tve-u-16e8d3838e9"><div data-css="tve-u-17362c8dffa"><div data-css="tve-u-17362c8dffb"><div data-css="tve-u-17362c8dffc"><div data-css="tve-u-17362c8dffd"><p><span><img alt="Math Vault Standard Post" src="https://secure.gravatar.com/avatar/3e6005b4ba6abd9cef0c322ce2905523?s=256&amp;r=g" srcset="https://secure.gravatar.com/avatar/3e6005b4ba6abd9cef0c322ce2905523?s=512&amp;r=g 2x" loading="lazy" data-d-f="author" title="Math Vault Standard Post" data-css=""></span></p><p data-css="tve-u-17362c8dfff"><span data-css="tve-u-1739c03d42c" data-extra_key="" data-option-inline="1" data-shortcode="tcb_post_author_name" data-shortcode-name="Author Name">Kim Thibault</span></p></div></div><div data-css="tve-u-17362c8e001"><div data-css="tve-u-17362c8e002"><p data-css="tve-u-17362c8e003"><h4 data-css="tve-u-17362cd5fcd">About the author</h4></p><p data-css="tve-u-17362c8e006"><span data-extra_key="" data-option-inline="1" data-shortcode="tcb_post_author_bio" data-shortcode-name="Author Bio" data-css="tve-u-1736301163e">Kim Thibault is an incorrigible polymath. After a Ph.D. in Physics, she did applied research in machine learning for audio, then a stint in programming, to finally become an author and scientific translator. She occasionally solves differential equations as a hobby. Her blog can be found at <a href="http://kimthibault.mystrikingly.com/blog"><strong>kimthibault.mystrikingly.com/blog</strong></a> and her professional profile at <a href="https://linkedin.com/in/kimthibaultphd">linkedin.com/in/kimthibaultphd</a>.</span></p></div></div></div></div></div><p data-css="tve-u-17358ffc154"><h4 data-css="tve-u-170199ce799">You may also like</h4></p><div data-type="grid" data-pagination-type="none" data-pages_near_current="2" data-css="tve-u-17355fb4c5e" data-total_post_count="16" data-total_sticky_count="0" data-disabled-links="1" data-no_posts_text=""><article id="post-31923" tcb_hover_state_parent="" data-selector=".post-wrapper" data-permalink="https://mathvault.ca/euler-formula/"><a href="https://mathvault.ca/euler-formula/" title="Euler’s Formula: A Complete Guide" data-css=""><img width="900" height="572" src="https://mathvault.ca/wp-content/uploads/Euler-formula-diagram.png" alt="Diagram illustrating Euler's formula for complex numbers" loading="lazy" title="Euler formula diagram"></a><div><p data-css="tve-u-17356046414">		<span data-attr-link="0" data-attr-rel="0" data-attr-target="0" data-extra_key="" data-option-inline="1" data-shortcode="tcb_post_title" data-shortcode-name="Post title" data-css="tve-u-17391b16085">Euler’s Formula: A Complete Guide</span></p> 	<br></div></article><article id="post-9087" tcb_hover_state_parent="" data-selector=".post-wrapper" data-permalink="https://mathvault.ca/statistical-significance/"><a href="https://mathvault.ca/statistical-significance/" title="A First Introduction to Statistical Significance — Through Dice Rolling and Other Uncanny Examples" data-css=""><img width="1000" height="600" src="https://mathvault.ca/wp-content/uploads/Statistical-Significance.jpg" alt="Header image of Math Vault's A Primer on Statistical Significance" loading="lazy" title="Statistical Significance"></a><div><p data-css="tve-u-17356046414">		<span data-attr-link="0" data-attr-rel="0" data-attr-target="0" data-extra_key="" data-option-inline="1" data-shortcode="tcb_post_title" data-shortcode-name="Post title" data-css="tve-u-17391b16085">A First Introduction to Statistical Significance — Through Dice Rolling and Other Uncanny Examples</span></p> 	<br></div></article></div></div></div></div></div></div>]]>
            </description>
            <link>https://mathvault.ca/laplace-transform/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24630882</guid>
            <pubDate>Tue, 29 Sep 2020 17:53:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kaleidoscopic Rainbow Pattern Generator]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24630724">thread link</a>) | @newcoders
<br/>
September 29, 2020 | https://www.csh.bz/line/05xp.html?play | <a href="https://web.archive.org/web/*/https://www.csh.bz/line/05xp.html?play">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.csh.bz/line/05xp.html?play</link>
            <guid isPermaLink="false">hacker-news-small-sites-24630724</guid>
            <pubDate>Tue, 29 Sep 2020 17:41:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Effective Shell – Fly on the Command Line]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24630268">thread link</a>) | @dwmkerr
<br/>
September 29, 2020 | https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/ | <a href="https://web.archive.org/web/*/https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>This is my favourite chapter of the book! The tricks I picked up on rapidly moving around in the command line have saved me an enormous amount of time over the years.</p><p>In this chapter, we'll look at the ways you can rapidly move your cursor around on the command line, as well as how to easily open up the current command in an editor (which is <em>incredibly</em> useful if you realise you are building a more complex sequence of commands).</p><p>Below is a quick reference which you can use - we'll see each operation in more detail as we go through the chapter!</p><p><a href="https://github.com/dwmkerr/effective-shell"><img src="https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/images/command-line.png" alt="command line"></a></p><ul><li><a href="#basic-navigation">Basic Navigation</a><ul><li><a href="#go-to-beginning--end">Go to beginning / end</a></li><li><a href="#move-backwards--forwards-one-word">Move backwards / forwards one word</a></li><li><a href="#delete-a-word-or-undo-a-mistake">Delete a word or undo a mistake</a></li><li><a href="#delete-the-next-word">Delete the next word</a></li><li><a href="#delete-to-beginning--clear-line">Delete to beginning / clear line</a></li><li><a href="#delete-to-end">Delete to end</a></li></ul></li><li><a href="#searching">Searching</a><ul><li><a href="#search-backwards--forwards">Search Backwards / Forwards</a></li><li><a href="#run-the-command-found-in-a-search">Run the command found in a search</a></li><li><a href="#edit-the-command-found">Edit the command found</a></li><li><a href="#stop-searching">Stop Searching</a></li></ul></li><li><a href="#editing-in-place">Editing In-Place</a></li><li><a href="#clear-the-screen">Clear the Screen</a></li><li><a href="#see-the-history-and-execute-a-recent-command">See the History and Execute a Recent Command</a></li><li><a href="#pro-tip-all-the-keys">Pro Tip: All The Keys!</a></li><li><a href="#pro-tip-transposing">Pro Tip: Transposing!</a></li><li><a href="#the-power-of-readline">The Power of Readline</a></li></ul><p>Let's assume we have a very simple command we are writing, which is going to write a quote to a text file:</p><div><pre><code data-lang="bash">echo <span>"The trouble with writing fiction is that it has to make sense,
</span><span>whereas real life doesn't. -- Iain M. Banks"</span> &gt;&gt; quote.txt
</code></pre></div><p>Navigating around long lines of text is a slow process if you are only relying on the arrow keys.</p><p>Let's see how we can quickly move around and manipulate text!</p><h2 id="go-to-beginning--end">Go to beginning / end</h2><p>Quickly jump to the beginning or end of the text:</p><ul><li><code>Ctrl + a</code> - Go to beginning</li><li><code>Ctrl + e</code> - Go to end</li></ul><p><img src="https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/images/begin-end.gif" alt="begin / end"></p><h2 id="move-backwards--forwards-one-word">Move backwards / forwards one word</h2><p>For a little more fine-grained movement, you can jump backwards or forwards one word at a time:</p><ul><li><code>Alt + b</code> - Go back one word</li><li><code>Alt + f</code> - Go forward one word</li></ul><p><img src="https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/images/forward-backwards.gif" alt="backward / forward"></p><h2 id="delete-a-word-or-undo-a-mistake">Delete a word or undo a mistake</h2><p>As this is the first operation we're seeing which <em>changes</em> the text, it is useful to remember how to <em>undo</em> any changes you make!</p><ul><li><code>Ctrl + w</code> - Delete a word</li><li><code>Ctrl + -</code> - Undo most recent change</li></ul><p><img src="https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/images/delete-undo.gif" alt="delete / undo"></p><h2 id="delete-the-next-word">Delete the next word</h2><p>We've seen how to delete the word on or behind the cursor, now let's see how to delete the <em>next</em> word:</p><ul><li><code>Alt + d</code> - Delete next word</li></ul><p><img src="https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/images/delete-next-word.gif" alt="delete next word"></p><p>Remember, just like any edit you can undo these changes with the <code>Ctrl + -</code> command.</p><h2 id="delete-to-beginning--clear-line">Delete to beginning / clear line</h2><p>In the Bash shell, you can delete all the way to the beginning of the line with <code>Ctrl + u</code>. However - if you are using the Z-Shell this will delete the entire line!</p><ul><li><code>Ctrl + u</code> - Delete to beginning of line OR delete line</li></ul><p><img src="https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/images/delete-to-beginning.gif" alt="delete to beginning"></p><h2 id="delete-to-end">Delete to end</h2><p>You can also delete all of the way to the end of the line.</p><ul><li><code>Ctrl + k</code> - Delete to end</li></ul><p><img src="https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/images/delete-to-end.gif" alt="delete to end"></p><p>When you find yourself repeatedly using the arrow or delete keys, refer back to this section to remind yourself of the shortcut - it will save a lot of time in the long run!</p><p>Once you have the basic navigation commands down, the next essential is <em>searching</em>. Let's assume we've run the following three commands:</p><div><pre><code data-lang="bash">$ command1 param1 param2 param3
$ command2 param4 param5 param6
$ command3 param7 param8 param9
</code></pre></div><p>You can search backwards or forwards with <code>Ctrl + r</code> and <code>Ctrl + s</code>. This will search in the current line and then iteratively through previous lines:</p><p><img src="https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/images/search-backwards-and-forwards.gif" alt="search backwards and forwards"></p><p>People often remember this as searching through the history - but remember that it actually searches the <em>current line</em> as well. So this is often the fastest way to move to the desired location in the current line.</p><p>This is useful for searching in the current command, but can be also used to quickly search backwards and forwards through the command history:</p><p><img src="https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/images/search-commands-backwards-and-forwards.gif" alt="search commands backwards and forwards"></p><p>As you type, your command history is searched, the most recent commands coming first. Use the arrow keys to edit the command, press enter to execute it, or <code>Ctrl + g</code> to cancel the search.</p><p>I think it's a little easier to see these commands in action with a more realistic example, so here's how they look with the text we used earlier.</p><h2 id="search-backwards--forwards">Search Backwards / Forwards</h2><p>Search backwards or forwards through the current line and also the history:</p><ul><li><code>Ctrl + r</code> - Search backwards (<em>reverse</em> search)</li><li><code>Ctrl + s</code> - Search forwards</li></ul><p><img src="https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/images/search-history-next.gif" alt="find next occurrence"></p><h2 id="run-the-command-found-in-a-search">Run the command found in a search</h2><p>This one is easy! Just hit <code>Enter</code>:
<img src="https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/images/search-history-execute.gif" alt="execute"></p><h2 id="edit-the-command-found">Edit the command found</h2><p>When you have found the command or positioned the cursor where you want it, use the Left or Right arrow keys to stop searching and to go back into the normal editing mode:</p><p><img src="https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/images/search-history-edit.gif" alt="edit command"></p><h2 id="stop-searching">Stop Searching</h2><p>Cancel the search and return back to the text as it was before you started with the <code>Ctrl + g</code> command:</p><p><img src="https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/images/search-history-cancel.gif" alt="cancel search"></p><p>These tips and tricks are helpful, but if you are working with a really long or complex command, you might find it useful just to jump into your favourite editor. This is one of those tricks that when you know it, you'll wonder how you lived without it!</p><p>Use <code>Ctrl + x , Ctrl + e</code> to edit-in place, opening the current command line in your default editor:</p><p><img src="https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/images/edit-in-place.gif" alt="edit in place"></p><p>Now it's important to explain that this is the <em>shell's</em> default editor. This might not be the same as the default editor for your operating system. You can see what the shell is using as its default editor by printing the contents of the <code>EDITOR</code> environment variable. For example, my shell will show this:</p><pre><code>$ echo $EDITOR
vim
</code></pre><p>This means <code>vim</code> will be used to edit the command line. Your shell might use <code>emacs</code> or <code>nano</code> as a default editor. Unless you are familiar with <code>vim</code> or <code>emacs</code>, you might not find them particularly user friendly as an editor. You can change your default editor by setting the <code>EDITOR</code> variable. For example, below I set the editor to <code>code</code> (with the <code>-w</code> flag which tells the <code>code</code> program not to return control immediately back to the shell but instead wait until I've finished editing the file):</p><p><img src="https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/images/editor-vs-code.gif" alt="Screen Capture: Edit in Place with Visual Studio Code"></p><p>Now this works (just about), but I wouldn't recommend using a Graphical Editor like Visual Studio Code for this. The reason is that because the editor runs in a separate window, it is actually easy to lose track of it (or the shell). You pause to take a short break, come back, close the editor and the contents are either lost or written to the shell (and if you see in the example above, the shell actually <em>executed</em> the command, rather than just putting it in the command line ready for me to execute).</p><p>The other reason to avoid a graphical editor is that if you are using a shell on another user's machine, the editor might not be present (or might be configured differently). In general however, the main reason to avoid a graphical editor is that it moves the <em>context</em> of the command away from where you are in the shell to another place, which can be confusing. If you see the screenshot below, I have <em>two</em> editors open:</p><p><img src="https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/images/multiple-editors.png" alt="Screenshot: Two shell editors"></p><p>The top right pane has my <code>git commit</code> command running (which is asking me to write a description of my changes) and the bottom right pane has the command line editor running (where I am testing out the commands for this chapter).</p><p>In this example, each editor has taken the place of the contents of the shell, so there's no ambiguity about <em>which</em> command I am editing. If I was to open a graphical editor, it would open multiple tabs for this operation and I'd have to track which tab was which.</p><p>It can be daunting to learn an editor like <code>vim</code> or <code>emacs</code>. Chapter 27 goes into more detail on the terminal based text editors - for now if you are not familiar with these programs I recommend you use the <code>nano</code> editor. Nano is small, simple and shows the shortcuts in a convenient menu at the bottom of the screen:</p><p><img src="https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/images/screenshot-nano.png" alt="Screenshot: The Nano Editor"></p><p>In Chapter 18 we'll see how to make permanent customisations to the shell, configuring things like the default editor.</p><p>Probably the shortcut I use the most is <code>Ctrl + l</code>, which clears the screen without trashing your current command. Here's how it looks:</p><p><img src="https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/images/clear-screen.gif" alt="clear screen"></p><p>This is very helpful if you have a lot of noise and output on the screen and are ready to start with a fresh command.</p><p>Just a few days ago a friend showed me a fantastic trick. If you run the <code>history</code> command, the shell will print the recent history of commands you have entered. But as an added bonus, you can <em>execute</em> any of these commands by entering an exclamation mark and the number next to the command:</p><p><img src="https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/images/screenshot-history.png" alt="Screenshot History and Execute Recent Command"></p><p>The number is actually just the <em>line number</em> in the <em>history file</em>. Most shells maintain a history of commands which have been entered (to allow for things like searching through old commands). Where this history file is kept will depend on your shell, configuration and operating system, but in most cases you can find the file by running:</p><p>There are many configuration options for the shell history. But the main thing to remember is that you can see recent history with the <code>history</code> command and quickly execute the command at line <code>n</code> by running <code>!n</code>.</p><p>You can use the <code>bindkey</code> command to see a list of all keyboard shortcuts:</p><pre><code>$ bindkeys
"^@" set-mark-command
"^A" beginning-of-line
"^B" backward-char
"^D" delete-char-or-list
"^E" end-of-line
"^F" forward-char
"^G" send-break
"^H" backward-delete-char
"^I" expand-or-complete
"^J" accept-line
"^K" kill-line
"^L" clear-screen
...
</code></pre><p>This is an extremely useful command to use if you forget the specific keyboard shortcuts, or just want to see the shortcuts which are available.</p><p>If you've mastered all of the commands here and feel like adding something else to your repertoire, try this:</p><p><img src="https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/images/transpose-word.gif" alt="transpose-word"></p><p>The <code>Alt + t</code> shortcut will transpose the last two words. Use <code>Ctrl + t</code> to transpose the last two letters:</p><p><img src="https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/images/transpose-letters.gif" alt="transpose-letters"></p><p>These two commands were new to me when I was researching this chapter. I can't see myself ever being able to remember the commands more quickly than just deleting the last two words (<code>Ctrl+w</code> twice!) or characters and re-typing them, but perhaps you'll find them useful!</p><p>All of the movement commands you've learned in this chapter apply to:</p><ol><li>Bash</li><li>zsh</li><li>The Python REPL</li><li>The Node.js REPL</li></ol><p>And many more! The reason is that all of these programs use the same library under the hood to control reading command line input. This library is called <em>GNU Readline</em>.</p><p>If you are ever looking to go deeper on this topic then search the web for <em>GNU Readline</em>. You can actually configure lower level details of how all programs which use readline work, with the <a href="https://www.gnu.org/software/bash/manual/html_node/Readline-Init-File.html"><code>.inputrc</code></a> configuration file.</p><p>This configuration file can be used to configure things like the shortcuts used to move around. All of these shortcuts should be familiar to Emacs users. There is in fact also ‘Vi Mode’ option for readline, which …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/">https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/</a></em></p>]]>
            </description>
            <link>https://effective-shell.com/docs/part-2-core-skills/8-fly-on-the-command-line/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24630268</guid>
            <pubDate>Tue, 29 Sep 2020 17:04:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I've become obsessed with networked thought]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24630175">thread link</a>) | @scotthtaylor
<br/>
September 29, 2020 | https://st.im/ive-become-obsessed-with-networked-thought/ | <a href="https://web.archive.org/web/*/https://st.im/ive-become-obsessed-with-networked-thought/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
<div>
  <main>
      <article>
  
  <div>
        <p>Imagine opening a note on your computer and within it you link to, and create, another note by writing [[<em><strong>something</strong></em>]] in square brackets. You now have a link from one note to another, and two notes.</p><p>Sounds simple, right? Nothing groundbreaking here, surely? </p><p>Upon first glance, yes. But hear me out, I believe this seemingly minor feature has fundamentally changed note-taking. I would even go as far to say it will change how our brains use and rely upon computers —as it pertains to supporting knowledge retention and plasticity.</p><p>With this new networked connection, note-taking has become an active, bi-directional relationship —rather than just a one-way dumping ground. </p><p>This is the basic premise of <strong>networked thought</strong>. </p><p>You might have seen some of the hype around apps such as <a href="https://roamresearch.com/">Roam Research</a>, <a href="https://obsidian.md/">Obsidian.md</a> or <a href="https://walling.app/">Walling</a>. The foundations of these apps are built upon networked thought. Billing themselves as your second brain.</p><figure><img src="https://st.im/content/images/2020/09/image-1.png" alt="" srcset="https://st.im/content/images/size/w600/2020/09/image-1.png 600w, https://st.im/content/images/2020/09/image-1.png 954w" sizes="(min-width: 720px) 720px"><figcaption>Screenshot of Roam Research</figcaption></figure><p>Over the past few years I've developed a pretty good habit of writing daily. Sometimes just for as little as twenty minutes. Building this cornerstone habit of journalling and note-taking has had a huge impact on my productivity —I'd highly recommend it. It reduced the strain on my brain's short term memory, as well as my dependency upon it. </p><p>With my daily habit established, I wanted to level up.</p><p>I wanted to evolve my journalling and note-taking habit to a higher level of reflection and connection. Just dumping my thoughts into a note wasn't enough.</p><p>I discovered the idea of <strong>Index, Maps of Content, and other fluid Frameworks</strong> (IMF). Basically some frameworks, structures, modules and approaches that note-taking pros had come up with, to use in apps such as Obsidian and Roam. By using this IMF foundation, I was able to build a network of thoughts on top of which I could be creative, innovative and strengthen and codify my knowledge.</p><p>One of the core aspects of IMF are Maps of Content. </p><h2 id="maps-of-content-mocs-">Maps of Content (MOCs)</h2><p>MOCs help us get past 'mental squeeze points'. They encourage thinking, create favourable conditions for flow, and allow us to create meaningful spatial constellations of thought. They have limitless interpretations, are non-destructive and non-limiting because they act as fluid, augmented layers.</p><p>MOCs have three basic stages in a full lifecycle:</p><ol><li><strong>Collect, curate, incubate</strong> - put related stuff on a new digital workbench</li><li><strong>Battle, collide, dismember, combine, craft, discover</strong> - have your ideas battle for relational positioning. This is the most joyous and valuable stage</li><li><strong>Enjoy and use </strong>- enjoy the spatial constellation you created out of concepts. It will be meaningful to <em>you</em>. Use it for different purposes: for final products (content creation), as a reference point in the future, or for the inherent joy the ideas provide.</li></ol><p>So what is an MOC? Simply put: let's say you read something interesting on a topic - for example '<em>habits</em>', and you make a note. Later on, you make a couple more notes on the same topic. You start to think you might lose some of the ideas. So to pass this 'mental squeeze point' you go ahead and make a special note. You call it '<strong>Habits MOC</strong>'</p><p>A 'mental squeeze point' is when your unsorted knowledge becomes so messy it overwhelms and discourages you. Either you are equipped with frameworks to overcome the squeeze point, or you are discouraged and possibly abandon your project. This is usually followed by yet another search for the next app that will make all the difference.</p><h3 id="habits-moc-stage-1">Habits MOC - Stage 1</h3><p><strong>Collect, curate, incubate</strong> - put related stuff on a new digital workbench.</p><p>To continue the example, I decided to compile old notes I collected on the topic of 'habits'. They aren't organised yet within Obsidian:</p><pre><code>201303102051 Habit Planning
201502201031 Habit Formation Research Article
201502201713 Habit Concepts and Theory
201910011142 Atomic Habits
201901250999 Resiliency Routines
</code></pre><h3 id="habits-moc-stage-2">Habits MOC - Stage 2</h3><p><strong>Battle, collide, dismember, combine, craft, discover</strong> - have your ideas battle for relational positioning. This is the most joyful and valuable stage.</p><p>Excitedly, without a task manager telling me what to do - I open the first note and I craft it into an evergreen note (something in my own words). But when I try to name it, I realise it's too big, so I split it up into two evergreen notes:</p><pre><code>The neural formation of habits are additive 
The truest habit metaphors are additive 
</code></pre><p>And the others I leave alone for now. I'm done for the night. I'm comforted by this MOC; the other notes have a digital workbench to rest upon. I'm satisfied with creating two evergreen notes. They have value to me.</p><p>The next day, I continue where I left off.</p><p>Looking at the collected notes —questions just arrive, unforced: What are they trying to say? What is redundant? What note needs to be split into two? What outside concepts relate to this? You naturally work yourself into a state of Flow and time becomes timeless; effort effortless.</p><h3 id="habits-moc-stage-3">Habits MOC - Stage 3</h3><p><strong>Enjoy and use </strong>- enjoy the spatial constellation you created out of concepts. It most likely is meaningful to you. My 'Habits MOC' now looks like this:</p><pre><code>**Understanding Habits**
Defining a habit
Habit formation provides an evolutionary advantage
Habits carry a ton of hidden inertia
The neural formation of habits is additive
	The truest habit metaphors are additive
        
**Designing Habits**
Understanding the habit cycle and habitual cues
	How Atomic Habits fit into the conversation on habits
	Resiliency Routines are my most important habits to regain a sense of control
An asymptotic curve models the development of skills, strength, habits, and more
	The mechanism for breaking through development plateaus

**Example of Habit Design**
Charting out habit cycles in my life circa 2013

**Related Concepts**
Positive Feedback Loop, Like begets like
Cobwebs into Cables, Reps
Natural Selection, Selfish Gene, Survival of the Fittest</code></pre><p>Within this example, we've only touched upon one MOC. Imagine combining everything in your brain —creating a knowledge graph. Below I've shown a snippet of my '<strong>000 Index</strong>'. I'd recommend visiting some of the <a href="https://forum.obsidian.md/c/knowledge-management/6">discussion forums</a>, download a template, and start moulding it to best suit your needs. </p><h2 id="screenshot-of-my-obsidian-imf-structure">Screenshot of my Obsidian IMF Structure </h2><figure><img src="https://st.im/content/images/2020/09/Screenshot-2020-09-29-at-15.40.18.png" alt="" srcset="https://st.im/content/images/size/w600/2020/09/Screenshot-2020-09-29-at-15.40.18.png 600w, https://st.im/content/images/size/w1000/2020/09/Screenshot-2020-09-29-at-15.40.18.png 1000w, https://st.im/content/images/size/w1600/2020/09/Screenshot-2020-09-29-at-15.40.18.png 1600w, https://st.im/content/images/2020/09/Screenshot-2020-09-29-at-15.40.18.png 2232w" sizes="(min-width: 720px) 720px"></figure><h2 id="final-note">Final note</h2><p>The three stages of MOCs are not distinct like these examples. They overlap. Don't get hung up on the stages, and don't view the process as linear.</p><p>The process is overlapping and cyclical. An MOC is rarely a finalised concrete statue. Instead, it should be able to free evolve with the times. Or you can just create a new one.</p>
              <section>
                <h2>Enjoying these posts? Subscribe for more</h2>
                <a href="https://st.im/subscribe/">Subscribe now</a>
                <br>
                <a href="https://st.im/signin/">Already have an account? Sign in</a>
              </section>
  </div>
    
</article>          
          


  </main>
</div>
      </div><p>
  You've successfully subscribed to Scott Taylor.
  
</p><p>
  Great! Next, complete checkout for full access to Scott Taylor.
  
</p><p>
  Welcome back! You've successfully signed in.
  
</p><p>
  Success! Your account is fully activated, you now have access to all content.
  
</p><p>
  Success! Your billing info is updated.
  
</p></div>]]>
            </description>
            <link>https://st.im/ive-become-obsessed-with-networked-thought/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24630175</guid>
            <pubDate>Tue, 29 Sep 2020 16:56:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DIY IoT door monitor with ESP8266]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24630168">thread link</a>) | @gk1
<br/>
September 29, 2020 | https://cri.dev/posts/2020-09-03-DIY-IoT-door-monitor-with-ESP8266/ | <a href="https://web.archive.org/web/*/https://cri.dev/posts/2020-09-03-DIY-IoT-door-monitor-with-ESP8266/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>Using an ESP8266 for IoT projects makes me go fast while prototyping.</p><p>The compact format is perfect for small DIY devices.</p><p>Wi-Fi connectivity is built-in, and it's super affordable.</p><blockquote><p>The ESP8266 is a low-cost Wi-Fi microchip, with a full TCP/IP stack and microcontroller capability (<a href="https://en.wikipedia.org/wiki/ESP8266">wikipedia</a>)</p></blockquote><hr><h2>Table of Contents</h2><ul><li><a href="#tldr">tldr;</a></li><li><a href="#requirements">Requirements</a></li><li><a href="#circuit-explanation">Circuit explanation</a></li><li><a href="#coding">Coding</a><ul><li><a href="#install-libraries-for-esp8266">Install libraries for ESP8266</a><ul><li><a href="#adding-the-esp8266-board">Adding the ESP8266 Board</a></li><li><a href="#additional-libraries">Additional libraries</a></li></ul></li><li><a href="#flash-it">Flash it</a></li></ul></li><li><a href="#try-it-out">Try it out!</a></li><li><a href="#next-steps">Next steps</a></li><li><a href="#rest-api">REST API</a></li><li><a href="#web-ui">Web UI</a></li><li><a href="#demo">Demo</a></li></ul><h2>tldr;</h2><p>The door monitor running in my home activates a buzzer when the proximity sensor detects that the door is opened.</p><p>Additionally, it creates an AP for Wi-Fi configuration using a Web interface, and can connect to a desired Wi-Fi network afterwards. <a href="#web-ui">Read more about this below</a></p><p>Source code can be found on <a href="https://github.com/christian-fei/door-monitor-esp8266">GitHub christian-fei/door-monitor-esp8266</a></p><pre><code>git clone https://github.com/christian-fei/door-monitor-esp8266.git
</code></pre><p>The worst photo I could take of the "Gate keeper" in action:</p><p><a href="https://github.com/christian-fei/door-monitor-esp8266/blob/master/Gatekeeper.svg"><img src="https://cri.dev/assets/images/posts/door-monitor/project.jpg" alt="project photo"></a></p><p>Now I added a case! (<strong>update 2020-09-10</strong>)</p><p><a href="https://github.com/christian-fei/door-monitor-esp8266/blob/master/Gatekeeper.svg"><img src="https://cri.dev/assets/images/posts/door-monitor/project-update.jpg" alt="project photo"></a></p><p>The Web UI that this thing has (see home-assistant integration <a href="#next-steps">at the end</a>)</p><p><img src="https://cri.dev/assets/images/posts/door-monitor/gate-keeper-ui.png" alt="gate-keeper-ui"></p><h2>Requirements</h2><p>To build your own, this is what you need:</p><ul><li>Microcontroller ESP8266 (LoLin)</li><li>Active Piezo Buzzer</li><li>Proximity Sensor FC-51</li><li>optionally a breadboard</li></ul><p>Arduino IDE or the Arduino Plug-in for VSCode will work fine for flashing the ESP8266.</p><h2>Circuit explanation</h2><p>Here the schematics for the circuit</p><p><img src="https://cri.dev/assets/images/posts/door-monitor/schematics.svg" alt="schematics door monitor"></p><p>The piezo buzzer is connected to GPIO D6, as an <code>OUTPUT</code> pin.</p><p>The proximity sensor is connected to GPIO D5, as an <code>INPUT</code> pin.</p><p>When the proximity sensor detects that the door is open, the GPIO D5 pin will read <code>HIGH</code>.</p><p>This is when the piezo buzzer is activated, and a simple alarm sound is played.</p><h2>Coding</h2><p>Clone the repository</p><pre><code>git clone https://github.com/christian-fei/door-monitor-esp8266.git
</code></pre><p>Open the project with Arduino IDE by clicking on the <a href="https://github.com/christian-fei/door-monitor-esp8266/blob/master/Gatekeeper.ino"><code>Gatekeeper.ino</code></a> file.</p><p>There is no need to change the code.</p><h3>Install libraries for ESP8266</h3><h4>Adding the ESP8266 Board</h4><p>Using the "Library Manager" in the Arduino IDE, you need to install support for ESP8266.</p><p>Here you can find <a href="https://arduino-esp8266.readthedocs.io/en/latest/installing.html#instructions">the official installation guide</a></p><h4>Additional libraries</h4><p>The project uses <a href="https://github.com/me-no-dev/ESPAsyncTCP/archive/master.zip"><code>ESPAsyncTCP</code></a> and <a href="https://github.com/me-no-dev/ESPAsyncWebServer/archive/master.zip"><code>ESPAsyncWebServer</code></a>.</p><p>Download both ZIP files, and add them either to your Arduino IDE installation libraries or via <code>Add .ZIP Library</code>.</p><h3>Flash it</h3><p>Connect your ESP8266 via USB to your PC.</p><p>Select the <code>usbserial</code> port and <code>NodeMCU 1.0 (ESP - 12 E Module)</code> board in the Arduino IDE.</p><p>Click <code>Upload</code> and flash the ESP8266.</p><h2>Try it out!</h2><p>Now you're ready to apply the board near a door you want to monitor.</p><p>The proximity sensor can both be placed on the door itself or on a wall near the door.</p><p>You'll need to calibrate the sensitivity of the sensor by rotating the potentiometer on the FC-51 chip.</p><h2>Next steps</h2><p>From here I went the following route:</p><p>Made the Gatekeeper available as an iframe element in my <a href="https://www.home-assistant.io/">homeassistant</a> installation. The URL I used was <code>http://gatekeeper.fritz.box</code> (after I connected it to my Wi-Fi network using <a href="#web-ui">the Web UI</a>)</p><p>On the Web UI of the Gatekeeper I can "disarm" the alarm sound and check whether the door is open or closed.</p><p>It looks like this:</p><p><img src="https://cri.dev/assets/images/posts/door-monitor/gate-keeper-homeassistant.png" alt="gate-keeper-homeassistant"></p><p>The next challenge is to register the door monitor as a "sensor" (or "entity" I think it's called in homeassistant lingo).</p><h2>REST API</h2><p>The Gatekeeper can already be called via HTTP on its REST API:</p><pre><code>  HTTP GET /
    -&gt; replies with the client html
  HTTP GET /door
    -&gt; returns the status of the door, whether it's "open" or "closed"
  HTTP GET /alarm
    -&gt; returns the status of the alarm, whether it's "on" or "off"
  HTTP POST /toggle-alarm
    -&gt; toggles the alarm and returns the current status of it
  HTTP POST /setup
    -&gt; to save the Wi-Fi credentials and connect to the desired access point
</code></pre><h2>Web UI</h2><p>The Web UI give you the current status of the door.</p><p>It also features a form where you can input the Wi-Fi credentials to connect to your home network.</p><p><img src="https://cri.dev/assets/images/posts/door-monitor/gate-keeper-ui.png" alt="gate-keeper-ui"></p><p>This means that once the door monitor is connected to Wi-Fi, it's accessible via the hostname <code>gatekeeper</code>.</p><p>E.g. with my FritzBox setup, it's available under <code>gatekeeper.fritz.box:80</code></p><h2>Demo</h2></div></div>]]>
            </description>
            <link>https://cri.dev/posts/2020-09-03-DIY-IoT-door-monitor-with-ESP8266/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24630168</guid>
            <pubDate>Tue, 29 Sep 2020 16:56:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Coinbase Got It Wrong and Tech Leaders Need to Speak Out]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24629685">thread link</a>) | @geoffroberts
<br/>
September 29, 2020 | https://www.outseta.com/posts/tech-leaders-your-silence-is-deafening | <a href="https://web.archive.org/web/*/https://www.outseta.com/posts/tech-leaders-your-silence-is-deafening">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page" role="main">
        
          <article data-page-sections="5e5ab77cbd974c787316c1ca" id="sections">
  
    <section data-section-id="5e5ab77cbd974c787316c1cc" data-controller="SectionWrapperController, MagicPaddingController" data-current-styles="{
                &quot;imageOverlayOpacity&quot;: 0.15,
                &quot;video&quot;: {
                  &quot;playbackSpeed&quot;: 0.5,
                  &quot;filter&quot;: 1,
                  &quot;filterStrength&quot;: 0,
                  &quot;zoom&quot;: 0
                },
                &quot;backgroundWidth&quot;: &quot;background-width--full-bleed&quot;,
                &quot;sectionHeight&quot;: &quot;section-height--medium&quot;,
                &quot;customSectionHeight&quot;: 10,
                &quot;horizontalAlignment&quot;: &quot;horizontal-alignment--center&quot;,
                &quot;verticalAlignment&quot;: &quot;vertical-alignment--middle&quot;,
                &quot;contentWidth&quot;: &quot;content-width--wide&quot;,
                &quot;customContentWidth&quot;: 50,
                &quot;sectionTheme&quot;: &quot;&quot;,
                &quot;sectionAnimation&quot;: &quot;none&quot;,
                &quot;backgroundMode&quot;: &quot;image&quot;
              }" data-animation="none">
  
  <div>
    <div>
      
      
      <div data-content-field="main-content" data-item-id="">
  <article id="article-">
  
    <div>
      

      <div>
        <div><div data-layout-label="Post Body" data-type="item" id="item-5f7351eccb435d65f7911f6d"><div><div><div data-block-type="2" id="block-f7fa6d006ae58f15a59b"><div><p>Why Coinbase got it wrong and tech leaders need to speak out about an election that runs much deeper than politics</p><p>By <a href="https://twitter.com/GeoffTRoberts">Geoff Roberts</a> · 10 min read</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1601394878123_12103"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e5ab1236ecd6e20d27a0927/1601395351980-VXU2GJP2G2FE39NL02UK/ke17ZwdGBToddI8pDm48kPVZ5JZEC-owcWMIQ2jhW4FZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpz0f89Yb3Pubh4TAiMtJKLZ57c4HEOU3qcz1kuI8OxB6YUDP7-Ncnym616I1rvTmUE/CoinbaseMissionFocused.png" data-image="https://images.squarespace-cdn.com/content/v1/5e5ab1236ecd6e20d27a0927/1601395351980-VXU2GJP2G2FE39NL02UK/ke17ZwdGBToddI8pDm48kPVZ5JZEC-owcWMIQ2jhW4FZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpz0f89Yb3Pubh4TAiMtJKLZ57c4HEOU3qcz1kuI8OxB6YUDP7-Ncnym616I1rvTmUE/CoinbaseMissionFocused.png" data-image-dimensions="575x411" data-image-focal-point="0.5,0.5" alt="CoinbaseMissionFocused.png" data-load="false" data-image-id="5f735a9626ac6c47a4e12e49" data-type="image" src="https://www.outseta.com/posts/CoinbaseMissionFocused.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1601394878123_12394"><div><p>Jerry McGuire had his late night memo. This may very well prove to be mine.</p><p>Yesterday I opened up Twitter and came across <a href="https://blog.coinbase.com/coinbase-is-a-mission-focused-company-af882df8804">this post from Brian Armstrong, the CEO of Coinbase</a>. I read it and was severely disappointed. Then I came across this endorsement of the article from Y-combinator founder Paul Graham. I was nothing short of mortified.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1601394878123_14960"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e5ab1236ecd6e20d27a0927/1601395425248-4E8SW1WEH8NZBKKXQV0T/ke17ZwdGBToddI8pDm48kMOpxdSxSGrNDrvMgwlDLLpZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxX9hRL0dftBSPVvkhsJfoiCGBA6CkuD9n85DoWEf5iLvRwwlYokq_d0zgwshhFUSs/PaulGrahamCoinbase" data-image="https://images.squarespace-cdn.com/content/v1/5e5ab1236ecd6e20d27a0927/1601395425248-4E8SW1WEH8NZBKKXQV0T/ke17ZwdGBToddI8pDm48kMOpxdSxSGrNDrvMgwlDLLpZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxX9hRL0dftBSPVvkhsJfoiCGBA6CkuD9n85DoWEf5iLvRwwlYokq_d0zgwshhFUSs/PaulGrahamCoinbase" data-image-dimensions="608x206" data-image-focal-point="0.5,0.5" alt="PaulGrahamCoinbase" data-load="false" data-image-id="5f735ae003ee376ca2c77eba" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1601394878123_17587"><div><p><em>If only because those who don’t are less likely to succeed</em>…. Are you kidding me?</p><p>If you don’t live in the tech world, Coinbase is a tech company that allows you to buy and sell cryptocurrency. The company does billions of dollars in revenue and may soon become publicly traded. Paul Graham is an investor and founder of arguably the most well known start-up accelerator in the world. Few people better embody the idea of “tech leaders” than these two.&nbsp;</p><p>Now I don’t know Brian or Paul, and for all I know they are good people. I appreciate the tone of Brian’s post and I genuinely think he’s trying to do what he believes is the right thing. But as I read his thoughts, I couldn’t help but think to myself…</p><p><em>“Well if this isn’t the walking embodiment of all that’s wrong with the United States right now, I’m not sure what is.”&nbsp;</em></p><p>This article isn’t meant to be an attack on Brian or Paul—far from it. But I am going to use their example to illustrate why they got this oh-so-wrong. And let me begin by saying I write this with no political agenda—I don’t identify with any political party—which leads me to the crux of my argument…</p></div></div><div data-block-type="31" id="block-yui_3_17_2_1_1601393386670_18556"><div>

<figure>
  <blockquote data-animation-role="quote">
    <span>“</span>This election is NOT about politics. It’s about basic human rights, decency, ethics, and the behavior that we expect and accept from our leaders.&nbsp;<span>”</span>
  </blockquote>
  
</figure>
</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1601393386670_18620"><div><p>Brian likely wanted his post to communicate…</p><p><em>”We’re focused on our mission as a company, and aren’t going to be taking a political or social stance.”</em></p><p>Unfortunately all he effectively communicated was…</p><p><em>&nbsp;“We don’t care enough to speak up about basic human rights, decency, and ethics if it’s going to impact our company’s balance sheet.”</em></p><p>And no matter your politics, that’s a massive failure of leadership. That’s turning a blind eye.</p><h2>It’s OK to separate business and politics</h2><p>If you haven’t read Brian’s post, I think it can very fairly be summed up as follows:</p><p><em>Coinbase is a “mission driven” company. Building a company is damn hard, and taking sides politically or in terms of social activism isn’t part of that mission. We have employees with diverse views and don’t want to divide our own company by sharing perspectives that could distract the company from the mission that unites it.</em></p><p>On the surface, that may sound fine—I 100% understand and respect wanting to keep business and politics separate. I personally believe that’s any person’s or company’s right, as much as I wish more businesses would take a stand for what they believe in.&nbsp;</p><p>Likewise, not all businesses need to be altruistic. Fine by me. In all honestly I’ve spent the first 33 years of my life never once intentionally mixing business and politics. And up until this year I’ve always identified as “non-political.” But 2020 has made me realize how much <em>that description of myself</em> came from a position of great privilege. And as I said, the upcoming election in the US is about something so much fundamentally bigger than politics. If you’re truly a leader, you can’t just say “I’m not going there” to something as big as this.</p><h2>Why I’ve started to speak up as a “non-political” person</h2><p>At the subtle prompting of people like Rand Fishkin and Peter Caputa, I’ve started <a href="https://www.outseta.com/posts/leadership-hope-and-minimalism">to speak up</a>. My <a href="https://twitter.com/GeoffTRoberts/status/1307096268703969280">tonality and the topics of my tweets have changed</a>. And none of it has been to show support for any political party—it’s all been in recognition that this election is different.&nbsp;</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1601393386670_21622"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e5ab1236ecd6e20d27a0927/1601394137547-FK6BE4M3LCYRUUFDATCC/ke17ZwdGBToddI8pDm48kLaroNP0RQ9jWQ5AgMRuSbxZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpyh6qQVTa5d6aWizGl61QgfQsimZojEZtf2Vf89u0m5VPIytlZ9YjucZs5QDZUMtdU/PeterCaputaElection.png" data-image="https://images.squarespace-cdn.com/content/v1/5e5ab1236ecd6e20d27a0927/1601394137547-FK6BE4M3LCYRUUFDATCC/ke17ZwdGBToddI8pDm48kLaroNP0RQ9jWQ5AgMRuSbxZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpyh6qQVTa5d6aWizGl61QgfQsimZojEZtf2Vf89u0m5VPIytlZ9YjucZs5QDZUMtdU/PeterCaputaElection.png" data-image-dimensions="609x256" data-image-focal-point="0.5,0.5" alt="PeterCaputaElection.png" data-load="false" data-image-id="5f7355d98b9cde1a2962745d" data-type="image" src="https://www.outseta.com/posts/PeterCaputaElection.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1601393386670_26382"><div><p>Ethics and decency and human rights shouldn’t be construed as “political” or “Democratic” or “Republican”—they should be viewed as ideals that make up the very fabric of America with bi-partisan support, yet somehow we’ve landed here. This election <em>is</em> about showing that we care about having leaders who lead by example.</p><p>At the heart of Brian and Paul’s comments are two devastating ideas:</p><ul data-rte-list="default"><li><p>First, that building a company is hard enough as it is. So hard, that it’s not worth taking a stand on issues that could rock the boat financially.&nbsp;</p></li><li><p>Second, that in some way this is “leadership”—putting the financial interests of your company first and foremost.&nbsp;</p></li></ul><p>I fully recognize that we live in a capitalistic society, and I think that’s mostly a good thing. I want my own start-up to be a roaring financial success. But the perils of capitalism could not be illuminated more than by this interaction—we’re essentially saying “anything goes” because our most important obligations are to our financial constituents? We’re going to turn a blind eye to blatant and rampant ethical violations by the highest elected leader in our country because we need to improve outcomes for our financial stakeholders quarter over quarter?&nbsp;</p><p>I have a hard time calling that anything but having no soul.&nbsp;&nbsp;</p><h2>Tech leaders, no one is asking you to take a political stance</h2><p>What’s altogether missing from this perspective is the very reason people are calling on leaders to take a stand right now. </p></div></div><div data-block-type="31" id="block-yui_3_17_2_1_1601393386670_33129"><div>

<figure>
  <blockquote data-animation-role="quote">
    <span>“</span>No one is asking you, tech leaders, to identify your company as being supportive of Republican or Democatic ideals. <span>”</span>
  </blockquote>
  
</figure>
</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1601393386670_33193"><div><p>The call to arms is simple—the US is being led by a person right now who undeniably:</p><ul data-rte-list="default"><li><p>Acts in his own financial interests and hasn’t paid his fair share</p></li><li><p>Has intentionally and consistently divided the country for his own political agenda</p></li><li><p>Has denied science, from Coronavirus to climate change</p></li><li><p>Is a pathological liar</p></li></ul><p>Tech leaders, you’re not being asked to take a stand on politics! You’re being asked to take a stand on basic human decency and the type of behavior we expect from our leaders. If you’re not comfortable saying, “We expect the truth, we expect a leader who tries to unite us, we expect a leader who leads by example,” then you are unfit to be a leader yourself.&nbsp;</p><p>After all, we all work in technology, right? Isn’t the mission of the tech industry to better the human condition? To advance our abilities as a species? To create a better and more promising future for the next generation?</p><p>If you’re not comfortable denouncing the behaviors that Donald Trump has demonstrated over the past 4 years, you’re either complicit or cowardly. Cowardly? Fine. But true leaders don’t stay silent when the going gets tough. Complicit? OK. But at least be ready to openly admit it.</p><p>If you’re hiding behind being a “mission driven” company so you don’t have to stand up for basic human decency or hold our leaders accountable in any way, at least have fortitude to say, “I’m choosing to act in my company’s best financial interests over anything else.” If you come out and say that I’ll at least respect your honesty. If you won’t my message for you is—<em>have some guts. </em></p><p>Edmund Burke’s quote sums up the election in front of the US perfectly:</p></div></div><div data-block-type="31" id="block-yui_3_17_2_1_1601393386670_36155"><div>

<figure>
  <blockquote data-animation-role="quote">
    <span>“</span>The only thing necessary for the triumph of evil is for good men to do nothing.<span>”</span>
  </blockquote>
  
</figure>
</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1601393386670_36219"><div><h2>Stand for something greater than your balance sheet</h2><p>Taking a stand against obviously absurd and unethical behavior might be hard. It might be polarizing. It might impact your business’ bottom line.&nbsp;</p><p>Boo-hoo-hoo. Get over it.&nbsp;</p><p>It’s still absolutely the right thing to do if you care at all about the next generation, if you care at all about the world your kids will grow up in, if you care at all about what your actions truly say about you and your company. There’s more to life than term sheets, growth rates, and shareholder value.</p><p>I’m becoming increasingly disenfranchised with the tech industry on behalf of the complete and utter silence I’ve heard from the vast majority of tech leaders here in the US. The one thing the silence has made clear is this:</p></div></div><div data-block-type="31" id="block-yui_3_17_2_1_1601393386670_38316"><div>

<figure>
  <blockquote data-animation-role="quote">
    <span>“</span>Most tech leaders are willing to turn a blind eye to protect their own financial interests.<span>”</span>
  </blockquote>
  
</figure>
</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1601393386670_40783"><div><p><em>﻿</em>Perhaps the biggest kicker here is that in taking a stand for what you believe is right, you might lose some business, sure. But I’d guess that more than anything you would be applauded and rewarded by people who actually give a shit who they do business with. Brands are built on opinions, not by using your brand’s “mission” as in invisibility cloak.</p><h2>Easy for you to say—you don’t have the same responsibilities</h2><p>I can hear the criticism of this article already—but Geoff, you’re not running a billion dollar company with thousands of employees and investors as constituents. That’s true. But nobody said leadership at that scale was going to be easy. You’re the person charged with making the tough calls—have the spine to make one. And I am running a business where publishing posts like this directly impacts my ability to put dinner on the table so my kids can eat, so reconsider your assessment of my own personal stakes. If I’ve learned anything in my lifetime it’s this—at the end of the day the only constituent that matters is the person you see looking back at you in the mirror.</p><p>So if you’re out there and you’ve been silent, don’t speak out to take a stand on behalf of the Democrats or the Republicans. Speak out on behalf of being a decent, ethical person. …</p></div></div></div></div></div></div></div></div></article></div></div></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.outseta.com/posts/tech-leaders-your-silence-is-deafening">https://www.outseta.com/posts/tech-leaders-your-silence-is-deafening</a></em></p>]]>
            </description>
            <link>https://www.outseta.com/posts/tech-leaders-your-silence-is-deafening</link>
            <guid isPermaLink="false">hacker-news-small-sites-24629685</guid>
            <pubDate>Tue, 29 Sep 2020 16:18:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What it feels like when you've found product-market fit]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24629624">thread link</a>) | @amrrs
<br/>
September 29, 2020 | https://www.lennyrachitsky.com/p/what-it-feels-like-when-youve-found | <a href="https://web.archive.org/web/*/https://www.lennyrachitsky.com/p/what-it-feels-like-when-youve-found">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>👋 Hello, I’m&nbsp;<a href="https://twitter.com/lennysan">Lenny</a> and welcome to a ✨ <strong>once-a-month-free-edition </strong>✨ of my newsletter. Each week I humbly tackle reader questions about product, growth, working with humans, and anything else that’s stressing you out at the office.</p><p>If you’re not a paid subscriber, here’s what you missed this month:</p><ol><li><p><a href="https://www.lennyrachitsky.com/p/getting-better-at-product-strategy">Getting better at product strategy</a></p></li><li><p><a href="https://www.lennyrachitsky.com/p/fostering-a-culture-of-experimentation">Fostering a culture of experimentation</a></p></li><li><p><a href="https://www.lennyrachitsky.com/p/when-to-hire-your-first-product-manager">When to hire your first product manager</a></p></li></ol><p><em>“When we hit PMF, we started feeling pull for the first time”</em></p><p><em>“Like getting pressed into the back of your seat by a fast car or a plane taking off”</em></p><p><em>“Word of mouth was uncontrollable”</em></p><p><em>“Why won't you take my money???”</em></p><p><em>“Yeah, you really can't miss it”</em></p><p>This is what you hear from successful founders when you ask them what product-market fit felt like. But is this always what it feels like? I wanted to find out.</p><p><strong>Over the past few months I reached out to founders of the twenty five most iconic companies I could get a hold of and asked them one question</strong>: </p><blockquote><p><em><strong>When did you first know you found product-market fit?</strong> Whatever that point means to you – was there something you noticed, felt, or experienced where you were like “Damn, I think we got something here!”</em></p></blockquote><p>After collecting and reviewing their stories (all of which you’ll find below), one thing became clear: every company <em>did</em> have a clear moment of PMF, and many <em>did</em>  experience a sudden hard-to-miss pull from the market, BUT many companies <em>did not</em>. For many companies PMF became clear over time through a series of compounding wins or milestones. Here’s how it broke down across the companies I looked at:</p><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fddea5493-43b6-4017-93b5-47a3b37e38b6_1766x994.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fddea5493-43b6-4017-93b5-47a3b37e38b6_1766x994.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/ddea5493-43b6-4017-93b5-47a3b37e38b6_1766x994.png&quot;,&quot;height&quot;:820,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:390110,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></p><h4><strong>Some of my biggest takeaways from these stories:</strong></h4><p><strong>1. Market “pull” comes in many forms:</strong></p><ul><li><p>An inflection in organic growth</p></li><li><p>Customers asking to pay for the product before you ask</p></li><li><p>Users flip from being excited about what you <em>have</em> to mad about what you <em>don’t have</em></p></li><li><p>Customers complaining when your site goes down</p></li><li><p>People using the product even when it’s broken</p></li></ul><p><strong>2. About half of these companies found PMF immediately after launch, but half spent months or years iterating to get there</strong>:</p><ul><li><p>Netflix: 18 months</p></li><li><p>Segment: 1.5 years</p></li><li><p>Airbnb: 2 years</p></li><li><p>PagerDuty: 2 years</p></li><li><p>Superhuman: 3 years</p></li><li><p>Amplitude: 4 years</p></li></ul><p>Once they got there though, it became obvious.</p><p><strong>3. The intensity of the pull is a factor of the </strong><em><strong>fit</strong></em><strong> (how good your product is at solving the user’s problem) AND </strong><em><strong>initial market size</strong></em><strong> (is it niche or broad)</strong>. Dropbox, Netflix, and Tinder were 10x better products within a huge market —&gt; sudden and broad pull. Instacart, Superhuman, and Substack were 10x better products but for a narrow set of initial customers —&gt; steady and compounding pull.</p><h4>What is Product-Market fit anyway?</h4><p>I covered this in <a href="https://www.lennyrachitsky.com/p/how-to-know-if-youve-got-productmarket">a previous post</a>, and I want to make clear that getting to a feeling of PMF does not mean you’ll automatically be able to build a successful business. There are three things you have to get right to find <strong>True Product-Market Fit</strong>:</p><ol><li><p><strong>Make a product that people want</strong> — that’s what this post is all about. </p></li><li><p><strong>Make a profit delivering this product to people at scale</strong> — companies like <a href="https://techcrunch.com/2012/12/23/cherry-car-wash-shut-down/">Cherry</a>, <a href="https://www.bizjournals.com/sanfrancisco/news/2017/04/27/valet-startup-luxe-shuts-down-its-door-to-door.html">Luxe</a>, and <a href="https://techcrunch.com/2013/09/10/rip-lazy-times/">Exec</a> are valuable cautionary tales.</p></li><li><p><strong>Find and keep these people, sustainably</strong> — <a href="https://www.lennyrachitsky.com/p/how-to-know-if-youve-got-productmarket">check out this previous post</a> that covers the quantitative side of PMF, like retention and sales yield.</p></li></ol><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8975379-7419-4366-b1f5-5f074a3a9c21_2400x1350.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8975379-7419-4366-b1f5-5f074a3a9c21_2400x1350.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/d8975379-7419-4366-b1f5-5f074a3a9c21_2400x1350.png&quot;,&quot;height&quot;:819,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:140575,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></p><p>Of these three milestones though, the most likely to kill your business is the first: not building something people want. And that what this post focuses on — <strong>how do you know when you’ve built something people want</strong>? Below you’ll find stories from twenty-five companies — many of which have never been shared before — revealing the moment they realized they had something special.</p><p>Let’s dive in!</p><p><em>❤️ A HUGE thank you to these generous humans who helped make this post possible: Alex Solomon, Brianne Kimmel, Calvin French-Owen, Chris Best, Cliff Obrecht, Dan Hockenmaier, Drew Houston, Henry Ward, James Beshara, Jason Wang, Jeff Morris Jr., Jeffrey Queisser, Joe Gebbia, Jonathan Badeen, Katie Dill, Keenan Rice, Li Jin, Marc Randolph, Matthias Wagner, Max Mullen, Nikhil Basu Trivedi, Nina Achadjian, Olivier Pomel, Patrick Lightbody, Rahul Vohra, Ryan Graves, Ryan Hoover, Samuel Yam, Sarah Leary, Scott Gorlick, Tai Rattigan, Todd Goldberg, Tom Preston-Werner, and Tomer London ❤️</em></p><h2>Sign 1: 🔥 Sudden and significant pull from the market</h2><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F616f359c-2191-4289-a42d-80adf532482b_1474x412.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F616f359c-2191-4289-a42d-80adf532482b_1474x412.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/616f359c-2191-4289-a42d-80adf532482b_1474x412.jpeg&quot;,&quot;height&quot;:407,&quot;width&quot;:1456,&quot;resizeWidth&quot;:218,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Dropbox for Business is Coming to Salesforce World Tour! - Salesforce  Australia &amp; NZ Blog&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt="Dropbox for Business is Coming to Salesforce World Tour! - Salesforce  Australia &amp; NZ Blog"></a></p><blockquote><p>“For me there was a visceral sense of your thing taking on a life of its own and lurching forward, <strong>like getting pressed into the back of your seat by a fast car or a plane taking off</strong>. The most standout moment for me was our demo video hitting the top of Digg (and then Reddit).”</p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F4a553e07-1eb0-4466-9806-e3bec9802a27_646x413.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F4a553e07-1eb0-4466-9806-e3bec9802a27_646x413.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/4a553e07-1eb0-4466-9806-e3bec9802a27_646x413.png&quot;,&quot;height&quot;:413,&quot;width&quot;:646,&quot;resizeWidth&quot;:596,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;image.png&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt="image.png"></a><p>ー Drew Houston, CEO and co-founder</p></blockquote><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F8ee5dc69-f6f8-444e-aeb6-74de26e48cc5_418x135.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F8ee5dc69-f6f8-444e-aeb6-74de26e48cc5_418x135.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/8ee5dc69-f6f8-444e-aeb6-74de26e48cc5_418x135.png&quot;,&quot;height&quot;:135,&quot;width&quot;:418,&quot;resizeWidth&quot;:212,&quot;bytes&quot;:13721,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></p><blockquote><p>“With apologies to Justice Potter Stewart, I’ve often felt that Product Market Fit is not unlike hard core pornography: hard to define, but you know it when you see it. <strong>It took us at Netflix 18 months to finally find the repeatable scalable business model that worked</strong>.</p><p>As you know, I called my book "That Will Never Work" because everyone I pitched that original idea had that reaction.&nbsp;(Including my wife!). But they were right. The original idea didn’t work. But hundreds of failed experiments later, and and after many a sleepless night of worrying, we finally tested the unlikely combination of No Due Dates, No Late Fees, and Subscription that ultimately was the thing that ended up working. And boy did it work. <strong>Within days of testing it we knew we had a winner. </strong></p><p><strong>Where before we were struggling to get traffic, all of sudden we couldn’t keep up.  Our previously prodigious amounts of inventory were suddenly not enough.  Engagement soared, churn went dramatically down. Everything started working!</strong></p><p>If there was a moment when Netflix stopped being a start up and became a real company, it was then.”</p><p>ー Marc Randolph, first CEO and co-founder</p></blockquote><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9e84f3c5-f8b3-43c4-913b-19172788cd3b_278x132.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9e84f3c5-f8b3-43c4-913b-19172788cd3b_278x132.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/9e84f3c5-f8b3-43c4-913b-19172788cd3b_278x132.png&quot;,&quot;height&quot;:132,&quot;width&quot;:278,&quot;resizeWidth&quot;:154,&quot;bytes&quot;:6353,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></p><blockquote><p>“Uber never really had a product market fit problem — <strong>zero marketing budget and we were growing like a weed. Word of mouth was uncontrollable</strong>, and especially as regulatory heat started it's all anyone could talk about (is how it felt). Marketing was free because media loved the story.”</p><p>— Ryan Graves, first CEO, founding team</p></blockquote><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9d3925d8-6349-4063-802a-3ed038ca3e69_3600x1200.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9d3925d8-6349-4063-802a-3ed038ca3e69_3600x1200.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/9d3925d8-6349-4063-802a-3ed038ca3e69_3600x1200.jpeg&quot;,&quot;height&quot;:485,&quot;width&quot;:1456,&quot;resizeWidth&quot;:236,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Tinder Review September 2020: Are You Ready to Swipe? - DatingScout.com.au&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt="Tinder Review September 2020: Are You Ready to Swipe? - DatingScout.com.au"></a></p><blockquote><p>“Besides any gut feeling or friend input, I’d say we knew <strong>we had PMF towards the end of December 2012 when downloads started to pick up. By early to mid January 2013 those downloads started to skyrocket</strong>.</p><p>The rise of Tinder was really fast and there were very, very few changes to the product before it had already taken off. The swipe had been added within weeks of launching in August or September 2012. I think we were working on the 2.0 of the app already before we rose but it wasn’t finished or released until we were already spreading like wildfire.”</p><p>ー Jonathan Badeen, co-founder and CSO</p></blockquote><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd5f9b73a-d940-4976-b653-bfb9f40474d2_900x280.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd5f9b73a-d940-4976-b653-bfb9f40474d2_900x280.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/d5f9b73a-d940-4976-b653-bfb9f40474d2_900x280.png&quot;,&quot;height&quot;:280,&quot;width&quot;:900,&quot;resizeWidth&quot;:294,&quot;bytes&quot;:18299,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></p><blockquote><p>“The biggest difference between our ideas pre-PMF vs. when we found <strong>it was this feeling of </strong><em><strong>pull</strong></em>. Before we had any sort of fit, it always felt like we had to push our ideas on other people. We had to nag people to use the product. </p><p><strong>When we hit PMF, we started feeling 'pull' for the first time</strong>. We solved one problem for people... so they started asking us to solve a second, third, fourth, and fifth. Most of our early product iteration was just responding to customer requests.”</p><p>ー Calvin French-Owen, co-founder</p></blockquote><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F3f7bc07f-00ad-4cd0-b100-bfbca3677b29_640x343.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F3f7bc07f-00ad-4cd0-b100-bfbca3677b29_640x343.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/3f7bc07f-00ad-4cd0-b100-bfbca3677b29_640x343.png&quot;,&quot;height&quot;:343,&quot;width&quot;:640,&quot;resizeWidth&quot;:122,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;File:Box, Inc. logo.svg - Wikimedia Commons&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt="File:Box, Inc. logo.svg - Wikimedia Commons"></a></p><blockquote><p>“For us it really felt like Geoffrey Moore's <strong>Inside the Tornado</strong>. Nearly 100% inbound sales because there was sufficient demand to keep the phones ringing.”</p><p>ー Jeffrey Queisser, co-founder and SVP of Engineering</p></blockquote><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F20e15927-d2af-4707-a238-3eb81068f9a2_1280x537.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F20e15927-d2af-4707-a238-3eb81068f9a2_1280x537.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/20e15927-d2af-4707-a238-3eb81068f9a2_1280x537.png&quot;,&quot;height&quot;:537,&quot;width&quot;:1280,&quot;resizeWidth&quot;:170,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;File:Stripe Logo, revised 2016.svg - Wikimedia Commons&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt="File:Stripe Logo, revised 2016.svg - Wikimedia Commons"></a></p><blockquote><p>“What indicated to us that there was something interesting here was that our friends who were using it asked if they could invite their friends, and those people invited their friends, and it <strong>spread through word of mouth process</strong>.</p><p><strong>We just put up a wait list on our site and demand took off, over a couple months we had a huge wait list. We weren’t expecting it.</strong>”</p><p>— Patrick Collison, CEO and co-founder (<a href="https://medium.com/notes-essays-cs183c-technology-enabled-blitzscalin/class-11-notes-essay-reid-hoffman-john-lilly-chris-yeh-and-allen-blue-s-cs183c-technology-ebf34cebae26">source</a>, <a href="http://techzinglive.com/page/939/168-tz-interview-patrick-collison-stripe">source</a>)</p></blockquote><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F72fca2d4-c92e-419e-aad1-724e9a19c3b0_992x394.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F72fca2d4-c92e-419e-aad1-724e9a19c3b0_992x394.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/72fca2d4-c92e-419e-aad1-724e9a19c3b0_992x394.png&quot;,&quot;height&quot;:394,&quot;width&quot;:992,&quot;resizeWidth&quot;:224,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Patreon Png ,HD PNG . (+) Pictures - vhv.rs&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt="Patreon Png ,HD PNG . (+) Pictures - vhv.rs"></a></p><blockquote><p>“For Patreon, it was actually right after we launched with Jack's music video on YouTube video and patrons and creators started writing in.</p><p id="youtube2-mZ02alEkbLw" data-attrs="{&quot;videoId&quot;:&quot;mZ02alEkbLw&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}"><iframe src="https://www.youtube-nocookie.com/embed/mZ02alEkbLw?rel=0&amp;autoplay=0&amp;showinfo=0" frameborder="0" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true"></iframe></p><p><strong>I'd never seen that level of passion and immediate resonance</strong>,&nbsp;and our launch was particularly fraught with stress since weeks before all the creators that were asked to launch rejected&nbsp;us. I actually emailed investors right after this, with a now cringey-esque note: ‘If you recall anything about me, I'm not one to exaggerate or overstate things, but based on the results and response thus far, I really think this company is going to be the one.’”&nbsp;</p><p>— Samuel Yam, co-funder and CTO</p></blockquote><blockquote></blockquote><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F86d436a8-3910-4aba-8fc4-bdbe282dc481_320x158.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F86d436a8-3910-4aba-8fc4-bdbe282dc481_320x158.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/86d436a8-3910-4aba-8fc4-bdbe282dc481_320x158.png&quot;,&quot;height&quot;:158,&quot;width&quot;:320,&quot;resizeWidth&quot;:178,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Carta | Equity Management Solutions - Equity Plans, Cap Tables &amp; 409A&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt="Carta | Equity Management Solutions - Equity Plans, Cap Tables &amp; 409A"></a></p><blockquote><p>“About six months after we launched we changed our phone provider I think to DialPad or RingCentral. We misconfigured the system and for some reason after it prompted the user to "Press #1 for Sales" and the user pressed the button, it would just hang up on the caller. We didn't know about it for three weeks because we were just trying to fill the non-phone orders. </p><p>The way we found out was a prospect was able to contact us through chat support and wrote <strong>"I've been trying to get to your sales people for weeks and you keep hanging up on me!!! Why won't you take my money???" That's what product market fit feels like.</strong>”</p><p>ー Henry Ward, CEO and co-founder</p></blockquote><blockquote></blockquote><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F222d8da0-614d-492f-96f3-ea18f955dc65_2000x665.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F222d8da0-614d-492f-96f3-ea18f955dc65_2000x665.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/222d8da0-614d-492f-96f3-ea18f955dc65_2000x665.png&quot;,&quot;height&quot;:484,&quot;width&quot;:1456,&quot;resizeWidth&quot;:286,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Github Logo Png&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt="Github Logo Png"></a></p><blockquote><p><strong>“</strong>When we launched our private beta (mostly enthusiasts from the Ruby community) we were offering it for free.<strong> To our surprise, users started writing to us asking ‘Can we pay for this??’ They liked it so much they wanted to pay for it. That was the first sign this was going to work.</strong></p><p>Our early users were individuals from the Ruby community. These people already demonstrated they were willing to operate on the cutting edge, Ruby was really new still in 2009. It was critical that we were embedded in that community before then, I don’t think we’d be able to convince people to try GitHub otherwise.</p><p><strong>After we got traction with individuals we were able to expand into SMBs, and then enterprises.”</strong></p><p>— Tom Preston-Werner, first CEO and co-founder</p></blockquote><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F284047ac-81c2-41c5-b751-8e3cc5665165_611x180.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F284047ac-81c2-41c5-b751-8e3cc5665165_611x180.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/284047ac-81c2-41c5-b751-8e3cc5665165_611x180.png&quot;,&quot;height&quot;:180,&quot;width&quot;:611,&quot;resizeWidth&quot;:321,&quot;bytes&quot;:22984,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></p><blockquote><p>“I remember distinctly it was a Friday night. We had been working on the wait list in preparation for our press launch, which would have been, I think, the following Wednesday or Thursday. Everyone goes home, and I wake up Saturday …</p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.lennyrachitsky.com/p/what-it-feels-like-when-youve-found">https://www.lennyrachitsky.com/p/what-it-feels-like-when-youve-found</a></em></p>]]>
            </description>
            <link>https://www.lennyrachitsky.com/p/what-it-feels-like-when-youve-found</link>
            <guid isPermaLink="false">hacker-news-small-sites-24629624</guid>
            <pubDate>Tue, 29 Sep 2020 16:13:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Self hosted GitHub Actions runners in Kubernetes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24629532">thread link</a>) | @SkyLinx
<br/>
September 29, 2020 | https://vitobotta.com/2020/09/29/self-hosted-github-actions-runners-in-kubernetes/ | <a href="https://web.archive.org/web/*/https://vitobotta.com/2020/09/29/self-hosted-github-actions-runners-in-kubernetes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
        <article>
          <header>
  <span>
    
  </span>

  
  
  
    
	
  
  
    <div>
      
      <p>
        , &nbsp;published <time>Tuesday, Sep 29 2020</time>
      </p>
    </div>

    <p>
      Published &nbsp; <time>Tuesday, Sep 29 2020</time>
    </p>
 	
  
  
</header>

          <!--<div class="mt-8 sharethis-inline-share-buttons"></div>-->
          <section>
            
<div>
<p>Since August last year,<b>&nbsp;<a href="https://github.com/features/actions" target="_blank">Github Actions</a></b>&nbsp;has evolved into a complete solution to build pipelines for CI/CD, as well as a wide variety of other automation tasks. It's not always been the most reliable CI/CD&nbsp;solution available, but the service has improved a lot over time and it's a reasonably good option now. Writing YAML&nbsp;<i>﻿workflows</i>﻿ for Github Actions is pretty easy, and you get 2000 minutes of usage of Github's hosted runners included with the free Github plan, which is plenty for small teams. After that, pricing is affordable and competitive compared to that of other solutions in the market.</p>
<p>Besides the ease of use and the overall good design, one thing I particularly like is that you can also self host Github Actions runners in your own infrastructure for absolutely no cost. It's totally free, and you can use as beefy servers for this as you like, which can translate in better performance when executing workflows compared to Github's own runners which only have 2 cores and 7 GB of memory. Self hosted runners allow for greater control, making workflows more flexible. Also, if your workflows build Docker images, you need some workarounds to benefit from layer caching with Github's own runners since each time a workflow runs a brand new environment is spun up, so images built with previous runs are not cached out of the box. By using a self hosted runner instead, you can choose to use the same Docker instance across workflow runs, so new workflow runs can leverage layers cached in previous builds, which can dramatically speed up the execution.</p>
<p>I have been using a self hosted runner for Github Actions for a little while now, but while until recently I was using a VPS dedicated to the job, I am now leveraging some spare capacity in my Kubernetes cluster for this purpose to build, test and deploy <b>﻿<a href="https://www.dynablogger.com/" target="_blank">DynaBlogger</a></b>; this post is about how to set up self hosted runners for Github Actions in Kubernetes for workflows that require building Docker images. I'll assume you are already familiar with how Github Actions work.</p>
<p>There are various ways to build Docker images inside a Kubernetes cluster, but perhaps the easiest is with the&nbsp;<b>﻿"Docker in Docker</b>﻿" approach available with the <a href="https://hub.docker.com/_/docker" target="_blank">official Docker image</a>&nbsp;- it's basically the ability to run a Docker daemon inside a container and you can run the usual build commands as if you ran these commands directly on the actual host. We'll need a deployment of&nbsp;Docker in Docker ("dind") as well as a deployment of an image containing all the required dependencies to run self hosted runners for Github Actions which will leverage the dind deployment. This has a couple of important benefits:</p>
<ul>
<li>we can use a persistent volume for dind, so to benefit from layer caching across multiple workflow runs</li>
<li>we can easily scale runners by just scaling the deployment, allowing for multiple workflows to be executed in parallel.</li>
</ul>
<h2>Setting up the Docker in Docker deployment</h2>
<p>For dind we'll use a regular Kubernetes deployment and the&nbsp;<i>﻿dind</i>﻿ version of the official Docker image. First things first, you'll need to create a namespace - I name this namespace as&nbsp;<i>﻿docker-in-docker</i>﻿:<i></i><i></i></p>
<pre><code>kubectl create ns docker-in-docker</code></pre>
<p>Next, we need to create a persistent volume claim (pvc) in this namespace that dind will use to persist the Docker layers even if the pod is rescheduled for any reason:</p>
<pre><code>apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: dind
  namespace: docker-in-docker
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 50Gi

</code></pre>
<p>I am creating a volume of 50GB&nbsp;here since that should be enough for me (I can just exec into the container and prune images if needed every now and then), but you are free to create a larger or smaller volume.</p>
<p>Like I said for dind we'll need a regular deployment, so create&nbsp;<i>﻿deployment-dind.yml</i>﻿ with<i></i>&nbsp;the following:</p>
<pre><code>apiVersion: apps/v1
kind: Deployment
metadata:
  name: dind
  namespace: docker-in-docker
spec:
  replicas: 1
  selector:
    matchLabels:
      workload: deployment-docker-in-docker-dind
  template:
    metadata:
      labels:
        workload: deployment-docker-in-docker-dind
    spec:
      containers:
      - command:
        - dockerd
        - --host=unix:///var/run/docker.sock
        - --host=tcp://0.0.0.0:2376
        env:
        - name: DOCKER_TLS_CERTDIR
        image: docker:19.03.12-dind
        imagePullPolicy: IfNotPresent
        name: dind
        resources: {}
        securityContext:
          privileged: true
          readOnlyRootFilesystem: false
        stdin: true
        tty: true
        volumeMounts:
        - mountPath: /var/lib/docker
          name: dind-storage
      volumes:
      - name: dind-storage
        persistentVolumeClaim:
          claimName: dind</code></pre>
<p>A few things to note here:</p>
<ul>
<li>we are setting the command explicitly because by default dind will run with TLS for the connections between the daemon and the clients. You can either leave the command unset to use TLS or override it to ignore TLS to make things a bit easier, it's up to you. I choose to disable TLS for this. Besides specifying a command without the default TLS arguments, we also need to set the&nbsp;<i>﻿DOCKER_TLS_CERTDIR</i>﻿ environment variable to an empty string;&nbsp;</li>
<li>the image we are using is the latest docker image with the&nbsp;<i>﻿dind</i>﻿ tag, so to be able to make the Docker daemon available to remote clients;</li>
<li>I am leaving the resources unset in this cluster, but since CPU-intensive workflows might use a lot of CPU, you may want to set some limits here;</li>
<li>finally, we are making sure that the pod can use the persistent volume claim we created earlier.<br>
</li>
</ul>
<p>To deploy, run:</p>
<pre><code>kubectl apply -f deployment-dind.yml</code></pre>

<h2>Setting up the Github Actions runners' deployment</h2>
<p>The next thing we need to do, is set up the deployment for the actual runners. I found a few different ways to do this, but the easiest for me was using&nbsp;<a href="https://github.com/SanderKnape/github-runner" target="_blank">this repo</a>&nbsp;since it already includes a useful Dockerfile as well as a sample deployment manifest for kubernetes. So go ahead and clone the repository, then open the&nbsp;<i>﻿Dockerfile</i>﻿ in your editor.&nbsp;</p>
<p>The Dockerfile installs the dependencies required by Github Actions to connect the runner to the Github Actions service, so that the runner can listen for jobs and report progress to Github. We can build a custom image using this Dockerfile and that's what we'll do in order to make using the dind instance possible. In particular we need to add the following to the&nbsp;<i>﻿apt install</i>﻿ command:</p>
<pre><code>    &amp;&amp; curl https://download.docker.com/linux/static/stable/x86_64/docker-19.03.9.tgz --output docker-19.03.9.tgz \
    &amp;&amp; tar xvfz docker-19.03.9.tgz \
    &amp;&amp; cp docker/* /usr/bin/</code></pre>
<p>The final Dockerfile will look something like the following:</p>
<pre><code>FROM debian:buster-slim

ARG GITHUB_RUNNER_VERSION="2.273.4"

ENV RUNNER_NAME "runner"
ENV GITHUB_PAT ""
ENV GITHUB_OWNER ""
ENV GITHUB_REPOSITORY ""
ENV RUNNER_WORKDIR "_work"
ENV RUNNER_LABELS ""
ENV DOCKER_HOST="tcp://docker-in-docker.dind:2376"

RUN apt-get update \
    &amp;&amp; apt-get install -y \
        curl \
        sudo \
        git \
        jq \
        iputils-ping \
    &amp;&amp; apt-get clean \
    &amp;&amp; rm -rf /var/lib/apt/lists/* \
    &amp;&amp; useradd -m github \
    &amp;&amp; usermod -aG sudo github \
    &amp;&amp; echo "%sudo ALL=(ALL) NOPASSWD:ALL" &gt;&gt; /etc/sudoers \\
    &amp;&amp; curl https://download.docker.com/linux/static/stable/x86_64/docker-19.03.9.tgz --output docker-19.03.9.tgz \
    &amp;&amp; tar xvfz docker-19.03.9.tgz \
    &amp;&amp; cp docker/* /usr/bin/

USER github
WORKDIR /home/github

RUN curl -Ls https://github.com/actions/runner/releases/download/v${GITHUB_RUNNER_VERSION}/actions-runner-linux-x64-${GITHUB_RUNNER_VERSION}.tar.gz | tar xz \
    &amp;&amp; sudo ./bin/installdependencies.sh

COPY --chown=github:github entrypoint.sh ./entrypoint.sh
RUN sudo chmod u+x ./entrypoint.sh

ENTRYPOINT ["/home/github/entrypoint.sh"]
</code></pre>
<p>One important thing to note here is that whenever there is a new release of the runner's software, we'll need to rebuild our image and update the deployment. The reason is that the runner itself will listen not only to jobs for workflows to run, but also to notifications whenever a new version of its software is available, which triggers a download of the new software followed by a restart of the runner. Of course, in Kubernetes this will cause the pod to restart, and then the runner will download the new software and restart again, causing a crash loop. To prevent that, I recommend you watch <a href="https://github.com/actions/runner" target="_blank">the runner's code repo</a>&nbsp;so you get notified when a new version is available, and can rebuild the image.</p>
<p>Next, go ahead and build the image, then push it to your registry of choice. If you don't need to change anything in the Dockerfile, you can just use the image I prebuilt and published on Docker Hub,&nbsp;<i>vitobotta/github-actions-runner:0.0.4</i>.<i>﻿</i></p>
<p>You don't need to change anything in the <i>entrypoint.sh</i> script, which simply installs the runner's software. However you need to make a few small changes to the deployment manifest <i>deployment.yml&nbsp;</i>﻿so that it looks like the following:</p>
<pre><code>apiVersion: apps/v1
kind: Deployment
metadata:
  name: github-runner
  namespace: github-actions
  labels:
    app: github-runner
spec:
  replicas: 1
  selector:
    matchLabels:
      app: github-runner
  template:
    metadata:
      labels:
        app: github-runner
    spec:
      containers:
      - name: github-runner
        image: vitobotta/github-actions-runner:0.0.4
        env:
        - name: DOCKER_HOST
          value: tcp://dind.docker-in-docker:2376
        - name: GITHUB_OWNER
          value: &lt;your github username&gt;
        - name: GITHUB_REPOSITORY
          value: &lt;your repository&gt;
        - name: GITHUB_PAT
          valueFrom:
            secretKeyRef:
              name: github-actions-token
              key: pat
</code></pre>
<p>As you can see we set the&nbsp;<i>﻿DOCKER_HOST</i>﻿ to our dind pod. …</p></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vitobotta.com/2020/09/29/self-hosted-github-actions-runners-in-kubernetes/">https://vitobotta.com/2020/09/29/self-hosted-github-actions-runners-in-kubernetes/</a></em></p>]]>
            </description>
            <link>https://vitobotta.com/2020/09/29/self-hosted-github-actions-runners-in-kubernetes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24629532</guid>
            <pubDate>Tue, 29 Sep 2020 16:07:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Redis TLS was a big hit to performance – a look at how KeyDB addressed it]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24629370">thread link</a>) | @benschermel
<br/>
September 29, 2020 | https://docs.keydb.dev/blog/2020/09/29/blog-post/ | <a href="https://web.archive.org/web/*/https://docs.keydb.dev/blog/2020/09/29/blog-post/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span><div id="blog_body">
<p>We were extremely excited about TLS (Transport Layer Security) support which arrived in the ‘6.0’ versions of Redis and KeyDB. TLS database connections are part of a continuing trend towards defense in depth which has been a long time in the making, first starting with <a href="https://arstechnica.com/information-technology/2013/11/googlers-say-f-you-to-nsa-company-encrypts-internal-network/">google encrypting links</a> between their datacenters in 2013.</p>
<p>Unfortunately with Redis, TLS came with a big hit to performance ranging from 36-61%. While security is important, making a trade-off with performance may not always be a viable compromise. We thought carefully about the TLS implementation in KeyDB to try and prevent our users from experiencing this. By taking advantage of KeyDB’s multithreaded architecture we were able to maintain performance achieving nearly 1M ops/sec which was over 7X faster than the Redis TLS implementation.</p>
<!--truncate-->
<p>For those who may not be aware, <a href="https://github.com/JohnSully/KeyDB">KeyDB</a> is an open source project and compatible with Redis API, protocol and clients.</p>
<h2>An Analysis of TLS Perf by Redis</h2>
<p>I was recently looking through a detailed <a href="https://github.com/redis/redis/issues/7595">github issue response</a> by a RedisLabs performance engineer . He did a great job analyzing CPU holdup &amp; performance degradation when using TLS.</p>
<p>Here he suggests there is approximately a 36% drop in ops/sec with single threaded performance. In his analysis he states “TLS involves another layer in the stack, that brings additional overhead. The added SSL/TLS stack implies 28% CPU time devoted to it ( writing/reading bytes from ssl connetion, encrypt/decrypt and integrity check” … “Based on the flame graphs they moved from spending 17% on the handler to spending 45% of the CPU time with tls.”</p>
<p>Redis currently does not support using io-threads per their <a href="https://github.com/redis/redis/blob/unstable/TLS.md#connections">docs</a>.
RedisLabs <a href="https://docs.redislabs.com/latest/rs/administering/designing-production/security/client-connections/">documentation</a> also warns that  “TLS encryption can significantly impact database throughput and latency”</p>
<h2>A Comparison of Redis, TLS and Multithreaded KeyDB</h2>
<h3>Benchmarking Ops/sec</h3>
<p>Running tests of our own, we saw the same results (36% decline) to those stated by Redis for a single node. We will also include a comparison with Redis io-threads and how KeyDB performs with TLS enabled. This test looks at performance of a single node. Tests were done on AWS m5 instances of adequate size to ensure the machines were not a bottleneck.</p>
<p>The tests below were performed using memtier on a m5.8xlarge with the following command:</p>
<pre><code>$ memtier_benchmark --hide-histogram --tls <span>--cert</span>=/path/to/redis.crt <span>--key</span>=/path/to/tls/redis.key <span>--cacert</span>=/path/to/tls/ca.crt -s 172.31.56.132 <span>--threads</span>=32
</code></pre>
<p>KeyDB and Redis were operated on a m5.4xlarge. To see more details on setup for reproducing benchmarks please see the end of this blog.</p>
<p><img src="https://docs.keydb.dev/img/blog/2020-09-15/ops_comparison.png" alt="image"></p>
<p>You will see that our testing shows the same measured decline of 36%  with TLS enabled on Redis6 (single threaded). However if you were previously using the io-thread feature, you could see a 61% drop in performance as io-threads is not supported using TLS. This is stated in  <a href="https://github.com/redis/redis/blob/unstable/TLS.md#connections">TLS.md</a></p>
<h3>Why KeyDB perf does not decline</h3>
<p>With KeyDB there is almost no decline using TLS as multithreading is supported and it can scale vertically. The performance remains considerably higher in general due to architectural difference between the projects. There are considerably more CPU resources used with TLS, but that is something KeyDB is great at accounting for.</p>
<p>With 8 threads allocated, we were hitting closer to 800K ops/sec vs 1M ops/sec without TLS. However increasing threadcount as high as 16 threads enabled us to get back up to near the 1M ops/sec mark.</p>
<p>This enables us to compensate to the load and still offer the security without the penalty to performance for our users who rely on the perf.</p>
<h3>Latency Benchmark (lower is better)</h3>
<p>Similar trends can be seen in the latency measurements of the same test performed above. You can see that latency is significantly higher at these loads when using TLS. KeyDB not only serves at very high volumes, but the latency is also up to 7x lower that Redis with TLS. It can be noted latencies measured with memtier are pushing peak loads and when not heavily loaded will achieve much lower latencies. This should be taken as a relative comparison under load.</p>
<p><img src="https://docs.keydb.dev/img/blog/2020-09-15/latency_comparison.png" alt="image"></p>
<h3>Flamegraphs</h3>
<p>In the RedisLabs analysis they provided flamegraphs for context. For those interested we ran flame graphs on Redis 6, Redis 6 with io-threads, Redis 6 + TLS, KeyDB and KeyDB + TLS. Full expandable breakdowns can be seen by following the links below the charts.</p>
<p><img src="https://docs.keydb.dev/img/blog/2020-09-15/flamegraphs.PNG" alt="image"></p>
<p>Links to complete expandable flamegraphs:</p>
<ul>
<li><a href="https://download.keydb.dev/blog-2020-09-15/redis-fg.svg">Redis (single-threaded)  </a></li>
<li><a href="https://download.keydb.dev/blog-2020-09-15/redis-iothreads8-fg.svg">Redis with io-threads</a></li>
<li><a href="https://download.keydb.dev/blog-2020-09-15/redis-tls-fg.svg">Redis with TLS enabled</a></li>
<li><a href="https://download.keydb.dev/blog-2020-09-15/keydb-fg.svg">KeyDB (Multithreaded)    </a></li>
<li><a href="https://download.keydb.dev/blog-2020-09-15/keydb-tls-fg.svg">KeyDB with TLS enabled (multithreaded)</a></li>
</ul>
<h2>Conclusion</h2>
<p>TLS encryption is a great option when it comes to security, however if you are currently using Redis this may come with a performance penalty. If you are not heavily loading Redis you may be able to handle the additional overhead, but its something that should be taken into account.</p>
<p>To summarize performance:</p>
<ul>
<li>Redis with TLS experienced a 36% drop from single threaded Redis, and a 61% drop compared to using Redis with io-threads enabled.</li>
<li>KeyDB achieved close to 1 million ops/sec with little to no performance drop after adding additional threads</li>
<li>KeyDB got close to 1 million ops/sec with TLS enabled, while Redis got ~130k ops/sec</li>
</ul>
<p>Options for Redis users to increase performance would come in the form of sharding or increasing cluster size. KeyDB can also be used as a drop in replacement for the Redis binary.</p>
<p>KeyDB comes in at over 7X faster than Redis when using TLS. It may be a viable alternative when using this feature if performance is an issue for you.</p>
<h2>Find out More:</h2>
<ul>
<li><a href="https://github.com/JohnSully/KeyDB">KeyDB open source project on github</a></li>
<li><a href="https://keydb.dev/">Website</a></li>
<li><a href="https://eqalpha.us20.list-manage.com/subscribe/post?u=978f486c2f95589b24591a9cc&amp;id=4ab9220500">Subscribe to Mailing List</a>
<i></i></li><i>
</i></ul><p><i>
<h2>Reproducing benchmarks:</h2>
<p>For benchmark testing, an aws m5.8xlarge was needed as the benchmarking machine which used memtier as the benchmark tool. For the Redis/KeyDB instance a m5.4xlarge was used. Machine size selection was based off terminal performance ensuring the machine was not the bottleneck. A larger machine size would not make a difference in results, however a smaller machine may result in lower throughput.</p>
<p>If you are using TLS for the first time you can generate certificates simply cloning the github project and running <code>./utils/gen-test-certs.sh</code> to create the certificates for Redis or KeyDB.</p>
<p>You can now run keydb-server with the following command:</p>
<pre><code>$ keydb-server <span>--tls-port</span> 6379 <span>--port</span> 0 <span>--tls-cert-file</span> <span>./tests/tls/redis.crt</span> <span>--tls-key-file</span> <span>./tests/tls/redis.key</span> <span>--tls-ca-cert-file</span> <span>./tests/tls/ca.crt</span> <span>--server-threads</span> 16 <span>--server-thread-affinity</span> <span>true</span> <span>--protected-mode</span> no
</code></pre>
<p>For Redis we ran the following command:</p>
<pre><code>$ redis-server <span>--tls-port</span> 6379 <span>--port</span> 0 <span>--tls-cert-file</span> <span>./tests/tls/redis.crt</span> <span>--tls-key-file</span> <span>./tests/tls/redis.key</span> <span>--tls-ca-cert-file</span> <span>./tests/tls/ca.crt</span> <span>--protected-mode</span> no
</code></pre>
<p>In order to use memtier to connect via TLS ensure you transfer the ./test/tls/* files over to the benchmarking machine. You can the run the following command:</p>
<pre><code>$ memtier_benchmark --hide-histogram --tls <span>--cert</span>=/path/to/redis.crt <span>--key</span>=/path/to/tls/redis.key <span>--cacert</span>=/path/to/tls/ca.crt -s 172.31.56.132 <span>--threads</span>=32
</code></pre>
<p>For tests without TLS, the following commands were used:
KeyDB:</p>
<pre><code>$ keydb-<span>server</span> –-<span>server</span>-threads <span>10</span> –-<span>server</span>-thread-affinity <span>true</span> –-<span>protected</span>-mode no 
</code></pre>
<p>Redis:</p>
<pre><code>$ redis-server -–io-threads <span>8</span> –-<span>protected</span>-mode no
</code></pre>
<p>Memtier:</p>
<pre><code>$ memtier_benchmark -s <span>172.31</span><span>.56</span><span>.132</span> --hide-histogram  –-threads=<span>32</span> 
</code></pre>
<h3>Avoid bottlenecks</h3>
</i></p><ul><i>
<li>Because of KeyDB’s multithreading and performance gains, we typically need a much larger benchmark machine than the one KeyDB is running on. We have found that a 32 core m5.8xlarge is needed to produce enough throughput with memtier. This supports throughput for up to a 16 core KeyDB instance (medium to 4xlarge)</li>
<li>When using Memtier run 32 threads.</li>
<li>Run tests over the same network. If comparing instances, make sure your instances are in the same area zone (AZ). Ie both instances in us-east-2a</li>
<li>Run with private IP addresses. If you are using AWS public IPs there can be more variance associated with the network</li>
<li>Beware running through a proxy or VPC. When using such methods, firewalls, and additional layers it can be difficult to know for sure what might be the bottleneck. Best to benchmark in a simple environment (within same vpc) and add the layers afterwards to make sure you are optimized.</li>
<li>When comparing different machine instances ensure they are in the same AZ and tested as closely as possible in time. Network throughput throughout the day does change so performing tests close to eachother provides the most representative relative comparison.</li>
</i><li><i>KeyDB is multithreaded. Ensure you specify multiple threads when running
</i></li>
</ul>
</div>
</span></p></div></div></div>]]>
            </description>
            <link>https://docs.keydb.dev/blog/2020/09/29/blog-post/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24629370</guid>
            <pubDate>Tue, 29 Sep 2020 15:56:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Music Is Helpful for Concentration]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 14 (<a href="https://news.ycombinator.com/item?id=24629356">thread link</a>) | @pavelegorkin
<br/>
September 29, 2020 | https://tinnire.app/blog/why-music-is-helpful-for-concentration/ | <a href="https://web.archive.org/web/*/https://tinnire.app/blog/why-music-is-helpful-for-concentration/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Discover the best music for focusing. Read the article to learn how to improve the efficiency of your work.</p>
    <h2>Content</h2>
    <ol>
        <li>What is concentration?</li>
        <li>Ways to improve focus and concentration</li>
        <li>What kind of music disrupts focusing</li>
        <li>Flow state music</li>
    </ol>

    <h2>What is Concentration?</h2>

    <p>There are several meanings of the word concentration. If we talk about focusing attention, then this is keeping the interest on one aspect while ignoring other things.</p>
    <p>In English language, this word came in the 1630s <a href="https://www.etymonline.com/word/concentrate?ref=etymonline_crossreference#etymonline_v_17305" target="_blank">from Italian</a> <i>concentrare</i>. Its origin is Latin: <i>com</i> ‘with, together’ + <i>centrum</i> ‘center’. This literally means ‘action of bringing to a central point’.</p>
    <p>Our ability to concentrate is important because the human body has limited resources. If we work being constantly distracted, then we will not be able to complete the task.</p>
    <p>Since ancient times, people have developed various techniques to stay focused. Let's dwell on the most popular methods.</p>

    <h2>Ways to Improve Focus and Concentration</h2>
    <ul>
        <li>
            <b>Choose the most productive working hours.</b> The early birds and late rasers have their peaks of activity at completely different times of the day. So, for the top-priority tasks, choose the time according to your individual characteristics.
        </li>
        <li>
            <b>Minimize the number of simultaneous tasks.</b> Scientists at <a href="https://news.stanford.edu/news/2009/august24/multitask-research-study-082409.html" target="_blank">Stanford University</a> have found that multitasking lowers human performance. Therefore, you should reduce the number of tasks and focus on one or two.
        </li>
        <li>
            <b>Make a clear plan and stick to it.</b> Until you complete one of the items, do not pay attention to anything else. Between plan items, you can take small breaks and change in the type of activity. If you are a computer worker, look out of the window or do a few push-ups.
        </li>
        <li>
            <b>Avoid checking your email and phone at work.</b> According to the
            <a href="http://www.fieldworksmarketing.co.uk/wellness/how-to-reduce-stress-for-international-stress-awareness-week/" target="_blank">International Journal of Information Management</a>, it takes us approximately 64 seconds to come back to the working process after checking email. If your job is not directly related to making calls and writing letters, put the phone away. Adopt a rule to check email and messengers before work and after work. Mute all notifications the rest of the time.
        </li>
        <li>
            <b>Use background music for concentration or white noise.</b> If you can't find a quiet place to work, you can use background sounds to drown out any distracting noises and keep your attention on the main thing.
        </li>
    </ul>
    <p>However, it happens that music does not help to focus. Let's find out why.</p>

    <h2>What Kind of Music Disrupts Focusing</h2>

    <p>Loud or fast-paced music. In general, any soundtrack that grabs your attention distracts you from your work. Dance music is created with the intention of fascinating you, creating a sense of celebration and encouraging you to dance.</p>
    <p>At the same time, if you put a song that you actively dislike, it will also not help your concentration, because you will think about your feelings.</p>
    <p>Songs with lyrics or commercials are also a bad choice for focusing. The brain will try to understand and process the text it hears.</p>

    <h2>Flow State Music</h2>
    <p>There is a particular type of music that is specifically designed to help you focus as much as possible. It calls flow state music.</p>
    <p>The term <i>flow state</i> was coined by the American psychologist <a href="https://en.wikipedia.org/wiki/Mihaly_Csikszentmihalyi" target="_blank">Mihaly Csikszentmihalyi</a>. He described this state as a maximum motivation and focusing on completing work. A person in the flow state feels freedom, joy and total satisfaction.</p>
    <p>Probably anyone who has been doing what they love has experienced the flow state. The Tinnire App offers an endless amount of music tracks that will help you stay in this state all day long. This AI-assisted music has been created specifically for concentrating. Visit
        the <a href="https://tinnire.app/">Tinnire website</a> and try it for free.</p>

</div></div>]]>
            </description>
            <link>https://tinnire.app/blog/why-music-is-helpful-for-concentration/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24629356</guid>
            <pubDate>Tue, 29 Sep 2020 15:55:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cloud-Native Security has Two R’s, not Three]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24629352">thread link</a>) | @hobbiton
<br/>
September 29, 2020 | https://dr-knz.net/cloud-native-security-containers.html | <a href="https://web.archive.org/web/*/https://dr-knz.net/cloud-native-security-containers.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
            <p>This article explains how I stopped a software vendor and at least one of its
customers from hemorraging $50K+ yearly due to unnecessary&nbsp;costs.</p>
<p>❦❦❦</p>
<p>A recommended best practice in Enterprise security is the “three R’s”:
Repair, Repave and Rotate <a href="https://builttoadapt.io/the-three-r-s-of-enterprise-security-rotate-repave-and-repair-f64f6d6ba29d?gi=428524632f99">[1]</a> <a href="https://thenewstack.io/why-wells-fargo-repaves-its-entire-platform-every-day/">[2]</a> <a href="https://tanzu.vmware.com/cloud-native-security">[3]</a>.</p>
<p>Repair means applying security patches as soon as available. Rotate
means rotating credentials often. Those two are useful and, at this
stage of our industry, necessary for good security&nbsp;hygiene.</p>
<p>The third R, “Repave,” meaning “bring back the software image to a
known state” is popular but, it is my argument today, <em>useless</em>—in a
truly cloud-native world, it is not&nbsp;needed.</p>
<p>That’s it!  Save money, use <em>immutable containers</em>, don’t&nbsp;repave.</p>
<p>End of&nbsp;story.</p>
<p>(<em>Repair,</em> on the other hand, remains absolutely relevant: container
images do contain <em>outdated</em> software, especially the base
image—libraries, run-time systems, etc. Folk who use containers should
regularly rebuild their container images to include the latest
security patches. But that is a story for another&nbsp;time.)</p>
<p>❦❦❦</p>
<p>I could be writing an article about the technicalities of <em>why</em>
repaving is not&nbsp;needed.</p>
<p>I could be explaining how repaving was invented for a world where
software was <em>installed</em> anew upon every new deployment by mutating an
<span>OS</span> image using an installation program, how the system image remained
mutable afterwards, and therefore how a risk remained for hackers to
install malware on top of&nbsp;it.</p>
<p>I could be explaining how FreeBSD <a href="https://en.wikipedia.org/wiki/FreeBSD_jail">Jails</a> (2000), Solaris <a href="https://en.wikipedia.org/wiki/Solaris_Containers">Zones</a>
(2004), and <a href="https://en.wikipedia.org/wiki/Docker_(software)">Docker</a> (2013) have been <em>specifically</em> designed and
implemented to support immutable filesystem mounts, with all
executable code and configuration “baked in” so that no amount of
bugs, mistakes or hackers can ever <em>change</em> the software within the
container and make it diverge from a known-good&nbsp;state.</p>
<p>I could also glaringly point out that software deployed <em>today</em> in
clouds comes most often as immutable containers, and thus that this form of
<em>cloud-native software</em>, once deployed, can never change—<em>by
construction</em>.</p>
<p>I could then conclude that requests from enterprise-y customers for
<em>procedures</em> and/or <em>processes</em> to “repave” a container-based software
deployment are, at best, <em>meaningless</em>; and in truth, <em>just a way to
throw good money after bad</em>.</p>
<p>The Enterprise mindset is to continue to do something long after it is not
needed any more. News at 11! <em>How is that even an interesting story to write&nbsp;about?</em></p>
<p>❦❦❦</p>
<p>The <em>real</em> story here is how a software vendor (who shall remain
nameless) got roped into spending significant effort over about a
year, and thus extremely significant $$$$, to entertain a
“repaving” story for container-based deployments, without anybody
realizing what was going&nbsp;on.</p>
<p>This story is not even very long, but it is <em>instructive</em>.</p>
<p>The story begins as follows: a customer says “I need a repaving
procedure.” Vendor assumes that the customer is installing on bare
metal or in a <span>VM</span>. Vendor obliges and start a year-long initiative to
ensure that the software behaves properly when reinstalled from
scratch. This was a complex project technically because the software
had to remain online while the repaving took&nbsp;place.</p>
<p>Then <em>someone</em> comes in and listens to a report about that customer’s
deployments and learns that the customer is really using <a href="https://en.wikipedia.org/wiki/Kubernetes">Kubernetes</a>
and deploys their software as immutable&nbsp;containers.</p>
<p><em>Huh</em>?</p>
<p>It turns out&nbsp;that:</p>
<ul>
<li>customer was saying “I need repaving” to one person,
and did not mention their use of containers to that
person. This first person did not <em>ask</em> about containers&nbsp;either.</li>
<li>Meanwhile, the customer was saying “I use containers” to <em>another</em> person.
The second person was not involved in the repaving&nbsp;story.</li>
</ul>
<p>And so two folk at the vendor did not connect the dots, and the
organization spent a minimum of $50k (I estimate $70k-$100k) in
combined hours from 4 departments to solve a problem that did not need
solving. Classic&nbsp;miscommunication.</p>
<p>(Also, did I mention that this vendor <em>recommends containers</em> as their
primary deployment mechanism, and their own <em>business strategy</em>
revolves around containers? That the repaving story even got traction
internally, given that business focus, astounds&nbsp;me.)</p>
<p>❦❦❦</p>
<p>To me personally, what is painful to admit is that I was listening on
both sides of the story for that entire year and it took me awfully
too long to connect the&nbsp;dots.</p>
<p>I would really like to be able to defend myself and say that the
customer was a large organization, and thus that I was <em>assuming</em> that
there were really two different groups of users, one using containers
and one using bare metal / VMs and repaving. But that was just that—an
<em>assumption</em>, and it was my job to check that assumption, and I did&nbsp;not.</p>
<p>❦❦❦</p>
<p>What is the lesson&nbsp;here?</p>
<ul>
<li><p>At a very minimum, when a customer says “I need something” a vendor
should probably ask&nbsp;“why”.</p>
</li>
<li><p>Then, if the reason given is security-related, the vendor should
probably ask a <em>security expert</em> to verify any&nbsp;assumptions.</p>
</li>
<li><p>Then, assuming a security expert is involved in the discussion, the
expert would ask about, then take into account, the entire customer’s
deployment practices to evaluate the problem to solve,
in a <em>holistic</em>&nbsp;manner.</p>
<p>This way, lateral knowledge about the customer’s practices would
surface, and could be used to point out that the “something” being
asked is&nbsp;redundant.</p>
</li>
</ul>
<p>And, of course, the obvious: security “best practices”
should not be implemented without understanding the <a href="https://dr-knz.net/stride-threat-model-with-examples.html">threat model</a>.</p>
<p>Repaving is not needed with immutable&nbsp;containers.</p>



             




 
                <hr>
    <p><a href="https://dr-knz.net/#about-the-author" target="_blank" rel="nofollow noopener noreferrer">
            <img src="https://dr-knz.net/images/avatars/cat.jpg" alt="Raphael ‘kena’ Poss Avatar" title="Raphael ‘kena’ Poss">
            
        </a>
        is a computer scientist and software engineer specialized in compiler construction, computer architecture, operating systems and databases.
    </p>

            







<section>
    
    

    
</section>

            <hr>
<section>
    <h2>Keep Reading</h2>

<hr>
</section>
            
        </div></div>]]>
            </description>
            <link>https://dr-knz.net/cloud-native-security-containers.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24629352</guid>
            <pubDate>Tue, 29 Sep 2020 15:55:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CockroachDB Code Commenting Guidelines]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24629333">thread link</a>) | @knz42
<br/>
September 29, 2020 | https://wiki.crdb.io/wiki/spaces/CRDB/pages/914260289/Code+commenting+guidelines | <a href="https://web.archive.org/web/*/https://wiki.crdb.io/wiki/spaces/CRDB/pages/914260289/Code+commenting+guidelines">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://wiki.crdb.io/wiki/spaces/CRDB/pages/914260289/Code+commenting+guidelines</link>
            <guid isPermaLink="false">hacker-news-small-sites-24629333</guid>
            <pubDate>Tue, 29 Sep 2020 15:54:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New homeowner 'freaked out' when stranger took control of her security system]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24629254">thread link</a>) | @joeyespo
<br/>
September 29, 2020 | https://www.cbc.ca/news/business/security-system-app-homeowner-stranger-1.5733444 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/business/security-system-app-homeowner-stranger-1.5733444">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>A new homeowner discovers a stranger can disarm the alarm, unlock windows and doors and track when she comes and goes from her new house. Security and privacy experts say the situation is the result of weak laws and cancellation policies written to benefit companies instead of protecting customers.</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5733519.1600744704!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/taylor-fornell.jpg"></p></div><figcaption>Taylor Fornell had been living in her new home in Stony Plain, Alta., for several weeks before discovering someone she'd never met could control her home security system.<!-- --> <!-- -->(Art Raham/CBC)</figcaption></figure><p><span><p>The message came out of the blue for Taylor Fornell. A stranger told her he had complete control over the home security system in her new house in Stony Plain, Alta., and could prove it.</p>  <p>As she stood alone in her front hall, she watched in disbelief as the man unarmed the system, unlocked doors and windows and&nbsp;told her he could track&nbsp;when she left the house&nbsp;— all with a few clicks on the security company's app.</p>  <p>"I felt a little sick to my stomach … It's just really creepy and a breach of trust," Fornell told Go Public, referring to Vivint, the security company that installed and ran the system.</p>  <p>Fornell was lucky. The stranger who connected&nbsp;with her on Facebook was the former owner of the house.</p>  <p>Rob Hall wanted to warn her he still had control over the security system, despite asking the company to cancel the service weeks before Fornell moved in.</p>  <p>Security and privacy experts say the situation is the result of weak laws and cancellation policies that are written to boost companies' bottom lines instead of protecting customers.</p>  <p>"It's so frustrating that consumers should have to be the ones to pick up the slack on how to protect their privacy. It's outrageous," said&nbsp;privacy advocate and former Ontario privacy commissioner Ann Cavoukian.</p>  <p>She said security companies should be required to cancel their services as soon as "you depart from the home, should you sell it or something."</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5334357.1600801578!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/ann-cavoukian.jpg 300w,https://i.cbc.ca/1.5334357.1600801578!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/ann-cavoukian.jpg 460w,https://i.cbc.ca/1.5334357.1600801578!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/ann-cavoukian.jpg 620w,https://i.cbc.ca/1.5334357.1600801578!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/ann-cavoukian.jpg 780w,https://i.cbc.ca/1.5334357.1600801578!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/ann-cavoukian.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5334357.1600801578!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/ann-cavoukian.jpg"></p></div><figcaption>Ontario's former privacy commissioner Ann Cavoukian says privacy protection rules ought to be written into contracts for home security systems.<!-- --> <!-- -->(Onnig Cavoukian)</figcaption></figure></span></p>  <h2>'She kind of freaked out'</h2>  <p>When Hall moved out, the security equipment was left behind. He had no idea he would still be able to control it after he handed over the keys.</p>  <p>He said Fornell&nbsp;"kind of freaked out because she was literally standing in her new house watching all the doors unlocking."</p>  <p>Hall's contract with Vivint had already expired when he called on May 21, requesting the service be cut off.&nbsp;He also sent an email that same day confirming his request.</p>  <p>On June 17, he realized&nbsp;he could still control the security system and contacted Fornell.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5733531.1600746262!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/rob-hall.jpg 300w,https://i.cbc.ca/1.5733531.1600746262!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/rob-hall.jpg 460w,https://i.cbc.ca/1.5733531.1600746262!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/rob-hall.jpg 620w,https://i.cbc.ca/1.5733531.1600746262!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/rob-hall.jpg 780w,https://i.cbc.ca/1.5733531.1600746262!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/rob-hall.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5733531.1600746262!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/rob-hall.jpg"></p></div><figcaption>Rob Hall shows Go Public's Rosa Marchitelli the app he used to control Fornell's security system. <!-- --> <!-- -->(Art Raham/CBC)</figcaption></figure></span></p>  <p>Go Public spoke with three others&nbsp;who say they had the same experience with Vivint after selling or buying a home. All posted&nbsp;their&nbsp;stories on a private community Facebook page after reading what happened to Hall.<strong><strong> </strong></strong></p>  <p>"I just thought that was absolutely crazy," Hall said.</p>  <p>Hall says he called the company again the day he showed Fornell he still had access,&nbsp;and was told he'd have to wait a few more days before it would be cut off.</p>  <p>"I said, 'So you're going to give me access to somebody else's house? I literally could go on the app, I could watch them leave the house, then I could walk up to the front door, unlock it, disarm the system, walk and steal everything in the&nbsp;place because an alarm company gave me access.'"&nbsp;</p>  <p>Hall&nbsp;says that's when Vivint deactivated the app, a process which took less than 30 seconds.</p>  <p>Vivint says its policy requires 30 days' notice for cancellation but says it&nbsp;can cut off access right away if needed. The company says Hall&nbsp;didn't provide a move-out date when he cancelled the service and the company representative&nbsp;didn't ask.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5733527.1600793114!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/facebook-post.jpg 300w,https://i.cbc.ca/1.5733527.1600793114!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/facebook-post.jpg 460w,https://i.cbc.ca/1.5733527.1600793114!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/facebook-post.jpg 620w,https://i.cbc.ca/1.5733527.1600793114!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/facebook-post.jpg 780w,https://i.cbc.ca/1.5733527.1600793114!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/facebook-post.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5733527.1600793114!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/facebook-post.jpg"></p></div><figcaption>Several people, including this Edmonton woman, responded with similar stories when Hall posted his experience with Vivint on Facebook.<!-- --> <!-- -->(Facebook)</figcaption></figure></span></p>  <p>The company said "that step was overlooked" by its representatives in all the cases Go Public asked about.</p>  <p>"Our company policy is to confirm this&nbsp;timing but that step was overlooked in the cases you have shared … We have reviewed our process to ensure these situations are handled per our policies moving forward," spokesperson Liz Tanner told Go Public in an email</p>  <p>She added that the company honoured the terms of the customer agreement in all the cases.</p>  <p>Home security systems are big business in Canada,&nbsp;$2.6-billion a year according to IBISWorld, a private company that provides statistics and research on Canadian industries.&nbsp; That same report found&nbsp;Vivint&nbsp;is on track to have the second&nbsp;largest share of the&nbsp;national security system market by the end of 2020, after&nbsp;ADT.&nbsp;</p>  <p>It's also an industry with a lot of privacy and security issues, according to Kevvie Fowler from the&nbsp;consultancy firm&nbsp;Deloitte, who has 25 years' experience as a software developer and a security expert and who works with companies to prevent and recover from security breaches.</p>  <p>For example, Fowler says cancellation policies — which can range from 30 days to six months or more depending on the company — aren't written with privacy and security in mind, but to increase sales.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5733533.1600893361!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/kevvie-fowler.jpg 300w,https://i.cbc.ca/1.5733533.1600893361!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/kevvie-fowler.jpg 460w,https://i.cbc.ca/1.5733533.1600893361!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/kevvie-fowler.jpg 620w,https://i.cbc.ca/1.5733533.1600893361!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/kevvie-fowler.jpg 780w,https://i.cbc.ca/1.5733533.1600893361!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/kevvie-fowler.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5733533.1600893361!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/kevvie-fowler.jpg"></p></div><figcaption>Security expert Kevvie Fowler says security companies delay cancellations, hoping new homeowners will sign up for the service.<!-- --> <!-- -->(Submitted by Kevvie Fowler)</figcaption></figure></span></p>  <p>"It's advantageous for the monitoring companies not to cancel your service with the hopes that the new homeowner will actually come on board and sign up to the service … that's why they focus on the contract and having that extended period of time to actually cancel the service," he said.</p>  <p>Vivint says that's not the case with its contracts, saying it requires 30 days to cancel so customers can find another provider&nbsp;or&nbsp;move out of the house&nbsp;or continue to protect a vacant property during a sale.</p>  <p>None of those reasons apply to Hall or the other Vivint customers Go Public spoke with.</p>  <p>Fowler says he's seen a lot of situations when people have had access to home security systems who shouldn't — including access to cameras and microphones in and outside a house.</p>  <h2>Couple taunted by hacker</h2>  <p>Problems with security systems have been well documented. <a href="https://www.youtube.com/watch?reload=9&amp;v=-P0rSnt2HSU">CBC Marketplace</a> exposed problems with some security devices.&nbsp;</p>  <p>Arjun and Jessica Sud learned that firsthand. In January 2019, a stranger was able to hack into the Lake Barrington, Ill.,&nbsp;couple's Google Nest security system, verbally taunting them through their security cameras, after cranking up the heat in their seven-month old son's bedroom to 32 C as a prank, the couple told Go Public.</p>  <p><em><strong>WATCH | Homeowners confront digital intruder (Warning: graphic language):</strong></em></p>  <p><span><span><div><div role="button" tabindex="0" title="WATCH | Home owners confront digital intruder  (Warning: graphic language)"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/976/323/GPSUD_2500kbps_1280x720_1793105475866.jpg" alt=""></p></div></div></div><span>Arjun and Jessie Sud of Barrington Lake, Illinois heard a voice in their baby's bedroom in January 2019 and discovered a hacker watching them via their home security system.<!-- --> <!-- -->1:18</span></span></span></p>  <p>"The camera that was up on the wall in the living room lights up and a man's voice starts talking to me. I was horrified. My hair still stands up when I talk about it," Sud said.</p>  <p>He says he and his wife immediately disconnected all the cameras and complained to the company.</p>  <h2>Privacy laws out of date</h2>  <p>Cavoukian, the former privacy commissioner, says Canada's weak privacy laws, which were passed&nbsp;20 years ago,&nbsp;are a troubling part of the problem.&nbsp;</p>  <p>She&nbsp;says the law should require&nbsp;privacy protection rules to be written into every aspect of business, including contracts and policies, a <a href="http://www.ipc.on.ca/wp-content/uploads/resources/7foundationalprinciples.pdf">concept she developed</a> called&nbsp;"privacy by design."&nbsp;</p>  <p>Without that, she says Canadians are often left with a false sense of security.</p>  <p>"Our&nbsp;privacy law, [<a href="http://www.priv.gc.ca/en/privacy-topics/privacy-laws-in-canada/the-personal-information-protection-and-electronic-documents-act-pipeda/">the&nbsp;Personal Information Protection and Electronic Documents Act</a>]&nbsp;is so outdated. Our federal privacy commissioner has been trying to get the federal government to upgrade it and modernize it for years," she said.</p>  <p>Taylor Fornell and Rob Hall&nbsp;would also like to see stronger laws and see companies be upfront about how they protect customers' safety and privacy.</p>  <p>Fornell says she was considering signing up with Vivint before Hall let her know what was happening.</p>  <p>"It was crazy that someone who didn't have keys to my front door could unlock my house without even being on my street," she said.</p>  <p>"If [Hall] was somebody else, if he wasn't an honest person, he could have come in and done who knows what."</p>  <hr>  <p><strong>Submit your story ideas</strong></p>  <p>Go Public is an investigative news segment on CBC-TV, radio and the web.</p>  <p>We tell your stories, shed light on wrongdoing, and hold the powers that be accountable.</p>  <p>If you have a story in the public interest, or if you're an insider with information, contact&nbsp;<a href="https://www.cbc.ca/news/gopublic">GoPublic@cbc.ca</a>&nbsp;with your name, contact information and a brief summary. All emails are confidential until you decide to Go Public.</p>  <p>Follow&nbsp;<a href="https://twitter.com/cbcgopublic" target="_blank">@CBCGoPublic</a>&nbsp;on Twitter.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/business/security-system-app-homeowner-stranger-1.5733444</link>
            <guid isPermaLink="false">hacker-news-small-sites-24629254</guid>
            <pubDate>Tue, 29 Sep 2020 15:48:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It Is Never a Compiler Bug Until It Is]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24629234">thread link</a>) | @haakon
<br/>
September 29, 2020 | http://r6.ca/blog/20200929T023701Z.html | <a href="https://web.archive.org/web/*/http://r6.ca/blog/20200929T023701Z.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>Last week I was trying to add some <a href="https://github.com/bitcoin-core/secp256k1/pull/822/commits/aa833603a6b4c947c21da04aeac40d80444ebcc1#diff-b04459e37839cd223176618536295715R425">testing code to libsecp256k1</a> and I was pulling out my hair trying to get it to work.
No amount of <code>printf</code> was working to illuminate what I was doing wrong.
Finally, out of desperation, I thought I would do a quick check to see if there are any compiler bugs related to <code>memcmp</code>, and lo and behold, I found <a href="https://gcc.gnu.org/bugzilla/show_bug.cgi?id=95189">GCC bug #95189: memcmp being wrongly stripped like strcmp</a>.</p><p>Honestly this was a pretty horrifying bug to read about.
Under some circumstances GCC 9 and 10 will cause <code>memcmp</code> to return an incorrect value when one of the inputs is statically known array that contains <code>NULL</code> bytes.
As I rushed to <a href="https://gist.githubusercontent.com/roconnor/2b8e22e829ed80088ed6690cc3c7f3a8/raw/455571a6d9053c597c1585debe6f9dbd6af85071/gistfile1.txt">recompile my computer system using GCC 8</a>, I contemplated the vast consequences of such a bug could be, and pondered how it was possible that computers could function at all.</p><p>However over the week, with the help of my colleagues, we managed to get a better understanding of the scope of the bug.
The bug can only convert non-zero values to zero values.
The static array needs to have a <code>NULL</code> byte within the first 4 bytes.
Most importantly, the <code>memcmp</code> result must not immediately be compared to <code>0</code> for equality or inequality, or any equivalent test.
A different code path is taken in the compiler in that case.
That explained why computers were still functioning.
I expect the vast majority of the uses of <code>memcmp</code> does an immediate test for equality with <code>0</code>.</p><p>I still wondered though, how much code was being affected. My colleague Tim suggested that it would be possible to instrument GCC to emit a message when it was about to miscompile a program.
Together we came up with <a href="https://gcc.gnu.org/bugzilla/attachment.cgi?id=49276&amp;action=diff">a patch</a> to GCC 9 and 10 that would print a debugging message.
Once again, I recompiled my entire system, to see what GCC was miscompiling.
This is what I found:</p><ul>
<li><a href="https://github.com/unicode-org/icu/blob/4fb47b12a70737ee12326220e71c2d73c5ec658f/icu4c/source/common/uniset_props.cpp#L709">https://github.com/unicode-org/icu/blob/4fb47b12a70737ee12326220e71c2d73c5ec658f/icu4c/source/common/uniset_props.cpp#L709</a></li>
<li><a href="https://github.com/xiph/flac/blob/ce6dd6b5732e319ef60716d9cc9af6a836a4011a/src/flac/decode.c#L1310">https://github.com/xiph/flac/blob/ce6dd6b5732e319ef60716d9cc9af6a836a4011a/src/flac/decode.c#L1310</a></li>
<li><a href="https://github.com/torvalds/linux/blob/fb0155a09b0224a7147cb07a4ce6034c8d29667f/drivers/atm/zatm.c#L1172">https://github.com/torvalds/linux/blob/fb0155a09b0224a7147cb07a4ce6034c8d29667f/drivers/atm/zatm.c#L1172</a></li>
<li><a href="https://github.com/nss-dev/nss/blob/1f3746f5107535a47bb4e3969f561e1bd1314bab/gtests/pk11_gtest/pk11_chacha20poly1305_unittest.cc#L425">https://github.com/nss-dev/nss/blob/1f3746f5107535a47bb4e3969f561e1bd1314bab/gtests/pk11_gtest/pk11_chacha20poly1305_unittest.cc#L425</a></li>
<li><a href="https://github.com/GNOME/glib/blob/010569b3734f864fcf584f771915b78bd391eb5f/glib/tests/refstring.c#L70">https://github.com/GNOME/glib/blob/010569b3734f864fcf584f771915b78bd391eb5f/glib/tests/refstring.c#L70</a></li>
<li><a href="https://github.com/heimdal/heimdal/blob/7ae2dfd853c87f9cbecb6f399de4dad09bad4606/lib/gssapi/krb5/arcfour.c#L390">https://github.com/heimdal/heimdal/blob/7ae2dfd853c87f9cbecb6f399de4dad09bad4606/lib/gssapi/krb5/arcfour.c#L390</a>, <a href="https://github.com/heimdal/heimdal/blob/7ae2dfd853c87f9cbecb6f399de4dad09bad4606/lib/gssapi/krb5/arcfour.c#L661">https://github.com/heimdal/heimdal/blob/7ae2dfd853c87f9cbecb6f399de4dad09bad4606/lib/gssapi/krb5/arcfour.c#L661</a>, <a href="https://github.com/heimdal/heimdal/blob/7ae2dfd853c87f9cbecb6f399de4dad09bad4606/lib/gssapi/krb5/arcfour.c#L1279">https://github.com/heimdal/heimdal/blob/7ae2dfd853c87f9cbecb6f399de4dad09bad4606/lib/gssapi/krb5/arcfour.c#L1279</a></li>
<li><a href="https://github.com/zeromq/libzmq/blob/22d218a182855f28038e865cb75bf5897ff0c786/tests/test_mock_pub_sub.cpp#L203">https://github.com/zeromq/libzmq/blob/22d218a182855f28038e865cb75bf5897ff0c786/tests/test_mock_pub_sub.cpp#L203</a></li>
<li><a href="https://github.com/pigoz/mplayer-svn/blob/8d651873a9eb193f5155ffb51ece206f187cf00f/sub/sub_cc.c#L391-L412">https://github.com/pigoz/mplayer-svn/blob/8d651873a9eb193f5155ffb51ece206f187cf00f/sub/sub_cc.c#L391-L412</a></li>
</ul>
<p>On my entire system I only found 10 lines of code that were miscompiled.
Three lines are tests.
All of the lines could be rewritten as a comparison to 0.
None of the lines looked that serious.
I am not sure which one is the worse: the reduced message integrity code(?) from some ARCFOUR implementation or the something something from an ATM driver?</p><p>The mplayer miscompilation is the most mysterious.
The code surrounding that function all appears to be immediately compare <code>memcmp</code> with <code>0</code>.
And given that my debug message refused to point to exactly what line is being miscompiled in that function, I fear some set of optimizations has happened to allow this code to be miscompiled in some way.</p><p>With more hardware I could do <a href="https://hydra.nixos.org/jobset/nixpkgs/trunk#tabs-jobs">a more thorough investigation</a> of the consequences of this GCC bug.
Until then I am going to stick with GCC 8 until GCC 9 and 10 have a new point releases.

</p></div></div>]]>
            </description>
            <link>http://r6.ca/blog/20200929T023701Z.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24629234</guid>
            <pubDate>Tue, 29 Sep 2020 15:46:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fourier Filtering]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24629172">thread link</a>) | @gus_massa
<br/>
September 29, 2020 | http://bigwww.epfl.ch/demo/ip/demos/FFT-filtering/ | <a href="https://web.archive.org/web/*/http://bigwww.epfl.ch/demo/ip/demos/FFT-filtering/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Running ...</p><div id="main">
    
    <p>
        Your browser does not support the HTML5 canvas element. Please, try with a newer browser.<br>
    </p>
    

    <div id="imageChooser">
        <div id="imagesContainer">
            <p><img src="http://bigwww.epfl.ch/demo/ip/demos/icons/open_file.png">
                <span>from disk</span>
            </p>

            <p><img src="http://bigwww.epfl.ch/demo/ip/demos/icons/open_url.png">
                <span>from url</span>
            </p>
            
        </div>
        </div>

    
    

     <p id="animationBlock">Steps<br>
         <progress id="animationSteps" min="0" value="1" max="10"></progress> <span>0/5</span>
    </p>

    <div>
        

        <div title="SNR">
            <div>
                <p>SNR:</p>
                <p>0.0</p>
            </div>
        </div>

        <!-- <div class="container-item" title="save a screenshot">
            <a id="export1">
                <div id="export_container">
                    <img id="export_img" src="http://bigwww.epfl.ch/demo/ip/demos/icons/screenshot.png"/>
                </div>
            </a>
        </div>

        <div class="container-item" title="save a screenshot">
            <a id="export2">
                <div id="export_container">
                    <img id="export_img" src="http://bigwww.epfl.ch/demo/ip/demos/icons/screenshot.png"/>
                </div>
            </a>
        </div> -->
    </div>

</div><p>
	© 2018 Image Processing Online Demonstration, Biomedical Imaging Group, EPFL.
	<br>
	The Javascript/HTML5/ImageAccess library (<a href="http://bigwww.epfl.ch/publications/sage0303.html">Reference</a>) 
	was written by <b>Cyril Favre</b>, <b>Robin Lang</b>, and <a href="mailto:daniel.sage@epfl.ch">Daniel Sage</a>.
	</p></div>]]>
            </description>
            <link>http://bigwww.epfl.ch/demo/ip/demos/FFT-filtering/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24629172</guid>
            <pubDate>Tue, 29 Sep 2020 15:42:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Following ransomware attack, Tyler Tech advises clients to change passwords]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24629164">thread link</a>) | @rhinoh
<br/>
September 29, 2020 | https://www.route-fifty.com/tech-data/2020/09/tyler-tech-ransomware-password-change-clients/168837/ | <a href="https://web.archive.org/web/*/https://www.route-fifty.com/tech-data/2020/09/tyler-tech-ransomware-password-change-clients/168837/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    

    <div>

      <div>
        

        
          
        

        
  
    <div>
      


<div>
  
  <p>Connecting state and local government leaders</p>
</div>

    </div>
  


        
          

          
        

      </div>

      
      <div>

        <div>
          
          <p>
            
              
                
                  



  By


<span><span><a href="https://www.route-fifty.com/voices/bill-lucia/10687/?oref=rf-post-author?oref=rf-post-author">Bill Lucia</a></span></span>

                
              
            
          </p>

          
            <p><span>|</span>
          

          
            <time datetime="2020-09-28T21:09:00+00:00">
             September 28, 2020
            </time>
          
        </p></div>

        
          <h2>The company is a leading provider of software to state and local governments. So far, it says it looks like the security breach has affected only its internal computer systems. </h2>
        

        
  <ul>
    
      <li>
        <a href="https://www.route-fifty.com/topic/cybersecurity/?oref=rf-article-topics">
          <span>
            <span>
              <span>
                Cybersecurity
              </span>
            </span>
          </span>
        </a>
      </li>
    
      <li>
        <a href="https://www.route-fifty.com/topic/information-technology/?oref=rf-article-topics">
          <span>
            <span>
              <span>
                Information Technology
              </span>
            </span>
          </span>
        </a>
      </li>
    
  </ul>


        





        

      </div>
      

    </div>
  </div><div>
<div>

<div>
<p>Tyler Technologies, a vendor that provides software to states and localities, has advised clients to change passwords after reports of suspicious login attempts, a warning that comes as the company is dealing with a ransomware attack on its own internal network.</p><p>The company said over the weekend that it was aware&nbsp;of&nbsp;“several suspicious logins to client systems” and strongly recommended that clients reset remote network access passwords&nbsp;for Tyler staff, as well as credentials the company’s staff would use to access applications.</p><p>A statement posted on Tyler’s website says that the company learned of a cybersecurity breach to its internal systems—including phone and IT systems—last Wednesday and has since confirmed that the situation involves a ransomware attack.</p><p>The company declined to comment on Monday about how many clients reported suspicious login attempts, where those clients are located, or if any of the login attempts had succeeded and resulted in nefarious activity of any kind.</p><p>In its <a href="https://www.tylertech.com/about-us" target="_blank">online statement</a>, Tyler says that because the company’s investigation into the incident is still active it would not provide additional specifics.</p><p>But the company emphasized over the weekend that evidence so far seemed to indicate that the digital attack was directed at its own internal corporate network and phone systems, which are separate from where the company hosts software for clients.</p><p>The company says it has been in contact with the FBI about the breach.</p><p>While the situation is unfolding during the runup to the November election, Tyler has noted that it does not make election software.&nbsp;</p><p>There is heightened concern about cybersecurity around the election after&nbsp;efforts by Russia to interfere in the 2016 presidential contest.&nbsp;</p><p>But, in a statement issued Monday, the FBI and the Cybersecurity and Infrastructure Security Agency suggested that bad actors may be fanning the flames around these worries to raise doubts about the integrity of the upcoming election.</p><p>“Foreign actors and cyber criminals,” the agencies said, are spreading false and inconsistent information through online platforms in an attempt to manipulate public opinion, discredit the electoral process and undermine confidence in U.S. democratic institutions.</p><p>“These malicious actors could use these forums to also spread disinformation suggesting successful cyber operations have compromised election infrastructure and facilitated the ‘hacking’ and ‘leaking’ of U.S. voter registration data,” the agencies added.</p><p>They pointed out that a lot of U.S. voter information can be purchased or acquired through publicly available sources, and said that while “cyber actors” have in recent years obtained voter registration information this did not affect the integrity of election results.&nbsp;</p><p>“The FBI and CISA have no information suggesting any cyberattack on U.S. election infrastructure has prevented an election from occurring, compromised the accuracy of voter registration information, prevented a registered voter from casting a ballot, or compromised the integrity of any ballots cast,” the agencies also said.</p><p>The situation with Tyler is unfolding as Washington state has faced a cyberattack in recent days. State officials there <a href="https://apnews.com/article/technology-phishing-washington-jay-inslee-bf63ccf1f0e4709efc8871bb7457ef1c" target="_blank">said last week</a> that hackers were targeting the state. <a href="https://www.bloomberg.com/news/articles/2020-09-27/hackers-have-infiltrated-many-of-washington-state-s-agencies" target="_blank"><em>Bloomberg</em> reported</a> on Sunday that the attack had infected computer systems used by many state agencies.</p><p>Washington’s secretary of state’s office said in a tweet last week that it was aware of “an active cyber threat” facing government entities throughout the country, but that the office had “no reason at this time to believe this is targeted at elections.”<svg>
<use xlink:href="/static/b/base/svg/spritesheet.svg#icon-rf-shield-alt"></use>
</svg></p></div></div>
</div></div>]]>
            </description>
            <link>https://www.route-fifty.com/tech-data/2020/09/tyler-tech-ransomware-password-change-clients/168837/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24629164</guid>
            <pubDate>Tue, 29 Sep 2020 15:41:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Breakthrough Listen Makes the Case for a SETI Telescope on the Moon]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24629161">thread link</a>) | @n0pe_p0pe
<br/>
September 29, 2020 | https://www.supercluster.com/editorial/the-case-for-building-a-seti-observatory-on-the-moon | <a href="https://web.archive.org/web/*/https://www.supercluster.com/editorial/the-case-for-building-a-seti-observatory-on-the-moon">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span>On Monday, a group of researchers sponsored by Breakthrough Listen, the world’s largest SETI program, </span><a href="http://seti.berkeley.edu/lunarseti/" rel="noopener noreferrer" target="_blank">submitted a paper</a><span> to National Academy of Sciences’ Planetary Science and Astrobiology Decadal Survey that makes the case for establishing a SETI radio observatory on the farside of the moon. The decadal survey establishes scientific priorities for the next ten years and the new paper addresses one of the biggest problems facing the search for extraterrestrial intelligence today: The overwhelming amount of radio interference.&nbsp;</span></p></div><div><p><span>Our planet has become so “loud” in the part of the radio spectrum observed by SETI that it threatens to drown out any signal sent from an intelligent civilization. Not only would a lunar radio telescope not have to deal with terrestrial radio interference, it could also significantly increase our chances of hearing from ET by opening up parts of the radio spectrum that are blocked by Earth's atmosphere. While the idea of using the moon for radio astronomy is decades old, the researchers make the case that technological advancements have finally made a lunar SETI observatory truly feasible.</span></p></div><div><div><p><span>
says Eric Michaud, an intern at the SETI Berkeley Research Center and the first author of the paper. “Maybe not today, but I think it’s going to get more and more feasible as time goes on.”&nbsp;</span></p></div></div><div><p><span>Radio interference has been a problem for SETI from the very beginning. In the spring of 1960, the planetary scientist Frank Drake trained the massive radio telescope at Green Bank Observatory in West Virginia on Tau Ceti and Epsilon Eridani, two stars a mere 12 light years from Earth. That summer, Drake spent his days studying the signals picked up by Green Bank’s giant mechanical ear in the hopes of receiving a message broadcast by an alien civilization orbiting those stars. Known as Project Ozma, Drake’s experiment marked the beginning of SETI, the scientific search for extraterrestrial intelligence.&nbsp;</span></p></div><div><p><span>Shortly after Drake started his observations, he was surprised to find what appeared to be a signal of intelligent origin. After days of watching a needle drift lazily over a spool of paper recording the random undulations of cosmic static, Drake and his colleagues were jolted awake when the machine started recording the frantic pulses of a strong radio signal picked up by the telescope. The timing and magnitude of the pulses clearly marked them as artificial; there was nothing in the natural world that could produce such a frenetic radio profile. It would have been an astounding stroke of luck to pick up an alien message after only a few hours of observation, but it was hard to argue with the data.&nbsp;</span></p></div><div><p><span>“None of us had ever seen anything like it,” Drake recalled in </span><em>Is Anyone Out There?</em><span>, his autobiographical book about the early days of SETI. “We looked at each other wide-eyed. Could discovery be this easy?”</span></p></div><div><div><p><span>

It was a letdown, but the false detection turned out to be a portent for the future of SETI. In the 60 years since Drake’s pioneering experiment, researchers have conducted dozens of SETI searches across thousands of stars and turned up empty-handed. At the same time, the sources of radio interference on Earth—military radars, TV towers, cell phones, and satellites—have exponentially increased, which greatly increases the chances that an extraterrestrial signal will be lost among the noise.&nbsp;</span></p></div></div><div><p><span>Earth was never a particularly great place to do any kind of radio astronomy due to our thick atmosphere blocking a large portion of the radio spectrum. The proliferation of radio communication technologies has only made things harder. The moon, by comparison, has no atmosphere and its nights last for weeks on end, which limits radio noise from the sun. And as&nbsp;NASA discovered through a spate of lunar orbiter missions in the late 1960s, the moon also acts as a natural shield that blocks radio signals emanating from Earth. As the planetary astronomer Phillipe Zarka has put it, “the farside of the moon during the lunar night is the most radio-quiet place in our local universe.” It’s exactly the sort of peace and quiet you want if you’re searching for faint radio signals from solar systems that might be hundreds of light years away.&nbsp;</span></p></div><div><p><span>The new Breakthrough Listen paper proposed two main approaches to a lunar SETI observatory: an orbiter and a telescope on the surface. The basic idea behind a SETI lunar orbiter would be to scan for signals as it passed over the lunar farside and relay data back to Earth as it passed over the near side. One of the main advantages of an orbiter is cost. The proliferation of small satellites that are capable of accurate tracking combined with low-cost small launch providers like Rocket Lab means that a SETI orbiter could conceivably be sent to the moon </span><a href="https://www.nasa.gov/press-release/nasa-awards-contract-to-launch-cubesat-to-moon-from-virginia/#:~:text=The%20firm%2Dfixed%2Dprice%20launch,Tyvak%20Nano%2DSatellite%20Systems%20Inc." rel="noopener noreferrer" target="_blank">for less than $20 million</a><span>. This would be a valuable pathfinder mission that could pave the way for a more ambitious observatory on the surface, but without the risk and cost.&nbsp; As the </span><a href="https://www.supercluster.com/editorial/the-supercluster-podcast-water-bears-might-now-occupy-the-moon" rel="noopener noreferrer" target="_blank">ill-fated Israeli Beresheet lander mission</a><span> reminded us, landing on the moon is extremely challenging even when the mission is backed by $100 million.&nbsp;</span></p></div><div><p><span>But a SETI lunar orbiter would also come with a lot of compromises. It would only be able to conduct observations during the brief stretches when it was on the lunar farside, which would make a sustained observation campaign more challenging. The upshot is that an orbiter would have access to the full sky, whereas a telescope on the surface would be constrained by the moon’s rotation. The biggest downside of an orbiter is that it might lose a lot of the shielding benefits of the moon and be more vulnerable to radio interference from Earth since it would be orbiting high above the lunar surface.&nbsp;</span></p></div><div><p><span>“The first SETI observations that are done from the lunar farside will be done from orbit, there’s no question about that,” says Andrew Siemion, the director of the Berkeley SETI Research Center and the second author on the paper. “I think eventually we absolutely want to do something on the surface because we want to build a very large aperture telescope, but even when we’re at that point I don’t think that would negate the utility of doing things from orbit as well.”&nbsp;</span></p></div><div><p><span>So what would a SETI observatory on the moon look like? One idea is to use the naturally parabolic lunar crater as a radio dish, much like the Arecibo telescope in Puerto Rico and </span><a href="https://www.supercluster.com/editorial/chinas-massive-telescope-is-the-next-great-seti-hope" rel="noopener noreferrer" target="_blank">the FAST telescope in China</a><span>, which are built into natural depressions in the land. This idea was </span><a href="https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/RS012i005p00845" rel="noopener noreferrer" target="_blank">first considered</a><span> back in the late 1970s by a group of scientists at the radio physics lab at the Stanford Research Institute. Their idea was to recreate Arecibo on the moon by suspending an antenna from the lip of a crater and using the basin as a reflector. The reduced gravity on the moon would allow for a radio telescope far larger than any on Earth, which could significantly enhance the sensitivity of SETI searches. Ultimately the researchers concluded that a lunar radio observatory was too expensive compared to SETI telescopes that could be built on Earth.&nbsp;</span></p></div><div><p><span>But 40 years later, Michaud says that building a radio dish in a lunar crater may finally be cheap enough to pull off. One of the main drivers of this cost reduction is the advent of commercial launch providers like SpaceX and Rocket Lab, which have </span><a href="https://www.supercluster.com/editorial/cheaper-rockets-growing-the-human-family-in-space" rel="noopener noreferrer" target="_blank">dramatically lowered the cost of space access</a><span>. Another driver is NASA’s push to establish a permanent human presence on the moon, which has subsidized the development of a fleet of commercial lunar exploration vehicles. “There’s so much interest in going back to the moon,” says Michaud, who cited Blue Origin’s lunar lander and Rocket Lab’s Photon Lunar satellite as examples of technologies enabled by </span><a href="https://www.supercluster.com/editorial/nasas-first-puerto-rican-born-director-aims-for-a-moonshot" rel="noopener noreferrer" target="_blank">NASA’s Artemis program</a><span>.&nbsp;</span></p></div><div><p><span>A crux of the original vision for lunar SETI observatories was that it would require a human settlement on the moon to build and operate the radio dish. But robotic systems have improved enough that it may be possible to take humans out of the equation. This was clearly demonstrated in 2019 when China’s Chang’e 4 rover landed autonomously on the farside of the moon. These advancements in autonomous navigation have laid the foundation for a lunar radio observatory that is built entirely by robots.&nbsp;</span></p></div><div><p><span>It sounds like science fiction, but earlier this year NASA’s Advanced Innovative Concepts program </span><a href="https://www.nasa.gov/directorates/spacetech/niac/2020_Phase_I_Phase_II/lunar_crater_radio_telescope/" rel="noopener noreferrer" target="_blank">awarded one of it’s prestigious grants to Saptarshi Bandyopadhyay, a researcher at the Jet Propulsion Laboratory, to figure out a way to make it happen</a><span>. His idea is to use rovers to deploy wire mesh in a crater on the lunar farside and suspend a receiver over the dish. NIAC is all about funding high risk, high reward missions, and there’s no guarantee that Bandyopadhyay’s proposal will ever come to fruition. Still, addressing the technical problems associated with building a radio receiver on the farside of the moon is an important first step.</span></p></div><div><p><span>And Bandyopadhyay isn’t the only NASA-backed researcher contemplating a lunar radio observatory. Jack Burns, a radio astronomer at the University of Colorado, has also received a grant to study a mission concept for a radio telescope array called </span><a href="https://www.colorado.edu/project/lunar-farside/dr-jack-burns" rel="noopener noreferrer" target="_blank">FARSIDE</a><span>. Instead of using a crater as a dish, FARSIDE would deploy several smaller antennas across the lunar surface that would collectively form a large radio telescope. Both NASA studies are focused on radio astronomy rather than SETI, but Siemion sees the two disciplines as natural allies in the quest to establish an observatory on the lunar farside. SETI has piggybacked on other radio astronomy projects in the past—SERENDIP, for instance, opportunistically searched for ET signals during radio observation campaigns at a variety of telescopes—and it seems plausible that a similar arrangement could be made with an observatory on the moon.&nbsp;</span></p></div><div><p><span>Siemion acknowledged that there were certain technical challenges that would arise in a collaboration on a lunar radio observatory. The biggest issue, he says, is that a lot of radio astronomy is done at frequencies that don’t really require an observatory on the moon. “Radio …</span></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.supercluster.com/editorial/the-case-for-building-a-seti-observatory-on-the-moon">https://www.supercluster.com/editorial/the-case-for-building-a-seti-observatory-on-the-moon</a></em></p>]]>
            </description>
            <link>https://www.supercluster.com/editorial/the-case-for-building-a-seti-observatory-on-the-moon</link>
            <guid isPermaLink="false">hacker-news-small-sites-24629161</guid>
            <pubDate>Tue, 29 Sep 2020 15:41:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Double Digit Decline in Infectious Disease Research During Coronavirus Pandemic]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24628957">thread link</a>) | @KaiserSanchez
<br/>
September 29, 2020 | https://www.medifind.com/news/post/double-digit-decline-in-infectious-disease-research-during-coronavirus-pandemic | <a href="https://web.archive.org/web/*/https://www.medifind.com/news/post/double-digit-decline-in-infectious-disease-research-during-coronavirus-pandemic">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><div><div>
<p>As featured on <a rel="noreferrer noopener" href="https://www.contagionlive.com/news/double-digit-decline-infectious-disease-research-coronavirus-pandemic" target="_blank">Contagion Live</a></p>



<p>As resources have been poured into the COVID-19 response, other infectious disease priorities have been displaced. Patrick Howie, CEO of a firm which aggregates useful clinical data/analysis, explains.</p>



<figure><p>
<iframe title="Double Digit Decline in Infectious Disease Research During Coronavirus Pandemic" width="500" height="281" src="https://www.youtube.com/embed/fpZbcASIbYs?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<div><p><em>“The areas of research most negatively affected by COVID-19 include other infectious diseases, many types of cancer&nbsp;and neurological diseases. The impact is potentially dire in all categories, but in somewhat different ways.”&nbsp;<p>&nbsp;“Failing to make advances against infectious diseases could have&nbsp;a&nbsp;global impact in the future,&nbsp;given their ability to spread quickly&nbsp;and&nbsp;indiscriminately. Slowdowns in research here may severely limit our ability to counteract outbreaks of&nbsp;both&nbsp;known infectious diseases and novel ones, given the fact that learnings are often relevant across different vectors of disease.&nbsp;</p></em></p><p><em>“Unfortunately, the way our medical research system is structured means there are limited resources, and thus clear winners and losers in the face of crisis. Progress against COVID-19 comes at the expense of many other important diseases, with implications that could last years. A researcher&nbsp;diverting&nbsp;their focus to COVID-19 may have a difficult time regaining funding, employees and resources when the time comes. Patients who were candidates for a clinical trial that was delayed due to&nbsp;the pandemic may&nbsp;have pursued&nbsp;other options that&nbsp;could&nbsp;later disqualify&nbsp;them, or&nbsp;faced even more dire consequences of these delays. With clinical trials unable to proceed as normal, and recruitment and retention becoming problematic, the delays in new research may be far-reaching and long-lasting.&nbsp;<br>&nbsp;</em><br><em>“COVID-19 was an unprecedented challenge and call-to-arms for the global medical research community. The speed and size of the response has been stunning, serving as evidence of our ability to scale up global collaboration in record time, across borders and boundaries. The response stands as a&nbsp;monument to the work we&nbsp;can&nbsp;do together when necessary. This reality offers hope not only for future pandemics, but also points to possibilities for more purposeful and progressive collaboration in the thousands of other diseases that rely on continued research. Disease isn’t limited by geopolitical boundaries, and our response can’t be either.&nbsp;&nbsp;<p>&nbsp;“COVID-19 has also put a new spotlight on the numerous issues in the healthcare system, including technological barriers like limited data interoperability. It’s become clear that no single&nbsp;person&nbsp;(or even group) can conduct research on the scale required for&nbsp;a&nbsp;challenge&nbsp;like&nbsp;COVID-19. To succeed, we desperately need to accelerate our ability to use tools like artificial intelligence and machine learning to amplify human effort.&nbsp;&nbsp;</p></em><br><em>“COVID-19, like SARS and MERS before it,&nbsp;has&nbsp;naturally relied heavily on the talents of infectious disease specialists. In all cases, these experts had to divert their attention, time, energy and perhaps even funding, given that they were best equipped to tackle these new threats. What’s different about COVID-19 is the scale of the impact. COVID-19 has impacted the entire world in dramatic numbers, leaving no country unscathed. The scale of increase in coronavirus research, and the related scale of decrease in all other research, is novel.”&nbsp;</em></p></div>
</div></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.medifind.com/news/post/double-digit-decline-in-infectious-disease-research-during-coronavirus-pandemic</link>
            <guid isPermaLink="false">hacker-news-small-sites-24628957</guid>
            <pubDate>Tue, 29 Sep 2020 15:26:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenNebula Webinar: Managing your Kubernetes clusters with Rancher]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24628837">thread link</a>) | @amarti
<br/>
September 29, 2020 | https://us02web.zoom.us/webinar/register/7916013795590/WN_3l49ozQMSgGGyY83RmsVHQ | <a href="https://web.archive.org/web/*/https://us02web.zoom.us/webinar/register/7916013795590/WN_3l49ozQMSgGGyY83RmsVHQ">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<p><label for="timezone">Time Zone:</label>&nbsp;&nbsp;

</p>
</div>
</div></div>]]>
            </description>
            <link>https://us02web.zoom.us/webinar/register/7916013795590/WN_3l49ozQMSgGGyY83RmsVHQ</link>
            <guid isPermaLink="false">hacker-news-small-sites-24628837</guid>
            <pubDate>Tue, 29 Sep 2020 15:17:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Graph Databases: TerminusDB vs. Neo4j]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24628809">thread link</a>) | @vivek9209
<br/>
September 29, 2020 | https://terminusdb.com/blog/2020/09/24/graph-databases-terminusdb-vs-neo4j/ | <a href="https://web.archive.org/web/*/https://terminusdb.com/blog/2020/09/24/graph-databases-terminusdb-vs-neo4j/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div id="markdown" itemprop="articleBody">
          <p>Are Graph Databases the future?  Structured and unstructured data coming from multiple sources can have immense value if you can find the relationships within it, Graph databases consider the relationships between data as first class citizens.</p>

<p>Inter-connected data are the future, and probably the easiest way to model interconnected data is using a Graph Database.</p>

<p>In this tutorial will see two different way to model and query data using native graph database technology - TerminusDB and Neo4j.</p>

<p>if you have never used TerminusDB before, this article includes everything you need to get started with TerminusDB.
<a href="https://terminusdb.com/2020/01/14/my-first-terminusdb-graph-visualisation-bike-share-data/">My First TerminusDB Graph Visualisation — Bike Share Data</a>.</p>

<p>Now let’s see how TerminusDB handles tasks compared to Neo4j in practice.</p>

<h2 id="graph-database-main-concepts">Graph Database Main Concepts</h2>

<p>Graph databases  are databases that use graph structures to organize data: nodes, edges (relationship), and properties to represent and store data. The relationships allow data in the store to be linked together.</p>

<h4 id="neo4j-main-concepts">Neo4J Main Concepts</h4>

<ul>
  <li>Node</li>
  <li>Label (:Person)</li>
  <li>Relationship :KNOWS</li>
  <li>Property {name}</li>
</ul>

<p><img src="https://terminusdb.com/blog/assets/images/neo4j-graph-know.png" alt=""></p>

<p>In Neo4j the main components of the property graph model are nodes and relationships, in our example, <strong>Maria</strong>, <strong>Anna</strong>, <strong>Tom</strong> and <strong>Jim</strong> are our nodes and <strong>KNOWS</strong> is our relationship between nodes.</p>

<p>Nodes and Relationships can have properties, properties are name-value pairs that provide additional details for nodes and relationships. You can group similar nodes together by assigning a node label (:Person). A node can have zero to many labels.</p>

<h4 id="terminusdb">TerminusDB</h4>

<ul>
  <li>OrdinaryClass</li>
  <li>DocumentClass (doc:Person)</li>
  <li>ObjectProperty (knows:doc:Person)</li>
  <li>DatatypeProperty (name:String)</li>
</ul>

<p><img src="https://terminusdb.com/blog/assets/images/terminusdb-graph-knows.png" alt=""></p>

<p>In TerminusDB everything is an object of a Class - objects can have properties and some of these properties may link to other objects. Document Classes are top-level classes, which allow the graph to be serialized into documents.  Our example <strong>Maria</strong>, <strong>Anna</strong>, <strong>Tom</strong>, and <strong>Jim</strong> are our Document Objects. The <strong>knows</strong> property is an ObjectProperty with range being the <strong>Person</strong> document.</p>

<p>Classes can be subclasses of other classes, which means that they inherit all the parent’s properties (much like inheritance in object-oriented programming). Multiple inheritance is supported.</p>

<p>The type of data that the property points to can either be a simple datatype literal (e.g. an integer or string) (DatatypeProperty) or it can be a class (ObjectProperty).</p>

<h2 id="query-language">Query language</h2>

<p>Neo4j uses <strong>Cypher</strong> to store and retrieve data from the graph database. Cypher is 
a graph query language and the best way to interact with Neo4j.</p>

<p>TerminusDB uses <a href="https://terminusdb.com/docs/woql"><strong>WOQL</strong> (Web Object Query Language)</a> which allows queries to be written in either javascript, python or as JSON-LD documents. All these examples are written using woql.js a javascript layer that allows queries to be written in simple javascript.</p>

<h2 id="schema">Schema</h2>

<p>A schema in Neo4j refers to indexes and constraints that can be applied to nodes. Neo4j is often described as schema optional, meaning that it is not necessary to create indexes and constraints. Index and Constraint can be added at any time.</p>

<p><em>In our example we create the constraint <strong>person_unique</strong>, it specifies that the properties <strong>name</strong> and <strong>born</strong> have to exist on all nodes with label <strong>Person</strong> and the combination of the property values is unique.</em></p>

<div><div><pre><code><span>CREATE</span> <span>CONSTRAINT</span> <span>person_unique</span>
<span>ON</span> <span>(</span><span>n</span><span>:</span><span>Person</span><span>)</span> <span>ASSERT</span> <span>(</span><span>n</span><span>.</span><span>name</span><span>,</span> <span>n</span><span>.</span><span>born</span><span>)</span> <span>IS</span> <span>NODE</span> <span>KEY</span>
</code></pre></div></div>

<p>TerminusDB is schema optional, but to take advantage of schema checking, it is better to create a schema before inserting data. TerminusDB lets you change your schema at any time. 
TerminusDB is a graph database that stores data like Git. <strong>TerminusDB allows for the whole suite of revision control features: branch, merge, squash, rollback, blame, and time-travel.</strong></p>

<p><a href="https://terminusdb.com/docs/quickstart/"><strong>If you want to read more …</strong></a></p>

<div><div><pre><code><span>WOQL</span><span>.</span><span>doctype</span><span>(</span><span>"</span><span>Person</span><span>"</span><span>)</span>            
  <span>.</span><span>label</span><span>(</span><span>"</span><span>Person Name</span><span>"</span><span>)</span>            
  <span>.</span><span>description</span><span>(</span><span>"</span><span>A Person Document</span><span>"</span><span>)</span>
	<span>.</span><span>property</span><span>(</span><span>"</span><span>name</span><span>"</span><span>,</span> <span>"</span><span>string</span><span>"</span><span>).</span><span>label</span><span>(</span><span>"</span><span>Name</span><span>"</span><span>).</span><span>cardinality</span><span>(</span><span>1</span><span>)</span>
	<span>.</span><span>property</span><span>(</span><span>"</span><span>date_of_birth</span><span>"</span><span>,</span> <span>"</span><span>date</span><span>"</span><span>).</span><span>label</span><span>(</span><span>"</span><span>Date Of Birth</span><span>"</span><span>).</span><span>cardinality</span><span>(</span><span>1</span><span>)</span>
	<span>.</span><span>property</span><span>(</span><span>"</span><span>knows</span><span>"</span><span>,</span> <span>"</span><span>Person</span><span>"</span><span>).</span><span>label</span><span>(</span><span>"</span><span>Knows</span><span>"</span><span>)</span>
</code></pre></div></div>

<p>Using the WOQL.js api, we create the <strong>Person</strong> Document class. This object has 3 properties, with three different types. The data type range in <strong>knows</strong> property (ObjectProperty) is the <strong>Person</strong> document class. The cardinality 1 for <em>name</em> and <em>date_of_birth</em> specifies that both property values have a single value.</p>

<h2 id="insert-data">Insert Data</h2>

<p>Here is an example of Cypress syntax for inserting data</p>

<p>We add 4 nodes of type (label) <strong>Person</strong> and relationships <strong>KNOWS</strong> between the nodes.</p>

<div><div><pre><code>
<span>CREATE</span> <span>(</span><span>maria</span><span>:</span><span>Person</span> <span>{</span> <span>name</span><span>:</span><span>"Maria"</span><span>,</span><span>born</span><span>:</span><span>date</span><span>(</span><span>'1978-12-03'</span><span>)</span><span>}</span><span>)</span>
<span>CREATE</span> <span>(</span><span>anna</span><span>:</span><span>Person</span> <span>{</span> <span>name</span><span>:</span><span>"Anna"</span><span>,</span><span>born</span><span>:</span><span>date</span><span>(</span><span>'1974-02-10'</span><span>)</span><span>}</span><span>)</span>
<span>CREATE</span> <span>(</span><span>tom</span><span>:</span><span>Person</span> <span>{</span> <span>name</span><span>:</span><span>"Tom"</span><span>,</span><span>born</span><span>:</span><span>date</span><span>(</span><span>'1975-06-23'</span><span>)</span><span>}</span><span>)</span>
<span>CREATE</span> <span>(</span><span>jim</span><span>:</span><span>Person</span> <span>{</span> <span>name</span><span>:</span><span>"Jim"</span><span>,</span><span>born</span><span>:</span><span>date</span><span>(</span><span>'1974-07-20'</span><span>)</span><span>}</span><span>)</span>

<span>MERGE</span> <span>(</span><span>maria</span><span>)</span><span>-</span><span>[</span><span>r</span><span>:</span><span>KNOWS</span> <span>{</span> <span>label</span><span>:</span> <span>maria</span><span>.</span><span>name</span> <span>+</span> <span>' knows '</span> <span>+</span> <span>anna</span><span>.</span><span>name</span> <span>}</span><span>]</span><span>-&gt;</span><span>(</span><span>anna</span><span>)</span>
<span>MERGE</span> <span>(</span><span>anna</span><span>)</span><span>-</span><span>[</span><span>r01</span><span>:</span><span>KNOWS</span> <span>{</span> <span>label</span><span>:</span> <span>anna</span><span>.</span><span>name</span> <span>+</span> <span>' knows '</span> <span>+</span> <span>tom</span><span>.</span><span>name</span> <span>}</span><span>]</span><span>-&gt;</span><span>(</span><span>tom</span><span>)</span>
<span>MERGE</span> <span>(</span><span>tom</span><span>)</span><span>-</span><span>[</span><span>r02</span><span>:</span><span>KNOWS</span> <span>{</span> <span>label</span><span>:</span> <span>tom</span><span>.</span><span>name</span> <span>+</span> <span>' knows '</span> <span>+</span> <span>maria</span><span>.</span><span>name</span> <span>}</span><span>]</span><span>-&gt;</span><span>(</span><span>maria</span><span>)</span>
<span>MERGE</span> <span>(</span><span>tom</span><span>)</span><span>-</span><span>[</span><span>r03</span><span>:</span><span>KNOWS</span> <span>{</span> <span>label</span><span>:</span> <span>tom</span><span>.</span><span>name</span> <span>+</span> <span>' knows '</span> <span>+</span> <span>jim</span><span>.</span><span>name</span> <span>}</span><span>]</span><span>-&gt;</span><span>(</span><span>jim</span><span>)</span>

<span>RETURN</span> <span>maria</span><span>.</span><span>name</span><span>,</span> <span>anna</span><span>.</span><span>name</span><span>,</span> <span>tom</span><span>.</span><span>name</span><span>,</span> <span>jim</span><span>.</span><span>name</span>

</code></pre></div></div>

<p>Let’s see how we add documents and relationships with TerminusDB - queries are accessible in a very easy way with JavaScript using the woql.js layer.</p>

<p>We create <strong>Person</strong> documents and we link them using the <strong>“knows”</strong> property in <strong>Person</strong> document. Our relationships between documents have been created.</p>

<div><div><pre><code><span>and</span><span>(</span>
  <span>idgen</span><span>(</span><span>"</span><span>doc:Person</span><span>"</span><span>,[</span><span>"</span><span>Maria</span><span>"</span><span>,</span><span>"</span><span>1978-12-03</span><span>"</span><span>],</span><span>"</span><span>v:Maria</span><span>"</span><span>),</span>
  <span>idgen</span><span>(</span><span>"</span><span>doc:Person</span><span>"</span><span>,[</span><span>"</span><span>Anna</span><span>"</span><span>,</span><span>"</span><span>1974-02-10</span><span>"</span><span>],</span><span>"</span><span>v:Anna</span><span>"</span><span>),</span>
  <span>idgen</span><span>(</span><span>"</span><span>doc:Person</span><span>"</span><span>,[</span><span>"</span><span>Tom</span><span>"</span><span>,</span><span>"</span><span>1975-06-23</span><span>"</span><span>],</span><span>"</span><span>v:Tom</span><span>"</span><span>),</span>
  <span>idgen</span><span>(</span><span>"</span><span>doc:Person</span><span>"</span><span>,[</span><span>"</span><span>Jim</span><span>"</span><span>,</span><span>"</span><span>1974-07-20</span><span>"</span><span>],</span><span>"</span><span>v:Jim</span><span>"</span><span>),</span>
 	
  <span>insert</span><span>(</span><span>"</span><span>v:Maria</span><span>"</span><span>,</span> <span>"</span><span>Person</span><span>"</span><span>).</span><span>label</span><span>(</span><span>"</span><span>Maria</span><span>"</span><span>)</span>
  <span>.</span><span>property</span><span>(</span><span>"</span><span>date_of_birth</span><span>"</span><span>,</span> <span>literal</span><span>(</span><span>"</span><span>1978-12-03</span><span>"</span><span>,</span><span>'</span><span>date</span><span>'</span><span>))</span>
  <span>.</span><span>property</span><span>(</span><span>"</span><span>name</span><span>"</span><span>,</span> <span>"</span><span>Maria</span><span>"</span><span>)</span>
  <span>.</span><span>property</span><span>(</span><span>"</span><span>knows</span><span>"</span><span>,</span> <span>"</span><span>v:Anna</span><span>"</span><span>),</span>

  <span>insert</span><span>(</span><span>"</span><span>v:Anna</span><span>"</span><span>,</span> <span>"</span><span>Person</span><span>"</span><span>).</span><span>label</span><span>(</span><span>"</span><span>Anna</span><span>"</span><span>)</span>
  <span>.</span><span>property</span><span>(</span><span>"</span><span>date_of_birth</span><span>"</span><span>,</span> <span>literal</span><span>(</span><span>"</span><span>1974-02-10</span><span>"</span><span>,</span><span>'</span><span>date</span><span>'</span><span>))</span>
  <span>.</span><span>property</span><span>(</span><span>"</span><span>name</span><span>"</span><span>,</span> <span>"</span><span>Anna</span><span>"</span><span>)</span>
  <span>.</span><span>property</span><span>(</span><span>"</span><span>knows</span><span>"</span><span>,</span> <span>"</span><span>v:Tom</span><span>"</span><span>),</span>

  <span>insert</span><span>(</span><span>"</span><span>v:Tom</span><span>"</span><span>,</span> <span>"</span><span>Person</span><span>"</span><span>).</span><span>label</span><span>(</span><span>"</span><span>Tom</span><span>"</span><span>)</span>
  <span>.</span><span>property</span><span>(</span><span>"</span><span>date_of_birth</span><span>"</span><span>,</span> <span>literal</span><span>(</span><span>"</span><span>1975-06-23</span><span>"</span><span>,</span><span>'</span><span>date</span><span>'</span><span>))</span>
  <span>.</span><span>property</span><span>(</span><span>"</span><span>name</span><span>"</span><span>,</span> <span>"</span><span>Tom</span><span>"</span><span>)</span>
  <span>.</span><span>property</span><span>(</span><span>"</span><span>knows</span><span>"</span><span>,</span> <span>"</span><span>v:Maria</span><span>"</span><span>),</span>

  <span>insert</span><span>(</span><span>"</span><span>v:Jim</span><span>"</span><span>,</span> <span>"</span><span>Person</span><span>"</span><span>).</span><span>label</span><span>(</span><span>"</span><span>Jim</span><span>"</span><span>)</span>
  <span>.</span><span>property</span><span>(</span><span>"</span><span>date_of_birth</span><span>"</span><span>,</span> <span>literal</span><span>(</span><span>"</span><span>1974-07-20</span><span>"</span><span>,</span><span>'</span><span>date</span><span>'</span><span>))</span>
  <span>.</span><span>property</span><span>(</span><span>"</span><span>name</span><span>"</span><span>,</span> <span>"</span><span>Jim</span><span>"</span><span>)</span>
  <span>.</span><span>property</span><span>(</span><span>"</span><span>knows</span><span>"</span><span>,</span> <span>"</span><span>v:Tom</span><span>"</span><span>)</span>
<span>)</span>
</code></pre></div></div>

<h2 id="add-a-new-node-type-and-relationship">Add a new node type and relationship</h2>

<p>In Neo4j we add a node with the label <strong>City</strong>, a new constaint and we connect our nodes <strong>Person</strong> and <strong>City</strong> with <strong>CITY_OF_BIRTH</strong> relationship</p>

<div><div><pre><code><span>CREATE</span><span>(</span><span>dublin</span><span>:</span><span>City</span> <span>{</span> <span>name</span><span>:</span><span>"Dublin"</span><span>}</span><span>)</span>

<span>CREATE</span> <span>CONSTRAINT</span> <span>city_name</span> <span>ON</span> <span>(</span><span>city</span><span>:</span><span>City</span><span>)</span> <span>ASSERT</span> <span>city</span><span>.</span><span>name</span> <span>IS</span> <span>UNIQUE</span>

<span>MATCH</span> <span>(</span><span>a</span><span>:</span><span>Person</span><span>),(</span><span>b</span><span>:</span><span>City</span><span>)</span>
<span>WHERE</span> <span>b</span><span>.</span><span>name</span> <span>=</span> <span>'Dublin'</span>
<span>MERGE</span> <span>(</span><span>a</span><span>)</span><span>-</span><span>[</span><span>r</span><span>:</span><span>CITY_OF_BIRTH</span> <span>{</span> <span>label</span><span>:</span> <span>a</span><span>.</span><span>name</span> <span>+</span> <span>' born in '</span> <span>+</span> <span>b</span><span>.</span><span>name</span> <span>}</span><span>]</span><span>-&gt;</span><span>(</span><span>b</span><span>)</span>
<span>RETURN</span> <span>type</span><span>(</span><span>r</span><span>),</span> <span>r</span><span>.</span><span>label</span>

</code></pre></div></div>

<p>In TerminusDB we create a new Document Object <strong>City</strong></p>

<div><div><pre><code><span>WOQL</span><span>.</span><span>doctype</span><span>(</span><span>"</span><span>City</span><span>"</span><span>).</span><span>label</span><span>(</span><span>"</span><span>City Name</span><span>"</span><span>).</span><span>description</span><span>(</span><span>"</span><span>A City name</span><span>"</span><span>)</span>
</code></pre></div></div>

<p>We add a new property <strong>city_of_birth</strong> in the Document <strong>Person</strong> with range type <strong>City</strong>.
Here our relationship between <strong>Person</strong>-&gt;<strong>City</strong></p>

<div><div><pre><code><span>add_property</span><span>(</span><span>"</span><span>city_of_birth</span><span>"</span><span>,</span><span>"</span><span>City</span><span>"</span><span>).</span><span>domain</span><span>(</span><span>"</span><span>Person</span><span>"</span><span>)</span>
</code></pre></div></div>

<p>Now update the data!!</p>

<div><div><pre><code><span>and</span><span>(</span>
  <span>idgen</span><span>(</span><span>"</span><span>doc:City</span><span>"</span><span>,[</span><span>"</span><span>Dublin</span><span>"</span><span>],</span><span>"</span><span>v:City_id</span><span>"</span><span>),</span>
  <span>insert</span><span>(</span><span>"</span><span>v:City_id</span><span>"</span><span>,</span> <span>"</span><span>City</span><span>"</span><span>).</span><span>label</span><span>(</span><span>"</span><span>Dublin</span><span>"</span><span>),</span>
  <span>triple</span><span>(</span><span>'</span><span>v:Person</span><span>'</span><span>,</span><span>'</span><span>type</span><span>'</span><span>,</span><span>'</span><span>scm:Person</span><span>'</span><span>),</span>
  <span>add_triple</span><span>(</span><span>"</span><span>v:Person</span><span>"</span><span>,</span><span>"</span><span>city_of_birth</span><span>"</span><span>,</span><span>"</span><span>v:City_id</span><span>"</span><span>)</span>
<span>)</span>

</code></pre></div></div>

<h2 id="creating-hierarchies">Creating hierarchies</h2>

<p>In our graph we now add another type of Person called Doctor, this entity has all the Person properties plus it is connected to the other nodes by the <strong>patient</strong> relationship</p>

<p>In Neo4j we can add multi labels to a node so our node is Person and Doctor at the same time.</p>

<div><div><pre><code>
<span>create</span> <span>(</span><span>freud</span><span>:</span><span>Person</span><span>:</span><span>Doctor</span> <span>{</span><span>name</span><span>:</span><span>'Freud'</span><span>,</span> <span>born</span><span>:</span><span>'1976-08-25'</span><span>}</span><span>)</span>

<span>MATCH</span> <span>(</span><span>a</span><span>:</span><span>Person</span><span>),(</span><span>b</span><span>:</span><span>Doctor</span><span>)</span>
<span>WHERE</span> <span>a</span><span>.</span><span>name</span> <span>=</span> <span>'Maria'</span> <span>AND</span> <span>b</span><span>.</span><span>name</span><span>=</span><span>"Freud"</span>
<span>MERGE</span> <span>(</span><span>a</span><span>)</span><span>-</span><span>[</span><span>r</span><span>:</span><span>IS_PATIENT_OF</span> <span>{</span> <span>label</span><span>:</span> <span>a</span><span>.</span><span>name</span> <span>+</span> <span>' is patient of '</span> <span>+</span> <span>b</span><span>.</span><span>name</span> <span>}</span><span>]</span><span>-&gt;</span><span>(</span><span>b</span><span>)</span>
<span>RETURN</span> <span>type</span><span>(</span><span>r</span><span>),</span> <span>r</span><span>.</span><span>label</span>

<span>MATCH</span> <span>(</span><span>a</span><span>:</span><span>Person</span><span>),(</span><span>b</span><span>:</span><span>Doctor</span><span>)</span>
<span>WHERE</span> <span>a</span><span>.</span><span>name</span> <span>=</span> <span>'Tom'</span> <span>AND</span> <span>b</span><span>.</span><span>name</span><span>=</span><span>"Freud"</span>
<span>MERGE</span> <span>(</span><span>a</span><span>)</span><span>-</span><span>[</span><span>r</span><span>:</span><span>IS_PATIENT_OF</span> <span>{</span> <span>label</span><span>:</span> <span>a</span><span>.</span><span>name</span> <span>+</span> <span>' is patient of '</span> <span>+</span> <span>b</span><span>.</span><span>name</span> <span>}</span><span>]</span><span>-&gt;</span><span>(</span><span>b</span><span>)</span>
<span>RETURN</span> <span>type</span><span>(</span><span>r</span><span>),</span> <span>r</span><span>.</span><span>label</span>

</code></pre></div></div>

<p>In TerminusDB classes can be subclasses of other classes, so let’s add a subclass for <strong>scm:Person</strong> called <strong>scm:Doctor</strong>.</p>

<p>A Doctor shares all of the properties available to a Person, but it also has a <strong>patient</strong> (ObjectProperty).</p>

<div><div><pre><code>
<span>WOQL</span><span>.</span><span>doctype</span><span>(</span><span>"</span><span>Doctor</span><span>"</span><span>)</span>
  <span>.</span><span>parent</span><span>(</span><span>"</span><span>Person</span><span>"</span><span>)</span>
  <span>.</span><span>label</span><span>(</span><span>"</span><span>Doctor</span><span>"</span><span>)</span>
  <span>.</span><span>description</span><span>(</span><span>"</span><span>A Doctor is a person with patients</span><span>"</span><span>)</span>
  <span>.</span><span>property</span><span>(</span><span>"</span><span>patient</span><span>"</span><span>,</span> <span>"</span><span>Person</span><span>"</span><span>)</span>

<span>WOQL</span><span>.</span><span>and</span><span>(</span>
  <span>idgen</span><span>(</span><span>"</span><span>doc:Doctor</span><span>"</span><span>,[</span><span>"</span><span>Freud</span><span>"</span><span>,</span><span>"</span><span>1976-08-25</span><span>"</span><span>],</span><span>"</span><span>v:Freud</span><span>"</span><span>),</span>
  <span>insert</span><span>(</span><span>"</span><span>v:Freud</span><span>"</span><span>,</span> <span>"</span><span>Doctor</span><span>"</span><span>).</span><span>label</span><span>(</span><span>"</span><span>Freud</span><span>"</span><span>)</span>
  <span>.</span><span>property</span><span>(</span><span>"</span><span>date_of_birth</span><span>"</span><span>,</span> <span>literal</span><span>(</span><span>"</span><span>1976-08-25</span><span>"</span><span>,</span><span>'</span><span>date</span><span>'</span><span>})</span>
  <span>.</span><span>property</span><span>(</span><span>"</span><span>name</span><span>"</span><span>,</span> <span>"</span><span>Freud</span><span>"</span><span>)</span>
  <span>.</span><span>property</span><span>(</span><span>"</span><span>patient</span><span>"</span><span>,</span><span>"</span><span>doc:Person_Maria_1978-12-03</span><span>"</span><span>)</span>
  <span>.</span><span>property</span><span>(</span><span>"</span><span>patient</span><span>"</span><span>,</span><span>"</span><span>doc:Person_Tom_1975-06-23</span><span>"</span><span>)</span>
       	
<span>)</span>

</code></pre></div></div>

<h2 id="query-the-data">Query the Data</h2>

<p>Now, how we write our query for getting how the <strong>Person</strong> <strong>knows</strong> each others</p>

<p>Here an Cypher example</p>

<div><div><pre><code>
<span>MATCH</span> <span>(</span><span>person</span><span>:</span><span>Person</span><span>)</span><span>-</span><span>[:</span><span>KNOWS</span><span>]</span><span>-</span><span>(</span><span>otherPerson</span><span>:</span><span>Person</span><span>)</span>
<span>RETURN</span> <span>person</span><span>.</span><span>name</span><span>,</span><span>otherPerson</span><span>.</span><span>name</span>

</code></pre></div></div>

<p>Let’s see the TerminusDB WOQL query using woql.js</p>

<div><div><pre><code>
<span>or</span><span>(</span><span>triple</span><span>(</span><span>'</span><span>v:Person</span><span>'</span><span>,</span> <span>'</span><span>knows</span><span>'</span><span>,</span> <span>'</span><span>v:OtherPerson</span><span>'</span><span>),</span>
   <span>triple</span><span>(</span><span>'</span><span>v:OtherPerson</span><span>'</span><span>,</span><span>'</span><span>knows</span><span>'</span><span>,</span><span>'</span><span>v:Person</span><span>'</span><span>)</span>
<span>)</span>

</code></pre></div></div>

<p>How do we get only people who knows each other and are patients of the doctor <strong>Freud</strong> ?</p>

<p>Neo4j Cypher query example</p>

<p><img src="https://terminusdb.com/blog/assets/images/neo4j-graph-knows-doc.png" alt=""></p>

<div><div><pre><code>
<span>MATCH</span> <span>(</span><span>doc</span><span>:</span><span>Doctor</span> <span>{</span> <span>name</span><span>:</span> <span>'Freud'</span> <span>}</span><span>)</span><span>&lt;-</span><span>[:</span><span>IS_PATIENT_OF</span><span>]</span><span>-</span><span>(</span><span>person</span><span>:</span><span>Person</span><span>),</span>
      <span>(</span><span>doc</span><span>:</span><span>Doctor</span> <span>{</span> <span>name</span><span>:</span> <span>'Freud'</span> <span>}</span><span>)</span><span>&lt;-</span><span>[:</span><span>IS_PATIENT_OF</span><span>]</span><span>-</span><span>(</span><span>otherPerson</span><span>:</span><span>Person</span><span>)</span>
<span>WHERE</span> <span>(</span><span>person</span><span>:</span><span>Person</span><span>)</span><span>-</span><span>[:</span><span>KNOWS</span><span>]</span><span>-</span><span>(</span><span>otherPerson</span><span>:</span><span>Person</span><span>)</span>
<span>RETURN</span> <span>person</span><span>.</span><span>name</span>

</code></pre></div></div>

<p>TerminusDB query example</p>

<p><img src="https://terminusdb.com/blog/assets/images/terminusdb-graph-know-doc.png" alt=""></p>

<div><div><pre><code><span>and</span><span>(</span>
  <span>triple</span><span>(</span><span>'</span><span>v:Person</span><span>'</span><span>,</span> <span>'</span><span>knows</span><span>'</span><span>,</span> <span>'</span><span>v:OtherPerson</span><span>'</span><span>),</span>
  <span>triple</span><span>(</span><span>"</span><span>v:Doc</span><span>"</span><span>,</span><span>'</span><span>patient</span><span>'</span><span>,</span><span>'</span><span>v:Person</span><span>'</span><span>),</span>
  <span>triple</span><span>(</span><span>"</span><span>v:Doc</span><span>"</span><span>,</span><span>'</span><span>patient</span><span>'</span><span>,</span><span>'</span><span>v:OtherPerson</span><span>'</span><span>),</span>
  <span>triple</span><span>(</span><span>"</span><span>v:Doc</span><span>"</span><span>,</span><span>'</span><span>name</span><span>'</span><span>,</span><span>'</span><span>v:Freud</span><span>'</span><span>)</span>
<span>)</span>

</code></pre></div></div>

<p>Let’s jump into another interesting tutorial and continue to build
<a href="https://terminusdb.com/blog/2020/07/27/taking-terminusdb-to-the-bank/">Bank Tutorial</a></p>


        </div>

        



      </div>
    </div></div>]]>
            </description>
            <link>https://terminusdb.com/blog/2020/09/24/graph-databases-terminusdb-vs-neo4j/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24628809</guid>
            <pubDate>Tue, 29 Sep 2020 15:15:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deprecate WebSockets: GraphQL Subscriptions Using SSE]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24628801">thread link</a>) | @ChrisArchitect
<br/>
September 29, 2020 | https://wundergraph.com/blog/deprecate_graphql_subscriptions_over_websockets | <a href="https://web.archive.org/web/*/https://wundergraph.com/blog/deprecate_graphql_subscriptions_over_websockets">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>WebSockets are an outdated technology deemed dead thanks to the ietf not adding HTTP/2 support. Using Server Sent Events, we could simplify the implementation of GraphQL Subscriptions, reduce frontend code and increase performance as well as flexibility when writing modern frontend applications.</p><p>GraphQL subscriptions are a mechanism to stream updates from the GraphQL server to the GraphQL client. You can use subscriptions e.g to automatically update the UI once there's a new message available in a chat room. Here's an example Operation:</p><div><div><div tabindex="0"><div><p><span>subscription Chat </span><span>{</span><span></span></p><p><span>  messages</span><span>(</span><span>room</span><span>:</span><span> </span><span>1</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>    message </span><span>{</span><span></span></p><p><span>      id</span></p><p><span>      author</span></p><p><span>      text</span></p><p><span>    </span><span>}</span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span></span><span>}</span></p></div></div></div></div><p>In order to stream messages from the server to the client, there needs to be a persisted connection between the two. The most used transport for GraphQL Subscriptions is using WebSockets based on the <a href="https://github.com/apollographql/subscriptions-transport-ws/blob/master/PROTOCOL.md" target="_blank" rel="noopener noreferrer">GraphQL over WebSockets Protocol</a> by Apollo.</p><p>I'd like to discuss various aspects of this approach and why I think we should deprecate it in favour of technology that is a much better fit, Server-Sent Events (SSE).</p><p>To initiate the protocol it's not enough to just open a WebSocket connection. The client needs to send a "connection init" message to which the server needs to respond with "ack". WebSockets operate over TCP so it's not obvious to me why you would need to ack receiving a message.</p><p>Once the initial message is acknowledged the client needs to send a GraphQL operation alongside the ID of the operation. Both the client and the server have to remember the ID of each individual Operation because all Operations/Subscriptions get multiplexed over a single WebSocket connection. This makes the implementation of both server and client overly complex. We will see how SSE will improve this because it takes care of the multiplexing for us.</p><p>If the client decides to unsubscribe a subscription it needs to send a "stop" message over the WebSocket connection. This gets once again acknowledged by the server sending a "done" message. Again, as this is still using TCP I'm not sure why this is required.</p><p>Multiplexing in terms of GraphQL means that multiple Subscriptions use the same connection. In case of the implementation over WebSockets multiplexing is implemented using Javascript. This code needs to be written and maintained. It needs to be transpiled and then must run in each and every browser. Ideally, we can remove as much code as possible to simplify development and keep the Javascript running in the browser as little as possible.</p><p>The Browser API to use Server-Sent Events is named EventSource. While WebSockets allow bidirectional communication, Server-Sent Events, as the name indicates only allow the server to stream events to the client and not in both directions. Luckily, we don't have to stream messages from the client to the server to implement GraphQL subscriptions. We simply open one EventSource for each Subscription. This simplifies both the client as well as the server implementation. There's no more custom code required to remember operations and their ID's to associate a message with the right Subscription. Multiplexing is done by the client &amp; server automatically.</p><p>The ietf decided to not add WebSocket support over HTTP/2. This means that for each WebSocket connection, the browser has to open a new TCP connection to the server because the initial Handshake is based on HTTP/1.1. Depending on the browser your users are using the number of allowed TCP connections per host varies between 2 and 8 averaging at around 5. Keep in mind that a user might open multiple tabs with the same website so you should try keeping open connections at a minimum.</p><p>With Server-Sent Events this is a different story. Server-Sent Events, when used with HTTP/2 multiplex automatically over a single TCP Connection. This means you can open more than 100 EventSources to the same host across multiple tabs and would still only use one single TCP connection.</p><p>These days, component-based single page applications get more and more popular. Frameworks like React, Vue, Flutter etc. all have some concept of Components that take data and render it.</p><p>Using a persisted WebSocket connection means we have to use dependency injection to make this connection available to all components.</p><p>With the EventSource API on the other hand we can simplify the code required to implement Subscriptions. Here's an example using React's Hooks API:</p><div><div><div tabindex="0"><div><p><span>const</span><span> </span><span>SubscriptionComponent</span><span> </span><span>=</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>    </span><span>const</span><span> </span><span>[</span><span>data</span><span>,</span><span>setData</span><span>]</span><span> </span><span>=</span><span> </span><span>useState</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span>    </span><span>useEffect</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>        </span><span>const</span><span> source </span><span>=</span><span> </span><span>new</span><span> </span><span>EventSource</span><span>(</span><span>"https://example.com/persisted/FooSubscription"</span><span>)</span><span>;</span><span></span></p><p><span>        source</span><span>.</span><span>onmessage</span><span> </span><span>=</span><span> </span><span>e</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>            </span><span>setData</span><span>(</span><span>e</span><span>.</span><span>data</span><span>)</span><span>;</span><span></span></p><p><span>        </span><span>}</span><span></span></p><p><span>        </span><span>return</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>            source</span><span>.</span><span>close</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span>        </span><span>}</span><span></span></p><p><span>    </span><span>}</span><span>,</span><span>[</span><span>]</span><span>)</span><span></span></p><p><span>    </span><span>return</span><span> </span><span>(</span><span></span></p><p><span>        </span><span>&lt;</span><span>div</span><span>&gt;</span><span>{</span><span>data</span><span>}</span><span>&lt;/</span><span>div</span><span>&gt;</span><span></span></p><p><span>    </span><span>)</span><span></span></p><p><span></span><span>}</span></p></div></div></div></div><p>The implementation is rather simple. Once the component get's mounted we start the EventSource. New messages get pushed into setState() to trigger re-rendering the component. The <code>return () =&gt; </code> function at the end of useEffect can be used to clean up the EventSource to avoid memory leaks. No additional library is required to implement multiplexing.</p><p>What looks simple on the client is even simpler on the server. In comparison to WebSockets, Server-Sent Events can be implemented without any additional dependencies. Have a look at this <a href="https://gist.github.com/ismasan/3fb75381cd2deb6bfa9c" target="_blank" rel="noopener noreferrer">Example</a> written in Golang to see how simple the implementation is.</p><p>With all the positive aspects what might hold you back from adopting this?</p><h2>Internet Explorer</h2><p>First of all, the EventSource API is supported by 93.8% by all Browsers. The WebSocket API, on the other hand, is supported by 97.41%. That is because IE does not support the SSE API. Is this a blocker? No, but it contradicts with the idea of reducing complexity. If you want to support IE you have to add a polyfill for the missing API.</p><h2>HTTP/2</h2><p>The EventSource API makes a lot of sense when used together with HTTP/2 because only then you can multiplex all Subscriptions over a single TCP connection. So, if your server or clients don't support HTTP/2 you're in trouble. If you're not sure if your clients can use HTTP/2 you might want to stick with WebSockets.</p><h2>URL length limitations</h2><p>The non-polyfill Browser API to initiate an EventSource doesn't allow you to send a payload. That is, you have to send the Operation as well as the variables in the query string of the URL. Due to URL length limitations, you might not be able to send the Operation in its original format. This problem is best addressed using persisted queries. I've written another article on persisted queries if you want to get more details about the concept.</p><h2>Summary</h2><p>Server-Sent Events and the EventSource Browser API simplify both the client as well as the server implementation a lot. We can reduce the amount of code and are able to improve performance with HTTP/2 while reducing resource consumption because we're running less Javascript code.</p><p>At the same time, we're forced to use Persisted Queries and need to migrate from our WebSocket implementation to SSE, don't we? Not really, this is where WunderGraph comes into the picture.</p><p>We have done the migration already. WunderGraph takes your GraphQL Server with the WebSocket implementation and turns all Subscriptions into Server-Sent Events on the fly.</p><p>We also take care of persisting all GraphQL Operations for you and generate a client for any frontend framework you'd like to use.</p><p>This means you get all the benefits of SSE without any additional work to be done.</p><p>As a side effect your GraphQL server becomes a lot more secure because it's not directly exposed anymore to the public. It's hidden behind WunderGraph which only allows the persisted you previously registered.</p><h2>There's one more thing..</h2><p>Did you know that the Query Planner of WunderGraph allows you to join Subscriptions with other data sources?</p><div><div><div tabindex="0"><div><p><span>subscription RocketStatus </span><span>{</span><span></span></p><p><span>  rocketStatus </span><span>{</span><span></span></p><p><span>    speed</span></p><p><span>    altitude</span></p><p><span>    aboveCountryCode</span></p><p><span>    country </span><span>{</span><span></span></p><p><span>      name</span></p><p><span>      capital</span></p><p><span>      currency</span></p><p><span>    </span><span>}</span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span></span><span>}</span></p></div></div></div></div><p>This feature allows you to join any type of different data sources together with very little configuration.</p><p>For the future we're planning to add support for GraphQL Federation. This means you will be able to have Subscriptions and many more features for your federated GraphQL implementations thanks to the WunderGraph Query Planner and Execution Engine.</p><p>If you're interested in this functionality, leave your email in the chat so we can inform you once we have implemented it.</p></section></div>]]>
            </description>
            <link>https://wundergraph.com/blog/deprecate_graphql_subscriptions_over_websockets</link>
            <guid isPermaLink="false">hacker-news-small-sites-24628801</guid>
            <pubDate>Tue, 29 Sep 2020 15:15:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I regained control when my startup dream was crashing down]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24628760">thread link</a>) | @robertorodes
<br/>
September 29, 2020 | https://freegrowth.co/blog/regain-control/ | <a href="https://web.archive.org/web/*/https://freegrowth.co/blog/regain-control/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wtr-content" data-bg="#FFFFFF" data-fg="#f44813" data-width="5" data-mute="1" data-fgopacity="0.5" data-mutedopacity="0.5" data-placement="top" data-placement-offset="0" data-content-offset="0" data-placement-touch="top" data-placement-offset-touch="0" data-transparent="" data-touch="1" data-non-touch="1" data-comments="0" data-commentsbg="#ffcece" data-location="page" data-mutedfg="#f44813" data-rtl="">
<p><em>“I feel useless. This is not our place.”</em></p>



<p>It all came out of my mouth while working with my brother.</p>



<p>That was a feeling we both had been sharing for long. This time I just said it out loud.</p>



<p>After having failed twice with our previous startups, we were trying one more time.&nbsp;</p>



<p>However, after looking for success for more than six years, this one looked like our last chance.</p>



<p>Little was the energy and money that remained on us. We were on the ropes.</p>



<p>One more time, we were desperately trying to come up with a new business idea out of thin air. And again, we’d just hit a wall. </p>



<p>The pieces were falling down.</p>



<p>It felt like we were always running in circles.&nbsp;</p>



<p>After all the energy and effort, nothing seemed to work. We felt we’d grown a lot. We’d learned many valuable skills. Yet, nothing appeared to make a difference.</p>



<p>And as if that wasn’t enough, we felt tremendously undervalued by people in our environment.</p>



<p>It was devastating.</p>



<p>“We need to move forward once and for all.” —that was the recurring thought for long.&nbsp;</p>



<p>Nonetheless, this time we’d reached a breaking point.</p>



<p>We’d always relied on the standard advice.&nbsp;</p>



<p>We followed Lean Startup, made customer discovery, interviewed people, did surveys, performed market experiments, and built MVPs.</p>



<p>We designed landing pages, run Facebook Ads campaigns, and used many of the usual tools and tactics.&nbsp;</p>



<p>We tried everything.&nbsp;</p>



<p>And still, nothing worked.</p>



<p>After lots of research and conversations, I’m sure this is more common than it seems.&nbsp;</p>



<p>It’s a real struggle for many. And if that’s your case, stay calm. You’re not alone.</p>



<p>Today I’m sharing what probably was the most crucial lesson we learned along more than six years of pain, suffering, and effort to get out of the blockade.&nbsp;</p>



<p>We hope it will serve you too as a first step to start making progress in the right direction once and for all.</p>



<h2><strong>Getting off track as soon as you start the race.</strong></h2>



<figure><img src="https://freegrowth.co/wp-content/uploads/2020/08/jamie-street-_94HLr_QXo8-unsplash-1024x690.jpg" alt="" srcset="https://freegrowth.co/wp-content/uploads/2020/08/jamie-street-_94HLr_QXo8-unsplash-1024x690.jpg 1024w, https://freegrowth.co/wp-content/uploads/2020/08/jamie-street-_94HLr_QXo8-unsplash-300x202.jpg 300w, https://freegrowth.co/wp-content/uploads/2020/08/jamie-street-_94HLr_QXo8-unsplash-768x517.jpg 768w, https://freegrowth.co/wp-content/uploads/2020/08/jamie-street-_94HLr_QXo8-unsplash-1536x1035.jpg 1536w, https://freegrowth.co/wp-content/uploads/2020/08/jamie-street-_94HLr_QXo8-unsplash-2048x1380.jpg 2048w" sizes="(max-width: 1024px) 100vw, 1024px" data-lazy-srcset="https://freegrowth.co/wp-content/uploads/2020/08/jamie-street-_94HLr_QXo8-unsplash-1024x690.jpg 1024w, https://freegrowth.co/wp-content/uploads/2020/08/jamie-street-_94HLr_QXo8-unsplash-300x202.jpg 300w, https://freegrowth.co/wp-content/uploads/2020/08/jamie-street-_94HLr_QXo8-unsplash-768x517.jpg 768w, https://freegrowth.co/wp-content/uploads/2020/08/jamie-street-_94HLr_QXo8-unsplash-1536x1035.jpg 1536w, https://freegrowth.co/wp-content/uploads/2020/08/jamie-street-_94HLr_QXo8-unsplash-2048x1380.jpg 2048w" data-lazy-src="https://freegrowth.co/wp-content/uploads/2020/08/jamie-street-_94HLr_QXo8-unsplash-1024x690.jpg?is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Photo by <a href="https://unsplash.com/@jamie452?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Jamie Street</a> on <a href="https://unsplash.com/collections/11722728/article%3Ahow-to-start-moving-forward-when-you-are-starting-up/14b4d886248c3fd5d964d5507a1b57fb?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></figcaption></figure>



<p>I jumped into my first independent startup venture more than eight years ago.</p>



<p>At that time, I’d just left Facephi, the startup I joined as its first employee and CTO.&nbsp;</p>



<p>After more than four years, a pretty nice salary, a remarkably promising product out into the market, and 2+ million in investor funding, I felt the time for a change had come.</p>



<p>I wanted to keep growing.</p>



<p>I was trying to run away from things I didn’t want in my life and desired to create my own business.</p>



<p>I wanted to become happier and more fulfilled, but my idea of what all that meant was pretty fuzzy by then.&nbsp;</p>



<p>Obviously, starting a path without knowing what I was seeking was a ticket for disaster.</p>



<figure><blockquote><p>Would you tell me, please, which way I ought to go from here? —said Alice.<br>That depends a good deal on where you want to get to. —said the Cat.<br>I don’t much care where. —said Alice.<br>Then it doesn’t matter which way you go. —said the Cat.</p><cite>Lewis Carrol, Alice in Wonderland.</cite></blockquote></figure>



<p>I got captive and became a slave of my business and all the stakeholders around.</p>



<p>I had little time for what I enjoyed doing. I was dragged by meetings, external requests, recruiting, managing people, looking for funding, doing administrative tasks, putting out fires in general, and carrying out other unfulfilling stuff.</p>



<p>As a consequence, everything I did was useless. I couldn’t focus on the important, and couldn’t make any meaningful progress.</p>



<p>To top it all, it affected my personal life as well.</p>



<p>I didn’t have much time for family and friends anymore. I started doing far less physical exercise, began eating and sleeping worse, and had to renounce other goals in my life.</p>



<p>In every way, I neglected my health and well-being.</p>



<p>The case of my brother was no different.</p>



<p>It was evident that we’d made many unfitting choices.</p>



<h2><strong>The exit is inward.</strong>..</h2>



<blockquote><p>The least obvious part of the system, its function or purpose, is often the most crucial determinant of the system’s behavior.</p><cite><em>Daniella Meadows, Thinking in Systems</em></cite></blockquote>



<p>Where was I trying to get to? That’s the question I started asking myself following our last failure.</p>



<p>I had an intuition, but I’d never taken the time to reflect deep enough on it. I must admit that, up to that point, and to some extent, I’d looked outside for answers.</p>



<p>I needed to find the reasons why I was doing what I was doing. So, after a profound exercise of introspection and 6+ years of hustling, I finally found out what I was searching for.</p>



<p>In essence, I wanted to be freer to do what intrinsically moves me.&nbsp;</p>



<p>I wanted to feel useful and, what’s more important, live ethically. I felt a deep desire to do the right thing.</p>



<p>That was the purpose I expected entrepreneurship to fulfill in my life. That’s what success looked like to me.</p>



<p>This level of clarity caused a radical shift in our way of thinking.</p>



<p>It was like finding a light in the middle of darkness.&nbsp;</p>



<p>Everything became pretty more evident than before. Without knowing where we wanted to get to, it was barely impossible to get to our right place.</p>



<p>The question is that, when everything started, I didn’t know that I didn’t know it —even though I thought I did.&nbsp;</p>



<p>It’s easy not to notice it. Society bombards you with deceptive images of success and demands you to follow them.&nbsp;</p>



<p>You know, the dream of the billion-dollar companies and the hypergrowth VC path.</p>



<p>But this is a dangerous trap to fall into.</p>



<p>We fell dragged into those fake ideals and made life-changing decisions when what we wanted for our future was still blurred in our minds.</p>



<p>And inadvertently, we started being driven by others’ goals.</p>



<p>Now, one thing was neat. Whatever new system we followed, it should deliver on what we value.</p>



<p>It should be meant to get more freedom to explore, learn, and create on our own terms.&nbsp;</p>



<p>It should aim to gain more room to pursue other goals and grow in other areas of our lives.</p>



<p>And last but not least, it should help to contribute to this world, for good.</p>



<p>Did I need to build a macro-business overnight for that? Of course not. There was a more sustainable path.</p>



<p>Now, we wouldn’t focus on developing a high-growth business. Instead, we’d make it all about growing ourselves successfully as creators.&nbsp;</p>



<p>We turned our approach inside out and pressed a key that would change the rules of the game forever.</p>



<p>This new mindset suddenly made many vital decisions to become evident.</p>



<h2>Getting more freedom.</h2>



<p>This time, <strong>we decided to grow our new venture by ourselves</strong>. Unlike previous projects, we chose to avoid toxic relationships and commitments with investors and other stakeholders that could get us off track again.</p>



<p>Now, with Freegrowth, we’ve come to follow the bootstrapping route.</p>



<p>Second, <strong>we chose to work remotely and pick our work hours</strong>. We did it about a year ago and haven’t regretted ever since.&nbsp;</p>



<p>Now, no particular physical location or schedule ties us.&nbsp;</p>



<p>We toil at whatever time that better works for us, from whatever place that better fits our lives —something that, especially in the face of the current times, has proven invaluable.</p>



<p>Last, <strong>we chose to diversify and avoid long-term lock-in by the projects we get into</strong>. It’s our way to control risk and bring optionality into our path.</p>



<p>As in the stock market, these days, we strive to keep our risk portfolio balanced by combining high-risk investments with other safer options.&nbsp;</p>



<p>Here, we are the resource to invest, so we better do it wisely.</p>



<figure><blockquote><p>Common sense suggests that creative accomplishments can’t flourish without big windows of time and energy, and companies can’t thrive without intensive effort. Those assumptions overlook the central benefit of a balanced risk portfolio: Having a sense of security in one realm gives us the freedom to be original in another. By covering our bases financially, we escape the pressure to publish half-baked books, sell shoddy art, or launch untested businesses.</p><cite>Adam Grant, Originals.</cite></blockquote></figure>



<p>In the same fashion, we turned our attention toward the concept of liquidity.</p>



<p>Now, we approach our growth through small bets. We explore the terrain before anything else and make sure of the way to go before committing further.</p>



<p>Before getting ourselves tied to any particular commitment, we explore and try first.&nbsp;</p>



<p>We focus on experiencing what it takes and feels like to go through a given route. We try to uncover what we don’t know before moving on. That way, we cap the risk of getting into a place we don’t want to be.</p>



<p>There are many implications related to this.&nbsp;</p>



<p>To cite an example, consider that different types of products involve different levels of commitment. A SaaS app implies a dependency of customers on us. Among other things, it carries with it the need to deliver customer support for the long-haul.&nbsp;</p>



<p>As such, it entails a life-long responsibility.&nbsp;</p>



<p>Today, before building a product, we assess the level of commitment we want to assume.</p>



<p>If we consider building a software product, we ask ourselves, “Is this something we want to commit our time, money, energy, and knowledge for years?”</p>



<p>If the answer is no, we move on to another thing.</p>



<p>If we are not sure yet, maybe we’ll work on removing the uncertainty through smaller bets.</p>



<p>If the answer is “<a href="https://sive.rs/hellyeah">Hell yeah!</a>” then well…still, in the early stages, we’ll approach it through small bets to give us room to change course if necessary —we don’t know what we don’t know yet.</p>



<h2>Learning and creating.</h2>



<p>We focused on learning and creating regularly.&nbsp;</p>



<p><strong>We made study a part of our routine</strong>. It was already there, but now we made it more prominent.</p>



<p>Acquiring <a href="https://marker.medium.com/the-case-for-generalists-29f9af19c8da">range</a> and depth in and out of our fields has become a habit for satisfying our curiosity and overcoming upcoming challenges.&nbsp;</p>



<p>That has proven to be game-changing as it’s giving us a more holistic vision to find and approach problems and shape better solutions. While we previously operated from the ground, now we work from a 10000-feet perspective.</p>



<p>On the other hand, <strong>we chose to release …</strong></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://freegrowth.co/blog/regain-control/">https://freegrowth.co/blog/regain-control/</a></em></p>]]>
            </description>
            <link>https://freegrowth.co/blog/regain-control/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24628760</guid>
            <pubDate>Tue, 29 Sep 2020 15:11:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Breaking down the complexity of notification system design]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24628595">thread link</a>) | @JaneKCall
<br/>
September 29, 2020 | https://magicbell.io/blog/building-a-user-notification-system/ | <a href="https://web.archive.org/web/*/https://magicbell.io/blog/building-a-user-notification-system/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://magicbell.io/blog/content/images/size/w300/2020/09/MagicBell.gif 300w,
                            https://magicbell.io/blog/content/images/size/w600/2020/09/MagicBell.gif 600w,
                            https://magicbell.io/blog/content/images/size/w1000/2020/09/MagicBell.gif 1000w,
                            https://magicbell.io/blog/content/images/size/w2000/2020/09/MagicBell.gif 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://magicbell.io/blog/content/images/size/w2000/2020/09/MagicBell.gif" alt="Can you build a complete notification system without breaking a sweat?">
            </figure>

            <section>
                <div>
                    <p>User notifications significantly increase engagement in social apps and productivity in business apps. Today, email notifications, web notifications, and cross-platform mobile push notifications have become the standard in user expectations. While some savvy customers want notifications sent to their Slack channels, others might want SMS notifications. Keeping customers in the loop through all the channels is a monumental task--and not one your development team’s core competency or interest.</p><p>Before <a href="https://www.mailgun.com/" rel="noopener nofollow">Mailgun</a> and <a href="https://postmarkapp.com/" rel="noopener nofollow">Postmark</a> were on the map, companies struggled with reliably delivering emails. Before Facebook Connect or Google Auth, everyone built their own authentication systems. </p><p>Not anymore. With <a href="https://magicbell.io/">MagicBell</a>, nobody has to worry about building a bespoke notification system ever again.</p><h2 id="the-complexity-of-notifications">The Complexity of Notifications</h2><p>Let’s consider the most basic, cross-platform notifications setup. A system event requires a user notification(for example, if they were tagged in a comment). If you provide a web app, you’ll first need to verify the user is online before you can send them a notification in-app. If they are offline, you’ll need to push the notification via email. (You can push the notification through both channels, but we believe this practice to be less effective). </p><p>If you also offer a mobile app, you may send them a push notification, but then you should remember to remove it if your user sees it on another channel. To get an idea of just how complex notification systems can get, take a look at this flow chart that Slack, which offers a visual of heir notifications logic:</p><figure><img src="https://magicbell.io/blog/content/images/2020/01/0GXxzU9.jpg"><figcaption>Slack’s notifications logic, thanks to Slack</figcaption></figure><p>And that’s just the very basic notifications. What if you would like your users to act on notifications, send them a digest version, or offer other channels like Slack or SMS? Then things get even more complex. And you want to split test your notification, or analytics on the effectiveness of your notifications on user engagement, you’re going to have to build out even more pathways.</p><h2 id="the-secret-world-of-notification-mismanagement">The Secret World of Notification Mismanagement</h2><p>A lot of companies build a notification system but barely have time to maintain or improve it. Notifications are not just fired and forgotten. You need to worry about deliverability and giving your users subscription options and troubleshooting help. &nbsp;An additional concern is the management of notification preferences; you’ll need to build a screen where they can select how and when they want to be notified and about what. Finally, there’s security. Most don’t have any debugging or customer support infrastructure around notifications and end up just hoping for the best. </p><h2 id="introducing-magicbell">Introducing MagicBell</h2><p>There’s a silver lining. These implementation patterns are highly similar across products and companies and render themselves well to a SaaS service. </p><p>We have been thinking about this problem for many years in SupportBee and finally decided we were the ones to solve it. </p><p>We introduce our solution: MagicBell.</p><h2 id="your-email-notifications-supercharged-">Your Email Notifications, Supercharged!</h2><p>One more thing. Apps and services almost always offer email notifications. MagicBell re-uses your email notifications to give your users a notification center, automagically. All you have to do is BCC: your email notifications to a project-specific magic email address, and we do the rest! MagicBell sorts emails and understands who the notification is for, what the title of the notification is, and where it should direct the user.</p><p>All of this behavior is customizable in under than 5 mins: <a href="https://magicbell.supportbee.com/149-magicbell-s-help-docs/269-email-setup/381-configure-postfix-to-bcc-emails">BCC emails in postfix</a> with just one line of config change, and embed our widget in your site. To <a href="https://magicbell.supportbee.com/149-magicbell-s-help-docs/269-email-setup/341-customizing-notifications-using-email-headers">customize the notifications</a>, simply send us some custom email headers.</p><p>For more intelligent delivery, send us the email notifications via SMTP and let us worry about notification preferences, and smart delivery to the right channels, including email. </p><figure><img src="https://magicbell.io/blog/content/images/2020/01/image.png"></figure><p><a href="https://magicbell.io/" rel="noopener nofollow">MagicBell</a> is currently delivering over a million notifications a month for some great products. I invite you to give it a try for your app or service. <a href="https://magicbell.typeform.com/to/RNKqWW">P</a>lease <a href="https://app.magicbell.io/">signup for an account</a> or <a href="https://calendly.com/hana_mohan/30min">book a demo</a>.</p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://magicbell.io/blog/building-a-user-notification-system/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24628595</guid>
            <pubDate>Tue, 29 Sep 2020 14:58:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Doing discourse better: Stuff I wish I knew]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24628593">thread link</a>) | @dyno-might
<br/>
September 29, 2020 | https://dyno-might.github.io/2020/09/29/doing-discourse-better-stuff-i-wish-i-knew/ | <a href="https://web.archive.org/web/*/https://dyno-might.github.io/2020/09/29/doing-discourse-better-stuff-i-wish-i-knew/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <div>
        

<div>
    <div>
        <div>
            <p><strong>Sep 29, 2020</strong></p>
            





<p>Nick and Maria want to talk about sugar. Does it reduce lifespan? They disagree, but are honest and principled. They want to find the truth and agree on it.</p>

<p>How should they talk? Take turns? Try hard to be polite and respectful? Allow interruptions? Search for origins of disagreement? Areas of agreement? Make bets? Get a moderator?</p>

<p>Or maybe Nick and Maria want to talk about tax-exemption for churches. It might be hard to get consensus, since this is a matter of opinion. Still, they’d like to reduce their disagreement to different underlying values. What should they do? Repeat the other’s argument? Tell personal stories? Run ideological Turing tests?</p>

<p>Do conversations have known best practices? How much do they improve the odds of landing on the truth?</p>



<p>In East Africa 70,000 years ago, humans made their first steps towards language. This didn’t happen for <em>truth</em>, it happened to <em>increase reproductive fitness</em>. Overly open-minded people were probably easy to manipulate. Scrupulously honest people were probably bad at manipulating. Many false beliefs still <em>enhanced reproductive fitness</em> (typically by <a href="https://dynomight.home.blog/2020/05/27/sapiens-part-1-the-cognitive-revolution/">improving cooperation</a>).</p>

<p>So, one might argue, <em>of course</em> we are terrible at finding truth via conversation! Why are we surprised that our instincts are bad at something we never evolved to be good at?</p>



<p>Doing some research, Maria finds the work of Robert Cialdini, who says we are persuaded by reciprocity, scarcity, authority, consistency, liking, and consensus. But these don’t seems useful to Maria. They are mostly “dark patterns” of persuasion, that work for anything regardless of its truth.</p>

<p>Instead, are there “non-dark” patterns of persuasion, that work well <em>for true stuff</em> but not for false stuff?</p>



<p>Over a few months, Nick and Maria have a dozen of these conversations. The results are exactly what you’d expect: No one ever changes their mind about anything. Maria has a feeling she can’t be right about <em>everything</em>. But try as she might, she can’t find a case where Nick’s arguments convince her.</p>

<p>Eventually, she has a strange idea. Maybe she should fight fire with fire, cognitive-bias wise. She decides that in each discussion they should both <em>intentionally</em> subject themselves to as much dark-pattern manipulation as possible. Her theory is that there is an “energy barrier” that prevents them from getting into a mind-space where it’s even possible to appreciate the other position fairly.</p>

<p>By temporarily brainwashing themselves a little bit, can they can actually give the other position a fair chance?</p>



<p>It’s reasonable to be skeptical about the above ideas. Humans have been talking for 70,000 years. If there was a trick to talking better, wouldn’t we have found it already? I showed some of the above thoughts to a friend, who responded, “LOLOLOLOLOL, dynomight, you sweet wide-eyed gazelle. The rare Nicks and Marias of the world do great already. The problem is <em>dishonest</em>, <em>unprincipled</em> people.”</p>

<p>So perhaps better conversation can’t save the world. Still, I think a different type of discourse has much more room for improvement: That in <em>online forums</em>. It sounds hyperbolic, but I genuinely believe this could move the needle on the future of humanity.</p>

<p>Just think about it. The world is a complex place. Want to understand the effects of the minimum wage? The long-term trajectory of population growth? The effects of vitamin C? No one human brain can process all the relevant information for such questions. But shouldn’t <em>groups</em> of brains, if we could “network” them properly, have much greater capabilities?</p>



<p><img src="https://dyno-might.github.io/img/discourse/conversational_graphs.png">
</p>

<p>Online forums have various design dimensions.</p>

<ul>
  <li><strong>Conversational graphs.</strong> An old-school message board is a chronological list. Modern forums (Reddit, LessWrong) represent comments in a reply tree. On 4chan, a directed acyclic graph of replies is overlaid on the chronological list: Someone can reply to multiple messages, and pointers are provided at both ends to move around the graph that way. In Stack Overflow, <em>answers</em> are ordered by votes, but <em>comments on answers</em> are chronological.</li>
  <li><strong>Voting.</strong> Some don’t use it at all (old-school boards). Some order everything by votes (Reddit). Some use votes to order some levels but not others (Stack Overflow).</li>
  <li><strong>Who can put content where?</strong> On Twitter, anyone can throw their replies up on anyone else’s content. It would be a very different place if you could only do this if that person followed you.</li>
  <li><strong>Moderation.</strong> This varies from <em>Moderate to Crush the Human Spirit</em> (Stack Overflow) to <em>Moderate When Alternative is Prison</em> (4chan).</li>
</ul>

<p>It’s hard to understand the influence of most of these choices, since popular forums vary along many dimensions at the same time. Most forums today are optimized for the goal of “make forum owners rich.” We don’t know the decision-making process, or what tradeoffs would be made with different goals.</p>

<p>I don’t think it’s possible to sit around and figure out what effects a given forum design will have. Human beings and social behavior are too complex. We need to systematically test the different designs, and see what actually happens empirically. Is anyone doing that?</p>



<p>Here are some ideas:</p>

<ul>
  <li>Sometimes people have useful ideas, but give them in a long, boring, hard to read form. Can we allow users to edit each others’ content?</li>
  <li>“Flattening” comments into a linear order is always a distortion. Why not learn-in to the idea of a full conversational graph, with some kind of visualization that allows people to elegantly navigate it?</li>
  <li>Inside a conversation are many interesting sub-conversations. Can users create “curated views” to highlight the best comments in one sub-conversation?</li>
  <li>We <em>say</em> we want beauty and truth and to be better people. But we can’t resist cat videos and the latest political outrage. Can we allow users to “Ulysses nudge” themselves, by choosing the kind of content they <em>wish</em> they enjoyed? Let the algorithm find a way to try to manipulate the user into doing what the user’s “better self” wants.</li>
  <li>Forums are great ways to share knowledge. Prediction markets are also a great way to combine knowledge. Can we find an effective way to combine the two?</li>
</ul>

<p>These ideas are all probably terrible. I’m just trying to say that there’s a <em>lot</em> of possibilities, and some of them are surely good.</p>

<p>Suppose we could look 30 years into the future. Forums will no doubt look very different. Probably some of the differences rely on exogenous technological innovation. But surely <em>some</em> differences could be “back-ported” to today, if only we knew what they were. What are they, and why is the pace of innovation in online forums so slow right now?</p>



<p>If we want a historical example of “public forum with rules and norms carefully derived to find truth” I think the best we can do is the system of journal publications. For all their imperfections, these have done a decent job of uncovering truth for several hundred years. What lessons do these offer?</p>

<p>I think for our purposes, the three biggest differences vs. online forums today are:</p>

<p>First, journals have a <em>crazy</em> focus on <strong>credit attribution</strong>. There is a formalized system of citations. Reviewers check that the claimed new ideas in papers really are new, and that credit (citations) have been provided to all (most? some?) related work. One paper can reply (cite) to many other papers. (Journals share this with 4chan!)</p>

<p>Second, journals provide strong <strong>quality signals</strong> coupled to <strong>heavy “moderation”</strong>. In most fields there is a fairly clear status hierarchy. The moderators (reviewers/editors) at top journals spend a lot of effort moderating, and are very picky about what they accept. This provides strong signaling for the papers that are accepted.</p>

<p>Third, there are extremely strong <strong>external incentives</strong> for people to appear in the top journals. (Ultimately, jobs and money are on the line.)</p>

<p>There other differences (e.g. journals are slow and cost money) but I think the three above are the most significant. What would happen if we added these to online forums today? Unfortunately, it’s a bit hard to say. These wouldn’t be easy to copy. The first is laborious, and the others are as much properties of the society the journal is embedded in as the journal system itself.</p>



<p>Maybe figuring out how to improve forums is hard. As a first step, maybe we can at least understand where things go wrong? Here’s some proposed failure modes.</p>

<p><strong>The user death spiral.</strong> Some cool people start a forum and have cool conversations. Random trolls show up sometimes, but they are easily banned. Eventually, some not-quite-as-cool people find their way to the forum. They aren’t misbehaving and make some good points sometime. It feels tyrannical to ban them so no one does. Still, the coolest people become slightly more likely to drift away. New very-cool people become slightly less likely to join. Eventually the median shifts enough that barely-cool-at-all people are joining. Gradually, the average coolness of people in the forum decreases to zero.</p>

<p><strong>The tyranny of the minority.</strong> Human experience is vast. There are people out there who truly, passionately believe that bestiality should be legal and accepted. Some are smart and compelling writers. Almost all forums block these people. You don’t, figuring that you believe in free speech, these people are a tiny minority, and the truth will emerge as they argue with the majority. Suddenly, in every thread people are findings connections to the “injustice” of the current prohibition on bestiality. Why? Because every other high-status place on the internet prohibited these people, and they’ve all been funneled to you.</p>

<p><strong>The village becomes anonymous.</strong> In small forums, you see the same person repeatedly. This has two advantages: A) You know people will remember you, and you want them to be nice to you, so you try not to act like a jerk. B) After seeing the same people for a while, you have some <em>context</em> for their comments. The conversation can actually evolve and grow over time. After …</p></div></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dyno-might.github.io/2020/09/29/doing-discourse-better-stuff-i-wish-i-knew/">https://dyno-might.github.io/2020/09/29/doing-discourse-better-stuff-i-wish-i-knew/</a></em></p>]]>
            </description>
            <link>https://dyno-might.github.io/2020/09/29/doing-discourse-better-stuff-i-wish-i-knew/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24628593</guid>
            <pubDate>Tue, 29 Sep 2020 14:58:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[HTML Canvas Art in TypeScript]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24628489">thread link</a>) | @xvzq
<br/>
September 29, 2020 | https://www.chrismytton.com/2020/06/06/canvas-art-in-typescript/ | <a href="https://web.archive.org/web/*/https://www.chrismytton.com/2020/06/06/canvas-art-in-typescript/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
<p>I ported a JavaScript “random art generator” I created a few years ago over to TypeScript. This post contains some notes from the process.</p>

<ul>
  <li>See the project: <a href="https://www.chrismytton.com/art/">www.chrismytton.com/art</a></li>
  <li>Check out the code: <a href="https://github.com/chrismytton/art/blob/1f34e99d121f2c7dd698eb8c9d45da1e9b7f450c/src/random.ts">chrismytton/art on GitHub</a></li>
</ul>

<hr>

<p>I’ve been learning TypeScript recently. As part of that I wanted to dig out some of my old JavaScript projects and port them to TypeScript. I find porting code to a new language is a good way to learn.</p>

<p>I found an old project that I created in 2014 which uses JavaScript and the Canvas API to create random pieces of art which change on every page load. The code itself is fairly straightforward, so it seemed like a good candidate for porting to TypeScript.</p>

<h2 id="classes-in-typescript">Classes in TypeScript</h2>

<p>TypeScript classes build on <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Classes">ES6 classes</a>. The major difference is that in TypeScript you need to explicitly declare the types of properties you’re expecting on the class.</p>

<div><div><pre><code><span>class</span> <span>CanvasPainting</span> <span>{</span>
  <span>viewport</span><span>:</span> <span>HTMLCanvasElement</span><span>;</span>
  <span>ctx</span><span>:</span> <span>CanvasRenderingContext2D</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>If you try to use <code>this.viewport</code> without declaring the property TypeScript will tell you:</p>

<blockquote>
  <p>Property ‘viewport’ does not exist on type ‘CanvasPainting’.</p>
</blockquote>

<p>I find having these properties explicitly defined actually makes it easier to figure out what the class might be doing internally. They provide useful documentation about what kind of data you can expect to find in each property.</p>

<h2 id="index-signatures">Index signatures</h2>

<p>This is something I struggled with for a while. I was trying to dynamically call methods on my <code>Shapes</code> class using <code>this[shape]</code>, but TypeScript was giving this warning:</p>

<blockquote>
  <p>Element implicitly has an ‘any’ type because expression of type ‘string’ can’t be used to index type ‘Shapes’.</p>

  <p>No index signature with a parameter of type ‘string’ was found on type ‘Shapes’.</p>
</blockquote>

<p>After reading various bits of the TypeScript documentation and some Stack Overflow answers I eventually figured out that I needed to define an index signature on my shapes class. This tells TypeScript what can be used to index this class, and what the indexing might return.</p>

<div><div><pre><code><span>class</span> <span>Shapes</span> <span>extends</span> <span>CanvasPainting</span> <span>{</span>
  <span>[</span><span>key</span><span>:</span> <span>string</span><span>]:</span> <span>any</span><span>;</span>

  <span>// ...</span>
<span>}</span>
</code></pre></div></div>

<p>This tells TypeScript that you can index this class with a string, and it will return <em>something</em>. There might be a way to avoid using <code>any</code> here, but I haven’t figured that out yet.</p>

<h2 id="dealing-with-null-values">Dealing with null values</h2>

<p>TypeScript knows which methods can return <code>null</code> and will make you deal with those cases. If you try to call a method on a value that might be null then TypeScript will give you a warning.</p>

<p>You can avoid this warning by explicitly checking for <code>null</code> before using the value.</p>

<div><div><pre><code><span>class</span> <span>CanvasPainting</span> <span>{</span>
  <span>viewport</span><span>:</span> <span>HTMLCanvasElement</span><span>;</span>
  <span>ctx</span><span>:</span> <span>CanvasRenderingContext2D</span><span>;</span>

  <span>constructor</span><span>(</span><span>viewport</span><span>:</span> <span>HTMLCanvasElement</span><span>)</span> <span>{</span>
    <span>this</span><span>.</span><span>viewport</span> <span>=</span> <span>viewport</span><span>;</span>
    <span>const</span> <span>ctx</span> <span>=</span> <span>viewport</span><span>.</span><span>getContext</span><span>(</span><span>'</span><span>2d</span><span>'</span><span>);</span>

    <span>// getContext can return null, so check for that case.</span>
    <span>if</span> <span>(</span><span>!</span><span>ctx</span><span>)</span> <span>{</span>
      <span>throw</span> <span>new</span> <span>Error</span><span>(</span><span>"</span><span>getContext('2d') failed</span><span>"</span><span>);</span>
    <span>}</span>
    <span>this</span><span>.</span><span>ctx</span> <span>=</span> <span>ctx</span><span>;</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Without this check for <code>null</code> TypeScript warns you that <code>Type 'null' is not assignable to type 'CanvasRenderingContext2D'.</code>.</p>

<p>It’s easy to forget to check for <code>null</code> when writing JavaScript. TypeScript protects you from this class of error at the compile stage.</p>

<h2 id="summary">Summary</h2>

<p>I really like what I’ve seen so far with TypeScript. Working on little projects like this is a great way to get some experience with new tools.</p>

<p>I’d forgotten all about this fun little art project. It’s nice to have given it a bit of polish and released it into the world, rather than it gathering dust on my hard drive.</p>

<p>See the project: <a href="https://www.chrismytton.com/art/">www.chrismytton.com/art</a>.</p>

<p>Check out the code: <a href="https://github.com/chrismytton/art/blob/1f34e99d121f2c7dd698eb8c9d45da1e9b7f450c/src/random.ts">chrismytton/art on GitHub</a>.</p>


  </div></div>]]>
            </description>
            <link>https://www.chrismytton.com/2020/06/06/canvas-art-in-typescript/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24628489</guid>
            <pubDate>Tue, 29 Sep 2020 14:50:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Stop the Wildfires]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24628394">thread link</a>) | @Reedx
<br/>
September 29, 2020 | https://www.persuasion.community/p/how-to-stop-the-wildfires?r=222a5 | <a href="https://web.archive.org/web/*/https://www.persuasion.community/p/how-to-stop-the-wildfires?r=222a5">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb40d974-20f0-44d1-8873-0773c651aa72_6583x4389.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb40d974-20f0-44d1-8873-0773c651aa72_6583x4389.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/cb40d974-20f0-44d1-8873-0773c651aa72_6583x4389.jpeg&quot;,&quot;height&quot;:971,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:13915552,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></p><p>Two weeks ago, San Francisco residents awoke to an apocalyptic scene. The sky was blood red. A thick shroud of smoke blocked the sun. Toxic ash fell from the sky.</p><p><a href="https://www.sfchronicle.com/california-wildfires/article/The-day-the-sun-didn-t-come-up-People-in-15554470.php">“The day the sun didn’t rise”</a> marked a low point in the ongoing battle with the California wildfires that have killed dozens and displaced thousands. In some heavily populated regions, the air quality index has exceeded 400, far worse than recent measurements in Beijing or New Delhi. Residents have taken to sealing windows, vents and door jambs with masking tape and plastic. Air filters are out of stock and people already struggling to avoid exposure to a deadly microbe suddenly need to avoid exposure to deadly particulates as well. </p><p>Headlines have been quick to declare that <a href="https://www.youtube.com/watch?v=UW1MYQqvED4">“This Is Climate Change.”</a> Just as quickly, climate skeptics have <a href="https://dailycaller.com/2020/09/13/california-oregon-wildfires-land-management-climate-change/">challenged</a> the claim. Decades of poor forest management at the behest of environmentalists who oppose logging, they argue, is the real culprit. </p><p>Both are partly right. Climate change <em>is</em> making California’s wildfires worse. But California’s forestry policies have massively contributed to the problem. </p><p>Climate change has changed how fires burn in California. Tinder dry conditions make forests burn explosively. And because wildfire season is now fifty percent longer than in the past, it increasingly overlaps with the windiest time of year. For these reasons, small fires are much more likely to turn into big fires very quickly. </p><p>Yet climate change alone can’t explain the onslaught of catastrophic fires the state has faced in recent years. California’s forest and grassland ecosystems are naturally adapted to fire. But a century of fire suppression has turned the state’s forests into a gigantic fuel bunker. When forests like these don’t burn for decades, they become choked with small trees and dense underbrush. When fires do start, there is much more fuel to burn. </p><p>The alternative to burning in many areas is to thin forests, taking out the smaller trees and undergrowth so that there is less fuel and the trees that remain are more resistant to fire. But the state’s powerful environmental lobby has long opposed proposals to thin forests, criticizing them as a lifeline for the state’s failing timber industry.</p><p>Finally, suburban and exurban sprawl into the fire zone has exacerbated the problem. Millions of people now live in the middle of California’s forests, making efforts to limit fire risk through thinning, controlled burns, and other methods more complicated and more controversial.&nbsp; </p><p>Ultimately, it is impossible to disentangle the contributions that climate change, forest management, and suburban and exurban sprawl have made to increasing the risk of catastrophic wildfires in California. But while the causes can’t be disentangled, the solutions can. </p><p>Ambitious efforts to cut carbon emissions, both in California and globally, have much to recommend them. But saving California from fiery apocalypse is not among them. Until fuel loads are dramatically reduced in California’s forests, catastrophic wildfires will continue to wreak havoc across the state. Solving that problem will require a totally different approach to forest management than what either environmentalists or their critics have long favored. </p><p>The environmental community has traditionally advocated letting forests burn, as they did before the arrival of Europeans. But in a state with 39 million residents, many of whom live in close proximity to the fire zone, this is simply unrealistic. Even fires that are far removed from population centers create enormous public health risks. The fire responsible for San Francisco’s red sky at morning, for example, burned in a largely uninhabited area several hundred miles away. Until fuel loads are reduced sufficiently to transition forests back to less intense natural fire regimes, allowing remote fires to burn themselves out is likely to increase the choking smoke that now regularly settles over the state’s densely populated regions. </p><p>Meanwhile, conservatives who insist that the timber industry would, but for onerous environmental regulations, take care of the problem are completely out of touch with the state of the industry, the economics of logging California’s forests, and the reality of what is needed for effective long-term fuel reduction. The state’s remnant timber industry does not remotely have the capacity to thin the state’s forests at the necessary scale. Nor would doing so be economical in many forested regions of the state, as the big trees that pay the bills are largely gone. Even where logging is economically viable, removing mature trees is frequently counterproductive, since they tend to be replaced by more flammable undergrowth.</p><p>Ultimately, neither carbon caps nor subsidies for solar or wind energy will stop California’s wildfires. Resuscitating the timber industry won’t either. Limiting catastrophic wildfires in California will instead require intensive management of the state’s forests at an unprecedented scale. This will require a new, publicly funded forest management industry dedicated not to the extraction of valuable timber for private profit but rather to the removal of low-value underbrush and immature trees for public benefit.</p><p>In the rush to find convenient villains, both climate advocates and their opponents avoid harder policy choices. Conservatives insist that forest management, not climate change, is the cause of the problem—but are unwilling to support big spending to actively manage California forests. Environmentalists argue that climate change “changes everything”—but still insist that the solution to climate fueled megafires is to return to the state’s historic fire pattern. </p><p>Environmentalists are right that, over the long-term, we need to cut carbon emissions to something close to zero. And conservatives are also right that, without radical changes to both land use and forest management policy, catastrophic wildfires will continue to plague the state. To engage these issues in good faith, protagonists on both sides of the debate will need to follow their arguments through to their logical conclusions rather than refusing to accept any inference that contradicts their ideological priors. To succeed in addressing either climate change or California’s wildfires, we will need to stop debates about climate change from degenerating into a stale culture war rather than imagining that we might win them. </p><p><strong>Ted Nordhaus and Alex Trembath are executive director and deputy director, respectively, of the Breakthrough Institute.</strong></p></div></div>]]>
            </description>
            <link>https://www.persuasion.community/p/how-to-stop-the-wildfires?r=222a5</link>
            <guid isPermaLink="false">hacker-news-small-sites-24628394</guid>
            <pubDate>Tue, 29 Sep 2020 14:42:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Bytecode Surgery to Create an Ouroboros]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24628194">thread link</a>) | @underanalyzer
<br/>
September 29, 2020 | https://www.peterstefek.me/ouroboros.html | <a href="https://web.archive.org/web/*/https://www.peterstefek.me/ouroboros.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
 <div>
  
  <p><label>Posted on <strong>28 September 2020</strong></label></p>
<p>The code associated with this article can be found <a href="https://github.com/Mr4k/ouroboros">here</a>.</p>
<p>Consider the following function in Python which sums up the first n numbers:</p>
<div><pre><span></span><span>def</span> <span>sum</span><span>(</span><span>n</span>, <span>acc</span><span>=</span><span>0</span><span>)</span>:
  <span>if</span> <span>n</span> <span>==</span> <span>0</span>:
    <span>return</span> <span>acc</span>
  <span>else</span>:
    <span>return</span> <span>sum</span><span>(</span><span>n</span> <span>-</span> <span>1</span>, <span>acc</span> <span>+</span> <span>n</span><span>)</span>
</pre></div>


<p>So sum(1) returns 1, sum(2) returns 3 and sum(3) returns 6. What about sum(10000000)?<br>
Most likely if you call sum(10000000) you will get the following error:  </p>
<p><code>Maximum recursion depth exceeded</code>  </p>
<p>A quick google shows that we have exceeded a limit that Python has on how deep recursion can go. Why don't we just increase it to 10000001? Let's try it! Now what happens?<br>
Most likely you will see a different error which looks like this:  </p>
<p><code>Segmentation fault: 11</code>  </p>
<p>What happened here? It turns out that we ran out of memory. This is because every recursive call pushes a new stack frame, containing new variables and function information, onto Python's call stack.  </p>
<p>But if you are incredibly observant or have taken a functional programming course, you might realize that the final result of this recursion is just the value returned by the base case. This value is then passed up a long chain back to the original call. It turns out in this case we don't need the chain. This observation is at the heart of so-called tail call optimization. The optimization eliminates unnecessary stack frames when calling functions from within functions. Most languages (even some js runtimes) implement tail call optimization, however Python's design committee has always been stubbornly against it.  </p>
<p>Since I was looking for small projects to do during my first week at the <a href="https://www.recurse.com/">Recurse Center</a>, I decided to try to implement a basic version of tail call optimization in Python. Note this is not an original idea and I had already seen some clever hacks which used exceptions to break out of sub calls. I decided to try something different, although after presenting my implementation to the greater RC community I learned that another Recurser had given a <a href="https://www.youtube.com/watch?v=Qk1I6ZxcceU&amp;feature=share">fantastic talk</a> which used the same idea back in 2015 (small world!)  </p>
<p>Before I dive into the details let's look at the prototype in action:<br>
sum.py is a file which contains the same sum calculation from the beginning of this post:  </p>
<div><pre><span></span><span>def</span> <span>sum</span><span>(</span><span>n</span>, <span>acc</span><span>=</span><span>0</span><span>)</span>:
  <span>if</span> <span>n</span> <span>==</span> <span>0</span>:
    <span>return</span> <span>acc</span>
  <span>else</span>:
    <span>return</span> <span>sum</span><span>(</span><span>n</span> <span>-</span> <span>1</span>, <span>acc</span> <span>+</span> <span>n</span><span>)</span>

<span>print</span><span>(</span><span>sum</span><span>(</span><span>1000000</span><span>))</span>
</pre></div>


<p>If type <code>python sum.py</code> we will get an error.<br>
Now let's try using my tool:  </p>
<div><pre><span></span><span>python</span> <span>optimize</span><span>-</span><span>tail</span><span>-</span><span>calls</span><span>.</span><span>py</span> <span>sum</span><span>.</span><span>py</span>
</pre></div>


<p>This prints <code>500000500000</code> as expected.  </p>
<p><strong>Identifying Tail Recursive Functions Calls</strong> <br>
The first thing I did was to come up with a way to identify which function calls can be optimized.   </p>
<p>Let's say we have a function <code>f</code> which calls a function <code>g</code> inside of it (<code>g</code> could be a recursive call to <code>f</code> but doesn't have to be). If <code>f</code> just returns the value of <code>g</code> without modifying it, then we do not need to remember <code>f</code> existed in the first place (it does not have to stay on the call stack).  </p>
<p>Let's see how we can translate that definition into something we can implement with Python.   </p>
<p><strong>A Byte Sized Definition</strong><br>
It turns out the Python VM does not evaluate python code directly but rather compiles it to an intermediate bytecode. Below is an example of the bytecode generated for our <code>sum</code> function from above,  </p>
<p>
    <img src="https://www.peterstefek.me/images/ouroboros/sum-bytecode.png" width="50%"> 
</p>

<p>This code may look familiar to anyone who has seen assembly language before. Basically it is a set of instructions which must be executed in roughly sequential order. As you can see here, the CALL_FUNCTION instruction comes right before the return statement. In theory, this gives us a pretty good heuristic to tell if a function call is a tail call. That is to say, a function call is tail call optimizable if it comes right before a return statement (or in some cases jumps to a return statement). Note this definition might not capture every case but does a pretty good job overall. It also should not have false positives.  </p>
<p>✂️ <strong>Bytecode Surgery</strong> ✂️<br>
Now that we know which calls are tail call optimizable, all we have to do is to remove the unnecessary stack frames right? Unfortunately this is where we hit our first big limitation of Python's VM. We do not have full access to the stack pointer like we do in some assembly languages. Therefore, we really don't have a lot of control over the call stack. This really limits our ability to optimize. Some Python tail call optimization implementations get around this by using the exception system to break out of the current call. I chose not to do this due to the complexity of exceptions.   </p>
<p>However if we focus our attention on tail recursive calls (where the tail call functions call the parent function) there is another way to hack around our problem. The simplified version is that we can replace the CALL_FUNCTION instruction with the JUMP_ABSOLUTE instruction, which we can use to take us back to the beginning of the current function.  </p>
<p>
    <img src="https://www.peterstefek.me/images/ouroboros/bytecode-surgery.png" width="99%"> 
</p>

<p>Of course, reality is a little more complex. We actually have to insert more than one instruction to do things like store the function arguments into the proper variables and pop the initial function reference off the stack. To make things more complicated, Python will sometimes have jump statements elsewhere in the call. If we simply replace one instruction in the middle of the function with several instructions, all the indexes get messed up and things will break in subtle ways. The way I dealt with this problem was to replace CALL_FUNCTION with a jump which goes to the end of the function where we can append the rest of our instructions without having to worry about messing up other indexes. Of course this breaks for enormous functions but that's outside of the scope of this prototype.   </p>
<p><strong>More Complications</strong><br>
Unfortunately, there's one more major problem with our clean bytecode definition of a tail recursive function call. The problem is that there is no reliable way to tell from the bytecode which function is being called without actually running the bytecode. This means that in order to really know whether a tail call is tail recursive or not we need more information. I chose to use the AST (Abstract Syntax Tree) form of the code to figure this out.  </p>
<p>To determine if a function call is tail recursive, I used another heuristic which consists of four criteria: </p>
<ul>
<li>the call is the sole direct child of the return statement</li>
<li>the call calls the parent function</li>
<li>the call and entire return statement must be on one line</li>
<li>nothing unrelated to the return statement can be on the same line</li>
</ul>
<p>This heuristic further narrows the number of calls we can mark as tail recursive. I think it can be improved but I chose it partially for simplicity of implementation. One other quirk about python's bytecode is that it gives us the line where each instruction is based but does not give us any more granular information. This is why I have the same line requirement. </p>
<p>We can now mark all the lines with tail recursive calls. Then when going through the bytecode, if we see a function call next to a return statement we can check if it is a tail recursive call or not based on the line number.  </p>
<p><strong>An Ouroboros</strong><br>
</p><p>
    <img src="https://www.peterstefek.me/images/ouroboros/ouroboros.jpg" width="40%"> 
</p> <p>
The Ouroboros is a snake which is eating its own tail. It symbolizes eternal cyclic renewal. In Python I consider this function to represent an Ouroboros,  </p>
<div><pre><span></span><span>def</span> <span>ouroboros</span><span>()</span>:
    <span>return</span> <span>ouroboros</span><span>()</span>
</pre></div>


<p>Now that we can optimize tail recursive function calls, this function will run forever (read as until we send SIGINT), eating it's own stack in an endless cycle.  </p>
<p><strong>Further Places to Improve</strong><br>
I think with a little work the AST based heuristic could be complete (it would not miss any tail call optimizable functions).   </p>
<p>When I started this project I was wondering about diving into the cpython VM code itself. I think it was neat that I didn't have to but I wonder if being able to make these tail call optimization decisions at runtime would be better. This would allow us to know which function was about to be called at runtime and we could decide whether or not to jump then. We would no longer need any AST based heuristics.  </p>
<p>Of course if I had full VM access, I could also potentially allow jumping between functions without having to resort to exceptions which would really allow full tail call optimization. That might be an undertaking though.</p>
<p>Have questions / comments / corrections?<br>
Get in touch: <a href="mailto:pstefek.dev@gmail.com">pstefek.dev@gmail.com</a>   </p>
 </div>
</div></div>]]>
            </description>
            <link>https://www.peterstefek.me/ouroboros.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24628194</guid>
            <pubDate>Tue, 29 Sep 2020 14:24:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Benchmarking TensorFlow on Nvidia GeForce RTX 3090]]>
            </title>
            <description>
<![CDATA[
Score 99 | Comments 101 (<a href="https://news.ycombinator.com/item?id=24628189">thread link</a>) | @rkwasny
<br/>
September 29, 2020 | https://www.evolution.ai/post/benchmarking-deep-learning-workloads-with-tensorflow-on-the-nvidia-geforce-rtx-3090 | <a href="https://web.archive.org/web/*/https://www.evolution.ai/post/benchmarking-deep-learning-workloads-with-tensorflow-on-the-nvidia-geforce-rtx-3090">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>NVIDIA recently released the much-anticipated GeForce RTX 30 Series of Graphics cards, with the largest and most powerful, the RTX 3090, boasting 24GB of memory and 10,500 CUDA cores. This is the natural upgrade to 2018’s 24GB RTX Titan and we were eager to benchmark the training performance performance of the latest GPU against the Titan with modern deep learning workloads.</p><p>Based on the specs alone, the 3090 RTX offers a great improvement in the number of CUDA cores, which should give us a nice speed up on FP32 tasks. However, NVIDIA decided to cut the number of tensor cores in GA102 (compared to GA100 found in A100 cards) which might impact FP16 performance.<br></p><p>‍<br></p><div>
<table>
  <tbody><tr>
    <th></th>
    <th>Titan RTX</th>
    <th>3090 RTX</th>
  </tr>
  <tr>
    <td><i>Architecture</i></td>
    <td>Turing TU102</td>
    <td>Ampere GA102</td>
  </tr>
  <tr>
    <td><i>Cuda cores</i></td>
    <td>4,609</td>
    <td>10,496</td>
  </tr>
  <tr>
    <td><i>Tensor cores</i></td>
    <td>576</td>
    <td>328</td>
  </tr>
  <tr>
    <td><i>Memory</i></td>
    <td>24GB</td>
    <td>24GB</td>
  </tr>
  <tr>
    <td><i>Memory bandwidth</i></td>
    <td>672 GB/sec</td>
    <td>936 GB/sec</td>
  </tr>
  <tr>
    <td><i>TDP (watts)</i></td>
    <td>285</td>
    <td>350</td>
  </tr>
</tbody></table></div><p>System:<br></p><p><em>Ubuntu 18.04.3</em></p><p><em>Driver Version: 455.23.05</em></p><p><em>CUDA Version: 11.1</em></p><p><em>Tensorflow: tf-nightly 2.4.0.dev20200928</em></p><p>It is very important to use the latest version of CUDA (11.1) and latest tensorflow, some features&nbsp;like TensorFloat are not yet available in a stable release at the time of writing.</p><p><br>We use our own fork of the <a href="https://github.com/lambdal/lambda-tensorflow-benchmark/tree/tf2">Lambda Tensorflow Benchmark</a> which measures the training performance for several deep learning models trained on ImageNet.</p><p>‍</p><div>


<table>
	<caption>Training performance in images processed per second</caption>
  <thead>
    <tr>
      <th></th>
      <th colspan="2">FP16</th>
      <th colspan="2">FP32</th>
    </tr>
    <tr>
      <th></th>
      <th>Titan RTX</th>
      <th>RTX 3090</th>
      <th>Titan RTX</th>
      <th>RTX 3090</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><i>AlexNet</i></td>
      <td>6634.31</td>
      <td>8255.43</td>
      <td>4448.46</td>
      <td>6493.16</td>
    </tr>
    <tr>
      <td><i>Inception3</i></td>
      <td>656.13</td>
      <td>616.25</td>
      <td>222.95</td>
      <td>337.31</td>
    </tr>
    <tr>
      <td><i>Inception4</i></td>
      <td>298.11</td>
      <td>132.73</td>
      <td>99.74</td>
      <td>143.65</td>
    </tr>
    <tr>
      <td><i>ResNet152</i></td>
      <td>423.92</td>
      <td>484.02</td>
      <td>134.47</td>
      <td>203.58</td>
    </tr>
    <tr>
      <td><i>ResNet150</i></td>
      <td>966.77</td>
      <td>1259.95</td>
      <td>335.96</td>
      <td>525.88</td>
    </tr>
    <tr>
      <td><i>VGG16</i></td>
      <td>339.73</td>
      <td>442.49</td>
      <td>212.06</td>
      <td>325.60</td>
    </tr>
  </tbody>
</table></div><p>‍</p><p>‍</p><p>‍</p><figure id="w-node-81c38bb21f8c-a8a0c0ce"><p><img src="https://assets.website-files.com/5f286b01a607cf5cd1531aa9/5f731993be0980f19dfb79a2_gpu_benchmark.svg" loading="lazy" alt=""></p><figcaption>Speedup of RTX 3090 over Titan RTX</figcaption></figure><p>‍</p><p>We're able to achieve a 1.4-1.6x training speed-up for all the models training with FP32! As expected, the FP16 is not quite as significant, with a 1.0-1.2x speed-up for most models and a drop for Inception.</p><p>‍</p><p>Please get in touch at <a href="mailto:hello@evolution.ai">hello@evolution.ai</a> with any questions or comments!</p></div></div></div></div>]]>
            </description>
            <link>https://www.evolution.ai/post/benchmarking-deep-learning-workloads-with-tensorflow-on-the-nvidia-geforce-rtx-3090</link>
            <guid isPermaLink="false">hacker-news-small-sites-24628189</guid>
            <pubDate>Tue, 29 Sep 2020 14:24:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Going from JavaScript to WebAssembly in Three Steps]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24627952">thread link</a>) | @jasperk
<br/>
September 29, 2020 | https://engineering.q42.nl/webassembly/ | <a href="https://web.archive.org/web/*/https://engineering.q42.nl/webassembly/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://engineering.q42.nl/content/images/size/w300/2020/09/Going-From-JavaScript-to-WebAssembly-in-Three-Steps.png 300w,
                            https://engineering.q42.nl/content/images/size/w600/2020/09/Going-From-JavaScript-to-WebAssembly-in-Three-Steps.png 600w,
                            https://engineering.q42.nl/content/images/size/w1000/2020/09/Going-From-JavaScript-to-WebAssembly-in-Three-Steps.png 1000w,
                            https://engineering.q42.nl/content/images/size/w2000/2020/09/Going-From-JavaScript-to-WebAssembly-in-Three-Steps.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://engineering.q42.nl/content/images/size/w2000/2020/09/Going-From-JavaScript-to-WebAssembly-in-Three-Steps.png" alt="Going from JavaScript to WebAssembly in Three Steps">
            </figure>

            <section>
                <div>
                    <!--kg-card-begin: markdown--><p>Hi! I'm Marcel, web developer at <a href="https://www.q42.com/">Q42</a> and creator of the <a href="https://micr.io/">Micrio storytelling platform</a>.</p>
<p>In 2015, I started developing a JavaScript viewer for ultra high resolution 2D and 360° images with added markers, tours, audio, and more. Since then, I've been pushing to find the best balance between hardware performance, minimal CPU and bandwidth use, and compatibility for older browsers to deliver a sharp and high quality viewing experience.</p>
<p>For Micrio, it is vital that the performance on the client's browser is as good as possible. The reason for this is very simple: when you are being told a story, or watching a movie, even <em>a single frameskip</em> immediately takes you out of your experience.</p>
<p>Since Micrio is being used for an <a href="https://micr.io/showcases">ever growing list</a> of awesome projects, the most important thing is that for whoever visits a Micrio project, it must work, and <em>work well</em>: delivering fast load times, and a butter smooth interactive experience.</p>
<p><a href="https://webassembly.org/">WebAssembly</a> (Wasm) is the ability for your browser to run <em>compiled</em> code at (near-) native speeds. It is now recognised by the W3C as the <a href="https://www.w3.org/2019/12/pressrelease-wasm-rec.html.en">4th official web programming language</a>, after HTML, CSS and JavaScript.</p>
<p>With it, you can run compiled code written in a variety of programming languages (C/C++, Rust, Go, AssemblyScript, <a href="https://github.com/appcypher/awesome-wasm-langs">and many more</a>) in your browser, without any need for plugins.</p>
<p>Finding out about Wasm in late 2019 really made me want to try it out. Could I use this tech to make the Micrio client run smoother than the current version does? Would I need to rewrite everything in C++, and if so, how would that work? Would the effort be worth the gains it would give me? And not in the least.. <em>how does it work!?</em></p>
<p>This article describes my journey from upgrading the Micrio <strong>JavaScript-only client to use WebAssembly</strong>, with the hopes of improving performance, and taking my code to the next level.</p>
<h3 id="thecurrentversion">The current version</h3>
<p>To give a rough idea about the tech stack of the current latest JS-only revision of Micrio (<a href="https://b.micr.io/micrio-2.9.min.js">version 2.9</a>): This library as a single JS file works on all semi-modern browsers, including even Internet Explorer 10 for 2D, and IE 11 for 360° images.</p>
<p>It uses Canvas2D for the rendering of 2D images, and <a href="https://threejs.org/">three.js</a>/WebGL rendering for 360° images. Written in <a href="https://caniuse.com/#search=es6">ES6 JavaScript</a> (or ECMAScript 6, the latest version of JavaScript), it still <a href="https://developers.google.com/closure/compiler">compiles</a> to ES5 to support Internet Explorer 11.</p>
<p>As you can imagine, displaying a <a href="https://micr.io/i/xCSYV/">231.250 x 193.750 pixel image</a> in your browser in a matter of milliseconds, allowing the user to freely zoom in and navigate, requires a little bit of processing power.</p>
<p>Now, Micrio 2.9 <em>isn't bad</em>. It runs pretty smoothly on all devices. But with WebAssembly around the corner, allowing all calculations to be done at native CPU speeds, this could potentially make a big difference in making Micrio's performance even better, and could improve the code architecture a lot.</p>
<p>And, perhaps, this could also mark the setup for a new major version, where I will draw a clear line and drop all compatibility and polyfills for older browsers: <strong>Micrio 3.0</strong>.</p>
<h2 id="firstrewritecandemscripten">First Rewrite: C++ and emscripten</h2>
<p>As a first step into the world of WebAssembly, getting to know the ecosystem, I started to play around with <a href="https://emscripten.org/">emscripten</a>. With it, you can take almost any project made in C or C++, and compile it to a binary <code>.wasm</code> file that your browser can natively run.</p>
<p>At this point, I didn't really have a clear image of where WebAssembly starts and ends, and how autonomously it could run inside your browser. So I started a new project from scratch to see if I could make a C++-implementation of the basic Micrio logic: a virtual <em>zoomable</em> and <em>pannable</em> image consisting of a lot of separate tiles, using a virtual camera for displaying only the tiles necessary for what the user is viewing inside your screen.</p>
<p>It turns out, emscripten already had great compatibility for <a href="https://www.libsdl.org/">libsdl</a>: a low-level audio, keyboard/mouse input, and OpenGL library. Which is awesome, because I could write my code using this very well documented library, even including mouse and key inputs and WebGL rendering. Since I was also working with downloading images, I also used the <a href="https://github.com/nothings/stb">stb_image.h</a> image library.</p>
<p><img src="https://raw.githubusercontent.com/marcelduin/Micrio.Blogpost.wasm-v3/master/img/cpp.png" alt="Setting up SDL and OpenGL" title="C++ in the 21st century"></p>
<p>The largest struggle of this was picking up C++ again, never having used it outside of hobby scope many years ago. But after a few days of cursing and second guessing myself, I had a working first version with all of the most important features written with help of the SDL library:</p>
<ul>
<li>A virtual camera and all necessary viewing logic;</li>
<li>Image tiles downloading;</li>
<li>Rendering using WebGL(/OpenGL) using a simple shader;</li>
<li>Mouse event handling for panning and zooming the image;</li>
<li>Resize event handling to fit Micrio to the desired <code>&lt;canvas&gt;</code> HTML element</li>
</ul>
<p>You can see this version running here: <a href="https://b.micr.io/_test/wasm/index.html">https://b.micr.io/_test/wasm/index.html</a> :</p>
<p><a href="https://b.micr.io/_test/wasm/index.html"><img src="https://raw.githubusercontent.com/marcelduin/Micrio.Blogpost.wasm-v3/master/img/emscripten.png" alt="Micrio in native C++"></a></p>
<h3 id="firstresults">First Results</h3>
<p>As incredibly awesome it was to see Micrio in C++ running smoothly in my browser, and even handing all the user's input, there were a few reservations, which left me with an unsatisfied feeling.</p>
<h4 id="1codingcfeltoldfashioned">1. Coding C++ felt old-fashioned</h4>
<p>Writing C++ felt like going back in time. Incredibly powerful and fully proven, but also archaic, especially for me as a web developer. I spent more time fiddling with making an optimized <code>Makefile</code> than I care to admit.</p>
<p><img src="https://raw.githubusercontent.com/marcelduin/Micrio.Blogpost.wasm-v3/master/img/makefile.png" alt="The emscripten C++ Makefile" title="( ͡° ͜ʖ ͡°)"></p>
<h4 id="2thecompiledwasmbinarywasverylarge">2. The compiled <code>.wasm</code> binary was very large</h4>
<p>As great as the help of <code>libsdl</code> and <code>stb_image.h</code> were to let me use OpenGL and JPG image functions, as much did they add to the final compiled binary file. Even with all <code>emcc</code> compiler optimizations (which can even use the awesome <code>closure</code> JS compiler), the resulting WebAssembly binary file was 760KB. Compared to the JavaScript version of Micrio being around 240KB, this was a major setback. These libraries packed a lot of functionalities that were not necessary for Micrio, but were still included in the compiled version.</p>
<h4 id="3tilagluefile">3. TIL: A <em>glue</em> file</h4>
<p>This is the part where I learnt where the limits of WebAssembly start and finish. <strong>WebAssembly is not a magical self-contained binary that lets you run full applications out of the box</strong>. It actually needs to be <em>bound</em> to the browser using JavaScript.</p>
<p><img src="https://raw.githubusercontent.com/marcelduin/Micrio.Blogpost.wasm-v3/master/img/glued.png" alt="glue clipart"><br>
<small><a href="http://www.clker.com/clipart-13445.html">Image source</a></small></p>
<p>Where I thought that all the SDL OpenGL code in C++ would automagically be recognised by the browser: <em>wrong</em>. What <code>emscripten</code> does, is to take all OpenGL operations from C++, and <em>convert them</em> to WebGL operations your browser can understand.</p>
<p>Same with the <code>libsdl</code> mouse and keyboard-inputs: these were <strong>glued</strong> to the browser using an extra JavaScript file that would set event listeners for the specific cases, and send them to the WebAssembly binary. This separate JavaScript file was generated by the emscripten compiler, and had to be included in the HTML alongside the compiled binary <code>.wasm</code> file.</p>
<p>Everything added together, the new total of the <em>base engine</em> of Micrio was a whopping <strong>791KB</strong>; a bit too much for my liking.</p>
<h2 id="secondrewriteassemblyscript">Second Rewrite: AssemblyScript</h2>
<p>Fast forward a few months, to just after having attended the awesome <a href="https://webassembly-summit.org/">WebAssembly Summit</a> in Mountain View in February 2020. With a bundle of fresh energy and inspiration, I decided to see if I could use WebAssembly to improve the Micrio JavaScript client a second time.</p>
<p>During the WebAssembly conference, I was very impressed by a <a href="https://www.youtube.com/watch?v=C8j_ieOm4vE">synth demo</a> written in <strong><a href="https://www.assemblyscript.org/">AssemblyScript</a></strong>, a language created specifically for WebAssembly, using the TypeScript syntax. Basically you can write (near) TypeScript, which compiles to a <code>.wasm</code>-binary. So anyone familiar with either TypeScript or JavaScript ES6 will not have a lot of difficulties using it.</p>
<p>And the great thing-- it's all installed using <code>npm</code>, so <a href="https://www.assemblyscript.org/quick-start.html">getting it up and running</a> and compiling your program is super easy!</p>
<p>There are a few basic <a href="https://www.assemblyscript.org/types.html"><code>types</code> added in AssemblyScript</a>, which are required for compile-time optimizations:</p>
<ul>
<li><code>f64</code> / <code>f32</code> : For 64 or 32-bit floats;</li>
<li><code>i8</code> / <code>i16</code> / <code>i32</code> / <code>i64</code> : For signed <code>int</code>s, ranging in precision</li>
<li><code>u8</code> .. <code>u64</code> : For unsigned <code>int</code>s</li>
<li><a href="https://www.assemblyscript.org/types.html">And a few more</a></li>
</ul>
<h3 id="goingatomic">Going atomic</h3>
<p>This time, I wanted to see if it was possible to only let a small part of Micrio run inside WebAssembly, and still use most of the JavaScript that was already inside the client. <em>How small can we get it?</em> I decided to focus on a subset of camera functions, such as translating screen coordinates to image coordinates and vice versa. So this time no rendering, event handling, or writing shaders.</p>
<p><img src="https://raw.githubusercontent.com/marcelduin/Micrio.Blogpost.wasm-v3/master/img/assemblyscript.png" alt="Simple camera functions in AssemblyScript" title="My First AssemblyScript"><br>
<small><em>Simple camera functions in AssemblyScript</em></small></p>
<p>The result: a 3KB binary containing some basic math functions, that take an input and return an output. AssemblyScript offers some <em>glue-tooling</em> by providing its own <a href="https://www.assemblyscript.org/loader.html">Loader</a>, which will deal with importing the binary file and being able to call these functions.</p>
<p>However, this is optional and I ended up using the JavaScript <a href="https://developer.mozilla.org/en-US/docs/WebAssembly/Using_the_JavaScript_API">WebAssembly API</a>, <em>neat</em>. And it turns out, this is super easy: simply use the <code>fetch</code> API to load your compiled <code>.wasm</code> file, cast it as an <code>ArrayBuffer</code>, and use the <code>WebAssembly.instantiate()</code> function to get it up and running.</p>
<p><img src="https://raw.githubusercontent.com/marcelduin/Micrio.Blogpost.wasm-v3/master/img/instantiate.png" alt="Loading a wasm file" title="Gluing it yourself"></p>
<p>The compiled binary will then offer an <code>exports</code> object, containing the functions that you have exported in the AssemblyScript file, which you can immediately call from JavaScript as if they were normal functions.</p>
<p>Wait.. "<em>which you can immediately call from JavaScript as if they were normal functions</em>"...</p>
<p><strong>WebAssembly is running synchronously to JavaScript!</strong> 🤯</p>
<p>Having worked with WebWorkers before, I honestly thought that WebAssembly would run inside its own CPU thread, and that any function calls would be <code>async</code>. Nope, the Wasm-functions you call will return immediately!</p>
<p><a href="https://www.assemblyscript.org/exports-and-imports.html#exports"><em>This is, like, powerful stuff</em>!</a></p>
<h3 id="bundlingthecompiledwasminsidethejsfile">Bundling the compiled Wasm inside the JS file</h3>
<p>Since I now had some extra performing hands on deck for Micrio that was very easy to integrate, I decided to include this minimal WebAssembly binary in the then-stable release of Micrio (2.9).</p>
<p>However, I didn't want an extra HTTP request for the Wasm binary every time someone loaded the Micrio JS. So I included a <code>base64</code> encoded version of the Wasm-file <em>inside</em> the Micrio JS, and for browsers that support it, auto-loaded that. As a …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://engineering.q42.nl/webassembly/">https://engineering.q42.nl/webassembly/</a></em></p>]]>
            </description>
            <link>https://engineering.q42.nl/webassembly/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24627952</guid>
            <pubDate>Tue, 29 Sep 2020 14:06:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Saturated ASCII Text, the unknown markup language]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24627899">thread link</a>) | @oileurre
<br/>
September 29, 2020 | https://www.cs.ru.nl/~freek/books/sat.sat | <a href="https://web.archive.org/web/*/https://www.cs.ru.nl/~freek/books/sat.sat">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.cs.ru.nl/~freek/books/sat.sat</link>
            <guid isPermaLink="false">hacker-news-small-sites-24627899</guid>
            <pubDate>Tue, 29 Sep 2020 14:01:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to convert more users when their trial expires]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24627648">thread link</a>) | @pmuens
<br/>
September 29, 2020 | https://philippmuens.com/how-to-convert-more-users-when-their-trial-expires/ | <a href="https://web.archive.org/web/*/https://philippmuens.com/how-to-convert-more-users-when-their-trial-expires/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>Your product offers a free trial but your users aren't converting when it expires?</p><p>Most of the time the worst part is that you don't have any data to figure out why users stopped using your product. Even if you reach out, feedback is usually sparse and often doesn't reveal any useful patterns you can look into.</p><p>In response to that, a lot of time and energy is usually spent tweaking the onboarding flow or marketing funnel.</p><p>But there's a simpler, better way to increase your conversion rates. Let's see how it works.</p><h2 id="why-a-free-trial-is-a-hard-sell">Why a free trial is a hard sell</h2><p>There's a lot of debate whether having a free trial is the best way to acquire new customers.</p><p>The clear upside of offering a free trial is that the barrier of entry is extremely low. An E-Mail address and a password is usually enough to get new users into the door. The more users you have onboarded, the more likely it is that they talk about your product in their peer groups and network (assuming it solves a real pain). Even better if your product has built-in functionalities which incentivize your users to invite others. This mix of Word-of-Mouth and network effects kick-starts the growth flywheel which will attract even more users. Rinse and repeat.</p><p>Eventually a small percentage of your overall user base converts and upgrades to a paid plan.</p><p>Hundreds of large-scale companies followed this exact playbook. Given their success it should be a no-brainer to follow this strategy as well, correct?</p><p>Despite the aforementioned upsides there are also clear downsides to this approach. Having more users usually translates into more customer support requests your support staff needs to handle. In addition to that it's tricky to get the math right such that you can use the revenue you generate via your paid plans to finance the resources and infrastructure necessary for your free trials.</p><p>There isn't a clear, definite answer whether you should offer a free trial or avoid it at all costs. At the end of the day it all comes down to the type of product you sell and the audience you're serving.</p><p>Regardless of the way you acquire new customers there's one metric you should monitor closely when onboarding new users: <strong>User engagement</strong>.</p><h2 id="the-core-problem-with-free-trials">The core problem with free trials</h2><p>Low user engagement is at the very core of problems related to free trials.</p><p>Given that one only needs an E-Mail address and a password to sign up for your product it's an easy decision to take the leap and give it a try. Testing it is free after all and who doesn't like getting something for free?</p><p>The issue is that finding the time to sit down and "work with it in the next couple of days" usually never materializes. Life gets in the way and sooner rather than later the trial expires and your users are locked-out, never to be seen again.</p><p>Sure, this isn't always the case but more often than not people just don't get around testing your product enough to uncover the benefits they'll experience when using it in their day-to-day to solve their problems.</p><h2 id="free-plans-and-asking-for-the-credit-card-upfront">Free plans and "asking for the credit card upfront"</h2><p>One solution to mitigate this problem is to offer a limited, "always free" plan. This way users will have enough time to tinker around and assess whether your product is worth its money. But this only kicks the can down the road as you'll likely face the same issue of low user engagement as before. In addition to that you open up a can of worms because now you have to deal with all the other challenges a free plan entails:</p><ul><li>Even more customer support</li><li>Figuring out what to offer in the free plan and what to put in the paid plans</li><li>Ways to incentivize powers users of your "always free" plan to upgrade</li><li>Increasing spent on infrastructure and other resources</li><li>...</li></ul><p>Another common strategy to solve the free trial dilemma is to "ask for the credit card upfront", meaning that users have to put in their credit card information when they sign up but they won't be charged after their trial expired. While asking for credit card information is a good way to filter out users who might never convert into paid customers it comes with the sames problems we just discussed.</p><p>Offering an "always free" plan or asking for the credit card upfront still doesn't solve the issue of low <strong>user engagement</strong>.</p><h2 id="how-to-solve-the-user-engagement-debacle">How to solve the user engagement debacle</h2><p>Now that we know why free trials and free plans are a tough sell it's time to tackle the underlying issue: <strong>Low user engagement</strong>.</p><p>Basic human psychology tells us that human beings value items more if they've spent money to acquire them. Think about the last time you got something for free vs. the time you spent money on a similar item. Chances are that you've used and valued the item you paid money for more.</p><p>This discovery can be used to inform the way how you can design your trial version to eventually convert more users into paying customers.</p><p>Rather than offering a free trial which expires in 30 days offer a paid version of that exact same trial.</p><p>Yes, you read that right. Turn your free trial into a <strong>paid trial</strong>.</p><h2 id="the-benefits-of-a-paid-trial">The benefits of a paid trial</h2><p>Offering a paid trial comes with a couple of major advantages:</p><ol><li>Only users who are seriously considering your product will sign up for the paid trial</li><li>It's more likely that your users will find the time to test your product because they paid for it</li><li>Your users value your product more compared to your competitors who offer a free plan / free trial</li><li>Your users are more committed to get the most value out of your product during the trial</li><li>Another huge point of friction is already removed from the conversion process (asking to put in the credit card information and subscribe to a paid plan)</li></ol><p>In fact, I learned about the power a paid plan can have from a personal experience. Given my growing interest in SEM, SEO and marketing in general I did some research to figure out what tools the market has to offer in that space.</p><p>In particular I was looking for a tool which would help me conducting Keyword Research, Backlink analysis and SEO monitoring. What I stumbled upon was the well-known tool Ahrefs.</p><p>However what struck me was that compared to their competitors their pricing structure was different. There was no "Free trial". I had to pay 7 USD to get access to the tool for 7 days. After some hesitation I decided to give it a shot and try it for the next 7 days. In fact, I spent a significant amount of time upfront, learning and researching everything I could about their toolings to figure out if their paid trial would be really worth it.</p><p>Needless to say that I used Ahrefs every single day during that week. The felt "pressure" to get the most out of the 7 days in combination with their excellent, educational E-Mail sequence helped me to explore all the values their tool has to offer. I'm absolutely certain that their conversion rates from paid trial to paying customer aren't too shabby.</p><figure><img src="https://philippmuens.com/content/images/2020/09/Bildschirmfoto-2020-09-29-um-11.46.08.png" alt="" srcset="https://philippmuens.com/content/images/size/w600/2020/09/Bildschirmfoto-2020-09-29-um-11.46.08.png 600w, https://philippmuens.com/content/images/size/w1000/2020/09/Bildschirmfoto-2020-09-29-um-11.46.08.png 1000w, https://philippmuens.com/content/images/size/w1600/2020/09/Bildschirmfoto-2020-09-29-um-11.46.08.png 1600w, https://philippmuens.com/content/images/size/w2400/2020/09/Bildschirmfoto-2020-09-29-um-11.46.08.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Ahrefs 7-day trial for $7</figcaption></figure><h2 id="your-challenge">Your challenge</h2><p>Do you have a free plan, free trial or are thinking about introducing such a plan in the near future?</p><p>I'd challenge you to take a step back and think about offering a paid trial instead. Your paid trial shouldn't be too expensive but it should be enough that your users are incentivized to explore your product in more depth. Combine your paid trial with a helpful, educational E-Mail onboarding sequence and check-in with your users every now and then to understand what their problems are and to help them succeed.</p><p>I'm certain that this will help you tackle any conversion-related problems you might be facing!</p><h2 id="conclusion">Conclusion</h2><p>Converting users you've attracted via a free trial or a free plan to become paying customers is hard. There are a couple of issues one has to be aware of. It's tough to get the math right and take the profits you made from your paid plans to offset the costs you'll introduce by offering a free plan / free trial. While it's highly likely that you'll get new users using your product you'll also experience an increase in customer support requests and an almost guaranteed low conversion rate.</p><p>One of the underlying core problem with all this is a lack of user engagement. Paid products are valued more than free ones.</p><p>You can use this fact and offer a paid trial which incentivizes your users to take action and explore the values your product has to offer. Having a more engaged user base helps you tackle the conversion-related problems you might be facing.</p><p>I hope that you enjoyed this article and I'd love to invite you to subscribe to my Newsletter if you're interested in more, action-oriented posts like this.</p><p>Do you have any questions, feedback or comments? Feel free to reach out via E-Mail or connect with me on <a href="https://twitter.com/pmmuens">Twitter</a>.</p>
                </div>
            </section></div>]]>
            </description>
            <link>https://philippmuens.com/how-to-convert-more-users-when-their-trial-expires/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24627648</guid>
            <pubDate>Tue, 29 Sep 2020 13:38:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Microservices – architecture nihilism in minimalism's clothes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24627616">thread link</a>) | @vlfig
<br/>
September 29, 2020 | https://vlfig.me/posts/microservices | <a href="https://web.archive.org/web/*/https://vlfig.me/posts/microservices">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Some recent <a href="https://twitter.com/gergelyorosz/status/1247132806041546754" target="_blank" rel="nofollow noopener noreferrer">backtracking</a> <a href="https://twitter.com/copyconstruct/status/1247130488667394049" target="_blank" rel="nofollow noopener noreferrer">from</a> what we have been calling “Microservices” has sparked anew the debate around that software architecture pattern. It turns out that for increasingly more software people, having a backend with (<a href="https://www.infoq.com/presentations/monzo-microservices/" target="_blank" rel="nofollow noopener noreferrer">sometimes several</a>) hundreds of services wasn’t that great an idea after all. The debate has <a href="https://riak.com/posts/technical/microservices-please-dont/" target="_blank" rel="nofollow noopener noreferrer">been going on for a while</a> and much has already been said, but there are still a couple of things I’d like to say.</p>
<p><strong>TL;DR</strong> “Microservices” was a good idea taken too far and applied too bluntly. The fix isn’t just to dial back the granularity knob but instead to 1) focus on the split-join criteria as opposed to size; and 2) differentiate between the project model and the deployment model when applying them.</p>
<p>I explain. Allow me to rant a bit first.</p>


<p>There were three main reasons for the initial success of <em>microservices</em> as an architectural pattern for software: 1) forced modularisation, 2) weakened dependencies, and 3) an excuse for having no architecture. In order:</p>
<ol>
<li>In the monoliths of old, you could in theory enforce module boundaries. You could say that your <code>acme-helpers</code> or <code>acme-data-tools</code> could not depend on <code>acme-domain</code>, say, and you even had some tooling to enforce that, but it was fallible. Especially in big companies where these monoliths spanned more than a team’s cognitive horizon, violations of those boundaries were often a simple <code>import</code> away, and of course rife. Angry architects saw in microservices the promise of making those a thing of the past: now the developer is forced to only deal with the API. Codebases parted ways and calls were made to go down the network stack and back.</li>
<li>
<p>So then, one wouldn’t depend on a fellow service at build time, only at runtime. Great. Method calls became http calls. “Now we don’t need to care about dependencies” — actual people said this, as if the dependency wasn’t fundamental and instead just an accidental artifact of the build setup. Everybody brushed up on their HTTP and different server and client implementations, read all about REST and Soap (and RPC, RMI and CORBA while at it) and merrily created a layer of indirection between modules — now <em>services</em> — that was <em>very</em> loose. Typed APIs, granular network policies and contract testing came much later.</p>
<p>It felt liberating until the complexities of API versioning, delivery semantics, error propagation, distributed transaction management and the sprawl of client code in all callers of a service began to show up. This was a gigantic <strong>shift right</strong>, but hey, the build process was simpler.</p>
</li>
<li>
<p>More insidious perhaps was the validation that “doing microservices” brought to organisations that lacked a thesis about how their architecture should be. There was now a sanctioned answer to most architectural dilemmas: another microservice. Another entry in the service catalog for any and all interested parties to call. This ecology of interacting parties, each acting in their own interest for the common good spoke to an underlying, tacit belief that the emergent mesh of services would approximate the latent natural architecture of the domain.</p>
<p>So soft and convenient was the lure of not having to draw hard architectural lines that we got lazy where we weren’t and accepted our lazyness where we already were. If you didn’t subscribe to that belief, the problem was you and your lack of understanding of complex systems, you objectivist cretin.</p>
</li>
</ol>
<p>Yes, there was real pain in managing monoliths and sure, many systems were too monolithic (i.e. had deployables too large) but the zealotry of a newfound purity swung the pendulum too far, as they always do. Not only do we not need to run so many services so small, we also don’t benefit from isolating their codebases so much. To summarise:</p>
<ol>
<li>having a big flat permissive build is no good reason to split deployables;</li>
<li>weakening dependencies between different parts of our systems is a “shift-right” loan with high interest; and</li>
<li>having a ready answer when the thinking gets tough is a soothing lie that just moves complexity about. There is no substitute to the effortful application of cognitive power to a problem.</li>
</ol>

<p>Two things: focus on the right criteria for splitting a service instead of on its size, and apply those criteria more thoughtfully.</p>
<h2 id="size-is-not-the-answer"><a href="#size-is-not-the-answer" aria-label="size is not the answer permalink"></a>Size is not the answer</h2>
<p>The <em>micro</em> in microservices ought to be at best a prediction, never a goal. We may predict services <em>will be</em> micro but they don’t <em>have to be</em>. <a href="https://kalele.io/microservices-and-microservices/" target="_blank" rel="nofollow noopener noreferrer">Vaugh Vernon is right</a> when he speaks about “cohesion for a reason”.</p>
<p>There should be no prescribed <em>a priori</em> granularity of services. There <em>is</em> no prescribed size of a service. There are instead <strong>good and bad reasons to split</strong> parts of a software system.</p>
<p>So the heuristic is:</p>
<div data-language="text"><pre><code>                      Start one, split with a reason.</code></pre></div>
<p>Conversely, if a reason ceases to exist, consider joining them.</p>
<h2 id="the-missing-hinge"><a href="#the-missing-hinge" aria-label="the missing hinge permalink"></a>The missing hinge</h2>
<p>There are however different realms in which “software systems” exist: they exist both as artifacts we interact with and as artifacts computers interact with. Code and binary. We organise them in different ways: the <strong>project model</strong> (repositories, projects, modules and their dependencies) and the <strong>deployment model</strong> (what production environments look like and how deployables run in them).</p>
<figure>
    <span>
      <a href="https://vlfig.me/static/8123a14a0e4efcacfddc6f26f7ad3e78/6246a/monolith.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="A monolithic setup where one big repo builds one single big deployable." title="A monolithic setup where one big repo builds one single big deployable." src="https://vlfig.me/static/8123a14a0e4efcacfddc6f26f7ad3e78/6a068/monolith.jpg" srcset="https://vlfig.me/static/8123a14a0e4efcacfddc6f26f7ad3e78/09b79/monolith.jpg 240w,
https://vlfig.me/static/8123a14a0e4efcacfddc6f26f7ad3e78/7cc5e/monolith.jpg 480w,
https://vlfig.me/static/8123a14a0e4efcacfddc6f26f7ad3e78/6a068/monolith.jpg 960w,
https://vlfig.me/static/8123a14a0e4efcacfddc6f26f7ad3e78/644c5/monolith.jpg 1440w,
https://vlfig.me/static/8123a14a0e4efcacfddc6f26f7ad3e78/6246a/monolith.jpg 1463w" sizes="(max-width: 960px) 100vw, 960px" loading="lazy">
  </a>
    </span>
    <figcaption><p>A monolithic setup where one big repo builds one single big deployable.</p></figcaption>
  </figure>
<p>In the process of going from coarse to granular (i.e. from monolith to microservices) however, little attention was paid to the difference — and possible indirection — between those two models. The hammer hit both fairly indiscriminately and made us split codebases because of runtime concerns and split deployables due to project concerns.</p>
<figure>
    <span>
      <a href="https://vlfig.me/static/fd7e19a50516d91d0b3a84dd16e262ca/6c0a0/stiff-1-1.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="A set of repositories each building their own self-contained independent service." title="Excessive mirroring between the project and deployment models." src="https://vlfig.me/static/fd7e19a50516d91d0b3a84dd16e262ca/6a068/stiff-1-1.jpg" srcset="https://vlfig.me/static/fd7e19a50516d91d0b3a84dd16e262ca/09b79/stiff-1-1.jpg 240w,
https://vlfig.me/static/fd7e19a50516d91d0b3a84dd16e262ca/7cc5e/stiff-1-1.jpg 480w,
https://vlfig.me/static/fd7e19a50516d91d0b3a84dd16e262ca/6a068/stiff-1-1.jpg 960w,
https://vlfig.me/static/fd7e19a50516d91d0b3a84dd16e262ca/6c0a0/stiff-1-1.jpg 1062w" sizes="(max-width: 960px) 100vw, 960px" loading="lazy">
  </a>
    </span>
    <figcaption><p>Excessive mirroring between the project and deployment models.</p></figcaption>
  </figure>
<p>Much like stiffness in a part of the human spine can result in pain in another, <strong>stiffness in our build DAGs is causing excessive mirroring between our project and deployment models</strong>; between our repositories and our services; between the way we organise our code and the way our services run. That mirroring is on the one hand preventing us from shifting left concerns about the relationships between modules that have often been made weak and fragile runtime dependencies, while on the other hand encouraging us to have more services than what the runtime reality would call for. That brings pain.</p>
<figure>
    <span>
      <a href="https://vlfig.me/static/1f3476e5c0b1320f4dd42084cfc102b9/dc6ba/hinge.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="The build DAG as a hinge between the project model and the deployment model." title="A build DAG mediates the project and the deployment models, absorbing the impedance mismatch between what is human friendly and what is machine-friendly." src="https://vlfig.me/static/1f3476e5c0b1320f4dd42084cfc102b9/6a068/hinge.jpg" srcset="https://vlfig.me/static/1f3476e5c0b1320f4dd42084cfc102b9/09b79/hinge.jpg 240w,
https://vlfig.me/static/1f3476e5c0b1320f4dd42084cfc102b9/7cc5e/hinge.jpg 480w,
https://vlfig.me/static/1f3476e5c0b1320f4dd42084cfc102b9/6a068/hinge.jpg 960w,
https://vlfig.me/static/1f3476e5c0b1320f4dd42084cfc102b9/dc6ba/hinge.jpg 1335w" sizes="(max-width: 960px) 100vw, 960px" loading="lazy">
  </a>
    </span>
    <figcaption><p>A build DAG mediates the project and the deployment models, absorbing the impedance mismatch between what is human friendly and what is machine-friendly.</p></figcaption>
  </figure>
<p>Central to resolving this stiffness is the realisation that the build flow, at least conceptually, is a DAG – Directed Acyclic Graph – where the nodes are <em>jobs</em> and <em>versioned artifacts</em> and the edges connect either a job to a versioned artifact (“produces”) or a versioned artifact to a jobs (“dependency_of”). Deployables are by definition the versioned artifacts that are consumed by the deployment jobs.</p>
<figure>
    <span>
      <a href="https://vlfig.me/static/e029adab126c3c2556e80d1647accb16/50066/dag.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="A graph of two types of nodes, jobs and versioned artifacts, connected by edges 'dependency_of' and 'produces'. Versioned artifacts can be further specialised." title="A graph of two types of nodes, jobs and versioned artifacts, connected by edges 'dependency_of' and 'produces'. Versioned artifacts can be further specialised." src="https://vlfig.me/static/e029adab126c3c2556e80d1647accb16/6a068/dag.jpg" srcset="https://vlfig.me/static/e029adab126c3c2556e80d1647accb16/09b79/dag.jpg 240w,
https://vlfig.me/static/e029adab126c3c2556e80d1647accb16/7cc5e/dag.jpg 480w,
https://vlfig.me/static/e029adab126c3c2556e80d1647accb16/6a068/dag.jpg 960w,
https://vlfig.me/static/e029adab126c3c2556e80d1647accb16/50066/dag.jpg 1384w" sizes="(max-width: 960px) 100vw, 960px" loading="lazy">
  </a>
    </span>
    <figcaption><p>A graph of two types of nodes, jobs and versioned artifacts, connected by edges ‘dependency_of’ and ‘produces’. Versioned artifacts can be further specialised.</p></figcaption>
  </figure>
<p>For too long we overlooked how much a flexible and frictionless build DAG allows us to improve our architecture on both sides. With moderately rich build patterns we can have our code where its intent is clearer and more constraints can be validated at build time and still have it deployed into its simplest viable form, running where its execution is cheaper, faster and safer.</p>
<figure>
    <span>
      <a href="https://vlfig.me/static/08e9b2a03b92afa1c2b43018fb141eb0/a18e1/wedding-altar.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="Cheesy cisgender, neurotypical westernised image of a wedding altar with the build dag marrying developer effectiveness with mechanical sympathy." title="Sorry. I had to." src="https://vlfig.me/static/08e9b2a03b92afa1c2b43018fb141eb0/a18e1/wedding-altar.jpg" srcset="https://vlfig.me/static/08e9b2a03b92afa1c2b43018fb141eb0/09b79/wedding-altar.jpg 240w,
https://vlfig.me/static/08e9b2a03b92afa1c2b43018fb141eb0/7cc5e/wedding-altar.jpg 480w,
https://vlfig.me/static/08e9b2a03b92afa1c2b43018fb141eb0/a18e1/wedding-altar.jpg 612w" sizes="(max-width: 612px) 100vw, 612px" loading="lazy">
  </a>
    </span>
    <figcaption><p>Sorry. I had to.</p></figcaption>
  </figure><p>.</p>
<h3 id="why-so-stiff-bro"><a href="#why-so-stiff-bro" aria-label="why so stiff bro permalink"></a>Why so stiff, bro?</h3>
<p>I’m not sure what the historically accurate account is that would explain the excessive simplicity of build patterns across the industry. I do know from experience that too many practices make do with very simple and linear flows where one repository builds independently one and only one service. Regardless of the legitimate argument about code duplication and its tradeoffs, there seems to be an aversion to build-time internal dependencies, even when these bring in clearly desirable data or logic such as message format definitions.</p>
<p>I suspect it might have something to do with how very few CI tools support composition natively (i.e. the outputs of jobs being able to be the inputs of others), how fallible semantic versioning in practice is and the difficulty of automating deterministic version propagation.</p>
<p>By that I mean keeping local copies in sync with CI, builds repeatable, and new upstream versions automatically used by their downstream dependents. It isn’t trivial and requires some versioning and build-fu that, to my knowledge, most practices end up shortcutting to either sacrifice repeatability by using <code>latest</code> or stifling the flow by requiring repeated manual work. Hence the pressure to have a simple build setup.</p>
<p>The exact cause is unimportant though. What is important is that overcoming this is crucial.</p>

<p>Many criteria for splitting or joining software systems, ranging from the social (teams, bounded contexts) to the mechanical (cpu or io boundedness) have been put forth, and they all make some form of sense. However, most of them are either a good reason to split projects or modules, or a good reason to split deployables, rarely both. Keeping that in mind will help us apply them more effectively.</p>
<p>Below are a few possible criteria and some comments about their application. I’m not trying to be exhaustive, just illustrating the kind of reasoning makes sense to me.</p>
<h2 id="runtime-deployment-side-criteria"><a href="#runtime-deployment-side-criteria" aria-label="runtime deployment side criteria permalink"></a>Runtime, deployment side criteria</h2>
<ul>
<li><strong>Different Runtime</strong> – If a part of the codebase compiles to a different runtime it becomes a different deployable and we call it a different service.</li>
<li><strong>Elasticity Profile</strong> – Some parts of the system may have a spikier load profile. It might pay off to have them scale in and out separately from the rest.</li>
<li><strong>Load Type</strong> – Some parts of a generally latency-oriented io-bound system may generate occasional peaks of cpu-bound load which can hurt response times. It might be better to put them in a …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vlfig.me/posts/microservices">https://vlfig.me/posts/microservices</a></em></p>]]>
            </description>
            <link>https://vlfig.me/posts/microservices</link>
            <guid isPermaLink="false">hacker-news-small-sites-24627616</guid>
            <pubDate>Tue, 29 Sep 2020 13:34:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Indian festival goes high-tech]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24627261">thread link</a>) | @mtmail
<br/>
September 29, 2020 | https://restofworld.org/2020/india-magh-mela/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/india-magh-mela/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p><span>I</span>t’s 3:13 a.m., and Radio Inspector Ashok Kumar turns around to look at his computer. His face stiffens. He zooms in on the screen and squints at an unauthorized SUV crossing a pontoon bridge.</p>



<p>Kumar and his team are in the Integrated Command and Control Center (ICCC) overlooking operations for this year’s Magh Mela, an annual Hindu pilgrimage and festival that draws millions of people in a single day. Each year, devotees from all across the country congregate at the spot where the Ganges, Yamuna, and mythical Saraswati rivers converge at Prayagraj in the northern Indian state of Uttar Pradesh. There, devotees dip in the water, which they believe cleanses them of their sins.</p>



<p>It is here at the ICCC, a big white room with two rows of desks, that the police keep a vigil over the mela (the Hindi word for “fair”). At each terminal, policemen hunch over computer screens as they monitor feeds from around 700 closed-circuit TV cameras. A video wall dominates, with 55-inch screens arranged in a 10 by 2 matrix along the length of the room. Khaki jackets emblazoned with “Uttar Pradesh Police” hang on the backs of the chairs. Tapping their shoeless feet on the carpeted floor, the officers glance at each other regularly, followed by tentative nods implying that everything is fine.</p>



<p>The monitoring team is on high alert. Kumar and his team have been here since 8 p.m. last night, on a 12-hour shift, and the first bathing rituals began at 3 a.m. Today is February 9, and it is the full moon day of Maghi Purnima. Police are expecting a crowd of 7.5 million — down from a single-day peak of 11 million two weeks earlier. Millions of pilgrims will be leaving after today’s dip. Many are joined by their families, who have come to take them home.</p>



<p>Kumar’s job is to keep this massive crowd under control. Stampedes, terror attacks, and theft are on his mind. He places a call, and minutes after the SUV is vetted, a police officer appears on-screen to set up a barricade at the foot of the bridge.</p>



<p>Outside, as LED lights switch off, an easterly sunrise turns the sky several shades of crimson. On the water, the boats stand out in silhouette. The air contains a mix of piety and festivity.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/06/MaghMela077-1-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/06/MaghMela077-1-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/06/MaghMela077-1-2800x1575.jpg 2800w, https://restofworld.org/wp-content/uploads/2020/06/MaghMela077-1-1600x900.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/06/MaghMela077-1-768x432.jpg 768w, " sizes="(max-width: 640px) 100vw, calc(100vw - 40px)" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>

    <figure>
      <div>
				<ul>
					<li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/06/MaghMela011-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/06/MaghMela011-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/06/MaghMela011-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2020/06/MaghMela011-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2020/06/MaghMela011-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/06/MaghMela011-2800x1867.jpg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li><li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/06/MaghMela009-1-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/06/MaghMela009-1-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/06/MaghMela009-1-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2020/06/MaghMela009-1-600x400.jpg 600w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li>
				</ul>
			</div>
      <figcaption>Police from the Integrated Command and Control Centre monitor the crowd of devotees with around 700 closed-circuit TV cameras.</figcaption>
    </figure>


<hr>



<p><strong>The Magh Mela</strong> is a smaller version of the<a href="https://en.wikipedia.org/wiki/Kumbh_Mela"> Kumbh Mela</a>, the<a href="https://en.wikipedia.org/wiki/List_of_largest_peaceful_gatherings"> largest human gathering</a> on earth. The Kumbh is held every six years, and the previous one was held in 2019. Over 49 days last year, more than 250 million people took a dip in the <em>sangam</em>, the point where the three rivers meet, with the biggest one-day crowd reaching 50 million. It was the second-largest <a href="https://en.wikipedia.org/wiki/List_of_largest_peaceful_gatherings">gathering</a> in history.</p>



<p>To prepare for the melas, tens of thousands of officials spend months setting up a massive temporary city on the banks of the Ganges. Viewed from above, it is a colorful patchwork divided by big and small bodies of water. Much of this — tents, floating bridges, and metal sheet roads — is built specifically for the festival. As the riverbed floods every year, the city lasts for only several months before the Ganges threatens to reclaim the land.</p>



<p>The physical structure of the mela changes each year, depending on the river. The groundwork usually starts in October, after monsoon season, when the Ganges retreats. Temporary roads are marked, and pontoon bridges are built to join land separated by water. Jetties are built on the banks; the roads are lined with metal sheets; pipelines and electricity cables are laid. Bathing stations are set up along a 3-mile floating jetty, with nets spread underneath to catch those who fall in.</p>



<p>This year, the Ganges’ water levels remained high later than usual. “We could reclaim land only by the end of November, but heavy rains kept hampering civil works until December,” says Rajneesh Mishra, a civil servant who oversees the Mela. This year’s mela was spread over 270 hectares (667 acres), about 30% bigger than Monaco, and divided into six sectors for administrative purposes. Setting up the infrastructure was — and is — an immense logistical feat. The mela has 13 police stations, 40 police outposts, and five thermal power stations. There are five hospitals with operation theaters and 25 beds each, as well as labs, testing facilities, and on-site ambulances.</p>



<p>All of this requires a substantial budget. For this year’s mela, the state<strong> </strong>government budgeted $77 million. Last year, for the Kumbh, it spent $558 million.</p>



<p>All IT operations for the festival are run by the ICCC, which is based in a three-story concrete building that was inaugurated a little over a year ago by Prime Minister Narendra Modi. It’s one of the few permanent structures in the mela area, besides a temple and a 16th-century fort. The center itself is divided up between the monitoring room, which uses a video surveillance system to keep a bird’s-eye view on the mela; the wireless grid room, which liaises between monitors and the ground staff; the war room, where personnel from the fire, water, and police departments as well as the military are on hand at all hours to deal with emergencies; and, finally, a call center.</p>



<p>The key tool in the ICCC’s arsenal is the crowd management application (CMA) system, which keeps an eye on crowd density across all 700 camera feeds. The system is taught how much ground area each CCTV camera covers, which then allows it to estimate, with 85% accuracy, the number of people in a space at any given time. If there are more than three people per square meter, the system issues a warning, and the ground police team is notified and instructed to stop, hold, or divert the crowd.</p>



<p>The Prayagraj Smart City Mission team, which oversees the ICCC, considered various methods for crowd management before settling on the CMA. One option was to estimate crowd size by measuring an area’s smartphone density. But this idea was quickly scrapped. Most devotees at Magh Mela are not smartphone users, says assistant manager Vipin Singh. Only <a href="https://www.news18.com/news/tech/smartphone-users-in-india-crossed-500-million-in-2019-states-report-2479529.html">500 million</a> people in India — roughly one-third of the population — own smartphones. Additionally, many families share one phone, and rural residents (who form as much as 95% of mela attendees, according to police estimates) often don’t use them at all. “If the system shows three people,” says Singh, “there might actually be 100, where 97 are carrying basic mobile phones or no phones at all.”</p>



<p>Last year, officials also experimented with a facial recognition system. The idea was that the technology would provide accurate headcounts, track patterns of movement, and measure time spent between distinct points. But that didn’t work either, as people often carry big bags on their heads as they navigate mela crowds. That meant that, for every face the system could see, a piece of luggage might conceal several more.</p>



<p>Cars have proven easier to track. The automated number plate recognition (ANPR) system records the license number of every vehicle entering or exiting the city, checking it against a database containing the license numbers of stolen vehicles and ones involved in crimes. If a match is found, an alert goes off. For this Magh Mela, says Singh, the administration installed ANPR-aided cameras at eight locations on the city’s periphery. But there are plans to ramp up. “For the next mela,” he says, “we’re looking to increase this to 28 locations.”</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/06/MaghMela107-1-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/06/MaghMela107-1-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/06/MaghMela107-1-2800x1575.jpg 2800w, https://restofworld.org/wp-content/uploads/2020/06/MaghMela107-1-1600x900.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/06/MaghMela107-1-768x432.jpg 768w, " sizes="(max-width: 640px) 100vw, calc(100vw - 40px)" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<hr>



<p><strong>It’s 7:17 a.m.</strong> Mamta Sharma<strong> </strong>stands knee-deep in the river.</p>



<p>Facing east toward the Ganges, she presses her hands in a namaste. She bows her head several times and chants a prayer under her breath. And then she takes a dip in the river, repeating it four times.</p>



<p>Seagulls glide over the heads of bowing devotees, but neither seem to mind the other. When pilgrims toss bits of fruit into the river, the seagulls scoop them up before they land in the water.</p>



<p>Some devotees hire boats to get to the point believed to be the exact location where the three rivers meet. There, people offer their respects to the river, take dips, and fill plastic cans with sacred water. At the <em>sangam</em>, you can see colors mixing, says boatman Ajay Nishad. “The whitish water is that of the Ganges, and the black that of the Yamuna,” he says. Stare long enough and one might think that he is right.</p>



<p>People who can’t afford to hire a boat, which is most pilgrims, instead bathe close to the bank. The mela administration encourages this to avoid overcrowding.</p>



<p>Sharma comes out of the river. Still dripping, she makes a video call to her mother, who could not come with her. She pans her phone to show the <em>sangam</em> to her mother, who offers namaste multiple times, her eyes welling up.</p>



<p>While she dries off, Sharma keeps looking up expectantly. On some auspicious days, the mela administration showers flowers on bathing devotees from a helicopter. She has seen videos of it on social media. “We were all excited about it, but it hasn’t happened today,” she says.</p>



<p>“Still, the holy dip is quite an experience.”</p>



<p>Sharma, who lives in Kolkata in eastern India, has come to the Magh Mela with a group of 12. They live in different cities but come from the same family in Jaunpur, over 100 kilometers from here. Most are elderly. At 31, Sharma is the youngest.</p>



<p>Nishad, the boatman, has been ferrying visitors to the <em>sangam</em> for three years, and he says the melas are always very well organized. Police designate holding areas to keep people safe when crowds swell, and are good at managing foot traffic to prevent bottlenecks. While it can take several hours to find missing people — pilgrims getting separated is a common problem at melas — he says the administration always tracks them down.</p>



<p>But, lately, he has noticed something new. …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://restofworld.org/2020/india-magh-mela/">https://restofworld.org/2020/india-magh-mela/</a></em></p>]]>
            </description>
            <link>https://restofworld.org/2020/india-magh-mela/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24627261</guid>
            <pubDate>Tue, 29 Sep 2020 13:05:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Audrey Tang on her “conservative-anarchist” vision for Taiwan’s future]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24627208">thread link</a>) | @leoschwartz
<br/>
September 29, 2020 | https://restofworld.org/2020/audrey-tang-the-conservative-anarchist/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/audrey-tang-the-conservative-anarchist/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>“Civil Rap Song,” a <a href="https://www.billboard.com/articles/news/international/9392471/japan-dos-monos-civil-rap-song-taiwan-digital-minister-audrey-tang-watch-new-video">track</a> by the Japanese hip-hop trio Dos Monos, begins not with an MC’s rhymes but a faraway voice speaking slow, bureaucratic English. The deconstructed audio is sampled over gloomy synth:<em> “If you overemphasize … amplifying the public and private sector … where is the civic sector? … where is the social sector?”</em> Made in less than a week during Japan’s state of emergency over Covid-19, the track was intended to be “culturally empowering,” according to a band member — a way to remind the public that it still had choices, even in the midst of a crisis.</p>



<p>The speaker in the song is 39-year-old Audrey Tang, a prodigy hacker turned activist turned digital minister in the Taiwanese government. Tang, who wears rimless glasses and dark, baggy clothes by Issey Miyake, does not fit the profile of a rapper’s muse. Yet over the course of the coronavirus pandemic, which her country has managed with singular, tech-enabled ease, she has become an international messenger of Taiwan’s “radically transparent” “digital democracy.” For Tang, the Taiwanese model offers an imitable middle ground: between the internet and personal privacy; between corporate interests and the welfare state.</p>



<p>Before Covid-19, you may have heard of Tang if you followed Taiwanese news, tech gossip, or transgender politics. She is considered one of Taiwan’s top coders, having taught herself the programming languages Haskell and Perl before developing software for Apple that would be used in Siri. In the spring of 2014, when news that Taiwan’s then-president Ma Ying-jeou had threatened the island nation’s independence by attempting to force through a trade deal with China, Tang quit a job at Socialtext, where she worked on Google Suite–like productivity software, to join a scrum of hackers gathered outside the main government building in Taipei. This was the beginning of the Sunflower Movement, a popular uprising against the prospect of national absorption, and Tang helped broadcast the protests and debates online. After a nearly monthlong occupation, Ma was forced to abandon the pact, and the Sunflower activists turned to political organizing. They successfully ran progressive candidates in the 2014 local elections and, in 2016, elected Tsai Ing-wen as president. Tsai’s administration recruited Tang to become the first out transgender person in Taiwan’s executive cabinet.</p>



<p>While Tang’s title is “digital minister,” she is a minister without a ministry. As one of nine <a href="http://www.politicseastasia.com/research/audrey_tang_interview/">“horizontal ministers,”</a> she advises other parts of the government on all things tech — and, because she happens to be obsessed with the U.N.’s Sustainable Development Goals — environmental overlaps. In 2017, for instance, she and her staff worked with the Ministry of the Interior and a risk-management agency to combine separate systems used to prevent and respond to natural disasters. Upon Tang’s recommendation, the government agreed to implement a new cloud-based interface to trim costs and give the public quick, easy access to information on floods, fires, and extreme weather. Last year, during the second <a href="https://www.roc-taiwan.org/uk_en/post/6295.html">“presidential hackathon,”</a> an annual event that invites startup-style ideas for governance, she helped facilitate the development of a solar-powered device that can measure and log water-pollution levels on an open-source blockchain. Soon, any citizen worried about downstream industrial waste will be able to buy a few of these monitors, drop them in a creek, and create a dataset to hold corporations and local officials accountable to environmental regulations.</p>



<p>This is clearly government work, but Tang, at her core a hacker iconoclast, bristles at the notion that she works <em>for </em>Taipei. She still prefers to see herself as a liaison, or, in her words, “a moderator or editor,” between the public and the state. This explains why Tang — though not a doctor or epidemiologist — found herself at the center of Taiwan’s response to Covid-19.&nbsp;</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/ARX_ROW_AT_00054-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/ARX_ROW_AT_00054-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/ARX_ROW_AT_00054-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2020/09/ARX_ROW_AT_00054-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2020/09/ARX_ROW_AT_00054-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2020/09/ARX_ROW_AT_00054-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/09/ARX_ROW_AT_00054-2800x1867.jpg 2800w, " sizes="(max-width: 640px) 100vw, (max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<hr>



<p>When rumors of a dangerous flu emerged from Wuhan, China, last December, the Taiwanese reacted fast. Carrying the memory of the 2003 SARS epidemic, they rushed to buy face masks, threatening to deplete local supplies. In the city of Tainan, an engineer named Howard Wu created a fix: a mapping system to track available masks, using Google GPS and Places API. The platform was an immediate hit. Tang reached out to Wu and secured funding from Google to support and extend the project, which eventually inspired a similar system in South Korea. By spring, the Taiwanese government was managing the supply and distribution of cheap N95-type masks through neighborhood pharmacies. All 24 million residents of Taiwan could buy a certain number per week, at any pharmacy, based on their national health insurance card. Long lines got shorter, and people went about social distancing with confidence. The success of this model — Taiwan has had fewer than 500 total cases and just seven deaths — was what attracted the Dos Monos rappers to Tang.</p>



<p>It helped that, in East Asia, masks were “already ‘natural’ before the pandemic; we didn’t have to invent new things,” Tang said. In response to the common, mostly Western critique that East Asian technocracy relies too much on digital surveillance, Tang explained that Taiwan’s containment method involved “a deep but very narrow and time-limited privacy infringement: You either, when flying back, go to the quarantine hotel for 14 days, or you can choose the digital fence,” that is, submit to strict tracking. “We do not collect new data,” she added. “It’s not a new app. It’s not GPS. People understand it’s proportional.” Taiwan also invested in fact-checking startups and enlisted comedians to craft lighthearted responses to Covid-19 disinformation and consumer misbehavior. In a public-service announcement intended to stem panic-buying of toilet paper, a cartoon version of Tang’s boss, Premier Su Tseng-chang, shimmies his rear end beneath the <a href="https://qz.com/1863931/taiwan-is-using-humor-to-quash-coronavirus-fake-news/">words</a>, “You only have one butt.”</p>



<p>When I spoke with Tang via Skype in July, she referred to Taiwan as “post-pandemic.” The country had never shut down completely, and its streets, markets, and schools were beginning to feel normal. She had just made her morning commute in downtown Taipei, a 15-minute walk from Da’an Park, past the Jianguo flower market, to a broad concrete complex surrounded by lush trees. There, in an open-air arcade that once belonged to the air force, is the Social Innovation Lab, the headquarters of Tang’s digital non-ministry. She dialed in from her office, which resembled the lounge of a coworking space. A vertical Chinese scroll hung over her right shoulder: “More and more graceful every day.”</p>



<p>Tang had been holding public “office hours” on Tuesdays and Wednesdays and was booked through September to chat with locals about tech and government policy, entrepreneurship, and sustainability. Nearly all her interactions, including media interviews and meetings with lobbyists, are subject to a “radical transparency” policy: They are recorded, transcribed, and posted online for all to see. Tang also holds regular virtual visits with communities all over Taiwan.</p>



<figure><blockquote><p>“<strong>Any top-down, coercion, whether it’s from the capitalists or from the state, is equally bad.”</strong></p></blockquote></figure>



<p>During a recent one, entrepreneurs from Taiwan’s indigenous community pressed for changes to the business code. Tang listened and recalled a solution she helped devise last year, when Taiwan became the first Asian country to legalize same-sex marriage. Many older, conservative Taiwanese could accept that gay people should have equal rights but felt reluctant to have their extended-family registries — official, patrilineal records stretching back to the early 20th century — reflect LGBT unions. The fix was a “hyperlink act” that, with a single click, would amend relevant sections of the civil code to give queer couples the same rights and duties as anyone else but would not, as with straight marriages, “hyperlink to the in-laws,” meaning that the families of the same-sex couple wouldn’t be permanently bonded in the eyes of the state. “Their families don’t wed. It’s the individuals that wed,” she told me. “It’s a social innovation that convinced both generations that the values that they cherish are not disrupted when we pass marriage equality. It’s marriage equality with intergenerational solidarity.”</p>



<p>It’s also a compromise. Tang, whose mother was active in Taiwan’s cooperative movement before the country transitioned to democracy, much prefers collaboration to battle. This might relate as well to another aspect of Tang’s childhood: she was born with a heart defect and often talks about the virtues of unhurried observation. “If you’re slow in your motion, you tend to notice other, nonhuman beings,” she told me — trees, rivers, computers. As digital minister, she invoked this cooperative ideal to implement Pol.is, an online discussion board where Taiwanese people can engage in a “rough-consensus process” about social issues, such as what sorts of rules should govern Uber or how best to combat the spread of revenge porn. To prevent trolling, the platform functions without a reply button.</p>



<p>Taiwan’s constitution prohibits private businesses from acting against “the balanced development of national wealth and people’s livelihood,” yet the country’s most famous corporation is high-tech Apple supplier Foxconn, which gained notoriety for driving its mainland Chinese factory workers to suicide. I asked whether the cruelties of big businesses hadn’t dimmed Tang’s faith in the possibility of social equilibrium. “The manufacturing companies, they learned, of course, not to do [things with] adverse effects within Taiwan proper,” she replied, referring to Foxconn’s compounds in mainland China. But the next generation of Taiwanese entrepreneurs, she said, will use robotics to reduce worker exploitation, embrace “worker associations,” and pursue …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://restofworld.org/2020/audrey-tang-the-conservative-anarchist/">https://restofworld.org/2020/audrey-tang-the-conservative-anarchist/</a></em></p>]]>
            </description>
            <link>https://restofworld.org/2020/audrey-tang-the-conservative-anarchist/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24627208</guid>
            <pubDate>Tue, 29 Sep 2020 13:00:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learning Rust the Open Source Way]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24627068">thread link</a>) | @bradsherman
<br/>
September 29, 2020 | https://bitsbybrad.com/2020-09-29-learning-rust/ | <a href="https://web.archive.org/web/*/https://bitsbybrad.com/2020-09-29-learning-rust/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article role="main">
        <p>A few months ago I started learning Rust, and in the process I ended up contributing to an open source project for the first time. It turned out to be a great vehicle for learning Rust, so in this post I’d like to go over what I did and why I think it was a good learning experience. In particular I want to walk through my thought process as I navigated my first open source contribution in the hopes that others who face similar challenges are encouraged to overcome them. Throughout this post I’ll also explain more about how this helped me learn Rust.</p>

<h2 id="motivation">Motivation</h2>

<p>The main impetus for deciding to learn Rust was that I had read a lot of great reviews and Rust seemed to be growing in popularity, so I thought it would be a nice addition to my tool-belt. I also use C++ in my day job and saw that Rust was trying to improve on some of the drawbacks of C++ (like easily writing safe, concurrent code), so I wanted to start investigating for myself.</p>

<p>The first thing I did was read <a href="https://doc.rust-lang.org/book/">The Rust Programming Language</a> (which I highly recommend for anyone else new to Rust!). I breezed through it fairly quickly, dutifully completing all of the exercises. Once I finished, I still felt like I had the training wheels on and I wanted to learn more. I briefly thought about finding <em>another</em> guide or tutorial to go through, but luckily I realized that was a one-way ticket to <a href="https://www.freecodecamp.org/news/how-to-escape-tutorial-purgatory-as-a-new-developer-or-at-any-time-in-your-career-e3a4b2384a40/">tutorial purgatory</a>, before getting in too deep. To be clear, the book (and most language introduction texts in my opinion) was great for understanding the basics and acting as a reference as I got more experience with the language. It’s just that I wanted to get to the next level of understanding and be able to write new code from scratch (take off the training wheels). In order to do that, I needed a project to sink my teeth into and push myself towards that deeper level of understanding.</p>

<p>In general at this point I could have done one of two things: start my own project or help with someone else’s project. I spent a decent amount of time trying to think of an exciting project, but I didn’t have any great ideas off the top of my head. Plus I had already accumulated plenty of small, unfinished toy projects on Github, so I started investigating the open source route. That way I would get clear instructions on what needed to get done and I could simply focus on improving my Rust abilities.</p>

<p>This wasn’t the first time I’ve thought about contributing to open source. I’ve had a desire to start contributing to open source software ever since college, but I never felt like I was good enough to help out. It was a clear case of <a href="https://en.wikipedia.org/wiki/Impostor_syndrome">imposter syndrome</a>. I imagine there are many other developers who have run into this feeling. Certainly it’s much more common in an interview but the idea here is the same. There’s no fool proof way of shaking off imposter syndrome, but the fact that I didn’t personally know any of the project maintainers helped me at least decide to give it a shot!</p>

<p>Once I stopped focusing on all the things that could go wrong for a second, I started to realize how beneficial contributing to an open source project could be in my quest to learn Rust. There are multiple experienced developers reviewing your code who know way more about the language and tools you are using so they can quickly explain important concepts you might not understand or even know about. You get the chance to have discussions with people all over the world who have their own ideas for a solution. I think anywhere you can find a cross-pollination of ideas like this is a great place to learn. The trick is to not be afraid to admit you don’t know something, or that your idea is wrong. By no means is it easy to do this, but once you do it is quite liberating!</p>

<h2 id="clippy">Clippy</h2>

<p>The next step was to find a project to contribute to. After googling a couple variations of “rust open source projects for beginners”, I found <a href="https://github.com/rust-lang/rust-clippy">Clippy</a>. The best summary comes from their Github: “A collection of lints to catch common mistakes and improve your Rust code”. I am always a fan of developer productivity and encouraging good coding standards, so this project seemed perfect! Part of the reason I picked this project is because the maintainers do a great job of labeling issues that are easier with ‘good first issue’ so that I could quickly find potential issues to solve. I recommend finding a project like this as it makes the initial experience with open source much smoother. Being able to choose from multiple issues that were better suited for beginners reduced the overwhelming feeling of being new. I still had to do plenty of work to acclimate myself with the new code base and the issue I was trying to solve, but I was able to proceed knowing that I was not out of my league.</p>

<p>I ended up volunteering to add a new lint for the use of <code>.nth(0)</code> on any iterator. I’ll post a link to the issue at the end of this post, but the basic idea is that Rust developers should call <code>.next()</code> on the iterator instead of <code>.nth(0)</code> (if you’re curious, check out the docs for <a href="https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.nth">nth</a> and <a href="https://doc.rust-lang.org/std/iter/trait.Iterator.html#tymethod.next">next</a> to see why this is desired). It was my job to make Clippy output a helpful suggestion anytime this situation is found. I forked and cloned the repository, and then spent some time building the code and running the tests. I think this is important to do, especially in a new language, so that you can get familiar with the build system first and focus on implementing your solution after. Another reason Clippy was a nice place to start was there are hundreds of lints and therefore hundreds of other examples of what I had to do. I searched for examples of similar lints to the one I was implementing so I could start to understand which parts of the code I needed to change. After a while I was able to cobble together some changes, but I was pretty confident they were not correct. I was stuck and didn’t really know what to do. I returned to the Clippy Github page to see if I could find any useful information and found this in <code>CONTRIBUTING.md</code>:</p>

<blockquote>
  <p>First: if you’re unsure or afraid of <strong>anything</strong>, just ask or submit the issue or pull request anyway. You won’t be yelled at for giving it your best effort. The worst that can happen is that you’ll be politely asked to change something. We appreciate any sort of contributions, and don’t want a wall of rules to get in the way of that.</p>
</blockquote>

<p>They know this is going to happen, and they welcome the pull requests anyway. Clearly my best course of action was to push it up, admit I’m stuck, and ask for help. It felt weird pushing up code I know did not work, but the reason I chose to do this in the first place was to learn so I pushed up the branch and asked for a review.</p>

<h3 id="feedback">Feedback</h3>

<p>As I suspected, there were more than a few problems with my initial implementation, but that’s okay! I received encouraging and helpful feedback from multiple users. I learned new macros in Rust like <a href="https://docs.rs/if_chain/1.0.0/if_chain/">if_chain</a>, and was guided towards more helpful examples in the code related to what I needed to do. After a bit more back and forth, my pull request was merged! It was a great feeling knowing that I contributed at least in a small way to software that is used by thousands of developers every day!</p>

<p>I think it’s important to make a special note about the initial round of feedback I received. It wasn’t condescending or mean, even though I missed some things that by now have become second nature to the maintainers. I received simple, encouraging, and timely feedback that allowed me to quickly make changes and not feel bad about getting it wrong the first time. If the feedback is too complex, disrespectful, or takes forever there’s a good chance I wouldn’t want to contribute to the project again. What’s worse, I may write off contributing to open source altogether! Creating a welcoming environment for new contributors is key to establishing a thriving open source project.</p>

<h2 id="takeaways">Takeaways</h2>

<p>So, what did I learn about Rust after this whole experience? Well, there’s still so much to learn but after reading <a href="https://doc.rust-lang.org/book/">The Rust Programming Language</a> I was particularly intrigued by Rust’s idea of <a href="https://doc.rust-lang.org/book/ch04-01-what-is-ownership.html">ownership</a>. I was immediately able to make a connection to my professional work in C++, particularly with regards to <a href="https://www.internalpointers.com/post/c-rvalue-references-and-move-semantics-beginners">move semantics and rvalue references</a>. Rust makes it very explicit who can read and modify data, and the compiler will yell at you if you break the rules. These rules help prevent multiple threads from modifying the same piece of data at the same time, also known as a data race. C++’s rules around data ownership and mutability are less strict, so the compiler cannot protect you from data races as much as it can in Rust. Just by writing Rust code for Clippy and being exposed to the rules that the Rust compiler enforces made me a better C++ programmer in this aspect. Now I am explicitly thinking about ownership and mutability when I write C++ code even though there are no rules forcing me to do so.</p>

<p>Other concepts I found interesting were <a href="https://doc.rust-lang.org/book/ch06-00-enums.html">pattern matching</a> and <a href="https://doc.rust-lang.org/book/ch09-02-recoverable-errors-with-result.html">recoverable errors</a>, which I had no experience with before. Contributing to Clippy gave me valuable experience dealing with these ideas and helped solidify my understanding. These features of the language, among others, were my first significant exposure to functional programming language concepts. Having come from an almost exclusively procedural background, it was interesting to see the two worlds collide. I was excited to have discovered something new, and I look forward to learning more about functional programming languages in the future as well!</p>

<h2 id="conclusion">Conclusion</h2>

<p>To wrap things up I want to reiterate some key lessons I learned from contributing to an open source project for the first time. I think it’s really important to find the right project and have a positive mindset when trying to jump into the open source world. Specifically:</p>

<ul>
  <li>Find a project that has a label for beginners, such as ‘good first issue’. These labels reduce the burden of finding an issue to choose, which can be overwhelming on large projects.</li>
  <li>Take a look at some of the …</li></ul></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bitsbybrad.com/2020-09-29-learning-rust/">https://bitsbybrad.com/2020-09-29-learning-rust/</a></em></p>]]>
            </description>
            <link>https://bitsbybrad.com/2020-09-29-learning-rust/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24627068</guid>
            <pubDate>Tue, 29 Sep 2020 12:48:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Abandoned Cart Recovery: Email vs. Messenger 2020]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24627034">thread link</a>) | @JonasvdP
<br/>
September 29, 2020 | https://www.iampop.com/blog/infographic-abandoned-cart-recovery-email-vs-messenger/ | <a href="https://web.archive.org/web/*/https://www.iampop.com/blog/infographic-abandoned-cart-recovery-email-vs-messenger/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <h2 id="using-a-range-of-data-we-looked-into-some-of-the-most-recent-cart-abandonment-statistics-and-how-ecommerce-shops-can-minimize-this-issue-">Using a range of data, we looked into some of the most recent cart abandonment statistics, and how ecommerce shops can minimize this issue. </h2><p>Should you use email marketing, chat marketing or both to recover abandoned carts? And which sectors stand to win back most revenue in 2020? Here are some of the headline stats from the data we compiled:</p><h3 id="abandoned-cart-rates-across-sectors-">Abandoned cart rates across sectors:</h3><p>Average all sectors: <strong>88.05%</strong></p><div><p>Out of all industries, ecommerce fashion businesses can benefit most from running abandoned cart recovery campaigns. Using email marketing to recover abandoned carts works well, but its efficiency has been on the decline:</p><p>Fashion: <strong>90.68% </strong><br>Retail: <strong>84.51% </strong><br>Travel: <strong>79.95%</strong></p></div><p><em>Source: <a href="https://www.iampop.com/blog/infographic-abandoned-cart-recovery-email-vs-messenger/[https://www.statista.com/statistics/457078/category-cart-abandonment-rate-worldwide/](https://www.statista.com/statistics/457078/category-cart-abandonment-rate-worldwide/)">Statista</a></em></p><p>Abandoned cart email open rates have dropped from <strong>46.1%</strong> in 2013 to <strong>40.76%</strong> in 2020. These open rates are still relatively high. Click rates for this type of email have also dropped from <strong>13.3%</strong> in 2013 to <strong>8.24%</strong> in 2020. </p><p><em>Source: <a href="https://www.iampop.com/blog/infographic-abandoned-cart-recovery-email-vs-messenger/[https://www.statista.com/statistics/457078/category-cart-abandonment-rate-worldwide/](https://www.statista.com/statistics/457078/category-cart-abandonment-rate-worldwide/)">Barilliance</a></em></p><p>How about Messenger's abandoned cart recovery performance?</p><h3 id="messenger-open-and-click-through-rates-">Messenger open and click through rates:</h3><p>Messenger average open rates (<strong>80-90%</strong>) and click-through rates (<strong>56%</strong>) are significantly higher than email. At the same time, where abandoned cart email conversion rates lie at <strong>10.7%</strong>, Messenger performs around <strong>33%</strong> better. </p><p><em>Sources: <a href="https://www.iampop.com/blog/infographic-abandoned-cart-recovery-email-vs-messenger/[https://moosend.com/blog/cart-abandonment-rate-infographic/](https://moosend.com/blog/cart-abandonment-rate-infographic/)">Moosend</a>, <a href="https://neilpatel.com/blog/open-rates-facebook-messenger/">Neil Patel</a>, <a href="https://upbeatagency.com/facebook-messenger-bring-customers-back/">Upbeat</a></em></p><p>Basically, while abandoned cart emails still perform relatively well in 2020, they are less efficient than a few years ago. At the same time, Messenger outperforms email for every benchmark. </p><h2 id="abandoned-cart-recovery-email-vs-messenger-2020">Abandoned Cart Recovery: Email vs. Messenger 2020</h2><!--kg-card-begin: markdown--><figure><img src="https://www.iampop.com/blog/content/images/2020/09/Infographic-Abandoned-Cart-Recovery-Statistics-Email-vs-Messenger-2020-2.png" alt="Infographic-Abandoned-Cart-Recovery-Statistics-Email-vs-Messenger-2020" title="Infographic-Abandoned-Cart-Recovery-Statistics-Email-vs-Messenger-2020"></figure><!--kg-card-end: markdown--><p>If you liked this infographic, show us some <strong><strong><strong><strong>â�¤ï¸�</strong></strong></strong></strong> and tweet about it by clicking <a href="https://ctt.ac/8_b9d">here</a> ðŸ‘ˆ</p><!--kg-card-begin: hr--><hr><!--kg-card-end: hr--><!--kg-card-begin: markdown--><div>
 <p>Hey there ðŸ‘‹</p>
 <p>
Use POP to set up an abandoned cart campaign.
 </p>
 <p><a href="https://www.iampop.com/dashboard/commerce/shopify" target="_blank">
  Get started
 </a>
</p></div>
<!--kg-card-end: markdown--><p><em>Or why don't you connect to POP directly through Messenger at <a href="https://m.me/bypophq">https://m.me/bypophq</a></em></p>
        </div></div>]]>
            </description>
            <link>https://www.iampop.com/blog/infographic-abandoned-cart-recovery-email-vs-messenger/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24627034</guid>
            <pubDate>Tue, 29 Sep 2020 12:45:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Write Shorter Blog Posts]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24626848">thread link</a>) | @HermanMartinus
<br/>
September 29, 2020 | https://jonathancai.bearblog.dev/shorter/ | <a href="https://web.archive.org/web/*/https://jonathancai.bearblog.dev/shorter/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>I realize a big hindrance to me writing more is thinking that every post has to be significant/long. This is wrong.</p>
</div></div>]]>
            </description>
            <link>https://jonathancai.bearblog.dev/shorter/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24626848</guid>
            <pubDate>Tue, 29 Sep 2020 12:26:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[3 key RPA+ML insights from invoice process automation project]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24626595">thread link</a>) | @arauhala
<br/>
September 29, 2020 | https://aito.ai/blog/top-3-insights-from-using-rpa-ml-to-automate-invoice-processing/ | <a href="https://web.archive.org/web/*/https://aito.ai/blog/top-3-insights-from-using-rpa-ml-to-automate-invoice-processing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><blockquote><p>This post appeared first on <a href="https://towardsdatascience.com/top-3-insights-from-using-query-based-ml-to-automate-invoice-processing-a3260c3b840d">Towards Data Science</a> in September 25th, 2020.</p></blockquote><p>The <a href="http://robotic_process_automation/">RPA</a> team of <a href="https://www.posti.fi/en">Posti</a>, the Finnish logistics giant, started to use machine learning to boost their invoice automation. These are the key insights from that project. A good read for whoever is leading or contributing when taking existing automation and making it intelligent using machine learning.</p><p>You can read more about the project <a href="https://aito.ai/blog/posti-boosts-their-rpa-with-aito/">here</a>. In short, the problem was that <a href="https://www.posti.fi/">Posti</a> receives ten thousand purchase invoices a month. For accounting, payment and taxation purposes, each invoice needs to be associated with 1) a reviewer 2) a budget/account 3) department and 4) value added tax code.</p><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/blog/top3-purchase-invoice-form.png" alt=""></p></div><p><span>In the purchase invoice automation process the goal was to automatically fill the 4 missing fields based on 4 known invoice fields. Such forms get continuously filled by the countless senior employees, accountants, managers and executives in virtually all organizations. Image source: Aito </span></p></div><p>As a solution, UiPath was used to copy the historical invoices to the predictive database. Then the predictive database queries were used to predict the missing fields:</p><div data-language="json"><pre><code><span>{</span>
  “from” <span>:</span> “purchase_invoices”<span>,</span>
  “where”<span>:</span> <span>{</span>
    “purchase_number “<span>:</span> “XY<span>12345678</span>”<span>,</span>
    “company_id”<span>:</span> “<span>234234</span>–<span>3</span>”<span>,</span>
    “vendor_number”<span>:</span> “<span>0002948810</span>”<span>,</span>
    “currency” <span>:</span> “EUR"
  <span>}</span><span>,</span>
  “predict”<span>:</span> “reviewer”
<span>}</span></code></pre></div><p>The predictions with high confidence/probability estimates were then used to fill the missing fields in the invoices by the RPA machinery and automate different phases of the process.</p><p>This is what we learned.</p><p>Process automation is a very rewarding field for machine learning application, because:</p><ol><li>Companies tend to have high quality and complete records of their core business processes, because the business cannot operate without those records (e.g. orders or invoices) and in the worst case there may be juridical implications (as with invoices), if the business records are not well maintained.</li><li>Most processes have extremely strong patterns. For example, the invoices coming from ‘the Parking company’ tend to always go to the ‘parking budget’. Such patterns are very easy to harvest from data and utilize in process automation allowing for example 20%-99% automation rates in exchange for 1%-5% errors in the statistical process.</li><li>Large companies can have a very high volumes in their core processes. For example: Posti processes about ten thousand invoices a month.</li></ol><p>As consequence of good data, high automation rates and high volumes, the existing process data is often easy to untap and reuse in intelligent automation for a significant business gain.</p><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/blog/top3-mantas-hesthaven.jpg" alt=""></p></div><p><span>There are huge opportunities in the RPA+ML space especially now, when the economics of machine learning fit better the limited RPA project budgets. Photo by Mantas Hesthaven on Unsplash</span></p></div><p>Also based on the discussions with the Posti project team:</p><ul><li>RPA+ML projects are not that expensive compared to the traditional ML projects if done with a predictive database. Posti RPA team estimated that the median RPA project may take e.g. 3 months on average (there is typically a lot of analysis, communication and organizing overhead involved), while an RPA+ML project might take 4 months (extra month for the ML part, the extra data integrations, extra communication and the extra steps to handle possible errors). Still, it’s good to reserve significantly more time to the first RPA+ML project done by your organization.</li><li>There are lot of use cases. It was estimated that 10%-20% of the Posti RPA use cases could benefit from the similar kind of machine learning. </li><li>The business benefits of RPA+ML applications can be high: possibly hundreds of thousands of euros, because of high automation rates in moderately complex high volume processes</li></ul><p>As a result of these discussions: the team did identify many rewarding business cases and opportunities and decided to expand the deployment of ML with the same setup of tools.</p><p>While in the traditional rule-based RPA you may have strong guarantees that the process is errorless, with the intelligent automation it’s difficult to create an entirely error-free solution. This applies because the machine learning component operates in a statistical fashion.</p><div><div><p><img src="https://source.unsplash.com/GikVY_KS9vQ" alt=""></p></div><p><span>Statistical systems introduce a controlled error rate. Photo by Michał Parzuchowski on Unsplash</span></p></div><p>But while you cannot have a perfectly error-free system, what you can have is:</p><ul><li><p>A controlled error rate. In the Posti case, the ML component was able to fill the missing tax code field in 99% of cases with less than 1% error and 63% of the cost center cases with less than 5% error rate. In the invoice automation case, the content is double-checked in accounting, so a small error rate is typically not an issue.</p></li><li><p>Radically higher automation rates for extremely complex systems. In the Posti case, you could see thousands or even tens of thousands of separate purchase invoice types &amp; special cases. Developing and maintaining thousands of different rules to implement a rule-based RPA with high coverage is simply not feasible in such a case. While complex rule-based automation may manage to handle e.g. 10% of the invoices, I have seen 80% or 90% automation rates with ML based solutions.</p></li></ul><p>In essence with RPA+ML: you accept a controlled error rate in exchange for a radically higher automation rate, lower maintenance cost and an ability to solve otherwise unsolvable problems.</p><p>In practice, this requires a change in the mindset and a straightforward discussion with the business owners about the statistical errors and the optimal error rate/automation rate trade-off. It may also require an additional step in the process to review and correct the statistical decisions with an error rate above 1%.</p><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/blog/top3-you-x-ventures.jpg" alt=""></p></div><p><span>As a part of the Posti project, the RPA team and the accounting team meet to decide the automation rate vs error rate trade-off. Photo by You X Ventures on Unsplash</span></p></div><p>You can find more information about the topic in an TDS article about <a href="https://towardsdatascience.com/return-on-investment-for-machine-learning-1a0c431509e">ML return on investment</a></p><p>In the implemented invoice automation, the basic interaction was simplistic:</p><ol><li>First, the RPA robot scrapes the processed invoice forms from the accounting system into the predictive database.</li><li>Second, the robot reads the incoming invoices, makes 4 simple predictive queries to predict the missing fields</li><li>Third, the robot uses predictions to write the missing fields into the accounting system and changes the invoice process state.</li></ol><p>There are numerous RPA+ML problems that can be solved in a similar simple manner. In essence, whenever you see a process with a form it can likely be automated in the same way.</p><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/blog/top3-customer-contact-form.png" alt=""></p></div><p><span>Any process that includes a form is a potential target for ML+RPA based automation. In this example: the customer can be statistically inferred based on the email, while the product, the issue category and the correct customer support person can be inferred from the title and the description. As such, an ML enabled robot may process most cases flawlessly. Image source: Aito</span></p></div><p>Still, while the RPA part can be relatively straightforward, the ML part can be the exact opposite. In a typical scenario, you’ll ask for the data science team time for fitting, deploying and integrating the 4 ML models, that do the predictions for the 4 different fields. The data science project can take a while, it can be expensive and in essence: the data science team will schedule the time according to their wider priorities and often RPA is not at the top of their list.</p><p>On the other hand, if you use a predictive database to query the unknown fields, the experience is similar to using an SQL database to query the known fields. This SQL-like experience is easy enough for most RPA developers and the related effort and the time investments fit better the tight RPA budgets and schedules. The inherent easiness of the approach was reflected by the Posti RPA developer comment: ‘What I most like in Aito is that it’s easy to use’. It was also observed that the database integrations were a rather small part of the project and that the approach allowed the RPA team to do RPA+ML autonomously. </p><p>So the right tools can make RPA+ML easy and let the RPA teams progress on their intelligent automation roadmap autonomously. Of the alternative ML tools available: the used predictive database seems especially promising, because <a href="https://aito.ai/blog/could-predictive-database-queries-replace-machine-learning-models/">the fundamental easiness of doing machine learning with predictive queries</a>.</p><p>RPA+ML creates immediate business impact, it doesn't require a data scientist and it doesn't need to be hard.</p><p>Yet, we have found that most companies have difficulties in recognizing RPA+ML use cases. This is quite understandable, because RPA teams often lack machine learning experience and expertise in the level most of the solutions in the market require.</p><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/blog/top3-markus-spiske.jpg" alt=""></p></div><p><span>While the RPA+ML opportunities are numerous, there are challenges in identifying use cases, because the lack of machine learning expertise in RPA teams. Photo by Markus Spiske on Unsplash </span></p></div><p>As a consequence: while a company can have an abundance of good use cases, these can go largely unrecognized. Now to solve the issues regarding use cases:</p><ol><li>A simple thought exercise can help here. Like mentioned before: any business process that can be thought of as a form is a potential RPA+ML automation target.</li><li>There are a lot of use case descriptions available online.</li><li>Also you can always consult intelligent automation experts or vendors like us for advice.</li></ol><p>If you have questions or comments about the topic, we are happy to help at <a href="https://aito.ai/contact-us/">https://aito.ai/contact-us/</a> or you can contact our RPA consultant friends at <a href="https://sisuadigital.com/">Sisua Digital</a>. Sisua has a strong expertise in ML-supported RPA automation and they held an advisory role in the Posti invoice automation project.</p><a href="https://aito.ai/blog">Back to blog list</a></div></div>]]>
            </description>
            <link>https://aito.ai/blog/top-3-insights-from-using-rpa-ml-to-automate-invoice-processing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24626595</guid>
            <pubDate>Tue, 29 Sep 2020 11:58:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Almost no-JS solution: Real-time monitoring of Hacker News and Reddit]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24626578">thread link</a>) | @stanislavb
<br/>
September 29, 2020 | https://alertcamp.com/live/Apple,Google,Microsoft,Amazon,Facebook | <a href="https://web.archive.org/web/*/https://alertcamp.com/live/Apple,Google,Microsoft,Amazon,Facebook">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
<div data-phx-main="true" data-phx-session="SFMyNTY.g2gDaAJhBHQAAAAHZAACaWRtAAAAFHBoeC1Gam9mZzl1ZGVWdDFmN1J4ZAAKcGFyZW50X3BpZGQAA25pbGQACHJvb3RfcGlkZAADbmlsZAAJcm9vdF92aWV3ZAAcRWxpeGlyLkFsZXJ0Y2FtcFdlYi5MaXZlTGl2ZWQABnJvdXRlcmQAGkVsaXhpci5BbGVydGNhbXBXZWIuUm91dGVyZAAHc2Vzc2lvbnQAAAAAZAAEdmlld2QAHEVsaXhpci5BbGVydGNhbXBXZWIuTGl2ZUxpdmVuBgA9pmzodAFiAAFRgA.4_IUGrX7-7RvNFRGCHzuODhlDMF7NC5S74RGDEUhJag" data-phx-static="SFMyNTY.g2gDaAJhBHQAAAADZAAKYXNzaWduX25ld2pkAAVmbGFzaHQAAAAAZAACaWRtAAAAFHBoeC1Gam9mZzl1ZGVWdDFmN1J4bgYAPaZs6HQBYgABUYA.76MP41qhCrdOk0IvP8B4D9s3hVHuYWOO9kLTZkcb-m4" data-phx-view="LiveLive" id="phx-Fjofg9udeVt1f7Rx">



<div>
  <div>
    <p>
      Live monitoring of everything that's being posted on <b>Reddit</b> &amp; <b>HackerNews</b>.<br>
      Sponsored by <a href="https://www.saashub.com/">SaaSHub</a>
    </p>

      <div>
        <div>
            <p><span>Monitoring</span>
            <a href="#" phx-click="toggle-play" phx-disable-with="pause...">pause</a>
        </p></div>
        <p><span>Online Users</span>
-        </p>
        <div>
<p><a data-phx-link="redirect" data-phx-link-state="push" href="https://alertcamp.com/live?placeholder=Apple%2CGoogle%2CMicrosoft%2CAmazon%2CFacebook">Change keywords</a>        </p></div>
      </div>
  </div>

  <div>
      <table>
        <thead>
          <tr>
            <th colspan="2">
              Matches count
            </th>
          </tr>
        </thead>
        <tbody>
            <tr>
              <td>Amazon</td>
              <td>0</td>
            </tr>
            <tr>
              <td>Apple</td>
              <td>0</td>
            </tr>
            <tr>
              <td>Facebook</td>
              <td>0</td>
            </tr>
            <tr>
              <td>Google</td>
              <td>0</td>
            </tr>
            <tr>
              <td>Microsoft</td>
              <td>0</td>
            </tr>
        </tbody>
      </table>
  </div>
</div>
<hr>

<ul id="matches" phx-hook="LiveMatchesUpdated">
</ul><p>

    Waiting for keyword matches...<br>
    This may take up to 30 seconds
</p></div>      </div>
    </div></div>]]>
            </description>
            <link>https://alertcamp.com/live/Apple,Google,Microsoft,Amazon,Facebook</link>
            <guid isPermaLink="false">hacker-news-small-sites-24626578</guid>
            <pubDate>Tue, 29 Sep 2020 11:56:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Check downtime status of top websites like Gmail, linkedin]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24626391">thread link</a>) | @1hakr
<br/>
September 29, 2020 | https://simpleops.io/websites | <a href="https://web.archive.org/web/*/https://simpleops.io/websites">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://simpleops.io/websites</link>
            <guid isPermaLink="false">hacker-news-small-sites-24626391</guid>
            <pubDate>Tue, 29 Sep 2020 11:33:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Identifying Airtel middleboxes that censor HTTPS traffic]]>
            </title>
            <description>
<![CDATA[
Score 375 | Comments 121 (<a href="https://news.ycombinator.com/item?id=24626388">thread link</a>) | @justDankin
<br/>
September 29, 2020 | http://iamkush.me/sni-airtel/ | <a href="https://web.archive.org/web/*/http://iamkush.me/sni-airtel/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>Back in November 2019, <a target="blank" href="https://cis-india.org/internet-governance/blog/reliance-jio-is-using-sni-inspection-to-block-websites">we reported</a> that Reliance Jio is able to block HTTPS internet traffic by means of a deep packet inspection (DPI) technique. In response, some readers messaged us saying that they ran our test and were able to reproduce similar behaviour on Airtel mobile networks. According to <a href="https://trai.gov.in/sites/default/files/PIR_08012020_0.pdf" target="_blank">TRAI's Performance Indicators report for Jul-Sep 2019</a>, Reliance Jio and Airtel serve roughly 52% and 23% of internet subscribers in India respectively. <strong>This essentially means that SNI inspection based censorship is now impacting every 3 out of 4 internet connections in India.</strong></p>

<p>Although the previous test was able to detect the presence of SNI inspection based censorship, it was not very insightful. In this post, we delve into a more informative test which not only confirms the presence of SNI inspection based censorship, but also helps us identify the exact mechanism. Furthermore, it also allows us to identify middleboxes which are actively inspecting SNI in TLS handshakes and censoring requests. <strong>Using this method, we were able to discover 25 different middleboxes registered to Airtel, which are actively censoring HTTPS traffic.</strong></p>

<p>Quick links to different sections of this post: <br>
1. <a href="#secTLS">Transport Layer Security</a> <br>
1.1 <a href="#secSNI">Server Name Indication</a> <br>
2. <a href="#secSNICensor">SNI Inspection based censorship</a> <br>
3. <a href="#secINT">Iterative Network Tracing</a> <br>
4. <a href="#secData">Data Preparation</a> <br>
5. <a href="#secMethod">Methodology</a> <br>
6. <a href="#secAirtel">Examining Airtel's behaviour</a> <br>
7. <a href="#secRef">References</a></p>

<p>All the code for replicating this experiment, as well as the logs from our test runs can be found in <a target="_blank" href="https://github.com/kush789/INT-SNI">this repository</a>. Big shout-out to <a href="https://ipinfo.io/" target="_blank">IPinfo</a> for giving us access to their IP address dataset, and <a href="https://gurshabad.github.io/" target="_blank">Gurshabad Grover</a> for his suggestions while ideating the methodology and for editing this post.</p>





<p>Transport Layer Security (TLS) is a cryptographic protocol for providing communication confidentiality and authenticity, commonly used for encrypting web traffic (as done in HTTPS). Normally TLS is used over TCP, as it requires a reliable in-order data stream. A <a href="https://www.cloudflare.com/learning/ssl/transport-layer-security-tls" target="_blank">quick refresher</a> on TLS by Cloudflare.</p>

<p><img src="https://i.imgur.com/OlMYujg.png" alt="img">
</p><center>A TCP handshake followed by a TLS Handshake. The ClientHello is a message sent by the client, which initiates the TLS handshake. This message can contain extensions such as SNI. Image credits - <a href="https://www.cloudflare.com/learning/ssl/what-happens-in-a-tls-handshake/">Cloudflare</a></center>



<h3 id="servernameindication">Server Name Indication</h3>

<p>Server Name Indication (SNI), defined first in <a href="https://tools.ietf.org/html/rfc4366" target="_blank">RFC4366</a> and then in <a href="https://tools.ietf.org/html/rfc6066" target="_blank">RFC6066</a>, is a TLS extension designed to facilitate the hosting of multiple HTTPS websites on the same IP address. While sending a <code>ClientHello</code> message (which initiates the establishment of a secure connection), the client is expected to fill in the SNI attribute with the hostname of the website it wishes to connect to. SNI, unfortunately, travels on the network in cleartext, i.e. <strong>network operators can not only see the websites you’re visiting, but also filter traffic based on this information.</strong></p>

<hr>





<p>Since the SNI present is in cleartext, anyone in the network can inspect and filter traffic based on its value. As seen in other countries, ISPs can leverage this to deny access to certain websites. We can observe the same by attempting a TLS connection using openssl and monitoring packets to the host.  </p>

<pre><code>openssl s_client -state -connect 103.224.212.222:443 -servername fullhd720.com  
</code></pre>

<p><img src="https://raw.githubusercontent.com/kush789/INT-SNI/master/images/airtel_103.224.212.222_fullhd720.com.png" alt="img">
</p><center>An attempted TLS connection to <code>103.224.212.222</code>, with SNI <code>fullhd720.com</code>. We observe a RST packet immediately after the ClientHello message containing the SNI is sent.</center>

<p>For instance, using Airtel, we can see that the client receives a TCP RST packet when it tries to connect to a blocked website "fullhd720.com". The RST packet seems to be originating from the actual host, and is received right after the ClientHello message containing the SNI is sent. <a href="https://github.com/kush789/INT-SNI/blob/master/pcaps/airtel_103.224.212.222_fullhd720.com.pcap" target="_blank">PCAP</a>.</p>

<p>To confirm that the connection termination was indeed due to the SNI, we can reattempt the connection with a different SNI which we don't expect to be blocked (in this case we use <code>facebook.com</code>).</p>

<pre><code>openssl s_client -state -connect 103.224.212.222:443 -servername facebook.com  
</code></pre>

<p><img src="https://raw.githubusercontent.com/kush789/INT-SNI/master/images/airtel_103.224.212.222_facebook.com.png" alt="img">
</p><center>An attempted TLS connection to <code>103.224.212.222</code> with a different SNI, <code>facebook.com</code>. In this case, we observe a successful TLS handshake</center>

<p>This time we notice a successful connection, indicating that the RST in the previous attempt was indeed due to the specified SNI. <a href="https://github.com/kush789/INT-SNI/blob/master/pcaps/airtel_103.224.212.222_facebook.com.pcap" target="_blank">PCAP</a>.</p>

<p>Although this test does demonstrate the presence of SNI inspection based censorship, the packet dumps are not sufficient to prove that the RST packet was actually forged by a middlebox belonging to the ISP.</p>

<hr>  





<p>For a given host, let's call the minimum Time to Live (<a href="https://packetpushers.net/ip-time-to-live-and-hop-limit-basics/" target="_blank">TTL</a>) required for a packet to reach from the client to the host, <code>min_ttl</code>. Any packet where the TTL set is less than <code>min_ttl</code> would expire in transit, and never reach the host. Ideally, the router at which the TTL of the packet expired should respond with an ICMP Time Exceeded (<a href="http://www.networksorcery.com/enp/protocol/icmp/msg11.htm" target="_blank">ICMP message type 11</a>) message. However, this is not guaranteed, and some routers are even configured to not send them (in order to hide the topology of the network).</p>

<p><img src="https://i.imgur.com/aSrR375.png" alt="img">
</p><center>Iterative Network Tracing; we send ClientHello messages with increasing TTL. In this particular case, the minimum TTL required is 9. A middlebox which censors requests would send back a censored response even when the TTL is less than 9. Image credits - <a href="#cite1">Yadav et al.</a></center>

<p>So if the RST received is forged by a middlebox, we should receive it even when we send the ClientHello message with TTL less than <code>min_ttl</code>. This approach, known as Iterative Network Tracing (INT), has been previously used to ascertain the presence of middleboxes which censor DNS and HTTP traffic in India [<a href="#cite1">Yadav et al.</a>] and China <a href="#cite2">Xu et al.</a> Similar to these studies, we use INT to detect censorship of TLS traffic (explained further in the <a href="#secMethod">methodology</a> section).</p>

<hr>  





<p>We run our tests using a list of potentially blocked websites (PBWs), curated from leaked court and government orders. The list and more information pertaining to it can be found <a href="https://github.com/kush789/How-India-Censors-The-Web-Data" target="_blank">here</a>.</p>

<p>Using Google's DNS over HTTPS (DoH) <a href="https://developers.google.com/speed/public-dns/docs/doh" target="_blank">service</a>, each hostname was resolved to its correct IP address. Using DoH here is important as it ensures that no DNS based censorship intervenes with the test. This resulted in roughly 5000 (hostname, ip) pairs. Next we selected a random subset and checked for TCP connectivity to port 443 to each of those ips (since not all would support HTTPS traffic), filtering our list down to 1370 pairs.</p>

<p>For each of these test points, we establish a TCP connection with the resolved_ip, and send a TLS ClientHello with the SNI set as the correct_hostname. We sniff and save these ClientHello packets (just the SSL layer) for use later. Similarly, we save the ClientHello packet with the SNI set as <code>facebook.com</code>. These sniffed packets can be found <a href="https://github.com/kush789/INT-SNI/tree/master/tls_client_hellos" target="_blank">here</a>.</p>

<hr>  





<p>The input to the test is a 2-tuple, (<code>correct_hostname</code>, <code>resolved_ip</code>). We would like to understand the behaviour of a middlebox when it observes a ClientHello message containing an SNI for a website it wishes to block.</p>

<p>First, we calculate the <code>min_ttl</code> for a given test point. We begin by establishing a TCP connection with <code>resolved_ip</code>.</p>

<pre><code>import socket  
import random  
from scapy.all import *

resolved_ip = "103.224.212.222"  
dport = 443 # TLS connection  
sport = random.randint(1024, 65535) # Random source port

def create_connection(resolved_ip):  
    s = socket.socket(socket.AF_PACKET, socket.SOCK_RAW)
    s.bind(("usb0", 0)) # Was using a tethered mobile connection for the experiment

    IP_PACKET = IP(dst = resolved_ip)

    seq = random.randint(12345, 67890) # Randomise initial seq number
    SYN = TCP(sport = sport, dport = dport, flags = "S", seq = seq)
    SYNACK = sr1(IP_PACKET / SYN)
    ACK = TCP(sport = sport, dport = dport, flags = "A", seq = seq + 1, ack = SYNACK.seq + 1)
    send(IP_PACKET / ACK)
    return IP_PACKET, ACK
</code></pre>

<p><strong>Note</strong>: When the linux kernel feature gets a TCP packet to an unknown socket, it sends a RST back to the originator. Since we'll be creating our own raw sockets, we need to suppress these outbound RSTs from the kernel using iptables before running experiments.</p>

<pre><code>sudo iptables -A OUTPUT -p tcp --tcp-flags RST RST -j DROP  
</code></pre>

<p>Once the TCP connection has been established, we send ClientHello messages (containing <code>facebook.com</code> in SNI) after updating the TTL (<code>probe_ttl</code>) in the underlying IP header. We specify <code>facebook.com</code> in the SNI so that the middlebox doesn't attempt to terminate the connection. <code>min_ttl</code> would be the minimum TTL at which we receive a TLS ServerHello or TLS Alert from the host.</p>

<pre><code># Load ClientHello with garbled hostname in SNI (sniffed earlier, read Data Preparation)
max_ttl = 35

def find_min_ttl(resolved_ip)

    with open("tls_client_hellos/facebook.com", 'rb') as fp:
        tls_client_hello_facebook_com_sni = fp.read()

    for probe_ttl in range(1, max_ttl):
        IP_PACKET, ACK = create_connection(resolved_ip)
        IP_PACKET.ttl = probe_ttl
        del IP_PACKET.chksum # Will force scapy to recalculate checksum after TTL update

        resp, _ = sr(IP_PACKET / ACK / tls_client_hello_facebook_com_sni, timeout = 2, retry = 0, multi = True)

        for _, ans_packet in resp:
            tls_alert = ans_packet.get(tls.TLS, {}).get(tls.TLSAlert)
            tls_server_hello = ans_packet.get(tls.TLS, {}).get(tls.TLSHandshakes, {}).get(tls.TLSServerHello)

            if tls_alert or tls_server_hello:
                return probe_ttl # min_ttl found!
</code></pre>

<p>Next, we send ClientHello messages containing the <code>correct_hostname</code> in the SNI with TTL increasing from 1 to <code>min_ttl</code> - 1. If there is no middlebox interfering with the connection, all such requests should receive either an ICMP Time Exceeded in response or no response at all. If at any point we receive an RST packet which seems to be originating from <code>resolved_ip</code>, we can say with certainty that the packet was forged by a middlebox.</p>

<pre><code>min_ttl = find_min_ttl(resolved_ip, tls_client_hello)

with open("tls_client_hellos/fullhd720.com", 'rb') as fp:  
    tls_client_hello_correct_sni = fp.read()

for probe_ttl in range(1, min_ttl):  
    IP_PACKET, ACK = create_connection(resolved_ip)
    IP_PACKET.ttl …</code></pre></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://iamkush.me/sni-airtel/">http://iamkush.me/sni-airtel/</a></em></p>]]>
            </description>
            <link>http://iamkush.me/sni-airtel/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24626388</guid>
            <pubDate>Tue, 29 Sep 2020 11:33:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bitemporality in Crux]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24626358">thread link</a>) | @diggan
<br/>
September 29, 2020 | https://opencrux.com/about/bitemporality.html | <a href="https://web.archive.org/web/*/https://opencrux.com/about/bitemporality.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                    
                
<div>
<h2 id="overview"><a href="#overview"></a>Overview</h2>
<div>
<p>Crux is optimised for efficient and globally consistent point-in-time queries
using a pair of <code>transaction-time</code> and <code>valid-time</code> timestamps.</p>
<p>Ad-hoc systems for bitemporal recordkeeping typically rely on explicitly
tracking either <code>valid-from</code> and <code>valid-to</code> timestamps or range types directly
within relations.  The bitemporal document model that Crux provides is very
simple to reason about and it is universal across the entire database,
therefore it does not require you to consider which historical information is
worth storing in special "bitemporal tables" upfront.</p>
<p>One or more documents may be inserted into Crux via a <code>put</code> transaction at a
specific <code>valid-time</code>, defaulting to the <code>transaction time</code> (i.e. <code>now</code>), and
each document remains valid until explicitly updated with a new version via
<code>put</code> or deleted via <code>delete</code>.</p>
</div>
</div>
<div>
<h2 id="why"><a href="#why"></a>Why?</h2>
<div>
<p>The rationale for bitemporality is also explained in this
<a href="https://juxt.pro/blog/posts/value-of-bitemporality.html">blog post</a>.</p>
<p>A baseline notion of time that is always available is
<code>transaction-time</code>; the point at which data is transacted into the
database.</p>
<p>Bitemporality is the addition of another time-axis: <code>valid-time</code>.</p>
<table id="table-conversion">
<caption>Table 1. Time Axes</caption>
<colgroup>
<col>
<col>
</colgroup>
<thead>
<tr>
<th>Time</th>
<th>Purpose</th>
</tr>
</thead>
<tbody>
<tr>
<td><p><code>transaction-time</code></p></td>
<td><p>Used for audit purposes, technical requirements such as event sourcing.</p></td>
</tr>
<tr>
<td><p><code>valid-time</code></p></td>
<td><p>Used for querying data across time, historical analysis.</p></td>
</tr>
</tbody>
</table>
<p><code>transaction-time</code> represents the point at which data arrives into the
database. This gives us an audit trail and we can see what the state
of the database was at a particular point in time. You cannot write a
new transaction with a <code>transaction-time</code> that is in the past.</p>
<p><strong>valid-time</strong> is an arbitrary time that can originate from an upstream
 system, or by default is set to transaction-time. Valid time is
 what users will typically use for query purposes.</p>

<div>
<table>
<tbody><tr>
<td>
<i title="Note"></i>
</td>
<td>
In Crux, when <code>transaction-time</code> isn’t specified, it is set to
<em>now</em>. When writing data, in case there isn’t any specific valid-time
available, valid-time and transaction-time take the same value.
</td>
</tr>
</tbody></table>
</div>
</div>
</div>
<div>
<h2 id="valid"><a href="#valid"></a>Valid Time</h2>
<div>
<p>In situations where your database is not the ultimate owner of the data—where
corrections to data can flow in from various sources and at various times—use
of <strong>transaction-time</strong> is inappropriate for historical queries.</p>
<p>Imagine you have a financial trading system and you want to perform
calculations based on the official 'end of day', that occurs each day at 17:00
hours. Does all the data arrive into your database at exactly 17:00? Or does
the data arrive from an upstream source where we have to allow for data to
arrive out of order, and where some might always arrive after 17:00?</p>
<p>This can often be the case with high throughput systems where there
are clusters of processing nodes, enriching the data before it gets to
our store.</p>
<p>In this example, we want our queries to include the straggling bits of
data for our calculation purposes, and this is where <strong>valid-time</strong>
comes in. When data arrives into our database, it can come with an
arbitrary time-stamp that we can use for querying purposes.</p>
<p>We can tolerate data arriving out of order, as we’re not completely
dependent on transaction-time.</p>

</div>
</div>
<div>
<h2 id="transaction"><a href="#transaction"></a>Transaction Time</h2>
<div>
<p>For audit reasons, we might wish to know with certainty the value of a
given entity-attribute at a given <code>tx-instant</code>. In this case, we want to
exclude the possibility of the valid past being amended, so we need a
pre-correction view of the data, relying on <code>tx-instant</code>.</p>
<p>To achieve this you can use <code>as-of</code> using <code>ts</code> (<code>valid-time</code>) and <code>tx-ts</code>
(<code>transaction-time</code>).</p>

</div>
</div>
<div>
<h2 id="domain"><a href="#domain"></a>Domain Time</h2>
<div>
<p>Valid time is valuable for tracking a consistent view of the entire state of
the database, however, unless you explicitly include a timestamp or other
temporal component within your documents you cannot currently use this
information about valid time inside of your Datalog queries.</p>
<p>Domain time or "user-defined" time is simply the storing of any additional
time-related information within your documents, for instance <code>valid-time</code>,
<code>duration</code> or timestamps relating to additional temporal life-cycles (e.g.
decision, receipt, notification, availability).</p>
<p>Queries that use domain times do not automatically benefit from any
kind of native indexes to support efficient execution, however Crux
encourages you to build additional layers of functionality to do
so. See <a href="https://github.com/crux-labs/crux-decorators">decorators</a> for
examples.</p>
</div>
</div>
<div>
<h2 id="uses"><a href="#uses"></a>Known Uses</h2>
<div>
<p>Recording bitemporal information with your data is essential when dealing with
lag, corrections, and efficient auditability:</p>
<div>
<ul>
<li>
<p>Lag is found wherever there is risk of non-trivial delay until an event can
  be recorded. This is common between systems that communicate over unreliable
networks.</p>
</li>
<li>
<p>Corrections are needed as errors are uncovered and as facts are reconciled.</p>
</li>
<li>
<p>Ad-hoc auditing is an otherwise intensive and slow process requiring
significant operational complexity.</p>
</li>
</ul>
</div>
<p>With Crux you retain visibility of all historical changes whilst compensating
for lag, making corrections, and performing audit queries. By default, deleting
data only erases visibility of that data from the current perspective. You may
of course still evict data completely as the legal status of information
changes.</p>
<p>These capabilities are known to be useful for:</p>
<div>
<ul>
<li>
<p>Event Sourcing (e.g.
  <a href="https://fr.slideshare.net/ThomasPierrain/as-time-goes-by-episode-2">retroactive
and scheduled events</a> and <a href="https://oparu.uni-ulm.de/xmlui/bitstream/handle/123456789/4150/RetroactiveComputing_Mueller2016.pdf?sequence=5&amp;isAllowed=y">event-driven computing on evolving graphs</a>)</p>
</li>
<li>
<p>Ingesting out-of-order temporal data from upstream timestamping systems</p>
</li>
<li>
<p>Maintaining a slowly changing dimension for decision support applications</p>
</li>
<li>
<p>Recovering from accidental data changes and application errors (e.g. billing
systems)</p>
</li>
<li>
<p>Auditing all data changes and performing data forensics when necessary</p>
</li>
<li>
<p>Responding to new compliance regulations and audit requirements</p>
</li>
<li>
<p>Avoiding the need to set up additional databases for historical data and
improving end-to-end data governance</p>
</li>
<li>
<p>Building historical models that factor in all historical data (e.g. insurance
calculations)</p>
</li>
<li>
<p>Accounting and financial calculations (e.g payroll systems)</p>
</li>
<li>
<p>Development, simulation and testing</p>
</li>
<li>
<p>Live migrations from legacy systems using ad-hoc batches of backfilled
temporal data</p>
</li>
<li>
<p>Scheduling and previewing future states (e.g. publishing and content
management)</p>
</li>
<li>
<p>Reconciling temporal data across eventually consistent systems</p>
</li>
</ul>
</div>
<p>Applied industry-specific examples include:</p>
<div>
<ul>
<li>
<p>Legal Documentation – maintain visibility of all critical dates relating to
  legal documents, including what laws were known to be applicable at the time,
and any subsequent laws that may be relevant and applied retrospectively</p>
</li>
<li>
<p>Insurance Coverage – assess the level of coverage for a beneficiary across
the lifecycle of care and legislation changes</p>
</li>
<li>
<p>Reconstruction of Trades – readily comply with evolving financial regulations</p>
</li>
<li>
<p>Adverse Events in Healthcare – accurately record a patient’s records over
time and mitigate human error</p>
</li>
<li>
<p>Intelligence Gathering – build an accurate model of currently known
information to aid predictions and understanding of motives across time</p>
</li>
<li>
<p>Criminal Investigations – efficiently organise analysis and evidence whilst
enabling a simple retracing of investigative efforts</p>
</li>
</ul>
</div>
</div>
</div>
<div>
<h2 id="examples"><a href="#examples"></a>Example Queries</h2>
<div>
<div>
<h3 id="crime"><a href="#crime"></a>Crime Investigations</h3>
<p>This example is based on an academic paper.</p>

<p>During a criminal investigation it is critical to be able to refine a temporal
understanding of past events as new evidence is brought to light, errors in
documentation are accounted for, and speculation is corroborated. The paper
referenced above gives the following query example:</p>

<p>The paper then lists a sequence of entry and departure events at various United
States border checkpoints. We as the investigator will step through this
sequence to monitor a set of suspects. These events will arrive in an
undetermined chronological order based on how and when each checkpoint is able
to manually relay the information.</p>
<div>
<h4 id="_day_0"><a href="#_day_0"></a>Day 0</h4>
<p>Assuming Day 0 for the investigation period is <code>#inst "2018-12-31"</code>, the
initial documents are ingested using the Day 0 valid time:</p>
<div>
<div>
<pre><code data-lang="clj">  {:crux.db/id :p2
   :entry-pt :SFO
   :arrival-time #inst "2018-12-31"
   :departure-time :na}

  {:crux.db/id :p3
   :entry-pt :LA
   :arrival-time #inst "2018-12-31"
   :departure-time :na}
  #inst "2018-12-31"</code></pre>
</div>
</div>
<p>The first document shows that <code>Person 2</code> was recorded entering via <code>:SFO</code> and
the second document shows that <code>Person 3</code> was recorded entering <code>:LA</code>.</p>
</div>
<div>
<h4 id="_day_1"><a href="#_day_1"></a>Day 1</h4>
<p>No new recorded events arrive on Day 1 (<code>#inst "2019-01-01"</code>), so there are no
documents available to ingest.</p>
</div>
<div>
<h4 id="_day_2"><a href="#_day_2"></a>Day 2</h4>
<p>A single event arrives on Day 2 showing <code>Person 4</code> arriving at <code>:NY</code>:</p>
<div>
<div>
<pre><code data-lang="clj">  {:crux.db/id :p4
   :entry-pt :NY
   :arrival-time #inst "2019-01-02"
   :departure-time :na}
  #inst "2019-01-02"</code></pre>
</div>
</div>
</div>
<div>
<h4 id="_day_3"><a href="#_day_3"></a>Day 3</h4>
<p>Next, we learn on Day 3 that <code>Person 4</code> departed from <code>:NY</code>, which is
represented as an update to the existing document using the Day 3 valid time:</p>
<div>
<div>
<pre><code data-lang="clj">  {:crux.db/id :p4
   :entry-pt :NY
   :arrival-time #inst "2019-01-02"
   :departure-time #inst "2019-01-03"}
  #inst "2019-01-03"</code></pre>
</div>
</div>
</div>
<div>
<h4 id="_day_4"><a href="#_day_4"></a>Day 4</h4>
<p>On Day 4 we begin to receive events relating to the previous days of the
investigation.</p>
<p>First we receive an event showing that <code>Person 1</code> entered <code>:NY</code> on Day 0 which
must ingest using the Day 0 valid time <code>#inst "2018-12-31"</code>:</p>
<div>
<div>
<pre><code data-lang="clj">  {:crux.db/id :p1
   :entry-pt :NY
   :arrival-time #inst "2018-12-31"
   :departure-time :na}
  #inst "2018-12-31"</code></pre>
</div>
</div>
<p>We then receive an event showing that <code>Person 1</code> departed from <code>:NY</code> on Day 3,
so again we ingest this document using the corresponding Day 3 valid time:</p>
<div>
<div>
<pre><code data-lang="clj">  {:crux.db/id :p1
   :entry-pt :NY
   :arrival-time #inst "2018-12-31"
   :departure-time #inst "2019-01-03"}
  #inst "2019-01-03"</code></pre>
</div>
</div>
<p>Finally, we receive two events relating to Day 4, which can be ingested using
the current valid time:</p>
<div>
<div>
<pre><code data-lang="clj">  {:crux.db/id :p1
   :entry-pt :LA
   :arrival-time #inst "2019-01-04"
   :departure-time :na}

  {:crux.db/id :p3
   :entry-pt :LA
   :arrival-time #inst "2018-12-31"
   :departure-time #inst "2019-01-04"}
  #inst "2019-01-04"</code></pre>
</div>
</div>
</div>
<div>
<h4 id="_day_5"><a href="#_day_5"></a>Day 5</h4>
<p>On Day 5 there is an event showing that <code>Person 2</code>, having arrived on Day 0
(which we already knew), departed from <code>:SFO</code> on Day 5.</p>
<div>
<div>
<pre><code data-lang="clj">  {:crux.db/id :p2
   :entry-pt :SFO
   :arrival-time #inst "2018-12-31"
   :departure-time #inst …</code></pre></div></div></div></div></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://opencrux.com/about/bitemporality.html">https://opencrux.com/about/bitemporality.html</a></em></p>]]>
            </description>
            <link>https://opencrux.com/about/bitemporality.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24626358</guid>
            <pubDate>Tue, 29 Sep 2020 11:28:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My little articles about tool I'm creating]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24626272">thread link</a>) | @Puchaczov
<br/>
September 29, 2020 | https://puchaczov.github.io/Musoq/articles/ | <a href="https://web.archive.org/web/*/https://puchaczov.github.io/Musoq/articles/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article>

  

  <div>
    <h3 id="generating-ranged-ip-addresses">Generating ranged IP addresses</h3>

<p>Recently I stumbled upon a necessity to generate IP ranged addresses. 
I was working on allowing developers to use a single self signed certificate across multiple environments we have.
To do so, while generating certificate, there must be a section <code>alt_names</code> that contains IP entries written in such manner</p>

<div><div><pre><code>IP.1 = 10.0.12.13
IP.2 = 10.0.12.14
...
IP.N = 10.0.X.Y
</code></pre></div></div>

<p>It’s necessary to add that asteriks (<code>*</code>) sign is not allowed in certificate so the only option is to propagate the range we have mentioned before.
The problem I had was that I couldn’t assume developers will have assigned static ip in the future so I had to use pregenerated ranges that I would include into certificate.
Based on that I introduce how to generate the range using <code>Musoq</code>.</p>

<p>Let’s look at the query:</p>

<div><div><pre><code>select 
	Replace(
		Replace(
			Replace('IP.{X}=10.0.{A}.{B}', '{A}', ToString(r1.Value)), 
			'{B}', 
			ToString(r2.Value)), 
		'{X}', 
		ToString(RowNumber())) 
	from 
		#system.range(0, 256) r1 inner join 
		#system.range(0, 256) r2 on 1 = 1
</code></pre></div></div>

<p>and the result it generates:</p>

<p><img src="https://puchaczov.github.io/Musoq/assets/images/ip_ranges.png" alt="image"></p>

<p>The way how this query works is pretty easy. We just do the cross join of two ranges and for each pair of <code>r1</code> and <code>r2</code> replace <code>{A}</code> and <code>{B}</code> from text. The last thing is to just replace <code>{X}</code> with the row number.
That way, we are also able to customize our range with <code>where</code> clause. For example we would mark isles that we are focused on <code>... where r1.Value &gt; 10 and r1.Value &lt;= 20 and r2.Value &gt; 40 and r2.Value &lt;= 50</code></p>

<h3 id="analyzing-space-consumption-on-partition-with-windows-and-sql">Analyzing space consumption on partition with Windows and SQL</h3>

<p>Once upon a time in my computer… I faced a problem that appears to all of us from time to time. 
I was rumming in the system settings and I suddenly realized that my primary partition is almost full. 
There were only 30 gigabytes left and I really don’t know where all of my empty space disappeared as I haven’t installed anything big lately. 
To be honest, it’s not that it just disappeared. 
It was long term process that I was just ignoring for a long period of time. 
I’m aware of how Windows loves to consume all space left so I decided to analyze it and figure out what those files are and can I delete them?</p>

<p>This is what we want to achieve:</p>

<p><img src="https://puchaczov.github.io/Musoq/assets/images/executed_query.png" alt="image"></p>

<p>Clear table with listed directories and the space they occupies (including sub directories!). 
As there is a tremendous amount of files in the file system we need something that does quick overview of where to look for lost space.</p>

<p>It’s my personal preference to continuously go deeper into tree only for that directories that have high level of used space. 
This way, I can visit only those directories that have something big inside (or aggregated size of files is big) as I don’t want to waste of time to look over lowly occupied folders. 
Let’s look a query then:</p>

<div><div><pre><code>select 
	::1 as RootDirectory, 
	Round(Sum(Length) / 1024 / 1024 / 1024, 1) 
from #os.files('C:/', true) 
group by RelativeSubPath(1)
</code></pre></div></div>

<p>Looks easy, huh? It is so simple because the query does only few things and you don’t see all the underlying operations that evaluator does for you. <br>
First of all, all files are visited on every nested directory of <code>C</code> with <code>C</code> included. 
We get the starting location from <code>#os.files('C:/', true)</code>. 
The literal value <code>true</code> is passed to instruct query evaluator to visit sub directories.
To be precise I have to say we don’t have to be scared that all the files as it visits, will be loaded into memory. 
Query evaluator will just read the metadata of the file.<br>
By going further, we would like to visit all of the files in partition and on every of that file apply grouping operator. 
In our example, it will work on the result of <code>RelativeSubPath(1)</code>.
If you asked me what this method does I would be obligated to say: it gives a relative sub path of the file that is processed. 
In fact, the whole method <code>string RelativeSubPath ([InjectSource] ExtendedFileInfo, int nesting)</code> is a shorthand for two different methods:</p>

<ul>
  <li><code>string SubPath(string directory, int nesting)</code></li>
  <li><code>string GetRelativePath(ExtendedFileInfo fileInfo, string basePath)</code></li>
</ul>

<p>Result of that method is string that contains the relative path to one of the main directories we started to traverse from so in our case it will be <code>C:/Some</code>. 
Let me explain it on a simple example, if your path is:</p>



<p>and you start from</p>



<p>then your relative path will be <code>Some\Very\Long\Path</code>. 
If your path is the same but you starts from</p>



<p>then your relative path will be <code>Very\Long\Path</code>.</p>

<p>Did you get it? There is still literal argument <code>1</code> passed to this method. 
With these argument, we can limit the depth of the relative path <code>Some\Very\Long\Path</code> by setting it some numeric. 
With argument value <code>1</code> we end up with <code>Some</code>, with <code>2</code> it’s gonna be <code>Some\Very</code>. 
Based on that, we are able to flattening the whole tree to small subset of main directories. 
We can match the file from nested directory with the top directory as if it would belong to him directly. 
Every single file will belong to a single group - group that describes one of main directories.</p>

<h4 id="conclusion">Conclusion</h4>

<p>I hope it will be usefull you. 
In the future I will probably write about something more advanced using Musoq. 
Primarily I will describe my peripeteia with the tool as it is my swiss army knife I use with combination of other tools. 
If you enjoyed the reading and wants to ask something, please contact me through email or just make an issue within the github project.</p>


  </div>

</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://puchaczov.github.io/Musoq/articles/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24626272</guid>
            <pubDate>Tue, 29 Sep 2020 11:11:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[“If you want a task done quickly, ask a busy person to do it.”]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24626209">thread link</a>) | @mcrittenden
<br/>
September 29, 2020 | https://critter.blog/2020/09/29/if-you-want-a-task-done-quickly-ask-a-busy-person-to-do-it/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/09/29/if-you-want-a-task-done-quickly-ask-a-busy-person-to-do-it/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-968">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>That quote has been around <a href="https://quoteinvestigator.com/2018/01/30/busy/">since at least the 1850’s</a>. I heard it a while back and immediately rejected it as nonsense. Then it kept bugging me for another week or two, so I tweeted about it.</p>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><div lang="en" dir="ltr"><p>"If you want something done ask a busy person to do it."</p><p>I don't get this quote. Is the assumption that busy people are productive people?</p></div>— Mike Crittenden (@mcrittenden) <a href="https://twitter.com/mcrittenden/status/1299764398844776450?ref_src=twsrc%5Etfw">August 29, 2020</a></blockquote></div>
</div></figure>



<p>I got exactly 3 responses, and they’re all fascinating:</p>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">At least in non-profit world, some people observe and some people do.  They do-ers volunteer for jobs big and small while others stay silent. That's where busy = productive.</p>— weitzman (@weitzman) <a href="https://twitter.com/weitzman/status/1299804752491012098?ref_src=twsrc%5Etfw">August 29, 2020</a></blockquote></div>
</div></figure>



<p>The assumption here is that busy people are do-ers, and non-busy people are watchers. And you’d trust a do-er with your task more than a watcher, even if the do-er is busier. Seems reasonable to me. </p>



<p>It’s not the busyness itself that makes a person a good choice for your task. It’s that busyness is usually a trait of a do-er. If you could somehow find a do-er who wasn’t busy, that would be ideal. But do-ers by definition tend to be doing stuff.</p>



<hr>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">Presumably this quote is from a bygone era where busy people aren't uselessly shuffling between meetings, messages, and unfinished tasks all day every day</p>— Christiann MacAuley (@xiann) <a href="https://twitter.com/xiann/status/1299766512589377538?ref_src=twsrc%5Etfw">August 29, 2020</a></blockquote></div>
</div></figure>



<p>Ouch. Too real. The quote <em>is</em> from a bygone era, meaning it dates back at least 150 years. So that part is correct. But were people spending their time on more meaningful tasks back then? Did deep work vs. shallow work exist 100+ years ago like it exists today?</p>



<p>They didn’t have Slack, Zoom, email, or even telephones to fill up their days with shallow work. So it seems reasonable that “busy” back then meant something more than it means now. </p>



<p>Then again, they couldn’t use computers or robots to automate the monotonous parts of the job. Maybe “busy” 150+ years ago meant manual number crunching and hand writing and paper folding?</p>



<p>I’m not sure, and my Google searches about this have ended in frustration. Anyone have any insight?</p>



<hr>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><div lang="en" dir="ltr"><p>My take is about the efficiency that comes with constraints on time (which exist because you're busy).</p><p>A task will expand or contract to take up the amount of time available. So because busy people have shorter chunks of free time, they will get a thing done more quickly.</p></div>— Jess Rohloff (@metajess) <a href="https://twitter.com/metajess/status/1308985359070527497?ref_src=twsrc%5Etfw">September 24, 2020</a></blockquote></div>
</div></figure>



<p>I didn’t expect <a href="https://en.wikipedia.org/wiki/Parkinson%27s_law">Parkinson’s law</a> to make an appearance when I tweeted that. But that’s the thing about Parkinson’s law; it likes to sneak in when you don’t expect it. </p>



<p>The more time you have for a task, the longer it takes. If you want something done quickly, give it to someone who doesn’t have much time for it. I love that interpretation.</p>



<hr>



<p>What do you think? Is this quote a relic, or is there still some wisdom to be had here? <a href="https://twitter.com/mcrittenden">Tweet me</a> and let me know!</p>

		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/09/29/if-you-want-a-task-done-quickly-ask-a-busy-person-to-do-it/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24626209</guid>
            <pubDate>Tue, 29 Sep 2020 11:01:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Best Python Blogs to Follow]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24625999">thread link</a>) | @karlhughes
<br/>
September 29, 2020 | https://learn.draft.dev/technical-blogs/python | <a href="https://web.archive.org/web/*/https://learn.draft.dev/technical-blogs/python">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  
<article>
  <div>
    
    <div>
      <p><img src="https://learn.draft.dev/assets/posts/python.png" alt="Background image for The Best Python Blogs"></p>
    </div>
    
    <p>
      By Matthew Warholak&nbsp;&nbsp;&nbsp;—&nbsp;
      14 minute read
    </p>

    
      <p>Python is one of <a href="https://pypl.github.io/PYPL.html">the most popular programming languages</a> in use today, so I went on a journey to find the best Python blogs on the internet. Each of these sites demonstrates technical expertise, is relatively easy to comprehend, publishes content consistently, and has stood the test of time.</p>

<p>During this process, I used the same approach for analyzing and comparing common qualities (or deficiencies) in each blog.</p>

<p>I looked at the depth of each blog’s technical content and the usefulness of that content. I read a few posts from start to finish to get a sense of the writing quality and comprehensibility. I looked at how consistently each blog publishes new content, and I did some digging to learn how long each site has been around.</p>

<p>Here are the top 29 Python blogs I found:</p>

<h3 id="1-effbot">1. <a href="http://effbot.org/">effbot</a></h3>

<p><em><a href="http://effbot.org/zone/rss.xml">RSS</a></em></p>

<p><img src="https://i.imgur.com/FK1a7lG.png" alt="effbot.org blog"></p>

<p>Effbot is a minimalist early 2000s blog that hosts hundreds of articles on Python and related technologies. You’ll be glad you discovered this expansive resource consisting of overviews, tutorials, repositories, and articles covering all proficiency levels and unique user applications. Effbot’s articles offer comprehensive details and cogent explanations of advanced technical problems and strategies. While the content is mostly technical, both summaries and examples alike are clean and organized.</p>

<ul>
  <li>Writing Quality - 4</li>
  <li>Consistency -  3</li>
  <li>Longevity - 4</li>
  <li>Technical Depth -  5</li>
  <li>Broad Usefulness - 4</li>
</ul>

<p><strong>Overall Score: 4.75</strong></p>


      


      
<h3 id="2-rpython">2. <a href="https://www.reddit.com/r/Python/">r/Python</a></h3>

<p><em><a href="https://www.reddit.com/r/Python.rss">RSS</a></em></p>

<p><img src="https://i.imgur.com/SkZRdFD.png" alt="Reddit r/Python"></p>

<p>Reddit is a massive crowd-sourced message board with a ‘subreddit’ specifically dedicated to Python, among other programming languages. “r/Python,” est. 2008, is composed of a large community of members (&gt;500K) with varying degrees of proficiency who share dozens of questions, solutions, and ideas everyday. As is the case with some message boards, there are no sub-categories or <em>sub</em>-subreddits, so all posts are centralized in one location. Writing is often clear and high quality, depending on the writer; however, all posts are subjective and contributed solely by other Reddit users, so readability, clarity, and even language fluency does not always meet expectations.</p>

<ul>
  <li>Writing Quality - 4</li>
  <li>Consistency -  5</li>
  <li>Longevity - 5</li>
  <li>Technical Depth -  5</li>
  <li>Broad Usefulness - 4</li>
</ul>

<p><strong>Overall Score: 4.6</strong></p>

<h3 id="3-real-python">3. <a href="https://realpython.com/">Real Python</a></h3>

<p><em><a href="https://realpython.com/atom.xml">RSS</a>, <a href="https://twitter.com/realpython">Twitter</a></em></p>

<p>Real Python is an educational platform with a large archive of blog posts, tutorials, books, and courses. The content ranges in difficulty level and technical objective. While some of the books and courses are purchase-only, there is an abundance of useful information from 2013 to present made freely available to developers of all backgrounds. Writing is clear, well-researched, aesthetically formatted, and readers can look forward to several new blog posts regularly every month.</p>

<ul>
  <li>Writing Quality - 4</li>
  <li>Consistency -  5</li>
  <li>Longevity - 4</li>
  <li>Technical Depth - 5</li>
  <li>Broad Usefulness - 5</li>
</ul>

<p><strong>Overall Score: 4.6</strong></p>

<h3 id="4-pyimagesearch">4. <a href="https://www.pyimagesearch.com/blog/">PyImageSearch</a></h3>
<p><em><a href="https://www.pyimagesearch.com/feed/">RSS</a></em>, <em><a href="https://twitter.com/pyimagesearch">Twitter</a></em></p>

<p><img src="https://i.imgur.com/IBQugNM.png" alt="PyImageSearch Python blog"></p>

<p>PyImageSearch is a niche community that revolves around development in Computer Vision, Deep Learning, and OpenCV. Live since 2014, you’ll be greeted with weekly blog posts offering expertise from beginner to expert proficiency. The writing is clean, sharp, and informative, with no filler text or useless gifs, but be prepared for ample promotional links.</p>

<ul>
  <li>Writing Quality - 4</li>
  <li>Consistency -  5</li>
  <li>Longevity - 4</li>
  <li>Technical Depth -  5</li>
  <li>Broad Usefulness - 4</li>
</ul>

<p><strong>Overall Score: 4.4</strong></p>

<h3 id="5-matt-layman">5. <a href="https://www.mattlayman.com/">Matt Layman</a></h3>
<p><em><a href="https://www.mattlayman.com/index.xml">RSS</a>, <a href="https://twitter.com/mblayman">Twitter</a></em></p>

<p>Matt Layman is a self-named personal blog, composed of text, audio, and video posts demonstrating useful techniques, strategies, tutorials, and tips. The writing quality is above average, clean, and simple, with few errors and well-organized examples that help the blog’s message without being overly promotional. Impressively active since 2008, followers can expect a few sporadic posts every month.</p>

<ul>
  <li>Writing Quality - 4</li>
  <li>Consistency -  4</li>
  <li>Longevity - 5</li>
  <li>Technical Depth -  5</li>
  <li>Broad Usefulness - 4</li>
</ul>

<p><strong>Overall Score: 4.4</strong></p>

<h3 id="6-python-programming">6. <a href="https://pythonprogramming.net/">Python Programming</a></h3>

<p><em><a href="https://twitter.com/sentdex">Twitter</a></em></p>

<p>Python Programming is a content hub featuring multi-level tutorials in varying difficulty levels across several popular Python use-cases, including Machine Learning, Web Dev, Bots &amp; AI, Finance, and Quantum Computing. The publishing strategy is tutorial-centric, but after you start a tutorial, you’ll find the technical subject to be excellently presented with ample detail and supporting evidence. The writing is not poor, just not great. Some necessary links are present, other times they are not where you’d expect to find them.</p>

<ul>
  <li>Writing Quality - 3</li>
  <li>Consistency -  N/A</li>
  <li>Longevity - N/A</li>
  <li>Technical Depth -  5</li>
  <li>Broad Usefulness - 5</li>
</ul>

<p><strong>Overall Score: 4.3</strong></p>

<h3 id="7-the-mouse-vs-the-python">7. <a href="https://www.blog.pythonlibrary.org/">The Mouse vs. the Python</a></h3>

<p><em><a href="https://www.blog.pythonlibrary.org/feed/">RSS</a>, <a href="https://twitter.com/driscollis">Twitter</a></em></p>

<p><em>Mouse vs. Python</em> is a personal blog that shares content on a variety of topics in both written and video formats. A recurring post type seems to be one-on-one interviews with developers, which may be less useful to current programmers than tutorials and technical breakdowns. That’s not to say the technical depth is not above average, as both formats provide moderate expertise and value. The blog has been around since 2008 and has established itself as a reliable publisher of content, as readers can typically expect 5-15 new posts every month. <em>Mouse vs. Python’s</em> writing is simple and cogent enough to comprehend.</p>

<ul>
  <li>Writing Quality - 3</li>
  <li>Consistency -  5</li>
  <li>Longevity - 5</li>
  <li>Technical Depth -  4</li>
  <li>Broad Usefulness - 4</li>
</ul>

<p><strong>Overall Score: 4.2</strong></p>

<h3 id="8-finxter">8. <a href="https://blog.finxter.com/blog/">Finxter</a></h3>

<p><em><a href="https://blog.finxter.com/feed/">RSS</a>, <a href="https://twitter.com/finxterdotcom?lang=en">Twitter</a></em></p>

<p>Finxter is an educational Python blog that offers everything from newbie guides to intermediate puzzles to in-depth technical guides and challenges. Finxter has featured regular posts every month since 2012. The writing is good, not great, with marginal room for language improvement. Like many technical blogs, Finxter’s content quality is boosted by supportive links and applicable references.</p>

<ul>
  <li>Writing Quality - 4</li>
  <li>Consistency -  4</li>
  <li>Longevity - 5</li>
  <li>Technical Depth - 4</li>
  <li>Broad Usefulness - 4</li>
</ul>

<p><strong>Overall Score: 4.2</strong></p>

<h3 id="9-pyfound">9. <a href="https://pyfound.blogspot.com/">Pyfound</a></h3>

<p><em><a href="https://pyfound.blogspot.com/feeds/posts/default">RSS</a>, <a href="https://twitter.com/ThePSF">Twitter</a></em></p>

<p>PyFound is the Blog arm of the Python Foundation, which has published official development updates, industry conferences, and project timelines since 2011. While the blog is informative and provides useful links, it’s predicated on sharing the organization’s development progress and community events. If you sift through the event and fundraiser updates, you’ll find the technical subject matter is thoroughly researched, and the writing is clear, concise, and with few errors. New posts are sporadic but can be expected between one and five times per month.</p>

<ul>
  <li>Writing Quality - 4</li>
  <li>Consistency -  3</li>
  <li>Longevity - 5</li>
  <li>Technical Depth -  5</li>
  <li>Broad Usefulness - 3</li>
</ul>

<p><strong>Overall Score: 4.0</strong></p>

<h3 id="10-full-stack-python">10. <a href="https://www.fullstackpython.com/blog.html">Full Stack Python</a></h3>

<p><em><a href="https://www.fullstackpython.com/feed">RSS</a>, <a href="https://twitter.com/fullstackpython">Twitter</a></em></p>

<p><img src="https://i.imgur.com/U00VrJJ.png" alt="Full Stack Python blog"></p>

<p>Full Stack Python is a personally-managed blog for Python developers and devs to-be. Active since 2012, posts are a combination of original content and automatically aggregated posts from other publications. The articles are predominantly technical findings, explanations, tutorials, and the like. The blog’s content is in-depth, shows a range of technical expertise, and maintains a clear and concise voice with no major red flags. Unfortunately, new content is published unpredictably and in seemingly random batches.</p>

<ul>
  <li>Writing Quality - 4</li>
  <li>Consistency -  2</li>
  <li>Longevity - 4</li>
  <li>Technical Depth -  5</li>
  <li>Broad Usefulness - 5</li>
</ul>

<p><strong>Overall Score: 4.0</strong></p>

<h3 id="11-ned-batchelder">11. <a href="https://nedbatchelder.com/blog/tag/python.html">Ned Batchelder</a></h3>

<p><em><a href="https://nedbatchelder.com/blog/rss.xml">RSS</a>, <a href="https://twitter.com/nedbat">Twitter</a></em></p>

<p>Ned Batchelder is the personal blog of veteran Python developer Ned Batchelder, which is one of the original and oldest active Python blogs from the early 2000s. There’s plenty of content dating back nearly 20 years; some topics being detailed breakdowns, others simple one paragraph tips. Ned keeps his content simple with no frills. Blog posts are clear enough to get the point across while sacrificing some elegance. The only improvement I can recommend would be more frequent posts; you’d be lucky to get one per month. Fortunately, there’s a huge backlog of posts to study up on, and it comes directly from the mind of a programmer who’s experimented with and written Python longer than most.</p>

<ul>
  <li>Writing Quality - 3</li>
  <li>Consistency -  3</li>
  <li>Longevity - 5</li>
  <li>Technical Depth -  5</li>
  <li>Broad Usefulness - 4</li>
</ul>

<p><strong>Overall Score: 4.0</strong></p>

<h3 id="12-practical-business-python">12. <a href="https://pbpython.com/">Practical Business Python</a></h3>

<p><em><a href="https://pbpython.com/feeds/all.atom.xml">RSS</a>, <a href="https://twitter.com/chris1610">Twitter</a></em></p>

<p>Practical Business Python is a Python blog boasting a variety of applicable technical subjects, primarily around Python business use cases and operability versus podcasts or interviews. Articles demonstrate strong technical knowledge supported with pertinent screenshots. Most posts are more functional than fluid, but not without references or properly supportive links. Followers can expect 1-2 posts sporadically per month but should be entertained while they wait by perusing the trove of articles going back to 2014.</p>

<ul>
  <li>Writing Quality - 4</li>
  <li>Consistency -  3</li>
  <li>Longevity - 4</li>
  <li>Technical Depth -  5</li>
  <li>Broad Usefulness - 4</li>
</ul>

<p><strong>Overall Score: 4.0</strong></p>

<h3 id="13-python-tips--yasoobme">13. <a href="https://yasoob.me/">Python Tips / Yasoob.me</a></h3>

<p><em><a href="https://yasoob.me/index.xml">RSS</a>, <a href="https://twitter.com/yasoobkhalid">Twitter</a></em></p>

<p>Python Tips is a personal blog that explores technical applications and nuances of Python. You’ll find a large collection of articles, guides, explanations, and deep-dives, sure to be useful for most Python programmers. Yasoob, the blog’s sole writer since 2013, showcases a strong technical grasp of the whats, wheres, whens, whys, and hows to walk the reader through complex concepts with clarity and detail. Its usefulness is hamstrung by periods of sporadic posting, followed by 2-3 months of silence. Like many technical blogs, the articles are informative and packed with data and supporting links, but also reads like many technical blogs: substance over aesthetics.</p>

<ul>
  <li>Writing Quality - 3</li>
  <li>Consistency -  3</li>
  <li>Longevity - 4</li>
  <li>Technical Depth -  5</li>
  <li>Broad Usefulness - 5</li>
</ul>

<p><strong>Overall Score: 4.0</strong></p>

<h3 id="14-invent-with-python">14. <a href="http://inventwithpython.com/">Invent with Python</a></h3>

<p><em><a href="https://twitter.com/AlSweigart">Twitter</a></em></p>

<p>Invent with Python is an educational programming blog by Al Sweigart, a Python veteran, and teacher. The blog is predicated on providing free tools, guides, courses, and tutorials to help beginners learning to code. You’ll find technical …</p></div></article></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://learn.draft.dev/technical-blogs/python">https://learn.draft.dev/technical-blogs/python</a></em></p>]]>
            </description>
            <link>https://learn.draft.dev/technical-blogs/python</link>
            <guid isPermaLink="false">hacker-news-small-sites-24625999</guid>
            <pubDate>Tue, 29 Sep 2020 10:34:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Forgetting as a Form of Feedback]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24625674">thread link</a>) | @olalola
<br/>
September 29, 2020 | https://universeofmemory.com/forgetting-as-a-form-of-feedback/ | <a href="https://web.archive.org/web/*/https://universeofmemory.com/forgetting-as-a-form-of-feedback/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="tve_flt"><div id="tve_editor" data-post-id="13036"><div><p>Forgetting is as integral to our lives as it is disliked. It takes many forms - from the nastiest ones, i.e. neurodegenerative diseases (e.g. Alzheimer's), to relatively innocent ones (why am I standing in front of the open refrigerator again?!)</p><p>No wonder <strong>we treat this phenomenon as our worst enemy</strong>. After all, it robs you of the fruits of your work. You have put so much work into acquiring a given skill, and after a couple of months not much is left in your head. As depressing as it all might seem, I would like to show you a different perspective.</p><p><strong>What if forgetting is not your opponent but your ally?</strong></p><p>Your brain is actively working to make you forget most of the things you've come into contact with. It is the most sophisticated spam filter in the world. This process allows you to focus on the most important information. In other words,</p></div><div><div><p data-css="tve-u-174c11f34ce"><strong>forgetting is one of the best forms of feedback.</strong></p></div></div><p>It took me many years to understand this simple truth. It was also a turning point for me, which completely changed the memory systems I created at that time. Since, as far as I know, this concept is not widely discussed, I hope this article will be a sort of "memory awakening" for you.</p><div><h2>What Is the Purpose of Memory?</h2><p>Many people believe that the purpose of memory is to store information as accurately as possible. I think this is an erroneous perspective.</p></div><div><div><p><strong>Memory serves to guide and optimize decision-making by sticking only to meaningful and valuable information.</strong></p></div></div><p>I could describe a lot of memory processes that take place during the stage of encoding or information retrieval. Still, I think it's better to focus on a very logical and practical example.</p><div><h3>Optimization of decision-making processes as exemplified by crossing the street</h3><p>Think for a moment how much information you need to safely walk from one side of the street to the other.</p><h5>While performing this activity, do you analyze:</h5></div><div data-icon-code="icon-check" data-css="tve-u-174c1228afc"><ul><li><span data-css="tve-u-174c1228aff">Wind speed?</span></li><li><span data-css="tve-u-174c1228b01">Type of surface?</span></li><li><span data-css="tve-u-174c1228b03">The number of people in front of you?</span></li><li><span data-css="tve-u-174c1228b05">The number of people on your sides?</span></li><li><span data-css="tve-u-174c1228b08">The distance you have to travel?</span></li><li><span data-css="tve-u-174c1228b0a">Air humidity?</span></li><li><span data-css="tve-u-174c1228b0c">Surface moisture?</span></li></ul></div><p>Of course not.</p><div><div><p data-css="tve-u-174c6a21c61"><strong>Too much irrelevant information is detrimental to a given decision-making process.</strong></p></div></div><div><p>If you really had to take into account all this information, it would take you forever to make any decision at all. In other words, the process would not be optimal, also energy-wise.</p><h5>Thus, it is much easier to focus on activities such as:</h5></div><div data-icon-code="icon-check" data-css="tve-u-174c1238c0a"><ul><li><span data-css="tve-u-174c1238c0c">checking if there are traffic lights at the crosswalk,</span></li><li><span data-css="tve-u-174c1238c0f">making sure the light is green,</span></li><li><span data-css="tve-u-174c1238c11">looking to your left and right (and left again).</span></li></ul></div><div><p>As you can see, <strong>a handful of relevant information can be more valuable to the brain than a ton of meaningless data</strong>. However, we shouldn't forget that it doesn't make sense to remember much—quite the contrary. The trick is to <a href="http://universeofmemory.com/biggest-problem-in-learning-effectively/" target="_blank" spellcheck="false" data-css="tve-u-174c6a391b8">combine the memorized information into meaningful scripts</a> that can be activated in a given situation.</p><p>In the example above, a type of surface is almost certainly a useless piece of information. Nevertheless, if our decision-making process required making sure that we can do a dangerous stunt on the said surface, it would be one of the first factors that should be taken into consideration.</p></div><div><h2>What Kind of Information Is Meaningful To Your Brain?</h2></div><p><span><a href="https://universeofmemory.com/wp-content/uploads/2020/09/juan-rumimpunu-nLXOatvTaLo-unsplash.jpg" target="_blank"><img alt="Forgetting" data-id="13043" width="642" data-init-width="1920" height="428" data-init-height="1280" title="Forgetting" loading="lazy" src="https://universeofmemory.com/wp-content/uploads/2020/09/juan-rumimpunu-nLXOatvTaLo-unsplash.jpg" data-width="642" data-height="428" data-link-wrap="true" data-css="tve-u-174c152fca7" srcset="https://universeofmemory.com/wp-content/uploads/2020/09/juan-rumimpunu-nLXOatvTaLo-unsplash.jpg 1920w, https://universeofmemory.com/wp-content/uploads/2020/09/juan-rumimpunu-nLXOatvTaLo-unsplash-300x200.jpg 300w, https://universeofmemory.com/wp-content/uploads/2020/09/juan-rumimpunu-nLXOatvTaLo-unsplash-1024x683.jpg 1024w, https://universeofmemory.com/wp-content/uploads/2020/09/juan-rumimpunu-nLXOatvTaLo-unsplash-768x512.jpg 768w, https://universeofmemory.com/wp-content/uploads/2020/09/juan-rumimpunu-nLXOatvTaLo-unsplash-600x400.jpg 600w, https://universeofmemory.com/wp-content/uploads/2020/09/juan-rumimpunu-nLXOatvTaLo-unsplash-1536x1024.jpg 1536w, https://universeofmemory.com/wp-content/uploads/2020/09/juan-rumimpunu-nLXOatvTaLo-unsplash-1320x880.jpg 1320w, https://universeofmemory.com/wp-content/uploads/2020/09/juan-rumimpunu-nLXOatvTaLo-unsplash-272x182.jpg 272w" sizes="(max-width: 642px) 100vw, 642px" data-lazy-srcset="https://universeofmemory.com/wp-content/uploads/2020/09/juan-rumimpunu-nLXOatvTaLo-unsplash.jpg 1920w, https://universeofmemory.com/wp-content/uploads/2020/09/juan-rumimpunu-nLXOatvTaLo-unsplash-300x200.jpg 300w, https://universeofmemory.com/wp-content/uploads/2020/09/juan-rumimpunu-nLXOatvTaLo-unsplash-1024x683.jpg 1024w, https://universeofmemory.com/wp-content/uploads/2020/09/juan-rumimpunu-nLXOatvTaLo-unsplash-768x512.jpg 768w, https://universeofmemory.com/wp-content/uploads/2020/09/juan-rumimpunu-nLXOatvTaLo-unsplash-600x400.jpg 600w, https://universeofmemory.com/wp-content/uploads/2020/09/juan-rumimpunu-nLXOatvTaLo-unsplash-1536x1024.jpg 1536w, https://universeofmemory.com/wp-content/uploads/2020/09/juan-rumimpunu-nLXOatvTaLo-unsplash-1320x880.jpg 1320w, https://universeofmemory.com/wp-content/uploads/2020/09/juan-rumimpunu-nLXOatvTaLo-unsplash-272x182.jpg 272w" data-lazy-src="https://universeofmemory.com/wp-content/uploads/2020/09/juan-rumimpunu-nLXOatvTaLo-unsplash.jpg?is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></span></p><div><p>Another question we have to answer is what information the brain perceives as valuable, and what information is the equivalent of food scraps at the bottom of the dishwasher.</p><h5>In simple terms, information must meet two main criteria to be considered valuable:</h5></div><div data-icon-code="icon-check" data-css="tve-u-174c12130a6"><ul><li data-css="tve-u-174c6a41120"><span data-css="tve-u-174c120bb0a">frequently appear in your immediate environment,</span></li><li data-css="tve-u-174c6a41120"><span data-css="tve-u-174c120bb0a">it must be related to your life, i.e. be relevant to you.</span></li></ul></div><p>I will discuss them in more detail later in this article. At the moment, it is worth looking at how slowly we forget information when the above two criteria are met.</p><div><h2>Almost Complete Elimination of Forgetting</h2></div><div><h3>Problems with research on memory</h3><p>One of the big problems that plague most of the memory studies is that<strong> they are often detached from reality</strong>. The overwhelming majority of them are carried out in laboratories. I know what you are thinking. Why would that be a disadvantage?</p><p>Laboratories are artificial creations which, according to the rules of the scientific method, try to limit the number of variables that affect the tested value as much as possible. It sounds nice until we realize that <strong>our memory does not work in a vacuum</strong>. <strong>Hundreds of stimuli and information constantly flood our minds</strong><strong>.</strong> One should not try to artificially separate them from the process of memorizing and retrieving data.</p><p>The effect is that most such studies come to conclusions that are as out of touch with reality as a team of Marvel superheroes from a nearby asylum.</p><p>What's even worse is that there are quite a few people who accept this nonsense uncritically. I often hear some strange websites or YT channels saying that "in this or that study, scientists proved (sic!) that if you imagine that you have an orange on the top of your head, your ability to remember and concentrate will increase by 15%".</p><p>I wish it were an anecdote, but the video had over 100k views and lots of positive comments at the time. In my mind's eye, I could almost see 20,000 people sitting with their eyes rolled over and the face of a constipated walrus wondering why memorizing books didn't get any easier.</p></div><div><h3>Forgetting names - Bahrick's and Wittlinger's research</h3><p>Bahrick is one of my favorite memory researchers. He was one of the first scientists to insist that research of this kind be carried out outside the laboratory, despite the difficulties it poses.</p><p>One of his groundbreaking works, which he did in 1975 with Wittlinger, is about remembering the names and faces of high school friends over many years. The study lasted 50 years (!!!), and it showed for many years<strong>&nbsp;after graduating from high school, the process of forgetting this information occurred only slightly.&nbsp;</strong>Although, as always, the active recall was the first to go.</p></div><p><span><a href="https://universeofmemory.com/wp-content/uploads/2020/09/Bahrick-Names-Forgetting.png" target="_blank"><img alt="" data-id="13052" width="505" data-init-width="505" height="473" data-init-height="473" title="Bahrick - Names Forgetting" loading="lazy" src="https://universeofmemory.com/wp-content/uploads/2020/09/Bahrick-Names-Forgetting.png" data-width="505" data-height="473" data-link-wrap="true" srcset="https://universeofmemory.com/wp-content/uploads/2020/09/Bahrick-Names-Forgetting.png 505w, https://universeofmemory.com/wp-content/uploads/2020/09/Bahrick-Names-Forgetting-300x281.png 300w" sizes="(max-width: 505px) 100vw, 505px" data-lazy-srcset="https://universeofmemory.com/wp-content/uploads/2020/09/Bahrick-Names-Forgetting.png 505w, https://universeofmemory.com/wp-content/uploads/2020/09/Bahrick-Names-Forgetting-300x281.png 300w" data-lazy-src="https://universeofmemory.com/wp-content/uploads/2020/09/Bahrick-Names-Forgetting.png?is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></span></p><div><p>You can conduct this experiment virtually. Assuming a minimum of 10 years has passed since you have graduated from high school, check if you can still remember everyone in your class? I know I certainly didn't have almost any problems with it.</p></div><div><h3>How to explain the almost complete absence of forgetting over a long period?</h3><p>In one of my past articles,&nbsp;<a data-saferedirecturl="https://www.google.com/url?q=https://universeofmemory.com/optimize-your-repetitions/&amp;source=gmail&amp;ust=1601053411857000&amp;usg=AFQjCNGEsWrkDpiWu5XTxXC7R1uMEXDm_Q" href="https://universeofmemory.com/optimize-your-repetitions/" target="_blank" spellcheck="false" data-css="tve-u-174c125ee3c">I mentioned the Ebbinghaus curve</a>:</p></div><p><span><a href="https://universeofmemory.com/wp-content/uploads/2020/09/Forgettingcurve-767x434-1.jpg" target="_blank"><img alt="the Ebbinghaus curve - Forgetting as a Form of Feedback" data-id="13040" width="767" data-init-width="767" height="434" data-init-height="434" title="the Ebbinghaus curve - Forgetting as a Form of Feedback" loading="lazy" src="https://universeofmemory.com/wp-content/uploads/2020/09/Forgettingcurve-767x434-1.jpg" data-width="767" data-height="434" data-link-wrap="true" srcset="https://universeofmemory.com/wp-content/uploads/2020/09/Forgettingcurve-767x434-1.jpg 767w, https://universeofmemory.com/wp-content/uploads/2020/09/Forgettingcurve-767x434-1-300x170.jpg 300w, https://universeofmemory.com/wp-content/uploads/2020/09/Forgettingcurve-767x434-1-600x340.jpg 600w" sizes="(max-width: 767px) 100vw, 767px" data-lazy-srcset="https://universeofmemory.com/wp-content/uploads/2020/09/Forgettingcurve-767x434-1.jpg 767w, https://universeofmemory.com/wp-content/uploads/2020/09/Forgettingcurve-767x434-1-300x170.jpg 300w, https://universeofmemory.com/wp-content/uploads/2020/09/Forgettingcurve-767x434-1-600x340.jpg 600w" data-lazy-src="https://universeofmemory.com/wp-content/uploads/2020/09/Forgettingcurve-767x434-1.jpg?is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></span></p><div><p>Notice how huge the difference in retention (i.e., keeping the information in your head) is between Bahrick's and Ebbinghaus's experiment. Even after 7 years, the retention of names was higher than the retention of meaningless knowledge presented by the Ebbinghaus curve after 20 minutes.</p><p>The explanation for this phenomenon is based on many elements.&nbsp;</p></div><div><h4>1. High frequency of repetitions</h4><p>Note that the contact with first and last names in high school is extremely common, be it during the roll call or the regular socialization with your peers. What's more, almost all children are forced continuously to retrieve this knowledge. It would be difficult to get through high school only by yelling, "Hey you!"</p></div><div><h4>2. Relevance of the information</h4><p>Ebbinghaus tested the information decay by memorizing nonsense letter clusters. Bahrick, on the other hand, demonstrated how we absorb vital information in the real world.</p><p>It is worth mentioning that the relevance of information automatically means one more thing -<strong> emotional load</strong>. It doesn't matter if it's positive or negative. <strong>It is an inherent factor modulating your ability to remember.</strong></p><p>The meaningfulness of the information is a very personal and individual thing. Two different people may perceive the same facts as useless or vital. It is reflected in another one of Bahrick's (1984) studies, that showed that college professors have difficulties with remembering their students' name.</p><p>Can you see that contrast? Of course, one might argue that the frequency of information, in this case, is much lower. However, in my opinion, the decisive factor here is the indifference of lecturers. Most students are as important to them as half-dried pigeon carrion on the side of the road.</p><p>Of course, we could name more factors that contributed to the almost complete absence of forgetting in the first study. However, I think that the ones mentioned above are the most important.</p></div><div><h2>Forgetting as a Form of Feedback, I.e. What Information Does It Provide You With?</h2><p>The example above does not seem to be fully related to subjects such as physics, foreign languages or medicine. Regardless, I hope it convinced you of one thing - <strong>the frequency and relevance of information are among the most critical factors affecting your ability to remember information.</strong></p><p>Thus, from now on, I would like you to change your mind about the phenomenon of forgetting. Don't see it as something negative.</p></div><div><div><p>Treat forgetting as the best possible form of feedback.</p></div></div><div><p>If you can't keep information in your head, your brain is trying to subtly say, "Hey buddy! Don't even try to make me remember this string of numbers. I don't know; I don't understand, I don't care. When are we going to do something exciting like tap dancing in banana peel shoes?&nbsp;</p><p>Whenever you cannot recall information, you should ask yourself, "How can I modify it so that it makes more sense to my brain?"</p></div><div><h2>Forgetting as a Form of Feedback - Three Main Takeaways</h2></div><div><h3>1. Too little interaction with the information</h3><p>Consider whether you should <strong>increase the frequency of a given element</strong>. If you use programs like <a href="https://apps.ankiweb.net/" target="_blank"><strong>ANKI</strong></a>, it happens organically to some degree.</p></div><div><h3>2. No connection between the element and your background knowledge</h3></div><p><span><a href="https://universeofmemory.com/wp-content/uploads/2020/09/fabio-bracht-_z0DiiaIhB4-unsplash-1-scaled.jpg" target="_blank"><img alt="Forgetting as a Form of Feedback" data-id="13044" width="700" data-init-width="1602" height="1119" data-init-height="2560" title="Forgetting as a Form of Feedback" loading="lazy" src="https://universeofmemory.com/wp-content/uploads/2020/09/fabio-bracht-_z0DiiaIhB4-unsplash-1-scaled.jpg" data-width="700" data-height="1119" data-link-wrap="true" data-css="tve-u-174c158a579" srcset="https://universeofmemory.com/wp-content/uploads/2020/09/fabio-bracht-_z0DiiaIhB4-unsplash-1-scaled.jpg 1602w, https://universeofmemory.com/wp-content/uploads/2020/09/fabio-bracht-_z0DiiaIhB4-unsplash-1-188x300.jpg 188w, https://universeofmemory.com/wp-content/uploads/2020/09/fabio-bracht-_z0DiiaIhB4-unsplash-1-641x1024.jpg 641w, https://universeofmemory.com/wp-content/uploads/2020/09/fabio-bracht-_z0DiiaIhB4-unsplash-1-768x1227.jpg 768w, https://universeofmemory.com/wp-content/uploads/2020/09/fabio-bracht-_z0DiiaIhB4-unsplash-1-600x959.jpg 600w, https://universeofmemory.com/wp-content/uploads/2020/09/fabio-bracht-_z0DiiaIhB4-unsplash-1-961x1536.jpg 961w, https://universeofmemory.com/wp-content/uploads/2020/09/fabio-bracht-_z0DiiaIhB4-unsplash-1-1282x2048.jpg 1282w, https://universeofmemory.com/wp-content/uploads/2020/09/fabio-bracht-_z0DiiaIhB4-unsplash-1-1320x2109.jpg 1320w" sizes="(max-width: 700px) 100vw, 700px" data-lazy-srcset="https://universeofmemory.com/wp-content/uploads/2020/09/fabio-bracht-_z0DiiaIhB4-unsplash-1-scaled.jpg 1602w, https://universeofmemory.com/wp-content/uploads/2020/09/fabio-bracht-_z0DiiaIhB4-unsplash-1-188x300.jpg 188w, https://universeofmemory.com/wp-content/uploads/2020/09/fabio-bracht-_z0DiiaIhB4-unsplash-1-641x1024.jpg 641w, https://universeofmemory.com/wp-content/uploads/2020/09/fabio-bracht-_z0DiiaIhB4-unsplash-1-768x1227.jpg 768w, https://universeofmemory.com/wp-content/uploads/2020/09/fabio-bracht-_z0DiiaIhB4-unsplash-1-600x959.jpg 600w, https://universeofmemory.com/wp-content/uploads/2020/09/fabio-bracht-_z0DiiaIhB4-unsplash-1-961x1536.jpg 961w, https://universeofmemory.com/wp-content/uploads/2020/09/fabio-bracht-_z0DiiaIhB4-unsplash-1-1282x2048.jpg 1282w, https://universeofmemory.com/wp-content/uploads/2020/09/fabio-bracht-_z0DiiaIhB4-unsplash-1-1320x2109.jpg 1320w" data-lazy-src="https://universeofmemory.com/wp-content/uploads/2020/09/fabio-bracht-_z0DiiaIhB4-unsplash-1-scaled.jpg?is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></span></p><div><p>Your brain is a very practical sponge. If it finds no connection between an item and the rest of the information you have in mind, it considers that item to be irrelevant. Thus, this information is forgotten very quickly (see&nbsp;<a data-saferedirecturl="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Forgetting_curve&amp;source=gmail&amp;ust=1601053411857000&amp;usg=AFQjCNHwsdgc6CGBmdmZXERAk99urdfR5A" href="https://en.wikipedia.org/wiki/Forgetting_curve" target="_blank" spellcheck="false" data-css="tve-u-174c134a01a">Ebbinghaus forgetting curve</a>).</p><p><strong>If you want to remember a given piece of information, there is nothing to prevent more than one flashcard from encoding a given word or concept.</strong></p></div><div><h3>3. Lack of the relevance of the information</h3><p>The relevance of information always means one thing - emotional load. It is the basis of the so-called&nbsp;<a data-saferedirecturl="https://www.google.com/url?q=https://link.springer.com/chapter/10.1007/978-3-319-67615-9_1%23:~:text%3DAlthough%252520the%252520issues%252520around%252520emotions%252Cdriven%252520or%252520at%252520least%252520enhanced.&amp;source=gmail&amp;ust=1601053411857000&amp;usg=AFQjCNHjnV_mlGqfTGocZFiAHMhdHOqj9A" href="https://link.springer.com/chapter/10.1007/978-3-319-67615-9_1#:~:text=Although%2520the%2520issues%2520around%2520emotions%2Cdriven%2520or%2520at%2520least%2520enhanced." target="_blank" spellcheck="false" data-css="tve-u-174c134c638">affective learning</a> that is <strong>related to feelings and emotions</strong>.</p><p>If you …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://universeofmemory.com/forgetting-as-a-form-of-feedback/">https://universeofmemory.com/forgetting-as-a-form-of-feedback/</a></em></p>]]>
            </description>
            <link>https://universeofmemory.com/forgetting-as-a-form-of-feedback/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24625674</guid>
            <pubDate>Tue, 29 Sep 2020 09:45:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Encrypted CRDTs for building privacy focused collaborative software]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24625563">thread link</a>) | @kn8
<br/>
September 29, 2020 | https://www.kn8.lt/blog/building-privacy-focused-collaborative-software/ | <a href="https://web.archive.org/web/*/https://www.kn8.lt/blog/building-privacy-focused-collaborative-software/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="reach-skip-nav"><div><p>I want to be able to build privacy focused applications that are as powerful and as user friendly as the “traditional” web apps we’re so used to today.</p>
<p><strong>Privacy focused</strong> means the application developers never get to see the content their users are creating - your data is yours only. <strong>Powerful</strong> means real-time collaboration between multiple users, search, notifications. <strong>User friendly</strong> means it’s easy to access or recover your data on a new device and easy to invite collaborators.</p>
<p>And that’s really hard today. Really really hard.</p>
<h2>Why do it?</h2>
<p>Why should we even care about building privacy focused applications? Why does privacy matter? Privacy might sometimes feel like a philosophical topic, but it’s one with very real life altering and threatening implications (including <a href="https://time.com/5290043/nazi-history-eu-data-privacy-gdpr/" target="_blank" rel="noopener">the Holocaust</a>). I won’t be tackling this question in more depth here and if you want to learn more about the importance of privacy I recommend reading <a href="https://www.amazon.co.uk/Identity-Reboot-Reimagining-Privacy-Century/dp/1916314414" target="_blank" rel="noopener">Identity Reboot: Reimagining Data Privacy for the 21st Century</a> by Arwen Smit.</p>
<p>“Privacy focused” can mean many things and is a really broad topic. This article looks specifically at collaborative content creation tools such as Google Docs and Slack - tools that individuals, teams and communities use to create private digital content. End-to-end encryption or removal of centralised servers could offer a technical solution to enhanced privacy in such applications. Public digital content creation like Wikipedia and Twitter, ambient content collection such as Amazon Alexa and Tesla car recordings and many other digital privacy issues are not considered in this article.</p>
<h2>Misaligned incentives</h2>
<p>Building collaborative content creation applications such as Google Docs, Asana or Slack, but in a way where all the content is end-to-end encrypted and only accessible to the content creators is technically very difficult. We will look at some of the technical challenges in more depth in the remainder of the article, but here are a few:</p>
<ul>
<li>added UX challenges of handling encryption keys</li>
<li>handling real-time collaborations on encrypted data</li>
<li>search over encrypted data is difficult to impossible</li>
<li>debugging, optimizing and supporting customers all become more difficult</li>
</ul>
<p>Technical overhead alone removes a lot of the incentive for any company to even try. What’s more, having access to the raw data provides companies with extra value. Data can be used to power features (e.g. Gmail’s smart compose) and data is what created today’s most profitable businesses by fuelling Ad targeting.</p>
<p>There’s also the fact that end-to-end encryption is not applicable to every type of application. E.g. building a web search engine, wikipedia or a social network does not require all of the content to be encrypted end-to-end. The fact that this problem is not universal further reduces the incentive to tackle it.</p>
<p>And so we have a chicken and egg problem, where lack of incentives means progress on technological solutions is slow, mostly being pushed forward by decentralisation hackers and academic researchers, while many of the world’s engineers are being paid to do the opposite - extracting more value from the data.</p>
<p>To make matters worse, end-to-end encryption tech could become more and more government regulated at any point. Perhaps anecdotal, but COVID-19 created an incentive to build a <a href="https://twitter.com/romy/status/1303852660320215042" target="_blank" rel="noopener">privacy focused exposure notification system</a> (great!), but it’s also up to the governments to opt into it, and <a href="https://twitter.com/babynewt_/status/1304052101883064320" target="_blank" rel="noopener">not all of them are doing so</a>.</p>
<h2>Encryption trade offs</h2>
<p>To be clear, I’m not saying that encrypting all of the content is necessarily the best thing to do. Amassing data centrally can be of value not just to the companies, but to the users and society at large. While it might be possible to power a lot of innovative technology in a privacy focused manner, such as utilising on-device machine learning, it’s probably more efficient to develop say self driving cars if you can collect real video data from as many cars as possible.</p>
<p>And even if you’re not extracting value from data, storing unencrypted data is simpler and more efficient. It’s also more convenient for the users as the data is always backed up and easy to access from any device.</p>
<p>All that, coupled with the technical difficulty of creating end-to-end encrypted applications, it might well be the case that we will always have to lean on privacy policies, government regulations and put trust in companies when it comes to protecting our data.</p>
<h2>Privacy focused software landscape</h2>
<p>Nevertheless, high quality tools that are built in a privacy focused manner do exist. Perhaps most impressively - WhatsApp with its mass deployment of end-to-end encryption tech (Facebook ownership aside), as well as similar messaging apps, Signal and Wire. Then there’s ProtonMail providing the end-to-end encrypted email service. And 1Password, a cloud backed encrypted password manager.</p>
<p>Another, less known tool built on cutting edge tech is <a href="https://scuttlebutt.nz/" target="_blank" rel="noopener">Scuttlebutt</a> a fully decentralised (and fully functional) p2p social network. Scuttlebutt, which is similar to Twitter, does not utilise end-to-end encryption (for the social networking functionality), but it’s built in a way that means it works entirely without any servers (!). It’s completely p2p and it’s impressive that they made it work so well. BitTorrents are p2p and they work too, but that’s static file sharing, where Scuttlebutt is a living, breathing, dynamic social network with messages getting posted and propagated to the relevant peers all the time. I bring up Scuttlebutt, because as we see later it can inform the architecture of building privacy focused collaborative software.</p>
<p><em>Tangent: Speaking of privacy, election meddling and Scuttlebutt… Scuttlebutt can be viewed as an alternative to Facebook’s centralised approach. Facebook’s data is behind a login and access is monitored and limited (not always true as we’ve seen with the Cambridge Analytica). While Scuttlebutt’s data is completely open for anyone to mine, archive and analyse. But Scuttlebutt doesn’t have profit motives or server costs and so does not need to create targeted Ad tools or even algorithmic feeds that were used in election meddling. Which approach is better?</em></p>
<p>Finally, <a href="https://bear.app/" target="_blank" rel="noopener">Bear</a> or <a href="https://culturedcode.com/things/" target="_blank" rel="noopener">Things</a> take a different privacy focused approach. Even though these apps do not encrypt the data, they store it in your private iCloud account, which means the app developers never get to see it. However, these apps do not offer collaboration. They are meant for single user only (with the exception of having to sync data across all of your devices, which they don’t always handle gracefully).</p>
<h2>Building a Google Docs alternative</h2>
<p>Is it possible then to build a multi user, collaborative, end-to-end encrypted, privacy focused Google Docs alternative? I picked Google Docs, because it’s so familiar and features what to this date remains to be such an impressive piece of tech – the real-time collaborative editing with shared cursors and comments. I don’t think anybody has done collaborative text editing better than Google Docs since it’s launch, at least not in such a widely used tool or in such a useful way.</p>
<p>To be able to answer if this is possible, let’s make a list of requirements.</p>
<h4>1. End-to-end encrypted</h4>
<p>Nobody, but the content creators get to see the content.</p>
<h4>2. Collaborative</h4>
<p>It should be as close as possible to the real-time collaborative editing experience of Google Docs – shared cursors and commenting. Not only that, but documents, entire collections of documents and application state, such as document tags and folder structures, should be easily shareable between multiple people.</p>
<h4>3. Easy sharing</h4>
<p>Sharing a document, a collection of documents, or inviting other people into your workspace should be easy enough so that anyone can do it (e.g. invite by email address as opposed to copying and pasting public keys).</p>
<h4>4. Search</h4>
<p>I should be able to search through all of the documents I have access to.</p>
<h4>5. Offline capable</h4>
<p>I’d like to be able to access and edit documents offline, without internet connection and sync later. Including any text edits and comment interactions.</p>
<h4>6. Backups</h4>
<p>If you drop your phone in the mud with all the documents, you can restore them from an encrypted cloud backup.</p>
<h4>7. High availability</h4>
<p>If I make changes to a document on my phone, those changes should propagate to other collaborators reliably and quickly even if they were offline at the time of me typing those changes. That is, collaborators don’t have to be online at the same time to sync their changes. Similarly, if you invite a new member to your workspace with some documents shared, they should be able to retrieve and decrypt those documents without any other collaborator being online.</p>
<h4>8. Stretch goal: p2p mode</h4>
<p>Ideally, the software, accepting some limitations (i.e. no high availability), should be able to work completely peer to peer. That is you should be able to opt out of any server participation and still be able to use the application in full even if the service provider shuts down, a longevity oriented approach.</p>
<p>Not all of the above requirements are strictly necessary for building privacy focused software, but they do interconnect in unexpected ways. For example, since search can not be done server side on the encrypted data, that implies having to store all the data on the client, making offline capability a useful side effect. In addition to privacy, these requirements try to incorporate longevity, data ownership and other ideas of <a href="https://www.inkandswitch.com/local-first.html" target="_blank" rel="noopener">Local-first software</a>.</p>
<h2>Possible approaches</h2>
<p>I can think of at least three distinctly different approaches to building an application like this. Let’s see how each of the approaches holds against our requirements.</p>
<h4>Traditional server/client web app</h4>
<p>You can most definitely create Google Docs as a web app (it is already a web app, duh). But once you add the data privacy or end-to-end encryption requirement, that’s when things get tricky.</p>
<p>For starters, powering a feature like Search becomes nearly impossible with encrypted content on the server. To be able to …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.kn8.lt/blog/building-privacy-focused-collaborative-software/">https://www.kn8.lt/blog/building-privacy-focused-collaborative-software/</a></em></p>]]>
            </description>
            <link>https://www.kn8.lt/blog/building-privacy-focused-collaborative-software/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24625563</guid>
            <pubDate>Tue, 29 Sep 2020 09:26:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What is the C++ standard library?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24625526">thread link</a>) | @bvaldivielso
<br/>
September 29, 2020 | https://cor3ntin.github.io/posts/std/ | <a href="https://web.archive.org/web/*/https://cor3ntin.github.io/posts/std/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p><a href="https://xkcd.com/2347/">
<img src="https://imgs.xkcd.com/comics/dependency.png">
</a>
</p>
<hr>
<p><strong>DISCLAIMER</strong></p>
<p>The following represent my opinions, not that of the C++ committee (WG21), any of its members or any other person mentioned in this article.</p>
<hr>
<p>I think the most fundamental work done by WG21 is trying to answer meta-questions about itself.
What is C++, what is its essence, what should we focus on? How to evolve a language with a growing community,
a growing committee?
A language that is deployed on billions of devices, with an estimated 50 billions actively maintained lines of code.
During a CppCon panel last week I was asked about stability VS evolution. This is a hot topic,
one that may never stop being on people’s mind.</p>
<p>There are a lot of interesting meta-questions worth asking about the standard library too.
A question that comes over and over again, is what does it mean to deprecate something, why and when.
Another is what to put in there to begin with.</p>
<p>I wrote a few times on the subject <a href="https://cor3ntin.github.io/posts/what_should_go_in_stl/">before</a>,
hopefully, I will be self-consistent. Not promising anything!</p>
<p>Bryce Adelstein Lelbach, then chair of LEWGI coined the phrase</p>
<blockquote>
<p>Knowing that our resources are scarce and our time is limited, do we want to give more time to this proposal?</p>
</blockquote>
<p>This has become somewhat of a meme in the committee.
Since then, we shipped C++20, Bryce became chair of LEWG (which is a super difficult job that he does brilliantly),
and oh. There is this pandemic you might have heard about.</p>
<p>Never have the scarcity of our resources and the limitedness of our time be more apparent.</p>
<p>We try to make the best of the situation, but I think it’s fair to say that WG21’s output is
reduced. And frankly, we cannot ask of anyone to prioritize C++ standardization with all that’s going on right now.
But even at the best of times, C++ library design is a costly, lengthy process involving a lot of people.
Which is good, <a href="https://en.wikipedia.org/wiki/Linus%27s_law">Linus’s law</a>, plays a huge role in the quality of the standard library.</p>
<p>I don’t know that this used to be a question anyone asked. For a very long time, there were few enough proposals
that they virtually could accept all of those they liked.
At the beginning of the committee, there even was a single pipeline for both language and library.
We can argue whether the separation of rooms we have today is always sensible.
Most of the time library features can be added without new language proposal, but at the same time ADL, customization points,
overload sets etc have been growing pain point for the library, and no organization can escape Conway’s law.</p>
<p>Anyway, the influx of new proposal has grown enough in the past few years that LEWG has now the luxury
and the burden to chose which direction to go in and how to use its far too limited time.</p>
<h2 id="standardization-is-expensive">Standardization is expensive</h2>
<p>I think the life cycle of a library feature goes a bit like this:</p>
<ul>
<li>Someone floats an idea and write a paper</li>
<li>The paper is matured over 1-10 years</li>
<li>There is some latency for implementations (6 months - 5 years) - at least 3 or 4 implementations</li>
<li>There is a ton of latency in deploying toolchains where people can use them (this might be a story for another day)</li>
<li>There is a literal ton of people writing blog posts / textbooks / conference talks about that one feature</li>
<li>Then there is a slow adoption and debate about whether adopting the feature is good or not</li>
</ul>
<p>And every step is resources constrained. Deprecation and removal is also very slow.
People are still using components that were deprecated 10, 20 years ago.</p>
<p>Critical flight software at NASA is estimated at 1000$ per line.
I wouldn’t be surprised if the standard library costs more.
And so, one of the way to answer
“Should that piece of code be in the standard” can maybe be reformulated as “Would this benefit from the standardization process?”</p>
<p>Fundamentally, that makes the standard library a bad package manager.
If the only motivation for something to be in the standard is to palliate to the lack of good package managers,
then it’s probably not a good motivation.
(Especially as the standard library is super bad at availability. it will be years until <code>&lt;ranges&gt;</code> is everywhere.)</p>
<p>Of course, that argument falls flat if you consider <code>std::vector</code>. It doesn’t <em>need</em> to be there, but we are all sure glad it is.
So there is an <em>universality</em> argument to be made too.
If something is universally useful (for example, 90% of programs would use it), then it starts to be a very compelling
feature for the standard library.</p>
<p>Some features can’t live anywhere but in the STL:</p>
<p>Type traits, and everything that needs or benefits from compiler magic and intrinsics.
<a href="http://eel.is/c++draft/support.srcloc">source_location</a>, <a href="https://wg21.link/p0881r6">std::stacktrace</a>, <a href="https://wg21.link/p1885r2">encoding detection</a>,
Reflection support library and other introspection capabilities, <a href="https://wg21.link/p0627r3">std::unreachable</a>, <a href="https://wg21.link/p1773r0">std::assume</a>,
<a href="https://wg21.link/p1040r6">std::embed</a>.
All of these are magic and rely on the compiler. In other words they cannot be implemented portably outside of the standard library.
These are necessary for communicating between user code and compiler, and are the basis of higher-level components.
A logger would use <code>std::source_location</code> for example.</p>
<p>This is especially true of reflection: until C++ gets reflection, an entire class of program cannot be written.
Pattern matching make it possible to write cleaner code. Reflection make it possible to write… code.
Code that you cannot otherwise emulate in standard C++, regardless how much you try.
And that can be pretty expensive across the industry.</p>
<p>So library components that make new things possible are high on the list of the things I think should go in the standard library.</p>
<p>Then, even more obvious, come amelioration to what’s already there.
As standard types get deployed, the committee has to improve them. Both in response to usage experience and to increase synergy between types
or add obvious features that were missing, bug fix, support for new language features.
As such, this <a href="https://wg21.link/p1679r3">std::string::contains</a> proposal might not be the most exciting that will land in 23,
but it might be one of the most useful for many people.</p>
<p>This is the rationale for my own  <a href="https://wg21.link/p2019r0">thread name proposal</a>.
It is not possible to name threads created by <code>std::thread</code>,
and people who rely on that (for ex. the game industry) need to write an entire thread class to replace <code>std::thread</code>, just for this extra piece of functionality.
Other people might give a name to their threads if it’s easy, but might not bother if it implies reimplementing <code>std::thread</code> themselves.
The cost/benefit of using a feature decreases if that feature is present in the standard library. But that is mostly true for small quality-of-life features,
not larger features that are application critical.</p>
<p>There are also vocabulary types: types that are designed to be the glue between libraries, a universal language for interface boundaries.
These get used everywhere. We spend a lot of time getting them right because of this by-design pervasiveness. <code>std::span</code> might simultaneously
be the simplest type of C++20 and also the one that took the most work getting right.
One example of glaringly missing vocabulary type is <a href="https://wg21.link/p1059r0"><code>std::expected</code></a>:
A type that is a bit stuck in another super important meta-conversation: What are the error handlings mechanism that should be used and promoted in C++?
We still have to answer that question.</p>
<p>But… I am not sure types are the right kind of entities at interfaces boundary.
Concepts make for a better vocabulary because they prescribe interfaces, not implementations. (<code>span</code> is nothing if not ““template erasure”” over any <code>contiguous_range</code>).
So maybe the standard library should mainly provide concepts to tie all 3rd parties together? The <code>&lt;concept&gt;</code> header is a good start here.</p>
<p>There is however an issue with just trying to add concepts in the standard.
Concepts are informed by concrete types and how they are used, they cannot be pulled out of thin air. Not without making mistakes anyway, and <a href="https://www.youtube.com/watch?v=v_yzLe-wnfk">concepts are not amendable to mistakes</a>.</p>
<p>So, it would seem that if the STL is to have concepts, it need algorithms.</p>
<blockquote><p lang="en" dir="ltr">Generic Programming pro tip: Although Concepts are constraints on types, you don't find them by looking at the types in your system. You find them by studying the algorithms.<a href="https://twitter.com/hashtag/cpp?src=hash&amp;ref_src=twsrc%5Etfw">#cpp</a></p>— Eric Niebler (@ericniebler) <a href="https://twitter.com/ericniebler/status/990390059579789312?ref_src=twsrc%5Etfw">April 29, 2018</a></blockquote>


<p>Good algorithms are agnostic of domain-specific knowledge and can be used in the widest variety of situations.
Algorithms are not useful to people who write games, or people who make microcontrollers, they are useful to people who write C++.
I’d write better code if I was able to recognise more algorithms.</p>
<p>A focus of C++20 was concepts and ranges, and I hope this remains the case in future versions of C++. views in particular are one of these things people might not actively looked for if available by default.
I sure think <code>views::product</code> is more maintainable than nested loops, but I might not try to find a library that has it, if it’s not in the standard.</p>
<p>So, magic types, vocabulary types, concepts and improvements of existing facilities. A good list of what might be LEWG priorities.</p>
<p>But what about networking, Unicode, processes, 15D graphics, audio, a web engine, ML facilities, JSON parsing, crypto, blockchains, Http, event handling, regexes that don’t suck, etc?</p>
<p>These sure make a great front page cover.
But here is the thing:</p>
<p>WG21 is… kinda bad at design?
Not because we are inherently inept, but because library design is fundamentally hard.
And what we understand to be good library design is a somewhat fast-moving target.</p>
<p>The STL is the foundation of the entire C++ ecosystem. And often used to demonstrate how to use new features and write good code. And we try to cover as many use cases as possible.
Design is finding a path in the maze of the design space, and at each crossing, we go in the direction that we think is the most widely useful.
Problem is, the numbers of crossings grows exponentially with the number of abstraction layers or the complexity of the domain.
It soon becomes impossible to please everybody, or even a majority of people.</p>
<p><code>vector</code> has a few knobs: allocation strategies, growth strategies, error handling etc. It’s a manageable number of knobs that we can tweak …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cor3ntin.github.io/posts/std/">https://cor3ntin.github.io/posts/std/</a></em></p>]]>
            </description>
            <link>https://cor3ntin.github.io/posts/std/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24625526</guid>
            <pubDate>Tue, 29 Sep 2020 09:18:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Fix PostgreSQL Performance Issues with PG Extras]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24625471">thread link</a>) | @todsacerdoti
<br/>
September 29, 2020 | https://pawelurbanek.com/postgresql-fix-performance | <a href="https://web.archive.org/web/*/https://pawelurbanek.com/postgresql-fix-performance">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
    <p><img title="PostgreSQL performance checklist is represented by a notebook Photo by Aaron Burden on Unsplash" alt="PostgreSQL performance checklist is represented by a notebook Photo by Aaron Burden on Unsplash" data-src="https://pawelurbanek.com/assets/postgres-performance-notebook-223d1a2313851e07a649511f2ec7d7d7bbcf49c50cff6fbccf133f7a50a164f1.jpg" src="https://pawelurbanek.com/assets/postgres-performance-notebook-thumb-d32ee718054bdb4e0941997a0fef3c2040885ba2197dfc125668a82f6dea1a0b.jpg">
    </p>
  

  

  <p>PostgreSQL database queries are a common performance bottleneck for web apps. Before you resort to more complex optimization techniques like caching or read replicas, you should double-check if your database engine is correctly tuned and queries are not underperforming.</p>

<p>PG Extras is a tool that allows you to spot common PostgreSQL pitfalls. <a href="https://github.com/pawurb/ruby-pg-extras" rel="noopener noreferrer" target="_blank">Ruby</a>, <a href="https://github.com/pawurb/rails-pg-extras" rel="noopener noreferrer" target="_blank">Rails</a>, <a href="https://github.com/pawurb/ecto_psql_extras" rel="noopener noreferrer" target="_blank">Elixir</a>, and <a href="https://github.com/pawurb/node-postgres-extras" rel="noopener noreferrer" target="_blank">NodeJS</a> implementations are currently available.</p>

<p>In this blog post, I present a step by step guide on using PG Extras library to spot and resolve common PostgreSQL database performance issues.</p>



<p>Please refer to READMEs of respective implementations for installation details.  API is almost identical for all the versions. Let’s compare the invocation of the <code>cache_hit</code> method:</p>

<p><code>Ruby</code></p>

<figure><pre><code data-lang="ruby"><span>RubyPGExtras</span><span>.</span><span>cache_hit</span></code></pre></figure>

<p><code>Rails</code></p>

<figure><pre><code data-lang="ruby"><span>RailsPGExtras</span><span>.</span><span>cache_hit</span></code></pre></figure>

<p><code>Elixir</code></p>

<figure><pre><code data-lang="elixir"><span>EctoPSQLExtras</span><span>.</span><span>query</span><span>(</span><span>:cache_hit</span><span>,</span> <span>YourApp</span><span>.</span><span>Repo</span><span>)</span></code></pre></figure>

<p><code>NodeJS</code></p>

<figure><pre><code data-lang="javascript"><span>PostgresExtras</span><span>.</span><span>cache_hit</span><span>()</span></code></pre></figure>

<p>In this blog post, I’ll be using examples from the pure Ruby version.</p>

<h3 id="enable-pg_stat_statements-extension">Enable <code>pg_stat_statements</code> extension</h3>

<p>Some of the PG Extras methods depend on the <code>pg_stat_statements</code> extension. If you are using a default Heroku PostgreSQL plugin or <a href="https://aws.amazon.com/rds/" rel="noopener noreferrer" target="_blank">AWS RDS</a>, you should be good to go without making any changes.</p>

<p>To check if the extension is already enabled you can use PG Extras itself:</p>

<figure><pre><code data-lang="ruby"><span>RubyPGExtras</span><span>.</span><span>extensions</span>

<span>...</span>
<span>|</span> <span>pg_stat_statements</span> <span>|</span> <span>1.7</span> <span>|</span> <span>1.7</span> <span>|</span> <span>track</span> <span>execution</span> <span>statistics</span> <span>of</span> <span>all</span> <span>SQL</span> <span>statements</span> <span>executed</span>
<span>...</span></code></pre></figure>

<p>If <code>pg_stat_statements</code> is not listed you should check out <a href="https://www.postgresql.org/docs/current/pgstatstatements.html" target="_blank">these docs</a> for info on installing it.</p>

<p>Now that you’ve set up the library in the language of your choice let’s start checking our database’s health.</p>

<p><strong>[Important]</strong> <em>Make certain to run all the checks on a warmed up production database. Under the hood, PG Extras performs a lightweight queries on PostgreSQL metadata tables. It will not impact your production workload.</em></p>

<h2 id="1-validate-your-database-specs-with-cache-hit-ratios">1) Validate your database specs with cache hit ratios</h2>

<p>In theory, the simplest solution to optimize the underperforming database is to scale it up vertically. Before you start throwing money at your performance issues, it’s good to check if it will actually help.</p>

<p>PostgreSQL tracks access patterns of your data and keeps frequently read chunks in a memory cache. A reliable indicator that a database should be scaled up is an invalid cache hit ratio.</p>

<p>You can check index and table cache hit ratios using the following code:</p>

<figure><pre><code data-lang="ruby"><span>RubyPGExtras</span><span>.</span><span>cache_hit</span>

      <span>name</span>      <span>|</span>         <span>ratio</span>
<span>----------------+------------------------</span>
 <span>index</span> <span>hit</span> <span>rate</span> <span>|</span>        <span>0.999577</span>
 <span>table</span> <span>hit</span> <span>rate</span> <span>|</span>        <span>0.988721</span></code></pre></figure>

<p>If you want to drill down into each individual’s table and index cache hit ratios, you can use <code>table_cache_hit</code> and <code>index_cache_hit</code> methods.</p>

<p>The rule of the thumb is that values should be above 99%. If your database cache hit ratios are lower, it’s either not correctly configured or should be scaled up to increase the performance.</p>

<p>Heroku PostgreSQL ships with already optimized settings and does not allow you to change them. If you see low cache hit ratios, your best bet is to provision a more powerful database instance.</p>

<p>Amazon RDS is notorious for shipping the database instances with incorrect default settings. If you’re using it, make sure to tweak them before deciding to scale up the instance. <a href="https://pgtune.leopard.in.ua/" rel="noopener noreferrer" target="_blank">PGTune</a> is the best tool to help you tweak the most important Postgres buttons and dials to the correct values.</p>

<h2 id="2-remove-unused-indexes">2) Remove unused indexes</h2>

<p>Overusing indexes is a recipe for a sluggish web app.</p>

<p>The more indexes you add, the more write operations have to be performed on each data update. Misconfigured indexes also tend to unecessarily bloat the size of a database, slowing down the backup/restore/upgrade operations.</p>

<p>It’s entirely possible that some of your indexes and not used and can be safely removed.</p>

<p>PG Extras <code>unused_indexes</code> method can help you spot them:</p>

<figure><pre><code data-lang="ruby"><span>RubyPGExtras</span><span>.</span><span>unused_indexes</span>

          <span>table</span>      <span>|</span>                       <span>index</span>                <span>|</span> <span>index_size</span> <span>|</span> <span>index_scans</span>
<span>---------------------+--------------------------------------------+------------+-------------</span>
 <span>public</span><span>.</span><span>grade_levels</span> <span>|</span> <span>index_placement_attempts_on_grade_level_id</span> <span>|</span> <span>97</span> <span>MB</span>      <span>|</span>           <span>0</span>
 <span>public</span><span>.</span><span>observations</span> <span>|</span> <span>observations_attrs_grade_resources</span>         <span>|</span> <span>33</span> <span>MB</span>      <span>|</span>           <span>0</span>
 <span>public</span><span>.</span><span>messages</span>     <span>|</span> <span>user_resource_id_idx</span>                       <span>|</span> <span>12</span> <span>MB</span>      <span>|</span>           <span>0</span></code></pre></figure>

<p>Few <code>index_scans</code> on an index that has been around for a while means that it should be removed. If the index is large, remember to use the <a href="https://www.postgresql.org/docs/current/sql-dropindex.html" rel="noopener noreferrer" target="_blank"><code>CONCURRENTLY</code></a> option when dropping it, to avoid exclusively blocking the whole related table.</p>

<p><code>index_size</code> method can give you a quick overview of how much space your database indexes are taking:</p>

<figure><pre><code data-lang="ruby"><span>RubyPGExtras</span><span>.</span><span>index_size</span>

     <span>name</span>            <span>|</span>  <span>size</span>
<span>-----------------------------------------------</span>
 <span>index_a_name</span>        <span>|</span> <span>5196</span> <span>MB</span>
 <span>index_b_name</span>        <span>|</span> <span>4045</span> <span>MB</span>
 <span>index_b_name</span>        <span>|</span> <span>2611</span> <span>MB</span></code></pre></figure>

<h2 id="3-add-missing-indexes">3) Add missing indexes</h2>

<p>Now that we’ve removed unused indexes, let’s add some new ones. We don’t want them to share the fate of their recently deprovisioned cousins. Let’s look at PG Extras <code>seq_scans</code> and <code>calls</code> methods before deciding on what should be indexed.</p>

<p>A <em>sequential scan</em> is an action that Postgres performs if it cannot find an index necessary to fulfill the query condition. For the following query:</p>

<figure><pre><code data-lang="sql"><span>SELECT</span> <span>*</span> <span>FROM</span> <span>USERS</span> <span>WHERE</span> <span>AGE</span> <span>=</span> <span>18</span><span>;</span></code></pre></figure>

<p>the related <code>EXPLAIN ANALYZE</code> query output will show <code>Seq scan on users Filter: AGE = 18</code> or <code>Index Scan using users_age_index Index Cond: AGE = 18</code> depending on whether the index on <code>age</code> column is present or not.</p>

<p><code>seq_scans</code> method displays the number of <code>Seq Scan</code> operations for each table:</p>

<figure><pre><code data-lang="ruby"><span>RubyPGExtras</span><span>.</span><span>seq_scans</span>

               <span>name</span>                <span>|</span>  <span>count</span>
<span>-----------------------------------+----------</span>
 <span>learning_coaches</span>                  <span>|</span> <span>44820063</span>
 <span>states</span>                            <span>|</span> <span>36794975</span>
 <span>grade_levels</span>                      <span>|</span> <span>13972293</span>
 <span>charities_customers</span>               <span>|</span>  <span>8615277</span></code></pre></figure>

<p>Now that we know which tables are often read inefficiently, we can use <code>calls</code> and <code>outliers</code> methods to list the most often executed and most time-consuming queries.</p>

<p>Both of those methods let you extract the raw query string. You can use it to perform <code>EXPLAIN ANALYZE</code> and check if the query planner does <code>Seq scan</code> on one of the tables.</p>

<p>By correlating all those sources of data, you should be able to spot queries that are consuming a lot of your database resources and are potentially missing an index.</p>

<p>Watch out to avoid premature optimization by adding unnecessary indexes. PostgreSQL will often fallback to <code>Seq Scan</code> instead of <code>Index Scan</code> on small tables, for which using the index would be less efficient than reading the whole table row by row.</p>

<h2 id="4-identify-deadlocks">4) Identify deadlocks</h2>

<p>PostgreSQL uses locks to ensure data consistency in multithreaded environments. There are different kinds of locks, but we’ll focus on <code>ExclusiveLock</code> and <code>RowExclusiveLock</code>. A healthy web app should never lock for more than a couple of hundred of miliseconds.</p>

<p>Deadlock is two more or database locks blocking each other and not able to continue execution. An implementation error that results in a deadlock might have disastrous consequences for your application. The queue of requests not able to proceed could start piling up and eventually crash your servers.</p>

<p>Common reasons for deadlocks and locks that are granted for too long:</p>

<ul>
  <li>too broad database transaction scope</li>
  <li>adding or removing index without using the <code>CONCURRENTLY</code> option</li>
  <li>updating lots of rows at once</li>
  <li>adding a new column with the default value (before PostgreSQL 12)</li>
</ul>

<h3 id="how-to-detect-locks-and-deadlocks">How to detect locks and deadlocks</h3>

<p>You can use <code>locks</code> method to see all the currently obtained locks together with the source query:</p>

<figure><pre><code data-lang="ruby"><span>RubyPGExtras</span><span>.</span><span>locks</span>

 <span>procpid</span> <span>|</span> <span>relname</span> <span>|</span> <span>transactionid</span> <span>|</span> <span>granted</span> <span>|</span>     <span>query_snippet</span>     <span>|</span> <span>mode</span>             <span>|</span>       <span>age</span>
<span>---------+---------+---------------+---------+-----------------------+-------------------------------------</span>
   <span>31776</span> <span>|</span>         <span>|</span>               <span>|</span> <span>t</span>       <span>|</span> <span>&lt;</span><span>IDLE</span><span>&gt;</span> <span>in</span> <span>transaction</span> <span>|</span> <span>ExclusiveLock</span>    <span>|</span>  <span>00</span><span>:</span><span>19</span><span>:</span><span>29.837898</span>
   <span>31776</span> <span>|</span>         <span>|</span>          <span>1294</span> <span>|</span> <span>t</span>       <span>|</span> <span>&lt;</span><span>IDLE</span><span>&gt;</span> <span>in</span> <span>transaction</span> <span>|</span> <span>RowExclusiveLock</span> <span>|</span>  <span>00</span><span>:</span><span>19</span><span>:</span><span>29.837898</span>
   <span>31912</span> <span>|</span>         <span>|</span>               <span>|</span> <span>t</span>       <span>|</span> <span>select</span> <span>*</span> <span>from</span> <span>hello</span><span>;</span>  <span>|</span> <span>ExclusiveLock</span>    <span>|</span>  <span>00</span><span>:</span><span>19</span><span>:</span><span>17.94259</span>
    <span>3443</span> <span>|</span>         <span>|</span>               <span>|</span> <span>t</span>       <span>|</span>                      <span>+|</span> <span>ExclusiveLock</span>    <span>|</span>  <span>00</span><span>:</span><span>00</span><span>:</span><span>00</span></code></pre></figure>

<p>The mere presence of locks does not mean that something is wrong with your database. Only locks that are granted for too long are potentially problematic. You can use the following Ruby snippet integrated into the background job to alert you if this happens:</p>

<figure><pre><code data-lang="ruby"><span>TRESHOLD_SECONDS</span> <span>=</span> <span>1</span>

<span>long_locks</span> <span>=</span> <span>RubyPGExtras</span><span>.</span><span>locks</span><span>(</span><span>in_format: :hash</span><span>).</span><span>select</span> <span>do</span> <span>|</span><span>lock</span><span>|</span>
  <span>Time</span><span>.</span><span>parse</span><span>(</span><span>lock</span><span>.</span><span>fetch</span><span>(</span><span>"age"</span><span>)).</span><span>seconds_since_midnight</span> <span>&gt;</span> <span>TRESHOLD_SECONDS</span>
<span>end</span>

<span>raise</span> <span>"Long running locks: </span><span>#{</span><span>long_locks</span><span>}</span><span>"</span> <span>if</span> <span>long_locks</span><span>.</span><span>present?</span></code></pre></figure>

<p>If you notice extended locks, you can use the <code>blocking</code> method to check which SQL statements cannot continue execution because of a lock:</p>

<figure><pre><code data-lang="ruby"><span>RubyPGExtras</span><span>.</span><span>blocking</span>

 <span>blocked_pid</span> <span>|</span>    <span>blocking_statement</span>    <span>|</span> <span>blocking_duration</span> <span>|</span> <span>blocking_pid</span> <span>|</span>                                        <span>blocked_statement</span>                           <span>|</span> <span>blocked_duration</span>
<span>-------------+--------------------------+-------------------+--------------+------------------------------------------------------------------------------------+------------------</span>
         <span>461</span> <span>|</span> <span>select</span> <span>count</span><span>(</span><span>*</span><span>)</span> <span>from</span> <span>app</span> <span>|</span> <span>00</span><span>:</span><span>00</span><span>:</span><span>03</span><span>.</span><span>838314</span>   <span>|</span>        <span>15682</span> <span>|</span> <span>UPDATE</span> <span>"app"</span> <span>SET</span> <span>"updated_at"</span> <span>=</span> <span>'2013-03-04 15:07:04.746688'</span> <span>WHERE</span> <span>"id"</span> <span>=</span> <span>12823149</span> <span>|</span> <span>00</span><span>:</span><span>00</span><span>:</span><span>03</span><span>.</span><span>821826</span></code></pre></figure>

<p>If your app is crashing because of deadlocks, you can use the <code>kill_all</code> to terminate all the database processes before you manage to resolve the underlying cause.</p>

<h2 id="5-get-rid-of-unnecessary-bloat">5) Get rid of unnecessary bloat</h2>

<p>The way PostgreSQL works is that it never updates or removes the data in place but instead marks each row as visible or not for transactions using two meta columns <code>xmin</code> and <code>xmax</code>. Rows no longer visible for any of the currently active transactions are called <em>dead rows</em> or <em>bloat</em>.</p>

<p>Dead rows are regularly <em>garbage collected</em> by a process called <em>AUTOVACUUM</em>, …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pawelurbanek.com/postgresql-fix-performance">https://pawelurbanek.com/postgresql-fix-performance</a></em></p>]]>
            </description>
            <link>https://pawelurbanek.com/postgresql-fix-performance</link>
            <guid isPermaLink="false">hacker-news-small-sites-24625471</guid>
            <pubDate>Tue, 29 Sep 2020 09:06:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WhatsApp Chatbots – The Ultimate Guide (2020)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24625400">thread link</a>) | @chatimize
<br/>
September 29, 2020 | https://chatimize.com/whatsapp-chatbots/ | <a href="https://web.archive.org/web/*/https://chatimize.com/whatsapp-chatbots/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			<div data-elementor-type="wp-post" data-elementor-id="4545" data-elementor-settings="[]">
			<div>
				<div>
							<section data-id="650a3768" data-element_type="section">
						<div>
				<div>
				<div data-id="cee7aa2" data-element_type="column">
			<div>
					<div>
				
				<div data-id="50106658" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><div><p><img alt="joren-wouters-avatar" src="https://chatimize.com/wp-content/themes/chatimize/images/joren-wouters.jpg" data-src="https://chatimize.com/wp-content/themes/chatimize/images/joren-wouters.jpg"></p><p>By Joren Wouters <span>•</span> Updated on <time datetime="2020-09-29T07:51:07+00:00">Sep 29, 2020</time></p></div>
				</div>
				</div>
				<section data-id="2bb6a39" data-element_type="section">
						<div>
				<div>
				
				<div data-id="457b65e" data-element_type="column">
			<div>
					<div>
				<div data-id="ec62486" data-element_type="widget" data-widget_type="html.default">
				<div>
			<div>
    <div>
        <p>This is the ultimate guide to WhatsApp Chatbots in 2020.</p>
        <p>And I will cover <strong><u>everything</u></strong>.</p>
        <p>What WhatsApp chatbots are. <br>
        What message rules apply on WhatsApp. <br>How you can build a WhatsApp Chatbot.</p>
        <p><strong>And even more.</strong></p>
        <p>So if you're looking to use WhatsApp chatbots in your marketing, you'll love this new guide.</p>
    </div>
    <p><img src="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-chatbots.png" data-src="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-chatbots.png" alt="whatsapp-chatbots" width="1000" height="1032" data-srcset="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-chatbots.png 1000w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-chatbots-291x300.png 291w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-chatbots-768x793.png 768w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-chatbots-992x1024.png 992w" data-sizes="(max-width: 1000px) 100vw, 1000px" srcset="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-chatbots.png 1000w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-chatbots-291x300.png 291w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-chatbots-768x793.png 768w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-chatbots-992x1024.png 992w">
    </p>
</div>		</div>
				</div>
						</div>
			</div>
		</div>
				
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
						</div>
			</div>
		</div></section>
				<section data-id="5f004b5e" data-element_type="section" id="winner" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;}">
						
		</section>
				<section data-id="5927f47" data-element_type="section" id="intro-whatsapp" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;}">
						<div>
				<div>
				<div data-id="40c8773" data-element_type="column">
			<div>
					<div>
				<div data-id="d9f2218" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2><strong>Chapter 1:</strong> Intro to WhatsApp Chatbots</h2>		</p>
				</div>
				<section data-id="53ee519" data-element_type="section">
						<div>
				<div>
				
				<div data-id="1f456ec" data-element_type="column">
			<div>
					<div>
				<div data-id="2cba36b" data-element_type="widget" data-widget_type="html.default">
				<div>
			<div>
    
    <p><img src="https://chatimize.com/wp-content/uploads/2020/09/basics-whatsapp-chatbots.png" data-src="https://chatimize.com/wp-content/uploads/2020/09/basics-whatsapp-chatbots.png" alt="intro-whatsapp-chatbots">
    </p>
</div>		</div>
				</div>
						</div>
			</div>
		</div>
				
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="a7978fb" data-element_type="section" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;}">
						<div>
				<div>
				<div data-id="0d19ce8" data-element_type="column">
			<div>
					<div>
				<div data-id="ac9bf20" data-element_type="widget" id="what-is" data-widget_type="heading.default">
				<p>
			<h2>What is a WhatsApp chatbot?</h2>		</p>
				</div>
				<section data-id="05e68f4" data-element_type="section">
						<div>
				<div>
				
				<div data-id="da3b036" data-element_type="column">
			<div>
					<div>
				<div data-id="690393b" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>A WhatsApp <a href="https://chatimize.com/chatbot/">chatbot</a> is an automated conversation partner on WhatsApp.</p><p>It facilitates a conversation between a person and a computer.</p><p>Usually, you will have a conversation with another person on WhatsApp (for example, one of your friends), but with chatbots, you are talking to a computer, not a human.</p></div>
				</div>
				</div>
						</div>
			</div>
		</div>
				
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="3ed98d8" data-element_type="section" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;}">
						<div>
				<div>
				<div data-id="c6ac601" data-element_type="column">
			<div>
					<div>
				
				<section data-id="0b93cb5" data-element_type="section">
						<div>
				<div>
				
				<div data-id="17658ca" data-element_type="column">
			<div>
					<div>
				<div data-id="90ba18e" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>Now a real-life example: the KLM WhatsApp Chatbot.</p><p>KLM Royal Dutch Airlines is one of the biggest airlines in the world. They have over 30.000 employees and serve passengers and cargo to 145 destinations.&nbsp;</p><p>I’m originally from the Netherlands, so I really like the fact that <a href="https://news.klm.com/klm-first-airline-with-verified-whatsapp-business-account/" target="_blank" rel="noopener">KLM was the first airline with a WhatsApp chatbot</a>.</p><p>KLM used the chatbot to send booking information, check-in notifications, boarding passes and flight status updates. Besides that, users could ask KLM questions in 10 different languages:</p></div>
				</div>
				</div>
				
						</div>
			</div>
		</div>
				
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="34a084c" data-element_type="section" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;}">
						<div>
				<div>
				<div data-id="3e63315" data-element_type="column">
			<div>
					<div>
				<div data-id="570966b" data-element_type="widget" id="why-whatsapp-chatbot" data-widget_type="heading.default">
				<p>
			<h2>Why use WhatsApp Chatbots?</h2>		</p>
				</div>
				<section data-id="26b0509" data-element_type="section">
						<div>
				<div>
				
				<div data-id="c437b41" data-element_type="column">
			<div>
					<div>
				<div data-id="be29912" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>WhatsApp is one of the biggest messaging apps in the world, with over <a href="https://www.oberlo.com/blog/whatsapp-statistics" target="_blank" rel="noopener">2 billion users</a> around the globe. It is available in more than 180 countries and 60 different languages.</p><p>Moreover, 1.6 billion WhatsApp users access the app on a monthly basis.</p><p><a href="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-users-1.png"><img src="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-users-1.png" data-src="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-users-1.png" alt="whatsapp-users" width="1459" height="553" data-srcset="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-users-1.png 1459w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-users-1-300x114.png 300w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-users-1-768x291.png 768w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-users-1-1024x388.png 1024w" data-sizes="(max-width: 1459px) 100vw, 1459px" srcset="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-users-1.png 1459w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-users-1-300x114.png 300w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-users-1-768x291.png 768w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-users-1-1024x388.png 1024w"></a></p><p>And this leads to 65 billion WhatsApp messages sent every day.</p><p><a href="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-messages.png"><img src="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-messages.png" data-src="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-messages.png" alt="whatsapp-messages" width="1459" height="553" data-srcset="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-messages.png 1459w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-messages-300x114.png 300w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-messages-768x291.png 768w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-messages-1024x388.png 1024w" data-sizes="(max-width: 1459px) 100vw, 1459px" srcset="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-messages.png 1459w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-messages-300x114.png 300w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-messages-768x291.png 768w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-messages-1024x388.png 1024w"></a></p><p>Overwhelming, right?</p><p>So basically, you should use WhatsApp because your customers are already there, they are just waiting for you to send them a message. Besides that, you can reach any potential client on WhatsApp, because it is used by so many users all over the world.</p><p>Now I hear you thinking “Okay, I should use WhatsApp. But why use a chatbot?”</p><p>Good one.</p><p>In fact, I made a complete post about <a href="https://chatimize.com/why-chatbots/">why you should use chatbots</a>, but here are the ten most important reasons:</p><ol><li>Save time and money on customer service</li><li>Boost your sales</li><li>Get more leads</li><li>Reply in seconds, instead of days</li><li>24/7 available, everywhere</li><li>Send real-time, tailored messages to customers</li><li>Messenger apps (like WhatsApp) become more popular</li><li>People are open to using chatbots</li><li>You can use chatbots internally in your company</li><li>Stand out from the crowd (aka, not many businesses use chatbots yet)</li></ol></div>
				</div>
				</div>
						</div>
			</div>
		</div>
				
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="2dd9403" data-element_type="section" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;}">
						<div>
				<div>
				<div data-id="953cb1c" data-element_type="column">
			<div>
					<div>
				<div data-id="f60f589" data-element_type="widget" id="how-whatsapp-chatbot" data-widget_type="heading.default">
				<p>
			<h2>How does a WhatsApp Chatbot work?</h2>		</p>
				</div>
				<section data-id="5ef3c27" data-element_type="section">
						<div>
				<div>
				
				<div data-id="0477877" data-element_type="column">
			<div>
					<div>
				<div data-id="392637b" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>A WhatsApp chatbot works really simple.</p><p>Someone can just send a message to the WhatsApp number of a certain business and the chatbot will try to answer that message, just like any normal person would do.</p><p>I will illustrate this by giving an example:</p><ol><li>A user starts a conversation with a WhatsApp chatbot of a wine company. The user asks “What red wine do you recommend?”</li><li>The chatbot understands this message and recognizes the words “red wine” and “recommend”</li><li>Based on those recognized words, the chatbot will look in the wine database for “recommended red wines”</li><li>Finally, the chatbot will send a message back with all the recommended red wines in the wine database.</li></ol><p>Pretty simple, right?</p><p>“But what about KLM? Nobody sent them a message and they automatically send someone’s boarding pass?”</p><p>That’s right. It’s also possible that the chatbot starts the conversation with the user. But this is only allowed in certain situations. We will talk more about that in the next chapter 😉</p></div>
				</div>
				</div>
						</div>
			</div>
		</div>
				
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="3dc9d56" data-element_type="section" id="whatsapp-message-rules" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;}">
						<div>
				<div>
				<div data-id="3fd8f10" data-element_type="column">
			<div>
					<div>
				<div data-id="6895a0d" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2><strong>Chapter 2:</strong> WhatsApp Message Rules</h2>		</p>
				</div>
				<section data-id="27cc5f9" data-element_type="section">
						<div>
				<div>
				
				<div data-id="c6e5c42" data-element_type="column">
			<div>
					<div>
				<div data-id="387e922" data-element_type="widget" data-widget_type="html.default">
				<div>
			<div>
    <div>
        <p>Unfortunately, you can't just send any message to anyone with your WhatsApp chatbot.</p>

<p>There are certain rules that you must follow.</p>

<p>Why is this? So that businesses don't spam everyone on WhatsApp (which is really anoying).</p>

<p>So, what are these rules?</p>

<p>Let's jump right in.</p>
    </div>
    <p><img src="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-message-rules.png" data-src="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-message-rules.png" alt="whatsapp-message-rules" width="1000" height="961" data-srcset="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-message-rules.png 1000w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-message-rules-300x288.png 300w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-message-rules-768x738.png 768w" data-sizes="(max-width: 1000px) 100vw, 1000px" srcset="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-message-rules.png 1000w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-message-rules-300x288.png 300w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-message-rules-768x738.png 768w">
    </p>
</div>		</div>
				</div>
						</div>
			</div>
		</div>
				
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="2917218" data-element_type="section" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;}">
						<div>
				<div>
				<div data-id="07ab3ad" data-element_type="column">
			<div>
					<div>
				<div data-id="b47bff3" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2>Intro to WhatsApp Message Rules</h2>		</p>
				</div>
				<section data-id="ff4aea9" data-element_type="section">
						<div>
				<div>
				
				<div data-id="7ab42fb" data-element_type="column">
			<div>
					<div>
				<div data-id="c78367c" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>Basically, there are two kinds of conversations with WhatsApp Chatbots:</p><ol><li>The user starts the conversation with the chatbot – WhatsApp calls this “Customer Care”</li><li>The chatbot starts the conversation with the user – This is called WhatsApp Message Templates or WhatsApp Notifications</li></ol><p>If you are only planning to provide Customer Care to your users, then don’t worry, because you won’t break any rules.</p><p>But if you want to do more, I recommend to read on.</p><p>So, every time a user sends a message to your WhatsApp chatbot, a&nbsp;<strong>24-hour window</strong> will open. Within this 24-hour window, you can send any message to the user, with absolutely no constraints.</p><p>Please note that this 24-hour window will reopen,&nbsp;<strong>every time</strong> the user sends a message. Take this example:</p><ul><li>User sends message to chatbot&nbsp;<strong>*24-hour window will open*</strong></li><li>User says nothing for 8 hours <strong>*There are 16 hours left in the 24-hour window*</strong></li><li>After 8 hours, the user sends another message&nbsp;<strong>*24-hour window will re-open*</strong></li></ul><p><a href="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-24-hour-window.png"><img src="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-24-hour-window.png" data-src="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-24-hour-window.png" alt="whatsapp-24-hour-window" width="1313" height="678" data-srcset="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-24-hour-window.png 1313w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-24-hour-window-300x155.png 300w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-24-hour-window-768x397.png 768w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-24-hour-window-1024x529.png 1024w" data-sizes="(max-width: 1313px) 100vw, 1313px" srcset="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-24-hour-window.png 1313w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-24-hour-window-300x155.png 300w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-24-hour-window-768x397.png 768w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-24-hour-window-1024x529.png 1024w"></a></p><p><strong>By the way</strong>, these message inside the 24-hour window are also called&nbsp;<strong>“Session Messages”.</strong></p><p>But what about messages outside the 24-hour window?</p><p>WhatsApp uses Message Templates/Notifications for that.</p></div>
				</div>
				</div>
						</div>
			</div>
		</div>
				
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="e6a99ca" data-element_type="section" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;}">
						<div>
				<div>
				<div data-id="b4ffd8c" data-element_type="column">
			<div>
					<div>
				<div data-id="d1a7810" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2>WhatsApp Message Templates / Notifications</h2>		</p>
				</div>
				<section data-id="351a5aa" data-element_type="section">
						<div>
				<div>
				
				<div data-id="36bfbdc" data-element_type="column">
			<div>
					<div>
				<div data-id="8155c2a" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>You can use WhatsApp Message Templates to send messages to users outside the 24-hour window.</p><p>But you can only send these message templates in really specific situations.</p><p>In total, there are 11 situations and I will go by them one-by-one.</p><h3>Account update</h3><p>You can use this category to send messages to users when their account is updated or changed. For example, you can inform customers when they have successfully created an account on your webshop.&nbsp;</p><h3>Alert update</h3><p>Send important updates or news to customers.</p><p>This category is more for general updates to users. For example, you can send an update to a user if he ordered a product at your webshop.</p><h3>Appointment Update</h3><p>The Appointment Update is used to send confirmations, reminders or other updates to users about their appointments:</p><figure id="attachment_4735" aria-describedby="caption-attachment-4735"><a href="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-reservation-message-template.jpg"><img src="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-reservation-message-template.jpg" data-src="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-reservation-message-template.jpg" alt="whatsapp-reservation-message-template" width="1536" height="1289" data-srcset="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-reservation-message-template.jpg 1536w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-reservation-message-template-300x252.jpg 300w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-reservation-message-template-768x645.jpg 768w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-reservation-message-template-1024x859.jpg 1024w" data-sizes="(max-width: 1536px) 100vw, 1536px" srcset="https://chatimize.com/wp-content/uploads/2020/09/whatsapp-reservation-message-template.jpg 1536w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-reservation-message-template-300x252.jpg 300w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-reservation-message-template-768x645.jpg 768w, https://chatimize.com/wp-content/uploads/2020/09/whatsapp-reservation-message-template-1024x859.jpg 1024w"></a><figcaption id="caption-attachment-4735">Source: <a href="https://trengo.com/blog/communication/examples-of-whatsapp-business-templates-that-make-life-easier/">Trengo</a></figcaption></figure><h3>Auto-Reply</h3><p>You can use this category to send auto-replies to customers when your business isn’t online or available to respond right away.</p><p>To be honest, most business with WhatsApp chatbots don’t use this feature, because a chatbot is 24/7 available and can always respond.</p><h3>Issue Resolution</h3><p>With the Issue Resolution category, you can respond to questions or concerns from users about your business.</p><p>For example, when your website or service isn’t online at the moment, you can inform users that you are working on a resolution to solve the issue.</p><h3>Payment Update</h3><p>The Payment Update is meant to send messages to customers about their payment. For example, you can send a message when the payment has been succesfully received.</p><h3>Personal Finance Update</h3><p>You can use the Personal Finance Update to send messages to customers about their personal finances. This is especially useful for insurance organizations or financial institutions.</p><h3>Reservation Update</h3><p>This one is quite similar to the Appointment Update.</p><p>With the Reservation Update, you can send confirmations, reminders or other updates to users about their reservations.</p><h3>Shipping Update</h3><p>You can use the Shipping Update to send updates to customers about shipping their products. For example, you can send “You will receive your products within 24 hours.”</p><h3>Ticket Update</h3><p>This can be used to send ticketing information or updates to customers. It is especially useful if you solved a ticket outside the 24-hour window.</p><h3>Transportation Update</h3><p>This template is used for sending transportation information or updates to customers. For example, you could send a message when a flight has been delayed (Exactly what KLM used!)</p></div>
				</div>
				</div>
						</div>
			</div>
		</div>
				
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="7355590" data-element_type="section" id="create-whatsapp-chatbot" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;}">
						<div>
				<div>
				<div data-id="d9e8b5a" data-element_type="column">
			<div>
					<div>
				<div data-id="4495bfd" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2><strong>Chapter 3:</strong> How to create a chatbot on WhatsApp</h2>		</p>
				</div>
				<section data-id="2b8d936" data-element_type="section">
						<div>
				<div>
				
				<div data-id="b562a6c" data-element_type="column">
			<div>
					<div>
				<div data-id="a83979c" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>Now, we know the basics of WhatsApp Chatbots and the rules we need to follow in order to build one.</p><p>So, we got everything to build a WhatsApp chatbot ourselves.</p><p>Let’s dive in.</p><p><a href="https://chatimize.com/wp-content/uploads/2020/09/how-to-create-whatsapp-chatbot.png"><img src="https://chatimize.com/wp-content/uploads/2020/09/how-to-create-whatsapp-chatbot.png" data-src="https://chatimize.com/wp-content/uploads/2020/09/how-to-create-whatsapp-chatbot.png" alt="how-to-create-whatsapp-chatbot" width="1920" height="1106" data-srcset="https://chatimize.com/wp-content/uploads/2020/09/how-to-create-whatsapp-chatbot.png 1920w, https://chatimize.com/wp-content/uploads/2020/09/how-to-create-whatsapp-chatbot-300x173.png 300w, https://chatimize.com/wp-content/uploads/2020/09/how-to-create-whatsapp-chatbot-768x442.png 768w, https://chatimize.com/wp-content/uploads/2020/09/how-to-create-whatsapp-chatbot-1024x590.png 1024w" data-sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://chatimize.com/wp-content/uploads/2020/09/how-to-create-whatsapp-chatbot.png 1920w, https://chatimize.com/wp-content/uploads/2020/09/how-to-create-whatsapp-chatbot-300x173.png 300w, https://chatimize.com/wp-content/uploads/2020/09/how-to-create-whatsapp-chatbot-768x442.png 768w, https://chatimize.com/wp-content/uploads/2020/09/how-to-create-whatsapp-chatbot-1024x590.png 1024w"></a></p></div>
				</div>
				</div>
						</div>
			</div>
		</div>
				
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="2c34759" data-element_type="section" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;}">
						<div>
				<div>
				<div data-id="7665f4e" data-element_type="column">
			<div>
					<div>
				<div data-id="af218be" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2>Choose your chatbot software</h2>		</p>
				</div>
				<section data-id="651a437" data-element_type="section">
						<div>
				<div>
				
				<div data-id="191b3c7" data-element_type="column">
			<div>
					<div>
				<div data-id="94c2439" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>The first thing you need to do, is choose the chatbot software you are going to use to build your WhatsApp chatbot.</p><p>There are basically two options:</p><ul><li>Choose a chatbot builder that has WhatsApp inside their platform (such as <a href="https://landbot.grsm.io/chatimize">Landbot</a>)</li><li>Go with a chatbot builder that has an integration with <a href="http://www.twilio.com/referral/TpDZL3" target="_blank" rel="noopener">Twilio</a> (like <a href="https://silferbots.io/">SilFer Bots</a>)</li></ul><p>The last option is the most common approach for chatbot builders that offer …</p></div></div></div></div></div></div></div></div></section></div></div></div></div></div></section></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://chatimize.com/whatsapp-chatbots/">https://chatimize.com/whatsapp-chatbots/</a></em></p>]]>
            </description>
            <link>https://chatimize.com/whatsapp-chatbots/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24625400</guid>
            <pubDate>Tue, 29 Sep 2020 08:50:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Single Machine Startup Company System]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24625277">thread link</a>) | @blazeeboy
<br/>
September 29, 2020 | https://www.emadelsaid.com/single-machine-startup-company-system/ | <a href="https://web.archive.org/web/*/https://www.emadelsaid.com/single-machine-startup-company-system/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div dir="auto">
    <p>Technology is moving fast. This is true for the tools we developers are using to
build web applications. You wake up everyday on news about new library or
framework or a new feature in the language you’re already using. Tools are
getting more complex and layers of abstractions are added over each other faster
than I can keep up with. Marketing are getting stronger everyday. Reading
documentation for a framework/program recently triggers me with a lot of
marketing sentences that doesn’t deliver any concrete proof to their claims,
just shiny buzz words that should excite me to use this new tool.</p>

<p>With that I think it’s more sane for me to understand the existing software that
I have on my system before I add anything to it. I’m using Linux on all of my
work machines and servers. That means I should gain a deeper understanding to
the userland applications that comes with my work machine distribution
(Archlinux) and the one I use on my servers (Ubuntu). With a better
understanding to what the system can already do I would gain a more stable
knowledge that has a further expiration date than say a new components
JavaScript library.</p>

<p>This following will be my attempt to aggregate the knowledge I gained to build
an organized Linux system that can host multiple Web services for a small
company. I’ll try to use the system features as much as possible before adding
more software. Software choices will favor boring old software than new and
shiny ones. I’ll try to keep it simple. That doesn’t mean it’ll be an easy task
but a simpler one with less abstraction layers to understand and maintain. I’ll
try to keep what I do relevant to two Linux distributions (Archlinux and
Ubuntu).</p>

<p>At the end of this page we should have a Linux system that’s ready to
host several web applications with all it needs from HTTP servers, database
servers, caching server, logs and monitoring..etc.</p>

<h2 id="a-new-linux-server-where-should-i-start">A New Linux server, Where should I start?</h2>

<p>You can get a good VPS server for cheap price from many providers, Digital ocean
and Linode are famous choices, My favorite provider is Hetzner their prices are
way better and they are very reliable I’m have been a customer for 5 years now
with no issues.</p>

<h2 id="allow-ssh-key-login-and-disable-password-login">Allow SSH key login and disable password login</h2>

<p>The default login to your VPS server uses a username and password so lets
make that better.</p>

<p>We’ll create an RSA key pair for you, on your machine execute this command:</p>


<p>Then copy the generated public key to your server</p>
<div><div><pre><code>ssh-copy-id -i ~/.ssh/id_rsa.pub root@your-server-ip
</code></pre></div></div>

<p>Now SSHing to your server should work without a password, make sure of that
before disabling the password login.</p>

<p>Disable the password login in your server SSH by editing <code>/etc/ssh/sshd_config</code>
and set <code>ChallengeResponseAuthentication</code> and <code>PasswordAuthentication</code> to <code>no</code>.</p>

<p>After editing the file changes won’t apply to the current SSH server until you
reload it. SSH is running as systemd service, to reload it</p>



<p>Here is a bonus, If you already have systemd running on your system you can
execute the systemctl commands with <code>-H root@your-server-ip</code> to execute the
command on your server. You don’t need to login to execute it. the <code>-H</code>
argument will execute the command on the remote server.</p>

<p>For the previous couple commands we used the <code>ssh-keygen</code> and <code>ssh-copy-id</code> from
<code>openssh</code> package and <code>sshd</code> on the server and <code>systemctl</code> from systemd to
reload the service. I encourage you to read more about them. Try reading their
manual page on your machine with <code>man command-name</code>.</p>

<p>If you want to show your server SSH service logs you can use another program
from systemd package <code>journalctl</code> to do that.</p>



<h3 id="make-it-easier-to-ssh">Make it easier to SSH</h3>

<p>On your local machine SSH command reads <code>~/.ssh/config</code> to know about the
servers and their IP addresses and which keys to use and which user…etc so I
do a simple configuration for my SSH server in this file as follows:</p>

<div><div><pre><code>Host vps
     HostName server.ip.address.here
     User root
     IdentityFile ~/.ssh/id_rsa
</code></pre></div></div>

<p>This will allow you to ssh to your server with this</p>



<p>instead of this</p>
<div><div><pre><code>ssh root@server.ip.address.here
</code></pre></div></div>

<p>The <code>IdentityFile</code> line is not necessary if you’re using <code>~/.ssh/id_rsa</code> but if
you generated the VPS private key to another file use it here.</p>

<p>This simple configuration saved me a lot of time.</p>

<p>Many guides on the web recommend having SSHd listening on another port than the
default and disabling the root user login and using another user name. I fail to
see the benefit for that so far but feel free to do it if you wish.</p>

<h2 id="update-the-system-packages">Update the system packages</h2>

<p>Lets update the packages. The command will depend on your distribution.</p>

<div><div><pre><code>Ubuntu: apt update &amp;&amp; apt upgrade &amp;&amp; apt autoremove
Archlinux: pacman -Syu
</code></pre></div></div>

<h2 id="clean-the-system">Clean the system</h2>

<p>I also review the installed packages and uninstall the unnecessary ones, list
your installed packages with</p>

<div><div><pre><code>Ubuntu: apt list --installed
Archlinux: pacman -Qet
</code></pre></div></div>

<p>Then uninstall the ones you feel not useful to you.</p>
<div><div><pre><code>Ubuntu: apt remove &lt;package-name&gt;
Archlinux: pacman -Rs &lt;package-name&gt;
</code></pre></div></div>

<p>And review the running services and stop the ones you don’t need</p>

<div><div><pre><code>systemctl list-unit-files --state=enabled
</code></pre></div></div>

<p>Also the enabled timers</p>



<h2 id="enable-the-firewall">Enable the firewall</h2>

<p>Lets allow SSH only for now and enable the firewall, make sure you can login
with SSH after doing it</p>



<h2 id="setting-up-users-groups">Setting up users groups</h2>

<p>First concept we’ll map from our company is Teams. Each team in the company
we’ll correspond to a Linux group. Teams members will be Linux users in their
teams group. Simple and straight forward.</p>

<p>So for each team in the company we’ll create a user and a group. Initially I was
set to create only a group for each team, but I also need projects to work under
teams not team members. So As creating a new user will also create a group for
him I decided to create a user + group for each team. This way we can use the
user home for projects and for running services (we’ll get in to that later).</p>

<div><div><pre><code>useradd -m teamname
useradd -m membername
usermod -a -G teamname membername
</code></pre></div></div>

<p>So for every team member he’ll have his home directory for private files and
team home for projects and shared data.</p>

<div><div><pre><code>chmod 770 /home/teamname
chmod g+s /home/teamname
</code></pre></div></div>

<p>Each team directory will be readable and writable for each member of the team.</p>

<h2 id="give-access-to-each-team-member">Give access to each team member</h2>

<p>Each user should generate an SSH key and you should get their public key and add
it to their <code>.ssh/authorized_keys</code></p>

<h2 id="our-first-web-service">Our first web service</h2>

<p>Now we have our teams setup and team members on our system, they can login and
use the system existing software, they can download binaries and run it as they
wish.</p>

<p>This means if there is a program one of our teams wrote they can run it by login
and putting the project files in their team home directory and run the program
to listen on a port.</p>

<p>Having this application run as the team user instead of the team member user is
the first challenge we’ll tackle.</p>

<h2 id="running-web-service-as-a-systemd-service">Running web service as a systemd service</h2>

<p>This is the next concept we’ll map from our real world to the system. Each
project we’ll need to run on our system will be equivalent to a systemd service.</p>

<p>Systemd manages our system resources, background services like the http server,
database server, redis server, networking, and alot of things we’ll use some of
them in time.</p>

<p>Systemd allow us to define our own services and run it as a user on this system
as long as we’re logged into the system.</p>

<p>First lets define our service file. In your team home directory you need to
create file for your web service
<code>/home/teamname/.config/systemd/user/myservice.service</code> with similar content</p>

<div><div><pre><code>[<span>Unit</span>]
<span>Description</span>=<span>A</span> <span>useful</span> <span>web</span> <span>service</span>
<span>After</span>=<span>network</span>.<span>target</span>

[<span>Service</span>]
<span>ExecStart</span>=/<span>home</span>/<span>teamname</span>/<span>projects</span>/<span>myservice</span>/<span>program</span>/<span>binary</span>
<span>WorkingDirectory</span>=/<span>home</span>/<span>teamname</span>/<span>projects</span>/<span>myservice</span>
<span>User</span>=<span>teamname</span>
<span>Group</span>=<span>teamname</span>
<span>Restart</span>=<span>always</span>

[<span>Install</span>]
<span>WantedBy</span>=<span>multi</span>-<span>user</span>.<span>target</span>
</code></pre></div></div>

<p>Now reload systemd to discover this new service file</p>



<p>Listing systemd services with <code>systemctl list-unit-files</code> should have your new
service among them.</p>

<p>enabling it and starting it should run your service</p>

<div><div><pre><code>systemctl enable myservice --user
systemctl start myservice --user
</code></pre></div></div>

<p>And when you login to the system with any this team group account the service
will start automatically. When you logout it’ll be stopped.</p>

<p>To make the service run on boot we need to turn on the lingering for the team,
and as this is a common use case you’ll need to do it for all the teams</p>

<div><div><pre><code>loginctl enable-linger teamname
</code></pre></div></div>

<p>The only problem now is that we login as a team member and we want to run the
previous <code>enable</code> and <code>start</code> commands as this team user not our user so the
service runs for the team and any one in the team can control it. If you
executed the commands as you the service will run under the team member account
which will make it stop when he’s logged out.</p>

<p>So we need team member to switch to the group user when they want without
password, the command responsible about that is</p>



<p>But it asks for a password, so to allow team members for <code>teamname</code> to <code>sudo</code>
without password as <code>teamname</code> user. Add the following line to <code>/etc/sudoers</code>
for each team.</p>

<div><div><pre><code>%teamname ALL = (teamname) NOPASSWD: ALL
</code></pre></div></div>

<p>Now any team member can start/stop/enable/disable the service for the team.</p>

<div><div><pre><code>sudo -u teamname systemctl start myservice --user
</code></pre></div></div>

<p>And it’ll keep running after the team member logout, If necessary you can have a
CI user for each team that execute these commands as part of your continuous
integration steps.</p>

<p>So far our service will be used inside the system, so if the service listens on
port 8080 you can curl it with</p>

<div><div><pre><code>curl http://localhost:8080
</code></pre></div></div>

<p>so lets improve this <code>localhost</code> to our actual company name <code>companyname</code></p>



<p>And add your domain name to <code>/etc/hosts</code> to allow local services to resolve it
faster when using it to refer to other services</p>

<div><div><pre><code>127.0.0.1    companyname.tld
</code></pre></div></div>

<p>So now you can curl your service with <code>curl http://companyname.tld:8080</code>
instead.</p>

<h2 id="further-securing-your-web-service">Further securing your web service</h2>

<p>Systemd provides many features to isolate your service so in the case of
misbehaving it’ll do the least damage possible to the system.</p>

<p>Each of these features can be turned …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.emadelsaid.com/single-machine-startup-company-system/">https://www.emadelsaid.com/single-machine-startup-company-system/</a></em></p>]]>
            </description>
            <link>https://www.emadelsaid.com/single-machine-startup-company-system/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24625277</guid>
            <pubDate>Tue, 29 Sep 2020 08:20:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Knowledge Organization (5 ways to capture everything your company knows)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24625204">thread link</a>) | @xdze2
<br/>
September 29, 2020 | https://blog.fibery.io/the-knowledge-organization/ | <a href="https://web.archive.org/web/*/https://blog.fibery.io/the-knowledge-organization/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>In a creative organization — tech startup, management consultancy, law school&nbsp;—&nbsp;Henry Ford’s productivity is much less relevant than Douglas Engelbart’s collective intelligence.</p>
<p><small>Yeah, our objectives were set in <a href="https://www.dougengelbart.org/pubs/papers/scanned/Doug_Engelbart-AugmentingHumanIntellect.pdf" target="_blank" rel="noopener">1962</a>. So what? 🦕</small> 
</p>
<p>Instead of looking for ways to “boost productivity”, we wonder how we can “augment collective intelligence”. Here are our goals as Engelbart put it:</p>
<ul>
<li>more-rapid and better comprehension</li>
<li>gaining a useful degree of comprehension in a situation that previously was too complex</li>
<li>speedier and better solutions</li>
<li><em>finding solutions to problems that before seemed insoluble</em></li>
</ul>
<p><small><a href="https://fibery.io/connect?utm_source=blog.fibery.io&amp;utm_medium=referral&amp;utm_campaign=the-knowledge-organization" target="_blank" rel="noopener">Fibery</a> is a connected workspace for teams. Yes, yet another 🤦‍♀️</small> 
</p>
<p>In a series of joyfully boring essays we are going to explore ways of achieving these goals. Maybe, some ideas will even find their way into Fibery’s vision, who knows.</p>
<p>So where should we start?</p>
<h2>Knowledge Architecture</h2>
<p>At the basic level, it all comes down to capturing, sharing, and generating knowledge. So the first step is to get this knowledge out of bright heads and into a shared space.</p>
<p>How should this space look like? Good old files and folders? Powerful databases? Trendy networks?</p>
<p><small>We resisted the "5 ways to capture everything your company knows" clickbait title 💪</small> 
</p> 
<p>In this article we are going to explore five different approaches to knowledge architecture in an organization. We are looking for the most natural structure that encourages people to discover and share knowledge. The structure should help us to build on top of each other’s ideas. </p>
<p>Starting with…</p>
<h2>Vertical Hierarchy</h2>
<p><span>
      <span></span>
  <img alt="vertical hierarchy" title="Vertical hierarchies in popular tools: Google Drive, Asana, ClickUp, Confluence, and Trello" src="https://blog.fibery.io/static/88213e107b66de17b2f51eba1ae34459/99f37/vertical-hierarchy.png" srcset="https://blog.fibery.io/static/88213e107b66de17b2f51eba1ae34459/6b2ea/vertical-hierarchy.png 275w,
https://blog.fibery.io/static/88213e107b66de17b2f51eba1ae34459/dd45a/vertical-hierarchy.png 550w,
https://blog.fibery.io/static/88213e107b66de17b2f51eba1ae34459/99f37/vertical-hierarchy.png 1100w,
https://blog.fibery.io/static/88213e107b66de17b2f51eba1ae34459/573d3/vertical-hierarchy.png 1650w,
https://blog.fibery.io/static/88213e107b66de17b2f51eba1ae34459/821da/vertical-hierarchy.png 2200w,
https://blog.fibery.io/static/88213e107b66de17b2f51eba1ae34459/97a96/vertical-hierarchy.png 2400w" sizes="(max-width: 1100px) 100vw, 1100px" loading="lazy">
    </span></p>
<p>The most ubiquitous structure is a strict vertical hierarchy.</p>
<p>Some bearded guys borrowed the file cabinet metaphor in 1960s, and it has become a standard since. From cloud drives to note taking and work management tools&nbsp;— it’s all folders and files in some shape or form.</p>
<p>💎 <strong>The onboarding is easy.</strong> With the ubiquity comes familiarity — you don’t need to explain to anyone how folders work.</p>
<p>Unfortunately, <a href="https://youtu.be/oAHbLRjF0vo?t=32" target="_blank" rel="noopener">popular ≠ the best</a>. The strict hierarchy made sense in the real world: a book can only be on a single shelf in a particular room. However, the restrictions of physical objects should not apply to abstract knowledge.</p>
<p>💩 <strong>Every entity has to be exactly in one place.</strong> Two teams collaborating on the same project? Let them decide where the project goes in a vicious pillow fight: </p>
<figure>
    <img src="https://blog.fibery.io/196cdba16c74313951ec270b27ba2a3e/entity-in-exactly-one-place.gif" alt="The same Project should be in two folders at the same time: for Product and Marketing teams">
    <figcaption><p>In our examples we will pretend that all organizations build digital products 🤷‍♀</p></figcaption> 
</figure>
<p>Alternatively, duplicate the data and hope that the intricate two-way sync won’t suprise you with a merge conflict any time soon. </p>
<p>💩 <strong>The organization has to agree on a single hierarchy for all purposes.</strong> Business folks want folders to be initiatives, engineering folks — product areas. Let them decide in a vicious pillow fight:</p>
<p><span>
      <span></span>
  <img alt="competing hierarchies" title="Competing hierarchies: folders as initiatives or product areas" src="https://blog.fibery.io/static/7bae05409fa1f5c4550c798c2725fe3a/99f37/competing-hierarchies.png" srcset="https://blog.fibery.io/static/7bae05409fa1f5c4550c798c2725fe3a/6b2ea/competing-hierarchies.png 275w,
https://blog.fibery.io/static/7bae05409fa1f5c4550c798c2725fe3a/dd45a/competing-hierarchies.png 550w,
https://blog.fibery.io/static/7bae05409fa1f5c4550c798c2725fe3a/99f37/competing-hierarchies.png 1100w,
https://blog.fibery.io/static/7bae05409fa1f5c4550c798c2725fe3a/573d3/competing-hierarchies.png 1650w,
https://blog.fibery.io/static/7bae05409fa1f5c4550c798c2725fe3a/821da/competing-hierarchies.png 2200w,
https://blog.fibery.io/static/7bae05409fa1f5c4550c798c2725fe3a/97a96/competing-hierarchies.png 2400w" sizes="(max-width: 1100px) 100vw, 1100px" loading="lazy">
    </span></p>
<p>And once they decide, there is no going back because…</p>
<p>💩 <strong>Evolution is near impossible.</strong> A company is transitioning from outsource (folders = clients) to product (folders = products) development? The next few months will be fun!</p>
<p>Speaking of fun — what about cross-team collaboration?</p>
<p>💩 <strong>Horizontal connections are lost.</strong> Try mapping this natural workflow into a vertical structure:</p>
<figure>
    <img src="https://blog.fibery.io/0c887eda53c96a94797af94f4886024f/horizontal-connections.gif" alt="Horizontal connections between Marketing, CRM, Software Development, and Dev Ops">
</figure>
<p>The vertical approach produces inflexible information silos. As Ted Nelson noted in the legendary <a href="https://www.goodreads.com/book/show/722414.Computer_Lib_Dream_Machines" target="_blank" rel="noopener">Computer Lib/Dream Machines</a>:</p>
<blockquote>
Hierarchical structures are usually forced and artificial. Interwingularity is not generally acknowledged —&nbsp;people think they can make things hierarchical, categorizable and sequential when they can't.
</blockquote>
<p>So let’s… acknowledge interwingularity?</p>
<h2>Flat Network</h2>
<p><span>
      <span></span>
  <img alt="flat network" title="Flat network: nodes representing thoughts and ideas connected to each other" src="https://blog.fibery.io/static/09bb5795dd9691396b52ee3de1d05c32/99f37/flat-network.png" srcset="https://blog.fibery.io/static/09bb5795dd9691396b52ee3de1d05c32/6b2ea/flat-network.png 275w,
https://blog.fibery.io/static/09bb5795dd9691396b52ee3de1d05c32/dd45a/flat-network.png 550w,
https://blog.fibery.io/static/09bb5795dd9691396b52ee3de1d05c32/99f37/flat-network.png 1100w,
https://blog.fibery.io/static/09bb5795dd9691396b52ee3de1d05c32/573d3/flat-network.png 1650w,
https://blog.fibery.io/static/09bb5795dd9691396b52ee3de1d05c32/821da/flat-network.png 2200w,
https://blog.fibery.io/static/09bb5795dd9691396b52ee3de1d05c32/97a96/flat-network.png 2400w" sizes="(max-width: 1100px) 100vw, 1100px" loading="lazy">
    </span></p>
<p>In a flat network we are free to form arbitrary connections between nodes (pages).</p>
<p>In a good network, these connections are bi-directional: if two pages are related, we’ll always see the connection on both of them. Unfortunately, this is not how most networks work — yet 🤞.</p>
<p>Lately, we’ve seen a revival of the “networked thought”&nbsp;fueled by the idea that… </p>
<p>💎 <strong>Free associations are closer to how brain works.</strong> Thoughts are not neatly packed in file cabinets: rather one leads to another and yet another. In a flat network this means that the “campaign → lead →&nbsp;bug&nbsp;→&nbsp;version” workflow we mentioned above works like a charm.</p>
<p>💎 <strong>Knowledge naturally accumulates.</strong> There is no limit on the size of the network and no restrictions on how it should grow.</p>
<p>Just like our brains, flat networks are great at working with unstructured knowledge but suck when it comes to structured data.</p>
<p>💩 <strong>Querying data is hard.</strong> All pages have either the same or unpredictable attributes. Getting all high-priority features or all customers due to renew the next month is nearly impossible.</p>
<p>💩 <strong>Visualizations are limited.</strong> Most vizualizations rely on structured data — so forget about a Kanban board with swimlanes, an event calendar, a gantt chart, or a hierarchical list. </p>
<p>💩 <strong>Repeatable processes are undiscoverable.</strong> Since there are no required (or even desired) attributes and relations, there is nothing to nudge folks into a predictable workflow. You have to explain each newcomer that “we decompose Epic into Stories, estimate these Stories, and plan into Sprints” —&nbsp;a flat network cannot guide them.   </p>
<p>So we need both horizontal and vertical connections as well as the ability to handle structured data. Sounds pretty much like…</p>
<h2>Relational Databases</h2>
<p><span>
      <span></span>
  <img alt="relational databases" title="Relational databases: each standalone database stores multiple connected tables" src="https://blog.fibery.io/static/4b4502a9f4fa425f6646c5719df7b3f0/99f37/relational-databases.png" srcset="https://blog.fibery.io/static/4b4502a9f4fa425f6646c5719df7b3f0/6b2ea/relational-databases.png 275w,
https://blog.fibery.io/static/4b4502a9f4fa425f6646c5719df7b3f0/dd45a/relational-databases.png 550w,
https://blog.fibery.io/static/4b4502a9f4fa425f6646c5719df7b3f0/99f37/relational-databases.png 1100w,
https://blog.fibery.io/static/4b4502a9f4fa425f6646c5719df7b3f0/573d3/relational-databases.png 1650w,
https://blog.fibery.io/static/4b4502a9f4fa425f6646c5719df7b3f0/821da/relational-databases.png 2200w,
https://blog.fibery.io/static/4b4502a9f4fa425f6646c5719df7b3f0/97a96/relational-databases.png 2400w" sizes="(max-width: 1100px) 100vw, 1100px" loading="lazy">
    </span></p>
<p>In a relational database, both vertical and horizontal connections are present through one-to-many and many-to-many relations. Each table has its own attributes making home for structured data.</p>
<p>💎 <strong>The structure is flexible.</strong> The knowledge architect is free to create as many or as few tables as needed and connect them in the way it makes sense to the particular organization. As organization evolves, she creates more tables and adds more relations.</p>
<p><small>A common pitfall is to design a database that doesn't satisfy at least <a href="https://en.wikipedia.org/wiki/Database_normalization" target="_blank" rel="noopener">3NF</a> and struggle with complicated queries and data duplication.  
 
  
 </small>
</p>
<p>💩 <strong>Building a database requires time and skill.</strong> This is the price your pay for the flexibility. While <a href="https://airtable.com/" target="_blank" rel="noopener">Airtable</a> has democratized online databases, the knowledge architect still has to understand how data normalization works —&nbsp;at least intuitively.</p>
<p>💩 <strong>It’s either one unmanageable, or many disconnected databases.</strong> When all teams share the same database, it quickly becomes huge and messy. When teams split into several bases, it’s “hello” to information silos and “bye” to cross-team collaboration. Instead of sharing data, it’s all back to pillow fights — where should the customers table go, in sales or marketing db.</p>
<p>On the bright side…</p>
<p>💎 <strong>Pretty much any visualization or query is possible.</strong> Tables, boards, charts, and even maps — with data filtered and sorted as you desire. If a database doesn’t have a visualization out of the box, you can usually build one.</p>
<p>While the structured data feels at home…</p>
<p>💩 <strong>Unstructured knowledge is not welcome.</strong> Collaborative documents, whiteboards, and multimedia are second-class citizens at best and are simply missing at worst.</p>
<p>Is there a way to combine structured and unstructured knowledge, vertical and horizontal connections?</p>
<h2>Single-Purpose Hierarchical Networks</h2>
<p><span>
      <span></span>
  <img alt="single purpose networks" title="Single-purpose hierarchical networks: Jira for software development, Hubspot&nbsp;for sales CRM" src="https://blog.fibery.io/static/415372b75f91438859beffc6af54e4a4/99f37/single-purpose-networks.png" srcset="https://blog.fibery.io/static/415372b75f91438859beffc6af54e4a4/6b2ea/single-purpose-networks.png 275w,
https://blog.fibery.io/static/415372b75f91438859beffc6af54e4a4/dd45a/single-purpose-networks.png 550w,
https://blog.fibery.io/static/415372b75f91438859beffc6af54e4a4/99f37/single-purpose-networks.png 1100w,
https://blog.fibery.io/static/415372b75f91438859beffc6af54e4a4/573d3/single-purpose-networks.png 1650w,
https://blog.fibery.io/static/415372b75f91438859beffc6af54e4a4/821da/single-purpose-networks.png 2200w,
https://blog.fibery.io/static/415372b75f91438859beffc6af54e4a4/97a96/single-purpose-networks.png 2400w" sizes="(max-width: 1100px) 100vw, 1100px" loading="lazy">
    </span></p>
<p>Most single-purpose work management tools are, basically, hierarchical networks. Tool vendors understand they need the best of all worlds to foster collaboration.</p>
<p>💎 <strong>Structured and unstructured knowledge is mixed.</strong> You set feature priority, but you also write specs. You advance deals through a pipeline, but also take meeting notes. Hopefully, digital whiteboards and interactive embeds will also be welcome —&nbsp;one day 🤞.</p>
<p>💎 <strong>Multiple parallel hierarchies coexist.</strong> A Task belongs to a Sprint, but also to a Version and a Component. A few pillows saved.</p>
<p> 💎 <strong>Visualizations are tailor-made to specific workflows.</strong> If a team adapts its behavior to the tool, it’s rewarded with a top-notch user experience.</p>
<p>Wait, but what if a team is happy with its habits and doesn’t want to kneel before the tool? That’s the catch.</p>
<p>💩 <strong>Single-purpose is synonymous with inflexible.</strong> A team has grown, and you need an extra level of hierarchy — 🤷‍♀️. You call it Deals, not Opportunities — 🤷‍♀️. Haven’t yet settled on a process and are experimenting with workflows —&nbsp;🤷‍♀️. Want to look at the data from a different angle&nbsp;— 🤷‍♀️.</p>
<p>Teams are diverse so each one gets its own purpose-built network.</p>
<p>💩 <strong>Networks are isolated.</strong> We are back to information silos, islands of knowledge, bubbles of data, please stop me, idea zoos, insight prisons. Because of the incompatible data models, cross-network integrations are always limited and clunky.</p>
<p><span>
      <span></span>
  <img alt="isolated networks" title="An isolated Jira network with feedback, ideas, campaign, and leads excluded" src="https://blog.fibery.io/static/f998f8d59e6dbf7c65eff943d52612c6/99f37/isolated-networks.png" srcset="https://blog.fibery.io/static/f998f8d59e6dbf7c65eff943d52612c6/6b2ea/isolated-networks.png 275w,
https://blog.fibery.io/static/f998f8d59e6dbf7c65eff943d52612c6/dd45a/isolated-networks.png 550w,
https://blog.fibery.io/static/f998f8d59e6dbf7c65eff943d52612c6/99f37/isolated-networks.png 1100w,
https://blog.fibery.io/static/f998f8d59e6dbf7c65eff943d52612c6/573d3/isolated-networks.png 1650w,
https://blog.fibery.io/static/f998f8d59e6dbf7c65eff943d52612c6/821da/isolated-networks.png 2200w,
https://blog.fibery.io/static/f998f8d59e6dbf7c65eff943d52612c6/97a96/isolated-networks.png 2400w" sizes="(max-width: 1100px) 100vw, 1100px" loading="lazy">
    </span></p>
<p>So what can we have instead of many single-purpose networks? A single generic…</p>
<h2>Hierarchical Network</h2>
<figure>
    <span>
      <span></span>
  <img alt="Wait, was it all just content marketing? 😱" title="Hierarchical network in a product company and a creative agency: multiple hierarchies coexist" src="https://blog.fibery.io/static/d1f2d92c65149efda95f83319d730df8/99f37/hierarchical-network.png" srcset="https://blog.fibery.io/static/d1f2d92c65149efda95f83319d730df8/6b2ea/hierarchical-network.png 275w,
https://blog.fibery.io/static/d1f2d92c65149efda95f83319d730df8/dd45a/hierarchical-network.png 550w,
https://blog.fibery.io/static/d1f2d92c65149efda95f83319d730df8/99f37/hierarchical-network.png 1100w,
https://blog.fibery.io/static/d1f2d92c65149efda95f83319d730df8/573d3/hierarchical-network.png 1650w,
https://blog.fibery.io/static/d1f2d92c65149efda95f83319d730df8/821da/hierarchical-network.png 2200w,
https://blog.fibery.io/static/d1f2d92c65149efda95f83319d730df8/97a96/hierarchical-network.png 2400w" sizes="(max-width: 1100px) 100vw, 1100px" loading="lazy">
    </span>
    <figcaption>Wait, was it all just content marketing? 😱</figcaption>
  </figure>
<p>Each node in the network is of a particular type (Objective, Customer). Types form hierarchies: Objective has several Key Results, Customer — many logged Chats and a few too many reported Bugs.</p>
<p>A single generic hierarchical network is capable of holding all the knowledge of an organization. So why aren’t these networks common?</p>
<p>First of all, the vertical hierarchy has become a no-brainer default, and we rarely stopped to ask if there might be a better generic storage architecture. This “things have already been figured out” effect has been common across computer science since 1980s. Bret Victor put it best: </p>
<p><small>Replace "programming" with "knowledge architecture" (29:52—31:17)
 </small>
</p>
<p> <iframe src="https://www.youtube-nocookie.com/embed/8pTEmbeENF4?start=1792" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe> </p>
<p>Second, there hasn’t been a platform to easily build such networks. Why hasn’t there been a platform? Well, as we have found out in the last 3 <a href="https://fibery.io/anxiety?utm_source=blog.fibery.io&amp;utm_medium=referral&amp;utm_campaign=the-knowledge-organization" target="_blank" rel="noopener">miserable</a> years, the platform is damn hard to build&nbsp;—&nbsp;interview what is left of our engineers.</p>
<p>What’s so special about the hierarchical network? </p>
<p>💎 <strong>Adapts and evolves with an organization.</strong> It’s easy to start with a simple network and create more hierarchies as the company grows and diversifies. Each team constructs its own subnetwork —&nbsp;connected to the wider pool of knowledge. </p>
<p>Here is Ted Nelson again:</p>
<p><small>The first chapters of …</small></p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.fibery.io/the-knowledge-organization/">https://blog.fibery.io/the-knowledge-organization/</a></em></p>]]>
            </description>
            <link>https://blog.fibery.io/the-knowledge-organization/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24625204</guid>
            <pubDate>Tue, 29 Sep 2020 08:04:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When the Impact of Digital Tech on Our Mental Health Begins to Matter]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24625172">thread link</a>) | @Lima_Writes
<br/>
September 29, 2020 | https://lifebeyond.one/blogs/tech-impact/when-the-impact-of-digital-tech-on-our-mental-health-begins-to-matter | <a href="https://web.archive.org/web/*/https://lifebeyond.one/blogs/tech-impact/when-the-impact-of-digital-tech-on-our-mental-health-begins-to-matter">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <div>
    <div>
      <div id="shopify-section-article-template">

<div>
  <section name="9b04">

<div>
<div>
<h3 name="d56f">Seeing ourselves through the eyes of our children and our&nbsp;tech</h3>
<figure name="c560"><img data-image-id="1*vr4Rb1HI9B3nHj0E1snGoA.jpeg" data-width="1161" data-height="728" src="https://cdn-images-1.medium.com/max/1200/1*vr4Rb1HI9B3nHj0E1snGoA.jpeg"></figure>
<p name="2ab1"><strong>The above photo is from the </strong><a href="https://weconomics.org/events/congres2019/congresprogramma/" data-href="https://weconomics.org/events/congres2019/congresprogramma/" rel="noopener noreferrer" target="_blank"><strong>Weconomics convention</strong></a><strong> last year, where I had the opportunity to pre-present my book </strong><a href="https://lifebeyond.one/" data-href="https://lifebeyond.one/" rel="noopener noreferrer" target="_blank"><strong>Life Beyond the Touch Screen</strong></a><strong> before its official launch in 2020. Something really interesting happened during my session.</strong></p>
<p name="da59">I never presented my book as much as I simply told a story about my personal experience with technology and mental health.&nbsp;</p>
<p name="f245">In my presentation and workshop I mostly just shared the story about <a href="https://lifebeyond.one/blogs/tech-impact/smartphone-addiction-burnout-and-balance?_pos=2&amp;_sid=0e6e4570f&amp;_ss=r" data-href="https://lifebeyond.one/blogs/tech-impact/smartphone-addiction-burnout-and-balance?_pos=2&amp;_sid=0e6e4570f&amp;_ss=r" rel="noopener noreferrer" target="_blank">my own experience with digital dependency and with burnout</a>.&nbsp;</p>
<p name="5820">In that story I recount how for about two years I was simply asking far too much from myself; my body and my brain. And how looking back, I could easily retrace the steps that led to my inevitable collapse, more or less.</p>
<p name="f412">The fun part is that — though I do mention here and there that <a href="https://lifebeyond.one/blogs/tech-impact/smartphone-addiction-technology-dependency-science-and-statistics?_pos=1&amp;_sid=76458b6a6&amp;_ss=r" data-href="https://lifebeyond.one/blogs/tech-impact/smartphone-addiction-technology-dependency-science-and-statistics?_pos=1&amp;_sid=76458b6a6&amp;_ss=r" rel="noopener noreferrer" target="_blank">study after study is showing the possible heinous effects overuse of digital technology</a> can and probably does have on our mental health — </p>
<blockquote name="302e">Digital technology is not the root cause in my story.</blockquote>
<h4 name="dbf8">Digital tech is your black&nbsp;mirror</h4>
<p name="a727">Digital technology, in my personal experience, is simply a (black) mirror that shows us what we’re <em>actually</em> giving our focus and attention to — as compared to what we <em>think</em> our priorities and values are. If we let it, it can show us what’s really going on under the surface.</p>
<p name="2187">My talk at the Weconomics convention was by far the best received ‘performance’ I have ever given. The reactions from listeners were easily 10x those of my greatest and best performances in my time as a musician.</p>
<p name="969a">I think it had to do with relevance, vulnerability and authenticity.</p>
<p name="753a">But there was something else that absolutely stood out to me as well.</p>
<h4 name="c19b">When do things start to matter to&nbsp;humans?</h4>
<p name="e8ee">I saw faces in the crowd change, and I noticed the tone of the discussion become much, much more serious when we started talking about the impacts of tech on our younger generations. Our kids.</p>
<blockquote name="530f">What if our children are already, inevitably headed to digitally-induced mental health disaster, and there’s not much we can do now to stop the train?</blockquote>
<p name="7f01">Touching as it may have felt, it also had me worried. Why can we suddenly see how serious something can really be impacting our focus, energy, creativity, productivity — generally; our growth and wellbeing — when it’s about our children? Why can’t we see that when it’s about <em>ourselves</em>?</p>
<p name="e05c">You want my blunt, honest opinion? I think it’s a combination of an underdeveloped capacity to seriously self-reflect as human adults, with an underdeveloped degree of self-love.&nbsp;</p>
<p name="3499">And the funny thing is: if we want a better world and a better future for our children — it starts exactly there: with ourselves, our self-love and self-awareness.&nbsp;</p>
<p name="ff4e">Namasté, peoples.</p>
</div>
</div>
</section>
<section name="79ac">


</section>
</div>


  <!-- /snippets/social-sharing.liquid -->







</div>
    </div>
  </div>
</article></div>]]>
            </description>
            <link>https://lifebeyond.one/blogs/tech-impact/when-the-impact-of-digital-tech-on-our-mental-health-begins-to-matter</link>
            <guid isPermaLink="false">hacker-news-small-sites-24625172</guid>
            <pubDate>Tue, 29 Sep 2020 07:57:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Keep your GitHub forks up to date]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24625051">thread link</a>) | @reconquestio
<br/>
September 29, 2020 | https://samizdat.dev/keep-your-github-forks-up-to-date/ | <a href="https://web.archive.org/web/*/https://samizdat.dev/keep-your-github-forks-up-to-date/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<article>
    <p>Sometimes I do fork repositories and do some tweaks here and there for my personal needs which ain’t
really going to be merged into the upstream repository.</p>
<p>One thing that used to concern me is that I needed to manually rebase my changes onto the upstream
to have new goods but keep my changes on top of them.</p>
<p>Fortunately, GitHub Actions supports the <code>schedule</code> trigger for workflows and this is what we are
going to use.</p>
<p>The CI plan is simple and straightforward:</p>
<ul>
<li>Tigger by a schedule or by a manual run.</li>
<li>Fetch &amp; checkout repository.</li>
<li>Specify an upstream Git URL. Unfortunately, GitHub doesn’t expose an environment variable of a
upstream repository (or I didn’t find it).</li>
<li>Rebase onto upstream.</li>
<li>Push changes.</li>
</ul>
<div><pre><code data-lang="yaml"><span>name</span><span>:</span><span> </span><span>'Rebase'</span><span>
</span><span>
</span><span></span><span>on</span><span>:</span><span>
</span><span>  </span><span>schedule</span><span>:</span><span>
</span><span>    </span>- <span>cron</span><span>:</span><span> </span><span>'*/15 * * * *'</span><span>
</span><span>  </span><span>workflow_dispatch</span><span>:</span><span>
</span><span>
</span><span>
</span><span></span><span>jobs</span><span>:</span><span>
</span><span>  </span><span>rebase</span><span>:</span><span>
</span><span>    </span><span>runs-on</span><span>:</span><span> </span>ubuntu-latest<span>
</span><span>    </span><span>steps</span><span>:</span><span>
</span><span>    </span>- <span>uses</span><span>:</span><span> </span>actions/checkout@v2<span>
</span><span>    </span>- <span>uses</span><span>:</span><span> </span>shitiomatic/forkbacon@master<span>
</span><span>      </span><span>with</span><span>:</span><span>
</span><span>        </span><span>upstream_url</span><span>:</span><span> </span><span>"upstream url here"</span><span>
</span><span>        </span><span>upstream_branch</span><span>:</span><span> </span><span>"master"</span><span>
</span><span>        </span><span>branch</span><span>:</span><span> </span><span>"master"</span><span>
</span><span>        </span><span>method</span><span>:</span><span> </span><span>"rebase"</span><span>
</span></code></pre></div><p>Almost there. GitHub doesn’t sync &amp; install schedules for forked repositoies without a manual run or
an additional push. Go to Actions, find Rebase workflow and click on the Run workflow button.</p>
<p>That’s it, really. If the rebase fails, GitHub will send you an email letting you know about it.</p>
</article>

        </div></div>]]>
            </description>
            <link>https://samizdat.dev/keep-your-github-forks-up-to-date/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24625051</guid>
            <pubDate>Tue, 29 Sep 2020 07:33:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Designing an accessible color palette with magic numbers]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 12 (<a href="https://news.ycombinator.com/item?id=24624914">thread link</a>) | @darekkay
<br/>
September 29, 2020 | https://darekkay.com/blog/accessible-color-palette/ | <a href="https://web.archive.org/web/*/https://darekkay.com/blog/accessible-color-palette/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>A low text contrast is the <a href="https://webaim.org/projects/million/" target="_blank" rel="noopener">most common accessibility issue</a>. 86% of the top 1,000,000 websites have at least one contrast ratio violation, which may lead to a bad user experience. Our favorite orange website isn’t leading by example, either. Some comments are almost unreadable:</p><figure><picture><img src="https://darekkay.com/blog/accessible-color-palette/hacker-news.png" srcset="https://darekkay.com/blog/accessible-color-palette/hacker-news.png, https://darekkay.com/blog/accessible-color-palette/hacker-news-2x.png 2x" alt="Insufficient contrast ratio on Hacker News"></picture><figcaption>Insufficient contrast ratio on Hacker News</figcaption></figure><p>There are various tools that help us <em>identify</em> and <em>fix</em> contrast ratio issues on our websites. This post presents an approach for designing and structuring color palettes so that we can prevent such issues <em>before</em> they arise: “magic numbers”.</p><h2 id="Which-contrast-ratio-is-accessible"><a href="#Which-contrast-ratio-is-accessible" title="Which contrast ratio is accessible?"></a>Which contrast ratio is accessible?</h2><p>How do we know whether the contrast ratio between a text and its background is sufficient? The <em>Web Content Accessibility Guidelines</em> (WCAG) <a href="https://www.w3.org/TR/WCAG20-TECHS/G18.html" target="_blank" rel="noopener">define</a> minimum required contrast ratios, based on colors, text properties (size, boldness) and conformance levels (AA vs. AAA):</p><figure><table><thead><tr><th></th><th>Level AA</th><th>Level AAA</th></tr></thead><tbody><tr><td><strong>small text</strong></td><td>4.5+</td><td>7+</td></tr><tr><td><strong>large text</strong></td><td>3+</td><td>4.5+</td></tr></tbody></table><figcaption>Minimum required contrast ratio values</figcaption></figure><p>Note: <em>large text</em> is defined as <em>19px+ bold</em> or <em>24px+ normal</em>.</p><p>As a rule of thumb, try to go for a <strong>4.5:1</strong> minimum contrast ratio, which will pass <strong>WCAG AA</strong> independent of the text size. This provides a good cost-value trade-off and is often the legal accessibility requirement.</p><p>Calculating the accessibility conformance manually is tedious. Instead, I suggest using a tool like <a href="https://contrast-ratio.com/" target="_blank" rel="noopener">contrast-ratio.com</a>. DevTools in <a href="https://developer.mozilla.org/en-US/docs/Tools/Accessibility_inspector#Color_contrast" target="_blank" rel="noopener">Firefox</a> and <a href="https://umaar.com/dev-tips/236-accessible-colour-suggestions/" target="_blank" rel="noopener">Chrome</a> provide great built-in browser support. Finally, <a href="https://github.com/dequelabs/axe-cli" target="_blank" rel="noopener">axe-core</a> will scan a website for all kinds of accessibility violations.</p><p>Those tools are a great way to find contrast ratio issues, but let me describe a technique to prevent them in the first place.</p><h2 id="Magic-numbers"><a href="#Magic-numbers" title="Magic numbers"></a>Magic numbers</h2><p>Most color palettes divide their colors into grades (e.g. <code>pink-10</code> … <code>pink-90</code>).</p><p>Let’s define a <em>difference between two color grades</em> as <strong>magic number</strong>, e.g.:</p><ul><li>Colors: <code>blue-80</code> and <code>orange-30</code></li><li>Magic number: <code>80 - 30</code> = <code>50</code></li></ul><p>What if we could find a magic number for the whole palette that ensures a sufficient color contrast between two colors? The first time I’ve heard about this concept was in a <a href="https://pspeter3.com/blog/2020/02/19/accessible-contrast-shades/" target="_blank" rel="noopener">blog post</a> from Phips Peter. I’ve learned about the <a href="https://designsystem.digital.gov/design-tokens/color/overview/" target="_blank" rel="noopener">U.S. Web Design System</a> and was immediately hooked. The color system provides the following magic numbers:</p><ul><li>A magic number of <strong>40+</strong> ensures a contrast ratio of <strong>3+</strong></li><li>A magic number of <strong>50+</strong> ensures a contrast ratio of <strong>4.5+</strong></li><li>A magic number of <strong>70+</strong> ensures a contrast ratio of <strong>7+</strong></li></ul><p>By looking at the color names, I know that <code>red-40</code> and <code>gray-90</code> (= <code>50</code>) will definitely pass <em>WCAG AA</em> (required contrast ratio <code>4.5+</code>), while <code>red-60</code> and <code>gray-90</code> (= <code>30</code>) will not. This leads to a <em>fantastic</em> designer/developer experience. I don’t have to use a contrast checker or look anything up to ensure a sufficient contrast ratio. A difference of 50 or more is all I care about.</p><h2 id="Calculating-magic-numbers-for-an-existing-color-palette"><a href="#Calculating-magic-numbers-for-an-existing-color-palette" title="Calculating magic numbers for an existing color palette"></a>Calculating magic numbers for an existing color palette</h2><p>Some libraries define their magic numbers in the documentation, but what about others?</p><p>I have written <a href="https://github.com/darekkay/a11y-contrast" target="_blank" rel="noopener">a11y-contrast</a> to calculate the magic numbers for any color palette that follows a grade naming pattern (e.g. <code>red-20</code>). This tool also finds all violations for any given magic number. This way you can prevent regression issues after adding or adjusting a color value.</p><figure><picture><img src="https://darekkay.com/blog/accessible-color-palette/a11y-contrast.png" srcset="https://darekkay.com/blog/accessible-color-palette/a11y-contrast.png, https://darekkay.com/blog/accessible-color-palette/a11y-contrast-2x.png 2x" alt="CLI output with magic numbers and a list of violations"></picture><figcaption>CLI output with magic numbers and a list of violations</figcaption></figure><p>I’ve calculated the magic numbers for some common color palettes:</p><table><thead><tr><th></th><th>3+</th><th>4.5+</th><th>7+</th></tr></thead><tbody><tr><td><a href="https://designsystem.digital.gov/design-tokens/color/system-tokens/" target="_blank" rel="noopener">USWDS</a></td><td>40</td><td>50</td><td>70</td></tr><tr><td><a href="https://www.ibm.com/design/v1/language/resources/color-library/" target="_blank" rel="noopener">IBM v1</a></td><td>50</td><td>60</td><td>70</td></tr><tr><td><a href="https://github.com/carbon-design-system/carbon/tree/master/packages/colors" target="_blank" rel="noopener">IBM Carbon v2.1</a></td><td>50</td><td>50</td><td>70</td></tr><tr><td><a href="https://tailwindcss.com/docs/customizing-colors/#default-color-palette" target="_blank" rel="noopener">Tailwind v1</a></td><td>60</td><td>70</td><td>80</td></tr><tr><td><a href="https://github.com/tailwindlabs/tailwindcss/pull/2132" target="_blank" rel="noopener">Tailwind v2</a> (proposal)</td><td>50</td><td>60</td><td>80</td></tr><tr><td><a href="https://yeun.github.io/open-color/" target="_blank" rel="noopener">Open Color</a></td><td>-</td><td>-</td><td>-</td></tr></tbody></table><p>Here are my takeaways:</p><ul><li><strong>USWDS</strong> defines <em>by far</em> the most colors (461!), and yet it uses the smallest magic numbers. This leads to a much wider spectrum of allowed color combinations than any of the other color palettes I’ve checked.</li><li><strong>Open color</strong> doesn’t have <em>any</em> magic numbers. This means I cannot reliably derive the contrast ratio from the color naming (e.g., <code>gray-90/red-20</code> is fine, but <code>red-90/red-20</code> is not).</li><li>Both <a href="https://github.com/uswds/uswds/issues/3329" target="_blank" rel="noopener">USWDS</a> and <a href="https://github.com/carbon-design-system/carbon/issues/6130" target="_blank" rel="noopener">IBM Carbon</a> previously contained minor violations, showing the importance of automatic tests.</li></ul><h2 id="Defining-luminance-bounds-with-fixed-magic-numbers"><a href="#Defining-luminance-bounds-with-fixed-magic-numbers" title="Defining luminance bounds with fixed magic numbers"></a>Defining luminance bounds with fixed magic numbers</h2><p>Predefined color palettes are great, but what if we want to change or add a color? What grade does a certain color map to?</p><p>Because the contrast ratio between two colors depends only on their <a href="https://www.w3.org/TR/WCAG20-TECHS/G17.html" target="_blank" rel="noopener">luminance values</a>, it is possible to create a mapping from a color to a grade between 0 and 100. For the USWDS color palette, here are the <a href="https://github.com/uswds/uswds/issues/3329#issuecomment-594762982" target="_blank" rel="noopener">luminance bounds</a>:</p><table><thead><tr><th>grade</th><th>min luminance (%)</th><th>max luminance (%)</th></tr></thead><tbody><tr><td>0</td><td>100</td><td>100</td></tr><tr><td>5</td><td>85</td><td>93</td></tr><tr><td>10</td><td>75</td><td>82</td></tr><tr><td>20</td><td>50</td><td>65</td></tr><tr><td>30</td><td>35</td><td>45</td></tr><tr><td>40</td><td>25</td><td>30</td></tr><tr><td>50</td><td>17.5</td><td>18.3</td></tr><tr><td>60</td><td>10</td><td>12.5</td></tr><tr><td>70</td><td>5</td><td>7</td></tr><tr><td>80</td><td>2</td><td>4</td></tr><tr><td>90</td><td>0.05</td><td>1.5</td></tr><tr><td>100</td><td>0</td><td>0</td></tr></tbody></table><p><a href="https://github.com/thisisdano" target="_blank" rel="noopener">Dan O. Williams</a> — a USWDS maintainer — optimized those values for <em>consistency</em> instead of <em>coverage</em>. This means there are more colors that don’t fit into <em>any</em> bound, even though they would technically pass the WCAG contrast ratio. While this setup is more constraining, I agree with the consistency benefits.</p><blockquote><p>It’s important that our color system be consistent and predictable, that users know what they’re getting when they choose a color of a certain grade. This makes us inclined to favor smaller, more equal ranges, and consistent spacing between ranges.</p></blockquote><p>If you want to calculate the luminance value and the potential USWDS grade of any color, check out my <a href="https://darekkay.com/dev/color-tools.html">Color Tools</a>.</p><picture><source type="image/webp" srcset="https://darekkay.com/blog/accessible-color-palette/color-palette.webp, https://darekkay.com/blog/accessible-color-palette/color-palette-2x.webp 2x"><img src="https://darekkay.com/blog/accessible-color-palette/color-palette.jpg" srcset="https://darekkay.com/blog/accessible-color-palette/color-palette.jpg, https://darekkay.com/blog/accessible-color-palette/color-palette-2x.jpg 2x" alt=""></picture><h2 id="Conclusion"><a href="#Conclusion" title="Conclusion"></a>Conclusion</h2><p>Let me summarize all the theory into some <strong>actionable advice</strong>. There are two ways to create an accessible color palette with <em>magic numbers</em>:</p><ol><li>Create a color palette first and calculate the magic numbers with <a href="https://github.com/darekkay/a11y-contrast" target="_blank" rel="noopener">a11y-contrast</a>. Depending on the colors, the magic numbers might be rather high or even non-existent (see Open Color).</li><li>Define luminance bounds with fixed magic numbers and use only colors that can be mapped. This approach is more constraining and requires more work, but the result is a future-proof and consistent color palette.</li></ol><p>If you don’t want to go through all the work, I suggest you try out the <a href="https://designsystem.digital.gov/design-tokens/color/system-tokens/" target="_blank" rel="noopener">USWDS color palette</a>.</p></div></div></div>]]>
            </description>
            <link>https://darekkay.com/blog/accessible-color-palette/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24624914</guid>
            <pubDate>Tue, 29 Sep 2020 07:09:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Security September: Still Early Days for ABAC]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24624908">thread link</a>) | @boyter
<br/>
September 29, 2020 | https://onecloudplease.com/blog/security-september-still-early-days-for-abac | <a href="https://web.archive.org/web/*/https://onecloudplease.com/blog/security-september-still-early-days-for-abac">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">

		<div data-page-title="Security September: Still Early Days for ABAC – One Cloud Please">

			<section>

	

</section>

<section>

	<p><img src="https://onecloudplease.com/images/posts/tag.jpg" alt=""></p>

<p><em>This is the final part of a 5-part series on AWS exploits and similar findings discovered over the course of 2020. All findings discussed in this series have been <a href="https://aws.amazon.com/security/vulnerability-reporting/">disclosed</a> to the AWS security team and had patches rolled out to all affected regions, where necessary. A big thanks to my friend and fellow Australian <a href="https://twitter.com/__steele">Aidan Steele</a> for co-authoring this series with me. Check out parts <a href="https://onecloudplease.com/blog/security-september-escaping-codebuild">2</a> and <a href="https://onecloudplease.com/blog/security-september-cataclysms-in-the-cloud-formations">4</a> for his work!</em></p>

<p>In the final part of this series we take a look at an exploit that let us tag S3 buckets without permission, even with an explicit deny, and what this means for attribute-based access control (ABAC).</p>

<h2 id="discovery">Discovery</h2>

<p>I recently embarked on a <a href="https://github.com/iann0036/aws-leastprivilege">project</a> that attempts to generate detailed IAM policy statements given a defined CloudFormation template. I admit this was a little too ambitious and this didn’t get too far, but the process required me to create valid CloudFormation templates which hit every possible field for a resource type so I could incrementally determine what permissions were needed on a field-by-field basis.</p>

<p>When performing this for the <code>AWS::S3::Bucket</code> type, I eventually had a template where I had to define the <code>Tags</code> field. To my surprise, the stack successfully updated without the <code>s3:PutBucketTagging</code> permission I expected to require (as referenced in the <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazons3.html">ARC</a> documentation).</p>

<p>After some testing, I determined that S3 buckets within a stack could have its tags modified without the presence of the tagging permission, or even if an explicit deny IAM permission is set. I could also bring existing S3 buckets into a stack using the CloudFormation import feature and adjust tags for the imported resource.</p>

<p>I never had the exact reason for this discrepancy explained to me, but my theory relates to the automatic application of <a href="https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-resource-tags.html">stack tags</a> to supported resources within a stack. These stack tags are prefixed with <code>aws:</code>, which is a prefix that standard users are not permitted to use. I believe that the application of these stack tags are performed through an internal endpoint and that perhaps the S3 tag application was also occurring through this endpoint, which means that the usual <a href="https://aws.amazon.com/blogs/security/protect-sensitive-data-in-the-cloud-with-automated-reasoning-zelkova/">automated reasoning</a> was not being performed - however this is just a theory.</p>



<p>I <a href="https://aws.amazon.com/security/vulnerability-reporting/">raised</a> the issue directly with the AWS security team, who got back to me within a day.</p>

<p>This issue had some complications that led to a couple of delays with the rollout likely due to the fact that some in-depth analysis was occurring to determine which customers would be affected and, if necessary, reach out to them to ensure their workloads wouldn’t be affected by providing remediation steps. Per those communications, it seems RDS and ELB had similar issues.</p>

<p>If users attempt to perform the S3 action today, they’d receive the following stack event:</p>

<p><img src="https://onecloudplease.com/images/posts/s3-cfn-permission-1.png" alt=""></p>

<h2 id="on-attribute-based-access-control-abac">On Attribute-Based Access Control (ABAC)</h2>

<p>This incident did not change my view on <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/introduction_attribute-based-access-control.html">ABAC</a> and only strengthened my beliefs that it is a high risk approach for the security of your cloud resources. The AWS team <a href="https://aws.amazon.com/blogs/mt/simplifying-permissions-management-at-scale-using-tags-in-aws-organizations/">publish</a> <a href="https://aws.amazon.com/blogs/security/attribute-based-access-control-ad-fs-simplify-iam-permissions-management/">great</a> <a href="https://www.youtube.com/watch?v=7eC5eUVt_VI">content</a> on how the ABAC model improves agility however I strongly believe that at this point tags are a tool for auditing, billing and automation - not for access control.</p>

<p>With the amount of services utilizing tags for their own purposes and subsequently tagging permissions being seen as a low risk permission, I recommend cloud security practitioners stick to traditional resource-based access control. <a href="https://twitter.com/iann0036">@ me</a> if you disagree!</p>

<h2 id="closing-out">Closing out</h2>

<p>I was able to work with the teams to get this patched, however it is a good opportunity to revisit your security model if you’re using ABAC in your organization. Many services and methods have functionality that is built with an RBAC model in mind, and you should be vigilant that the assumptions within your environment continue to hold true.</p>

<p>Thanks to the AWS security, S3 and CloudFormation team members who worked with me to help remediate this issue, and thanks for those readers who took the time to read this series. Both Aidan and I enjoyed writing it and I hope you all enjoyed reading it!</p>

<p>✌️</p>


</section>

		</div>

	</div></div>]]>
            </description>
            <link>https://onecloudplease.com/blog/security-september-still-early-days-for-abac</link>
            <guid isPermaLink="false">hacker-news-small-sites-24624908</guid>
            <pubDate>Tue, 29 Sep 2020 07:08:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fun Yet Effective Meetings]]>
            </title>
            <description>
<![CDATA[
Score 80 | Comments 42 (<a href="https://news.ycombinator.com/item?id=24624819">thread link</a>) | @thesnide
<br/>
September 28, 2020 | https://blog.pwkf.org/2020/09/27/we-should-only-have-fun-meetings.html | <a href="https://web.archive.org/web/*/https://blog.pwkf.org/2020/09/27/we-should-only-have-fun-meetings.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <blockquote>
  <p>⚠️ This article is extreme &amp; satirical on the purpose of being thought-provoking. Therefore, please, do take it with some grain of salt.</p>

  <p>This is a followup of my <a href="https://blog.pwkf.org/2020/09/26/remote-working-is-a-paradigm-shift.html">Remote-mostly working is a paradigm shift</a>.</p>
</blockquote>



<p>My #1 advice about distributed teams is actually even the case in colocated teams:
<strong>Try as hard as possible to avoid meetings, use textual IM instead</strong> as <a href="https://blog.codinghorror.com/meetings-where-work-goes-to-die/">meetings are where work goes to die</a>.
I know it sounds pretty dull, but if you really think about it you’ll see that it’s usually wasted time.
The usual pattern of decision taking is:</p>

<div><div><pre><code>1. if you don’t have a clue, ask someone else.
2. to ask him, schedule a meeting
3. to schedule a meeting, you have to find a slot
4. that usually postpones the decision
</code></pre></div></div>

<p>Postponing the decision is usually what one really wants, even unknowingly: “<em>to be able to have an excuse not to decide at once</em>”.</p>

<p>It’s a very very fair humane reaction, I also fell myself into that trap.</p>

<p><img src="https://blog.pwkf.org/assets/images/out-of-window.jpg" alt="Thrown out of the fence for proposing an textual chat"></p>



<p>I end up having the following workflow:</p>

<ul>
  <li>Avoid email loops. Those have too much overhead, and will divide your audience pretty quickly.</li>
  <li>Create a slack channel instead of the email loop. This will retain the whole conversation in 1 central place.</li>
  <li>Systematically push back on any meetings. Accept them only if you have a clear statement of who will drive it.</li>
  <li>
    <p>Meetings should be a broadcast mode. All the Q&amp;A should go back to the slack channel.</p>

    <ul>
      <li>Having everything searchable makes it super easy for
        <ul>
          <li>newcomers that can simply scroll back</li>
          <li>old timers such as me that forget and can also simply scroll back</li>
        </ul>
      </li>
      <li>
        <p>Even recorded meetings are a vast of time if you need to find an information, as it’s not indexed.</p>
      </li>
      <li>If not recorded, sending the minutes afterwards are usually a loss of information.
        <ul>
          <li>It’s still very important to extract “executive summaries” from those meetings, even only textual. As can be posted on a public place for massive &amp; broad sharing.</li>
          <li>Yet, the real context on those summaries will be kept inside the whole meeting</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<blockquote>
  <p><strong>Context effectively fights Cargo Cult</strong></p>

  <p>Usually the why of decisions are not provided in a “<a href="https://english.stackexchange.com/questions/120739/a-peek-into-the-sausage-factory">build the sausage</a>” manner. But after a while, the hypothesis of the decision are not true anymore, and therefore another decision has to be taken.</p>

  <p>This is not possible when loss of information occurs and that’s when <a href="https://en.wikipedia.org/wiki/Cargo_cult_programming">Cargo cult</a> begins to creep in.</p>
</blockquote>

<p>In a record-everything scenario, context switch is just a matter of reading back some previous messages. Otherwise you’ll spend numerous times “explaining the context” in a meeting to everyone. And then everyone will just move to something else, and you’ll have pitiful engagement, while still spending time on it.</p>

<p><strong>A company that use its time effectively, is a company that moves much faster than its competitors</strong>, no matter the skillsets in that company. Even if you have the brightest minds, if you waste their talents in boring activities, you’ll dry them up. And either they’ll leave, or worse, they <a href="https://www.sbnonline.com/article/the-quit-and-stay-syndrome-a-business-epidemic-thats-a-silent-profit-killer/">quit &amp; stay</a>.</p>

<blockquote>
  <p>💡 This enabled me to scale to a reasonable multitasking ability while curbing its overhead to a manageable level</p>
</blockquote>

<p><strong>That’s why “startups” are so effective</strong> : they are small and therefore very fast. Being fast brings capacity to try &amp; fail, and therefore agility.</p>

<blockquote>
  <p>💡 <strong>time is the only really scarse resource in a company</strong> : you can’t buy it back, no matter the price.</p>
</blockquote>

<h2 id="why-you-should-only-have-fun-ones">Why you should only have fun ones</h2>

<p>That said, I do agree that travelling is necessary. But we should name the real usecase of travelling : having <em>fun</em> <strong>together</strong>.</p>

<p>The nicest part of that purpose is :</p>

<ul>
  <li>you can plan it far in advance</li>
  <li>you can also budget it in advance</li>
  <li>you can mentally map yourself in those fun times, and focus on actual work right now.</li>
</ul>



<p>The most used reason for meetings is “alignments”, but it is very usually wasted as :</p>

<ul>
  <li>There’s always someone missing for that meeting</li>
  <li>No-one really wants to write the minutes out of it</li>
  <li>If written nonetheless, those minutes are only seldom capturing the <em>why</em> the decision is reached. Which is the most important part!</li>
</ul>

<p>The “<em>there’s always someone missing from that meeting</em>” is the worst part, as usually, that is the one that says “what you decided cannot be done”. And you’ll end up with yet another round of thinking at best. At worst you’ll try to shoehorn your precious alignment (that did sink a huge travel budget) into the needs of that missing person.</p>

<blockquote>
  <p>💡 We can draw a parallel to the paradigm shift I mentioned earlier:</p>
</blockquote>

<ul>
  <li><strong>F2F</strong> Meetings are the <strong>monolith</strong> way.</li>
  <li>Informal, dedicated &amp; <strong>textual meetings</strong> are the <strong>micro-services</strong> way.</li>
</ul>

<p>Now, one immediately notices the following:</p>

<ul>
  <li><strong>People are very much at ease with monoliths</strong>. It takes a huge mental leap to go micro-services.</li>
  <li><strong>Micro-services have an overhead</strong>. But no-one will argue that they can scale way better.</li>
  <li>Monoliths can seldomly be distributed the way micro-services can : you’ll quickly end up with that infamous distributed monolith pattern.</li>
</ul>

<blockquote>
  <p>💡 Now, let’s travel only for “team building” purposes.</p>

  <p>You can plan them in advance, and you won’t have over-budget ones. As their outcome is predictable, and if there’s someone missing, it won’t jeopardy the whole travelling.</p>
</blockquote>

<p>A final word of caution, the reference to scaling is <strong>not about runtime performance</strong>. It’s more about <strong>organisation size</strong>. As Martin Fowler said : <em>don’t even consider microservices unless you have a system that’s too complex to manage as a monolith</em>.</p>

<p>So, it usually makes very much sense to start with a small, colocated team, that has traditional meetings. The trick is to recognize the need to change the paradigm when the team grows, as it always done smoothly over the months. Just don’t forget to have good meeting hygiene (written inputs &amp; outputs), as <strong>even monoliths should be nicely modular</strong>.</p>

<blockquote>
  <p>I posted those 2 articles (<a href="https://blog.pwkf.org/2020/09/26/remote-working-is-a-paradigm-shift.html">Remote-mostly working</a>, <a href="https://blog.pwkf.org/2020/09/27/we-should-only-have-fun-meetings.html">Effective Meetings</a>) internally to my company some years ago, but I’m republishing those publicly to help others the same way it helped us.</p>
</blockquote>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://blog.pwkf.org/2020/09/27/we-should-only-have-fun-meetings.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24624819</guid>
            <pubDate>Tue, 29 Sep 2020 06:54:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tips for the most immersive video calls]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24624798">thread link</a>) | @telotortium
<br/>
September 28, 2020 | https://www.benkuhn.net/vc/ | <a href="https://web.archive.org/web/*/https://www.benkuhn.net/vc/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>I spend a lot of my day on video calls. Wave is a distributed company, so they’re the main way we communicate. But compared to talking in person, they feel unnatural:</p><ul><li>Most people have low-quality microphones and webcams that make them look and sound bad.</li><li>There’s a lag between when you say something and when the other person hears it, making it hard to navigate conversational <a href="https://en.wikipedia.org/wiki/Turn-taking" target="_blank">turn-taking</a>.</li><li>If you’re using headphones, you can’t hear your own voice very well.</li><li>Because of <a href="https://en.wikipedia.org/wiki/Echo_suppression_and_cancellation" target="_blank">echo cancellation</a>, you often can’t talk when someone else is also talking, which makes the conversation flow less well.</li></ul><p>I started wondering how much nicer video calls would feel if I fixed these problems. So I spent way too much time fiddling with gear and software. This post summarizes what I’ve learned.</p><p>Collectively, these recommendations have had a pretty big impact: when talking one-on-one to friends with equally good setups, I’ve been able to go 4+ hours without feeling fatigued.</p><p><em><small>Epistemic status: best guess; not a professional; almost certainly contains wrong bits. Tell me which ones by comment or <a href="https://www.benkuhn.net/contact/">email</a>!</small></em></p><h2 id="omg-ben-dont-make-me-read-your-4500-word-doorstopper-just-tell-me-what-to-do">omg ben don’t make me read your 4500 word doorstopper, just tell me what to do</h2><p>Here’s how I would stack-rank my advice for my past self. (Of course, your personal ranking might be different depending on your situation.)</p><ol><li><p>($depends) Don’t work in a space where your noise can bother other people, or vice versa.</p></li><li><p>($10-30) If you ever have network issues, run <a href="https://amzn.to/3luTVdV" target="_blank">a cable</a> between your computer and router. You’ll probably need an <a href="https://amzn.to/2YOFis9" target="_blank">adapter</a>. (Contrary to popular belief that a bad connection is your ISP’s fault, it’s <a href="https://www.benkuhn.net/wireless/">more likely to be flaky wifi</a>.)</p></li><li><p>(~$100) Buy <a href="https://amzn.to/3bULynH" target="_blank">open-back headphones</a>, which let you hear your own voice normally and are extremely comfortable.</p></li><li><p>(~$30) Switch from your built-in computer mic to a <a href="https://www.sweetwater.com/store/detail/BoomProMic--v-moda-boompro-microphone-communication-mic-for-headphones" target="_blank">headset mic</a> (and <a href="https://amzn.to/3hOU5JU" target="_blank">pop filter</a>), which will sound much better and pick up less noise. Note this requires a headset with detachable cable, like the one I linked above.</p><p>You can now leave yourself unmuted! If the other person also has headphones, you can also talk at the same time. Both of these will make your conversations flow better.</p></li><li><p>($0) Prefer Zoom to most alternatives; it has higher sound quality, better echo cancellation, and fewer silly behaviors. If you have headphones and a good mic, enable “original sound” to turn off some unnecessary audio filtering.</p></li><li><p>(~$200) Get a second monitor for notes so that you can keep Zoom full-screen on your main monitor. It’s easier to stay present if you can always glance at people’s faces. (I use an iPad with <a href="https://support.apple.com/en-us/HT210380" target="_blank">Sidecar</a> for this; for a dedicated device, the right search term is <a href="https://amzn.to/3iZRUVz" target="_blank">“portable monitor”</a>. Also, if your meetings frequently involve presentations or screensharing, consider getting a third monitor too.)</p></li><li><p>($0?) Arrange your lighting to cast lots of diffuse light on your face, and move any lights that shine directly into your camera. Lighting makes a bigger difference to image quality than what hardware you use!</p></li><li><p>(~$20-80 if you have a nice camera) Use your camera as a webcam. There’s software for <a href="https://www.usa.canon.com/internet/portal/us/home/support/self-help-center/eos-webcam-utility" target="_blank">Canon</a>, <a href="https://fujifilm-x.com/en-us/support/download/software/x-webcam/" target="_blank">Fujifilm</a>, <a href="https://downloadcenter.nikonimglib.com/en/download/sw/176.html" target="_blank">Nikon</a>, and <a href="https://support.d-imaging.sony.co.jp/app/webcam/en/" target="_blank">Sony</a> cameras (Windows-only for Nikon and Sony); for others, if they can output clean HDMI (check <a href="https://www.elgato.com/en/gaming/cam-link/camera-check" target="_blank">this list</a>), you can buy an <a href="https://amzn.to/3kgunjj" target="_blank">HDMI capture card</a>. You will also want to be able to plug your camera into a power source, for which you may need a “dummy battery.”</p></li><li><p>(~$40 if you have a smartphone with a good camera) Use that as a webcam via <a href="https://reincubate.com/camo/" target="_blank">Camo</a>.</p></li><li><p>(~$350) If you don’t own a nice camera but want one, you can get a used entry-level mirrorless camera + lens + dummy battery + boom arm. See <a href="#a-note-on-camera-buying">buying tips below</a>.</p></li></ol><p>More detailed recommendations and justifications follow.</p><h2 id="network">Network</h2><p>Connection problems are the thing that makes video calls suck the most. They do this in three different ways:</p><ol><li><p>If your connection ever gets really bad, your audio will break up, which is exhausting to listen to and ruins the flow.</p></li><li><p>Even if it doesn’t get that bad, a poor connection will increase <em>latency</em>, or the time between when you speak and when the other person hears you. High latency is what causes the dreaded “you first, no <em>you</em> first” dance.</p></li><li><p>Finally (and least importantly), a bad connection limits the amount of data you can exchange, forcing you to use lower-quality video. This doesn’t really matter if you’re using a webcam, but by the end of this post, you might have a good enough camera that it matters.</p></li></ol><p>I wrote a whole post of its own on how to troubleshoot your home network for video calls, but realistically, most connection problems are because <a href="https://www.benkuhn.net/wireless/">wifi sucks</a> and you can avoid them by not using wifi. So, first try running an <a href="https://amzn.to/3luTVdV" target="_blank">Ethernet cable</a> between your computer and your router. If you still notice high latency or your connection dropping, or if you really can’t run a cable for some reason, <a href="https://www.benkuhn.net/vcnet/">check the guide</a> for more troubleshooting advice.</p><h2 id="audio">Audio</h2><p>Video improvements are flashy and noticeable, but audio is the reason you’re having the call, thus ultimately more important. So audio comes first.</p><h3 id="get-away-from-other-people">Get away from other people</h3><p>This is a basic prerequisite for everything below. Coworking spaces and cafés are nice if you plan to be silent all day, but will make natural-feeling meetings impossible due to your crippling self-consciousness about noise levels. If you’re going to be on a call for more than 5 minutes, get your own space.</p><p>(If you are committed to taking your meetings in a crowded and noisy space, ignore the rest of the audio section. You’re mostly just doomed to crappy calls in this case, though you might be able to limit the damage by getting <a href="https://www.sweetwater.com/store/detail/BoomProMic--v-moda-boompro-microphone-communication-mic-for-headphones" target="_blank">a nice headset mic</a> and installing <a href="https://krisp.ai/" target="_blank">krisp.ai</a>.)</p><p>If you’re talking to someone else who’s in a noisy environment, you can apparently also use krisp.ai to filter their audio yourself, though I haven’t tried this.</p><h3 id="get-full-duplex-audio-with-no-echo">Get full-duplex audio with no echo</h3><p>One key ingredient to making voice conversations feel “natural” is that both participants need be able to talk and hear the other person talking at the same time (“full-duplex audio”). Full-duplex audio is important because it allows you to talk simultaneously (“overlap”) with the other person.</p><p>You might think that overlap should be rare, because interrupting someone else is rude. While that’s true of large-scale overlaps, we often use small-scale overlaps to <a href="https://en.wikipedia.org/wiki/Turn-taking#Overlap" target="_blank">negotiate conversational turn-taking</a> (e.g. starting talking when the speaker is trailing off but hasn’t finished), or to signify that we’re paying attention (“uh-huh,” “yeah”).</p><p>The hard problem of full-duplex audio is that if someone else is talking, their voice is going to come out of your computer’s speakers and go back into your microphone. If your computer leaves the microphone on, in that case, it’ll end up playing back an “echo” of their own voice to them, which is extremely annoying. So video call tries to filter out feedback from your speakers into your microphone, which is called <a href="https://en.wikipedia.org/wiki/Echo_suppression_and_cancellation" target="_blank">echo cancellation</a>.</p><p>Unfortunately, removing <em>only</em> the speaker echo from your microphone stream is really hard to do. So instead, the software often ends up completely muting your mic if someone else is talking. If you’ve ever tried to micro-overlap with someone and noticed that their audio cut out briefly, that’s what’s going on.</p><p>If your listeners can’t overlap with you, it’s harder to tell whether they’re following along, and it’s harder to negotiate whose turn it is to speak. This makes the conversation feel less natural, especially in larger groups.</p><p>To get full-duplex audio, you need to (a) have an audio setup that doesn’t produce echoes, then (b) convince your video call app not to try to suppress echoes.</p><p>(a), “an audio setup that doesn’t produce echoes,” means that your microphone should not pick up any sound from your speakers. In practice this means that your “speakers” must be headphones.</p><p>(b), “convince your video call app not to try to suppress echoes,” seemed surprisingly tricky when I tried to research it, because each video call app has its own heuristics for when to engage echo-cancellation.</p><p>So I did my own tests of echo cancellation Zoom, Skype, and Hangouts in Chrome and Firefox. I started a chat between two computers, both with headphones attached—a setup that should have required no echo cancellation. I then played music into the microphone of one computer. On the other, I spoke into the microphone and listened for whether the music got quieter.</p><p>Zoom, Skype and Hangouts in Firefox all seemed to slightly decrease the audio volume when I spoke, indicating light echo cancellation. For Hangouts in Chrome, the audio cut out <em>completely</em> every time I said anything. In Zoom, I was able to eliminate all echo cancellation by selecting the “use original audio” option, which you can also permanently enable for particular audio devices—I’d recommend doing this.</p><h3 id="throw-your-wireless-headset-in-the-trash">Throw your wireless headset in the trash</h3><p>The gear I recommend in this guide is all wired, not Bluetooth. While Bluetooth seems like it should be great, in practice it has <a href="https://www.benkuhn.net/wireless/">horrible problems with audio latency, quality and reliability</a>. Also, I don’t think wireless open-back headphones (see below) exist.</p><p>If you finished the previous paragraph and still think you can get away with using wireless audio gear, read the post at the link :)</p><h3 id="hear-yourself-clearly-with-open-back-headphones">Hear yourself clearly with open-back headphones</h3><p>Most headphones are <em>closed-back</em>, which means they form an acoustic seal over your ear that attenuates outside sound. This is good for “noise isolation” when you’re listening to music. But it’s bad in calls because it also isolates you from your own voice, making you sound muffled and unnatural to yourself. (The same thing also happens with any earbuds that form a seal, i.e. pretty much everything except EarPods or non-Pro AirPods.)</p><p>Personally, without the feedback from hearing myself, I also tend to start speaking louder or shouting on calls. This tires out my voice, and can get stressful for whoever I’m <del>shouting at</del> talking to.</p><p>To avoid this, you can buy <em>open-back headphones</em>, which have mesh instead of a closed covering over your ears. I bought the <a href="https://amzn.to/3bULynH" target="_blank">Philips SHP9500</a>, which I like a lot; I haven’t tested any other pairs. (I chose a low-end pair because for …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.benkuhn.net/vc/">https://www.benkuhn.net/vc/</a></em></p>]]>
            </description>
            <link>https://www.benkuhn.net/vc/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24624798</guid>
            <pubDate>Tue, 29 Sep 2020 06:49:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Radio I/Q Data for Dummies]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24624796">thread link</a>) | @pabo
<br/>
September 28, 2020 | http://whiteboard.ping.se/SDR/IQ | <a href="https://web.archive.org/web/*/http://whiteboard.ping.se/SDR/IQ">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wikitext">
<p>This is a description of using I/Q Data (aka "analytic signal") representing a signal. Since the topic may be quite confusing, I've described the same thing here from different point of views. If you find the information somewhat redundant, it is because it is. Different views may appeal to different readers, and if something seems unclear, keep on reading and it may be more comprehensible later - hopefully.
</p>
<h2>Why I/Q Data?</h2>
<p>I/Q Data is a signal representation much more precise than just using a series of samples of the momentary amplitude of the signal. Have a look at the following signal below.
</p>
<p><img src="http://whiteboard.ping.se/uploads/SDR/cosample.png" alt="Plain signal" title="Plain signal"></p>
<p>This is what you may be used to work with. So why I/Q Data - isn't this good enough?
</p>
<p>Not really. We have a few problems here.
</p>
<ul><li>First, it is impossible to determine the frequency of this signal. Sure, it looks simple enough, just look at the period length? True, but you have no clue if it's a positive or negative frequency since they both generate the same curve. I.e. cos(x) = cos(-x). This becomes a problem working with the signal. Mixing (multiplying) two signals and it'll cause multiple solutions due to the uncertainty of the sign: f1 âŠ— f2 equals f1 + f2 as well as f1 - f2.
</li><li>Second, it's hard to determine the power (peak amplitude, envelope) of the signal. Basically you can only see the peak amplitude here at 0Â°, 180Â°, 360Â° etc, and how do you know the power is the same everywhere else as well? And did you sample the signal exactly at its peak? You really don't know.
</li></ul><p>I/Q Data solves this. Instead of looking at the signal as a flat curve as above, look at it as a corkscrew (helix, spiral, coil spring) in three dimensions.
</p>
<p><img src="http://whiteboard.ping.se/uploads/SDR/corkscrew.png" alt="Complex signal" title="Complex signal"></p>
<hr>
<p>Now if you look at this curve from the side, you'll actually get the same graph as the first one above. Your "real" signal actually is this 2D projection of this corkscrew signal. This is your "I" in I/Q data.
</p>
<p><img src="http://whiteboard.ping.se/uploads/SDR/corkI.png" alt="Side view" title="Side view"></p>
<hr>
<p>Now have a look at the corkscrew from above. This looks quite similar, but as you see, it is out of phase 90Â°  starting at zero, not at one as the other. This this the Q part of your I/Q data.
</p>
<p><img src="http://whiteboard.ping.se/uploads/SDR/corkQ.png" alt="Top view" title="Top view"></p>
<hr>
<p>Now looking at the corkscrew down the time axis you'll see it winds counter-clockwise. This means we know the frequency is positive. It could have wound clockwise as well, still generating the same I-signal (projection) but different Q-signal, representing a negative frequency.
</p>
<p>You also see that the radius of the corkscrew is constant at every sample, if small in I large in Q and vice versa. The radius is the peak amplitude of your signal. 
</p>
<p>The axes are of course 90Â°, so the radius must be equal to (IÂ²+QÂ²)<sup>1/2</sup>. This is the peak amplitude of your signal, and as you can see you know this for each and every sample.
</p>
<p><img src="http://whiteboard.ping.se/uploads/SDR/corkT.png" alt="Viewed down time axis" title="Viewed down time axis"></p>
<h2>What is I/Q Data?</h2>
<p>AS you now understand, the I/Q Data Sample is the coordinates of your signal as seen down the time axis of the corkscrew.
</p>
<p><img src="http://whiteboard.ping.se/uploads/SDR/onesample.png" alt="" title=""></p>
<p>You might object that your signal isn't a pure cosine function as the one we have shown here, and it might be very true. Still, every single sample of your signal can be described as such, i.e. with a peak amplitude times cosine of some phase angle.
</p>
<p>Every single point of your signal can be described as the function Aâ‹…cos(Ï•)
</p>
<p>Since you may freely chose any amplitude A and angle Ï• this must of course be true (as long as the signal is continuous). The value of Aâ‹…cos(Ï•) is the <strong>I</strong> component of the I/Q signal, i.e. your real signal. Note that this only describes your signal in one single point, i.e. one sample. Next sample gives you a new I and Q very likely resulting in another amplitude and/or phase angle, reflecting the modulation of the signal.
</p>
<h2>One sample I/Q Data</h2>
<p>Ok, lets take one sample of I/Q Data and see what it represents. This is also called a phase vector, or phasor.
</p>
<pre>I = 0.69
Q = 0.40
</pre>
<p>Lets draw this in the complex plane.
</p>
<p><img src="http://whiteboard.ping.se/uploads/SDR/iqdraw1.png" alt="" title=""></p>
<p>Lets see what this tells us about our data point.
</p>
<ul><li>The momentary amplitude of our real signal is by definition <strong>I</strong>, i.e. 0.69
</li><li>Pythagoras tells us the amplitude A of the cosine wave is <code>(0.69Â²+0.40Â²)<sup>1/2</sup> = 0.8</code>
</li><li>Trigonometry tells us our angle is +30Â° into our cosine wave.
</li></ul><p>- <em>Hold it</em>, you say, <em>what cosine wave?</em>
</p>
<p>Well, I/Q actually assumes your real signal (<strong>I</strong>, that is) can be described as the
function <strong>I</strong> = Aâ‹…cos(Ï•)
</p>
<p>Since you are free to chose A and Ï• this must of course be true, as long the function is continuous. Remember we are looking at one single sample now, i.e. one point in time.
</p>
<p>So by using IQ Data we not only get the momentary values of our signal, but the function generating it as well. If we put above together we get:
</p>
<p>The real signal I = 0.8â‹…cos(30Â°)
</p>
<hr>
<ul><li>I/Q Data is the representation (data type) of this cosine function.
</li></ul><p>I/Q Data is the rectangular representation of the polar notation we used above. There is a unique transformation between the two, and the different notations have different properties calculating with them. The rectangular form of I/Q Data is chosen due to the ease of hardware implementations of the most common operations.
</p>
<p>I/Q Data consists of I and Q represented as two separate variables, a vector of length two, or more often, the complex number  I + Q<em>i</em>  (yes, I is the real part).
</p>
<p><img src="http://whiteboard.ping.se/uploads/SDR/polrep.png" alt="" title=""></p>
<p>Note that the Amplitude above is the waves peak amplitude, not the momentary amplitude.
</p>
<ul><li>I is the current momentary amplitude of the signal (i.e. the Real signal)
</li><li>Q is the momentary amplitude of the signal phase shifted -90Â°.
</li></ul><p>For a simple function such as sine, the phase shift is what the signal was earlier in time, but for a signal with more than one sine component, Q reflects a -90Â° shift of the individual components, and not the composite signal as such. To convert a Real Signal to a I/Q Data Signal, discrete Fourier transformation is required (Hilberts transform).
</p>
<h2>Different ways of representing the same I/Q Data Sample</h2>
<p>There are at least three common ways to represent the I/Q Data Sample. Different representations gives you different pros and cons. Some are more easy to add, other are more easy to multiply etc. This may be important in the implementation, resulting in less complex hardware/software using the best representation.
</p>
<h3>The rectangular form</h3>
<p>The I/Q Data on the form Q and I is called "rectangular" (or "Cartesian") form as it can be viewed as positions in a coordinate system. I and Q are the x and y axis respectively. This is the most common representation you are used to. This form is most common due the ease of modulating/demodulating it in hardware. More about that later.
</p>
<ul><li>As a complex number: I + Q<em>i</em>
</li><li>As a vector [I,Q]
</li><li>Or just the two plain variables I and Q
</li></ul><h3>The polar form</h3>
<ul><li>Amplitude and angle
</li></ul><p>I = Amplitudeâ‹…cos(angle) <br>Q = Amplitudeâ‹…sin(angle)
</p>
<p>The Amplitude is the peak amplitude of the cos (and sin) function, and the angle is how far into the period from zero to 360Â° you are (or 0 to 2Ï€ if you prefers radians).
</p>
<h3>Eulers form</h3>
<p>Since cos(Ï•) + iâ‹…sin(Ï•) = e<sup>iÏ•</sup> we can write our IQ sample as
</p>
<p><span> Ae<sup>iÏ•</sup> </span>
</p>
<p>This might (not?) be the most intuitive representation of the sample. Ï• rotates the angle as seen in the polar representation, and A is of course the amplitude. Realizing this, Eulers identity becomes obvious. Because Ï• is the rotation of the vector in the complex plane, rotating it half a turn, 180Â° or Ï€ radians, results in a real part of -1 and no imaginary part, hence:
</p>
<p><span> e<sup>Ï€i</sup>+1 = 0 </span>
</p>
<p><em>"The student should find this to be immediately obvious,</em> <br><em>otherwise he'll never be a first rate mathematician"</em>
</p>
<p><em>-- Carl Friedrich Gauss </em>
</p>
<h2>Positive versus negative frequency</h2>
<p>It is now easy to see that using I/Q we can represent the signal frequency either as positive or negative. Have a look at the two I/Q signals red and blue below to the left and compare them with their corresponding real projections. It is as obvious they differ in signs in I/Q, as it's impossible to determine the signs using only the real signal component (neither the I nor the Q projection separately).
</p>
<p><img src="http://whiteboard.ping.se/uploads/SDR/freqsign.gif" alt="Positive versus negative frequencies" title="Positive versus negative frequencies"></p>
<p><span>(sidenote: I've put them slightly out of phase compared to each other since else they wouldn't be possible to distinguish at all in the real representation to the right. Also, please note I'm here, quiet unconventional, using the x axis in the phasor for the imaginary <strong>Q</strong>)</span>
</p>
<p>The same signal (well, more or less) in a 3D representation.
</p>
<p>The <strong>I</strong> components (side view):
</p><p><img src="http://whiteboard.ping.se/uploads/SDR/sign-i.png" alt="" title=""></p>
<p>The <strong>Q</strong> components (top view):
</p><p><img src="http://whiteboard.ping.se/uploads/SDR/sign-q.png" alt="" title=""></p>
<p>The I/Q signals in 3D:
</p><p><img src="http://whiteboard.ping.se/uploads/SDR/sign-3d.png" alt="" title=""></p>
<p><a name="twopriceone" id="twopriceone"></a>
As the Nyquistâ€“Shannon sampling theorem states you can only represent
frequencies up to <code>f/2</code> using a samplings rate of <code>f</code>. This is still true
using IQ Data, but since you now can represent negative frequencies
the signal spans <code>[-f/2..+f/2]</code> compared to <code>[0..+f/2]</code> using a â„�eal signal,
hence the range is in effect doubled. Using a
sampling rate of <code>f</code> and you now can represent a signal range of <code>f</code> as well.
Two to the price of one!
</p>
<h2>Mixing and multiplying signals</h2>
<p>Using real signals or IQ Signals gives different results when you multiply them. This is because using only the real component it's not possible to uniquely determine the phase angle of the signal, hence impossible to distinguish a positive frequency from a negative.
</p>
<p><span><img src="http://whiteboard.ping.se/uploads/SDR/mix-real.png" alt="Mixing 10 kHz with 3 kHz using real" title="Mixing 10 kHz with 3 kHz using real"></span></p>
<p>Multiplying two signals f1 and f2 in the real domain:
</p>
<p><span> Â±f1 âŠ— Â±f2 = (Â±)f1 Â± f2 </span>
</p>
<p><span><img src="http://whiteboard.ping.se/uploads/SDR/mix-iq.png" alt="Mixing 10 kHz with 3 kHz using I/Q" title="Mixing 10 kHz with 3 kHz using I/Q"></span></p>
<p>Using IQ Data the signs are now given, and the result is unambiguous:
</p>
<p><span> f1 âŠ— f2 = f1 + f2 </span>
</p>
<p><br>
A frequency spectrum in the real domain usually never show the negative side, since it always must be symmetric around zero due to the uncertainty of the sign of the frequency of the real signal -- hence the parentheses around the sign of <code>f1</code> in the first formula mixing the real signals. I've included the negative side here for illustrative purposes, despite of its redundancy.
</p>
<p>Multiplying two complex number is easiest understood in the polar representation. The amplitude is multiplied and the angle added.
</p>
<p><span> A<sub>1</sub>â‹…e<sup>iÏ•<sub>1</sub></sup>â‹…A<sub>2</sub> e<sup>iÏ•<sub>2</sub></sup> = A<sub>1</sub>A<sub>2</sub> e<sup>i(Ï•<sub>1</sub>+Ï•<sub>2</sub>)</sup> </span>
</p>
<p>Realizing the angle is added under multiplication makes it obvious that the frequencies are added as well.
</p>
<h3>And in time domain ...</h3>
<p>Now let us have a look at this in time domain. To make it easier (doable!) to calculate the DFT in our …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://whiteboard.ping.se/SDR/IQ">http://whiteboard.ping.se/SDR/IQ</a></em></p>]]>
            </description>
            <link>http://whiteboard.ping.se/SDR/IQ</link>
            <guid isPermaLink="false">hacker-news-small-sites-24624796</guid>
            <pubDate>Tue, 29 Sep 2020 06:49:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Everything you need to know about running an A/B test. – Aanand Shekhar Roy]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24624555">thread link</a>) | @aanandshekhar
<br/>
September 28, 2020 | http://www.aanandshekharroy.com/articles/2020-09/intro-to-ab-tests | <a href="https://web.archive.org/web/*/http://www.aanandshekharroy.com/articles/2020-09/intro-to-ab-tests">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    

    <article>
      <p>A/B test is a powerful tool that every product team can use to get insights from their customers. A/B tests or experiments provide us a controlled environment to understand why certain things happened. We all have heard ‘Correlation doesn’t imply causation’, meaning, just because two variables are correlated (sales of ice cream are increasing, and Amazon is expanding its ever-increasing empire), doesn’t mean one is causing another.
This, however, puts us in an uncomfortable place. How would we ever be able to confirm that our ingenious idea of adding a  little song and dance above the ‘Buy Now’ button is responsible for a 10x sale on our website? It could be due to the change we made, or it could just mean that discount code of 90% off went viral.</p>



<p>A/B tests help us to establish causality. How does it work? In short, we divide our users into two groups, one is called ‘control group’, and another is called ‘test group’. Then we show a design change only to users in the ‘test group’. Then we analyze the effects. Since the design change was the only difference between the control group and the test group, we can be certain to establish the causality that the design change is most likely the reason behind the observed effect. 
Note that in the above description I loosely used ‘design change’ as a catch-all term for any changes that you make, but it’s not just related to changes in design. You could use it for experimenting with different pricing points, subscription options, etc.
Here’s a little diagram I borrowed from a very good book on the topic which you should check out <a href="https://amzn.to/33ODbX7">Designing with Data: Improving the User Experience with A/B Testing</a>
<img src="http://www.aanandshekharroy.com/assets/img/abtestexperiment.png" alt="abtestdiagram"></p>

<p>People have been running experiments since the dawn of time. In the 18th century, a British captain ran an experiment where he gave citrus fruit to half of the sailors and observed that people who were not given citrus fruit had a higher rate of scurvy(which is caused by Vitamin C deficiency), so he concluded citrus fruit can prevent scurvy.
A/B tests in an online world today is experimentation on steroids. You can get feedback within hours from hundreds and thousands of people, cutting the time it takes to conclude radically. 
We’ll now look at important aspects of running an A/B test.</p>

<h2 id="sampling-the-users">Sampling the users</h2>

<p>This is the first and probably the most important step. In this step, you decide how to distribute your users under the control and test group. You have to be careful that you aren’t accidentally inducing bias in how the users are sampled. The best and the easiest way is to assign them randomly. This should certainly cancel out any unfair advantage one group may have over another.</p>

<h3 id="subdivision">Subdivision</h3>

<p>Another important consideration in an experiment is, which user group to get data about? 
One large user base is quite varied. If you subdivide your user base within cohorts and segments, you’d better understand the motivation and behavioral difference which might get unnoticed when considered as one big group.</p>

<h4 id="cohort-and-segment">Cohort and Segment</h4>

<p>A cohort is a group of users who have the same experience. It could be based on time (all 500 new users acquired during January because of a big sale on the e-commerce platform).
Or, you can segment your user base on a more stable characteristic like demographics, gender, etc.</p>

<p>If you focus on one single cohort/segment, you can better tap into their unique needs and motivations.</p>

<h3 id="new-users-vs-old-users">New users vs Old users</h3>

<p>Why it matters? Your existing users are accustomed to interactions with the app, so they might get a hang of your design changes easily (compared to new users). This learned behavior may influence the decision they make or experience your product.</p>

<p>“Learning effect” is a real thing. It takes time for users to get accustomed to your new UX. When you make a design change, if it is big, expect your metrics to go haywire initially.
One way to detect that a learning effect might be going on is to compare the metrics of new and old users. If old users are doing a lot better than new users, then probably you should let the experiment run a little bit longer. You might notice the metrics will become stable over time as they slowly get around the changes.</p>

<h2 id="metric-what-we-wish-to-influence">Metric: What we wish to influence</h2>

<p>We do an A/B experiment to test which approach might be better at improving a certain metric. There’s always a metric you have in mind that you want to influence, or else, why would you look for a better way to do a certain thing?
On a higher level, there are KPIs. They are key performance metrics that tell you the health of the company. They can be the number of new users, revenue generated by months, etc. But not all small A/B tests will reflect in a change in your KPIs, simply because KPIs are too big a target. To deal with this problem, you can create <em>proxy metrics</em>. They are basic metrics that correlate to the big KPIs. Let’s say you have ‘Revenue generated per month’ as a KPI, and you are testing a new design of the checkout button.
You can create the ‘Checkout button clicked’ metric and test which version of the test improved that metric. Clicking on the checkout button correlates highly to the ‘revenue generated’ metric so it’s a good proxy metric here.</p>

<p>The rationale here is simple. If you are observing an insensitive metric that takes longer time and effort to be changed meaningfully (like NPS score) you might not record any significant changes even after making significant changes in the user experience. For eg. Changing the copy in login form may result in a lot more people signing up, but may not have any effect on the NPS score.</p>

<h2 id="concluding-results">Concluding results</h2>

<p>So you’ve done all the pre-requisites, which means that you have a hypothesis that you want to test using the A/B test, You’ve decided which segment or cohort of users to run the tests on, and you’ve also picked up the metric you wish to influence. You run the test, and you get the results. How would you conclude that you’ve proved or disproved your hypothesis? Can we be sure of the tests and decide to invest resources based on these results? 
If we can say that we have statistically significant results, we can conclude the experiment and say confidently whether the hypothesis that we were testing is proved or disproved. To do that, we have to understand what a <strong>significance level</strong> is.</p>

<h3 id="significance-level">Significance level</h3>

<p>The significance level tells you the probability that a certain observation/result is caused by chance. For example, significance level, or in short <em>p-value</em> of 0.05 tells you that there is a 5% chance that the difference observed between the test and control group is due to pure chance. In other words, we are 95% confident that change in the test and control group is not caused by randomness/luck/chance.
Which <em>p-value</em> is the best? There is no right answer. In most social studies, p of 0.05 is commonly used. In experimental physics, a p-value of 0.0000003 can be used. As you can guess through intuition, to get a higher level of confidence, you’d need more data, more samples, which might make sense when you are making critical design based on the A/B tests, but it’s not always the case, and you might be ok with 10% chance of being wrong.
I’ve written more on <a href="http://www.aanandshekharroy.com/articles/2020-09/statistical-singificance-in-data">How to tell if you have ‘statistically significant’ results?</a> which goes into more detail.</p>

<p>Now you can conclude whether the results you have are statistically significant or not. Let’s say you can tell with 99% confidence that a little song and dance above the checkout button leads to more people buying stuff from you. Does that mean you should go ahead with the change? 
This a kind of question ‘statistical significance’ can’t tell you. There is a term called ‘Minimum detectable effect’, or MDE. This means, what’s the minimum change between the test and control group needs to be to call this A/B test a success and decide to further invest in this approach. Imagine in the above case we figured out that we need to observe a 10% improvement in people clicking on the ‘Checkout’ button to make a meaningful impact in our revenue, 10% would be our MDE. In that case, there needs to be a 10% improvement between the control and test group in our A/B test.
Note that it’s easier to detect bigger MDEs. As in, it’s easier to detect a 90% of a difference than a 0.9% difference. As a result, smaller MDEs require more powerful tests and large samples. Usually, you’d be running tests with smaller MDEs if you are working on optimizing experience, hence the changes will be subtle and small, but still may worth it. A 0.1% improvement in a billion-dollar revenue company is still huge :)</p>



<p>A/B tests are a great quantitative way of getting data to make a critical decision, but as with all quantitative methods, it’s difficult to know ‘why’ people make the decision that they made. To account for that lapse of data, you shouldn’t be afraid to club your A/B tests with their methods of data gathering, like surveys, etc to know why people made a certain decision.
Armed with that knowledge you’ll have a better picture of the problem.</p>

<h3 id="bias-in-the-data">Bias in the data</h3>
<ul>
  <li>It’s imperative that the data you have isn’t inherently biased. Either directly or indirectly.</li>
</ul>

<blockquote>
  <p>“Most statistics books assume that you are using good data, just as a cookbook assumes
that you are not buying rancid meat and rotten vegetables. But even the finest
recipe isn’t going to salvage a meal that begins with spoiled ingredients”</p>
</blockquote>

<p>I wrote a piece <a href="http://www.aanandshekharroy.com/articles/2020-09/hidden-bias-in-data">‘Garbage in, Garbage out: Hidden biases in data’</a> which goes in the detail of that issue.</p>

<hr>
<p>Resources:</p>

<p><a href="https://amzn.to/33ODbX7">Designing with Data: Improving the User Experience with A/B Testing</a></p>

<p><a href="https://amzn.to/2DE5tKJ">How to Lie with Statistics By D. Huff, I. Geis</a></p>

<p><a href="https://amzn.to/32872do">Naked Statistics: Stripping the Dread from the Data</a></p>

      <!-- <div class="center">
        <h4 >
          I am making a new course for you on Advanced Android Development and I’d love your input.
          Just click below to answer 5 very short questions. It only takes 1 minute.</h4>
          <div class="center">
            <a class="btn" href="https://goo.gl/forms/7sLk5CVAoYoP058u2">
              Click here
            </a>
          </div>
          <h4>  P.S. Check out the bonus question if you’d like an early access (It's already 25% complete!).
        </h4>
      </div> -->
      <!-- <iframe style="height:400px;width:100%;max-width:800px;margin:30px auto;" src="https://upscri.be/42a5c9?as_embed"></iframe> -->
      <!-- Begin Mailchimp Signup Form -->




<!--End mc_embed_signup-->
    </article>
  </div></div>]]>
            </description>
            <link>http://www.aanandshekharroy.com/articles/2020-09/intro-to-ab-tests</link>
            <guid isPermaLink="false">hacker-news-small-sites-24624555</guid>
            <pubDate>Tue, 29 Sep 2020 06:00:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Blur attacks bypass Bluetooth Classic and BLE security mechanisms CVE-2020-15802]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24624206">thread link</a>) | @a5withtrrs
<br/>
September 28, 2020 | https://hexhive.epfl.ch/BLURtooth/ | <a href="https://web.archive.org/web/*/https://hexhive.epfl.ch/BLURtooth/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      
      

      <h2 id="blur-attacks">BLUR attacks</h2>

<p>BLURtooth (the BLUR attacks) exploits the lack of cross-transport key
validation, allowing an attacker to bypass Bluetooth Classic and Bluetooth Low
Energy security mechanisms.</p>

<p>Bluetooth’s cross-transport key derivation (CTKD) is vulnerable to attacks
enabling to attack Bluetooth Classic from Bluetooth Low Energy and vice versa.
A remote attacker in Bluetooth range may impersonate, man-in-the-middle, and
establish malicious sessions with arbitrary devices.</p>

<ul>
  <li><strong><em>Security Impact:</em></strong> device impersonation, man-in-the-middle, malicious
session establishment with arbitrary devices</li>
  <li><strong><em>Affected Devices:</em></strong> the attack is standard compliant, so all BT/BLE
devices supporting CTKD are likely vulnerable; all our tested devices are
vulnerable</li>
  <li>BLURtooth is tracked under <a href="https://kb.cert.org/vuls/id/589825">CVE-2020-15802</a></li>
  <li><strong><em>Credit:</em></strong> Daniele Antonioli and Mathias Payer
from École Polytechnique Fédérale de Lausanne (EPFL),
Nils Ole Tippenhauer from Helmholtz Center for Information Security (CISPA),
and Kasper Rasmussen from University of Oxford.</li>
  <li><strong><em>Contacts at EPFL:</em></strong>
<a href="mailto:daniele.antonioli@epfl.ch,mathias.payer@nebelwelt.net">Daniele Antonioli and Mathias Payer</a></li>
</ul>

<h2 id="summary">Summary</h2>

<p>Here, we provide more details about a set of novel and standard-compliant
Bluetooth vulnerabilities affecting both Bluetooth Classic (BT) and Bluetooth
Low Energy (BLE).  The uncovered vulnerabilities affect a security mechanism
called cross-transport key derivation (CTKD). CTKD is used to improve the
usability of Bluetooth pairing by allowing to generate BT and BLE pairing keys
just by pairing two devices either on BT or BLE (rather than pairing them two
times).</p>

<p>However, we find that CTKD introduces cross-transport security issues and that
an attacker can abuse those issues to attack BT from BLE and vice versa.  In
particular, our attacks enable to impersonate, man-in-the-middle, and establish
malicious sessions with arbitrary devices by abusing CTKD, while defeating all
the security mechanisms put in place by BT and BLE.  Our work is named BLURtooth
and the related attacks are called BLUR attacks as they blur the security
boundary between BT and BLE.</p>

<p>The team behind this work consists of
<a href="https://francozappa.github.io/">Daniele Antonioli</a>
and
<a href="https://nebelwelt.net/">Mathias Payer</a>
from the <a href="https://hexhive.epfl.ch/">HexHive group</a> at
École Polytechnique Fédérale de Lausanne (EPFL),
<a href="https://tippenhauer.de/">Nils Ole Tippenhauer</a>
from Helmholtz Center for Information Security (CISPA), and
<a href="https://www.cs.ox.ac.uk/people/kasper.rasmussen/">Kasper Rasmussen</a>
from the University of Oxford.</p>

<p>In the remainder of this document, we provide information on
technical details, disclosure, impact, our proposed mitigation, the response
from the Bluetooth SIG.</p>

<h2 id="technical-details">Technical Details</h2>

<p>The Bluetooth standard includes two technologies <em>Bluetooth Classic (BT)</em> (also
known as Bluetooth BR/EDR) and <em>Bluetooth Low Energy (BLE)</em>. The majority of
mobile devices, including laptops, smartphones, tablets, headphones, and
smartwatches, support both and are defined as <em>dual-mode</em> Bluetooth devices. To
securely use dual-mode devices over BT and BLE a user has to pair her devices
two times, once for BT and once for BLE. As pairing the same device is
considered <em>user-unfriendly</em>, in 2014, with the release of Bluetooth version
4.2, the Bluetooth standard introduced a security mechanism that allows a user
to pair dual-mode Bluetooth devices once (either over BT or BLE) and then
securely use them both over BT and BLE. This security mechanism is called
<em>cross-transport key derivation (CTKD)</em>, and, as the name implies, it enables
deriving pairing keys across different transports (i.e.  derive a BT pairing key
from BLE and vice versa).</p>

<p>Despite being a security-critical mechanism, CTKD is not part of the Bluetooth
threat model and there are no security evaluations of CTKD. Those reasons
motivated us to perform a security analysis of CTKD, resulting in our findings.
In particular, CTKD is affected by 5 major issues (i.e.  vulnerabilities)
enabling an attacker to abuse Bluetooth roles, association, security modes,
keys, and pairing states across BT and BLE. Such issues derive from the <em>lack of
a cross-transport threat model</em> in the Bluetooth standard. The standard
considers BT and BLE with separate threat models and security architectures
while, through CTKD, opens avenues for cross-transport attacks (i.e., attacks
that exploit BT by taking advantage of a vulnerability in BLE or vice versa).</p>

<p>We demonstrate that the identified CTKD issues can be exploited by a remote
attacker in Bluetooth range with the victims. In particular, the attacker can
perform impersonation, man-in-the-middle, and malicious session establishment
attacks while bypassing all the security mechanisms provided by BT and BLE
(including Secure Connections or strong association).  Those are very serious
attacks that violate the security guarantees promised by Bluetooth.  We
confirmed the feasibility of our attacks by testing them on 13 common Bluetooth
devices using 10 unique Bluetooth chips. All of them were vulnerable.</p>

<p>You will find technical details about CTKD, our security analysis, a detailed
discussion of the threads, a discussion, and potential mitigations in our
<a href="https://arxiv.org/abs/2009.11776">BLURtooth preprint</a>.</p>

<h2 id="disclosure">Disclosure</h2>

<p>We discovered the vulnerability in March 2020 and responsibly disclosed our
findings along with suggested countermeasures to the Bluetooth SIG in May 2020.
We kept our findings private and the Bluetooth SIG publicly disclosed them,
without informing us, on the 10th of September of 2020.  Our work is assigned
<em><a href="https://kb.cert.org/vuls/id/589825">CVE-2020-15802</a></em>.</p>

<h2 id="impact">Impact</h2>

<p>The BLUR attacks are a <em>significant threat for all Bluetooth users and
the related vulnerabilities remain 0-days</em>. Our claim
is backed up by our experimental results where we successfully conducted
impersonation, man-in-the-middle, and malicious sessions establishment attacks
on 13 different devices. Our device sample include manufacturers such as
Dell, Google, Lenovo, Samsung, and Sony, operating systems, such as Windows
10, Linux, and Android, and Bluetooth chip manufacturers such as Cypress,
Qualcomm, Intel, Broadcom, and Cambridge Silicon Radio (CSR).</p>

<h2 id="our-mitigations">Our Mitigations</h2>

<p>As part of our disclosure, we provided <em>concrete fixes to combat the BLUR
attacks</em>. In particular, we recommended disabling the capability to overwrite
keys via CTKD in certain circumstances, enforce strong association and Secure
Connections and roles across BT and BLE, disable pairing over BT and/or BLE when
not needed, and add user notifications in case of odd behaviors. Our fixes can
be implemented at the standard level and do not require vendor-specific
features.</p>

<h2 id="response-from-the-bluetooth-sig">Response from the Bluetooth SIG</h2>

<p>At the time of writing, there are <em>no deployed patches</em> to address the BLUR
attacks on actual devices.  The Bluetooth SIG suggested that version 5.1 of the
standard will contain guidelines to mitigate the BLUR attacks (e.g., disable key
overwrites in certain circumstances as proposed in our countermeasures), but
such guidelines are not (yet) public and we cannot comment on them.  The
Bluetooth SIG provides a <a href="https://www.bluetooth.com/learn-about-bluetooth/bluetooth-technology/bluetooth-security/blurtooth/">public statement about BLURtooth and the BLUR
attacks</a>.</p>


      
    </div></div>]]>
            </description>
            <link>https://hexhive.epfl.ch/BLURtooth/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24624206</guid>
            <pubDate>Tue, 29 Sep 2020 04:43:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: GraphQL for Taskord is out now]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24624057">thread link</a>) | @bigint
<br/>
September 28, 2020 | https://taskord.com/graphiql | <a href="https://web.archive.org/web/*/https://taskord.com/graphiql">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://taskord.com/graphiql</link>
            <guid isPermaLink="false">hacker-news-small-sites-24624057</guid>
            <pubDate>Tue, 29 Sep 2020 04:03:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[XRHealth debuts new at-home VR therapy for ADHD]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24624048">thread link</a>) | @vrfinal
<br/>
September 28, 2020 | https://www.vrfinal.com/xrhealth-debuts-new-at-home-vr-therapy-for-adhd/ | <a href="https://web.archive.org/web/*/https://www.vrfinal.com/xrhealth-debuts-new-at-home-vr-therapy-for-adhd/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <main>
            <article>
                            <p><time datetime="2020-09-28">
                  Sep 28, 2020
                </time>
                <span>1 min read</span>
              </p>
                <div>
    <p><a href="https://www.vrfinal.com/xrhealth-debuts-new-at-home-vr-therapy-for-adhd/">
        <img data-srcset="/content/images/size/w400/2020/09/XRHealth_1.png 400w, /content/images/size/w750/2020/09/XRHealth_1.png 750w, /content/images/size/w960/2020/09/XRHealth_1.png 960w" data-sizes="auto" alt="XRHealth debuts new at-home VR therapy for ADHD" srcset="https://www.vrfinal.com/content/images/size/w400/2020/09/XRHealth_1.png 400w, https://www.vrfinal.com/content/images/size/w750/2020/09/XRHealth_1.png 750w, https://www.vrfinal.com/content/images/size/w960/2020/09/XRHealth_1.png 960w">
      </a>
    </p>
  </div>
              <div>
                <div>
                  <p>XRHealth has developed a VR app for people suffering from ADHD. </p><p>ADHD affects millions of people; it causes issues around impulse control and attention. Medications are available to treat lack of focus, but concentration skills can also be instilled through personal instruction, this is what XRHealth’s new app aims to deal with.</p><p>The app was developed to improve the cognitive function of people with ADHD. It is based on the principle of “brain plasticity”, the ability of the brain to restructure itself in order to adapt to new environments and challenges.</p><figure><iframe width="612" height="344" src="https://www.youtube.com/embed/Ue3TgMKGq0E?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><p>A new policy from the FDA allows US medical providers to prescribe VR therapy to patients during the Covid-19 pandemic, this is an attempt to modify the older in-person outpatient system. According to the<a href="https://www.xr.health/"> XRHealth website</a> they offer, <em>“The first-and-only VR treatment for children and adults with ADHD.”</em></p><p>The app works by presenting the patient with a visual, auditory, and physical experience similar to real life, the patient then works through several tasks and challenges designed to test and improve their cognitive functions. All of the data, eye movements and general performance, will be sent to the physician who prescribed the therapy, they can then adjust the difficulty and track daily improvements.</p><p>The XRHealth app is not meant to be a replacement for other treatments, instead, it is used to work with medications and in-person therapy. Due to the current pandemic, home solutions like the app are becoming more and more popular but they won’t replace traditional treatments.If you live in the US, you can apply for your insurance to cover the costs of their TeleHealth VR kit. The VR system provided is a heavily locked down version of the<a href="https://www.pico-interactive.com/us/neo2.html"> Pico Neo 2</a> but users who own the Oculus Quest or Oculus Go can install the app on their devices.</p>
                </div>
                  
                              </div>
            </article>
              <section>
    <p><img data-src="/content/images/size/w150/2020/09/IMG_20200812_155324.jpg" alt="Andrew Boggs" src="https://www.vrfinal.com/content/images/size/w150/2020/09/IMG_20200812_155324.jpg">
    </p>
    <div>
      
      <p>Andrew is a Northern Ireland based journalist with a passion for video games. His latest hobby is watching people speedrun Super Mario 64 and realising how bad he is at platformers.</p>
    </div>
  </section>
            <div>
      <div>
        <p><img data-srcset="/content/images/size/w400/2020/09/budget-1.jpg 400w, /content/images/size/w750/2020/09/budget-1.jpg 750w, /content/images/size/w960/2020/09/budget-1.jpg 960w" data-sizes="auto" alt="Budget Cuts FINALLY hits PSVR" srcset="https://www.vrfinal.com/content/images/size/w400/2020/09/budget-1.jpg 400w, https://www.vrfinal.com/content/images/size/w750/2020/09/budget-1.jpg 750w, https://www.vrfinal.com/content/images/size/w960/2020/09/budget-1.jpg 960w">
        <span>Previous Post</span></p><h4>Budget Cuts FINALLY hits PSVR</h4>
        </div>

    <div>
      <p><img data-srcset="/content/images/size/w400/2020/09/mortal-blitz3.jpg 400w, /content/images/size/w750/2020/09/mortal-blitz3.jpg 750w, /content/images/size/w960/2020/09/mortal-blitz3.jpg 960w" data-sizes="auto" alt="Mortal Blitz: Combat Arena gets PSVR Release Next Week" srcset="https://www.vrfinal.com/content/images/size/w400/2020/09/mortal-blitz3.jpg 400w, https://www.vrfinal.com/content/images/size/w750/2020/09/mortal-blitz3.jpg 750w, https://www.vrfinal.com/content/images/size/w960/2020/09/mortal-blitz3.jpg 960w">
      <span>Next Post</span></p><h4>Mortal Blitz: Combat Arena gets PSVR Release Next Week</h4>
      </div>
</div>            


        </main>
      </div>
    </div></div>]]>
            </description>
            <link>https://www.vrfinal.com/xrhealth-debuts-new-at-home-vr-therapy-for-adhd/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24624048</guid>
            <pubDate>Tue, 29 Sep 2020 04:01:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Our Vision – Coalition for App Fairness]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24624006">thread link</a>) | @tambourine_man
<br/>
September 28, 2020 | https://appfairness.org/our-vision/ | <a href="https://web.archive.org/web/*/https://appfairness.org/our-vision/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><div><div id="primary"><main id="main"><article class="page" id="post-394" itemtype="https://schema.org/CreativeWork" itemscope="itemscope"><div itemprop="text"><div data-elementor-type="wp-page" data-elementor-id="394" data-elementor-settings="[]"><div><div><section data-id="e1785ac" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"></section><section data-id="29e5348" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="df3eaf0" data-element_type="column"><div><div><div data-id="9fdb9b1" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;,&quot;_animation_delay&quot;:300}" data-widget_type="text-editor.default"><div><p>The world’s most popular online platforms and the app stores that govern access to them have become a critical gateway to the consumers of digital products and services worldwide. While they can be beneficial when fairly operated, they can also be used by platform owners to hurt developers and consumers. As enforcers, regulators and legislators around the world seek to address these important issues, we, the Coalition for App Fairness, urge them to recognize that every app developer, regardless of size or the nature of the developer’s business, is entitled to fair treatment by these app stores and the platform owners who operate them, and should be afforded the following rights:</p></div></div></div></div></div></div></div></section><section data-id="e9c6c37" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;gradient&quot;,&quot;animation&quot;:&quot;none&quot;}"><div><div><div data-id="537c477" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;,&quot;animation&quot;:&quot;fadeInUp&quot;,&quot;animation_delay&quot;:300}"><div><div><section data-id="ec9b1aa" data-element_type="section" data-settings="{&quot;animation&quot;:&quot;none&quot;}"><div><div><div data-id="5b0d45c" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="a4f6862" data-element_type="widget" data-widget_type="tp-info-box.default"><div><div id="info_box5f76e32f79c2b" data-id="info_box5f76e32f79c2b" data-connection="" data-eventtype=""><div><div><div><div><p><img src="https://appfairness.org/wp-content/uploads/2020/09/icon-number_1.png" alt="one"></p><div><p>No developer should be required to use an app store exclusively, or to use ancillary services of the app store owner, including payment systems, or to accept other supplementary obligations in order to have access to the app store.</p></div></div></div></div></div></div></div></div></div></div></div><div data-id="5eefa74" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="143ef27" data-element_type="widget" data-widget_type="tp-info-box.default"><div><div id="info_box5f76e32f7cb07" data-id="info_box5f76e32f7cb07" data-connection="" data-eventtype=""><div><div><div><div><p><img src="https://appfairness.org/wp-content/uploads/2020/09/icon-number_2.png" alt="two"></p><div><p>No developer should be blocked from the platform or discriminated against based on a developer’s business model, how it delivers content and services, or whether it competes in any way with the app store owner.</p></div></div></div></div></div></div></div></div></div></div></div></div></div></section><section data-id="a36f301" data-element_type="section" data-settings="{&quot;animation&quot;:&quot;none&quot;}"><div><div><div data-id="c13739d" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="dd74397" data-element_type="widget" data-widget_type="tp-info-box.default"><div><div id="info_box5f76e32f80517" data-id="info_box5f76e32f80517" data-connection="" data-eventtype=""><div><div><div><div><p><img src="https://appfairness.org/wp-content/uploads/2020/09/icon-number_3.png" alt="three"></p><div><p>Every developer should have timely access to the same interoperability interfaces and technical information as the app store owner makes available to its own developers.</p></div></div></div></div></div></div></div></div></div></div></div><div data-id="d7acc59" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="c8f0078" data-element_type="widget" data-widget_type="tp-info-box.default"><div><div id="info_box5f76e32f859f7" data-id="info_box5f76e32f859f7" data-connection="" data-eventtype=""><div><div><div><div><p><img src="https://appfairness.org/wp-content/uploads/2020/09/icon-number_4.png" alt="four"></p><div><p>Every developer should always have access to app stores as long as its app meets fair, objective and nondiscriminatory standards for security, privacy, quality, content, and digital safety.</p></div></div></div></div></div></div></div></div></div></div></div></div></div></section><section data-id="c3f38e1" data-element_type="section" data-settings="{&quot;animation&quot;:&quot;none&quot;}"><div><div><div data-id="c29ef73" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="6d00f0d" data-element_type="widget" data-widget_type="tp-info-box.default"><div><div id="info_box5f76e32f89a26" data-id="info_box5f76e32f89a26" data-connection="" data-eventtype=""><div><div><div><div><p><img src="https://appfairness.org/wp-content/uploads/2020/09/icon-number_5.png" alt="five"></p><div><p>A developer’s data should not be used to compete with the developer.</p></div></div></div></div></div></div></div></div></div></div></div><div data-id="7c1173a" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="aaac757" data-element_type="widget" data-widget_type="tp-info-box.default"><div><div id="info_box5f76e32f8c9df" data-id="info_box5f76e32f8c9df" data-connection="" data-eventtype=""><div><div><div><div><p><img src="https://appfairness.org/wp-content/uploads/2020/09/icon-number_6.png" alt="six"></p><div><p>Every developer should always have the right to communicate directly with its users through its app for legitimate business purposes.</p></div></div></div></div></div></div></div></div></div></div></div></div></div></section><section data-id="00e085e" data-element_type="section" data-settings="{&quot;animation&quot;:&quot;none&quot;}"><div><div><div data-id="0931faa" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="be80356" data-element_type="widget" data-widget_type="tp-info-box.default"><div><div id="info_box5f76e32f90229" data-id="info_box5f76e32f90229" data-connection="" data-eventtype=""><div><div><div><div><p><img src="https://appfairness.org/wp-content/uploads/2020/09/icon-number_7.png" alt="seven"></p><div><p>No app store owner or its platform should engage in self-preferencing its own apps or services, or interfere with users’ choice of preferences or defaults.</p></div></div></div></div></div></div></div></div></div></div></div><div data-id="c58956e" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="e726b73" data-element_type="widget" data-widget_type="tp-info-box.default"><div><div id="info_box5f76e32f931ae" data-id="info_box5f76e32f931ae" data-connection="" data-eventtype=""><div><div><div><div><p><img src="https://appfairness.org/wp-content/uploads/2020/09/icon-number_8.png" alt="eight"></p><div><p>No developer should be required to pay unfair, unreasonable or discriminatory fees or revenue shares, nor be required to sell within its app anything it doesn’t wish to sell, as a condition to gain access to the app store.</p></div></div></div></div></div></div></div></div></div></div></div></div></div></section><section data-id="b79a45e" data-element_type="section" data-settings="{&quot;animation&quot;:&quot;none&quot;}"><div><div><div data-id="35127a4" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="669eafc" data-element_type="widget" data-widget_type="tp-info-box.default"><div><div id="info_box5f76e32f96d24" data-id="info_box5f76e32f96d24" data-connection="" data-eventtype=""><div><div><div><div><p><img src="https://appfairness.org/wp-content/uploads/2020/09/icon-number_9.png" alt="nine"></p><div><p>No app store owner should prohibit third parties from offering competing app stores on the app store owner’s platform, or discourage developers or consumers from using them.</p></div></div></div></div></div></div></div></div></div></div></div><div data-id="e891f97" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="a8cb9a4" data-element_type="widget" data-widget_type="tp-info-box.default"><div><div id="info_box5f76e32f9ace3" data-id="info_box5f76e32f9ace3" data-connection="" data-eventtype=""><div><div><div><div><p><img src="https://appfairness.org/wp-content/uploads/2020/09/icon-number_10.png" alt="ten"></p><div><p>All app stores will be transparent about their rules and policies and opportunities for promotion and marketing, apply these consistently and objectively, provide notice of changes, and make available a quick, simple and fair process to resolve disputes.</p></div></div></div></div></div></div></div></div></div></div></div></div></div></section></div></div></div></div></div></section><section data-id="d605c57" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="1d8304b" data-element_type="column"><div><div><div data-id="15c3e7a" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;,&quot;_animation_delay&quot;:400}" data-widget_type="text-editor.default"><div><p>The Coalition for App Fairness was created by industry leading companies who want to see freedom of choice for consumers and a level playing field for businesses. This is an open call to all developers, big and small, to join us – and together we will fight back against the monopolist control of the app ecosystem by Apple.</p></div></div></div></div></div></div></div></section></div></div></div></div></article></main></div></div></div></div>]]>
            </description>
            <link>https://appfairness.org/our-vision/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24624006</guid>
            <pubDate>Tue, 29 Sep 2020 03:50:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Possible reason for crashes of the Nvidia RTX 3080 and RTX 3090]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24623963">thread link</a>) | @g42gregory
<br/>
September 28, 2020 | https://www.igorslab.de/en/what-real-what-can-be-investigative-within-the-crashes-and-instabilities-of-the-force-rtx-3080-andrtx-3090/ | <a href="https://web.archive.org/web/*/https://www.igorslab.de/en/what-real-what-can-be-investigative-within-the-crashes-and-instabilities-of-the-force-rtx-3080-andrtx-3090/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article id="post-149171"><div><div><div><div><div><p>Not only the editors and testers were surprised by sudden instabilities of the new GeForce RTX 3080 and RTX 3090, but also the first customers who were able to get board partner cards from the first wave. An interesting pattern of behavior emerged that did not affect all cards or manufacturers and the problems only occurred at certain boost clock rates above or just around 2 GHz. To make matters worse, NVIDIA has obviously also slightly undermined the quality management of the board partners (AIC) due to the secrecy – unconsciously, of course, but with plausible consequences. A chain of adverse circumstances? This could well be the case, because this explains the somewhat diffuse error pattern from the most diverse forums.</p><h3><span><strong>Start of production without real function control?</strong></span></h3><p>Let’s start with the latter, before I get lost in the technical analyses. You probably remember when I wrote that the board partners couldn’t use working drivers yet and only work with a very limited driver and NVPunish. Since the driver problem lasted until shortly before the launch, but the first wave of cards had to be produced already, the functional testing of the first models was obviously limited to power-on and thermal stability. Running, not running. However, this does not say much about the chip quality and the possible maximum frequencies that the respective chip can safely handle.</p><p>Thus, it would at least be plausible that cards could have been sold as OC cards, which wouldn’t have passed a real quality test at the manufacturer with the delivered settings. Real binning? Nothing. Subsequent selection of particularly overclocked cards? Impossible, in fact. And so it is by no means impossible that one or the other “Potato” chip could also have gotten lost on such an OC card. We know the consequences from the posts of the buyers in the relevant forums.</p><h3><span><strong>Wrong component selection? Plausible!</strong></span></h3><p>Now let’s come to the fact that even good chips have dropped out now and then. That they are good, you can see for yourself e.g. by the boost cycle and the temperatures. So it is quite easy to find out with a selected card. This brings us now to a point that I was actually very unconsciously haunting the back of my mind at first, and which then solidified into a realization when comparing the boards of different models So let’s go directly to the “reference board” PG132, which can also be understood as a so-called Base Design. Especially the backside and especially the area below the BGA is interesting. What is interesting about such drawings and the so-called BoM (Bill of Materials) is that you are offered different placement alternatives.</p><p><a href="https://www.igorslab.de/wp-content/uploads/2020/09/Bottom-POSCAP-vs-MLCC.jpg"><img loading="lazy" src="https://www.igorslab.de/wp-content/uploads/2020/09/Bottom-POSCAP-vs-MLCC.jpg" alt="" width="980" height="765" srcset="https://www.igorslab.de/wp-content/uploads/2020/09/Bottom-POSCAP-vs-MLCC.jpg 980w, https://www.igorslab.de/wp-content/uploads/2020/09/Bottom-POSCAP-vs-MLCC-300x234.jpg 300w, https://www.igorslab.de/wp-content/uploads/2020/09/Bottom-POSCAP-vs-MLCC-768x600.jpg 768w" sizes="(max-width: 980px) 100vw, 980px"></a></p><p>I will (have to) simplify the following for better understanding. Below the BGA we see the six NECESSARY capacitors for filtering high frequencies on the voltage rails, i.e. NVVDD and MSVDD. Apart from the fact that there is still enough high-frequency “garbage” from the voltage converters, it is mainly the so-called GPU load including all jumps caused by boost, which leads to very broadband frequency mixtures, which become more extreme the higher the boost clock goes. The BoM and the drawing from June leave it open whether large-area POSCAPs (Conductive Polymer Tantalum Solid Capacitors) are used (marked in red), or rather the somewhat more expensive MLCCs (Multilayer Ceramic Chip Capacitor). The latter are smaller and have to be grouped for a higher capacity.</p><p>According to the list and specifications of Nvidia, both are possible. In terms of quality, however, good MLCCs are better able to filter the very high frequency components in particular. In the end, this is simple practical knowledge, which only often enough collides with the world view of a financial controller.&nbsp; If one searches the forums, it seems that the Zotac Trinity is particularly affected when it comes to instabilities starting at certain boost clock rates from around 2010 MHz. A feat, because Zotac is relying on a total of six cheaper POSCAPs.</p><p><a href="https://www.igorslab.de/wp-content/uploads/2020/09/Zotac-Trinity.jpg"><img loading="lazy" src="https://www.igorslab.de/wp-content/uploads/2020/09/Zotac-Trinity.jpg" alt="" width="980" height="390" srcset="https://www.igorslab.de/wp-content/uploads/2020/09/Zotac-Trinity.jpg 980w, https://www.igorslab.de/wp-content/uploads/2020/09/Zotac-Trinity-300x119.jpg 300w, https://www.igorslab.de/wp-content/uploads/2020/09/Zotac-Trinity-768x306.jpg 768w" sizes="(max-width: 980px) 100vw, 980px"></a></p><p>And what does NVIDIA do with its own Founders Editions? One does it obviously better, because I could not reproduce these stability problems with any FE even very clearly beyond 2 GHz (fan to 100%). If something went wrong, it was almost certainly a driver problem. If we take a look at the FE, we see only four SP-CAPs (red) and in the middle two MLCC groups of 10 individual capacitors each (green). This is definitely the better solution and the optimal compromise. because especially the middle areas should best be provided with suitable filters (short circuit of the high-frequency frequency mixtures).</p><p><a href="https://www.igorslab.de/wp-content/uploads/2020/09/Founders-1.jpg"><img loading="lazy" src="https://www.igorslab.de/wp-content/uploads/2020/09/Founders-1.jpg" alt="" width="980" height="406" srcset="https://www.igorslab.de/wp-content/uploads/2020/09/Founders-1.jpg 980w, https://www.igorslab.de/wp-content/uploads/2020/09/Founders-1-300x124.jpg 300w, https://www.igorslab.de/wp-content/uploads/2020/09/Founders-1-768x318.jpg 768w" sizes="(max-width: 980px) 100vw, 980px"></a></p><p>If it is only about NVVDD, a single MLCC block may be sufficient to solve the most serious problems. For example, MSI uses only one on the Gaming X Trio, which is theoretically enough, but could have been better solved if, for example, the 2.1 GHz were to be used with water. Whether this is still enough would of course have to be tested. PC Partner, Zotac’s mother company, seems to have recognised this and is obviously changing its cards. By the way, the following example is from a soldering experiment that was NOT made by Zotac, but which confirmed the effectiveness of MLCC smoothing very impressively. One can almost be envious of these soldering skills.</p><p><a href="https://www.igorslab.de/wp-content/uploads/2020/09/Hand-made-MLCC.jpg"><img loading="lazy" src="https://www.igorslab.de/wp-content/uploads/2020/09/Hand-made-MLCC.jpg" alt="" width="980" height="497" srcset="https://www.igorslab.de/wp-content/uploads/2020/09/Hand-made-MLCC.jpg 980w, https://www.igorslab.de/wp-content/uploads/2020/09/Hand-made-MLCC-300x152.jpg 300w, https://www.igorslab.de/wp-content/uploads/2020/09/Hand-made-MLCC-768x389.jpg 768w" sizes="(max-width: 980px) 100vw, 980px"></a></p><p>By the way, you also have to praise a company here that recognized the whole thing from the start and didn’t even let it touch them, as the Asus TUF RTX 3080 Gaming consequently did without POSCAPs and only used MLCC groups. My compliments, it fits!</p><p><a href="https://www.igorslab.de/wp-content/uploads/2020/09/Asus-TUF-1.jpg"><img loading="lazy" src="https://www.igorslab.de/wp-content/uploads/2020/09/Asus-TUF-1.jpg" alt="" width="980" height="439" srcset="https://www.igorslab.de/wp-content/uploads/2020/09/Asus-TUF-1.jpg 980w, https://www.igorslab.de/wp-content/uploads/2020/09/Asus-TUF-1-300x134.jpg 300w, https://www.igorslab.de/wp-content/uploads/2020/09/Asus-TUF-1-768x344.jpg 768w" sizes="(max-width: 980px) 100vw, 980px"></a></p><p>Interestingly, all board partners are silent on this issue, no matter who you ask. No answer is also an answer, because this behaviour is the absolute exception and almost resembles a muzzle decree. This is because components are normally spoken freely when the launch has already taken place. But here comes nothing but meaningful silence. This also applies to the question of whether the BoM was subsequently changed again to completely exclude the exclusive use of POSCAPs/SP-CAPs.</p><p>Sometimes things are so obvious that you really have to look several times to see them. But once you have understood it, many things suddenly go from nebulous to plausible. NVIDIA, by the way, cannot be blamed directly, because the fact that MLCCs work better than POSCAPs is something that any board designer who hasn’t taken the wrong profession knows. Such a thing can even be simulated if necessary. I will of course stay on it, because my interest is naturally aroused.</p><p>Please read also the latest follow up to that sory:</p><h2><a href="https://www.igorslab.de/en/nvidia-geforce-rtx-3080-und-rtx-3090-and-the-crash-why-the-capacitors-are-so-important-and-what-are-the-object-behind/" target="_blank" rel="noopener noreferrer">NVIDIA GeForce RTX 3080 and RTX 3090 and the crashes – Why capacitors are so important and what’s behind them</a></h2><p><iframe title="Aufgedeckt: Gründe, warum eine NVIDIA GeForce RTX 3080 oder RTX 3090 oberhalb 2 GHz crashen könnten!" width="1320" height="743" src="https://www.youtube.com/embed/7YQ7rNgoqMA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p> </div></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.igorslab.de/en/what-real-what-can-be-investigative-within-the-crashes-and-instabilities-of-the-force-rtx-3080-andrtx-3090/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24623963</guid>
            <pubDate>Tue, 29 Sep 2020 03:38:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[City of Amsterdam’s Algorithm Register]]>
            </title>
            <description>
<![CDATA[
Score 101 | Comments 20 (<a href="https://news.ycombinator.com/item?id=24623639">thread link</a>) | @cpeterso
<br/>
September 28, 2020 | https://algoritmeregister.amsterdam.nl/en/ai-register/ | <a href="https://web.archive.org/web/*/https://algoritmeregister.amsterdam.nl/en/ai-register/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-pm="normal" data-desktopportraitmargin="5|*|0|*|65|*|0|*|px+" data-tabletportraitmargin="0|*|0|*|0|*|0|*|px+" data-mobileportraitmargin="-20|*|0|*|0|*|0|*|px+" data-desktopportraitheight="0" data-has-maxwidth="1" data-desktopportraitmaxwidth="520" data-tabletportraitmaxwidth="430" data-mobileportraitmaxwidth="295" data-cssselfalign="inherit" data-desktopportraitselfalign="inherit" data-sstype="layer" data-rotation="0" data-desktopportrait="1" data-desktoplandscape="1" data-tabletportrait="1" data-tabletlandscape="1" data-mobileportrait="1" data-mobilelandscape="1" data-adaptivefont="0" data-desktopportraitfontsize="100" data-tabletportraitfontsize="90" data-mobileportraitfontsize="120" data-plugin="rendered"><div><p><br>The Algorithm Register is an overview of the artificial intelligence systems and algorithms used by the City of Amsterdam. Through the register, you can get acquainted with the quick overviews of the city's algorithmic systems or examine their more detailed information based on your own interests. You can also give feedback and thus participate in building human-centered algorithms in Amsterdam. The register is still under development.</p></div></div></div>]]>
            </description>
            <link>https://algoritmeregister.amsterdam.nl/en/ai-register/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24623639</guid>
            <pubDate>Tue, 29 Sep 2020 02:27:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Keeping Large Mammals in Zoos and Aquariums Damages Their Brains]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24623399">thread link</a>) | @laurex
<br/>
September 28, 2020 | https://science.thewire.in/environment/mammals-captivity-zoos-aquariums-brain-damage/ | <a href="https://web.archive.org/web/*/https://science.thewire.in/environment/mammals-captivity-zoos-aquariums-brain-damage/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
										                <p><em>Featured image: Lolita the Killer Whale is fed a fish by a trainer during a show at the Miami Seaquarium in Miami January 21, 2015. Photo: Reuters/Andrew Innerarity</em></p>
<p><a href="http://elephantsinjapan.com/worlds-loneliest-elephant-hanako/">Hanako</a>, a female Asian elephant, lived in a tiny concrete enclosure at Japan’s Inokashira Park Zoo for more than 60 years, often in chains, with no stimulation. In the wild, <a href="https://www.elephantvoices.org/elephant-sense-a-sociality-4/elephants-are-socially-complex.html">elephants live in herds</a>, with close family ties. Hanako was solitary for the last decade of her life.</p>
<p><a href="https://whalesanctuaryproject.org/whales/kiska-alone-again/">Kiska</a>, a young female orca, was captured in 1978 off the Iceland coast and taken to Marineland Canada, an aquarium and amusement park. Orcas are social animals that live in family <a href="https://www.nationalgeographic.com/animals/mammals/o/orca/">pods</a> with up to 40 members, but Kiska has lived alone in a small tank since 2011. Each of her five calves died. To combat stress and boredom, she swims in slow, endless circles and has gnawed her teeth to the pulp on her concrete pool.</p>


<p>Unfortunately, these are common conditions for many large, captive mammals in the “entertainment” industry. In decades of <a href="https://scholar.google.com/citations?user=KvCW9T0AAAAJ&amp;hl=en">studying the brains of humans, African elephants, humpback whales and other large mammals</a>, I’ve noted the organ’s great sensitivity to the environment, including serious impacts on its structure and function from living in captivity.</p>
<figure>
<figure><a href="https://images.theconversation.com/files/349255/original/file-20200723-31-16bcfav.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=1000&amp;fit=clip"><img data-src="https://images.theconversation.com/files/349255/original/file-20200723-31-16bcfav.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip" sizes="(min-width: 1466px) 754px, (max-width: 599px) 100vw, (min-width: 600px) 600px, 237px" data-sizes="auto" data-srcset="https://images.theconversation.com/files/349255/original/file-20200723-31-16bcfav.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=600&amp;h=560&amp;fit=crop&amp;dpr=1 600w, https://images.theconversation.com/files/349255/original/file-20200723-31-16bcfav.jpg?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=600&amp;h=560&amp;fit=crop&amp;dpr=2 1200w, https://images.theconversation.com/files/349255/original/file-20200723-31-16bcfav.jpg?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=600&amp;h=560&amp;fit=crop&amp;dpr=3 1800w, https://images.theconversation.com/files/349255/original/file-20200723-31-16bcfav.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;h=704&amp;fit=crop&amp;dpr=1 754w, https://images.theconversation.com/files/349255/original/file-20200723-31-16bcfav.jpg?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=704&amp;fit=crop&amp;dpr=2 1508w, https://images.theconversation.com/files/349255/original/file-20200723-31-16bcfav.jpg?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=754&amp;h=704&amp;fit=crop&amp;dpr=3 2262w" alt="" width="600" height="560" src="https://images.theconversation.com/files/349255/original/file-20200723-31-16bcfav.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip"></a><figcaption>Hanako, an Asian elephant kept at Japan’s Inokashira Park Zoo; and Kiska, an orca that lives at Marineland Canada. One image depicts Kiska’s damaged teeth. Elephants in Japan (left image), Ontario Captive Animal Watch (right image), CC BY-ND</figcaption></figure></figure>
<p><strong>Affecting health and altering behaviour</strong></p>
<p>It is easy to observe the overall health and psychological consequences of life in captivity for these animals. Many captive elephants suffer from arthritis, obesity or skin problems. Both <a href="https://doi.org/10.11609/JoTT.o2620.1826-36">elephants</a> and orcas often have severe dental problems. Captive orcas are plagued by <a href="https://doi.org/10.1016/j.jveb.2019.05.005">pneumonia, kidney disease, gastrointestinal illnesses and infections</a>.</p>
<p>Many animals <a href="https://doi.org/10.1016/j.neubiorev.2017.09.010">try to cope</a> with captivity by adopting abnormal behaviors. Some develop “<a href="https://doi.org/10.1016/j.applanim.2017.05.003">stereotypies</a>,” which are repetitive, purposeless habits such as constantly bobbing their heads, swaying incessantly or chewing on the bars of their cages. Others, especially big cats, pace their enclosures. Elephants rub or break their tusks.</p>
<p><ins>Also read: <a href="https://science.thewire.in/environment/lockdown-elephants-starvation/">As Captive Elephants Starve, Lockdown Brings a Problem Practice to the Fore</a></ins></p>
<p><strong>Changing brain structure</strong></p>
<p>Neuroscientific research indicates that living in an impoverished, stressful captive environment <a href="https://doi.org/10.1016/j.jveb.2019.05.005">physically damages the brain</a>. These changes have been documented in many <a href="https://doi.org/10.1002/cne.903270108">species</a>, including rodents, rabbits, cats and <a href="https://doi.org/10.1006/nimg.2001.0917">humans</a>.</p>
<p>Although researchers have directly studied some animal brains, most of what we know comes from observing animal behavior, analyzing stress hormone levels in the blood and applying knowledge gained from a half-century of neuroscience research. Laboratory research also suggests that mammals in a zoo or aquarium have compromised brain function.</p>
<figure>
<figure><a href="https://images.theconversation.com/files/359445/original/file-20200922-16-gunhd.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=1000&amp;fit=clip"><img data-src="https://images.theconversation.com/files/359445/original/file-20200922-16-gunhd.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip" sizes="(min-width: 1466px) 754px, (max-width: 599px) 100vw, (min-width: 600px) 600px, 237px" data-sizes="auto" data-srcset="https://images.theconversation.com/files/359445/original/file-20200922-16-gunhd.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=600&amp;h=803&amp;fit=crop&amp;dpr=1 600w, https://images.theconversation.com/files/359445/original/file-20200922-16-gunhd.jpg?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=600&amp;h=803&amp;fit=crop&amp;dpr=2 1200w, https://images.theconversation.com/files/359445/original/file-20200922-16-gunhd.jpg?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=600&amp;h=803&amp;fit=crop&amp;dpr=3 1800w, https://images.theconversation.com/files/359445/original/file-20200922-16-gunhd.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;h=1008&amp;fit=crop&amp;dpr=1 754w, https://images.theconversation.com/files/359445/original/file-20200922-16-gunhd.jpg?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=1008&amp;fit=crop&amp;dpr=2 1508w, https://images.theconversation.com/files/359445/original/file-20200922-16-gunhd.jpg?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=754&amp;h=1008&amp;fit=crop&amp;dpr=3 2262w" alt="" width="600" height="803" src="https://images.theconversation.com/files/359445/original/file-20200922-16-gunhd.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip"></a><figcaption>This illustration shows differences in the brain’s cerebral cortex in animals held in impoverished (captive) and enriched (natural) environments. Impoverishment results in thinning of the cortex, a decreased blood supply, less support for neurons and decreased connectivity among neurons. Photo: Arnold B. Scheibel, CC BY-ND</figcaption></figure></figure>
<p>Subsisting in confined, barren quarters that lack intellectual stimulation or appropriate social contact seems to <a href="https://doi.org/10.1590/S0001-37652001000200006">thin the cerebral cortex</a> – the part of the brain involved in voluntary movement and higher cognitive function, including memory, planning and decision-making.</p>
<p>There are other consequences. Capillaries shrink, depriving the brain of the oxygen-rich blood it needs to survive. Neurons become smaller, and their dendrites – the branches that form connections with other neurons – become less complex, impairing communication within the brain. As a result, the cortical neurons in captive animals <a href="https://doi.org/10.1002/cne.901230110">process information less efficiently</a> than those living in <a href="https://doi.org/10.1002/dev.420020208">enriched, more natural environments</a>.</p>
<figure>
<figure><a href="https://images.theconversation.com/files/349257/original/file-20200723-25-16c33n4.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=1000&amp;fit=clip"><img data-src="https://images.theconversation.com/files/349257/original/file-20200723-25-16c33n4.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip" sizes="(min-width: 1466px) 754px, (max-width: 599px) 100vw, (min-width: 600px) 600px, 237px" data-sizes="auto" data-srcset="https://images.theconversation.com/files/349257/original/file-20200723-25-16c33n4.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=600&amp;h=398&amp;fit=crop&amp;dpr=1 600w, https://images.theconversation.com/files/349257/original/file-20200723-25-16c33n4.jpg?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=600&amp;h=398&amp;fit=crop&amp;dpr=2 1200w, https://images.theconversation.com/files/349257/original/file-20200723-25-16c33n4.jpg?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=600&amp;h=398&amp;fit=crop&amp;dpr=3 1800w, https://images.theconversation.com/files/349257/original/file-20200723-25-16c33n4.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;h=500&amp;fit=crop&amp;dpr=1 754w, https://images.theconversation.com/files/349257/original/file-20200723-25-16c33n4.jpg?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=500&amp;fit=crop&amp;dpr=2 1508w, https://images.theconversation.com/files/349257/original/file-20200723-25-16c33n4.jpg?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=754&amp;h=500&amp;fit=crop&amp;dpr=3 2262w" alt="" width="600" height="398" src="https://images.theconversation.com/files/349257/original/file-20200723-25-16c33n4.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip"></a><figcaption>An actual cortical neuron in a wild African elephant living in its natural habitat compared with a hypothesized cortical neuron from a captive elephant. Photo: Bob Jacobs, CC BY-ND</figcaption></figure></figure>
<p>Brain health is also affected by living in small quarters that <a href="https://doi.org/10.3233/BPL-160040">don’t allow for needed exercise</a>. Physical activity increases the flow of blood to the brain, which requires large amounts of oxygen. Exercise increases the production of new connections and <a href="http://dx.doi.org/10.1126/science.aaw2622">enhances cognitive abilities</a>.</p>
<p>In their native habits these animals must move to survive, covering great distances to forage or find a mate. Elephants<br>
typically travel anywhere from <a href="https://www.elephantsforafrica.org/elephant-facts/#:%7E:text=How%20far%20do%20elephants%20walk,km%20on%20a%20daily%20basis.">15 to 120 miles per day</a>. In a zoo, they average <a href="https://doi.org/10.1371/journal.pone.0150331">three miles daily</a>, often walking back and forth in small enclosures. One free orca studied in Canada swam <a href="https://doi.org/10.1007/s00300-010-0958-x">up to 156 miles a day</a>; meanwhile, an average orca tank is about 10,000 times smaller than its <a href="https://www.cascadiaresearch.org/projects/killer-whales/using-dtags-study-acoustics-and-behavior-southern">natural home range</a>.</p>
<p><ins>Also read: <a href="https://science.thewire.in/the-sciences/animal-culture-meme-social-learning/">The Complex Social Lives of Animals</a></ins></p>
<p><strong>Disrupting brain chemistry and killing cells</strong></p>
<p>Living in enclosures that restrict or prevent normal behavior creates chronic frustration and boredom. In the wild, an animal’s stress-response system helps it escape from danger. But captivity traps animals with <a href="https://doi.org/10.1073/pnas.1215502109">almost no control</a> over their environment.</p>
<p>These situations foster <a href="https://doi.org/10.1037/rev0000033">learned helplessness</a>, negatively impacting the <a href="https://doi.org/10.1155/2016/6391686">hippocampus</a>, which handles memory functions, and the <a href="https://doi.org/10.1016/j.neuropharm.2011.02.024">amygdala</a>, which processes emotions. Prolonged stress <a href="https://doi.org/10.3109/10253899609001092">elevates stress hormones</a> and <a href="https://doi.org/10.1523/JNEUROSCI.10-09-02897.1990">damages or even kills neurons</a> in both brain regions. It also disrupts the <a href="https://doi.org/10.1016/j.neubiorev.2005.03.021">delicate balance of serotonin</a>, a neurotransmitter that stabilizes mood, among other functions.</p>
<p>In humans, <a href="https://doi.org/10.1006/nimg.2001.0917">deprivation</a> can trigger <a href="https://doi.org/10.3389/fnins.2018.00367">psychiatric issues</a>, including depression, anxiety, <a href="https://doi.org/10.3389/fnins.2018.00367">mood disorders</a> or <a href="https://doi.org/10.1177/1073858409333072">post-traumatic stress disorder</a>. <a href="https://doi.org/10.1007/s00429-010-0288-3">Elephants</a>, <a href="https://doi.org/10.1371/journal.pbio.0050139">orcas</a> and other animals with large brains are likely to react in similar ways to life in a severely stressful environment.</p>
<p><strong>Damaged wiring</strong></p>
<p>Captivity can damage the brain’s complex circuitry, including the basal ganglia. This group of neurons communicates with the cerebral cortex along two networks: a direct pathway that enhances movement and behavior, and an indirect pathway that inhibits them.</p>
<p>The repetitive, <a href="http://dx.doi.org/10.1016/j.bbr.2014.05.057">stereotypic behaviors</a> that many animals adopt in captivity are caused by an imbalance of two neurotransmitters, dopamine and <a href="https://doi.org/10.1016/j.neubiorev.2010.02.004">serotonin</a>. This impairs the indirect pathway’s ability to modulate movement, a condition documented in species from chickens, cows, sheep and horses to primates and big cats.</p>
<figure>
<figure><a href="https://images.theconversation.com/files/349258/original/file-20200723-17-dzrjt3.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=1000&amp;fit=clip"><img data-src="https://images.theconversation.com/files/349258/original/file-20200723-17-dzrjt3.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip" sizes="(min-width: 1466px) 754px, (max-width: 599px) 100vw, (min-width: 600px) 600px, 237px" data-sizes="auto" data-srcset="https://images.theconversation.com/files/349258/original/file-20200723-17-dzrjt3.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=600&amp;h=375&amp;fit=crop&amp;dpr=1 600w, https://images.theconversation.com/files/349258/original/file-20200723-17-dzrjt3.jpg?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=600&amp;h=375&amp;fit=crop&amp;dpr=2 1200w, https://images.theconversation.com/files/349258/original/file-20200723-17-dzrjt3.jpg?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=600&amp;h=375&amp;fit=crop&amp;dpr=3 1800w, https://images.theconversation.com/files/349258/original/file-20200723-17-dzrjt3.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;h=471&amp;fit=crop&amp;dpr=1 754w, https://images.theconversation.com/files/349258/original/file-20200723-17-dzrjt3.jpg?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=471&amp;fit=crop&amp;dpr=2 1508w, https://images.theconversation.com/files/349258/original/file-20200723-17-dzrjt3.jpg?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=754&amp;h=471&amp;fit=crop&amp;dpr=3 2262w" alt="Image of brain showing areas affected by captivity" width="600" height="375" src="https://images.theconversation.com/files/349258/original/file-20200723-17-dzrjt3.jpg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip"></a><figcaption>The cerebral cortex, hippocampus and amygdala are physically altered by captivity, along with brain circuitry that involves the basal ganglia. PHoto: Bob Jacobs, CC BY-ND</figcaption></figure></figure>
<p>Evolution has constructed animal brains to be exquisitely responsive to their environment. Those reactions can affect neural function by <a href="https://www.penguinrandomhouse.com/books/311787/behave-by-robert-m-sapolsky/">turning different genes on or off</a>. Living in inappropriate or abusive circumstance alters biochemical processes: It disrupts the synthesis of proteins that build connections between brain cells and the neurotransmitters that facilitate communication among them.</p>
<p>There is strong evidence that <a href="https://doi.org/10.1523/JNEUROSCI.0577-11.2011">enrichment</a>, social contact and appropriate space in more natural habitats are <a href="https://doi.org/10.1111/j.1748-1090.2003.tb02071.x">necessary</a> for long-lived animals with large brains such as <a href="https://doi.org/10.1371/journal.pone.0152490">elephants</a> and <a href="https://doi.org/10.1080/13880292.2017.1309858">cetaceans</a>. Better conditions <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5543669/">reduce disturbing sterotypical behaviors</a>, improve connections in the brain, and <a href="https://doi.org/10.1038/cdd.2009.193">trigger neurochemical changes</a> that enhance learning and memory.</p>
<p><ins>Also read:&nbsp;<a href="https://thewire.in/environment/elephants-bengal-deaths-kerala-drought">Giving Elephants the Space They Need, One SMS at a Time</a></ins></p>
<p><strong>The captivity question</strong></p>
<p>Some people defend keeping animals in captivity, arguing that it helps conserve endangered species or offers educational benefits for <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.574.3479&amp;rep=rep1&amp;type=pdf">visitors to zoos and aquariums</a>. These justifications are questionable, particularly for <a href="https://animalstudiesrepository.org/acwp_zoae/8/">large mammals</a>. As my own research and work by many other scientists shows, caging large mammals and putting them on display is undeniably cruel from a neural perspective. It causes brain damage.</p>
<p>Public perceptions of captivity are slowly changing, as shown by the reaction to the documentary <em><a href="https://en.wikipedia.org/wiki/Blackfish_(film)">Blackfish</a></em>. For animals that cannot be free, there are well-designed sanctuaries. Several already exist for elephants and other large mammals in <a href="https://www.elephants.com/">Tennessee</a>, <a href="https://globalelephants.org/overview/">Brazil</a> and Northern <a href="http://www.pawsweb.org/about_our_sanctuaries.html">California</a>. Others are being developed for large <a href="https://whalesanctuaryproject.org/">cetaceans</a>.</p>
<p>Perhaps it is not too late for Kiska.</p>
<p><em>Dr. Lori Marino, president of the Whale Sanctuary Project and a former senior lecturer at Emory University, contributed to this article.<br>
</em><!-- Below is The Conversation's page counter tag. Please DO NOT REMOVE. --><img src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" data-src="https://counter.theconversation.com/content/142240/count.gif?distributor=republish-lightbox-basic" alt="The Conversation" width="1" height="1"><!-- End of code. If you don't see any code above, please get new code from the Advanced tab after you click the republish button. The page counter does not collect any personal data. More info: https://theconversation.com/republishing-guidelines --><br>
<em>Bob Jacobs is a Professor of Neuroscience at Colorado College</em></p>
<p><em>This article is republished from </em><a href="https://theconversation.com/">The Conversation</a><em> under a Creative Commons license. Read the <a href="https://theconversation.com/the-neural-cruelty-of-captivity-keeping-large-mammals-in-zoos-and-aquariums-damages-their-brains-142240">original article</a>.</em></p>

<!-- AI CONTENT END 1 -->
																												              </div></div>]]>
            </description>
            <link>https://science.thewire.in/environment/mammals-captivity-zoos-aquariums-brain-damage/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24623399</guid>
            <pubDate>Tue, 29 Sep 2020 01:48:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using machine learning to create images to match Sufjan Stevens lyrics]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24623366">thread link</a>) | @no_bear_so_low
<br/>
September 28, 2020 | https://deponysum.com/2020/09/26/artificial-intelligence-dreams-images-to-accompany-sufjan-stevens-lyrics/ | <a href="https://web.archive.org/web/*/https://deponysum.com/2020/09/26/artificial-intelligence-dreams-images-to-accompany-sufjan-stevens-lyrics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
	<p><a href="#content">Skip to content</a></p><header id="masthead" role="banner">
		<div>
							<p><a href="https://deponysum.com/" rel="home">DePonySum</a></p>
							<p>Immanentize the eschaton but carefully. Check out our Twitter @sumdepony, and our subreddit at r/deponysum</p>
					</div>

		<nav id="site-navigation" role="navigation">
			
			<div><ul id="menu-primary"><li id="menu-item-6"><a href="https://deponysum.com/">Home</a></li>
<li id="menu-item-7"><a href="https://deponysum.com/contact/">Contact</a></li>
</ul></div>		</nav><!-- #site-navigation -->
	</header><!-- #masthead -->

	<div id="content">
		
	<div id="primary">
		<main id="main" role="main">

		
			
<article id="post-2524">
	<header>
				
		<div>
			<p><span><a href="https://deponysum.com/2020/09/26/artificial-intelligence-dreams-images-to-accompany-sufjan-stevens-lyrics/" rel="bookmark"><time datetime="2020-09-26T23:54:48+01:00">26th Sep 2020</time><time datetime="2020-09-27T03:38:36+01:00">27th Sep 2020</time></a></span><span><span><span> ~ </span><a href="https://deponysum.com/author/deponysum/">deponysum</a></span></span>					</p></div><!-- .entry-meta -->
	</header><!-- .entry-header -->

	<div>
		
<p>Continuing this blog’s project of creating Sufjan themed art using AI I’ve automatically generated a collection of images to accompany Sufjan lyrics. Using this <a href="https://vision-explorer.allenai.org/text_to_image_generation" rel="nofollow">https://vision-explorer.allenai.org/text_to_image_generation</a> I gave a computer program hundreds of Sufjan Steven lyrics and picked the best results.</p>



<figure><img data-attachment-id="2526" data-permalink="https://deponysum.com/i-was-dressed-in-white/" data-orig-file="https://deponysum.files.wordpress.com/2020/09/i-was-dressed-in-white.png" data-orig-size="400,401" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="i-was-dressed-in-white" data-image-description="" data-medium-file="https://deponysum.files.wordpress.com/2020/09/i-was-dressed-in-white.png?w=300" data-large-file="https://deponysum.files.wordpress.com/2020/09/i-was-dressed-in-white.png?w=400" src="https://deponysum.files.wordpress.com/2020/09/i-was-dressed-in-white.png?w=400" alt="" srcset="https://deponysum.files.wordpress.com/2020/09/i-was-dressed-in-white.png 400w, https://deponysum.files.wordpress.com/2020/09/i-was-dressed-in-white.png?w=150 150w, https://deponysum.files.wordpress.com/2020/09/i-was-dressed-in-white.png?w=300 300w" sizes="(max-width: 400px) 100vw, 400px"><figcaption><strong>I was dressed in white</strong></figcaption></figure>



<figure><img data-attachment-id="2543" data-permalink="https://deponysum.com/you-stare-at-the-sun-to-see-the-sublime/" data-orig-file="https://deponysum.files.wordpress.com/2020/09/you-stare-at-the-sun-to-see-the-sublime.png" data-orig-size="400,401" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="you-stare-at-the-sun-to-see-the-sublime" data-image-description="" data-medium-file="https://deponysum.files.wordpress.com/2020/09/you-stare-at-the-sun-to-see-the-sublime.png?w=300" data-large-file="https://deponysum.files.wordpress.com/2020/09/you-stare-at-the-sun-to-see-the-sublime.png?w=400" src="https://deponysum.files.wordpress.com/2020/09/you-stare-at-the-sun-to-see-the-sublime.png?w=400" alt="" srcset="https://deponysum.files.wordpress.com/2020/09/you-stare-at-the-sun-to-see-the-sublime.png 400w, https://deponysum.files.wordpress.com/2020/09/you-stare-at-the-sun-to-see-the-sublime.png?w=150 150w, https://deponysum.files.wordpress.com/2020/09/you-stare-at-the-sun-to-see-the-sublime.png?w=300 300w" sizes="(max-width: 400px) 100vw, 400px"><figcaption><strong>You stare at the sun to see the sublime</strong></figcaption></figure>



<figure><img data-attachment-id="2552" data-permalink="https://deponysum.com/the-lion-and-the-lamb-were-restored/" data-orig-file="https://deponysum.files.wordpress.com/2020/09/the-lion-and-the-lamb-were-restored.png" data-orig-size="400,401" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="the-lion-and-the-lamb-were-restored" data-image-description="" data-medium-file="https://deponysum.files.wordpress.com/2020/09/the-lion-and-the-lamb-were-restored.png?w=300" data-large-file="https://deponysum.files.wordpress.com/2020/09/the-lion-and-the-lamb-were-restored.png?w=400" src="https://deponysum.files.wordpress.com/2020/09/the-lion-and-the-lamb-were-restored.png?w=400" alt="" srcset="https://deponysum.files.wordpress.com/2020/09/the-lion-and-the-lamb-were-restored.png 400w, https://deponysum.files.wordpress.com/2020/09/the-lion-and-the-lamb-were-restored.png?w=150 150w, https://deponysum.files.wordpress.com/2020/09/the-lion-and-the-lamb-were-restored.png?w=300 300w" sizes="(max-width: 400px) 100vw, 400px"><figcaption><strong>The lion and the lamb were restored</strong></figcaption></figure>



<figure><img data-attachment-id="2527" data-permalink="https://deponysum.com/his-father-was-a-drinker/" data-orig-file="https://deponysum.files.wordpress.com/2020/09/his-father-was-a-drinker.png" data-orig-size="400,401" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="his-father-was-a-drinker" data-image-description="" data-medium-file="https://deponysum.files.wordpress.com/2020/09/his-father-was-a-drinker.png?w=300" data-large-file="https://deponysum.files.wordpress.com/2020/09/his-father-was-a-drinker.png?w=400" src="https://deponysum.files.wordpress.com/2020/09/his-father-was-a-drinker.png?w=400" alt="" srcset="https://deponysum.files.wordpress.com/2020/09/his-father-was-a-drinker.png 400w, https://deponysum.files.wordpress.com/2020/09/his-father-was-a-drinker.png?w=150 150w, https://deponysum.files.wordpress.com/2020/09/his-father-was-a-drinker.png?w=300 300w" sizes="(max-width: 400px) 100vw, 400px"><figcaption><strong>His father was a drinker</strong></figcaption></figure>



<figure><img data-attachment-id="2529" data-permalink="https://deponysum.com/in-the-tower-above-the-earth/" data-orig-file="https://deponysum.files.wordpress.com/2020/09/in-the-tower-above-the-earth.png" data-orig-size="400,401" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="in-the-tower-above-the-earth" data-image-description="" data-medium-file="https://deponysum.files.wordpress.com/2020/09/in-the-tower-above-the-earth.png?w=300" data-large-file="https://deponysum.files.wordpress.com/2020/09/in-the-tower-above-the-earth.png?w=400" src="https://deponysum.files.wordpress.com/2020/09/in-the-tower-above-the-earth.png?w=400" alt="" srcset="https://deponysum.files.wordpress.com/2020/09/in-the-tower-above-the-earth.png 400w, https://deponysum.files.wordpress.com/2020/09/in-the-tower-above-the-earth.png?w=150 150w, https://deponysum.files.wordpress.com/2020/09/in-the-tower-above-the-earth.png?w=300 300w" sizes="(max-width: 400px) 100vw, 400px"><figcaption><strong>In the tower above the earth</strong></figcaption></figure>



<figure><img data-attachment-id="2530" data-permalink="https://deponysum.com/all-things-grow/" data-orig-file="https://deponysum.files.wordpress.com/2020/09/all-things-grow.png" data-orig-size="400,401" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="all-things-grow" data-image-description="" data-medium-file="https://deponysum.files.wordpress.com/2020/09/all-things-grow.png?w=300" data-large-file="https://deponysum.files.wordpress.com/2020/09/all-things-grow.png?w=400" src="https://deponysum.files.wordpress.com/2020/09/all-things-grow.png?w=400" alt="" srcset="https://deponysum.files.wordpress.com/2020/09/all-things-grow.png 400w, https://deponysum.files.wordpress.com/2020/09/all-things-grow.png?w=150 150w, https://deponysum.files.wordpress.com/2020/09/all-things-grow.png?w=300 300w" sizes="(max-width: 400px) 100vw, 400px"><figcaption><strong>All things grow</strong></figcaption></figure>



<figure><img data-attachment-id="2532" data-permalink="https://deponysum.com/ill-find-sleep-ill-find-peace/" data-orig-file="https://deponysum.files.wordpress.com/2020/09/ill-find-sleep-ill-find-peace.png" data-orig-size="400,401" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ill-find-sleep-ill-find-peace" data-image-description="" data-medium-file="https://deponysum.files.wordpress.com/2020/09/ill-find-sleep-ill-find-peace.png?w=300" data-large-file="https://deponysum.files.wordpress.com/2020/09/ill-find-sleep-ill-find-peace.png?w=400" src="https://deponysum.files.wordpress.com/2020/09/ill-find-sleep-ill-find-peace.png?w=400" alt="" srcset="https://deponysum.files.wordpress.com/2020/09/ill-find-sleep-ill-find-peace.png 400w, https://deponysum.files.wordpress.com/2020/09/ill-find-sleep-ill-find-peace.png?w=150 150w, https://deponysum.files.wordpress.com/2020/09/ill-find-sleep-ill-find-peace.png?w=300 300w" sizes="(max-width: 400px) 100vw, 400px"><figcaption><strong>I’ll find sleep, I’ll find peace</strong></figcaption></figure>



<figure><img data-attachment-id="2534" data-permalink="https://deponysum.com/its-your-own-damn-head-on-that-plate/" data-orig-file="https://deponysum.files.wordpress.com/2020/09/its-your-own-damn-head-on-that-plate.png" data-orig-size="400,401" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="its-your-own-damn-head-on-that-plate" data-image-description="" data-medium-file="https://deponysum.files.wordpress.com/2020/09/its-your-own-damn-head-on-that-plate.png?w=300" data-large-file="https://deponysum.files.wordpress.com/2020/09/its-your-own-damn-head-on-that-plate.png?w=400" src="https://deponysum.files.wordpress.com/2020/09/its-your-own-damn-head-on-that-plate.png?w=400" alt="" srcset="https://deponysum.files.wordpress.com/2020/09/its-your-own-damn-head-on-that-plate.png 400w, https://deponysum.files.wordpress.com/2020/09/its-your-own-damn-head-on-that-plate.png?w=150 150w, https://deponysum.files.wordpress.com/2020/09/its-your-own-damn-head-on-that-plate.png?w=300 300w" sizes="(max-width: 400px) 100vw, 400px"><figcaption><strong>It’s your own damn head on that plate</strong></figcaption></figure>



<figure><img data-attachment-id="2535" data-permalink="https://deponysum.com/justice-delivers-its-death/" data-orig-file="https://deponysum.files.wordpress.com/2020/09/justice-delivers-its-death.png" data-orig-size="400,401" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="justice-delivers-its-death" data-image-description="" data-medium-file="https://deponysum.files.wordpress.com/2020/09/justice-delivers-its-death.png?w=300" data-large-file="https://deponysum.files.wordpress.com/2020/09/justice-delivers-its-death.png?w=400" src="https://deponysum.files.wordpress.com/2020/09/justice-delivers-its-death.png?w=400" alt="" srcset="https://deponysum.files.wordpress.com/2020/09/justice-delivers-its-death.png 400w, https://deponysum.files.wordpress.com/2020/09/justice-delivers-its-death.png?w=150 150w, https://deponysum.files.wordpress.com/2020/09/justice-delivers-its-death.png?w=300 300w" sizes="(max-width: 400px) 100vw, 400px"><figcaption><strong>Justice delivers its death</strong></figcaption></figure>



<figure><img data-attachment-id="2537" data-permalink="https://deponysum.com/blackbird-on-my-shoulder/" data-orig-file="https://deponysum.files.wordpress.com/2020/09/blackbird-on-my-shoulder.png" data-orig-size="400,401" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="blackbird-on-my-shoulder" data-image-description="" data-medium-file="https://deponysum.files.wordpress.com/2020/09/blackbird-on-my-shoulder.png?w=300" data-large-file="https://deponysum.files.wordpress.com/2020/09/blackbird-on-my-shoulder.png?w=400" src="https://deponysum.files.wordpress.com/2020/09/blackbird-on-my-shoulder.png?w=400" alt="" srcset="https://deponysum.files.wordpress.com/2020/09/blackbird-on-my-shoulder.png 400w, https://deponysum.files.wordpress.com/2020/09/blackbird-on-my-shoulder.png?w=150 150w, https://deponysum.files.wordpress.com/2020/09/blackbird-on-my-shoulder.png?w=300 300w" sizes="(max-width: 400px) 100vw, 400px"><figcaption><strong>Blackbird on my shoulder</strong></figcaption></figure>



<figure><img data-attachment-id="2540" data-permalink="https://deponysum.com/i-built-your-walls-around-me/" data-orig-file="https://deponysum.files.wordpress.com/2020/09/i-built-your-walls-around-me.png" data-orig-size="400,401" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="i-built-your-walls-around-me" data-image-description="" data-medium-file="https://deponysum.files.wordpress.com/2020/09/i-built-your-walls-around-me.png?w=300" data-large-file="https://deponysum.files.wordpress.com/2020/09/i-built-your-walls-around-me.png?w=400" src="https://deponysum.files.wordpress.com/2020/09/i-built-your-walls-around-me.png?w=400" alt="" srcset="https://deponysum.files.wordpress.com/2020/09/i-built-your-walls-around-me.png 400w, https://deponysum.files.wordpress.com/2020/09/i-built-your-walls-around-me.png?w=150 150w, https://deponysum.files.wordpress.com/2020/09/i-built-your-walls-around-me.png?w=300 300w" sizes="(max-width: 400px) 100vw, 400px"><figcaption><strong>I built your walls around me</strong></figcaption></figure>



<figure><img data-attachment-id="2541" data-permalink="https://deponysum.com/all-of-me-wants-all-of-you/" data-orig-file="https://deponysum.files.wordpress.com/2020/09/all-of-me-wants-all-of-you.png" data-orig-size="400,401" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="all-of-me-wants-all-of-you" data-image-description="" data-medium-file="https://deponysum.files.wordpress.com/2020/09/all-of-me-wants-all-of-you.png?w=300" data-large-file="https://deponysum.files.wordpress.com/2020/09/all-of-me-wants-all-of-you.png?w=400" src="https://deponysum.files.wordpress.com/2020/09/all-of-me-wants-all-of-you.png?w=400" alt="" srcset="https://deponysum.files.wordpress.com/2020/09/all-of-me-wants-all-of-you.png 400w, https://deponysum.files.wordpress.com/2020/09/all-of-me-wants-all-of-you.png?w=150 150w, https://deponysum.files.wordpress.com/2020/09/all-of-me-wants-all-of-you.png?w=300 300w" sizes="(max-width: 400px) 100vw, 400px"><figcaption><strong>All of me wants all of you</strong></figcaption></figure>



<figure><img data-attachment-id="2547" data-permalink="https://deponysum.com/signs-and-wonders/" data-orig-file="https://deponysum.files.wordpress.com/2020/09/signs-and-wonders.png" data-orig-size="400,401" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="signs-and-wonders" data-image-description="" data-medium-file="https://deponysum.files.wordpress.com/2020/09/signs-and-wonders.png?w=300" data-large-file="https://deponysum.files.wordpress.com/2020/09/signs-and-wonders.png?w=400" src="https://deponysum.files.wordpress.com/2020/09/signs-and-wonders.png?w=400" alt="" srcset="https://deponysum.files.wordpress.com/2020/09/signs-and-wonders.png 400w, https://deponysum.files.wordpress.com/2020/09/signs-and-wonders.png?w=150 150w, https://deponysum.files.wordpress.com/2020/09/signs-and-wonders.png?w=300 300w" sizes="(max-width: 400px) 100vw, 400px"><figcaption><strong>Signs and wonders</strong></figcaption></figure>



<figure><img data-attachment-id="2549" data-permalink="https://deponysum.com/my-friend-ran-away/" data-orig-file="https://deponysum.files.wordpress.com/2020/09/my-friend-ran-away.png" data-orig-size="400,401" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="my-friend-ran-away" data-image-description="" data-medium-file="https://deponysum.files.wordpress.com/2020/09/my-friend-ran-away.png?w=300" data-large-file="https://deponysum.files.wordpress.com/2020/09/my-friend-ran-away.png?w=400" src="https://deponysum.files.wordpress.com/2020/09/my-friend-ran-away.png?w=400" alt="" srcset="https://deponysum.files.wordpress.com/2020/09/my-friend-ran-away.png 400w, https://deponysum.files.wordpress.com/2020/09/my-friend-ran-away.png?w=150 150w, https://deponysum.files.wordpress.com/2020/09/my-friend-ran-away.png?w=300 300w" sizes="(max-width: 400px) 100vw, 400px"><figcaption><strong>My friend is gone, he ran away</strong></figcaption></figure>



<figure><img data-attachment-id="2555" data-permalink="https://deponysum.com/we-were-ashamed-of-her/" data-orig-file="https://deponysum.files.wordpress.com/2020/09/we-were-ashamed-of-her.png" data-orig-size="400,401" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="we-were-ashamed-of-her" data-image-description="" data-medium-file="https://deponysum.files.wordpress.com/2020/09/we-were-ashamed-of-her.png?w=300" data-large-file="https://deponysum.files.wordpress.com/2020/09/we-were-ashamed-of-her.png?w=400" src="https://deponysum.files.wordpress.com/2020/09/we-were-ashamed-of-her.png?w=400" alt="" srcset="https://deponysum.files.wordpress.com/2020/09/we-were-ashamed-of-her.png 400w, https://deponysum.files.wordpress.com/2020/09/we-were-ashamed-of-her.png?w=150 150w, https://deponysum.files.wordpress.com/2020/09/we-were-ashamed-of-her.png?w=300 300w" sizes="(max-width: 400px) 100vw, 400px"><figcaption><strong>We were ashamed of her</strong></figcaption></figure>



<figure><img data-attachment-id="2556" data-permalink="https://deponysum.com/were-all-going-to-die/" data-orig-file="https://deponysum.files.wordpress.com/2020/09/were-all-going-to-die.png" data-orig-size="400,401" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="were-all-going-to-die" data-image-description="" data-medium-file="https://deponysum.files.wordpress.com/2020/09/were-all-going-to-die.png?w=300" data-large-file="https://deponysum.files.wordpress.com/2020/09/were-all-going-to-die.png?w=400" src="https://deponysum.files.wordpress.com/2020/09/were-all-going-to-die.png?w=400" alt="" srcset="https://deponysum.files.wordpress.com/2020/09/were-all-going-to-die.png 400w, https://deponysum.files.wordpress.com/2020/09/were-all-going-to-die.png?w=150 150w, https://deponysum.files.wordpress.com/2020/09/were-all-going-to-die.png?w=300 300w" sizes="(max-width: 400px) 100vw, 400px"><figcaption><strong>We’re all going to die</strong></figcaption></figure>
			</div><!-- .entry-content -->

	<!-- .entry-footer -->

		<div>
				<p><img alt="" src="https://2.gravatar.com/avatar/844c2b3fe77c2f3e30212fe26c1c30f2?s=60&amp;d=identicon&amp;r=G" height="60" width="60">		</p><!-- .author-avatar -->
		
		<p>
			<h2>Published by <span>deponysum</span></h2>
		</p><!-- .author-heading -->

		<p>
						<a href="https://deponysum.com/author/deponysum/" rel="author">
				View all posts by deponysum			</a>
		</p><!-- .author-bio -->
	</div><!-- .entry-auhtor -->
</article><!-- #post-## -->

			
	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		<div><div><p><a href="https://deponysum.com/2020/09/25/should-you-vote/" rel="prev"><span>‹ Previous</span>Should you vote?</a></p></div><div><p><a href="https://deponysum.com/2020/09/29/in-a-shocking-twist-reddit-protects-a-structurally-racist-judicial-system-from-criticism/" rel="next"><span>Next ›</span>In a shocking twist, Reddit protects a structurally racist judicial system from&nbsp;criticism</a></p></div></div>
	</nav>
			
<div id="comments">

	
	
	
		<div id="respond">
		<h3 id="reply-title">Leave a Reply <small></small></h3><form action="https://deponysum.com/wp-comments-post.php" method="post" id="commentform" novalidate="">


<div>
	<p><label for="comment">Enter your comment here...</label></p>
</div>

<div id="comment-form-identity">
	<div id="comment-form-nascar">
		<p>Fill in your details below or click an icon to log in:</p>
		<ul>
			
			<li>
				<a href="#comment-form-load-service:WordPress.com" id="postas-wordpress" title="Login via WordPress.com">
					<svg xmlns="http://www.w3.org/2000/svg" role="presentation" viewBox="0 0 24 24"><rect x="0" fill="none" width="24" height="24"></rect><g><path fill="#0087be" d="M12.158 12.786l-2.698 7.84c.806.236 1.657.365 2.54.365 1.047 0 2.05-.18 2.986-.51-.024-.037-.046-.078-.065-.123l-2.762-7.57zM3.008 12c0 3.56 2.07 6.634 5.068 8.092L3.788 8.342c-.5 1.117-.78 2.354-.78 3.658zm15.06-.454c0-1.112-.398-1.88-.74-2.48-.456-.74-.883-1.368-.883-2.11 0-.825.627-1.595 1.51-1.595.04 0 .078.006.116.008-1.598-1.464-3.73-2.36-6.07-2.36-3.14 0-5.904 1.613-7.512 4.053.21.008.41.012.58.012.94 0 2.395-.114 2.395-.114.484-.028.54.684.057.74 0 0-.487.058-1.03.086l3.275 9.74 1.968-5.902-1.4-3.838c-.485-.028-.944-.085-.944-.085-.486-.03-.43-.77.056-.742 0 0 1.484.114 2.368.114.94 0 2.397-.114 2.397-.114.486-.028.543.684.058.74 0 0-.488.058-1.03.086l3.25 9.665.897-2.997c.456-1.17.684-2.137.684-2.907zm1.82-3.86c.04.286.06.593.06.924 0 .912-.17 1.938-.683 3.22l-2.746 7.94c2.672-1.558 4.47-4.454 4.47-7.77 0-1.564-.4-3.033-1.1-4.314zM12 22C6.486 22 2 17.514 2 12S6.486 2 12 2s10 4.486 10 10-4.486 10-10 10z"></path></g></svg>				</a>
			</li>
			<li>
				<a href="#comment-form-load-service:Twitter" id="postas-twitter" title="Login via Twitter">
					<svg xmlns="http://www.w3.org/2000/svg" role="presentation" viewBox="0 0 24 24"><rect x="0" fill="none" width="24" height="24"></rect><g><path fill="#1DA1F2" d="M22.23 5.924c-.736.326-1.527.547-2.357.646.847-.508 1.498-1.312 1.804-2.27-.793.47-1.67.812-2.606.996C18.325 4.498 17.258 4 16.078 4c-2.266 0-4.103 1.837-4.103 4.103 0 .322.036.635.106.935-3.41-.17-6.433-1.804-8.457-4.287-.353.607-.556 1.312-.556 2.064 0 1.424.724 2.68 1.825 3.415-.673-.022-1.305-.207-1.86-.514v.052c0 1.988 1.415 3.647 3.293 4.023-.344.095-.707.145-1.08.145-.265 0-.522-.026-.773-.074.522 1.63 2.038 2.817 3.833 2.85-1.404 1.1-3.174 1.757-5.096 1.757-.332 0-.66-.02-.98-.057 1.816 1.164 3.973 1.843 6.29 1.843 7.547 0 11.675-6.252 11.675-11.675 0-.178-.004-.355-.012-.53.802-.578 1.497-1.3 2.047-2.124z"></path></g></svg>				</a>
			</li>
			<li>
				<a href="#comment-form-load-service:Facebook" id="postas-facebook" title="Login via Facebook">
					<svg xmlns="http://www.w3.org/2000/svg" role="presentation" viewBox="0 0 24 24"><rect x="0" fill="none" width="24" height="24"></rect><g><path fill="#3B5998" d="M20.007 3H3.993C3.445 3 3 3.445 3 3.993v16.013c0 .55.445.994.993.994h8.62v-6.97H10.27V11.31h2.346V9.31c0-2.325 1.42-3.59 3.494-3.59.993 0 1.847.073 2.096.106v2.43h-1.438c-1.128 0-1.346.537-1.346 1.324v1.734h2.69l-.35 2.717h-2.34V21h4.587c.548 0 .993-.445.993-.993V3.993c0-.548-.445-.993-.993-.993z"></path></g></svg>				</a>
			</li>
		</ul>
	</div>

	<div id="comment-form-guest">
		<div>
			<p><a href="https://gravatar.com/site/signup/" target="_blank">				<img src="https://1.gravatar.com/avatar/ad516503a11cd5ca435acc9bb6523536?s=25&amp;d=identicon&amp;forcedefault=y&amp;r=G" alt="Gravatar" width="25">
</a>			</p>

				<div>
				<div>
					<p><label for="email">Email <span>(required)</span> <span>(Address never made public)</span></label></p>
				</div>
				<div>
					<p><label for="author">Name <span>(required)</span></label></p>
				</div>
				<div>
					<p><label for="url">Website</label></p>
				</div>
			</div>
			
		</div>
	</div>

	<div id="comment-form-wordpress">
		<div>
			<p><img src="https://1.gravatar.com/avatar/ad516503a11cd5ca435acc9bb6523536?s=25&amp;d=identicon&amp;forcedefault=y&amp;r=G" alt="WordPress.com Logo" width="25">
			</p>

				<div>
				<p>
			<strong></strong>
			You are commenting using your WordPress.com account.			<span>
				(&nbsp;Log&nbsp;Out&nbsp;/&nbsp;
				<a href="#" onclick="javascript:HighlanderComments.switchAccount();return false;">Change</a>&nbsp;)
			</span>
			<span><svg xmlns="http://www.w3.org/2000/svg" role="presentation" viewBox="0 0 24 24"><rect x="0" fill="none" width="24" height="24"></rect><g><path fill="#0087be" d="M12.158 12.786l-2.698 7.84c.806.236 1.657.365 2.54.365 1.047 0 2.05-.18 2.986-.51-.024-.037-.046-.078-.065-.123l-2.762-7.57zM3.008 12c0 3.56 2.07 6.634 5.068 8.092L3.788 8.342c-.5 1.117-.78 2.354-.78 3.658zm15.06-.454c0-1.112-.398-1.88-.74-2.48-.456-.74-.883-1.368-.883-2.11 0-.825.627-1.595 1.51-1.595.04 0 .078.006.116.008-1.598-1.464-3.73-2.36-6.07-2.36-3.14 0-5.904 1.613-7.512 4.053.21.008.41.012.58.012.94 0 2.395-.114 2.395-.114.484-.028.54.684.057.74 0 0-.487.058-1.03.086l3.275 9.74 1.968-5.902-1.4-3.838c-.485-.028-.944-.085-.944-.085-.486-.03-.43-.77.056-.742 0 0 1.484.114 2.368.114.94 0 2.397-.114 2.397-.114.486-.028.543.684.058.74 0 0-.488.058-1.03.086l3.25 9.665.897-2.997c.456-1.17.684-2.137.684-2.907zm1.82-3.86c.04.286.06.593.06.924 0 .912-.17 1.938-.683 3.22l-2.746 7.94c2.672-1.558 4.47-4.454 4.47-7.77 0-1.564-.4-3.033-1.1-4.314zM12 22C6.486 22 2 17.514 2 12S6.486 2 12 2s10 4.486 10 10-4.486 10-10 10z"></path></g></svg></span>
		</p>
					</div>
	
		</div>
	</div>

	<div id="comment-form-googleplus">
		<div>
			<p><img src="https://1.gravatar.com/avatar/ad516503a11cd5ca435acc9bb6523536?s=25&amp;d=identicon&amp;forcedefault=y&amp;r=G" alt="Google photo" width="25">
			</p>

				<div>
				<p>
			<strong></strong>
			You are commenting using your Google account.			<span>
				(&nbsp;Log&nbsp;Out&nbsp;/&nbsp;
				<a href="#" onclick="javascript:HighlanderComments.switchAccount();return false;">Change</a>&nbsp;)
			</span>
			<span><svg xmlns="http://www.w3.org/2000/svg" role="presentation" x="0px" y="0px" viewBox="0 0 60 60"><path fill="#519bf7" d="M56.3,30c0,-1.6 -0.2,-3.4 -0.6,-5h-3.1H42.2H30v10.6h14.8C44,39.3 42,42 39.1,43.9l8.8,6.8C53,46 56.3,39 56.3,30z"></path><path fill="#3db366" d="M30,57.5c6.7,0 13.1,-2.4 17.9,-6.8l-8.8,-6.8c-2.5,1.6 -5.6,2.4 -9.1,2.4c-7.2,0 -13.3,-4.7 -15.4,-11.2l-9.3,7.1C9.8,51.3 19.1,57.5 30,57.5z"></path><path fill="#fdc600" d="M5.3,42.2l9.3,-7.1c-0.5,-1.6 -0.8,-3.3 -0.8,-5.1s0.3,-3.5 0.8,-5.1l-9.3,-7.1C3.5,21.5 2.5,25.6 2.5,30S3.5,38.5 5.3,42.2z"></path><path fill="#f15b44" d="M40.1,17.4l8,-8C43.3,5.1 37,2.5 30,2.5C19.1,2.5 9.8,8.7 5.3,17.8l9.3,7.1c2.1,-6.5 8.2,-11.1 15.4,-11.1C33.9,13.7 37.4,15.1 40.1,17.4z"></path></svg></span>
		</p>
					</div>
	
		</div>
	</div>

	<div id="comment-form-twitter">
		<div>
			<p><img src="https://1.gravatar.com/avatar/ad516503a11cd5ca435acc9bb6523536?s=25&amp;d=identicon&amp;forcedefault=y&amp;r=G" alt="Twitter picture" width="25">
			</p>

				<div>
				<p>
			<strong></strong>
			You are commenting using your Twitter account.			<span>
				(&nbsp;Log&nbsp;Out&nbsp;/&nbsp;
				<a href="#" onclick="javascript:HighlanderComments.switchAccount();return false;">Change</a>&nbsp;)
			</span>
			<span><svg xmlns="http://www.w3.org/2000/svg" role="presentation" viewBox="0 0 24 24"><rect x="0" fill="none" width="24" height="24"></rect><g><path fill="#1DA1F2" d="M22.23 5.924c-.736.326-1.527.547-2.357.646.847-.508 1.498-1.312 1.804-2.27-.793.47-1.67.812-2.606.996C18.325 4.498 17.258 4 16.078 4c-2.266 0-4.103 1.837-4.103 4.103 0 .322.036.635.106.935-3.41-.17-6.433-1.804-8.457-4.287-.353.607-.556 1.312-.556 2.064 0 1.424.724 2.68 1.825 3.415-.673-.022-1.305-.207-1.86-.514v.052c0 1.988 1.415 3.647 3.293 4.023-.344.095-.707.145-1.08.145-.265 0-.522-.026-.773-.074.522 1.63 2.038 2.817 3.833 2.85-1.404 1.1-3.174 1.757-5.096 1.757-.332 0-.66-.02-.98-.057 1.816 1.164 3.973 1.843 6.29 1.843 7.547 0 11.675-6.252 11.675-11.675 0-.178-.004-.355-.012-.53.802-.578 1.497-1.3 2.047-2.124z"></path></g></svg></span>
		</p>
					</div>
	
		</div>
	</div>

	<div id="comment-form-facebook">
		<div>
			<p><img src="https://1.gravatar.com/avatar/ad516503a11cd5ca435acc9bb6523536?s=25&amp;d=identicon&amp;forcedefault=y&amp;r=G" alt="Facebook photo" width="25">
			</p>

				<div>
				<p>
			<strong></strong>
			You are commenting using your Facebook account.			<span>
				(&nbsp;Log&nbsp;Out&nbsp;/&nbsp;
				<a href="#" onclick="javascript:HighlanderComments.switchAccount();return false;">Change</a>&nbsp;)
			</span>
			<span><svg xmlns="http://www.w3.org/2000/svg" role="presentation" viewBox="0 0 24 24"><rect x="0" fill="none" width="24" height="24"></rect><g><path fill="#3B5998" d="M20.007 3H3.993C3.445 3 3 3.445 3 3.993v16.013c0 .55.445.994.993.994h8.62v-6.97H10.27V11.31h2.346V9.31c0-2.325 1.42-3.59 3.494-3.59.993 0 1.847.073 2.096.106v2.43h-1.438c-1.128 0-1.346.537-1.346 1.324v1.734h2.69l-.35 2.717h-2.34V21h4.587c.548 0 .993-.445.993-.993V3.993c0-.548-.445-.993-.993-.993z"></path></g></svg></span>
		</p>
					</div>
	
		</div>
	</div>


	<div id="comment-form-load-service">
		<div><p>Cancel</p></div>
		<p>Connecting to %s</p>
	</div>

</div>



<div id="comment-form-subscribe">
	<p> <label id="subscribe-label" for="subscribe">Notify me of new comments via email.</label></p><p> <label id="subscribe-blog-label" for="subscribe_blog">Notify me of new posts via email.</label></p></div>






</form>	</div><!-- #respond -->
	
</div><!-- #comments -->

		
		</main><!-- #main -->
	</div><!-- #primary -->

	<div id="secondary" role="complementary">
			</div><!-- #secondary -->

	</div><!-- #content -->

	<!-- #colophon -->
</div></div>]]>
            </description>
            <link>https://deponysum.com/2020/09/26/artificial-intelligence-dreams-images-to-accompany-sufjan-stevens-lyrics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24623366</guid>
            <pubDate>Tue, 29 Sep 2020 01:42:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CMake: Public vs Private vs Interface]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24623282">thread link</a>) | @keyboardman
<br/>
September 28, 2020 | https://leimao.github.io/blog/CMake-Public-Private-Interface/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/CMake-Public-Private-Interface/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>CMake is one of the most convenient building tools for C/C++ projects. When it comes to <a href="https://cmake.org/cmake/help/latest/command/target_include_directories.html"><code>target_include_directories</code></a> and <a href="https://cmake.org/cmake/help/latest/command/target_link_libraries.html"><code>target_link_libraries</code></a>, there are several keywords, <code>PUBLIC</code>, <code>PRIVATE</code>, and <code>INTERFACE</code>, that I got confused about from time to time even if I have read the related official documentations. So When I was building my C/C++ projects using CMake, I often just use <code>PUBLIC</code> everywhere or leave the keyword blank (CMake will then use <code>PUBLIC</code> by default), the libraries and executables built from the projects would work in most of the scenarios. However, it is certainly not best practice.</p>



<p>Today, I read Kuba Sejdak’s blog post <a href="https://kubasejdak.com/modern-cmake-is-like-inheritance">“Modern CMake is Like Inheritance”</a> and I found his interpretation on the CMake keywords <code>PUBLIC</code>, <code>PRIVATE</code>, and <code>INTERFACE</code> inspiring. So in this blog post, I would like to discuss some of my thoughts on these CMake keywords from the perspective of “inheritance”.</p>

<h3 id="c-inheritance">C++ Inheritance</h3>

<h4 id="access-specifiers">Access Specifiers</h4>

<p>In C++ object oriented programming, there are three types of access specifiers for classes.</p>



<table>
<thead>
  <tr>
    <th>Access Specifier</th>
    <th>Description</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>public</td>
    <td>Members are accessible from outside the class.</td>
  </tr>
  <tr>
    <td>protected</td>
    <td>Members cannot be accessed from outside the class. However, they can be accessed in inherited classes.</td>
  </tr>
  <tr>
    <td>private</td>
    <td>Members cannot be accessed (or viewed) from outside the class.</td>
  </tr>
</tbody>
</table>

<p>Alternatively, this could be described using the following simplified table.</p>



<table>
<thead>
  <tr>
    <th>Access Specifier</th>
    <th>Same Class</th>
    <th>Derived Class</th>
    <th>Outside Class</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>public</td>
    <td>Yes</td>
    <td>Yes</td>
    <td>Yes</td>
  </tr>
  <tr>
    <td>protected</td>
    <td>Yes</td>
    <td>Yes</td>
    <td>No</td>
  </tr>
  <tr>
    <td><span>private</span></td>
    <td>Yes</td>
    <td>No</td>
    <td>No</td>
  </tr>
</tbody>
</table>

<h4 id="inheritance-types">Inheritance Types</h4>

<p>When it comes to class inheritance, there are also three types of inheritances.</p>



<table>
<thead>
  <tr>
    <th>Inheritance Type</th>
    <th>Description</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>public</td>
    <td>Public members of the base class become public members of the derived class and protected members of the base class become protected members of the derived class. A base class's private members are never accessible directly from a derived class, but can be accessed through calls to the public and protected members of the base class.</td>
  </tr>
  <tr>
    <td><span>protected</span></td>
    <td>Public and protected members of the base class become protected members of the derived class.</td>
  </tr>
  <tr>
    <td>private</td>
    <td>Public and protected members of the base class become private members of the derived class.<br></td>
  </tr>
</tbody>
</table>

<p>Alternatively, this could be described using the following simplified table.</p>



<table>
<thead>
  <tr>
    <th>Inheritance Type</th>
    <th>base: public member</th>
    <th><span>base: </span>protected <span>member</span></th>
    <th><span>base: </span>private <span>member</span></th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>public</td>
    <td>derived: public member</td>
    <td><span>derived: </span>protected member</td>
    <td>-</td>
  </tr>
  <tr>
    <td>protected</td>
    <td><span>derived: </span>protected <span>member</span></td>
    <td><span>derived:</span> protected <span>member</span></td>
    <td>-</td>
  </tr>
  <tr>
    <td>private</td>
    <td><span>derived:</span> private <span>member</span></td>
    <td><span>derived:</span> private <span>member</span></td>
    <td>-</td>
  </tr>
</tbody>
</table>

<h3 id="cmake-inheritance">CMake Inheritance</h3>

<p>CMake uses somewhat similar inheritance concepts to C++, especially for the C++ <code>public</code> and <code>private</code> access specifiers and inheritance types. The CMake keywords <code>PUBLIC</code>, <code>PRIVATE</code>, and <code>INTERFACE</code> used in <code>target_include_directories</code> and <code>target_link_libraries</code>, in my opinion, are mixtures of access specifier and inheritance type from C++.</p>

<h4 id="include-inheritance">Include Inheritance</h4>

<p>In CMake, for any <code>target</code>, in the preprocessing stage, it comes with a <code>INCLUDE_DIRECTORIES</code> and a <code>INTERFACE_INCLUDE_DIRECTORIES</code> for searching the header files building. <code>target_include_directories</code> will populate all the directories to <code>INCLUDE_DIRECTORIES</code> and/or <code>INTERFACE_INCLUDE_DIRECTORIES</code> depending on the keyword <code>&lt;PRIVATE|PUBLIC|INTERFACE&gt;</code> we specified. The <code>INCLUDE_DIRECTORIES</code> will be used for the current <code>target</code> only and the <code>INTERFACE_INCLUDE_DIRECTORIES</code> will be appended to the <code>INCLUDE_DIRECTORIES</code> of any other <code>target</code> which has dependencies on the current <code>target</code>. With such settings, the configurations of <code>INCLUDE_DIRECTORIES</code> and <code>INTERFACE_INCLUDE_DIRECTORIES</code> for all building targets are easy to compute and scale up even for multiple hierarchical layers of building dependencies and many building targets.</p>



<table>
<thead>
  <tr>
    <th>Include Inheritance</th>
    <th>Description</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>PUBLIC</td>
    <td>All the directories following PUBLIC will be used for the current target and <span>the other targets that have dependencies on the current target, i.e., appending the directories to </span>INCLUDE_DIRECTORIES and INTERFACE_INCLUDE_DIRECTORIES.</td>
  </tr>
  <tr>
    <td>PRIVATE</td>
    <td><span>All the include directories following PRIVATE will be used for the current target only</span>, i.e., appending the directories to <span>INCLUDE_DIRECTORIES.</span></td>
  </tr>
  <tr>
    <td>INTERFACE</td>
    <td><span>All the include directories following INTERFACE</span> will NOT be used for the current target but will be accessible for the other targets that have dependencies on the current target<span>, i.e., appending the directories to </span>INTERFACE_INCLUDE_DIRECTORIES.</td>
  </tr>
</tbody>
</table>

<p>Note that when we do <code>target_link_libraries(&lt;target&gt; &lt;PRIVATE|PUBLIC|INTERFACE&gt; &lt;item&gt;)</code>, the dependent <code>&lt;item&gt;</code>, if built in the same CMake project, would append the <code>INTERFACE_INCLUDE_DIRECTORIES</code> of <code>&lt;item&gt;</code> to the <code>INCLUDE_DIRECTORIES</code> of <code>&lt;target&gt;</code>. By controlling the <code>INTERFACE_INCLUDE_DIRECTORIES</code>, we could eliminate some unwanted or conflicting declarations from <code>&lt;item&gt;</code> to the <code>&lt;target&gt;</code>.</p>



<p>For example, the <code>fruit</code> library has <code>INCLUDE_DIRECTORIES</code> of <code>fruit_h</code>, <code>tree_h</code>, and <code>INTERFACE_INCLUDE_DIRECTORIES</code> of <code>fruit_h</code>. If there is a <code>apple</code> library that is linked with the <code>fruit</code> library, the <code>apple</code> library would also have the <code>fruit_h</code> in its <code>INCLUDE_DIRECTORIES</code> as well. We could equivalently say, the <code>apple</code> library’s include directory inherited the <code>fruit_h</code> of the  <code>fruit</code> library.</p>

<h4 id="link-inheritance">Link Inheritance</h4>

<p>Similarly, for any <code>target</code>, in the linking stage, we would need to decide, given the <code>item</code> to be linked, whether we have to put the <code>item</code> in the link dependencies, or the link interface, or both, in the compiled <code>target</code>. Here the link dependencies means the <code>item</code> has some implementations that the <code>target</code> would use, and it is linked to the <code>item</code>, so that whenever we call the functions or methods corresponding to those implementations it will always be mapped correctly to the implementations in <code>item</code> via the link, whereas the link interface means the <code>target</code> becomes an interface for linking the <code>item</code> for other targets which have dependencies on the <code>target</code>, and the <code>target</code> does not have to use <code>item</code> at all.</p>



<table>
<thead>
  <tr>
    <th>Link Type</th>
    <th>Description</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>PUBLIC</td>
    <td>All the objects following PUBLIC will be used for linking to the current target and providing the interface to the other targets that have dependencies on the current target.</td>
  </tr>
  <tr>
    <td>PRIVATE</td>
    <td><span>All the objects following </span>PRIVATE will only be used for linking to the current target.</td>
  </tr>
  <tr>
    <td>INTERFACE</td>
    <td><span>All the objects following </span>INTERFACE will only be used for providing the interface to the other targets that have dependencies on the current target.</td>
  </tr>
</tbody>
</table>

<p>For example, if the <code>fruit</code> library has the implementation of functions, such as <code>size</code> and <code>color</code>, and the <code>apple</code> library has a function <code>apple_size</code> which called the <code>size</code> from the <code>fruit</code> library and was <code>PRIVATE</code> linked with the <code>fruit</code> library. We could create an executable <code>eat_apple</code> that calls <code>apple_size</code> by <code>PUBLIC</code> or <code>PRIVATE</code> linking with the <code>apple</code> library. However, if we want to create an executable <code>eat_apple</code> that calls the <code>size</code> and <code>color</code> from the <code>fruit</code> library, only linking with the <code>apple</code> library will cause building error, since the <code>fruit</code> library was not part of the interface in the <code>apple</code> library, and is thus inaccessible to <code>eat_apple</code>. To make the <code>apple</code> library to inherit the <code>size</code> and <code>color</code> from the <code>fruit</code> library, we have to make the linking of the <code>apple</code> library to the the <code>fruit</code> library <code>PUBLIC</code> instead of <code>PRIVATE</code>.</p>

<h3 id="conclusions">Conclusions</h3>

<p>The CMake builds a hierarchical project via the include interface or link interface. The “inheritance” mechanism in C++ is built upon the include interface or link interface.</p>

<h3 id="faq">FAQ</h3>

<h4 id="how-to-understand-cmake-interface">How to Understand CMake Interface?</h4>

<p>In my understanding, CMake interface is just like a telephone switch station in old times.</p>

<div>
<figure>
    <img src="https://leimao.github.io/images/blog/2020-08-08-CMake-Public-Private-Interface/medienwandel-chicago-union-station-telegraph-switchboard.jpg">
    <figcaption>Telephone Switch Station</figcaption>
</figure>
</div>

<p>If <code>A</code> wants to call <code>B</code> and there is no direct telephone cable connection between <code>A</code> and <code>B</code>, <code>A</code> has to call a telephone switch station that has connection to <code>B</code> and the personal in the telephone switch station will connect <code>A</code> and <code>B</code> by jointing the cable of <code>A</code> and the cable of <code>B</code> together. If the telephone switch station does not know there is a <code>B</code>, it is impossible to get <code>A</code> and <code>B</code> connected. So CMake interface is simply a registration in the telephone switch station. When there is a dependency in CMake targets, targets from different levels of hierarchy are connected via interfaces, for both <code>include</code> and <code>link</code>.</p>

<h4 id="what-are-the-key-points-for-this-blog-post">What are the Key Points for This Blog Post?</h4>

<p><code>PRIVATE</code> only cares about himself and does not allow inheritance. <code>INTERFACE</code> only cares about others and allows inheritance. <code>PUBLIC</code> cares about everyone and allows inheritance.</p>

<h4 id="is-public-private-interface-part-of-the-gccg-compiler">Is PUBLIC, PRIVATE, INTERFACE Part of the GCC/G++ Compiler?</h4>

<p>No. Compilers, such as <code>gcc</code> and <code>g++</code>, do not have such mechanism. CMake invented those keywords for user to create a building graph that has very clear and explicit dependencies. The building graph translates to normal building commands using <code>gcc</code> and <code>g++</code>.</p>

<h3 id="references">References</h3>

<ul>
  <li><a href="https://kubasejdak.com/modern-cmake-is-like-inheritance">Modern CMake is Like Inheritance</a></li>
</ul>

      <hr>
      
    </div></div>]]>
            </description>
            <link>https://leimao.github.io/blog/CMake-Public-Private-Interface/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24623282</guid>
            <pubDate>Tue, 29 Sep 2020 01:27:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenStreetMap State of the Map conf 2020 – a few thoughts on the experiment]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24623160">thread link</a>) | @pabs3
<br/>
September 28, 2020 | http://blog.imagico.de/sotm-2020-a-few-thoughts-on-the-experiment/ | <a href="https://web.archive.org/web/*/http://blog.imagico.de/sotm-2020-a-few-thoughts-on-the-experiment/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p>Last weekend has been the <a href="https://2020.stateofthemap.org/">2020 State of the Map conference</a> – which did not take place like it was originally planned and as it has been conducted in the past years at a specific physical place (in this case Capetown, South Africa) but was done in a purely virtual distributed form across the internet.</p>
<p>I regard this change – forced by the pandemic situation we all struggle with these days in some form – as in a way a welcome disruption.  Due to an outside event the powers-that-be have been forced to try something they would not have tried probably in many years to come otherwise.</p>
<p>The implementation of the virtual distributed conference as an afterthought on an originally planned physical single place event led of course to some flaws and inconsistencies in the practical setup and to not using the full potential of the virtual setting in all of its aspects.  This is obviously owed a lot to the desire not to throw away work already done.  The most obvious issue resulting from that approach is that the main conference program contained almost exclusively program items submitted by people under the original premise of a physical conference – or in other words:  The chance to hold a talk at the virtual conference still depended on the willingness and ability of people to travel to South Africa and be there for the talk in person.</p>
<p>This means the conference in its program was not even remotely as diverse as it could have been it it had been set up as a distributed remote conference in the first place.  This should IMO be kept in mind by everyone evaluating how SotM 2020 turned out.</p>
<p>I regard the whole event mostly as an experiment to test various techniques and methods and means of communication to have a virtual conference in the OSM context.  This applies both to behind-the-scene infrastructure and the public interfaces.  If the SotM WG documents and shares their findings publicly that could have use far beyond SotM for the OSM community.</p>
<h3>Practical observations from the conference</h3>
<p>The pads for collecting questions and comments on talks worked great.  This is definitely a concept that could play a central role in future distributed conferences.  Initially the questions were asked anonymously which has led in particular in case of Frederik’s talk to quite a lot of people making vile comments under the disguise of anonymity.  It was later established that questions and comments should be signed.  I also think that the use of pads could be extended to non-talk program items like self organized sessions.</p>
<div id="attachment_9119"><p><a href="https://pad.sotm.bitcast.co.za/p/general-feedback"><img src="http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_pad.png" alt="" width="512" height="429" srcset="http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_pad.png 512w, http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_pad-320x268.png 320w" sizes="(max-width: 512px) 100vw, 512px"></a></p><p>general feedback pad of the conference – there was a similar pad for questions and comments on each of the talks</p></div>
<p>The attractiveness of the pads to a large extent comes from the real time capability (which is essential for a real time conference obviously) combined with the non-linear free form structure of the text (which contrasts pleasantly with most other real time communication channels that tend to have a strictly linear structure).</p>
<p>There are quite a few things that could be improved about the audio.  This starts with the levels of the pause music relative to the talk audio levels and continues with reverberations in poorly dampened rooms of some presenters and feedback noise in some people’s audio setup.  That is mostly a matter of sufficient testing and experience with setting up and adjusting equipment in a way that works well.  That takes time from everyone involved obviously.  This is the hardest the first time but gets easier once you gain experience.  And i am confident with the corona virus crisis incentivizing many people to gain more practice in remote communication knowledge and experience in this field is much improving every day.  More communication about how to ensure good audio recording and communication quality within the community, sharing experiences and techniques used, would definitely be helpful.</p>
<p>None the less what also became clear to me during the conference is that the willingness of people to engage in communication was very clearly in the order written conversation &gt; audio communication &gt; video.  I think this is an observation to consider for any audio or video conversation in the OSM context.  Video meetings might be very convenient for heavily engaged extroverted community members with a pre-existing prominence but for many people this can be a source of discomfort.  And cultural and language barriers can be strongly emphasized by use of real time audio and especially video communication.</p>
<h3>Comments on the talks</h3>
<p>I have not watched all the talks of the conference so this is more a list of anecdotal observations than a complete review.  All the talks of the main conference program were pre-recorded while the Q&amp;A after the talks were live.  The pre-recorded talks offered a lot of options for presenters which would not be available in a live conference talk and which were used very differently by the presenters.  Ilya in his talk <em><a href="https://2020.stateofthemap.org/sessions/CKYTVS">Send me a Postcard</a></em> IMO showed the most innovative approach to this.  Watching this talk is recommended to anyone who in the future might be in the position to pre-record a conference talk as a positive example.</p>
<p>Some of the talks i watched so far that i consider particularly interesting:</p>
<div id="attachment_9121"><p><a href="https://2020.stateofthemap.org/sessions/RRVNAM"><img src="http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_allan2.png" alt="" width="512" height="288" srcset="http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_allan2.png 512w, http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_allan2-320x180.png 320w" sizes="(max-width: 512px) 100vw, 512px"></a></p><p>Allan’s American perspective on the political spectrum of OSM</p></div>
<p>Allan’s keynote <em><a href="https://2020.stateofthemap.org/sessions/RRVNAM">Winds of Change in OpenStreetMap</a></em> – While this did not provide much new information of substance to those following OSMF politics in general and who have read past statements from Allan on that subject, it seems to provide a valuable glimpse into the current mentality of the OSMF board regarding their work.  Although Allan had a prominent disclaimer that these are his personal views and do not represent those of the board, it is quite clear from statements and actions of other board members that they see many of these things similarly.  There is quite a lot of accurate analysis in the talk but also quite a few highly questionable selective perceptions, assumptions and conclusions.  I might comment about some of those separately although it is not clear at this time if the board is currently willing to openly discuss the merits of their views and opinions on the OSM community and the future of the OSM project and on the OSMFs role and defend their views and conclusions on these matters in a public setting.</p>
<div id="attachment_9122"><p><a href="https://2020.stateofthemap.org/sessions/DYXWDC"><img src="http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_fred.png" alt="" width="512" height="288" srcset="http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_fred.png 512w, http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_fred-320x180.png 320w" sizes="(max-width: 512px) 100vw, 512px"></a></p><p>Frederik explaining OpenStreetMap</p></div>
<p>Frederik’s talk <em><a href="https://2020.stateofthemap.org/sessions/DYXWDC">There might have been a misunderstanding…</a></em> – As usual Frederik explains in a well understandable way many of the central aspects of the OpenStreetMap project which new contributors as well as data users often struggle with because they differ from what people are used to, either in other internet communities or in the world of geodata.  Naturally, a lot of these frequently misunderstood aspects of OSM are also fairly controversial and this has – as hinted above – led to a lot of critical and in parts insulting comments on the talk by people who would like these things to change and for OSM to become more compatible with their expectations.  What Frederik presents however is for the most part not wishful thinking – presenting how he would like OSM to be – but how OpenStreetMap actually works and functions based on knowledge derived from many years of practical involvement in the project.  Other long term participants will largely be able to confirm that.  So whether you like these aspects of OSM or not and in what direction you might want OSM to develop in the future this is a very useful talk to watch to understand how OpenStreetMap ticks.  </p>
<div id="attachment_9123"><p><a href="https://2020.stateofthemap.org/sessions/RHDUV9"><img src="http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_mikel.png" alt="" width="512" height="288" srcset="http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_mikel.png 512w, http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_mikel-320x180.png 320w" sizes="(max-width: 512px) 100vw, 512px"></a></p><p>Mikel mocking concerns about conflicts of interest of corporate employees in the OSMF</p></div>
<p>Mikel’s talk <em><a href="https://2020.stateofthemap.org/sessions/RHDUV9">An Incomplete History of Companies and Professionals in OpenStreetMap</a></em> – Essentially Mikel is painting corporate activities in OSM and their history in rosy colors while saying: just pay no attention to all the skeletons lying around here.  A lot could be criticized about selective presentations of facts as well as factual and logical errors or about the technique of jokingly dismissing and ridiculing differentiated philosophical critique of the influence of corporate interests in OSM.  Anyway – I think this is a valuable talk to watch to get a glimpse into the mindset of many corporate employees involved in OSM as part of or in relation to their job.  </p>
<div id="attachment_9124"><p><a href="https://2020.stateofthemap.org/sessions/DZ8PWQ"><img src="http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_janet.png" alt="" width="512" height="288" srcset="http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_janet.png 512w, http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_janet-320x180.png 320w" sizes="(max-width: 512px) 100vw, 512px"></a></p><p>Janet explaining aid work in rural Tanzania</p></div>
<p>Janet’s talk <em><a href="https://2020.stateofthemap.org/sessions/DZ8PWQ">Building mapping communities in rural Tanzania – challenges, successes and lessons learnt</a></em> – I found this interesting because of a certain observation.  In the beginning a number of specific non mapping related examples are shown of aid being given to people in rural areas of Tanzania for everyday life problems.  And emphasis is admirably given to helping locals solving these problems themselves in a sustainable and independent fashion using locally available means.  Yet when it comes to mapping and digital technology the same initiative (and from what i know also many other humanitarian mapping projects) critiquelessly rely on commercial services and proprietary tools and encourage locals to use and rely on those services and tools that increase and perpetuate dependence of local people on non-local corporations for their local mapping work instead of educating people in using open source technology and tools they can manage and control themselves.</p>
<p>To be clear, i am not at all saying that this talk in any way constitutes an example for particularly bad practice in that regard, on the contrary the examples shown illustrate a principal awareness of the issue that is missing elsewhere.  But to me it demonstrates quite well how fundamentally different measures are applied to the goal of supplying aid in a way that enables locals to solve serious problems in a sustainable fashion outside the digital world and within it.  </p>
<div id="attachment_9125"><p><a href="https://2020.stateofthemap.org/sessions/CKYTVS"><img src="http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_ilya.png" alt="" width="512" height="288" srcset="http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_ilya.png 512w, http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_ilya-320x180.png 320w" sizes="(max-width: 512px) 100vw, 512px"></a></p><p>Ilya making a case for sending postcards in an innovative style video</p></div>
<p>Ilya’s talk <em><a href="https://2020.stateofthemap.org/sessions/CKYTVS">Send me a Postcard</a></em> – I mentioned his talk already above as an example for making innovative use of the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://blog.imagico.de/sotm-2020-a-few-thoughts-on-the-experiment/">http://blog.imagico.de/sotm-2020-a-few-thoughts-on-the-experiment/</a></em></p>]]>
            </description>
            <link>http://blog.imagico.de/sotm-2020-a-few-thoughts-on-the-experiment/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24623160</guid>
            <pubDate>Tue, 29 Sep 2020 01:09:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Julia mixed precision GEMM codegen meets and exceeds CUBLAS]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24623153">thread link</a>) | @amkkma
<br/>
September 28, 2020 | https://juliagpu.org/2020-09-28-gemmkernels/ | <a href="https://web.archive.org/web/*/https://juliagpu.org/2020-09-28-gemmkernels/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <main id="main">
        





<i data-feather="calendar"></i> <time datetime="2020-09-28">Sep 28, 2020</time>




  <br>
  <i data-feather="edit-2"></i> Thomas Faingnaert, Tim Besard, Bjorn De Sutter


<p>General Matrix Multiplication or GEMM kernels take center place in high performance
computing and machine learning. Recent NVIDIA GPUs include GEMM accelerators, such as
NVIDIA’s Tensor Cores. In this paper we show how it is possible to program these
accelerators from Julia, and present abstractions and interfaces that allow to do so
efficiently without sacrificing performance.</p>
<p>A pre-print of the paper has been published on arXiv:
<a href="https://arxiv.org/abs/2009.12263">arXiv:2009.12263</a>. <br> The source code can be found on
GitHub:
<a href="https://github.com/thomasfaingnaert/GemmKernels.jl">thomasfaingnaert/GemmKernels.jl</a>.</p>
<p>With the APIs from GemmKernels.jl, it is possible to instantiate GEMM kernels that perform
in the same ball park as, and sometimes even outperform state-of-the-art libraries like
CUBLAS and CUTLASS. For example, performing a mixed-precision multiplication of two 16-bit
matrixes into a 32-bit accumulator (on different combinations of layouts):</p>


<figure>
	<img src="https://juliagpu.org/2020-09-28-gemmkernels/mixed_precision.png" alt="Performance of mixed-precision GEMM">
</figure>

<p>The APIs are also highly flexible and allow customization of each step, e.g., to apply the
activation function <code>max(x, 0)</code> for implementing a rectified linear unit (ReLU):</p>
<div><pre><code data-lang="julia">a <span>=</span> CuArray(rand(<span>Float16</span>, (M, K)))
b <span>=</span> CuArray(rand(<span>Float16</span>, (K, N)))
c <span>=</span> CuArray(rand(<span>Float32</span>, (M, N)))
d <span>=</span> similar(c)

conf <span>=</span> GemmKernels<span>.</span>get_config(
    gemm_shape <span>=</span> (M <span>=</span> M, N <span>=</span> N, K <span>=</span> K),
    operator <span>=</span> Operator<span>.</span>WMMAOp{<span>16</span>, <span>16</span>, <span>16</span>},
    global_a_layout <span>=</span> Layout<span>.</span>AlignedColMajor{<span>Float16</span>},
    global_c_layout <span>=</span> Layout<span>.</span>AlignedColMajor{<span>Float32</span>})

GemmKernels<span>.</span>matmul(
    a, b, c, d, conf;
    transform_regs_to_shared_d <span>=</span> Transform<span>.</span>Elementwise(x <span>-&gt;</span> max(x, <span>0</span>)))
</code></pre></div><p>The GemmKernels.jl framework is written entirely in Julia, demonstrating the
high-performance GPU programming capabilities of this language, but at the same time keeping
the research accessible and easy to modify or repurpose by other Julia developers.</p>



      </main>
    </div></div>]]>
            </description>
            <link>https://juliagpu.org/2020-09-28-gemmkernels/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24623153</guid>
            <pubDate>Tue, 29 Sep 2020 01:08:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenBSD on the Desktop (Part I)]]>
            </title>
            <description>
<![CDATA[
Score 85 | Comments 49 (<a href="https://news.ycombinator.com/item?id=24622788">thread link</a>) | @upofadown
<br/>
September 28, 2020 | https://paedubucher.ch/articles/2020-09-05-openbsd-on-the-desktop-part-i.html | <a href="https://web.archive.org/web/*/https://paedubucher.ch/articles/2020-09-05-openbsd-on-the-desktop-part-i.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Let's install OpenBSD on a Lenovo Thinkpad X270. I used this computer for my
computer science studies. It has both Arch Linux and Windows 10 installed as
dual boot. Now that I'm no longer required to run Windows, I can ditch the dual
boot and install an operating system of my choice.</p>

<p>First, I grab my work Thinkpad running Arch Linux and some USB dongle big enough
for the <a href="https://cdn.openbsd.org/pub/OpenBSD/6.7/amd64/miniroot67.fs">amd64 miniroot
image</a> (roughly
five megabytes, that is). This small image does not include the file sets, which
will be downloaded during installation instead. I also download the <a href="https://mirror.ungleich.ch/pub/OpenBSD/6.7/amd64/SHA256">SHA256
checksums</a> from the
Swiss mirror, and verify the downloaded image, before I copy it on my dongle:</p>
<pre><code>$ sha256sum -c --ignore-missing SHA256 
miniroot67.fs: OK
$ sudo dd if=miniroot67.fs of=/dev/sda bs=1M
</code></pre>

<p>The Thinkpad X270 is connected to my network through Ethernet. The WiFi firmware
usually needs to be installed separately, so only Ethernet will work out of the
box. The BIOS has UEFI activated. OpenBSD and UEFI has issues on older hardware
(at least on a 2014 Dell laptop I have), but let's try it on this laptop,
anyway.</p>
<p>I plug in the dongle prepared before, and start the computer. I interrupt
the regular boot with Enter and pick an alternative boot method by pressing F12.
Now I pick my USB dongle. After roughly a minute, the installer has been
started. Now I follow these steps:</p>
<ul>
<li>I choose the option <code>I</code> to install OpenBSD.</li>
<li>For the keyboard layout, I pick <code>sg</code>, for Swiss German.</li>
<li>As a hostname, I simply pick <code>x270</code>, because it's a Thinkpad X270, and I'm not
  very creative when it comes to naming things.</li>
<li>From the available network options (<code>iwm0</code>: WiFi, <code>em0</code>: Ethernet, and
  <code>vlan0</code>: Virtual LAN), I pick <code>em0</code>.</li>
<li>I try to get an IPv4 address over DHCP, which seems to work very quickly.</li>
<li>Next, I type in my very secret root password twice.</li>
<li>I do <em>not</em> start <code>sshd</code> by default, because I don't need to connect to this
  machine through SSH. It's supposed to be a workstation, not a server.</li>
<li>The X Window System should not be started by <code>xnodm(1)</code>, so I leave it to
  <code>no</code>.</li>
<li>Neither do I want to change the default to <code>com0</code>.</li>
<li>I set up my user <code>patrick</code> with my proper name <code>Patrick Bucher</code>, and a decent
  password.</li>
<li>The time zone has been detected properly as <code>Europe/Zurich</code>, which I just
  leave the way it is.</li>
<li>The installer detected two disks: <code>sd0</code> and <code>sd1</code>. Since <code>sd0</code> is the detected
  SSD in my laptop, the UEFI issue from my Dell laptop doesn't exist on this
  computer. I pick <code>sd0</code> for the root disk, since <code>sd1</code> is my USB dongle.</li>
<li>I choose to use the whole disk with a GPT partitioning schema, because it's
  2020.</li>
<li>An auto-allocated layout for <code>sd0</code> is presented. It looks decent to me, so I
  just go with that auto layout.</li>
<li>I don't want to initialize another disk, so I just press Enter (<code>done</code>).</li>
<li>Since the miniroot image does not come with the file sets, I pick <code>http</code> as
  the location for the sets.</li>
<li>I don't use a proxy, and use the mirror <code>mirrog.ungleich.ch</code> and the server
  directory <code>pub/OpenBSD/6.7/amd64</code> as proposed.</li>
<li>Next, I unselect the game sets by entering <code>-game*</code>. (I heard that they're not
  much fun to play.) I leave all the other sets activated, including the <code>x</code>
  sets, which will be required for the GUI later on.</li>
<li>After those sets are installed, I press Enter (<code>done</code>). Now the installer
  performs various tasks, after which I choose to <code>halt</code> the computer. This
  gives me time to remove the USB dongle.</li>
</ul>

<p>I now restart my laptop, and OpenBSD boots. This takes more time than booting
Arch Linux, which uses <code>systemd</code>, whereas OpenBSD uses <code>rc</code>, which performs the
startup tasks sequentially.</p>
<p>There's a message showing up that various firmware (<code>intel-firmware</code>,
<code>iwm-firmware</code>, <code>inteldrm-firmware</code>, <code>uvideo-firmware</code>, and <code>vmm-firmware</code>) has
been installed automatically. Very nice, indeed.</p>
<h2>WiFi Connection</h2>
<p>Now that the <code>iwm-firmware</code> has been installed, I can connect right away to my
WiFi network <code>frzbxpdb5</code>. I create a file called <code>/etc/hostname.iwm0</code>, wich
<code>hostname</code> being a literal string, and <code>iwm0</code> being the WiFi network card. The
connection to my WiFi network consists of a single line:</p>
<pre><code>dhcp nwid frzbxpdb5 wpakey [my-wpakey]
</code></pre>
<p>Whereas <code>frzbxpdb5</code> is my WiFi network's ESSID, and <code>[my-wpakey]</code> needs to be
replaced by the actual WPA key.</p>
<p>Then the networking can be restarted for that device:</p>
<pre><code># sh /etc/netstart iwm0
</code></pre>
<p>This script is kind enough to set the file permissions of <code>/etc/hostname.iwm0</code>
to <code>640</code>, and then connects to my WiFi network.</p>
<p>I unplug the Ethernet cable and <code>ping openbsd.org</code>, which works fine, even after
a restart.</p>

<p>My GUI on Unix-like systems is based on the Dynamic Window Manager (<code>dwm</code>) and a
couple of other tools, such as <code>dmenu</code>, <code>st</code>, <code>slstatus</code>, <code>slock</code>, all created and
maintained by the <a href="http://suckless.org/">Suckless</a> community.</p>
<p>This software doesn't come with configuration facilities, but needs to be
configured in the respective C header file <code>config.h</code>, and then re-compiled.
Even though OpenBSD offers <code>dwm</code> as a package, customizing and configuring that
window manager requires to build it from source.</p>
<h2>Building <code>dwm</code> and Friends</h2>
<p>First, I need to install <code>git</code> to fetch the source code:</p>
<pre><code># pkg_add git
</code></pre>
<p>Then I fetch the source code for <code>dwm</code>, <code>dmenu</code>, <code>st</code>, and <code>slstatus</code> from <a href="http://suckless.org/">Suckless</a>:</p>
<pre><code>$ git clone https://git.suckless.org/dwm
$ git clone https://git.suckless.org/dmenu
$ git clone https://git.suckless.org/st
$ git clone https://git.suckless.org/slstatus
</code></pre>
<h3>Building <code>dwm</code></h3>
<p>Next, I try to build <code>dwm</code>:</p>
<pre><code>$ cd dwm
$ make
</code></pre>
<p>This fails with an error message (<code>'ft2build.h' file not found</code>), which reminds
me of building <code>dwm</code> on FreeBSD roughly a month before. Since I can finde the
header file at another location:</p>
<pre><code># find / -type f -name ft2build.h
/usr/X11R6/include/freetype2/ft2build.h
</code></pre>
<p>I simply can modify the <code>config.mk</code> accordingly by changing</p>
<pre><code>FREETYPEINC = /usr/include/freetype2
</code></pre>
<p>to</p>
<pre><code>FREETYPEINC = $(X11INC}/freetype2
</code></pre>
<p>Actually, I only need to comment the above line, and uncomment the line below</p>
<pre><code># OpenBSD (uncomment)
</code></pre>
<p>The Suckless folks obviously are friendly towards OpenBSD, which is also
noticable in other places (more evidence to be shown further below).</p>
<p>The next compilation attempt succeeds:</p>
<pre><code>$ make
</code></pre>
<p>So let's install <code>dwm</code>, too:</p>
<pre><code># make install
</code></pre>
<p>By default, and as to be seen in <code>config.h</code>, the keyboard combination
<code>[Alt]+[Shift]+[Enter]</code> (deeply engraved into the muscle memories of many <code>dwm</code>
users) starts the <code>st</code> terminal. This will be built in a while. However, I
prefer to use the <em>Super</em> or <em>Windows</em> key instead of <code>Alt</code>, since the former
is of no use in OpenBSD, and the latter still comes in handy when working with
the emacs readline mode. Therefore, I change the <code>MODKEY</code> from</p>
<pre><code>#define MODKEY Mod1Mask
</code></pre>
<p>to</p>
<pre><code>#define MODKEY Mod4Mask
</code></pre>
<p>Then I rebuild and reinstall <code>dwm</code>:</p>
<pre><code># make install
</code></pre>
<h3>Building <code>st</code></h3>
<p>Let's switch over to the <code>st</code> source directory and just try to compile it:</p>
<pre><code>$ cd ../st
$ make
</code></pre>
<p>Here, we get a warning that the function <code>pledge</code> (an OpenBSD mitigation, which
is built into the <code>master</code> branch, but surrounded by an <code>ifdef</code> preprocessor
statement, so that it will only be compiled for OpenBSD) is imported implicitly.
Let's just ignore this warning for now.</p>
<p>What's worse, the compilation fails with the error message:</p>
<pre><code>ld: error: unable to find library -lrt
</code></pre>
<p>Here, the FAQ comes in handy, stating that</p>
<pre><code>If you want to compile st for OpenBSD you have to remove -lrt from
config.mk, ...
</code></pre>
<p>Having done so in <code>config.mk</code>, <code>st</code> compiles without any further issues, and,
thus, can be rebuilt and installed:</p>
<pre><code># make install
</code></pre>
<h3>Building <code>dmenu</code></h3>
<p>Even OpenBSD users with Suckless tools have to open another GUI application than
a terminal emulator once in a while. For this purpose, Suckless offers <code>dmenu</code>.
Let's switch over to it and compile it:</p>
<pre><code>$ cd ../dmenu
$ make
</code></pre>
<p>Again, we have the issue with <code>ft2build.h</code>, which can be resolved as above with
<code>dwm</code>: by using the proper path for <code>FREETYPEINC</code> in <code>config.mk</code>. Afterwards,
the build succeeds, and <code>dmenu</code> can be installed:</p>
<pre><code># make install
</code></pre>
<h3>Building <code>slstatus</code></h3>
<p><code>dwm</code> has a status bar on the top right, which can be used to show various
information. I used to write some shell commands in <code>.xinitrc</code> to compose such a
status line, and then set it by <code>xset -b</code> once every five seconds or so. This
approach generates a multitude of processes every couple of seconds.</p>
<p><code>slstatus</code> is a C programm that is capable of showing various kinds of more or
less useful information. Let's switch over to <code>slstatus</code> and see, what is
available in <code>config.def.h</code>:</p>
<pre><code>$ cd ../slstatus
$ less config.def.h
</code></pre>
<p>The comments section lists different functions (<code>battery_perc</code> for the battery
percentage, <code>datetime</code> for date and time information, <code>temp</code> for thermal
information, etc.). I usually display the CPU load, the battery percentage, the
memory usage, the current keyboard layout, and the current date and time.</p>
<p>Before configuring those, let's try to compile <code>slstatus</code>:</p>
<pre><code>$ make
</code></pre>
<p>This worked fine, so let's configure the information to be displayed in
<code>config.h</code>:</p>
<pre><code>static const struct arg args[] = {
    /* function    format    argument */
    { datetime,    "%s",     "%F %T" },
};
</code></pre>
<p>This renders the current date as follows:</p>
<pre><code>$ date +"%F %T"
2020-09-05 19:26:38
</code></pre>
<p>I also like to have the weekday included, but not the seconds, so I define a
different argument string:</p>
<pre><code>$ date +"%a %Y-%m-%d %H:%M"
Sat 2020-09-05 19:27
</code></pre>
<p>That's better, so let's use it in <code>config.h</code> (surrounded with some spaces in the
format string):</p>
<pre><code>static const struct arg args[] = {
    /* function    format    argument */
    { datetime,    " %s ",   "%a %Y-%m-%d %H:%M" },
};
</code></pre>
<p>The other settings I like to have do not require any arguments, at least not on
OpenBSD, so I only need to define a decent format string (with <code>|</code> as a
seperator) for those:</p>
<pre><code>static const struct arg args[] = {
    /* function    format           argument */
    { cpu_perc,     " cpu: %s%% |", NULL },
    { battery_perc, " bat: %s%% |", NULL },
    { ram_used,     " mem: %s |",   NULL },
    { keymap,       " %s |"         NULL },
    { datetime,     " %s ",         "%a %Y-%m-%d %H:%M" },
};
</code></pre>
<p>This actually compiles, so let's install it:</p>
<pre><code># make install
</code></pre>
<h2>Configuring X Startup</h2>
<p>Now that all software is compiled and installed, let's run X. To do so, a file
<code>.xinitrc</code> in the user's directory is …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://paedubucher.ch/articles/2020-09-05-openbsd-on-the-desktop-part-i.html">https://paedubucher.ch/articles/2020-09-05-openbsd-on-the-desktop-part-i.html</a></em></p>]]>
            </description>
            <link>https://paedubucher.ch/articles/2020-09-05-openbsd-on-the-desktop-part-i.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24622788</guid>
            <pubDate>Tue, 29 Sep 2020 00:23:20 GMT</pubDate>
        </item>
    </channel>
</rss>
