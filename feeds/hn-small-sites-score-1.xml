<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 16 Aug 2020 12:24:29 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sun, 16 Aug 2020 12:24:29 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[How to quickly create a Jamstack site]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24155601">thread link</a>) | @ndumai
<br/>
August 14, 2020 | https://www.stackbit.com/blog/create-a-jamstack-site-in-minutes/ | <a href="https://web.archive.org/web/*/https://www.stackbit.com/blog/create-a-jamstack-site-in-minutes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="___gatsby"><div tabindex="-1" id="gatsby-focus-wrapper"><div id="page"><main id="content"><article><div><p><img src="https://www.stackbit.com/images/jamstack-site-minutes.png" alt="How to Create a Jamstack Website in Minutes!"></p><div><p>The Stackbit Site Builder created a CMS connected Jamstack site with just a few clicks and in just minutes. Let's explore how.</p><p>At Stackbit, we believe that the Jamstack can help make a better web for everyone because Jamstack sites are fast and secure. We want to make it easy for any developer to adopt the Jamstack for their next project. That's why one of the foundational elements that has defined Stackbit since day one has been the ability to generate a Jamstack site with just a few clicks. The basic steps are:</p><h2>1. Choose a theme</h2><p>We currently have eight themes to choose from, including our new, highly customizable theme called <a href="https://themes.stackbit.com/demos/starter/">Starter</a>. Plus, there are dozens of community themes available on GitHub, such as the popular <a href="https://github.com/snipcart/stackbit-theme-planty">Planty ecommerce theme</a> by Snipcart, or even more on <a href="https://jamstackthemes.dev/">JamstackThemes.dev</a>. You also have the ability to import a custom theme of your own (for details on how to configure that, you can <a href="https://docs.stackbit.com/site-builder/custom-themes/">check the docs</a>)</p><h2>2. Choose a static site generator (SSG)</h2><p>All of our themes can be generaed using Gatsby, Hugo or Jekyll (with additional support coming <em>very</em> soon...but I won't spoil the surprise). This gives you options to choose the tool and language you prefer to use for developing your Jamstack site. (Not sure which one to choose? <a href="https://www.stackbit.com/blog/choosing-your-ssg/">We have some advice here</a>.)</p><h2>3. Choose a headless content management system (CMS)</h2><p>One of the powerful things about buildng a site through the Stackbit site builder is that it is pre-configured for content management through your choice of <a href="https://www.stackbit.com/blog/what-is-a-headless-cms/">headless CMS</a>, including Sanity, Contentful, DataCMS, Forestry and NetilfyCMS. We've even added a new option for using files in your GitHub repository that can still get the full inline content editing features in Stackbit. (More on that in an upcoming post!)</p><p>One you've made these three choices, you are ready to go. Stackbit will build the site, place the source in GitHub and deploy to Netlify. Within minutes your site is ready and deployed!</p><p>Let's be honest though, telling you about this is far less exciting than simply showing you...so let's see what this looks like in action.</p><iframe width="560" height="315" src="https://www.youtube.com/embed/d1Xlr4L44KE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><h2>Make the site your own</h2><p>The really important thing you should know about your new Jamstack site is that <strong>the code is yours.</strong> The code ends up in a GitHub respository you own. You can edit and customize it as you wish. In fact, we've made it easy to get your site running on your local machine and start editing by providing the instructions in the project's <code>README.md</code> or via Stackbit's online editor. This gives you the ability to do things like:</p><ul><li><a href="https://www.stackbit.com/blog/stackbit-gatsby-site-improvements/">Add a favicon, analytics, social sharing and a sitemap</a></li><li><a href="https://www.stackbit.com/blog/gatsby-search/">Add site search using Algolia</a></li><li><a href="https://www.stackbit.com/blog/jamstack-gatsby-mailchimp/">Add a mailing list form that connects to Mailchimp</a></li><li><a href="https://www.stackbit.com/blog/complete-guide-netlify-forms/">Customize how your form submissions are handled</a></li></ul><p>...and anything else you can think of!</p><p>The best part is that everything I have described to you here is also available at no cost. Just head on over to the <a href="https://app.stackbit.com/create">Stackbit Site Builder</a> and start creating your Jamstack site!</p></div></div></article></main></div></div></div></div>]]>
            </description>
            <link>https://www.stackbit.com/blog/create-a-jamstack-site-in-minutes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24155601</guid>
            <pubDate>Fri, 14 Aug 2020 09:11:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tell no-one: A century of secret deals between the NSA and the telecom industry]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24155374">thread link</a>) | @trymas
<br/>
August 14, 2020 | https://media.ccc.de/v/31c3_-_6600_-_en_-_saal_2_-_201412281245_-_tell_no-one_-_james_bamford#t=2215 | <a href="https://web.archive.org/web/*/https://media.ccc.de/v/31c3_-_6600_-_en_-_saal_2_-_201412281245_-_tell_no-one_-_james_bamford#t=2215">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<p><a href="https://media.ccc.de/c/31c3">
<img alt="conference logo" src="https://static.media.ccc.de/media/congress/2014/folder-2014.png">
</a>
</p>

<h2>
A century of secret deals between the NSA and the telecom industry
</h2>
</div>
<p>
<span></span>
<a href="https://media.ccc.de/search?p=James+Bamford">James Bamford</a>

</p>
<div data-aspect-ratio="16:9">

<!-- Mediaelement Player -->
<video controls="controls" data-id="2179" data-timeline="https://static.media.ccc.de/media/congress/2014/e8e29f6a-11df-491a-acae-1253879ae8f9-timeline.jpg" height="100%" poster="https://static.media.ccc.de/media/congress/2014/6600-hd_preview.jpg" preload="metadata" width="100%">
<source data-lang="eng" data-quality="high" src="https://cdn.media.ccc.de/congress/2014/webm-hd/31c3-6600-en-de-Tell_no-one_webm-hd.webm" title="eng 1080p" type="video/webm">
<source data-lang="eng" data-quality="high" src="https://cdn.media.ccc.de/congress/2014/h264-hd-web/31c3-6600-en-Tell_no-one_hd.mp4" title="eng 1080p" type="video/mp4">
<source data-lang="eng" data-quality="low" src="https://cdn.media.ccc.de/congress/2014/webm-sd/31c3-6600-en-de-Tell_no-one_webm-sd.webm" title="eng 576p" type="video/webm">
<source data-lang="eng" data-quality="low" src="https://cdn.media.ccc.de/congress/2014/h264-sd/31c3-6600-en-de-Tell_no-one_sd.mp4" title="eng 576p" type="video/mp4">
<source data-lang="eng" data-quality="high" src="https://cdn.media.ccc.de/congress/2014/h264-hd/31c3-6600-en-de-Tell_no-one_hd.mp4" title="eng 1080p" type="video/mp4">
<track kind="metadata" label="thumbnails" src="https://static.media.ccc.de/media/congress/2014/e8e29f6a-11df-491a-acae-1253879ae8f9-thumbnails.vtt" srclang="">

</video>


</div><p>
Playlists:
<a href="https://media.ccc.de/v/31c3_-_6600_-_en_-_saal_2_-_201412281245_-_tell_no-one_-_james_bamford/playlist">'31c3' videos starting here</a>
/
<a data-method="get" href="https://media.ccc.de/v/31c3_-_6600_-_en_-_saal_2_-_201412281245_-_tell_no-one_-_james_bamford/audio">audio</a>
/
<a href="https://media.ccc.de/v/31c3_-_6600_-_en_-_saal_2_-_201412281245_-_tell_no-one_-_james_bamford/related">related events</a></p><ul>
<li>
<span></span>
62 min
</li>
<li>
<span title="event and release date"></span>
2014-12-28
</li>
<li>
<span></span>
6224
</li>
<li>
<span></span>
<a href="http://events.ccc.de/congress/2014/Fahrplan/events/6600.html">Fahrplan</a>
</li>
</ul>
<!-- %h3 About -->
<p>For nearly one hundred years, the NSA and its predecessors have been engaging in secret, illegal deals with the American telecom industry, with both virtually immune from prosecution.</p>

<h3>Download</h3>
<div>
<div>
<div>
<p>
<h4>Video</h4>
</p>
<div>
<ul role="tablist">
<li role="presentation">
<a aria-controls="mp4" data-toggle="tab" href="#mp4" role="tab">
MP4
</a>
</li>
<li role="presentation">
<a aria-controls="webm" data-toggle="tab" href="#webm" role="tab">
WebM
</a>
</li>
</ul>
<div>
<div id="mp4" role="tabpanel">
<div>
<a href="https://cdn.media.ccc.de/congress/2014/h264-hd/31c3-6600-en-de-Tell_no-one_hd.mp4">
<p>Download 1080p</p>
<span>eng</span>
<span>484 MB</span>
</a>
</div>
<div>
<a href="https://cdn.media.ccc.de/congress/2014/h264-sd/31c3-6600-en-de-Tell_no-one_sd.mp4">
<p>Download 576p</p>
<span>eng</span>
<span>253 MB</span>
</a>
</div>
</div>
<div id="webm" role="tabpanel">
<div>
<a href="https://cdn.media.ccc.de/congress/2014/webm-hd/31c3-6600-en-de-Tell_no-one_webm-hd.webm">
<p>Download 1080p</p>
<span>eng</span>
<span>486 MB</span>
</a>
</div>
<div>
<a href="https://cdn.media.ccc.de/congress/2014/webm-sd/31c3-6600-en-de-Tell_no-one_webm-sd.webm">
<p>Download 576p</p>
<span>eng</span>
<span>208 MB</span>
</a>
</div>
</div>
</div>
</div>
</div>
<div>
<p>
<h4>Subtitles</h4>
</p>
<div>
<p><a href="https://www.c3subtitles.de/talk/guid/e8e29f6a-11df-491a-acae-1253879ae8f9" target="_blank">
Help us to subtitle this talk!
</a>
</p></div>
</div>
<div>
<p>
<h4>Audio</h4>
</p>
<div>
<div>
<div>
<a href="https://cdn.media.ccc.de/congress/2014/mp3/31c3-6600-en-de-Tell_no-one_mp3.mp3">
<p>Download mp3</p>
<span>eng</span>
<span>85 MB</span>
</a>
</div>
<div>
<a href="https://cdn.media.ccc.de/congress/2014/opus/31c3-6600-en-de-Tell_no-one_opus.opus">
<p>Download opus</p>
<span>eng</span>
<span>43 MB</span>
</a>
</div>
</div>
</div>
</div>
</div>

</div>
<h3>Related</h3>
<div>
<div>
<p><a href="https://media.ccc.de/v/32c3-7143-the_state_of_internet_censorship">
<img alt="The state of Internet Censorship" src="https://static.media.ccc.de/media/congress/2015/7143-hd.jpg" title="The state of Internet Censorship">
</a>
</p>
<p><a href="https://media.ccc.de/v/31c3_-_6175_-_en_-_saal_6_-_201412282300_-_superheroes_still_need_phoneboxes_-_ben_dalton">
<img alt="Superheroes Still Need Phoneboxes" src="https://static.media.ccc.de/media/congress/2014/6175-hd.jpg" title="Superheroes Still Need Phoneboxes">
</a>
</p>
<p><a href="https://media.ccc.de/v/31c3_-_6121_-_en_-_saal_2_-_201412291715_-_what_ever_happened_to_nuclear_weapons_-_michael_buker">
<img alt="What Ever Happened to Nuclear Weapons?" src="https://static.media.ccc.de/media/congress/2014/6121-hd.jpg" title="What Ever Happened to Nuclear Weapons?">
</a>
</p>
<p><a href="https://media.ccc.de/v/31c3_-_6595_-_en_-_saal_1_-_201412281900_-_hard_drive_punch_-_aram_bartholl">
<img alt="»Hard Drive Punch«" src="https://static.media.ccc.de/media/congress/2014/6595-hd.jpg" title="»Hard Drive Punch«">
</a>
</p>
<p><a href="https://media.ccc.de/v/31c3_-_6602_-_en_-_saal_1_-_201412301130_-_the_case_of_chelsea_manning_-_alexa_o_brien_-_nancy_hollander_-_ahmed_ghappour_-_chase_strangio">
<img alt="The case of Chelsea Manning" src="https://static.media.ccc.de/media/congress/2014/6602-hd.jpg" title="The case of Chelsea Manning">
</a>
</p>
<p><a href="https://media.ccc.de/v/31c3_-_6530_-_en_-_saal_6_-_201412272145_-_in_security_of_mobile_banking_-_ericfiliol_-_paul_irolla">
<img alt="(In)Security of Mobile Banking" src="https://static.media.ccc.de/media/congress/2014/6530-hd.jpg" title="(In)Security of Mobile Banking">
</a>
</p>
<p><a href="https://media.ccc.de/v/31c3_-_6370_-_en_-_saal_g_-_201412281900_-_internet_of_toilets_-_tbsprs">
<img alt="Internet of toilets" src="https://static.media.ccc.de/media/congress/2014/6370-hd.jpg" title="Internet of toilets">
</a>
</p>
<p><a href="https://media.ccc.de/v/31c3_-_6430_-_de_-_saal_2_-_201412291130_-_nsa_points_of_presence_in_at_-_erich_moechel">
<img alt="NSA Points of Presence in AT" src="https://static.media.ccc.de/media/congress/2014/6430-hd.jpg" title="NSA Points of Presence in AT">
</a>
</p>
<p><a href="https://media.ccc.de/v/31c3_-_6244_-_de_-_saal_6_-_201412281245_-_serenitat_anleitung_zum_glucklichsein_-_elektra_-_andrea_behrendt_-_read_delete">
<img alt="Serenität – Anleitung zum Glücklichsein" src="https://static.media.ccc.de/media/congress/2014/6244-hd.jpg" title="Serenität – Anleitung zum Glücklichsein">
</a>
</p>
<p><a href="https://media.ccc.de/v/31c3_-_5930_-_en_-_saal_6_-_201412291400_-_funky_file_formats_-_ange_albertini">
<img alt="Funky File Formats" src="https://static.media.ccc.de/media/congress/2014/5930-hd.jpg" title="Funky File Formats">
</a>
</p>
</div>
</div>

<!-- %h3 Embed/Share -->

<h3>Tags</h3>
<div>
<p><a href="https://media.ccc.de/c/31c3/Ethics,%20Society%20&amp;%20Politics" rel="tag">Ethics, Society &amp; Politics</a>
</p></div>
</div></div>]]>
            </description>
            <link>https://media.ccc.de/v/31c3_-_6600_-_en_-_saal_2_-_201412281245_-_tell_no-one_-_james_bamford#t=2215</link>
            <guid isPermaLink="false">hacker-news-small-sites-24155374</guid>
            <pubDate>Fri, 14 Aug 2020 08:34:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Save Mozilla]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24155372">thread link</a>) | @caisah
<br/>
August 14, 2020 | http://dpk.io/savemozilla | <a href="https://web.archive.org/web/*/http://dpk.io/savemozilla">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><header>
  
</header>

<p><i>Disclaimer: I’m not a current or former Mozilla employee and have no other affiliation with Mozilla.</i> This is my own analysis of the publically-available information surrounding Mozilla’s decision to <a href="https://blog.mozilla.org/blog/2020/08/11/changing-world-changing-mozilla/">radically downsize</a> in a way that seems to further threaten Firefox’s future.

</p><p>A lot of people are very angry at Mozilla’s management for their decision to restructure the foundation, which is <a href="https://twitter.com/withoutboats/status/1217558588857544704">not unreasonable.</a> But seen in context, I think most people would, if in their position, make the same decision.

</p><p>Why is Mozilla cutting staff on its most popular product (Firefox) and refocusing on things that look like unsuccessful stunt projects? <a href="https://medium.com/swlh/could-google-crush-firefox-in-2020-13a55b5d4526">Because they’re about to lose the revenue from it.</a> <em>Google</em> is to blame for not renewing the contract that gives Mozilla a share of the ad revenue from the Firefox search bar. The web browser market has been walking on thin ice since 2008 when Chrome came out, because with Chrome available and under its own control, Google no longer had a reason to support the ecosystem with revenue-sharing deals. Now it seems like Google wants to see just how thin it can make the ice before Mozilla goes under.

</p><p>And why are they focussing on products nobody uses? Because they can make money by selling VPN subscriptions and premium bookmarking accounts without depending on the (obviously limited) goodwill of their competitors.

</p><p>What can you do about this? Here are some suggestions:

</p><ul>
  <li><strong>Buy one of Mozilla’s other products.</strong> It might seem like validating the bad decision made by Mozilla management, but it is reasonable to hope that income from, say, Mozilla VPN might be enough to keep a rag-tag Firefox team going.
  </li><li><strong>Just straight up <a href="https://donate.mozilla.org/">donate to Mozilla.</a></strong> Remember, Mozilla is a non-profit organization. While Google is developing Chrome to strengthen its bottom line and pay out more to shareholders, Mozilla’s interest in the Web platform is actually public-spirited. They fought against DRM in HTML and the mandatory use of patent-encumbered technologies on the open web, and when these efforts failed (largely for the same reasons Google is now able to crush Firefox entirely) they adopted laudable compromises, giving their users a genuine choice about using these technologies. And more than that&nbsp;—&nbsp;they’re actively participating in projects to create new, widely-supported and superior alternatives to these problematic technologies for the future. The web would be a worse place without Mozilla, and for that they deserve your goodwill.
  </li><li><strong>Write to your lawmaker urging an investigation into Google’s anti-competitive practices</strong> in the web browser and web markup space. This could be particularly effective if you live in the EU and write to your European Parliamentarians. Google is probably counting on the Trump administration not caring about their blatant repeat of Microsoft’s anti-trust violations&nbsp;— but other major jurisdictions which still have functioning regulatory systems can make a difference.
  </li><li><strong>Actually use Firefox, or one of its derivatives like the Tor Browser.</strong> One reason Google feels able to do this is probably because of Firefox’s shrinking market share. But Firefox is a vital part of the browser ecosystem, not least as the only major browser left that isn’t based on a WebKit-derivative engine, and as a hackable open-source browser that’s a vital component of equally-vital privacy projects like Tor. And Firefox still has really great features, especially for web developers. Switch back to Firefox&nbsp;— especially if you’re on Chrome!
  </li><li><strong>Switch away from Google products as much as possible.</strong> I know that other web search engines are still embarrassingly bad&nbsp;—&nbsp;I’m not here to guilt-trip anyone into using DuckDuckGo. But if you use Gmail, stop. There are <a href="https://www.fastmail.com/">fantastic</a> <a href="https://protonmail.com/">alternatives</a> out there which, yes, filter spam just as well as Gmail does these days. Use Apple Maps or OpenStreetMap or Yelp instead of Google Maps. Run an ad blocker that blocks YouTube ads, and support your favourite YouTubers directly over Patreon instead.
</li></ul>


</div>]]>
            </description>
            <link>http://dpk.io/savemozilla</link>
            <guid isPermaLink="false">hacker-news-small-sites-24155372</guid>
            <pubDate>Fri, 14 Aug 2020 08:34:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pitfalls using React Hooks]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24155368">thread link</a>) | @lukstei
<br/>
August 14, 2020 | https://lukstei.com/2019-10-27-doing-asynchronous-calls-using-react-hooks#1 | <a href="https://web.archive.org/web/*/https://lukstei.com/2019-10-27-doing-asynchronous-calls-using-react-hooks#1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
Doing asynchronous calls using React hooks is not straightforward.
One has to know how correctly write a functional component and also comply to the <a href="https://reactjs.org/docs/hooks-rules.html">Rules of hooks</a>.</p>
<p>In this post we discover various challenges doing asynchronous calls when using functional components.
We then build our own custom hooks, one which triggers the asynchronous calls when the component is mounted and one that triggers the call imperatively (e.g. when a button is clicked).</p>
<blockquote>
<p>With “asynchronous function” or “asynchronous call” we mean any javascript function, which triggers a side effect and returns a standard javascript <code>Promise</code>. At some point, the promise will either be resolved (on success) or be rejected (if an error occurs). If the promise is not yet resolved or rejected, it is in the loading state.</p>
</blockquote>
<blockquote>
<p>In our examples we use the <code>fetch</code> function, but the asynchronous function could be any function which returns a promise.</p>
</blockquote>
<h2>Naive approach</h2>
<p>One could just trigger the asynchronous call directly in the render method:</p>
<div data-language="jsx"><pre><code><span>import</span> React<span>,</span> <span>{</span> useState <span>}</span> <span>from</span> <span>"react"</span>

<span>export</span> <span>default</span> <span>function</span> <span>Example</span><span>(</span><span>)</span> <span>{</span>
  <span>const</span> <span>[</span>result<span>,</span> setResult<span>]</span> <span>=</span> <span>useState</span><span>(</span><span>)</span>
  <span>const</span> <span>[</span>error<span>,</span> setError<span>]</span> <span>=</span> <span>useState</span><span>(</span><span>)</span>
  <span>const</span> <span>[</span>isLoading<span>,</span> setIsLoading<span>]</span> <span>=</span> <span>useState</span><span>(</span><span>true</span><span>)</span>

<span>  <span>const</span> <span>doCall</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>fetch</span><span>(</span><span>"/api/users"</span><span>)</span><span>.</span><span>then</span><span>(</span><span>r</span> <span>=&gt;</span> r<span>.</span><span>text</span><span>(</span><span>)</span><span>)</span></span>
<span>  <span>doCall</span><span>(</span><span>)</span><span>.</span><span>then</span><span>(</span></span><span>    <span>r</span> <span>=&gt;</span> <span>{</span></span><span>      <span>setIsLoading</span><span>(</span><span>false</span><span>)</span></span><span>      <span>setResult</span><span>(</span>r<span>)</span></span><span>    <span>}</span><span>,</span></span><span>    <span>e</span> <span>=&gt;</span> <span>{</span></span><span>      <span>setIsLoading</span><span>(</span><span>false</span><span>)</span></span><span>      <span>setError</span><span>(</span>e<span>)</span></span><span>    <span>}</span></span><span>  <span>)</span></span>
  <span>return</span> <span>(</span>
    <span><span><span>&lt;</span></span><span>&gt;</span></span><span></span>
<span>      </span><span>{</span>isLoading <span>&amp;&amp;</span> <span><span><span>&lt;</span>p</span><span>&gt;</span></span><span>Loading data...</span><span><span><span>&lt;/</span>p</span><span>&gt;</span></span><span>}</span><span></span>
<span>      </span><span>{</span>error <span>&amp;&amp;</span> <span><span><span>&lt;</span>p</span><span>&gt;</span></span><span>An error occurred</span><span><span><span>&lt;/</span>p</span><span>&gt;</span></span><span>}</span><span></span>
<span>      </span><span>{</span>result <span>&amp;&amp;</span> <span><span><span>&lt;</span>div</span><span>&gt;</span></span><span>{</span>result<span>}</span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span><span>}</span><span></span>
<span>    </span><span><span><span>&lt;/</span></span><span>&gt;</span></span>
  <span>)</span>
<span>}</span></code></pre></div>
<p>In the example above we directly trigger the call inside the body of the render function.
Remember, when using a functional component, as we do, the function body itself is the render method (we directly return the components to be rendered).</p>
<p>One problem in this example is, that it is not allowed to do side effects directly inside the body of the render method. Quoting the React documentation:</p>
<blockquote>
<p>All React components must act like pure functions with respect to their props.</p>
</blockquote>
<p>Additionally, a cleanup when the component unmounts is not happening. Imagine, the promise returned by the <code>doCall</code> function takes 10 seconds to resolve and in the meantime, the component is unmounted. The function <code>setResult</code> is still called, which could possibly lead to memory leaks.</p>
<p>When the promise is resolved and the component is already unmounted, we would get a warning like <em>“Warning: Can’t perform a React state update on an unmounted component. This is a no-op, but it indicates a memory leak in your application. To fix, cancel all subscriptions and asynchronous tasks in a useEffect cleanup function.”</em></p>
<p>One last problem is, that the call is executed every time the component is re-rendered, which could happen anytime.</p>
<p>So how can we do better?</p>
<h2>Using the effect hook</h2>
<p>The right way to do side effects in a functional component is to use the <code>useEffect</code> hook.
We need to pass the (wrapped) asynchronous function as the first argument to the <code>useEffect</code> hook:</p>
<div data-language="jsx"><pre><code><span>import</span> React<span>,</span> <span>{</span> useEffect<span>,</span> useState <span>}</span> <span>from</span> <span>"react"</span>

<span>export</span> <span>default</span> <span>function</span> <span>Example</span><span>(</span><span>)</span> <span>{</span>
  <span>const</span> <span>[</span>result<span>,</span> setResult<span>]</span> <span>=</span> <span>useState</span><span>(</span><span>)</span>
  <span>const</span> <span>[</span>error<span>,</span> setError<span>]</span> <span>=</span> <span>useState</span><span>(</span><span>)</span>
  <span>const</span> <span>[</span>isLoading<span>,</span> setIsLoading<span>]</span> <span>=</span> <span>useState</span><span>(</span><span>true</span><span>)</span>

<span>  <span>useEffect</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span></span>    <span>const</span> <span>doCall</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>fetch</span><span>(</span><span>"/api/users"</span><span>)</span><span>.</span><span>then</span><span>(</span><span>r</span> <span>=&gt;</span> r<span>.</span><span>text</span><span>(</span><span>)</span><span>)</span>

    <span>doCall</span><span>(</span><span>)</span><span>.</span><span>then</span><span>(</span>
      <span>r</span> <span>=&gt;</span> <span>{</span>
        <span>setIsLoading</span><span>(</span><span>false</span><span>)</span>
        <span>setResult</span><span>(</span>r<span>)</span>
      <span>}</span><span>,</span>
      <span>e</span> <span>=&gt;</span> <span>{</span>
        <span>setIsLoading</span><span>(</span><span>false</span><span>)</span>
        <span>setError</span><span>(</span>e<span>)</span>
      <span>}</span>
    <span>)</span>
  <span>}</span><span>)</span>

  <span>return</span> <span>(</span>
    <span><span><span>&lt;</span></span><span>&gt;</span></span><span></span>
<span>      </span><span>{</span>isLoading <span>&amp;&amp;</span> <span><span><span>&lt;</span>p</span><span>&gt;</span></span><span>Loading data...</span><span><span><span>&lt;/</span>p</span><span>&gt;</span></span><span>}</span><span></span>
<span>      </span><span>{</span>error <span>&amp;&amp;</span> <span><span><span>&lt;</span>p</span><span>&gt;</span></span><span>An error occurred</span><span><span><span>&lt;/</span>p</span><span>&gt;</span></span><span>}</span><span></span>
<span>      </span><span>{</span>result <span>&amp;&amp;</span> <span><span><span>&lt;</span>div</span><span>&gt;</span></span><span>{</span>result<span>}</span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span><span>}</span><span></span>
<span>    </span><span><span><span>&lt;/</span></span><span>&gt;</span></span>
  <span>)</span>
<span>}</span></code></pre></div>
<p>When using the <code>useEffect</code> hook we are doing side effects the correct way.</p>
<p>By default, the function passed to the <code>useEffect</code> hook is called for every rerender, which would cause our call to be executed for every props or state change, which we in our example certainly do not want.</p>
<p>To control this behaviour, we can pass a second argument to the <code>useEffect</code> hook, which is an array which defines the dependencies of the passed function.
When some value inside the dependency array changes, the effect is re-executed.</p>
<p>When passing an empty array, which effectively means, the effect has no dependencies, then the passed function is only executed once when the component is mounted.
This is the behaviour we want in our example.</p>
<div data-language="jsx"><pre><code><span>import</span> React<span>,</span> <span>{</span> useEffect<span>,</span> useState <span>}</span> <span>from</span> <span>"react"</span>

<span>export</span> <span>default</span> <span>function</span> <span>Example</span><span>(</span><span>)</span> <span>{</span>
  <span>const</span> <span>[</span>result<span>,</span> setResult<span>]</span> <span>=</span> <span>useState</span><span>(</span><span>)</span>
  <span>const</span> <span>[</span>error<span>,</span> setError<span>]</span> <span>=</span> <span>useState</span><span>(</span><span>)</span>
  <span>const</span> <span>[</span>isLoading<span>,</span> setIsLoading<span>]</span> <span>=</span> <span>useState</span><span>(</span><span>true</span><span>)</span>

  <span>useEffect</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
      <span>const</span> <span>doCall</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>fetch</span><span>(</span><span>"/api/users"</span><span>)</span><span>.</span><span>then</span><span>(</span><span>r</span> <span>=&gt;</span> r<span>.</span><span>text</span><span>(</span><span>)</span><span>)</span>

      <span>doCall</span><span>(</span><span>)</span><span>.</span><span>then</span><span>(</span>
        <span>r</span> <span>=&gt;</span> <span>{</span>
          <span>setIsLoading</span><span>(</span><span>false</span><span>)</span>
          <span>setResult</span><span>(</span>r<span>)</span>
        <span>}</span><span>,</span>
        <span>e</span> <span>=&gt;</span> <span>{</span>
          <span>setIsLoading</span><span>(</span><span>false</span><span>)</span>
          <span>setError</span><span>(</span>e<span>)</span>
        <span>}</span>
      <span>)</span>
    <span>}</span><span>,</span>
<span>    <span>[</span><span>]</span></span>  <span>)</span>

  <span>return</span> <span>(</span>
    <span><span><span>&lt;</span></span><span>&gt;</span></span><span></span>
<span>      </span><span>{</span>isLoading <span>&amp;&amp;</span> <span><span><span>&lt;</span>p</span><span>&gt;</span></span><span>Loading data...</span><span><span><span>&lt;/</span>p</span><span>&gt;</span></span><span>}</span><span></span>
<span>      </span><span>{</span>error <span>&amp;&amp;</span> <span><span><span>&lt;</span>p</span><span>&gt;</span></span><span>An error occurred</span><span><span><span>&lt;/</span>p</span><span>&gt;</span></span><span>}</span><span></span>
<span>      </span><span>{</span>result <span>&amp;&amp;</span> <span><span><span>&lt;</span>div</span><span>&gt;</span></span><span>{</span>result<span>}</span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span><span>}</span><span></span>
<span>    </span><span><span><span>&lt;/</span></span><span>&gt;</span></span>
  <span>)</span>
<span>}</span></code></pre></div>
<p>When the asynchronous call is dependent on some value and we want to re-trigger the call based on when some state changes or when property passed to the component changes, we explicitly need to add it to the dependencies array.</p>
<p>Imagine, we have a component which displays a user based on the passed user id, we need to pass the <code>userId</code> value as a dependency:</p>
<div data-language="jsx"><pre><code><span>import</span> React<span>,</span> <span>{</span> useEffect<span>,</span> useState <span>}</span> <span>from</span> <span>"react"</span>

<span>export</span> <span>default</span> <span>function</span> <span>ShowUser</span><span>(</span><span><span>{</span> userId <span>}</span></span><span>)</span> <span>{</span>
  <span>const</span> <span>[</span>result<span>,</span> setResult<span>]</span> <span>=</span> <span>useState</span><span>(</span><span>)</span>
  <span>const</span> <span>[</span>error<span>,</span> setError<span>]</span> <span>=</span> <span>useState</span><span>(</span><span>)</span>
  <span>const</span> <span>[</span>isLoading<span>,</span> setIsLoading<span>]</span> <span>=</span> <span>useState</span><span>(</span><span>true</span><span>)</span>

  <span>useEffect</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
      <span>const</span> <span>doCall</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>fetch</span><span>(</span><span><span>`</span><span>/api/users/</span><span><span>${</span>userId<span>}</span></span><span>`</span></span><span>)</span><span>.</span><span>then</span><span>(</span><span>r</span> <span>=&gt;</span> r<span>.</span><span>text</span><span>(</span><span>)</span><span>)</span>

      <span>setIsLoading</span><span>(</span><span>true</span><span>)</span>

      <span>doCall</span><span>(</span><span>)</span><span>.</span><span>then</span><span>(</span>
        <span>r</span> <span>=&gt;</span> <span>{</span>
          <span>setIsLoading</span><span>(</span><span>false</span><span>)</span>
          <span>setResult</span><span>(</span>r<span>)</span>
        <span>}</span><span>,</span>
        <span>e</span> <span>=&gt;</span> <span>{</span>
          <span>setIsLoading</span><span>(</span><span>false</span><span>)</span>
          <span>setError</span><span>(</span>e<span>)</span>
        <span>}</span>
      <span>)</span>
    <span>}</span><span>,</span>
<span>    <span>[</span>userId<span>]</span></span>  <span>)</span>

  <span>return</span> <span>(</span>
    <span><span><span>&lt;</span></span><span>&gt;</span></span><span></span>
<span>      </span><span>{</span>isLoading <span>&amp;&amp;</span> <span><span><span>&lt;</span>p</span><span>&gt;</span></span><span>Loading data...</span><span><span><span>&lt;/</span>p</span><span>&gt;</span></span><span>}</span><span></span>
<span>      </span><span>{</span>error <span>&amp;&amp;</span> <span><span><span>&lt;</span>p</span><span>&gt;</span></span><span>An error occurred</span><span><span><span>&lt;/</span>p</span><span>&gt;</span></span><span>}</span><span></span>
<span>      </span><span>{</span>result <span>&amp;&amp;</span> <span><span><span>&lt;</span>div</span><span>&gt;</span></span><span>{</span>result<span>}</span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span><span>}</span><span></span>
<span>    </span><span><span><span>&lt;/</span></span><span>&gt;</span></span>
  <span>)</span>
<span>}</span></code></pre></div>
<p>When using the <code>useEffect</code> hook, we solved the issue with the prohibited side effects in the render method.
However when using calls with dependencies (e.g. like in the example above), we actually introduced a new problem:
When the effect is re-triggered and our asynchronous function is called again, we now have a race condition.</p>
<p>Imagine, the component is rendered as <code>&lt;ShowUser userId={1} /&gt;</code>. When the component is mounted, the call to load user 1 is triggered as expected.
Now the component’s <code>userId</code> property changes: <code>&lt;ShowUser userId={2} /&gt;</code>. The component is then re-rendered with the changed property.
Subsequently also the effect is re-executed and the call to load user 2 is triggered.
Everything works as expected unless in some (possibly) rare cases, the first call takes longer to resolve than the second call. What would happen in this case, first the <code>setResult(&lt;user 2&gt;)</code> is called, and after the first call finally is resolved <code>setResult(&lt;user 1&gt;)</code>. This in turn would then certainly display the wrong user.</p>
<p>Remember, one additional challenge in the naive approach was, that there was no cleanup function, which could lead to problems, when the component is unmounted.</p>
<p>We can solve both problems using a cleanup function inside the effect.
In the function passed to the <code>useEffect</code> hook, we can return a callback function, which is executed when the effect is cleaned up. This cleanup happens each time the dependency array changes and at the very end, i.e. when the component is unmounted.</p>
<p>In our simple example, we just want to ignore the results after cleanup when the promise is resolved or rejected.</p>
<blockquote>
<p>If the API would support it, we could also, for example, cancel the fetch in the cleanup callback, effectively avoiding doing unnecessary work after the effect is cleaned up.</p>
</blockquote>
<div data-language="jsx"><pre><code><span>import</span> React<span>,</span> <span>{</span> useEffect<span>,</span> useState <span>}</span> <span>from</span> <span>"react"</span>

<span>export</span> <span>default</span> <span>function</span> <span>ShowUser</span><span>(</span><span><span>{</span> userId <span>}</span></span><span>)</span> <span>{</span>
  <span>const</span> <span>[</span>result<span>,</span> setResult<span>]</span> <span>=</span> <span>useState</span><span>(</span><span>)</span>
  <span>const</span> <span>[</span>error<span>,</span> setError<span>]</span> <span>=</span> <span>useState</span><span>(</span><span>)</span>
  <span>const</span> <span>[</span>isLoading<span>,</span> setIsLoading<span>]</span> <span>=</span> <span>useState</span><span>(</span><span>true</span><span>)</span>

  <span>useEffect</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>const</span> <span>doCall</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>fetch</span><span>(</span><span><span>`</span><span>/api/users/</span><span><span>${</span>userId<span>}</span></span><span>`</span></span><span>)</span><span>.</span><span>then</span><span>(</span><span>r</span> <span>=&gt;</span> r<span>.</span><span>text</span><span>(</span><span>)</span><span>)</span>

    <span>let</span> subscribed <span>=</span> <span>true</span>
    <span>setIsLoading</span><span>(</span><span>true</span><span>)</span>

    <span>doCall</span><span>(</span><span>)</span><span>.</span><span>then</span><span>(</span>
      <span>r</span> <span>=&gt;</span> <span>{</span>
        <span>if</span> <span>(</span>subscribed<span>)</span> <span>{</span>
          <span>setIsLoading</span><span>(</span><span>false</span><span>)</span>
          <span>setResult</span><span>(</span>r<span>)</span>
        <span>}</span>
      <span>}</span><span>,</span>
      <span>e</span> <span>=&gt;</span> <span>{</span>
        <span>if</span> <span>(</span>subscribed<span>)</span> <span>{</span>
          <span>setIsLoading</span><span>(</span><span>false</span><span>)</span>
          <span>setError</span><span>(</span>e<span>)</span>
        <span>}</span>
      <span>}</span>
    <span>)</span>

<span>    <span>return</span> <span>function</span> <span>cleanup</span><span>(</span><span>)</span> <span>{</span></span><span>      subscribed <span>=</span> <span>false</span></span><span>    <span>}</span></span>  <span>}</span><span>,</span> <span>[</span>userId<span>]</span><span>)</span>

  <span>return</span> <span>(</span>
    <span><span><span>&lt;</span></span><span>&gt;</span></span><span></span>
<span>      </span><span>{</span>isLoading <span>&amp;&amp;</span> <span><span><span>&lt;</span>p</span><span>&gt;</span></span><span>Loading data...</span><span><span><span>&lt;/</span>p</span><span>&gt;</span></span><span>}</span><span></span>
<span>      </span><span>{</span>error <span>&amp;&amp;</span> <span><span><span>&lt;</span>p</span><span>&gt;</span></span><span>An error occurred</span><span><span><span>&lt;/</span>p</span><span>&gt;</span></span><span>}</span><span></span>
<span>      </span><span>{</span>result <span>&amp;&amp;</span> <span><span><span>&lt;</span>div</span><span>&gt;</span></span><span>{</span>result<span>}</span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span><span>}</span><span></span>
<span>    </span><span><span><span>&lt;/</span></span><span>&gt;</span></span>
  <span>)</span>
<span>}</span></code></pre></div>
<p>As we see in the example above, the discussed race condition cannot happen anymore, because the cleanup function is called when the dependencies (in our case the <code>userId</code>) change, and the result is then ignored when the promise is resolved or rejected.</p>
<h2>Creating our own custom hook</h2>
<p>Since we do have to take care for a lot of things to do for one asynchronous call, we can create our own custom hook, which abstracts the details of doing the calls the right way away.</p>
<p>A custom hook is a function which itself calls other hooks. Of course must also comply to the rules of hooks.</p>
<p>In our custom hook, the caller needs to have access to the loading and result states (<code>result</code>, <code>error</code>, <code>isLoading</code>) and of course we need to pass the asynchronous function to be triggered to the hook (including the dependencies of the call).
Everything else can be abstracted away.
Inside the hook we can just use the <code>useEffect</code> hook with the same ideas as in the examples above.</p>
<p>To pass the state and result variables we use the array deconstruction syntax, which is also used by the other built-in hooks, so we return everything the caller needs to know in one array.</p>
<div data-language="jsx"><pre><code><span>import</span> React<span>,</span> <span>{</span> useEffect<span>,</span> useState <span>}</span> <span>from</span> <span>"react"</span>

<span>export</span> <span>default</span> <span>function</span> <span>usePromise</span><span>(</span><span>f<span>,</span> deps</span><span>)</span> <span>{</span>
  <span>const</span> <span>[</span>resul…</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lukstei.com/2019-10-27-doing-asynchronous-calls-using-react-hooks#1">https://lukstei.com/2019-10-27-doing-asynchronous-calls-using-react-hooks#1</a></em></p>]]>
            </description>
            <link>https://lukstei.com/2019-10-27-doing-asynchronous-calls-using-react-hooks#1</link>
            <guid isPermaLink="false">hacker-news-small-sites-24155368</guid>
            <pubDate>Fri, 14 Aug 2020 08:34:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Game Dev Examines a Unique Arcade Mobile Game]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24155135">thread link</a>) | @handlingelect
<br/>
August 14, 2020 | https://www.staticcatgames.com/2020/08/cloud-runner-review.html | <a href="https://web.archive.org/web/*/https://www.staticcatgames.com/2020/08/cloud-runner-review.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><iframe allowfullscreen="" height="266" src="https://www.youtube.com/embed/3PZEx5fHhzg" width="320" youtube-src-id="3PZEx5fHhzg"></iframe></p><p><span>I've played a lot of mobile games and there are some which, in my opinion, deserve a much wider audience. One of these games is the wonderful <i>Cloud Runner</i> by S Tier Games, a developer I hadn't come across before.&nbsp;</span></p><p><span>This is an endless runner featuring three adorable characters (Pinky, Bluu and Chubs) that have to escape from a large, menacing bug. You will see it appear from the left hand screen of the game as you play and it's your job to try and escape it. Tap to jump and try and get as far away as possible without dying.&nbsp;</span></p><p><span>Along the way, you can pick up flowers which can unlock new characters (Chubs), locations (forest and hills), trails and power-ups such as a watering can. You can buy optional IAP packs of flowers if you don't feel like collecting them. Sharing the game with your friends can help you unlock Bluu, the Jungle level and the Blaze trail.&nbsp;</span></p><p><span>The pixel graphics in the game are lovely, with charming backgrounds and character designs. I especially like the music, which is a great electronica soundtrack that is quite addictive.&nbsp;</span></p><p><span>If you own an Android smartphone or tablet and are a fan of arcade games, try <i>Cloud Runner</i>. This is a fun endless runner worth playing.</span></p>
</div></div>]]>
            </description>
            <link>https://www.staticcatgames.com/2020/08/cloud-runner-review.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24155135</guid>
            <pubDate>Fri, 14 Aug 2020 08:01:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Epic fight against app store monopolies (Epic Games)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24154938">thread link</a>) | @simplertms
<br/>
August 14, 2020 | https://4thquadrant.io/snippets/snippet-the-epic-fight-against-app-store-monopolies/ | <a href="https://web.archive.org/web/*/https://4thquadrant.io/snippets/snippet-the-epic-fight-against-app-store-monopolies/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-td-block-uid="tdi_27_fd5">

<div>
<p>Epic Games introduced an update to their mobile (iOS and Android) version of Fortnite that allows users to buy directly from Epic Games at a 20% discount, removing incentives to pay with the officially sanctioned payment systems on the App Store and Play Store.&nbsp;</p>



<p>Soon after this update, Apple removed Fortnite from its App Store, Google was not far behind in doing the same. In response, Epic Games has filed individual suits against both tech giants claiming that their behaviour is monopolistic control over their respective ecosystems. However, there is some nuance and differences that we should explore between the two ecosystems that could have implications for the validity of the anti-trust lawsuits that Epic will have to contend with.&nbsp;</p>



<p>Looking at the two ecosystems holistically, it is perhaps more appropriate in this case to think of Android and iOS as marketplaces rather than solely focusing on their function as operating systems. The contention is that the marketplaces are being monopolised and controlled to the disadvantage of developers. This is especially true of Apple iOS, where the entire OS is a marketplace, where the App Store is the only access point for third-party applications to the ecosystem. If an application is removed from the App Store, the third-party application simply cannot exist on the iOS ecosystem.&nbsp;</p>



<p>Comparatively, Google’s Android OS functions a little differently. The OS acts as an open ecosystem which is augmented by the Play Store. The Play Store, not the OS, is the marketplace – the place for discovery. The Play Store as a standalone application can have comparative and competitive marketplaces on the Android OS, like the Samsung store. Further, the Android OS allows for third-party installs of applications albeit with security warnings.&nbsp;</p>



<p>Epic might have a hard time arguing that Google is being anti-competitive when it has avenues of access – albeit less direct – outside of the Google Play Store. Applications can still exist within the Android ecosystem even when the Play Store removes listings according to their marketplace rules.</p>



<p>Apple, on the other hand, has its entire ecosystem siloed as a marketplace, with no third-party marketplaces allowed and no ability to legally install third-party applications – placing them in a much more difficult position when it comes to anti-competitive claims. In recent months, Apple has come under increasing scrutiny as they butt heads with application developers, most notably Hey email client, Google’s Stadia platform and Microsoft’s xCloud platform.&nbsp;</p>



<div id="slimcalltoaction"><p>This is box title</p><p>If you enjoyed this article, take advantage of our 14 days free trial to explore our exclusive content. Or sign-up for our free weekly newsletters. View our subscription options <a href="https://4thquadrant.io/subscribe">here.</a></p></div>
</div></div><div data-td-block-uid="tdi_28_955">

<div><h3><span>CONTACT THE EDITOR</span></h3>
<p>We welcome thoughtful discourse on all our content. If you would like to further explore or discuss any of the ideas covered in this article please contact our editors directly.<br><span>Contact Details</span></p>
</div></div></div>]]>
            </description>
            <link>https://4thquadrant.io/snippets/snippet-the-epic-fight-against-app-store-monopolies/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24154938</guid>
            <pubDate>Fri, 14 Aug 2020 07:33:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Balena Fin v1.1 recall due to heat issues]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24154924">thread link</a>) | @cjnicholls
<br/>
August 14, 2020 | https://www.balena.io/blog/usb-issue-rca/ | <a href="https://web.archive.org/web/*/https://www.balena.io/blog/usb-issue-rca/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
            <p>Earlier today, we announced our decision to recall all v1.1 balenaFins due to a USB malfunction at high temperatures. If you think your balenaFin might be affected, please follow the instructions outlined <a href="https://store.balena.io/pages/product-recall-announcement">here</a>.</p>

<p>This issue prevents affected balenaFins from accessing any USB peripherals when the ambient temperature rises above 45-50°C (113-132°F). It also means that those devices relying on ethernet connectivity are disconnected at these higher temperatures since the ethernet bridge is also USB-based.</p>

<p>Based on our estimates, around 90% of all deployed balenaFins are likely affected by this issue. We are fully aware that a recall negatively impacts our customers and introduces friction in their fleet operations, which we, as a company, strive to reduce. <br>
Ultimately, it is our responsibility to take this as a learning opportunity to improve our processes. We now have a more robust testing procedure for both our design and manufacturing processes. The performance of every connectivity protocol at low and high operational temperatures is now part of our standard suite of tests.</p>

<p>This blogpost aims to offer an in-depth technical explanation of the underlying issue and the steps we are taking to prevent this from happening again.</p>

<h3 id="balenafinusbtopology">balenaFin USB topology</h3>

<p><img src="https://www.balena.io/blog/content/images/2020/08/USB-topology-diagram.png" alt="" title="">  </p>

<p>Key components of the balenaFin's USB topology are presented in figure 1. The two main blocks are the USB hub and switch, which allows for regular USB operation and internal eMMC flashing.</p>

<p>The USB hub is based on the LAN9514i chipset (LAN9514 on the v1.0 revision), which has an integrated USB to Ethernet bridge (PHY included). This structure has the benefit of a considerably smaller footprint, but it also means that if the hub is disconnected, so will the Ethernet connection.</p>

<p>The USB switch works by sensing power (VBUS) on the micro-USB connector. When a powered device is detected, the USB interface on the compute module is wired directly to the micro-USB connector. When no powered device is detected, the compute module is connected to the USB hub. The former situation only occurs when the balenaFin is connected to a host device (PC or laptop) to flash the internal eMMC memory.</p>

<h3 id="reportedissues">Reported issues</h3>

<p>The first report of a potential operating temperature issue was posted in our forums in June 2019:</p>

<ul>
<li><a href="https://forums.balena.io/t/questions-around-thermal-restarts-on-the-fin/17330">https://forums.balena.io/t/questions-around-thermal-restarts-on-the-fin/17330</a></li>
</ul>

<p>We concluded that the USB power protections were being triggered by the heat generated from a combination of high current draw and CPU load. This theory seemed to be confirmed by the fact that placing a heatsink on top of the USB protection chips made the issue disappear. </p>

<p>In retrospect, we missed that the addition of vents also reduced the ambient temperature inside the case, hinting that something else might have been going on. </p>

<p>Approximately a year later, another balenaFin customer contacted us via our balenaCloud support chat to report a similar issue. The following situation was also reported in our forums around that time:</p>

<ul>
<li><a href="https://forums.balena.io/t/thermal-operating-range-of-balenafin/150982">https://forums.balena.io/t/thermal-operating-range-of-balenafin/150982</a></li>
</ul>

<p>With the help of a customer who performed an extensive early investigation, we extracted two previously unknown facts:</p>

<ul>
<li>The Ethernet interface was being disconnected along with the plugged USB devices.</li>
<li>balenaFin revision (v1.0) did not appear to be affected.</li>
</ul>

<p>With this new information, we decided to launch a full investigation to test the v1.1 balenaFin's performance at higher temperatures. <br>
While the v1.0 balenaFin was fully tested under high temperatures, the v1.1 balenaFin was only subject to a limited test suite (cold-boot and power-cycle). There were two main reasons for that:</p>

<ul>
<li>Since the LAN9514i hub is individually tested for performance at high temperatures by the manufacturer, we decided to skip this test.</li>
<li>The only other change related to the USB circuitry was the ability to power from the micro-USB port. This is only used when flashing the balenaFin memory, and not intended to be done at high temperatures.</li>
</ul>

<h3 id="investigation">Investigation</h3>

<p>We performed a series of tests in a temperature-controlled chamber that was set to reach an ambient temperature of 80°C, heating at a rate of 1°C/minute. Once the maximum temperature was reached, the devices were left idle for a minimum of 30 minutes before performing any further operations.</p>

<p><img src="https://www.balena.io/blog/content/images/2020/08/WhatsApp-Image-2020-08-13-at-10-53-29-PM-1.jpeg" alt=""></p>

<h6 id="july6th">July 6th</h6>

<p><strong>Test #1:</strong>  </p>

<ul>
<li>Device: Standard v1.0 balenaFin.  </li>
<li>Result: No issues were found on the USB subsystem and no functional degradation was observed. </li>
</ul>

<p><strong>Test #2:</strong>  </p>

<ul>
<li>Device: Standard v1.1 Fin. </li>
<li>Result: At 48C ambient temperature, the USB peripherals connected were suddenly shut down. Ethernet connectivity was also lost.  </li>
<li>Observations: Kernel logs reported that the USB hub was disconnected and no longer accessible.  </li>
</ul>

<p>Note: the above tests were repeated in every session with the exact same results.</p>

<p><strong>Test #3:</strong>   </p>

<ul>
<li>Device: Modified v1.1 balenaFin with the USB power controllers removed.  </li>
<li>Results: We experienced the same issues as the unmodified v1.1 balenaFin.  </li>
<li>Observations: This test's objective was to review our original hypothesis that the USB power controllers are the root cause of the issue. The result disproved our initial hypothesis. </li>
</ul>

<h6 id="july10th">July 10th</h6>

<p><strong>Test #1:</strong>  </p>

<ul>
<li>Device: Modified v1.1 balenaFin with the following changes: <br>
<ul><li>The USB header pins were removed, as this was a significant design change between revisions v1.0 and v1.1 and therefore stood out as a potential culprit  </li>
<li>Wire soldered to the 5V USB bus and connected to an oscilloscope.  </li>
<li>Wire soldered to the 3.3V rail and hooked to an oscilloscope.  </li></ul></li>
<li>Result: Same as unmodified v1.1 balenaFin.  </li>
<li>Observations: On the oscilloscope, we noticed some noise on the 3.3V rail right when the USB hub was shutting down. This noise suggested a potential issue between the power converters and the USB hub. After the device was power cycled at a constant temperature of 60C, the same glitches were observed every 2-3 seconds.</li>
</ul>

<p><strong>Test #2:</strong> </p>

<ul>
<li>Device: The balenaFin from test #1 was modified to cut power to the USB hub by desoldering L20. </li>
<li>Result: Power glitches were not observed. The USB hub was not powered so it remained disconnected throughout the entire test.</li>
<li>Observations: Results seemed to point to a power delivery issue at high temperatures. For further testing, we requested our contract manufacturer to produce a v1.1 balenaFin with a LAN9514 (instead of a LAN9514i) to rule out the potential of the issue being caused by a  faulty batch of USB hubs. Since the power delivery circuitry stayed mostly unchanged between revisions v1.0 and v1.1, it would also help us single out any power distribution faults. </li>
</ul>

<h6 id="july15th">July 15th</h6>

<p>During the previous testing sessions, we were able to consistently reproduce the issue at 45-50°C, allowing us to run tests locally without a professional heat chamber. </p>

<p>We proceeded to test an off-the-shelf v1.1 balenaFin with the LAN9514i replaced by a LAN9514. The results were mainly the same as previous tests, where the USB hub shut down at ~50°C, and the same noise was present in the power rails. <br>
To rule out power delivery being the root cause, we decided to power the USB hub from a separate bench power supply unit placed away from the heat source. Issues persisted with this setup, pointing us away from a power delivery problem.</p>

<p>During these last few tests, we realized that the hub would remain off if it did not receive any signal from the compute module, regardless if it was powered or not. The latter suggested that the issue might not be the hub powering off, but instead not receiving any input from the CM. </p>

<h3 id="rootcauseanalysis">Root cause analysis</h3>

<p>The issue was introduced by a seemingly unrelated change in revision v1.1 that allowed the balenaFin to be powered from the micro-USB port.</p>

<p><img src="https://www.balena.io/blog/content/images/2020/08/Power-schematics.png" alt=""></p>

<p>We used Schottky diodes to prevent back current being injected into a power supply in the accidental case where more than one power supply was connected.  </p>

<p>This type of diodes is widely used in power applications due to their relatively high forward current and low voltage drop. On the flip side, they typically have high reverse leakage current, which increases by an order of magnitude for every 25°C increase.  </p>

<p>Reverse current is hardly ever an issue when sunk by power supplies, even at high temperatures, but in our case, it was causing another undesirable side effect. As shown in figure 3, the USB switch senses the voltage on the micro-USB bus (5V_USB_DBG), and it is triggered when the transistor's gate voltage (Vg) reaches the transistor’s <code>on</code> level (typically 0.8V).  </p>

<p><img src="https://www.balena.io/blog/content/images/2020/08/USB-Switch-schematics.png" alt=""></p>

<p>For the sake of simplicity, the transistor gate current (Ig) can be considered zero, as its value is orders of magnitude lower than the reverse leakage current (Irl). At room temperature (25°C) the value of Irl is around 2uA, making the gate voltage:</p>

<p><code>Vg = Irl * R = 2.5uA * 47kOhm = 117.5mV</code></p>

<p>At 50°C, Irl becomes 20uA, so:</p>

<p><code>Vg = Irl * R = 203uA * 47kOhm = 940mV</code></p>

<p>At this temperature level, the gate voltage becomes high enough to turn the transistor on, tying the switch pin to ground and consequently disconnecting the USB hub from the compute module. </p>

<h3 id="fix">Fix</h3>

<p>The most straightforward way to reduce the impact of the leakage current in the circuit is to reduce the value of R116 (see image 3). Such value should be low enough such that  Vg never reaches 0.6V (which is the minimum 'on' voltage according to the transistor datasheet). <br>
There is a small downside to this approach; it will consume more power when the USB switch is on. Such a situation only happens when the balenaFin is put in mass storage device mode to flash the eMMC (powered by the micro-USB connector). In this case, the vast majority of the peripherals are off, minimizing the downside of a slightly larger current, so we decided this was an acceptable tradeoff. </p>

<p>We selected a value of 1kOhm, which makes the gate voltage:</p>

<p><code>Vg = Irl * R = 2uA *1kOhm = 2mV @ 25°C</code> <br>
<code>Vg = Irl * R = 20uA *1kOhm = 20mV @ 50°C</code> <br>
<code>Vg = Irl * R = 200uA *1kOhm = 200mV @ 75°C</code></p>

<h6 id="july27th">July 27th</h6>

<p>We went back to the lab to perform some tests on a pair of fixed …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.balena.io/blog/usb-issue-rca/">https://www.balena.io/blog/usb-issue-rca/</a></em></p>]]>
            </description>
            <link>https://www.balena.io/blog/usb-issue-rca/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24154924</guid>
            <pubDate>Fri, 14 Aug 2020 07:30:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gadgetbridge (FLOSS gadget companion app) adding support for Mi Band 5 and TLW64]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24154628">thread link</a>) | @vanous
<br/>
August 13, 2020 | https://blog.freeyourgadget.org/release-0_46_0.html | <a href="https://web.archive.org/web/*/https://blog.freeyourgadget.org/release-0_46_0.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>Gadgetbridge 0.46.0 has been release and after a whole week of waiting it
landed in F-Droid.</p>
<p>This release, which adds TLW64 support contributed by Erik Bloß, also has
support for the new Mi Band 5, which is basically runnig on the Mi Band 4 code.</p>
<p>On the Huami front there are fixes for GTR/GTS activity data on newer
firmware version. There seems to be extra data which we ignore for now to make
the current code run with it. In the future we will look at making use of
the new data which unfortunately would need a new database schema.</p>
<p>Another quite big changes was contributed by Taavi Eomäe, who refactored the
device discovery activity which fixes tons of bugs and also new features,
like displaying already paired devices an notes about devices needing a
pairing key.</p>
<p>The release 0.45.0 did not have its own blog post, please refer to the list below
for details on what changed with the 0.45.0 and 0.45.1 releases.</p>
<p>But there is one thing I would like to highlight. There is a new,
experimental way of getting weather data from an new open source app developed
by Pawel Dube, that directly supports Gadgetbridge. No need for API keys.
The App is still alpha and work in progress, but we highly recommend trying it.
<a href="https://codeberg.org/Starfish/TinyWeatherForecastGermany">TinyWeatherForecast</a>
Don't be fooled by the name it supports a lot of locations worldwide.
If you like it please give it a star on Codeberg.org!</p>
<p>For all user-facing changes since the previous blog post, check the following list:</p>
<h4>0.46.0</h4>
<ul>
<li>Initial support for Mi Band 5</li>
<li>Initial support for TLW64</li>
<li>Amazfit GTR/GTS: Fix broken activity data on newer firmwares</li>
<li>Big refactoring of the device discovery activity (See PR #1927 description for details)</li>
<li>Add about screen</li>
<li>New icon for Amazfit Bip</li>
<li>Avoid duplicated entries in preferred media player selection</li>
<li>Avoid a lot of crashes and improve error handling in various places</li>
</ul>
<h4>0.45.1</h4>
<ul>
<li>Amazfit GTR/GTS: Fix connection issue with latest firmwares (probably other Huami devices also affected)</li>
<li>Add experimental support for TinyWeatherForecastGermany</li>
</ul>
<h4>0.45.0</h4>
<ul>
<li>Initial support for Amazfit T-Rex</li>
<li>Amazfit Bip S: Support installation of latest .res</li>
<li>Amazfit Bip S: Support longer notification messages</li>
<li>Huami: Limit weather forecast to 7 days to fix problems with weather notificaon 0.3.11</li>
<li>Huami: Improve music playback information</li>
<li>Huami: Ensure cutting strings on UTF-8 border</li>
<li>Stop incoming call notification when VoIP calls are missed</li>
<li>Fix a crash when with Farsi translation</li>
</ul></div></div>]]>
            </description>
            <link>https://blog.freeyourgadget.org/release-0_46_0.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24154628</guid>
            <pubDate>Fri, 14 Aug 2020 06:54:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Rust Lambdas in Production]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24154506">thread link</a>) | @lukastyrychtr
<br/>
August 13, 2020 | https://www.cvpartner.com/blog/using-rust-lambdas-in-production | <a href="https://web.archive.org/web/*/https://www.cvpartner.com/blog/using-rust-lambdas-in-production">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><figure id="w-node-c687bec1ed8c-01d6604b"><p><img src="https://assets.website-files.com/56d31f469aaa616f5089a267/5f23ffebdba110f2cab1d06d_Rust%20Lambda.png" alt=""></p></figure><div><p>Update:&nbsp;Join the discussion over at <a href="https://news.ycombinator.com/item?id=24154506">HackerNews</a>! </p><p>We’ve written in the past about how the CV Partner web application is written in Ruby on Rails. The web application isn’t the whole story, though. Surrounding it are many supporting services, and we are increasingly using Rust to write these services.</p></div><p>We’re also using more Lambdas in our architecture, and we want to use Rust in those as well. The landscape for Rust lambdas isn’t barren, but it’s not well-trodden either.<br></p><p>This post is going to cover how we write, build, and deploy our Rust lambdas. Our lambdas have the following qualities that we’re proud of and want to share with you:<br></p><ol role="list"><li><strong>Fast, standardised build.</strong> All of our lambdas use the same Dockerfile to build, and make good use of Docker’s layer caching. Incremental builds in CI take under a minute.</li><li><strong>Run locally. </strong>If you’re working on a lambda, you don’t want to have to sit through a CI build to see if your changes work. All of our lambdas can run locally and in AWS using the same code.</li><li><strong>Private GitHub dependencies. There aren’t many options out there for private Cargo repositories, so we use private GitHub repositories for our internal libraries.</strong></li></ol><h2>The code<br></h2><p>The starting point for writing a Lambda in Rust is to use the official <a href="https://github.com/awslabs/aws-lambda-rust-runtime">Rust lambda runtime</a>. At the time of writing, the last release of this library is version 0.2, which doesn’t support async/await. Async/await support is present in master, though. Here’s how it looks in practice:</p><div><pre><code>
use lambda::{lambda, Context};
use serde_json::Value;

type Error = Box<dyn std::error::error="" +="" send="" sync="" 'static="">;

#[lambda]
#[tokio::main]
async fn main(event: Value, _: Context) -&gt; Result<value, error=""> {
    Ok(event)
}

</value,></dyn></code></pre></div><p>The problem with this is that you can’t run it locally. The #[lambda] attribute wraps your main function in another main function that calls in to the AWS lambda API.<br></p><p>To get around this, we write two main functions:<br></p><div><pre><code>

#[cfg(feature = "with-lambda")]
use lambda::{lambda, Context};
use serde::{Deserialize, Serialize};

type Error = Box<dyn std::error::error="" +="" send="" sync="" 'static="">;

#[derive(Deserialize, Debug)]
struct Input {
    name: String
}

#[derive(Serialize, Debug)]
struct Output {
    greeting: String
}

async fn handler(input: Input) -&gt; Result<output, error=""> {
    Ok(Output { greeting: format!(“Hello, {}!”, input.name) })
}

#[cfg(feature = "with-lambda")]
#[lambda]
#[tokio::main]
async fn main(input: Input, _: Context) -&gt; Result<output, error=""> {
    handler(input).await
}

#[cfg(not(feature = "with-lambda"))]
#[tokio::main]
async fn main() -&gt; Result&lt;(), Error&gt; {
    let input_str = std::env::args().nth(1);
    if input_str.is_none() {
        panic!(
            "you must pass an input parameter as the first argument, and it must be a JSON string"
        );
    }
    let input = serde_json::from_str(&amp;input_str.unwrap())?;
    let output = handler(input).await?;
    println!("{}", serde_json::to_string(&amp;output)?);
    Ok(())
}

</output,></output,></dyn></code></pre></div><p>We’re making use of Rust’s “feature” flags to compile a different harness around the handle function depending on whether we want to run locally or in AWS.</p><p>Here’s the Cargo.toml file:</p><div><pre><code>
[package]
name = "rust-lambda-template"
version = "0.1.0"
authors = ["Sam Rose <sam@cvpartner.com>"]
edition = "2018"

[dependencies]
lambda = { git = "https://github.com/awslabs/aws-lambda-rust-runtime/", rev = "c8dbcd39e0b1cf9ecf395e2b2f9df6c6c0d97780" }
tokio = { version = "0.2", features = ["full"] }
serde = { version = "1", features = ["derive"] }
serde_derive = "1"
serde_json = "1"

[features]
with-lambda = []

</sam@cvpartner.com></code></pre></div><p>Two noteworthy things:<br></p><ol role="list"><li>We’re using a version of the aws-lambda-rust-runtime that hasn’t officially been released. This isn’t ideal, and we’re eagerly awaiting a 0.3 release.</li><li>We have a features section, which is where we define the with-lambda feature we use in the Rust code shown above.<br></li></ol><p>Running our lambda now gives us the following:</p><div><pre><code>
$ cargo run -- ‘{ “name”: “Sam” }’
{ “message”: “Hello, Sam!” }

</code></pre></div><h2><strong>The Dockerfile</strong></h2><p>All of our lambdas build with the same Dockerfile. I’ll show it in all of its glory and then explain what’s going on bit by bit. Brace yourself.</p><div><pre><code>
# syntax=docker/dockerfile:experimental

FROM rust:latest as cargo-build
ARG name

RUN apt-get update
RUN apt-get install musl-tools -y
RUN rustup target add x86_64-unknown-linux-musl

WORKDIR /usr/src/${name}
COPY Cargo.toml Cargo.toml
RUN mkdir src/
RUN echo "fn main() {println!(\"if you see this, the build broke\")}" &gt; src/main.rs
RUN mkdir -p $HOME/.ssh
RUN ssh-keyscan github.com &gt; $HOME/.ssh/known_hosts
RUN test "$(cat $HOME/.ssh/known_hosts | ssh-keygen -lf -)" = "2048 SHA256:nThbg6kXUpJWGl7E1IGOCspRomTxdCARLviKw6E5SY8 github.com (RSA)"
RUN --mount=type=ssh RUSTFLAGS=-Clinker=musl-gcc cargo build --features with-lambda --release --target=x86_64-unknown-linux-musl

RUN rm src/main.rs
COPY src/* src
RUN touch src/**
RUN --mount=type=ssh RUSTFLAGS=-Clinker=musl-gcc cargo test --features with-lambda --release --target=x86_64-unknown-linux-musl
RUN --mount=type=ssh RUSTFLAGS=-Clinker=musl-gcc cargo build --features with-lambda --release --target=x86_64-unknown-linux-musl

FROM alpine:latest
ARG name
COPY --from=cargo-build /usr/src/${name}/target/x86_64-unknown-linux-musl/release/${name} /usr/local/bin/${name}

</code></pre></div><p>First of all, shout out to Shane Utt whose <a href="https://shaneutt.com/blog/rust-fast-small-docker-image-builds/">blog post</a> we used as a starting point for this.<br></p><p>The first line is a Docker directive that says we want to use some experimental Dockerfile syntax. The syntax in question is the --mount=type=ssh flag to the RUN commands, but we’ll talk about later.</p><div><pre><code>
FROM rust:latest as cargo-build
ARG name

</code></pre></div><p>This next bit says we want to use the latest Rust image, and we’re passing in a build arg called “name.” This is how we’re able to share this Dockerfile between all of our lambdas without having to modify it.</p><div><pre><code>
RUN apt-get update
RUN apt-get install musl-tools -y
RUN rustup target add x86_64-unknown-linux-musl

</code></pre></div><p>Next we run an update on the image, and we install <a href="https://musl.libc.org/">musl</a>. If you’re not familiar, musl is a libc replacement that you can link to statically. This means the resulting binary won’t depend on the system’s libc, which makes it more portable. It’s not a strict requirement for running on AWS Lambda, but it’s good practice.</p><div><pre><code>
WORKDIR /usr/src/${name}
COPY Cargo.toml Cargo.toml
RUN mkdir src/
RUN echo "fn main() {println!(\"if you see this, the build broke\")}" &gt; src/main.rs

</code></pre></div><p>The next few lines set up a pseudo project, where the only things we’re going to compile are our dependencies and a dummy main.rs. The idea behind this is to use Docker’s layer caching to avoid having to compile our dependencies every build. This leads to significantly faster incremental builds in Docker.</p><div><pre><code>
RUN mkdir -p $HOME/.ssh
RUN ssh-keyscan github.com &gt; $HOME/.ssh/known_hosts
RUN test "$(cat $HOME/.ssh/known_hosts | ssh-keygen -lf -)" = "2048 SHA256:nThbg6kXUpJWGl7E1IGOCspRomTxdCARLviKw6E5SY8 github.com (RSA)"

</code></pre></div><p>Up until now, we’ve done exactly what Shane Utt did in his version of this. These three lines, though, are new. Because we use SSH to fetch private dependencies (more on this later), we would sometimes find that our builds would fail with the error “host key verification failed.” To get around that we pull down GitHub’s host keys and make sure they’re what we expect them to be based on the values <a href="https://docs.github.com/en/github/authenticating-to-github/githubs-ssh-key-fingerprints">here</a>.</p><div><pre><code>
RUN mkdir -p $HOME/.ssh
RUN --mount=type=ssh RUSTFLAGS=-Clinker=musl-gcc cargo build --features with-lambda --release --target=x86_64-unknown-linux-musl

</code></pre></div><p>Our first bit of experimental syntax! The --mount flag is a new thing introduced with the BuildKit engine for Docker, you can read about it in depth <a href="https://medium.com/@tonistiigi/build-secrets-and-ssh-forwarding-in-docker-18-09-ae8161d066">here</a>. The type=ssh bit is us telling Docker that we want to use an SSH agent for this command. In the docker build invocation, which we’ll see later, we can tell Docker what keys to add to this SSH agent.</p><p>The reason we do this is because it was the only way we could find that let us depend on private GitHub repositories in our Cargo.toml file, in a way that worked both locally and in CI. It means we can do this in our Cargo.toml file:</p><div><pre><code>
[dependencies]
private-library = { git = "ssh://github.com/cvpartner/private-library", tag = "1.0" }

</code></pre></div><p>And it Just Works<strong>™</strong>.</p><p>The rest of the RUN command is our first cargo build. It looks a lot scarier than it is. Most of it is us telling rustc to link against musl instead of the default libc. The only other interesting bit is the --features with-lambda. This matches up with the code we saw earlier to produce a binary that’s going to work properly when deployed in AWS.</p><div><pre><code>
RUN rm src/main.rs
COPY src/* src
RUN touch src/**
RUN --mount=type=ssh RUSTFLAGS=-Clinker=musl-gcc cargo test --features with-lambda --release --target=x86_64-unknown-linux-musl
RUN --mount=type=ssh RUSTFLAGS=-Clinker=musl-gcc cargo build --features with-lambda --release --target=x86_64-unknown-linux-musl

</code></pre></div><p>Next up, we’re copying over our actual source code. The touch command is necessary for cargo to realise the files are new, because when we created our dummy main.rs file earlier we created a new file with a timestamp later than the one on the real main.rs file. This is different to the approach taken by Shane Utt, as we found that approach would often result in builds where the dummy main.rs file was the one that ended up in the final build.</p><p>Another addition is the cargo test invocation. Tests are good!</p><div><pre><code>
FROM alpine:latest
ARG name
COPY --from=cargo-build /usr/src/${name}/target/x86_64-unknown-linux-musl/release/${name} /usr/local/bin/${name}

</code></pre></div><p>Lastly we create a new build stage and copy over the final executable. The new build stage is in order to keep the final image small. Ours tend to clock in at around 8MB.<br></p><h2><strong>The build script</strong><br></h2><p>Invoking Docker is done in a shell script which is also identical for all of our lambdas.</p><div><pre><code>
#!/usr/bin/env bash

set -e
set -x

DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" &amp;&amp; pwd )"
cd $DIR

NAME=$(cat Cargo.toml | grep "name" | head -n 1 | sed -E 's/name = "(.*)"/\1/')
DOCKER_NAME="cvpartner/$NAME"

if [[ -z $BUILD_ID ]];
then
  TAG=$DOCKER_NAME
  SSH="--ssh default"
else
  TAG="our.private.docker.registry/$DOCKER_NAME"
  SSH="--ssh default=/home/ci/.ssh/id_rsa"
fi

DOCKER_BUILDKIT=1 docker build $SSH --cache-from $TAG …</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cvpartner.com/blog/using-rust-lambdas-in-production">https://www.cvpartner.com/blog/using-rust-lambdas-in-production</a></em></p>]]>
            </description>
            <link>https://www.cvpartner.com/blog/using-rust-lambdas-in-production</link>
            <guid isPermaLink="false">hacker-news-small-sites-24154506</guid>
            <pubDate>Fri, 14 Aug 2020 06:39:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Legal Compliance and Taxation Outlook of America]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24154322">thread link</a>) | @espayex
<br/>
August 13, 2020 | http://blog.espay.exchange/legal-compliance-and-taxation-outlook-of-americas/ | <a href="https://web.archive.org/web/*/http://blog.espay.exchange/legal-compliance-and-taxation-outlook-of-americas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="mainContentOfPage">

			
			<article>
	<div>
		<div>
							<p><img width="1024" height="576" src="http://blog.espay.exchange/wp-content/uploads/2020/08/Blog-Post-73-Legal-compliance-and-Taxation-outlook-of-Americas.jpg" alt="Legal compliance and Taxation outlook of Americas" srcset="http://blog.espay.exchange/wp-content/uploads/2020/08/Blog-Post-73-Legal-compliance-and-Taxation-outlook-of-Americas.jpg 1024w, http://blog.espay.exchange/wp-content/uploads/2020/08/Blog-Post-73-Legal-compliance-and-Taxation-outlook-of-Americas-300x169.jpg 300w, http://blog.espay.exchange/wp-content/uploads/2020/08/Blog-Post-73-Legal-compliance-and-Taxation-outlook-of-Americas-768x432.jpg 768w" sizes="(max-width: 1024px) 100vw, 1024px" title="Legal compliance and Taxation outlook of Americas">				</p>
						
		</div>

			</div>
</article>

<section><div><div><div><div><div><h2>Introduction</h2>
	<div>
		<p><span>Cryptocurrencies in America are not considered legal tender. However, Cryptocurrency exchanges are legal and the regulations vary by state. In this article, we will be discussing the entire regulation and taxation situation in the US, along with state laws that pertain to Cryptocurrency and blockchain technology. Let’s get started!</span></p>
	</div>
<h2>Cryptocurrency Regulation Outlook</h2>
	<div>
		<div>
			<p><span>It is quite overwhelming to find a reliable lawful approach to Cryptocurrencies in the US. Every law that is governing&nbsp;</span><a href="https://www.espay.exchange/centralized-exchange-solutions"><b>centralized crypto exchanges</b></a><span>&nbsp;varies by state. Moreover, federal authorities differ in their definition of the term – Cryptocurrency. The FinCEN (Financial Crimes Enforcement Network) doesn’t consider Cryptocurrencies to be a legal tender. However, FinCEN has been considering exchanges as money transmitters since 2013, based on the fact the tokens are other value that substitutes for currency. On the contrary, the IRS considers Cryptocurrencies as property and has issued tax regulation for that reason.&nbsp;&nbsp;</span></p>
<p><span>Regulatory laws for Cryptocurrency exchange in the US are also in an indecisive lawful territory. Many of the federal regulators allege jurisdiction. The Securities and Exchange Commission has indicated that it considers Cryptocurrencies as securities. In March 2018, SEC stated that it was seeking to apply securities laws comprehensively for exchanges and digital wallets. On the contrary, the Commodities Futures Trading Commission has adopted a friendly and do-no-harm approach, explaining Bitcoin as a commodity and permitting Cryptocurrency derivatives to buy and sell openly.&nbsp;</span></p>
<p><span>The Justice Department is working with the CFTC and SEC over future Cryptocurrency regulations to make sure that the customers are effectively protected and regulatory oversight is more streamlined. Treasury of the US has emphasized an urgent need for crypto regulation to combat domestic and global criminal activities. In January 2018, Steve Mnuchin and Treasury Secretary declared a new FSOC working group to look at the progressively more crowded Cryptocurrency marketplace.</span></p>
<p><span>In June 2015, New York managed to become the first state of the US to regulate virtual currency companies via state agency rulemaking. In 2019, there were 32 states of the US that introduced legislation accepting or encourage the utilization of Bitcoin and blockchain distributed ledger technology (DLT). A few states passed them into law. However, some of them established task forces to revise the further use of technology. In 2017, the FTC gave LedgerX – Crypto trading platform operator in the US, permission to become the first federally regulated digital currency options exchange and clearinghouse.</span></p>

		</div>
	</div>
<h2> State Regulations Pertaining to Cryptocurrency and the Blockchain Technology</h2><h2>New York</h2>
	<div>
		<div>
			<p><span>Crypto Regulatory Sandbox – In 2015, New York released the “BitLicense” that is needed by any virtual currency company serving New York business owners or residents. The New York State Department of Financial Services (NYDFS) established the BitLicense to provide guardrails that safeguard customers and root out illegal doings without stifling advantageous improvement.&nbsp; According to the legislation, any individual or company who is involved in any of the following activities in New York should obtain a BitLicense:</span></p>
<ol>
<li><span>Performing exchange services as a customer business</span></li>
<li><span>Trading virtual currency as a customer business</span></li>
<li><span>Virtual currency transmission</span></li>
<li><span>Issuing, controlling or administering a virtual currency</span></li>
<li><span>Maintaining custody of virtual currency on the behalf of others</span></li>
</ol>
<p><span>Trading Ban – No</span></p>
<p><span>Banking Ban – No</span></p>
<p><span>Tax Haven Region – No</span></p>
<p><span>Is it best Place for License – Yes, BitLicense can be acquired by following simple instructions in New York</span></p>

		</div>
	</div>
<h2>Washington State</h2>
	<div>
		<div>
			<p><span>Crypto Regulatory Sandbox – In December 2014, the DFI in Washington State formed the Emerging Payments Task Force during the annual conference of State Bank Supervision (CSBS). In September 2015, the annual conference of State Bank Supervision released a model regulatory platform for virtual currencies.&nbsp;</span></p>
<p><span>According to the Washington State’s government, virtual currencies are considered as a digital currency or Cryptocurrency. Virtual currencies are the medium of exchange not adopted by a government. In December 2014, Bitcoin was added to the definition of Money Transmission. Every virtual currency in the state of Washington is subject to the UMSA – Uniform Money Services Act.</span></p>
<p><span>Trading Ban – No</span></p>
<p><span>Banking Ban – No</span></p>
<p><span>Tax Haven Region – Yes</span></p>
<p><span>Is it best Place for License – Yes, Washington has generated a multi-state licensing program to make it easy for companies to comply with crypto regulations.</span></p>

		</div>
	</div>
<h2>California</h2>
	<div>
		<div>
			<p><span>Crypto Regulatory Sandbox – The legislature of California is working on a new set of regulations specifically designed for virtual currencies and inspired by the New York BitLicense. In February 2017, the Virtual Currency Act was a bill proposed to the California Legislature. The Assembly Bill was released by the Legislature in August 2016. Just like the New York BitLicense, already established banks would not be needed to apply for the California Virtual Currency License if they want to involve themselves in the activities of the Cryptocurrency business. Nonetheless, the bill will be needed for any new businesses that lack a bank charter.</span></p>
<p><span>This bill would prohibit an individual from involving in any virtual currency business, as defined, in California unless the individual is licensed by the Commissioner of Business Oversight or is exempt from the licensure prerequisite, as provided. This bill will also need applicants for licensure, including an applicant for licensure and approval to get control of a licensee, in order to pay the commissioner a nonrefundable application fee and finish an application form, amongst other things, prior virtual currency services offered by the applicant, detail of the applicant, a sample form of receipt for transactions concerning the virtual currency business, and specified financial statements.&nbsp;</span></p>
<p><span>Trading Ban – No</span></p>
<p><span>Banking Ban – No</span></p>
<p><span>Tax Haven Region – No</span></p>
<p><span>Is it best Place for License – No, it’s too early to create a license on Bitcoin and other virtual currencies since they are still in the earliest stages of development.</span></p>

		</div>
	</div>
<h2>Argentina</h2>
	<div>
		<div>
			<p><span>According to the National Constitution of this country, the only authority that is able to issue legal currency is the Central Bank. Bitcoins are not lawful currency strictly speaking, as they are not issued by the monetary authorities of the government and are not a legal tender.&nbsp;</span></p>
<p><span>Hence, they can be considered money but not legal currency. They are not an essential means of cancelling debts or obligations.&nbsp;</span></p>
<p><span>Even though Bitcoins are not certainly regulated, they are increasingly being used in this country that has strict controls over foreign currencies. According to some professionals, a bitcoin can be considered a good or a thing under the civil code, and transactions related to Bitcoins can be governed by the rules of the sale of products under the civil code. The latest amendment to the Income Tax Law provides that the gain derived from the sale of digital currency will be considered income and taxed as such.&nbsp;</span></p>
<p><span>Trading Ban –No</span></p>
<p><span>Banking Ban – No</span></p>
<p><span>Tax Haven Region – No</span></p>
<p><span>Is it best place for License – No</span></p>
<p><span>Crypto Regulatory Sandbox – currently, there are no such crypto sandboxes that are designed to promote investment and research in Cryptocurrency in Argentine. Except for the taxation and anti-money laundering regulations, the regulatory authorities have adopted a wait-and-see tactic in regarding to cryptocurrencies. However, the Central Bank has created several research groups – amongst which there are a few groups dedicated to cryptocurrencies and Blockchain technologies.</span></p>

		</div>
	</div>
<h2>Cryptocurrency Taxation Outlook of America</h2>
	<div>
		<div>
			<p><span>In October 2019, the US Internal Revenue Service (IRS) issued new guidelines on the tax treatment of virtual currency willing to assist taxpayers to understand tax and reporting obligations for transactions including virtual currency, along with tax treatment of “hard fork” transactions.</span></p>
<p><span>In the same year, the IRS also released a draft of Schedule 1 to Form 1040. That draft would need taxpayers to answer whether they had any virtual currency-related transactions during the tax year.</span></p>
<p><span>The guidelines issued by IRS and the proposed amendment of Schedule 1 Form part of the Virtual Currency Compliance Campaign of the IRS that was initiated in July 2018 and emphasizes that the tax outcomes of Cryptocurrency or virtual currency transactions are a focal point for the IRS.</span></p>
<p><span>The new guidelines also mention that the income tax treatment of certain transactions that are unique to Cryptocurrency, for example, airdrops and hard forks.</span></p>
<p><span>According to the new guidance issued by the IRS:</span></p>
<ul>
<li><span>A person who is paying tax does not recognize gross income as an outcome of the hard fork of the Cryptocurrency owned by the taxpayer if that person does not receive units of new Cryptocurrency.</span></li>
<li><span>A person who is paying tax does recognize gross income, ordinary in character, as an outcome of an airdrop of new Cryptocurrency following a hard fork if the person who is paying tax receives units of Cryptocurrency. The total amount of the gross income to be recognized is the fair market value of the new Cryptocurrency.</span></li>
<li><span>If the person who is paying tax is capable of selling, transferring, or exchanging, or otherwise disposing of Cryptocurrency, which will be the case once the Cryptocurrency is recorded in the distributed ledger of the taxpayer, then the taxpayer has the vital extent of control and dominion.</span></li>
<li><span>In cases where the ledger of the taxpayer at a Cryptocurrency exchange does not get credited due to the reason that the exchange does not yet favors the new Cryptocurrency, the person who is paying tax does not have dominion until the new Cryptocurrency is accredited.&nbsp;</span></li>
</ul>

		</div>
	</div>
<h2>Final Thoughts</h2>
	<div>
		<p><span>Before you get started with&nbsp;</span><span>centralized…</span></p></div></div></div></div></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://blog.espay.exchange/legal-compliance-and-taxation-outlook-of-americas/">http://blog.espay.exchange/legal-compliance-and-taxation-outlook-of-americas/</a></em></p>]]>
            </description>
            <link>http://blog.espay.exchange/legal-compliance-and-taxation-outlook-of-americas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24154322</guid>
            <pubDate>Fri, 14 Aug 2020 06:14:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The future of SARS-CoV-2]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24154278">thread link</a>) | @baal80spam
<br/>
August 13, 2020 | https://www.virology.ws/2020/08/13/the-future-trajectory-of-sars-cov-2/ | <a href="https://web.archive.org/web/*/https://www.virology.ws/2020/08/13/the-future-trajectory-of-sars-cov-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">

<div><figure><img src="https://www.virology.ws/wp-content/uploads/2020/02/coronavirus-300x261.png" alt="coronavirus" srcset="https://www.virology.ws/wp-content/uploads/2020/02/coronavirus-300x261.png 300w, https://www.virology.ws/wp-content/uploads/2020/02/coronavirus.png 722w" sizes="(max-width: 300px) 100vw, 300px"></figure></div>


<p>What does the future hold for SARS-CoV-2? Will it remain in its current configuration, with 20% of infections causing serious damage? Will everyone on Earth need to be vaccinated regularly to prevent infection? Allow me to indulge in some speculation and suggest that SARS-CoV-2 will eventually become the fifth common cold coronavirus (CoV).</p>
<p>There are five CoV that regularly cause mild upper respiratory tract infections in most humans. Called OC43, HKU1, 229E and NL63, they infect children in their first years of live and cause little disease. Immunity wanes within a year and reinfections occur regularly, but with little consequence.</p>
<p>OC43, HKU1, 229E and NL63 were originally viruses that infect bats and rodents. Hundreds of years ago these viruses spilled over into humans and eventually became the viruses we know today. It is likely that the initial emergence of these viruses from bat and rodent reservoirs led to epidemics that were not noticed. There was no medicine or science or public health to record such epidemics, and given the much smaller human population, they likely spread slowly and were not noticed amid the generally poor state of human health.</p>
<p>It is likely that since their emergence hundreds of years ago, OC43, HKU1, 229E and NL63 slowly underwent change and became less pathogenic for humans. I base this assumption on the fact that contemporary spillovers of CoVs have led to serious disease in humans. In 2003, SARS-CoV emerged from bats into humans and caused severe atypical respiratory disease; however we were able to eradicate this virus after only 8000 known human infections. In 2013, MERS-CoV emerged from camels into humans, but this virus has never been able to establish itself in humans. Every small outbreak is, for the most part, the consequence of a new spillover of virus from camels into humans. These short chains of infection eventually terminate.</p>
<p>However in late 2019 SARS-CoV-2 emerged from bats into humans and established itself as a human virus. It transmits very well among humans and because 80% of infections are mild, it spreads silently. The more serious infections that require hospitalization contribute little to transmission of the virus in the human population. Indeed, these seriously ill patients have problems because their own immune response has gone awry. SARS-CoV-2 is no longer their problem.</p>
<p>It seems likely that with time, SARS-CoV-2 will change so that infected patients no longer develop serious disease. This assumption is based on the fact that causing serious disease is absolutely not required for virus transmission. As the virus moves through humans over the years, its genome will slowly accumulate mutations as a consequence of error-prone replication. Some of these mutations will be lethal and cause viral replication to cease. Other mutations will be tolerated, and among these will be changes that alter the viral reproduction cycle so that serious disease no longer occurs in 20% of infected patients. Although viral reproduction in seriously ill patients is very low, it is likely that some virus-mediated event early in infection sets the stage for the later immune dysregulation. I submit that mutations will eventually accumulate in the viral genome that prevent these late sequelae.</p>
<p>There is good reason to think that SARS-CoV-2 will eventually lose the ability to cause serious disease. The main selective force for viral evolution is transmission; little else matters (viruses can be selected to become drug resistant but such events play a minuscule role in the bigger scheme of viral evolution). Put another way, there is simply no selective advantage for the virus to remain pathogenic as this property contributes nothing to transmission. With no selection to maintain pathogenicity, SARS-CoV-2 will eventually become benign. It will become the fifth common cold CoV.</p>
<p>Why does SARS-CoV-2 cause severe disease in 20% of infected people? Recall that the ancestors of this virus originated in bats where have likely circulated for many thousands of years. These viruses became well adapted to their bat hosts, such that they replicated efficiently and were transmitted effectively to new hosts. Their genome had evolved to co-exist with the unusual immune system of bats, which is tuned to deal with the damage caused by high oxygen usage during flight. Then one day late in 2019 one of these viruses encounters a human host. It replicates well in that host but in the face of a very different immune response, problems such as cytokine storms arise. It will be some years before the genome of SARS-CoV-2 changes sufficiently so that it no longer triggers aberrant immune reactions in the human host.</p>
<p>How long it will take before SARS-CoV-2 changes sufficiently to become common cold CoV #5 is unknown. It depends in part on how well the experimental vaccines currently under development work. I suspect that none of these vaccines will completely block viral reproduction, although they may mitigate disease. Consequently SARS-CoV-2 will continue to circulate and the mutations that will eventually reduce its virulence will arise. I do think that at one day in the future we will no longer need any of the SARS-CoV-2 vaccines that are currently in development, because the virus will no longer cause serious disease. For this reason we do not have vaccines against the four common cold CoVs – there is no medical need for them.</p>
<p>To put this another way, here we have a pandemic virus whose emergence could have been stopped had we invested a few billion dollars in development of pan-CoV antiviral drugs. Instead, many companies and governments are spending billions of dollars to develop vaccines that will one day be obsolete. This lack of vision should infuriate every human on Earth.</p>
<p>Pandemic viruses will continue to emerge from animal reservoirs in the coming years. Will we be ready for them? I doubt it.</p>				</div></div>]]>
            </description>
            <link>https://www.virology.ws/2020/08/13/the-future-trajectory-of-sars-cov-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24154278</guid>
            <pubDate>Fri, 14 Aug 2020 06:09:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Implementing a Type-safe printf in Rust]]>
            </title>
            <description>
<![CDATA[
Score 65 | Comments 27 (<a href="https://news.ycombinator.com/item?id=24154263">thread link</a>) | @lukastyrychtr
<br/>
August 13, 2020 | https://willcrichton.net/notes/type-safe-printf/ | <a href="https://web.archive.org/web/*/https://willcrichton.net/notes/type-safe-printf/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  
  <p>
    
    Will Crichton
    
    &nbsp; — &nbsp;
    June 21, 2020
  </p>
  <p>I show how to use heterogeneous lists and traits to implement a type-safe printf in Rust. These mechanisms can ensure that two variadic argument lists share important properties, like the number of format string holes matches the number of printf arguments.</p>
  <p><em>Part of an ongoing series about type-level programming in Rust. Consider reading <a href="http://willcrichton.net/notes/type-level-programming/">part one</a> first! All code in this note can be found in <a href="https://gist.github.com/willcrichton/e7fcf1b0e84b4be7f172f0e0245cf149">this gist</a>.</em></p>

<p>Rust has a great printf function, <a href="https://doc.rust-lang.org/std/macro.println.html"><code>println!</code></a>. It has a rich formatting language, but also catches mistakes at compile-time. For example, <code>println!</code> will check that the number of arguments matches the number of holes in the format string:</p>

<div><div><pre><code>error: 2 positional arguments in format string, but there is 1 argument
  --&gt; src/printf.rs:36:13
   |
36 |   println!("{} {}", "Hello");
</code></pre></div></div>

<p>How does the Rust compiler make this check? Because both the format string and the argument are within the macro, Rust will check that the number of holes matches the number of arguments. Consequently, format strings <em>have</em> to be within the macro. If we write:</p>

<div><div><pre><code><span>let</span> <span>s</span> <span>=</span> <span>"{} {}"</span><span>;</span>
<span>println!</span><span>(</span><span>s</span><span>,</span> <span>"hi"</span><span>)</span>
</code></pre></div></div>

<p>This code fails to compile with the error:</p>

<div><div><pre><code>error: format argument must be a string literal
  --&gt; src/printf.rs:42:12
   |
42 |   println!(s, "hi");
</code></pre></div></div>

<p>I’ll show you how to implement type-safe printf without using procedural macros. More generally, this note contains a Rust recipe for functions where:</p>

<ol>
  <li>Arguments are variadic</li>
  <li>Each argument can be a different type (<code>Vec&lt;T&gt;</code> not allowed)</li>
  <li>Multiple variadic inputs share a parallel property, e.g. the number of arguments should match the number of format holes</li>
</ol>

<h2 id="core-mechanism-hlist">Core mechanism: HList</h2>

<p>First, we need to understand the main type-level mechanism: a heterogeneous list (or H-list). An H-list is a sequence of values of potentially different types. For example, <code>[1, "a", true]</code> is an H-list, but not a valid Rust vector. H-lists are implemented in Rust using a linked-list style:</p>

<div><div><pre><code><span>struct</span> <span>HNil</span><span>;</span>
<span>struct</span> <span>HCons</span><span>&lt;</span><span>Head</span><span>,</span> <span>Tail</span><span>&gt;</span> <span>{</span>
  <span>head</span><span>:</span> <span>Head</span><span>,</span>
  <span>tail</span><span>:</span> <span>Tail</span>
<span>}</span>

<span>let</span> <span>example</span><span>:</span> <span>HCons</span><span>&lt;</span><span>i32</span><span>,</span> <span>HCons</span><span>&lt;</span><span>bool</span><span>,</span> <span>HNil</span><span>&gt;&gt;</span> <span>=</span>
  <span>HCons</span><span>{</span><span>head</span><span>:</span> <span>1</span><span>,</span> <span>tail</span><span>:</span> <span>HCons</span><span>{</span><span>head</span><span>:</span> <span>true</span><span>,</span> <span>tail</span><span>:</span> <span>HNil</span><span>}};</span>
</code></pre></div></div>

<p>The key idea is that the type of an H-list changes every time you make a change to it. By contrast, if you push to a <code>Vec&lt;T&gt;</code>, the type of the vector stays the same.</p>

<p>Just like Rust has <code>vec![]</code>, we can use the <a href="https://github.com/lloydmeta/frunk#hlist">frunk</a> crate to get an <code>hlist!</code> macro.</p>

<div><div><pre><code><span>let</span> <span>example</span> <span>=</span> <span>hlist!</span><span>[</span><span>1</span><span>,</span> <span>true</span><span>];</span> <span>// same as above</span>
</code></pre></div></div>

<h2 id="setting-up-printf">Setting up printf</h2>

<p>Let’s go back to the ingredients of printf. We need a format string and an argument list. The key idea is to represent both with an H-list, and carefully use Rust’s traits to ensure our desired property: the number of arguments should match the number of holes.</p>

<p>First, to represent format strings, we will have a sequence of structs that represent each part of the string.</p>

<div><div><pre><code><span>pub</span> <span>struct</span> <span>FString</span><span>(</span><span>&amp;</span><span>'static</span> <span>str</span><span>);</span>
<span>pub</span> <span>struct</span> <span>FVar</span><span>;</span>

<span>// Assume that we compile "Hello {}! The first prime is {}" into this code.</span>
<span>// That would be a simple syntactic transformation.</span>
<span>let</span> <span>example</span> <span>=</span> <span>hlist!</span><span>[</span>
  <span>FString</span><span>(</span><span>"Hello "</span><span>),</span> <span>FVar</span><span>,</span> <span>FString</span><span>(</span><span>"! The first prime is "</span><span>),</span> <span>FVar</span>
<span>];</span>
</code></pre></div></div>

<p>To represent arguments, we will use a matching H-list of values. For example:</p>

<div><div><pre><code><span>let</span> <span>args</span> <span>=</span> <span>hlist!</span><span>[</span><span>"world"</span><span>,</span> <span>2</span><span>];</span>
</code></pre></div></div>

<p>Then, our goal is to create a function <code>format</code> such that this is true:</p>

<div><div><pre><code><span>assert_eq!</span><span>(</span>
  <span>example</span><span>.format</span><span>(</span><span>args</span><span>),</span>
  <span>"Hello world! The first prime is 2"</span>
<span>);</span>
</code></pre></div></div>

<p>And this should be a compile-time (NOT run-time) error:</p>

<div><div><pre><code><span>example</span><span>.format</span><span>(</span><span>hlist!</span><span>[</span><span>"Only one arg"</span><span>]);</span>
</code></pre></div></div>

<h2 id="the-format-trait">The Format trait</h2>

<p>In the spirit of type-level computation, we start by defining a trait.</p>

<div><div><pre><code><span>trait</span> <span>Format</span><span>&lt;</span><span>ArgList</span><span>&gt;</span> <span>{</span>
  <span>fn</span> <span>format</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>args</span><span>:</span> <span>ArgList</span><span>)</span> <span>-&gt;</span> <span>String</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>Here, <code>self</code> is the H-list of the format directives, and <code>ArgList</code> is the H-list of the variadic arguments. <code>Format</code> need to take <code>ArgList</code> as a type parameter, because its type will change as we remove elements from the <code>ArgList</code> list.</p>

<p>Now, we proceed to implement the <code>Format</code> trait by cases. First, the base case for reaching the end of the format list <code>HNil</code>:</p>

<div><div><pre><code><span>impl</span> <span>Format</span><span>&lt;</span><span>HNil</span><span>&gt;</span> <span>for</span> <span>HNil</span> <span>{</span>
  <span>fn</span> <span>format</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>_</span><span>args</span><span>:</span> <span>HNil</span><span>)</span> <span>-&gt;</span> <span>String</span> <span>{</span>
    <span>""</span><span>.to_string</span><span>()</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>This impl says that when we reach the end of a format list, just return the empty string. And the only argument we will accept is an empty argument list. Combined with the next impls, this inductively ensures that extra arguments are not accepted.</p>

<p>Next, we will implement <code>FString</code>. This implementation should use the string constant contained in the <code>FString</code> struct, and combine it recursively with the rest of the format list. We don’t use variadic arguments for <code>FString</code>, so they get passed along. In Rust, this English specification becomes:</p>

<div><div><pre><code><span>impl</span><span>&lt;</span><span>ArgList</span><span>,</span> <span>FmtList</span><span>&gt;</span> <span>Format</span><span>&lt;</span><span>ArgList</span><span>&gt;</span>
<span>for</span> <span>HCons</span><span>&lt;</span><span>FString</span><span>,</span> <span>FmtList</span><span>&gt;</span>
<span>where</span> <span>FmtList</span><span>:</span> <span>Format</span><span>&lt;</span><span>ArgList</span><span>&gt;</span>
<span>{</span>
  <span>fn</span> <span>format</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>args</span><span>:</span> <span>ArgList</span><span>)</span> <span>-&gt;</span> <span>String</span> <span>{</span>
    <span>self</span><span>.head</span><span>.</span><span>0</span><span>.to_owned</span><span>()</span> <span>+</span> <span>&amp;</span><span>self</span><span>.tail</span><span>.format</span><span>(</span><span>args</span><span>)</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Note that we have to add <code>FmtList: Format&lt;ArgList&gt;</code> to ensure the recursive call to <code>self.tail.format</code> works. Also note that we aren’t implementing <code>Format</code> directly on <code>FString</code>, but rather on an H-list containing <code>FString</code>.</p>

<p>Finally, the most complex case, <code>FVar</code>. We want this impl to take an argument from the <code>ArgList</code>, then format the remaining format list with the remaining arguments.</p>

<div><div><pre><code><span>impl</span><span>&lt;</span><span>T</span><span>,</span> <span>ArgList</span><span>,</span> <span>FmtList</span><span>&gt;</span> <span>Format</span><span>&lt;</span><span>HCons</span><span>&lt;</span><span>T</span><span>,</span> <span>ArgList</span><span>&gt;&gt;</span>
<span>for</span> <span>HCons</span><span>&lt;</span><span>FVar</span><span>,</span> <span>FmtList</span><span>&gt;</span>
<span>where</span>
  <span>FmtList</span><span>:</span> <span>Format</span><span>&lt;</span><span>ArgList</span><span>&gt;</span><span>,</span>
  <span>T</span><span>:</span> <span>ToString</span><span>,</span>
<span>{</span>
  <span>fn</span> <span>format</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>args</span><span>:</span> <span>HCons</span><span>&lt;</span><span>T</span><span>,</span> <span>ArgList</span><span>&gt;</span><span>)</span> <span>-&gt;</span> <span>String</span> <span>{</span>
    <span>args</span><span>.head</span><span>.to_string</span><span>()</span> <span>+</span> <span>&amp;</span><span>self</span><span>.tail</span><span>.format</span><span>(</span><span>args</span><span>.tail</span><span>)</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Be careful to observe which H-list is being accessed by <code>head</code> and <code>tail</code>. Here, the <code>args</code> H-list provides the data to fill the hole via <code>args.head</code>.</p>

<h2 id="checking-our-properties">Checking our properties</h2>

<p>With this implementation, our correct example successfully compiles and runs:</p>

<div><div><pre><code><span>let</span> <span>example</span> <span>=</span> <span>hlist!</span><span>[</span>
  <span>FString</span><span>(</span><span>"Hello "</span><span>),</span> <span>FVar</span><span>,</span> <span>FString</span><span>(</span><span>"! The first prime is "</span><span>),</span> <span>FVar</span>
<span>];</span>
<span>assert_eq!</span><span>(</span>
  <span>example</span><span>.format</span><span>(</span><span>hlist!</span><span>[</span><span>"world"</span><span>,</span> <span>2</span><span>]),</span>
  <span>"Hello world! The first prime is 2"</span>
<span>);</span>
</code></pre></div></div>

<p>What about our incorrect example? If we write this:</p>

<div><div><pre><code><span>example</span><span>.format</span><span>(</span><span>hlist!</span><span>[</span><span>"just one arg"</span><span>]);</span>
</code></pre></div></div>

<p>This code fails to compile with the error:</p>

<div><div><pre><code>error[E0308]: mismatched types
  --&gt; src/printf.rs:48:18
   |
48 |   example.format(hlist!["just one arg"]);
   |                  ^^^^^^^^^^^^^^^^^^^^^^
   |                  expected struct `Cons`, found struct `HNil`
   |
   = note: expected struct `HCons&lt;_, HNil&gt;`
              found struct `HNil`
</code></pre></div></div>

<p>While the error is enigmatic, our mistake is at least correctly caught at compile-time. This is because Rust deduces that <code>example.format()</code> expects an H-list of the shape <code>HCons&lt;_, HCons&lt;_, HNil&gt;&gt;</code>, but it finds <code>HNil</code> too soon in our 1-element H-list. A similar error occurs when providing too many args.</p>

<p>Stupendous! We have successfully implemented a type-safe printf using H-lists and traits.</p>

<h2 id="extending-our-abstraction">Extending our abstraction</h2>

<p>Right now, our <code>Format</code> function just checks that the format list and argument list are the same length. We could extend our format structures, for example to ensure that an <code>FVar</code> must be a particular type, or must use <code>Debug</code> vs. <code>Display</code>. Here’s the sketch of such a strategy:</p>

<div><div><pre><code><span>use</span> <span>std</span><span>::</span><span>marker</span><span>::</span><span>PhantomData</span><span>;</span>

<span>// Add flags for whether using Display or Debug</span>
<span>pub</span> <span>struct</span> <span>FDisplay</span><span>;</span>
<span>pub</span> <span>struct</span> <span>FDebug</span><span>;</span>

<span>// Use a type parameter with PhantomData to represent the intended type</span>
<span>pub</span> <span>struct</span> <span>FVar</span><span>&lt;</span><span>T</span><span>,</span> <span>Flag</span><span>&gt;</span><span>(</span><span>PhantomData</span><span>&lt;</span><span>(</span><span>T</span><span>,</span> <span>Flag</span><span>)</span><span>&gt;</span><span>);</span>

<span>// Now, T has to be the same between the format list and arg list</span>
<span>// Also, FDisplay flag requires that `T: Display`</span>
<span>impl</span><span>&lt;</span><span>T</span><span>,</span> <span>ArgList</span><span>,</span> <span>FmtList</span><span>&gt;</span> <span>Format</span><span>&lt;</span><span>HCons</span><span>&lt;</span><span>T</span><span>,</span> <span>ArgList</span><span>&gt;&gt;</span>
<span>for</span> <span>HCons</span><span>&lt;</span><span>FVar</span><span>&lt;</span><span>T</span><span>,</span> <span>FDisplay</span><span>&gt;</span><span>,</span> <span>FmtList</span><span>&gt;</span>
<span>where</span>
  <span>FmtList</span><span>:</span> <span>Format</span><span>&lt;</span><span>ArgList</span><span>&gt;</span><span>,</span>
  <span>T</span><span>:</span> <span>Display</span><span>,</span>
<span>{</span>
  <span>fn</span> <span>format</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>args</span><span>:</span> <span>HCons</span><span>&lt;</span><span>T</span><span>,</span> <span>ArgList</span><span>&gt;</span><span>)</span> <span>-&gt;</span> <span>String</span> <span>{</span>
    <span>// using format! is cheating, but you get the idea</span>
    <span>format!</span><span>(</span><span>"{}"</span><span>,</span> <span>args</span><span>)</span> <span>+</span> <span>&amp;</span><span>self</span><span>.tail</span><span>.format</span><span>(</span><span>args</span><span>.tail</span><span>)</span>
  <span>}</span>
<span>}</span>

<span>// Similar impl for `T: Debug` when `FDebug` is used</span>
</code></pre></div></div>

<p>With this approach, if our format list and arg list differ in type:</p>

<div><div><pre><code><span>let</span> <span>fmt</span> <span>=</span> <span>hlist!</span><span>[</span><span>FString</span><span>(</span><span>"n: "</span><span>),</span> <span>FVar</span><span>::</span><span>&lt;</span><span>i32</span><span>,</span> <span>FDisplay</span><span>&gt;</span><span>(</span><span>PhantomData</span><span>)];</span>
<span>fmt</span><span>.format</span><span>(</span><span>hlist!</span><span>[</span><span>"not a number"</span><span>]);</span>
</code></pre></div></div>

<p>Then the code will not compile with the error, <code>&amp;'static str is not i32</code>.</p>

<p>Shout-out to <a href="https://www.servant.dev/posts/2018-07-12-servant-dsl-typelevel.html">this blog post</a> from Haskell’s servant framework which got me thinking about adapting their strategy into Rust.</p>

</div></div>]]>
            </description>
            <link>https://willcrichton.net/notes/type-safe-printf/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24154263</guid>
            <pubDate>Fri, 14 Aug 2020 06:07:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a Brainfuck Compiler with Rust and LLVM]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24154210">thread link</a>) | @lukastyrychtr
<br/>
August 13, 2020 | https://benkonz.github.io/building-a-brainfuck-compiler-with-rust-and-llvm/ | <a href="https://web.archive.org/web/*/https://benkonz.github.io/building-a-brainfuck-compiler-with-rust-and-llvm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><a href="https://llvm.org/">LLVM</a> is a collection of compiler toolchain technologies  used to compile dynamic and static programming languages. Itâ€™s heavly used in programming languages, such as <a href="https://clang.llvm.org/">Clang</a>, <a href="https://emscripten.org/">Emscripten</a>, and <a href="https://www.rust-lang.org/">Rust</a>!</p>

<p>This tutorial is going to go over how to create a simple compiler using LLVM for <a href="https://en.wikipedia.org/wiki/Brainfuck">Brainf*ck</a> in Rust. The completed code can be found here: <a href="https://github.com/benkonz/brainfrick-rust">brainfrick-rust</a></p>



<p><a href="https://en.wikipedia.org/wiki/Brainfuck">Brainf-ck</a> is a very simple, turing complete, programming language that is made up of 8 commands. Each command is a single character, so parsing out an entire brainf*ck file is easy. Just read every character and match the character with a command. If the character isnâ€™t a command, just skip it and move to the next character.</p>

<h2 id="commands">Commands</h2>

<table>
  <thead>
    <tr>
      <th>Character</th>
      <th>Meaning</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>&gt;</code></td>
      <td>increment data pointer</td>
    </tr>
    <tr>
      <td><code>&lt;</code></td>
      <td>decrement data pointer</td>
    </tr>
    <tr>
      <td><code>+</code></td>
      <td>increment the byte at the data pointer</td>
    </tr>
    <tr>
      <td><code>-</code></td>
      <td>decrement the byte at the data pointer</td>
    </tr>
    <tr>
      <td><code>.</code></td>
      <td>output the byte at the data pointer to <code>stdout</code></td>
    </tr>
    <tr>
      <td><code>,</code></td>
      <td>accept one byte of input from <code>stdin</code>, storing itâ€™s value in the byte at the data pointer</td>
    </tr>
    <tr>
      <td><code>[</code></td>
      <td>if the byte at the data pointer is zero, then move the program counter to instruction after the matching <code>]</code>, otherwise move to the next instruction</td>
    </tr>
    <tr>
      <td><code>]</code></td>
      <td>if the byte at the data pointer is nonzero, then move the program counter to the instruction after the matching <code>[</code>, otherwise move to the next instruction</td>
    </tr>
  </tbody>
</table>

<h2 id="sample-program">Sample Program</h2>

<p>This simple program is going to add the current cellâ€™s value to the next cell</p>



<p>Think of <code>[</code> and <code>]</code> as <code>while (*data_ptr) {</code> and <code>}</code>, respectivly.
We decrement the current cellâ€™s value with <code>-</code>, then increment the <code>data_ptr</code> with <code>&gt;</code>, then increment the new value at our data pointer with <code>+</code>, then decrement the <code>data_ptr</code> back to where it was at the start of the loop with <code>-</code>.</p>

<p>Since this is surrounded in a <code>[</code> <code>]</code>, we are going to do this until the value at the <code>data_ptr</code> is <code>0</code>, effectivly adding the value at the <code>data_ptr</code> to the next value in memory.</p>



<p>This project uses <a href="https://releases.llvm.org/10.0.0/docs/ReleaseNotes.html">LLVM-10</a>, as well as <a href="https://crates.io/">Cargo</a>.</p>

<p>Start with:</p>

<div><div><pre><code>cargo new --bin brainfrick-rust
</code></pre></div></div>

<p>then edit the <code>Cargo.toml</code> file and add this to the dependencies:</p>

<div><div><pre><code><span>inkwell</span> <span>=</span> <span>{</span> <span>git</span> <span>=</span> <span>"https://github.com/TheDan64/inkwell"</span><span>,</span> <span>branch</span> <span>=</span> <span>"llvm10-0"</span> <span>}</span>
<span>clap</span> <span>=</span> <span>"2.33"</span>
</code></pre></div></div>

<p><code>clap</code> is used to make parsing command line args easier</p>

<p>Verify that everything works by running:</p>



<p>Unless youâ€™ve already installed the LLVM-10 development files on your machine, you will probably get an error message complaining about being unable to find LLVM-10. If thatâ€™s the case, just follow the â€œCompiling LLVMâ€� instructions <a href="https://crates.io/crates/llvm-sys">here</a>.</p>



<p>Weâ€™re going to start by making a simple executable that just returns <code>0</code>.</p>

<p>To start, weâ€™ll parse out the command line args. The first argument will be our input file and the <code>-o OUTPUT</code> will be our output file.</p>

<div><div><pre><code><span>#[macro_use]</span>
<span>extern</span> <span>crate</span> <span>clap</span><span>;</span>

<span>use</span> <span>clap</span><span>::{</span><span>App</span><span>,</span> <span>Arg</span><span>};</span>

<span>fn</span> <span>main</span><span>()</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>(),</span> <span>String</span><span>&gt;</span> <span>{</span>
     <span>let</span> <span>matches</span> <span>=</span> <span>App</span><span>::</span><span>new</span><span>(</span><span>crate_name!</span><span>())</span>
        <span>.version</span><span>(</span><span>crate_version!</span><span>())</span>
        <span>.author</span><span>(</span><span>crate_authors!</span><span>())</span>
        <span>.about</span><span>(</span><span>crate_description!</span><span>())</span>
        <span>.arg</span><span>(</span>
            <span>Arg</span><span>::</span><span>with_name</span><span>(</span><span>"INPUT"</span><span>)</span>
                <span>.help</span><span>(</span><span>"source bf file to compile"</span><span>)</span>
                <span>.required</span><span>(</span><span>true</span><span>)</span>
                <span>.index</span><span>(</span><span>1</span><span>),</span>
        <span>)</span>
        <span>.arg</span><span>(</span>
            <span>Arg</span><span>::</span><span>with_name</span><span>(</span><span>"output"</span><span>)</span>
                <span>.short</span><span>(</span><span>"o"</span><span>)</span>
                <span>.help</span><span>(</span><span>"output filename"</span><span>)</span>
                <span>.takes_value</span><span>(</span><span>true</span><span>)</span>
                <span>.required</span><span>(</span><span>true</span><span>),</span>
        <span>)</span>
        <span>.get_matches</span><span>();</span>
<span>}</span>
</code></pre></div></div>

<p>Next, weâ€™ll create our <code>context</code>, <code>module</code>, and <code>builder</code></p>

<div><div><pre><code><span>use</span> <span>inkwell</span><span>::</span><span>context</span><span>::</span><span>Context</span><span>;</span>

<span>let</span> <span>context</span> <span>=</span> <span>Context</span><span>::</span><span>create</span><span>();</span>
<span>let</span> <span>module</span> <span>=</span> <span>context</span><span>.create_module</span><span>(</span><span>"brainfrick_rust"</span><span>);</span>
<span>let</span> <span>builder</span> <span>=</span> <span>context</span><span>.create_builder</span><span>();</span>
</code></pre></div></div>

<p>After that, weâ€™ll create a main function type, which takes no arguments and returns an <code>i32</code> and add it to our module</p>

<div><div><pre><code><span>use</span> <span>inkwell</span><span>::</span><span>module</span><span>::</span><span>Linkage</span><span>;</span>

<span>let</span> <span>i32_type</span> <span>=</span> <span>context</span><span>.i32_type</span><span>();</span>
<span>let</span> <span>main_fn_type</span> <span>=</span> <span>i32_type</span><span>.fn_type</span><span>(</span><span>&amp;</span><span>[],</span> <span>false</span><span>);</span>
<span>let</span> <span>main_fn</span> <span>=</span> <span>module</span>
                <span>.add_function</span><span>(</span><span>"main"</span><span>,</span> <span>main_fn_type</span><span>,</span> <span>Some</span><span>(</span><span>Linkage</span><span>::</span><span>External</span><span>));</span>
</code></pre></div></div>

<p>Next, weâ€™ll set the builderâ€™s instruction pointer to the main function and use it to build a return instruction</p>

<div><div><pre><code><span>let</span> <span>basic_block</span> <span>=</span> <span>context</span><span>.append_basic_block</span><span>(</span><span>main_fn</span><span>,</span> <span>"entry"</span><span>);</span>
<span>builder</span><span>.position_at_end</span><span>(</span><span>basic_block</span><span>);</span>

<span>// our compiler will go here</span>

<span>let</span> <span>i32_zero</span> <span>=</span> <span>i32_type</span><span>.const_int</span><span>(</span><span>0</span><span>,</span> <span>false</span><span>);</span>
<span>builder</span><span>.build_return</span><span>(</span><span>Some</span><span>(</span><span>&amp;</span><span>i32_zero</span><span>));</span>
</code></pre></div></div>

<p>Finally, weâ€™ll have to setup LLVM to convert the builder to machine code and write that result to a file</p>

<div><div><pre><code><span>use</span> <span>inkwell</span><span>::</span><span>targets</span><span>::{</span>
    <span>CodeModel</span><span>,</span> <span>FileType</span><span>,</span> <span>InitializationConfig</span><span>,</span> <span>RelocMode</span><span>,</span> <span>Target</span><span>,</span> <span>TargetMachine</span><span>,</span>
<span>};</span>
<span>use</span> <span>inkwell</span><span>::</span><span>OptimizationLevel</span><span>;</span>

<span>Target</span><span>::</span><span>initialize_all</span><span>(</span><span>&amp;</span><span>InitializationConfig</span><span>::</span><span>default</span><span>());</span>
<span>// use the host machine as the compilation target</span>
<span>let</span> <span>target_triple</span> <span>=</span> <span>TargetMachine</span><span>::</span><span>get_default_triple</span><span>();</span>
<span>let</span> <span>cpu</span> <span>=</span> <span>TargetMachine</span><span>::</span><span>get_host_cpu_name</span><span>()</span><span>.to_string</span><span>();</span>
<span>let</span> <span>features</span> <span>=</span> <span>TargetMachine</span><span>::</span><span>get_host_cpu_features</span><span>()</span><span>.to_string</span><span>();</span>

<span>// make a target from the triple</span>
<span>let</span> <span>target</span> <span>=</span> <span>Target</span><span>::</span><span>from_triple</span><span>(</span><span>&amp;</span><span>target_triple</span><span>)</span>
<span>.map_err</span><span>(|</span><span>e</span><span>|</span> <span>format!</span><span>(</span><span>"{:?}"</span><span>,</span> <span>e</span><span>))</span><span>?</span><span>;</span>

<span>// make a machine from the target</span>
<span>let</span> <span>target_machine</span> <span>=</span> <span>target</span>
    <span>.create_target_machine</span><span>(</span>
        <span>&amp;</span><span>target_triple</span><span>,</span>
        <span>&amp;</span><span>cpu</span><span>,</span>
        <span>&amp;</span><span>features</span><span>,</span>
        <span>OptimizationLevel</span><span>::</span><span>Default</span><span>,</span>
        <span>RelocMode</span><span>::</span><span>Default</span><span>,</span>
        <span>CodeModel</span><span>::</span><span>Default</span><span>,</span>
    <span>)</span>
    <span>.ok_or_else</span><span>(||</span> <span>"Unable to create target machine!"</span><span>.to_string</span><span>())</span><span>?</span><span>;</span>

<span>// use the machine to convert our module to machine code and write the result to a file</span>
<span>let</span> <span>output_filename</span> <span>=</span> <span>matches</span><span>.value_of</span><span>(</span><span>"output"</span><span>)</span><span>.unwrap</span><span>();</span>
<span>target_machine</span>
    <span>.write_to_file</span><span>(</span><span>&amp;</span><span>module</span><span>,</span> <span>FileType</span><span>::</span><span>Object</span><span>,</span> <span>output_filename</span><span>.as_ref</span><span>())</span>
    <span>.map_err</span><span>(|</span><span>e</span><span>|</span> <span>format!</span><span>(</span><span>"{:?}"</span><span>,</span> <span>e</span><span>))</span><span>?</span><span>;</span>
</code></pre></div></div>

<p>The <code>FileType::Object</code> can be changed to <code>FileType::Assembly</code> to write human-readable machine instructions, which is very useful for debugging your compiler</p>

<h2 id="running-the-executable">Running the executable</h2>

<p>By setting the file type to <code>FileType::Object</code>, LLVM will produce an <a href="https://en.wikipedia.org/wiki/Object_file">Object File</a>. That file cannot be run by itself, and needs to be linked togeather by a linker. Typically, this is ued by <a href="https://linux.die.net/man/1/ld">ld</a>, but the right arguments to <code>ld</code> varies based on Linux disro. The easier way to link your object file is with <a href="https://gcc.gnu.org/">gcc</a>, which, internally, calls <code>ld</code> with the right args.</p>

<div><div><pre><code>cargo run INPUT_FILE -o OUTPUT_FILE
gcc OUTPUT_FILE -o OUTPUT_FILE.exe
./OUTPUT_FILE.exe
echo $?
0
</code></pre></div></div>

<p>The <code>echo $?</code> should print out the status code of the last program. You can modify the <code>let i32_zero = i32_type.const_int(0, false);</code> line to return any integer.</p>



<p>Before we start compiling our source program, we need to initialize the memory that our brainf*ck programs will use. This means calling the <a href="https://en.cppreference.com/w/c/memory/calloc">calloc</a> libc call.</p>

<p>After weâ€™ve initialized our <code>builder</code>, weâ€™re going to add this code</p>

<div><div><pre><code><span>use</span> <span>inkwell</span><span>::</span><span>AddressSpace</span><span>;</span>

<span>let</span> <span>i64_type</span> <span>=</span> <span>context</span><span>.i64_type</span><span>();</span>
<span>let</span> <span>i8_type</span> <span>=</span> <span>context</span><span>.i8_type</span><span>();</span>
<span>let</span> <span>i8_ptr_type</span> <span>=</span> <span>i8_type</span><span>.ptr_type</span><span>(</span><span>AddressSpace</span><span>::</span><span>Generic</span><span>);</span>

<span>let</span> <span>calloc_fn_type</span> <span>=</span> <span>i8_ptr_type</span><span>.fn_type</span><span>(</span><span>&amp;</span><span>[</span><span>i64_type</span><span>.into</span><span>(),</span> <span>i64_type</span><span>.into</span><span>()],</span> <span>false</span><span>);</span>
<span>let</span> <span>calloc_fn</span> <span>=</span> <span>module</span>
    <span>.add_function</span><span>(</span><span>"calloc"</span><span>,</span> <span>calloc_fn_type</span><span>,</span> <span>Some</span><span>(</span><span>Linkage</span><span>::</span><span>External</span><span>));</span>

</code></pre></div></div>

<p>Weâ€™re also going to want to add the <code>getchar</code> and <code>putchar</code> functions, which are going to get used by the <code>.</code> and  <code>,</code> commands.</p>

<div><div><pre><code><span>let</span> <span>getchar_fn_type</span> <span>=</span> <span>i32_type</span><span>.fn_type</span><span>(</span><span>&amp;</span><span>[],</span> <span>false</span><span>);</span>
<span>let</span> <span>getchar_fn</span> <span>=</span><span>module</span>
    <span>.add_function</span><span>(</span><span>"getchar"</span><span>,</span> <span>getchar_fn_type</span><span>,</span> <span>Some</span><span>(</span><span>Linkage</span><span>::</span><span>External</span><span>));</span>

<span>let</span> <span>putchar_fn_type</span> <span>=</span> <span>i32_type</span><span>.fn_type</span><span>(</span><span>&amp;</span><span>[</span><span>i32_type</span><span>.into</span><span>()],</span> <span>false</span><span>);</span>
<span>let</span> <span>putchar_fn</span> <span>=</span><span>module</span>
    <span>.add_function</span><span>(</span><span>"putchar"</span><span>,</span> <span>putchar_fn_type</span><span>,</span> <span>Some</span><span>(</span><span>Linkage</span><span>::</span><span>External</span><span>));</span>
</code></pre></div></div>

<p>Next, weâ€™re going to call <code>calloc</code> and initialize our <code>data</code> and <code>ptr</code> variables, which will both point to the result of our <code>calloc</code> call. After the <code>builder.position_at_end(basic_block);</code> line, weâ€™re going to add this code:</p>

<div><div><pre><code><span>let</span> <span>i8_type</span> <span>=</span> <span>context</span><span>.i8_type</span><span>();</span>
<span>let</span> <span>i8_ptr_type</span> <span>=</span> <span>i8_type</span><span>.ptr_type</span><span>(</span><span>AddressSpace</span><span>::</span><span>Generic</span><span>);</span>

<span>let</span> <span>data</span> <span>=</span> <span>builder</span><span>.build_alloca</span><span>(</span><span>i8_ptr_type</span><span>,</span> <span>"data"</span><span>);</span>
<span>let</span> <span>ptr</span> <span>=</span> <span>builder</span><span>.build_alloca</span><span>(</span><span>i8_ptr_type</span><span>,</span> <span>"ptr"</span><span>);</span>

<span>let</span> <span>i64_type</span> <span>=</span> <span>context</span><span>.i64_type</span><span>();</span>
<span>let</span> <span>i64_memory_size</span> <span>=</span> <span>i64_type</span><span>.const_int</span><span>(</span><span>30_000</span><span>,</span> <span>false</span><span>);</span>
<span>let</span> <span>i64_element_size</span> <span>=</span> <span>i64_type</span><span>.const_int</span><span>(</span><span>1</span><span>,</span> <span>false</span><span>);</span>

<span>let</span> <span>data_ptr</span> <span>=</span> <span>builder</span><span>.build_call</span><span>(</span>
    <span>calloc_fn</span><span>,</span>
    <span>&amp;</span><span>[</span><span>i64_memory_size</span><span>.into</span><span>(),</span> <span>i64_element_size</span><span>.into</span><span>()],</span>
    <span>"calloc_call"</span><span>,</span>
<span>);</span>
<span>let</span> <span>data_ptr_result</span><span>:</span> <span>Result</span><span>&lt;</span><span>_</span><span>,</span> <span>_</span><span>&gt;</span> <span>=</span> <span>data_ptr</span><span>.try_as_basic_value</span><span>()</span><span>.flip</span><span>()</span><span>.into</span><span>();</span>
<span>let</span> <span>data_ptr_basic_val</span> <span>=</span>
    <span>data_ptr_result</span><span>.map_err</span><span>(|</span><span>_</span><span>|</span> <span>"calloc returned void for some reason!"</span><span>)</span><span>?</span><span>;</span>

<span>builder</span><span>.build_store</span><span>(</span><span>data</span><span>,</span> <span>data_ptr_basic_val</span><span>);</span>
<span>builder</span><span>.build_store</span><span>(</span><span>ptr</span><span>,</span> <span>data_ptr_basic_val</span><span>);</span>
</code></pre></div></div>

<p>Finally, weâ€™re going to call <a href="https://en.cppreference.com/w/c/memory/free">free</a> on our <code>data</code> pointer. This isnâ€™t really necessary, since the program ends right after, but it is good practice. LLVM has a convience function called <code>build_free</code>, so we donâ€™t need to add the free function to our module.</p>

<div><div><pre><code>  <span>builder</span>
    <span>.build_free</span><span>(</span><span>builder</span><span>.build_load</span><span>(</span><span>data</span><span>,</span> <span>"load"</span><span>)</span><span>.into_pointer_value</span><span>());</span>

</code></pre></div></div>

<p>Letâ€™s verify that everything is working correctly. Recompile our code and make another executable with <code>cargo run</code>. Re-link it with <code>gcc</code>, then run <code>ltrace ./OUTPUT_FILE.exe</code>. You should see something like this:</p>

<div><div><pre><code>calloc(30000, 1)        = 0x55a9ec9482a0
free(0x55a9ec9482a0)    = &lt;void&gt;
+++ exited (status 0) +++
</code></pre></div></div>

<p><code>ltrace</code> traces all of the library calls of an executable, so we should see a call to <code>calloc</code> and a call to <code>free</code>.</p>

<p>Weâ€™ll need to setup some boilerplate code to read in our input file and iterate through all of the characters. After <code>builder.build_store(ptr, data_ptr_basic_val);</code>, add</p>

<div><div><pre><code><span>use</span> <span>std</span><span>::</span><span>fs</span><span>::</span><span>File</span><span>;</span>
<span>use</span> <span>std</span><span>::</span><span>io</span><span>::</span><span>prelude</span><span>::</span><span>*</span><span>;</span>
<span>use</span> <span>std</span><span>::</span><span>collections</span><span>::</span><span>VecDeque</span><span>;</span>
<span>use</span> <span>inkwell</span><span>::</span><span>basic_block</span><span>::</span><span>BasicBlock</span><span>;</span>

<span>let</span> <span>source_filename</span> <span>=</span> <span>matches</span><span>.value_of</span><span>(</span><span>"INPUT"</span><span>)</span><span>.unwrap</span><span>();</span>
<span>let</span> <span>mut</span> <span>f</span> <span>=</span> <span>File</span><span>::</span><span>open</span><span>(</span><span>source_filename</span><span>)</span><span>.map_err</span><span>(|</span><span>e</span><span>|</span> <span>format!</span><span>(</span><span>"{:?}"</span><span>,</span> <span>e</span><span>))</span><span>?</span><span>;</span>
<span>let</span> <span>mut</span> <span>program</span> <span>=</span> <span>String</span><span>::</span><span>new</span><span>();</span>
<span>f</span><span>.read_to_string</span><span>(</span><span>&amp;</span><span>mut</span> <span>program</span><span>)</span>
    <span>.map_err</span><span>(|</span><span>e</span><span>|</span> <span>format!</span><span>(</span><span>"{:?}"</span><span>,</span> <span>e</span><span>))</span><span>?</span><span>;</span>

<span>let</span> <span>mut</span> <span>while_blocks</span> <span>=</span> <span>VecDeque</span><span>::</span><span>new</span><span>();</span>

<span>for</span> <span>command</span> <span>in</span> <span>program</span><span>.chars</span><span>()</span> <span>{</span>
    <span>match</span> <span>command</span> <span>{</span>
        <span>'&gt;'</span> <span>=&gt;</span> <span>build_add_ptr</span><span>(</span><span>&amp;</span><span>context</span><span>,</span> <span>&amp;</span><span>builder</span><span>,</span> <span>1</span><span>,</span> <span>&amp;</span><span>ptr</span><span>),</span>
        <span>'&lt;'</span> <span>=&gt;</span> <span>build_add_ptr</span><span>(</span><span>&amp;</span><span>context</span><span>,</span> <span>&amp;</span><span>builder</span><span>,</span> <span>-</span><span>1</span><span>,</span> <span>&amp;</span><span>ptr</span><span>),</span>
        <span>'+'</span> <span>=&gt;</span> <span>build_add</span><span>(</span><span>&amp;</span><span>context</span><span>,</span> <span>&amp;</span><span>builder</span><span>,</span> <span>1</span><span>,</span> <span>&amp;</span><span>ptr</span><span>),</span>
        <span>'-'</span> <span>=&gt;</span> <span>build_add</span><span>(</span><span>&amp;</span><span>context</span><span>,</span> <span>&amp;</span><span>builder</span><span>,</span> <span>-</span><span>1</span><span>,</span> <span>&amp;</span><span>ptr</span><span>),</span>
        <span>'.'</span> <span>=&gt;</span> <span>build_put</span><span>(</span><span>&amp;</span><span>context</span><span>,</span> <span>&amp;</span><span>builder</span><span>,</span> <span>&amp;</span><span>putchar_fn</span><span>,</span> <span>&amp;</span><span>ptr</span><span>),</span>
        <span>','</span> <span>=&gt;</span> <span>build_get</span><span>(</span><span>&amp;</span><span>context</span><span>,</span> <span>&amp;</span><span>builder</span><span>,</span> <span>&amp;</span><span>getchar_fn</span><span>,</span> <span>&amp;</span><span>ptr</span><span>)</span><span>?</span><span>,</span>
        <span>'['</span> <span>=&gt;</span> <span>build_while_start</span><span>(</span><span>&amp;</span><span>context</span><span>,</span> <span>&amp;</span><span>builder</span><span>,</span> <span>&amp;</span><span>main_fn</span><span>,</span> <span>&amp;</span><span>ptr</span><span>,</span>…</code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://benkonz.github.io/building-a-brainfuck-compiler-with-rust-and-llvm/">https://benkonz.github.io/building-a-brainfuck-compiler-with-rust-and-llvm/</a></em></p>]]>
            </description>
            <link>https://benkonz.github.io/building-a-brainfuck-compiler-with-rust-and-llvm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24154210</guid>
            <pubDate>Fri, 14 Aug 2020 05:59:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Virtual Tracing: A simpler alternative to distributed tracing]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24154119">thread link</a>) | @gk1
<br/>
August 13, 2020 | https://www.zebrium.com/blog/virtual-tracing-a-simpler-alternative-to-distributed-tracing-for-troubleshooting | <a href="https://web.archive.org/web/*/https://www.zebrium.com/blog/virtual-tracing-a-simpler-alternative-to-distributed-tracing-for-troubleshooting">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><h2>The promise of tracing</h2>
<p>Distributed tracing is commonly used in Application Performance Monitoring (APM) to monitor and manage application performance, giving a view into what parts of a transaction call chain are slowest. It is a powerful tool for monitoring call completion times and examining particular requests and transactions.</p>
<!--more--><p>Quite beyond APM, it seems natural to expect tracing to yield a ‘troubleshooting tool to rule them all’. The detail and semantic locality of the trace, coupled with the depth of the service call graph, generate this expectation. It’s obvious that correlating across services gives diagnostic power. The typical traceview screams the sort of “first this, then that” narrative RCAs are made of.</p>

<p>In reality, though, users have seen mixed results. According to a prospect:</p>

<p><em>“We paid six figures for a &lt;well-known tracing tool&gt; contract, to reduce MTTR significantly. We’ve given up on that. We’re writing it off. Engineers had to do extra work to implement it. Operations had to do extra work to set and respond to alerts. The alerts worked well but, in the end, finding root-cause was still slow. It just wasn’t worth it.”</em></p>

<p>This is not isolated feedback.</p>
<h2>“Tell me where to focus”</h2>
<p>There are two issues raised: work required to yield results, and inadequacy of those results. The first issue is easy to understand: depending on the stack, the application, the application’s evolution, the deployment mechanisms and so on, it may indeed be a lot of work to generate useful traces. This problem is not surprising and can be surmounted; it is worth taking away that zero-configuration, zero-instrumentation (i.e., <em>autonomous</em>) solutions are of great value.</p>

<p>The larger issue is around applicability for root-cause detection. Here, respected Observability author and blogger Cindy Sridharan has some insightful things to say. I’ll lift a quote <a href="https://medium.com/@copyconstruct/distributed-tracing-weve-been-doing-it-wrong-39fc92a857df" rel="noopener" target="_blank">from her article</a>&nbsp;which I highly recommend:</p>

<p><em>“What’s ideally required at the time of debugging is a tool that’ll help&nbsp;reduce the search space… Instead of seeing an entire trace, what I really want to be seeing is a&nbsp;portion&nbsp;of the trace where something interesting or unusual is happening… dynamically generated service topology views&nbsp;based on specific attributes like error rate or response time…”</em></p>

<p><em><img src="https://www.zebrium.com/hs-fs/hubfs/Blogs/distributed%20tracing.png?width=900&amp;name=distributed%20tracing.png" alt="distributed tracing" width="900" srcset="https://www.zebrium.com/hs-fs/hubfs/Blogs/distributed%20tracing.png?width=450&amp;name=distributed%20tracing.png 450w, https://www.zebrium.com/hs-fs/hubfs/Blogs/distributed%20tracing.png?width=900&amp;name=distributed%20tracing.png 900w, https://www.zebrium.com/hs-fs/hubfs/Blogs/distributed%20tracing.png?width=1350&amp;name=distributed%20tracing.png 1350w, https://www.zebrium.com/hs-fs/hubfs/Blogs/distributed%20tracing.png?width=1800&amp;name=distributed%20tracing.png 1800w, https://www.zebrium.com/hs-fs/hubfs/Blogs/distributed%20tracing.png?width=2250&amp;name=distributed%20tracing.png 2250w, https://www.zebrium.com/hs-fs/hubfs/Blogs/distributed%20tracing.png?width=2700&amp;name=distributed%20tracing.png 2700w" sizes="(max-width: 900px) 100vw, 900px"></em></p>

<p>We need a tool that takes a stab at incident and, if possible, root-cause detection, or highlighting. Stepping back further, I would posit that trace data has become a bit like log data: a treasure trove of untapped information for root-cause detection, in-part because there is just too much detail to sift through without help.</p>
<h2>Virtual tracing alone</h2>
<p>Tracing is so promising for troubleshooting because of semantic locality. Tracing works the way it does because span ids are passed around the stack - in headers or log lines, for example. These spans are then associated together into a trace, and so we know all the spans in the trace are at least to some extent “about” the same thing - a transaction or request, for example.</p>

<p>There are other ways to establish semantic locality. Looking again at a trace, we might note that its spans demonstrate temporal locality, as well. We might suppose that a majority of service-impacting incidents also have temporal locality: if Service A fails, and Service B calls Service A, then Service B is likely also to fail, soon after Service A does. Our job will be to determine spans of telemetric data that share semantic locality.</p>

<p>Could we suppose that events happening nearby in time are semantically related? Of course not… but, we could look for features in *ordinary telemetry* - “rareness” or “badness”, for example - and model inter-occurrence intervals of such features across services. Rareness might be indicated by rare log events from a given container, for example, or a multi-hour peak in a metric; badness might be indicated by a flurry of errors from another container, or a host log.</p>

<p>Machine learning could observe the ordinary behavior of the system to estimate parameters for our model, and then use the model to hypothesize which features ARE semantically related, with high probability. Related features would in this way correspond to a virtual trace; each virtual span would map directly to a timespan of telemetric data capture for a single generator - host, container, or service, for example.</p>
<h2>A virtual tracing example</h2>
<p>A database server is inadvertently shut down. A number of rare events are emitted into its log stream; a rare spike in available memory occurs on the host(s). A few seconds later, a flurry of unusual errors are emitted in the log stream of a service reliant on the database because it cannot connect to the database.</p>

<p>Say, rare events in the database log stream happen at random about once per day, on average; rare errors in the consumer’s log stream happen about once every hour; comparable spikes in available memory happen twice a day. But now, all three of these rare things happened within 3 seconds.</p>

<p>The ML model decides these all should be part of a virtual trace, as a result; we construct spans of related activity on each generator - contiguous timespans, in fact - and bundle them up. If there was enough badness, we notify; we fingerprint to keep track of separate “trace types”. In this way we’ve achieved the goals of autonomous incident and root-cause detection; we can present only the data and services where attention should be focused.</p>
<p><img src="https://www.zebrium.com/hs-fs/hubfs/Blogs/vifrtual%20tracing.png?width=900&amp;name=vifrtual%20tracing.png" alt="vifrtual tracing" width="900" srcset="https://www.zebrium.com/hs-fs/hubfs/Blogs/vifrtual%20tracing.png?width=450&amp;name=vifrtual%20tracing.png 450w, https://www.zebrium.com/hs-fs/hubfs/Blogs/vifrtual%20tracing.png?width=900&amp;name=vifrtual%20tracing.png 900w, https://www.zebrium.com/hs-fs/hubfs/Blogs/vifrtual%20tracing.png?width=1350&amp;name=vifrtual%20tracing.png 1350w, https://www.zebrium.com/hs-fs/hubfs/Blogs/vifrtual%20tracing.png?width=1800&amp;name=vifrtual%20tracing.png 1800w, https://www.zebrium.com/hs-fs/hubfs/Blogs/vifrtual%20tracing.png?width=2250&amp;name=vifrtual%20tracing.png 2250w, https://www.zebrium.com/hs-fs/hubfs/Blogs/vifrtual%20tracing.png?width=2700&amp;name=vifrtual%20tracing.png 2700w" sizes="(max-width: 900px) 100vw, 900px"></p>
<h2>Virtual and instrumented tracing combined</h2>
<p>Combining these approaches yields real opportunities for improving the user experience. The instrumented trace augments the virtual one. For example, the service graph can be used to exclude virtual spans from a virtual trace based on implausibility of the related generator causing the observed badness; the full trace can give deep performance context to the virtual trace and serve as a launching-off point to navigate to other services and/or similar traces. Instrumented tracing brings precision, depth, and broad context to a virtual trace.</p>

<p>Similarly, the virtual trace augments the instrumented one. We can hone or auto-tune our alerting based on badness seen in the virtual trace; we can hone the traceview to just those services and components touching the virtual trace, and then allow the user to expand outward, if need be. Virtual tracing brings autonomy, incident detection, and root-cause indication to an instrumented trace.</p>

<p>Zebrium has built an implementation of virtual tracing into its autonomous log management and monitoring platform. <a href="https://www.zebrium.com/" rel=" noopener">You can read more about it here</a>.&nbsp;</p>
</span>
</p>
</div></div>]]>
            </description>
            <link>https://www.zebrium.com/blog/virtual-tracing-a-simpler-alternative-to-distributed-tracing-for-troubleshooting</link>
            <guid isPermaLink="false">hacker-news-small-sites-24154119</guid>
            <pubDate>Fri, 14 Aug 2020 05:43:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Startupschool Build Sprint Panic]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24153818">thread link</a>) | @100-xyz
<br/>
August 13, 2020 | https://toonclip.com/blog | <a href="https://web.archive.org/web/*/https://toonclip.com/blog">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://toonclip.com/blog</link>
            <guid isPermaLink="false">hacker-news-small-sites-24153818</guid>
            <pubDate>Fri, 14 Aug 2020 05:08:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Separating Concerns in React with the 'Named Children' Pattern]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24153729">thread link</a>) | @todsacerdoti
<br/>
August 13, 2020 | https://ncphi.dev/blog/react-named-children | <a href="https://web.archive.org/web/*/https://ncphi.dev/blog/react-named-children">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><article><p>Components that wrap other content usually use the <code>children</code> pattern. For example, if we want to put a message inside of a <code>&lt;Card&gt;</code> we would do:</p><p>If we want to adjust how big the <code>&lt;Card&gt;</code> itself works then we could pass it extra props:</p><div><pre><code><span>&lt;</span><span>Card</span><span> </span><span>size</span><span>=</span><span>"</span><span>large</span><span>"</span><span>&gt;</span><span>Hello World</span><span>&lt;/</span><span>Card</span><span>&gt;</span></code></pre></div><p>This pattern works well if there's only the main body, but what if the <code>&lt;Card&gt;</code> has multiple sections?</p><p>Usually we might pass the content in as <code>props</code>.</p><div><pre><code><span>&lt;</span><span>Card</span><span>
</span><span>  </span><span>size</span><span>=</span><span>"</span><span>large</span><span>"</span><span>
</span><span>  </span><span>title</span><span>=</span><span>"</span><span>Hello World</span><span>"</span><span>
</span><span>  </span><span>subtitle</span><span>=</span><span>"</span><span>This is a basic example</span><span>"</span><span>
</span><span>  </span><span>body</span><span>=</span><span>"</span><span>Here is where a lot more text would go.</span><span>"</span><span>
</span><span></span><span>/&gt;</span></code></pre></div><p>This is kinda awkward though because <code>props</code> is mixing two concerns:</p><ul><li>it configures of the <code>Card</code> itself</li><li>it provides the inner-content of the <code>Card</code></li></ul><p>This looks especially weird if we wanted to wrap <code>example</code> in a <code>&lt;strong&gt;</code> tag:</p><div><pre><code><span>&lt;</span><span>Card</span><span>
</span><span>  </span><span>size</span><span>=</span><span>"</span><span>large</span><span>"</span><span>
</span><span>  </span><span>title</span><span>=</span><span>"</span><span>Hello World</span><span>"</span><span>
</span><span>  </span><span>subtitle</span><span>=</span><span>{</span><span>
</span><span>    </span><span>&lt;</span><span>&gt;</span><span>
</span><span>      This is a basic </span><span>&lt;</span><span>strong</span><span>&gt;</span><span>example</span><span>&lt;/</span><span>strong</span><span>&gt;</span><span>
</span><span>    </span><span>&lt;/</span><span>&gt;</span><span>
</span><span>  </span><span>}</span><span>
</span><span>  </span><span>body</span><span>=</span><span>"</span><span>Here is where a lot more text would go.</span><span>"</span><span>
</span><span></span><span>/&gt;</span></code></pre></div><p>Luckily the <em>Named Children</em> pattern is an approach that deals with that mixing of concerns!</p><div><pre><code><span>&lt;</span><span>Card</span><span> </span><span>size</span><span>=</span><span>"</span><span>large</span><span>"</span><span>&gt;</span><span>
</span><span></span><span>{</span><span>{</span><span>
</span><span>  title</span><span>:</span><span> </span><span>"Hello World"</span><span>
</span><span>  subtitle</span><span>:</span><span> </span><span>&lt;</span><span>&gt;</span><span>This is a basic </span><span>&lt;</span><span>strong</span><span>&gt;</span><span>example</span><span>&lt;/</span><span>strong</span><span>&gt;</span><span>&lt;/</span><span>&gt;</span><span>
</span><span>  body</span><span>:</span><span> </span><span>"Here is where a lot more text would go."</span><span>
</span><span></span><span>}</span><span>}</span><span>
</span><span></span><span>&lt;/</span><span>Card</span><span>&gt;</span></code></pre></div><p>With this pattern the <code>Card</code> receives an object as <code>children</code> which maps the name of the section to it's content. The <em>Named Children</em> pattern allows us to separate the config for the <code>Card</code> from the definition of it's children. This makes it easier to see what is configuration, and what is content to more quickly understand what's happening with this component.</p><p>Here's a quick example of what that <code>Card</code> component might look like:</p><div><pre><code><span>function</span><span> </span><span>Card</span><span>(</span><span>{</span><span> size</span><span>,</span><span> children </span><span>}</span><span>)</span><span> </span><span>{</span><span>
</span><span>  </span><span>return</span><span> </span><span>(</span><span>
</span><span>    </span><span>&lt;</span><span>div</span><span> </span><span>className</span><span>=</span><span>{</span><span>size</span><span>}</span><span>&gt;</span><span>
</span><span>      </span><span>&lt;</span><span>h2</span><span>&gt;</span><span>{</span><span>children</span><span>.</span><span>title</span><span>}</span><span>&lt;/</span><span>h2</span><span>&gt;</span><span>
</span><span>      </span><span>&lt;</span><span>h3</span><span>&gt;</span><span>{</span><span>children</span><span>.</span><span>subtitle</span><span>}</span><span>&lt;/</span><span>h3</span><span>&gt;</span><span>
</span><span>      </span><span>&lt;</span><span>p</span><span>&gt;</span><span>{</span><span>children</span><span>.</span><span>body</span><span>&lt;/</span><span>p</span><span>&gt;</span><span>
</span><span>    </span><span>&lt;/</span><span>div</span><span>&gt;</span><span>
</span><span>  </span><span>)</span><span>
</span><span></span><span>}</span></code></pre></div><p>I haven't had much of a chance to use this pattern, but I'm excited to give it a try. The Named Children
pattern allows us to <a href="https://en.wikipedia.org/wiki/Separation_of_concerns">separate the concerns</a> of our
Components. Hopefully this will result in cleaner code that's easier to change.</p></article></div></div></div></div>]]>
            </description>
            <link>https://ncphi.dev/blog/react-named-children</link>
            <guid isPermaLink="false">hacker-news-small-sites-24153729</guid>
            <pubDate>Fri, 14 Aug 2020 04:59:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Valve Index HMD detailed teardown]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24153709">thread link</a>) | @Jerry2
<br/>
August 13, 2020 | https://www.thevrist.com/indexteardown | <a href="https://web.archive.org/web/*/https://www.thevrist.com/indexteardown">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>If you have ever wondered what is inside Valve Index, you might have stumbled upon my <a href="https://www.reddit.com/r/ValveIndex/comments/cpayc5/valve_index_disassembly/">reddit post from 2019</a>. I’ve decided to dive into the details of what makes Valve Index great and share my thoughts on tech inside.</p>

<p>Teardown should begin from the simplest parts - remove the face mask (held by just magnets), unplug the main cable, and remove headphones that are held in place by a single screw each. Next remove the rubber cover that is glued around lenses. It’s not that well glued, you can just pull it off.</p>

<p><img src="https://www.thevrist.com/assets/images/index1.jpg" alt="">
<em>Rubber cover that prevents dust from getting inside lenses</em></p>

<p>Let’s start with a front panel - glossy front panel is removed by hand, since it is only held by magnets (but you already knew that from all the numerous pictures of people shoving stuff in the frunk of the headset). The rest of the front panel can be easily split in two parts. First is the frunk section, it will give you access to the main circuit board of the headset. You can remove it quite painlessly if you have the correct screwdriver. This panel does not contain any electronics.</p>

<p><img src="https://www.thevrist.com/assets/images/index-face.jpg" alt="">
<em>Just look at this beauty</em></p>

<p>Second part of the front panel is more complex. It contains tracking points for the SteamVR tracking - you can see them by looking at the plastic at different angles - plastic covering tracking points is thinner so laser beams from base stations could shoot through it. SteamVR trackers are split in two independent parts, which are connected to the main circuit separately. Also this panel contains two front facing cameras, which makes the process of taking it off even more delicate. You have to disconnect two cameras and two halves of the tracking plate’s system to finally fully reveal the main circuit.</p>

<h2 id="main-circuit">Main Circuit</h2>

<p><img src="https://www.thevrist.com/assets/images/index2.jpg" alt="">
<em>The “meat” of Valve Index</em></p>

<p>Finally we get to the main computing power of the headset. You can identify the main points of the headset.</p>

<p><img src="https://www.thevrist.com/assets/images/index3-1.png" alt="">
<em>This is where all the cables connect to the HMD</em></p>

<p>On the top there is a metal connector with FPC cable going in. It is going to the smaller circuit in the top part of the headset where the cable plugs in the headset.</p>

<p><img src="https://www.thevrist.com/assets/images/index4.jpg" alt="">
<em>Circuit board with main cable and 3.5 mm audio port. It also connects to the proximity sensor</em></p>

<p>Same circuit has a 3.5 mm audio port for connecting headphones (I bet you didn’t know there is an audio jack) and proximity sensor between lenses. Last one is used for turning off the screens when the headset is not on the head.</p>

<p><img src="https://www.thevrist.com/assets/images/index2-1.png" alt="">
<em>SteamVR tracking points are connected here</em></p>

<p>On the sides of the main circuit board there are two black FPC cables. Those are going to the SteamVR tracking dots located in the sides of the headsets. Here is a picture of the tracking “web” when taken out of the headset.</p>

<p><img src="https://www.thevrist.com/assets/images/index5.jpg" alt="">
<em>One side of SteamVR tracking web taken out of the HMD</em></p>

<p>Final two FPC cables are orange color and located at the bottom of the main board. They are connecting to a pair of displays located right behind this circuit.</p>

<h2 id="microchips">Microchips</h2>

<p>Now it is time to dive in a wonderful world of microchips and circuit boards. I want to thank <a href="https://www.linkedin.com/in/popovs/">Sergejs Popovs</a> for helping to identify most of the components on the board.</p>

<p>Let’s start with simple chips. Here are two bluetooth <a href="https://www.nordicsemi.com/Products/Low-power-short-range-wireless/nRF52840">chips from Nordic Semiconductors</a>. Each of these chips is used for connecting one controller with the headset. That’s why there is a limitation of two devices connected to the HMD. If you want to connect more devices (Vive Trackers or other controllers) you will need to use a USB dongle with a separate Bluetooth chip.</p>

<p><img src="https://www.thevrist.com/assets/images/index6.jpg" alt="">
<img src="https://www.thevrist.com/assets/images/index7.jpg" alt="">
<em>Bluetooth microchips, each connects to one device</em></p>

<p>Do you remember the USB port in the frunk? Well, this is a <a href="http://ww1.microchip.com/downloads/en/DeviceDoc/USB5744-Data-Sheet-DS00001855J.pdf">chip from Microchip</a> for that USB port - hence USB in the name.</p>

<p><img src="https://www.thevrist.com/assets/images/index4-4.jpg" alt="">
<em>USB chip for USB port next to it</em></p>

<p>Here is a <a href="https://www.via-labs.com/product_show.php?id=96">chip from Via-Labs</a>. It has a purpose of converting USB 3.1 signal to the 2.0 one. Some of the chips on the circuit are not advanced enough to understand 3.1 USB, so this chip “dumbs it down”. When the signal will need to go back to the PC, the chip will convert the signal back to the USB 3.1.</p>

<p><img src="https://www.thevrist.com/assets/images/index8.jpg" alt="">
<em>USB signal converter chip</em></p>

<p>This is a flash memory chip from <a href="https://www.digikey.com/products/en/integrated-circuits-ics/memory/774?k=w25q32jw">Winbond Electronics</a>.</p>

<p><img src="https://www.thevrist.com/assets/images/index9.jpg" alt="">
<em>Flash memory can be used for different kinds of tasks</em></p>

<p>Next are these two microchips. The smaller one is a <a href="https://www.analogix.com/en/products/dp-mipi-converters/anx7530">SlimPort® 4K receiver from Analogix</a>. It is capable of receiving Image in 4K at 60 Hz, but since screens in Valve Index are only 1440 by 1600 pixels it allows to process video at 90, 120, and even 144 Hz. It also splits the signal in two allowing each display to get its own image.</p>

<p><img src="https://www.thevrist.com/assets/images/index10.jpg" alt="">
<em>Video chips convert image that you see in your SteamVR mirror in beautiful VR image</em></p>

<p>Larger chip is a multipurpose <a href="https://www.digikey.com/products/en/integrated-circuits-ics/embedded-fpgas-field-programmable-gate-array/696?k=ICE40HX8K">FPGA (Field Programmable Gate Array) chip from Lattice Semiconductor</a>. It is used for tracking - all the data received from the tracking sensors is gathered here. This chip combined with the <a href="http://ww1.microchip.com/downloads/en/DeviceDoc/Atmel-11289-32-bit-Cortex-M4-Microcontroller-SAM-G55_Summary-Datasheet.pdf">Atmel MCU</a> (located on the other side of the circuit board) are doing all the necessary tracking calculations.</p>

<p><a href="http://www.etron.com.tw/cn/products/webcam_detial.php?Product_ID=10">EtronTech microchip</a> is used for merging video feeds from external cameras and transmitting it to your PC.</p>

<p><img src="https://www.thevrist.com/assets/images/index11.jpg" alt="">
<em>Microchip for processing image from webcams</em></p>

<p>Last two chips on this side of the circuit from <a href="https://www.silabs.com/power/efp01-power-management-ic">SiliconLabs</a> are most likely related to power regulation. Both of them are located near the capacitors and an inductor (metal thingy with 150 written on it). These are making sure that nothing will get too hot on your face.</p>

<p><img src="https://www.thevrist.com/assets/images/index12.jpg" alt="">
<img src="https://www.thevrist.com/assets/images/index13.jpg" alt="">
<em>Power regulating microchips</em></p>

<p>Next step is to remove the main circuit board and look on its other side. Other side is less interesting and has very little information to offer. Most parts are related to the power regulation mentioned in the previous paragraph.</p>

<p><img src="https://www.thevrist.com/assets/images/index14.jpg" alt="">
<em>Back side of the main circuit board</em></p>

<p>Largest chip is an Atmel MCU, which I’ve already mentioned is related to the tracking system. On the left from it is a <a href="https://www.nxp.com/docs/en/data-sheet/LPC11U1X.pdf">microcontroller from NXP</a>. These are all the chips we managed to identify. One chip that is missing, is the additional Bluetooth module. Unlike Vive and Vive Pro, Index has bluetooth in the headset. It is used for connecting to the base stations, updating base station firmware, and sending them to sleep mode when the headset is turning off. Last one is completely optional - I prefer to keep my base stations 2.0 on all the time.</p>

<p><img src="https://www.thevrist.com/assets/images/index14-2.jpg" alt="">
<em>The only two chips worth noting on this side of the motherboard - larger one is for tracking calculations</em></p>

<p>Why there is no separate Bluetooth chip for this purpose is still a mystery for me. Only possible explanation is that two Bluetooth chips for controllers are capable of switching to different modes and control the base stations.</p>

<h2 id="screens">Screens</h2>

<p>After the circuit is removed you will reveal several key components. First - you can see two displays - quick search shows that those panels are made by BOE Technology - Chinese display manufacturer. Those are 1440×1600, 615PPI 3.5” <a href="https://www.panelook.com/VS035ZSM-NW0-69P0_BOE_3.5_LCM_overview_37926.html">panels</a>.</p>

<p><img src="https://www.thevrist.com/assets/images/index15.jpg" alt="">
<em>View of the HMD with main board removed</em></p>

<p>Note some key elements in this view. On the bottom there is a circular mechanism with a metal pin with springs going through the whole headset. Similar pin is barely visible on the top of the headset. This is an IPD adjustment system - movement of the knob at the bottom of the HMD will rotate circular element in the bottom center which will push screens apart.
On the left and right sides of HMD you can see black gears - this is a system for eye relief - rotating a knob on the side of the headset will move the facemask relatively to the screens. Gear system is making sure both sides are rotating simultaneously, without giving too much pressure to the mechanism.</p>

<p><img src="https://www.thevrist.com/assets/images/index16.jpg" alt="">
<em>IPD knob is actually a screw</em></p>

<p>In order to take the central part out from the headset, you will need to take the cap off the IPD adjustment knob and unscrew it.</p>

<p><img src="https://www.thevrist.com/assets/images/index17.jpg" alt="">
<em>Lens chambers with IPD mechanism still attached</em></p>

<p>Next was what I call the “wondering in the dark” part of teardown - for about 30 minutes we were trying to find a way of taking it apart without breaking anything, eventually using force to break one gear inside that was holding display chambers in place.</p>

<p><img src="https://www.thevrist.com/assets/images/index18.jpg" alt="">
<em>Right eye lens chamber removed</em></p>

<p>After this step you can easily take off separate lens chambers and view the details. Chambers are sealed shut so nothing will get inside - they are assembled in perfectly clean conditions with no dust particles. 
In order to take it apart you can probably try to melt glue or something like that. But we are no iFixit, we used good ol’ force. Here you can see the screen separated from the chamber.</p>

<p><img src="https://www.thevrist.com/assets/images/index19.jpg" alt="">
<img src="https://www.thevrist.com/assets/images/index20.jpg" alt="">
<em>BOE screen removed from the chamber</em></p>

<p>Screen has a polarised diffuser glued to it, which is particularly difficult to remove. It is made of very thin crystal glass and it cracks easily. You can see that the corners of it are cracked.</p>

<p><img src="https://www.thevrist.com/assets/images/index21.jpg" alt="">
<em>Crystal polarisation diffuser</em></p>

<p>Diffuser is added to blend pixels better, making the screen door effect even lower.</p>

<p><img src="https://www.thevrist.com/assets/images/index22.jpg" alt="">
<em>Fancy multilayered lens</em></p>

<p>Finally - the lenses. I was expecting them to be thicker with the effect that they create. Valve are saying “The custom lenses built into the Valve Index Headset maximize field of view without sacrificing edge-to-edge clarity. High geometric stability allows you to look around the scene by moving your eyes (not just your head) with minimal shape distortion”. I tend to agree that these are the most advanced lenses in modern mass produced HMD, even though they have their own flaws. Main issue is the light spill when using a headset, you can see the bright light’s reflections in spots where they shouldn’t be.</p>

<h2 id="final-thoughts">Final thoughts</h2>

<p>As you can clearly see, it is not possible to replace a damaged screen or scratched lens all by yourself (even though for latter one you might try to take the lens out using a suction cup, however I don’t think that is a good idea, as lenses and screens are calibrated in the factory).</p>

<p><img src="https://www.thevrist.com/assets/images/index-end.jpg" alt="">
<em>Sometimes… I feel like a monster…</em></p>

<p>I am going to put the high-resolution images of the teardown and of the motherboard <a href="https://photos.app.goo.gl/dhuPVWTu6P5XWo4HA">here</a> so you can see and check all the details by yourself. If you have any corrections, notes, or questions, shoot me an <a href="mailto:zegarsilya@gmail.com">email</a> or PM me on <a href="https://twitter.com/GamerToTheEnd">Twitter</a>.</p>

           …</div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.thevrist.com/indexteardown">https://www.thevrist.com/indexteardown</a></em></p>]]>
            </description>
            <link>https://www.thevrist.com/indexteardown</link>
            <guid isPermaLink="false">hacker-news-small-sites-24153709</guid>
            <pubDate>Fri, 14 Aug 2020 04:57:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Save the USPS]]>
            </title>
            <description>
<![CDATA[
Score 174 | Comments 206 (<a href="https://news.ycombinator.com/item?id=24153311">thread link</a>) | @mooreds
<br/>
August 13, 2020 | https://2pml.com/2020/08/10/usps/ | <a href="https://web.archive.org/web/*/https://2pml.com/2020/08/10/usps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-12653">
	<!-- .entry-header -->

	<div>
		<p><img data-attachment-id="12682" data-permalink="https://2pml.com/2020/08/10/usps/cvbbjbi0/" data-orig-file="https://i0.wp.com/2pml.com/wp-content/uploads/2020/08/cVBbjbi0.jpg?fit=1600%2C1144&amp;ssl=1" data-orig-size="1600,1144" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="cVBbjbi0" data-image-description="" data-medium-file="https://i0.wp.com/2pml.com/wp-content/uploads/2020/08/cVBbjbi0.jpg?fit=300%2C215&amp;ssl=1" data-large-file="https://i0.wp.com/2pml.com/wp-content/uploads/2020/08/cVBbjbi0.jpg?fit=740%2C529&amp;ssl=1" loading="lazy" src="https://i0.wp.com/2pml.com/wp-content/uploads/2020/08/cVBbjbi0.jpg?resize=740%2C529&amp;ssl=1" alt="cVBbjbi0" width="740" height="529" srcset="https://i0.wp.com/2pml.com/wp-content/uploads/2020/08/cVBbjbi0.jpg?w=1600&amp;ssl=1 1600w, https://i0.wp.com/2pml.com/wp-content/uploads/2020/08/cVBbjbi0.jpg?resize=300%2C215&amp;ssl=1 300w, https://i0.wp.com/2pml.com/wp-content/uploads/2020/08/cVBbjbi0.jpg?resize=1024%2C732&amp;ssl=1 1024w, https://i0.wp.com/2pml.com/wp-content/uploads/2020/08/cVBbjbi0.jpg?resize=768%2C549&amp;ssl=1 768w, https://i0.wp.com/2pml.com/wp-content/uploads/2020/08/cVBbjbi0.jpg?resize=1536%2C1098&amp;ssl=1 1536w, https://i0.wp.com/2pml.com/wp-content/uploads/2020/08/cVBbjbi0.jpg?w=1480&amp;ssl=1 1480w" sizes="(max-width: 740px) 100vw, 740px" data-recalc-dims="1"></p>
<p>There are three types of infrastructure. One is visible: roads, dams and bridges. The second is invisible: broadband internet provisions and the entirety of our cellular infrastructure. Both are still vital in building our present. The third form of infrastructure is one being rebuilt in order to be repurposed for future use. I explained in <em>J-Curves and Agglomeration</em>:</p>
<blockquote><p>The U.S. Postal Service is a key component of the eCommerce economy. Packages are just 5% of its shipping volume but eCommerce accounts for nearly 30% of the agency’s revenue. Partnerships with vendors like Amazon (or providers like FedEx and UPS) provide a majority of its package volume but small businesses and direct-to-consumer brands rely on USPS’ pricing. Raising costs on retailers may lead to more attrition. […]</p>
<p>By raising prices to combat Amazon’s growing influence over the economy, disrupting the postal economy is no different than digging up paved roads before a period of heightened freight transit. [<a href="https://2pml.com/2020/05/18/agglomeration/">2PM, 1</a>]</p></blockquote>
<p>The U.S. Postal Service is all three. When an American institution is 250 years old, it may as well be the ground that we stand on. The service has contributed services and innovations that we don’t readily attribute to it. Consider its contribution to the middle class: the U.S. Postal Service is one the country’s biggest employers with nearly 330,000 career employees and an average salary of $50,000. They are building the future of eCommerce, a still-nascent industry.</p>
<p>Critics of the USPS will cite cost of labor as a reason for the service’s obsolescence. A common refrain is “Why couldn’t Amazon takeover the service?” Consider that in the fourth quarter of 2019, eCommerce was just 11.9% of all retail. Amazon constituted right under half of that volume. And without the postal service, Amazon would not exist. The market costs of shipment subsidized a number of Amazon’s operations, allowing it to capture market share.</p>
<h2>“The Ground We Stand On”</h2>
<p>The postal service began before the founding of the United States. Benjamin Franklin was fired from his role as postmaster due to his involvement with the American Revolution. Just one year later in 1775, the Continental Congress appointed Franklin the Postmaster General of the “United Colonies.” His tenure left a mail system that offered service between the then-colonies and Great Britain. By 1802, the first African-Americans to work for the Postal Service were enslaved mail carriers. Senator James Jackson of Georgia, Chairman of the Committee of the Senate on the Post Office Establishment, once wrote:</p>
<blockquote><p>… The most active and intelligent [slaves] are employed as post riders. By travelling from day to day, and hourly mixing with people […] they will acquire information. They will learn that a man’s rights do not depend on his color. They will, in time, become teachers to their brethren.</p></blockquote>
<p>Within two months of Senator Jackson’s proclamation, African-Americans would be banned from the postal service, lasting from 1802 to March 1865, just one month before the conclusion of the Civil War. This disbarment ended by congressional decree.</p>
<blockquote><p>No person, by reason of color, shall be disqualified from employment in carrying the mails. (13 Stat. 515)</p></blockquote>
<p>The next decades would see an unparalleled push for African-American financial stability. Nearly 800 would serve as postal employees prior to the 20th century. More than 200 African Americans are known to have served in the high rank of postmaster prior to the conclusion of Reconstruction and the Progressive Era (1863-1920). Of them, nearly 20 were women. The postal service has always been politicized.</p>
<p>Soon after, the U.S. Government expanded on the postal service’s role in democratizing America, both literally and figuratively. President Theodore “Teddy” Roosevelt expanded on this with the <em>Square Deal</em> in 1902, communicating a fairness policy in hiring and leadership. The result was momentous for many. Roosevelt stated:</p>
<blockquote>
<p>It is and should be my consistent policy in every State, where their numbers warranted it, to recognize colored men of good repute and standing in making appointments to office. […] I can not consent to take the position that the door of hope – the door of opportunity – is to be shut upon any man, no matter how worthy, purely upon the grounds of race or color. <a href="https://about.usps.com/who-we-are/postal-history/african-american-workers-20thc.htm#_edn2" name="_ednref2">[2]</a></p>
</blockquote>
<p>Today, 21% (or nearly 70,000) of the agency’s employees are African-American. However, the postal service was consequential beyond matters of social equity. By 1823, the U.S. Postal Service and the U.S. Government established 80,000 miles of “post roads” to help carriers navigate new rural areas. By 1860, these roads connected nearly 28,000 post offices. Today, the postal service maintains nearly 40,000 post offices, clearing 212 billion letters and mail to 144 million homes.</p>
<blockquote data-card-controls="1" data-card-align="center" data-card-theme="light" data-card-key="3101080c845e4679b6077080f81a573e">
<h4><a href="https://twitter.com/web/status/1292117127055519744">No Title</a></h4>
<p>Save the @USPS.There is no institution more critical to the next phases of our commerce economy.</p>
</blockquote>

<p>Today, the service is tasked with another generational shift: supporting online retail. The pandemic shifted the American consumer towards online retail, this while reducing the number of units shipped. As such, companies like UPS and FedEx have responded by hiking prices. In response to USPS’ distress, FedEx recently stated:</p>
<blockquote>
<p>The COVID-19 pandemic has negatively impacted mail volumes and mix resulting in a further decrease in revenues and negative financial impact for the USPS. Additionally, the USPS continues to experience budgetary uncertainty as well as increased political debate regarding potential privatization or restructuring of its operations.</p>
</blockquote>

<figure id="attachment_12683" aria-describedby="caption-attachment-12683"><img data-attachment-id="12683" data-permalink="https://2pml.com/2020/08/10/usps/sleikjxu/" data-orig-file="https://i2.wp.com/2pml.com/wp-content/uploads/2020/08/sLEikjXU-scaled.jpg?fit=2048%2C1259&amp;ssl=1" data-orig-size="2048,1259" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="sLEikjXU" data-image-description="" data-medium-file="https://i2.wp.com/2pml.com/wp-content/uploads/2020/08/sLEikjXU-scaled.jpg?fit=300%2C184&amp;ssl=1" data-large-file="https://i2.wp.com/2pml.com/wp-content/uploads/2020/08/sLEikjXU-scaled.jpg?fit=740%2C455&amp;ssl=1" loading="lazy" src="https://i2.wp.com/2pml.com/wp-content/uploads/2020/08/sLEikjXU-scaled.jpg?resize=740%2C455&amp;ssl=1" alt="sLEikjXU" width="740" height="455" srcset="https://i2.wp.com/2pml.com/wp-content/uploads/2020/08/sLEikjXU-scaled.jpg?w=2048&amp;ssl=1 2048w, https://i2.wp.com/2pml.com/wp-content/uploads/2020/08/sLEikjXU-scaled.jpg?resize=300%2C184&amp;ssl=1 300w, https://i2.wp.com/2pml.com/wp-content/uploads/2020/08/sLEikjXU-scaled.jpg?resize=1024%2C630&amp;ssl=1 1024w, https://i2.wp.com/2pml.com/wp-content/uploads/2020/08/sLEikjXU-scaled.jpg?resize=768%2C472&amp;ssl=1 768w, https://i2.wp.com/2pml.com/wp-content/uploads/2020/08/sLEikjXU-scaled.jpg?resize=1536%2C944&amp;ssl=1 1536w, https://i2.wp.com/2pml.com/wp-content/uploads/2020/08/sLEikjXU-scaled.jpg?w=1480&amp;ssl=1 1480w" sizes="(max-width: 740px) 100vw, 740px" data-recalc-dims="1"><figcaption id="caption-attachment-12683">The most popular government sites: June 18, 2020</figcaption></figure>
<p>Cost inflation is the most concerning obstacle ahead for digitally native retailers. Without the treatment that the United States’ oldest civilian service afforded Amazon in its infancy, it will be more difficult to build more businesses of Amazon’s scale. The economics were difficult enough as is; these added costs will only add pressure to pass along costs to consumers, many of whom are facing down one of the most economically vulnerable periods since 2008.We should consider the postal service an investment into our present and future and a monument to our past.</p>
<p>If our economy is to begin addressing the shortfalls caused by the overwhelming contraction in the traditional retail industry, it will need the support of the postal service. For eCommerce, their service is the industry’s last mile for thousands of direct-to-consumer small businesses. The postal service uniquely sits at the intersection of our physical roads and our digital infrastructure. There isn’t a direct substitute and we shouldn’t wait to find out the hard way. Save the USPS. We will need more companies like the the successful hundreds that were built on its 250 year old infrastructure. That includes Amazon.</p>
<p><strong>By Web Smith | Editor: Hilary Milnes | Art by Alex Remy | <a href="http://2pml.com/about">About 2PM</a></strong></p>
			</div><!-- .entry-content -->

	
	</article></div>]]>
            </description>
            <link>https://2pml.com/2020/08/10/usps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24153311</guid>
            <pubDate>Fri, 14 Aug 2020 04:18:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TikTok? Never]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24153225">thread link</a>) | @croom
<br/>
August 13, 2020 | https://kowabit.de/tiktok-2/ | <a href="https://web.archive.org/web/*/https://kowabit.de/tiktok-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-206408"><div><p><img width="720" height="250" src="https://kowabit.de/wp-content/uploads/2019/02/social.png" alt="" loading="lazy" srcset="https://kowabit.de/wp-content/uploads/2019/02/social.png 720w, https://kowabit.de/wp-content/uploads/2019/02/social-300x104.png 300w" sizes="(max-width: 720px) 100vw, 720px"></p><div><p>I’m sure you’ve read or heard it. Trump doesn’t like TikTok. He doesn’t like Tik-Tok because of the Chinese. Apparently, they use it for espionage. That’s why he wants the app banned in the United States. He also wants to ban the WeChat app. He has already issued a decree to do this. (<a href="https://www.tagesschau.de/ausland/trump-tik-tok-verfuegung-101.html" target="_blank" rel="noopener noreferrer">1</a>, <a href="https://www.heise.de/news/Analyst-Trump-Verfuegung-gegen-WeChat-schaedigt-iPhone-Geschaeft-4866876.html" target="_blank" rel="noopener noreferrer">2</a>)</p><p>TikTok is a video app. Entertainment on the go. WeChat is an app for communication and even with payment function. Mainly used in China.</p><p>I am over 40 years young. I had already heard TikTok. But I have never used it. I do not have the time for that. A few days ago, a visitor came to see my daughter. The girl had TikTok on her smartphone. She explained the app to me and I observed how it was used.</p><p>I had made a judgement very quickly. I have to test TikTok. Installed on my test phone and started. At the beginning you choose a few categories to get started. I chose humorous, learning and society. The consumption of videos should finally bring me some value. The good thing is that everyone of you can test the app that way. A registration beyond this level is not necessary for the consumption. Only those who want more would have to open an account.</p><p>I had planned to test TikTok for two hours. It should already be one movie length to make a judgement. If my daughter’s classmates use this app, she will sooner or later come across TikTok as well.</p><p>I have given myself the additional task of keeping a tally sheet. I wanted to know how many videos I watch in the two hours and how many videos I have to laugh or take something positive with me. It is not about casual laughter when there is a small funny scene, but hearty, beautiful laughter. Knowledge must trigger an eye-opening effect.</p><p>And so it began … and I was there for 24 minutes. After that I was completely exhausted.</p><p>I consumed 74 videos. I laughed once.</p><p>TikTok is continuous bombardment with short videos. The <a href="https://en.wikipedia.org/wiki/Katyusha_rocket_launcher" target="_blank" rel="noopener noreferrer">Stalin organ</a> of entertainment. You can really feel how big parts of your own brain explode and are useless afterwards.</p><p>TikTok is the cruelest app, the worst entertainment I have ever experienced. I have seen different actors performing the same sketch. I’ve seen German stars in bad performances. I’ve seen people acting as if they already have no brain at all. I’ve seen young people acting as if they were the children of adults who have no brains. It was a culture shock.</p><p>I can’t explain how bad, how underground, how primitive the content if TikTok is. Respect for every TikTok entertainer who produces trash every day and finds fans who give him presents for it. I don’t know if it should be the goal of life to produce trash, but 24 minutes showed me that nuclear waste is less toxic than the contents on TikTok.</p><p>TikTok does not exist in our household. The domains are blocked in the router. It is completely irresponsible to let underaged people use this app. At Apple and in the Google Play Store the app is listed from 12 years of age. And just like my daughter, however, the visitor was younger than 12 years. And according to her, many of her classmates use this app. Do parents buy their children smartphones to turn them into zombies on purpose? Terrifying. TikTok is proof that parents who don’t monitor their children’s online use must be severely punished.</p><p>TikTok should not be banned for fear of Chinese espionage. TikTok should be banned for being stupid on a massive scale. A realistic classification would be from the age of 18. Then it would be ensured that ex-minors can only go through this garbage dump of do-it-yourself entertainment when it can be assumed that they have developed a few brain cells.</p><p>If you have never tested TikTok, but there are people in the household who consume the contents, then inform yourself. Be prepared, however, that you will start to doubt the viability of some TikTokers and especially the users. And if not, I wish you a happy life, but please never go to a democratic election.</p><p>TikTok? Never!</p> <p><span>Tagged <a href="https://kowabit.de/tag/app/" rel="tag">App</a>, <a href="https://kowabit.de/tag/diy/" rel="tag">diy</a>, <a href="https://kowabit.de/tag/entertainment/" rel="tag">entertainment</a>, <a href="https://kowabit.de/tag/minors/" rel="tag">minors</a>, <a href="https://kowabit.de/tag/smartphone/" rel="tag">Smartphone</a>, <a href="https://kowabit.de/tag/tiktok/" rel="tag">tiktok</a></span></p></div></div></article></div>]]>
            </description>
            <link>https://kowabit.de/tiktok-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24153225</guid>
            <pubDate>Fri, 14 Aug 2020 04:06:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Review of Ethernet Sgmii (8B/10B Serdes) Concepts]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24152863">thread link</a>) | @mindchasers
<br/>
August 13, 2020 | https://mindchasers.com/dev/hw-sgmii-review | <a href="https://web.archive.org/web/*/https://mindchasers.com/dev/hw-sgmii-review">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
		

<h2>Overview</h2>
<p>
	This article reviews various SGMII (&amp; 1000BASE-SX) concepts that
	are integral to our <a href="https://mindchasers.com/privateisland">Private Island™</a> project
	and its current soft Verilog <a href="https://mindchasers.com/repos/cgit.cgi/privateisland/tree/source/mac.v" target="_blank">MAC layer</a>. We provide oscilloscope screen shots
	below from our Rohde &amp; Schwarz RTO to help illustrate the concepts.
</p>

<p>
	As shown in the block diagram below, Private Island utilizes a Lattice
	Semiconductor <a href="https://mindchasers.com/dev/pi-lattice-ecp5" target="_blank">ECP5UM</a> FPGA<sup><a href="#note1">1</a></sup> to
	interface SGMII Gigabit Ethernet PHYS and other SERDES 8B10B
	peripherals. Unlike a typical SoC, the FPGA is capable of asserting an
	external interrupt synchronous to specific packet transmit or receive
	events. The interrupt can also assert on specific octets / special
	codes within the Ethernet frame (i.e., end of packet). This interrupt
	flexibility is important for certain security functions and provides a
	reliable and predictable way to trigger our scope during debug of the
	SGMII / SERDES bus for both hardware and software debug.
</p>

<p>For the oscilloscope screen shots provided in this article, the
	FPGA is configured as a transparent bridge between an Ethernet switch
	and an embedded Linux node. Certain received Ethernet frames from the
	LAN are mirrored onto a TAP port with the simultaneous assertion of an
	interrupt line. Oscilloscope probes are applied to the interrupt line
	and the SGMII TAP port.</p>

<p>
	The tap port can be realized today with <a href="https://mindchasers.com/dev/darsena-hw-spec" target="_blank">Darsena</a> using a third Ethernet port provided by our
	<a href="https://mindchasers.com/dev/hw-gige-shield" target="_blank">Gigabit Ethernet
		shield</a> or using our <a href="https://mindchasers.com/dev/hw-high-speed-shield" target="_blank">SMA
		shield</a>. In the former case, a differential probe is placed across a
	pair of AC coupling caps. In the latter case, SMA to BNC cables are
	used to directly connect to the oscilloscope. Note that we're also in the process
	of developing a Gigabit optical transceiver shield to support
	1000BASE-SX.
</p>

<figure>
	<figcaption>Probing 8B10 SERDES on Private Island</figcaption>
	<img src="https://mindchasers.com/static/images/hw-sgmii-review/sgmii-phy-fpga.png" alt="SGMII Block Diagram">
</figure>

<svg>
	<line x1="0" y1="0" x2="2000" y2="0"></line>
</svg>

<h2>Brief overview of popular PHY Interfaces</h2>

<ul>

	<li>GMII, which is specified by IEEE 802.3-2015 defines a separate
		8-bit bus for transmit and receive data plus several signals to convey
		additional information between the MAC and PHY. GMII is based on MII,
		which is defined in Clause 22. In addition to the data buses and
		control signals, GMII requires two 125 MHz bit clocks: GTX_CLK and
		RX_CLK</li>
	<li>RGMII, which was defined by HP, Broadcom, and Marvell, reduces
		the pin count primarily by utilizing separate 4-bit buses for transmit
		and receive and both edges of the bit clocks (double data rate).</li>
	<li>SGMII, which was defined by Cisco, utilizes two pairs of
		SERDES / LVDS differential buses to carry transmit and receive data at
		1.25 Gbps. Differential clocks are defined but are optional and
		typically not used. Instead, the clocks are recovered from the data on
		the differential pairs. The data is encoded using an 8B/10B coding
		scheme, which is specified in clause 36 of 802.3-2015. The effective
		bit rate is 8 / 10 * 1.25 Gbps = 1.0 Gbps, as you would expect. The
		out-of-band information conveyed by the GMII control signals (TX_EN,
		TX_ER, RX_ER, and RX_DV) are replaced by special code groups (K
		values). This enables conveying information such as configuration,
		line state, and carrier events between the MAC and PHY.</li>
</ul>

<svg>
	<line x1="0" y1="0" x2="2000" y2="0"></line>
</svg>

<h2>SGMII Hardware Signaling</h2>

<p>
	The SGMII specification provides its own definition of LVDS, which is
	derived from <a href="http://standards.ieee.org/findstds/standard/1596.3-1996.html" target="_blank">IEEE 1596.3-1996</a>. However, the parameters provided
	in the SGMII specification are defined in the IEEE specification. For
	the purpose of SGMII hardware signaling, these two specifications are
	sufficient. PHY vendors often refer to this specification rather than
	providing their own numbers. Note that LVDS in general is an industry
	standard, and is defined in EIA/TIA-644A. A great resource for LVDS and
	differential signaling is the <a href="http://www.ti.com/litv/pdf/snla187" target="_blank">TI /
		National LVDS Owners Manual</a>.
</p>

<p>The figure below provides a very simple schematic of LVDS
	signaling. The concept being conveyed is that the transmitter drives a
	small current across a 100 ohm load in the receiver in one of two
	directions to produce either a positive or negative voltage across the
	receiver (Vod). This small current is superimposed over a common
	voltage (Vos), typically 1.2V. The industry standard LVDS specifies a
	3.5 mA driver current. The SGMII specification implies it is less since
	|Vod| max is 400 mV. In practice, most SGMII drivers (e.g., PHYs)
	support the configuration of multiple drive levels.</p>


<div>
	<div>
		<figure>
			<figcaption>Simplified LVDS Signaling</figcaption>
			<img src="https://mindchasers.com/static/images/hw-sgmii-review/sgmii_lvds_schematic.jpg" alt="Simplified LVDS Signaling">
		</figure>
	</div>

	<p>{% include "article-mid-ad.html"
		%}</p>
</div>


<p>The next figure shows an oscilloscope screen shot of an SGMII bus
	using a 4.5 GHz differential probe (RT-ZD40). The probe tips are placed
	on the two AC coupling caps of the differential SGMII bus. The yellow
	signal is the SGMII signal, and the blue square wave is generated from
	the scope's HW CDR math function. A probe meter function is shown in
	the lower right. This is a feature / function of the probe and shows
	that the common mode voltage (Vos) is near 1.2V</p>

<figure>
	<figcaption>SGMII LVDS</figcaption>
	<a href="#sgmii_lvds" data-rel="popup" data-position-to="window" data-transition="fade"><img src="https://mindchasers.com/static/images/hw-sgmii-review/sgmii_lvds.png" alt="SGMII LVDS"></a>
</figure>

<p>The next screen shot shows an SGMII eye diagram with 100 ms
	persistence enabled. As expected, the unit interval (UI) is
	approximately 800 ps. As can be seen in the upper right, the trigger is
	the built-in HW CDR.</p>

<figure>
	<figcaption>SGMII LVDS Eye Diagram</figcaption>
	<img src="https://mindchasers.com/static/images/hw-sgmii-review/sgmii_eye.png" alt="SGMII LVDS">
</figure>

<svg>
	<line x1="0" y1="0" x2="2000" y2="0"></line>
</svg>



<h2>A Look at SGMII Special Code Groups</h2>

<p>Clause 36 of 802.3-2015 defines certain 10-bit values as K values
	to convey non-data (out of band) information between the MAC and PHY.
	These K values take the place of the GMII control signals and special
	encodings of the GMII data bus. For Example, /K27.7/ defines a start of
	packet on the SGMII bus.</p>

<p>Referring to 802.3 Table 36-2 (valid special code-groups) and the
	screen shot below, we can see that K27.7 is defined as the bit sequence
	001001 0111 ([a..j] with 'a' transmitted first). This screen shot was
	taken using two single ended SMA cables (see figure below) and utilizes
	the 8B/10B protocol decode function equipped with our RTO. Note that
	that when the orange waveform is positive, the signal is a 1 and when
	the blue waveform is positive the signal is a 0.</p>

<p>The '+' after K27.7 indicates that the 10-bit waveform has a
	currently positive running disparity. Each code, both special and data,
	can either have a current positive or negative running disparity, and
	this indicates the difference of the total number of 1's and 0's on the
	wire. Refer to 802.3 clause 36.2 and Annex 36B for the details on
	running disparity and its rules.</p>

<figure>
	<figcaption>Special Code K.27</figcaption>
	<img src="https://mindchasers.com/static/images/hw-sgmii-review/scope-spd.png" alt="Special Code K.27">
</figure>


<figure>
	<figcaption>Probe 8B/10B SERDES with Diff Probe or SMA Cables</figcaption>
	<img src="https://mindchasers.com/static/images/hw-sgmii-review/probing_methods.png" alt="Probe 8B/10B with SMA Cables">
</figure>

<svg>
	<line x1="0" y1="0" x2="2000" y2="0"></line>
</svg>

<figure>
	<a href="https://www.efinixinc.com/promo/riscv/mc-riscv.html" target="_blank"><img src="https://mindchasers.com/static/images/efinix/riscv-banner-1200x200.png"></a>
</figure>

<svg>
	<line x1="0" y1="0" x2="2000" y2="0"></line>
</svg>


<h3>Ordered Sets</h3>

<p>802.3 defines ordered sets (Table 36-3) that consist of one or
	more code groups, each of which starts with a special code group (K
	value). For example, /I2/ specifies the IDLE2 line state and is encoded
	by /K28.5/D16.2/. This waveform continually repeats while the line
	remains in a powered up idle state, and is shown in the figure below.</p>

<ul>
	<li>K28.5-: 001111 1010
	</li><li>D16.2+: 100100 0101
</li></ul>

<figure>
	<figcaption>IDLE 2 Code Group Repeating</figcaption>
	<img src="https://mindchasers.com/static/images/hw-sgmii-review/scope-sgmii-hw-cdr-idle.png" alt="IDLE 2 Code Group">
</figure>

<svg>
	<line x1="0" y1="0" x2="2000" y2="0"></line>
</svg>


<h2>Data and Packets on an SGMII Bus</h2>

<p>The next figure shows a captured packet preamble on an SGMII bus.
	Per 802.3 35.2.3.2.1 and 36.2.4.14, An /S/ code (start of packet
	delimiter, K27.7) replaces the first octet of the preamble followed by
	the remaining PREAMBLE/SFD sequence: 0x55 0x55 0x55 0x55 0x55 0x55
	0xD5.</p>

<p>Note in the figure below that the special code groups (K) are
	shown in blue and the data code groups (D) are shown in yellow.</p>

<figure>
	<figcaption>SGMII Preamble</figcaption>
	<img src="https://mindchasers.com/static/images/hw-sgmii-review/scope-sgmii-sop.png" alt="SGMII Start of Packet">
</figure>



<p>
	Our last scope screen shot shows a complete packet captured. The FPGA's
	interrupt line is used to trigger the scope synchronously with the
	reception of the packet on the TAP port. The scope trace highlights the
	functionality of the 8B/10B protocol decode feature, showing the full
	decode results in a table and a search result box looking for the K27.7
	special code group, which appears on the SGMII bus 60.46 ns after the
	interrupt. <em>This certainly gives new meaning to the term packet
		inspection.</em>
</p>

<figure>
	<figcaption>SGMII Start of Packet Search</figcaption>
	<img src="https://mindchasers.com/static/images/hw-sgmii-review/scope-sgmii-search-sop.png" alt="SGMII Start of Packet Search">
</figure>

<svg>
	<line x1="0" y1="0" x2="2000" y2="0"></line>
</svg>

<h3>1000Base-SX</h3>

<p>It's important to note that SGMII is derived from 1000BASE-SX,
	which is defined in 802.3 Section 3. 1000BASE-SX is a specification for
	Ethernet over Fiber, and it utilizes 8B/10B coding for out of band
	signaling.</p>

<p>Note that we are currently developing an SFP Shield to support
	optical transceivers for 1000BASE-SX.</p>

<p>
	The figure below shows Darsnea in series with a low cost <a href="https://www.amazon.com/gp/product/B074WS6J3M/ref=as_li_ss_tl?ie=UTF8&amp;psc=1&amp;linkCode=ll1&amp;tag=mindchasers08-20&amp;linkId=1f9e1f051056ca92fe1a503b0eeae9dd&amp;language=en_US" target="_blank">Optical Media Adapter</a>. The great thing about this
	particular media adapter is that it has AC coupling caps on the PCB
	(even though they're not required). Therefore, we can use our diff
	probe to monitor both the transmit and receive data between the optical
	transceiver and the adapter's ASIC/SoC. If you're in the market for a
	low cost optical-to-electrical converter, this might be a good choice.
</p>

<figure>
	<figcaption>Probing a Low-Cost Optical Media Adapter</figcaption>
	<img src="https://mindchasers.com/static/images/hw-sgmii-review/probe_media_adapter.png" alt="Probing an Optical Media Adapter">
</figure>

<svg>
	<line x1="0" y1="0" x2="2000" y2="0"></line>
</svg>

<h2>Footnotes:</h2>
<ol>
	<li id="note1">Both Darsena and Private Island are being upgraded
		to support a newer generation FPGA.</li>
</ol>






	</div><p>
	Didn't find an answer to your question? Post your issue below or in our <span>new</span> <a href="https://mindchasers.com/forum" target="_blank">FORUM</a>, and we'll try our best to
	help you find a solution.
</p><p>
	And please note that we update our site daily with new content related to our open source
	approach to network security and system design. If you would like to be
	notified about these changes, then please follow us on <a href="https://twitter.com/Mindchasers" target="_blank">Twitter</a> and
	join our <a href="#mc-mail-list">mailing
		list</a>.
</p></div>]]>
            </description>
            <link>https://mindchasers.com/dev/hw-sgmii-review</link>
            <guid isPermaLink="false">hacker-news-small-sites-24152863</guid>
            <pubDate>Fri, 14 Aug 2020 03:14:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Temptation Bundling]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24152737">thread link</a>) | @rohitkaul
<br/>
August 13, 2020 | https://seekingnorth.in/beshort/ | <a href="https://web.archive.org/web/*/https://seekingnorth.in/beshort/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-elementor-type="wp-page" data-elementor-id="667" data-elementor-settings="[]">
			<div>
				<div>
							<header data-id="735e5a89" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="f711f2c" data-element_type="column">
			<div>
					<div>
				<div data-id="1f43e21d" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img src="https://secureservercdn.net/45.40.148.147/c7p.7a8.myftpupload.com/wp-content/uploads/2020/05/Logo_N2.png?time=1597375198" data-src="https://secureservercdn.net/45.40.148.147/c7p.7a8.myftpupload.com/wp-content/uploads/2020/05/Logo_N2.png?time=1597375198" title="Seeking North" alt="Seeking North Logo">											</p>
				</div>
				</div>
						</div>
			</div>
		</div>
				
				
				
						</div>
			</div>
		</header>
				<section data-id="5fe8386" data-element_type="section">
						<div>
				<div>
				<div data-id="5061d81" data-element_type="column">
			<div>
					<div>
				<div data-id="b90dc79" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2>BE Short: All the Behavior Science goodness that fits  on a single smartphone screen</h2>		</p>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="51d77d0" data-element_type="section">
						<div>
				<div>
				<div data-id="7289cb2" data-element_type="column">
			<div>
					<div>
				<div data-id="978a4f0" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>Join Seeking North’s mailing list below to get all Behavior Science goodness directly in your inbox</p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="3975f12" data-element_type="section">
						
		</section>
				<section data-id="222ff7a" data-element_type="section">
						<div>
				<div>
				<div data-id="3b5c0aa" data-element_type="column">
			<div>
					<div>
				<div data-id="bd1f823" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>Click on the image below to enlarge the image. Use ‘Left’ and ‘Right’ arrow keys or swipe left/right to move between images.</p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="b6af63e" data-element_type="section">
						
		</section>
				<section data-id="4bdd2ffc" data-element_type="section" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;}">
						<div>
				<div>
				<div data-id="3879d9a2" data-element_type="column">
			<div>
					<div>
				<div data-id="2d92342" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>All rights reserved. Views Personal. Copyright Seeking North 2020.</p><p>We use cookies to ensure that we give you the best experience on our website. If you continue to use this site we will assume that you are happy with it. For more details refer to the Privacy Policy.</p></div>
				</div>
				</div>
						</div>
			</div>
		</div>
				
						</div>
			</div>
		</section>
						</div>
			</div>
		</div></div>]]>
            </description>
            <link>https://seekingnorth.in/beshort/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24152737</guid>
            <pubDate>Fri, 14 Aug 2020 02:58:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Two Ruby apps, same code, but different output: what's going on?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24152544">thread link</a>) | @vaillancourtmax
<br/>
August 13, 2020 | https://maximevaillancourt.com/blog/debugging-ruby-casecmp-bug-using-gdb | <a href="https://web.archive.org/web/*/https://maximevaillancourt.com/blog/debugging-ruby-casecmp-bug-using-gdb">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
  <p><img src="https://images.unsplash.com/photo-1522776851755-3914469f0ca2?ixlib=rb-1.2.1&amp;ixid=eyJhcHBfaWQiOjEyMDd9&amp;auto=format&amp;fit=crop&amp;w=1000&amp;h=500&amp;q=80"></p>

<p>I noticed something odd today while working on two different Ruby codebases. This simple line of Ruby behaved differently in both applications:</p>

<div><div><pre><code><span>"luck"</span><span>.</span><span>casecmp</span><span>(</span><span>"L`auguste"</span><span>)</span>
</code></pre></div></div>

<p>Executing <code>"luck".casecmp("L`auguste")</code> in application A returned <code>-1</code>, while executing it in application B returned <code>1</code>.</p>

<p>â€œDid the alphabet change at some point and I didnâ€™t get the memo?â€�, I thought.</p>

<blockquote>
  <p><strong>Aside</strong></p>

  <p><a href="https://ruby-doc.org/core-2.7.1/String.html#method-i-casecmp"><code>String#casecmp</code></a> is a built-in Ruby method that returns <code>-1</code>, <code>0</code>, <code>1</code>, or <code>nil</code> depending on whether the object on which itâ€™s called is less than, equal to, or greater than the function argument, and it does so in case-insensitive fashion. Here are a few simple examples of how it behaves:</p>

  <div><div><pre><code><span>"aBcDeF"</span><span>.</span><span>casecmp</span><span>(</span><span>"abcde"</span><span>)</span>     <span>#=&gt; 1</span>
<span>"aBcDeF"</span><span>.</span><span>casecmp</span><span>(</span><span>"abcdef"</span><span>)</span>    <span>#=&gt; 0</span>
<span>"aBcDeF"</span><span>.</span><span>casecmp</span><span>(</span><span>"abcdefg"</span><span>)</span>   <span>#=&gt; -1</span>
<span>"abcdef"</span><span>.</span><span>casecmp</span><span>(</span><span>"ABCDEF"</span><span>)</span>    <span>#=&gt; 0</span>
</code></pre></div>  </div>
</blockquote>

<h2 id="looking-for-monkey-patches">Looking for monkey patches</h2>

<p>Seeing as one of the applications is built on top of Ruby of Rails and the other isnâ€™t, my first thought was that maybe there was a Rails and/or ActiveSupport patch on <code>String#casecmp</code> that would change the behavior of this line in one of the applications. However, I didnâ€™t find anything that pointed to this. I kept digging, hoping to maybe find a patch in the <em>other</em> application that could explain this difference in behavior. Again, I didnâ€™t find anything. ðŸ™ˆ</p>

<h2 id="different-rubies">Different Rubies</h2>

<p>Eventually, after exploring a bit more, I realized that both applications ran on different versions of Ruby: application A was on Ruby 2.6, while application B was using Ruby 2.7.</p>

<p>Running the same command on both versions of Ruby indeed gives us different results:</p>

<div><div><pre><code><span>$ </span>~/.rubies/ruby-2.6.6/bin/ruby <span>-e</span> <span>'puts "luck".casecmp("L`Auguste")'</span>
<span>-1</span>

<span>$ </span>~/.rubies/ruby-2.7.0/bin/ruby <span>-e</span> <span>'puts "luck".casecmp("L`Auguste")'</span>
1
</code></pre></div></div>

<p>Ah ha! Weâ€™re getting closer. While I could have called it a day here and simply updated application B to Ruby 2.7 to resolve the issue, I wanted to understand: what causes it?</p>

<h2 id="changelogs--bindingpry">Changelogs &amp; <code>binding.pry</code></h2>

<p>I then started to comb through Ruby changelogs, trying to find if anything changed between Ruby 2.6 and Ruby 2.7 for <code>String#casecmp</code>, or anything somehow related to string comparison. I didnâ€™t find anything.</p>

<p>Of course, it would be nice to debug this using <code>binding.pry</code> or other similar Ruby-level debugging tools by stepping into the <code>String#casecmp</code> call to see whatâ€™s going on inside. However, this doesnâ€™t get us very far, as trying to use Rubyâ€™s <code>Tracer</code> or <code>binding.pry</code> doesnâ€™t really help.</p>

<p>Running this:</p>

<div><div><pre><code><span>$ </span>ruby <span>-r</span> tracer <span>-e</span> <span>'"luck".casecmp("L`Auguste")'</span>
</code></pre></div></div>

<p>â€¦ returns this output:</p>

<div><div><pre><code>#0:-e:1::-: "luck".casecmp("L`Auguste")
</code></pre></div></div>

<p>â€¦ and not much else. Thatâ€™s because <code>String#casecmp</code> is implemented in C, directly inside MRIâ€™s <a href="https://github.com/ruby/ruby/blob/master/string.c"><code>string.c</code></a>, so thereâ€™s no actual Ruby code underneath <code>String#casecmp</code> that we can step into using Ruby-level debugging tools.</p>

<p>Here comes the GDB part: because weâ€™re essentially dealing with C code at this point, we can use GDB to understand what happens inside the call to <code>String#casecmp</code>. So with that, I fired up GDB for the first time in years (I typically work with Ruby, so GDB is not something I commonly use).</p>

<h2 id="identifying-the-root-cause-using-gdb">Identifying the root cause using GDB</h2>

<p>Letâ€™s see how to use GDB to understand why both Ruby 2.6 and Ruby 2.7 behave differently with the same input to <code>String#casecmp</code>.</p>

<p>I first prepared a simple Ruby file containing the source that replicates the issue:</p>

<div><div><pre><code><span># ~/casecmp.rb</span>
<span>puts</span> <span>"luck"</span><span>.</span><span>casecmp</span><span>(</span><span>"L`Auguste"</span><span>)</span>
</code></pre></div></div>

<p>Notice that the second character in the input to <code>casecmp</code> is a backtick (<code>`</code>), which has ASCII code 96. This is relevant for paragraphs below.</p>

<h3 id="in-ruby-270">In Ruby 2.7.0</h3>

<p>Letâ€™s start by firing up GDB with a self-compiled version of Ruby 2.7.0:</p>

<div><div><pre><code><span>$ </span><span>sudo </span>gdb /Users/maximevaillancourt/.rubies/ruby-2.7.0/bin/ruby
Reading symbols from /Users/maximevaillancourt/.rubies/ruby-2.7.0/bin/ruby...
</code></pre></div></div>

<p>Then, we add a breakpoint on the <code>str_casecmp</code> function so execution pauses once we reach it:</p>

<div><div><pre><code>(gdb) break str_casecmp
Breakpoint 1 at 0x1001fa766: file string.c, line 3371.
</code></pre></div></div>

<p>Perfect. Weâ€™re now ready to run the <code>casecmp.rb</code> Ruby script from above.</p>

<div><div><pre><code>(gdb) run casecmp.rb
Starting program: /Users/maximevaillancourt/.rubies/ruby-2.7.0/bin/ruby casecmp.rb
</code></pre></div></div>

<p>We eventually hit the breakpoint we just set:</p>

<div><div><pre><code>Thread 2 hit Breakpoint 1, str_casecmp (str1=4329352680, str2=4329352640) at string.c:3371
3371	    enc = rb_enc_compatible(str1, str2);
</code></pre></div></div>

<blockquote>
  <p><strong>Aside</strong></p>

  <p>Internally, <a href="https://github.com/ruby/ruby/blob/4318aba9c94ebff53e4168886e1a35a24013924f/string.c#L3467-L3468"><code>String#str_casecmp</code></a> is quite simple: it iterates over each character in both inputs by index starting from the first character, converting both characters to the same case so that the function behaves in a case-insensitive way, and returns early if the two currently considered characters from each input are different. In doing so, it determines which character is â€œbiggerâ€� than the other using the character code (an <a href="http://www.asciitable.com/">ASCII code table</a> is a useful asset to have nearby for the rest of this blog post).</p>
</blockquote>

<p>In Ruby 2.7.0, notice that the case conversion <a href="https://github.com/ruby/ruby/blob/e9e4f8430a62f56a4e62dd728f4498ee4c300c12/string.c#L3381-L3382">converts both inputs to lowercase using <code>TOLOWER</code></a>:</p>

<div><div><pre><code><span>while</span> <span>(</span><span>p1</span> <span>&lt;</span> <span>p1end</span> <span>&amp;&amp;</span> <span>p2</span> <span>&lt;</span> <span>p2end</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>*</span><span>p1</span> <span>!=</span> <span>*</span><span>p2</span><span>)</span> <span>{</span>
    <span>unsigned</span> <span>int</span> <span>c1</span> <span>=</span> <span>TOLOWER</span><span>(</span><span>*</span><span>p1</span> <span>&amp;</span> <span>0xff</span><span>);</span>
    <span>unsigned</span> <span>int</span> <span>c2</span> <span>=</span> <span>TOLOWER</span><span>(</span><span>*</span><span>p2</span> <span>&amp;</span> <span>0xff</span><span>);</span>
    <span>if</span> <span>(</span><span>c1</span> <span>!=</span> <span>c2</span><span>)</span>
      <span>return</span> <span>INT2FIX</span><span>(</span><span>c1</span> <span>&lt;</span> <span>c2</span> <span>?</span> <span>-</span><span>1</span> <span>:</span> <span>1</span><span>);</span>
  <span>}</span>
  <span>p1</span><span>++</span><span>;</span>
  <span>p2</span><span>++</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>After navigating in <code>str_casecmp</code> using <code>next</code> a few times, we enter the loop and arrive at a point where we can print <code>c1</code> and <code>c2</code>, which are the codes for the characters at the current index for both inputs:</p>

<div><div><pre><code>3382	                unsigned int c2 = TOLOWER(*p2 &amp; 0xff);
(gdb) print c1
$11 = 108
(gdb) next
3383	                if (c1 != c2)
(gdb) print c2
$12 = 108
</code></pre></div></div>

<p>Hereâ€™s a visual representation of the buffers:</p>

<div><div><pre><code>c1
 â†“
108  ?   ?   ?
 l   u   c   k

108  ?   ?   ?   ?   ?   ?   ?   ?
 l   `   a   u   g   u   s   t   e
 â†‘
c2
</code></pre></div></div>

<p>108 is the decimal ASCII character code representation for the first letter of both inputs: <code>l</code> (lowercase â€œLâ€�), so the loop continues to the next iteration because <code>c1</code> and <code>c2</code> are the same.</p>

<p>On the second iteration of the loop (on the second character of both inputs), we get the following results:</p>

<div><div><pre><code>3382	                unsigned int c2 = TOLOWER(*p2 &amp; 0xff);
(gdb) print c1
$14 = 117
(gdb) next
3383	                if (c1 != c2)
(gdb) print c2
$16 = 96
</code></pre></div></div>

<p>Hereâ€™s a visual representation of the buffers:</p>

<div><div><pre><code>    c1
     â†“
108 117  ?   ?
 l   u   c   k

108  96  ?   ?   ?   ?   ?   ?   ?
 l   `   a   u   g   u   s   t   e
     â†‘
     c2
</code></pre></div></div>

<p><code>c1</code> contains <code>117</code>, which is the decimal ASCII character code representation for <code>u</code>, while <code>96</code> (in <code>c2</code>) is the character code for a backtick (<code>`</code>). We then enter the <code>if (c1 != c2)</code> conditional, and the return value is <code>1</code> because <code>c1 &gt; c2</code> (<code>117 &gt; 96</code>).</p>

<p>Okay. So far so good. This lines up with the initial observation of the issue. How are things different in Ruby 2.6.6?</p>

<h3 id="in-ruby-266">In Ruby 2.6.6</h3>

<p>We do almost the same setup as above (same one-line Ruby script to replicate the issue, same breakpoint on <code>str_casecmp</code>), but we fire up GDB with Ruby 2.6.6:</p>

<div><div><pre><code><span>$ </span><span>sudo </span>gdb /Users/maximevaillancourt/.rubies/ruby-2.6.6/bin/ruby
Reading symbols from /Users/maximevaillancourt/.rubies/ruby-2.6.6/bin/ruby...

<span>(</span>gdb<span>)</span> <span>break </span>str_casecmp
...

<span>(</span>gdb<span>)</span> run casecmp.rb
Starting program: /Users/maximevaillancourt/.rubies/ruby-2.6.6/bin/ruby casecmp.rb

Thread 2 hit Breakpoint 1, str_casecmp ...
</code></pre></div></div>

<p>Letâ€™s look at the loop we presented above in Ruby 2.7.0, but <a href="https://github.com/ruby/ruby/blob/a9a48e6a741f048766a2a287592098c4f6c7b7c7/string.c#L3413-L3414">in Ruby 2.6.6</a> this time:</p>

<div><div><pre><code><span>while</span> <span>(</span><span>p1</span> <span>&lt;</span> <span>p1end</span> <span>&amp;&amp;</span> <span>p2</span> <span>&lt;</span> <span>p2end</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>*</span><span>p1</span> <span>!=</span> <span>*</span><span>p2</span><span>)</span> <span>{</span>
    <span>unsigned</span> <span>int</span> <span>c1</span> <span>=</span> <span>TOUPPER</span><span>(</span><span>*</span><span>p1</span> <span>&amp;</span> <span>0xff</span><span>);</span>
    <span>unsigned</span> <span>int</span> <span>c2</span> <span>=</span> <span>TOUPPER</span><span>(</span><span>*</span><span>p2</span> <span>&amp;</span> <span>0xff</span><span>);</span>
    <span>if</span> <span>(</span><span>c1</span> <span>!=</span> <span>c2</span><span>)</span>
      <span>return</span> <span>INT2FIX</span><span>(</span><span>c1</span> <span>&lt;</span> <span>c2</span> <span>?</span> <span>-</span><span>1</span> <span>:</span> <span>1</span><span>);</span>
  <span>}</span>
  <span>p1</span><span>++</span><span>;</span>
  <span>p2</span><span>++</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>Notice that instead of using <code>TOLOWER</code> as in Ruby 2.7.0, Ruby 2.6.6 uses <code>TOUPPER</code>. Interesting.</p>

<p>Letâ€™s fast-forward to the part where we get to <code>c1</code> and <code>c2</code> for the second character in the input:</p>

<div><div><pre><code>3414			unsigned int c2 = TOUPPER(*p2 &amp; 0xff);
(gdb) next
3415	                if (c1 != c2)
(gdb) print c1
$5 = 85
(gdb) print c2
$6 = 96
</code></pre></div></div>

<p>Hereâ€™s a visual representation of the buffers:</p>

<div><div><pre><code>     c1
     â†“
108  85  ?   ?
 L   U   C   K

108  96  ?   ?   ?   ?   ?   ?   ?
 L   `   A   U   G   U   S   T   E
     â†‘
     c2
</code></pre></div></div>

<p><code>c1</code> is <code>85</code>, which is the character code for <code>U</code>, and <code>c2</code> is <code>96</code> (just like in Ruby 2.7.0), which is the character code for a backtick (<code>`</code>).</p>

<p>This time though, the comparison result is different, because <code>c1 &lt; c2</code> (<code>85 &lt; 96</code>), so <code>str_casecmp</code> returns <code>-1</code>.</p>

<p>There it is: because Ruby 2.6 uses <code>TOUPPER</code> and Ruby 2.7 uses <code>TOLOWER</code> before comparing the inputs, and because one of the characters to compare is a backtick (<code>`</code>, which canâ€™t be converted to uppercase or lowercase in any way), the other characterâ€™s code â€œmovesâ€� differently around the â€œfixedâ€� backtick character code, affecting the result of the <code>String#casecmp</code> function.</p>

<hr>

<p>To summarize, the root cause of the issue is that <code>String#casecmp</code> was updated in Ruby 2.7 to <strong>lowercase</strong> the two inputs before comparing them, while Ruby 2.6 used to <strong>uppercase</strong> the two inputs before comparing them. <a href="https://github.com/ruby/ruby/commit/082424ef58116db9663a754157d6c441d60fd101#diff-7a2f2c7dfe0bf61d38272aeaf68ac768">This is the commit where this change was introduced.</a></p>

<p>Fun debugging session. :)</p>

<p><em>Found a typo? Think I could clarify something? Reach out on Twitter (<a href="https://twitter.com/vaillancourtmax">@vaillancourtmax</a>).</em></p>

</article></div>]]>
            </description>
            <link>https://maximevaillancourt.com/blog/debugging-ruby-casecmp-bug-using-gdb</link>
            <guid isPermaLink="false">hacker-news-small-sites-24152544</guid>
            <pubDate>Fri, 14 Aug 2020 02:32:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My electricity bill was wrong for two years]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24152325">thread link</a>) | @PlanetLotus
<br/>
August 13, 2020 | https://planetlotus.github.io/2020/08/13/meter-mixup.html | <a href="https://web.archive.org/web/*/https://planetlotus.github.io/2020/08/13/meter-mixup.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

  

  <article>
    <p>I’ve lived in my house for just under two years. Last summer, I noticed something strange. Our electricity bill increased by 40-90% depending on the month. This year, I finally tracked it down and discovered our meter was being mixed up with our neighbor’s. Here’s how I tracked this down and what you can do to prevent it from happening to you.</p>



<p>I have an amateur interest in electricity, conserving energy, and energy efficiency in general. I care about my carbon footprint, as well as my bill, and I’m passionate about innovation in this space. I’ve made it a habit to have a good idea of how much electricity different appliances use and, in general, I try to be aware of where my electricity is going. Years ago, I bought a simple <a href="https://en.wikipedia.org/wiki/Kill_A_Watt">Kill A Watt</a> to quickly get an idea of how much power things use.</p>



<p>The first time I noticed a problem was when we got our July bill in the summer of 2019. It was about 40% higher than usual. My grandparents stayed with us (in their motorhome) for a week that month, and their motorhome has a big air conditioner, so I chalked it up to that, though that still seemed high.</p>

<p>A couple months passed and the problem got worse. It went from 40% higher than normal, to a peak of about 90%. I couldn’t explain that. We don’t have central air conditioning. Most of our heavy appliances use natural gas. We did use a portable air conditioner briefly, but never for more than a couple hours a night. I also measured the power usage of the A/C and thought, there’s no way this adds up. This confusion continued until we got our October bill and it returned to normal, and I forgot about it for another year.</p>



<p>And…it came back! I first noticed this year in June when the bill jumped about 20%. I figure it’s reasonable for the bill to fluctuate a little, but not by that much. Plus, what made even less sense is that we used supplemental electric heating this winter, so if anything, our bill should’ve been higher in the winter! Again, no central air conditioning, so another unexplained bill. I tracked power usage on everything I could think of, to make sure I hadn’t missed something. For awhile, my big suspect was our fridge. It’s 18 years old, so I figured, maybe there’s a problem with it and it uses more power when it should, especially when the ambient temperature is higher. I cleaned the coils and played around with the fridge settings, then waited for our next bill. It got worse.</p>

<p>This year, I noticed our power company has a cool interface online where you can see your daily power usage. Very handy. I noticed that, in non-summer months, it was very consistent, ranging between 9-12 kWh per day. Then, in the summer months, it just goes all over the place. Sometimes it was 8, other days it went as high as 24! This seemed loosely correlated with the temperature but I just couldn’t explain that, due to a lack of central cooling in our house. I finally decided to call the power company at this point. Naturally, they did not take me too seriously, and were fairly insistent that it was my air conditioning (that I didn’t have). I was told to hire an electrician to investigate.</p>

<p>Then it got weirder. In late July, I noticed that in recent weeks, our daily power usage (according to the power company) dipped as low as 1 kWh per day! That’s just not possible, I thought. My electronics, combined, should use more than that per day, not even counting heavier users like the fridge. The power usage still fluctuated quite a bit, but there were several days where the power usage was as low as 1-3 kWh. I called the power company again and, no surprise, they took this much more seriously and agreed that wasn’t possible. I insisted that the peaks in usage didn’t make sense either, that I couldn’t explain those, but no luck there…they were really only interested in the low days and said they were opening an investigation that could take “at least a few weeks” to finish.</p>



<p>One night, I finally put it together. I wondered if my bill was mixed up with my neighbor’s. My neighbor had moved out in July, and that’s about when the daily power usage fell to almost nothing. I also happened to know that they have central air conditioning. I looked at my bill and noticed it actually has the meter number on it, very helpful! I looked at my meter and the number on the bill wasn’t even remotely close. It wasn’t off-by-one. The format looked consistent, but the values looked randomized. I was wondering whether I was even looking at the right number. So, the next morning, I took a look at my neighbor’s (vacant) house’s meter. Sure enough, it exactly matched what was on my bill.</p>

<p>A few frustrating phone calls later (not important), and the issue is fixed. We got the charges corrected and are enjoying a large credit on our account that ought to last us about 6 months (after having lived here only 2 years).</p>

<p>In any future house I live in, I will be sure to check that my bill’s meter number matches what’s on the property. I highly recommend everyone do the same, because I get the impression this is fairly common. A quick search online and I found about half a dozen news articles about this happening, often more egregious cases than my own. Most of us may not notice a mixup, either because the usage is fairly consistent or we just don’t know how much power we use. Thankfully, you should be able to check the accuracy of your bill in about 5 minutes if your meter is easily accessible. Simply look for the meter number on your bill (hopefully all power companies give this info), and then look physically at the meter for a sticker from your power company, and see if the numbers match.</p>

  </article>

  




</div>

      </div>
    </div></div>]]>
            </description>
            <link>https://planetlotus.github.io/2020/08/13/meter-mixup.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24152325</guid>
            <pubDate>Fri, 14 Aug 2020 01:57:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Machine Learning of Sets]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24152216">thread link</a>) | @akosiorek
<br/>
August 13, 2020 | http://akosiorek.github.io/ml/2020/08/12/machine_learning_of_sets.html | <a href="https://web.archive.org/web/*/http://akosiorek.github.io/ml/2020/08/12/machine_learning_of_sets.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>In machine learning, we typically work with input pairs (x, y), and we try to figure out how x and y depend on each other.
To do so, we gather many such pairs and hope that the dependence will reveal itself if a) we have enough data, b) our model is expressive enough to approximate this dependency, and c) we get the hyperparameters right.
In the simplest case, both x and y are just scalar values (or vectors \(\mathbf{x}, \mathbf{y}\)); for example, given some measurements of a plant’s shape, we might want to predict its species. The measurements here are real vectors \(\mathbf{x} \in \mathcal{X}\), where the input space \(\mathcal{X} = \mathbb{R}^d\) is usually Euclidean, and the species is a label \(\mathbf{y} \in \mathcal{Y}\) (usually an integer or a one-hot vector), but it is common for \(\mathbf{x}\) and \(\mathbf{y}\) to have more structure.</p>

<p>One of the main assumptions we rely on is that the pairs of (x, y) points are <a href="https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables">independent and identically distributed (i.i.d.) random variables</a>.
Let us unpack this a bit, starting from the end,</p>

<ul>
  <li><code>random variable</code>: there exists some stochastic generative process from which the variables were randomly sampled,</li>
  <li><code>identically</code>: all samples come from the same probability distribution,</li>
  <li><code>independent</code>: the generative process has no memory of generated samples, and hence any generated sample does not change the distribution over future generated samples.</li>
</ul>

<p>Any structure in \(\mathbf{x}, \mathbf{y}\), or both introduces constraints, and a successful application of an algorithm to a particular problem does heavily depend on whether or not this algorithm takes the relevant constraints into account.
A common constraint in image-related problems is translation equivariance<sup id="fnref:cnnequiv" role="doc-noteref"><a href="#fn:cnnequiv">1</a></sup>—the output of the algorithm should shift with any shifts applied to the image (you can read more about equvariances in <a href="https://fabianfuchsml.github.io/equivariance1of2/">this excellent blog post</a>).
In natural language-related problems, a typical constraint is causality: a token at position t can depend on any previous tokens at position 1:t-1, but it cannot depend on any future tokens<sup id="fnref:languecausality" role="doc-noteref"><a href="#fn:languecausality">2</a></sup>.</p>

<p>In the above examples, the dependencies between points (e.g., autoregressive dependence in NLP) are clear from the context.
However, if a data point is not a vector, matrix, or a sequence of vectors, but it is a <strong>set of vectors</strong>, these dependencies become less clear.
In particular, elements in an input set resemble elements in a dataset (i.e., lack of order), but the critical difference is that they are <strong>not independent</strong>, therefore breaking the i.i.d. assumption.
Accounting for this specific structure in inputs or outputs of an ML model leads to a family of set learning problems, which have recently gained considerable attention in the machine learning community.
I thought it would be useful to delve into the machine learning of sets.
In the following, we will consider set-to-vector, vector-to-set, and set-to-set problems and provide implementations of simple algorithms in <a href="https://github.com/google/jax">JAX</a> and <a href="https://github.com/deepmind/dm-haiku">haiku</a>.</p>

<p>First some imports:</p>

<div><div><pre><code>import jax
import jax.numpy as jnp
import haiku as hk
</code></pre></div></div>


<p>Before we start, it is useful to introduce some notation.
Let \(\mathbf{x} \in \mathbb{R}^d\) be an input vector, \(\mathbf{y} \in \mathbb{R}^k\) the output vector, and let \(X = \{\mathbf{x}_i\}_{i=1}^M\) and \(Y = \{\mathbf{y}_j\}_{j=1}^N\) be sets of \(M\) and \(N\) elements, respectively.
Note that, until now, \(y\) or \(\mathbf{y}\) were simply labels.
From now on, however, \(\mathbf{x}\) and \(\mathbf{y}\) can live in the same space, and simply be elements of different sets.
I will also use \(\mathcal{L}(X, Y)\) as a loss function operating on two sets, and \(l(\mathbf{x}, \mathbf{y})\) will be a loss function for pairs of elements.</p>


<p>This is perhaps the simplest set-learning problem since it only requires permutation invariance.
A function \(f\) is invariant to permutations \(\pi\) if \(\forall \pi\): \(f(X) = f(\pi X)\).
Permutation invariance has always been known in machine learning, as loss functions we use almost never<sup id="fnref:acn" role="doc-noteref"><a href="#fn:acn">3</a></sup> depend on the ordering of elements in our datasets or minibatches.
This is not for the lack of order: to create a minibatch, we stack multiple data elements in an array; this pairs every element in the minibatch with its minibatch index, therefore implicitly creating an order.
Loss functions tend to discard information about the order, usually by taking the mean over data examples.
We can create permutation-invariant functions by following a similar logic.</p>

<p>Examples in a minibatch are processed independently (which reflects their i.i.d. nature), but if each entry in the minibatch contains more than just a single data point (many pixels in an image, points in a point cloud, tokens in a language sentence), then flattening these points into a vector and feeding it into an MLP or a CNN results in different parameters being used for processing different data points, and hence order is used implicitly; feeding the points into an RNN reuses parameters, but introduces an explicit dependence on the order.</p>

<p>A straightforward solution to this issue is to treat points in a single example in the same way we treat examples in the minibatch: treat them independently.
This approach, followed by a permutation-invariant pooling operation such as max or mean pooling, is explored in <a href="https://arxiv.org/abs/1703.06114">Zaheer et al., “Deep Sets”, NeurIPS 2017</a> and is proven to be a universal set-function approximator<sup id="fnref:deepsetdim" role="doc-noteref"><a href="#fn:deepsetdim">4</a></sup>.</p>

<div><div><pre><code>class DeepSet(hk.Module):

  def __init__(self, encoder, decoder):
    super().__init__()
    self._encoder = encoder
    self._decoder = decoder
    
  def __call__(self, x):
    """Compute the DeepSet embedding.

    Args:
      x: Tensor of shape [batch_size, n_elems, n_dim].
    """
    return self._decoder(self._encoder(x).mean(1))
</code></pre></div></div>

<p>While newer approaches with better empirical performance exist, they all draw from the Deep Sets framework<sup id="fnref:setembeddings" role="doc-noteref"><a href="#fn:setembeddings">5</a></sup>.
Another factor contributing to the fact that the set-to-vector problem is quite easy is that pooling operations naturally work with variable-sized sets–there is nothing extra we have to do to handle sets of variable cardinality.
This is not the case in the following two problems, where we have to take the set size into account explicitly.</p>


<p>In vector-to-set, the task is to generate a set of real vectors from some (usually vector-valued) conditioning.</p>

<p>The majority of approaches out there focus on generating ordered sequences instead of unordered sets, and usually of fixed or at least known size.
This allows using MLPs<sup id="fnref:setae" role="doc-noteref"><a href="#fn:setae">6</a></sup> and RNNs<sup id="fnref:order_matters" role="doc-noteref"><a href="#fn:order_matters">7</a></sup> to predict fixed- and variable-length sets, respectively, but at the price of having to learn permutation-equivariance from data.
Learning permutation-equivariance can be induced by data augmentation. It is easy to generate different permutations, but usually comes at a decreased performance and/or longer training times compared to truly permutation-equivariant methods<sup id="fnref:data_augmentation" role="doc-noteref"><a href="#fn:data_augmentation">8</a></sup>.</p>

<div><div><pre><code>  def set_mlp(conditioning, decoder, n_elements):
    """Predicts a set.

    Args:
      conditioning: tensor of shape [batch_size, n_dim].
      decoder: callable, e.g. an MLP.
      n_elements: int.
    """
    z = decoder(conditioning)
    batch_size = conditioning.shape[0]
    # all we can do here is reshape!
    return z.reshape(batch_size, n_elements, -1)

  def set_rnn(conditioning, state, rnn, n_elements):
    """Predicts a set.

    Args:
      conditioning: tensor of shape [batch_size, n_dim].
      state: initial state for the rnn.
      rnn: rnn core.
      n_elements: int.
    """
    zs = []
    for _ in range(n_elements):
      z, state = rnn(conditioning, state)
      zs.append(z[:, None])  # add an axis

    return jnp.concatenate(zs, 1)
</code></pre></div></div>

<h4 id="permutation-invariant-loss-functions">Permutation-Invariant Loss Functions</h4>
<p>Learning to generate sets based on some conditioning typically requires scoring that set against the conditioning.
If we have ground-truth sets at our disposal, we can compare the generated sets against the ground-truth ones for the same conditioning.
This can take the form of supervised learning (think of detecting objects in an image, where we need to generate a set of bounding boxes) or unsupervised learning (autoencoding point-clouds, say).
Since we generally have no guarantee that the generated sets will obey any ordering (why should they?), we have to apply losses invariant to that ordering.
We have two options here:</p>

<ul>
  <li>We can find an optimal matching between two sets<sup id="fnref:bipartite_matching" role="doc-noteref"><a href="#fn:bipartite_matching">9</a></sup>, which comes down to finding a permutation \(\pi\) of one of the sets that minimizes the computed loss, that is: \(\pi^\star = \arg \min_\pi \mathcal{L}( \pi X, Y)\), with \(\mathcal{L}( \pi X, Y) = \sum_i l(\mathbf{x}_{\pi(i)}, \mathbf{y}_i)\). This can be done exactly using the cubic <a href="https://en.wikipedia.org/wiki/Hungarian_algorithm">Hungarian matching</a> algorithm, or approximately using e.g. <a href="https://arxiv.org/abs/1106.1925">optimal-transport</a>- or <a href="https://web.stanford.edu/~bayati/papers/bpmwmIT.pdf">message-passing</a>-based algorithms.</li>
  <li>Instead of finding a matching, we can find a lower bound on what the matched loss would be. A popular choice here is the Chamfer loss<sup id="fnref:chamfer" role="doc-noteref"><a href="#fn:chamfer">10</a></sup>, which computes \(\sum_{x \in X} \min_{y \in Y} l(x, y) + \sum_{y \in Y} \min_{x \in X} l(x, y)\). For every element in one set, it finds the element in the other set that results in the lowest pairwise loss. This loss does not work for multisets as elements can be repeated.</li>
</ul>

<p>If we do not have ground-truth for each conditioning (we have just sets), or if we have many possible sets for each conditioning (e.g., a group of possible sets for one of a few labels), we can instead learn by matching distributions e.g., in the GAN setting.
If we take this approach, we have two problems, really: that of vector-to-set for the generator and set-to-vector for the discriminator. 
Fortunately, we know how to solve the set-to-vector problem with a permutation-invariant neural net, and shortly I am going to describe some permutation-equivariant methods for generation.
This is precisely what we recently explored in <a href="https://oolworkshop.github.io/program/ool_32.html">Stelzner et al., “Generative Adversarial Set Transformers”, ICML 2020 Object-Oriented Learning Workshop</a>.</p>

<p>Coincidentally, sometimes we have to deal with a set of latent variables inside a model. For example in …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://akosiorek.github.io/ml/2020/08/12/machine_learning_of_sets.html">http://akosiorek.github.io/ml/2020/08/12/machine_learning_of_sets.html</a></em></p>]]>
            </description>
            <link>http://akosiorek.github.io/ml/2020/08/12/machine_learning_of_sets.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24152216</guid>
            <pubDate>Fri, 14 Aug 2020 01:40:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google Won't Stop]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24152157">thread link</a>) | @bccdee
<br/>
August 13, 2020 | https://www.blackcap.site/posts/google_wont_stop/ | <a href="https://web.archive.org/web/*/https://www.blackcap.site/posts/google_wont_stop/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <p>So I read <a href="https://drewdevault.com/2020/08/13/Web-browsers-need-to-stop.html">this blog post</a>, and it’s bothering me.
It’s pretty short, so I recommend you read it before continuing with this post.</p>
<p>Done? Alright.</p>

<p><img src="https://www.blackcap.site/img/divider.svg" width="300">
</p>
<p>I think that article expresses a generally good opinion in the worst way possible.</p>
<p>It’s true that if Chrome becomes the only browser on the market, it’d lead to a very unhealthy monopoly situation.
There’s an analogy to be drawn with Microsoft’s <a href="https://en.wikipedia.org/wiki/Embrace,_extend,_and_extinguish">EEE strategy</a>, except that instead of extending open software with proprietary APIs, Google is extending it with <em>so many</em> APIs that no one can ever build anything compatible.</p>
<p>For the web to remain an open and innovative platform, there need to be multiple competing browser engines.
The more features Google adds to Chrome, the harder it becomes for Firefox to keep up, and the more impossible it becomes for anyone to build a new browser from scratch.</p>
<p>But this article seems almost allergic to actual solutions.
It is intent on blaming all the wrong people without proposing any real answers.</p>
<p>Look at this bit:</p>
<blockquote>
<p>Mozilla just fired everyone relevant to focus on crap no one asked for like Pocket, and fad nonsense like a paid VPN service and virtual reality tech.</p>
</blockquote>
<p>Of course they did – they had no choice.
It takes money to build software.
Pocket, even if it is “crap no one asked for,” is an opportunity to serve ads.
“Fad nonsense” like paid VPNs actually make quite a bit of money these days.
Mozilla makes Firefox, Servo, MDN, and Rust, and does it all for free.
I love Mozilla for it, but this article seems to believe that all that is needed for this state of affairs to continue is… what, exactly?</p>
<blockquote>
<p>No layoffs or pay cuts at the management level, of course!
It’s not like they’re responsible for these problems, it’s not like anyone’s fucking responsible for any of this, it’s not like the very idea of personal responsibility has been forgotten by both executives and engineers, no sir!</p>
</blockquote>
<p>“Personal responsibility,” apparently.
I totally support pay cuts for executives, but you can’t save 250 jobs like that, and “personal responsibility” alone can’t pay the bills.
Not only does appealing to personal responsibility solve nothing, it distracts us from actual solutions by letting us blame individuals for the systemic reasons that our problems exist in the first place.</p>
<p>If we want to protect the public good by keeping Mozilla in the black, we need to stop expecting them to do their work for free while still making money in the market.
We need to provide them with government grants.
Clearly charitable donations aren’t enough – let’s fund important software the same way we fund important science: with public money.</p>
<p>As for the question of scope creep in browsers, how do we solve that?
Google seems content to just keep adding features, even if that’s ultimately bad for the ecosystem.
This applies to AMP too.
Google bumps AMP websites to the top of its search results regardless of speed.
This is anti-competitive behaviour.
How does this article propose we stop this?</p>
<blockquote>
<p>No one wants AMP.
Google knows it, you know it, I know it.
If you’re a Google engineer who is still working on AMP, you are a disgrace to your field.
Take responsibility for the code you write.
This project needs to be dead and buried and the earth above salted, and it needs to happen yesterday.</p>
</blockquote>
<p>“Personal responsibility,” again.
Let’s just <em>ask</em> all the engineers at Google to stop making AMP.
That’s not a solution; we can’t solve problems just by asking everyone to stop doing the thing.
What’s next, are we gonna fix global warming by asking everyone working in the fossil fuel sector to quit?
Are we gonna end sweatshop labour by asking every Nike employee to resign?
At no point in history has social change ever worked this way.
This is a non-solution.</p>
<p>If we think AMP is anti-competitive, the answer is anti-trust legislation.
Plain and simple.
If we want to decouple Chrome from Google’s private interests, the only way to actually do that is to break up Google, separating the Chrome team into its own non-profit org.</p>
<p>Are these good proposals?
Maybe.
I like them.
They’re worth discussing, at least.
But they’re better than “enough is enough,” because that’s nothing at all.
And they’re infinitely better than this weird “personal responsibility” thing, because that’s the <em>opposite</em> of a solution:
It’s something that feels like a solution – something we can waste our time talking about for ages – but something which will never actually solve the problem.</p>
<blockquote>
<p>I call for an immediate and indefinite suspension of the addition of new developer-facing APIs to web browsers.</p>
</blockquote>
<p>Google does not care what you think.
If you want to change their behaviour, you can’t just ask them to do something else.
You have to change the system of incentives and barriers which Google operates within, and force them to act differently.
By ignoring the political instruments and market forces which Google responds to in favour of shaming individuals into “taking personal responsibility,” you achieve nothing.</p>

<p><img src="https://www.blackcap.site/img/divider.svg" width="300">
</p>
<p>Having written all of this, I feel like I may be being too harsh.
This article never claimed to have solutions – in fact, it’s only a few paragraphs long.
I’ve more than quadrupled its word count in this response.
But if all we do is complain about problems, and then complain about how no one’s “taking responsibility,” we never actually fix anything.
This article blames individuals instead of systems.
It is concerned entirely with symptoms instead of looking for the root cause.</p>
<p>This is a type of thought which I find particularly frustrating, because it points fingers but doesn’t solve problems.
We will never stop corporate monopoly power by exercising our “personal responsibility.”
Shouting “Google, please stop!” into the void does nothing at all.
They will never stop of their own volition.
Ask voters to stop them instead.</p>

  </article></div>]]>
            </description>
            <link>https://www.blackcap.site/posts/google_wont_stop/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24152157</guid>
            <pubDate>Fri, 14 Aug 2020 01:32:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New hi-res microscope reveals fine details without continuously zooming in]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24152041">thread link</a>) | @finphil
<br/>
August 13, 2020 | https://nuadox.com/post/626385139089424384/hi-res-microscope-no-zoom-in | <a href="https://web.archive.org/web/*/https://nuadox.com/post/626385139089424384/hi-res-microscope-no-zoom-in">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 
                 
                    
                    <article id="626385139089424384">
                        <div>
                            <div>
                                <a href="https://nuadox.com/post/626385139089424384/hi-res-microscope-no-zoom-in"><h2>New hi-res microscope reveals fine details without continuously zooming in</h2></a>
                                <figure data-orig-width="1000" data-orig-height="563"><img src="https://64.media.tumblr.com/7be7ac0e1ee421725d18806124e275bc/5bc87f9f39561f66-6f/s1280x1920/5035b4294cf3aa878cfcf37436ecd941f79c0710.jpg" alt="image" data-orig-width="1000" data-orig-height="563" width="1000" height="563"></figure><p><b>- By&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fengineering.tamu.edu%2Fcontact%2Fprofiles%2Fsuresh-vandana.html&amp;t=ZGVmYWU4ZTRkNWNhYmMyODc2MzBjMjhkYjg0NTY0NWY3ZTQzNTQ2ZSw4RmVldkVyRQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F626385139089424384%2Fhi-res-microscope-no-zoom-in&amp;m=0&amp;ts=1597580677">Vandana Suresh</a> , <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.tamu.edu%2F&amp;t=ZjEzNGY0NTZmODhlMjYyY2M3YTNkMjY5OWRjY2FmNjYzMDc4NzVhZiw4RmVldkVyRQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F626385139089424384%2Fhi-res-microscope-no-zoom-in&amp;m=0&amp;ts=1597580677">Texas A&amp;M University</a> -&nbsp;</b></p><p>Since the early 1930s, electron microscopy has provided unprecedented access to the alien world of the extraordinarily small, revealing intricate details that are otherwise impossible to discern with conventional light microscopy. But to achieve high resolution over a large specimen area, the energy of the electron beams needs to be cranked up, which is costly and detrimental to the specimen under observation. </p><p>Texas A&amp;M University researchers may have found a new method to improve the quality of low-resolution electron micrographs without compromising the integrity of specimen samples. By training deep neural networks, a type of artificial intelligence algorithm, on pairs of images from the same sample but at different physical resolutions, they have found that details in lower-resolution images can be enhanced further. </p><p>“Normally, a high-energy electron beam is passed through the sample at locations where greater image resolution is desired. But with our image processing techniques, we can super resolve an entire image by using just a few smaller-sized, high-resolution images,” said Dr. Yu Ding, Mike and Sugar Barnes Professor in the Wm Michael Barnes ‘64 Department of Industrial and Systems Engineering. “This method is less destructive since most parts of the specimen sample needn’t be scanned with high-energy electron beams.”</p><p>The researchers published their image processing technique in <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fieeexplore.ieee.org%2Fabstract%2Fdocument%2F9117049&amp;t=N2YzODE3ZTZiYjM2NGQ1MjI3YTc1ZWY4ZWFlMjI4NjljNDQ5NTZiNSw4RmVldkVyRQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F626385139089424384%2Fhi-res-microscope-no-zoom-in&amp;m=0&amp;ts=1597580677"><i> Institute of Electric and Electronics Engineers’ Transactions on Image Processing</i></a> in June. </p><p>Unlike in light microscopy where photons, or tiny packets of light, are used to illuminate an object, in electron microscopy, a beam of electrons is utilized. The electrons reflected from or passing through the object are then collected to form an image, called the electron micrograph. </p><p>Thus, the energy of the electron beams plays a crucial role in determining the resolution of images. That is, the higher the energy electrons, the better the resolution. However, the risk of damaging the specimen also increases, similar to how ultraviolet rays, which are the more energetic relatives of visible light, can damage sensitive materials like the skin. </p><p>“There’s always that dilemma for scientists,” said Ding. “To maintain the specimen’s integrity, high-energy electron beams are used sparingly. But if one does not use energetic beams, high-resolution or the ability to see at finer scales becomes limited.”</p><p>But there are ways to get high resolution or super resolution using low-resolution images. One method involves using multiple low-resolution images of essentially the same region. Another method learns common patterns between small image patches and uses unrelated high-resolution images to enhance existing low-resolution images.</p><p>These methods almost exclusively use natural light images instead of electron micrographs. Hence, they run into problems for super-resolving electron micrographs since the underlying physics for light and electron microscopy is different, Ding explained.</p><p>The researchers turned to pairs of low- and high-resolution electron microscopic images for a given sample. Although these types of pairs are not very common in public image databases, they are relatively common in materials science research and medical imaging.</p><p>For their experiments, Ding and his team first took a low-resolution image of a specimen and then subjected roughly 25% of the area under observation to high-energy electron beams to get a high-resolution image. The researchers noted that the information in the high-resolution and low-resolution image pair are very tightly correlated. They said that this property can be leveraged even though the available dataset might be small.</p><p>For their analyses, Ding and his team used 22 pairs of images of materials infused with nanoparticles. They then divided the high-resolution image and its equivalent area in the low-resolution image into three by three subimages. Next, each subimage pair was used to “self-train” deep neural networks. Post-training, their algorithm became familiar at recognizing image features, such as edges. &nbsp;</p><p>When they tested the trained deep neural network on a new location on the low-resolution image for which there was no high-resolution counterpart, they found that their algorithm could enhance features that were hard to discern by up to 50%.</p><p>Although their image processing technique shows a lot of promise, Ding noted that it still requires a lot of computational power. In the near future, his team will be directing their efforts in developing algorithms that are much faster and can be supported by lesser computing hardware.</p><p>“Our paired image processing technique reveals details in low-resolution images that were not discernable before,” said Ding. “We are all familiar with the magic wand feature on our smartphones. It makes the image clearer. What we aim to do in the long run is to provide the research community a similar convenient tool for enhancing electron micrographs.”</p><p>–</p><p><i>Header image:&nbsp;Left and right images show false-colored electron microscopic images of the same region on the specimen. But the image on the right has been super-resolved using Dr. Ding’s new image processing method. Credit: <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fengineering.tamu.edu%2Fnews%2F2020%2F08%2Fnew-super-resolution-method-reveals-fine-details-without-constantly-needing-to-zoom-in.html&amp;t=ZDFkYmMxYjMxNGY2ZmVkYzNkZTNiZGRlZDA0ZDk2MDNkZmJjMTViNyw4RmVldkVyRQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F626385139089424384%2Fhi-res-microscope-no-zoom-in&amp;m=0&amp;ts=1597580677">Dr. Yu Ding,&nbsp;Texas A&amp;M University College of Engineering</a>.</i></p><p><b>Source:&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fengineering.tamu.edu%2Fnews%2F2020%2F08%2Fnew-super-resolution-method-reveals-fine-details-without-constantly-needing-to-zoom-in.html&amp;t=ZDFkYmMxYjMxNGY2ZmVkYzNkZTNiZGRlZDA0ZDk2MDNkZmJjMTViNyw4RmVldkVyRQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F626385139089424384%2Fhi-res-microscope-no-zoom-in&amp;m=0&amp;ts=1597580677">Texas A&amp;M University</a></b></p><p><b>Full study:</b>&nbsp;“Effective Super-Resolution Methods for Paired Electron Microscopic Images”,&nbsp;<i>Institute of Electric and Electronics Engineers’ Transactions on Image Processing</i>.</p><p><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fdoi.org%2F10.1109%2FTIP.2020.3000964&amp;t=MmQ4ZGQxYTcyZjA1MzhlMDJjN2FiNzljYjQ0NTUyNmQ0M2IzZmVmYiw4RmVldkVyRQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F626385139089424384%2Fhi-res-microscope-no-zoom-in&amp;m=0&amp;ts=1597580677">https://doi.org/10.1109/TIP.2020.3000964</a><br></p><h2><b>Read Also</b></h2><p><a href="https://nuadox.com/post/613241787281260544/high-speed-microscope-brain-signals">High-speed microscope captures millisecond brain signals</a></p>
                    
                      
                    
                    
                    
                    
                    
                    
                    
                    
                                             
                                <p><span>
                                    <p>
                                    
                                        <a href="https://nuadox.com/tagged/microscope">microscope</a>
                                    
                                        <a href="https://nuadox.com/tagged/imaging">imaging</a>
                                    
                                        <a href="https://nuadox.com/tagged/ai">ai</a>
                                    
                                        <a href="https://nuadox.com/tagged/artificial-intelligence">artificial intelligence</a>
                                    
                                    </p>
                                </span></p>
                                
                            </div>
                        </div>
                    </article>
                 
                </div></div>]]>
            </description>
            <link>https://nuadox.com/post/626385139089424384/hi-res-microscope-no-zoom-in</link>
            <guid isPermaLink="false">hacker-news-small-sites-24152041</guid>
            <pubDate>Fri, 14 Aug 2020 01:13:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[USPS Releases 2020 Ruth Asawa Stamp]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24152035">thread link</a>) | @arunc
<br/>
August 13, 2020 | https://ruthasawa.com/usps-announces-2020-ruth-asawa-stamp/ | <a href="https://web.archive.org/web/*/https://ruthasawa.com/usps-announces-2020-ruth-asawa-stamp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="tc-page-wrap">

  		
  	   	
  		                                                                                    <div id="main-wrapper">

    
    <div role="main">
        <div>

            
                <div id="content">

                    
                        
                                                                                                                              
                                                                    <article id="post-1462">
                                                
                  <section>
              <div id="attachment_1468"><p><img aria-describedby="caption-attachment-1468" src="https://ruthasawa.com/wp-content/uploads/2020/04/stamp-1200.jpg" alt="" width="1200" height="769" srcset="https://ruthasawa.com/wp-content/uploads/2020/04/stamp-1200.jpg 1200w, https://ruthasawa.com/wp-content/uploads/2020/04/stamp-1200-300x192.jpg 300w, https://ruthasawa.com/wp-content/uploads/2020/04/stamp-1200-1024x656.jpg 1024w, https://ruthasawa.com/wp-content/uploads/2020/04/stamp-1200-768x492.jpg 768w" sizes="(max-width: 1200px) 100vw, 1200px"></p><p id="caption-attachment-1468">© 2020 U.S. Postal Service. All rights reserved.</p></div><p>The U.S. Postal Service honors pioneering Japanese American artist Ruth Asawa (1926-2013). Showcasing Asawa’s wire sculptures, the pane includes 20 stamps, with two each of 10 designs, featuring photographs by Dan Bradica and Laurence Cuneo. The selvage features a photograph of Asawa taken by Nat Farbman in 1954 for <em>Life</em> magazine. Ethel Kessler served as art director and designer.</p>
<p>Customers may purchase stamps and other philatelic products through the Postal Store at <a href="https://store.usps.com/store/product/buy-stamps/ruth-asawa-S_476304" target="_blank" rel="noopener noreferrer">usps.com/shopstamps</a>, by calling 800-STAMP24 (800-782-6724), by mail through USA Philatelic, or at Post Office locations nationwide. Videos of most stamp ceremonies will be available on facebook.com/usps. </p>
<p>The pane includes 20 stamps, featuring photographs by Laurence Cuneo and Dan Bradica for David Zwirner. The selvage features a photograph of Asawa taken by Nat Farbman in 1954 for Life magazine. Ethel Kessler served as art director and designer for this issuance.</p>
<p><a href="https://store.usps.com/store/product/buy-stamps/ruth-asawa-S_476304" rel="noopener noreferrer" target="_blank">Stamps are available now &gt;</a></p>
<p>Information on ordering first-day-of-issue postmarks and covers is at <a href="https://usps.com/shopstamps" target="_blank" rel="noopener noreferrer">usps.com/shopstamps</a> under “Collectors.”</p>
<p>Paul Lanier, son of Ruth Asawa; George Takei of The Japanese American National Museum; and Jonathan Laib, of David Zwirner Gallery participated in the virtual opening event with USPS officials:</p>
<p>The Postal Service receives no tax dollars for operating expenses and relies on the sale of postage, products and services to fund its operations. All images are preliminary and are subject to change prior to printing.</p>
<p><a href="https://ruthasawa.com/art/">Explore galleries of Asawa’s art forms &gt;</a></p>
<p><a href="https://ruthasawa.com/life/">View a timeline of her life &gt;</a></p>
<p><a href="https://ruthasawa.com/view-installation/">Experience an Asawa installation virtually &gt;</a></p>
<!-- AddThis Advanced Settings above via filter on the_content --><!-- AddThis Advanced Settings below via filter on the_content --><!-- AddThis Advanced Settings generic via filter on the_content --><!-- AddThis Share Buttons above via filter on the_content --><!-- AddThis Share Buttons below via filter on the_content --><!-- AddThis Share Buttons generic via filter on the_content -->                                                                                </section><!-- .entry-content -->
                                            </article>
                                
                                                                      
                        
                    
                </div><!--.article-container -->

           
        </div><!--.row -->
    </div><!-- .container role: main -->

    
</div><!-- //#main-wrapper -->

                                            		<!-- FOOTER -->
  		
    </div></div>]]>
            </description>
            <link>https://ruthasawa.com/usps-announces-2020-ruth-asawa-stamp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24152035</guid>
            <pubDate>Fri, 14 Aug 2020 01:12:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Story from world war two]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24151996">thread link</a>) | @kickasscoder
<br/>
August 13, 2020 | https://www.monkwhocode.com/2020/04/the-story-of-hiroo-onoda-and-norio.html | <a href="https://web.archive.org/web/*/https://www.monkwhocode.com/2020/04/the-story-of-hiroo-onoda-and-norio.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<div>


<h3>
The story of Hiroo Onoda and Norio Suzuki .
</h3>
<div>
<div id="post-body-5431664009188123112">
<div dir="ltr" trbidi="on"><p>
Well the story begins with <b>Hiroo Onodo</b>.</p><div>
<p>
A Japanese&nbsp; Army Intelligence officer who fought in world war II.&nbsp;</p>
<p>
On 23 December 1944 he was sent to Lubang Island&nbsp; in the Philippines with orders which stated that under no conditions he should surrender or take his own life.</p>
<p>
But after few months The United States detonated two nuclear weapons over the Japanese cities of Hiroshima and Nagasaki on August 6 and 9, 1945 which&nbsp; ended the World War II as Japanese surrenders.The Philippines forces distributed leaflet announcing that Japan has surrender in Oct 1945,However he and his companion distrusted the leaflet thinking that it was a allied propaganda.As they continue to carry out guerrilla&nbsp; activities and shootouts with the forces .In 1952 letters and family pictures were dropped from aircraft&nbsp; urging them to surrender,but they concluded that it was a trick. In 1972 his companion Kozuka was killed by local police. Onoda was now alone. After 2 years&nbsp; On Feb 20,1974 , Onoda met a Japanese man Norio Suzuki and then after orders from his senior was relived from his duty after 30 years.He was then a popular person in Japan.</p>
<p>
(He also released an autobiography, No Surrender: My Thirty-Year War, shortly after his return, detailing his life as a guerrilla fighter in a war that was long over)</p>
<p><b>Norio Suzuki?</b></p>
<p>
He&nbsp;was a Japanese explorer and adventurer. He studied economics but then dropped out and decided to explore the world. Four year he wander Asia, Africa&nbsp; and Middle east and then returned to Japan in 1972. As in 1972&nbsp; Japanese Media reported Kozuka was killed and his body then was surrender to Japan and after that there where many search efforts to find&nbsp; Hiroo Onodo which ended in a failure.</p>
<p>
Norio Suzuki then decided to search for the officer.</p>
<p>
He expressed his decision in this way: He wanted to search for "Lieutenant Onoda, a panda, and the Abominable Snowman(Yeti), in that order".This was kind of crazy life goals of&nbsp; Norio Suzuki .</p>
<p>
Suzuki found Onoda after four days of searching and later they both become friends.</p>
<p>
After finding Onoda, Suzuki quickly found a wild panda, and claimed to have spotted a yeti from a distance by July 1975, hiking in the Dhaulagiri range of the Himalayas. He married in 1976 but did not give up his quest.</p>
<p>
Suzuki died in November 1986 in an avalanche while searching for the yeti. His remains were discovered a year later and returned to his family.</p>
<div><p>
Hope you like the story of these two devoted people.<br>
There were people earlier having such dedication towards there goals nowadays we hardly find such thing. It is always good to have a goal set in your mind may it be anything but you must work on it everyday. It will always pay you back with high intensity.</p><p>

WRITTEN BY:<br>
<b>Saurabh Joshi</b></p></div>
</div>
</div>
</div>
</div>

</div>
</div></div>]]>
            </description>
            <link>https://www.monkwhocode.com/2020/04/the-story-of-hiroo-onoda-and-norio.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24151996</guid>
            <pubDate>Fri, 14 Aug 2020 01:05:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Open Standards Are Simple]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24151909">thread link</a>) | @wyclif
<br/>
August 13, 2020 | https://portal.mozz.us/gemini/ebc.li/posts/open-standards-are-simple.gmi | <a href="https://web.archive.org/web/*/https://portal.mozz.us/gemini/ebc.li/posts/open-standards-are-simple.gmi">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div><p><a href="https://portal.mozz.us/gemini/ebc.li/">Home</a></p>
<p>2020-08-13

If you want to create a truly open standard, you _need_ to make it simple.

There are no exceptions to this rule. When a standard becomes harder to fully implement than what your average motivated programmer can do in two months (max!), it _shouldn't_ be considered "open" anymore.

Why?

</p>
<h2>Complicated Standards Lead to Implementation Monopolies</h2>
<p>Since implementing a complex standard is hard, you will eventually end up with the implementation that started the earliest and maintained since, being the only implementation that is actually usable. And that implementation will most likely be the one created by the standard's creators.

In cases where the standard's creators don't maintain an implementation like "the web"⁰, the only choices are either the standard dying out because of it's complexity, or the actively maintained implementations requiring tons of effort, with (most likely) companies backing said implementations.

</p>
<h2>Implementation Monopolies Lead to Extensions</h2>
<p>If a big implementation just decides one day that your standard is lacking, they can just extend the parts they want. The two outcomes of this being that:

</p>
<ul><li>The other implementations copy their extensions</li>
<li>That one implementation getting more users, and eventually, a near monopoly because of a bigger feature set</li></ul>
<p>
At that point, the "standard" implemented by said implementations is longer the actual defined standard, but because people will inevitably use the said extensions, any new implementation that wants to be considered usable will eventually need to support said proprietary extensions.

</p>
<h2>Too Many Extensions Spoil The Standard</h2>
<p>Even if you have an "open" extension system, where implementations can all propose and agree on extensions to the standard, you need to be able to keep those implementations in check, so their extensions don't overcomplicate the standard.

Remember: Having a simple standard with a million extensions is no better than a complex standard with no extensions.

</p>
<h2>Examples</h2>
<p>Please note that I will be skipping the elephant in the room: "the web", as it has been discussed _to death_.

</p>
<h3>Matrix</h3>
<p>Matrix is _technically_ an open standard. But because of the complexity it has accumulated over the years, Synapse is the only usable server implementation. Even Dendrite, the new implementation by *the same folk that created the standard*, is barely usable after _years_.

The same applies to Matrix clients, with Element being the only usable client implementation. That space definitely seems healthier than the server space, but the same issues are there.

</p>
<h3>Various Programming Languages</h3>
<p>I will not be specifying any language, as I might get any specifics incorrect, but a general pattern I have seen is that most programming languages have only a few compiler/interpreter implementations, even though the language is standardized in some form.

This example actually has some interesting reasoning behind this issue on top of the complicated standards:

</p>
<ul><li>Writing a compiler/interpreter can be hard.</li>
<li>Especially if the current implementations do optimizations or other "clever" tricks.</li></ul>
<p>
These issues can devolve into arguments regarding seeing the complexity of these issues as a part of the standard, and other "technology is too complicated in general" arguments, which I will not dive into here.

</p>
<h3>X Display Server</h3>
<p>The X Display Server standard got so complicated, the people developing it decided to abandon it entirely and create Wayland.

It probably didn't help that most of the standard was no longer being used, and a lot of extensions are required for its use today.

Wayland probably will also suffer the "too many extensions" problem at some point, so I am looking forward to that too...

</p>
<h2>Footnotes</h2>
<p>0: Well, Google, Mozilla and Apple all had a hand in most of the "modern" parts of the standards...
</p></div>
        </div></div>]]>
            </description>
            <link>https://portal.mozz.us/gemini/ebc.li/posts/open-standards-are-simple.gmi</link>
            <guid isPermaLink="false">hacker-news-small-sites-24151909</guid>
            <pubDate>Fri, 14 Aug 2020 00:52:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Developing Python with Poetry and POETRY2NIX]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24151666">thread link</a>) | @figomore
<br/>
August 13, 2020 | https://www.tweag.io/blog/2020-08-12-poetry2nix/ | <a href="https://web.archive.org/web/*/https://www.tweag.io/blog/2020-08-12-poetry2nix/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><div><p>Most Python projects are in fact <em>polyglot</em>.
Indeed, many popular libraries on <a href="https://pypi.org/">PyPi</a> are Python wrappers around C code.
This applies particularly to popular scientific computing packages, such as <code>scipy</code> and <code>numpy</code>.
Normally, this is the terrain where Nix shines, but its support for Python projects has often been labor-intensive, requiring lots of manual fiddling and fine-tuning.
One of the reasons for this is that most Python package management tools do not give enough static information about the project, not offering the determinism needed by Nix.</p>
<p>Thanks to <a href="https://python-poetry.org/">Poetry</a>, this is a problem of the past — its rich lock file offers more than enough information to get Nix running, with minimal manual intervention.
In this post, I will show how to use Poetry, together with <a href="https://github.com/nix-community/poetry2nix">Poetry2nix</a>, to easily manage Python projects with Nix.
I will show how to package a simple Python application both using the existing support for Python in Nixpkgs, and then using Poetry2nix.
This will both show why Poetry2nix is more convenient, and serve as a short tutorial covering its features.</p>
<h2>Our application</h2>
<p>We are going to package a simple application, a <a href="https://flask.palletsprojects.com/">Flask</a> server with two endpoints: one returning a static string “Hello World” and another returning a resized image.
This application was chosen because:</p>
<ol>
<li>It can fit into a single file for the purposes of this post.</li>
<li>Image resizing using Pillow requires the use of native libraries, which is something of a strength of Nix.</li>
</ol>
<p>The code for it is in the <code>imgapp/__init__.py</code> file:</p>
<div data-language="python"><pre><code><span>from</span> flask <span>import</span> send_file
<span>from</span> flask <span>import</span> Flask
<span>from</span> io <span>import</span> BytesIO
<span>from</span> PIL <span>import</span> Image
<span>import</span> requests


app <span>=</span> Flask<span>(</span>__name__<span>)</span>


IMAGE_URL <span>=</span> <span>"https://farm1.staticflickr.com/422/32287743652_9f69a6e9d9_b.jpg"</span>
IMAGE_SIZE <span>=</span> <span>(</span><span>300</span><span>,</span> <span>300</span><span>)</span>


<span>@app<span>.</span>route</span><span>(</span><span>'/'</span><span>)</span>
<span>def</span> <span>hello</span><span>(</span><span>)</span><span>:</span>
    <span>return</span> <span>"Hello World!"</span>


<span>@app<span>.</span>route</span><span>(</span><span>'/image'</span><span>)</span>
<span>def</span> <span>image</span><span>(</span><span>)</span><span>:</span>
    r <span>=</span> requests<span>.</span>get<span>(</span>IMAGE_URL<span>)</span>
    <span>if</span> <span>not</span> r<span>.</span>status_code <span>==</span> <span>200</span><span>:</span>
        <span>raise</span> ValueError<span>(</span><span><span>f"Response code was '</span><span><span>{</span>r<span>.</span>status_code<span>}</span></span><span>'"</span></span><span>)</span>

    img_io <span>=</span> BytesIO<span>(</span><span>)</span>

    img <span>=</span> Image<span>.</span><span>open</span><span>(</span>BytesIO<span>(</span>r<span>.</span>content<span>)</span><span>)</span>
    img<span>.</span>thumbnail<span>(</span>IMAGE_SIZE<span>)</span>
    img<span>.</span>save<span>(</span>img_io<span>,</span> <span>'JPEG'</span><span>,</span> quality<span>=</span><span>70</span><span>)</span>

    img_io<span>.</span>seek<span>(</span><span>0</span><span>)</span>

    <span>return</span> send_file<span>(</span>img_io<span>,</span> mimetype<span>=</span><span>'image/jpeg'</span><span>)</span>


<span>def</span> <span>main</span><span>(</span><span>)</span><span>:</span>
    app<span>.</span>run<span>(</span><span>)</span>


<span>if</span> __name__ <span>==</span> <span>'__main__'</span><span>:</span>
    main<span>(</span><span>)</span></code></pre></div>
<h2>The status quo for packaging Python with Nix</h2>
<p>There are two standard techniques for integrating Python projects with Nix.</p>
<h3>Nix only</h3>
<p>The first technique uses only Nix for package management, and is described in the <a href="https://nixos.org/nixpkgs/manual/#python">Python section</a> of the Nix manual.
While it works and may look very appealing on the surface, it uses Nix for all package management needs, which comes with some drawbacks:</p>
<ol>
<li>We are essentially tied to whatever package version Nixpkgs provides for any given dependency.
This can be worked around with overrides, but those can cause version incompatibilities.
This happens often in complex Python projects, such as data science ones, which tend to be very sensitive to version changes.</li>
<li>We are tied to using packages already in Nixpkgs.
While Nixpkgs has many Python packages already packaged up (around 3000 right now) there are many packages missing — PyPi, the Python Package Index has more than 200000 packages.
This can of course be worked around with overlays and manual packaging, but this quickly becomes a daunting task.</li>
<li>In a team setting, every team member wanting to add packages needs to buy in to Nix and at least have some experience using and understanding Nix.</li>
</ol>
<p>All these factors lead us to a conclusion: we need to embrace Python tooling so we can efficiently work with the entire Python ecosystem.</p>
<h3>Pip and Pypi2Nix</h3>
<p>The second standard method tries to overcome the faults above by using a hybrid approach of Python tooling together with Nix code generation.
Instead of writing dependencies manually in Nix, they are extracted from the <code>requirements.txt</code> file that users of Pip and Virtualenv are very used to.
That is, from a <code>requirements.txt</code> file containing the necessary dependencies:</p>

<p>we can use <a href="https://github.com/nix-community/pypi2nix">pypi2nix</a> to package our application in a more automatic fashion than before:</p>
<div data-language="sh"><pre><code>nix-shell -p pypi2nix --run "pypi2nix -r requirements.txt"</code></pre></div>
<p>However, Pip is not a dependency manager and therefore the <code>requirements.txt</code> file is not explicit enough — it lacks both exact versions for libraries, and system dependencies.
Therefore, the command above will not produce a working Nix expression.
In order to make pypi2nix work correctly, one has to manually find all dependencies incurred by the use of Pillow:</p>
<div data-language="sh"><pre><code>nix-shell -p pypi2nix --run "pypi2nix -V 3.8 -E pkgconfig -E freetype -E libjpeg -E openjpeg -E zlib -E libtiff -E libwebp -E tcl -E lcms2 -E xorg.libxcb -r requirements.txt"</code></pre></div>
<p>This will generate a large Nix expression, that will indeed work as expected.
Further use of Pypi2nix is left to the reader, but we can already draw some conclusions about this approach:</p>
<ol>
<li>Code generation results in huge Nix expressions that can be hard to debug and understand.
These expressions will typically be checked into a project repository, and can get out of sync with actual dependencies.</li>
<li>It’s very high friction, especially around native dependencies.</li>
</ol>
<p>Having many large Python projects, I wasn’t satisfied with the status quo around Python package management.
So I looked into what could be done to make the situation better, and which tools could be more appropriate for our use-case.
A potential candidate was <a href="https://github.com/pypa/pipenv">Pipenv</a>, however its dependency
solver and lock file format were difficult to work with.
In particular, Pipenv’s detection of “local” vs “non-local” dependencies did not work properly inside the Nix shell and gave us the wrong dependency graph.
Eventually, I found <a href="https://python-poetry.org/">Poetry</a> and it looked very promising.</p>
<h2>Poetry and Poetry2nix</h2>
<p>The <a href="https://python-poetry.org/docs/">Poetry package manager</a> is a relatively recent addition to the Python ecosystem but it is gaining popularity very quickly.
Poetry features a nice CLI with good UX and deterministic builds through lock files.</p>
<p>Poetry uses <code>pip</code> under the hood and, for this reason, inherited some of its shortcomings and lock file design.
I managed to land a few patches in Poetry before the 1.0 release to improve the lock file format, and now it is fit for use in Nix builds.
The result was <a href="https://github.com/nix-community/poetry2nix">Poetry2nix</a>, whose key design goals were:</p>
<ol>
<li>Dead simple API.</li>
<li>Work with the entire Python ecosystem using regular Python tooling.</li>
<li>Python developers should not have to be Nix experts, and vice versa.</li>
<li>Being an expert should allow you to “drop down” into the lower levels of the build and customise it.</li>
</ol>
<p>Poetry2nix is not a code generation tool — it is implemented in pure Nix.
This fixes many of problems outlined in previous paragraphs, since there is a single point of truth for dependencies and their versions.</p>
<p>But what about our native dependencies from before?
How does Poetry2nix know about those?
Indeed, Poetry2nix comes with an extensive set of overrides built-in for a lot of common packages, including Pillow.
Users are encouraged to contribute overrides <a href="https://github.com/nix-community/poetry2nix/blob/master/overrides.nix">upstream</a> for popular packages, so everyone can have a better user experience.</p>
<p>Now, let’s see how Poetry2nix works in practice.</p>
<h3>Developing with Poetry</h3>
<p>Let’s start with only our application file above (<code>imgapp/__init__.py</code>) and a <code>shell.nix</code>:</p>
<div data-language="nix"><pre><code><span>{</span> pkgs <span>?</span> <span>import</span> <span>&lt;</span>nixpkgs<span>&gt;</span> <span>{</span><span>}</span> <span>}</span><span>:</span>

pkgs<span>.</span>mkShell <span>{</span>

  buildInputs <span>=</span> <span>[</span>
    pkgs<span>.</span>python3
    pkgs<span>.</span>poetry
  <span>]</span><span>;</span>

<span>}</span></code></pre></div>
<p>Poetry comes with some nice helpers to create a project, so we run:</p>

<p>And then we’ll add our dependencies:</p>
<div data-language="sh"><pre><code>$ poetry add requests pillow flask</code></pre></div>
<p>We now have two files in the folder:</p>
<ul>
<li>The first one is <code>pyproject.toml</code> which not only specifies our dependencies but also replaces <code>setup.py</code>.</li>
<li>The second is <code>poetry.lock</code> which contains our entire pinned Python dependency graph.</li>
</ul>
<p>For Nix to know which scripts to install in the <code>bin/</code> output directory, we also need to add a <code>scripts</code> section to <code>pyproject.toml</code>:</p>
<div data-language="toml"><pre><code><span>[</span><span>tool.poetry</span><span>]</span>
<span>name</span> <span>=</span> <span>"imgapp"</span>
<span>version</span> <span>=</span> <span>"0.1.0"</span>
<span>description</span> <span>=</span> <span>""</span>
<span>authors</span> <span>=</span> <span>[</span><span>"adisbladis &lt;<a href="https://www.tweag.io/cdn-cgi/l/email-protection" data-cfemail="f190959882939d90959882b1969c90989ddf929e9c">[email&nbsp;protected]</a>&gt;"</span><span>]</span>

<span>[</span><span>tool.poetry.dependencies</span><span>]</span>
<span>python</span> <span>=</span> <span>"^3.7"</span>
<span>requests</span> <span>=</span> <span>"^2.23.0"</span>
<span>pillow</span> <span>=</span> <span>"^7.1.2"</span>
<span>flask</span> <span>=</span> <span>"^1.1.2"</span>

<span>[</span><span>tool.poetry.dev-dependencies</span><span>]</span>

<span>[</span><span>tool.poetry.scripts</span><span>]</span>
<span>imgapp</span> <span>=</span> <span>'imgapp:main'</span>

<span>[</span><span>build-system</span><span>]</span>
<span>requires</span> <span>=</span> <span>[</span><span>"poetry&gt;=0.12"</span><span>]</span>
<span>build-backend</span> <span>=</span> <span>"poetry.masonry.api"</span></code></pre></div>
<h3>Packaging with Poetry2nix</h3>
<p>Since Poetry2nix is not a code generation tool but implemented entirely in Nix, this step is trivial.
Create a <code>default.nix</code> containing:</p>
<div data-language="nix"><pre><code><span>{</span> pkgs <span>?</span> <span>import</span> <span>&lt;</span>nixpkgs<span>&gt;</span> <span>{</span><span>}</span> <span>}</span><span>:</span>
pkgs<span>.</span>poetry2nix<span>.</span>mkPoetryApplication <span>{</span>
  projectDir <span>=</span> <span>./.</span><span>;</span>
<span>}</span></code></pre></div>
<p>We can now invoke <code>nix-build</code> to build our package defined in <code>default.nix</code>.
Poetry2nix will automatically infer package names, dependencies, meta attributes and more from the Poetry metadata.</p>
<h3>Manipulating overrides</h3>
<p>Many overrides for system dependencies are already upstream, but what if some are lacking?
These overrides can be manipulated and extended manually:</p>
<div data-language="nix"><pre><code>poetry2nix<span>.</span>mkPoetryApplication <span>{</span>
    projectDir <span>=</span> <span>./.</span><span>;</span>
    overrides <span>=</span> poetry2nix<span>.</span>overrides<span>.</span>withDefaults <span>(</span>self<span>:</span> super<span>:</span> <span>{</span>
      foo <span>=</span> foo<span>.</span>overridePythonAttrs<span>(</span>oldAttrs<span>:</span> <span>{</span><span>}</span><span>)</span><span>;</span>
    <span>}</span><span>)</span><span>;</span>
<span>}</span></code></pre></div>
<h2>Conclusion</h2>
<p>By embracing both modern Python package management tooling and the Nix language, we can achieve best-in-class user experience for Python developers and Nix developers alike.</p>
<p>There are ongoing efforts to make Poetry2nix and other Nix Python tooling work better with data science packages like <code>numpy</code> and <code>scipy</code>.
I believe that Nix may soon rival Conda on Linux and MacOS for data science.</p>
<p>Python + Nix has a bright future ahead of it!</p></div></div></div></section></div>]]>
            </description>
            <link>https://www.tweag.io/blog/2020-08-12-poetry2nix/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24151666</guid>
            <pubDate>Fri, 14 Aug 2020 00:21:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Automate Your Excel-Based Workflow in Java – Invoice Builder Example]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24151616">thread link</a>) | @visionPASSION
<br/>
August 13, 2020 | https://keikai.io/blog/p/invoice-builder.html | <a href="https://web.archive.org/web/*/https://keikai.io/blog/p/invoice-builder.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div><p>After helping my colleague in the administration department turning her Excel file into a <a href="https://dzone.com/articles/turn-you-excel-file-into-a-web-application">Buy Currency Web App</a>, I now have the chance to help my colleague in the sales department by automating their invoice-generating process. In this article, I will share with you how I did it.</p>



<p>For salespersons, it is very common to create an invoice with Excel. But the process usually involves many error-prone manual actions like inputting data, copy/pasting,... etc. My colleague, like any salesperson, wishes that the data can be populated from the database into the invoice Excel template automatically, instead of having to input it manually. Therefore I took the time and created a web application, <strong>Invoice Builder</strong>, and turned such a manual process into an integrated, automated process leveraging Excel files, Java and, <a href="https://keikai.io/">Keikai</a>.</p>

<p>Here is a short clip of usage:</p>

<p><img src="https://keikai.io/blog/images/2020-08-invoice/usage-demo.gif" alt=""></p>



<p>The image below shows the architecture of invoice builder application:</p>

<p><img src="https://keikai.io/blog/images/2020-08-invoice/architecture.jpg" alt=""></p>

<ul>
<li>Initially, I import a source Excel file that has 2 empty tables -- the customer table and product table. A salesman will select customers and products from these tables.</li>
<li>Customer and product data is populated into the corresponding tables based on database queries.</li>
<li>We also import 2 invoice templates; they are created in Excel by our salesman. These templates will be used later.</li>
<li>Workflow: after selecting customers and products, the app will create invoices by combining customer and product data with the selected invoice template.</li>
</ul>



<p>The first step is to build the UI for this app. Since our salesman is used to work with Excel templates, we use Keikai Spreadsheet here so that he can continue using his existing templates. To give you a quick background, Keikai is based on <a href="http://www.zkoss.org/">ZK UI framework</a> which provides a complete set of UI components, and an XML-formatted UI language, <a href="https://www.zkoss.org/wiki/ZUML_Reference"><strong>ZUL</strong></a>. Following ZK's syntax, I build this web application's UI with the following UI components in XML tags:</p>
<div><pre><code data-lang="xml"><span>&lt;hlayout</span> <span>vflex=</span><span>"1"</span> <span>width=</span><span>"100%"</span> <span>apply=</span><span>"io.keikai.devref.usecase.invoice.InvoiceBuilderController"</span><span>&gt;</span>
    <span>&lt;spreadsheet</span> <span>height=</span><span>"100%"</span> <span>id=</span><span>"spreadsheet"</span> <span>hflex=</span><span>"8"</span>
                <span>maxVisibleRows=</span><span>"6"</span> <span>maxVisibleColumns=</span><span>"8"</span>
                <span>src=</span><span>"/WEB-INF/books/invoice-source.xlsx"</span>
                <span>showSheetbar=</span><span>"true"</span><span>/&gt;</span>
    <span>&lt;vlayout</span> <span>hflex=</span><span>"2"</span> <span>height=</span><span>"100%"</span><span>&gt;</span>
        <span>&lt;groupbox</span> <span>id=</span><span>"templateBox"</span> <span>title=</span><span>"Template"</span> <span>style=</span><span>"text-align: center"</span><span>&gt;</span>
        <span>&lt;/groupbox&gt;</span>
        <span>&lt;button</span> <span>id=</span><span>"create"</span> <span>label=</span><span>"Create"</span> <span>style=</span><span>"float: right"</span><span>/&gt;</span>
    <span>&lt;/vlayout&gt;</span>
<span>&lt;/hlayout&gt;</span>
</code></pre></div>
<ul>
<li><code>&lt;spreadsheet&gt;</code>: keikai spreadsheet.</li>
<li><a href="https://www.zkoss.org/zkdemo/getting_started/layout"><code>&lt;hlayout&gt;</code></a>: It layouts its child components horizontally in a row, and <code>&lt;vlayout&gt;</code> layouts components vertically.</li>
<li><a href="https://www.zkoss.org/zkdemo/layout/group_box"><code>&lt;groupbox&gt;</code></a>: It groups components with a border and a title.</li>
</ul>

<p>Each tag supports some attributes, for example:</p>

<ul>
<li><code>src</code>: specify an Excel file path to be imported into Keikai.</li>
<li><code>maxVisibleRows</code>: controls the maximum visible rows when keikai renders a sheet in a browser.</li>
</ul>

<p>For the complete attribute list, please refer to <a href="https://doc.keikai.io/dev-ref/Control_Components#zul-attributes">Keikai Developer Reference</a> and <a href="http://books.zkoss.org/wiki/ZK_Component_Reference">ZK Component Reference</a>.</p>



<p>I am used to working with MVC and Keikai does support that. Let me explain each role under the context of Keikai:</p>

<p><img src="https://keikai.io/blog/images/2020-08-invoice/mvc.jpg" alt=""></p>

<ul>
<li><strong>View</strong> : An XML file written in ZUL. ZK translates a zul file into UI components and renders in your browsers.</li>
<li><strong>Controller</strong>: A Java class that extends ZK <a href="https://www.zkoss.org/javadoc/latest/zk/org/zkoss/zk/ui/select/SelectorComposer.html"><code>SelectorComposer</code></a> that listens to events fired from View and control ZK UI components. It controls Keikai by <code>Spreadsheet</code> and <code>Range</code> API.</li>
<li><strong>Model</strong>: In my case, it's <code>CustomerService</code>, but it could be any of your java business classes, e.g. authentication, data query</li>
</ul>

<h2 id="specify-a-controller">Specify a Controller</h2>

<p>To specify a Controller for a page, I specify a full-qualified class name at <code>apply</code> attribute:</p>
<div><pre><code data-lang="xml"><span>&lt;hlayout</span> <span>vflex=</span><span>"1"</span> <span>width=</span><span>"100%"</span> <span>apply=</span><span>"io.keikai.devref.usecase.invoice.InvoiceBuilderController"</span><span>&gt;</span>
...
<span>&lt;/hlayout&gt;</span>
</code></pre></div>
<p>Then this controller can control <code>&lt;hlayout&gt;</code> and its child components. I usually specify a controller at the root component on a page.</p>



<p>Personally, I like to work with zul because it is easy to read. If you prefer to work with pure Java (like Swing) instead of using zul, it is also possible. You can create a component with <a href="https://www.zkoss.org/javadoc/latest/zk/org/zkoss/zul/Image.html"><code>new Image()</code></a>, add a component into a Groupbox (container) by <code>appendChild()</code>, and register an event listener with <code>addEventListener()</code>. With those API, you can dynamically create template preview images upon a template list array inside a groupbox:</p>

<p><img src="https://keikai.io/blog/images/2020-08-invoice/preview-images.jpg" alt=""></p>
<div><pre><code data-lang="java"><span>@Wire</span>
<span>private</span> <span>Groupbox</span> <span>templateBox</span><span>;</span>
<span>private</span> <span>String</span><span>[]</span> <span>templateFileNameList</span> <span>=</span> <span>{</span><span>"invoice-template1.xlsx"</span><span>,</span> <span>"invoice-template2.xlsx"</span><span>};</span>
<span>...</span>
<span>private</span> <span>void</span> <span>buildTemplatePreview</span><span>()</span> <span>{</span>
    <span>...</span>
    <span>Arrays</span><span>.</span><span>stream</span><span>(</span><span>templateFileNameList</span><span>).</span><span>forEach</span><span>(</span><span>fileName</span> <span>-&gt;</span> <span>{</span>
        <span>...</span>
        <span>Image</span> <span>preview</span> <span>=</span> <span>new</span> <span>Image</span><span>(</span><span>fileNameWithoutExt</span> <span>+</span> <span>"-preview.jpg"</span><span>);</span>
        <span>templateBox</span><span>.</span><span>appendChild</span><span>(</span><span>preview</span><span>);</span>
        <span>preview</span><span>.</span><span>setAttribute</span><span>(</span><span>TEMPLATE_KEY</span><span>,</span> <span>fileName</span><span>);</span>
        <span>preview</span><span>.</span><span>addEventListener</span><span>(</span><span>org</span><span>.</span><span>zkoss</span><span>.</span><span>zk</span><span>.</span><span>ui</span><span>.</span><span>event</span><span>.</span><span>Events</span><span>.</span><span>ON_CLICK</span><span>,</span> <span>event</span> <span>-&gt;</span>
                <span>selectTemplate</span><span>((</span><span>Image</span><span>)</span> <span>event</span><span>.</span><span>getTarget</span><span>()));</span>
        <span>...</span>
    <span>});</span>
    <span>...</span>
<span>}</span>
</code></pre></div>


<p>Now that we can display the spreadsheet and the source file, we need to populate data into the table.</p>

<p>The source Excel file just contains an empty customer table with table styles like column names and header colors. One good thing here is that this Excel file is created by my salesperson using Excel -- he knows better what he wants to see in this table.</p>

<p><img src="https://keikai.io/blog/images/2020-08-invoice/customer-table.jpg" alt=""></p>

<p>I load customer list from a service class and populate the list into the table:</p>
<div><pre><code data-lang="java"><span>private</span> <span>void</span> <span>populateCustomers</span><span>()</span> <span>{</span>
    <span>List</span><span>&lt;</span><span>String</span><span>[]&gt;</span> <span>customers</span> <span>=</span> <span>CustomerService</span><span>.</span><span>getCustomerList</span><span>();</span>
    <span>Range</span> <span>startingCell</span> <span>=</span> <span>customerTable</span><span>.</span><span>toCellRange</span><span>(</span><span>0</span><span>,</span> <span>1</span><span>);</span> <span>//the 1st column is for checkbox</span>
    <span>for</span> <span>(</span><span>String</span><span>[]</span> <span>c</span> <span>:</span> <span>customers</span><span>)</span> <span>{</span>
        <span>RangeHelper</span><span>.</span><span>setValuesInRow</span><span>(</span><span>startingCell</span><span>,</span> <span>c</span><span>);</span>
        <span>startingCell</span> <span>=</span> <span>startingCell</span><span>.</span><span>toShiftedRange</span><span>(</span><span>1</span><span>,</span> <span>0</span><span>);</span>
    <span>}</span>
<span>}</span>
</code></pre></div>
<ul>
<li><code>CustomerService</code> could also be any Java class that provides data entities in your case.</li>
<li><code>setValuesInRow()</code> fills multiple cells one by one in a row with an array of string, e.g. B2, C2, D2...</li>
<li><a href="https://keikai.io/javadoc/latest/io/keikai/api/Range.html#toShiftedRange-int-int-"><code>toShiftedRange(1, 0)</code></a> shifts <code>startingCell</code> to the next row.</li>
</ul>



<p>When populating data to the spreadsheet UI, we need to specify the target cells that we wish to populate the data into. I go with Named Ranges as it is a flexible way. It works like a <strong>place holder</strong> in this application. Firstly, I create several named ranges in each template file e.g. <code>Name</code>, <code>Phone</code>, and <code>Email</code> for customer details. After an end-user selects customers and products, the controller extracts each row as a map. The key is header value, the value is the corresponding cell value, e.g. <code>{Name: Debra, Phone: 338-8777, Email: debra@yahoo.com...}</code>. Then I clone an invoice sheet from the selected template and populate customer details into the corresponding named ranges.</p>

<p><img src="https://keikai.io/blog/images/2020-08-invoice/populate-named-range.png" alt=""></p>
<div><pre><code data-lang="java"><span>@Listen</span><span>(</span><span>org</span><span>.</span><span>zkoss</span><span>.</span><span>zk</span><span>.</span><span>ui</span><span>.</span><span>event</span><span>.</span><span>Events</span><span>.</span><span>ON_CLICK</span> <span>+</span> <span>"=#create"</span><span>)</span>
<span>public</span> <span>void</span> <span>createInvoice</span><span>()</span> <span>{</span>
    <span>...</span>
    <span>Book</span> <span>invoiceBook</span> <span>=</span> <span>Books</span><span>.</span><span>createBook</span><span>(</span><span>"invoice.xlsx"</span><span>);</span>
    <span>for</span> <span>(</span><span>Map</span> <span>customer</span> <span>:</span> <span>selectedCustomers</span><span>)</span> <span>{</span>
        <span>Sheet</span> <span>invoiceSheet</span> <span>=</span> <span>Ranges</span><span>.</span><span>range</span><span>(</span><span>invoiceBook</span><span>).</span><span>cloneSheetFrom</span><span>(</span><span>customer</span><span>.</span><span>get</span><span>(</span><span>"CompanyName"</span><span>).</span><span>toString</span><span>()</span>
                <span>,</span> <span>templates</span><span>.</span><span>get</span><span>(</span><span>getSelectedTemplateFileName</span><span>()).</span><span>getSheetAt</span><span>(</span><span>0</span><span>));</span>
        <span>populateNamedRange</span><span>(</span><span>generateAgentData</span><span>(),</span> <span>invoiceSheet</span><span>);</span>
        <span>populateNamedRange</span><span>(</span><span>customer</span><span>,</span> <span>invoiceSheet</span><span>);</span>
        <span>...</span>
    <span>}</span>
    <span>...</span>
<span>}</span>
<span>/**</span>
<span> * Each key in the specified fieldMap represents a named range, populate its value to the corresponding named range in the specified sheet</span>
<span> */</span>
<span>private</span> <span>void</span> <span>populateNamedRange</span><span>(</span><span>Map</span><span>&lt;</span><span>String</span><span>,</span> <span>Object</span><span>&gt;</span> <span>fieldMap</span><span>,</span> <span>Sheet</span> <span>sheet</span><span>)</span> <span>{</span>
    <span>List</span><span>&lt;</span><span>String</span><span>&gt;</span> <span>namedRanges</span> <span>=</span> <span>Ranges</span><span>.</span><span>getNames</span><span>(</span><span>sheet</span><span>);</span>
    <span>fieldMap</span><span>.</span><span>forEach</span><span>((</span><span>name</span><span>,</span> <span>value</span><span>)</span> <span>-&gt;</span> <span>{</span>
        <span>if</span> <span>(</span><span>namedRanges</span><span>.</span><span>contains</span><span>(</span><span>name</span><span>))</span> <span>{</span>
            <span>Range</span> <span>range</span> <span>=</span> <span>Ranges</span><span>.</span><span>rangeByName</span><span>(</span><span>sheet</span><span>,</span> <span>name</span><span>);</span>
            <span>range</span><span>.</span><span>setCellValue</span><span>(</span><span>value</span><span>);</span>
        <span>}</span>
    <span>});</span>
<span>}</span>
</code></pre></div>


<p>In this app, customer data is populated from the database, and we don't want our salespersons to change them. They should only select these records. Therefore, I limit what they can do on the UI in the following ways:</p>

<h2 id="hide-toolbar-and-context-menu">Hide Toolbar and Context Menu</h2>

<p>I make the sheet tab visible by specifying <code>showSheetbar="true"</code>. Everything else like the toolbar, formula bar, and the context menu is invisible by default. With this, users won't accidentally change what's displayed on the UI.</p>
<div><pre><code data-lang="xml"><span>&lt;spreadsheet</span> <span>...</span> <span>showSheetbar=</span><span>"true"</span><span>/&gt;</span>
</code></pre></div>
<h2 id="enable-sheet-protection-amp-disable-adding-a-sheet">Enable Sheet Protection &amp; Disable Adding a Sheet</h2>

<p>Then, I also enable sheet protection by <code>protectSheet()</code> to make all sheets read-only and forbid users adding a sheet by <code>disableUserAction()</code>.</p>
<div><pre><code data-lang="java"><span>private</span> <span>void</span> <span>limitAccess</span><span>()</span> <span>{</span>
    <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>spreadsheet</span><span>.</span><span>getBook</span><span>().</span><span>getNumberOfSheets</span><span>();</span> <span>i</span><span>++)</span> <span>{</span>
        <span>Ranges</span><span>.</span><span>range</span><span>(</span><span>spreadsheet</span><span>.</span><span>getBook</span><span>().</span><span>getSheetAt</span><span>(</span><span>i</span><span>)).</span><span>protectSheet</span><span>(</span><span>SELECTION_FILTER</span><span>);</span>
    <span>}</span>
    <span>spreadsheet</span><span>.</span><span>disableUserAction</span><span>(</span><span>AuxAction</span><span>.</span><span>ADD_SHEET</span><span>,</span> <span>true</span><span>);</span>
<span>}</span>
</code></pre></div>
<h2 id="editable-area-under-sheet-protection">Editable Area under Sheet Protection</h2>

<p>In Excel, you can uncheck <strong>locked</strong> status to make a cell editable under sheet protection. Other cells will remain read-only. With this setting, you can allow a range of editable area in a protected sheet. This setting will stay after importing to Keikai, so this can be done from the Excel side when we prepare the source files.</p>

<p><img src="https://keikai.io/blog/images/2020-08-invoice/unchecked-locked.jpg" alt=""></p>



<p>In this app, I have 2 Excel templates and I want to import them once and then use them whenever needed. </p>

<p>Keikai <a href="https://keikai.io/javadoc/latest/io/keikai/api/Importer.html"><code>Importer</code></a> converts an Excel xlsx file into a <a href="https://keikai.io/javadoc/latest/io/keikai/api/model/Book.html"><code>Book</code></a>. You can assign the <code>Book</code> to <a href="https://keikai.io/javadoc/latest/io/keikai/ui/Spreadsheet.html"><code>Spreadsheet</code></a> and render it to a browser. Alternatively, you can manipulate a <code>Book</code> with <a href="https://keikai.io/javadoc/latest/io/keikai/api/Range.html"><code>Range</code></a> directly without assigning it to a <code>Spreadsheet</code>. The most-commonly usages are to clone sheets or copy cells from a template book. Everyone who needs the Excel template can grab content from them without importing the template file again.</p>

<p>In my application, I store the <code>Book</code> objects of 2 template Excel files in a <code>Map</code> (<code>templateWarehouse</code>) for future use:</p>
<div><pre><code data-lang="java"><span>private</span> <span>static</span> <span>HashMap</span><span>&lt;</span><span>String</span><span>,</span> <span>Book</span><span>&gt;</span> <span>templateWarehouse</span> <span>=</span> <span>new</span> <span>HashMap</span><span>&lt;&gt;();</span>
<span>private</span> <span>static</span> <span>Importer</span> <span>importer</span> <span>=</span> <span>Importers</span><span>.</span><span>getImporter</span><span>();</span>
<span>...</span>
<span>private</span> <span>void</span> <span>importInvoiceTemplate</span><span>()</span> <span>{</span>
    <span>...</span>
        <span>for</span> <span>(</span><span>String</span> <span>fileName</span> <span>:</span> <span>templateFileNameList</span><span>)</span> <span>{</span>
            <span>if</span> <span>(!</span><span>templateWarehouse</span><span>.</span><span>containsKey</span><span>(</span><span>fileName</span><span>))</span> <span>{</span> <span>//avoid importing again</span>
                <span>templateWarehouse</span><span>.</span><span>put</span><span>(</span><span>fileName</span>
        …</code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://keikai.io/blog/p/invoice-builder.html">https://keikai.io/blog/p/invoice-builder.html</a></em></p>]]>
            </description>
            <link>https://keikai.io/blog/p/invoice-builder.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24151616</guid>
            <pubDate>Fri, 14 Aug 2020 00:16:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Valve Index HMD Detailed Teardown]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24151496">thread link</a>) | @adwi
<br/>
August 13, 2020 | https://www.thevrist.com//indexteardown | <a href="https://web.archive.org/web/*/https://www.thevrist.com//indexteardown">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>If you have ever wondered what is inside Valve Index, you might have stumbled upon my <a href="https://www.reddit.com/r/ValveIndex/comments/cpayc5/valve_index_disassembly/">reddit post from 2019</a>. I’ve decided to dive into the details of what makes Valve Index great and share my thoughts on tech inside.</p>

<p>Teardown should begin from the simplest parts - remove the face mask (held by just magnets), unplug the main cable, and remove headphones that are held in place by a single screw each. Next remove the rubber cover that is glued around lenses. It’s not that well glued, you can just pull it off.</p>

<p><img src="https://www.thevrist.com/assets/images/index1.jpg" alt="">
<em>Rubber cover that prevents dust from getting inside lenses</em></p>

<p>Let’s start with a front panel - glossy front panel is removed by hand, since it is only held by magnets (but you already knew that from all the numerous pictures of people shoving stuff in the frunk of the headset). The rest of the front panel can be easily split in two parts. First is the frunk section, it will give you access to the main circuit board of the headset. You can remove it quite painlessly if you have the correct screwdriver. This panel does not contain any electronics.</p>

<p><img src="https://www.thevrist.com/assets/images/index-face.jpg" alt="">
<em>Just look at this beauty</em></p>

<p>Second part of the front panel is more complex. It contains tracking points for the SteamVR tracking - you can see them by looking at the plastic at different angles - plastic covering tracking points is thinner so laser beams from base stations could shoot through it. SteamVR trackers are split in two independent parts, which are connected to the main circuit separately. Also this panel contains two front facing cameras, which makes the process of taking it off even more delicate. You have to disconnect two cameras and two halves of the tracking plate’s system to finally fully reveal the main circuit.</p>

<h2 id="main-circuit">Main Circuit</h2>

<p><img src="https://www.thevrist.com/assets/images/index2.jpg" alt="">
<em>The “meat” of Valve Index</em></p>

<p>Finally we get to the main computing power of the headset. You can identify the main points of the headset.</p>

<p><img src="https://www.thevrist.com/assets/images/index3-1.png" alt="">
<em>This is where all the cables connect to the HMD</em></p>

<p>On the top there is a metal connector with FPC cable going in. It is going to the smaller circuit in the top part of the headset where the cable plugs in the headset.</p>

<p><img src="https://www.thevrist.com/assets/images/index4.jpg" alt="">
<em>Circuit board with main cable and 3.5 mm audio port. It also connects to the proximity sensor</em></p>

<p>Same circuit has a 3.5 mm audio port for connecting headphones (I bet you didn’t know there is an audio jack) and proximity sensor between lenses. Last one is used for turning off the screens when the headset is not on the head.</p>

<p><img src="https://www.thevrist.com/assets/images/index2-1.png" alt="">
<em>SteamVR tracking points are connected here</em></p>

<p>On the sides of the main circuit board there are two black FPC cables. Those are going to the SteamVR tracking dots located in the sides of the headsets. Here is a picture of the tracking “web” when taken out of the headset.</p>

<p><img src="https://www.thevrist.com/assets/images/index5.jpg" alt="">
<em>One side of SteamVR tracking web taken out of the HMD</em></p>

<p>Final two FPC cables are orange color and located at the bottom of the main board. They are connecting to a pair of displays located right behind this circuit.</p>

<h2 id="microchips">Microchips</h2>

<p>Now it is time to dive in a wonderful world of microchips and circuit boards. I want to thank <a href="https://www.linkedin.com/in/popovs/">Sergejs Popovs</a> for helping to identify most of the components on the board.</p>

<p>Let’s start with simple chips. Here are two bluetooth <a href="https://www.nordicsemi.com/Products/Low-power-short-range-wireless/nRF52840">chips from Nordic Semiconductors</a>. Each of these chips is used for connecting one controller with the headset. That’s why there is a limitation of two devices connected to the HMD. If you want to connect more devices (Vive Trackers or other controllers) you will need to use a USB dongle with a separate Bluetooth chip.</p>

<p><img src="https://www.thevrist.com/assets/images/index6.jpg" alt="">
<img src="https://www.thevrist.com/assets/images/index7.jpg" alt="">
<em>Bluetooth microchips, each connects to one device</em></p>

<p>Do you remember the USB port in the frunk? Well, this is a <a href="http://ww1.microchip.com/downloads/en/DeviceDoc/USB5744-Data-Sheet-DS00001855J.pdf">chip from Microchip</a> for that USB port - hence USB in the name.</p>

<p><img src="https://www.thevrist.com/assets/images/index4-4.jpg" alt="">
<em>USB chip for USB port next to it</em></p>

<p>Here is a <a href="https://www.via-labs.com/product_show.php?id=96">chip from Via-Labs</a>. It has a purpose of converting USB 3.1 signal to the 2.0 one. Some of the chips on the circuit are not advanced enough to understand 3.1 USB, so this chip “dumbs it down”. When the signal will need to go back to the PC, the chip will convert the signal back to the USB 3.1.</p>

<p><img src="https://www.thevrist.com/assets/images/index8.jpg" alt="">
<em>USB signal converter chip</em></p>

<p>This is a flash memory chip from <a href="https://www.digikey.com/products/en/integrated-circuits-ics/memory/774?k=w25q32jw">Winbond Electronics</a>.</p>

<p><img src="https://www.thevrist.com/assets/images/index9.jpg" alt="">
<em>Flash memory can be used for different kinds of tasks</em></p>

<p>Next are these two microchips. The smaller one is a <a href="https://www.analogix.com/en/products/dp-mipi-converters/anx7530">SlimPort® 4K receiver from Analogix</a>. It is capable of receiving Image in 4K at 60 Hz, but since screens in Valve Index are only 1440 by 1600 pixels it allows to process video at 90, 120, and even 144 Hz. It also splits the signal in two allowing each display to get its own image.</p>

<p><img src="https://www.thevrist.com/assets/images/index10.jpg" alt="">
<em>Video chips convert image that you see in your SteamVR mirror in beautiful VR image</em></p>

<p>Larger chip is a multipurpose <a href="https://www.digikey.com/products/en/integrated-circuits-ics/embedded-fpgas-field-programmable-gate-array/696?k=ICE40HX8K">FPGA (Field Programmable Gate Array) chip from Lattice Semiconductor</a>. It is used for tracking - all the data received from the tracking sensors is gathered here. This chip combined with the <a href="http://ww1.microchip.com/downloads/en/DeviceDoc/Atmel-11289-32-bit-Cortex-M4-Microcontroller-SAM-G55_Summary-Datasheet.pdf">Atmel MCU</a> (located on the other side of the circuit board) are doing all the necessary tracking calculations.</p>

<p><a href="http://www.etron.com.tw/cn/products/webcam_detial.php?Product_ID=10">EtronTech microchip</a> is used for merging video feeds from external cameras and transmitting it to your PC.</p>

<p><img src="https://www.thevrist.com/assets/images/index11.jpg" alt="">
<em>Microchip for processing image from webcams</em></p>

<p>Last two chips on this side of the circuit from <a href="https://www.silabs.com/power/efp01-power-management-ic">SiliconLabs</a> are most likely related to power regulation. Both of them are located near the capacitors and an inductor (metal thingy with 150 written on it). These are making sure that nothing will get too hot on your face.</p>

<p><img src="https://www.thevrist.com/assets/images/index12.jpg" alt="">
<img src="https://www.thevrist.com/assets/images/index13.jpg" alt="">
<em>Power regulating microchips</em></p>

<p>Next step is to remove the main circuit board and look on its other side. Other side is less interesting and has very little information to offer. Most parts are related to the power regulation mentioned in the previous paragraph.</p>

<p><img src="https://www.thevrist.com/assets/images/index14.jpg" alt="">
<em>Back side of the main circuit board</em></p>

<p>Largest chip is an Atmel MCU, which I’ve already mentioned is related to the tracking system. On the left from it is a <a href="https://www.nxp.com/docs/en/data-sheet/LPC11U1X.pdf">microcontroller from NXP</a>. These are all the chips we managed to identify. One chip that is missing, is the additional Bluetooth module. Unlike Vive and Vive Pro, Index has bluetooth in the headset. It is used for connecting to the base stations, updating base station firmware, and sending them to sleep mode when the headset is turning off. Last one is completely optional - I prefer to keep my base stations 2.0 on all the time.</p>

<p><img src="https://www.thevrist.com/assets/images/index14-2.jpg" alt="">
<em>The only two chips worth noting on this side of the motherboard - larger one is for tracking calculations</em></p>

<p>Why there is no separate Bluetooth chip for this purpose is still a mystery for me. Only possible explanation is that two Bluetooth chips for controllers are capable of switching to different modes and control the base stations.</p>

<h2 id="screens">Screens</h2>

<p>After the circuit is removed you will reveal several key components. First - you can see two displays - quick search shows that those panels are made by BOE Technology - Chinese display manufacturer. Those are 1440×1600, 615PPI 3.5” <a href="https://www.panelook.com/VS035ZSM-NW0-69P0_BOE_3.5_LCM_overview_37926.html">panels</a>.</p>

<p><img src="https://www.thevrist.com/assets/images/index15.jpg" alt="">
<em>View of the HMD with main board removed</em></p>

<p>Note some key elements in this view. On the bottom there is a circular mechanism with a metal pin with springs going through the whole headset. Similar pin is barely visible on the top of the headset. This is an IPD adjustment system - movement of the knob at the bottom of the HMD will rotate circular element in the bottom center which will push screens apart.
On the left and right sides of HMD you can see black gears - this is a system for eye relief - rotating a knob on the side of the headset will move the facemask relatively to the screens. Gear system is making sure both sides are rotating simultaneously, without giving too much pressure to the mechanism.</p>

<p><img src="https://www.thevrist.com/assets/images/index16.jpg" alt="">
<em>IPD knob is actually a screw</em></p>

<p>In order to take the central part out from the headset, you will need to take the cap off the IPD adjustment knob and unscrew it.</p>

<p><img src="https://www.thevrist.com/assets/images/index17.jpg" alt="">
<em>Lens chambers with IPD mechanism still attached</em></p>

<p>Next was what I call the “wondering in the dark” part of teardown - for about 30 minutes we were trying to find a way of taking it apart without breaking anything, eventually using force to break one gear inside that was holding display chambers in place.</p>

<p><img src="https://www.thevrist.com/assets/images/index18.jpg" alt="">
<em>Right eye lens chamber removed</em></p>

<p>After this step you can easily take off separate lens chambers and view the details. Chambers are sealed shut so nothing will get inside - they are assembled in perfectly clean conditions with no dust particles. 
In order to take it apart you can probably try to melt glue or something like that. But we are no iFixit, we used good ol’ force. Here you can see the screen separated from the chamber.</p>

<p><img src="https://www.thevrist.com/assets/images/index19.jpg" alt="">
<img src="https://www.thevrist.com/assets/images/index20.jpg" alt="">
<em>BOE screen removed from the chamber</em></p>

<p>Screen has a polarised diffuser glued to it, which is particularly difficult to remove. It is made of very thin crystal glass and it cracks easily. You can see that the corners of it are cracked.</p>

<p><img src="https://www.thevrist.com/assets/images/index21.jpg" alt="">
<em>Crystal polarisation diffuser</em></p>

<p>Diffuser is added to blend pixels better, making the screen door effect even lower.</p>

<p><img src="https://www.thevrist.com/assets/images/index22.jpg" alt="">
<em>Fancy multilayered lens</em></p>

<p>Finally - the lenses. I was expecting them to be thicker with the effect that they create. Valve are saying “The custom lenses built into the Valve Index Headset maximize field of view without sacrificing edge-to-edge clarity. High geometric stability allows you to look around the scene by moving your eyes (not just your head) with minimal shape distortion”. I tend to agree that these are the most advanced lenses in modern mass produced HMD, even though they have their own flaws. Main issue is the light spill when using a headset, you can see the bright light’s reflections in spots where they shouldn’t be.</p>

<h2 id="final-thoughts">Final thoughts</h2>

<p>As you can clearly see, it is not possible to replace a damaged screen or scratched lens all by yourself (even though for latter one you might try to take the lens out using a suction cup, however I don’t think that is a good idea, as lenses and screens are calibrated in the factory).</p>

<p><img src="https://www.thevrist.com/assets/images/index-end.jpg" alt="">
<em>Sometimes… I feel like a monster…</em></p>

<p>I am going to put the high-resolution images of the teardown and of the motherboard <a href="https://photos.app.goo.gl/dhuPVWTu6P5XWo4HA">here</a> so you can see and check all the details by yourself. If you have any corrections, notes, or questions, shoot me an <a href="mailto:zegarsilya@gmail.com">email</a> or PM me on <a href="https://twitter.com/GamerToTheEnd">Twitter</a>.</p>

           …</div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.thevrist.com//indexteardown">https://www.thevrist.com//indexteardown</a></em></p>]]>
            </description>
            <link>https://www.thevrist.com//indexteardown</link>
            <guid isPermaLink="false">hacker-news-small-sites-24151496</guid>
            <pubDate>Fri, 14 Aug 2020 00:02:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding .NET Generic Host Model]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24151361">thread link</a>) | @sahan
<br/>
August 13, 2020 | https://sahansera.dev/dotnet-core-generic-host/ | <a href="https://web.archive.org/web/*/https://sahansera.dev/dotnet-core-generic-host/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In this article, we will concentrate on how the Generic Host model hosts ASP.NET Core 3.x Web app and a Worker Service. We will first discuss the definition of a <em>Host</em> and its configuration. In the subsequent sections, we will dive into the implementation details from a higher level.</p>
<h3>So what’s the deal with the Generic Host</h3>
<p>With the separation of execution and initialisation, Generic Host provides us with a cleaner way to configure and start up our apps. By default, when you create an ASP.NET Core app now, your application will be hosted using the Generic Host model. If you create a new worker service app, it will be hosted the same way.</p>
<p>Not only that, but this model also provides you standardised configuration, DI, logging, and many more. You can even create a traditional console app, beef it up and make use of Generic Host.</p>
<blockquote>
<p>💡 Follow along with the code from this <a href="https://github.com/sahan91/dotnet-generic-host-example">repository</a></p>
</blockquote>
<h3>The Host</h3>
<p>According to the official documentation, a <code>Host</code> is,</p>
<blockquote>
<p>ASP.NET Core apps configure and launch a host. The host is responsible for app startup and lifetime management. At a minimum, the host configures a server and a request processing pipeline. The host can also set up logging, dependency injection, and configuration.</p>
</blockquote>
<p>Let’s create a new .NET 3.1 WebAPI and a Worker Service project</p>
<div data-language="bash"><pre><code>dotnet new webapi -n WebApplication
dotnet new worker -n WorkerService
dotnet new sln
dotnet sln <span>add</span> WebApplication WorkerService</code></pre></div>
<p>If you open up the solution in an IDE, you will see the following project structure.</p>
<p><span>
      <span></span>
  <img alt="dotnet-core-generic-host-1.png" title="dotnet-core-generic-host-1.png" src="https://sahansera.dev/static/7574402368b68f39b8626bb1f9bc8f39/0c69d/dotnet-core-generic-host-1.png" srcset="https://sahansera.dev/static/7574402368b68f39b8626bb1f9bc8f39/772e8/dotnet-core-generic-host-1.png 200w,
https://sahansera.dev/static/7574402368b68f39b8626bb1f9bc8f39/e17e5/dotnet-core-generic-host-1.png 400w,
https://sahansera.dev/static/7574402368b68f39b8626bb1f9bc8f39/0c69d/dotnet-core-generic-host-1.png 598w" sizes="(max-width: 598px) 100vw, 598px" loading="lazy">
    </span></p>
<p>They both have a <code>Program.cs</code> which takes care of setting up a host. In the case of the WebApplication project, it sets up a request processing pipeline defined in a <code>Startup.cs</code> and in the WorkerService project, sets a new hosted service which is an essentially an <code>IHostedService</code>.</p>
<p>In the WebApplication project, when you open up the Program.cs file, you will find the following boilerplate code has been added by the template:</p>
<div data-language="csharp"><pre><code><span>public</span> <span>static</span> <span><span>void</span></span> <span>Main</span><span>(</span><span><span>string</span><span>[</span><span>]</span></span> args<span>)</span>
<span>{</span>
    <span>CreateHostBuilder</span><span>(</span>args<span>)</span><span>.</span><span>Build</span><span>(</span><span>)</span><span>.</span><span>Run</span><span>(</span><span>)</span><span>;</span>
<span>}</span>

<span>public</span> <span>static</span> <span>IHostBuilder</span> <span>CreateHostBuilder</span><span>(</span><span><span>string</span><span>[</span><span>]</span></span> args<span>)</span> <span>=&gt;</span>
    Host<span>.</span><span>CreateDefaultBuilder</span><span>(</span>args<span>)</span>
        <span>.</span><span>ConfigureWebHostDefaults</span><span>(</span>webBuilder <span>=&gt;</span>
        <span>{</span>
            webBuilder<span>.</span><span><span>UseStartup</span><span><span>&lt;</span>Startup<span>&gt;</span></span></span><span>(</span><span>)</span><span>;</span>
        <span>}</span><span>)</span><span>;</span></code></pre></div>
<p>And, in the WorkerService project we have the following code:</p>
<div data-language="csharp"><pre><code><span>public</span> <span>static</span> <span><span>void</span></span> <span>Main</span><span>(</span><span><span>string</span><span>[</span><span>]</span></span> args<span>)</span>
<span>{</span>
    <span>CreateHostBuilder</span><span>(</span>args<span>)</span><span>.</span><span>Build</span><span>(</span><span>)</span><span>.</span><span>Run</span><span>(</span><span>)</span><span>;</span>
<span>}</span>

<span>public</span> <span>static</span> <span>IHostBuilder</span> <span>CreateHostBuilder</span><span>(</span><span><span>string</span><span>[</span><span>]</span></span> args<span>)</span> <span>=&gt;</span>
    Host<span>.</span><span>CreateDefaultBuilder</span><span>(</span>args<span>)</span>
        <span>.</span><span>ConfigureServices</span><span>(</span><span>(</span>hostContext<span>,</span> services<span>)</span> <span>=&gt;</span>
        <span>{</span>
            services<span>.</span><span><span>AddHostedService</span><span><span>&lt;</span>Worker<span>&gt;</span></span></span><span>(</span><span>)</span><span>;</span>
        <span>}</span><span>)</span><span>;</span></code></pre></div>
<p>Except for the <code>ConfigureWebHostDefaults()</code> and <code>ConfigureServices()</code>, everything else is the same.</p>
<h3>Host Configuration</h3>
<p>If you look at the <code>CreateHostBuilder</code> method in the above code, it calls a <code>CreateDefaultBuilder</code> static method from <a href="https://github.com/dotnet/runtime/blob/master/src/libraries/Microsoft.Extensions.Hosting/src/Host.cs">Host</a> coming from <a href="https://docs.microsoft.com/en-us/dotnet/api/microsoft.extensions.hosting.host.createdefaultbuilder?view=dotnet-plat-ext-3.1">Microsoft.Extensions.Hosting</a> namespace. It looks like that when we scaffold an ASP.NET Core app, it gives us a <em>.NET Generic Host</em> by default now. We used to have Web Host in ASP.NET Core 2.x, which was made deprecated since ASP.NET Core 3.0. For any future applications, it is recommended to use the .NET Generic Host.</p>
<p>This does a few things under the covers by wrapping,</p>
<ul>
<li>Dependency Injection services</li>
<li>HTTP Server implementation (such as Kestrel)</li>
<li>Logging</li>
<li>Configuration etc.</li>
</ul>
<p>In order to get an idea what the above methods do, I looked into the <a href="https://github.com/dotnet/runtime/blob/master/src/libraries/Microsoft.Extensions.Hosting/src/Host.cs">source code on Github</a>.</p>
<p>We will start off with CreateDefaultBuilder method first.</p>
<p><strong><a href="https://github.com/dotnet/runtime/blob/6072e4d3a7a2a1493f514cdf4be75a3d56580e84/src/libraries/Microsoft.Extensions.Hosting/src/Host.cs">Host.CreateDefaultBuilder()</a></strong></p>
<div data-language="csharp"><pre><code><span>public</span> <span>static</span> <span>IHostBuilder</span> <span>CreateDefaultBuilder</span><span>(</span><span><span>string</span><span>[</span><span>]</span></span> args<span>)</span>
<span>{</span>
    
    <span><span>var</span></span> builder <span>=</span> <span>new</span> <span>HostBuilder</span><span>(</span><span>)</span><span>;</span>

    
    builder<span>.</span><span>UseContentRoot</span><span>(</span>Directory<span>.</span><span>GetCurrentDirectory</span><span>(</span><span>)</span><span>)</span><span>;</span>

    
    
    builder<span>.</span><span>ConfigureHostConfiguration</span><span>(</span>config <span>=&gt;</span> <span>..</span><span>.</span> <span>)</span><span>;</span>

    
    
    builder<span>.</span><span>ConfigureAppConfiguration</span><span>(</span><span>(</span>hostingContext<span>,</span> config<span>)</span> <span>=&gt;</span> <span>..</span><span>.</span> <span>)</span>

    
    <span>.</span><span>ConfigureLogging</span><span>(</span><span>(</span>hostingContext<span>,</span> logging<span>)</span> <span>=&gt;</span> <span>..</span><span>.</span> <span>)</span>

    
    <span>.</span><span>UseDefaultServiceProvider</span><span>(</span><span>(</span>context<span>,</span> options<span>)</span> <span>=&gt;</span> <span>..</span><span>.</span> <span>)</span><span>;</span>

    <span>return</span> builder<span>;</span>
<span>}</span></code></pre></div>
<p>As you can see, it pretty much configures a <code>HostBuilder</code> object and returns it. There’s nothing really specific to web hosting in here. This is why it’s common to both HTTP and non-HTTP workloads.</p>
<p>Taking a step further, let’s look at how the web host gets configured. We will now look through <code>ConfigureWebHostDefaults</code> method.</p>
<p><strong><a href="https://github.com/dotnet/aspnetcore/blob/4d4f2fe00ffa7c1b9ea08164f9f26a51a392d007/src/DefaultBuilder/src/GenericHostBuilderExtensions.cs#L26">GenericHostBuilderExtensions.ConfigureWebHostDefaults()</a></strong></p>
<div data-language="csharp"><pre><code><span>public</span> <span>static</span> <span>IHostBuilder</span> <span>ConfigureWebHostDefaults</span><span>(</span><span>this</span> <span>IHostBuilder</span> builder<span>,</span> <span>Action<span>&lt;</span>IWebHostBuilder<span>&gt;</span></span> configure<span>)</span>
<span>{</span>
    <span>return</span> builder<span>.</span><span>ConfigureWebHost</span><span>(</span>webHostBuilder <span>=&gt;</span>
    <span>{</span>
        WebHost<span>.</span><span>ConfigureWebDefaults</span><span>(</span>webHostBuilder<span>)</span><span>;</span>

        <span>configure</span><span>(</span>webHostBuilder<span>)</span><span>;</span>
    <span>}</span><span>)</span><span>;</span>
<span>}</span></code></pre></div>
<p>Remember that <code>ConfigureWebHostDefaults</code> is used only for HTTP workloads and let’s see what we get as the default web host configuration.</p>
<p><strong><a href="https://github.com/dotnet/aspnetcore/blob/4d4f2fe00ffa7c1b9ea08164f9f26a51a392d007/src/DefaultBuilder/src/WebHost.cs#L215">WebHost.ConfigureWebDefaults()</a></strong></p>
<div data-language="csharp"><pre><code><span>internal</span> <span>static</span> <span><span>void</span></span> <span>ConfigureWebDefaults</span><span>(</span><span>IWebHostBuilder</span> builder<span>)</span>
<span>{</span>
	
    builder<span>.</span><span>ConfigureAppConfiguration</span><span>(</span><span>(</span>ctx<span>,</span> cb<span>)</span> <span>=&gt;</span> <span>..</span><span>.</span> <span>)</span><span>;</span>

	
    builder<span>.</span><span>UseKestrel</span><span>(</span><span>(</span>builderContext<span>,</span> options<span>)</span> <span>=&gt;</span> <span>..</span><span>.</span> <span>)</span>

	
    <span>.</span><span>ConfigureServices</span><span>(</span><span>(</span>hostingContext<span>,</span> services<span>)</span> <span>=&gt;</span> <span>..</span><span>.</span> <span>)</span>

	
    <span>.</span><span>UseIIS</span><span>(</span><span>)</span>
    <span>.</span><span>UseIISIntegration</span><span>(</span><span>)</span><span>;</span>
<span>}</span></code></pre></div>
<p>So far, we have seen that both approaches use the same Generic Host paradigm in the two projects. If you are interested in customising the default configuration, head over to <a href="https://docs.microsoft.com/en-us/aspnet/core/fundamentals/host/generic-host?view=aspnetcore-3.1#host-configuration">Microsoft Docs’ official documentation</a>.</p>
<h3>Finally, how does it all run?</h3>
<p>Now comes the interesting part.</p>
<p>In both cases, after the configuration sections, we finally call the <code>Run()</code> on <code>IHost</code> object implemented in <code>HostingAbstractionsHostExtensions</code>. This will run the app and block the calling thread until the host is shut down. This is enabled by <code>WaitForShutdownAsync</code> which is called at the beginning of the start-up process, which can be triggered by Ctrl+C/SIGTERM or SIGINIT.</p>
<p>Let’s look at how both web hosts and worker services run.</p>
<p>For a worker service, remember how we registered our Worker class by passing it into <code>ConfigureServices</code> method. This Worker class extends <a href="https://docs.microsoft.com/en-us/dotnet/api/microsoft.extensions.hosting.backgroundservice?view=dotnet-plat-ext-3.1"><code>BackgroundService</code></a> which in turn implements <a href="https://docs.microsoft.com/en-us/dotnet/api/microsoft.extensions.hosting.ihostedservice?view=dotnet-plat-ext-3.1"><code>IHostedService</code></a>. <code>IHostedService</code> provides 2 methods, namely, <code>StartAsync</code> and <code>StopAsync</code>. So when we run our host, it must be retrieving our Worker service and invoking these methods.</p>
<p><span>
      <span></span>
  <img alt="dotnet-core-generic-host-2.png" title="dotnet-core-generic-host-2.png" src="https://sahansera.dev/static/62f75431b28332dbbf2b7b1d69754ff8/5a190/dotnet-core-generic-host-2.png" srcset="https://sahansera.dev/static/62f75431b28332dbbf2b7b1d69754ff8/772e8/dotnet-core-generic-host-2.png 200w,
https://sahansera.dev/static/62f75431b28332dbbf2b7b1d69754ff8/e17e5/dotnet-core-generic-host-2.png 400w,
https://sahansera.dev/static/62f75431b28332dbbf2b7b1d69754ff8/5a190/dotnet-core-generic-host-2.png 800w,
https://sahansera.dev/static/62f75431b28332dbbf2b7b1d69754ff8/c1b63/dotnet-core-generic-host-2.png 1200w,
https://sahansera.dev/static/62f75431b28332dbbf2b7b1d69754ff8/29007/dotnet-core-generic-host-2.png 1600w,
https://sahansera.dev/static/62f75431b28332dbbf2b7b1d69754ff8/575bd/dotnet-core-generic-host-2.png 1791w" sizes="(max-width: 800px) 100vw, 800px" loading="lazy">
    </span></p>
<p><em>Source: <a href="https://devblogs.microsoft.com/cesardelatorre/implementing-background-tasks-in-microservices-with-ihostedservice-and-the-backgroundservice-class-net-core-2-x/">Microsoft</a></em></p>
<p>In the <code>Host.cs</code> there’s a separate <code>StartAsync</code> method and we can find the following lines inside it.</p>
<div data-language="csharp"><pre><code>_hostedServices <span>=</span> Services<span>.</span><span><span>GetService</span><span><span>&lt;</span>IEnumerable<span>&lt;</span>IHostedService<span>&gt;</span><span>&gt;</span></span></span><span>(</span><span>)</span><span>;</span>

<span>foreach</span> <span>(</span><span><span>var</span></span> hostedService <span>in</span> _hostedServices<span>)</span>
<span>{</span>
    
    <span>await</span> hostedService<span>.</span><span>StartAsync</span><span>(</span>combinedCancellationToken<span>)</span><span>.</span><span>ConfigureAwait</span><span>(</span><span>false</span><span>)</span><span>;</span>
<span>}</span></code></pre></div>
<p>So our guess was correct. It certainly invokes the <code>StartAsync</code> method of <code>BackgroundService</code>, that calls <code>ExecuteAsync</code> method in which we have ultimately implemented in our <code>Worker</code> class.</p>
<p>For a web host, there’s a little bit of abstraction on top of this before it hits the above section. A summary of how it reaches this as follows;</p>
<ol>
<li>In Program.cs, configure a new webhost builder object in ConfigureWebHostDefaults</li>
<li>Register Startup class</li>
<li><code>GenericHostBuilderExtensions.ConfigureWebHostDefaults</code> method gets called</li>
<li><code>GenericHostWebHostBuilderExtensions.ConfigureWebHost</code> gets called</li>
<li>Register a <code>GenericWebHostService</code> service</li>
</ol>
<div data-language="csharp"><pre><code><span>public</span> <span>static</span> <span>IHostBuilder</span> <span>ConfigureWebHost</span><span>(</span><span>this</span> <span>IHostBuilder</span> builder<span>,</span> <span>Action<span>&lt;</span>IWebHostBuilder<span>&gt;</span></span> configure<span>)</span>
<span>{</span>
    <span><span>var</span></span> webhostBuilder <span>=</span> <span>new</span> <span>GenericWebHostBuilder</span><span>(</span>builder<span>)</span><span>;</span>
    <span>configure</span><span>(</span>webhostBuilder<span>)</span><span>;</span>
    builder<span>.</span><span>ConfigureServices</span><span>(</span><span>(</span>context<span>,</span> services<span>)</span> <span>=&gt;</span> services<span>.</span><span><span>AddHostedService</span><span><span>&lt;</span>GenericWebHostService<span>&gt;</span></span></span><span>(</span><span>)</span><span>)</span><span>;</span>
    <span>return</span> builder<span>;</span>
<span>}</span></code></pre></div>
<p>So what is a <code>GenericWebHostService</code> ? It’s an <code>IHostedService</code> 🤩. Rest of the story is as above as we looked at in the worker service scenario. Because of this nicely decoupled initialisation we are able to run both ASP.NET Core and Worker services on the Generic Host.</p>
<h3>Summary</h3>
<p>To summarise, we looked at what makes the Generic Host <em>generic</em> and dug deeper into the implementation details in .NET Github repo. We also looked at what makes an ASP.NET Core web application and a worker service different, configuration-wise. This post became a bit longer than I initially I thought it would be 😅 Nevertheless, hope you picked up a thing or two.</p>
<p>Cheers!</p>
<h3>References</h3>
<ol>
<li><a href="https://docs.microsoft.com/en-us/aspnet/core/fundamentals/host/hosted-services?view=aspnetcore-3.1&amp;tabs=visual-studio">https://docs.microsoft.com/en-us/aspnet/core/fundamentals/host/hosted-services?view=aspnetcore-3.1&amp;tabs=visual-studio</a></li>
<li><a href="https://docs.microsoft.com/en-us/aspnet/core/fundamentals/host/generic-host?view=aspnetcore-3.1">https://docs.microsoft.com/en-us/aspnet/core/fundamentals/host/generic-host?view=aspnetcore-3.1</a></li>
<li><a href="https://andrewlock.net/exploring-the-new-project-file-program-and-the-generic-host-in-asp-net-core-3/">https://andrewlock.net/exploring-the-new-project-file-program-and-the-generic-host-in-asp-net-core-3/</a></li>
</ol></div></div>]]>
            </description>
            <link>https://sahansera.dev/dotnet-core-generic-host/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24151361</guid>
            <pubDate>Thu, 13 Aug 2020 23:49:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Surprising Value of Catching Up and Getting Ahead]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24151082">thread link</a>) | @hackernewsreadr
<br/>
August 13, 2020 | https://blogofjake.com/2020/08/09/the-surprising-value-of-catching-up-and-getting-ahead/ | <a href="https://web.archive.org/web/*/https://blogofjake.com/2020/08/09/the-surprising-value-of-catching-up-and-getting-ahead/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Imagine a race between two people. They are moving at the same exact speed. The only difference is that one of them got a 10-second headstart. That person has the advantage of being ahead the entire race, even though they are doing the exact same thing, moving at the exact same speed. They are always winning while the other person is always losing. Now imagine that race is not a simple sprint or even a marathon, but a race as long as life. This illustrates the unthinkable advantage of getting ahead. It is no harder for the person with the headstart to maintain their lead than it is for the person losing the entire way to maintain the distance they trail behind. In fact, it may in some cases be easier to stay ahead.</p>



<p>Another way to help illustrate this point is to look at the difference between savings and debt. Imagine two people both earn the same breakeven income to cover their same costs of living. The only difference is that one person starts with a little bit of savings and the other person starts with a little bit of debt. This small initial difference in their wealth will not only remain over time — it will actually grow much larger. The first person’s savings work for them, earning them interest over time. The second person’s debt works against them, charging them interest over time. Keep in mind, they are both earning the same income to cover the same costs of living the entire time. In this case, it is significantly easier for the person with the headstart to maintain their advantage than it is for the other person to maintain the amount by which they trail behind. Even if they both do the exact same thing over the long haul, the advantage granted by the initial headstart only increases over time.</p>



<p>This phenomenon applies in a number of other areas as well. Instead of thinking of it as the difference in a competition between two people, one can also think of it as the difference between two possible versions of oneself.</p>



<p>For example, one can lose the weight they want to lose in a relatively short period of time and then maintain a lower weight for years with no more effort than they would have needed to maintain their old heavier weight over time. All else equal, that person can enjoy the benefit of being in better shape for the rest of their life all because they put in some extra work for a short time to get down to their target weight just once.</p>



<p>This is the value of catching up and getting ahead. An early advantage can offer a lead for life. By putting in the short-term work in various areas to catch up and then get ahead, one can stay ahead in all of these areas without any more long-term effort in each, and often with less. This allows them to move on to catching up and getting ahead in other areas. The virtuous cycle continues.</p>



<p>Humans seem hardwired to always be behind. In school, kids do not do all of their assignments a week before they are due. They do them all the night before they are due. Most people tend to focus on not getting too far behind rather than on catching up and getting ahead. They fail to realize that it would often take the same or less effort to maintain a lead as it does the deficit. </p>



<p>Catching up and getting ahead is not necessarily easy, but once it is done, it is just as easy to stay ahead as it would have been to stay where one started. Catching up and getting ahead of wherever one is at the moment takes less time than that over which the benefits of doing so may be enjoyed. Get some leads in life. It is no harder and often easier to stay ahead than it is to stay behind. Why keep losing when you could just as easily keep winning? Catch up. Get ahead.</p>
	</div><div>
				<p><strong>Published</strong>
			<time datetime="2020-08-09T10:31:31-04:00">August 9, 2020</time><time datetime="2020-08-09T11:25:34-04:00">August 9, 2020</time>		</p><!-- .site-posted-on -->
	</div></div>]]>
            </description>
            <link>https://blogofjake.com/2020/08/09/the-surprising-value-of-catching-up-and-getting-ahead/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24151082</guid>
            <pubDate>Thu, 13 Aug 2020 23:29:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GRAAL: The search for GRAnd ALgorithms in truly global software markets (2012)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24150955">thread link</a>) | @pedrodelfino
<br/>
August 13, 2020 | https://boletim.de/silvio/graal-the-search-for-grand-algorithms-in-truly-global-software-markets/ | <a href="https://web.archive.org/web/*/https://boletim.de/silvio/graal-the-search-for-grand-algorithms-in-truly-global-software-markets/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                
            	
<p>The world’s economy and society is starting to enter an era of INFORMATICITY, which is based upon the provision, servicing, using and billing of information services just in the same way we are used to generate, distribute, consume and pay for electricity. This is the reason for the “icity” over there in “informaticity” (informatics + icity), denoting information services as a “flow”: not as installed software in the company’s or person’s hardware infrastructure or even as software itself, when provided as services.</p>



<p>The infrastructure and means to provide such “information services as flows” is growing very fast and, at the same time, is disappearing in the background, as well as our perception of it, much in the same way electricity has disappeared in the course of dozens of years of evolution. In fact, we only notice that there is a whole complex of systems providing electricity to us when it fails somehow. And this, for the economy and society’s infrastructure at large, is how it should be. It would take us nowhere to depend upon shaky bases.</p>



<p>The same effect is starting to happen in the information economy, with consequences that might be even greater than those of electricity-as-a-service: information as a flow (or service) can be both generated and consumed globally, because the cost and loss of exchanging bits over very long distances is orders of magnitude smaller than that of moving electrons from source to sink over the same distances. This is giving rise to a number of global information services like those provided by Google and Salesforce, that are starting to have the characteristics of informaticity. In a number of cases that will be generalized over the next few years, they are starting to take over part of the roles of legacy corporate IT systems and software, as well as substituting the software boxes of old that used to serve as our personal information systems. Not only that, but they are also the information repositories of choice that we all use, more and more, day by day.</p>



<p>This represents a major change in hardware and software markets and, the more connected to the global information infrastructure is a given peripheral geography, the greater the challenge its small IT companies, in all sectors, will face from the global informaticity services. For many tiny IT companies that have survived so far providing hardware and software expertise do local and small businesses, it might be the end of the story. Even more so because of the diseconomies of scale of peripheral software markets, where it is nearly always the case that a very large number of companies develop (from scratch, usually) and provide (for a small geography and market) more or less the same few commodity &nbsp;information systems that will be made redundant as soon as that market scales (through mergers, acquisitions and the influx of foreign companies) and/or global information service providers reach such area and companies.</p>



<p>Copycat, commodity,&nbsp;<em>me too</em>&nbsp;software is being globalized by a few informaticity providers and we will most probably find a very large proportion of its current –legacy- providers out of the market soon. This is starting to happen now and is, on one side, good news for most users and small companies, both of which can benefit from world-class solutions at a smaller (sometimes zero)&nbsp; cost. On the other side, what should the software companies that are being, in a sense “globalized” do?…</p>



<p>The answer seems pretty obvious: they should look for sustainable competitive advantages. In the software and information services sector, where does that come from?… From the search for original, complex, “grand” algorithms and their implementation and deployment as global services, just like the aforementioned companies are doing. Google and Salesforce (as well as Facebook, Twitter, and parts of Apple, Amazon and Microsoft) are what we could call algorithm-based companies. Of course, most companies depend upon software to deliver most –if not all- of its goods and services these days, from aircraft manufacturers &nbsp;to the local bakery. But some depend much more than others, which is the case of the information and software companies just mentioned. And competing against information service companies which are algorithmically strong and centered is not just a matter of writing and serving a “similar” information system. For this is not an easy endeavor, as big would be competitors have discovered while trying to write a family of algorithms to match Google in search. And Google, as many others, has discovered that it is equally difficult to do the same &nbsp;for &nbsp;the “social” class of algorithms that is the core of Facebook.</p>



<p>Both Google and Facebook (and many other companies, of course) have their algorithm bases very well covered. They might still fail for other reasons, but not because someone (say Apple) would just start using their pile of cash to fund the creation of a copycat service. There is so much in terms of fundamental algorithms and solid software engineering behind –say- Google that most people that have the means for the effort of competing against it are currently investing their dimes and billions in trying to find the&nbsp;<em>next</em>&nbsp;generation of algorithms for its market. And no doubt they will, especially if Google decides to use most –if not all- of its own cash just to protect its current market, as most successful companies do (and die just because of that).</p>



<p>And so… if you are thinking of a starting a software (or software-intensive) business, waht should&nbsp;<em>you</em>&nbsp;do? Whether you are a team of two or ten, funded by tens of thousands or many millions, think twice before deciding to write just another information system of the sort that so many did trying to copy (what was then seen as) the success of Groupon. It is very unlikely that&nbsp;<em>just another implementation of a commodity information system</em>&nbsp;(JAICIS…) would be the basis for a startup that has any hope of having sustainable competitive advantages over the competition. Especially over those which are treating the algorithm core of their new business with care.</p>



<p>In countries like Brazil, due to factors like population, information market size, educational and scientific competencies and the emerging availability &nbsp;of venture capital, we can aim even higher than just asking for our startups to develop an algorithmic core that is competitive in their market. We could try to discover truly grand algorithms for serving the global informaticity market, targeting the chance of creating platforms and services that would compete not for millions but for tens, hundreds of millions of users. This is where the search for GRAAL –the grand algorithms- could lead us: to solve the problems of a sizeable percentage of a given global market and, by doing so, reap the returns while helping &nbsp;to balance the global emerging informaticity market, currently dominated by US providers.</p>



<figure><img src="https://s7380.pcdn.co/wp-content/uploads/2019/02/ball.png" alt="" srcset="https://s7380.pcdn.co/wp-content/uploads/2019/02/ball.png 926w, https://s7380.pcdn.co/wp-content/uploads/2019/02/ball-300x194.png 300w, https://s7380.pcdn.co/wp-content/uploads/2019/02/ball-640x413.png 640w, https://s7380.pcdn.co/wp-content/uploads/2019/02/ball-785x507.png 785w" sizes="(max-width: 926px) 100vw, 926px" data-old-src="https://s7380.pcdn.co/wp-content/plugins/lazy-load/images/1x1.trans.gif" data-lazy-src="https://s7380.pcdn.co/wp-content/uploads/2019/02/ball.png"></figure>
            	
                
                <!-- Boletim.de/silvio - Footer -->
                
			
			
                
                    

                        

                
                		<div><p>
        	sobre o autor: <a href="https://boletim.de/silvio/author/silvio/" title="Posts de Silvio Meira" rel="author">Silvio Meira</a>			<img alt="" src="https://secure.gravatar.com/avatar/83ab8b5696bf20d821faa44fa624af25?s=75&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/83ab8b5696bf20d821faa44fa624af25?s=150&amp;d=mm&amp;r=g 2x" height="75" width="75" data-old-src="https://s7380.pcdn.co/wp-content/plugins/lazy-load/images/1x1.trans.gif"></p><p>silvio meira é professor extraordinário da CESAR.school e presidente do conselho do portodigital.org</p>
		</div>

                

                


<!-- #comments -->

			</div></div>]]>
            </description>
            <link>https://boletim.de/silvio/graal-the-search-for-grand-algorithms-in-truly-global-software-markets/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24150955</guid>
            <pubDate>Thu, 13 Aug 2020 23:19:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rough week for tech organising in Berlin]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24150758">thread link</a>) | @CapacitorSet
<br/>
August 13, 2020 | https://techworkersberlin.com/news/2020-08-12-rough-week-for-berlin-tech/ | <a href="https://web.archive.org/web/*/https://techworkersberlin.com/news/2020-08-12-rough-week-for-berlin-tech/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

      <main>
        <section>
          <!--  -->
<!-- Output author details if some exist. -->

<article>
  
  <div>
    <p>Normally, we have positive news when it comes to election staff representation called Works Councils (Betriebsräte), but this week is an exception.</p>

<h2 id="n26-retaliates-against-works-council-initiators">N26 retaliates against Works Council initiators</h2>

<p>Workers of the online bank N26 announced their intent to elect a Works Council, with electoral committee elections scheduled for Thursday and Friday (13/14th August) this week. In a public letter, N26 workers outline why they’re forming one: https://www.worker26.com/</p>

<p>Since then, management has resorted to filing a lawsuit against the initiators, barring them from continuing their duties. They are actively working with Ver.di union to fight these obvious union busting tactics, to intimidate and scare workers. Please share your support online by messaging N26 customer service, and tweeting your support for Works Council at N26.</p>

<p>On 13 August 2020, Ver.di announced they will chair the meeting, because 6 N26 employees were banned by legal injunction. An electoral committee was voted upon for N26 Operations GmbH. The following day, N26 management raised a new injunction, banning Ver.di from chairing it, so the sister union, IG Metall stepped in to chair today’s meeting. On top of that, “someone” called the police, who fortunately left after seeing there was nothing illegal happening. What would make an incredible crime novel has become part and parcel of management tactics. We will not buckle down and we will prevail in the end!</p>

<p>For live updates check out their twitter account: https://twitter.com/worker291</p>

<p><img src="https://techworkersberlin.com/static/n26_workers.557b1b12da.png" alt="N26 Works Council campaign pic, with unicorns"></p>

<h2 id="webhelp-tries-to-shut-down-works-council">Webhelp tries to shut down Works Council</h2>

<p>Webhelp Holding Germany GmbH, which is already notorious for outsourcing already has a Works Council, so management decided to make life a living hell for the elected Works Councillors, by verbally shouting at employees, withholding pay, and trying to dissolve the Works Council. This situation is so extreme, IG Metall Berlin took the rare step and filed a <a href="https://www.igmetall-berlin.de/aktuelles/meldung/webhelp-standortleiter-untergraebt-betriebsratsarbeit/">criminal complaint against Webhelp</a>.</p>

<h2 id="mozilla-fires-25-of-staff-including-in-berlin">Mozilla fires 25% of staff, including in Berlin</h2>
<p>Mozilla is known for their open source Firefox browser and Thunderbird mail client. This is the second round of layoffs at Mozilla this year, this time over 250 people lost their jobs including the entire Taipei office. To support people looking for jobs, check out #MozillaLifeBoat. This has deep ramifications for the future of the open web.</p>

<p>What’s clear is, we are winning and management is terrified of that, so they’re playing dirty. The support and expertise of IG Metal and Ver.di unions in these cases are crucial, for fighting back when needed. If you have questions about which union is right for you, you’re in the right space and am happy to discuss it with you!</p>

<p>If you are a journalist, or know someone who’s a journalist. Workers and Union representatives are available from both campaigns, please privately message back.</p>

<p>Solidarity,
Steering Committee — Berlin Tech Workers Coalition</p>

    <h2>Get involved</h2>
    <ul>
  
  
  
  
</ul>

  </div>
</article>

        </section>
      </main>

    </div></div>]]>
            </description>
            <link>https://techworkersberlin.com/news/2020-08-12-rough-week-for-berlin-tech/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24150758</guid>
            <pubDate>Thu, 13 Aug 2020 23:03:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google play music shutting down]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24150597">thread link</a>) | @abuckenheimer
<br/>
August 13, 2020 | https://blog.youtube/news-and-events/youtube-music-will-replace-google-play-music-end-2020/ | <a href="https://web.archive.org/web/*/https://blog.youtube/news-and-events/youtube-music-will-replace-google-play-music-end-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="jump-content" tabindex="-1">
            
  <article>
    
    


<div>

<section>
    
    <div>
      
      <div>
        <p><img src="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/GPM_15s_en_US_1.gif" alt="YouTube Music will replace Google Play Music by end of 2020">
        
        </p>
      </div>
      <p>
        <article>
          Today we're announcing two important updates.
        </article>
      </p>
    </div>
  </section>
</div>


    
      
        



<section data-component="yt-paragraph-media" data-media-type="paragraph">
  <div>
    
    <div>
      <div>
        <div><p>Over the past couple of months, we’ve been welcoming Google Play Music listeners to YouTube Music as they <a href="https://youtube.googleblog.com/2020/05/youtube-music-transfer-google-play-music-library.html">effortlessly transfer</a> their music libraries, personal taste preferences and playlists to YouTube Music. Today we're announcing two important updates. First, YouTube Music will replace Google Play Music by December 2020. Users will have the opportunity to transfer their music libraries from Google Play Music to YouTube Music in that timeframe. Second, in the coming months, Google Play Music users will no longer be able to stream from or use the Google Play Music app. Additionally, we are making changes to the Google Play store and Music Manager.&nbsp;</p><p>Starting in September 2020 in New Zealand and South Africa — and in October for all other global markets — users will no longer be able to stream from or use the Google Play Music app. But don’t worry, we will be holding onto things like your playlists, uploads, purchases, likes and more until December 2020 to make your transfer to YouTube Music easier. Users who wish to transfer their music libraries from Google Play Music to YouTube Music, can do so through December 2020, after which their Google Play Music libraries will no longer be available.</p><h2>Simple transfer and additional changes to Music Manager</h2><p>Starting in late August, users will no longer be able to purchase and pre-order music or upload and download music from Google Play Music through Music Manager.&nbsp;</p><p>To ensure users don’t lose any of their content, they’ll need to use the simple<a href="http://music.youtube.com/transfer"> transfer tool</a> to migrate any purchases over to YouTube Music or use<a href="https://takeout.google.com/"> Google Takeout</a> to export data and download their purchased and uploaded music. Once the Music Store is no longer available, users will continue to be able to upload any tracks purchased elsewhere to YouTube Music.</p><p>For Google Play listeners that have not yet started the transfer process over to YouTube Music, now’s the time. Listeners can also choose to delete their Google Play Music data, and we will clearly notify all users before they lose access to their Google Play Music library and data.</p></div>
      </div>
      
    </div>
  </div>
</section>

      
    
      
        



<section data-component="yt-paragraph-media" data-media-type="image_paragraph">
  <div>
    <div>
      
        <div>
          
              <p><img src="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/unnamed_1_eb3YIiY.jpg" alt="GPM II">
                
              
              </p>
          
          

          
        </div>
        
      
    </div>
    <div>
      <div>
        <div><h2>Enhancements to your new home for music: YouTube Music&nbsp;&nbsp;&nbsp;</h2><p>Since<a href="https://youtube.googleblog.com/2020/05/youtube-music-transfer-google-play-music-library.html"> introducing the transfer tool in May</a>, we’ve continued to improve and add new features to YouTube Music for all music lovers to enjoy, including many that are important and familiar to Google Play Music users.&nbsp;</p><br><ul><li><p><b>Playlists: We’re continuously evolving the way listeners can create and enjoy playlists, including:</b></p></li><ul><li><p><b>Assistive Playlist Creation </b>- Quickly and easily create playlists by adding recommended songs based on existing songs in the playlist, as well as personalized signals, such as watch history and likes.</p></li><li><p><b>Collaborative Playlists</b> - Collaborate with other music fans to create shared playlists for any occasion.</p></li><li><p><b>New Programmed Playlists </b>- Explore newly launched programmed playlists like <a href="https://music.youtube.com/playlist?list=RDCLAK5uy_mu-BhJj3yO1OXEMzahs_aJVtNWJwAwFEE">Highline</a>, <a href="https://music.youtube.com/playlist?list=RDCLAK5uy_kUFCSc-grF3m-L_49W6p1QyGsMbueEbog">Caribbean Pulse</a>, <a href="https://music.youtube.com/playlist?list=RDCLAK5uy_m0Nsi5Jnn_g6qbvc7fywPRhEv1qN0PcMM">Conditions Underground</a>, and more.</p></li></ul><li><p><b>New Features and Improvements:&nbsp;</b></p></li><ul><li><p><b>Player Page Redesign</b> - Updates to the player page, available for Android mobile users, provides a more modern design that allows better playback controls and easier access to related music and other features like song lyrics.</p></li><li><p><b>Explore Tab</b> -&nbsp;The new Explore tab, available on both mobile and the web is the consistent destination to find new releases including albums, singles, and music videos, as well as browse our vast catalog of diverse playlists through the Moods &amp; Genre section</p></li></ul><li><p><b>More Ways to Enjoy YouTube Music:</b></p></li><ul><li><p><b>Android TV</b> - An update for Android TV brings YouTube Music to the big screen, letting listeners enjoy videos and live performances from their favorite artists, along with all their favorite music.</p></li><li><p><b>Google Maps</b> - The Android integration lets listeners seamlessly listen to music and get personalized music recommendations within the Google Maps interface.</p></li><li><p><b>Discover music with Google Assistant</b> - You can now ask your Google Home and Nest smart speakers, “Hey Google, play recommended music from YouTube Music.” Then, Google Assistant will share personalized recommendations based on your favorite artists and genres.&nbsp;</p></li></ul></ul></div>
      </div>
      
    </div>
  </div>
</section>

      
    
      
        



<section data-component="yt-paragraph-media" data-media-type="paragraph">
  <div>
    
    <div>
      <div>
        <div><p>Over the last few years, we've worked to build a fantastic fan experience on YouTube Music, merging the very best of Google Play Music with the very best of YouTube. For users who decide not to transfer their Google Play Music account to YouTube music, we will be sure to cancel your subscription at the end of your billing cycle so you aren't paying for a subscription. This will happen in September in New Zealand and South Africa and in October for all other markets. And, of course, we will be sure to notify all users ahead of subscriptions being canceled.</p><p>We can’t wait for you to start exploring YouTube Music features and discovering new music favorites along the way. Have more questions or need help? Check out all of our support resources <a href="https://support.google.com/youtubemusic/answer/9698084">here</a>.</p><br></div>
      </div>
      
    </div>
  </div>
</section>

      
    

    


<section>
  <article>
    
  </article>
</section>


    
    
  


  </article>


        </div></div>]]>
            </description>
            <link>https://blog.youtube/news-and-events/youtube-music-will-replace-google-play-music-end-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24150597</guid>
            <pubDate>Thu, 13 Aug 2020 22:48:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[JavaScript Face Detection and Recognition Libraries 2020]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24150436">thread link</a>) | @truly_furqan
<br/>
August 13, 2020 | https://www.edopedia.com/blog/javascript-face-detection-and-recognition-libraries/ | <a href="https://web.archive.org/web/*/https://www.edopedia.com/blog/javascript-face-detection-and-recognition-libraries/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.edopedia.com/blog/javascript-face-detection-and-recognition-libraries/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24150436</guid>
            <pubDate>Thu, 13 Aug 2020 22:36:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building Blocks of Every Machine Learning Solutions]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24150088">thread link</a>) | @FHMS
<br/>
August 13, 2020 | https://datarevenue.com/en-blog/machine-learning-project-architecture | <a href="https://web.archive.org/web/*/https://datarevenue.com/en-blog/machine-learning-project-architecture">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>Machine learning solutions are used to solve a wide variety of problems, but in nearly all cases the core components are the same. Whether you simply want to understand the skeleton of machine learning solutions better or are embarking on building your own, understanding these components - and how they interact - can help.</p><p>Here’s a visual and written explanation of what these are and what they do.</p><figure id="w-node-1017d6fd20b2-018ecc93"><p><img src="https://global-uploads.webflow.com/5d3ec351b1eba4332d213004/5f2d1b1667b2cfe2a3ceec18_Q5H2ISpXvST4SJ7rp6-MMChpY5W_Bxul_c1g2CGCSMFSRNT_wlI1PT7XoxABOu-ftF6reUZVHRMHAzRKz7wXgxMz7umLRlFYq6gahk-GdlPW2ZUEL1M8PSuPPnNQK1nXNDV6HP2Y.png" alt="A diagram showing the components of a machine learning solution."></p><figcaption>Machine learning consists of many components, not just an algorithm. (Want more content like this? <a href="https://datarevenue.com/signup">Subscribe</a> to our newsletter).</figcaption></figure><p>‍<strong>The components of a machine learning solution</strong></p><ol role="list"><li><strong>Data Generation: </strong>Every machine learning application lives off data. That data has to come from somewhere. Usually it’s generated by one of your core business functions.</li><li><strong>Data Collection: </strong>Data is only useful if it’s accessible, so it needs to be stored – ideally in a consistent structure and conveniently in one place.</li><li><strong>Feature Engineering Pipeline:</strong> Algorithms can't make sense of raw data. We have to select, transform, combine, and otherwise prepare our data so the algorithm can find useful patterns.</li><li><strong>Training:</strong> This is where the magic happens. We apply algorithms, and they learn patterns from the data. Then they use these patterns to perform particular tasks.</li><li><strong>Evaluation: </strong>We need to carefully test how well our algorithm performs on data it hasn’t seen before (during training). This ensures we don’t use prediction models that work well on “seen” data, but not in real-world settings.</li><li><strong>Task Orchestration:</strong> Feature engineering, training, and prediction all need to be scheduled on our compute infrastructure (such as AWS or Azure) – usually with non-trivial interdependence. So we need to reliably orchestrate our tasks.</li><li><strong>Prediction:</strong> This is the moneymaker. We use the model we’ve trained to perform new tasks and solve new problems – which usually means making a prediction.</li><li><strong>Infrastructure: </strong>Even in the age of the cloud, the solution has to live and be served somewhere. This will require setup and maintenance.&nbsp;</li><li><strong>Authentication:</strong> This keeps our models secure and makes sure only those who have permission can use them.</li><li><strong>Interaction:</strong> We need some way to interact with our model and give it problems to solve. Usually this takes the form of an API, a user interface, or a command-line interface.<strong>‍</strong></li><li><strong>Monitoring: </strong>We need to regularly check our model’s performance. This usually involves periodically generating a report or showing performance history in a dashboard.</li></ol><h2><strong>Building your own ML Architecture</strong></h2><p>Data generation and collection, training, and evaluation are must-haves, but you may need domain-specific components too.</p><p>A <a href="https://datarevenue.com/en-blog/building-ai-projects-or-hiltch-skyline-ai">common mistake we see</a> is people focussing too much on the prediction component and not enough on the feature engineering pipeline (or trying to skip this component completely).</p><p>Do you need a second opinion on how to set up the architecture for your ML applications? <a href="https://datarevenue.com/en-contact">Schedule a call</a> with us.</p></div></div></div></div>]]>
            </description>
            <link>https://datarevenue.com/en-blog/machine-learning-project-architecture</link>
            <guid isPermaLink="false">hacker-news-small-sites-24150088</guid>
            <pubDate>Thu, 13 Aug 2020 22:07:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: 33% Memory Reduction by Reordering Struct Fields]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24149637">thread link</a>) | @lanecwagner
<br/>
August 13, 2020 | https://qvault.io/2020/08/07/saving-a-third-of-our-memory-by-re-ordering-go-struct-fields | <a href="https://web.archive.org/web/*/https://qvault.io/2020/08/07/saving-a-third-of-our-memory-by-re-ordering-go-struct-fields">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			
<p>In past projects at <a href="https://classroom.qvault.io/">Qvault</a> we had an application that typically ran with <strong>~2GB</strong> in memory at any given time. By simply changing the order of some <code>uint</code> variables we managed to drop the memory usage to less than <strong>1.4GB</strong>. The vast majority of this allocated memory is due to an enormous slice of <code>stats</code> structs.</p>



<p>The <code>stats</code> struct has the following type definition:</p>



<pre><code lang="go">type stats struct {
	NumPosts uint8
	Reach    uint16
	NumLikes uint8
}</code></pre>



<p>In theory, this struct will use a measly 4 bytes. Each <code>uint8</code> uses 1 <code>byte</code>, and the single <code>uint16</code> needs 2. We began to suspect that we had some wasteful memory issues, so I built the following little program to show how memory is being used by our struct:</p>



<pre><code lang="go">package main

import (
	"fmt"
	"reflect"
	"runtime"
)

type stats struct {
	NumPosts uint8
	Reach    uint16
	NumLikes uint8
}

func main() {
	typ := reflect.TypeOf(stats{})
	fmt.Printf("Struct is %d bytes long\n", typ.Size())
	n := typ.NumField()
	for i := 0; i &lt; n; i++ {
		field := typ.Field(i)
		fmt.Printf("%s at offset %v, size=%d, align=%d\n",
			field.Name, field.Offset, field.Type.Size(),
			field.Type.Align())
	}

	allStats := []stats{}
	for i := 0; i &lt; 100000000; i++ {
		allStats = append(allStats, stats{})
	}

	printMemUsage()
}

func printMemUsage() {
	var m runtime.MemStats
	runtime.ReadMemStats(&amp;m)
	fmt.Printf("Alloc = %v MiB", bToMb(m.Alloc))
	fmt.Printf("\tTotalAlloc = %v MiB", bToMb(m.TotalAlloc))
	fmt.Printf("\tSys = %v MiB", bToMb(m.Sys))
	fmt.Printf("\tNumGC = %v\n", m.NumGC)
}

func bToMb(b uint64) uint64 {
	return b / 1024 / 1024
}</code></pre>



<p>On my MacBook using Go 1.14.1 the above program prints:</p>



<pre><code lang="bash">Struct is 6 bytes long
NumPosts at offset 0, size=1, align=1
Reach at offset 2, size=2, align=2
NumLikes at offset 4, size=1, align=1
Alloc = 1084 MiB        TotalAlloc = 3012 MiB   Sys = 2713 MiB  NumGC = 19</code></pre>



<p>Notice that even though <code>NumPosts</code> only has a size of 1 byte, the next field, <code>Reach</code>, still starts at offset 2. A whole byte is being wasted! The same thing happens with the <code>NumLikes</code> field, it starts at offset 4 with a size of 1, but the struct still takes up the full 6 bytes.</p>



<p>This may not seem like a big deal, but when you are storing millions of these structs in memory the bloat starts to add up quick.</p>



<p>If we change the <code>stats</code> struct such that the <code>uint16</code> isn’t defined between the <code>uint8</code>s:</p>



<pre><code lang="go">type stats struct {
	Reach    uint16
	NumPosts uint8
	NumLikes uint8
}</code></pre>



<p>Then the output of the program becomes:</p>



<pre><code lang="bash">Struct is 4 bytes long
Reach at offset 0, size=2, align=2
NumPosts at offset 2, size=1, align=1
NumLikes at offset 3, size=1, align=1
Alloc = 694 MiB TotalAlloc = 1927 MiB   Sys = 1391 MiB  NumGC = 19</code></pre>



<p>The total allocated memory drops from 3 GB to less than 2, and each instance of the struct now only uses 4 bytes.</p>



<h2>Why?</h2>



<p>Modern CPU hardware performs reads and writes to memory most efficiently when the data is&nbsp;<em><a href="https://en.wikipedia.org/wiki/Data_structure_alignment" target="_blank" rel="noreferrer noopener">naturally aligned</a></em>. The memory that is stored side by side should be accessible using a common multiple, so the Go compiler makes sure that it is.</p>



<p>With our first struct, the Reach field is between the NumPosts and NumLikes fields, which means that the compiler will add some padding to keep things nice and even. </p>



<figure><img loading="lazy" width="1024" height="645" src="https://qvault.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-07-at-2.51.09-PM-1024x645.png" alt="golang memory usage struct alignment" srcset="https://qvault.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-07-at-2.51.09-PM-1024x645.png 1024w, https://qvault.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-07-at-2.51.09-PM-300x189.png 300w, https://qvault.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-07-at-2.51.09-PM-768x484.png 768w, https://qvault.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-07-at-2.51.09-PM.png 1194w" sizes="(max-width: 1024px) 100vw, 1024px" title="Screen Shot 2020 08 07 at 2.51.09 PM"></figure>



<p>In our updated struct however, we have grouped the smaller fields, and since they add up to the same amount of memory as the larger <code>Reach</code> field we can save some space!</p>



<figure><img loading="lazy" width="1024" height="624" src="https://qvault.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-07-at-2.54.26-PM-1024x624.png" alt="golang memory usage struct alignment fixed" srcset="https://qvault.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-07-at-2.54.26-PM-1024x624.png 1024w, https://qvault.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-07-at-2.54.26-PM-300x183.png 300w, https://qvault.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-07-at-2.54.26-PM-768x468.png 768w, https://qvault.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-07-at-2.54.26-PM.png 1178w" sizes="(max-width: 1024px) 100vw, 1024px" title="Screen Shot 2020 08 07 at 2.54.26 PM"></figure>



<p>This was is a weird quirk, but making the smal optimizations has made a huge impact on some of our services.</p>



<div><div>
<h2>Thanks For Reading!</h2>



<p>Follow us on Twitter <a href="https://twitter.com/q_vault" rel="noopener">@q_vault</a> if you have any questions or comments</p>



<p>Take game-like coding courses on <a href="https://classroom.qvault.io/#/">Qvault Classroom</a></p>



<p><a href="https://mailchi.mp/5c7f5c281bbe/qvault-newsletter-subscribe" rel="noopener">Subscribe</a> to our Newsletter for more educational articles</p>
</div></div>

		</div></div>]]>
            </description>
            <link>https://qvault.io/2020/08/07/saving-a-third-of-our-memory-by-re-ordering-go-struct-fields</link>
            <guid isPermaLink="false">hacker-news-small-sites-24149637</guid>
            <pubDate>Thu, 13 Aug 2020 21:34:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Knurling-Rs Announcement]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24149469">thread link</a>) | @lukastyrychtr
<br/>
August 13, 2020 | https://ferrous-systems.com/blog/knurling-rs/ | <a href="https://web.archive.org/web/*/https://ferrous-systems.com/blog/knurling-rs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://ferrous-systems.com/images/knurling-rs.png" alt="Knurling-rs"></p>

<p>Today we're announcing <a href="https://github.com/knurling-rs">Knurling</a> - Ferrous' effort to sustainably build better tooling for developing and debugging Rust software for embedded systems.</p>

<p>To make this a reality, we are opening a <a href="https://github.com/knurling-rs/meta">GitHub organization</a> to collect these efforts, as well as making it possible to <a href="https://github.com/sponsors/knurling-rs">support our efforts through GitHub Sponsors</a>.</p>

<h2 id="the-mission">The Mission</h2>

<p>We believe that developing software for embedded systems should be no more difficult than developing for hosted platforms. It should be possible to use the same workflows and equally powerful tooling to develop applications and libraries for tiny embedded systems as well as server-class hardware.</p>

<p>To that end, we want to enable:</p>

<ul>
  <li>Learning embedded Rust with up to date and maintained teaching material</li>
  <li>Space-efficient and real-time capable logging</li>
  <li>Tools that integrate into your standard cargo run and cargo test workflows</li>
  <li>Execution tracing</li>
  <li>Simple data logging and visualization straight into your IDE or Browser</li>
</ul>

<p>We are already active contributors in the open source ecosystem, but we want to spend more time dedicated to building tools that improve the experience for the entire ecosystem, and we can't do that without <a href="https://github.com/sponsors/knurling-rs">your support</a>.</p>

<h2 id="release-model">Release Model</h2>

<p>We plan to make everything we develop under Knurling to be open source, in order to support the community. This includes all of the tooling, teaching material, and support libraries we develop.</p>

<p>The items we release will all be under <a href="https://opensource.org/licenses/MIT">MIT</a>+<a href="https://www.apache.org/licenses/LICENSE-2.0.html">Apache 2.0</a> licenses for code, and <a href="https://creativecommons.org/licenses/by-sa/4.0/">CC-BY-SA 4.0</a> for written material.</p>

<p>Sponsors will also have early access to work in progress tools and libraries before they are released, as well as early access to our training material and exercises before they are made public.</p>

<p>Early Access is available for all sponsors, regardless of tier.</p>

<p>Let's take a quick tour of the things we plan to make possible with <a href="https://github.com/knurling-rs/meta">Knurling</a>:</p>



<blockquote>
  <p>EDIT: This blog post has been updated to reflect the rename of <code>binfmt</code> to <code>defmt</code>.</p>
</blockquote>

<p><img src="https://ferrous-systems.com/images/defmt-teaser.jpg" alt="defmt preview"></p>

<p>We'd like to spend time to make it easier to design, build, debug, and release software components with embedded Rust. This includes developing target-side libraries, as well as host-side applications that interact with these components.</p>

<p>We also want to make it possible to have best-in-class debugging tools, allowing you to monitor, graph, and visualize what your system is doing. We think that it's possible to make developing embedded systems painless through better and extensible tooling!</p>

<p>The first of these tools we plan to release is <code>defmt</code> (in the screenshot above), a tool for efficient logging and tracing in real-time, using a variety of different transport methods like Semihosting, RTT, or even a UART or radio. <code>defmt</code> will allow for logging of data without incurring expensive formatting costs on the device itself.</p>

<p>We'll be talking more about defmt next week on our blog, but you can check it out now if you <a href="https://github.com/sponsors/knurling-rs">become a sponsor today</a>!</p>

<h2 id="more-training-and-learning-examples">More Training and Learning Examples</h2>

<p><img src="https://ferrous-systems.com/images/emb-trainings.png" alt="embedded trainings"></p>

<p>We're already developing open source training material for embedded systems in Rust, including our training material for <a href="https://github.com/ferrous-systems/teaching-material/">basic Rust training</a>, the material for our <a href="https://github.com/ferrous-systems/embedded-trainings">2019 Embedded Trainings</a>, as well as our most recent <a href="https://github.com/ferrous-systems/embedded-trainings-2020">2020 Embedded Trainings</a>.</p>

<p>We plan to develop a new, continuously maintained set of training material that consists of two parts:</p>

<p>The first part is <strong>Knurling Books</strong>, which are written guides that teach general concepts of embedded systems and Rust, and come with associated sample projects demonstrating the concepts. This is a great place for folks to learn embedded systems or embedded systems with Rust!</p>

<p>The second part is <strong>Knurling Sessions</strong>, which are quarterly embedded projects that explore specific projects using generally available hardware, building full systems and components using microcontrollers, sensors, and actuators.</p>

<p>These will be guided, hands-on tutorials for building projects like a CO2 Sensor, Data Loggers, and even robots! For folks that want to learn in a more hands-on way, or want to know "what hardware should I buy to get started", Knurling Sessions are a great option!</p>

<p>Before each session, we'll announce the hardware we'll use and how we'll use it. If you want to follow along and build the project at home, we'll include links to purchase the hardware. We'll reuse components session to session, so you can start building your own collection of parts!</p>

<p>In the future, we plan to also offer video based training and Q&amp;A sessions where we explore the concepts in a deeper and more detailed way, great for learning how and why things are built.</p>

<p>As we mentioned, all of the <strong>Knurling Books</strong> and <strong>Knurling Sessions</strong> will be made public and open source, but <a href="https://github.com/sponsors/knurling-rs">Sponsors</a> will get early access to both!</p>

<p>We'll be announcing our first training books and sessions later in August, so stay tuned!</p>

<h2 id="more-experiments-and-ecosystem-improvements">More Experiments and Ecosystem Improvements</h2>

<p><img src="https://ferrous-systems.com/images/async-on-embedded.png" alt="async on embedded"></p>

<p>In the past, we've done a number of experiments and improvements towards the Rust and Rust Embedded ecosystems. Most recently, we <a href="https://ferrous-systems.com/blog/embedded-async-await/">wrote about</a> making <a href="https://ferrous-systems.com/blog/async-on-embedded/">async/await</a> possible <a href="https://ferrous-systems.com/blog/stable-async-on-embedded/">for embedded systems</a>, and were even able to contribute optimizations that sped up compilation and run time for all users of async/await!</p>

<p>We released these experiments as <a href="https://github.com/ferrous-systems/async-on-embedded">an open source project</a>, and it has already been <a href="https://github.com/rust-embedded-community/async-on-embedded">transferred to community ownership</a>.</p>

<p>We'd like to dedicate more time to these kinds of projects, exploring what could be possible with embedded Rust, bringing crates to a maintained 1.0 status, or improving the compiler to benefit embedded systems developers. You can help us make this happen by <a href="https://github.com/sponsors/knurling-rs">sponsoring our efforts</a>!</p>

<h2 id="thank-you-all">Thank you all!</h2>

<p>We think the embedded Rust ecosystem is already the best way to develop embedded software today, but we can make it even better and easier, whether you are a developer who has never touched a microcontroller before, or you are a developer that is already an expert in embedded Rust.</p>

<p>If you'd like to support these works as an individual or through your company, we'd <a href="https://github.com/sponsors/knurling-rs">appreciate it a lot</a>! If you're interested in more details, or there is something you'd like to see us do, <a href="mailto:knurling@ferrous-systems.com">just drop us an email</a>!</p>
</div></div>]]>
            </description>
            <link>https://ferrous-systems.com/blog/knurling-rs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24149469</guid>
            <pubDate>Thu, 13 Aug 2020 21:24:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Implementing the .NET Profiling API in Rust]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24149368">thread link</a>) | @lukastyrychtr
<br/>
August 13, 2020 | https://code.camdenreslink.com/dev/implementing-the-dot-net-profiling-api-in-rust/ | <a href="https://web.archive.org/web/*/https://code.camdenreslink.com/dev/implementing-the-dot-net-profiling-api-in-rust/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="article-content">
					<figure id="article-image-banner">
                        
						<figcaption></figcaption>
					</figure>
					<section>

<p><em>The code for the library used in this post can be found <a href="https://github.com/camdenreslink/clr-profiler">here</a>. It is only intended as a proof of concept, so user beware!</em></p>



<p>Here is a simple .NET profiler implemented in Rust that prints the name of a function just before it is JIT compiled. The client library must create a type that implements all of the <code>CorProfilerCallback</code> traits. All of the methods in the callback traits have default implementations, so you only need to implement the methods that you actually want to use. COM boilerplate is set up for you behind the scenes with the <code>register!</code> macro call at the end of the code snippet.</p>


<div>
        
        
                <div><pre><code data-lang="rust"><span>#[derive(Clone)]</span>
<span>struct</span> <span>Profiler</span> {
    clsid: <span>Uuid</span>,
    profiler_info: Option<span>&lt;</span>ProfilerInfo<span>&gt;</span>,
}

<span>impl</span> ClrProfiler <span>for</span> Profiler {
    <span>fn</span> <span>new</span>() -&gt; <span>Profiler</span> {
        Profiler {
            clsid: <span>Uuid</span>::parse_str(<span>"DF63A541-5A33-4611-8829-F4E495985EE3"</span>).unwrap(),
            profiler_info: None,
        }
    }
    <span>fn</span> <span>clsid</span>(<span>&amp;</span>self) -&gt; <span>&amp;</span><span>Uuid</span> {
        <span>&amp;</span>self.clsid
    }
    <span>fn</span> <span>profiler_info</span>(<span>&amp;</span>self) -&gt; <span>&amp;</span><span>ProfilerInfo</span> {
        self.profiler_info.as_ref().unwrap()
    }
}

<span>impl</span> CorProfilerCallback <span>for</span> Profiler {
    <span>fn</span> <span>initialize</span>(<span>&amp;</span><span>mut</span> self, profiler_info: <span>ProfilerInfo</span>) -&gt; Result<span>&lt;</span>(), HRESULT<span>&gt;</span> {
        <span>//</span> Initialize ICorProfilerInfo reference
        self.profiler_info <span>=</span> Some(profiler_info);

        <span>//</span> Set the event mask
        self.profiler_info()
            .set_event_mask(COR_PRF_MONITOR::COR_PRF_ALL)<span>?</span>;

        Ok(())
    }
    <span>fn</span> <span>jit_compilation_started</span>(
        <span>&amp;</span><span>mut</span> self,
        function_id: <span>FunctionID</span>,
        _is_safe_to_block: <span>bool</span>,
    ) -&gt; Result<span>&lt;</span>(), HRESULT<span>&gt;</span> {
        <span>let</span> function_info <span>=</span> self.profiler_info().get_function_info(function_id)<span>?</span>;
        <span>let</span> metadata <span>=</span> self
            .profiler_info()
            .get_module_metadata(function_info.module_id, CorOpenFlags::ofRead)<span>?</span>;
        <span>let</span> method_props <span>=</span> metadata.import.get_method_props(function_info.token)<span>?</span>;
        println<span>!</span>(<span>"{}"</span>, method_props.name);
        Ok(())
    }
}
<span>impl</span> CorProfilerCallback2 <span>for</span> Profiler {}
<span>impl</span> CorProfilerCallback3 <span>for</span> Profiler {}
<span>impl</span> CorProfilerCallback4 <span>for</span> Profiler {}
<span>impl</span> CorProfilerCallback5 <span>for</span> Profiler {}
<span>impl</span> CorProfilerCallback6 <span>for</span> Profiler {}
<span>impl</span> CorProfilerCallback7 <span>for</span> Profiler {}
<span>impl</span> CorProfilerCallback8 <span>for</span> Profiler {}
<span>impl</span> CorProfilerCallback9 <span>for</span> Profiler {}

register<span>!</span>(Profiler);</code></pre></div>
        
</div>

<p>To generate a shared object file capable of being consumed by the .NET runtime, your cargo config file should look like the following:</p>


<div>
        
        
                <div><pre><code data-lang="toml">[<span>package</span>]
<span>name</span> = <span>"demo_profiler"</span>
<span>version</span> = <span>"0.1.0"</span>
<span>authors</span> = [<span>"Han Solo &lt;han_solo@gmail.com&gt;"</span>]
<span>edition</span> = <span>"2018"</span>
<span>license</span> = <span>"MIT"</span>
<span>repository</span> = <span>"https://github.com/camdenreslink/clr-profiler"</span>

[<span>dependencies</span>]
<span>clr_profiler</span> = <span>"0.1.0"</span>
<span>uuid</span> = <span>"0.8"</span>

[<span>lib</span>]
<span>crate</span><span>-</span><span>type</span> = [<span>"cdylib"</span>] <span># This is the key configuration value</span></code></pre></div>
        
</div>

<p>On Linux, you will also have to set the following environment variables:</p>

<ul>
<li><code>CORECLR_ENABLE_PROFILING=1</code></li>
<li><code>CORECLR_PROFILER=DF63A541-5A33-4611-8829-F4E495985EE3</code>

<ul>
<li>This should be the CLSID set in your profiler data type.</li>
</ul></li>
<li><code>CORECLR_PROFILER_PATH=/some/path/demo_profiler.so</code></li>
</ul>

<p>Here is some sample output:</p>


<div>
        
        
                <div><pre><code data-lang="text">...
Contains
Contains
GetLocaleName
IndexOf
IndexOf
IndexOf
get_LCID
LocaleNameToLCID
GetLocaleDataNumericPart
SearchCultureName
.cctor
CompareOrdinal
get_TwoLetterISOCountryName
GetLocaleInfo
GetLocaleInfo
WriteLine
WriteLine
op_Implicit
WriteSpan
MemoryCopy
...</code></pre></div>
        
</div>



<p>The .NET Profiling API is a mechanism exposed by the .NET runtime which allows an external library to hook into certain events such as garbage collection, jit compilation, and assembly loading. One step of the CLR startup routine is checking if a profiler has been registered (using the registry on Windows, and environment variables on non-Windows platforms). If one has been registered, the CLR loads the profiler library into the same OS process as the CLR itself. This allows the CLR and the profiler to communicate by efficiently passing pointers to data back and forth (no IPC overhead required).</p>



<p>.NET Profiling API interfaces are defined as COM interfaces. The following steps happen when the CLR process starts to hook the CLR and Profiling library together.</p>

<ul>
<li>The CLR will call the <code>DllGetClassObject</code> function exposed by your library.</li>
<li>This will pass back to the CLR an object that implements the <code>IClassFactory</code> interface.</li>
<li>The CLR then calls the <code>CreateInstance</code> method on the <code>IClassFactory</code> that it now has a handle to. This returns an object that adheres to one of the <code>ICorProfilerCallback</code> interfaces.</li>
<li>Now that the CLR has a handle to your profiler object, it can call the methods defined on it to provide important information about the behavior of the profiled application (e.g. <code>AssemblyLoadStarted()</code> or <code>ObjectAllocated()</code>).</li>
</ul>

<p><strong>What does it mean for an object to implement a COM interface?</strong></p>

<p>The implementation of COM is very C++-centric. COM objects are expected to be laid out in memory the same way the C++ classes are laid out. A C++ class is a struct whose first member is a pointer to an array that consists of function pointers to that class’ method implementations. This function pointer array is called a <em>virtual method table</em>, and we can replicate its structure in Rust.</p>

















    


<figure>
    
        <img src="https://code.camdenreslink.com/dev/implementing-the-dot-net-profiling-api-in-rust/img/com-class-layout.png">
    
    
</figure>

<p>Here is a simple example:</p>


<div>
        
        
                <div><pre><code data-lang="rust"><span>#[repr(C)]</span>
<span>pub</span> <span>struct</span> <span>IUnknown</span><span>&lt;</span>T<span>&gt;</span> {
    <span>pub</span> QueryInterface: <span>unsafe</span> <span>extern</span> <span>"system"</span> <span>fn</span>(
        this: <span>&amp;</span><span>mut</span> T,
        riid: <span>REFIID</span>,
        ppvObject: <span>*</span><span>mut</span> <span>*</span><span>mut</span> c_void,
    ) -&gt; <span>HRESULT</span>,
    <span>pub</span> AddRef: <span>unsafe</span> <span>extern</span> <span>"system"</span> <span>fn</span>(this: <span>&amp;</span><span>mut</span> T) -&gt; <span>ULONG</span>,
    <span>pub</span> Release: <span>unsafe</span> <span>extern</span> <span>"system"</span> <span>fn</span>(this: <span>&amp;</span><span>mut</span> T) -&gt; <span>ULONG</span>,
}

<span>#[repr(C)]</span>
<span>pub</span> <span>struct</span> <span>IMethodMalloc</span><span>&lt;</span>T<span>&gt;</span> {
    <span>pub</span> Alloc: <span>unsafe</span> <span>extern</span> <span>"system"</span> <span>fn</span>(this: <span>&amp;</span><span>T</span>, cb: <span>ULONG</span>) -&gt; <span>HRESULT</span>,
}

<span>#[repr(C)]</span>
<span>pub</span> <span>struct</span> <span>MethodMallocVtbl</span> {
    <span>pub</span> IUnknown: <span>IUnknown</span><span>&lt;</span>MethodMalloc<span>&gt;</span>,
    <span>pub</span> IMethodMalloc: <span>IMethodMalloc</span><span>&lt;</span>MethodMalloc<span>&gt;</span>,
}

<span>#[repr(C)]</span>
<span>pub</span> <span>struct</span> <span>MethodMalloc</span> {
    <span>pub</span> lpVtbl: <span>*</span><span>const</span> MethodMallocVtbl,
}</code></pre></div>
        
</div>

<p>In the above example, our COM class is implemented by the Rust struct <code>MethodMalloc</code>. It contains only a raw pointer to another struct implementing its virtual method table, <code>MethodMallocVtbl</code>. This method table contains the function pointers corresponding to the <code>IUnknown</code> and <code>IMethodMalloc</code> COM interfaces. Notice that the <code>IUnknown</code> interface is defined as the first field of the virtual method table struct. All COM classes must implement <code>IUnknown</code>. The order of the function pointers in the virtual method table is important, so care must be taken to ensure the functions are laid out correctly.</p>



<p>In-process COM servers must implement the <code>DllGetClassObject</code> function to provide a way for a client (in our case the CLR) to access instances of the COM classes it provides. In the case of a profiler, we are providing a class to the CLR that implements the <code>ICorProfilerCallback</code> interfaces. If we want to maintain Rust’s type safety, but still provide a generic way to generate a <code>DllGetClassObject</code> function that will return some provided profiler data type, we’ll need to use Rust’s <em>procedural macros</em> feature. This allows a library author to manipulate tokens of Rust source code at compile time to dynamically generate code. Here is an example procedural macro that generates a <code>DllGetClassObject</code> function definition at compile time:</p>


<div>
        
        
                <div><pre><code data-lang="rust"><span>#[proc_macro]</span>
<span>pub</span> <span>fn</span> <span>register</span>(item: <span>TokenStream</span>) -&gt; <span>TokenStream</span> {
    <span>let</span> profiler_type <span>=</span> parse_macro_input<span>!</span>(item <span>as</span> Type);
    <span>let</span> output <span>=</span> quote<span>!</span> {
        <span>use</span> clr_profiler::ffi::{ClassFactory <span>as</span> FFIClassFactory, CorProfilerCallback <span>as</span> FFICorProfilerCallback, E_FAIL <span>as</span> FFI_E_FAIL, GUID <span>as</span> FFI_GUID, HRESULT <span>as</span> FFI_HRESULT, LPVOID <span>as</span> FFI_LPVOID, REFCLSID <span>as</span> FFI_REFCLSID, REFIID <span>as</span> FFI_REFIID};
        <span>#[no_mangle]</span>
        <span>unsafe</span> <span>extern</span> <span>"system"</span> <span>fn</span> <span>DllGetClassObject</span>(
            rclsid: <span>FFI_REFCLSID</span>,
            riid: <span>FFI_REFIID</span>,
            ppv: <span>*</span><span>mut</span> FFI_LPVOID,
        ) -&gt; <span>FFI_HRESULT</span> {
            <span>let</span> profiler <span>=</span> <span>&lt;</span><span>#</span>profiler_type<span>&gt;</span>::new();
            <span>let</span> clsid <span>=</span> FFI_GUID::from(<span>*</span>profiler.clsid());
            <span>if</span> ppv.is_null() <span>||</span> <span>*</span>rclsid <span>!=</span> clsid {
                println<span>!</span>(<span>"CLSID didn't match. CLSID: {:?}"</span>, clsid);
                FFI_E_FAIL
            } <span>else</span> {
                <span>let</span> class_factory: <span>&amp;</span><span>mut</span> FFIClassFactory<span>&lt;</span><span>#</span>profiler_type<span>&gt;</span> <span>=</span> FFIClassFactory::new(profiler);
                class_factory.QueryInterface(riid, ppv)
            }
        }
    };
    output.into()
}</code></pre></div>
        
</div>

<p>The line <code>let profiler = &lt;#profiler_type&gt;::new();</code> will dynamically create an instance of the provided profiler type. This means that the type must provide an empty constructor function, or the macro will fail to compile. Some of the names are prefixed with <code>FFI</code> to prevent naming collisions within any modules that the macro is invoked.</p>



<p>Rust has certain patterns and language features that improve safety and make coding more enjoyable. Some effort was made to adapt the Profiling API method signatures to follow Rust idioms.</p>

<p><strong>Using <code>Result&lt;Ok, Err&gt;</code> to indicate potential failure</strong></p>

<p>Almost all methods in the .NET Unmanaged API return an <code>HRESULT</code>, which is a type of error code. In order to achieve returning the intended values from the method along with the error code, mutable pointers are passed into the method and populated. This can be the source of errors, because sometimes it is unclear who is responsible for allocation/deallocating memory for these data structures. The concept of ownership (Rust’s killer feature) addresses this, but we must still deal with it at the FFI (foreign function interface) boundary. For example, the following function returns a <code>ClassID</code> when provided with an <code>ObjectID</code>. A function would typically just have <code>ClassID</code> as the return type, but instead the <code>HRESULT</code> error code is the return type.</p>


<div>
        
        
                <div><pre><code data-lang="c++">HRESULT <span>GetClassFromObject</span>(  
    [in]  ObjectID objectId,  
    [out] ClassID <span>*</span>pClassId);
</code></pre></div>
        
</div>

<p>This …</p></section></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://code.camdenreslink.com/dev/implementing-the-dot-net-profiling-api-in-rust/">https://code.camdenreslink.com/dev/implementing-the-dot-net-profiling-api-in-rust/</a></em></p>]]>
            </description>
            <link>https://code.camdenreslink.com/dev/implementing-the-dot-net-profiling-api-in-rust/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24149368</guid>
            <pubDate>Thu, 13 Aug 2020 21:18:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't Worry, Python Is Not Going Away]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24148925">thread link</a>) | @bajcmartinez
<br/>
August 13, 2020 | https://livecodestream.dev/post/2020-08-13-dont-worry-python-is-not-going-away/ | <a href="https://web.archive.org/web/*/https://livecodestream.dev/post/2020-08-13-dont-worry-python-is-not-going-away/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <article>
        
        
        
        <h2>At least not anytime soon!</h2>
        
        
        <section>
            <figure>
                
                <img alt="Feature Image" width="1200" height="675" src="https://livecodestream.dev/post/2020-08-13-dont-worry-python-is-not-going-away/featured_hu4a8d7989115f0f8a2e85aed33a55a83a_96291_680x0_resize_q75_box.jpg">
            </figure>
            <p>In the last few months, perhaps a year or more, a lot of people started talking about how Python would be going away in favor of other newer programming languages like Julia, Rust, Go, etc. However today I want to discuss what the data actually show us and I’ll let you make your own conclusions (though, based on the title, you know mine).</p>
<p>Let’s get started with some of the arguments against Python.</p>
<hr>
<h2 id="whats-wrong-with-python">What’s wrong with Python</h2>
<p>There are a number of arguments against Python, and how other languages are filling that gap, or resolving some of the issues. Let’s see some of the arguments against Python.</p>
<h3 id="speed">Speed</h3>
<p>Python is <strong>SLOW</strong>, it is well known that Python can’t perform side by side to programming languages like C++, Go, or Rust (among others), but sometimes speed is not all. Python may not be the fastest programming language, but with the right setups, libraries, and coding it can support wild volumes, process huge amounts of data. Don’t be obsessed with raw speed only, most of the time you won’t need it, and the simplicity of Python and availability of developers may well compensate for the lack of speed.</p>
<h3 id="types">Types</h3>
<p>Even though since Python supports types with <a href="https://docs.python.org/3/library/typing.html">Python 3.6 - Typings</a>, it is also true that while you can annotate a variable with a type to have better code completion on your IDE, Python would still handle that variable with dynamic typing without performing any validation. If you want to have type validation you are required to do it yourself, or even better, use a Python library like <a href="https://pydantic-docs.helpmanual.io/">Pydantic</a>.</p>
<p>There are good frameworks using Python types, like FastAPI, which we covered in a previous article. <a href="https://livecodestream.dev/post/2020-08-05-quickly-develop-highly-performant-apis-with-fastapi-python/">Quickly Develop Highly Performant APIs with FastAPI &amp; Python</a>.</p>
<h3 id="its-old">It’s old</h3>
<p>I can’t believe this is an actual argument but seems like it does. Yes, Python is from the 90s, and it has a few more years than some of its contenders but it is still pretty solid. Over time not only turned out to be a great programming language but also has built a great community, a huge library repository, and much more. There are problems that date back to what was consider a best practice back then, that now is not so much, but being old by itself is not an argument.</p>
<hr>
<h2 id="the-data-to-the-rescue">The data to the rescue</h2>
<p>In order to understand why I believe Python is not going away anytime soon, we will focus on DATA, impartial (maybe), simple, old fashioned data.</p>
<h3 id="the-state-of-developer-ecosystem-2020httpswwwjetbrainscomlpdevecosystem-2020"><a href="https://www.jetbrains.com/lp/devecosystem-2020/">The State of Developer Ecosystem 2020</a></h3>
<p>We will start reviewing a recent report from JetBrains, where, in their own words, they combined results of the fourth annual Developer Ecosystem Survey with the feedback from 19,696 developers whom they surveyed in the beginning of 2020 to identify the latest trends around tools, technologies, programming languages, and many other exciting facets of the development world.</p>
<p>The first relevant question in the survey is “What are your primary programming languages?", which highlights Python on 3rd place right after JavaScript and Java. But if we look at the next question “Do you plan to adopt or migrate to other languages in the next 12 months? If so, to which ones?” We can see many Java developers planning to learn or migrate into Python. So the Python adoption is actually growing and not shrinking.</p>







    
        
        
    


<figure data-src="/post/2020-08-13-dont-worry-python-is-not-going-away/jetbrains-languages-chart_huc70f111a0316ff338676a3c4e160e73d_35691_700x0_resize_q75_box.jpg">
<img src="https://livecodestream.dev/post/2020-08-13-dont-worry-python-is-not-going-away/jetbrains-languages-chart_huc70f111a0316ff338676a3c4e160e73d_35691_417ecb468b8c004b02f2c970a15a9925.jpg" width="700" height="525" alt="JetBrains Survey 2020 - Primary Programming Languages"> <figcaption>
    <p>JetBrains Survey 2020 - Primary Programming Languages</p>
</figcaption>
</figure>

<p>The survey has other very interesting sections that go a bit off-topic of this post, so I recommend you read it in full, or you can just read the <a href="https://www.jetbrains.com/lp/devecosystem-2020/python/">Python section</a> where they talk about IDEs, what is Python being used for and other interesting stuff.</p>
<h3 id="stackoverflow-2020-developer-surveyhttpsinsightsstackoverflowcomsurvey2020"><a href="https://insights.stackoverflow.com/survey/2020">StackOverflow 2020 Developer Survey</a></h3>
<p>Probably the biggest and most important development survey out there, very interesting, I’m always participating in the character of the respondent. It has a ton of insightful questions, but let’s see what developers are saying about programming languages and Python in particular.</p>
<p>In the report one of the metrics is the popularity of technology, with the results being:</p>







    
        
        
    


<figure data-src="/post/2020-08-13-dont-worry-python-is-not-going-away/so-languages-popularity_hu9e7a47c7da82f414dbeac8e0ed976530_22242_700x0_resize_q75_box.jpg">
<img src="https://livecodestream.dev/post/2020-08-13-dont-worry-python-is-not-going-away/so-languages-popularity_hu9e7a47c7da82f414dbeac8e0ed976530_22242_091d9d22c61e795f2301614f6d1e5abc.jpg" width="700" height="390" alt="StackOverflow Developer Survey 2020 - Most Popular Programming Languages"> <figcaption>
    <p>StackOverflow Developer Survey 2020 - Most Popular Programming Languages</p>
</figcaption>
</figure>

<p>With Python on a solid 4th place after JavaScript, HTML/CSS and SQL, which if we focus only on programming languages would be 2nd right above Java, which is different compared to the previous survey, though we could see there as well the trend of people jumping to Python over Java.</p>
<p>Now things get good, one popular section in the survey is: “Most Loved, Dreaded, and Wanted Languages”, let’s see how Python stands up in each of them:</p>







    
        
        
    


<figure data-src="/post/2020-08-13-dont-worry-python-is-not-going-away/so-languages-loved_hud15b325920c9759118189179a1ea9bd8_22589_700x0_resize_q75_box.jpg">
<img src="https://livecodestream.dev/post/2020-08-13-dont-worry-python-is-not-going-away/so-languages-loved_hud15b325920c9759118189179a1ea9bd8_22589_fbe658e130bedec23d5e3e3e452342d6.jpg" width="700" height="390" alt="StackOverflow Developer Survey 2020 - Most Loved Programming Languages"> <figcaption>
    <p>StackOverflow Developer Survey 2020 - Most Loved Programming Languages</p>
</figcaption>
</figure>








    
        
        
    


<figure data-src="/post/2020-08-13-dont-worry-python-is-not-going-away/so-languages-wanted_hu48d98af3aed792df9fe60a8c9493990f_22162_700x0_resize_q75_box.jpg">
<img src="https://livecodestream.dev/post/2020-08-13-dont-worry-python-is-not-going-away/so-languages-wanted_hu48d98af3aed792df9fe60a8c9493990f_22162_139cf581c7fdc07935dadb7d03c390dc.jpg" width="700" height="390" alt="StackOverflow Developer Survey 2020 - Most Wanted Programming Languages"> <figcaption>
    <p>StackOverflow Developer Survey 2020 - Most Wanted Programming Languages</p>
</figcaption>
</figure>

<p>Again in both sections, Python is at the top, being the 3rd most loved programming language after Rust and TypeScript, and being the most loved programming language.</p>
<p>This survey is fantastic and deserves a full read if you haven’t done that already.</p>
<hr>
<h2 id="conclusion">Conclusion</h2>
<p>Python has its flaws, speed, kinda old, with old concepts, but it is still a major player, clearly a top contender and <a href="https://livecodestream.dev/post/2020-05-30-what-is-python-best-for/">widely used in a variety of projects</a> from web development to IoT and data science.</p>
<p>After seeing the numbers I understand that Python is not going away anytime soon. It will probably be a time when this may be different, but Python is a language still worth learning, exploring, and mastering.</p>
<p>Thanks for reading!</p>

        </section>

        

        <section>
            
            
            
        </section>

        <section>
    <h2>Join the Free Newsletter</h2>
    <p>A free, weekly e-mail with the best new articles, courses, and special bonuses.</p>

    




    <p>
        We won't send you spam. Unsubscribe at any time.
    </p>
</section>


        
    </article>
</div><div>
    





    <section>
        <h2>Contribute</h2>
        <p>
            If you like this article and you want to support my work, you can:
        </p>
        
    </section>
</div></div>]]>
            </description>
            <link>https://livecodestream.dev/post/2020-08-13-dont-worry-python-is-not-going-away/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24148925</guid>
            <pubDate>Thu, 13 Aug 2020 20:52:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Guide to Environment Variables in Go]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24148795">thread link</a>) | @mkfeuhrer
<br/>
August 13, 2020 | https://mohitkhare.me/blog/environment-variables-golang/ | <a href="https://web.archive.org/web/*/https://mohitkhare.me/blog/environment-variables-golang/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <!-- Toc if any -->
                
                <!-- End Toc -->
                <p>In this tutorial, I will be covering the basics around environment variables and some of the default and most used Golang environment variables. We will also learn how to set environment config from our golang programs.</p>

<p>Let’s begin!</p>

<h2 id="what-are-the-environment-variables">What are the environment variables?</h2>

<p>An <a href="https://en.wikipedia.org/wiki/Environment_variable"><em>environment variable</em></a> is a name/value pair that is present outside of the program but can be referenced at a given time. There are a lot of environment variables which are already predefined in your system. Eg. <strong>$HOME</strong></p>

<p>Trying running <code>echo $HOME</code> this will display your current user home directory. For me it’s like - <code>/home/mohit</code> . The result may vary based on your OS. Since I am using Ubuntu, the results might be different on your machine. But, concepts remains the same 😎</p>

<p>These environment variables can be set/unset or used anytime similar to how variables work in our programs.</p>

<p>You can see all the environment variables in your system with <code>env</code> command.</p>

<hr>

<h2 id="go-default-environment-variables">Go default Environment variables</h2>

<p>There are many variables that come with Golang when you install it and can be configured as per use. Some of the most used ones are -</p>

<h3 id="goroot">GOROOT</h3>

<p>This is the path where the Go standard library is located on your local filesystem. You generally won’t need to modify this unless you want to use some other versions of Go as well. It is set to <code>/usr/local/&lt;go-version&gt;</code> by default</p>

<h3 id="gopath">GOPATH</h3>

<p>This variable defines the root of your workspace. It tells Go where to look for your code. It stores all the files necessary for the development of the programs. It consists of three directories -</p>

<ul>
  <li><code>/bin</code> - where go places binaries that <code>go install</code> compile</li>
  <li><code>/pkg</code> - location of compiled package code</li>
  <li><code>/src</code> - where your go code resides</li>
</ul>

<p>By default, it is unset and points to a subdirectory named <code>go</code> in the user’s home directory. ($HOME/go on Unix, %USERPROFILE%\go on Windows)</p>

<h3 id="goproxy">GOPROXY</h3>

<p>From Go docs -</p>

<blockquote>
  <p>A Go module proxy is any web server that can respond to GET requests
for URLs of a specified form.</p>
</blockquote>

<p>GO proxy allows control over the download source and provides caching as well. This serves the <code>zip</code> archive of source code over HTTP making it faster.</p>

<p>You can use the proxy server by setting -</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre><span>export </span>GOPROXY <span>=</span> https://proxy.golang.org/
</pre></td></tr></tbody></table></code></pre></div></div>

<p>The above proxy is run by the Go team. To make changes permanent , add it to <code>~/.bashrc</code>.</p>

<h3 id="goos">GOOS</h3>

<p>GOOS defines the operating system for which to compile code. Examples are linux, darwin, windows, etc. This is an optional environment variable by default is set to empty.</p>

<hr>

<h2 id="setting-custom-env-variablesconfigs-in-go">Setting custom Env. variables/Configs in Go</h2>

<p>Now that you have learned the basics of environment variables and some default ones provided by Go, you might be wondering to use it in your own projects. Configs should be used to store all kind of important information which can be easy to change. This also provides additional security to your passwords, secret keys to be directly available in your source code and are visible to anyone who has access to code.</p>

<p>Also, various environments require different configs. Like you would want to give different config in your test/development servers to those of production servers.</p>

<p>That’s a lot of explanation but it was required so that you don’t push secrets and use configs. There are a lot of ways to manage configs in go projects via <code>.env</code>,<code>.json</code>,<code>.yaml</code>, <code>.toml</code> and other formats. For simplicity, for now we will set the environment variables via code -</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
</pre></td><td><pre><span>package</span> <span>main</span>

<span>import</span> <span>(</span>
    <span>"fmt"</span>
    <span>"os"</span>
<span>)</span>

<span>func</span> <span>main</span><span>()</span> <span>{</span>
    <span>// Set an environment variable</span>
    <span>os</span><span>.</span><span>Setenv</span><span>(</span><span>"SOME_VARIABLE"</span><span>,</span> <span>"SOME_VALUE"</span><span>)</span>

    <span>// Get the environment variable we set in previous step</span>
    <span>value</span> <span>:=</span> <span>os</span><span>.</span><span>Getenv</span><span>(</span><span>"SOME_VARIABLE"</span><span>)</span>
    <span>fmt</span><span>.</span><span>Println</span><span>(</span><span>value</span><span>)</span>

    <span>// Unset an Environment Variable</span>
    <span>os</span><span>.</span><span>Unsetenv</span><span>(</span><span>"SOME_VARIABLE"</span><span>)</span>
    <span>fmt</span><span>.</span><span>Println</span><span>(</span><span>"After unset -&gt; "</span><span>,</span> <span>os</span><span>.</span><span>Getenv</span><span>(</span><span>"SOME_VARIABLE"</span><span>))</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre><span># Output</span>
SOME_VALUE
After <span>unset</span> -&gt;
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Here, the program is pretty straightforward where we first set the variable and then fetch it with <code>os.Getenv()</code>, then we unset it using <code>os.Unsetenv()</code></p>

<p>There are a couple of other useful methods -</p>

<ul>
  <li><code>os.Environ()</code> - This returns all the environment variable which are set in key=value format.</li>
  <li><code>os.LookupEnv()</code> - This function combines the functionality of checking whether such variable exists, if yes then it returns the value.</li>
  <li><code>os.Clearenv()</code>- This method deletes all the environment variables and is useful when we are writing tests.</li>
</ul>

<p>Well, it is not a good practice to use these secrets in your code directly. To solve this there are a number of libraries like <a href="https://github.com/joho/godotenv">godotenv</a>, <a href="https://github.com/spf13/viper">viper</a> and others.</p>

<p>Here, the code below uses <code>godotenv</code> -
You can get it using <code>go get github.com/joho/godotenv</code></p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
</pre></td><td><pre><span>package</span> <span>main</span>

<span>import</span> <span>(</span>
    <span>"log"</span>
    <span>"github.com/joho/godotenv"</span>
    <span>"fmt"</span>
    <span>"os"</span>
<span>)</span>

<span>// init() is invoked before main()</span>
<span>// Loading variables before main() runs</span>
<span>func</span> <span>init</span><span>()</span> <span>{</span>
    <span>// loads values from .env into the system</span>
    <span>if</span> <span>err</span> <span>:=</span> <span>godotenv</span><span>.</span><span>Load</span><span>();</span> <span>err</span> <span>!=</span> <span>nil</span> <span>{</span>
        <span>log</span><span>.</span><span>Print</span><span>(</span><span>".env file not found"</span><span>)</span>
    <span>}</span>
<span>}</span>

<span>func</span> <span>main</span><span>()</span> <span>{</span>
    <span>// Get the REDIS_PORT environment variable</span>
    <span>redisPort</span><span>,</span> <span>found</span> <span>:=</span> <span>os</span><span>.</span><span>LookupEnv</span><span>(</span><span>"REDIS_PORT"</span><span>)</span>
    <span>if</span> <span>found</span> <span>{</span>
        <span>fmt</span><span>.</span><span>Println</span><span>(</span><span>redisPort</span><span>)</span>
    <span>}</span>
<span>}</span>

<span>// Output based on .env below</span>
<span>6379</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>In this code, we first load the environment variables from a <code>.env</code> file in this project directory. Then, we fetch the <code>REDIS_PORT</code> key. The <code>.env</code> file looks like -</p>



<h2 id="resources">Resources</h2>

<ul>
  <li><a href="https://medium.com/chingu/an-introduction-to-environment-variables-and-how-to-use-them-f602f66d15fa">Nice piece on environment variables</a></li>
  <li><a href="https://golang.org/cmd/go/">Go command line - learn about default env</a></li>
  <li><a href="https://dev.to/ilyakaznacheev/a-clean-way-to-pass-configs-in-a-go-application-1g64">Covers good ways to add configs</a></li>
</ul>

<p>Awesome! You just learned how to manage configs in Golang. There are couple of other ways to manage configs in a better way, will cover them in some other article. I hope now you can easily add configs in your projects.</p>

<p>Liked the article? Consider <a href="https://www.buymeacoffee.com/chHAzigTb">supporting me</a> ☕️</p>

<hr>

<p>Feel free to suggest improvements ✔️</p>

<p>I hope you learned something interesting and new. Don’t miss out on the latest blogs — <a href="http://eepurl.com/g2Mbc9">Subscribe now</a></p>

<p>Interested in more technology, productivity and life stuff? I share updates/knowledge almost daily on <a href="https://twitter.com/mkfeuhrer">Twitter</a>.</p>

<p>Reach out to me at <a href="https://mohitkhare.me/">https://mohitkhare.me/</a></p>

<p><strong>Keep exploring 🔎 Keep learning 🚀</strong></p>

    
            </div></div>]]>
            </description>
            <link>https://mohitkhare.me/blog/environment-variables-golang/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24148795</guid>
            <pubDate>Thu, 13 Aug 2020 20:45:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Future of Automation: The End of Silos and Rise of Workflows]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24148532">thread link</a>) | @omi1997
<br/>
August 13, 2020 | https://cto.ai/blog/the-future-of-automation-the-end-of-silos-rise-of-workflows/ | <a href="https://web.archive.org/web/*/https://cto.ai/blog/the-future-of-automation-the-end-of-silos-rise-of-workflows/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
			<!-- .cover -->
			<div>
				<p>Tooling has always been a strategically important method for engineering teams to bolster efficiency. The latest research by <a href="https://www.mckinsey.com/industries/technology-media-and-telecommunications/our-insights/developer-velocity-how-software-excellence-fuels-business-performance?cid=soc-app">McKinsey &amp; Company</a>, where 440 senior engineering executives were surveyed, demonstrates that companies are 65% likely to be more innovative with better tooling. </p><p>There’s nothing new here, engineers have always looked at tooling as a source for automation. But with the report revealing that only 5% of executives listed tooling a top three method for software enablement. With technologies rapidly rising and falling, software companies need to be leaner than ever in their adoption of automation tools. </p><p>To master this accelerating shift, technical leaders need to look at automation adoption beyond engineering departments and view the software delivery process as a cross-departmental effort. If you’re one of the many forward-looking technical leads hoping to gain strategic advantages, here’s how to ensure automation success. </p><h2 id="devops-today-and-the-automation-of-tomorrow">DevOps Today and the Automation of Tomorrow</h2><p>Traditionally, the developer tooling market has always been geared towards engineers, where DevOps specialists would craft automation, pipelines, and processes by integrating different technologies for the developer, and the graphic below shows the current tools out there.</p><!--kg-card-begin: image--><figure><img src="https://lh3.googleusercontent.com/rT9GfCt5hb7rwD2AC_bDeFI-pDxKlW8a7SZ8MSQYywCh0hNXj8UxXfs7ZmEpEPeoMB5tWFsxgBr_UpjJrSfroqayELR9eVfvWco1bjr-jOH6P4-zF-Ct97DGJjmjD4cMSzveToM7"></figure><!--kg-card-end: image--><p>In essence, the automation that the tools above provide was built with developers in mind as the end-user. The end result yields greater developer satisfaction, as their talent and imagination are given the means to shine. </p><p>As evidenced by the <a href="https://services.google.com/fh/files/misc/state-of-devops-2019.pdf">2019 State of DevOps reports</a>, the software industry values speed and automation of delivery and tasks, and the report, in particular, asserts that strong tool-chains give developers a culture of “psychological safety,” effectively bolstering team productivity. With <a href="https://stripe.com/en-ca/reports/developer-coefficient-2018">$300 billion being lost annually in developer productivity</a>, we can see a real opportunity for automation to keep saving developers, and the overall business, precious time. </p><h2 id="a-movement-to-workflows">A Movement to Workflows</h2><p>There’s already been a movement in the software industry to streamline processes with automation. For example, GitOps is streamlining source control by tightly integrating it with CI/CD. But that just doesn’t go far enough. As the developer tooling market grows, more and more tools are now required to be integrated into the software delivery process, causing greater market fragmentation. Companies like Salesforce are even launching their own DevOps platforms, meaning vendor-specific integration is more of a challenge than ever before for DevOps teams who are looking to streamline their delivery across their technology portfolio.</p><p>So, as business toolchains grow, it has become more critical than ever to eliminate silos of automation creation and empower other functions across the business, especially that outside of engineering, to be able to automate on their own. Essentially the cost of automation ownership must be lowered to allow for a more frictionless process for automation to take place. In this scenario, we see the rise of the workflow – a set of tasks and processes whereby multiple tools can be seamlessly integrated. As such, businesses must see automation outside the lens of engineering, and look to democratize its extraordinary benefits across the entire business to other departments.</p><p>A great example of a company lowering the barriers to automation is Atlassian. The company announced a <a href="https://www.computerworld.com/article/3532328/atlassian-adds-no-code-automation-to-jira-cloud-products.html">no-code workflow creator</a> for any user across it’s Jira Cloud portfolio. &nbsp; </p><p>In parallel, an interesting insight provided by McKinsey, which was missing from other reports, is the growing benefits of low-code tools. The study reveals that low-code tools help organizations adopt automation advantages at a much lower cost of ownership and allow them to exponentially increase their leverage on their development talent. The study observed that teams were able to adopt automation much faster when the barrier to automation (i.e. code complexity) is lowered. This makes automation accessible to less technical team members and enhances self-service and cross-functional accessibility to automation through workflows that they can create to their own needs. </p><p>At CTO.ai, we rethought automation from the bottom up to address these challenges. We realized that the most obvious solution was not only to lower the cost of automation through low code, but also to bring these developer tools to the place where people meet across the entire organization – Slack – and more specifically, SlackOps or DevOps in Slack (often more generally called ChatOps in the industry).</p><p>We further realized that businesses need an easy platform that all employees can leverage. By bringing the ease of chat and automation in a shared and transparent environment such as Slack, there’s an opportunity for businesses to significantly reduce inefficiencies and turbocharge productivity. </p><h2 id="a-brave-new-automation">A Brave New Automation</h2><p>With automation changing form, there will be winners and losers concerning how businesses approach the new world we’re entering. Businesses that are unwilling to begin implementing changes in their software development tooling and wider business access to workflow creation will be left behind. </p><p>For technical leadership, this is an opportunity to export engineering-based concepts and ideas such as CI/CD, automation testing, and more to other departments. Engineering departments have, generally speaking, long been ahead of other departments in regards to optimization, and use of automation. After all, engineers can code, but other departments don’t have such requirements in their job descriptions. </p><p>We at CTO.ai continue to advocate for greater use of automation for DevOps and all departments. As we continue to iterate our cutting-edge technology for Slack workflows (SlackOps), not only does the rise of the workflow become an important factor in the accessibility of automation, but also the measurement of workflow efficacy becomes even more critical. As such, companies need to be cognizant of their workflow efficacy and therefore must continue to ever optimize for scale. This is why we’re also introducing a Workflow Metrics MVP, the first-concept measurement of workflow efficiency.</p><p><em>Want to see our private demo? Contact us by<a href="https://w.cto.ai/contact-us"> clicking here </a>to see the private Alpha of the MVP.</em></p>
			</div><!-- .post-content -->
			<!-- .post-footer -->
		</article></div>]]>
            </description>
            <link>https://cto.ai/blog/the-future-of-automation-the-end-of-silos-rise-of-workflows/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24148532</guid>
            <pubDate>Thu, 13 Aug 2020 20:31:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Internationalization and Localization Matters]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24148141">thread link</a>) | @gsilva49
<br/>
August 13, 2020 | https://labcodes.com.br/blog/articles/why-internationalization-and-localization-matters.html | <a href="https://web.archive.org/web/*/https://labcodes.com.br/blog/articles/why-internationalization-and-localization-matters.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>According to the always trustworthy Wikipedia, there are approximately 360 million native English speakers in the world. We, as developers, are so used to write code and documentation in English that we may not realize that this number only represents 4.67% of the world population. It is very useful to have a common language for the communication between developers, but this doesn’t mean that the user shouldn’t feel a little bit more comfortable when using your product.</p>
<p>This post will start discussing the definition of internationalization and localization and why they matter for your application. Then we will go over some of the internationalization tools that developers have available to work on their Python and Django projects. Finally, we will present how we had to adapt our development flow to incorporate the internationalization step.</p>
<h2>Localization vs Internationalization</h2>
<p><strong>Localization (l10n</strong><sup id="fnref:1"><a href="#fn:1">1</a></sup><strong>)</strong> is the process of adapting an application, product or even a document to be more user-friendly to customers from different countries and cultures.</p>
<p>On the other hand, <strong>internationalization (i18n)</strong> is the process of enabling localization of the product on the application. Implementing a software in a way that it will know when and how to show different content depending on the costumer’s locale.</p>
<p>As the Django documentation perfectly summarizes: localization is done by translators and internationalization is done by developers<sup id="fnref:2"><a href="#fn:2">2</a></sup></p>
<p>However, this simplified definition of internationalization and localization may give the wrong impression that this is just about translation. This process entails several other adaptations needed to make users from different cultures feel more comfortable using your product, such as:</p>
<ul>
<li>Date and currency formatting</li>
<li>Currency conversion</li>
<li>Units of measurement conversion</li>
<li>Unicode characters and bidirectional text (see example below)</li>
<li>Time zones, calendar and special holidays</li>
</ul>
<p><img alt="Wikipedia homepage in English" src="https://labcodes.com.br/blog/images/internationalization/wikipedia_english.png">
<em>Wikipedia homepage in English</em></p>
<p><img alt="Wikipedia homepage in Arabic" src="https://labcodes.com.br/blog/images/internationalization/wikipedia_arabic.png">
<em>Wikipedia homepage in Arabic</em></p>
<p>With these adaptations, we can provide a better experience for the customer when using the application.</p>
<h2>How can we do that in Python?</h2>
<h3>GNU gettext</h3>
<p>There are some tools that can help localize your Python application. Starting with the GNU gettext package that is part of the Translation Project<sup id="fnref:3"><a href="#fn:3">3</a></sup>. This package offers:</p>
<ul>
<li>A runtime library that supports the retrieval of translated messages.</li>
<li>A set of conventions about how programs should be written to support message catalogs.</li>
<li>A library supporting the parsing and creation of files containing translated messages.</li>
</ul>
<p>The following code snippet is just a simple Hello World, a <code>app.py</code> file, where we are using the <code>gettext</code> Python module to create a translation object (<code>gettext.translation</code>) for our app domain, specifying a locale directory and the language that we want to translate our strings to. Then, we assign the gettext function to an underscore (a common practice to reduce the overhead of typing <code>gettext</code> for each translatable string) and, finally, we flag the string <code>“Hello World!”</code> to be translated.</p>
<div><pre><span></span><span>import</span> <span>gettext</span>

<span>gettext</span><span>.</span><span>bindtextdomain</span><span>(</span><span>"app"</span><span>,</span> <span>"/locale"</span><span>)</span>
<span>gettext</span><span>.</span><span>textdomain</span><span>(</span><span>"app"</span><span>)</span>
<span>t</span> <span>=</span> <span>gettext</span><span>.</span><span>translation</span><span>(</span><span>"app"</span><span>,</span> <span>localedir</span><span>=</span><span>"locale"</span><span>,</span> <span>languages</span><span>=</span><span>[</span><span>'en_US'</span><span>])</span>
<span>t</span><span>.</span><span>install</span><span>()</span>
<span>_</span> <span>=</span> <span>t</span><span>.</span><span>gettext</span>

<span>greeting</span> <span>=</span> <span>_</span><span>(</span><span>"Hello, world!"</span><span>)</span>
<span>print</span><span>(</span><span>greeting</span><span>)</span>
</pre></div>


<p>After flagging the translatable strings in the code, we can collect them using the GNU <code>xgettext</code> CLI tool. This tool generates a PO file containing all the strings that we have flagged.</p>
<p><code>xgettext -d app app.py</code></p>
<p>The PO file (which stands for Portable Object file) contains a list of entries and here is the basic structure of an entry:</p>
<div><pre><span></span>#  translator-comments
#. extracted-comments
#: reference…
#, flag…
#| msgid previous-untranslated-string
msgid untranslated-string
msgstr translated-string
</pre></div>


<p>We can add comments for translators, some references and flags for the string. Then we have the <strong>entry ID</strong> (<code>msgid</code>), which is the untranslated string flagged in the code and the <strong>entry string</strong> (<code>msgstr</code>) representing the translated version of the string.</p>
<p>When we run <code>xgettext</code> in the command line passing the <code>app.py</code> as input file, this is the PO file that is generated:</p>
<div><pre><span></span><span>"Project-Id-Version: PACKAGE VERSION\n"</span>
<span>"Report-Msgid-Bugs-To: \n"</span>
<span>"POT-Creation-Date: 2019-05-03 13:23-0300\n"</span>
<span>"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"</span>
<span>"Last-Translator: FULL NAME &lt;EMAIL@ADDRESS&gt;\n"</span>
<span>"Language-Team: LANGUAGE &lt;LL@li.org&gt;\n"</span>
<span>"Language: \n"</span>
<span>"MIME-Version: 1.0\n"</span>
<span>"Content-Type: text/plain; charset=UTF-8\n"</span>
<span>"Content-Transfer-Encoding: 8bit\n"</span>

<span>#</span><span>:</span> <span>app</span><span>.</span><span>py</span><span>:</span><span>7</span>
<span>msgid</span> <span>"Hello, world!"</span>
<span>msgstr</span> <span>""</span>
</pre></div>


<p>At the top of the file, we have some metadata about the file, the project and the translation process. Then, we have the untranslated string "Hello, world!" as the <strong>entry ID</strong> and an empty string for the <strong>entry string</strong>. If no translated string is provided for a certain entry, the entry ID will be used in the translation.</p>
<p>Once the PO file is generated, we can start translating our terms to different languages. It is important to notice that the GNU gettext library is going to look for translated PO files in a specific folder path structure (<code>&lt;localedir&gt;/&lt;language_code&gt;/LC_MESSAGES/&lt;domain&gt;.po</code>) and there must be one PO file for each language that you want to support.</p>
<div><pre><span></span>|-- app.py
|-- locale
   |-- en_US
   |   |-- LC_MESSAGES
   |       |-- app.po
   |-- pt_BR
       |-- LC_MESSAGES
       |   |-- app.po
</pre></div>


<p>Here is an example of the same PO file translated to Portuguese:</p>
<div><pre><span></span><span>"Project-Id-Version: PACKAGE VERSION\n"</span>
<span>"Report-Msgid-Bugs-To: \n"</span>
<span>"POT-Creation-Date: 2019-05-03 13:23-0300\n"</span>
<span>"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"</span>
<span>"Last-Translator: FULL NAME &lt;EMAIL@ADDRESS&gt;\n"</span>
<span>"Language-Team: LANGUAGE &lt;LL@li.org&gt;\n"</span>
<span>"Language: \n"</span>
<span>"MIME-Version: 1.0\n"</span>
<span>"Content-Type: text/plain; charset=UTF-8\n"</span>
<span>"Content-Transfer-Encoding: 8bit\n"</span>

<span>#</span><span>:</span> <span>app</span><span>.</span><span>py</span><span>:</span><span>7</span>
<span>msgid</span> <span>"Hello, world!"</span>
<span>msgstr</span> <span>"Olá, mundo!"</span>
</pre></div>


<p>In order to use the translated strings in the code, we need to compile the PO file into MO file using the <code>msgfmt</code> command.</p>
<p><code>msgfmt -o app.mo app.po</code></p>
<p>With the MO file in place, it is possible to change the language of the program to Portuguese in the languages input for the translation function. If we run the following code, the flagged string will get translated to “Olá, mundo!”:</p>
<div><pre><span></span><span>import</span> <span>gettext</span>

<span>gettext</span><span>.</span><span>bindtextdomain</span><span>(</span><span>"app"</span><span>,</span> <span>"/locale"</span><span>)</span>
<span>gettext</span><span>.</span><span>textdomain</span><span>(</span><span>"app"</span><span>)</span>
<span>t</span> <span>=</span> <span>gettext</span><span>.</span><span>translation</span><span>(</span><span>"app"</span><span>,</span> <span>localedir</span><span>=</span><span>"locale"</span><span>,</span> <span>languages</span><span>=</span><span>[</span><span>'pt_BR'</span><span>])</span>
<span>t</span><span>.</span><span>install</span><span>()</span>
<span>_</span> <span>=</span> <span>t</span><span>.</span><span>gettext</span>

<span>greeting</span> <span>=</span> <span>_</span><span>(</span><span>"Hello, world!"</span><span>)</span>
<span>print</span><span>(</span><span>greeting</span><span>)</span>
</pre></div>


<h3>Locale Module</h3>
<p>This module has access to POSIX locale database and is specially useful for handling dates, numbers and currencies format. The following example shows how to use the Locale library:</p>
<div><pre><span></span><span>import</span> <span>datetime</span>
<span>import</span> <span>locale</span>

<span>locale</span><span>.</span><span>setlocale</span><span>(</span><span>locale</span><span>.</span><span>LC_ALL</span><span>,</span> <span>locale</span><span>=</span><span>'en_US'</span><span>)</span>
<span>local_conv</span> <span>=</span> <span>locale</span><span>.</span><span>localeconv</span><span>()</span>
<span>now</span> <span>=</span> <span>datetime</span><span>.</span><span>datetime</span><span>.</span><span>now</span><span>()</span>
<span>some_price</span> <span>=</span> <span>1234567.89</span>
<span>formatted_price</span> <span>=</span> <span>locale</span><span>.</span><span>format</span><span>(</span><span>'</span><span>%1.2f</span><span>'</span><span>,</span> <span>some_price</span><span>,</span> <span>grouping</span><span>=</span><span>True</span><span>)</span>
<span>currency_symbol</span> <span>=</span> <span>local_conv</span><span>[</span><span>'currency_symbol'</span><span>]</span>

<span>print</span><span>(</span><span>now</span><span>.</span><span>strftime</span><span>(</span><span>'</span><span>%x</span><span>'</span><span>))</span>
<span>print</span><span>(</span><span>f</span><span>'{currency_symbol}{formatted_price}'</span><span>)</span>
</pre></div>


<p>In this example, we are importing the module, changing all locale settings to US English and retrieving the locale conventions. Using the <code>locale.format</code> method, we can format the number without worrying about decimal and thousands separator symbols. Using the <code>%x</code> directive to format the date, it will display day, month and year in the correct order for the locale. From the locale conventions, we are able to get the correct currency symbol.</p>
<p>This is the output of that Python code. We can see that the date is following the format of <code>Month/Day/Year</code>, tthe decimal separator is a dot while the thousands separator is a comma and there is a dollar sign to represent US currency.</p>
<div><pre><span></span>$ python format_example.py
<span>05</span>/03/2019
<span>$1</span>,234,567.89
</pre></div>


<p>Now using the same code, just changing the locale to Portuguese Brazil, we get a different output based on Brazilians conventions for formatting: the date is following <code>Day/Month/Year</code> format, we have comma as the decimal separator, dots as thousands separator and the R$ symbol to represent Brazilian currency Real.</p>
<div><pre><span></span><span>import</span> <span>datetime</span>
<span>import</span> <span>locale</span>

<span>locale</span><span>.</span><span>setlocale</span><span>(</span><span>locale</span><span>.</span><span>LC_ALL</span><span>,</span> <span>locale</span><span>=</span><span>'pt_BR'</span><span>)</span>
<span>local_conv</span> <span>=</span> <span>locale</span><span>.</span><span>localeconv</span><span>()</span>
<span>now</span> <span>=</span> <span>datetime</span><span>.</span><span>datetime</span><span>.</span><span>now</span><span>()</span>
<span>some_price</span> <span>=</span> <span>1234567.89</span>
<span>formatted_price</span> <span>=</span> <span>locale</span><span>.</span><span>format</span><span>(</span><span>'</span><span>%1.2f</span><span>'</span><span>,</span> <span>some_price</span><span>,</span> <span>grouping</span><span>=</span><span>True</span><span>)</span>
<span>currency_symbol</span> <span>=</span> <span>local_conv</span><span>[</span><span>'currency_symbol'</span><span>]</span>

<span>print</span><span>(</span><span>now</span><span>.</span><span>strftime</span><span>(</span><span>'</span><span>%x</span><span>'</span><span>))</span>
<span>print</span><span>(</span><span>f</span><span>'{currency_symbol}{formatted_price}'</span><span>)</span>
</pre></div>


<div><pre><span></span>$ python format_example.py
<span>03</span>/05/2019
R<span>$1</span>.234.567,89
</pre></div>


<h2>Does it get easier with Django?</h2>
<h3>Translations and Formatting</h3>
<p>Internationalization is enabled by default when you create your Django project. The translation module encapsulates the GNU library and provides the <code>gettext</code> function with translation setup based on the language received in the <strong>Accept-Language</strong> header, that is passed by the browser in the request object. So, all that Python code that we saw before is encapsulated in the django utils translation module so we can jump ahead and just use the gettext function in our view:</p>
<div><pre><span></span><span>from</span> <span>django.http</span> <span>import</span> <span>HttpResponse</span>
<span>from</span> <span>django.utils.translation</span> <span>import</span> <span>gettext</span> <span>as</span> <span>_</span>

<span>def</span> <span>my_view</span><span>(</span><span>request</span><span>):</span>
    <span>greetings</span> <span>=</span> <span>_</span><span>(</span><span>'Hello, World!'</span><span>)</span>
    <span>return</span> <span>HttpResponse</span><span>(</span><span>greetings</span><span>)</span>
</pre></div>


<p>For translations, we can flag translatable strings in both Python and template code (once we load the internationalization tags). The <code>trans</code> template tag translates a single string, while <code>blocktrans</code> tag is able to mark as translatable a block of strings, including variable content.</p>
<div><pre><span></span><span>&lt;</span><span>p</span><span>&gt;</span>{% trans "Hello, World!" %}<span>&lt;/</span><span>p</span><span>&gt;</span>
<span>&lt;</span><span>p</span><span>&gt;</span>{% blocktrans %}This string will have {{ value }} inside.{% endblocktrans %}<span>&lt;/</span><span>p</span><span>&gt;</span>
</pre></div>


<p>Besides the standard <code>gettext</code> function, in Django we can have lazy translations: the flagged string will only be translated when the value is used in a string context, such as in template rendering. This is specially useful for translating <code>help_text</code> and <code>verbose_name</code> attributes in the Django models.</p>
<p>Regarding GNU command line interface, django admin provides equivalent commands for the ones most used in the development process. To …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://labcodes.com.br/blog/articles/why-internationalization-and-localization-matters.html">https://labcodes.com.br/blog/articles/why-internationalization-and-localization-matters.html</a></em></p>]]>
            </description>
            <link>https://labcodes.com.br/blog/articles/why-internationalization-and-localization-matters.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24148141</guid>
            <pubDate>Thu, 13 Aug 2020 20:13:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Research Says Solo Founders Perform Better]]>
            </title>
            <description>
<![CDATA[
Score 157 | Comments 70 (<a href="https://news.ycombinator.com/item?id=24148113">thread link</a>) | @rmason
<br/>
August 13, 2020 | https://www.growthclub.online/post/research-says-solo-founders-perform-better-here-is-why | <a href="https://web.archive.org/web/*/https://www.growthclub.online/post/research-says-solo-founders-perform-better-here-is-why">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="7.16.2"><div dir="ltr"><div><div id="viewer-68erk"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img" aria-label=""><p><img data-pin-url="https://www.growthclub.online/post/research-says-solo-founders-perform-better-here-is-why" data-pin-media="https://static.wixstatic.com/media/49c34c_add7b504cfd8464abddc1602dcb09c96~mv2.jpg/v1/fit/w_3508,h_1981,al_c,q_80/file.png" src="https://static.wixstatic.com/media/49c34c_add7b504cfd8464abddc1602dcb09c96~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg" alt=""></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div><p><span>Better to be a Han Solo in startups? Credit: deviantart.com/dzikawa</span></p></div></div></div><p id="viewer-9t57p">A recent <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3107898" target="_blank" rel="noopener"><u>study</u></a> suggests that: </p><blockquote id="viewer-ah7c2">"Solo founders are <!-- -->more than twice as likely to own an ongoing, for-profit venture than two or more founders". </blockquote><p id="viewer-c6nq5">Or to put it in other words, ventures with solo founders are twice as likely to be profitable than ventures with 2 or more founders. See the graph below.</p><div id="viewer-5g984"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.growthclub.online/post/research-says-solo-founders-perform-better-here-is-why" data-pin-media="https://static.wixstatic.com/media/49c34c_46bd6f501d98445cb0381d51c061589d~mv2.png/v1/fit/w_2560,h_1280,al_c,q_80/file.png" src="https://static.wixstatic.com/media/49c34c_46bd6f501d98445cb0381d51c061589d~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-bd3ie">How can that be true? And what could be the dangers of being a solopreneur that founders should watch out for? Let us explore!</p><h2 id="viewer-674bv">Why solo is better</h2><p id="viewer-bhfs4">As much as it may feel scary to go alone, there are good reasons to consider building a business alone, especially if you are spending a lot of time finding a co-founder.</p><h3 id="viewer-addh7">Reason #1: Speed</h3><p id="viewer-3mptm">As the famous African proverb goes, “If you want to go fast, go alone. If you want to go far, go together.” Solo founders move faster since they don't need to worry about the team alignment on every decision. And being fast can be argued to be the biggest advantage for a startup.</p><h3 id="viewer-d4jnc">Reason #2: Founder disagreements</h3><p id="viewer-bsbd7"><a href="https://www.cbinsights.com/research/startup-failure-reasons-top/#:~:text=Not%20pivoting%20away%20or%20quickly,by%20a%20lack%20of%20progress" target="_blank" rel="noopener"><u>Top 3 reason</u></a><u>s</u> why startups fail is the founder team in-fighting. Sounds wrong to say this, but no co-founders - no problems.</p><h3 id="viewer-8l2gn">Reason #3: Lower costs</h3><p id="viewer-6jfou">It seems like there is no big difference between one person on the team and three, but at the early stage, even small differences matter a lot. Whether you need an office, and how many salaries you need to pay are all crucial questions at the start.</p><h3 id="viewer-6su88">Reason #4: Taking risks</h3><p id="viewer-bg12b">Founding a startup is a big risk. Three people who've already sacrificed quite a bit tend to be more risk-averse and the chances of someone choosing the safer path are higher. </p><h2 id="viewer-f2gim">The dangers of going solo</h2><p id="viewer-fuou5">We will be honest - going solo is not for everyone. Consider the following dangers:</p><h3 id="viewer-3t7ks">Danger #1: Funding</h3><p id="viewer-cdd78">It's the sad truth that due to Y Combinator and Paul Graham's gospel, the Zeitgeist of our times is that being a solo founder means that you just couldn't convince your friends to join and therefore can't be trusted. Solo founders tend to receive considerably less funding, yet it could also play to their advantage, allow them to grow more organically and make fewer stupid mistakes.</p><h3 id="viewer-50pot">Danger #2: Lack of support </h3><p id="viewer-cte29">Loneliness and depression hit entrepreneurs harder and solo founders harder still. Solo founders might also miss on diverse perspectives. I would advise solo founders to get something called a hands-on advisor or joining a supportive community of solo founders like <a href="https://www.growthclub.online/?utm_source=growthclub&amp;utm_medium=solo_vs_team_article_body&amp;utm_campaign=content_promo" target="_blank" rel="noopener"><u>GrowthClub</u></a>. Both of those options are described in <a href="https://www.growthclub.online/post/advice-for-solo-founders?utm_source=growthclub&amp;utm_medium=solo_vs_team_article_body&amp;utm_campaign=content_promo" target="_blank" rel="noopener"><u>my previous article</u></a>.</p><h2 id="viewer-7kknt">In sum  </h2><p id="viewer-9mv3p">Solopreneurs move faster, avoid the drama of teams falling apart, reduce costs by default, and have an easier time taking risks. That being said, they should be aware of fewer funding opportunities and build their own support system.</p><p id="viewer-4an2c">Thanks for sticking till the end! I am a hands-on advisor at<a href="https://www.growthclub.online/?utm_source=growthclub&amp;utm_medium=solo_vs_team_article_footer&amp;utm_campaign=content_promo" target="_blank" rel="noopener"> <!-- -->GrowthClub</a>. GrowthClub is a community of founders with $5K+ MRR where founders exchange growth hacks and build genuine connections in 1-on-1 video calls.</p><p id="viewer-f6iut">I started with GrowthClub as a user. I liked it so much that I ended up helping the founder. Currently, after experiencing a great inflow of founders from our launch on <a href="https://www.producthunt.com/posts/growthclub" target="_blank" rel="noopener"><u>Product Hunt</u></a> and Indie Hackers <a href="https://www.indiehackers.com/post/community-the-new-business-model-for-indie-hackers-01908d3dc3" target="_blank" rel="noopener"><u>featured article</u></a>, we are signing up 30 hand-picked founders to form the core of our platform to actively iterate the product with them.</p></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.growthclub.online/post/research-says-solo-founders-perform-better-here-is-why</link>
            <guid isPermaLink="false">hacker-news-small-sites-24148113</guid>
            <pubDate>Thu, 13 Aug 2020 20:12:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Comfortable C while Editing with Emacs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24148112">thread link</a>) | @daptaq
<br/>
August 13, 2020 | https://zge.us.to/txt/emacs-c.html | <a href="https://web.archive.org/web/*/https://zge.us.to/txt/emacs-c.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://zge.us.to/txt/emacs-c.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24148112</guid>
            <pubDate>Thu, 13 Aug 2020 20:12:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[In search of the perfect pocket device]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24148036">thread link</a>) | @todsacerdoti
<br/>
August 13, 2020 | https://isene.org/2020/08/Nerding.html | <a href="https://web.archive.org/web/*/https://isene.org/2020/08/Nerding.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p>In my lock-down geekery, I have been searching for the perfect pocket computer setup.</p>

<p>Having been an <a href="https://youtu.be/czzuz1j364E">HP calculator collector</a> since a couple of decades, I have a passion for pocket computing power with really long battery life.</p>

<p>The <a href="https://isene.org/hp-41/">HP-41</a> is an amazing calculator with months of battery life. But it is still a calculator. I also want real computing power - with the ability to run <a href="https://en.wikipedia.org/wiki/Vim_(text_editor)">VIM</a> for editing text (with a decent keyboard) and as much of other goodies as I can cram into it.</p>

<p><img src="https://isene.org/assets/posts/nerdvana.png" alt=""></p>

<p>I started my quest for the perfect pocket computer with reviving my old <a href="https://en.wikipedia.org/wiki/HP_200LX">HP-200LX</a>. It’s a very early pocket computer running DOS 5.0 - and I have VIM running on it :-) Being a DOS device, it can run <a href="http://mizj.com/">lots of nice programs</a>. Yes, it is slow, but it is cool.</p>

<p>In search for a better keyboard, I got the <a href="http://phonedb.net/index.php?m=device&amp;id=840&amp;c=ericsson_mc218">Ericsson MC218</a> (a <a href="https://en.wikipedia.org/wiki/Psion_Series_5">Psion Series 5</a> pocket computer) up and running, hoping to make it boot Linux. While this is possible, it turns out that the CF card reader on the device was flaky, so I kept searching.</p>

<p>Some forums later, and I stumbled upon an interesting project - the <a href="https://n-o-d-e.net/zeroterminal.html">Zero Terminal</a>. Now we’re talking. A Raspberry PI Zero packed with all sorts of ports and expansion capabilities. But waiting for it? I’m not the patient type…</p>

<p>But wait a minute! I always carry my <a href="https://en.wikipedia.org/wiki/Samsung_Galaxy_S20">Samsung S20 Ultra</a> anyway. Couldn’t it serve all my needs? True, the battery life sucks. But as it is my cell phone, I always have it charged, so that shouldn’t be a problem. And with my <a href="https://www.aliexpress.com/item/33044680958.html?spm=2114.search0303.3.36.3e2f50e4kUuHVD&amp;ws_ab_test=searchweb0_0,searchweb201602_0,searchweb201603_0,ppcSwitch_0&amp;algo_pvid=c05d6fa4-cb6c-4b28-aaa8-9da88e98cd0f&amp;algo_expid=c05d6fa4-cb6c-4b28-aaa8-9da88e98cd0f-5">small, foldable bluetooth keyboard</a>, I have massive computing power with me at all times. An added benefit is that it can easily use a monitor or TV screen via the built-in <i>Smart View</i>.</p>

<p>The real kicker is that it runs VIM in all its galore - even with my <a href="https://isene.org/hyperlist/">HyperList</a> plugin. It runs <a href="https://www.ruby-lang.org/en/">Ruby</a> and my whole <a href="https://isene.org/2018/08/Amar-Tools.html">Amar Tools</a> <a href="https://github.com/isene/Amar-Tools">package</a>. And <a href="https://en.wikipedia.org/wiki/LaTeX">LaTeX</a> and <a href="https://www.ssh.com/ssh/">SSH</a> and <a href="https://weechat.org/">Weechat</a> and… you name it. Lots of terminal/console programs are readily available via <a href="https://termux.com/">Termux</a>.</p>

<p>But that’s not all you can do. With the X Server app <a href="https://play.google.com/store/apps/details?id=x.org.server&amp;hl=en">XSDL</a> and the <a href="https://play.google.com/store/apps/details?id=tech.ula&amp;hl=en">UserLand</a> app, you can in fact install a full Linux distro and fire it up on your Android phone. With the full glory of both terminals and graphical software. Run an <a href="https://i3wm.org/">i3</a> session with <a href="https://wiki.archlinux.org/index.php/Rxvt-unicode">urxvt</a> terminals running <a href="http://zsh.sourceforge.net/">zsh</a>, <a href="https://www.gimp.org/">Gimp</a>, <a href="https://www.libreoffice.org/">LibreOffice</a> and whatnot. Now, that’s Nerdvana!</p>

<p><img src="https://isene.org/assets/posts/userland.png" alt=""></p>

<p>So, from my HP-41, via the HP-200LX, the MC218 and looking at Zero Terminal, I found the answer right here in my pocket. Quite a detour. But ending in bliss :-)</p>

<hr>
<p>Link to this post: <a href="https://isene.org/2020/08/Nerding.html">https://isene.org/2020/08/Nerding.html</a></p>

            </div></div>]]>
            </description>
            <link>https://isene.org/2020/08/Nerding.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24148036</guid>
            <pubDate>Thu, 13 Aug 2020 20:08:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using GPT-3 to enrich NPC interactions in MUDs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24148003">thread link</a>) | @teebes
<br/>
August 13, 2020 | https://blog.writtenrealms.com/gpt3/ | <a href="https://web.archive.org/web/*/https://blog.writtenrealms.com/gpt3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>How Written Realms is using the latest generation of Artificial Intelligence to animate its fictional worlds.</p><div>
<p>We were fortunate enough to receive an invite to the <a href="https://openai.com/blog/openai-api/">OpenAI private beta</a> a few weeks ago, gaining an interface to their <a href="https://arxiv.org/abs/2005.14165">GPT-3</a> engine. Using AI for mob interactions within <a href="https://writtenrealms.com/">Written Realms</a> had been a long term goal of ours for many years, and we jumped at the opportunity to play with it.</p>
<h2 id="howtheopenaiapiworks">How the OpenAI API works</h2>
<p>The OpenAI API provides a 'completion' endpoint (also available as a Python binding) for interacting with the GPT-3 engine.</p>
<p>Given a text prompt, the API attempts to complete the pattern that you gave it. For example if you give it an input of <code>1 2 4 8</code> and request 1 token back, you will get a response of: <code>16</code>. The API understood the pattern to be a doubling function and gave the next result.</p>
<p>It's not limited to math. If you give as input <code>Barking is to dogs as meowing is to</code>, you will get as a result: <code>cats</code>.</p>
<p>Not only is GPT-3 good at reading comprehension, but it also good at tailoring its output to match the style of the input. Consider the following prompt:</p>
<pre><code>Tom went fishing all afternoon. He comes home to his wife at sunset, who asks him a question.

Question: What did you do today?
Answer:
</code></pre>
<p>The API returns <code>I went fishing.</code> </p>
<p>It is possible to get a more creative answer by providing more information in the prompt and turning up the <code>temperature</code> setting, which gives GPT-3 more of a creative license to make stuff up. For example, if after adding <code>Tom responds enthusiastically, providing many details.</code> to the prompt before the question and turning the temperature to its max value, here's how the API responded: </p>
<pre><code>I went fishing all day, and in the afternoon I fought the biggest fish that I have ever seen before. I just held on for as long as I could, because once I gave up there was no way I was getting the fish back again. I had to pull everything I could, and my catch ended up weighing 3 pounds of flounder and 4 pounds of bluegill.
</code></pre>
<p>Evidently, GPT-3 is quite proficient at making stuff up given the right temperature.</p>
<h2 id="howwereusinggpt3">How we're using GPT-3</h2>
<p>For our first foray into GPT-3, we created a Historian NPC (Non-Player Character) who is able to answer arbitrary questions about Edeus, our flagship world. All of our lore is original and it can be challenging to impart it all to the players at once. An AI able to answer the organic questions of a player in real-time seemed like a perfect use-case.</p>
<p>We already had a feature called 'Reactions' that allows NPCs to respond to something said in their room with predetermined commands. The adjustment made here was to add a <code>gpt</code> flag to the Historian which at reaction time forwards the user's input to OpenAI in order to get the response.</p>
<p>As with the fisherman above, we can use the dialog pattern, and precede it with a certain context, which explains to GPT-3 what the background is for the interactions. In this case, we gave it an excerpt from a fictional history book written by the NPC in question, and then provided a little bit of background about the NPC himself. Here is a sample interaction with him:</p>
<pre><code>You say 'hello there'
Grae the Historian says 'Greetings, traveler.'

You say 'Who are you?'
Grae the Historian says 'I am Historian Grae, a Priest of the Church of Thune.'

You say 'Where are we?'
Grae the Historian says 'You are in Bluefinch, a village in the realm of Saphrin.'

You say 'Is there anything I should be doing?'
Grae the Historian says 'You should be killing orcs.'

You say 'Why? What have the orcs ever done to us?'
Grae the Historian says 'The orcs are evil. They want to destroy us.'

You say 'Okay. Can you tell me more about our origin?'
Grae the Historian says 'Humans were created by Thune, the Allmighty God.'

You say 'Who rules this area?'
Grae the Historian says 'The King of Saphrin, Arctus Kerinin, rules this area.'

You say 'Thanks Grae! You've been very helpful'
Grae the Historian says 'You're welcome.'
</code></pre>
<p>If you want to test this out for yourself, Grae is located 3 north, 1 east of Bluefinch Square in Edeus. We're always tweaking his backstory and various settings so his outputs may (and should!) vary a bit.</p>
<h2 id="theknowledgeexclusionlimitation">The Knowledge Exclusion Limitation</h2>
<p>The main issue we've been running up against is that it's difficult to constrain the AI's knowledge to that of a fictional world. It cannot help knowing things about the real world. For example:</p>
<pre><code>You say 'When was JFK born?'
Grae the Historian says 'John Fitzgerald Kennedy was born on May 29, 1917.'
</code></pre>
<p>Ideally, the historian would not know about anything outside of Edeus. But even though we specify in the prompt's backstory that he only answers questions pertaining to his own world, that distinction is not always understood. It's difficult to exclude knowledge.</p>
<h2 id="futureimprovements">Future Improvements</h2>
<p>We plan to keep iterating and try to make the AI feel as human and authentic as possible. One issue is that currently each interaction with the NPC is its own isolated event. For example:</p>
<pre><code>You say 'What is the name of this village?'
Grae the Historian says 'This village is called Bluefinch.'

You say 'Where did it get its name from?'
Grae the Historian says 'Edeus is named after the two titans that fought in the First Age. Thune and Raeshyk.'
</code></pre>
<p>Clearly the NPC didn't connect that the second question was a follow-up from the first. This is because each time we do a call to OpenAI we append the user's query to the end of the same base prompt, making each a separate interaction. It could be improved upon by including a few of the previous back and forths when generating a new prompt, provided it was the same player.</p>
<p>There's also entirely different ways we could leverage GPT-3. For example, it could be used to generate content like room, character and item descriptions, or even dynamic quests. A text-based platform and a text-based AI share great synergy, and the possible applications of it seem endless to the imaginative.</p></div></div>]]>
            </description>
            <link>https://blog.writtenrealms.com/gpt3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24148003</guid>
            <pubDate>Thu, 13 Aug 2020 20:06:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Post-Open Source]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24147804">thread link</a>) | @OberstKrueger
<br/>
August 13, 2020 | https://www.boringcactus.com/2020/08/13/post-open-source.html | <a href="https://web.archive.org/web/*/https://www.boringcactus.com/2020/08/13/post-open-source.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
    <p>i’m writing this like a day after <a href="https://www.fastcompany.com/90539632/mozilla-vows-mdn-isnt-going-anywhere-as-layoffs-cause-panic-among-developers">big mozilla layoffs</a> that included a lot of people working on cool and important shit.
the consensus i’m seeing is that it reflects mozilla’s search for profit over impact, mismanagement, and disproportionate executive compensation.
this is taking place in a larger trend of corporatization of open source over the past several years, an ongoing open source sustainability crisis, and of course COVID-19, the all-consuming crisis that makes all our other crises worse.
all of this was summed up most concisely by <a href="https://twitter.com/zkat__/status/1293626135142477825">Kat Marchán</a>:</p>

<blockquote>
  <p>Imo, open source as a community endeavor is falling apart right before our eyes, and being replaced by open source as Big Corp entrenchment strategy.</p>

  <p>I mean it’s been happening for a while, but seeing Mozilla sinking like this is just driving the point home for me.</p>

  <p>FOSS is dead</p>
</blockquote>

<p>how did we get here?
where even are we?
what happens next?</p>

<p>i am incredibly unqualified to answer any of this - i didn’t show up until right around the peak of SourceForge, i wasn’t there for most of this - but i’m not gonna let that stop me.</p>

<h2 id="names">names</h2>

<p>to start this funeral service for FOSS, we have to unpack the term itself.
“free and open source software” as a term already contains multitudes.
on one hand, “free software”, an explicitly political movement with a decidedly anti-charismatic leader.
on the other hand, “open source software”, defanged and corporate-friendly by design.
the free software people (correctly) criticize “open source” as milquetoast centrism.
the open source people (correctly) criticize “free software” as stubborn idealism fighting tooth and nail to reject the real world as it actually exists.
they have as much in common as leftists and liberals (but they’re more prepared to work together), and although their short-term goals were similar enough that it made sense to lump them together (hence the cooperation), now that the movement is dead i think there’s more to gain from considering them separately.
most software licenses that i’m going to bring up technically qualify as both, but they’re popular with one or the other, so i’ll refer to “free software licenses” and “open source licenses” as licenses that are more directly tied to those movements, even though any given license likely meets both definitions.</p>

<p>i’d say free software died a while ago, and open source went horribly right.</p>

<h2 id="freedom">freedom</h2>

<p>the free software movement, for all its faults, has always known <a href="https://www.gnu.org/philosophy/free-sw.html.en">what it’s about</a>:</p>

<blockquote>
  <ol>
    <li>The freedom to run the program for any purpose.</li>
    <li>The freedom to study how the program works, and change it to make it do what you wish.</li>
    <li>The freedom to redistribute and make copies so you can help your neighbour.</li>
    <li>The freedom to improve the program, and release your improvements (and modified versions in general) to the public, so that the whole community benefits.</li>
  </ol>
</blockquote>

<p>it’s concise, it’s understandable, and it’s… kinda useless.
this point was <a href="https://lu.is/blog/2016/03/23/free-as-in-my-libreplanet-2016-talk/">raised better by actual lawyer Luis Villa</a> (Karl Marx slander notwithstanding), but those freedoms don’t actually mean shit to the average end user.
only programmers care if they have access to the source code, and most people aren’t programmers.
and i <em>am</em> a programmer, and i don’t give a shit.
the freedom to not think about my operating system and just get work done overrules all of those for me, so i use windows.
like, yeah, those things are all in principle nice to have, and between two otherwise equally good programs i’d take the free one.
but they’re really fuckin specific things, and even if i have the freedom to do them i’m not likely to have the ability or desire to do them, so there’s no good reason for me as a user to use software that’s worse in other ways because it gives me freedoms i don’t need.</p>

<p>the free software movement is explicitly political, but its politics suck.
it’s a movement by and for ideological diehards but the ideology is extremely esoteric.
theirs was a losing battle from day one.
so what was it that actually killed them?
i think in a very real way it was the GPLv3.</p>

<h2 id="losing">losing</h2>

<p>the flagship projects of the free software movement are probably Linux and the GNU pile of tools.
the Linux kernel being released under a free software license doesn’t directly create more free software, though, since even things that tie closely to the kernel aren’t obligated to also be free software, and of course user-level applications can have whatever license they want.
and also most of the people using Linux right now are using it by accident, distributed as ChromeOS or Android, neither of which is free software.
so Linux is a win for the free software movement but a useless one.</p>

<p>the GNU userland tools are, for the most part, even more underwhelming.
it may be technically more accurate to call it GNU/Linux, but the only time i remember my linux userland tools are GNU or free software at all is when there’s <a href="https://twitter.com/boring_cactus/status/1166408436386430976">some weird inconsistency between a GNU tool and its BSD equivalent</a>, and that’s not exactly ideal.
gcc had, as far as i can tell, been basically <em>the</em> C compiler for a while, if you weren’t stuck with MSVC or something worse.
the free software movement were stubborn ideologues with weird priorities, but they still had one big technical advantage.
then the GPLv3 happened.</p>

<p>the GPLv2 was pretty popular at the time, but there were a couple notable loopholes some big corporations had been taking advantage of, which the free software people wanted to close.
a whole bunch of people thought the GPLv2 was fine the way it was, though - closing the loopholes as aggressively as the GPLv3 did cut off some justifiable security measures, and some people said that it could do more harm than good.
the linux kernel, along with a lot more stuff, declared it was sticking with the GPLv2 and not moving to the GPLv3.
when your movement says “here is the new version of The Right Way To Do Things” and several of your largest adherents say “nah fuck you we’re going with the old version” that is not a good sign.
around the same time, free software organizations were starting to successfully sue companies who were using free software but not complying with the license.
so big companies, like Apple, saw new restrictions coming in at the same time as more aggressive enforcement, and said “well shit, we want to base our software on these handy convenient tools like GCC but we can’t use GPLv3 software while keeping our hardware and software as locked together as we’d like.”
so they started pouring money into a new C compiler, LLVM, that was instead open source.</p>

<p>and LLVM became at least as good as GCC, and a less risky decision for big companies, and easier to use to build new languages.
so the free software movement’s last technical advantage was gone.
its social advantages also kinda went up in flames with the GPLv3, too: the software that was the foundation for the GPL enforcement lawsuits stuck with the GPLv2.
the discourse over that decision was so nasty that the lead maintainer (Rob Landley; he’ll come up later) started an identical project which he wound up relicensing under an open source license because the lawsuits had completely backfired: instead of complying with the terms of the GPL, companies were just avoiding GPL software.</p>

<p>the free software movement, in the end, burned itself out, by fighting for a tiny crumb of success and then turning around and lighting that success on fire.
the death of free software tells us that we can’t use a license to trick corporations into sharing our values: they want to profit, and if good software has a license that puts a limit on how much they can do that, they’ll put more resources into writing their own alternative than they would spend complying with the license in the first place.</p>

<h2 id="openness">openness</h2>

<p>the open source movement manages to share the same short term goals as the free software movement but be bad in almost entirely disjoint ways.
the <a href="https://opensource.org/about">mission of the Open Source Initiative</a> says</p>

<blockquote>
  <p>Open source enables a development method for software that harnesses the power of distributed peer review and transparency of process.
The promise of open source is higher quality, better reliability, greater flexibility, lower cost, and an end to predatory vendor lock-in.</p>
</blockquote>

<p>this is so profoundly different from the free software definition that it’s almost comical.
where free software says “we value freedom, which we define in these ways,” open source says “your code will get better.”
the free software movement was prepared to start fights with corporations that used their work but didn’t play by their rules.
the open source movement was invented to be a friendly, apolitical, pro-corporate alternative to the free software movement.</p>

<p>the contrast between “use free software because it preserves your freedom” and “use open source software because it’s better” is profound and honestly a little disappointing to revisit this explicitly.
free software preserves freedoms i don’t need or care about as a user, but it does at least do that.
open source software is frequently not in fact better than closed source alternatives, and “use open source software because on rare occasions it manages to be almost as good” is an even more underwhelming sales pitch than anything free software can give.</p>

<p>where free software is misguided and quixotic, open source is spineless and centrist.
and as tends to happen with spineless centrism, it has eaten the world.</p>

<h2 id="winning">winning</h2>

<p>if there’s anything corporations love more than rewriting software so it lets them make all the money they can dream of, it’s letting other people do that work for them.
it took a while to take off, because the conservative approach of “keep things closed source” was pretty solidly entrenched in a lot of places, but now even the once conservative holdouts have accepted the gospel of centrism.
corporations have little to nothing to lose by publishing existing source code, and can gain all sorts of unpaid volunteer labor.
if they start a new internal project, important enough that they’re …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.boringcactus.com/2020/08/13/post-open-source.html">https://www.boringcactus.com/2020/08/13/post-open-source.html</a></em></p>]]>
            </description>
            <link>https://www.boringcactus.com/2020/08/13/post-open-source.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24147804</guid>
            <pubDate>Thu, 13 Aug 2020 19:54:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Brain Compatible Programming]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24147008">thread link</a>) | @pbw
<br/>
August 13, 2020 | https://tobeva.com/articles/brain-compatible-code/ | <a href="https://web.archive.org/web/*/https://tobeva.com/articles/brain-compatible-code/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://tobeva.com/articles/brain-compatible-code/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24147008</guid>
            <pubDate>Thu, 13 Aug 2020 19:05:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Blanket Solutions and Microservices]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24146926">thread link</a>) | @stopachka
<br/>
August 13, 2020 | https://stopa.io/post/236 | <a href="https://web.archive.org/web/*/https://stopa.io/post/236">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span><p>Much of my system design philosophy was forged during my time at Facebook. We did a lot of things differently that I think was responsible for our technical success. I want to share one of them with you. It’s the most common pitfall I've see prevalent in our industry, and it relates how we solve problems at the system level. I’ll illustrate it with a story:</p><h2>Beginning</h2><p>You kick off your startup. One service, one repo, one database. Version zero ships quickly. You iterate and iterate until you sense product market fit. </p><p>All of a sudden, you’ve got it and you’re on a rocket ship. You grow your team, you’re onboarding customers, and you’ve got some great problems on your hands. </p><h2>Emergency</h2><p>One of those problems: your systems break.</p><p>Your build infrastructure slows down. Deployment becomes an all-day, panic-ridden affair. Commits start to break unrelated components more and more frequently. The development environment becomes slower and slower. You get incidents left and right. Oncall becomes more demanding than a newborn at night.</p><p>Slow down productivity and you’ll get grumpy engineers, but take away their sleep and you’ll get rioting engineers. Now you have an emergency on your hands. </p><h2>Light in the Darkness</h2><p>You look around, and the technical debt is overwhelming. You think: it’s time to grow up. You research and land on microservices as the answer. It seems to solve all your biggest pain points:</p><p><strong><em>Speed up deployments</em></strong></p><p>Teams can manage their own deployments. Because deploying smaller systems is easier and safer than larger ones, your teams can now deploy faster. Heck, they could even roll back now.</p><p><strong><em>Separate concerns</em></strong></p><p>You’ll force stronger code boundaries. No more commits breaking unrelated components</p><p><strong><em>Empower teams</em></strong> </p><p>You’ll be able to use the right tools for the job. No more need to have the same language or stack. Teams can use whatever will make the most productive at solving their particular problem.</p><p><strong><em>Ensure quality</em></strong></p><p>You’ll be able to clarify ownership. No more spaghetti code because service owners will ultimately be responsible</p><h2>Uh Oh</h2><p>This is the dream. You kick off that initiative. But…you see some serious costs:</p><p><strong><em>Hardened boundaries are harder to change</em></strong></p><p>Those strict code boundaries come with their own costs. If you split incorrectly, you’re prone to dupe your data and your logic. But, even if you split correctly, what happens when your business needs change? What if you get new regulation that requires system-wide changes? All of a sudden, the way you split those services won’t make sense anymore, and evolving those boundaries become a magnitude more difficult.</p><p><strong><em>Hardened boundaries make it more difficult to ship unanticipated changesets</em></strong></p><p>What if you need to make changes that your org and service structure didn’t anticipate? These changes won’t cleanly fit into one service, or even groups of services. All of a sudden a change that could have been done by one engineer before requires teams to align to deliver. </p><p><strong><em>Hardened boundaries reduce the potential impact of your engineers</em></strong></p><p>What if one of your engineers comes up with a performance improvement, or a new idea for the business? Their impact is now constrained by the services they have control over. If the languages are different they won’t be able to actualize that performance improvement for the whole company. Even if we force all services to use the same language, delivering that to all services becomes a difficult affair.</p><p><strong><em>More Incidental complexity</em></strong></p><p>Sharing code, managing deploys, logging infrastructure, service orchestration, rpc are all made more difficult by a change to multiple services. None of the added difficulty helps you move faster or ship with higher quality. </p><h2>Root Cause</h2><p>Why so many unanticipated issues? Because microservices as a strategy is a <strong>blanket solution.</strong> </p><p>Blanket solutions don’t <em>specifically</em> address any one issue, but try to address a multitude of issues. This is often done with philosophy (new principles we will follow to build things) then with technology (how exactly we will solve problems). Whenever a solution addresses a multitude of issues with philosophy, it’s likely to come with a multitude of unanticipated problems.</p><h2>An Alternative Path</h2><p>The alternative path is evolution. As a rule of thumb, the changes you introduce should concretely solve the problems you care about. This doesn’t mean that all solutions need to be iterative, but it does mean that all solutions need to be under strong selection pressure. Every solution should have immediate wins in sight.</p><p>For example: </p><p><strong><em>Deployment, CI, logging issues?</em></strong> </p><p><em>What if you built a centralized team that owned that complexity, and built infrastructure so product engineers didn’t have to worry about it? For example, most product engineers did not have to worry about deploys, observability, or logging at Facebook. Infra was already in place that they could leverage, managed by an underlying team.</em></p><p><strong><em>Code boundary issues?</em></strong> </p><p><em>What if you evolved your system to use</em> <em>immutable structures</em> <em>and</em> <em>smaller interfaces between boundaries**?  What if you pushed some of these problems down the stack? For example, there may be a lot of complexity introduced with privacy. You can centralize that concern, into building infrastructure with a small interface, that product engineers can use. Facebook did this with viewer context</em></p><p><strong><em>Scaling issues?</em></strong>  </p><p><em>This may be a true concern, but instead of applying a general philosophy, could we focus on solving this problem directly? Do all systems need to scale independently, or does it only matter that just a few things scale independently?  exactly are the problems? Could you address with</em> <em>only changing the hottest, most intensive paths?</em></p><p><strong><em>Complexity issues?</em></strong> </p><p><em>Where is the complexity exactly? Could we evolve modules so you could localize the reasoning behind them? Could we abstract the difficult portions? Sophie Alpert gives a great example of this</em> <a href="https://sophiebits.com/2020/01/01/fast-maintainable-db-patterns.html" target="_blank"><em>here</em></a></p><p>This kind of thinking leads to a philosophy of system design based on simplicity:</p><p><em>You address problems concretely with a view towards evolving your system.</em> At each step of the way, you constantly optimize for engineering velocity. Engineering velocity is a great metric to use, because it implies correctness and quality alongside with speed. It’s impossible to ship if you don’t have confidence in your system. You push and centralize complexity down the stack. You evolve your system so product engineers can think locally within the module they’re working on. You make changes that empower any engineer to drive impact throughout the stack.</p><p>Doing this won’t be a magic pill — it will look like your system is constantly broken and in need of improvement — but that is its secret weapon. You’re constantly evolving it. </p><p><em>Thanks to Daniel Woelfel, Jacky Wang, Kam Leung, Joe Averbukh, Phil Nachum, Alexandre Lebrun, for reviewing drafts of this essay</em></p></span></p></div></div></div>]]>
            </description>
            <link>https://stopa.io/post/236</link>
            <guid isPermaLink="false">hacker-news-small-sites-24146926</guid>
            <pubDate>Thu, 13 Aug 2020 18:59:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Algorithmic Casting Director]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24146795">thread link</a>) | @mikeberv
<br/>
August 13, 2020 | https://www.billiondollarstartupideas.com/ideas/algorithmic-casting-director | <a href="https://web.archive.org/web/*/https://www.billiondollarstartupideas.com/ideas/algorithmic-casting-director">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-6b4b2d22430cb673522b"><div><p><strong>Problem: </strong>There about <a href="https://work.chron.com/statistics-people-getting-famous-acting-23946.html#:~:text=According%20to%20this%20estimation%2C%20in,U.S.%2C%20both%20employed%20and%20unemployed.">135,600 actors in the US</a> that are both employed and unemployed. Globally this number is even higher. Given this, it is extremely difficult for casting directors to find high-quality talent.</p><p><strong>Solution: </strong>An algorithmic casting director that can analyze the audio and video submissions from candidates to determine if they would be a good fit for the role. Right now, casting directors have to watch each individual video in order to determine whether or not to move someone forward in the process. Given that these directors are looking at hundreds or thousands of videos, this leads to implicit bias. Thus, the business would attempt to eliminate bias and increase diversity in casting by being more objective and (hopefully) more accurate in finding high-quality artists.</p><p>One great model for this business is HireVue. As the <a href="https://www.washingtonpost.com/technology/2019/10/22/ai-hiring-face-scanning-algorithm-increasingly-decides-whether-you-deserve-job/">Washington Post wrote in October 2019</a>, </p><blockquote><p><em>Designed by the recruiting-technology firm HireVue, the system uses candidates’ computer or cellphone cameras to analyze their facial movements, word choice and speaking voice before ranking them against other applicants based on an automatically generated “employability” score.</em></p><p><em>HireVue’s “AI-driven assessments” have become so pervasive in some industries, including hospitality and finance, that universities make special efforts to train students on how to look and speak for best results. More than 100 employers now use the system, including&nbsp;</em><a href="https://jobs.hilton.com/select-country.php" target="_blank"><em>Hilton</em></a><em>&nbsp;and&nbsp;</em><a href="https://www.unilever.com/careers/" target="_blank"><em>Unilever</em></a><em>, and more than a million job seekers have been analyzed.</em></p></blockquote><p>Some researchers claim that “digital snake oil — an unfounded blend of superficial measurements and arbitrary number-crunching that is not rooted in scientific fact.“ While this is a fair concern, one assumption is that in the next decade as AI and ML technologies advance, these systems will become more and more accurate and trustworthy. </p><p>Some of the most successful casting agencies <a href="https://www.managerskills.org/management/talent-agencies/">make upwards of $7 billion annually</a>. Major players in this field include CAA, <a href="http://www.icmtalent.com/">ICM</a>, <a href="https://www.wmeagency.com/">William Morris</a> (<a href="https://www.nytimes.com/2009/04/28/business/media/28talent.html">merged with Endeavour about a decade ago</a>), and <a href="https://www.businessinsider.com/wme-acquires-img-in-huge-22-billion-deal-2013-12">Silver Lake Partners</a> (<a href="https://deadline.com/tag/silver-lake-partners/">details about them</a> here, they also <a href="https://deadline.com/2012/05/wme-internally-announces-equity-partner-265482/">own 31% of WME</a>). You can learn more about this indsutry and these companies in the <a href="https://www.sec.gov/Archives/edgar/data/1766363/000119312519155034/d681105ds1.htm">SEC filing</a> (<a href="https://deadline.com/2019/05/endeavor-ipo-ari-emanuel-patrick-whitesell-executive-compensation-financials-board-makeup-1202623220/">write-up here</a>) from Endeavour Operating Company (which eventually was pulled due to weak investor demand, as you can read <a href="https://www.marketwatch.com/story/entertainment-giant-endeavor-is-going-public-5-things-to-know-ahead-of-its-ipo-2019-05-31">here</a> and <a href="https://www.reuters.com/article/us-endeavor-group-ipo/talent-agency-endeavor-abandons-ipo-amid-weak-investor-demand-idUSKBN1WB2HD">here</a>).</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597343379751_29394"><div><p><strong>Monetization: </strong>Subscription service for actors and/or directors. Additionally, a percentage of earnings from people who get roles through the platform.</p><p><strong>Contributed by: </strong><a href="https://www.michaelbervell.com/">Michael Bervell</a> (Billion Dollar Startup Ideas) and <a href="https://www.broadwayworld.com/people/Laura%2BSky-Herman/">Laura Sky Herman</a> (Broadway Actress)</p></div></div></div>]]>
            </description>
            <link>https://www.billiondollarstartupideas.com/ideas/algorithmic-casting-director</link>
            <guid isPermaLink="false">hacker-news-small-sites-24146795</guid>
            <pubDate>Thu, 13 Aug 2020 18:48:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Windows 10 UX deep copy on Linux]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24146508">thread link</a>) | @1337shadow
<br/>
August 13, 2020 | http://www.linuxfx.org/index.php/sistemas-operacionais/linuxfx-10-w | <a href="https://web.archive.org/web/*/http://www.linuxfx.org/index.php/sistemas-operacionais/linuxfx-10-w">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="g-page-surround">
                                    

                                            
                <section id="g-top">
                
        
    </section>
                
                                
                
    
                <section id="g-container-9688">
                <div>                    <div>                        

        <div>
             <section id="g-mainbar">
                                        <div>                        

        <div>
             <div>
                                                            <div><div><div itemscope="" itemtype="https://schema.org/Article">
	<meta itemprop="inLanguage" content="pt-BR">
	
		
			
					
		
	
	
		
								<div itemprop="articleBody">
		
<p><a href="https://www.youtube.com/watch?v=gFss_DliNPE" target="_blank" rel="noopener noreferrer"><img src="http://www.linuxfx.org/images/desktop_mini.jpg" alt=""></a></p>
<p><span><strong>LINUXFX 10.4.2 WX DESKTOP</strong></span></p>
<p><span><strong>LINUXFX NO TELEGRAM PT-BR :&nbsp;<a href="https://t.me/linuxfxbr">https://t.me/linuxfxbr</a></strong></span></p>
<p><span><strong>LINUXFX NO TELEGRAM EN :&nbsp;<a href="https://t.me/linuxfxen">https://t.me/linuxfxen</a></strong></span></p>

<p><span>O projeto Linuxfx / Windowsfx foi desenvolvido para ajudar usuários do Microsoft© Windows® a migrarem de maneira direta para o Linux, aproveitando toda sua curva de aprendizado. Aproveitar o hardware que não suporta a versão mais nova do&nbsp;Microsoft© Windows® também é uma diretiva do Linuxfx, assim como prover suporte a rede, Active Directory, programas .exe e .msi, navegação segura e proteção contra vírus. Utilizando o Linuxfx / Windowsfx no seu computador, você terá um sistema rápido, que consome pouca memória e é imune a vírus&nbsp;desenvolvido para a plataforma&nbsp;Microsoft© Windows®.</span></p>


<p><span>Linuxfx 10.4 WX Desktop System Core</span></p>
<ul>
<li><span><strong>Tema</strong>: WX Desktop (Windows 10 <a href="https://b00merang.weebly.com/windows-10.html" target="_blank" rel="noopener noreferrer">b00merang theme</a>)</span></li>
<li><span><strong>Gerenciamento de processos de núcleo</strong>: Linuxfx Pro System Pack</span></li>
<li><span><strong>Gerenciador de janelas</strong>: Cinnamon 4.6</span></li>
<li><span><strong>Compatibilidade com rede A.D</strong>: CID, PBIS (beyond trusty)</span></li>
<li><span><strong>Compatibilidade com rede Microsoft®</strong>: SAMBA + Linuxfx Pro Network Tools</span></li>
<li><span><strong>Desktop virtual</strong>: Citrix, Vmware, Rdesktop</span></li>
<li><span><strong>Assistência remota</strong>: Anydesk, Teamviewer</span></li>
<li><span><strong>Compatibilidade com Microsoft® Windows®</strong>: Wine + Linuxfx Pro Cross Specs</span></li>
<li><span><strong>Sistema base</strong>: Ubuntu 20.04 LTS</span></li>
</ul>


<p><span><a title="Download Etcher" href="https://etcher.io/" target="_blank" rel="noopener noreferrer"><img src="https://dl2.macupdate.com/images/icons256/57903.png?d=1524853176" alt="Resultado de imagem para etcher logo" width="125" height="125"></a></span></p>
<p><span><a title="Download Etcher" href="https://etcher.io/" target="_blank" rel="noopener noreferrer"><img src="http://resin.io/blog/content/images/2017/02/etcher-logo.jpg" alt="Resultado de imagem para etcher logo" width="424" height="77"></a></span></p>
<p><a title="Download Etcher" href="https://etcher.io/" target="_blank" rel="noopener noreferrer"><strong><span>UTILIZE O ETCHER PARA GRAVAR O LINUXFX</span><span>&nbsp;</span></strong></a></p>


<p><span><a href="https://sourceforge.net/projects/linuxfxdevil/" target="_blank" rel="noopener noreferrer"><img src="http://www.linuxfx.org/images/pc.png" alt=""></a></span></p>
<p><span><strong><a href="https://sourceforge.net/projects/linuxfxdevil/" target="_blank" rel="noopener noreferrer">DOWNLOAD X86-64 BITS PC</a></strong></span></p>
<p><span><strong>DUAL CORE + 2GB RAM MIN</strong></span></p>


<p><span><strong><a href="https://sourceforge.net/projects/linuxfxarm/" target="_blank" rel="noopener noreferrer"><img src="http://www.linuxfx.org/images/rasp.png" alt=""></a></strong></span></p>
<p><span><a href="https://sourceforge.net/projects/linuxfxarm/" target="_blank" rel="noopener noreferrer">DOWNLOAD 32 BITS ARMHF</a></span></p>
<p><span><strong>RASPBERRY PI - 2 - 3 - 4</strong></span></p>


<p><a href="https://sourceforge.net/projects/linuxfxtinker/" target="_blank" rel="noopener noreferrer"><img src="http://www.linuxfx.org/images/tinker.png" alt=""></a>&nbsp;</p>
<p><span><a href="https://sourceforge.net/projects/linuxfxtinker/" target="_blank" rel="noopener noreferrer">DOWNLOAD 32 BITS ARMHF</a></span></p>
<p><span><strong>ASUS&nbsp;TINKERBOARD</strong></span></p>


<p><a title="Linuxfx DistroWatch.com" href="https://distrowatch.com/table.php?distribution=linuxfx" target="_blank" rel="noopener noreferrer"><img src="http://www.linuxfx.org/images/dwbanner.png" alt=""></a></p> 	</div>

	
							</div></div></div>
    
            
    </div>
        </div>
            </div>
            
    </section>
        </div>
            </div>
    </div>
        
    </section>
    
                                
                
                                
                <section id="g-copyright">
                
        
    </section>
                                
                <section id="g-fixedside">
                <div>                                <div>                        

        <div>
             <p><a href="http://www.linuxfx.org/" title="" rel="">
        <img src="http://www.linuxfx.org/templates/rt_kraken/images/logo/logo.png" alt="Linuxfx">
        <span></span>
</a>
            </p>
        </div>
            </div>
                            
                            
            </div>
        
    </section>
            
                        

        </div></div>]]>
            </description>
            <link>http://www.linuxfx.org/index.php/sistemas-operacionais/linuxfx-10-w</link>
            <guid isPermaLink="false">hacker-news-small-sites-24146508</guid>
            <pubDate>Thu, 13 Aug 2020 18:26:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Coding Is Dangerous for Developers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24146314">thread link</a>) | @rolandtshen
<br/>
August 13, 2020 | https://idontremember.imprint.to/post/coding-is-dangerous-for-developers | <a href="https://web.archive.org/web/*/https://idontremember.imprint.to/post/coding-is-dangerous-for-developers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Coding is a tool, but there is so much depth within that it often feels like an art form. There are many ways to approach the same problem with different frameworks, languages, and architectures. The end product could be the same but look totally different under the hood. This is the underlying reason coding is so dangerous for developers. With so much freedom, we can lose sight of the original goal: solving a problem.</p><p>It’s very easy to dive into a project and decide that you should build it from scratch because you’re a developer, you can code! You have the magic power to bring amazing things into being with only a keyboard! You start building, troubleshooting bugs you didn’t imagine would pop up to ruin your plans. Then, the features you pictured in your head turn out to be significantly more complicated. Hours later, you discover a spreadsheet and Google form could solve it in a few minutes. It’s an amazing feeling to see your work come to life, but it can blind us to the simple solutions that we can discover with a little more patience.</p><p>Alright, so you’ve searched around and mulled it over, it actually does make sense to build something new to solve your problem. Awesome, you’ve been meaning to try out that brand new language you found! Chances are, you won’t be the last person working on this solution though. Will the next person have the experience &amp; knowledge to maintain a niche language? Does it put your company in a position where their <a href="https://en.wikipedia.org/wiki/Bus_factor">bus factor</a> is just you?</p><p>Fine, we decided it made more sense to use technologies that are more stable and commonplace, even if they aren’t as exciting. Well, this should incorporate some machine-learning background jobs to give us insights on the best path forward, right? Maybe a little blockchain under the hood? It also needs to be multi-region &amp; scalable to the nth degree to make sure we can handle the millions of users waiting around the corner for this. If it’s not fully resilient, they won’t want to use it! Developers love adding features and improving software, especially the ones who care about the craft. Like artists, they will never be satisfied with their work and can always find something to tweak. Eventually, the energy is better spent elsewhere. We forget to ask ourselves “Are these features actually what people need/asked for?".</p><p>The danger in these situations is when coding becomes a ‘feel-productive’ task while not moving you closer to a solution. This happens because of the disconnect between the actions taken that let us check off boxes (writing a new feature, deploying the service, etc.) with the actual planned outcome. It feels great to see progress, but if that path leads to nowhere you are just wasting time.</p><p>The possibilities available when you know how to code are staggering. It’s easy to become lost in the void of possibilities, losing your tether to your original goal. Next time you’re looking over a project ask yourself:</p><ul><li>Does it need code?</li><li>What is the Simple Lovable Complete (<a href="https://blog.asmartbear.com/slc.html">SLC</a>) version of the solution?</li><li>What tech stack makes the most sense for the context of the project, rather than what is shiny and interesting?</li><li>Am I actually making progress toward this goal or do I just feel productive? (Ask this one regularly)</li></ul></div><div><div><p><a href="https://idontremember.imprint.to/">I Don't Remember</a></p><p>Thoughts on life, software, and making products.</p></div></div></div>]]>
            </description>
            <link>https://idontremember.imprint.to/post/coding-is-dangerous-for-developers</link>
            <guid isPermaLink="false">hacker-news-small-sites-24146314</guid>
            <pubDate>Thu, 13 Aug 2020 18:12:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lessons from Go: Keep Calm and Use the Byte Array]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24146280">thread link</a>) | @todsacerdoti
<br/>
August 13, 2020 | https://preslav.me/2020/08/12/lessons-from-golang-keep-calm-and-use-the-byte-array/ | <a href="https://web.archive.org/web/*/https://preslav.me/2020/08/12/lessons-from-golang-keep-calm-and-use-the-byte-array/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
              <p>Before coming to Go, I had spent years cushioned by the high level of abstraction of Web frameworks such as <a href="https://spring.io/projects/spring-framework">Spring</a> or <a href="https://dotnet.microsoft.com/apps/aspnet">ASP.NET</a>. Thus, I was set aback when I first encountered Go's ubiquitous <em>byte slice</em> (<code>[]byte</code>).</p><p>To say that byte arrays are unique to Go will of course be a big lie. Computers communicate using bytes. Thus, any form of data exchange between a software application and its external environment is an array of bytes. This includes IO, database, network, data conversion, and many other kinds of operations.</p><p>While other technologies try to abstract away from working with byte arrays directly, in Go they are everywhere. Go's term for byte arrays of unspecified length is called a "byte slice", but the concept is pretty much the same. You will use byte slices when reading a file, for example:</p><pre><code>f, err := os.Open("./input.txt")
defer f.Close()
if err != nil {
    // handle the error
}

buf := bytes.NewBuffer(make([]byte, 0))
buf.ReadFrom(f)
fmt.Printf(string(buf.Bytes()))
</code></pre><p>Converting to/from XML, JSON, or other transport formats:</p><pre><code>jsonString := `{"Foo": "Bar"}`

// Parse the incoming JSON string
type S struct{ Foo string }
var s S
json.Unmarshal([]byte(jsonString), &amp;s)

// Turn into XML
xmlResult, _ := xml.MarshalIndent(&amp;s, "", "")

// Write to a file
ioutil.WriteFile("out.txt", xmlResult, 0644)
</code></pre><p>Or the mother-of-all-examples, handling an HTTP request:</p><pre><code>func postTodo(w http.ResponseWriter, r *http.Request) {
    var todo Todo
    err := json.NewDecoder(r.Body).Decode(&amp;todo)
    defer r.Body.Close()
    if err != nil {
        // handle the error
    }

    err = store.addTodo(todo)
    if err != nil {
        // handle the error
    }

    w.WriteHeader(http.StatusOK)
    json.NewEncoder(w).Encode(todo)
}
</code></pre><h2 id="reader-and-writer">Reader and Writer</h2><p>Go's standard library provides two extremely convenient interfaces to wrap around the use of byte array's: <code><a href="https://golang.org/pkg/io/#Reader">Reader</a></code> and <code><a href="https://golang.org/pkg/io/#Writer">Writer</a></code>. Those two are the poster children of the concept of interfaces in Go. They are super simple (each having only a single method to implement). This is the reason why they are used all over the place in the standard library and in many Go projects. Make your custom type implement one or the other (or both), and it gets superpowers. You can serialize it, store it on disk, or send in network requests. All that using the standard library alone, without having to write any additional code.</p><h2 id="the-cost-of-abstractions">The Cost of Abstractions</h2><p>As mentioned in the beginning, I frowned upon seeing byte slices the first time around. I had worked with Java's <code>InputStream</code> and <code>OutputStream</code> before, as well as with their .NET Stream equivalent. While one can find them used in foundational libraries and frameworks, their use in applications is rather sparse.</p><p>The reasons could be many. One that comes to mind are the complex class hierarchies built around each, which make the right choice difficult, and the usage cumbersome. Another, might be the use of reflection everywhere. While an HTTP request in Spring or ASP.NET can be handled similarly to its Go equivalent, working with bytes directly is an exceptional case. The accepted solution is to use reflection, in order to cast incoming byte arrays to typed objects:</p><pre><code>[HttpPost]
public async Task&lt;ActionResult&lt;TodoItem&gt;&gt; PostTodoItem(TodoItem todoItem)
{
    _store.TodoItems.Add(todoItem);
    await _store.SaveChangesAsync();
    return todoItem;
}
</code></pre><p>This is a great example of hiding complexity behind abstractions, and is how the majority of modern software gets developed. For decades, the Computer Science curriculum preached to students the values of not repeating oneself (DRY). Only in the last few years, did people start to question DRY's practicality.</p><p>Abstractions are great when things work fine, but terrible when they break. The probability of something crumbling down is directly proportional to its level of complexity. The deeper in the abstraction chain a problem occurs, the more difficult and costly it is to fix. This is where Computer Science theory meets hard reality.</p><h2 id="sticking-to-go-s-minimalism">Sticking to Go's Minimalism</h2><p>Go's creators wanted a pragmatic language for tooling, backend, and systems programming. One that doesn't hide complexity from the developer. Go intentionally makes certain things verbose, and favors copying over premature dependency. It may not be the most elegant programming language, but it plays its part really well.</p><p>Along with error handling and the lack of generics, the prevalent use of byte slices evoked resistance at first, but I quickly got used to it.</p><hr><figure><a href="https://medium.com/@tyler_brewer2/bits-bytes-and-byte-slices-in-go-8a99012dcc8f"><div><p>Bits, Bytes, and Byte Slices in Go</p><p>If you come from a background other than Computer Science and learned programming through a higher level language such as Ruby (like I did), you may have never really “needed” to be concerned about…</p><p><img src="https://cdn-images-1.medium.com/fit/c/152/152/1*8I-HPL0bfoIzGied-dzOvA.png"><span>Medium</span></p></div><p><img src="https://miro.medium.com/max/1200/1*hNlOKSdJjr-Af1R5snxIMQ.png"></p></a></figure>
                <section>
                  
                  <ul>
                      <li>
                        <a href="https://preslav.me/tag/programming/" title="Programming">Programming</a>
                      </li>
                      <li>
                        <a href="https://preslav.me/tag/golang/" title="Golang">Golang</a>
                      </li>
                      <li>
                        <a href="https://preslav.me/tag/java/" title="Java">Java</a>
                      </li>
                      <li>
                        <a href="https://preslav.me/tag/net/" title=".NET">.NET</a>
                      </li>
                  </ul>
                </section>
            </div></div>]]>
            </description>
            <link>https://preslav.me/2020/08/12/lessons-from-golang-keep-calm-and-use-the-byte-array/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24146280</guid>
            <pubDate>Thu, 13 Aug 2020 18:09:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Altair: Declarative Visualization in Python – Altair 4.1.0 documentation]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24146171">thread link</a>) | @rbanffy
<br/>
August 13, 2020 | https://altair-viz.github.io/index.html | <a href="https://web.archive.org/web/*/https://altair-viz.github.io/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

   
  <div>

    
    <nav data-toggle="wy-nav-shift">
      
    </nav>

    <section data-toggle="wy-nav-shift">

      
      <nav aria-label="top navigation">
        
          <i data-toggle="wy-nav-top"></i>
          <a href="#">Altair</a>
        
      </nav>


      <div>
        
        <div>
        
          
















          <div role="main" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div id="altair-declarative-visualization-in-python">

<p>Altair is a declarative statistical visualization library for Python, based on
<a href="http://vega.github.io/vega">Vega</a> and <a href="http://vega.github.io/vega-lite">Vega-Lite</a>, and the source is available on
<a href="http://github.com/altair-viz/altair">GitHub</a>.</p>
<p>With Altair, you can spend more time understanding your data and its meaning.
Altair’s API is simple, friendly and consistent and built on top of the
powerful <a href="http://vega.github.io/vega-lite">Vega-Lite</a> visualization grammar. This elegant simplicity produces
beautiful and effective visualizations with a minimal amount of code.</p>






<div id="bug-reports-questions">
<h2>Bug Reports &amp; Questions<a href="#bug-reports-questions" title="Permalink to this headline">¶</a></h2>
<p>Altair is BSD-licensed and the source is available on <a href="http://github.com/altair-viz/altair">GitHub</a>. If any
questions or issues come up as you use Altair, please get in touch via
<a href="http://github.com/altair-viz/altair/issues">Git Issues</a> or our <a href="https://groups.google.com/forum/#!forum/altair-viz">Google Group</a>.</p>
</div>

</div>


           </div>
           
          </div>
          

        </div>
      </div>

    </section>

  </div>
  


  

    
      
      
      
      
      
      

  

  

   


</div>]]>
            </description>
            <link>https://altair-viz.github.io/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24146171</guid>
            <pubDate>Thu, 13 Aug 2020 17:59:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Handmade Web]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24146025">thread link</a>) | @cookingoils
<br/>
August 13, 2020 | https://handmade-web.net/fall20/index.html | <a href="https://web.archive.org/web/*/https://handmade-web.net/fall20/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
            “I evoke the term ‘handmade web’ to suggest slowness and smallness as forms of resistance.”<br>
            —— J. R. Carpenter
          </p><p>The hand has become increasingly less present in the web as we know it today. Websites are automated or built from templates, and the knowledge of how to make a website is relegated to a select few. It has only gotten easier to learn and make on the web, but the idea and perceived requirements for a website have become so convoluted and arcane that many avoid the subject. This course seeks to dispel these ideas and will emphasize the hand-quality of websites by developing an understanding of the best practices, language, history, and present context of the web. We will examine the space of the web at large and explore and challenge what a website is and can be with the hopes of reclaiming an important creative space.</p><p>The websites we will make may be small, but their hearts will be big.</p><p>The first half of the class will be technically focused. It will comprise of a series of lessons, readings, workshops, and small projects to develop familiarity and confidence with the language of the web. We will focus on the basic languages of web development: HTML, CSS, and a little Javascript. This class is designed for students with no programming experience at all, but should be friendly to any skill level. The second half will be focused on a larger project website.</p><div>

          
          <p>This class will place heavy emphasis on the hand, craft, and care of your design and code. We will learn how to borrow and learn from others’ code, but we will strive to understand how to code it ourselves. This class will question much of what is commonly understood about the web and technology in general.</p>
          <ul>
            <li>Is tech always the answer? (“There’s an app for that…”)</li>
            <li>Why put something on the web?</li>
            <li>How can we think about accessibility, legibility, efficiency, and speed on the web?</li>
          </ul>

          <hr>

          
          <p>The first goal of this class is to demystify and remove the barrier for entry into web development and programming. Any and all questions are welcome. I will not know every answer, but we can work together to find one (and there are always many when it comes to programming). Learning how to search is the programmer’s greatest tool.</p>
          <p>By the end of the class you will:</p>
            <ul>
              <li>Have a working knowledge of HTML, CSS, and basic Javascript</li>
              <li>Understand the design principles particular to the web and dynamic media</li>
              <li>Have a basic understanding of web publishing</li>
              <li>Have an understanding of the history and present context of web</li>
              
            </ul>

          <hr>

          
          <p>Early in the semester we will set up individual class websites to house all products of this class (projects, writing, anything else…). We will host them using Github Pages and purchase a domain name to attach to it. You can design and organize this however you like, so long all content is accessible and easily found——I will be grading from this!</p>

          <hr>

          
          <p>For assigned readings I will ask you to respond to the reading with a rough written/sketched website concept (or, if you want, a coded sketch of the website) that reacts to the concepts and topics of the reading. Then, upload this response to your class site. Use this as an opportunity to catalogue some ideas for future web projects (either in this class or beyond!).</p>
          <p>There will be some time for reading discussions, but class time will largely be reserved for work, review, and activities. However, these readings will help facilitate a common understanding about the history and present context of the web. Ideally, they will also serve as inspiration for you (as they have been for me!).</p>
          <p>For each week that we have a reading for, only choose 1 to respond to. For example: if there are 3 assigned readings in a week, only respond to one of those.</p>
          <p>More details can be found in the <a href="https://handmade-web.net/fall20/projects/reading.html">project page</a>.</p>

          <hr>

          
          <p>During the first half of the class we will work on a series of smaller projects to practice and experiment with designing for the web:</p>
            <ol>
              <li><a href="https://handmade-web.net/fall20/projects/article.html">Article</a></li>
              <li><a href="https://handmade-web.net/fall20/projects/screensaver.html">Screensaver</a></li>
              <li><a href="https://handmade-web.net/fall20/projects/secret.html">Secret</a></li>
              <li><a href="https://handmade-web.net/fall20/projects/aura.html">Aura</a></li>
            </ol>
          <p>Details for each project will be outlined on the <a href="https://handmade-web.net/fall20/projects/index.html">Projects</a> page.</p>

          <hr>

          
          <p>The final project will take up the last half of the class. It can be anything you like: a project you’ve had in mind for some time; an extension of your practice or an even larger project outside of this class. What is important is the craft, care, and concept of the project. It will be graded on these qualities. It should be unique, personal, and a world of its own.</p>

          <hr>

          
          <p>For each major project there will be an informal presentation and feedback session. As much of this class is focused on technical introduction and skill-building, the finished projects will likely still be works in progress (the web is always under construction). Treat these sessions as opportunities to ask technical or conceptual questions to push your projects further!</p>
          <p>Beyond these review sessions I would encourage everyone to regularly share work and code inside and out of class!</p>

          <hr>

          
          <p>
            40% —— Participation<br>
            40% —— Process<br>
            20% —— Execution
          </p>

          <hr>

          
          <p>This class will require a computer, a text-editor (I recommend <a href="https://atom.io/">Atom</a>), and a browser (<a href="https://www.google.com/chrome/">Chrome</a>). I would also suggest a sketchbook for much encouraged off-screen thinking, note-taking, sketching, and journaling.</p>

          <p>More details can be found in the <a href="https://handmade-web.net/fall20/library.html">Library</a>.</p>

          <hr>

          
          <p>This class will take place entirely online, with some flexibility on potentially meeting in person for individual meetings. Unless stated otherwise, we will regularly meet (synchronously) during the scheduled class times using Zoom.</p>
          <p>You will also have access to the scheduled class space in Pollak Room 317 if you want to use that space during class time, though we will still all collectively meet online through Zoom. One thing to note is that departmental policy, at the time, only allows 10 students in a classroom at a time and only during the scheduled class time. Please make sure to prioritize your own safety and the safety of others when using public spaces!</p>
          <p>We can consider this a feature rather than a hinderance for learning web design as we will inhabit and communicate within the environment that we will be making for!</p>

          <hr>

          
          <p>As this class will take place online, we will be using a <a href="https://discord.com/" target="_blank">Discord</a> server to centralize communication and announcements for the class. The Discord will also serve as a space for feedback and comments during feedback sessions. If there are any updates/changes to the class I will announce them on the Discord, so be sure to check often.</p>

          <hr>

          
          <p>The standard VCU attendance policy states that student absences during the semester are not expected to exceed the number of times the class meets in one week (2). This semester, because we are facing unprecedented circumstances, we will be following a revised policy that addresses larger issues of expected engagement in the course, articulated below. Consistent engagement is a vital component of successful completion of the course objectives.</p>
          <p>The progression of this course requires all participants to be present and actively engaged in class, both during synchronous on-screen meetings, in-person, and with asynchronous activities. Consistency of engagement is vital for a successful completion of the course objectives. Each of us carries different circumstances and capacities; we are accountable for our own agency. This is always true, but especially crucial now.</p>
          <p>If at any point during the semester you are unable to be present, communicate this with me as soon as you can. While presence in class is important, my primary concerns with this class are your wellbeing and an emphasis on not applying unnecessary pressure in an already difficult period. Please remember to prioritize your mental and physical health over school.</p>

          <hr>

          
          <p>The University requires all students and faculty to be aware of policies outlining expectations, requirements and student services related to  academic life. Please visit the following link and review these at the start of each semester: <a target="_blank" href="https://go.vcu.edu/syllabus">go.vcu.edu/syllabus</a>
          </p>

          <hr>

          
          <p>For information regarding institutional adjustments, policies, and safety precautions during COVID-19 please consult the web page for <a target="_blank" href="https://together.vcu.edu/students/">One VCU: Responsible Together</a>.
          </p>

          <hr>

          
          <p>This syllabus and class’s foundation has a number of sources to thank</p>
          <ul>
            <li><a href="http://laurelschwulst.com/">Laurel Schwulst</a> —— whose published syllabi and class portals served as my own unbidden introduction to web design. Much of the pacing and tone of this class is modeled after her approach.</li>
            <li><a href="http://mindyseu.com/">Mindy Seu</a> —— whose classes and workshops have helped expand my thought around digital pedagogy.</li>
            <li>Roy McKelvey —— whose generously provided syllabus has served as the organizational structure of this class.</li>
          </ul>

          <hr>
        </div></div>]]>
            </description>
            <link>https://handmade-web.net/fall20/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24146025</guid>
            <pubDate>Thu, 13 Aug 2020 17:46:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[World's simplest text editor passes 20k monthly users]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24145941">thread link</a>) | @ent101
<br/>
August 13, 2020 | https://www.outpan.com/app/e7d5b37405/mytextarea | <a href="https://web.archive.org/web/*/https://www.outpan.com/app/e7d5b37405/mytextarea">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><nav role="navigation"><div><div><form action="/search" method="get"></form><p><img src="https://opimg.s3.amazonaws.com/e7d5b37405-200x200.jpg" id="app-toolbar-icon"></p><div id="app-options-wrapper"><div><div><p data-toggle="modal" data-target="#review-modal" id="reviews-modal-link" title="View reviews or write one"><span></span> <span>32</span></p></div></div></div></div><div id="navbar-user-items" aria-expanded="false"><p><a href="https://www.outpan.com/signup">Sign Up</a></p><ul><li></li></ul><ul><li><a href="https://www.outpan.com/">Home</a></li><li><a href="https://www.outpan.com/login?ref=https://www.outpan.com/app/e7d5b37405/mytextarea">Login</a></li><li><a href="https://www.outpan.com/signup">Sign Up</a></li></ul><form action="/search" method="get"></form></div></div></nav><div><div><div><div></div></div></div></div></div>]]>
            </description>
            <link>https://www.outpan.com/app/e7d5b37405/mytextarea</link>
            <guid isPermaLink="false">hacker-news-small-sites-24145941</guid>
            <pubDate>Thu, 13 Aug 2020 17:39:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Jira Is a Microcosm of What’s Broken in Software Development]]>
            </title>
            <description>
<![CDATA[
Score 131 | Comments 168 (<a href="https://news.ycombinator.com/item?id=24145665">thread link</a>) | @davetwichell
<br/>
August 13, 2020 | https://linearb.io/blog/jira-is-a-microcosm-of-whats-broken-in-software-development/ | <a href="https://web.archive.org/web/*/https://linearb.io/blog/jira-is-a-microcosm-of-whats-broken-in-software-development/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="670d84f7" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
			
<p>This blog is not about how project management tools are too complex and over-engineered with features dev teams don’t need.</p>



<p>Those complaints are well articulated by others like Justin James, Chief Architect at Cloud Development Resources.</p>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-2.png.webp 1386w" sizes="(max-width: 1386px) 100vw, 1386px">
<img src="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-2.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-2.png 1386w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-2-300x143.png 300w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-2-1024x488.png 1024w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-2-768x366.png 768w" sizes="(max-width: 1386px) 100vw, 1386px">
</picture>
</figure>







<p><em>“Jira has *never once* made my life as a developer easier or better… It’s overly complicated and the workflow is painful.”&nbsp;</em></p>



<p>Justin goes on to say…&nbsp;</p>



<p><em>“Jira is Word when it had the toolbar filled with tiny little icons for formatting only paralegals or scientists or some other specialized author needed. It does *all this stuff* and none of it is easy or makes sense…”&nbsp;</em></p>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-82.png.webp 1386w" sizes="(max-width: 1386px) 100vw, 1386px">
<img src="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-82.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-82.png 1386w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-82-300x143.png 300w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-82-1024x488.png 1024w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-82-768x366.png 768w" sizes="(max-width: 1386px) 100vw, 1386px">
</picture>
</figure>







<p>Most popular project management tools are highly configurable which can be a plus and a minus depending on how your company has it set up. </p>



<p>So if project tools have so much flexibility, why do so many organizations configure them in a way that causes their dev teams to complain? </p>







<h4><strong>Project management tools are not perfect but they’re not the problem. The root cause of most complaints devs have with project tools are rooted in bad culture, bad management or bad process. </strong></h4>



<p>Let’s examine 4 of the most common complaints I’ve heard about project management tools from software development teams. </p>







<h3>1. “<strong>Project tools are made with PMs in mind, not dev teams</strong>“</h3>



<p>Justin said <em>“I wish Atlassian would sit down with real-world developers and design this product the way we need it to work.”&nbsp;</em></p>



<p>I’ve heard this complaint from a lot of devs. “Project tools were made with project managers and product managers in mind. Not dev teams.” It is true. Project and product managers (collectively referred to as PMs going forward) are the usually primary buyers and owners of project management systems. Not engineers.&nbsp;</p>



<p>I’ve also heard “the development process is fluid, real-time, and doesn’t always follow a linear path. Project tools force you into a workflow that does not match that reality.” </p>



<p>So why do companies use a tool that works for a few PMs and business leaders when some engineers dislike it so much?&nbsp;</p>



<p><strong>The real issue: Executives force top-down decision making on dev teams</strong></p>



<p>Some companies embrace a mindset of decisions being made by a few people “at the top”. In their world, the planning process is king. The creating process is an afterthought.&nbsp;</p>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-4.png.webp 1386w" sizes="(max-width: 1386px) 100vw, 1386px">
<img src="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-4.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-4.png 1386w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-4-300x143.png 300w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-4-1024x488.png 1024w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-4-768x366.png 768w" sizes="(max-width: 1386px) 100vw, 1386px">
</picture>
</figure>







<p>The current software delivery process revolves around pushing decisions down to dev teams and forcing engineers to push status updates back up. This system ensures executives are the only ones who have context and can see the bigger picture while engineers do all of the work.&nbsp;</p>



<p>This is backwards. It holds us back from building the best product and slows us down from delivering faster.&nbsp;</p>



<figure><blockquote><p>Join our mission to end useless status meetings.</p><p><a href="https://linearb.io/status-updates-on/" target="_blank" rel="noreferrer noopener">Click here for access</a>&nbsp;to the dev team dashboard of the future powered by Git data.</p></blockquote></figure>







<h3>2. “<strong>Project tools are plan-first tools, not a develop-first tool</strong>s”</h3>



<p>It makes sense. PM’s, who own Jira, spend a lot of time on ideas, strategy, prioritization, requirements gathering, and preparing for the future. They want a tool that helps them succeed in those areas. Once the iteration starts, PMs shift from being planners to being status communicators. Jira is designed this way. It’s pretty good when you’re in the planning phase and it works well if you’re the PM receiving the status update.</p>



<p>But when you’re in the development phase, it’s not as well suited to dev team tasks. If you’re the engineer who has to constantly manually update the status, it’s annoying. </p>



<p>I see the merit behind this argument. Dev teams live elsewhere like in Git and Slack.&nbsp;Stopping to login in to another system throughout the day is not ideal. </p>



<p>What PMs do is really important – being the voice of the customer, planning, prioritizing and communicating with the rest of the business.  They need tools for this. </p>



<p>I also think dev teams need tools that reflect the fluidity of the development process. It’s sort of like the famous Mike Tyson quote… <em>“Everybody has a plan until they get punched in the mouth.”</em> Once development starts, a million micro-decisions are being made every hour and things change quickly. Most project tools are not set up for this reality.&nbsp;</p>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-33.png.webp 1386w" sizes="(max-width: 1386px) 100vw, 1386px">
<img src="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-33.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-33.png 1386w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-33-300x143.png 300w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-33-1024x488.png 1024w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-33-768x366.png 768w" sizes="(max-width: 1386px) 100vw, 1386px">
</picture>
</figure>







<p>The problem is we’re taking different groups of people who spend their time in different ways and forcing them in to one workflow. 80% of the people involved in software development spend 80% of their time in the development phase. In most companies, fewer people spend less time in the planning phase.&nbsp;</p>



<p>So why are we using a plan-first tool to manage the full development lifecycle?&nbsp;</p>



<p><strong>The real issue: Many execs get product strategy but not product development</strong></p>



<p>Most business leaders think like PMs, not like engineers. Executives understand ideas, strategy, and prioritization. They’re also familiar with the process and key metrics of sales and marketing. They know the vocabulary and speak the language.&nbsp;</p>



<p>They do not understand software development as well. They don’t know the terms. When it comes to the dev team, most just want to know “are we on track to deliver feature XYZ by the deadline?”&nbsp;</p>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-3.png.webp 1386w" sizes="(max-width: 1386px) 100vw, 1386px">
<img src="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-3.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-3.png 1386w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-3-300x143.png 300w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-3-1024x488.png 1024w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-3-768x366.png 768w" sizes="(max-width: 1386px) 100vw, 1386px">
</picture>
</figure>







<p>This is dangerous because it holds them back from understanding our process which holds them back from engaging in intelligent conversations with engineering leaders and teams.&nbsp;</p>



<p>If sales miss their number, the CEO has 100 questions ready to analyze what levers they can pull to right the ship. If the dev team misses a deadline, other than maybe asking “do we need to work more hours?”, all they can do is wait or apply (unhelpful) artificial pressure to finish.&nbsp;</p>



<p>How we work matters. Not just the output.&nbsp;</p>







<h3>3. <strong>“Project tools perpetuate synchronous communication, not asynchronous</strong>” </h3>



<p>Project management tools seems like it should encourage asynchronous communication. But in my experience they do the opposite. </p>



<p>When execs have a meeting with a customer or the sales team, they need information about product delivery timelines and they need it now. They ask the PM and the PM sends you an urgent Slack. Or worse, the PM calls you into a meeting to find out what’s going on. Those interruptions are costly.&nbsp;</p>











<p>Why doesn’t the exec or the PM just look at project board? Because it’s not up to date. Why? Things change so rapidly that, in order for the board to be up to date, engineers would need to constantly manually update tickets. One engineering manager told me recently that even teams he’s worked on that really care about project tool hygiene only capture about 60-70% of their real work activity. Most teams are closer to 50%.&nbsp;</p>



<p>Even if the project board was up to date, it’s still missing context.&nbsp;</p>



<p>Execs and PMs want to know:&nbsp;</p>



<ul><li>When is the bug going to be fixed?&nbsp;</li><li>When is the new feature being delivered?&nbsp;</li><li>What risks could stop us from hitting our date?&nbsp;</li><li>Which features are getting attention right now and which aren’t?&nbsp;</li><li>What % of the team is invested in features versus bugs versus non-functional?&nbsp;</li></ul>



<p>There’s nothing on the project board that answers those questions. So they pull you away from deep focus mode to ask you. And it takes you a while to get your focus back. Which slows you down from delivering the thing they want most of all – more features.&nbsp;</p>



<p><strong>The real issue: Companies run on a “manager’s schedule” not a “maker’s schedule”&nbsp;&nbsp;</strong></p>



<p>Paul Graham, computer programmer and co-founder of Y Combinator, explains the disconnect between the way developers and executives get work done in his 2009 essay <em>Maker’s Schedule, Manager’s Schedule</em>.&nbsp;</p>



<p>Here’s a summary:&nbsp;</p>



<ul><li>Bosses (managers) get stuff done through meetings – changing tasks every 60 minutes.</li><li>Developers (makers) and other creators need 3-4 hour blocks of time to get work done.</li><li>Each way of working is perfectly fine by itself but problems arise when the two collide.</li><li>For a maker, a single meeting at the wrong time can disrupt their entire day of work.</li><li>Most powerful people are on a manager schedule and they directly or indirectly force the makers in their company, like software engineers, to revolve around the way they work.&nbsp;</li></ul>







<p>I couldn’t agree more with Paul. The lack of understanding some execs have for the software development process, leads to a lack of empathy for software developers. Companies subject their engineers to the manager’s schedule which disrupts the flow of development.&nbsp;</p>



<p>When engineers point out they could ship more features faster if there were fewer meetings, business leaders hear that as a complaint versus what it really is, a cry for help.&nbsp;</p>







<h3>4. “Project tools <strong>create separation between engineers and PMs</strong>“</h3>



<p>Some devs describe their interactions with their PM in a way that reminds me of <a rel="noreferrer noopener" href="https://www.youtube.com/watch?v=Fy3rjQGc6lA&amp;feature=youtu.be" target="_blank">Peter from Office Space</a> when his boss asks him for the new cover sheet on the TPS report.&nbsp;</p>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-6.png.webp 1386w" sizes="(max-width: 1386px) 100vw, 1386px">
<img src="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-6.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-6.png 1386w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-6-300x143.png 300w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-6-1024x488.png 1024w, https://linearb.io/wp-content/uploads/2020/08/Blog-Jira-6-768x366.png 768w" sizes="(max-width: 1386px) 100vw, 1386px">
</picture>
</figure>







<p>In the real world, most devs I know really value their PMs. Great PMs allow engineers to do great work. I’ve worked with some awesome ones. </p>



<p>But the <a rel="noreferrer noopener" href="https://linearb.io/blog/vp-engineering-vp-product-how-to-keep-a-united-front/" target="_blank">PM + engineer relationship is hard to get right</a>. Having additional tension built-in makes it even harder.&nbsp;</p>



<p>It’s just not engineers that don’t like having to share status updates all day. PMs don’t want to bug us either! They feel like babysitters. Imagine what they could be doing instead… talking to customers, writing high-quality user stories… or actually spending their time with us on something useful like brainstorming ideas or sharing customer feedback. </p>



<p><strong>The real issue: Some companies are lacking empathy and understanding between different departments. </strong></p>



<p>I’m lucky to work at a company where our CEO (Ori Keren) and our COO (me) are software engineers. We ensure everyone in the company understands the development process which helps maintain tight alignment between our dev, marketing, customer success, and sales teams.&nbsp;</p>



<p>I think more start-ups should be led by programmers and more big companies should promote their CTOs to CEO.&nbsp;</p>



<p>In the …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://linearb.io/blog/jira-is-a-microcosm-of-whats-broken-in-software-development/">https://linearb.io/blog/jira-is-a-microcosm-of-whats-broken-in-software-development/</a></em></p>]]>
            </description>
            <link>https://linearb.io/blog/jira-is-a-microcosm-of-whats-broken-in-software-development/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24145665</guid>
            <pubDate>Thu, 13 Aug 2020 17:13:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OnlineEvent: What Can Tech Do to be Anti-Racist? 9/3/2020]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24145540">thread link</a>) | @ermanwes
<br/>
August 13, 2020 | https://techequitycollaborative.org/event/what-can-tech-do-to-be-anti-racist/ | <a href="https://web.archive.org/web/*/https://techequitycollaborative.org/event/what-can-tech-do-to-be-anti-racist/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The Movement for Black Lives has rallied people together across the country and generated a wave of support from the tech sector. More companies than ever are taking a public stand on racial equity and systemic change. However, very few companies have shared commitments, beyond donating to civil rights organizations, for how they will facilitate structural change in their company and community.</p><p>Much of the onus is being placed onto members of black employee resource groups (ERGs), who are spending significant time and energy on top of their full-time roles educating and advising their companies on how to engage on this issue. It’s clear that tech still has a long way to go before real racial equity is inherent to the industry.</p><p>Join us on Thursday, September 3rd to hear from ERG leaders, Diversity, Equity &amp; Inclusion experts, and social impact professionals for a conversation on how tech can build a culture of anti-racism and drive real, structural change. If you have time, we recommend reading the following articles in advance of this conversation:</p><ul><li><a href="https://www.washingtonpost.com/technology/2020/06/26/black-ergs-tech/" target="_blank" rel="noreferrer noopener">Tech companies are asking their black employee groups to fix Silicon Valley’s race problem — often for free</a></li><li><a href="https://techcrunch.com/2020/06/11/tech-companies-its-time-to-show-that-black-lives-really-matter-to-you/" target="_blank" rel="noreferrer noopener">Tech companies: It’s time to show that Black lives really matter to you</a></li></ul><p>The panel will be moderated by Catherine Bracy, TechEquity Co-Founder and Executive Director. Panelists include:</p><ul><li>Cynthia Overton, Tech Workplace Initiatives at Kapor Center</li><li>Maurice Wilkins Jr., Global Diversity and Inclusion at Fastly</li><li>Natrina Gandana, Project Director at Next Chapter</li></ul><p>Agenda:</p><ul><li>Webinar kicks off at 12:00 PM</li><li>Panel discussion begins at 12:05 PM</li><li>Q&amp;A from attendees from 12:40-1:00 PM</li></ul><p>—————-</p><p>We enforce a&nbsp;<a href="https://techequitycollaborative.org/code-of-conduct/" target="_blank" rel="noreferrer noopener">Code of Conduct</a>&nbsp;at our events. Please take a minute and read it through.</p></div></div>]]>
            </description>
            <link>https://techequitycollaborative.org/event/what-can-tech-do-to-be-anti-racist/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24145540</guid>
            <pubDate>Thu, 13 Aug 2020 17:02:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making Python 3 the Default on macOS]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24145518">thread link</a>) | @nonoesp
<br/>
August 13, 2020 | https://nono.ma/python-3-default-macos | <a href="https://web.archive.org/web/*/https://nono.ma/python-3-default-macos">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
		
				
		
		
		
		<p>While <code>macOS</code> ships with Python 2 by default, you can install set Python 3 as the default Python version on your Mac.</p>
<p>First, you install Python 3 with Homebrew.</p>
<pre><code>brew update &amp;&amp; brew install python
</code></pre>
<p>To make this new version your default add the following line to your <code>~/.zshrc</code> file.</p>
<pre><code>alias python=/usr/local/bin/python3
</code></pre>
<p>Then open a new Terminal and Python 3 should be running.</p>
<p>Let's verify this is true.</p>
<pre><code>python --version # e.g. Python 3.8.5
</code></pre>
<h2>How do I find the <code>python3</code> path?</h2>
<p>Homebrew provides info about any installed "bottle" via the <code>info</code> command.</p>
<pre><code>brew info python
# python@3.8: stable 3.8.5 (bottled)
# Interpreted, interactive, object-oriented programming language
# https://www.python.org/
# /usr/local/Cellar/python@3.8/3.8.5 (4,372 files, 67.7MB) *
# ...
</code></pre>
<p>And you can find the path we're looking for <code>grep</code>.</p>
<pre><code>brew info python | grep bin
# /usr/local/bin/python3
# /usr/local/opt/python@3.8/libexec/bin
</code></pre>
<h2>How do I use Python 2 if I need it?</h2>
<p>Your system's Python 2.7 is still there.</p>
<pre><code>/usr/bin/python --version # e.g Python 2.7.16
</code></pre>
<p>You can also use Homebrew's Python 2.</p>
<pre><code>brew install python@2
</code></pre>
<!--more-->
<h2>Before you go</h2>
<p>If you found this useful, you might want to join my <a href="https://nono.ma/mailing-lists">mailing lists</a>; or take a look at other posts about <a target="_blank" href="https://nono.ma/says/tag/code">code</a>, <a target="_blank" href="https://nono.ma/says/tag/python">Python</a>, and <a target="_blank" href="https://nono.ma/says/tag/macos">macOS</a>.</p>

	</div></div>]]>
            </description>
            <link>https://nono.ma/python-3-default-macos</link>
            <guid isPermaLink="false">hacker-news-small-sites-24145518</guid>
            <pubDate>Thu, 13 Aug 2020 17:00:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[HTTP – It's Simpler Than You Think. It's More Complex Than You Think]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24145502">thread link</a>) | @Crzymary15
<br/>
August 13, 2020 | http://bluegraybox.com/blog/2014/08/29/its-simpler-than-you-think-its-more-complex-than-you-think/ | <a href="https://web.archive.org/web/*/http://bluegraybox.com/blog/2014/08/29/its-simpler-than-you-think-its-more-complex-than-you-think/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
            <div>
                <article>
                    <header>
                        
                        <span>
                            
                                Posted in
                                
                                    <a href="http://bluegraybox.com/blog//categories/networking">networking</a>
                                
                            

                            
                        </span>
                         - 
                        <time>Friday, August 29, 2014</time>
                    </header>
                    <section>
                        

<p>I’ve been doing web development for a pretty long time, but just over the last few years I’ve come to really appreciate the fundamentals of HTTP, what’s going on under the hood when I’m building web applications. There are two sides of this. The first is that HTTP is in one sense a very simple protocol. It’s just little text messages going back and forth between your browser and the web server. Whether I’m using Node or Django or some huge WSDL-driven Java XML-Beans monstrosity, what it’s doing isn’t rocket science; it’s just taking care of a bunch of tedious, nit-picky bookkeeping that I don’t want to be bothered with. If I really wanted to, I could just type the messages myself (and we’ll get to that in a minute).</p>

<p>The practical upside of that is that you can use really simple tools to debug big, hairy, complex web applications. A few years ago, I was working in one of those Big Web Services systems with WSDL files and auto-generated Java code and layers and layers of middleware. We’d get some kind of error at the front end, and it’d be really hard to tell which piece had broken. So I ended up writing a bunch of really simple shell scripts to test the web services in isolation. I’d spackle together something using <code>curl</code>, <code>grep</code>, and <code>sed</code> that built up and picked apart the messages as text, without dragging in all that mess of Java code.</p>

<p>The flip side is that HTTP is actually a richer protocol than I’d realized. There’s a lot I didn’t know about it until I started building RESTful web services and trying to understand the “right” way to do it. There’s all this stuff you can do with status codes and headers that I’d been re-implementing at the application level.</p>

<p>To take a recent example, I’ve been working on a web service that talks to other web services. Someone would make a call to us, we’d call the back-end services, they’d time out or barf up some sort of error, and we’d pass back a 500 error to our client. They’d see it and email us asking what was wrong with our service. It’d be nice to let them know it’s not our fault and that they should pester the back-end systems people instead. We could send back a message body that says something like, “Back-end systems failure. Original error message follows,” but it turns out we can say that just by returning a different status code. Not only is there a 502 status code, which means that a back-end system failed, but there’s also a 504, which means that we timed out trying to contact it. That tells our client that they can try again in a little while and the request might go through.</p>

<p>Ok, enough talking. Now code.</p>

<h2 id="goin-all-mechanical-turk-on-this">Goin’ all Mechanical Turk on this</h2>

<p>To illustrate the first point, that this is all just text, I’m going to play human web server, using <code>netcat</code>. If you’re not familiar with it, it’s a standard unix utility that just opens a network connection. Anything you type gets sent along it; anything that comes back gets printed out on your screen. I open up a terminal and type:</p>

<pre><code>nc -l 3333
</code></pre>

<p>That starts up <code>netcat</code> listening on port 3333. Then I switch to my browser and tell it to go to <code>http://localhost:3333/</code>. The “page loading” indicator starts spinning. In the <code>netcat</code> terminal, I see:</p>

<pre><code>GET / HTTP/1.1
Host: localhost:3333
Connection: keep-alive
Cache-Control: max-age=0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8
User-Agent: Mozilla/5.0 (X11; Linux i686) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.125 Safari/537.36
Accept-Encoding: gzip,deflate,sdch
Accept-Language: en-US,en;q=0.8
</code></pre>

<p>That’s Chrome telling me it wants the root resource (<code>/</code>, which Apache or whatever would normally interpret as <code>index.html</code>). It’s also telling me a lot about what kind of response it can handle. I’m going to ignore all that for now and just type:</p>

<pre><code>HTTP/1.1 200 OK 
Content-type: text/plain
Content-length: 7

Hello!
</code></pre>

<p>Pretty straightforward. The content length is 7 because it includes the return character after “Hello!” Here’s what we see in Chrome:</p>

<p><img src="https://raw.githubusercontent.com/bluegraybox/bash_REST/master/img/hws-1.png" alt="" title="Chrome window with plain text &quot;Hello!&quot;"></p>

<p>Switch back to the browser and go to <code>http://localhost:3333/index.html</code>. In the <code>netcat</code> terminal, we get a request that’s much the same as before, except the first line is:</p>

<pre><code>GET /index.html HTTP/1.1
</code></pre>

<p>Since they asked for HTML, I’ll give them HTML. I type:</p>

<pre><code>HTTP/1.1 200 OK
Content-type: text/html
Content-length: 16

&lt;h1&gt;Hello!&lt;/h1&gt;
</code></pre>

<p>And in Chrome we see:</p>

<p><img src="https://raw.githubusercontent.com/bluegraybox/bash_REST/master/img/hws-2.png" alt="" title="Chrome window with HTML H1 header &quot;Hello!&quot;"></p>

<p>So at some fundamental level, that’s all a web application is. It’s a program that listens for a connection, gets little text messages, interprets them, and sends back responses. How simple can we make that?</p>

<h2 id="restful-web-services-in-bash">RESTful Web Services in Bash</h2>

<p>How about this?</p>

<pre><code>#!/bin/bash

echo "Content-type:text/plain"
echo 
uptime
</code></pre>

<p><code>uptime</code> is a standard unix utility that reports how long the computer has been running and what the 1, 5, and 15 minute system load averages are. That’s marginally useful - I’ve actually used a script much like this for basic server monitoring. Put it in a file, make it executable, run it from the command line, and it’ll spit out something like:</p>

<pre><code>Content-type:text/plain

 21:29:32 up 9 days, 15:17,  5 users,  load average: 0.05, 0.10, 0.18
</code></pre>

<p>From here, if you want to follow along, you’ll need to have Apache set up and configured to let you run CGI scripts in the directory you’re working in. (That’s a whole tutorial on its own, but here’s some <a href="http://www.cgi101.com/book/connect/mac.html">instructions for Mac OS X</a>. Otherwise, Google for “apache enable cgi” and your operating system.)</p>

<p>On my machine, this script is saved as <code>public_html/api/v1/load/index.cgi</code>. That lets me access it as <code>http://localhost/~colin/api/v1/load/</code>, as we can see in Chrome:</p>

<p><img src="https://raw.githubusercontent.com/bluegraybox/bash_REST/master/img/v1-load.png" alt="" title="Chrome showing uptime report"></p>

<p>We can also use <code>netcat</code> in place of Chrome. Instead of listening on a port, we open a connection to the web server’s port:</p>

<pre><code>$ nc -c localhost 80
</code></pre>

<p>Then I type:</p>

<pre><code>GET /~colin/api/v1/load/ HTTP/1.1
Host: localhost
</code></pre>

<p>And I get this back from Apache:</p>

<pre><code>HTTP/1.1 200 OK
Date: Wed, 27 Aug 2014 01:14:11 GMT
Server: Apache/2.4.7 (Ubuntu)
Vary: Accept-Encoding
Transfer-Encoding: chunked
Content-Type: text/plain

46
 21:14:19 up 9 days, 15:01,  5 users,  load average: 0.08, 0.18, 0.28

0
</code></pre>

<p>You can see that Apache includes a bunch of header fields that I didn’t bother to when I was playing web server. (I’ll trim most of these out of later examples to cut down on the clutter.) The more interesting thing is that it doesn’t have a <code>Content-length</code> header. What it has instead is <code>Transfer-Encoding: chunked</code>. That says that its content will be in chunks, prefixed by their size (in hexadecimal). 46 hex is 70, which is the length of the next line (again, counting the return character at the end). The ‘0’ for the next chunk says, “that’s all, folks!”</p>

<p>We can make this a little easier on ourselves by using <code>curl</code> instead of <code>netcat</code>. It’s a somewhat more custom tool for making HTTP requests. We can just run <code>curl -si http://localhost/~colin/api/v1/load/</code> from the command line, and get back:</p>

<pre><code>HTTP/1.1 200 OK
Transfer-Encoding: chunked
Content-Type: text/plain

 22:05:42 up 9 days, 15:53,  5 users,  load average: 0.14, 0.13, 0.19
</code></pre>

<p>That’s the same as what <code>netcat</code> gave us (minus the header clutter), but notice that it combined the chunked response for us. Even at this level, some of the details are being hidden.</p>

<h2 id="status-seeking">Status Seeking</h2>

<p>Let’s take this a step further. The <a href="https://raw.githubusercontent.com/bluegraybox/bash_REST/master/v1/status/index.cgi">status script</a> gets a status message (“GREEN”, “YELLOW”, or “RED”) from a file, and prints it out like so:</p>

<pre><code>$ curl -si http://localhost/~colin/api/v1/status/
HTTP/1.1 200 OK
Content-Length: 4
Content-Type: text/plain

RED
</code></pre>

<p>It also lets us set a new status like so:</p>

<pre><code>$ curl -si -X PUT -d GREEN http://localhost/~colin/api/v1/status/
HTTP/1.1 204 No Content
Content-Length: 0
Content-Type: text/plain
</code></pre>

<p>Note that we used the same URL, but changed the HTTP method to <code>PUT</code> (instead of the default <code>GET</code> - don’t ask me why that’s the <code>-X</code> option) and specified “GREEN” as the data (<code>-d</code>) to be sent along with the request. We get back an exciting new response code: 204! Since we’re telling not asking, it doesn’t make much sense for the server to send anything back. The 204 status just says, “That thing you were doing? It worked.” No reason to have a message body saying “Success!” when the code already tells you that. I’ve definitely been guilty of reinventing that wheel before I ran across this.</p>

<p>What if we try to send a bad status, like ‘BLUE’?</p>

<pre><code>$ curl -si -X PUT -d BLUE http://localhost/~colin/api/v1/status/
HTTP/1.1 400 Bad Request
Content-Type: text/plain

Invalid status code
</code></pre>

<p>400 is the “your mistake” error code, which is pretty generic, so we include a descriptive message in the response body. Since it’s a user error, it’s reasonable to just have a human-readable message.</p>

<p>If you look at the script, you’ll see references to environment variables like <code>$REQUEST_METHOD</code>. That’s how Apache makes information about the request avaliable to the script (as part of the CGI standard). In case you want to see all of them, I’ve added an <a href="https://raw.githubusercontent.com/bluegraybox/bash_REST/master/env/index.cgi">env script</a>, which dumps them all out, plus the content. You can hit it with Chrome or <code>curl</code>, or even <code>netcat</code>. See what’s different between them.</p>

<h2 id="api-documentation">API Documentation</h2>

<p>Ok, great! Now we have two simple yet useful web services. But they’re not so simple that they don’t need any documentation, so let’s add some. We could have some sort of parallel hierarchy for documentation, like <code>/api/docs/v1/load/</code>, etc., but that’s kinda clunky. Instead, let’s rework our services so they give you data when you ask for data, and text when you ask for text. For that, we take advantage of the <code>Accept</code> header. Take a …</p></section></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://bluegraybox.com/blog/2014/08/29/its-simpler-than-you-think-its-more-complex-than-you-think/">http://bluegraybox.com/blog/2014/08/29/its-simpler-than-you-think-its-more-complex-than-you-think/</a></em></p>]]>
            </description>
            <link>http://bluegraybox.com/blog/2014/08/29/its-simpler-than-you-think-its-more-complex-than-you-think/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24145502</guid>
            <pubDate>Thu, 13 Aug 2020 16:59:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GPT-3: An Abstraction of Time vs. Money]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24145383">thread link</a>) | @ceohockey60
<br/>
August 13, 2020 | https://interconnected.blog/gpt-3-abstraction-of-time-money/ | <a href="https://web.archive.org/web/*/https://interconnected.blog/gpt-3-abstraction-of-time-money/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <p>Hype or not, GPT-3, OpenAI’s newest natural language AI model, has been percolating in the back of my mind ever since it was announced <a href="https://openai.com/blog/openai-api/">two months ago</a>. This post will be some open musing of what I think its implications are in the intersection of tech, business, and geopolitics.</p><p>【想看<a href="https://interconnected.blog/gpt-3-abstraction-of-time-money/#chinese-version-below">中文的读者请点击这里</a>或滚动到本页下方】</p><p>Not to get too philosophical, but I see GPT-3 as <strong>a beautiful abstraction of the relationship and tradeoffs between time and money.</strong> (Don’t worry, this isn’t the machine talking. This is still written by me, the human author, not GPT-3.)</p><h2 id="gpt-3-in-a-nutshell">GPT-3 in a Nutshell</h2><p>To quickly summarize what is GPT-3 in plain language: it’s the 3rd generation of OpenAI’s natural language processing model, the previous generation being GPT-2, <a href="https://openai.com/blog/better-language-models/">released in early 2019</a>. GPT-3 has <strong>175 billion parameters </strong>compared to GPT-2’s 1.5 billion parameters. In the world of Deep Learning AI, if a model has more parameters, it’s (literally) bigger, more complex, and usually produces better results. In this case, GPT-3 is more than 100-times bigger than GPT-2. GPT-3 is also trained on a much larger dataset -- almost a trillion words from the Common Crawl dataset, which crawls the entire Internet and makes the data publicly available for research. Again, in Deep Learning AI, more training data usually produces a better model, thus better results from that model. Presumably, there will be GPT-4, 5, 6, etc. that will be more powerful than GPT-3.</p><p><em>(There are of course many more details to GPT-3’s underlying technology. Since Interconnected caters to a wide range of readers, I won’t belabor all the details here. I’d encourage readers who are technical to </em><a href="https://arxiv.org/pdf/2005.14165.pdf"><em>read the GPT-3 paper</em></a><em>, which lays out all aspects of the model, including algorithm, architecture, training process, evaluation, limitations, and ethical implications.)</em></p><p>GPT-3 is also <em>not</em> open sourced. Instead, the model’s abilities are exposed through an API layer that can be controlled. OpenAI’s justification is to limit malicious use of the model; if someone is abusing GPT-3 for nefarious purposes, OpenAI can turn off that user’s access to the API. Given just the limited examples of “magical” things that hobbyists have <a href="https://gptcrush.com/">produced using GPT-3</a> -- from business writing and poetry, to designing a website and other forms of simple coding -- I think this approach is well-justified, even though it goes against my default position that always prefers open source.</p><p>This approach is not without its critics. When GPT-2 was first released, it was heavily criticized, both <a href="https://venturebeat.com/2019/02/22/ai-weekly-experts-say-openais-controversial-model-is-a-potential-threat-to-society-and-science/">externally by other AI researchers </a>and <a href="https://www.technologyreview.com/2020/02/17/844721/ai-openai-moonshot-elon-musk-sam-altman-greg-brockman-messy-secretive-reality/">internally by OpenAI employees</a>, for being not open sourced. These critiques also have merit: openness and transparency are important for other researchers to reproduce the technology. After all, good results can always be hard-coded and human-generated on the backend. OpenAI eventually open sourced GPT-2, as <a href="https://github.com/openai/gpt-2">a public repository that is archived</a>, after it felt comfortable that the model won’t be abused. I expect GPT-3 to follow this measured path to eventually becoming open sourced.</p><h2 id="money-can-solve-a-lot-of-problems">Money Can Solve (a lot of) Problems</h2><p>Money can’t solve all our problems, but in the case of GPT-3, it has solved a lot of problems. In this context, money means cloud computing resources to train the model, where the larger the model and training dataset (both of which are very large for GPT-3), the more expensive it is to compute.</p><p>Broadly speaking, the path to developing AGI (artificial general intelligence) falls in one of two camps. One end of the research believes that Deep Learning is <em>not</em> the ultimate technique and more innovation is necessary. The other end believes that the necessary techniques are all available, so the focus should be on how to put them together and scale their training process and production deployment. More succinctly, the former thinks <em><strong>more time</strong></em> is needed to create better techniques, the latter thinks <em><strong>more money</strong></em> is needed to scale the current Deep Learning techniques.</p><p>According to <a href="https://www.technologyreview.com/2020/02/17/844721/ai-openai-moonshot-elon-musk-sam-altman-greg-brockman-messy-secretive-reality/">this MIT Technology Review profile </a>of OpenAI, the group’s strategy squarely falls in the “more money” camp. That’s why it has a rather bizarre corporate structure that’s a hybrid of a nonprofit and a normal VC-backed startup, but the investors’ returns are capped at a certain multiple -- 100x for the earliest round of investors. Microsoft also invested <a href="https://venturebeat.com/2019/07/22/microsoft-invests-1-billion-in-openai-to-develop-ai-technologies-on-azure/">$1 billion in OpenAI</a> with a preferred partnership to use Azure’s cloud infrastructure, as Microsoft works to develop its own AI supercomputer for its cloud offering.</p><p>(<em>Aside: this partnership was quite a coup for Microsoft and to the detriment of Google in particular, given that GPT-3’s theoretical foundation, known as the transformer architecture, originated from Google. Google has also been developing its special-purpose Deep Learning hardware, the TPU (tensor processing unit), to differentiate GCP as the most capable AI cloud on the market. Google of course owns DeepMind, the other AGI company, so forging a partnership with OpenAI may even be a conflict of interest. For what it’s worth, Satya Nadella was openly bullish about </em><a href="https://seekingalpha.com/article/4360065-microsoft-corp-msft-ceo-satya-nadella-on-q4-2020-results-earnings-call-transcript?part=single"><em>GPT-3 during Microsoft’s most recent earnings call</em></a><em> when talking about Azure. Whether OpenAI will help propel Azure to become the market-leading AI cloud or will Google maintain its technical advantage is a competitive dynamic worth watching.)</em></p><figure><img src="https://lh3.googleusercontent.com/P7Sj0IoAnhqFEsCeBUNob3mMvPFsfmy4N6wzps1Klma6dbt4EW2lwBnTO2-96jdnJXlM5L8kTpT7QVAArL3VEbljsZ9F5WE38mnF792VrhKFAaySr2AeOulSRsSl_w-EPCSL_3Z1" alt=""><figcaption>Transformer Architecture model. Source: https://medium.com/inside-machine-learning/what-is-a-transformer-d07dd1fbec04</figcaption></figure><p>That $1 billion Microsoft money is rumored to be <a href="https://www.technologyreview.com/2020/02/17/844721/ai-openai-moonshot-elon-musk-sam-altman-greg-brockman-messy-secretive-reality/">a split between cash and Azure credits</a>. Regardless of which form the money comes in, OpenAI could use it and is using it. GPT-3 is estimated to have <a href="https://venturebeat.com/2020/06/11/openai-launches-an-api-to-commercialize-its-research/">a memory requirement of more than 350GB and a training cost </a>of more than <strong>$12 million</strong>. That’s likely the cost of a single round of training. <strong>Most models go through several rounds of training to achieve good results. </strong>Training GPT-3 three or four times could easily sink around $50 million, and that doesn’t include the cost of data cleaning and pipelining that usually goes into preparing a model for training.</p><p>OpenAI has <a href="https://openai.com/blog/ai-and-compute/">done some interesting research</a> on the connection between the amount of compute used and progress in AI (though perhaps just to support its “more money” approach). Since 2012, the amount of compute used in the largest AI training exercises (e.g. AlphaZero) has been <strong>doubling every 3.4 months</strong>. The research compares and contrasts this finding with <a href="https://en.wikipedia.org/wiki/Moore%27s_law">Moore’s Law</a>, which observes the doubling of the number of transistors on a chip <strong>every two years</strong>. This comparison is only useful to the extent that while <a href="https://www.technologyreview.com/2020/02/24/905789/were-not-prepared-for-the-end-of-moores-law/">Moore’s Law may be reaching its limit</a>, AI computing advancement is far from slowing down. And much of this advancement is focused on parallel computing (i.e. efficient use of multiple chips processing workloads at the same time) and creating more special-purpose AI chips (e.g. TPUs or Tesla’s <a href="https://interconnected.blog/tesla-china-the-tech-cold-war/">Full-Selfing Driving chip</a>, which I’ve written about before), thus it is not directly constrained by Moore’s Law either.</p><figure><img src="https://lh6.googleusercontent.com/i525LbrPPQ941EnDlacKkYUkIdxSH70elCufr2_YA0-g9dvGJl-5aoMmWwfl_HePRJUrIpyQJAndwNAzNE9GIZhKKTIYnv5L8o8OrMXVmrMECG01-N5MMwEiiXEsTwjO4Z8jbHe8" alt=""><figcaption>Source: https://openai.com/blog/ai-and-compute/</figcaption></figure><p>I have a pragmatic attitude towards AI (and most things) and don’t have a strong opinion between the “more time” vs “more money” approach. If it’s working, it’s working.</p><p>It looks like GPT-3 is definitely working. Even if OpenAI’s <strong>observation and development strategy turn out to be half true</strong>, we will see future generations of GPT advance rapidly within the next five years.</p><h2 id="time-and-expertise-is-premium">Time and Expertise is Premium</h2><p>So what is there left for humans to do? Plenty, but differently.</p><p>What AI models, like GPT, do to language understanding and state-of-the-art computer vision models do to visual understanding is the <strong>continuous commoditization of rote memorization (X is Y) and basic pattern matching (when X happens, Y usually happens), where the value approaches zero</strong>. Thus, any task that falls in one of these two broad categories that is currently done by human beings will be done more by AI.</p><p>We can get a hint of which industries GPT-3 may impact in this way, just by looking at the <a href="https://venturebeat.com/2020/06/11/openai-launches-an-api-to-commercialize-its-research/">initial list of beta users</a>:</p><ul><li>Algolia (search engine)</li><li>Koko (mental health and emotional well-being via chat)</li><li>MessageBird (customer service via text or voice)</li><li>Sapling (HR and operations processes)</li><li>Replika (mental health bot that keeps you company)</li><li>Quizlet (online education via flashcard quizzes)</li><li>Casetext (legal research)</li><li>Reddit (public discussion forum)</li><li>Middlebury Institute (higher education, known for having one of the top foreign language study programs in the world)</li></ul><p>This list of companies and institutions may seem to cover a wide range of unrelated use cases, but they all have an element of memorization or basic pattern matching to their workflow that can be standardized by a well-functioning AI model to ensure consistency and quality. Furthermore, the GPT-3 paper revealed that while training the model was expensive (prohibitively so for most companies), producing inferences (aka results) <a href="https://arxiv.org/pdf/2005.14165.pdf">from the trained model is cheap and consumes little energy</a>. Thus, from a cost-efficiency perspective, companies will be incentivized to build their services on top of something like GPT.</p><p>What all this means, I believe, is that there will be a premium for the one thing that requires more time, but not necessarily money, to acquire: <strong>deep domain expertise</strong>.</p><p>Vitalik Buterin, the creator of the Ethereum blockchain, captured this possibility well in this tweet:</p><figure><blockquote data-width="550"><p lang="en" dir="ltr">I can easily see many jobs in the next 10-20 years changing their workflow to "human describes, AI builds, human debugs". <a href="https://t.co/96ZSNr0YoN">https://t.co/96ZSNr0YoN</a></p>— vitalik.eth (@VitalikButerin) <a href="https://twitter.com/VitalikButerin/status/1284185128768503808?ref_src=twsrc%5Etfw">July 17, 2020</a></blockquote>

</figure><p>What’s implicit in a “human describes, AI builds, human debugs" future is that the human must have enough expertise <strong>built over time</strong> to know “how to describe” a problem and “what to debug”. What this also means is that the very notion of “domain expertise” will become more niche and specific.</p><blockquote><em>Knowing how to onboard a new employee <strong>may not be</strong> that valuable; knowing how to onboard a junior engineer two years out of college, so she can be …</em></blockquote></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://interconnected.blog/gpt-3-abstraction-of-time-money/">https://interconnected.blog/gpt-3-abstraction-of-time-money/</a></em></p>]]>
            </description>
            <link>https://interconnected.blog/gpt-3-abstraction-of-time-money/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24145383</guid>
            <pubDate>Thu, 13 Aug 2020 16:48:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Llama Logs – Architecture Diagrams from Your Logs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24145223">thread link</a>) | @bakenator
<br/>
August 13, 2020 | https://llamalogs.com/docs/what | <a href="https://web.archive.org/web/*/https://llamalogs.com/docs/what">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    

    <p>Overview</p>
    <div>

        <p>Llama Logs is a brand new tool that turns distributed logs into a <b>real time interactive graph</b>.</p>
        <p>Llama Logs was created to help bring clarity to complex cloud architectures.</p>
        

        <p><img height="auto" width="600px" src="https://llamalogs.com/images/doc-examples/complexArch.gif"></p><p>With Llama Logs, <b>never again</b> will you need to:</p>
        <ul>
            <li>Create and update architecture diagrams by hand.</li>
            <li>Install agents onto your machines.</li>
            <li>Hunt down erors through mulitple machines and log files.</li>
            <li>Struggle to teach new team members your architecture.</li>
            <li>Limit your analytics to the machine level.</li>
        </ul> 

        <p>With <b>only a few log lines</b> in your code base, </p>
        <p><img height="auto" width="600px" src="https://llamalogs.com/images/codeScreenshot.png"></p><p>Llama Logs will instantly create a live visualization of the activity within your system. </p>
        
        <p>Llama Logs is <b>built for developers</b>, so the possibilities are endless!</p>
    </div>


    
    <p>The Llama Logs Graph</p>
    <div>
        <p>The graph is where all of the events from a system are visualized automatically by Llama Logs.</p>
        <p>Below is an example of a Llama Logs graph for a Cloud Architecture with Multiple Cloud Functions and a Database.</p>
        <p>Each one of the circles moving between components represents logged events occurring between those two components.</p>
        
        <p><img src="https://llamalogs.com/images/LlamaStartingDemo.gif"></p><p>Instantly we can see the structure and activity of the entire architecture in real time!</p>
        <p>The graph even shows errors in red that are occuring during the response from one of the modules in the first Cloud Function.</p>

        

        <p>See more examples of Llama Logs system visualizations on our <a href="https://llamalogs.com/docs/examples">examples page</a>.</p>
    </div>
    
    
    <p>Benefits</p>
    <div>
        <p>Llama Logs has tremendous benefits over other types of analytics:</p>
        <ul>
            <li>Aggregates distributed data into a single easy to understand graph.</li>
            <li>Seamlessly bridges the gap between application and infrastructure data layers.</li>
            <li>Handles millions of events per component with ease.</li>
            <li>Allows <b>You</b> to creatively define how your data will be visualized.</li>
        </ul>
    </div>


    
    
    <p>Supported Languages</p>
    
    
    
    <p>Demo</p>
    <div>
        <p>You are only 2 clicks away having a live Llama Logs graph to experiment with.</p>
        <p><a href="https://llamalogs.com/docs/demo" target="_blank">Start The Demo</a>
    </p></div>

    


    <p>Start Using Llama Logs</p>
    

    

    <p>More Info</p>
    

    </div></div>]]>
            </description>
            <link>https://llamalogs.com/docs/what</link>
            <guid isPermaLink="false">hacker-news-small-sites-24145223</guid>
            <pubDate>Thu, 13 Aug 2020 16:35:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Architecture of Consoles – Nintendo DS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24145124">thread link</a>) | @bobbybabylon
<br/>
August 13, 2020 | https://www.copetti.org/projects/consoles/nintendo-ds/ | <a href="https://web.archive.org/web/*/https://www.copetti.org/projects/consoles/nintendo-ds/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div class="page"><nav id="navbar"></nav><div><ul><li><a href="#cover-model">Model</a></li><li><a href="#cover-motherboard">Motherboard</a></li><li><a href="#cover-diagram">Diagram</a></li></ul><div><div id="cover-motherboard"><figcaption>Showing first revision<br>Controllers are plugged using a separate daughterboard<br>Missing SRAM chips are on the back and there are four unpopulated SRAM slots</figcaption></div><div id="cover-diagram"><a href="https://www.copetti.org/images/consoles/nintendods/diagram.png"><picture>
<img alt="Diagram" src="https://www.copetti.org/images/consoles/nintendods/diagram.png" data-src="https://www.copetti.org/images/consoles/nintendods/diagram.png"></picture></a><figcaption>If you have trouble following the components: Top is only accessed by ARM9, bottom section is ARM7-only, middle section is shared</figcaption></div></div></div><hr><h2 id="a-quick-introduction">A quick introduction</h2><p>This console is an interesting answer to many needs that weren’t possible to fulfil in the handheld ecosystem. There will be some innovation and a few compromises, but this combination may pave the way for new and ingenious content.</p><hr><h2 id="cpu">CPU</h2><p>As with Nintendo’s <a href="https://www.copetti.org/projects/consoles/game-boy-advance/">previous portable console</a>, the system revolves around a big chip named <strong>CPU NTR</strong>. ‘NTR’ is shorthand for ‘Nitro’, the codename of the original Nintendo DS.</p><p>Now, CPU NTR implements an interesting multi-processor architecture using two different ARM CPUs, this design was done before ARM Holdings officially released multi-processor solutions. So, their functioning may be considered a bit unorthodox taking into account the present technology available.</p><p>While this is not the first parallel system analysed for <a href="https://www.copetti.org/projects/consoles/">this series</a>, its design is very different from the rest. For instance, we are not talking about the ‘experimental’ master-slave configuration that the <a href="https://www.copetti.org/projects/consoles/sega-saturn/">Saturn</a> debuted or the ‘co-processor’ approach found on the <a href="https://www.copetti.org/projects/consoles/playstation/">PS1</a> or <a href="https://www.copetti.org/projects/consoles/nintendo-64/">N64</a>. The Nintendo DS includes two very independent computers that will perform exclusive operations, each one having a dedicated bus. This co-dependency will condition the overall performance of this console.</p><p>That being said, let’s take a look now at the two CPUs:</p><div><ul><li id="tab-1-1-arm7tdmi-link"><a href="#tab-1-1-arm7tdmi">ARM7TDMI</a></li><li id="tab-1-2-arm946e-s-link"><a href="#tab-1-2-arm946e-s">ARM946E-S</a></li></ul><div><div id="tab-1-1-arm7tdmi"><h4>ARM7TDMI</h4><div><a href="https://www.copetti.org/images/consoles/nintendods/cpu/arm7_core.8a9851c20df1dda3c252ae75f544a8ce7a6749026fa4bc870027741cda1003b4.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/nintendods/cpu/arm7_core.8a9851c20df1dda3c252ae75f544a8ce7a6749026fa4bc870027741cda1003b4.png" data-src="https://www.copetti.org/images/consoles/nintendods/cpu/arm7_core.8a9851c20df1dda3c252ae75f544a8ce7a6749026fa4bc870027741cda1003b4.png"></picture></a><figcaption>ARM7 structure and components</figcaption></div><p>Starting with the more familiar one, the <strong>ARM7TDMI</strong> is the same CPU found on the <a href="https://www.copetti.org/projects/consoles/game-boy-advance/#cpu">GameBoy Advance</a> but now running at <strong>~34 MHz</strong> (double its original speed). It still includes all its original features (especially <a href="https://www.copetti.org/projects/consoles/game-boy-advance/#whats-new">Thumb</a>).</p><p>Now for the changes: Because Nintendo’s engineers placed the ARM7 next to most of the I/O ports, this CPU will be tasked with arbitrating and assisting I/O operations. In fact, no other processor can directly connect to the I/O. As you can see, this is not the ‘main’ processor that will be in charge of the system, but rather the ‘sub-processor’ offloading the main CPU by passing data around many components.</p></div><div id="tab-1-2-arm946e-s"><h4>ARM946E-S</h4><div><a href="https://www.copetti.org/images/consoles/nintendods/cpu/arm9_core.213329ca27287083c84d30b27fb9da63edd81998406a10b9ee7289089d0fe94d.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/nintendods/cpu/arm9_core.213329ca27287083c84d30b27fb9da63edd81998406a10b9ee7289089d0fe94d.png" data-src="https://www.copetti.org/images/consoles/nintendods/cpu/arm9_core.213329ca27287083c84d30b27fb9da63edd81998406a10b9ee7289089d0fe94d.png"></picture></a><figcaption>ARM9 structure and components</figcaption></div><p>Here is the ‘main’ CPU of the Nintendo DS running at <strong>~67 MHz</strong>. If you ignore the ill-fated ARM8 series, you could say the ARM946E-S is the ‘next-gen’ version of the ARM7. Part of the <strong>ARM9 series</strong>, this core in particular not only inherits all the features of the <strong>ARM7TDMI</strong> but also includes some additional bits:</p><ul><li>The <strong>ARMv5TE ISA</strong>: Compared to the previous v4, features some new instructions and a faster multiplier.<ul><li>If you take a look at the core name, the letter ‘E’ means <strong>Enhanced DSP</strong> which implies that lots of these new instructions have to do with applications for signal processing.</li></ul></li><li><strong>5-stage Pipeline</strong>: This is another increment from the previous 3-stage pipeline.</li><li><strong>12 KB of L1 Cache</strong>: The core now features cache, where 8 KB are allocated for instructions and 4 KB for data.</li><li><strong>48 KB of Tightly-Coupled Memory</strong> or ‘TCM’: Similar to <a href="https://www.copetti.org/projects/consoles/playstation/#cpu">Scratchpad memory</a>, however this one discriminates between instructions (32 KB) and data (16 KB).</li></ul><p>Nintendo also added the following components around it:</p><ul><li>A <strong>Divisor and Square root unit</strong> to speed up these type of operations (the ARM9 by itself is not capable of performing this type of math).</li><li>A <strong>Direct Memory Access Controller</strong>: Accelerates memory transfers without depending on the CPU. Combined with the use of cache, both CPU and DMA can potentially work concurrently.<ul><li>Cache and DMA can provide a lot of performance but also create new problems, such as data integrity. So programmers will have to manually maintain memory consistency by flushing the <a href="https://www.copetti.org/projects/consoles/playstation-2/#preventing-past-mishaps">write-buffer</a> before triggering DMA, for instance.</li></ul></li></ul></div></div></div><p>I guess with hardware like this, it’s easy to figure out the <em>real</em> reason kids loved this console, eh?</p><h4 id="interconnection">Interconnection</h4><p>So far I’ve talked about how the two CPUs work individually. But to work as a whole, they require to co-operate constantly. To accomplish this, both CPUs directly ‘talk’ to each other using a dedicated <strong>FIFO unit</strong>, this block of data holds two 64-byte queues (up to 16 elements) for <strong>bi-directional communication</strong>.</p><div><a href="https://www.copetti.org/images/consoles/nintendods/cpu/fifo.4c452b5f9236fb1e98454d2f90d2cab902ee4c561e165e8eaf8a8fc0cd7a05f4.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/nintendods/cpu/fifo.4c452b5f9236fb1e98454d2f90d2cab902ee4c561e165e8eaf8a8fc0cd7a05f4.png" data-src="https://www.copetti.org/images/consoles/nintendods/cpu/fifo.4c452b5f9236fb1e98454d2f90d2cab902ee4c561e165e8eaf8a8fc0cd7a05f4.png"></picture></a><figcaption>Representation of FIFO unit</figcaption></div><p>This works as follows: The ‘sender’ CPU (that effectively needs to send the other a message) places a 32-bit block of data in the queue, the CPU acting as a ‘receiver’ can then pull that block from the queue and perform the required operations with it.</p><p>Whenever there’s a value written on the queue, either CPU can fetch it manually (<strong>polling</strong>) however, this requires to constantly check for new values (which can be expensive). Alternatively, an <strong>interrupt unit</strong> can be activated to notify the receiver whenever there’s a new value in the queue.</p><h4 id="main-memory">Main memory</h4><p>Just like its predecessor, RAM is spread around many different locations, enabling to prioritise data placement by speed of access. In summary, we have the following general-purpose memory available:</p><div><div><a href="https://www.copetti.org/images/consoles/nintendods/cpu/ram.99e9bd12e464182ef51ea4aa89a7fc60323a46a72550afbacd737957372cf190.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/nintendods/cpu/ram.99e9bd12e464182ef51ea4aa89a7fc60323a46a72550afbacd737957372cf190.png" data-src="https://www.copetti.org/images/consoles/nintendods/cpu/ram.99e9bd12e464182ef51ea4aa89a7fc60323a46a72550afbacd737957372cf190.png"></picture></a><figcaption>RAM model of this console</figcaption></div><ul><li><strong>32 KB of WRAM</strong> (Work RAM) using a <strong>32-bit</strong> bus: To hold fast data shared between the ARM7 and ARM9.<ul><li>Bear in mind that only one CPU can access the same address at a time.</li></ul></li><li><strong>64 KB of WRAM</strong> using a <strong>32-bit</strong> bus: For fast data as well, but only accessible from the ARM7, like the GBA had.</li><li><strong>4 MB of PSRAM</strong> using a <strong>16-bit</strong> bus: A slower type, available from either CPU and it’s controlled by a memory interface unit.<ul><li>Pseudo SRAM or ‘PSRAM’ is a variant of DRAM which, by contrast, performs refreshes from within the chip. Therefore, behaving like SRAM (the faster, but more expensive alternative to DRAM). This design reminds me of <a href="https://www.copetti.org/projects/consoles/gamecube/#clever-memory-system">1T‑SRAM</a>.</li></ul></li></ul></div><h4 id="backwards-compatibility">Backwards compatibility</h4><p>Even though the architecture is significantly different from its predecessor, it still managed to maintain the critical bits that would grant it native compatibility with GameBoy Advance games.</p><p>But for the DS to revert to an ‘internal’ GBA, the former includes a set of software routines that set the console in <strong>AGB Compatibility Mode</strong>. In doing so, it effectively halts the ARM9, disables most of the ‘special’ hardware, redirects the buses, puts the ARM7 in charge and slows it down at 16.78 MHz. Finally, the ARM7 proceeds to boot the original AGB BIOS which bootstraps the GamePak cartridge (just like an original GameBoy Advance). This mode still exhibits some features not found in the original console, such as displaying the game with black margins (we’ll see in the next section that the new screen resolution happens to be bigger). Moreover, since the DS has two screens, users can set which screen will be used to display the GBA game.</p><p>Once in GBA mode <strong>there’s no going back</strong>, the console must be reset to re-activate the rest of the hardware.</p><h4 id="secrets-and-limitations">Secrets and limitations</h4><p>With so many sophisticated components fitted in a single and inexpensive chip, it’s no mystery that some issues emerged due to the way they were forced to work with each other.</p><div><ul><li id="tab-2-1-unused-power-link"><a href="#tab-2-1-unused-power">Unused Power</a></li><li id="tab-2-2-a-question-about-the-hardware-choice-link"><a href="#tab-2-2-a-question-about-the-hardware-choice">A question about the hardware choice</a></li></ul><div><div id="tab-2-1-unused-power"><h4>Unused Power</h4><p>Sometimes I wonder how Nintendo planned the way the two CPU’s would be used, and if they already assumed some performance would be hit by the design they chose.</p><p>Let me start with the ARM9, this CPU runs at twice the speed of the ARM7, but most (if not all) of the I/O depends on the ARM7, so the ARM9 is vulnerable to excessive stalling until the ARM7 answers. If that wasn’t enough, <strong>ARM9’s external bus runs at half the speed</strong>, so there are a few bottlenecks identified.</p><p>Additionally, the Main Memory bus is only <strong>16-bit wide</strong>. Thus, whenever any CPU needs to fetch a word (32-bit wide) from memory, the interface <strong>stalls the CPU</strong> (up to 3 ‘wait’ cycles) until a full world is reconstructed. The worst impact happens when memory access is not sequential, which makes it stall for every single access. This issue will also arise when instructions are fetched (unfortunately, ARM didn’t support sequential opcode fetching back then) which, to my dismay, also affects Thumb code (since every 16-bit fetch is done as a 32-bit block). On the other hand, this penalty (as some sources call it) can be alleviated by making full use of cache and TCM.</p><p>All in all, this means that in the worst case, the ‘whooping’ ARM9’s 66 MHz horsepower is practically reduced to a mere ~8&nbsp;MHz. That is if the program makes an abysmal use of cache/TCM.</p></div><div id="tab-2-2-a-question-about-the-hardware-choice"><h4>A question about the hardware choice</h4><p>Back when I read about the CPU of the GameBoy Advance, I was really surprised by the potential of the ARM7: The CPU not only performed its designated tasks, but could also assist with others, such as providing audio sequencing or pseudo-3D graphics.</p><p>Now, during the commercialisation ARM7, ARM Holdings joined forces with DEC to design a high-end version of ARM’s chips. For this, DEC grabbed the datapath design of their processor, <strong>Alpha</strong>, and mixed it with ARM’s. The result was a new series of CPUs called <strong>StrongARM</strong> which was surprisingly <em>fast</em>. At the expense of removing certain features (Thumb and debug), DEC managed to cross the megahertz threshold by reaching speeds of up to 233 MHz. As a normal user prepared to buy a new ARM PC (let’s say a <em>RiscPC</em>), you could either choose one with the old ARM710 at 40 MHz or another one with a StrongARM running ~582% faster. The impact of StrongARM was so disruptive that ARM Holdings absorbed some of StrongARMs features to produce their next line of CPUs, starting with ARM9. And the rest is history.</p><p>But here’s where my question resides: Considering the new developments in the ARM world, why did Nintendo ultimately choose an awfully slow ARM9 combined by an even slower ARM7, instead of a faster ARM9 (or even a StrongARM)? To give you an idea, other companies like Apple just adopted the StrongARM with their Newton PDA line.</p><p>I don’t mean to criticise Nintendo’s choice, but I believe the amount of emerging technology was just too great for me to ignore. I guess their choice was done in an effort to preserve battery life and maintain production costs (by using the same CPU found in the GBA).</p></div></div></div><hr><h2 id="graphics">Graph…</h2></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.copetti.org/projects/consoles/nintendo-ds/">https://www.copetti.org/projects/consoles/nintendo-ds/</a></em></p>]]>
            </description>
            <link>https://www.copetti.org/projects/consoles/nintendo-ds/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24145124</guid>
            <pubDate>Thu, 13 Aug 2020 16:27:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Open Standards Are Simple]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24145001">thread link</a>) | @freddyym
<br/>
August 13, 2020 | https://portal.mozz.us/gemini/ebc.li/posts/open-standards-are-simple.gmi | <a href="https://web.archive.org/web/*/https://portal.mozz.us/gemini/ebc.li/posts/open-standards-are-simple.gmi">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div><p><a href="https://portal.mozz.us/gemini/ebc.li/">Home</a></p>
<p>2020-08-13

If you want to create a truly open standard, you _need_ to make it simple.

There are no exceptions to this rule. When a standard becomes harder to fully implement than what your average motivated programmer can do in two months (max!), it _shouldn't_ be considered "open" anymore.

Why?

</p>
<h2>Complicated Standards Lead to Implementation Monopolies</h2>
<p>Since implementing a complex standard is hard, you will eventually end up with the implementation that started the earliest and maintained since, being the only implementation that is actually usable. And that implementation will most likely be the one created by the standard's creators.

In cases where the standard's creators don't maintain an implementation like "the web"⁰, the only choices are either the standard dying out because of it's complexity, or the actively maintained implementations requiring tons of effort, with (most likely) companies backing said implementations.

</p>
<h2>Implementation Monopolies Lead to Extensions</h2>
<p>If a big implementation just decides one day that your standard is lacking, they can just extend the parts they want. The two outcomes of this being that:

</p>
<ul><li>The other implementations copy their extensions</li>
<li>That one implementation getting more users, and eventually, a near monopoly because of a bigger feature set</li></ul>
<p>
At that point, the "standard" implemented by said implementations is longer the actual defined standard, but because people will inevitably use the said extensions, any new implementation that wants to be considered usable will eventually need to support said proprietary extensions.

</p>
<h2>Too Many Extensions Spoil The Standard</h2>
<p>Even if you have an "open" extension system, where implementations can all propose and agree on extensions to the standard, you need to be able to keep those implementations in check, so their extensions don't overcomplicate the standard.

Remember: Having a simple standard with a million extensions is no better than a complex standard with no extensions.

</p>
<h2>Examples</h2>
<p>Please note that I will be skipping the elephant in the room: "the web", as it has been discussed _to death_.

</p>
<h3>Matrix</h3>
<p>Matrix is _technically_ an open standard. But because of the complexity it has accumulated over the years, Synapse is the only usable server implementation. Even Dendrite, the new implementation by *the same folk that created the standard*, is barely usable after _years_.

The same applies to Matrix clients, with Element being the only usable client implementation. That space definitely seems healthier than the server space, but the same issues are there.

</p>
<h3>Various Programming Languages</h3>
<p>I will not be specifying any language, as I might get any specifics incorrect, but a general pattern I have seen is that most programming languages have only a few compiler/interpreter implementations, even though the language is standardized in some form.

This example actually has some interesting reasoning behind this issue on top of the complicated standards:

</p>
<ul><li>Writing a compiler/interpreter can be hard.</li>
<li>Especially if the current implementations do optimizations or other "clever" tricks.</li></ul>
<p>
These issues can devolve into arguments regarding seeing the complexity of these issues as a part of the standard, and other "technology is too complicated in general" arguments, which I will not dive into here.

</p>
<h3>X Display Server</h3>
<p>The X Display Server standard got so complicated, the people developing it decided to abandon it entirely and create Wayland.

It probably didn't help that most of the standard was no longer being used, and a lot of extensions are required for its use today.

Wayland probably will also suffer the "too many extensions" problem at some point, so I am looking forward to that too...

</p>
<h2>Footnotes</h2>
<p>0: Well, Google, Mozilla and Apple all had a hand in most of the "modern" parts of the standards...
</p></div>
        </div></div>]]>
            </description>
            <link>https://portal.mozz.us/gemini/ebc.li/posts/open-standards-are-simple.gmi</link>
            <guid isPermaLink="false">hacker-news-small-sites-24145001</guid>
            <pubDate>Thu, 13 Aug 2020 16:19:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Q&A: How Eventbrite prioritizes developer productivity]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24144790">thread link</a>) | @kklin
<br/>
August 13, 2020 | https://kelda.io/blog/eventbrite-interview/ | <a href="https://web.archive.org/web/*/https://kelda.io/blog/eventbrite-interview/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><picture id="hero-thumbnail">
<source data-srcset="https://kelda.io/img/blog/interview%20microphone.webp" type="image/webp"></picture><p><h2>Published on Aug 11, 2020</h2></p></section><p>Deciding when to invest in developer productivity improvements is hard. If you’re on the ops side of things, you’re usually concerned about production and releases. If you’re a developer, you’re concerned about getting new features out as quickly as possible.</p><p>Usually, teams make development productivity improvements in two situations. Either the fix is so small that you can just do it in addition to your other work, or development is so painful that making changes has ground to a halt.</p><p>However, there’s still a large murky middle ground: how do you decide that it’s worth investing in a <strong>large change</strong> to your development workflow <strong>before development has ground to a halt?</strong></p><p><a href="https://medium.com/@remy.dewolf">Remy DeWolf</a> spent three years making these sorts of decisions as a <strong>principal engineer on the DevTools team at Eventbrite</strong>. He was part of the decision to build <code>yak</code>, which moved Eventbrite’s development environment into the cloud. This was a highly calculated decision since it cost a few EC2 instances per engineer and <code>yak</code> was built from scratch.</p><p>In this first post, we’ll dig into how Remy made this tough decision, and got buy-in from the rest of the company. In our next post, we’ll get into the nitty-gritty on how their remote development environment works, and what it’s been like for developers.</p><h2 id="how-is-the-eventbrite-application-architected">How is the Eventbrite application architected?</h2><p>This is a common story that you will find in a lot of startups. The founding engineers built a monolith and the strategy was to build features fast and capture the market. It was a very successful approach.</p><p>As the company grew over time, having a large team working on the monolith became challenging. And after a certain size, it was also harder to keep scaling the monolith vertically.</p><p>Over time, some of the monolith was migrated over to microservices. New services are generally containerized, and the monolith is containerized in development but not in production.</p><h2 id="whats-your-development-environment-setup-now">What’s your development environment setup now?</h2><p>Every engineer runs <strong>~50 containers</strong> which corresponds to the monolith, the microservices, the data stores (MySQL, Redis, Kafka…) and various tools (logging, monitoring).</p><p>Developers use <code>yak</code> (which we built internally) to deploy and manage their remote containers.</p><p>We use AWS EKS for the Kubernetes clusters, in which every developer has their own namespace. We have hundreds of developers and many EKS clusters.</p><p><code>yak</code> is very similar to <a href="https://kelda.io/blimp">blimp</a> since it enables the engineers to manage their remote containers without exposing them to the complexity of Kubernetes.</p><h2 id="how-did-you-decide-it-was-time-to-build-yak">How did you decide it was time to build yak?</h2><p>Before <code>yak</code>, each developer ran their development environment locally on their laptop. However, the development environment became so big that it slowed down developer laptops.</p><p>The main issue was that you might not realize that this was an issue because it was creeping one service at a time.</p><p>Once we added instrumentalization to our tools, we started to understand the scale of the problems. Moving to the cloud is expensive but when we were able to put it side by side with the wasted engineering time, the decision was easy for us.</p><p>Another goal of <code>yak</code> was to make Kubernetes easy for developers. We kept it as minimal as possible and the configuration files are plain Kubernetes manifest files. The intent was to feed developer curiosity so they learn more about Kubernetes over time.</p><h2 id="what-areas-do-you-recommend-tracking-regarding-developer-productivity">What areas do you recommend tracking regarding developer productivity?</h2><p>Whenever possible, align the developer productivity goals with the business. Every DevTool team should understand how they contribute to the company goals and vice versa. If this is unclear, I would start with that.</p><p>Next, make sure that developer productivity is part of the plan, not an afterthought. For example, some engineering teams move to microservices and only track the number of services and the uptime in production. These are great metrics, but they’re incomplete. They will generate inconsistency and the developer experience will suffer over time.</p><p>In terms of which metrics to pick, there is no general recommendation. It’s important to understand how developers work, understand how frequently they perform critical tasks, and instrument the tools that they use. With this data, you will be able to identify the most important areas to invest and track the progress over time.</p><p>I would also recommend having a metric about mean time to recovery (MTTR). If a developer is completely stuck, how would you bring them back to a clean state so they can resume their work? For this one, if you run the developer environment locally, you will have many different combinations of OS/tools/versions resulting in many different issues. If you are on the cloud and use a generic solution (e.g. Docker + Kubernetes), this problem will be much easier to solve.</p><h2 id="how-did-you-collect-feedback-at-eventbrite">How did you collect feedback at Eventbrite?</h2><p>We had many channels:</p><ul><li>Instrumentation into the tools. Every time a developer would build, run, or deploy docker images we would send metrics. Similarly, every CI job would do the same. Then we would generate some dashboards for the metrics to track and measure the progress over time. If you are using a tool like Sumologic or Datadog, it’s very easy to send custom metrics and build dashboards.</li><li>Quarterly engagement surveys.</li><li>Demos: invite other engineers to show them the progress and engage with them.</li><li>New hires: these new employees bring a fresh perspective and they are not afraid to ask questions and challenge the status quo.</li><li>Networking: build relationships with other developers (coffee breaks, office visits, lunches, etc..)</li></ul><h2 id="can-you-give-some-examples-of-developer-productivity-okrs">Can you give some examples of developer productivity OKRs?</h2><ol><li><p><strong>Time to start the developer environment is under x min</strong></p><p>This time is usually wasted time, so it’s important to track it and improve it. If the dev stack is unreliable or slow, it would be captured in this OKR.</p></li><li><p><strong>Engagement is over x%</strong></p><p>If you send an engagement survey every quarter, you can have an OKR to make sure the trend is upward. Seeing a drop would mean that the team might not be working on the most relevant projects.</p></li><li><p><strong>Average time from commit to QA/Prod</strong></p><p>This one will capture the CI/CD pipeline effectiveness. If you experience some flaky tests or deployment errors in the pipeline, it would negatively impact the key results.</p></li></ol><p>Over time, some OKRs will be exhausted, so consider renewing them over time. For example, if your survey always has the same questions, developers will eventually stop responding. Also if an OKR has been greatly improved, it’s a good time to shift priorities.</p><p>In my personal experience, I would focus on a few OKRs instead of having too many. Sometimes by trying to please everybody, you will not have a big impact. Some projects might require the full team focus, which can temporarily impact other OKRs. This would be a calculated strategy as these projects would bring huge improvements when delivered.</p><h2 id="are-there-any-warning-signs-people-should-look-out-for-in-order-to-know-their-developer-productivity-is-suffering">Are there any warning signs people should look out for in order to know their developer productivity is suffering?</h2><p>This is where it’s important to have good metrics and monitor them over time. You should be able to feel the pulse of your developers by looking at different data points. Ideally, you would tie these to your OKRs and review the progress every sprint and make adjustments.</p><p>If you don’t have this data there are still warning signs that productivity is suffering:</p><ul><li>Increase in support cases and/or requests for help. If developers need external help to do their work, this is a sign that a process is too hard to use or not well documented.</li><li>On the other hand, I’d be worried if you find out that some processes aren’t working properly but nobody reported them to your team. You want developers to be always looking for improvements and not accepting a broken process.</li></ul><p>Kelda has collaborated with Eventbrite for a long time. We first met when we were building the predecessor to <a href="https://kelda.io/blimp">Blimp</a>, which moves your Docker Compose development environment into the cloud. Eventbrite had already built <code>yak</code> internally, and we were trying to make a general solution. We’ve been trading ideas ever since.</p><p><a href="https://kelda.io/blimp">Check out Blimp</a> to get the benefits of <code>yak</code> without having to build it yourself!</p><h2 id="references">References</h2><p>See <a href="https://kelda.io/blimp/docs/#/usage">Blimp commands and usage</a> in the Docs</p><p>Read <a href="https://kelda.io/blog/common-docker-compose-mistakes/">5 common Docker Compose mistakes</a></p><p><a href="https://medium.com/@remy.dewolf">Remy DeWolf’s Medium</a></p><hr><p>By: Kevin Lin</p></div></div>]]>
            </description>
            <link>https://kelda.io/blog/eventbrite-interview/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24144790</guid>
            <pubDate>Thu, 13 Aug 2020 16:01:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gemini Gateway]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24144789">thread link</a>) | @jermier
<br/>
August 13, 2020 | https://portal.mozz.us/gemini/gemini.circumlunar.space/ | <a href="https://web.archive.org/web/*/https://portal.mozz.us/gemini/gemini.circumlunar.space/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>

<h2>Overview</h2>
<p>
Gemini is a new internet protocol which:

</p>
<ul><li>Is heavier than gopher</li>
<li>Is lighter than the web</li>
<li>Will not replace either</li>
<li>Strives for maximum power to weight ratio</li>
<li>Takes user privacy very seriously</li></ul>

<h2>Resources</h2>

<p><a href="https://portal.mozz.us/gemini/gemini.circumlunar.space/docs/">Gemini documentation</a><br>
<a href="https://portal.mozz.us/gemini/gemini.circumlunar.space/software/">Gemini software</a><br>
<a href="https://portal.mozz.us/gemini/gemini.circumlunar.space/servers/">Known Gemini servers</a><br>
<a href="https://lists.orbitalfox.eu/listinfo/gemini">Gemini mailing list</a><br>
<a href="https://portal.mozz.us/gemini/gemini.conman.org/test/torture/">Gemini client torture test</a></p>
<h2>Web proxies</h2>

<p><a href="https://portal.mozz.us/?url=gemini%3A%2F%2Fgemini.circumlunar.space%2F&amp;fmt=fixed">Gemini-to-web proxy service</a><br>
<a href="https://proxy.vulpes.one/gemini/gemini.circumlunar.space">Another Gemini-to-web proxy service</a></p>
<h2>Search engines</h2>

<p><a href="https://portal.mozz.us/gemini/gus.guru/">Gemini Universal Search engine</a><br>
<a href="https://portal.mozz.us/gemini/houston.coder.town">Houston search engine</a></p>
<h2>Geminispace aggregators</h2>

<p><a href="https://portal.mozz.us/gemini/gemini.circumlunar.space/capcom/">CAPCOM</a><br>
<a href="https://portal.mozz.us/gemini/rawtext.club:1965/%7Esloum/spacewalk.gmi">Spacewalk</a></p>
<h2>Gemini mirrors of web resources</h2>

<p><a href="https://portal.mozz.us/gemini/gempaper.strangled.net/mirrorlist/">A list of mirrored services</a></p>
<h2>Free Gemini hosting</h2>

<p><a href="https://portal.mozz.us/gemini/gemini.circumlunar.space/users/">Users with Gemini content on this server</a><br></p></div>
        </div></div>]]>
            </description>
            <link>https://portal.mozz.us/gemini/gemini.circumlunar.space/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24144789</guid>
            <pubDate>Thu, 13 Aug 2020 16:01:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Windows 10 LSASS Flaw patched by Microsoft is still vulnerable says researcher]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24144698">thread link</a>) | @vvpvijay
<br/>
August 13, 2020 | https://androidrookies.com/windows-10-lsass-flaw-patched-by-microsoft-is-still-vulnerable-says-researcher/ | <a href="https://web.archive.org/web/*/https://androidrookies.com/windows-10-lsass-flaw-patched-by-microsoft-is-still-vulnerable-says-researcher/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-10134"><div><div><div><h2>Google researcher who found the Windows 8.1/10/Server LSASS Flaw says that Microsoft’s August 2020 patch Tuesday doesn’t fix the vulnerability</h2><p>In May 2020, Google Project Zero security researcher James Forshaw found a highly critical vulnerability in the way Windows systems handle privileges. Forshaw discovered that nearly all Windows operating systems including Windows 8.1, Windows 10, and Windows Server versions are vulnerable to an elevation of privilege vulnerability in the Windows Local Security Authority Subsystem Service (LSASS).</p><p>The vulnerability identified by Forshaw was issued a unique identifier, CVE-2020-1509 and has a CVSS score of 8.8/10.&nbsp; Potential hackers could exploit the vulnerability through specially crafted authentication requests to gain escalated privileges within the Windows system. However, for successful exploitation, the hacker needs to have previously obtained Windows credentials for the local network.&nbsp;“LSASS doesn’t correctly enforce the Enterprise Authentication Capability which allows any AppContainer to perform network authentication with the user’s credentials,” Project Zero security researcher James Forshaw noted in May.</p><p>Microsoft had acknowledged the severity of the LSASS vulnerability and addressed the issue through a fix issued through the <a href="https://androidrookies.com/microsoft-releases-windows-10-cumulative-update-kb4566782-here-is-the-complete-changelog/">August 2020 Patch Tuesday update released on 11th August 2020</a>.&nbsp; Microsoft on its security bulletin says that the patches released through the August 2020 Patch Tuesday fix the issue and there is no further need for mitigation.</p><p>However, Forshaw disagrees. In a tweet, Forshaw said that the patch issued by Microsoft for CVE-2020-1509 is incomplete and Windows 8.1/10/Server run systems are vulnerable to the LSASS flaw.</p><blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">Seems that it was incorrectly fixed (guess it's one of those days). As I pointed out in the original report the parsing of the SPN was wildly incorrect, as it hasn't been fixed as long as the system has a proxy configured you can bypass the fix. <a href="https://t.co/IytJ8YKDKi">https://t.co/IytJ8YKDKi</a> <a href="https://t.co/mXlriMS29R">https://t.co/mXlriMS29R</a></p><p>— James Forshaw (@tiraniddo) <a href="https://twitter.com/tiraniddo/status/1293327807439831040?ref_src=twsrc%5Etfw">August 11, 2020</a></p></blockquote><p>Forshaw says that the Windows operating system run PC/laptops/servers are still vulnerable as long as a configured proxy is present on the system.</p><p>Forshaws says that the <a href="https://bugs.chromium.org/p/project-zero/issues/detail?id=2039#c4">Proof-of-Concept exploit</a> build by him in May can still be used. Only, potential hackers could have to manually add a proxy server in the settings and the code can be executed with specific arguments.&nbsp;“The issue is the DsCrackSpn2 call which was highlighted as incorrect has not been fixed. This allows you to specify an SPN which will both satisfy the proxy check and SPN check-in CIFS etc. This isn’t as general as the original bug as the system needs to have a configured proxy, however in enterprise environments that’s likely a given and where this issue is the most serious.” Forshaw says.</p></div></div></div></article></div>]]>
            </description>
            <link>https://androidrookies.com/windows-10-lsass-flaw-patched-by-microsoft-is-still-vulnerable-says-researcher/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24144698</guid>
            <pubDate>Thu, 13 Aug 2020 15:55:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Palantir Plans Direct Listing for Late September]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24144641">thread link</a>) | @JumpCrisscross
<br/>
August 13, 2020 | https://www.bnnbloomberg.ca/palantir-plans-direct-listing-for-late-september-1.1479300 | <a href="https://web.archive.org/web/*/https://www.bnnbloomberg.ca/palantir-plans-direct-listing-for-late-september-1.1479300">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>(Bloomberg) -- Palantir Technologies Inc. is planning to go public through a direct listing of its shares in late September, according to people familiar with the matter.</p><p>The company, which sells data analysis software used by governments and large companies worldwide, might still change its plans, said the people, who asked not to be identified because the information wasnâ€™t public.</p><p>A company spokeswoman declined to comment.</p><p>A direct listing would allow the companyâ€™s current investors to sell their shares on the first day of trading rather than having to wait for a lock-up period to expire, as would be required in a traditional initial public offering. Unlike an IPO, though, the company doesnâ€™t raise capital in a direct listing.</p><p>Palantir is in the process of raising $961 million, $550 million of which it has already secured, according to a July filing with the U.S. Securities and Exchange Commission. That includes a $500 million investment from Sompo Japan Nipponkoa Holdings Inc. and $50 million from Fujitsu Ltd.</p><p>Those sums make listing the stock directly a more accessible path for Palantir, following in the footsteps of Spotify Technology SA and Slack Technologies Inc.</p><p>Billionaire Peter Thiel founded Palantir in 2003 with a group of business partners including Alex Karp, the chief executive officer. In 2015, Palantir reached a valuation of $20 billion, though in recent years stockholders have sold blocks of shares for much less.</p><p>The company told investors this year that it expects to break even in 2020 on revenue of about $1 billion.</p><p>In June, Palantir added three directors including the first woman to serve on its board, former Wall Street Journal reporter Alexandra Wolfe Schiff.</p><p>Dozens of law enforcement and government agencies around the world use Palantir to compile and search for data on citizens with the intent of combating crime, hunting terrorists and, in recent months, tracking the spread of Covid-19. The pandemic has boosted business as companies use its products to help determine how to reopen.</p><p>Palantir is controversial for the way its tools have been used by some to enable surveillance and compromise privacy. Its use by police and immigration officials, in particular, has sparked numerous protests.</p><p>The Palo Alto, California-based company had long resisted a public offering to avoid getting valued as a consultancy, and to stay out of the public eye while it reduced its dependence on engineers customizing software for each client and worked toward profitability, people familiar with the matter have said.</p><p>The company said in a statement in July that it had filed with the SEC for a â€œpublic listingâ€� of its stock, wording that has been used by other companies planning to pursue a direct listing instead of an IPO.</p><p>Palantirâ€™s funders include Founders Fund, the venture capital firm started by Thiel. Other investors include Morgan Stanley, BlackRock Inc. and Tiger Global Management.</p><p>Â©2020 Bloomberg L.P.</p></div></div>]]>
            </description>
            <link>https://www.bnnbloomberg.ca/palantir-plans-direct-listing-for-late-september-1.1479300</link>
            <guid isPermaLink="false">hacker-news-small-sites-24144641</guid>
            <pubDate>Thu, 13 Aug 2020 15:50:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Postgres Row-Level Security in Python and Django]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24144405">thread link</a>) | @karlhughes
<br/>
August 13, 2020 | https://pganalyze.com/blog/postgres-row-level-security-django-python | <a href="https://web.archive.org/web/*/https://pganalyze.com/blog/postgres-row-level-security-django-python">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>
Postgres introduced <a href="https://www.postgresql.org/docs/9.5/ddl-rowsecurity.html">row-level security</a> in 2016 to give database administrators a way to limit the rows a user can access, adding an extra layer of data protection. What's nice about RLS is that if a user tries to select or alter a row they don't have access to, their query will return 0 rows, rather than throwing a permissions error. This way, a user can use <code>select * from table_name</code>, and they will only receive the rows they have access to with no knowledge of rows they don't.</p>
<p>Most examples of RLS limit row access by database user. This can be a powerful feature. In this article, we will have a look at how you can make this happen for your Django app. The problem most people run into when trying to implement row level security is that most web applications, including Django applications, connect to the database with a single user, which makes it hard to take advantage of row level security. </p>
<p>One way to get around this is to create a database user for each application user. We’ll start with just the database layer. We’ll build out our tables and create a couple of users, then write our first row level security policy to limit which rows those users can access. Once we have an understanding of how RLS works in Postgres, we’ll expand our project out into Django and see how we can handle working with policies and multiple database users in a web application. </p>

<p><span>
      <a href="https://pganalyze.com/static/d60954c89ce5f6b9a9e49e6096324a14/29114/postgres-row-level-security-django.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Postgres Row-Level Security in Python and Django" title="Postgres Row-Level Security in Python and Django" src="https://pganalyze.com/static/d60954c89ce5f6b9a9e49e6096324a14/8c557/postgres-row-level-security-django.png" srcset="https://pganalyze.com/static/d60954c89ce5f6b9a9e49e6096324a14/4edbd/postgres-row-level-security-django.png 175w, https://pganalyze.com/static/d60954c89ce5f6b9a9e49e6096324a14/13ae7/postgres-row-level-security-django.png 350w, https://pganalyze.com/static/d60954c89ce5f6b9a9e49e6096324a14/8c557/postgres-row-level-security-django.png 700w, https://pganalyze.com/static/d60954c89ce5f6b9a9e49e6096324a14/e996b/postgres-row-level-security-django.png 1050w, https://pganalyze.com/static/d60954c89ce5f6b9a9e49e6096324a14/2cefc/postgres-row-level-security-django.png 1400w, https://pganalyze.com/static/d60954c89ce5f6b9a9e49e6096324a14/29114/postgres-row-level-security-django.png 1920w" sizes="(max-width: 700px) 100vw, 700px" loading="lazy">
  </a>
    </span></p>
<h2 id="how-to-use-rls-at-the-database-level"><a href="#how-to-use-rls-at-the-database-level" aria-label="how to use rls at the database level permalink"></a>How to use RLS at the database level</h2>
<p>Before we get to the Django side of things, let's take a look at how RLS works in Postgres. We'll keep it simple and say we are building an app to help our salespeople keep track of their clients, and we want to make sure no salesperson can access the clients of another salesperson. (These are very competitive, cutthroat salespeople). </p>
<p>First, let's set up our tables and populate them with some data:</p>
<div data-language="sql"><pre><code><span>CREATE</span> <span>TABLE</span> salespeople <span>(</span>id <span>serial</span> <span>primary</span> <span>key</span><span>,</span> name <span>text</span><span>)</span><span>;</span>
<span>CREATE</span> <span>TABLE</span> clients <span>(</span>id <span>serial</span> <span>primary</span> <span>key</span><span>,</span> name <span>text</span><span>,</span> salesperson_id <span>integer</span><span>)</span><span>;</span>

<span>INSERT</span> <span>INTO</span> salespeople <span>(</span>name<span>)</span> <span>values</span> <span>(</span><span>'Picard'</span><span>)</span><span>;</span>
<span>INSERT</span> <span>INTO</span> salespeople <span>(</span>name<span>)</span> <span>values</span> <span>(</span><span>'Crusher'</span><span>)</span><span>;</span>

<span>INSERT</span> <span>INTO</span> clients <span>(</span>name<span>,</span> salesperson_id<span>)</span> <span>values</span> <span>(</span><span>'client1'</span><span>,</span> <span>1</span><span>)</span><span>;</span>
<span>INSERT</span> <span>INTO</span> clients <span>(</span>name<span>,</span> salesperson_id<span>)</span> <span>values</span> <span>(</span><span>'client2'</span><span>,</span> <span>2</span><span>)</span><span>;</span>
<span>INSERT</span> <span>INTO</span> clients <span>(</span>name<span>,</span> salesperson_id<span>)</span> <span>values</span> <span>(</span><span>'client3'</span><span>,</span> <span>2</span><span>)</span><span>;</span></code></pre></div>
<p>Now, we have two salespeople. <code>Picard</code> has one client, and <code>Crusher</code> has two clients.</p>
<p>Next, we are going to need some database users, one for each salesperson. Because two salespeople might share the same name, we are going to use the <code>id</code> to create Postgres users. We are also going to create a role called <code>salespeople</code>. This will be the role we grant permissions on, and all of our salespeople can inherit from it.</p>
<div data-language="sql"><pre><code><span>CREATE</span> ROLE <span>"1"</span><span>;</span>
<span>CREATE</span> ROLE <span>"2"</span><span>;</span>
<span>CREATE</span> ROLE salespeople<span>;</span>

<span>GRANT</span> <span>select</span><span>,</span> <span>insert</span> <span>ON</span> clients <span>TO</span> salespeople<span>;</span>
<span>GRANT</span> salespeople <span>TO</span> <span>"1"</span><span>;</span>
<span>GRANT</span> salespeople <span>TO</span> <span>"2"</span><span>;</span></code></pre></div>
<p>This setup will come in handy in the next section when we have to deal with Django's tables in addition to the ones we create for our models.</p>
<p>Now we are ready to set up RLS on our <code>clients</code> table. Our policy will limit access to the Postgres <code>current_user</code> so that they can only view rows where <code>current_user</code> matches <code>salesperson_id</code>. </p>
<div data-language="sql"><pre><code><span>ALTER</span> <span>TABLE</span> clients <span>ENABLE</span> <span>ROW</span> <span>LEVEL</span> SECURITY<span>;</span>
<span>CREATE</span> POLICY salesperson_clients <span>ON</span> clients <span>USING</span> <span>(</span>salesperson_id::<span>text</span> <span>=</span> <span>current_user</span><span>)</span><span>;</span></code></pre></div>
<p>When we create the policy, we give it a name, <code>salesperson_clients</code>, and enter the table we want to set the policy on, <code>clients</code>. Next, we define the policy. In this case, it is very simple: the <code>salesperson_id</code> on the table must be equal to the value of <code>current_user</code>. We have to convert the <code>salesperson_id</code> from an integer to text because our <code>current_user</code> must be a string (we can't create Postgres users with integers as names).</p>
<p>Right now, we are logged in as the <code>postgres</code> user.</p>
<div data-language="sql"><pre><code><span>SELECT</span> <span>session_user</span><span>,</span> <span>current_user</span><span>;</span></code></pre></div>
<div data-language="text"><pre><code> session_user  | current_user  
---------------+---------------
 postgres      | postgres
(1 row)</code></pre></div>
<p>If we query our <code>clients</code> table, we will be able to see all the rows because <strong>RLS policies do not apply to superusers.</strong></p>

<div data-language="text"><pre><code> id |  name   | salesperson_id 
----+---------+----------------
  1 | client1 |              1
  2 | client2 |              2
  3 | client3 |              2
(3 rows)</code></pre></div>
<p>But if we change the current user, we only get the rows that belong to that user. </p>
<div data-language="sql"><pre><code><span>SET</span> ROLE <span>"1"</span><span>;</span>
<span>SELECT</span> <span>session_user</span><span>,</span> <span>current_user</span><span>;</span></code></pre></div>
<div data-language="text"><pre><code> session_user | current_user 
--------------+--------------
 postgres     | 1
(1 row)</code></pre></div>

<div data-language="text"><pre><code> id |  name   | salesperson_id 
----+---------+----------------
  1 | client1 |              1
(1 row)</code></pre></div>
<h2 id="how-to-use-postgres-row-level-security-in-django"><a href="#how-to-use-postgres-row-level-security-in-django" aria-label="how to use postgres row level security in django permalink"></a>How to Use Postgres Row-Level Security in Django</h2>
<p>Now, how can we translate this to a Django application?</p>
<p>First, we will need to create a database user for each app user we create. One way to accomplish this would be to override the <code>save</code> method on the Salesperson model, but this is a great opportunity to take advantage of <a href="https://docs.djangoproject.com/en/3.0/ref/signals/">Django signals</a> , so we'll create a signal that creates the database user after a new salesperson is saved.  </p>
<p>Next, we'll have to figure out how to switch to the correct user when a salesperson logs in. For this, we can use a middleware that gets the <code>salesperson_id</code> and sets the role in the database. </p>
<h3 id="models"><a href="#models" aria-label="models permalink"></a>Models</h3>
<p>Our models reflect exactly what we set up in our earlier database example. Here I chose to make Salesperson a proxy of Django's built-in <code>User</code> model, but this is not required.</p>
<div data-language="python"><pre><code><span>from</span> django<span>.</span>db <span>import</span> models
<span>from</span> django<span>.</span>contrib<span>.</span>auth<span>.</span>models <span>import</span> User

<span>class</span> <span>Salesperson</span><span>(</span>User<span>)</span><span>:</span>
    <span>class</span> <span>Meta</span><span>:</span>
        proxy <span>=</span> <span>True</span>
    
<span>class</span> <span>Client</span><span>(</span>models<span>.</span>Model<span>)</span><span>:</span>
    name <span>=</span> models<span>.</span>CharField<span>(</span>max_length<span>=</span><span>50</span><span>)</span>
    Salesperson <span>=</span> models<span>.</span>ForeignKey<span>(</span>Employee<span>,</span> on_delete<span>=</span>models<span>.</span>CASCADE<span>)</span></code></pre></div>
<h3 id="django-signals-creating-our-database-user"><a href="#django-signals-creating-our-database-user" aria-label="django signals creating our database user permalink"></a>Django Signals: Creating Our Database User</h3>
<p>We want to create a new database user every time a new salesperson record is created. We can use Django signals to execute some code after a new record is saved. If you're not familiar with signals, the Django docs on this topic are easy to understand. If this piqued your interest, <a href="https://simpleisbetterthancomplex.com/tutorial/2016/07/28/how-to-create-django-signals.html">this article</a> goes into more detail. </p>
<p>Here is the code for the signal itself, but you'll have to reference the above article to get it registered in your app: </p>
<div data-language="python"><pre><code><span>from</span> <span>.</span>models <span>import</span> Salesperson
<span>from</span> django<span>.</span>db<span>.</span>models<span>.</span>signals <span>import</span> post_save
<span>from</span> django<span>.</span>db <span>import</span> connection

<span>def</span> <span>create_db_user</span><span>(</span>sender<span>,</span> instance<span>,</span> created<span>,</span> <span>**</span>kwargs<span>)</span><span>:</span>
    <span>if</span> created<span>:</span>
        user_id <span>=</span> instance<span>.</span><span>id</span>
        <span>with</span> connection<span>.</span>cursor<span>(</span><span>)</span> <span>as</span> cursor<span>:</span>
            cursor<span>.</span>execute<span>(</span><span><span>f'CREATE ROLE "</span><span><span>{</span>user_id<span>}</span></span><span>"'</span></span><span>)</span>
            cursor<span>.</span>execute<span>(</span><span><span>f'GRANT salespeople TO "</span><span><span>{</span>user_id<span>}</span></span><span>"'</span></span><span>)</span>

post_save<span>.</span>connect<span>(</span>create_db_user<span>,</span> sender<span>=</span>Salesperson<span>)</span> </code></pre></div>
<p>The <code>post_save</code> signal can take a named argument <code>created</code>, which is a boolean. This avoids running the code every time we update the record and ensures it will only run when we create a new salesperson. From there, we can get the user id from the instance and use <code>django.db.connection</code> to run our SQL to create the role and grant permissions. </p>
<p>It's very important to note that if you want to use Django's built-in <code>User</code> model and the authentication that comes with it, you'll need to grant <code>salesperson</code> permissions on the <code>django_admin_log</code> and <code>auth_user</code> tables. That's why it's so helpful to have this parent role that all individual users inherit from.</p>
<h3 id="django-middleware-setting-current-user"><a href="#django-middleware-setting-current-user" aria-label="django middleware setting current user permalink"></a>Django Middleware: Setting Current User</h3>
<p>Now, we can write a <a href="https://docs.djangoproject.com/en/3.0/topics/http/middleware/">middleware</a> to switch the database user to the current application user making the request.</p>
<div data-language="python"><pre><code><span>from</span> django<span>.</span>db <span>import</span> connection

<span>class</span> <span>RlsMiddleware</span><span>(</span><span>object</span><span>)</span><span>:</span>
    <span>def</span> <span>__init__</span> <span>(</span>self<span>,</span> get_response<span>)</span><span>:</span>
        self<span>.</span>get_response <span>=</span> get_response
        
    <span>def</span> <span>__call__</span> <span>(</span>self<span>,</span> request<span>)</span><span>:</span>
        user_id <span>=</span> request<span>.</span>user<span>.</span><span>id</span>
        <span>with</span> connection<span>.</span>cursor<span>(</span><span>)</span> <span>as</span> cursor<span>:</span>
            cursor<span>.</span>execute<span>(</span><span><span>f'SET ROLE "</span><span><span>{</span>user_id<span>}</span></span><span>" '</span></span><span>)</span>

        response <span>=</span> self<span>.</span>get_response<span>(</span>request<span>)</span>
        <span>return</span> response</code></pre></div>
<p>We get the user id from the request object. After that, the code looks pretty similar to our signal. We use the Django <code>db</code> connection again to set the role to the corresponding database user, which should match the application user's id. Don't forget to <a href="https://docs.djangoproject.com/en/3.0/topics/http/middleware/#activating-middleware">register your middleware</a> in <code>settings.py</code>.</p>
<p>Now we can use all of Django's built-in query methods while maintaining row-level security in Postgres. What is particularly cool is that, with the role set, all we need to do to get all of a salesperson's clients is call <code>Client.objects.all()</code>, and we can be sure that only the clients related to the salesperson will be returned. If a salesperson tries to query for a client that doesn't belong to them, they'll get zero results.</p>
<h2 id="conclusion"><a href="#conclusion" aria-label="conclusion permalink"></a>Conclusion</h2>
<p>In this article we were able to create a simple but powerful row level security policy and, with the help of Django middleware and Django signals, implement the policy at the application level. We saw how to create database users each time we created a new application user, and looked at setting the database role to the correct user after log in, ensuring each application user only had access to the rows that belonged to them. </p>
<p>There are a few caveats here. For one, using the ids <code>1, 2, 3</code> is probably not a good idea in production. You'd want to set up some kind of UUID or some other identifier. Also, creating a new database user for every application user becomes hard to scale at a certain point. Row level security can be a useful tool for limiting access at the database level, and we just scratched the surface of what's possible.</p>
<p>Still, you should be sure RLS is the right solution for your application before trying to implement it. In particular, the performance implications of row-level security, and how the Postgres planner treats it for query plans should not be overlooked. This has been <a href="https://medium.com/@cazzer/designing-the-most-performant-row-level-security-strategy-in-postgres-a06084f31945">significantly improved in Postgres 10</a>, but its still essential to <a href="https://pganalyze.com/postgres-explain">monitor your Postgres query plans</a> when using RLS.</p>
<p>In many cases, RLS is not needed, and you’ll be able to secure your data using the <a href="https://coderbook.com/@marcus/how-to-restrict-access-with-django-permissions/">security measures</a> already built into Django.</p>
<p><strong>Share this article:</strong> If you liked this article you might want to <a href="https://ctt.ac/K5png">tweet it to your peers</a>.</p>
<h2 id="about-the-author"><a href="#about-the-author" aria-label="about the author permalink"></a>About the Author</h2>
<p>Josh is a former educator turned developer with a proven ability to learn …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pganalyze.com/blog/postgres-row-level-security-django-python">https://pganalyze.com/blog/postgres-row-level-security-django-python</a></em></p>]]>
            </description>
            <link>https://pganalyze.com/blog/postgres-row-level-security-django-python</link>
            <guid isPermaLink="false">hacker-news-small-sites-24144405</guid>
            <pubDate>Thu, 13 Aug 2020 15:33:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A breakdown of how Nginx is configured with Django]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24144369">thread link</a>) | @ralston3
<br/>
August 13, 2020 | https://mattsegal.dev/nginx-django-reverse-proxy-config.html | <a href="https://web.archive.org/web/*/https://mattsegal.dev/nginx-django-reverse-proxy-config.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>You are trying to deploy your Django web app to the internet.
You have never done this before, so you follow a guide like <a href="https://www.digitalocean.com/community/tutorials/how-to-set-up-django-with-postgres-nginx-and-gunicorn-on-ubuntu-16-04">this one</a>.
The guide gives you many instructions, which includes installing and configuring an "NGINX reverse proxy".
At some point you mutter to yourself:</p>
<blockquote>
<p>What-the-hell is an NGINX? Eh, whatever, let's keep reading.</p>
</blockquote>
<p>You will have to copy-paste some weird gobbledygook into a file, which looks like this:</p>
<div><pre><span></span><code><span># NGINX site config file at /etc/nginx/sites-available/myproject</span>
<span>server</span> <span>{</span>
    <span>listen</span> <span>80</span><span>;</span>
    <span>server_name</span> <span>foo.com</span><span>;</span>
    <span>location</span> <span>/</span> <span>{</span>
        <span>proxy_pass</span> <span>http://127.0.0.1:8000</span><span>;</span>
        <span>proxy_set_header</span> <span>Host</span> <span>$host</span><span>;</span>
        <span>proxy_set_header</span> <span>X-Forwarded-For</span> <span>$proxy_add_x_forwarded_for</span><span>;</span>
        <span>proxy_set_header</span> <span>X-Forwarded-Proto</span> <span>$scheme</span><span>;</span>
        <span>proxy_redirect</span> <span>http://127.0.0.1:8000</span> <span>http://foo.com</span><span>;</span>
    <span>}</span>
    <span>location</span> <span>/static/</span> <span>{</span>
        <span>root</span> <span>/home/myuser/myproject</span><span>;</span>
    <span>}</span>
<span>}</span>
</code></pre></div>
<p>What is all this stuff? What is it supposed to do?</p>
<p>Most people do their first Django deployment as a learning exercise.
You want to understand what you are doing, so that you can fix problems if you get stuck
and so you don't need to rely on guides in the future.
In this post I'll break down the elements of this NGINX config and how it ties in with Django,
so that you can confidently debug, update and extend it in the future.</p>
<h2>What is this file supposed to achieve?</h2>
<p>This scary-looking config file sets up NGINX so that it acts as the entrypoint to your Django application.
Explaining <em>why</em> you might choose to use NGINX is a topic too expansive for this post, so I'm just going to stick to explaining
how it works.</p>
<p>NGINX is completely separate program to your Django app.
It is running inside its own process, while Django is running inside a <a href="https://mattsegal.dev/simple-django-deployment-2.html#wsgi">WSGI server</a> process, such as Gunicorn.
In this post I will sometimes refer to Gunicorn and Django interchangeably.</p>
<p><img alt="nginx as a separate process" src="https://mattsegal.dev/nginx-separate-process.png"></p>
<p>All HTTP requests that hit your Django app have to go through NGINX first.</p>
<p><img alt="nginx proxy" src="https://mattsegal.dev/nginx-proxy.png"></p>
<p>NGINX listens for incoming HTTP requests on port 80 and HTTPS requests on port 443.
When a new request comes in:</p>
<ul>
<li>NGINX looks at the request, checks some rules, and sends it on to your WSGI server, which is usually listening on localhost, port 8000</li>
<li>Your Django app will process the request and eventually produce a response</li>
<li>Your WSGI server will send the response back to NGINX; and then</li>
<li>NGINX will send the response back out to the original requesting client</li>
</ul>
<p>You can also configure NGINX to serve static files, like images, directly from the filesystem, so that requests for these assets don't need to go through Django</p>
<p><img alt="nginx proxy with static files" src="https://mattsegal.dev/nginx-static-proxy.png"></p>
<p>You can adjust the rules in NGINX so that it selectively routes requests to multiple app servers. You could, for example, run a Wordpress site and a Django app from the same server:</p>
<p><img alt="nginx multi proxy" src="https://mattsegal.dev/nginx-multi-proxy.png"></p>
<p>Now that you have a general idea of what NGINX is supposed to do, let's go over the config file that makes this happen.</p>
<h2>Server block</h2>
<p>The top level block in the NGINX config file is the <a href="https://docs.nginx.com/nginx/admin-guide/web-server/web-server/#setting-up-virtual-servers">virtual server</a>.
The main utility of virtual servers is that they allow you to sort incoming requests based on the port and hostname.
Let's start by looking at a basic server block:</p>
<div><pre><span></span><code><span>server</span> <span>{</span>
    <span># Listen on port 80 for incoming requests.</span>
    <span>listen</span> <span>80</span><span>;</span>
    <span># Return status code 200 with text "Hello World".</span>
    <span>return</span> <span>200</span> <span>'Hello</span> <span>World'</span><span>;</span>
<span>}</span>
</code></pre></div>
<p>Let me show you some example requests. Say we're on the same server as NGINX and we send a GET request using the command line tool <code>curl</code>.</p>
<div><pre><span></span><code>curl localhost
<span># Hello World</span>
</code></pre></div>
<p>This <code>curl</code> command sends the following <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Messages">HTTP request</a> to localhost, port 80:</p>
<div><pre><span></span><code><span>GET</span> <span>/</span> <span>HTTP</span><span>/</span><span>1.1</span>
<span>Host</span><span>:</span> <span>localhost</span>
<span>User-Agent</span><span>:</span> <span>curl/7.58.0</span>
</code></pre></div>
<p>We will get the following HTTP response back from NGINX, with a 200 OK status code and "Hello World" in the body:</p>
<div><pre><span></span><code><span>HTTP</span><span>/</span><span>1.1</span> <span>200</span> <span>OK</span>
<span>Content-Type</span><span>:</span> <span>application/octet-stream</span>
<span>Content-Length</span><span>:</span> <span>11</span>

Hello World
</code></pre></div>
<p>We can also request some random path and we get the same result:</p>
<div><pre><span></span><code>curl localhost/some/path/on/website
<span># Hello World</span>
</code></pre></div>
<p>With <code>curl</code> sending this HTTP request: </p>
<div><pre><span></span><code><span>GET</span> <span>/some/path/on/website</span> <span>HTTP</span><span>/</span><span>1.1</span>
<span>Host</span><span>:</span> <span>localhost</span>
<span>User-Agent</span><span>:</span> <span>curl/7.58.0</span>
</code></pre></div>
<p>and we get back the same response as before:</p>
<div><pre><span></span><code><span>HTTP</span><span>/</span><span>1.1</span> <span>200</span> <span>OK</span>
<span>Content-Type</span><span>:</span> <span>application/octet-stream</span>
<span>Content-Length</span><span>:</span> <span>11</span>

Hello World
</code></pre></div>
<p>Simple so far, but not very interesting, let's start to mix it up with multiple server blocks.</p>
<h2>Multiple virtual servers</h2>
<p>You can add more than one virtual server in NGINX:</p>
<div><pre><span></span><code><span># All requests to foo.com return a 200 OK status code</span>
<span>server</span> <span>{</span>
    <span>listen</span> <span>80</span><span>;</span>
    <span>server_name</span> <span>foo.com</span><span>;</span>
    <span>return</span> <span>200</span> <span>'Welcome</span> <span>to</span> <span>foo.com!'</span><span>;</span>
<span>}</span>

<span># Any other requests get a 404 Not Found page</span>
<span>server</span> <span>{</span>
    <span>listen</span> <span>80</span> <span>default_server</span><span>;</span>
    <span>return</span> <span>404</span><span>;</span>
<span>}</span>
</code></pre></div>
<p>NGINX uses the <code>server_name</code> directive to check the <code>Host</code> header of incoming requests and match the request to a virtual server. Your web browser will usually set this header automatically for you.
You can set up a particular virtual server to be the default choice (<code>default_server</code>) if no other ones match the incoming request. You can use this feature to host multiple
Django apps on a single server. All you need to do is <a href="https://mattsegal.dev/dns-for-noobs.html">set up your DNS</a> to get multiple domain names to point to a single server, and then add a virtual server for each Django app.</p>
<p>Let's test out the config above. If send a request to <code>localhost</code>, we'll get a 404 status code from the default server:</p>
<div><pre><span></span><code>curl localhost
<span># &lt;html&gt;</span>
<span>#   &lt;head&gt;&lt;title&gt;404 Not Found&lt;/title&gt;&lt;/head&gt;</span>
<span>#   ...</span>
<span># &lt;/html&gt;</span>
</code></pre></div>
<p>This is the request that gets sent:</p>
<div><pre><span></span><code><span>GET</span> <span>/</span> <span>HTTP</span><span>/</span><span>1.1</span>
<span>Host</span><span>:</span> <span>localhost</span>
<span>User-Agent</span><span>:</span> <span>curl/7.58.0</span>
</code></pre></div>
<p>Our request was matched to the default server because the <code>Host</code> header we sent didn't match <code>foo.com</code>. Let's try setting the <code>Host</code> header to <code>foo.com</code>:</p>
<div><pre><span></span><code>curl localhost --header <span>"Host: foo.com"</span>
<span># Welcome to foo.com!</span>
</code></pre></div>
<p>This is the request that gets sent:</p>
<div><pre><span></span><code><span>GET</span> <span>/</span> <span>HTTP</span><span>/</span><span>1.1</span>
<span>Host</span><span>:</span> <span>foo.com</span>
<span>User-Agent</span><span>:</span> <span>curl/7.58.0</span>
</code></pre></div>
<p>Now are directed to the <code>foo.com</code> virtual server because we sent the correct <code>Host</code> header in our request.
Finally, we can see that setting a random <code>Host</code> header sends us to the default server:</p>
<div><pre><span></span><code>curl localhost --header <span>"Host: fasfsadfs.com"</span>
<span># &lt;html&gt;</span>
<span>#   &lt;head&gt;&lt;title&gt;404 Not Found&lt;/title&gt;&lt;/head&gt;</span>
<span>#   ...</span>
<span># &lt;/html&gt;</span>
</code></pre></div>
<p>There's <a href="https://docs.nginx.com/nginx/admin-guide/web-server/web-server/#setting-up-virtual-servers">more</a> that you can do with virtual servers in NGINX,
but what we've covered so far should be enough for you to understand their typical usage with Django. </p>
<h2>Location blocks</h2>
<p>Within a virtual server you can route the request based on the path.</p>
<div><pre><span></span><code><span>server</span> <span>{</span>
    <span>listen</span> <span>80</span><span>;</span>
    <span># Requests to the root path get a 200 OK response</span>
    <span>location</span> <span>/</span> <span>{</span>
        <span>return</span> <span>200</span> <span>'Cool!'</span><span>;</span>
    <span>}</span>
    <span># Requests to /forbidden get 403 Forbidden response</span>
    <span>location</span> <span>/forbidden</span> <span>{</span>
        <span>return</span> <span>403</span><span>;</span>
    <span>}</span>
<span>}</span>
</code></pre></div>
<p>Under this configuration, any requested path that matches <code>/forbidden</code> will return a 403 Forbidden status code, and everything else will return <em>Cool!</em> Let's try it out:</p>
<div><pre><span></span><code>curl localhost
<span># Cool!</span>
curl localhost/blah/blah/blah
<span># Cool!</span>
curl localhost/forbidden
<span># &lt;html&gt;</span>
<span># &lt;head&gt;&lt;title&gt;403 Forbidden&lt;/title&gt;&lt;/head&gt;</span>
<span># ...</span>
<span># &lt;/html&gt;</span>

curl localhost/forbidden/blah/blah/blah
<span># &lt;html&gt;</span>
<span># &lt;head&gt;&lt;title&gt;403 Forbidden&lt;/title&gt;&lt;/head&gt;</span>
<span># ...</span>
<span># &lt;/html&gt;</span>
</code></pre></div>
<p>Now that we've covered <code>server</code> and <code>location</code> blocks it should be easier to make sense of some of the config that I showed you at the start of this post:</p>
<div><pre><span></span><code><span>server</span> <span>{</span>
    <span>listen</span> <span>80</span><span>;</span>
    <span>server_name</span> <span>foo.com</span><span>;</span>
    <span>location</span> <span>/</span> <span>{</span>
        <span># Do something...</span>
    <span>}</span>
    <span>location</span> <span>/static/</span> <span>{</span>
        <span># Do something...</span>
    <span>}</span>
<span>}</span>
</code></pre></div>
<p>Next we'll dig into the connection between NGINX and our WSGI server.</p>
<h2>Reverse proxy location</h2>
<p>As mentioned earlier, NGINX acts as a <a href="https://en.wikipedia.org/wiki/Reverse_proxy#:~:text=In%20computer%20networks%2C%20a%20reverse,from%20the%20proxy%20server%20itself.">reverse proxy</a> for Django:</p>
<p><img alt="nginx proxy" src="https://mattsegal.dev/nginx-proxy.png"></p>
<p>This reverse proxy setup is configured within this location block:</p>
<div><pre><span></span><code><span>location</span> <span>/</span> <span>{</span>
    <span>proxy_pass</span> <span>http://127.0.0.1:8000</span><span>;</span>
    <span>proxy_set_header</span> <span>Host</span> <span>$host</span><span>;</span>
    <span>proxy_set_header</span> <span>X-Forwarded-For</span> <span>$proxy_add_x_forwarded_for</span><span>;</span>
    <span>proxy_set_header</span> <span>X-Forwarded-Proto</span> <span>$scheme</span><span>;</span>
    <span>proxy_redirect</span> <span>http://127.0.0.1:8000</span> <span>http://foo.com</span><span>;</span>
<span>}</span>
</code></pre></div>
<p>In the next few sections I will break down the directives in this block so that you understand what is going on.
You might also find the NGINX documentation on <a href="https://docs.nginx.com/nginx/admin-guide/web-server/reverse-proxy/">reverse proxies</a> helpful for understanding this config.</p>
<h2>Proxy pass</h2>
<p>The <code>proxy_pass</code> directive tells NGINX to send all requests for that location to the specified address.
For example, if your WSGI server was running on localhost (which has IP 127.0.0.1), port 8000, then you would use this config:</p>
<div><pre><span></span><code><span>server</span> <span>{</span>
    <span>listen</span> <span>80</span><span>;</span>
    <span>location</span> <span>/</span> <span>{</span>
        <span>proxy_pass</span> <span>http://127.0.0.1:8000</span><span>;</span>
    <span>}</span>
<span>}</span>
</code></pre></div>
<p>You can also point <code>proxy_pass</code> at a <a href="https://en.wikipedia.org/wiki/Unix_domain_socket#:~:text=A%20Unix%20domain%20socket%20or,the%20same%20host%20operating%20system.">Unix domain socket</a>, with Gunicorn listening on that socket, which is very similar to using localhost except it doesn't use up a port number and it's a bit faster:</p>
<div><pre><span></span><code><span>server</span> <span>{</span>
    <span>listen</span> <span>80</span><span>;</span>
    <span>location</span> <span>/</span> <span>{</span>
        <span>proxy_pass</span> <span>http://unix:/home/user/my-socket-file.sock</span><span>;</span>
    <span>}</span>
<span>}</span>
</code></pre></div>
<p>Seems simple enough - you just point NGINX at your WSGI server, so... what was all that other crap? Why do you set <code>proxy_set_header</code> and <code>proxy_redirect</code>? That's what we'll discuss next.</p>
<h2>NGINX is lying to you</h2>
<p>As a reverse proxy, NGINX will receive HTTP requests from clients and then send those requests to our Gunicorn WSGI server.
The problem is that NGINX hides information from our WSGI server. The HTTP request that Gunicorn receives is not the same as the one that NGINX received from the client.</p>
<p><img alt="nginx hiding info" src="https://mattsegal.dev/nginx-hide-info.png"></p>
<p>Let me give you an example, which is illustrated above. You, the client, have an IP of <code>12.34.56.78</code> and you go to <code>https://foo.com</code> in your web browser and try to load the page. The request hits the server on port 443 and is read by NGINX. At this stage, NGINX knows that:</p>
<ul>
<li>the protocol is <a href="https://www.cloudflare.com/learning/ssl/what-is-https/">HTTPS</a></li>
<li>the client has an IP address of <code>12.34.56.78</code></li>
<li>the request is for the host <code>foo.com</code></li>
</ul>
<p>NGINX then sends the request onwards to Gunicorn. When Gunicorn receives this request, it thinks:</p>
<ul>
<li>the protocol is HTTP, not HTTPS, because the connection between NGINX and Gunicorn is not encrypted</li>
<li>the client has the IP address <code>127.0.0.1</code>, because that's the address NGINX is using</li>
<li>the host is <code>127.0.0.1:8000</code> because NGINX said so</li>
</ul>
<p>Some of this lost information is useful, and we want to force NGINX to send it to our WSGI server. That's what these lines are for:</p>
<div><pre><span></span><code><span>proxy_set_header</span> <span>Host</span> <span>$host</span><span>;</span>
<span>proxy_set_header</span> <span>X-Forwarded-For</span> <span>$proxy_add_x_forwarded_for</span><span>;</span>
<span>proxy_…</span></code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mattsegal.dev/nginx-django-reverse-proxy-config.html">https://mattsegal.dev/nginx-django-reverse-proxy-config.html</a></em></p>]]>
            </description>
            <link>https://mattsegal.dev/nginx-django-reverse-proxy-config.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24144369</guid>
            <pubDate>Thu, 13 Aug 2020 15:29:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The art of asking effective questions in various professions]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24144363">thread link</a>) | @jensbackbom
<br/>
August 13, 2020 | http://www.jensbackbom.com/2020/08/13/asking-effective-questions/ | <a href="https://web.archive.org/web/*/http://www.jensbackbom.com/2020/08/13/asking-effective-questions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <article>
  
  <time datetime="2020-08-13T00:00:00+00:00">13 Aug 2020</time>
  <p>One might think that knowledge work depends on <em>knowing</em> things, but often it’s actually about knowing how to <em>ask the right questions</em>. In many professions this is a core skill you’ll need to learn from the start (eg. journalism, medicine, therapy), but as soon as you move into leadership roles you’ll find that asking questions takes up a lot of your time, no matter which profession you’re in. There are (at least) four hard things about asking questions:</p>

<ol>
  <li>You want to make sure you’re asking the right question.</li>
  <li>You can’t ask the exact question you want answered because you won’t get honest answers or you won’t know whom to ask.</li>
  <li>You often have limited time to ask questions, so you need to be effective.</li>
  <li>Sometimes, the important thing is not <em>what</em> you ask, but <em>how much</em> you ask or <em>when</em>.</li>
</ol>

<p>Let’s see what effective questions might look like in various roles, situations and professions:</p>

<h3 id="as-someone-who-wants-to-start-a-company">As someone who wants to start a company</h3>
<p>Let’s start with a non-profession: A person who wants to start a company but who doesn’t have a business idea yet. I think the most important question to ask yourself is <em>why</em> you want to start a company. You should ask yourself: <em>Do I want to become rich or do I want freedom?</em> If you want to be rich, you’ll need to build something big, which means you’ll probably need external financing of some kind. However, having external investors removes a lot of the freedom. If you want to start a company to be your own boss, this is <em>not</em> the path you should take.</p>

<p>No matter which route you take (big or independent), most successful entrepreneurs I know took a two-step approach:</p>

<ol>
  <li>Try to think like a surfer and ask yourself: <em>Where will the next big wave show up?</em> (where wave = market) Then try to put yourself in a position where you might take advantage of the wave. In my experience most of these waves tend to come from new technology or regulation.</li>
  <li>Try to have open conversations with people in that market and ask them: <em>What things often frustrate you?</em>. Stop once you’ve found five people who have the same problem that they desperately want a solution for. If they’re desperate, they will probably be very helpful when you try to solve the problem for them.</li>
</ol>

<h3 id="as-a-startup-founder">As a startup founder</h3>
<p>Once you’ve started your company, you’ll want to know if you’re going after a real problem, and if so, if what you’re doing is actually solving it. The founders of Superhuman discovered one question that stood out in order to assess this. They would ask their users:</p>

<ul>
  <li><em>How would you feel if you could no longer use the product?</em></li>
</ul>

<p>and measure the percentage of users who would answer “Very disappointed”. This became their “product-market fit score”, where the magic threshold seems to be 40%. (Source: First Round Review)</p>

<p>Another way of assessing your product-market fit might be to calculate a Net Promotor Score. This is done by asking your users:</p>

<ul>
  <li><em>How likely is it that you would recommend our product to a friend or colleague?</em> (Scale 0-10 where 10 is Extremely likely)</li>
</ul>

<p>Research shows that the people answering 9 or 10 are the ones who will actually recommend you product - they are the <em>promotors</em>. The people answering 7 or 8 are <em>passives</em> and 0 to 6 are <em>detractors</em>. Your Net promotor score is calculated as (number of promotors - number of detractors)/(total number of respondents) and can vary between -100 (only detractors) and +100 (only promotors). Generally, an NPS score of more than 50 is considered excellent.</p>

<h3 id="as-a-startup-investor">As a startup investor</h3>
<p>When investing in startups, most investments actually fail. Therefore, the few investments who are successful will need to compensate for the ones who fail, which is why startup investors will want every investment to have a huge potential. There are three main limits to a startup’s potential: The market, the founding team and their execution. Contrary to what many first-time startup founders think, the <em>idea</em> is not that important since that will change over time. To assess the <em>market</em>, you’ll want the answers to the following questions:</p>

<ul>
  <li><em>How big is the current market for what the company is doing right now?</em> If it’s not big enough, could the market be made bigger by segmenting, finding new target groups or selling adjacent products or services?</li>
  <li><em>How fast is the market growing?</em> It’s much easier to find a profitable segment for your company if the market is growing.</li>
</ul>

<p>To assess the <em>team</em>, two questions stand out:</p>

<ul>
  <li><em>Are the team members intelligent?</em> Starting a successful company means solving problems, and for that you need a combination of brain horsepower and street smarts. A certain “clarity of thought” often helps too.</li>
  <li><em>Can they stand the grind?</em> Running a startup is an emotional roller coaster, and not for the faint of heart. You will want to know if the team has the same level of ambition (extremely important) and if they can show examples of how they’ve handled difficult situations.</li>
</ul>

<p>To assess the <em>execution</em>, it’s important to understand that many startups go up against big incumbents that they can never outspend. The only way to win when competing with an incumbent is to be <em>faster</em>. Therefore, you will want a clear Yes! to the following question:</p>

<ul>
  <li><em>Am I impressed by what this small team has accomplished with their limited resources?</em></li>
</ul>

<h3 id="as-a-salesperson">As a salesperson</h3>
<p>If you’re a salesperson, ultimately you want to know the answer to the questions <em>Who will become my customer?</em> and <em>How much will they buy from me?</em> If you knew the answers to these questions, you could more or less just sort them by contribution margin and start dialing. The problem is that this can be hard to find out, so you will inevitably need to talk to a lot of prospects that will end up not becoming your customers. The key thing for a salesperson is therefore to qualify their leads, i.e. to make sure that they spend as much time as possible with relevant customers.</p>

<ul>
  <li><em>Does the customer need to solve the problem that our product can solve?</em> Please note the focus on problem here, and google <em>Jobs to be done</em> for more theory.</li>
  <li><em>Is the person you are talking to allowed to spend money on solving the problem?</em> If not, you might want to talk to one of their colleagues.</li>
  <li><em>Does the customer have a budget allocated?</em> If not, at least make sure they allocate money next year if they’re interested in your product.</li>
</ul>

<h3 id="as-a-buyer">As a buyer</h3>
<p>If you work in procurement (ie. buying things for your organization), you might think that you should be asking questions about deliveries, contracts, price levels etc. However, the most effective question is often:</p>

<p><em>What do we actually need in order to do our job?</em></p>

<p>You might find that not everyone in your company who asks for a new computer, phone or car actually needs one in order to do their job. Similarly, you might be able to cut down on software that’s not being used, or downgrade SaaS licenses to plans with less features.</p>

<h3 id="as-a-recruiter">As a recruiter</h3>
<p>Hiring people is of course all about asking questions. What you really want to find out is <em>Is this candidate worth trying to hire?</em> (Will they be able to do the job? Do they have potential beyond the current job scope? Does the candidate have better options than working for us?)
How can you assess all of this during a short interview? You can’t cover all aspects, of course. However, it will be really hard to predict the candidate’s future job performance if you spend the entire interview digging into one single question or case study. Instead, you’ll want to ask <em>as many different questions as possible</em> during the interview. The reasoning behind this is that one big case study might overlap poorly with your skillset by accident, but if you fail on ten unrelated questions after each other you’re more likely to fail in a real work settings. An example: If you’re hiring developers you might want to try to spend the interview discussing several pre-made code examples instead of having the candidate write code (which takes much longer). A great blog post on this topic <a href="https://erikbern.com/2018/05/02/interviewing-is-a-noisy-prediction-problem.html">here</a>.</p>

<h3 id="as-a-software-developer">As a software developer</h3>
<p>The most important thing about asking questions as a software developer isn’t really <em>which</em> questions to ask, but having the courage to <em>ask them sooner rather than later</em>. One of the most rewarding things about developing software is solving problems, but the desire to solve them yourself can easily lead to a lot of wasted time. However, as long as you have actually tried to solve a problem, you’ll learn as much by asking someone for help as you would by solving it yourself. Sometimes it even helps explaining the problem to someone.</p>

<h3 id="as-a-ux-researcher">As a UX researcher</h3>
<p>If you are interviewing users of a product in order to learn about potential improvements, the key is to ask open-ended questions. You’ll want to avoid asking <em>Show me how you’d use the product to do X</em>, because the user might not even be aware that you could use the product to do X! Instead, you’ll want to ask things such as <em>What do you use the product for?</em> and <em>Can you show me how?</em> Also, you might want to dig deeper into all thing you discover by asking <em>Why?</em> several times. Google <em>The five whys</em> for more info on this method.</p>

<h3 id="as-a-doctor">As a doctor</h3>
<p>I am not a doctor, so I won’t dive to deep into medical practice, but as I’ve understood it there is a big difference between being a primary care physician (where you meet one patient at a time and you’re not in a rush) and an emergency-care physician (where the patient might actually die within five minutes). As a primary-care physician, you’ll want to start high-level and ask open-ended questions, in order to find out things that you might want to dig deeper into. You’ll also want to make sure that the patient understood everything, and check whether they are actually using the medicine you prescribed last time. As an emergency-care physician, you want an immediate <em>triage</em>: What is the emergency? What is the patient’s temperature, blood pressure, pulse rate and respiratory rate? These pieces of information will give you enough to prioritize the most urgent patients.</p>

<p>Generally, I think this in an interesting distinction. In many professions you’ll be …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.jensbackbom.com/2020/08/13/asking-effective-questions/">http://www.jensbackbom.com/2020/08/13/asking-effective-questions/</a></em></p>]]>
            </description>
            <link>http://www.jensbackbom.com/2020/08/13/asking-effective-questions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24144363</guid>
            <pubDate>Thu, 13 Aug 2020 15:29:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understand HTTP3 in 5 Minutes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24144243">thread link</a>) | @sharjeelsayed
<br/>
August 13, 2020 | https://www.jesuisundev.com/en/understand-http3-in-5-minutes/ | <a href="https://web.archive.org/web/*/https://www.jesuisundev.com/en/understand-http3-in-5-minutes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

			
<!-- Horizontal Top Article -->
<p>You haven’t quite figured out HTTP2 yet that you’re already starting to get pissed off by people talking about HTTP3. But there’s a reason for that: HTTP3 is fast. I bet you in five minutes you’ll agree with me. </p>



<h3>Once upon a time</h3>



<p>I can’t tell you about the future without telling you about the present. <strong>Do you know about HTTP ?</strong> Defined in 1991, it’s the protocol that manages the web. It means <a href="https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol" target="_blank" rel="noreferrer noopener">HyperText Transfer Protocol</a> and it allows you to fetch resources from a web page. </p>



<p>From a web server to your browser. It’s built on a lower level protocol –<strong>TCP: it’s going to be important-</strong> and it’s stateless. It means that each request is completely independent. Each GIF present on this page is a GIF proudly independent in its life on the internet. That’s good for him and his life as a GIF. But for us it’s a bit of a broken system.</p>



<p>Because the problem is that <strong>each request will only look for one file at a time</strong>. Each time an expensive TCP connection is created for the occasion. Imagine if you had 10,000 Internet tips on your page.</p>



<p> I know a lot of people absolutely loved my pattern making skills in the previous article. So, to explain the Internets to you properly, I’m doing it again.</p>



<div><figure><img src="https://i.imgur.com/iI0MrHF.jpg" data-src="https://i.imgur.com/iI0MrHF.jpg" alt="http"></figure></div>



<p>Despite the fact that a browser can make six different requests at the same time, HTTP is still slow and full of TCP connections. Plus, we developers, usualy don’t care about that. <strong>We like to put as much crap on our pages as possible. </strong>Big jQuery lib with 300 useless CSS stylesheets ending with a big transparent 8 mega PNG. </p>



<p>When Google saw all the crap we were doing everywhere <strong>they started talking about SPDY</strong> (it’s called speedy). The point? To speed up the Internets. </p>



<p>SPDY is a specification that proposes to use HTTP as is but with a change of rules. And by <strong>compressing headers, prioritizing requests and multiplexing</strong>, it will transform all TCP requests and connections into one! </p>



<p>Concretely, when your HTML is read, your browser looks at everything you’re going to ask in your page. Then, it’s getting everything all at once. <strong>This way you avoid doing it file by file.</strong> </p>



<p>The first draft of HTTP2 is SPDY based. Very quickly HTTP2 was adopted and life on the internet has become faster. <strong>Today <a href="https://w3techs.com/technologies/details/ce-http2" target="_blank" rel="noreferrer noopener">42.7% of the internet</a> use HTTP2.</strong></p>



<div><figure><img src="https://i.imgur.com/2jePyHC.jpg" data-src="https://i.imgur.com/2jePyHC.jpg" alt="http2"></figure></div>



<h3>Great, what about HTTP3?</h3>



<p>If I piss you off with HTTP and HTTP2 when you explicitly clicked to see sexy HTTP3, there’s a good reason. HTTP2 was created by taking HTTP as a base and changing the rules.<strong> It’s the same thing with HTTP3. </strong>So by understanding the present it’s easier for me to explain the future to you.</p>



<p>Googlers are geeks, they never stop. After SPDY became HTTP2, they thought that it was still not fast enough. So they started talking about QUIC (it’s called Quick). <strong>This will be the second experimental technology developed by Google to become an official upgrade of the HTTP protocol</strong>. But what’s so special about this protocol?</p>



<p>The main big evolution of HTTP3 is the change of transport layer. No more of the heavy TCP connections I’ve been telling you about since the beginning. <strong>Now, it’s all about UDP. </strong></p>



<p>By the way QUIC means “Quick UDP Internet Connections”. This change of protocol will speed up connection establishment and data transfer times enormously. Howerver, <strong>UDP is certainly faster and simpler, but it doesn’t have the reliability and error handling of TCP.</strong></p>



<p>TCP has to make several round trips just to establish a connection in a square and stable way. <strong>Where UDP doesn’t give a damn and does it really fast without stability and risk of lost packets. </strong>However UDP can dramatically reduce latency in requests. Up to almost zero latency in repeated connections to the same server because no roundtrip is made to establish connections.</p>



<figure><img src="https://i.imgur.com/hDmNkpS.png" data-src="https://i.imgur.com/hDmNkpS.png" alt="http3"></figure>



<p>HTTP3 is the multiplexing and compression features of HTTP2 with a protocol change from TCP to UDP. The Google guys then added their layer in the protocol to guarantee stability, order in the reception of packets and of course security. </p>



<p><strong>So HTTP3 uses UDP for its high speed while keeping the stability of QUIC</strong>, without forgetting the security of TLS. Because yes, in QUIC you find TLS 1.3 which allows you to make your beautiful SSL. I’ve been talking about layers for a while, this is what it looks like under the hood.</p>



<figure><img src="https://i.imgur.com/QdNsQHL.jpg" data-src="https://i.imgur.com/QdNsQHL.jpg" alt="http3"></figure>



<p>In 2018, QUIC became HTTP3. The Internet Enginerring Task Force dudes, <a href="https://www.youtube.com/watch?v=uVf_yyMfIPQ&amp;t=4956" target="_blank" rel="noreferrer noopener"><strong>dudes in shorts who decide on Internet protocols</strong></a>, have agreed. And that’s great news because the Internets will never be fast enough for us, impatient people.</p>



<h3>Epilogue</h3>



<p>HTTP3 is the sexy future with a HTTP base that has been tuned to the maximum by google geeks. At the time of writing, <a href="https://w3techs.com/technologies/details/ce-quic" target="_blank" rel="noreferrer noopener">only 4.6% of the Internet uses HTTP3</a> but this figure is likely to grow in the coming years. We stayed on the surface today, but there are a lot of deep-dive articles everywhere that I invite you to consult if you’re more curious.</p>

			<!-- clearfix -->
			

			
		</div></div>]]>
            </description>
            <link>https://www.jesuisundev.com/en/understand-http3-in-5-minutes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24144243</guid>
            <pubDate>Thu, 13 Aug 2020 15:18:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Offloaded My Anxiety to Trello]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24144229">thread link</a>) | @allending
<br/>
August 13, 2020 | https://cate.blog/2020/07/22/how-i-offloaded-my-anxiety-to-trello/ | <a href="https://web.archive.org/web/*/https://cate.blog/2020/07/22/how-i-offloaded-my-anxiety-to-trello/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">

		<!-- #masthead -->

			<!-- .image-header -->
	
	

<section id="content">
	<div>
		<div>
						<div id="primary">
							<main id="main" role="main">

					
						
<article id="post-52292">
	<!-- .entry-header -->

	<div>
		<p>I’ve never been good at what you might call “life admin”, but I used to keep track of it through having a high level of 1) recall, 2) guilt and anxiety.</p>
<p>I can’t say this system was working <em>well</em>, I was pretty behind on this stuff (such as… still having an Australian bank account five years after I moved away). But the critical things were mainly taken care of and the non-critical… remained in runtime memory.</p>
<p>A bit over a year ago, having dealt with what I termed the “inner monologue of self hate”, my every failing as a person was no longer running on a loop in every moment of downtime. At this point, I realised I needed a system that didn’t involve me remembering everything and worrying about it.</p>
<p>Enter: Trello.</p>
<h2>Board 1: Life Admin</h2>
<p>I created a board that I “jokingly” called “Life Failures” (since renamed to Life Admin), and set up a bunch of columns. I don’t exist kanban style in my life so the main features are:</p>
<ul>
<li>A list of areas of responsibility, such as “finances”, “house”, “car” etc.</li>
<li>Labels, primarily: “waiting”, “work hours phone call”, “easy”, “blocking”. During lockdown I created a “post-pandemic” label to filter out visually the things I couldn’t expect to make progress on, which was helpful.</li>
<li>A done column that resets each month, i.e. “Done – June”, and “Done – July”. I tend to keep the previous month’s around and then archive when I create a new one. So right now in July, June is still around. When I create August, I will archive June.</li>
<li>Extensive use of checklists.</li>
</ul>
<p>Each card is on some level a mini life “project”, and I keep tabs on things using the labels and the checklists. This is the one where I changed my bank account, it entered waiting / blocking states multiple times, was closed off in May, even though it began in March.</p>
<p><img data-attachment-id="52293" data-permalink="https://cate.blog/2020/07/22/how-i-offloaded-my-anxiety-to-trello/screenshot-2020-07-18-at-11-57-02/" data-orig-file="https://i2.wp.com/cate.blog/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-11.57.02.png?resize=512%2C1034&amp;ssl=1" data-orig-size="512,1034" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screenshot 2020-07-18 at 11.57.02" data-image-description="" data-medium-file="https://149354112.v2.pressablecdn.com/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-11.57.02-149x300.png" data-large-file="https://149354112.v2.pressablecdn.com/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-11.57.02-507x1024.png" loading="lazy" src="https://i2.wp.com/cate.blog/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-11.57.02.png?resize=512%2C1034&amp;ssl=1" alt="Screenshot 2020-07-18 at 11.57.02.png" width="512" height="1034" srcset="https://i2.wp.com/cate.blog/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-11.57.02.png?w=512&amp;ssl=1 512w, https://i2.wp.com/cate.blog/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-11.57.02.png?resize=149%2C300&amp;ssl=1 149w, https://i2.wp.com/cate.blog/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-11.57.02.png?resize=507%2C1024&amp;ssl=1 507w, https://i2.wp.com/cate.blog/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-11.57.02.png?resize=248%2C500&amp;ssl=1 248w" sizes="(max-width: 512px) 100vw, 512px" data-recalc-dims="1"></p>
<p>This sometimes creates a disconnect between the amount of work I’ve done and the amount I really get to “check off” but I am trying to embrace with this list the idea that life admin is something that is continually chipped away at. The goal is not to empty the board, the goal is to be more on top of things and not create cascading failure in my personal life (again).</p>
<p>Since adopting this system I’ve made progress on so many things that have dragged on for <em>years</em>. Particularly in the “financial” list which has always been my biggest struggle (there is no visual reminder, it’s extremely boring and usually bureaucratic which I find disproportionately stressful). The Australian bank account is closed, I <em>finally</em> managed to transfer my stock from the Conglomerate out of the mandated system and to my regular investment manager (this was so painful and had stopped and started multiple times before we really made a concerted effort earlier this year). I managed to untangle the mess of paying emergency tax for ~18+ months over three tax years. Addressing these things doesn’t really affect my day to day, but it does make it easier to make bigger decisions, because everything is accessible and where it should be.</p>
<p><img data-attachment-id="52298" data-permalink="https://cate.blog/2020/07/22/how-i-offloaded-my-anxiety-to-trello/screenshot-2020-07-18-at-13-49-37/" data-orig-file="https://i1.wp.com/cate.blog/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-13.49.37.png?resize=750%2C160&amp;ssl=1" data-orig-size="2247,479" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screenshot 2020-07-18 at 13.49.37" data-image-description="" data-medium-file="https://149354112.v2.pressablecdn.com/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-13.49.37-300x64.png" data-large-file="https://149354112.v2.pressablecdn.com/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-13.49.37-1024x218.png" loading="lazy" src="https://i1.wp.com/cate.blog/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-13.49.37.png?resize=750%2C160&amp;ssl=1" alt="Screenshot 2020-07-18 at 13.49.37" width="750" height="160" srcset="https://i1.wp.com/cate.blog/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-13.49.37.png?w=2247&amp;ssl=1 2247w, https://i1.wp.com/cate.blog/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-13.49.37.png?resize=300%2C64&amp;ssl=1 300w, https://i1.wp.com/cate.blog/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-13.49.37.png?resize=1024%2C218&amp;ssl=1 1024w, https://i1.wp.com/cate.blog/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-13.49.37.png?resize=768%2C164&amp;ssl=1 768w, https://i1.wp.com/cate.blog/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-13.49.37.png?resize=1536%2C327&amp;ssl=1 1536w, https://i1.wp.com/cate.blog/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-13.49.37.png?resize=2048%2C437&amp;ssl=1 2048w, https://i1.wp.com/cate.blog/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-13.49.37.png?resize=750%2C160&amp;ssl=1 750w, https://i1.wp.com/cate.blog/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-13.49.37.png?resize=1000%2C213&amp;ssl=1 1000w" sizes="(max-width: 750px) 100vw, 750px" data-recalc-dims="1"></p>
<p>The board is broad, and there are obvious ways to streamline it or break things out into their own board, but I choose not to. The board is broad because life is broad, and because some months I may move things from one column, and other months from other columns, the point is that everything is tracked, and moving overall.</p>
<p>List of columns:</p>
<ul>
<li>Finances</li>
<li>House</li>
<li>Car</li>
<li>Travel</li>
<li>Cate as a Person</li>
<li>Self-Employment</li>
<li>Professional</li>
<li>Writing</li>
<li>Misc</li>
<li>Things to buy</li>
<li>Done – Current Month</li>
<li>Done – Previous Month</li>
</ul>
<h2>Board 2: Day to Day</h2>
<p>At the start of this year, I created a second board, which I call “Day to Day”. The idea of that one is to capture the repeating tasks. This consists of three lists:</p>
<ul>
<li>Week</li>
<li>Month</li>
<li>Current Month</li>
</ul>
<p>At any given time I have a “week” card which captures the things I try to do every week, and a “month” card which captures the things I try to do every month. When the week is up, I move it under the current month, and then I archive that at the end of the month. Initially I had “day” cards but I found that it was just annoying me, so I got rid of them.</p>
<p>I use template cards, so each time I create a new week or month card, they come with the same checklist. If I was going to add something, I would add it to the template card. For instance, I didn’t feel the need to track going to the gym on the week card because it was 1) more of a daily thing, and 2) a strong habit. After the gym being shut for nearly 4 months, I might add it in as I rebuild that habit.</p>
<p>This is the current state of the board:</p>
<p><img data-attachment-id="52299" data-permalink="https://cate.blog/2020/07/22/how-i-offloaded-my-anxiety-to-trello/screenshot-2020-07-18-at-13-57-10/" data-orig-file="https://i0.wp.com/cate.blog/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-13.57.10.png?resize=750%2C239&amp;ssl=1" data-orig-size="1694,539" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screenshot 2020-07-18 at 13.57.10" data-image-description="" data-medium-file="https://149354112.v2.pressablecdn.com/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-13.57.10-300x95.png" data-large-file="https://149354112.v2.pressablecdn.com/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-13.57.10-1024x326.png" loading="lazy" src="https://i0.wp.com/cate.blog/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-13.57.10.png?resize=750%2C239&amp;ssl=1" alt="Screenshot 2020-07-18 at 13.57.10" width="750" height="239" srcset="https://i0.wp.com/cate.blog/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-13.57.10.png?w=1694&amp;ssl=1 1694w, https://i0.wp.com/cate.blog/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-13.57.10.png?resize=300%2C95&amp;ssl=1 300w, https://i0.wp.com/cate.blog/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-13.57.10.png?resize=1024%2C326&amp;ssl=1 1024w, https://i0.wp.com/cate.blog/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-13.57.10.png?resize=768%2C244&amp;ssl=1 768w, https://i0.wp.com/cate.blog/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-13.57.10.png?resize=1536%2C489&amp;ssl=1 1536w, https://i0.wp.com/cate.blog/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-13.57.10.png?resize=750%2C239&amp;ssl=1 750w, https://i0.wp.com/cate.blog/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-13.57.10.png?resize=1000%2C318&amp;ssl=1 1000w" sizes="(max-width: 750px) 100vw, 750px" data-recalc-dims="1"></p>

<p>This is the current state of July:</p>
<p><img data-attachment-id="52296" data-permalink="https://cate.blog/2020/07/22/how-i-offloaded-my-anxiety-to-trello/screenshot-2020-07-18-at-12-54-50/" data-orig-file="https://i2.wp.com/cate.blog/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-12.54.50.png?resize=750%2C458&amp;ssl=1" data-orig-size="1521,928" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screenshot 2020-07-18 at 12.54.50" data-image-description="" data-medium-file="https://149354112.v2.pressablecdn.com/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-12.54.50-300x183.png" data-large-file="https://149354112.v2.pressablecdn.com/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-12.54.50-1024x625.png" loading="lazy" src="https://i2.wp.com/cate.blog/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-12.54.50.png?resize=750%2C458&amp;ssl=1" alt="Screenshot 2020-07-18 at 12.54.50" width="750" height="458" srcset="https://i2.wp.com/cate.blog/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-12.54.50.png?w=1521&amp;ssl=1 1521w, https://i2.wp.com/cate.blog/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-12.54.50.png?resize=300%2C183&amp;ssl=1 300w, https://i2.wp.com/cate.blog/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-12.54.50.png?resize=1024%2C625&amp;ssl=1 1024w, https://i2.wp.com/cate.blog/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-12.54.50.png?resize=768%2C469&amp;ssl=1 768w, https://i2.wp.com/cate.blog/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-12.54.50.png?resize=750%2C458&amp;ssl=1 750w, https://i2.wp.com/cate.blog/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-12.54.50.png?resize=820%2C500&amp;ssl=1 820w" sizes="(max-width: 750px) 100vw, 750px" data-recalc-dims="1"></p>
<p>The month list is relatively short, and really just captures 1) taking some time for myself (the spa!), 2) a task that I dread (the personal expense report) and 3) the vague thing that I feel is best done through continuous small efforts (the “external thing”, a profile building/maintaining exercise).</p>
<p>This is the current state of this week:</p>
<p><img data-attachment-id="52297" data-permalink="https://cate.blog/2020/07/22/how-i-offloaded-my-anxiety-to-trello/screenshot-2020-07-18-at-13-14-06/" data-orig-file="https://i1.wp.com/cate.blog/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-13.14.06.png?resize=750%2C734&amp;ssl=1" data-orig-size="1377,1348" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screenshot 2020-07-18 at 13.14.06" data-image-description="" data-medium-file="https://149354112.v2.pressablecdn.com/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-13.14.06-300x294.png" data-large-file="https://149354112.v2.pressablecdn.com/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-13.14.06-1024x1002.png" loading="lazy" src="https://i1.wp.com/cate.blog/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-13.14.06.png?resize=750%2C734&amp;ssl=1" alt="Screenshot 2020-07-18 at 13.14.06" width="750" height="734" srcset="https://i1.wp.com/cate.blog/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-13.14.06.png?w=1377&amp;ssl=1 1377w, https://i1.wp.com/cate.blog/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-13.14.06.png?resize=300%2C294&amp;ssl=1 300w, https://i1.wp.com/cate.blog/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-13.14.06.png?resize=1024%2C1002&amp;ssl=1 1024w, https://i1.wp.com/cate.blog/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-13.14.06.png?resize=768%2C752&amp;ssl=1 768w, https://i1.wp.com/cate.blog/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-13.14.06.png?resize=750%2C734&amp;ssl=1 750w, https://i1.wp.com/cate.blog/wp-content/uploads/2020/07/Screenshot-2020-07-18-at-13.14.06.png?resize=511%2C500&amp;ssl=1 511w" sizes="(max-width: 750px) 100vw, 750px" data-recalc-dims="1"></p>
<p>The week list is longer, and captures the aspects that I think create a well rounded life – good friendships (regular social interaction, doing something nice for other people), personal well being (writing, cultural experiences, regularly chipping away at the hardest list in life admin) and self care (making an effort with my appearance, maintaining a beautiful home). It’s always interesting what drops off depending on circumstances.</p>
<p>Initially I had the idea that these lists should capture everything, and had the concept of “extras” where I would note down things not covered by the list. But over time I’ve concluded that it works best for me when the concepts are general, and it creates regular opportunities to consider what, of the things I consider important, am I making time for? And what am I not?</p>
<h2>&nbsp;✅</h2>
<p>Both boards combine to address the nagging sense that I’m behind or not doing enough, and allow me to capture what goes into keeping my life moving along and the things make me happy. The things I “should” do no longer run in a loop in my head; they are captured in Trello, and it’s a vastly better way to live.</p>

	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article><!-- #post-## -->
						
	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
						
<!-- #comments -->

					
				</main><!-- #main -->
			</div><!-- #primary -->
			
<!-- #secondary -->
		</div><!-- .row -->
	</div><!-- .container -->
</section><!-- #main -->


		<!-- #colophon -->
	</div></div>]]>
            </description>
            <link>https://cate.blog/2020/07/22/how-i-offloaded-my-anxiety-to-trello/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24144229</guid>
            <pubDate>Thu, 13 Aug 2020 15:17:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It's likely better to test for accessibility than for Firefox]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24144140">thread link</a>) | @ecmascript
<br/>
August 13, 2020 | https://blog.ecmascript.tv/its-likely-better-to-test-for-accessibility-than-for-firefox/ | <a href="https://web.archive.org/web/*/https://blog.ecmascript.tv/its-likely-better-to-test-for-accessibility-than-for-firefox/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<figure><blockquote data-width="550"><div lang="en" dir="ltr"><p>Your tweet reeks of bad conscience. In 2014-15, I could not get funding or a job, went outside valley to found Brave, took big pay cut &amp; still-substantial long-term risk. (Compare to chart for top job at Mozilla vs. "performance".)</p><p>I'm not complaining, but you are spinning. Why? <a href="https://t.co/XRNyDvuZfO">pic.twitter.com/XRNyDvuZfO</a></p></div>— BrendanEich (@BrendanEich) <a href="https://twitter.com/BrendanEich/status/1217512049716035584?ref_src=twsrc%5Etfw">January 15, 2020</a></blockquote>

</figure><p>This is everything you essentially need to know. In the last few years, the Firefox market share has fallen, a lot, most likely due to the rise of mobile and a failure of Mozilla to establish themselves on it.</p><p>The Firefox market share is such that it's practically unnecessary to test against it, especially if your users are using your web apps or sites on their phones. If you instead take that time and focus and create a more accessible app or site, it will be a more reasonable use of your time since more people have disabilities than Firefox has market share.</p><!--kg-card-begin: markdown--><blockquote>
<p>One billion people, or 15% of the world's population, experience some form of disability, and disability prevalence is higher for developing countries. One-fifth of the estimated global total, or between 110 million and 190 million people, experience significant disabilities.</p>
</blockquote>
<!--kg-card-end: markdown--><figure><a href="https://www.worldbank.org/en/topic/disability"><div><p>Disability Inclusion Overview</p><p>One billion people, or 15% of the world’s population, experience some form of disability. Persons with disabilities on average are more likely to experience adverse socioeconomic outcomes than persons without disabilities, such as lower rates of education, worse health outcomes, less employment, and…</p><p><img src="https://www.worldbank.org/content/dam/wbr-redesign/logos/wbg-favicon.png"><span>World Bank</span></p></div><p><img src="https://www.worldbank.org/content/dam/wbr/share-logo/social-share.jpg"></p></a></figure><p>Even for the most generous apps or sites, which only rely on desktop browsers for example and have users in regions such as Europe or North America, Firefox market share is lower than that. Of course, far from everyone with a disability has a disability that makes it difficult to consume web content but for most sites and apps today a majority of traffic comes from mobile users where Firefox market share is less than a percent which is lower than the percentage of people with sight issues.</p><p>Personally, I think the <a href="https://blog.mozilla.org/blog/2014/04/03/brendan-eich-steps-down-as-mozilla-ceo/">firing of Brendan Eich</a> as the big boss was one of the biggest mistake Mozilla ever did and I think the current news about Mozilla proves me right. He had a salary of $800k as max and has done so much for the web as it is today. Suddenly when he was replaced, the salary more than tripled, isn't that strange? To request a salary more than three times as much as the previous guy should require the result being at least three times as good in my opinion. Mozilla has for the last couple of years shifted from being laser focused making the best, most awesome browser to promoting diversity over all else, purchasing pocket and pushing a lot of other things like Firefox Send. Things that have been good and bad, but most importantly not really about the browser or the web itself.</p><p>The funny thing is, that the urge to be profitable never seems to have encountered the most obvious realization, to profit from their most popular product, Firefox itself. They could simply charge for Firefox to unlock some pro features like ad blocking, Firefox Send (which was actually a great service) and other things that most normal users don't use anyway. Hence, they could keep their mission cake and eat it too.</p><p>I would gladly pay for Firefox if the money actually went there, but it seems that even donating to Mozilla is <a href="https://foundation.mozilla.org/en/about/">just sending your money towards some diversity cause</a> or perhaps to Bakers own pocket.</p><p>To summarize my thoughts, it is clear that specifically supporting Firefox in its current state is not a goal for me anymore. I have lost faith in Mozilla after all these years. I will use the time to test for accessibility instead of being an active tester for Firefox. If you have the luxury to have enough time to always thoroughly test for both things, that's awesome but for me that is simply a position that I seldom find myself in. From now on, I will simply assume that stuff I make works in Firefox as I follow the web standards. Because honestly, if you have to choose it is likely better to test for accessibility than for Firefox.</p><p>For you people out there that values privacy but not political activism, I recommend you to try out the Brave web browser as an alternative to Firefox.</p><figure><a href="https://brave.com/"><div><p>Secure, Fast &amp; Private Web Browser with Adblocker | Brave Browser</p><p>The Brave browser is a fast, private and secure web browser for PC, Mac and mobile. Download now to enjoy a faster browsing experience that saves data and battery life by blocking tracking software.</p><p><img src="https://brave.com/wp-content/uploads/2018/02/cropped-brave_appicon_release-192x192.png"><span>Brave Browser</span></p></div><p><img src="https://brave.com/wp-content/uploads/2018/03/brave.png"></p></a></figure>
			</section><section>

				

				

				

						

			</section></div>]]>
            </description>
            <link>https://blog.ecmascript.tv/its-likely-better-to-test-for-accessibility-than-for-firefox/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24144140</guid>
            <pubDate>Thu, 13 Aug 2020 15:11:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Game dev examines a unique take on the brain training games]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24144123">thread link</a>) | @handlingelect
<br/>
August 13, 2020 | https://www.staticcatgames.com/2020/08/brain-wash-review.html | <a href="https://web.archive.org/web/*/https://www.staticcatgames.com/2020/08/brain-wash-review.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><iframe allowfullscreen="" height="266" src="https://www.youtube.com/embed/ciMCahzC408" width="320" youtube-src-id="ciMCahzC408"></iframe></p><p><i>Brain Wash</i> by SayGames is the hyper-casual equivalent of something like one of the <i>Brain Training </i>games. I'm not sure if this is a new trend, but I've seen a few these pop up on the app stores and they all follow the same style of gameplay: search/fill/fix/solve a random puzzle.&nbsp;</p><p><i>Brain Wash</i> is no different in this regard. The puzzles, all of which are designed in a friendly, modern and approachable style, involve you touching the screen to fix a puzzle, put something in the right order, solve something, move an object or draw something on a screen. These mechanics (and their variations) are used throughout <i>Brain Wash's</i> levels to challenge the player.&nbsp;</p><p>There are two main issues I have with <i>Brain Wash</i>. Firstly, the game is incredibly easy. Seriously, the puzzles aren't that hard and anyone looking for a challenge should download something else. Secondly, there are the ads. I've written before about the intrusive nature of ads in hyper-casual games and <i>Brain Wash</i> is no different. The ads slowly creep up on you and before you know it, are inundated.&nbsp;</p><p>This is currently the third bestselling free game on Google Play. Obviously, it must have some appeal. I think it would be okay for a few minutes during a break as it's very easy and you can blast through the levels quite quickly. If you can bear the ads, it's not a bad choice.</p>&nbsp;
</div></div>]]>
            </description>
            <link>https://www.staticcatgames.com/2020/08/brain-wash-review.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24144123</guid>
            <pubDate>Thu, 13 Aug 2020 15:10:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You've Never Manifested Anything]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24144059">thread link</a>) | @willpatrick
<br/>
August 13, 2020 | https://www.willpatrick.co.uk/articles/youve-never-manifested-anything | <a href="https://web.archive.org/web/*/https://www.willpatrick.co.uk/articles/youve-never-manifested-anything">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>Ask And You May Or May Not Receive</h2><p><strong>Manifesting</strong> (v): <em>to bring something into the world - via 'the universe' - by imagining that it already exists.</em></p><p>Have you ever read (or - <em>the horror</em> - watched) 'The Secret'? It’s the book/film combo responsible for making the concept of manifesting - thinking riches and success into existence - so widespread and popular. Sixteen years after the film appeared, the idea has become blandly pedestrian. 'Oh yeah,' you'll hear over your latest zoom brunch, 'I've been working really hard on manifesting [insert material gain] and now it's paying off. So blessed.' (It has also recently been made into another movie - this time a <a href="https://www.imdb.com/title/tt4411584/"> dramatisation</a>.)</p><p>In its popular format, manifesting is a concept of such empty pseudoscience that <strong>it should be actively avoided by everyone currently alive on planet earth</strong>. Where this new-age idea drifts by more or less harmlessly in the good times (broadly defined as whenever we are not in <em>another</em> 'once-in-a-generation' economic crisis or highly infectious respiratory pandemic), it surges in popularity when things get tough. </p><p>Thanks to Covid19 many have been financially, physically and emotionally pummelled over the last few months. The great pandemic lottery of 'whose careers survive or not' has surprised few with who has so far won and lost. Conversely, others have been able to continue on as normal and some, the smallest and most fortunate group, have thrived and profited.</p><p>Within the more fortunate groups, some are more prone than others to explain their good fortune because of the mindset they have adopted. This is a responseI believe stems from the popularity of the manifestation philosophy. Those that are down on their luck may see this and turn, inevitably, to the ever-flowing font of mindset motivation and self-help wisdom that exists online and in print. Never mind that not all jobs can be done from home - don't be so negative - you must <em>manifest</em> your way out of this particular pinch.</p><p><strong>But how?</strong></p><h2>The (Mutable) Law of Attraction</h2><p>Manifesting is just another name for ‘the law of attraction’, the belief that you can get what you want just by thinking about it.</p><p>Here's a quick 101:</p><ul role="list"><li>You can have <em>anything you desire </em>- you just have to ask the universe for it. (The universe, through some unknown mechanism, has sentience and cares about whether or not you get what you want.)</li><li>To get the universe to give you what you want, you have to generate the right 'frequency' or 'vibration' which will then be reflected back at you. (What physical properties these frequencies have or exactly what is doing the, er, <em>vibrating</em> is left open to interpretation.)</li><li>To get the right frequency, you have to think positively and imagine that you already have the thing that you want. If you dwell on how you don't yet have what you want, your frequency will be <em>all wrong!</em> (In essence, a milquetoast flavour of cognitive dissonance.)</li><li>Then... Bam! Eventually, the universe delivers unto you exactly what you were seeking. (Purists, note well: you don't necessarily have to actually <em>do</em> anything to get to this point other than thinking.)</li></ul><p>There's a lot to unpack here. The biggest assumptions are that <strong>the universe has sentience, is aware of you, and is somehow interested in helping you get what you want</strong>, no matter how minor. In the 2004 film of ’<a href="https://www.imdb.com/title/tt0846789/">The Secret</a>’, one example is of some rube imagining himself driving a sports car he really wants. He sits in his armchair, closes his eyes, then heads out for a drive in his mind. He works the pedals and grips a non-existent steering wheel in front of him, feeling the wind on his face as he changes gears. </p><p>It’s quite an image; I think if a family member or friend were to walk in on me doing anything like that <em>in flagrante</em> I think on balance I'd rather be caught masturbating than driving an imaginary car. All this is to say that the idea the universe is a) aware you want a car and b) cares enough to help you get it, is absurd. <strong>You'd hope the unfathomable, grand infinite expanse of our billions-of-years-old plane of existence has bigger fish to fry than helping a relatively smart mammal get a new Porsche, but apparently not.</strong></p><p>(Typical examples used by the acolytes of manifestation are almost always material: cars, houses, bigger salaries, promotions etc. Curiously, nobody selling LOA has ever had the smart idea of organising collective action to imagine world peace or to reverse climate change. Or, if they have, it hasn't worked.)</p><p>Secondly, there's this whole idea about frequencies and vibrations. This is peak yogababbling drivel at its most inane. As far as I can tell, it’s got something to do with the bastardisation of Einstein’s E=mC^2 - it's the difference between ‘matter has equivalent energy’ and ‘everything is, like, <em>energy, man!</em>’</p><p>If there really is a frequency for 'I want a new car', I'd love to know what it is and exactly where it appears on the <a href="https://en.wikipedia.org/wiki/Electromagnetic_spectrum">electromagnetic spectrum</a>. Is it somewhere between infrared and visible light, or does it carry more energy than a gamma ray burst? If it's going to fatally irradiate my entire city I think I'll stick with my modest Volkswagen.</p><p>But this is all only surface level. <strong>It gets much worse.</strong></p><h2>What Do You Mean You Don't Want a Race Car?</h2><p>The unethical problem at the core of manifestation is that<strong> it is the preserve of the privileged</strong>, completely disregarding any potential influence from the outside world. If you are a relatively wealthy individual with agency over your actions you can manifest your new car easily enough by, perhaps, spending less on other luxuries and shopping around for a dealership that will give you a good financing arrangement. </p><p>The logic of the gospel of manifestation is that it shouldn't matter if you live in a country, a society, a system, a city, a family or a relationship where you are held back by the context you inhabit because if you're not getting the results you want, well... <strong>it's because you're just not imagining it hard enough.</strong></p><p>Consider this: if you would not be comfortable sitting down with someone living in or fleeing from a war, or a cartel, or abuse, and telling them with a clear conscience that <em>the only thing holding them back is their mindset</em> and that they need to adopt 'an attitude of gratitude', <strong>then the rationale of the entire enterprise is sunk</strong>. </p><p>Is it one rule for you and another for them? Do you only enter the manifesting club when your socioeconomic status is good enough? Are you just doing it <em>better</em> than they are? Does the universe care about you, but not give two shits about them? Are you sure it's got nothing to do with the fact that you live in a rich country, have the time to read indulgent books about the law of attraction and enjoy ignoring your own privileges and rights granted to you by dint of the circumstances you find yourself in?</p><p>It might come as no surprise that <strong>the majority of the people saying anything about manifesting are usually selling something about it, too</strong>; many derive their wealth from motivational speaking and training. The core narrative that these self-help gurus spin is that it is the individual <em>alone</em> - yes, you! - who has the power to change their life for the better. It's the kind of thing that fits in well with the American dream - the self-made, you-can-do-it-too, go-getter narrative.</p><p>In a deliciously ugly twist of irony, they then turn around and tell you that, actually, you can’t do it on your own. You need their help to make those dreams happen and <strong>they just so happen to have a course or a book or a seminar </strong>that will make the whole process that much easier. Usually it's seven habits, or six simple steps, or a sixty seven step program. Naturally, the success that they evidence to their students - their own wealth and good fortune - is financed entirely by the people who have paid to learn this from them in the first place.</p><p><strong>It is self-help as Ouroboros</strong>, the great snake that devours itself.</p><h2>Human Psychology At Work</h2><p>Before you charge me with being some kind of irredeemably negative fun-sponge, know this: I personally believe that <strong>having clear goals and visualising success absolutely can help us to get what we want</strong>. Where I differ though, is <strong>how, where and when</strong> these processes actually work. The where and the when are largely a factor of whether or not you already live in a wealthy country and aren't threatened by, oh I don't know, an imminent coup d'etat, famine, war, the disintegration of the rule of law or the appearance of masked men at your door in the middle of the night.</p><p>If you're lucky enough to have the means to engage in all that top-of-Maslow's-Pyramid type stuff, then <strong>you're good to go</strong>.</p><p>In terms of the <em>how</em>, though, this is just regular, run-of-the-mill human psychology. This is perhaps why manifesting and the law of attraction is so insidious - <strong>among the scientific truth, all of the other yogababble can creep in</strong>.</p><p>Here's a handful of effects that are actually at work:</p><p><strong>Frequency illusion:</strong> if you have a long and involved conversation with someone about red cars, you will subsequently begin to notice more red cars. Similarly, if you're always thinking about new jobs to apply for, you are more likely to notice and recognise opportunities when you're browsing around.</p><p><strong>Long term motivation:</strong> visualisation of a given goal or objective motivates us to take action and plan for a certain outcome. If you're obsessing over getting that dream job mentioned above, you're more likely to go and look for it and look in places where you are more likely to find it. (<a href="https://www.researchgate.net/profile/Judith_Harackiewicz/publication/263916494_Approach_and_Avoidance_Achievement_Goals_and_Intrinsic_Motivation_A_Mediational_Analysis/links/54d0db7d0cf20323c219faea.pdf">Citation</a>.)</p><p><strong>Skill building:</strong> some amount of visualisation helps to improve your skills, albeit only up to a point. If you think about being good at finding a job, you are more likely to adopt a slightly more effective approach for a while. (<a href="https://pdfs.semanticscholar.org/a501/1fa801a9fd7e446af1131c27b5aa0bffdbdc.pdf">Citation</a>.)</p><p><strong>Confirmation bias: </strong>wherein we take actions and look for evidence to fit and confirm the beliefs we already have. Finally got that job? It can only have been because of manifesting! (<a href="http://pages.ucsd.edu/~mckenzie/nickersonConfirmationBias.pdf">Citation</a>.)</p><h2>Thank People, Not the Universe</h2><p>By all means visualise as much as you want, set goals, take action and - …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.willpatrick.co.uk/articles/youve-never-manifested-anything">https://www.willpatrick.co.uk/articles/youve-never-manifested-anything</a></em></p>]]>
            </description>
            <link>https://www.willpatrick.co.uk/articles/youve-never-manifested-anything</link>
            <guid isPermaLink="false">hacker-news-small-sites-24144059</guid>
            <pubDate>Thu, 13 Aug 2020 15:05:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Compressed GPU texture formats – a review and compute shader decoders – part 1]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24143902">thread link</a>) | @Impossible
<br/>
August 13, 2020 | https://themaister.net/blog/2020/08/12/compressed-gpu-texture-formats-a-review-and-compute-shader-decoders-part-1/ | <a href="https://web.archive.org/web/*/https://themaister.net/blog/2020/08/12/compressed-gpu-texture-formats-a-review-and-compute-shader-decoders-part-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-327">
	
	<!-- .entry-header -->

	<div>
		<p>Compressed texture formats is one of the esoteric aspects of graphics programming almost no one cares all that much about. Neither did I, however, I’ve recently taken an academic interest in the zoo of compressed texture formats.</p>
<p>During development in Granite, I occasionally find it useful to test scenes which target mobile on desktop and vice versa, and in Vulkan, where there are no fallback paths for unsupported compression formats, we gotta roll our own decompression.</p>
<p>While it really isn’t all that useful to write a decoder for these formats, my goal is to create a suite of reasonably understandable compute shader kernels which can decode all of the standard formats I care about. Of course, I could just use a Frankenstein decoder which merges together a lot of C reference decoders and call it a day, but that’s not aesthetically pleasing or interesting to me. By implementing these formats straight from the <a href="https://www.khronos.org/registry/DataFormat/">Khronos Data Format</a> specification, I learned a lot of things I would not otherwise know about these formats.</p>
<p>There are several major families of formats we can consider multi-vendor and standardized. Each of them fill their own niche. Unfortunately, desktop and mobile each have their own timelines with different texture compression standards, which is not fully resolved to this day in GPU hardware. (Basis Universal is something I will need to study eventually as well as it aims to solve this problem in software.)</p>
<p>By implementing all these formats, I got to see the evolution of block compression formats, see the major differences and design decisions that went into each format.</p>
<h3>The major format families</h3>
<p>First, it is useful to summarize all the families of texture compression I’ve looked at.</p>
<h4>S3TC / DXT</h4>
<p>The simplest family of formats. These formats are also known as the “BC” formats in Vulkan, or rather, BC 1, 2 and 3. This is the granddad of texture compression, similar to how I view MPEG1 in the video compression world.</p>
<p>These formats are firmly rooted in desktop GPUs. They are basically non-existent on mobile GPUs, probably for historical patent reasons.</p>
<h4>RGTC</h4>
<p>A very close relative of S3TC. These formats are very simple formats which specialize in encoding 1 and 2 uncorrelated channels, perfect for normal maps, metallic-roughness maps, etc. It is somewhat questionable to call these a separate family of formats (the Data Format specification separates them), since the basic format is basically exactly equal to the alpha format of S3TC, except that it extends the format to also support SNORM (-1, 1 range) alongside UNORM. These formats represent BC4 and BC5 in Vulkan.</p>
<p>These formats are firmly rooted in desktop GPUs. They are basically non-existent on mobile GPUs.</p>
<h4>ETC</h4>
<p>The ETC family of formats is very similarly laid out to S3TC in how different texture types are supported, but the implementation detail is quite different (and ETC2 is quite the interesting format). To support encoding full depth alpha and 1/2-component textures, there is the EAC format, which mirrors the RGTC formats.</p>
<p>These formats are firmly rooted in mobile GPUs. ETC1 was originally the only mandated format for OpenGLES 2.0 implementations, and ETC2 was mandated for OpenGLES 3.0 GPUs. It has almost no support on desktop GPUs. Intel iGPU is an exception here.</p>
<h4>BPTC</h4>
<p>This is where complexity starts to explode and where things get interesting. BC6 and BC7 are designed to compress high quality color images at 8bpp. BC6 adds support for HDR, which is to this day, one of only two ways to compress HDR images.</p>
<p>On desktop, BPTC is the state of the art in texture compression and was introduced around 2010.</p>
<h4>ASTC</h4>
<p>ASTC is the final boss of texture compression, and is the current state of the art in texture compression. Its complexity is staggering and aims to dominate the world with 128 bits. Mere mortals are not supposed to understand this format.</p>
<p>ASTC’s roots are on Mali GPUs, but it was always a Khronos standard, and is widely supported now on mobile Vulkan implementation (and Intel iGPU :3), at least the LDR profile. What you say, profiles in a texture compression format? Yes … yes, this is just the beginning of the madness that is ASTC.</p>
<h4>PVRTC?</h4>
<p>PVRTC is a PowerVR-exclusive format that has had some staying power due to iOS and I will likely ignore it in this series. However, it seems like a <strong>very different kind of format</strong> to all the others and studying it might be interesting. However, there is zero reason to use this format in Granite, and I don’t want to chew over too much.</p>
<h2>What is a texture compression format anyway?</h2>
<p>In a texture compression format, the specification describes a process for taking random bits given to it, and how to decode the bit-soup into texels. There are fundamental constraints in texture compression which is unique to this problem domain, and these restrictions heavily influence the design of the formats in question.</p>
<h4>Fixed block size</h4>
<p>To be able to randomly access any texel in a texture, there must be an O(1) mapping from texture coordinate to memory address. The only reasonable way to do this is to have a fixed block size. In all formats, 4×4 is the most common one. (As you can guess, ASTC can do odd-ball block sizes like 6×5).</p>
<p>Similarly, for reasons of random access, the number of bits spent per block must be constant. The typical block sizes are 64-bits and 128-bits, which is 4bpp and 8bpp respectively at 4×4 block size.</p>
<p>Image and video compression has none of these restrictions. That is a major reason why image and video compression is so much more efficient.</p>
<h4>A set of coding tools</h4>
<p>Each format has certain things it can do. The more complex the operations the format can do, the more expensive the decoding hardware becomes (and complex a software decoder becomes), so there’s always a challenge to balance complexity with quality per bit when standardizing a format. The most typical way to add coding tools is to be able to select between different modes of operation based on the content of the block, where each mode is suited to certain patterns of input. Use the right tool for the job! As we will see in this study, the number of coding tools will increase exponentially, and it starts to become impossible to make good use of all the tools given to you by the format.</p>
<p>Encoding becomes an optimization task where we aim to figure out the best coding tools to use among the ones given to us. In simpler formats, there are very few things to try, and approaching the optimal solution becomes straight forward, but as we get into the more esoteric formats, the real challenge is to prune dead ends early, since brute forcing our way through a near-infinite configuration space is not practical (but maybe it is with GPU encode? :3)</p>
<h2>Commonalities across formats</h2>
<p>Image compression and video compression uses the Discrete Cosine Transform (DCT) even to this day. This fundamental compression technique has been with us since the 80s and refuses to die. All the new compression formats just keep piling on complexity on top of more complexity, but in the center of it all, we find the DCT, or some equivalent of it.</p>
<p>Very similarly, texture compression achieves its compression through interpolation between two color values. Somehow, the formats all let us specify two <strong>endpoints</strong> which are constant over the 4×4 block and interpolation <strong>weights</strong>, which vary per pixel. Most of the innovation in the formats all comes down to how complicated and esoteric we can make the process of generating the endpoints and weights.</p>
<p>The weight values are typically expressed with very few bits of precision per texel (usually 2 or 3), and this is the main way we will keep bits spent per pixel down. This snippet is the core coding tool in all the formats I have studied:</p>
<pre>decoded_texel = mix(endpoint0, endpoint1, weight_between_0_and_1);</pre>
<h4>To correlate, or not to correlate?</h4>
<p>The endpoint model blends all components in lock-step. Typically the endpoint will be an RGB value. We call this correlated, because this interpolation will only work well if chrominance remains fairly constant with luminance being the only component which varies significantly. In uncorrelated input, say, RGB with an alpha mask, many formats let us express decorrelated inputs with two sets of weights.</p>
<pre>decoded_rgb = mix(endpoint0_rgb, endpoint1_rgb, rgb_weight);
decoded_alpha = mix(endpoint0_alpha, endpoint1_alpha, alpha_weight);</pre>
<p>This costs a lot more bits to encode since alpha_weight is very different from rgb_weight, but it should be worth it.</p>
<p>Many formats let us express if there is correlation or not. Correlation should always be exploited.</p>
<h4>Working around the horrible endpoint interpolation artifacts</h4>
<p>Almost all formats beyond the most trivial ones try really hard to come up with ways to work around the fact that endpoint interpolation leads to horrible results in all but the simplest input. The most common approach here is to split the block into partitions, where each partition has its own endpoints.</p>
<h2>S3TC – The basics</h2>
<p>A compute shader decoder:</p>
<p><a href="https://github.com/Themaister/Granite/blob/master/assets/shaders/decode/s3tc.comp">https://github.com/Themaister/Granite/blob/master/assets/shaders/decode/s3tc.comp</a></p>
<p><a href="https://github.com/Themaister/Granite/blob/master/assets/shaders/decode/rgtc.h">https://github.com/Themaister/Granite/blob/master/assets/shaders/decode/rgtc.h</a></p>
<h3>BC1 – 4×4 – 64 bits</h3>
<p>The BC1 format is extremely simple and a good starting point. 32 bits is used to encode two RGB endpoints in RGB565 format. The other 32 bits encode 16 weights, with 2 bits allocated to each texel.</p>
<p>This lets us represent interpolation weights of 0, 1/3, 2/3 and 1.</p>
<p>Since there is a symmetry in this design, i.e.:</p>
<pre>mix(a, b, l) == mix(b, a, 1.0 - l)</pre>
<p>there would be two ways to specify the same block, where we swap endpoints and invert the weights to compensate. This is an extra bit of information we can exploit. Based on the integer representation of the two endpoints, we can check if one of greater than the other, and use a different decoding mode based on that information. This exploitation of symmetry will pop up again in many formats later! In the secondary mode, we add support for 1-bit …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://themaister.net/blog/2020/08/12/compressed-gpu-texture-formats-a-review-and-compute-shader-decoders-part-1/">https://themaister.net/blog/2020/08/12/compressed-gpu-texture-formats-a-review-and-compute-shader-decoders-part-1/</a></em></p>]]>
            </description>
            <link>https://themaister.net/blog/2020/08/12/compressed-gpu-texture-formats-a-review-and-compute-shader-decoders-part-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24143902</guid>
            <pubDate>Thu, 13 Aug 2020 14:51:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Clear is kind, unclear is unkind]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24143896">thread link</a>) | @mcrittenden
<br/>
August 13, 2020 | https://critter.blog/2020/08/13/clear-is-kind-unclear-is-unkind/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/08/13/clear-is-kind-unclear-is-unkind/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-663">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>I am terrified of awkwardness. I know nobody likes an awkward moment, but for me it’s downright crippling. I’ve walked out of the room during awkward moments on TV shows. I once faked internet issues to get out of an uncomfortable work call. I’m a huge fan of the Irish goodbye, because dealing with the not-sure-if-we-should-hug thing sucks. It’s been a serious problem in my life.</p>



<p>And wouldn’t you know it – I also hate giving people news that might upset them. Because that’s often pretty dang awkward. I’ve gotten good at figuring out ways to avoid it without feeling like I avoided it. For example:</p>



<ul><li>I’ve given negative feedback about something really tiny and specific in hopes that it would solve the bigger, much more critical problem, because talking about the critical problem may have been awkward. Spoiler: it never worked.</li><li>I’ve flat out avoided giving negative feedback because “they’re already dealing with a lot” or “I’m going to wait until I have a better example to use, or else it wouldn’t be fair to them” or who knows how many other reasons.</li><li>I’ve given negative feedback that really came from me, but I pitched it like “I don’t think this, but I’m wondering if &lt;a coworker&gt; may think it, from their point of view.”</li></ul>



<p>In that way, I convince my monkey brain that I’m being caring because I’m still “delivering feedback” just without the hurt feelings, right? But no, I’m being a jerk, because <a href="https://brenebrown.com/blog/2018/10/15/clear-is-kind-unclear-is-unkind/">clear is kind, and unclear is unkind</a>. </p>



<p>I don’t know where this first came from, but I heard it from Brené Brown and it was a smack in the face. If I’m not being clear, then I’m being unkind. Period. No matter how much I can try to convince myself that it’s not that simple, it really is.</p>



<p>I am changed. With this as my guiding principle, I feel confident in giving tough feedback no matter how awkward it might be, because anything else would be unkind. And even though I hate awkwardness, I hate being unkind even more.</p>

		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/08/13/clear-is-kind-unclear-is-unkind/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24143896</guid>
            <pubDate>Thu, 13 Aug 2020 14:50:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Even Unicorns Get the Blues]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24143764">thread link</a>) | @StuntPope
<br/>
August 13, 2020 | https://outofthecave.io/articles/even-unicorns-get-the-blues/ | <a href="https://web.archive.org/web/*/https://outofthecave.io/articles/even-unicorns-get-the-blues/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h3>Heretical Judge Rules that Uber Can’t Externalize its Labour Costs</h3>
<p><img loading="lazy" src="https://outofthecave.io/wp-content/uploads/2020/08/dead-unicorn-copy.jpg" alt="" width="693" height="478" srcset="https://outofthecave.io/wp-content/uploads/2020/08/dead-unicorn-copy.jpg 800w, https://outofthecave.io/wp-content/uploads/2020/08/dead-unicorn-copy-300x207.jpg 300w, https://outofthecave.io/wp-content/uploads/2020/08/dead-unicorn-copy-150x104.jpg 150w, https://outofthecave.io/wp-content/uploads/2020/08/dead-unicorn-copy-768x530.jpg 768w, https://outofthecave.io/wp-content/uploads/2020/08/dead-unicorn-copy-65x45.jpg 65w, https://outofthecave.io/wp-content/uploads/2020/08/dead-unicorn-copy-220x152.jpg 220w, https://outofthecave.io/wp-content/uploads/2020/08/dead-unicorn-copy-145x100.jpg 145w, https://outofthecave.io/wp-content/uploads/2020/08/dead-unicorn-copy-358x247.jpg 358w, https://outofthecave.io/wp-content/uploads/2020/08/dead-unicorn-copy-580x400.jpg 580w, https://outofthecave.io/wp-content/uploads/2020/08/dead-unicorn-copy-652x450.jpg 652w, https://outofthecave.io/wp-content/uploads/2020/08/dead-unicorn-copy-739x510.jpg 739w" sizes="(max-width: 693px) 100vw, 693px"></p>
<p>As I briefly covered <a href="https://axisofeasy.com/aoe/axisofeasy-158-hundreds-of-smartphone-apps-sell-your-location-data-to-government-connected-data-firms/">in my AxisOfEasy tech digest</a> this week, Uber and Lyft were bracing themselves for a ruling by a California judge that threatened to force them into treating their <span>wage slaves</span> drivers as employees. Lyft said if the ruling went against them it would cause “irreparable damage”. Uber CEO Dara Khosrowshahi penned an <a href="https://www.nytimes.com/2020/08/10/opinion/uber-ceo-dara-khosrowshahi-gig-workers-deserve-better.html">op-ed in the New York Times</a> that just so happened to run Monday, pining for a fair shake for gig economy <span>serfs</span> workers.<span id="more-1152"></span></p>
<p>Khosrowshahi, whose compensation package last year clocked in at $45,000,000 USD, waxed pensively,<em> ‘There has to be a “third way” for gig workers.’ .&nbsp;</em>Ideally one in which Uber wouldn’t be on the hook for their benefits and would be able to continue apace as a Silicon Valley unicorn: posting billions of dollars a quarter in losses and <a href="https://www.forbes.com/sites/janetwburns/2020/03/26/uber-and-airbnb-ask-for-bailouts-critics-arent-having-it/#2a5d61ff7639">jockeying for Federal bailouts.</a> Meanwhile the early stage backers, the VC’s and the private equity funds, would continue to live large off of financialization, not having to worry about the consequences of being <em>the&nbsp;</em>driving force in a race to the bottom for everybody else (even Uber’s lümpenvestors who bought into the IPO are still underwater).</p>
<p>As it turned out, <a href="https://www.theverge.com/2020/8/10/21362460/uber-lyft-drivers-employees-california-court-ruling">Judge Schulman ruled</a> that these gig economy workers are to be treated as employees in the State of California, and sure enough, Uber is now <a href="https://ktla.com/news/california/uber-lyft-threaten-to-leave-california-if-court-upholds-ruling-forcing-them-to-treat-drivers-as-employees/">threatening to pick up their ball and go home.</a></p>
<p>People following my writings may be surprised that I’m not approaching this as yet another government inflicted wound against capitalism, like how laws mandating higher minimum wages actually increase unemployment. It’s a fair point.</p>
<p>But we’re not talking about countless mom-and-pops and other main street businesses having their costs jacked up by economically illiterate career politicians. Even in a climate of government mis-micromanagement and overreach, the so called “free enterprise” participants should be competing under the same conditions. If an independently owned and operated driver service in the state has to operate under onerous taxation and terms, then being a Silicon Valley unicorn shouldn’t exempt you from suffering the same conditions.</p>
<p>In this case we’re talking <a href="https://outofthecave.io/articles/wait-why-is-the-fed-buying-my-biggest-competitors-bonds/">about Cantillonaires</a> who feel entitled to special privileges and exemptions but the reality is this:</p>
<h3>These companies were never intended to be economically viable.</h3>
<p><em>Uber and Lyft started the year with $11.3B and $2.8B in cash on their balance sheets respectively. They posted TTM losses of $10B and$ 2B respectively.&nbsp; They are valued around $54B and $9.2B</em></p>
<p>The only thing that mattered from the outset was to cannibilize the entire market, driving down prices and wages while operating at a loss so that they could garner the next financial event, be it a series D, E or F up-round and then eventually some monster acquisition or IPO. Within truly un-manipulated, free market competition, Uber and Lyft would have either had to compete, <em>viably</em>, with numerous entrants and competitors all fighting under their own steam, or else be snuffed out by economic reality.</p>
<p>The truth is that you can’t actually build a business where every transaction and input is subsidized, ultimately by central bank stimulus, while&nbsp; all normal course responsibilities of operations, like expenses, are externalized.</p>
<p>With the Everything Bubble <a href="https://outofthecave.io/articles/unicorn-winter/">finally looking to pop</a>, and pent up reality s-l-o-w-l-y <a href="https://outofthecave.io/articles/the-jackpot-chronicles-scenario-1-force-majeure/">beginning to reassert itself</a>, these Unicorns will have to face the same situation that every other non-unicorn, non Silicon Valley funded business has to face: Whatever your “boil-the-ocean” big idea is, you’re gonna have to do it in an economically viable way, or it’s not going to happen.</p>
<p><em>To follow my work sign up for the&nbsp;<a href="https://outofthecave.io/join/">Out Of The Cave mailing list</a>, or on&nbsp;<a href="https://nojack.easydns.ca/@stuntpope">Mastodon</a>&nbsp;or&nbsp;<a href="https://twitter.com/stuntpope">Twitter&nbsp;</a></em></p>
<p><a href="#" rel="nofollow" onclick="window.print(); return false;" title="Printer Friendly, PDF &amp; Email"><img src="https://cdn.printfriendly.com/buttons/printfriendly-button.png" alt="Print Friendly, PDF &amp; Email"></a></p></div></div>]]>
            </description>
            <link>https://outofthecave.io/articles/even-unicorns-get-the-blues/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24143764</guid>
            <pubDate>Thu, 13 Aug 2020 14:37:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stop Getting F'ed by Technical Recruiters]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24143721">thread link</a>) | @tacomondays
<br/>
August 13, 2020 | https://scottturman.com/stop-getting-fcked-by-technical-recruiters/ | <a href="https://web.archive.org/web/*/https://scottturman.com/stop-getting-fcked-by-technical-recruiters/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="69190526" data-element_type="column">
			<div>
					<div>
				<div data-id="11bdfd87" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;,&quot;_animation_delay&quot;:50}" data-widget_type="heading.default">
				<p>
			<h2>Get notified when we publish!</h2>		</p>
				</div>
				<div data-id="50628801" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;,&quot;_animation_delay&quot;:100}" data-widget_type="heading.default">
				<p>
			<h2>New Book -Stop Getting Fu*ked By Technical Recruiters</h2>		</p>
				</div>
				
				<div data-id="27158996" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;,&quot;_animation_delay&quot;:200}" data-widget_type="heading.default">
				<p>
			<h2>You probably never had anyone teach you how to negotiate your salary or benefits. Not your parents, school and certainly not your employer. Learning to negotiate how much you will charge for your labor may be one of the most important life skills you can ever develop as it will set the tone for how well you can live your life.</h2>		</p>
				</div>
				<section data-id="1bc4b15c" data-element_type="section" data-settings="{&quot;animation&quot;:&quot;fadeIn&quot;,&quot;animation_delay&quot;:300}">
						<div>
				<div>
				<div data-id="1a9f3005" data-element_type="column">
			<div>
					<div>
				
				<div data-id="53e472ce" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>This book is a collection of what I have learned as to how to accomplish this. I hope you will see the value of this book when you stop and realize that for every $10 more per hour you are able to get from a recruiter/employer will translate into another $20,000’ish more per year to your salary. It is also important to understand that every salary can have an additive effect over the lifetime of your total career earnings.</p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="562d2017" data-element_type="section" data-settings="{&quot;animation&quot;:&quot;fadeIn&quot;,&quot;animation_delay&quot;:300}">
						<div>
				<div>
				<div data-id="4bbccccc" data-element_type="column">
			<div>
					<div>
				
				<div data-id="61cdec01" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p><span>This book is going to teach you to take the power back. You can negotiate a higher rate, as you are the prize. You are the one with the skills needed to make the technology go and the recruiting company is simply one of the many conduits for the work that exists out there in the world.&nbsp;</span></p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
						</div>
			</div>
		</div></div>]]>
            </description>
            <link>https://scottturman.com/stop-getting-fcked-by-technical-recruiters/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24143721</guid>
            <pubDate>Thu, 13 Aug 2020 14:33:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using JDK FlightRecorder and JDK Mission Control]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24143664">thread link</a>) | @mfiguiere
<br/>
August 13, 2020 | https://blog.arkey.fr/2020/06/28/using-jdk-flight-recorder-and-jdk-mission-control/ | <a href="https://web.archive.org/web/*/https://blog.arkey.fr/2020/06/28/using-jdk-flight-recorder-and-jdk-mission-control/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>At some point we had an issue with application startup performance.
For a bit of context this app runs in a Kubernetes cluster, with k8s it’s possible
to define a <em>rollout policy</em> to avoid service disruption, that what we had, so there’s a
rollout, new pods (a pod is composed of the application container) get created,
new application are started, then Kubernetes has a mean to check when the application is
<strong>ready</strong>, it’s called the readiness probe. This probe can be a call to http endpoint or a script,
ours is an HTTP endpoint.</p>
<p>WHen the probe indicates the application is ready, the application starts receiving traffic,
from this moment latencies increased from 10-20 milliseconds to seconds.</p>
<p>Opening the recording JMC, it will start an automated analysis. Sometime it’s helpful
and warning should be looked at. In this case the issue was elsewhere.</p>
<p>To help in our case, I needed to go in the thread view, which as a <em>thread lanes</em>
which displays each thread as an horizontal bar, and JFR event are painted on the bar
at the time they happened and for how long. At the bottom there’s a the time axis.</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-0-thread-lanes.png" alt="startup 0 thread lanes">
</p>
<p>Thread Lanes</p>
</div>
<p>The first things that catch our eyes will be the vertical patterns, especially the one with
yellow and red around 12:51:15. Let’s zoom (you can select and right click, or use arrow keys.).</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-0-threads-lanes-closer.png" alt="startup 0 threads lanes closer">
</p>
<p>Zooming on the problematic</p>
</div>
<p>The vertical pattern is more precise, these vertical pattern indicates a <em>cross
threads phenomena</em>. And we can notice that all thread are not affected the same way.</p>
<p>The lanes in green at the top indicates these threads are progressing normally, nothing’s
wrong with them. However, if we go down there especially, the pattern materialize around
12:51:11.</p>
<p>Each color indicate some events:</p>
<div>
<ul>
<li>
<p>Gray ⇒ the thread does nothing, it’s parked</p>
</li>
<li>
<p>Small dark point ⇒ The park event, the thread was scheduled but was eventually parked</p>
</li>
<li>
<p>Red ⇒ In this case it’s a <em>blocked lock</em></p>
</li>
<li>
<p>Yellow ⇒ Here the yellow events that interests us are thread waiting on a lock</p>
</li>
</ul>
</div>
<p>I’m not well versed in describing colors, so know that there are other events that use
a slightly different tone / shade of red, yellow or else. Just click on the event
to see what’s going on.</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-1-threads-jedis-lock-event.png" alt="startup 1 threads jedis lock event">
</p>
<p>monitor blocked</p>
</div>
<p>The UI could be improved but going over the events shows a popup with its details,
for the Monitor Blocked event, there’s the duration this monitor was block, who held
this monitor before, and the monitor address in the heap.</p>
<p>This monitor was held for ~9s, that’s a big bottleneck !</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-1-threads-jedis-monitor-acquire-blocked.png" alt="startup 1 threads jedis monitor acquire blocked">
</p>
</div>
<p>In this case this application had ~200 thread competing for this lock in particular. And finding
the thread that acquired it is not automated, it’s a bit tedious, but in the end didn’t reveal
anything.</p>
<p>However, the Monitor Blocked event has another interesting element, the stacktrace. In the lower
pane of JMC, if the event is selected, we can see the stack trace where this event was emitted.</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-1-threads-jedis-monitor-blocked-stack.png" alt="startup 1 threads jedis monitor blocked stack">
</p>
<p>jedis classloading</p>
</div>
<p>Here that’s the JDK classloader. I would never have thought that the JDK code would cause ~9s
contention. But looking at the stacktrace, there <em>jedis</em> (a Redis client) connection pool involved.
Maybe the class have static initialization that does IO, maybe it’s the agent that runs in production
that introduces latencies during this specific classloading.</p>
<p>But all the threads starts working again around 12:51:22, and redis bottleneck is not anymore an issue
afterward. Let’s look at the story on the IO side, open the Socket IO view.</p>
<p>Identify which one is related to redis, either via IP or via port (Redis is <code>6379</code>).</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-1-socketio-redis-port.png" alt="startup 1 socketio redis port">
</p>
<p>Socket IO with redis port selected</p>
</div>
<p>While we see a total time of 30s, it’s the accumulated time for all thread for the recording duration (6m).
So nothing fancy here. However, we see that actual IO happens later, around 12:51:22.</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-1-socketio-redis.png" alt="startup 1 socketio redis">
</p>
<p>Socket IO actual Redis read / write</p>
</div>
<p>I’m not sure of the cause, we can definitely rule out Redis, the is either in the network, during
connection establishment, or actually during classloading.</p>
<p>In order to remediate that, we noticed this code is called once the application is ready.
So in order to avoid the contention the code was changed to pre-connect to redis during the
application startup before the application is considered ready. And it worked, this
specific issue disappeared.</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-2-thread-lanes.png" alt="startup 2 thread lanes">
</p>
</div>
<p>The issue identified in the first recording showed some contention on redis, this is now gone.
There is however in this second iteration multiple other issues when flying the mouse pointer
over the yellow and red events.</p>
<div>
<p>Incriminating stack traces 1</p>
<div>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-2-stack-01.png" alt="startup 2 stack 01">
</p>
<p>Jersey’s <code>ListMultiMap</code> classloading</p>
</div>
</div>
</div>
<div>
<p>2</p>
<div>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-2-stack-02.png" alt="startup 2 stack 02">
</p>
<p>Jackson’s <code>SerializerCache</code> initialization</p>
</div>
</div>
</div>
<div>
<p>3</p>
<div>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-2-stack-03.png" alt="startup 2 stack 03">
</p>
<p>Jersey’s <code>ImprovedAbstractMap</code> classloading</p>
</div>
</div>
</div>
<div>
<p>4</p>
<div>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-2-stack-04.png" alt="startup 2 stack 04">
</p>
<p>Jackson’s <code>PropertySerializerMap</code> initialization</p>
</div>
</div>
</div>
<div>
<p>5</p>
<div>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-2-stack-05.png" alt="startup 2 stack 05">
</p>
<p>Jackson’s <code>TypeFactory</code> initialization</p>
</div>
</div>
</div>
<div>
<p>6</p>
<div>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-2-stack-06.png" alt="startup 2 stack 06">
</p>
<p>Jackson’s <code>DeserializerCache</code> initialization</p>
</div>
</div>
</div>
<div>
<p>7</p>
<div>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-2-stack-07.png" alt="startup 2 stack 07">
</p>
<p>Guava’s <code>hash</code> function involving classloading</p>
</div>
</div>
</div>
<div>
<p>8</p>
<div>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-2-stack-08.png" alt="startup 2 stack 08">
</p>
<p>Newrelic’s <code>SynchronizedCollection.size()</code></p>
</div>
</div>
</div>
<div>
<p>9</p>
<div>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-2-stack-09.png" alt="startup 2 stack 09">
</p>
<p>Jackson’s <code>PropertySerializerMap</code> initialization</p>
</div>
</div>
</div>
<div>
<p>10</p>
<div>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-2-stack-10.png" alt="startup 2 stack 10">
</p>
<p>Datastax cassandra driver’s <code>ChainedResultSetFuture</code> involving classloading</p>
</div>
</div>
</div>
<div>
<p>11</p>
<div>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-2-stack-11.png" alt="startup 2 stack 11">
</p>
<p>Jersey’s <code>AbstractMapBasedMultimap</code> involving classloading</p>
</div>
</div>
</div>
<p>All the stacktraces above have one thing in common, a contention on a lock.
As thread were blocked, and new request appeared, this had the effects of increase the
queuing, and made tomcat creates new <em>http nio</em> worked threads until the maximum is reached
(200 by default). I applied the same trick: i.e before readiness, exercise code paths that
are lazy initialized. And it worked too. Most contention disappeared afterward.</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-3-C2-compiler.png" alt="startup 3 C2 compiler">
</p>
<p>Better startup / C2 compiler event</p>
</div>
<p>There was still some potential gain however. I noticed a few C2 compiler related events.
If you don’t know C1 and C2, those are the compilers that transform bytecode to assembly.
C1 interprets the bytecode and may perform some tricks like escape
analysis, but its role is to be fast to execute bytecode and not about optimizing the machine
code assembly. In a second phase C2 may kick in for hot code path that is code that is executed
very often, and its job is to output highly optimized code at the cost of higher computation
resources.</p>
<p>Note this compilation event <strong>is not</strong> blocking threads !</p>
<p>As an experiment I used the Graal compiler, which I believe is the new
generation of compiler that have a chance to replace C2. <a href="https://github.com/oracle/graal/blob/master/compiler/README.md">Graal compiler</a>
is part of the <a href="https://github.com/oracle/graal">GraalVM</a> project.
It ships as an experimental option : <code>-XX:+UnlockExperimentalVMOptions -XX:+UseJVMCICompiler</code>.</p>
<p>And the result for this work load in particular, just activating the Graal compiler between
these two successive rollouts.</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-3-grafana.png" alt="startup 3 grafana">
</p>
<p>Improved P99</p>
</div>
<p>This graph is falling under the <a href="https://latencytipoftheday.blogspot.com/2014/06/latencytipoftheday-most-page-loads.html"><em>percentlie</em></a>
but the improvement is still visible.</p>
<p>After that experiment when I analyzed the new profile I noticed that JVM was using a lot of time to
revoke bias locking. Note the events in fushia are custom JFR events that track HTTP requests.
(<a href="https://twitter.com/gunnarmorling">Gunnar Morling</a> has an inspiring
<a href="https://www.morling.dev/blog/rest-api-monitoring-with-custom-jdk-flight-recorder-events/">write up</a> about it).</p>
<p>This VM operation is done during safepoint during which the JVM is paused. At this time a lot of
bias revocation event appears, so we removed them, and it works too.</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-4-threads-revoke-biased-locks.png" alt="startup 4 threads revoke biased locks">
</p>
<p>Revoke Bias locking</p>
</div>
<p>The graphic below shows the difference in startup time. Other consuming backend services had to timeout
and eventually perform retries during rollouts which increased the pressure on the application.</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-5-before-after.png" alt="startup 5 before after">
</p>
<p>Before ⇒ after</p>
</div>
<p>Other smaller issues could be discovered and tackled, for example I noticed a few gaps
200ms wide at 30/1min intervals that were related to GC pauses.</p>
<div>
<p>GC gaps</p>
<p><span><img src="https://blog.arkey.fr/assets/jfr/startup-9-gc-pause-1.png" alt="startup 9 gc pause 1" title="GC gap 1"></span> <span><img src="https://blog.arkey.fr/assets/jfr/startup-9-gc-pause-2.png" alt="startup 9 gc pause 2" title="GC gap 2"></span></p>
</div>
<p>For this application the GC is working within 20ms excepts for a few larger pauses
during the early minutes of startup:</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/startup-9-thread-lanes-gc-pauses-effect.png" alt="startup 9 thread lanes gc pauses effect">
</p>
<p>GC pauses causes new HTTP worker threads</p>
</div>
<p>Tuning GC is out of scope for this article, but JMC presents a nice view that could help identify GC
causes. In my opinion it’s currently a bit less powerful as GC logs because GC events lack
useful information only found in GC logs with appropriate tags and level.</p>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/jmc-java-application-view.png" alt="jmc java application view">
</p>
<p>Java Application view</p>
</div>
<div>
<p><img src="https://blog.arkey.fr/assets/jfr/jmc-garbage-collection-view.png" alt="jmc garbage collection view">
</p>
<p>Garbage Collection view</p>
</div>
<p>Anyway from there we could imagine a <em>setting</em> file in the JDK dedicated for GC events.
Instead of parsing log files whose <em>string format</em> that may change a bit over releases
(even with unified logging) GC events could be analyzed leveraging the included JFR schema.</p>
<p>Also, with JFR it’s even possible to record memory leak using the <code>profile</code> <em>settings</em> file,
I never tried that in a real situation though, but if this avoids the need to make a heap dump
and parse it then I’m all in.</p>
</div></div>]]>
            </description>
            <link>https://blog.arkey.fr/2020/06/28/using-jdk-flight-recorder-and-jdk-mission-control/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24143664</guid>
            <pubDate>Thu, 13 Aug 2020 14:28:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Eight Great DevOps Resources for Beginners]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24143403">thread link</a>) | @savovaleks
<br/>
August 13, 2020 | https://microtica.com/great-devops-resources/ | <a href="https://web.archive.org/web/*/https://microtica.com/great-devops-resources/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div>
<p>The future of DevOps solutions is bright. The <a href="https://www.marketsandmarkets.com/Market-Reports/devops-824.html" target="_blank" rel="noreferrer noopener">global DevOps market size</a> is expected to <strong>increase from $2.90 billion in 2017 to $10.31 billion by 2023</strong>, at a Compound Annual Growth Rate (CAGR) of 24.7% during the forecast period.&nbsp;</p>



<p>The growing need for fast app delivery is driving the market growth, with organizations that want to achieve both speed and quality.&nbsp;</p>



<p>However, the world is facing <a href="https://www.shuttleops.io/the-shortage-of-devops-skills" target="_blank" rel="noreferrer noopener">a shortage of DevOps skills</a>. That’s why DevOps engineers are highly-paid, with <a href="https://www.glassdoor.com/Salaries/devops-engineer-salary-SRCH_KO0,15.htm" target="_blank" rel="noreferrer noopener">Glassdoor estimating</a> <strong>the average annual pay at around $100,000</strong>.&nbsp;</p>



<p>So, if you’re looking for a career switch or upgrade, learning DevOps is a good idea. From books to podcasts, <em>here are the best DevOps resources to start with:&nbsp;</em></p>



<h2><strong><a rel="noreferrer noopener" href="https://www.bookdepository.com/Phoenix-Project-Gene-Kim/9781942788294?ref=grid-view&amp;qid=1588577029418&amp;sr=1-1" target="_blank">The Phoenix Project</a></strong></h2>



<p>Who would have thought you could write a novel about DevOps? Well, Gene Kim, Kevin Behr, and George Spafford obviously did a great job!&nbsp;</p>



<p><strong>The Phoenix Project </strong>is an amazing novel about DevOps. The story revolves around a fictional company called “Parts Unlimited”, where the IT manager gets promoted into a senior position. Then, he gets a deadline of 90 days to repair “The Phoenix Project”, a failing and messy code project that’s crucial to the future of the company. If he fails, the CEO threatens to outsource the entire IT department and let go of the people working in it.</p>



<p>So, he starts working on it with the help of some board members. The most important thing here is his philosophy called The Three Ways. It consists of (obviously) three parts—maximizing the flow of work from left-to-right, starting from business to development to IT operations to the end-user; increasing the feedback loop from right to left, and developing and nurturing a culture of <a href="https://microtica.com/cracking-the-continuous-deployment-code/" target="_blank" rel="noreferrer noopener">continuous deployment</a> and learning.</p>



<p>This philosophy helps him create <strong>a streamlined workflow in the department</strong>, <a href="https://microtica.com/6-tips-to-solve-miscommunication-in-dev-teams/">improve </a><strong><a href="https://microtica.com/6-tips-to-solve-miscommunication-in-dev-teams/" target="_blank" rel="noreferrer noopener">communication</a> and effectiveness</strong>, and make the IT department really valuable to the company.&nbsp;</p>



<p>I think this is a really great book, especially for beginners. It gives a sense of what problems IT departments face every day, and offers realistic solutions.&nbsp;</p>



<h2><strong><a rel="noreferrer noopener" href="https://www.oreilly.com/library/view/infrastructure-as-code/9781491924334/" target="_blank">Infrastructure as Code</a></strong></h2>



<p>Coming from ThoughtWorks, this is another book that focuses on <strong>the entire DevOps movement from a more technical aspect</strong>. This book covers the principles of Infrastructure as Code, practical examples, dynamic infrastructure platforms, various cloud options, tools, patterns, software engineering practices, <a href="https://microtica.com/how-to-create-simple-ci-cd-pipeline/" target="_blank" rel="noreferrer noopener">creation and management of pipelines</a>, workflows, and infrastructure management. They are all divided into three sections—Foundations, Patterns, and Practices.&nbsp;</p>



<p>If you’re interested in similar books, you can check <a href="https://www.amazon.com/Evolutionary-Architecture-Nature-Basis-Design/dp/0471117269" target="_blank" rel="noreferrer noopener">Evolutionary Architecture</a> and <a href="https://www.amazon.com/Building-Microservices-Designing-Fine-Grained-Systems/dp/1491950358/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1508683865&amp;sr=1-1&amp;keywords=microservices" target="_blank" rel="noreferrer noopener">Building Microservices</a>, also by ThoughtWorks.&nbsp;</p>



<h2><a href="https://www.udemy.com/course/linux-academy-devops-essentials/?LSNPUBID=JVFxdTr9V80&amp;ranEAID=JVFxdTr9V80&amp;ranMID=39197&amp;ranSiteID=JVFxdTr9V80-BF4jpUPRiGZluHvCXXjptQ" target="_blank" rel="noreferrer noopener"><strong>DevOps Essentials</strong></a></h2>



<p>This Udemy course has hosted over 40,000 students who gave an average rating of 4.4/5. The course is completely free, covering 2 hours and 15 minutes of video lessons.&nbsp;</p>



<p>This course can give you an understanding of <strong>how DevOps impacts the IT world</strong>. You’ll learn the basic DevOps terminology, the evolution of DevOps, the most important processes, the most common tools used, and the most popular DevOps and cloud providers.&nbsp;</p>



<h2><strong><a rel="noreferrer noopener" href="https://www.udemy.com/course/docker-and-kubernetes-the-complete-guide/?ranMID=39197&amp;ranEAID=JVFxdTr9V80&amp;ranSiteID=JVFxdTr9V80-T3DyVhPcjn.KepO0Rg.oZg&amp;LSNPUBID=JVFxdTr9V80" target="_blank">Docker and Kubernetes: The Complete Guide</a></strong></h2>



<p>Another Udemy course with over 120,000 students enrolled and an average rating of 4.6. During 21.5 hours of video materials, you’ll learn everything you need to know about <strong>Docker and Kubernetes</strong>, even if you don’t have previous experience with these topics.&nbsp;</p>



<p>The course starts with a deep dive into the Docker world, showing you all the Docker fundamentals. Then, you’ll learn everything you need to know about setting up a <a href="https://microtica.com/how-to-create-simple-ci-cd-pipeline/" target="_blank" rel="noreferrer noopener">CI/CD pipeline</a> and implementing it on Github and AWS.&nbsp;</p>



<p>Then, you’ll learn to construct a multi-container application utilizing Node, React, Redis, and Postgres. After this, you should be able to <a href="https://microtica.com/start-creating-infrastructure-on-aws-like-a-pro/" target="_blank" rel="noreferrer noopener">deploy both single- and multi-container applications on AWS</a>.</p>



<p>Finally, you’ll learn how to build a <a href="https://microtica.com/deploy-your-first-microservice-on-kubernetes-in-10-mins/" target="_blank" rel="noreferrer noopener">Kubernetes Cluster</a>. This course even covers setting up HTTPS on Kubernetes.&nbsp;</p>



<p>In their reviews, students say how they loved the way the teacher explains all concepts step-by-step. All in all, it’s one of the best courses on Udemy.&nbsp;</p>



<h2><a href="https://www.udemy.com/course/learn-devops-continuously-deliver-better-software/?LSNPUBID=JVFxdTr9V80&amp;ranEAID=JVFxdTr9V80&amp;ranMID=39197&amp;ranSiteID=JVFxdTr9V80-ImNkBFHUPJQ04wh3qXOm9A" target="_blank" rel="noreferrer noopener"><strong>Learn DevOps: Continuously Deliver Better Software</strong></a></h2>



<p>One of the most detailed courses about DevOps that targets more experienced engineers, System Administrators, IT managers, IT operation members, and other IT professionals.&nbsp;</p>



<p>The lecturer explains how to <strong>improve software delivery with automation, configuration management, provisioning, and deployment.</strong> Docker and Kubernetes are also covered.&nbsp;</p>



<p>Although the course lasts about 4.5 hours, you can add much more by trying everything by yourself. The lecturer even offers support for people who get stuck. Students also have a Facebook group where they post questions and discuss.</p>



<h2><a href="https://netflixtechblog.com/" target="_blank" rel="noreferrer noopener"><strong>The Netflix Tech Blog</strong></a></h2>



<p>The Netflix Tech Blog is a great place where you can find out “how they build code at Netflix.” Developers share literally everything, going beyond DevOps. Here, you’ll learn <strong>how Netflix creates, builds, and manages its system and engineering organizations</strong>.&nbsp;</p>



<p>For example, in one of their blogs, they elaborated on how they applied <a href="https://netflixtechblog.com/applying-netflix-devops-patterns-to-windows-2a57f2dbbf79" target="_blank" rel="noreferrer noopener">Netflix DevOps patterns to Windows</a>, while another one is about their <a href="https://netflixtechblog.com/ready-for-changes-with-hexagonal-architecture-b315ec967749" target="_blank" rel="noreferrer noopener">hexagonal architecture</a>.&nbsp;</p>



<h2><a href="https://www.reddit.com/r/devops/" target="_blank" rel="noreferrer noopener"><strong>DevOps SubReddit</strong></a></h2>



<p>Although it’s not everyone’s first choice, the DevOps SubReddit has many interesting and useful information software engineers should check out. Here, you’ll find a lot of blog posts, articles, and news about DevOps.</p>



<p>Most importantly, you can <strong>engage in discussions with fellow DevOps enthusiasts </strong>and learn a lot from their knowledge and experience, sharing a lot of practical examples.&nbsp;</p>



<h2><strong><a rel="noreferrer noopener" href="https://www.arresteddevops.com/" target="_blank">Podcast: Arrested DevOps</a></strong></h2>



<p>Arrested DevOps is a podcast hosted by Joe Laha, Bridget Kromhout, Matt Stratton, Trever Hess, and Jessica Kerr. They’ve recorded over 130 episodes, with the goal to help developers evolve practices and manage teams that will help them take the maximum out of DevOps.&nbsp;</p>



<p>Listeners can learn more about <strong>DevOps strategies, best tools, and integrations</strong> from delightful guest speakers that come from different parts of the world. The episodes last about 40-45 minutes and are released on a monthly basis.</p>



<p><strong>Here are some other links with DevOps resources you might find useful:&nbsp;</strong></p>



<ul><li><a href="https://techbeacon.com/devops/53-essential-resources-devops-practitioners" target="_blank" rel="noreferrer noopener">53 essential resources for DevOps practitioners</a></li><li><a href="https://aws.amazon.com/devops/resources/" target="_blank" rel="noreferrer noopener">DevOps resources – AWS</a></li><li><a href="https://www.upguard.com/blog/devops-resources-online" target="_blank" rel="noreferrer noopener">The best DevOps resources online</a></li><li><a href="https://opensource.com/article/19/12/devops-resources" target="_blank" rel="noreferrer noopener">8 must-read DevOps articles for success in 2020</a></li></ul>




<!--<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="https://microtica.com/great-devops-resources/"
    dc:identifier="https://microtica.com/great-devops-resources/"
    dc:title="8 Great DevOps Resources for Beginners &#038; Advanced"
    trackback:ping="https://microtica.com/great-devops-resources/trackback/" />
</rdf:RDF>-->
</div></article></div>]]>
            </description>
            <link>https://microtica.com/great-devops-resources/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24143403</guid>
            <pubDate>Thu, 13 Aug 2020 14:00:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elon Musk's Emoji Profile]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24143309">thread link</a>) | @simonpure
<br/>
August 13, 2020 | https://emojigraph.org/blog/elon-musk-emoji/ | <a href="https://web.archive.org/web/*/https://emojigraph.org/blog/elon-musk-emoji/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        
                            <div><p>I've conducted an analysis of 10,683 tweets, which were posted by Elon Musk between June 4th 2010 and August 2nd 2020. 622 of these tweets contained emojis.</p><h2>Elon's First Emoji</h2><p>Between 2010 and 2017, Elon Musk didn't use any emojis in his tweets, instead opting only for the emoticon "<strong>:)</strong>". He used an emoji for the first time in a tweet on the 4th of June 2017. The tweet was about his Mom and it contained the <a href="https://emojigraph.org/red-heart/">❤️Red Heart</a> emoji.</p>
<h2>📈 On The Rise</h2><p>In the second half of 2017, Elon slowly began to use more emojis in his tweets. In May 2018, he used 56 emojis throughout the month.</p><p><img alt="Elon Musk emoji count by months" height="355" src="https://emojigraph.org/media/images/Elon_Musk_emoji_usage_by_months.width-800.png" width="800"></p><p><em>Figure 1: Emoji count by months.</em></p><p>Following this, he became more active with his emoji usage, and his record sits at 98 emojis in one month, which he set only recently.</p><p><img alt="Elon Musk Total emoji count by days" height="459" src="https://emojigraph.org/media/images/Elon_Musk_Total_emoji_count_by_days.width-800.png" width="800"></p><p><em>Figure 2: Total emoji count by days.</em></p><p>Fast forward to August 2nd 2020, he'd used a total of 1,096 emojis in his tweets, with the number of unique emojis sitting at 172.</p><p>Of the 3,332 tweets he posted in the last 12 months, 311 of these tweets (9.33%) contained a total of 518 emojis. That's, on average, 43 emojis per month.</p><h2>🔝 TOP</h2><p>Elon Musk's Top 100 emojis are shown in the Emoji cloud below:</p><p><img alt="Elon Musk Emoji Cloud" height="689" src="https://emojigraph.org/media/images/Elon_Musk_Emoji_Cloud_croped.width-800.png" width="800"></p><p>To illustrate how his Top 100 emoji list has changed, I've also created a time series race chart:</p>
<p>Let's take a closer look at his Top 20 emojis.</p><p><img alt="Elon Musk top 20 emoji on twitter" height="582" src="https://emojigraph.org/media/images/Elon_Musk_top_20_emoji_on_twitter.width-800.png" width="800"></p><p><em>Figure 3: Top 20 emojis.</em></p><p>The most used was the <a href="https://emojigraph.org/rolling-on-the-floor-laughing/">🤣Rolling on the Floor Laughing</a> emoji, also known as ROFL. Of it's 247 appearances, around 222 consisted of the 🤣🤣 combination.</p><p>Other popular combos included:</p><p><img alt="Emoji Combos" height="992" src="https://emojigraph.org/media/images/Emoji_Combos.width-1000.png" width="984"></p><p><em>Figure 4: Top emoji combos.</em></p><p>The second most used emoji was the <a href="https://emojigraph.org/heart-suit/">♥️Heart Suit</a> emoji, which featured 124 times. This was also used in different combos, but was most often used (13 times) like this: ♥️♥️♥️.</p><p>The <a href="https://emojigraph.org/black-heart/">🖤Black Heart</a> emoji sits in 3rd place and is followed by the <a href="https://emojigraph.org/grinning-face/">😀Grinning Face</a> emoji.</p><p>The <a href="https://emojigraph.org/fire/">🔥Fire</a> emoji was used most often in combos like 🔥🔥, while the <a href="https://emojigraph.org/rocket/">🚀Rocket</a> emoji was often used in tweets relating to Elon's SpaceX business.</p>
<p>After the <a href="https://emojigraph.org/winking-face/">😉Winking Face</a>, <a href="https://emojigraph.org/two-hearts/">💕Two Hearts</a>, and <a href="https://emojigraph.org/thumbs-up/">👍Thumbs Up</a>, we can see the <a href="https://emojigraph.org/oncoming-automobile/">🚘Oncoming Automobile</a> emoji in 10th place, which was used most commonly in tweets relating to Tesla.</p><div>
    <blockquote><p lang="en" dir="ltr">Needed another general assembly line to reach 5k/week Model 3 production. A new building was impossible, so we built a giant tent in 2 weeks. Tesla team kfa!! Gah, love them so much ♥️🚘💫</p>— Elon Musk (@elonmusk) <a href="https://twitter.com/elonmusk/status/1008906087611883521?ref_src=twsrc%5Etfw">June 19, 2018</a></blockquote>


</div>
<p>Other emojis in the Top 20 included:</p><ul><li><a href="https://emojigraph.org/flying-saucer/">🛸Flying Saucer</a></li><li><a href="https://emojigraph.org/red-heart/">❤️Red Heart</a></li><li><a href="https://emojigraph.org/dashing-away/">💨Dashing Away</a></li><li><a href="https://emojigraph.org/dizzy/">💫Dizzy</a></li><li><a href="https://emojigraph.org/thinking-face/">🤔Thinking Face</a></li><li><a href="https://emojigraph.org/musical-notes/">🎶Musical Notes</a></li><li>The <a href="https://emojigraph.org/hugging-face/">🤗Hugging Face</a> emoji, which could have also been used as a "jazz hands" emoji.</li><li><a href="https://emojigraph.org/alien/">👽Alien</a></li><li><a href="https://emojigraph.org/honeybee/">🐝Honeybee</a></li><li><a href="https://emojigraph.org/grinning-face-with-sweat/">😅Grinning Face with Sweat</a></li></ul><h2>What if Twitter had profile emoji statistics?</h2><p>I've been thinking about this and I've put together an idea of how this could look. I'd love to get your feedback!</p><p>Vertical:</p><p><img alt="Elon emoji profile narrow HD" height="2000" src="https://emojigraph.org/media/images/Elon_emoji_profile_narrow_HD.width-800.png" width="800"></p><p>Share it on your website:</p><p><code>&lt;a href='https://emojigraph.org/blog/elon-musk-emoji/'&gt;&lt;img src='https://emojigraph.org/media/images/Elon_emoji_profile_narrow_HD.original.png' alt='Elon Musk emoji profile' /&gt;&lt;/a&gt;</code></p><p>Horizontal:</p><p><img alt="Elon emoji profile wide HD" height="400" src="https://emojigraph.org/media/images/Elon_emoji_profile_wide_HD.width-800.png" width="800"></p><p>Share it on your website:</p><p><code>&lt;a href='https://emojigraph.org/blog/elon-musk-emoji/'&gt;&lt;img src='https://emojigraph.org/media/images/Elon_emoji_profile_wide_HD.original.png' alt='Elon Musk emoji profile' /&gt;&lt;/a&gt;</code></p><p>We hope you found this analysis insightful. More research will be coming soon.</p><p>From the team at Emojigraph ❤️</p></div>
                        

                    
                    </div></div>]]>
            </description>
            <link>https://emojigraph.org/blog/elon-musk-emoji/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24143309</guid>
            <pubDate>Thu, 13 Aug 2020 13:51:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Major Drivers of Corporate Reputation Management]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24143280">thread link</a>) | @Gpetrium
<br/>
August 13, 2020 | https://gpetrium.com/drivers-of-corporate-reputation-management/ | <a href="https://web.archive.org/web/*/https://gpetrium.com/drivers-of-corporate-reputation-management/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://gpetrium.com/drivers-of-corporate-reputation-management/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24143280</guid>
            <pubDate>Thu, 13 Aug 2020 13:49:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Type Scale Generator with automatic CSS generation]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24143269">thread link</a>) | @Santosh83
<br/>
August 13, 2020 | https://baseline.is/tools/type-scale-generator | <a href="https://web.archive.org/web/*/https://baseline.is/tools/type-scale-generator">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://baseline.is/tools/type-scale-generator</link>
            <guid isPermaLink="false">hacker-news-small-sites-24143269</guid>
            <pubDate>Thu, 13 Aug 2020 13:48:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SOC2 Compliance Best Practices with Chef Habitat and ShuttleOps]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24143061">thread link</a>) | @gscho
<br/>
August 13, 2020 | https://www.shuttleops.io/soc2-compliance-best-practices-with-chef-habitat-and-shuttleops-compliance-agents | <a href="https://web.archive.org/web/*/https://www.shuttleops.io/soc2-compliance-best-practices-with-chef-habitat-and-shuttleops-compliance-agents">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article id="post-3495" role="article" itemscope="" itemprop="blogPost" itemtype="http://schema.org/BlogPosting"><header><p> Posted <time datetime="2020-08-10" itemprop="datePublished">August 10, 2020</time> <span>by</span> <span itemprop="author" itemscope="" itemptype="http://schema.org/Person">Yonathan Koren</span></p></header><section itemprop="articleBody"><h2 id="Agentless-and-Agent-based-Scanning-Solutions" data-renderer-start-pos="1">Agentless and Agent-based Scanning Solutions</h2><p data-renderer-start-pos="47">A Compliance Agent is software provided by a Security Vendor in order to supplement traditional network scans and authenticated scans conducted by a centralized software installation dedicated for such scans. These agents run on a Linux host as a daemon, or on a Windows host as a service, and report to the control plane supplied by the Security Vendor. Some examples of such agents are:</p><ul><li><p data-renderer-start-pos="439">Nessus Agent by Tenable</p></li><li><p data-renderer-start-pos="466"><span id="5087e708-04ce-47be-b2b7-66f090fab7a4" data-renderer-mark="true" data-mark-type="annotation" data-mark-annotation-type="inlineComment" data-id="5087e708-04ce-47be-b2b7-66f090fab7a4">Insight Agent</span> by Rapid7</p></li><li><p data-renderer-start-pos="493">Cloud Agent by Qualys</p></li></ul><p data-renderer-start-pos="518">The former scanning solution, done with a centralized scanning software installation, is often referred to as an <em data-renderer-mark="true">agentless</em> scanning solution.</p><p data-renderer-start-pos="518"><picture>
<source type="image/webp" srcset="https://www.shuttleops.io/wp-content/uploads/2020/08/fa7fa367-fdce-4fb9-a299-a8afd5eff456-1024x607.png.webp 1024w, https://www.shuttleops.io/wp-content/uploads/2020/08/fa7fa367-fdce-4fb9-a299-a8afd5eff456-300x178.png.webp 300w, https://www.shuttleops.io/wp-content/uploads/2020/08/fa7fa367-fdce-4fb9-a299-a8afd5eff456-768x456.png.webp 768w, https://www.shuttleops.io/wp-content/uploads/2020/08/fa7fa367-fdce-4fb9-a299-a8afd5eff456-1536x911.png.webp 1536w, https://www.shuttleops.io/wp-content/uploads/2020/08/fa7fa367-fdce-4fb9-a299-a8afd5eff456.png.webp 1792w" sizes="(max-width: 680px) 100vw, 680px">
<img src="https://www.shuttleops.io/wp-content/uploads/2020/08/fa7fa367-fdce-4fb9-a299-a8afd5eff456-1024x607.png" alt="" width="680" height="403" srcset="https://www.shuttleops.io/wp-content/uploads/2020/08/fa7fa367-fdce-4fb9-a299-a8afd5eff456-1024x607.png 1024w, https://www.shuttleops.io/wp-content/uploads/2020/08/fa7fa367-fdce-4fb9-a299-a8afd5eff456-300x178.png 300w, https://www.shuttleops.io/wp-content/uploads/2020/08/fa7fa367-fdce-4fb9-a299-a8afd5eff456-768x456.png 768w, https://www.shuttleops.io/wp-content/uploads/2020/08/fa7fa367-fdce-4fb9-a299-a8afd5eff456-1536x911.png 1536w, https://www.shuttleops.io/wp-content/uploads/2020/08/fa7fa367-fdce-4fb9-a299-a8afd5eff456.png 1792w" sizes="(max-width: 680px) 100vw, 680px">
</picture>
</p><p data-renderer-start-pos="518">Agentless Scanning Solution Architecture</p><p data-renderer-start-pos="706">Because an agentless scanning solution needs to perform <span id="6f2df3fa-8266-4a6a-b991-bf79b110a44e" data-renderer-mark="true" data-mark-type="annotation" data-mark-annotation-type="inlineComment" data-id="6f2df3fa-8266-4a6a-b991-bf79b110a44e">outbound</span> network connections to all of its targets, including SSH connections for authenticated scans, the solution works best in a centralized-hub-and-spoke Virtual Private Cloud (VPC) architecture. In this architecture, one centralized ‘hub’ VPC is peered with multiple ‘spoke’ VPCs, with each of these spoke VPCs typically representing an environment for a user-facing service. Often, the centralized hub VPC contains services used by the organization for internal uses. For example: scanning software, a VPN server, an artifact repository, a CI/CD system, etc.</p><p data-renderer-start-pos="1328">However, not all organizations make use of a centralized-hub-and-spoke architecture. For example, picture the following organization’s overall infrastructure:</p><ul><li><p data-renderer-start-pos="1490">Four unpeered VPCs, each representing an environment for an AWS Elastic Kubernetes Service (EKS) cluster with four self-managed EKS worker nodes, which will run the organization’s user-facing services.</p></li><li><p data-renderer-start-pos="1695">CircleCI as the CI/CD system to build Docker images to run on the EKS clusters.</p></li><li><p data-renderer-start-pos="1778">AWS Elastic Container Registry as the Docker Registry for the aforementioned images.</p></li><li><p data-renderer-start-pos="1866">AWS Systems Manager (SSM) Agent running on the EKS worker nodes, for remote access directly from the AWS console (no need for a VPN server).</p></li><li><p data-renderer-start-pos="2010">GitHub as the VCS provider for the organization.</p></li></ul><p data-renderer-start-pos="2062">In this case, a centralized VPC would have nothing to host! However, this does not change the fact that the organization may need to undergo a SOC2 audit. In this case, a couple of their audit deliverables may be to create organizational procedures for periodic scans of their assets (the self-managed EKS worker nodes), and also a report of their assets run against a CIS level 2 benchmark and the resulting list of security objectives that need to be rectified.</p><p data-renderer-start-pos="2527">In order to create these deliverables, the organization needs a scanning software, especially one featuring predefined controls, such as the CIS level 2 benchmark for Amazon Linux 2 – which corresponds to the base Linux distribution of the EKS worker nodes. Security Vendors such as Tenable, Rapid7, and Qualys supply products for this exact use case.</p><p data-renderer-start-pos="2880">Thus, the organization described above is able to leverage the Compliance Agents provided by one of these three vendors in an architecture without a centralized VPC, and without VPC peering:</p><p data-renderer-start-pos="2880"><picture>
<source type="image/webp" srcset="https://www.shuttleops.io/wp-content/uploads/2020/08/e3a8b973-6149-41d9-93b4-281f482a4343-1024x607.png.webp 1024w, https://www.shuttleops.io/wp-content/uploads/2020/08/e3a8b973-6149-41d9-93b4-281f482a4343-300x178.png.webp 300w, https://www.shuttleops.io/wp-content/uploads/2020/08/e3a8b973-6149-41d9-93b4-281f482a4343-768x456.png.webp 768w, https://www.shuttleops.io/wp-content/uploads/2020/08/e3a8b973-6149-41d9-93b4-281f482a4343-1536x911.png.webp 1536w, https://www.shuttleops.io/wp-content/uploads/2020/08/e3a8b973-6149-41d9-93b4-281f482a4343.png.webp 1792w" sizes="(max-width: 680px) 100vw, 680px">
<img src="https://www.shuttleops.io/wp-content/uploads/2020/08/e3a8b973-6149-41d9-93b4-281f482a4343-1024x607.png" alt="" width="680" height="403" srcset="https://www.shuttleops.io/wp-content/uploads/2020/08/e3a8b973-6149-41d9-93b4-281f482a4343-1024x607.png 1024w, https://www.shuttleops.io/wp-content/uploads/2020/08/e3a8b973-6149-41d9-93b4-281f482a4343-300x178.png 300w, https://www.shuttleops.io/wp-content/uploads/2020/08/e3a8b973-6149-41d9-93b4-281f482a4343-768x456.png 768w, https://www.shuttleops.io/wp-content/uploads/2020/08/e3a8b973-6149-41d9-93b4-281f482a4343-1536x911.png 1536w, https://www.shuttleops.io/wp-content/uploads/2020/08/e3a8b973-6149-41d9-93b4-281f482a4343.png 1792w" sizes="(max-width: 680px) 100vw, 680px">
</picture>
</p><p data-renderer-start-pos="3075">Here, rather than having a centralized, self-managed scanning software installation, each agent on the organization’s self-managed EKS worker nodes has an outbound connection to a Security Vendor’s managed control plane. The organization can perform scans, generate reports, and pursue outstanding security objectives as needed, without needing to change their mostly vendor-managed, hub-free architecture.</p><h2 id="Enter-ShuttleOps" data-renderer-start-pos="3483">Enter ShuttleOps</h2><p data-renderer-start-pos="3501">ShuttleOps believes that minimizing operational overhead for an organization will maximize its ability to continuously deliver software and hence value for its customers. ShuttleOps acts on this belief by providing organizations with a fully-managed CI/CD system for building and deploying artifacts using existing codebases, and also providing the service orchestration control plane to monitor and manage application environments.</p><p data-renderer-start-pos="3935">ShuttleOps supports Chef Habitat Packages as artifacts for its Build and Deploy Pipelines. We’ve created a <a title="https://github.com/ShuttleOps/soc2-habitat-best-practices/tree/master/effortless-compliance-agent" href="https://github.com/ShuttleOps/soc2-habitat-best-practices/tree/master/effortless-compliance-agent" target="_blank" rel="noopener noreferrer" data-renderer-mark="true">Chef Habitat Effortless Package which deploys the Qualys Cloud Agent on an instance</a> in order to promote the use of vendor-supplied Compliance Agents, which we consider to be a security best practice.</p><h2 id="Using-a-Chef-Effortless-Package-for-the-Compliance-Agent" data-renderer-start-pos="4243">Using a Chef Effortless Package for the Compliance Agent</h2><p data-renderer-start-pos="4301">We can leverage a pattern of Chef Habitat Packages called Chef Effortless. This pattern builds Chef Infra Cookbooks and packages them inside the Chef Habitat package. The Chef Infra Cookbooks are pieces of Configuration Management code, similar to Ansible Playbooks or SaltStack States. However, the benefit of the Chef Effortless model is that we can leverage the Chef Infra Cookbooks without the need for a Chef Server: Using ShuttleOps, we can create a Build Pipeline and a Deployment Pipeline for a Chef Effortless package, link the two pipelines together, and thus every time we push to the codebase’s master branch, ShuttleOps will rebuild the package and redeploy it.</p><p data-renderer-start-pos="4977">Using a Configuration Management solution such as Chef Infra Cookbooks, we can perform a vendor-supported installation of the Compliance Agent:</p><p><code>rpm_package 'qualys-cloud-agent' do<br> source "#{node['qualys']['assets_dir']}/#{node['qualys']['pkg_name']}"<br> end</code></p><p data-renderer-start-pos="5236">(<a title="https://github.com/ShuttleOps/soc2-habitat-best-practices/blob/master/effortless-compliance-agent/cookbooks/qualys/recipes/qualys.rb#L22-L24" href="https://github.com/ShuttleOps/soc2-habitat-best-practices/blob/master/effortless-compliance-agent/cookbooks/qualys/recipes/qualys.rb#L22-L24" target="_blank" rel="noopener noreferrer" data-renderer-mark="true">link to code</a>)</p><p><code>execute 'link-agent' do<br> command "/usr/local/qualys/cloud-agent/bin/qualys-cloud-agent.sh ActivationId=#{node['qualys']['activation_id']} CustomerId=#{node['qualys']['customer_id']}"<br> end</code></p><p data-renderer-start-pos="5441">(<a title="https://github.com/ShuttleOps/soc2-habitat-best-practices/blob/master/effortless-compliance-agent/cookbooks/qualys/recipes/qualys.rb#L45-L47" href="https://github.com/ShuttleOps/soc2-habitat-best-practices/blob/master/effortless-compliance-agent/cookbooks/qualys/recipes/qualys.rb#L45-L47" target="_blank" rel="noopener noreferrer" data-renderer-mark="true">link to code</a>)</p><h2 id="Deploying-the-Qualys-Cloud-Agent-using-ShuttleOps" data-renderer-start-pos="5457">Deploying the Qualys Cloud Agent using ShuttleOps</h2><p data-renderer-start-pos="5508">We start by forking the following GitHub repository: <span data-inline-card="true" data-card-url="https://github.com/ShuttleOps/soc2-habitat-best-practices"><span><a tabindex="0" role="button" href="https://github.com/ShuttleOps/soc2-habitat-best-practices" target="_blank" rel="noopener noreferrer" data-testid="inline-card-unauthorized-view"><span><span>https://github.com/ShuttleOps/soc2-habitat-best-practices</span></span></a></span></span>. We can then visit <a title="http://app.shuttleops.io" href="http://app.shuttleops.io/" data-renderer-mark="true">app.shuttleops.io</a> and immediately log in using GitHub.</p><p data-renderer-start-pos="5640">Once that is done, we’ll see in the Connections tab that our VCS provider, GitHub, is automatically connected:</p><p data-renderer-start-pos="5640"><picture>
<source type="image/webp" srcset="https://www.shuttleops.io/wp-content/uploads/2020/08/2052d680-2d59-49da-8b33-3aa61518faef-1024x378.png.webp 1024w, https://www.shuttleops.io/wp-content/uploads/2020/08/2052d680-2d59-49da-8b33-3aa61518faef-300x111.png.webp 300w, https://www.shuttleops.io/wp-content/uploads/2020/08/2052d680-2d59-49da-8b33-3aa61518faef-768x284.png.webp 768w, https://www.shuttleops.io/wp-content/uploads/2020/08/2052d680-2d59-49da-8b33-3aa61518faef-1536x567.png.webp 1536w, https://www.shuttleops.io/wp-content/uploads/2020/08/2052d680-2d59-49da-8b33-3aa61518faef.png.webp 1915w" sizes="(max-width: 680px) 100vw, 680px">
<img src="https://www.shuttleops.io/wp-content/uploads/2020/08/2052d680-2d59-49da-8b33-3aa61518faef-1024x378.png" alt="" width="680" height="251" srcset="https://www.shuttleops.io/wp-content/uploads/2020/08/2052d680-2d59-49da-8b33-3aa61518faef-1024x378.png 1024w, https://www.shuttleops.io/wp-content/uploads/2020/08/2052d680-2d59-49da-8b33-3aa61518faef-300x111.png 300w, https://www.shuttleops.io/wp-content/uploads/2020/08/2052d680-2d59-49da-8b33-3aa61518faef-768x284.png 768w, https://www.shuttleops.io/wp-content/uploads/2020/08/2052d680-2d59-49da-8b33-3aa61518faef-1536x567.png 1536w, https://www.shuttleops.io/wp-content/uploads/2020/08/2052d680-2d59-49da-8b33-3aa61518faef.png 1915w" sizes="(max-width: 680px) 100vw, 680px">
</picture>
</p><p data-renderer-start-pos="5640">We are going to be building the Chef Habitat Package from the repository we’ve just forked on GitHub, and then deploying the package on AWS EC2 instances. This means that we need an artifact store for the Chef Habitat package and AWS credentials, respectively. Therefore, we need the following connections enabled:</p><ul><li><p data-renderer-start-pos="6073">Chef Habitat Builder (tutorial: <a title="https://help.shuttleops.io/support/solutions/articles/44001932343-connect-to-chef-habitat-builder" href="https://help.shuttleops.io/support/solutions/articles/44001932343-connect-to-chef-habitat-builder" target="_blank" rel="noopener noreferrer" data-renderer-mark="true">https://help.shuttleops.io/support/solutions/articles/44001932343-connect-to-chef-habitat-builder</a>)</p></li><li><p data-renderer-start-pos="6207">AWS (tutorial: <a title="https://help.shuttleops.io/support/solutions/articles/44001932339-connect-to-amazon-web-services-aws-" href="https://help.shuttleops.io/support/solutions/articles/44001932339-connect-to-amazon-web-services-aws-" data-renderer-mark="true">https://help.shuttleops.io/support/solutions/articles/44001932339-connect-to-amazon-web-services-aws-</a>)</p></li></ul><h3 id="Creating-the-Build-Pipeline" data-renderer-start-pos="6328">Creating the Build Pipeline</h3><p data-renderer-start-pos="6357">Once the Chef Habitat Builder and AWS connections are created, we can <a title="https://help.shuttleops.io/support/solutions/articles/44001932747-create-a-build-pipeline" href="https://help.shuttleops.io/support/solutions/articles/44001932747-create-a-build-pipeline" target="_blank" rel="noopener noreferrer" data-renderer-mark="true">create our first Build Pipeline</a>. When adding the codebase to our build pipeline, we need to make sure to set the <strong data-renderer-mark="true">plan.sh</strong> file path to be that of the <strong data-renderer-mark="true">effortless-compliance-agent</strong> package. That is, <strong data-renderer-mark="true">effortless-compliance-agent/habitat/plan.sh</strong></p><p data-renderer-start-pos="6357"><picture>
<source type="image/webp" srcset="https://www.shuttleops.io/wp-content/uploads/2020/08/956a68ef-1d62-41b0-b622-f8a2d4c90035-1024x549.png.webp 1024w, https://www.shuttleops.io/wp-content/uploads/2020/08/956a68ef-1d62-41b0-b622-f8a2d4c90035-300x161.png.webp 300w, https://www.shuttleops.io/wp-content/uploads/2020/08/956a68ef-1d62-41b0-b622-f8a2d4c90035-768x412.png.webp 768w, https://www.shuttleops.io/wp-content/uploads/2020/08/956a68ef-1d62-41b0-b622-f8a2d4c90035.png.webp 1477w" sizes="(max-width: 680px) 100vw, 680px">
<img src="https://www.shuttleops.io/wp-content/uploads/2020/08/956a68ef-1d62-41b0-b622-f8a2d4c90035-1024x549.png" alt="" width="680" height="365" srcset="https://www.shuttleops.io/wp-content/uploads/2020/08/956a68ef-1d62-41b0-b622-f8a2d4c90035-1024x549.png 1024w, https://www.shuttleops.io/wp-content/uploads/2020/08/956a68ef-1d62-41b0-b622-f8a2d4c90035-300x161.png 300w, https://www.shuttleops.io/wp-content/uploads/2020/08/956a68ef-1d62-41b0-b622-f8a2d4c90035-768x412.png 768w, https://www.shuttleops.io/wp-content/uploads/2020/08/956a68ef-1d62-41b0-b622-f8a2d4c90035.png 1477w" sizes="(max-width: 680px) 100vw, 680px">
</picture>
</p><p data-renderer-start-pos="6357">We also need to set the Chef Habitat origin to upload the package to. We’ve chosen <strong data-renderer-mark="true">shuttleops-tutorials</strong> – an origin which belongs to us – but any accessible origin can be used:</p><p data-renderer-start-pos="6357"><picture>
<source type="image/webp" srcset="https://www.shuttleops.io/wp-content/uploads/2020/08/d47f0ff7-0cc6-4c2c-b88c-6973d781a0ee.png.webp 701w, https://www.shuttleops.io/wp-content/uploads/2020/08/d47f0ff7-0cc6-4c2c-b88c-6973d781a0ee-300x201.png.webp 300w" sizes="(max-width: 701px) 100vw, 701px">
<img src="https://www.shuttleops.io/wp-content/uploads/2020/08/d47f0ff7-0cc6-4c2c-b88c-6973d781a0ee.png" alt="" width="701" height="470" srcset="https://www.shuttleops.io/wp-content/uploads/2020/08/d47f0ff7-0cc6-4c2c-b88c-6973d781a0ee.png 701w, https://www.shuttleops.io/wp-content/uploads/2020/08/d47f0ff7-0cc6-4c2c-b88c-6973d781a0ee-300x201.png 300w" sizes="(max-width: 701px) 100vw, 701px">
</picture>
</p><p data-renderer-start-pos="6357">We can then kick off the Build Pipeline and watch it run to completion:</p><p data-renderer-start-pos="6357"><picture>
<source type="image/webp" srcset="https://www.shuttleops.io/wp-content/uploads/2020/08/fa702192-74c2-4c18-a54a-6b06555aa15e-1024x530.png.webp 1024w, https://www.shuttleops.io/wp-content/uploads/2020/08/fa702192-74c2-4c18-a54a-6b06555aa15e-300x155.png.webp 300w, https://www.shuttleops.io/wp-content/uploads/2020/08/fa702192-74c2-4c18-a54a-6b06555aa15e-768x397.png.webp 768w, https://www.shuttleops.io/wp-content/uploads/2020/08/fa702192-74c2-4c18-a54a-6b06555aa15e-1536x794.png.webp 1536w, https://www.shuttleops.io/wp-content/uploads/2020/08/fa702192-74c2-4c18-a54a-6b06555aa15e.png.webp 1636w" sizes="(max-width: 680px) 100vw, 680px">
<img src="https://www.shuttleops.io/wp-content/uploads/2020/08/fa702192-74c2-4c18-a54a-6b06555aa15e-1024x530.png" alt="" width="680" height="352" srcset="https://www.shuttleops.io/wp-content/uploads/2020/08/fa702192-74c2-4c18-a54a-6b06555aa15e-1024x530.png 1024w, https://www.shuttleops.io/wp-content/uploads/2020/08/fa702192-74c2-4c18-a54a-6b06555aa15e-300x155.png 300w, https://www.shuttleops.io/wp-content/uploads/2020/08/fa702192-74c2-4c18-a54a-6b06555aa15e-768x397.png 768w, https://www.shuttleops.io/wp-content/uploads/2020/08/fa702192-74c2-4c18-a54a-6b06555aa15e-1536x794.png 1536w, https://www.shuttleops.io/wp-content/uploads/2020/08/fa702192-74c2-4c18-a54a-6b06555aa15e.png 1636w" sizes="(max-width: 680px) 100vw, 680px">
</picture>
</p><h3 id="Creating-the-Deployment-Pipeline" data-renderer-start-pos="6927">Creating the Deployment Pipeline</h3><p data-renderer-start-pos="6961">Once the Build Pipeline is complete, we can <a title="https://help.shuttleops.io/support/solutions/articles/44001932779-create-a-deployment-pipeline" href="https://help.shuttleops.io/support/solutions/articles/44001932779-create-a-deployment-pipeline" target="_blank" rel="noopener noreferrer" data-renderer-mark="true">create a Deployment Pipeline</a>. We need to make sure that we set the following Chef Habitat configuration variables for our Chef Effortless package, in particular:</p><ul><li><p data-renderer-start-pos="7170">attributes.qualys.is_remote_pkg = true</p></li><li><p data-renderer-start-pos="7212">attributes.qualys.pkg_name = “qualys-cloud-agent.x86_64.deb”</p></li><li><p data-renderer-start-pos="7276">attributes.qualys.pkg_remote_source = “https://[your artifact store]/qualys-cloud-agent.x86_64.deb”</p></li><li><p data-renderer-start-pos="7379">attributes.qualys.activation_id = “[retrieved from the Qualys dashboard]“</p></li><li><p data-renderer-start-pos="7456">attributes.qualys.customer_id = “[retrieved from the Qualys dashboard]“</p></li></ul><p><picture>
<source type="image/webp" srcset="https://www.shuttleops.io/wp-content/uploads/2020/08/42da0515-8211-4d4f-91a2-cb057cd94b0c.png.webp 787w, https://www.shuttleops.io/wp-content/uploads/2020/08/42da0515-8211-4d4f-91a2-cb057cd94b0c-288x300.png.webp 288w, https://www.shuttleops.io/wp-content/uploads/2020/08/42da0515-8211-4d4f-91a2-cb057cd94b0c-768x800.png.webp 768w" sizes="(max-width: 787px) 100vw, 787px">
<img src="https://www.shuttleops.io/wp-content/uploads/2020/08/42da0515-8211-4d4f-91a2-cb057cd94b0c.png" alt="" width="787" height="820" srcset="https://www.shuttleops.io/wp-content/uploads/2020/08/42da0515-8211-4d4f-91a2-cb057cd94b0c.png 787w, https://www.shuttleops.io/wp-content/uploads/2020/08/42da0515-8211-4d4f-91a2-cb057cd94b0c-288x300.png 288w, https://www.shuttleops.io/wp-content/uploads/2020/08/42da0515-8211-4d4f-91a2-cb057cd94b0c-768x800.png 768w" sizes="(max-width: 787px) 100vw, 787px">
</picture>
Then, we need to select the deployment targets for our Deployment Pipeline. For this demo, we’ve selected 3 T3.micro EC2 instances.</p> <picture>
<source type="image/webp" srcset="https://www.shuttleops.io/wp-content/uploads/2020/08/image-20200806-172817-1024x623.png.webp 1024w, https://www.shuttleops.io/wp-content/uploads/2020/08/image-20200806-172817-300x183.png.webp 300w, https://www.shuttleops.io/wp-content/uploads/2020/08/image-20200806-172817-768x467.png.webp 768w, https://www.shuttleops.io/wp-content/uploads/2020/08/image-20200806-172817.png.webp 1103w" sizes="(max-width: 680px) 100vw, 680px">
<img src="https://www.shuttleops.io/wp-content/uploads/2020/08/image-20200806-172817-1024x623.png" alt="" width="680" height="414" srcset="https://www.shuttleops.io/wp-content/uploads/2020/08/image-20200806-172817-1024x623.png 1024w, https://www.shuttleops.io/wp-content/uploads/2020/08/image-20200806-172817-300x183.png 300w, https://www.shuttleops.io/wp-content/uploads/2020/08/image-20200806-172817-768x467.png 768w, https://www.shuttleops.io/wp-content/uploads/2020/08/image-20200806-172817.png 1103w" sizes="(max-width: 680px) 100vw, 680px">
</picture>
<p>Finally, we can kick off the Deployment Pipeline and watch it run to completion, provisioning our Deployment Targets and loading our configured service:</p> <picture>
<source type="image/webp" srcset="https://www.shuttleops.io/wp-content/uploads/2020/08/image-20200805-214733-1024x480.png.webp 1024w, https://www.shuttleops.io/wp-content/uploads/2020/08/image-20200805-214733-300x141.png.webp 300w, https://www.shuttleops.io/wp-content/uploads/2020/08/image-20200805-214733-768x360.png.webp 768w, https://www.shuttleops.io/wp-content/uploads/2020/08/image-20200805-214733-1536x720.png.webp 1536w, https://www.shuttleops.io/wp-content/uploads/2020/08/image-20200805-214733.png.webp 1654w" sizes="(max-width: 680px) 100vw, 680px">
<img src="https://www.shuttleops.io/wp-content/uploads/2020/08/image-20200805-214733-1024x480.png" alt="" width="680" height="319" srcset="https://www.shuttleops.io/wp-content/uploads/2020/08/image-20200805-214733-1024x480.png 1024w, https://www.shuttleops.io/wp-content/uploads/2020/08/image-20200805-214733-300x141.png 300w, https://www.shuttleops.io/wp-content/uploads/2020/08/image-20200805-214733-768x360.png 768w, https://www.shuttleops.io/wp-content/uploads/2020/08/image-20200805-214733-1536x720.png 1536w, https://www.shuttleops.io/wp-content/uploads/2020/08/image-20200805-214733.png 1654w" sizes="(max-width: 680px) 100vw, 680px">
</picture>
<h3 id="Seeing-the-Compliance-Agent-in-Action" data-renderer-start-pos="7827">Seeing the Compliance Agent in Action</h3><p data-renderer-start-pos="7866">A few minutes after deployment, the Chef Effortless package will have fully completed its Chef Infra run, and the Qualys Cloud Agent will have connected to the Qualys Cloud Platform and configured itself.</p><p data-renderer-start-pos="7866"><img src="https://www.shuttleops.io/wp-content/uploads/2020/08/image-20200805-215102-1024x415.png" alt="" width="680" height="276" srcset="https://www.shuttleops.io/wp-content/uploads/2020/08/image-20200805-215102-1024x415.png 1024w, https://www.shuttleops.io/wp-content/uploads/2020/08/image-20200805-215102-300x122.png 300w, https://www.shuttleops.io/wp-content/uploads/2020/08/image-20200805-215102-768x311.png 768w, https://www.shuttleops.io/wp-content/uploads/2020/08/image-20200805-215102.png 1283w" sizes="(max-width: 680px) 100vw, 680px"></p><p data-renderer-start-pos="7866">Now we can even begin generating reports, for example, we can generate the following CIS level 2 benchmark report for Ubuntu 18.x (the Linux distribution which ShuttleOps’ Deployment Target EC2 Instances run on):</p><p data-renderer-start-pos="7866"><img src="https://www.shuttleops.io/wp-content/uploads/2020/08/image-20200806-060302-1024x565.png" alt="" width="680" height="375" srcset="https://www.shuttleops.io/wp-content/uploads/2020/08/image-20200806-060302-1024x565.png 1024w, https://www.shuttleops.io/wp-content/uploads/2020/08/image-20200806-060302-300x165.png 300w, https://www.shuttleops.io/wp-content/uploads/2020/08/image-20200806-060302-768x424.png 768w, https://www.shuttleops.io/wp-content/uploads/2020/08/image-20200806-060302.png 1512w" sizes="(max-width: 680px) 100vw, 680px"></p><p data-renderer-start-pos="7866">With ShuttleOps building and deploying the Chef Effortless package which performs the vendor-supported installation of the our Compliance Agent of choice, we can deploy an application package built and deployed by ShuttleOps side-by-side with our Compliance Agent Effortless package:</p><p data-renderer-start-pos="7866"><img src="https://www.shuttleops.io/wp-content/uploads/2020/08/image-20200806-173237-1024x631.png" alt="" width="680" height="419" srcset="https://www.shuttleops.io/wp-content/uploads/2020/08/image-20200806-173237-1024x631.png 1024w, https://www.shuttleops.io/wp-content/uploads/2020/08/image-20200806-173237-300x185.png 300w, https://www.shuttleops.io/wp-content/uploads/2020/08/image-20200806-173237-768x473.png 768w, https://www.shuttleops.io/wp-content/uploads/2020/08/image-20200806-173237.png 1113w" sizes="(max-width: 680px) 100vw, 680px"></p><p data-renderer-start-pos="7866">We hope that this article gave some more insight into Compliance Agents, why organizations use them, and how to leverage them in the context of Chef Habitat and ShuttleOps. Check out <a href="https://app.shuttleops.io/signin">ShuttleOps’ free tier</a> if you’re looking to get started on deploying a Chef Effortless package today!</p></section></article></div></div>]]>
            </description>
            <link>https://www.shuttleops.io/soc2-compliance-best-practices-with-chef-habitat-and-shuttleops-compliance-agents</link>
            <guid isPermaLink="false">hacker-news-small-sites-24143061</guid>
            <pubDate>Thu, 13 Aug 2020 13:24:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Decentralized Finance, the YAM fiasco and the road to DeFi sustainability]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24143042">thread link</a>) | @bpierre
<br/>
August 13, 2020 | https://blog.rotki.com/2020/08/13/sustainable-defi/ | <a href="https://web.archive.org/web/*/https://blog.rotki.com/2020/08/13/sustainable-defi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
  
  <p><span>13 Aug 2020</span></p><ul>
  <li><a href="#introduction">Introduction</a></li>
  <li><a href="#what-is-defi">What is DeFi</a>
    <ul>
      <li><a href="#decentralized-exchanges">Decentralized Exchanges</a></li>
      <li><a href="#lendingborrowing-protocols">Lending/Borrowing Protocols</a></li>
      <li><a href="#synthetic-assets">Synthetic Assets</a></li>
    </ul>
  </li>
  <li><a href="#what-new-possibilities-does-defi-unlock">What new possibilities does DeFi unlock?</a></li>
  <li><a href="#the-dark-side-of-defi">The dark side of DeFi</a>
    <ul>
      <li><a href="#yam-finance">YAM finance.</a></li>
    </ul>
  </li>
  <li><a href="#responsible-decentralized-finance">Responsible Decentralized Finance</a>
    <ul>
      <li><a href="#responsible-defi-user">Responsible DeFi user</a></li>
      <li><a href="#responsible-defi-founder">Responsible DeFi founder</a></li>
      <li><a href="#towards-a-sustainable-defi-ecosystem">Towards a sustainable DeFi ecosystem</a></li>
    </ul>
  </li>
  <li><a href="#closing--about-the-author">Closing / About the author</a></li>
</ul>

  

<p>This post explores what is the concept of Decentralized Finance (DeFi), what new possibilities does it unlock and why it’s so cool and hot right now. On the other side of the coin it touches on the dark side of DeFi with the YOLO farming and unaudited contracts most recently highlighted by the YAM fiasco. Finally it takes a look on the road ahead, the lessons that the community needs to learn in order to create sustainable and responsible DeFi for decades to come. Finacial instruments and tools that will not only be used by a few Twitter bros but permisionlessly by everyone around the world.</p>



<p>In one sentence, decentralized finance is the permissionless decentralized version of various traditional financial instruments such as exchanges, lending, borrowing, synthetic assets e.t.c. There has been a lot of innovation in the sector in the past 2 years.</p>

<h2 id="decentralized-exchanges">Decentralized Exchanges</h2>

<p>We have various decentralized exchanges such as:</p>

<ul>
  <li><a href="https://uniswap.org/">Uniswap</a></li>
  <li><a href="https://kyberswap.com/swap">Kyber</a></li>
  <li><a href="https://www.deversifi.com/">Deversifi</a></li>
</ul>

<p>They all operate in a decentralized way and are non-custodial in stark contrast with centralized exchanges such as Binance, Kraken to which you have to first deposit and give custody of your funds.</p>

<h2 id="lendingborrowing-protocols">Lending/Borrowing Protocols</h2>

<p>There are protocols such as <a href="https://app.compound.finance/">Compound</a> and <a href="https://app.aave.com/home">Aave</a> that allow users to lend their assets to earn interest or to borrow assets after staking some collateral. MakerDAO also offers a form of borrowing via <a href="https://oasis.app/borrow">vaults</a> that can mint the DAI stable token after depositing various forms of collateral.</p>

<h2 id="synthetic-assets">Synthetic Assets</h2>

<p>Synthetic asset protocols such as <a href="https://www.synthetix.io/">Synthetix</a> or <a href="https://www.tokensets.com/">Token Sets</a> combine a mix of different assets into a single asset. This way you can get exposure to multiple different assets by just holding a single synthetic asset.</p>



<p>What DeFi does is nothing new. All of this already exist in one form or another in the world of “traditional finance”. What is so amazing and revolutionary about DeFi is that it’s completely decentralized and permissionless. And that it is accessible to everyone regardless of location or background. It’s unlocking a ton of possibilities for people around the world, building a new permisionless financial system in the process.</p>



<p>Just like with everything involving money this sector also attracts short-termed myopic people and projects who are driven by greed.</p>

<p>There is the concept of a yield farmer, someone who provides liquidity or stakes in a protocol in return for interest, fees or some governance token. Yield farming is not bad per se. Everyone who provides liquidity in all the DeFi protocols is essentially yield farming. There is nothing wrong with that.</p>



<p><img src="https://blog.rotki.com/public/post8/defichad.jpeg"></p>



<p>The bad side of farming is the “DeFi chad” or “Defi Degen”. The kind of meme-driven farmer who jumps from protocol to protocol without any thought on contract safety, chasing the biggest yield, dumping their tokens to the new guys and then moving on. A practice that is obviously unsustainable.</p>

<h2 id="yam-finance">YAM finance.</h2>

<p>A very good example of the irresponsible approach to DeFi is YAM. An experiment that did not even manage to last 2 days. It <a href="https://medium.com/@yamfinance/yam-finance-d0ad577250c7">launched</a> in 19:00 UTC, August 11th, 2020 and <a href="https://medium.com/@yamfinance/yam-post-rescue-attempt-update-c9c90c05953f">died</a> 36 hours later.</p>

<h3 id="what-happened">What happened?</h3>

<p>YAM advertised itself as an experiment from the start. It was a mashup of code from various other DeFi projects, completely unaudited and without any safety hatches or deposit limits. For all intents and purposes a completely reckless enterprise. Despite that at its peak it had over $500m locked in it!</p>

<p>For a technical explanation of the bug read <a href="https://medium.com/@yamfinance/yam-post-rescue-attempt-update-c9c90c05953f">their post</a>. In short the bug made it impossible for the YAM holders to reach quorum on anything so essentially the governance part of the protocol was broken and without it the entire protocol could no longer function.</p>

<p>Once people realized that, the market cap of YAM went within minutes from $60m to 0. Everyone left holding YAM they bought took a loss as they can’t sell it, so did uniswap liquidity providers as they took a loss every time someone sold YAM through them.</p>

<h3 id="could-this-have-been-avoided">Could this have been avoided?</h3>

<p>ABSOLUTELY</p>

<p>There were multiple warnings from many prominet people in the crypto sector including myself that this is going to end in tears. The minimum precaution that could have been taken is:</p>

<ul>
  <li>Write contract tests</li>
  <li>Have some sort of security audit of the code</li>
  <li>IF you claim it’s an experiment then treat it as such by:
    <ul>
      <li>Putting deposit limits in the code to protect your users</li>
      <li>Put an escape hatch in the code to protect your users.</li>
    </ul>
  </li>
</ul>

<h3 id="ponzi">Ponzi</h3>

<p>What’s worse is that from the tokenomics of YAM it was obvious that this was a ponzi game. Note the difference between ponzi game and ponzi scheme as explained in <a href="https://jpkoning.blogspot.com/2018/05/ethereum-is-full-of-ponzis-is-that.html">this</a> article.</p>

<p>Every 12 hours the total supply of the token increased but the amount held by each user stayed the same through a process called rebasing. The first farmers were incentivized to pump and shill YAM via social media so they can find victims onto whom to dump their tokens after the rebase. The new holders had the exact same incentives to pump it even more so they can in turn dump their bags onto the poor sods after the second rebase. And so on and so forth.</p>

<p>It was a “fair” and transparent ponzi, but a ponzi nonetheless. And with the amount of due dilligence people do in Crypto I am 100% certain that most of the people who got shilled into it did not realize that and lost money as a result.</p>

<h3 id="shilling-in-twitter">Shilling in Twitter</h3>

<p>What I personally found <strong>absolutely disgusting</strong> was the incessant amount of shilling of YAM in Twitter by many people in the ethereum community whom I actually respect who were also farming it.</p>

<p>It’s inexcusable, reckless and irresponsible. They were shilling a protocol that had not seen any production use yet, had unaudited code, no tests, no deposit limits or anything. They were doing so only to get more people into the Ponzi game to sustain their profits and dump their bags onto them.</p>

<p>I sincerely hope lessons are now learned. If you are shilling an unaudited insecure ponzi you are part of the problem of why this sector is not taken seriously. We can’t have such irresponsible behavior if we are ever going to reach mass adoption.</p>

<h3 id="what-did-it-cost-us">What did it cost us?</h3>

<p><img src="https://blog.rotki.com/public/post8/yamcrash.jpeg"></p>

<p>Some people lost a lot of money</p>

<ul>
  <li>Marketcap dropped from $60m to $0.</li>
  <li>People who bought YAM are left holding a hot potato, got burned and lost everything they invested.</li>
  <li>Uniswap liquidity providers lost money due to providing liquidity for sellers of a dying token.</li>
  <li>Lots of money in gas fees (300+ gwei) for nothing</li>
</ul>

<p>The rest of the non yam farming ethereum users were left with 300 gwei gas prices and could not really use the ethereum blockchain.</p>

<p>And finally and most importantly, outsiders roll their eyes and we lose credibility. Every nocoiner I know that I tried to explain this to just get their view that crypto is only for scams and ponzi schemes reinforced. Can you blame them?</p>



<p>If you are to keep anything from this post as a take-home message let it be this section. DeFi is good and is here to stay. We just all need to be more responsible about it.</p>

<h2 id="responsible-defi-user">Responsible DeFi user</h2>

<p>As a user don’t rush into every new thing that pops up and promises amazing 100%+ returns. Do you due dilligence, demand audit reports, ask people in the community about the history and portfolio of the founders of the protocol and if possible read the code and understand the tokenomics. DYOR. If something sounds too good to be true that’s because it’s probably a scam or a ponzi.</p>

<h2 id="responsible-defi-founder">Responsible DeFi founder</h2>

<p>As a founder/developer for the love of god DO NOT TEST IN PRODUCTION. Be responsible. Users do not heed warnings, or disclaimers. If it’s an experiment and you want to experiment in the mainnet that’s fine. Then put deposit limits and centralized escape hatches for the first X months. The safety of your users is your responsibility. Avoiding that responsbility through the veil of “just an experiment” won’t be accepted.</p>

<h2 id="towards-a-sustainable-defi-ecosystem">Towards a sustainable DeFi ecosystem</h2>

<p>It is only through responsible development and professionalism that this sector can mature. We won’t get any new users with the YOLO yield farming memes. For DeFi to fullfill its goals of a new permisionless financial system it needs to go mainstream. And it will not achieve that through ponzi games and chad memes in Twitter. This will only be achieved when the ecosystem is perceived by normies to be mature enough so that they can also come in and participante in it. Let’s all then do our part to advance the ecosystem through responsible building and sustainable development and build a new financial system for the many and not for the few.</p>



<p>My name is <a href="https://twitter.com/LefterisJP">Lefteris Karapetsas</a>. I am the founder of <a href="https://rotki.com/">Rotki</a>. It is a project that deals with DeFi, among other things, and believes in the dream of a sustainable permissionless new financial system. We are a portfolio tracker and accounting tool that respect our users’ privacy and we are in this game for the long run and not to scam our users for short term gain.</p>

<p>Here is how you can help us:</p>

<ul>
  <li>Try out Rotki’s <a href="https://github.com/rotki/rotki/releases">latest release</a> and use it daily.</li>
  <li><a href="https://rotki.com/products/">Buy</a> a premium subscription to unlock awesome premium features and also support our development.</li>
  <li>Provide us with <a href="https://github.com/rotki/rotki/issues">feedback</a> in the form of bug reports and feature requests.</li>
  <li><a href="https://github.com/rotki/rotki">Star</a> our Github repo and <a href="https://twitter.com/rotkiapp">follow</a> us on Twitter.</li>
  <li>Chat with us and other users of Rotki in <a href="https://discord.gg/aGCxHG7">Discord</a> or in <a href="https://t.me/rotkiportfolio">Telegram</a>.</li>
  <li>Spread the word so that more people get to try and use Rotki and learn how to both manage their finances but also how to protect the privacy of their financial data.</li>
</ul>

</div>

    </div></div>]]>
            </description>
            <link>https://blog.rotki.com/2020/08/13/sustainable-defi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24143042</guid>
            <pubDate>Thu, 13 Aug 2020 13:21:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Tour of Seq's Storage Engine]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24143014">thread link</a>) | @el_duderino
<br/>
August 13, 2020 | https://blog.datalust.co/a-tour-of-seqs-storage-engine/ | <a href="https://web.archive.org/web/*/https://blog.datalust.co/a-tour-of-seqs-storage-engine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    <article>

        

        <section>
            <!--kg-card-begin: html--><section>
    <p>Reading time: 15 minutes</p>
</section><!--kg-card-end: html--><p>This post is the first in a series on Seq’s storage engine. It’s a technical dive meant to share some of the more interesting aspects of its design and implementation.</p><p>Seq is a log server with its own embedded storage engine for log events<a href="https://blog.datalust.co/rust-at-datalust-how-we-integrate-rust-with-csharp/"> written (mostly) in Rust</a>. We call this storage engine <em>Flare</em>. We’ve <a href="https://blog.datalust.co/rust-at-datalust/">written a bit</a> about our experiences with Rust in the past, but we’ve been wanting to dive into the design of Flare itself since we first shipped it in August of 2018.</p><p>To get a sense of what Flare is all about we’ll first introduce its broad design and then explore some of its components. We’ll do this by tracing the ingestion of an event through Seq’s HTTP API through to disk, and then later back from disk via a query, and finally deleting the event entirely. This post is a long and tangential tour of the design and implementation of the database to provide context for deeper dives into specific components in future posts.</p><h2 id="contents">Contents</h2><ul><li><a href="#the-design-of-flare">The design of Flare</a></li><li><a href="#ingesting-events">Ingesting events</a></li><li><a href="#merging-write-optimized-files-into-read-optimized-files">Merging write-optimized files into read-optimized files</a></li><li><a href="#querying-events">Querying events</a></li><li><a href="#deleting-events">Deleting events</a></li></ul><h2 id="the-design-of-flare">The design of Flare</h2><p>Flare is a conceptually small database. It’s fully abstracted from the underlying OS and doesn’t attempt to do any of its own threading, even though it’s designed for concurrent access. That makes it nicely portable (it can actually run entirely in WebAssembly) and embedded in other programming languages. In Seq, we embed Flare in .NET.</p><figure><img src="https://blog.datalust.co/content/images/2020/08/flare-in-seq.png" alt="Flare is a combination of C# and Rust components that are used by Seq" srcset="https://blog.datalust.co/content/images/size/w600/2020/08/flare-in-seq.png 600w, https://blog.datalust.co/content/images/size/w1000/2020/08/flare-in-seq.png 1000w, https://blog.datalust.co/content/images/size/w1600/2020/08/flare-in-seq.png 1600w, https://blog.datalust.co/content/images/size/w2400/2020/08/flare-in-seq.png 2400w" sizes="(min-width: 720px) 720px"></figure><h3 id="choosing-trade-offs">Choosing trade-offs</h3><p>As a database, Flare only has three things to worry about:</p><ul><li>Storing data on disk.</li><li>Removing data from disk.</li><li>Fetching data from disk.</li></ul><p>Doing those things efficiently though, while also guaranteeing ACID properties (that is, atomicity, consistency, isolation, and durability), is actually very tricky! Even lightweight general-purpose embedded databases like SQLite are complex. Flare isn’t a general-purpose database though. To maintain performance and reliability within a manageable level of complexity, Flare takes advantage of some properties of log events in its design. Log events are:</p><ul><li>immutable.</li><li>schema-less.</li><li>about 1Kb in size on average.</li><li>written with recent timestamps.</li><li>deleted with old timestamps.</li></ul><p>We alluded to performance and reliability as constraints on Flare's design above, but there are others we have too:</p><ul><li><strong>Understandability.</strong> We're a small team with a lot of code to maintain. We need Flare to be understandable so we can quickly reconstitute the mental stack needed to work on it.</li><li><strong>Supportability.</strong> Flare is deployed in environments we have no control over. We need it to be as robust as possible and give us plenty of insight into how it's running.</li></ul><p>These properties together have lead to a design where data files can be initially appended to, but are eventually aged into an immutable format. Deletes are filtered copies into new data files.</p><p>There are some trade-offs in Flare’s design:</p><ul><li>the database is tolerant of some historical and future writes, but regular random writes (such as applications logging using <em>really</em> skewed system clocks) have poor performance characteristics.</li><li>keys have to be slowly incrementing, so the only key that makes any sense is a timestamp.</li><li>there are no random deletes, and retention isn’t really a mechanism for quickly reclaiming disk space.</li></ul><h3 id="transactions-and-state">Transactions and state</h3><p>Flare is transactional. It has three different kinds of transactions each with different capabilities for interacting with the state of the database:</p><ul><li><strong>Read transactions</strong>. These give access to the data files and can iterate through their log events. There can be any number of read transactions and they don’t block any other transactions.</li><li><strong>Write transactions</strong>. These allow data files to be created, log events to be appended to them, and for those data files to be marked as read-only. There can only be one write transaction at a time.</li><li><strong>Maintenance transactions</strong>. These allow immutable data files to be created and reshaped. They’re used for long-running background tasks. There can only be one maintenance transaction at a time.</li></ul><p>Flare uses a series of locks and MVCC (multi-version concurrency control) internally to manage its transactions. MVCC is a technique for allowing concurrent access to state by making changes to that state <em>generational</em>. State is accessed by grabbing the current generation, and is updated by creating a new generation that includes any changes. In Rust, we can model MVCC nicely using the standard <code>Arc&lt;T&gt;</code> atomic reference counted smart pointer.</p><p>The locks live at the heart of Flare together with the <em>in-memory state</em> of the database. This in-memory state is a MVCC generational set of all the database’s files and metadata. When a transaction is started it receives a snapshot of the current generation’s set of files to work with. Since transactions only see the generation that was current when they were started they don’t observe any changes made by other transactions.</p><p>As an example, consider the following chain of events:</p><ol><li>A read transaction, <code>read1</code>, is started. It’s based on the current generation <code>1</code>.</li><li>A write transaction, <code>write1</code>, is started. It’s based on the current generation <code>1</code>.</li><li>The write transaction appends some data.</li><li>The write transaction is committed. This moves the current generation to <code>2</code> to include the newly appended data.</li><li>A read transaction, <code>read2</code>, is started. It’s based on the current generation <code>2</code>.</li><li>Data is read from <code>read2</code>. It sees the data appended by <code>write1</code>.</li><li>Data is read from <code>read1</code>. It doesn’t see the data appended by <code>write1</code>.</li></ol><figure><img src="https://blog.datalust.co/content/images/2020/08/flare-transactions.png" alt="Each transaction only sees the state of the database that was current when it was started" srcset="https://blog.datalust.co/content/images/size/w600/2020/08/flare-transactions.png 600w, https://blog.datalust.co/content/images/size/w1000/2020/08/flare-transactions.png 1000w, https://blog.datalust.co/content/images/size/w1600/2020/08/flare-transactions.png 1600w, https://blog.datalust.co/content/images/size/w2400/2020/08/flare-transactions.png 2400w" sizes="(min-width: 720px) 720px"></figure><h3 id="what-s-next">What’s next?</h3><p>Flare is an embedded, transactional collection of data files that’s designed with embedding and streamlined support in mind. With that bit of context, let’s dive a little deeper by following a log event through the engine from ingestion through to querying and deletion.</p><h2 id="ingesting-events">Ingesting events</h2><p>Let’s say we have this log event:</p><pre><code>{
    "@t": "2020-07-29T07:10:16.1729056Z",
    "@mt": "Health check {Method} {TargetUrl} {Outcome} with status code {StatusCode} in {Elapsed:0.000} ms",
    "HealthCheckTitle": "Health Endpoints",
    "Method": "GET",
    "TargetUrl": "myapp/health",
    "Outcome": "succeeded",
    "Elapsed": 124.02390000000001,
    "StatusCode": 200,
    "ContentType": "application/json; charset=utf-8",
    "ContentLength": 84,
    "ProbeId": "aOiAcXYe0Znd",
    "Data": {
        "version": "1.5.314",
        "environment": "Production",
        "checks": {
            "database": {
                "isOk": true
            }
        }
    },
    "ProbedUrl": "myapp/health?__probe=aOiAcXYe0Znd",
    "@r": [
        "124.024"
    ]
}</code></pre><p>The log event first arrives as JSON at Seq’s HTTP ingestion endpoint, which is based on ASP.NET. From there it’s deserialized into a regular .NET object and appended to a write queue for persistence. The queue is flushed by serializing its waiting log events into a normalized JSON format and sending in a batch to Flare to write to disk, then adding them to Seq’s RAM cache. From here everything is Rust.</p><p>When a write needs to be performed in Flare, it is done under <em>the write lock</em> as part of a <em>write transaction</em>. The write lock ensures there’s only ever a single write transaction active at once. A write transaction is capable of creating and appending to the files used to durably persist log events. These files are called <em>ingest buffers</em> (if you have a Seq instance handy, you can find ingest buffers by looking for <code>.tick</code> files in your <code>Stream</code> folder).</p><h3 id="ingest-buffers">Ingest buffers</h3><p>Each ingest buffer is an unordered, append-only list of log events whose timestamps all fall within a fixed 5 minute range. We call these 5 minute ranges <em>ticks</em> (which is where the <code>.tick</code> extension comes from).</p><p>Log events encoded as JSON are written to an ingest buffer compressed using the snappy algorithm. These compressed bytes are staged in an in-memory buffer before reaching the underlying file. We ended up writing an implementation of the snappy framing protocol that uses a 1Kib frame size to keep its space requirements bounded (everything in Flare is designed to work in bounded space, so that it leaves plenty of RAM for the cache). Flare uses headers and trailers to separate encoded log events in all its data files, including ingest buffers, rather than a line or null delimited protocol. The header for each log event contains its timestamp and the length of the encoded payload. The trailer contains a CRC hash of the payload.</p><p>The in-memory buffer may be flushed to disk on-demand. Log events that are flushed to disk aren’t visible to new reads until they’ve been committed though. This ensures that, within the span of time covered by a <code>.tick</code> file, batched writes either succeed or fail atomically, and never leave the file in a corrupted, partially-committed, or ambiguous state. Committing an ingest buffer is done by fully flushing the in-memory buffer to disk, then writing a single <code>0xCC</code> commit byte to the data file and flushing again. The double-flush makes sure <em>all</em> written memory pages have actually been persisted to real storage, which isn’t necessarily guaranteed by a single flush on all filesystems. If the writes made to the data file don’t cross a page boundary then the double flush is avoided as an optimization in favor of a single flush after writing the commit byte.</p><figure><img src="https://blog.datalust.co/content/images/2020/08/flare-ingest-buf-format.png" alt="Ingest buffers are length-prefixed on disk" srcset="https://blog.datalust.co/content/images/size/w600/2020/08/flare-ingest-buf-format.png 600w, https://blog.datalust.co/content/images/size/w1000/2020/08/flare-ingest-buf-format.png 1000w, https://blog.datalust.co/content/images/size/w1600/2020/08/flare-ingest-buf-format.png 1600w, https://blog.datalust.co/content/images/size/w2400/2020/08/flare-ingest-buf-format.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>Once the batch pulled from the write queue containing our event has been written and committed, the database advances its in-memory state to a new generation containing the file offset to the new commit byte. Then the write transaction is completed (usually to be immediately followed by a new one). Other transactions started from this point will be able to see the new batch of events.</p><h3 id="what-s-next-1">What’s next?</h3><p>So that’s how a log event sent to Seq’s HTTP API is persisted by Flare on disk. Before we look at how the event can be queried back from disk let’s give it some time to age into a different format. Ingest buffers are optimized for writes but are very slow to read in order, because they need to be sorted first.</p><h2 id="merging-write-optimized-files-into-read-optimized-files">Merging write-optimized files into read-optimized files</h2><p>Once an ingest buffer has been left …</p></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.datalust.co/a-tour-of-seqs-storage-engine/">https://blog.datalust.co/a-tour-of-seqs-storage-engine/</a></em></p>]]>
            </description>
            <link>https://blog.datalust.co/a-tour-of-seqs-storage-engine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24143014</guid>
            <pubDate>Thu, 13 Aug 2020 13:17:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[YouTube's persistent flaws make it a hard app to love]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24142790">thread link</a>) | @whalabi
<br/>
August 13, 2020 | https://unlikekinds.com/article/youtubes-persistent-flaws-make-it-a-hard-app-to-love | <a href="https://web.archive.org/web/*/https://unlikekinds.com/article/youtubes-persistent-flaws-make-it-a-hard-app-to-love">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <div>
            <div>
      <div>
  <h2 id="the-ludicrousness-of-being-forced-to-watch-youtube-in-480p-on-a-4k-tv">The ludicrousness of being forced to watch YouTube in 480p on a 4K TV</h2>

<p>To watch YouTube videos from my phone, which is where I find them, on my TV, which is where I want to watch them, I’ve long since thrown up my hands and given up using the Cast function of the app. Every time I do, the video shows in 480p, even though I have a fiber connection on which YouTube never buffers. If I change the resolution to 1080p, YouTube stubbornly continues to play the video in a resolution that belongs in the 90s. The issue is <a href="https://support.google.com/chromecast/thread/2308994?hl=en" rel="nofollow noopener" target="_blank" data-vars-outbound-link="https://support.google.com/chromecast/thread/2308994?hl=en">widespread</a>, and pre-dates YouTube’s limitations put in place during the pandemic. My TV is an Android TV, made for Google integration with a built-in YouTube app, and my phone is a Pixel phone. Partially chosen with the hope that they’d work well together.</p>

<p>My connection and TV are perfectly capable of playing the video in 1080p, as I learnt when I discovered a clumsy, irritating workaround: adding videos to my Watch Later list on my phone, then opening the YouTube app on my TV, and fumbling through its clumsy interface with a clumsy remote to pick them up again directly on the TV. Plays in 1080p just fine, no buffering.</p>

<figure><img alt="Thousands of YouTube users frustrated with a long-lived bug" width="840" height="593" src="https://i.imgur.com/zD5nKkS.png"><figcaption>Thousands of YouTube users frustrated with a long-lived bug</figcaption></figure>

<h2 id="have-some-captions-with-that">Have some captions with that</h2>

<p>Even when I’ve given in and kept casting blurry videos, a bizarre issue crops up. After watching for a lengthy period of time, maybe an hour or two, YouTube will decide to pop up English captions over an English video while watching on my English account. I’ll shake my head and switch them off; thankfully at least that setting works even if the quality setting doesn’t. Problem is, when the next video in the queue starts playing, the captions switch themselves back on, for every video thereafter. It’s only rectified by disconnecting my phone from my TV, which loses my queued videos, and starting again. This has been happening for many users, and shockingly, <a href="https://support.google.com/youtube/thread/38916902?hl=en" rel="nofollow noopener" target="_blank" data-vars-outbound-link="https://support.google.com/youtube/thread/38916902?hl=en">since 2013</a>.</p>

<p>I can only imagine there’s some kind of complicated machine learning going on here - after all YouTube seems to apply fuzzy logic when it decides to turn captions on or off by itself - the captions come on for some non-English videos but not others. It works a lot of the time and seems fairly smart, but not smart enough: they come on only some of the time I watch a K-pop music video, even by the same artist, for example. Every time this happens, I turn off the captions and rewind the video, providing plenty of data, which I’m sure Google is dutifully recording, about my captioning habits, data it could be using to decide whether to override my choices and turn them back on incessantly.</p>

<p>In a pre-ML world, you might code the captions to come on for non-English videos on an English account, perhaps making a different decision based on music videos, and provide a setting, so the user can decide. This would perfectly suit my needs. The behaviour would be predictable, and in my control. This is a problem with the state of ML these days: the decision is completely opaque, inevitably flawed, and non-overridable.</p>

<h2 id="if-you-cant-guess-just-let-me-choose">If you can’t guess just let me choose</h2>

<p>Playing videos directly on my phone is just as frustrating. Much of the time (but not all of the time) I choose something to watch, it’s 480p on my fiber connection which never buffers. Sometimes the video plays in 1080p, but whether it does or not is completely unpredictable. Now everytime I play a video I immediately open the quality settings and change it over to 1080p and rewind, if it isn’t already. It appears to be happening to <a href="https://support.google.com/youtube/thread/14927224?hl=en" rel="nofollow noopener" target="_blank" data-vars-outbound-link="https://support.google.com/youtube/thread/14927224?hl=en">plenty</a> of <a href="https://www.reddit.com/r/youtube/comments/ae5utz/auto_quality_setting_keeps_defaulting_to_the/" rel="nofollow noopener" target="_blank" data-vars-outbound-link="https://www.reddit.com/r/youtube/comments/ae5utz/auto_quality_setting_keeps_defaulting_to_the/">users</a>.</p>

<p>If this is the result of YouTube attempting to intelligently guess a resolution that won’t buffer, it’s failing miserably. Were they to provide an option to always stream at a minimum 1080p, users’ experience would be much better - they could even choose auto if they want to let YouTube decide for them. Instead YouTube makes a decision for me with an invisible process I have no say in.</p>

<figure><img alt="YouTube’s widely reviled video suggestions" width="775" height="530" src="https://i.imgur.com/WpPKYs4.jpg"><figcaption>YouTube’s widely reviled video suggestions</figcaption></figure>

<p>Users often take a back seat on YouTube. One of the issues in YouTube’s support forums with the <a href="https://support.google.com/youtube/thread/11285006?hl=en" rel="nofollow noopener" target="_blank" data-vars-outbound-link="https://support.google.com/youtube/thread/11285006?hl=en">most upvotes</a> concerns the recommended video thumbnails which can overlap the last <a href="https://support.google.com/youtube/answer/6388789?hl=en" rel="nofollow noopener" target="_blank" data-vars-outbound-link="https://support.google.com/youtube/answer/6388789?hl=en">5-20 seconds</a> of the video you chose to watch, causing what is often a significant interruption, or in the case of the support thread above, a critical penalty save in a soccer match. Some argue that it’s up to the uploader to add these or not. It’s up to YouTube whether they appear over the last 1 second or 20, or appear under a video rather in massive intrusive thumbnails over the video. I pay for YouTube, but I have no control over these. If it’s just being provided in the user’s interest, why not give us the option to switch them off?</p>

<h2 id="play-music-or-youtube-music">Play Music or YouTube Music</h2>

<p>Google Play Music is shutting down in favor of YouTube Music, both are services I’ve used for years and pay for. Play Music is different in that it stores your own uploaded music, from back when people had such things. As it’s shutting down, these uploads are being transferred across to YouTube Music. It turns out you <a href="https://support.google.com/youtubemusic/thread/45163028?hl=en" rel="nofollow noopener" target="_blank" data-vars-outbound-link="https://support.google.com/youtubemusic/thread/45163028?hl=en">can’t transfer your uploaded music to a “Brand account”</a> - I’m not a brand, I have an account which doesn’t use my real name because I prefer to remain anonymous amongst, well, YouTubers. This was made possible when Google <a href="https://www.theguardian.com/technology/2014/jul/16/youtube-trolls-google-real-name-commenter-policy" rel="nofollow noopener" target="_blank" data-vars-outbound-link="https://www.theguardian.com/technology/2014/jul/16/youtube-trolls-google-real-name-commenter-policy">backtracked</a> after the disastrous ruckus that began when they tried to enforce a real-name policy.</p>

<p>But it also meant that users ended up with 2 YouTube accounts, unwittingly, one with their Google-set real name, and a so-called brand account. A problem arose. In YouTube Music, I have one account with all my music history, likes, favorites, and recommendations, and another with my substantial uploaded music library. Which means I can’t benefit from recommendations based on my history, without rebuilding it all over again with my real name account (which I’d rather not do, in any case, but have no power over.)</p>

<p>In the <a href="https://support.google.com/youtubemusic/thread/45163028?hl=en" rel="nofollow noopener" target="_blank" data-vars-outbound-link="https://support.google.com/youtubemusic/thread/45163028?hl=en">YouTube support thread</a> announcing this, Hazel from TeamYouTube happily says “If you have any more questions, let us know in the comments below!”, then received a critical comment, and promptly locked the thread.</p>

<h2 id="let-users-have-some-control-in-the-apps-they-use">Let users have some control in the apps they use</h2>

<p>YouTube, like many big tech companies in the ML age, are using algorithms to govern the experience of their billions of users with inner workings that are invisible to their users, frequently work against their interest, and are unable to be overridden. Worse, whether it’s a bug that’s been around since 2013, a smart AI which isn’t so smart, or a crummy user experience decision, users aren’t being heard or their choices respected.</p>

</div>
</div>
    </div>

          

  </div></div>]]>
            </description>
            <link>https://unlikekinds.com/article/youtubes-persistent-flaws-make-it-a-hard-app-to-love</link>
            <guid isPermaLink="false">hacker-news-small-sites-24142790</guid>
            <pubDate>Thu, 13 Aug 2020 12:51:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Social robots are here to manage our emotions]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24142617">thread link</a>) | @donohoe
<br/>
August 13, 2020 | https://restofworld.org/2020/social-robots-are-here-to-hug-you/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/social-robots-are-here-to-hug-you/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p><span>S</span>arah, an eight-year-old pneumonia patient at <a href="http://www.wigmoreclinic.am/">Wigmore Clinic</a>, had barely eaten for two days. She was scared and depressed; none of the medical staff’s pleas that she try a bite of salad or meat had worked. Then Robin entered her room. Robin made eye contact with Sarah, guessing her age and gender. Robin said hello. Sarah said hello back. They talked about their favorite colors and animals and played “I spy.”&nbsp;</p>



<p>After 20 minutes, Robin told her, “I need to recharge my battery.”&nbsp;</p>



<p>“No, no. Don’t go,” Sarah said. “I want to play more.”&nbsp;</p>



<p>“I will come back if you recharge yourself too,” Robin said.&nbsp;</p>



<p>Sarah picked up her plate and started to eat. Robin, a nearly 4-foot-tall robot, smiled and wheeled away.</p>



<p>In the hallway, Sarah’s parents approached <a href="https://www.linkedin.com/in/karenkhachikyan/">Karén Khachikyan</a>, CEO and co-founder of Expper Technologies, to give him a hug. The robot’s intervention had worked. “It was a very emotional and inspiring moment for us,” Khachikyan said. “We saw how important peer-to-peer connection and interactions are.”&nbsp;</p>



<p><a href="https://www.forbes.com/sites/jeffkart/2020/06/17/robin-the-robot-comforts-kids-in-hospitals-can-help-with-covid-19/">Robin</a>, an <a href="https://meaww.com/amp/robin-friendly-robot-companion-children-expper-tech-la-hospital-khachikyan-armenian-start-up">emotional-support robot</a> for hospitalized children designed by the Armenian startup <a href="https://www.expper.tech/">Expper Technologies</a>, launched earlier this year in four hospitals in Armenia and <a href="https://www.uclahealth.org/welcome-robin-the-ai-robot">expanded</a> to <a href="https://www.abckidsdentalla.com/">ABC Kids Dental Group</a> in Los Angeles and <a href="https://www.uclahealth.org/mattel/">UCLA Mattel Children’s Hospital</a> <a href="https://www.uclahealth.org/body.cfm?id=1397&amp;action=detail&amp;ref=7280&amp;fr=true">in July</a>. Robin can speak English and Armenian, though the team is considering adding Spanish to better serve patients in California. The robot is gender-neutral, roughly the size of an 8-year-old child, and ergonomically designed to be huggable. The robot’s face is an 11-inch display screen that can show various emotions through facial expressions as well as play cartoons, animations, or interactive games.&nbsp;</p>



<p>When he was a university student, then-26-year-old Khachikyan designed <a href="https://www.f6s.com/karenkhachikyan">Charlie</a>, an educational robot that was used by more than 300 children in Armenia. He theorized that, if children were emotionally connected to Charlie, they would be more motivated to learn. “We were creating a friend,” he said.</p>



<p>Now Khachikyan’s goal is to change the way that kids experience hospitalization — particularly, to ameliorate their feelings of loneliness and fear. Robin the robot automates emotional labor in a medical setting, not with the aim of replacing people but of augmenting them, filling in the gaps in emotional support. Why settle for a doctor, nurse, and occupational therapist when you could have all three — plus a robot to keep your fears at bay?&nbsp;</p>



<p>Hospital workers are often overwhelmed. <a href="https://www.researchgate.net/publication/326278803_The_emotional_labor_automation_model_Towards_the_unmanaged_heart">Ekaterina Pogrebtsova</a>, a psychology researcher at the University of Guelph in Ontario, focuses on the cognitive automation processes of emotional labor in humans. She said nursing professionals often suffer from burnout because they perform emotionally intensive tasks on a daily basis. While there are techniques for lessening the strain of this work, they take time to perfect. Pogrebtsova said AI technologies like Robin can “supplement a lot of the tedious, laborious work that employees have had to do for centuries now.”&nbsp;</p>



<p>There are some delightful (and odd) examples of robots that have tried to fulfill emotional needs in a medical setting. Many are furry and responsive. <a href="https://www.sproutel.com/products.html">My Special Aflac Duck</a> is a white duck that <a href="https://www.youtube.com/watch?v=4gbzcDJKxlI">comforts</a> children diagnosed with cancer. Kids can tap seven different cards to the duck’s chest, each of which prompts the duck to express the emotion displayed on the card. (If you put your finger in the duck’s mouth, it will pretend to eat.) PARO, a robotic <a href="https://vancouversun.com/news/robotic-seal-provides-emotional-support-for-alzheimers-patients-at-vancouver-general-hospital">baby harp seal</a>, is covered with tactile sensors on its body and whiskers. PARO is able to recognize its own name and uses AI to repeat behaviors that, in the past, have led to its being petted. There are over 6,000 PARO units in use worldwide, mostly in patient-care settings.&nbsp;</p>



<p>Other examples are even more surreal. <a href="https://www.youtube.com/watch?v=Ugv2LqlepGw">Qoobo</a>, a <a href="https://www.youtube.com/watch?v=-2TbYYXajNY">headless, tadpole-like cushion</a> developed by <a href="https://www.ux-xu.com/products-en">Yukai Engineering</a>, is designed to soothe. A robotic tail wags vigorously when the cushion is petted quickly, at a lackadaisical pace when petted slowly, and intermittently when left by itself. When the product launched in Japan in December 2018, the intended audience was women in their 20s and 30s who live alone and want a pet. Since then, Qoobo has found a market in nursing homes and among patients who have dementia or Alzheimer’s; 15,000 units have been sold in Japan and some 300 in the U.S. A smaller, more portable version, <a href="https://camp-fire.jp/projects/view/228513">Petit Qoobo</a>, is now available for preorder. Petit Qoobo even has a subtle heartbeat.</p>


    <figure>
      <div>
				<ul>
					<li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/08/qoobo_016-40x27.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/08/qoobo_016-768x432.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/08/qoobo_016-400x267.png 400w, https://restofworld.org/wp-content/uploads/2020/08/qoobo_016-600x400.png 600w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="Qoobo, a headless, tadpole-like cushion.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder">Photo courtesy of Qoobo</span>
			</figcaption>
		</figure></li><li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/08/nursing-home-original-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/08/nursing-home-original-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/08/nursing-home-original-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2020/08/nursing-home-original-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2020/08/nursing-home-original-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/08/nursing-home-original-2800x1867.jpg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="PARO, the seal robot from Japan.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder">Photo courtesy of AIST, Japan</span>
			</figcaption>
		</figure></li>
				</ul>
			</div>
      
    </figure>


<p>When Khachikyan and his team were researching the existing landscape of emotional-support robots, they noticed that many models were created as toys or tools of distraction. “There is a lack of communication,” he said. “They are not social.”&nbsp;</p>



<p>Khachikyan’s Expper Technologies focused on creating a robotic peer who lives in the hospital and behaves like a child. “When kids see Robin, it’s like they see another kid,” Khachikyan said. Many of the children put their arms around the robot for a hug. In preliminary tests, some children grew so affectionate toward Robin that they asked if they could get sick again, in order to see it again.&nbsp;</p>



<p>Rather than relying on preprogrammed dialogues providing generic answers to particular questions, the team at Expper trained Robin by studying the conversational patterns of two Armenian psychologists and an occupational therapist. The engineers then used behavior cloning — a machine-learning technique — to teach Robin how to mimic the professionals. The model learns the style of a psychologist’s speech and copies the way they interact with patients.&nbsp;</p>



<p>Robin’s front-facing camera is equipped with facial-recognition technology that analyzes a child’s facial expressions, mood, age, gender, and conversation in order to build a holistic understanding of a child’s emotional state. Based on this analysis, Robin can suggest games or ask questions, in order to improve a child’s mood. An embedded memory model allows Robin to remember particular details about a patient and build follow-up conversations based on that memory.&nbsp;</p>



<p>Mineh Badmagharian, an occupational therapist on the Expper team, described the algorithm directing Robin as a “two-player positive-sum game.” Robin and the child are working together. “The kid wants to receive positive emotions, and Robin’s objective is to maximize that,” she told <em>Rest of World. </em></p>



<p>Last year, Khachikyan and his team raised $200,000 in initial funding from <a href="https://www.smartgate.vc/portfolio">SmartGateVC</a>, <a href="https://hiveventures.co/">HIVE Ventures</a>, and angel investors. They are currently in seed funding to advance the technology and begin mass-producing Robins. The robots are manufactured in Armenia, though Khachikyan said they aim to move production to China. With the success of Robin among adolescent patients, Expper is considering expanding into the field of elder care.</p>



<p>We tend to hear about robots and AI working in less wholesome, less emotionally involved contexts; facial recognition, surveillance, self-driving cars, and customer-service chatbots can have an eldritch <a href="https://www.forbes.com/sites/cognitiveworld/2020/06/15/perfectly-imperfect-coping-with-the-flaws-of-artificial-intelligence-ai/">underbelly</a>. Robin and a generation of emotional-support robots show that AI can replace human <a href="https://howwegettonext.com/let-robots-handle-your-emotional-burnout-at-work-e09babbe81e8">emotional labor</a>, narrowing <a href="https://knowledge.insead.edu/blog/insead-blog/can-emotion-be-automated-11941">emotional literacy gaps</a> between robots and humans. “I believe that people need people,” Khachikyan said. “We don’t want to replace anyone with Robin. Our vision is to create a teammate.”</p>
		</div></div>]]>
            </description>
            <link>https://restofworld.org/2020/social-robots-are-here-to-hug-you/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24142617</guid>
            <pubDate>Thu, 13 Aug 2020 12:23:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Coffee chat: Easy way to install Kubernetes Apps - arkade (ark)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24142603">thread link</a>) | @alexellisuk
<br/>
August 13, 2020 | https://sachcode.com/tech/coffee-chat-easy-way-install-kubernetes-apps/ | <a href="https://web.archive.org/web/*/https://sachcode.com/tech/coffee-chat-easy-way-install-kubernetes-apps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>🚀 👋  Want to get through those repetitive and boring tasks in DevOps? </p>
<p>How about, setting up a TLS-enabled Docker registry? 🐳 </p>
<p>I’m a big fan of open source CLI tools that reduce repetition and efforts. </p>
<p>This one is a quick chat about <code>arkade</code> which provides a simple CLI with strongly-typed flags to install Helm charts and Kubernetes apps to your cluster in a single command.</p>
<div data-language="js"><pre><code>$ arkade install ingress<span>-</span>nginx <span>--</span>help

Install ingress<span>-</span>nginx<span>.</span> This app can be installed <span>with</span> Host networking <span>for</span>
cases where an external <span>LB</span> is not available<span>.</span> please see the <span>--</span>host<span>-</span>mode
flag and the ingress<span>-</span>nginx docs <span>for</span> more info</code></pre></div>
<p><span>
      <span></span>
  <img alt="arkade cli k8s" title="arkade cli k8s" src="https://sachcode.com/static/18765390c945fc124c79694c4a9d3e6b/302a4/arkade-cli-k8s.png" srcset="https://sachcode.com/static/18765390c945fc124c79694c4a9d3e6b/5a46d/arkade-cli-k8s.png 300w,
https://sachcode.com/static/18765390c945fc124c79694c4a9d3e6b/0a47e/arkade-cli-k8s.png 600w,
https://sachcode.com/static/18765390c945fc124c79694c4a9d3e6b/302a4/arkade-cli-k8s.png 1080w" sizes="(max-width: 1080px) 100vw, 1080px" loading="lazy">
    </span> </p>
<h4 id="heres-how-you-can-get-a-self-hosted-docker-registry-with-tls-and-authentication-in-just-5-commands-on-an-empty-cluster"><a href="#heres-how-you-can-get-a-self-hosted-docker-registry-with-tls-and-authentication-in-just-5-commands-on-an-empty-cluster" aria-label="heres how you can get a self hosted docker registry with tls and authentication in just 5 commands on an empty cluster permalink"></a>Here’s how you can get a self-hosted Docker registry with TLS and authentication in just 5 commands on an empty cluster:</h4>
<div data-language="js"><pre><code>arkade install ingress<span>-</span>nginx
arkade install cert<span>-</span>manager
arkade install docker<span>-</span>registry
arkade install docker<span>-</span>registry<span>-</span>ingress \
  <span>--</span>email web@example<span>.</span>com \
  <span>--</span>domain reg<span>.</span>example<span>.</span>com</code></pre></div>
<h4 id="the-same-for-openfaas-would-look-like-this"><a href="#the-same-for-openfaas-would-look-like-this" aria-label="the same for openfaas would look like this permalink"></a>The same for OpenFaaS would look like this:</h4>
<div data-language="js"><pre><code>arkade install ingress<span>-</span>nginx
arkade install cert<span>-</span>manager
arkade install openfaas
arkade install openfaas<span>-</span>ingress \
  <span>--</span>email web@example<span>.</span>com \
  <span>--</span>domain reg<span>.</span>example<span>.</span>com</code></pre></div>
<p>📓 🚀 💡</p>
<p>Repo link: <a href="https://github.com/alexellis/arkade">https://github.com/alexellis/arkade</a></p>
<p>📝 Blog:  <a href="https://itnext.io/kubernetes-apps-the-easy-way-f06d9e5cad3c">arkade by example — Kubernetes apps, the easy way 😎 - Alex Ellis</a></p></div></div>]]>
            </description>
            <link>https://sachcode.com/tech/coffee-chat-easy-way-install-kubernetes-apps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24142603</guid>
            <pubDate>Thu, 13 Aug 2020 12:22:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Trying Out Vim]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24142515">thread link</a>) | @Sandeepg33k
<br/>
August 13, 2020 | https://blog.nawaz.info/trying-out-vim-ckdriafbe00k0gws1b5hd5q5o | <a href="https://web.archive.org/web/*/https://blog.nawaz.info/trying-out-vim-ckdriafbe00k0gws1b5hd5q5o">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1597244649420/jX9JzFN5o.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div itemprop="text"><p><a target="_blank" rel="noopener" href="https://www.vim.org/">Vim</a> (<strong>V</strong>i <strong>IM</strong>proved) is a highly configurable text editor built to make creating and changing any kind of text very efficiently. It is included as "vi" with most UNIX systems and with Apple OS X.I attempted to learn Vim quite a few times before but could not cope up with it. But recently I thought I should at least know very basic usage of Vim. So I started learning the absolute basics. Here I am putting all the basic commands and usage of Vim for any absolute beginner like me. This can be helpful to get started with Vim I think. But there is a lot of things to learn about this handy tool that will take much time and practice. One will get proficient in using Vim only by using it consistently.</p>
<p>Vim has two basic modes:</p>
<ol>
<li>One is <code>INSERT</code> mode, in which you write text as if in a normal text editor.</li>
<li>Another is <code>NORMAL</code> mode which provides you efficient ways to navigate and manipulate text. This is also called <code>Command</code> mode cause we can do various vim commands on this mode.</li>
</ol>
<p>To change between modes, use <code>ESC</code> for normal mode and <code>i</code> for insert mode.</p>
<h2 id="vim-commands">VIM Commands</h2>
<table>
<thead>
<tr>
<td>Command</td><td>Action</td></tr>
</thead>
<tbody>
<tr>
<td>:e <em>filename</em></td><td>Open <em>filename</em> for editon</td></tr>
<tr>
<td>:w</td><td>Save file</td></tr>
<tr>
<td>:q</td><td>Exit vim</td></tr>
<tr>
<td>:q!</td><td>Quit without saving</td></tr>
<tr>
<td>:x</td><td>Save and Exit</td></tr>
<tr>
<td>:sav <em>name</em></td><td>Save current file as <em>name</em></td></tr>
<tr>
<td>.</td><td>Repeat last change made in <code>NORMAL</code> mode</td></tr>
</tbody>
</table>
<hr>
<h2 id="cursor-movements">Cursor Movements</h2>
<ul>
<li><code>h</code> to move cursor left (←)</li>
<li><code>l</code> to move cursor right (→)</li>
<li><code>k</code> to move cursor up (↑)</li>
<li><code>j</code> to move cursor down (↓)</li>
<li><code>b</code> moves to the beginning of the word</li>
<li><code>e</code> moves to the end of the word</li>
<li><code>w</code> moves to the beginning of the next word</li>
</ul>
<h2 id="number-based-movements">Number Based Movements</h2>
<p>Using a <code>number</code> before each command can execute that command that many times. e.g <code>3w</code> will move to the 3rd next word.</p>
<h2 id="insert-text-repeatedly">Insert Text Repeatedly</h2>
<p>To insert the same text multiple times use <code>&lt;number&gt;i&lt;text&gt;esc</code>. e.g <code>3&lt;i&gt;go&lt;esc&gt;</code> will write <code>gogogo</code>.</p>
<h2 id="find-a-character">Find a Character</h2>
<p>To find and move to the next (or previous) occurrence of a character, use <code>f</code> and <code>F</code>, e.g. <code>fo</code> finds next 'o'. You can combine f with a number. e.g. you can find 3rd occurrence of 'q' with <code>3fq</code>.</p>
<h2 id="go-to-matching-parenthesis">Go to Matching Parenthesis</h2>
<p>In text that is structured with parentheses or brackets, <code>(</code> or <code>{</code> or <code>[</code>, use <code>%</code> to jump to the matching parenthesis or bracket.</p>
<h2 id="start-end-of-line">Start/End of Line</h2>
<p>To reach the beginning of a line, use <code>0</code>. For the end of line use <code>$</code>.</p>
<h2 id="find-word-under-cursor">Find Word Under Cursor</h2>
<p>Find the next occurrence of the word under the cursor with <code>*</code>, and the previous with <code>#</code>.</p>
<h2 id="go-to-line">Go to Line</h2>
<p><code>gg</code> takes you to the beginning of the file; <code>G</code> to the end. To jump directly to a specific line, give its line number along with <code>G</code>. e.g <code>5G</code> will take you to the fifth line of the file.</p>
<h2 id="search-for-text">Search for Text</h2>
<p>Searching text is a vital part of any text editor. In Vim, press <code>/</code>, and give the text to search for. The search can be repeated for next and previous occurrences with <code>n</code> and <code>N</code> respectively. For advanced use cases, it's possible to use regexps that help to find the text of a particular form.</p>
<h2 id="insert-new-line">Insert New Line</h2>
<p>To insert text into a new line <strong>after</strong> the current line use <code>o</code> and to insert a new line <strong>before</strong> the current line use <code>O</code>.</p>
<p>After a new line is created, the editor is set to <code>insert</code> mode.</p>
<h2 id="removing-a-character">Removing a Character</h2>
<p><code>x</code> and <code>X</code> delete the character under the cursor and to the left of the cursor, respectively.</p>
<p>Also adding a <code>number</code> before <code>x</code> of <code>X</code> can perform the action that many times. e.g <code>5x</code> will remove the <strong>next</strong> five characters <strong>including</strong> the character under the cursor and <code>5X</code> will remove the <strong>previous</strong> five characters <strong>excluding</strong> the character under the cursor.</p>
<h2 id="replace-a-character">Replace a Character</h2>
<p>User <code>r</code> to replace only one character under the cursor.</p>
<h2 id="deleting">Deleting</h2>
<p><code>d</code> is the delete command. It can be combined it with movements, e.g. <code>dw</code> deletes the characters on the right side of the cursor up to the beginning of the next word. <code>de</code> deletes all the characters of the word on the right side of the cursor <strong>including</strong> the character under cursor. <code>db</code> will delete the previous word if the cursor is under the first letter of a word or else it will delete the characters left to the cursor upto the beginning of the word.</p>
<p>It also <strong>copies</strong> the content, so that you can <strong>paste</strong> it with <code>p</code> to another location.</p>
<p><code>dd</code> will delete the whole line.</p>
<h2 id="repeat-command">Repeat Command</h2>
<p>To repeat the previous command, just use <code>.</code> (period).</p>
<h2 id="replace-mode">Replace Mode</h2>
<p>Use <code>R</code> to enter <code>REPLACE</code> mode. In this mode characters under the cursor can be replaced.</p>
<h2 id="visual-mode">Visual Mode</h2>
<p>Use <code>v</code> to enter the <code>VISUAL</code> mode and <code>V</code> to enter <code>VISUAL LINE</code> mode. In this mode the text can be selected by the movement keys before deciding what to do with it.</p>
<p>Selected text can be <strong>deleted/cut</strong> using <code>d</code> or <strong>copied</strong> using <code>y</code>. It can be <strong>pasted</strong> after the cursor using <code>p</code> or before the cursor using <code>P</code>.
&lt;/esc&gt;&lt;/i&gt;&lt;/text&gt;&lt;/number&gt;</p>
</div></div></section></div></div>]]>
            </description>
            <link>https://blog.nawaz.info/trying-out-vim-ckdriafbe00k0gws1b5hd5q5o</link>
            <guid isPermaLink="false">hacker-news-small-sites-24142515</guid>
            <pubDate>Thu, 13 Aug 2020 12:11:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Significant JavaScript projects from 2006 to 2020]]>
            </title>
            <description>
<![CDATA[
Score 108 | Comments 57 (<a href="https://news.ycombinator.com/item?id=24142462">thread link</a>) | @michaelrambeau
<br/>
August 13, 2020 | https://bestofjs.org/timeline | <a href="https://web.archive.org/web/*/https://bestofjs.org/timeline">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://bestofjs.org/timeline</link>
            <guid isPermaLink="false">hacker-news-small-sites-24142462</guid>
            <pubDate>Thu, 13 Aug 2020 12:04:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Tokenize Japanese in Python]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24142172">thread link</a>) | @polm23
<br/>
August 13, 2020 | https://www.dampfkraft.com/nlp/how-to-tokenize-japanese.html | <a href="https://web.archive.org/web/*/https://www.dampfkraft.com/nlp/how-to-tokenize-japanese.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Over the past several years there's been a welcome trend in NLP projects to be
broadly multi-lingual. However, even when many languages are supported, there's
a few that tend to be left out. One of these is Japanese. Japanese is written
without spaces, and deciding where one word ends and another begins is not
trivial. While highly accurate tokenizers are available, they can be hard to
use, and English documentation is scarce. This is a short guide to tokenizing
Japanese in Python that should be enough to get you started adding Japanese
support to your application.</p>
<figure><a href="https://www.dampfkraft.com/by-id/23543c9a/fugashi-sample.jpg"><img src="https://www.dampfkraft.com/by-id/23543c9a/img/fugashi-sample.jpg.l.jpg"></a><figcaption><span>Photo by <a href="https://unsplash.com/@skrowze?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Alexandre .L</a> on <a href="https://unsplash.com/s/photos/tokyo-tower?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></span>
</figcaption></figure>
<h2 id="getting-ready"> Getting Ready</h2>
<p>First, you'll need to install a tokenizer and a dictionary. For this tutorial
we'll use <a href="https://github.com/polm/fugashi">fugashi</a> with <a href="https://github.com/polm/unidic-lite">unidic-lite</a>, both projects I maintain. You can
install them like this:</p>
<pre><code>pip install fugashi[unidic-lite]
</code></pre>
<p>Fugashi comes with a script so you can test it out at the command line. Type in
some Japanese and the output will have one word per line, along with other
information like part of speech.</p>
<pre><code>&gt; fugashi
麩菓子は、麩を主材料とした日本の菓子。
麩      フ      フ      麩      名詞-普通名詞-一般
菓子    カシ    カシ    菓子    名詞-普通名詞-一般
は      ワ      ハ      は      助詞-係助詞
、                      、      補助記号-読点
麩      フ      フ      麩      名詞-普通名詞-一般
を      オ      ヲ      を      助詞-格助詞
主材    シュザイ        シュザイ        主材    名詞-普通名詞-一般
料      リョー  リョウ  料      接尾辞-名詞的-一般
と      ト      ト      と      助詞-格助詞
し      シ      スル    為る    動詞-非自立可能 サ行変格        連用形-一般
た      タ      タ      た      助動詞  助動詞-タ       連体形-一般
日本    ニッポン        ニッポン        日本    名詞-固有名詞-地名-国
の      ノ      ノ      の      助詞-格助詞
菓子    カシ    カシ    菓子    名詞-普通名詞-一般
。                      。      補助記号-句点
EOS
</code></pre>
<p>The <code>EOS</code> stands for "end of sentence", though fugashi is not actually
performing sentence tokenization; in this case it just marks the end of the
input.</p>
<h2 id="sample-code"> Sample Code</h2>
<p>Now we're ready to get started with converting plain Japanese text into a list
of words in Python.</p>
<pre><code>import fugashi

# This is our sample text.
# "Fugashi" is a Japanese snack primarily made of gluten.
text = "麩菓子は、麩を主材料とした日本の菓子。"

# The Tagger object holds state about the dictionary. 
tagger = fugashi.Tagger()

words = [word.surface for word in tagger(text)]
print(*words)
# =&gt; 麩 菓子 は 、 麩 を 主材 料 と し た 日本 の 菓子 。
</code></pre>
<p>This prints the original sentence with spaces inserted between words. In many
cases, that's all you need, but fugashi provides a lot of other information,
such as part of speech, lemmas, broad etymological category, pronunciation, and
more. This information all comes from <a href="https://unidic.ninjal.ac.jp/">UniDic</a>, a dictionary provided by the
<a href="https://www.ninjal.ac.jp/">National Institute for Japanese Language and Linguistics</a> (NINJAL).</p>
<p>fugashi is a wrapper for <a href="https://taku910.github.io/mecab/">MeCab</a>, a C++ Japanese tokenizer. MeCab is doing
all the hard work here, but fugashi wraps it to make it more Pythonic, easier
to install, and to clarify some common error cases.</p>
<p>You may wonder why part of speech and other information is included by default.
In the classical NLP pipeline for languages like English, tokenization is a
separate step before part of speech tagging. In Japanese, however, knowing part
of speech is important in getting tokenization right, so they're conventionally
solved as a joint task. This is why Japanese tokenizers are often referred to
as "morphological analyzers" (形態素解析器).</p>
<h2 id="notes-on-japanese-tokenization"> Notes on Japanese Tokenization</h2>
<p>There are several things about Japanese tokenization that may be surprising if
you're used to languages like English.</p>
<h3 id="lemmas-may-not-resemble-the-words-in-the-text-at-all"> Lemmas May Not Resemble the Words in the Text at All</h3>
<p>Here's how you get <a href="https://en.wikipedia.org/wiki/Lemma_(morphology)">lemma</a> information with fugashi:</p>
<pre><code>import fugashi
tagger = fugashi.Tagger()
text = "麩を用いた菓子は江戸時代からすでに存在していた。"

print("input:", text)
for word in tagger(text):
    # feature is a named tuple holding all the Unidic info
    print(word.surface, word.feature.lemma, sep="\t")
</code></pre>
<p>And here's the output of the script:</p>
<pre><code>input: 麩を用いた菓子は江戸時代からすでに存在していた。
麩      麩
を      を
用い    用いる
た      た
菓子    菓子
は      は
江戸    エド
時代    時代
から    から
すでに  既に
存在    存在
し      為る
て      て
い      居る
た      た
。      。
</code></pre>
<p>You can see that 用い has 用いる as a lemma, and that し has 為る and い has
居る, handling both inflection and orthographic variation. すでに is not
inflected, but the lemma uses the kanji form 既に.</p>
<p>These lemmas come from UniDic, which by convention uses the "dictionary form"
of a word for lemmas. This is typically in kanji even if the word isn't usually
written in kanji because the kanji form is considered less ambiguous. For
example, この ("this [thing]") has 此の as a lemma, even though normal modern
writing would never use that form. This is also true of 為る in the above
example.</p>
<p>This can be surprising if you aren't familiar with Japanese, but it's not a
problem. It is worth keeping in mind if your application ever shows lemmas to
your user for any reason, though, as it may not be in a form they expect.</p>
<p>Another thing to keep in mind is that most lemmas in Japanese deal with
orthographic rather than inflectional variation. This orthographic variation is
called "<a href="https://ja.wikipedia.org/wiki/%E8%A1%A8%E8%A8%98%E3%82%86%E3%82%8C">hyoukiyure</a>" and causes problems similar to spelling errors in
English.</p>
<h3 id="verbs-will-often-be-multiple-tokens"> Verbs Will Often Be Multiple Tokens</h3>
<p>Any inflection of a verb will result in multiple tokens. This can also affect
adjectives that inflect, like 赤い.  You can see this in the verbs at the end
of the previous example, or in this more compact example:</p>
<pre><code>input: 見た ("looked" or "saw")
output:
見      ミ      ミル    見る    動詞-非自立可能 上一段-マ行     連用形-一般
た      タ      タ      た      助動詞  助動詞-タ       終止形-一般
</code></pre>
<p>This would be like if "looked" was tokenized into "look" and "ed" in English.
This feels strange even to native Japanese speakers, but it's common to all
modern tokenizers. The main reason for this is that verb inflections are
extremely regular, so registering verb stems and verb parts separately in the
dictionary makes dictionary maintenance easier and the tokenizer implementation
simpler and faster. It also works better in the rare case an unknown verb shows
up. (Verbs are a <a href="https://en.wikipedia.org/wiki/Part_of_speech#cite_ref-2:~:text=closed%20classes%20(such%20as%20pronouns%20and%20conjunctions)%20acquire%20new%20members%20infrequently%2C%20if%20at%20all.">closed class</a> in Japanese, which means new verbs aren't
common.)</p>
<p>In the early 90s several tokenizers handled verb morphology directly, but that
approach has been abandoned over time because of the above advantages of the
fine-grained approach. Depending on your application needs you can use some
simple rules to lump verb parts together or just discard non-stem parts as stop
words.</p>
<h3 id="the-tagger-object-has-a-startup-cost"> The Tagger Object Has a Startup Cost</h3>
<p>It's fast enough that you won't notice for one invocation, but creating the
Tagger is a lot of work for the computer. When processing text in a loop it's
important you re-use the Tagger rather than creating a new Tagger for each
input.</p>
<pre><code># Don't do this
for text in texts:
    tagger = fugashi.Tagger()
    words = tagger(text)

# Do this instead
tagger = fugashi.Tagger()
for text in texts:
    words = tagger(text)
</code></pre>
<p>If you follow the second pattern MeCab shouldn't be a speed bottleneck for
normal applications.</p>
<h3 id="always-note-your-tokenizer-details"> Always Note Your Tokenizer Details</h3>
<p>If you publish a resource using tokenized Japanese text, always be careful to
mention what tokenizer and what dictionary you used so your results can be
replicated. Saying you used MeCab isn't enough information to reproduce your
results, because there are many different dictionaries for MeCab that can give
completely different results. Even if you specify the dictionary, it's critical
that you specify the version too, since popular dictionaries like UniDic may be
updated over time. If you want to know more you can read <a href="https://www.dampfkraft.com/nlp/japanese-tokenizer-dictionaries.html">my article about
Japanese tokenizer dictionaries</a>.</p>
<hr>
<p>Hopefully that's enough to get you started with tokenizing Japanese. If you
have trouble, feel free to <a href="https://github.com/polm/fugashi/issues">file an issue</a> or <a href="mailto:polm@dampfkraft.com">contact me</a>.
I'm glad to help out with open source projects as time allows, and for
commercial projects you can hire me to handle the integration directly. Ψ</p>
</div></div>]]>
            </description>
            <link>https://www.dampfkraft.com/nlp/how-to-tokenize-japanese.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24142172</guid>
            <pubDate>Thu, 13 Aug 2020 11:25:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Things I'm excited for in Neovim 0.5.0: Language Server Protocol]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24142041">thread link</a>) | @numToStr
<br/>
August 13, 2020 | https://nathansmith.io/posts/neovim-lsp | <a href="https://web.archive.org/web/*/https://nathansmith.io/posts/neovim-lsp">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>The next major release of <a href="https://neovim.io/">Neovim</a>, 0.5.0, is currently in development and has five <a href="https://neovim.io/roadmap/">promised features</a>:</p>
<blockquote>
<ul>
<li>Lua remote plugin host</li>
<li>Lua user-config: init.lua</li>
<li>Treesitter syntax engine</li>
<li>LSP client for code navigation, refactoring</li>
<li>Extended marks (text properties, decorations, virtual text)</li>
</ul>
</blockquote>
<p>Enticed by offerings of the Neovim roadmap, I decided to install the nightly builds of Neovim and try them for myself. This post will be the first in a series where we focus on the features of Neovim 0.5.0. Today, we’ll look at Neovim’s Language Server Protocol.</p>
<h2 id="what-is-language-server-protocol">What is Language Server Protocol?<a href="#what-is-language-server-protocol" aria-label="what is language server protocol permalink"></a></h2>
<p>The <a href="https://microsoft.github.io/language-server-protocol/">Language Server Protocol</a>, or LSP, is a JSON RPC protocol introduced in 2016 by Microsoft that defines how an editor should talk to a language server. What is a language server? It’s a small program that runs locally on your computer that can provide information about the code you’re writing. The idea is that you tell the LSP where your project is, it scans all your files, and then has an understanding about your project. It can then provide go-to-definition, type info, compiler errors, completion suggestions, and more back to your editor. As the name implies, each language server generally supports only one language. There’s a <a href="https://langserver.org/">community maintained list</a> of major LSP implementations.</p>
<p>That’s cool, you say, but my editor already supports these features. Why should I start using a language server?</p>
<p>That’s a good question. If your editor already supports typo info, auto-completion, and everything else, you likely don’t need a language server. In fact, the LSP might slow you down – it’s likely a built-in editor feature would be faster than your editor making an RPC request to a server running on your computer.</p>
<p>However, the main advantage of the LSP is that it brings together developers who use different editors. The LSP is editor agnostic – if your editor speaks the protocol, it can talk to the server running. That is, instead of developers having to create an Emacs JavaScript plugin, and a Vim JavaScript plugin, and a VS Code JavaScript plugin, they need only create a single JavaScript language server and language server plugins for each editor.</p>
<p><a href="https://langserver.org/">Langserver.org</a> calls this problem “the matrix”, and it’s easy to see why. If we have <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span> languages and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span></span> editors, instead of making <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>×</mo><mi>m</mi></mrow><annotation encoding="application/x-tex">n \times m</annotation></semantics></math></span></span> integrations we only have to create <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span> language servers plus <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span></span> editor LSP plugins.</p>
<figure>
    <span>
      <span></span>
  <img alt="The Matrix Problem. The Language Server Protocol ideally means we have to write less tools and can share tools across editors and environments more easily." title="The Matrix Problem. The Language Server Protocol ideally means we have to write less tools and can share tools across editors and environments more easily." src="https://d33wubrfki0l68.cloudfront.net/12005bad22eafa1b9bdcf4d1d17015b714bded83/b3443/static/96b7982529b79bd6a4f0b7a177abe150/c5bb3/matrix-problem.png" srcset="https://d33wubrfki0l68.cloudfront.net/f19838a5a467210f204603091fc65df562fb57e3/169f6/static/96b7982529b79bd6a4f0b7a177abe150/04472/matrix-problem.png 170w, https://d33wubrfki0l68.cloudfront.net/3424f4fbddec6d16f90e57176654b074aa5cbe2e/17ef2/static/96b7982529b79bd6a4f0b7a177abe150/9f933/matrix-problem.png 340w, https://d33wubrfki0l68.cloudfront.net/12005bad22eafa1b9bdcf4d1d17015b714bded83/b3443/static/96b7982529b79bd6a4f0b7a177abe150/c5bb3/matrix-problem.png 680w, https://d33wubrfki0l68.cloudfront.net/673668b2c637dfeded44b6dc09b1106f9110a2d6/f327d/static/96b7982529b79bd6a4f0b7a177abe150/b12f7/matrix-problem.png 1020w, https://d33wubrfki0l68.cloudfront.net/f2a86b00c660bf46bdd7561e959c2f3e33179bbb/fe4cf/static/96b7982529b79bd6a4f0b7a177abe150/b5a09/matrix-problem.png 1360w, https://d33wubrfki0l68.cloudfront.net/15df038d58e7fa53d1fcbcf5a31b8c4c7d70d78c/91c2c/static/96b7982529b79bd6a4f0b7a177abe150/f2f8c/matrix-problem.png 1490w" sizes="(max-width: 680px) 100vw, 680px" loading="lazy">
    </span>
    <figcaption>The Matrix Problem. The Language Server Protocol ideally means we have to write less tools and can share tools across editors and environments more easily.</figcaption>
  </figure>
<p>Okay, you tell me, so now you’ve just proved <a href="https://en.wikipedia.org/wiki/Conway%27s_law">Conway’s law</a> also applies to open source. But you didn’t answer my original question: why should I use a language server?</p>
<p>Since the community of all JavaScript developers is a superset of all JavaScript Vim developers, this means that you should see more developers working on a JavaScript language server as opposed to a JavaScript Vim plugin. This should ideally mean a generally better language server.</p>
<p>Additionally, since the community of all Vim developers is also better than all JavaScript Vim developers, this should mean better LSP integration support. Vim users can unite and benefit around building a common language server, even if the day-to-day languages they use are different.</p>
<p>While this may not necessarily be true for all editor plugins, it certainly is for Vim. Vim completion can be done for already existing keywords, dictionary words, ctags results, or omnicomplete. Of these, ctags and omnicomplete are the most IDE-like. In my experience, while ctags is pretty good, it can often give inaccurate results if the same name is used in different contexts across a codebase. And omnicomplete is often left neglected: JavaScript omnicomplete hasn’t been <a href="https://github.com/vim/vim/blob/5be4ceecea5520265066eac972460ebb1cdf05e7/runtime/autoload/javascriptcomplete.vim">updated since 2017</a>, a sign of the matrix problem.</p>
<h2 id="upgrading-to-neovim-nightly">Upgrading to Neovim Nightly<a href="#upgrading-to-neovim-nightly" aria-label="upgrading to neovim nightly permalink"></a></h2>
<p>Okay, so I’ve convinced you to try out an LSP. How does it work in Neovim?</p>
<p>Neovim has <a href="https://github.com/neovim/neovim/wiki/Installing-Neovim">great install instructions</a> for most systems (macOS, Windows, popular Linux distros). I’m on macOS, so I ran:</p>
<div data-language="text"><pre><code>brew install --HEAD neovim</code></pre></div>
<p>From there, you can confirm that the installed version of Neovim has LSP support with <code>:h lsp</code>.</p>
<h2 id="a-note-on-lua">A note on Lua<a href="#a-note-on-lua" aria-label="a note on lua permalink"></a></h2>
<p>Recall the first two features of 0.5.0:</p>
<blockquote>
<ul>
<li>Lua remote plugin host</li>
<li>Lua user-config: init.lua</li>
</ul>
</blockquote>
<p>Vimscript, or VimL, is the de facto configuration of Vim. However, it’s also <a href="https://www.reddit.com/r/vim/comments/1bf672/why_does_viml_suck/">not that great of a language</a>: there are lots of odd quirks and performance issues that come with it. As a result, the Neovim core developers decided to add support for Lua in Neovim. Justin M. Keyes goes over the rationale for this decision in a <a href="https://youtu.be/Bt-vmPC_-Ho">great VimConf presentation</a>. The tl;dr is that Lua is a fast language that already exists and is simpler to learn than Vimscript.</p>
<p>Why does this matter? We were going to go over the LSP today, not Lua, right?</p>
<p>Yes and no. Just as Vimscript is the language for which Vim apis are exposed, Lua is becoming the preferred language for which Neovim apis are being exposed. The LSP api is in Lua, meaning we’ll have to write a little bit of Lua to set it up.</p>
<p>If you haven’t written any Lua, don’t fear! Ample code examples will be provided for your copy/pasting pleasure. Lua is a fairly easy language to read if you know any programming language already. If you’re interested in more Lua, <a href="https://learnxinyminutes.com/docs/lua/">Learn X in Y minutes</a> is a great place to start.</p>
<p>However, most Vimmers don’t currently have any Lua configuration files lying around, so we need to cover the basics of going from an <code>init.vim</code> Vimscript file into triggering Lua code. There are a couple ways to do this.</p>
<h3 id="lua-in-your-vim">Lua in your vim<a href="#lua-in-your-vim" aria-label="lua in your vim permalink"></a></h3>
<p>You can put Lua code directly in vimscript files, like so:</p>
<div data-language="vim"><pre><code>lua <span>&lt;</span><span>&lt;</span> EOF
<span>print</span><span>(</span><span>"hello world"</span><span>)</span>
EOF</code></pre></div>
<p>This is great for small to medium snippets of Lua code.</p>
<h3 id="lua-in-a-file">Lua in a file<a href="#lua-in-a-file" aria-label="lua in a file permalink"></a></h3>
<p>You can also tell Neovim to source lua files, given that that fit a directory structure. In Vimscript:</p>

<p>This will look for the file: <code>nvim/lua/lsp/init.lua</code>. This is great for larger, self-contained chunks of Lua code. I prefer this approach and use it in <a href="https://github.com/nathunsmitty/.config">my dotfiles</a>, since it gives me access to Lua syntax highlighting, linters, etc. while editing.</p>
<h2 id="configuring-support-for-servers">Configuring Support for Servers<a href="#configuring-support-for-servers" aria-label="configuring support for servers permalink"></a></h2>
<p>Neovim provides the LSP client built-in, but it needs to which language servers to run and where on your machine they’re located. There’s a <a href="https://neovim.io/doc/user/lsp.html#lsp-core">Lua api</a> provided that allows you to do this; the following will trigger JavaScript LSP:</p>
<div data-language="lua"><pre><code><span>local</span> root_dir <span>=</span> <span>buffer_find_root_dir</span><span>(</span>bufnr<span>,</span> <span>function</span><span>(</span>dir<span>)</span>
  <span>return</span> <span>is_dir</span><span>(</span><span>path_join</span><span>(</span>dir<span>,</span> <span>'node_modules'</span><span>)</span><span>)</span>
<span>end</span><span>)</span>

<span>local</span> bufnr <span>=</span> vim<span>.</span>api<span>.</span><span>nvim_get_current_buf</span><span>(</span><span>)</span>
<span>local</span> javascript_lsp_config <span>=</span> <span>{</span>
  name <span>=</span> <span>"javascript"</span><span>;</span>
  cmd <span>=</span> <span>{</span> <span>path_join</span><span>(</span>os<span>.</span><span>getenv</span><span>(</span><span>"JAVASCRIPT_LANGUAGE_SERVER_DIRECTORY"</span><span>)</span><span>,</span> <span>"lib"</span><span>,</span> <span>"language-server-stdio.js"</span><span>)</span> <span>}</span><span>;</span>
<span>}</span>

<span>local</span> new_config <span>=</span> vim<span>.</span><span>tbl_extend</span><span>(</span><span>"error"</span><span>,</span> javascript_lsp_config<span>,</span> <span>{</span>
  root_dir <span>=</span> root_dir<span>;</span>
<span>}</span><span>)</span>
client_id <span>=</span> vim<span>.</span>lsp<span>.</span><span>start_client</span><span>(</span>new_config<span>)</span>
vim<span>.</span>lsp<span>.</span><span>buf_attach_client</span><span>(</span>bufnr<span>,</span> client_id<span>)</span></code></pre></div>
<p>(This is adapted from <a href="https://neovim.io/doc/user/lsp.html#lsp-extension-example">an example</a> in the LSP manual.)</p>
<p>However, this is a lot of configuration. Is there a better solution?</p>
<h3 id="nvim-lsp-common-server-configuration">nvim-lsp: Common Server Configuration<a href="#nvim-lsp-common-server-configuration" aria-label="nvim lsp common server configuration permalink"></a></h3>
<p>To give a higher level of abstraction for end users who just want to start using a LSP, Neovim provides an official plugin: <a href="https://github.com/neovim/nvim-lsp">nvim-lsp</a>. This is a collection of common LSPs with integrations ready to go. Let’s install it!</p>
<div data-language="vim"><pre><code>
Plug <span>'neovim/nvim-lsp'</span>

<span>call</span> minpac#<span>add</span><span>(</span><span>'neovim/nvim-lsp'</span><span>,</span> <span>{</span><span>'type'</span><span>:</span> <span>'opt'</span><span>}</span><span>)</span>
packadd nvim<span>-</span><span>lsp</span></code></pre></div>
<p>Note that if you’re using a Vim 8’s native package manager (or a package manager that leverages the native package manager, like <a href="https://github.com/k-takata/minpac">minpac</a>), then you need to add the line <code>packadd nvim-lsp</code>. This is because Neovim <a href="https://github.com/neovim/neovim/issues/12670">currently does not source Lua plugins before your <code>init.vim</code> file</a>, meaning that your LSP config will execute before nvim-lsp is loaded, giving errors. With an older <a href="https://neovim.io/doc/user/options.html#'runtimepath'">runtimepath</a>-based plugin manager like <a href="https://github.com/junegunn/vim-plug">vim-plug</a>, this is not an issue.</p>
<p>Now that we’ve downloaded nvim-lsp, we can configure a language server. To set up the <a href="https://github.com/theia-ide/typescript-language-server">TypeScript language server</a>, we simply need to add:</p>
<div data-language="vim"><pre><code>require<span>'nvim_lsp'</span><span>.</span>tsserver<span>.</span>setup<span>{</span><span>}</span></code></pre></div>
<p>There are also <a href="https://github.com/neovim/nvim-lsp#tsserver">configuration options</a> for which filetypes to run it on, how to detect your project’s root directory, etc.</p>
<p>While we’re configuring stuff, let’s add some nice, vim-like shortcuts for LSP features:</p>
<div data-language="vim"><pre><code>nnoremap <span>&lt;</span><span>silent</span><span>&gt;</span> <span>gd</span> <span>&lt;</span>cmd<span>&gt;</span>lua <span>vim</span><span>.</span><span>lsp</span><span>.</span>buf<span>.</span><span>definition</span><span>(</span><span>)</span><span>&lt;</span>CR<span>&gt;</span>
nnoremap <span>&lt;</span><span>silent</span><span>&gt;</span> gh     <span>&lt;</span>cmd<span>&gt;</span>lua <span>vim</span><span>.</span><span>lsp</span><span>.</span>buf<span>.</span><span>hover</span><span>(</span><span>)</span><span>&lt;</span>CR<span>&gt;</span>
nnoremap <span>&lt;</span><span>silent</span><span>&gt;</span> gD    <span>&lt;</span>cmd<span>&gt;</span>lua <span>vim</span><span>.</span><span>lsp</span><span>.</span>buf<span>.</span><span>implementation</span><span>(</span><span>)</span><span>&lt;</span>CR<span>&gt;</span>
nnoremap <span>&lt;</span><span>silent</span><span>&gt;</span> <span>&lt;</span><span>c</span><span>-</span><span>k</span><span>&gt;</span> <span>&lt;</span>cmd<span>&gt;</span>lua <span>vim</span><span>.</span><span>lsp</span><span>.</span>buf<span>.</span><span>signature_help</span><span>(</span><span>)</span><span>&lt;</span>CR<span>&gt;</span>
nnoremap <span>&lt;</span><span>silent</span><span>&gt;</span> 1gD   <span>&lt;</span>cmd<span>&gt;</span>lua <span>vim</span><span>.</span><span>lsp</span><span>.</span>buf<span>.</span><span>type_definition</span><span>(</span><span>)</span><span>&lt;</span>CR<span>&gt;</span>
nnoremap <span>&lt;</span><span>silent</span><span>&gt;</span> <span>gr</span>    <span>&lt;</span>cmd<span>&gt;</span>lua <span>vim</span><span>.</span><span>lsp</span><span>.</span>buf<span>.</span><span>references</span><span>(</span><span>)</span><span>&lt;</span>CR<span>&gt;</span>
nnoremap <span>&lt;</span><span>silent</span><span>&gt;</span> g0    <span>&lt;</span>cmd<span>&gt;</span>lua <span>vim</span><span>.</span><span>lsp</span><span>.</span>buf<span>.</span><span>document_symbol</span><span>(</span><span>)</span><span>&lt;</span>CR<span>&gt;</span>
nnoremap <span>&lt;</span><span>silent</span><span>&gt;</span> gW    <span>&lt;</span>cmd<span>&gt;</span>lua <span>vim</span><span>.</span><span>lsp</span><span>.</span>buf<span>.</span><span>workspace_symbol</span><span>(</span><span>)</span><span>&lt;</span>CR<span>&gt;</span></code></pre></div>
<p>Note that these mappings override some Vim defaults, so in order to ensure they only work on</p>
<p>Awesome! However, unless you have the TypeScript language server already installed, you still won’t notice any LSP features. This is because you need to install the language server. The bad news is that each language server has its own installation instructions. The good news is the nvim-lsp takes care of it by providing a <code>LspInstall</code> command. All we have to do is run:</p>

<p>and we’re in business!</p>
<h3 id="even-more-abstractions">Even more abstractions<a href="#even-more-abstractions" aria-label="even more abstractions permalink"></a></h3>
<p>There are a few other optional plugins for Neovim that will improve your LSP quality-of-life. These are by no means necessary, you could implement them with a bit of Vimscript and Lua, but they do provide some more polish to the experience.</p>
<h4 id="completion-nvim">completion-nvim<a href="#completion-nvim" aria-label="completion nvim permalink"></a></h4>
<p><a href="https://github.com/nvim-lua/completion-nvim">completion-nvim</a>, as the name implies, is an autocompletion plugin. It’s similar to something like <a href="https://github.com/ycm-core/YouCompleteMe">YouCompleteMe</a> or <a href="https://github.com/Shougo/deoplete.nvim">Deoplete</a> in that it gives auto popup and other improvements on top of Neovim’s LSP api, as well as some other sources.</p>
<div data-language="vim"><pre><code><span>call</span> minpac#<span>add</span><span>(</span><span>'nvim-lua/completion-nvim'</span><span>,</span> <span>{</span><span>'type'</span><span>:</span> <span>'opt'</span><span>}</span><span>)</span>
packadd completion<span>-</span>nvim</code></pre></div>
<div data-language="lua"><pre><code><span>local</span> on_attach <span>=</span> <span>function</span><span>(</span><span>)</span>
  require<span>'completion'</span><span>.</span><span>on_attach</span><span>(</span><span>)</span>
  require<span>'diagnostic'</span><span>.</span><span>on_attach</span><span>(</span><span>)</span>
<span>end</span>
require<span>'nvim_lsp'</span><span>.</span>pyls<span>.</span><span>setup</span><span>{</span>on_attach<span>=</span>on_attach_vim<span>}</span></code></pre></div>
<h4 id="lsp-statusnvim-statusline-support">lsp-status.nvim: Statusline Support<a href="#lsp-statusnvim-statusline-support" aria-label="lsp statusnvim statusline support permalink"></a></h4>
<p><a href="https://github.com/nvim-lua/lsp-status.nvim">lsp-status.nvim</a> is a Lua plugin that allows you to display information from …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://nathansmith.io/posts/neovim-lsp">https://nathansmith.io/posts/neovim-lsp</a></em></p>]]>
            </description>
            <link>https://nathansmith.io/posts/neovim-lsp</link>
            <guid isPermaLink="false">hacker-news-small-sites-24142041</guid>
            <pubDate>Thu, 13 Aug 2020 11:07:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Business logic is the weakest link in Low-Code security]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24141927">thread link</a>) | @xiwenc
<br/>
August 13, 2020 | https://cinaq.com/post/2020/08/09/your-business-logic-is-the-weakest-link-in-low-code-security/ | <a href="https://web.archive.org/web/*/https://cinaq.com/post/2020/08/09/your-business-logic-is-the-weakest-link-in-low-code-security/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p>Over the past 5 years <a href="https://trends.google.com/trends/explore?date=2015-01-01%202020-08-02&amp;q=%2Fg%2F11c6cx4nrr">interest in low-code increased 100 folds</a> according to Google Trends:
<img src="https://cinaq.com/media/low-code-trends.png" alt="Low-code development trends">
This correlates with human psychology eager to optimise for efficiency in everything and building software solutions is no exception. As programming is becoming easier and more accessible, in the future, anyone should be able solve their own information automation challenges. Low-code is a relatively new movement that tries to enable those citizen developers with the right tooling lowering the barrier to build applications without writing traditional code. Because most of my professional experience with low-code is around <a href="https://www.mendix.com/">Mendix</a>, I will use it as reference through out this article.</p>

<p>First computer programs were written in machine code by few experts in the early days. This programming ability felt like a super power to many. Just like the Industrial age boosted the human civilisation, the Information Technology age we are currently in is helping the human race reach new heights. Programming languages are invented or improved to enable more efficient or better programming paradigms. This trend in <a href="https://en.wikipedia.org/wiki/History_of_programming_languages">programming languages timeline</a> is recently leading towards visual programming. In the industry this idea is marked as <a href="https://en.wikipedia.org/wiki/Low-code_development_platform">low-code platforms</a>. To me this is currently the highest programming level because of its high productivity characteristics. Low-code is in a nutshell an unification of deployment and composable building blocks nicely packed to play well together reducing the feedback loop at development and runtime.</p>

<p>The cost of higher abstraction which often correlates with higher productivity is <a href="https://en.wikipedia.org/wiki/High-level_programming_language#Abstraction_penalty">Abstraction penalty</a>. As we move up in the pyramid depicted below, we accomplish more with fewer efforts. That little effort however translates to more execute computing instructions. Due to this fact we loose optimisations and also unaware of the extra assumptions made in between. This problem increases more as applications grow larger and depend on libraries. No matter how well documented the libraries are, they are again abstractions of the actual implementation which might be inaccurate or the user of such library might not know or understand the full extends of the functionalities being leveraged on.</p>
<p><img src="https://cinaq.com/media/low-code-productivity-pyramid.png" alt="Higher programming languages result in higher computational instructions count"></p>

<p>A critical aspect of abstraction penalty is the unawareness of implied behaviours. Citizen developers (Low-code developers) leverage a lot from low-code platform itself; often with insufficient experience and knowledge of the underlaying runtime environment. This is a natural cause because these platforms were designed and promoted  for easy adoption. In the case of Mendix a typical security pitfall is negligence of <a href="https://docs.mendix.com/refguide/access-rules">entity access on attributes level</a>. Developers often focus on getting the program to work, in this particular case, a developer would grant access to all users. No matter the seniority, people make mistakes and forget access rule must be refined. In low-code platform like this, it’s very easy to make mistakes and leave open major security holes.</p>
<p>Platforms like Mendix already has <a href="https://www.mendix.com/evaluation-guide/enterprise-capabilities/security">security covered very well</a>. However with a strong platform, you can still build vulnerable applications because the platform does not know or understand your data risk levels. Therefore the weakest link is your business logic on a low-code platform.</p>
<p><img src="https://cinaq.com/media/low-code-mendix-security.png" alt="Business logic is weakest link with Mendix"></p>
<p>A typical example is: developer gives all access to credit card number attribute in the application model. The developer makes a remark to fine tune the access rules later but forgets to do so. Due to time pressure, testers mostly focussed on the happy use cases which did not reveal the CC information leak.</p>
<p>Therefore it’s crucial to have tooling to help detect these mistakes before they hit production. A tool that could reveal more that meets the eye for developers and testers alike. In Mendix, this would mean bypass the View (from <a href="https://en.wikipedia.org/wiki/Model%E2%80%93view%E2%80%93controller">Model View Controller</a>) showing all accessible data and function calls for a given user. There are few challenges here:</p>
<ul>
<li>How to extensively and automatically collect these data</li>
<li>How to make sense of the collected data to identify security weaknesses</li>
<li>Finally a repeatable and preferably incremental method to assess the security risk coverage</li>
</ul>
<p>Often pentest consultants are called in to assess the security risks of low-code applications. However this process is very labor intensive and error prone. As pointed out, higher generation languages like low-code has a bigger attack vector (related to number of computational instructions together with rapid feature building) requires extensive manual work.</p>

<p>In this article we learned low-code is an upcoming trend and it helps companies innovate faster by increasing the productivity of its developers. However, with the higher abstraction levels, it’s also easier to make security mistakes leaving the application vulnerable to attacks. As the citizen developers group grows, we need tooling in place to help identity security risks with the same low threshold as it requires to develop an app on a low-code platform.</p>

			</div></div>]]>
            </description>
            <link>https://cinaq.com/post/2020/08/09/your-business-logic-is-the-weakest-link-in-low-code-security/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24141927</guid>
            <pubDate>Thu, 13 Aug 2020 10:50:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cloud Encryption Is Worthless]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24141844">thread link</a>) | @URfejk
<br/>
August 13, 2020 | https://www.chrisfarris.com/post/cloud-encryption/ | <a href="https://web.archive.org/web/*/https://www.chrisfarris.com/post/cloud-encryption/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
        <p>(With apologies for the click-bait headline. It seems to be what all the cool kids are doing when they’re not on TikTok)</p>
<p>I have spent way too much of my life the last three years in the cloud compliance and cloud security posture monitoring space. One of the biggest issues I’ve struggled with is putting a priority on the issue of re-encrypting cloud <em>existing</em> resources.</p>
<p>Let me start off by saying that <strong>you should always check that little box to encrypt at rest</strong>. Because at some point, some one is going to audit your environment and come back with: “this thing isn’t encrypted”. You will then waste more time in meetings with officious people asking when you will encrypt that thing. Save yourself the grief and encrypt now.
<img src="https://www.chrisfarris.com/post/cloud-encryption/RemindYouOfMyLove.png" alt="I will Terminate all your EC2 Instances to remind you of my love"><br>
<em>Da da da dat da dat da da da da ya da<br>
Da da dat dat da ya da!</em></p>
<p>I even made you some scripts to help with <a href="https://github.com/WarnerMedia/aws-fast-fixes/tree/master/s3-bucket-default-encryption">buckets</a> and <a href="https://github.com/WarnerMedia/aws-fast-fixes/tree/master/ebs-encryption">volumes</a>.</p>
<p>So, having said you should always encrypt, this post is about discussing what to do when you discover a cloud resource isn’t encrypted. I will argue that re-encrypting things in the cloud is a high-effort, low-security-value exercise that should be a the bottom of your cloud posture hygiene priority list.</p>
<h2 id="encryption-at-rest">Encryption At Rest</h2>
<p>Lets talk about the value of <strong>Encryption At Rest</strong> in public cloud (and again, I’ll use AWS as my example, but these principles apply to most CSPs).</p>
<p>What threat are you defending against? Obviously, Disclosure is the primary one. Alteration is another. What are the most likely vectors of information disclosure or alteration in the cloud? Is it Ninjas descending on us-east-1a to steal the hard-drives your data is stored on? Or is it Bob in accounting who has an overly-permissioned IAM Key so he can download the AWS bill each month?</p>
<p><strong>Don’t be focusing on encryption before you first have your IAM and account governance houses in order!</strong></p>
<p>It doesn’t matter how much encryption you have on your data. If I provide AWS the right AKIA and 40 character random gobbledygook, Amazon will happily decrypt and hand me your data.</p>
<p>Ok then, besides ninjas, what threats does encryption-at-rest protect against?</p>
<ol>
<li>Cloud Insider Threats - AWS has access to your data. As <a href="https://tidbits.com/2012/04/09/how-to-tell-if-your-cloud-provider-can-read-your-data/">Rich Mogull wrote</a>: “<em>If you can see your data in a Web browser after entering only your account password, the odds are extremely high that your provider can read it as well.</em>” However, there are segregation of duties at AWS, and the person in the S3 team with access to your bits is not the same person who has access to your KMS key. So the S3 engineer would need to meet and conspire with the KMS engineer at the nearby Starbucks and then decide they want to go after <em>your</em> data. Maybe what you have is so valuable it’s worth the risk to them. Perhaps you should keep that shit on-prem.</li>
<li>Bad Code Paths - KMS, even AWS Managed KMS, is tied to your account. Assuming a software bug in the S3 service removed some amount of access controls, KMS access controls <em>might</em> prevent the decryption of the data. As far as anyone knows this has never happened, but it’s not outside the realm of possibility.</li>
<li>Poor Cloud Hygiene - If you have an EBS Volume that is encrypted, and you snapshot that volume and accidentally share it to the world, access to the KMS key would be required to hydrate that snapshot into a volume in an adversary’s account. However if you have such crappy cloud hygiene, you’re probably also not encrypting things consistently, so focus on fixing the hygiene and stop having myopic focus on encryption.</li>
<li>Encryption-in-Transit in the hypervisor-plane - <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html">AWS documentations states</a> that EBS encrypt/decrypt operations happen in the hypervisor of the compute node (not on the node where the volume is stored). As a result, the EBS I/O is encrypted when going across that back-end AWS network.</li>
</ol>
<h4 id="types-of-kms">Types of KMS</h4>
<p>AWS has three types of Customer Managed Keys (CMK), where the last one comes in two flavors:</p>
<ol>
<li><a href="https://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#aws-owned-cmk">AWS Owned CMK</a> - this seems like a oxymoron “AWS Managed Customer Managed Key”. These keys are used by AWS for services across multiple accounts</li>
<li><a href="https://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#aws-managed-cmk">AWS Managed CMK</a> - are in your account, but AWS manages the resource policy, not the customer.</li>
<li><a href="https://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#customer-cmk">Customer managed CMKs</a> - another silly named key - Customer Managed Customer Managed Key. Here you as the key owner can manage the resource policy and control who can use the key and in what ways.</li>
<li><a href="https://docs.aws.amazon.com/kms/latest/developerguide/importing-keys.html">Customer Provided</a> Customer managed CMKs - With these Customer managed CMKs, AWS does not generate the master key material. It is created by you and imported into the KMS service. Here is the $65 million dollar warning though: <em>“In the unlikely event of certain regionwide failures that affect the service (such as a total loss of power), AWS KMS cannot automatically restore your imported key material."</em></li>
</ol>
<!-- raw HTML omitted -->
<p>AWS Owned CMKs exist to check a box on a compliance spreadsheet. Luckily most cases this encrpytion is enabled by default.</p>
<p>AWS Managed CMKs might protect against the “Bad Code Paths” threat outlined above, while also checking a box on a spreadsheet.</p>
<p>Customer Managed CMKs do provide an extra level of security if you’re IAM and/or account governance is a mess. But defining a resource policy on a specific CMK, you can prevent other IAM Principals in the account from using that key for specific decrypt operations. This is important when you have large multi-tenant accounts due to poor application separation.</p>
<p>Customer Provided CMKs are a bad idea. If you need that you should stay on-prem. Otherwise you need to regularly test your procedures for extracting the key material from your on-prem vault and re-importing it into AWS. Because if there is a disaster with KMS, you are completely dead in the water till that is done.</p>
<h4 id="the-cost-of-re-encrypting">The cost of re-encrypting</h4>
<p>If you didn’t heed my initial advice and you did create a data store without enabling encryption at rest, what do you do?</p>
<p>For EBS volumes, you need to:</p>
<ol>
<li>Stop your instance</li>
<li>create a snapshot</li>
<li>create a new volume (with encryption)</li>
<li>attach new volume to a new instance</li>
<li>Start instance</li>
<li><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-initialize.html">Suffer performance impacts</a> till all the blocks are copied from the snapshot to the volume on read.</li>
</ol>
<p>(<a href="https://github.com/jchrisfarris/aws_scripts/blob/master/bin/encrypt_all_volumes.py">here is a script</a> I wrote three years ago when a cloud migration failed to do the right thing in terraform.)</p>
<p>For S3, you’ll need to copy each S3 Object and re-encrypt. <a href="https://aws.amazon.com/blogs/storage/encrypting-objects-with-amazon-s3-batch-operations/">AWS Batch Operations</a> can help there. But for a large enough volume of data, you’ll incur some costs. PutObject operations aren’t cheap at scale.</p>
<p>RDS also requires taking a snapshot, encrypting the snapshot when you copy it, then launching a new RDS from the encrypted snapshot. <a href="https://cintia.me/blog/post/lazy-rds/">With another performance impact</a>.</p>
<p><strong>The issue here is: “Is this worth it?” - The production downtime, performance impacts, lost time on the sprint that could be delivering business value or fixing the AppSec issues?</strong></p>
<h2 id="encryption-in-transit">Encryption in Transit</h2>
<p><a href="https://docs.aws.amazon.com/general/latest/gr/aws-general.pdf#aws-service-information">All AWS services support TLS Endpoints</a> and if you’re using the SDKs the <a href="https://boto3.amazonaws.com/v1/documentation/api/latest/reference/core/session.html#boto3.session.Session.client">default behavior</a> is to use the https endpoint. This means that most of your serverless applications get encrypt-in-transit out of the box. API Gateway invoking a lambda, which calls out to Lex is all encrypted-in-transit (with identity as the perimeter too).</p>
<p>Additionally, ACM makes it dirt-simple to drop a custom TLS Cert on your load balancer or CloudFront (which is how this site is https://).</p>
<p>Where you run into problems is when you’re inside of the VPC. Virtual Private Cloud does not mean virtual encrypted cloud. There is no encryption of traffic inside your VPC.</p>
<p>Your VPC exists across multiple AZs which means it also exists across multiple buildings. Traffic between instances across AZs travels unencrypted across metro areas. If your threat model includes adversaries that can compel warrantless wiretaps, you need to focus on intra-VPC Encryption. If that’s not your adversarial threat model go back and look at your other cloud hygiene issues first.</p>
<p>All that said, intra-VPC Encryption-in-Transit is undifferentiated heavy lifting. Managing keys on instances and containers is added complexity that interferes with builders. <strong>AWS should provide KMS support on ENIs for all intra-VPC traffic.</strong> [<a href="#edit-1">edit-1</a>]</p>
<h2 id="conclusion">Conclusion</h2>
<p>When evaluating your cloud security posture priorities, <strong>encryption should be at the bottom of your list.</strong> Yes, you should <a href="https://aws.amazon.com/premiumsupport/knowledge-center/ebs-automatic-encryption">enable Default EBS encryption</a>, and then enable <a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/bucket-encryption.html">Default S3 encryption</a> on all your S3 Buckets.</p>
<p>But first get your IAM house in order. Get rid of IAM users and figure out least-privilege identity federation. Fix your InstanceProfile or Lambda policies so you’re not <a href="https://krebsonsecurity.com/tag/capital-one-breach/">the next CapitalOne</a>.</p>
<p>Fix those Launch Wizards that are open to the world. Close your S3 buckets, and turn on CloudTrail FFS!</p>
<p>Make sure you’re leveraging organizations to effectively protect your accounts from outside the account (via SCPs). Operationalize GuardDuty and IAM Access Analyzer. Pay attention to your AppSec, since those SSRFs are how you’re leaking keys to the world.</p>
<p>Once you’ve done all that, then consider re-encrypting the cloud resources you missed encrypting on creation.</p>
<h5 id="edit-1">Edit 1</h5>
<p>2020-Aug-3 @0710 EDT - In a slack discussion with <a href="https://summitroute.com/">Scott Piper</a> after this was published, he led me to some docs that show some ENIs do support transparent encryption. However the instance types are quite limited, and NAT and Transit gateways aren’t supported. <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/data-protection.html#encryption-transit">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/data-protection.html#encryption-transit</a></p>
<p>Additionally AWS states (emphasis mine):</p>
<blockquote>
<p><em>All data flowing across the AWS global network that interconnects our datacenters and regions <strong>is automatically encrypted at the physical layer before it leaves our secured facilities</strong>. Additional encryption layers exist as well; for example, all VPC cross-region peering traffic, and customer or service-to-service TLS connections.</em>(<a href="https://aws.amazon.com/security/">link</a>)</p>
</blockquote>

        
    </div></div>]]>
            </description>
            <link>https://www.chrisfarris.com/post/cloud-encryption/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24141844</guid>
            <pubDate>Thu, 13 Aug 2020 10:34:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Danger of Having a B-Team]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24141704">thread link</a>) | @svmanager
<br/>
August 13, 2020 | https://staysaasy.com/management/2020/08/11/Team-Topology.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/management/2020/08/11/Team-Topology.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Make the seniority, talent, and quality-of-mission of your organization’s teams as consistent as possible. The pretstige of team missions and their capability should all be comparable. There should be no dramatic differences between the caliber of your teams.</p>

<h2 id="the-problem">The Problem</h2>

<p>It’s not uncommon for a leader to bucket what needs to get done as a set of hard, medium, and easy missions. The next step they’ll take is to assemble teams of respectively different talent levels and seniority to handle those challenges of different prestige levels. The outcome are teams that vary in their ability and the importance (real or perceived) of their mission. You’ve just turned your department into a caste system.</p>

<p>This creates lots of challenges:</p>
<ul>
  <li>People who are on low-caliber teams know it. This causes morale and retention issues.</li>
  <li>In some cases, people end up selling the company to recruits based off of what the prestigious teams are doing, only to place people into other teams. This causes morale and retention issues.</li>
  <li>The weak-mission teams will often not have a growth path to the highest levels. This essentially means it’s a transient team unless you hire people to stagnate. A great litmus test is: can every team support promotions to the highest level?</li>
  <li>You end up constantly having to field questions around internal transfers to the prestigious teams. Good managers tell the truth when people aren’t ready for the other team or when the team isn’t ready for them. Bad managers give little glimmers of hope that don’t reflect reality and lead to a long tail of frustration.</li>
  <li>Dysfunctional organizations will actually lower the hiring and promotion bars for lower caliber teams for political and morale reasons. This can lead to very, very bad outcomes like reducing the integrity of compensation bands or causing internal strife at the mis-match across teams.</li>
  <li>This set of variables is also very dangerous because internal processes of an organization are based on the people they’re serving. Different cohorts of people need different enablement, onboarding, rules, and rewards. Having major differences amongst teams means it’s harder to have one overarching culture and set of organizational mechanics.</li>
</ul>

<p>How do you fix this? Let’s go back and revisit some assumptions.</p>

<h2 id="assumption-1-we-have-hard-medium-and-easy-missions">Assumption 1: We Have Hard, Medium and Easy Missions</h2>

<p>People get this wrong all the time. When looking at the missions of a team, it’s not uncommon for a leader to have standard biases or an ego that leads to total miscalculations of the difficulty of certain missions.</p>

<p>An example is in software engineering, where leaders might view their team’s goals as fancy backend “hard stuff’’ and simple front-end “easy stuff”. That’s obviously bullshit. Think of all of the terrible UIs you encounter on a day to day basis. If frontend engineering was easy UI would be a solved problem.</p>

<p>Another example is when a leader or a team aren’t executing well on a part of their responsibilities and they end up saying that it just needs to be handled by some other team because it’s easy but distracting. In reality, if it’s easy they’d be doing a good job at it. This kind of thinking can lead teams to push away what is actually more important work in lieu of more interesting (or greenfield, or easy) work.</p>

<p>People often make bad calls on what’s difficult and what’s easy and then make things worse with the second, equally damaging assumption.</p>

<h2 id="assumption-2-easy-missions-should-be-done-by-lower-caliber-teams">Assumption 2: Easy Missions Should Be Done By Lower-Caliber Teams</h2>

<p>Leaders will then compound the problem by staffing teams to get the “easy missions” done with less senior or skillful talent. So they assume a problem is easy, understaff it, and then as things inevitably go wrong they end up blaming either the team, the mission, or anything else but the poor decisions that lead to a self-fulfilling prophecy.</p>

<h2 id="a-better-path">A Better Path</h2>

<p>To solve this problem, take a hard look at the topology of work you’re trying to get done:</p>
<ul>
  <li>If a <em>small</em> volume of work is much simpler than other tasks, you should add it into the responsibilities of your existing teams.</li>
  <li>If a <em>large</em> volume work is much simpler than other work- meaning it’d meaningfully distract your regular teams - you should either contract it out or you build an different organization to handle it.</li>
  <li>Sometimes you’ll have a team who has lower perceived prestigue because it doesn’t contain as many buzzwords or trendy technologies as other teams. Absent active efforts, that team will have a harder time hiring and retaining. To counteract this, you should make sure you’re overloading that team with talent, so that you make up for the team’s perceived mission prestigue with personel prestige.</li>
  <li>In all cases, expectation setting and integrity in decision making is critical. Don’t hire people into roles with the false hope of transferring to other teams if it’s not possible. Don’t transfer people to other teams if they’re not ready.</li>
</ul>

<h2 id="examples">Examples</h2>
<ul>
  <li>Your hot-stuff AI/ML startup has 4 high-powered product teams, but you keep having this pesky problem of a trickle of internal requests from the client-facing teams. You decide to create a team to just handle those requests. You figure it’s not that big of a problem and don’t want to distract your teams, so you hire a junior team to just handle that. You’ve just made a huge mistake. That team will be unhappy and have retention problems forever. You should have either contracted that work or found a process for your other teams to get it done.</li>
  <li>Your hot-stuff AI/ML startup has built out a customer portal that is getting a ton of traction. The work has meaningful challenges and growth opportunities, but it’s very different than your core team’s responsibilities. The people you hire, the promotion paths, the culture needed to execute well, and the evaluation criteria are existentially inconsistent with your other teams. You work with senior management to build out an entirely new organization to work on the portal. Great job, you’ve done the right thing. This was a lot of work that warranted a focused division to manage the mission.</li>
</ul>


    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/management/2020/08/11/Team-Topology.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24141704</guid>
            <pubDate>Thu, 13 Aug 2020 10:10:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[US Core Inflation Jumps by Most Since 1991]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 29 (<a href="https://news.ycombinator.com/item?id=24141694">thread link</a>) | @jules-jules
<br/>
August 13, 2020 | https://confoundedinterest.net/2020/08/12/us-core-inflation-jumps-by-most-since-1991-while-rent-inflation-fell-to-lowest-rate-since-2015/ | <a href="https://web.archive.org/web/*/https://confoundedinterest.net/2020/08/12/us-core-inflation-jumps-by-most-since-1991-while-rent-inflation-fell-to-lowest-rate-since-2015/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-12687">
			<!-- .entry-header -->		<div>
			<p>
							<span>
					<a href="https://confoundedinterest.net/category/bubble/" rel="category tag">#bubble</a>, <a href="https://confoundedinterest.net/category/banking/" rel="category tag">Banking</a>, <a href="https://confoundedinterest.net/category/bernanke/" rel="category tag">Bernanke</a>, <a href="https://confoundedinterest.net/category/cmbs/" rel="category tag">CMBS</a>, <a href="https://confoundedinterest.net/category/cre/" rel="category tag">CRE</a>, <a href="https://confoundedinterest.net/category/ecb/" rel="category tag">ECB</a>, <a href="https://confoundedinterest.net/category/economy/" rel="category tag">Economy</a>, <a href="https://confoundedinterest.net/category/fannie-mae/" rel="category tag">fannie mae</a>, <a href="https://confoundedinterest.net/category/fed/" rel="category tag">Fed</a>, <a href="https://confoundedinterest.net/category/freddie-mac/" rel="category tag">Freddie Mac</a>, <a href="https://confoundedinterest.net/category/gdp/" rel="category tag">GDP</a>, <a href="https://confoundedinterest.net/category/housing/" rel="category tag">Housing</a>, <a href="https://confoundedinterest.net/category/inflation/" rel="category tag">Inflation</a>, <a href="https://confoundedinterest.net/category/mortgage/" rel="category tag">Mortgage</a>, <a href="https://confoundedinterest.net/category/pension/" rel="category tag">Pension</a>, <a href="https://confoundedinterest.net/category/powell/" rel="category tag">Powell</a>, <a href="https://confoundedinterest.net/category/reits/" rel="category tag">REITs</a>, <a href="https://confoundedinterest.net/category/treasuries/" rel="category tag">Treasuries</a>, <a href="https://confoundedinterest.net/category/treasury/" rel="category tag">Treasury</a>, <a href="https://confoundedinterest.net/category/uncategorized/" rel="category tag">Uncategorized</a>, <a href="https://confoundedinterest.net/category/volatility/" rel="category tag">Volatility</a>, <a href="https://confoundedinterest.net/category/yellen/" rel="category tag">Yellen</a>				</span></p><!-- .cat-links -->
			
			
			<p><span>
				<time datetime="2020-08-12T12:46:59-04:00">August 12, 2020</time><time datetime="2020-08-12T14:36:15-04:00">August 12, 2020</time>			</span>

			<span>1 Minute</span>		</p></div><!-- .entry-meta -->
	
	<div>
		
<p>Well, The Federal Reserve finally got its wish: INFLATION!</p>



<p><em>U.S. consumer prices&nbsp;rose&nbsp;in July by more than expected on a bounce in auto and apparel costs. <strong>The so-called core figure, which excludes volatile food and fuel costs, climbed 0.6% from the prior month, the biggest surge in almost three decades</strong>, according to a Labor Department report Wednesday. The headline figure also increased 0.6%, following the same gain in June. The trend reflects a rebound in demand for goods and services from the depths of the pandemic-induced lockdowns earlier this year</em>.</p>



<figure><img data-attachment-id="12691" data-permalink="https://confoundedinterest.net/coreinf/" data-orig-file="https://confoundedinterestnet.files.wordpress.com/2020/08/coreinf.png" data-orig-size="736,530" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="coreinf" data-image-description="" data-medium-file="https://confoundedinterestnet.files.wordpress.com/2020/08/coreinf.png?w=300" data-large-file="https://confoundedinterestnet.files.wordpress.com/2020/08/coreinf.png?w=736" src="https://confoundedinterestnet.files.wordpress.com/2020/08/coreinf.png?w=736" alt="" srcset="https://confoundedinterestnet.files.wordpress.com/2020/08/coreinf.png 736w, https://confoundedinterestnet.files.wordpress.com/2020/08/coreinf.png?w=150 150w, https://confoundedinterestnet.files.wordpress.com/2020/08/coreinf.png?w=300 300w" sizes="(max-width: 736px) 100vw, 736px"></figure>



<p>But on a YoY basis, core inflation rose only 1.6%.</p>



<figure><img data-attachment-id="12694" data-permalink="https://confoundedinterest.net/the-core-1/" data-orig-file="https://confoundedinterestnet.files.wordpress.com/2020/08/the-core-1.png" data-orig-size="736,530" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="the-core-1" data-image-description="" data-medium-file="https://confoundedinterestnet.files.wordpress.com/2020/08/the-core-1.png?w=300" data-large-file="https://confoundedinterestnet.files.wordpress.com/2020/08/the-core-1.png?w=736" src="https://confoundedinterestnet.files.wordpress.com/2020/08/the-core-1.png?w=736" alt="" srcset="https://confoundedinterestnet.files.wordpress.com/2020/08/the-core-1.png 736w, https://confoundedinterestnet.files.wordpress.com/2020/08/the-core-1.png?w=150 150w, https://confoundedinterestnet.files.wordpress.com/2020/08/the-core-1.png?w=300 300w" sizes="(max-width: 736px) 100vw, 736px"></figure>







<figure><img data-attachment-id="12697" data-permalink="https://confoundedinterest.net/indl-1/" data-orig-file="https://confoundedinterestnet.files.wordpress.com/2020/08/indl-1.png" data-orig-size="736,530" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="indl-1" data-image-description="" data-medium-file="https://confoundedinterestnet.files.wordpress.com/2020/08/indl-1.png?w=300" data-large-file="https://confoundedinterestnet.files.wordpress.com/2020/08/indl-1.png?w=736" src="https://confoundedinterestnet.files.wordpress.com/2020/08/indl-1.png?w=736" alt="" srcset="https://confoundedinterestnet.files.wordpress.com/2020/08/indl-1.png 736w, https://confoundedinterestnet.files.wordpress.com/2020/08/indl-1.png?w=150 150w, https://confoundedinterestnet.files.wordpress.com/2020/08/indl-1.png?w=300 300w" sizes="(max-width: 736px) 100vw, 736px"></figure>



<p>But rent inflation fell to 2.8% YoY, the lowest since 2015.</p>



<figure><img data-attachment-id="12698" data-permalink="https://confoundedinterest.net/rentcpi-2/" data-orig-file="https://confoundedinterestnet.files.wordpress.com/2020/08/rentcpi.png" data-orig-size="736,529" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="rentcpi" data-image-description="" data-medium-file="https://confoundedinterestnet.files.wordpress.com/2020/08/rentcpi.png?w=300" data-large-file="https://confoundedinterestnet.files.wordpress.com/2020/08/rentcpi.png?w=736" src="https://confoundedinterestnet.files.wordpress.com/2020/08/rentcpi.png?w=736" alt="" srcset="https://confoundedinterestnet.files.wordpress.com/2020/08/rentcpi.png 736w, https://confoundedinterestnet.files.wordpress.com/2020/08/rentcpi.png?w=150 150w, https://confoundedinterestnet.files.wordpress.com/2020/08/rentcpi.png?w=300 300w" sizes="(max-width: 736px) 100vw, 736px"></figure>



<figure><img data-attachment-id="12709" data-permalink="https://confoundedinterest.net/ogd-1/" data-orig-file="https://confoundedinterestnet.files.wordpress.com/2020/08/ogd-1.jpg" data-orig-size="329,750" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ogd-1" data-image-description="" data-medium-file="https://confoundedinterestnet.files.wordpress.com/2020/08/ogd-1.jpg?w=132" data-large-file="https://confoundedinterestnet.files.wordpress.com/2020/08/ogd-1.jpg?w=329" src="https://confoundedinterestnet.files.wordpress.com/2020/08/ogd-1.jpg?w=329" alt="" srcset="https://confoundedinterestnet.files.wordpress.com/2020/08/ogd-1.jpg 329w, https://confoundedinterestnet.files.wordpress.com/2020/08/ogd-1.jpg?w=66 66w, https://confoundedinterestnet.files.wordpress.com/2020/08/ogd-1.jpg?w=132 132w" sizes="(max-width: 329px) 100vw, 329px"></figure>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

	<div>
			<!-- .entry-auhtor -->
		<p><strong>Published</strong>
			<time datetime="2020-08-12T12:46:59-04:00">August 12, 2020</time><time datetime="2020-08-12T14:36:15-04:00">August 12, 2020</time>		</p><!-- .site-posted-on -->
	</div>
</article></div>]]>
            </description>
            <link>https://confoundedinterest.net/2020/08/12/us-core-inflation-jumps-by-most-since-1991-while-rent-inflation-fell-to-lowest-rate-since-2015/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24141694</guid>
            <pubDate>Thu, 13 Aug 2020 10:08:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Limiting Asynchronous Operations Concurrency in JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24141535">thread link</a>) | @ziir_hn
<br/>
August 13, 2020 | https://timtech.blog/posts/limiting-async-operations-promise-concurrency-javascript/ | <a href="https://web.archive.org/web/*/https://timtech.blog/posts/limiting-async-operations-promise-concurrency-javascript/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <p>Today's post is about a little trick I have learned about 2years ago, and that I have since used numerous times in short Node.js scripts I had to write.<br>
It really isn't much, but I guess it may be helpful to others, and probably is an alright first JavaScript post on this blog.</p>
<blockquote>
<p>Say one has a list of things, and for every of these things, one needs to perform an asynchronous operation that returns a Promise, and be notified when all operations have been performed.<br>
How does one limit the number of asynchronous operations being performed conccurently? Without 3rd party dependencies and just a few lines of code?</p>
</blockquote>
<p>Are you seeing the problem yet? Let's build some context:</p>
<h3 id="we-have-a-list-of-99-things%2C-say-resource-identifiers">We have a list of 99 things, say resource identifiers <a href="#we-have-a-list-of-99-things%2C-say-resource-identifiers">#</a></h3>
<pre><code><span>const</span> ids <span>=</span> Array<span>.</span><span>from</span><span>(</span><span>Array</span><span>(</span><span>99</span><span>)</span><span>,</span> <span>(</span><span>_<span>,</span> i</span><span>)</span> <span>=&gt;</span> i <span>+</span> <span>1</span><span>)</span><span>;</span><br><span>&gt;</span> <span>[</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>...</span> <span>99</span><span>]</span></code></pre>
<h3 id="for-each-of-these-things%2C-we-need-to-perform-an-asynchronous-operation">For each of these things, we need to perform an asynchronous operation <a href="#for-each-of-these-things%2C-we-need-to-perform-an-asynchronous-operation">#</a></h3>
<p>First, let's define the function that will perform said asynchronous operation:</p>
<pre><code><br><br><span>function</span> <span>performAsyncOperation</span><span>(</span><span>id</span><span>)</span> <span>{</span><br>  <span>return</span> <span>new</span> <span>Promise</span><span>(</span><span>(</span><span>resolve</span><span>)</span> <span>=&gt;</span> <span>{</span><br>    <span>setTimeout</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span><br>      console<span>.</span><span>log</span><span>(</span><span><span>`</span><span>Performed operation for resource </span><span><span>${</span>id<span>}</span></span><span>.</span><span>`</span></span><span>)</span><span>;</span><br>      <span>resolve</span><span>(</span><span>)</span><span>;</span><br>    <span>}</span><span>,</span> <span>300</span><span>)</span><span>;</span><br>  <span>}</span><span>)</span><span>;</span><br><span>}</span></code></pre>
<p>Now, we know that we need to call this function of every single thing out of our list of 99 things, every resource id we have in <code>ids</code>.<br>
Our first approach, would be to naively use <a href="https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Array/map">Array.prototype.map</a> and <a href="https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Promise/all">Promise.all</a> and call it a day. But let's have a closer look to this innocent line of code and its implications:</p>
<pre><code><span>await</span> Promise<span>.</span><span>all</span><span>(</span>ids<span>.</span><span>map</span><span>(</span>performAsyncOperation<span>)</span><span>)</span><span>;</span><br>console<span>.</span><span>log</span><span>(</span><span>'All operations performed, moving on to something else now.'</span><span>)</span><span>;</span></code></pre>
<p><em>Note: we might arguably use <a href="https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Promise/allSettled">Promise.allSettled</a> in a real world scenario, but let's assume our asynchronous operations cannot fail.</em></p>
<p>Which we would give us the following complete script:</p>
<pre><code><span>function</span> <span>performAsyncOperation</span><span>(</span><span>id</span><span>)</span> <span>{</span><br>  <span>return</span> <span>new</span> <span>Promise</span><span>(</span><span>(</span><span>resolve</span><span>)</span> <span>=&gt;</span> <span>{</span><br>    <span>setTimeout</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span><br>    console<span>.</span><span>log</span><span>(</span><span><span>`</span><span>Performed operation for resource </span><span><span>${</span>id<span>}</span></span><span>.</span><span>`</span></span><span>)</span><span>;</span><br>    <span>resolve</span><span>(</span><span>)</span><span>;</span><br>    <span>}</span><span>,</span> <span>300</span><span>)</span><span>;</span><br>  <span>}</span><span>)</span><span>;</span><br><span>}</span><p><span>async</span> <span>function</span> <span>run</span><span>(</span><span>)</span> <span>{</span><br>  <span>const</span> start <span>=</span> Date<span>.</span><span>now</span><span>(</span><span>)</span><span>;</span><br>  <span>const</span> ids <span>=</span> Array<span>.</span><span>from</span><span>(</span><span>Array</span><span>(</span><span>99</span><span>)</span><span>,</span> <span>(</span><span>_<span>,</span> i</span><span>)</span> <span>=&gt;</span> i <span>+</span> <span>1</span><span>)</span><span>;</span></p><p>  <span>await</span> Promise<span>.</span><span>all</span><span>(</span>ids<span>.</span><span>map</span><span>(</span>performAsyncOperation<span>)</span><span>)</span><span>;</span><br>  <span>const</span> end <span>=</span> Date<span>.</span><span>now</span><span>(</span><span>)</span><span>;</span><br>  console<span>.</span><span>log</span><span>(</span><span><span>`</span><span>All operations performed in </span><span><span>${</span>end <span>-</span> start<span>}</span></span><span>ms, moving on to something else now.</span><span>`</span></span><span>)</span><span>;</span><br><span>}</span></p><p><span>run</span><span>(</span><span>)</span><span>;</span></p></code></pre>
<p>Now, let's run it:</p>
<pre><code>$ node async-operations-promise-all.js
</code></pre>
<pre><code>[tim@praxis ~]$ node limit-async.js 
Performed operation for resource 1.
Performed operation for resource 2.
Performed operation for resource 3.
...
Performed operation for resource 97.
Performed operation for resource 98.
Performed operation for resource 99.
All operations performed in 338ms, moving on to something else now.
</code></pre>
<p>As we can see, ~all the asynchronous operations were performed <strong>concurrently</strong>, and sometimes, that's perfectly fine and exactly what we want.</p>
<p><em>Note: <code>Promise.all</code> only waits for all the <code>Promise</code>s to be resolved. The actual asynchronous operation is triggered by the function call from <code>Array.prototype.map</code>, creating a new <code>Promise</code> on each call.</em></p>
<h3 id="the-problem-of-performing-operations-concurrently">The problem of performing operations concurrently <a href="#the-problem-of-performing-operations-concurrently">#</a></h3>
<p>Now, let's assume that our <code>performAsyncOperation</code> really performs an HTTP request, an API Call, a database query, or really anything else that would either suffer or punish us for the load we push on to it. It might be a rate-limited API, or a fragile host.</p>
<p><em>Note: in the actual case of an HTTP request, or database query, the Web/Node.js/etc... API being used will already probably limit concurrency, of which value may or may not configurable, but let's assume that we cannot or do not want to change such settings.</em></p>
<p>In such cases, we simply cannot allow our script to perform all these operations concurrently, as it risks getting our API key revoked, our IP blocked, or the target host/database responding unreliably, etc... Thus we will be searching for a way to limit this concurrency to avoid such scenario.</p>
<p><em>Note: depending on the actual work performed by the asynchronous operation, performing many of these concurrently may also make the process running it consuming significant amount of CPU and/or memory resources on the machine it runs.</em></p>
<h3 id="a-solution%3A-performing-asynchronous-operations-sequentially">A solution: performing asynchronous operations sequentially <a href="#a-solution%3A-performing-asynchronous-operations-sequentially">#</a></h3>
<p>The first solution that may come to mind, would be to perform each of these operations <strong>sequentially</strong>:</p>
<pre><code><span><span>async</span> <span>function</span> <span>run</span><span>(</span><span>)</span> <span>{</span></span><br><span>  <span>const</span> start <span>=</span> Date<span>.</span><span>now</span><span>(</span><span>)</span><span>;</span></span><br><span>  <span>const</span> ids <span>=</span> Array<span>.</span><span>from</span><span>(</span><span>Array</span><span>(</span><span>99</span><span>)</span><span>,</span> <span>(</span><span>_<span>,</span> i</span><span>)</span> <span>=&gt;</span> i <span>+</span> <span>1</span><span>)</span><span>;</span></span><br><span></span><br><del>  <span>-</span> <span>await</span> Promise<span>.</span><span>all</span><span>(</span>ids<span>.</span><span>map</span><span>(</span>performAsyncOperation<span>)</span><span>)</span><span>;</span></del><br><ins>  <span>+</span> <span>for</span> <span>(</span><span>const</span> id <span>of</span> ids<span>)</span> <span>{</span></ins><br><ins>  <span>+</span>   <span>await</span> <span>performAsyncOperation</span><span>(</span>id<span>)</span><span>;</span></ins><br><ins>  <span>+</span> <span>}</span></ins><br><span>  <span>const</span> end <span>=</span> Date<span>.</span><span>now</span><span>(</span><span>)</span><span>;</span></span><br><span>  console<span>.</span><span>log</span><span>(</span><span><span>`</span><span>All operations performed in </span><span><span>${</span>end <span>-</span> start<span>}</span></span><span>ms, moving on to something else now.</span><span>`</span></span><span>)</span><span>;</span></span><br><span><span>}</span></span></code></pre>
<p>Which, if we run this script, gives the following output:</p>
<pre><code>[tim@praxis ~]$ node limit-async.js 
Performed operation for resource 1.
Performed operation for resource 2.
Performed operation for resource 3.
...
Performed operation for resource 97.
Performed operation for resource 98.
Performed operation for resource 99.
All operations performed in 29825ms, moving on to something else now.
</code></pre>
<p>As we'd expect, every operation awaits for the previous one to be completed, and, in a way, we found a succesful solution to our problem.<br>
However, one would probably argue this being far from optimal, and that the system against which we run these asynchronous operations can safely withstand up to 3 concurrent operations, thus, our script could theoretically be ~3 times faster.</p>
<h3 id="the-solution%3A-limiting-concurrency-using-workers">The solution: limiting concurrency using workers <a href="#the-solution%3A-limiting-concurrency-using-workers">#</a></h3>
<p>Now, let's take a look at how we can update our script to perform at most 3 operations concurrently.<br>
For that, let's introduce a <code>worker</code> function, to which we will delegate the job of performing one asynchronous operation at a time.</p>
<pre><code><span>const</span> <span>worker</span> <span>=</span> <span>next_</span> <span>=&gt;</span> <span>async</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span><br>  <span>let</span> next<span>;</span><br>  <span>while</span> <span>(</span><span>(</span>next <span>=</span> <span>next_</span><span>(</span><span>)</span><span>)</span><span>)</span> <span>{</span><br>    <span>await</span> <span>performAsyncOperation</span><span>(</span>next<span>)</span><span>;</span><br>  <span>}</span><br><span>}</span><span>;</span></code></pre>
<p><em>Note: such a <code>worker</code> function can be implemented in various ways, this implementation is just an example of what I've used in the past.</em></p>
<p>However big the number of asynchronous operations we wish to perform, we will ever need at most, 3 concurrent <code>workers</code>.</p>
<pre><code><span>const</span> <span>CONCURRENT_WORKERS</span> <span>=</span> <span>3</span><span>;</span></code></pre>
<p>We will then want to give a way to our <code>workers</code> to retrieve the next resource identifier, or thing, to perform the asynchronous operation from.</p>
<pre><code><span>const</span> workers <span>=</span> <span>[</span><span>]</span><span>;</span><br><span>for</span> <span>(</span><span>let</span> i <span>=</span> <span>0</span><span>;</span> i <span>&lt;</span> <span>CONCURRENT_WORKERS</span><span>;</span> i<span>++</span><span>)</span> <span>{</span><br>  <span>const</span> w <span>=</span> <span>worker</span><span>(</span>ids<span>.</span><span>pop</span><span>.</span><span>bind</span><span>(</span>ids<span>)</span><span>)</span><span>;</span><br>  workers<span>.</span><span>push</span><span>(</span><span>w</span><span>(</span>ids<span>)</span><span>)</span><span>;</span><br><span>}</span></code></pre>
<p>Let us update our script:</p>
<pre><code><span><span>function</span> <span>performAsyncOperation</span><span>(</span><span>id</span><span>)</span> <span>{</span></span><br><span>  <span>return</span> <span>new</span> <span>Promise</span><span>(</span><span>(</span><span>resolve</span><span>)</span> <span>=&gt;</span> <span>{</span></span><br><span>    <span>setTimeout</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span></span><br><span>    console<span>.</span><span>log</span><span>(</span><span><span>`</span><span>Performed operation for resource </span><span><span>${</span>id<span>}</span></span><span>.</span><span>`</span></span><span>)</span><span>;</span></span><br><span>    <span>resolve</span><span>(</span><span>)</span><span>;</span></span><br><span>    <span>}</span><span>,</span> <span>300</span><span>)</span><span>;</span></span><br><span>  <span>}</span><span>)</span><span>;</span></span><br><span><span>}</span></span><br><span></span><br><ins><span>const</span> <span>worker</span> <span>=</span> <span>next_</span> <span>=&gt;</span> <span>async</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span></ins><br><ins>  <span>let</span> next<span>;</span></ins><br><ins>  <span>while</span> <span>(</span><span>(</span>next <span>=</span> <span>next_</span><span>(</span><span>)</span><span>)</span><span>)</span> <span>{</span></ins><br><ins>    <span>await</span> <span>performAsyncOperation</span><span>(</span>next<span>)</span><span>;</span></ins><br><ins>  <span>}</span></ins><br><ins><span>}</span><span>;</span></ins><br><ins></ins><br><ins><span>const</span> <span>CONCURRENT_WORKERS</span> <span>=</span> <span>3</span><span>;</span></ins><br><ins></ins><br><ins><span>async</span> <span>function</span> <span>run</span><span>(</span><span>)</span> <span>{</span></ins><br><ins>  <span>const</span> start <span>=</span> Date<span>.</span><span>now</span><span>(</span><span>)</span><span>;</span></ins><br><ins>  <span>const</span> ids <span>=</span> Array<span>.</span><span>from</span><span>(</span><span>Array</span><span>(</span><span>99</span><span>)</span><span>,</span> <span>(</span><span>_<span>,</span> i</span><span>)</span> <span>=&gt;</span> i <span>+</span> <span>1</span><span>)</span><span>;</span></ins><br><ins></ins><br><ins>  <span>const</span> workers <span>=</span> <span>[</span><span>]</span><span>;</span></ins><br><ins>  <span>for</span> <span>(</span><span>let</span> i <span>=</span> <span>0</span><span>;</span> i <span>&lt;</span> <span>CONCURRENT_WORKERS</span><span>;</span> i<span>++</span><span>)</span> <span>{</span></ins><br><ins>    <span>const</span> w <span>=</span> <span>worker</span><span>(</span>ids<span>.</span><span>pop</span><span>.</span><span>bind</span><span>(</span>ids<span>)</span><span>)</span><span>;</span></ins><br><ins>    workers<span>.</span><span>push</span><span>(</span><span>w</span><span>(</span>ids<span>)</span><span>)</span><span>;</span></ins><br><ins>  <span>}</span></ins><br><ins></ins><br><ins>  <span>await</span> Promise<span>.</span><span>all</span><span>(</span>workers<span>)</span><span>;</span></ins><br><span></span><br><span>  <span>const</span> end <span>=</span> Date<span>.</span><span>now</span><span>(</span><span>)</span><span>;</span></span><br><span>  console<span>.</span><span>log</span><span>(</span><span><span>`</span><span>All operations performed in </span><span><span>${</span>end <span>-</span> start<span>}</span></span><span>ms, moving on to something else now.</span><span>`</span></span><span>)</span><span>;</span></span><br><span><span>}</span></span><br><span></span><br><span><span>run</span><span>(</span><span>)</span><span>;</span></span></code></pre>
<p>And run it:</p>
<pre><code>[tim@praxis ~]$ node limit-async.js 
Performed operation for resource 1.
Performed operation for resource 2.
Performed operation for resource 3.
...
Performed operation for resource 97.
Performed operation for resource 98.
Performed operation for resource 99.
All operations performed in 9948ms, moving on to something else now.
</code></pre>
<h3 id="bonus-solution%3A-batching-concurrent-operations">Bonus solution: batching concurrent operations <a href="#bonus-solution%3A-batching-concurrent-operations">#</a></h3>
<p>There's one more way to look at the problem, and reach another solution: splitting the asynchronous operations to be performed in <strong>batches</strong>.<br>
In our case, if we have 99 operations to perform, we can split these into 33 batches of 3 operations.<br>
With batching, every operation within one batch will be performed conccurently, and the next batch will only be started once the previous one is finished.<br>
How does one implement concurrent operations batching with JavaScript?</p>
<pre><code><span><span>async</span> <span>function</span> <span>run</span><span>(</span><span>)</span> <span>{</span></span><br><span>  <span>const</span> start <span>=</span> Date<span>.</span><span>now</span><span>(</span><span>)</span><span>;</span></span><br><span>  <span>const</span> ids <span>=</span> Array<span>.</span><span>from</span><span>(</span><span>Array</span><span>(</span><span>99</span><span>)</span><span>,</span> <span>(</span><span>_<span>,</span> i</span><span>)</span> <span>=&gt;</span> i <span>+</span> <span>1</span><span>)</span><span>;</span></span><br><span></span><br><del>  <span>-</span> <span>await</span> Promise<span>.</span><span>all</span><span>(</span>ids<span>.</span><span>map</span><span>(</span>performAsyncOperation<span>)</span><span>)</span><span>;</span></del><br><ins>  <span>+</span> <span>let</span> i <span>=</span> <span>1</span><span>;</span></ins><br><ins>  <span>+</span> <span>while</span> <span>(</span>ids<span>.</span>length<span>)</span> <span>{</span></ins><br><ins>  <span>+</span>   <span>await</span> Promise<span>.</span><span>all</span><span>(</span>ids<span>.</span><span>splice</span><span>(</span><span>0</span><span>,</span> <span>3</span><span>)</span><span>.</span><span>map</span><span>(</span>performAsyncOperation<span>)</span><span>;</span></ins><br><ins>  <span>+</span>   console<span>.</span><span>log</span><span>(</span><span>'Performed async operactions batch number'</span><span>,</span> i<span>)</span><span>;</span></ins><br><ins>  <span>+</span>   i<span>++</span><span>;</span></ins><br><ins>  <span>+</span> <span>}</span></ins><br><span>  <span>const</span> end <span>=</span> Date<span>.</span><span>now</span><span>(</span><span>)</span><span>;</span></span><br><span>  console<span>.</span><span>log</span><span>(</span><span><span>`</span><span>All operations performed in </span><span><span>${</span>end <span>-</span> start<span>}</span></span><span>ms, moving on to something else now.</span><span>`</span></span><span>)</span><span>;</span></span><br><span><span>}</span></span></code></pre>
<p>Which gives us the following output:</p>
<pre><code>[tim@praxis ~]$ node limit-async.js 
Performed operation for resource 1.
Performed operation for resource 2.
Performed operation for resource 3.
Performed async operactions batch number 1
...
Performed operation for resource 97.
Performed operation for resource 98.
Performed operation for resource 99.
Performed async operactions batch number 33
All operations performed in 9981ms, moving on to something else now.
</code></pre>
<h3 id="conclusion">Conclusion <a href="#conclusion">#</a></h3>
<p>Asynchronous JavaScript can be tricky, and though one may argue the language lacks high-level APIs to deal more efficiently with some of these tricky cases like the one we've just covered, it's always worth taking our chance at solving the problems leveraging the features that we're provided by the language.</p>
<p>In this post we've built and lived through a common scenario of managing asynchronous operations concurrency in JavaScript, along with a common pitfall associated with a naive approach, as well as an intermediary solution that is also very useful on some other cases, and finally the optimal solution for dealing with this problem, all without using third party modules. I hope this may be useful to some of you, and that I did not take too many shortcuts in the process.</p>
<p>If you liked this post, feel free to encourage me by saying so on <a href="https://twitter.com/tpillard">my Twitter</a> and/or by liking/retweeting the associated tweet or sharing the article around you.<br>
If, on the contrary, you did not like this post and think I should never write JavaScript and/or on a public medium again, keep it to yourself dude, I know already.<br>
Finally, feel free to share your feedback …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://timtech.blog/posts/limiting-async-operations-promise-concurrency-javascript/">https://timtech.blog/posts/limiting-async-operations-promise-concurrency-javascript/</a></em></p>]]>
            </description>
            <link>https://timtech.blog/posts/limiting-async-operations-promise-concurrency-javascript/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24141535</guid>
            <pubDate>Thu, 13 Aug 2020 09:42:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Haskell to Core: Understanding Haskell Features Through Their Desugaring]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24141425">thread link</a>) | @NaeosPsy
<br/>
August 13, 2020 | https://serokell.io/blog/haskell-to-core | <a href="https://web.archive.org/web/*/https://serokell.io/blog/haskell-to-core">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>This article is based on <a href="https://www.youtube.com/watch?v=fty9QL4aSRc">my talk with the same title</a>, which I gave at the Haskell Love conference in 2020, where I give a cursory overview of GHC’s front-end pipeline, the internal Core language, and the desugaring pass.</em></p><p>Haskell is an expressive language with many features. On the one hand, it makes Haskell convenient, equipping the programmer with a rich arsenal of tools to get the job done and write high-quality software. On the other hand, developing a thorough understanding of these tools, of all the language features, takes time, effort, and experience.</p><p>One way to build an intuition for a language feature is to use it. Practice makes perfect, and by trial and error, you can discover the ins and outs of using certain parts of the language. However, the knowledge acquired this way may be superficial, and the mental model will only be as good as it was needed for the tasks at hand.</p><p>Deeper insight comes from a different perspective: you need to decompose a concept into its basic constituents. For example, what are multi-argument functions? In a curried language, we know that <code>\a b c -&gt; ...</code> is much the same as <code>\a -&gt; \b -&gt; \c -&gt; ...</code>. Thus we have reduced the concept of a multi-argument function into a simpler concept of a single-argument function.</p><p>For a more involved example: what is <code>do</code>-notation? To grasp it, you need to think about how it is desugared into <code>&gt;&gt;=</code> and <code>&gt;&gt;</code> (and also <code>&lt;*&gt;</code> with <code>-XApplicativeDo</code>).</p><p>What about infix operators, if-then-else expressions, list comprehensions, type classes, type families, GADTs? How much Haskell is essential, and how much is sugar on top?</p><p>This becomes clear if we start thinking about the way Haskell programs are desugared into GHC’s Core: a small, elegant language, used as an intermediate representation in GHC’s compilation pipeline. The many features of Haskell are reducible to the few constructs of Core.</p><p>Desugaring translates a program that uses many different language constructs into a program that uses only a few.</p><p>For example, consider this snippet:</p><pre><code><span>product</span> [a + b, c + d]
</code></pre><p>It uses several Haskell features:</p><ol>
<li>Lists literals: <code>[a, b, c, ...]</code></li>
<li>Operator application: <code>x # y</code></li>
<li>Function application: <code>f x</code></li>
</ol><p>But we can rewrite it in such a way that it uses only function application:</p><pre><code><span>product</span> (
  (:) ((+) a b) (
  (:) ((+) c d) (
  [])))
</code></pre><p>Granted, the end result is not as readable. But the building blocks used to write this program are simpler, and that’s the important bit.</p><p>Desugaring is not just an abstract idea: it’s a concrete step of GHC’s pipeline. Every Haskell program is desugared into Core during compilation. So, to see the full picture, it’s helpful to consider the steps that occur prior to desugaring.</p><p>The input to the compiler is a string, a sequence of characters:</p><center><img src="https://serokell.io/files/dy/dy2sc5q9.ParserInput.png" alt="Parser Input"></center><p>Where would one begin to process this sequence? Actually, this is fairly well known. The first step is <strong>lexical analysis</strong>, which groups subsequences of these characters into labeled tokens:</p><center><img src="https://serokell.io/files/mf/mfm4t5lo.LexerOutput.png" alt="Lexer Output"></center><p>Then the tokens are organized into a tree. That’s <strong>syntactic analysis</strong>:</p><center><img src="https://serokell.io/files/oa/oav0bml8.ParserOutput.png" alt="Parser Output"></center><p>The structure of this tree depends on the language we’re working with. In Haskell, a module contains declarations, such as data declarations, class declarations, function/variable definitions, and so on. In this example, we have two value bindings, marked as ‘bind’.</p><p>In a ‘bind’, there’s a pattern on the left-hand side and an expression on the right-hand side. In this example, the patterns are simply variable names, but we could also have as-patterns, view-patterns, matching on specific data constructors, and so on.</p><p>An expression can be one of many forms, but here we have:</p><ul>
<li>‘app’ – function application, consisting of a function and its argument;</li>
<li>‘op app’ – operator application, consisting of two operands and an operator;</li>
<li>‘var’ – references to other named values;</li>
<li>‘lit’ – numeric and string literals.</li>
</ul><p>Then we do <strong>name resolution</strong>, to figure out which name refers to what:</p><center><img src="https://serokell.io/files/8v/8vvt57kn.RenamerOutput.png" alt="Renamer Output"></center><p>Here, ‘print’, ‘+’, and ‘length’ are imported from other modules, whereas ‘x’ is defined in the same module.</p><p>And then, we analyse the program to <strong>check and infer the types</strong> of its expressions and subexpressions:</p><pre><code><span>main</span> :: <span>IO</span> ()
<span>x</span> :: <span>Int</span>
</code></pre><p>So that’s the GHC pipeline, or at least its front-end:</p><p><img src="https://serokell.io/files/sx/sxg6b87v.PipelineGHC.png" alt="sxg6b87v.PipelineGHC.png"></p><ul>
<li>text to tokens;</li>
<li>tokens to a syntax tree;</li>
<li>add scoping information to the syntax tree;</li>
<li>add type information to the syntax tree;</li>
</ul><p>This leaves us with a well-scoped, well-typed syntax tree. This is the input to desugaring. And the output is a Core program, where Core is a language like Haskell, but it’s much smaller and with fewer features.</p><p>To understand how Core is simpler, let’s first take a deeper look at Haskell. To represent a Haskell expression, GHC defines a type called <code>HsExpr</code>. If you open <code><a href="https://gitlab.haskell.org/ghc/ghc/-/blob/master/compiler/GHC/Hs/Expr.hs">compiler/GHC/Hs/Expr.hs</a></code> in GHC sources, you will see it:</p><pre><code><span><span>data</span> <span>HsExpr</span> p</span>
  = <span>HsVar</span> ...         
  | <span>HsLit</span> ...         
  | <span>HsApp</span> ...         
  | <span>OpApp</span> ...         
  | ...
</code></pre><p>Remember how syntactic analysis creates a node for each subexpression? And these nodes can be of different varieties, such as function application, operator application, variables, literals, etc.? <code>HsExpr</code> has a constructor for each node type: <code>HsVar</code>, <code>HsLit</code>, <code>HsApp</code>, <code>OpApp</code>, and so on.</p><p>And there are lots and lots of node types:</p><pre><code><span><span>data</span> <span>HsExpr</span> p</span>
  = <span>HsVar</span> ...         
  | <span>HsLit</span> ...         
  | <span>HsApp</span> ...         
  | <span>OpApp</span> ...         
  | <span>HsAppType</span> ...     
  | <span>HsLam</span> ...         
  | <span>HsLet</span> ...         
  | <span>ExprWithTySig</span> ... 
  | <span>ExplicitList</span> ...  
  | <span>SectionL</span> ...      
  | <span>SectionR</span> ...      
  | <span>ExplicitTuple</span> ... 
  | <span>HsCase</span> ...        
  | <span>HsLamCase</span> ...     
  | <span>HsIf</span> ...          
  | <span>HsMultiIf</span> ...     
  | <span>HsDo</span> ...          
  | <span>RecordCon</span> ...     
  | <span>RecordUpd</span> ...     
  | <span>ArithSeq</span> ...      
  | <span>HsPar</span> ...         
  | <span>NegApp</span> ...        
  | <span>HsBracket</span> ...     
  | <span>HsSpliceE</span> ...     
  | <span>HsProc</span> ...        
  | <span>HsStatic</span> ...      
  | <span>HsOverLabel</span> ...   
  | ...
</code></pre><p>And that’s just expressions. There are also patterns, defined in <code><a href="https://gitlab.haskell.org/ghc/ghc/-/blob/master/compiler/GHC/Hs/Pat.hs">compiler/GHC/Hs/Pat.hs</a></code>:</p><pre><code><span><span>data</span> <span>Pat</span> p</span>
  = <span>WildPat</span> ...       
  | <span>VarPat</span> ...        
  | <span>LazyPat</span> ...       
  | <span>BangPat</span> ...       
  | <span>AsPat</span> ...         
  | <span>ParPat</span> ...        
  | <span>ListPat</span> ...       
  | <span>TuplePat</span> ...      
  | <span>ConPat</span> ...        
  | <span>ViewPat</span> ...       
  | <span>LitPat</span> ...        
  | <span>SigPat</span> ...        
  | <span>NPat</span> ...          
  | <span>NPlusKPat</span> ...     
  | <span>SplicePat</span> ...     
  | ...
</code></pre><p>And types, defined in <code><a href="https://gitlab.haskell.org/ghc/ghc/-/blob/master/compiler/GHC/Hs/Type.hs">compiler/GHC/Hs/Type.hs</a></code>:</p><pre><code><span><span>data</span> <span>HsType</span> p</span>
  = <span>HsForAllTy</span> ...    
  | <span>HsQualTy</span> ...      
  | <span>HsTyVar</span> ...       
  | <span>HsAppTy</span> ...       
  | <span>HsAppKindTy</span> ...   
  | <span>HsFunTy</span> ...       
  | <span>HsListTy</span> ...      
  | <span>HsTupleTy</span> ...     
  | <span>HsOpTy</span> ...        
  | <span>HsParTy</span> ...       
  | <span>HsIParamTy</span> ...    
  | <span>HsStarTy</span> ...      
  | <span>HsKindSig</span> ...     
  | <span>HsSpliceTy</span> ...    
  | <span>HsTyLit</span> ...       
  | <span>HsWildCardTy</span> ...  
  | ...
</code></pre><p>In <code><a href="https://gitlab.haskell.org/ghc/ghc/-/blob/master/compiler/GHC/Hs/Decls.hs">compiler/GHC/Hs/Decls.hs</a></code> there are data declarations, classes, type families, instances, and so on:</p><pre><code><span><span>data</span> <span>TyClDecl</span> p</span>
  = <span>FamDecl</span> ...       
  | <span>SynDecl</span> ...       
  | <span>DataDecl</span> ...      
  | <span>ClassDecl</span> ...     

<span><span>data</span> <span>InstDecl</span> p</span>
  = <span>ClsInstD</span> ...      
  | <span>DataFamInstD</span> ...  
  | <span>TyFamInstD</span> ...    
</code></pre><p>That’s not all, of course. You can browse <code>compiler/GHC/Hs/...</code> to see more.</p><p>What about Core? Here’s the entirety of its syntax:</p><pre><code><span><span>data</span> <span>Expr</span></span>
  = <span>Var</span>   <span>Id</span>
  | <span>Lit</span>   <span>Literal</span>
  | <span>App</span>   <span>Expr</span> <span>Expr</span>
  | <span>Lam</span>   <span>Var</span> <span>Expr</span>
  | <span>Let</span>   <span>Bind</span> <span>Expr</span>
  | <span>Case</span>  <span>Expr</span> <span>Var</span> <span>Type</span> [<span>Alt</span>]
  | <span>Cast</span>  <span>Expr</span> <span>Coercion</span>
  | <span>Type</span>  <span>Type</span>
  | <span>Coercion</span> <span>Coercion</span>
  | <span>Tick</span>  ...  

<span><span>type</span> <span>Alt</span> = (<span>AltCon</span>, [<span>Var</span>], <span>Expr</span>)</span>

<span><span>data</span> <span>AltCon</span></span>
  = <span>DataAlt</span> <span>DataCon</span>
  | <span>LitAlt</span>  <span>Literal</span>
  | <span>DEFAULT</span>

<span><span>data</span> <span>Bind</span></span>
  = <span>NonRec</span> <span>Var</span> <span>Expr</span>
  | <span>Rec</span> [(<span>Var</span>, <span>Expr</span>)]

<span><span>data</span> <span>Type</span></span>
  = <span>TyVarTy</span> <span>Var</span>
  | <span>AppTy</span> <span>Type</span> <span>Type</span>
  | <span>TyConApp</span> <span>TyCon</span> [<span>Type</span>]
  | <span>ForAllTy</span> <span>TyCoVarBinder</span> <span>Type</span>
  | <span>FunTy</span> <span>Mult</span> <span>Type</span> <span>Type</span>
  | <span>LitTy</span> <span>TyLit</span>
  | <span>CastTy</span> <span>Type</span> <span>Coercion</span>
  | <span>CoercionTy</span> <span>Coercion</span>
</code></pre><p>Its expression syntax has only nine constructs:</p><ul>
<li>variables (<code>Var</code>)</li>
<li>literals (<code>Lit</code>)</li>
<li>function application (<code>App</code>)</li>
<li>lambdas (<code>Lam</code>)</li>
<li>let-bindings (<code>Let</code>)</li>
<li>case-expressions (<code>Case</code>)</li>
<li>casts (<code>Cast</code>)</li>
<li>coercions (<code>Coercion</code>)</li>
</ul><p>If you learn what these are, you know Core. And if you know both Core and how Haskell programs are desugared into it, then you can easily reason about the menagerie of Haskell language features.</p><p>At a first approximation, you can think of Core as a subset of Haskell plus coercions (and casts, these two are closely related). That’s not the full story, though. For example, there are also differences in strictness, as <code>case</code> in Core is always strict. Here are some resources if you want to delve deeper into this:</p><ul>
<li><a href="https://www.youtube.com/watch?v=uR_VzYxvbxg">“Into the Core - Squeezing Haskell into Nine Constructors"</a></li>
<li><a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2007/01/tldi22-sulzmann-with-appendix.pdf">“System F with Type Equality Coercions"</a></li>
<li><a href="https://repository.brynmawr.edu/cgi/viewcontent.cgi?article=1014&amp;context=compsci_pubs">“System FC with Explicit Kind Equality"</a></li>
<li><a href="https://github.com/ghc/ghc/blob/master/docs/core-spec/core-spec.pdf">“System FC, as implemented in GHC"</a></li>
<li>Read the GHC sources (e.g. <code>dsLExpr</code>) and <code>-ddump-simpl</code> output</li>
</ul><p>However, as a starting point, it’s sufficient to assume that Core is a subset of Haskell.</p><p>Now let’s see how Haskell programs are transformed into Core by looking at specific examples. We’ll start with the most basic features and progress to more complex ones.</p><h2 id="infix-operators">Infix Operators</h2><p>Infix operators are translated into function applications:</p><table><tbody><tr><th>
Haskell
</th>
<th>
Core
</th></tr>
<tr><td>
<pre><code><span>a</span> &amp;&amp; b
</code></pre>
</td>
<td>
<pre><code>(&amp;&amp;) a b
</code></pre>
</td></tr></tbody></table><p>There isn’t much to it. But keep in mind that in Core, all variable occurrences have type information, so a more accurate translation would look like this:</p><pre><code>((&amp;&amp;) :: <span>Bool</span> -&gt; <span>Bool</span> -&gt; <span>Bool</span>)
  (a :: <span>Bool</span>)
  (b :: <span>Bool</span>)
</code></pre><p>However, more often than not, I will omit type annotations to save visual space.</p><h2 id="function-bindings">Function Bindings</h2><p>Bindings in Core always have a single variable name on the left-hand side. Function bindings are desugared into lambdas:</p><table><tbody><tr><th>
Haskell
</th>
<th>
Core
</th></tr>
<tr><td>
<pre><code><span>f</span> x y = not x &amp;&amp; y
</code></pre>
</td>
<td>
<pre><code><span>f</span> =
  \(x :: <span>Bool</span>) -&gt;
  \(y :: <span>Bool</span>) -&gt;
     (&amp;&amp;) (not x) y
</code></pre>
</td></tr></tbody></table><p>Also, there are no separate type signatures. All type information is stored inline.</p><h2 id="multi-argument-function-bindings">Multi-Argument Function Bindings</h2><p>Multi-argument functions are translated into nested lambdas. In Core, all lambdas are single-argument:</p><table><tbody><tr><th>
Haskell
</th>
<th>
Core
</th></tr>
<tr><td>
<pre><code><span>f</span> x y = not x &amp;&amp; y
</code></pre>
</td>
<td>
<pre><code><span>f</span> =
  \(x :: <span>Bool</span>) -&gt;
  \(y :: <span>Bool</span>) -&gt;
     (&amp;&amp;) (not x) y
</code></pre>
</td></tr></tbody></table><p>This is also true for hand-written multi-argument lambdas:</p><table><tbody><tr><th>
Haskell
</th>
<th>
Core
</th></tr>
<tr><td>
<pre><code><span>f</span> = \x y -&gt; not x &amp;&amp; y
</code></pre>
</td>
<td>
<pre><code><span>f</span> =
  \(x :: <span>Bool</span>) -&gt;
  \(y :: <span>Bool</span>) -&gt;
     (&amp;&amp;) (not x) y
</code></pre>
</td></tr></tbody></table><p>This treatment of multi-argument functions may be familiar to you if you’ve heard of <a href="https://en.wikipedia.org/wiki/Currying">cu…</a></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://serokell.io/blog/haskell-to-core">https://serokell.io/blog/haskell-to-core</a></em></p>]]>
            </description>
            <link>https://serokell.io/blog/haskell-to-core</link>
            <guid isPermaLink="false">hacker-news-small-sites-24141425</guid>
            <pubDate>Thu, 13 Aug 2020 09:22:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[RFC22: Control flow: Builtin switch statement, by Damian Conway]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24141297">thread link</a>) | @lizmat
<br/>
August 13, 2020 | https://raku-advent.blog/2020/08/13/rfc22-control-flow-builtin-switch-statement-by-damian-conway/ | <a href="https://web.archive.org/web/*/https://raku-advent.blog/2020/08/13/rfc22-control-flow-builtin-switch-statement-by-damian-conway/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-587">

	

	
	<div>
		<h2 id="the-problem">The problem</h2>
<p>C has switch/case, and many other languages either copied it, or created a similar construct. Perl in 2000 didn’t have any such thing, and this was seen as a lack.</p>
<h2 id="a-tale-of-two-languages">A Tale of Two Languages</h2>
<p><a href="https://raku.org/archive//rfc/22.html">This RFC</a> not only became two (related) features, it did so in both Perl and Raku with dramatically different results: in Perl it’s widely considered the biggest design failure of the past two decades, whereas in Raku it’s an entirely non-controversial. The switch that Perl ended up with is working very similar to the original proposal. This is actually helpful in analysing what changes were necessary to make it a successful feature. It looks something like this (in both languages):</p>
<pre><code>given $foo {
    when /foo/ {
        say "No dirty words here";
    }
    when "None" {

    }
    when 1 {
        say "One!";
    }
    when $_ &gt; 42 {
        say "It's more than life, the universe and everything";
    }
}
</code></pre>
<p>The switch is actually two features (for the price of only one RFC): smartmatch and <a href="https://docs.raku.org/language/control#index-entry-switch_(given)">given/when</a> on top of it. Smartmatch is an operator <code>~~</code> that checks if the left hand side fits the constraints of the right hand side. Given/when is a construct that smartmatches the given argument to a series of when arguments (e.g.&nbsp;<code>$given ~~ $when</code>) until one succeeds.</p>
<p>However, one of the distinguishing features of Perl is that it doesn’t generally overload operators, instead it has different operators for different purposes (e.g.&nbsp;<code>==</code> for comparing numbers and <code>eq</code> for comparing strings). Smartmatch however is inherently all about overloading. This mismatch is essentially the source of all the trouble of smartmatch in Perl. Raku on the other hand has an extensive type-system, and is not so dependent on type specific operators (though it still has some for convenience), and hence is much more predictable.</p>
<p>Most obviously, the type system of Raku means that it doesn’t use a table of possibilities, but instead <code>$left ~~ $right</code> just translates to <code>$right.ACCEPTS($left)</code>. The right-first semantics makes it a lot easier to reason about (e.g.&nbsp;matching against a number will always do numeric equality).</p>
<p>It means it can easily distinguish between a string and an integer, unlike Perl which has to guess what you meant: <code>$foo ~~ 1</code> always means <code>$foo == 1</code>, and <code>$foo ~~ "foo"</code> always means <code>$foo eq "foo"</code>. In Perl, <code>$foo ~~ "1"</code> would do a numeric match.</p>
<p>But perhaps the most important rule is smartmatching booleans. Perl doesn’t have them, and this makes <code>when</code> so much more complicated than most people realize. The problem is with statements like <code>$_ &gt; 42</code>, which need boolean logic. Perl solves this using a <a href="https://perldoc.perl.org/perlsyn.html#Experimental-Details-on-given-and-when">complex heuristic</a> that no one really can remember (no really, no one). Most surprisingly, that means that <code>when /foo/</code> does not use smartmatching (this becomes obvious when the left hand side is an arrayref).</p>
<p>Raku uses a very different method to solve this problem. In Raku, when <em>always</em> smartmatches. Smartmatching against a <code>Bool</code> (like in <code>$_ &gt; 42</code>), will always return that bool, so <code>$foo ~~ True</code> always equals <code>True</code>. This enables a wide series of boolean expressions to be used as <code>when</code> condition without problems. It’s a much simpler, and surprisingly effective method of dealing with this challenge.</p>
<h2 id="other-uses">Other uses</h2>
<p>The other difference between smartmatching in Perl versus Raku is that it is actually used outside of given/when. In particular, selecting methods such as <code>grep</code> and <code>first</code> use it to great effect: <code>@array.grep(1)</code>, <code>@array.grep(Str)</code>, <code>@array.grep(/foo/)</code>, <code>@array.grep(&amp;function)</code>, <code>@array.grep(1..3)</code>, and <code>@array.grep((1, *, 3))</code>* all do what you probably expect them to do. Likewise it’s used in a number of other places where one checks if a value is part of a certain group or not, like the ending argument of a sequence (e.g.&nbsp;<code>1000, 1001 ... *.is-prime</code>) and the flip-flop operators.</p>
<p>Smartmatch is all about making code do what you mean, and it’s pretty useful and reusable for that.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

			<!-- .author-bio -->
	
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://raku-advent.blog/2020/08/13/rfc22-control-flow-builtin-switch-statement-by-damian-conway/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24141297</guid>
            <pubDate>Thu, 13 Aug 2020 09:00:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Django for Beginners – Updated to 3.1]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24141190">thread link</a>) | @nanna
<br/>
August 13, 2020 | https://learndjango.com/tutorials/whats-new-django-31 | <a href="https://web.archive.org/web/*/https://learndjango.com/tutorials/whats-new-django-31">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<ul>
<li>By Will Vincent</li>
<li>
<i></i>
<span>Jul 27, 2020</span>
</li>
<li>
<span><a href="https://learndjango.com/tutorials/whats-new-django-31#disqus_thread"></a></span>
</li>
</ul>


<p>Django 3.1 will be released in early August 2020 and comes with a number of major new features and many minor improvements including asynchronous views and middleware support, asynchronous tests, JSONField for all supported database backends (not just PostgreSQL), an updated admin page, <code>SECURE_REFERRER_POLICY</code>, and much more. The <a href="https://docs.djangoproject.com/en/3.1/releases/3.1/">official release notes</a> are the canonical reference, but this post will cover some of the highlights as well as tips for upgrading.</p>
<h2>How to Upgrade</h2>
<p>You really should strive to be on the latest version of both Django and Python. This will result in faster, more supported, and feature-laden code. To upgrade, create a new virtual environment, install Django 3.1, and run your test suite (you have one, yes?) by adding the <code>-Wa</code> flag to show full deprecation warnings. </p>
<div><pre><span></span><span>(env) $ python -Wa manage.py test</span>
</pre></div>
<p>If you don't have tests in your project yet, you can still use <code>python -Wa manage.py runserver</code> to see some warnings. Refer to the <a href="https://docs.djangoproject.com/en/3.1/howto/upgrade-version/">official upgrade list</a> for more advice. </p>
<p>Django 3.1 requires Python 3.6, 3.7, or 3.8. You can read more about supported Python versions on the <a href="https://docs.djangoproject.com/en/3.1/faq/install/#what-python-version-can-i-use-with-django">Django prerequisites page</a>. If you're curious about Django's version and release policy, the <a href="https://www.djangoproject.com/download/">download page</a> shows the supported versions timeline and future LTS (long-term support) releases.</p>
<p>For further context, the Django Chat podcast co-hosted by Django Fellow Carlton Gibson has episodes on <a href="https://djangochat.com/episodes/django-versions">Django Versions</a> and <a href="https://djangochat.com/episodes/security-releases">Django Security Releases</a>.</p>
<h2>Asynchronous Views, Middleware, Tests</h2>
<p>With version 3.0, Django began its async journey in earnest with <a href="https://asgi.readthedocs.io/en/latest/">ASGI</a> support. In 3.1, Django now supports a fully asynchronous request path with views, middleware, and tests/test client.</p>
<p>A basic example, provided in the docs, is to make a request that waits for half a second and then returns a response.</p>
<div><pre><span></span><span># views.py</span>
<span>async</span> <span>def</span> <span>my_view</span><span>(</span><span>request</span><span>):</span>
    <span>await</span> <span>asyncio</span><span>.</span><span>sleep</span><span>(</span><span>0.5</span><span>)</span>
    <span>return</span> <span>HttpResponse</span><span>(</span><span>'Hello, async world!'</span><span>)</span>
</pre></div>
<p>This works whether you are running WSGI or <a href="https://asgi.readthedocs.io/en/latest/">ASGI</a> mode, which was first added in 3.0.</p>
<p>A more relevant example would be to asynchronously fetch a URL in Django using <a href="https://www.python-httpx.org/">HTTPX</a>, the next-generation version of the popular <a href="https://github.com/psf/requests">requests</a> library.</p>
<h2>Cross-db JSONField</h2>
<p>JSONField support for <a href="https://docs.djangoproject.com/en/3.1/ref/models/fields/#django.db.models.JSONField">models</a> and <a href="https://docs.djangoproject.com/en/3.1/ref/forms/fields/#django.forms.JSONField">forms</a> has now been extended to all Django-supported backends (MariaDB, MySQL, Oracle, and SQLite), not just PostgreSQL. This provides full support for <a href="https://docs.djangoproject.com/en/3.1/topics/db/queries/#querying-jsonfield">JSONField queries</a>.</p>
<div><pre><span></span><span># models.py</span>
<span>from</span> <span>django.db</span> <span>import</span> <span>models</span> 

<span>class</span> <span>SoccerInfo</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span>
    <span>data</span> <span>=</span> <span>models</span><span>.</span><span>JSONField</span><span>()</span>

<span>SoccerInfo</span><span>.</span><span>objects</span><span>.</span><span>create</span><span>(</span><span>data</span><span>=</span><span>{</span>
    <span>'team'</span><span>:</span> <span>'Liverpool'</span><span>,</span>
    <span>'coaches'</span><span>:</span> <span>[</span><span>'Klopp'</span><span>,</span> <span>'Krawietz'</span><span>],</span>
    <span>'players'</span><span>:</span> <span>{</span><span>'forwards'</span><span>:</span> <span>[</span><span>'Salah'</span><span>,</span> <span>'Firmino'</span><span>,</span> <span>'Mané'</span><span>]},</span>
<span>})</span>
<span>SoccerInfo</span><span>.</span><span>objects</span><span>.</span><span>filter</span><span>(</span>
    <span>data__team</span><span>=</span><span>'Liverpool'</span><span>,</span>
    <span>data__coaches__contains</span><span>=</span><span>'Klopp'</span><span>,</span>
    <span>data__players__has_key</span><span>=</span><span>'forwards'</span><span>,</span>
<span>)</span><span>.</span><span>delete</span><span>()</span>
</pre></div>
<h2>Admin Layout</h2>
<p>The admin now has a sidebar on the lefthand side for easier naviation on large screens. The historical breadcrumbs pattern is still available. If you'd like to disable the new sidebar, set <a href="https://docs.djangoproject.com/en/3.1/ref/contrib/admin/#django.contrib.admin.AdminSite.enable_nav_sidebar">AdminSite.enable_nav_sidebar</a> to <code>False</code>.</p>
<p>Here is the older admin view:</p>
<p><img src="https://learndjango.com/static/images/tutorials/django31/admin_30.png" alt="3.0 Admin"></p>
<p>And here is the new admin view with sidebar:</p>
<p><img src="https://learndjango.com/static/images/tutorials/django31/admin_31.png" alt="3.1 Admin"></p>
<h2>pathlib</h2>
<p>Django has switched from using <a href="https://docs.python.org/3.8/library/os.path.html">os.path</a> to the more modern and concise <a href="https://docs.python.org/3/library/pathlib.html">pathlib</a>. If you create a new project using the <code>startproject</code> command, the automatically generated <code>settings.py</code> file now defaults to <code>pathlib</code>.</p>
<p>Here is the Django 3.0 version:</p>
<div><pre><span></span><span># settings.py</span>
<span>import</span> <span>os</span>

<span>BASE_DIR</span> <span>=</span> <span>os</span><span>.</span><span>path</span><span>.</span><span>dirname</span><span>(</span><span>os</span><span>.</span><span>path</span><span>.</span><span>dirname</span><span>(</span><span>os</span><span>.</span><span>path</span><span>.</span><span>abspath</span><span>(</span><span>__file__</span><span>)))</span>

<span>DATABASES</span> <span>=</span> <span>{</span>
    <span>'default'</span><span>:</span> <span>{</span>
        <span>'ENGINE'</span><span>:</span> <span>'django.db.backends.sqlite3'</span><span>,</span>
        <span>'NAME'</span><span>:</span> <span>os</span><span>.</span><span>path</span><span>.</span><span>join</span><span>(</span><span>BASE_DIR</span><span>,</span> <span>'db.sqlite3'</span><span>),</span>
    <span>}</span>
<span>}</span>
</pre></div>
<p>And here is the newer Django 3.1 version:</p>
<div><pre><span></span><span># settings.py</span>
<span>from</span> <span>pathlib</span> <span>import</span> <span>Path</span>

<span>BASE_DIR</span> <span>=</span> <span>Path</span><span>(</span><span>__file__</span><span>)</span><span>.</span><span>resolve</span><span>(</span><span>strict</span><span>=</span><span>True</span><span>)</span><span>.</span><span>parent</span><span>.</span><span>parent</span>

<span>DATABASES</span> <span>=</span> <span>{</span>
    <span>'default'</span><span>:</span> <span>{</span>
        <span>'ENGINE'</span><span>:</span> <span>'django.db.backends.sqlite3'</span><span>,</span>
        <span>'NAME'</span><span>:</span> <span>BASE_DIR</span> <span>/</span> <span>'db.sqlite3'</span><span>,</span>
    <span>}</span>
<span>}</span>
</pre></div>
<h2>SECURE_REFERRER_POLICY</h2>
<p>The <a href="https://docs.djangoproject.com/en/3.1/ref/settings/#std:setting-SECURE_REFERRER_POLICY">SECURE_REFERRER_POLICY</a> now defaults to 'same-origin', which is more secure. This is one of many steps the Django team makes around security. You can--and should--run the <a href="https://docs.djangoproject.com/en/3.1/howto/deployment/checklist/">Django deployment checklist</a> to ensure your project is secure before pushing to production: <code>python manage.py check --deploy</code>.</p>
<h2>Conclusion</h2>
<p>There are many more new features, extensively documented in the <a href="https://docs.djangoproject.com/en/3.1/releases/3.1/">official release notes</a>, which are well-worth reading in full as well as the accompanying Django 3.1 documentation.</p>
<p>Every major new Django release is a team effort and 3.1 is no exception. The Django Fellows, <a href="https://twitter.com/carltongibson">Carlton Gibson</a> and <a href="https://twitter.com/MariuszFelisiak">Mariusz Feliask</a>, are resonsible for an enormous amount of work to ensure the release process occurs smoothly and on time. Particular thanks are due to <a href="https://twitter.com/andrewgodwin?">Andrew Godwin</a> for his work on async features and <a href="https://twitter.com/laymonage">Sage Abdullah</a> for adding cross-db JSONFields.</p>
<p>If you'd like to support the continued development of Django, please do so on the <a href="https://www.djangoproject.com/fundraising/">official fundraising page</a> or by becoming a <a href="https://github.com/sponsors/django">GitHub Sponsor</a>.</p>
</div></div>]]>
            </description>
            <link>https://learndjango.com/tutorials/whats-new-django-31</link>
            <guid isPermaLink="false">hacker-news-small-sites-24141190</guid>
            <pubDate>Thu, 13 Aug 2020 08:39:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Go 1.15 improved converting small integer values to interfaces]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24141174">thread link</a>) | @ngaut
<br/>
August 13, 2020 | https://utcc.utoronto.ca/~cks/space/blog/programming/Go115InterfaceSmallInts | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/programming/Go115InterfaceSmallInts">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>How Go 1.15 improved converting small integer values to interfaces</h2>

	<p><small>August 12, 2020</small></p>
</div><div><p>In Go, <a href="https://golang.org/ref/spec#Interface_types">interface values</a>
are famously implemented as a pair of pointers (see Russ Cox's <a href="https://research.swtch.com/interfaces">Go
Data Structures: Interfaces</a>);
a pointer to information about the type and a pointer to the value
itself. This generally means that the value must be dynamically
allocated in the <em>heap</em>, which means that it will contribute to the
work that Go's garbage collection does.</p>

<p>The <a href="https://golang.org/doc/go1.15">Go 1.15 release notes</a> mention
an intriguing improvement in <a href="https://golang.org/doc/go1.15#runtime">the runtime section</a>:</p>

<blockquote><p>Converting a small integer value into an interface value no longer
causes allocation.</p>
</blockquote>

<p>When I saw that, I immediately wondered how it works, and especially
if Go's runtime was now sometimes using the value pointer field in
interface values to directly store the value.
(There are a number of languages that do this, using various approaches
like <a href="https://wiki.c2.com/?TagBit">tag bits</a> to tell values from real
pointers.)</p>

<p>The answer turns out to be pretty straightforward, and is in <a href="https://go-review.googlesource.com/c/go/+/216401">Go
CL 216401</a> (merged
in <a href="https://github.com/golang/go/commit/9828c43288a53d3df75b1f73edad0d037a91dff8">this commit</a>,
which may be easier to read). The Go runtime has a special static
array of the first 256 integers (0 to 255), and when it would
normally have to allocate memory to store an integer on the heap
as part of converting it to an interface, it first checks to see
if it can just return a pointer to the appropriate element in the
array instead. This kind of static allocation of frequently used
values is common in languages with lots of dynamic allocation;
Python does something similar for small integers, for example
(<a href="https://utcc.utoronto.ca/~cks/space/blog/python/ObjectIdentityGotcha">which can sometimes surprise you</a>).</p>

<p>(It turns out that Go previously had an optimization where if you were
converting 0 to an interface value, it would return a pointer to a
special static zero value. This new optimization for 0-255 replaces
that.)</p>

<p>There is one special trick that Go plays here. The actual array is
an array of <code>uint64</code>, but it reuses the same array for smaller sized
values as well. On <a href="https://en.wikipedia.org/wiki/Endianness">little endian</a> systems like x86, this
is fine as it stands because a pointer to a 64-bit value is also a
valid pointer to that value interpreted as 32 or 16 bits (or 8
bits). But on big endian systems this isn't the case, so if Go is
running on a big endian machine it bumps up the pointer so that it
works properly (making it point to either the last two bytes or the
last four bytes of the 8-byte value).</p>

<p>(On a little endian machine, the pointer is to the low byte of the
value and the remaining bytes are all zero so it doesn't matter how
many more of them you look at. On a big endian machine, the pointer
is to the high byte, but the low byte is the thing that matters.)</p>

<p>As bonus trivia for this change, this new array of 0-255 <code>uint64</code>
values was then reused for avoiding allocating anything for one-byte
strings in another change (<a href="https://github.com/golang/go/commit/bda42a7a782dbcf4b123d617c5b60f3c848cbb82">this commit</a>,
<a href="https://go-review.googlesource.com/c/go/+/221979">CL 221979</a>).
Go previously had an array of bytes for this purpose, but why have
two arrays. Big endian machines need the same sort of pointer bumping
they did for small integers being converted to interface values,
but little endian machines can once again use the pointers as is.</p>

<p>PS: There are runtime functions for converting 16, 32, and 64 bit
values to interface values, in <a href="https://github.com/golang/go/blob/master/src/runtime/iface.go">runtime/iface.go</a>
(they can be inlined in actual code), but I was puzzled because
there is no runtime function for converting 8 bit values. It turns
out that 8-bit values are directly handled by the compiler in
<a href="https://github.com/golang/go/blob/master/src/cmd/compile/internal/gc/walk.go#L837">walk.go</a>,
where it generates inline code that uses the <code>staticuint64s</code> array.
This may be done directly in the compiler partly because it needs
no fallback path for larger values, unlike the 16, 32, and 64 bit
cases, since an 8 bit value will always be in <code>staticuint64s</code>.</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/programming/Go115InterfaceSmallInts</link>
            <guid isPermaLink="false">hacker-news-small-sites-24141174</guid>
            <pubDate>Thu, 13 Aug 2020 08:35:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stopping phishing campaigns with Bash]]>
            </title>
            <description>
<![CDATA[
Score 436 | Comments 154 (<a href="https://news.ycombinator.com/item?id=24141127">thread link</a>) | @geek_at
<br/>
August 13, 2020 | https://blog.haschek.at/2020/stopping-phishing-campaigns-with-bash.html | <a href="https://web.archive.org/web/*/https://blog.haschek.at/2020/stopping-phishing-campaigns-with-bash.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                    <div>
                        <div>
                            <div>
                            <p>A few days ago my wife got a text message that was obviously a bad phishing attempt</p>
<figure><img loading="lazy" src="https://pictshare.net/xcz7r5.jpg"><figcaption>It says: Our -bankname- system has noticed that your "pushTAN" service is not active. Click here to activate</figcaption></figure>
<p>I spun up a VM and took a look at the website it linked to, which is <a href="https://www.sso-meinelba.com/">https://www.sso-meinelba.com/</a> (almost like the real domain but with a typo) and of course it was just a copy of a banks login form that had only one change made to it.</p>
<figure><img loading="lazy" src="https://pictshare.net/0fuchr.png"><figcaption>The phishers added a "PIN" field to the logon page</figcaption></figure>
<p>The way these things work is that they act like they're the real login form, <code>steal your credentials</code> and usually send you off to the real bank so you think you made a typo or something.</p>

<p>These phishing backends are usually very simple PHP scripts that just take the data from the submitted form and save them to a file. The phishers then <a href="https://krebsonsecurity.com/2017/12/the-market-for-stolen-account-credentials/">sell them via hidden services</a> (trying real hard not to use the bullshit term <code>darknet</code> here).</p>
<p>If the phishers didn't think too hard about getting garbage data you can have a little fun and poison their loot with fake logins.</p>
<p>So with a few lines of Bash I was able to send a few thousand datapoints to their backend, filling it with garbage.</p>
<pre><code>while :; do

    # generate random numbers for login and password
    verf=$(cat /dev/urandom | tr -dc '0-9' | fold -w 7 | head -n 1)
    pin=$(cat /dev/urandom | tr -dc '0-9' | fold -w 5 | head -n 1)

    # send them to their server as your browser would
    curl 'https://www.sso-meinelba.com/files/index/identifier/verfueger/uz1.php' \
        -H 'authority: www.sso-meinelba.com' \
        -H 'origin: https://www.sso-meinelba.com' \
        -H 'content-type: application/x-www-form-urlencoded' \
        -H 'user-agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.105 Safari/537.36' \
        -H 'referer: https://www.sso-meinelba.com/files/index/identifier/verfueger/' \
        --data-raw "verfueger=Wien&amp;Verf%C3%BCgernummer=$verf&amp;Pin=$pin&amp;submit=Weiter"

    echo "Sending $verf with pin $pin"
done</code></pre>
<figure>
<video id="video" poster="https://pictshare.net/i3khmn.mp4/preview/i3khmn.mp4" preload="auto" autoplay="autoplay" controls="" muted="muted" loop="loop" webkit-playsinline="">   
    <source src="https://pictshare.net/i3khmn.mp4/raw" type="video/mp4">
</video>
<figcaption>Which was running for about half an hour until I had an idea</figcaption>
</figure>
<h2>The form was limiting my input.. but does the backend too?</h2>
<p>The phishing form limited the account number to 7 digits and the pin to 5 digits but what if I would send a bit more?</p>
<p>So I edited the script to send 256 character account numbers and passwords and then this happened.</p>
<h2>It killed their site (?)</h2>
<figure><img loading="lazy" src="https://pictshare.net/rcr9g6.png"><figcaption>The site didn't like my input</figcaption></figure>
<p>After my first request with two times 256 characters, the site went down. I'm not sure what happened and if it was a big coincidence and they took it down in the exact second I sent the large strings or I activated self destruction but since this request the site is down.</p>
<figure><img loading="lazy" src="https://pictshare.net/b71byj.png"><figcaption>Site is down now. Did I do that?</figcaption></figure>
<p>The server seems up but the content is gone.</p>
<h2>Strange things</h2>
<p>What struck me as odd was that the fake domain <code>sso-meinelba.com</code> had a valid SSL Wildcard certificate from the italian company <a href="https://www.actalis.it/">Actalis</a>. Usually phishers only get free certificates like Let's encrypt but they really seemed to have bought one. Odd</p>
<figure><img loading="lazy" src="https://pictshare.net/1fiexe.png"><figcaption>The certificate</figcaption></figure>
<p>I also noticed that the website was hosted on webx1413.aruba.it. The scammers must have rented a small VPS that hosts the scamming site</p>
<h2>How do they hide their scamming site from being detected?</h2>
<p>Remember the <code>bitly.com</code> link from the screenshot? It actually doesn't point directly to <code>sso-meinelba.com</code> but rather to a sub folder on <a href="https://kls-study.com/">https://kls-study.com</a> which is (as far as I can tell) an old homepage of the italian <a href="http://klm.education/">KLM Education</a> language school.</p>
<p>Obviously the phishers found a bug in their website and used the subdirectory <code>https://kls-study.com/redi/ccui</code> (the last part of the path seems to be random) to forward users to their phishing campaigns.</p>

<p>On the local Austrian subreddit <a href="https://www.reddit.com/r/Austria/comments/i88imh/wei%C3%9F_jemand_wieso_mir_raiffeisen_das_geschickt/">I saw a post describing a similar</a> phishing campaign and I also took a look.</p>
<p>It was the same banking login page but the backend was much more professional. It seems they actively tried to use the login credentials in the backend before saving them because after entering login data I saw this and had to laugh.</p>
<figure><img loading="lazy" src="https://pictshare.net/qm3tsb.png"><figcaption>My IP address in a subfolder called "victims"</figcaption></figure>
<p>This txt file was called once per second and it had the value <code>0</code> in it. I assume they tried to login with the credentials I entered and if it was valid, they'd forward me to the real website of the bank.</p>
<p>Sadly the server didn't enable indexing otherwise I would have seen all victims, but it was funny nonetheless.</p>
<h2>Also attacking this phishing site</h2>
<p>I saw that every request to <code>http://elba-app.com/Raiffeisen/</code> seemed to create a folder with a random string on their server. (eg <code>http://elba-app.com/Raiffeisen/f5255513e44fa68/</code>) so I thought I'd spam them again and it worked well</p>
<figure>
<video id="video2" poster="https://pictshare.net/a1s52s.mp4/preview/a1s52s.mp4" preload="auto" autoplay="autoplay" controls="" muted="muted" loop="loop" webkit-playsinline="">   
                <source src="https://pictshare.net/a1s52s.mp4/raw" type="video/mp4">
</video>
<figcaption>With every request there is a folder generated on their server</figcaption>
</figure>
<p>until</p>
<figure><img loading="lazy" src="https://pictshare.net/dj72f5.png"><figcaption>They blocked my IP</figcaption></figure>
<p>Being a sysadmin this of course is not the only IP at my disposal so I tried the BOMB request (256 instead of 7 characters) again and what happened?</p>
<figure><img loading="lazy" src="https://pictshare.net/r33l7v.png"><figcaption>Their server was not happy with my input</figcaption></figure>
<p>This time the server didn't crash or self destruct, I just seem to produce a lot of error messages on their side.</p>
<p>Also their site is a bit more complex as they don't have a single form where to post login credentials but they have 3 steps:</p>
<p><strong>Step 1:</strong>
Go to <code>http://elba-app.com/Raiffeisen</code> and the server will respond with a 302 redirect to the folder they created for you</p>
<figure><img loading="lazy" src="https://pictshare.net/jilwi2.png"><figcaption>Redirect in the location header</figcaption></figure>
<p><strong>Step 2:</strong>
They send you to a sumbit.php that only takes the account name and redirects you to</p>
<p><strong>Step 3:</strong>
Now they want your pin on <code>/hundle-pin.php</code>. I'm not sure why they did leave in that typo but here we are.</p>

<p>I made a few changes to my script to handle all 3 steps and let it run over night from a dozen different ip addresses.</p>
<p>The result? They stopped their campaign from this Domain</p>
<figure><img loading="lazy" src="https://pictshare.net/17p4v8.png"><figcaption>This phishing site is gone too</figcaption></figure>
<p><a href="https://gist.github.com/geek-at/53768c6b7aee7a973032cfb7daf65107">Here's my updated script</a> for those playing along at home</p>

<p>We saw 2 phishing attacks in different quality. Both sent out as SMS to users who are customers of the same bank.</p>
<p>I wrote a script to poison their data and got both of the sites to stop working. Great success!</p>
                            </div>
                        </div>
                    </div></article></div>]]>
            </description>
            <link>https://blog.haschek.at/2020/stopping-phishing-campaigns-with-bash.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24141127</guid>
            <pubDate>Thu, 13 Aug 2020 08:25:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I created the exact same app in React and Vue. Here are the differences]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24141081">thread link</a>) | @rocho
<br/>
August 13, 2020 | https://sunilsandhu.com/posts/i-created-the-exact-same-app-in-react-and-vue-2020-edition | <a href="https://web.archive.org/web/*/https://sunilsandhu.com/posts/i-created-the-exact-same-app-in-react-and-vue-2020-edition">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="__next"><div><div><div><p><a href="https://sunilsandhu.com/"><img src="https://sunilsandhu.com/assets/icons/home.png" alt="Home"></a></p></div></div><section><h2>2020 Edition: Now with React Hooks vs Vue 3 + Composition API!</h2><p>28th Jul, 2020</p><article><!-- ### Finally, a side-by-side code comparison between React and Vue! 🎉

Back in 2017/2018, I'd been using Vue at work quite a lot. I felt comfortable with it and had a
fairly solid understanding of how it worked. I had, however, been curious to know what the grass was
like on the other side of the fence — the grass in this scenario being React.

I’d read the React docs and watched a few tutorial videos and, while they were great and all, what I
really wanted to know was how different React was from Vue. By “different”, I didn’t mean things
such as whether they both had virtual DOMS or how they went about rendering pages. I wanted someone
to take the time to explain the code! I wanted to find an article that took the time to explain this
so that someone new to either Vue or React (or Web Development as a whole) could gain a better
understanding of the differences between the two.

Unfortunately, I couldn’t find anything that tackled this. So I came to the realisation that I would
have to go ahead and build this myself in order to see the similarities and differences. In doing
so, I thought I’d document the whole process so that an article on this will finally exist.

![Who wore it better?](/assets/post-content/i-created-the-exact-same-app-in-react-and-vue-2020-edition/react-vs-vue.png) -->
<p>A few years ago, I decided to try and build a fairly standard To Do App in React and Vue. Both apps
were built using the default CLIs (create-react-app for React, and vue-cli for Vue). My aim was to
write something that was unbiased and simply provided a snapshot of how you would perform certain
tasks with both technologies.</p>
<p>When React Hooks were released, I followed up the original article with a
'<a href="https://medium.com/javascript-in-plain-english/i-created-the-exact-same-app-in-react-and-vue-here-are-the-differences-2019-edition-42ba2cab9e56">2019 Edition</a>'
which replaced the use of Class Components with Functional Hooks. <strong>With the release of Vue version
3 and its Composition API, now is the time to one again update this article with a '2020 Edition'.</strong></p>
<h3>Let’s take a quick look at how the two apps look:</h3>
<p><img src="https://sunilsandhu.com/assets/post-content/i-created-the-exact-same-app-in-react-and-vue-2020-edition/todo-side-by-side.png" alt="React vs Vue. The Immovable Object meets the Irresistible Force!"></p>
<p>The CSS code for both apps are exactly the same, but there are differences in where these are
located. With that in mind, let’s next have a look at the file structure of both apps:</p>
<p><img src="https://sunilsandhu.com/assets/post-content/i-created-the-exact-same-app-in-react-and-vue-2020-edition/folder-structure-side-by-side.png"></p>
<p>You’ll see that their structures are similar as well. The key difference so far is that the React
app has two CSS files, whereas the Vue app doesn’t have any. The reason for this is because
create-react-app creates its default React components with a separate CSS file for its styles,
whereas Vue CLI creates single files that contain HTML, CSS, and JavaScript for its default Vue
components.</p>
<p>Ultimately, they both achieve the same thing, and there is nothing to say that you can’t go ahead
and structure your files differently in React or Vue. It really comes down to personal preference.
You will hear plenty of discussion from the dev community over how CSS should be structured,
especially with regard to React, as there are a number of CSS-in-JS solutions such as
styled-components, and emotion. CSS-in-JS is literally what it sounds like by the way. While these
are useful, for now, we will just follow the structure laid out in both CLIs.</p>
<p>But before we go any further, let’s take a quick look at what a typical Vue and React component look
like:</p>
<p><strong>A typical React file:</strong>
<img src="https://sunilsandhu.com/assets/post-content/i-created-the-exact-same-app-in-react-and-vue-2020-edition/react-todoitem.png" title="A typical React file"></p>
<p><strong>A typical Vue file:</strong>
<img src="https://sunilsandhu.com/assets/post-content/i-created-the-exact-same-app-in-react-and-vue-2020-edition/vue-todoitem.png" title="A typical Vue file"></p>
<p>Now that’s out of the way, let’s get into the nitty gritty detail!</p>
<h3>How do we mutate data?</h3>
<p>But first, what do we even mean by “mutate data”? Sounds a bit technical doesn’t it? It basically
just means changing the data that we have stored. So if we wanted to change the value of a person’s
name from John to Mark, we would be ‘mutating the data’. So this is where a key difference between
React and Vue lies. While Vue essentially creates a data object, where data can freely be updated,
React handles this through what is known as a state hook.</p>
<p>Let’s take a look at the set up for both in the images below, then we will explain what is going on
after:</p>
<p><strong>React state:</strong>
<img src="https://sunilsandhu.com/assets/post-content/i-created-the-exact-same-app-in-react-and-vue-2020-edition/react-state.png" title="React state"></p>
<p><strong>Vue state:</strong>
<img src="https://sunilsandhu.com/assets/post-content/i-created-the-exact-same-app-in-react-and-vue-2020-edition/vue-state.png" title="Vue state"></p>
<p>So you can see that we have passed the same data into both, but the structure is a bit different.</p>
<p>With React — or at least since 2019 — we would typically handle state through a series of Hooks.
These might look a bit strange at first if you haven’t seen this type of concept before. Basically,
it works as follows:</p>
<p>Let’s say we want to create a list of todos. We would likely need to create a variable called list
and it would likely take an array of either strings or maybe objects (if say we want to give each
todo string an ID and maybe some other things. We would set this up by writing
<code>const [list, setList] = useState([])</code>. Here we are using what React calls a Hook — called
<code>useState</code>. This basically lets us keep local state within our components.</p>
<p>Also, you may have noticed that we passed in an empty array <code>[]</code> inside of <code>useState()</code>. What we put
inside there is what we want list to initially be set to, which in our case, we want to be an empty
array. However, you will see from the image above that we passed in some data inside of the array,
which ends up being the initialised data for list. Wondering what setList does? There will be more
on this later!</p>
<p>In Vue, you would typically place all of your mutable data for a component inside of a <code>setup()</code>
function that returns an object with the data and functions you want to expose (which basically just
means the things you want to be able to make available for use in your app). You will notice that
each piece of state (aka the data we want to be able to mutate) data in our app is wrapped inside of
a <code>ref()</code> function. This <code>ref()</code> function is something that we import from Vue and makes it possible
for our app to update whenever any of those pieces of data are changed/updated. In short, if you
want to make mutable data in Vue, assign a variable to the <code>ref()</code> function and place any default
data inside of it.</p>
<h3>So how would we reference mutable data in our app?</h3>
<p>Well, let’s say that we have some piece of data called name that has been assigned a value of
<code>Sunil</code>.</p>
<p>In React, as we have our smaller pieces of state that we created with <code>useState()</code>, it is likely
that we would have created something along the lines of <code>const [name, setName] = useState('Sunil')</code>.
In our app, we would reference the same piece of data by calling simply calling name. Now the key
difference here is that we cannot simply write <code>name = 'John'</code>, because React has restrictions in
place to prevent this kind of easy, care-free mutation-making. So in React, we would write
<code>setName('John')</code>. This is where the setName bit comes into play. Basically, in
<code>const [name, setName] = useState('Sunil')</code>, it creates two variables, one which becomes
<code>const name = 'Sunil'</code>, while the second <code>const setName</code> is assigned a function that enables name to
be recreated with a new value.</p>
<p>In Vue, this would be sitting inside of the <code>setup()</code> function and would have been called
<code>const name = ref(‘Sunil')</code>. In our app, we would reference this by calling <code>name.value</code>. With Vue,
if we want to use the value created inside of a <code>ref()</code> function, we look for <code>.value</code> on the
variable rather than simply calling the variable. In other words, if we want the value of a variable
that holds state, we look for <code>name.value</code>, <em>not</em> <code>name</code>. If you want to update the value of <code>name</code>,
you would do so by updating <code>name.value</code>. For example, let's say that I want to change my name from
Sunil to John. I'd do this by writing <code>name.value = "John"</code>. I’m not sure how I feel about being
called John, but hey ho, things happen! 😅</p>
<p>Effectively React and Vue are doing the same thing here, which is creating data that can be updated.
Vue essentially combines its own version of name and setName by default whenever a piece of data
wrappeed inside of a <code>ref()</code> function gets updated. React requires that you call setName() with the
value inside in order to update state, Vue makes an assumption that you’d want to do this if you
were ever trying to update values inside the data object. So Why does React even bother with
separating the value from the function, and why is <code>useState()</code> even needed? Essentially, React
wants to be able to re-run certain life cycle hooks whenever state changes. In our example, if
<code>setName()</code> is called, React will know that some state has changed and can, therefore, run those
lifecycle hooks. If you directly mutated state, React would have to do more work to keep track of
changes and what lifecycle hooks to run etc.</p>
<p>Now that we have mutations out of the way, let’s get into the nitty, gritty by looking at how we
would go about adding new items to both of our To Do Apps.</p>
<h3>How do we create new To Do Items?</h3>
<h4>React:</h4>
<pre><code>const createNewToDoItem = () =&gt; {
    const newId = generateId();
    const newToDo = { id: newId, text: toDo };
    setList([...list, newToDo]);
    setToDo("");
};
</code></pre>
<h4>How did React do that?</h4>
<p>In React, our input field has an attribute on it called <strong>value. </strong>This value gets automatically
updated every time its value changes through what is known as an <strong>onChange event listener</strong>. The
JSX (which is basically a variant of HTML), looks like this:</p>
<pre><code>&lt;input
    type="text"
    placeholder="I need to..."
    value={toDo}
    onChange={handleInput}
    onKeyPress={handleKeyPress}
/&gt;
</code></pre>
<p>So every time the value is changed, it updates state. The handleInput function looks like this:</p>
<pre><code>const handleInput = (e) =&gt; {
    setToDo(e.target.value);
};
</code></pre>
<p>Now, whenever a user presses the <strong>+ </strong>button on the page to add a new item, the <strong>createNewToDoItem
</strong>function is triggered. Let’s take a look at that function again to break down what is going on:</p>
<pre><code>const createNewToDoItem = () =&gt; {
    const newId = generateId();
    const newToDo = { id: newId, text: toDo };
    setList([...list, newToDo]);
    setToDo("");
};
</code></pre>
<p>Essentially the <code>newId</code> function is basically creating a new ID that we will give to our new <code>toDo</code>
item. The <code>newToDo</code> variable is an object that takes that has an id key that is given the value from
newId. It also has a <code>text</code> key which takes the value from <code>toDo</code> as its value. That is the same
<code>toDo</code> that was being updated whenever the input value changed.</p>
<p>We then run out setList function and we pass in an array that includes our entire <code>list</code> as well as
the newly created <code>newToDo</code>.</p>
<p>If the <code>...list</code>, bit seems strange, the three dots at the beginning is something known as a spread
operator, which basically passes in all of the values from the <code>list</code> but as separate items, rather
than simply passing in an entire array of items as an array. Confused? If so, I highly recommend
reading up on spread because it’s great!</p>
<p>Anyway, finally we run <code>setToDo()</code> and pass in an empty string. This is so that our input value is
empty, ready for new toDos to be typed in.</p>
<h4>Vue:</h4>
<pre><code>function createNewToDoItem() {
    const newId = generateId();
    list.value.push({ id: newId, text: todo.value });
    todo.value = "";
}
</code></pre>
<h4>How did Vue do that?</h4>
<p>In Vue, our <strong>input</strong> field has a handle on it called <strong>v-model</strong>. This allows us to do something
known as <strong>two-way binding</strong>. Let’s just quickly look at our input field, then we’ll explain what is
going on:</p>
<pre><code>&lt;input
    type="text"
    placeholder="I need to..."
    v-model="todo"
    v-on:keyup.enter="createNewToDoItem"
/&gt;
</code></pre>
<p>V-Model ties the input of this field to a variable we created at the top of our <code>setup()</code> function
and then exposed as a key inside of the object we returned. We …</p></article></section></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sunilsandhu.com/posts/i-created-the-exact-same-app-in-react-and-vue-2020-edition">https://sunilsandhu.com/posts/i-created-the-exact-same-app-in-react-and-vue-2020-edition</a></em></p>]]>
            </description>
            <link>https://sunilsandhu.com/posts/i-created-the-exact-same-app-in-react-and-vue-2020-edition</link>
            <guid isPermaLink="false">hacker-news-small-sites-24141081</guid>
            <pubDate>Thu, 13 Aug 2020 08:15:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nintendo DS Architecture]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24141035">thread link</a>) | @charliechuck
<br/>
August 13, 2020 | https://www.copetti.org/projects/consoles/nintendo-ds/ | <a href="https://web.archive.org/web/*/https://www.copetti.org/projects/consoles/nintendo-ds/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div class="page"><nav id="navbar"></nav><div><ul><li><a href="#cover-model">Model</a></li><li><a href="#cover-motherboard">Motherboard</a></li><li><a href="#cover-diagram">Diagram</a></li></ul><div><div id="cover-motherboard"><figcaption>Showing first revision<br>Controllers are plugged using a separate daughterboard<br>Missing SRAM chips are on the back and there are four unpopulated SRAM slots</figcaption></div><div id="cover-diagram"><a href="https://www.copetti.org/images/consoles/nintendods/diagram.png"><picture>
<img alt="Diagram" src="https://www.copetti.org/images/consoles/nintendods/diagram.png" data-src="https://www.copetti.org/images/consoles/nintendods/diagram.png"></picture></a><figcaption>If you have trouble following the components: Top is only accessed by ARM9, bottom section is ARM7-only, middle section is shared</figcaption></div></div></div><hr><h2 id="a-quick-introduction">A quick introduction</h2><p>This console is an interesting answer to many needs that weren’t possible to fulfil in the handheld ecosystem. There will be some innovation and a few compromises, but this combination may pave the way for new and ingenious content.</p><hr><h2 id="cpu">CPU</h2><p>As with Nintendo’s <a href="https://www.copetti.org/projects/consoles/game-boy-advance/">previous portable console</a>, the system revolves around a big chip named <strong>CPU NTR</strong>. ‘NTR’ is shorthand for ‘Nitro’, the codename of the original Nintendo DS.</p><p>Now, CPU NTR implements an interesting multi-processor architecture using two different ARM CPUs, this design was done before ARM Holdings officially released multi-processor solutions. So, their functioning may be considered a bit unorthodox taking into account the present technology available.</p><p>While this is not the first parallel system analysed for <a href="https://www.copetti.org/projects/consoles/">this series</a>, its design is very different from the rest. For instance, we are not talking about the ‘experimental’ master-slave configuration that the <a href="https://www.copetti.org/projects/consoles/sega-saturn/">Saturn</a> debuted or the ‘co-processor’ approach found on the <a href="https://www.copetti.org/projects/consoles/playstation/">PS1</a> or <a href="https://www.copetti.org/projects/consoles/nintendo-64/">N64</a>. The Nintendo DS includes two very independent computers that will perform exclusive operations, each one having a dedicated bus. This co-dependency will condition the overall performance of this console.</p><p>That being said, let’s take a look now at the two CPUs:</p><div><ul><li id="tab-1-1-arm7tdmi-link"><a href="#tab-1-1-arm7tdmi">ARM7TDMI</a></li><li id="tab-1-2-arm946e-s-link"><a href="#tab-1-2-arm946e-s">ARM946E-S</a></li></ul><div><div id="tab-1-1-arm7tdmi"><h4>ARM7TDMI</h4><div><a href="https://www.copetti.org/images/consoles/nintendods/cpu/arm7_core.8a9851c20df1dda3c252ae75f544a8ce7a6749026fa4bc870027741cda1003b4.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/nintendods/cpu/arm7_core.8a9851c20df1dda3c252ae75f544a8ce7a6749026fa4bc870027741cda1003b4.png" data-src="https://www.copetti.org/images/consoles/nintendods/cpu/arm7_core.8a9851c20df1dda3c252ae75f544a8ce7a6749026fa4bc870027741cda1003b4.png"></picture></a><figcaption>ARM7 structure and components</figcaption></div><p>Starting with the more familiar one, the <strong>ARM7TDMI</strong> is the same CPU found on the <a href="https://www.copetti.org/projects/consoles/game-boy-advance/#cpu">GameBoy Advance</a> but now running at <strong>~34 MHz</strong> (double its original speed). It still includes all its original features (especially <a href="https://www.copetti.org/projects/consoles/game-boy-advance/#whats-new">Thumb</a>).</p><p>Now for the changes: Because Nintendo’s engineers placed the ARM7 next to most of the I/O ports, this CPU will be tasked with arbitrating and assisting I/O operations. In fact, no other processor can directly connect to the I/O. As you can see, this is not the ‘main’ processor that will be in charge of the system, but rather the ‘sub-processor’ offloading the main CPU by passing data around many components.</p></div><div id="tab-1-2-arm946e-s"><h4>ARM946E-S</h4><div><a href="https://www.copetti.org/images/consoles/nintendods/cpu/arm9_core.213329ca27287083c84d30b27fb9da63edd81998406a10b9ee7289089d0fe94d.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/nintendods/cpu/arm9_core.213329ca27287083c84d30b27fb9da63edd81998406a10b9ee7289089d0fe94d.png" data-src="https://www.copetti.org/images/consoles/nintendods/cpu/arm9_core.213329ca27287083c84d30b27fb9da63edd81998406a10b9ee7289089d0fe94d.png"></picture></a><figcaption>ARM9 structure and components</figcaption></div><p>Here is the ‘main’ CPU of the Nintendo DS running at <strong>~67 MHz</strong>. If you ignore the ill-fated ARM8 series, you could say the ARM946E-S is the ‘next-gen’ version of the ARM7. Part of the <strong>ARM9 series</strong>, this core in particular not only inherits all the features of the <strong>ARM7TDMI</strong> but also includes some additional bits:</p><ul><li>The <strong>ARMv5TE ISA</strong>: Compared to the previous v4, features some new instructions and a faster multiplier.<ul><li>If you take a look at the core name, the letter ‘E’ means <strong>Enhanced DSP</strong> which implies that lots of these new instructions have to do with applications for signal processing.</li></ul></li><li><strong>5-stage Pipeline</strong>: This is another increment from the previous 3-stage pipeline.</li><li><strong>12 KB of L1 Cache</strong>: The core now features cache, where 8 KB are allocated for instructions and 4 KB for data.</li><li><strong>48 KB of Tightly-Coupled Memory</strong> or ‘TCM’: Similar to <a href="https://www.copetti.org/projects/consoles/playstation/#cpu">Scratchpad memory</a>, however this one discriminates between instructions (32 KB) and data (16 KB).</li></ul><p>Nintendo also added the following components around it:</p><ul><li>A <strong>Divisor and Square root unit</strong> to speed up these type of operations (the ARM9 by itself is not capable of performing this type of math).</li><li>A <strong>Direct Memory Access Controller</strong>: Accelerates memory transfers without depending on the CPU. Combined with the use of cache, both CPU and DMA can potentially work concurrently.<ul><li>Cache and DMA can provide a lot of performance but also create new problems, such as data integrity. So programmers will have to manually maintain memory consistency by flushing the <a href="https://www.copetti.org/projects/consoles/playstation-2/#preventing-past-mishaps">write-buffer</a> before triggering DMA, for instance.</li></ul></li></ul></div></div></div><p>I guess with hardware like this, it’s easy to figure out the <em>real</em> reason kids loved this console, eh?</p><h4 id="interconnection">Interconnection</h4><p>So far I’ve talked about how the two CPUs work individually. But to work as a whole, they require to co-operate constantly. To accomplish this, both CPUs directly ‘talk’ to each other using a dedicated <strong>FIFO unit</strong>, this block of data holds two 64-byte queues (up to 16 elements) for <strong>bi-directional communication</strong>.</p><div><a href="https://www.copetti.org/images/consoles/nintendods/cpu/fifo.4c452b5f9236fb1e98454d2f90d2cab902ee4c561e165e8eaf8a8fc0cd7a05f4.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/nintendods/cpu/fifo.4c452b5f9236fb1e98454d2f90d2cab902ee4c561e165e8eaf8a8fc0cd7a05f4.png" data-src="https://www.copetti.org/images/consoles/nintendods/cpu/fifo.4c452b5f9236fb1e98454d2f90d2cab902ee4c561e165e8eaf8a8fc0cd7a05f4.png"></picture></a><figcaption>Representation of FIFO unit</figcaption></div><p>This works as follows: The ‘sender’ CPU (that effectively needs to send the other a message) places a 32-bit block of data in the queue, the CPU acting as a ‘receiver’ can then pull that block from the queue and perform the required operations with it.</p><p>Whenever there’s a value written on the queue, either CPU can fetch it manually (<strong>polling</strong>) however, this requires to constantly check for new values (which can be expensive). Alternatively, an <strong>interrupt unit</strong> can be activated to notify the receiver whenever there’s a new value in the queue.</p><h4 id="main-memory">Main memory</h4><p>Just like its predecessor, RAM is spread around many different locations, enabling to prioritise data placement by speed of access. In summary, we have the following general-purpose memory available:</p><div><div><a href="https://www.copetti.org/images/consoles/nintendods/cpu/ram.99e9bd12e464182ef51ea4aa89a7fc60323a46a72550afbacd737957372cf190.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/nintendods/cpu/ram.99e9bd12e464182ef51ea4aa89a7fc60323a46a72550afbacd737957372cf190.png" data-src="https://www.copetti.org/images/consoles/nintendods/cpu/ram.99e9bd12e464182ef51ea4aa89a7fc60323a46a72550afbacd737957372cf190.png"></picture></a><figcaption>RAM model of this console</figcaption></div><ul><li><strong>32 KB of WRAM</strong> (Work RAM) using a <strong>32-bit</strong> bus: To hold fast data shared between the ARM7 and ARM9.<ul><li>Bear in mind that only one CPU can access the same address at a time.</li></ul></li><li><strong>64 KB of WRAM</strong> using a <strong>32-bit</strong> bus: For fast data as well, but only accessible from the ARM7, like the GBA had.</li><li><strong>4 MB of PSRAM</strong> using a <strong>16-bit</strong> bus: A slower type, available from either CPU and it’s controlled by a memory interface unit.<ul><li>Pseudo SRAM or ‘PSRAM’ is a variant of DRAM which, by contrast, performs refreshes from within the chip. Therefore, behaving like SRAM (the faster, but more expensive alternative to DRAM). This design reminds me of <a href="https://www.copetti.org/projects/consoles/gamecube/#clever-memory-system">1T‑SRAM</a>.</li></ul></li></ul></div><h4 id="backwards-compatibility">Backwards compatibility</h4><p>Even though the architecture is significantly different from its predecessor, it still managed to maintain the critical bits that would grant it native compatibility with GameBoy Advance games.</p><p>But for the DS to revert to an ‘internal’ GBA, the former includes a set of software routines that set the console in <strong>AGB Compatibility Mode</strong>. In doing so, it effectively halts the ARM9, disables most of the ‘special’ hardware, redirects the buses, puts the ARM7 in charge and slows it down at 16.78 MHz. Finally, the ARM7 proceeds to boot the original AGB BIOS which bootstraps the GamePak cartridge (just like an original GameBoy Advance). This mode still exhibits some features not found in the original console, such as displaying the game with black margins (we’ll see in the next section that the new screen resolution happens to be bigger). Moreover, since the DS has two screens, users can set which screen will be used to display the GBA game.</p><p>Once in GBA mode <strong>there’s no going back</strong>, the console must be reset to re-activate the rest of the hardware.</p><h4 id="secrets-and-limitations">Secrets and limitations</h4><p>With so many sophisticated components fitted in a single and inexpensive chip, it’s no mystery that some issues emerged due to the way they were forced to work with each other.</p><div><ul><li id="tab-2-1-unused-power-link"><a href="#tab-2-1-unused-power">Unused Power</a></li><li id="tab-2-2-a-question-about-the-hardware-choice-link"><a href="#tab-2-2-a-question-about-the-hardware-choice">A question about the hardware choice</a></li></ul><div><div id="tab-2-1-unused-power"><h4>Unused Power</h4><p>Sometimes I wonder how Nintendo planned the way the two CPU’s would be used, and if they already assumed some performance would be hit by the design they chose.</p><p>Let me start with the ARM9, this CPU runs at twice the speed of the ARM7, but most (if not all) of the I/O depends on the ARM7, so the ARM9 is vulnerable to excessive stalling until the ARM7 answers. If that wasn’t enough, <strong>ARM9’s external bus runs at half the speed</strong>, so there are a few bottlenecks identified.</p><p>Additionally, the Main Memory bus is only <strong>16-bit wide</strong>. Thus, whenever any CPU needs to fetch a word (32-bit wide) from memory, the interface <strong>stalls the CPU</strong> (up to 3 ‘wait’ cycles) until a full world is reconstructed. The worst impact happens when memory access is not sequential, which makes it stall for every single access. This issue will also arise when instructions are fetched (unfortunately, ARM didn’t support sequential opcode fetching back then) which, to my dismay, also affects Thumb code (since every 16-bit fetch is done as a 32-bit block). On the other hand, this penalty (as some sources call it) can be alleviated by making full use of cache and TCM.</p><p>All in all, this means that in the worst case, the ‘whooping’ ARM9’s 66 MHz horsepower is practically reduced to a mere ~8&nbsp;MHz. That is if the program makes an abysmal use of cache/TCM.</p></div><div id="tab-2-2-a-question-about-the-hardware-choice"><h4>A question about the hardware choice</h4><p>Back when I read about the CPU of the GameBoy Advance, I was really surprised by the potential of the ARM7: The CPU not only performed its designated tasks, but could also assist with others, such as providing audio sequencing or pseudo-3D graphics.</p><p>Now, during the commercialisation ARM7, ARM Holdings joined forces with DEC to design a high-end version of ARM’s chips. For this, DEC grabbed the datapath design of their processor, <strong>Alpha</strong>, and mixed it with ARM’s. The result was a new series of CPUs called <strong>StrongARM</strong> which was surprisingly <em>fast</em>. At the expense of removing certain features (Thumb and debug), DEC managed to cross the megahertz threshold by reaching speeds of up to 233 MHz. As a normal user prepared to buy a new ARM PC (let’s say a <em>RiscPC</em>), you could either choose one with the old ARM710 at 40 MHz or another one with a StrongARM running ~582% faster. The impact of StrongARM was so disruptive that ARM Holdings absorbed some of StrongARMs features to produce their next line of CPUs, starting with ARM9. And the rest is history.</p><p>But here’s where my question resides: Considering the new developments in the ARM world, why did Nintendo ultimately choose an awfully slow ARM9 combined by an even slower ARM7, instead of a faster ARM9 (or even a StrongARM)? To give you an idea, other companies like Apple just adopted the StrongARM with their Newton PDA line.</p><p>I don’t mean to criticise Nintendo’s choice, but I believe the amount of emerging technology was just too great for me to ignore. I guess their choice was done in an effort to preserve battery life and maintain production costs (by using the same CPU found in the GBA).</p></div></div></div><hr><h2 id="graphics">Graph…</h2></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.copetti.org/projects/consoles/nintendo-ds/">https://www.copetti.org/projects/consoles/nintendo-ds/</a></em></p>]]>
            </description>
            <link>https://www.copetti.org/projects/consoles/nintendo-ds/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24141035</guid>
            <pubDate>Thu, 13 Aug 2020 08:05:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Proof of Work for X]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24140942">thread link</a>) | @wolframhempel
<br/>
August 13, 2020 | https://julian.digital/2020/08/06/proof-of-x/ | <a href="https://web.archive.org/web/*/https://julian.digital/2020/08/06/proof-of-x/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
 		
<p><span>01</span> Intro</p>



<p>Sparked by <a href="https://twitter.com/dwr/status/1273307320911450112">an interesting Twitter discussion</a>, I’ve spent a lot of time recently thinking about different proof-of-work mechanisms. </p>



<p>When I say proof-of-work, I’m not talking about consensus algorithms like the ones that some crypto currencies use. I’m talking about social networks.</p>



<p>At their core, social networks are primarily about one thing: Building social capital through signaling. As I wrote in <a href="http://julian.digital/2020/03/28/signaling-as-a-service/">Signaling as a Service</a>, signaling can be broken down into three different components:</p>



<ul><li><strong>Signaling Message</strong><br>A hidden status subtext you’re trying to convey about yourself</li><li><strong>Signaling Distribution</strong><br>The channel through which you’re communicating your signaling message</li><li><strong>Signaling Amplification</strong><br>Ways to boost your signaling message to compete against status rivals</li></ul>



<p>For example: A Patagonia vest signals both a prosocial attitude (<em>“I care about the environment</em>“) as well as wealth (“<em>I can afford to spend $500 on a jacket</em>“). Depending on where you live, it might also signal something about <a href="https://vcstarterkit.com/">your occupation</a>.</p>



<p><img src="https://julian.digital/wp-content/uploads/2020/07/patagucci.png"></p><p>In order to signal these messages to others and build actual social capital you need a signaling distribution channel. One option would be to wear the vest in public where others can see it – but there are obvious physical constraints to the size of the audience you’d be able to reach.</p>



<p>This is where social networks come in.</p>



<p>Their primary role is to distribute signaling messages at scale and transform them into quantifiable social capital (in the form of likes and followers).</p>



<p>As social networks grow, they increase the potential reach of your signaling messages – but they also get crowded with status rivals. This is why social networks typically provide you with a set of signaling amplification tools. These tools help you boost your signaling messages and stand out from the crowd.</p>



<p>In <a href="http://julian.digital/2020/03/28/signaling-as-a-service/">Signaling as a Service</a> I compared signaling amplification to <a href="https://www.eugenewei.com/blog/2019/2/19/status-as-a-service">Eugene Wei’s idea of proof-of-work hurdles</a>, which he describes as follows:</p>



<p><i>Almost every social network of note had an early signature proof of work hurdle. For Facebook it was posting some witty text-based status update. For Instagram, it was posting an interesting square photo. For Vine, an entertaining 6-second video. For Twitter, it was writing an amusing bit of text of 140 characters or fewer. Pinterest? Pinning a compelling photo. You can likely derive the proof of work for other networks like Quora and Reddit and Twitch and so on. Successful social networks don’t pose trick questions at the start, it’s usually clear what they want from you.</i></p>



<p>But the more I think about it, the less I like the comparison. I actually think that Eugene’s proof-of-work theory only scratches the surface of what social networks actually do.</p>



<p>Let me explain.</p>



<p><span>02</span> A closer look at proof mechanisms</p>



<p>Take a look at this very cliché Instagram picture. The photographer clearly put a lot of thought and effort into its composition and applied different filters and editing tools to make it look nicer.</p>



<figure>
<img src="https://julian.digital/wp-content/uploads/2020/08/creativework.png">
<figcaption><span>Full disclosure: I actually took this picture from Unsplash. No influencers were harmed during the production of this blog post.<br></span>
</figcaption></figure>



<p>It’s a perfect example of Eugene’s definition of proof-of-work. <br>Proof-of-<strong><em>creative</em></strong>-work, to be more exact. </p>



<p>Editing your photo helps to amplify your signaling message and sets you apart within Instagram’s status arena (aka the newsfeed). It also adds additional signaling messages to your post: <em>“Look how great a photographer I am”</em> or <em>“I’m a creative person”</em>.</p>



<p>But those are not the main signaling messages you are communicating here. What you really want to tell your followers with this photo is something along the lines of <em>“I’m a world-traveler”</em> and <em>“I’m in a happy relationship”</em> <span>(which in turn are also just signaling proxies for wealth and mating worthiness)</span>. </p>



<p>The photo and the location tag are your proof points.</p>



<figure><img src="https://julian.digital/wp-content/uploads/2020/07/igexample02-1.png">
<figcaption><span>If you look closely, you’ll notice additional hidden signaling messages in the form of Allbirds sneakers and what’s most likely a Patagonia vest → proof-of-ownership<br></span>
</figcaption></figure>



<p>Social networks are therefore not only signaling distribution (and amplification) networks – they also allow users to prove their signaling messages. </p>



<p>The creative proof-of-work is just pretext and helps to boost your post. What’s more important are the additional proof mechanisms that social networks provide. In the case of Instagram those are photos and location tags.</p>



<p>Instagram is essentially “pics or it didn’t happen”-as-a-service.</p>



<p><span>03</span> Implications for new social networks</p>



<p>When new social networks emerge they have to introduce new proof mechanisms to differentiate themselves from existing incumbents. These can either be novel proof-of-creative-work hurdles or completely new proof-of-x mechanisms.</p>



<p>TikTok is a good example for proof-of-<em>creative</em>-work innovation. The app provides creators with a powerful set of video editing tools that have opened a whole new level of creativity. </p>



<p>The cost to participate in TikTok’s status game is a lot higher than Instagram’s <span>(compare a well-made dance choreography on TikTok to your median Instagram travel post)</span> – but its powerful feed algorithms also make discovery easier and thus reward users faster and with more social capital. </p>



<p>TikTok doesn’t add any new proof points beyond its novel creative work hurdle though. You can signal and prove your creativity but you could achieve the same by uploading your video to Instagram.</p>



<p>Strava, on the other hand, introduced an entirely new proof mechanism: Proof-of-physical-activity. By using your phone’s GPS sensor (or a 3rd-party fitness tracker), users can actually prove how much and fast they ran or cycled. In contrast to <a href="https://www.telegraph.co.uk/news/2017/10/20/grounded-private-jet-hire-helps-russians-fake-lavish-lifestyles/">Instagram</a> <a href="https://www.vice.com/da/article/wdaqgw/instagrams-ballers-discount-private-jets-324">photos</a>, Strava’s proof mechanism is a lot harder to fake <span>(though there are <a href="https://www.google.com/search?q=fake+strava+5k+downhill&amp;oq=fake+strava+5k+downhill">exceptions</a>)</span>.</p>



<p><img src="https://julian.digital/wp-content/uploads/2020/08/stravaproof.png"></p><p>What’s great about Strava is that it reinforces a behavior that’s actually good for you: While the status game that initially got you into the app might be zero sum, the actual physical exercise you have to put in to compete has a very positive, compounding effect.</p>



<p>The question is: What other social networks should we build that could have similar positive feedback loops? And what are their proof mechanisms?</p>



<p><span>04</span> Strava for X</p>



<p>Let’s start with the two examples in <a href="https://twitter.com/dwr/status/1273307320911450112">this tweet</a>.</p>



<p><img src="https://julian.digital/wp-content/uploads/2020/08/tweetstrava.png"></p><p>I love the idea of a <strong>Strava for Cooking</strong> – but I’m very skeptical that it can be built. Why? Because the necessary proof mechanisms don’t exist.</p>



<p>The primary metric you optimize on when cooking is taste. But how would you measure or quantify taste? The closest proxy to taste that we have is optics: How good does the meal that you cooked look? This can easily be proved with a photo .. but that’s a proof-of-work mechanism that Instagram already offers (including filters to make your food look nicer). As long as no one comes up with a better proof mechanism for cooking, I think it’s unlikely that we will see a successful social network in the space.</p>



<p>I’m more optimistic about <strong>Strava for Learning</strong>.</p>



<p>While the activity of learning itself might be hard to quantify, you can measure the outcome of learning: knowledge. Has anyone built a multiplayer version of <a href="https://apps.ankiweb.net/">Anki</a> yet? Flash cards would be a perfect proof-of-knowledge mechanism and could easily be turned into a game where you compete against friends.</p>



<p>Similar to physical activity in the Strava example, learning is not something that most people enjoy doing. As TikTok founder <a href="https://youtu.be/wTyg2E44pBA?t=245">Alex Zhu points out</a>, education goes a little against human nature. In combination with a strong enough signaling mechanism however, you can get users to participate. It’s kind of the opposite of <a href="https://cdixon.org/2015/01/31/come-for-the-tool-stay-for-the-network">Chris Dixon’s famous “Come for the tool, stay for the network” strategy</a>. Come for the status, stay for the tool.</p>



<p>A related product I’d love to see is <strong>Strava for Reading</strong>. Imagine an eBook reader that not only tracks how much time you spend reading but also *what* you are reading. Based on these proof-of-(reading)-work mechanisms you could build streaks or GitHub-contributions-like visualizations that incentivize users to read more (and more regularly).</p>



<p><img src="https://julian.digital/wp-content/uploads/2020/07/githubforreading.png"></p><p>You could even build leaderboards for different topics based on the content of the books and articles you read. Or think about a score that indicated how balanced your reading behavior per topic was (to incentivize users to read takes on political topics from different perspectives).</p>



<p>Unfortunately, I think it’s unlikely that we will see a product like I described anytime soon. <a href="https://twitter.com/lehrjulian/status/1086659965719404544">The world’s largest bookstore, most popular eBook reader, and biggest social network for books</a> are all owned by a company that has very little competency in design and user-facing product innovation.</p>



<p>(Side note: Amazon’s monopoly on books might be the most underrated sub-optimal equilibrium in tech.)</p>



<p>Another app that would be interesting is a social investing app. Think “Robinhood but as a social network”. It seems like investing is already quite a social activity – just look at <a href="https://www.bloomberg.com/news/articles/2020-02-26/reddit-s-profane-greedy-traders-are-shaking-up-the-stock-market">communities like r/wallstreetbets</a>. As <a href="https://twitter.com/patio11/status/1250703738634829824">patio11 pointed out</a>, Robinhood already feels more like a game than a finance app.</p>



<p><img src="https://julian.digital/wp-content/uploads/2020/08/robinhood.png"></p><p>So why not build an investing app that opens with a feed of all your friends’ investments and their returns over time? Instead of sharing screenshots on Reddit and Instagram you could prove your investments right in the app.</p>



<p><strong>Note that an app like this would not be about signaling wealth. It’s about signaling <em>being right</em> and the ability to prove it</strong>. This is probably an even stronger and more engaging mechanism than signaling wealth – and the reason why I’m still bullish on prediction markets.</p>



<p>Perhaps a well-designed, consumer-friendly prediction market app would be the ultimate proof-of-x social network. <strong>Strava for being right.</strong></p>



<p><span>05</span> A Closing Ask</p>



<p>While we are on the topic of being right: Do you agree with my thoughts in this post? What other social networks and proof-of-x mechanisms would you like to see?</p>



<p>Please leave <a href="https://twitter.com/lehrjulian/status/1291397928788135942">your comments here</a>.</p>







<p><em>Thanks to <a href="https://twitter.com/dwr">Dan Romero</a>, <em><a href="https://twitter.com/destraynor">Des Traynor</a>,</em></em> <em><a href="https://twitter.com/einkoenig">Jan König</a>, <a href="https://twitter.com/cutler_max">Max …</a></em></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://julian.digital/2020/08/06/proof-of-x/">https://julian.digital/2020/08/06/proof-of-x/</a></em></p>]]>
            </description>
            <link>https://julian.digital/2020/08/06/proof-of-x/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24140942</guid>
            <pubDate>Thu, 13 Aug 2020 07:48:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Student founders are in their prime]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24140835">thread link</a>) | @rolandtshen
<br/>
August 13, 2020 | https://roland.imprint.to/post/student-founders-are-in-their-prime | <a href="https://web.archive.org/web/*/https://roland.imprint.to/post/student-founders-are-in-their-prime">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Many students don’t fathom the possibility of creating something new. Tons of great things solving real problems get built as class projects, hackathon projects, or side-projects for the sake of personal learning. Lots of these projects have tons of potential, but I don’t see enough students taking those high potential projects one step further.</p><p>I think it might be due to how clear the traditional path is. Go to school, try to achieve good grades, then do what it takes to get that job. Learn a lot of programming languages so you can slap them on the resume. Build one or two projects that could make you stand out on paper. In my view, building things not for the sake of creating something new, but to bolster one’s reputation minimizes the impact a great idea or project can deliver.</p><p>So I’m writing this article, because I believe that many student founders don’t realize the prime position they’re in. Responsibilities pile up, including studying and extracurricular involvements, but the amount of resources students have access to is crazier than many believe.</p><p>1. <strong>People love helping student founders</strong>. I talked a bit about getting past imposter syndrome yesterday, and to understand that people come from similar roots. Those in positions to help you were probably students themselves, who were looking for guidance from others too. They know that it’s hard, and are more willing than you think to lend a hand. It’s just a matter of reaching out. (If <a href="https://imprint.to/user/rz">@richard</a> could successfully cold email Mark Cuban for help, imagine how many others would be happy to help!)</p><figure><img src="https://cosmonaut-storage.s3.amazonaws.com/441594976770449_image.png"></figure><p>2. <strong>Companies love supporting students</strong>. Take advantage of all the deals and programs that companies offer! They make it super affordable (often free) to get something off the ground. Here’s a few of my favorite products with great student deals:</p><ul><li>Github Student Pack (tons of dev and SaaS tools for free)</li><li>Notion</li><li>Figma</li><li>PersistIQ</li><li>Loom</li></ul><p>3.<strong> Tons of underutilized institutions setup for student founders</strong>. Institutions are in place all over the country. Entrepreneurship organizations provide like minded students and a great place to find co-founders. Hackathons give you unlimited fuel (food + energy drinks) and an environment to build cool stuff. Keep on the lookout for on-campus accelerator programs and such too. Moral of the story, there are tons of resources out there, it's just up to you to seek them out and to take advantage while you're there.</p><p>4. <strong>Safety net</strong>. I want to note that this doesn’t apply to everyone, since different financial situations change the effect of this safety net. But I’ll say that if you’re a university student, the cost of failure won’t be as high. If you fail, you go back to focusing on classes and activities. As an adult with a family or a stable job, pursuing a startup inherently poses a higher risk. Your #1 job as a student is to learn anyway, and there’s no place you can learn more than from building something from scratch and figuring out the bits and pieces as you go.</p><p>If you’re a student who’s considering building something, go for it. And if you’ve already worked on something cool for a class or anything, think and talk to some people about the value it provides. If it’s solving a legitimate issue, then consider pumping some energy into that old project. Who knows where it could go?</p></div><div><div><p><a href="https://roland.imprint.to/">Roland's Notes</a></p><p>My thoughts, stories, and ideas</p></div></div></div>]]>
            </description>
            <link>https://roland.imprint.to/post/student-founders-are-in-their-prime</link>
            <guid isPermaLink="false">hacker-news-small-sites-24140835</guid>
            <pubDate>Thu, 13 Aug 2020 07:28:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mozilla Is Dead]]>
            </title>
            <description>
<![CDATA[
Score 65 | Comments 60 (<a href="https://news.ycombinator.com/item?id=24140547">thread link</a>) | @kowabit
<br/>
August 12, 2020 | https://kowabit.de/mozilla-is-dead/ | <a href="https://web.archive.org/web/*/https://kowabit.de/mozilla-is-dead/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-206394"><div><p><img width="720" height="250" src="https://kowabit.de/wp-content/uploads/2019/02/software.png" alt="" loading="lazy" srcset="https://kowabit.de/wp-content/uploads/2019/02/software.png 720w, https://kowabit.de/wp-content/uploads/2019/02/software-300x104.png 300w" sizes="(max-width: 720px) 100vw, 720px"></p><div><p>If the official news and the unofficial information come true, I believe that Mozilla will die. Ciao Firefox, ciao Thunderbird. Sorry. Also goodbye to all other products that nobody ordered.</p><p>In an <a href="https://blog.mozilla.org/blog/2020/08/11/changing-world-changing-mozilla/" target="_blank" rel="noopener noreferrer">official blog post</a> and an e-mail (<a href="https://blog.mozilla.org/wp-content/uploads/2020/08/Message-to-Employees-Change-in-Difficult-Times.pdf" target="_blank" rel="noopener noreferrer">PDF</a>) Mozilla announces that a quarter of the employees are to be fired. The current Corona crisis have contributed to this. However, the explanation for this action is only PR-speech. In the message to all employees there is again talk of new products and they are supposed to adopt a new way of thinking. Mozilla has often been criticized in the past. Projects like pocket, Send, Lockwise, Firefox OS were/are either born dead and/or burned a lot of money and resources. I have never met anyone in my professional life who has used the additional products or features. Honestly. Me neither.</p><p>According to unofficial information e.g. via Twitter or Github the documentation team, the Firefox engine team (Gecko) and the security team are affected (<a href="https://twitter.com/MichalPurzynski/status/1293220570885062657" target="_blank" rel="noopener noreferrer">1</a>, <a href="https://twitter.com/gcpascutto/status/1293519587967983616" target="_blank" rel="noopener noreferrer">2</a>, <a href="https://github.com/servo/servo/discussions/27575" target="_blank" rel="noopener noreferrer">3</a>, <a href="https://twitter.com/SteveALee/status/1293487542382333952" target="_blank" rel="noopener noreferrer">4</a>). In a crisis never the responsible head of an organization saying goodbye. The head that should have made its own company crisis-proof. Now the most important organs of the whole body are apparently being removed.</p><p>Which products Mozilla wants to market without these teams remains the secret of the management floor. As an administrator in the main job and helper in the private sphere for some people, Firefox as a browser can no longer be an option. The danger of unpatched security holes and lack of further development in the core area endangers the infrastructure and systems. Decision makers also have to pay attention to this when it comes to equipping company networks with software. An organization that buries the most important committees for the maintenance of its products no longer has a product.</p><p>If Mozilla wants to survive, the management will be fired with unearned compensation, the most important departments will be strengthened, products that nobody ordered will be discontinued and the organization will be limited to its core competence. Browser, email, security, adaptability and the fight for a free Internet. And they work with all their might to ensure that the products will become an integral part of everyday life and all operating systems.</p><p>Three months. That’s all the time they have for a clear signal. After that, users have to make a decision. Unfortunately, it will probably only be something with chromium.</p><p>Poor Internet.</p> <p><span>Tagged <a href="https://kowabit.de/tag/firefox/" rel="tag">Firefox</a>, <a href="https://kowabit.de/tag/gecko/" rel="tag">gecko</a>, <a href="https://kowabit.de/tag/goodbye/" rel="tag">goodbye</a>, <a href="https://kowabit.de/tag/imho/" rel="tag">imho</a>, <a href="https://kowabit.de/tag/mozilla/" rel="tag">mozilla</a>, <a href="https://kowabit.de/tag/security/" rel="tag">security</a>, <a href="https://kowabit.de/tag/thunderbird/" rel="tag">thunderbird</a></span></p></div></div></article></div>]]>
            </description>
            <link>https://kowabit.de/mozilla-is-dead/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24140547</guid>
            <pubDate>Thu, 13 Aug 2020 06:30:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Can we do better than our C compiler?]]>
            </title>
            <description>
<![CDATA[
Score 113 | Comments 54 (<a href="https://news.ycombinator.com/item?id=24139943">thread link</a>) | @signa11
<br/>
August 12, 2020 | https://briancallahan.net/blog/20200812.html | <a href="https://web.archive.org/web/*/https://briancallahan.net/blog/20200812.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
	<a name="top"></a>
	<div id="main">
	    
	    <p>academic, developer, with an eye towards a brighter techno-social life</p>
	    <hr>
		
	    <hr>
	</div>
<h5 id="prev"><a href="https://briancallahan.net/blog/20200808.html">[prev]</a></h5>
<h5 id="next">[next]</h5>
    <h2 id="title">2020-08-12: Can we do better than our C compiler?</h2>
<p>Today, I wanted to become a C compiler. I added a <a href="https://github.com/ibara/echo/blob/master/echo.s">hand-compiled assembly version of echo</a> from <a href="https://briancallahan.net/blog/20200808.html">our previous coding exercise</a> and added a new make target, <code>make asm</code>, that will assemble it. Let's look at our hand-compiled assembly and compare it to our C compiler and ask whether or not it was worth it.</p>
<h4>My hand-compiled assembly</h4>
<p>It's quite small.</p>
<pre>	.text
	.p2align 2
	.globl	main
	.type	main,@function
main:
	movq	%rdi, %r15	# Get argc from %rdi, put it in %r15
	movq	%rsi, %r14	# Get argv from %rsi, put it in %r14
loop:
	decl	%r15d		# 47: for (i = 0; i &lt; argc; i++) {
	jz	done		# Rewritten as: while (--argc) {
	addq	$8, %r14	# ++argv
	movl	$4, %eax	# Set up write(2)
	movl	$1, %edi	# First parameter is 1
	movq	(%r14), %rsi	# Second parameter is *argv
	leaq	-1(%rsi), %rdx	# Get *argv[0]
strlen:				# Note: strlen has been inlined
	cmpb	$0, 1(%rdx)	# 36: while (*t != '\0')
	leaq	1(%rdx), %rdx	# 37: t++;
	jne	strlen
	subq	%rsi, %rdx	# 39: return t - s;
	syscall			# 48: write(1, *argv, %rdx);
	cmpl	$1, %r15d	# 49: if (i + 1 != argc)
	je	done		# Rewritten as: if (argc != 1)
	movl	$4, %eax	# Set up write(2)
	movl	$1, %edi	# First parameter is 1
	movq	%r14, %rsi	# Set %rsi back to beginning of *argv
	movb	$32, (%rsi)	# Second parameter is " "
	movl	$1, %edx	# Third parameter is 1
	syscall			# 50: write(1, " ", 1);
	jmp	loop
done:
	movl	$4, %eax	# Set up write(2)
	movl	$1, %edi	# First parameter is 1
	movq	%r14, %rsi	# Set %rsi back to beginning of *argv
	movb	$10, (%rsi)	# Second parameter is "\n"
	movl	$1, %edx	# Third parameter is 1
	syscall			# 52: write(1, "\n", 1);
	xorl	%eax, %eax	# Return value is 0
	retq			# 54: return 0;
	.size	main,.-main
</pre>
<p>The whole source is annotated. Comments that begin with a number are for easy cross-referencing with our <a href="https://github.com/ibara/echo/blob/master/echo.c">C version of echo</a>.</p>
<h4>Better optimization for the C code</h4>
<p>The primary tricks are are a manual inlining of the strlen function and not needing the write and _syscall functions, instead being able to use syscall directly. We could inline strlen in the C code if we wanted, but the compiler is very likely to do that for us anyway. We probably can't avoid the write and _syscall functions in C, as we discussed previously.</p>
<p>There is also some rewriting of loops to avoid the use of variables: the <code>for (i = 0; i &lt; argc; i++)</code> is rewritten as <code>while (--argc)</code> and <code>if (i + 1 != argc)</code> becomes <code>if (argc != 1)</code>, which means that we can get rid of the <code>int i</code> variable and increment through argv with <code>++argv</code>. These changes can of course be applied to the C code as well.</p>
<p>Some other tricks include using *argv as scratch space for our space and newline characters. We don't actually care what the value of *argv is once we've written it out—we only use it the one time. So it becomes free memory space for us to overwrite it with whatever we want (as long as things fit; our space and newline characters are a single byte each so we're safe). We could do this one in C too if we wanted.</p>
<p>If we made these changes, our new main function in C might look like this.</p>
<pre>int
main(int argc, char *argv[])
{

	while (--argc) {
		++argv;
		write(1, *argv, strlen(*argv));
		if (argc != 1) {
			*argv[0] = ' ';
			write(1, *argv, 1);
		}
	}
	*argv[0] = '\n';
	write(1, *argv, 1);

	return 0;
}
</pre>
<h4>Even better assembly?</h4>
<p>If we let our C compiler (clang 10.0.0) compile this to assembly, we get the following.
</p><pre>	.text
	.file	"echo.c"
	.globl	main                    # -- Begin function main
	.type	main,@function
main:                                   # @main
# %bb.0:
	pushq	%r15
	pushq	%r14
	pushq	%r12
	movq	%rsi, %r14
	movl	%edi, %r15d
	pushq	$1
	popq	%r12
.LBB0_1:                                # =&gt;This Loop Header: Depth=1
                                        #     Child Loop BB0_3 Depth 2
	decl	%r15d
	je	.LBB0_6
# %bb.2:                                #   in Loop: Header=BB0_1 Depth=1
	movq	8(%r14), %rdi
	addq	$8, %r14
	leaq	-1(%rdi), %rsi
.LBB0_3:                                #   Parent Loop BB0_1 Depth=1
                                        # =&gt;  This Inner Loop Header: Depth=2
	cmpb	$0, 1(%rsi)
	leaq	1(%rsi), %rsi
	jne	.LBB0_3
# %bb.4:                                #   in Loop: Header=BB0_1 Depth=1
	subq	%rdi, %rsi
	callq	write
	cmpl	$1, %r15d
	je	.LBB0_1
# %bb.5:                                #   in Loop: Header=BB0_1 Depth=1
	movq	(%r14), %rax
	movb	$32, (%rax)
	movq	(%r14), %rdi
	movq	%r12, %rsi
	callq	write
	jmp	.LBB0_1
.LBB0_6:
	movq	(%r14), %rax
	movb	$10, (%rax)
	movq	(%r14), %rdi
	pushq	$1
	popq	%rsi
	callq	write
	xorl	%eax, %eax
	popq	%r12
	popq	%r14
	popq	%r15
	retq
.Lfunc_end0:
	.size	main, .Lfunc_end0-main
                                        # -- End function
	.type	write,@function         # -- Begin function write
write:                                  # @write
# %bb.0:
	movq	%rsi, %rcx
	movq	%rdi, %rdx
	pushq	$4
	popq	%rdi
	pushq	$1
	popq	%rsi
	xorl	%r8d, %r8d
	xorl	%r9d, %r9d
	jmp	_syscall                # TAILCALL
.Lfunc_end1:
	.size	write, .Lfunc_end1-write
                                        # -- End function
	.section	".note.GNU-stack","",@progbits
	.addrsig
</pre>
<p>It seems that both clang and I found very similar ways to optimize the program. According to size, I did a little bit better than clang: my hand-compiled assembly came out to a 104-byte object file whereas clang generated a very heavy 125-byte object file. When factoring in the necessary glue code (_start.s, crt,s, and _syscall.s for the C version), my hand-compiled assembly ended up 152 bytes whereas clang was a distant 197 bytes. But clang had the last laugh: running ls -l on the final binaries resulted in 848 bytes for the hand-compiled assembly and 840 bytes for clang. So there is clearly something else going on under the hood that I am losing out on with my hand-compiled assembly. Perhaps you can do better than me.</p>
<h4>Smarter than me</h4>
<p>As will come as little surprise, a production-ready compiler with large teams of developers and larger pools of money is smarter than I am. But I think I did a decent job at it. I believe that learning assembly for several different processors is worthwhile but I think I will stick to higher level languages for most of my work (unless you're paying me to do otherwise...). Because there is one cost we haven't mentioned yet: time. It took me all of 30 seconds, if that, to optimize the C code whereas it took maybe half an hour to write the assembly version.</p>
<h4>Conclusion</h4>
I enjoy assembly. I teach courses that require a deep knowledge of assembly. But I think I'm going to stick to optimizing higher level code rather than cranking out assembly by hand. Or maybe not. Even our original C code was honestly good enough. I'm glad to live in a world where we have a choice of smart compilers.
<p><a href="#top"><img alt="Top" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA4AAAAICAYAAADJEc7MAAAABmJLR0QA/wD/AP+gvaeTAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAB3RJTUUH4wkWDyUKJxzXegAAAB1pVFh0Q29tbWVudAAAAAAAQ3JlYXRlZCB3aXRoIEdJTVBkLmUHAAAAUklEQVQY02Ocd/j/fwY0kGjDwMhACPz//5/h////DPMO//8PYxODWXAZOP8Iw39k22F8uBg2G7Gx0cWYGMgEWJ2aaMPAiO5UDOcTGxjogUe2UwHwdJDZUucW5QAAAABJRU5ErkJggg=="></a></p>
<a href="https://briancallahan.net/blog/feed.xml"><img src="https://briancallahan.net/blog/media/pic_rss.gif"></a>
	<br>
	<hr>
	
    

</div>]]>
            </description>
            <link>https://briancallahan.net/blog/20200812.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24139943</guid>
            <pubDate>Thu, 13 Aug 2020 04:28:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Build a RESTful API Back End on MongoDB Using Node.js and Mongoose]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24139898">thread link</a>) | @sssaini
<br/>
August 12, 2020 | https://saasbase.dev/build-a-restful-api-backend-on-mongodb-using-nodejs-and-mongoose/ | <a href="https://web.archive.org/web/*/https://saasbase.dev/build-a-restful-api-backend-on-mongodb-using-nodejs-and-mongoose/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://saasbase.dev/content/images/size/w300/2020/07/Blog-Post-Banner-03-3.png 300w,
                            https://saasbase.dev/content/images/size/w600/2020/07/Blog-Post-Banner-03-3.png 600w,
                            https://saasbase.dev/content/images/size/w1000/2020/07/Blog-Post-Banner-03-3.png 1000w,
                            https://saasbase.dev/content/images/size/w2000/2020/07/Blog-Post-Banner-03-3.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://saasbase.dev/content/images/size/w2000/2020/07/Blog-Post-Banner-03-3.png" alt="Build a RESTful API backend on MongoDB using Node.js and Mongoose">
            </figure>

            <section>
                <div>
                    <p>MongoDB is an excellent NoSQL database. </p><p>In this tutorial, we will create an Node.js application that stores books for an established bookstore. </p><hr><h3 id="prerequisites">Prerequisites</h3><ol><li><a href="https://nodejs.org/en/download/">Node.js </a></li><li><a href="https://www.mongodb.com/try/download/community">MongoDB </a></li><li><a href="https://www.mongodb.com/products/compass">Compass for MongoDB</a></li></ol><h3 id="start-up-mongodb">Start up MongoDB</h3><p>Open up Command Prompt. Type in,</p><pre><code>mongod</code></pre><p>This will start a MongoDB server on localhost on port 27017 by default.</p><p>Open up Compass and connect to the MongoDB. It allows you to inspect the data much easier without the need of shell commands.</p><figure><img src="https://saasbase.dev/content/images/2020/07/1-3.png" alt="" srcset="https://saasbase.dev/content/images/size/w600/2020/07/1-3.png 600w, https://saasbase.dev/content/images/size/w1000/2020/07/1-3.png 1000w, https://saasbase.dev/content/images/2020/07/1-3.png 1266w" sizes="(min-width: 720px) 720px"><figcaption>Connect to Local MongoDB using Compass</figcaption></figure><h3 id="create-a-new-project">Create a new project</h3><p>Clone the simple Node.js project <a href="https://github.com/bdcorps/serve-static-website-nodejs">here</a>. </p><p>New to Node.js? Refer to this <a href="https://medium.com/@adnanrahic/hello-world-app-with-node-js-and-express-c1eb7cfa8a30">link</a> for a detailed walkthrough.</p><p>Install NPM packages,</p><pre><code>npm install body-parser express mongoose</code></pre><p>Run it locally using,</p><pre><code>node app.js</code></pre><p>Go to <a href="localhost:3000">localhost:3000</a> and "Hello World" should appear on the screen.</p><h3 id="create-the-data-model">Create the data model</h3><p>Since we're saving records of our favorite books, let's define how our <code>book</code> model.</p><p>Create a new file, <code>book/book.model.js</code></p><pre><code>var mongoose = require("mongoose");
var Schema = mongoose.Schema;

var bookSchema = new Schema({
  title: String,
  author: String,
  rating: Number,
});

var bookModel = mongoose.model("book", bookSchema, "book");

module.exports = bookModel;</code></pre><h3 id="create-the-service-layer">Create the service layer</h3><p>As part of best practices, it is always better to have a set of standardized functions like <code>createBook</code>, <code>getBooks</code> &nbsp;instead of interfacing with the model directly from the main application. This also makes it much easier to add unit tests.</p><p>Create a new file, <code>book/book.service.js</code></p><pre><code>const addBook = (Book) =&gt; (title, author, rating) =&gt; {
  if (!title || !author || !rating)
    throw new Error(
      "Missing Data. Please provide values for title, author, and rating."
    );
  const book = new Book({ title, author, rating });
  return book.save();
};

const listBooks = (Book) =&gt; () =&gt; {
  return Book.find({});
};

module.exports = (Book) =&gt; {
  return {
    addBook: addBook(Book),
    listBooks: listBooks(Book),
  };
};</code></pre><p>Create a new file, <code>book/index.js</code></p><pre><code>const Book = require("./book.model");
const BookService = require("./book.service");

module.exports = BookService(Book);</code></pre><h3 id="add-api-endpoints">Add API endpoints </h3><p>Let's set up the API endpoints that will be used to add and list books currently available in the bookstore.</p><p>Create a file called, <code>app.js</code> </p><pre><code>"use strict";
var express = require("express");
var bodyParser = require("body-parser");
var mongoose = require("mongoose");

const BookService = require("./book");

var app = express();

mongoose.Promise = global.Promise;

var uri = "mongodb://localhost:27017/bookstore";
mongoose.connect(uri, {
  useUnifiedTopology: true,
  useNewUrlParser: true,
});

app.use(
  bodyParser.urlencoded({
    extended: false,
  })
);
app.use(bodyParser.json());

app.get("/listBooks", async function (req, res, next) {
  try {
    const books = await BookService.listBooks();
    res.json(books);
  } catch (e) {
    next(e);
  }
});

app.get("/addBook", async function (req, res, next) {
  const title = req.query.title;
  const author = req.query.author;
  const rating = req.query.rating;

  try {
    const books = await BookService.addBook(title, author, rating);
    res.json(books);
  } catch (e) {
    next(e);
  }
});

app.listen(3000, "0.0.0.0", function () {
  console.log("server starting on localhost:3000");
});
</code></pre><h3 id="test-out-the-application">Test out the application</h3><p>Start the application by running,</p><figure><pre><code>node app</code></pre><figcaption>Start command for bookstore application</figcaption></figure><p>Let's open up Postman and try adding a new book. </p><figure><img src="https://saasbase.dev/content/images/2020/07/2-3.png" alt="" srcset="https://saasbase.dev/content/images/size/w600/2020/07/2-3.png 600w, https://saasbase.dev/content/images/size/w1000/2020/07/2-3.png 1000w, https://saasbase.dev/content/images/2020/07/2-3.png 1281w" sizes="(min-width: 720px) 720px"><figcaption>Adding a new book to the bookstore using Postman</figcaption></figure><p>We can open up Compass and confirm that the book record has indeed been added. </p><figure><img src="https://saasbase.dev/content/images/2020/07/3.png" alt="" srcset="https://saasbase.dev/content/images/size/w600/2020/07/3.png 600w, https://saasbase.dev/content/images/size/w1000/2020/07/3.png 1000w, https://saasbase.dev/content/images/2020/07/3.png 1266w" sizes="(min-width: 720px) 720px"></figure><p>Let's try listing all the available books.</p><figure><img src="https://saasbase.dev/content/images/2020/07/4.png" alt="" srcset="https://saasbase.dev/content/images/size/w600/2020/07/4.png 600w, https://saasbase.dev/content/images/size/w1000/2020/07/4.png 1000w, https://saasbase.dev/content/images/2020/07/4.png 1281w" sizes="(min-width: 720px) 720px"></figure><figure><a href="https://github.com/bdcorps/node-mongoose-mocha"><div><p>bdcorps/node-mongoose-mocha</p><p>Contribute to bdcorps/node-mongoose-mocha development by creating an account on GitHub.</p><p><img src="https://github.githubassets.com/favicons/favicon.svg"><span>GitHub</span></p></div><p><img src="https://avatars1.githubusercontent.com/u/6132555?s=400&amp;v=4"></p></a><figcaption>View complete source code on Github</figcaption></figure><h2 id="next-steps">Next Steps</h2><p>In this tutorial, we<a href="https://hub.docker.com/"> </a>connected our local MongoDB server to our Node.js application so we can save and read data. Add endpoints for <code>updateBook</code> and <code>deleteBook</code> to build more functionality. Add a simple HTML page that makes it easy for a user to create and list books.</p>
                </div>
            </section>

                <section>
    <h3>Subscribe to SaaSBase</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>

            


        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://saasbase.dev/build-a-restful-api-backend-on-mongodb-using-nodejs-and-mongoose/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24139898</guid>
            <pubDate>Thu, 13 Aug 2020 04:20:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Animating URL's with JavaScript and Emojis]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24139680">thread link</a>) | @os7borne
<br/>
August 12, 2020 | https://matthewrayfield.com/articles/animating-urls-with-javascript-and-emojis/ | <a href="https://web.archive.org/web/*/https://matthewrayfield.com/articles/animating-urls-with-javascript-and-emojis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">
            <div id="main">
                
                <h4>by <a href="http://matthewrayfield.com/">Matthew Rayfield</a> on January 17th 2019</h4>

                <p>
                    <iframe width="560" height="315" src="https://www.youtube.com/embed/4YZt4HEv48Y" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe>
                </p>

                <p>
                    You can use emoji (and other graphical unicode characters) in URLs. And wow is it great. But no one seems to do it.
                    Why? Perhaps emoji are too exotic for normie web platforms to handle? Or maybe they are avoided for fear of angering the SEO gods?
                </p>

                <p>
                    Whatever the reason, the overlapping portion on the Venn diagram of "It's Possible v.s. No One Is Doing It" is where my excitement usually lies.
                    So I decided to put a little time into the possibilities of graphical characters in URLs. Specifically, with the possibility for animating these characters by way of some Javascript.
                </p>

                <h2>Loopin'</h2>

                <p>
                    First off, make sure your page's Javascript code is being labelled as UTF-8 or you're gonna have a bad time putting emoji in your code at all. This can be accomplished via an HTTP header, or page META tag. There's a good chance you don't have to worry about this. But you can find more info about this here: <a href="https://flaviocopes.com/javascript-unicode/" target="_none">Unicode in Javascript by Flavio</a>
                </p>

                <p>
                    To achieve our desired outcome of emoji dancing like sugar plum fairies in our address bar, we need a loop.
                    And really, all we need is a loop. We start the loop, it loops, and we're happy. So here's our first loop, a spinning emoji moon.
                    I think when they added this sequence of emoji they must have had this in mind right?
                </p>

                <p><img src="https://matthewrayfield.com/articles/animating-urls-with-javascript-and-emojis/moon.gif"></p>

                <pre>var f = ['🌑', '🌒', '🌓', '🌔', '🌝', '🌖', '🌗', '🌘'];

    function loop() {
        location.hash = f[Math.floor((Date.now()/100)%f.length)];

        setTimeout(loop, 50);
    }

    loop();</pre>
                <p><label for="moon-check">Run Moon Code:</label> </p>

                <p>
                    You can click the toggle checkbox above to see the result of this loop in your URL bar.
                </p>

                <p>
                    If you don't like the spinning moons you can swap out that array with whatever emojis you want. Like a clock:
                </p>

                <p><img src="https://matthewrayfield.com/articles/animating-urls-with-javascript-and-emojis/clock.gif"></p>

                <pre>var f = ['🕐','🕑','🕒','🕓','🕔','🕕','🕖','🕗','🕘','🕙','🕚','🕛'];</pre>
                <p><label for="clock-check">Run Clock Code:</label> </p>

                <p>
                    This is a real simple example. Too simple really. So let's upgrade our loop so that it generates a string of multiple emoji! This time we're utilizing the emoji "skin tone modifiers" characters to make some color-changing babies:
                </p>

                <p><img src="https://matthewrayfield.com/articles/animating-urls-with-javascript-and-emojis/babies2.gif"></p>

                <pre>var e = ['🏻', '🏼', '🏽', '🏾', '🏿'];

    function loop() {
        var s = '',
            i, m;

        for (i = 0; i &lt; 10; i ++) {
            m = Math.floor(e.length * ((Math.sin((Date.now()/100) + i)+1)/2));
            s += '👶' + e[m];
        }

        location.hash = s;

        setTimeout(loop, 50);
    }

    loop();</pre>
                <p><label for="babies-check">Run Babies Code:</label> </p>

                <p>
                    We use a sine wave controlled by time and position to select which color we want. This gives us a nice loopy color changing effect!
                </p>

                <p>
                    Or how about we revisit our moon spinner, spread it out, and make something resembling a loading indicator? Sure, let's do it:
                </p>

                <p><img src="https://matthewrayfield.com/articles/animating-urls-with-javascript-and-emojis/moons.gif"></p>

                <pre>var f = ['🌑', '🌘', '🌗', '🌖', '🌕', '🌔', '🌓', '🌒'],
        d = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        m = 0;

    function loop() {
        var s = '', x = 0;

        if (!m) {
            while (d[x] == 4) {
                x ++;
            }

            if (x &gt;= d.length) m = 1;
            else {
                d[x] ++;
            }
        }
        else {
            while (d[x] == 0) {
                x ++;
            }

            if (x &gt;= d.length) m = 0;
            else {
                d[x] ++;

                if (d[x] == 8) d[x] = 0;
            }
        }

        d.forEach(function (n) {
            s += f[n];
        });

        location.hash = s;

        setTimeout(loop, 50);
    }

    loop();</pre>
                <p><label for="multi-moon-check">Run Multi-Moon Code:</label> </p>

                <h2>Exploring Other Characters</h2>

                <p>
                    But it's not just emoji that give us a means to pump graphics out of our URL bar. There's a whole boatload of unicode characters of interest to our goals.
                </p>

                <p>
                    Particularly interesting are the <a href="https://en.wikipedia.org/wiki/Box-drawing_character" target="_none">Box-drawing Characters</a>:
                </p>

                <p><img src="https://matthewrayfield.com/articles/animating-urls-with-javascript-and-emojis/box-characters.png"></p>

                <p>
                    Many of these lend themselves better to a two dimensional output. But they're still pretty good on the single line we have to play with.
                    For instance we can make a string of multiple height varied block characters and construct a nice little wave:
                </p>

                <p><img src="https://matthewrayfield.com/articles/animating-urls-with-javascript-and-emojis/wavy.gif"></p>

                <pre>function loop() {
        var i, n, s = '';

        for (i = 0; i &lt; 10; i++) {
            n = Math.floor(Math.sin((Date.now()/200) + (i/2)) * 4) + 4;

            s += String.fromCharCode(0x2581 + n);
        }

        window.location.hash = s;

        setTimeout(loop, 50);
    }

    loop();</pre>
                <p><label for="wavy-check">Run Wavy Code:</label> </p>

                <p>
                    I liked this look so much I put it up permanently at <a href="http://wavyurl.com/" target="_none">wavyurl.com</a>.
                </p>

                <p>
                    Using the variable width characters we can even wiggle on the horizontal, creating something like a progress bar:
                </p>

                <p><img src="https://matthewrayfield.com/articles/animating-urls-with-javascript-and-emojis/progress.gif"></p>

                <pre>function loop() {
        var s = '',
            p;

        p = Math.floor(((Math.sin(Date.now()/300)+1)/2) * 100);

        while (p &gt;= 8) {
            s += '█';
            p -= 8;
        }
        s += ['⠀','▏','▎','▍','▌','▋','▊','▉'][p];

        location.hash = s;
        setTimeout(loop, 50);
    }</pre>
                <p><label for="progress-bar-check">Run Progress Bar Code:</label> </p>

                <p>
                    A progress bar huh? That's like, almost useful. Which brings me to...
                </p>

                <h2>Displaying Video Progress In The URL Bar</h2>

                <p>
                    In an attempt to reduce the frivolity in our little experiment, I came up with the idea to show a web video's progress in the URL.
                    I simply attach a function that renders our progress string to the "timeupdate" event for a video, and voila! A video progress indicator in the URL, complete with the time and duration!
                </p>

                <p><img src="https://matthewrayfield.com/articles/animating-urls-with-javascript-and-emojis/video-progress.gif"></p>

                <pre>var video;

    function formatTime(seconds) {
        var minutes = Math.floor(seconds/60),
            seconds = Math.floor(seconds - (minutes*60));

        return ('0'+minutes).substr(-2) + ':' + ('0'+seconds).substr(-2);
    }

    function renderProgressBar() {
        var s = '',
            l = 15,
            p = Math.floor(video.currentTime / video.duration * (l-1)),
            i;

        for (i = 0; i &lt; l; i ++) {
            if (i == p) s +='◯';
            else if (i &lt; p) s += '─';
            else s += '┄';
        }

        location.hash = '╭'+s+'╮'+formatTime(video.currentTime)+'╱'+formatTime(video.duration);
    }

    video = document.getElementById('video');
    video.addEventListener('timeupdate', renderProgressBar);</pre>
                <p><label for="video-progress-check">Run Video Progress Bar Code:</label> </p>

                <p>With the above checkbox checked, you can use the video below to try it out.</p>

                

                <p>
                    I rather like this lines and circle progress bar, but if you fancy some moon emoji, I've got you covered:
                </p>

                <p><img src="https://matthewrayfield.com/articles/animating-urls-with-javascript-and-emojis/video-moons.gif"></p>

                <pre>var e = ['🌑', '🌘', '🌗', '🌖', '🌕'],
        video;

    function formatTime(seconds) {
        var minutes = Math.floor(seconds/60),
            seconds = Math.floor(seconds - (minutes*60));

        return ('0'+minutes).substr(-2) + ':' + ('0'+seconds).substr(-2);
    }

    function renderProgressBar() {
        var s = '',
            c = 0,
            l = 10,
            p = Math.floor(video.currentTime / video.duration * ((l*5)-1)),
            i;

        while (p &gt;= 5) {
            s += e[4];
            c ++;
            p -= 5;
        }
        s += e[p];
        c ++;

        while (c &lt; l) {
            s += e[0];
            c ++;
        }

        location.hash = s+formatTime(video.currentTime)+'╱'+formatTime(video.duration);
    }

    video = document.getElementById('video');
    video.addEventListener('timeupdate', renderProgressBar);</pre>
                <p><label for="video-moons-check">Run Video Moons Progress Bar Code:</label> </p>

                <p>
                    Okay, calling this progress bar "useful" is a stretch. But if I squint, I can almost see a scenario where it would be useful to have this in a video sharing URL. Like YouTube has the option of creating a link to a video at a specific time. Might it not be cool to include a visual indication? Hmmm?
                </p>

                <p>
                    Maybe there is some more useful implementation of this "technology" that I haven't come up with. I'll keep thinking on that. And hey, maybe you can come up with something?
                </p>

                <h2>One Last Thing</h2>

                <p>
                    You may be wondering why I used "location.hash =" instead of the newer and shinier HTML5 History API. Two reasons. One solvable. The other less so. Both inconvenient.
                </p>

                <p>
                    Issue 1 is also a feature of the History API: It actually changes the whole URL path, not just the hash. So if I use the History API and change our page to "/🌑🌘🌗🌖🌕", it'll look nicer than having tacked on a #. But it also means my web server must be able to response to "/🌑🌘🌗🌖🌕", or the user will be out of luck if they refresh, or otherwise navigate to the modified URL. This is doable, but trickier than using "location.hash =" which doesn't require me to prepare the …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://matthewrayfield.com/articles/animating-urls-with-javascript-and-emojis/">https://matthewrayfield.com/articles/animating-urls-with-javascript-and-emojis/</a></em></p>]]>
            </description>
            <link>https://matthewrayfield.com/articles/animating-urls-with-javascript-and-emojis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24139680</guid>
            <pubDate>Thu, 13 Aug 2020 03:26:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Projecting Bitcoin’s Price with Popularity (Google Trends)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24139553">thread link</a>) | @hackernewsreadr
<br/>
August 12, 2020 | https://blogofjake.com/2020/07/31/projecting-bitcoins-price-with-popularity-google-trends/ | <a href="https://web.archive.org/web/*/https://blogofjake.com/2020/07/31/projecting-bitcoins-price-with-popularity-google-trends/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p><strong><span>A Tale of Two Charts</span></strong></p>



<p>The chart below shows the monthly average <a href="https://www.coindesk.com/price/bitcoin">price of bitcoin</a> since October 2013.</p>



<figure><img data-attachment-id="1238" data-permalink="https://blogofjake.com/image-26/" data-orig-file="https://theblogofjake.files.wordpress.com/2020/07/image-26.png" data-orig-size="782,307" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-26" data-image-description="" data-medium-file="https://theblogofjake.files.wordpress.com/2020/07/image-26.png?w=300" data-large-file="https://theblogofjake.files.wordpress.com/2020/07/image-26.png?w=782" src="https://theblogofjake.files.wordpress.com/2020/07/image-26.png?w=782" alt="" srcset="https://theblogofjake.files.wordpress.com/2020/07/image-26.png 782w, https://theblogofjake.files.wordpress.com/2020/07/image-26.png?w=150 150w, https://theblogofjake.files.wordpress.com/2020/07/image-26.png?w=300 300w, https://theblogofjake.files.wordpress.com/2020/07/image-26.png?w=768 768w" sizes="(max-width: 782px) 100vw, 782px"></figure>



<p>This second chart shows the <a href="https://trends.google.com/trends/explore?date=all&amp;q=bitcoin">Google Trends Score</a> by month for the search term “bitcoin”, also since October 2013.</p>



<figure><img data-attachment-id="1239" data-permalink="https://blogofjake.com/image-27/" data-orig-file="https://theblogofjake.files.wordpress.com/2020/07/image-27.png" data-orig-size="783,307" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-27" data-image-description="" data-medium-file="https://theblogofjake.files.wordpress.com/2020/07/image-27.png?w=300" data-large-file="https://theblogofjake.files.wordpress.com/2020/07/image-27.png?w=783" src="https://theblogofjake.files.wordpress.com/2020/07/image-27.png?w=783" alt="" srcset="https://theblogofjake.files.wordpress.com/2020/07/image-27.png 783w, https://theblogofjake.files.wordpress.com/2020/07/image-27.png?w=150 150w, https://theblogofjake.files.wordpress.com/2020/07/image-27.png?w=300 300w, https://theblogofjake.files.wordpress.com/2020/07/image-27.png?w=768 768w" sizes="(max-width: 783px) 100vw, 783px"></figure>



<p>When I first saw the second chart, I thought it looked remarkably similar to the first. Sure enough, it does. Below are the two charts together. The darker line shows the price according to the left-side axis and the lighter line shows the Google Trends Score according to the right-side axis.</p>



<figure><img data-attachment-id="1240" data-permalink="https://blogofjake.com/image-28/" data-orig-file="https://theblogofjake.files.wordpress.com/2020/07/image-28.png" data-orig-size="783,306" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-28" data-image-description="" data-medium-file="https://theblogofjake.files.wordpress.com/2020/07/image-28.png?w=300" data-large-file="https://theblogofjake.files.wordpress.com/2020/07/image-28.png?w=783" src="https://theblogofjake.files.wordpress.com/2020/07/image-28.png?w=783" alt="" srcset="https://theblogofjake.files.wordpress.com/2020/07/image-28.png 783w, https://theblogofjake.files.wordpress.com/2020/07/image-28.png?w=150 150w, https://theblogofjake.files.wordpress.com/2020/07/image-28.png?w=300 300w, https://theblogofjake.files.wordpress.com/2020/07/image-28.png?w=768 768w" sizes="(max-width: 783px) 100vw, 783px"></figure>



<p>It turns out that bitcoin’s price and its Google Trends Score are quite correlated.</p>



<p>Specifically, they have had a 72% positive correlation since October 2013. This compares favorably to bitcoin’s <a href="https://cointelegraph.com/news/bitcoins-correlation-with-gold-is-weakening-says-new-kraken-report">26% correlation with the stock market and 24% correlation with gold</a> over the last year.</p>



<p>I should note that the correlation between bitcoin’s price and its Google Trends Score was much stronger up until both price and score peaked in December 2017 (98%) than it has been since (59%).</p>



<p>Nonetheless, the purpose of this analysis is not to argue about the level of correlation nor to assert causation one way or another (though it seems logical that the price and popularity feed off of each other). Rather, the purpose of this analysis is to make a speculative projection regarding what bitcoin’s price could be if and when its popularity (as measured by its Google Trends Score) returns to and surpasses its previous all-time high.</p>



<p>In order to make this projection, we first must consider the historical ratio between bitcoin’s average price and its Google Trends Score on a monthly basis. Let us refer to this as the <em><strong>price:score ratio</strong></em><strong> </strong>for short.</p>



<p><strong><span>Bitcoin’s Price:Score Ratio</span></strong></p>



<p>The chart below shows how bitcoin’s price:score ratio has increased over the last several years.</p>



<figure><img data-attachment-id="1241" data-permalink="https://blogofjake.com/image-29/" data-orig-file="https://theblogofjake.files.wordpress.com/2020/07/image-29.png" data-orig-size="783,307" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-29" data-image-description="" data-medium-file="https://theblogofjake.files.wordpress.com/2020/07/image-29.png?w=300" data-large-file="https://theblogofjake.files.wordpress.com/2020/07/image-29.png?w=783" src="https://theblogofjake.files.wordpress.com/2020/07/image-29.png?w=783" alt="" srcset="https://theblogofjake.files.wordpress.com/2020/07/image-29.png 783w, https://theblogofjake.files.wordpress.com/2020/07/image-29.png?w=150 150w, https://theblogofjake.files.wordpress.com/2020/07/image-29.png?w=300 300w, https://theblogofjake.files.wordpress.com/2020/07/image-29.png?w=768 768w" sizes="(max-width: 783px) 100vw, 783px"></figure>



<p>For a ratio that has been relatively volatile historically, it has remained unusually consistent for the last two months (June &amp; July) at 729, just 4% short of its all-time high of 758 in November 2019.</p>



<p>Bitcoin’s price:score ratio has been above 645 for 9 of the last 12 months after having only reached such a level once before, and barely (646 in October 2018).</p>



<p>The 3 months in the last year during which the ratio was lower than 645 can be fairly easily explained. They took place this past March, April, and May as hype grew in anticipation of bitcoin’s once every four years halving event on May 11, 2020. Additionally, people perhaps were searching more than usual for information about alternative assets (including bitcoin) when the stock market crashed ~30% in the early days of the lockdown resulting from the pandemic. Those two factors together seem sufficient to explain the uptick in bitcoin’s Google Trends Score over that period. On the other side of the price:score ratio, bitcoin’s price fell along with the market, and so with the price going down and the score going up, the decreased price:score ratio over those few months makes sense.</p>



<p>Since the stock market substantially recovered and the halving event came and went without materially moving bitcoin’s price, the Google Trends Score has returned to the pre-pandemic, pre-halving-hype range. For the last two months (June &amp; July), bitcoin’s monthly Google Trends Score has stayed steady at 13, which is equal to its average from April 2018 (after the peak) through February 2020 (before the halving hype and market crash).</p>



<p>For some additional context, it should be noted that bitcoin’s Google Trends Score has only been equal to or greater than 21 in 7 months since bitcoin’s inception and they all took place consecutively surrounding bitcoin’s last major surge from September 2017 through March 2018 (with scores chronologically of 21, 22, 44, 100, 55, 39, and 23).</p>



<p><strong><span>Flying Under The Radar</span></strong></p>



<p>Sufficed to say, bitcoin’s average score of 13 since the last surge, excluding the three aforementioned months from earlier this year (14 if we include them), shows objectively that bitcoin is flying under the radar (in terms of its popularity as a search term at least). Of course, it may not seem this way to people who follow crypto closely and daily but the algorithmic and mass-data collecting Google Trends Score should be trusted over any single person’s speculative and subjective observation about the current level of hype and attention.</p>



<p>If you, like me, believe that bitcoin is and has been flying under the radar for more than two years now, the natural question to ask is this. What do we expect to happen when that is no longer the case? In other words, what happens to bitcoin’s price if and when it reaches the pinnacle of its next hype cycle? How high might bitcoin fly the next time we see a situation similar to that of December 2017?</p>



<p><strong><span>Projecting Bitcoin’s Price</span></strong></p>



<p>I believe a reasonable response to this question can be made by applying bitcoin’s average price:score ratio over the last twelve months (643) to a Google Trends Score of 100 to estimate what bitcoin’s price would be if the price:score ratio stays about constant and bitcoin’s popularity in terms of search returns to its all-time high. The price implied by this projection is about $65,000 as is demonstrated by the maximum value in the top right corner of the chart below. Basically, if one believes that bitcoin will at least at some point return to the level of popularity it attained in December 2017, this methodology would lead that person to expect bitcoin to attain a price of at least $60,000 at that time.</p>



<figure><img data-attachment-id="1242" data-permalink="https://blogofjake.com/image-30/" data-orig-file="https://theblogofjake.files.wordpress.com/2020/07/image-30.png" data-orig-size="783,308" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-30" data-image-description="" data-medium-file="https://theblogofjake.files.wordpress.com/2020/07/image-30.png?w=300" data-large-file="https://theblogofjake.files.wordpress.com/2020/07/image-30.png?w=783" src="https://theblogofjake.files.wordpress.com/2020/07/image-30.png?w=783" alt="" srcset="https://theblogofjake.files.wordpress.com/2020/07/image-30.png 783w, https://theblogofjake.files.wordpress.com/2020/07/image-30.png?w=150 150w, https://theblogofjake.files.wordpress.com/2020/07/image-30.png?w=300 300w, https://theblogofjake.files.wordpress.com/2020/07/image-30.png?w=768 768w" sizes="(max-width: 783px) 100vw, 783px"></figure>



<p>This estimate can be made less conservative in two ways. The first is to assume that the price:score ratio will continue to increase as it has all along (6% month-over-month), rather than calculating the price using the LTM average of the ratio. The second is to assume that bitcoin’s popularity as a search term will well surpass its previous all-time high set in December 2017 just as that all-time was more than twice as great as any high before it and more than 8 times greater than the all-time high before May 2017 (which was set in December 2013, perhaps not coincidentally exactly 4 years or one halving period prior to the latest all-time high). I hesitate to call either of these two less conservative assumptions aggressive because they are not only reasonable but actually probable if one is to simply assume that the historical trends will continue in terms of the score and the ratio.</p>



<p>As such, I will close by presenting a chart which one can use to approximate the price implied by their own inputs for the Google Trends Score and the price:score ratio. In this chart, I show the ratio for the last 12 months, 2 years, 3 years, and so on, and use the average year-over-year growth rate between those figures (16%) to project the next twelve months (“NTM”), next two years (“N2Y”), and next three years (“N3Y”) ratios.</p>



<p>The highest price projected on the chart is right around $300,000 based on a Google Trends Score of 3 times the previous all-time high (300) and a projected N3Y price:score ratio of 996 (the LTM average of 643 increased 16% 3 times for 3 years). Of course, this maximum price projection is limited only arbitrarily by the maximums I have decided to present on this chart for both the score and the ratio.</p>



<figure><img data-attachment-id="1243" data-permalink="https://blogofjake.com/image-31/" data-orig-file="https://theblogofjake.files.wordpress.com/2020/07/image-31.png" data-orig-size="783,306" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-31" data-image-description="" data-medium-file="https://theblogofjake.files.wordpress.com/2020/07/image-31.png?w=300" data-large-file="https://theblogofjake.files.wordpress.com/2020/07/image-31.png?w=783" src="https://theblogofjake.files.wordpress.com/2020/07/image-31.png?w=783" alt="" srcset="https://theblogofjake.files.wordpress.com/2020/07/image-31.png 783w, https://theblogofjake.files.wordpress.com/2020/07/image-31.png?w=150 150w, https://theblogofjake.files.wordpress.com/2020/07/image-31.png?w=300 300w, https://theblogofjake.files.wordpress.com/2020/07/image-31.png?w=768 768w" sizes="(max-width: 783px) 100vw, 783px"></figure>



<p><strong><span>To Be Continued…</span></strong></p>



<p>Many people have employed many methodologies in attempting to accurately project bitcoin’s price. For example, <a href="https://medium.com/@100trillionUSD">PlanB</a>‘s stock to flow ratio looks at scarcity to make one of the more convincing price projections I’ve seen. My price:score ratio looks at popularity in endeavoring to do the same. This analysis was not intended to be totally comprehensive. My intention was merely to introduce this methodology for others to critique. As such, my hope is that this becomes widely enough read so that I may receive ample critical feedback for further consideration and refinement of the methodology.</p>



<p><em>As always, I welcome all outreach to jake@blogofjake.com and any comments on Twitter <a href="https://twitter.com/blogofjake">@blogofjake</a></em></p>
	</div></div>]]>
            </description>
            <link>https://blogofjake.com/2020/07/31/projecting-bitcoins-price-with-popularity-google-trends/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24139553</guid>
            <pubDate>Thu, 13 Aug 2020 03:00:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Brief Overview of Support Vector Machines (SVM)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24139506">thread link</a>) | @dhanfordata
<br/>
August 12, 2020 | https://www.iunera.com/kraken/fabric/support-vector-machines-svm/ | <a href="https://web.archive.org/web/*/https://www.iunera.com/kraken/fabric/support-vector-machines-svm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-colibri-id="23-m11"><div><p>In the domain of Statistics and <a href="https://www.iunera.com/kraken/fabric/data-science/">Machine Learning</a>, some many different methods and techniques could<a rel="noreferrer noopener" href="https://www.iunera.com/kraken/fabric/data-science/"></a> be used in a separate area of interest.<strong> Classification</strong> and <strong>Regression </strong>with <a href="https://www.iunera.com/kraken/fabric/support-vector-machines-svm/">Support Vector Machines (SVM) and Support Vector Regression (SVR)</a> is an approach whereby a certain amount of input data is fed into a computer model. The Support Vector Machines (SVM) and Support Vector Regression (SVR) model tries to learn the features of the input data to classify and predict new observations with some form of confidence based on the data that the algorithm is trained on.</p><p>The input dataset could vary from images, videos, text, languages, documents, <a href="https://www.iunera.com/kraken/fabric/time-series/">time-series data</a> and so on. These input data are then fed into computer models where specific algorithms are applied to perform the classification and produce an output. In most cases, the outputs will be a <strong>vector of probabilities</strong>.</p><figure><img src="https://www.iunera.com/wp-content/uploads/image-18-1024x597.png?v=1596605766" alt="Separation of 2 different spaces similar to Support Vector Machines" srcset="https://www.iunera.com/wp-content/uploads/image-18-1024x597.png?v=1596985240 1024w, https://www.iunera.com/wp-content/uploads/image-18-300x175.png?v=1596985240 300w, https://www.iunera.com/wp-content/uploads/image-18-768x447.png?v=1596985240 768w, https://www.iunera.com/wp-content/uploads/image-18.png?v=1596985240 1332w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="//www.iunera.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://www.iunera.com/wp-content/uploads/image-18-1024x597.png?v=1596605766" data-srcset="https://www.iunera.com/wp-content/uploads/image-18-1024x597.png?v=1596985240 1024w, https://www.iunera.com/wp-content/uploads/image-18-300x175.png?v=1596985240 300w, https://www.iunera.com/wp-content/uploads/image-18-768x447.png?v=1596985240 768w, https://www.iunera.com/wp-content/uploads/image-18.png?v=1596985240 1332w"><figcaption>A boundary between 2 different spaces similar to classification. Source: <a href="https://unsplash.com/@markusspiske" target="_blank" rel="noreferrer noopener">Markus Spiske</a></figcaption></figure><p>Noble classifications algorithms make it possible to perform this. Below listed are some of the popular ones that are commonly used in the industry and researchers in the application:</p><ul><li>Decision Trees</li><li>k Nearest Neighbour (k-NN)</li><li>Artificial Neural Networks (ANN)</li><li><strong>Support Vector Machines</strong> <strong>(SVM)</strong></li><li>Random Forest</li><li>Clustering</li><li>Binary Tree</li><li><em>and others</em></li></ul><h2 id="0-support-vector-machines-svm">Support Vector Machines (SVM)</h2><p>Before getting into SVR, let’s understand the basics of how SVM works. SVM is a supervised <a href="https://www.iunera.com/kraken/fabric/data-science/">Machine Learning algorithm</a> that is used in many classifications and regression problems. It still presents as one of the most used robust prediction methods that can be applied to many use cases involving classifications.</p><p>Support vector machine works by finding an optimal separation line called a ‘hyperplane’ to accurately separate 2 or more different classes in a classification problem. The goal is to find the <strong>optimal hyperplane</strong> separation through training the linearly separable data with the SVM algorithm.</p><p>More formally, the algorithm (SVM) creates a hyperplane that is of higher dimensional space (if not linearly separable) which will aid in the classification, outlier detection, regression and so on. A good separation of classes is achieved by having a hyperplane that has the <a href="https://en.wikipedia.org/wiki/Support_vector_machine" target="_blank" rel="noreferrer noopener">largest distance to the nearest training</a> data points.</p><figure><img src="https://www.iunera.com/wp-content/uploads/image-15.png" alt="How SVM can be used to separate 2 different classes" srcset="https://www.iunera.com/wp-content/uploads/image-15.png?v=1597286859 892w, https://www.iunera.com/wp-content/uploads/image-15-300x188.png?v=1597286859 300w, https://www.iunera.com/wp-content/uploads/image-15-768x480.png?v=1597286859 768w, https://www.iunera.com/wp-content/uploads/image-15-320x200.png?v=1597286859 320w" sizes="(max-width: 892px) 100vw, 892px" data-old-src="//www.iunera.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://www.iunera.com/wp-content/uploads/image-15.png" data-srcset="https://www.iunera.com/wp-content/uploads/image-15.png?v=1597286859 892w, https://www.iunera.com/wp-content/uploads/image-15-300x188.png?v=1597286859 300w, https://www.iunera.com/wp-content/uploads/image-15-768x480.png?v=1597286859 768w, https://www.iunera.com/wp-content/uploads/image-15-320x200.png?v=1597286859 320w"><figcaption>2 classes Class 1 and Class 6 are linearly separable which can be classified using SVM. Source: Own Image</figcaption></figure><h2 id="1-support-vectors-">Support Vectors</h2><p>Support vectors, on the other hand, are the points that lie the closest to the hyperplane between the 2 or more classes. These are the <strong>data points that are the most difficult to classify</strong>. In general, the larger the margin or distance between the support vectors, the easier it is for the algorithm to classify accurately. Hence, once the hyperplane is optimised, it is said to be the optimal separation or the maximum <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Margin_classifier" target="_blank">margin classifier</a>.</p><figure><img src="https://www.iunera.com/wp-content/uploads/image-16-1024x756.png?v=1596602837" alt="Support Vectors are the data points that are the hardest to classify" srcset="https://www.iunera.com/wp-content/uploads/image-16-1024x756.png?v=1596613714 1024w, https://www.iunera.com/wp-content/uploads/image-16-300x222.png?v=1596613714 300w, https://www.iunera.com/wp-content/uploads/image-16-768x567.png?v=1596613714 768w, https://www.iunera.com/wp-content/uploads/image-16.png?v=1596613714 1086w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="//www.iunera.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://www.iunera.com/wp-content/uploads/image-16-1024x756.png?v=1596602837" data-srcset="https://www.iunera.com/wp-content/uploads/image-16-1024x756.png?v=1596613714 1024w, https://www.iunera.com/wp-content/uploads/image-16-300x222.png?v=1596613714 300w, https://www.iunera.com/wp-content/uploads/image-16-768x567.png?v=1596613714 768w, https://www.iunera.com/wp-content/uploads/image-16.png?v=1596613714 1086w"><figcaption>Support Vector and Margin between 2 classes (Red and Blue). Source: <a href="http://peterwooldridge.me/svm_1.html" target="_blank" rel="noreferrer noopener">SVM</a></figcaption></figure><h2 id="2-linear-classification">Linear Classification</h2><p>Linear SVM can be applied on a linearly separable data. In a linearly separable data, a straight line function can be drawn to separate all the items in class A and class B.</p><figure><img src="https://www.iunera.com/wp-content/uploads/image-19.png" alt="A straight line function " srcset="https://www.iunera.com/wp-content/uploads/image-19.png?v=1596985684 898w, https://www.iunera.com/wp-content/uploads/image-19-300x229.png?v=1596985684 300w, https://www.iunera.com/wp-content/uploads/image-19-768x585.png?v=1596985684 768w" sizes="(max-width: 898px) 100vw, 898px" data-old-src="//www.iunera.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://www.iunera.com/wp-content/uploads/image-19.png" data-srcset="https://www.iunera.com/wp-content/uploads/image-19.png?v=1596985684 898w, https://www.iunera.com/wp-content/uploads/image-19-300x229.png?v=1596985684 300w, https://www.iunera.com/wp-content/uploads/image-19-768x585.png?v=1596985684 768w"><figcaption>A straight red line (hyperplane) can be optimised to differentiate items in Class A and Class B.</figcaption></figure><blockquote><p><strong>Actually, an infinite number of hyperplanes can be drawn to separate the classes</strong> <strong>for linearly separable data</strong></p></blockquote><p>This is where the basic idea of SVM comes in play to find out the optimal hyperplane or the <strong>maximum margin classifier</strong> which is the farthest from the observations.</p><h2 id="3-non-linear-classification">Non-Linear Classification</h2><p>What happens if the data that was presented to us for classification is not linearly separable? Now, linearly separable data can be represented in a 1-dimensional plane. But that is not possible with a non-linear data.</p><p>The general idea on how to approach this <strong>is to map the original feature space to some higher-dimensional</strong> <strong>space</strong> where the training set is separable. Of course, we would want to do so in ways that preserve relevant dimensions of relatedness between data points, so that the resultant classifier should still generalize well.</p><h3 id="4-1-understanding-kernel-function-">1. Understanding Kernel Function</h3><p>Let’s recap what we have seen. In short, an SVM classifier can be solved by computing the convex <a href="http://people.csail.mit.edu/dsontag/courses/ml13/slides/lecture6.pdf" target="_blank" rel="noreferrer noopener">Lagrange</a> <a href="http://people.csail.mit.edu/dsontag/courses/ml13/slides/lecture6.pdf">dual</a> of the max-margin SVM formulation <em>(Lagrange multipliers are determined by solving the problem using&nbsp;<a href="https://www.sciencedirect.com/topics/computer-science/quadratic-programming" target="_blank" rel="noreferrer noopener">Quadratic Programming</a>)</em> where is as follows:</p><figure><img src="https://www.iunera.com/wp-content/uploads/image-22.png" alt="Lagrange Dual Equation " srcset="https://www.iunera.com/wp-content/uploads/image-22.png?v=1596985228 590w, https://www.iunera.com/wp-content/uploads/image-22-300x46.png?v=1596985228 300w" sizes="(max-width: 590px) 100vw, 590px" data-old-src="//www.iunera.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://www.iunera.com/wp-content/uploads/image-22.png" data-srcset="https://www.iunera.com/wp-content/uploads/image-22.png?v=1596985228 590w, https://www.iunera.com/wp-content/uploads/image-22-300x46.png?v=1596985228 300w"><figcaption>Lagrange Dual Equation with <em>N </em>representing number of support vectors. Source: <a href="https://www.quora.com/What-is-the-intuition-behind-Gaussian-kernel-in-SVM-How-can-I-visualize-the-transformation-function-%CF%95-that-corresponds-to-the-Gaussian-kernel-Why-is-the-Gaussian-kernel-popular" target="_blank" rel="noreferrer noopener">Quora</a></figcaption></figure><p>For a non-linear data, instead of imagining the original features of each data point, let us first consider a transformation to a new feature space where the data point has&nbsp;N&nbsp;features, one for each support-vector.</p><p>Do note that once the kernel function transformation is applied, the original features of the data point are now irrelevant. It is then represented only in terms of its dot products with support vectors (which are basically special data points chosen by the SVM optimization algorithm).</p><p>There are a couple of non-linear methods that are called <strong>kernel functions</strong> or <strong>kernel tricks</strong> which can be applied to transform the data. It is stated as below.</p><h3 id="5-2-polynomial-function-pf">2. Polynomial Function (PF)</h3><figure><img src="https://www.iunera.com/wp-content/uploads/image-20.png" alt="Polynomial Function" srcset="https://www.iunera.com/wp-content/uploads/image-20.png?v=1596985233 322w, https://www.iunera.com/wp-content/uploads/image-20-300x63.png?v=1596985233 300w, https://www.iunera.com/wp-content/uploads/image-20-320x68.png?v=1596985233 320w" sizes="(max-width: 322px) 100vw, 322px" data-old-src="//www.iunera.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://www.iunera.com/wp-content/uploads/image-20.png" data-srcset="https://www.iunera.com/wp-content/uploads/image-20.png?v=1596985233 322w, https://www.iunera.com/wp-content/uploads/image-20-300x63.png?v=1596985233 300w, https://www.iunera.com/wp-content/uploads/image-20-320x68.png?v=1596985233 320w"><figcaption>Polynomial Function. Source: <a href="https://en.wikipedia.org/wiki/Polynomial_kernel" target="_blank" rel="noreferrer noopener">Wiki</a></figcaption></figure><p>Polynomial kernel not only looks at the features of the linear input data during training to understand the similarity but also learns the <strong>interaction features </strong>that are present in polynomial regression. A polynomial regression model tries to fit a nonlinear correlation of data between the value of&nbsp;<em><strong>x</strong></em>&nbsp;and the corresponding&nbsp;<a href="https://en.wikipedia.org/wiki/Conditional_expectation" target="_blank" rel="noreferrer noopener">conditional mean</a>&nbsp;of&nbsp;<em><strong>y</strong></em>.</p><p>Polynomial kernels are quite extensively used in Natural Language Processing (NLP). You can read more on this <a href="https://www.aclweb.org/anthology/P08-2060.pdf" target="_blank" rel="noreferrer noopener">here</a>.</p><h3 id="6-3-gaussian-radial-basis-function-grbf">3. Gaussian Radial Basis Function (GRBF)</h3><p>Gaussian radial basis function is another popular method used in SVM to handle non linear data.</p><figure><img src="https://www.iunera.com/wp-content/uploads/image-21.png" alt="Gaussian Radial Basis Function" srcset="https://www.iunera.com/wp-content/uploads/image-21.png?v=1596985229 422w, https://www.iunera.com/wp-content/uploads/image-21-300x90.png?v=1596985229 300w" sizes="(max-width: 422px) 100vw, 422px" data-old-src="//www.iunera.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://www.iunera.com/wp-content/uploads/image-21.png" data-srcset="https://www.iunera.com/wp-content/uploads/image-21.png?v=1596985229 422w, https://www.iunera.com/wp-content/uploads/image-21-300x90.png?v=1596985229 300w"><figcaption><br>Radial Basis kernel. Source: <a href="https://www.quora.com/What-is-the-intuition-behind-Gaussian-kernel-in-SVM-How-can-I-visualize-the-transformation-function-%CF%95-that-corresponds-to-the-Gaussian-kernel-Why-is-the-Gaussian-kernel-popular" target="_blank" rel="noreferrer noopener">Quora</a></figcaption></figure><p>Similar to the polynomial function, RBF also <strong>performs transformations</strong> as shown in the Lagrange equation. The nominator represents the squared Euclidean distance between two data points <em>x</em> and <em>y</em>. Given that it is a Gaussian distribution function, it is computed with the maximum value of which is obtained at the support-vector, and which decays uniformly in all directions around the support vector which leads to round contour like below.</p><figure><img src="https://www.iunera.com/wp-content/uploads/image-24-1024x693.png?v=1596981619" alt="Kernal tricks applied, in this example is the Radial Basis Function" srcset="https://www.iunera.com/wp-content/uploads/image-24-1024x693.png?v=1596985225 1024w, https://www.iunera.com/wp-content/uploads/image-24-300x203.png?v=1596985225 300w, https://www.iunera.com/wp-content/uploads/image-24-768x520.png?v=1596985225 768w, https://www.iunera.com/wp-content/uploads/image-24.png?v=1596985225 1158w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="//www.iunera.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://www.iunera.com/wp-content/uploads/image-24-1024x693.png?v=1596981619" data-srcset="https://www.iunera.com/wp-content/uploads/image-24-1024x693.png?v=1596985225 1024w, https://www.iunera.com/wp-content/uploads/image-24-300x203.png?v=1596985225 300w, https://www.iunera.com/wp-content/uploads/image-24-768x520.png?v=1596985225 768w, https://www.iunera.com/wp-content/uploads/image-24.png?v=1596985225 1158w"><figcaption>The red boundary is the RBF function that is influenced by certain parameters. Source: <a href="https://chrisalbon.com/machine_learning/support_vector_machines/svc_parameters_using_rbf_kernel/" target="_blank" rel="noreferrer noopener">Chris Albon</a></figcaption></figure><p>From that point onwards, the classifier is then simply a weighted linear combination of the kernel function computed between a point and each of the support vectors.</p><p>With appropriate and optimised use of the parameters, RBF and other kernel functions guarantee a globally optimal predictor which minimises errors in a classifier.</p><h2 id="7-support-vector-regression-svr">Support Vector Regression (SVR)</h2><p>Support Vector Regression (SVR) uses mostly all the same principles as the SVM for classification. But there are some minor differences that can be explained.</p><p>While SVM is more commonly used for classification, SVR is better practised in regression problems both for linear and non-linear data. SVR has the flexibility to define <strong>how much error is tolerable in the model </strong>and only then a hyperplane will be trained to fit.</p><h3 id="8-1-classification">1. Classification</h3><p>The goal of Classification is to maximise the margin. The inspiration behind&nbsp;<strong>maximising the margin</strong>&nbsp;is that this will give us a unique solution such that two or more classes can be independently separated. Eventually, our classifier will have separated data points as far as possible from the hyperplane.</p><h3 id="9-2-regression">2. Regression</h3><p>The goal of Regression is to find a straight line function <strong>f(x) = Wx + B </strong>under the condition that the obtained <strong>f(x)</strong> value is <strong>within a certain accuracy</strong> (<strong>ɛ</strong>) of every data point. We want the data point to be as close as possible to the straight-line function.</p><h2 id="10-conclusion">Conclusion</h2><p>Classification methods such as Support Vector Machines (SVM), Support Vector Regression (SVR) and more have always been used in Machine Learning, Data Science and other applications. Let it be in the domain of Image, Text, NLP or anything, multiple algorithms could be used, and SVM/SVR is just one of them. Hence, depending on the complexity and use cases, choosing the right algorithm (and simplest) matters to save time and cost ultimately.</p><section><div><h2>Where is SVM used?</h2><p> Support vector machines are most commonly used in classification related problem whereby the algorithm is trained to provide a clear boundary between 2 or more classes.</p></div></section><section><div><h2>What are Support Vectors?</h2><p> Support vectors are simply the points that lie the closest to the hyperplane between the 2 or more classes and also are the most difficult to classify.</p></div></section><section><div><h2>How to handle non-linear data in SVM?</h2><p> For non-linear data, kernel functions or tricks can be applied such as Polynomial, Radial Basis functions.</p></div></section> </div></div></div>]]>
            </description>
            <link>https://www.iunera.com/kraken/fabric/support-vector-machines-svm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24139506</guid>
            <pubDate>Thu, 13 Aug 2020 02:52:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Much Do TikTok Biddable Ads Cost?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24139454">thread link</a>) | @WalterJT
<br/>
August 12, 2020 | https://jungletopp.com/tiktok-ads-costs/ | <a href="https://web.archive.org/web/*/https://jungletopp.com/tiktok-ads-costs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="310ca8db" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
			
<p>TikTok has quickly become the powerhouse for creators and advertisers alike. When they join together, they can create quite the profit for a brand. However, what would happen if the biddable ads on the platform came into play?&nbsp;</p>



<p>To best define biddable media, it’s when advertisers and marketers bid for paid search or paid social media spots to place their advertising. This is essentially competitive bidding for ad space, and it normally occurs in real-time. The one thing both advertisers and marketers know is that advertising/marketing in this way incorporates so much more than what one might initially expect.&nbsp;</p>



<p>One of the bigger questions for this type of platform is the cost. When it comes to any type of biddable advertising, the cost can be somewhat of a grey area. This is especially true when you look and see that not one advertising platform is the same either. By looking into TikTok ad costs in their biddable ads, we’ll search to find clarity and to find a base for marketers/advertisers to look to for reference.&nbsp;&nbsp;</p>



<h2><strong>TikTok Ads Minimum Cost&nbsp;</strong></h2>



<p>For <a href="https://jungletopp.com/tiktok-ads/">TikTok ads</a> to truly be effective, there is a set minimum budget that they require when brands choose to market or advertise on the platform. In fact, they want to make sure there is a sufficient budget at hand so that the maximum outcome can really be achieved for the brands.&nbsp;</p>



<p>With this being said, the minimum budget at the campaign level is placed at $500 while at the ad group level it’s at $50. Of course if needed, that budget can be altered, but this is the base the platform is currently comfortable with setting.</p>



<p>When looking at TikTok advertising in general, it’s not known to be the cheapest. Take a look at the following.&nbsp;</p>



<ul><li>Brand Takeover- $50,000 per day (5 million impressions guaranteed)&nbsp;&nbsp;</li><li>In-Feed- $10 per impression (minimum 600 impressions prepaid)</li><li>Hashtag Challenge- $150,000 per week&nbsp;&nbsp;&nbsp;</li></ul>



<h2><strong>What’s the Average Cost Per Click?&nbsp;</strong></h2>



<p>While all advertising budgets and outcomes are pretty different, it helps to know that there is a base that can be followed. We analyzed a budget of $50,000 and compared its usage between <a href="https://jungletopp.com/tiktok-ads-vs-facebook-ads/">Facebook, Instagram, and TikTok</a>.&nbsp;</p>



<p>In that analysis, TikTok ads actually generated 155% more clicks all while spending 36% less money. This is quite a significant difference and one to be watched for future ad campaigns.&nbsp;</p>



<p>Within that statistic, the CPC for TikTok was at a total of $0.19 while Facebook and Instagram was at a combined $0.46. For more clarity, all advertisements were run in the United States only.&nbsp;&nbsp;</p>



<h3><strong>What About Cost Per 1000 Impressions (CPM)?&nbsp;</strong></h3>



<p>Now when we look at CPM, similar results also ensue. On that same experiment, the TikTok CPM only cost $1.82 while the combined Facebook and Instagram cost for CPM is $6.73. This is a huge difference, and shows that with this particular experiment that TikTok is able to deliver more.&nbsp;</p>



<p>The total spending for this TikTok campaign ended at $20,128.11 whereas the total spending for Facebook and Instagram ended at a total of $31,615.51.&nbsp;</p>



<p>When looking at TikTok advertising in general, the rationale for this difference in cost may also rely heavily on the fact that this is a platform that has been able to command some of the highest engagement from all different users and audiences. In fact, this is an app that is the most downloaded in 2020 and has over 800 million monthly users.&nbsp;&nbsp;&nbsp;</p>



<h2><strong>Let’s Look at the Functioning and Positives of Ad Auction Work&nbsp;</strong></h2>



<p>Believe it or not, bidding is actually a strong part of the overall ad creation process. There are actually several different types of bidding that a marketer may choose from as they maneuver through the ad posting.&nbsp;</p>



<p>As of right now, these are the four different bidding methods:&nbsp;</p>



<ul><li>Cost Per Click (CPC)</li><li>Optimized Cost Per Click (oCPC)&nbsp;</li><li>Cost Per Mile/Thousand Impressions (CPM)&nbsp;</li><li>Cost Per Thousand Views (CPV)</li></ul>



<p>All four of these are able to contribute to different results from the consumer as well as give the marketer the ability to shift and alter the budget where she sees fit.&nbsp;&nbsp;&nbsp;</p>



<h2><strong>How to Determine TikTok Advertising Costs?&nbsp;</strong></h2>



<p>There are actually two different ways you can pay for advertising on TikTok by choosing from the following.&nbsp;</p>



<p><strong>Budget: </strong>There are two different budgeting options for TikTok ads. These are daily or lifetime. Marketers actually have the capability to change out the budget on their campaign at any time. Best of all, the system won’t ever exceed on the budget that’s set.&nbsp;</p>



<p><strong>Bid: </strong>On the other hand, there’s a bid that shows how much a marketer is willing to pay for the action, and we’re currently finding out how to determine the costs for it all.&nbsp;</p>



<h2><strong>How TikTok Compares to Other Platforms&nbsp;</strong></h2>



<p>While all platforms have their own strengths, TikTok has been proven to be unique and valuable in it’s own ways. According to Digiday, TikTok’s cost-per-thousand impressions are as low as $1. On Facebook, the cost has the potential to raise as high as $4 on the news feed and story formats.&nbsp;</p>



<p>This cost comparison alone makes TikTok desirable enough for consideration, especially since they’re able to provide the results to match.&nbsp;</p>



<h2><strong>Final Thoughts&nbsp;</strong></h2>



<p>TikTok biddable ads definitely have their perks, especially since the platform alone already delivers so many different and unique features. When compared to other major social media platforms such as Instagram and Facebook, it also proves to have its own strengths that don’t quite compare to the rest.&nbsp;</p>



<p>As we all watch TikTok grow and change, it can be easily understood that this isn’t a platform to come and go super quickly either. The momentum in the past year has been able to propel it far enough that it’s size and influence will not be easily diminished.&nbsp;&nbsp;&nbsp;</p>



<p>Are biddable cost ads worth it to you and your marketing/advertising campaigns? Are you planning on utilizing TikTok Ads with a <a href="https://jungletopp.com/tiktok-ads-agency/">TikTok advertising agency</a>? Let us know in the comments as we’d love to know your thoughts and actions during your campaign process.&nbsp;&nbsp;<br></p>
		</div>
				</div></div>]]>
            </description>
            <link>https://jungletopp.com/tiktok-ads-costs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24139454</guid>
            <pubDate>Thu, 13 Aug 2020 02:42:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I'm 15 and made a bedtime calculator with React JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 304 | Comments 119 (<a href="https://news.ycombinator.com/item?id=24139339">thread link</a>) | @joshternyak
<br/>
August 12, 2020 | https://www.sleepsources.com/bed-time-calculator/ | <a href="https://web.archive.org/web/*/https://www.sleepsources.com/bed-time-calculator/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.sleepsources.com/bed-time-calculator/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24139339</guid>
            <pubDate>Thu, 13 Aug 2020 02:22:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reimbursement Subscription]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24139211">thread link</a>) | @mikeberv
<br/>
August 12, 2020 | https://www.billiondollarstartupideas.com/ideas/reimbursement-subscription | <a href="https://web.archive.org/web/*/https://www.billiondollarstartupideas.com/ideas/reimbursement-subscription">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site">

      

      <main id="page" role="main" data-content-field="main-content" data-controller="FadeInContent">

        <div data-content-field="main-content" data-item-id="5f345c2627596008f7a23ddd">
  
  <div>
    <p><time datetime="2020-08-12" pubdate="">
      <p><span>Aug </span><span>12</span>
      </p>
    </time></p><h2 data-content-field="title"><time datetime="2020-08-12" pubdate="">Aug 12 </time>Reimbursement Subscription</h2>

    
  </div>
  

  <div>
    <article id="article-5f345c2627596008f7a23ddd">
      
      
      <div data-controller="BlogProgressBar">
        
        
        <div><div data-layout-label="Post Body" data-type="item" data-updated-on="1597267675857" id="item-5f345c2627596008f7a23ddd"><div><div><div data-block-type="2" id="block-8bd4312266dd6b944c7c"><div><p><strong>Problem: </strong>Subscription services like gyms only make money for the days that you don’t show up. They profit from having a critical mass of “inactive users.” Many other businesses also thrive off this “inactive user model.” This does not help to develop positive habits.</p><p><strong>Solution: </strong>Transitioning “inactive user businesses” (like gyms, sports clubs, clubhouses, and other businesses) into subscriptions services where you pay a high up-front-fee and get <em>reimbursed </em>for your use of the space. This could happen on any cadence. This would give businesses more capital up-front to use for development and growth while also incentivizing use of services and increased user satisfaction.</p><p>This idea was heavily inspired by <a href="https://twitter.com/moizali/status/1271949904928223233">Moiz Ali</a> and <a href="https://twitter.com/highdeepak/status/1272165921969192961">Deepak Kanakaraju</a> in their tweets earlier this summer.</p></div></div><div data-block-json="{&quot;hSize&quot;:null,&quot;floatDir&quot;:null,&quot;url&quot;:&quot;https://twitter.com/moizali/status/1271949904928223233&quot;,&quot;html&quot;:&quot;<blockquote class=\&quot;twitter-tweet\&quot;><p lang=\&quot;en\&quot; dir=\&quot;ltr\&quot;>$100M idea: <br><br>Gym cost $30 a month. Each day you show up, you get $1 back.  <br><br>Don't come? $30 a month. <br>Come everyday: Free. <br><br>1 year commitment required when you sign up.</p>\u2014 Moiz Ali (@moizali) <a href=\&quot;https://twitter.com/moizali/status/1271949904928223233?ref_src=twsrc%5Etfw\&quot;>June 13, 2020</a></blockquote>\n<script async=\&quot;\&quot; src=\&quot;https://platform.twitter.com/widgets.js\&quot; charset=\&quot;utf-8\&quot;></script>&quot;,&quot;resolveObject&quot;:&quot;Tweet&quot;,&quot;resolvedBy&quot;:&quot;twitter&quot;,&quot;resolved&quot;:true,&quot;width&quot;:550,&quot;height&quot;:null,&quot;type&quot;:&quot;rich&quot;,&quot;cache_age&quot;:&quot;3153600000&quot;,&quot;version&quot;:&quot;1.0&quot;,&quot;authorName&quot;:&quot;Moiz Ali&quot;,&quot;authorUrl&quot;:&quot;https://twitter.com/moizali&quot;,&quot;providerName&quot;:&quot;Twitter&quot;,&quot;providerUrl&quot;:&quot;https://twitter.com&quot;}" data-block-type="22" id="block-yui_3_17_2_1_1597265517080_26657"><div><blockquote><div lang="en" dir="ltr"><p>$100M idea: </p><p>Gym cost $30 a month. Each day you show up, you get $1 back.  </p><p>Don't come? $30 a month. <br>Come everyday: Free. </p><p>1 year commitment required when you sign up.</p></div>— Moiz Ali (@moizali) <a href="https://twitter.com/moizali/status/1271949904928223233?ref_src=twsrc%5Etfw">June 13, 2020</a></blockquote>
</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597265517080_26724"><div><p>These up-front and per-day reimbursement models can help to create a new business model that can break into the <a href="https://www.ibisworld.com/industry-statistics/market-size/gym-health-fitness-clubs-united-states/">$34 billion Gym, Health, and Fitness Club</a> market. Moreover, it would help to build positive habits that reward following through on goals and New Years resolutions that current (i.e. broken) business models do not promote or enforce.</p><p>This business would essentially gamify habits to make it much easier and much more fun to become a better person. Perhaps the mission would be “Paying you to become 1% better every day.”</p><p><strong>Monetization: </strong>A small premium for creating this incentive service. </p><p><strong>Contributed by: </strong><a href="https://www.michaelbervell.com/">Michael Bervell</a> (Billion Dollar Startup Ideas)</p></div></div></div></div></div></div>

        

        

        
      </div>
      

    </article>
  </div>







  
    
        
        
      
  
</div>

      </main>

      

    </div></div>]]>
            </description>
            <link>https://www.billiondollarstartupideas.com/ideas/reimbursement-subscription</link>
            <guid isPermaLink="false">hacker-news-small-sites-24139211</guid>
            <pubDate>Thu, 13 Aug 2020 01:57:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Package managers need a permission model like mobile]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24139196">thread link</a>) | @awinter-py
<br/>
August 12, 2020 | https://abe-winter.github.io/seno/ekta/gamat/2020/08/12/libperms.html | <a href="https://web.archive.org/web/*/https://abe-winter.github.io/seno/ekta/gamat/2020/08/12/libperms.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Software libraries and language package managers need a permission model like mobile.</p>

<p>I really hate mobile but permissions are the best thing they’ve done.
I installed zoom on my phone and not on my laptop, for example, because zoom is an infestation and mobile OSes are built for isolation.</p>

<p>We should have the same ability to isolate and limit 3rd-party code that gets built into the applications that we write.</p>

<p>It would be great to assert,
in my requirements.txt or package.json or go.mod,
that a library doesn’t connect to the internet, or write to disk, or start threads (i.e. do out of band work), or access heap (i.e. read anything not passed into it).</p>

<p>And it should FAIL THE EFFING BUILD if that changes in the future.</p>

<h2 id="how">How</h2>

<p>‘How’ is complicated – you might block access to parts of the standard library.
But OSes provide a lot of attack surfaces for network access (filesystem, system calls), so I don’t think this is totally simple.</p>

<p>I suspect compiled languages are harder to control than interpreted languages, and might require more sophisticated protection.</p>

<p>Compiled code already has an ‘executable’ bit to distinguish it from random memory and protect against buffer overflows.
I think this is hardware-mediated, not OS-level, so it’s not as simple as patching the kernel.
But it would be neat to have your hardware enforce ‘no system calls’ for parts of your program.
I wonder if pervasive VMs in cloud hosting make this easier; can Xen enforce this?</p>

<h2 id="why-arent-software-supply-chain-attacks-pervasive">Why aren’t software supply chain attacks pervasive</h2>

<p>I wonder about this all the time.</p>

<p>Maybe it takes a fair amount of earned trust to produce a useful library, and it’s hard-ish to fake that, and expensive to squander it?</p>

<p>My sense (and I don’t study this, so don’t quote me) is that supply chain attacks now happen through
abandonware, or typos for common packages.</p>

<p>There are some war stories for binary downloads and system updates.
<a href="https://www.wired.com/story/inside-the-unnerving-supply-chain-attack-that-corrupted-ccleaner/">Avast’s CCleaner got hit</a>,
<a href="https://www.kaspersky.com/blog/shadow-hammer-teaser/26149/">ASUS’s system update tool got compromised</a>,
<a href="https://www.zdnet.com/article/linux-mint-website-hacked-malicious-backdoor-version/">someone replaced the download URL for Linux MINT</a>.
Interestingly none of these are for source downloads.</p>

<p>I think the NSA pressured RSA or RSA employees to weaken some prime numbers that they used in key generation.
I could be convinced that a lot of state-level supply chain attacks take this form, of introducing or preserving subtle flaws.</p>

<p>I don’t doubt that software trust will become more important,
and that attacks will pick up.
We need more tools to keep our stuff safe.
Package permissions can be one of them.</p>






  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://abe-winter.github.io/seno/ekta/gamat/2020/08/12/libperms.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24139196</guid>
            <pubDate>Thu, 13 Aug 2020 01:54:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Being a generalist requires more sleep than specialists]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24138674">thread link</a>) | @searchableguy
<br/>
August 12, 2020 | https://hndex.org/1730462 | <a href="https://web.archive.org/web/*/https://hndex.org/1730462">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<header>

<a href="https://news.ycombinator.com/item?id=1730462" target="_blank">comments</a> <a href="https://andymckenzie.blogspot.com/2010/09/trade-off-10-plasticity-vs.html" target="_blank">original article</a></header>
<p>In college, I was constantly reading neuro lit extolling the
virtues of neural plasticity, which is the ability of neurons to
change based on feedback from the environment. Plasticity certainly
has huge benefits. Specifically, plasticity allows for a better
match between phenotype and environment across variable
environments than a single, constant phenotype would.</p>
<p>But after a while, the idolatry of plasticity began to annoy me,
in part because much of the lit discussed plasticity <i>as if it
had no downsides</i>, which seems impossible. (If there really were
no costs to plasticity, then evolution should have selected for it
like <i>woah</i>).</p>
<p>The general downside seems to be that plasticity hinders
specialization. That is, if a system has the ability to change
easily (i.e. it has high plasticity), then it will tend to expend
resources on a wide range of trait values, and will have fewer
resources to focus on the most important and relevant traits. A few
examples:</p>
<ul>
<li>Synaptic pruning and other mechanisms for synaptic plasticity
allow for learning and memory, but they are energetically costly.
Indeed, one hypothesis holds that sleep is the price we have to pay
for plasticity the previous day. (see here)</li>
<li>In an evolutionary framework, the major costs to more
plasticity are 1) actually sensing the current environmental
conditions, and 2) producing the actual trait in a less efficient
way. Both of these divert resources from other tasks. (see here and
here)</li>
<li>People with autism spectrum disorders often find it difficult
to parse novel stimuli, but can sometimes concentrate for
especially long periods of time on specific niches. So one might
think of the autistic cognitive style as shifted towards the
specialization side of this trade off. (see here)</li>
</ul>
<p>Despite the many applications, the members of the committee and
I are a bit wary about this trade off. First, its status depends
largely on one's particular definitions of plasticity and
specialization. Also, some think it might just be a specific case
of trade off #3, switching costs vs change gains.</p>
<p>But given our current working definitions (plasticity = the
ability, which is highly correlated with the tendency, for
context-dependent change; specialization = funneling energy
expenditures to a narrow purpose), and because it is sort of one
level "meta" to switching costs vs change gains, we are granting
this trade off its own place in the canon.</p>
<p>(Above photo taken by flickr user uncle beast. Plants are often
studied w/r/t genetic plasticity because they can't simply pack up
shop and move if the environment changes, like an animal or insect
could.)</p>
</article></div>]]>
            </description>
            <link>https://hndex.org/1730462</link>
            <guid isPermaLink="false">hacker-news-small-sites-24138674</guid>
            <pubDate>Thu, 13 Aug 2020 00:19:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vitamin D, part 1: back to basics]]>
            </title>
            <description>
<![CDATA[
Score 371 | Comments 137 (<a href="https://news.ycombinator.com/item?id=24138590">thread link</a>) | @conorh
<br/>
August 12, 2020 | https://www.devaboone.com/post/vitamin-d-part-1-back-to-basics | <a href="https://web.archive.org/web/*/https://www.devaboone.com/post/vitamin-d-part-1-back-to-basics">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="7.16.2"><div dir="ltr"><div><div id="viewer-cnct8"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.devaboone.com/post/vitamin-d-part-1-back-to-basics" data-pin-media="https://static.wixstatic.com/media/3e0600_d714cff5c2c346ca9f3f81a007aa2b44~mv2.jpg/v1/fit/w_900,h_597,al_c,q_80/file.png" src="https://static.wixstatic.com/media/3e0600_d714cff5c2c346ca9f3f81a007aa2b44~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-dpa1h">Vitamin D is a big deal. Recent studies have shown that patients with low Vitamin D levels are more likely to die from Covid-19 than their Vitamin D-rich counterparts,(1) and deficiency in the vitamin has been linked to seven of the ten leading causes of death in the U.S.(2) These facts alone have been enough incentive for many people to start supplementing the vitamin. A common question from my patients is: how much Vitamin D should I take? This is a simple question, but there are a lot of assumptions built in. Before you order that case of Vitamin D for you and your family, let’s back up and look a little more at the data.
 </p><p id="viewer-49tlt">First, why I’m interested in Vitamin D: I’m a parathyroid surgeon, and the vitamin is something I track closely in my patients. For background, the parathyroid glands are tiny endocrine organs in your neck that regulate blood calcium levels. They do this partly through the activation of Vitamin D, which helps the intestines absorb calcium. Without Vitamin D, you will have difficulty getting enough calcium, even if you are taking calcium supplements. Your bones need calcium, so a severe deficiency in Vitamin D leads to bone deformities in children (rickets) and bone loss in adults (osteomalacia). </p><div id="viewer-bovng"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.devaboone.com/post/vitamin-d-part-1-back-to-basics" data-pin-media="https://static.wixstatic.com/media/3e0600_4a3a0724a42049019ad1182bcdb30d79~mv2.png/v1/fit/w_700,h_375,al_c,q_80/file.png" src="https://static.wixstatic.com/media/3e0600_4a3a0724a42049019ad1182bcdb30d79~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-csmdc"><em> Normal child femurs compared to femurs of a child with rickets. Rickets is caused by a severe Vitamin D deficiency while bones are growing. This condition is now very rare in the U.S. due to the fortification of almost all milk with Vitamin D.* </em></p><p id="viewer-6lba0">The relationship between parathyroid hormone, calcium, and Vitamin D is complex and fascinating (at least to a parathyroid surgeon), but the vitamin appears to do much more than just influence calcium. We’re still figuring out all that it does, but we have some circumstantial evidence about its roles. Low Vitamin D levels are linked to a variety of illnesses including cancers, hypertension, diabetes, obesity, heart failure, stroke, dementia, autoimmune disease, and respiratory tract infections (including Covid-19). A simple search of the medical literature on PubMed produces page after page of articles on the harms of Vitamin D deficiency. </p><p id="viewer-5l5ac"><strong>Most studies follow this pattern:</strong> Two sets of people are evaluated. One set has a certain disease (diabetes, for example). The other set does not have the disease. Vitamin D levels are measured in both groups. Vitamin D deficiency is found to be much more common in the group of diseased individuals. </p><p id="viewer-4f52t">Using this study method, Vitamin D deficiency is correlated with many diseases. But correlation does not equal causation. The fact that two things are related does not imply that one caused the other. With regard to the vitamin and diabetes, it could be that diabetes causes low Vitamin D. Or it may be that some other health condition causes both low Vitamin D and diabetes. Obesity, for example, is a known risk factor for diabetes, and people who are obese also tend to have low Vitamin D levels, due mostly to the dilution of the fat-soluble vitamin in the larger mass of adipose tissue. The close association between Vitamin D and diabetes could be due simply to the association they both share with obesity. </p><p id="viewer-1plm0">Here is another example: Early interest in respiratory infections and Vitamin D was due to research on hospitalized children. Young children who were hospitalized with respiratory infections were found to have much higher rates of rickets than children hospitalized for other causes.(3) Rickets, of course, is caused by Vitamin D deficiency. If Vitamin D deficiency also causes immune dysfunction, we might come up with an explanation for how low Vitamin D in these children made them more susceptible to infection. But there are other explanations. Children with a serious vitamin deficiency are likely to be less healthy overall compared to non-deficient children. In addition, rickets can cause rib deformities, which are known to make it harder to cough and breathe deeply, leading to an increased risk of respiratory infections. Vitamin D itself is not necessary for explaining the infections in these children. 
 </p><p id="viewer-8d45v">Most researchers understand that correlation does not equal causation. The classic example of this involves the correlation between ice cream and violent crime. As ice cream consumption rises, so does the rate of violent crime. The association is strong, and puzzling, until you remember that more ice cream is sold during warmer months, which is also when violent crime rates rise. Ice cream has no causative connection to crime. </p><div id="viewer-8u104"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.devaboone.com/post/vitamin-d-part-1-back-to-basics" data-pin-media="https://static.wixstatic.com/media/3e0600_7750c8e0f0804ca7b241349a5caa3f6a~mv2.jpg/v1/fit/w_900,h_720,al_c,q_80/file.png" src="https://static.wixstatic.com/media/3e0600_7750c8e0f0804ca7b241349a5caa3f6a~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-2muq9"><em>Children about to embark on a life of crime?</em></p><p id="viewer-i9b6"><strong>But the temptation to equate correlation and causation is strong.</strong> Many articles showing a correlation with Vitamin D will add an untested but completely plausible physiological explanation for how low vitamin levels could lead to the disease. Armed with a solid correlation and a reasonable argument for causation, they may feel justified in concluding that the evidence for causation is strong. And once you have made that leap, you are almost obligated in recommending Vitamin D supplementation for anyone affected by or concerned about your disease of interest. </p><p id="viewer-9rfi1">Assuming that the correlations between Vitamin D and various illnesses are accurate, the argument for supplementation then depends on the plausibility of the physiologic mechanism. The numerous conditions associated with the deficiency involve disparate organs and body systems. To understand how one vitamin could be involved in so much, and whether we can explain a disease state by the vitamin's deficiency, it helps to know the basics of what Vitamin D does on a molecular level.</p><p id="viewer-ccvgc"><strong>Vitamin D is a hormone that binds to the Vitamin D Receptor</strong>, a protein made by cells throughout your body. The vitamin acts like a key, while the receptor is a lock. A key and lock are pointless individually, but useful together. Vitamin D and its receptor are inactive until they combine, and then they interact with DNA to produce certain actions within the cell. Based on what we already know, it is easy to understand why the intestines, parathyroids, and bones make Vitamin D Receptors – these organs are all involved in regulating calcium levels, and we know Vitamin D regulates calcium metabolism. But those are not the only organs that have the receptors. We find these receptors all over the place, in the kidneys, lungs, pancreas, uterus, and blood cells involved in immune function, just to name a few.(4,5) </p><p id="viewer-5olt1">Our bodies like to conserve resources, so if an organ or cell uses energy and resources to make these receptors, we can assume that they use them. This is the first solid piece of evidence that Vitamin D is involved in many processes throughout multiple organs. The next goal is to figure out how the organs use Vitamin D. There are various ways to do this. One clever method involves the use of mutant mice called “knockout mice” that have been genetically modified to inactivate a specific gene. In this case, the gene for the Vitamin D Receptor is inactivated, to produce "VDR null" mice. Studies in these animals provide important clues about Vitamin D, since without the lock, or receptor, the key is useless. As expected, these knockout mice have problems with calcium absorption, and the most notable effect is stunted bone growth.(6) This can be mitigated by giving the mice lots of calcium, which makes sense, since it is possible but harder for calcium to be absorbed without Vitamin D.</p><div id="viewer-3qo09"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.devaboone.com/post/vitamin-d-part-1-back-to-basics" data-pin-media="https://static.wixstatic.com/media/a27d24_ea278d26b9924aa2b2b0105b816d4c62~mv2.jpg/v1/fit/w_887,h_377,al_c,q_80/file.png" src="https://static.wixstatic.com/media/a27d24_ea278d26b9924aa2b2b0105b816d4c62~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-75iel"><em>Knockout mice are mice that have been genetically modified to inactivate a specific gene. VDR null mice are knockout mice that do not make Vitamin D Receptors. (The mouse in the photo is just a random mouse. We don't actually grow them in petri dishes.)</em></p><p id="viewer-4s6nd">But we already knew about Vitamin D and calcium. What about those other effects? VDR null mice should be helpful in explaining Vitamin D’s other roles, and we do see some revealing changes: these mutant mice on average have higher blood pressure than normal mice, and mice lacking the receptor specifically on the heart have decreased cardiac function. Certain immune cells also seem to also be impaired in the mutant mice.</p><p id="viewer-fakeg">Following this out a few steps, we could come up with a logical explanation for how Vitamin D helps the immune system, and thus deficiency would lead to impaired immune function, which then lead to increased susceptibility to infections. It sounds reasonable. But there are a few assumptions we are making: 1. We assume that Vitamin D deficiency is similar to a complete absence of the receptor. This is questionable, since even people with severe Vitamin D deficiencies still have some amount of Vitamin D. 2. We also assume that the receptor works exactly the same in mice as it does in humans. Mice and humans are relatively close on the evolutionary tree (when compared to, say, shiitake mushrooms), so this could be true, but maybe not.</p><p id="viewer-5b36s">Maybe we need to go back to humans. Interestingly, there is a very rare condition in humans characterized by ineffective Vitamin D Receptors due to a genetic mutation, similar to the VDR null mice.(7) Like the mice, these individuals will develop severely abnormal bone growth if untreated. Thinking logically and using what we know about the receptor in mice, we might expect that these individuals who cannot process Vitamin D effectively would have immune dysfunction, and perhaps cardiac issues. So far, we have not seen this. They do not appear to have an increased risk of cancer, respiratory infections, diabetes, or any of the other conditions found to be associated with Vitamin D deficiency. This genetic defect is extremely rare, though, and we have not yet been able to study these patients over a lifetime, so we may have more to learn. </p><p id="viewer-1lu5r">Studying the Vitamin D Receptor in living bodies is not the only way to assess Vitamin D’s actions. We can also study Vitamin D in a lab, using living cells in a test tube or culture dish. Much of our evidence for a link between Vitamin D and immunity comes from these <em>in vitro</em> studies. Vitamin D Receptors are …</p></div></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.devaboone.com/post/vitamin-d-part-1-back-to-basics">https://www.devaboone.com/post/vitamin-d-part-1-back-to-basics</a></em></p>]]>
            </description>
            <link>https://www.devaboone.com/post/vitamin-d-part-1-back-to-basics</link>
            <guid isPermaLink="false">hacker-news-small-sites-24138590</guid>
            <pubDate>Thu, 13 Aug 2020 00:07:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Memoization in Dynamic Programming Through Examples]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24138567">thread link</a>) | @algodaily
<br/>
August 12, 2020 | https://algodaily.com/lessons/memoization-in-dynamic-programming/?view=article | <a href="https://web.archive.org/web/*/https://algodaily.com/lessons/memoization-in-dynamic-programming/?view=article">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://algodaily.com/lessons/memoization-in-dynamic-programming/?view=article</link>
            <guid isPermaLink="false">hacker-news-small-sites-24138567</guid>
            <pubDate>Thu, 13 Aug 2020 00:03:33 GMT</pubDate>
        </item>
    </channel>
</rss>
